commit e7a79811d0db136dc2d336b56d54cf1b774ce972
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Jun 15 10:38:44 2020 +0100

    btrfs: check if a log root exists before locking the log_mutex on unlink
    
    This brings back an optimization that commit e678934cbe5f02 ("btrfs:
    Remove unnecessary check from join_running_log_trans") removed, but in
    a different form. So it's almost equivalent to a revert.
    
    That commit removed an optimization where we avoid locking a root's
    log_mutex when there is no log tree created in the current transaction.
    The affected code path is triggered through unlink operations.
    
    That commit was based on the assumption that the optimization was not
    necessary because we used to have the following checks when the patch
    was authored:
    
      int btrfs_del_dir_entries_in_log(...)
      {
            (...)
            if (dir->logged_trans < trans->transid)
                return 0;
    
            ret = join_running_log_trans(root);
            (...)
       }
    
       int btrfs_del_inode_ref_in_log(...)
       {
            (...)
            if (inode->logged_trans < trans->transid)
                return 0;
    
            ret = join_running_log_trans(root);
            (...)
       }
    
    However before that patch was merged, another patch was merged first which
    replaced those checks because they were buggy.
    
    That other patch corresponds to commit 803f0f64d17769 ("Btrfs: fix fsync
    not persisting dentry deletions due to inode evictions"). The assumption
    that if the logged_trans field of an inode had a smaller value then the
    current transaction's generation (transid) meant that the inode was not
    logged in the current transaction was only correct if the inode was not
    evicted and reloaded in the current transaction. So the corresponding bug
    fix changed those checks and replaced them with the following helper
    function:
    
      static bool inode_logged(struct btrfs_trans_handle *trans,
                               struct btrfs_inode *inode)
      {
            if (inode->logged_trans == trans->transid)
                    return true;
    
            if (inode->last_trans == trans->transid &&
                test_bit(BTRFS_INODE_NEEDS_FULL_SYNC, &inode->runtime_flags) &&
                !test_bit(BTRFS_FS_LOG_RECOVERING, &trans->fs_info->flags))
                    return true;
    
            return false;
      }
    
    So if we have a subvolume without a log tree in the current transaction
    (because we had no fsyncs), every time we unlink an inode we can end up
    trying to lock the log_mutex of the root through join_running_log_trans()
    twice, once for the inode being unlinked (by btrfs_del_inode_ref_in_log())
    and once for the parent directory (with btrfs_del_dir_entries_in_log()).
    
    This means if we have several unlink operations happening in parallel for
    inodes in the same subvolume, and the those inodes and/or their parent
    inode were changed in the current transaction, we end up having a lot of
    contention on the log_mutex.
    
    The test robots from intel reported a -30.7% performance regression for
    a REAIM test after commit e678934cbe5f02 ("btrfs: Remove unnecessary check
    from join_running_log_trans").
    
    So just bring back the optimization to join_running_log_trans() where we
    check first if a log root exists before trying to lock the log_mutex. This
    is done by checking for a bit that is set on the root when a log tree is
    created and removed when a log tree is freed (at transaction commit time).
    
    Commit e678934cbe5f02 ("btrfs: Remove unnecessary check from
    join_running_log_trans") was merged in the 5.4 merge window while commit
    803f0f64d17769 ("Btrfs: fix fsync not persisting dentry deletions due to
    inode evictions") was merged in the 5.3 merge window. But the first
    commit was actually authored before the second commit (May 23 2019 vs
    June 19 2019).
    
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Link: https://lore.kernel.org/lkml/20200611090233.GL12456@shao2-debian/
    Fixes: e678934cbe5f02 ("btrfs: Remove unnecessary check from join_running_log_trans")
    CC: stable@vger.kernel.org # 5.4+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 30ce7039bc27..d404cce8ae40 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1009,6 +1009,8 @@ enum {
 	BTRFS_ROOT_DEAD_RELOC_TREE,
 	/* Mark dead root stored on device whose cleanup needs to be resumed */
 	BTRFS_ROOT_DEAD_TREE,
+	/* The root has a log tree. Used only for subvolume roots. */
+	BTRFS_ROOT_HAS_LOG_TREE,
 };
 
 /*

commit 55e20bd12a56e06c38b953177bb162cbbaa96004
Author: David Sterba <dsterba@suse.com>
Date:   Tue Jun 9 19:56:06 2020 +0200

    Revert "btrfs: switch to iomap_dio_rw() for dio"
    
    This reverts commit a43a67a2d715540c1368b9501a22b0373b5874c0.
    
    This patch reverts the main part of switching direct io implementation
    to iomap infrastructure. There's a problem in invalidate page that
    couldn't be solved as regression in this development cycle.
    
    The problem occurs when buffered and direct io are mixed, and the ranges
    overlap. Although this is not recommended, filesystems implement
    measures or fallbacks to make it somehow work. In this case, fallback to
    buffered IO would be an option for btrfs (this already happens when
    direct io is done on compressed data), but the change would be needed in
    the iomap code, bringing new semantics to other filesystems.
    
    Another problem arises when again the buffered and direct ios are mixed,
    invalidation fails, then -EIO is set on the mapping and fsync will fail,
    though there's no real error.
    
    There have been discussions how to fix that, but revert seems to be the
    least intrusive option.
    
    Link: https://lore.kernel.org/linux-btrfs/20200528192103.xm45qoxqmkw7i5yl@fiona/
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 47b8874eddff..30ce7039bc27 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2933,7 +2933,6 @@ int btrfs_writepage_cow_fixup(struct page *page, u64 start, u64 end);
 void btrfs_writepage_endio_finish_ordered(struct page *page, u64 start,
 					  u64 end, int uptodate);
 extern const struct dentry_operations btrfs_dentry_operations;
-ssize_t btrfs_direct_IO(struct kiocb *iocb, struct iov_iter *iter);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit f4c48b44080e18d86d7983c1a60ee5a7f9d07e3e
Author: David Sterba <dsterba@suse.com>
Date:   Tue Jun 9 19:19:27 2020 +0200

    Revert "btrfs: split btrfs_direct_IO to read and write part"
    
    This reverts commit d8f3e73587ce574f7a9bc165e0db69b0b148f6f8.
    
    The patch is a cleanup of direct IO port to iomap infrastructure,
    which gets reverted.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 161533040978..47b8874eddff 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -28,7 +28,6 @@
 #include <linux/dynamic_debug.h>
 #include <linux/refcount.h>
 #include <linux/crc32c.h>
-#include <linux/iomap.h>
 #include "extent-io-tree.h"
 #include "extent_io.h"
 #include "extent_map.h"
@@ -2935,8 +2934,6 @@ void btrfs_writepage_endio_finish_ordered(struct page *page, u64 start,
 					  u64 end, int uptodate);
 extern const struct dentry_operations btrfs_dentry_operations;
 ssize_t btrfs_direct_IO(struct kiocb *iocb, struct iov_iter *iter);
-extern const struct iomap_ops btrfs_dio_iomap_ops;
-extern const struct iomap_dio_ops btrfs_dops;
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit d8f3e73587ce574f7a9bc165e0db69b0b148f6f8
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 19 09:46:29 2020 -0500

    btrfs: split btrfs_direct_IO to read and write part
    
    The read and write versions don't have anything in common except for the
    call to iomap_dio_rw.  So split this function, and merge each half into
    its only caller.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 47b8874eddff..161533040978 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -28,6 +28,7 @@
 #include <linux/dynamic_debug.h>
 #include <linux/refcount.h>
 #include <linux/crc32c.h>
+#include <linux/iomap.h>
 #include "extent-io-tree.h"
 #include "extent_io.h"
 #include "extent_map.h"
@@ -2934,6 +2935,8 @@ void btrfs_writepage_endio_finish_ordered(struct page *page, u64 start,
 					  u64 end, int uptodate);
 extern const struct dentry_operations btrfs_dentry_operations;
 ssize_t btrfs_direct_IO(struct kiocb *iocb, struct iov_iter *iter);
+extern const struct iomap_ops btrfs_dio_iomap_ops;
+extern const struct iomap_dio_ops btrfs_dops;
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit a43a67a2d715540c1368b9501a22b0373b5874c0
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Tue May 19 09:14:18 2020 -0500

    btrfs: switch to iomap_dio_rw() for dio
    
    Switch from __blockdev_direct_IO() to iomap_dio_rw().
    Rename btrfs_get_blocks_direct() to btrfs_dio_iomap_begin() and use it
    as iomap_begin() for iomap direct I/O functions. This function
    allocates and locks all the blocks required for the I/O.
    btrfs_submit_direct() is used as the submit_io() hook for direct I/O
    ops.
    
    Since we need direct I/O reads to go through iomap_dio_rw(), we change
    file_operations.read_iter() to a btrfs_file_read_iter() which calls
    btrfs_direct_IO() for direct reads and falls back to
    generic_file_buffered_read() for incomplete reads and buffered reads.
    
    We don't need address_space.direct_IO() anymore so set it to noop.
    Similarly, we don't need flags used in __blockdev_direct_IO(). iomap is
    capable of direct I/O reads from a hole, so we don't need to return
    -ENOENT.
    
    BTRFS direct I/O is now done under i_rwsem, shared in case of reads and
    exclusive in case of writes. This guards against simultaneous truncates.
    
    Use iomap->iomap_end() to check for failed or incomplete direct I/O:
     - for writes, call __endio_write_update_ordered()
     - for reads, unlock extents
    
    btrfs_dio_data is now hooked in iomap->private and not
    current->journal_info. It carries the reservation variable and the
    amount of data submitted, so we can calculate the amount of data to call
    __endio_write_update_ordered in case of an error.
    
    This patch removes last use of struct buffer_head from btrfs.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 30ce7039bc27..47b8874eddff 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2933,6 +2933,7 @@ int btrfs_writepage_cow_fixup(struct page *page, u64 start, u64 end);
 void btrfs_writepage_endio_finish_ordered(struct page *page, u64 start,
 					  u64 end, int uptodate);
 extern const struct dentry_operations btrfs_dentry_operations;
+ssize_t btrfs_direct_IO(struct kiocb *iocb, struct iov_iter *iter);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit e289f03ea79bbc6574b78ac25682555423a91cbb
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 18 12:14:50 2020 +0100

    btrfs: fix corrupt log due to concurrent fsync of inodes with shared extents
    
    When we have extents shared amongst different inodes in the same subvolume,
    if we fsync them in parallel we can end up with checksum items in the log
    tree that represent ranges which overlap.
    
    For example, consider we have inodes A and B, both sharing an extent that
    covers the logical range from X to X + 64KiB:
    
    1) Task A starts an fsync on inode A;
    
    2) Task B starts an fsync on inode B;
    
    3) Task A calls btrfs_csum_file_blocks(), and the first search in the
       log tree, through btrfs_lookup_csum(), returns -EFBIG because it
       finds an existing checksum item that covers the range from X - 64KiB
       to X;
    
    4) Task A checks that the checksum item has not reached the maximum
       possible size (MAX_CSUM_ITEMS) and then releases the search path
       before it does another path search for insertion (through a direct
       call to btrfs_search_slot());
    
    5) As soon as task A releases the path and before it does the search
       for insertion, task B calls btrfs_csum_file_blocks() and gets -EFBIG
       too, because there is an existing checksum item that has an end
       offset that matches the start offset (X) of the checksum range we want
       to log;
    
    6) Task B releases the path;
    
    7) Task A does the path search for insertion (through btrfs_search_slot())
       and then verifies that the checksum item that ends at offset X still
       exists and extends its size to insert the checksums for the range from
       X to X + 64KiB;
    
    8) Task A releases the path and returns from btrfs_csum_file_blocks(),
       having inserted the checksums into an existing checksum item that got
       its size extended. At this point we have one checksum item in the log
       tree that covers the logical range from X - 64KiB to X + 64KiB;
    
    9) Task B now does a search for insertion using btrfs_search_slot() too,
       but it finds that the previous checksum item no longer ends at the
       offset X, it now ends at an of offset X + 64KiB, so it leaves that item
       untouched.
    
       Then it releases the path and calls btrfs_insert_empty_item()
       that inserts a checksum item with a key offset corresponding to X and
       a size for inserting a single checksum (4 bytes in case of crc32c).
       Subsequent iterations end up extending this new checksum item so that
       it contains the checksums for the range from X to X + 64KiB.
    
       So after task B returns from btrfs_csum_file_blocks() we end up with
       two checksum items in the log tree that have overlapping ranges, one
       for the range from X - 64KiB to X + 64KiB, and another for the range
       from X to X + 64KiB.
    
    Having checksum items that represent ranges which overlap, regardless of
    being in the log tree or in the chekcsums tree, can lead to problems where
    checksums for a file range end up not being found. This type of problem
    has happened a few times in the past and the following commits fixed them
    and explain in detail why having checksum items with overlapping ranges is
    problematic:
    
      27b9a8122ff71a "Btrfs: fix csum tree corruption, duplicate and outdated checksums"
      b84b8390d6009c "Btrfs: fix file read corruption after extent cloning and fsync"
      40e046acbd2f36 "Btrfs: fix missing data checksums after replaying a log tree"
    
    Since this specific instance of the problem can only happen when logging
    inodes, because it is the only case where concurrent attempts to insert
    checksums for the same range can happen, fix the issue by using an extent
    io tree as a range lock to serialize checksum insertion during inode
    logging.
    
    This issue could often be reproduced by the test case generic/457 from
    fstests. When it happens it produces the following trace:
    
     BTRFS critical (device dm-0): corrupt leaf: root=18446744073709551610 block=30625792 slot=42, csum end range (15020032) goes beyond the start range (15015936) of the next csum item
     BTRFS info (device dm-0): leaf 30625792 gen 7 total ptrs 49 free space 2402 owner 18446744073709551610
     BTRFS info (device dm-0): refs 1 lock (w:0 r:0 bw:0 br:0 sw:0 sr:0) lock_owner 0 current 15884
          item 0 key (18446744073709551606 128 13979648) itemoff 3991 itemsize 4
          item 1 key (18446744073709551606 128 13983744) itemoff 3987 itemsize 4
          item 2 key (18446744073709551606 128 13987840) itemoff 3983 itemsize 4
          item 3 key (18446744073709551606 128 13991936) itemoff 3979 itemsize 4
          item 4 key (18446744073709551606 128 13996032) itemoff 3975 itemsize 4
          item 5 key (18446744073709551606 128 14000128) itemoff 3971 itemsize 4
     (...)
     BTRFS error (device dm-0): block=30625792 write time tree block corruption detected
     ------------[ cut here ]------------
     WARNING: CPU: 1 PID: 15884 at fs/btrfs/disk-io.c:539 btree_csum_one_bio+0x268/0x2d0 [btrfs]
     Modules linked in: btrfs dm_thin_pool ...
     CPU: 1 PID: 15884 Comm: fsx Tainted: G        W         5.6.0-rc7-btrfs-next-58 #1
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.0-59-gc9ba5276e321-prebuilt.qemu.org 04/01/2014
     RIP: 0010:btree_csum_one_bio+0x268/0x2d0 [btrfs]
     Code: c7 c7 ...
     RSP: 0018:ffffbb0109e6f8e0 EFLAGS: 00010296
     RAX: 0000000000000000 RBX: ffffe1c0847b6080 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: ffffffffaa963988 RDI: 0000000000000001
     RBP: ffff956a4f4d2000 R08: 0000000000000000 R09: 0000000000000001
     R10: 0000000000000526 R11: 0000000000000000 R12: ffff956a5cd28bb0
     R13: 0000000000000000 R14: ffff956a649c9388 R15: 000000011ed82000
     FS:  00007fb419959e80(0000) GS:ffff956a7aa00000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     CR2: 0000000000fe6d54 CR3: 0000000138696005 CR4: 00000000003606e0
     DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     Call Trace:
      btree_submit_bio_hook+0x67/0xc0 [btrfs]
      submit_one_bio+0x31/0x50 [btrfs]
      btree_write_cache_pages+0x2db/0x4b0 [btrfs]
      ? __filemap_fdatawrite_range+0xb1/0x110
      do_writepages+0x23/0x80
      __filemap_fdatawrite_range+0xd2/0x110
      btrfs_write_marked_extents+0x15e/0x180 [btrfs]
      btrfs_sync_log+0x206/0x10a0 [btrfs]
      ? kmem_cache_free+0x315/0x3b0
      ? btrfs_log_inode+0x1e8/0xf90 [btrfs]
      ? __mutex_unlock_slowpath+0x45/0x2a0
      ? lockref_put_or_lock+0x9/0x30
      ? dput+0x2d/0x580
      ? dput+0xb5/0x580
      ? btrfs_sync_file+0x464/0x4d0 [btrfs]
      btrfs_sync_file+0x464/0x4d0 [btrfs]
      do_fsync+0x38/0x60
      __x64_sys_fsync+0x10/0x20
      do_syscall_64+0x5c/0x280
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
     RIP: 0033:0x7fb41953a6d0
     Code: 48 3d ...
     RSP: 002b:00007ffcc86bd218 EFLAGS: 00000246 ORIG_RAX: 000000000000004a
     RAX: ffffffffffffffda RBX: 000000000000000d RCX: 00007fb41953a6d0
     RDX: 0000000000000009 RSI: 0000000000040000 RDI: 0000000000000003
     RBP: 0000000000040000 R08: 0000000000000001 R09: 0000000000000009
     R10: 0000000000000064 R11: 0000000000000246 R12: 0000556cf4b2c060
     R13: 0000000000000100 R14: 0000000000000000 R15: 0000556cf322b420
     irq event stamp: 0
     hardirqs last  enabled at (0): [<0000000000000000>] 0x0
     hardirqs last disabled at (0): [<ffffffffa96bdedf>] copy_process+0x74f/0x2020
     softirqs last  enabled at (0): [<ffffffffa96bdedf>] copy_process+0x74f/0x2020
     softirqs last disabled at (0): [<0000000000000000>] 0x0
     ---[ end trace d543fc76f5ad7fd8 ]---
    
    In that trace the tree checker detected the overlapping checksum items at
    the time when we triggered writeback for the log tree when syncing the
    log.
    
    Another trace that can happen is due to BUG_ON() when deleting checksum
    items while logging an inode:
    
     BTRFS critical (device dm-0): slot 81 key (18446744073709551606 128 13635584) new key (18446744073709551606 128 13635584)
     BTRFS info (device dm-0): leaf 30949376 gen 7 total ptrs 98 free space 8527 owner 18446744073709551610
     BTRFS info (device dm-0): refs 4 lock (w:1 r:0 bw:0 br:0 sw:1 sr:0) lock_owner 13473 current 13473
      item 0 key (257 1 0) itemoff 16123 itemsize 160
              inode generation 7 size 262144 mode 100600
      item 1 key (257 12 256) itemoff 16103 itemsize 20
      item 2 key (257 108 0) itemoff 16050 itemsize 53
              extent data disk bytenr 13631488 nr 4096
              extent data offset 0 nr 131072 ram 131072
     (...)
     ------------[ cut here ]------------
     kernel BUG at fs/btrfs/ctree.c:3153!
     invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC PTI
     CPU: 1 PID: 13473 Comm: fsx Not tainted 5.6.0-rc7-btrfs-next-58 #1
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.0-59-gc9ba5276e321-prebuilt.qemu.org 04/01/2014
     RIP: 0010:btrfs_set_item_key_safe+0x1ea/0x270 [btrfs]
     Code: 0f b6 ...
     RSP: 0018:ffff95e3889179d0 EFLAGS: 00010282
     RAX: 0000000000000000 RBX: 0000000000000051 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: ffffffffb7763988 RDI: 0000000000000001
     RBP: fffffffffffffff6 R08: 0000000000000000 R09: 0000000000000001
     R10: 00000000000009ef R11: 0000000000000000 R12: ffff8912a8ba5a08
     R13: ffff95e388917a06 R14: ffff89138dcf68c8 R15: ffff95e388917ace
     FS:  00007fe587084e80(0000) GS:ffff8913baa00000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     CR2: 00007fe587091000 CR3: 0000000126dac005 CR4: 00000000003606e0
     DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     Call Trace:
      btrfs_del_csums+0x2f4/0x540 [btrfs]
      copy_items+0x4b5/0x560 [btrfs]
      btrfs_log_inode+0x910/0xf90 [btrfs]
      btrfs_log_inode_parent+0x2a0/0xe40 [btrfs]
      ? dget_parent+0x5/0x370
      btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      btrfs_sync_file+0x42b/0x4d0 [btrfs]
      __x64_sys_msync+0x199/0x200
      do_syscall_64+0x5c/0x280
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
     RIP: 0033:0x7fe586c65760
     Code: 00 f7 ...
     RSP: 002b:00007ffe250f98b8 EFLAGS: 00000246 ORIG_RAX: 000000000000001a
     RAX: ffffffffffffffda RBX: 00000000000040e1 RCX: 00007fe586c65760
     RDX: 0000000000000004 RSI: 0000000000006b51 RDI: 00007fe58708b000
     RBP: 0000000000006a70 R08: 0000000000000003 R09: 00007fe58700cb61
     R10: 0000000000000100 R11: 0000000000000246 R12: 00000000000000e1
     R13: 00007fe58708b000 R14: 0000000000006b51 R15: 0000558de021a420
     Modules linked in: dm_log_writes ...
     ---[ end trace c92a7f447a8515f5 ]---
    
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5afeb17a3f1a..30ce7039bc27 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1167,6 +1167,9 @@ struct btrfs_root {
 	/* Record pairs of swapped blocks for qgroup */
 	struct btrfs_qgroup_swapped_blocks swapped_blocks;
 
+	/* Used only by log trees, when logging csum items */
+	struct extent_io_tree log_csum_range;
+
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 	u64 alloc_bytenr;
 #endif

commit 0202e83fdab05b3bf641804afea57a2bfcbcbd70
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 15 19:35:59 2020 +0200

    btrfs: simplify iget helpers
    
    The inode lookup starting at btrfs_iget takes the full location key,
    while only the objectid is used to match the inode, because the lookup
    happens inside the given root thus the inode number is unique.
    The entire location key is properly set up in btrfs_init_locked_inode.
    
    Simplify the helpers and pass only inode number, renaming it to 'ino'
    instead of 'objectid'. This allows to remove temporary variables key,
    saving some stack space.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 616fdbc53695..5afeb17a3f1a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2898,10 +2898,9 @@ void btrfs_free_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);
 int __init btrfs_init_cachep(void);
 void __cold btrfs_destroy_cachep(void);
-struct inode *btrfs_iget_path(struct super_block *s, struct btrfs_key *location,
+struct inode *btrfs_iget_path(struct super_block *s, u64 ino,
 			      struct btrfs_root *root, struct btrfs_path *path);
-struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
-			 struct btrfs_root *root);
+struct inode *btrfs_iget(struct super_block *s, u64 ino, struct btrfs_root *root);
 struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,
 				    struct page *page, size_t pg_offset,
 				    u64 start, u64 end);

commit aeb935a455812e0ec15e15801f7a42d887e6c22f
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 15 14:01:42 2020 +0800

    btrfs: don't set SHAREABLE flag for data reloc tree
    
    SHAREABLE flag is set for subvolumes because users can create snapshot
    for subvolumes, thus sharing tree blocks of them.
    
    But data reloc tree is not exposed to user space, as it's only an
    internal tree for data relocation, thus it doesn't need the full path
    replacement handling at all.
    
    This patch will make data reloc tree a non-shareable tree, and add
    btrfs_fs_info::data_reloc_root for data reloc tree, so relocation code
    can grab it from fs_info directly.
    
    This would slightly improve tree relocation, as now data reloc tree
    can go through regular COW routine to get relocated, without bothering
    the complex tree reloc tree routine.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bf46093be76e..616fdbc53695 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -582,6 +582,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *quota_root;
 	struct btrfs_root *uuid_root;
 	struct btrfs_root *free_space_root;
+	struct btrfs_root *data_reloc_root;
 
 	/* the log root tree is a directory of all the other log roots */
 	struct btrfs_root *log_root_tree;

commit 92a7cc4252231d1641b36c38cf845cfc50308ab0
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 15 14:01:40 2020 +0800

    btrfs: rename BTRFS_ROOT_REF_COWS to BTRFS_ROOT_SHAREABLE
    
    The name BTRFS_ROOT_REF_COWS is not very clear about the meaning.
    
    In fact, that bit can only be set to those trees:
    
    - Subvolume roots
    - Data reloc root
    - Reloc roots for above roots
    
    All other trees won't get this bit set.  So just by the result, it is
    obvious that, roots with this bit set can have tree blocks shared with
    other trees.  Either shared by snapshots, or by reloc roots (an special
    snapshot created by relocation).
    
    This patch will rename BTRFS_ROOT_REF_COWS to BTRFS_ROOT_SHAREABLE to
    make it easier to understand, and update all comment mentioning
    "reference counted" to follow the rename.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0a1fa1526c43..bf46093be76e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -969,7 +969,28 @@ enum {
 	 * is used to tell us when more checks are required
 	 */
 	BTRFS_ROOT_IN_TRANS_SETUP,
-	BTRFS_ROOT_REF_COWS,
+
+	/*
+	 * Set if tree blocks of this root can be shared by other roots.
+	 * Only subvolume trees and their reloc trees have this bit set.
+	 * Conflicts with TRACK_DIRTY bit.
+	 *
+	 * This affects two things:
+	 *
+	 * - How balance works
+	 *   For shareable roots, we need to use reloc tree and do path
+	 *   replacement for balance, and need various pre/post hooks for
+	 *   snapshot creation to handle them.
+	 *
+	 *   While for non-shareable trees, we just simply do a tree search
+	 *   with COW.
+	 *
+	 * - How dirty roots are tracked
+	 *   For shareable roots, btrfs_record_root_in_trans() is needed to
+	 *   track them, while non-subvolume roots have TRACK_DIRTY bit, they
+	 *   don't need to set this manually.
+	 */
+	BTRFS_ROOT_SHAREABLE,
 	BTRFS_ROOT_TRACK_DIRTY,
 	BTRFS_ROOT_IN_RADIX,
 	BTRFS_ROOT_ORPHAN_ITEM_INSERTED,
@@ -1055,7 +1076,7 @@ struct btrfs_root {
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
 
-	/* the dirty list is only used by non-reference counted roots */
+	/* The dirty list is only used by non-shareable roots */
 	struct list_head dirty_list;
 
 	struct list_head root_list;

commit 2b48966a4da4bcb35f0883bc23dcaf63fcb8557f
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 29 03:04:10 2020 +0200

    btrfs: constify extent_buffer in the API functions
    
    There are many helpers around extent buffers, found in extent_io.h and
    ctree.h. Most of them can be converted to take constified eb as there
    are no changes to the extent buffer structure itself but rather the
    pages.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 557de0dc904a..0a1fa1526c43 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1384,7 +1384,7 @@ void btrfs_set_token_##bits(struct btrfs_map_token *token,		\
 			    u##bits val);				\
 u##bits btrfs_get_##bits(const struct extent_buffer *eb,		\
 			 const void *ptr, unsigned long off);		\
-void btrfs_set_##bits(struct extent_buffer *eb, void *ptr,		\
+void btrfs_set_##bits(const struct extent_buffer *eb, void *ptr,	\
 		      unsigned long off, u##bits val);
 
 DECLARE_BTRFS_SETGET_BITS(8)
@@ -1399,7 +1399,7 @@ static inline u##bits btrfs_##name(const struct extent_buffer *eb,	\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
 	return btrfs_get_##bits(eb, s, offsetof(type, member));		\
 }									\
-static inline void btrfs_set_##name(struct extent_buffer *eb, type *s,	\
+static inline void btrfs_set_##name(const struct extent_buffer *eb, type *s, \
 				    u##bits val)			\
 {									\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
@@ -1425,7 +1425,7 @@ static inline u##bits btrfs_##name(const struct extent_buffer *eb)	\
 	u##bits res = le##bits##_to_cpu(p->member);			\
 	return res;							\
 }									\
-static inline void btrfs_set_##name(struct extent_buffer *eb,		\
+static inline void btrfs_set_##name(const struct extent_buffer *eb,	\
 				    u##bits val)			\
 {									\
 	type *p = page_address(eb->pages[0]);				\
@@ -1443,7 +1443,7 @@ static inline void btrfs_set_##name(type *s, u##bits val)		\
 }
 
 
-static inline u64 btrfs_device_total_bytes(struct extent_buffer *eb,
+static inline u64 btrfs_device_total_bytes(const struct extent_buffer *eb,
 					   struct btrfs_dev_item *s)
 {
 	BUILD_BUG_ON(sizeof(u64) !=
@@ -1451,7 +1451,7 @@ static inline u64 btrfs_device_total_bytes(struct extent_buffer *eb,
 	return btrfs_get_64(eb, s, offsetof(struct btrfs_dev_item,
 					    total_bytes));
 }
-static inline void btrfs_set_device_total_bytes(struct extent_buffer *eb,
+static inline void btrfs_set_device_total_bytes(const struct extent_buffer *eb,
 						struct btrfs_dev_item *s,
 						u64 val)
 {
@@ -1555,13 +1555,13 @@ static inline char *btrfs_stripe_dev_uuid_nr(struct btrfs_chunk *c, int nr)
 	return btrfs_stripe_dev_uuid(btrfs_stripe_nr(c, nr));
 }
 
-static inline u64 btrfs_stripe_offset_nr(struct extent_buffer *eb,
+static inline u64 btrfs_stripe_offset_nr(const struct extent_buffer *eb,
 					 struct btrfs_chunk *c, int nr)
 {
 	return btrfs_stripe_offset(eb, btrfs_stripe_nr(c, nr));
 }
 
-static inline u64 btrfs_stripe_devid_nr(struct extent_buffer *eb,
+static inline u64 btrfs_stripe_devid_nr(const struct extent_buffer *eb,
 					 struct btrfs_chunk *c, int nr)
 {
 	return btrfs_stripe_devid(eb, btrfs_stripe_nr(c, nr));
@@ -1648,14 +1648,14 @@ BTRFS_SETGET_FUNCS(extent_flags, struct btrfs_extent_item, flags, 64);
 
 BTRFS_SETGET_FUNCS(tree_block_level, struct btrfs_tree_block_info, level, 8);
 
-static inline void btrfs_tree_block_key(struct extent_buffer *eb,
+static inline void btrfs_tree_block_key(const struct extent_buffer *eb,
 					struct btrfs_tree_block_info *item,
 					struct btrfs_disk_key *key)
 {
 	read_eb_member(eb, item, struct btrfs_tree_block_info, key, key);
 }
 
-static inline void btrfs_set_tree_block_key(struct extent_buffer *eb,
+static inline void btrfs_set_tree_block_key(const struct extent_buffer *eb,
 					    struct btrfs_tree_block_info *item,
 					    struct btrfs_disk_key *key)
 {
@@ -1701,7 +1701,7 @@ BTRFS_SETGET_STACK_FUNCS(stack_key_blockptr, struct btrfs_key_ptr,
 BTRFS_SETGET_STACK_FUNCS(stack_key_generation, struct btrfs_key_ptr,
 			 generation, 64);
 
-static inline u64 btrfs_node_blockptr(struct extent_buffer *eb, int nr)
+static inline u64 btrfs_node_blockptr(const struct extent_buffer *eb, int nr)
 {
 	unsigned long ptr;
 	ptr = offsetof(struct btrfs_node, ptrs) +
@@ -1709,7 +1709,7 @@ static inline u64 btrfs_node_blockptr(struct extent_buffer *eb, int nr)
 	return btrfs_key_blockptr(eb, (struct btrfs_key_ptr *)ptr);
 }
 
-static inline void btrfs_set_node_blockptr(struct extent_buffer *eb,
+static inline void btrfs_set_node_blockptr(const struct extent_buffer *eb,
 					   int nr, u64 val)
 {
 	unsigned long ptr;
@@ -1718,7 +1718,7 @@ static inline void btrfs_set_node_blockptr(struct extent_buffer *eb,
 	btrfs_set_key_blockptr(eb, (struct btrfs_key_ptr *)ptr, val);
 }
 
-static inline u64 btrfs_node_ptr_generation(struct extent_buffer *eb, int nr)
+static inline u64 btrfs_node_ptr_generation(const struct extent_buffer *eb, int nr)
 {
 	unsigned long ptr;
 	ptr = offsetof(struct btrfs_node, ptrs) +
@@ -1726,7 +1726,7 @@ static inline u64 btrfs_node_ptr_generation(struct extent_buffer *eb, int nr)
 	return btrfs_key_generation(eb, (struct btrfs_key_ptr *)ptr);
 }
 
-static inline void btrfs_set_node_ptr_generation(struct extent_buffer *eb,
+static inline void btrfs_set_node_ptr_generation(const struct extent_buffer *eb,
 						 int nr, u64 val)
 {
 	unsigned long ptr;
@@ -1744,7 +1744,7 @@ static inline unsigned long btrfs_node_key_ptr_offset(int nr)
 void btrfs_node_key(const struct extent_buffer *eb,
 		    struct btrfs_disk_key *disk_key, int nr);
 
-static inline void btrfs_set_node_key(struct extent_buffer *eb,
+static inline void btrfs_set_node_key(const struct extent_buffer *eb,
 				      struct btrfs_disk_key *disk_key, int nr)
 {
 	unsigned long ptr;

commit 870b388db02cac33eebe40a1cbeb056cf13e9f40
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 29 19:29:04 2020 +0200

    btrfs: preset set/get token with first page and drop condition
    
    All the set/get helpers first check if the token contains a cached
    address. After first use the address is always valid, but the extra
    check is done for each call.
    
    The token initialization can optimistically set it to the first extent
    buffer page, that we know always exists. Then the condition in all
    btrfs_token_*/btrfs_set_token_* can be simplified by removing the
    address check from the condition, but for development the assertion
    still makes sure it's valid.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dcb82d690e76..557de0dc904a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1352,7 +1352,8 @@ static inline void btrfs_init_map_token(struct btrfs_map_token *token,
 					struct extent_buffer *eb)
 {
 	token->eb = eb;
-	token->kaddr = NULL;
+	token->kaddr = page_address(eb->pages[0]);
+	token->offset = 0;
 }
 
 /* some macros to generate set/get functions for the struct fields.  This

commit cc4c13d55cba8a0b81bc18243eabc57be1aa44d2
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 29 02:15:56 2020 +0200

    btrfs: drop eb parameter from set/get token helpers
    
    Now that all set/get helpers use the eb from the token, we don't need to
    pass it to many btrfs_token_*/btrfs_set_token_* helpers, saving some
    stack space.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6e226c371972..dcb82d690e76 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1340,7 +1340,7 @@ do {                                                                   \
 	 BTRFS_INODE_ROOT_ITEM_INIT)
 
 struct btrfs_map_token {
-	const struct extent_buffer *eb;
+	struct extent_buffer *eb;
 	char *kaddr;
 	unsigned long offset;
 };
@@ -1376,12 +1376,11 @@ static inline void btrfs_init_map_token(struct btrfs_map_token *token,
 			   sizeof(((type *)0)->member)))
 
 #define DECLARE_BTRFS_SETGET_BITS(bits)					\
-u##bits btrfs_get_token_##bits(const struct extent_buffer *eb,		\
-			       const void *ptr, unsigned long off,	\
-			       struct btrfs_map_token *token);		\
-void btrfs_set_token_##bits(struct extent_buffer *eb, const void *ptr,	\
-			    unsigned long off, u##bits val,		\
-			    struct btrfs_map_token *token);		\
+u##bits btrfs_get_token_##bits(struct btrfs_map_token *token,		\
+			       const void *ptr, unsigned long off);	\
+void btrfs_set_token_##bits(struct btrfs_map_token *token,		\
+			    const void *ptr, unsigned long off,		\
+			    u##bits val);				\
 u##bits btrfs_get_##bits(const struct extent_buffer *eb,		\
 			 const void *ptr, unsigned long off);		\
 void btrfs_set_##bits(struct extent_buffer *eb, void *ptr,		\
@@ -1405,19 +1404,17 @@ static inline void btrfs_set_##name(struct extent_buffer *eb, type *s,	\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
 	btrfs_set_##bits(eb, s, offsetof(type, member), val);		\
 }									\
-static inline u##bits btrfs_token_##name(const struct extent_buffer *eb,\
-					 const type *s,			\
-					 struct btrfs_map_token *token)	\
+static inline u##bits btrfs_token_##name(struct btrfs_map_token *token,	\
+					 const type *s)			\
 {									\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
-	return btrfs_get_token_##bits(eb, s, offsetof(type, member), token); \
+	return btrfs_get_token_##bits(token, s, offsetof(type, member));\
 }									\
-static inline void btrfs_set_token_##name(struct extent_buffer *eb,	\
-					  type *s, u##bits val,		\
-                                         struct btrfs_map_token *token)	\
+static inline void btrfs_set_token_##name(struct btrfs_map_token *token,\
+					  type *s, u##bits val)		\
 {									\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
-	btrfs_set_token_##bits(eb, s, offsetof(type, member), val, token); \
+	btrfs_set_token_##bits(token, s, offsetof(type, member), val);	\
 }
 
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\

commit 684b752b0933ac287fdd1f4cdc53c4a937e90e46
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri May 8 11:01:59 2020 +0100

    btrfs: move the block group freeze/unfreeze helpers into block-group.c
    
    The helpers btrfs_freeze_block_group() and btrfs_unfreeze_block_group()
    used to be named btrfs_get_block_group_trimming() and
    btrfs_put_block_group_trimming() respectively.
    
    At the time they were added to free-space-cache.c, by commit e33e17ee1098
    ("btrfs: add missing discards when unpinning extents with -o discard")
    because all the trimming related functions were in free-space-cache.c.
    
    Now that the helpers were renamed and are used in scrub context as well,
    move them to block-group.c, a much more logical location for them.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 242f974a4451..6e226c371972 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2481,8 +2481,6 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_ref *generic_ref);
 
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
-void btrfs_freeze_block_group(struct btrfs_block_group *cache);
-void btrfs_unfreeze_block_group(struct btrfs_block_group *cache);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
 enum btrfs_reserve_flush_enum {

commit 6b7304af62d02d77d740defd4cfddf2ef3188067
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri May 8 11:01:47 2020 +0100

    btrfs: rename member 'trimming' of block group to a more generic name
    
    Back in 2014, commit 04216820fe83d5 ("Btrfs: fix race between fs trimming
    and block group remove/allocation"), I added the 'trimming' member to the
    block group structure. Its purpose was to prevent races between trimming
    and block group deletion/allocation by pinning the block group in a way
    that prevents its logical address and device extents from being reused
    while trimming is in progress for a block group, so that if another task
    deletes the block group and then another task allocates a new block group
    that gets the same logical address and device extents while the trimming
    task is still in progress.
    
    After the previous fix for scrub (patch "btrfs: fix a race between scrub
    and block group removal/allocation"), scrub now also has the same needs that
    trimming has, so the member name 'trimming' no longer makes sense.
    Since there is already a 'pinned' member in the block group that refers
    to space reservations (pinned bytes), rename the member to 'frozen',
    add a comment on top of it to describe its general purpose and rename
    the helpers to increment and decrement the counter as well, to match
    the new member name.
    
    The next patch in the series will move the helpers into a more suitable
    file (from free-space-cache.c to block-group.c).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 86ec25250ac5..242f974a4451 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2481,8 +2481,8 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_ref *generic_ref);
 
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
-void btrfs_get_block_group_trimming(struct btrfs_block_group *cache);
-void btrfs_put_block_group_trimming(struct btrfs_block_group *cache);
+void btrfs_freeze_block_group(struct btrfs_block_group *cache);
+void btrfs_unfreeze_block_group(struct btrfs_block_group *cache);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
 enum btrfs_reserve_flush_enum {

commit 31344b2fcead3239c5b801016d9bae82506b92c2
Author: David Sterba <dsterba@suse.com>
Date:   Mon May 11 14:49:10 2020 +0200

    btrfs: remove more obsolete v0 extent ref declarations
    
    The extent references v0 have been superseded long time go, there are
    some unused declarations of access helpers. We can safely remove them
    now. The struct btrfs_extent_ref_v0 is not used anywhere, but struct
    btrfs_extent_item_v0 is still part of a backward compatibility check in
    relocation.c and thus not removed.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0b78ab0213bb..86ec25250ac5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1648,9 +1648,6 @@ BTRFS_SETGET_FUNCS(extent_generation, struct btrfs_extent_item,
 		   generation, 64);
 BTRFS_SETGET_FUNCS(extent_flags, struct btrfs_extent_item, flags, 64);
 
-BTRFS_SETGET_FUNCS(extent_refs_v0, struct btrfs_extent_item_v0, refs, 32);
-
-
 BTRFS_SETGET_FUNCS(tree_block_level, struct btrfs_tree_block_info, level, 8);
 
 static inline void btrfs_tree_block_key(struct extent_buffer *eb,
@@ -1698,12 +1695,6 @@ static inline u32 btrfs_extent_inline_ref_size(int type)
 	return 0;
 }
 
-BTRFS_SETGET_FUNCS(ref_root_v0, struct btrfs_extent_ref_v0, root, 64);
-BTRFS_SETGET_FUNCS(ref_generation_v0, struct btrfs_extent_ref_v0,
-		   generation, 64);
-BTRFS_SETGET_FUNCS(ref_objectid_v0, struct btrfs_extent_ref_v0, objectid, 64);
-BTRFS_SETGET_FUNCS(ref_count_v0, struct btrfs_extent_ref_v0, count, 32);
-
 /* struct btrfs_node */
 BTRFS_SETGET_FUNCS(key_blockptr, struct btrfs_key_ptr, blockptr, 64);
 BTRFS_SETGET_FUNCS(key_generation, struct btrfs_key_ptr, generation, 64);

commit 943aeb0dae9903ec70157129daed246086e8e111
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Sat May 9 19:22:43 2020 +0800

    btrfs: remove unused function btrfs_dev_extent_chunk_tree_uuid
    
    There's no callers in-tree anymore since
    commit d24ee97b96db ("btrfs: use new helpers to set uuids in eb")
    
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 03ea7370aea7..0b78ab0213bb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1643,13 +1643,6 @@ BTRFS_SETGET_FUNCS(dev_extent_chunk_objectid, struct btrfs_dev_extent,
 BTRFS_SETGET_FUNCS(dev_extent_chunk_offset, struct btrfs_dev_extent,
 		   chunk_offset, 64);
 BTRFS_SETGET_FUNCS(dev_extent_length, struct btrfs_dev_extent, length, 64);
-
-static inline unsigned long btrfs_dev_extent_chunk_tree_uuid(struct btrfs_dev_extent *dev)
-{
-	unsigned long ptr = offsetof(struct btrfs_dev_extent, chunk_tree_uuid);
-	return (unsigned long)dev + ptr;
-}
-
 BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 64);
 BTRFS_SETGET_FUNCS(extent_generation, struct btrfs_extent_item,
 		   generation, 64);

commit 5c047a699aa9433ad92136343a9306d985134c24
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Apr 16 14:46:24 2020 -0700

    btrfs: get rid of endio_repair_workers
    
    This was originally added in commit 8b110e393c5a ("Btrfs: implement
    repair function when direct read fails") to avoid a deadlock. In that
    commit, the direct I/O read endio executes on the endio_workers
    workqueue, submits a repair bio, and waits for it to complete. The
    repair bio endio must execute on a different workqueue, otherwise it
    could block on the endio_workers workqueue becoming available, which
    won't happen because the original endio is blocked on the repair bio.
    
    As of the previous commit, the original endio doesn't wait for the
    repair bio, so this separate workqueue is unnecessary.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e4b8f5f2273d..03ea7370aea7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -758,7 +758,6 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *endio_workers;
 	struct btrfs_workqueue *endio_meta_workers;
 	struct btrfs_workqueue *endio_raid56_workers;
-	struct btrfs_workqueue *endio_repair_workers;
 	struct btrfs_workqueue *rmw_workers;
 	struct btrfs_workqueue *endio_meta_write_workers;
 	struct btrfs_workqueue *endio_write_workers;

commit e3b8336117e515a260da32fa10bb3354ba12c429
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Apr 17 15:08:21 2020 +0800

    btrfs: remove the redundant parameter level in btrfs_bin_search()
    
    All callers pass the eb::level so we can get read it directly inside the
    btrfs_bin_search and key_search.
    
    This is inspired by the work of Marek in U-boot.
    
    CC: Marek Behun <marek.behun@nic.cz>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c322568231a4..e4b8f5f2273d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2552,7 +2552,7 @@ void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, const struct btrfs_key *key,
-		     int level, int *slot);
+		     int *slot);
 int __pure btrfs_comp_cpu_keys(const struct btrfs_key *k1, const struct btrfs_key *k2);
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,

commit 7f9fe614407692f670601a634621138233ac00d7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Mar 13 15:58:05 2020 -0400

    btrfs: improve global reserve stealing logic
    
    For unlink transactions and block group removal
    btrfs_start_transaction_fallback_global_rsv will first try to start an
    ordinary transaction and if it fails it will fall back to reserving the
    required amount by stealing from the global reserve. This is problematic
    because of all the same reasons we had with previous iterations of the
    ENOSPC handling, thundering herd.  We get a bunch of failures all at
    once, everybody tries to allocate from the global reserve, some win and
    some lose, we get an ENSOPC.
    
    Fix this behavior by introducing BTRFS_RESERVE_FLUSH_ALL_STEAL. It's
    used to mark unlink reservation. To fix this we need to integrate this
    logic into the normal ENOSPC infrastructure.  We still go through all of
    the normal flushing work, and at the moment we begin to fail all the
    tickets we try to satisfy any tickets that are allowed to steal by
    stealing from the global reserve.  If this works we start the flushing
    system over again just like we would with a normal ticket satisfaction.
    This serializes our global reserve stealing, so we don't have the
    thundering herd problem.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Tested-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 01b03e8a671f..c322568231a4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2512,6 +2512,7 @@ enum btrfs_reserve_flush_enum {
 	BTRFS_RESERVE_FLUSH_LIMIT,
 	BTRFS_RESERVE_FLUSH_EVICT,
 	BTRFS_RESERVE_FLUSH_ALL,
+	BTRFS_RESERVE_FLUSH_ALL_STEAL,
 };
 
 enum btrfs_flush_state {

commit 55465730bcea75606c2c281ca55701c7fc20a000
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Mar 3 14:26:02 2020 +0800

    btrfs: backref: rename and move should_ignore_root()
    
    This function is mostly single purpose to relocation backref cache, but
    since we're moving the main part of backref cache to backref.c, we need
    to export such function.
    
    And to avoid confusion, rename the function to
    btrfs_should_ignore_reloc_root() make the name a little more clear.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e8a0a513e73..01b03e8a671f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3383,6 +3383,7 @@ int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 int btrfs_should_cancel_balance(struct btrfs_fs_info *fs_info);
 struct btrfs_root *find_reloc_root(struct btrfs_fs_info *fs_info,
 				   u64 bytenr);
+int btrfs_should_ignore_reloc_root(struct btrfs_root *root);
 
 /* scrub.c */
 int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,

commit 2433bea592d26daf6bd15492ce4262b598a7f804
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Mar 6 14:04:12 2020 +0800

    btrfs: reloc: make reloc root search-specific for relocation backref cache
    
    find_reloc_root() searches reloc_control::reloc_root_tree to find the
    reloc root.  This behavior is only useful for relocation backref cache.
    
    For the incoming more generic purpose backref cache, we don't care
    about who owns the reloc root, but only care if it's a reloc root.
    
    So this patch makes the following modifications to make the reloc root
    search more specific to relocation backref:
    
    - Add backref_node::is_reloc_root
      This will be an extra indicator for generic purposed backref cache.
      User doesn't need to read root key from backref_node::root to
      determine if it's a reloc root.
      Also for reloc tree root, it's useless and will be queued to useless
      list.
    
    - Add backref_cache::is_reloc
      This will allow backref cache code to do different behavior for
      generic purpose backref cache and relocation backref cache.
    
    - Pass fs_info to find_reloc_root()
    
    - Export find_reloc_root()
      So backref.c can utilize this function.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8aa7b9dac405..1e8a0a513e73 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3381,6 +3381,8 @@ void btrfs_reloc_pre_snapshot(struct btrfs_pending_snapshot *pending,
 int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending);
 int btrfs_should_cancel_balance(struct btrfs_fs_info *fs_info);
+struct btrfs_root *find_reloc_root(struct btrfs_fs_info *fs_info,
+				   u64 bytenr);
 
 /* scrub.c */
 int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,

commit c75e839414d3610e6487ae3145199c500d55f7f7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:47 2020 -0500

    btrfs: kill the subvol_srcu
    
    Now that we have proper root ref counting everywhere we can kill the
    subvol_srcu.
    
    * removal of fs_info::subvol_srcu reduces size of fs_info by 1176 bytes
    
    * the refcount_t used for the references checks for accidental 0->1
      in cases where the root lifetime would not be properly protected
    
    * there's a leak detector for roots to catch unfreed roots at umount
      time
    
    * SRCU served us well over the years but is was not a proper
      synchronization mechanism for some cases
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f1eef81aaa49..8aa7b9dac405 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -697,7 +697,6 @@ struct btrfs_fs_info {
 	struct rw_semaphore cleanup_work_sem;
 
 	struct rw_semaphore subvol_sem;
-	struct srcu_struct subvol_srcu;
 
 	spinlock_t trans_lock;
 	/*

commit 3fd6372758d91d8ba801e0733b17d082066a04ef
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:40 2020 -0500

    btrfs: make the extent buffer leak check per fs info
    
    I'm going to make the entire destruction of btrfs_root's controlled by
    their refcount, so it will be helpful to notice if we're leaking their
    eb's on umount.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ebca8e8365ce..f1eef81aaa49 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -949,6 +949,9 @@ struct btrfs_fs_info {
 	struct kobject *debug_kobj;
 	struct kobject *discard_debug_kobj;
 	struct list_head allocated_roots;
+
+	spinlock_t eb_leak_lock;
+	struct list_head allocated_ebs;
 #endif
 };
 

commit a5eeb3d17b979f7afe3ac68fe049ce8b0a039b03
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Mar 9 12:41:06 2020 +0000

    btrfs: add helper to get the end offset of a file extent item
    
    Getting the end offset for a file extent item requires a bit of code since
    the extent can be either inline or regular/prealloc. There are some places
    all over the code base that open code this logic and in another patch
    later in this series it will be needed again. Therefore encapsulate this
    logic in a helper function and use it.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index af7229eac02b..ebca8e8365ce 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2836,6 +2836,7 @@ int btrfs_inode_clear_file_extent_range(struct btrfs_inode *inode, u64 start,
 int btrfs_inode_set_file_extent_range(struct btrfs_inode *inode, u64 start,
 				      u64 len);
 void btrfs_inode_safe_disk_i_size_write(struct inode *inode, u64 new_i_size);
+u64 btrfs_file_extent_end(const struct btrfs_path *path);
 
 /* inode.c */
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,

commit 0078a9f941d2a994d756c330f225e888c31c768d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Mar 10 11:43:51 2020 +0200

    btrfs: Remove block_rsv parameter from btrfs_drop_snapshot
    
    It's no longer used following 30d40577e322 ("btrfs: reloc: Also queue
    orphan reloc tree for cleanup to avoid BUG_ON()"), so just remove it.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e490cfd70bba..af7229eac02b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2657,9 +2657,8 @@ static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
 	return btrfs_next_old_item(root, p, 0);
 }
 int btrfs_leaf_free_space(struct extent_buffer *leaf);
-int __must_check btrfs_drop_snapshot(struct btrfs_root *root,
-				     struct btrfs_block_rsv *block_rsv,
-				     int update_ref, int for_reloc);
+int __must_check btrfs_drop_snapshot(struct btrfs_root *root, int update_ref,
+				     int for_reloc);
 int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct extent_buffer *node,

commit 726a342120eba8197b3bc5e01af1bd2dbf80f77f
Author: Qu Wenruo <wqu@suse.com>
Date:   Mon Feb 17 14:16:52 2020 +0800

    btrfs: relocation: add error injection points for cancelling balance
    
    Introduce a new error injection point, should_cancel_balance().
    
    It's just a wrapper of atomic_read(&fs_info->balance_cancel_req), but
    allows us to override the return value.
    
    Currently there are only one locations using this function:
    
    - btrfs_balance()
      It checks cancel before each block group.
    
    There are other locations checking fs_info->balance_cancel_req, but they
    are not used as an indicator to exit, so there is no need to use the
    wrapper.
    
    But there will be more locations coming, and some locations can cause
    kernel panic if not handled properly.  So introduce this error injection
    to provide better test interface.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ecd016f7dab1..e490cfd70bba 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3378,6 +3378,7 @@ void btrfs_reloc_pre_snapshot(struct btrfs_pending_snapshot *pending,
 			      u64 *bytes_to_reserve);
 int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending);
+int btrfs_should_cancel_balance(struct btrfs_fs_info *fs_info);
 
 /* scrub.c */
 int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,

commit 6a177381007b463ad611375cce526c24f12ab081
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Feb 28 13:04:17 2020 +0000

    Btrfs: move all reflink implementation code into its own file
    
    The reflink code is quite large and has been living in ioctl.c since ever.
    It has grown over the years after many bug fixes and improvements, and
    since I'm planning on making some further improvements on it, it's time
    to get it better organized by moving into its own file, reflink.c
    (similar to what xfs does for example).
    
    This change only moves the code out of ioctl.c into the new file, it
    doesn't do any other change.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ea5d0675465a..ecd016f7dab1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2974,9 +2974,6 @@ int btrfs_dirty_pages(struct inode *inode, struct page **pages,
 		      size_t num_pages, loff_t pos, size_t write_bytes,
 		      struct extent_state **cached);
 int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
-loff_t btrfs_remap_file_range(struct file *file_in, loff_t pos_in,
-			      struct file *file_out, loff_t pos_out,
-			      loff_t len, unsigned int remap_flags);
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,

commit 42c9d0b524cf9af180dcb788a938cdc4c678e8cb
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 11:54:13 2019 +0100

    btrfs: simplify parameters of btrfs_set_disk_extent_flags
    
    All callers pass extent buffer start and length so the extent buffer
    itself should work fine.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1cde3f1d8f20..ea5d0675465a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2482,7 +2482,7 @@ int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf, int full_backref);
 int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
-				u64 bytenr, u64 num_bytes, u64 flags,
+				struct extent_buffer *eb, u64 flags,
 				int level, int is_data);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_ref *ref);
 

commit c4ac75419826c7afc997bbe4da07ad6f963da22f
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:17:13 2019 +0100

    btrfs: open code trivial helper btrfs_header_chunk_tree_uuid
    
    The helper btrfs_header_chunk_tree_uuid follows naming convention of
    other struct accessors but does something compeletly different. As the
    offsetof calculation is clear in the context of extent buffer operations
    we can remove it.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f66c4ea7491d..1cde3f1d8f20 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1973,11 +1973,6 @@ static inline void btrfs_set_header_backref_rev(struct extent_buffer *eb,
 	btrfs_set_header_flags(eb, flags);
 }
 
-static inline unsigned long btrfs_header_chunk_tree_uuid(const struct extent_buffer *eb)
-{
-	return offsetof(struct btrfs_header, chunk_tree_uuid);
-}
-
 static inline int btrfs_is_leaf(const struct extent_buffer *eb)
 {
 	return btrfs_header_level(eb) == 0;

commit 9a8658e33d8fd45879eebc44178b2a172e76bb47
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:15:57 2019 +0100

    btrfs: open code trivial helper btrfs_header_fsid
    
    The helper btrfs_header_fsid follows naming convention of other struct
    accessors but does something compeletly different. As the offsetof
    calculation is clear in the context of extent buffer operations we can
    remove it.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index db9e872bcc79..f66c4ea7491d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1973,11 +1973,6 @@ static inline void btrfs_set_header_backref_rev(struct extent_buffer *eb,
 	btrfs_set_header_flags(eb, flags);
 }
 
-static inline unsigned long btrfs_header_fsid(void)
-{
-	return offsetof(struct btrfs_header, fsid);
-}
-
 static inline unsigned long btrfs_header_chunk_tree_uuid(const struct extent_buffer *eb)
 {
 	return offsetof(struct btrfs_header, chunk_tree_uuid);

commit dcc3eb9638c3c927f1597075e851d0a16300a876
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Jan 30 14:59:45 2020 +0200

    btrfs: convert snapshot/nocow exlcusion to drew lock
    
    This patch removes all haphazard code implementing nocow writers
    exclusion from pending snapshot creation and switches to using the drew
    lock to ensure this invariant still holds.
    
    'Readers' are snapshot creators from create_snapshot and 'writers' are
    nocow writers from buffered write path or btrfs_setsize. This locking
    scheme allows for multiple snapshots to happen while any nocow writers
    are blocked, since writes to page cache in the nocow path will make
    snapshots inconsistent.
    
    So for performance reasons we'd like to have the ability to run multiple
    concurrent snapshots and also favors readers in this case. And in case
    there aren't pending snapshots (which will be the majority of the cases)
    we rely on the percpu's writers counter to avoid cacheline contention.
    
    The main gain from using the drew lock is it's now a lot easier to
    reason about the guarantees of the locking scheme and whether there is
    some silent breakage lurking.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ab8151247b93..db9e872bcc79 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -957,11 +957,6 @@ static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
 	return sb->s_fs_info;
 }
 
-struct btrfs_subvolume_writers {
-	struct percpu_counter	counter;
-	wait_queue_head_t	wait;
-};
-
 /*
  * The state of btrfs root
  */
@@ -1133,8 +1128,9 @@ struct btrfs_root {
 	 * root_item_lock.
 	 */
 	int dedupe_in_progress;
-	struct btrfs_subvolume_writers *subv_writers;
-	atomic_t will_be_snapshotted;
+	/* For exclusion of snapshot creation and nocow writes */
+	struct btrfs_drew_lock snapshot_lock;
+
 	atomic_t snapshot_force_cow;
 
 	/* For qgroup metadata reserved space */

commit 2992df73268f78ec9281692b9b44ae92f3933b54
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Jan 30 14:59:44 2020 +0200

    btrfs: Implement DREW lock
    
    A (D)ouble (R)eader (W)riter (E)xclustion lock is a locking primitive
    that allows to have multiple readers or multiple writers but not
    multiple readers and writers holding it concurrently.
    
    The code is factored out from the existing open-coded locking scheme
    used to exclude pending snapshots from nocow writers and vice-versa.
    Current implementation actually favors Readers (that is snapshot
    creaters) to writers (nocow writers of the filesystem).
    
    The API provides lock/unlock/trylock for reads and writes.
    
    Formal specification for TLA+ provided by Valentin Schneider is at
    https://lore.kernel.org/linux-btrfs/2dcaf81c-f0d3-409e-cb29-733d8b3b4cc9@arm.com/
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2ee7d8b4968f..ab8151247b93 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -33,6 +33,7 @@
 #include "extent_map.h"
 #include "async-thread.h"
 #include "block-rsv.h"
+#include "locking.h"
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;

commit c0c907a47dccf2cf26251a8fb4a8e7a3bf79ce84
Author: Marcos Paulo de Souza <mpdesouza@suse.com>
Date:   Fri Feb 21 14:56:12 2020 +0100

    btrfs: export helpers for subvolume name/id resolution
    
    The functions will be used outside of export.c and super.c to allow
    resolving subvolume name from a given id, eg. for subvolume deletion by
    id ioctl.
    
    Signed-off-by: Marcos Paulo de Souza <mpdesouza@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ split from the next patch ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ad275d06e95f..2ee7d8b4968f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2999,6 +2999,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 int btrfs_parse_options(struct btrfs_fs_info *info, char *options,
 			unsigned long new_flags);
 int btrfs_sync_fs(struct super_block *sb, int wait);
+char *btrfs_get_subvol_name_from_objectid(struct btrfs_fs_info *fs_info,
+					  u64 subvol_objectid);
 
 static inline __printf(2, 3) __cold
 void btrfs_no_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)

commit 560b7a4aa2258e27ad38eb417aabebc1e2c05f5f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Feb 18 16:56:07 2020 +0200

    btrfs: call btrfs_check_uuid_tree_entry directly in btrfs_uuid_tree_iterate
    
    btrfs_uuid_tree_iterate is called from only once place and its 2nd
    argument is always btrfs_check_uuid_tree_entry. Simplify
    btrfs_uuid_tree_iterate's signature by removing its 2nd argument and
    directly calling btrfs_check_uuid_tree_entry. Also move the latter into
    uuid-tree.h. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bb237d577725..ad275d06e95f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2738,9 +2738,7 @@ int btrfs_uuid_tree_add(struct btrfs_trans_handle *trans, u8 *uuid, u8 type,
 			u64 subid);
 int btrfs_uuid_tree_remove(struct btrfs_trans_handle *trans, u8 *uuid, u8 type,
 			u64 subid);
-int btrfs_uuid_tree_iterate(struct btrfs_fs_info *fs_info,
-			    int (*check_func)(struct btrfs_fs_info *, u8 *, u8,
-					      u64));
+int btrfs_uuid_tree_iterate(struct btrfs_fs_info *fs_info);
 
 /* dir-item.c */
 int btrfs_check_dir_item_collision(struct btrfs_root *root, u64 dir,

commit fe119a6eeb670585e29dbe3932e00ad29ae8f5f9
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 20 16:09:18 2020 +0200

    btrfs: switch to per-transaction pinned extents
    
    This commit flips the switch to start tracking/processing pinned extents
    on a per-transaction basis. It mostly replaces all references from
    btrfs_fs_info::(pinned_extents|freed_extents[]) to
    btrfs_transaction::pinned_extents.
    
    Two notable modifications that warrant explicit mention are changing
    clean_pinned_extents to get a reference to the previously running
    transaction. The other one is removal of call to
    btrfs_destroy_pinned_extent since transactions are going to be cleaned
    in btrfs_cleanup_one_transaction.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 22d0cb0019d1..bb237d577725 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -596,8 +596,8 @@ struct btrfs_fs_info {
 	/* keep track of unallocated space */
 	atomic64_t free_chunk_space;
 
-	struct extent_io_tree freed_extents[2];
-	struct extent_io_tree *pinned_extents;
+	/* Track ranges which are used by log trees blocks/logged data extents */
+	struct extent_io_tree excluded_extents;
 
 	/* logical->physical extent mapping */
 	struct extent_map_tree mapping_tree;

commit 9fce5704542c5e97d458cc97f9cecef253f02f06
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 20 16:09:13 2020 +0200

    btrfs: Make btrfs_pin_extent_for_log_replay take transaction handle
    
    Preparation for refactoring pinned extents tracking.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3518cbd07015..22d0cb0019d1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2465,7 +2465,7 @@ int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     u64 offset, int metadata, u64 *refs, u64 *flags);
 int btrfs_pin_extent(struct btrfs_trans_handle *trans, u64 bytenr, u64 num,
 		     int reserved);
-int btrfs_pin_extent_for_log_replay(struct btrfs_fs_info *fs_info,
+int btrfs_pin_extent_for_log_replay(struct btrfs_trans_handle *trans,
 				    u64 bytenr, u64 num_bytes);
 int btrfs_exclude_logged_extents(struct extent_buffer *eb);
 int btrfs_cross_ref_exist(struct btrfs_root *root,

commit 7bfc10070573591163dae7be9bb09552d4e6dee5
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 20 16:09:12 2020 +0200

    btrfs: Make btrfs_pin_reserved_extent take transaction handle
    
    btrfs_pin_reserved_extent is now only called with a valid transaction so
    exploit the fact to take a transaction. This is preparation for tracking
    pinned extents on a per-transaction basis.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2f0ca1cb1fb9..3518cbd07015 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2501,7 +2501,7 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_ref *ref);
 
 int btrfs_free_reserved_extent(struct btrfs_fs_info *fs_info,
 			       u64 start, u64 len, int delalloc);
-int btrfs_pin_reserved_extent(struct btrfs_fs_info *fs_info, u64 start,
+int btrfs_pin_reserved_extent(struct btrfs_trans_handle *trans, u64 start,
 			      u64 len);
 void btrfs_prepare_extent_commit(struct btrfs_fs_info *fs_info);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans);

commit b25c36f84b59a64fd5815f341b6ddbd8a8a2bb56
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 20 16:09:09 2020 +0200

    btrfs: Make btrfs_pin_extent take trans handle
    
    Preparation for switching pinned extent tracking to a per-transaction
    basis.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ffd99c3f64db..2f0ca1cb1fb9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2463,8 +2463,8 @@ int btrfs_lookup_data_extent(struct btrfs_fs_info *fs_info, u64 start, u64 len);
 int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     struct btrfs_fs_info *fs_info, u64 bytenr,
 			     u64 offset, int metadata, u64 *refs, u64 *flags);
-int btrfs_pin_extent(struct btrfs_fs_info *fs_info,
-		     u64 bytenr, u64 num, int reserved);
+int btrfs_pin_extent(struct btrfs_trans_handle *trans, u64 bytenr, u64 num,
+		     int reserved);
 int btrfs_pin_extent_for_log_replay(struct btrfs_fs_info *fs_info,
 				    u64 bytenr, u64 num_bytes);
 int btrfs_exclude_logged_extents(struct extent_buffer *eb);

commit bd647ce385ec110fe7796267b6555873e48e44eb
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:33:00 2020 -0500

    btrfs: add a leak check for roots
    
    Now that we're going to start relying on getting ref counting right for
    roots, add a list to track allocated roots and print out any roots that
    aren't freed up at free_fs_info time.
    
    Hide this behind CONFIG_BTRFS_DEBUG because this will just be used for
    developers to verify they aren't breaking things.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8c1a8f275773..ffd99c3f64db 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -947,6 +947,7 @@ struct btrfs_fs_info {
 #ifdef CONFIG_BTRFS_DEBUG
 	struct kobject *debug_kobj;
 	struct kobject *discard_debug_kobj;
+	struct list_head allocated_roots;
 #endif
 };
 
@@ -1149,6 +1150,10 @@ struct btrfs_root {
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 	u64 alloc_bytenr;
 #endif
+
+#ifdef CONFIG_BTRFS_DEBUG
+	struct list_head leak_list;
+#endif
 };
 
 struct btrfs_clone_extent_info {

commit 0d4b0463011de06288d8ca80a873a97a7d99a948
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:53 2020 -0500

    btrfs: export and rename free_fs_info
    
    We're going to start freeing roots and doing other complicated things in
    free_fs_info, so we need to move it to disk-io.c and export it in order
    to use things lik btrfs_put_fs_root().
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 36dbf4e7c0dc..8c1a8f275773 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2695,23 +2695,6 @@ static inline int btrfs_need_cleaner_sleep(struct btrfs_fs_info *fs_info)
 	return fs_info->sb->s_flags & SB_RDONLY || btrfs_fs_closing(fs_info);
 }
 
-static inline void free_fs_info(struct btrfs_fs_info *fs_info)
-{
-	kfree(fs_info->balance_ctl);
-	kfree(fs_info->delayed_root);
-	kfree(fs_info->extent_root);
-	kfree(fs_info->tree_root);
-	kfree(fs_info->chunk_root);
-	kfree(fs_info->dev_root);
-	kfree(fs_info->csum_root);
-	kfree(fs_info->quota_root);
-	kfree(fs_info->uuid_root);
-	kfree(fs_info->free_space_root);
-	kfree(fs_info->super_copy);
-	kfree(fs_info->super_for_commit);
-	kvfree(fs_info);
-}
-
 /* tree mod log functions from ctree.c */
 u64 btrfs_get_tree_mod_seq(struct btrfs_fs_info *fs_info,
 			   struct seq_list *elem);

commit 41a2ee75aab0290a5899677437736ec715dcd1b6
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 17 09:02:21 2020 -0500

    btrfs: introduce per-inode file extent tree
    
    In order to keep track of where we have file extents on disk, and thus
    where it is safe to adjust the i_size to, we need to have a tree in
    place to keep track of the contiguous areas we have file extents for.
    
    Add helpers to use this tree, as it's not required for NO_HOLES file
    systems.  We will use this by setting DIRTY for areas we know we have
    file extent item's set, and clearing it when we remove file extent items
    for truncation.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 36df977b64d9..36dbf4e7c0dc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2859,6 +2859,11 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 				     struct btrfs_file_extent_item *fi,
 				     const bool new_inline,
 				     struct extent_map *em);
+int btrfs_inode_clear_file_extent_range(struct btrfs_inode *inode, u64 start,
+					u64 len);
+int btrfs_inode_set_file_extent_range(struct btrfs_inode *inode, u64 start,
+				      u64 len);
+void btrfs_inode_safe_disk_i_size_write(struct inode *inode, u64 new_i_size);
 
 /* inode.c */
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,

commit 7227ff4de55d931bbdc156c8ef0ce4f100c78a5b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jan 22 12:23:20 2020 +0000

    Btrfs: fix race between adding and putting tree mod seq elements and nodes
    
    There is a race between adding and removing elements to the tree mod log
    list and rbtree that can lead to use-after-free problems.
    
    Consider the following example that explains how/why the problems happens:
    
    1) Task A has mod log element with sequence number 200. It currently is
       the only element in the mod log list;
    
    2) Task A calls btrfs_put_tree_mod_seq() because it no longer needs to
       access the tree mod log. When it enters the function, it initializes
       'min_seq' to (u64)-1. Then it acquires the lock 'tree_mod_seq_lock'
       before checking if there are other elements in the mod seq list.
       Since the list it empty, 'min_seq' remains set to (u64)-1. Then it
       unlocks the lock 'tree_mod_seq_lock';
    
    3) Before task A acquires the lock 'tree_mod_log_lock', task B adds
       itself to the mod seq list through btrfs_get_tree_mod_seq() and gets a
       sequence number of 201;
    
    4) Some other task, name it task C, modifies a btree and because there
       elements in the mod seq list, it adds a tree mod elem to the tree
       mod log rbtree. That node added to the mod log rbtree is assigned
       a sequence number of 202;
    
    5) Task B, which is doing fiemap and resolving indirect back references,
       calls btrfs get_old_root(), with 'time_seq' == 201, which in turn
       calls tree_mod_log_search() - the search returns the mod log node
       from the rbtree with sequence number 202, created by task C;
    
    6) Task A now acquires the lock 'tree_mod_log_lock', starts iterating
       the mod log rbtree and finds the node with sequence number 202. Since
       202 is less than the previously computed 'min_seq', (u64)-1, it
       removes the node and frees it;
    
    7) Task B still has a pointer to the node with sequence number 202, and
       it dereferences the pointer itself and through the call to
       __tree_mod_log_rewind(), resulting in a use-after-free problem.
    
    This issue can be triggered sporadically with the test case generic/561
    from fstests, and it happens more frequently with a higher number of
    duperemove processes. When it happens to me, it either freezes the VM or
    it produces a trace like the following before crashing:
    
      [ 1245.321140] general protection fault: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC PTI
      [ 1245.321200] CPU: 1 PID: 26997 Comm: pool Not tainted 5.5.0-rc6-btrfs-next-52 #1
      [ 1245.321235] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.0-0-ga698c8995f-prebuilt.qemu.org 04/01/2014
      [ 1245.321287] RIP: 0010:rb_next+0x16/0x50
      [ 1245.321307] Code: ....
      [ 1245.321372] RSP: 0018:ffffa151c4d039b0 EFLAGS: 00010202
      [ 1245.321388] RAX: 6b6b6b6b6b6b6b6b RBX: ffff8ae221363c80 RCX: 6b6b6b6b6b6b6b6b
      [ 1245.321409] RDX: 0000000000000001 RSI: 0000000000000000 RDI: ffff8ae221363c80
      [ 1245.321439] RBP: ffff8ae20fcc4688 R08: 0000000000000002 R09: 0000000000000000
      [ 1245.321475] R10: ffff8ae20b120910 R11: 00000000243f8bb1 R12: 0000000000000038
      [ 1245.321506] R13: ffff8ae221363c80 R14: 000000000000075f R15: ffff8ae223f762b8
      [ 1245.321539] FS:  00007fdee1ec7700(0000) GS:ffff8ae236c80000(0000) knlGS:0000000000000000
      [ 1245.321591] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [ 1245.321614] CR2: 00007fded4030c48 CR3: 000000021da16003 CR4: 00000000003606e0
      [ 1245.321642] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [ 1245.321668] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [ 1245.321706] Call Trace:
      [ 1245.321798]  __tree_mod_log_rewind+0xbf/0x280 [btrfs]
      [ 1245.321841]  btrfs_search_old_slot+0x105/0xd00 [btrfs]
      [ 1245.321877]  resolve_indirect_refs+0x1eb/0xc60 [btrfs]
      [ 1245.321912]  find_parent_nodes+0x3dc/0x11b0 [btrfs]
      [ 1245.321947]  btrfs_check_shared+0x115/0x1c0 [btrfs]
      [ 1245.321980]  ? extent_fiemap+0x59d/0x6d0 [btrfs]
      [ 1245.322029]  extent_fiemap+0x59d/0x6d0 [btrfs]
      [ 1245.322066]  do_vfs_ioctl+0x45a/0x750
      [ 1245.322081]  ksys_ioctl+0x70/0x80
      [ 1245.322092]  ? trace_hardirqs_off_thunk+0x1a/0x1c
      [ 1245.322113]  __x64_sys_ioctl+0x16/0x20
      [ 1245.322126]  do_syscall_64+0x5c/0x280
      [ 1245.322139]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [ 1245.322155] RIP: 0033:0x7fdee3942dd7
      [ 1245.322177] Code: ....
      [ 1245.322258] RSP: 002b:00007fdee1ec6c88 EFLAGS: 00000246 ORIG_RAX: 0000000000000010
      [ 1245.322294] RAX: ffffffffffffffda RBX: 00007fded40210d8 RCX: 00007fdee3942dd7
      [ 1245.322314] RDX: 00007fded40210d8 RSI: 00000000c020660b RDI: 0000000000000004
      [ 1245.322337] RBP: 0000562aa89e7510 R08: 0000000000000000 R09: 00007fdee1ec6d44
      [ 1245.322369] R10: 0000000000000073 R11: 0000000000000246 R12: 00007fdee1ec6d48
      [ 1245.322390] R13: 00007fdee1ec6d40 R14: 00007fded40210d0 R15: 00007fdee1ec6d50
      [ 1245.322423] Modules linked in: ....
      [ 1245.323443] ---[ end trace 01de1e9ec5dff3cd ]---
    
    Fix this by ensuring that btrfs_put_tree_mod_seq() computes the minimum
    sequence number and iterates the rbtree while holding the lock
    'tree_mod_log_lock' in write mode. Also get rid of the 'tree_mod_seq_lock'
    lock, since it is now redundant.
    
    Fixes: bd989ba359f2ac ("Btrfs: add tree modification log functions")
    Fixes: 097b8a7c9e48e2 ("Btrfs: join tree mod log code with the code holding back delayed refs")
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f90b82050d2d..36df977b64d9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -714,14 +714,12 @@ struct btrfs_fs_info {
 	atomic_t nr_delayed_iputs;
 	wait_queue_head_t delayed_iputs_wait;
 
-	/* this protects tree_mod_seq_list */
-	spinlock_t tree_mod_seq_lock;
 	atomic64_t tree_mod_seq;
-	struct list_head tree_mod_seq_list;
 
-	/* this protects tree_mod_log */
+	/* this protects tree_mod_log and tree_mod_seq_list */
 	rwlock_t tree_mod_log_lock;
 	struct rb_root tree_mod_log;
+	struct list_head tree_mod_seq_list;
 
 	atomic_t async_delalloc_pages;
 

commit 68c467cbb2f389b6c933e235bce0d1756fc8cc34
Author: David Sterba <dsterba@suse.com>
Date:   Mon Dec 16 20:00:48 2019 +0100

    btrfs: separate definition of assertion failure handlers
    
    There's a report where objtool detects unreachable instructions, eg.:
    
      fs/btrfs/ctree.o: warning: objtool: btrfs_search_slot()+0x2d4: unreachable instruction
    
    This seems to be a false positive due to compiler version. The cause is
    in the ASSERT macro implementation that does the conditional check as
    IS_DEFINED(CONFIG_BTRFS_ASSERT) and not an #ifdef.
    
    To avoid that, use the ifdefs directly.
    
    There are still 2 reports that aren't fixed:
    
      fs/btrfs/extent_io.o: warning: objtool: __set_extent_bit()+0x71f: unreachable instruction
      fs/btrfs/relocation.o: warning: objtool: find_data_references()+0x4e0: unreachable instruction
    
    Co-developed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Reported-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 569931dd0ce5..f90b82050d2d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3157,17 +3157,21 @@ do {								\
 	rcu_read_unlock();					\
 } while (0)
 
-__cold
-static inline void assfail(const char *expr, const char *file, int line)
+#ifdef CONFIG_BTRFS_ASSERT
+__cold __noreturn
+static inline void assertfail(const char *expr, const char *file, int line)
 {
-	if (IS_ENABLED(CONFIG_BTRFS_ASSERT)) {
-		pr_err("assertion failed: %s, in %s:%d\n", expr, file, line);
-		BUG();
-	}
+	pr_err("assertion failed: %s, in %s:%d\n", expr, file, line);
+	BUG();
 }
 
-#define ASSERT(expr)	\
-	(likely(expr) ? (void)0 : assfail(#expr, __FILE__, __LINE__))
+#define ASSERT(expr)						\
+	(likely(expr) ? (void)0 : assertfail(#expr, __FILE__, __LINE__))
+
+#else
+static inline void assertfail(const char *expr, const char* file, int line) { }
+#define ASSERT(expr)	(void)(expr)
+#endif
 
 /*
  * Use that for functions that are conditionally exported for sanity tests but

commit 9ddf648f9c2a492cef4e41e31c50515a817d0562
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Jan 2 16:26:41 2020 -0500

    btrfs: keep track of discard reuse stats
    
    Keep track of how much we are discarding and how often we are reusing
    with async discard. The discard_*_bytes values don't need any special
    protection because the work item provides the single threaded access.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 486b9d1532eb..569931dd0ce5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -473,6 +473,9 @@ struct btrfs_discard_ctl {
 	unsigned long delay;
 	u32 iops_limit;
 	u32 kbps_limit;
+	u64 discard_extent_bytes;
+	u64 discard_bitmap_bytes;
+	atomic64_t discard_bytes_saved;
 };
 
 /* delayed seq elem */

commit 7fe6d45e4009d9502fef32ac6222862ac17f8674
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Jan 2 16:26:39 2020 -0500

    btrfs: have multiple discard lists
    
    Non-block group destruction discarding currently only had a single list
    with no minimum discard length. This can lead to caravaning more
    meaningful discards behind a heavily fragmented block group.
    
    This adds support for multiple lists with minimum discard lengths to
    prevent the caravan effect. We promote block groups back up when we
    exceed the BTRFS_ASYNC_DISCARD_MAX_FILTER size, currently we support
    only 2 lists with filters of 1MB and 32KB respectively.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa6c95fdf5c6..486b9d1532eb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -456,7 +456,7 @@ struct btrfs_full_stripe_locks_tree {
  * afterwards represent monotonically decreasing discard filter sizes to
  * prioritize what should be discarded next.
  */
-#define BTRFS_NR_DISCARD_LISTS		2
+#define BTRFS_NR_DISCARD_LISTS		3
 #define BTRFS_DISCARD_INDEX_UNUSED	0
 #define BTRFS_DISCARD_INDEX_START	1
 

commit 19b2a2c71979f849cadc33af3577f739cc95e1f0
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Jan 2 16:26:38 2020 -0500

    btrfs: make max async discard size tunable
    
    Expose max_discard_size as a tunable via sysfs and switch the current
    fixed maximum to the default value.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f58b1cfeeca6..fa6c95fdf5c6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -469,6 +469,7 @@ struct btrfs_discard_ctl {
 	u64 prev_discard;
 	atomic_t discardable_extents;
 	atomic64_t discardable_bytes;
+	u64 max_discard_size;
 	unsigned long delay;
 	u32 iops_limit;
 	u32 kbps_limit;

commit e93591bb6ecf3e31c8f5366eac143f4f9c270915
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Jan 2 16:26:36 2020 -0500

    btrfs: add kbps discard rate limit for async discard
    
    Provide the ability to rate limit based on kbps in addition to iops as
    additional guides for the target discard rate. The delay used ends up
    being max(kbps_delay, iops_delay).
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 451dade0a4bb..f58b1cfeeca6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -466,10 +466,12 @@ struct btrfs_discard_ctl {
 	spinlock_t lock;
 	struct btrfs_block_group *block_group;
 	struct list_head discard_list[BTRFS_NR_DISCARD_LISTS];
+	u64 prev_discard;
 	atomic_t discardable_extents;
 	atomic64_t discardable_bytes;
 	unsigned long delay;
 	u32 iops_limit;
+	u32 kbps_limit;
 };
 
 /* delayed seq elem */

commit a2309300841207de28307ecd2f0e031fccde37a3
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Jan 2 16:26:35 2020 -0500

    btrfs: calculate discard delay based on number of extents
    
    An earlier patch keeps track of discardable_extents. These are
    undiscarded extents managed by the free space cache. Here, we will use
    this to dynamically calculate the discard delay interval.
    
    There are 3 rate to consider. The first is the target convergence rate,
    the rate to discard all discardable_extents over the
    BTRFS_DISCARD_TARGET_MSEC time frame. This is clamped by the lower
    limit, the iops limit or BTRFS_DISCARD_MIN_DELAY (1ms), and the upper
    limit, BTRFS_DISCARD_MAX_DELAY (1s). We reevaluate this delay every
    transaction commit.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7c1c236d13ae..451dade0a4bb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -468,6 +468,8 @@ struct btrfs_discard_ctl {
 	struct list_head discard_list[BTRFS_NR_DISCARD_LISTS];
 	atomic_t discardable_extents;
 	atomic64_t discardable_bytes;
+	unsigned long delay;
+	u32 iops_limit;
 };
 
 /* delayed seq elem */

commit 5dc7c10b87474c98116d3438739743cd77263e9f
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:21 2019 -0800

    btrfs: keep track of discardable_bytes for async discard
    
    Keep track of this metric so that we can understand how ahead or behind
    we are in discarding rate. This uses the same accounting method as
    discardable_extents, deltas between previous/current values and
    propagating them up.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 533c5ea0e8c0..7c1c236d13ae 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -467,6 +467,7 @@ struct btrfs_discard_ctl {
 	struct btrfs_block_group *block_group;
 	struct list_head discard_list[BTRFS_NR_DISCARD_LISTS];
 	atomic_t discardable_extents;
+	atomic64_t discardable_bytes;
 };
 
 /* delayed seq elem */

commit dfb79ddb130e0a239e3e90aaf5f5b908555f52bb
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:20 2019 -0800

    btrfs: track discardable extents for async discard
    
    The number of discardable extents will serve as the rate limiting metric
    for how often we should discard. This keeps track of discardable extents
    in the free space caches by maintaining deltas and propagating them to
    the global count.
    
    The deltas are calculated from 2 values stored in PREV and CURR entries,
    then propagated up to the global discard ctl.  The current counter value
    becomes the previous counter value after update.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 71317047c321..533c5ea0e8c0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -101,6 +101,14 @@ struct btrfs_ref;
 
 #define BTRFS_MAX_EXTENT_SIZE SZ_128M
 
+/*
+ * Deltas are an effective way to populate global statistics.  Give macro names
+ * to make it clear what we're doing.  An example is discard_extents in
+ * btrfs_free_space_ctl.
+ */
+#define BTRFS_STAT_NR_ENTRIES	2
+#define BTRFS_STAT_CURR		0
+#define BTRFS_STAT_PREV		1
 
 /*
  * Count how many BTRFS_MAX_EXTENT_SIZE cover the @size
@@ -458,6 +466,7 @@ struct btrfs_discard_ctl {
 	spinlock_t lock;
 	struct btrfs_block_group *block_group;
 	struct list_head discard_list[BTRFS_NR_DISCARD_LISTS];
+	atomic_t discardable_extents;
 };
 
 /* delayed seq elem */

commit e4faab844a55edb9b628bf1f982fbc30f07b9700
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:19 2019 -0800

    btrfs: sysfs: add UUID/debug/discard directory
    
    Setup base sysfs directory for discard stats + tunables.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0626e5562993..71317047c321 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -930,6 +930,7 @@ struct btrfs_fs_info {
 
 #ifdef CONFIG_BTRFS_DEBUG
 	struct kobject *debug_kobj;
+	struct kobject *discard_debug_kobj;
 #endif
 };
 

commit 93945cb43ead1e22e0d5ab50ae361a62cb783ab2
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:18 2019 -0800

    btrfs: sysfs: make UUID/debug have its own kobject
    
    Btrfs only allowed attributes to be exposed in debug/. Let's let other
    groups be created by making debug its own kobject.
    
    This also makes the per-fs debug options separate from the global
    features mount attributes. This seems to be needed as
    sysfs_create_files() requires const struct attribute * while
    sysfs_create_group() can take struct attribute *. This seems nicer as
    per file system, you'll probably use to_fs_info().
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d15a4aa721aa..0626e5562993 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -927,6 +927,10 @@ struct btrfs_fs_info {
 	spinlock_t ref_verify_lock;
 	struct rb_root block_tree;
 #endif
+
+#ifdef CONFIG_BTRFS_DEBUG
+	struct kobject *debug_kobj;
+#endif
 };
 
 static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)

commit 6e80d4f8c422d3b2b0c37324d3243f5ed9b558c8
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:15 2019 -0800

    btrfs: handle empty block_group removal for async discard
    
    block_group removal is a little tricky. It can race with the extent
    allocator, the cleaner thread, and balancing. The current path is for a
    block_group to be added to the unused_bgs list. Then, when the cleaner
    thread comes around, it starts a transaction and then proceeds with
    removing the block_group. Extents that are pinned are subsequently
    removed from the pinned trees and then eventually a discard is issued
    for the entire block_group.
    
    Async discard introduces another player into the game, the discard
    workqueue. While it has none of the racing issues, the new problem is
    ensuring we don't leave free space untrimmed prior to forgetting the
    block_group.  This is handled by placing fully free block_groups on a
    separate discard queue. This is necessary to maintain discarding order
    as in the future we will slowly trim even fully free block_groups. The
    ordering helps us make progress on the same block_group rather than say
    the last fully freed block_group or needing to search through the fully
    freed block groups at the beginning of a list and insert after.
    
    The new order of events is a fully freed block group gets placed on the
    unused discard queue first. Once it's processed, it will be placed on
    the unusued_bgs list and then the original sequence of events will
    happen, just without the final whole block_group discard.
    
    The mount flags can change when processing unused_bgs, so when flipping
    from DISCARD to DISCARD_ASYNC, the unused_bgs must be punted to the
    discard_list to be trimmed. If we flip off DISCARD_ASYNC, we punt
    free block groups on the discard_list to the unused_bg queue which will
    do the final discard for us.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f7b429277089..d15a4aa721aa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -443,9 +443,14 @@ struct btrfs_full_stripe_locks_tree {
 /* Discard control. */
 /*
  * Async discard uses multiple lists to differentiate the discard filter
- * parameters.
+ * parameters.  Index 0 is for completely free block groups where we need to
+ * ensure the entire block group is trimmed without being lossy.  Indices
+ * afterwards represent monotonically decreasing discard filter sizes to
+ * prioritize what should be discarded next.
  */
-#define BTRFS_NR_DISCARD_LISTS		1
+#define BTRFS_NR_DISCARD_LISTS		2
+#define BTRFS_DISCARD_INDEX_UNUSED	0
+#define BTRFS_DISCARD_INDEX_START	1
 
 struct btrfs_discard_ctl {
 	struct workqueue_struct *discard_workers;

commit b0643e59cfa609c4b5f246f2b2c33b078f87e9d9
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:14 2019 -0800

    btrfs: add the beginning of async discard, discard workqueue
    
    When discard is enabled, everytime a pinned extent is released back to
    the block_group's free space cache, a discard is issued for the extent.
    This is an overeager approach when it comes to discarding and helping
    the SSD maintain enough free space to prevent severe garbage collection
    situations.
    
    This adds the beginning of async discard. Instead of issuing a discard
    prior to returning it to the free space, it is just marked as untrimmed.
    The block_group is then added to a LRU which then feeds into a workqueue
    to issue discards at a much slower rate. Full discarding of unused block
    groups is still done and will be addressed in a future patch of the
    series.
    
    For now, we don't persist the discard state of extents and bitmaps.
    Therefore, our failure recovery mode will be to consider extents
    untrimmed. This lets us handle failure and unmounting as one in the
    same.
    
    On a number of Facebook webservers, I collected data every minute
    accounting the time we spent in btrfs_finish_extent_commit() (col. 1)
    and in btrfs_commit_transaction() (col. 2). btrfs_finish_extent_commit()
    is where we discard extents synchronously before returning them to the
    free space cache.
    
    discard=sync:
                     p99 total per minute       p99 total per minute
          Drive   |   extent_commit() (ms)  |    commit_trans() (ms)
        ---------------------------------------------------------------
         Drive A  |           434           |          1170
         Drive B  |           880           |          2330
         Drive C  |          2943           |          3920
         Drive D  |          4763           |          5701
    
    discard=async:
                     p99 total per minute       p99 total per minute
          Drive   |   extent_commit() (ms)  |    commit_trans() (ms)
        --------------------------------------------------------------
         Drive A  |           134           |           956
         Drive B  |            64           |          1972
         Drive C  |            59           |          1032
         Drive D  |            62           |          1200
    
    While it's not great that the stats are cumulative over 1m, all of these
    servers are running the same workload and and the delta between the two
    are substantial. We are spending significantly less time in
    btrfs_finish_extent_commit() which is responsible for discarding.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2f6c21ea84af..f7b429277089 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -440,6 +440,21 @@ struct btrfs_full_stripe_locks_tree {
 	struct mutex lock;
 };
 
+/* Discard control. */
+/*
+ * Async discard uses multiple lists to differentiate the discard filter
+ * parameters.
+ */
+#define BTRFS_NR_DISCARD_LISTS		1
+
+struct btrfs_discard_ctl {
+	struct workqueue_struct *discard_workers;
+	struct delayed_work work;
+	spinlock_t lock;
+	struct btrfs_block_group *block_group;
+	struct list_head discard_list[BTRFS_NR_DISCARD_LISTS];
+};
+
 /* delayed seq elem */
 struct seq_list {
 	struct list_head list;
@@ -526,6 +541,9 @@ enum {
 	 * so we don't need to offload checksums to workqueues.
 	 */
 	BTRFS_FS_CSUM_IMPL_FAST,
+
+	/* Indicate that the discard workqueue can service discards. */
+	BTRFS_FS_DISCARD_RUNNING,
 };
 
 struct btrfs_fs_info {
@@ -816,6 +834,8 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *scrub_wr_completion_workers;
 	struct btrfs_workqueue *scrub_parity_workers;
 
+	struct btrfs_discard_ctl discard_ctl;
+
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	u32 check_integrity_print_mask;
 #endif
@@ -1189,6 +1209,7 @@ static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_fs_info *info)
 #define BTRFS_MOUNT_FREE_SPACE_TREE	(1 << 26)
 #define BTRFS_MOUNT_NOLOGREPLAY		(1 << 27)
 #define BTRFS_MOUNT_REF_VERIFY		(1 << 28)
+#define BTRFS_MOUNT_DISCARD_ASYNC	(1 << 29)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 #define BTRFS_DEFAULT_MAX_INLINE	(2048)

commit 46b27f5059e6ce7a7e3805d53144b37897723e3b
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:11 2019 -0800

    btrfs: rename DISCARD mount option to to DISCARD_SYNC
    
    This series introduces async discard which will use the flag
    DISCARD_ASYNC, so rename the original flag to DISCARD_SYNC as it is
    synchronously done in transaction commit.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e416ef6c9415..2f6c21ea84af 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1170,7 +1170,7 @@ static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_fs_info *info)
 #define BTRFS_MOUNT_FLUSHONCOMMIT       (1 << 7)
 #define BTRFS_MOUNT_SSD_SPREAD		(1 << 8)
 #define BTRFS_MOUNT_NOSSD		(1 << 9)
-#define BTRFS_MOUNT_DISCARD		(1 << 10)
+#define BTRFS_MOUNT_DISCARD_SYNC	(1 << 10)
 #define BTRFS_MOUNT_FORCE_COMPRESS      (1 << 11)
 #define BTRFS_MOUNT_SPACE_CACHE		(1 << 12)
 #define BTRFS_MOUNT_CLEAR_CACHE		(1 << 13)

commit 39b07b5d7072f8e9fd8cc2f840d3749f86699bbb
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Dec 2 17:34:23 2019 -0800

    btrfs: drop create parameter to btrfs_get_extent()
    
    We only pass this as 1 from __extent_writepage_io(). The parameter
    basically means "pretend I didn't pass in a page". This is silly since
    we can simply not pass in the page. Get rid of the parameter from
    btrfs_get_extent(), and since it's used as a get_extent_t callback,
    remove it from get_extent_t and btree_get_extent(), neither of which
    need it.
    
    While we're here, let's document btrfs_get_extent().
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f895fb490b75..e416ef6c9415 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2875,7 +2875,7 @@ struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root);
 struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,
 				    struct page *page, size_t pg_offset,
-				    u64 start, u64 end, int create);
+				    u64 start, u64 end);
 int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode);

commit db72e47f79c5dbd95611edd453328d46c1eae93a
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Dec 10 10:37:35 2019 -0800

    btrfs: get rid of at_offset parameter to btrfs_lookup_bio_sums()
    
    We can encode this in the offset parameter: -1 means use the page
    offsets, anything else is a valid offset.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b1c971cea33a..f895fb490b75 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2789,7 +2789,7 @@ struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, u64 bytenr, u64 len);
 blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
-				   bool at_offset, u64 offset, u8 *dst);
+				   u64 offset, u8 *dst);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,

commit e62958fce94b30ef6aab99bb1bc49fde7fac73ea
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Dec 2 17:34:17 2019 -0800

    btrfs: get rid of trivial __btrfs_lookup_bio_sums() wrappers
    
    Currently, we have two wrappers for __btrfs_lookup_bio_sums():
    btrfs_lookup_bio_sums_dio(), which is used for direct I/O, and
    btrfs_lookup_bio_sums(), which is used everywhere else. The only
    difference is that the _dio variant looks up csums starting at the given
    offset instead of using the page index, which isn't actually direct
    I/O-specific. Let's clean up the signature and return value of
    __btrfs_lookup_bio_sums(), rename it to btrfs_lookup_bio_sums(), and get
    rid of the trivial helpers.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ea49e4b52cd2..b1c971cea33a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2789,9 +2789,7 @@ struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, u64 bytenr, u64 len);
 blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
-				   u8 *dst);
-blk_status_t btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio,
-			      u64 logical_offset);
+				   bool at_offset, u64 offset, u8 *dst);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,

commit a0fbf736d35efcddbfaacddd88aa4ca61c1668c3
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 21 14:03:31 2019 +0200

    btrfs: Rename __btrfs_free_reserved_extent to btrfs_pin_reserved_extent
    
    __btrfs_free_reserved_extent now performs the actions of
    btrfs_free_and_pin_reserved_extent. But this name is a bit of a
    misnomer, since the extent is not really freed but just pinned. Reflect
    this in the new name. No semantics changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 54efb21c2727..ea49e4b52cd2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2449,8 +2449,8 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_ref *ref);
 
 int btrfs_free_reserved_extent(struct btrfs_fs_info *fs_info,
 			       u64 start, u64 len, int delalloc);
-int btrfs_free_and_pin_reserved_extent(struct btrfs_fs_info *fs_info,
-				       u64 start, u64 len);
+int btrfs_pin_reserved_extent(struct btrfs_fs_info *fs_info, u64 start,
+			      u64 len);
 void btrfs_prepare_extent_commit(struct btrfs_fs_info *fs_info);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,

commit 40e046acbd2f369cfbf93c3413639c66514cec2d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Dec 5 16:58:30 2019 +0000

    Btrfs: fix missing data checksums after replaying a log tree
    
    When logging a file that has shared extents (reflinked with other files or
    with itself), we can end up logging multiple checksum items that cover
    overlapping ranges. This confuses the search for checksums at log replay
    time causing some checksums to never be added to the fs/subvolume tree.
    
    Consider the following example of a file that shares the same extent at
    offsets 0 and 256Kb:
    
       [ bytenr 13893632, offset 64Kb, len 64Kb  ]
       0                                         64Kb
    
       [ bytenr 13631488, offset 64Kb, len 192Kb ]
       64Kb                                      256Kb
    
       [ bytenr 13893632, offset 0, len 256Kb    ]
       256Kb                                     512Kb
    
    When logging the inode, at tree-log.c:copy_items(), when processing the
    file extent item at offset 0, we log a checksum item covering the range
    13959168 to 14024704, which corresponds to 13893632 + 64Kb and 13893632 +
    64Kb + 64Kb, respectively.
    
    Later when processing the extent item at offset 256K, we log the checksums
    for the range from 13893632 to 14155776 (which corresponds to 13893632 +
    256Kb). These checksums get merged with the checksum item for the range
    from 13631488 to 13893632 (13631488 + 256Kb), logged by a previous fsync.
    So after this we get the two following checksum items in the log tree:
    
       (...)
       item 6 key (EXTENT_CSUM EXTENT_CSUM 13631488) itemoff 3095 itemsize 512
               range start 13631488 end 14155776 length 524288
       item 7 key (EXTENT_CSUM EXTENT_CSUM 13959168) itemoff 3031 itemsize 64
               range start 13959168 end 14024704 length 65536
    
    The first one covers the range from the second one, they overlap.
    
    So far this does not cause a problem after replaying the log, because
    when replaying the file extent item for offset 256K, we copy all the
    checksums for the extent 13893632 from the log tree to the fs/subvolume
    tree, since searching for an checksum item for bytenr 13893632 leaves us
    at the first checksum item, which covers the whole range of the extent.
    
    However if we write 64Kb to file offset 256Kb for example, we will
    not be able to find and copy the checksums for the last 128Kb of the
    extent at bytenr 13893632, referenced by the file range 384Kb to 512Kb.
    
    After writing 64Kb into file offset 256Kb we get the following extent
    layout for our file:
    
       [ bytenr 13893632, offset 64K, len 64Kb   ]
       0                                         64Kb
    
       [ bytenr 13631488, offset 64Kb, len 192Kb ]
       64Kb                                      256Kb
    
       [ bytenr 14155776, offset 0, len 64Kb     ]
       256Kb                                     320Kb
    
       [ bytenr 13893632, offset 64Kb, len 192Kb ]
       320Kb                                     512Kb
    
    After fsync'ing the file, if we have a power failure and then mount
    the filesystem to replay the log, the following happens:
    
    1) When replaying the file extent item for file offset 320Kb, we
       lookup for the checksums for the extent range from 13959168
       (13893632 + 64Kb) to 14155776 (13893632 + 256Kb), through a call
       to btrfs_lookup_csums_range();
    
    2) btrfs_lookup_csums_range() finds the checksum item that starts
       precisely at offset 13959168 (item 7 in the log tree, shown before);
    
    3) However that checksum item only covers 64Kb of data, and not 192Kb
       of data;
    
    4) As a result only the checksums for the first 64Kb of data referenced
       by the file extent item are found and copied to the fs/subvolume tree.
       The remaining 128Kb of data, file range 384Kb to 512Kb, doesn't get
       the corresponding data checksums found and copied to the fs/subvolume
       tree.
    
    5) After replaying the log userspace will not be able to read the file
       range from 384Kb to 512Kb, because the checksums are missing and
       resulting in an -EIO error.
    
    The following steps reproduce this scenario:
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt/sdc
    
      $ xfs_io -f -c "pwrite -S 0xa3 0 256K" /mnt/sdc/foobar
      $ xfs_io -c "fsync" /mnt/sdc/foobar
      $ xfs_io -c "pwrite -S 0xc7 256K 256K" /mnt/sdc/foobar
    
      $ xfs_io -c "reflink /mnt/sdc/foobar 320K 0 64K" /mnt/sdc/foobar
      $ xfs_io -c "fsync" /mnt/sdc/foobar
    
      $ xfs_io -c "pwrite -S 0xe5 256K 64K" /mnt/sdc/foobar
      $ xfs_io -c "fsync" /mnt/sdc/foobar
    
      <power failure>
    
      $ mount /dev/sdc /mnt/sdc
      $ md5sum /mnt/sdc/foobar
      md5sum: /mnt/sdc/foobar: Input/output error
    
      $ dmesg | tail
      [165305.003464] BTRFS info (device sdc): no csum found for inode 257 start 401408
      [165305.004014] BTRFS info (device sdc): no csum found for inode 257 start 405504
      [165305.004559] BTRFS info (device sdc): no csum found for inode 257 start 409600
      [165305.005101] BTRFS info (device sdc): no csum found for inode 257 start 413696
      [165305.005627] BTRFS info (device sdc): no csum found for inode 257 start 417792
      [165305.006134] BTRFS info (device sdc): no csum found for inode 257 start 421888
      [165305.006625] BTRFS info (device sdc): no csum found for inode 257 start 425984
      [165305.007278] BTRFS info (device sdc): no csum found for inode 257 start 430080
      [165305.008248] BTRFS warning (device sdc): csum failed root 5 ino 257 off 393216 csum 0x1337385e expected csum 0x00000000 mirror 1
      [165305.009550] BTRFS warning (device sdc): csum failed root 5 ino 257 off 393216 csum 0x1337385e expected csum 0x00000000 mirror 1
    
    Fix this simply by deleting first any checksums, from the log tree, for the
    range of the extent we are logging at copy_items(). This ensures we do not
    get checksum items in the log tree that have overlapping ranges.
    
    This is a long time issue that has been present since we have the clone
    (and deduplication) ioctl, and can happen both when an extent is shared
    between different files and within the same file.
    
    A test case for fstests follows soon.
    
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b2e8fd8a8e59..54efb21c2727 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2787,7 +2787,7 @@ struct btrfs_inode_extref *btrfs_find_name_in_ext_backref(
 /* file-item.c */
 struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
-		    struct btrfs_fs_info *fs_info, u64 bytenr, u64 len);
+		    struct btrfs_root *root, u64 bytenr, u64 len);
 blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 				   u8 *dst);
 blk_status_t btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio,

commit 32da5386d9a4fd5c1155cecf703df104d918954c
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 29 19:20:18 2019 +0100

    btrfs: rename btrfs_block_group_cache
    
    The type name is misleading, a single entry is named 'cache' while this
    normally means a collection of objects. Rename that everywhere. Also the
    identifier was quite long, making function prototypes harder to format.
    
    Suggested-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e76b3cda13e3..b2e8fd8a8e59 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,7 +39,7 @@ struct btrfs_transaction;
 struct btrfs_pending_snapshot;
 struct btrfs_delayed_ref_root;
 struct btrfs_space_info;
-struct btrfs_block_group_cache;
+struct btrfs_block_group;
 extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
@@ -415,7 +415,7 @@ struct btrfs_free_cluster {
 	/* We did a full search and couldn't create a cluster */
 	bool fragmented;
 
-	struct btrfs_block_group_cache *block_group;
+	struct btrfs_block_group *block_group;
 	/*
 	 * when a cluster is allocated from a block group, we put the
 	 * cluster onto a list in the block group so that it can
@@ -478,8 +478,8 @@ struct btrfs_swapfile_pin {
 	void *ptr;
 	struct inode *inode;
 	/*
-	 * If true, ptr points to a struct btrfs_block_group_cache. Otherwise,
-	 * ptr points to a struct btrfs_device.
+	 * If true, ptr points to a struct btrfs_block_group. Otherwise, ptr
+	 * points to a struct btrfs_device.
 	 */
 	bool is_block_group;
 };
@@ -2401,7 +2401,7 @@ static inline u64 btrfs_calc_metadata_size(struct btrfs_fs_info *fs_info,
 
 int btrfs_add_excluded_extent(struct btrfs_fs_info *fs_info,
 			      u64 start, u64 num_bytes);
-void btrfs_free_excluded_extents(struct btrfs_block_group_cache *cache);
+void btrfs_free_excluded_extents(struct btrfs_block_group *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   unsigned long count);
 void btrfs_cleanup_ref_head_accounting(struct btrfs_fs_info *fs_info,
@@ -2457,8 +2457,8 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_ref *generic_ref);
 
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
-void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
-void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
+void btrfs_get_block_group_trimming(struct btrfs_block_group *cache);
+void btrfs_put_block_group_trimming(struct btrfs_block_group *cache);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
 enum btrfs_reserve_flush_enum {

commit cfbb825c76198c9095428c5f9362fbf6ae06f417
Author: David Sterba <dsterba@suse.com>
Date:   Tue Jul 10 18:15:05 2018 +0200

    btrfs: add incompat for raid1 with 3, 4 copies
    
    The new raid1c3 and raid1c4 profiles are backward incompatible and the
    name shall be 'raid1c34', the status can be found in the global
    supported features in /sys/fs/btrfs/features or in the per-filesystem
    directory.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 923a8804ae94..e76b3cda13e3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -292,7 +292,8 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF |		\
 	 BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA |	\
 	 BTRFS_FEATURE_INCOMPAT_NO_HOLES	|	\
-	 BTRFS_FEATURE_INCOMPAT_METADATA_UUID)
+	 BTRFS_FEATURE_INCOMPAT_METADATA_UUID	|	\
+	 BTRFS_FEATURE_INCOMPAT_RAID1C34)
 
 #define BTRFS_FEATURE_INCOMPAT_SAFE_SET			\
 	(BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF)

commit 8d6fac0087e538173f34ca7431ed9b58581acf28
Author: David Sterba <dsterba@suse.com>
Date:   Fri Mar 2 22:56:53 2018 +0100

    btrfs: add support for 4-copy replication (raid1c4)
    
    Add new block group profile to store 4 copies in a simliar way that
    current RAID1 does.  The profile attributes and constraints are defined
    in the raid table and used by the same code that already handles the 2-
    and 3-copy RAID1.
    
    The minimum number of devices is 4, the maximum number of devices/chunks
    that can be lost/damaged is 3. There is no comparable traditional RAID
    level, the profile is added for future needs to accompany triple-parity
    and beyond.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aa1b437fb951..923a8804ae94 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -57,9 +57,9 @@ struct btrfs_ref;
  * filesystem data as well that can be used to read data in order to repair
  * read errors on other disks.
  *
- * Current value is derived from RAID1C3 with 3 copies.
+ * Current value is derived from RAID1C4 with 4 copies.
  */
-#define BTRFS_MAX_MIRRORS (3 + 1)
+#define BTRFS_MAX_MIRRORS (4 + 1)
 
 #define BTRFS_MAX_LEVEL 8
 

commit 47e6f7423b9196ad6832d26cae52b7015f81ee7f
Author: David Sterba <dsterba@suse.com>
Date:   Fri Mar 2 22:56:53 2018 +0100

    btrfs: add support for 3-copy replication (raid1c3)
    
    Add new block group profile to store 3 copies in a simliar way that
    current RAID1 does. The profile attributes and constraints are defined
    in the raid table and used by the same code that already handles the
    2-copy RAID1.
    
    The minimum number of devices is 3, the maximum number of devices/chunks
    that can be lost/damaged is 2. Like RAID6 but with 33% space
    utilization.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1c8f01eaf27c..aa1b437fb951 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -57,9 +57,9 @@ struct btrfs_ref;
  * filesystem data as well that can be used to read data in order to repair
  * read errors on other disks.
  *
- * Current value is derived from RAID1 with 2 copies.
+ * Current value is derived from RAID1C3 with 3 copies.
  */
-#define BTRFS_MAX_MIRRORS (2 + 1)
+#define BTRFS_MAX_MIRRORS (3 + 1)
 
 #define BTRFS_MAX_LEVEL 8
 

commit 0222dfdd4af1be2e70db956db61f9b43386ab76b
Author: David Sterba <dsterba@suse.com>
Date:   Wed Oct 23 18:48:20 2019 +0200

    btrfs: rename extent buffer block group item accessors
    
    Accessors defined by BTRFS_SETGET_FUNCS take a raw extent buffer and
    manipulate the items there, there's no special prefix required. The
    block group accessors had _disk_ because previously the names were
    occupied by the on-stack accessors. As this has been addressed in the
    previous patch, we can now unify the naming.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cbec0f071729..1c8f01eaf27c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1521,14 +1521,14 @@ static inline u64 btrfs_stripe_devid_nr(struct extent_buffer *eb,
 /* struct btrfs_block_group_item */
 BTRFS_SETGET_STACK_FUNCS(stack_block_group_used, struct btrfs_block_group_item,
 			 used, 64);
-BTRFS_SETGET_FUNCS(disk_block_group_used, struct btrfs_block_group_item,
+BTRFS_SETGET_FUNCS(block_group_used, struct btrfs_block_group_item,
 			 used, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_block_group_chunk_objectid,
 			struct btrfs_block_group_item, chunk_objectid, 64);
 
-BTRFS_SETGET_FUNCS(disk_block_group_chunk_objectid,
+BTRFS_SETGET_FUNCS(block_group_chunk_objectid,
 		   struct btrfs_block_group_item, chunk_objectid, 64);
-BTRFS_SETGET_FUNCS(disk_block_group_flags,
+BTRFS_SETGET_FUNCS(block_group_flags,
 		   struct btrfs_block_group_item, flags, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_block_group_flags,
 			struct btrfs_block_group_item, flags, 64);

commit de0dc456fd62d387a596508aac1c75736ef6c760
Author: David Sterba <dsterba@suse.com>
Date:   Wed Oct 23 18:48:18 2019 +0200

    btrfs: rename block_group_item on-stack accessors to follow naming
    
    All accessors defined by BTRFS_SETGET_STACK_FUNCS contain _stack_ in the
    name, the block group ones were not following that scheme, so let's
    switch them.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4a842c0fa062..cbec0f071729 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1519,18 +1519,18 @@ static inline u64 btrfs_stripe_devid_nr(struct extent_buffer *eb,
 }
 
 /* struct btrfs_block_group_item */
-BTRFS_SETGET_STACK_FUNCS(block_group_used, struct btrfs_block_group_item,
+BTRFS_SETGET_STACK_FUNCS(stack_block_group_used, struct btrfs_block_group_item,
 			 used, 64);
 BTRFS_SETGET_FUNCS(disk_block_group_used, struct btrfs_block_group_item,
 			 used, 64);
-BTRFS_SETGET_STACK_FUNCS(block_group_chunk_objectid,
+BTRFS_SETGET_STACK_FUNCS(stack_block_group_chunk_objectid,
 			struct btrfs_block_group_item, chunk_objectid, 64);
 
 BTRFS_SETGET_FUNCS(disk_block_group_chunk_objectid,
 		   struct btrfs_block_group_item, chunk_objectid, 64);
 BTRFS_SETGET_FUNCS(disk_block_group_flags,
 		   struct btrfs_block_group_item, flags, 64);
-BTRFS_SETGET_STACK_FUNCS(block_group_flags,
+BTRFS_SETGET_STACK_FUNCS(stack_block_group_flags,
 			struct btrfs_block_group_item, flags, 64);
 
 /* struct btrfs_free_space_info */

commit b4e967be431cf37f56cd1993592943007d7ab03b
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 8 18:41:33 2019 +0200

    btrfs: add member for a specific checksum driver
    
    Currently all the checksum algorithms generate a fixed size digest size
    and we use it.  The on-disk format can hold up to BTRFS_CSUM_SIZE bytes
    and BLAKE2b produces digest of 512 bits by default. We can't do that and
    will use the blake2b-256, this needs to be passed to the crypto API.
    
    Separate that from the base algorithm name and add a member to request
    specific driver, in this case with the digest size.
    
    The only place that uses the driver name is the crypto API setup.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b17944995e09..4a842c0fa062 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2163,6 +2163,7 @@ BTRFS_SETGET_STACK_FUNCS(super_uuid_tree_generation, struct btrfs_super_block,
 
 int btrfs_super_csum_size(const struct btrfs_super_block *s);
 const char *btrfs_super_csum_name(u16 csum_type);
+const char *btrfs_super_csum_driver(u16 csum_type);
 size_t __const btrfs_get_num_csums(void);
 
 

commit f7cea56c0fff95bd5a6cd21b9fa299f66193b604
Author: David Sterba <dsterba@suse.com>
Date:   Mon Oct 7 11:11:03 2019 +0200

    btrfs: sysfs: export supported checksums
    
    Export supported checksum algorithms via sysfs in the list of static
    features:
    
      /sys/fs/btrfs/features/supported_checksums
    
    Space spearated list of checksum algorithm names.
    
    Co-developed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d5c9fbe32c0c..b17944995e09 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2163,6 +2163,8 @@ BTRFS_SETGET_STACK_FUNCS(super_uuid_tree_generation, struct btrfs_super_block,
 
 int btrfs_super_csum_size(const struct btrfs_super_block *s);
 const char *btrfs_super_csum_name(u16 csum_type);
+size_t __const btrfs_get_num_csums(void);
+
 
 /*
  * The leaf data grows from end-to-front in the node.

commit ba8a9d07954397f0645cf62bcc1ef536e8e7ba24
Author: Chris Mason <clm@fb.com>
Date:   Wed Jul 10 12:28:15 2019 -0700

    Btrfs: delete the entire async bio submission framework
    
    Now that we're not using btrfs_schedule_bio() anymore, delete all the
    code that supported it.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d486703009fa..d5c9fbe32c0c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -723,7 +723,6 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *endio_meta_write_workers;
 	struct btrfs_workqueue *endio_write_workers;
 	struct btrfs_workqueue *endio_freespace_worker;
-	struct btrfs_workqueue *submit_workers;
 	struct btrfs_workqueue *caching_workers;
 	struct btrfs_workqueue *readahead_workers;
 

commit e1f60a6580c04d0d2492bb6034e968b8c29c78cf
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 1 19:57:39 2019 +0200

    btrfs: add __pure attribute to functions
    
    The attribute is more relaxed than const and the functions could
    dereference pointers, as long as the observable state is not changed. We
    do have such functions, based on -Wsuggest-attribute=pure .
    
    The visible effects of this patch are negligible, there are differences
    in the assembly but hard to summarize.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8d7ac1cd49b4..d486703009fa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2508,7 +2508,7 @@ void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, const struct btrfs_key *key,
 		     int level, int *slot);
-int btrfs_comp_cpu_keys(const struct btrfs_key *k1, const struct btrfs_key *k2);
+int __pure btrfs_comp_cpu_keys(const struct btrfs_key *k1, const struct btrfs_key *k2);
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
@@ -2907,7 +2907,7 @@ long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 long btrfs_compat_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 int btrfs_ioctl_get_supported_features(void __user *arg);
 void btrfs_sync_inode_flags_to_i_flags(struct inode *inode);
-int btrfs_is_empty_uuid(u8 *uuid);
+int __pure btrfs_is_empty_uuid(u8 *uuid);
 int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      struct btrfs_ioctl_defrag_range_args *range,
 		      u64 newer_than, unsigned long max_pages);

commit 4143cb8b6f00910e73a7503fd922211b9f08cf48
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 1 19:57:37 2019 +0200

    btrfs: add const function attribute
    
    For some reason the attribute is called __attribute_const__ and not
    __const, marks functions that have no observable effects on program
    state, IOW not reading pointers, just the arguments and calculating a
    value. Allows the compiler to do some optimizations, based on
    -Wsuggest-attribute=const . The effects are rather small, though, about
    60 bytes decrese of btrfs.ko.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b23fb083a1d5..8d7ac1cd49b4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3141,7 +3141,7 @@ __cold
 void __btrfs_handle_fs_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);
 
-const char *btrfs_decode_error(int errno);
+const char * __attribute_const__ btrfs_decode_error(int errno);
 
 __cold
 void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,

commit 4c66e0d4243bb8829f2c936e966030d967726e90
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 3 19:09:35 2019 +0200

    btrfs: drop unused parameter is_new from btrfs_iget
    
    The parameter is now always set to NULL and could be dropped. The last
    user was get_default_root but that got reworked in 05dbe6837b60 ("Btrfs:
    unify subvol= and subvolid= mounting") and the parameter became unused.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 668524097a3c..b23fb083a1d5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2869,10 +2869,9 @@ int btrfs_drop_inode(struct inode *inode);
 int __init btrfs_init_cachep(void);
 void __cold btrfs_destroy_cachep(void);
 struct inode *btrfs_iget_path(struct super_block *s, struct btrfs_key *location,
-			      struct btrfs_root *root, int *new,
-			      struct btrfs_path *path);
+			      struct btrfs_root *root, struct btrfs_path *path);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
-			 struct btrfs_root *root, int *was_new);
+			 struct btrfs_root *root);
 struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,
 				    struct page *page, size_t pg_offset,
 				    u64 start, u64 end, int create);

commit 1f95ec012cb4a3fabfef3efd9ba0b59e14ce48ce
Author: David Sterba <dsterba@suse.com>
Date:   Tue Sep 24 19:17:17 2019 +0200

    btrfs: move btrfs_unlock_up_safe to other locking functions
    
    The function belongs to the family of locking functions, so move it
    there. The 'noinline' keyword is dropped as it's now an exported
    function that does not need it.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9939b552089b..668524097a3c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2568,8 +2568,6 @@ int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 void btrfs_release_path(struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
-void btrfs_set_path_blocking(struct btrfs_path *p);
-void btrfs_unlock_up_safe(struct btrfs_path *p, int level);
 
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_path *path, int slot, int nr);

commit 9c7d3a548331e72ba3613eaa5c8a74839462b764
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Sep 23 10:05:19 2019 -0400

    btrfs: move extent_io_tree defs to their own header
    
    extent_io.c/h are huge, encompassing a bunch of different things.  The
    extent_io_tree code can live on its own, so separate this out.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fe2b8765d9e6..9939b552089b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -28,6 +28,7 @@
 #include <linux/dynamic_debug.h>
 #include <linux/refcount.h>
 #include <linux/crc32c.h>
+#include "extent-io-tree.h"
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"

commit 8702ba9396bf7bbae2ab93c94acd4bd37cfa4f09
Author: Qu Wenruo <wqu@suse.com>
Date:   Mon Oct 14 14:34:51 2019 +0800

    btrfs: qgroup: Always free PREALLOC META reserve in btrfs_delalloc_release_extents()
    
    [Background]
    Btrfs qgroup uses two types of reserved space for METADATA space,
    PERTRANS and PREALLOC.
    
    PERTRANS is metadata space reserved for each transaction started by
    btrfs_start_transaction().
    While PREALLOC is for delalloc, where we reserve space before joining a
    transaction, and finally it will be converted to PERTRANS after the
    writeback is done.
    
    [Inconsistency]
    However there is inconsistency in how we handle PREALLOC metadata space.
    
    The most obvious one is:
    In btrfs_buffered_write():
            btrfs_delalloc_release_extents(BTRFS_I(inode), reserve_bytes, true);
    
    We always free qgroup PREALLOC meta space.
    
    While in btrfs_truncate_block():
            btrfs_delalloc_release_extents(BTRFS_I(inode), blocksize, (ret != 0));
    
    We only free qgroup PREALLOC meta space when something went wrong.
    
    [The Correct Behavior]
    The correct behavior should be the one in btrfs_buffered_write(), we
    should always free PREALLOC metadata space.
    
    The reason is, the btrfs_delalloc_* mechanism works by:
    - Reserve metadata first, even it's not necessary
      In btrfs_delalloc_reserve_metadata()
    
    - Free the unused metadata space
      Normally in:
      btrfs_delalloc_release_extents()
      |- btrfs_inode_rsv_release()
         Here we do calculation on whether we should release or not.
    
    E.g. for 64K buffered write, the metadata rsv works like:
    
    /* The first page */
    reserve_meta:   num_bytes=calc_inode_reservations()
    free_meta:      num_bytes=0
    total:          num_bytes=calc_inode_reservations()
    /* The first page caused one outstanding extent, thus needs metadata
       rsv */
    
    /* The 2nd page */
    reserve_meta:   num_bytes=calc_inode_reservations()
    free_meta:      num_bytes=calc_inode_reservations()
    total:          not changed
    /* The 2nd page doesn't cause new outstanding extent, needs no new meta
       rsv, so we free what we have reserved */
    
    /* The 3rd~16th pages */
    reserve_meta:   num_bytes=calc_inode_reservations()
    free_meta:      num_bytes=calc_inode_reservations()
    total:          not changed (still space for one outstanding extent)
    
    This means, if btrfs_delalloc_release_extents() determines to free some
    space, then those space should be freed NOW.
    So for qgroup, we should call btrfs_qgroup_free_meta_prealloc() other
    than btrfs_qgroup_convert_reserved_meta().
    
    The good news is:
    - The callers are not that hot
      The hottest caller is in btrfs_buffered_write(), which is already
      fixed by commit 336a8bb8e36a ("btrfs: Fix wrong
      btrfs_delalloc_release_extents parameter"). Thus it's not that
      easy to cause false EDQUOT.
    
    - The trans commit in advance for qgroup would hide the bug
      Since commit f5fef4593653 ("btrfs: qgroup: Make qgroup async transaction
      commit more aggressive"), when btrfs qgroup metadata free space is slow,
      it will try to commit transaction and free the wrongly converted
      PERTRANS space, so it's not that easy to hit such bug.
    
    [FIX]
    So to fix the problem, remove the @qgroup_free parameter for
    btrfs_delalloc_release_extents(), and always pass true to
    btrfs_inode_rsv_release().
    
    Reported-by: Filipe Manana <fdmanana@suse.com>
    Fixes: 43b18595d660 ("btrfs: qgroup: Use separate meta reservation type for delalloc")
    CC: stable@vger.kernel.org # 4.19+
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c1489c229694..fe2b8765d9e6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2487,8 +2487,7 @@ int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     int nitems, bool use_global_rsv);
 void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv);
-void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes,
-				    bool qgroup_free);
+void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes);
 
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);

commit 80ed4548d0711d15ca51be5dee0ff813051cfc90
Author: David Sterba <dsterba@suse.com>
Date:   Sat Oct 12 18:42:10 2019 +0200

    btrfs: don't needlessly create extent-refs kernel thread
    
    The patch 32b593bfcb58 ("Btrfs: remove no longer used function to run
    delayed refs asynchronously") removed the async delayed refs but the
    thread has been created, without any use. Remove it to avoid resource
    consumption.
    
    Fixes: 32b593bfcb58 ("Btrfs: remove no longer used function to run delayed refs asynchronously")
    CC: stable@vger.kernel.org # 5.2+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 19d669d12ca1..c1489c229694 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -734,8 +734,6 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *fixup_workers;
 	struct btrfs_workqueue *delayed_workers;
 
-	/* the extent workers do delayed refs on the extent allocation tree */
-	struct btrfs_workqueue *extent_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
 	u32 thread_pool_size;

commit af024ed2e0e56f27279cdba4d27a23dbb7677e40
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Fri Aug 30 13:36:09 2019 +0200

    btrfs: create structure to encode checksum type and length
    
    Create a structure to encode the type and length for the known on-disk
    checksums.  This makes it easier to add new checksums later.
    
    The structure and helpers are moved from ctree.h so they don't occupy
    space in all headers including ctree.h. This save some space in the
    final object.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 033a0d5d1789..19d669d12ca1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -83,10 +83,6 @@ struct btrfs_ref;
  */
 #define BTRFS_LINK_MAX 65535U
 
-/* four bytes for CRC32 */
-static const int btrfs_csum_sizes[] = { 4 };
-static const char *btrfs_csum_names[] = { "crc32c" };
-
 #define BTRFS_EMPTY_DIR_SIZE 0
 
 /* ioprio of readahead is set to idle */
@@ -2167,20 +2163,8 @@ BTRFS_SETGET_STACK_FUNCS(super_magic, struct btrfs_super_block, magic, 64);
 BTRFS_SETGET_STACK_FUNCS(super_uuid_tree_generation, struct btrfs_super_block,
 			 uuid_tree_generation, 64);
 
-static inline int btrfs_super_csum_size(const struct btrfs_super_block *s)
-{
-	u16 t = btrfs_super_csum_type(s);
-	/*
-	 * csum type is validated at mount time
-	 */
-	return btrfs_csum_sizes[t];
-}
-
-static inline const char *btrfs_super_csum_name(u16 csum_type)
-{
-	/* csum type is validated at mount time */
-	return btrfs_csum_names[csum_type];
-}
+int btrfs_super_csum_size(const struct btrfs_super_block *s);
+const char *btrfs_super_csum_name(u16 csum_type);
 
 /*
  * The leaf data grows from end-to-front in the node.

commit c82f823c9b006c31059341af41da9f8b2e3e64d9
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 9 17:48:21 2019 +0200

    btrfs: tie extent buffer and it's token together
    
    Further simplifaction of the get/set helpers is possible when the token
    is uniquely tied to an extent buffer. A condition and an assignment can
    be avoided.
    
    The initializations are moved closer to the first use when the extent
    buffer is valid. There's one exception in __push_leaf_left where the
    token is reused.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8e18fb062215..033a0d5d1789 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1303,8 +1303,10 @@ struct btrfs_map_token {
 #define BTRFS_BYTES_TO_BLKS(fs_info, bytes) \
 				((bytes) >> (fs_info)->sb->s_blocksize_bits)
 
-static inline void btrfs_init_map_token (struct btrfs_map_token *token)
+static inline void btrfs_init_map_token(struct btrfs_map_token *token,
+					struct extent_buffer *eb)
 {
+	token->eb = eb;
 	token->kaddr = NULL;
 }
 

commit cb49511328dcce73840a54661622950d7fa6384e
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 9 17:12:38 2019 +0200

    btrfs: define separate btrfs_set/get_XX helpers
    
    There are helpers for all type widths defined via macro and optionally
    can use a token which is a cached pointer to avoid repeated mapping of
    the extent buffer.
    
    The token value is known at compile time, when it's valid it's always
    address of a local variable, otherwise it's NULL passed by the
    token-less helpers.
    
    This can be utilized to remove some branching as the helpers are used
    frequenlty.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 292e21b23217..8e18fb062215 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1335,17 +1335,10 @@ u##bits btrfs_get_token_##bits(const struct extent_buffer *eb,		\
 void btrfs_set_token_##bits(struct extent_buffer *eb, const void *ptr,	\
 			    unsigned long off, u##bits val,		\
 			    struct btrfs_map_token *token);		\
-static inline u##bits btrfs_get_##bits(const struct extent_buffer *eb,	\
-				       const void *ptr,			\
-				       unsigned long off)		\
-{									\
-	return btrfs_get_token_##bits(eb, ptr, off, NULL);		\
-}									\
-static inline void btrfs_set_##bits(struct extent_buffer *eb, void *ptr,\
-				    unsigned long off, u##bits val)	\
-{									\
-       btrfs_set_token_##bits(eb, ptr, off, val, NULL);			\
-}
+u##bits btrfs_get_##bits(const struct extent_buffer *eb,		\
+			 const void *ptr, unsigned long off);		\
+void btrfs_set_##bits(struct extent_buffer *eb, void *ptr,		\
+		      unsigned long off, u##bits val);
 
 DECLARE_BTRFS_SETGET_BITS(8)
 DECLARE_BTRFS_SETGET_BITS(16)

commit 6ff49c6ad285160b8ba48589ebdbf6cebdd42f74
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Aug 27 14:46:29 2019 +0300

    btrfs: Make btrfs_find_name_in_ext_backref return struct btrfs_inode_extref
    
    btrfs_find_name_in_ext_backref returns either 0/1 depending on whether it
    found a backref for the given name. If it returns true then the actual
    inode_ref struct is returned in one of its parameters. That's pointless,
    instead refactor the function such that it returns either a pointer
    to the btrfs_inode_extref or NULL it it didn't find anything. This
    streamlines the function calling convention.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 31ed47d195c2..292e21b23217 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2803,11 +2803,9 @@ btrfs_lookup_inode_extref(struct btrfs_trans_handle *trans,
 struct btrfs_inode_ref *btrfs_find_name_in_backref(struct extent_buffer *leaf,
 						   int slot, const char *name,
 						   int name_len);
-int btrfs_find_name_in_ext_backref(struct extent_buffer *leaf, int slot,
-				   u64 ref_objectid, const char *name,
-				   int name_len,
-				   struct btrfs_inode_extref **extref_ret);
-
+struct btrfs_inode_extref *btrfs_find_name_in_ext_backref(
+		struct extent_buffer *leaf, int slot, u64 ref_objectid,
+		const char *name, int name_len);
 /* file-item.c */
 struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,

commit 9bb8407f54f63242d822d6c57f4edb7d1ae2b901
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Aug 27 14:46:28 2019 +0300

    btrfs: Make btrfs_find_name_in_backref return btrfs_inode_ref struct
    
    btrfs_find_name_in_backref returns either 0/1 depending on whether it
    found a backref for the given name. If it returns true then the actual
    inode_ref struct is returned in one of its parameters. That's pointless,
    instead refactor the function such that it returns either a pointer
    to the btrfs_inode_ref or NULL it it didn't find anything. This
    streamlines the function calling convention.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ba34f7b435a2..31ed47d195c2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2800,9 +2800,9 @@ btrfs_lookup_inode_extref(struct btrfs_trans_handle *trans,
 			  u64 inode_objectid, u64 ref_objectid, int ins_len,
 			  int cow);
 
-int btrfs_find_name_in_backref(struct extent_buffer *leaf, int slot,
-			       const char *name,
-			       int name_len, struct btrfs_inode_ref **ref_ret);
+struct btrfs_inode_ref *btrfs_find_name_in_backref(struct extent_buffer *leaf,
+						   int slot, const char *name,
+						   int name_len);
 int btrfs_find_name_in_ext_backref(struct extent_buffer *leaf, int slot,
 				   u64 ref_objectid, const char *name,
 				   int name_len,

commit 1dc990dfd31096176788312d39e1275645901fcb
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 20:05:32 2019 +0200

    btrfs: move dev_stats helpers to volumes.c
    
    The other dev stats functions are already there and the helpers are not
    used by anything else.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0b6eca746fd4..ba34f7b435a2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2258,30 +2258,6 @@ static inline u32 btrfs_file_extent_inline_item_len(
 	return btrfs_item_size(eb, e) - BTRFS_FILE_EXTENT_INLINE_DATA_START;
 }
 
-/* btrfs_dev_stats_item */
-static inline u64 btrfs_dev_stats_value(const struct extent_buffer *eb,
-					const struct btrfs_dev_stats_item *ptr,
-					int index)
-{
-	u64 val;
-
-	read_extent_buffer(eb, &val,
-			   offsetof(struct btrfs_dev_stats_item, values) +
-			    ((unsigned long)ptr) + (index * sizeof(u64)),
-			   sizeof(val));
-	return val;
-}
-
-static inline void btrfs_set_dev_stats_value(struct extent_buffer *eb,
-					     struct btrfs_dev_stats_item *ptr,
-					     int index, u64 val)
-{
-	write_extent_buffer(eb, &val,
-			    offsetof(struct btrfs_dev_stats_item, values) +
-			     ((unsigned long)ptr) + (index * sizeof(u64)),
-			    sizeof(val));
-}
-
 /* btrfs_qgroup_status_item */
 BTRFS_SETGET_FUNCS(qgroup_status_generation, struct btrfs_qgroup_status_item,
 		   generation, 64);

commit 67b61aefcef3842a360e6c603860a785fd971c7a
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 19:57:04 2019 +0200

    btrfs: move struct io_ctl to free-space-cache.h
    
    The io_ctl structure is used for free space management, and used only by
    the v1 space cache code, but unfortunatlly the full definition is
    required by block-group.h so it can't be moved to free-space-cache.c
    without additional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 17cd88521ad2..0b6eca746fd4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -434,20 +434,6 @@ enum btrfs_caching_type {
 	BTRFS_CACHE_ERROR,
 };
 
-struct btrfs_io_ctl {
-	void *cur, *orig;
-	struct page *page;
-	struct page **pages;
-	struct btrfs_fs_info *fs_info;
-	struct inode *inode;
-	unsigned long size;
-	int index;
-	int num_pages;
-	int entries;
-	int bitmaps;
-	unsigned check_crcs:1;
-};
-
 /*
  * Tree to record all locked full stripes of a RAID5/6 block group
  */

commit 18d0f5c6e16ce762f92ab7879c30ff2e37cd9cef
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 19:12:59 2019 +0200

    btrfs: move functions for tree compare to send.c
    
    Send is the only user of tree_compare, we can move it there along with
    the other helpers and definitions.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dc465df47b32..17cd88521ad2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2590,20 +2590,6 @@ int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
 struct extent_buffer *btrfs_read_node_slot(struct extent_buffer *parent,
 					   int slot);
 
-enum btrfs_compare_tree_result {
-	BTRFS_COMPARE_TREE_NEW,
-	BTRFS_COMPARE_TREE_DELETED,
-	BTRFS_COMPARE_TREE_CHANGED,
-	BTRFS_COMPARE_TREE_SAME,
-};
-typedef int (*btrfs_changed_cb_t)(struct btrfs_path *left_path,
-				  struct btrfs_path *right_path,
-				  struct btrfs_key *key,
-				  enum btrfs_compare_tree_result result,
-				  void *ctx);
-int btrfs_compare_trees(struct btrfs_root *left_root,
-			struct btrfs_root *right_root,
-			btrfs_changed_cb_t cb, void *ctx);
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,

commit 4b231ae47417d47a6bafab92b452ad629acdacb0
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 19:16:27 2019 +0200

    btrfs: rename and export read_node_slot
    
    Preparatory work for code that will be moved out of ctree and uses this
    function.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 07c08831d6e7..dc465df47b32 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2587,6 +2587,9 @@ int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
 int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
 			 struct btrfs_path *path,
 			 u64 min_trans);
+struct extent_buffer *btrfs_read_node_slot(struct extent_buffer *parent,
+					   int slot);
+
 enum btrfs_compare_tree_result {
 	BTRFS_COMPARE_TREE_NEW,
 	BTRFS_COMPARE_TREE_DELETED,

commit 8a953348afdd75f45d75e5ff489876fe88f3731d
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 19:06:17 2019 +0200

    btrfs: move private raid56 definitions from ctree.h
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5cb410cc1502..07c08831d6e7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -471,22 +471,6 @@ enum btrfs_orphan_cleanup_state {
 	ORPHAN_CLEANUP_DONE	= 2,
 };
 
-/* used by the raid56 code to lock stripes for read/modify/write */
-struct btrfs_stripe_hash {
-	struct list_head hash_list;
-	spinlock_t lock;
-};
-
-/* used by the raid56 code to lock stripes for read/modify/write */
-struct btrfs_stripe_hash_table {
-	struct list_head stripe_cache;
-	spinlock_t cache_lock;
-	int cache_size;
-	struct btrfs_stripe_hash table[];
-};
-
-#define BTRFS_STRIPE_HASH_TABLE_BITS 11
-
 void btrfs_init_async_reclaim_work(struct work_struct *work);
 
 /* fs_info */

commit 602cbe91fb012a923a9fea880e600e004eb1543b
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 18:48:25 2019 +0200

    btrfs: move cond_wake_up functions out of ctree
    
    The file ctree.h serves as a header for everything and has become quite
    bloated. Split some helpers that are generic and create a new file that
    should be the catch-all for code that's not btrfs-specific.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ef40fffb5e46..5cb410cc1502 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3517,26 +3517,4 @@ static inline int btrfs_is_testing(struct btrfs_fs_info *fs_info)
 }
 #endif
 
-static inline void cond_wake_up(struct wait_queue_head *wq)
-{
-	/*
-	 * This implies a full smp_mb barrier, see comments for
-	 * waitqueue_active why.
-	 */
-	if (wq_has_sleeper(wq))
-		wake_up(wq);
-}
-
-static inline void cond_wake_up_nomb(struct wait_queue_head *wq)
-{
-	/*
-	 * Special case for conditional wakeup where the barrier required for
-	 * waitqueue_active is implied by some of the preceding code. Eg. one
-	 * of such atomic operations (atomic_dec_and_return, ...), or a
-	 * unlock/lock sequence, etc.
-	 */
-	if (waitqueue_active(wq))
-		wake_up(wq);
-}
-
 #endif

commit 3acd48507dc43eeeb0a1fe965b8bad91cab904a7
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Wed Aug 21 15:05:55 2019 +0000

    btrfs: fix allocation of free space cache v1 bitmap pages
    
    Various notifications of type "BUG kmalloc-4096 () : Redzone
    overwritten" have been observed recently in various parts of the kernel.
    After some time, it has been made a relation with the use of BTRFS
    filesystem and with SLUB_DEBUG turned on.
    
    [   22.809700] BUG kmalloc-4096 (Tainted: G        W        ): Redzone overwritten
    
    [   22.810286] INFO: 0xbe1a5921-0xfbfc06cd. First byte 0x0 instead of 0xcc
    [   22.810866] INFO: Allocated in __load_free_space_cache+0x588/0x780 [btrfs] age=22 cpu=0 pid=224
    [   22.811193]  __slab_alloc.constprop.26+0x44/0x70
    [   22.811345]  kmem_cache_alloc_trace+0xf0/0x2ec
    [   22.811588]  __load_free_space_cache+0x588/0x780 [btrfs]
    [   22.811848]  load_free_space_cache+0xf4/0x1b0 [btrfs]
    [   22.812090]  cache_block_group+0x1d0/0x3d0 [btrfs]
    [   22.812321]  find_free_extent+0x680/0x12a4 [btrfs]
    [   22.812549]  btrfs_reserve_extent+0xec/0x220 [btrfs]
    [   22.812785]  btrfs_alloc_tree_block+0x178/0x5f4 [btrfs]
    [   22.813032]  __btrfs_cow_block+0x150/0x5d4 [btrfs]
    [   22.813262]  btrfs_cow_block+0x194/0x298 [btrfs]
    [   22.813484]  commit_cowonly_roots+0x44/0x294 [btrfs]
    [   22.813718]  btrfs_commit_transaction+0x63c/0xc0c [btrfs]
    [   22.813973]  close_ctree+0xf8/0x2a4 [btrfs]
    [   22.814107]  generic_shutdown_super+0x80/0x110
    [   22.814250]  kill_anon_super+0x18/0x30
    [   22.814437]  btrfs_kill_super+0x18/0x90 [btrfs]
    [   22.814590] INFO: Freed in proc_cgroup_show+0xc0/0x248 age=41 cpu=0 pid=83
    [   22.814841]  proc_cgroup_show+0xc0/0x248
    [   22.814967]  proc_single_show+0x54/0x98
    [   22.815086]  seq_read+0x278/0x45c
    [   22.815190]  __vfs_read+0x28/0x17c
    [   22.815289]  vfs_read+0xa8/0x14c
    [   22.815381]  ksys_read+0x50/0x94
    [   22.815475]  ret_from_syscall+0x0/0x38
    
    Commit 69d2480456d1 ("btrfs: use copy_page for copying pages instead of
    memcpy") changed the way bitmap blocks are copied. But allthough bitmaps
    have the size of a page, they were allocated with kzalloc().
    
    Most of the time, kzalloc() allocates aligned blocks of memory, so
    copy_page() can be used. But when some debug options like SLAB_DEBUG are
    activated, kzalloc() may return unaligned pointer.
    
    On powerpc, memcpy(), copy_page() and other copying functions use
    'dcbz' instruction which provides an entire zeroed cacheline to avoid
    memory read when the intention is to overwrite a full line. Functions
    like memcpy() are writen to care about partial cachelines at the start
    and end of the destination, but copy_page() assumes it gets pages. As
    pages are naturally cache aligned, copy_page() doesn't care about
    partial lines. This means that when copy_page() is called with a
    misaligned pointer, a few leading bytes are zeroed.
    
    To fix it, allocate bitmaps through kmem_cache instead of using kzalloc()
    The cache pool is created with PAGE_SIZE alignment constraint.
    
    Reported-by: Erhard F. <erhard_f@mailbox.org>
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=204371
    Fixes: 69d2480456d1 ("btrfs: use copy_page for copying pages instead of memcpy")
    Cc: stable@vger.kernel.org # 4.19+
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ rename to btrfs_free_space_bitmap ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d27b39858339..ef40fffb5e46 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -43,6 +43,7 @@ extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 extern struct kmem_cache *btrfs_free_space_cachep;
+extern struct kmem_cache *btrfs_free_space_bitmap_cachep;
 struct btrfs_ordered_sum;
 struct btrfs_ref;
 

commit 2bd36e7b4fd60d4ff5f9ba6a0ad84557ae4803c4
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Aug 22 15:14:33 2019 -0400

    btrfs: rename the btrfs_calc_*_metadata_size helpers
    
    btrfs_calc_trunc_metadata_size differs from trans_metadata_size in that
    it doesn't take into account any splitting at the levels, because
    truncate will never split nodes.  However truncate _and_ changing will
    never split nodes, so rename btrfs_calc_trunc_metadata_size to
    btrfs_calc_metadata_size.  Also btrfs_calc_trans_metadata_size is purely
    for inserting items, so rename this to btrfs_calc_insert_metadata_size.
    Making these clearer will help when I start using them differently in
    upcoming patches.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 20793742c9d3..d27b39858339 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2451,17 +2451,21 @@ u64 hash_extent_data_ref(u64 root_objectid, u64 owner, u64 offset);
 
 u64 btrfs_csum_bytes_to_leaves(struct btrfs_fs_info *fs_info, u64 csum_bytes);
 
-static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,
-						 unsigned num_items)
+/*
+ * Use this if we would be adding new items, as we could split nodes as we cow
+ * down the tree.
+ */
+static inline u64 btrfs_calc_insert_metadata_size(struct btrfs_fs_info *fs_info,
+						  unsigned num_items)
 {
 	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
 }
 
 /*
- * Doing a truncate won't result in new nodes or leaves, just what we need for
- * COW.
+ * Doing a truncate or a modification won't result in new nodes or leaves, just
+ * what we need for COW.
  */
-static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
+static inline u64 btrfs_calc_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
 	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;

commit 0785a9aacf9de9cd6a89a628b3b5d6b7e9ce5316
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Aug 9 09:24:24 2019 +0800

    btrfs: tree-checker: Add EXTENT_DATA_REF check
    
    EXTENT_DATA_REF is a little like DIR_ITEM which contains hash in its
    key->offset.
    
    This patch will check the following contents:
    - Key->objectid
      Basic alignment check.
    
    - Hash
      Hash of each extent_data_ref item must match key->offset.
    
    - Offset
      Basic alignment check.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b161224b5a0b..20793742c9d3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2447,6 +2447,7 @@ enum btrfs_inline_ref_type {
 int btrfs_get_extent_inline_ref_type(const struct extent_buffer *eb,
 				     struct btrfs_extent_inline_ref *iref,
 				     enum btrfs_inline_ref_type is_data);
+u64 hash_extent_data_ref(u64 root_objectid, u64 owner, u64 offset);
 
 u64 btrfs_csum_bytes_to_leaves(struct btrfs_fs_info *fs_info, u64 csum_bytes);
 

commit d3984c90414a36af581b3b7c0daa87f9de3c0533
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Aug 1 18:19:37 2019 -0400

    btrfs: introduce an evict flushing state
    
    We have this weird space flushing loop inside inode.c for evict where
    we'll do the normal LIMIT flush, and then commit the transaction and
    hope we get our space.  This is super janky, and in fact there's really
    nothing stopping us from using FLUSH_ALL except that we run delayed
    iputs, which means we could deadlock.  So introduce a new flush state
    for eviction that does the normal priority flushing with all of the
    states that are safe for eviction.
    
    The nice side-effect of this is that we'll try harder for evictions.
    Previously if (for example generic/269) you had a bunch of other
    operations happening on the fs you could race with those reservations
    when committing the transaction, and eventually miss getting a
    reservation for the evict.  With this code we'll have our ticket in
    place through the transaction commit, so any pinned bytes will go to our
    pending evictions first.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4ad4715a7941..b161224b5a0b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2536,6 +2536,7 @@ enum btrfs_reserve_flush_enum {
 	 * case, use FLUSH LIMIT
 	 */
 	BTRFS_RESERVE_FLUSH_LIMIT,
+	BTRFS_RESERVE_FLUSH_EVICT,
 	BTRFS_RESERVE_FLUSH_ALL,
 };
 

commit 844245b4548499efad26e33e408a459b1fe3a346
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Aug 1 18:19:33 2019 -0400

    btrfs: add a flush step for delayed iputs
    
    Delayed iputs could very well free up enough space without needing to
    commit the transaction, so make this step it's own step.  This will
    allow us to skip the step for evictions in a later patch.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 85b808e3ea42..4ad4715a7941 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2548,7 +2548,8 @@ enum btrfs_flush_state {
 	FLUSH_DELALLOC_WAIT	=	6,
 	ALLOC_CHUNK		=	7,
 	ALLOC_CHUNK_FORCE	=	8,
-	COMMIT_TRANS		=	9,
+	RUN_DELAYED_IPUTS	=	9,
+	COMMIT_TRANS		=	10,
 };
 
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,

commit 3e43c279e824889dacd5321505a88506e8c772e3
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:38:06 2019 -0400

    btrfs: migrate the block group cleanup code
    
    This can now be easily migrated as well.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ refresh on top of sysfs cleanups ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e1ad681b9e1a..85b808e3ea42 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2524,7 +2524,6 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_ref *generic_ref);
 
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
-int btrfs_free_block_groups(struct btrfs_fs_info *info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
@@ -2561,7 +2560,6 @@ void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes,
 				    bool qgroup_free);
 
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
-void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
 int btrfs_error_unpin_extent_range(struct btrfs_fs_info *fs_info,
 				   u64 start, u64 end);

commit 878d7b679491665997122d6599001538c639cca9
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:38:05 2019 -0400

    btrfs: migrate the alloc_profile helpers
    
    These feel more at home in block-group.c.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ refresh, adjust btrfs_get_alloc_profile exports ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fe25b7211f2d..e1ad681b9e1a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2527,10 +2527,6 @@ int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
-u64 btrfs_data_alloc_profile(struct btrfs_fs_info *fs_info);
-u64 btrfs_metadata_alloc_profile(struct btrfs_fs_info *fs_info);
-u64 btrfs_system_alloc_profile(struct btrfs_fs_info *fs_info);
-u64 btrfs_get_alloc_profile(struct btrfs_fs_info *fs_info, u64 orig_flags);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
 enum btrfs_reserve_flush_enum {

commit 07730d87ac7872b54efa02da5d20b42fd6bb165a
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:38:04 2019 -0400

    btrfs: migrate the chunk allocation code
    
    This feels more at home in block-group.c than in extent-tree.c.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>i
    [ refresh ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6b17573c2fe6..fe25b7211f2d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2556,28 +2556,6 @@ enum btrfs_flush_state {
 	COMMIT_TRANS		=	9,
 };
 
-/*
- * control flags for do_chunk_alloc's force field
- * CHUNK_ALLOC_NO_FORCE means to only allocate a chunk
- * if we really need one.
- *
- * CHUNK_ALLOC_LIMITED means to only try and allocate one
- * if we have very few chunks already allocated.  This is
- * used as part of the clustering code to help make sure
- * we have a good pool of storage to cluster in, without
- * filling the FS with empty chunks
- *
- * CHUNK_ALLOC_FORCE means it must try to allocate one
- *
- */
-enum btrfs_chunk_alloc_enum {
-	CHUNK_ALLOC_NO_FORCE,
-	CHUNK_ALLOC_LIMITED,
-	CHUNK_ALLOC_FORCE,
-};
-
-int btrfs_chunk_alloc(struct btrfs_trans_handle *trans, u64 flags,
-		      enum btrfs_chunk_alloc_enum force);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
 				     int nitems, bool use_global_rsv);
@@ -2593,7 +2571,6 @@ int btrfs_error_unpin_extent_range(struct btrfs_fs_info *fs_info,
 				   u64 start, u64 end);
 int btrfs_discard_extent(struct btrfs_fs_info *fs_info, u64 bytenr,
 			 u64 num_bytes, u64 *actual_bytes);
-int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans, u64 type);
 int btrfs_trim_fs(struct btrfs_fs_info *fs_info, struct fstrim_range *range);
 
 int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
@@ -2602,7 +2579,6 @@ int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 int btrfs_start_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
-void check_system_chunk(struct btrfs_trans_handle *trans, const u64 type);
 
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, const struct btrfs_key *key,

commit 77745c05115fcf3c2b7deb599799a6b51d1c5155
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:38:00 2019 -0400

    btrfs: migrate the dirty bg writeout code
    
    This can be easily migrated over now.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update comments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f97ad638983b..6b17573c2fe6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2523,9 +2523,6 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_ref *generic_ref);
 
-int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans);
-int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans);
-int btrfs_setup_space_cache(struct btrfs_trans_handle *trans);
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);

commit 26ce2095e03c248759951d81fdff37e2bf32601c
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:59 2019 -0400

    btrfs: migrate inc/dec_block_group_ro code
    
    This can easily be moved now.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ refresh ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 92564b96ad7d..f97ad638983b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2590,8 +2590,6 @@ void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes,
 				    bool qgroup_free);
 
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
-int btrfs_inc_block_group_ro(struct btrfs_block_group_cache *cache);
-void btrfs_dec_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
 int btrfs_error_unpin_extent_range(struct btrfs_fs_info *fs_info,

commit 4358d9635a16a7bc92fecf095fd76d5a3d776188
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:57 2019 -0400

    btrfs: migrate the block group read/creation code
    
    All of the prep work has been done so we can now cleanly move this chunk
    over.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ refresh, add btrfs_get_alloc_profile export, comment updates ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aedee3f66764..92564b96ad7d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2528,16 +2528,12 @@ int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans);
 int btrfs_setup_space_cache(struct btrfs_trans_handle *trans);
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
-int btrfs_read_block_groups(struct btrfs_fs_info *info);
-int btrfs_make_block_group(struct btrfs_trans_handle *trans,
-			   u64 bytes_used, u64 type, u64 chunk_offset,
-			   u64 size);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
-void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans);
 u64 btrfs_data_alloc_profile(struct btrfs_fs_info *fs_info);
 u64 btrfs_metadata_alloc_profile(struct btrfs_fs_info *fs_info);
 u64 btrfs_system_alloc_profile(struct btrfs_fs_info *fs_info);
+u64 btrfs_get_alloc_profile(struct btrfs_fs_info *fs_info, u64 orig_flags);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
 enum btrfs_reserve_flush_enum {

commit e3e0520b32bc3dbc64110536d171bfb334ac7a2a
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:55 2019 -0400

    btrfs: migrate the block group removal code
    
    This is the removal code and the unused bgs code.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ refresh, move clear_incompat_bg_bits ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 17eb4c91f0e1..aedee3f66764 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2532,12 +2532,6 @@ int btrfs_read_block_groups(struct btrfs_fs_info *info);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 bytes_used, u64 type, u64 chunk_offset,
 			   u64 size);
-struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
-				struct btrfs_fs_info *fs_info,
-				const u64 chunk_offset);
-int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
-			     u64 group_start, struct extent_map *em);
-void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans);
@@ -2618,7 +2612,6 @@ int btrfs_start_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans, const u64 type);
-void btrfs_mark_bg_unused(struct btrfs_block_group_cache *bg);
 
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, const struct btrfs_key *key,

commit 9f21246d8c7efb940b96098cb556bfe86205fbed
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Tue Aug 6 16:43:19 2019 +0200

    btrfs: migrate the block group caching code
    
    We can now just copy it over to block-group.c.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fc5031e6fd23..17eb4c91f0e1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2618,8 +2618,6 @@ int btrfs_start_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans, const u64 type);
-u64 add_new_free_space(struct btrfs_block_group_cache *block_group,
-		       u64 start, u64 end);
 void btrfs_mark_bg_unused(struct btrfs_block_group_cache *bg);
 
 /* ctree.c */

commit 67715b206c397b28b8a41c9ddbdc1776a0e7a25f
Author: David Sterba <dsterba@suse.com>
Date:   Thu Aug 1 19:46:20 2019 +0200

    btrfs: cleanup kobject.h includes
    
    The kobject should be pulled in via sysfs.h and that needs to include it
    because it needs various definitions like kobj_attribute or kobject.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c40f28f175c8..fc5031e6fd23 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -16,7 +16,6 @@
 #include <linux/backing-dev.h>
 #include <linux/wait.h>
 #include <linux/slab.h>
-#include <linux/kobject.h>
 #include <trace/events/btrfs.h>
 #include <asm/kmap_types.h>
 #include <asm/unaligned.h>

commit 89439109bc2be5f19c0955d392fb6ea7d0f4ecb3
Author: David Sterba <dsterba@suse.com>
Date:   Thu Aug 1 17:34:41 2019 +0200

    btrfs: move sysfs declarations out of ctree.h
    
    As the header for sysfs code already exists, use it to clean up ctree.h.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b95d7472b2a9..c40f28f175c8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -398,12 +398,6 @@ struct btrfs_dev_replace {
 	wait_queue_head_t replace_wait;
 };
 
-/* For raid type sysfs entries */
-struct raid_kobject {
-	u64 flags;
-	struct kobject kobj;
-};
-
 /*
  * free clusters are used to claim free space in relatively large chunks,
  * allowing us to do less seeky writes. They are used for all metadata
@@ -3096,12 +3090,6 @@ loff_t btrfs_remap_file_range(struct file *file_in, loff_t pos_in,
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root);
 
-/* sysfs.c */
-int __init btrfs_init_sysfs(void);
-void __cold btrfs_exit_sysfs(void);
-int btrfs_sysfs_add_mounted(struct btrfs_fs_info *fs_info);
-void btrfs_sysfs_remove_mounted(struct btrfs_fs_info *fs_info);
-
 /* super.c */
 int btrfs_parse_options(struct btrfs_fs_info *info, char *options,
 			unsigned long new_flags);

commit 6f410d1b3dbf9213ee89c569e8213511319bbd90
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:49 2019 -0400

    btrfs: export the excluded extents helpers
    
    We'll need this to move the caching stuff around.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 04785e912e52..b95d7472b2a9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2473,6 +2473,9 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
+int btrfs_add_excluded_extent(struct btrfs_fs_info *fs_info,
+			      u64 start, u64 num_bytes);
+void btrfs_free_excluded_extents(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   unsigned long count);
 void btrfs_cleanup_ref_head_accounting(struct btrfs_fs_info *fs_info,

commit 3eeb3226a8891544ea4a9baf27ba3d73e8a42991
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:47 2019 -0400

    btrfs: migrate nocow and reservation helpers
    
    These are relatively straightforward as well.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ae8f39c3dcd2..04785e912e52 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2473,12 +2473,6 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
-void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
-					 const u64 start);
-void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);
-bool btrfs_inc_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
-void btrfs_dec_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
-void btrfs_wait_nocow_writers(struct btrfs_block_group_cache *bg);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   unsigned long count);
 void btrfs_cleanup_ref_head_accounting(struct btrfs_fs_info *fs_info,

commit 3cad128400c2445d9140c0f5720018e075ef66c6
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:46 2019 -0400

    btrfs: migrate the block group ref counting stuff
    
    Another easy set to move over to block-group.c.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 49ac72c3d0cd..ae8f39c3dcd2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2479,7 +2479,6 @@ void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);
 bool btrfs_inc_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
 void btrfs_dec_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
 void btrfs_wait_nocow_writers(struct btrfs_block_group_cache *bg);
-void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   unsigned long count);
 void btrfs_cleanup_ref_head_accounting(struct btrfs_fs_info *fs_info,
@@ -2496,8 +2495,6 @@ int btrfs_pin_extent_for_log_replay(struct btrfs_fs_info *fs_info,
 int btrfs_exclude_logged_extents(struct extent_buffer *eb);
 int btrfs_cross_ref_exist(struct btrfs_root *root,
 			  u64 objectid, u64 offset, u64 bytenr);
-void btrfs_get_block_group(struct btrfs_block_group_cache *cache);
-void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 struct extent_buffer *btrfs_alloc_tree_block(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,
 					     u64 parent, u64 root_objectid,

commit 2e405ad842546a1a37aaa586d5140d071cb1f802
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:45 2019 -0400

    btrfs: migrate the block group lookup code
    
    Move these bits first as they are the easiest to move.  Export two of
    the helpers so they can be moved all at once.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor style updates ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e95fdd1d9dd2..49ac72c3d0cd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2496,9 +2496,6 @@ int btrfs_pin_extent_for_log_replay(struct btrfs_fs_info *fs_info,
 int btrfs_exclude_logged_extents(struct extent_buffer *eb);
 int btrfs_cross_ref_exist(struct btrfs_root *root,
 			  u64 objectid, u64 offset, u64 bytenr);
-struct btrfs_block_group_cache *btrfs_lookup_block_group(
-						 struct btrfs_fs_info *info,
-						 u64 bytenr);
 void btrfs_get_block_group(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 struct extent_buffer *btrfs_alloc_tree_block(struct btrfs_trans_handle *trans,

commit aac0023c2106952538414254960c51dcf0dc39e9
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:44 2019 -0400

    btrfs: move basic block_group definitions to their own header
    
    This is prep work for moving all of the block group cache code into its
    own file.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor comment updates ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 88042497dbec..e95fdd1d9dd2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,6 +39,7 @@ struct btrfs_transaction;
 struct btrfs_pending_snapshot;
 struct btrfs_delayed_ref_root;
 struct btrfs_space_info;
+struct btrfs_block_group_cache;
 extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
@@ -439,26 +440,6 @@ enum btrfs_caching_type {
 	BTRFS_CACHE_ERROR,
 };
 
-enum btrfs_disk_cache_state {
-	BTRFS_DC_WRITTEN,
-	BTRFS_DC_ERROR,
-	BTRFS_DC_CLEAR,
-	BTRFS_DC_SETUP,
-};
-
-struct btrfs_caching_control {
-	struct list_head list;
-	struct mutex mutex;
-	wait_queue_head_t wait;
-	struct btrfs_work work;
-	struct btrfs_block_group_cache *block_group;
-	u64 progress;
-	refcount_t count;
-};
-
-/* Once caching_thread() finds this much free space, it will wake up waiters. */
-#define CACHING_CTL_WAKE_UP SZ_2M
-
 struct btrfs_io_ctl {
 	void *cur, *orig;
 	struct page *page;
@@ -481,120 +462,6 @@ struct btrfs_full_stripe_locks_tree {
 	struct mutex lock;
 };
 
-struct btrfs_block_group_cache {
-	struct btrfs_key key;
-	struct btrfs_block_group_item item;
-	struct btrfs_fs_info *fs_info;
-	struct inode *inode;
-	spinlock_t lock;
-	u64 pinned;
-	u64 reserved;
-	u64 delalloc_bytes;
-	u64 bytes_super;
-	u64 flags;
-	u64 cache_generation;
-
-	/*
-	 * If the free space extent count exceeds this number, convert the block
-	 * group to bitmaps.
-	 */
-	u32 bitmap_high_thresh;
-
-	/*
-	 * If the free space extent count drops below this number, convert the
-	 * block group back to extents.
-	 */
-	u32 bitmap_low_thresh;
-
-	/*
-	 * It is just used for the delayed data space allocation because
-	 * only the data space allocation and the relative metadata update
-	 * can be done cross the transaction.
-	 */
-	struct rw_semaphore data_rwsem;
-
-	/* for raid56, this is a full stripe, without parity */
-	unsigned long full_stripe_len;
-
-	unsigned int ro;
-	unsigned int iref:1;
-	unsigned int has_caching_ctl:1;
-	unsigned int removed:1;
-
-	int disk_cache_state;
-
-	/* cache tracking stuff */
-	int cached;
-	struct btrfs_caching_control *caching_ctl;
-	u64 last_byte_to_unpin;
-
-	struct btrfs_space_info *space_info;
-
-	/* free space cache stuff */
-	struct btrfs_free_space_ctl *free_space_ctl;
-
-	/* block group cache stuff */
-	struct rb_node cache_node;
-
-	/* for block groups in the same raid type */
-	struct list_head list;
-
-	/* usage count */
-	atomic_t count;
-
-	/* List of struct btrfs_free_clusters for this block group.
-	 * Today it will only have one thing on it, but that may change
-	 */
-	struct list_head cluster_list;
-
-	/* For delayed block group creation or deletion of empty block groups */
-	struct list_head bg_list;
-
-	/* For read-only block groups */
-	struct list_head ro_list;
-
-	atomic_t trimming;
-
-	/* For dirty block groups */
-	struct list_head dirty_list;
-	struct list_head io_list;
-
-	struct btrfs_io_ctl io_ctl;
-
-	/*
-	 * Incremented when doing extent allocations and holding a read lock
-	 * on the space_info's groups_sem semaphore.
-	 * Decremented when an ordered extent that represents an IO against this
-	 * block group's range is created (after it's added to its inode's
-	 * root's list of ordered extents) or immediately after the allocation
-	 * if it's a metadata extent or fallocate extent (for these cases we
-	 * don't create ordered extents).
-	 */
-	atomic_t reservations;
-
-	/*
-	 * Incremented while holding the spinlock *lock* by a task checking if
-	 * it can perform a nocow write (incremented if the value for the *ro*
-	 * field is 0). Decremented by such tasks once they create an ordered
-	 * extent or before that if some error happens before reaching that step.
-	 * This is to prevent races between block group relocation and nocow
-	 * writes through direct IO.
-	 */
-	atomic_t nocow_writers;
-
-	/* Lock for free space tree operations. */
-	struct mutex free_space_lock;
-
-	/*
-	 * Does the block group need to be added to the free space tree?
-	 * Protected by free_space_lock.
-	 */
-	int needs_free_space;
-
-	/* Record locked full stripes for RAID5/6 block group */
-	struct btrfs_full_stripe_locks_tree full_stripe_locks_root;
-};
-
 /* delayed seq elem */
 struct seq_list {
 	struct list_head list;
@@ -1387,19 +1254,6 @@ static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_fs_info *info)
 	btrfs_clear_opt(fs_info->mount_opt, opt);			\
 }
 
-#ifdef CONFIG_BTRFS_DEBUG
-static inline int
-btrfs_should_fragment_free_space(struct btrfs_block_group_cache *block_group)
-{
-	struct btrfs_fs_info *fs_info = block_group->fs_info;
-
-	return (btrfs_test_opt(fs_info, FRAGMENT_METADATA) &&
-		block_group->flags & BTRFS_BLOCK_GROUP_METADATA) ||
-	       (btrfs_test_opt(fs_info, FRAGMENT_DATA) &&
-		block_group->flags &  BTRFS_BLOCK_GROUP_DATA);
-}
-#endif
-
 /*
  * Requests for changes that need to be done during transaction commit.
  *

commit 82253cb6863ccada8df5a9548b35c5d5a12b90af
Author: David Sterba <dsterba@suse.com>
Date:   Thu Aug 1 19:53:04 2019 +0200

    btrfs: remove unused key type set/get helpers
    
    The switch to open coded set/get has happend long time ago in
    962a298f3511 ("btrfs: kill the key type accessor helpers"), remove the
    stray helpers.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6bb42460d7ff..88042497dbec 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2069,16 +2069,6 @@ static inline void btrfs_dir_item_key_to_cpu(const struct extent_buffer *eb,
 	btrfs_disk_key_to_cpu(key, &disk_key);
 }
 
-static inline u8 btrfs_key_type(const struct btrfs_key *key)
-{
-	return key->type;
-}
-
-static inline void btrfs_set_key_type(struct btrfs_key *key, u8 val)
-{
-	key->type = val;
-}
-
 /* struct btrfs_header */
 BTRFS_SETGET_HEADER_FUNCS(header_bytenr, struct btrfs_header, bytenr, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_generation, struct btrfs_header,

commit 112974d4067ba29ae59f94e0bc79f19bf9db1a53
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Jul 19 14:51:44 2019 +0800

    btrfs: volumes: Remove ENOSPC-prone btrfs_can_relocate()
    
    [BUG]
    Test case btrfs/156 fails since commit 302167c50b32 ("btrfs: don't end
    the transaction for delayed refs in throttle") with ENOSPC.
    
    [CAUSE]
    The ENOSPC is reported from btrfs_can_relocate().
    
    This function will check:
    - If this block group is empty, we can relocate
    - If we can enough free space, we can relocate
    
    Above checks are valid but the following check is vague due to its
    implementation:
    - If and only if we can allocated a new block group to contain all the
      used space, we can relocate
    
    This design itself is OK, but the way to determine if we can allocate a
    new block group is problematic.
    
    btrfs_can_relocate() uses find_free_dev_extent() to find free space on a
    device.
    However find_free_dev_extent() only searches commit root and excludes
    dev extents allocated in current trans, this makes it unable to use dev
    extent just freed in current transaction.
    
    So for the following example, btrfs_can_relocate() will report ENOSPC:
    The example block group layout:
    1M      129M        257M       385M      513M       550M
    |///////|///////////|//////////|         |          |
    // = Used bg, consider all bg is 100% used for easy calculation.
    And all block groups are SINGLE, on-disk bytenr is the same as the
    logical bytenr.
    
    1) Bg in [129M, 257M) get relocated to [385M, 513M), transid=100
    1M      129M        257M       385M      513M       550M
    |///////|           |//////////|/////////|
    In transid 100, bg in [129M, 257M) get relocated to [385M, 513M)
    
    However transid 100 is not committed yet, so in dev commit tree, we
    still have the old dev extents layout:
    1M      129M        257M       385M      513M       550M
    |///////|///////////|//////////|         |          |
    
    2) Try to relocate bg [257M, 385M)
    We goes into btrfs_can_relocate(), no free space in current bgs, so we
    check if we can find large enough free dev extents.
    
    The first slot is [385M, 513M), but that is already used by new bg at
    [385M, 513M), so we continue search.
    
    The remaining slot is [512M, 550M), smaller than the bg's length 128M.
    So btrfs_can_relocate report ENOSPC.
    
    However this is over killed, in fact if we just skip btrfs_can_relocate()
    check, and go into regular relocation routine, at extent reservation time,
    if we can't find free extent, then we fallback to commit transaction,
    which will free up the dev extents and allow new block group to be created.
    
    [FIX]
    The fix here is to remove btrfs_can_relocate() completely.
    
    If we hit the false ENOSPC case just like btrfs/156, extent allocator
    will push harder by committing transaction and we will have space for
    new block group, avoiding the false ENOSPC.
    
    If we really ran out of space, we will hit ENOSPC at
    relocate_block_group(), and btrfs will just reports the ENOSPC error as
    usual.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d2807b99aa97..6bb42460d7ff 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2701,7 +2701,6 @@ int btrfs_setup_space_cache(struct btrfs_trans_handle *trans);
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_fs_info *info);
-int btrfs_can_relocate(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 bytes_used, u64 type, u64 chunk_offset,
 			   u64 size);

commit 330a582790452a159686c5dab8f4286babd9c00e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jul 17 16:18:17 2019 +0300

    btrfs: Remove leftover of in-band dedupe
    
    It's unlikely in-band dedupe is going to land so just remove any
    leftovers - dedupe.h header as well as the 'dedupe' parameter to
    btrfs_set_extent_delalloc.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 670973025048..d2807b99aa97 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3147,7 +3147,7 @@ int btrfs_start_delalloc_snapshot(struct btrfs_root *root);
 int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int nr);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      unsigned int extra_bits,
-			      struct extent_state **cached_state, int dedupe);
+			      struct extent_state **cached_state);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root,
 			     struct btrfs_root *parent_root,

commit 690a5dbfc5131572910e6350d65d7b9d55439817
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Jul 5 11:09:50 2019 +0100

    Btrfs: fix ENOSPC errors, leading to transaction aborts, when cloning extents
    
    When cloning extents (or deduplicating) we create a transaction with a
    space reservation that considers we will drop or update a single file
    extent item of the destination inode (that we modify a single leaf). That
    is fine for the vast majority of scenarios, however it might happen that
    we need to drop many file extent items, and adjust at most two file extent
    items, in the destination root, which can span multiple leafs. This will
    lead to either the call to btrfs_drop_extents() to fail with ENOSPC or
    the subsequent calls to btrfs_insert_empty_item() or btrfs_update_inode()
    (called through clone_finish_inode_update()) to fail with ENOSPC. Such
    failure results in a transaction abort, leaving the filesystem in a
    read-only mode.
    
    In order to fix this we need to follow the same approach as the hole
    punching code, where we create a local reservation with 1 unit and keep
    ending and starting transactions, after balancing the btree inode,
    when __btrfs_drop_extents() returns ENOSPC. So fix this by making the
    extent cloning call calls the recently added btrfs_punch_hole_range()
    helper, which is what does the mentioned work for hole punching, and
    make sure whenever we drop extent items in a transaction, we also add a
    replacing file extent item, to avoid corruption (a hole) if after ending
    a transaction and before starting a new one, the old transaction gets
    committed and a power failure happens before we finish cloning.
    
    A test case for fstests follows soon.
    
    Reported-by: David Goodwin <david@codepoets.co.uk>
    Link: https://lore.kernel.org/linux-btrfs/a4a4cf31-9cf4-e52c-1f86-c62d336c9cd1@codepoets.co.uk/
    Reported-by: Sam Tygier <sam@tygier.co.uk>
    Link: https://lore.kernel.org/linux-btrfs/82aace9f-a1e3-1f0b-055f-3ea75f7a41a0@tygier.co.uk/
    Fixes: b6f3409b2197e8f ("Btrfs: reserve sufficient space for ioctl clone")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 94660063a162..670973025048 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1279,6 +1279,16 @@ struct btrfs_root {
 #endif
 };
 
+struct btrfs_clone_extent_info {
+	u64 disk_offset;
+	u64 disk_len;
+	u64 data_offset;
+	u64 data_len;
+	u64 file_offset;
+	char *extent_buf;
+	u32 item_size;
+};
+
 struct btrfs_file_private {
 	void *filldir_buf;
 };
@@ -3233,6 +3243,10 @@ int __btrfs_drop_extents(struct btrfs_trans_handle *trans,
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode, u64 start,
 		       u64 end, int drop_cache);
+int btrfs_punch_hole_range(struct inode *inode, struct btrfs_path *path,
+			   const u64 start, const u64 end,
+			   struct btrfs_clone_extent_info *clone_info,
+			   struct btrfs_trans_handle **trans_out);
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct btrfs_inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);

commit d7cd4dd907c19c0295829c947d79afa290b6fc24
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Aug 7 11:21:46 2019 +0100

    Btrfs: fix sysfs warning and missing raid sysfs directories
    
    In the 5.3 merge window, commit 7c7e301406d0a9 ("btrfs: sysfs: Replace
    default_attrs in ktypes with groups"), we started using the member
    "defaults_groups" for the kobject type "btrfs_raid_ktype". That leads
    to a series of warnings when running some test cases of fstests, such
    as btrfs/027, btrfs/124 and btrfs/176. The traces produced by those
    warnings are like the following:
    
      [116648.059212] kernfs: can not remove 'total_bytes', no directory
      [116648.060112] WARNING: CPU: 3 PID: 28500 at fs/kernfs/dir.c:1504 kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.066482] CPU: 3 PID: 28500 Comm: umount Tainted: G        W         5.3.0-rc3-btrfs-next-54 #1
      (...)
      [116648.069376] RIP: 0010:kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.072385] RSP: 0018:ffffabfd0090bd08 EFLAGS: 00010282
      [116648.073437] RAX: 0000000000000000 RBX: ffffffffc0c11998 RCX: 0000000000000000
      [116648.074201] RDX: ffff9fff603a7a00 RSI: ffff9fff603978a8 RDI: ffff9fff603978a8
      [116648.074956] RBP: ffffffffc0b9ca2f R08: 0000000000000000 R09: 0000000000000001
      [116648.075708] R10: ffff9ffe1f72e1c0 R11: 0000000000000000 R12: ffffffffc0b94120
      [116648.076434] R13: ffffffffb3d9b4e0 R14: 0000000000000000 R15: dead000000000100
      [116648.077143] FS:  00007f9cdc78a2c0(0000) GS:ffff9fff60380000(0000) knlGS:0000000000000000
      [116648.077852] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [116648.078546] CR2: 00007f9fc4747ab4 CR3: 00000005c7832003 CR4: 00000000003606e0
      [116648.079235] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [116648.079907] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [116648.080585] Call Trace:
      [116648.081262]  remove_files+0x31/0x70
      [116648.081929]  sysfs_remove_group+0x38/0x80
      [116648.082596]  sysfs_remove_groups+0x34/0x70
      [116648.083258]  kobject_del+0x20/0x60
      [116648.083933]  btrfs_free_block_groups+0x405/0x430 [btrfs]
      [116648.084608]  close_ctree+0x19a/0x380 [btrfs]
      [116648.085278]  generic_shutdown_super+0x6c/0x110
      [116648.085951]  kill_anon_super+0xe/0x30
      [116648.086621]  btrfs_kill_super+0x12/0xa0 [btrfs]
      [116648.087289]  deactivate_locked_super+0x3a/0x70
      [116648.087956]  cleanup_mnt+0xb4/0x160
      [116648.088620]  task_work_run+0x7e/0xc0
      [116648.089285]  exit_to_usermode_loop+0xfa/0x100
      [116648.089933]  do_syscall_64+0x1cb/0x220
      [116648.090567]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [116648.091197] RIP: 0033:0x7f9cdc073b37
      (...)
      [116648.100046] ---[ end trace 22e24db328ccadf8 ]---
      [116648.100618] ------------[ cut here ]------------
      [116648.101175] kernfs: can not remove 'used_bytes', no directory
      [116648.101731] WARNING: CPU: 3 PID: 28500 at fs/kernfs/dir.c:1504 kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.105649] CPU: 3 PID: 28500 Comm: umount Tainted: G        W         5.3.0-rc3-btrfs-next-54 #1
      (...)
      [116648.107461] RIP: 0010:kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.109336] RSP: 0018:ffffabfd0090bd08 EFLAGS: 00010282
      [116648.109979] RAX: 0000000000000000 RBX: ffffffffc0c119a0 RCX: 0000000000000000
      [116648.110625] RDX: ffff9fff603a7a00 RSI: ffff9fff603978a8 RDI: ffff9fff603978a8
      [116648.111283] RBP: ffffffffc0b9ca41 R08: 0000000000000000 R09: 0000000000000001
      [116648.111940] R10: ffff9ffe1f72e1c0 R11: 0000000000000000 R12: ffffffffc0b94120
      [116648.112603] R13: ffffffffb3d9b4e0 R14: 0000000000000000 R15: dead000000000100
      [116648.113268] FS:  00007f9cdc78a2c0(0000) GS:ffff9fff60380000(0000) knlGS:0000000000000000
      [116648.113939] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [116648.114607] CR2: 00007f9fc4747ab4 CR3: 00000005c7832003 CR4: 00000000003606e0
      [116648.115286] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [116648.115966] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [116648.116649] Call Trace:
      [116648.117326]  remove_files+0x31/0x70
      [116648.117997]  sysfs_remove_group+0x38/0x80
      [116648.118671]  sysfs_remove_groups+0x34/0x70
      [116648.119342]  kobject_del+0x20/0x60
      [116648.120022]  btrfs_free_block_groups+0x405/0x430 [btrfs]
      [116648.120707]  close_ctree+0x19a/0x380 [btrfs]
      [116648.121396]  generic_shutdown_super+0x6c/0x110
      [116648.122057]  kill_anon_super+0xe/0x30
      [116648.122702]  btrfs_kill_super+0x12/0xa0 [btrfs]
      [116648.123335]  deactivate_locked_super+0x3a/0x70
      [116648.123961]  cleanup_mnt+0xb4/0x160
      [116648.124586]  task_work_run+0x7e/0xc0
      [116648.125210]  exit_to_usermode_loop+0xfa/0x100
      [116648.125830]  do_syscall_64+0x1cb/0x220
      [116648.126463]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [116648.127080] RIP: 0033:0x7f9cdc073b37
      (...)
      [116648.135923] ---[ end trace 22e24db328ccadf9 ]---
    
    These happen because, during the unmount path, we call kobject_del() for
    raid kobjects that are not fully initialized, meaning that we set their
    ktype (as btrfs_raid_ktype) through link_block_group() but we didn't set
    their parent kobject, which is done through btrfs_add_raid_kobjects().
    
    We have this split raid kobject setup since commit 75cb379d263521
    ("btrfs: defer adding raid type kobject until after chunk relocation") in
    order to avoid triggering reclaim during contextes where we can not
    (either we are holding a transaction handle or some lock required by
    the transaction commit path), so that we do the calls to kobject_add(),
    which triggers GFP_KERNEL allocations, through btrfs_add_raid_kobjects()
    in contextes where it is safe to trigger reclaim. That change expected
    that a new raid kobject can only be created either when mounting the
    filesystem or after raid profile conversion through the relocation path.
    However, we can have new raid kobject created in other two cases at least:
    
    1) During device replace (or scrub) after adding a device a to the
       filesystem. The replace procedure (and scrub) do calls to
       btrfs_inc_block_group_ro() which can allocate a new block group
       with a new raid profile (because we now have more devices). This
       can be triggered by test cases btrfs/027 and btrfs/176.
    
    2) During a degraded mount trough any write path. This can be triggered
       by test case btrfs/124.
    
    Fixing this by adding extra calls to btrfs_add_raid_kobjects(), not only
    makes things more complex and fragile, can also introduce deadlocks with
    reclaim the following way:
    
    1) Calling btrfs_add_raid_kobjects() at btrfs_inc_block_group_ro() or
       anywhere in the replace/scrub path will cause a deadlock with reclaim
       because if reclaim happens and a transaction commit is triggered,
       the transaction commit path will block at btrfs_scrub_pause().
    
    2) During degraded mounts it is essentially impossible to figure out where
       to add extra calls to btrfs_add_raid_kobjects(), because allocation of
       a block group with a new raid profile can happen anywhere, which means
       we can't safely figure out which contextes are safe for reclaim, as
       we can either hold a transaction handle or some lock needed by the
       transaction commit path.
    
    So it is too complex and error prone to have this split setup of raid
    kobjects. So fix the issue by consolidating the setup of the kobjects in a
    single place, at link_block_group(), and setup a nofs context there in
    order to prevent reclaim being triggered by the memory allocations done
    through the call chain of kobject_add().
    
    Besides fixing the sysfs warnings during kobject_del(), this also ensures
    the sysfs directories for the new raid profiles end up created and visible
    to users (a bug that existed before the 5.3 commit 7c7e301406d0a9
    ("btrfs: sysfs: Replace default_attrs in ktypes with groups")).
    
    Fixes: 75cb379d263521 ("btrfs: defer adding raid type kobject until after chunk relocation")
    Fixes: 7c7e301406d0a9 ("btrfs: sysfs: Replace default_attrs in ktypes with groups")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 299e11e6c554..94660063a162 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -401,7 +401,6 @@ struct btrfs_dev_replace {
 struct raid_kobject {
 	u64 flags;
 	struct kobject kobj;
-	struct list_head list;
 };
 
 /*
@@ -915,8 +914,6 @@ struct btrfs_fs_info {
 	u32 thread_pool_size;
 
 	struct kobject *space_info_kobj;
-	struct list_head pending_raid_kobjs;
-	spinlock_t pending_raid_kobjs_lock; /* uncontended */
 
 	u64 total_pinned;
 
@@ -2698,7 +2695,6 @@ int btrfs_can_relocate(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 bytes_used, u64 type, u64 chunk_offset,
 			   u64 size);
-void btrfs_add_raid_kobjects(struct btrfs_fs_info *fs_info);
 struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
 				struct btrfs_fs_info *fs_info,
 				const u64 chunk_offset);

commit 867363429d706984915cb4b1f299ce05f8413e23
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Jun 19 15:12:00 2019 -0400

    btrfs: migrate the delalloc space stuff to it's own home
    
    We have code for data and metadata reservations for delalloc.  There's
    quite a bit of code here, and it's used in a lot of places so I've
    separated it out to it's own file.  inode.c and file.c are already
    pretty large, and this code is complicated enough to live in its own
    space.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 56e6746010fc..299e11e6c554 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2758,16 +2758,6 @@ enum btrfs_chunk_alloc_enum {
 
 int btrfs_chunk_alloc(struct btrfs_trans_handle *trans, u64 flags,
 		      enum btrfs_chunk_alloc_enum force);
-int btrfs_alloc_data_chunk_ondemand(struct btrfs_inode *inode, u64 bytes);
-int btrfs_check_data_free_space(struct inode *inode,
-			struct extent_changeset **reserved, u64 start, u64 len);
-void btrfs_free_reserved_data_space(struct inode *inode,
-			struct extent_changeset *reserved, u64 start, u64 len);
-void btrfs_delalloc_release_space(struct inode *inode,
-				  struct extent_changeset *reserved,
-				  u64 start, u64 len, bool qgroup_free);
-void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
-					    u64 len);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
 				     int nitems, bool use_global_rsv);
@@ -2777,10 +2767,6 @@ void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes,
 				    bool qgroup_free);
 
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
-void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes,
-				     bool qgroup_free);
-int btrfs_delalloc_reserve_space(struct inode *inode,
-			struct extent_changeset **reserved, u64 start, u64 len);
 int btrfs_inc_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_dec_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);

commit fb6dea26601b60e41d70c310537dd1e2617b25b6
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Jun 19 15:11:59 2019 -0400

    btrfs: migrate btrfs_trans_release_chunk_metadata
    
    Move this into transaction.c with the rest of the transaction related
    code.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 45d6fc7ed21f..56e6746010fc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2768,7 +2768,6 @@ void btrfs_delalloc_release_space(struct inode *inode,
 				  u64 start, u64 len, bool qgroup_free);
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);
-void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
 				     int nitems, bool use_global_rsv);

commit 6ef03debdb3d82d7deec65f96e143b9adcfb2cd4
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Jun 19 15:11:58 2019 -0400

    btrfs: migrate the delayed refs rsv code
    
    These belong with the delayed refs related code, not in extent-tree.c.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index adb6d2747e0c..45d6fc7ed21f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2622,8 +2622,6 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
-int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans);
-bool btrfs_check_space_for_delayed_refs(struct btrfs_fs_info *fs_info);
 void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
 					 const u64 start);
 void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);
@@ -2784,13 +2782,6 @@ void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes,
 				     bool qgroup_free);
 int btrfs_delalloc_reserve_space(struct inode *inode,
 			struct extent_changeset **reserved, u64 start, u64 len);
-void btrfs_delayed_refs_rsv_release(struct btrfs_fs_info *fs_info, int nr);
-void btrfs_update_delayed_refs_rsv(struct btrfs_trans_handle *trans);
-int btrfs_delayed_refs_rsv_refill(struct btrfs_fs_info *fs_info,
-				  enum btrfs_reserve_flush_enum flush);
-void btrfs_migrate_to_delayed_refs_rsv(struct btrfs_fs_info *fs_info,
-				       struct btrfs_block_rsv *src,
-				       u64 num_bytes);
 int btrfs_inc_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_dec_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);

commit d12ffdd1aa4c165774748265c67af3aa1edab1a0
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Jun 19 13:47:17 2019 -0400

    btrfs: move btrfs_block_rsv definitions into it's own header
    
    Prep work for separating out all of the block_rsv related code into its
    own file.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b78470fdc226..adb6d2747e0c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -32,6 +32,7 @@
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
+#include "block-rsv.h"
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
@@ -403,49 +404,6 @@ struct raid_kobject {
 	struct list_head list;
 };
 
-/*
- * Types of block reserves
- */
-enum {
-	BTRFS_BLOCK_RSV_GLOBAL,
-	BTRFS_BLOCK_RSV_DELALLOC,
-	BTRFS_BLOCK_RSV_TRANS,
-	BTRFS_BLOCK_RSV_CHUNK,
-	BTRFS_BLOCK_RSV_DELOPS,
-	BTRFS_BLOCK_RSV_DELREFS,
-	BTRFS_BLOCK_RSV_EMPTY,
-	BTRFS_BLOCK_RSV_TEMP,
-};
-
-struct btrfs_block_rsv {
-	u64 size;
-	u64 reserved;
-	struct btrfs_space_info *space_info;
-	spinlock_t lock;
-	unsigned short full;
-	unsigned short type;
-	unsigned short failfast;
-
-	/*
-	 * Qgroup equivalent for @size @reserved
-	 *
-	 * Unlike normal @size/@reserved for inode rsv, qgroup doesn't care
-	 * about things like csum size nor how many tree blocks it will need to
-	 * reserve.
-	 *
-	 * Qgroup cares more about net change of the extent usage.
-	 *
-	 * So for one newly inserted file extent, in worst case it will cause
-	 * leaf split and level increase, nodesize for each file extent is
-	 * already too much.
-	 *
-	 * In short, qgroup_size/reserved is the upper limit of possible needed
-	 * qgroup metadata reservation.
-	 */
-	u64 qgroup_rsv_size;
-	u64 qgroup_rsv_reserved;
-};
-
 /*
  * free clusters are used to claim free space in relatively large chunks,
  * allowing us to do less seeky writes. They are used for all metadata
@@ -2826,31 +2784,6 @@ void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes,
 				     bool qgroup_free);
 int btrfs_delalloc_reserve_space(struct inode *inode,
 			struct extent_changeset **reserved, u64 start, u64 len);
-void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
-struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_fs_info *fs_info,
-					      unsigned short type);
-void btrfs_init_metadata_block_rsv(struct btrfs_fs_info *fs_info,
-				   struct btrfs_block_rsv *rsv,
-				   unsigned short type);
-void btrfs_free_block_rsv(struct btrfs_fs_info *fs_info,
-			  struct btrfs_block_rsv *rsv);
-int btrfs_block_rsv_add(struct btrfs_root *root,
-			struct btrfs_block_rsv *block_rsv, u64 num_bytes,
-			enum btrfs_reserve_flush_enum flush);
-int btrfs_block_rsv_check(struct btrfs_block_rsv *block_rsv, int min_factor);
-int btrfs_block_rsv_refill(struct btrfs_root *root,
-			   struct btrfs_block_rsv *block_rsv, u64 min_reserved,
-			   enum btrfs_reserve_flush_enum flush);
-int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
-			    struct btrfs_block_rsv *dst_rsv, u64 num_bytes,
-			    bool update_size);
-int btrfs_block_rsv_use_bytes(struct btrfs_block_rsv *block_rsv, u64 num_bytes);
-int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
-			     struct btrfs_block_rsv *dest, u64 num_bytes,
-			     int min_factor);
-void btrfs_block_rsv_release(struct btrfs_fs_info *fs_info,
-			     struct btrfs_block_rsv *block_rsv,
-			     u64 num_bytes);
 void btrfs_delayed_refs_rsv_release(struct btrfs_fs_info *fs_info, int nr);
 void btrfs_update_delayed_refs_rsv(struct btrfs_trans_handle *trans);
 int btrfs_delayed_refs_rsv_refill(struct btrfs_fs_info *fs_info,

commit c2a67a76ec87579a46a16c49fc9997737b7fa844
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Tue Jun 18 16:09:23 2019 -0400

    btrfs: export block_rsv_use_bytes
    
    We are going to need this to move the metadata reservation stuff to
    space_info.c.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8fca40370cf1..b78470fdc226 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2844,6 +2844,7 @@ int btrfs_block_rsv_refill(struct btrfs_root *root,
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 			    struct btrfs_block_rsv *dst_rsv, u64 num_bytes,
 			    bool update_size);
+int btrfs_block_rsv_use_bytes(struct btrfs_block_rsv *block_rsv, u64 num_bytes);
 int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *dest, u64 num_bytes,
 			     int min_factor);

commit fc471cb0c8f0016ac7ec5cc3e329c5e23d83d593
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Tue Jun 18 16:09:17 2019 -0400

    btrfs: rename do_chunk_alloc to btrfs_chunk_alloc
    
    Really we just need the enum, but as we break more things up it'll help
    to have this external to extent-tree.c.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1d6a60f437a6..8fca40370cf1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2780,6 +2780,28 @@ enum btrfs_flush_state {
 	COMMIT_TRANS		=	9,
 };
 
+/*
+ * control flags for do_chunk_alloc's force field
+ * CHUNK_ALLOC_NO_FORCE means to only allocate a chunk
+ * if we really need one.
+ *
+ * CHUNK_ALLOC_LIMITED means to only try and allocate one
+ * if we have very few chunks already allocated.  This is
+ * used as part of the clustering code to help make sure
+ * we have a good pool of storage to cluster in, without
+ * filling the FS with empty chunks
+ *
+ * CHUNK_ALLOC_FORCE means it must try to allocate one
+ *
+ */
+enum btrfs_chunk_alloc_enum {
+	CHUNK_ALLOC_NO_FORCE,
+	CHUNK_ALLOC_LIMITED,
+	CHUNK_ALLOC_FORCE,
+};
+
+int btrfs_chunk_alloc(struct btrfs_trans_handle *trans, u64 flags,
+		      enum btrfs_chunk_alloc_enum force);
 int btrfs_alloc_data_chunk_ondemand(struct btrfs_inode *inode, u64 bytes);
 int btrfs_check_data_free_space(struct inode *inode,
 			struct extent_changeset **reserved, u64 start, u64 len);

commit 8719aaae8d696bf0c73f74e6d6cc75451b50d5df
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Tue Jun 18 16:09:16 2019 -0400

    btrfs: move space_info to space-info.h
    
    Migrate the struct definition and the one helper that's in ctree.h into
    space-info.h
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5e89e4d5b065..1d6a60f437a6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -37,6 +37,7 @@ struct btrfs_trans_handle;
 struct btrfs_transaction;
 struct btrfs_pending_snapshot;
 struct btrfs_delayed_ref_root;
+struct btrfs_space_info;
 extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
@@ -402,72 +403,6 @@ struct raid_kobject {
 	struct list_head list;
 };
 
-struct btrfs_space_info {
-	spinlock_t lock;
-
-	u64 total_bytes;	/* total bytes in the space,
-				   this doesn't take mirrors into account */
-	u64 bytes_used;		/* total bytes used,
-				   this doesn't take mirrors into account */
-	u64 bytes_pinned;	/* total bytes pinned, will be freed when the
-				   transaction finishes */
-	u64 bytes_reserved;	/* total bytes the allocator has reserved for
-				   current allocations */
-	u64 bytes_may_use;	/* number of bytes that may be used for
-				   delalloc/allocations */
-	u64 bytes_readonly;	/* total bytes that are read only */
-
-	u64 max_extent_size;	/* This will hold the maximum extent size of
-				   the space info if we had an ENOSPC in the
-				   allocator. */
-
-	unsigned int full:1;	/* indicates that we cannot allocate any more
-				   chunks for this space */
-	unsigned int chunk_alloc:1;	/* set if we are allocating a chunk */
-
-	unsigned int flush:1;		/* set if we are trying to make space */
-
-	unsigned int force_alloc;	/* set if we need to force a chunk
-					   alloc for this space */
-
-	u64 disk_used;		/* total bytes used on disk */
-	u64 disk_total;		/* total bytes on disk, takes mirrors into
-				   account */
-
-	u64 flags;
-
-	/*
-	 * bytes_pinned is kept in line with what is actually pinned, as in
-	 * we've called update_block_group and dropped the bytes_used counter
-	 * and increased the bytes_pinned counter.  However this means that
-	 * bytes_pinned does not reflect the bytes that will be pinned once the
-	 * delayed refs are flushed, so this counter is inc'ed every time we
-	 * call btrfs_free_extent so it is a realtime count of what will be
-	 * freed once the transaction is committed.  It will be zeroed every
-	 * time the transaction commits.
-	 */
-	struct percpu_counter total_bytes_pinned;
-
-	struct list_head list;
-	/* Protected by the spinlock 'lock'. */
-	struct list_head ro_bgs;
-	struct list_head priority_tickets;
-	struct list_head tickets;
-	/*
-	 * tickets_id just indicates the next ticket will be handled, so note
-	 * it's not stored per ticket.
-	 */
-	u64 tickets_id;
-
-	struct rw_semaphore groups_sem;
-	/* for block groups in our same type */
-	struct list_head block_groups[BTRFS_NR_RAID_TYPES];
-	wait_queue_head_t wait;
-
-	struct kobject kobj;
-	struct kobject *block_group_kobjs[BTRFS_NR_RAID_TYPES];
-};
-
 /*
  * Types of block reserves
  */
@@ -2693,12 +2628,6 @@ static inline u64 btrfs_extref_hash(u64 parent_objectid, const char *name,
        return (u64) crc32c(parent_objectid, name, len);
 }
 
-static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
-{
-	return ((space_info->flags & BTRFS_BLOCK_GROUP_METADATA) &&
-		(space_info->flags & BTRFS_BLOCK_GROUP_DATA));
-}
-
 static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 {
 	return mapping_gfp_constraint(mapping, ~__GFP_FS);

commit c9d713d5b5e8c1fb97af8fa3e267300fe25b8921
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 13 17:55:03 2019 +0200

    btrfs: improve messages when updating feature flags
    
    Currently the messages printed after setting an incompat feature are
    cryptis, we can easily make it better as the textual description is
    passed to the helpers. Old:
    
      setting 128 feature flag
    
    updated:
    
      setting incompat feature flag for RAID56 (0x80)
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 02a29516dacf..5e89e4d5b065 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3636,10 +3636,11 @@ do {									\
 /* compatibility and incompatibility defines */
 
 #define btrfs_set_fs_incompat(__fs_info, opt) \
-	__btrfs_set_fs_incompat((__fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
+	__btrfs_set_fs_incompat((__fs_info), BTRFS_FEATURE_INCOMPAT_##opt, \
+				#opt)
 
 static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
-					   u64 flag)
+					   u64 flag, const char* name)
 {
 	struct btrfs_super_block *disk_super;
 	u64 features;
@@ -3652,18 +3653,20 @@ static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
 		if (!(features & flag)) {
 			features |= flag;
 			btrfs_set_super_incompat_flags(disk_super, features);
-			btrfs_info(fs_info, "setting %llu feature flag",
-					 flag);
+			btrfs_info(fs_info,
+				"setting incompat feature flag for %s (0x%llx)",
+				name, flag);
 		}
 		spin_unlock(&fs_info->super_lock);
 	}
 }
 
 #define btrfs_clear_fs_incompat(__fs_info, opt) \
-	__btrfs_clear_fs_incompat((__fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
+	__btrfs_clear_fs_incompat((__fs_info), BTRFS_FEATURE_INCOMPAT_##opt, \
+				  #opt)
 
 static inline void __btrfs_clear_fs_incompat(struct btrfs_fs_info *fs_info,
-					     u64 flag)
+					     u64 flag, const char* name)
 {
 	struct btrfs_super_block *disk_super;
 	u64 features;
@@ -3676,8 +3679,9 @@ static inline void __btrfs_clear_fs_incompat(struct btrfs_fs_info *fs_info,
 		if (features & flag) {
 			features &= ~flag;
 			btrfs_set_super_incompat_flags(disk_super, features);
-			btrfs_info(fs_info, "clearing %llu feature flag",
-					 flag);
+			btrfs_info(fs_info,
+				"clearing incompat feature flag for %s (0x%llx)",
+				name, flag);
 		}
 		spin_unlock(&fs_info->super_lock);
 	}
@@ -3694,10 +3698,11 @@ static inline bool __btrfs_fs_incompat(struct btrfs_fs_info *fs_info, u64 flag)
 }
 
 #define btrfs_set_fs_compat_ro(__fs_info, opt) \
-	__btrfs_set_fs_compat_ro((__fs_info), BTRFS_FEATURE_COMPAT_RO_##opt)
+	__btrfs_set_fs_compat_ro((__fs_info), BTRFS_FEATURE_COMPAT_RO_##opt, \
+				 #opt)
 
 static inline void __btrfs_set_fs_compat_ro(struct btrfs_fs_info *fs_info,
-					    u64 flag)
+					    u64 flag, const char *name)
 {
 	struct btrfs_super_block *disk_super;
 	u64 features;
@@ -3710,18 +3715,20 @@ static inline void __btrfs_set_fs_compat_ro(struct btrfs_fs_info *fs_info,
 		if (!(features & flag)) {
 			features |= flag;
 			btrfs_set_super_compat_ro_flags(disk_super, features);
-			btrfs_info(fs_info, "setting %llu ro feature flag",
-				   flag);
+			btrfs_info(fs_info,
+				"setting compat-ro feature flag for %s (0x%llx)",
+				name, flag);
 		}
 		spin_unlock(&fs_info->super_lock);
 	}
 }
 
 #define btrfs_clear_fs_compat_ro(__fs_info, opt) \
-	__btrfs_clear_fs_compat_ro((__fs_info), BTRFS_FEATURE_COMPAT_RO_##opt)
+	__btrfs_clear_fs_compat_ro((__fs_info), BTRFS_FEATURE_COMPAT_RO_##opt, \
+				   #opt)
 
 static inline void __btrfs_clear_fs_compat_ro(struct btrfs_fs_info *fs_info,
-					      u64 flag)
+					      u64 flag, const char *name)
 {
 	struct btrfs_super_block *disk_super;
 	u64 features;
@@ -3734,8 +3741,9 @@ static inline void __btrfs_clear_fs_compat_ro(struct btrfs_fs_info *fs_info,
 		if (features & flag) {
 			features &= ~flag;
 			btrfs_set_super_compat_ro_flags(disk_super, features);
-			btrfs_info(fs_info, "clearing %llu ro feature flag",
-				   flag);
+			btrfs_info(fs_info,
+				"clearing compat-ro feature flag for %s (0x%llx)",
+				name, flag);
 		}
 		spin_unlock(&fs_info->super_lock);
 	}

commit 9e967495e0e0ae8bb08f52aa71b29affc7075d31
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 22 16:44:09 2019 +0100

    Btrfs: prevent send failures and crashes due to concurrent relocation
    
    Send always operates on read-only trees and always expected that while it
    is in progress, nothing changes in those trees. Due to that expectation
    and the fact that send is a read-only operation, it operates on commit
    roots and does not hold transaction handles. However relocation can COW
    nodes and leafs from read-only trees, which can cause unexpected failures
    and crashes (hitting BUG_ONs). while send using a node/leaf, it gets
    COWed, the transaction used to COW it is committed, a new transaction
    starts, the extent previously used for that node/leaf gets allocated,
    possibly for another tree, and the respective extent buffer' content
    changes while send is still using it. When this happens send normally
    fails with EIO being returned to user space and messages like the
    following are found in dmesg/syslog:
    
      [ 3408.699121] BTRFS error (device sdc): parent transid verify failed on 58703872 wanted 250 found 253
      [ 3441.523123] BTRFS error (device sdc): did not find backref in send_root. inode=63211, offset=0, disk_byte=5222825984 found extent=5222825984
    
    Other times, less often, we hit a BUG_ON() because an extent buffer that
    send is using used to be a node, and while send is still using it, it
    got COWed and got reused as a leaf while send is still using, producing
    the following trace:
    
     [ 3478.466280] ------------[ cut here ]------------
     [ 3478.466282] kernel BUG at fs/btrfs/ctree.c:1806!
     [ 3478.466965] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
     [ 3478.467635] CPU: 0 PID: 2165 Comm: btrfs Not tainted 5.0.0-btrfs-next-46 #1
     [ 3478.468311] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626ccb91-prebuilt.qemu-project.org 04/01/2014
     [ 3478.469681] RIP: 0010:read_node_slot+0x122/0x130 [btrfs]
     (...)
     [ 3478.471758] RSP: 0018:ffffa437826bfaa0 EFLAGS: 00010246
     [ 3478.472457] RAX: ffff961416ed7000 RBX: 000000000000003d RCX: 0000000000000002
     [ 3478.473151] RDX: 000000000000003d RSI: ffff96141e387408 RDI: ffff961599b30000
     [ 3478.473837] RBP: ffffa437826bfb8e R08: 0000000000000001 R09: ffffa437826bfb8e
     [ 3478.474515] R10: ffffa437826bfa70 R11: 0000000000000000 R12: ffff9614385c8708
     [ 3478.475186] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     [ 3478.475840] FS:  00007f8e0e9cc8c0(0000) GS:ffff9615b6a00000(0000) knlGS:0000000000000000
     [ 3478.476489] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     [ 3478.477127] CR2: 00007f98b67a056e CR3: 0000000005df6005 CR4: 00000000003606f0
     [ 3478.477762] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     [ 3478.478385] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     [ 3478.479003] Call Trace:
     [ 3478.479600]  ? do_raw_spin_unlock+0x49/0xc0
     [ 3478.480202]  tree_advance+0x173/0x1d0 [btrfs]
     [ 3478.480810]  btrfs_compare_trees+0x30c/0x690 [btrfs]
     [ 3478.481388]  ? process_extent+0x1280/0x1280 [btrfs]
     [ 3478.481954]  btrfs_ioctl_send+0x1037/0x1270 [btrfs]
     [ 3478.482510]  _btrfs_ioctl_send+0x80/0x110 [btrfs]
     [ 3478.483062]  btrfs_ioctl+0x13fe/0x3120 [btrfs]
     [ 3478.483581]  ? rq_clock_task+0x2e/0x60
     [ 3478.484086]  ? wake_up_new_task+0x1f3/0x370
     [ 3478.484582]  ? do_vfs_ioctl+0xa2/0x6f0
     [ 3478.485075]  ? btrfs_ioctl_get_supported_features+0x30/0x30 [btrfs]
     [ 3478.485552]  do_vfs_ioctl+0xa2/0x6f0
     [ 3478.486016]  ? __fget+0x113/0x200
     [ 3478.486467]  ksys_ioctl+0x70/0x80
     [ 3478.486911]  __x64_sys_ioctl+0x16/0x20
     [ 3478.487337]  do_syscall_64+0x60/0x1b0
     [ 3478.487751]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
     [ 3478.488159] RIP: 0033:0x7f8e0d7d4dd7
     (...)
     [ 3478.489349] RSP: 002b:00007ffcf6fb4908 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
     [ 3478.489742] RAX: ffffffffffffffda RBX: 0000000000000105 RCX: 00007f8e0d7d4dd7
     [ 3478.490142] RDX: 00007ffcf6fb4990 RSI: 0000000040489426 RDI: 0000000000000005
     [ 3478.490548] RBP: 0000000000000005 R08: 00007f8e0d6f3700 R09: 00007f8e0d6f3700
     [ 3478.490953] R10: 00007f8e0d6f39d0 R11: 0000000000000202 R12: 0000000000000005
     [ 3478.491343] R13: 00005624e0780020 R14: 0000000000000000 R15: 0000000000000001
     (...)
     [ 3478.493352] ---[ end trace d5f537302be4f8c8 ]---
    
    Another possibility, much less likely to happen, is that send will not
    fail but the contents of the stream it produces may not be correct.
    
    To avoid this, do not allow send and relocation (balance) to run in
    parallel. In the long term the goal is to allow for both to be able to
    run concurrently without any problems, but that will take a significant
    effort in development and testing.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 31198499f175..02a29516dacf 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -793,6 +793,7 @@ enum {
 	/*
 	 * Indicate that balance has been set up from the ioctl and is in the
 	 * main phase. The fs_info::balance_ctl is initialized.
+	 * Set and cleared while holding fs_info::balance_mutex.
 	 */
 	BTRFS_FS_BALANCE_RUNNING,
 
@@ -1175,6 +1176,12 @@ struct btrfs_fs_info {
 
 	struct crypto_shash *csum_shash;
 
+	/*
+	 * Number of send operations in progress.
+	 * Updated while holding fs_info::balance_mutex.
+	 */
+	int send_in_progress;
+
 #ifdef CONFIG_BTRFS_FS_REF_VERIFY
 	spinlock_t ref_verify_lock;
 	struct rb_root block_tree;

commit 71a9c4885e1dec0f8ec5e4b05ecd6fddd27fc6c1
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 31 17:22:59 2019 +0200

    btrfs: document BTRFS_MAX_MIRRORS
    
    The real meaning of that constant is not clear from the context due to
    the target device inclusion.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fb7435533478..31198499f175 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -46,7 +46,16 @@ struct btrfs_ref;
 
 #define BTRFS_MAGIC 0x4D5F53665248425FULL /* ascii _BHRfS_M, no null */
 
-#define BTRFS_MAX_MIRRORS 3
+/*
+ * Maximum number of mirrors that can be available for all profiles counting
+ * the target device of dev-replace as one. During an active device replace
+ * procedure, the target device of the copy operation is a mirror for the
+ * filesystem data as well that can be used to read data in order to repair
+ * read errors on other disks.
+ *
+ * Current value is derived from RAID1 with 2 copies.
+ */
+#define BTRFS_MAX_MIRRORS (2 + 1)
 
 #define BTRFS_MAX_LEVEL 8
 

commit 6f8e4fd43073406aa5e2d7f27ffc45510778ac3e
Author: David Sterba <dsterba@suse.com>
Date:   Thu May 30 18:43:53 2019 +0200

    btrfs: use file:line format for assertion report
    
    The filename:line format is commonly understood by editors and can be
    copy&pasted more easily than the current format.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e908c557fb2..fb7435533478 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3536,8 +3536,7 @@ __cold
 static inline void assfail(const char *expr, const char *file, int line)
 {
 	if (IS_ENABLED(CONFIG_BTRFS_ASSERT)) {
-		pr_err("assertion failed: %s, file: %s, line: %d\n",
-		       expr, file, line);
+		pr_err("assertion failed: %s, in %s:%d\n", expr, file, line);
 		BUG();
 	}
 }

commit 6d97c6e31b553bc9f58b83ac3c4c79c17affbda8
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 3 16:58:56 2019 +0200

    btrfs: add boilerplate code for directly including the crypto framework
    
    Add boilerplate code for directly including the crypto framework.  This
    helps us flipping the switch for new algorithms.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a66ed58058d9..2e908c557fb2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -73,6 +73,7 @@ struct btrfs_ref;
 
 /* four bytes for CRC32 */
 static const int btrfs_csum_sizes[] = { 4 };
+static const char *btrfs_csum_names[] = { "crc32c" };
 
 #define BTRFS_EMPTY_DIR_SIZE 0
 
@@ -1163,6 +1164,8 @@ struct btrfs_fs_info {
 	spinlock_t swapfile_pins_lock;
 	struct rb_root swapfile_pins;
 
+	struct crypto_shash *csum_shash;
+
 #ifdef CONFIG_BTRFS_FS_REF_VERIFY
 	spinlock_t ref_verify_lock;
 	struct rb_root block_tree;
@@ -2454,6 +2457,11 @@ static inline int btrfs_super_csum_size(const struct btrfs_super_block *s)
 	return btrfs_csum_sizes[t];
 }
 
+static inline const char *btrfs_super_csum_name(u16 csum_type)
+{
+	/* csum type is validated at mount time */
+	return btrfs_csum_names[csum_type];
+}
 
 /*
  * The leaf data grows from end-to-front in the node.

commit 1e25a2e3ca0dab0ed1030570e95d98af47113eae
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed May 22 10:19:01 2019 +0200

    btrfs: don't assume ordered sums to be 4 bytes
    
    BTRFS has the implicit assumption that a checksum in btrfs_orderd_sums
    is 4 bytes. While this is true for CRC32C, it is not for any other
    checksum.
    
    Change the data type to be a byte array and adjust loop index
    calculation accordingly.
    
    This includes moving the adjustment of 'index' by 'ins_size' in
    btrfs_csum_file_blocks() before dividing 'ins_size' by the checksum
    size, because before this patch the 'sums' member of 'struct
    btrfs_ordered_sum' was 4 Bytes in size and afterwards it is only one
    byte.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3691cd177ead..a66ed58058d9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3199,7 +3199,8 @@ int btrfs_find_name_in_ext_backref(struct extent_buffer *leaf, int slot,
 struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_fs_info *fs_info, u64 bytenr, u64 len);
-blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst);
+blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
+				   u8 *dst);
 blk_status_t btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio,
 			      u64 logical_offset);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,

commit 65019df8c3b0efa363c30ca4dd69a1a370a3ebe8
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed May 22 10:18:59 2019 +0200

    btrfs: resurrect btrfs_crc32c()
    
    Commit 9678c54388b6 ("btrfs: Remove custom crc32c init code") removed
    the btrfs_crc32c() function, because it was a duplicate of the crc32c()
    library function we already have in the kernel.
    
    Resurrect it as a shim wrapper over crc32c() to make following
    transformations of the checksumming code in btrfs easier.
    
    Also provide a btrfs_crc32_final() to ease following transformations.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1baa8cc39571..3691cd177ead 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -19,6 +19,7 @@
 #include <linux/kobject.h>
 #include <trace/events/btrfs.h>
 #include <asm/kmap_types.h>
+#include <asm/unaligned.h>
 #include <linux/pagemap.h>
 #include <linux/btrfs.h>
 #include <linux/btrfs_tree.h>
@@ -2644,6 +2645,16 @@ BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cursor_right,
 	((unsigned long)(BTRFS_LEAF_DATA_OFFSET + \
 	btrfs_item_offset_nr(leaf, slot)))
 
+static inline u32 btrfs_crc32c(u32 crc, const void *address, unsigned length)
+{
+	return crc32c(crc, address, length);
+}
+
+static inline void btrfs_crc32c_final(u32 crc, u8 *result)
+{
+	put_unaligned_le32(~crc, result);
+}
+
 static inline u64 btrfs_name_hash(const char *name, int len)
 {
        return crc32c((u32)~1, name, len);

commit c8bf1b67039556884d0532f7b06acd524c90ed87
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 17 11:43:17 2019 +0200

    btrfs: remove mapping tree structures indirection
    
    fs_info::mapping_tree is the physical<->logical mapping tree and uses
    the same underlying structure as extents, but is embedded to another
    structure. There are no other members and this indirection is useless.
    No functional change.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 02870c1bb68a..1baa8cc39571 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -99,10 +99,6 @@ static inline u32 count_max_extents(u64 size)
 	return div_u64(size + BTRFS_MAX_EXTENT_SIZE - 1, BTRFS_MAX_EXTENT_SIZE);
 }
 
-struct btrfs_mapping_tree {
-	struct extent_map_tree map_tree;
-};
-
 static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 {
 	BUG_ON(num_stripes == 0);
@@ -830,7 +826,7 @@ struct btrfs_fs_info {
 	struct extent_io_tree *pinned_extents;
 
 	/* logical->physical extent mapping */
-	struct btrfs_mapping_tree mapping_tree;
+	struct extent_map_tree mapping_tree;
 
 	/*
 	 * block reservation for extent, checksum, root tree and

commit 9b4e675a9978800995f83af0ed90e890ca501f31
Author: David Sterba <dsterba@suse.com>
Date:   Thu May 16 13:39:59 2019 +0200

    btrfs: detect fast implementation of crc32c on all architectures
    
    Currently, there's only check for fast crc32c implementation on X86,
    based on the CPU flags. This is used to decide if checksumming should be
    offloaded to worker threads or can be calculated by the caller.
    
    As there are more architectures that implement a faster version of
    crc32c (ARM, SPARC, s390, MIPS, PowerPC), also there are specialized hw
    cards.
    
    The detection is based on driver name, all generic C implementations
    contain 'generic', while the specialized versions do not. Alternatively
    the priority could be used, but this is not currently provided by the
    crypto API.
    
    The flag is set per-filesystem at mount time and used for the offloading
    decisions.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0a61dff27f57..02870c1bb68a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -791,6 +791,12 @@ enum {
 
 	/* Indicate that the cleaner thread is awake and doing something. */
 	BTRFS_FS_CLEANER_RUNNING,
+
+	/*
+	 * The checksumming has an optimized version and is considered fast,
+	 * so we don't need to offload checksums to workqueues.
+	 */
+	BTRFS_FS_CSUM_IMPL_FAST,
 };
 
 struct btrfs_fs_info {

commit 9f2e3a53f7ec9ef55e9d01bc29a6285d291c151e
Merge: 78438ce18f26 b1c16ac978fd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 11:34:19 2019 -0700

    Merge tag 'for-5.2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "This time the majority of changes are cleanups, though there's still a
      number of changes of user interest.
    
      User visible changes:
    
       - better read time and write checks to catch errors early and before
         writing data to disk (to catch potential memory corruption on data
         that get checksummed)
    
       - qgroups + metadata relocation: last speed up patch int the series
         to address the slowness, there should be no overhead comparing
         balance with and without qgroups
    
       - FIEMAP ioctl does not start a transaction unnecessarily, this can
         result in a speed up and less blocking due to IO
    
       - LOGICAL_INO (v1, v2) does not start transaction unnecessarily, this
         can speed up the mentioned ioctl and scrub as well
    
       - fsync on files with many (but not too many) hardlinks is faster,
         finer decision if the links should be fsynced individually or
         completely
    
       - send tries harder to find ranges to clone
    
       - trim/discard will skip unallocated chunks that haven't been touched
         since the last mount
    
      Fixes:
    
       - send flushes delayed allocation before start, otherwise it could
         miss some changes in case of a very recent rw->ro switch of a
         subvolume
    
       - fix fallocate with qgroups that could lead to space accounting
         underflow, reported as a warning
    
       - trim/discard ioctl honours the requested range
    
       - starting send and dedupe on a subvolume at the same time will let
         only one of them succeed, this is to prevent changes that send
         could miss due to dedupe; both operations are restartable
    
      Core changes:
    
       - more tree-checker validations, errors reported by fuzzing tools:
          - device item
          - inode item
          - block group profiles
    
       - tracepoints for extent buffer locking
    
       - async cow preallocates memory to avoid errors happening too deep in
         the call chain
    
       - metadata reservations for delalloc reworked to better adapt in
         many-writers/low-space scenarios
    
       - improved space flushing logic for intense DIO vs buffered workloads
    
       - lots of cleanups
          - removed unused struct members
          - redundant argument removal
          - properties and xattrs
          - extent buffer locking
          - selftests
          - use common file type conversions
          - many-argument functions reduction"
    
    * tag 'for-5.2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (227 commits)
      btrfs: Use kvmalloc for allocating compressed path context
      btrfs: Factor out common extent locking code in submit_compressed_extents
      btrfs: Set io_tree only once in submit_compressed_extents
      btrfs: Replace clear_extent_bit with unlock_extent
      btrfs: Make compress_file_range take only struct async_chunk
      btrfs: Remove fs_info from struct async_chunk
      btrfs: Rename async_cow to async_chunk
      btrfs: Preallocate chunks in cow_file_range_async
      btrfs: reserve delalloc metadata differently
      btrfs: track DIO bytes in flight
      btrfs: merge calls of btrfs_setxattr and btrfs_setxattr_trans in btrfs_set_prop
      btrfs: delete unused function btrfs_set_prop_trans
      btrfs: start transaction in xattr_handler_set_prop
      btrfs: drop local copy of inode i_mode
      btrfs: drop old_fsflags in btrfs_ioctl_setflags
      btrfs: modify local copy of btrfs_inode flags
      btrfs: drop useless inode i_flags copy and restore
      btrfs: start transaction in btrfs_ioctl_setflags()
      btrfs: export btrfs_set_prop
      btrfs: refactor btrfs_set_props to validate externally
      ...

commit 26602cab411782dab49a75b316f375933ef380d3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 10 15:14:41 2019 -0400

    btrfs: use ->free_inode()
    
    a lot of stuff remains in ->destroy_inode()
    
    Acked-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b3642367a595..5260a9263d73 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3267,6 +3267,7 @@ void btrfs_evict_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
+void btrfs_free_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);
 int __init btrfs_init_cachep(void);
 void __cold btrfs_destroy_cachep(void);

commit 4297ff84dc24d120753e0425702e8ad9b80ed10f
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Apr 10 15:56:09 2019 -0400

    btrfs: track DIO bytes in flight
    
    When diagnosing a slowdown of generic/224 I noticed we were not doing
    anything when calling into shrink_delalloc().  This is because all
    writes in 224 are O_DIRECT, not delalloc, and thus our delalloc_bytes
    counter is 0, which short circuits most of the work inside of
    shrink_delalloc().  However O_DIRECT writes still consume metadata
    resources and generate ordered extents, which we can still wait on.
    
    Fix this by tracking outstanding DIO write bytes, and use this as well
    as the delalloc bytes counter to decide if we need to lookup and wait on
    any ordered extents.  If we have more DIO writes than delalloc bytes
    we'll go ahead and wait on any ordered extents regardless of our flush
    state as flushing delalloc is likely to not gain us anything.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ use dio instead of odirect in identifiers ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aeaadeebc1fd..b81c331b28fa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1016,6 +1016,7 @@ struct btrfs_fs_info {
 	/* used to keep from writing metadata until there is a nice batch */
 	struct percpu_counter dirty_metadata_bytes;
 	struct percpu_counter delalloc_bytes;
+	struct percpu_counter dio_bytes;
 	s32 dirty_metadata_batch;
 	s32 delalloc_batch;
 

commit 62d54f3a7fa27ef6a74d6cdf643ce04beba3afa7
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 22 16:43:42 2019 +0100

    Btrfs: fix race between send and deduplication that lead to failures and crashes
    
    Send operates on read only trees and expects them to never change while it
    is using them. This is part of its initial design, and this expection is
    due to two different reasons:
    
    1) When it was introduced, no operations were allowed to modifiy read-only
       subvolumes/snapshots (including defrag for example).
    
    2) It keeps send from having an impact on other filesystem operations.
       Namely send does not need to keep locks on the trees nor needs to hold on
       to transaction handles and delay transaction commits. This ends up being
       a consequence of the former reason.
    
    However the deduplication feature was introduced later (on September 2013,
    while send was introduced in July 2012) and it allowed for deduplication
    with destination files that belong to read-only trees (subvolumes and
    snapshots).
    
    That means that having a send operation (either full or incremental) running
    in parallel with a deduplication that has the destination inode in one of
    the trees used by the send operation, can result in tree nodes and leaves
    getting freed and reused while send is using them. This problem is similar
    to the problem solved for the root nodes getting freed and reused when a
    snapshot is made against one tree that is currenly being used by a send
    operation, fixed in commits [1] and [2]. These commits explain in detail
    how the problem happens and the explanation is valid for any node or leaf
    that is not the root of a tree as well. This problem was also discussed
    and explained recently in a thread [3].
    
    The problem is very easy to reproduce when using send with large trees
    (snapshots) and just a few concurrent deduplication operations that target
    files in the trees used by send. A stress test case is being sent for
    fstests that triggers the issue easily. The most common error to hit is
    the send ioctl return -EIO with the following messages in dmesg/syslog:
    
     [1631617.204075] BTRFS error (device sdc): did not find backref in send_root. inode=63292, offset=0, disk_byte=5228134400 found extent=5228134400
     [1631633.251754] BTRFS error (device sdc): parent transid verify failed on 32243712 wanted 24 found 27
    
    The first one is very easy to hit while the second one happens much less
    frequently, except for very large trees (in that test case, snapshots
    with 100000 files having large xattrs to get deep and wide trees).
    Less frequently, at least one BUG_ON can be hit:
    
     [1631742.130080] ------------[ cut here ]------------
     [1631742.130625] kernel BUG at fs/btrfs/ctree.c:1806!
     [1631742.131188] invalid opcode: 0000 [#6] SMP DEBUG_PAGEALLOC PTI
     [1631742.131726] CPU: 1 PID: 13394 Comm: btrfs Tainted: G    B D W         5.0.0-rc8-btrfs-next-45 #1
     [1631742.132265] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626ccb91-prebuilt.qemu-project.org 04/01/2014
     [1631742.133399] RIP: 0010:read_node_slot+0x122/0x130 [btrfs]
     (...)
     [1631742.135061] RSP: 0018:ffffb530021ebaa0 EFLAGS: 00010246
     [1631742.135615] RAX: ffff93ac8912e000 RBX: 000000000000009d RCX: 0000000000000002
     [1631742.136173] RDX: 000000000000009d RSI: ffff93ac564b0d08 RDI: ffff93ad5b48c000
     [1631742.136759] RBP: ffffb530021ebb7d R08: 0000000000000001 R09: ffffb530021ebb7d
     [1631742.137324] R10: ffffb530021eba70 R11: 0000000000000000 R12: ffff93ac87d0a708
     [1631742.137900] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000001
     [1631742.138455] FS:  00007f4cdb1528c0(0000) GS:ffff93ad76a80000(0000) knlGS:0000000000000000
     [1631742.139010] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     [1631742.139568] CR2: 00007f5acb3d0420 CR3: 000000012be3e006 CR4: 00000000003606e0
     [1631742.140131] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     [1631742.140719] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     [1631742.141272] Call Trace:
     [1631742.141826]  ? do_raw_spin_unlock+0x49/0xc0
     [1631742.142390]  tree_advance+0x173/0x1d0 [btrfs]
     [1631742.142948]  btrfs_compare_trees+0x268/0x690 [btrfs]
     [1631742.143533]  ? process_extent+0x1070/0x1070 [btrfs]
     [1631742.144088]  btrfs_ioctl_send+0x1037/0x1270 [btrfs]
     [1631742.144645]  _btrfs_ioctl_send+0x80/0x110 [btrfs]
     [1631742.145161]  ? trace_sched_stick_numa+0xe0/0xe0
     [1631742.145685]  btrfs_ioctl+0x13fe/0x3120 [btrfs]
     [1631742.146179]  ? account_entity_enqueue+0xd3/0x100
     [1631742.146662]  ? reweight_entity+0x154/0x1a0
     [1631742.147135]  ? update_curr+0x20/0x2a0
     [1631742.147593]  ? check_preempt_wakeup+0x103/0x250
     [1631742.148053]  ? do_vfs_ioctl+0xa2/0x6f0
     [1631742.148510]  ? btrfs_ioctl_get_supported_features+0x30/0x30 [btrfs]
     [1631742.148942]  do_vfs_ioctl+0xa2/0x6f0
     [1631742.149361]  ? __fget+0x113/0x200
     [1631742.149767]  ksys_ioctl+0x70/0x80
     [1631742.150159]  __x64_sys_ioctl+0x16/0x20
     [1631742.150543]  do_syscall_64+0x60/0x1b0
     [1631742.150931]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
     [1631742.151326] RIP: 0033:0x7f4cd9f5add7
     (...)
     [1631742.152509] RSP: 002b:00007ffe91017708 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
     [1631742.152892] RAX: ffffffffffffffda RBX: 0000000000000105 RCX: 00007f4cd9f5add7
     [1631742.153268] RDX: 00007ffe91017790 RSI: 0000000040489426 RDI: 0000000000000007
     [1631742.153633] RBP: 0000000000000007 R08: 00007f4cd9e79700 R09: 00007f4cd9e79700
     [1631742.153999] R10: 00007f4cd9e799d0 R11: 0000000000000202 R12: 0000000000000003
     [1631742.154365] R13: 0000555dfae53020 R14: 0000000000000000 R15: 0000000000000001
     (...)
     [1631742.156696] ---[ end trace 5dac9f96dcc3fd6b ]---
    
    That BUG_ON happens because while send is using a node, that node is COWed
    by a concurrent deduplication, gets freed and gets reused as a leaf (because
    a transaction commit happened in between), so when it attempts to read a
    slot from the extent buffer, at ctree.c:read_node_slot(), the extent buffer
    contents were wiped out and it now matches a leaf (which can even belong to
    some other tree now), hitting the BUG_ON(level == 0).
    
    Fix this concurrency issue by not allowing send and deduplication to run
    in parallel if both operate on the same readonly trees, returning EAGAIN
    to user space and logging an exlicit warning in dmesg/syslog.
    
    [1] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=be6821f82c3cc36e026f5afd10249988852b35ea
    [2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=6f2f0b394b54e2b159ef969a0b5274e9bbf82ff2
    [3] https://lore.kernel.org/linux-btrfs/CAL3q7H7iqSEEyFaEtpRZw3cp613y+4k2Q8b4W7mweR3tZA05bQ@mail.gmail.com/
    
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b19c7d65fe7d..aeaadeebc1fd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1340,6 +1340,12 @@ struct btrfs_root {
 	 * manipulation with the read-only status via SUBVOL_SETFLAGS
 	 */
 	int send_in_progress;
+	/*
+	 * Number of currently running deduplication operations that have a
+	 * destination inode belonging to this root. Protected by the lock
+	 * root_item_lock.
+	 */
+	int dedupe_in_progress;
 	struct btrfs_subvolume_writers *subv_writers;
 	atomic_t will_be_snapshotted;
 	atomic_t snapshot_force_cow;

commit f5c8daa5b2ae6de4baa18a95002271cd7f90be90
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 11:43:36 2019 +0100

    btrfs: remove unused parameter fs_info from btrfs_set_disk_extent_flags
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 93318ab9ceb9..b19c7d65fe7d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2746,7 +2746,6 @@ int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf, int full_backref);
 int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
-				struct btrfs_fs_info *fs_info,
 				u64 bytenr, u64 num_bytes, u64 flags,
 				int level, int is_data);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_ref *ref);

commit c71dd88007bdc8ba62e99439d93050b0778f101a
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:51:10 2019 +0100

    btrfs: remove unused parameter fs_info from btrfs_extend_item
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b6b570bcadaa..93318ab9ceb9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2930,8 +2930,7 @@ int btrfs_copy_root(struct btrfs_trans_handle *trans,
 		      struct extent_buffer **cow_ret, u64 new_root_objectid);
 int btrfs_block_can_be_shared(struct btrfs_root *root,
 			      struct extent_buffer *buf);
-void btrfs_extend_item(struct btrfs_fs_info *fs_info, struct btrfs_path *path,
-		       u32 data_size);
+void btrfs_extend_item(struct btrfs_path *path, u32 data_size);
 void btrfs_truncate_item(struct btrfs_path *path, u32 new_size, int from_end);
 int btrfs_split_item(struct btrfs_trans_handle *trans,
 		     struct btrfs_root *root,

commit 78ac4f9e5ae022bd183ca21da7b373d300b7be17
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:49:12 2019 +0100

    btrfs: remove unused parameter fs_info from btrfs_truncate_item
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aa557b43d349..b6b570bcadaa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2932,8 +2932,7 @@ int btrfs_block_can_be_shared(struct btrfs_root *root,
 			      struct extent_buffer *buf);
 void btrfs_extend_item(struct btrfs_fs_info *fs_info, struct btrfs_path *path,
 		       u32 data_size);
-void btrfs_truncate_item(struct btrfs_fs_info *fs_info,
-			 struct btrfs_path *path, u32 new_size, int from_end);
+void btrfs_truncate_item(struct btrfs_path *path, u32 new_size, int from_end);
 int btrfs_split_item(struct btrfs_trans_handle *trans,
 		     struct btrfs_root *root,
 		     struct btrfs_path *path,

commit ffd4bb2a19cd29681f5b70a200654ab92619de8a
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Apr 4 14:45:36 2019 +0800

    btrfs: extent-tree: Use btrfs_ref to refactor btrfs_free_extent()
    
    Similar to btrfs_inc_extent_ref(), use btrfs_ref to replace the long
    parameter list and the confusing @owner parameter.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 820c7425258a..aa557b43d349 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2749,10 +2749,7 @@ int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 				struct btrfs_fs_info *fs_info,
 				u64 bytenr, u64 num_bytes, u64 flags,
 				int level, int is_data);
-int btrfs_free_extent(struct btrfs_trans_handle *trans,
-		      struct btrfs_root *root,
-		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,
-		      u64 owner, u64 offset);
+int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_ref *ref);
 
 int btrfs_free_reserved_extent(struct btrfs_fs_info *fs_info,
 			       u64 start, u64 len, int delalloc);

commit 82fa113fccc41fe5204b4ce35341d69ebde0020f
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Apr 4 14:45:35 2019 +0800

    btrfs: extent-tree: Use btrfs_ref to refactor btrfs_inc_extent_ref()
    
    Use the new btrfs_ref structure and replace parameter list to clean up
    the usage of owner and level to distinguish the extent types.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 05731e4ca358..820c7425258a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -41,6 +41,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 extern struct kmem_cache *btrfs_free_space_cachep;
 struct btrfs_ordered_sum;
+struct btrfs_ref;
 
 #define BTRFS_MAGIC 0x4D5F53665248425FULL /* ascii _BHRfS_M, no null */
 
@@ -2760,9 +2761,7 @@ int btrfs_free_and_pin_reserved_extent(struct btrfs_fs_info *fs_info,
 void btrfs_prepare_extent_commit(struct btrfs_fs_info *fs_info);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
-			 struct btrfs_root *root,
-			 u64 bytenr, u64 num_bytes, u64 parent,
-			 u64 root_objectid, u64 owner, u64 offset);
+			 struct btrfs_ref *generic_ref);
 
 int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans);

commit 163e97ee0d0f8194ef66f10b0bf0851b7f6b55dd
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 16:32:55 2019 +0100

    btrfs: get fs_info from device in btrfs_scrub_cancel_dev
    
    We can read fs_info from the device and can drop it from the parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 69a60d2217e5..05731e4ca358 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3752,8 +3752,7 @@ int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,
 void btrfs_scrub_pause(struct btrfs_fs_info *fs_info);
 void btrfs_scrub_continue(struct btrfs_fs_info *fs_info);
 int btrfs_scrub_cancel(struct btrfs_fs_info *info);
-int btrfs_scrub_cancel_dev(struct btrfs_fs_info *info,
-			   struct btrfs_device *dev);
+int btrfs_scrub_cancel_dev(struct btrfs_device *dev);
 int btrfs_scrub_progress(struct btrfs_fs_info *fs_info, u64 devid,
 			 struct btrfs_scrub_progress *progress);
 static inline void btrfs_init_full_stripe_locks_tree(

commit 32b593bfcb58638f40a72fd5c6db50a21616a54e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Apr 17 10:28:47 2019 +0100

    Btrfs: remove no longer used function to run delayed refs asynchronously
    
    It used to be called from only two places (truncate path and releasing a
    transaction handle), but commits 28bad2125767c5 ("btrfs: fix truncate
    throttling") and db2462a6ad3dc4 ("btrfs: don't run delayed refs in the end
    transaction logic") removed their calls to this function, so it's not used
    anymore. Just remove it and all its helpers.
    
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cad183a17c1c..69a60d2217e5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2701,8 +2701,6 @@ void btrfs_wait_nocow_writers(struct btrfs_block_group_cache *bg);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   unsigned long count);
-int btrfs_async_run_delayed_refs(struct btrfs_fs_info *fs_info,
-				 unsigned long count, u64 transid, int wait);
 void btrfs_cleanup_ref_head_accounting(struct btrfs_fs_info *fs_info,
 				  struct btrfs_delayed_ref_root *delayed_refs,
 				  struct btrfs_delayed_ref_head *head);

commit 5742d15fa76adfc833642f9c24f7c31c9b1a1646
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 12:04:08 2019 +0100

    btrfs: get fs_info from trans in btrfs_write_dirty_block_groups
    
    We can read fs_info from the transaction and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 66f282340c62..cad183a17c1c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2767,8 +2767,7 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 u64 root_objectid, u64 owner, u64 offset);
 
 int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans);
-int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
-				   struct btrfs_fs_info *fs_info);
+int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans);
 int btrfs_setup_space_cache(struct btrfs_trans_handle *trans);
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);

commit bbebb3e0babb68bbff240608aaa14229d2d5d1dc
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 12:02:55 2019 +0100

    btrfs: get fs_info from trans in btrfs_setup_space_cache
    
    We can read fs_info from the transaction and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1a6c5ce0cdac..66f282340c62 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2769,8 +2769,7 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				   struct btrfs_fs_info *fs_info);
-int btrfs_setup_space_cache(struct btrfs_trans_handle *trans,
-			    struct btrfs_fs_info *fs_info);
+int btrfs_setup_space_cache(struct btrfs_trans_handle *trans);
 int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_fs_info *info);

commit e74e3993bcf6a1d119a2bbe7af2cc278a147f930
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Mar 27 14:24:15 2019 +0200

    btrfs: Factor out in_range macro
    
    This is used in more than one places so let's factor it out in ctree.h.
    No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 93270e20a8e7..1a6c5ce0cdac 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3806,6 +3806,8 @@ static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
 	return signal_pending(current);
 }
 
+#define in_range(b, first, len) ((b) >= (first) && (b) < (first) + (len))
+
 /* Sanity test specific functions */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 void btrfs_test_inode_set_ops(struct inode *inode);

commit 1c11b63eff2a67906cb9137bc6b2ee27767f313b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Mar 27 14:24:12 2019 +0200

    btrfs: replace pending/pinned chunks lists with io tree
    
    The pending chunks list contains chunks that are allocated in the
    current transaction but haven't been created yet. The pinned chunks
    list contains chunks that are being released in the current transaction.
    Both describe chunks that are not reflected on disk as in use but are
    unavailable just the same.
    
    The pending chunks list is anchored by the transaction handle, which
    means that we need to hold a reference to a transaction when working
    with the list.
    
    The way we use them is by iterating over both lists to perform
    comparisons on the stripes they describe for each device. This is
    backwards and requires that we keep a transaction handle open while
    we're trimming.
    
    This patchset adds an extent_io_tree to btrfs_device that maintains
    the allocation state of the device.  Extents are set dirty when
    chunks are first allocated -- when the extent maps are added to the
    mapping tree. They're cleared when last removed -- when the extent
    maps are removed from the mapping tree. This matches the lifespan
    of the pending and pinned chunks list and allows us to do trims
    on unallocated space safely without pinning the transaction for what
    may be a lengthy operation. We can also use this io tree to mark
    which chunks have already been trimmed so we don't repeat the operation.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 19833b4af630..93270e20a8e7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1149,12 +1149,6 @@ struct btrfs_fs_info {
 	struct mutex unused_bg_unpin_mutex;
 	struct mutex delete_unused_bgs_mutex;
 
-	/*
-	 * Chunks that can't be freed yet (under a trim/discard operation)
-	 * and will be latter freed. Protected by fs_info->chunk_mutex.
-	 */
-	struct list_head pinned_chunks;
-
 	/* Cached block sizes */
 	u32 nodesize;
 	u32 sectorsize;

commit 496245cac57e26d8b738d85c7a29cf9a47610f3f
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Mar 13 14:31:35 2019 +0800

    btrfs: tree-checker: Verify inode item
    
    There is a report in kernel bugzilla about mismatch file type in dir
    item and inode item.
    
    This inspires us to check inode mode in inode item.
    
    This patch will check the following members:
    
    - inode key objectid
      Should be ROOT_DIR_DIR or [256, (u64)-256] or FREE_INO.
    
    - inode key offset
      Should be 0
    
    - inode item generation
    - inode item transid
      No newer than sb generation + 1.
      The +1 is for log tree.
    
    - inode item mode
      No unknown bits.
      No invalid S_IF* bit.
      NOTE: S_IFMT check is not enough, need to check every know type.
    
    - inode item nlink
      Dir should have no more link than 1.
    
    - inode item flags
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5d85c55032dd..19833b4af630 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1537,6 +1537,21 @@ do {                                                                   \
 
 #define BTRFS_INODE_ROOT_ITEM_INIT	(1 << 31)
 
+#define BTRFS_INODE_FLAG_MASK						\
+	(BTRFS_INODE_NODATASUM |					\
+	 BTRFS_INODE_NODATACOW |					\
+	 BTRFS_INODE_READONLY |						\
+	 BTRFS_INODE_NOCOMPRESS |					\
+	 BTRFS_INODE_PREALLOC |						\
+	 BTRFS_INODE_SYNC |						\
+	 BTRFS_INODE_IMMUTABLE |					\
+	 BTRFS_INODE_APPEND |						\
+	 BTRFS_INODE_NODUMP |						\
+	 BTRFS_INODE_NOATIME |						\
+	 BTRFS_INODE_DIRSYNC |						\
+	 BTRFS_INODE_COMPRESS |						\
+	 BTRFS_INODE_ROOT_ITEM_INIT)
+
 struct btrfs_map_token {
 	const struct extent_buffer *eb;
 	char *kaddr;

commit 90b1377daa9633973d595487d717d43d3c601420
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 27 16:55:26 2019 +0100

    btrfs: qgroup: remove obsolete fs_info members
    
    The commit fcebe4562dec ("Btrfs: rework qgroup accounting") reworked
    qgroups and added some new structures. Another rework of qgroup
    mechanics e69bcee37692 ("btrfs: qgroup: Cleanup the old
    ref_node-oriented mechanism.") stopped using them and left uncleaned.
    
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1d1e12400552..5d85c55032dd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1092,10 +1092,7 @@ struct btrfs_fs_info {
 
 	/* holds configuration and tracking. Protected by qgroup_lock */
 	struct rb_root qgroup_tree;
-	struct rb_root qgroup_op_tree;
 	spinlock_t qgroup_lock;
-	spinlock_t qgroup_op_lock;
-	atomic_t qgroup_op_seq;
 
 	/*
 	 * used to avoid frequently calling ulist_alloc()/ulist_free()

commit e902baac656479bdb956224ed693578424cf9e96
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:36:46 2019 +0100

    btrfs: get fs_info from eb in btrfs_leaf_free_space
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1ec08bb1c2e0..1d1e12400552 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3011,8 +3011,7 @@ static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
 {
 	return btrfs_next_old_item(root, p, 0);
 }
-int btrfs_leaf_free_space(struct btrfs_fs_info *fs_info,
-			  struct extent_buffer *leaf);
+int btrfs_leaf_free_space(struct extent_buffer *leaf);
 int __must_check btrfs_drop_snapshot(struct btrfs_root *root,
 				     struct btrfs_block_rsv *block_rsv,
 				     int update_ref, int for_reloc);

commit bcdc428cfe7dda315ad128cbe06abe72add2c73f
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 12:14:33 2019 +0100

    btrfs: get fs_info from eb in btrfs_exclude_logged_extents
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7fabe4fd0800..1ec08bb1c2e0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2708,8 +2708,7 @@ int btrfs_pin_extent(struct btrfs_fs_info *fs_info,
 		     u64 bytenr, u64 num, int reserved);
 int btrfs_pin_extent_for_log_replay(struct btrfs_fs_info *fs_info,
 				    u64 bytenr, u64 num_bytes);
-int btrfs_exclude_logged_extents(struct btrfs_fs_info *fs_info,
-				 struct extent_buffer *eb);
+int btrfs_exclude_logged_extents(struct extent_buffer *eb);
 int btrfs_cross_ref_exist(struct btrfs_root *root,
 			  u64 objectid, u64 offset, u64 bytenr);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(

commit 8f881e8c1880fb7029e74ccdaa7891bd042b6c63
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 11:33:10 2019 +0100

    btrfs: get fs_info from eb in leaf_data_end
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c03852d1aa34..7fabe4fd0800 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2443,13 +2443,12 @@ static inline int btrfs_super_csum_size(const struct btrfs_super_block *s)
  * this returns the address of the start of the last item,
  * which is the stop of the leaf data stack
  */
-static inline unsigned int leaf_data_end(const struct btrfs_fs_info *fs_info,
-					 const struct extent_buffer *leaf)
+static inline unsigned int leaf_data_end(const struct extent_buffer *leaf)
 {
 	u32 nr = btrfs_header_nritems(leaf);
 
 	if (nr == 0)
-		return BTRFS_LEAF_DATA_SIZE(fs_info);
+		return BTRFS_LEAF_DATA_SIZE(leaf->fs_info);
 	return btrfs_item_offset_nr(leaf, nr - 1);
 }
 

commit 80fbc341dcff73b4e976b753e4b9ac3db992f229
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Mar 19 14:04:17 2019 +0800

    btrfs: Make btrfs_(set|clear)_header_flag return void
    
    From the introduction of btrfs_(set|clear)_header_flag, there is no
    usage of its return value.  So just make it return void.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b3642367a595..c03852d1aa34 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2163,18 +2163,16 @@ static inline int btrfs_header_flag(const struct extent_buffer *eb, u64 flag)
 	return (btrfs_header_flags(eb) & flag) == flag;
 }
 
-static inline int btrfs_set_header_flag(struct extent_buffer *eb, u64 flag)
+static inline void btrfs_set_header_flag(struct extent_buffer *eb, u64 flag)
 {
 	u64 flags = btrfs_header_flags(eb);
 	btrfs_set_header_flags(eb, flags | flag);
-	return (flags & flag) == flag;
 }
 
-static inline int btrfs_clear_header_flag(struct extent_buffer *eb, u64 flag)
+static inline void btrfs_clear_header_flag(struct extent_buffer *eb, u64 flag)
 {
 	u64 flags = btrfs_header_flags(eb);
 	btrfs_set_header_flags(eb, flags & ~flag);
-	return (flags & flag) == flag;
 }
 
 static inline int btrfs_header_backref_rev(const struct extent_buffer *eb)

commit 92825b0298ca6822085ef483f914b6e0dea9bf66
Merge: 1fbf3e48123d d3865159ac78
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 12 14:53:57 2019 -0700

    Merge tag 'for-5.1-part2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "Correctness and a deadlock fixes"
    
    * tag 'for-5.1-part2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      btrfs: zstd: ensure reclaim timer is properly cleaned up
      btrfs: move ulist allocation out of transaction in quota enable
      btrfs: save drop_progress if we drop refs at all
      btrfs: check for refs on snapshot delete resume
      Btrfs: fix deadlock between clone/dedupe and rename
      Btrfs: fix corruption reading shared and compressed extents after hole punching

commit b5dd0c658c31b469ccff1b637e5124851e7a4a1c
Merge: 610cd4eadec4 fe0436e10c88
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 7 19:25:37 2019 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Merge more updates from Andrew Morton:
    
     - some of the rest of MM
    
     - various misc things
    
     - dynamic-debug updates
    
     - checkpatch
    
     - some epoll speedups
    
     - autofs
    
     - rapidio
    
     - lib/, lib/lzo/ updates
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (83 commits)
      samples/mic/mpssd/mpssd.h: remove duplicate header
      kernel/fork.c: remove duplicated include
      include/linux/relay.h: fix percpu annotation in struct rchan
      arch/nios2/mm/fault.c: remove duplicate include
      unicore32: stop printing the virtual memory layout
      MAINTAINERS: fix GTA02 entry and mark as orphan
      mm: create the new vm_fault_t type
      arm, s390, unicore32: remove oneliner wrappers for memblock_alloc()
      arch: simplify several early memory allocations
      openrisc: simplify pte_alloc_one_kernel()
      sh: prefer memblock APIs returning virtual address
      microblaze: prefer memblock API returning virtual address
      powerpc: prefer memblock APIs returning virtual address
      lib/lzo: separate lzo-rle from lzo
      lib/lzo: implement run-length encoding
      lib/lzo: fast 8-byte copy on arm64
      lib/lzo: 64-bit CTZ on arm64
      lib/lzo: tidy-up ifdefs
      ipc/sem.c: replace kvmalloc/memset with kvzalloc and use struct_size
      ipc: annotate implicit fall through
      ...

commit afe1a715e8b699ab029eaa2afe83ee63a6c62810
Author: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Date:   Thu Mar 7 16:28:00 2019 -0800

    btrfs: implement btrfs_debug* in terms of helper macro
    
    First, the btrfs_debug macros open-code (one possible definition of)
    DYNAMIC_DEBUG_BRANCH, so they don't benefit from the CONFIG_JUMP_LABEL
    optimization.
    
    Second, a planned change of struct _ddebug (to reduce its size on 64 bit
    machines) requires that all descriptors in a translation unit use
    distinct identifiers.
    
    Using the new _dynamic_func_call_no_desc helper macro from
    dynamic_debug.h takes care of both of these.  No functional change.
    
    Link: http://lkml.kernel.org/r/20190212214150.4807-12-linux@rasmusvillemoes.dk
    Signed-off-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Acked-by: David Sterba <dsterba@suse.com>
    Acked-by: Jason Baron <jbaron@akamai.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: "Rafael J . Wysocki" <rafael.j.wysocki@intel.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7a2a2621f0d9..94618a028730 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3415,31 +3415,17 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...);
 
 #if defined(CONFIG_DYNAMIC_DEBUG)
 #define btrfs_debug(fs_info, fmt, args...)				\
-do {									\
-        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt);         	\
-        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT))  	\
-		btrfs_printk(fs_info, KERN_DEBUG fmt, ##args);		\
-} while (0)
-#define btrfs_debug_in_rcu(fs_info, fmt, args...) 			\
-do {									\
-        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt); 	        \
-        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT)) 		\
-		btrfs_printk_in_rcu(fs_info, KERN_DEBUG fmt, ##args);	\
-} while (0)
+	_dynamic_func_call_no_desc(fmt, btrfs_printk,			\
+				   fs_info, KERN_DEBUG fmt, ##args)
+#define btrfs_debug_in_rcu(fs_info, fmt, args...)			\
+	_dynamic_func_call_no_desc(fmt, btrfs_printk_in_rcu,		\
+				   fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl_in_rcu(fs_info, fmt, args...)			\
-do {									\
-        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt);         	\
-        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT))  	\
-		btrfs_printk_rl_in_rcu(fs_info, KERN_DEBUG fmt,		\
-				       ##args);\
-} while (0)
-#define btrfs_debug_rl(fs_info, fmt, args...) 				\
-do {									\
-        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt);         	\
-        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT))  	\
-		btrfs_printk_ratelimited(fs_info, KERN_DEBUG fmt,	\
-					 ##args);			\
-} while (0)
+	_dynamic_func_call_no_desc(fmt, btrfs_printk_rl_in_rcu,		\
+				   fs_info, KERN_DEBUG fmt, ##args)
+#define btrfs_debug_rl(fs_info, fmt, args...)				\
+	_dynamic_func_call_no_desc(fmt, btrfs_printk_ratelimited,	\
+				   fs_info, KERN_DEBUG fmt, ##args)
 #elif defined(DEBUG)
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)

commit 78c52d9eb6b7ac899bcd5a681aeff7c971c22934
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Feb 6 15:46:14 2019 -0500

    btrfs: check for refs on snapshot delete resume
    
    There's a bug in snapshot deletion where we won't update the
    drop_progress key if we're in the UPDATE_BACKREF stage.  This is a
    problem because we could drop refs for blocks we know don't belong to
    ours.  If we crash or umount at the right time we could experience
    messages such as the following when snapshot deletion resumes
    
     BTRFS error (device dm-3): unable to find ref byte nr 66797568 parent 0 root 258  owner 1 offset 0
     ------------[ cut here ]------------
     WARNING: CPU: 3 PID: 16052 at fs/btrfs/extent-tree.c:7108 __btrfs_free_extent.isra.78+0x62c/0xb30 [btrfs]
     CPU: 3 PID: 16052 Comm: umount Tainted: G        W  OE     5.0.0-rc4+ #147
     Hardware name: To Be Filled By O.E.M. To Be Filled By O.E.M./890FX Deluxe5, BIOS P1.40 05/03/2011
     RIP: 0010:__btrfs_free_extent.isra.78+0x62c/0xb30 [btrfs]
     RSP: 0018:ffffc90005cd7b18 EFLAGS: 00010286
     RAX: 0000000000000000 RBX: 0000000000000001 RCX: 0000000000000000
     RDX: ffff88842fade680 RSI: ffff88842fad6b18 RDI: ffff88842fad6b18
     RBP: ffffc90005cd7bc8 R08: 0000000000000000 R09: 0000000000000001
     R10: 0000000000000001 R11: ffffffff822696b8 R12: 0000000003fb4000
     R13: 0000000000000001 R14: 0000000000000102 R15: ffff88819c9d67e0
     FS:  00007f08bb138fc0(0000) GS:ffff88842fac0000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     CR2: 00007f8f5d861ea0 CR3: 00000003e99fe000 CR4: 00000000000006e0
     Call Trace:
     ? _raw_spin_unlock+0x27/0x40
     ? btrfs_merge_delayed_refs+0x356/0x3e0 [btrfs]
     __btrfs_run_delayed_refs+0x75a/0x13c0 [btrfs]
     ? join_transaction+0x2b/0x460 [btrfs]
     btrfs_run_delayed_refs+0xf3/0x1c0 [btrfs]
     btrfs_commit_transaction+0x52/0xa50 [btrfs]
     ? start_transaction+0xa6/0x510 [btrfs]
     btrfs_sync_fs+0x79/0x1c0 [btrfs]
     sync_filesystem+0x70/0x90
     generic_shutdown_super+0x27/0x120
     kill_anon_super+0x12/0x30
     btrfs_kill_super+0x16/0xa0 [btrfs]
     deactivate_locked_super+0x43/0x70
     deactivate_super+0x40/0x60
     cleanup_mnt+0x3f/0x80
     __cleanup_mnt+0x12/0x20
     task_work_run+0x8b/0xc0
     exit_to_usermode_loop+0xce/0xd0
     do_syscall_64+0x20b/0x210
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    To fix this simply mark dead roots we read from disk as DEAD and then
    set the walk_control->restarted flag so we know we have a restarted
    deletion.  From here whenever we try to drop refs for blocks we check to
    verify our ref is set on them, and if it is not we skip it.  Once we
    find a ref that is set we unset walk_control->restarted since the tree
    should be in a normal state from then on, and any problems we run into
    from there are different issues.  I tested this with an existing broken
    fs and my reproducer that creates a broken fs and it fixed both file
    systems.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 85140913c0f5..0f4838e00fbc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1210,6 +1210,8 @@ enum {
 	 * Set for the subvolume tree owning the reloc tree.
 	 */
 	BTRFS_ROOT_DEAD_RELOC_TREE,
+	/* Mark dead root stored on device whose cleanup needs to be resumed */
+	BTRFS_ROOT_DEAD_TREE,
 };
 
 /*

commit 0ea82076262f4467ff6f7f8ac11efeeeed0d1a33
Author: David Sterba <dsterba@suse.com>
Date:   Tue Feb 12 18:20:04 2019 +0100

    btrfs: scrub: remove unused nocow worker pointer
    
    The member btrfs_fs_info::scrub_nocow_workers is unused since the nocow
    optimization was removed from scrub in 9bebe665c3e4 ("btrfs: scrub:
    Remove unused copy_nocow_pages and its callchain").
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f92f97304e69..85140913c0f5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1082,7 +1082,6 @@ struct btrfs_fs_info {
 	refcount_t scrub_workers_refcnt;
 	struct btrfs_workqueue *scrub_workers;
 	struct btrfs_workqueue *scrub_wr_completion_workers;
-	struct btrfs_workqueue *scrub_nocow_workers;
 	struct btrfs_workqueue *scrub_parity_workers;
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY

commit c8352942745e260d68dfdfdfbecd276c2aac3277
Author: David Sterba <dsterba@suse.com>
Date:   Tue Feb 12 16:51:18 2019 +0100

    btrfs: scrub: add assertions for worker pointers
    
    The scrub worker pointers are not NULL iff the scrub is running, so
    reset them back once the last reference is dropped. Add assertions to
    the initial phase of scrub to verify that.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7efa1edb30cd..f92f97304e69 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1075,6 +1075,10 @@ struct btrfs_fs_info {
 	atomic_t scrubs_paused;
 	atomic_t scrub_cancel_req;
 	wait_queue_head_t scrub_pause_wait;
+	/*
+	 * The worker pointers are NULL iff the refcount is 0, ie. scrub is not
+	 * running.
+	 */
 	refcount_t scrub_workers_refcnt;
 	struct btrfs_workqueue *scrub_workers;
 	struct btrfs_workqueue *scrub_wr_completion_workers;

commit ff09c4ca5992b839b4e8b411f55aecd75735fc16
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Jan 30 14:45:02 2019 +0800

    btrfs: scrub: convert scrub_workers_refcnt to refcount_t
    
    Use the refcount_t for fs_info::scrub_workers_refcnt instead of int so
    we get the extra checks. All reference changes are still done under
    scrub_lock.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9306925b6790..7efa1edb30cd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1075,7 +1075,7 @@ struct btrfs_fs_info {
 	atomic_t scrubs_paused;
 	atomic_t scrub_cancel_req;
 	wait_queue_head_t scrub_pause_wait;
-	int scrub_workers_refcnt;
+	refcount_t scrub_workers_refcnt;
 	struct btrfs_workqueue *scrub_workers;
 	struct btrfs_workqueue *scrub_wr_completion_workers;
 	struct btrfs_workqueue *scrub_nocow_workers;

commit 450114fc0db0cd5c2e7324b917e5de52cff991d7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Nov 21 14:03:08 2018 -0500

    btrfs: don't use global reserve for chunk allocation
    
    We've done this forever because of the voodoo around knowing how much
    space we have.  However, we have better ways of doing this now, and on
    normal file systems we'll easily have a global reserve of 512MiB, and
    since metadata chunks are usually 1GiB that means we'll allocate
    metadata chunks more readily.  Instead use the actual used amount when
    determining if we need to allocate a chunk or not.
    
    This has a side effect for mixed block group fs'es where we are no
    longer allocating enough chunks for the data/metadata requirements.  To
    deal with this add a ALLOC_CHUNK_FORCE step to the flushing state
    machine.  This will only get used if we've already made a full loop
    through the flushing machinery and tried committing the transaction.
    
    If we have then we can try and force a chunk allocation since we likely
    need it to make progress.  This resolves issues I was seeing with
    the mixed bg tests in xfstests without the new flushing state.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ merged with patch "add ALLOC_CHUNK_FORCE to the flushing code" ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6e0fd98c6bd9..9306925b6790 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2805,7 +2805,8 @@ enum btrfs_flush_state {
 	FLUSH_DELALLOC		=	5,
 	FLUSH_DELALLOC_WAIT	=	6,
 	ALLOC_CHUNK		=	7,
-	COMMIT_TRANS		=	8,
+	ALLOC_CHUNK_FORCE	=	8,
+	COMMIT_TRANS		=	9,
 };
 
 int btrfs_alloc_data_chunk_ondemand(struct btrfs_inode *inode, u64 bytes);

commit 034f784d7cab9af731ccd41b34e5e9625ef47db7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Dec 3 11:06:52 2018 -0500

    btrfs: replace cleaner_delayed_iput_mutex with a waitqueue
    
    The throttle path doesn't take cleaner_delayed_iput_mutex, which means
    we could think we're done flushing iputs in the data space reservation
    path when we could have a throttler doing an iput.  There's no real
    reason to serialize the delayed iput flushing, so instead of taking the
    cleaner_delayed_iput_mutex whenever we flush the delayed iputs just
    replace it with an atomic counter and a waitqueue.  This removes the
    short (or long depending on how big the inode is) window where we think
    there are no more pending iputs when there really are some.
    
    The waiting is killable as it could be indirectly called from user
    operations like fallocate or zero-range. Such call sites should handle
    the error but otherwise it's not necessary. Eg. flush_space just needs
    to attempt to make space by waiting on iputs.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ add killable comment and changelog parts ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2399f56d8a54..6e0fd98c6bd9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -934,7 +934,8 @@ struct btrfs_fs_info {
 
 	spinlock_t delayed_iput_lock;
 	struct list_head delayed_iputs;
-	struct mutex cleaner_delayed_iput_mutex;
+	atomic_t nr_delayed_iputs;
+	wait_queue_head_t delayed_iputs_wait;
 
 	/* this protects tree_mod_seq_list */
 	spinlock_t tree_mod_seq_lock;
@@ -3282,6 +3283,7 @@ int btrfs_orphan_cleanup(struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t oldsize, loff_t size);
 void btrfs_add_delayed_iput(struct inode *inode);
 void btrfs_run_delayed_iputs(struct btrfs_fs_info *fs_info);
+int btrfs_wait_on_delayed_iputs(struct btrfs_fs_info *fs_info);
 int btrfs_prealloc_file_range(struct inode *inode, int mode,
 			      u64 start, u64 num_bytes, u64 min_size,
 			      loff_t actual_len, u64 *alloc_hint);

commit 2eec5f004205be12b5a35628236b593fe1d1cbd5
Author: Anders Roxell <anders.roxell@linaro.org>
Date:   Tue Jan 29 14:01:46 2019 +0100

    btrfs: let the assertion expression compile in all configs
    
    A compiler warning (in a patch in development) pointed to a variable
    that was used only inside and ASSERT:
    
      u64 root_objectid = root->root_key.objectid;
      ASSERT(root_objectid == ...);
    
      fs/btrfs/relocation.c: In function ‘insert_dirty_subv’:
      fs/btrfs/relocation.c:2138:6: warning: unused variable ‘root_objectid’ [-Wunused-variable]
        u64 root_objectid = root->root_key.objectid;
            ^~~~~~~~~~~~~
    
    When CONFIG_BRTFS_ASSERT isn't enabled, variable root_objectid isn't used.
    
    Rework the assertion helper by adding a runtime check instead of the
    '#ifdef CONFIG_BTRFS_ASSERT #else ...", so the compiler sees the
    condition being passed into an inline function after preprocessing.
    
    Signed-off-by: Anders Roxell <anders.roxell@linaro.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 007b0e81992a..2399f56d8a54 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3518,21 +3518,18 @@ do {								\
 	rcu_read_unlock();					\
 } while (0)
 
-#ifdef CONFIG_BTRFS_ASSERT
-
 __cold
 static inline void assfail(const char *expr, const char *file, int line)
 {
-	pr_err("assertion failed: %s, file: %s, line: %d\n",
-	       expr, file, line);
-	BUG();
+	if (IS_ENABLED(CONFIG_BTRFS_ASSERT)) {
+		pr_err("assertion failed: %s, file: %s, line: %d\n",
+		       expr, file, line);
+		BUG();
+	}
 }
 
 #define ASSERT(expr)	\
 	(likely(expr) ? (void)0 : assfail(#expr, __FILE__, __LINE__))
-#else
-#define ASSERT(expr)	((void)0)
-#endif
 
 /*
  * Use that for functions that are conditionally exported for sanity tests but

commit 370a11b8114bcca3738fe6a5d7ed8babcc212f39
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:16 2019 +0800

    btrfs: qgroup: Introduce per-root swapped blocks infrastructure
    
    To allow delayed subtree swap rescan, btrfs needs to record per-root
    information about which tree blocks get swapped.  This patch introduces
    the required infrastructure.
    
    The designed workflow will be:
    
    1) Record the subtree root block that gets swapped.
    
       During subtree swap:
       O = Old tree blocks
       N = New tree blocks
             reloc tree                         subvolume tree X
                Root                               Root
               /    \                             /    \
             NA     OB                          OA      OB
           /  |     |  \                      /  |      |  \
         NC  ND     OE  OF                   OC  OD     OE  OF
    
      In this case, NA and OA are going to be swapped, record (NA, OA) into
      subvolume tree X.
    
    2) After subtree swap.
             reloc tree                         subvolume tree X
                Root                               Root
               /    \                             /    \
             OA     OB                          NA      OB
           /  |     |  \                      /  |      |  \
         OC  OD     OE  OF                   NC  ND     OE  OF
    
    3a) COW happens for OB
        If we are going to COW tree block OB, we check OB's bytenr against
        tree X's swapped_blocks structure.
        If it doesn't fit any, nothing will happen.
    
    3b) COW happens for NA
        Check NA's bytenr against tree X's swapped_blocks, and get a hit.
        Then we do subtree scan on both subtrees OA and NA.
        Resulting 6 tree blocks to be scanned (OA, OC, OD, NA, NC, ND).
    
        Then no matter what we do to subvolume tree X, qgroup numbers will
        still be correct.
        Then NA's record gets removed from X's swapped_blocks.
    
    4)  Transaction commit
        Any record in X's swapped_blocks gets removed, since there is no
        modification to swapped subtrees, no need to trigger heavy qgroup
        subtree rescan for them.
    
    This will introduce 128 bytes overhead for each btrfs_root even qgroup
    is not enabled. This is to reduce memory allocations and potential
    failures.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dd0ccc6403b0..007b0e81992a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1208,6 +1208,17 @@ enum {
 	BTRFS_ROOT_DEAD_RELOC_TREE,
 };
 
+/*
+ * Record swapped tree blocks of a subvolume tree for delayed subtree trace
+ * code. For detail check comment in fs/btrfs/qgroup.c.
+ */
+struct btrfs_qgroup_swapped_blocks {
+	spinlock_t lock;
+	/* RM_EMPTY_ROOT() of above blocks[] */
+	bool swapped;
+	struct rb_root blocks[BTRFS_MAX_LEVEL];
+};
+
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.
@@ -1343,6 +1354,9 @@ struct btrfs_root {
 	/* Number of active swapfiles */
 	atomic_t nr_swapfiles;
 
+	/* Record pairs of swapped blocks for qgroup */
+	struct btrfs_qgroup_swapped_blocks swapped_blocks;
+
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 	u64 alloc_bytenr;
 #endif

commit d2311e69857815ae2f728b48e6730f833a617092
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:14 2019 +0800

    btrfs: relocation: Delay reloc tree deletion after merge_reloc_roots
    
    Relocation code will drop btrfs_root::reloc_root as soon as
    merge_reloc_root() finishes.
    
    However later qgroup code will need to access btrfs_root::reloc_root
    after merge_reloc_root() for delayed subtree rescan.
    
    So alter the timming of resetting btrfs_root:::reloc_root, make it
    happens after transaction commit.
    
    With this patch, we will introduce a new btrfs_root::state,
    BTRFS_ROOT_DEAD_RELOC_TREE, to info part of btrfs_root::reloc_tree user
    that although btrfs_root::reloc_tree is still non-NULL, but still it's
    not used any more.
    
    The lifespan of btrfs_root::reloc tree will become:
              Old behavior            |              New
    ------------------------------------------------------------------------
    btrfs_init_reloc_root()      ---  | btrfs_init_reloc_root()      ---
      set reloc_root              |   |   set reloc_root              |
                                  |   |                               |
                                  |   |                               |
    merge_reloc_root()            |   | merge_reloc_root()            |
    |- btrfs_update_reloc_root() ---  | |- btrfs_update_reloc_root() -+-
         clear btrfs_root::reloc_root |      set ROOT_DEAD_RELOC_TREE |
                                      |      record root into dirty   |
                                      |      roots rbtree             |
                                      |                               |
                                      | reloc_block_group() Or        |
                                      | btrfs_recover_relocation()    |
                                      | | After transaction commit    |
                                      | |- clean_dirty_subvols()     ---
                                      |     clear btrfs_root::reloc_root
    
    During ROOT_DEAD_RELOC_TREE set lifespan, the only user of
    btrfs_root::reloc_tree should be qgroup.
    
    Since reloc root needs a longer life-span, this patch will also delay
    btrfs_drop_snapshot() call.
    Now btrfs_drop_snapshot() is called in clean_dirty_subvols().
    
    This patch will increase the size of btrfs_root by 16 bytes.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fecc64d8e285..dd0ccc6403b0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1199,6 +1199,13 @@ enum {
 	BTRFS_ROOT_MULTI_LOG_TASKS,
 	BTRFS_ROOT_DIRTY,
 	BTRFS_ROOT_DELETING,
+
+	/*
+	 * Reloc tree is orphan, only kept here for qgroup delayed subtree scan
+	 *
+	 * Set for the subvolume tree owning the reloc tree.
+	 */
+	BTRFS_ROOT_DEAD_RELOC_TREE,
 };
 
 /*
@@ -1311,6 +1318,14 @@ struct btrfs_root {
 	struct list_head ordered_root;
 	u64 nr_ordered_extents;
 
+	/*
+	 * Not empty if this subvolume root has gone through tree block swap
+	 * (relocation)
+	 *
+	 * Will be used by reloc_control::dirty_subvol_roots.
+	 */
+	struct list_head reloc_dirty_list;
+
 	/*
 	 * Number of currently running SEND ioctls to prevent
 	 * manipulation with the read-only status via SUBVOL_SETFLAGS

commit 4ab47a8d9ce2d0d6b73dedbda7a5ee0c545af526
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Dec 12 09:42:32 2018 +0200

    btrfs: Remove unused arguments from btrfs_get_extent_fiemap
    
    This function is a simple wrapper over btrfs_get_extent that returns
    either:
    
    a) A real extent in the passed range or
    b) Adjusted extent based on whether delalloc bytes are found backing up
       a hole.
    
    To support these semantics it doesn't need the page/pg_offset/create
    arguments which are passed to btrfs_get_extent in case an extent is to
    be created. So simplify the function by removing the unused arguments.
    No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ae0e21b7c79f..fecc64d8e285 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3181,8 +3181,7 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 
 /* inode.c */
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,
-		struct page *page, size_t pg_offset, u64 start,
-		u64 len, int create);
+					   u64 start, u64 len);
 noinline int can_nocow_extent(struct inode *inode, u64 offset, u64 *len,
 			      u64 *orig_start, u64 *orig_block_len,
 			      u64 *ram_bytes);

commit bc9a8bf79cb049eb3af26d53e6ca96dd6a881358
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Dec 19 09:50:20 2018 +0200

    btrfs: Make first argument of btrfs_run_delalloc_range directly an inode
    
    Since this function is no longer a callback there is no need to have
    its first argument obfuscated with a void *. Change it directly to a
    pointer to an inode. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7a2a2621f0d9..ae0e21b7c79f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3261,7 +3261,7 @@ int btrfs_prealloc_file_range_trans(struct inode *inode,
 				    struct btrfs_trans_handle *trans, int mode,
 				    u64 start, u64 num_bytes, u64 min_size,
 				    loff_t actual_len, u64 *alloc_hint);
-int btrfs_run_delalloc_range(void *private_data, struct page *locked_page,
+int btrfs_run_delalloc_range(struct inode *inode, struct page *locked_page,
 		u64 start, u64 end, int *page_started, unsigned long *nr_written,
 		struct writeback_control *wbc);
 int btrfs_writepage_cow_fixup(struct page *page, u64 start, u64 end);

commit 1be969f4682b0aa1995e46fba51502de55f15ce8
Merge: 315a6d850a82 fd340d0f68cc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 21 07:35:26 2019 +1300

    Merge tag 'for-5.0-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "A handful of fixes (some of them in testing for a long time):
    
       - fix some test failures regarding cleanup after transaction abort
    
       - revert of a patch that could cause a deadlock
    
       - delayed iput fixes, that can help in ENOSPC situation when there's
         low space and a lot data to write"
    
    * tag 'for-5.0-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      btrfs: wakeup cleaner thread when adding delayed iput
      btrfs: run delayed iputs before committing
      btrfs: wait on ordered extents on abort cleanup
      btrfs: handle delayed ref head accounting cleanup in abort
      Revert "btrfs: balance dirty metadata pages in btrfs_finish_ordered_io"

commit fd340d0f68cc87badfc9efcb226f23a5428826a0
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 11 10:21:02 2019 -0500

    btrfs: wakeup cleaner thread when adding delayed iput
    
    The cleaner thread usually takes care of delayed iputs, with the
    exception of the btrfs_end_transaction_throttle path.  Delaying iputs
    means we are potentially delaying the eviction of an inode and it's
    respective space.  The cleaner thread only gets woken up every 30
    seconds, or when we require space.  If there are a lot of inodes that
    need to be deleted we could induce a serious amount of latency while we
    wait for these inodes to be evicted.  So instead wakeup the cleaner if
    it's not already awake to process any new delayed iputs we add to the
    list.  If we suddenly need space we will less likely be backed up
    behind a bunch of inodes that are waiting to be deleted, and we could
    possibly free space before we need to get into the flushing logic which
    will save us some latency.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 34019c8b6158..8b1d06fa222d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -787,6 +787,9 @@ enum {
 	 * main phase. The fs_info::balance_ctl is initialized.
 	 */
 	BTRFS_FS_BALANCE_RUNNING,
+
+	/* Indicate that the cleaner thread is awake and doing something. */
+	BTRFS_FS_CLEANER_RUNNING,
 };
 
 struct btrfs_fs_info {

commit 31890da0bfdd24b135a258404b93c58a65510c7a
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Nov 21 14:05:41 2018 -0500

    btrfs: handle delayed ref head accounting cleanup in abort
    
    We weren't doing any of the accounting cleanup when we aborted
    transactions.  Fix this by making cleanup_ref_head_accounting global and
    calling it from the abort code, this fixes the issue where our
    accounting was all wrong after the fs aborts.
    
    The test generic/475 on a 2G VM can trigger the problems eg.:
    
      [ 8502.136957] WARNING: CPU: 0 PID: 11064 at fs/btrfs/extent-tree.c:5986 btrfs_free_block_grou +ps+0x3dc/0x410 [btrfs]
      [ 8502.148372] CPU: 0 PID: 11064 Comm: umount Not tainted 5.0.0-rc1-default+ #394
      [ 8502.150807] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626 +cc-prebuilt.qemu-project.org 04/01/2014
      [ 8502.154317] RIP: 0010:btrfs_free_block_groups+0x3dc/0x410 [btrfs]
      [ 8502.160623] RSP: 0018:ffffb1ab84b93de8 EFLAGS: 00010206
      [ 8502.161906] RAX: 0000000001000000 RBX: ffff9f34b1756400 RCX: 0000000000000000
      [ 8502.163448] RDX: 0000000000000002 RSI: 0000000000000001 RDI: ffff9f34b1755400
      [ 8502.164906] RBP: ffff9f34b7e8c000 R08: 0000000000000001 R09: 0000000000000000
      [ 8502.166716] R10: 0000000000000000 R11: 0000000000000001 R12: ffff9f34b7e8c108
      [ 8502.168498] R13: ffff9f34b7e8c158 R14: 0000000000000000 R15: dead000000000100
      [ 8502.170296] FS:  00007fb1cf15ffc0(0000) GS:ffff9f34bd400000(0000) knlGS:0000000000000000
      [ 8502.172439] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [ 8502.173669] CR2: 00007fb1ced507b0 CR3: 000000002f7a6000 CR4: 00000000000006f0
      [ 8502.175094] Call Trace:
      [ 8502.175759]  close_ctree+0x17f/0x350 [btrfs]
      [ 8502.176721]  generic_shutdown_super+0x64/0x100
      [ 8502.177702]  kill_anon_super+0x14/0x30
      [ 8502.178607]  btrfs_kill_super+0x12/0xa0 [btrfs]
      [ 8502.179602]  deactivate_locked_super+0x29/0x60
      [ 8502.180595]  cleanup_mnt+0x3b/0x70
      [ 8502.181406]  task_work_run+0x98/0xc0
      [ 8502.182255]  exit_to_usermode_loop+0x83/0x90
      [ 8502.183113]  do_syscall_64+0x15b/0x180
      [ 8502.183919]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Corresponding to
    
      release_global_block_rsv() {
      ...
      WARN_ON(fs_info->delayed_refs_rsv.reserved > 0);
    
    CC: stable@vger.kernel.org
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ add log dump ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f031a447a047..34019c8b6158 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -35,6 +35,7 @@
 struct btrfs_trans_handle;
 struct btrfs_transaction;
 struct btrfs_pending_snapshot;
+struct btrfs_delayed_ref_root;
 extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
@@ -2664,6 +2665,9 @@ int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   unsigned long count);
 int btrfs_async_run_delayed_refs(struct btrfs_fs_info *fs_info,
 				 unsigned long count, u64 transid, int wait);
+void btrfs_cleanup_ref_head_accounting(struct btrfs_fs_info *fs_info,
+				  struct btrfs_delayed_ref_root *delayed_refs,
+				  struct btrfs_delayed_ref_head *head);
 int btrfs_lookup_data_extent(struct btrfs_fs_info *fs_info, u64 start, u64 len);
 int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     struct btrfs_fs_info *fs_info, u64 bytenr,

commit 505b050fdf42097883b2d37b8e796e1f11dbef50
Merge: 9b286efeb5eb 718c43038f28
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 5 13:25:58 2019 -0800

    Merge branch 'mount.part1' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs mount API prep from Al Viro:
     "Mount API prereqs.
    
      Mostly that's LSM mount options cleanups. There are several minor
      fixes in there, but nothing earth-shattering (leaks on failure exits,
      mostly)"
    
    * 'mount.part1' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (27 commits)
      mount_fs: suppress MAC on MS_SUBMOUNT as well as MS_KERNMOUNT
      smack: rewrite smack_sb_eat_lsm_opts()
      smack: get rid of match_token()
      smack: take the guts of smack_parse_opts_str() into a new helper
      LSM: new method: ->sb_add_mnt_opt()
      selinux: rewrite selinux_sb_eat_lsm_opts()
      selinux: regularize Opt_... names a bit
      selinux: switch away from match_token()
      selinux: new helper - selinux_add_opt()
      LSM: bury struct security_mnt_opts
      smack: switch to private smack_mnt_opts
      selinux: switch to private struct selinux_mnt_opts
      LSM: hide struct security_mnt_opts from any generic code
      selinux: kill selinux_sb_get_mnt_opts()
      LSM: turn sb_eat_lsm_opts() into a method
      nfs_remount(): don't leak, don't ignore LSM options quietly
      btrfs: sanitize security_mnt_opts use
      selinux; don't open-code a loop in sb_finish_set_opts()
      LSM: split ->sb_set_mnt_opts() out of ->sb_kern_mount()
      new helper: security_sb_eat_lsm_opts()
      ...

commit a65001e8a4d465693d0191297a6fd864c96b3147
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Dec 10 17:19:21 2018 -0500

    btrfs: sanitize security_mnt_opts use
    
    1) keeping a copy in btrfs_fs_info is completely pointless - we never
    use it for anything.  Getting rid of that allows for simpler calling
    conventions for setup_security_options() (caller is responsible for
    freeing mnt_opts in all cases).
    
    2) on remount we want to use ->sb_remount(), not ->sb_set_mnt_opts(),
    same as we would if not for FS_BINARY_MOUNTDATA.  Behaviours *are*
    close (in fact, selinux sb_set_mnt_opts() ought to punt to
    sb_remount() in "already initialized" case), but let's handle
    that uniformly.  And the only reason why the original btrfs changes
    didn't go for security_sb_remount() in btrfs_remount() case is that
    it hadn't been exported.  Let's export it for a while - it'll be
    going away soon anyway.
    
    Reviewed-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 80953528572d..f7ec833e6c7a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1100,9 +1100,6 @@ struct btrfs_fs_info {
 	struct mutex unused_bg_unpin_mutex;
 	struct mutex delete_unused_bgs_mutex;
 
-	/* For btrfs to record security options */
-	struct security_mnt_opts security_opts;
-
 	/*
 	 * Chunks that can't be freed yet (under a trim/discard operation)
 	 * and will be latter freed. Protected by fs_info->chunk_mutex.
@@ -2959,7 +2956,6 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->free_space_root);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
-	security_free_mnt_opts(&fs_info->security_opts);
 	kvfree(fs_info);
 }
 

commit 83354f0772cd07828b0fcdf1ef2872fd2032acb8
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Nov 30 11:52:13 2018 -0500

    btrfs: catch cow on deleting snapshots
    
    When debugging some weird extent reference bug I suspected that we were
    changing a snapshot while we were deleting it, which could explain my
    bug.  This was indeed what was happening, and this patch helped me
    verify my theory.  It is never correct to modify the snapshot once it's
    being deleted, so mark the root when we are deleting it and make sure we
    complain about it when it happens.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6520e8e70b09..f031a447a047 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1197,6 +1197,7 @@ enum {
 	BTRFS_ROOT_FORCE_COW,
 	BTRFS_ROOT_MULTI_LOG_TASKS,
 	BTRFS_ROOT_DIRTY,
+	BTRFS_ROOT_DELETING,
 };
 
 /*

commit 64403612b73a94bc7b02cf8ca126e3b8ced6e921
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Dec 3 10:20:36 2018 -0500

    btrfs: rework btrfs_check_space_for_delayed_refs
    
    Now with the delayed_refs_rsv we can now know exactly how much pending
    delayed refs space we need.  This means we can drastically simplify
    btrfs_check_space_for_delayed_refs by simply checking how much space we
    have reserved for the global rsv (which acts as a spill over buffer) and
    the delayed refs rsv.  If our total size is beyond that amount then we
    know it's time to commit the transaction and stop any more delayed refs
    from being generated.
    
    With the introduction of dealyed_refs_rsv infrastructure, namely
    btrfs_update_delayed_refs_rsv we now know exactly how much pending
    delayed refs space is required.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d07a23f15e22..6520e8e70b09 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2651,7 +2651,7 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 }
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans);
-int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans);
+bool btrfs_check_space_for_delayed_refs(struct btrfs_fs_info *fs_info);
 void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
 					 const u64 start);
 void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);

commit 413df7252d5256df406a23d7efb679f46d19a23d
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Dec 3 10:20:35 2018 -0500

    btrfs: add new flushing states for the delayed refs rsv
    
    A nice thing we gain with the delayed refs rsv is the ability to flush
    the delayed refs on demand to deal with enospc pressure.  Add states to
    flush delayed refs on demand, and this will allow us to remove a lot of
    ad-hoc work around checking to see if we should commit the transaction
    to run our delayed refs.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ab9d9ed20e0c..d07a23f15e22 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2765,10 +2765,12 @@ enum btrfs_reserve_flush_enum {
 enum btrfs_flush_state {
 	FLUSH_DELAYED_ITEMS_NR	=	1,
 	FLUSH_DELAYED_ITEMS	=	2,
-	FLUSH_DELALLOC		=	3,
-	FLUSH_DELALLOC_WAIT	=	4,
-	ALLOC_CHUNK		=	5,
-	COMMIT_TRANS		=	6,
+	FLUSH_DELAYED_REFS_NR	=	3,
+	FLUSH_DELAYED_REFS	=	4,
+	FLUSH_DELALLOC		=	5,
+	FLUSH_DELALLOC_WAIT	=	6,
+	ALLOC_CHUNK		=	7,
+	COMMIT_TRANS		=	8,
 };
 
 int btrfs_alloc_data_chunk_ondemand(struct btrfs_inode *inode, u64 bytes);

commit ba2c4d4e3bda7d6de2bc616ae6715e0a0725b294
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 3 10:20:33 2018 -0500

    btrfs: introduce delayed_refs_rsv
    
    Traditionally we've had voodoo in btrfs to account for the space that
    delayed refs may take up by having a global_block_rsv.  This works most
    of the time, except when it doesn't.  We've had issues reported and seen
    in production where sometimes the global reserve is exhausted during
    transaction commit before we can run all of our delayed refs, resulting
    in an aborted transaction.  Because of this voodoo we have equally
    dubious flushing semantics around throttling delayed refs which we often
    get wrong.
    
    So instead give them their own block_rsv.  This way we can always know
    exactly how much outstanding space we need for delayed refs.  This
    allows us to make sure we are constantly filling that reservation up
    with space, and allows us to put more precise pressure on the enospc
    system.  Instead of doing math to see if its a good time to throttle,
    the normal enospc code will be invoked if we have a lot of delayed refs
    pending, and they will be run via the normal flushing mechanism.
    
    For now the delayed_refs_rsv will hold the reservations for the delayed
    refs, the block group updates, and deleting csums.  We could have a
    separate rsv for the block group updates, but the csum deletion stuff is
    still handled via the delayed_refs so that will stay there.
    
    Historical background:
    
    The global reserve has grown to cover everything we don't reserve space
    explicitly for, and we've grown a lot of weird ad-hoc heuristics to know
    if we're running short on space and when it's time to force a commit.  A
    failure rate of 20-40 file systems when we run hundreds of thousands of
    them isn't super high, but cleaning up this code will make things less
    ugly and more predictible.
    
    Thus the delayed refs rsv.  We always know how many delayed refs we have
    outstanding, and although running them generates more we can use the
    global reserve for that spill over, which fits better into it's desired
    use than a full blown reservation.  This first approach is to simply
    take how many times we're reserving space for and multiply that by 2 in
    order to save enough space for the delayed refs that could be generated.
    This is a niave approach and will probably evolve, but for now it works.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com> # high-level review
    [ added background notes from the cover letter ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5fb4cb646c82..ab9d9ed20e0c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -468,6 +468,7 @@ enum {
 	BTRFS_BLOCK_RSV_TRANS,
 	BTRFS_BLOCK_RSV_CHUNK,
 	BTRFS_BLOCK_RSV_DELOPS,
+	BTRFS_BLOCK_RSV_DELREFS,
 	BTRFS_BLOCK_RSV_EMPTY,
 	BTRFS_BLOCK_RSV_TEMP,
 };
@@ -831,6 +832,8 @@ struct btrfs_fs_info {
 	struct btrfs_block_rsv chunk_block_rsv;
 	/* block reservation for delayed operations */
 	struct btrfs_block_rsv delayed_block_rsv;
+	/* block reservation for delayed refs */
+	struct btrfs_block_rsv delayed_refs_rsv;
 
 	struct btrfs_block_rsv empty_block_rsv;
 
@@ -2816,6 +2819,13 @@ int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 void btrfs_block_rsv_release(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);
+void btrfs_delayed_refs_rsv_release(struct btrfs_fs_info *fs_info, int nr);
+void btrfs_update_delayed_refs_rsv(struct btrfs_trans_handle *trans);
+int btrfs_delayed_refs_rsv_refill(struct btrfs_fs_info *fs_info,
+				  enum btrfs_reserve_flush_enum flush);
+void btrfs_migrate_to_delayed_refs_rsv(struct btrfs_fs_info *fs_info,
+				       struct btrfs_block_rsv *src,
+				       u64 num_bytes);
 int btrfs_inc_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_dec_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);

commit 53176dde0acd8fa49c6c2e6097283acc6241480f
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 5 01:41:06 2018 +0200

    btrfs: dev-replace: remove custom read/write blocking scheme
    
    After the rw semaphore has been added, the custom blocking using
    ::blocking_readers and ::read_lock_wq is redundant.
    
    The blocking logic in __btrfs_map_block is replaced by extending the
    time the semaphore is held, that has the same blocking effect on writes
    as the previous custom scheme that waited until ::blocking_readers was
    zero.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b4f97120aecd..5fb4cb646c82 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -379,8 +379,6 @@ struct btrfs_dev_replace {
 
 	struct mutex lock_finishing_cancel_unmount;
 	struct rw_semaphore rwsem;
-	atomic_t blocking_readers;
-	wait_queue_head_t read_lock_wq;
 
 	struct btrfs_scrub_progress scrub_progress;
 

commit 129827e3001fd1e6892a0629b48f9c7c91cbb8b6
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 5 01:29:24 2018 +0200

    btrfs: dev-replace: swich locking to rw semaphore
    
    This is the first part of removing the custom locking and waiting scheme
    used for device replace. It was probably copied from extent buffer
    locking, but there's nothing that would require more than is provided by
    the common locking primitives.
    
    The rw spinlock protects waiting tasks counter in case of incompatible
    locks and the waitqueue. Same as rw semaphore.
    
    This patch only switches the locking primitive, for better
    bisectability.  There should be no functional change other than the
    overhead of the locking and potential sleeping instead of spinning when
    the lock is contended.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 81cbbb24678e..b4f97120aecd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -378,7 +378,7 @@ struct btrfs_dev_replace {
 	struct btrfs_device *tgtdev;
 
 	struct mutex lock_finishing_cancel_unmount;
-	rwlock_t lock;
+	struct rw_semaphore rwsem;
 	atomic_t blocking_readers;
 	wait_queue_head_t read_lock_wq;
 

commit bbe339cc323ca9d2a57ac203d2d9d11a09655dcc
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 15:25:13 2018 +0100

    btrfs: drop extra enum initialization where using defaults
    
    The first auto-assigned value to enum is 0, we can use that and not
    initialize all members where the auto-increment does the same. This is
    used for values that are not part of on-disk format.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 41d056010d9e..81cbbb24678e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -334,7 +334,7 @@ struct btrfs_node {
  * The slots array records the index of the item or block pointer
  * used while walking the tree.
  */
-enum { READA_NONE = 0, READA_BACK, READA_FORWARD };
+enum { READA_NONE, READA_BACK, READA_FORWARD };
 struct btrfs_path {
 	struct extent_buffer *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];
@@ -532,18 +532,18 @@ struct btrfs_free_cluster {
 };
 
 enum btrfs_caching_type {
-	BTRFS_CACHE_NO		= 0,
-	BTRFS_CACHE_STARTED	= 1,
-	BTRFS_CACHE_FAST	= 2,
-	BTRFS_CACHE_FINISHED	= 3,
-	BTRFS_CACHE_ERROR	= 4,
+	BTRFS_CACHE_NO,
+	BTRFS_CACHE_STARTED,
+	BTRFS_CACHE_FAST,
+	BTRFS_CACHE_FINISHED,
+	BTRFS_CACHE_ERROR,
 };
 
 enum btrfs_disk_cache_state {
-	BTRFS_DC_WRITTEN	= 0,
-	BTRFS_DC_ERROR		= 1,
-	BTRFS_DC_CLEAR		= 2,
-	BTRFS_DC_SETUP		= 3,
+	BTRFS_DC_WRITTEN,
+	BTRFS_DC_ERROR,
+	BTRFS_DC_CLEAR,
+	BTRFS_DC_SETUP,
 };
 
 struct btrfs_caching_control {
@@ -2621,10 +2621,10 @@ static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 /* extent-tree.c */
 
 enum btrfs_inline_ref_type {
-	BTRFS_REF_TYPE_INVALID =	 0,
-	BTRFS_REF_TYPE_BLOCK =		 1,
-	BTRFS_REF_TYPE_DATA =		 2,
-	BTRFS_REF_TYPE_ANY =		 3,
+	BTRFS_REF_TYPE_INVALID,
+	BTRFS_REF_TYPE_BLOCK,
+	BTRFS_REF_TYPE_DATA,
+	BTRFS_REF_TYPE_ANY,
 };
 
 int btrfs_get_extent_inline_ref_type(const struct extent_buffer *eb,

commit 61fa90c16b0b5efd1d5a6d1c74124c46e9138350
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 14:57:19 2018 +0100

    btrfs: switch BTRFS_ROOT_* to enums
    
    We can use simple enum for values that are not part of on-disk format:
    root tree flags.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 99f8fff8f2ae..41d056010d9e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1180,22 +1180,23 @@ struct btrfs_subvolume_writers {
 /*
  * The state of btrfs root
  */
-/*
- * btrfs_record_root_in_trans is a multi-step process,
- * and it can race with the balancing code.   But the
- * race is very small, and only the first time the root
- * is added to each transaction.  So IN_TRANS_SETUP
- * is used to tell us when more checks are required
- */
-#define BTRFS_ROOT_IN_TRANS_SETUP	0
-#define BTRFS_ROOT_REF_COWS		1
-#define BTRFS_ROOT_TRACK_DIRTY		2
-#define BTRFS_ROOT_IN_RADIX		3
-#define BTRFS_ROOT_ORPHAN_ITEM_INSERTED	4
-#define BTRFS_ROOT_DEFRAG_RUNNING	5
-#define BTRFS_ROOT_FORCE_COW		6
-#define BTRFS_ROOT_MULTI_LOG_TASKS	7
-#define BTRFS_ROOT_DIRTY		8
+enum {
+	/*
+	 * btrfs_record_root_in_trans is a multi-step process, and it can race
+	 * with the balancing code.   But the race is very small, and only the
+	 * first time the root is added to each transaction.  So IN_TRANS_SETUP
+	 * is used to tell us when more checks are required
+	 */
+	BTRFS_ROOT_IN_TRANS_SETUP,
+	BTRFS_ROOT_REF_COWS,
+	BTRFS_ROOT_TRACK_DIRTY,
+	BTRFS_ROOT_IN_RADIX,
+	BTRFS_ROOT_ORPHAN_ITEM_INSERTED,
+	BTRFS_ROOT_DEFRAG_RUNNING,
+	BTRFS_ROOT_FORCE_COW,
+	BTRFS_ROOT_MULTI_LOG_TASKS,
+	BTRFS_ROOT_DIRTY,
+};
 
 /*
  * in ram representation of the tree.  extent_root is used for all allocations

commit eb1a524c95206e41c54e8cee25a66f9488a151ef
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 14:55:46 2018 +0100

    btrfs: switch BTRFS_FS_* to enums
    
    We can use simple enum for values that are not part of on-disk format:
    internal filesystem states.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index becfe1d10e47..99f8fff8f2ae 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -757,38 +757,37 @@ struct btrfs_swapfile_pin {
 
 bool btrfs_pinned_by_swapfile(struct btrfs_fs_info *fs_info, void *ptr);
 
-#define BTRFS_FS_BARRIER			1
-#define BTRFS_FS_CLOSING_START			2
-#define BTRFS_FS_CLOSING_DONE			3
-#define BTRFS_FS_LOG_RECOVERING			4
-#define BTRFS_FS_OPEN				5
-#define BTRFS_FS_QUOTA_ENABLED			6
-#define BTRFS_FS_UPDATE_UUID_TREE_GEN		9
-#define BTRFS_FS_CREATING_FREE_SPACE_TREE	10
-#define BTRFS_FS_BTREE_ERR			11
-#define BTRFS_FS_LOG1_ERR			12
-#define BTRFS_FS_LOG2_ERR			13
-#define BTRFS_FS_QUOTA_OVERRIDE			14
-/* Used to record internally whether fs has been frozen */
-#define BTRFS_FS_FROZEN				15
-
-/*
- * Indicate that a whole-filesystem exclusive operation is running
- * (device replace, resize, device add/delete, balance)
- */
-#define BTRFS_FS_EXCL_OP			16
-
-/*
- * To info transaction_kthread we need an immediate commit so it doesn't
- * need to wait for commit_interval
- */
-#define BTRFS_FS_NEED_ASYNC_COMMIT		17
-
-/*
- * Indicate that balance has been set up from the ioctl and is in the main
- * phase. The fs_info::balance_ctl is initialized.
- */
-#define BTRFS_FS_BALANCE_RUNNING		18
+enum {
+	BTRFS_FS_BARRIER,
+	BTRFS_FS_CLOSING_START,
+	BTRFS_FS_CLOSING_DONE,
+	BTRFS_FS_LOG_RECOVERING,
+	BTRFS_FS_OPEN,
+	BTRFS_FS_QUOTA_ENABLED,
+	BTRFS_FS_UPDATE_UUID_TREE_GEN,
+	BTRFS_FS_CREATING_FREE_SPACE_TREE,
+	BTRFS_FS_BTREE_ERR,
+	BTRFS_FS_LOG1_ERR,
+	BTRFS_FS_LOG2_ERR,
+	BTRFS_FS_QUOTA_OVERRIDE,
+	/* Used to record internally whether fs has been frozen */
+	BTRFS_FS_FROZEN,
+	/*
+	 * Indicate that a whole-filesystem exclusive operation is running
+	 * (device replace, resize, device add/delete, balance)
+	 */
+	BTRFS_FS_EXCL_OP,
+	/*
+	 * To info transaction_kthread we need an immediate commit so it
+	 * doesn't need to wait for commit_interval
+	 */
+	BTRFS_FS_NEED_ASYNC_COMMIT,
+	/*
+	 * Indicate that balance has been set up from the ioctl and is in the
+	 * main phase. The fs_info::balance_ctl is initialized.
+	 */
+	BTRFS_FS_BALANCE_RUNNING,
+};
 
 struct btrfs_fs_info {
 	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];

commit 688a75b9a30a72cd944aa5e6a428a80472f44877
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 14:53:06 2018 +0100

    btrfs: switch BTRFS_BLOCK_RSV_* to enums
    
    We can use simple enum for values that are not part of on-disk format:
    block reserve types.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84ffd3163aec..becfe1d10e47 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -461,13 +461,18 @@ struct btrfs_space_info {
 	struct kobject *block_group_kobjs[BTRFS_NR_RAID_TYPES];
 };
 
-#define	BTRFS_BLOCK_RSV_GLOBAL		1
-#define	BTRFS_BLOCK_RSV_DELALLOC	2
-#define	BTRFS_BLOCK_RSV_TRANS		3
-#define	BTRFS_BLOCK_RSV_CHUNK		4
-#define	BTRFS_BLOCK_RSV_DELOPS		5
-#define	BTRFS_BLOCK_RSV_EMPTY		6
-#define	BTRFS_BLOCK_RSV_TEMP		7
+/*
+ * Types of block reserves
+ */
+enum {
+	BTRFS_BLOCK_RSV_GLOBAL,
+	BTRFS_BLOCK_RSV_DELALLOC,
+	BTRFS_BLOCK_RSV_TRANS,
+	BTRFS_BLOCK_RSV_CHUNK,
+	BTRFS_BLOCK_RSV_DELOPS,
+	BTRFS_BLOCK_RSV_EMPTY,
+	BTRFS_BLOCK_RSV_TEMP,
+};
 
 struct btrfs_block_rsv {
 	u64 size;

commit b00146b5d53c0306326eb46245901d20b69efd16
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 14:50:27 2018 +0100

    btrfs: switch BTRFS_FS_STATE_* to enums
    
    We can use simple enum for values that are not part of on-disk format:
    global filesystem states.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0ac7efd3d2b2..84ffd3163aec 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -109,13 +109,26 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 }
 
 /*
- * File system states
+ * Runtime (in-memory) states of filesystem
  */
-#define BTRFS_FS_STATE_ERROR		0
-#define BTRFS_FS_STATE_REMOUNTING	1
-#define BTRFS_FS_STATE_TRANS_ABORTED	2
-#define BTRFS_FS_STATE_DEV_REPLACING	3
-#define BTRFS_FS_STATE_DUMMY_FS_INFO	4
+enum {
+	/* Global indicator of serious filesystem errors */
+	BTRFS_FS_STATE_ERROR,
+	/*
+	 * Filesystem is being remounted, allow to skip some operations, like
+	 * defrag
+	 */
+	BTRFS_FS_STATE_REMOUNTING,
+	/* Track if a transaction abort has been reported on this filesystem */
+	BTRFS_FS_STATE_TRANS_ABORTED,
+	/*
+	 * Bio operations should be blocked on this filesystem because a source
+	 * or target device is being destroyed as part of a device replace
+	 */
+	BTRFS_FS_STATE_DEV_REPLACING,
+	/* The btrfs_fs_info created for self-tests */
+	BTRFS_FS_STATE_DUMMY_FS_INFO,
+};
 
 #define BTRFS_BACKREF_REV_MAX		256
 #define BTRFS_BACKREF_REV_SHIFT		56

commit da12fe5414f922d896289f037515096f189c66da
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Nov 27 20:57:58 2018 +0200

    btrfs: Refactor btrfs_merge_bio_hook
    
    This function really checks whether adding more data to the bio will
    straddle a stripe/chunk. So first let's give it a more appropraite name
    - btrfs_bio_fits_in_stripe. Secondly, the offset parameter was never
    used to just remove it. Thirdly, pages are submitted to either btree or
    data inodes so it's guaranteed that tree->ops is set so replace the
    check with an ASSERT. Finally, document the parameters of the function.
    No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d2a930279a1a..0ac7efd3d2b2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3191,9 +3191,8 @@ void btrfs_merge_delalloc_extent(struct inode *inode, struct extent_state *new,
 				 struct extent_state *other);
 void btrfs_split_delalloc_extent(struct inode *inode,
 				 struct extent_state *orig, u64 split);
-int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
-			 size_t size, struct bio *bio,
-			 unsigned long bio_flags);
+int btrfs_bio_fits_in_stripe(struct page *page, size_t size, struct bio *bio,
+			     unsigned long bio_flags);
 void btrfs_set_range_writeback(struct extent_io_tree *tree, u64 start, u64 end);
 vm_fault_t btrfs_page_mkwrite(struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);

commit de37aa513105f864d3c21105bf5542d498f21ca2
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 30 16:43:24 2018 +0200

    btrfs: Remove fsid/metadata_fsid fields from btrfs_info
    
    Currently btrfs_fs_info structure contains a copy of the
    fsid/metadata_uuid fields. Same values are also contained in the
    btrfs_fs_devices structure which fs_info has a reference to. Let's
    reduce duplication by removing the fields from fs_info and always refer
    to the ones in fs_devices. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f8429cd8afb6..d2a930279a1a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -773,10 +773,6 @@ bool btrfs_pinned_by_swapfile(struct btrfs_fs_info *fs_info, void *ptr);
 #define BTRFS_FS_BALANCE_RUNNING		18
 
 struct btrfs_fs_info {
-	/* User-visible fs UUID */
-	u8 fsid[BTRFS_FSID_SIZE];
-	/* UUID written to btree blocks */
-	u8 metadata_fsid[BTRFS_FSID_SIZE];
 	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
 	unsigned long flags;
 	struct btrfs_root *extent_root;

commit 7239ff4b2be8ec0c3160da7fdd1475785fdb4cb9
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 30 16:43:23 2018 +0200

    btrfs: Introduce support for FSID change without metadata rewrite
    
    This field is going to be used when the user wants to change the UUID
    of the filesystem without having to rewrite all metadata blocks. This
    field adds another level of indirection such that when the FSID is
    changed what really happens is the current UUID (the one with which the
    fs was created) is copied to the 'metadata_uuid' field in the superblock
    as well as a new incompat flag is set METADATA_UUID. When the kernel
    detects this flag is set it knows that the superblock in fact has 2
    UUIDs:
    
    1. Is the UUID which is user-visible, currently known as FSID.
    2. Metadata UUID - this is the UUID which is stamped into all on-disk
       datastructures belonging to this file system.
    
    When the new incompat flag is present device scanning checks whether
    both fsid/metadata_uuid of the scanned device match any of the
    registered filesystems. When the flag is not set then both UUIDs are
    equal and only the FSID is retained on disk, metadata_uuid is set only
    in-memory during mount.
    
    Additionally a new metadata_uuid field is also added to the fs_info
    struct. It's initialised either with the FSID in case METADATA_UUID
    incompat flag is not set or with the metdata_uuid of the superblock
    otherwise.
    
    This commit introduces the new fields as well as the new incompat flag
    and switches all users of the fsid to the new logic.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor updates in comments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 83f0d98c9d5d..f8429cd8afb6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -195,9 +195,10 @@ struct btrfs_root_backup {
  * it currently lacks any block count etc etc
  */
 struct btrfs_super_block {
-	u8 csum[BTRFS_CSUM_SIZE];
 	/* the first 4 fields must match struct btrfs_header */
-	u8 fsid[BTRFS_FSID_SIZE];    /* FS specific uuid */
+	u8 csum[BTRFS_CSUM_SIZE];
+	/* FS specific UUID, visible to user */
+	u8 fsid[BTRFS_FSID_SIZE];
 	__le64 bytenr; /* this block number */
 	__le64 flags;
 
@@ -234,8 +235,11 @@ struct btrfs_super_block {
 	__le64 cache_generation;
 	__le64 uuid_tree_generation;
 
+	/* the UUID written into btree blocks */
+	u8 metadata_uuid[BTRFS_FSID_SIZE];
+
 	/* future expansion */
-	__le64 reserved[30];
+	__le64 reserved[28];
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 	struct btrfs_root_backup super_roots[BTRFS_NUM_BACKUP_ROOTS];
 } __attribute__ ((__packed__));
@@ -265,7 +269,8 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_RAID56 |		\
 	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF |		\
 	 BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA |	\
-	 BTRFS_FEATURE_INCOMPAT_NO_HOLES)
+	 BTRFS_FEATURE_INCOMPAT_NO_HOLES	|	\
+	 BTRFS_FEATURE_INCOMPAT_METADATA_UUID)
 
 #define BTRFS_FEATURE_INCOMPAT_SAFE_SET			\
 	(BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF)
@@ -768,7 +773,10 @@ bool btrfs_pinned_by_swapfile(struct btrfs_fs_info *fs_info, void *ptr);
 #define BTRFS_FS_BALANCE_RUNNING		18
 
 struct btrfs_fs_info {
+	/* User-visible fs UUID */
 	u8 fsid[BTRFS_FSID_SIZE];
+	/* UUID written to btree blocks */
+	u8 metadata_fsid[BTRFS_FSID_SIZE];
 	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
 	unsigned long flags;
 	struct btrfs_root *extent_root;

commit f8f591df7d725e3b1ea97e13ac830791b7c4a038
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Nov 19 10:38:16 2018 +0100

    btrfs: introduce EXPORT_FOR_TESTS macro
    
    Depending on whether CONFIG_BTRFS_FS_RUN_SANITY_TESTS is set, some BTRFS
    functions are either local to the file they are implemented in and thus
    should be declared static or are called from within the test
    implementation defined in a different file.
    
    Introduce an EXPORT_FOR_TESTS macro which depending on
    CONFIG_BTRFS_FS_RUN_SANITY_TESTS either adds the 'static' keyword to a
    function or not.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e62824cae00a..83f0d98c9d5d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3471,6 +3471,16 @@ static inline void assfail(const char *expr, const char *file, int line)
 #define ASSERT(expr)	((void)0)
 #endif
 
+/*
+ * Use that for functions that are conditionally exported for sanity tests but
+ * otherwise static
+ */
+#ifndef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+#define EXPORT_FOR_TESTS static
+#else
+#define EXPORT_FOR_TESTS
+#endif
+
 __cold
 static inline void btrfs_print_v0_err(struct btrfs_fs_info *fs_info)
 {

commit 3cd24c698004d2f7668e0eb9fc1f096f533c791b
Author: Ethan Lien <ethanlien@synology.com>
Date:   Thu Nov 1 14:49:03 2018 +0800

    btrfs: use tagged writepage to mitigate livelock of snapshot
    
    Snapshot is expected to be fast. But if there are writers steadily
    creating dirty pages in our subvolume, the snapshot may take a very long
    time to complete. To fix the problem, we use tagged writepage for
    snapshot flusher as we do in the generic write_cache_pages(), so we can
    omit pages dirtied after the snapshot command.
    
    This does not change the semantics regarding which data get to the
    snapshot, if there are pages being dirtied during the snapshotting
    operation.  There's a sync called before snapshot is taken in old/new
    case, any IO in flight just after that may be in the snapshot but this
    depends on other system effects that might still sync the IO.
    
    We do a simple snapshot speed test on a Intel D-1531 box:
    
    fio --ioengine=libaio --iodepth=32 --bs=4k --rw=write --size=64G
    --direct=0 --thread=1 --numjobs=1 --time_based --runtime=120
    --filename=/mnt/sub/testfile --name=job1 --group_reporting & sleep 5;
    time btrfs sub snap -r /mnt/sub /mnt/snap; killall fio
    
    original: 1m58sec
    patched:  6.54sec
    
    This is the best case for this patch since for a sequential write case,
    we omit nearly all pages dirtied after the snapshot command.
    
    For a multi writers, random write test:
    
    fio --ioengine=libaio --iodepth=32 --bs=4k --rw=randwrite --size=64G
    --direct=0 --thread=1 --numjobs=4 --time_based --runtime=120
    --filename=/mnt/sub/testfile --name=job1 --group_reporting & sleep 5;
    time btrfs sub snap -r /mnt/sub /mnt/snap; killall fio
    
    original: 15.83sec
    patched:  10.35sec
    
    The improvement is smaller compared to the sequential write case,
    since we omit only half of the pages dirtied after snapshot command.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Ethan Lien <ethanlien@synology.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c48fcaf4004d..e62824cae00a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3170,7 +3170,7 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       struct inode *inode, u64 new_size,
 			       u32 min_type);
 
-int btrfs_start_delalloc_inodes(struct btrfs_root *root);
+int btrfs_start_delalloc_snapshot(struct btrfs_root *root);
 int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int nr);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      unsigned int extra_bits,

commit c629732d247e253e811a7ef6667a53349ae5a0ab
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 8 10:18:08 2018 +0200

    btrfs: Remove unused extent_state argument from btrfs_writepage_endio_finish_ordered
    
    This parameter was never used, yet was part of the interface of the
    function ever since its introduction as extent_io_ops::writepage_end_io_hook
    in e6dcd2dc9c48 ("Btrfs: New data=ordered implementation"). Now that
    NULL is passed everywhere as a value for this parameter let's remove it
    for good. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8b41ec42f405..c48fcaf4004d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3179,7 +3179,7 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root,
 			     struct btrfs_root *parent_root,
 			     u64 new_dirid);
-void btrfs_set_delalloc_extent(struct inode *inode, struct extent_state *state,
+ void btrfs_set_delalloc_extent(struct inode *inode, struct extent_state *state,
 			       unsigned *bits);
 void btrfs_clear_delalloc_extent(struct inode *inode,
 				 struct extent_state *state, unsigned *bits);
@@ -3231,7 +3231,7 @@ int btrfs_run_delalloc_range(void *private_data, struct page *locked_page,
 		struct writeback_control *wbc);
 int btrfs_writepage_cow_fixup(struct page *page, u64 start, u64 end);
 void btrfs_writepage_endio_finish_ordered(struct page *page, u64 start,
-		u64 end, struct extent_state *state, int uptodate);
+					  u64 end, int uptodate);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit eede2bf34f4fa84ce82e36878ccdd0fdc4b1463c
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Nov 3 10:28:12 2016 -0700

    Btrfs: prevent ioctls from interfering with a swap file
    
    A later patch will implement swap file support for Btrfs, but before we
    do that, we need to make sure that the various Btrfs ioctls cannot
    change a swap file.
    
    When a swap file is active, we must make sure that the extents of the
    file are not moved and that they don't become shared. That means that
    the following are not safe:
    
    - chattr +c (enable compression)
    - reflink
    - dedupe
    - snapshot
    - defrag
    
    Don't allow those to happen on an active swap file.
    
    Additionally, balance, resize, device remove, and device replace are
    also unsafe if they affect an active swapfile. Add a red-black tree of
    block groups and devices which contain an active swapfile. Relocation
    checks each block group against this tree and skips it or errors out for
    balance or resize, respectively. Device remove and device replace check
    the tree for the device they will operate on.
    
    Note that we don't have to worry about chattr -C (disable nocow), which
    we ignore for non-empty files, because an active swapfile must be
    non-empty and can't be truncated. We also don't have to worry about
    autodefrag because it's only done on COW files. Truncate and fallocate
    are already taken care of by the generic code. Device add doesn't do
    relocation so it's not an issue, either.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9025bab58e81..8b41ec42f405 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -712,6 +712,28 @@ struct btrfs_fs_devices;
 struct btrfs_balance_control;
 struct btrfs_delayed_root;
 
+/*
+ * Block group or device which contains an active swapfile. Used for preventing
+ * unsafe operations while a swapfile is active.
+ *
+ * These are sorted on (ptr, inode) (note that a block group or device can
+ * contain more than one swapfile). We compare the pointer values because we
+ * don't actually care what the object is, we just need a quick check whether
+ * the object exists in the rbtree.
+ */
+struct btrfs_swapfile_pin {
+	struct rb_node node;
+	void *ptr;
+	struct inode *inode;
+	/*
+	 * If true, ptr points to a struct btrfs_block_group_cache. Otherwise,
+	 * ptr points to a struct btrfs_device.
+	 */
+	bool is_block_group;
+};
+
+bool btrfs_pinned_by_swapfile(struct btrfs_fs_info *fs_info, void *ptr);
+
 #define BTRFS_FS_BARRIER			1
 #define BTRFS_FS_CLOSING_START			2
 #define BTRFS_FS_CLOSING_DONE			3
@@ -1114,6 +1136,10 @@ struct btrfs_fs_info {
 	u32 sectorsize;
 	u32 stripesize;
 
+	/* Block groups and devices containing active swapfiles. */
+	spinlock_t swapfile_pins_lock;
+	struct rb_root swapfile_pins;
+
 #ifdef CONFIG_BTRFS_FS_REF_VERIFY
 	spinlock_t ref_verify_lock;
 	struct rb_root block_tree;
@@ -1274,6 +1300,9 @@ struct btrfs_root {
 	u64 qgroup_meta_rsv_pertrans;
 	u64 qgroup_meta_rsv_prealloc;
 
+	/* Number of active swapfiles */
+	atomic_t nr_swapfiles;
+
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 	u64 alloc_bytenr;
 #endif

commit abbb55f4cd56dffb20ba7dd8dfc53154c79934f1
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:53 2018 +0200

    btrfs: Remove extent_io_ops::split_extent_hook callback
    
    This is the counterpart to merge_extent_hook, similarly, it's used only
    for data/freespace inodes so let's remove it, rename it and call it
    directly where necessary. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a75887d1fe3f..9025bab58e81 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3156,6 +3156,8 @@ void btrfs_clear_delalloc_extent(struct inode *inode,
 				 struct extent_state *state, unsigned *bits);
 void btrfs_merge_delalloc_extent(struct inode *inode, struct extent_state *new,
 				 struct extent_state *other);
+void btrfs_split_delalloc_extent(struct inode *inode,
+				 struct extent_state *orig, u64 split);
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);

commit 5c848198aad3ad1c68309aa7002fa571a540568c
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:52 2018 +0200

    btrfs: Remove extent_io_ops::merge_extent_hook callback
    
    This callback is used only for data and free space inodes. Such inodes
    are guaranteed to have their extent_io_tree::private_data set to the
    inode struct. Exploit this fact to directly call the function. Also give
    it a more descriptive name. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 18ed4643cde1..a75887d1fe3f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3154,6 +3154,8 @@ void btrfs_set_delalloc_extent(struct inode *inode, struct extent_state *state,
 			       unsigned *bits);
 void btrfs_clear_delalloc_extent(struct inode *inode,
 				 struct extent_state *state, unsigned *bits);
+void btrfs_merge_delalloc_extent(struct inode *inode, struct extent_state *new,
+				 struct extent_state *other);
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);

commit a36bb5f9a90c9bab05b7084d21718450e8067fb0
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:51 2018 +0200

    btrfs: Remove extent_io_ops::clear_bit_hook callback
    
    This is the counterpart to ex-set_bit_hook (now btrfs_set_delalloc_extent),
    similar to what was done before remove clear_bit_hook and rename the
    function. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9a0e4e1c59ea..18ed4643cde1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3152,6 +3152,8 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     u64 new_dirid);
 void btrfs_set_delalloc_extent(struct inode *inode, struct extent_state *state,
 			       unsigned *bits);
+void btrfs_clear_delalloc_extent(struct inode *inode,
+				 struct extent_state *state, unsigned *bits);
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);

commit e06a1fc99cc7eca09118cc02c4d7540fa69e9d09
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:50 2018 +0200

    btrfs: Remove extent_io_ops::set_bit_hook extent_io callback
    
    This callback is used to properly account delalloc extents for data
    inodes (ordinary file inodes and freespace v1 inodes). Those can be
    easily identified since they have their extent_io trees ->private_data
    member point to the inode. Let's exploit this fact to remove the
    needless indirection through extent_io_hooks and directly call the
    function. Also give the function a name which reflects its purpose -
    btrfs_set_delalloc_extent.
    
    This patch also modified test_find_delalloc so that the extent_io_tree
    used for testing doesn't have its ->private_data set which would have
    caused a crash in btrfs_set_delalloc_extent due to the btrfs_inode->root
    member not being initialised. The old version of the code also didn't
    call set_bit_hook since the extent_io ops weren't set for the inode.  No
    functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index edcbca9cd813..9a0e4e1c59ea 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3150,6 +3150,8 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root,
 			     struct btrfs_root *parent_root,
 			     u64 new_dirid);
+void btrfs_set_delalloc_extent(struct inode *inode, struct extent_state *state,
+			       unsigned *bits);
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);

commit 7087a9d8db88ef9b7f8a30ac5706aa396b78e6c9
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:48 2018 +0200

    btrfs: Remove extent_io_ops::writepage_end_io_hook
    
    This callback is ony ever called for data page writeout so there is no
    need to actually abstract it via extent_io_ops. Lets just export it,
    remove the definition of the callback and call it directly in the
    functions that invoke the callback. Also rename the function to
    btrfs_writepage_endio_finish_ordered since what it really does is
    account finished io in the ordered extent data structures.  No
    functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a10240f5910f..edcbca9cd813 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3193,6 +3193,8 @@ int btrfs_run_delalloc_range(void *private_data, struct page *locked_page,
 		u64 start, u64 end, int *page_started, unsigned long *nr_written,
 		struct writeback_control *wbc);
 int btrfs_writepage_cow_fixup(struct page *page, u64 start, u64 end);
+void btrfs_writepage_endio_finish_ordered(struct page *page, u64 start,
+		u64 end, struct extent_state *state, int uptodate);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit d75855b4518b525dbba4e461819b26bc5bb89a82
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:47 2018 +0200

    btrfs: Remove extent_io_ops::writepage_start_hook
    
    This hook is called only from __extent_writepage_io which is already
    called only from the data page writeout path. So there is no need to
    make an indirect call via extent_io_ops. This patch just removes the
    callback definition, exports the callback function and calls it directly
    at the only call site. Also give the function a more descriptive name.
    No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3a4d19e6a8e9..a10240f5910f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3192,6 +3192,7 @@ int btrfs_prealloc_file_range_trans(struct inode *inode,
 int btrfs_run_delalloc_range(void *private_data, struct page *locked_page,
 		u64 start, u64 end, int *page_started, unsigned long *nr_written,
 		struct writeback_control *wbc);
+int btrfs_writepage_cow_fixup(struct page *page, u64 start, u64 end);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit 5eaad97af8aeff38debe7d3c69ec3a0d71f8350f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:46 2018 +0200

    btrfs: Remove extent_io_ops::fill_delalloc
    
    This callback is called only from writepage_delalloc which in turn is
    guaranteed to be called from the data page writeout path. In the end
    there is no reason to have the call to this function to be indrected via
    the extent_io_ops structure. This patch removes the callback definition,
    exports the function and calls it directly. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ rename to btrfs_run_delalloc_range ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 68f322f600a0..3a4d19e6a8e9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3189,6 +3189,9 @@ int btrfs_prealloc_file_range_trans(struct inode *inode,
 				    struct btrfs_trans_handle *trans, int mode,
 				    u64 start, u64 num_bytes, u64 min_size,
 				    loff_t actual_len, u64 *alloc_hint);
+int btrfs_run_delalloc_range(void *private_data, struct page *locked_page,
+		u64 start, u64 end, int *page_started, unsigned long *nr_written,
+		struct writeback_control *wbc);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit 63a42e1a5cb3d01eef2f370c11d8733a32f12f86
Merge: c140f8b072d1 d6fd0ae25c64
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 11 16:54:38 2018 -0600

    Merge tag 'for-4.20-rc1-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "Several fixes to recent release (4.19, fixes tagged for stable) and
      other fixes"
    
    * tag 'for-4.20-rc1-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      Btrfs: fix missing delayed iputs on unmount
      Btrfs: fix data corruption due to cloning of eof block
      Btrfs: fix infinite loop on inode eviction after deduplication of eof block
      Btrfs: fix deadlock on tree root leaf when finding free extent
      btrfs: avoid link error with CONFIG_NO_AUTO_INLINE
      btrfs: tree-checker: Fix misleading group system information
      Btrfs: fix missing data checksums after a ranged fsync (msync)
      btrfs: fix pinned underflow after transaction aborted
      Btrfs: fix cur_offset in the error case for nocow

commit 4222ea7100c0e37adace2790c8822758bbeee179
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Oct 24 10:13:03 2018 +0100

    Btrfs: fix deadlock on tree root leaf when finding free extent
    
    When we are writing out a free space cache, during the transaction commit
    phase, we can end up in a deadlock which results in a stack trace like the
    following:
    
     schedule+0x28/0x80
     btrfs_tree_read_lock+0x8e/0x120 [btrfs]
     ? finish_wait+0x80/0x80
     btrfs_read_lock_root_node+0x2f/0x40 [btrfs]
     btrfs_search_slot+0xf6/0x9f0 [btrfs]
     ? evict_refill_and_join+0xd0/0xd0 [btrfs]
     ? inode_insert5+0x119/0x190
     btrfs_lookup_inode+0x3a/0xc0 [btrfs]
     ? kmem_cache_alloc+0x166/0x1d0
     btrfs_iget+0x113/0x690 [btrfs]
     __lookup_free_space_inode+0xd8/0x150 [btrfs]
     lookup_free_space_inode+0x5b/0xb0 [btrfs]
     load_free_space_cache+0x7c/0x170 [btrfs]
     ? cache_block_group+0x72/0x3b0 [btrfs]
     cache_block_group+0x1b3/0x3b0 [btrfs]
     ? finish_wait+0x80/0x80
     find_free_extent+0x799/0x1010 [btrfs]
     btrfs_reserve_extent+0x9b/0x180 [btrfs]
     btrfs_alloc_tree_block+0x1b3/0x4f0 [btrfs]
     __btrfs_cow_block+0x11d/0x500 [btrfs]
     btrfs_cow_block+0xdc/0x180 [btrfs]
     btrfs_search_slot+0x3bd/0x9f0 [btrfs]
     btrfs_lookup_inode+0x3a/0xc0 [btrfs]
     ? kmem_cache_alloc+0x166/0x1d0
     btrfs_update_inode_item+0x46/0x100 [btrfs]
     cache_save_setup+0xe4/0x3a0 [btrfs]
     btrfs_start_dirty_block_groups+0x1be/0x480 [btrfs]
     btrfs_commit_transaction+0xcb/0x8b0 [btrfs]
    
    At cache_save_setup() we need to update the inode item of a block group's
    cache which is located in the tree root (fs_info->tree_root), which means
    that it may result in COWing a leaf from that tree. If that happens we
    need to find a free metadata extent and while looking for one, if we find
    a block group which was not cached yet we attempt to load its cache by
    calling cache_block_group(). However this function will try to load the
    inode of the free space cache, which requires finding the matching inode
    item in the tree root - if that inode item is located in the same leaf as
    the inode item of the space cache we are updating at cache_save_setup(),
    we end up in a deadlock, since we try to obtain a read lock on the same
    extent buffer that we previously write locked.
    
    So fix this by using the tree root's commit root when searching for a
    block group's free space cache inode item when we are attempting to load
    a free space cache. This is safe since block groups once loaded stay in
    memory forever, as well as their caches, so after they are first loaded
    we will never need to read their inode items again. For new block groups,
    once they are created they get their ->cached field set to
    BTRFS_CACHE_FINISHED meaning we will not need to read their inode item.
    
    Reported-by: Andrew Nelson <andrew.s.nelson@gmail.com>
    Link: https://lore.kernel.org/linux-btrfs/CAPTELenq9x5KOWuQ+fa7h1r3nsJG8vyiTH8+ifjURc_duHh2Wg@mail.gmail.com/
    Fixes: 9d66e233c704 ("Btrfs: load free space cache if it exists")
    Tested-by: Andrew Nelson <andrew.s.nelson@gmail.com>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 68ca41dbbef3..f7f955109d8b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3163,6 +3163,9 @@ void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);
 int __init btrfs_init_cachep(void);
 void __cold btrfs_destroy_cachep(void);
+struct inode *btrfs_iget_path(struct super_block *s, struct btrfs_key *location,
+			      struct btrfs_root *root, int *new,
+			      struct btrfs_path *path);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root, int *was_new);
 struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,

commit c2aa1a444cab2c673650ada80a7dffc4345ce2e6
Merge: b69f9e17a57a bf4a1fcf0bc1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 2 09:33:08 2018 -0700

    Merge tag 'xfs-4.20-merge-2' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux
    
    Pull vfs dedup fixes from Dave Chinner:
     "This reworks the vfs data cloning infrastructure.
    
      We discovered many issues with these interfaces late in the 4.19 cycle
      - the worst of them (data corruption, setuid stripping) were fixed for
      XFS in 4.19-rc8, but a larger rework of the infrastructure fixing all
      the problems was needed. That rework is the contents of this pull
      request.
    
      Rework the vfs_clone_file_range and vfs_dedupe_file_range
      infrastructure to use a common .remap_file_range method and supply
      generic bounds and sanity checking functions that are shared with the
      data write path. The current VFS infrastructure has problems with
      rlimit, LFS file sizes, file time stamps, maximum filesystem file
      sizes, stripping setuid bits, etc and so they are addressed in these
      commits.
    
      We also introduce the ability for the ->remap_file_range methods to
      return short clones so that clones for vfs_copy_file_range() don't get
      rejected if the entire range can't be cloned. It also allows
      filesystems to sliently skip deduplication of partial EOF blocks if
      they are not capable of doing so without requiring errors to be thrown
      to userspace.
    
      Existing filesystems are converted to user the new remap_file_range
      method, and both XFS and ocfs2 are modified to make use of the new
      generic checking infrastructure"
    
    * tag 'xfs-4.20-merge-2' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux: (28 commits)
      xfs: remove [cm]time update from reflink calls
      xfs: remove xfs_reflink_remap_range
      xfs: remove redundant remap partial EOF block checks
      xfs: support returning partial reflink results
      xfs: clean up xfs_reflink_remap_blocks call site
      xfs: fix pagecache truncation prior to reflink
      ocfs2: remove ocfs2_reflink_remap_range
      ocfs2: support partial clone range and dedupe range
      ocfs2: fix pagecache truncation prior to reflink
      ocfs2: truncate page cache for clone destination file before remapping
      vfs: clean up generic_remap_file_range_prep return value
      vfs: hide file range comparison function
      vfs: enable remap callers that can handle short operations
      vfs: plumb remap flags through the vfs dedupe functions
      vfs: plumb remap flags through the vfs clone functions
      vfs: make remap_file_range functions take and return bytes completed
      vfs: remap helper should update destination inode metadata
      vfs: pass remap flags to generic_remap_checks
      vfs: pass remap flags to generic_remap_file_range_prep
      vfs: combine the clone and dedupe into a single remap_file_range
      ...

commit 42ec3d4c02187a18e27ff94b409ec27234bf2ffd
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Tue Oct 30 10:41:49 2018 +1100

    vfs: make remap_file_range functions take and return bytes completed
    
    Change the remap_file_range functions to take a number of bytes to
    operate upon and return the number of bytes they operated on.  This is a
    requirement for allowing fs implementations to return short clone/dedupe
    results to the user, which will enable us to obey resource limits in a
    graceful manner.
    
    A subsequent patch will enable copy_file_range to signal to the
    ->clone_file_range implementation that it can handle a short length,
    which will be returned in the function's return value.  For now the
    short return is not implemented anywhere so the behavior won't change --
    either copy_file_range manages to clone the entire range or it tries an
    alternative.
    
    Neither clone ioctl can take advantage of this, alas.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Dave Chinner <david@fromorbit.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 124a05662fc2..771a961d77ad 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3247,9 +3247,9 @@ int btrfs_dirty_pages(struct inode *inode, struct page **pages,
 		      size_t num_pages, loff_t pos, size_t write_bytes,
 		      struct extent_state **cached);
 int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
-int btrfs_remap_file_range(struct file *file_in, loff_t pos_in,
-			   struct file *file_out, loff_t pos_out, u64 len,
-			   unsigned int remap_flags);
+loff_t btrfs_remap_file_range(struct file *file_in, loff_t pos_in,
+			      struct file *file_out, loff_t pos_out,
+			      loff_t len, unsigned int remap_flags);
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,

commit 2e5dfc99f2e61c42083ba742395e7a7b353513d1
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Tue Oct 30 10:41:21 2018 +1100

    vfs: combine the clone and dedupe into a single remap_file_range
    
    Combine the clone_file_range and dedupe_file_range operations into a
    single remap_file_range file operation dispatch since they're
    fundamentally the same operation.  The differences between the two can
    be made in the prep functions.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Amir Goldstein <amir73il@gmail.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dave Chinner <david@fromorbit.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2cddfe7806a4..124a05662fc2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3218,9 +3218,6 @@ void btrfs_get_block_group_info(struct list_head *groups_list,
 				struct btrfs_ioctl_space_info *space);
 void btrfs_update_ioctl_balance_args(struct btrfs_fs_info *fs_info,
 			       struct btrfs_ioctl_balance_args *bargs);
-int btrfs_dedupe_file_range(struct file *src_file, loff_t src_loff,
-			    struct file *dst_file, loff_t dst_loff,
-			    u64 olen);
 
 /* file.c */
 int __init btrfs_auto_defrag_init(void);
@@ -3250,8 +3247,9 @@ int btrfs_dirty_pages(struct inode *inode, struct page **pages,
 		      size_t num_pages, loff_t pos, size_t write_bytes,
 		      struct extent_state **cached);
 int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
-int btrfs_clone_file_range(struct file *file_in, loff_t pos_in,
-			   struct file *file_out, loff_t pos_out, u64 len);
+int btrfs_remap_file_range(struct file *file_in, loff_t pos_in,
+			   struct file *file_out, loff_t pos_out, u64 len,
+			   unsigned int remap_flags);
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,

commit 7c8616278b19c42141ff4617573cbf950f4a456b
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Thu Oct 11 13:40:36 2018 +0800

    btrfs: remove fs_info from btrfs_should_throttle_delayed_refs
    
    The avg_delayed_ref_runtime can be referenced from the transaction
    handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4002c9fd924b..68ca41dbbef3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2598,8 +2598,7 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
-int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,
-				       struct btrfs_fs_info *fs_info);
+int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans);
 int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans);
 void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
 					 const u64 start);

commit af9b8a0e2085fc90dca85acd85ee83ece7c05130
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Thu Oct 11 13:40:35 2018 +0800

    btrfs: remove fs_info from btrfs_check_space_for_delayed_refs
    
    It can be referenced from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 15c659f23411..4002c9fd924b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2600,8 +2600,7 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,
 				       struct btrfs_fs_info *fs_info);
-int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans,
-				       struct btrfs_fs_info *fs_info);
+int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans);
 void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
 					 const u64 start);
 void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);

commit 523983401644ebeb331c923c28c9591c07430a7d
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Wed Aug 22 05:54:37 2018 +0800

    Btrfs: kill btrfs_clear_path_blocking
    
    Btrfs's btree locking has two modes, spinning mode and blocking mode,
    while searching btree, locking is always acquired in spinning mode and
    then converted to blocking mode if necessary, and in some hot paths we may
    switch the locking back to spinning mode by btrfs_clear_path_blocking().
    
    When acquiring locks, both of reader and writer need to wait for blocking
    readers and writers to complete before doing read_lock()/write_lock().
    
    The problem is that btrfs_clear_path_blocking() needs to switch nodes
    in the path to blocking mode at first (by btrfs_set_path_blocking) to
    make lockdep happy before doing its actual clearing blocking job.
    
    When switching to blocking mode from spinning mode, it consists of
    
    step 1) bumping up blocking readers counter and
    step 2) read_unlock()/write_unlock(),
    
    this has caused serious ping-pong effect if there're a great amount of
    concurrent readers/writers, as waiters will be woken up and go to
    sleep immediately.
    
    1) Killing this kind of ping-pong results in a big improvement in my 1600k
    files creation script,
    
    MNT=/mnt/btrfs
    mkfs.btrfs -f /dev/sdf
    mount /dev/def $MNT
    time fsmark  -D  10000  -S0  -n  100000  -s  0  -L  1 -l /tmp/fs_log.txt \
            -d  $MNT/0  -d  $MNT/1 \
            -d  $MNT/2  -d  $MNT/3 \
            -d  $MNT/4  -d  $MNT/5 \
            -d  $MNT/6  -d  $MNT/7 \
            -d  $MNT/8  -d  $MNT/9 \
            -d  $MNT/10  -d  $MNT/11 \
            -d  $MNT/12  -d  $MNT/13 \
            -d  $MNT/14  -d  $MNT/15
    
    w/o patch:
    real    2m27.307s
    user    0m12.839s
    sys     13m42.831s
    
    w/ patch:
    real    1m2.273s
    user    0m15.802s
    sys     8m16.495s
    
    1.1) latency histogram from funclatency[1]
    
    Overall with the patch, there're ~50% less write lock acquisition and
    the 95% max latency that write lock takes also reduces to ~100ms from
    >500ms.
    
    --------------------------------------------
    w/o patch:
    --------------------------------------------
    Function = btrfs_tree_lock
         msecs               : count     distribution
             0 -> 1          : 2385222  |****************************************|
             2 -> 3          : 37147    |                                        |
             4 -> 7          : 20452    |                                        |
             8 -> 15         : 13131    |                                        |
            16 -> 31         : 3877     |                                        |
            32 -> 63         : 3900     |                                        |
            64 -> 127        : 2612     |                                        |
           128 -> 255        : 974      |                                        |
           256 -> 511        : 165      |                                        |
           512 -> 1023       : 13       |                                        |
    
    Function = btrfs_tree_read_lock
         msecs               : count     distribution
             0 -> 1          : 6743860  |****************************************|
             2 -> 3          : 2146     |                                        |
             4 -> 7          : 190      |                                        |
             8 -> 15         : 38       |                                        |
            16 -> 31         : 4        |                                        |
    
    --------------------------------------------
    w/ patch:
    --------------------------------------------
    Function = btrfs_tree_lock
         msecs               : count     distribution
             0 -> 1          : 1318454  |****************************************|
             2 -> 3          : 6800     |                                        |
             4 -> 7          : 3664     |                                        |
             8 -> 15         : 2145     |                                        |
            16 -> 31         : 809      |                                        |
            32 -> 63         : 219      |                                        |
            64 -> 127        : 10       |                                        |
    
    Function = btrfs_tree_read_lock
         msecs               : count     distribution
             0 -> 1          : 6854317  |****************************************|
             2 -> 3          : 2383     |                                        |
             4 -> 7          : 601      |                                        |
             8 -> 15         : 92       |                                        |
    
    2) dbench also proves the improvement,
    dbench -t 120 -D /mnt/btrfs 16
    
    w/o patch:
    Throughput 158.363 MB/sec
    
    w/ patch:
    Throughput 449.52 MB/sec
    
    3) xfstests didn't show any additional failures.
    
    One thing to note is that callers may set path->leave_spinning to have
    all nodes in the path stay in spinning mode, which means callers are
    ready to not sleep before releasing the path, but it won't cause
    problems if they don't want to sleep in blocking mode.
    
    [1]: https://github.com/iovisor/bcc/blob/master/tools/funclatency.py
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e8244c0b0597..15c659f23411 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2868,8 +2868,6 @@ void btrfs_release_path(struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
 void btrfs_set_path_blocking(struct btrfs_path *p);
-void btrfs_clear_path_blocking(struct btrfs_path *p,
-			       struct extent_buffer *held, int held_rw);
 void btrfs_unlock_up_safe(struct btrfs_path *p, int level);
 
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,

commit 7f8d236ae132a8886a0186008c828e21f7460474
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 5 01:04:49 2018 +0200

    btrfs: dev-replace: move replace members out of fs_info
    
    The replace_wait and bio_counter were mistakenly added to fs_info in
    commit c404e0dc2c843b154f ("Btrfs: fix use-after-free in the finishing
    procedure of the device replace"), but they logically belong to
    fs_info::dev_replace. Besides, bio_counter is a very generic name and is
    confusing in bare fs_info context.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index daa273c7e150..e8244c0b0597 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -365,6 +365,9 @@ struct btrfs_dev_replace {
 	wait_queue_head_t read_lock_wq;
 
 	struct btrfs_scrub_progress scrub_progress;
+
+	struct percpu_counter bio_counter;
+	wait_queue_head_t replace_wait;
 };
 
 /* For raid type sysfs entries */
@@ -1087,9 +1090,6 @@ struct btrfs_fs_info {
 	/* device replace state */
 	struct btrfs_dev_replace dev_replace;
 
-	struct percpu_counter bio_counter;
-	wait_queue_head_t replace_wait;
-
 	struct semaphore uuid_tree_rescan_sem;
 
 	/* Used to reclaim the metadata space in the background. */

commit 3280f874576d31b03fe19cbcc23585d96feb4ceb
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 17:32:29 2018 +0200

    btrfs: remove btrfs_dev_replace::read_locks
    
    This member seems to be copied from the extent_buffer locking scheme and
    is at least used to assert that the read lock/unlock is properly nested.
    In some way. While the _inc/_dec are called inside the read lock
    section, the asserts are both inside and outside, so the ordering is not
    guaranteed and we can see read/inc/dec ordered in any way
    (theoretically).
    
    A missing call of btrfs_dev_replace_clear_lock_blocking could cause
    unexpected read_locks count, so this at least looks like a valid
    assertion, but this will become unnecessary with later updates.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 36ade217e462..daa273c7e150 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -361,7 +361,6 @@ struct btrfs_dev_replace {
 
 	struct mutex lock_finishing_cancel_unmount;
 	rwlock_t lock;
-	atomic_t read_locks;
 	atomic_t blocking_readers;
 	wait_queue_head_t read_lock_wq;
 

commit b2fa11547bc1693a8dd8e7379dd4e43d31f49c50
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 17 17:48:13 2018 +0200

    btrfs: tests: polish ifdefs around testing helper
    
    Avoid the inline ifdefs and use two sections for self-tests enabled and
    disabled.
    
    Though there could be no ifdef and unconditional test_bit of
    BTRFS_FS_STATE_DUMMY_FS_INFO, the static inline can help to optimize out
    any code that would depend on conditions using btrfs_is_testing.
    
    As this is only for the testing code, drop unlikely().
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4653c87d0ff5..36ade217e462 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3706,17 +3706,17 @@ static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 void btrfs_test_inode_set_ops(struct inode *inode);
 void btrfs_test_destroy_inode(struct inode *inode);
-#endif
 
 static inline int btrfs_is_testing(struct btrfs_fs_info *fs_info)
 {
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-	if (unlikely(test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO,
-			      &fs_info->fs_state)))
-		return 1;
-#endif
+	return test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO, &fs_info->fs_state);
+}
+#else
+static inline int btrfs_is_testing(struct btrfs_fs_info *fs_info)
+{
 	return 0;
 }
+#endif
 
 static inline void cond_wake_up(struct wait_queue_head *wq)
 {

commit a654666a3474312ee76aa2bb9744376a46da3307
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 17 17:44:13 2018 +0200

    btrfs: tests: group declarations of self-test helpers
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0e637cfc90d1..4653c87d0ff5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3192,9 +3192,6 @@ int btrfs_prealloc_file_range_trans(struct inode *inode,
 				    u64 start, u64 num_bytes, u64 min_size,
 				    loff_t actual_len, u64 *alloc_hint);
 extern const struct dentry_operations btrfs_dentry_operations;
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-void btrfs_test_inode_set_ops(struct inode *inode);
-#endif
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
@@ -3707,6 +3704,7 @@ static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
 
 /* Sanity test specific functions */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+void btrfs_test_inode_set_ops(struct inode *inode);
 void btrfs_test_destroy_inode(struct inode *inode);
 #endif
 

commit 57ec5fb478a3c27073ebc8f8f47a91eaaa083c13
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 17 17:38:12 2018 +0200

    btrfs: tests: move testing members of struct btrfs_root to the end
    
    The data used only for tests are better placed at the end of the
    structure so that they don't change the structure layout. All new
    members of btrfs_root should be placed before.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f4d5eeb2be20..0e637cfc90d1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1202,11 +1202,6 @@ struct btrfs_root {
 
 	u64 highest_objectid;
 
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-	/* only used with CONFIG_BTRFS_FS_RUN_SANITY_TESTS is enabled */
-	u64 alloc_bytenr;
-#endif
-
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
@@ -1279,6 +1274,10 @@ struct btrfs_root {
 	spinlock_t qgroup_meta_rsv_lock;
 	u64 qgroup_meta_rsv_pertrans;
 	u64 qgroup_meta_rsv_prealloc;
+
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+	u64 alloc_bytenr;
+#endif
 };
 
 struct btrfs_file_private {

commit 9c36396c2a788facd4282a2b0646a1c4ac19847a
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 17 17:28:06 2018 +0200

    btrfs: tests: add separate stub for find_lock_delalloc_range
    
    The helper find_lock_delalloc_range is now conditionally built static,
    dpending on whether the self-tests are enabled or not. There's a macro
    that is supposed to hide the export, used only once. To discourage
    further use, drop it an add a public wrapper for the helper needed by
    tests.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 441610de9908..f4d5eeb2be20 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -41,12 +41,6 @@ extern struct kmem_cache *btrfs_path_cachep;
 extern struct kmem_cache *btrfs_free_space_cachep;
 struct btrfs_ordered_sum;
 
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-#define STATIC noinline
-#else
-#define STATIC static noinline
-#endif
-
 #define BTRFS_MAGIC 0x4D5F53665248425FULL /* ascii _BHRfS_M, no null */
 
 #define BTRFS_MAX_MIRRORS 3

commit de2c6615dcddf2af868c5cbd1db2e9e73b4beb58
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Sat Aug 25 13:47:59 2018 +0800

    Btrfs: fix alignment in declaration and prototype of btrfs_get_extent
    
    This fixes btrfs_get_extent to be consistent with our existing
    declaration style.
    
    Note: For the record, indentation styles that are accepted are both,
    aligning under the opening ( and tab or double tab indentation on the
    next line.  Preferrably not spliting the type or long expressions in the
    argument lists.
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    [ add note ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 923ac6cb9784..441610de9908 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3178,8 +3178,8 @@ void __cold btrfs_destroy_cachep(void);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root, int *was_new);
 struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,
-		struct page *page, size_t pg_offset,
-		u64 start, u64 end, int create);
+				    struct page *page, size_t pg_offset,
+				    u64 start, u64 end, int create);
 int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode);

commit 4fd786e6c3d67b1348e0ad4f450efe9fc9d7a306
Author: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Mon Aug 6 14:25:24 2018 +0900

    btrfs: Remove 'objectid' member from struct btrfs_root
    
    There are two members in struct btrfs_root which indicate root's
    objectid: objectid and root_key.objectid.
    
    They are both set to the same value in __setup_root():
    
      static void __setup_root(struct btrfs_root *root,
                               struct btrfs_fs_info *fs_info,
                               u64 objectid)
      {
        ...
        root->objectid = objectid;
        ...
        root->root_key.objectid = objecitd;
        ...
      }
    
    and not changed to other value after initialization.
    
    grep in btrfs directory shows both are used in many places:
      $ grep -rI "root->root_key.objectid" | wc -l
      133
      $ grep -rI "root->objectid" | wc -l
      55
     (4.17, inc. some noise)
    
    It is confusing to have two similar variable names and it seems
    that there is no rule about which should be used in a certain case.
    
    Since ->root_key itself is needed for tree reloc tree, let's remove
    'objecitd' member and unify code to use ->root_key.objectid in all places.
    
    Signed-off-by: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index df260a9867be..923ac6cb9784 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1202,7 +1202,6 @@ struct btrfs_root {
 	int last_log_commit;
 	pid_t log_start_pid;
 
-	u64 objectid;
 	u64 last_trans;
 
 	u32 type;

commit 684572df940181b070760bf027a6ded6b7b55c3d
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Sat Aug 4 21:10:57 2018 +0800

    btrfs: Remove root parameter from btrfs_insert_dir_item
    
    All callers pass the root tree of dir, we can push that down to the
    function itself.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3dd4d0cb0c7e..df260a9867be 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3021,8 +3021,7 @@ int btrfs_uuid_tree_iterate(struct btrfs_fs_info *fs_info,
 /* dir-item.c */
 int btrfs_check_dir_item_collision(struct btrfs_root *root, u64 dir,
 			  const char *name, int name_len);
-int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root, const char *name,
+int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, const char *name,
 			  int name_len, struct btrfs_inode *dir,
 			  struct btrfs_key *location, u8 type, u64 index);
 struct btrfs_dir_item *btrfs_lookup_dir_item(struct btrfs_trans_handle *trans,

commit 3a58417486ca99a3bfef40e309f38adb45a5171d
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Sat Aug 4 21:10:55 2018 +0800

    btrfs: switch update_size to bool in btrfs_block_rsv_migrate and btrfs_rsv_add_bytes
    
    Using true and false here is closer to the expected semantic than using
    0 and 1.  No functional change.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2cddfe7806a4..3dd4d0cb0c7e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2771,7 +2771,7 @@ int btrfs_block_rsv_refill(struct btrfs_root *root,
 			   enum btrfs_reserve_flush_enum flush);
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 			    struct btrfs_block_rsv *dst_rsv, u64 num_bytes,
-			    int update_size);
+			    bool update_size);
 int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *dest, u64 num_bytes,
 			     int min_factor);

commit 5404525b98c2fa18b8bd47047f9bf2e67825c857
Merge: b36fdc6853a3 b6fdfbff0789
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 6 09:04:45 2018 -0700

    Merge tag 'for-4.19-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
    
     - fix for improper fsync after hardlink
    
     - fix for a corruption during file deduplication
    
     - use after free fixes
    
     - RCU warning fix
    
     - fix for buffered write to nodatacow file
    
    * tag 'for-4.19-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      btrfs: Fix suspicious RCU usage warning in btrfs_debug_in_rcu
      btrfs: use after free in btrfs_quota_enable
      btrfs: btrfs_shrink_device should call commit transaction at the end
      btrfs: fix qgroup_free wrong num_bytes in btrfs_subvolume_reserve_metadata
      Btrfs: fix data corruption when deduplicating between different files
      Btrfs: sync log after logging new name
      Btrfs: fix unexpected failure of nocow buffered writes after snapshotting when low on space

commit b6fdfbff078975c53383fc146a2a54985eab6b6d
Author: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Fri Aug 24 11:35:28 2018 +0900

    btrfs: Fix suspicious RCU usage warning in btrfs_debug_in_rcu
    
    Commit 672d599041c8 ("btrfs: Use wrapper macro for rcu string to remove
    duplicate code") replaces some open coded RCU string handling with macro.
    
    It turns out that btrfs_debug_in_rcu() is used for the first time and
    the macro lacks lock/unlock of RCU string for non-debug case (i.e. when
    the message is not printed), leading to suspicious RCU usage warning
    when CONFIG_PROVE_RCU is on.
    
    Fix this by adding a wrapper to call lock/unlock for the non-debug case
    too.
    
    Fixes: 672d599041c8 ("btrfs: Use wrapper macro for rcu string to remove duplicate code")
    Reported-by: David Howells <dhowells@redhat.com>
    Tested-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a67cc190a84b..0b856da2fd3b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3390,9 +3390,9 @@ do {									\
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_in_rcu(fs_info, fmt, args...) \
-	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
+	btrfs_no_printk_in_rcu(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl_in_rcu(fs_info, fmt, args...) \
-	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
+	btrfs_no_printk_in_rcu(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl(fs_info, fmt, args...) \
 	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
 #endif
@@ -3404,6 +3404,13 @@ do {							\
 	rcu_read_unlock();				\
 } while (0)
 
+#define btrfs_no_printk_in_rcu(fs_info, fmt, args...)	\
+do {							\
+	rcu_read_lock();				\
+	btrfs_no_printk(fs_info, fmt, ##args);		\
+	rcu_read_unlock();				\
+} while (0)
+
 #define btrfs_printk_ratelimited(fs_info, fmt, args...)		\
 do {								\
 	static DEFINE_RATELIMIT_STATE(_rs,			\

commit d9a185f8b49678775ef56ecbdbc7b76970302897
Merge: c22fc16d172f 989974c80457
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 21 18:19:09 2018 -0700

    Merge tag 'ovl-update-4.19' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs
    
    Pull overlayfs updates from Miklos Szeredi:
     "This contains two new features:
    
       - Stack file operations: this allows removal of several hacks from
         the VFS, proper interaction of read-only open files with copy-up,
         possibility to implement fs modifying ioctls properly, and others.
    
       - Metadata only copy-up: when file is on lower layer and only
         metadata is modified (except size) then only copy up the metadata
         and continue to use the data from the lower file"
    
    * tag 'ovl-update-4.19' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs: (66 commits)
      ovl: Enable metadata only feature
      ovl: Do not do metacopy only for ioctl modifying file attr
      ovl: Do not do metadata only copy-up for truncate operation
      ovl: add helper to force data copy-up
      ovl: Check redirect on index as well
      ovl: Set redirect on upper inode when it is linked
      ovl: Set redirect on metacopy files upon rename
      ovl: Do not set dentry type ORIGIN for broken hardlinks
      ovl: Add an inode flag OVL_CONST_INO
      ovl: Treat metacopy dentries as type OVL_PATH_MERGE
      ovl: Check redirects for metacopy files
      ovl: Move some dir related ovl_lookup_single() code in else block
      ovl: Do not expose metacopy only dentry from d_real()
      ovl: Open file with data except for the case of fsync
      ovl: Add helper ovl_inode_realdata()
      ovl: Store lower data inode in ovl_inode
      ovl: Fix ovl_getattr() to get number of blocks from lower
      ovl: Add helper ovl_dentry_lowerdata() to get lower data dentry
      ovl: Copy up meta inode data from lowest data inode
      ovl: Modify ovl_lookup() and friends to lookup metacopy dentry
      ...

commit 8ecebf4d767e2307a946c8905278d6358eda35c3
Author: Robbie Ko <robbieko@synology.com>
Date:   Mon Aug 6 10:30:30 2018 +0800

    Btrfs: fix unexpected failure of nocow buffered writes after snapshotting when low on space
    
    Commit e9894fd3e3b3 ("Btrfs: fix snapshot vs nocow writting") forced
    nocow writes to fallback to COW, during writeback, when a snapshot is
    created. This resulted in writes made before creating the snapshot to
    unexpectedly fail with ENOSPC during writeback when success (0) was
    returned to user space through the write system call.
    
    The steps leading to this problem are:
    
    1. When it's not possible to allocate data space for a write, the
       buffered write path checks if a NOCOW write is possible.  If it is,
       it will not reserve space and success (0) is returned to user space.
    
    2. Then when a snapshot is created, the root's will_be_snapshotted
       atomic is incremented and writeback is triggered for all inode's that
       belong to the root being snapshotted. Incrementing that atomic forces
       all previous writes to fallback to COW during writeback (running
       delalloc).
    
    3. This results in the writeback for the inodes to fail and therefore
       setting the ENOSPC error in their mappings, so that a subsequent
       fsync on them will report the error to user space. So it's not a
       completely silent data loss (since fsync will report ENOSPC) but it's
       a very unexpected and undesirable behaviour, because if a clean
       shutdown/unmount of the filesystem happens without previous calls to
       fsync, it is expected to have the data present in the files after
       mounting the filesystem again.
    
    So fix this by adding a new atomic named snapshot_force_cow to the
    root structure which prevents this behaviour and works the following way:
    
    1. It is incremented when we start to create a snapshot after triggering
       writeback and before waiting for writeback to finish.
    
    2. This new atomic is now what is used by writeback (running delalloc)
       to decide whether we need to fallback to COW or not. Because we
       incremented this new atomic after triggering writeback in the
       snapshot creation ioctl, we ensure that all buffered writes that
       happened before snapshot creation will succeed and not fallback to
       COW (which would make them fail with ENOSPC).
    
    3. The existing atomic, will_be_snapshotted, is kept because it is used
       to force new buffered writes, that start after we started
       snapshotting, to reserve data space even when NOCOW is possible.
       This makes these writes fail early with ENOSPC when there's no
       available space to allocate, preventing the unexpected behaviour of
       writeback later failing with ENOSPC due to a fallback to COW mode.
    
    Fixes: e9894fd3e3b3 ("Btrfs: fix snapshot vs nocow writting")
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 318be7864072..a67cc190a84b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1280,6 +1280,7 @@ struct btrfs_root {
 	int send_in_progress;
 	struct btrfs_subvolume_writers *subv_writers;
 	atomic_t will_be_snapshotted;
+	atomic_t snapshot_force_cow;
 
 	/* For qgroup metadata reserved space */
 	spinlock_t qgroup_meta_rsv_lock;

commit 85c39548199b966062578fb99d4d4ecdeae2afae
Author: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Thu Jul 26 11:40:54 2018 +0900

    btrfs: extent-tree: Remove unused __btrfs_free_block_rsv
    
    There is no user of this function anymore.
    
    This was forgotten to be removed in commit a575ceeb1338
    ("Btrfs: get rid of unused orphan infrastructure").
    
    Signed-off-by: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c275ea258f9a..318be7864072 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2761,7 +2761,6 @@ void btrfs_init_metadata_block_rsv(struct btrfs_fs_info *fs_info,
 				   unsigned short type);
 void btrfs_free_block_rsv(struct btrfs_fs_info *fs_info,
 			  struct btrfs_block_rsv *rsv);
-void __btrfs_free_block_rsv(struct btrfs_block_rsv *rsv);
 int btrfs_block_rsv_add(struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv, u64 num_bytes,
 			enum btrfs_reserve_flush_enum flush);

commit 6025c19fb208e93b99eafc304e7f16160e49fc88
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Aug 1 11:32:29 2018 +0800

    btrfs: Remove fs_info from btrfs_add_root_ref
    
    It can be referenced from the passed transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3677082ddf4c..c275ea258f9a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2984,10 +2984,9 @@ void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
 int btrfs_old_root_level(struct btrfs_root *root, u64 time_seq);
 
 /* root-item.c */
-int btrfs_add_root_ref(struct btrfs_trans_handle *trans,
-		       struct btrfs_fs_info *fs_info,
-		       u64 root_id, u64 ref_id, u64 dirid, u64 sequence,
-		       const char *name, int name_len);
+int btrfs_add_root_ref(struct btrfs_trans_handle *trans, u64 root_id,
+		       u64 ref_id, u64 dirid, u64 sequence, const char *name,
+		       int name_len);
 int btrfs_del_root_ref(struct btrfs_trans_handle *trans, u64 root_id,
 		       u64 ref_id, u64 dirid, u64 *sequence, const char *name,
 		       int name_len);

commit 3ee1c5530e649182e602eb2f81193289c4d2e655
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Aug 1 11:32:28 2018 +0800

    btrfs: Remove fs_info from btrfs_del_root_ref
    
    It can be referenced from the passed transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9ef47a171e2f..3677082ddf4c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2988,10 +2988,9 @@ int btrfs_add_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_fs_info *fs_info,
 		       u64 root_id, u64 ref_id, u64 dirid, u64 sequence,
 		       const char *name, int name_len);
-int btrfs_del_root_ref(struct btrfs_trans_handle *trans,
-		       struct btrfs_fs_info *fs_info,
-		       u64 root_id, u64 ref_id, u64 dirid, u64 *sequence,
-		       const char *name, int name_len);
+int btrfs_del_root_ref(struct btrfs_trans_handle *trans, u64 root_id,
+		       u64 ref_id, u64 dirid, u64 *sequence, const char *name,
+		       int name_len);
 int btrfs_del_root(struct btrfs_trans_handle *trans,
 		   const struct btrfs_key *key);
 int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,

commit ab9ce7d42bf66f0750a4ca4a228a2db238376afb
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Aug 1 11:32:27 2018 +0800

    btrfs: Remove fs_info from btrfs_del_root
    
    It can be referenced from the passed transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e32584c635f..9ef47a171e2f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2993,7 +2993,7 @@ int btrfs_del_root_ref(struct btrfs_trans_handle *trans,
 		       u64 root_id, u64 ref_id, u64 dirid, u64 *sequence,
 		       const char *name, int name_len);
 int btrfs_del_root(struct btrfs_trans_handle *trans,
-		   struct btrfs_fs_info *fs_info, const struct btrfs_key *key);
+		   const struct btrfs_key *key);
 int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		      const struct btrfs_key *key,
 		      struct btrfs_root_item *item);

commit 2ffad70ed3b6fbc946bc102f9d11c0e7c1cd380f
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jul 20 16:30:23 2018 +0200

    btrfs: constify strings passed to assertion helper
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5f6ec80d374f..2e32584c635f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3425,7 +3425,7 @@ do {								\
 #ifdef CONFIG_BTRFS_ASSERT
 
 __cold
-static inline void assfail(char *expr, char *file, int line)
+static inline void assfail(const char *expr, const char *file, int line)
 {
 	pr_err("assertion failed: %s, file: %s, line: %d\n",
 	       expr, file, line);

commit e9539cff04728e31e150b41000b828745fc0c2b3
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jul 20 16:30:20 2018 +0200

    btrfs: dev-replace: remove unused members of btrfs_dev_replace
    
    Lock owner and nesting level have been unused since day 1, probably
    copy&pasted from the extent_buffer locking scheme without much thinking.
    The locking of device replace is simpler and does not need any lock
    nesting.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4ca6c4e141ea..5f6ec80d374f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -365,8 +365,6 @@ struct btrfs_dev_replace {
 	struct btrfs_device *srcdev;
 	struct btrfs_device *tgtdev;
 
-	pid_t lock_owner;
-	atomic_t nesting_level;
 	struct mutex lock_finishing_cancel_unmount;
 	rwlock_t lock;
 	atomic_t read_locks;

commit e17385ca2960177da402d6f4d80bdc5b53c29bc4
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jul 20 16:30:18 2018 +0200

    btrfs: remove unused member btrfs_root::name
    
    Added in 58176a9604c ("Btrfs: Add per-root block accounting and sysfs
    entries") in 2007, the roots had names exported in sysfs. The code
    was commented out in 4df27c4d5cc1dda54ed ("Btrfs: change how subvolumes
    are organized") and cleaned by 182608c8294b5fe9 ("btrfs: remove old
    unused commented out code").
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9c638931b75e..4ca6c4e141ea 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1219,7 +1219,6 @@ struct btrfs_root {
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
-	char *name;
 
 	/* the dirty list is only used by non-reference counted roots */
 	struct list_head dirty_list;

commit 5cdc84bfde22dc17b11ee7cb18cebd48f4a09f70
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 20:32:52 2018 +0200

    btrfs: drop extent_io_ops::set_range_writeback callback
    
    The data and metadata callback implementation both use the same
    function. We can remove the call indirection and intermediate helper
    completely.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ee1e152cb94b..9c638931b75e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3172,7 +3172,7 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);
-void btrfs_set_range_writeback(void *private_data, u64 start, u64 end);
+void btrfs_set_range_writeback(struct extent_io_tree *tree, u64 start, u64 end);
 vm_fault_t btrfs_page_mkwrite(struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);

commit 031f24da2c8a7b611331c368d7bfabccafda09fa
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue May 22 16:43:47 2018 +0800

    btrfs: Use btrfs_mark_bg_unused to replace open code
    
    Introduce a small helper, btrfs_mark_bg_unused(), to acquire locks and
    add a block group to unused_bgs list.
    
    No functional modification, and only 3 callers are involved.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bf1451bf3ed7..ee1e152cb94b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2801,6 +2801,7 @@ void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans, const u64 type);
 u64 add_new_free_space(struct btrfs_block_group_cache *block_group,
 		       u64 start, u64 end);
+void btrfs_mark_bg_unused(struct btrfs_block_group_cache *bg);
 
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, const struct btrfs_key *key,

commit dec59fa3a760952fc71f2e122e66a7291109670a
Author: Ethan Lien <ethanlien@synology.com>
Date:   Fri Jul 13 16:50:42 2018 +0800

    btrfs: use customized batch size for total_bytes_pinned
    
    In commit b150a4f10d878 ("Btrfs: use a percpu to keep track of possibly
    pinned bytes") we use total_bytes_pinned to track how many bytes we are
    going to free in this transaction. When we are close to ENOSPC, we check it
    and know if we can make the allocation by commit the current transaction.
    For every data/metadata extent we are going to free, we add
    total_bytes_pinned in btrfs_free_extent() and btrfs_free_tree_block(), and
    release it in unpin_extent_range() when we finish the transaction. So this
    is a variable we frequently update but rarely read - just the suitable
    use of percpu_counter. But in previous commit we update total_bytes_pinned
    by default 32 batch size, making every update essentially a spin lock
    protected update. Since every spin lock/unlock operation involves syncing
    a globally used variable and some kind of barrier in a SMP system, this is
    more expensive than using total_bytes_pinned as a simple atomic64_t.
    
    So fix this by using a customized batch size. Since we only read
    total_bytes_pinned when we are close to ENOSPC and fail to allocate new
    chunk, we can use a really large batch size and have nearly no penalty
    in most cases.
    
    [Test]
    We tested the patch on a 4-cores x86 machine:
    
    1. fallocate a 16GiB size test file
    2. take snapshot (so all following writes will be COW)
    3. run a 180 sec, 4 jobs, 4K random write fio on test file
    
    We also added a temporary lockdep class on percpu_counter's spin lock
    used by total_bytes_pinned to track it by lock_stat.
    
    [Results]
    unpatched:
    lock_stat version 0.4
    -----------------------------------------------------------------------
                                  class name    con-bounces    contentions
    waittime-min   waittime-max waittime-total   waittime-avg    acq-bounces
    acquisitions   holdtime-min   holdtime-max holdtime-total   holdtime-avg
    
                   total_bytes_pinned_percpu:            82             82
            0.21           0.61          29.46           0.36         298340
          635973           0.09          11.01      173476.25           0.27
    
    patched:
    lock_stat version 0.4
    -----------------------------------------------------------------------
                                  class name    con-bounces    contentions
    waittime-min   waittime-max waittime-total   waittime-avg    acq-bounces
    acquisitions   holdtime-min   holdtime-max holdtime-total   holdtime-avg
    
                   total_bytes_pinned_percpu:             1              1
            0.62           0.62           0.62           0.62          13601
           31542           0.14           9.61       11016.90           0.35
    
    [Analysis]
    Since the spin lock only protects a single in-memory variable, the
    contentions (number of lock acquisitions that had to wait) in both
    unpatched and patched version are low. But when we see acquisitions and
    acq-bounces, we get much lower counts in patched version. Here the most
    important metric is acq-bounces. It means how many times the lock gets
    transferred between different cpus, so the patch can really reduce
    cacheline bouncing of spin lock (also the global counter of percpu_counter)
    in a SMP system.
    
    Fixes: b150a4f10d878 ("Btrfs: use a percpu to keep track of possibly pinned bytes")
    Signed-off-by: Ethan Lien <ethanlien@synology.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 427ca5de8542..bf1451bf3ed7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -84,6 +84,14 @@ static const int btrfs_csum_sizes[] = { 4 };
 
 #define BTRFS_DIRTY_METADATA_THRESH	SZ_32M
 
+/*
+ * Use large batch size to reduce overhead of metadata updates.  On the reader
+ * side, we only read it when we are close to ENOSPC and the read overhead is
+ * mostly related to the number of CPUs, so it is OK to use arbitrary large
+ * value here.
+ */
+#define BTRFS_TOTAL_BYTES_PINNED_BATCH	SZ_128M
+
 #define BTRFS_MAX_EXTENT_SIZE SZ_128M
 
 

commit ba3c2b196bf59ba8574808fe6f8fd88d0fed7510
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Jun 26 16:57:36 2018 +0300

    btrfs: Add graceful handling of V0 extents
    
    Following the removal of the v0 handling code let's be courteous and
    print an error message when such extents are handled. In the cases
    where we have a transaction just abort it, otherwise just call
    btrfs_handle_fs_error. Both cases result in the FS being re-mounted RO.
    
    In case the error handling would be too intrusive, leave the BUG_ON in
    place, like extent_data_ref_count, other proper handling would catch
    that earlier.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9fa958ed065e..427ca5de8542 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3432,6 +3432,13 @@ static inline void assfail(char *expr, char *file, int line)
 #define ASSERT(expr)	((void)0)
 #endif
 
+__cold
+static inline void btrfs_print_v0_err(struct btrfs_fs_info *fs_info)
+{
+	btrfs_err(fs_info,
+"Unsupported V0 extent filesystem detected. Aborting. Please re-create your filesystem with a newer kernel");
+}
+
 __printf(5, 6)
 __cold
 void __btrfs_handle_fs_error(struct btrfs_fs_info *fs_info, const char *function,

commit a79865c680d81220a1355cd13098e75227dc2994
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Jun 21 09:45:00 2018 +0300

    btrfs: Remove V0 extent support
    
    The v0 compat code was introduced in commit 5d4f98a28c7d
    ("Btrfs: Mixed back reference  (FORWARD ROLLING FORMAT CHANGE)") 9
    years ago, which was merged in 2.6.31. This means that the code is
    there to support filesystems which are _VERY_ old and if you are using
    btrfs on such an old kernel, you have much bigger problems. This coupled
    with the fact that no one is likely testing/maintining this code likely
    means it has bugs lurking. All things considered I think 43 kernel
    releases later it's high time this remnant of the past got removed.
    
    This patch removes all code wrapped in #ifdefs but leaves the BUG_ONs in case
    we have a v0 with no support intact as a sort of safety-net.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 41ba770b9db9..9fa958ed065e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -55,8 +55,6 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_OLDEST_GENERATION	0ULL
 
-#define BTRFS_COMPAT_EXTENT_TREE_V0
-
 /*
  * the max metadata block size.  This limit is somewhat artificial,
  * but the memmove costs go through the roof for larger blocks.

commit e41ca5897489b1c18af75ff0cc8f5c80260b3281
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jun 6 15:41:49 2018 +0800

    btrfs: Get rid of the confusing btrfs_file_extent_inline_len
    
    We used to call btrfs_file_extent_inline_len() to get the uncompressed
    data size of an inlined extent.
    
    However this function is hiding evil, for compressed extent, it has no
    choice but to directly read out ram_bytes from btrfs_file_extent_item.
    While for uncompressed extent, it uses item size to calculate the real
    data size, and ignoring ram_bytes completely.
    
    In fact, for corrupted ram_bytes, due to above behavior kernel
    btrfs_print_leaf() can't even print correct ram_bytes to expose the bug.
    
    Since we have the tree-checker to verify all EXTENT_DATA, such mismatch
    can be detected pretty easily, thus we can trust ram_bytes without the
    evil btrfs_file_extent_inline_len().
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 12cb327cd16e..41ba770b9db9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2428,32 +2428,6 @@ static inline u32 btrfs_file_extent_inline_item_len(
 	return btrfs_item_size(eb, e) - BTRFS_FILE_EXTENT_INLINE_DATA_START;
 }
 
-/* this returns the number of file bytes represented by the inline item.
- * If an item is compressed, this is the uncompressed size
- */
-static inline u32 btrfs_file_extent_inline_len(const struct extent_buffer *eb,
-					int slot,
-					const struct btrfs_file_extent_item *fi)
-{
-	struct btrfs_map_token token;
-
-	btrfs_init_map_token(&token);
-	/*
-	 * return the space used on disk if this item isn't
-	 * compressed or encoded
-	 */
-	if (btrfs_token_file_extent_compression(eb, fi, &token) == 0 &&
-	    btrfs_token_file_extent_encryption(eb, fi, &token) == 0 &&
-	    btrfs_token_file_extent_other_encoding(eb, fi, &token) == 0) {
-		return btrfs_file_extent_inline_item_len(eb,
-							 btrfs_item_nr(slot));
-	}
-
-	/* otherwise use the ram bytes field */
-	return btrfs_token_file_extent_ram_bytes(eb, fi, &token);
-}
-
-
 /* btrfs_dev_stats_item */
 static inline u64 btrfs_dev_stats_value(const struct extent_buffer *eb,
 					const struct btrfs_dev_stats_item *ptr,

commit 43a7e99db6788110fb2bd97bdad5aa5c0c004aff
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 20 15:49:15 2018 +0300

    btrfs: Remove fs_info from btrfs_force_chunk_alloc
    
    It can be referenced from the passed transaction handle.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5bb083de8f2c..12cb327cd16e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2809,8 +2809,7 @@ int btrfs_error_unpin_extent_range(struct btrfs_fs_info *fs_info,
 				   u64 start, u64 end);
 int btrfs_discard_extent(struct btrfs_fs_info *fs_info, u64 bytenr,
 			 u64 num_bytes, u64 *actual_bytes);
-int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
-			    struct btrfs_fs_info *fs_info, u64 type);
+int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans, u64 type);
 int btrfs_trim_fs(struct btrfs_fs_info *fs_info, struct fstrim_range *range);
 
 int btrfs_init_space_info(struct btrfs_fs_info *fs_info);

commit c83488afc5a772e424d8f159236bcf805b3c249c
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 20 15:49:14 2018 +0300

    btrfs: Remove fs_info from btrfs_inc_block_group_ro
    
    It can be referenced from the passed bg cache.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bc4bb275e339..5bb083de8f2c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2801,8 +2801,7 @@ int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 void btrfs_block_rsv_release(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);
-int btrfs_inc_block_group_ro(struct btrfs_fs_info *fs_info,
-			     struct btrfs_block_group_cache *cache);
+int btrfs_inc_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_dec_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);

commit 61da2abfcad9c7e1a9c2f74ae7af8637d9fba36e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 20 15:49:13 2018 +0300

    btrfs: Remove fs_info from btrfs_alloc_logged_file_extent
    
    It can be referenced from trans since the function is always called
    within a valid transaction.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index db97e34aa113..bc4bb275e339 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2676,7 +2676,6 @@ int btrfs_alloc_reserved_file_extent(struct btrfs_trans_handle *trans,
 				     u64 offset, u64 ram_bytes,
 				     struct btrfs_key *ins);
 int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
-				   struct btrfs_fs_info *fs_info,
 				   u64 root_objectid, u64 owner, u64 offset,
 				   struct btrfs_key *ins);
 int btrfs_reserve_extent(struct btrfs_root *root, u64 ram_bytes, u64 num_bytes,

commit 451a2c130342125ca44dbbf3b62521c3f0041cfb
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 20 15:49:07 2018 +0300

    btrfs: Remove fs_info from check_system_chunk
    
    It can be referenced from trans since the function is always called
    within a transaction.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7df6739e8eca..db97e34aa113 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2821,8 +2821,7 @@ int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 int btrfs_start_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
-void check_system_chunk(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info, const u64 type);
+void check_system_chunk(struct btrfs_trans_handle *trans, const u64 type);
 u64 add_new_free_space(struct btrfs_block_group_cache *block_group,
 		       u64 start, u64 end);
 

commit 5a98ec0141805a0ff9adb18fd18834a906637f2f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 20 15:48:56 2018 +0300

    btrfs: Remove fs_info from btrfs_remove_block_group
    
    This function is always called with a valid transaction handle from
    where we can reference fs_info. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b77f9ac699c1..7df6739e8eca 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2723,8 +2723,7 @@ struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
 				struct btrfs_fs_info *fs_info,
 				const u64 chunk_offset);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
-			     struct btrfs_fs_info *fs_info, u64 group_start,
-			     struct extent_map *em);
+			     u64 group_start, struct extent_map *em);
 void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);

commit e7e02096d98388a003323c4223630d011ba1b382
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 20 15:48:55 2018 +0300

    btrfs: Remove fs_info from btrfs_make_block_group
    
    This function is always called with a valid transaction handle from
    where we can reference the fs_info. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e671a1fcbbec..b77f9ac699c1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2716,8 +2716,8 @@ int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_fs_info *info);
 int btrfs_can_relocate(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
-			   struct btrfs_fs_info *fs_info, u64 bytes_used,
-			   u64 type, u64 chunk_offset, u64 size);
+			   u64 bytes_used, u64 type, u64 chunk_offset,
+			   u64 size);
 void btrfs_add_raid_kobjects(struct btrfs_fs_info *fs_info);
 struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
 				struct btrfs_fs_info *fs_info,

commit a944442c2b8a420301e7830f976bab8cc86a2b4d
Author: Allen Pais <allen.lkml@gmail.com>
Date:   Tue Jun 12 17:18:25 2018 +0530

    btrfs: replace get_seconds with new 64bit time API
    
    The get_seconds() function is deprecated as it truncates the timestamp
    to 32 bits. Change it to or ktime_get_real_seconds().
    
    Signed-off-by: Allen Pais <allen.lkml@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 118346aceea9..e671a1fcbbec 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -342,8 +342,8 @@ struct btrfs_path {
 					sizeof(struct btrfs_item))
 struct btrfs_dev_replace {
 	u64 replace_state;	/* see #define above */
-	u64 time_started;	/* seconds since 1-Jan-1970 */
-	u64 time_stopped;	/* seconds since 1-Jan-1970 */
+	time64_t time_started;	/* seconds since 1-Jan-1970 */
+	time64_t time_stopped;	/* seconds since 1-Jan-1970 */
 	atomic64_t num_write_errors;
 	atomic64_t num_uncorrectable_read_errors;
 

commit 87eb5eb2423213ac0e7315ce5d275f1ff80e0263
Author: Miklos Szeredi <mszeredi@redhat.com>
Date:   Fri Jul 6 23:57:03 2018 +0200

    vfs: dedupe: rationalize args
    
    Clean up f_op->dedupe_file_range() interface.
    
    1) Use loff_t for offsets and length instead of u64
    2) Order the arguments the same way as {copy|clone}_file_range().
    
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1c7c13334423..d9d924017dfb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3247,8 +3247,9 @@ void btrfs_get_block_group_info(struct list_head *groups_list,
 				struct btrfs_ioctl_space_info *space);
 void btrfs_update_ioctl_balance_args(struct btrfs_fs_info *fs_info,
 			       struct btrfs_ioctl_balance_args *bargs);
-int btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
-			    struct file *dst_file, u64 dst_loff);
+int btrfs_dedupe_file_range(struct file *src_file, loff_t src_loff,
+			    struct file *dst_file, loff_t dst_loff,
+			    u64 olen);
 
 /* file.c */
 int __init btrfs_auto_defrag_init(void);

commit 5740c99e9d30b81fcc478797e7215c61e241f44e
Author: Miklos Szeredi <mszeredi@redhat.com>
Date:   Fri Jul 6 23:57:03 2018 +0200

    vfs: dedupe: return int
    
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 118346aceea9..1c7c13334423 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3247,8 +3247,8 @@ void btrfs_get_block_group_info(struct list_head *groups_list,
 				struct btrfs_ioctl_space_info *space);
 void btrfs_update_ioctl_balance_args(struct btrfs_fs_info *fs_info,
 			       struct btrfs_ioctl_balance_args *bargs);
-ssize_t btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
-			   struct file *dst_file, u64 dst_loff);
+int btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
+			    struct file *dst_file, u64 dst_loff);
 
 /* file.c */
 int __init btrfs_auto_defrag_init(void);

commit a528a24150870c5c16cbbbec69dba7e992b08456
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Wed Jun 6 19:54:44 2018 +0530

    btrfs: change return type of btrfs_page_mkwrite to vm_fault_t
    
    Use the new return type vm_fault_t for fault handler. For now, this is
    just documenting that the function returns a VM_FAULT value rather than
    an errno. Once all instances are converted, vm_fault_t will become a
    distinct type.
    
    Reference commit 1c8f422059ae ("mm: change return type to vm_fault_t")
    
    vmf_error() is the newly introduced inline function in 4.17-rc6.
    
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f4bf7874c24a..118346aceea9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3197,7 +3197,7 @@ int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);
 void btrfs_set_range_writeback(void *private_data, u64 start, u64 end);
-int btrfs_page_mkwrite(struct vm_fault *vmf);
+vm_fault_t btrfs_page_mkwrite(struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);

commit c4c129db5da8f070147f1757e16196d377ccf20b
Author: Gu JinXiang <gujx@cn.fujitsu.com>
Date:   Wed May 30 11:00:38 2018 +0800

    btrfs: drop unused parameter qgroup_reserved
    
    Since commit 7775c8184ec0 ("btrfs: remove unused parameter from
    btrfs_subvolume_release_metadata") parameter qgroup_reserved is not used
    by caller of function btrfs_subvolume_reserve_metadata.  So remove it.
    
    Signed-off-by: Gu JinXiang <gujx@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9a62bc59cc39..f4bf7874c24a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2767,8 +2767,7 @@ void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
-				     int nitems,
-				     u64 *qgroup_reserved, bool use_global_rsv);
+				     int nitems, bool use_global_rsv);
 void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv);
 void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes,

commit d19577912d57c143bb592a061e3dbd7b6f78f71a
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Tue May 29 15:01:54 2018 +0800

    btrfs: Remove fs_info argument from btrfs_uuid_tree_rem
    
    This function always takes a transaction handle which contains a
    reference to the fs_info. Use that and remove the extra argument.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    [ rename the function ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3dc1db981be7..9a62bc59cc39 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3042,8 +3042,7 @@ void btrfs_update_root_times(struct btrfs_trans_handle *trans,
 /* uuid-tree.c */
 int btrfs_uuid_tree_add(struct btrfs_trans_handle *trans, u8 *uuid, u8 type,
 			u64 subid);
-int btrfs_uuid_tree_rem(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info, u8 *uuid, u8 type,
+int btrfs_uuid_tree_remove(struct btrfs_trans_handle *trans, u8 *uuid, u8 type,
 			u64 subid);
 int btrfs_uuid_tree_iterate(struct btrfs_fs_info *fs_info,
 			    int (*check_func)(struct btrfs_fs_info *, u8 *, u8,

commit cdb345a877205849042a18cc568a17620935b8f9
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Tue May 29 15:01:53 2018 +0800

    btrfs: Remove fs_info argument from btrfs_uuid_tree_add
    
    This function always takes a transaction handle which contains a
    reference to the fs_info. Use that and remove the extra argument.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bbb358143ded..3dc1db981be7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3040,8 +3040,7 @@ void btrfs_update_root_times(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
 
 /* uuid-tree.c */
-int btrfs_uuid_tree_add(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info, u8 *uuid, u8 type,
+int btrfs_uuid_tree_add(struct btrfs_trans_handle *trans, u8 *uuid, u8 type,
 			u64 subid);
 int btrfs_uuid_tree_rem(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info, u8 *uuid, u8 type,

commit a575ceeb1338e7eae6d14e223b077b3c6fd3bb6b
Author: Omar Sandoval <osandov@fb.com>
Date:   Fri May 11 13:13:38 2018 -0700

    Btrfs: get rid of unused orphan infrastructure
    
    Now that we don't keep long-standing reservations for orphan items,
    root->orphan_block_rsv isn't used. We can git rid of it, along with:
    
    - root->orphan_lock, which was used to protect root->orphan_block_rsv
    - root->orphan_inodes, which was used as a refcount for root->orphan_block_rsv
    - BTRFS_INODE_ORPHAN_META_RESERVED, which was used to track reservations
      in root->orphan_block_rsv
    - btrfs_orphan_commit_root(), which was the last user of any of these
      and does nothing else
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 71aecf0b7cf5..bbb358143ded 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1223,9 +1223,6 @@ struct btrfs_root {
 	spinlock_t log_extents_lock[2];
 	struct list_head logged_list[2];
 
-	spinlock_t orphan_lock;
-	atomic_t orphan_inodes;
-	struct btrfs_block_rsv *orphan_block_rsv;
 	int orphan_cleanup_state;
 
 	spinlock_t inode_lock;
@@ -2768,9 +2765,6 @@ void btrfs_delalloc_release_space(struct inode *inode,
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
-int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
-				  struct btrfs_inode *inode);
-void btrfs_orphan_release_metadata(struct btrfs_inode *inode);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
 				     int nitems,
@@ -3228,8 +3222,6 @@ int btrfs_update_inode_fallback(struct btrfs_trans_handle *trans,
 int btrfs_orphan_add(struct btrfs_trans_handle *trans,
 		struct btrfs_inode *inode);
 int btrfs_orphan_cleanup(struct btrfs_root *root);
-void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
-			      struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t oldsize, loff_t size);
 void btrfs_add_delayed_iput(struct inode *inode);
 void btrfs_run_delayed_iputs(struct btrfs_fs_info *fs_info);

commit 7b6a221e5b21fdd4fd0f8a2ebf3f251338a10fea
Author: David Sterba <dsterba@suse.com>
Date:   Mon Mar 26 18:40:21 2018 +0200

    btrfs: rename btrfs_update_iflags to reflect which flags it touches
    
    The btrfs inode flag flavour is now simply called 'inode flags' and the
    vfs inode are i_flags.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfa96697209a..71aecf0b7cf5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3249,7 +3249,7 @@ void btrfs_test_inode_set_ops(struct inode *inode);
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 long btrfs_compat_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 int btrfs_ioctl_get_supported_features(void __user *arg);
-void btrfs_update_iflags(struct inode *inode);
+void btrfs_sync_inode_flags_to_i_flags(struct inode *inode);
 int btrfs_is_empty_uuid(u8 *uuid);
 int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      struct btrfs_ioctl_defrag_range_args *range,

commit 20a68004022d5b894efdf5959ebd538b8e91ec73
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Apr 27 14:36:24 2018 +0300

    btrfs: Unexport and rename btrfs_invalidate_inodes
    
    This function is no longer used outside of inode.c so just make it
    static. At the same time give a more becoming name, since it's not
    really invalidating the inodes but just calling d_prune_alias. Last,
    but not least - move the function above the sole caller to avoid
    introducing yet-another-pointless forward declaration.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3d6b2dc86c8f..bfa96697209a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3231,7 +3231,6 @@ int btrfs_orphan_cleanup(struct btrfs_root *root);
 void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t oldsize, loff_t size);
-void btrfs_invalidate_inodes(struct btrfs_root *root);
 void btrfs_add_delayed_iput(struct inode *inode);
 void btrfs_run_delayed_iputs(struct btrfs_fs_info *fs_info);
 int btrfs_prealloc_file_range(struct inode *inode, int mode,

commit 110a21feedd78d398598d91be57db60e19b76fe0
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 26 15:43:18 2018 +0100

    btrfs: introduce conditional wakeup helpers
    
    Add convenience wrappers for the waitqueue management that involves
    memory barriers to prevent deadlocks. The helpers will let us remove
    barriers and the necessary comments in several places.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 954bfb5054b1..3d6b2dc86c8f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3755,4 +3755,26 @@ static inline int btrfs_is_testing(struct btrfs_fs_info *fs_info)
 	return 0;
 }
 
+static inline void cond_wake_up(struct wait_queue_head *wq)
+{
+	/*
+	 * This implies a full smp_mb barrier, see comments for
+	 * waitqueue_active why.
+	 */
+	if (wq_has_sleeper(wq))
+		wake_up(wq);
+}
+
+static inline void cond_wake_up_nomb(struct wait_queue_head *wq)
+{
+	/*
+	 * Special case for conditional wakeup where the barrier required for
+	 * waitqueue_active is implied by some of the preceding code. Eg. one
+	 * of such atomic operations (atomic_dec_and_return, ...), or a
+	 * unlock/lock sequence, etc.
+	 */
+	if (waitqueue_active(wq))
+		wake_up(wq);
+}
+
 #endif

commit 4457c1c702fa1cb2f032bae6dfa0dd2f84ff2b5c
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu May 10 15:44:45 2018 +0300

    btrfs: Remove fs_info argument from add_new_free_space
    
    This function also takes a btrfs_block_group_cache which contains a
    referene to the fs_info. So use that and remove the extra argument.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 27aa9b58b001..954bfb5054b1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2832,7 +2832,7 @@ void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info, const u64 type);
 u64 add_new_free_space(struct btrfs_block_group_cache *block_group,
-		       struct btrfs_fs_info *info, u64 start, u64 end);
+		       u64 start, u64 end);
 
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, const struct btrfs_key *key,

commit 3a2f8c07e1d60739eb6b90ffba41bd1d0de33fc2
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Apr 24 17:23:59 2018 +0300

    btrfs: Unexport btrfs_alloc_delalloc_work
    
    It's used only in inode.c so makes no sense to have it exported. Also
    move the definition of btrfs_delalloc_work to inode.c since it's used
    only this file.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6cdc6d0e8525..27aa9b58b001 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3167,15 +3167,6 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 				     struct extent_map *em);
 
 /* inode.c */
-struct btrfs_delalloc_work {
-	struct inode *inode;
-	struct completion completion;
-	struct list_head list;
-	struct btrfs_work work;
-};
-
-struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode);
-
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start,
 		u64 len, int create);

commit 076da91cd9ec4032f88bb30a162d576e9e46c2d6
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Apr 23 10:54:16 2018 +0300

    btrfs: Remove delayed_iput member from btrfs_delalloc_work
    
    When allocating a delalloc work we are always setting the delayed_iput
    to 0. So remove the delay_iput member of btrfs_delalloc_work, as a
    result also remove it as a parameter from btrfs_alloc_delalloc_work
    since it's not used anymore.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0dbb5a19d977..6cdc6d0e8525 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3169,14 +3169,12 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 /* inode.c */
 struct btrfs_delalloc_work {
 	struct inode *inode;
-	int delay_iput;
 	struct completion completion;
 	struct list_head list;
 	struct btrfs_work work;
 };
 
-struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,
-						    int delay_iput);
+struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode);
 
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start,

commit 76f32e240ee6a3c1903ce8f1e934b43f2971bffc
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Apr 23 10:54:14 2018 +0300

    btrfs: Remove delayed_iput parameter from btrfs_start_delalloc_inodes
    
    It's always set to 0, so just remove it and collapse the constant value
    to the only function we are passing it.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0d15d98a964a..0dbb5a19d977 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3204,7 +3204,7 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       struct inode *inode, u64 new_size,
 			       u32 min_type);
 
-int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
+int btrfs_start_delalloc_inodes(struct btrfs_root *root);
 int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int nr);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      unsigned int extra_bits,

commit 82b3e53b8da19b25ef36b68316374df47f8fa268
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Apr 23 10:54:13 2018 +0300

    btrfs: Remove delayed_iput parameter of btrfs_start_delalloc_roots
    
    This parameter was introduced alongside the function in
    eb73c1b7cea7 ("Btrfs: introduce per-subvolume delalloc inode list") to
    avoid deadlocks since this function was used in the transaction commit
    path. However, commit 8d875f95da43 ("btrfs: disable strict file flushes
    for renames and truncates") removed that usage, rendering the parameter
    obsolete.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9cc90f407cae..0d15d98a964a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3205,8 +3205,7 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
-int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int delay_iput,
-			       int nr);
+int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int nr);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      unsigned int extra_bits,
 			      struct extent_state **cached_state, int dedupe);

commit 008ef0969dd966ccb567d9c5c6e606f68119a380
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 21 02:05:27 2018 +0100

    btrfs: drop lock parameter from update_ioctl_balance_args and rename
    
    The parameter controls locking of the stats part but we can lock it
    unconditionally, as this only happens once when balance starts. This is
    not performance critical.
    
    Add the prefix for an exported function.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8fdc97312b61..9cc90f407cae 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3267,7 +3267,9 @@ int btrfs_is_empty_uuid(u8 *uuid);
 int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      struct btrfs_ioctl_defrag_range_args *range,
 		      u64 newer_than, unsigned long max_pages);
-void update_ioctl_balance_args(struct btrfs_fs_info *fs_info, int lock,
+void btrfs_get_block_group_info(struct list_head *groups_list,
+				struct btrfs_ioctl_space_info *space);
+void btrfs_update_ioctl_balance_args(struct btrfs_fs_info *fs_info,
 			       struct btrfs_ioctl_balance_args *bargs);
 ssize_t btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
 			   struct file *dst_file, u64 dst_loff);

commit 3009a62f3b18230a000d1a91e9a676036487e834
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 21 01:31:04 2018 +0100

    btrfs: track running balance in a simpler way
    
    Currently fs_info::balance_running is 0 or 1 and does not use the
    semantics of atomics. The pause and cancel check for 0, that can happen
    only after __btrfs_balance exits for whatever reason.
    
    Parallel calls to balance ioctl may enter btrfs_ioctl_balance multiple
    times but will block on the balance_mutex that protects the
    fs_info::flags bit.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index add0e5a3f415..8fdc97312b61 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -739,6 +739,12 @@ struct btrfs_delayed_root;
  */
 #define BTRFS_FS_NEED_ASYNC_COMMIT		17
 
+/*
+ * Indicate that balance has been set up from the ioctl and is in the main
+ * phase. The fs_info::balance_ctl is initialized.
+ */
+#define BTRFS_FS_BALANCE_RUNNING		18
+
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
 	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
@@ -1003,7 +1009,6 @@ struct btrfs_fs_info {
 	/* restriper state */
 	spinlock_t balance_lock;
 	struct mutex balance_mutex;
-	atomic_t balance_running;
 	atomic_t balance_pause_req;
 	atomic_t balance_cancel_req;
 	struct btrfs_balance_control *balance_ctl;

commit dccdb07bc996e9c8de80d06813163ca08288bf73
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 21 00:20:05 2018 +0100

    btrfs: kill btrfs_fs_info::volume_mutex
    
    Mutual exclusion of device add/rm and balance was done by the volume
    mutex up to version 3.7. The commit 5ac00addc7ac091109 ("Btrfs: disallow
    mutually exclusive admin operations from user mode") added a bit that
    essentially tracked the same information.
    
    The status bit has an advantage over a mutex that it can be set without
    restrictions of function context, so it started to be used in the
    mount-time resuming of balance or device replace.
    
    But we don't really need to track the same information in two ways.
    
    1) After the previous cleanups, the main ioctl handlers for
       add/del/resize copy the EXCL_OP bit next to the volume mutex, here
       it's clearly safe.
    
    2) Resuming balance during mount or after rw remount will set only the
       EXCL_OP bit and the volume_mutex is held in the kernel thread that
       calls btrfs_balance.
    
    3) Resuming device replace during mount or after rw remount is done
       after balance and is excluded by the EXCL_OP bit. It does not take
       the volume_mutex at all and completely relies on the EXCL_OP bit.
    
    4) The resuming of balance and dev-replace cannot hapen at the same time
       as the ioctls cannot be started in parallel. Nevertheless, a crafted
       image could trigger that and a warning is printed.
    
    5) Balance is normally excluded by EXCL_OP and also uses own mutex to
       protect against concurrent access to its status data. There's some
       trickery to maintain the right lock nesting in case we need to
       reexamine the status in btrfs_ioctl_balance. The volume_mutex is
       removed and the unlock/lock sequence is left in place as we might
       expect other waiters to proceed.
    
    6) Similar to 5, the unlock/lock sequence is kept in
       btrfs_cancel_balance to allow waiters to continue.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index de86f2217816..add0e5a3f415 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -838,7 +838,6 @@ struct btrfs_fs_info {
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;
 	struct mutex chunk_mutex;
-	struct mutex volume_mutex;
 
 	/*
 	 * this is taken to make sure we don't set block groups ro after

commit 40012f96b6765e588d8ffd7508d492339f2b9212
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Apr 19 10:46:39 2018 +0300

    btrfs: Remove btrfs_wait_and_free_delalloc_work
    
    This function is called from only 1 place and is effectively a wrapper
    over wait_completion/kfree. It doesn't really bring any value having
    those two calls in a separate function. Just open code it and remove it.
    No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3a382ed94030..de86f2217816 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3173,7 +3173,6 @@ struct btrfs_delalloc_work {
 
 struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,
 						    int delay_iput);
-void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
 
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start,

commit f60a2364a4eee4d8c335775a3a0c39aa955aa6b7
Author: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Wed Apr 18 11:34:52 2018 +0900

    btrfs: Factor out the main deletion process from btrfs_ioctl_snap_destroy()
    
    Factor out the second half of btrfs_ioctl_snap_destroy() as
    btrfs_delete_subvolume(), which performs some subvolume specific checks
    before deletion:
    
    1. send is not in progress
    2. the subvolume is not the default subvolume
    3. the subvolume does not contain other subvolumes
    
    and actual deletion process. btrfs_delete_subvolume() requires
    inode_lock for both @dir and inode of @dentry. The remaining part of
    btrfs_ioctl_snap_destroy() is mainly permission checks.
    
    Note that call of d_delete() is not included in btrfs_delete_subvolume()
    as this function will also be used by btrfs_rmdir() to delete an empty
    subvolume and in that case d_delete() is called in VFS layer.
    
    As a result, btrfs_unlink_subvol() and may_destroy_subvol()
    become static functions. No functional changes.
    
    Signed-off-by: Tomohiro Misono <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor comment updates ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fe7e5177119d..3a382ed94030 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3193,11 +3193,7 @@ int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
 int btrfs_add_link(struct btrfs_trans_handle *trans,
 		   struct btrfs_inode *parent_inode, struct btrfs_inode *inode,
 		   const char *name, int name_len, int add_backref, u64 index);
-int btrfs_unlink_subvol(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root,
-			struct inode *dir, u64 objectid,
-			const char *name, int name_len);
-noinline int may_destroy_subvol(struct btrfs_root *root);
+int btrfs_delete_subvolume(struct inode *dir, struct dentry *dentry);
 int btrfs_truncate_block(struct inode *inode, loff_t from, loff_t len,
 			int front);
 int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,

commit ec42f167348a1949ac309532aa34760cfc96c92f
Author: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Wed Apr 18 11:34:13 2018 +0900

    btrfs: Move may_destroy_subvol() from ioctl.c to inode.c
    
    This is a preparation work to refactor btrfs_ioctl_snap_destroy()
    and to allow rmdir(2) to delete an empty subvolume.
    
    Signed-off-by: Tomohiro Misono <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor update of the function comment ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 15e34172cdf0..fe7e5177119d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3197,6 +3197,7 @@ int btrfs_unlink_subvol(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct inode *dir, u64 objectid,
 			const char *name, int name_len);
+noinline int may_destroy_subvol(struct btrfs_root *root);
 int btrfs_truncate_block(struct inode *inode, loff_t from, loff_t len,
 			int front);
 int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,

commit c065f5b1cf52d50b9518aa02c7e50415820895af
Author: Su Yue <suy.fnst@cn.fujitsu.com>
Date:   Mon Apr 2 17:24:11 2018 +0800

    btrfs: rename btrfs_get_block_group_info and make it static
    
    The function btrfs_get_block_group_info() was introduced by the
    commit 5af3e8cce8b7 ("Btrfs: make filesystem read-only when submitting
     barrier fails") which used it in disk-io.c.
    
    However, the function is only called in ioctl.c now.
    Its parameter type btrfs_ioctl_space_info* is only for ioctl.
    
    So, make it static and rename it to be original name
    get_block_group_info.
    
    No functional change.
    
    Signed-off-by: Su Yue <suy.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0d422c9908b8..15e34172cdf0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3267,8 +3267,6 @@ int btrfs_is_empty_uuid(u8 *uuid);
 int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      struct btrfs_ioctl_defrag_range_args *range,
 		      u64 newer_than, unsigned long max_pages);
-void btrfs_get_block_group_info(struct list_head *groups_list,
-				struct btrfs_ioctl_space_info *space);
 void update_ioctl_balance_args(struct btrfs_fs_info *fs_info, int lock,
 			       struct btrfs_ioctl_balance_args *bargs);
 ssize_t btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,

commit 2b8773313494ede83a26fb372466e634564002ed
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Apr 27 12:21:51 2018 +0300

    btrfs: Split btrfs_del_delalloc_inode into 2 functions
    
    This is in preparation of fixing delalloc inodes leakage on transaction
    abort. Also export the new function.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2771cc56a622..0d422c9908b8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3182,6 +3182,8 @@ noinline int can_nocow_extent(struct inode *inode, u64 offset, u64 *len,
 			      u64 *orig_start, u64 *orig_block_len,
 			      u64 *ram_bytes);
 
+void __btrfs_del_delalloc_inode(struct btrfs_root *root,
+				struct btrfs_inode *inode);
 struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry);
 int btrfs_set_inode_index(struct btrfs_inode *dir, u64 *index);
 int btrfs_unlink_inode(struct btrfs_trans_handle *trans,

commit ff6bc37eb7f6e7b052e50c13a480e1080b3ec07a
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Dec 21 13:42:04 2017 +0800

    btrfs: qgroup: Use independent and accurate per inode qgroup rsv
    
    Unlike reservation calculation used in inode rsv for metadata, qgroup
    doesn't really need to care about things like csum size or extent usage
    for the whole tree COW.
    
    Qgroups care more about net change of the extent usage.
    That's to say, if we're going to insert one file extent, it will mostly
    find its place in COWed tree block, leaving no change in extent usage.
    Or causing a leaf split, resulting in one new net extent and increasing
    qgroup number by nodesize.
    Or in an even more rare case, increase the tree level, increasing qgroup
    number by 2 * nodesize.
    
    So here instead of using the complicated calculation for extent
    allocator, which cares more about accuracy and no error, qgroup doesn't
    need that over-estimated reservation.
    
    This patch will maintain 2 new members in btrfs_block_rsv structure for
    qgroup, using much smaller calculation for qgroup rsv, reducing false
    EDQUOT.
    
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ec84e2dabb04..2771cc56a622 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -459,6 +459,25 @@ struct btrfs_block_rsv {
 	unsigned short full;
 	unsigned short type;
 	unsigned short failfast;
+
+	/*
+	 * Qgroup equivalent for @size @reserved
+	 *
+	 * Unlike normal @size/@reserved for inode rsv, qgroup doesn't care
+	 * about things like csum size nor how many tree blocks it will need to
+	 * reserve.
+	 *
+	 * Qgroup cares more about net change of the extent usage.
+	 *
+	 * So for one newly inserted file extent, in worst case it will cause
+	 * leaf split and level increase, nodesize for each file extent is
+	 * already too much.
+	 *
+	 * In short, qgroup_size/reserved is the upper limit of possible needed
+	 * qgroup metadata reservation.
+	 */
+	u64 qgroup_rsv_size;
+	u64 qgroup_rsv_reserved;
 };
 
 /*

commit a514d63882c3d2063b21b865447266ebcb18b04c
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Dec 22 16:06:39 2017 +0800

    btrfs: qgroup: Commit transaction in advance to reduce early EDQUOT
    
    Unlike previous method that tries to commit transaction inside
    qgroup_reserve(), this time we will try to commit transaction using
    fs_info->transaction_kthread to avoid nested transaction and no need to
    worry about locking context.
    
    Since it's an asynchronous function call and we won't wait for
    transaction commit, unlike previous method, we must call it before we
    hit the qgroup limit.
    
    So this patch will use the ratio and size of qgroup meta_pertrans
    reservation as indicator to check if we should trigger a transaction
    commit.  (meta_prealloc won't be cleaned in transaction committ, it's
    useless anyway)
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5474ef14d6e6..ec84e2dabb04 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -714,6 +714,12 @@ struct btrfs_delayed_root;
  */
 #define BTRFS_FS_EXCL_OP			16
 
+/*
+ * To info transaction_kthread we need an immediate commit so it doesn't
+ * need to wait for commit_interval
+ */
+#define BTRFS_FS_NEED_ASYNC_COMMIT		17
+
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
 	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];

commit 9888c3402c8567a977de37f61e9dd87792723064
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:16:55 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- headers
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Unify the include protection macros to match the file names.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0eb55825862a..5474ef14d6e6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,23 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Copyright (C) 2007 Oracle.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
-#ifndef __BTRFS_CTREE__
-#define __BTRFS_CTREE__
+#ifndef BTRFS_CTREE_H
+#define BTRFS_CTREE_H
 
 #include <linux/mm.h>
 #include <linux/sched/signal.h>
@@ -3752,4 +3739,5 @@ static inline int btrfs_is_testing(struct btrfs_fs_info *fs_info)
 #endif
 	return 0;
 }
+
 #endif

commit 8287475a20552af66b32c07704dbdbeeb898ac1f
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:34 2017 +0800

    btrfs: qgroup: Use root::qgroup_meta_rsv_* to record qgroup meta reserved space
    
    For quota disabled->enable case, it's possible that at reservation time
    quota was not enabled so no bytes were really reserved, while at release
    time, quota was enabled so we will try to release some bytes we didn't
    really own.
    
    Such situation can cause metadata reserveation underflow, for both types,
    also less possible for per-trans type since quota enable will commit
    transaction.
    
    To address this, record qgroup meta reserved bytes into
    root::qgroup_meta_rsv_pertrans and ::prealloc.
    So at releasing time we won't free any bytes we didn't reserve.
    
    For DATA, it's already handled by io_tree, so nothing needs to be done
    there.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7924e50cc528..0eb55825862a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1264,6 +1264,11 @@ struct btrfs_root {
 	int send_in_progress;
 	struct btrfs_subvolume_writers *subv_writers;
 	atomic_t will_be_snapshotted;
+
+	/* For qgroup metadata reserved space */
+	spinlock_t qgroup_meta_rsv_lock;
+	u64 qgroup_meta_rsv_pertrans;
+	u64 qgroup_meta_rsv_prealloc;
 };
 
 struct btrfs_file_private {

commit 43b18595d6603cb4197fb9b063915cd7802141a6
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:32 2017 +0800

    btrfs: qgroup: Use separate meta reservation type for delalloc
    
    Before this patch, btrfs qgroup is mixing per-transcation meta rsv with
    preallocated meta rsv, making it quite easy to underflow qgroup meta
    reservation.
    
    Since we have the new qgroup meta rsv types, apply it to delalloc
    reservation.
    
    Now for delalloc, most of its reserved space will use META_PREALLOC qgroup
    rsv type.
    
    And for callers reducing outstanding extent like btrfs_finish_ordered_io(),
    they will convert corresponding META_PREALLOC reservation to
    META_PERTRANS.
    
    This is mainly due to the fact that current qgroup numbers will only be
    updated in btrfs_commit_transaction(), that's to say if we don't keep
    such placeholder reservation, we can exceed qgroup limitation.
    
    And for callers freeing outstanding extent in error handler, we will
    just free META_PREALLOC bytes.
    
    This behavior makes callers of btrfs_qgroup_release_meta() or
    btrfs_qgroup_convert_meta() to be aware of which type they are.
    So in this patch, btrfs_delalloc_release_metadata() and its callers get
    an extra parameter to info qgroup to do correct meta convert/release.
    
    The good news is, even we use the wrong type (convert or free), it won't
    cause obvious bug, as prealloc type is always in good shape, and the
    type only affects how per-trans meta is increased or not.
    
    So the worst case will be at most metadata limitation can be sometimes
    exceeded (no convert at all) or metadata limitation is reached too soon
    (no free at all).
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index df0463e2ab7f..7924e50cc528 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2742,7 +2742,8 @@ int btrfs_check_data_free_space(struct inode *inode,
 void btrfs_free_reserved_data_space(struct inode *inode,
 			struct extent_changeset *reserved, u64 start, u64 len);
 void btrfs_delalloc_release_space(struct inode *inode,
-			struct extent_changeset *reserved, u64 start, u64 len);
+				  struct extent_changeset *reserved,
+				  u64 start, u64 len, bool qgroup_free);
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
@@ -2755,10 +2756,12 @@ int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     u64 *qgroup_reserved, bool use_global_rsv);
 void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv);
-void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes);
+void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes,
+				    bool qgroup_free);
 
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
-void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes);
+void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes,
+				     bool qgroup_free);
 int btrfs_delalloc_reserve_space(struct inode *inode,
 			struct extent_changeset **reserved, u64 start, u64 len);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);

commit e1211d0e896b71d395fe411d0e0a76f4bc336617
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:30 2017 +0800

    btrfs: qgroup: Don't use root->qgroup_meta_rsv for qgroup
    
    Since qgroup has seperate metadata reservation types now, we can
    completely get rid of the old root->qgroup_meta_rsv, which mostly acts
    as current META_PERTRANS reservation type.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f9f512be9d41..df0463e2ab7f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1264,9 +1264,6 @@ struct btrfs_root {
 	int send_in_progress;
 	struct btrfs_subvolume_writers *subv_writers;
 	atomic_t will_be_snapshotted;
-
-	/* For qgroup metadata space reserve */
-	atomic64_t qgroup_meta_rsv;
 };
 
 struct btrfs_file_private {

commit 4408ea7c5fd92cbdff3b5890601b9be6610bbb33
Author: Misono, Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Tue Mar 20 15:47:06 2018 +0900

    btrfs: ctree.h: Fix wrong comment position about csum size
    
    Signed-off-by: Tomohiro Misono <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8d3aa56b928b..f9f512be9d41 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -89,9 +89,9 @@ struct btrfs_ordered_sum;
  */
 #define BTRFS_LINK_MAX 65535U
 
+/* four bytes for CRC32 */
 static const int btrfs_csum_sizes[] = { 4 };
 
-/* four bytes for CRC32 */
 #define BTRFS_EMPTY_DIR_SIZE 0
 
 /* ioprio of readahead is set to idle */

commit 75cb379d2635215ad2c67750693f7dc45ad19a5f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Mar 20 15:25:26 2018 -0400

    btrfs: defer adding raid type kobject until after chunk relocation
    
    Any time the first block group of a new type is created, we add a new
    kobject to sysfs to hold the attributes for that type.  Kobject-internal
    allocations always use GFP_KERNEL, making them prone to fs-reclaim races.
    While it appears as if this can occur any time a block group is created,
    the only times the first block group of a new type can be created in
    memory is at mount and when we create the first new block group during
    raid conversion.
    
    This patch adds a new list to track pending kobject additions and then
    handles them after we do chunk relocation.  Between relocating the
    target chunk (or forcing allocation of a new chunk in the case of data)
    and removing the old chunk, we're in a safe place for fs-reclaim to
    occur.  We're holding the volume mutex, which is already held across
    page faults, and the delete_unused_bgs_mutex, which will only stall
    the cleaner thread.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ffa72ca5755d..8d3aa56b928b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -385,8 +385,9 @@ struct btrfs_dev_replace {
 
 /* For raid type sysfs entries */
 struct raid_kobject {
-	int raid_type;
+	u64 flags;
 	struct kobject kobj;
+	struct list_head list;
 };
 
 struct btrfs_space_info {
@@ -940,6 +941,8 @@ struct btrfs_fs_info {
 	u32 thread_pool_size;
 
 	struct kobject *space_info_kobj;
+	struct list_head pending_raid_kobjs;
+	spinlock_t pending_raid_kobjs_lock; /* uncontended */
 
 	u64 total_pinned;
 
@@ -2700,6 +2703,7 @@ int btrfs_can_relocate(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_fs_info *fs_info, u64 bytes_used,
 			   u64 type, u64 chunk_offset, u64 size);
+void btrfs_add_raid_kobjects(struct btrfs_fs_info *fs_info);
 struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
 				struct btrfs_fs_info *fs_info,
 				const u64 chunk_offset);

commit dc2d3005d27da41247d6c42077e335a777afc79c
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Mar 20 15:25:25 2018 -0400

    btrfs: remove dead create_space_info calls
    
    Since commit 2be12ef79 (btrfs: Separate space_info create/update), we've
    separated out the creation and updating of the space info structures.
    That commit was a straightforward refactoring of the two parts of
    update_space_info, but we can go a step further.  Since commits
    c59021f84 (Btrfs: fix OOPS of empty filesystem after balance) and
    b742bb82f (Btrfs: Link block groups of different raid types), we know
    that the space_info structures will be created at mount and there will
    only ever be, at most, three of them.
    
    This patch cleans out the create_space_info calls after __find_space_info
    returns NULL since __find_space_info *can't* return NULL.
    
    The initial cause for reviewing this was the kobject_add calls from
    create_space_info occuring in sites where fs-reclaim wasn't allowed.  Now
    we are certain they occur only early in the mount process and are safe.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 03be51d77357..ffa72ca5755d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -954,9 +954,9 @@ struct btrfs_fs_info {
 	struct btrfs_fs_devices *fs_devices;
 
 	/*
-	 * the space_info list is almost entirely read only.  It only changes
-	 * when we add a new raid type to the FS, and that happens
-	 * very rarely.  RCU is used to protect it.
+	 * The space_info list is effectively read only after initial
+	 * setup.  It is populated at mount time and cleaned up after
+	 * all block groups are removed.  RCU is used to protect it.
 	 */
 	struct list_head space_info;
 

commit 5ead2dd02c776e2acf50d5a8cd31a90513f45433
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Mar 15 16:00:26 2018 +0200

    btrfs: Drop fs_info parameter from btrfs_finish_extent_commit
    
    It's provided by the transaction handle.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b0573cdb4d20..03be51d77357 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2682,8 +2682,7 @@ int btrfs_free_reserved_extent(struct btrfs_fs_info *fs_info,
 int btrfs_free_and_pin_reserved_extent(struct btrfs_fs_info *fs_info,
 				       u64 start, u64 len);
 void btrfs_prepare_extent_commit(struct btrfs_fs_info *fs_info);
-int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
-			       struct btrfs_fs_info *fs_info);
+int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,

commit c79a70b1330b374d6f4d88f266552054a4b58d08
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Mar 15 17:27:37 2018 +0200

    btrfs: drop fs_info parameter from btrfs_run_delayed_refs
    
    It's provided by the transaction handle.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 50c068fd3b38..b0573cdb4d20 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2623,7 +2623,7 @@ void btrfs_dec_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
 void btrfs_wait_nocow_writers(struct btrfs_block_group_cache *bg);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
-			   struct btrfs_fs_info *fs_info, unsigned long count);
+			   unsigned long count);
 int btrfs_async_run_delayed_refs(struct btrfs_fs_info *fs_info,
 				 unsigned long count, u64 transid, int wait);
 int btrfs_lookup_data_extent(struct btrfs_fs_info *fs_info, u64 start, u64 len);

commit 92e2f7e37004115db2ba98c6999a74ff5e41c83f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 5 10:41:16 2018 +0200

    btrfs: Remove btrfs_fs_info::open_ioctl_trans
    
    Since userspace transaction have been removed we no longer have use
    for this field so delete it.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 395bfc51e256..50c068fd3b38 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -880,7 +880,6 @@ struct btrfs_fs_info {
 	struct rb_root tree_mod_log;
 
 	atomic_t async_delalloc_pages;
-	atomic_t open_ioctl_trans;
 
 	/*
 	 * this is used to protect the following list -- ordered_roots.

commit 859e682d58a2bd60f1aa2a32f712ee444faf4003
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 5 10:41:14 2018 +0200

    btrfs: Remove btrfs_file_private::trans
    
    Now that the userspace transaction IOCTL have been removed, this member
    is no longer used so just remove it
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f2396a13c0c2..395bfc51e256 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1268,7 +1268,6 @@ struct btrfs_root {
 };
 
 struct btrfs_file_private {
-	struct btrfs_trans_handle *trans;
 	void *filldir_buf;
 };
 

commit 7a5a07a81062915c65ce27e80608b1c819b1f936
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 5 10:41:13 2018 +0200

    btrfs: Remove userspace transaction ioctls
    
    Commit 3558d4f88ec8 ("btrfs: Deprecate userspace transaction ioctls")
    marked the beginning of the end of userspace transaction. This commit
    finishes the job! There are no known users and ceph does not use the
    ioctl anymore.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Acked-by: Sage Weil <sage@redhat.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 15bf111cd5c5..f2396a13c0c2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3207,7 +3207,6 @@ void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);
 int __init btrfs_init_cachep(void);
 void __cold btrfs_destroy_cachep(void);
-long btrfs_ioctl_trans_end(struct file *file);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root, int *was_new);
 struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,

commit 7c829b722dffb22aaf9e3ea1b1d88dac49bd0768
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Mar 7 17:29:18 2018 +0800

    btrfs: add define for oldest generation
    
    Some functions can filter metadata by the generation. Add a define that
    will annotate such arguments.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f4926dc9649f..15bf111cd5c5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -66,6 +66,8 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAX_LEVEL 8
 
+#define BTRFS_OLDEST_GENERATION	0ULL
+
 #define BTRFS_COMPAT_EXTENT_TREE_V0
 
 /*

commit 738c93d42c277d790cd49372c9bf24bcfea13306
Author: David Sterba <dsterba@suse.com>
Date:   Tue Feb 27 15:48:59 2018 +0100

    btrfs: move btrfs_listxattr prototype to xattr.h
    
    There's a proper header for xattr handlers.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index eabc8431b442..f4926dc9649f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3294,9 +3294,6 @@ void __cold btrfs_exit_sysfs(void);
 int btrfs_sysfs_add_mounted(struct btrfs_fs_info *fs_info);
 void btrfs_sysfs_remove_mounted(struct btrfs_fs_info *fs_info);
 
-/* xattr.c */
-ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
-
 /* super.c */
 int btrfs_parse_options(struct btrfs_fs_info *info, char *options,
 			unsigned long new_flags);

commit d612ac59efc3b57858f310c8471d7ee2779658c9
Author: Anand Jain <anand.jain@oracle.com>
Date:   Mon Feb 26 16:46:05 2018 +0800

    btrfs: unify types for metadata_ratio and data_chunk_allocations
    
    We have btrfs_fs_info::data_chunk_allocations and
    btrfs_fs_info::metadata_ratio declared as unsigned which would be
    unsinged int and kernel style prefers unsigned int over bare unsigned.
    So this patch changes them to u32.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d6a2fc311187..eabc8431b442 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -994,8 +994,8 @@ struct btrfs_fs_info {
 	struct btrfs_balance_control *balance_ctl;
 	wait_queue_head_t balance_wait_q;
 
-	unsigned data_chunk_allocations;
-	unsigned metadata_ratio;
+	u32 data_chunk_allocations;
+	u32 metadata_ratio;
 
 	void *bdev_holder;
 

commit e67c718b5b9a306bde7e966be7b4ca48fa063d73
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 19 17:24:18 2018 +0100

    btrfs: add more __cold annotations
    
    The __cold functions are placed to a special section, as they're
    expected to be called rarely. This could help i-cache prefetches or help
    compiler to decide which branches are more/less likely to be taken
    without any other annotations needed.
    
    Though we can't add more __exit annotations, it's still possible to add
    __cold (that's also added with __exit). That way the following function
    categories are tagged:
    
    - printf wrappers, error messages
    - exit helpers
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 92b9db7186bb..d6a2fc311187 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3204,7 +3204,7 @@ struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);
 int __init btrfs_init_cachep(void);
-void btrfs_destroy_cachep(void);
+void __cold btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root, int *was_new);
@@ -3255,7 +3255,7 @@ ssize_t btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
 
 /* file.c */
 int __init btrfs_auto_defrag_init(void);
-void btrfs_auto_defrag_exit(void);
+void __cold btrfs_auto_defrag_exit(void);
 int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 			   struct btrfs_inode *inode);
 int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
@@ -3290,7 +3290,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 
 /* sysfs.c */
 int __init btrfs_init_sysfs(void);
-void btrfs_exit_sysfs(void);
+void __cold btrfs_exit_sysfs(void);
 int btrfs_sysfs_add_mounted(struct btrfs_fs_info *fs_info);
 void btrfs_sysfs_remove_mounted(struct btrfs_fs_info *fs_info);
 
@@ -3302,13 +3302,14 @@ int btrfs_parse_options(struct btrfs_fs_info *info, char *options,
 			unsigned long new_flags);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 
-static inline __printf(2, 3)
+static inline __printf(2, 3) __cold
 void btrfs_no_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 {
 }
 
 #ifdef CONFIG_PRINTK
 __printf(2, 3)
+__cold
 void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...);
 #else
 #define btrfs_printk(fs_info, fmt, args...) \

commit 9678c54388b6a6b309ff7ee5c8d23fa9eba7c06f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 8 11:45:05 2018 +0200

    btrfs: Remove custom crc32c init code
    
    The custom crc32 init code was introduced in
    14a958e678cd ("Btrfs: fix btrfs boot when compiled as built-in") to
    enable using btrfs as a built-in. However, later as pointed out by
    60efa5eb2e88 ("Btrfs: use late_initcall instead of module_init") this
    wasn't enough and finally btrfs was switched to late_initcall which
    comes after the generic crc32c implementation is initiliased. The
    latter commit superseeded the former. Now that we don't have to
    maintain our own code let's just remove it and switch to using the
    generic implementation.
    
    Despite touching a lot of files the patch is really simple. Here is the gist of
    the changes:
    
    1. Select LIBCRC32C rather than the low-level modules.
    2. s/btrfs_crc32c/crc32c/g
    3. replace hash.h with linux/crc32c.h
    4. Move the btrfs namehash funcs to ctree.h and change the tree accordingly.
    
    I've tested this with btrfs being both a module and a built-in and xfstest
    doesn't complain.
    
    Does seem to fix the longstanding problem of not automatically selectiong
    the crc32c module when btrfs is used. Possibly there is a workaround in
    dracut.
    
    The modinfo confirms that now all the module dependencies are there:
    
    before:
    depends:        zstd_compress,zstd_decompress,raid6_pq,xor,zlib_deflate
    
    after:
    depends:        libcrc32c,zstd_compress,zstd_decompress,raid6_pq,xor,zlib_deflate
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add more info to changelog from mails ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a4877b6959e3..92b9db7186bb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -40,6 +40,7 @@
 #include <linux/sizes.h>
 #include <linux/dynamic_debug.h>
 #include <linux/refcount.h>
+#include <linux/crc32c.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
@@ -98,6 +99,7 @@ static const int btrfs_csum_sizes[] = { 4 };
 
 #define BTRFS_MAX_EXTENT_SIZE SZ_128M
 
+
 /*
  * Count how many BTRFS_MAX_EXTENT_SIZE cover the @size
  */
@@ -2553,6 +2555,20 @@ BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cursor_right,
 	((unsigned long)(BTRFS_LEAF_DATA_OFFSET + \
 	btrfs_item_offset_nr(leaf, slot)))
 
+static inline u64 btrfs_name_hash(const char *name, int len)
+{
+       return crc32c((u32)~1, name, len);
+}
+
+/*
+ * Figure the key offset of an extended inode ref
+ */
+static inline u64 btrfs_extref_hash(u64 parent_objectid, const char *name,
+                                   int len)
+{
+       return (u64) crc32c(parent_objectid, name, len);
+}
+
 static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
 {
 	return ((space_info->flags & BTRFS_BLOCK_GROUP_METADATA) &&

commit 3e72ee8874f42ddbe72a090044f7c03740158183
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Jan 30 18:20:45 2018 +0800

    btrfs: Refactor __get_raid_index() to btrfs_bg_flags_to_raid_index()
    
    Function __get_raid_index() is used to convert block group flags into
    raid index, which can be used to get various info directly from
    btrfs_raid_array[].
    
    Refactor this function a little:
    
    1) Rename to btrfs_bg_flags_to_raid_index()
       Double underline prefix is normally for internal functions, while the
       function is used by both extent-tree and volumes.
    
       Although the name is a little longer, but it should explain its usage
       quite well.
    
    2) Move it to volumes.h and make it static inline
       Just several if-else branches, really no need to define it as a normal
       function.
    
       This also makes later code re-use between kernel and btrfs-progs
       easier.
    
    3) Remove function get_block_group_index()
       Really no need to do such a simple thing as an exported function.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa29ad826d7c..a4877b6959e3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2627,7 +2627,6 @@ struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 u64 bytenr);
 void btrfs_get_block_group(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
-int get_block_group_index(struct btrfs_block_group_cache *cache);
 struct extent_buffer *btrfs_alloc_tree_block(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,
 					     u64 parent, u64 root_objectid,
@@ -2787,7 +2786,6 @@ int btrfs_trim_fs(struct btrfs_fs_info *fs_info, struct fstrim_range *range);
 int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
-int __get_raid_index(u64 flags);
 int btrfs_start_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);

commit 5d23515be66904fa3b1b5d6bd72d2199cd2447ab
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jan 31 10:52:04 2018 +0200

    btrfs: Move qgroup rescan on quota enable to btrfs_quota_enable
    
    Currently btrfs_run_qgroups is doing a bit too much. Not only is it
    responsible for synchronizing in-memory state of qgroups to disk but
    it also contains code to trigger the initial qgroup rescan when
    quota is enabled initially. This condition is detected by checking that
    BTRFS_FS_QUOTA_ENABLED is not set and BTRFS_FS_QUOTA_ENABLING is set.
    Nothing really requires from the code to be structured (and scattered)
    the way it is so let's streamline things. First move the quota rescan
    code into btrfs_quota_enable, where its invocation is closer to the
    use. This also makes the FS_QUOTA_ENABLING flag redundant so let's
    remove it as well.
    
    This has been tested with a full xfstest run with qgroups enabled on
    the scratch device of every xfstest and no regressions were observed.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 024d5feb5856..fa29ad826d7c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -707,7 +707,6 @@ struct btrfs_delayed_root;
 #define BTRFS_FS_LOG_RECOVERING			4
 #define BTRFS_FS_OPEN				5
 #define BTRFS_FS_QUOTA_ENABLED			6
-#define BTRFS_FS_QUOTA_ENABLING			7
 #define BTRFS_FS_UPDATE_UUID_TREE_GEN		9
 #define BTRFS_FS_CREATING_FREE_SPACE_TREE	10
 #define BTRFS_FS_BTREE_ERR			11

commit d3740608646f72fb94705a853946f647abcfaec4
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Feb 13 17:50:46 2018 +0800

    btrfs: manage commit mount option as %u
    
    As the commit mount option is unsigned so manage it as %u for token
    verifications, instead of %d.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 407f435245f5..024d5feb5856 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -788,7 +788,7 @@ struct btrfs_fs_info {
 	unsigned long pending_changes;
 	unsigned long compress_type:4;
 	unsigned int compress_level;
-	int commit_interval;
+	u32 commit_interval;
 	/*
 	 * It is a suggestive number, the read side is safe even it gets a
 	 * wrong number because we will write out the data into a regular

commit f7b885befd05fa4f546cdc3e6c9a3b4a30484cd1
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Feb 13 17:50:42 2018 +0800

    btrfs: manage thread_pool mount option as %u
    
    The mount option thread_pool is always unsigned. Manage it that way all
    around.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2c96275c17e6..407f435245f5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -935,7 +935,7 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *extent_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
-	int thread_pool_size;
+	u32 thread_pool_size;
 
 	struct kobject *space_info_kobj;
 

commit 21217054203cd10f26ba133352046895c16cd3de
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Feb 7 17:55:41 2018 +0200

    btrfs: Don't pass fs_info arg to btrfs_start_dirty_block_groups
    
    It can be referenced from the passed transaction so no point in passing
    it as a function argument. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d58625a31109..2c96275c17e6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2675,8 +2675,7 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 u64 bytenr, u64 num_bytes, u64 parent,
 			 u64 root_objectid, u64 owner, u64 offset);
 
-int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans,
-				   struct btrfs_fs_info *fs_info);
+int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				   struct btrfs_fs_info *fs_info);
 int btrfs_setup_space_cache(struct btrfs_trans_handle *trans,

commit 6c686b359a2dc501353ea61adcca441dd1473e91
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Feb 7 17:55:40 2018 +0200

    btrfs: Remove fs_info argument from btrfs_create_pending_block_groups
    
    It can be referenced from the passed transaciton so no point in
    passing it as function argument. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f7ab01fa5315..d58625a31109 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2697,8 +2697,7 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
-void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
-				       struct btrfs_fs_info *fs_info);
+void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans);
 u64 btrfs_data_alloc_profile(struct btrfs_fs_info *fs_info);
 u64 btrfs_metadata_alloc_profile(struct btrfs_fs_info *fs_info);
 u64 btrfs_system_alloc_profile(struct btrfs_fs_info *fs_info);

commit 0e34693f7bb149273b747194b3988801a9ca8c8e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Feb 7 17:55:37 2018 +0200

    btrfs: Make btrfs_trans_release_metadata private to transaction.c
    
    This function is only ever used in __btrfs_end_transaction and
    btrfs_commit_transaction so there is no need to export it via header.
    Let's move it closer to where it's used, make it static and remove it
    from the header. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index da308774b8a4..f7ab01fa5315 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2733,8 +2733,6 @@ void btrfs_delalloc_release_space(struct inode *inode,
 			struct extent_changeset *reserved, u64 start, u64 len);
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);
-void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
-				  struct btrfs_fs_info *fs_info);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
 				  struct btrfs_inode *inode);

commit 1f250e929a9c9332fd6ea34da684afee73837cfe
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 28 15:56:10 2018 +0000

    Btrfs: fix log replay failure after unlink and link combination
    
    If we have a file with 2 (or more) hard links in the same directory,
    remove one of the hard links, create a new file (or link an existing file)
    in the same directory with the name of the removed hard link, and then
    finally fsync the new file, we end up with a log that fails to replay,
    causing a mount failure.
    
    Example:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ mkdir /mnt/testdir
      $ touch /mnt/testdir/foo
      $ ln /mnt/testdir/foo /mnt/testdir/bar
    
      $ sync
    
      $ unlink /mnt/testdir/bar
      $ touch /mnt/testdir/bar
      $ xfs_io -c "fsync" /mnt/testdir/bar
    
      <power failure>
    
      $ mount /dev/sdb /mnt
      mount: mount(2) failed: /mnt: No such file or directory
    
    When replaying the log, for that example, we also see the following in
    dmesg/syslog:
    
      [71813.671307] BTRFS info (device dm-0): failed to delete reference to bar, inode 258 parent 257
      [71813.674204] ------------[ cut here ]------------
      [71813.675694] BTRFS: Transaction aborted (error -2)
      [71813.677236] WARNING: CPU: 1 PID: 13231 at fs/btrfs/inode.c:4128 __btrfs_unlink_inode+0x17b/0x355 [btrfs]
      [71813.679669] Modules linked in: btrfs xfs f2fs dm_flakey dm_mod dax ghash_clmulni_intel ppdev pcbc aesni_intel aes_x86_64 crypto_simd cryptd glue_helper evdev psmouse i2c_piix4 parport_pc i2c_core pcspkr sg serio_raw parport button sunrpc loop autofs4 ext4 crc16 mbcache jbd2 zstd_decompress zstd_compress xxhash raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c crc32c_generic raid1 raid0 multipath linear md_mod ata_generic sd_mod virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel floppy virtio e1000 scsi_mod [last unloaded: btrfs]
      [71813.679669] CPU: 1 PID: 13231 Comm: mount Tainted: G        W        4.15.0-rc9-btrfs-next-56+ #1
      [71813.679669] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
      [71813.679669] RIP: 0010:__btrfs_unlink_inode+0x17b/0x355 [btrfs]
      [71813.679669] RSP: 0018:ffffc90001cef738 EFLAGS: 00010286
      [71813.679669] RAX: 0000000000000025 RBX: ffff880217ce4708 RCX: 0000000000000001
      [71813.679669] RDX: 0000000000000000 RSI: ffffffff81c14bae RDI: 00000000ffffffff
      [71813.679669] RBP: ffffc90001cef7c0 R08: 0000000000000001 R09: 0000000000000001
      [71813.679669] R10: ffffc90001cef5e0 R11: ffffffff8343f007 R12: ffff880217d474c8
      [71813.679669] R13: 00000000fffffffe R14: ffff88021ccf1548 R15: 0000000000000101
      [71813.679669] FS:  00007f7cee84c480(0000) GS:ffff88023fc80000(0000) knlGS:0000000000000000
      [71813.679669] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [71813.679669] CR2: 00007f7cedc1abf9 CR3: 00000002354b4003 CR4: 00000000001606e0
      [71813.679669] Call Trace:
      [71813.679669]  btrfs_unlink_inode+0x17/0x41 [btrfs]
      [71813.679669]  drop_one_dir_item+0xfa/0x131 [btrfs]
      [71813.679669]  add_inode_ref+0x71e/0x851 [btrfs]
      [71813.679669]  ? __lock_is_held+0x39/0x71
      [71813.679669]  ? replay_one_buffer+0x53/0x53a [btrfs]
      [71813.679669]  replay_one_buffer+0x4a4/0x53a [btrfs]
      [71813.679669]  ? rcu_read_unlock+0x3a/0x57
      [71813.679669]  ? __lock_is_held+0x39/0x71
      [71813.679669]  walk_up_log_tree+0x101/0x1d2 [btrfs]
      [71813.679669]  walk_log_tree+0xad/0x188 [btrfs]
      [71813.679669]  btrfs_recover_log_trees+0x1fa/0x31e [btrfs]
      [71813.679669]  ? replay_one_extent+0x544/0x544 [btrfs]
      [71813.679669]  open_ctree+0x1cf6/0x2209 [btrfs]
      [71813.679669]  btrfs_mount_root+0x368/0x482 [btrfs]
      [71813.679669]  ? trace_hardirqs_on_caller+0x14c/0x1a6
      [71813.679669]  ? __lockdep_init_map+0x176/0x1c2
      [71813.679669]  ? mount_fs+0x64/0x10b
      [71813.679669]  mount_fs+0x64/0x10b
      [71813.679669]  vfs_kern_mount+0x68/0xce
      [71813.679669]  btrfs_mount+0x13e/0x772 [btrfs]
      [71813.679669]  ? trace_hardirqs_on_caller+0x14c/0x1a6
      [71813.679669]  ? __lockdep_init_map+0x176/0x1c2
      [71813.679669]  ? mount_fs+0x64/0x10b
      [71813.679669]  mount_fs+0x64/0x10b
      [71813.679669]  vfs_kern_mount+0x68/0xce
      [71813.679669]  do_mount+0x6e5/0x973
      [71813.679669]  ? memdup_user+0x3e/0x5c
      [71813.679669]  SyS_mount+0x72/0x98
      [71813.679669]  entry_SYSCALL_64_fastpath+0x1e/0x8b
      [71813.679669] RIP: 0033:0x7f7cedf150ba
      [71813.679669] RSP: 002b:00007ffca71da688 EFLAGS: 00000206
      [71813.679669] Code: 7f a0 e8 51 0c fd ff 48 8b 43 50 f0 0f ba a8 30 2c 00 00 02 72 17 41 83 fd fb 74 11 44 89 ee 48 c7 c7 7d 11 7f a0 e8 38 f5 8d e0 <0f> ff 44 89 e9 ba 20 10 00 00 eb 4d 48 8b 4d b0 48 8b 75 88 4c
      [71813.679669] ---[ end trace 83bd473fc5b4663b ]---
      [71813.854764] BTRFS: error (device dm-0) in __btrfs_unlink_inode:4128: errno=-2 No such entry
      [71813.886994] BTRFS: error (device dm-0) in btrfs_replay_log:2307: errno=-2 No such entry (Failed to recover log tree)
      [71813.903357] BTRFS error (device dm-0): cleaner transaction attach returned -30
      [71814.128078] BTRFS error (device dm-0): open_ctree failed
    
    This happens because the log has inode reference items for both inode 258
    (the first file we created) and inode 259 (the second file created), and
    when processing the reference item for inode 258, we replace the
    corresponding item in the subvolume tree (which has two names, "foo" and
    "bar") witht he one in the log (which only has one name, "foo") without
    removing the corresponding dir index keys from the parent directory.
    Later, when processing the inode reference item for inode 259, which has
    a name of "bar" associated to it, we notice that dir index entries exist
    for that name and for a different inode, so we attempt to unlink that
    name, which fails because the inode reference item for inode 258 no longer
    has the name "bar" associated to it, making a call to btrfs_unlink_inode()
    fail with a -ENOENT error.
    
    Fix this by unlinking all the names in an inode reference item from a
    subvolume tree that are not present in the inode reference item found in
    the log tree, before overwriting it with the item from the log tree.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0f521ba5f2f9..da308774b8a4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3095,7 +3095,10 @@ btrfs_lookup_inode_extref(struct btrfs_trans_handle *trans,
 			  u64 inode_objectid, u64 ref_objectid, int ins_len,
 			  int cow);
 
-int btrfs_find_name_in_ext_backref(struct btrfs_path *path,
+int btrfs_find_name_in_backref(struct extent_buffer *leaf, int slot,
+			       const char *name,
+			       int name_len, struct btrfs_inode_ref **ref_ret);
+int btrfs_find_name_in_ext_backref(struct extent_buffer *leaf, int slot,
 				   u64 ref_objectid, const char *name,
 				   int name_len,
 				   struct btrfs_inode_extref **extref_ret);

commit a8fd1f71749387c9a1053a83ff1c16287499a4e7
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Feb 15 22:59:47 2018 -0500

    btrfs: use kvzalloc to allocate btrfs_fs_info
    
    The srcu_struct in btrfs_fs_info scales in size with NR_CPUS.  On
    kernels built with NR_CPUS=8192, this can result in kmalloc failures
    that prevent mounting.
    
    There is work in progress to try to resolve this for every user of
    srcu_struct but using kvzalloc will work around the failures until
    that is complete.
    
    As an example with NR_CPUS=512 on x86_64: the overall size of
    subvol_srcu is 3460 bytes, fs_info is 6496.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1a462ab85c49..0f521ba5f2f9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2974,7 +2974,7 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
 	security_free_mnt_opts(&fs_info->security_opts);
-	kfree(fs_info);
+	kvfree(fs_info);
 }
 
 /* tree mod log functions from ctree.c */

commit c04e61b5e41b0e8ace4aa4b67685fbe68ac37a46
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Jan 5 12:51:11 2018 -0700

    Btrfs: move extent map specific code to extent_map.c
    
    These helpers are extent map specific, move them to extent_map.c.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e05fc7e0e35..1a462ab85c49 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3143,8 +3143,6 @@ struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,
 						    int delay_iput);
 void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
 
-int btrfs_add_extent_mapping(struct extent_map_tree *em_tree,
-			     struct extent_map **em_in, u64 start, u64 len);
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start,
 		u64 len, int create);

commit 7b4df058b051fb67db61ea371f7d278131cb6e7b
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Jan 5 12:51:10 2018 -0700

    Btrfs: add helper for em merge logic
    
    This is a prepare work for the following extent map selftest, which
    runs tests against em merge logic.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1a462ab85c49..1e05fc7e0e35 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3143,6 +3143,8 @@ struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,
 						    int delay_iput);
 void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
 
+int btrfs_add_extent_mapping(struct extent_map_tree *em_tree,
+			     struct extent_map **em_in, u64 start, u64 len);
 struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start,
 		u64 len, int create);

commit 203e02d934ed0570551b87c8d0a0a9cf917487cb
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Dec 22 16:23:01 2017 -0700

    Btrfs: remove unused wait in btrfs_stripe_hash
    
    In fact nobody is waiting on @wait's waitqueue, it can be safely
    removed.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 09b72b6996ce..1a462ab85c49 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -679,7 +679,6 @@ enum btrfs_orphan_cleanup_state {
 /* used by the raid56 code to lock stripes for read/modify/write */
 struct btrfs_stripe_hash {
 	struct list_head hash_list;
-	wait_queue_head_t wait;
 	spinlock_t lock;
 };
 

commit bae15d95e247f94ceb32caaf13d1d71ecbfc8735
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Nov 8 08:54:26 2017 +0800

    btrfs: Cleanup existing name_len checks
    
    Since tree-checker has verified leaf when reading from disk, we don't
    need the existing verify_dir_item() or btrfs_is_name_len_valid() checks.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a56d00311578..09b72b6996ce 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3060,15 +3060,10 @@ struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
 					  struct btrfs_path *path, u64 dir,
 					  const char *name, u16 name_len,
 					  int mod);
-int verify_dir_item(struct btrfs_fs_info *fs_info,
-		    struct extent_buffer *leaf, int slot,
-		    struct btrfs_dir_item *dir_item);
 struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_fs_info *fs_info,
 						 struct btrfs_path *path,
 						 const char *name,
 						 int name_len);
-bool btrfs_is_name_len_valid(struct extent_buffer *leaf, int slot,
-			     unsigned long start, u16 name_len);
 
 /* orphan.c */
 int btrfs_insert_orphan_item(struct btrfs_trans_handle *trans,

commit f5c29bd9dbd3e90e03ab7697ecc373b49394e62e
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Nov 2 17:21:50 2017 -0600

    Btrfs: add __init macro to btrfs init functions
    
    Adding __init macro gives kernel a hint that this function is only used
    during the initialization phase and its memory resources can be freed up
    after.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 13c260b525a1..a56d00311578 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3197,7 +3197,7 @@ int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);
-int btrfs_init_cachep(void);
+int __init btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
@@ -3248,7 +3248,7 @@ ssize_t btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
 			   struct file *dst_file, u64 dst_loff);
 
 /* file.c */
-int btrfs_auto_defrag_init(void);
+int __init btrfs_auto_defrag_init(void);
 void btrfs_auto_defrag_exit(void);
 int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 			   struct btrfs_inode *inode);
@@ -3283,7 +3283,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root);
 
 /* sysfs.c */
-int btrfs_init_sysfs(void);
+int __init btrfs_init_sysfs(void);
 void btrfs_exit_sysfs(void);
 int btrfs_sysfs_add_mounted(struct btrfs_fs_info *fs_info);
 void btrfs_sysfs_remove_mounted(struct btrfs_fs_info *fs_info);

commit 26cd94744e142dd5d5a21e2c1e31bacc120b2d74
Merge: 198e0c0c61b6 ea37d5998b50
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 29 14:26:50 2017 -0800

    Merge tag 'for-4.15-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "We've collected some fixes in since the pre-merge window freeze.
    
      There's technically only one regression fix for 4.15, but the rest
      seems important and candidates for stable.
    
       - fix missing flush bio puts in error cases (is serious, but rarely
         happens)
    
       - fix reporting stat::st_blocks for buffered append writes
    
       - fix space cache invalidation
    
       - fix out of bound memory access when setting zlib level
    
       - fix potential memory corruption when fsync fails in the middle
    
       - fix crash in integrity checker
    
       - incremetnal send fix, path mixup for certain unlink/rename
         combination
    
       - pass flags to writeback so compressed writes can be throttled
         properly
    
       - error handling fixes"
    
    * tag 'for-4.15-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      Btrfs: incremental send, fix wrong unlink path after renaming file
      btrfs: tree-checker: Fix false panic for sanity test
      Btrfs: fix list_add corruption and soft lockups in fsync
      btrfs: Fix wild memory access in compression level parser
      btrfs: fix deadlock when writing out space cache
      btrfs: clear space cache inode generation always
      Btrfs: fix reported number of inode blocks after buffered append writes
      Btrfs: move definition of the function btrfs_find_new_delalloc_bytes
      Btrfs: bail out gracefully rather than BUG_ON
      btrfs: dev_alloc_list is not protected by RCU, use normal list_del
      btrfs: add missing device::flush_bio puts
      btrfs: Fix transaction abort during failure in btrfs_rm_dev_item
      Btrfs: add write_flags for compression bio

commit 1751e8a6cb935e555fcdbcb9ab4f0446e322ca3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 27 13:05:09 2017 -0800

    Rename superblock flags (MS_xyz -> SB_xyz)
    
    This is a pure automated search-and-replace of the internal kernel
    superblock flags.
    
    The s_flags are now called SB_*, with the names and the values for the
    moment mirroring the MS_* flags that they're equivalent to.
    
    Note how the MS_xyz flags are the ones passed to the mount system call,
    while the SB_xyz flags are what we then use in sb->s_flags.
    
    The script to do this was:
    
        # places to look in; re security/*: it generally should *not* be
        # touched (that stuff parses mount(2) arguments directly), but
        # there are two places where we really deal with superblock flags.
        FILES="drivers/mtd drivers/staging/lustre fs ipc mm \
                include/linux/fs.h include/uapi/linux/bfs_fs.h \
                security/apparmor/apparmorfs.c security/apparmor/include/lib.h"
        # the list of MS_... constants
        SYMS="RDONLY NOSUID NODEV NOEXEC SYNCHRONOUS REMOUNT MANDLOCK \
              DIRSYNC NOATIME NODIRATIME BIND MOVE REC VERBOSE SILENT \
              POSIXACL UNBINDABLE PRIVATE SLAVE SHARED RELATIME KERNMOUNT \
              I_VERSION STRICTATIME LAZYTIME SUBMOUNT NOREMOTELOCK NOSEC BORN \
              ACTIVE NOUSER"
    
        SED_PROG=
        for i in $SYMS; do SED_PROG="$SED_PROG -e s/MS_$i/SB_$i/g"; done
    
        # we want files that contain at least one of MS_...,
        # with fs/namespace.c and fs/pnode.c excluded.
        L=$(for i in $SYMS; do git grep -w -l MS_$i $FILES; done| sort|uniq|grep -v '^fs/namespace.c'|grep -v '^fs/pnode.c')
    
        for f in $L; do sed -i $f $SED_PROG; done
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f7df5536ab61..51477a537c83 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2957,7 +2957,7 @@ static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
  */
 static inline int btrfs_need_cleaner_sleep(struct btrfs_fs_info *fs_info)
 {
-	return fs_info->sb->s_flags & MS_RDONLY || btrfs_fs_closing(fs_info);
+	return fs_info->sb->s_flags & SB_RDONLY || btrfs_fs_closing(fs_info);
 }
 
 static inline void free_fs_info(struct btrfs_fs_info *fs_info)

commit e3b8a4858566a6cc25422fbfdfdd760b13b79280
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Nov 4 00:16:59 2017 +0000

    Btrfs: fix reported number of inode blocks after buffered append writes
    
    The patch from commit a7e3b975a0f9 ("Btrfs: fix reported number of inode
    blocks") introduced a regression where if we do a buffered write starting
    at position equal to or greater than the file's size and then stat(2) the
    file before writeback is triggered, the number of used blocks does not
    change (unless there's a prealloc/unwritten extent). Example:
    
      $ xfs_io -f -c "pwrite -S 0xab 0 64K" foobar
      $ du -h foobar
      0     foobar
      $ sync
      $ du -h foobar
      64K   foobar
    
    The first version of that patch didn't had this regression and the second
    version, which was the one committed, was made only to address some
    performance regression detected by the intel test robots using fs_mark.
    
    This fixes the regression by setting the new delaloc bit in the range, and
    doing it at btrfs_dirty_pages() while setting the regular dealloc bit as
    well, so that this way we set both bits at once avoiding navigation of the
    inode's io tree twice. Doing it at btrfs_dirty_pages() is also the most
    meaninful place, as we should set the new dellaloc bit when if we set the
    delalloc bit, which happens only if we copied bytes into the pages at
    __btrfs_buffered_write().
    
    This was making some of LTP's du tests fail, which can be quickly run
    using a command line like the following:
    
      $ ./runltp -q -p -l /ltp.log -f commands -s du -d /mnt
    
    Fixes: a7e3b975a0f9 ("Btrfs: fix reported number of inode blocks")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f7df5536ab61..72dcbf19f6ce 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3180,6 +3180,7 @@ int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
 int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int delay_iput,
 			       int nr);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
+			      unsigned int extra_bits,
 			      struct extent_state **cached_state, int dedupe);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root,

commit 69fe2d75dd91d0124ad2ab6e9fef07633bd730e0
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Oct 19 14:15:57 2017 -0400

    btrfs: make the delalloc block rsv per inode
    
    The way we handle delalloc metadata reservations has gotten
    progressively more complicated over the years.  There is so much cruft
    and weirdness around keeping the reserved count and outstanding counters
    consistent and handling the error cases that it's impossible to
    understand.
    
    Fix this by making the delalloc block rsv per-inode.  This way we can
    calculate the actual size of the outstanding metadata reservations every
    time we make a change, and then reserve the delta based on that amount.
    This greatly simplifies the code everywhere, and makes the error
    handling in btrfs_delalloc_reserve_metadata far less terrifying.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2ede3b6ceb68..f7df5536ab61 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -763,8 +763,6 @@ struct btrfs_fs_info {
 	 * delayed dir index item
 	 */
 	struct btrfs_block_rsv global_block_rsv;
-	/* block reservation for delay allocation */
-	struct btrfs_block_rsv delalloc_block_rsv;
 	/* block reservation for metadata operations */
 	struct btrfs_block_rsv trans_block_rsv;
 	/* block reservation for chunk tree */
@@ -2757,6 +2755,9 @@ int btrfs_delalloc_reserve_space(struct inode *inode,
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_fs_info *fs_info,
 					      unsigned short type);
+void btrfs_init_metadata_block_rsv(struct btrfs_fs_info *fs_info,
+				   struct btrfs_block_rsv *rsv,
+				   unsigned short type);
 void btrfs_free_block_rsv(struct btrfs_fs_info *fs_info,
 			  struct btrfs_block_rsv *rsv);
 void __btrfs_free_block_rsv(struct btrfs_block_rsv *rsv);

commit 8b62f87bad9cf06e536799bf8cb942ab95f6bfa4
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Oct 19 14:15:55 2017 -0400

    Btrfs: rework outstanding_extents
    
    Right now we do a lot of weird hoops around outstanding_extents in order
    to keep the extent count consistent.  This is because we logically
    transfer the outstanding_extent count from the initial reservation
    through the set_delalloc_bits.  This makes it pretty difficult to get a
    handle on how and when we need to mess with outstanding_extents.
    
    Fix this by revamping the rules of how we deal with outstanding_extents.
    Now instead everybody that is holding on to a delalloc extent is
    required to increase the outstanding extents count for itself.  This
    means we'll have something like this
    
    btrfs_delalloc_reserve_metadata - outstanding_extents = 1
     btrfs_set_extent_delalloc      - outstanding_extents = 2
    btrfs_release_delalloc_extents  - outstanding_extents = 1
    
    for an initial file write.  Now take the append write where we extend an
    existing delalloc range but still under the maximum extent size
    
    btrfs_delalloc_reserve_metadata - outstanding_extents = 2
      btrfs_set_extent_delalloc
        btrfs_set_bit_hook          - outstanding_extents = 3
        btrfs_merge_extent_hook     - outstanding_extents = 2
    btrfs_delalloc_release_extents  - outstanding_extnets = 1
    
    In order to make the ordered extent transition we of course must now
    make ordered extents carry their own outstanding_extent reservation, so
    for cow_file_range we end up with
    
    btrfs_add_ordered_extent        - outstanding_extents = 2
    clear_extent_bit                - outstanding_extents = 1
    btrfs_remove_ordered_extent     - outstanding_extents = 0
    
    This makes all manipulations of outstanding_extents much more explicit.
    Every successful call to btrfs_delalloc_reserve_metadata _must_ now be
    combined with btrfs_release_delalloc_extents, even in the error case, as
    that is the only function that actually modifies the
    outstanding_extents counter.
    
    The drawback to this is now we are much more likely to have transient
    cases where outstanding_extents is much larger than it actually should
    be.  This could happen before as we manipulated the delalloc bits, but
    now it happens basically at every write.  This may put more pressure on
    the ENOSPC flushing code, but I think making this code simpler is worth
    the cost.  I have another change coming to mitigate this side-effect
    somewhat.
    
    I also added trace points for the counter manipulation.  These were used
    by a bpf script I wrote to help track down leak issues.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2c02d9524055..2ede3b6ceb68 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2748,6 +2748,8 @@ int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     u64 *qgroup_reserved, bool use_global_rsv);
 void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv);
+void btrfs_delalloc_release_extents(struct btrfs_inode *inode, u64 num_bytes);
+
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode,

commit f51d2b59120ff364a5e612a594ed358767e1cd09
Author: David Sterba <dsterba@suse.com>
Date:   Fri Sep 15 17:36:57 2017 +0200

    btrfs: allow to set compression level for zlib
    
    Preliminary support for setting compression level for zlib, the
    following works:
    
    $ mount -o compess=zlib                 # default
    $ mount -o compess=zlib0                # same
    $ mount -o compess=zlib9                # level 9, slower sync, less data
    $ mount -o compess=zlib1                # level 1, faster sync, more data
    $ mount -o remount,compress=zlib3       # level set by remount
    
    The compress-force works the same as compress'.  The level is visible in
    the same format in /proc/mounts. Level set via file property does not
    work yet.
    
    Required patch: "btrfs: prepare for extensions in compression options"
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7bda8429e93f..2c02d9524055 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -790,6 +790,7 @@ struct btrfs_fs_info {
 	 */
 	unsigned long pending_changes;
 	unsigned long compress_type:4;
+	unsigned int compress_level;
 	int commit_interval;
 	/*
 	 * It is a suggestive number, the read side is safe even it gets a

commit d4417e22551377c6e589c15ff2b931610e5230bc
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Oct 16 16:48:40 2017 +0300

    btrfs: Replace opencoded sizes with their symbolic constants
    
    Currently btrfs' code uses a mix of opencoded sizes and defines from sizes.h.
    Let's unifiy the code base to always use the symbolic constants. No functional
    changes
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e2afe524e25e..7bda8429e93f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -523,7 +523,7 @@ struct btrfs_caching_control {
 };
 
 /* Once caching_thread() finds this much free space, it will wake up waiters. */
-#define CACHING_CTL_WAKE_UP (1024 * 1024 * 2)
+#define CACHING_CTL_WAKE_UP SZ_2M
 
 struct btrfs_io_ctl {
 	void *cur, *orig;

commit fd708b81d972a0714b02a60eb4792fdbf15868c4
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Sep 29 15:43:50 2017 -0400

    Btrfs: add a extent ref verify tool
    
    We were having corruption issues that were tied back to problems with
    the extent tree.  In order to track them down I built this tool to try
    and find the culprit, which was pretty successful.  If you compile with
    this tool on it will live verify every ref update that the fs makes and
    make sure it is consistent and valid.  I've run this through with
    xfstests and haven't gotten any false positives.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update error messages, add fixup from Dan Carpenter to handle errors
      of read_tree_block ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2fcc3c30d471..e2afe524e25e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1097,6 +1097,11 @@ struct btrfs_fs_info {
 	u32 nodesize;
 	u32 sectorsize;
 	u32 stripesize;
+
+#ifdef CONFIG_BTRFS_FS_REF_VERIFY
+	spinlock_t ref_verify_lock;
+	struct rb_root block_tree;
+#endif
 };
 
 static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)

commit 84f7d8e6242ceb377c7af10a7133c653cc7fea5f
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Sep 29 15:43:49 2017 -0400

    btrfs: pass root to various extent ref mod functions
    
    We need the actual root for the ref verifier tool to work, so change
    these functions to pass the root around instead.  This will be used in
    a subsequent patch.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 75947c6c04c3..2fcc3c30d471 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2637,7 +2637,7 @@ void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
 			   struct extent_buffer *buf,
 			   u64 parent, int last_ref);
 int btrfs_alloc_reserved_file_extent(struct btrfs_trans_handle *trans,
-				     u64 root_objectid, u64 owner,
+				     struct btrfs_root *root, u64 owner,
 				     u64 offset, u64 ram_bytes,
 				     struct btrfs_key *ins);
 int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
@@ -2656,7 +2656,7 @@ int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 				u64 bytenr, u64 num_bytes, u64 flags,
 				int level, int is_data);
 int btrfs_free_extent(struct btrfs_trans_handle *trans,
-		      struct btrfs_fs_info *fs_info,
+		      struct btrfs_root *root,
 		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,
 		      u64 owner, u64 offset);
 
@@ -2668,7 +2668,7 @@ void btrfs_prepare_extent_commit(struct btrfs_fs_info *fs_info);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_fs_info *fs_info);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
-			 struct btrfs_fs_info *fs_info,
+			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,
 			 u64 root_objectid, u64 owner, u64 offset);
 
@@ -2807,6 +2807,7 @@ void btrfs_set_item_key_safe(struct btrfs_fs_info *fs_info,
 			     const struct btrfs_key *new_key);
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
+struct extent_buffer *btrfs_read_lock_root_node(struct btrfs_root *root);
 int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
 			struct btrfs_key *key, int lowest_level,
 			u64 min_trans);

commit fb592373cddeb4ed6c21eef4d6063f15176ab463
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Sep 29 15:43:48 2017 -0400

    btrfs: add ref-verify mount option
    
    This adds the infrastructure for turning ref verify on and off for a
    mount, to be used by a later patch.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ enhnance btrfs_print_mod_info to print if ref-verify is compiled in ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7995666af959..75947c6c04c3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1335,6 +1335,7 @@ static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_fs_info *info)
 #define BTRFS_MOUNT_FRAGMENT_METADATA	(1 << 25)
 #define BTRFS_MOUNT_FREE_SPACE_TREE	(1 << 26)
 #define BTRFS_MOUNT_NOLOGREPLAY		(1 << 27)
+#define BTRFS_MOUNT_REF_VERIFY		(1 << 28)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 #define BTRFS_DEFAULT_MAX_INLINE	(2048)

commit 736cd52e0c720103f52ab9da47b6cc3af6b083f6
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Sep 7 11:22:22 2017 -0600

    Btrfs: remove nr_async_submits and async_submit_draining
    
    Now that we have the combo of flushing twice, which can make sure IO
    have started since the second flush will wait for page lock which
    won't be unlocked unless setting page writeback and queuing ordered
    extents, we don't need %async_submit_draining, %async_delalloc_pages
    and %nr_async_submits to tell whether the IO has actually started.
    
    Moreover, all the flushers in use are followed by functions that wait
    for ordered extents to complete, so %nr_async_submits, which tracks
    whether bio's async submit has made progress, doesn't really make
    sense.
    
    However, %async_delalloc_pages is still required by shrink_delalloc()
    as that function doesn't flush twice in the normal case (just issues a
    writeback with WB_REASON_FS_FREE_SPACE).
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bc1b6a033700..7995666af959 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -878,8 +878,6 @@ struct btrfs_fs_info {
 	rwlock_t tree_mod_log_lock;
 	struct rb_root tree_mod_log;
 
-	atomic_t nr_async_submits;
-	atomic_t async_submit_draining;
 	atomic_t async_delalloc_pages;
 	atomic_t open_ioctl_trans;
 

commit f851689b5ae3eb8e1b4d397eaf2805ccfd88bf77
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Sep 7 11:22:20 2017 -0600

    Btrfs: remove nr_async_bios
    
    This was intended to congest higher layers to not send bios, but as
    
    1) the congested bit has been taken by writeback
    
    Async bios come from buffered writes and DIO writes.
    
    For DIO writes, we want to submit them ASAP, while for buffered writes,
    writeback uses balance_dirty_pages() to throttle how much dirty pages we
    can have.
    
    2) and no one is waiting for %nr_async_bios down to zero,
    
    Historically, it was introduced along with changes which let
    checksumming workload spread accross different cpus.  And at that time,
    pdflush was used instead of per-bdi flushing, perhaps pdflush did not
    have the necessary information for writeback to do throttling.
    
    We can safely remove them now.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    [ additional explanation from mails, removed unused variable 'limit' ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 16b3537f31d4..bc1b6a033700 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -880,7 +880,6 @@ struct btrfs_fs_info {
 
 	atomic_t nr_async_submits;
 	atomic_t async_submit_draining;
-	atomic_t nr_async_bios;
 	atomic_t async_delalloc_pages;
 	atomic_t open_ioctl_trans;
 

commit ee8c494f88736c1a1873fdd65559828f9a734bcf
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Aug 21 12:43:45 2017 +0300

    btrfs: Remove unused arguments from btrfs_changed_cb_t
    
    btrfs_changed_cb_t represents the signature of the callback being passed
    to btrfs_compare_trees. Currently there is only one such callback,
    namely changed_cb in send.c. This function doesn't really uses the first
    2 parameters, i.e. the roots. Since there are not other functions
    implementing the btrfs_changed_cb_t let's remove the unused parameters
    from the prototype and implementation.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8fc690384c58..16b3537f31d4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2821,9 +2821,7 @@ enum btrfs_compare_tree_result {
 	BTRFS_COMPARE_TREE_CHANGED,
 	BTRFS_COMPARE_TREE_SAME,
 };
-typedef int (*btrfs_changed_cb_t)(struct btrfs_root *left_root,
-				  struct btrfs_root *right_root,
-				  struct btrfs_path *left_path,
+typedef int (*btrfs_changed_cb_t)(struct btrfs_path *left_path,
 				  struct btrfs_path *right_path,
 				  struct btrfs_key *key,
 				  enum btrfs_compare_tree_result result,

commit bf2db0b9f5808fa5b78141b68d55ec630bf06313
Merge: b77779b93d7a 69ad59767d09
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 6 09:03:08 2017 -0700

    Merge branch 'for-4.14-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "Two more fixes for bugs introduced in 4.13.
    
      The sector_t problem with 32bit architecture and !LBDAF config seems
      serious but the number of affected deployments is hopefully low.
    
      The clashing status bits could lead to a confusing in-memory state of
      the whole-filesystem operations if used with the quota override sysfs
      knob"
    
    * 'for-4.14-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      Btrfs: fix overlap of fs_info::flags values
      btrfs: avoid overflow when sector_t is 32 bit

commit 69ad59767d094752c23c0fc180a79532fde073d0
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Wed Oct 4 11:05:17 2017 +0900

    Btrfs: fix overlap of fs_info::flags values
    
    Because the values of BTRFS_FS_EXCL_OP and BTRFS_FS_QUOTA_OVERRIDE overlap,
    we should change the value.
    
    First, BTRFS_FS_EXCL_OP was set to 14.
    
      commit 171938e52807 ("btrfs: track exclusive filesystem operation in flags")
    
    Next, the value of BTRFS_FS_QUOTA_OVERRIDE was set to 14.
    
      commit f29efe292198 ("btrfs: add quota override flag to enable quota override for CAP_SYS_RESOURCE")
    
    As a result, the value 14 overlapped, by accident.
    This problem is solved by defining the value of BTRFS_FS_EXCL_OP as 16,
    the flags are internal.
    
    Fixes: f29efe292198 ("btrfs: add quota override flag to enable quota override for CAP_SYS_RESOURCE")
    CC: stable@vger.kernel.org # 4.13+
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minimize the change, update only BTRFS_FS_EXCL_OP ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b7ccfcc01732..aff3248beb90 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -721,7 +721,7 @@ struct btrfs_delayed_root;
  * Indicate that a whole-filesystem exclusive operation is running
  * (device replace, resize, device add/delete, balance)
  */
-#define BTRFS_FS_EXCL_OP			14
+#define BTRFS_FS_EXCL_OP			16
 
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];

commit 5ba88cd6e9a658be0cdcaf4fc0438b7d63d32bf6
Merge: 7b5ef82336e7 8c6c592831a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 29 12:57:35 2017 -0700

    Merge branch 'for-4.14-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "We've collected a bunch of isolated fixes, for crashes, user-visible
      behaviour or missing bits from other subsystem cleanups from the past.
    
      The overall number is not small but I was not able to make it
      significantly smaller. Most of the patches are supposed to go to
      stable"
    
    * 'for-4.14-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      btrfs: log csums for all modified extents
      Btrfs: fix unexpected result when dio reading corrupted blocks
      btrfs: Report error on removing qgroup if del_qgroup_item fails
      Btrfs: skip checksum when reading compressed data if some IO have failed
      Btrfs: fix kernel oops while reading compressed data
      Btrfs: use btrfs_op instead of bio_op in __btrfs_map_block
      Btrfs: do not backup tree roots when fsync
      btrfs: remove BTRFS_FS_QUOTA_DISABLING flag
      btrfs: propagate error to btrfs_cmp_data_prepare caller
      btrfs: prevent to set invalid default subvolid
      Btrfs: send: fix error number for unknown inode types
      btrfs: fix NULL pointer dereference from free_reloc_roots()
      btrfs: finish ordered extent cleaning if no progress is found
      btrfs: clear ordered flag on cleaning up ordered extents
      Btrfs: fix incorrect {node,sector}size endianness from BTRFS_IOC_FS_INFO
      Btrfs: do not reset bio->bi_ops while writing bio
      Btrfs: use the new helper wbc_to_write_flags

commit c2faff790ccd11ea5be8e3ca99713f116fcd6030
Author: Misono, Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Wed Aug 30 16:33:16 2017 +0900

    btrfs: remove BTRFS_FS_QUOTA_DISABLING flag
    
    Currently, "btrfs quota enable" would fail after "btrfs quota disable" on
    the first time with syslog output "qgroup_rescan_init failed with -22", but
    it would succeed on the second time.
    
    When "quota disable" is called, BTRFS_FS_QUOTA_DISABLING flag bit will be
    set in fs_info->flags in btrfs_quota_disable(), but it will not be droppd
    in btrfs_run_qgroups() (which is called in btrfs_commit_transaction())
    because quota_root has already been freed. If "quota enable" is called
    after that, both BTRFS_FS_QUOTA_DISABLING and BTRFS_FS_QUOTA_ENABLED flag
    would be dropped in the btrfs_run_qgroups() since quota_root is not NULL.
    This leads to the failure of "quota enable" on the first time.
    
    BTRFS_FS_QUOTA_DISABLING flag is not used outside of "quota disable"
    context and is equivalent to whether quota_root is NULL or not.
    btrfs_run_qgroups() checks whether quota_root is NULL or not in the first
    place.
    
    So, let's remove BTRFS_FS_QUOTA_DISABLING flag.
    
    Signed-off-by: Tomohiro Misono <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2add002662f4..b7ccfcc01732 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -708,7 +708,6 @@ struct btrfs_delayed_root;
 #define BTRFS_FS_OPEN				5
 #define BTRFS_FS_QUOTA_ENABLED			6
 #define BTRFS_FS_QUOTA_ENABLING			7
-#define BTRFS_FS_QUOTA_DISABLING		8
 #define BTRFS_FS_UPDATE_UUID_TREE_GEN		9
 #define BTRFS_FS_CREATING_FREE_SPACE_TREE	10
 #define BTRFS_FS_BTREE_ERR			11

commit e7cdb60fd28b252f1c15a0e50f79a01906124915
Merge: a2bc8dea9e96 87bf54bb43dd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 17:30:49 2017 -0700

    Merge branch 'zstd-minimal' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull zstd support from Chris Mason:
     "Nick Terrell's patch series to add zstd support to the kernel has been
      floating around for a while. After talking with Dave Sterba, Herbert
      and Phillip, we decided to send the whole thing in as one pull
      request.
    
      zstd is a big win in speed over zlib and in compression ratio over
      lzo, and the compression team here at FB has gotten great results
      using it in production. Nick will continue to update the kernel side
      with new improvements from the open source zstd userland code.
    
      Nick has a number of benchmarks for the main zstd code in his lib/zstd
      commit:
    
          I ran the benchmarks on a Ubuntu 14.04 VM with 2 cores and 4 GiB
          of RAM. The VM is running on a MacBook Pro with a 3.1 GHz Intel
          Core i7 processor, 16 GB of RAM, and a SSD. I benchmarked using
          `silesia.tar` [3], which is 211,988,480 B large. Run the following
          commands for the benchmark:
    
            sudo modprobe zstd_compress_test
            sudo mknod zstd_compress_test c 245 0
            sudo cp silesia.tar zstd_compress_test
    
          The time is reported by the time of the userland `cp`.
          The MB/s is computed with
    
            1,536,217,008 B / time(buffer size, hash)
    
          which includes the time to copy from userland.
          The Adjusted MB/s is computed with
    
            1,536,217,088 B / (time(buffer size, hash) - time(buffer size, none)).
    
          The memory reported is the amount of memory the compressor
          requests.
    
            | Method   | Size (B) | Time (s) | Ratio | MB/s    | Adj MB/s | Mem (MB) |
            |----------|----------|----------|-------|---------|----------|----------|
            | none     | 11988480 |    0.100 |     1 | 2119.88 |        - |        - |
            | zstd -1  | 73645762 |    1.044 | 2.878 |  203.05 |   224.56 |     1.23 |
            | zstd -3  | 66988878 |    1.761 | 3.165 |  120.38 |   127.63 |     2.47 |
            | zstd -5  | 65001259 |    2.563 | 3.261 |   82.71 |    86.07 |     2.86 |
            | zstd -10 | 60165346 |   13.242 | 3.523 |   16.01 |    16.13 |    13.22 |
            | zstd -15 | 58009756 |   47.601 | 3.654 |    4.45 |     4.46 |    21.61 |
            | zstd -19 | 54014593 |  102.835 | 3.925 |    2.06 |     2.06 |    60.15 |
            | zlib -1  | 77260026 |    2.895 | 2.744 |   73.23 |    75.85 |     0.27 |
            | zlib -3  | 72972206 |    4.116 | 2.905 |   51.50 |    52.79 |     0.27 |
            | zlib -6  | 68190360 |    9.633 | 3.109 |   22.01 |    22.24 |     0.27 |
            | zlib -9  | 67613382 |   22.554 | 3.135 |    9.40 |     9.44 |     0.27 |
    
          I benchmarked zstd decompression using the same method on the same
          machine. The benchmark file is located in the upstream zstd repo
          under `contrib/linux-kernel/zstd_decompress_test.c` [4]. The
          memory reported is the amount of memory required to decompress
          data compressed with the given compression level. If you know the
          maximum size of your input, you can reduce the memory usage of
          decompression irrespective of the compression level.
    
            | Method   | Time (s) | MB/s    | Adjusted MB/s | Memory (MB) |
            |----------|----------|---------|---------------|-------------|
            | none     |    0.025 | 8479.54 |             - |           - |
            | zstd -1  |    0.358 |  592.15 |        636.60 |        0.84 |
            | zstd -3  |    0.396 |  535.32 |        571.40 |        1.46 |
            | zstd -5  |    0.396 |  535.32 |        571.40 |        1.46 |
            | zstd -10 |    0.374 |  566.81 |        607.42 |        2.51 |
            | zstd -15 |    0.379 |  559.34 |        598.84 |        4.61 |
            | zstd -19 |    0.412 |  514.54 |        547.77 |        8.80 |
            | zlib -1  |    0.940 |  225.52 |        231.68 |        0.04 |
            | zlib -3  |    0.883 |  240.08 |        247.07 |        0.04 |
            | zlib -6  |    0.844 |  251.17 |        258.84 |        0.04 |
            | zlib -9  |    0.837 |  253.27 |        287.64 |        0.04 |
    
      I ran a long series of tests and benchmarks on the btrfs side and the
      gains are very similar to the core benchmarks Nick ran"
    
    * 'zstd-minimal' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      squashfs: Add zstd support
      btrfs: Add zstd support
      lib: Add zstd modules
      lib: Add xxhash module

commit 1cd5447eb677822c5c22bb52161c2105507dcce0
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Aug 17 10:25:11 2017 -0400

    btrfs: pass fs_info to btrfs_del_root instead of tree_root
    
    btrfs_del_roots always uses the tree_root.  Let's pass fs_info instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b7cfc74c1757..2add002662f4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2988,8 +2988,8 @@ int btrfs_del_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_fs_info *fs_info,
 		       u64 root_id, u64 ref_id, u64 dirid, u64 *sequence,
 		       const char *name, int name_len);
-int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		   const struct btrfs_key *key);
+int btrfs_del_root(struct btrfs_trans_handle *trans,
+		   struct btrfs_fs_info *fs_info, const struct btrfs_key *key);
 int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		      const struct btrfs_key *key,
 		      struct btrfs_root_item *item);

commit 4335958de2a43c6790c7f6aa0682aa7189983fa4
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Aug 18 15:15:20 2017 -0600

    Btrfs: remove BUG() in btrfs_extent_inline_ref_size
    
    Now that btrfs_get_extent_inline_ref_type() can report if type is a
    valid one and all callers can gracefully deal with that, we don't need
    to crash here.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 542db9d0dbcd..b7cfc74c1757 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1804,7 +1804,6 @@ static inline u32 btrfs_extent_inline_ref_size(int type)
 	if (type == BTRFS_EXTENT_DATA_REF_KEY)
 		return sizeof(struct btrfs_extent_data_ref) +
 		       offsetof(struct btrfs_extent_inline_ref, offset);
-	BUG();
 	return 0;
 }
 

commit 167ce953ca55bdee20fe56c3c0fa51002435f745
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Aug 18 15:15:18 2017 -0600

    Btrfs: add a helper to retrive extent inline ref type
    
    An invalid value of extent inline ref type may be read from a
    malicious image which may force btrfs to crash.
    
    This adds a helper which does sanity check for the ref type, so we can
    know if it's sane, return he type, otherwise return an error.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minimal tweak const types, causing warnings due to other cleanup patches ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ca087ad5ac48..542db9d0dbcd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2567,6 +2567,17 @@ static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 
 /* extent-tree.c */
 
+enum btrfs_inline_ref_type {
+	BTRFS_REF_TYPE_INVALID =	 0,
+	BTRFS_REF_TYPE_BLOCK =		 1,
+	BTRFS_REF_TYPE_DATA =		 2,
+	BTRFS_REF_TYPE_ANY =		 3,
+};
+
+int btrfs_get_extent_inline_ref_type(const struct extent_buffer *eb,
+				     struct btrfs_extent_inline_ref *iref,
+				     enum btrfs_inline_ref_type is_data);
+
 u64 btrfs_csum_bytes_to_leaves(struct btrfs_fs_info *fs_info, u64 csum_bytes);
 
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,

commit 0174484d619460a65e88f594c36983cd2b7f4128
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Jul 27 14:22:11 2017 +0300

    btrfs: Remove chunk_objectid argument from btrfs_make_block_group
    
    btrfs_make_block_group is always called with chunk_objectid set to
    BTRFS_FIRST_CHUNK_TREE_OBJECTID. There's no reason why this behavior will
    change anytime soon, so let's remove the argument and decrease the cognitive
    load when reading the code path. No functional change
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 02edcddbcc9c..ca087ad5ac48 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2676,8 +2676,7 @@ int btrfs_read_block_groups(struct btrfs_fs_info *info);
 int btrfs_can_relocate(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_fs_info *fs_info, u64 bytes_used,
-			   u64 type, u64 chunk_objectid, u64 chunk_offset,
-			   u64 size);
+			   u64 type, u64 chunk_offset, u64 size);
 struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
 				struct btrfs_fs_info *fs_info,
 				const u64 chunk_offset);

commit 583b723151794e2ff1691f1510b4e43710293875
Author: Hans van Kranenburg <hans.van.kranenburg@mendix.com>
Date:   Fri Jul 28 08:31:28 2017 +0200

    btrfs: Do not use data_alloc_cluster in ssd mode
    
        This patch provides a band aid to improve the 'out of the box'
    behaviour of btrfs for disks that are detected as being an ssd.  In a
    general purpose mixed workload scenario, the current ssd mode causes
    overallocation of available raw disk space for data, while leaving
    behind increasing amounts of unused fragmented free space. This
    situation leads to early ENOSPC problems which are harming user
    experience and adoption of btrfs as a general purpose filesystem.
    
    This patch modifies the data extent allocation behaviour of the ssd mode
    to make it behave identical to nossd mode.  The metadata behaviour and
    additional ssd_spread option stay untouched so far.
    
    Recommendations for future development are to reconsider the current
    oversimplified nossd / ssd distinction and the broken detection
    mechanism based on the rotational attribute in sysfs and provide
    experienced users with a more flexible way to choose allocator behaviour
    for data and metadata, optimized for certain use cases, while keeping
    sane 'out of the box' default settings.  The internals of the current
    btrfs code have more potential than what currently gets exposed to the
    user to choose from.
    
        The SSD story...
    
        In the first year of btrfs development, around early 2008, btrfs
    gained a mount option which enables specific functionality for
    filesystems on solid state devices. The first occurance of this
    functionality is in commit e18e4809, labeled "Add mount -o ssd, which
    includes optimizations for seek free storage".
    
    The effect on allocating free space for doing (data) writes is to
    'cluster' writes together, writing them out in contiguous space, as
    opposed to a 'tetris' way of putting all separate writes into any free
    space fragment that fits (which is what the -o nossd behaviour does).
    
    A somewhat simplified explanation of what happens is that, when for
    example, the 'cluster' size is set to 2MiB, when we do some writes, the
    data allocator will search for a free space block that is 2MiB big, and
    put the writes in there. The ssd mode itself might allow a 2MiB cluster
    to be composed of multiple free space extents with some existing data in
    between, while the additional ssd_spread mount option kills off this
    option and requires fully free space.
    
    The idea behind this is (commit 536ac8ae): "The [...] clusters make it
    more likely a given IO will completely overwrite the ssd block, so it
    doesn't have to do an internal rwm cycle."; ssd block meaning nand erase
    block. So, effectively this means applying a "locality based algorithm"
    and trying to outsmart the actual ssd.
    
    Since then, various changes have been made to the involved code, but the
    basic idea is still present, and gets activated whenever the ssd mount
    option is active. This also happens by default, when the rotational flag
    as seen at /sys/block/<device>/queue/rotational is set to 0.
    
        However, there's a number of problems with this approach.
    
        First, what the optimization is trying to do is outsmart the ssd by
    assuming there is a relation between the physical address space of the
    block device as seen by btrfs and the actual physical storage of the
    ssd, and then adjusting data placement. However, since the introduction
    of the Flash Translation Layer (FTL) which is a part of the internal
    controller of an ssd, these attempts are futile. The use of good quality
    FTL in consumer ssd products might have been limited in 2008, but this
    situation has changed drastically soon after that time. Today, even the
    flash memory in your automatic cat feeding machine or your grandma's
    wheelchair has a full featured one.
    
    Second, the behaviour as described above results in the filesystem being
    filled up with badly fragmented free space extents because of relatively
    small pieces of space that are freed up by deletes, but not selected
    again as part of a 'cluster'. Since the algorithm prefers allocating a
    new chunk over going back to tetris mode, the end result is a filesystem
    in which all raw space is allocated, but which is composed of
    underutilized chunks with a 'shotgun blast' pattern of fragmented free
    space. Usually, the next problematic thing that happens is the
    filesystem wanting to allocate new space for metadata, which causes the
    filesystem to fail in spectacular ways.
    
    Third, the default mount options you get for an ssd ('ssd' mode enabled,
    'discard' not enabled), in combination with spreading out writes over
    the full address space and ignoring freed up space leads to worst case
    behaviour in providing information to the ssd itself, since it will
    never learn that all the free space left behind is actually free.  There
    are two ways to let an ssd know previously written data does not have to
    be preserved, which are sending explicit signals using discard or
    fstrim, or by simply overwriting the space with new data.  The worst
    case behaviour is the btrfs ssd_spread mount option in combination with
    not having discard enabled. It has a side effect of minimizing the reuse
    of free space previously written in.
    
    Fourth, the rotational flag in /sys/ does not reliably indicate if the
    device is a locally attached ssd. For example, iSCSI or NBD displays as
    non-rotational, while a loop device on an ssd shows up as rotational.
    
    The combination of the second and third problem effectively means that
    despite all the good intentions, the btrfs ssd mode reliably causes the
    ssd hardware and the filesystem structures and performance to be choked
    to death. The clickbait version of the title of this story would have
    been "Btrfs ssd optimizations considered harmful for ssds".
    
    The current nossd 'tetris' mode (even still without discard) allows a
    pattern of overwriting much more previously used space, causing many
    more implicit discards to happen because of the overwrite information
    the ssd gets. The actual location in the physical address space, as seen
    from the point of view of btrfs is irrelevant, because the actual writes
    to the low level flash are reordered anyway thanks to the FTL.
    
        Changes made in the code
    
    1. Make ssd mode data allocation identical to tetris mode, like nossd.
    2. Adjust and clean up filesystem mount messages so that we can easily
    identify if a kernel has this patch applied or not, when providing
    support to end users. Also, make better use of the *_and_info helpers to
    only trigger messages on actual state changes.
    
        Backporting notes
    
    Notes for whoever wants to backport this patch to their 4.9 LTS kernel:
    * First apply commit 951e7966 "btrfs: drop the nossd flag when
      remounting with -o ssd", or fixup the differences manually.
    * The rest of the conflicts are because of the fs_info refactoring. So,
      for example, instead of using fs_info, it's root->fs_info in
      extent-tree.c
    
    Signed-off-by: Hans van Kranenburg <hans.van.kranenburg@mendix.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a3db2b1738aa..02edcddbcc9c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -470,8 +470,8 @@ struct btrfs_block_rsv {
 
 /*
  * free clusters are used to claim free space in relatively large chunks,
- * allowing us to do less seeky writes.  They are used for all metadata
- * allocations and data allocations in ssd mode.
+ * allowing us to do less seeky writes. They are used for all metadata
+ * allocations. In ssd_spread mode they are also used for data allocations.
  */
 struct btrfs_free_cluster {
 	spinlock_t lock;
@@ -967,7 +967,7 @@ struct btrfs_fs_info {
 
 	struct reloc_control *reloc_ctl;
 
-	/* data_alloc_cluster is only used in ssd mode */
+	/* data_alloc_cluster is only used in ssd_spread mode */
 	struct btrfs_free_cluster data_alloc_cluster;
 
 	/* all metadata allocations go through this cluster */

commit 23b5ec74943f44378b68c0edd8e210a86318ea5e
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Jul 24 15:14:25 2017 -0400

    btrfs: fix readdir deadlock with pagefault
    
    Readdir does dir_emit while under the btree lock.  dir_emit can trigger
    the page fault which means we can deadlock.  Fix this by allocating a
    buffer on opening a directory and copying the readdir into this buffer
    and doing dir_emit from outside of the tree lock.
    
    Thread A
    readdir  <holding tree lock>
      dir_emit
        <page fault>
          down_read(mmap_sem)
    
    Thread B
    mmap write
      down_write(mmap_sem)
        page_mkwrite
          wait_ordered_extents
    
    Process C
    finish_ordered_extent
      insert_reserved_file_extent
       try to lock leaf <hang>
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ copy the deadlock scenario to changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b9d5d95bc583..a3db2b1738aa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1264,6 +1264,11 @@ struct btrfs_root {
 	atomic64_t qgroup_meta_rsv;
 };
 
+struct btrfs_file_private {
+	struct btrfs_trans_handle *trans;
+	void *filldir_buf;
+};
+
 static inline u32 btrfs_inode_sectorsize(const struct inode *inode)
 {
 	return btrfs_sb(inode->i_sb)->sectorsize;

commit d3c0bab5632337f6d3841fbe0dc238a743cb4472
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 22 03:35:28 2017 +0200

    btrfs: remove trivial wrapper btrfs_force_ra
    
    It's a simple call page_cache_sync_readahead, same arguments in the same
    order.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 95a50b88c31e..b9d5d95bc583 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3136,14 +3136,6 @@ noinline int can_nocow_extent(struct inode *inode, u64 offset, u64 *len,
 			      u64 *orig_start, u64 *orig_block_len,
 			      u64 *ram_bytes);
 
-/* This forces readahead on a given range of bytes in an inode */
-static inline void btrfs_force_ra(struct address_space *mapping,
-				  struct file_ra_state *ra, struct file *file,
-				  pgoff_t offset, unsigned long req_size)
-{
-	page_cache_sync_readahead(mapping, ra, file, offset, req_size);
-}
-
 struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry);
 int btrfs_set_inode_index(struct btrfs_inode *dir, u64 *index);
 int btrfs_unlink_inode(struct btrfs_trans_handle *trans,

commit 35dc313046f3f1b95178a307e646e612b288e628
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 22 03:28:55 2017 +0200

    btrfs: drop ancient page flag mappings
    
    There's no PageFsMisc. Added by patch 4881ee5a2e995 in 2008, the flag is
    not present in current kernels.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 874d814da371..95a50b88c31e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3136,13 +3136,6 @@ noinline int can_nocow_extent(struct inode *inode, u64 offset, u64 *len,
 			      u64 *orig_start, u64 *orig_block_len,
 			      u64 *ram_bytes);
 
-/* RHEL and EL kernels have a patch that renames PG_checked to FsMisc */
-#if defined(ClearPageFsMisc) && !defined(ClearPageChecked)
-#define ClearPageChecked ClearPageFsMisc
-#define SetPageChecked SetPageFsMisc
-#define PageChecked PageFsMisc
-#endif
-
 /* This forces readahead on a given range of bytes in an inode */
 static inline void btrfs_force_ra(struct address_space *mapping,
 				  struct file_ra_state *ra, struct file *file,

commit ea14b57fd1954fa3193e025224bbbeab7415c490
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 22 02:19:11 2017 +0200

    btrfs: fix spelling of snapshotting
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6510f246f71e..874d814da371 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1258,7 +1258,7 @@ struct btrfs_root {
 	 */
 	int send_in_progress;
 	struct btrfs_subvolume_writers *subv_writers;
-	atomic_t will_be_snapshoted;
+	atomic_t will_be_snapshotted;
 
 	/* For qgroup metadata space reserve */
 	atomic64_t qgroup_meta_rsv;
@@ -2773,8 +2773,8 @@ int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
 int __get_raid_index(u64 flags);
-int btrfs_start_write_no_snapshoting(struct btrfs_root *root);
-void btrfs_end_write_no_snapshoting(struct btrfs_root *root);
+int btrfs_start_write_no_snapshotting(struct btrfs_root *root);
+void btrfs_end_write_no_snapshotting(struct btrfs_root *root);
 void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info, const u64 type);

commit 19aee8dea31fbaa5139968d20e36e1d78cbf30a0
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Jul 18 17:37:05 2017 +0800

    btrfs: btrfs_inherit_iflags() can be static
    
    btrfs_new_inode() is the only consumer move it to inode.c,
    from ioctl.c.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 06033b5f1657..6510f246f71e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3230,7 +3230,6 @@ long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 long btrfs_compat_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 int btrfs_ioctl_get_supported_features(void __user *arg);
 void btrfs_update_iflags(struct inode *inode);
-void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
 int btrfs_is_empty_uuid(u8 *uuid);
 int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      struct btrfs_ioctl_defrag_range_args *range,

commit bc3cce2378b9eeb420873b17664493e68fd07e8c
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Mar 9 09:34:41 2017 +0800

    btrfs: Cleanup num_tolerated_disk_barrier_failures
    
    As we use per-chunk degradable check, the global
    num_tolerated_disk_barrier_failures is of no use.
    
    We can now remove it.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 34ed3dabd43a..06033b5f1657 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1071,8 +1071,6 @@ struct btrfs_fs_info {
 	/* next backup root to be overwritten */
 	int backup_root_index;
 
-	int num_tolerated_disk_barrier_failures;
-
 	/* device replace state */
 	struct btrfs_dev_replace dev_replace;
 

commit 1cbb1f454e5321e47fc1e6b233066c7ccc979d15
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 28 21:56:53 2017 -0600

    btrfs: struct-funcs, constify readers
    
    We have reader helpers for most of the on-disk structures that use
    an extent_buffer and pointer as offset into the buffer that are
    read-only.  We should mark them as const and, in turn, allow consumers
    of these interfaces to mark the buffers const as well.
    
    No impact on code, but serves as documentation that a buffer is intended
    not to be modified.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 589491040950..34ed3dabd43a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1434,7 +1434,7 @@ do {                                                                   \
 #define BTRFS_INODE_ROOT_ITEM_INIT	(1 << 31)
 
 struct btrfs_map_token {
-	struct extent_buffer *eb;
+	const struct extent_buffer *eb;
 	char *kaddr;
 	unsigned long offset;
 };
@@ -1468,18 +1468,19 @@ static inline void btrfs_init_map_token (struct btrfs_map_token *token)
 			   sizeof(((type *)0)->member)))
 
 #define DECLARE_BTRFS_SETGET_BITS(bits)					\
-u##bits btrfs_get_token_##bits(struct extent_buffer *eb, void *ptr,	\
-			       unsigned long off,			\
-                              struct btrfs_map_token *token);		\
-void btrfs_set_token_##bits(struct extent_buffer *eb, void *ptr,	\
+u##bits btrfs_get_token_##bits(const struct extent_buffer *eb,		\
+			       const void *ptr, unsigned long off,	\
+			       struct btrfs_map_token *token);		\
+void btrfs_set_token_##bits(struct extent_buffer *eb, const void *ptr,	\
 			    unsigned long off, u##bits val,		\
 			    struct btrfs_map_token *token);		\
-static inline u##bits btrfs_get_##bits(struct extent_buffer *eb, void *ptr, \
+static inline u##bits btrfs_get_##bits(const struct extent_buffer *eb,	\
+				       const void *ptr,			\
 				       unsigned long off)		\
 {									\
 	return btrfs_get_token_##bits(eb, ptr, off, NULL);		\
 }									\
-static inline void btrfs_set_##bits(struct extent_buffer *eb, void *ptr, \
+static inline void btrfs_set_##bits(struct extent_buffer *eb, void *ptr,\
 				    unsigned long off, u##bits val)	\
 {									\
        btrfs_set_token_##bits(eb, ptr, off, val, NULL);			\
@@ -1491,7 +1492,8 @@ DECLARE_BTRFS_SETGET_BITS(32)
 DECLARE_BTRFS_SETGET_BITS(64)
 
 #define BTRFS_SETGET_FUNCS(name, type, member, bits)			\
-static inline u##bits btrfs_##name(struct extent_buffer *eb, type *s)	\
+static inline u##bits btrfs_##name(const struct extent_buffer *eb,	\
+				   const type *s)			\
 {									\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
 	return btrfs_get_##bits(eb, s, offsetof(type, member));		\
@@ -1502,7 +1504,8 @@ static inline void btrfs_set_##name(struct extent_buffer *eb, type *s,	\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
 	btrfs_set_##bits(eb, s, offsetof(type, member), val);		\
 }									\
-static inline u##bits btrfs_token_##name(struct extent_buffer *eb, type *s, \
+static inline u##bits btrfs_token_##name(const struct extent_buffer *eb,\
+					 const type *s,			\
 					 struct btrfs_map_token *token)	\
 {									\
 	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
@@ -1517,9 +1520,9 @@ static inline void btrfs_set_token_##name(struct extent_buffer *eb,	\
 }
 
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
-static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
+static inline u##bits btrfs_##name(const struct extent_buffer *eb)	\
 {									\
-	type *p = page_address(eb->pages[0]);				\
+	const type *p = page_address(eb->pages[0]);			\
 	u##bits res = le##bits##_to_cpu(p->member);			\
 	return res;							\
 }									\
@@ -1531,7 +1534,7 @@ static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 }
 
 #define BTRFS_SETGET_STACK_FUNCS(name, type, member, bits)		\
-static inline u##bits btrfs_##name(type *s)				\
+static inline u##bits btrfs_##name(const type *s)			\
 {									\
 	return le##bits##_to_cpu(s->member);				\
 }									\
@@ -1856,7 +1859,7 @@ static inline unsigned long btrfs_node_key_ptr_offset(int nr)
 		sizeof(struct btrfs_key_ptr) * nr;
 }
 
-void btrfs_node_key(struct extent_buffer *eb,
+void btrfs_node_key(const struct extent_buffer *eb,
 		    struct btrfs_disk_key *disk_key, int nr);
 
 static inline void btrfs_set_node_key(struct extent_buffer *eb,
@@ -1885,28 +1888,28 @@ static inline struct btrfs_item *btrfs_item_nr(int nr)
 	return (struct btrfs_item *)btrfs_item_nr_offset(nr);
 }
 
-static inline u32 btrfs_item_end(struct extent_buffer *eb,
+static inline u32 btrfs_item_end(const struct extent_buffer *eb,
 				 struct btrfs_item *item)
 {
 	return btrfs_item_offset(eb, item) + btrfs_item_size(eb, item);
 }
 
-static inline u32 btrfs_item_end_nr(struct extent_buffer *eb, int nr)
+static inline u32 btrfs_item_end_nr(const struct extent_buffer *eb, int nr)
 {
 	return btrfs_item_end(eb, btrfs_item_nr(nr));
 }
 
-static inline u32 btrfs_item_offset_nr(struct extent_buffer *eb, int nr)
+static inline u32 btrfs_item_offset_nr(const struct extent_buffer *eb, int nr)
 {
 	return btrfs_item_offset(eb, btrfs_item_nr(nr));
 }
 
-static inline u32 btrfs_item_size_nr(struct extent_buffer *eb, int nr)
+static inline u32 btrfs_item_size_nr(const struct extent_buffer *eb, int nr)
 {
 	return btrfs_item_size(eb, btrfs_item_nr(nr));
 }
 
-static inline void btrfs_item_key(struct extent_buffer *eb,
+static inline void btrfs_item_key(const struct extent_buffer *eb,
 			   struct btrfs_disk_key *disk_key, int nr)
 {
 	struct btrfs_item *item = btrfs_item_nr(nr);
@@ -1942,8 +1945,8 @@ BTRFS_SETGET_STACK_FUNCS(stack_dir_name_len, struct btrfs_dir_item,
 BTRFS_SETGET_STACK_FUNCS(stack_dir_transid, struct btrfs_dir_item,
 			 transid, 64);
 
-static inline void btrfs_dir_item_key(struct extent_buffer *eb,
-				      struct btrfs_dir_item *item,
+static inline void btrfs_dir_item_key(const struct extent_buffer *eb,
+				      const struct btrfs_dir_item *item,
 				      struct btrfs_disk_key *key)
 {
 	read_eb_member(eb, item, struct btrfs_dir_item, location, key);
@@ -1951,7 +1954,7 @@ static inline void btrfs_dir_item_key(struct extent_buffer *eb,
 
 static inline void btrfs_set_dir_item_key(struct extent_buffer *eb,
 					  struct btrfs_dir_item *item,
-					  struct btrfs_disk_key *key)
+					  const struct btrfs_disk_key *key)
 {
 	write_eb_member(eb, item, struct btrfs_dir_item, location, key);
 }
@@ -1963,8 +1966,8 @@ BTRFS_SETGET_FUNCS(free_space_bitmaps, struct btrfs_free_space_header,
 BTRFS_SETGET_FUNCS(free_space_generation, struct btrfs_free_space_header,
 		   generation, 64);
 
-static inline void btrfs_free_space_key(struct extent_buffer *eb,
-					struct btrfs_free_space_header *h,
+static inline void btrfs_free_space_key(const struct extent_buffer *eb,
+					const struct btrfs_free_space_header *h,
 					struct btrfs_disk_key *key)
 {
 	read_eb_member(eb, h, struct btrfs_free_space_header, location, key);
@@ -1972,7 +1975,7 @@ static inline void btrfs_free_space_key(struct extent_buffer *eb,
 
 static inline void btrfs_set_free_space_key(struct extent_buffer *eb,
 					    struct btrfs_free_space_header *h,
-					    struct btrfs_disk_key *key)
+					    const struct btrfs_disk_key *key)
 {
 	write_eb_member(eb, h, struct btrfs_free_space_header, location, key);
 }
@@ -1999,25 +2002,25 @@ static inline void btrfs_cpu_key_to_disk(struct btrfs_disk_key *disk,
 	disk->objectid = cpu_to_le64(cpu->objectid);
 }
 
-static inline void btrfs_node_key_to_cpu(struct extent_buffer *eb,
-				  struct btrfs_key *key, int nr)
+static inline void btrfs_node_key_to_cpu(const struct extent_buffer *eb,
+					 struct btrfs_key *key, int nr)
 {
 	struct btrfs_disk_key disk_key;
 	btrfs_node_key(eb, &disk_key, nr);
 	btrfs_disk_key_to_cpu(key, &disk_key);
 }
 
-static inline void btrfs_item_key_to_cpu(struct extent_buffer *eb,
-				  struct btrfs_key *key, int nr)
+static inline void btrfs_item_key_to_cpu(const struct extent_buffer *eb,
+					 struct btrfs_key *key, int nr)
 {
 	struct btrfs_disk_key disk_key;
 	btrfs_item_key(eb, &disk_key, nr);
 	btrfs_disk_key_to_cpu(key, &disk_key);
 }
 
-static inline void btrfs_dir_item_key_to_cpu(struct extent_buffer *eb,
-				      struct btrfs_dir_item *item,
-				      struct btrfs_key *key)
+static inline void btrfs_dir_item_key_to_cpu(const struct extent_buffer *eb,
+					     const struct btrfs_dir_item *item,
+					     struct btrfs_key *key)
 {
 	struct btrfs_disk_key disk_key;
 	btrfs_dir_item_key(eb, item, &disk_key);
@@ -2049,7 +2052,7 @@ BTRFS_SETGET_STACK_FUNCS(stack_header_nritems, struct btrfs_header,
 			 nritems, 32);
 BTRFS_SETGET_STACK_FUNCS(stack_header_bytenr, struct btrfs_header, bytenr, 64);
 
-static inline int btrfs_header_flag(struct extent_buffer *eb, u64 flag)
+static inline int btrfs_header_flag(const struct extent_buffer *eb, u64 flag)
 {
 	return (btrfs_header_flags(eb) & flag) == flag;
 }
@@ -2068,7 +2071,7 @@ static inline int btrfs_clear_header_flag(struct extent_buffer *eb, u64 flag)
 	return (flags & flag) == flag;
 }
 
-static inline int btrfs_header_backref_rev(struct extent_buffer *eb)
+static inline int btrfs_header_backref_rev(const struct extent_buffer *eb)
 {
 	u64 flags = btrfs_header_flags(eb);
 	return flags >> BTRFS_BACKREF_REV_SHIFT;
@@ -2088,12 +2091,12 @@ static inline unsigned long btrfs_header_fsid(void)
 	return offsetof(struct btrfs_header, fsid);
 }
 
-static inline unsigned long btrfs_header_chunk_tree_uuid(struct extent_buffer *eb)
+static inline unsigned long btrfs_header_chunk_tree_uuid(const struct extent_buffer *eb)
 {
 	return offsetof(struct btrfs_header, chunk_tree_uuid);
 }
 
-static inline int btrfs_is_leaf(struct extent_buffer *eb)
+static inline int btrfs_is_leaf(const struct extent_buffer *eb)
 {
 	return btrfs_header_level(eb) == 0;
 }
@@ -2127,12 +2130,12 @@ BTRFS_SETGET_STACK_FUNCS(root_stransid, struct btrfs_root_item,
 BTRFS_SETGET_STACK_FUNCS(root_rtransid, struct btrfs_root_item,
 			 rtransid, 64);
 
-static inline bool btrfs_root_readonly(struct btrfs_root *root)
+static inline bool btrfs_root_readonly(const struct btrfs_root *root)
 {
 	return (root->root_item.flags & cpu_to_le64(BTRFS_ROOT_SUBVOL_RDONLY)) != 0;
 }
 
-static inline bool btrfs_root_dead(struct btrfs_root *root)
+static inline bool btrfs_root_dead(const struct btrfs_root *root)
 {
 	return (root->root_item.flags & cpu_to_le64(BTRFS_ROOT_SUBVOL_DEAD)) != 0;
 }
@@ -2189,51 +2192,51 @@ BTRFS_SETGET_STACK_FUNCS(backup_num_devices, struct btrfs_root_backup,
 /* struct btrfs_balance_item */
 BTRFS_SETGET_FUNCS(balance_flags, struct btrfs_balance_item, flags, 64);
 
-static inline void btrfs_balance_data(struct extent_buffer *eb,
-				      struct btrfs_balance_item *bi,
+static inline void btrfs_balance_data(const struct extent_buffer *eb,
+				      const struct btrfs_balance_item *bi,
 				      struct btrfs_disk_balance_args *ba)
 {
 	read_eb_member(eb, bi, struct btrfs_balance_item, data, ba);
 }
 
 static inline void btrfs_set_balance_data(struct extent_buffer *eb,
-					  struct btrfs_balance_item *bi,
-					  struct btrfs_disk_balance_args *ba)
+				  struct btrfs_balance_item *bi,
+				  const struct btrfs_disk_balance_args *ba)
 {
 	write_eb_member(eb, bi, struct btrfs_balance_item, data, ba);
 }
 
-static inline void btrfs_balance_meta(struct extent_buffer *eb,
-				      struct btrfs_balance_item *bi,
+static inline void btrfs_balance_meta(const struct extent_buffer *eb,
+				      const struct btrfs_balance_item *bi,
 				      struct btrfs_disk_balance_args *ba)
 {
 	read_eb_member(eb, bi, struct btrfs_balance_item, meta, ba);
 }
 
 static inline void btrfs_set_balance_meta(struct extent_buffer *eb,
-					  struct btrfs_balance_item *bi,
-					  struct btrfs_disk_balance_args *ba)
+				  struct btrfs_balance_item *bi,
+				  const struct btrfs_disk_balance_args *ba)
 {
 	write_eb_member(eb, bi, struct btrfs_balance_item, meta, ba);
 }
 
-static inline void btrfs_balance_sys(struct extent_buffer *eb,
-				     struct btrfs_balance_item *bi,
+static inline void btrfs_balance_sys(const struct extent_buffer *eb,
+				     const struct btrfs_balance_item *bi,
 				     struct btrfs_disk_balance_args *ba)
 {
 	read_eb_member(eb, bi, struct btrfs_balance_item, sys, ba);
 }
 
 static inline void btrfs_set_balance_sys(struct extent_buffer *eb,
-					 struct btrfs_balance_item *bi,
-					 struct btrfs_disk_balance_args *ba)
+				 struct btrfs_balance_item *bi,
+				 const struct btrfs_disk_balance_args *ba)
 {
 	write_eb_member(eb, bi, struct btrfs_balance_item, sys, ba);
 }
 
 static inline void
 btrfs_disk_balance_args_to_cpu(struct btrfs_balance_args *cpu,
-			       struct btrfs_disk_balance_args *disk)
+			       const struct btrfs_disk_balance_args *disk)
 {
 	memset(cpu, 0, sizeof(*cpu));
 
@@ -2253,7 +2256,7 @@ btrfs_disk_balance_args_to_cpu(struct btrfs_balance_args *cpu,
 
 static inline void
 btrfs_cpu_balance_args_to_disk(struct btrfs_disk_balance_args *disk,
-			       struct btrfs_balance_args *cpu)
+			       const struct btrfs_balance_args *cpu)
 {
 	memset(disk, 0, sizeof(*disk));
 
@@ -2321,7 +2324,7 @@ BTRFS_SETGET_STACK_FUNCS(super_magic, struct btrfs_super_block, magic, 64);
 BTRFS_SETGET_STACK_FUNCS(super_uuid_tree_generation, struct btrfs_super_block,
 			 uuid_tree_generation, 64);
 
-static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
+static inline int btrfs_super_csum_size(const struct btrfs_super_block *s)
 {
 	u16 t = btrfs_super_csum_type(s);
 	/*
@@ -2336,8 +2339,8 @@ static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
  * this returns the address of the start of the last item,
  * which is the stop of the leaf data stack
  */
-static inline unsigned int leaf_data_end(struct btrfs_fs_info *fs_info,
-					 struct extent_buffer *leaf)
+static inline unsigned int leaf_data_end(const struct btrfs_fs_info *fs_info,
+					 const struct extent_buffer *leaf)
 {
 	u32 nr = btrfs_header_nritems(leaf);
 
@@ -2362,7 +2365,7 @@ BTRFS_SETGET_STACK_FUNCS(stack_file_extent_compression,
 			 struct btrfs_file_extent_item, compression, 8);
 
 static inline unsigned long
-btrfs_file_extent_inline_start(struct btrfs_file_extent_item *e)
+btrfs_file_extent_inline_start(const struct btrfs_file_extent_item *e)
 {
 	return (unsigned long)e + BTRFS_FILE_EXTENT_INLINE_DATA_START;
 }
@@ -2396,8 +2399,9 @@ BTRFS_SETGET_FUNCS(file_extent_other_encoding, struct btrfs_file_extent_item,
  * size of any extent headers.  If a file is compressed on disk, this is
  * the compressed size
  */
-static inline u32 btrfs_file_extent_inline_item_len(struct extent_buffer *eb,
-						    struct btrfs_item *e)
+static inline u32 btrfs_file_extent_inline_item_len(
+						const struct extent_buffer *eb,
+						struct btrfs_item *e)
 {
 	return btrfs_item_size(eb, e) - BTRFS_FILE_EXTENT_INLINE_DATA_START;
 }
@@ -2405,9 +2409,9 @@ static inline u32 btrfs_file_extent_inline_item_len(struct extent_buffer *eb,
 /* this returns the number of file bytes represented by the inline item.
  * If an item is compressed, this is the uncompressed size
  */
-static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
-					       int slot,
-					       struct btrfs_file_extent_item *fi)
+static inline u32 btrfs_file_extent_inline_len(const struct extent_buffer *eb,
+					int slot,
+					const struct btrfs_file_extent_item *fi)
 {
 	struct btrfs_map_token token;
 
@@ -2429,8 +2433,8 @@ static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
 
 
 /* btrfs_dev_stats_item */
-static inline u64 btrfs_dev_stats_value(struct extent_buffer *eb,
-					struct btrfs_dev_stats_item *ptr,
+static inline u64 btrfs_dev_stats_value(const struct extent_buffer *eb,
+					const struct btrfs_dev_stats_item *ptr,
 					int index)
 {
 	u64 val;

commit 23d1f73788785a770fe6eb348fee4b26281d2064
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 28 11:05:22 2017 +0300

    btrfs: remove unused sectorsize member
    
    The sectorsize member of btrfs_block_group_cache is unused. So remove it, this
    reduces the number of holes in the struct.
    
    With patch:
    /* size: 856, cachelines: 14, members: 40 */
    /* sum members: 837, holes: 4, sum holes: 19 */
    /* bit holes: 1, sum bit holes: 29 bits */
    /* last cacheline: 24 bytes */
    
    Without patch:
    /* size: 864, cachelines: 14, members: 41 */
    /* sum members: 841, holes: 5, sum holes: 23 */
    /* bit holes: 1, sum bit holes: 29 bits */
    /* last cacheline: 32 bytes */
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3f3eb7b17cac..589491040950 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -558,7 +558,6 @@ struct btrfs_block_group_cache {
 	u64 bytes_super;
 	u64 flags;
 	u64 cache_generation;
-	u32 sectorsize;
 
 	/*
 	 * If the free space extent count exceeds this number, convert the block

commit 5c1aab1dd5445ed8bdcdbb575abc1b0d7ee5b2e7
Author: Nick Terrell <terrelln@fb.com>
Date:   Wed Aug 9 19:39:02 2017 -0700

    btrfs: Add zstd support
    
    Add zstd compression and decompression support to BtrFS. zstd at its
    fastest level compresses almost as well as zlib, while offering much
    faster compression and decompression, approaching lzo speeds.
    
    I benchmarked btrfs with zstd compression against no compression, lzo
    compression, and zlib compression. I benchmarked two scenarios. Copying
    a set of files to btrfs, and then reading the files. Copying a tarball
    to btrfs, extracting it to btrfs, and then reading the extracted files.
    After every operation, I call `sync` and include the sync time.
    Between every pair of operations I unmount and remount the filesystem
    to avoid caching. The benchmark files can be found in the upstream
    zstd source repository under
    `contrib/linux-kernel/{btrfs-benchmark.sh,btrfs-extract-benchmark.sh}`
    [1] [2].
    
    I ran the benchmarks on a Ubuntu 14.04 VM with 2 cores and 4 GiB of RAM.
    The VM is running on a MacBook Pro with a 3.1 GHz Intel Core i7 processor,
    16 GB of RAM, and a SSD.
    
    The first compression benchmark is copying 10 copies of the unzipped
    Silesia corpus [3] into a BtrFS filesystem mounted with
    `-o compress-force=Method`. The decompression benchmark times how long
    it takes to `tar` all 10 copies into `/dev/null`. The compression ratio is
    measured by comparing the output of `df` and `du`. See the benchmark file
    [1] for details. I benchmarked multiple zstd compression levels, although
    the patch uses zstd level 1.
    
    | Method  | Ratio | Compression MB/s | Decompression speed |
    |---------|-------|------------------|---------------------|
    | None    |  0.99 |              504 |                 686 |
    | lzo     |  1.66 |              398 |                 442 |
    | zlib    |  2.58 |               65 |                 241 |
    | zstd 1  |  2.57 |              260 |                 383 |
    | zstd 3  |  2.71 |              174 |                 408 |
    | zstd 6  |  2.87 |               70 |                 398 |
    | zstd 9  |  2.92 |               43 |                 406 |
    | zstd 12 |  2.93 |               21 |                 408 |
    | zstd 15 |  3.01 |               11 |                 354 |
    
    The next benchmark first copies `linux-4.11.6.tar` [4] to btrfs. Then it
    measures the compression ratio, extracts the tar, and deletes the tar.
    Then it measures the compression ratio again, and `tar`s the extracted
    files into `/dev/null`. See the benchmark file [2] for details.
    
    | Method | Tar Ratio | Extract Ratio | Copy (s) | Extract (s)| Read (s) |
    |--------|-----------|---------------|----------|------------|----------|
    | None   |      0.97 |          0.78 |    0.981 |      5.501 |    8.807 |
    | lzo    |      2.06 |          1.38 |    1.631 |      8.458 |    8.585 |
    | zlib   |      3.40 |          1.86 |    7.750 |     21.544 |   11.744 |
    | zstd 1 |      3.57 |          1.85 |    2.579 |     11.479 |    9.389 |
    
    [1] https://github.com/facebook/zstd/blob/dev/contrib/linux-kernel/btrfs-benchmark.sh
    [2] https://github.com/facebook/zstd/blob/dev/contrib/linux-kernel/btrfs-extract-benchmark.sh
    [3] http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia
    [4] https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.11.6.tar.xz
    
    zstd source repository: https://github.com/facebook/zstd
    
    Signed-off-by: Nick Terrell <terrelln@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3f3eb7b17cac..845d77c097d6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -270,6 +270,7 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS |		\
 	 BTRFS_FEATURE_INCOMPAT_BIG_METADATA |		\
 	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO |		\
+	 BTRFS_FEATURE_INCOMPAT_COMPRESS_ZSTD |		\
 	 BTRFS_FEATURE_INCOMPAT_RAID56 |		\
 	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF |		\
 	 BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA |	\

commit 8c27cb3566762613a23c080e3db7d0501af9a787
Merge: 7114f51fcb97 848c23b78faf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 5 16:41:23 2017 -0700

    Merge branch 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "The core updates improve error handling (mostly related to bios), with
      the usual incremental work on the GFP_NOFS (mis)use removal,
      refactoring or cleanups. Except the two top patches, all have been in
      for-next for an extensive amount of time.
    
      User visible changes:
    
       - statx support
    
       - quota override tunable
    
       - improved compression thresholds
    
       - obsoleted mount option alloc_start
    
      Core updates:
    
       - bio-related updates:
           - faster bio cloning
           - no allocation failures
           - preallocated flush bios
    
       - more kvzalloc use, memalloc_nofs protections, GFP_NOFS updates
    
       - prep work for btree_inode removal
    
       - dir-item validation
    
       - qgoup fixes and updates
    
       - cleanups:
           - removed unused struct members, unused code, refactoring
           - argument refactoring (fs_info/root, caller -> callee sink)
           - SEARCH_TREE ioctl docs"
    
    * 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (115 commits)
      btrfs: Remove false alert when fiemap range is smaller than on-disk extent
      btrfs: Don't clear SGID when inheriting ACLs
      btrfs: fix integer overflow in calc_reclaim_items_nr
      btrfs: scrub: fix target device intialization while setting up scrub context
      btrfs: qgroup: Fix qgroup reserved space underflow by only freeing reserved ranges
      btrfs: qgroup: Introduce extent changeset for qgroup reserve functions
      btrfs: qgroup: Fix qgroup reserved space underflow caused by buffered write and quotas being enabled
      btrfs: qgroup: Return actually freed bytes for qgroup release or free data
      btrfs: qgroup: Cleanup btrfs_qgroup_prepare_account_extents function
      btrfs: qgroup: Add quick exit for non-fs extents
      Btrfs: rework delayed ref total_bytes_pinned accounting
      Btrfs: return old and new total ref mods when adding delayed refs
      Btrfs: always account pinned bytes when dropping a tree block ref
      Btrfs: update total_bytes_pinned when pinning down extents
      Btrfs: make BUG_ON() in add_pinned_bytes() an ASSERT()
      Btrfs: make add_pinned_bytes() take an s64 num_bytes instead of u64
      btrfs: fix validation of XATTR_ITEM dir items
      btrfs: Verify dir_item in iterate_object_props
      btrfs: Check name_len before in btrfs_del_root_ref
      btrfs: Check name_len before reading btrfs_get_name
      ...

commit bc42bda22345efdb5d8b578d1b4df2c6eaa85c58
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Feb 27 15:10:39 2017 +0800

    btrfs: qgroup: Fix qgroup reserved space underflow by only freeing reserved ranges
    
    [BUG]
    For the following case, btrfs can underflow qgroup reserved space
    at an error path:
    (Page size 4K, function name without "btrfs_" prefix)
    
             Task A                  |             Task B
    ----------------------------------------------------------------------
    Buffered_write [0, 2K)           |
    |- check_data_free_space()       |
    |  |- qgroup_reserve_data()      |
    |     Range aligned to page      |
    |     range [0, 4K)          <<< |
    |     4K bytes reserved      <<< |
    |- copy pages to page cache      |
                                     | Buffered_write [2K, 4K)
                                     | |- check_data_free_space()
                                     | |  |- qgroup_reserved_data()
                                     | |     Range alinged to page
                                     | |     range [0, 4K)
                                     | |     Already reserved by A <<<
                                     | |     0 bytes reserved      <<<
                                     | |- delalloc_reserve_metadata()
                                     | |  And it *FAILED* (Maybe EQUOTA)
                                     | |- free_reserved_data_space()
                                          |- qgroup_free_data()
                                             Range aligned to page range
                                             [0, 4K)
                                             Freeing 4K
    (Special thanks to Chandan for the detailed report and analyse)
    
    [CAUSE]
    Above Task B is freeing reserved data range [0, 4K) which is actually
    reserved by Task A.
    
    And at writeback time, page dirty by Task A will go through writeback
    routine, which will free 4K reserved data space at file extent insert
    time, causing the qgroup underflow.
    
    [FIX]
    For btrfs_qgroup_free_data(), add @reserved parameter to only free
    data ranges reserved by previous btrfs_qgroup_reserve_data().
    So in above case, Task B will try to free 0 byte, so no underflow.
    
    Reported-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Tested-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1ee4489dc398..5bdd36664421 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2711,7 +2711,10 @@ enum btrfs_flush_state {
 int btrfs_alloc_data_chunk_ondemand(struct btrfs_inode *inode, u64 bytes);
 int btrfs_check_data_free_space(struct inode *inode,
 			struct extent_changeset **reserved, u64 start, u64 len);
-void btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
+void btrfs_free_reserved_data_space(struct inode *inode,
+			struct extent_changeset *reserved, u64 start, u64 len);
+void btrfs_delalloc_release_space(struct inode *inode,
+			struct extent_changeset *reserved, u64 start, u64 len);
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
@@ -2730,7 +2733,6 @@ int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode,
 			struct extent_changeset **reserved, u64 start, u64 len);
-void btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_fs_info *fs_info,
 					      unsigned short type);

commit 364ecf3651e0862152c8b340d7cb3021dc0122c7
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Feb 27 15:10:38 2017 +0800

    btrfs: qgroup: Introduce extent changeset for qgroup reserve functions
    
    Introduce a new parameter, struct extent_changeset for
    btrfs_qgroup_reserved_data() and its callers.
    
    Such extent_changeset was used in btrfs_qgroup_reserve_data() to record
    which range it reserved in current reserve, so it can free it in error
    paths.
    
    The reason we need to export it to callers is, at buffered write error
    path, without knowing what exactly which range we reserved in current
    allocation, we can free space which is not reserved by us.
    
    This will lead to qgroup reserved space underflow.
    
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5e33e1d6d5c9..1ee4489dc398 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2708,8 +2708,9 @@ enum btrfs_flush_state {
 	COMMIT_TRANS		=	6,
 };
 
-int btrfs_check_data_free_space(struct inode *inode, u64 start, u64 len);
 int btrfs_alloc_data_chunk_ondemand(struct btrfs_inode *inode, u64 bytes);
+int btrfs_check_data_free_space(struct inode *inode,
+			struct extent_changeset **reserved, u64 start, u64 len);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);
@@ -2727,7 +2728,8 @@ void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv);
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes);
-int btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);
+int btrfs_delalloc_reserve_space(struct inode *inode,
+			struct extent_changeset **reserved, u64 start, u64 len);
 void btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_fs_info *fs_info,

commit e79a33270d05f711e985b9524a392fd45ad3e93f
Author: Su Yue <suy.fnst@cn.fujitsu.com>
Date:   Tue Jun 6 17:57:01 2017 +0800

    btrfs: Check name_len with boundary in verify dir_item
    
    Originally, verify_dir_item verifies name_len of dir_item with fixed
    values but not item boundary.
    If corrupted name_len was not bigger than the fixed value, for example
    255, the function will think the dir_item is fine. And then reading
    beyond boundary will cause crash.
    
    Example:
            1. Corrupt one dir_item name_len to be 255.
            2. Run 'ls -lar /mnt/test/ > /dev/null'
    dmesg:
    [   48.451449] BTRFS info (device vdb1): disk space caching is enabled
    [   48.451453] BTRFS info (device vdb1): has skinny extents
    [   48.489420] general protection fault: 0000 [#1] SMP
    [   48.489571] Modules linked in: ext4 jbd2 mbcache btrfs xor raid6_pq
    [   48.489716] CPU: 1 PID: 2710 Comm: ls Not tainted 4.10.0-rc1 #5
    [   48.489853] Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 1.10.2-20170228_101828-anatol 04/01/2014
    [   48.490008] task: ffff880035df1bc0 task.stack: ffffc90004800000
    [   48.490008] RIP: 0010:read_extent_buffer+0xd2/0x190 [btrfs]
    [   48.490008] RSP: 0018:ffffc90004803d98 EFLAGS: 00010202
    [   48.490008] RAX: 000000000000001b RBX: 000000000000001b RCX: 0000000000000000
    [   48.490008] RDX: ffff880079dbf36c RSI: 0005080000000000 RDI: ffff880079dbf368
    [   48.490008] RBP: ffffc90004803dc8 R08: ffff880078e8cc48 R09: ffff880000000000
    [   48.490008] R10: 0000160000000000 R11: 0000000000001000 R12: ffff880079dbf288
    [   48.490008] R13: ffff880078e8ca88 R14: 0000000000000003 R15: ffffc90004803e20
    [   48.490008] FS:  00007fef50c60800(0000) GS:ffff88007d400000(0000) knlGS:0000000000000000
    [   48.490008] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   48.490008] CR2: 000055f335ac2ff8 CR3: 000000007356d000 CR4: 00000000001406e0
    [   48.490008] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [   48.490008] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [   48.490008] Call Trace:
    [   48.490008]  btrfs_real_readdir+0x3b7/0x4a0 [btrfs]
    [   48.490008]  iterate_dir+0x181/0x1b0
    [   48.490008]  SyS_getdents+0xa7/0x150
    [   48.490008]  ? fillonedir+0x150/0x150
    [   48.490008]  entry_SYSCALL_64_fastpath+0x18/0xad
    [   48.490008] RIP: 0033:0x7fef5032546b
    [   48.490008] RSP: 002b:00007ffeafcdb830 EFLAGS: 00000206 ORIG_RAX: 000000000000004e
    [   48.490008] RAX: ffffffffffffffda RBX: 00007fef5061db38 RCX: 00007fef5032546b
    [   48.490008] RDX: 0000000000008000 RSI: 000055f335abaff0 RDI: 0000000000000003
    [   48.490008] RBP: 00007fef5061dae0 R08: 00007fef5061db48 R09: 0000000000000000
    [   48.490008] R10: 000055f335abafc0 R11: 0000000000000206 R12: 00007fef5061db38
    [   48.490008] R13: 0000000000008040 R14: 00007fef5061db38 R15: 000000000000270e
    [   48.490008] RIP: read_extent_buffer+0xd2/0x190 [btrfs] RSP: ffffc90004803d98
    [   48.499455] ---[ end trace 321920d8e8339505 ]---
    
    Fix it by adding a parameter @slot and check name_len with item boundary
    by calling btrfs_is_name_len_valid.
    
    Signed-off-by: Su Yue <suy.fnst@cn.fujitsu.com>
    rev
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d182ce792173..5e33e1d6d5c9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3036,7 +3036,7 @@ struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
 					  const char *name, u16 name_len,
 					  int mod);
 int verify_dir_item(struct btrfs_fs_info *fs_info,
-		    struct extent_buffer *leaf,
+		    struct extent_buffer *leaf, int slot,
 		    struct btrfs_dir_item *dir_item);
 struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_fs_info *fs_info,
 						 struct btrfs_path *path,

commit 19c6dcbfa74674ac5ab5d18096ee813f858668c3
Author: Su Yue <suy.fnst@cn.fujitsu.com>
Date:   Tue Jun 6 17:57:00 2017 +0800

    btrfs: Introduce btrfs_is_name_len_valid to avoid reading beyond boundary
    
    Introduce function btrfs_is_name_len_valid.
    
    The function compares parameter @name_len with item boundary then
    returns true if name_len is valid.
    
    Signed-off-by: Su Yue <suy.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ s/btrfs_leaf_data/BTRFS_LEAF_DATA_OFFSET/ ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 15a77e64dc20..d182ce792173 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3042,6 +3042,8 @@ struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_fs_info *fs_info,
 						 struct btrfs_path *path,
 						 const char *name,
 						 int name_len);
+bool btrfs_is_name_len_valid(struct extent_buffer *leaf, int slot,
+			     unsigned long start, u16 name_len);
 
 /* orphan.c */
 int btrfs_insert_orphan_item(struct btrfs_trans_handle *trans,

commit 7dfb8be11b5d1db4325414ce16b8c164e08f52d8
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Jun 16 14:39:20 2017 +0300

    btrfs: Round down values which are written for total_bytes_size
    
    We got an internal report about a file system not wanting to mount
    following 99e3ecfcb9f4 ("Btrfs: add more validation checks for
    superblock").
    
    BTRFS error (device sdb1): super_total_bytes 1000203816960 mismatch with
    fs_devices total_rw_bytes 1000203820544
    
    Subtracting the numbers we get a difference of less than a 4kb. Upon
    closer inspection it became apparent that mkfs actually rounds down the
    size of the device to a multiple of sector size. However, the same
    cannot be said for various functions which modify the total size and are
    called from btrfs_balance as well as when adding a new device. So this
    patch ensures that values being saved into on-disk data structures are
    always rounded down to a multiple of sectorsize.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b31515a2ef71..15a77e64dc20 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1556,6 +1556,7 @@ static inline void btrfs_set_device_total_bytes(struct extent_buffer *eb,
 {
 	BUILD_BUG_ON(sizeof(u64) !=
 		     sizeof(((struct btrfs_dev_item *)0))->total_bytes);
+	WARN_ON(!IS_ALIGNED(val, eb->fs_info->sectorsize));
 	btrfs_set_64(eb, s, offsetof(struct btrfs_dev_item, total_bytes), val);
 }
 

commit eca152edf57e04f61d5a79e404d8e6c147278fdf
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Jun 16 14:39:19 2017 +0300

    btrfs: Manually implement device_total_bytes getter/setter
    
    The device->total_bytes member needs to always be rounded down to sectorsize
    so that it corresponds to the value of super->total_bytes. However, there are
    multiple places where the setter is fed a value which is not rounded which
    can cause a fs to be unmountable due to the check introduced in
    99e3ecfcb9f4 ("Btrfs: add more validation checks for superblock"). This patch
    implements the getter/setter manually so that in a later patch I can add
    necessary code to catch offenders.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d868509afd5b..b31515a2ef71 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1541,8 +1541,26 @@ static inline void btrfs_set_##name(type *s, u##bits val)		\
 	s->member = cpu_to_le##bits(val);				\
 }
 
+
+static inline u64 btrfs_device_total_bytes(struct extent_buffer *eb,
+					   struct btrfs_dev_item *s)
+{
+	BUILD_BUG_ON(sizeof(u64) !=
+		     sizeof(((struct btrfs_dev_item *)0))->total_bytes);
+	return btrfs_get_64(eb, s, offsetof(struct btrfs_dev_item,
+					    total_bytes));
+}
+static inline void btrfs_set_device_total_bytes(struct extent_buffer *eb,
+						struct btrfs_dev_item *s,
+						u64 val)
+{
+	BUILD_BUG_ON(sizeof(u64) !=
+		     sizeof(((struct btrfs_dev_item *)0))->total_bytes);
+	btrfs_set_64(eb, s, offsetof(struct btrfs_dev_item, total_bytes), val);
+}
+
+
 BTRFS_SETGET_FUNCS(device_type, struct btrfs_dev_item, type, 64);
-BTRFS_SETGET_FUNCS(device_total_bytes, struct btrfs_dev_item, total_bytes, 64);
 BTRFS_SETGET_FUNCS(device_bytes_used, struct btrfs_dev_item, bytes_used, 64);
 BTRFS_SETGET_FUNCS(device_io_align, struct btrfs_dev_item, io_align, 32);
 BTRFS_SETGET_FUNCS(device_io_width, struct btrfs_dev_item, io_width, 32);

commit 0d0c71b317207082856f40dbe8a2bac813f49677
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 15 01:30:06 2017 +0200

    btrfs: obsolete and remove mount option alloc_start
    
    The mount option alloc_start was used in the past for debugging and
    stressing the chunk allocator. Not meant to be used by users, so we're
    not breaking anybody's setup.
    
    There was some added complexity handling changes of the value and when
    it was not same as default. Such code has likely been untested and I
    think it's better to remove it.
    
    This patch kills all use of alloc_start, and by doing that also fixes
    a bug when alloc_size is set, potentially called from statfs:
    
    in btrfs_calc_avail_data_space, traversing the list in RCU, the RCU
    protection is temporarily dropped so btrfs_account_dev_extents_size can
    be called and then RCU is locked again! Doing that inside
    list_for_each_entry_rcu is just asking for trouble, but unlikely to be
    observed in practice.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6375e57a5a69..d868509afd5b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -799,17 +799,7 @@ struct btrfs_fs_info {
 	 * so it is also safe.
 	 */
 	u64 max_inline;
-	/*
-	 * Protected by ->chunk_mutex and sb->s_umount.
-	 *
-	 * The reason that we use two lock to protect it is because only
-	 * remount and mount operations can change it and these two operations
-	 * are under sb->s_umount, but the read side (chunk allocation) can not
-	 * acquire sb->s_umount or the deadlock would happen. So we use two
-	 * locks to protect it. On the write side, we must acquire two locks,
-	 * and on the read side, we just need acquire one of them.
-	 */
-	u64 alloc_start;
+
 	struct btrfs_transaction *running_transaction;
 	wait_queue_head_t transaction_throttle;
 	wait_queue_head_t transaction_wait;

commit fac03c8daeb581e2bc38e5a8c0c6a42cf87cf1c3
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 15 19:10:03 2017 +0200

    btrfs: move fs_info::fs_frozen to the flags
    
    We can keep the state among the other fs_info flags, there's no reason
    why fs_frozen would need to be separate.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f0f5f28784b6..6375e57a5a69 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -716,6 +716,8 @@ struct btrfs_delayed_root;
 #define BTRFS_FS_LOG1_ERR			12
 #define BTRFS_FS_LOG2_ERR			13
 #define BTRFS_FS_QUOTA_OVERRIDE			14
+/* Used to record internally whether fs has been frozen */
+#define BTRFS_FS_FROZEN				15
 
 /*
  * Indicate that a whole-filesystem exclusive operation is running
@@ -1107,9 +1109,6 @@ struct btrfs_fs_info {
 	 */
 	struct list_head pinned_chunks;
 
-	/* Used to record internally whether fs has been frozen */
-	int fs_frozen;
-
 	/* Cached block sizes */
 	u32 nodesize;
 	u32 sectorsize;

commit 4b5faeac4688174fd523f2a22b7d70d5a96842fb
Author: David Sterba <dsterba@suse.com>
Date:   Tue Mar 28 12:06:05 2017 +0200

    btrfs: use generic slab for for btrfs_transaction
    
    Observing the number of slab objects of btrfs_transaction, there's just
    one active on an almost quiescent filesystem, and the number of objects
    goes to about ten when sync is in progress. Then the nubmer goes down to
    1.  This matches the expectations of the transaction lifetime.
    
    For such use the separate slab cache is not justified, as we do not
    reuse objects frequently. For the shortlived transaction, the generic
    slab (size 512) should be ok. We can optimistically expect that the 512
    slabs are not all used (fragmentation) and there are free slots to take
    when we do the allocation, compared to potentially allocating a whole new
    page for the separate slab.
    
    We'll lose the stats about the object use, which could be added later if
    we really need them.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 388f1128544e..f0f5f28784b6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -48,7 +48,6 @@ struct btrfs_trans_handle;
 struct btrfs_transaction;
 struct btrfs_pending_snapshot;
 extern struct kmem_cache *btrfs_trans_handle_cachep;
-extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 extern struct kmem_cache *btrfs_free_space_cachep;

commit 118c701e20ad6edfb35fd83ec6989991714b1d89
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon May 22 13:16:11 2017 +0300

    btrfs: remove __BTRFS_LEAF_DATA_SIZE
    
    __BTRFS_LAF_DATA_SIZE is used only by BTRFS_LEAF_DATA_SIZE. Make the
    latter subsume the former.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0bc9c80f62fe..388f1128544e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1278,19 +1278,16 @@ struct btrfs_root {
 	/* For qgroup metadata space reserve */
 	atomic64_t qgroup_meta_rsv;
 };
+
 static inline u32 btrfs_inode_sectorsize(const struct inode *inode)
 {
 	return btrfs_sb(inode->i_sb)->sectorsize;
 }
 
-static inline u32 __BTRFS_LEAF_DATA_SIZE(u32 blocksize)
-{
-	return blocksize - sizeof(struct btrfs_header);
-}
-
 static inline u32 BTRFS_LEAF_DATA_SIZE(const struct btrfs_fs_info *info)
 {
-	return __BTRFS_LEAF_DATA_SIZE(info->nodesize);
+
+	return info->nodesize - sizeof(struct btrfs_header);
 }
 
 #define BTRFS_LEAF_DATA_OFFSET		offsetof(struct btrfs_leaf, items)

commit 3d9ec8c49ad16a5c113e8d23ba07abb96518a586
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon May 29 09:43:43 2017 +0300

    btrfs: rename btrfs_leaf_data to BTRFS_LEAF_DATA_OFFSET
    
    Commit 5f39d397dfbe ("Btrfs: Create extent_buffer interface
    for large blocksizes") refactored btrfs_leaf_data function to take
    extent_buffer rather than struct btrfs_leaf. However, as it turns out the
    parameter being passed is never used. Furthermore this function no longer
    returns the leaf data but rather the offset to it. So rename the function
    to BTRFS_LEAF_DATA_OFFSET to make it consistent with other BTRFS_LEAF_*
    helpers and turn it into a macro.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    [ removed () from the macro ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c13b4859df73..0bc9c80f62fe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1293,6 +1293,8 @@ static inline u32 BTRFS_LEAF_DATA_SIZE(const struct btrfs_fs_info *info)
 	return __BTRFS_LEAF_DATA_SIZE(info->nodesize);
 }
 
+#define BTRFS_LEAF_DATA_OFFSET		offsetof(struct btrfs_leaf, items)
+
 static inline u32 BTRFS_MAX_ITEM_SIZE(const struct btrfs_fs_info *info)
 {
 	return BTRFS_LEAF_DATA_SIZE(info) - sizeof(struct btrfs_item);
@@ -2325,10 +2327,6 @@ static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
 	return btrfs_csum_sizes[t];
 }
 
-static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
-{
-	return offsetof(struct btrfs_leaf, items);
-}
 
 /*
  * The leaf data grows from end-to-front in the node.
@@ -2539,11 +2537,11 @@ BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cursor_right,
 
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
-	((type *)(btrfs_leaf_data(leaf) + \
+	((type *)(BTRFS_LEAF_DATA_OFFSET + \
 	btrfs_item_offset_nr(leaf, slot)))
 
 #define btrfs_item_ptr_offset(leaf, slot) \
-	((unsigned long)(btrfs_leaf_data(leaf) + \
+	((unsigned long)(BTRFS_LEAF_DATA_OFFSET + \
 	btrfs_item_offset_nr(leaf, slot)))
 
 static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)

commit 1b86826d12dc4acf9576cad9c43da74025dc8074
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed May 17 11:38:35 2017 -0400

    btrfs: cleanup root usage by btrfs_get_alloc_profile
    
    There are two places where we don't already know what kind of alloc
    profile we need before calling btrfs_get_alloc_profile, but we need
    access to a root everywhere we call it.
    
    This patch adds helpers for btrfs_{data,metadata,system}_alloc_profile()
    and relegates btrfs_system_alloc_profile to a static for use in those
    two cases.  The next patch will eliminate one of those.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c457cb177340..c13b4859df73 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2681,7 +2681,9 @@ void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
 				       struct btrfs_fs_info *fs_info);
-u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
+u64 btrfs_data_alloc_profile(struct btrfs_fs_info *fs_info);
+u64 btrfs_metadata_alloc_profile(struct btrfs_fs_info *fs_info);
+u64 btrfs_system_alloc_profile(struct btrfs_fs_info *fs_info);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
 enum btrfs_reserve_flush_enum {

commit c6100a4b4e3d1650deafda45e49571b83270c714
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri May 5 11:57:13 2017 -0400

    Btrfs: replace tree->mapping with tree->private_data
    
    For extent_io tree's we have carried the address_mapping of the inode
    around in the io tree in order to pull the inode back out for calling
    into various tree ops hooks.  This works fine when everything that has
    an extent_io_tree has an inode.  But we are going to remove the
    btree_inode, so we need to change this.  Instead just have a generic
    void * for private data that we can initialize with, and have all the
    tree ops use that instead.  This had a lot of cascading changes but
    should be relatively straightforward.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor reordering of the callback prototypes ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aea1b3cee887..c457cb177340 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3172,6 +3172,7 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);
+void btrfs_set_range_writeback(void *private_data, u64 start, u64 end);
 int btrfs_page_mkwrite(struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);

commit f29efe292198b9dbf67fb79ec9ffb5865ca29fb8
Author: Sargun Dhillon <sargun@sargun.me>
Date:   Thu May 11 21:17:33 2017 +0000

    btrfs: add quota override flag to enable quota override for CAP_SYS_RESOURCE
    
    This patch introduces the quota override flag to btrfs_fs_info, and a
    change to quota limit checking code to temporarily allow for quota to be
    overridden for processes with CAP_SYS_RESOURCE.
    
    It's useful for administrative programs, such as log rotation, that may
    need to temporarily use more disk space in order to free up a greater
    amount of overall disk space without yielding more disk space to the
    rest of userland.
    
    Eventually, we may want to add the idea of an operator-specific quota,
    operator reserved space, or something else to allow for administrative
    override, but this is perhaps the simplest solution.
    
    Signed-off-by: Sargun Dhillon <sargun@sargun.me>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor changelog edits ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0334452a7be1..aea1b3cee887 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -716,6 +716,8 @@ struct btrfs_delayed_root;
 #define BTRFS_FS_BTREE_ERR			11
 #define BTRFS_FS_LOG1_ERR			12
 #define BTRFS_FS_LOG2_ERR			13
+#define BTRFS_FS_QUOTA_OVERRIDE			14
+
 /*
  * Indicate that a whole-filesystem exclusive operation is running
  * (device replace, resize, device add/delete, balance)

commit a5ed45f8224f2c7e4ad5a9673cb50e8e3128bd88
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu May 11 09:17:46 2017 +0300

    btrfs: Convert fs_info->free_chunk_space to atomic64_t
    
    The ->free_chunk_space variable is used to track the unallocated space
    and access to it is protected by a spinlock, which is not used for
    anything else.  Make the code a bit self-explanatory by switching the
    variable to an atomic64_t type and kill the spinlock.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    [ not a performance critical code, use of atomic type is ok ]
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4f8f75d9e839..0334452a7be1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -748,8 +748,7 @@ struct btrfs_fs_info {
 	struct rb_root block_group_cache_tree;
 
 	/* keep track of unallocated space */
-	spinlock_t free_chunk_lock;
-	u64 free_chunk_space;
+	atomic64_t free_chunk_space;
 
 	struct extent_io_tree freed_extents[2];
 	struct extent_io_tree *pinned_extents;

commit 8f66439eec46d652255b9351abebb540ee5b2fd9
Merge: 22ec656bcc3f 32c1431eea48
Author: Jens Axboe <axboe@kernel.dk>
Date:   Mon Jun 12 08:30:13 2017 -0600

    Merge tag 'v4.12-rc5' into for-4.13/block
    
    We've already got a few conflicts and upcoming work depends on some of the
    changes that have gone into mainline as regression fixes for this series.
    
    Pull in 4.12-rc5 to resolve these conflicts and make it easier on down stream
    trees to continue working on 4.13 changes.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 66cea28a947739343ba3f804641de5cdf388cffa
Merge: ac1a14a239bb 70e7af244f24
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jun 10 11:06:05 2017 -0700

    Merge branch 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Some fixes that Dave Sterba collected.
    
      We've been hitting an early enospc problem on production machines that
      Omar tracked down to an old int->u64 mistake. I waited a bit on this
      pull to make sure it was really the problem from production, but it's
      on ~2100 hosts now and I think we're good.
    
      Omar also noticed a commit in the queue would make new early ENOSPC
      problems. I pulled that out for now, which is why the top three
      commits are younger than the rest.
    
      Otherwise these are all fixes, some explaining very old bugs that
      we've been poking at for a while"
    
    * 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix delalloc accounting leak caused by u32 overflow
      Btrfs: clear EXTENT_DEFRAG bits in finish_ordered_io
      btrfs: tree-log.c: Wrong printk information about namelen
      btrfs: fix race with relocation recovery and fs_root setup
      btrfs: fix memory leak in update_space_info failure path
      btrfs: use correct types for page indices in btrfs_page_exists_in_range
      btrfs: fix incorrect error return ret being passed to mapping_set_error
      btrfs: Make flush bios explicitely sync
      btrfs: fiemap: Cache and merge fiemap extent before submit it to user

commit 70e7af244f24c94604ef6eca32ad297632018583
Author: Omar Sandoval <osandov@fb.com>
Date:   Fri Jun 2 01:20:01 2017 -0700

    Btrfs: fix delalloc accounting leak caused by u32 overflow
    
    btrfs_calc_trans_metadata_size() does an unsigned 32-bit multiplication,
    which can overflow if num_items >= 4 GB / (nodesize * BTRFS_MAX_LEVEL * 2).
    For a nodesize of 16kB, this overflow happens at 16k items. Usually,
    num_items is a small constant passed to btrfs_start_transaction(), but
    we also use btrfs_calc_trans_metadata_size() for metadata reservations
    for extent items in btrfs_delalloc_{reserve,release}_metadata().
    
    In drop_outstanding_extents(), num_items is calculated as
    inode->reserved_extents - inode->outstanding_extents. The difference
    between these two counters is usually small, but if many delalloc
    extents are reserved and then the outstanding extents are merged in
    btrfs_merge_extent_hook(), the difference can become large enough to
    overflow in btrfs_calc_trans_metadata_size().
    
    The overflow manifests itself as a leak of a multiple of 4 GB in
    delalloc_block_rsv and the metadata bytes_may_use counter. This in turn
    can cause early ENOSPC errors. Additionally, these WARN_ONs in
    extent-tree.c will be hit when unmounting:
    
        WARN_ON(fs_info->delalloc_block_rsv.size > 0);
        WARN_ON(fs_info->delalloc_block_rsv.reserved > 0);
        WARN_ON(space_info->bytes_pinned > 0 ||
                space_info->bytes_reserved > 0 ||
                space_info->bytes_may_use > 0);
    
    Fix it by casting nodesize to a u64 so that
    btrfs_calc_trans_metadata_size() does a full 64-bit multiplication.
    While we're here, do the same in btrfs_calc_trunc_metadata_size(); this
    can't overflow with any existing uses, but it's better to be safe here
    than have another hard-to-debug problem later on.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e82516fe2d8..43a8c42cdf07 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2564,7 +2564,7 @@ u64 btrfs_csum_bytes_to_leaves(struct btrfs_fs_info *fs_info, u64 csum_bytes);
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
-	return fs_info->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
+	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
 }
 
 /*
@@ -2574,7 +2574,7 @@ static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,
 static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
-	return fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
+	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,

commit 4e4cbee93d56137ebff722be022cae5f70ef84fb
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:06 2017 +0200

    block: switch bios to blk_status_t
    
    Replace bi_error with a new bi_status to allow for a clear conversion.
    Note that device mapper overloaded bi_error with a private value, which
    we'll have to keep arround at least for now and thus propagate to a
    proper blk_status_t value.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 643c70d2b2e6..d2da0a52d560 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3078,8 +3078,8 @@ int btrfs_find_name_in_ext_backref(struct btrfs_path *path,
 struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_fs_info *fs_info, u64 bytenr, u64 len);
-int btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst);
-int btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio,
+blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst);
+blk_status_t btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio,
 			      u64 logical_offset);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
@@ -3094,7 +3094,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums);
-int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
+blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 		       u64 file_start, int contig);
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit);

commit 1176032cb12bb89ad558a3e57e82f2f25b817eff
Merge: 56868a460b83 9bcaaea7418d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 10 08:33:17 2017 -0700

    Merge branch 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has fixes and cleanups Dave Sterba collected for the merge
      window.
    
      The biggest functional fixes are between btrfs raid5/6 and scrub, and
      raid5/6 and device replacement. Some of our pending qgroup fixes are
      included as well while I bash on the rest in testing.
    
      We also have the usual set of cleanups, including one that makes
      __btrfs_map_block() much more maintainable, and conversions from
      atomic_t to refcount_t"
    
    * 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (71 commits)
      btrfs: fix the gfp_mask for the reada_zones radix tree
      Btrfs: fix reported number of inode blocks
      Btrfs: send, fix file hole not being preserved due to inline extent
      Btrfs: fix extent map leak during fallocate error path
      Btrfs: fix incorrect space accounting after failure to insert inline extent
      Btrfs: fix invalid attempt to free reserved space on failure to cow range
      btrfs: Handle delalloc error correctly to avoid ordered extent hang
      btrfs: Fix metadata underflow caused by btrfs_reloc_clone_csum error
      btrfs: check if the device is flush capable
      btrfs: delete unused member nobarriers
      btrfs: scrub: Fix RAID56 recovery race condition
      btrfs: scrub: Introduce full stripe lock for RAID56
      btrfs: Use ktime_get_real_ts for root ctime
      Btrfs: handle only applicable errors returned by btrfs_get_extent
      btrfs: qgroup: Fix qgroup corruption caused by inode_cache mount option
      btrfs: use q which is already obtained from bdev_get_queue
      Btrfs: switch to div64_u64 if with a u64 divisor
      Btrfs: update scrub_parity to use u64 stripe_len
      Btrfs: enable repair during read for raid56 profile
      btrfs: use clear_page where appropriate
      ...

commit 694752922b12bd318aa80191bd9d8c3dcfb39055
Merge: a351e9b9fc24 9438b3e080be
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 10:39:57 2017 -0700

    Merge branch 'for-4.12/block' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
    
     - Add BFQ IO scheduler under the new blk-mq scheduling framework. BFQ
       was initially a fork of CFQ, but subsequently changed to implement
       fairness based on B-WF2Q+, a modified variant of WF2Q. BFQ is meant
       to be used on desktop type single drives, providing good fairness.
       From Paolo.
    
     - Add Kyber IO scheduler. This is a full multiqueue aware scheduler,
       using a scalable token based algorithm that throttles IO based on
       live completion IO stats, similary to blk-wbt. From Omar.
    
     - A series from Jan, moving users to separately allocated backing
       devices. This continues the work of separating backing device life
       times, solving various problems with hot removal.
    
     - A series of updates for lightnvm, mostly from Javier. Includes a
       'pblk' target that exposes an open channel SSD as a physical block
       device.
    
     - A series of fixes and improvements for nbd from Josef.
    
     - A series from Omar, removing queue sharing between devices on mostly
       legacy drivers. This helps us clean up other bits, if we know that a
       queue only has a single device backing. This has been overdue for
       more than a decade.
    
     - Fixes for the blk-stats, and improvements to unify the stats and user
       windows. This both improves blk-wbt, and enables other users to
       register a need to receive IO stats for a device. From Omar.
    
     - blk-throttle improvements from Shaohua. This provides a scalable
       framework for implementing scalable priotization - particularly for
       blk-mq, but applicable to any type of block device. The interface is
       marked experimental for now.
    
     - Bucketized IO stats for IO polling from Stephen Bates. This improves
       efficiency of polled workloads in the presence of mixed block size
       IO.
    
     - A few fixes for opal, from Scott.
    
     - A few pulls for NVMe, including a lot of fixes for NVMe-over-fabrics.
       From a variety of folks, mostly Sagi and James Smart.
    
     - A series from Bart, improving our exposed info and capabilities from
       the blk-mq debugfs support.
    
     - A series from Christoph, cleaning up how handle WRITE_ZEROES.
    
     - A series from Christoph, cleaning up the block layer handling of how
       we track errors in a request. On top of being a nice cleanup, it also
       shrinks the size of struct request a bit.
    
     - Removal of mg_disk and hd (sorry Linus) by Christoph. The former was
       never used by platforms, and the latter has outlived it's usefulness.
    
     - Various little bug fixes and cleanups from a wide variety of folks.
    
    * 'for-4.12/block' of git://git.kernel.dk/linux-block: (329 commits)
      block: hide badblocks attribute by default
      blk-mq: unify hctx delay_work and run_work
      block: add kblock_mod_delayed_work_on()
      blk-mq: unify hctx delayed_run_work and run_work
      nbd: fix use after free on module unload
      MAINTAINERS: bfq: Add Paolo as maintainer for the BFQ I/O scheduler
      blk-mq-sched: alloate reserved tags out of normal pool
      mtip32xx: use runtime tag to initialize command header
      scsi: Implement blk_mq_ops.show_rq()
      blk-mq: Add blk_mq_ops.show_rq()
      blk-mq: Show operation, cmd_flags and rq_flags names
      blk-mq: Make blk_flags_show() callers append a newline character
      blk-mq: Move the "state" debugfs attribute one level down
      blk-mq: Unregister debugfs attributes earlier
      blk-mq: Only unregister hctxs for which registration succeeded
      blk-mq-debugfs: Rename functions for registering and unregistering the mq directory
      blk-mq: Let blk_mq_debugfs_register() look up the queue name
      blk-mq: Register <dev>/queue/mq after having registered <dev>/queue
      ide-pm: always pass 0 error to ide_complete_rq in ide_do_devset
      ide-pm: always pass 0 error to __blk_end_request_all
      ..

commit 9e11ceee23f25b6bb03de97ad1b729784f09538c
Author: Jan Kara <jack@suse.cz>
Date:   Wed Apr 12 12:24:32 2017 +0200

    btrfs: Convert to separately allocated bdi
    
    Allocate struct backing_dev_info separately instead of embedding it
    inside superblock. This unifies handling of bdi among users.
    
    CC: Chris Mason <clm@fb.com>
    CC: Josef Bacik <jbacik@fb.com>
    CC: David Sterba <dsterba@suse.com>
    CC: linux-btrfs@vger.kernel.org
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 29b7fc28c607..f6019ce20035 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -810,7 +810,6 @@ struct btrfs_fs_info {
 	struct btrfs_super_block *super_for_commit;
 	struct super_block *sb;
 	struct inode *btree_inode;
-	struct backing_dev_info bdi;
 	struct mutex tree_log_mutex;
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;

commit 0966a7b1300f953b04b436aa82486d3d1b17c96d
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Apr 14 08:35:54 2017 +0800

    btrfs: scrub: Introduce full stripe lock for RAID56
    
    Unlike mirror based profiles, RAID5/6 recovery needs to read out the
    whole full stripe.
    
    And if we don't do proper protection, it can easily cause race condition.
    
    Introduce 2 new functions: lock_full_stripe() and unlock_full_stripe()
    for RAID5/6.
    Which store a rb_tree of mutexes for full stripes, so scrub callers can
    use them to lock a full stripe to avoid race.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor comment adjustments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 70631d773669..1e82516fe2d8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -539,6 +539,14 @@ struct btrfs_io_ctl {
 	unsigned check_crcs:1;
 };
 
+/*
+ * Tree to record all locked full stripes of a RAID5/6 block group
+ */
+struct btrfs_full_stripe_locks_tree {
+	struct rb_root root;
+	struct mutex lock;
+};
+
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
@@ -649,6 +657,9 @@ struct btrfs_block_group_cache {
 	 * Protected by free_space_lock.
 	 */
 	int needs_free_space;
+
+	/* Record locked full stripes for RAID5/6 block group */
+	struct btrfs_full_stripe_locks_tree full_stripe_locks_root;
 };
 
 /* delayed seq elem */
@@ -3653,6 +3664,12 @@ int btrfs_scrub_cancel_dev(struct btrfs_fs_info *info,
 			   struct btrfs_device *dev);
 int btrfs_scrub_progress(struct btrfs_fs_info *fs_info, u64 devid,
 			 struct btrfs_scrub_progress *progress);
+static inline void btrfs_init_full_stripe_locks_tree(
+			struct btrfs_full_stripe_locks_tree *locks_root)
+{
+	locks_root->root = RB_ROOT;
+	mutex_init(&locks_root->lock);
+}
 
 /* dev-replace.c */
 void btrfs_bio_counter_inc_blocked(struct btrfs_fs_info *fs_info);

commit 171938e528079deced3226a17dcab12121312a64
Author: David Sterba <dsterba@suse.com>
Date:   Tue Mar 28 14:44:21 2017 +0200

    btrfs: track exclusive filesystem operation in flags
    
    There are several operations, usually started from ioctls, that cannot
    run concurrently. The status is tracked in
    mutually_exclusive_operation_running as an atomic_t. We can easily track
    the status as one of the per-filesystem flag bits with same
    synchronization guarantees.
    
    The conversion replaces:
    
    * atomic_xchg(..., 1)    ->   test_and_set_bit(FLAG, ...)
    * atomic_set(..., 0)     ->   clear_bit(FLAG, ...)
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e9d77115e695..70631d773669 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -705,6 +705,11 @@ struct btrfs_delayed_root;
 #define BTRFS_FS_BTREE_ERR			11
 #define BTRFS_FS_LOG1_ERR			12
 #define BTRFS_FS_LOG2_ERR			13
+/*
+ * Indicate that a whole-filesystem exclusive operation is running
+ * (device replace, resize, device add/delete, balance)
+ */
+#define BTRFS_FS_EXCL_OP			14
 
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
@@ -1070,8 +1075,6 @@ struct btrfs_fs_info {
 	/* device replace state */
 	struct btrfs_dev_replace dev_replace;
 
-	atomic_t mutually_exclusive_operation_running;
-
 	struct percpu_counter bio_counter;
 	wait_queue_head_t replace_wait;
 

commit de47c9d3ff875a3cb1251af35ee8d30afaca78bd
Author: Edmund Nadolski <enadolski@suse.com>
Date:   Thu Mar 16 10:04:34 2017 -0600

    btrfs: replace hardcoded value with SEQ_LAST macro
    
    Define the SEQ_LAST macro to replace (u64)-1 in places where said
    value triggers a special-case ref search behavior.
    
    Signed-off-by: Edmund Nadolski <enadolski@suse.com>
    Reviewed-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7343bf7f2b35..e9d77115e695 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -659,6 +659,8 @@ struct seq_list {
 
 #define SEQ_LIST_INIT(name)	{ .list = LIST_HEAD_INIT((name).list), .seq = 0 }
 
+#define SEQ_LAST	((u64)-1)
+
 enum btrfs_orphan_cleanup_state {
 	ORPHAN_CLEANUP_STARTED	= 1,
 	ORPHAN_CLEANUP_DONE	= 2,

commit d48d71aa9977473b6515bb48933617a06cdc7be9
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 19:43:30 2017 +0100

    btrfs: remove redundant parameter from btree_readahead_hook
    
    We can read fs_info from eb.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 285566cc2f7d..7343bf7f2b35 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3672,8 +3672,7 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 			      struct btrfs_key *start, struct btrfs_key *end);
 int btrfs_reada_wait(void *handle);
 void btrfs_reada_detach(void *handle);
-int btree_readahead_hook(struct btrfs_fs_info *fs_info,
-			 struct extent_buffer *eb, int err);
+int btree_readahead_hook(struct extent_buffer *eb, int err);
 
 static inline int is_fstree(u64 rootid)
 {

commit 0700cea7c8b387c8c6bc4de79b197baa0b3fc4a3
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:18 2017 +0200

    btrfs: convert btrfs_root.refs from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cdfc2a46448b..285566cc2f7d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1222,7 +1222,7 @@ struct btrfs_root {
 	dev_t anon_dev;
 
 	spinlock_t root_item_lock;
-	atomic_t refs;
+	refcount_t refs;
 
 	struct mutex delalloc_mutex;
 	spinlock_t delalloc_lock;

commit 1e4f4714d59e3fdcde29ee12d40d2e96875a026f
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:14 2017 +0200

    btrfs: convert btrfs_caching_control.count from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c4115901d906..cdfc2a46448b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,6 +39,7 @@
 #include <linux/security.h>
 #include <linux/sizes.h>
 #include <linux/dynamic_debug.h>
+#include <linux/refcount.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
@@ -518,7 +519,7 @@ struct btrfs_caching_control {
 	struct btrfs_work work;
 	struct btrfs_block_group_cache *block_group;
 	u64 progress;
-	atomic_t count;
+	refcount_t count;
 };
 
 /* Once caching_thread() finds this much free space, it will wake up waiters. */

commit fe8e12b5032536d37751c47e1c0446f17e974e5c
Merge: f9799ad21b5e 41a75a6eb2bf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 31 17:58:48 2017 -0700

    Merge branch 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "We have three small fixes queued up in my for-linus-4.11 branch"
    
    * 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix an integer overflow check
      btrfs: Change qgroup_meta_rsv to 64bit
      Btrfs: bring back repair during read

commit ce0dcee626c482183b42d45b6ea43198c7223fc7
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Tue Mar 14 05:25:09 2017 -0500

    btrfs: Change qgroup_meta_rsv to 64bit
    
    Using an int value is causing qg->reserved to become negative and
    exclusive -EDQUOT to be reached prematurely.
    
    This affects exclusive qgroups only.
    
    TEST CASE:
    
    DEVICE=/dev/vdb
    MOUNTPOINT=/mnt
    SUBVOL=$MOUNTPOINT/tmp
    
    umount $SUBVOL
    umount $MOUNTPOINT
    
    mkfs.btrfs -f $DEVICE
    mount /dev/vdb $MOUNTPOINT
    btrfs quota enable $MOUNTPOINT
    btrfs subvol create $SUBVOL
    umount $MOUNTPOINT
    mount /dev/vdb $MOUNTPOINT
    mount -o subvol=tmp $DEVICE $SUBVOL
    btrfs qgroup limit -e 3G $SUBVOL
    
    btrfs quota rescan /mnt -w
    
    for i in `seq 1 44000`; do
      dd if=/dev/zero of=/mnt/tmp/test_$i bs=10k count=1
      if [[ $? > 0 ]]; then
         btrfs qgroup show -pcref $SUBVOL
         exit 1
      fi
    done
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    [ add reproducer to changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f03c2f285eb1..660d485b6e8b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1258,7 +1258,7 @@ struct btrfs_root {
 	atomic_t will_be_snapshoted;
 
 	/* For qgroup metadata space reserve */
-	atomic_t qgroup_meta_rsv;
+	atomic64_t qgroup_meta_rsv;
 };
 static inline u32 btrfs_inode_sectorsize(const struct inode *inode)
 {

commit 1827adb11ad26b2290dc9fe2aaf54976b2439865
Merge: 78769912f680 5eca1c10cbaa
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 3 10:16:38 2017 -0800

    Merge branch 'WIP.sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull sched.h split-up from Ingo Molnar:
     "The point of these changes is to significantly reduce the
      <linux/sched.h> header footprint, to speed up the kernel build and to
      have a cleaner header structure.
    
      After these changes the new <linux/sched.h>'s typical preprocessed
      size goes down from a previous ~0.68 MB (~22K lines) to ~0.45 MB (~15K
      lines), which is around 40% faster to build on typical configs.
    
      Not much changed from the last version (-v2) posted three weeks ago: I
      eliminated quirks, backmerged fixes plus I rebased it to an upstream
      SHA1 from yesterday that includes most changes queued up in -next plus
      all sched.h changes that were pending from Andrew.
    
      I've re-tested the series both on x86 and on cross-arch defconfigs,
      and did a bisectability test at a number of random points.
    
      I tried to test as many build configurations as possible, but some
      build breakage is probably still left - but it should be mostly
      limited to architectures that have no cross-compiler binaries
      available on kernel.org, and non-default configurations"
    
    * 'WIP.sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (146 commits)
      sched/headers: Clean up <linux/sched.h>
      sched/headers: Remove #ifdefs from <linux/sched.h>
      sched/headers: Remove the <linux/topology.h> include from <linux/sched.h>
      sched/headers, hrtimer: Remove the <linux/wait.h> include from <linux/hrtimer.h>
      sched/headers, x86/apic: Remove the <linux/pm.h> header inclusion from <asm/apic.h>
      sched/headers, timers: Remove the <linux/sysctl.h> include from <linux/timer.h>
      sched/headers: Remove <linux/magic.h> from <linux/sched/task_stack.h>
      sched/headers: Remove <linux/sched.h> from <linux/sched/init.h>
      sched/core: Remove unused prefetch_stack()
      sched/headers: Remove <linux/rculist.h> from <linux/sched.h>
      sched/headers: Remove the 'init_pid_ns' prototype from <linux/sched.h>
      sched/headers: Remove <linux/signal.h> from <linux/sched.h>
      sched/headers: Remove <linux/rwsem.h> from <linux/sched.h>
      sched/headers: Remove the runqueue_is_locked() prototype
      sched/headers: Remove <linux/sched.h> from <linux/sched/hotplug.h>
      sched/headers: Remove <linux/sched.h> from <linux/sched/debug.h>
      sched/headers: Remove <linux/sched.h> from <linux/sched/nohz.h>
      sched/headers: Remove <linux/sched.h> from <linux/sched/stat.h>
      sched/headers: Remove the <linux/gfp.h> include from <linux/sched.h>
      sched/headers: Remove <linux/rtmutex.h> from <linux/sched.h>
      ...

commit bbe08c0a43e2c5ee3a00de68c0e867a08a9aa990
Merge: 94e877d0fb43 e9f467d028cd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 2 16:03:00 2017 -0800

    Merge branch 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull more btrfs updates from Chris Mason:
     "Btrfs round two.
    
      These are mostly a continuation of Dave Sterba's collection of
      cleanups, but Filipe also has some bug fixes and performance
      improvements"
    
    * 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (69 commits)
      btrfs: add dummy callback for readpage_io_failed and drop checks
      btrfs: drop checks for mandatory extent_io_ops callbacks
      btrfs: document existence of extent_io ops callbacks
      btrfs: let writepage_end_io_hook return void
      btrfs: do proper error handling in btrfs_insert_xattr_item
      btrfs: handle allocation error in update_dev_stat_item
      btrfs: remove BUG_ON from __tree_mod_log_insert
      btrfs: derive maximum output size in the compression implementation
      btrfs: use predefined limits for calculating maximum number of pages for compression
      btrfs: export compression buffer limits in a header
      btrfs: merge nr_pages input and output parameter in compress_pages
      btrfs: merge length input and output parameter in compress_pages
      btrfs: constify name of subvolume in creation helpers
      btrfs: constify buffers used by compression helpers
      btrfs: constify input buffer of btrfs_csum_data
      btrfs: constify device path passed to relevant helpers
      btrfs: make btrfs_inode_resume_unlocked_dio take btrfs_inode
      btrfs: make btrfs_inode_block_unlocked_dio take btrfs_inode
      btrfs: Make btrfs_add_nondir take btrfs_inode
      btrfs: Make btrfs_add_link take btrfs_inode
      ...

commit 174cd4b1e5fbd0d74c68cf3a74f5bd4923485512
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 2 19:15:33 2017 +0100

    sched/headers: Prepare to move signal wakeup & sigpending methods from <linux/sched.h> into <linux/sched/signal.h>
    
    Fix up affected files that include this signal functionality via sched.h.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 105d4d43993e..a8812d95359d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -20,6 +20,7 @@
 #define __BTRFS_CTREE__
 
 #include <linux/mm.h>
+#include <linux/sched/signal.h>
 #include <linux/highmem.h>
 #include <linux/fs.h>
 #include <linux/rwsem.h>

commit db0a669fb002416faafe34481d6a6e21cdf0e926
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:51:08 2017 +0200

    btrfs: Make btrfs_add_link take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 809736ec549b..f03c2f285eb1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3129,7 +3129,7 @@ int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
 		       struct btrfs_inode *dir, struct btrfs_inode *inode,
 		       const char *name, int name_len);
 int btrfs_add_link(struct btrfs_trans_handle *trans,
-		   struct inode *parent_inode, struct inode *inode,
+		   struct btrfs_inode *parent_inode, struct btrfs_inode *inode,
 		   const char *name, int name_len, int add_backref, u64 index);
 int btrfs_unlink_subvol(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,

commit fc4f21b1d8d023cf0a2b1b050ae18e15dbe7068e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:51:06 2017 +0200

    btrfs: Make get_extent_t take btrfs_inode
    
    In addition to changing the signature, this patch also switches
    all the functions which are used as an argument to also take btrfs_inode.
    Namely those are: btrfs_get_extent and btrfs_get_extent_filemap.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e0845eafcbc..809736ec549b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3100,9 +3100,9 @@ struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,
 						    int delay_iput);
 void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
 
-struct extent_map *btrfs_get_extent_fiemap(struct inode *inode, struct page *page,
-					   size_t pg_offset, u64 start, u64 len,
-					   int create);
+struct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,
+		struct page *page, size_t pg_offset, u64 start,
+		u64 len, int create);
 noinline int can_nocow_extent(struct inode *inode, u64 offset, u64 *len,
 			      u64 *orig_start, u64 *orig_block_len,
 			      u64 *ram_bytes);
@@ -3166,9 +3166,9 @@ void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root, int *was_new);
-struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
-				    size_t pg_offset, u64 start, u64 end,
-				    int create);
+struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,
+		struct page *page, size_t pg_offset,
+		u64 start, u64 end, int create);
 int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode);

commit 9cdc51241090a36d3b7b4ff374fb18b764b3b3a4
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:51:02 2017 +0200

    btrfs: Make btrfs_extent_item_to_extent_map take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index af68f8452f19..2e0845eafcbc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3081,7 +3081,7 @@ int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 		       u64 file_start, int contig);
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit);
-void btrfs_extent_item_to_extent_map(struct inode *inode,
+void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 				     const struct btrfs_path *path,
 				     struct btrfs_file_extent_item *fi,
 				     const bool new_inline,

commit 73f2e545b68f6af033fd2c083ca9dc3079e79083
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:59 2017 +0200

    btrfs: Make btrfs_orphan_add take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2bfc2e289f51..af68f8452f19 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3174,7 +3174,8 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct inode *inode);
 int btrfs_update_inode_fallback(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root, struct inode *inode);
-int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
+int btrfs_orphan_add(struct btrfs_trans_handle *trans,
+		struct btrfs_inode *inode);
 int btrfs_orphan_cleanup(struct btrfs_root *root);
 void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root);

commit 7a6d7067958c32d1c76e0bfd1a0d46be06340b2e
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Mon Feb 20 13:50:48 2017 +0200

    btrfs: Make btrfs_mark_extent_written take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4db18e5dc8f9..2bfc2e289f51 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3233,7 +3233,7 @@ int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode, u64 start,
 		       u64 end, int drop_cache);
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
-			      struct inode *inode, u64 start, u64 end);
+			      struct btrfs_inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);
 int btrfs_dirty_pages(struct inode *inode, struct page **pages,
 		      size_t num_pages, loff_t pos, size_t write_bytes,

commit dcdbc059f01e242f92e3239654a1a57d15b0da5a
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Mon Feb 20 13:50:45 2017 +0200

    btrfs: Make btrfs_drop_extent_cache take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5246cbe4c17f..4db18e5dc8f9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3219,7 +3219,7 @@ int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
 void btrfs_cleanup_defrag_inodes(struct btrfs_fs_info *fs_info);
 int btrfs_sync_file(struct file *file, loff_t start, loff_t end, int datasync);
-void btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
+void btrfs_drop_extent_cache(struct btrfs_inode *inode, u64 start, u64 end,
 			     int skip_pinned);
 extern const struct file_operations btrfs_file_operations;
 int __btrfs_drop_extents(struct btrfs_trans_handle *trans,

commit 6158e1ce1cc620df650ebdcfb3cc08a3d86f5a4c
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Mon Feb 20 13:50:43 2017 +0200

    btrfs: Make (__)btrfs_add_inode_defrag take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7f7f3b60a73d..5246cbe4c17f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3215,7 +3215,7 @@ ssize_t btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
 int btrfs_auto_defrag_init(void);
 void btrfs_auto_defrag_exit(void);
 int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
-			   struct inode *inode);
+			   struct btrfs_inode *inode);
 int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
 void btrfs_cleanup_defrag_inodes(struct btrfs_fs_info *fs_info);
 int btrfs_sync_file(struct file *file, loff_t start, loff_t end, int datasync);

commit 691fa059673b3b33c25d7925acb0a58e8204dbd6
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:42 2017 +0200

    btrfs: all btrfs_delalloc_release_metadata take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 23dcc42f479b..7f7f3b60a73d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2704,7 +2704,7 @@ int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv);
 int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
-void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
+void btrfs_delalloc_release_metadata(struct btrfs_inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);
 void btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);

commit 9f3db423f98c5c6c53b47f4bb2729901500bc330
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Mon Feb 20 13:50:41 2017 +0200

    btrfs: Make btrfs_delalloc_reserve_metadata take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8eb07a9dfa6a..23dcc42f479b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2703,7 +2703,7 @@ int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     u64 *qgroup_reserved, bool use_global_rsv);
 void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv);
-int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
+int btrfs_delalloc_reserve_metadata(struct btrfs_inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);
 void btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);

commit 703b391a0362e0ee35260dd16d7d0c7a12fef0e6
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Mon Feb 20 13:50:40 2017 +0200

    btrfs: Make btrfs_orphan_release_metadata take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 52af63e1d9a0..8eb07a9dfa6a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2696,7 +2696,7 @@ void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
 				  struct btrfs_inode *inode);
-void btrfs_orphan_release_metadata(struct inode *inode);
+void btrfs_orphan_release_metadata(struct btrfs_inode *inode);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
 				     int nitems,

commit 8ed7a2a0e0732b62d925041ff04a5e9621e0e58b
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Mon Feb 20 13:50:39 2017 +0200

    btrfs: Make btrfs_orphan_reserve_metadata take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 76e661d00822..52af63e1d9a0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2695,7 +2695,7 @@ void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				  struct btrfs_fs_info *fs_info);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
-				  struct inode *inode);
+				  struct btrfs_inode *inode);
 void btrfs_orphan_release_metadata(struct inode *inode);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,

commit 04f4f916531adc7d2ca6fdb16a68b6f2ff2a8a3b
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:36 2017 +0200

    btrfs: make btrfs_alloc_data_chunk_ondemand take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8ab0ce65a218..76e661d00822 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2687,7 +2687,7 @@ enum btrfs_flush_state {
 };
 
 int btrfs_check_data_free_space(struct inode *inode, u64 start, u64 len);
-int btrfs_alloc_data_chunk_ondemand(struct inode *inode, u64 bytes);
+int btrfs_alloc_data_chunk_ondemand(struct btrfs_inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);

commit 70ddc553b5522b96e65a162be1cecba532630841
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:35 2017 +0200

    btrfs: make btrfs_is_free_space_inode take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 97f84a80b479..8ab0ce65a218 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3123,7 +3123,7 @@ static inline void btrfs_force_ra(struct address_space *mapping,
 }
 
 struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry);
-int btrfs_set_inode_index(struct inode *dir, u64 *index);
+int btrfs_set_inode_index(struct btrfs_inode *dir, u64 *index);
 int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root,
 		       struct btrfs_inode *dir, struct btrfs_inode *inode,

commit 8e7611cf38765f1bf1324ed1190f1f8e76ab9546
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:31 2017 +0200

    btrfs: Make btrfs_insert_dir_item take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ad23a73ac7e7..97f84a80b479 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2982,7 +2982,7 @@ int btrfs_check_dir_item_collision(struct btrfs_root *root, u64 dir,
 			  const char *name, int name_len);
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, const char *name,
-			  int name_len, struct inode *dir,
+			  int name_len, struct btrfs_inode *dir,
 			  struct btrfs_key *location, u8 type, u64 index);
 struct btrfs_dir_item *btrfs_lookup_dir_item(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,

commit 9003ed1fed2a3fe2774a6b67dcbe1ab31d7f8ec3
Merge: 94eae8034002 6288d6eabc75
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 25 14:53:58 2017 -0800

    Merge branch 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has a series of fixes and cleanups that Dave Sterba has been
      collecting.
    
      There is a pretty big variety here, cleaning up internal APIs and
      fixing corner cases"
    
    * 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (124 commits)
      Btrfs: use the correct type when creating cow dio extent
      Btrfs: fix deadlock between dedup on same file and starting writeback
      btrfs: use btrfs_debug instead of pr_debug in transaction abort
      btrfs: btrfs_truncate_free_space_cache always allocates path
      btrfs: free-space-cache, clean up unnecessary root arguments
      btrfs: convert btrfs_inc_block_group_ro to accept fs_info
      btrfs: flush_space always takes fs_info->fs_root
      btrfs: pass fs_info to (more) routines that are only called with extent_root
      btrfs: qgroup: Move half of the qgroup accounting time out of commit trans
      btrfs: remove unused parameter from adjust_slots_upwards
      btrfs: remove unused parameters from __btrfs_write_out_cache
      btrfs: remove unused parameter from cleanup_write_cache_enospc
      btrfs: remove unused parameter from __add_inode_ref
      btrfs: remove unused parameter from clone_copy_inline_extent
      btrfs: remove unused parameters from btrfs_cmp_data
      btrfs: remove unused parameter from __add_inline_refs
      btrfs: remove unused parameters from scrub_setup_wr_ctx
      btrfs: remove unused parameter from create_snapshot
      btrfs: remove unused parameter from init_first_rw_device
      btrfs: remove unused parameter from __btrfs_alloc_chunk
      ...

commit 11bac80004499ea59f361ef2a5516c84b6eab675
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Fri Feb 24 14:56:41 2017 -0800

    mm, fs: reduce fault, page_mkwrite, and pfn_mkwrite to take only vmf
    
    ->fault(), ->page_mkwrite(), and ->pfn_mkwrite() calls do not need to
    take a vma and vmf parameter when the vma already resides in vmf.
    
    Remove the vma parameter to simplify things.
    
    [arnd@arndb.de: fix ARM build]
      Link: http://lkml.kernel.org/r/20170125223558.1451224-1-arnd@arndb.de
    Link: http://lkml.kernel.org/r/148521301778.19116.10840599906674778980.stgit@djiang5-desk3.ch.intel.com
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jan Kara <jack@suse.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6a823719b6c5..adf16307842a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3147,7 +3147,7 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);
-int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
+int btrfs_page_mkwrite(struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);

commit 71367b3fa7f56256029e7ed87862ef13386e1e7e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Feb 15 16:28:34 2017 -0500

    btrfs: use btrfs_debug instead of pr_debug in transaction abort
    
    Commit e5d6b12fe14 (Btrfs: don't WARN() in btrfs_transaction_abort() for
    IO errors) added a pr_debug call to be printed when a transaction is
    aborted with -EIO instead of WARN.  btrfs_debug prints which file system
    the message is associated with so let's use that instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7455a3e032cf..ad23a73ac7e7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3454,7 +3454,8 @@ do {								\
 			"BTRFS: Transaction aborted (error %d)\n",	\
 			(errno));					\
 		} else {						\
-			pr_debug("BTRFS: Transaction aborted (error %d)\n", \
+			btrfs_debug((trans)->fs_info,			\
+				    "Transaction aborted (error %d)", \
 				  (errno));			\
 		}						\
 	}							\

commit 5e00f1939f6e994123589c6e3d307de02b43c914
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Feb 15 16:28:29 2017 -0500

    btrfs: convert btrfs_inc_block_group_ro to accept fs_info
    
    btrfs_inc_block_group_ro is either passed the extent root or the dev
    root, but it doesn't do anything with the dev tree.  Let's convert
    to passing an fs_info and using the extent root.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e7dbda3dd3b8..7455a3e032cf 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2729,7 +2729,7 @@ int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 void btrfs_block_rsv_release(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);
-int btrfs_inc_block_group_ro(struct btrfs_root *root,
+int btrfs_inc_block_group_ro(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_group_cache *cache);
 void btrfs_dec_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);

commit 8b74c03e3c16c7a5a127a584bee687cd1578ceaa
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 10 19:20:56 2017 +0100

    btrfs: remove unused parameter from btrfs_prepare_extent_commit
    
    Added but never used.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0f5b85772023..e7dbda3dd3b8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2630,8 +2630,7 @@ int btrfs_free_reserved_extent(struct btrfs_fs_info *fs_info,
 			       u64 start, u64 len, int delalloc);
 int btrfs_free_and_pin_reserved_extent(struct btrfs_fs_info *fs_info,
 				       u64 start, u64 len);
-void btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
-				 struct btrfs_fs_info *fs_info);
+void btrfs_prepare_extent_commit(struct btrfs_fs_info *fs_info);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_fs_info *fs_info);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,

commit 7775c8184ec018deae89ccbc3ed1e319c910ca59
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 10 19:18:18 2017 +0100

    btrfs: remove unused parameter from btrfs_subvolume_release_metadata
    
    Unused since qgroup refactoring that split data and metadata accounting,
    the btrfs_qgroup_free helper.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1692ebb05955..0f5b85772023 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2703,8 +2703,7 @@ int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     int nitems,
 				     u64 *qgroup_reserved, bool use_global_rsv);
 void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
-				      struct btrfs_block_rsv *rsv,
-				      u64 qgroup_reserved);
+				      struct btrfs_block_rsv *rsv);
 int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);

commit e4c3b2dcd1449def1229efb138da7cb28c796c71
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Jan 30 12:25:28 2017 -0800

    Btrfs: kill trans in run_delalloc_nocow and btrfs_cross_ref_exist
    
    run_delalloc_nocow has used trans in two places where they don't
    actually need @trans.
    
    For btrfs_lookup_file_extent, we search for file extents without COWing
    anything, and for btrfs_cross_ref_exist, the only place where we need
    @trans is deferencing it in order to get running_transaction which we
    could easily get from the global fs_info.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 56b8595eacbb..1692ebb05955 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2584,8 +2584,7 @@ int btrfs_pin_extent_for_log_replay(struct btrfs_fs_info *fs_info,
 				    u64 bytenr, u64 num_bytes);
 int btrfs_exclude_logged_extents(struct btrfs_fs_info *fs_info,
 				 struct extent_buffer *eb);
-int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root,
+int btrfs_cross_ref_exist(struct btrfs_root *root,
 			  u64 objectid, u64 offset, u64 bytenr);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 struct btrfs_fs_info *info,

commit 310712b2f73ac1da4c3a99fd9886e8b652727508
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Jan 17 23:24:37 2017 -0800

    Btrfs: constify struct btrfs_{,disk_}key wherever possible
    
    In a lot of places, it's unclear when it's safe to reuse a struct
    btrfs_key after it has been passed to a helper function. Constify these
    arguments wherever possible to make it obvious.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0c8646217a71..56b8595eacbb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1961,7 +1961,7 @@ BTRFS_SETGET_STACK_FUNCS(disk_key_offset, struct btrfs_disk_key, offset, 64);
 BTRFS_SETGET_STACK_FUNCS(disk_key_type, struct btrfs_disk_key, type, 8);
 
 static inline void btrfs_disk_key_to_cpu(struct btrfs_key *cpu,
-					 struct btrfs_disk_key *disk)
+					 const struct btrfs_disk_key *disk)
 {
 	cpu->offset = le64_to_cpu(disk->offset);
 	cpu->type = disk->type;
@@ -1969,7 +1969,7 @@ static inline void btrfs_disk_key_to_cpu(struct btrfs_key *cpu,
 }
 
 static inline void btrfs_cpu_key_to_disk(struct btrfs_disk_key *disk,
-					 struct btrfs_key *cpu)
+					 const struct btrfs_key *cpu)
 {
 	disk->offset = cpu_to_le64(cpu->offset);
 	disk->type = cpu->type;
@@ -2001,8 +2001,7 @@ static inline void btrfs_dir_item_key_to_cpu(struct extent_buffer *eb,
 	btrfs_disk_key_to_cpu(key, &disk_key);
 }
 
-
-static inline u8 btrfs_key_type(struct btrfs_key *key)
+static inline u8 btrfs_key_type(const struct btrfs_key *key)
 {
 	return key->type;
 }
@@ -2595,10 +2594,11 @@ void btrfs_get_block_group(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int get_block_group_index(struct btrfs_block_group_cache *cache);
 struct extent_buffer *btrfs_alloc_tree_block(struct btrfs_trans_handle *trans,
-					struct btrfs_root *root, u64 parent,
-					u64 root_objectid,
-					struct btrfs_disk_key *key, int level,
-					u64 hint, u64 empty_size);
+					     struct btrfs_root *root,
+					     u64 parent, u64 root_objectid,
+					     const struct btrfs_disk_key *key,
+					     int level, u64 hint,
+					     u64 empty_size);
 void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct extent_buffer *buf,
@@ -2758,9 +2758,9 @@ u64 add_new_free_space(struct btrfs_block_group_cache *block_group,
 		       struct btrfs_fs_info *info, u64 start, u64 end);
 
 /* ctree.c */
-int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
+int btrfs_bin_search(struct extent_buffer *eb, const struct btrfs_key *key,
 		     int level, int *slot);
-int btrfs_comp_cpu_keys(struct btrfs_key *k1, struct btrfs_key *k2);
+int btrfs_comp_cpu_keys(const struct btrfs_key *k1, const struct btrfs_key *k2);
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
@@ -2768,7 +2768,7 @@ int btrfs_previous_extent_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid);
 void btrfs_set_item_key_safe(struct btrfs_fs_info *fs_info,
 			     struct btrfs_path *path,
-			     struct btrfs_key *new_key);
+			     const struct btrfs_key *new_key);
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
 int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
@@ -2810,22 +2810,23 @@ void btrfs_truncate_item(struct btrfs_fs_info *fs_info,
 int btrfs_split_item(struct btrfs_trans_handle *trans,
 		     struct btrfs_root *root,
 		     struct btrfs_path *path,
-		     struct btrfs_key *new_key,
+		     const struct btrfs_key *new_key,
 		     unsigned long split_offset);
 int btrfs_duplicate_item(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 struct btrfs_path *path,
-			 struct btrfs_key *new_key);
+			 const struct btrfs_key *new_key);
 int btrfs_find_item(struct btrfs_root *fs_root, struct btrfs_path *path,
 		u64 inum, u64 ioff, u8 key_type, struct btrfs_key *found_key);
-int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, struct btrfs_key *key, struct btrfs_path *p, int
-		      ins_len, int cow);
-int btrfs_search_old_slot(struct btrfs_root *root, struct btrfs_key *key,
+int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		      const struct btrfs_key *key, struct btrfs_path *p,
+		      int ins_len, int cow);
+int btrfs_search_old_slot(struct btrfs_root *root, const struct btrfs_key *key,
 			  struct btrfs_path *p, u64 time_seq);
 int btrfs_search_slot_for_read(struct btrfs_root *root,
-			       struct btrfs_key *key, struct btrfs_path *p,
-			       int find_higher, int return_any);
+			       const struct btrfs_key *key,
+			       struct btrfs_path *p, int find_higher,
+			       int return_any);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct extent_buffer *parent,
 		       int start_slot, u64 *last_ret,
@@ -2848,19 +2849,20 @@ static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 }
 
 void setup_items_for_insert(struct btrfs_root *root, struct btrfs_path *path,
-			    struct btrfs_key *cpu_key, u32 *data_size,
+			    const struct btrfs_key *cpu_key, u32 *data_size,
 			    u32 total_data, u32 total_size, int nr);
-int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, struct btrfs_key *key, void *data, u32 data_size);
+int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		      const struct btrfs_key *key, void *data, u32 data_size);
 int btrfs_insert_empty_items(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path,
-			     struct btrfs_key *cpu_key, u32 *data_size, int nr);
+			     const struct btrfs_key *cpu_key, u32 *data_size,
+			     int nr);
 
 static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,
-					  struct btrfs_key *key,
+					  const struct btrfs_key *key,
 					  u32 data_size)
 {
 	return btrfs_insert_empty_items(trans, root, path, key, &data_size, 1);
@@ -2949,15 +2951,15 @@ int btrfs_del_root_ref(struct btrfs_trans_handle *trans,
 		       u64 root_id, u64 ref_id, u64 dirid, u64 *sequence,
 		       const char *name, int name_len);
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		   struct btrfs_key *key);
-int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, struct btrfs_key *key, struct btrfs_root_item
-		      *item);
+		   const struct btrfs_key *key);
+int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		      const struct btrfs_key *key,
+		      struct btrfs_root_item *item);
 int __must_check btrfs_update_root(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root,
 				   struct btrfs_key *key,
 				   struct btrfs_root_item *item);
-int btrfs_find_root(struct btrfs_root *root, struct btrfs_key *search_key,
+int btrfs_find_root(struct btrfs_root *root, const struct btrfs_key *search_key,
 		    struct btrfs_path *path, struct btrfs_root_item *root_item,
 		    struct btrfs_key *root_key);
 int btrfs_find_orphan_roots(struct btrfs_fs_info *fs_info);

commit 4ec5934e43cabd16d3d61dd095e182c32e7433d5
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Wed Jan 18 00:31:44 2017 +0200

    btrfs: Make btrfs_unlink_inode take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <n.borisov.lkml@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6ebbccf41f46..0c8646217a71 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3127,7 +3127,7 @@ struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry);
 int btrfs_set_inode_index(struct inode *dir, u64 *index);
 int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root,
-		       struct inode *dir, struct inode *inode,
+		       struct btrfs_inode *dir, struct btrfs_inode *inode,
 		       const char *name, int name_len);
 int btrfs_add_link(struct btrfs_trans_handle *trans,
 		   struct inode *parent_inode, struct inode *inode,

commit 823bb20ab47071dc8a98acf272a470ccdcfcf6d1
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jan 4 11:09:51 2017 +0100

    btrfs: add wrapper for counting BTRFS_MAX_EXTENT_SIZE
    
    The expression is open-coded in several places, this asks for a wrapper.
    As we know the MAX_EXTENT fits to u32, we can use the appropirate
    division helper. This cascades to the result type updates.
    
    Compiler is clever enough to use shift instead of integer division, so
    there's no change in the generated assembly.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6a823719b6c5..6ebbccf41f46 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -97,6 +97,14 @@ static const int btrfs_csum_sizes[] = { 4 };
 
 #define BTRFS_MAX_EXTENT_SIZE SZ_128M
 
+/*
+ * Count how many BTRFS_MAX_EXTENT_SIZE cover the @size
+ */
+static inline u32 count_max_extents(u64 size)
+{
+	return div_u64(size + BTRFS_MAX_EXTENT_SIZE - 1, BTRFS_MAX_EXTENT_SIZE);
+}
+
 struct btrfs_mapping_tree {
 	struct extent_map_tree map_tree;
 };

commit 0110c350c86d511be2130cb2a30dcbb76c4af750
Merge: d9cb5bfcc333 9763f7a4a5f7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 17 18:44:00 2016 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull more vfs updates from Al Viro:
     "In this pile:
    
       - autofs-namespace series
       - dedupe stuff
       - more struct path constification"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (40 commits)
      ocfs2: implement the VFS clone_range, copy_range, and dedupe_range features
      ocfs2: charge quota for reflinked blocks
      ocfs2: fix bad pointer cast
      ocfs2: always unlock when completing dio writes
      ocfs2: don't eat io errors during _dio_end_io_write
      ocfs2: budget for extent tree splits when adding refcount flag
      ocfs2: prohibit refcounted swapfiles
      ocfs2: add newlines to some error messages
      ocfs2: convert inode refcount test to a helper
      simple_write_end(): don't zero in short copy into uptodate
      exofs: don't mess with simple_write_{begin,end}
      9p: saner ->write_end() on failing copy into non-uptodate page
      fix gfs2_stuffed_write_end() on short copies
      fix ceph_write_end()
      nfs_write_end(): fix handling of short copies
      vfs: refactor clone/dedupe_file_range common functions
      fs: try to clone files first in vfs_copy_file_range
      vfs: misc struct path constification
      namespace.c: constify struct path passed to a bunch of primitives
      quota: constify struct path in quota_on
      ...

commit a76b5b04375f974579c83433b06466758c0c552c
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Dec 9 16:17:19 2016 -0800

    fs: try to clone files first in vfs_copy_file_range
    
    A clone is a perfectly fine implementation of a file copy, so most
    file systems just implement the copy that way.  Instead of duplicating
    this logic move it to the VFS.  Currently btrfs and XFS implement copies
    the same way as clones and there is no behavior change for them, cifs
    only implements clones and grow support for copy_file_range with this
    patch.  NFS implements both, so this will allow copy_file_range to work
    on servers that only implement CLONE and be lot more efficient on servers
    that implements CLONE and COPY.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0b8ce2b9f7d0..05f75a949af4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3232,9 +3232,6 @@ int btrfs_dirty_pages(struct btrfs_root *root, struct inode *inode,
 		      loff_t pos, size_t write_bytes,
 		      struct extent_state **cached);
 int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
-ssize_t btrfs_copy_file_range(struct file *file_in, loff_t pos_in,
-			      struct file *file_out, loff_t pos_out,
-			      size_t len, unsigned int flags);
 int btrfs_clone_file_range(struct file *file_in, loff_t pos_in,
 			   struct file *file_out, loff_t pos_out, u64 len);
 

commit e5d6b12fe14e89ea1c494585c47b1dfb31d71183
Author: Chris Mason <clm@fb.com>
Date:   Fri Dec 9 05:56:33 2016 -0800

    Btrfs: don't WARN() in btrfs_transaction_abort() for IO errors
    
    btrfs_transaction_abort() has a WARN() to help us nail down whatever
    problem lead to the abort.  But most of the time, we're aborting for EIO,
    and the warning just adds noise.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fc1864acb368..50bcfb80d33a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3445,9 +3445,14 @@ do {								\
 	/* Report first abort since mount */			\
 	if (!test_and_set_bit(BTRFS_FS_STATE_TRANS_ABORTED,	\
 			&((trans)->fs_info->fs_state))) {	\
-		WARN(1, KERN_DEBUG				\
-		"BTRFS: Transaction aborted (error %d)\n",	\
-		(errno));					\
+		if ((errno) != -EIO) {				\
+			WARN(1, KERN_DEBUG				\
+			"BTRFS: Transaction aborted (error %d)\n",	\
+			(errno));					\
+		} else {						\
+			pr_debug("BTRFS: Transaction aborted (error %d)\n", \
+				  (errno));			\
+		}						\
 	}							\
 	__btrfs_abort_transaction((trans), __func__,		\
 				  __LINE__, (errno));		\

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 860103020ac9..fc1864acb368 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1349,10 +1349,9 @@ static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_fs_info *info)
 
 #ifdef CONFIG_BTRFS_DEBUG
 static inline int
-btrfs_should_fragment_free_space(struct btrfs_root *root,
-				 struct btrfs_block_group_cache *block_group)
+btrfs_should_fragment_free_space(struct btrfs_block_group_cache *block_group)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
+	struct btrfs_fs_info *fs_info = block_group->fs_info;
 
 	return (btrfs_test_opt(fs_info, FRAGMENT_METADATA) &&
 		block_group->flags & BTRFS_BLOCK_GROUP_METADATA) ||
@@ -2311,10 +2310,9 @@ static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
  * this returns the address of the start of the last item,
  * which is the stop of the leaf data stack
  */
-static inline unsigned int leaf_data_end(struct btrfs_root *root,
+static inline unsigned int leaf_data_end(struct btrfs_fs_info *fs_info,
 					 struct extent_buffer *leaf)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	u32 nr = btrfs_header_nritems(leaf);
 
 	if (nr == 0)
@@ -2536,7 +2534,7 @@ static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 
 /* extent-tree.c */
 
-u64 btrfs_csum_bytes_to_leaves(struct btrfs_root *root, u64 csum_bytes);
+u64 btrfs_csum_bytes_to_leaves(struct btrfs_fs_info *fs_info, u64 csum_bytes);
 
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
@@ -2555,9 +2553,9 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 }
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,
-				       struct btrfs_root *root);
+				       struct btrfs_fs_info *fs_info);
 int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans,
-				       struct btrfs_root *root);
+				       struct btrfs_fs_info *fs_info);
 void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
 					 const u64 start);
 void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);
@@ -2566,18 +2564,18 @@ void btrfs_dec_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
 void btrfs_wait_nocow_writers(struct btrfs_block_group_cache *bg);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, unsigned long count);
-int btrfs_async_run_delayed_refs(struct btrfs_root *root,
+			   struct btrfs_fs_info *fs_info, unsigned long count);
+int btrfs_async_run_delayed_refs(struct btrfs_fs_info *fs_info,
 				 unsigned long count, u64 transid, int wait);
-int btrfs_lookup_data_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_lookup_data_extent(struct btrfs_fs_info *fs_info, u64 start, u64 len);
 int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *root, u64 bytenr,
+			     struct btrfs_fs_info *fs_info, u64 bytenr,
 			     u64 offset, int metadata, u64 *refs, u64 *flags);
-int btrfs_pin_extent(struct btrfs_root *root,
+int btrfs_pin_extent(struct btrfs_fs_info *fs_info,
 		     u64 bytenr, u64 num, int reserved);
-int btrfs_pin_extent_for_log_replay(struct btrfs_root *root,
+int btrfs_pin_extent_for_log_replay(struct btrfs_fs_info *fs_info,
 				    u64 bytenr, u64 num_bytes);
-int btrfs_exclude_logged_extents(struct btrfs_root *root,
+int btrfs_exclude_logged_extents(struct btrfs_fs_info *fs_info,
 				 struct extent_buffer *eb);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
@@ -2598,12 +2596,11 @@ void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
 			   struct extent_buffer *buf,
 			   u64 parent, int last_ref);
 int btrfs_alloc_reserved_file_extent(struct btrfs_trans_handle *trans,
-				     struct btrfs_root *root,
 				     u64 root_objectid, u64 owner,
 				     u64 offset, u64 ram_bytes,
 				     struct btrfs_key *ins);
 int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
-				   struct btrfs_root *root,
+				   struct btrfs_fs_info *fs_info,
 				   u64 root_objectid, u64 owner, u64 offset,
 				   struct btrfs_key *ins);
 int btrfs_reserve_extent(struct btrfs_root *root, u64 ram_bytes, u64 num_bytes,
@@ -2614,39 +2611,39 @@ int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf, int full_backref);
 int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root,
+				struct btrfs_fs_info *fs_info,
 				u64 bytenr, u64 num_bytes, u64 flags,
 				int level, int is_data);
 int btrfs_free_extent(struct btrfs_trans_handle *trans,
-		      struct btrfs_root *root,
+		      struct btrfs_fs_info *fs_info,
 		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,
 		      u64 owner, u64 offset);
 
-int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len,
-			       int delalloc);
-int btrfs_free_and_pin_reserved_extent(struct btrfs_root *root,
+int btrfs_free_reserved_extent(struct btrfs_fs_info *fs_info,
+			       u64 start, u64 len, int delalloc);
+int btrfs_free_and_pin_reserved_extent(struct btrfs_fs_info *fs_info,
 				       u64 start, u64 len);
 void btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
-				 struct btrfs_root *root);
+				 struct btrfs_fs_info *fs_info);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *root);
+			       struct btrfs_fs_info *fs_info);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
-			 struct btrfs_root *root,
+			 struct btrfs_fs_info *fs_info,
 			 u64 bytenr, u64 num_bytes, u64 parent,
 			 u64 root_objectid, u64 owner, u64 offset);
 
 int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans,
-				   struct btrfs_root *root);
+				   struct btrfs_fs_info *fs_info);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
-				    struct btrfs_root *root);
+				   struct btrfs_fs_info *fs_info);
 int btrfs_setup_space_cache(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root);
-int btrfs_extent_readonly(struct btrfs_root *root, u64 bytenr);
+			    struct btrfs_fs_info *fs_info);
+int btrfs_extent_readonly(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_fs_info *info);
 int btrfs_can_relocate(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, u64 bytes_used,
+			   struct btrfs_fs_info *fs_info, u64 bytes_used,
 			   u64 type, u64 chunk_objectid, u64 chunk_offset,
 			   u64 size);
 struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
@@ -2659,7 +2656,7 @@ void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
-				       struct btrfs_root *root);
+				       struct btrfs_fs_info *fs_info);
 u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
@@ -2689,7 +2686,7 @@ void btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
 void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
 					    u64 len);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root);
+				  struct btrfs_fs_info *fs_info);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
 				  struct inode *inode);
@@ -2698,7 +2695,7 @@ int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
 				     int nitems,
 				     u64 *qgroup_reserved, bool use_global_rsv);
-void btrfs_subvolume_release_metadata(struct btrfs_root *root,
+void btrfs_subvolume_release_metadata(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_rsv *rsv,
 				      u64 qgroup_reserved);
 int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
@@ -2706,16 +2703,15 @@ void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);
 void btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
-struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root,
+struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_fs_info *fs_info,
 					      unsigned short type);
-void btrfs_free_block_rsv(struct btrfs_root *root,
+void btrfs_free_block_rsv(struct btrfs_fs_info *fs_info,
 			  struct btrfs_block_rsv *rsv);
 void __btrfs_free_block_rsv(struct btrfs_block_rsv *rsv);
 int btrfs_block_rsv_add(struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv, u64 num_bytes,
 			enum btrfs_reserve_flush_enum flush);
-int btrfs_block_rsv_check(struct btrfs_root *root,
-			  struct btrfs_block_rsv *block_rsv, int min_factor);
+int btrfs_block_rsv_check(struct btrfs_block_rsv *block_rsv, int min_factor);
 int btrfs_block_rsv_refill(struct btrfs_root *root,
 			   struct btrfs_block_rsv *block_rsv, u64 min_reserved,
 			   enum btrfs_reserve_flush_enum flush);
@@ -2725,22 +2721,21 @@ int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *dest, u64 num_bytes,
 			     int min_factor);
-void btrfs_block_rsv_release(struct btrfs_root *root,
+void btrfs_block_rsv_release(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);
 int btrfs_inc_block_group_ro(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
-void btrfs_dec_block_group_ro(struct btrfs_root *root,
-			      struct btrfs_block_group_cache *cache);
+void btrfs_dec_block_group_ro(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
-int btrfs_error_unpin_extent_range(struct btrfs_root *root,
+int btrfs_error_unpin_extent_range(struct btrfs_fs_info *fs_info,
 				   u64 start, u64 end);
-int btrfs_discard_extent(struct btrfs_root *root, u64 bytenr,
+int btrfs_discard_extent(struct btrfs_fs_info *fs_info, u64 bytenr,
 			 u64 num_bytes, u64 *actual_bytes);
 int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root, u64 type);
-int btrfs_trim_fs(struct btrfs_root *root, struct fstrim_range *range);
+			    struct btrfs_fs_info *fs_info, u64 type);
+int btrfs_trim_fs(struct btrfs_fs_info *fs_info, struct fstrim_range *range);
 
 int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
@@ -2750,8 +2745,7 @@ int btrfs_start_write_no_snapshoting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshoting(struct btrfs_root *root);
 void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root,
-			const u64 type);
+			struct btrfs_fs_info *fs_info, const u64 type);
 u64 add_new_free_space(struct btrfs_block_group_cache *block_group,
 		       struct btrfs_fs_info *info, u64 start, u64 end);
 
@@ -2801,10 +2795,10 @@ int btrfs_copy_root(struct btrfs_trans_handle *trans,
 		      struct extent_buffer **cow_ret, u64 new_root_objectid);
 int btrfs_block_can_be_shared(struct btrfs_root *root,
 			      struct extent_buffer *buf);
-void btrfs_extend_item(struct btrfs_root *root, struct btrfs_path *path,
+void btrfs_extend_item(struct btrfs_fs_info *fs_info, struct btrfs_path *path,
 		       u32 data_size);
-void btrfs_truncate_item(struct btrfs_root *root, struct btrfs_path *path,
-			 u32 new_size, int from_end);
+void btrfs_truncate_item(struct btrfs_fs_info *fs_info,
+			 struct btrfs_path *path, u32 new_size, int from_end);
 int btrfs_split_item(struct btrfs_trans_handle *trans,
 		     struct btrfs_root *root,
 		     struct btrfs_path *path,
@@ -2880,7 +2874,8 @@ static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
 {
 	return btrfs_next_old_item(root, p, 0);
 }
-int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
+int btrfs_leaf_free_space(struct btrfs_fs_info *fs_info,
+			  struct extent_buffer *leaf);
 int __must_check btrfs_drop_snapshot(struct btrfs_root *root,
 				     struct btrfs_block_rsv *block_rsv,
 				     int update_ref, int for_reloc);
@@ -2906,11 +2901,9 @@ static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
  * anything except sleeping. This function is used to check the status of
  * the fs.
  */
-static inline int btrfs_need_cleaner_sleep(struct btrfs_root *root)
+static inline int btrfs_need_cleaner_sleep(struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
-
-	return (fs_info->sb->s_flags & MS_RDONLY || btrfs_fs_closing(fs_info));
+	return fs_info->sb->s_flags & MS_RDONLY || btrfs_fs_closing(fs_info);
 }
 
 static inline void free_fs_info(struct btrfs_fs_info *fs_info)
@@ -3013,10 +3006,10 @@ struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
 					  struct btrfs_path *path, u64 dir,
 					  const char *name, u16 name_len,
 					  int mod);
-int verify_dir_item(struct btrfs_root *root,
+int verify_dir_item(struct btrfs_fs_info *fs_info,
 		    struct extent_buffer *leaf,
 		    struct btrfs_dir_item *dir_item);
-struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,
+struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_fs_info *fs_info,
 						 struct btrfs_path *path,
 						 const char *name,
 						 int name_len);
@@ -3061,10 +3054,9 @@ int btrfs_find_name_in_ext_backref(struct btrfs_path *path,
 struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_fs_info *fs_info, u64 bytenr, u64 len);
-int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
-			  struct bio *bio, u32 *dst);
-int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct bio *bio, u64 logical_offset);
+int btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst);
+int btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio,
+			      u64 logical_offset);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,
@@ -3078,8 +3070,8 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums);
-int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
-		       struct bio *bio, u64 file_start, int contig);
+int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
+		       u64 file_start, int contig);
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit);
 void btrfs_extent_item_to_extent_map(struct inode *inode,
@@ -3182,7 +3174,7 @@ void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
 int btrfs_cont_expand(struct inode *inode, loff_t oldsize, loff_t size);
 void btrfs_invalidate_inodes(struct btrfs_root *root);
 void btrfs_add_delayed_iput(struct inode *inode);
-void btrfs_run_delayed_iputs(struct btrfs_root *root);
+void btrfs_run_delayed_iputs(struct btrfs_fs_info *fs_info);
 int btrfs_prealloc_file_range(struct inode *inode, int mode,
 			      u64 start, u64 num_bytes, u64 min_size,
 			      loff_t actual_len, u64 *alloc_hint);
@@ -3236,9 +3228,8 @@ int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);
-int btrfs_dirty_pages(struct btrfs_root *root, struct inode *inode,
-		      struct page **pages, size_t num_pages,
-		      loff_t pos, size_t write_bytes,
+int btrfs_dirty_pages(struct inode *inode, struct page **pages,
+		      size_t num_pages, loff_t pos, size_t write_bytes,
 		      struct extent_state **cached);
 int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
 ssize_t btrfs_copy_file_range(struct file *file_in, loff_t pos_in,
@@ -3261,7 +3252,7 @@ void btrfs_sysfs_remove_mounted(struct btrfs_fs_info *fs_info);
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 
 /* super.c */
-int btrfs_parse_options(struct btrfs_root *root, char *options,
+int btrfs_parse_options(struct btrfs_fs_info *info, char *options,
 			unsigned long new_flags);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 
@@ -3637,12 +3628,12 @@ int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,
 		    u64 end, struct btrfs_scrub_progress *progress,
 		    int readonly, int is_dev_replace);
-void btrfs_scrub_pause(struct btrfs_root *root);
-void btrfs_scrub_continue(struct btrfs_root *root);
+void btrfs_scrub_pause(struct btrfs_fs_info *fs_info);
+void btrfs_scrub_continue(struct btrfs_fs_info *fs_info);
 int btrfs_scrub_cancel(struct btrfs_fs_info *info);
 int btrfs_scrub_cancel_dev(struct btrfs_fs_info *info,
 			   struct btrfs_device *dev);
-int btrfs_scrub_progress(struct btrfs_root *root, u64 devid,
+int btrfs_scrub_progress(struct btrfs_fs_info *fs_info, u64 devid,
 			 struct btrfs_scrub_progress *progress);
 
 /* dev-replace.c */

commit 0b246afa62b0cf5b09d078121f543135f28492ad
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:23 2016 -0400

    btrfs: root->fs_info cleanup, add fs_info convenience variables
    
    In routines where someptr->fs_info is referenced multiple times, we
    introduce a convenience variable.  This makes the code considerably
    more readable.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 19b6bb2f2368..860103020ac9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1352,9 +1352,11 @@ static inline int
 btrfs_should_fragment_free_space(struct btrfs_root *root,
 				 struct btrfs_block_group_cache *block_group)
 {
-	return (btrfs_test_opt(root->fs_info, FRAGMENT_METADATA) &&
+	struct btrfs_fs_info *fs_info = root->fs_info;
+
+	return (btrfs_test_opt(fs_info, FRAGMENT_METADATA) &&
 		block_group->flags & BTRFS_BLOCK_GROUP_METADATA) ||
-	       (btrfs_test_opt(root->fs_info, FRAGMENT_DATA) &&
+	       (btrfs_test_opt(fs_info, FRAGMENT_DATA) &&
 		block_group->flags &  BTRFS_BLOCK_GROUP_DATA);
 }
 #endif
@@ -2312,10 +2314,11 @@ static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 static inline unsigned int leaf_data_end(struct btrfs_root *root,
 					 struct extent_buffer *leaf)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	u32 nr = btrfs_header_nritems(leaf);
 
 	if (nr == 0)
-		return BTRFS_LEAF_DATA_SIZE(root->fs_info);
+		return BTRFS_LEAF_DATA_SIZE(fs_info);
 	return btrfs_item_offset_nr(leaf, nr - 1);
 }
 
@@ -2905,8 +2908,9 @@ static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
  */
 static inline int btrfs_need_cleaner_sleep(struct btrfs_root *root)
 {
-	return (root->fs_info->sb->s_flags & MS_RDONLY ||
-		btrfs_fs_closing(root->fs_info));
+	struct btrfs_fs_info *fs_info = root->fs_info;
+
+	return (fs_info->sb->s_flags & MS_RDONLY || btrfs_fs_closing(fs_info));
 }
 
 static inline void free_fs_info(struct btrfs_fs_info *fs_info)

commit 27965b6c2cad220f6c512334665808bf3d895e5e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Jun 16 11:07:27 2016 -0400

    btrfs: root->fs_info cleanup, btrfs_calc_{trans,trunc}_metadata_size
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6a5c0072a72b..19b6bb2f2368 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2535,20 +2535,20 @@ static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 
 u64 btrfs_csum_bytes_to_leaves(struct btrfs_root *root, u64 csum_bytes);
 
-static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
+static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
-	return root->fs_info->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
+	return fs_info->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
 }
 
 /*
  * Doing a truncate won't result in new nodes or leaves, just what we need for
  * COW.
  */
-static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_root *root,
+static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
-	return root->fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
+	return fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,

commit da17066c40472c2d6a1aab7bb0090c3d285531c9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 09:22:56 2016 -0400

    btrfs: pull node/sector/stripe sizes out of root and into fs_info
    
    We track the node sizes per-root, but they never vary from the values
    in the superblock.  This patch messes with the 80-column style a bit,
    but subsequent patches to factor out root->fs_info into a convenience
    variable fix it up again.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 15ff880bf4b5..6a5c0072a72b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -337,7 +337,7 @@ struct btrfs_path {
 	unsigned int need_commit_sem:1;
 	unsigned int skip_release_on_error:1;
 };
-#define BTRFS_MAX_EXTENT_ITEM_SIZE(r) ((BTRFS_LEAF_DATA_SIZE(r) >> 4) - \
+#define BTRFS_MAX_EXTENT_ITEM_SIZE(r) ((BTRFS_LEAF_DATA_SIZE(r->fs_info) >> 4) - \
 					sizeof(struct btrfs_item))
 struct btrfs_dev_replace {
 	u64 replace_state;	/* see #define above */
@@ -1084,8 +1084,18 @@ struct btrfs_fs_info {
 
 	/* Used to record internally whether fs has been frozen */
 	int fs_frozen;
+
+	/* Cached block sizes */
+	u32 nodesize;
+	u32 sectorsize;
+	u32 stripesize;
 };
 
+static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
+{
+	return sb->s_fs_info;
+}
+
 struct btrfs_subvolume_writers {
 	struct percpu_counter	counter;
 	wait_queue_head_t	wait;
@@ -1159,14 +1169,6 @@ struct btrfs_root {
 	u64 objectid;
 	u64 last_trans;
 
-	/* data allocations are done in sectorsize units */
-	u32 sectorsize;
-
-	/* node allocations are done in nodesize units */
-	u32 nodesize;
-
-	u32 stripesize;
-
 	u32 type;
 
 	u64 highest_objectid;
@@ -1250,38 +1252,42 @@ struct btrfs_root {
 	/* For qgroup metadata space reserve */
 	atomic_t qgroup_meta_rsv;
 };
+static inline u32 btrfs_inode_sectorsize(const struct inode *inode)
+{
+	return btrfs_sb(inode->i_sb)->sectorsize;
+}
 
 static inline u32 __BTRFS_LEAF_DATA_SIZE(u32 blocksize)
 {
 	return blocksize - sizeof(struct btrfs_header);
 }
 
-static inline u32 BTRFS_LEAF_DATA_SIZE(const struct btrfs_root *root)
+static inline u32 BTRFS_LEAF_DATA_SIZE(const struct btrfs_fs_info *info)
 {
-	return __BTRFS_LEAF_DATA_SIZE(root->nodesize);
+	return __BTRFS_LEAF_DATA_SIZE(info->nodesize);
 }
 
-static inline u32 BTRFS_MAX_ITEM_SIZE(const struct btrfs_root *root)
+static inline u32 BTRFS_MAX_ITEM_SIZE(const struct btrfs_fs_info *info)
 {
-	return BTRFS_LEAF_DATA_SIZE(root) - sizeof(struct btrfs_item);
+	return BTRFS_LEAF_DATA_SIZE(info) - sizeof(struct btrfs_item);
 }
 
-static inline u32 BTRFS_NODEPTRS_PER_BLOCK(const struct btrfs_root *root)
+static inline u32 BTRFS_NODEPTRS_PER_BLOCK(const struct btrfs_fs_info *info)
 {
-	return BTRFS_LEAF_DATA_SIZE(root) / sizeof(struct btrfs_key_ptr);
+	return BTRFS_LEAF_DATA_SIZE(info) / sizeof(struct btrfs_key_ptr);
 }
 
 #define BTRFS_FILE_EXTENT_INLINE_DATA_START		\
 		(offsetof(struct btrfs_file_extent_item, disk_bytenr))
-static inline u32 BTRFS_MAX_INLINE_DATA_SIZE(const struct btrfs_root *root)
+static inline u32 BTRFS_MAX_INLINE_DATA_SIZE(const struct btrfs_fs_info *info)
 {
-	return BTRFS_MAX_ITEM_SIZE(root) -
+	return BTRFS_MAX_ITEM_SIZE(info) -
 	       BTRFS_FILE_EXTENT_INLINE_DATA_START;
 }
 
-static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_root *root)
+static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_fs_info *info)
 {
-	return BTRFS_MAX_ITEM_SIZE(root) - sizeof(struct btrfs_dir_item);
+	return BTRFS_MAX_ITEM_SIZE(info) - sizeof(struct btrfs_dir_item);
 }
 
 /*
@@ -2309,7 +2315,7 @@ static inline unsigned int leaf_data_end(struct btrfs_root *root,
 	u32 nr = btrfs_header_nritems(leaf);
 
 	if (nr == 0)
-		return BTRFS_LEAF_DATA_SIZE(root);
+		return BTRFS_LEAF_DATA_SIZE(root->fs_info);
 	return btrfs_item_offset_nr(leaf, nr - 1);
 }
 
@@ -2505,11 +2511,6 @@ BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cursor_left,
 BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cursor_right,
 			 struct btrfs_dev_replace_item, cursor_right, 64);
 
-static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
-{
-	return sb->s_fs_info;
-}
-
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
@@ -2537,7 +2538,7 @@ u64 btrfs_csum_bytes_to_leaves(struct btrfs_root *root, u64 csum_bytes);
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)
 {
-	return root->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
+	return root->fs_info->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
 }
 
 /*
@@ -2547,7 +2548,7 @@ static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)
 {
-	return root->nodesize * BTRFS_MAX_LEVEL * num_items;
+	return root->fs_info->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,

commit f15376df0dc2b632eb689793a73d4adba8404987
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:56:18 2016 -0400

    btrfs: root->fs_info cleanup, io_ctl_init
    
    The io_ctl->root member was only being used to access root->fs_info.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9a3ca798087f..15ff880bf4b5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -519,7 +519,7 @@ struct btrfs_io_ctl {
 	void *cur, *orig;
 	struct page *page;
 	struct page **pages;
-	struct btrfs_root *root;
+	struct btrfs_fs_info *fs_info;
 	struct inode *inode;
 	unsigned long size;
 	int index;

commit c28f158e5ee78621ae693b8b18a9b89c7695af40
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:56:44 2016 -0400

    btrfs: struct reada_control.root -> reada_control.fs_info
    
    The root is never used.  We substitute extent_root in for the
    reada_find_extent call, since it's only ever used to obtain the node
    size.  This call site will be changed to use fs_info in a later patch.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 74110c7eebf1..9a3ca798087f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3652,7 +3652,7 @@ static inline void btrfs_bio_counter_dec(struct btrfs_fs_info *fs_info)
 
 /* reada.c */
 struct reada_control {
-	struct btrfs_root	*root;		/* tree to prefetch */
+	struct btrfs_fs_info	*fs_info;		/* tree to prefetch */
 	struct btrfs_key	key_start;
 	struct btrfs_key	key_end;	/* exclusive */
 	atomic_t		elems;

commit 6bccf3ab1e1f0913268bfcd1c09cadb1f4f2857d
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 21:16:51 2016 -0400

    btrfs: call functions that always use the same root with fs_info instead
    
    There are many functions that are always called with the same root
    argument.  Rather than passing the same root every time, we can
    pass an fs_info pointer instead and have the function get the root
    pointer itself.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 51cd757461c4..74110c7eebf1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2640,7 +2640,7 @@ int btrfs_setup_space_cache(struct btrfs_trans_handle *trans,
 int btrfs_extent_readonly(struct btrfs_root *root, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_fs_info *info);
-int btrfs_can_relocate(struct btrfs_root *root, u64 bytenr);
+int btrfs_can_relocate(struct btrfs_fs_info *fs_info, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, u64 bytes_used,
 			   u64 type, u64 chunk_objectid, u64 chunk_offset,
@@ -2649,7 +2649,7 @@ struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
 				struct btrfs_fs_info *fs_info,
 				const u64 chunk_offset);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *root, u64 group_start,
+			     struct btrfs_fs_info *fs_info, u64 group_start,
 			     struct extent_map *em);
 void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
 void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
@@ -2935,11 +2935,11 @@ int btrfs_old_root_level(struct btrfs_root *root, u64 time_seq);
 
 /* root-item.c */
 int btrfs_add_root_ref(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *tree_root,
+		       struct btrfs_fs_info *fs_info,
 		       u64 root_id, u64 ref_id, u64 dirid, u64 sequence,
 		       const char *name, int name_len);
 int btrfs_del_root_ref(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *tree_root,
+		       struct btrfs_fs_info *fs_info,
 		       u64 root_id, u64 ref_id, u64 dirid, u64 *sequence,
 		       const char *name, int name_len);
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -2954,7 +2954,7 @@ int __must_check btrfs_update_root(struct btrfs_trans_handle *trans,
 int btrfs_find_root(struct btrfs_root *root, struct btrfs_key *search_key,
 		    struct btrfs_path *path, struct btrfs_root_item *root_item,
 		    struct btrfs_key *root_key);
-int btrfs_find_orphan_roots(struct btrfs_root *tree_root);
+int btrfs_find_orphan_roots(struct btrfs_fs_info *fs_info);
 void btrfs_set_root_node(struct btrfs_root_item *item,
 			 struct extent_buffer *node);
 void btrfs_check_and_init_root_item(struct btrfs_root_item *item);
@@ -2963,10 +2963,10 @@ void btrfs_update_root_times(struct btrfs_trans_handle *trans,
 
 /* uuid-tree.c */
 int btrfs_uuid_tree_add(struct btrfs_trans_handle *trans,
-			struct btrfs_root *uuid_root, u8 *uuid, u8 type,
+			struct btrfs_fs_info *fs_info, u8 *uuid, u8 type,
 			u64 subid);
 int btrfs_uuid_tree_rem(struct btrfs_trans_handle *trans,
-			struct btrfs_root *uuid_root, u8 *uuid, u8 type,
+			struct btrfs_fs_info *fs_info, u8 *uuid, u8 type,
 			u64 subid);
 int btrfs_uuid_tree_iterate(struct btrfs_fs_info *fs_info,
 			    int (*check_func)(struct btrfs_fs_info *, u8 *, u8,
@@ -3613,7 +3613,7 @@ static inline int btrfs_init_acl(struct btrfs_trans_handle *trans,
 #endif
 
 /* relocation.c */
-int btrfs_relocate_block_group(struct btrfs_root *root, u64 group_start);
+int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start);
 int btrfs_init_reloc_root(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 int btrfs_update_reloc_root(struct btrfs_trans_handle *trans,

commit 5b4aacefb8fbfc996e68b9b083d30f8bc0972449
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 10:40:19 2016 -0400

    btrfs: call functions that overwrite their root parameter with fs_info
    
    There are 11 functions that accept a root parameter and immediately
    overwrite it.  We can pass those an fs_info pointer instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1b25a460ecea..51cd757461c4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2639,7 +2639,7 @@ int btrfs_setup_space_cache(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
 int btrfs_extent_readonly(struct btrfs_root *root, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
-int btrfs_read_block_groups(struct btrfs_root *root);
+int btrfs_read_block_groups(struct btrfs_fs_info *info);
 int btrfs_can_relocate(struct btrfs_root *root, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, u64 bytes_used,
@@ -3055,7 +3055,7 @@ int btrfs_find_name_in_ext_backref(struct btrfs_path *path,
 /* file-item.c */
 struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
-		    struct btrfs_root *root, u64 bytenr, u64 len);
+		    struct btrfs_fs_info *fs_info, u64 bytenr, u64 len);
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio, u32 *dst);
 int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,

commit ed0df618b1b06d7431ee4d985317fc5419a5d559
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 1 14:21:23 2016 +0100

    btrfs: store and load values of stripes_min/stripes_max in balance status item
    
    The balance status item contains currently known filter values, but the
    stripes filter was unintentionally not among them. This would mean, that
    interrupted and automatically restarted balance does not apply the
    stripe filters.
    
    Fixes: dee32d0ac3719ef8d640efaf0884111df444730f
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2cf4bc84388e..1b25a460ecea 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2210,6 +2210,8 @@ btrfs_disk_balance_args_to_cpu(struct btrfs_balance_args *cpu,
 	cpu->target = le64_to_cpu(disk->target);
 	cpu->flags = le64_to_cpu(disk->flags);
 	cpu->limit = le64_to_cpu(disk->limit);
+	cpu->stripes_min = le32_to_cpu(disk->stripes_min);
+	cpu->stripes_max = le32_to_cpu(disk->stripes_max);
 }
 
 static inline void
@@ -2228,6 +2230,8 @@ btrfs_cpu_balance_args_to_disk(struct btrfs_disk_balance_args *disk,
 	disk->target = cpu_to_le64(cpu->target);
 	disk->flags = cpu_to_le64(cpu->flags);
 	disk->limit = cpu_to_le64(cpu->limit);
+	disk->stripes_min = cpu_to_le32(cpu->stripes_min);
+	disk->stripes_max = cpu_to_le32(cpu->stripes_max);
 }
 
 /* struct btrfs_super_block */

commit 2230adffe4eae30ffce605daa81a116cb71b5960
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 9 00:03:12 2016 +0100

    btrfs: delete unused member from superblock
    
     __bdev' has never been used since
     0b86a832a1f38abec695864ec2eaedc9d2383f1b (2008).
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9768ce804265..2cf4bc84388e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -799,7 +799,6 @@ struct btrfs_fs_info {
 	spinlock_t super_lock;
 	struct btrfs_super_block *super_copy;
 	struct btrfs_super_block *super_for_commit;
-	struct block_device *__bdev;
 	struct super_block *sb;
 	struct inode *btree_inode;
 	struct backing_dev_info bdi;

commit fc2e901f26859a87b7cd5c49015552805b7a00e0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 13:50:03 2016 +0100

    btrfs: reada, sink start parameter to btree_readahead_hook
    
    Originally, the eb and start were passed separately in case eb is NULL.
    Since the readahead has been refactored in 4.6, this is not true anymore
    and we can get rid of the parameter.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b26b8b363f7f..9768ce804265 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3661,7 +3661,7 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 int btrfs_reada_wait(void *handle);
 void btrfs_reada_detach(void *handle);
 int btree_readahead_hook(struct btrfs_fs_info *fs_info,
-			 struct extent_buffer *eb, u64 start, int err);
+			 struct extent_buffer *eb, int err);
 
 static inline int is_fstree(u64 rootid)
 {

commit 939659dfd3ed4ff36dde532782207cfb0e5fbcf6
Author: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
Date:   Mon Nov 7 15:59:16 2016 +0800

    btrfs: add necessary comments about tickets_id
    
    Tickets_id's name may result in some misunderstandings,  it just indicates
    the next ticket will be handled and is not stored per ticket.
    
    Fixes: ce12965 ("btrfs: introduce tickets_id to determine whether
    asynchronous metadata reclaim work makes progress")
    Signed-off-by: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e4e01a99201a..b26b8b363f7f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -426,6 +426,10 @@ struct btrfs_space_info {
 	struct list_head ro_bgs;
 	struct list_head priority_tickets;
 	struct list_head tickets;
+	/*
+	 * tickets_id just indicates the next ticket will be handled, so note
+	 * it's not stored per ticket.
+	 */
 	u64 tickets_id;
 
 	struct rw_semaphore groups_sem;

commit cf8cddd38bab31b284af8d51fee536be9914f6ef
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 27 09:27:36 2016 +0200

    btrfs: don't abuse REQ_OP_* flags for btrfs_map_block
    
    btrfs_map_block supports different types of mappings, which to a large
    extent resemble block layer operations.  But they don't always do, and
    currently btrfs dangerously overlays it's own flag over the block layer
    flags.  This is just asking for a conflict, so introduce a different
    map flags enum inside of btrfs instead.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0b8ce2b9f7d0..e4e01a99201a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -90,9 +90,6 @@ static const int btrfs_csum_sizes[] = { 4 };
 /* four bytes for CRC32 */
 #define BTRFS_EMPTY_DIR_SIZE 0
 
-/* specific to btrfs_map_block(), therefore not in include/linux/blk_types.h */
-#define REQ_GET_READ_MIRRORS	(1 << 30)
-
 /* ioprio of readahead is set to idle */
 #define BTRFS_IOPRIO_READA (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_IDLE, 0))
 

commit d3304cadb2e24517938e24efd58fd9ee6504fefe
Merge: 1a892b485f32 d9ed71e5457c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 14 17:44:56 2016 -0700

    Merge branch 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Some fixes from Omar and Dave Sterba for our new free space tree.
    
      This isn't heavily used yet, but as we move toward making it the new
      default we wanted to nail down an endian bug"
    
    * 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: tests: uninline member definitions in free_space_extent
      btrfs: tests: constify free space extent specs
      Btrfs: expand free space tree sanity tests to catch endianness bug
      Btrfs: fix extent buffer bitmap tests on big-endian systems
      Btrfs: catch invalid free space trees
      Btrfs: fix mount -o clear_cache,space_cache=v2
      Btrfs: fix free space tree bitmaps on big-endian systems

commit d9ed71e5457c8c5bf1dc706e06468eab9e2aa87e
Merge: 19c4d2f99478 0e6757859efe
Author: Chris Mason <clm@fb.com>
Date:   Wed Oct 12 13:16:00 2016 -0700

    Merge branch 'fst-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.9
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit f29135b54bcbfe1fea97d94e2ae860bade1d5a31
Merge: 4c609922a3ae 19c4d2f99478
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 11 11:23:06 2016 -0700

    Merge branch 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This is a big variety of fixes and cleanups.
    
      Liu Bo continues to fixup fuzzer related problems, and some of Josef's
      cleanups are prep for his bigger extent buffer changes (slated for
      v4.10)"
    
    * 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (39 commits)
      Revert "btrfs: let btrfs_delete_unused_bgs() to clean relocated bgs"
      Btrfs: remove unnecessary btrfs_mark_buffer_dirty in split_leaf
      Btrfs: don't BUG() during drop snapshot
      btrfs: fix btrfs_no_printk stub helper
      Btrfs: memset to avoid stale content in btree leaf
      btrfs: parent_start initialization cleanup
      btrfs: Remove already completed TODO comment
      btrfs: Do not reassign count in btrfs_run_delayed_refs
      btrfs: fix a possible umount deadlock
      Btrfs: fix memory leak in do_walk_down
      btrfs: btrfs_debug should consume fs_info when DEBUG is not defined
      btrfs: convert send's verbose_printk to btrfs_debug
      btrfs: convert pr_* to btrfs_* where possible
      btrfs: convert printk(KERN_* to use pr_* calls
      btrfs: unsplit printed strings
      btrfs: clean the old superblocks before freeing the device
      Btrfs: kill BUG_ON in run_delayed_tree_ref
      Btrfs: don't leak reloc root nodes on error
      btrfs: squash lines for simple wrapper functions
      Btrfs: improve check_node to avoid reading corrupted nodes
      ...

commit 6675df311db87aa2107a04ef97e19420953cbace
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Sep 22 17:24:22 2016 -0700

    Btrfs: catch invalid free space trees
    
    There are two separate issues that can lead to corrupted free space
    trees.
    
    1. The free space tree bitmaps had an endianness issue on big-endian
       systems which is fixed by an earlier patch in this series.
    2. btrfs-progs before v4.7.3 modified filesystems without updating the
       free space tree.
    
    To catch both of these issues at once, we need to force the free space
    tree to be rebuilt. To do so, add a FREE_SPACE_TREE_VALID compat_ro bit.
    If the bit isn't set, we know that it was either produced by a broken
    big-endian kernel or may have been corrupted by btrfs-progs.
    
    This also provides us with a way to add rudimentary read-write support
    for the free space tree to btrfs-progs: it can just clear this bit and
    have the kernel rebuild the free space tree.
    
    Cc: stable@vger.kernel.org # 4.5+
    Tested-by: Holger Hoffstätte <holger@applied-asynchrony.com>
    Tested-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 33fe03551105..791e47ce9d27 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -251,7 +251,8 @@ struct btrfs_super_block {
 #define BTRFS_FEATURE_COMPAT_SAFE_CLEAR		0ULL
 
 #define BTRFS_FEATURE_COMPAT_RO_SUPP			\
-	(BTRFS_FEATURE_COMPAT_RO_FREE_SPACE_TREE)
+	(BTRFS_FEATURE_COMPAT_RO_FREE_SPACE_TREE |	\
+	 BTRFS_FEATURE_COMPAT_RO_FREE_SPACE_TREE_VALID)
 
 #define BTRFS_FEATURE_COMPAT_RO_SAFE_SET	0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SAFE_CLEAR	0ULL

commit 2fd57fcb16483d718043940fd6dfeb176d4dc09c
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Sep 23 18:05:21 2016 +0200

    btrfs: fix btrfs_no_printk stub helper
    
    The addition of btrfs_no_printk() caused a build failure when
    CONFIG_PRINTK is disabled:
    
    fs/btrfs/send.c: In function 'send_rename':
    fs/btrfs/ctree.h:3367:2: error: implicit declaration of function 'btrfs_no_printk' [-Werror=implicit-function-declaration]
    
    This moves the helper outside of that #ifdef so it is always
    defined, and changes the existing #ifdef to refer to that
    helper as well for consistency.
    
    Fixes: 47c57058ff2c ("btrfs: btrfs_debug should consume fs_info when DEBUG is not defined")
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5f1408b43e48..bf7cb6da78e6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3256,20 +3256,17 @@ int btrfs_parse_options(struct btrfs_root *root, char *options,
 			unsigned long new_flags);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 
+static inline __printf(2, 3)
+void btrfs_no_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
+{
+}
+
 #ifdef CONFIG_PRINTK
 __printf(2, 3)
 void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...);
-__printf(2, 3)
-static inline int btrfs_no_printk(const struct btrfs_fs_info *fs_info,
-				   const char *fmt, ...)
-{
-	return 0;
-}
 #else
-static inline __printf(2, 3)
-void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
-{
-}
+#define btrfs_printk(fs_info, fmt, args...) \
+	btrfs_no_printk(fs_info, fmt, ##args)
 #endif
 
 #define btrfs_emerg(fs_info, fmt, args...) \

commit 851cd173f06045816528176001cf82948282029c
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Sep 23 13:44:44 2016 -0700

    Btrfs: memset to avoid stale content in btree leaf
    
    This is an additional patch to
    "Btrfs: memset to avoid stale content in btree node block".
    
    This uses memset to initialize the unused space in a leaf to avoid
    potential stale content, which may be incurred by pushing items
    between sibling leaves.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cb0ae90649c0..5f1408b43e48 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2293,6 +2293,21 @@ static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 	return offsetof(struct btrfs_leaf, items);
 }
 
+/*
+ * The leaf data grows from end-to-front in the node.
+ * this returns the address of the start of the last item,
+ * which is the stop of the leaf data stack
+ */
+static inline unsigned int leaf_data_end(struct btrfs_root *root,
+					 struct extent_buffer *leaf)
+{
+	u32 nr = btrfs_header_nritems(leaf);
+
+	if (nr == 0)
+		return BTRFS_LEAF_DATA_SIZE(root);
+	return btrfs_item_offset_nr(leaf, nr - 1);
+}
+
 /* struct btrfs_file_extent_item */
 BTRFS_SETGET_FUNCS(file_extent_type, struct btrfs_file_extent_item, type, 8);
 BTRFS_SETGET_STACK_FUNCS(stack_file_extent_disk_bytenr,

commit c01f5f96f511419ee656a60e09605b7b6a63b66c
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Sep 21 12:17:37 2016 -0400

    btrfs: btrfs_debug should consume fs_info when DEBUG is not defined
    
    We can hit unused variable warnings when btrfs_debug and friends are
    just aliases for no_printk.  This is due to the fs_info not getting
    consumed by the function call, which can happen if convenenience
    variables are used.  This patch adds a new btrfs_no_printk static inline
    that consumes the convenience variable and does nothing else.  It
    silences the unused variable warning and has no impact on the generated
    code:
    
    $ size fs/btrfs/extent_io.o*
       text    data     bss     dec     hex filename
      44072     152      32   44256    ace0 fs/btrfs/extent_io.o.btrfs_no_printk
      44072     152      32   44256    ace0 fs/btrfs/extent_io.o.no_printk
    
    Fixes: 27a0dd61a5 (Btrfs: make btrfs_debug match pr_debug handling related to DEBUG)
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9e8fd5ecef55..cb0ae90649c0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3244,6 +3244,12 @@ int btrfs_sync_fs(struct super_block *sb, int wait);
 #ifdef CONFIG_PRINTK
 __printf(2, 3)
 void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...);
+__printf(2, 3)
+static inline int btrfs_no_printk(const struct btrfs_fs_info *fs_info,
+				   const char *fmt, ...)
+{
+	return 0;
+}
 #else
 static inline __printf(2, 3)
 void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
@@ -3358,13 +3364,13 @@ do {									\
 	btrfs_printk_ratelimited(fs_info, KERN_DEBUG fmt, ##args)
 #else
 #define btrfs_debug(fs_info, fmt, args...) \
-	no_printk(KERN_DEBUG fmt, ##args)
+	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_in_rcu(fs_info, fmt, args...) \
-	no_printk(KERN_DEBUG fmt, ##args)
+	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl_in_rcu(fs_info, fmt, args...) \
-	no_printk(KERN_DEBUG fmt, ##args)
+	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl(fs_info, fmt, args...) \
-	no_printk(KERN_DEBUG fmt, ##args)
+	btrfs_no_printk(fs_info, KERN_DEBUG fmt, ##args)
 #endif
 
 #define btrfs_printk_in_rcu(fs_info, fmt, args...)	\

commit ab8d0fc48dba09e0a2b8b0dbfe144d4de9eb874f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:02 2016 -0400

    btrfs: convert pr_* to btrfs_* where possible
    
    For many printks, we want to know which file system issued the message.
    
    This patch converts most pr_* calls to use the btrfs_* versions instead.
    In some cases, this means adding plumbing to allow call sites access to
    an fs_info pointer.
    
    fs/btrfs/check-integrity.c is left alone for another day.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8937f3f8780a..9e8fd5ecef55 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3395,7 +3395,7 @@ do {								\
 __cold
 static inline void assfail(char *expr, char *file, int line)
 {
-	pr_err("BTRFS: assertion failed: %s, file: %s, line: %d",
+	pr_err("assertion failed: %s, file: %s, line: %d\n",
 	       expr, file, line);
 	BUG();
 }

commit 62e855771dacf7c4d6daf9741642a965e7066d31
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:01 2016 -0400

    btrfs: convert printk(KERN_* to use pr_* calls
    
    This patch converts printk(KERN_* style messages to use the pr_* versions.
    
    One side effect is that anything that was KERN_DEBUG is now automatically
    a dynamic debug message.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2b7041ed4cb8..8937f3f8780a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1435,13 +1435,13 @@ static inline void btrfs_init_map_token (struct btrfs_map_token *token)
 #define cpu_to_le8(v) (v)
 #define __le8 u8
 
-#define read_eb_member(eb, ptr, type, member, result) (			\
+#define read_eb_member(eb, ptr, type, member, result) (\
 	read_extent_buffer(eb, (char *)(result),			\
 			   ((unsigned long)(ptr)) +			\
 			    offsetof(type, member),			\
 			   sizeof(((type *)0)->member)))
 
-#define write_eb_member(eb, ptr, type, member, result) (		\
+#define write_eb_member(eb, ptr, type, member, result) (\
 	write_extent_buffer(eb, (char *)(result),			\
 			   ((unsigned long)(ptr)) +			\
 			    offsetof(type, member),			\
@@ -3358,7 +3358,7 @@ do {									\
 	btrfs_printk_ratelimited(fs_info, KERN_DEBUG fmt, ##args)
 #else
 #define btrfs_debug(fs_info, fmt, args...) \
-    no_printk(KERN_DEBUG fmt, ##args)
+	no_printk(KERN_DEBUG fmt, ##args)
 #define btrfs_debug_in_rcu(fs_info, fmt, args...) \
 	no_printk(KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl_in_rcu(fs_info, fmt, args...) \

commit afcdd129e05a9210a5d19d4aa6e0afa475fc49e2
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Sep 2 15:40:02 2016 -0400

    Btrfs: add a flags field to btrfs_fs_info
    
    We have a lot of random ints in btrfs_fs_info that can be put into flags.  This
    is mostly equivalent with the exception of how we deal with quota going on or
    off, now instead we set a flag when we are turning it on or off and deal with
    that appropriately, rather than just having a pending state that the current
    quota_enabled gets set to.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 176a61967a8a..2b7041ed4cb8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -677,9 +677,25 @@ struct btrfs_device;
 struct btrfs_fs_devices;
 struct btrfs_balance_control;
 struct btrfs_delayed_root;
+
+#define BTRFS_FS_BARRIER			1
+#define BTRFS_FS_CLOSING_START			2
+#define BTRFS_FS_CLOSING_DONE			3
+#define BTRFS_FS_LOG_RECOVERING			4
+#define BTRFS_FS_OPEN				5
+#define BTRFS_FS_QUOTA_ENABLED			6
+#define BTRFS_FS_QUOTA_ENABLING			7
+#define BTRFS_FS_QUOTA_DISABLING		8
+#define BTRFS_FS_UPDATE_UUID_TREE_GEN		9
+#define BTRFS_FS_CREATING_FREE_SPACE_TREE	10
+#define BTRFS_FS_BTREE_ERR			11
+#define BTRFS_FS_LOG1_ERR			12
+#define BTRFS_FS_LOG2_ERR			13
+
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
 	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
+	unsigned long flags;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct btrfs_root *chunk_root;
@@ -908,10 +924,6 @@ struct btrfs_fs_info {
 	int thread_pool_size;
 
 	struct kobject *space_info_kobj;
-	int do_barriers;
-	int closing;
-	int log_root_recovering;
-	int open;
 
 	u64 total_pinned;
 
@@ -988,17 +1000,6 @@ struct btrfs_fs_info {
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	u32 check_integrity_print_mask;
 #endif
-	/*
-	 * quota information
-	 */
-	unsigned int quota_enabled:1;
-
-	/*
-	 * quota_enabled only changes state after a commit. This holds the
-	 * next state.
-	 */
-	unsigned int pending_quota_state:1;
-
 	/* is qgroup tracking in a consistent state? */
 	u64 qgroup_flags;
 
@@ -1062,7 +1063,6 @@ struct btrfs_fs_info {
 	wait_queue_head_t replace_wait;
 
 	struct semaphore uuid_tree_rescan_sem;
-	unsigned int update_uuid_tree_gen:1;
 
 	/* Used to reclaim the metadata space in the background. */
 	struct work_struct async_reclaim_work;
@@ -1081,7 +1081,6 @@ struct btrfs_fs_info {
 	 */
 	struct list_head pinned_chunks;
 
-	int creating_free_space_tree;
 	/* Used to record internally whether fs has been frozen */
 	int fs_frozen;
 };
@@ -2868,10 +2867,14 @@ int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
 {
 	/*
-	 * Get synced with close_ctree()
+	 * Do it this way so we only ever do one test_bit in the normal case.
 	 */
-	smp_mb();
-	return fs_info->closing;
+	if (test_bit(BTRFS_FS_CLOSING_START, &fs_info->flags)) {
+		if (test_bit(BTRFS_FS_CLOSING_DONE, &fs_info->flags))
+			return 2;
+		return 1;
+	}
+	return 0;
 }
 
 /*

commit ba8b04c1d4adbc66f3653e3de5bd6c74a9a003bf
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jul 19 16:50:36 2016 +0800

    btrfs: extend btrfs_set_extent_delalloc and its friends to support in-band dedupe and subpage size patchset
    
    Extend btrfs_set_extent_delalloc() and extent_clear_unlock_delalloc()
    parameters for both in-band dedupe and subpage sector size patchset.
    
    This should reduce conflict of both patchset and the effort to rebase
    them.
    
    Cc: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ae496e41692a..176a61967a8a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3119,7 +3119,7 @@ int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
 int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int delay_iput,
 			       int nr);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
-			      struct extent_state **cached_state);
+			      struct extent_state **cached_state, int dedupe);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root,
 			     struct btrfs_root *parent_root,

commit 897a41b1167955bd543bb252fd3f06f5844f2177
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Aug 31 23:55:33 2016 -0400

    btrfs: add dynamic debug support
    
    We can re-use the dynamic debugging descriptor to make use of the dynamic
    debugging mechanism but still use our own printk interface.
    
    Defining the DEBUG macro works as it did before.  When it's defined,
    all of the messages default to print.  We can also enable all debug
    messages at boot or module-load time using the 'dyndbg' and
    'btrfs.dyndbg' options.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 33fe03551105..ae496e41692a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -37,6 +37,7 @@
 #include <linux/workqueue.h>
 #include <linux/security.h>
 #include <linux/sizes.h>
+#include <linux/dynamic_debug.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
@@ -3315,7 +3316,35 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 	btrfs_printk_ratelimited(fs_info, KERN_NOTICE fmt, ##args)
 #define btrfs_info_rl(fs_info, fmt, args...) \
 	btrfs_printk_ratelimited(fs_info, KERN_INFO fmt, ##args)
-#ifdef DEBUG
+
+#if defined(CONFIG_DYNAMIC_DEBUG)
+#define btrfs_debug(fs_info, fmt, args...)				\
+do {									\
+        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt);         	\
+        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT))  	\
+		btrfs_printk(fs_info, KERN_DEBUG fmt, ##args);		\
+} while (0)
+#define btrfs_debug_in_rcu(fs_info, fmt, args...) 			\
+do {									\
+        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt); 	        \
+        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT)) 		\
+		btrfs_printk_in_rcu(fs_info, KERN_DEBUG fmt, ##args);	\
+} while (0)
+#define btrfs_debug_rl_in_rcu(fs_info, fmt, args...)			\
+do {									\
+        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt);         	\
+        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT))  	\
+		btrfs_printk_rl_in_rcu(fs_info, KERN_DEBUG fmt,		\
+				       ##args);\
+} while (0)
+#define btrfs_debug_rl(fs_info, fmt, args...) 				\
+do {									\
+        DEFINE_DYNAMIC_DEBUG_METADATA(descriptor, fmt);         	\
+        if (unlikely(descriptor.flags & _DPRINTK_FLAGS_PRINT))  	\
+		btrfs_printk_ratelimited(fs_info, KERN_DEBUG fmt,	\
+					 ##args);			\
+} while (0)
+#elif defined(DEBUG)
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_in_rcu(fs_info, fmt, args...) \

commit f0312210010bf063c29efe112b0d9accbc9191b3
Author: Miklos Szeredi <mszeredi@redhat.com>
Date:   Fri Sep 16 12:44:21 2016 +0200

    btrfs: use filemap_check_errors()
    
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Cc: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 33fe03551105..e62fd50237e4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3161,7 +3161,6 @@ int btrfs_prealloc_file_range_trans(struct inode *inode,
 				    struct btrfs_trans_handle *trans, int mode,
 				    u64 start, u64 num_bytes, u64 min_size,
 				    loff_t actual_len, u64 *alloc_hint);
-int btrfs_inode_check_errors(struct inode *inode);
 extern const struct dentry_operations btrfs_dentry_operations;
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 void btrfs_test_inode_set_ops(struct inode *inode);

commit f4a9c169c29efea31b22aec0012ad29df6cf84d4
Merge: 067c2f472d81 b7f3c7d345f7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 9 12:52:31 2016 -0700

    Merge branch 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "I'm not proud of how long it took me to track down that one liner in
      btrfs_sync_log(), but the good news is the patches I was trying to
      blame for these problems were actually fine (sorry Filipe)"
    
    * 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: introduce tickets_id to determine whether asynchronous metadata reclaim work makes progress
      btrfs: remove root_log_ctx from ctx list before btrfs_sync_log returns
      btrfs: do not decrease bytes_may_use when replaying extents

commit ce129655c9d9aaa7b3bcc46529db1b36693575ed
Author: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
Date:   Fri Sep 2 10:58:46 2016 +0800

    btrfs: introduce tickets_id to determine whether asynchronous metadata reclaim work makes progress
    
    In btrfs_async_reclaim_metadata_space(), we use ticket's address to
    determine whether asynchronous metadata reclaim work is making progress.
    
            ticket = list_first_entry(&space_info->tickets,
                                      struct reserve_ticket, list);
            if (last_ticket == ticket) {
                    flush_state++;
            } else {
                    last_ticket = ticket;
                    flush_state = FLUSH_DELAYED_ITEMS_NR;
                    if (commit_cycles)
                            commit_cycles--;
            }
    
    But indeed it's wrong, we should not rely on local variable's address to
    do this check, because addresses may be same. In my test environment, I
    dd one 168MB file in a 256MB fs, found that for this file, every time
    wait_reserve_ticket() called, local variable ticket's address is same,
    
    For above codes, assume a previous ticket's address is addrA, last_ticket
    is addrA. Btrfs_async_reclaim_metadata_space() finished this ticket and
    wake up it, then another ticket is added, but with the same address addrA,
    now last_ticket will be same to current ticket, then current ticket's flush
    work will start from current flush_state, not initial FLUSH_DELAYED_ITEMS_NR,
    which may result in some enospc issues(I have seen this in my test machine).
    
    Signed-off-by: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ec4154faab61..146d1c7078ed 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -427,6 +427,7 @@ struct btrfs_space_info {
 	struct list_head ro_bgs;
 	struct list_head priority_tickets;
 	struct list_head tickets;
+	u64 tickets_id;
 
 	struct rw_semaphore groups_sem;
 	/* for block groups in our same type */

commit 28687b935e93a9041a485b9ecdcab0e335f8eda5
Merge: 370f6017295d 28a235931b56
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 26 20:22:01 2016 -0700

    Merge branch 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "We've queued up a few different fixes in here.  These range from
      enospc corners to fsync and quota fixes, and a few targeted at error
      handling for corrupt metadata/fuzzing"
    
    * 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix lockdep warning on deadlock against an inode's log mutex
      Btrfs: detect corruption when non-root leaf has zero item
      Btrfs: check btree node's nritems
      btrfs: don't create or leak aliased root while cleaning up orphans
      Btrfs: fix em leak in find_first_block_group
      btrfs: do not background blkdev_put()
      Btrfs: clarify do_chunk_alloc()'s return value
      btrfs: fix fsfreeze hang caused by delayed iputs deal
      btrfs: update btrfs_space_info's bytes_may_use timely
      btrfs: divide btrfs_update_reserved_bytes() into two functions
      btrfs: use correct offset for reloc_inode in prealloc_file_extent_cluster()
      btrfs: qgroup: Fix qgroup incorrectness caused by log replay
      btrfs: relocation: Fix leaking qgroups numbers on data extents
      btrfs: qgroup: Refactor btrfs_qgroup_insert_dirty_extent()
      btrfs: waiting on qgroup rescan should not always be interruptible
      btrfs: properly track when rescan worker is running
      btrfs: flush_space: treat return value of do_chunk_alloc properly
      Btrfs: add ASSERT for block group's memory leak
      btrfs: backref: Fix soft lockup in __merge_refs function
      Btrfs: fix memory leak of reloc_root

commit 9e7cc91a6d18a4973c6d2cc104871439c9e94f3d
Author: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
Date:   Mon Aug 1 13:28:08 2016 +0800

    btrfs: fix fsfreeze hang caused by delayed iputs deal
    
    When running fstests generic/068, sometimes we got below deadlock:
      xfs_io          D ffff8800331dbb20     0  6697   6693 0x00000080
      ffff8800331dbb20 ffff88007acfc140 ffff880034d895c0 ffff8800331dc000
      ffff880032d243e8 fffffffeffffffff ffff880032d24400 0000000000000001
      ffff8800331dbb38 ffffffff816a9045 ffff880034d895c0 ffff8800331dbba8
      Call Trace:
      [<ffffffff816a9045>] schedule+0x35/0x80
      [<ffffffff816abab2>] rwsem_down_read_failed+0xf2/0x140
      [<ffffffff8118f5e1>] ? __filemap_fdatawrite_range+0xd1/0x100
      [<ffffffff8134f978>] call_rwsem_down_read_failed+0x18/0x30
      [<ffffffffa06631fc>] ? btrfs_alloc_block_rsv+0x2c/0xb0 [btrfs]
      [<ffffffff810d32b5>] percpu_down_read+0x35/0x50
      [<ffffffff81217dfc>] __sb_start_write+0x2c/0x40
      [<ffffffffa067f5d5>] start_transaction+0x2a5/0x4d0 [btrfs]
      [<ffffffffa067f857>] btrfs_join_transaction+0x17/0x20 [btrfs]
      [<ffffffffa068ba34>] btrfs_evict_inode+0x3c4/0x5d0 [btrfs]
      [<ffffffff81230a1a>] evict+0xba/0x1a0
      [<ffffffff812316b6>] iput+0x196/0x200
      [<ffffffffa06851d0>] btrfs_run_delayed_iputs+0x70/0xc0 [btrfs]
      [<ffffffffa067f1d8>] btrfs_commit_transaction+0x928/0xa80 [btrfs]
      [<ffffffffa0646df0>] btrfs_freeze+0x30/0x40 [btrfs]
      [<ffffffff81218040>] freeze_super+0xf0/0x190
      [<ffffffff81229275>] do_vfs_ioctl+0x4a5/0x5c0
      [<ffffffff81003176>] ? do_audit_syscall_entry+0x66/0x70
      [<ffffffff810038cf>] ? syscall_trace_enter_phase1+0x11f/0x140
      [<ffffffff81229409>] SyS_ioctl+0x79/0x90
      [<ffffffff81003c12>] do_syscall_64+0x62/0x110
      [<ffffffff816acbe1>] entry_SYSCALL64_slow_path+0x25/0x25
    
    >From this warning, freeze_super() already holds SB_FREEZE_FS, but
    btrfs_freeze() will call btrfs_commit_transaction() again, if
    btrfs_commit_transaction() finds that it has delayed iputs to handle,
    it'll start_transaction(), which will try to get SB_FREEZE_FS lock
    again, then deadlock occurs.
    
    The root cause is that in btrfs, sync_filesystem(sb) does not make
    sure all metadata is updated. There still maybe some codes adding
    delayed iputs, see below sample race window:
    
             CPU1                                  |         CPU2
    |-> freeze_super()                             |
        |-> sync_filesystem(sb);                   |
        |                                          |-> cleaner_kthread()
        |                                          |   |-> btrfs_delete_unused_bgs()
        |                                          |       |-> btrfs_remove_chunk()
        |                                          |           |-> btrfs_remove_block_group()
        |                                          |               |-> btrfs_add_delayed_iput()
        |                                          |
        |-> sb->s_writers.frozen = SB_FREEZE_FS;   |
        |-> sb_wait_write(sb, SB_FREEZE_FS);       |
        |   acquire SB_FREEZE_FS lock.             |
        |                                          |
        |-> btrfs_freeze()                         |
            |-> btrfs_commit_transaction()         |
                |-> btrfs_run_delayed_iputs()      |
                |   will handle delayed iputs,     |
                |   that means start_transaction() |
                |   will be called, which will try |
                |   to get SB_FREEZE_FS lock.      |
    
    To fix this issue, introduce a "int fs_frozen" to record internally whether
    fs has been frozen. If fs has been frozen, we can not handle delayed iputs.
    
    Signed-off-by: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add comment to btrfs_freeze ]
    Signed-off-by: David Sterba <dsterba@suse.com>
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 09cdff0d58e8..ec4154faab61 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1080,6 +1080,8 @@ struct btrfs_fs_info {
 	struct list_head pinned_chunks;
 
 	int creating_free_space_tree;
+	/* Used to record internally whether fs has been frozen */
+	int fs_frozen;
 };
 
 struct btrfs_subvolume_writers {

commit 18513091af9483ba84328d42092bd4d42a3c958f
Author: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
Date:   Mon Jul 25 15:51:40 2016 +0800

    btrfs: update btrfs_space_info's bytes_may_use timely
    
    This patch can fix some false ENOSPC errors, below test script can
    reproduce one false ENOSPC error:
            #!/bin/bash
            dd if=/dev/zero of=fs.img bs=$((1024*1024)) count=128
            dev=$(losetup --show -f fs.img)
            mkfs.btrfs -f -M $dev
            mkdir /tmp/mntpoint
            mount $dev /tmp/mntpoint
            cd /tmp/mntpoint
            xfs_io -f -c "falloc 0 $((64*1024*1024))" testfile
    
    Above script will fail for ENOSPC reason, but indeed fs still has free
    space to satisfy this request. Please see call graph:
    btrfs_fallocate()
    |-> btrfs_alloc_data_chunk_ondemand()
    |   bytes_may_use += 64M
    |-> btrfs_prealloc_file_range()
        |-> btrfs_reserve_extent()
            |-> btrfs_add_reserved_bytes()
            |   alloc_type is RESERVE_ALLOC_NO_ACCOUNT, so it does not
            |   change bytes_may_use, and bytes_reserved += 64M. Now
            |   bytes_may_use + bytes_reserved == 128M, which is greater
            |   than btrfs_space_info's total_bytes, false enospc occurs.
            |   Note, the bytes_may_use decrease operation will be done in
            |   end of btrfs_fallocate(), which is too late.
    
    Here is another simple case for buffered write:
                        CPU 1              |              CPU 2
                                           |
    |-> cow_file_range()                   |-> __btrfs_buffered_write()
        |-> btrfs_reserve_extent()         |   |
        |                                  |   |
        |                                  |   |
        |    .....                         |   |-> btrfs_check_data_free_space()
        |                                  |
        |                                  |
        |-> extent_clear_unlock_delalloc() |
    
    In CPU 1, btrfs_reserve_extent()->find_free_extent()->
    btrfs_add_reserved_bytes() do not decrease bytes_may_use, the decrease
    operation will be delayed to be done in extent_clear_unlock_delalloc().
    Assume in this case, btrfs_reserve_extent() reserved 128MB data, CPU2's
    btrfs_check_data_free_space() tries to reserve 100MB data space.
    If
            100MB > data_sinfo->total_bytes - data_sinfo->bytes_used -
                    data_sinfo->bytes_reserved - data_sinfo->bytes_pinned -
                    data_sinfo->bytes_readonly - data_sinfo->bytes_may_use
    btrfs_check_data_free_space() will try to allcate new data chunk or call
    btrfs_start_delalloc_roots(), or commit current transaction in order to
    reserve some free space, obviously a lot of work. But indeed it's not
    necessary as long as decreasing bytes_may_use timely, we still have
    free space, decreasing 128M from bytes_may_use.
    
    To fix this issue, this patch chooses to update bytes_may_use for both
    data and metadata in btrfs_add_reserved_bytes(). For compress path, real
    extent length may not be equal to file content length, so introduce a
    ram_bytes argument for btrfs_reserve_extent(), find_free_extent() and
    btrfs_add_reserved_bytes(), it's becasue bytes_may_use is increased by
    file content length. Then compress path can update bytes_may_use
    correctly. Also now we can discard RESERVE_ALLOC_NO_ACCOUNT, RESERVE_ALLOC
    and RESERVE_FREE.
    
    As we know, usually EXTENT_DO_ACCOUNTING is used for error path. In
    run_delalloc_nocow(), for inode marked as NODATACOW or extent marked as
    PREALLOC, we also need to update bytes_may_use, but can not pass
    EXTENT_DO_ACCOUNTING, because it also clears metadata reservation, so
    here we introduce EXTENT_CLEAR_DATA_RESV flag to indicate btrfs_clear_bit_hook()
    to update btrfs_space_info's bytes_may_use.
    
    Meanwhile __btrfs_prealloc_file_range() will call
    btrfs_free_reserved_data_space() internally for both sucessful and failed
    path, btrfs_prealloc_file_range()'s callers does not need to call
    btrfs_free_reserved_data_space() any more.
    
    Signed-off-by: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index acc6850a118f..09cdff0d58e8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2579,7 +2579,7 @@ int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root,
 				   u64 root_objectid, u64 owner, u64 offset,
 				   struct btrfs_key *ins);
-int btrfs_reserve_extent(struct btrfs_root *root, u64 num_bytes,
+int btrfs_reserve_extent(struct btrfs_root *root, u64 ram_bytes, u64 num_bytes,
 			 u64 min_alloc_size, u64 empty_size, u64 hint_byte,
 			 struct btrfs_key *ins, int is_data, int delalloc);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,

commit d2c609b834d62f1e91f1635a27dca29f7806d3d6
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Aug 15 12:10:33 2016 -0400

    btrfs: properly track when rescan worker is running
    
    The qgroup_flags field is overloaded such that it reflects the on-disk
    status of qgroups and the runtime state.  The BTRFS_QGROUP_STATUS_FLAG_RESCAN
    flag is used to indicate that a rescan operation is in progress, but if
    the file system is unmounted while a rescan is running, the rescan
    operation is paused.  If the file system is then mounted read-only,
    the flag will still be present but the rescan operation will not have
    been resumed.  When we go to umount, btrfs_qgroup_wait_for_completion
    will see the flag and interpret it to mean that the rescan worker is
    still running and will wait for a completion that will never come.
    
    This patch uses a separate flag to indicate when the worker is
    running.  The locking and state surrounding the qgroup rescan worker
    needs a lot of attention beyond this patch but this is enough to
    avoid a hung umount.
    
    Cc: <stable@vger.kernel.org> # v4.4+
    Signed-off-by; Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f66a0ba9a2a9..acc6850a118f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1028,6 +1028,7 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *qgroup_rescan_workers;
 	struct completion qgroup_rescan_completion;
 	struct btrfs_work qgroup_rescan_work;
+	bool qgroup_rescan_running;	/* protected by qgroup_rescan_lock */
 
 	/* filesystem state */
 	unsigned long fs_state;

commit d58b0d980f0b1c27204da0e05537b606da45a07f
Merge: 3a303258ef40 42049bf60db4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 4 19:56:16 2016 -0400

    Merge branch 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull more btrfs updates from Chris Mason:
     "This is part two of my btrfs pull, which is some cleanups and a batch
      of fixes.
    
      Most of the code here is from Jeff Mahoney, making the pointers we
      pass around internally more consistent and less confusing overall.  I
      noticed a small problem right before I sent this out yesterday, so I
      fixed it up and re-tested overnight"
    
    * 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (40 commits)
      Btrfs: fix __MAX_CSUM_ITEMS
      btrfs: btrfs_abort_transaction, drop root parameter
      btrfs: add btrfs_trans_handle->fs_info pointer
      btrfs: btrfs_relocate_chunk pass extent_root to btrfs_end_transaction
      btrfs: convert nodesize macros to static inlines
      btrfs: introduce BTRFS_MAX_ITEM_SIZE
      btrfs: cleanup, remove prototype for btrfs_find_root_ref
      btrfs: copy_to_sk drop unused root parameter
      btrfs: simpilify btrfs_subvol_inherit_props
      btrfs: tests, use BTRFS_FS_STATE_DUMMY_FS_INFO instead of dummy root
      btrfs: tests, require fs_info for root
      btrfs: tests, move initialization into tests/
      btrfs: btrfs_test_opt and friends should take a btrfs_fs_info
      btrfs: prefix fsid to all trace events
      btrfs: plumb fs_info into btrfs_work
      btrfs: remove obsolete part of comment in statfs
      btrfs: hide test-only member under ifdef
      btrfs: Ratelimit "no csum found" info message
      btrfs: Add ratelimit to btrfs printing
      Btrfs: fix unexpected balance crash due to BUG_ON
      ...

commit ba929b6646c5b87c7bb15cd8d3e51617725c983b
Merge: c9b95e5961c0 8b8b08cbfb90
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jul 31 21:27:32 2016 -0400

    Merge branch 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This pull is dedicated to Josef's enospc rework, which we've been
      testing for a few releases now.  It fixes some early enospc problems
      and is dramatically faster.
    
      This also includes an updated fix for the delalloc accounting that
      happens after a fault in copy_from_user.  My patch in v4.7 was almost
      but not quite enough"
    
    * 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix delalloc accounting after copy_from_user faults
      Btrfs: avoid deadlocks during reservations in btrfs_truncate_block
      Btrfs: use FLUSH_LIMIT for relocation in reserve_metadata_bytes
      Btrfs: fill relocation block rsv after allocation
      Btrfs: always use trans->block_rsv for orphans
      Btrfs: change how we calculate the global block rsv
      Btrfs: use root when checking need_async_flush
      Btrfs: don't bother kicking async if there's nothing to reclaim
      Btrfs: fix release reserved extents trace points
      Btrfs: add fsid to some tracepoints
      Btrfs: add tracepoints for flush events
      Btrfs: fix delalloc reservation amount tracepoint
      Btrfs: trace pinned extents
      Btrfs: introduce ticketed enospc infrastructure
      Btrfs: add tracepoint for adding block groups
      Btrfs: warn_on for unaccounted spaces
      Btrfs: change delayed reservation fallback behavior
      Btrfs: always reserve metadata for delalloc extents
      Btrfs: fix callers of btrfs_block_rsv_migrate
      Btrfs: add bytes_readonly to the spaceinfo at once

commit d05d7f40791ccbb6e543cc5dd6a6aa08fc71d635
Merge: 75a442efb1ca 17007f3994cd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 26 15:03:07 2016 -0700

    Merge branch 'for-4.8/core' of git://git.kernel.dk/linux-block
    
    Pull core block updates from Jens Axboe:
    
       - the big change is the cleanup from Mike Christie, cleaning up our
         uses of command types and modified flags.  This is what will throw
         some merge conflicts
    
       - regression fix for the above for btrfs, from Vincent
    
       - following up to the above, better packing of struct request from
         Christoph
    
       - a 2038 fix for blktrace from Arnd
    
       - a few trivial/spelling fixes from Bart Van Assche
    
       - a front merge check fix from Damien, which could cause issues on
         SMR drives
    
       - Atari partition fix from Gabriel
    
       - convert cfq to highres timers, since jiffies isn't granular enough
         for some devices these days.  From Jan and Jeff
    
       - CFQ priority boost fix idle classes, from me
    
       - cleanup series from Ming, improving our bio/bvec iteration
    
       - a direct issue fix for blk-mq from Omar
    
       - fix for plug merging not involving the IO scheduler, like we do for
         other types of merges.  From Tahsin
    
       - expose DAX type internally and through sysfs.  From Toshi and Yigal
    
    * 'for-4.8/core' of git://git.kernel.dk/linux-block: (76 commits)
      block: Fix front merge check
      block: do not merge requests without consulting with io scheduler
      block: Fix spelling in a source code comment
      block: expose QUEUE_FLAG_DAX in sysfs
      block: add QUEUE_FLAG_DAX for devices to advertise their DAX support
      Btrfs: fix comparison in __btrfs_map_block()
      block: atari: Return early for unsupported sector size
      Doc: block: Fix a typo in queue-sysfs.txt
      cfq-iosched: Charge at least 1 jiffie instead of 1 ns
      cfq-iosched: Fix regression in bonnie++ rewrite performance
      cfq-iosched: Convert slice_resid from u64 to s64
      block: Convert fifo_time from ulong to u64
      blktrace: avoid using timespec
      block/blk-cgroup.c: Declare local symbols static
      block/bio-integrity.c: Add #include "blk.h"
      block/partition-generic.c: Remove a set-but-not-used variable
      block: bio: kill BIO_MAX_SIZE
      cfq-iosched: temporarily boost queue priority for idle classes
      block: drbd: avoid to use BIO_MAX_SIZE
      block: bio: remove BIO_MAX_SECTORS
      ...

commit 66642832f06a4351e23cea6cf254967c227f8224
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Jun 10 18:19:25 2016 -0400

    btrfs: btrfs_abort_transaction, drop root parameter
    
    __btrfs_abort_transaction doesn't use its root parameter except to
    obtain an fs_info pointer.  We can obtain that from trans->root->fs_info
    for now and from trans->fs_info in a later patch.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 85e0b608b7c0..f66a0ba9a2a9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3379,23 +3379,23 @@ const char *btrfs_decode_error(int errno);
 
 __cold
 void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *root, const char *function,
+			       const char *function,
 			       unsigned int line, int errno);
 
 /*
  * Call btrfs_abort_transaction as early as possible when an error condition is
  * detected, that way the exact line number is reported.
  */
-#define btrfs_abort_transaction(trans, root, errno)		\
+#define btrfs_abort_transaction(trans, errno)		\
 do {								\
 	/* Report first abort since mount */			\
 	if (!test_and_set_bit(BTRFS_FS_STATE_TRANS_ABORTED,	\
-			&((root)->fs_info->fs_state))) {	\
+			&((trans)->fs_info->fs_state))) {	\
 		WARN(1, KERN_DEBUG				\
 		"BTRFS: Transaction aborted (error %d)\n",	\
 		(errno));					\
 	}							\
-	__btrfs_abort_transaction((trans), (root), __func__,	\
+	__btrfs_abort_transaction((trans), __func__,		\
 				  __LINE__, (errno));		\
 } while (0)
 

commit 1db1ff92b6ce2247999787480c2eeb63a1811e79
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 10:33:06 2016 -0400

    btrfs: convert nodesize macros to static inlines
    
    This patch converts the macros used to calculate various node
    size limits to static inlines.  That way we get type checking for free.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1d46ceec1fc0..85e0b608b7c0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -145,21 +145,6 @@ struct btrfs_header {
 	u8 level;
 } __attribute__ ((__packed__));
 
-#define BTRFS_NODEPTRS_PER_BLOCK(r) (((r)->nodesize - \
-				      sizeof(struct btrfs_header)) / \
-				     sizeof(struct btrfs_key_ptr))
-#define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
-#define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->nodesize))
-#define BTRFS_MAX_ITEM_SIZE(r) \
-	(BTRFS_LEAF_DATA_SIZE(r) - sizeof(struct btrfs_item))
-#define BTRFS_FILE_EXTENT_INLINE_DATA_START		\
-		(offsetof(struct btrfs_file_extent_item, disk_bytenr))
-#define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_MAX_ITEM_SIZE(r) - \
-					BTRFS_FILE_EXTENT_INLINE_DATA_START)
-#define BTRFS_MAX_XATTR_SIZE(r)	(BTRFS_MAX_ITEM_SIZE(r) - \
-				 sizeof(struct btrfs_dir_item))
-
-
 /*
  * this is a very generous portion of the super block, giving us
  * room to translate 14 chunks with 3 stripes each.
@@ -1261,6 +1246,39 @@ struct btrfs_root {
 	atomic_t qgroup_meta_rsv;
 };
 
+static inline u32 __BTRFS_LEAF_DATA_SIZE(u32 blocksize)
+{
+	return blocksize - sizeof(struct btrfs_header);
+}
+
+static inline u32 BTRFS_LEAF_DATA_SIZE(const struct btrfs_root *root)
+{
+	return __BTRFS_LEAF_DATA_SIZE(root->nodesize);
+}
+
+static inline u32 BTRFS_MAX_ITEM_SIZE(const struct btrfs_root *root)
+{
+	return BTRFS_LEAF_DATA_SIZE(root) - sizeof(struct btrfs_item);
+}
+
+static inline u32 BTRFS_NODEPTRS_PER_BLOCK(const struct btrfs_root *root)
+{
+	return BTRFS_LEAF_DATA_SIZE(root) / sizeof(struct btrfs_key_ptr);
+}
+
+#define BTRFS_FILE_EXTENT_INLINE_DATA_START		\
+		(offsetof(struct btrfs_file_extent_item, disk_bytenr))
+static inline u32 BTRFS_MAX_INLINE_DATA_SIZE(const struct btrfs_root *root)
+{
+	return BTRFS_MAX_ITEM_SIZE(root) -
+	       BTRFS_FILE_EXTENT_INLINE_DATA_START;
+}
+
+static inline u32 BTRFS_MAX_XATTR_SIZE(const struct btrfs_root *root)
+{
+	return BTRFS_MAX_ITEM_SIZE(root) - sizeof(struct btrfs_dir_item);
+}
+
 /*
  * Flags for mount options.
  *

commit 14a1e067b45614d6236e3c82b36f62caef44ac62
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 10:25:38 2016 -0400

    btrfs: introduce BTRFS_MAX_ITEM_SIZE
    
    We use BTRFS_LEAF_DATA_SIZE - sizeof(struct btrfs_item) in
    several places.  This introduces a BTRFS_MAX_ITEM_SIZE macro to do the
    same.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 950e4ee6b66e..1d46ceec1fc0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -150,13 +150,13 @@ struct btrfs_header {
 				     sizeof(struct btrfs_key_ptr))
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->nodesize))
+#define BTRFS_MAX_ITEM_SIZE(r) \
+	(BTRFS_LEAF_DATA_SIZE(r) - sizeof(struct btrfs_item))
 #define BTRFS_FILE_EXTENT_INLINE_DATA_START		\
 		(offsetof(struct btrfs_file_extent_item, disk_bytenr))
-#define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
-					sizeof(struct btrfs_item) - \
+#define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_MAX_ITEM_SIZE(r) - \
 					BTRFS_FILE_EXTENT_INLINE_DATA_START)
-#define BTRFS_MAX_XATTR_SIZE(r)	(BTRFS_LEAF_DATA_SIZE(r) - \
-				 sizeof(struct btrfs_item) -\
+#define BTRFS_MAX_XATTR_SIZE(r)	(BTRFS_MAX_ITEM_SIZE(r) - \
 				 sizeof(struct btrfs_dir_item))
 
 

commit 0c83b62e2222a8872f0b65d50540fdfa53b675ff
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 20:49:29 2016 -0400

    btrfs: cleanup, remove prototype for btrfs_find_root_ref
    
    The function isn't implemented anywhere.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 41d5ca986c0c..950e4ee6b66e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2888,9 +2888,6 @@ void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
 int btrfs_old_root_level(struct btrfs_root *root, u64 time_seq);
 
 /* root-item.c */
-int btrfs_find_root_ref(struct btrfs_root *tree_root,
-			struct btrfs_path *path,
-			u64 root_id, u64 ref_id);
 int btrfs_add_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *tree_root,
 		       u64 root_id, u64 ref_id, u64 dirid, u64 sequence,

commit f5ee5c9ac56cd328fcc915582f81226affebd81c
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 09:52:41 2016 -0400

    btrfs: tests, use BTRFS_FS_STATE_DUMMY_FS_INFO instead of dummy root
    
    Now that we have a dummy fs_info associated with each test that
    uses a root, we don't need the DUMMY_ROOT bit anymore.  This lets
    us make choices without needing an actual root like in e.g.
    btrfs_find_create_tree_block.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1cb84e01f2fd..41d5ca986c0c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1115,12 +1115,11 @@ struct btrfs_subvolume_writers {
 #define BTRFS_ROOT_REF_COWS		1
 #define BTRFS_ROOT_TRACK_DIRTY		2
 #define BTRFS_ROOT_IN_RADIX		3
-#define BTRFS_ROOT_DUMMY_ROOT		4
-#define BTRFS_ROOT_ORPHAN_ITEM_INSERTED	5
-#define BTRFS_ROOT_DEFRAG_RUNNING	6
-#define BTRFS_ROOT_FORCE_COW		7
-#define BTRFS_ROOT_MULTI_LOG_TASKS	8
-#define BTRFS_ROOT_DIRTY		9
+#define BTRFS_ROOT_ORPHAN_ITEM_INSERTED	4
+#define BTRFS_ROOT_DEFRAG_RUNNING	5
+#define BTRFS_ROOT_FORCE_COW		6
+#define BTRFS_ROOT_MULTI_LOG_TASKS	7
+#define BTRFS_ROOT_DIRTY		8
 
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
@@ -3613,13 +3612,13 @@ static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
 void btrfs_test_destroy_inode(struct inode *inode);
 #endif
 
-static inline int btrfs_test_is_dummy_root(struct btrfs_root *root)
+static inline int btrfs_is_testing(struct btrfs_fs_info *fs_info)
 {
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-	if (unlikely(test_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state)))
+	if (unlikely(test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO,
+			      &fs_info->fs_state)))
 		return 1;
 #endif
 	return 0;
 }
-
 #endif

commit 7c0260ee098db7a05fd68812b2e21ce2e19dfcf0
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Jun 20 14:14:09 2016 -0400

    btrfs: tests, require fs_info for root
    
    This allows the upcoming patchset to push nodesize and sectorsize into
    fs_info.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 61a53cca5963..1cb84e01f2fd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -117,6 +117,7 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 #define BTRFS_FS_STATE_REMOUNTING	1
 #define BTRFS_FS_STATE_TRANS_ABORTED	2
 #define BTRFS_FS_STATE_DEV_REPLACING	3
+#define BTRFS_FS_STATE_DUMMY_FS_INFO	4
 
 #define BTRFS_BACKREF_REV_MAX		256
 #define BTRFS_BACKREF_REV_SHIFT		56

commit 3cdde2240d4533ff71fbb8dc9c32d5d57d3cdeed
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Jun 9 21:38:35 2016 -0400

    btrfs: btrfs_test_opt and friends should take a btrfs_fs_info
    
    btrfs_test_opt and friends only use the root pointer to access
    the fs_info.  Let's pass the fs_info directly in preparation to
    eliminate similar patterns all over btrfs.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8627b7f26a60..61a53cca5963 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1301,21 +1301,21 @@ struct btrfs_root {
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
 #define btrfs_raw_test_opt(o, opt)	((o) & BTRFS_MOUNT_##opt)
-#define btrfs_test_opt(root, opt)	((root)->fs_info->mount_opt & \
+#define btrfs_test_opt(fs_info, opt)	((fs_info)->mount_opt & \
 					 BTRFS_MOUNT_##opt)
 
-#define btrfs_set_and_info(root, opt, fmt, args...)			\
+#define btrfs_set_and_info(fs_info, opt, fmt, args...)			\
 {									\
-	if (!btrfs_test_opt(root, opt))					\
-		btrfs_info(root->fs_info, fmt, ##args);			\
-	btrfs_set_opt(root->fs_info->mount_opt, opt);			\
+	if (!btrfs_test_opt(fs_info, opt))				\
+		btrfs_info(fs_info, fmt, ##args);			\
+	btrfs_set_opt(fs_info->mount_opt, opt);				\
 }
 
-#define btrfs_clear_and_info(root, opt, fmt, args...)			\
+#define btrfs_clear_and_info(fs_info, opt, fmt, args...)		\
 {									\
-	if (btrfs_test_opt(root, opt))					\
-		btrfs_info(root->fs_info, fmt, ##args);			\
-	btrfs_clear_opt(root->fs_info->mount_opt, opt);			\
+	if (btrfs_test_opt(fs_info, opt))				\
+		btrfs_info(fs_info, fmt, ##args);			\
+	btrfs_clear_opt(fs_info->mount_opt, opt);			\
 }
 
 #ifdef CONFIG_BTRFS_DEBUG
@@ -1323,9 +1323,9 @@ static inline int
 btrfs_should_fragment_free_space(struct btrfs_root *root,
 				 struct btrfs_block_group_cache *block_group)
 {
-	return (btrfs_test_opt(root, FRAGMENT_METADATA) &&
+	return (btrfs_test_opt(root->fs_info, FRAGMENT_METADATA) &&
 		block_group->flags & BTRFS_BLOCK_GROUP_METADATA) ||
-	       (btrfs_test_opt(root, FRAGMENT_DATA) &&
+	       (btrfs_test_opt(root->fs_info, FRAGMENT_DATA) &&
 		block_group->flags &  BTRFS_BLOCK_GROUP_DATA);
 }
 #endif

commit 05653ef38659edc46a886c9bda105e64edba6896
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jul 15 15:23:37 2016 +0200

    btrfs: hide test-only member under ifdef
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 83a6a931af09..8627b7f26a60 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1181,8 +1181,10 @@ struct btrfs_root {
 
 	u64 highest_objectid;
 
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 	/* only used with CONFIG_BTRFS_FS_RUN_SANITY_TESTS is enabled */
 	u64 alloc_bytenr;
+#endif
 
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;

commit f376df2b7da3a40f62f861a65efdd8c29fa1b877
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 25 13:25:56 2016 -0400

    Btrfs: add tracepoints for flush events
    
    We want to track when we're triggering flushing from our reservation code and
    what flushing is being done when we start flushing.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e04c9d6f21d..83a6a931af09 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2626,6 +2626,15 @@ enum btrfs_reserve_flush_enum {
 	BTRFS_RESERVE_FLUSH_ALL,
 };
 
+enum btrfs_flush_state {
+	FLUSH_DELAYED_ITEMS_NR	=	1,
+	FLUSH_DELAYED_ITEMS	=	2,
+	FLUSH_DELALLOC		=	3,
+	FLUSH_DELALLOC_WAIT	=	4,
+	ALLOC_CHUNK		=	5,
+	COMMIT_TRANS		=	6,
+};
+
 int btrfs_check_data_free_space(struct inode *inode, u64 start, u64 len);
 int btrfs_alloc_data_chunk_ondemand(struct inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);

commit 957780eb2788d8c218d539e19a85653f51a96dc1
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue May 17 13:30:55 2016 -0400

    Btrfs: introduce ticketed enospc infrastructure
    
    Our enospc flushing sucks.  It is born from a time where we were early
    enospc'ing constantly because multiple threads would race in for the same
    reservation and randomly starve other ones out.  So I came up with this solution
    to block any other reservations from happening while one guy tried to flush
    stuff to satisfy his reservation.  This gives us pretty good correctness, but
    completely crap latency.
    
    The solution I've come up with is ticketed reservations.  Basically we try to
    make our reservation, and if we can't we put a ticket on a list in order and
    kick off an async flusher thread.  This async flusher thread does the same old
    flushing we always did, just asynchronously.  As space is freed and added back
    to the space_info it checks and sees if we have any tickets that need
    satisfying, and adds space to the tickets and wakes up anything we've satisfied.
    
    Once the flusher thread stops making progress it wakes up all the current
    tickets and tells them to take a hike.
    
    There is a priority list for things that can't flush, since the async flusher
    could do anything we need to avoid deadlocks.  These guys get priority for
    having their reservation made, and will still do manual flushing themselves in
    case the async flusher isn't running.
    
    This patch gives us significantly better latencies.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fe16474fabf3..2e04c9d6f21d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -439,6 +439,8 @@ struct btrfs_space_info {
 	struct list_head list;
 	/* Protected by the spinlock 'lock'. */
 	struct list_head ro_bgs;
+	struct list_head priority_tickets;
+	struct list_head tickets;
 
 	struct rw_semaphore groups_sem;
 	/* for block groups in our same type */

commit 25d609f86d6808eb1f0e8a6cafc3edb4a2b5ae35
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 25 13:25:48 2016 -0400

    Btrfs: fix callers of btrfs_block_rsv_migrate
    
    So btrfs_block_rsv_migrate just unconditionally calls block_rsv_migrate_bytes.
    Not only this but it unconditionally changes the size of the block_rsv.  This
    isn't a bug strictly speaking, but it makes truncate block rsv's look funny
    because every time we migrate bytes over its size grows, even though we only
    want it to be a specific size.  So collapse this into one function that takes an
    update_size argument and make truncate and evict not update the size for
    consistency sake.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4274a7bfdaed..fe16474fabf3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2661,8 +2661,8 @@ int btrfs_block_rsv_refill(struct btrfs_root *root,
 			   struct btrfs_block_rsv *block_rsv, u64 min_reserved,
 			   enum btrfs_reserve_flush_enum flush);
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
-			    struct btrfs_block_rsv *dst_rsv,
-			    u64 num_bytes);
+			    struct btrfs_block_rsv *dst_rsv, u64 num_bytes,
+			    int update_size);
 int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_rsv *dest, u64 num_bytes,
 			     int min_factor);

commit 31b9655f439a26856edca0f3f8daa368a61f16d5
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Apr 11 17:37:40 2016 -0400

    Btrfs: track transid for delayed ref flushing
    
    Using the offwakecputime bpf script I noticed most of our time was spent waiting
    on the delayed ref throttling.  This is what is supposed to happen, but
    sometimes the transaction can commit and then we're waiting for throttling that
    doesn't matter anymore.  So change this stuff to be a little smarter by tracking
    the transid we were in when we initiated the throttling.  If the transaction we
    get is different then we can just bail out.  This resulted in a 50% speedup in
    my fs_mark test, and reduced the amount of time spent throttling by 60 seconds
    over the entire run (which is about 30 minutes).  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 101c3cfd3f7c..4274a7bfdaed 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2518,7 +2518,7 @@ void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
 int btrfs_async_run_delayed_refs(struct btrfs_root *root,
-				 unsigned long count, int wait);
+				 unsigned long count, u64 transid, int wait);
 int btrfs_lookup_data_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 bytenr,

commit 81a75f6781deb7a3b5274b4c683e327e5cb5b883
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:54 2016 -0500

    btrfs: use bio fields for op and flags
    
    The bio REQ_OP and bi_rw rq_flag_bits are now always setup, so there is
    no need to pass around the rq_flag_bits bits too. btrfs users should
    should access the bio insead.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 101c3cfd3f7c..4088d7f044e2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3091,7 +3091,7 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root,
 			     struct btrfs_root *parent_root,
 			     u64 new_dirid);
-int btrfs_merge_bio_hook(int rw, struct page *page, unsigned long offset,
+int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);

commit 42f31734eb7658fd01fb186d56312be869450a42
Merge: e73440868fde 0132761017e0
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 25 22:51:03 2016 +0200

    Merge branch 'cleanups-4.7' into for-chris-4.7-20160525

commit 0132761017e012ab4dc8584d679503f2ba26ca86
Author: Nicholas D Steeves <nsteeves@gmail.com>
Date:   Thu May 19 21:18:45 2016 -0400

    btrfs: fix string and comment grammatical issues and typos
    
    Signed-off-by: Nicholas D Steeves <nsteeves@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84a6a5b3384a..65e7a9fa881f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -186,7 +186,7 @@ static const int btrfs_csum_sizes[] = { 4 };
 /* four bytes for CRC32 */
 #define BTRFS_EMPTY_DIR_SIZE 0
 
-/* spefic to btrfs_map_block(), therefore not in include/linux/blk_types.h */
+/* specific to btrfs_map_block(), therefore not in include/linux/blk_types.h */
 #define REQ_GET_READ_MIRRORS	(1 << 30)
 
 #define BTRFS_FT_UNKNOWN	0
@@ -1221,7 +1221,7 @@ struct btrfs_space_info {
 	 * bytes_pinned does not reflect the bytes that will be pinned once the
 	 * delayed refs are flushed, so this counter is inc'ed every time we
 	 * call btrfs_free_extent so it is a realtime count of what will be
-	 * freed once the transaction is committed.  It will be zero'ed every
+	 * freed once the transaction is committed.  It will be zeroed every
 	 * time the transaction commits.
 	 */
 	struct percpu_counter total_bytes_pinned;
@@ -2392,7 +2392,7 @@ static inline void btrfs_init_map_token (struct btrfs_map_token *token)
 	token->kaddr = NULL;
 }
 
-/* some macros to generate set/get funcs for the struct fields.  This
+/* some macros to generate set/get functions for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple
  * one for u8:
  */

commit c315ef8d9db7f1a0ebd023a395ebdfde1c68057e
Merge: a88336d13c66 5f9a8a51d8b9
Author: Chris Mason <clm@fb.com>
Date:   Tue May 17 14:43:19 2016 -0700

    Merge branch 'for-chris-4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/fdmanana/linux into for-linus-4.7
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 680834ca0ad4e9827048d4bda1e38db69c3dd1e4
Merge: 36fac9e9ff20 14b05c510631
Author: David Sterba <dsterba@suse.com>
Date:   Mon May 16 15:46:29 2016 +0200

    Merge branch 'foreign/jeffm/uapi' into for-chris-4.7-20160516
    
    # Conflicts:
    #       include/uapi/linux/btrfs.h

commit 5ef64a3e757c94b2f2fc61465ef9603aaacaecff
Merge: 73d32ce21e17 e1860a772482
Author: David Sterba <dsterba@suse.com>
Date:   Mon May 16 15:46:24 2016 +0200

    Merge branch 'cleanups-4.7' into for-chris-4.7-20160516

commit f78c436c3931e7df713688028f2b4faf72bf9f2a
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 9 13:15:41 2016 +0100

    Btrfs: fix race between block group relocation and nocow writes
    
    Relocation of a block group waits for all existing tasks flushing
    dellaloc, starting direct IO writes and any ordered extents before
    starting the relocation process. However for direct IO writes that end
    up doing nocow (inode either has the flag nodatacow set or the write is
    against a prealloc extent) we have a short time window that allows for a
    race that makes relocation proceed without waiting for the direct IO
    write to complete first, resulting in data loss after the relocation
    finishes. This is illustrated by the following diagram:
    
               CPU 1                                     CPU 2
    
     btrfs_relocate_block_group(bg X)
    
                                                   direct IO write starts against
                                                   an extent in block group X
                                                   using nocow mode (inode has the
                                                   nodatacow flag or the write is
                                                   for a prealloc extent)
    
                                                   btrfs_direct_IO()
                                                     btrfs_get_blocks_direct()
                                                       --> can_nocow_extent() returns 1
    
       btrfs_inc_block_group_ro(bg X)
         --> turns block group into RO mode
    
       btrfs_wait_ordered_roots()
         --> returns and does not know about
             the DIO write happening at CPU 2
             (the task there has not created
              yet an ordered extent)
    
       relocate_block_group(bg X)
         --> rc->stage == MOVE_DATA_EXTENTS
    
         find_next_extent()
           --> returns extent that the DIO
               write is going to write to
    
         relocate_data_extent()
    
           relocate_file_extent_cluster()
    
             --> reads the extent from disk into
                 pages belonging to the relocation
                 inode and dirties them
    
                                                       --> creates DIO ordered extent
    
                                                     btrfs_submit_direct()
                                                       --> submits bio against a location
                                                           on disk obtained from an extent
                                                           map before the relocation started
    
       btrfs_wait_ordered_range()
         --> writes all the pages read before
             to disk (belonging to the
             relocation inode)
    
       relocation finishes
    
                                                     bio completes and wrote new data
                                                     to the old location of the block
                                                     group
    
    So fix this by tracking the number of nocow writers for a block group and
    make sure relocation waits for that number to go down to 0 before starting
    to move the extents.
    
    The same race can also happen with buffered writes in nocow mode since the
    patch I recently made titled "Btrfs: don't do unnecessary delalloc flushes
    when relocating", because we are no longer flushing all delalloc which
    served as a synchonization mechanism (due to page locking) and ensured
    the ordered extents for nocow buffered writes were created before we
    called btrfs_wait_ordered_roots(). The race with direct IO writes in nocow
    mode existed before that patch (no pages are locked or used during direct
    IO) and that fixed only races with direct IO writes that do cow.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 90e70e21e479..7ae758685c7b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1419,6 +1419,16 @@ struct btrfs_block_group_cache {
 	 */
 	atomic_t reservations;
 
+	/*
+	 * Incremented while holding the spinlock *lock* by a task checking if
+	 * it can perform a nocow write (incremented if the value for the *ro*
+	 * field is 0). Decremented by such tasks once they create an ordered
+	 * extent or before that if some error happens before reaching that step.
+	 * This is to prevent races between block group relocation and nocow
+	 * writes through direct IO.
+	 */
+	atomic_t nocow_writers;
+
 	/* Lock for free space tree operations. */
 	struct mutex free_space_lock;
 
@@ -3513,6 +3523,9 @@ int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans,
 void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
 					 const u64 start);
 void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);
+bool btrfs_inc_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
+void btrfs_dec_nocow_writers(struct btrfs_fs_info *fs_info, u64 bytenr);
+void btrfs_wait_nocow_writers(struct btrfs_block_group_cache *bg);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);

commit 9cfa3e34e20e6798a671236000d9e97c8aa5d318
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Apr 26 15:39:32 2016 +0100

    Btrfs: don't do unnecessary delalloc flushes when relocating
    
    Before we start the actual relocation process of a block group, we do
    calls to flush delalloc of all inodes and then wait for ordered extents
    to complete. However we do these flush calls just to make sure we don't
    race with concurrent tasks that have actually already started to run
    delalloc and have allocated an extent from the block group we want to
    relocate, right before we set it to readonly mode, but have not yet
    created the respective ordered extents. The flush calls make us wait
    for such concurrent tasks because they end up calling
    filemap_fdatawrite_range() (through btrfs_start_delalloc_roots() ->
    __start_delalloc_inodes() -> btrfs_alloc_delalloc_work() ->
    btrfs_run_delalloc_work()) which ends up serializing us with those tasks
    due to attempts to lock the same pages (and the delalloc flush procedure
    calls the allocator and creates the ordered extents before unlocking the
    pages).
    
    These flushing calls not only make us waste time (cpu, IO) but also reduce
    the chances of writing larger extents (applications might be writing to
    contiguous ranges and we flush before they finish dirtying the whole
    ranges).
    
    So make sure we don't flush delalloc and just wait for concurrent tasks
    that have already started flushing delalloc and have allocated an extent
    from the block group we are about to relocate.
    
    This change also ends up fixing a race with direct IO writes that makes
    relocation not wait for direct IO ordered extents. This race is
    illustrated by the following diagram:
    
            CPU 1                                       CPU 2
    
     btrfs_relocate_block_group(bg X)
    
                                               starts direct IO write,
                                               target inode currently has no
                                               ordered extents ongoing nor
                                               dirty pages (delalloc regions),
                                               therefore the root for our inode
                                               is not in the list
                                               fs_info->ordered_roots
    
                                               btrfs_direct_IO()
                                                 __blockdev_direct_IO()
                                                   btrfs_get_blocks_direct()
                                                     btrfs_lock_extent_direct()
                                                       locks range in the io tree
                                                     btrfs_new_extent_direct()
                                                       btrfs_reserve_extent()
                                                         --> extent allocated
                                                             from bg X
    
       btrfs_inc_block_group_ro(bg X)
    
       btrfs_start_delalloc_roots()
         __start_delalloc_inodes()
           --> does nothing, no dealloc ranges
               in the inode's io tree so the
               inode's root is not in the list
               fs_info->delalloc_roots
    
       btrfs_wait_ordered_roots()
         --> does not find the inode's root in the
             list fs_info->ordered_roots
    
         --> ends up not waiting for the direct IO
             write started by the task at CPU 2
    
       relocate_block_group(rc->stage ==
         MOVE_DATA_EXTENTS)
    
         prepare_to_relocate()
           btrfs_commit_transaction()
    
         iterates the extent tree, using its
         commit root and moves extents into new
         locations
    
                                                       btrfs_add_ordered_extent_dio()
                                                         --> now a ordered extent is
                                                             created and added to the
                                                             list root->ordered_extents
                                                             and the root added to the
                                                             list fs_info->ordered_roots
                                                         --> this is too late and the
                                                             task at CPU 1 already
                                                             started the relocation
    
         btrfs_commit_transaction()
    
                                                       btrfs_finish_ordered_io()
                                                         btrfs_alloc_reserved_file_extent()
                                                           --> adds delayed data reference
                                                               for the extent allocated
                                                               from bg X
    
       relocate_block_group(rc->stage ==
         UPDATE_DATA_PTRS)
    
         prepare_to_relocate()
           btrfs_commit_transaction()
             --> delayed refs are run, so an extent
                 item for the allocated extent from
                 bg X is added to extent tree
             --> commit roots are switched, so the
                 next scan in the extent tree will
                 see the extent item
    
         sees the extent in the extent tree
    
    When this happens the relocation produces the following warning when it
    finishes:
    
    [ 7260.832836] ------------[ cut here ]------------
    [ 7260.834653] WARNING: CPU: 5 PID: 6765 at fs/btrfs/relocation.c:4318 btrfs_relocate_block_group+0x245/0x2a1 [btrfs]()
    [ 7260.838268] Modules linked in: btrfs crc32c_generic xor ppdev raid6_pq psmouse sg acpi_cpufreq evdev i2c_piix4 tpm_tis serio_raw tpm i2c_core pcspkr parport_pc
    [ 7260.850935] CPU: 5 PID: 6765 Comm: btrfs Not tainted 4.5.0-rc6-btrfs-next-28+ #1
    [ 7260.852998] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [ 7260.852998]  0000000000000000 ffff88020bf57bc0 ffffffff812648b3 0000000000000000
    [ 7260.852998]  0000000000000009 ffff88020bf57bf8 ffffffff81051608 ffffffffa03c1b2d
    [ 7260.852998]  ffff8800b2bbb800 0000000000000000 ffff8800b17bcc58 ffff8800399dd000
    [ 7260.852998] Call Trace:
    [ 7260.852998]  [<ffffffff812648b3>] dump_stack+0x67/0x90
    [ 7260.852998]  [<ffffffff81051608>] warn_slowpath_common+0x99/0xb2
    [ 7260.852998]  [<ffffffffa03c1b2d>] ? btrfs_relocate_block_group+0x245/0x2a1 [btrfs]
    [ 7260.852998]  [<ffffffff810516d4>] warn_slowpath_null+0x1a/0x1c
    [ 7260.852998]  [<ffffffffa03c1b2d>] btrfs_relocate_block_group+0x245/0x2a1 [btrfs]
    [ 7260.852998]  [<ffffffffa039d9de>] btrfs_relocate_chunk.isra.29+0x66/0xdb [btrfs]
    [ 7260.852998]  [<ffffffffa039f314>] btrfs_balance+0xde1/0xe4e [btrfs]
    [ 7260.852998]  [<ffffffff8127d671>] ? debug_smp_processor_id+0x17/0x19
    [ 7260.852998]  [<ffffffffa03a9583>] btrfs_ioctl_balance+0x255/0x2d3 [btrfs]
    [ 7260.852998]  [<ffffffffa03ac96a>] btrfs_ioctl+0x11e0/0x1dff [btrfs]
    [ 7260.852998]  [<ffffffff811451df>] ? handle_mm_fault+0x443/0xd63
    [ 7260.852998]  [<ffffffff81491817>] ? _raw_spin_unlock+0x31/0x44
    [ 7260.852998]  [<ffffffff8108b36a>] ? arch_local_irq_save+0x9/0xc
    [ 7260.852998]  [<ffffffff811876ab>] vfs_ioctl+0x18/0x34
    [ 7260.852998]  [<ffffffff81187cb2>] do_vfs_ioctl+0x550/0x5be
    [ 7260.852998]  [<ffffffff81190c30>] ? __fget_light+0x4d/0x71
    [ 7260.852998]  [<ffffffff81187d77>] SyS_ioctl+0x57/0x79
    [ 7260.852998]  [<ffffffff81492017>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [ 7260.893268] ---[ end trace eb7803b24ebab8ad ]---
    
    This is because at the end of the first stage, in relocate_block_group(),
    we commit the current transaction, which makes delayed refs run, the
    commit roots are switched and so the second stage will find the extent
    item that the ordered extent added to the delayed refs. But this extent
    was not moved (ordered extent completed after first stage finished), so
    at the end of the relocation our block group item still has a positive
    used bytes counter, triggering a warning at the end of
    btrfs_relocate_block_group(). Later on when trying to read the extent
    contents from disk we hit a BUG_ON() due to the inability to map a block
    with a logical address that belongs to the block group we relocated and
    is no longer valid, resulting in the following trace:
    
    [ 7344.885290] BTRFS critical (device sdi): unable to find logical 12845056 len 4096
    [ 7344.887518] ------------[ cut here ]------------
    [ 7344.888431] kernel BUG at fs/btrfs/inode.c:1833!
    [ 7344.888431] invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
    [ 7344.888431] Modules linked in: btrfs crc32c_generic xor ppdev raid6_pq psmouse sg acpi_cpufreq evdev i2c_piix4 tpm_tis serio_raw tpm i2c_core pcspkr parport_pc
    [ 7344.888431] CPU: 0 PID: 6831 Comm: od Tainted: G        W       4.5.0-rc6-btrfs-next-28+ #1
    [ 7344.888431] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [ 7344.888431] task: ffff880215818600 ti: ffff880204684000 task.ti: ffff880204684000
    [ 7344.888431] RIP: 0010:[<ffffffffa037c88c>]  [<ffffffffa037c88c>] btrfs_merge_bio_hook+0x54/0x6b [btrfs]
    [ 7344.888431] RSP: 0018:ffff8802046878f0  EFLAGS: 00010282
    [ 7344.888431] RAX: 00000000ffffffea RBX: 0000000000001000 RCX: 0000000000000001
    [ 7344.888431] RDX: ffff88023ec0f950 RSI: ffffffff8183b638 RDI: 00000000ffffffff
    [ 7344.888431] RBP: ffff880204687908 R08: 0000000000000001 R09: 0000000000000000
    [ 7344.888431] R10: ffff880204687770 R11: ffffffff82f2d52d R12: 0000000000001000
    [ 7344.888431] R13: ffff88021afbfee8 R14: 0000000000006208 R15: ffff88006cd199b0
    [ 7344.888431] FS:  00007f1f9e1d6700(0000) GS:ffff88023ec00000(0000) knlGS:0000000000000000
    [ 7344.888431] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 7344.888431] CR2: 00007f1f9dc8cb60 CR3: 000000023e3b6000 CR4: 00000000000006f0
    [ 7344.888431] Stack:
    [ 7344.888431]  0000000000001000 0000000000001000 ffff880204687b98 ffff880204687950
    [ 7344.888431]  ffffffffa0395c8f ffffea0004d64d48 0000000000000000 0000000000001000
    [ 7344.888431]  ffffea0004d64d48 0000000000001000 0000000000000000 0000000000000000
    [ 7344.888431] Call Trace:
    [ 7344.888431]  [<ffffffffa0395c8f>] submit_extent_page+0xf5/0x16f [btrfs]
    [ 7344.888431]  [<ffffffffa03970ac>] __do_readpage+0x4a0/0x4f1 [btrfs]
    [ 7344.888431]  [<ffffffffa039680d>] ? btrfs_create_repair_bio+0xcb/0xcb [btrfs]
    [ 7344.888431]  [<ffffffffa037eeb4>] ? btrfs_writepage_start_hook+0xbc/0xbc [btrfs]
    [ 7344.888431]  [<ffffffff8108df55>] ? trace_hardirqs_on+0xd/0xf
    [ 7344.888431]  [<ffffffffa039728c>] __do_contiguous_readpages.constprop.26+0xc2/0xe4 [btrfs]
    [ 7344.888431]  [<ffffffffa037eeb4>] ? btrfs_writepage_start_hook+0xbc/0xbc [btrfs]
    [ 7344.888431]  [<ffffffffa039739b>] __extent_readpages.constprop.25+0xed/0x100 [btrfs]
    [ 7344.888431]  [<ffffffff81129d24>] ? lru_cache_add+0xe/0x10
    [ 7344.888431]  [<ffffffffa0397ea8>] extent_readpages+0x160/0x1aa [btrfs]
    [ 7344.888431]  [<ffffffffa037eeb4>] ? btrfs_writepage_start_hook+0xbc/0xbc [btrfs]
    [ 7344.888431]  [<ffffffff8115daad>] ? alloc_pages_current+0xa9/0xcd
    [ 7344.888431]  [<ffffffffa037cdc9>] btrfs_readpages+0x1f/0x21 [btrfs]
    [ 7344.888431]  [<ffffffff81128316>] __do_page_cache_readahead+0x168/0x1fc
    [ 7344.888431]  [<ffffffff811285a0>] ondemand_readahead+0x1f6/0x207
    [ 7344.888431]  [<ffffffff811285a0>] ? ondemand_readahead+0x1f6/0x207
    [ 7344.888431]  [<ffffffff8111cf34>] ? pagecache_get_page+0x2b/0x154
    [ 7344.888431]  [<ffffffff8112870e>] page_cache_sync_readahead+0x3d/0x3f
    [ 7344.888431]  [<ffffffff8111dbf7>] generic_file_read_iter+0x197/0x4e1
    [ 7344.888431]  [<ffffffff8117773a>] __vfs_read+0x79/0x9d
    [ 7344.888431]  [<ffffffff81178050>] vfs_read+0x8f/0xd2
    [ 7344.888431]  [<ffffffff81178a38>] SyS_read+0x50/0x7e
    [ 7344.888431]  [<ffffffff81492017>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [ 7344.888431] Code: 8d 4d e8 45 31 c9 45 31 c0 48 8b 00 48 c1 e2 09 48 8b 80 80 fc ff ff 4c 89 65 e8 48 8b b8 f0 01 00 00 e8 1d 42 02 00 85 c0 79 02 <0f> 0b 4c 0
    [ 7344.888431] RIP  [<ffffffffa037c88c>] btrfs_merge_bio_hook+0x54/0x6b [btrfs]
    [ 7344.888431]  RSP <ffff8802046878f0>
    [ 7344.970544] ---[ end trace eb7803b24ebab8ae ]---
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84a6a5b3384a..90e70e21e479 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1408,6 +1408,17 @@ struct btrfs_block_group_cache {
 
 	struct btrfs_io_ctl io_ctl;
 
+	/*
+	 * Incremented when doing extent allocations and holding a read lock
+	 * on the space_info's groups_sem semaphore.
+	 * Decremented when an ordered extent that represents an IO against this
+	 * block group's range is created (after it's added to its inode's
+	 * root's list of ordered extents) or immediately after the allocation
+	 * if it's a metadata extent or fallocate extent (for these cases we
+	 * don't create ordered extents).
+	 */
+	atomic_t reservations;
+
 	/* Lock for free space tree operations. */
 	struct mutex free_space_lock;
 
@@ -3499,6 +3510,9 @@ int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,
 				       struct btrfs_root *root);
 int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans,
 				       struct btrfs_root *root);
+void btrfs_dec_block_group_reservations(struct btrfs_fs_info *fs_info,
+					 const u64 start);
+void btrfs_wait_block_group_reservations(struct btrfs_block_group_cache *bg);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);

commit db6711600e27c885aed89751f04e727f3af26715
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Apr 1 16:14:29 2016 -0400

    btrfs: uapi/linux/btrfs_tree.h migration, item types and defines
    
    The BTRFS_IOC_SEARCH_TREE ioctl returns file system items directly
    to userspace.  In order to decode them, full type information is required.
    
    Create a new header, btrfs_tree to contain these since most users won't
    need them.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 89f36b6176b9..cf34fb58874c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -33,6 +33,7 @@
 #include <asm/kmap_types.h>
 #include <linux/pagemap.h>
 #include <linux/btrfs.h>
+#include <linux/btrfs_tree.h>
 #include <linux/workqueue.h>
 #include <linux/security.h>
 #include <linux/sizes.h>
@@ -64,98 +65,6 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_COMPAT_EXTENT_TREE_V0
 
-/* holds pointers to all of the tree roots */
-#define BTRFS_ROOT_TREE_OBJECTID 1ULL
-
-/* stores information about which extents are in use, and reference counts */
-#define BTRFS_EXTENT_TREE_OBJECTID 2ULL
-
-/*
- * chunk tree stores translations from logical -> physical block numbering
- * the super block points to the chunk tree
- */
-#define BTRFS_CHUNK_TREE_OBJECTID 3ULL
-
-/*
- * stores information about which areas of a given device are in use.
- * one per device.  The tree of tree roots points to the device tree
- */
-#define BTRFS_DEV_TREE_OBJECTID 4ULL
-
-/* one per subvolume, storing files and directories */
-#define BTRFS_FS_TREE_OBJECTID 5ULL
-
-/* directory objectid inside the root tree */
-#define BTRFS_ROOT_TREE_DIR_OBJECTID 6ULL
-
-/* holds checksums of all the data extents */
-#define BTRFS_CSUM_TREE_OBJECTID 7ULL
-
-/* holds quota configuration and tracking */
-#define BTRFS_QUOTA_TREE_OBJECTID 8ULL
-
-/* for storing items that use the BTRFS_UUID_KEY* types */
-#define BTRFS_UUID_TREE_OBJECTID 9ULL
-
-/* tracks free space in block groups. */
-#define BTRFS_FREE_SPACE_TREE_OBJECTID 10ULL
-
-/* device stats in the device tree */
-#define BTRFS_DEV_STATS_OBJECTID 0ULL
-
-/* for storing balance parameters in the root tree */
-#define BTRFS_BALANCE_OBJECTID -4ULL
-
-/* orhpan objectid for tracking unlinked/truncated files */
-#define BTRFS_ORPHAN_OBJECTID -5ULL
-
-/* does write ahead logging to speed up fsyncs */
-#define BTRFS_TREE_LOG_OBJECTID -6ULL
-#define BTRFS_TREE_LOG_FIXUP_OBJECTID -7ULL
-
-/* for space balancing */
-#define BTRFS_TREE_RELOC_OBJECTID -8ULL
-#define BTRFS_DATA_RELOC_TREE_OBJECTID -9ULL
-
-/*
- * extent checksums all have this objectid
- * this allows them to share the logging tree
- * for fsyncs
- */
-#define BTRFS_EXTENT_CSUM_OBJECTID -10ULL
-
-/* For storing free space cache */
-#define BTRFS_FREE_SPACE_OBJECTID -11ULL
-
-/*
- * The inode number assigned to the special inode for storing
- * free ino cache
- */
-#define BTRFS_FREE_INO_OBJECTID -12ULL
-
-/* dummy objectid represents multiple objectids */
-#define BTRFS_MULTIPLE_OBJECTIDS -255ULL
-
-/*
- * All files have objectids in this range.
- */
-#define BTRFS_FIRST_FREE_OBJECTID 256ULL
-#define BTRFS_LAST_FREE_OBJECTID -256ULL
-#define BTRFS_FIRST_CHUNK_TREE_OBJECTID 256ULL
-
-
-/*
- * the device items go into the chunk tree.  The key is in the form
- * [ 1 BTRFS_DEV_ITEM_KEY device_id ]
- */
-#define BTRFS_DEV_ITEMS_OBJECTID 1ULL
-
-#define BTRFS_BTREE_INODE_OBJECTID 1
-
-#define BTRFS_EMPTY_SUBVOL_DIR_OBJECTID 2
-
-#define BTRFS_DEV_REPLACE_DEVID 0ULL
-
 /*
  * the max metadata block size.  This limit is somewhat artificial,
  * but the memmove costs go through the roof for larger blocks.
@@ -175,12 +84,6 @@ struct btrfs_ordered_sum;
  */
 #define BTRFS_LINK_MAX 65535U
 
-/* 32 bytes in various csum fields */
-#define BTRFS_CSUM_SIZE 32
-
-/* csum types */
-#define BTRFS_CSUM_TYPE_CRC32	0
-
 static const int btrfs_csum_sizes[] = { 4 };
 
 /* four bytes for CRC32 */
@@ -189,17 +92,6 @@ static const int btrfs_csum_sizes[] = { 4 };
 /* spefic to btrfs_map_block(), therefore not in include/linux/blk_types.h */
 #define REQ_GET_READ_MIRRORS	(1 << 30)
 
-#define BTRFS_FT_UNKNOWN	0
-#define BTRFS_FT_REG_FILE	1
-#define BTRFS_FT_DIR		2
-#define BTRFS_FT_CHRDEV		3
-#define BTRFS_FT_BLKDEV		4
-#define BTRFS_FT_FIFO		5
-#define BTRFS_FT_SOCK		6
-#define BTRFS_FT_SYMLINK	7
-#define BTRFS_FT_XATTR		8
-#define BTRFS_FT_MAX		9
-
 /* ioprio of readahead is set to idle */
 #define BTRFS_IOPRIO_READA (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_IDLE, 0))
 
@@ -207,138 +99,10 @@ static const int btrfs_csum_sizes[] = { 4 };
 
 #define BTRFS_MAX_EXTENT_SIZE SZ_128M
 
-/*
- * The key defines the order in the tree, and so it also defines (optimal)
- * block layout.
- *
- * objectid corresponds to the inode number.
- *
- * type tells us things about the object, and is a kind of stream selector.
- * so for a given inode, keys with type of 1 might refer to the inode data,
- * type of 2 may point to file data in the btree and type == 3 may point to
- * extents.
- *
- * offset is the starting byte offset for this key in the stream.
- *
- * btrfs_disk_key is in disk byte order.  struct btrfs_key is always
- * in cpu native order.  Otherwise they are identical and their sizes
- * should be the same (ie both packed)
- */
-struct btrfs_disk_key {
-	__le64 objectid;
-	u8 type;
-	__le64 offset;
-} __attribute__ ((__packed__));
-
-struct btrfs_key {
-	u64 objectid;
-	u8 type;
-	u64 offset;
-} __attribute__ ((__packed__));
-
 struct btrfs_mapping_tree {
 	struct extent_map_tree map_tree;
 };
 
-struct btrfs_dev_item {
-	/* the internal btrfs device id */
-	__le64 devid;
-
-	/* size of the device */
-	__le64 total_bytes;
-
-	/* bytes used */
-	__le64 bytes_used;
-
-	/* optimal io alignment for this device */
-	__le32 io_align;
-
-	/* optimal io width for this device */
-	__le32 io_width;
-
-	/* minimal io size for this device */
-	__le32 sector_size;
-
-	/* type and info about this device */
-	__le64 type;
-
-	/* expected generation for this device */
-	__le64 generation;
-
-	/*
-	 * starting byte of this partition on the device,
-	 * to allow for stripe alignment in the future
-	 */
-	__le64 start_offset;
-
-	/* grouping information for allocation decisions */
-	__le32 dev_group;
-
-	/* seek speed 0-100 where 100 is fastest */
-	u8 seek_speed;
-
-	/* bandwidth 0-100 where 100 is fastest */
-	u8 bandwidth;
-
-	/* btrfs generated uuid for this device */
-	u8 uuid[BTRFS_UUID_SIZE];
-
-	/* uuid of FS who owns this device */
-	u8 fsid[BTRFS_UUID_SIZE];
-} __attribute__ ((__packed__));
-
-struct btrfs_stripe {
-	__le64 devid;
-	__le64 offset;
-	u8 dev_uuid[BTRFS_UUID_SIZE];
-} __attribute__ ((__packed__));
-
-struct btrfs_chunk {
-	/* size of this chunk in bytes */
-	__le64 length;
-
-	/* objectid of the root referencing this chunk */
-	__le64 owner;
-
-	__le64 stripe_len;
-	__le64 type;
-
-	/* optimal io alignment for this chunk */
-	__le32 io_align;
-
-	/* optimal io width for this chunk */
-	__le32 io_width;
-
-	/* minimal io size for this chunk */
-	__le32 sector_size;
-
-	/* 2^16 stripes is quite a lot, a second limit is the size of a single
-	 * item in the btree
-	 */
-	__le16 num_stripes;
-
-	/* sub stripes only matter for raid10 */
-	__le16 sub_stripes;
-	struct btrfs_stripe stripe;
-	/* additional stripes go here */
-} __attribute__ ((__packed__));
-
-#define BTRFS_FREE_SPACE_EXTENT	1
-#define BTRFS_FREE_SPACE_BITMAP	2
-
-struct btrfs_free_space_entry {
-	__le64 offset;
-	__le64 bytes;
-	u8 type;
-} __attribute__ ((__packed__));
-
-struct btrfs_free_space_header {
-	struct btrfs_disk_key location;
-	__le64 generation;
-	__le64 num_entries;
-	__le64 num_bitmaps;
-} __attribute__ ((__packed__));
-
 static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 {
 	BUG_ON(num_stripes == 0);
@@ -346,9 +110,6 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 		sizeof(struct btrfs_stripe) * (num_stripes - 1);
 }
 
-#define BTRFS_HEADER_FLAG_WRITTEN	(1ULL << 0)
-#define BTRFS_HEADER_FLAG_RELOC		(1ULL << 1)
-
 /*
  * File system states
  */
@@ -357,13 +118,6 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 #define BTRFS_FS_STATE_TRANS_ABORTED	2
 #define BTRFS_FS_STATE_DEV_REPLACING	3
 
-/* Super block flags */
-/* Errors detected */
-#define BTRFS_SUPER_FLAG_ERROR		(1ULL << 2)
-
-#define BTRFS_SUPER_FLAG_SEEDING	(1ULL << 32)
-#define BTRFS_SUPER_FLAG_METADUMP	(1ULL << 33)
-
 #define BTRFS_BACKREF_REV_MAX		256
 #define BTRFS_BACKREF_REV_SHIFT		56
 #define BTRFS_BACKREF_REV_MASK		(((u64)BTRFS_BACKREF_REV_MAX - 1) << \
@@ -598,357 +352,8 @@ struct btrfs_path {
 	unsigned int need_commit_sem:1;
 	unsigned int skip_release_on_error:1;
 };
-
-/*
- * items in the extent btree are used to record the objectid of the
- * owner of the block and the number of references
- */
-
-struct btrfs_extent_item {
-	__le64 refs;
-	__le64 generation;
-	__le64 flags;
-} __attribute__ ((__packed__));
-
-struct btrfs_extent_item_v0 {
-	__le32 refs;
-} __attribute__ ((__packed__));
-
 #define BTRFS_MAX_EXTENT_ITEM_SIZE(r) ((BTRFS_LEAF_DATA_SIZE(r) >> 4) - \
 					sizeof(struct btrfs_item))
-
-#define BTRFS_EXTENT_FLAG_DATA		(1ULL << 0)
-#define BTRFS_EXTENT_FLAG_TREE_BLOCK	(1ULL << 1)
-
-/* following flags only apply to tree blocks */
-
-/* use full backrefs for extent pointers in the block */
-#define BTRFS_BLOCK_FLAG_FULL_BACKREF	(1ULL << 8)
-
-/*
- * this flag is only used internally by scrub and may be changed at any time
- * it is only declared here to avoid collisions
- */
-#define BTRFS_EXTENT_FLAG_SUPER		(1ULL << 48)
-
-struct btrfs_tree_block_info {
-	struct btrfs_disk_key key;
-	u8 level;
-} __attribute__ ((__packed__));
-
-struct btrfs_extent_data_ref {
-	__le64 root;
-	__le64 objectid;
-	__le64 offset;
-	__le32 count;
-} __attribute__ ((__packed__));
-
-struct btrfs_shared_data_ref {
-	__le32 count;
-} __attribute__ ((__packed__));
-
-struct btrfs_extent_inline_ref {
-	u8 type;
-	__le64 offset;
-} __attribute__ ((__packed__));
-
-/* old style backrefs item */
-struct btrfs_extent_ref_v0 {
-	__le64 root;
-	__le64 generation;
-	__le64 objectid;
-	__le32 count;
-} __attribute__ ((__packed__));
-
-
-/* dev extents record free space on individual devices.  The owner
- * field points back to the chunk allocation mapping tree that allocated
- * the extent.  The chunk tree uuid field is a way to double check the owner
- */
-struct btrfs_dev_extent {
-	__le64 chunk_tree;
-	__le64 chunk_objectid;
-	__le64 chunk_offset;
-	__le64 length;
-	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
-} __attribute__ ((__packed__));
-
-struct btrfs_inode_ref {
-	__le64 index;
-	__le16 name_len;
-	/* name goes here */
-} __attribute__ ((__packed__));
-
-struct btrfs_inode_extref {
-	__le64 parent_objectid;
-	__le64 index;
-	__le16 name_len;
-	__u8   name[0];
-	/* name goes here */
-} __attribute__ ((__packed__));
-
-struct btrfs_timespec {
-	__le64 sec;
-	__le32 nsec;
-} __attribute__ ((__packed__));
-
-struct btrfs_inode_item {
-	/* nfs style generation number */
-	__le64 generation;
-	/* transid that last touched this inode */
-	__le64 transid;
-	__le64 size;
-	__le64 nbytes;
-	__le64 block_group;
-	__le32 nlink;
-	__le32 uid;
-	__le32 gid;
-	__le32 mode;
-	__le64 rdev;
-	__le64 flags;
-
-	/* modification sequence number for NFS */
-	__le64 sequence;
-
-	/*
-	 * a little future expansion, for more than this we can
-	 * just grow the inode item and version it
-	 */
-	__le64 reserved[4];
-	struct btrfs_timespec atime;
-	struct btrfs_timespec ctime;
-	struct btrfs_timespec mtime;
-	struct btrfs_timespec otime;
-} __attribute__ ((__packed__));
-
-struct btrfs_dir_log_item {
-	__le64 end;
-} __attribute__ ((__packed__));
-
-struct btrfs_dir_item {
-	struct btrfs_disk_key location;
-	__le64 transid;
-	__le16 data_len;
-	__le16 name_len;
-	u8 type;
-} __attribute__ ((__packed__));
-
-#define BTRFS_ROOT_SUBVOL_RDONLY	(1ULL << 0)
-
-/*
- * Internal in-memory flag that a subvolume has been marked for deletion but
- * still visible as a directory
- */
-#define BTRFS_ROOT_SUBVOL_DEAD		(1ULL << 48)
-
-struct btrfs_root_item {
-	struct btrfs_inode_item inode;
-	__le64 generation;
-	__le64 root_dirid;
-	__le64 bytenr;
-	__le64 byte_limit;
-	__le64 bytes_used;
-	__le64 last_snapshot;
-	__le64 flags;
-	__le32 refs;
-	struct btrfs_disk_key drop_progress;
-	u8 drop_level;
-	u8 level;
-
-	/*
-	 * The following fields appear after subvol_uuids+subvol_times
-	 * were introduced.
-	 */
-
-	/*
-	 * This generation number is used to test if the new fields are valid
-	 * and up to date while reading the root item. Every time the root item
-	 * is written out, the "generation" field is copied into this field. If
-	 * anyone ever mounted the fs with an older kernel, we will have
-	 * mismatching generation values here and thus must invalidate the
-	 * new fields. See btrfs_update_root and btrfs_find_last_root for
-	 * details.
-	 * the offset of generation_v2 is also used as the start for the memset
-	 * when invalidating the fields.
-	 */
-	__le64 generation_v2;
-	u8 uuid[BTRFS_UUID_SIZE];
-	u8 parent_uuid[BTRFS_UUID_SIZE];
-	u8 received_uuid[BTRFS_UUID_SIZE];
-	__le64 ctransid; /* updated when an inode changes */
-	__le64 otransid; /* trans when created */
-	__le64 stransid; /* trans when sent. non-zero for received subvol */
-	__le64 rtransid; /* trans when received. non-zero for received subvol */
-	struct btrfs_timespec ctime;
-	struct btrfs_timespec otime;
-	struct btrfs_timespec stime;
-	struct btrfs_timespec rtime;
-	__le64 reserved[8]; /* for future */
-} __attribute__ ((__packed__));
-
-/*
- * this is used for both forward and backward root refs
- */
-struct btrfs_root_ref {
-	__le64 dirid;
-	__le64 sequence;
-	__le16 name_len;
-} __attribute__ ((__packed__));
-
-struct btrfs_disk_balance_args {
-	/*
-	 * profiles to operate on, single is denoted by
-	 * BTRFS_AVAIL_ALLOC_BIT_SINGLE
-	 */
-	__le64 profiles;
-
-	/*
-	 * usage filter
-	 * BTRFS_BALANCE_ARGS_USAGE with a single value means '0..N'
-	 * BTRFS_BALANCE_ARGS_USAGE_RANGE - range syntax, min..max
-	 */
-	union {
-		__le64 usage;
-		struct {
-			__le32 usage_min;
-			__le32 usage_max;
-		};
-	};
-
-	/* devid filter */
-	__le64 devid;
-
-	/* devid subset filter [pstart..pend) */
-	__le64 pstart;
-	__le64 pend;
-
-	/* btrfs virtual address space subset filter [vstart..vend) */
-	__le64 vstart;
-	__le64 vend;
-
-	/*
-	 * profile to convert to, single is denoted by
-	 * BTRFS_AVAIL_ALLOC_BIT_SINGLE
-	 */
-	__le64 target;
-
-	/* BTRFS_BALANCE_ARGS_* */
-	__le64 flags;
-
-	/*
-	 * BTRFS_BALANCE_ARGS_LIMIT with value 'limit'
-	 * BTRFS_BALANCE_ARGS_LIMIT_RANGE - the extend version can use minimum
-	 * and maximum
-	 */
-	union {
-		__le64 limit;
-		struct {
-			__le32 limit_min;
-			__le32 limit_max;
-		};
-	};
-
-	/*
-	 * Process chunks that cross stripes_min..stripes_max devices,
-	 * BTRFS_BALANCE_ARGS_STRIPES_RANGE
-	 */
-	__le32 stripes_min;
-	__le32 stripes_max;
-
-	__le64 unused[6];
-} __attribute__ ((__packed__));
-
-/*
- * store balance parameters to disk so that balance can be properly
- * resumed after crash or unmount
- */
-struct btrfs_balance_item {
-	/* BTRFS_BALANCE_* */
-	__le64 flags;
-
-	struct btrfs_disk_balance_args data;
-	struct btrfs_disk_balance_args meta;
-	struct btrfs_disk_balance_args sys;
-
-	__le64 unused[4];
-} __attribute__ ((__packed__));
-
-#define BTRFS_FILE_EXTENT_INLINE 0
-#define BTRFS_FILE_EXTENT_REG 1
-#define BTRFS_FILE_EXTENT_PREALLOC 2
-
-struct btrfs_file_extent_item {
-	/*
-	 * transaction id that created this extent
-	 */
-	__le64 generation;
-	/*
-	 * max number of bytes to hold this extent in ram
-	 * when we split a compressed extent we can't know how big
-	 * each of the resulting pieces will be.  So, this is
-	 * an upper limit on the size of the extent in ram instead of
-	 * an exact limit.
-	 */
-	__le64 ram_bytes;
-
-	/*
-	 * 32 bits for the various ways we might encode the data,
-	 * including compression and encryption.  If any of these
-	 * are set to something a given disk format doesn't understand
-	 * it is treated like an incompat flag for reading and writing,
-	 * but not for stat.
-	 */
-	u8 compression;
-	u8 encryption;
-	__le16 other_encoding; /* spare for later use */
-
-	/* are we inline data or a real extent? */
-	u8 type;
-
-	/*
-	 * disk space consumed by the extent, checksum blocks are included
-	 * in these numbers
-	 *
-	 * At this offset in the structure, the inline extent data start.
-	 */
-	__le64 disk_bytenr;
-	__le64 disk_num_bytes;
-	/*
-	 * the logical offset in file blocks (no csums)
-	 * this extent record is for.  This allows a file extent to point
-	 * into the middle of an existing extent on disk, sharing it
-	 * between two snapshots (useful if some bytes in the middle of the
-	 * extent have changed
-	 */
-	__le64 offset;
-	/*
-	 * the logical number of file blocks (no csums included).  This
-	 * always reflects the size uncompressed and without encoding.
-	 */
-	__le64 num_bytes;
-
-} __attribute__ ((__packed__));
-
-struct btrfs_csum_item {
-	u8 csum;
-} __attribute__ ((__packed__));
-
-struct btrfs_dev_stats_item {
-	/*
-	 * grow this item struct at the end for future enhancements and keep
-	 * the existing values unchanged
-	 */
-	__le64 values[BTRFS_DEV_STAT_VALUES_MAX];
-} __attribute__ ((__packed__));
-
-#define BTRFS_DEV_REPLACE_ITEM_CONT_READING_FROM_SRCDEV_MODE_ALWAYS	0
-#define BTRFS_DEV_REPLACE_ITEM_CONT_READING_FROM_SRCDEV_MODE_AVOID	1
-#define BTRFS_DEV_REPLACE_ITEM_STATE_NEVER_STARTED	0
-#define BTRFS_DEV_REPLACE_ITEM_STATE_STARTED		1
-#define BTRFS_DEV_REPLACE_ITEM_STATE_SUSPENDED		2
-#define BTRFS_DEV_REPLACE_ITEM_STATE_FINISHED		3
-#define BTRFS_DEV_REPLACE_ITEM_STATE_CANCELED		4
-
 struct btrfs_dev_replace {
 	u64 replace_state;	/* see #define above */
 	u64 time_started;	/* seconds since 1-Jan-1970 */
@@ -979,167 +384,6 @@ struct btrfs_dev_replace {
 	struct btrfs_scrub_progress scrub_progress;
 };
 
-struct btrfs_dev_replace_item {
-	/*
-	 * grow this item struct at the end for future enhancements and keep
-	 * the existing values unchanged
-	 */
-	__le64 src_devid;
-	__le64 cursor_left;
-	__le64 cursor_right;
-	__le64 cont_reading_from_srcdev_mode;
-
-	__le64 replace_state;
-	__le64 time_started;
-	__le64 time_stopped;
-	__le64 num_write_errors;
-	__le64 num_uncorrectable_read_errors;
-} __attribute__ ((__packed__));
-
-/* different types of block groups (and chunks) */
-#define BTRFS_BLOCK_GROUP_DATA		(1ULL << 0)
-#define BTRFS_BLOCK_GROUP_SYSTEM	(1ULL << 1)
-#define BTRFS_BLOCK_GROUP_METADATA	(1ULL << 2)
-#define BTRFS_BLOCK_GROUP_RAID0		(1ULL << 3)
-#define BTRFS_BLOCK_GROUP_RAID1		(1ULL << 4)
-#define BTRFS_BLOCK_GROUP_DUP		(1ULL << 5)
-#define BTRFS_BLOCK_GROUP_RAID10	(1ULL << 6)
-#define BTRFS_BLOCK_GROUP_RAID5         (1ULL << 7)
-#define BTRFS_BLOCK_GROUP_RAID6         (1ULL << 8)
-#define BTRFS_BLOCK_GROUP_RESERVED	(BTRFS_AVAIL_ALLOC_BIT_SINGLE | \
-					 BTRFS_SPACE_INFO_GLOBAL_RSV)
-
-enum btrfs_raid_types {
-	BTRFS_RAID_RAID10,
-	BTRFS_RAID_RAID1,
-	BTRFS_RAID_DUP,
-	BTRFS_RAID_RAID0,
-	BTRFS_RAID_SINGLE,
-	BTRFS_RAID_RAID5,
-	BTRFS_RAID_RAID6,
-	BTRFS_NR_RAID_TYPES
-};
-
-#define BTRFS_BLOCK_GROUP_TYPE_MASK	(BTRFS_BLOCK_GROUP_DATA |    \
-					 BTRFS_BLOCK_GROUP_SYSTEM |  \
-					 BTRFS_BLOCK_GROUP_METADATA)
-
-#define BTRFS_BLOCK_GROUP_PROFILE_MASK	(BTRFS_BLOCK_GROUP_RAID0 |   \
-					 BTRFS_BLOCK_GROUP_RAID1 |   \
-					 BTRFS_BLOCK_GROUP_RAID5 |   \
-					 BTRFS_BLOCK_GROUP_RAID6 |   \
-					 BTRFS_BLOCK_GROUP_DUP |     \
-					 BTRFS_BLOCK_GROUP_RAID10)
-#define BTRFS_BLOCK_GROUP_RAID56_MASK	(BTRFS_BLOCK_GROUP_RAID5 |   \
-					 BTRFS_BLOCK_GROUP_RAID6)
-
-/*
- * We need a bit for restriper to be able to tell when chunks of type
- * SINGLE are available.  This "extended" profile format is used in
- * fs_info->avail_*_alloc_bits (in-memory) and balance item fields
- * (on-disk).  The corresponding on-disk bit in chunk.type is reserved
- * to avoid remappings between two formats in future.
- */
-#define BTRFS_AVAIL_ALLOC_BIT_SINGLE	(1ULL << 48)
-
-/*
- * A fake block group type that is used to communicate global block reserve
- * size to userspace via the SPACE_INFO ioctl.
- */
-#define BTRFS_SPACE_INFO_GLOBAL_RSV	(1ULL << 49)
-
-#define BTRFS_EXTENDED_PROFILE_MASK	(BTRFS_BLOCK_GROUP_PROFILE_MASK | \
-					 BTRFS_AVAIL_ALLOC_BIT_SINGLE)
-
-static inline u64 chunk_to_extended(u64 flags)
-{
-	if ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0)
-		flags |= BTRFS_AVAIL_ALLOC_BIT_SINGLE;
-
-	return flags;
-}
-static inline u64 extended_to_chunk(u64 flags)
-{
-	return flags & ~BTRFS_AVAIL_ALLOC_BIT_SINGLE;
-}
-
-struct btrfs_block_group_item {
-	__le64 used;
-	__le64 chunk_objectid;
-	__le64 flags;
-} __attribute__ ((__packed__));
-
-struct btrfs_free_space_info {
-	__le32 extent_count;
-	__le32 flags;
-} __attribute__ ((__packed__));
-
-#define BTRFS_FREE_SPACE_USING_BITMAPS (1ULL << 0)
-
-#define BTRFS_QGROUP_LEVEL_SHIFT		48
-static inline u64 btrfs_qgroup_level(u64 qgroupid)
-{
-	return qgroupid >> BTRFS_QGROUP_LEVEL_SHIFT;
-}
-
-/*
- * is subvolume quota turned on?
- */
-#define BTRFS_QGROUP_STATUS_FLAG_ON		(1ULL << 0)
-/*
- * RESCAN is set during the initialization phase
- */
-#define BTRFS_QGROUP_STATUS_FLAG_RESCAN		(1ULL << 1)
-/*
- * Some qgroup entries are known to be out of date,
- * either because the configuration has changed in a way that
- * makes a rescan necessary, or because the fs has been mounted
- * with a non-qgroup-aware version.
- * Turning qouta off and on again makes it inconsistent, too.
- */
-#define BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT	(1ULL << 2)
-
-#define BTRFS_QGROUP_STATUS_VERSION        1
-
-struct btrfs_qgroup_status_item {
-	__le64 version;
-	/*
-	 * the generation is updated during every commit. As older
-	 * versions of btrfs are not aware of qgroups, it will be
-	 * possible to detect inconsistencies by checking the
-	 * generation on mount time
-	 */
-	__le64 generation;
-
-	/* flag definitions see above */
-	__le64 flags;
-
-	/*
-	 * only used during scanning to record the progress
-	 * of the scan. It contains a logical address
-	 */
-	__le64 rescan;
-} __attribute__ ((__packed__));
-
-struct btrfs_qgroup_info_item {
-	__le64 generation;
-	__le64 rfer;
-	__le64 rfer_cmpr;
-	__le64 excl;
-	__le64 excl_cmpr;
-} __attribute__ ((__packed__));
-
-struct btrfs_qgroup_limit_item {
-	/*
-	 * only updated when any of the other values change
-	 */
-	__le64 flags;
-	__le64 max_rfer;
-	__le64 max_excl;
-	__le64 rsv_rfer;
-	__le64 rsv_excl;
-} __attribute__ ((__packed__));
-
 /* For raid type sysfs entries */
 struct raid_kobject {
 	int raid_type;
@@ -1992,197 +1236,6 @@ struct btrfs_root {
 	atomic_t qgroup_meta_rsv;
 };
 
-
-/*
- * inode items have the data typically returned from stat and store other
- * info about object characteristics.  There is one for every file and dir in
- * the FS
- */
-#define BTRFS_INODE_ITEM_KEY		1
-#define BTRFS_INODE_REF_KEY		12
-#define BTRFS_INODE_EXTREF_KEY		13
-#define BTRFS_XATTR_ITEM_KEY		24
-#define BTRFS_ORPHAN_ITEM_KEY		48
-/* reserve 2-15 close to the inode for later flexibility */
-
-/*
- * dir items are the name -> inode pointers in a directory.  There is one
- * for every name in a directory.
- */
-#define BTRFS_DIR_LOG_ITEM_KEY  60
-#define BTRFS_DIR_LOG_INDEX_KEY 72
-#define BTRFS_DIR_ITEM_KEY	84
-#define BTRFS_DIR_INDEX_KEY	96
-/*
- * extent data is for file data
- */
-#define BTRFS_EXTENT_DATA_KEY	108
-
-/*
- * extent csums are stored in a separate tree and hold csums for
- * an entire extent on disk.
- */
-#define BTRFS_EXTENT_CSUM_KEY	128
-
-/*
- * root items point to tree roots.  They are typically in the root
- * tree used by the super block to find all the other trees
- */
-#define BTRFS_ROOT_ITEM_KEY	132
-
-/*
- * root backrefs tie subvols and snapshots to the directory entries that
- * reference them
- */
-#define BTRFS_ROOT_BACKREF_KEY	144
-
-/*
- * root refs make a fast index for listing all of the snapshots and
- * subvolumes referenced by a given root.  They point directly to the
- * directory item in the root that references the subvol
- */
-#define BTRFS_ROOT_REF_KEY	156
-
-/*
- * extent items are in the extent map tree.  These record which blocks
- * are used, and how many references there are to each block
- */
-#define BTRFS_EXTENT_ITEM_KEY	168
-
-/*
- * The same as the BTRFS_EXTENT_ITEM_KEY, except it's metadata we already know
- * the length, so we save the level in key->offset instead of the length.
- */
-#define BTRFS_METADATA_ITEM_KEY	169
-
-#define BTRFS_TREE_BLOCK_REF_KEY	176
-
-#define BTRFS_EXTENT_DATA_REF_KEY	178
-
-#define BTRFS_EXTENT_REF_V0_KEY		180
-
-#define BTRFS_SHARED_BLOCK_REF_KEY	182
-
-#define BTRFS_SHARED_DATA_REF_KEY	184
-
-/*
- * block groups give us hints into the extent allocation trees.  Which
- * blocks are free etc etc
- */
-#define BTRFS_BLOCK_GROUP_ITEM_KEY 192
-
-/*
- * Every block group is represented in the free space tree by a free space info
- * item, which stores some accounting information. It is keyed on
- * (block_group_start, FREE_SPACE_INFO, block_group_length).
- */
-#define BTRFS_FREE_SPACE_INFO_KEY 198
-
-/*
- * A free space extent tracks an extent of space that is free in a block group.
- * It is keyed on (start, FREE_SPACE_EXTENT, length).
- */
-#define BTRFS_FREE_SPACE_EXTENT_KEY 199
-
-/*
- * When a block group becomes very fragmented, we convert it to use bitmaps
- * instead of extents. A free space bitmap is keyed on
- * (start, FREE_SPACE_BITMAP, length); the corresponding item is a bitmap with
- * (length / sectorsize) bits.
- */
-#define BTRFS_FREE_SPACE_BITMAP_KEY 200
-
-#define BTRFS_DEV_EXTENT_KEY	204
-#define BTRFS_DEV_ITEM_KEY	216
-#define BTRFS_CHUNK_ITEM_KEY	228
-
-/*
- * Records the overall state of the qgroups.
- * There's only one instance of this key present,
- * (0, BTRFS_QGROUP_STATUS_KEY, 0)
- */
-#define BTRFS_QGROUP_STATUS_KEY         240
-/*
- * Records the currently used space of the qgroup.
- * One key per qgroup, (0, BTRFS_QGROUP_INFO_KEY, qgroupid).
- */
-#define BTRFS_QGROUP_INFO_KEY           242
-/*
- * Contains the user configured limits for the qgroup.
- * One key per qgroup, (0, BTRFS_QGROUP_LIMIT_KEY, qgroupid).
- */
-#define BTRFS_QGROUP_LIMIT_KEY          244
-/*
- * Records the child-parent relationship of qgroups. For
- * each relation, 2 keys are present:
- * (childid, BTRFS_QGROUP_RELATION_KEY, parentid)
- * (parentid, BTRFS_QGROUP_RELATION_KEY, childid)
- */
-#define BTRFS_QGROUP_RELATION_KEY       246
-
-/*
- * Obsolete name, see BTRFS_TEMPORARY_ITEM_KEY.
- */
-#define BTRFS_BALANCE_ITEM_KEY	248
-
-/*
- * The key type for tree items that are stored persistently, but do not need to
- * exist for extended period of time. The items can exist in any tree.
- *
- * [subtype, BTRFS_TEMPORARY_ITEM_KEY, data]
- *
- * Existing items:
- *
- * - balance status item
- *   (BTRFS_BALANCE_OBJECTID, BTRFS_TEMPORARY_ITEM_KEY, 0)
- */
-#define BTRFS_TEMPORARY_ITEM_KEY	248
-
-/*
- * Obsolete name, see BTRFS_PERSISTENT_ITEM_KEY
- */
-#define BTRFS_DEV_STATS_KEY		249
-
-/*
- * The key type for tree items that are stored persistently and usually exist
- * for a long period, eg. filesystem lifetime. The item kinds can be status
- * information, stats or preference values. The item can exist in any tree.
- *
- * [subtype, BTRFS_PERSISTENT_ITEM_KEY, data]
- *
- * Existing items:
- *
- * - device statistics, store IO stats in the device tree, one key for all
- *   stats
- *   (BTRFS_DEV_STATS_OBJECTID, BTRFS_DEV_STATS_KEY, 0)
- */
-#define BTRFS_PERSISTENT_ITEM_KEY	249
-
-/*
- * Persistantly stores the device replace state in the device tree.
- * The key is built like this: (0, BTRFS_DEV_REPLACE_KEY, 0).
- */
-#define BTRFS_DEV_REPLACE_KEY	250
-
-/*
- * Stores items that allow to quickly map UUIDs to something else.
- * These items are part of the filesystem UUID tree.
- * The key is built like this:
- * (UUID_upper_64_bits, BTRFS_UUID_KEY*, UUID_lower_64_bits).
- */
-#if BTRFS_UUID_SIZE != 16
-#error "UUID items require BTRFS_UUID_SIZE == 16!"
-#endif
-#define BTRFS_UUID_KEY_SUBVOL	251	/* for UUIDs assigned to subvols */
-#define BTRFS_UUID_KEY_RECEIVED_SUBVOL	252	/* for UUIDs assigned to
-						 * received subvols */
-
-/*
- * string items are for debugging.  They just store a short string of
- * data in the FS
- */
-#define BTRFS_STRING_ITEM_KEY	253
-
 /*
  * Flags for mount options.
  *

commit 33ca913349962208e13e894ada99b9ae6e0080ee
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Apr 1 16:14:28 2016 -0400

    btrfs: uapi/linux/btrfs.h migration, move struct btrfs_ioctl_defrag_range_args
    
    struct btrfs_ioctl_defrag_range_args is used by the BTRFS_IOC_DEFRAG_RANGE
    ioctl.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 378482c705c3..89f36b6176b9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1992,37 +1992,6 @@ struct btrfs_root {
 	atomic_t qgroup_meta_rsv;
 };
 
-struct btrfs_ioctl_defrag_range_args {
-	/* start of the defrag operation */
-	__u64 start;
-
-	/* number of bytes to defrag, use (u64)-1 to say all */
-	__u64 len;
-
-	/*
-	 * flags for the operation, which can include turning
-	 * on compression for this one defrag
-	 */
-	__u64 flags;
-
-	/*
-	 * any extent bigger than this will be considered
-	 * already defragged.  Use 0 to take the kernel default
-	 * Use 1 to say every single extent must be rewritten
-	 */
-	__u32 extent_thresh;
-
-	/*
-	 * which compression method to use if turning on compression
-	 * for this defrag operation.  If unspecified, zlib will
-	 * be used
-	 */
-	__u32 compress_type;
-
-	/* spare for later */
-	__u32 unused[4];
-};
-
 
 /*
  * inode items have the data typically returned from stat and store other

commit 18db9ac644badcb948a623791e599672edade6dd
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Apr 1 16:14:26 2016 -0400

    btrfs: uapi/linux/btrfs.h migration, move feature flags
    
    The compat/compat_ro/incompat feature flags are used by the feature set/get
    ioctls.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c228b39fbd15..378482c705c3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -506,31 +506,6 @@ struct btrfs_super_block {
  * Compat flags that we support.  If any incompat flags are set other than the
  * ones specified below then we will fail to mount
  */
-#define BTRFS_FEATURE_COMPAT_RO_FREE_SPACE_TREE	(1ULL << 0)
-
-#define BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF	(1ULL << 0)
-#define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(1ULL << 1)
-#define BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS	(1ULL << 2)
-#define BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO	(1ULL << 3)
-/*
- * some patches floated around with a second compression method
- * lets save that incompat here for when they do get in
- * Note we don't actually support it, we're just reserving the
- * number
- */
-#define BTRFS_FEATURE_INCOMPAT_COMPRESS_LZOv2	(1ULL << 4)
-
-/*
- * older kernels tried to do bigger metadata blocks, but the
- * code was pretty buggy.  Lets not let them try anymore.
- */
-#define BTRFS_FEATURE_INCOMPAT_BIG_METADATA	(1ULL << 5)
-
-#define BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF	(1ULL << 6)
-#define BTRFS_FEATURE_INCOMPAT_RAID56		(1ULL << 7)
-#define BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA	(1ULL << 8)
-#define BTRFS_FEATURE_INCOMPAT_NO_HOLES		(1ULL << 9)
-
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_SAFE_SET		0ULL
 #define BTRFS_FEATURE_COMPAT_SAFE_CLEAR		0ULL

commit 83288b60bf6668933689078973136e0c9d387b38
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Apr 1 16:14:24 2016 -0400

    btrfs: uapi/linux/btrfs.h migration, qgroup limit flags
    
    The BTRFS_QGROUP_LIMIT_* flags are required to tell the kernel which
    fields are valid when using the BTRFS_IOC_QGROUP_LIMIT ioctl.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3beaa24aff9b..c228b39fbd15 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1154,14 +1154,6 @@ struct btrfs_qgroup_info_item {
 	__le64 excl_cmpr;
 } __attribute__ ((__packed__));
 
-/* flags definition for qgroup limits */
-#define BTRFS_QGROUP_LIMIT_MAX_RFER	(1ULL << 0)
-#define BTRFS_QGROUP_LIMIT_MAX_EXCL	(1ULL << 1)
-#define BTRFS_QGROUP_LIMIT_RSV_RFER	(1ULL << 2)
-#define BTRFS_QGROUP_LIMIT_RSV_EXCL	(1ULL << 3)
-#define BTRFS_QGROUP_LIMIT_RFER_CMPR	(1ULL << 4)
-#define BTRFS_QGROUP_LIMIT_EXCL_CMPR	(1ULL << 5)
-
 struct btrfs_qgroup_limit_item {
 	/*
 	 * only updated when any of the other values change

commit d4ae133b2d195d88cf5394072724adfa6ccdd64b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Apr 1 16:14:23 2016 -0400

    btrfs: uapi/linux/btrfs.h migration, move BTRFS_LABEL_SIZE
    
    BTRFS_LABEL_SIZE is required to define the BTRFS_IOC_GET_FSLABEL and
    BTRFS_IOC_SET_FSLABEL ioctls.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84a6a5b3384a..3beaa24aff9b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -410,7 +410,6 @@ struct btrfs_header {
  * room to translate 14 chunks with 3 stripes each.
  */
 #define BTRFS_SYSTEM_CHUNK_ARRAY_SIZE 2048
-#define BTRFS_LABEL_SIZE 256
 
 /*
  * just in case we somehow lose the roots and are not able to mount,

commit 4c63c2454eff996c5e27991221106eb511f7db38
Author: Luke Dashjr <luke@dashjr.org>
Date:   Thu Oct 29 08:22:21 2015 +0000

    btrfs: bugfix: handle FS_IOC32_{GETFLAGS,SETFLAGS,GETVERSION} in btrfs_ioctl
    
    32-bit ioctl uses these rather than the regular FS_IOC_* versions. They can
    be handled in btrfs using the same code. Without this, 32-bit {ch,ls}attr
    fail.
    
    Signed-off-by: Luke Dashjr <luke-jr+git@utopios.org>
    Cc: stable@vger.kernel.org
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84a6a5b3384a..208d19938fdf 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4122,6 +4122,7 @@ void btrfs_test_inode_set_ops(struct inode *inode);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
+long btrfs_compat_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 int btrfs_ioctl_get_supported_features(void __user *arg);
 void btrfs_update_iflags(struct inode *inode);
 void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);

commit c5f4ccb2f77355ac44433feb362fecd7f1a7d03e
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Mar 16 16:43:08 2016 +0800

    btrfs: move error handling code together in ctree.h
    
    Looks like we added the incompatible defines in between the error
    handling defines in the file ctree.h. Now group them back.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4f37e3766626..e22568a54545 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4338,6 +4338,46 @@ void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root, const char *function,
 			       unsigned int line, int errno);
 
+/*
+ * Call btrfs_abort_transaction as early as possible when an error condition is
+ * detected, that way the exact line number is reported.
+ */
+#define btrfs_abort_transaction(trans, root, errno)		\
+do {								\
+	/* Report first abort since mount */			\
+	if (!test_and_set_bit(BTRFS_FS_STATE_TRANS_ABORTED,	\
+			&((root)->fs_info->fs_state))) {	\
+		WARN(1, KERN_DEBUG				\
+		"BTRFS: Transaction aborted (error %d)\n",	\
+		(errno));					\
+	}							\
+	__btrfs_abort_transaction((trans), (root), __func__,	\
+				  __LINE__, (errno));		\
+} while (0)
+
+#define btrfs_handle_fs_error(fs_info, errno, fmt, args...)		\
+do {								\
+	__btrfs_handle_fs_error((fs_info), __func__, __LINE__,	\
+			  (errno), fmt, ##args);		\
+} while (0)
+
+__printf(5, 6)
+__cold
+void __btrfs_panic(struct btrfs_fs_info *fs_info, const char *function,
+		   unsigned int line, int errno, const char *fmt, ...);
+/*
+ * If BTRFS_MOUNT_PANIC_ON_FATAL_ERROR is in mount_opt, __btrfs_panic
+ * will panic().  Otherwise we BUG() here.
+ */
+#define btrfs_panic(fs_info, errno, fmt, args...)			\
+do {									\
+	__btrfs_panic(fs_info, __func__, __LINE__, errno, fmt, ##args);	\
+	BUG();								\
+} while (0)
+
+
+/* compatibility and incompatibility defines */
+
 #define btrfs_set_fs_incompat(__fs_info, opt) \
 	__btrfs_set_fs_incompat((__fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
 
@@ -4454,44 +4494,6 @@ static inline int __btrfs_fs_compat_ro(struct btrfs_fs_info *fs_info, u64 flag)
 	return !!(btrfs_super_compat_ro_flags(disk_super) & flag);
 }
 
-/*
- * Call btrfs_abort_transaction as early as possible when an error condition is
- * detected, that way the exact line number is reported.
- */
-#define btrfs_abort_transaction(trans, root, errno)		\
-do {								\
-	/* Report first abort since mount */			\
-	if (!test_and_set_bit(BTRFS_FS_STATE_TRANS_ABORTED,	\
-			&((root)->fs_info->fs_state))) {	\
-		WARN(1, KERN_DEBUG				\
-		"BTRFS: Transaction aborted (error %d)\n",	\
-		(errno));					\
-	}							\
-	__btrfs_abort_transaction((trans), (root), __func__,	\
-				  __LINE__, (errno));		\
-} while (0)
-
-#define btrfs_handle_fs_error(fs_info, errno, fmt, args...)		\
-do {								\
-	__btrfs_handle_fs_error((fs_info), __func__, __LINE__,	\
-			  (errno), fmt, ##args);		\
-} while (0)
-
-__printf(5, 6)
-__cold
-void __btrfs_panic(struct btrfs_fs_info *fs_info, const char *function,
-		   unsigned int line, int errno, const char *fmt, ...);
-
-/*
- * If BTRFS_MOUNT_PANIC_ON_FATAL_ERROR is in mount_opt, __btrfs_panic
- * will panic().  Otherwise we BUG() here.
- */
-#define btrfs_panic(fs_info, errno, fmt, args...)			\
-do {									\
-	__btrfs_panic(fs_info, __func__, __LINE__, errno, fmt, ##args);	\
-	BUG();								\
-} while (0)
-
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL
 struct posix_acl *btrfs_get_acl(struct inode *inode, int type);

commit 2351d743f6b69d289f04246127c9d92516621974
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Mar 16 16:43:07 2016 +0800

    btrfs: remove unused function btrfs_assert()
    
    Apparently looks like ASSERT does the same intended job,
    as intended btrfs_assert().
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 12f80cd230ab..4f37e3766626 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4326,7 +4326,6 @@ static inline void assfail(char *expr, char *file, int line)
 #define ASSERT(expr)	((void)0)
 #endif
 
-#define btrfs_assert()
 __printf(5, 6)
 __cold
 void __btrfs_handle_fs_error(struct btrfs_fs_info *fs_info, const char *function,

commit 34d9700702f4042ce10d68a092ab7f79575e7a3b
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Mar 16 16:43:06 2016 +0800

    btrfs: rename btrfs_std_error to btrfs_handle_fs_error
    
    btrfs_std_error() handles errors, puts FS into readonly mode
    (as of now). So its good idea to rename it to btrfs_handle_fs_error().
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ edit changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84a6a5b3384a..12f80cd230ab 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4329,7 +4329,7 @@ static inline void assfail(char *expr, char *file, int line)
 #define btrfs_assert()
 __printf(5, 6)
 __cold
-void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
+void __btrfs_handle_fs_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);
 
 const char *btrfs_decode_error(int errno);
@@ -4472,9 +4472,9 @@ do {								\
 				  __LINE__, (errno));		\
 } while (0)
 
-#define btrfs_std_error(fs_info, errno, fmt, args...)		\
+#define btrfs_handle_fs_error(fs_info, errno, fmt, args...)		\
 do {								\
-	__btrfs_std_error((fs_info), __func__, __LINE__,	\
+	__btrfs_handle_fs_error((fs_info), __func__, __LINE__,	\
 			  (errno), fmt, ##args);		\
 } while (0)
 

commit bb7ab3b92e46da06b580c6f83abe7894dc449cca
Author: Adam Buchbinder <adam.buchbinder@gmail.com>
Date:   Fri Mar 4 11:23:12 2016 -0800

    btrfs: Fix misspellings in comments.
    
    Signed-off-by: Adam Buchbinder <adam.buchbinder@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0ef28fd2bd27..84a6a5b3384a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -788,7 +788,7 @@ struct btrfs_root_item {
 
 	/*
 	 * This generation number is used to test if the new fields are valid
-	 * and up to date while reading the root item. Everytime the root item
+	 * and up to date while reading the root item. Every time the root item
 	 * is written out, the "generation" field is copied into this field. If
 	 * anyone ever mounted the fs with an older kernel, we will have
 	 * mismatching generation values here and thus must invalidate the
@@ -1219,10 +1219,10 @@ struct btrfs_space_info {
 	 * we've called update_block_group and dropped the bytes_used counter
 	 * and increased the bytes_pinned counter.  However this means that
 	 * bytes_pinned does not reflect the bytes that will be pinned once the
-	 * delayed refs are flushed, so this counter is inc'ed everytime we call
-	 * btrfs_free_extent so it is a realtime count of what will be freed
-	 * once the transaction is committed.  It will be zero'ed everytime the
-	 * transaction commits.
+	 * delayed refs are flushed, so this counter is inc'ed every time we
+	 * call btrfs_free_extent so it is a realtime count of what will be
+	 * freed once the transaction is committed.  It will be zero'ed every
+	 * time the transaction commits.
 	 */
 	struct percpu_counter total_bytes_pinned;
 

commit ebb8765b2ded869b75bf5154b048119eb52571f7
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Mar 10 17:26:59 2016 +0800

    btrfs: move btrfs_compression_type to compression.h
    
    So that its better organized.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b69ad1305b71..0ef28fd2bd27 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -718,14 +718,6 @@ struct btrfs_timespec {
 	__le32 nsec;
 } __attribute__ ((__packed__));
 
-enum btrfs_compression_type {
-	BTRFS_COMPRESS_NONE  = 0,
-	BTRFS_COMPRESS_ZLIB  = 1,
-	BTRFS_COMPRESS_LZO   = 2,
-	BTRFS_COMPRESS_TYPES = 2,
-	BTRFS_COMPRESS_LAST  = 3,
-};
-
 struct btrfs_inode_item {
 	/* nfs style generation number */
 	__le64 generation;

commit f5bc27c71a1b0741cb93dbec0f216b012b21d93f
Merge: fa695b01bcea d5131b658c2e
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:34 2016 +0100

    Merge branch 'dev/control-ioctl' into for-chris-4.6

commit fa695b01bceabc40be3267d309ca8a663de53d7a
Merge: f004fae0cfeb f7e98a7fff86
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:34 2016 +0100

    Merge branch 'misc-4.6' into for-chris-4.6
    
    # Conflicts:
    #       fs/btrfs/file.c

commit f004fae0cfeb96d33240eb5471f14cb6fbbd4eea
Merge: 675d276b322b f827ba9a641b
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:33 2016 +0100

    Merge branch 'cleanups-4.6' into for-chris-4.6

commit 675d276b322b45e7bf7c616a2847bdc425745b99
Merge: e9ddd77a31e6 73beece9ca07
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:32 2016 +0100

    Merge branch 'foreign/liubo/replace-lockup' into for-chris-4.6

commit ff7db6e05a93a23eb43c7d20dc2027bcc939b6a8
Merge: 23c1a966f252 7aff8cf4a6d6
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:30 2016 +0100

    Merge branch 'foreign/zhaolei/reada' into for-chris-4.6

commit 23c1a966f2525e71f895bf349a5ae9e5d7bdd67f
Merge: 67d605fec1d4 fed8f166ebf3
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:30 2016 +0100

    Merge branch 'foreign/qu/norecovery-v7' into for-chris-4.6

commit 67d605fec1d406f6a0272be39686801d389f59c9
Merge: e22b3d1fbe59 9f07e1d76eae
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:29 2016 +0100

    Merge branch 'dev/rename-keys' into for-chris-4.6

commit 5f1b5664d97842bc5dba40c2053bf95270b6ff7a
Merge: 388f7b1d6e8c 65bfa6580791
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:28 2016 +0100

    Merge branch 'chandan/prep-subpage-blocksize' into for-chris-4.6
    
    # Conflicts:
    #       fs/btrfs/file.c

commit 73beece9ca07c003e0e4f4825b12be167334d4ad
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Jul 17 16:49:19 2015 +0800

    Btrfs: fix lockdep deadlock warning due to dev_replace
    
    Xfstests btrfs/011 complains about a deadlock warning,
    
    [ 1226.649039] =========================================================
    [ 1226.649039] [ INFO: possible irq lock inversion dependency detected ]
    [ 1226.649039] 4.1.0+ #270 Not tainted
    [ 1226.649039] ---------------------------------------------------------
    [ 1226.652955] kswapd0/46 just changed the state of lock:
    [ 1226.652955]  (&delayed_node->mutex){+.+.-.}, at: [<ffffffff81458735>] __btrfs_release_delayed_node+0x45/0x1d0
    [ 1226.652955] but this lock took another, RECLAIM_FS-unsafe lock in the past:
    [ 1226.652955]  (&fs_info->dev_replace.lock){+.+.+.}
    
    and interrupts could create inverse lock ordering between them.
    
    [ 1226.652955]
    other info that might help us debug this:
    [ 1226.652955] Chain exists of:
      &delayed_node->mutex --> &found->groups_sem --> &fs_info->dev_replace.lock
    
    [ 1226.652955]  Possible interrupt unsafe locking scenario:
    
    [ 1226.652955]        CPU0                    CPU1
    [ 1226.652955]        ----                    ----
    [ 1226.652955]   lock(&fs_info->dev_replace.lock);
    [ 1226.652955]                                local_irq_disable();
    [ 1226.652955]                                lock(&delayed_node->mutex);
    [ 1226.652955]                                lock(&found->groups_sem);
    [ 1226.652955]   <Interrupt>
    [ 1226.652955]     lock(&delayed_node->mutex);
    [ 1226.652955]
     *** DEADLOCK ***
    
    Commit 084b6e7c7607 ("btrfs: Fix a lockdep warning when running xfstest.") tried
    to fix a similar one that has the exactly same warning, but with that, we still
    run to this.
    
    The above lock chain comes from
    btrfs_commit_transaction
      ->btrfs_run_delayed_items
        ...
        ->__btrfs_update_delayed_inode
          ...
          ->__btrfs_cow_block
             ...
             ->find_free_extent
                ->cache_block_group
                  ->load_free_space_cache
                    ->btrfs_readpages
                      ->submit_one_bio
                        ...
                        ->__btrfs_map_block
                          ->btrfs_dev_replace_lock
    
    However, with high memory pressure, tasks which hold dev_replace.lock can
    be interrupted by kswapd and then kswapd is intended to release memory occupied
    by superblock, inodes and dentries, where we may call evict_inode, and it comes
    to
    
    [ 1226.652955]  [<ffffffff81458735>] __btrfs_release_delayed_node+0x45/0x1d0
    [ 1226.652955]  [<ffffffff81459e74>] btrfs_remove_delayed_node+0x24/0x30
    [ 1226.652955]  [<ffffffff8140c5fe>] btrfs_evict_inode+0x34e/0x700
    
    delayed_node->mutex may be acquired in __btrfs_release_delayed_node(), and it leads
    to a ABBA deadlock.
    
    To fix this, we can use "blocking rwlock" used in the case of extent_buffer, but
    things are simpler here since we only needs read's spinlock to blocking lock.
    
    With this, btrfs/011 no more produces warnings in dmesg.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfe4a337fb4d..0b427a6966ad 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1002,8 +1002,10 @@ struct btrfs_dev_replace {
 	pid_t lock_owner;
 	atomic_t nesting_level;
 	struct mutex lock_finishing_cancel_unmount;
-	struct mutex lock_management_lock;
-	struct mutex lock;
+	rwlock_t lock;
+	atomic_t read_locks;
+	atomic_t blocking_readers;
+	wait_queue_head_t read_lock_wq;
 
 	struct btrfs_scrub_progress scrub_progress;
 };

commit d5131b658c2e906da11603da5d3cb4c3a445331d
Author: David Sterba <dsterba@suse.com>
Date:   Wed Feb 17 15:26:27 2016 +0100

    btrfs: drop unused argument in btrfs_ioctl_get_supported_features
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 47bc50fd4f55..82ce847318ae 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4089,7 +4089,7 @@ void btrfs_test_inode_set_ops(struct inode *inode);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
-int btrfs_ioctl_get_supported_features(struct file *file, void __user *arg);
+int btrfs_ioctl_get_supported_features(void __user *arg);
 void btrfs_update_iflags(struct inode *inode);
 void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
 int btrfs_is_empty_uuid(u8 *uuid);

commit c5868f8362f5620302c66848d400368f8d4b45f8
Author: David Sterba <dsterba@suse.com>
Date:   Wed Feb 17 15:24:14 2016 +0100

    btrfs: add GET_SUPPORTED_FEATURES to the control device ioctls
    
    The control device is accessible when no filesystem is mounted and we
    may want to query features supported by the module. This is already
    possible using the sysfs files, this ioctl is for parity and
    convenience.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfe4a337fb4d..47bc50fd4f55 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4089,6 +4089,7 @@ void btrfs_test_inode_set_ops(struct inode *inode);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
+int btrfs_ioctl_get_supported_features(struct file *file, void __user *arg);
 void btrfs_update_iflags(struct inode *inode);
 void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
 int btrfs_is_empty_uuid(u8 *uuid);

commit f7e98a7fff8634ae655c666dc2c9fc55a48d0a73
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 14:14:16 2015 +0200

    btrfs: change max_inline default to 2048
    
    The current practical default is ~4k on x86_64 (the logic is more complex,
    simplified for brevity), the inlined files land in the metadata group and
    thus consume space that could be needed for the real metadata.
    
    The inlining brings some usability surprises:
    
    1) total space consumption measured on various filesystems and btrfs
       with DUP metadata was quite visible because of the duplicated data
       within metadata
    
    2) inlined data may exhaust the metadata, which are more precious in case
       the entire device space is allocated to chunks (ie. balance cannot
       make the space more compact)
    
    3) performance suffers a bit as the inlined blocks are duplicate and
       stored far away on the device.
    
    Proposed fix: set the default to 2048
    
    This fixes namely 1), the total filesysystem space consumption will be on
    par with other filesystems.
    
    Partially fixes 2), more data are pushed to the data block groups.
    
    The characteristics of 3) are based on actual small file size
    distribution.
    
    The change is independent of the metadata blockgroup type (though it's
    most visible with DUP) or system page size as these parameters are not
    trival to find out, compared to file size.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfe4a337fb4d..6661ad8b4088 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2252,7 +2252,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_FREE_SPACE_TREE	(1 << 26)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
-#define BTRFS_DEFAULT_MAX_INLINE	(8192)
+#define BTRFS_DEFAULT_MAX_INLINE	(2048)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 0138b6fe8f7ea6aa83ed7ccfcabc89b490528ce8
Author: Byongho Lee <bhlee.kernel@gmail.com>
Date:   Wed Jan 27 01:33:04 2016 +0900

    btrfs: simplify expression in btrfs_calc_trans_metadata_size()
    
    Simplify expression in btrfs_calc_trans_metadata_size().
    
    Signed-off-by: Byongho Lee <bhlee.kernel@gmail.com>
    Reviewed-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfe4a337fb4d..91449e41d88d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3448,8 +3448,7 @@ u64 btrfs_csum_bytes_to_leaves(struct btrfs_root *root, u64 csum_bytes);
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)
 {
-	return (root->nodesize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
-		2 * num_items;
+	return root->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
 }
 
 /*

commit 2fefd5583f8b86171c898f90cadac7c09ccf9d73
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Jan 7 18:38:48 2016 +0800

    btrfs: reada: limit max works count
    
    Reada creates 2 works for each level of tree recursively.
    
    In case of a tree having many levels, the number of created works
    is 2^level_of_tree.
    Actually we don't need so many works in parallel, this patch limits
    max works to BTRFS_MAX_MIRRORS * 2.
    
    The per-fs works_counter will be also used for btrfs_reada_wait() to
    check is there are background workers.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e557e05d2318..e43d987e1c99 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1822,6 +1822,9 @@ struct btrfs_fs_info {
 	spinlock_t reada_lock;
 	struct radix_tree_root reada_tree;
 
+	/* readahead works cnt */
+	atomic_t reada_works_cnt;
+
 	/* Extent buffer radix tree */
 	spinlock_t buffer_lock;
 	struct radix_tree_root buffer_radix;

commit 02873e432518f84ad8f15d8911e79659ea38085f
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 22:46:45 2015 +0800

    btrfs: reada: Use fs_info instead of root in __readahead_hook's argument
    
    What __readahead_hook() need exactly is fs_info, no need to convert
    fs_info to root in caller and convert back in __readahead_hook()
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfe4a337fb4d..e557e05d2318 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4525,8 +4525,8 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 			      struct btrfs_key *start, struct btrfs_key *end);
 int btrfs_reada_wait(void *handle);
 void btrfs_reada_detach(void *handle);
-int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
-			 u64 start, int err);
+int btree_readahead_hook(struct btrfs_fs_info *fs_info,
+			 struct extent_buffer *eb, u64 start, int err);
 
 static inline int is_fstree(u64 rootid)
 {

commit 96da09192cda57a356467bd7c91a3641a2e78490
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jan 19 10:23:03 2016 +0800

    btrfs: Introduce new mount option to disable tree log replay
    
    Introduce a new mount option "nologreplay" to co-operate with "ro" mount
    option to get real readonly mount, like "norecovery" in ext* and xfs.
    
    Since the new parse_options() need to check new flags at remount time,
    so add a new parameter for parse_options().
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Tested-by: Austin S. Hemmelgarn <ahferroin7@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e39eeb99adc9..a79bb734f6c3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2250,6 +2250,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_FRAGMENT_DATA	(1 << 24)
 #define BTRFS_MOUNT_FRAGMENT_METADATA	(1 << 25)
 #define BTRFS_MOUNT_FREE_SPACE_TREE	(1 << 26)
+#define BTRFS_MOUNT_NOLOGREPLAY		(1 << 27)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 #define BTRFS_DEFAULT_MAX_INLINE	(8192)
@@ -4151,7 +4152,8 @@ void btrfs_sysfs_remove_mounted(struct btrfs_fs_info *fs_info);
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 
 /* super.c */
-int btrfs_parse_options(struct btrfs_root *root, char *options);
+int btrfs_parse_options(struct btrfs_root *root, char *options,
+			unsigned long new_flags);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 
 #ifdef CONFIG_PRINTK

commit 8dcddfa048de637c8bbfa20ffd22757aeab7c604
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jan 19 10:23:02 2016 +0800

    btrfs: Introduce new mount option usebackuproot to replace recovery
    
    Current "recovery" mount option will only try to use backup root.
    However the word "recovery" is too generic and may be confusing for some
    users.
    
    Here introduce a new and more specific mount option, "usebackuproot" to
    replace "recovery" mount option.
    "Recovery" will be kept for compatibility reason, but will be
    deprecated.
    
    Also, since "usebackuproot" will only affect mount behavior and after
    open_ctree() it has nothing to do with the filesystem, so clear the flag
    after mount succeeded.
    
    This provides the basis for later unified "norecovery" mount option.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    [ dropped usebackuproot from show_mount, added note about 'recovery' to
      docs ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfe4a337fb4d..e39eeb99adc9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2241,7 +2241,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_ENOSPC_DEBUG	 (1 << 15)
 #define BTRFS_MOUNT_AUTO_DEFRAG		(1 << 16)
 #define BTRFS_MOUNT_INODE_MAP_CACHE	(1 << 17)
-#define BTRFS_MOUNT_RECOVERY		(1 << 18)
+#define BTRFS_MOUNT_USEBACKUPROOT	(1 << 18)
 #define BTRFS_MOUNT_SKIP_BALANCE	(1 << 19)
 #define BTRFS_MOUNT_CHECK_INTEGRITY	(1 << 20)
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)

commit 242e2956e4afde7727fffe21adc0a7b198b77f96
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jan 25 17:51:31 2016 +0100

    btrfs: switch dev stats item to the permanent item key
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ffc081e11277..70054ed2bd7b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -100,6 +100,9 @@ struct btrfs_ordered_sum;
 /* tracks free space in block groups. */
 #define BTRFS_FREE_SPACE_TREE_OBJECTID 10ULL
 
+/* device stats in the device tree */
+#define BTRFS_DEV_STATS_OBJECTID 0ULL
+
 /* for storing balance parameters in the root tree */
 #define BTRFS_BALANCE_OBJECTID -4ULL
 
@@ -2219,7 +2222,7 @@ struct btrfs_ioctl_defrag_range_args {
  *
  * - device statistics, store IO stats in the device tree, one key for all
  *   stats
- *   (0, BTRFS_DEV_STATS_KEY, 0)
+ *   (BTRFS_DEV_STATS_OBJECTID, BTRFS_DEV_STATS_KEY, 0)
  */
 #define BTRFS_PERSISTENT_ITEM_KEY	249
 

commit 50c2d5abe64c1726b48d292a2ab04f60e8238933
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jan 25 17:32:11 2016 +0100

    btrfs: introduce key type for persistent permanent items
    
    The number of distinct key types is not that big that we could waste one
    for something new we want to store in the tree.
    
    Similar to the temporary items, we'll introduce a new name for an
    existing key value and use the objectid for further extension.  The
    victim is the BTRFS_DEV_STATS_KEY (248).
    
    The device stats are an example of a permanent item.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e20f40649917..ffc081e11277 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2204,10 +2204,24 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_TEMPORARY_ITEM_KEY	248
 
 /*
- * Persistantly stores the io stats in the device tree.
- * One key for all stats, (0, BTRFS_DEV_STATS_KEY, devid).
+ * Obsolete name, see BTRFS_PERSISTENT_ITEM_KEY
  */
-#define BTRFS_DEV_STATS_KEY	249
+#define BTRFS_DEV_STATS_KEY		249
+
+/*
+ * The key type for tree items that are stored persistently and usually exist
+ * for a long period, eg. filesystem lifetime. The item kinds can be status
+ * information, stats or preference values. The item can exist in any tree.
+ *
+ * [subtype, BTRFS_PERSISTENT_ITEM_KEY, data]
+ *
+ * Existing items:
+ *
+ * - device statistics, store IO stats in the device tree, one key for all
+ *   stats
+ *   (0, BTRFS_DEV_STATS_KEY, 0)
+ */
+#define BTRFS_PERSISTENT_ITEM_KEY	249
 
 /*
  * Persistantly stores the device replace state in the device tree.

commit 0bbbccb17fea86818e1a058faf5903aefd20b31a
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jan 25 17:32:11 2016 +0100

    btrfs: introduce key type for persistent temporary items
    
    The number of distinct key types is not that big that we could waste one
    for something new we want to store in the tree. We'll introduce a new
    name for an existing key value and use the objectid for further
    extension.  The victim is the BTRFS_BALANCE_ITEM_KEY (248).
    
    The nature of the balance status item is a good example of the temporary
    item. It exists from beginning of the balance, keeps the status until it
    finishes.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bfe4a337fb4d..e20f40649917 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2185,8 +2185,24 @@ struct btrfs_ioctl_defrag_range_args {
  */
 #define BTRFS_QGROUP_RELATION_KEY       246
 
+/*
+ * Obsolete name, see BTRFS_TEMPORARY_ITEM_KEY.
+ */
 #define BTRFS_BALANCE_ITEM_KEY	248
 
+/*
+ * The key type for tree items that are stored persistently, but do not need to
+ * exist for extended period of time. The items can exist in any tree.
+ *
+ * [subtype, BTRFS_TEMPORARY_ITEM_KEY, data]
+ *
+ * Existing items:
+ *
+ * - balance status item
+ *   (BTRFS_BALANCE_OBJECTID, BTRFS_TEMPORARY_ITEM_KEY, 0)
+ */
+#define BTRFS_TEMPORARY_ITEM_KEY	248
+
 /*
  * Persistantly stores the io stats in the device tree.
  * One key for all stats, (0, BTRFS_DEV_STATS_KEY, devid).

commit 9703fefe0b137bb4475187b5d82ec5823445616b
Author: Chandan Rajendra <chandan@linux.vnet.ibm.com>
Date:   Thu Jan 21 15:55:56 2016 +0530

    Btrfs: fallocate: Work with sectorsized blocks
    
    While at it, this commit changes btrfs_truncate_page() to truncate sectorsized
    blocks instead of pages. Hence the function has been renamed to
    btrfs_truncate_block().
    
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ffb3617fad98..42ab58250d9e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4030,7 +4030,7 @@ int btrfs_unlink_subvol(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct inode *dir, u64 objectid,
 			const char *name, int name_len);
-int btrfs_truncate_page(struct inode *inode, loff_t from, loff_t len,
+int btrfs_truncate_block(struct inode *inode, loff_t from, loff_t len,
 			int front);
 int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,

commit 2e78c927d79333f299a8ac81c2fd2952caeef335
Author: Chandan Rajendra <chandan@linux.vnet.ibm.com>
Date:   Thu Jan 21 15:55:53 2016 +0530

    Btrfs: __btrfs_buffered_write: Reserve/release extents aligned to block size
    
    Currently, the code reserves/releases extents in multiples of PAGE_CACHE_SIZE
    units. Fix this by doing reservation/releases in block size units.
    
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a9496644f47d..ffb3617fad98 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2353,6 +2353,9 @@ struct btrfs_map_token {
 	unsigned long offset;
 };
 
+#define BTRFS_BYTES_TO_BLKS(fs_info, bytes) \
+				((bytes) >> (fs_info)->sb->s_blocksize_bits)
+
 static inline void btrfs_init_map_token (struct btrfs_map_token *token)
 {
 	token->kaddr = NULL;

commit 2101ae42899a14fe7caa73114e2161e778328661
Merge: 391f2a16b74b a6111d11b8b5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 22 11:49:21 2016 -0800

    Merge branch 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull more btrfs updates from Chris Mason:
     "These are mostly fixes that we've been testing, but also we grabbed
      and tested a few small cleanups that had been on the list for a while.
    
      Zhao Lei's patchset also fixes some early ENOSPC buglets"
    
    * 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (21 commits)
      btrfs: raid56: Use raid_write_end_io for scrub
      btrfs: Remove unnecessary ClearPageUptodate for raid56
      btrfs: use rbio->nr_pages to reduce calculation
      btrfs: Use unified stripe_page's index calculation
      btrfs: Fix calculation of rbio->dbitmap's size calculation
      btrfs: Fix no_space in write and rm loop
      btrfs: merge functions for wait snapshot creation
      btrfs: delete unused argument in btrfs_copy_from_user
      btrfs: Use direct way to determine raid56 write/recover mode
      btrfs: Small cleanup for get index_srcdev loop
      btrfs: Enhance chunk validation check
      btrfs: Enhance super validation check
      Btrfs: fix deadlock running delayed iputs at transaction commit time
      Btrfs: fix typo in log message when starting a balance
      btrfs: remove duplicate const specifier
      btrfs: initialize the seq counter in struct btrfs_device
      Btrfs: clean up an error code in btrfs_init_space_info()
      btrfs: fix iterator with update error in backref.c
      Btrfs: fix output of compression message in btrfs_parse_options()
      Btrfs: Initialize btrfs_root->highest_objectid when loading tree root and subvolume roots
      ...

commit 0bc19f9031e0c59770286f82b8561c1d35064a65
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Wed Jan 6 18:56:36 2016 +0800

    btrfs: merge functions for wait snapshot creation
    
    wait_for_snapshot_creation() is in same group with oher two:
     btrfs_start_write_no_snapshoting()
     btrfs_end_write_no_snapshoting()
    
    Rename wait_for_snapshot_creation() and move it into same place
    with other two.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e9c2f8895eab..a9496644f47d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3641,6 +3641,7 @@ int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 int __get_raid_index(u64 flags);
 int btrfs_start_write_no_snapshoting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshoting(struct btrfs_root *root);
+void btrfs_wait_for_snapshot_creation(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			const u64 type);

commit c2d6cb1636d235257086f939a8194ef0bf93af6e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Jan 15 11:05:12 2016 +0000

    Btrfs: fix deadlock running delayed iputs at transaction commit time
    
    While running a stress test I ran into a deadlock when running the delayed
    iputs at transaction time, which produced the following report and trace:
    
    [  886.399989] =============================================
    [  886.400871] [ INFO: possible recursive locking detected ]
    [  886.401663] 4.4.0-rc6-btrfs-next-18+ #1 Not tainted
    [  886.402384] ---------------------------------------------
    [  886.403182] fio/8277 is trying to acquire lock:
    [  886.403568]  (&fs_info->delayed_iput_sem){++++..}, at: [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.403568]
    [  886.403568] but task is already holding lock:
    [  886.403568]  (&fs_info->delayed_iput_sem){++++..}, at: [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.403568]
    [  886.403568] other info that might help us debug this:
    [  886.403568]  Possible unsafe locking scenario:
    [  886.403568]
    [  886.403568]        CPU0
    [  886.403568]        ----
    [  886.403568]   lock(&fs_info->delayed_iput_sem);
    [  886.403568]   lock(&fs_info->delayed_iput_sem);
    [  886.403568]
    [  886.403568]  *** DEADLOCK ***
    [  886.403568]
    [  886.403568]  May be due to missing lock nesting notation
    [  886.403568]
    [  886.403568] 3 locks held by fio/8277:
    [  886.403568]  #0:  (sb_writers#11){.+.+.+}, at: [<ffffffff81174c4c>] __sb_start_write+0x5f/0xb0
    [  886.403568]  #1:  (&sb->s_type->i_mutex_key#15){+.+.+.}, at: [<ffffffffa054620d>] btrfs_file_write_iter+0x73/0x408 [btrfs]
    [  886.403568]  #2:  (&fs_info->delayed_iput_sem){++++..}, at: [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.403568]
    [  886.403568] stack backtrace:
    [  886.403568] CPU: 6 PID: 8277 Comm: fio Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [  886.403568] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [  886.403568]  0000000000000000 ffff88009f80f770 ffffffff8125d4fd ffffffff82af1fc0
    [  886.403568]  ffff88009f80f830 ffffffff8108e5f9 0000000200000000 ffff88009fd92290
    [  886.403568]  0000000000000000 ffffffff82af1fc0 ffffffff829cfb01 00042b216d008804
    [  886.403568] Call Trace:
    [  886.403568]  [<ffffffff8125d4fd>] dump_stack+0x4e/0x79
    [  886.403568]  [<ffffffff8108e5f9>] __lock_acquire+0xd42/0xf0b
    [  886.403568]  [<ffffffff810c22db>] ? __module_address+0xdf/0x108
    [  886.403568]  [<ffffffff8108eb77>] lock_acquire+0x10d/0x194
    [  886.403568]  [<ffffffff8108eb77>] ? lock_acquire+0x10d/0x194
    [  886.403568]  [<ffffffffa0538823>] ? btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.489542]  [<ffffffff8148556b>] down_read+0x3e/0x4d
    [  886.489542]  [<ffffffffa0538823>] ? btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.489542]  [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.489542]  [<ffffffffa0533953>] btrfs_commit_transaction+0x8f5/0x96e [btrfs]
    [  886.489542]  [<ffffffffa0521d7a>] flush_space+0x435/0x44a [btrfs]
    [  886.489542]  [<ffffffffa052218b>] ? reserve_metadata_bytes+0x26a/0x384 [btrfs]
    [  886.489542]  [<ffffffffa05221ae>] reserve_metadata_bytes+0x28d/0x384 [btrfs]
    [  886.489542]  [<ffffffffa052256c>] ? btrfs_block_rsv_refill+0x58/0x96 [btrfs]
    [  886.489542]  [<ffffffffa0522584>] btrfs_block_rsv_refill+0x70/0x96 [btrfs]
    [  886.489542]  [<ffffffffa053d747>] btrfs_evict_inode+0x394/0x55a [btrfs]
    [  886.489542]  [<ffffffff81188e31>] evict+0xa7/0x15c
    [  886.489542]  [<ffffffff81189878>] iput+0x1d3/0x266
    [  886.489542]  [<ffffffffa053887c>] btrfs_run_delayed_iputs+0x8f/0xbf [btrfs]
    [  886.489542]  [<ffffffffa0533953>] btrfs_commit_transaction+0x8f5/0x96e [btrfs]
    [  886.489542]  [<ffffffff81085096>] ? signal_pending_state+0x31/0x31
    [  886.489542]  [<ffffffffa0521191>] btrfs_alloc_data_chunk_ondemand+0x1d7/0x288 [btrfs]
    [  886.489542]  [<ffffffffa0521282>] btrfs_check_data_free_space+0x40/0x59 [btrfs]
    [  886.489542]  [<ffffffffa05228f5>] btrfs_delalloc_reserve_space+0x1e/0x4e [btrfs]
    [  886.489542]  [<ffffffffa053620a>] btrfs_direct_IO+0x10c/0x27e [btrfs]
    [  886.489542]  [<ffffffff8111d9a1>] generic_file_direct_write+0xb3/0x128
    [  886.489542]  [<ffffffffa05463c3>] btrfs_file_write_iter+0x229/0x408 [btrfs]
    [  886.489542]  [<ffffffff8108ae38>] ? __lock_is_held+0x38/0x50
    [  886.489542]  [<ffffffff8117279e>] __vfs_write+0x7c/0xa5
    [  886.489542]  [<ffffffff81172cda>] vfs_write+0xa0/0xe4
    [  886.489542]  [<ffffffff811734cc>] SyS_write+0x50/0x7e
    [  886.489542]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [ 1081.852335] INFO: task fio:8244 blocked for more than 120 seconds.
    [ 1081.854348]       Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [ 1081.857560] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [ 1081.863227] fio        D ffff880213f9bb28     0  8244   8240 0x00000000
    [ 1081.868719]  ffff880213f9bb28 00ffffff810fc6b0 ffffffff0000000a ffff88023ed55240
    [ 1081.872499]  ffff880206b5d400 ffff880213f9c000 ffff88020a4d5318 ffff880206b5d400
    [ 1081.876834]  ffffffff00000001 ffff880206b5d400 ffff880213f9bb40 ffffffff81482ba4
    [ 1081.880782] Call Trace:
    [ 1081.881793]  [<ffffffff81482ba4>] schedule+0x7f/0x97
    [ 1081.883340]  [<ffffffff81485eb5>] rwsem_down_write_failed+0x2d5/0x325
    [ 1081.895525]  [<ffffffff8108d48d>] ? trace_hardirqs_on_caller+0x16/0x1ab
    [ 1081.897419]  [<ffffffff81269723>] call_rwsem_down_write_failed+0x13/0x20
    [ 1081.899251]  [<ffffffff81269723>] ? call_rwsem_down_write_failed+0x13/0x20
    [ 1081.901063]  [<ffffffff81089fae>] ? __down_write_nested.isra.0+0x1f/0x21
    [ 1081.902365]  [<ffffffff814855bd>] down_write+0x43/0x57
    [ 1081.903846]  [<ffffffffa05211b0>] ? btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1081.906078]  [<ffffffffa05211b0>] btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1081.908846]  [<ffffffff8108d461>] ? mark_held_locks+0x56/0x6c
    [ 1081.910409]  [<ffffffffa0521282>] btrfs_check_data_free_space+0x40/0x59 [btrfs]
    [ 1081.912482]  [<ffffffffa05228f5>] btrfs_delalloc_reserve_space+0x1e/0x4e [btrfs]
    [ 1081.914597]  [<ffffffffa053620a>] btrfs_direct_IO+0x10c/0x27e [btrfs]
    [ 1081.919037]  [<ffffffff8111d9a1>] generic_file_direct_write+0xb3/0x128
    [ 1081.920754]  [<ffffffffa05463c3>] btrfs_file_write_iter+0x229/0x408 [btrfs]
    [ 1081.922496]  [<ffffffff8108ae38>] ? __lock_is_held+0x38/0x50
    [ 1081.923922]  [<ffffffff8117279e>] __vfs_write+0x7c/0xa5
    [ 1081.925275]  [<ffffffff81172cda>] vfs_write+0xa0/0xe4
    [ 1081.926584]  [<ffffffff811734cc>] SyS_write+0x50/0x7e
    [ 1081.927968]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [ 1081.985293] INFO: lockdep is turned off.
    [ 1081.986132] INFO: task fio:8249 blocked for more than 120 seconds.
    [ 1081.987434]       Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [ 1081.988534] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [ 1081.990147] fio        D ffff880218febbb8     0  8249   8240 0x00000000
    [ 1081.991626]  ffff880218febbb8 00ffffff81486b8e ffff88020000000b ffff88023ed75240
    [ 1081.993258]  ffff8802120a9a00 ffff880218fec000 ffff88020a4d5318 ffff8802120a9a00
    [ 1081.994850]  ffffffff00000001 ffff8802120a9a00 ffff880218febbd0 ffffffff81482ba4
    [ 1081.996485] Call Trace:
    [ 1081.997037]  [<ffffffff81482ba4>] schedule+0x7f/0x97
    [ 1081.998017]  [<ffffffff81485eb5>] rwsem_down_write_failed+0x2d5/0x325
    [ 1081.999241]  [<ffffffff810852a5>] ? finish_wait+0x6d/0x76
    [ 1082.000306]  [<ffffffff81269723>] call_rwsem_down_write_failed+0x13/0x20
    [ 1082.001533]  [<ffffffff81269723>] ? call_rwsem_down_write_failed+0x13/0x20
    [ 1082.002776]  [<ffffffff81089fae>] ? __down_write_nested.isra.0+0x1f/0x21
    [ 1082.003995]  [<ffffffff814855bd>] down_write+0x43/0x57
    [ 1082.005000]  [<ffffffffa05211b0>] ? btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1082.007403]  [<ffffffffa05211b0>] btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1082.008988]  [<ffffffffa0545064>] btrfs_fallocate+0x7c1/0xc2f [btrfs]
    [ 1082.010193]  [<ffffffff8108a1ba>] ? percpu_down_read+0x4e/0x77
    [ 1082.011280]  [<ffffffff81174c4c>] ? __sb_start_write+0x5f/0xb0
    [ 1082.012265]  [<ffffffff81174c4c>] ? __sb_start_write+0x5f/0xb0
    [ 1082.013021]  [<ffffffff811712e4>] vfs_fallocate+0x170/0x1ff
    [ 1082.013738]  [<ffffffff81181ebb>] ioctl_preallocate+0x89/0x9b
    [ 1082.014778]  [<ffffffff811822d7>] do_vfs_ioctl+0x40a/0x4ea
    [ 1082.015778]  [<ffffffff81176ea7>] ? SYSC_newfstat+0x25/0x2e
    [ 1082.016806]  [<ffffffff8118b4de>] ? __fget_light+0x4d/0x71
    [ 1082.017789]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [ 1082.018706]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    
    This happens because we can recursively acquire the semaphore
    fs_info->delayed_iput_sem when attempting to allocate space to satisfy
    a file write request as shown in the first trace above - when committing
    a transaction we acquire (down_read) the semaphore before running the
    delayed iputs, and when running a delayed iput() we can end up calling
    an inode's eviction handler, which in turn commits another transaction
    and attempts to acquire (down_read) again the semaphore to run more
    delayed iput operations.
    This results in a deadlock because if a task acquires multiple times a
    semaphore it should invoke down_read_nested() with a different lockdep
    class for each level of recursion.
    
    Fix this by simplifying the implementation and use a mutex instead that
    is acquired by the cleaner kthread before it runs the delayed iputs
    instead of always acquiring a semaphore before delayed references are
    run from anywhere.
    
    Fixes: d7c151717a1e (btrfs: Fix NO_SPACE bug caused by delayed-iput)
    Cc: stable@vger.kernel.org   # 4.1+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c5f40dc1f74f..e9c2f8895eab 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1614,7 +1614,7 @@ struct btrfs_fs_info {
 
 	spinlock_t delayed_iput_lock;
 	struct list_head delayed_iputs;
-	struct rw_semaphore delayed_iput_sem;
+	struct mutex cleaner_delayed_iput_mutex;
 
 	/* this protects tree_mod_seq_list */
 	spinlock_t tree_mod_seq_lock;

commit c1a198d9235b9e7d6942027374e44f78ebdcb455
Merge: 48f58ba9cbff 988f1f576d4f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 18 12:44:40 2016 -0800

    Merge branch 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has our usual assortment of fixes and cleanups, but the biggest
      change included is Omar Sandoval's free space tree.  It's not the
      default yet, mounting -o space_cache=v2 enables it and sets a readonly
      compat bit.  The tree can actually be deleted and regenerated if there
      are any problems, but it has held up really well in testing so far.
    
      For very large filesystems (30T+) our existing free space caching code
      can end up taking a huge amount of time during commits.  The new tree
      based code is faster and less work overall to update as the commit
      progresses.
    
      Omar worked on this during the summer and we'll hammer on it in
      production here at FB over the next few months"
    
    * 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (73 commits)
      Btrfs: fix fitrim discarding device area reserved for boot loader's use
      Btrfs: Check metadata redundancy on balance
      btrfs: statfs: report zero available if metadata are exhausted
      btrfs: preallocate path for snapshot creation at ioctl time
      btrfs: allocate root item at snapshot ioctl time
      btrfs: do an allocation earlier during snapshot creation
      btrfs: use smaller type for btrfs_path locks
      btrfs: use smaller type for btrfs_path lowest_level
      btrfs: use smaller type for btrfs_path reada
      btrfs: cleanup, use enum values for btrfs_path reada
      btrfs: constify static arrays
      btrfs: constify remaining structs with function pointers
      btrfs tests: replace whole ops structure for free space tests
      btrfs: use list_for_each_entry* in backref.c
      btrfs: use list_for_each_entry_safe in free-space-cache.c
      btrfs: use list_for_each_entry* in check-integrity.c
      Btrfs: use linux/sizes.h to represent constants
      btrfs: cleanup, remove stray return statements
      btrfs: zero out delayed node upon allocation
      btrfs: pass proper enum type to start_transaction()
      ...

commit b28cf57246d5b797ba725bb033110c247f2c301f
Merge: a3058101c17d a7ca42256d9f
Author: Chris Mason <clm@fb.com>
Date:   Mon Jan 11 06:08:37 2016 -0800

    Merge branch 'misc-cleanups-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit a3058101c17d2825f34a0ab5c37d93ead0f4d9dc
Merge: 511711af91f2 ee592d077161
Author: Chris Mason <clm@fb.com>
Date:   Mon Jan 11 05:59:32 2016 -0800

    Merge branch 'misc-for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5

commit 4fb72bf2e913ca3798afd9e226e2416918936e49
Author: David Sterba <dsterba@suse.com>
Date:   Fri Nov 27 16:31:45 2015 +0100

    btrfs: use smaller type for btrfs_path locks
    
    The values of btrfs_path::locks are 0 to 4, fit into a u8. Let's see:
    
    * overall size of btrfs_path drops down from 136 to 112 (-24 bytes),
    * better packing in a slab page +6 objects
    * the whole structure now fits to 2 cachelines
    * slight decrease in code size:
    
       text    data     bss     dec     hex filename
     938731   43670   23144 1005545   f57e9 fs/btrfs/btrfs.ko.before
     938203   43670   23144 1005017   f55d9 fs/btrfs/btrfs.ko.after
    
    (and the generated assembly does not change much)
    
    The main purpose is to decrease the size of the structure without
    affecting performance. The byte access is usually well behaving accross
    arches, the locks are not accessed frequently and sometimes just
    compared to zero.
    
    Note for further size reduction attempts: the slots could be made u16
    but this might generate worse code on some arches (non-byte and non-int
    access). Also the range of operations on slots is wider compared to
    locks and the potential performance drop should be evaluated first.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 09ee92d9670c..5e0fe0914d54 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -595,7 +595,7 @@ struct btrfs_path {
 	struct extent_buffer *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];
 	/* if there is real range locking, this locks field will change */
-	int locks[BTRFS_MAX_LEVEL];
+	u8 locks[BTRFS_MAX_LEVEL];
 	u8 reada;
 	/* keep some upper locks as we walk down */
 	u8 lowest_level;

commit 7853f15b2aeeb01c587168fc3f7f0ff76a3c9bfd
Author: David Sterba <dsterba@suse.com>
Date:   Fri Nov 27 16:31:42 2015 +0100

    btrfs: use smaller type for btrfs_path lowest_level
    
    The level is 0..7, we can use smaller type. The size of btrfs_path is now
    136 bytes from 144, which is +2 objects that fit into a 4k slab.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e5f9b96fc86f..09ee92d9670c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -598,7 +598,7 @@ struct btrfs_path {
 	int locks[BTRFS_MAX_LEVEL];
 	u8 reada;
 	/* keep some upper locks as we walk down */
-	int lowest_level;
+	u8 lowest_level;
 
 	/*
 	 * set by btrfs_split_item, tells search_slot to keep all locks

commit dccabfad20880bc6c8be21b538df4293506b99f8
Author: David Sterba <dsterba@suse.com>
Date:   Fri Nov 27 16:31:38 2015 +0100

    btrfs: use smaller type for btrfs_path reada
    
    The possible values for reada are all positive and bounded, we can later
    save some bytes by storing it in u8.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a1cf4c813578..e5f9b96fc86f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -596,7 +596,7 @@ struct btrfs_path {
 	int slots[BTRFS_MAX_LEVEL];
 	/* if there is real range locking, this locks field will change */
 	int locks[BTRFS_MAX_LEVEL];
-	int reada;
+	u8 reada;
 	/* keep some upper locks as we walk down */
 	int lowest_level;
 

commit e4058b54d1e442b6b3eca949f0d63d49ba2b020d
Author: David Sterba <dsterba@suse.com>
Date:   Fri Nov 27 16:31:35 2015 +0100

    btrfs: cleanup, use enum values for btrfs_path reada
    
    Replace the integers by enums for better readability. The value 2 does
    not have any meaning since a717531942f488209dded30f6bc648167bcefa72
    "Btrfs: do less aggressive btree readahead" (2009-01-22).
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 99059fcb563e..a1cf4c813578 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -590,6 +590,7 @@ struct btrfs_node {
  * The slots array records the index of the item or block pointer
  * used while walking the tree.
  */
+enum { READA_NONE = 0, READA_BACK, READA_FORWARD };
 struct btrfs_path {
 	struct extent_buffer *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];

commit 4d4ab6d6bc05ba65169de9a5391e6ccbe09d8719
Author: David Sterba <dsterba@suse.com>
Date:   Thu Nov 19 11:42:31 2015 +0100

    btrfs: constify static arrays
    
    There are a few statically initialized arrays that can be made const.
    The remaining (like file_system_type, sysfs attributes or prop handlers)
    do not allow that due to type mismatch when passed to the APIs or
    because the structures are modified through other members.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 35489e7129a7..99059fcb563e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -174,7 +174,7 @@ struct btrfs_ordered_sum;
 /* csum types */
 #define BTRFS_CSUM_TYPE_CRC32	0
 
-static int btrfs_csum_sizes[] = { 4 };
+static const int btrfs_csum_sizes[] = { 4 };
 
 /* four bytes for CRC32 */
 #define BTRFS_EMPTY_DIR_SIZE 0

commit ee22184b53c823f6956314c2815d4068e3820737
Author: Byongho Lee <bhlee.kernel@gmail.com>
Date:   Tue Dec 15 01:42:10 2015 +0900

    Btrfs: use linux/sizes.h to represent constants
    
    We use many constants to represent size and offset value.  And to make
    code readable we use '256 * 1024 * 1024' instead of '268435456' to
    represent '256MB'.  However we can make far more readable with 'SZ_256MB'
    which is defined in the 'linux/sizes.h'.
    
    So this patch replaces 'xxx * 1024 * 1024' kind of expression with
    single 'SZ_xxxMB' if 'xxx' is a power of 2 then 'xxx * SZ_1M' if 'xxx' is
    not a power of 2. And I haven't touched to '4096' & '8192' because it's
    more intuitive than 'SZ_4KB' & 'SZ_8KB'.
    
    Signed-off-by: Byongho Lee <bhlee.kernel@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index eddc461fb964..6202557b694b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -35,6 +35,7 @@
 #include <linux/btrfs.h>
 #include <linux/workqueue.h>
 #include <linux/security.h>
+#include <linux/sizes.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
@@ -196,9 +197,9 @@ static int btrfs_csum_sizes[] = { 4 };
 /* ioprio of readahead is set to idle */
 #define BTRFS_IOPRIO_READA (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_IDLE, 0))
 
-#define BTRFS_DIRTY_METADATA_THRESH	(32 * 1024 * 1024)
+#define BTRFS_DIRTY_METADATA_THRESH	SZ_32M
 
-#define BTRFS_MAX_EXTENT_SIZE (128 * 1024 * 1024)
+#define BTRFS_MAX_EXTENT_SIZE SZ_128M
 
 /*
  * The key defines the order in the tree, and so it also defines (optimal)

commit 9780c4976f5518f805b32fc00ed045b636fe8fa8
Author: Alexandru Moise <00moses.alexander00@gmail.com>
Date:   Sun Oct 18 21:35:41 2015 +0000

    btrfs: switch __btrfs_fs_incompat return type from int to bool
    
    Conform to __btrfs_fs_incompat() cast-to-bool (!!) by explicitly
    returning boolean not int.
    
    Signed-off-by: Alexandru Moise <00moses.alexander00@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 35489e7129a7..eddc461fb964 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4250,7 +4250,7 @@ static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
 #define btrfs_fs_incompat(fs_info, opt) \
 	__btrfs_fs_incompat((fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
 
-static inline int __btrfs_fs_incompat(struct btrfs_fs_info *fs_info, u64 flag)
+static inline bool __btrfs_fs_incompat(struct btrfs_fs_info *fs_info, u64 flag)
 {
 	struct btrfs_super_block *disk_super;
 	disk_super = fs_info->super_copy;

commit 2b3909f8a7fe94e0234850aa9d120cca15b6e1f7
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Sat Dec 19 00:56:05 2015 -0800

    btrfs: use new dedupe data function pointer
    
    Now that the VFS encapsulates the dedupe ioctl, wire up btrfs to it.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dd4733fa882c..b7e4e344e8e0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4024,6 +4024,8 @@ void btrfs_get_block_group_info(struct list_head *groups_list,
 				struct btrfs_ioctl_space_info *space);
 void update_ioctl_balance_args(struct btrfs_fs_info *fs_info, int lock,
 			       struct btrfs_ioctl_balance_args *bargs);
+ssize_t btrfs_dedupe_file_range(struct file *src_file, u64 loff, u64 olen,
+			   struct file *dst_file, u64 dst_loff);
 
 /* file.c */
 int btrfs_auto_defrag_init(void);

commit 511711af91f21d80b27f18b569352d6896562828
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 30 07:52:35 2015 -0800

    btrfs: don't run delayed references while we are creating the free space tree
    
    This is a short term solution to make sure btrfs_run_delayed_refs()
    doesn't change the extent tree while we are scanning it to create the
    free space tree.
    
    Longer term we need to synchronize scanning the block groups one by one,
    similar to what happens during a balance.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d79ba0570c55..9a88d0c69be4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1856,6 +1856,8 @@ struct btrfs_fs_info {
 	 * and will be latter freed. Protected by fs_info->chunk_mutex.
 	 */
 	struct list_head pinned_chunks;
+
+	int creating_free_space_tree;
 };
 
 struct btrfs_subvolume_writers {

commit f0f76413d332d74446d0ee9535a29a900c4f63e4
Merge: a53fe2576955 f7d3d2f99eea
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 23 13:29:09 2015 -0800

    Merge branch 'freespace-4.5' into for-linus-4.5

commit afa427cf9d6ef64e73df68882cbabde0e6a61639
Merge: 4ef7675344d6 35de6db28f26
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 23 13:10:26 2015 -0800

    Merge branch 'cleanup/misc-simplify' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5

commit f7d3d2f99eeaa9f5c111965b1516972f4fc5e449
Merge: 9f9499ae8e64 70f6d82ec73c
Author: Chris Mason <clm@fb.com>
Date:   Fri Dec 18 11:11:10 2015 -0800

    Merge branch 'freespace-tree' into for-linus-4.5
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 70f6d82ec73c3ae2d3adc6853c5bebcd73610097
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:38 2015 -0700

    Btrfs: add free space tree mount option
    
    Now we can finally hook up everything so we can actually use free space
    tree. The free space tree is enabled by passing the space_cache=v2 mount
    option. On the first mount with the this option set, the free space tree
    will be created and the FREE_SPACE_TREE read-only compat bit will be
    set. Any time the filesystem is mounted from then on, we must use the
    free space tree. The clear_cache option will also clear the free space
    tree.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0888c3e2cc7d..ed610f9c04b2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -531,7 +531,10 @@ struct btrfs_super_block {
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_SAFE_SET		0ULL
 #define BTRFS_FEATURE_COMPAT_SAFE_CLEAR		0ULL
-#define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
+
+#define BTRFS_FEATURE_COMPAT_RO_SUPP			\
+	(BTRFS_FEATURE_COMPAT_RO_FREE_SPACE_TREE)
+
 #define BTRFS_FEATURE_COMPAT_RO_SAFE_SET	0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SAFE_CLEAR	0ULL
 
@@ -2203,6 +2206,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)
 #define BTRFS_MOUNT_PANIC_ON_FATAL_ERROR	(1 << 22)
 #define BTRFS_MOUNT_RESCAN_UUID_TREE	(1 << 23)
+#define BTRFS_MOUNT_FREE_SPACE_TREE	(1 << 24)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 #define BTRFS_DEFAULT_MAX_INLINE	(8192)
@@ -3744,6 +3748,7 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->csum_root);
 	kfree(fs_info->quota_root);
 	kfree(fs_info->uuid_root);
+	kfree(fs_info->free_space_root);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
 	security_free_mnt_opts(&fs_info->security_opts);

commit a5ed91828518ab076209266c2bc510adabd078df
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:35 2015 -0700

    Btrfs: implement the free space B-tree
    
    The free space cache has turned out to be a scalability bottleneck on
    large, busy filesystems. When the cache for a lot of block groups needs
    to be written out, we can get extremely long commit times; if this
    happens in the critical section, things are especially bad because we
    block new transactions from happening.
    
    The main problem with the free space cache is that it has to be written
    out in its entirety and is managed in an ad hoc fashion. Using a B-tree
    to store free space fixes this: updates can be done as needed and we get
    all of the benefits of using a B-tree: checksumming, RAID handling,
    well-understood behavior.
    
    With the free space tree, we get commit times that are about the same as
    the no cache case with load times slower than the free space cache case
    but still much faster than the no cache case. Free space is represented
    with extents until it becomes more space-efficient to use bitmaps,
    giving us similar space overhead to the free space cache.
    
    The operations on the free space tree are: adding and removing free
    space, handling the creation and deletion of block groups, and loading
    the free space for a block group. We can also create the free space tree
    by walking the extent tree and clear the free space tree.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0e40d323f4e9..0888c3e2cc7d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1302,8 +1302,20 @@ struct btrfs_block_group_cache {
 	u64 delalloc_bytes;
 	u64 bytes_super;
 	u64 flags;
-	u64 sectorsize;
 	u64 cache_generation;
+	u32 sectorsize;
+
+	/*
+	 * If the free space extent count exceeds this number, convert the block
+	 * group to bitmaps.
+	 */
+	u32 bitmap_high_thresh;
+
+	/*
+	 * If the free space extent count drops below this number, convert the
+	 * block group back to extents.
+	 */
+	u32 bitmap_low_thresh;
 
 	/*
 	 * It is just used for the delayed data space allocation because
@@ -1359,6 +1371,15 @@ struct btrfs_block_group_cache {
 	struct list_head io_list;
 
 	struct btrfs_io_ctl io_ctl;
+
+	/* Lock for free space tree operations. */
+	struct mutex free_space_lock;
+
+	/*
+	 * Does the block group need to be added to the free space tree?
+	 * Protected by free_space_lock.
+	 */
+	int needs_free_space;
 };
 
 /* delayed seq elem */
@@ -1410,6 +1431,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *csum_root;
 	struct btrfs_root *quota_root;
 	struct btrfs_root *uuid_root;
+	struct btrfs_root *free_space_root;
 
 	/* the log root tree is a directory of all the other log roots */
 	struct btrfs_root *log_root_tree;
@@ -3555,6 +3577,9 @@ void btrfs_end_write_no_snapshoting(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			const u64 type);
+u64 add_new_free_space(struct btrfs_block_group_cache *block_group,
+		       struct btrfs_fs_info *info, u64 start, u64 end);
+
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit 208acb8c72d7ace6b672b105502dca0bcb050162
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:34 2015 -0700

    Btrfs: introduce the free space B-tree on-disk format
    
    The on-disk format for the free space tree is straightforward. Each
    block group is represented in the free space tree by a free space info
    item that stores accounting information: whether the free space for this
    block group is stored as bitmaps or extents and how many extents of free
    space exist for this block group (regardless of which format is being
    used in the tree). Extents are (start, FREE_SPACE_EXTENT, length) keys
    with no corresponding item, and bitmaps instead have the
    FREE_SPACE_BITMAP type and have a bitmap item attached, which is just an
    array of bytes.
    
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 60df67efef96..0e40d323f4e9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -96,6 +96,9 @@ struct btrfs_ordered_sum;
 /* for storing items that use the BTRFS_UUID_KEY* types */
 #define BTRFS_UUID_TREE_OBJECTID 9ULL
 
+/* tracks free space in block groups. */
+#define BTRFS_FREE_SPACE_TREE_OBJECTID 10ULL
+
 /* for storing balance parameters in the root tree */
 #define BTRFS_BALANCE_OBJECTID -4ULL
 
@@ -500,6 +503,8 @@ struct btrfs_super_block {
  * Compat flags that we support.  If any incompat flags are set other than the
  * ones specified below then we will fail to mount
  */
+#define BTRFS_FEATURE_COMPAT_RO_FREE_SPACE_TREE	(1ULL << 0)
+
 #define BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF	(1ULL << 0)
 #define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(1ULL << 1)
 #define BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS	(1ULL << 2)
@@ -1061,6 +1066,13 @@ struct btrfs_block_group_item {
 	__le64 flags;
 } __attribute__ ((__packed__));
 
+struct btrfs_free_space_info {
+	__le32 extent_count;
+	__le32 flags;
+} __attribute__ ((__packed__));
+
+#define BTRFS_FREE_SPACE_USING_BITMAPS (1ULL << 0)
+
 #define BTRFS_QGROUP_LEVEL_SHIFT		48
 static inline u64 btrfs_qgroup_level(u64 qgroupid)
 {
@@ -2058,6 +2070,27 @@ struct btrfs_ioctl_defrag_range_args {
  */
 #define BTRFS_BLOCK_GROUP_ITEM_KEY 192
 
+/*
+ * Every block group is represented in the free space tree by a free space info
+ * item, which stores some accounting information. It is keyed on
+ * (block_group_start, FREE_SPACE_INFO, block_group_length).
+ */
+#define BTRFS_FREE_SPACE_INFO_KEY 198
+
+/*
+ * A free space extent tracks an extent of space that is free in a block group.
+ * It is keyed on (start, FREE_SPACE_EXTENT, length).
+ */
+#define BTRFS_FREE_SPACE_EXTENT_KEY 199
+
+/*
+ * When a block group becomes very fragmented, we convert it to use bitmaps
+ * instead of extents. A free space bitmap is keyed on
+ * (start, FREE_SPACE_BITMAP, length); the corresponding item is a bitmap with
+ * (length / sectorsize) bits.
+ */
+#define BTRFS_FREE_SPACE_BITMAP_KEY 200
+
 #define BTRFS_DEV_EXTENT_KEY	204
 #define BTRFS_DEV_ITEM_KEY	216
 #define BTRFS_CHUNK_ITEM_KEY	228
@@ -2458,6 +2491,11 @@ BTRFS_SETGET_FUNCS(disk_block_group_flags,
 BTRFS_SETGET_STACK_FUNCS(block_group_flags,
 			struct btrfs_block_group_item, flags, 64);
 
+/* struct btrfs_free_space_info */
+BTRFS_SETGET_FUNCS(free_space_extent_count, struct btrfs_free_space_info,
+		   extent_count, 32);
+BTRFS_SETGET_FUNCS(free_space_flags, struct btrfs_free_space_info, flags, 32);
+
 /* struct btrfs_inode_ref */
 BTRFS_SETGET_FUNCS(inode_ref_name_len, struct btrfs_inode_ref, name_len, 16);
 BTRFS_SETGET_FUNCS(inode_ref_index, struct btrfs_inode_ref, index, 64);

commit 73fa48b674e819098c3bafc47618d0e2868191e5
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:33 2015 -0700

    Btrfs: refactor caching_thread()
    
    We're also going to load the free space tree from caching_thread(), so
    we should refactor some of the common code.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 42c41dc68cbb..60df67efef96 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1262,6 +1262,9 @@ struct btrfs_caching_control {
 	atomic_t count;
 };
 
+/* Once caching_thread() finds this much free space, it will wake up waiters. */
+#define CACHING_CTL_WAKE_UP (1024 * 1024 * 2)
+
 struct btrfs_io_ctl {
 	void *cur, *orig;
 	struct page *page;

commit 1abfbcdf56d9485f050149bc4968c1609f9a0773
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:32 2015 -0700

    Btrfs: add helpers for read-only compat bits
    
    We're finally going to add one of these for the free space tree, so
    let's add the same nice helpers that we have for the incompat bits.
    While we're add it, also add helpers to clear the bits.
    
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 938efe33be80..42c41dc68cbb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4100,6 +4100,30 @@ static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
 	}
 }
 
+#define btrfs_clear_fs_incompat(__fs_info, opt) \
+	__btrfs_clear_fs_incompat((__fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
+
+static inline void __btrfs_clear_fs_incompat(struct btrfs_fs_info *fs_info,
+					     u64 flag)
+{
+	struct btrfs_super_block *disk_super;
+	u64 features;
+
+	disk_super = fs_info->super_copy;
+	features = btrfs_super_incompat_flags(disk_super);
+	if (features & flag) {
+		spin_lock(&fs_info->super_lock);
+		features = btrfs_super_incompat_flags(disk_super);
+		if (features & flag) {
+			features &= ~flag;
+			btrfs_set_super_incompat_flags(disk_super, features);
+			btrfs_info(fs_info, "clearing %llu feature flag",
+					 flag);
+		}
+		spin_unlock(&fs_info->super_lock);
+	}
+}
+
 #define btrfs_fs_incompat(fs_info, opt) \
 	__btrfs_fs_incompat((fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
 
@@ -4110,6 +4134,64 @@ static inline int __btrfs_fs_incompat(struct btrfs_fs_info *fs_info, u64 flag)
 	return !!(btrfs_super_incompat_flags(disk_super) & flag);
 }
 
+#define btrfs_set_fs_compat_ro(__fs_info, opt) \
+	__btrfs_set_fs_compat_ro((__fs_info), BTRFS_FEATURE_COMPAT_RO_##opt)
+
+static inline void __btrfs_set_fs_compat_ro(struct btrfs_fs_info *fs_info,
+					    u64 flag)
+{
+	struct btrfs_super_block *disk_super;
+	u64 features;
+
+	disk_super = fs_info->super_copy;
+	features = btrfs_super_compat_ro_flags(disk_super);
+	if (!(features & flag)) {
+		spin_lock(&fs_info->super_lock);
+		features = btrfs_super_compat_ro_flags(disk_super);
+		if (!(features & flag)) {
+			features |= flag;
+			btrfs_set_super_compat_ro_flags(disk_super, features);
+			btrfs_info(fs_info, "setting %llu ro feature flag",
+				   flag);
+		}
+		spin_unlock(&fs_info->super_lock);
+	}
+}
+
+#define btrfs_clear_fs_compat_ro(__fs_info, opt) \
+	__btrfs_clear_fs_compat_ro((__fs_info), BTRFS_FEATURE_COMPAT_RO_##opt)
+
+static inline void __btrfs_clear_fs_compat_ro(struct btrfs_fs_info *fs_info,
+					      u64 flag)
+{
+	struct btrfs_super_block *disk_super;
+	u64 features;
+
+	disk_super = fs_info->super_copy;
+	features = btrfs_super_compat_ro_flags(disk_super);
+	if (features & flag) {
+		spin_lock(&fs_info->super_lock);
+		features = btrfs_super_compat_ro_flags(disk_super);
+		if (features & flag) {
+			features &= ~flag;
+			btrfs_set_super_compat_ro_flags(disk_super, features);
+			btrfs_info(fs_info, "clearing %llu ro feature flag",
+				   flag);
+		}
+		spin_unlock(&fs_info->super_lock);
+	}
+}
+
+#define btrfs_fs_compat_ro(fs_info, opt) \
+	__btrfs_fs_compat_ro((fs_info), BTRFS_FEATURE_COMPAT_RO_##opt)
+
+static inline int __btrfs_fs_compat_ro(struct btrfs_fs_info *fs_info, u64 flag)
+{
+	struct btrfs_super_block *disk_super;
+	disk_super = fs_info->super_copy;
+	return !!(btrfs_super_compat_ro_flags(disk_super) & flag);
+}
+
 /*
  * Call btrfs_abort_transaction as early as possible when an error condition is
  * detected, that way the exact line number is reported.

commit 04b38d601239b4d9be641b412cf4b7456a041c67
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 3 12:59:50 2015 +0100

    vfs: pull btrfs clone API to vfs layer
    
    The btrfs clone ioctls are now adopted by other file systems, with NFS
    and CIFS already having support for them, and XFS being under active
    development.  To avoid growth of various slightly incompatible
    implementations, add one to the VFS.  Note that clones are different from
    file copies in several ways:
    
     - they are atomic vs other writers
     - they support whole file clones
     - they support 64-bit legth clones
     - they do not allow partial success (aka short writes)
     - clones are expected to be a fast metadata operation
    
    Because of that it would be rather cumbersome to try to piggyback them on
    top of the recent clone_file_range infrastructure.  The converse isn't
    true and the clone_file_range system call could try clone file range as
    a first attempt to copy, something that further patches will enable.
    
    Based on earlier work from Peng Tao.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ede7277c167f..dd4733fa882c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4025,7 +4025,6 @@ void btrfs_get_block_group_info(struct list_head *groups_list,
 void update_ioctl_balance_args(struct btrfs_fs_info *fs_info, int lock,
 			       struct btrfs_ioctl_balance_args *bargs);
 
-
 /* file.c */
 int btrfs_auto_defrag_init(void);
 void btrfs_auto_defrag_exit(void);
@@ -4058,6 +4057,8 @@ int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
 ssize_t btrfs_copy_file_range(struct file *file_in, loff_t pos_in,
 			      struct file *file_out, loff_t pos_out,
 			      size_t len, unsigned int flags);
+int btrfs_clone_file_range(struct file *file_in, loff_t pos_in,
+			   struct file *file_out, loff_t pos_out, u64 len);
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,

commit 3042460136bee7bf48860f16a391e6d75f2d0d5c
Author: David Sterba <dsterba@suse.com>
Date:   Fri Nov 27 19:27:11 2015 +0100

    btrfs: remove wait from struct btrfs_delalloc_work
    
    The value is 0 and never changes, we can propagate the value, remove
    wait and the implied dead code.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cb540251f666..a61c53bce162 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3902,7 +3902,6 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 /* inode.c */
 struct btrfs_delalloc_work {
 	struct inode *inode;
-	int wait;
 	int delay_iput;
 	struct completion completion;
 	struct list_head list;

commit 651d494a678e48712f784e8f26450c34b5c61015
Author: David Sterba <dsterba@suse.com>
Date:   Fri Nov 27 19:24:16 2015 +0100

    btrfs: sink parameter wait to btrfs_alloc_delalloc_work
    
    There's only one caller and single value, we can propagate it down to
    the callee and remove the unused parameter.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8c58191249cc..cb540251f666 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3910,7 +3910,7 @@ struct btrfs_delalloc_work {
 };
 
 struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,
-						    int wait, int delay_iput);
+						    int delay_iput);
 void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
 
 struct extent_map *btrfs_get_extent_fiemap(struct inode *inode, struct page *page,

commit 3db11b2eecc02dc0eee943e71822c6d929281aa7
Author: Zach Brown <zab@redhat.com>
Date:   Tue Nov 10 16:53:32 2015 -0500

    btrfs: add .copy_file_range file operation
    
    This rearranges the existing COPY_RANGE ioctl implementation so that the
    .copy_file_range file operation can call the core loop that copies file
    data extent items.
    
    The extent copying loop is lifted up into its own function.  It retains
    the core btrfs error checks that should be shared.
    
    Signed-off-by: Zach Brown <zab@redhat.com>
    [Anna Schumaker: Make flags an unsigned int,
                     Check for COPY_FR_REFLINK]
    Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 35489e7129a7..ede7277c167f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4055,6 +4055,9 @@ int btrfs_dirty_pages(struct btrfs_root *root, struct inode *inode,
 		      loff_t pos, size_t write_bytes,
 		      struct extent_state **cached);
 int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
+ssize_t btrfs_copy_file_range(struct file *file_in, loff_t pos_in,
+			      struct file *file_out, loff_t pos_out,
+			      size_t len, unsigned int flags);
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,

commit 80e0c505b22e64ab1787285b182a1e8395e53991
Merge: 7e4b9359f483 dba72cb30b6a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 27 15:45:45 2015 -0800

    Merge branch 'for-linus-4.4' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This has Mark Fasheh's patches to fix quota accounting during subvol
      deletion, which we've been working on for a while now.  The patch is
      pretty small but it's a key fix.
    
      Otherwise it's a random assortment"
    
    * 'for-linus-4.4' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: fix balance range usage filters in 4.4-rc
      btrfs: qgroup: account shared subtree during snapshot delete
      Btrfs: use btrfs_get_fs_root in resolve_indirect_ref
      btrfs: qgroup: fix quota disable during rescan
      Btrfs: fix race between cleaner kthread and space cache writeout
      Btrfs: fix scrub preventing unused block groups from being deleted
      Btrfs: fix race between scrub and block group deletion
      btrfs: fix rcu warning during device replace
      btrfs: Continue replace when set_block_ro failed
      btrfs: fix clashing number of the enhanced balance usage filter
      Btrfs: fix the number of transaction units needed to remove a block group
      Btrfs: use global reserve when deleting unused block group after ENOSPC
      Btrfs: tests: checking for NULL instead of IS_ERR()
      btrfs: fix signed overflows in btrfs_sync_file

commit 758f2dfcf8a249b1f1510aa32e625c2ec20642a3
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Nov 19 11:45:48 2015 +0000

    Btrfs: fix scrub preventing unused block groups from being deleted
    
    Currently scrub can race with the cleaner kthread when the later attempts
    to delete an unused block group, and the result is preventing the cleaner
    kthread from ever deleting later the block group - unless the block group
    becomes used and unused again. The following diagram illustrates that
    race:
    
                  CPU 1                                 CPU 2
    
     cleaner kthread
       btrfs_delete_unused_bgs()
    
         gets block group X from
         fs_info->unused_bgs and
         removes it from that list
    
                                                 scrub_enumerate_chunks()
    
                                                   searches device tree using
                                                   its commit root
    
                                                   finds device extent for
                                                   block group X
    
                                                   gets block group X from the tree
                                                   fs_info->block_group_cache_tree
                                                   (via btrfs_lookup_block_group())
    
                                                   sets bg X to RO
    
         sees the block group is
         already RO and therefore
         doesn't delete it nor adds
         it back to unused list
    
    So fix this by making scrub add the block group again to the list of
    unused block groups if the block group is still unused when it finished
    scrubbing it and it hasn't been removed already.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d88994f71eae..a0165c6e6243 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3416,6 +3416,7 @@ int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 struct btrfs_fs_info *info,
 						 u64 bytenr);
+void btrfs_get_block_group(struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int get_block_group_index(struct btrfs_block_group_cache *cache);
 struct extent_buffer *btrfs_alloc_tree_block(struct btrfs_trans_handle *trans,

commit 7fd01182d1a1412cd44a5474b9aa93548d4a73ae
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 13 23:57:17 2015 +0000

    Btrfs: fix the number of transaction units needed to remove a block group
    
    We were using only 1 transaction unit when attempting to delete an unused
    block group but in reality we need 3 + N units, where N corresponds to the
    number of stripes. We were accounting only for the addition of the orphan
    item (for the block group's free space cache inode) but we were not
    accounting that we need to delete one block group item from the extent
    tree, one free space item from the tree of tree roots and N device extent
    items from the device tree.
    
    While one unit is not enough, it worked most of the time because for each
    single unit we are too pessimistic and assume an entire tree path, with
    the highest possible heigth (8), needs to be COWed with eventual node
    splits at every possible level in the tree, so there was usually enough
    reserved space for removing all the items and adding the orphan item.
    
    However after adding the orphan item, writepages() can by called by the VM
    subsystem against the btree inode when we are under memory pressure, which
    causes writeback to start for the nodes we COWed before, this forces the
    operation to remove the free space item to COW again some (or all of) the
    same nodes (in the tree of tree roots). Even without writepages() being
    called, we could fail with ENOSPC because these items are located in
    multiple trees and one of them might have a higher heigth and require
    node/leaf splits at many levels, exhausting all the reserved space before
    removing all the items and adding the orphan.
    
    In the kernel 4.0 release, commit 3d84be799194 ("Btrfs: fix BUG_ON in
    btrfs_orphan_add() when delete unused block group"), we attempted to fix
    a BUG_ON due to ENOSPC when trying to add the orphan item by making the
    cleaner kthread reserve one transaction unit before attempting to remove
    the block group, but this was not enough. We had a couple user reports
    still hitting the same BUG_ON after 4.0, like Stefan Priebe's report on
    a 4.2-rc6 kernel for example:
    
        http://www.spinics.net/lists/linux-btrfs/msg46070.html
    
    So fix this by reserving all the necessary units of metadata.
    
    Reported-by: Stefan Priebe <s.priebe@profihost.ag>
    Fixes: 3d84be799194 ("Btrfs: fix BUG_ON in btrfs_orphan_add() when delete unused block group")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1573be6f9518..d88994f71eae 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3480,7 +3480,8 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 type, u64 chunk_objectid, u64 chunk_offset,
 			   u64 size);
 struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
-				struct btrfs_fs_info *fs_info);
+				struct btrfs_fs_info *fs_info,
+				const u64 chunk_offset);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start,
 			     struct extent_map *em);

commit 8eab77ff167b62760d878f1d19312eb9f7d4c176
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 13 23:57:16 2015 +0000

    Btrfs: use global reserve when deleting unused block group after ENOSPC
    
    It's possible to reach a state where the cleaner kthread isn't able to
    start a transaction to delete an unused block group due to lack of enough
    free metadata space and due to lack of unallocated device space to allocate
    a new metadata block group as well. If this happens try to use space from
    the global block group reserve just like we do for unlink operations, so
    that we don't reach a permanent state where starting a transaction for
    filesystem operations (file creation, renames, etc) keeps failing with
    -ENOSPC. Such an unfortunate state was observed on a machine where over
    a dozen unused data block groups existed and the cleaner kthread was
    failing to delete them due to ENOSPC error when attempting to start a
    transaction, and even running balance with a -dusage=0 filter failed with
    ENOSPC as well. Also unmounting and mounting again the filesystem didn't
    help. Allowing the cleaner kthread to use the global block reserve to
    delete the unused data block groups fixed the problem.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a2e73f6053a8..1573be6f9518 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3479,6 +3479,8 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, u64 bytes_used,
 			   u64 type, u64 chunk_objectid, u64 chunk_offset,
 			   u64 size);
+struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(
+				struct btrfs_fs_info *fs_info);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start,
 			     struct extent_map *em);

commit ad804a0b2a769a0eed29015c53fe395449c09d13
Merge: ab9f2faf8f40 5f2a2d5d423d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 7 14:32:45 2015 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Merge second patch-bomb from Andrew Morton:
    
     - most of the rest of MM
    
     - procfs
    
     - lib/ updates
    
     - printk updates
    
     - bitops infrastructure tweaks
    
     - checkpatch updates
    
     - nilfs2 update
    
     - signals
    
     - various other misc bits: coredump, seqfile, kexec, pidns, zlib, ipc,
       dma-debug, dma-mapping, ...
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (102 commits)
      ipc,msg: drop dst nil validation in copy_msg
      include/linux/zutil.h: fix usage example of zlib_adler32()
      panic: release stale console lock to always get the logbuf printed out
      dma-debug: check nents in dma_sync_sg*
      dma-mapping: tidy up dma_parms default handling
      pidns: fix set/getpriority and ioprio_set/get in PRIO_USER mode
      kexec: use file name as the output message prefix
      fs, seqfile: always allow oom killer
      seq_file: reuse string_escape_str()
      fs/seq_file: use seq_* helpers in seq_hex_dump()
      coredump: change zap_threads() and zap_process() to use for_each_thread()
      coredump: ensure all coredumping tasks have SIGNAL_GROUP_COREDUMP
      signal: remove jffs2_garbage_collect_thread()->allow_signal(SIGCONT)
      signal: introduce kernel_signal_stop() to fix jffs2_garbage_collect_thread()
      signal: turn dequeue_signal_lock() into kernel_dequeue_signal()
      signals: kill block_all_signals() and unblock_all_signals()
      nilfs2: fix gcc uninitialized-variable warnings in powerpc build
      nilfs2: fix gcc unused-but-set-variable warnings
      MAINTAINERS: nilfs2: add header file for tracing
      nilfs2: add tracepoints for analyzing reading and writing metadata files
      ...

commit c62d25556be6c965dc14288e796a576e8e39a7e9
Author: Michal Hocko <mhocko@suse.com>
Date:   Fri Nov 6 16:28:49 2015 -0800

    mm, fs: introduce mapping_gfp_constraint()
    
    There are many places which use mapping_gfp_mask to restrict a more
    generic gfp mask which would be used for allocations which are not
    directly related to the page cache but they are performed in the same
    context.
    
    Let's introduce a helper function which makes the restriction explicit and
    easier to track.  This patch doesn't introduce any functional changes.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Suggested-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 938efe33be80..eb90f0f1a124 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3316,7 +3316,7 @@ static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
 
 static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 {
-	return mapping_gfp_mask(mapping) & ~__GFP_FS;
+	return mapping_gfp_constraint(mapping, ~__GFP_FS);
 }
 
 /* extent-tree.c */

commit 5846a3c26873e86b034c702a8bc202aa76082369
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Oct 26 14:11:18 2015 +0800

    btrfs: qgroup: Fix a race in delayed_ref which leads to abort trans
    
    Between btrfs_allocerved_file_extent() and
    btrfs_add_delayed_qgroup_reserve(), there is a window that delayed_refs
    are run and delayed ref head maybe freed before
    btrfs_add_delayed_qgroup_reserve().
    
    This will cause btrfs_dad_delayed_qgroup_reserve() to return -ENOENT,
    and cause transaction to be aborted.
    
    This patch will record qgroup reserve space info into delayed_ref_head
    at btrfs_add_delayed_ref(), to eliminate the race window.
    
    Reported-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4001585ec434..a2e73f6053a8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3430,7 +3430,8 @@ void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
 int btrfs_alloc_reserved_file_extent(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root,
 				     u64 root_objectid, u64 owner,
-				     u64 offset, struct btrfs_key *ins);
+				     u64 offset, u64 ram_bytes,
+				     struct btrfs_key *ins);
 int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root,
 				   u64 root_objectid, u64 owner, u64 offset,

commit bc3094673f22d00794a8606200788e411b4ec80d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 20 18:22:13 2015 +0200

    btrfs: extend balance filter usage to take minimum and maximum
    
    Similar to the 'limit' filter, we can enhance the 'usage' filter to
    accept a range. The change is backward compatible, the range is applied
    only in connection with the BTRFS_BALANCE_ARGS_USAGE_RANGE flag.
    
    We don't have a usecase yet, the current syntax has been sufficient. The
    enhancement should provide parity with other range-like filters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8ccbf4317a4a..4001585ec434 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -823,8 +823,18 @@ struct btrfs_disk_balance_args {
 	 */
 	__le64 profiles;
 
-	/* usage filter */
-	__le64 usage;
+	/*
+	 * usage filter
+	 * BTRFS_BALANCE_ARGS_USAGE with a single value means '0..N'
+	 * BTRFS_BALANCE_ARGS_USAGE_RANGE - range syntax, min..max
+	 */
+	union {
+		__le64 usage;
+		struct {
+			__le32 usage_min;
+			__le32 usage_max;
+		};
+	};
 
 	/* devid filter */
 	__le64 devid;

commit dee32d0ac3719ef8d640efaf0884111df444730f
Author: Gabríel Arthúr Pétursson <gabriel@system.is>
Date:   Mon Sep 28 22:32:41 2015 +0000

    btrfs: add balance filter for stripes
    
    Balance block groups which have the given number of stripes, defined by
    a range min..max. This is useful to selectively rebalance only chunks
    that do not span enough devices, applies to RAID0/10/5/6.
    
    Signed-off-by: Gabríel Arthúr Pétursson <gabriel@system.is>
    [ renamed bargs members, added to the UAPI, wrote the changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 460cd69b405e..8ccbf4317a4a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -859,7 +859,14 @@ struct btrfs_disk_balance_args {
 		};
 	};
 
-	__le64 unused[7];
+	/*
+	 * Process chunks that cross stripes_min..stripes_max devices,
+	 * BTRFS_BALANCE_ARGS_STRIPES_RANGE
+	 */
+	__le32 stripes_min;
+	__le32 stripes_max;
+
+	__le64 unused[6];
 } __attribute__ ((__packed__));
 
 /*

commit 12907fc79818a62a2478f84f7795afa774bf7f9c
Author: David Sterba <dsterba@suse.com>
Date:   Sat Oct 10 17:16:50 2015 +0200

    btrfs: extend balance filter limit to take minimum and maximum
    
    The 'limit' filter is underdesigned, it should have been a range for
    [min,max], with some relaxed semantics when one of the bounds is
    missing. Besides that, using a full u64 for a single value is a waste of
    bytes.
    
    Let's fix both by extending the use of the u64 bytes for the [min,max]
    range. This can be done in a backward compatible way, the range will be
    interpreted only if the appropriate flag is set
    (BTRFS_BALANCE_ARGS_LIMIT_RANGE).
    
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3fa3c3b7bb66..460cd69b405e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -846,8 +846,18 @@ struct btrfs_disk_balance_args {
 	/* BTRFS_BALANCE_ARGS_* */
 	__le64 flags;
 
-	/* BTRFS_BALANCE_ARGS_LIMIT value */
-	__le64 limit;
+	/*
+	 * BTRFS_BALANCE_ARGS_LIMIT with value 'limit'
+	 * BTRFS_BALANCE_ARGS_LIMIT_RANGE - the extend version can use minimum
+	 * and maximum
+	 */
+	union {
+		__le64 limit;
+		struct {
+			__le32 limit_min;
+			__le32 limit_max;
+		};
+	};
 
 	__le64 unused[7];
 } __attribute__ ((__packed__));

commit b06c4bf5c874a57254b197f53ddf588e7a24a2bf
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Oct 23 07:52:54 2015 +0100

    Btrfs: fix regression running delayed references when using qgroups
    
    In the kernel 4.2 merge window we had a big changes to the implementation
    of delayed references and qgroups which made the no_quota field of delayed
    references not used anymore. More specifically the no_quota field is not
    used anymore as of:
    
      commit 0ed4792af0e8 ("btrfs: qgroup: Switch to new extent-oriented qgroup mechanism.")
    
    Leaving the no_quota field actually prevents delayed references from
    getting merged, which in turn cause the following BUG_ON(), at
    fs/btrfs/extent-tree.c, to be hit when qgroups are enabled:
    
      static int run_delayed_tree_ref(...)
      {
         (...)
         BUG_ON(node->ref_mod != 1);
         (...)
      }
    
    This happens on a scenario like the following:
    
      1) Ref1 bytenr X, action = BTRFS_ADD_DELAYED_REF, no_quota = 1, added.
    
      2) Ref2 bytenr X, action = BTRFS_DROP_DELAYED_REF, no_quota = 0, added.
         It's not merged with Ref1 because Ref1->no_quota != Ref2->no_quota.
    
      3) Ref3 bytenr X, action = BTRFS_ADD_DELAYED_REF, no_quota = 1, added.
         It's not merged with the reference at the tail of the list of refs
         for bytenr X because the reference at the tail, Ref2 is incompatible
         due to Ref2->no_quota != Ref3->no_quota.
    
      4) Ref4 bytenr X, action = BTRFS_DROP_DELAYED_REF, no_quota = 0, added.
         It's not merged with the reference at the tail of the list of refs
         for bytenr X because the reference at the tail, Ref3 is incompatible
         due to Ref3->no_quota != Ref4->no_quota.
    
      5) We run delayed references, trigger merging of delayed references,
         through __btrfs_run_delayed_refs() -> btrfs_merge_delayed_refs().
    
      6) Ref1 and Ref3 are merged as Ref1->no_quota = Ref3->no_quota and
         all other conditions are satisfied too. So Ref1 gets a ref_mod
         value of 2.
    
      7) Ref2 and Ref4 are merged as Ref2->no_quota = Ref4->no_quota and
         all other conditions are satisfied too. So Ref2 gets a ref_mod
         value of 2.
    
      8) Ref1 and Ref2 aren't merged, because they have different values
         for their no_quota field.
    
      9) Delayed reference Ref1 is picked for running (select_delayed_ref()
         always prefers references with an action == BTRFS_ADD_DELAYED_REF).
         So run_delayed_tree_ref() is called for Ref1 which triggers the
         BUG_ON because Ref1->red_mod != 1 (equals 2).
    
    So fix this by removing the no_quota field, as it's not used anymore as
    of commit 0ed4792af0e8 ("btrfs: qgroup: Switch to new extent-oriented
    qgroup mechanism.").
    
    The use of no_quota was also buggy in at least two places:
    
    1) At delayed-refs.c:btrfs_add_delayed_tree_ref() - we were setting
       no_quota to 0 instead of 1 when the following condition was true:
       is_fstree(ref_root) || !fs_info->quota_enabled
    
    2) At extent-tree.c:__btrfs_inc_extent_ref() - we were attempting to
       reset a node's no_quota when the condition "!is_fstree(root_objectid)
       || !root->fs_info->quota_enabled" was true but we did it only in
       an unused local stack variable, that is, we never reset the no_quota
       value in the node itself.
    
    This fixes the remainder of problems several people have been having when
    running delayed references, mostly while a balance is running in parallel,
    on a 4.2+ kernel.
    
    Very special thanks to Stéphane Lesimple for helping debugging this issue
    and testing this fix on his multi terabyte filesystem (which took more
    than one day to balance alone, plus fsck, etc).
    
    Also, this fixes deadlock issue when using the clone ioctl with qgroups
    enabled, as reported by Elias Probst in the mailing list. The deadlock
    happens because after calling btrfs_insert_empty_item we have our path
    holding a write lock on a leaf of the fs/subvol tree and then before
    releasing the path we called check_ref() which did backref walking, when
    qgroups are enabled, and tried to read lock the same leaf. The trace for
    this case is the following:
    
      INFO: task systemd-nspawn:6095 blocked for more than 120 seconds.
      (...)
      Call Trace:
        [<ffffffff86999201>] schedule+0x74/0x83
        [<ffffffff863ef64c>] btrfs_tree_read_lock+0xc0/0xea
        [<ffffffff86137ed7>] ? wait_woken+0x74/0x74
        [<ffffffff8639f0a7>] btrfs_search_old_slot+0x51a/0x810
        [<ffffffff863a129b>] btrfs_next_old_leaf+0xdf/0x3ce
        [<ffffffff86413a00>] ? ulist_add_merge+0x1b/0x127
        [<ffffffff86411688>] __resolve_indirect_refs+0x62a/0x667
        [<ffffffff863ef546>] ? btrfs_clear_lock_blocking_rw+0x78/0xbe
        [<ffffffff864122d3>] find_parent_nodes+0xaf3/0xfc6
        [<ffffffff86412838>] __btrfs_find_all_roots+0x92/0xf0
        [<ffffffff864128f2>] btrfs_find_all_roots+0x45/0x65
        [<ffffffff8639a75b>] ? btrfs_get_tree_mod_seq+0x2b/0x88
        [<ffffffff863e852e>] check_ref+0x64/0xc4
        [<ffffffff863e9e01>] btrfs_clone+0x66e/0xb5d
        [<ffffffff863ea77f>] btrfs_ioctl_clone+0x48f/0x5bb
        [<ffffffff86048a68>] ? native_sched_clock+0x28/0x77
        [<ffffffff863ed9b0>] btrfs_ioctl+0xabc/0x25cb
      (...)
    
    The problem goes away by eleminating check_ref(), which no longer is
    needed as its purpose was to get a value for the no_quota field of
    a delayed reference (this patch removes the no_quota field as mentioned
    earlier).
    
    Reported-by: Stéphane Lesimple <stephane_btrfs@lesimple.fr>
    Tested-by: Stéphane Lesimple <stephane_btrfs@lesimple.fr>
    Reported-by: Elias Probst <mail@eliasprobst.eu>
    Reported-by: Peter Becker <floyd.net@gmail.com>
    Reported-by: Malte Schröder <malte@tnxip.de>
    Reported-by: Derek Dongray <derek@valedon.co.uk>
    Reported-by: Erkki Seppala <flux-btrfs@inside.org>
    Cc: stable@vger.kernel.org  # 4.2+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bc3c711e82f2..3fa3c3b7bb66 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3422,7 +3422,7 @@ int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,
-		      u64 owner, u64 offset, int no_quota);
+		      u64 owner, u64 offset);
 
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len,
 			       int delalloc);
@@ -3435,7 +3435,7 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,
-			 u64 root_objectid, u64 owner, u64 offset, int no_quota);
+			 u64 root_objectid, u64 owner, u64 offset);
 
 int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);

commit a9e6d153563d2ed69c6cd7fb4fa5ce4ca7c712eb
Merge: 56fa9d0762ed 0584f718ed1f
Author: Chris Mason <clm@fb.com>
Date:   Wed Oct 21 19:00:38 2015 -0700

    Merge branch 'allocator-fixes' into for-linus-4.4
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit c759c4e16179e47e099f491011e6acd7858f8625
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Oct 2 15:25:10 2015 -0400

    Btrfs: don't keep trying to build clusters if we are fragmented
    
    If we are extremely fragmented then we won't be able to create a free_cluster.
    So if this happens set last_ptr->fragmented so that all future allcations will
    give up trying to create a cluster.  When we unpin extents we will unset
    ->fragmented if we free up a sufficient amount of space in a block group.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 78a8f56c7e88..ced08c9608e2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1232,6 +1232,9 @@ struct btrfs_free_cluster {
 	/* first extent starting offset */
 	u64 window_start;
 
+	/* We did a full search and couldn't create a cluster */
+	bool fragmented;
+
 	struct btrfs_block_group_cache *block_group;
 	/*
 	 * when a cluster is allocated from a block group, we put the

commit 4f4db2174d8d6cdc093cbb79d17fbfe0f4d9fbde
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue Sep 29 11:40:47 2015 -0400

    Btrfs: keep track of max_extent_size per space_info
    
    When we are heavily fragmented we can induce a lot of latency trying to make an
    allocation happen that is simply not going to happen.  Thankfully we keep track
    of our max_extent_size when going through the allocator, so if we get to the
    point where we are exiting find_free_extent with ENOSPC then set our
    space_info->max_extent_size so we can keep future allocations from having to pay
    this cost.  We reset the max_extent_size whenever we release pinned bytes back
    into this space info so we can redo all the work.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 16384231db82..78a8f56c7e88 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1154,6 +1154,10 @@ struct btrfs_space_info {
 				   delalloc/allocations */
 	u64 bytes_readonly;	/* total bytes that are read only */
 
+	u64 max_extent_size;	/* This will hold the maximum extent size of
+				   the space info if we had an ENOSPC in the
+				   allocator. */
+
 	unsigned int full:1;	/* indicates that we cannot allocate any more
 				   chunks for this space */
 	unsigned int chunk_alloc:1;	/* set if we are allocating a chunk */

commit d0bd456074dca089579818312da7cbe726ad2ff9
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Sep 23 14:54:14 2015 -0400

    Btrfs: add fragment=* debug mount option
    
    In tracking down these weird bitmap problems it was helpful to artificially
    create an extremely fragmented file system.  These mount options let us either
    fragment data or metadata or both.  With these options I could reproduce all
    sorts of weird latencies and hangs that occur under extreme fragmentation and
    get them fixed.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 49bc792108b9..16384231db82 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2145,6 +2145,8 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)
 #define BTRFS_MOUNT_PANIC_ON_FATAL_ERROR	(1 << 22)
 #define BTRFS_MOUNT_RESCAN_UUID_TREE	(1 << 23)
+#define BTRFS_MOUNT_FRAGMENT_DATA	(1 << 24)
+#define BTRFS_MOUNT_FRAGMENT_METADATA	(1 << 25)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 #define BTRFS_DEFAULT_MAX_INLINE	(8192)
@@ -2169,6 +2171,18 @@ struct btrfs_ioctl_defrag_range_args {
 	btrfs_clear_opt(root->fs_info->mount_opt, opt);			\
 }
 
+#ifdef CONFIG_BTRFS_DEBUG
+static inline int
+btrfs_should_fragment_free_space(struct btrfs_root *root,
+				 struct btrfs_block_group_cache *block_group)
+{
+	return (btrfs_test_opt(root, FRAGMENT_METADATA) &&
+		block_group->flags & BTRFS_BLOCK_GROUP_METADATA) ||
+	       (btrfs_test_opt(root, FRAGMENT_DATA) &&
+		block_group->flags &  BTRFS_BLOCK_GROUP_DATA);
+}
+#endif
+
 /*
  * Requests for changes that need to be done during transaction commit.
  *

commit 51773bec7ea352f3b9afa11ecfc72324c7977335
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Oct 8 18:19:37 2015 +0800

    btrfs: qgroup: Avoid calling btrfs_free_reserved_data_space in clear_bit_hook
    
    In clear_bit_hook, qgroup reserved data is already handled quite well,
    either released by finish_ordered_io or invalidatepage.
    
    So calling btrfs_qgroup_free_data() here is completely meaningless, and
    since btrfs_qgroup_free_data() will lock io_tree, so it can't be called
    with io_tree lock hold.
    
    This patch will add a new function
    btrfs_free_reserved_data_space_noquota() for clear_bit_hook() to cease
    the lockdep warning.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0d0f5d2a534a..2135b82a6b61 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3455,6 +3455,8 @@ enum btrfs_reserve_flush_enum {
 int btrfs_check_data_free_space(struct inode *inode, u64 start, u64 len);
 int btrfs_alloc_data_chunk_ondemand(struct inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
+void btrfs_free_reserved_data_space_noquota(struct inode *inode, u64 start,
+					    u64 len);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);

commit 7cf5b97650f2ecefbd5afa2d58b61b289b6e3750
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:25:55 2015 +0800

    btrfs: qgroup: Cleanup old inaccurate facilities
    
    Cleanup the old facilities which use old btrfs_qgroup_reserve() function
    call, replace them with the newer version, and remove the "__" prefix in
    them.
    
    Also, make btrfs_qgroup_reserve/free() functions private, as they are
    now only used inside qgroup codes.
    
    Now, the whole btrfs qgroup is swithed to use the new reserve facilities.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0f1ade133111..0d0f5d2a534a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3452,11 +3452,9 @@ enum btrfs_reserve_flush_enum {
 	BTRFS_RESERVE_FLUSH_ALL,
 };
 
-int btrfs_check_data_free_space(struct inode *inode, u64 bytes, u64 write_bytes);
-int __btrfs_check_data_free_space(struct inode *inode, u64 start, u64 len);
+int btrfs_check_data_free_space(struct inode *inode, u64 start, u64 len);
 int btrfs_alloc_data_chunk_ondemand(struct inode *inode, u64 bytes);
-void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
-void __btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
+void btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
@@ -3472,10 +3470,8 @@ void btrfs_subvolume_release_metadata(struct btrfs_root *root,
 				      u64 qgroup_reserved);
 int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
-int btrfs_delalloc_reserve_space(struct inode *inode, u64 num_bytes);
-int __btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);
-void btrfs_delalloc_release_space(struct inode *inode, u64 num_bytes);
-void __btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);
+int btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);
+void btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root,
 					      unsigned short type);

commit 1ada3a62b56605befdfc34d6d1796601c0869103
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:25:53 2015 +0800

    btrfs: extent-tree: Add new version of btrfs_delalloc_reserve/release_space
    
    Add new version of btrfs_delalloc_reserve_space() and
    btrfs_delalloc_release_space() functions, which supports accurate qgroup
    reserve.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a55d19986311..0f1ade133111 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3473,7 +3473,9 @@ void btrfs_subvolume_release_metadata(struct btrfs_root *root,
 int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode, u64 num_bytes);
+int __btrfs_delalloc_reserve_space(struct inode *inode, u64 start, u64 len);
 void btrfs_delalloc_release_space(struct inode *inode, u64 num_bytes);
+void __btrfs_delalloc_release_space(struct inode *inode, u64 start, u64 len);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root,
 					      unsigned short type);

commit 4ceff0792d36256a5f879cec51c56e44db90b8ec
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:22:42 2015 +0800

    btrfs: extent-tree: Add new version of btrfs_check_data_free_space and btrfs_free_reserved_data_space.
    
    Add new functions __btrfs_check_data_free_space() and
    __btrfs_free_reserved_data_space() to work with new accurate qgroup
    reserved space framework.
    
    The new function will replace old btrfs_check_data_free_space() and
    btrfs_free_reserved_data_space() respectively, but until all the change
    is done, let's just use the new name.
    
    Also, export internal use function btrfs_alloc_data_chunk_ondemand(), as
    now qgroup reserve requires precious bytes, some operation can't get the
    accurate number in advance(like fallocate).
    But data space info check and data chunk allocate doesn't need to be
    that accurate, and can be called at the beginning.
    
    So export it for later operations.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9df8f01de4df..a55d19986311 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3453,7 +3453,10 @@ enum btrfs_reserve_flush_enum {
 };
 
 int btrfs_check_data_free_space(struct inode *inode, u64 bytes, u64 write_bytes);
+int __btrfs_check_data_free_space(struct inode *inode, u64 start, u64 len);
+int btrfs_alloc_data_chunk_ondemand(struct inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
+void __btrfs_free_reserved_data_space(struct inode *inode, u64 start, u64 len);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);

commit 55eeaf0578038c40baaf3cf9408c23e42cd2a2b8
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:08:38 2015 +0800

    btrfs: qgroup: Introduce new functions to reserve/free metadata
    
    Introduce new functions btrfs_qgroup_reserve/free_meta() to reserve/free
    metadata reserved space.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 49bc792108b9..9df8f01de4df 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1943,6 +1943,9 @@ struct btrfs_root {
 	int send_in_progress;
 	struct btrfs_subvolume_writers *subv_writers;
 	atomic_t will_be_snapshoted;
+
+	/* For qgroup metadata space reserve */
+	atomic_t qgroup_meta_rsv;
 };
 
 struct btrfs_ioctl_defrag_range_args {

commit 62fb50ab7c903357c92cef2f7677235b92ac575f
Merge: 640926ffdda7 73416dab235e
Author: Chris Mason <clm@fb.com>
Date:   Mon Oct 12 16:24:15 2015 -0700

    Merge branch 'anand/sysfs-updates-v4.3-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.4
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 1dd6d7ca9d062721ae37388900a322a4b959e939
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 10:51:11 2015 +0200

    btrfs: introduce ratelimited variants of message printing functions
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9c0fd901edbe..bca42c5733a1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4075,6 +4075,23 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 #define btrfs_info_rl_in_rcu(fs_info, fmt, args...) \
 	btrfs_printk_rl_in_rcu(fs_info, KERN_INFO fmt, ##args)
 
+/*
+ * Wrappers that use a ratelimited printk
+ */
+#define btrfs_emerg_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_EMERG fmt, ##args)
+#define btrfs_alert_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_ALERT fmt, ##args)
+#define btrfs_crit_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_CRIT fmt, ##args)
+#define btrfs_err_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_ERR fmt, ##args)
+#define btrfs_warn_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_WARNING fmt, ##args)
+#define btrfs_notice_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_NOTICE fmt, ##args)
+#define btrfs_info_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_INFO fmt, ##args)
 #ifdef DEBUG
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)
@@ -4082,6 +4099,8 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 	btrfs_printk_in_rcu(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl_in_rcu(fs_info, fmt, args...) \
 	btrfs_printk_rl_in_rcu(fs_info, KERN_DEBUG fmt, ##args)
+#define btrfs_debug_rl(fs_info, fmt, args...) \
+	btrfs_printk_ratelimited(fs_info, KERN_DEBUG fmt, ##args)
 #else
 #define btrfs_debug(fs_info, fmt, args...) \
     no_printk(KERN_DEBUG fmt, ##args)
@@ -4089,6 +4108,8 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 	no_printk(KERN_DEBUG fmt, ##args)
 #define btrfs_debug_rl_in_rcu(fs_info, fmt, args...) \
 	no_printk(KERN_DEBUG fmt, ##args)
+#define btrfs_debug_rl(fs_info, fmt, args...) \
+	no_printk(KERN_DEBUG fmt, ##args)
 #endif
 
 #define btrfs_printk_in_rcu(fs_info, fmt, args...)	\

commit 24aa6b41d4611b14ad0fb89fa0b899ae9ab7005c
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 10:27:02 2015 +0200

    btrfs: introduce ratelimited _in_rcu variants of message printing functions
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 88acdffbe384..9c0fd901edbe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4057,16 +4057,38 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 #define btrfs_info_in_rcu(fs_info, fmt, args...) \
 	btrfs_printk_in_rcu(fs_info, KERN_INFO fmt, ##args)
 
+/*
+ * Wrappers that use a ratelimited printk_in_rcu
+ */
+#define btrfs_emerg_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_EMERG fmt, ##args)
+#define btrfs_alert_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_ALERT fmt, ##args)
+#define btrfs_crit_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_CRIT fmt, ##args)
+#define btrfs_err_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_ERR fmt, ##args)
+#define btrfs_warn_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_WARNING fmt, ##args)
+#define btrfs_notice_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_NOTICE fmt, ##args)
+#define btrfs_info_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_INFO fmt, ##args)
+
 #ifdef DEBUG
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)
 #define btrfs_debug_in_rcu(fs_info, fmt, args...) \
 	btrfs_printk_in_rcu(fs_info, KERN_DEBUG fmt, ##args)
+#define btrfs_debug_rl_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_rl_in_rcu(fs_info, KERN_DEBUG fmt, ##args)
 #else
 #define btrfs_debug(fs_info, fmt, args...) \
     no_printk(KERN_DEBUG fmt, ##args)
 #define btrfs_debug_in_rcu(fs_info, fmt, args...) \
 	no_printk(KERN_DEBUG fmt, ##args)
+#define btrfs_debug_rl_in_rcu(fs_info, fmt, args...) \
+	no_printk(KERN_DEBUG fmt, ##args)
 #endif
 
 #define btrfs_printk_in_rcu(fs_info, fmt, args...)	\
@@ -4076,6 +4098,22 @@ do {							\
 	rcu_read_unlock();				\
 } while (0)
 
+#define btrfs_printk_ratelimited(fs_info, fmt, args...)		\
+do {								\
+	static DEFINE_RATELIMIT_STATE(_rs,			\
+		DEFAULT_RATELIMIT_INTERVAL,			\
+		DEFAULT_RATELIMIT_BURST);       		\
+	if (__ratelimit(&_rs))					\
+		btrfs_printk(fs_info, fmt, ##args);		\
+} while (0)
+
+#define btrfs_printk_rl_in_rcu(fs_info, fmt, args...)		\
+do {								\
+	rcu_read_lock();					\
+	btrfs_printk_ratelimited(fs_info, fmt, ##args);		\
+	rcu_read_unlock();					\
+} while (0)
+
 #ifdef CONFIG_BTRFS_ASSERT
 
 __cold

commit 08a84e25a80566cf3cb1903c2448123efedff132
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 08:48:52 2015 +0200

    btrfs: introduce _in_rcu variants of message printing functions
    
    Due to the missing variants there are messages that lack the information
    printed by btrfs_info etc helpers.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 938efe33be80..88acdffbe384 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4039,14 +4039,43 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 #define btrfs_info(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_INFO fmt, ##args)
 
+/*
+ * Wrappers that use printk_in_rcu
+ */
+#define btrfs_emerg_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_EMERG fmt, ##args)
+#define btrfs_alert_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_ALERT fmt, ##args)
+#define btrfs_crit_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_CRIT fmt, ##args)
+#define btrfs_err_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_ERR fmt, ##args)
+#define btrfs_warn_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_WARNING fmt, ##args)
+#define btrfs_notice_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_NOTICE fmt, ##args)
+#define btrfs_info_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_INFO fmt, ##args)
+
 #ifdef DEBUG
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)
+#define btrfs_debug_in_rcu(fs_info, fmt, args...) \
+	btrfs_printk_in_rcu(fs_info, KERN_DEBUG fmt, ##args)
 #else
 #define btrfs_debug(fs_info, fmt, args...) \
     no_printk(KERN_DEBUG fmt, ##args)
+#define btrfs_debug_in_rcu(fs_info, fmt, args...) \
+	no_printk(KERN_DEBUG fmt, ##args)
 #endif
 
+#define btrfs_printk_in_rcu(fs_info, fmt, args...)	\
+do {							\
+	rcu_read_lock();				\
+	btrfs_printk(fs_info, fmt, ##args);		\
+	rcu_read_unlock();				\
+} while (0)
+
 #ifdef CONFIG_BTRFS_ASSERT
 
 __cold

commit a4553fefb59cb0336f543fa567170b47e90142a9
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Sep 25 14:43:01 2015 +0800

    Btrfs: consolidate btrfs_error() to btrfs_std_error()
    
    btrfs_error() and btrfs_std_error() does the same thing
    and calls _btrfs_std_error(), so consolidate them together.
    And the main motivation is that btrfs_error() is closely
    named with btrfs_err(), one handles error action the other
    is to log the error, so don't closely name them.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Suggested-by: David Sterba <dsterba@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 448406307272..a86051e332ff 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4127,14 +4127,7 @@ do {								\
 				  __LINE__, (errno));		\
 } while (0)
 
-#define btrfs_std_error(fs_info, errno)				\
-do {								\
-	if ((errno))						\
-		__btrfs_std_error((fs_info), __func__,		\
-				   __LINE__, (errno), NULL);	\
-} while (0)
-
-#define btrfs_error(fs_info, errno, fmt, args...)		\
+#define btrfs_std_error(fs_info, errno, fmt, args...)		\
 do {								\
 	__btrfs_std_error((fs_info), __func__, __LINE__,	\
 			  (errno), fmt, ##args);		\

commit 6618a59bfc0a0490f2a51df37c67878e23285670
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Aug 14 18:32:47 2015 +0800

    Btrfs: rename btrfs_sysfs_remove_one to btrfs_sysfs_remove_mounted
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index afce3069697a..448406307272 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4005,7 +4005,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 int btrfs_init_sysfs(void);
 void btrfs_exit_sysfs(void);
 int btrfs_sysfs_add_mounted(struct btrfs_fs_info *fs_info);
-void btrfs_sysfs_remove_one(struct btrfs_fs_info *fs_info);
+void btrfs_sysfs_remove_mounted(struct btrfs_fs_info *fs_info);
 
 /* xattr.c */
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);

commit 96f3136e51580ed68a2952341c8b9e2d7f853472
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Aug 14 18:32:46 2015 +0800

    Btrfs: rename btrfs_sysfs_add_one to btrfs_sysfs_add_mounted
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 938efe33be80..afce3069697a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4004,7 +4004,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 /* sysfs.c */
 int btrfs_init_sysfs(void);
 void btrfs_exit_sysfs(void);
-int btrfs_sysfs_add_one(struct btrfs_fs_info *fs_info);
+int btrfs_sysfs_add_mounted(struct btrfs_fs_info *fs_info);
 void btrfs_sysfs_remove_one(struct btrfs_fs_info *fs_info);
 
 /* xattr.c */

commit 46cd28555ffaa40162290dba203daad0ff6f7abd
Merge: da2f0f74cf7d e33e17ee1098
Author: Chris Mason <clm@fb.com>
Date:   Sun Aug 9 07:35:33 2015 -0700

    Merge branch 'jeffm-discard-4.3' into for-linus-4.3

commit a4027a20c57a2c8779e17a61425737634bb7163d
Author: Byongho Lee <bhlee.kernel@gmail.com>
Date:   Fri Jul 10 13:10:26 2015 +0900

    Btrfs: remove unused mutex from struct 'btrfs_fs_info'
    
    The code using 'ordered_extent_flush_mutex' mutex has removed by below
    commit.
     - 8d875f95da43c6a8f18f77869f2ef26e9594fecc
       btrfs: disable strict file flushes for renames and truncates
    But the mutex still lives in struct 'btrfs_fs_info'.
    
    So, this patch removes the mutex from struct 'btrfs_fs_info' and its
    initialization code.
    
    Signed-off-by: Byongho Lee <bhlee.kernel@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f335c18bd263..d4042c89d29b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1518,12 +1518,6 @@ struct btrfs_fs_info {
 	 */
 	struct mutex ordered_operations_mutex;
 
-	/*
-	 * Same as ordered_operations_mutex except this is for ordered extents
-	 * and not the operations.
-	 */
-	struct mutex ordered_extent_flush_mutex;
-
 	struct rw_semaphore commit_root_sem;
 
 	struct rw_semaphore cleanup_work_sem;

commit 147d256e0980e31505d25d721be979d6a8d2148c
Author: Zhaolei <zhaolei@cn.fujitsu.com>
Date:   Thu Aug 6 20:58:11 2015 +0800

    btrfs: Remove unnecessary variants in relocation.c
    
    These arguments are not used in functions, remove them for cleanup
    and make kernel stack happy.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f57e6cae394b..f335c18bd263 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4185,8 +4185,7 @@ int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
 int btrfs_reloc_cow_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, struct extent_buffer *buf,
 			  struct extent_buffer *cow);
-void btrfs_reloc_pre_snapshot(struct btrfs_trans_handle *trans,
-			      struct btrfs_pending_snapshot *pending,
+void btrfs_reloc_pre_snapshot(struct btrfs_pending_snapshot *pending,
 			      u64 *bytes_to_reserve);
 int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending);

commit 868f401ae38acb439005626c04d575e64c5ae760
Author: Zhaolei <zhaolei@cn.fujitsu.com>
Date:   Wed Aug 5 16:43:27 2015 +0800

    btrfs: Use ref_cnt for set_block_group_ro()
    
    More than one code call set_block_group_ro() and restore rw in fail.
    
    Old code use bool bit to save blockgroup's ro state, it can not
    support parallel case(it is confirmd exist in my debug log).
    
    This patch use ref count to store ro state, and rename
    set_block_group_ro/set_block_group_rw
    to
    inc_block_group_ro/dec_block_group_ro.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aac314e14188..f57e6cae394b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1300,7 +1300,7 @@ struct btrfs_block_group_cache {
 	/* for raid56, this is a full stripe, without parity */
 	unsigned long full_stripe_len;
 
-	unsigned int ro:1;
+	unsigned int ro;
 	unsigned int iref:1;
 	unsigned int has_caching_ctl:1;
 	unsigned int removed:1;
@@ -3495,9 +3495,9 @@ int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
 void btrfs_block_rsv_release(struct btrfs_root *root,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);
-int btrfs_set_block_group_ro(struct btrfs_root *root,
+int btrfs_inc_block_group_ro(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
-void btrfs_set_block_group_rw(struct btrfs_root *root,
+void btrfs_dec_block_group_ro(struct btrfs_root *root,
 			      struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);

commit e33e17ee1098d8d751552ac11c111e1c1a3db014
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Jun 15 09:41:19 2015 -0400

    btrfs: add missing discards when unpinning extents with -o discard
    
    When we clear the dirty bits in btrfs_delete_unused_bgs for extents
    in the empty block group, it results in btrfs_finish_extent_commit being
    unable to discard the freed extents.
    
    The block group removal patch added an alternate path to forget extents
    other than btrfs_finish_extent_commit.  As a result, any extents that
    would be freed when the block group is removed aren't discarded.  In my
    test run, with a large copy of mixed sized files followed by removal, it
    left nearly 2/3 of extents undiscarded.
    
    To clean up the block groups, we add the removed block group onto a list
    that will be discarded after transaction commit.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Tested-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aac314e14188..19ef3f306559 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3437,6 +3437,8 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start,
 			     struct extent_map *em);
 void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
+void btrfs_get_block_group_trimming(struct btrfs_block_group_cache *cache);
+void btrfs_put_block_group_trimming(struct btrfs_block_group_cache *cache);
 void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
 				       struct btrfs_root *root);
 u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
@@ -4073,6 +4075,7 @@ __cold
 void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);
 
+const char *btrfs_decode_error(int errno);
 
 __cold
 void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,

commit 67c5e7d464bc466471b05e027abe8a6b29687ebd
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jun 11 00:58:53 2015 +0100

    Btrfs: fix race between balance and unused block group deletion
    
    We have a race between deleting an unused block group and balancing the
    same block group that leads to an assertion failure/BUG(), producing the
    following trace:
    
    [181631.208236] BTRFS: assertion failed: 0, file: fs/btrfs/volumes.c, line: 2622
    [181631.220591] ------------[ cut here ]------------
    [181631.222959] kernel BUG at fs/btrfs/ctree.h:4062!
    [181631.223932] invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
    [181631.224566] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop fuse acpi_cpufreq parpor$
    [181631.224566] CPU: 8 PID: 17451 Comm: btrfs Tainted: G        W       4.1.0-rc5-btrfs-next-10+ #1
    [181631.224566] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.1-0-g4adadbd-20150316_085822-nilsson.home.kraxel.org 04/01/2014
    [181631.224566] task: ffff880127e09590 ti: ffff8800b5824000 task.ti: ffff8800b5824000
    [181631.224566] RIP: 0010:[<ffffffffa03f19f6>]  [<ffffffffa03f19f6>] assfail.constprop.50+0x1e/0x20 [btrfs]
    [181631.224566] RSP: 0018:ffff8800b5827ae8  EFLAGS: 00010246
    [181631.224566] RAX: 0000000000000040 RBX: ffff8800109fc218 RCX: ffffffff81095dce
    [181631.224566] RDX: 0000000000005124 RSI: ffffffff81464819 RDI: 00000000ffffffff
    [181631.224566] RBP: ffff8800b5827ae8 R08: 0000000000000001 R09: 0000000000000000
    [181631.224566] R10: 0000000000000000 R11: 0000000000000000 R12: ffff8800109fc200
    [181631.224566] R13: ffff880020095000 R14: ffff8800b1a13f38 R15: ffff880020095000
    [181631.224566] FS:  00007f70ca0b0c80(0000) GS:ffff88013ec00000(0000) knlGS:0000000000000000
    [181631.224566] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [181631.224566] CR2: 00007f2872ab6e68 CR3: 00000000a717c000 CR4: 00000000000006e0
    [181631.224566] Stack:
    [181631.224566]  ffff8800b5827ba8 ffffffffa03f3916 ffff8800b5827b38 ffffffffa03d080e
    [181631.224566]  ffffffffa03d1423 ffff880020095000 ffff88001233c000 0000000000000001
    [181631.224566]  ffff880020095000 ffff8800b1a13f38 0000000a69c00000 0000000000000000
    [181631.224566] Call Trace:
    [181631.224566]  [<ffffffffa03f3916>] btrfs_remove_chunk+0xa4/0x6bb [btrfs]
    [181631.224566]  [<ffffffffa03d080e>] ? join_transaction.isra.8+0xb9/0x3ba [btrfs]
    [181631.224566]  [<ffffffffa03d1423>] ? wait_current_trans.isra.13+0x22/0xfc [btrfs]
    [181631.224566]  [<ffffffffa03f3fbc>] btrfs_relocate_chunk.isra.29+0x8f/0xa7 [btrfs]
    [181631.224566]  [<ffffffffa03f54df>] btrfs_balance+0xaa4/0xc52 [btrfs]
    [181631.224566]  [<ffffffffa03fd388>] btrfs_ioctl_balance+0x23f/0x2b0 [btrfs]
    [181631.224566]  [<ffffffff810872f9>] ? trace_hardirqs_on+0xd/0xf
    [181631.224566]  [<ffffffffa04019a3>] btrfs_ioctl+0xfe2/0x2220 [btrfs]
    [181631.224566]  [<ffffffff812603ed>] ? __this_cpu_preempt_check+0x13/0x15
    [181631.224566]  [<ffffffff81084669>] ? arch_local_irq_save+0x9/0xc
    [181631.224566]  [<ffffffff81138def>] ? handle_mm_fault+0x834/0xcd2
    [181631.224566]  [<ffffffff81138def>] ? handle_mm_fault+0x834/0xcd2
    [181631.224566]  [<ffffffff8103e48c>] ? __do_page_fault+0x211/0x424
    [181631.224566]  [<ffffffff811755e6>] do_vfs_ioctl+0x3c6/0x479
    (...)
    
    The sequence of steps leading to this are:
    
               CPU 0                                         CPU 1
    
      btrfs_balance()
        btrfs_relocate_chunk()
    
          btrfs_relocate_block_group(bg X)
            btrfs_lookup_block_group(bg X)
    
                                                   cleaner_kthread
                                                      locks fs_info->cleaner_mutex
    
                                                      btrfs_delete_unused_bgs()
                                                        finds bg X, which became
                                                        unused in the previous
                                                        transaction
    
                                                        checks bg X ->ro == 0,
                                                        so it proceeds
            sets bg X ->ro to 1
            (btrfs_set_block_group_ro(bg X))
    
            blocks on fs_info->cleaner_mutex
                                                        btrfs_remove_chunk(bg X)
                                                      unlocks fs_info->cleaner_mutex
    
            acquires fs_info->cleaner_mutex
            relocate_block_group()
              --> does nothing, no extents found in
                  the extent tree from bg X
            unlocks fs_info->cleaner_mutex
    
          btrfs_relocate_block_group(bg X) returns
    
        btrfs_remove_chunk(bg X)
           extent map not found
              --> ASSERT(0)
    
    Fix this by using a new mutex to make sure these 2 operations, block
    group relocation and removal, are serialized.
    
    This issue is reproducible by running fstests generic/038 (which stresses
    chunk allocation and automatic removal of unused block groups) together
    with the following balance loop:
    
        while true; do btrfs balance start -dusage=0 <mountpoint> ; done
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 80a9aefb0c46..aac314e14188 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1778,6 +1778,7 @@ struct btrfs_fs_info {
 	spinlock_t unused_bgs_lock;
 	struct list_head unused_bgs;
 	struct mutex unused_bg_unpin_mutex;
+	struct mutex delete_unused_bgs_mutex;
 
 	/* For btrfs to record security options */
 	struct security_mnt_opts security_opts;

commit c40b7b064f6159df3a080595a498613d08206e59
Merge: 37b8d27de5d0 f90fc5472882
Author: Chris Mason <clm@fb.com>
Date:   Tue Jun 23 05:34:39 2015 -0700

    Merge branch 'sysfs-fsdevices-4.2-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into anand

commit e69bcee37692f5d8c557335ddd2444cb4afe0005
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Apr 17 10:23:16 2015 +0800

    btrfs: qgroup: Cleanup the old ref_node-oriented mechanism.
    
    Goodbye, the old mechanisim.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 881549a35fca..0498f5cd8752 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1736,7 +1736,7 @@ struct btrfs_fs_info {
 	/* list of dirty qgroups to be written at next commit */
 	struct list_head dirty_qgroups;
 
-	/* used by btrfs_qgroup_record_ref for an efficient tree traversal */
+	/* used by qgroup for an efficient tree traversal */
 	u64 qgroup_seq;
 
 	/* qgroup rescan items */

commit 20b2e3029eef277cd93a46a991004260057e1a9e
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Jun 4 20:09:15 2015 +0800

    btrfs: Fix lockdep warning of wr_ctx->wr_lock in scrub_free_wr_ctx()
    
    lockdep report following warning in test:
     [25176.843958] =================================
     [25176.844519] [ INFO: inconsistent lock state ]
     [25176.845047] 4.1.0-rc3 #22 Tainted: G        W
     [25176.845591] ---------------------------------
     [25176.846153] inconsistent {SOFTIRQ-ON-W} -> {IN-SOFTIRQ-W} usage.
     [25176.846713] fsstress/26661 [HC0[0]:SC1[1]:HE1:SE0] takes:
     [25176.847246]  (&wr_ctx->wr_lock){+.?...}, at: [<ffffffffa04cdc6d>] scrub_free_ctx+0x2d/0xf0 [btrfs]
     [25176.847838] {SOFTIRQ-ON-W} state was registered at:
     [25176.848396]   [<ffffffff810bf460>] __lock_acquire+0x6a0/0xe10
     [25176.848955]   [<ffffffff810bfd1e>] lock_acquire+0xce/0x2c0
     [25176.849491]   [<ffffffff816489af>] mutex_lock_nested+0x7f/0x410
     [25176.850029]   [<ffffffffa04d04ff>] scrub_stripe+0x4df/0x1080 [btrfs]
     [25176.850575]   [<ffffffffa04d11b1>] scrub_chunk.isra.19+0x111/0x130 [btrfs]
     [25176.851110]   [<ffffffffa04d144c>] scrub_enumerate_chunks+0x27c/0x510 [btrfs]
     [25176.851660]   [<ffffffffa04d3b87>] btrfs_scrub_dev+0x1c7/0x6c0 [btrfs]
     [25176.852189]   [<ffffffffa04e918e>] btrfs_dev_replace_start+0x36e/0x450 [btrfs]
     [25176.852771]   [<ffffffffa04a98e0>] btrfs_ioctl+0x1e10/0x2d20 [btrfs]
     [25176.853315]   [<ffffffff8121c5b8>] do_vfs_ioctl+0x318/0x570
     [25176.853868]   [<ffffffff8121c851>] SyS_ioctl+0x41/0x80
     [25176.854406]   [<ffffffff8164da17>] system_call_fastpath+0x12/0x6f
     [25176.854935] irq event stamp: 51506
     [25176.855511] hardirqs last  enabled at (51506): [<ffffffff810d4ce5>] vprintk_emit+0x225/0x5e0
     [25176.856059] hardirqs last disabled at (51505): [<ffffffff810d4b77>] vprintk_emit+0xb7/0x5e0
     [25176.856642] softirqs last  enabled at (50886): [<ffffffff81067a23>] __do_softirq+0x363/0x640
     [25176.857184] softirqs last disabled at (50949): [<ffffffff8106804d>] irq_exit+0x10d/0x120
     [25176.857746]
     other info that might help us debug this:
     [25176.858845]  Possible unsafe locking scenario:
     [25176.859981]        CPU0
     [25176.860537]        ----
     [25176.861059]   lock(&wr_ctx->wr_lock);
     [25176.861705]   <Interrupt>
     [25176.862272]     lock(&wr_ctx->wr_lock);
     [25176.862881]
      *** DEADLOCK ***
    
    Reason:
     Above warning is caused by:
     Interrupt
     -> bio_endio()
     -> ...
     -> scrub_put_ctx()
     -> scrub_free_ctx() *1
     -> ...
     -> mutex_lock(&wr_ctx->wr_lock);
    
     scrub_put_ctx() is allowed to be called in end_bio interrupt, but
     in code design, it will never call scrub_free_ctx(sctx) in interrupe
     context(above *1), because btrfs_scrub_dev() get one additional
     reference of sctx->refs, which makes scrub_free_ctx() only called
     withine btrfs_scrub_dev().
    
     Now the code runs out of our wish, because free sequence in
     scrub_pending_bio_dec() have a gap.
    
     Current code:
     -----------------------------------+-----------------------------------
     scrub_pending_bio_dec()            |  btrfs_scrub_dev
     -----------------------------------+-----------------------------------
     atomic_dec(&sctx->bios_in_flight); |
     wake_up(&sctx->list_wait);         |
                                        | scrub_put_ctx()
                                        | -> atomic_dec_and_test(&sctx->refs)
     scrub_put_ctx(sctx);               |
     -> atomic_dec_and_test(&sctx->refs)|
     -> scrub_free_ctx()                |
     -----------------------------------+-----------------------------------
    
     We expected:
     -----------------------------------+-----------------------------------
     scrub_pending_bio_dec()            |  btrfs_scrub_dev
     -----------------------------------+-----------------------------------
     atomic_dec(&sctx->bios_in_flight); |
     wake_up(&sctx->list_wait);         |
     scrub_put_ctx(sctx);               |
     -> atomic_dec_and_test(&sctx->refs)|
                                        | scrub_put_ctx()
                                        | -> atomic_dec_and_test(&sctx->refs)
                                        | -> scrub_free_ctx()
     -----------------------------------+-----------------------------------
    
    Fix:
     Move scrub_pending_bio_dec() to a workqueue, to avoid this function run
     in interrupt context.
     Tested by check tracelog in debug.
    
    Changelog v1->v2:
     Use workqueue instead of adjust function call sequence in v1,
     because v1 will introduce a bug pointed out by:
     Filipe David Manana <fdmanana@gmail.com>
    
    Reported-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5e09834ac2ef..881549a35fca 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1698,6 +1698,7 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *scrub_workers;
 	struct btrfs_workqueue *scrub_wr_completion_workers;
 	struct btrfs_workqueue *scrub_nocow_workers;
+	struct btrfs_workqueue *scrub_parity_workers;
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	u32 check_integrity_print_mask;

commit 4617ea3a52cfe8ae407ef406ab999f40a558c369
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Jun 9 17:48:21 2015 +0100

    Btrfs: fix necessary chunk tree space calculation when allocating a chunk
    
    When allocating a new chunk or removing one we need to update num_devs
    device items and insert or remove a chunk item in the chunk tree, so
    in the worst case the space needed in the chunk space_info is:
    
      btrfs_calc_trunc_metadata_size(chunk_root, num_devs) +
         btrfs_calc_trans_metadata_size(chunk_root, 1)
    
    That is, in the worst case we need to cow num_devs paths and cow 1 other
    path that can result in splitting every node and leaf, and each path
    consisting of BTRFS_MAX_LEVEL - 1 nodes and 1 leaf. We were requiring
    some additional chunk_root->nodesize * BTRFS_MAX_LEVEL * num_devs bytes,
    which were unnecessary since updating the existing device items does
    not result in splitting the nodes and leaf since after updating them
    they remain with the same size.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 92e908394403..5e09834ac2ef 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3518,8 +3518,7 @@ int btrfs_start_write_no_snapshoting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshoting(struct btrfs_root *root);
 void check_system_chunk(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
-			const u64 type,
-			const bool is_allocation);
+			const u64 type);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit 39c2d7faccc5ca5a1be682b01c0db5fafa8adeda
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed May 20 14:01:55 2015 +0100

    Btrfs: fix -ENOSPC on block group removal
    
    Unlike when attempting to allocate a new block group, where we check
    that we have enough space in the system space_info to update the device
    items and insert a new chunk item in the chunk tree, we were not checking
    if the system space_info had enough space for updating the device items
    and deleting the chunk item in the chunk tree. This often lead to -ENOSPC
    error when attempting to allocate blocks for the chunk tree (during btree
    node/leaf COW operations) while updating the device items or deleting the
    chunk item, which resulted in the current transaction being aborted and
    turning the filesystem into read-only mode.
    
    While running fstests generic/038, which stresses allocation of block
    groups and removal of unused block groups, with a large scratch device
    (750Gb) this happened often, despite more than enough unallocated space,
    and resulted in the following trace:
    
    [68663.586604] WARNING: CPU: 3 PID: 1521 at fs/btrfs/super.c:260 __btrfs_abort_transaction+0x52/0x114 [btrfs]()
    [68663.600407] BTRFS: Transaction aborted (error -28)
    (...)
    [68663.730829] Call Trace:
    [68663.732585]  [<ffffffff8142fa46>] dump_stack+0x4f/0x7b
    [68663.734334]  [<ffffffff8108b6a2>] ? console_unlock+0x361/0x3ad
    [68663.739980]  [<ffffffff81045ea5>] warn_slowpath_common+0xa1/0xbb
    [68663.757153]  [<ffffffffa036ca6d>] ? __btrfs_abort_transaction+0x52/0x114 [btrfs]
    [68663.760925]  [<ffffffff81045f05>] warn_slowpath_fmt+0x46/0x48
    [68663.762854]  [<ffffffffa03b159d>] ? btrfs_update_device+0x15a/0x16c [btrfs]
    [68663.764073]  [<ffffffffa036ca6d>] __btrfs_abort_transaction+0x52/0x114 [btrfs]
    [68663.765130]  [<ffffffffa03b3638>] btrfs_remove_chunk+0x597/0x5ee [btrfs]
    [68663.765998]  [<ffffffffa0384663>] ? btrfs_delete_unused_bgs+0x245/0x296 [btrfs]
    [68663.767068]  [<ffffffffa0384676>] btrfs_delete_unused_bgs+0x258/0x296 [btrfs]
    [68663.768227]  [<ffffffff8143527f>] ? _raw_spin_unlock_irq+0x2d/0x4c
    [68663.769081]  [<ffffffffa038b109>] cleaner_kthread+0x13d/0x16c [btrfs]
    [68663.799485]  [<ffffffffa038afcc>] ? btrfs_alloc_root+0x28/0x28 [btrfs]
    [68663.809208]  [<ffffffff8105f367>] kthread+0xef/0xf7
    [68663.828795]  [<ffffffff810e603f>] ? time_hardirqs_on+0x15/0x28
    [68663.844942]  [<ffffffff8105f278>] ? __kthread_parkme+0xad/0xad
    [68663.846486]  [<ffffffff81435a88>] ret_from_fork+0x58/0x90
    [68663.847760]  [<ffffffff8105f278>] ? __kthread_parkme+0xad/0xad
    [68663.849503] ---[ end trace 798477c6d6dbaad6 ]---
    [68663.850525] BTRFS: error (device sdc) in btrfs_remove_chunk:2652: errno=-28 No space left
    
    So fix this by verifying that enough space exists in system space_info,
    and reserving the space in the chunk block reserve, before attempting to
    delete the block group and allocate a new system chunk if we don't have
    enough space to perform the necessary updates and delete in the chunk
    tree. Like for the block group creation case, we don't error our if we
    fail to allocate a new system chunk, since we might end up not needing
    it (no node/leaf splits happen during the COW operations and/or we end
    up not needing to COW any btree nodes or leafs because they were already
    COWed in the current transaction and their writeback didn't start yet).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8ee5645ef9e1..92e908394403 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3516,6 +3516,10 @@ int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 int __get_raid_index(u64 flags);
 int btrfs_start_write_no_snapshoting(struct btrfs_root *root);
 void btrfs_end_write_no_snapshoting(struct btrfs_root *root);
+void check_system_chunk(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root,
+			const u64 type,
+			const bool is_allocation);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit 4fbcdf6694544fd9d2aedbc1e73e52b90a4fcc20
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed May 20 14:01:54 2015 +0100

    Btrfs: fix -ENOSPC when finishing block group creation
    
    While creating a block group, we often end up getting ENOSPC while updating
    the chunk tree, which leads to a transaction abortion that produces a trace
    like the following:
    
    [30670.116368] WARNING: CPU: 4 PID: 20735 at fs/btrfs/super.c:260 __btrfs_abort_transaction+0x52/0x106 [btrfs]()
    [30670.117777] BTRFS: Transaction aborted (error -28)
    (...)
    [30670.163567] Call Trace:
    [30670.163906]  [<ffffffff8142fa46>] dump_stack+0x4f/0x7b
    [30670.164522]  [<ffffffff8108b6a2>] ? console_unlock+0x361/0x3ad
    [30670.165171]  [<ffffffff81045ea5>] warn_slowpath_common+0xa1/0xbb
    [30670.166323]  [<ffffffffa035daa7>] ? __btrfs_abort_transaction+0x52/0x106 [btrfs]
    [30670.167213]  [<ffffffff81045f05>] warn_slowpath_fmt+0x46/0x48
    [30670.167862]  [<ffffffffa035daa7>] __btrfs_abort_transaction+0x52/0x106 [btrfs]
    [30670.169116]  [<ffffffffa03743d7>] btrfs_create_pending_block_groups+0x101/0x130 [btrfs]
    [30670.170593]  [<ffffffffa038426a>] __btrfs_end_transaction+0x84/0x366 [btrfs]
    [30670.171960]  [<ffffffffa038455c>] btrfs_end_transaction+0x10/0x12 [btrfs]
    [30670.174649]  [<ffffffffa036eb6b>] btrfs_check_data_free_space+0x11f/0x27c [btrfs]
    [30670.176092]  [<ffffffffa039450d>] btrfs_fallocate+0x7c8/0xb96 [btrfs]
    [30670.177218]  [<ffffffff812459f2>] ? __this_cpu_preempt_check+0x13/0x15
    [30670.178622]  [<ffffffff81152447>] vfs_fallocate+0x14c/0x1de
    [30670.179642]  [<ffffffff8116b915>] ? __fget_light+0x2d/0x4f
    [30670.180692]  [<ffffffff81152863>] SyS_fallocate+0x47/0x62
    [30670.186737]  [<ffffffff81435b32>] system_call_fastpath+0x12/0x17
    [30670.187792] ---[ end trace 0373e6b491c4a8cc ]---
    
    This is because we don't do proper space reservation for the chunk block
    reserve when we have multiple tasks allocating chunks in parallel.
    
    So block group creation has 2 phases, and the first phase essentially
    checks if there is enough space in the system space_info, allocating a
    new system chunk if there isn't, while the second phase updates the
    device, extent and chunk trees. However, because the updates to the
    chunk tree happen in the second phase, if we have N tasks, each with
    its own transaction handle, allocating new chunks in parallel and if
    there is only enough space in the system space_info to allocate M chunks,
    where M < N, none of the tasks ends up allocating a new system chunk in
    the first phase and N - M tasks will get -ENOSPC when attempting to
    update the chunk tree in phase 2 if they need to COW any nodes/leafs
    from the chunk tree.
    
    Fix this by doing proper reservation in the chunk block reserve.
    
    The issue could be reproduced by running fstests generic/038 in a loop,
    which eventually triggered the problem.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9d7a6c38f0b1..8ee5645ef9e1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3458,6 +3458,7 @@ int btrfs_check_data_free_space(struct inode *inode, u64 bytes, u64 write_bytes)
 void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
+void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
 				  struct inode *inode);
 void btrfs_orphan_release_metadata(struct inode *inode);

commit 1f6e4b3f9f7c859fed7ac4c0853e976a1a752873
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue May 5 10:53:15 2015 +0800

    btrfs: Fix superblock csum type check.
    
    Old csum type check is wrong and can't catch csum_type 1(not supported).
    
    Fix it to avoid hostile 0 division.
    
    Reported-by: Lukas Lueg <lukas.lueg@gmail.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 670e4be7225b..9d7a6c38f0b1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -174,7 +174,7 @@ struct btrfs_ordered_sum;
 /* csum types */
 #define BTRFS_CSUM_TYPE_CRC32	0
 
-static int btrfs_csum_sizes[] = { 4, 0 };
+static int btrfs_csum_sizes[] = { 4 };
 
 /* four bytes for CRC32 */
 #define BTRFS_EMPTY_DIR_SIZE 0

commit c0d19e2b9a521bbdc33049ad92c94b517afda1f0
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Apr 24 19:11:57 2015 +0200

    btrfs: add 'cold' compiler annotations to all error handling functions
    
    The annotated functios will be placed into .text.unlikely section. The
    annotation also hints compiler to move the code out of the hot paths,
    and may implicitly mark if-statement leading to that block as unlikely.
    
    This is a heuristic, the impact on the generated code is not
    significant.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 98b33477235b..670e4be7225b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4050,6 +4050,7 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 
 #ifdef CONFIG_BTRFS_ASSERT
 
+__cold
 static inline void assfail(char *expr, char *file, int line)
 {
 	pr_err("BTRFS: assertion failed: %s, file: %s, line: %d",
@@ -4065,10 +4066,12 @@ static inline void assfail(char *expr, char *file, int line)
 
 #define btrfs_assert()
 __printf(5, 6)
+__cold
 void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);
 
 
+__cold
 void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root, const char *function,
 			       unsigned int line, int errno);
@@ -4138,6 +4141,7 @@ do {								\
 } while (0)
 
 __printf(5, 6)
+__cold
 void __btrfs_panic(struct btrfs_fs_info *fs_info, const char *function,
 		   unsigned int line, int errno, const char *fmt, ...);
 

commit 1a9a8a71ed1d457d4f03284ebfd3e40fe1e217ac
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Apr 24 19:11:54 2015 +0200

    btrfs: report exact callsite where transaction abort occurs
    
    WARN is called from a single location and all bugreports say that's in
    super.c __btrfs_abort_transaction. This is slightly confusing as we'd
    rather want to know the exact callsite. Whereas this information is
    printed in the syslog below the stacktrace, this requires further look
    and we usually see only the headline from WARNING.
    
    Moving the WARN into the macro has to inline some code and increases
    code by a few kilobytes:
    
      text    data     bss     dec     hex filename
    835481   20305   14120  869906   d4612 btrfs.ko.before
    842883   20305   14120  877308   d62fc btrfs.ko.after
    
    The delta is +7k (130+ calls), measured on 3.19 x86_64, distro config.
    The increase is not small and could lead to worse icache use. The code
    is on error/exit paths that can be recognized by compiler as cold and
    moved out of the way so the impact is speculated to be low, if
    measurable at all.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6f364e1d8d3d..98b33477235b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4111,11 +4111,17 @@ static inline int __btrfs_fs_incompat(struct btrfs_fs_info *fs_info, u64 flag)
  * Call btrfs_abort_transaction as early as possible when an error condition is
  * detected, that way the exact line number is reported.
  */
-
 #define btrfs_abort_transaction(trans, root, errno)		\
 do {								\
-	__btrfs_abort_transaction(trans, root, __func__,	\
-				  __LINE__, errno);		\
+	/* Report first abort since mount */			\
+	if (!test_and_set_bit(BTRFS_FS_STATE_TRANS_ABORTED,	\
+			&((root)->fs_info->fs_state))) {	\
+		WARN(1, KERN_DEBUG				\
+		"BTRFS: Transaction aborted (error %d)\n",	\
+		(errno));					\
+	}							\
+	__btrfs_abort_transaction((trans), (root), __func__,	\
+				  __LINE__, (errno));		\
 } while (0)
 
 #define btrfs_std_error(fs_info, errno)				\

commit 2e7910d6ca359ff1dbe05b74e3d7f353b5b65362
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Mar 10 06:38:29 2015 +0800

    Btrfs: sysfs: move super_kobj and device_dir_kobj from fs_info to btrfs_fs_devices
    
    This patch will provide a framework and help to create attributes
    from the structure btrfs_fs_devices which are available even before
    fs_info is created. So by moving the parent kobject super_kobj from
    fs_info to btrfs_fs_devices, it will help to create attributes
    from the btrfs_fs_devices as well.
    
    Patches on top of this patch now will be able to create the
    sys/fs/btrfs/fsid kobject and attributes from btrfs_fs_devices
    when devices are scanned and registered to the kernel.
    
    Just to note, this does not change any of the existing btrfs sysfs
    external kobject names and its attributes and not even the life
    cycle of them. Changes are internal only. And to ensure the same,
    this path has been tested with various device operations and,
    checking and comparing the sysfs kobjects and attributes with
    sysfs kobject and attributes with out this patch, and they remain
    same.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6f364e1d8d3d..3335245f2636 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1619,10 +1619,7 @@ struct btrfs_fs_info {
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
 
-	struct kobject super_kobj;
 	struct kobject *space_info_kobj;
-	struct kobject *device_dir_kobj;
-	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
 	int log_root_recovering;

commit e09fe2d2119800e6060f9b8ba71e072a0eb0fa4d
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 27 16:24:23 2015 +0800

    btrfs: Don't allow subvolid >= (1 << BTRFS_QGROUP_LEVEL_SHIFT) to be created
    
    Btrfs will create qgroup on subvolume creation if quota is enabled, but
    qgroup uses the high bits(currently 16 bits) as level, to build the
    inheritance.
    
    However it is fully possible a subvolume can be created with a
    subvolumeid larger than 1 << BTRFS_QGROUP_LEVEL_SHIFT, so it will be
    considered as level 1 and can't be assigned to other qgroup in level 1.
    
    This patch will prevent such things so qgroup inheritance will not be
    screwed up.
    The downside is very clear, btrfs subvolume number limit will decrease
    from (u64 max - 256(fisrt free objectid) - 256(last free objectid)) to
    (u48 max -256(first free objectid)).
    But we still have near u48(that's 15 digits in dec), so that should not
    be a huge problem.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8b851ac7c3fa..6f364e1d8d3d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4219,7 +4219,8 @@ int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 static inline int is_fstree(u64 rootid)
 {
 	if (rootid == BTRFS_FS_TREE_OBJECTID ||
-	    (s64)rootid >= (s64)BTRFS_FIRST_FREE_OBJECTID)
+	    ((s64)rootid >= (s64)BTRFS_FIRST_FREE_OBJECTID &&
+	      !btrfs_qgroup_level(rootid)))
 		return 1;
 	return 0;
 }

commit 8465ecec9611d60cbbc8e374ecf68453e0dd5b50
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 27 16:24:22 2015 +0800

    btrfs: Check qgroup level in kernel qgroup assign.
    
    Although we have qgroup level check in btrfs-progs, it's not enough
    since other programe may still call ioctl directly not using
    btrfs-progs. For example, systemd.
    
    But it's btrfs-progs to be blame since we don't provide a
    full-function(like subvolume create things) btrfs library with enough
    check, and only rely on kernel ioctl.
    
    So Add level checks in kernel too.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 851f2355f3c8..8b851ac7c3fa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1061,6 +1061,12 @@ struct btrfs_block_group_item {
 	__le64 flags;
 } __attribute__ ((__packed__));
 
+#define BTRFS_QGROUP_LEVEL_SHIFT		48
+static inline u64 btrfs_qgroup_level(u64 qgroupid)
+{
+	return qgroupid >> BTRFS_QGROUP_LEVEL_SHIFT;
+}
+
 /*
  * is subvolume quota turned on?
  */

commit e2d1f92399afb6ec518b68867ed10db2585b283a
Author: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
Date:   Fri Feb 6 10:26:52 2015 -0500

    btrfs: qgroup: do a reservation in a higher level.
    
    There are two problems in qgroup:
    
    a). The PAGE_CACHE is 4K, even when we are writing a data of 1K,
    qgroup will reserve a 4K size. It will cause the last 3K in a qgroup
    is not available to user.
    
    b). When user is writing a inline data, qgroup will not reserve it,
    it means this is a window we can exceed the limit of a qgroup.
    
    The main idea of this patch is reserving the data size of write_bytes
    rather than the reserve_bytes. It means qgroup will not care about
    the data size btrfs will reserve for user, but only care about the
    data size user is going to write. Then reserve it when user want to
    write and release it in transaction committed.
    
    In this way, qgroup can be released from the complex procedure in
    btrfs and only do the reserve when user want to write and account
    when the data is written in commit_transaction().
    
    Signed-off-by: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d48b22f31182..851f2355f3c8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3448,7 +3448,7 @@ enum btrfs_reserve_flush_enum {
 	BTRFS_RESERVE_FLUSH_ALL,
 };
 
-int btrfs_check_data_free_space(struct inode *inode, u64 bytes);
+int btrfs_check_data_free_space(struct inode *inode, u64 bytes, u64 write_bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);

commit d7c151717a1efe289aec29fb9f94485f64262c0b
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Feb 26 10:49:20 2015 +0800

    btrfs: Fix NO_SPACE bug caused by delayed-iput
    
    Steps to reproduce:
      while true; do
        dd if=/dev/zero of=/btrfs_dir/file count=[fs_size * 75%]
        rm /btrfs_dir/file
        sync
      done
    
      And we'll see dd failed because btrfs return NO_SPACE.
    
    Reason:
      Normally, btrfs_commit_transaction() call btrfs_run_delayed_iputs()
      in end to free fs space for next write, but sometimes it hadn't
      done work on time, because btrfs-cleaner thread get delayed-iputs
      from list before, but do iput() after next write.
    
      This is log:
      [ 2569.050776] comm=btrfs-cleaner func=btrfs_evict_inode() begin
    
      [ 2569.084280] comm=sync func=btrfs_commit_transaction() call btrfs_run_delayed_iputs()
      [ 2569.085418] comm=sync func=btrfs_commit_transaction() done btrfs_run_delayed_iputs()
      [ 2569.087554] comm=sync func=btrfs_commit_transaction() end
    
      [ 2569.191081] comm=dd begin
      [ 2569.790112] comm=dd func=__btrfs_buffered_write() ret=-28
    
      [ 2569.847479] comm=btrfs-cleaner func=add_pinned_bytes() 0 + 32677888 = 32677888
      [ 2569.849530] comm=btrfs-cleaner func=add_pinned_bytes() 32677888 + 23834624 = 56512512
      ...
      [ 2569.903893] comm=btrfs-cleaner func=add_pinned_bytes() 943976448 + 21762048 = 965738496
      [ 2569.908270] comm=btrfs-cleaner func=btrfs_evict_inode() end
    
    Fix:
      Make btrfs_commit_transaction() wait current running btrfs-cleaner's
      delayed-iputs() done in end.
    
    Test:
      Use script similar to above(more complex),
      before patch:
        7 failed in 100 * 20 loop.
      after patch:
        0 failed in 100 * 20 loop.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 10b6a75ab7e6..d48b22f31182 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1538,6 +1538,7 @@ struct btrfs_fs_info {
 
 	spinlock_t delayed_iput_lock;
 	struct list_head delayed_iputs;
+	struct rw_semaphore delayed_iput_sem;
 
 	/* this protects tree_mod_seq_list */
 	spinlock_t tree_mod_seq_lock;

commit cdfb080e1853660952db5e5332727e59427856df
Author: Chris Mason <clm@fb.com>
Date:   Mon Apr 6 18:17:00 2015 -0700

    Btrfs: fix use after free when close_ctree frees the orphan_rsv
    
    Near the end of close_ctree, we're calling btrfs_free_block_rsv
    to free up the orphan rsv.  The problem is this call updates the
    space_info, which has already been freed.
    
    This adds a new __ function that directly calls kfree instead of trying
    to update the space infos.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 83051fae9467..10b6a75ab7e6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3470,6 +3470,7 @@ struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root,
 					      unsigned short type);
 void btrfs_free_block_rsv(struct btrfs_root *root,
 			  struct btrfs_block_rsv *rsv);
+void __btrfs_free_block_rsv(struct btrfs_block_rsv *rsv);
 int btrfs_block_rsv_add(struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv, u64 num_bytes,
 			enum btrfs_reserve_flush_enum flush);

commit 1bbc621ef28462456131c035eaeb5567a1a2a2fe
Author: Chris Mason <clm@fb.com>
Date:   Mon Apr 6 12:46:08 2015 -0700

    Btrfs: allow block group cache writeout outside critical section in commit
    
    We loop through all of the dirty block groups during commit and write
    the free space cache.  In order to make sure the cache is currect, we do
    this while no other writers are allowed in the commit.
    
    If a large number of block groups are dirty, this can introduce long
    stalls during the final stages of the commit, which can block new procs
    trying to change the filesystem.
    
    This commit changes the block group cache writeout to take appropriate
    locks and allow it to run earlier in the commit.  We'll still have to
    redo some of the block groups, but it means we can get most of the work
    out of the way without blocking the entire FS.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1df0d9db5332..83051fae9467 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1491,6 +1491,12 @@ struct btrfs_fs_info {
 	struct mutex chunk_mutex;
 	struct mutex volume_mutex;
 
+	/*
+	 * this is taken to make sure we don't set block groups ro after
+	 * the free space cache has been allocated on them
+	 */
+	struct mutex ro_block_group_mutex;
+
 	/* this is used during read/modify/write to make sure
 	 * no two ios are trying to mod the same stripe at the same
 	 * time
@@ -3407,6 +3413,8 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 u64 bytenr, u64 num_bytes, u64 parent,
 			 u64 root_objectid, u64 owner, u64 offset, int no_quota);
 
+int btrfs_start_dirty_block_groups(struct btrfs_trans_handle *trans,
+				   struct btrfs_root *root);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
 int btrfs_setup_space_cache(struct btrfs_trans_handle *trans,

commit c9dc4c6578502c2085705347375b82089aad18d0
Author: Chris Mason <clm@fb.com>
Date:   Sat Apr 4 17:14:42 2015 -0700

    Btrfs: two stage dirty block group writeout
    
    Block group cache writeout is currently waiting on the pages for each
    block group cache before moving on to writing the next one.  This commit
    switches things around to send down all the caches and then wait on them
    in batches.
    
    The end result is much faster, since we're keeping the disk pipeline
    full.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e305ccd731fe..1df0d9db5332 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1261,9 +1261,12 @@ struct btrfs_io_ctl {
 	struct page *page;
 	struct page **pages;
 	struct btrfs_root *root;
+	struct inode *inode;
 	unsigned long size;
 	int index;
 	int num_pages;
+	int entries;
+	int bitmaps;
 	unsigned check_crcs:1;
 };
 
@@ -1332,6 +1335,9 @@ struct btrfs_block_group_cache {
 
 	/* For dirty block groups */
 	struct list_head dirty_list;
+	struct list_head io_list;
+
+	struct btrfs_io_ctl io_ctl;
 };
 
 /* delayed seq elem */

commit 4c6d1d85ad89fd8e32dc9204b7f944854399bda9
Author: Chris Mason <clm@fb.com>
Date:   Mon Apr 6 13:17:20 2015 -0700

    btrfs: move struct io_ctl into ctree.h and rename it
    
    We'll need to put the io_ctl into the block_group cache struct, so
    name it struct btrfs_io_ctl and move it into ctree.h
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6bf16d5134c5..e305ccd731fe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1256,6 +1256,17 @@ struct btrfs_caching_control {
 	atomic_t count;
 };
 
+struct btrfs_io_ctl {
+	void *cur, *orig;
+	struct page *page;
+	struct page **pages;
+	struct btrfs_root *root;
+	unsigned long size;
+	int index;
+	int num_pages;
+	unsigned check_crcs:1;
+};
+
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;

commit 28f75a0e6cdfbce8115487ecbc0968a2c4e01806
Author: Chris Mason <clm@fb.com>
Date:   Wed Feb 4 06:59:29 2015 -0800

    Btrfs: refill block reserves during truncate
    
    When truncate starts, it allocates some space in the block reserves so
    that we'll have enough to update metadata along the way.
    
    For very large files, we can easily go through all of that space as we
    loop through the extents.  This changes truncate to refill the space
    reservation as it progresses through the file.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 95944b81ed5c..6bf16d5134c5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3297,6 +3297,9 @@ static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 }
 
 /* extent-tree.c */
+
+u64 btrfs_csum_bytes_to_leaves(struct btrfs_root *root, u64 csum_bytes);
+
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)
 {

commit fc4c3c872f44bf425963feba57eb9c3f8ac2d7eb
Merge: 9deed229fa8a a4f3d2c4efe2
Author: Chris Mason <clm@fb.com>
Date:   Wed Mar 25 10:52:48 2015 -0700

    Merge branch 'cleanups-post-3.19' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.1
    
    Signed-off-by: Chris Mason <clm@fb.com>
    
    Conflicts:
            fs/btrfs/disk-io.c

commit 9deed229fa8a83bb5cd713b2d2a8e5c022a4b45b
Merge: bc465aa9d045 258ece02126a
Author: Chris Mason <clm@fb.com>
Date:   Wed Mar 25 10:43:16 2015 -0700

    Merge branch 'cleanups-for-4.1-v2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.1

commit 521d474631310e8aafef7953a8a7f7d1efd42da6
Merge: 0d122f7430ed e1cbbfa5f5aa
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 21 10:53:37 2015 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Most of these are fixing extent reservation accounting, or corners
      with tree writeback during commit.
    
      Josef's set does add a test, which isn't strictly a fix, but it'll
      keep us from making this same mistake again"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix outstanding_extents accounting in DIO
      Btrfs: add sanity test for outstanding_extents accounting
      Btrfs: just free dummy extent buffers
      Btrfs: account merges/splits properly
      Btrfs: prepare block group cache before writing
      Btrfs: fix ASSERT(list_empty(&cur_trans->dirty_bgs_list)
      Btrfs: account for the correct number of extents for delalloc reservations
      Btrfs: fix merge delalloc logic
      Btrfs: fix comp_oper to get right order
      Btrfs: catch transaction abortion after waiting for it
      btrfs: fix sizeof format specifier in btrfs_check_super_valid()

commit 6a3891c551268dd4ff0969b883c4c8b8d974db8f
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Mar 16 17:38:52 2015 -0400

    Btrfs: add sanity test for outstanding_extents accounting
    
    I introduced a regression wrt outstanding_extents accounting.  These are tricky
    areas that aren't easily covered by xfstests as we could change MAX_EXTENT_SIZE
    at any time.  So add sanity tests to cover the various conditions that are
    tricky in order to make sure we don't introduce regressions in the future.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a0c90a324f53..5bd721a1516e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3910,6 +3910,9 @@ int btrfs_prealloc_file_range_trans(struct inode *inode,
 				    loff_t actual_len, u64 *alloc_hint);
 int btrfs_inode_check_errors(struct inode *inode);
 extern const struct dentry_operations btrfs_dentry_operations;
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+void btrfs_test_inode_set_ops(struct inode *inode);
+#endif
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit dcdf7f6ddba006f3482ebee73dfa6b75aec5f07b
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Mar 2 16:37:31 2015 -0500

    Btrfs: prepare block group cache before writing
    
    Writing the block group cache will modify the extent tree quite a bit because it
    truncates the old space cache and pre-allocates new stuff.  To try and cut down
    on the churn lets do the setup dance first, then later on hopefully we can avoid
    looping with newly dirtied roots.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b3dd55f52f71..a0c90a324f53 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3386,6 +3386,8 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
+int btrfs_setup_space_cache(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root);
 int btrfs_extent_readonly(struct btrfs_root *root, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_root *root);

commit 3284da7b7b585e6e8e98f374a51d234d14c7a0a2
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 25 15:47:32 2015 +0100

    btrfs: use explicit initializer for seq_elem
    
    Using {} as initializer for struct seq_elem does not properly initialize
    the list_head member, but it currently works because it gets set through
    btrfs_get_tree_mod_seq if 'seq' is 0.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b3dd55f52f71..36e009ebab47 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1328,6 +1328,8 @@ struct seq_list {
 	u64 seq;
 };
 
+#define SEQ_LIST_INIT(name)	{ .list = LIST_HEAD_INIT((name).list), .seq = 0 }
+
 enum btrfs_orphan_cleanup_state {
 	ORPHAN_CLEANUP_STARTED	= 1,
 	ORPHAN_CLEANUP_DONE	= 2,

commit 2b9fb532d4168e8974fe49709e2c4c8d5352a64c
Merge: 4533f6e27a36 a742994aa2e2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 19 14:36:00 2015 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This pull is mostly cleanups and fixes:
    
       - The raid5/6 cleanups from Zhao Lei fixup some long standing warts
         in the code and add improvements on top of the scrubbing support
         from 3.19.
    
       - Josef has round one of our ENOSPC fixes coming from large btrfs
         clusters here at FB.
    
       - Dave Sterba continues a long series of cleanups (thanks Dave), and
         Filipe continues hammering on corner cases in fsync and others
    
      This all was held up a little trying to track down a use-after-free in
      btrfs raid5/6.  It's not clear yet if this is just made easier to
      trigger with this pull or if its a new bug from the raid5/6 cleanups.
      Dave Sterba is the only one to trigger it so far, but he has a
      consistent way to reproduce, so we'll get it nailed shortly"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (68 commits)
      Btrfs: don't remove extents and xattrs when logging new names
      Btrfs: fix fsync data loss after adding hard link to inode
      Btrfs: fix BUG_ON in btrfs_orphan_add() when delete unused block group
      Btrfs: account for large extents with enospc
      Btrfs: don't set and clear delalloc for O_DIRECT writes
      Btrfs: only adjust outstanding_extents when we do a short write
      btrfs: Fix out-of-space bug
      Btrfs: scrub, fix sleep in atomic context
      Btrfs: fix scheduler warning when syncing log
      Btrfs: Remove unnecessary placeholder in btrfs_err_code
      btrfs: cleanup init for list in free-space-cache
      btrfs: delete chunk allocation attemp when setting block group ro
      btrfs: clear bio reference after submit_one_bio()
      Btrfs: fix scrub race leading to use-after-free
      Btrfs: add missing cleanup on sysfs init failure
      Btrfs: fix race between transaction commit and empty block group removal
      btrfs: add more checks to btrfs_read_sys_array
      btrfs: cleanup, rename a few variables in btrfs_read_sys_array
      btrfs: add checks for sys_chunk_array sizes
      btrfs: more superblock checks, lower bounds on devices and sectorsize/nodesize
      ...

commit b7a0365ec7a0fb1d39113846fd34038af68ebd01
Author: Daniel Dressler <danieru.dressler@gmail.com>
Date:   Wed Nov 12 13:43:09 2014 +0900

    Btrfs: ctree: reduce args where only fs_info used
    
    This patch is part of a larger project to cleanup btrfs's internal usage
    of struct btrfs_root. Many functions take btrfs_root only to grab a
    pointer to fs_info.
    
    This causes programmers to ponder which root can be passed. Since only
    the fs_info is read affected functions can accept any root, except this
    is only obvious upon inspection.
    
    This patch reduces the specificty of such functions to accept the
    fs_info directly.
    
    This patch does not address the two functions in ctree.c (insert_ptr,
    and split_item) which only use root for BUG_ONs in ctree.c
    
    This patch affects the following functions:
      1) fixup_low_keys
      2) btrfs_set_item_key_safe
    
    Signed-off-by: Daniel Dressler <danieru.dressler@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b3dd55f52f71..216056c37940 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3483,7 +3483,8 @@ int btrfs_previous_item(struct btrfs_root *root,
 			int type);
 int btrfs_previous_extent_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid);
-void btrfs_set_item_key_safe(struct btrfs_root *root, struct btrfs_path *path,
+void btrfs_set_item_key_safe(struct btrfs_fs_info *fs_info,
+			     struct btrfs_path *path,
 			     struct btrfs_key *new_key);
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);

commit dcab6a3b2ae657a2017637083c28ee303b6b1b8e
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Feb 11 15:08:59 2015 -0500

    Btrfs: account for large extents with enospc
    
    On our gluster boxes we stream large tar balls of backups onto our fses.  With
    160gb of ram this means we get really large contiguous ranges of dirty data, but
    the way our ENOSPC stuff works is that as long as it's contiguous we only hold
    metadata reservation for one extent.  The problem is we limit our extents to
    128mb, so we'll end up with at least 800 extents so our enospc accounting is
    quite a bit lower than what we need.  To keep track of this make sure we
    increase outstanding_extents for every multiple of the max extent size so we can
    be sure to have enough reserved metadata space.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d3562dd43c66..b3dd55f52f71 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -198,6 +198,8 @@ static int btrfs_csum_sizes[] = { 4, 0 };
 
 #define BTRFS_DIRTY_METADATA_THRESH	(32 * 1024 * 1024)
 
+#define BTRFS_MAX_EXTENT_SIZE (128 * 1024 * 1024)
+
 /*
  * The key defines the order in the tree, and so it also defines (optimal)
  * block layout.

commit d4b450cd4b33ce7c572e7fdccf33b59c4cdf361c
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jan 29 19:18:25 2015 +0000

    Btrfs: fix race between transaction commit and empty block group removal
    
    Committing a transaction can race with automatic removal of empty block
    groups (cleaner kthread), leading to a BUG_ON() in the transaction
    commit code while running btrfs_finish_extent_commit(). The following
    sequence diagram shows how it can happen:
    
               CPU 1                                       CPU 2
    
    btrfs_commit_transaction()
      fs_info->running_transaction = NULL
      btrfs_finish_extent_commit()
        find_first_extent_bit()
          -> found range for block group X
             in fs_info->freed_extents[]
    
                                                   btrfs_delete_unused_bgs()
                                                     -> found block group X
    
                                                     Removed block group X's range
                                                     from fs_info->freed_extents[]
    
                                                     btrfs_remove_chunk()
                                                        btrfs_remove_block_group(bg X)
    
        unpin_extent_range(bg X range)
           btrfs_lookup_block_group(bg X)
              -> returns NULL
                -> BUG_ON()
    
    The trace that results from the BUG_ON() is:
    
    [48665.187808] ------------[ cut here ]------------
    [48665.188032] kernel BUG at fs/btrfs/extent-tree.c:5675!
    [48665.188032] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC
    [48665.188032] Modules linked in: dm_flakey dm_mod crc32c_generic btrfs xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop parport_pc evdev microcode
    [48665.197388] CPU: 2 PID: 31211 Comm: kworker/u32:16 Tainted: G        W      3.19.0-rc5-btrfs-next-4+ #1
    [48665.197388] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    [48665.197388] Workqueue: events_unbound btrfs_async_reclaim_metadata_space [btrfs]
    [48665.197388] task: ffff880222011810 ti: ffff8801b56a4000 task.ti: ffff8801b56a4000
    [48665.197388] RIP: 0010:[<ffffffffa0350d05>]  [<ffffffffa0350d05>] unpin_extent_range+0x6a/0x1ba [btrfs]
    [48665.197388] RSP: 0018:ffff8801b56a7b88  EFLAGS: 00010246
    [48665.197388] RAX: 0000000000000000 RBX: ffff8802143a6000 RCX: ffff8802220120c8
    [48665.197388] RDX: 0000000000000001 RSI: 0000000000000001 RDI: ffff8800a3c140b0
    [48665.197388] RBP: ffff8801b56a7bd8 R08: 0000000000000003 R09: 0000000000000000
    [48665.197388] R10: 0000000000000000 R11: 000000000000bbac R12: 0000000012e8e000
    [48665.197388] R13: ffff8800a3c14000 R14: 0000000000000000 R15: 0000000000000000
    [48665.197388] FS:  0000000000000000(0000) GS:ffff88023ec40000(0000) knlGS:0000000000000000
    [48665.197388] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [48665.197388] CR2: 00007f065e42f270 CR3: 0000000206f70000 CR4: 00000000000006e0
    [48665.197388] Stack:
    [48665.197388]  ffff8801b56a7bd8 0000000012ea0000 01ff8800a3c14138 0000000012e9ffff
    [48665.197388]  ffff880141df3dd8 ffff8802143a6000 ffff8800a3c14138 ffff880141df3df0
    [48665.197388]  ffff880141df3dd8 0000000000000000 ffff8801b56a7c08 ffffffffa0354227
    [48665.197388] Call Trace:
    [48665.197388]  [<ffffffffa0354227>] btrfs_finish_extent_commit+0xb0/0xd9 [btrfs]
    [48665.197388]  [<ffffffffa0366b4b>] btrfs_commit_transaction+0x791/0x92c [btrfs]
    [48665.197388]  [<ffffffffa0352432>] flush_space+0x43d/0x452 [btrfs]
    [48665.197388]  [<ffffffff814295c3>] ? _raw_spin_unlock+0x28/0x33
    [48665.197388]  [<ffffffffa035255f>] btrfs_async_reclaim_metadata_space+0x118/0x164 [btrfs]
    [48665.197388]  [<ffffffff81059917>] ? process_one_work+0x14b/0x3ab
    [48665.197388]  [<ffffffff810599ac>] process_one_work+0x1e0/0x3ab
    [48665.197388]  [<ffffffff81079fa9>] ? trace_hardirqs_off+0xd/0xf
    [48665.197388]  [<ffffffff8105a55b>] worker_thread+0x210/0x2d0
    [48665.197388]  [<ffffffff8105a34b>] ? rescuer_thread+0x2c3/0x2c3
    [48665.197388]  [<ffffffff8105e5c0>] kthread+0xef/0xf7
    [48665.197388]  [<ffffffff81429682>] ? _raw_spin_unlock_irq+0x2d/0x39
    [48665.197388]  [<ffffffff8105e4d1>] ? __kthread_parkme+0xad/0xad
    [48665.197388]  [<ffffffff81429dec>] ret_from_fork+0x7c/0xb0
    [48665.197388]  [<ffffffff8105e4d1>] ? __kthread_parkme+0xad/0xad
    [48665.197388] Code: 85 f6 74 14 49 8b 06 49 03 46 09 49 39 c4 72 1d 4c 89 f7 e8 83 ec ff ff 4c 89 e6 4c 89 ef e8 1e f1 ff ff 48 85 c0 49 89 c6 75 02 <0f> 0b 49 8b 1e 49 03 5e 09 48 8b
    [48665.197388] RIP  [<ffffffffa0350d05>] unpin_extent_range+0x6a/0x1ba [btrfs]
    [48665.197388]  RSP <ffff8801b56a7b88>
    [48665.272246] ---[ end trace b9c6ab9957521376 ]---
    
    Fix this by ensuring that unpining the block group's range in
    btrfs_finish_extent_commit() is done in a synchronized fashion
    with removing the block group's range from freed_extents[]
    in btrfs_delete_unused_bgs()
    
    This race got introduced with the change:
    
        Btrfs: remove empty block groups automatically
        commit 47ab2a6c689913db23ccae38349714edf8365e0a
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 54a66fa6beb1..d3562dd43c66 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1744,6 +1744,7 @@ struct btrfs_fs_info {
 
 	spinlock_t unused_bgs_lock;
 	struct list_head unused_bgs;
+	struct mutex unused_bg_unpin_mutex;
 
 	/* For btrfs to record security options */
 	struct security_mnt_opts security_opts;

commit a937b9791ec2ee71d5e303d2c02c8c1ad8abff35
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Dec 12 17:39:12 2014 +0100

    btrfs: kill btrfs_inode_*time helpers
    
    They just opencode taking address of the timespec member.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 85c697d482c2..54a66fa6beb1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2467,31 +2467,6 @@ BTRFS_SETGET_STACK_FUNCS(stack_inode_gid, struct btrfs_inode_item, gid, 32);
 BTRFS_SETGET_STACK_FUNCS(stack_inode_mode, struct btrfs_inode_item, mode, 32);
 BTRFS_SETGET_STACK_FUNCS(stack_inode_rdev, struct btrfs_inode_item, rdev, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_inode_flags, struct btrfs_inode_item, flags, 64);
-
-static inline struct btrfs_timespec *
-btrfs_inode_atime(struct btrfs_inode_item *inode_item)
-{
-	unsigned long ptr = (unsigned long)inode_item;
-	ptr += offsetof(struct btrfs_inode_item, atime);
-	return (struct btrfs_timespec *)ptr;
-}
-
-static inline struct btrfs_timespec *
-btrfs_inode_mtime(struct btrfs_inode_item *inode_item)
-{
-	unsigned long ptr = (unsigned long)inode_item;
-	ptr += offsetof(struct btrfs_inode_item, mtime);
-	return (struct btrfs_timespec *)ptr;
-}
-
-static inline struct btrfs_timespec *
-btrfs_inode_ctime(struct btrfs_inode_item *inode_item)
-{
-	unsigned long ptr = (unsigned long)inode_item;
-	ptr += offsetof(struct btrfs_inode_item, ctime);
-	return (struct btrfs_timespec *)ptr;
-}
-
 BTRFS_SETGET_FUNCS(timespec_sec, struct btrfs_timespec, sec, 64);
 BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_timespec, nsec, 32);
 BTRFS_SETGET_STACK_FUNCS(stack_timespec_sec, struct btrfs_timespec, sec, 64);

commit 78f55e5e1fa9f684705325667d455a957f43ad66
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Jan 13 00:55:10 2015 +0800

    Btrfs: fix unused members in struct btrfs_root
    
    There isn't any real use of following members of struct btrfs_root
    so delete them.
    
    struct kobject root_kobj;
    struct completion kobj_unregister;
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2ecdac0bd850..85c697d482c2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1798,8 +1798,6 @@ struct btrfs_root {
 	struct btrfs_fs_info *fs_info;
 	struct extent_io_tree dirty_log_pages;
 
-	struct kobject root_kobj;
-	struct completion kobj_unregister;
 	struct mutex objectid_mutex;
 
 	spinlock_t accounting_lock;

commit ffe2d2034bbb34f49f76c808550fdfbea2ea1659
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Tue Jan 20 15:11:44 2015 +0800

    Btrfs: Introduce BTRFS_BLOCK_GROUP_RAID56_MASK to check raid56 simply
    
    So we can check raid56 with:
     (map->type & BTRFS_BLOCK_GROUP_RAID56_MASK)
    instead of long:
     (map->type & (BTRFS_BLOCK_GROUP_RAID5 | BTRFS_BLOCK_GROUP_RAID6))
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0b4683f560c8..2ecdac0bd850 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1020,6 +1020,9 @@ enum btrfs_raid_types {
 					 BTRFS_BLOCK_GROUP_RAID6 |   \
 					 BTRFS_BLOCK_GROUP_DUP |     \
 					 BTRFS_BLOCK_GROUP_RAID10)
+#define BTRFS_BLOCK_GROUP_RAID56_MASK	(BTRFS_BLOCK_GROUP_RAID5 |   \
+					 BTRFS_BLOCK_GROUP_RAID6)
+
 /*
  * We need a bit for restriper to be able to tell when chunks of type
  * SINGLE are available.  This "extended" profile format is used in

commit ce93ec548cfa02f9cd6b70d546d5f36f4d160f57
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Nov 17 15:45:48 2014 -0500

    Btrfs: track dirty block groups on their own list
    
    Currently any time we try to update the block groups on disk we will walk _all_
    block groups and check for the ->dirty flag to see if it is set.  This function
    can get called several times during a commit.  So if you have several terabytes
    of data you will be a very sad panda as we will loop through _all_ of the block
    groups several times, which makes the commit take a while which slows down the
    rest of the file system operations.
    
    This patch introduces a dirty list for the block groups that we get added to
    when we dirty the block group for the first time.  Then we simply update any
    block groups that have been dirtied since the last time we called
    btrfs_write_dirty_block_groups.  This allows us to clean up how we write the
    free space cache out so it is much cleaner.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 45ed4dc6a0ce..0b4683f560c8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1238,7 +1238,6 @@ enum btrfs_disk_cache_state {
 	BTRFS_DC_ERROR		= 1,
 	BTRFS_DC_CLEAR		= 2,
 	BTRFS_DC_SETUP		= 3,
-	BTRFS_DC_NEED_WRITE	= 4,
 };
 
 struct btrfs_caching_control {
@@ -1276,7 +1275,6 @@ struct btrfs_block_group_cache {
 	unsigned long full_stripe_len;
 
 	unsigned int ro:1;
-	unsigned int dirty:1;
 	unsigned int iref:1;
 	unsigned int has_caching_ctl:1;
 	unsigned int removed:1;
@@ -1314,6 +1312,9 @@ struct btrfs_block_group_cache {
 	struct list_head ro_list;
 
 	atomic_t trimming;
+
+	/* For dirty block groups */
+	struct list_head dirty_list;
 };
 
 /* delayed seq elem */

commit e7070be198b34c26f39bd9010a29ce6462dc4f3e
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue Dec 16 08:54:43 2014 -0800

    Btrfs: change how we track dirty roots
    
    I've been overloading root->dirty_list to keep track of dirty roots and which
    roots need to have their commit roots switched at transaction commit time.  This
    could cause us to lose an update to the root which could corrupt the file
    system.  To fix this use a state bit to know if the root is dirty, and if it
    isn't set we go ahead and move the root to the dirty list.  This way if we
    re-dirty the root after adding it to the switch_commit list we make sure to
    update it.  This also makes it so that the extent root is always the last root
    on the dirty list to try and keep the amount of churn down at this point in the
    commit.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7e607416755a..45ed4dc6a0ce 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1775,6 +1775,7 @@ struct btrfs_subvolume_writers {
 #define BTRFS_ROOT_DEFRAG_RUNNING	6
 #define BTRFS_ROOT_FORCE_COW		7
 #define BTRFS_ROOT_MULTI_LOG_TASKS	8
+#define BTRFS_ROOT_DIRTY		9
 
 /*
  * in ram representation of the tree.  extent_root is used for all allocations

commit 75c68e9fbbdfc04467c9edcac76be998beaa630b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Jan 16 13:24:40 2015 +0000

    Btrfs: fix race deleting block group from space_info->ro_bgs list
    
    When removing a block group we were deleting it from its space_info's
    ro_bgs list without the correct protection - the space info's spinlock.
    Fix this by doing the list delete while holding the spinlock of the
    corresponding space info, which is the correct lock for any operation
    on that list.
    
    This issue was introduced in the 3.19 kernel by the following change:
    
        Btrfs: move read only block groups onto their own list V2
        commit 633c0aad4c0243a506a3e8590551085ad78af82d
    
    I ran into a kernel crash while a task was running statfs, which iterates
    the space_info->ro_bgs list while holding the space info's spinlock,
    and another task was deleting it from the same list, without holding that
    spinlock, as part of the block group remove operation (while running the
    function btrfs_remove_block_group). This happened often when running the
    stress test xfstests/generic/038 I recently made.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7e607416755a..0b180708bf79 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1171,6 +1171,7 @@ struct btrfs_space_info {
 	struct percpu_counter total_bytes_pinned;
 
 	struct list_head list;
+	/* Protected by the spinlock 'lock'. */
 	struct list_head ro_bgs;
 
 	struct rw_semaphore groups_sem;

commit 1edb647bb95439d90c0017e9ca23c4ecf00a0409
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Dec 8 14:01:12 2014 +0000

    Btrfs: remove non-sense btrfs_error_discard_extent() function
    
    It doesn't do anything special, it just calls btrfs_discard_extent(),
    so just remove it.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e6fbbd74b716..7e607416755a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3481,8 +3481,8 @@ void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
 int btrfs_error_unpin_extent_range(struct btrfs_root *root,
 				   u64 start, u64 end);
-int btrfs_error_discard_extent(struct btrfs_root *root, u64 bytenr,
-			       u64 num_bytes, u64 *actual_bytes);
+int btrfs_discard_extent(struct btrfs_root *root, u64 bytenr,
+			 u64 num_bytes, u64 *actual_bytes);
 int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root, u64 type);
 int btrfs_trim_fs(struct btrfs_root *root, struct fstrim_range *range);

commit 9627aeee3e203e30679549e4962633698a6bf87f
Merge: cb83b7b81698 5d3edd8f44aa
Author: Chris Mason <clm@fb.com>
Date:   Tue Dec 2 18:42:03 2014 -0800

    Merge branch 'raid56-scrub-replace' of git://github.com/miaoxie/linux-btrfs into for-linus

commit 04216820fe83d5e27322065ba989de27dbfc104d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Nov 27 21:14:15 2014 +0000

    Btrfs: fix race between fs trimming and block group remove/allocation
    
    Our fs trim operation, which is completely transactionless (doesn't start
    or joins an existing transaction) consists of visiting all block groups
    and then for each one to iterate its free space entries and perform a
    discard operation against the space range represented by the free space
    entries. However before performing a discard, the corresponding free space
    entry is removed from the free space rbtree, and when the discard completes
    it is added back to the free space rbtree.
    
    If a block group remove operation happens while the discard is ongoing (or
    before it starts and after a free space entry is hidden), we end up not
    waiting for the discard to complete, remove the extent map that maps
    logical address to physical addresses and the corresponding chunk metadata
    from the the chunk and device trees. After that and before the discard
    completes, the current running transaction can finish and a new one start,
    allowing for new block groups that map to the same physical addresses to
    be allocated and written to.
    
    So fix this by keeping the extent map in memory until the discard completes
    so that the same physical addresses aren't reused before it completes.
    
    If the physical locations that are under a discard operation end up being
    used for a new metadata block group for example, and dirty metadata extents
    are written before the discard finishes (the VM might call writepages() of
    our btree inode's i_mapping for example, or an fsync log commit happens) we
    end up overwriting metadata with zeroes, which leads to errors from fsck
    like the following:
    
            checking extents
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            read block failed check_tree_block
            owner ref check failed [833912832 16384]
            Errors found in extent allocation tree or chunk allocation
            checking free space cache
            checking fs roots
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            read block failed check_tree_block
            root 5 root dir 256 error
            root 5 inode 260 errors 2001, no inode item, link count wrong
                    unresolved ref dir 256 index 0 namelen 8 name foobar_3 filetype 1 errors 6, no dir index, no inode ref
            root 5 inode 262 errors 2001, no inode item, link count wrong
                    unresolved ref dir 256 index 0 namelen 8 name foobar_5 filetype 1 errors 6, no dir index, no inode ref
            root 5 inode 263 errors 2001, no inode item, link count wrong
            (...)
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 302f37c56546..d71915e04e92 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1279,6 +1279,7 @@ struct btrfs_block_group_cache {
 	unsigned int dirty:1;
 	unsigned int iref:1;
 	unsigned int has_caching_ctl:1;
+	unsigned int removed:1;
 
 	int disk_cache_state;
 
@@ -1311,6 +1312,8 @@ struct btrfs_block_group_cache {
 
 	/* For read-only block groups */
 	struct list_head ro_list;
+
+	atomic_t trimming;
 };
 
 /* delayed seq elem */
@@ -1740,6 +1743,12 @@ struct btrfs_fs_info {
 
 	/* For btrfs to record security options */
 	struct security_mnt_opts security_opts;
+
+	/*
+	 * Chunks that can't be freed yet (under a trim/discard operation)
+	 * and will be latter freed. Protected by fs_info->chunk_mutex.
+	 */
+	struct list_head pinned_chunks;
 };
 
 struct btrfs_subvolume_writers {
@@ -3405,7 +3414,8 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 type, u64 chunk_objectid, u64 chunk_offset,
 			   u64 size);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *root, u64 group_start);
+			     struct btrfs_root *root, u64 group_start,
+			     struct extent_map *em);
 void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
 void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
 				       struct btrfs_root *root);

commit 4f69cb987ecbb6a87b5b1d56d6e9f9b5fee69737
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Nov 26 15:28:51 2014 +0000

    Btrfs: fix crash caused by block group removal
    
    If we remove a block group (because it became empty), we might have left
    a caching_ctl structure in fs_info->caching_block_groups that points to
    the block group and is accessed at transaction commit time. This results
    in accessing an invalid or incorrect block group. This issue became visible
    after Josef's patch "Btrfs: remove empty block groups automatically".
    
    So if the block group is removed make sure we don't leave a dangling
    caching_ctl in caching_block_groups.
    
    Sample crash trace:
    
    [58380.439449] BUG: unable to handle kernel paging request at ffff8801446eaeb8
    [58380.439707] IP: [<ffffffffa03f6d05>] block_group_cache_done.isra.21+0xc/0x1c [btrfs]
    [58380.440879] PGD 1acb067 PUD 23f5ff067 PMD 23f5db067 PTE 80000001446ea060
    [58380.441220] Oops: 0000 [#1] SMP DEBUG_PAGEALLOC
    [58380.441486] Modules linked in: btrfs crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd fscache sunrpc loop psmouse processor i2c_piix4 parport_pc parport pcspkr serio_raw evdev i2ccore thermal_sys microcode button ext4 crc16 jbd2 mbcache sr_mod cdrom ata_generic sg sd_mod crc_t10dif crct10dif_generic crct10dif_common virtio_scsi floppy ata_piix e1000 libata virtio_pci scsi_mod virtio_ring virtio [last unloaded: btrfs]
    [58380.443238] CPU: 3 PID: 25728 Comm: btrfs-transacti Tainted: G        W      3.17.0-rc5-btrfs-next-1+ #1
    [58380.443238] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    [58380.443238] task: ffff88013ac82090 ti: ffff88013896c000 task.ti: ffff88013896c000
    [58380.443238] RIP: 0010:[<ffffffffa03f6d05>]  [<ffffffffa03f6d05>] block_group_cache_done.isra.21+0xc/0x1c [btrfs]
    [58380.443238] RSP: 0018:ffff88013896fdd8  EFLAGS: 00010283
    [58380.443238] RAX: ffff880222cae850 RBX: ffff880119ba74c0 RCX: 0000000000000000
    [58380.443238] RDX: 0000000000000000 RSI: ffff880185e16800 RDI: ffff8801446eaeb8
    [58380.443238] RBP: ffff88013896fdd8 R08: ffff8801a9ca9fa8 R09: ffff88013896fc60
    [58380.443238] R10: ffff88013896fd28 R11: 0000000000000000 R12: ffff880222cae000
    [58380.443238] R13: ffff880222cae850 R14: ffff880222cae6b0 R15: ffff8801446eae00
    [58380.443238] FS:  0000000000000000(0000) GS:ffff88023ed80000(0000) knlGS:0000000000000000
    [58380.443238] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [58380.443238] CR2: ffff8801446eaeb8 CR3: 0000000001811000 CR4: 00000000000006e0
    [58380.443238] Stack:
    [58380.443238]  ffff88013896fe18 ffffffffa03fe2d5 ffff880222cae850 ffff880185e16800
    [58380.443238]  ffff88000dc41c20 0000000000000000 ffff8801a9ca9f00 0000000000000000
    [58380.443238]  ffff88013896fe80 ffffffffa040fbcf ffff88018b0dcdb0 ffff88013ac82090
    [58380.443238] Call Trace:
    [58380.443238]  [<ffffffffa03fe2d5>] btrfs_prepare_extent_commit+0x5a/0xd7 [btrfs]
    [58380.443238]  [<ffffffffa040fbcf>] btrfs_commit_transaction+0x45c/0x882 [btrfs]
    [58380.443238]  [<ffffffffa040c058>] transaction_kthread+0xf2/0x1a4 [btrfs]
    [58380.443238]  [<ffffffffa040bf66>] ? btrfs_cleanup_transaction+0x3d8/0x3d8 [btrfs]
    [58380.443238]  [<ffffffff8105966b>] kthread+0xb7/0xbf
    [58380.443238]  [<ffffffff810595b4>] ? __kthread_parkme+0x67/0x67
    [58380.443238]  [<ffffffff813ebeac>] ret_from_fork+0x7c/0xb0
    [58380.443238]  [<ffffffff810595b4>] ? __kthread_parkme+0x67/0x67
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fc73e86235e8..302f37c56546 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1278,6 +1278,7 @@ struct btrfs_block_group_cache {
 	unsigned int ro:1;
 	unsigned int dirty:1;
 	unsigned int iref:1;
+	unsigned int has_caching_ctl:1;
 
 	int disk_cache_state;
 

commit 4245215d6a8dba1a51c50533b6667919687c0b89
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Nov 25 16:39:28 2014 +0800

    Btrfs, raid56: fix use-after-free problem in the final device replace procedure on raid56
    
    The commit c404e0dc (Btrfs: fix use-after-free in the finishing
    procedure of the device replace) fixed a use-after-free problem
    which happened when removing the source device at the end of device
    replace, but at that time, btrfs didn't support device replace
    on raid56, so we didn't fix the problem on the raid56 profile.
    Currently, we implemented device replace for raid56, so we need
    kick that problem out before we enable that function for raid56.
    
    The fix method is very simple, we just increase the bio per-cpu
    counter before we submit a raid56 io, and decrease the counter
    when the raid56 io ends.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fe69edda11fb..470e3177a7e8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4097,7 +4097,12 @@ int btrfs_scrub_progress(struct btrfs_root *root, u64 devid,
 /* dev-replace.c */
 void btrfs_bio_counter_inc_blocked(struct btrfs_fs_info *fs_info);
 void btrfs_bio_counter_inc_noblocked(struct btrfs_fs_info *fs_info);
-void btrfs_bio_counter_dec(struct btrfs_fs_info *fs_info);
+void btrfs_bio_counter_sub(struct btrfs_fs_info *fs_info, s64 amount);
+
+static inline void btrfs_bio_counter_dec(struct btrfs_fs_info *fs_info)
+{
+	btrfs_bio_counter_sub(fs_info, 1);
+}
 
 /* reada.c */
 struct reada_control {

commit 9ea24bbe17a29f937e7f48e4b15fd52e89e9d386
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Oct 29 11:57:59 2014 +0000

    Btrfs: fix snapshot inconsistency after a file write followed by truncate
    
    If right after starting the snapshot creation ioctl we perform a write against a
    file followed by a truncate, with both operations increasing the file's size, we
    can get a snapshot tree that reflects a state of the source subvolume's tree where
    the file truncation happened but the write operation didn't. This leaves a gap
    between 2 file extent items of the inode, which makes btrfs' fsck complain about it.
    
    For example, if we perform the following file operations:
    
        $ mkfs.btrfs -f /dev/vdd
        $ mount /dev/vdd /mnt
        $ xfs_io -f \
              -c "pwrite -S 0xaa -b 32K 0 32K" \
              -c "fsync" \
              -c "pwrite -S 0xbb -b 32770 16K 32770" \
              -c "truncate 90123" \
              /mnt/foobar
    
    and the snapshot creation ioctl was just called before the second write, we often
    can get the following inode items in the snapshot's btree:
    
            item 120 key (257 INODE_ITEM 0) itemoff 7987 itemsize 160
                    inode generation 146 transid 7 size 90123 block group 0 mode 100600 links 1 uid 0 gid 0 rdev 0 flags 0x0
            item 121 key (257 INODE_REF 256) itemoff 7967 itemsize 20
                    inode ref index 282 namelen 10 name: foobar
            item 122 key (257 EXTENT_DATA 0) itemoff 7914 itemsize 53
                    extent data disk byte 1104855040 nr 32768
                    extent data offset 0 nr 32768 ram 32768
                    extent compression 0
            item 123 key (257 EXTENT_DATA 53248) itemoff 7861 itemsize 53
                    extent data disk byte 0 nr 0
                    extent data offset 0 nr 40960 ram 40960
                    extent compression 0
    
    There's a file range, corresponding to the interval [32K; ALIGN(16K + 32770, 4096)[
    for which there's no file extent item covering it. This is because the file write
    and file truncate operations happened both right after the snapshot creation ioctl
    called btrfs_start_delalloc_inodes(), which means we didn't start and wait for the
    ordered extent that matches the write and, in btrfs_setsize(), we were able to call
    btrfs_cont_expand() before being able to commit the current transaction in the
    snapshot creation ioctl. So this made it possibe to insert the hole file extent
    item in the source subvolume (which represents the region added by the truncate)
    right before the transaction commit from the snapshot creation ioctl.
    
    Btrfs' fsck tool complains about such cases with a message like the following:
    
        "root 331 inode 257 errors 100, file extent discount"
    
    >From a user perspective, the expectation when a snapshot is created while those
    file operations are being performed is that the snapshot will have a file that
    either:
    
    1) is empty
    2) only the first write was captured
    3) only the 2 writes were captured
    4) both writes and the truncation were captured
    
    But never capture a state where only the first write and the truncation were
    captured (since the second write was performed before the truncation).
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9918ba3ec2b2..fc73e86235e8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3480,8 +3480,8 @@ int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
 int __get_raid_index(u64 flags);
-int btrfs_start_nocow_write(struct btrfs_root *root);
-void btrfs_end_nocow_write(struct btrfs_root *root);
+int btrfs_start_write_no_snapshoting(struct btrfs_root *root);
+void btrfs_end_write_no_snapshoting(struct btrfs_root *root);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit ad27c0dab76a7abc8809ec41ae59cf67de5ea906
Merge: b38ef71cb102 a6f69dc8018d
Author: Chris Mason <clm@fb.com>
Date:   Tue Nov 25 05:45:30 2014 -0800

    Merge branch 'dev/pending-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus

commit b38ef71cb102208dffcf4e8524e9d5ec4ec0eaa9
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Nov 13 17:01:45 2014 +0000

    Btrfs: ensure ordered extent errors aren't missed on fsync
    
    When doing a fsync with a fast path we have a time window where we can miss
    the fact that writeback of some file data failed, and therefore we endup
    returning success (0) from fsync when we should return an error.
    The steps that lead to this are the following:
    
    1) We start all ordered extents by calling filemap_fdatawrite_range();
    
    2) We do some other work like locking the inode's i_mutex, start a transaction,
       start a log transaction, etc;
    
    3) We enter btrfs_log_inode(), acquire the inode's log_mutex and collect all the
       ordered extents from inode's ordered tree into a list;
    
    4) But by the time we do ordered extent collection, some ordered extents we started
       at step 1) might have already completed with an error, and therefore we didn't
       found them in the ordered tree and had no idea they finished with an error. This
       makes our fsync return success (0) to userspace, but has no bad effects on the log
       like for example insertion of file extent items into the log that point to unwritten
       extents, because the invalid extent maps were removed before the ordered extent
       completed (in inode.c:btrfs_finish_ordered_io).
    
    So after collecting the ordered extents just check if the inode's i_mapping has any
    error flags set (AS_EIO or AS_ENOSPC) and leave with an error if it does. Whenever
    writeback fails for a page of an ordered extent, we call mapping_set_error (done in
    extent_io.c:end_extent_writepage, called by extent_io.c:end_bio_extent_writepage)
    that sets one of those error flags in the inode's i_mapping flags.
    
    This change also has the side effect of fixing the issue where for fast fsyncs we
    never checked/cleared the error flags from the inode's i_mapping flags, which means
    that a full fsync performed after a fast fsync could get such errors that belonged
    to the fast fsync - because the full fsync calls btrfs_wait_ordered_range() which
    calls filemap_fdatawait_range(), and the later checks for and clears those flags,
    while for fast fsyncs we never call filemap_fdatawait_range() or anything else
    that checks for and clears the error flags from the inode's i_mapping.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a9466e346358..49d956b2cf30 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3866,6 +3866,7 @@ int btrfs_prealloc_file_range_trans(struct inode *inode,
 				    struct btrfs_trans_handle *trans, int mode,
 				    u64 start, u64 num_bytes, u64 min_size,
 				    loff_t actual_len, u64 *alloc_hint);
+int btrfs_inode_check_errors(struct inode *inode);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit 5f5bc6b1e2d5a6f827bc860ef2dc5b6f365d1339
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sun Nov 9 08:38:39 2014 +0000

    Btrfs: make xattr replace operations atomic
    
    Replacing a xattr consists of doing a lookup for its existing value, delete
    the current value from the respective leaf, release the search path and then
    finally insert the new value. This leaves a time window where readers (getxattr,
    listxattrs) won't see any value for the xattr. Xattrs are used to store ACLs,
    so this has security implications.
    
    This change also fixes 2 other existing issues which were:
    
    *) Deleting the old xattr value without verifying first if the new xattr will
       fit in the existing leaf item (in case multiple xattrs are packed in the
       same item due to name hash collision);
    
    *) Returning -EEXIST when the flag XATTR_CREATE is given and the xattr doesn't
       exist but we have have an existing item that packs muliple xattrs with
       the same name hash as the input xattr. In this case we should return ENOSPC.
    
    A test case for xfstests follows soon.
    
    Thanks to Alexandre Oliva for reporting the non-atomicity of the xattr replace
    implementation.
    
    Reported-by: Alexandre Oliva <oliva@gnu.org>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa14081e3383..a9466e346358 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -607,6 +607,7 @@ struct btrfs_path {
 	unsigned int leave_spinning:1;
 	unsigned int search_commit_root:1;
 	unsigned int need_commit_sem:1;
+	unsigned int skip_release_on_error:1;
 };
 
 /*
@@ -3690,6 +3691,10 @@ struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
 int verify_dir_item(struct btrfs_root *root,
 		    struct extent_buffer *leaf,
 		    struct btrfs_dir_item *dir_item);
+struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,
+						 struct btrfs_path *path,
+						 const char *name,
+						 int name_len);
 
 /* orphan.c */
 int btrfs_insert_orphan_item(struct btrfs_trans_handle *trans,

commit 633c0aad4c0243a506a3e8590551085ad78af82d
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Oct 31 09:49:34 2014 -0400

    Btrfs: move read only block groups onto their own list V2
    
    Our gluster boxes were spending lots of time in statfs because our fs'es are
    huge.  The problem is statfs loops through all of the block groups looking for
    read only block groups, and when you have several terabytes worth of data that
    ends up being a lot of block groups.  Move the read only block groups onto a
    read only list and only proces that list in
    btrfs_account_ro_block_groups_free_space to reduce the amount of churn.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b72b35867a7f..fa14081e3383 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1170,6 +1170,7 @@ struct btrfs_space_info {
 	struct percpu_counter total_bytes_pinned;
 
 	struct list_head list;
+	struct list_head ro_bgs;
 
 	struct rw_semaphore groups_sem;
 	/* for block groups in our same type */
@@ -1305,6 +1306,9 @@ struct btrfs_block_group_cache {
 
 	/* For delayed block group creation or deletion of empty block groups */
 	struct list_head bg_list;
+
+	/* For read-only block groups */
+	struct list_head ro_list;
 };
 
 /* delayed seq elem */

commit 728404dacfddb5364d7256d821a2ea482159cbe7
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Oct 10 09:43:11 2014 +0100

    Btrfs: add helper btrfs_fdatawrite_range
    
    To avoid duplicating this double filemap_fdatawrite_range() call for
    inodes with async extents (compressed writes) so often.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fe69edda11fb..b72b35867a7f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3901,6 +3901,7 @@ int btrfs_dirty_pages(struct btrfs_root *root, struct inode *inode,
 		      struct page **pages, size_t num_pages,
 		      loff_t pos, size_t write_bytes,
 		      struct extent_state **cached);
+int btrfs_fdatawrite_range(struct inode *inode, loff_t start, loff_t end);
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,

commit d51033d05547675f898ce4233a7d8d1a0dfe2984
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Nov 12 14:24:35 2014 +0100

    btrfs: introduce pending action: commit
    
    In some contexts, like in sysfs handlers, we don't want to trigger a
    transaction commit. It's a heavy operation, we don't know what external
    locks may be taken. Instead, make it possible to finish the operation
    through sync syscall or SYNC_FS ioctl.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1c9157e4ab0c..817fc19b8159 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2132,6 +2132,7 @@ struct btrfs_ioctl_defrag_range_args {
 
 #define BTRFS_PENDING_SET_INODE_MAP_CACHE	(0)
 #define BTRFS_PENDING_CLEAR_INODE_MAP_CACHE	(1)
+#define BTRFS_PENDING_COMMIT			(2)
 
 #define btrfs_test_pending(info, opt)	\
 	test_bit(BTRFS_PENDING_##opt, &(info)->pending_changes)

commit 7e1876aca815029d5c3023a66a91e249eca3e533
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 15:26:17 2014 +0100

    btrfs: switch inode_cache option handling to pending changes
    
    The pending mount option(s) now share namespace and bits with the normal
    options, and the existing one for (inode_cache) is unset unconditionally
    at each transaction commit.
    
    Introduce a separate namespace for pending changes and enhance the
    descriptions of the intended change to use separate bits for each
    action.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f30b061ef77d..1c9157e4ab0c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2098,7 +2098,6 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)
 #define BTRFS_MOUNT_PANIC_ON_FATAL_ERROR	(1 << 22)
 #define BTRFS_MOUNT_RESCAN_UUID_TREE	(1 << 23)
-#define	BTRFS_MOUNT_CHANGE_INODE_CACHE	(1 << 24)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 #define BTRFS_DEFAULT_MAX_INLINE	(8192)
@@ -2131,6 +2130,9 @@ struct btrfs_ioctl_defrag_range_args {
  * transaction commit)
  */
 
+#define BTRFS_PENDING_SET_INODE_MAP_CACHE	(0)
+#define BTRFS_PENDING_CLEAR_INODE_MAP_CACHE	(1)
+
 #define btrfs_test_pending(info, opt)	\
 	test_bit(BTRFS_PENDING_##opt, &(info)->pending_changes)
 #define btrfs_set_pending(info, opt)	\

commit 572d9ab7845ea0e043ec34cd733a75228130ad03
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 15:26:17 2014 +0100

    btrfs: add support for processing pending changes
    
    There are some actions that modify global filesystem state but cannot be
    performed at the time of request, but later at the transaction commit
    time when the filesystem is in a known state.
    
    For example enabling new incompat features on-the-fly or issuing
    transaction commit from unsafe contexts (sysfs handlers).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fe69edda11fb..f30b061ef77d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1402,6 +1402,11 @@ struct btrfs_fs_info {
 	 */
 	u64 last_trans_log_full_commit;
 	unsigned long mount_opt;
+	/*
+	 * Track requests for actions that need to be done during transaction
+	 * commit (like for some mount options).
+	 */
+	unsigned long pending_changes;
 	unsigned long compress_type:4;
 	int commit_interval;
 	/*
@@ -2103,6 +2108,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define btrfs_raw_test_opt(o, opt)	((o) & BTRFS_MOUNT_##opt)
 #define btrfs_test_opt(root, opt)	((root)->fs_info->mount_opt & \
 					 BTRFS_MOUNT_##opt)
+
 #define btrfs_set_and_info(root, opt, fmt, args...)			\
 {									\
 	if (!btrfs_test_opt(root, opt))					\
@@ -2117,6 +2123,45 @@ struct btrfs_ioctl_defrag_range_args {
 	btrfs_clear_opt(root->fs_info->mount_opt, opt);			\
 }
 
+/*
+ * Requests for changes that need to be done during transaction commit.
+ *
+ * Internal mount options that are used for special handling of the real
+ * mount options (eg. cannot be set during remount and have to be set during
+ * transaction commit)
+ */
+
+#define btrfs_test_pending(info, opt)	\
+	test_bit(BTRFS_PENDING_##opt, &(info)->pending_changes)
+#define btrfs_set_pending(info, opt)	\
+	set_bit(BTRFS_PENDING_##opt, &(info)->pending_changes)
+#define btrfs_clear_pending(info, opt)	\
+	clear_bit(BTRFS_PENDING_##opt, &(info)->pending_changes)
+
+/*
+ * Helpers for setting pending mount option changes.
+ *
+ * Expects corresponding macros
+ * BTRFS_PENDING_SET_ and CLEAR_ + short mount option name
+ */
+#define btrfs_set_pending_and_info(info, opt, fmt, args...)            \
+do {                                                                   \
+       if (!btrfs_raw_test_opt((info)->mount_opt, opt)) {              \
+               btrfs_info((info), fmt, ##args);                        \
+               btrfs_set_pending((info), SET_##opt);                   \
+               btrfs_clear_pending((info), CLEAR_##opt);               \
+       }                                                               \
+} while(0)
+
+#define btrfs_clear_pending_and_info(info, opt, fmt, args...)          \
+do {                                                                   \
+       if (btrfs_raw_test_opt((info)->mount_opt, opt)) {               \
+               btrfs_info((info), fmt, ##args);                        \
+               btrfs_set_pending((info), CLEAR_##opt);                 \
+               btrfs_clear_pending((info), SET_##opt);                 \
+       }                                                               \
+} while(0)
+
 /*
  * Inode flags
  */

commit 1a4ed8fdca077d2489ec47d548451be69389e926
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Oct 27 10:44:24 2014 +0000

    Btrfs: fix invalid leaf slot access in btrfs_lookup_extent()
    
    If we couldn't find our extent item, we accessed the current slot
    (path->slots[0]) to check if it corresponds to an equivalent skinny
    metadata item. However this slot could be beyond our last item in the
    leaf (i.e. path->slots[0] >= btrfs_header_nritems(leaf)), in which case
    we shouldn't process it.
    
    Since btrfs_lookup_extent() is only used to find extent items for data
    extents, fix this by removing completely the logic that looks up for an
    equivalent skinny metadata item, since it can not exist.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d557264ee974..fe69edda11fb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3276,7 +3276,7 @@ int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
 int btrfs_async_run_delayed_refs(struct btrfs_root *root,
 				 unsigned long count, int wait);
-int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_lookup_data_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 bytenr,
 			     u64 offset, int metadata, u64 *refs, u64 *flags);

commit 0d4cf4e6bf29033709ae8aba4645d873ed0167cc
Author: Chris Mason <clm@fb.com>
Date:   Tue Oct 7 13:24:20 2014 -0700

    Btrfs: fix compiles when CONFIG_BTRFS_FS_RUN_SANITY_TESTS is off
    
    Commit fccb84c94 moved added some helpers to cleanup our sanity tests,
    but it looks like both Dave and I always compile with the tests enabled.
    
    This fixes things to work when they are turned off too.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b94c1c76cd59..d557264ee974 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1818,9 +1818,8 @@ struct btrfs_root {
 
 	u64 highest_objectid;
 
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+	/* only used with CONFIG_BTRFS_FS_RUN_SANITY_TESTS is enabled */
 	u64 alloc_bytenr;
-#endif
 
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;

commit f667aef6af626d0cdce0204bc7a2888e62076525
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 23 13:40:08 2014 +0800

    btrfs: Make btrfs handle security mount options internally to avoid losing security label.
    
    [BUG]
    Originally when mount btrfs with "-o subvol=" mount option, btrfs will
    lose all security lable.
    And if the btrfs fs is mounted somewhere else, due to the lost of
    security lable, SELinux will refuse to mount since the same super block
    is being mounted using different security lable.
    
    [REPRODUCER]
    With SELinux enabled:
     #mkfs -t btrfs /dev/sda5
     #mount -o context=system_u:object_r:nfs_t:s0 /dev/sda5 /mnt/btrfs
     #btrfs subvolume create /mnt/btrfs/subvol
     #mount -o subvol=subvol,context=system_u:object_r:nfs_t:s0 /dev/sda5
      /mnt/test
    
    kernel message:
    SELinux: mount invalid.  Same superblock, different security settings
    for (dev sda5, type btrfs)
    
    [REASON]
    This happens because btrfs will call vfs_kern_mount() and then
    mount_subtree() to handle subvolume name lookup.
    First mount will cut off all the security lables and when it comes to
    the second vfs_kern_mount(), it has no security label now.
    
    [FIX]
    This patch will makes btrfs behavior much more like nfs,
    which has the type flag FS_BINARY_MOUNTDATA,
    making btrfs handles the security label internally.
    So security label will be set in the real mount time and won't lose
    label when use with "subvol=" mount option.
    
    Reported-by: Eryu Guan <guaneryu@gmail.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f7555e2767de..b94c1c76cd59 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -34,6 +34,7 @@
 #include <linux/pagemap.h>
 #include <linux/btrfs.h>
 #include <linux/workqueue.h>
+#include <linux/security.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
@@ -1725,6 +1726,9 @@ struct btrfs_fs_info {
 
 	spinlock_t unused_bgs_lock;
 	struct list_head unused_bgs;
+
+	/* For btrfs to record security options */
+	struct security_mnt_opts security_opts;
 };
 
 struct btrfs_subvolume_writers {
@@ -3591,6 +3595,7 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->uuid_root);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
+	security_free_mnt_opts(&fs_info->security_opts);
 	kfree(fs_info);
 }
 

commit 27b19cc8864e206c4203041892b0f706f044a0f1
Merge: bbf65cf0b5b6 4d75f8a9c87b
Author: Chris Mason <clm@fb.com>
Date:   Sat Oct 4 09:57:14 2014 -0700

    Merge branch 'cleanup/blocksize-diet-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus

commit bbf65cf0b5b67843ca094df01019222b85af2183
Merge: bf8e8ca6fd4a fccb84c94a97
Author: Chris Mason <clm@fb.com>
Date:   Sat Oct 4 09:56:45 2014 -0700

    Merge branch 'cleanup/misc-for-3.18' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus
    
    Signed-off-by: Chris Mason <clm@fb.com>
    
    Conflicts:
            fs/btrfs/extent_io.c

commit 15b636e1dd8f56ef1c580e086e46c8b32d8fe2b4
Author: Fabian Frederick <fabf@skynet.be>
Date:   Thu Sep 25 23:33:06 2014 +0200

    Btrfs: remove redundant btrfs_verify_qgroup_counts declaration.
    
    Do like disk-io function declared under CONFIG_BTRFS_FS_RUN_SANITY_TESTS
    and keep prototype in qgroup.h only
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 089f6da09411..67ef9d1a1d9b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4126,8 +4126,6 @@ static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
 /* Sanity test specific functions */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 void btrfs_test_destroy_inode(struct inode *inode);
-int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
-			       u64 rfer, u64 excl);
 #endif
 
 #endif

commit fccb84c94a9755f48668e43d0a44d6ecc750900f
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Sep 29 23:53:21 2014 +0200

    btrfs: move checks for DUMMY_ROOT into a helper
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bae025a20e63..557fd9520607 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4131,4 +4131,13 @@ int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
 			       u64 rfer, u64 excl);
 #endif
 
+static inline int btrfs_test_is_dummy_root(struct btrfs_root *root)
+{
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+	if (unlikely(test_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state)))
+		return 1;
+#endif
+	return 0;
+}
+
 #endif

commit 7ec20afbcb7b257aec82ea5d66e6b0b7499abaca
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jul 24 17:34:58 2014 +0200

    btrfs: new define for the inline extent data start
    
    Use a common definition for the inline data start so we don't have to
    open-code it and introduce bugs like "Btrfs: fix wrong max inline data
    size limit" fixed.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dd79ba7ee3ea..bae025a20e63 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -385,9 +385,11 @@ struct btrfs_header {
 				     sizeof(struct btrfs_key_ptr))
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->nodesize))
+#define BTRFS_FILE_EXTENT_INLINE_DATA_START		\
+		(offsetof(struct btrfs_file_extent_item, disk_bytenr))
 #define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
 					sizeof(struct btrfs_item) - \
-					offsetof(struct btrfs_file_extent_item, disk_bytenr))
+					BTRFS_FILE_EXTENT_INLINE_DATA_START)
 #define BTRFS_MAX_XATTR_SIZE(r)	(BTRFS_LEAF_DATA_SIZE(r) - \
 				 sizeof(struct btrfs_item) -\
 				 sizeof(struct btrfs_dir_item))
@@ -896,6 +898,8 @@ struct btrfs_file_extent_item {
 	/*
 	 * disk space consumed by the extent, checksum blocks are included
 	 * in these numbers
+	 *
+	 * At this offset in the structure, the inline extent data start.
 	 */
 	__le64 disk_bytenr;
 	__le64 disk_num_bytes;
@@ -3043,14 +3047,12 @@ BTRFS_SETGET_STACK_FUNCS(stack_file_extent_compression,
 static inline unsigned long
 btrfs_file_extent_inline_start(struct btrfs_file_extent_item *e)
 {
-	unsigned long offset = (unsigned long)e;
-	offset += offsetof(struct btrfs_file_extent_item, disk_bytenr);
-	return offset;
+	return (unsigned long)e + BTRFS_FILE_EXTENT_INLINE_DATA_START;
 }
 
 static inline u32 btrfs_file_extent_calc_inline_size(u32 datasize)
 {
-	return offsetof(struct btrfs_file_extent_item, disk_bytenr) + datasize;
+	return BTRFS_FILE_EXTENT_INLINE_DATA_START + datasize;
 }
 
 BTRFS_SETGET_FUNCS(file_extent_disk_bytenr, struct btrfs_file_extent_item,
@@ -3080,9 +3082,7 @@ BTRFS_SETGET_FUNCS(file_extent_other_encoding, struct btrfs_file_extent_item,
 static inline u32 btrfs_file_extent_inline_item_len(struct extent_buffer *eb,
 						    struct btrfs_item *e)
 {
-	unsigned long offset;
-	offset = offsetof(struct btrfs_file_extent_item, disk_bytenr);
-	return btrfs_item_size(eb, e) - offset;
+	return btrfs_item_size(eb, e) - BTRFS_FILE_EXTENT_INLINE_DATA_START;
 }
 
 /* this returns the number of file bytes represented by the inline item.

commit 95ac567af212db3293af3897ccb521efdf1dd7ff
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Thu Aug 8 22:45:48 2013 +0100

    Btrfs: set default max_inline to 8KiB instead of 8MiB
    
    8MiB is way too large and likely set by mistake. This is not
    a significant issue as in practice the max amount of data
    added to an inline extent is also limited by the page cache
    and btree leaf sizes.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 089f6da09411..dd79ba7ee3ea 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2089,6 +2089,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define	BTRFS_MOUNT_CHANGE_INODE_CACHE	(1 << 24)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
+#define BTRFS_DEFAULT_MAX_INLINE	(8192)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 4d75f8a9c87b843c8ded15b82b8d137b9724cccc
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 01:54:12 2014 +0200

    btrfs: remove blocksize from btrfs_alloc_free_block and rename
    
    Rename to btrfs_alloc_tree_block as it fits to the alloc/find/free +
    _tree_block family. The parameter blocksize was set to the metadata
    block size, directly or indirectly.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 089f6da09411..3073b8876bca 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3290,9 +3290,9 @@ struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 u64 bytenr);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int get_block_group_index(struct btrfs_block_group_cache *cache);
-struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
-					struct btrfs_root *root, u32 blocksize,
-					u64 parent, u64 root_objectid,
+struct extent_buffer *btrfs_alloc_tree_block(struct btrfs_trans_handle *trans,
+					struct btrfs_root *root, u64 parent,
+					u64 root_objectid,
 					struct btrfs_disk_key *key, int level,
 					u64 hint, u64 empty_size);
 void btrfs_free_tree_block(struct btrfs_trans_handle *trans,

commit 47ab2a6c689913db23ccae38349714edf8365e0a
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Sep 18 11:20:02 2014 -0400

    Btrfs: remove empty block groups automatically
    
    One problem that has plagued us is that a user will use up all of his space with
    data, remove a bunch of that data, and then try to create a bunch of small files
    and run out of space.  This happens because all the chunks were allocated for
    data since the metadata requirements were so low.  But now there's a bunch of
    empty data block groups and not enough metadata space to do anything.  This
    patch solves this problem by automatically deleting empty block groups.  If we
    notice the used count go down to 0 when deleting or on mount notice that a block
    group has a used count of 0 then we will queue it to be deleted.
    
    When the cleaner thread runs we will double check to make sure the block group
    is still empty and then we will delete it.  This patch has the side effect of no
    longer having a bunch of BUG_ON()'s in the chunk delete code, which will be
    helpful for both this and relocate.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 51ff3f8dbab9..089f6da09411 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1298,8 +1298,8 @@ struct btrfs_block_group_cache {
 	 */
 	struct list_head cluster_list;
 
-	/* For delayed block group creation */
-	struct list_head new_bg_list;
+	/* For delayed block group creation or deletion of empty block groups */
+	struct list_head bg_list;
 };
 
 /* delayed seq elem */
@@ -1568,6 +1568,7 @@ struct btrfs_fs_info {
 	int do_barriers;
 	int closing;
 	int log_root_recovering;
+	int open;
 
 	u64 total_pinned;
 
@@ -1717,6 +1718,9 @@ struct btrfs_fs_info {
 
 	/* Used to reclaim the metadata space in the background. */
 	struct work_struct async_reclaim_work;
+
+	spinlock_t unused_bgs_lock;
+	struct list_head unused_bgs;
 };
 
 struct btrfs_subvolume_writers {
@@ -3344,6 +3348,7 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 size);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
+void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);
 void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
 				       struct btrfs_root *root);
 u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);

commit 8b110e393c5a6e72d50fcdf9fa7ed8b647cfdfc9
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:44:03 2014 +0800

    Btrfs: implement repair function when direct read fails
    
    This patch implement data repair function when direct read fails.
    
    The detail of the implementation is:
    - When we find the data is not right, we try to read the data from the other
      mirror.
    - When the io on the mirror ends, we will insert the endio work into the
      dedicated btrfs workqueue, not common read endio workqueue, because the
      original endio work is still blocked in the btrfs endio workqueue, if we
      insert the endio work of the io on the mirror into that workqueue, deadlock
      would happen.
    - After we get right data, we write it back to the corrupted mirror.
    - And if the data on the new mirror is still corrupted, we will try next
      mirror until we read right data or all the mirrors are traversed.
    - After the above work, we set the uptodate flag according to the result.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0f3e4f7e454a..51ff3f8dbab9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1538,6 +1538,7 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue *endio_workers;
 	struct btrfs_workqueue *endio_meta_workers;
 	struct btrfs_workqueue *endio_raid56_workers;
+	struct btrfs_workqueue *endio_repair_workers;
 	struct btrfs_workqueue *rmw_workers;
 	struct btrfs_workqueue *endio_meta_write_workers;
 	struct btrfs_workqueue *endio_write_workers;

commit 23ea8e5a07673127d05cb5cf6f9914d7a53e0847
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:43:54 2014 +0800

    Btrfs: load checksum data once when submitting a direct read io
    
    The current code would load checksum data for several times when we split
    a whole direct read io because of the limit of the raid stripe, it would
    make us search the csum tree for several times. In fact, it just wasted time,
    and made the contention of the csum tree root be more serious. This patch
    improves this problem by loading the data at once.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6db3d4bac6fd..0f3e4f7e454a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3719,8 +3719,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio, u32 *dst);
 int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct btrfs_dio_private *dip, struct bio *bio,
-			      u64 logical_offset);
+			      struct bio *bio, u64 logical_offset);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,

commit f87c4318af8bd5daec361e436c69f9d71a43b261
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Aug 20 17:34:22 2014 +0200

    btrfs: remove stale define after removing ordered operations
    
    Last user removed in commit "btrfs: disable strict file flushes for
    renames and truncates" (8d875f95da43c6a8f18f77869f2ef26e9594fecc).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 840ecb78e727..6db3d4bac6fd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -62,13 +62,6 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_COMPAT_EXTENT_TREE_V0
 
-/*
- * files bigger than this get some pre-flushing when they are added
- * to the ordered operations list.  That way we limit the total
- * work done by the commit
- */
-#define BTRFS_ORDERED_OPERATIONS_FLUSH_LIMIT (8 * 1024 * 1024)
-
 /* holds pointers to all of the tree roots */
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
 

commit c01a5c074c0f6f85a3b02e39432b9e5576ab51de
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Thu Jul 17 11:44:12 2014 +0800

    Btrfs: fix wrong max inline data size limit
    
    inline data is stored from offset of @disk_bytenr in
    struct btrfs_file_extent_item. So substracting total
    size of struct btrfs_file_extent_item is wrong, fix it.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6fc16d22d27d..840ecb78e727 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -394,7 +394,7 @@ struct btrfs_header {
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->nodesize))
 #define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
 					sizeof(struct btrfs_item) - \
-					sizeof(struct btrfs_file_extent_item))
+					offsetof(struct btrfs_file_extent_item, disk_bytenr))
 #define BTRFS_MAX_XATTR_SIZE(r)	(BTRFS_LEAF_DATA_SIZE(r) - \
 				 sizeof(struct btrfs_item) -\
 				 sizeof(struct btrfs_dir_item))

commit 707e8a071528385a87b63a72a37c2322e463c7b8
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jun 4 19:22:26 2014 +0200

    btrfs: use nodesize everywhere, kill leafsize
    
    The nodesize and leafsize were never of different values. Unify the
    usage and make nodesize the one. Cleanup the redundant checks and
    helpers.
    
    Shaves a few bytes from .text:
    
      text    data     bss     dec     hex filename
    852418   24560   23112  900090   dbbfa btrfs.ko.before
    851074   24584   23112  898770   db6d2 btrfs.ko.after
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a835a548e47e..6fc16d22d27d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -391,7 +391,7 @@ struct btrfs_header {
 				      sizeof(struct btrfs_header)) / \
 				     sizeof(struct btrfs_key_ptr))
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
-#define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->leafsize))
+#define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->nodesize))
 #define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
 					sizeof(struct btrfs_item) - \
 					sizeof(struct btrfs_file_extent_item))
@@ -474,7 +474,7 @@ struct btrfs_super_block {
 	__le64 num_devices;
 	__le32 sectorsize;
 	__le32 nodesize;
-	__le32 leafsize;
+	__le32 __unused_leafsize;
 	__le32 stripesize;
 	__le32 sys_chunk_array_size;
 	__le64 chunk_root_generation;
@@ -1806,9 +1806,6 @@ struct btrfs_root {
 	/* node allocations are done in nodesize units */
 	u32 nodesize;
 
-	/* leaf allocations are done in leafsize units */
-	u32 leafsize;
-
 	u32 stripesize;
 
 	u32 type;
@@ -2995,8 +2992,6 @@ BTRFS_SETGET_STACK_FUNCS(super_sectorsize, struct btrfs_super_block,
 			 sectorsize, 32);
 BTRFS_SETGET_STACK_FUNCS(super_nodesize, struct btrfs_super_block,
 			 nodesize, 32);
-BTRFS_SETGET_STACK_FUNCS(super_leafsize, struct btrfs_super_block,
-			 leafsize, 32);
 BTRFS_SETGET_STACK_FUNCS(super_stripesize, struct btrfs_super_block,
 			 stripesize, 32);
 BTRFS_SETGET_STACK_FUNCS(super_root_dir, struct btrfs_super_block,
@@ -3232,13 +3227,6 @@ static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
 	return sb->s_fs_info;
 }
 
-static inline u32 btrfs_level_size(struct btrfs_root *root, int level)
-{
-	if (level == 0)
-		return root->leafsize;
-	return root->nodesize;
-}
-
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
@@ -3263,7 +3251,7 @@ static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)
 {
-	return (root->leafsize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
+	return (root->nodesize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
 		2 * num_items;
 }
 
@@ -3274,8 +3262,7 @@ static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)
 {
-	return (root->leafsize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
-		num_items;
+	return root->nodesize * BTRFS_MAX_LEVEL * num_items;
 }
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,

commit 57cdc8db21bf9cfa6b2e45310d56e74e263e8609
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 02:37:48 2014 +0100

    btrfs: cleanup ino cache members of btrfs_root
    
    The naming is confusing, generic yet used for a specific cache. Add a
    prefix 'ino_' or rename appropriately.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8e29b614fe93..a835a548e47e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1776,12 +1776,12 @@ struct btrfs_root {
 
 	/* free ino cache stuff */
 	struct btrfs_free_space_ctl *free_ino_ctl;
-	enum btrfs_caching_type cached;
-	spinlock_t cache_lock;
-	wait_queue_head_t cache_wait;
+	enum btrfs_caching_type ino_cache_state;
+	spinlock_t ino_cache_lock;
+	wait_queue_head_t ino_cache_wait;
 	struct btrfs_free_space_ctl *free_ino_pinned;
-	u64 cache_progress;
-	struct inode *cache_inode;
+	u64 ino_cache_progress;
+	struct inode *ino_cache_inode;
 
 	struct mutex log_mutex;
 	wait_queue_head_t log_writer_wait;

commit e339a6b097c515a31ce230d498c44ff2e89f1cf4
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Jul 2 10:54:25 2014 -0700

    Btrfs: __btrfs_mod_ref should always use no_quota
    
    Before I extended the no_quota arg to btrfs_dec/inc_ref because I didn't
    understand how snapshot delete was using it and assumed that we needed the
    quota operations there.  With Mark's work this has turned out to be not the
    case, we _always_ need to use no_quota for btrfs_dec/inc_ref, so just drop the
    argument and make __btrfs_mod_ref call it's process function with no_quota set
    always.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index be91397f4e92..8e29b614fe93 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3326,9 +3326,9 @@ int btrfs_reserve_extent(struct btrfs_root *root, u64 num_bytes,
 			 u64 min_alloc_size, u64 empty_size, u64 hint_byte,
 			 struct btrfs_key *ins, int is_data, int delalloc);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf, int full_backref, int no_quota);
+		  struct extent_buffer *buf, int full_backref);
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf, int full_backref, int no_quota);
+		  struct extent_buffer *buf, int full_backref);
 int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 bytenr, u64 num_bytes, u64 flags,

commit e570fd27f2c5d7eac3876bccf99e9838d7f911a3
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jun 19 10:42:50 2014 +0800

    Btrfs: fix broken free space cache after the system crashed
    
    When we mounted the filesystem after the crash, we got the following
    message:
      BTRFS error (device xxx): block group xxxx has wrong amount of free space
      BTRFS error (device xxx): failed to load free space cache for block group xxx
    
    It is because we didn't update the metadata of the allocated space (in extent
    tree) until the file data was written into the disk. During this time, there was
    no information about the allocated spaces in either the extent tree nor the
    free space cache. when we wrote out the free space cache at this time (commit
    transaction), those spaces were lost. In fact, only the free space that is
    used to store the file data had this problem, the others didn't because
    the metadata of them is updated in the same transaction context.
    
    There are many methods which can fix the above problem
    - track the allocated space, and write it out when we write out the free
      space cache
    - account the size of the allocated space that is used to store the file
      data, if the size is not zero, don't write out the free space cache.
    
    The first one is complex and may make the performance drop down.
    This patch chose the second method, we use a per-block-group variant to
    account the size of that allocated space. Besides that, we also introduce
    a per-block-group read-write semaphore to avoid the race between
    the allocation and the free space cache write out.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b7e2c1c1ef36..be91397f4e92 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1259,11 +1259,19 @@ struct btrfs_block_group_cache {
 	spinlock_t lock;
 	u64 pinned;
 	u64 reserved;
+	u64 delalloc_bytes;
 	u64 bytes_super;
 	u64 flags;
 	u64 sectorsize;
 	u64 cache_generation;
 
+	/*
+	 * It is just used for the delayed data space allocation because
+	 * only the data space allocation and the relative metadata update
+	 * can be done cross the transaction.
+	 */
+	struct rw_semaphore data_rwsem;
+
 	/* for raid56, this is a full stripe, without parity */
 	unsigned long full_stripe_len;
 
@@ -3316,7 +3324,7 @@ int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
 				   struct btrfs_key *ins);
 int btrfs_reserve_extent(struct btrfs_root *root, u64 num_bytes,
 			 u64 min_alloc_size, u64 empty_size, u64 hint_byte,
-			 struct btrfs_key *ins, int is_data);
+			 struct btrfs_key *ins, int is_data, int delalloc);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf, int full_backref, int no_quota);
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -3330,7 +3338,8 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,
 		      u64 owner, u64 offset, int no_quota);
 
-int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len,
+			       int delalloc);
 int btrfs_free_and_pin_reserved_extent(struct btrfs_root *root,
 				       u64 start, u64 len);
 void btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,

commit 7ffbb598a059b73487909619d73150f99b50337a
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Mon Jun 9 03:48:05 2014 +0100

    Btrfs: make fsync work after cloning into a file
    
    When cloning into a file, we were correctly replacing the extent
    items in the target range and removing the extent maps. However
    we weren't replacing the extent maps with new ones that point to
    the new extents - as a consequence, an incremental fsync (when the
    inode doesn't have the full sync flag) was a NOOP, since it relies
    on the existence of extent maps in the modified list of the inode's
    extent map tree, which was empty. Therefore add new extent maps to
    reflect the target clone range.
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index af523d695432..b7e2c1c1ef36 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3749,6 +3749,12 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig);
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit);
+void btrfs_extent_item_to_extent_map(struct inode *inode,
+				     const struct btrfs_path *path,
+				     struct btrfs_file_extent_item *fi,
+				     const bool new_inline,
+				     struct extent_map *em);
+
 /* inode.c */
 struct btrfs_delalloc_work {
 	struct inode *inode;

commit c1895442be01c58449e3bf9272f22062a670e08f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue May 27 12:59:57 2014 -0400

    btrfs: allocate raid type kobjects dynamically
    
    We are currently allocating space_info objects in an array when we
    allocate space_info. When a user does something like:
    
    # btrfs balance start -mconvert=raid1 -dconvert=raid1 /mnt
    # btrfs balance start -mconvert=single -dconvert=single /mnt -f
    # btrfs balance start -mconvert=raid1 -dconvert=raid1 /
    
    We can end up with memory corruption since the kobject hasn't
    been reinitialized properly and the name pointer was left set.
    
    The rationale behind allocating them statically was to avoid
    creating a separate kobject container that just contained the
    raid type. It used the index in the array to determine the index.
    
    Ultimately, though, this wastes more memory than it saves in all
    but the most complex scenarios and introduces kobject lifetime
    questions.
    
    This patch allocates the kobjects dynamically instead. Note that
    we also remove the kobject_get/put of the parent kobject since
    kobject_add and kobject_del do that internally.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reported-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 02895a126ab9..af523d695432 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1123,6 +1123,12 @@ struct btrfs_qgroup_limit_item {
 	__le64 rsv_excl;
 } __attribute__ ((__packed__));
 
+/* For raid type sysfs entries */
+struct raid_kobject {
+	int raid_type;
+	struct kobject kobj;
+};
+
 struct btrfs_space_info {
 	spinlock_t lock;
 
@@ -1173,7 +1179,7 @@ struct btrfs_space_info {
 	wait_queue_head_t wait;
 
 	struct kobject kobj;
-	struct kobject block_group_kobjs[BTRFS_NR_RAID_TYPES];
+	struct kobject *block_group_kobjs[BTRFS_NR_RAID_TYPES];
 };
 
 #define	BTRFS_BLOCK_RSV_GLOBAL		1

commit a79b7d4b3e8118f265dcb4bdf9a572c392f02708
Author: Chris Mason <clm@fb.com>
Date:   Thu May 22 16:18:52 2014 -0700

    Btrfs: async delayed refs
    
    Delayed extent operations are triggered during transaction commits.
    The goal is to queue up a healthly batch of changes to the extent
    allocation tree and run through them in bulk.
    
    This farms them off to async helper threads.  The goal is to have the
    bulk of the delayed operations being done in the background, but this is
    also important to limit our stack footprint.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4896d7a947eb..02895a126ab9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1546,6 +1546,9 @@ struct btrfs_fs_info {
 	 */
 	struct btrfs_workqueue *fixup_workers;
 	struct btrfs_workqueue *delayed_workers;
+
+	/* the extent workers do delayed refs on the extent allocation tree */
+	struct btrfs_workqueue *extent_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
@@ -3268,6 +3271,8 @@ int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans,
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
+int btrfs_async_run_delayed_refs(struct btrfs_root *root,
+				 unsigned long count, int wait);
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 bytenr,

commit faa2dbf004e89e8f7ccd28fbe6f07c308417b8ae
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed May 7 17:06:09 2014 -0400

    Btrfs: add sanity tests for new qgroup accounting code
    
    This exercises the various parts of the new qgroup accounting code.  We do some
    basic stuff and do some things with the shared refs to make sure all that code
    works.  I had to add a bunch of infrastructure because I needed to be able to
    insert items into a fake tree without having to do all the hard work myself,
    hopefully this will be usefull in the future.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 06cc384933cc..4896d7a947eb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1798,6 +1798,10 @@ struct btrfs_root {
 
 	u64 highest_objectid;
 
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+	u64 alloc_bytenr;
+#endif
+
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
@@ -4111,6 +4115,8 @@ static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
 /* Sanity test specific functions */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 void btrfs_test_destroy_inode(struct inode *inode);
+int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
+			       u64 rfer, u64 excl);
 #endif
 
 #endif

commit fcebe4562dec83b3f8d3088d77584727b09130b2
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue May 13 17:30:47 2014 -0700

    Btrfs: rework qgroup accounting
    
    Currently qgroups account for space by intercepting delayed ref updates to fs
    trees.  It does this by adding sequence numbers to delayed ref updates so that
    it can figure out how the tree looked before the update so we can adjust the
    counters properly.  The problem with this is that it does not allow delayed refs
    to be merged, so if you say are defragging an extent with 5k snapshots pointing
    to it we will thrash the delayed ref lock because we need to go back and
    manually merge these things together.  Instead we want to process quota changes
    when we know they are going to happen, like when we first allocate an extent, we
    free a reference for an extent, we add new references etc.  This patch
    accomplishes this by only adding qgroup operations for real ref changes.  We
    only modify the sequence number when we need to lookup roots for bytenrs, this
    reduces the amount of churn on the sequence number and allows us to merge
    delayed refs as we add them most of the time.  This patch encompasses a bunch of
    architectural changes
    
    1) qgroup ref operations: instead of tracking qgroup operations through the
    delayed refs we simply add new ref operations whenever we notice that we need to
    when we've modified the refs themselves.
    
    2) tree mod seq:  we no longer have this separation of major/minor counters.
    this makes the sequence number stuff much more sane and we can remove some
    locking that was needed to protect the counter.
    
    3) delayed ref seq: we now read the tree mod seq number and use that as our
    sequence.  This means each new delayed ref doesn't have it's own unique sequence
    number, rather whenever we go to lookup backrefs we inc the sequence number so
    we can make sure to keep any new operations from screwing up our world view at
    that given point.  This allows us to merge delayed refs during runtime.
    
    With all of these changes the delayed ref stuff is a little saner and the qgroup
    accounting stuff no longer goes negative in some cases like it was before.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index efd3bf61696d..06cc384933cc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1648,7 +1648,10 @@ struct btrfs_fs_info {
 
 	/* holds configuration and tracking. Protected by qgroup_lock */
 	struct rb_root qgroup_tree;
+	struct rb_root qgroup_op_tree;
 	spinlock_t qgroup_lock;
+	spinlock_t qgroup_op_lock;
+	atomic_t qgroup_op_seq;
 
 	/*
 	 * used to avoid frequently calling ulist_alloc()/ulist_free()
@@ -3300,9 +3303,9 @@ int btrfs_reserve_extent(struct btrfs_root *root, u64 num_bytes,
 			 u64 min_alloc_size, u64 empty_size, u64 hint_byte,
 			 struct btrfs_key *ins, int is_data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf, int full_backref, int for_cow);
+		  struct extent_buffer *buf, int full_backref, int no_quota);
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf, int full_backref, int for_cow);
+		  struct extent_buffer *buf, int full_backref, int no_quota);
 int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 bytenr, u64 num_bytes, u64 flags,
@@ -3310,7 +3313,7 @@ int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,
-		      u64 owner, u64 offset, int for_cow);
+		      u64 owner, u64 offset, int no_quota);
 
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_free_and_pin_reserved_extent(struct btrfs_root *root,
@@ -3322,7 +3325,7 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,
-			 u64 root_objectid, u64 owner, u64 offset, int for_cow);
+			 u64 root_objectid, u64 owner, u64 offset, int no_quota);
 
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
@@ -3410,7 +3413,6 @@ int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
 int __get_raid_index(u64 flags);
-
 int btrfs_start_nocow_write(struct btrfs_root *root);
 void btrfs_end_nocow_write(struct btrfs_root *root);
 /* ctree.c */
@@ -3586,7 +3588,6 @@ u64 btrfs_get_tree_mod_seq(struct btrfs_fs_info *fs_info,
 			   struct seq_list *elem);
 void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
 			    struct seq_list *elem);
-u64 btrfs_tree_mod_seq_prev(u64 seq);
 int btrfs_old_root_level(struct btrfs_root *root, u64 time_seq);
 
 /* root-item.c */
@@ -4094,52 +4095,6 @@ void btrfs_reada_detach(void *handle);
 int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 			 u64 start, int err);
 
-/* qgroup.c */
-struct qgroup_update {
-	struct list_head list;
-	struct btrfs_delayed_ref_node *node;
-	struct btrfs_delayed_extent_op *extent_op;
-};
-
-int btrfs_quota_enable(struct btrfs_trans_handle *trans,
-		       struct btrfs_fs_info *fs_info);
-int btrfs_quota_disable(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info);
-int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
-void btrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info);
-int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info);
-int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
-			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
-int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,
-			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
-int btrfs_create_qgroup(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info, u64 qgroupid,
-			char *name);
-int btrfs_remove_qgroup(struct btrfs_trans_handle *trans,
-			      struct btrfs_fs_info *fs_info, u64 qgroupid);
-int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,
-		       struct btrfs_fs_info *fs_info, u64 qgroupid,
-		       struct btrfs_qgroup_limit *limit);
-int btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info);
-void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);
-struct btrfs_delayed_extent_op;
-int btrfs_qgroup_record_ref(struct btrfs_trans_handle *trans,
-			    struct btrfs_delayed_ref_node *node,
-			    struct btrfs_delayed_extent_op *extent_op);
-int btrfs_qgroup_account_ref(struct btrfs_trans_handle *trans,
-			     struct btrfs_fs_info *fs_info,
-			     struct btrfs_delayed_ref_node *node,
-			     struct btrfs_delayed_extent_op *extent_op);
-int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
-		      struct btrfs_fs_info *fs_info);
-int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
-			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
-			 struct btrfs_qgroup_inherit *inherit);
-int btrfs_qgroup_reserve(struct btrfs_root *root, u64 num_bytes);
-void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes);
-
-void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
-
 static inline int is_fstree(u64 rootid)
 {
 	if (rootid == BTRFS_FS_TREE_OBJECTID ||

commit 27cdeb7096b86f05ad018a24cdb63acdf0850a5d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Apr 2 19:51:05 2014 +0800

    Btrfs: use bitfield instead of integer data type for the some variants in btrfs_root
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0a805b8d61cc..efd3bf61696d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1710,6 +1710,26 @@ struct btrfs_subvolume_writers {
 	wait_queue_head_t	wait;
 };
 
+/*
+ * The state of btrfs root
+ */
+/*
+ * btrfs_record_root_in_trans is a multi-step process,
+ * and it can race with the balancing code.   But the
+ * race is very small, and only the first time the root
+ * is added to each transaction.  So IN_TRANS_SETUP
+ * is used to tell us when more checks are required
+ */
+#define BTRFS_ROOT_IN_TRANS_SETUP	0
+#define BTRFS_ROOT_REF_COWS		1
+#define BTRFS_ROOT_TRACK_DIRTY		2
+#define BTRFS_ROOT_IN_RADIX		3
+#define BTRFS_ROOT_DUMMY_ROOT		4
+#define BTRFS_ROOT_ORPHAN_ITEM_INSERTED	5
+#define BTRFS_ROOT_DEFRAG_RUNNING	6
+#define BTRFS_ROOT_FORCE_COW		7
+#define BTRFS_ROOT_MULTI_LOG_TASKS	8
+
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.
@@ -1721,6 +1741,7 @@ struct btrfs_root {
 	struct btrfs_root *log_root;
 	struct btrfs_root *reloc_root;
 
+	unsigned long state;
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
@@ -1755,7 +1776,6 @@ struct btrfs_root {
 	/* Just be updated when the commit succeeds. */
 	int last_log_commit;
 	pid_t log_start_pid;
-	bool log_multiple_pids;
 
 	u64 objectid;
 	u64 last_trans;
@@ -1775,23 +1795,9 @@ struct btrfs_root {
 
 	u64 highest_objectid;
 
-	/* btrfs_record_root_in_trans is a multi-step process,
-	 * and it can race with the balancing code.   But the
-	 * race is very small, and only the first time the root
-	 * is added to each transaction.  So in_trans_setup
-	 * is used to tell us when more checks are required
-	 */
-	unsigned long in_trans_setup;
-	int ref_cows;
-	int track_dirty;
-	int in_radix;
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-	int dummy_root;
-#endif
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
-	int defrag_running;
 	char *name;
 
 	/* the dirty list is only used by non-reference counted roots */
@@ -1805,7 +1811,6 @@ struct btrfs_root {
 	spinlock_t orphan_lock;
 	atomic_t orphan_inodes;
 	struct btrfs_block_rsv *orphan_block_rsv;
-	int orphan_item_inserted;
 	int orphan_cleanup_state;
 
 	spinlock_t inode_lock;
@@ -1823,8 +1828,6 @@ struct btrfs_root {
 	 */
 	dev_t anon_dev;
 
-	int force_cow;
-
 	spinlock_t root_item_lock;
 	atomic_t refs;
 

commit 21c7e75654b77b53a4436bf28496aac11536b6ba
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue May 13 17:29:04 2014 -0700

    Btrfs: reclaim the reserved metadata space at background
    
    Before applying this patch, the task had to reclaim the metadata space
    by itself if the metadata space was not enough. And When the task started
    the space reclamation, all the other tasks which wanted to reserve the
    metadata space were blocked. At some cases, they would be blocked for
    a long time, it made the performance fluctuate wildly.
    
    So we introduce the background metadata space reclamation, when the space
    is about to be exhausted, we insert a reclaim work into the workqueue, the
    worker of the workqueue helps us to reclaim the reserved space at the
    background. By this way, the tasks needn't reclaim the space by themselves at
    most cases, and even if the tasks have to reclaim the space or are blocked
    for the space reclamation, they will get enough space more quickly.
    
    Here is my test result(Tested by compilebench):
     Memory:        2GB
     CPU:           2Cores * 1CPU
     Partition:     40GB(SSD)
    
    Test command:
     # compilebench -D <mnt> -m
    
    Without this patch:
     intial create total runs 30 avg 54.36 MB/s (user 0.52s sys 2.44s)
     compile total runs 30 avg 123.72 MB/s (user 0.13s sys 1.17s)
     read compiled tree total runs 3 avg 81.15 MB/s (user 0.74s sys 4.89s)
     delete compiled tree total runs 30 avg 5.32 seconds (user 0.35s sys 4.37s)
    
    With this patch:
     intial create total runs 30 avg 59.80 MB/s (user 0.52s sys 2.53s)
     compile total runs 30 avg 151.44 MB/s (user 0.13s sys 1.11s)
     read compiled tree total runs 3 avg 83.25 MB/s (user 0.76s sys 4.91s)
     delete compiled tree total runs 30 avg 5.29 seconds (user 0.34s sys 4.34s)
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f4a439e1a43f..0a805b8d61cc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -33,6 +33,7 @@
 #include <asm/kmap_types.h>
 #include <linux/pagemap.h>
 #include <linux/btrfs.h>
+#include <linux/workqueue.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
@@ -1322,6 +1323,8 @@ struct btrfs_stripe_hash_table {
 
 #define BTRFS_STRIPE_HASH_TABLE_BITS 11
 
+void btrfs_init_async_reclaim_work(struct work_struct *work);
+
 /* fs_info */
 struct reloc_control;
 struct btrfs_device;
@@ -1697,6 +1700,9 @@ struct btrfs_fs_info {
 
 	struct semaphore uuid_tree_rescan_sem;
 	unsigned int update_uuid_tree_gen:1;
+
+	/* Used to reclaim the metadata space in the background. */
+	struct work_struct async_reclaim_work;
 };
 
 struct btrfs_subvolume_writers {

commit 521e0546c970c3d845076f243828fa7abd71edfc
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 15 16:41:44 2014 +0200

    btrfs: protect snapshots from deleting during send
    
    The patch "Btrfs: fix protection between send and root deletion"
    (18f687d538449373c37c) does not actually prevent to delete the snapshot
    and just takes care during background cleaning, but this seems rather
    user unfriendly, this patch implements the idea presented in
    
    http://www.spinics.net/lists/linux-btrfs/msg30813.html
    
    - add an internal root_item flag to denote a dead root
    - check if the send_in_progress is set and refuse to delete, otherwise
      set the flag and proceed
    - check the flag in send similar to the btrfs_root_readonly checks, for
      all involved roots
    
    The root lookup in send via btrfs_read_fs_root_no_name will check if the
    root is really dead or not. If it is, ENOENT, aborted send. If it's
    alive, it's protected by send_in_progress, send can continue.
    
    CC: Miao Xie <miaox@cn.fujitsu.com>
    CC: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e6f899dc5e47..f4a439e1a43f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -756,6 +756,12 @@ struct btrfs_dir_item {
 
 #define BTRFS_ROOT_SUBVOL_RDONLY	(1ULL << 0)
 
+/*
+ * Internal in-memory flag that a subvolume has been marked for deletion but
+ * still visible as a directory
+ */
+#define BTRFS_ROOT_SUBVOL_DEAD		(1ULL << 48)
+
 struct btrfs_root_item {
 	struct btrfs_inode_item inode;
 	__le64 generation;
@@ -2791,6 +2797,11 @@ static inline bool btrfs_root_readonly(struct btrfs_root *root)
 	return (root->root_item.flags & cpu_to_le64(BTRFS_ROOT_SUBVOL_RDONLY)) != 0;
 }
 
+static inline bool btrfs_root_dead(struct btrfs_root *root)
+{
+	return (root->root_item.flags & cpu_to_le64(BTRFS_ROOT_SUBVOL_DEAD)) != 0;
+}
+
 /* struct btrfs_root_backup */
 BTRFS_SETGET_STACK_FUNCS(backup_tree_root, struct btrfs_root_backup,
 		   tree_root, 64);

commit 7d824b6f9cf28917d8a05891ef423fb0e4e34c69
Author: David Sterba <dsterba@suse.cz>
Date:   Wed May 7 17:37:51 2014 +0200

    btrfs: balance filter: add limit of processed chunks
    
    This started as debugging helper, to watch the effects of converting
    between raid levels on multiple devices, but could be useful standalone.
    
    In my case the usage filter was not finegrained enough and led to
    converting too many chunks at once. Another example use is in connection
    with drange+devid or vrange filters that allow to work with a specific
    chunk or even with a chunk on a given device.
    
    The limit filter applies last, the value of 0 means no limiting.
    
    CC: Ilya Dryomov <idryomov@gmail.com>
    CC: Hugo Mills <hugo@carfax.org.uk>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ba6b88528dc7..e6f899dc5e47 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -840,7 +840,10 @@ struct btrfs_disk_balance_args {
 	/* BTRFS_BALANCE_ARGS_* */
 	__le64 flags;
 
-	__le64 unused[8];
+	/* BTRFS_BALANCE_ARGS_LIMIT value */
+	__le64 limit;
+
+	__le64 unused[7];
 } __attribute__ ((__packed__));
 
 /*
@@ -2897,6 +2900,7 @@ btrfs_disk_balance_args_to_cpu(struct btrfs_balance_args *cpu,
 	cpu->vend = le64_to_cpu(disk->vend);
 	cpu->target = le64_to_cpu(disk->target);
 	cpu->flags = le64_to_cpu(disk->flags);
+	cpu->limit = le64_to_cpu(disk->limit);
 }
 
 static inline void
@@ -2914,6 +2918,7 @@ btrfs_cpu_balance_args_to_disk(struct btrfs_disk_balance_args *disk,
 	disk->vend = cpu_to_le64(cpu->vend);
 	disk->target = cpu_to_le64(cpu->target);
 	disk->flags = cpu_to_le64(cpu->flags);
+	disk->limit = cpu_to_le64(cpu->limit);
 }
 
 /* struct btrfs_super_block */

commit 33c0022f0e687b0161a9bb84a5671df932551e3a
Merge: 2b9d1c050d29 cfd4a535b68f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Apr 27 13:26:28 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: limit the path size in send to PATH_MAX
      Btrfs: correctly set profile flags on seqlock retry
      Btrfs: use correct key when repeating search for extent item
      Btrfs: fix inode caching vs tree log
      Btrfs: fix possible memory leaks in open_ctree()
      Btrfs: avoid triggering bug_on() when we fail to start inode caching task
      Btrfs: move btrfs_{set,clear}_and_info() to ctree.h
      btrfs: replace error code from btrfs_drop_extents
      btrfs: Change the hole range to a more accurate value.
      btrfs: fix use-after-free in mount_subvol()

commit 9d89ce658718d9d21465666127a15ca2c82c4ea7
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Wed Apr 23 19:33:33 2014 +0800

    Btrfs: move btrfs_{set,clear}_and_info() to ctree.h
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ad1a5943a923..e7c9e1c540f4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2058,6 +2058,20 @@ struct btrfs_ioctl_defrag_range_args {
 #define btrfs_raw_test_opt(o, opt)	((o) & BTRFS_MOUNT_##opt)
 #define btrfs_test_opt(root, opt)	((root)->fs_info->mount_opt & \
 					 BTRFS_MOUNT_##opt)
+#define btrfs_set_and_info(root, opt, fmt, args...)			\
+{									\
+	if (!btrfs_test_opt(root, opt))					\
+		btrfs_info(root->fs_info, fmt, ##args);			\
+	btrfs_set_opt(root->fs_info->mount_opt, opt);			\
+}
+
+#define btrfs_clear_and_info(root, opt, fmt, args...)			\
+{									\
+	if (btrfs_test_opt(root, opt))					\
+		btrfs_info(root->fs_info, fmt, ##args);			\
+	btrfs_clear_opt(root->fs_info->mount_opt, opt);			\
+}
+
 /*
  * Inode flags
  */

commit 3123bca71993c2346a458875488863772c1d5dc4
Merge: 582076ab1677 e4fbaee29272
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 11 14:16:53 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull second set of btrfs updates from Chris Mason:
     "The most important changes here are from Josef, fixing a btrfs
      regression in 3.14 that can cause corruptions in the extent allocation
      tree when snapshots are in use.
    
      Josef also fixed some deadlocks in send/recv and other assorted races
      when balance is running"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (23 commits)
      Btrfs: fix compile warnings on on avr32 platform
      btrfs: allow mounting btrfs subvolumes with different ro/rw options
      btrfs: export global block reserve size as space_info
      btrfs: fix crash in remount(thread_pool=) case
      Btrfs: abort the transaction when we don't find our extent ref
      Btrfs: fix EINVAL checks in btrfs_clone
      Btrfs: fix unlock in __start_delalloc_inodes()
      Btrfs: scrub raid56 stripes in the right way
      Btrfs: don't compress for a small write
      Btrfs: more efficient io tree navigation on wait_extent_bit
      Btrfs: send, build path string only once in send_hole
      btrfs: filter invalid arg for btrfs resize
      Btrfs: send, fix data corruption due to incorrect hole detection
      Btrfs: kmalloc() doesn't return an ERR_PTR
      Btrfs: fix snapshot vs nocow writting
      btrfs: Change the expanding write sequence to fix snapshot related bug.
      btrfs: make device scan less noisy
      btrfs: fix lockdep warning with reclaim lock inversion
      Btrfs: hold the commit_root_sem when getting the commit root during send
      Btrfs: remove transaction from send
      ...

commit 36523e95129c0e69bf1592cd009261b1c6d96e77
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Feb 7 14:34:12 2014 +0100

    btrfs: export global block reserve size as space_info
    
    Introduce a block group type bit for a global reserve and fill the space
    info for SPACE_INFO ioctl. This should replace the newly added ioctl
    (01e219e8069516cdb98594d417b8bb8d906ed30d) to get just the 'size' part
    of the global reserve, while the actual usage can be now visible in the
    'btrfs fi df' output during ENOSPC stress.
    
    The unpatched userspace tools will show the blockgroup as 'unknown'.
    
    CC: Jeff Mahoney <jeffm@suse.com>
    CC: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d8a669ed5506..ad1a5943a923 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -987,7 +987,8 @@ struct btrfs_dev_replace_item {
 #define BTRFS_BLOCK_GROUP_RAID10	(1ULL << 6)
 #define BTRFS_BLOCK_GROUP_RAID5         (1ULL << 7)
 #define BTRFS_BLOCK_GROUP_RAID6         (1ULL << 8)
-#define BTRFS_BLOCK_GROUP_RESERVED	BTRFS_AVAIL_ALLOC_BIT_SINGLE
+#define BTRFS_BLOCK_GROUP_RESERVED	(BTRFS_AVAIL_ALLOC_BIT_SINGLE | \
+					 BTRFS_SPACE_INFO_GLOBAL_RSV)
 
 enum btrfs_raid_types {
 	BTRFS_RAID_RAID10,
@@ -1019,6 +1020,12 @@ enum btrfs_raid_types {
  */
 #define BTRFS_AVAIL_ALLOC_BIT_SINGLE	(1ULL << 48)
 
+/*
+ * A fake block group type that is used to communicate global block reserve
+ * size to userspace via the SPACE_INFO ioctl.
+ */
+#define BTRFS_SPACE_INFO_GLOBAL_RSV	(1ULL << 49)
+
 #define BTRFS_EXTENDED_PROFILE_MASK	(BTRFS_BLOCK_GROUP_PROFILE_MASK | \
 					 BTRFS_AVAIL_ALLOC_BIT_SINGLE)
 

commit 3f8a18cc53bd1be26eb5b5247e1386ad0e21b623
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 28 17:16:01 2014 -0400

    Btrfs: hold the commit_root_sem when getting the commit root during send
    
    We currently rely too heavily on roots being read-only to save us from just
    accessing root->commit_root.  We can easily balance blocks out from underneath a
    read only root, so to save us from getting screwed make sure we only access
    root->commit_root under the commit root sem.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4253ab257c9c..d8a669ed5506 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -609,6 +609,7 @@ struct btrfs_path {
 	unsigned int skip_locking:1;
 	unsigned int leave_spinning:1;
 	unsigned int search_commit_root:1;
+	unsigned int need_commit_sem:1;
 };
 
 /*

commit 9e351cc862b098d8ec8f8022d110932490794925
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Mar 13 15:42:13 2014 -0400

    Btrfs: remove transaction from send
    
    Lets try this again.  We can deadlock the box if we send on a box and try to
    write onto the same fs with the app that is trying to listen to the send pipe.
    This is because the writer could get stuck waiting for a transaction commit
    which is being blocked by the send.  So fix this by making sure looking at the
    commit roots is always going to be consistent.  We do this by keeping track of
    which roots need to have their commit roots swapped during commit, and then
    taking the commit_root_sem and swapping them all at once.  Then make sure we
    take a read lock on the commit_root_sem in cases where we search the commit root
    to make sure we're always looking at a consistent view of the commit roots.
    Previously we had problems with this because we would swap a fs tree commit root
    and then swap the extent tree commit root independently which would cause the
    backref walking code to screw up sometimes.  With this patch we no longer
    deadlock and pass all the weird send/receive corner cases.  Thanks,
    
    Reportedy-by: Hugo Mills <hugo@carfax.org.uk>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2a9d32e193a5..4253ab257c9c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1440,7 +1440,7 @@ struct btrfs_fs_info {
 	 */
 	struct mutex ordered_extent_flush_mutex;
 
-	struct rw_semaphore extent_commit_sem;
+	struct rw_semaphore commit_root_sem;
 
 	struct rw_semaphore cleanup_work_sem;
 
@@ -1711,7 +1711,6 @@ struct btrfs_root {
 	struct btrfs_block_rsv *block_rsv;
 
 	/* free ino cache stuff */
-	struct mutex fs_commit_mutex;
 	struct btrfs_free_space_ctl *free_ino_ctl;
 	enum btrfs_caching_type cached;
 	spinlock_t cache_lock;

commit 53c566625fb872e7826a237f0f5c21458028e94a
Merge: 34917f971390 00fdf13a2e9f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 4 15:31:36 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs changes from Chris Mason:
     "This is a pretty long stream of bug fixes and performance fixes.
    
      Qu Wenruo has replaced the btrfs async threads with regular kernel
      workqueues.  We'll keep an eye out for performance differences, but
      it's nice to be using more generic code for this.
    
      We still have some corruption fixes and other patches coming in for
      the merge window, but this batch is tested and ready to go"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (108 commits)
      Btrfs: fix a crash of clone with inline extents's split
      btrfs: fix uninit variable warning
      Btrfs: take into account total references when doing backref lookup
      Btrfs: part 2, fix incremental send's decision to delay a dir move/rename
      Btrfs: fix incremental send's decision to delay a dir move/rename
      Btrfs: remove unnecessary inode generation lookup in send
      Btrfs: fix race when updating existing ref head
      btrfs: Add trace for btrfs_workqueue alloc/destroy
      Btrfs: less fs tree lock contention when using autodefrag
      Btrfs: return EPERM when deleting a default subvolume
      Btrfs: add missing kfree in btrfs_destroy_workqueue
      Btrfs: cache extent states in defrag code path
      Btrfs: fix deadlock with nested trans handles
      Btrfs: fix possible empty list access when flushing the delalloc inodes
      Btrfs: split the global ordered extents mutex
      Btrfs: don't flush all delalloc inodes when we doesn't get s_umount lock
      Btrfs: reclaim delalloc metadata more aggressively
      Btrfs: remove unnecessary lock in may_commit_transaction()
      Btrfs: remove the unnecessary flush when preparing the pages
      Btrfs: just do dirty page flush for the inode with compression before direct IO
      ...

commit 573bfb72f7608eb7097d2dd036a714a6ab20cffe
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 6 13:55:03 2014 +0800

    Btrfs: fix possible empty list access when flushing the delalloc inodes
    
    We didn't have a lock to protect the access to the delalloc inodes list, that is
    we might access a empty delalloc inodes list if someone start flushing delalloc
    inodes because the delalloc inodes were moved into a other list temporarily.
    Fix it by wrapping the access with a lock.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5f4921554f0a..2a9d32e193a5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1490,6 +1490,7 @@ struct btrfs_fs_info {
 	 */
 	struct list_head ordered_roots;
 
+	struct mutex delalloc_root_mutex;
 	spinlock_t delalloc_root_lock;
 	/* all fs/file tree roots that have delalloc inodes. */
 	struct list_head delalloc_roots;
@@ -1805,6 +1806,7 @@ struct btrfs_root {
 	spinlock_t root_item_lock;
 	atomic_t refs;
 
+	struct mutex delalloc_mutex;
 	spinlock_t delalloc_lock;
 	/*
 	 * all of the inodes that have delalloc bytes.  It is possible for

commit 31f3d255c677073f83daa1e0671bbf2157bf8edc
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 6 13:55:02 2014 +0800

    Btrfs: split the global ordered extents mutex
    
    When we create a snapshot, we just need wait the ordered extents in
    the source fs/file root, but because we use the global mutex to protect
    this ordered extents list of the source fs/file root to avoid accessing
    a empty list, if someone got the mutex to access the ordered extents list
    of the other fs/file root, we had to wait.
    
    This patch splits the above global mutex, now every fs/file root has
    its own mutex to protect its own list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5a800986f416..5f4921554f0a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1814,6 +1814,8 @@ struct btrfs_root {
 	struct list_head delalloc_inodes;
 	struct list_head delalloc_root;
 	u64 nr_delalloc_inodes;
+
+	struct mutex ordered_extent_mutex;
 	/*
 	 * this is used by the balancing code to wait for all the pending
 	 * ordered extents

commit 6c255e67cec1c38a0569c7f823eba63f9449ccf8
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 6 13:55:01 2014 +0800

    Btrfs: don't flush all delalloc inodes when we doesn't get s_umount lock
    
    We needn't flush all delalloc inodes when we doesn't get s_umount lock,
    or we would make the tasks wait for a long time.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 374bb2f8ccd9..5a800986f416 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3740,7 +3740,8 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
-int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int delay_iput);
+int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int delay_iput,
+			       int nr);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,

commit 8257b2dc3c1a1057b84a589827354abdc4c767fd
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 6 13:38:19 2014 +0800

    Btrfs: introduce btrfs_{start, end}_nocow_write() for each subvolume
    
    If the snapshot creation happened after the nocow write but before the dirty
    data flush, we would fail to flush the dirty data because of no space.
    
    So we must keep track of when those nocow write operations start and when they
    end, if there are nocow writers, the snapshot creators must wait. In order
    to implement this function, I introduce btrfs_{start, end}_nocow_write(),
    which is similar to mnt_{want,drop}_write().
    
    These two functions are only used for nocow file write operations.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b4d2e957b89f..374bb2f8ccd9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1681,6 +1681,11 @@ struct btrfs_fs_info {
 	unsigned int update_uuid_tree_gen:1;
 };
 
+struct btrfs_subvolume_writers {
+	struct percpu_counter	counter;
+	wait_queue_head_t	wait;
+};
+
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.
@@ -1829,6 +1834,8 @@ struct btrfs_root {
 	 * manipulation with the read-only status via SUBVOL_SETFLAGS
 	 */
 	int send_in_progress;
+	struct btrfs_subvolume_writers *subv_writers;
+	atomic_t will_be_snapshoted;
 };
 
 struct btrfs_ioctl_defrag_range_args {
@@ -3353,6 +3360,9 @@ int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
 int __get_raid_index(u64 flags);
+
+int btrfs_start_nocow_write(struct btrfs_root *root);
+void btrfs_end_nocow_write(struct btrfs_root *root);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit d458b0540ebd728b4d6ef47cc5ef0dbfd4dd361a
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:19 2014 +0800

    btrfs: Cleanup the "_struct" suffix in btrfs_workequeue
    
    Since the "_struct" suffix is mainly used for distinguish the differnt
    btrfs_work between the original and the newly created one,
    there is no need using the suffix since all btrfs_workers are changed
    into btrfs_workqueue.
    
    Also this patch fixed some codes whose code style is changed due to the
    too long "_struct" suffix.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5a8c77a441ba..b4d2e957b89f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1221,7 +1221,7 @@ struct btrfs_caching_control {
 	struct list_head list;
 	struct mutex mutex;
 	wait_queue_head_t wait;
-	struct btrfs_work_struct work;
+	struct btrfs_work work;
 	struct btrfs_block_group_cache *block_group;
 	u64 progress;
 	atomic_t count;
@@ -1504,27 +1504,27 @@ struct btrfs_fs_info {
 	 * A third pool does submit_bio to avoid deadlocking with the other
 	 * two
 	 */
-	struct btrfs_workqueue_struct *workers;
-	struct btrfs_workqueue_struct *delalloc_workers;
-	struct btrfs_workqueue_struct *flush_workers;
-	struct btrfs_workqueue_struct *endio_workers;
-	struct btrfs_workqueue_struct *endio_meta_workers;
-	struct btrfs_workqueue_struct *endio_raid56_workers;
-	struct btrfs_workqueue_struct *rmw_workers;
-	struct btrfs_workqueue_struct *endio_meta_write_workers;
-	struct btrfs_workqueue_struct *endio_write_workers;
-	struct btrfs_workqueue_struct *endio_freespace_worker;
-	struct btrfs_workqueue_struct *submit_workers;
-	struct btrfs_workqueue_struct *caching_workers;
-	struct btrfs_workqueue_struct *readahead_workers;
+	struct btrfs_workqueue *workers;
+	struct btrfs_workqueue *delalloc_workers;
+	struct btrfs_workqueue *flush_workers;
+	struct btrfs_workqueue *endio_workers;
+	struct btrfs_workqueue *endio_meta_workers;
+	struct btrfs_workqueue *endio_raid56_workers;
+	struct btrfs_workqueue *rmw_workers;
+	struct btrfs_workqueue *endio_meta_write_workers;
+	struct btrfs_workqueue *endio_write_workers;
+	struct btrfs_workqueue *endio_freespace_worker;
+	struct btrfs_workqueue *submit_workers;
+	struct btrfs_workqueue *caching_workers;
+	struct btrfs_workqueue *readahead_workers;
 
 	/*
 	 * fixup workers take dirty pages that didn't properly go through
 	 * the cow mechanism and make them safe to write.  It happens
 	 * for the sys_munmap function call path
 	 */
-	struct btrfs_workqueue_struct *fixup_workers;
-	struct btrfs_workqueue_struct *delayed_workers;
+	struct btrfs_workqueue *fixup_workers;
+	struct btrfs_workqueue *delayed_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
@@ -1604,9 +1604,9 @@ struct btrfs_fs_info {
 	atomic_t scrub_cancel_req;
 	wait_queue_head_t scrub_pause_wait;
 	int scrub_workers_refcnt;
-	struct btrfs_workqueue_struct *scrub_workers;
-	struct btrfs_workqueue_struct *scrub_wr_completion_workers;
-	struct btrfs_workqueue_struct *scrub_nocow_workers;
+	struct btrfs_workqueue *scrub_workers;
+	struct btrfs_workqueue *scrub_wr_completion_workers;
+	struct btrfs_workqueue *scrub_nocow_workers;
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	u32 check_integrity_print_mask;
@@ -1647,9 +1647,9 @@ struct btrfs_fs_info {
 	/* qgroup rescan items */
 	struct mutex qgroup_rescan_lock; /* protects the progress item */
 	struct btrfs_key qgroup_rescan_progress;
-	struct btrfs_workqueue_struct *qgroup_rescan_workers;
+	struct btrfs_workqueue *qgroup_rescan_workers;
 	struct completion qgroup_rescan_completion;
-	struct btrfs_work_struct qgroup_rescan_work;
+	struct btrfs_work qgroup_rescan_work;
 
 	/* filesystem state */
 	unsigned long fs_state;
@@ -3680,7 +3680,7 @@ struct btrfs_delalloc_work {
 	int delay_iput;
 	struct completion completion;
 	struct list_head list;
-	struct btrfs_work_struct work;
+	struct btrfs_work work;
 };
 
 struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,

commit a046e9c88b0f46677923864295eac7c92cd962cb
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:18 2014 +0800

    btrfs: Cleanup the old btrfs_worker.
    
    Since all the btrfs_worker is replaced with the newly created
    btrfs_workqueue, the old codes can be easily remove.
    
    Signed-off-by: Quwenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a98f86ac187e..5a8c77a441ba 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1504,7 +1504,6 @@ struct btrfs_fs_info {
 	 * A third pool does submit_bio to avoid deadlocking with the other
 	 * two
 	 */
-	struct btrfs_workers generic_worker;
 	struct btrfs_workqueue_struct *workers;
 	struct btrfs_workqueue_struct *delalloc_workers;
 	struct btrfs_workqueue_struct *flush_workers;

commit 0339ef2f42bcfbb2d4021ad6f38fe20580082c85
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:17 2014 +0800

    btrfs: Replace fs_info->scrub_* workqueue with btrfs_workqueue.
    
    Replace the fs_info->scrub_* with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7b50def3f206..a98f86ac187e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1605,9 +1605,9 @@ struct btrfs_fs_info {
 	atomic_t scrub_cancel_req;
 	wait_queue_head_t scrub_pause_wait;
 	int scrub_workers_refcnt;
-	struct btrfs_workers scrub_workers;
-	struct btrfs_workers scrub_wr_completion_workers;
-	struct btrfs_workers scrub_nocow_workers;
+	struct btrfs_workqueue_struct *scrub_workers;
+	struct btrfs_workqueue_struct *scrub_wr_completion_workers;
+	struct btrfs_workqueue_struct *scrub_nocow_workers;
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	u32 check_integrity_print_mask;

commit fc97fab0ea59fb923cbe91b7d208ffc6f1d8a95c
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:16 2014 +0800

    btrfs: Replace fs_info->qgroup_rescan_worker workqueue with btrfs_workqueue.
    
    Replace the fs_info->qgroup_rescan_worker with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c07b67f6f924..7b50def3f206 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1648,9 +1648,9 @@ struct btrfs_fs_info {
 	/* qgroup rescan items */
 	struct mutex qgroup_rescan_lock; /* protects the progress item */
 	struct btrfs_key qgroup_rescan_progress;
-	struct btrfs_workers qgroup_rescan_workers;
+	struct btrfs_workqueue_struct *qgroup_rescan_workers;
 	struct completion qgroup_rescan_completion;
-	struct btrfs_work qgroup_rescan_work;
+	struct btrfs_work_struct qgroup_rescan_work;
 
 	/* filesystem state */
 	unsigned long fs_state;

commit 5b3bc44e2e69d42edf40ca3785040d233ca949f4
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:15 2014 +0800

    btrfs: Replace fs_info->delayed_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->delayed_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dd79fc5a8c99..c07b67f6f924 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1525,7 +1525,7 @@ struct btrfs_fs_info {
 	 * for the sys_munmap function call path
 	 */
 	struct btrfs_workqueue_struct *fixup_workers;
-	struct btrfs_workers delayed_workers;
+	struct btrfs_workqueue_struct *delayed_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;

commit dc6e320998fb907e4c19032d545d461bfe5040d1
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:14 2014 +0800

    btrfs: Replace fs_info->fixup_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->fixup_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b5f2a19177e8..dd79fc5a8c99 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1524,7 +1524,7 @@ struct btrfs_fs_info {
 	 * the cow mechanism and make them safe to write.  It happens
 	 * for the sys_munmap function call path
 	 */
-	struct btrfs_workers fixup_workers;
+	struct btrfs_workqueue_struct *fixup_workers;
 	struct btrfs_workers delayed_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;

commit 736cfa15e89a654436d4149c109bf1ae09fc67cf
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:13 2014 +0800

    btrfs: Replace fs_info->readahead_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->readahead_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e5c94cbaa3fa..b5f2a19177e8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1517,7 +1517,7 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue_struct *endio_freespace_worker;
 	struct btrfs_workqueue_struct *submit_workers;
 	struct btrfs_workqueue_struct *caching_workers;
-	struct btrfs_workers readahead_workers;
+	struct btrfs_workqueue_struct *readahead_workers;
 
 	/*
 	 * fixup workers take dirty pages that didn't properly go through

commit e66f0bb14465371d4c86fa70cff2acc331efa1fb
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:12 2014 +0800

    btrfs: Replace fs_info->cache_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->cache_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8102fcd8f1fe..e5c94cbaa3fa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1221,7 +1221,7 @@ struct btrfs_caching_control {
 	struct list_head list;
 	struct mutex mutex;
 	wait_queue_head_t wait;
-	struct btrfs_work work;
+	struct btrfs_work_struct work;
 	struct btrfs_block_group_cache *block_group;
 	u64 progress;
 	atomic_t count;
@@ -1516,7 +1516,7 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue_struct *endio_write_workers;
 	struct btrfs_workqueue_struct *endio_freespace_worker;
 	struct btrfs_workqueue_struct *submit_workers;
-	struct btrfs_workers caching_workers;
+	struct btrfs_workqueue_struct *caching_workers;
 	struct btrfs_workers readahead_workers;
 
 	/*

commit d05a33ac265c62d4be35788dd978b2665033f077
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:11 2014 +0800

    btrfs: Replace fs_info->rmw_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->rmw_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 42bf0da250f5..8102fcd8f1fe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1511,7 +1511,7 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue_struct *endio_workers;
 	struct btrfs_workqueue_struct *endio_meta_workers;
 	struct btrfs_workqueue_struct *endio_raid56_workers;
-	struct btrfs_workers rmw_workers;
+	struct btrfs_workqueue_struct *rmw_workers;
 	struct btrfs_workqueue_struct *endio_meta_write_workers;
 	struct btrfs_workqueue_struct *endio_write_workers;
 	struct btrfs_workqueue_struct *endio_freespace_worker;

commit fccb5d86d8f52161e013025ccf3101d8fab99a32
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:10 2014 +0800

    btrfs: Replace fs_info->endio_* workqueue with btrfs_workqueue.
    
    Replace the fs_info->endio_* workqueues with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c31a102d34de..42bf0da250f5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1508,13 +1508,13 @@ struct btrfs_fs_info {
 	struct btrfs_workqueue_struct *workers;
 	struct btrfs_workqueue_struct *delalloc_workers;
 	struct btrfs_workqueue_struct *flush_workers;
-	struct btrfs_workers endio_workers;
-	struct btrfs_workers endio_meta_workers;
-	struct btrfs_workers endio_raid56_workers;
+	struct btrfs_workqueue_struct *endio_workers;
+	struct btrfs_workqueue_struct *endio_meta_workers;
+	struct btrfs_workqueue_struct *endio_raid56_workers;
 	struct btrfs_workers rmw_workers;
-	struct btrfs_workers endio_meta_write_workers;
-	struct btrfs_workers endio_write_workers;
-	struct btrfs_workers endio_freespace_worker;
+	struct btrfs_workqueue_struct *endio_meta_write_workers;
+	struct btrfs_workqueue_struct *endio_write_workers;
+	struct btrfs_workqueue_struct *endio_freespace_worker;
 	struct btrfs_workqueue_struct *submit_workers;
 	struct btrfs_workers caching_workers;
 	struct btrfs_workers readahead_workers;

commit a44903abe9dc23ffa305898368a7a910dbae13c5
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:09 2014 +0800

    btrfs: Replace fs_info->flush_workers with btrfs_workqueue.
    
    Replace the fs_info->submit_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index abed94213e6a..c31a102d34de 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1507,7 +1507,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers generic_worker;
 	struct btrfs_workqueue_struct *workers;
 	struct btrfs_workqueue_struct *delalloc_workers;
-	struct btrfs_workers flush_workers;
+	struct btrfs_workqueue_struct *flush_workers;
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers endio_meta_workers;
 	struct btrfs_workers endio_raid56_workers;
@@ -3681,7 +3681,7 @@ struct btrfs_delalloc_work {
 	int delay_iput;
 	struct completion completion;
 	struct list_head list;
-	struct btrfs_work work;
+	struct btrfs_work_struct work;
 };
 
 struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,

commit a8c93d4ef6f6727764a61a2ee1c1878a755637c5
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:08 2014 +0800

    btrfs: Replace fs_info->submit_workers with btrfs_workqueue.
    
    Much like the fs_info->workers, replace the fs_info->submit_workers
    use the same btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3b2c30d870e1..abed94213e6a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1515,7 +1515,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers endio_meta_write_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers endio_freespace_worker;
-	struct btrfs_workers submit_workers;
+	struct btrfs_workqueue_struct *submit_workers;
 	struct btrfs_workers caching_workers;
 	struct btrfs_workers readahead_workers;
 

commit afe3d24267926eb78ba863016bdd65cfe718aef5
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:07 2014 +0800

    btrfs: Replace fs_info->delalloc_workers with btrfs_workqueue
    
    Much like the fs_info->workers, replace the fs_info->delalloc_workers
    use the same btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bd7cb8ca4d6c..3b2c30d870e1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1506,7 +1506,7 @@ struct btrfs_fs_info {
 	 */
 	struct btrfs_workers generic_worker;
 	struct btrfs_workqueue_struct *workers;
-	struct btrfs_workers delalloc_workers;
+	struct btrfs_workqueue_struct *delalloc_workers;
 	struct btrfs_workers flush_workers;
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers endio_meta_workers;

commit 5cdc7ad337fb08f630ac3538fb10e4a75de2572d
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:06 2014 +0800

    btrfs: Replace fs_info->workers with btrfs_workqueue.
    
    Use the newly created btrfs_workqueue_struct to replace the original
    fs_info->workers
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b2c0336db691..bd7cb8ca4d6c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1505,7 +1505,7 @@ struct btrfs_fs_info {
 	 * two
 	 */
 	struct btrfs_workers generic_worker;
-	struct btrfs_workers workers;
+	struct btrfs_workqueue_struct *workers;
 	struct btrfs_workers delalloc_workers;
 	struct btrfs_workers flush_workers;
 	struct btrfs_workers endio_workers;

commit d1433debe7f4346cf9fc0dafc71c3137d2a97bc4
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 20 18:08:59 2014 +0800

    Btrfs: just wait or commit our own log sub-transaction
    
    We might commit the log sub-transaction which didn't contain the metadata we
    logged. It was because we didn't record the log transid and just select
    the current log sub-transaction to commit, but the right one might be
    committed by the other task already. Actually, we needn't do anything
    and it is safe that we go back directly in this case.
    
    This patch improves the log sync by the above idea. We record the transid
    of the log sub-transaction in which we log the metadata, and the transid
    of the log sub-transaction we have committed. If the committed transid
    is >= the transid we record when logging the metadata, we just go back.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 906410719acb..b2c0336db691 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1723,6 +1723,9 @@ struct btrfs_root {
 	atomic_t log_commit[2];
 	atomic_t log_batch;
 	int log_transid;
+	/* No matter the commit succeeds or not*/
+	int log_transid_committed;
+	/* Just be updated when the commit succeeds. */
 	int last_log_commit;
 	pid_t log_start_pid;
 	bool log_multiple_pids;

commit 8b050d350c7846462a21e9e054c9154ede9b43cf
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 20 18:08:58 2014 +0800

    Btrfs: fix skipped error handle when log sync failed
    
    It is possible that many tasks sync the log tree at the same time, but
    only one task can do the sync work, the others will wait for it. But those
    wait tasks didn't get the result of the log sync, and returned 0 when they
    ended the wait. It caused those tasks skipped the error handle, and the
    serious problem was they told the users the file sync succeeded but in
    fact they failed.
    
    This patch fixes this problem by introducing a log context structure,
    we insert it into the a global list. When the sync fails, we will set
    the error number of every log context in the list, then the waiting tasks
    get the error number of the log context and handle the error if need.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 70c03f5f0953..906410719acb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1718,6 +1718,7 @@ struct btrfs_root {
 	struct mutex log_mutex;
 	wait_queue_head_t log_writer_wait;
 	wait_queue_head_t log_commit_wait[2];
+	struct list_head log_ctxs[2];
 	atomic_t log_writers;
 	atomic_t log_commit[2];
 	atomic_t log_batch;

commit bb14a59b619d3a9993c3fa04bb10347db35ca550
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 20 18:08:56 2014 +0800

    Btrfs: use signed integer instead of unsigned long integer for log transid
    
    The log trans id is initialized to be 0 every time we create a log tree,
    and the log tree need be re-created after a new transaction is started,
    it means the log trans id is unlikely to be a huge number, so we can use
    signed integer instead of unsigned long integer to save a bit space.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dac6653d4cce..70c03f5f0953 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1721,8 +1721,8 @@ struct btrfs_root {
 	atomic_t log_writers;
 	atomic_t log_commit[2];
 	atomic_t log_batch;
-	unsigned long log_transid;
-	unsigned long last_log_commit;
+	int log_transid;
+	int last_log_commit;
 	pid_t log_start_pid;
 	bool log_multiple_pids;
 

commit c404e0dc2c843b154f9a36c3aec10d0a715d88eb
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jan 30 16:46:55 2014 +0800

    Btrfs: fix use-after-free in the finishing procedure of the device replace
    
    During device replace test, we hit a null pointer deference (It was very easy
    to reproduce it by running xfstests' btrfs/011 on the devices with the virtio
    scsi driver). There were two bugs that caused this problem:
    - We might allocate new chunks on the replaced device after we updated
      the mapping tree. And we forgot to replace the source device in those
      mapping of the new chunks.
    - We might get the mapping information which including the source device
      before the mapping information update. And then submit the bio which was
      based on that mapping information after we freed the source device.
    
    For the first bug, we can fix it by doing mapping tree update and source
    device remove in the same context of the chunk mutex. The chunk mutex is
    used to protect the allocable device list, the above method can avoid
    the new chunk allocation, and after we remove the source device, all
    the new chunks will be allocated on the new device. So it can fix
    the first bug.
    
    For the second bug, we need make sure all flighting bios are finished and
    no new bios are produced during we are removing the source device. To fix
    this problem, we introduced a global @bio_counter, we not only inc/dec
    @bio_counter outsize of map_blocks, but also inc it before submitting bio
    and dec @bio_counter when ending bios.
    
    Since Raid56 is a little different and device replace dosen't support raid56
    yet, it is not addressed in the patch and I add comments to make sure we will
    fix it in the future.
    
    Reported-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fceddbdfdd3d..dac6653d4cce 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -351,6 +351,7 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 #define BTRFS_FS_STATE_ERROR		0
 #define BTRFS_FS_STATE_REMOUNTING	1
 #define BTRFS_FS_STATE_TRANS_ABORTED	2
+#define BTRFS_FS_STATE_DEV_REPLACING	3
 
 /* Super block flags */
 /* Errors detected */
@@ -1674,6 +1675,9 @@ struct btrfs_fs_info {
 
 	atomic_t mutually_exclusive_operation_running;
 
+	struct percpu_counter bio_counter;
+	wait_queue_head_t replace_wait;
+
 	struct semaphore uuid_tree_rescan_sem;
 	unsigned int update_uuid_tree_gen:1;
 };
@@ -4008,6 +4012,11 @@ int btrfs_scrub_cancel_dev(struct btrfs_fs_info *info,
 int btrfs_scrub_progress(struct btrfs_root *root, u64 devid,
 			 struct btrfs_scrub_progress *progress);
 
+/* dev-replace.c */
+void btrfs_bio_counter_inc_blocked(struct btrfs_fs_info *fs_info);
+void btrfs_bio_counter_inc_noblocked(struct btrfs_fs_info *fs_info);
+void btrfs_bio_counter_dec(struct btrfs_fs_info *fs_info);
+
 /* reada.c */
 struct reada_control {
 	struct btrfs_root	*root;		/* tree to prefetch */

commit e7651b819e90da924991d727d3c007200a18670d
Merge: 060e8e3b6f8f cf93da7bcf45
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 30 20:08:20 2014 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This is a pretty big pull, and most of these changes have been
      floating in btrfs-next for a long time.  Filipe's properties work is a
      cool building block for inheriting attributes like compression down on
      a per inode basis.
    
      Jeff Mahoney kicked in code to export filesystem info into sysfs.
    
      Otherwise, lots of performance improvements, cleanups and bug fixes.
    
      Looks like there are still a few other small pending incrementals, but
      I wanted to get the bulk of this in first"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (149 commits)
      Btrfs: fix spin_unlock in check_ref_cleanup
      Btrfs: setup inode location during btrfs_init_inode_locked
      Btrfs: don't use ram_bytes for uncompressed inline items
      Btrfs: fix btrfs_search_slot_for_read backwards iteration
      Btrfs: do not export ulist functions
      Btrfs: rework ulist with list+rb_tree
      Btrfs: fix memory leaks on walking backrefs failure
      Btrfs: fix send file hole detection leading to data corruption
      Btrfs: add a reschedule point in btrfs_find_all_roots()
      Btrfs: make send's file extent item search more efficient
      Btrfs: fix to catch all errors when resolving indirect ref
      Btrfs: fix protection between walking backrefs and root deletion
      btrfs: fix warning while merging two adjacent extents
      Btrfs: fix infinite path build loops in incremental send
      btrfs: undo sysfs when open_ctree() fails
      Btrfs: fix snprintf usage by send's gen_unique_name
      btrfs: fix defrag 32-bit integer overflow
      btrfs: sysfs: list the NO_HOLES feature
      btrfs: sysfs: don't show reserved incompat feature
      btrfs: call permission checks earlier in ioctls and return EPERM
      ...

commit 514ac8ad8793a097c0c9d89202c642479d6dfa34
Author: Chris Mason <clm@fb.com>
Date:   Fri Jan 3 21:07:00 2014 -0800

    Btrfs: don't use ram_bytes for uncompressed inline items
    
    If we truncate an uncompressed inline item, ram_bytes isn't updated to reflect
    the new size.  The fixe uses the size directly from the item header when
    reading uncompressed inlines, and also fixes truncate to update the
    size as it goes.
    
    Reported-by: Jens Axboe <axboe@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    CC: stable@vger.kernel.org

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84d4c052fcd9..fceddbdfdd3d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2990,15 +2990,6 @@ BTRFS_SETGET_FUNCS(file_extent_encryption, struct btrfs_file_extent_item,
 BTRFS_SETGET_FUNCS(file_extent_other_encoding, struct btrfs_file_extent_item,
 		   other_encoding, 16);
 
-/* this returns the number of file bytes represented by the inline item.
- * If an item is compressed, this is the uncompressed size
- */
-static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
-					       struct btrfs_file_extent_item *e)
-{
-	return btrfs_file_extent_ram_bytes(eb, e);
-}
-
 /*
  * this returns the number of bytes used by the item on disk, minus the
  * size of any extent headers.  If a file is compressed on disk, this is
@@ -3012,6 +3003,32 @@ static inline u32 btrfs_file_extent_inline_item_len(struct extent_buffer *eb,
 	return btrfs_item_size(eb, e) - offset;
 }
 
+/* this returns the number of file bytes represented by the inline item.
+ * If an item is compressed, this is the uncompressed size
+ */
+static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
+					       int slot,
+					       struct btrfs_file_extent_item *fi)
+{
+	struct btrfs_map_token token;
+
+	btrfs_init_map_token(&token);
+	/*
+	 * return the space used on disk if this item isn't
+	 * compressed or encoded
+	 */
+	if (btrfs_token_file_extent_compression(eb, fi, &token) == 0 &&
+	    btrfs_token_file_extent_encryption(eb, fi, &token) == 0 &&
+	    btrfs_token_file_extent_other_encoding(eb, fi, &token) == 0) {
+		return btrfs_file_extent_inline_item_len(eb,
+							 btrfs_item_nr(slot));
+	}
+
+	/* otherwise use the ram bytes field */
+	return btrfs_token_file_extent_ram_bytes(eb, fi, &token);
+}
+
+
 /* btrfs_dev_stats_item */
 static inline u64 btrfs_dev_stats_value(struct extent_buffer *eb,
 					struct btrfs_dev_stats_item *ptr,

commit 26b47ff65bcdff8473b87680d8f876c66208087b
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Jan 15 20:00:54 2014 +0800

    Btrfs: change the members' order of btrfs_space_info structure to reduce the cache miss
    
    It is better that the position of the lock is close to the data which is
    protected by it, because they may be in the same cache line, we will load
    less cache lines when we access them. So we rearrange the members' position
    of btrfs_space_info structure to make the lock be closer to the its data.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 52c96db0ec0a..84d4c052fcd9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1105,7 +1105,7 @@ struct btrfs_qgroup_limit_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_space_info {
-	u64 flags;
+	spinlock_t lock;
 
 	u64 total_bytes;	/* total bytes in the space,
 				   this doesn't take mirrors into account */
@@ -1115,14 +1115,25 @@ struct btrfs_space_info {
 				   transaction finishes */
 	u64 bytes_reserved;	/* total bytes the allocator has reserved for
 				   current allocations */
-	u64 bytes_readonly;	/* total bytes that are read only */
-
 	u64 bytes_may_use;	/* number of bytes that may be used for
 				   delalloc/allocations */
+	u64 bytes_readonly;	/* total bytes that are read only */
+
+	unsigned int full:1;	/* indicates that we cannot allocate any more
+				   chunks for this space */
+	unsigned int chunk_alloc:1;	/* set if we are allocating a chunk */
+
+	unsigned int flush:1;		/* set if we are trying to make space */
+
+	unsigned int force_alloc;	/* set if we need to force a chunk
+					   alloc for this space */
+
 	u64 disk_used;		/* total bytes used on disk */
 	u64 disk_total;		/* total bytes on disk, takes mirrors into
 				   account */
 
+	u64 flags;
+
 	/*
 	 * bytes_pinned is kept in line with what is actually pinned, as in
 	 * we've called update_block_group and dropped the bytes_used counter
@@ -1135,21 +1146,11 @@ struct btrfs_space_info {
 	 */
 	struct percpu_counter total_bytes_pinned;
 
-	unsigned int full:1;	/* indicates that we cannot allocate any more
-				   chunks for this space */
-	unsigned int chunk_alloc:1;	/* set if we are allocating a chunk */
-
-	unsigned int flush:1;		/* set if we are trying to make space */
-
-	unsigned int force_alloc;	/* set if we need to force a chunk
-					   alloc for this space */
-
 	struct list_head list;
 
+	struct rw_semaphore groups_sem;
 	/* for block groups in our same type */
 	struct list_head block_groups[BTRFS_NR_RAID_TYPES];
-	spinlock_t lock;
-	struct rw_semaphore groups_sem;
 	wait_queue_head_t wait;
 
 	struct kobject kobj;

commit 3818aea275423236db38a2d2d0a4951bc6da2e01
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Jan 13 13:36:06 2014 +0800

    btrfs: Add noinode_cache mount option
    
    Add noinode_cache mount option for btrfs.
    
    Since inode map cache involves all the btrfs_find_free_ino/return_ino
    things and if just trigger the mount_opt,
    an inode number get from inode map cache will not returned to inode map
    cache.
    
    To keep the find and return inode both in the same behavior,
    a new bit in mount_opt, CHANGE_INODE_CACHE, is introduced for this idea.
    CHANGE_INODE_CACHE is set/cleared in remounting, and the original
    INODE_MAP_CACHE is set/cleared according to CHANGE_INODE_CACHE after a
    success transaction.
    Since find/return inode is all done between btrfs_start_transaction and
    btrfs_commit_transaction, this will keep consistent behavior.
    
    Also noinode_cache mount option will not stop the caching_kthread.
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3708fd7ee83a..52c96db0ec0a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2023,6 +2023,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)
 #define BTRFS_MOUNT_PANIC_ON_FATAL_ERROR	(1 << 22)
 #define BTRFS_MOUNT_RESCAN_UUID_TREE	(1 << 23)
+#define	BTRFS_MOUNT_CHANGE_INODE_CACHE	(1 << 24)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 

commit ade2e0b3eeca941a5cd486bac21599ff87f288c8
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Sun Jan 12 21:38:33 2014 +0800

    Btrfs: fix to search previous metadata extent item since skinny metadata
    
    There is a bug that using btrfs_previous_item() to search metadata extent item.
    This is because in btrfs_previous_item(), we need type match, however, since
    skinny metada was introduced by josef, we may mix this two types. So just
    use btrfs_previous_item() is not working right.
    
    To keep btrfs_previous_item() like normal tree search, i introduce another
    function btrfs_previous_extent_item().
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ca6bcc33d033..3708fd7ee83a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3334,6 +3334,8 @@ int btrfs_comp_cpu_keys(struct btrfs_key *k1, struct btrfs_key *k2);
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
+int btrfs_previous_extent_item(struct btrfs_root *root,
+			struct btrfs_path *path, u64 min_objectid);
 void btrfs_set_item_key_safe(struct btrfs_root *root, struct btrfs_path *path,
 			     struct btrfs_key *new_key);
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);

commit 0a2b2a844af616addc87cac3cc18dcaba2a9d0fb
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Jan 23 10:54:11 2014 -0500

    Btrfs: throttle delayed refs better
    
    On one of our gluster clusters we noticed some pretty big lag spikes.  This
    turned out to be because our transaction commit was taking like 3 minutes to
    complete.  This is because we have like 30 gigs of metadata, so our global
    reserve would end up being the max which is like 512 mb.  So our throttling code
    would allow a ridiculous amount of delayed refs to build up and then they'd all
    get run at transaction commit time, and for a cold mounted file system that
    could take up to 3 minutes to run.  So fix the throttling to be based on both
    the size of the global reserve and how long it takes us to run delayed refs.
    This patch tracks the time it takes to run delayed refs and then only allows 1
    seconds worth of outstanding delayed refs at a time.  This way it will auto-tune
    itself from cold cache up to when everything is in memory and it no longer has
    to go to disk.  This makes our transaction commits take much less time to run.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3cebb4aeddc7..ca6bcc33d033 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1360,6 +1360,7 @@ struct btrfs_fs_info {
 
 	u64 generation;
 	u64 last_trans_committed;
+	u64 avg_delayed_ref_runtime;
 
 	/*
 	 * this is updated to the current trans every time a full commit
@@ -3172,6 +3173,8 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_root *root,
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,
 				       struct btrfs_root *root);
+int btrfs_check_space_for_delayed_refs(struct btrfs_trans_handle *trans,
+				       struct btrfs_root *root);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);

commit 63541927c8d11d2686778b1e8ec71c14b4fd53e4
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Jan 7 11:47:46 2014 +0000

    Btrfs: add support for inode properties
    
    This change adds infrastructure to allow for generic properties for
    inodes. Properties are name/value pairs that can be associated with
    inodes for different purposes. They are stored as xattrs with the
    prefix "btrfs."
    
    Properties can be inherited - this means when a directory inode has
    inheritable properties set, these are added to new inodes created
    under that directory. Further, subvolumes can also have properties
    associated with them, and they can be inherited from their parent
    subvolume. Naturally, directory properties have priority over subvolume
    properties (in practice a subvolume property is just a regular
    property associated with the root inode, objectid 256, of the
    subvolume's fs tree).
    
    This change also adds one specific property implementation, named
    "compression", whose values can be "lzo" or "zlib" and it's an
    inheritable property.
    
    The corresponding changes to btrfs-progs were also implemented.
    A patch with xfstests for this feature will follow once there's
    agreement on this change/feature.
    
    Further, the script at the bottom of this commit message was used to
    do some benchmarks to measure any performance penalties of this feature.
    
    Basically the tests correspond to:
    
    Test 1 - create a filesystem and mount it with compress-force=lzo,
    then sequentially create N files of 64Kb each, measure how long it took
    to create the files, unmount the filesystem, mount the filesystem and
    perform an 'ls -lha' against the test directory holding the N files, and
    report the time the command took.
    
    Test 2 - create a filesystem and don't use any compression option when
    mounting it - instead set the compression property of the subvolume's
    root to 'lzo'. Then create N files of 64Kb, and report the time it took.
    The unmount the filesystem, mount it again and perform an 'ls -lha' like
    in the former test. This means every single file ends up with a property
    (xattr) associated to it.
    
    Test 3 - same as test 2, but uses 4 properties - 3 are duplicates of the
    compression property, have no real effect other than adding more work
    when inheriting properties and taking more btree leaf space.
    
    Test 4 - same as test 3 but with 10 properties per file.
    
    Results (in seconds, and averages of 5 runs each), for different N
    numbers of files follow.
    
    * Without properties (test 1)
    
                        file creation time        ls -lha time
    10 000 files              3.49                   0.76
    100 000 files            47.19                   8.37
    1 000 000 files         518.51                 107.06
    
    * With 1 property (compression property set to lzo - test 2)
    
                        file creation time        ls -lha time
    10 000 files              3.63                    0.93
    100 000 files            48.56                    9.74
    1 000 000 files         537.72                  125.11
    
    * With 4 properties (test 3)
    
                        file creation time        ls -lha time
    10 000 files              3.94                    1.20
    100 000 files            52.14                   11.48
    1 000 000 files         572.70                  142.13
    
    * With 10 properties (test 4)
    
                        file creation time        ls -lha time
    10 000 files              4.61                    1.35
    100 000 files            58.86                   13.83
    1 000 000 files         656.01                  177.61
    
    The increased latencies with properties are essencialy because of:
    
    *) When creating an inode, we now synchronously write 1 more item
       (an xattr item) for each property inherited from the parent dir
       (or subvolume). This could be done in an asynchronous way such
       as we do for dir intex items (delayed-inode.c), which could help
       reduce the file creation latency;
    
    *) With properties, we now have larger fs trees. For this particular
       test each xattr item uses 75 bytes of leaf space in the fs tree.
       This could be less by using a new item for xattr items, instead of
       the current btrfs_dir_item, since we could cut the 'location' and
       'type' fields (saving 18 bytes) and maybe 'transid' too (saving a
       total of 26 bytes per xattr item) from the btrfs_dir_item type.
    
    Also tried batching the xattr insertions (ignoring proper hash
    collision handling, since it didn't exist) when creating files that
    inherit properties from their parent inode/subvolume, but the end
    results were (surprisingly) essentially the same.
    
    Test script:
    
    $ cat test.pl
      #!/usr/bin/perl -w
    
      use strict;
      use Time::HiRes qw(time);
      use constant NUM_FILES => 10_000;
      use constant FILE_SIZES => (64 * 1024);
      use constant DEV => '/dev/sdb4';
      use constant MNT_POINT => '/home/fdmanana/btrfs-tests/dev';
      use constant TEST_DIR => (MNT_POINT . '/testdir');
    
      system("mkfs.btrfs", "-l", "16384", "-f", DEV) == 0 or die "mkfs.btrfs failed!";
    
      # following line for testing without properties
      #system("mount", "-o", "compress-force=lzo", DEV, MNT_POINT) == 0 or die "mount failed!";
    
      # following 2 lines for testing with properties
      system("mount", DEV, MNT_POINT) == 0 or die "mount failed!";
      system("btrfs", "prop", "set", MNT_POINT, "compression", "lzo") == 0 or die "set prop failed!";
    
      system("mkdir", TEST_DIR) == 0 or die "mkdir failed!";
      my ($t1, $t2);
    
      $t1 = time();
      for (my $i = 1; $i <= NUM_FILES; $i++) {
          my $p = TEST_DIR . '/file_' . $i;
          open(my $f, '>', $p) or die "Error opening file!";
          $f->autoflush(1);
          for (my $j = 0; $j < FILE_SIZES; $j += 4096) {
              print $f ('A' x 4096) or die "Error writing to file!";
          }
          close($f);
      }
      $t2 = time();
      print "Time to create " . NUM_FILES . ": " . ($t2 - $t1) . " seconds.\n";
      system("umount", DEV) == 0 or die "umount failed!";
      system("mount", DEV, MNT_POINT) == 0 or die "mount failed!";
    
      $t1 = time();
      system("bash -c 'ls -lha " . TEST_DIR . " > /dev/null'") == 0 or die "ls failed!";
      $t2 = time();
      print "Time to ls -lha all files: " . ($t2 - $t1) . " seconds.\n";
      system("umount", DEV) == 0 or die "umount failed!";
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f52a60b9eba5..3cebb4aeddc7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3703,7 +3703,9 @@ int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int delay_iput);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *new_root, u64 new_dirid);
+			     struct btrfs_root *new_root,
+			     struct btrfs_root *parent_root,
+			     u64 new_dirid);
 int btrfs_merge_bio_hook(int rw, struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio,
 			 unsigned long bio_flags);

commit 1acae57b161ef1282f565ef907f72aeed0eb71d9
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Jan 7 11:42:27 2014 +0000

    Btrfs: faster file extent item replace operations
    
    When writing to a file we drop existing file extent items that cover the
    write range and then add a new file extent item that represents that write
    range.
    
    Before this change we were doing a tree lookup to remove the file extent
    items, and then after we did another tree lookup to insert the new file
    extent item.
    Most of the time all the file extent items we need to drop are located
    within a single leaf - this is the leaf where our new file extent item ends
    up at. Therefore, in this common case just combine these 2 operations into
    a single one.
    
    By avoiding the second btree navigation for insertion of the new file extent
    item, we reduce btree node/leaf lock acquisitions/releases, btree block/leaf
    COW operations, CPU time on btree node/leaf key binary searches, etc.
    
    Besides for file writes, this is an operation that happens for file fsync's
    as well. However log btrees are much less likely to big as big as regular
    fs btrees, therefore the impact of this change is smaller.
    
    The following benchmark was performed against an SSD drive and a
    HDD drive, both for random and sequential writes:
    
      sysbench --test=fileio --file-num=4096 --file-total-size=8G \
         --file-test-mode=[rndwr|seqwr] --num-threads=512 \
         --file-block-size=8192 \ --max-requests=1000000 \
         --file-fsync-freq=0 --file-io-mode=sync [prepare|run]
    
    All results below are averages of 10 runs of the respective test.
    
    ** SSD sequential writes
    
    Before this change: 225.88 Mb/sec
    After this change:  277.26 Mb/sec
    
    ** SSD random writes
    
    Before this change: 49.91 Mb/sec
    After this change:  56.39 Mb/sec
    
    ** HDD sequential writes
    
    Before this change: 68.53 Mb/sec
    After this change:  69.87 Mb/sec
    
    ** HDD random writes
    
    Before this change: 13.04 Mb/sec
    After this change:  14.39 Mb/sec
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5be778e62a29..f52a60b9eba5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3772,7 +3772,10 @@ extern const struct file_operations btrfs_file_operations;
 int __btrfs_drop_extents(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root, struct inode *inode,
 			 struct btrfs_path *path, u64 start, u64 end,
-			 u64 *drop_end, int drop_cache);
+			 u64 *drop_end, int drop_cache,
+			 int replace_extent,
+			 u32 extent_item_size,
+			 int *key_inserted);
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode, u64 start,
 		       u64 end, int drop_cache);

commit efe120a067c8674a8ae21b194f0e68f098b61ee2
Author: Frank Holton <fholton@gmail.com>
Date:   Fri Dec 20 11:37:06 2013 -0500

    Btrfs: convert printk to btrfs_ and fix BTRFS prefix
    
    Convert all applicable cases of printk and pr_* to the btrfs_* macros.
    
    Fix all uses of the BTRFS prefix.
    
    Signed-off-by: Frank Holton <fholton@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9318c7520f50..5be778e62a29 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3838,7 +3838,7 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 
 static inline void assfail(char *expr, char *file, int line)
 {
-	printk(KERN_ERR "BTRFS assertion failed: %s, file: %s, line: %d",
+	pr_err("BTRFS: assertion failed: %s, file: %s, line: %d",
 	       expr, file, line);
 	BUG();
 }
@@ -3876,7 +3876,7 @@ static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
 		if (!(features & flag)) {
 			features |= flag;
 			btrfs_set_super_incompat_flags(disk_super, features);
-			printk(KERN_INFO "btrfs: setting %llu feature flag\n",
+			btrfs_info(fs_info, "setting %llu feature flag",
 					 flag);
 		}
 		spin_unlock(&fs_info->super_lock);

commit 2c68653787f91c62f8891209dc1f617088c822e4
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Dec 16 17:34:17 2013 +0100

    btrfs: Check read-only status of roots during send
    
    All the subvolues that are involved in send must be read-only during the
    whole operation. The ioctl SUBVOL_SETFLAGS could be used to change the
    status to read-write and the result of send stream is undefined if the
    data change unexpectedly.
    
    Fix that by adding a refcount for all involved roots and verify that
    there's no send in progress during SUBVOL_SETFLAGS ioctl call that does
    read-only -> read-write transition.
    
    We need refcounts because there are no restrictions on number of send
    parallel operations currently run on a single subvolume, be it source,
    parent or one of the multiple clone sources.
    
    Kernel is silent when the RO checks fail and returns EPERM. The same set
    of checks is done already in userspace before send starts.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3c9053a153b1..9318c7520f50 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1814,6 +1814,12 @@ struct btrfs_root {
 	struct list_head ordered_extents;
 	struct list_head ordered_root;
 	u64 nr_ordered_extents;
+
+	/*
+	 * Number of currently running SEND ioctls to prevent
+	 * manipulation with the read-only status via SUBVOL_SETFLAGS
+	 */
+	int send_in_progress;
 };
 
 struct btrfs_ioctl_defrag_range_args {

commit e223cfcd3eed7401e4217c7fb7391017c8124d8c
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Dec 13 19:39:54 2013 +0000

    Btrfs: remove field tree_mod_seq_elem from btrfs_fs_info struct
    
    It's not used anywhere, so just drop it.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a924274a503e..3c9053a153b1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1462,7 +1462,6 @@ struct btrfs_fs_info {
 	spinlock_t tree_mod_seq_lock;
 	atomic64_t tree_mod_seq;
 	struct list_head tree_mod_seq_list;
-	struct seq_list tree_mod_seq_elem;
 
 	/* this protects tree_mod_log */
 	rwlock_t tree_mod_log_lock;

commit f28491e0a6c46d99cbbef0f8ef7e314afa2359c8
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 16 13:24:27 2013 -0500

    Btrfs: move the extent buffer radix tree into the fs_info
    
    I need to create a fake tree to test qgroups and I don't want to have to setup a
    fake btree_inode.  The fact is we only use the radix tree for the fs_info, so
    everybody else who allocates an extent_io_tree is just wasting the space anyway.
    This patch moves the radix tree and its lock into btrfs_fs_info so there is less
    stuff I have to fake to do qgroup sanity tests.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7158c97fdc5e..a924274a503e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1659,6 +1659,10 @@ struct btrfs_fs_info {
 	spinlock_t reada_lock;
 	struct radix_tree_root reada_tree;
 
+	/* Extent buffer radix tree */
+	spinlock_t buffer_lock;
+	struct radix_tree_root buffer_radix;
+
 	/* next backup root to be overwritten */
 	int backup_root_index;
 

commit 27a0dd61a5cf742ebcd7a82c47be2502b1113eff
Author: Frank Holton <fholton@gmail.com>
Date:   Tue Nov 12 19:22:53 2013 -0500

    Btrfs: make btrfs_debug match pr_debug handling related to DEBUG
    
    The kernel macro pr_debug is defined as a empty statement when DEBUG is
    not defined. Make btrfs_debug match pr_debug to avoid spamming
    the kernel log with debug messages
    
    Signed-off-by: Frank Holton <fholton@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 47835f5850de..7158c97fdc5e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3816,8 +3816,14 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 	btrfs_printk(fs_info, KERN_NOTICE fmt, ##args)
 #define btrfs_info(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_INFO fmt, ##args)
+
+#ifdef DEBUG
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)
+#else
+#define btrfs_debug(fs_info, fmt, args...) \
+    no_printk(KERN_DEBUG fmt, ##args)
+#endif
 
 #ifdef CONFIG_BTRFS_ASSERT
 

commit 33b98f22711142b7f92ad8e10f21fc3f921ffde2
Author: Sergei Trofimovich <slyfox@gentoo.org>
Date:   Wed Nov 13 17:46:48 2013 +0800

    btrfs: cleanup: removed unused 'btrfs_get_inode_ref_index'
    
    Found by uselex.rb:
    > btrfs_get_inode_ref_index: [R]: exported from:
    fs/btrfs/inode-item.o fs/btrfs/btrfs.o fs/btrfs/built-in.o
    
    Signed-off-by: Sergei Trofimovich <slyfox@gentoo.org>
    Reviewed-by: David Stebra <dsterba@suse.cz>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a58611fbf004..47835f5850de 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3587,12 +3587,6 @@ int btrfs_del_inode_ref(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   const char *name, int name_len,
 			   u64 inode_objectid, u64 ref_objectid, u64 *index);
-int btrfs_get_inode_ref_index(struct btrfs_trans_handle *trans,
-			      struct btrfs_root *root,
-			      struct btrfs_path *path,
-			      const char *name, int name_len,
-			      u64 inode_objectid, u64 ref_objectid, int mod,
-			      u64 *ret_index);
 int btrfs_insert_empty_inode(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid);

commit e33d5c3d6d61518c7f115af6d11d3dffa230d31f
Author: Kelley Nielsen <kelleynnn@gmail.com>
Date:   Mon Nov 4 19:33:33 2013 -0800

    btrfs: bootstrap generic btrfs_find_item interface
    
    There are many btrfs functions that manually search the tree for an
    item. They all reimplement the same mechanism and differ in the
    conditions that they use to find the item. __inode_info() is one such
    example. Zach Brown proposed creating a new interface to take the place
    of these functions.
    
    This patch is the first step to creating the interface. A new function,
    btrfs_find_item, has been added to ctree.c and prototyped in ctree.h.
    It is identical to __inode_info, except that the order of the parameters
    has been rearranged to more closely those of similar functions elsewhere
    in the code (now, root and path come first, then the objectid, offset
    and type, and the key to be filled in last). __inode_info's callers have
    been set to call this new function instead, and __inode_info itself has
    been removed.
    
    Signed-off-by: Kelley Nielsen <kelleynnn@gmail.com>
    Suggested-by: Zach Brown <zab@redhat.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dbe9b313cdf2..a58611fbf004 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3371,6 +3371,8 @@ int btrfs_duplicate_item(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 struct btrfs_path *path,
 			 struct btrfs_key *new_key);
+int btrfs_find_item(struct btrfs_root *fs_root, struct btrfs_path *path,
+		u64 inum, u64 ioff, u8 key_type, struct btrfs_key *found_key);
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);

commit 29e5be240a3caf175364fdeecb0441dff500d5d9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Nov 1 13:07:05 2013 -0400

    btrfs: publish device membership in sysfs
    
    Now that we have the infrastructure for per-super attributes, we can
    publish device membership in /sys/fs/btrfs/<fsid>/devices. The information
    is published as symlinks to the block devices.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f608306b5d88..dbe9b313cdf2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1530,6 +1530,7 @@ struct btrfs_fs_info {
 
 	struct kobject super_kobj;
 	struct kobject *space_info_kobj;
+	struct kobject *device_dir_kobj;
 	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;

commit 6ab0a2029ceaedb78af807871820708b7353e3be
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Nov 1 13:07:04 2013 -0400

    btrfs: publish allocation data in sysfs
    
    While trying to debug ENOSPC issues, it's helpful to understand what the
    kernel's view of the available space is. We export this information
    via ioctl, but sysfs files are more easily used.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c5c888fbf033..f608306b5d88 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1151,6 +1151,9 @@ struct btrfs_space_info {
 	spinlock_t lock;
 	struct rw_semaphore groups_sem;
 	wait_queue_head_t wait;
+
+	struct kobject kobj;
+	struct kobject block_group_kobjs[BTRFS_NR_RAID_TYPES];
 };
 
 #define	BTRFS_BLOCK_RSV_GLOBAL		1
@@ -1526,6 +1529,7 @@ struct btrfs_fs_info {
 	int thread_pool_size;
 
 	struct kobject super_kobj;
+	struct kobject *space_info_kobj;
 	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
@@ -3178,6 +3182,7 @@ struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 struct btrfs_fs_info *info,
 						 u64 bytenr);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
+int get_block_group_index(struct btrfs_block_group_cache *cache);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					struct btrfs_root *root, u32 blocksize,
 					u64 parent, u64 root_objectid,

commit 5ac1d209f11271fbfad0fa31ba56ec64c142d9ea
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Nov 1 13:06:58 2013 -0400

    btrfs: publish per-super attributes in sysfs
    
    This patch adds per-super attributes to sysfs.
    
    It doesn't publish any attributes yet, but does the proper lifetime
    handling as well as the basic infrastructure to add new attributes.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 498452ebfd37..c5c888fbf033 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3780,6 +3780,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 /* sysfs.c */
 int btrfs_init_sysfs(void);
 void btrfs_exit_sysfs(void);
+int btrfs_sysfs_add_one(struct btrfs_fs_info *fs_info);
+void btrfs_sysfs_remove_one(struct btrfs_fs_info *fs_info);
 
 /* xattr.c */
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);

commit 2eaa055fab4e3127c9f572fda1b710cbb2acdf1c
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Nov 15 15:33:55 2013 -0500

    btrfs: add ioctls to query/change feature bits online
    
    There are some feature bits that require no offline setup and can
    be enabled online. I've only reviewed extended irefs, but there will
    probably be more.
    
    We introduce three new ioctls:
    - BTRFS_IOC_GET_SUPPORTED_FEATURES: query the kernel for supported features.
    - BTRFS_IOC_GET_FEATURES: query the kernel for enabled features on a per-fs
      basis, as well as querying for which features are changeable with mounted.
    - BTRFS_IOC_SET_FEATURES: change features on a per-fs basis.
    
    We introduce two new masks per feature set (_SAFE_SET and _SAFE_CLEAR) that
    allow us to define which features are safe to change at runtime.
    
    The failure modes for BTRFS_IOC_SET_FEATURES are as follows:
    - Enabling a completely unsupported feature: warns and returns -ENOTSUPP
    - Enabling a feature that can only be done offline: warns and returns -EPERM
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1aafccda05d1..498452ebfd37 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -524,7 +524,12 @@ struct btrfs_super_block {
 #define BTRFS_FEATURE_INCOMPAT_NO_HOLES		(1ULL << 9)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
+#define BTRFS_FEATURE_COMPAT_SAFE_SET		0ULL
+#define BTRFS_FEATURE_COMPAT_SAFE_CLEAR		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
+#define BTRFS_FEATURE_COMPAT_RO_SAFE_SET	0ULL
+#define BTRFS_FEATURE_COMPAT_RO_SAFE_CLEAR	0ULL
+
 #define BTRFS_FEATURE_INCOMPAT_SUPP			\
 	(BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF |		\
 	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL |	\
@@ -536,6 +541,10 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA |	\
 	 BTRFS_FEATURE_INCOMPAT_NO_HOLES)
 
+#define BTRFS_FEATURE_INCOMPAT_SAFE_SET			\
+	(BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF)
+#define BTRFS_FEATURE_INCOMPAT_SAFE_CLEAR		0ULL
+
 /*
  * A leaf is full of items. offset and size tell us where to find
  * the item in the leaf (relative to the start of the data area)

commit e20d6c5ba38d066c7dc0f7d3b68da14b9ae7fe37
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Nov 13 21:11:49 2013 -0500

    Btrfs: fix check-integrity to look at the referenced data properly
    
    We were looking at file_extent_num_bytes unconditionally when looking at
    referenced data bytes, but this isn't correct for compression.  Fix this by
    checking the compression of the file extent we are and setting num_bytes to
    disk_num_bytes in the case of compression so that we are marking the proper
    bytes as referenced.  This fixes check_int_data freaking out when running
    btrfs/004.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8be78f7d57e1..1aafccda05d1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2927,6 +2927,10 @@ BTRFS_SETGET_STACK_FUNCS(stack_file_extent_generation,
 			 struct btrfs_file_extent_item, generation, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_file_extent_num_bytes,
 			 struct btrfs_file_extent_item, num_bytes, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_file_extent_disk_num_bytes,
+			 struct btrfs_file_extent_item, disk_num_bytes, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_file_extent_compression,
+			 struct btrfs_file_extent_item, compression, 8);
 
 static inline unsigned long
 btrfs_file_extent_inline_start(struct btrfs_file_extent_item *e)

commit 16e7549f045d33b0c5b0ebf19d08439e9221d40c
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Oct 22 12:18:51 2013 -0400

    Btrfs: incompatible format change to remove hole extents
    
    Btrfs has always had these filler extent data items for holes in inodes.  This
    has made somethings very easy, like logging hole punches and sending hole
    punches.  However for large holey files these extent data items are pure
    overhead.  So add an incompatible feature to no longer add hole extents to
    reduce the amount of metadata used by these sort of files.  This has a few
    changes for logging and send obviously since they will need to detect holes and
    log/send the holes if there are any.  I've tested this thoroughly with xfstests
    and it doesn't cause any issues with and without the incompat format set.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 54ab86127f7a..8be78f7d57e1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -521,6 +521,7 @@ struct btrfs_super_block {
 #define BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF	(1ULL << 6)
 #define BTRFS_FEATURE_INCOMPAT_RAID56		(1ULL << 7)
 #define BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA	(1ULL << 8)
+#define BTRFS_FEATURE_INCOMPAT_NO_HOLES		(1ULL << 9)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
@@ -532,7 +533,8 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO |		\
 	 BTRFS_FEATURE_INCOMPAT_RAID56 |		\
 	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF |		\
-	 BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
+	 BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA |	\
+	 BTRFS_FEATURE_INCOMPAT_NO_HOLES)
 
 /*
  * A leaf is full of items. offset and size tell us where to find
@@ -3399,6 +3401,7 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 }
 
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
+int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_next_old_leaf(struct btrfs_root *root, struct btrfs_path *path,
 			u64 time_seq);
 static inline int btrfs_next_old_item(struct btrfs_root *root,

commit 996a710d46418cacb5b4a519ab9341a74066551d
Author: Christoph Hellwig <hch@infradead.org>
Date:   Fri Dec 20 05:16:43 2013 -0800

    btrfs: use generic posix ACL infrastructure
    
    Also don't bother to set up a .get_acl method for symlinks as we do not
    support access control (ACLs or even mode bits) for symlinks in Linux.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 54ab86127f7a..7506825211a2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3899,20 +3899,17 @@ do {									\
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL
 struct posix_acl *btrfs_get_acl(struct inode *inode, int type);
+int btrfs_set_acl(struct inode *inode, struct posix_acl *acl, int type);
 int btrfs_init_acl(struct btrfs_trans_handle *trans,
 		   struct inode *inode, struct inode *dir);
-int btrfs_acl_chmod(struct inode *inode);
 #else
 #define btrfs_get_acl NULL
+#define btrfs_set_acl NULL
 static inline int btrfs_init_acl(struct btrfs_trans_handle *trans,
 				 struct inode *inode, struct inode *dir)
 {
 	return 0;
 }
-static inline int btrfs_acl_chmod(struct inode *inode)
-{
-	return 0;
-}
 #endif
 
 /* relocation.c */

commit 9650e05c071fc92e704d4359d59e3ac3ecae2875
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Tue Nov 12 19:32:04 2013 +0800

    Btrfs: remove dead codes from ctree.h
    
    These two functions are only stated but undefined.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f9aeb2759a64..54ab86127f7a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3613,9 +3613,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_ordered_sum *sums);
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig);
-int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root, struct btrfs_path *path,
-			u64 isize);
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit);
 /* inode.c */
@@ -3744,9 +3741,6 @@ void btrfs_cleanup_defrag_inodes(struct btrfs_fs_info *fs_info);
 int btrfs_sync_file(struct file *file, loff_t start, loff_t end, int datasync);
 void btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			     int skip_pinned);
-int btrfs_replace_extent_cache(struct inode *inode, struct extent_map *replace,
-			       u64 start, u64 end, int skip_pinned,
-			       int modified);
 extern const struct file_operations btrfs_file_operations;
 int __btrfs_drop_extents(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root, struct inode *inode,

commit 54563d41a58be77e9bd9ef7af1ea4026cf0e7e07
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 1 15:57:51 2013 -0400

    btrfs: get rid of fdentry()
    
    3 of 4 callers actually want file_inode()...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aea4433081dc..f9aeb2759a64 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3111,11 +3111,6 @@ static inline u32 btrfs_level_size(struct btrfs_root *root, int level)
 	((unsigned long)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset_nr(leaf, slot)))
 
-static inline struct dentry *fdentry(struct file *file)
-{
-	return file->f_path.dentry;
-}
-
 static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
 {
 	return ((space_info->flags & BTRFS_BLOCK_GROUP_METADATA) &&

commit 91aef86f3b8ab0685d930a5468254384513d1c97
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Nov 4 23:13:26 2013 +0800

    Btrfs: rename btrfs_start_all_delalloc_inodes
    
    rename the function -- btrfs_start_all_delalloc_inodes(), and make its
    name be compatible to btrfs_wait_ordered_roots(), since they are always
    used at the same place.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 34279665fd69..aea4433081dc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3680,8 +3680,7 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
-int btrfs_start_all_delalloc_inodes(struct btrfs_fs_info *fs_info,
-				    int delay_iput);
+int btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, int delay_iput);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,

commit 9b011adfe14977fcda977234609d43ca52463a3d
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Fri Oct 25 19:12:02 2013 +0800

    Btrfs: remove scrub_super_lock holding in btrfs_sync_log()
    
    Originally, we introduced scrub_super_lock to synchronize
    tree log code with scrubbing super.
    
    However we can replace scrub_super_lock with device_list_mutex,
    because writing super will hold this mutex, this will reduce an extra
    lock holding when writing supers in sync log code.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9f5e1cfb0209..34279665fd69 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1586,7 +1586,6 @@ struct btrfs_fs_info {
 	atomic_t scrubs_paused;
 	atomic_t scrub_cancel_req;
 	wait_queue_head_t scrub_pause_wait;
-	struct rw_semaphore scrub_super_lock;
 	int scrub_workers_refcnt;
 	struct btrfs_workers scrub_workers;
 	struct btrfs_workers scrub_wr_completion_workers;
@@ -3950,9 +3949,7 @@ int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,
 		    u64 end, struct btrfs_scrub_progress *progress,
 		    int readonly, int is_dev_replace);
 void btrfs_scrub_pause(struct btrfs_root *root);
-void btrfs_scrub_pause_super(struct btrfs_root *root);
 void btrfs_scrub_continue(struct btrfs_root *root);
-void btrfs_scrub_continue_super(struct btrfs_root *root);
 int btrfs_scrub_cancel(struct btrfs_fs_info *info);
 int btrfs_scrub_cancel_dev(struct btrfs_fs_info *info,
 			   struct btrfs_device *dev);

commit aaedb55bc08f384b7f57dbb3222a511baed4decf
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Oct 11 14:44:09 2013 -0400

    Btrfs: add tests for btrfs_get_extent
    
    I'm going to be removing hole extents in the near future so I wanted to make a
    sanity test for btrfs_get_extent to make sure I don't break anything in the
    meantime.  This patch just puts btrfs_get_extent through its paces by giving it
    a completely unreasonable mapping to look at and make sure it is giving us back
    maps that make sense.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2f398062b942..9f5e1cfb0209 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4034,5 +4034,9 @@ static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
 	return signal_pending(current);
 }
 
+/* Sanity test specific functions */
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+void btrfs_test_destroy_inode(struct inode *inode);
+#endif
 
 #endif

commit 294e30fee35d3151d100cfe59e839c2dbc16a374
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Oct 9 12:00:56 2013 -0400

    Btrfs: add tests for find_lock_delalloc_range
    
    So both Liu and I made huge messes of find_lock_delalloc_range trying to fix
    stuff, me first by fixing extent size, then him by fixing something I broke and
    then me again telling him to fix it a different way.  So this is obviously a
    candidate for some testing.  This patch adds a pseudo fs so we can allocate fake
    inodes for tests that need an inode or pages.  Then it addes a bunch of tests to
    make sure find_lock_delalloc_range is acting the way it is supposed to.  With
    this patch and all of our previous patches to find_lock_delalloc_range I am sure
    it is working as expected now.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9ca15a84cc5a..2f398062b942 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -47,6 +47,12 @@ extern struct kmem_cache *btrfs_path_cachep;
 extern struct kmem_cache *btrfs_free_space_cachep;
 struct btrfs_ordered_sum;
 
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+#define STATIC noinline
+#else
+#define STATIC static noinline
+#endif
+
 #define BTRFS_MAGIC 0x4D5F53665248425FULL /* ascii _BHRfS_M, no null */
 
 #define BTRFS_MAX_MIRRORS 3

commit 6174d3cb43aa974d0c8590a3e628ac35ab0bbc13
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Oct 1 16:13:42 2013 +0100

    Btrfs: remove unused max_key arg from btrfs_search_forward
    
    It is not used for anything.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ee8972b9f1ab..9ca15a84cc5a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3309,7 +3309,6 @@ int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
 			struct btrfs_key *key, int lowest_level,
 			u64 min_trans);
 int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
-			 struct btrfs_key *max_key,
 			 struct btrfs_path *path,
 			 u64 min_trans);
 enum btrfs_compare_tree_result {

commit 0a4e558609dd4df30a58a07d9eb14c5ddc2c1241
Author: Ross Kirk <ross.kirk@gmail.com>
Date:   Tue Sep 24 10:12:38 2013 +0100

    btrfs: remove unused parameter from btrfs_header_fsid
    
    Remove unused parameter, 'eb'. Unused since introduction in
    5f39d397dfbe140a14edecd4e73c34ce23c4f9ee
    
    Updated to be rebased against current upstream and correct diff supplied this time!
    
    Signed-off-by: Ross Kirk <ross.kirk@gmail.com>
    Reviewed-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ee0b8aa82828..ee8972b9f1ab 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2667,7 +2667,7 @@ static inline void btrfs_set_header_backref_rev(struct extent_buffer *eb,
 	btrfs_set_header_flags(eb, flags);
 }
 
-static inline unsigned long btrfs_header_fsid(struct extent_buffer *eb)
+static inline unsigned long btrfs_header_fsid(void)
 {
 	return offsetof(struct btrfs_header, fsid);
 }

commit 06ea65a398a2501e94beee3a425d07e1846ff25a
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Sep 19 16:07:01 2013 -0400

    Btrfs: add a sanity test for btrfs_split_item
    
    While looking at somebodys corruption I became completely convinced that
    btrfs_split_item was broken, so I wrote this test to verify that it was working
    as it was supposed to.  Thankfully it appears to be working as intended, so just
    add this test to make sure nobody breaks it in the future.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa117f7d5a8f..ee0b8aa82828 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1724,7 +1724,9 @@ struct btrfs_root {
 	int ref_cows;
 	int track_dirty;
 	int in_radix;
-
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+	int dummy_root;
+#endif
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;

commit dd3cc16b8750251ea9b1a843ce7806e82b015d5e
Author: Ross Kirk <ross.kirk@gmail.com>
Date:   Mon Sep 16 15:58:09 2013 +0100

    btrfs: drop unused parameter from btrfs_item_nr
    
    Remove unused eb parameter from btrfs_item_nr
    
    Signed-off-by: Ross Kirk <ross.kirk@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0506f40ede83..fa117f7d5a8f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2461,8 +2461,7 @@ static inline unsigned long btrfs_item_nr_offset(int nr)
 		sizeof(struct btrfs_item) * nr;
 }
 
-static inline struct btrfs_item *btrfs_item_nr(struct extent_buffer *eb,
-					       int nr)
+static inline struct btrfs_item *btrfs_item_nr(int nr)
 {
 	return (struct btrfs_item *)btrfs_item_nr_offset(nr);
 }
@@ -2475,30 +2474,30 @@ static inline u32 btrfs_item_end(struct extent_buffer *eb,
 
 static inline u32 btrfs_item_end_nr(struct extent_buffer *eb, int nr)
 {
-	return btrfs_item_end(eb, btrfs_item_nr(eb, nr));
+	return btrfs_item_end(eb, btrfs_item_nr(nr));
 }
 
 static inline u32 btrfs_item_offset_nr(struct extent_buffer *eb, int nr)
 {
-	return btrfs_item_offset(eb, btrfs_item_nr(eb, nr));
+	return btrfs_item_offset(eb, btrfs_item_nr(nr));
 }
 
 static inline u32 btrfs_item_size_nr(struct extent_buffer *eb, int nr)
 {
-	return btrfs_item_size(eb, btrfs_item_nr(eb, nr));
+	return btrfs_item_size(eb, btrfs_item_nr(nr));
 }
 
 static inline void btrfs_item_key(struct extent_buffer *eb,
 			   struct btrfs_disk_key *disk_key, int nr)
 {
-	struct btrfs_item *item = btrfs_item_nr(eb, nr);
+	struct btrfs_item *item = btrfs_item_nr(nr);
 	read_eb_member(eb, item, struct btrfs_item, key, disk_key);
 }
 
 static inline void btrfs_set_item_key(struct extent_buffer *eb,
 			       struct btrfs_disk_key *disk_key, int nr)
 {
-	struct btrfs_item *item = btrfs_item_nr(eb, nr);
+	struct btrfs_item *item = btrfs_item_nr(nr);
 	write_eb_member(eb, item, struct btrfs_item, key, disk_key);
 }
 

commit 363e4d354e51558629d13c5ae456f98c4b209576
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Sep 17 11:02:25 2013 -0400

    Btrfs: remove space_info->reservation_progress
    
    This isn't used for anything anymore, just remove it.
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 36490b92ee33..0506f40ede83 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1118,15 +1118,6 @@ struct btrfs_space_info {
 	 */
 	struct percpu_counter total_bytes_pinned;
 
-	/*
-	 * we bump reservation progress every time we decrement
-	 * bytes_reserved.  This way people waiting for reservations
-	 * know something good has happened and they can check
-	 * for progress.  The number here isn't to be trusted, it
-	 * just shows reclaim activity
-	 */
-	unsigned long reservation_progress;
-
 	unsigned int full:1;	/* indicates that we cannot allocate any more
 				   chunks for this space */
 	unsigned int chunk_alloc:1;	/* set if we are allocating a chunk */

commit c4fbb4300abd6f662c7d5049d01f868af9874069
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Sep 17 10:50:06 2013 -0400

    Btrfs: fix worst case calculator for space usage
    
    Forever ago I made the worst case calculator say that we could potentially split
    into 3 blocks for every level on the way down, which isn't right.  If we split
    we're only going to get two new blocks, the one we originally cow'ed and the new
    one we're going to split.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2491ba076b42..36490b92ee33 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3135,7 +3135,7 @@ static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)
 {
 	return (root->leafsize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
-		3 * num_items;
+		2 * num_items;
 }
 
 /*

commit 83d4cfd4da57b6ff16296875a962de2158799de6
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Aug 30 15:09:51 2013 -0400

    Btrfs: fixup error handling in btrfs_reloc_cow
    
    If we failed to actually allocate the correct size of the extent to relocate we
    will end up in an infinite loop because we won't return an error, we'll just
    move on to the next extent.  So fix this up by returning an error, and then fix
    all the callers to return an error up the stack rather than BUG_ON()'ing.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3c1da6f98a4d..2491ba076b42 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3939,9 +3939,9 @@ int btrfs_update_reloc_root(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
 int btrfs_recover_relocation(struct btrfs_root *root);
 int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
-void btrfs_reloc_cow_block(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, struct extent_buffer *buf,
-			   struct extent_buffer *cow);
+int btrfs_reloc_cow_block(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root, struct extent_buffer *buf,
+			  struct extent_buffer *cow);
 void btrfs_reloc_pre_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending,
 			      u64 *bytes_to_reserve);

commit d8f980391f418e567c805d3e40be5d63bfc4c8ea
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Sat Aug 24 19:51:06 2013 +0100

    Btrfs: fix memory leak of uuid_root in free_fs_info
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1f3fd584e5f4..3c1da6f98a4d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3460,6 +3460,7 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->dev_root);
 	kfree(fs_info->csum_root);
 	kfree(fs_info->quota_root);
+	kfree(fs_info->uuid_root);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
 	kfree(fs_info);

commit 2e17c7c65e5dcbb53a6384a3406244f62bca189c
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Aug 26 16:53:15 2013 -0400

    Btrfs: add support for asserts
    
    One of the complaints we get a lot is how many BUG_ON()'s we have.  So to help
    with this I'm introducing a kconfig option to enable/disable a new ASSERT()
    mechanism much like what XFS does.  This will allow us developers to still get
    our nice panics but allow users/distros to compile them out.  With this we can
    go through and convert any BUG_ON()'s that we have to catch actual programming
    mistakes to the new ASSERT() and then fix everybody else to return errors.  This
    will also allow developers to leave sanity checks in their new code to make sure
    we don't trip over problems while testing stuff and vetting new features.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c90be01cbe67..1f3fd584e5f4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3814,6 +3814,22 @@ void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 #define btrfs_debug(fs_info, fmt, args...) \
 	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)
 
+#ifdef CONFIG_BTRFS_ASSERT
+
+static inline void assfail(char *expr, char *file, int line)
+{
+	printk(KERN_ERR "BTRFS assertion failed: %s, file: %s, line: %d",
+	       expr, file, line);
+	BUG();
+}
+
+#define ASSERT(expr)	\
+	(likely(expr) ? (void)0 : assfail(#expr, __FILE__, __LINE__))
+#else
+#define ASSERT(expr)	((void)0)
+#endif
+
+#define btrfs_assert()
 __printf(5, 6)
 void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);

commit b308bc2f05a86e728bd035e21a4974acd05f4d1e
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:15 2013 +0200

    Btrfs: Make btrfs_header_chunk_tree_uuid() return unsigned long
    
    Internally, btrfs_header_chunk_tree_uuid() calculates an unsigned long, but
    casts it to a pointer, while all callers cast it to unsigned long again.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1b8f5def29c7..c90be01cbe67 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2680,10 +2680,9 @@ static inline unsigned long btrfs_header_fsid(struct extent_buffer *eb)
 	return offsetof(struct btrfs_header, fsid);
 }
 
-static inline u8 *btrfs_header_chunk_tree_uuid(struct extent_buffer *eb)
+static inline unsigned long btrfs_header_chunk_tree_uuid(struct extent_buffer *eb)
 {
-	unsigned long ptr = offsetof(struct btrfs_header, chunk_tree_uuid);
-	return (u8 *)ptr;
+	return offsetof(struct btrfs_header, chunk_tree_uuid);
 }
 
 static inline int btrfs_is_leaf(struct extent_buffer *eb)

commit fba6aa75654394fccf2530041e9451414c28084f
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:14 2013 +0200

    Btrfs: Make btrfs_header_fsid() return unsigned long
    
    Internally, btrfs_header_fsid() calculates an unsigned long, but casts
    it to a pointer, while all callers cast it to unsigned long again.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2202bd8c5e16..1b8f5def29c7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2675,10 +2675,9 @@ static inline void btrfs_set_header_backref_rev(struct extent_buffer *eb,
 	btrfs_set_header_flags(eb, flags);
 }
 
-static inline u8 *btrfs_header_fsid(struct extent_buffer *eb)
+static inline unsigned long btrfs_header_fsid(struct extent_buffer *eb)
 {
-	unsigned long ptr = offsetof(struct btrfs_header, fsid);
-	return (u8 *)ptr;
+	return offsetof(struct btrfs_header, fsid);
 }
 
 static inline u8 *btrfs_header_chunk_tree_uuid(struct extent_buffer *eb)

commit 231e88f41027d90e9516d257d8085069b65686dd
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:13 2013 +0200

    Btrfs: Make btrfs_dev_extent_chunk_tree_uuid() return unsigned long
    
    Internally, btrfs_dev_extent_chunk_tree_uuid() calculates an unsigned long,
    but casts it to a pointer, while all callers cast it to unsigned long
    again.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b71bc3a99342..2202bd8c5e16 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2330,10 +2330,10 @@ BTRFS_SETGET_FUNCS(dev_extent_chunk_offset, struct btrfs_dev_extent,
 		   chunk_offset, 64);
 BTRFS_SETGET_FUNCS(dev_extent_length, struct btrfs_dev_extent, length, 64);
 
-static inline u8 *btrfs_dev_extent_chunk_tree_uuid(struct btrfs_dev_extent *dev)
+static inline unsigned long btrfs_dev_extent_chunk_tree_uuid(struct btrfs_dev_extent *dev)
 {
 	unsigned long ptr = offsetof(struct btrfs_dev_extent, chunk_tree_uuid);
-	return (u8 *)((unsigned long)dev + ptr);
+	return (unsigned long)dev + ptr;
 }
 
 BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 64);

commit 1473b24ee0cb43d4b48aa0c5f1b8417928910a4d
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:12 2013 +0200

    Btrfs: Make btrfs_device_fsid() return unsigned long
    
    All callers of btrfs_device_fsid() cast its return type to unsigned long.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b4e70537cada..b71bc3a99342 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2169,9 +2169,9 @@ static inline unsigned long btrfs_device_uuid(struct btrfs_dev_item *d)
 	return (unsigned long)d + offsetof(struct btrfs_dev_item, uuid);
 }
 
-static inline char *btrfs_device_fsid(struct btrfs_dev_item *d)
+static inline unsigned long btrfs_device_fsid(struct btrfs_dev_item *d)
 {
-	return (char *)d + offsetof(struct btrfs_dev_item, fsid);
+	return (unsigned long)d + offsetof(struct btrfs_dev_item, fsid);
 }
 
 BTRFS_SETGET_FUNCS(chunk_length, struct btrfs_chunk, length, 64);

commit 410ba3a291081d98f0e58a868e1305110d986903
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:11 2013 +0200

    Btrfs: Make btrfs_device_uuid() return unsigned long
    
    All callers of btrfs_device_uuid() cast its return type to unsigned long.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7add85a645a3..b4e70537cada 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2164,9 +2164,9 @@ BTRFS_SETGET_STACK_FUNCS(stack_device_bandwidth, struct btrfs_dev_item,
 BTRFS_SETGET_STACK_FUNCS(stack_device_generation, struct btrfs_dev_item,
 			 generation, 64);
 
-static inline char *btrfs_device_uuid(struct btrfs_dev_item *d)
+static inline unsigned long btrfs_device_uuid(struct btrfs_dev_item *d)
 {
-	return (char *)d + offsetof(struct btrfs_dev_item, uuid);
+	return (unsigned long)d + offsetof(struct btrfs_dev_item, uuid);
 }
 
 static inline char *btrfs_device_fsid(struct btrfs_dev_item *d)

commit 6e71c47afee8178c0620323009b23813bfde7eac
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:08 2013 +0200

    Btrfs: Make BTRFS_DEV_REPLACE_DEVID an unsigned long long constant
    
    The internal btrfs device id is a u64, hence make the constant
    BTRFS_DEV_REPLACE_DEVID "unsigned long long" as well, so we no longer need
    a cast to print it.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0ef9d866952f..7add85a645a3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -146,7 +146,7 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_EMPTY_SUBVOL_DIR_OBJECTID 2
 
-#define BTRFS_DEV_REPLACE_DEVID 0
+#define BTRFS_DEV_REPLACE_DEVID 0ULL
 
 /*
  * the max metadata block size.  This limit is somewhat artificial,

commit f420ee1e923b931eeef5e2928791e84b1197cab3
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:24 2013 +0200

    Btrfs: add mount option to force UUID tree checking
    
    This should never be needed, but since all functions are there
    to check and rebuild the UUID tree, a mount option is added that
    allows to force this check and rebuild procedure.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8c954766db93..0ef9d866952f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1998,6 +1998,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_CHECK_INTEGRITY	(1 << 20)
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)
 #define BTRFS_MOUNT_PANIC_ON_FATAL_ERROR	(1 << 22)
+#define BTRFS_MOUNT_RESCAN_UUID_TREE	(1 << 23)
 
 #define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
 

commit 70f801754728017ebc909d603c69255dc1e6f06f
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:23 2013 +0200

    Btrfs: check UUID tree during mount if required
    
    If the filesystem was mounted with an old kernel that was not
    aware of the UUID tree, this is detected by looking at the
    uuid_tree_generation field of the superblock (similar to how
    the free space cache is doing it). If a mismatch is detected
    at mount time, a thread is started that does two things:
    1. Iterate through the UUID tree, check each entry, delete those
       entries that are not valid anymore (i.e., the subvol does not
       exist anymore or the value changed).
    2. Iterate through the root tree, for each found subvolume, add
       the UUID tree entries for the subvolume (if they are not
       already there).
    
    This mechanism is also used to handle and repair errors that
    happened during the initial creation and filling of the tree.
    The update of the uuid_tree_generation field (which indicates
    that the state of the UUID tree is up to date) is blocked until
    all create and repair operations are successfully completed.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 02b1cefbc308..8c954766db93 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1658,6 +1658,7 @@ struct btrfs_fs_info {
 	atomic_t mutually_exclusive_operation_running;
 
 	struct semaphore uuid_tree_rescan_sem;
+	unsigned int update_uuid_tree_gen:1;
 };
 
 /*
@@ -3511,6 +3512,9 @@ int btrfs_uuid_tree_add(struct btrfs_trans_handle *trans,
 int btrfs_uuid_tree_rem(struct btrfs_trans_handle *trans,
 			struct btrfs_root *uuid_root, u8 *uuid, u8 type,
 			u64 subid);
+int btrfs_uuid_tree_iterate(struct btrfs_fs_info *fs_info,
+			    int (*check_func)(struct btrfs_fs_info *, u8 *, u8,
+					      u64));
 
 /* dir-item.c */
 int btrfs_check_dir_item_collision(struct btrfs_root *root, u64 dir,

commit 26432799c902b76e87f68f5c88f2146a78ba84af
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:22 2013 +0200

    Btrfs: introduce uuid-tree-gen field
    
    In order to be able to detect the case that a filesystem is mounted
    with an old kernel, add a uuid-tree-gen field like the free space
    cache is doing it. It is part of the super block and written with
    each commit. Old kernels do not know this field and don't update it.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index df2b9c22b4cf..02b1cefbc308 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -482,9 +482,10 @@ struct btrfs_super_block {
 	char label[BTRFS_LABEL_SIZE];
 
 	__le64 cache_generation;
+	__le64 uuid_tree_generation;
 
 	/* future expansion */
-	__le64 reserved[31];
+	__le64 reserved[30];
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 	struct btrfs_root_backup super_roots[BTRFS_NUM_BACKUP_ROOTS];
 } __attribute__ ((__packed__));
@@ -2900,6 +2901,8 @@ BTRFS_SETGET_STACK_FUNCS(super_csum_type, struct btrfs_super_block,
 BTRFS_SETGET_STACK_FUNCS(super_cache_generation, struct btrfs_super_block,
 			 cache_generation, 64);
 BTRFS_SETGET_STACK_FUNCS(super_magic, struct btrfs_super_block, magic, 64);
+BTRFS_SETGET_STACK_FUNCS(super_uuid_tree_generation, struct btrfs_super_block,
+			 uuid_tree_generation, 64);
 
 static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
 {

commit 803b2f54fb4faf6d76fca43e59bcc555d9713cd4
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:21 2013 +0200

    Btrfs: fill UUID tree initially
    
    When the UUID tree is initially created, a task is spawned that
    walks through the root tree. For each found subvolume root_item,
    the uuid and received_uuid entries in the UUID tree are added.
    This is such a quick operation so that in case somebody wants
    to unmount the filesystem while the task is still running, the
    unmount is delayed until the UUID tree building task is finished.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bdc8498d6f03..df2b9c22b4cf 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -23,6 +23,7 @@
 #include <linux/highmem.h>
 #include <linux/fs.h>
 #include <linux/rwsem.h>
+#include <linux/semaphore.h>
 #include <linux/completion.h>
 #include <linux/backing-dev.h>
 #include <linux/wait.h>
@@ -1654,6 +1655,8 @@ struct btrfs_fs_info {
 	struct btrfs_dev_replace dev_replace;
 
 	atomic_t mutually_exclusive_operation_running;
+
+	struct semaphore uuid_tree_rescan_sem;
 };
 
 /*

commit dd5f9615fc5c5e8d3751aab3a17b92768fb1ce70
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:20 2013 +0200

    Btrfs: maintain subvolume items in the UUID tree
    
    When a new subvolume or snapshot is created, a new UUID item is added
    to the UUID tree. Such items are removed when the subvolume is deleted.
    The ioctl to set the received subvolume UUID is also touched and will
    now also add this received UUID into the UUID tree together with the
    ID of the subvolume. The latter is also done when read-only snapshots
    are created which inherit all the send/receive information from the
    parent subvolume.
    
    User mode programs use the BTRFS_IOC_TREE_SEARCH ioctl to search and
    read in the UUID tree.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c03e61ef7230..bdc8498d6f03 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3724,6 +3724,7 @@ extern const struct dentry_operations btrfs_dentry_operations;
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 void btrfs_update_iflags(struct inode *inode);
 void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
+int btrfs_is_empty_uuid(u8 *uuid);
 int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      struct btrfs_ioctl_defrag_range_args *range,
 		      u64 newer_than, unsigned long max_pages);

commit f7a81ea4cc6bdb51d8267d2f3ff485f0b4070074
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:19 2013 +0200

    Btrfs: create UUID tree if required
    
    This tree is not created by mkfs.btrfs. Therefore when a filesystem
    is mounted writable and the UUID tree does not exist, this tree is
    created if required. The tree is also added to the fs_info structure
    and initialized, but this commit does not yet read or write UUID tree
    elements.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 429c54ac1a65..c03e61ef7230 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1306,6 +1306,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *fs_root;
 	struct btrfs_root *csum_root;
 	struct btrfs_root *quota_root;
+	struct btrfs_root *uuid_root;
 
 	/* the log root tree is a directory of all the other log roots */
 	struct btrfs_root *log_root_tree;

commit 07b30a49dac4f60a6c4b0b3938bd6f45affb9455
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:17 2013 +0200

    Btrfs: introduce a tree for items that map UUIDs to something
    
    Mapping UUIDs to subvolume IDs is an operation with a high effort
    today. Today, the algorithm even has quadratic effort (based on the
    number of existing subvolumes), which means, that it takes minutes
    to send/receive a single subvolume if 10,000 subvolumes exist. But
    even linear effort would be too much since it is a waste. And these
    data structures to allow mapping UUIDs to subvolume IDs are created
    every time a btrfs send/receive instance is started.
    
    It is much more efficient to maintain a searchable persistent data
    structure in the filesystem, one that is updated whenever a
    subvolume/snapshot is created and deleted, and when the received
    subvolume UUID is set by the btrfs-receive tool.
    
    Therefore kernel code is added with this commit that is able to
    maintain data structures in the filesystem that allow to quickly
    search for a given UUID and to retrieve data that is assigned to
    this UUID, like which subvolume ID is related to this UUID.
    
    This commit adds a new tree to hold UUID-to-data mapping items. The
    key of the items is the full UUID plus the key type BTRFS_UUID_KEY.
    Multiple data blocks can be stored for a given UUID, a type/length/
    value scheme is used.
    
    Now follows the lengthy justification, why a new tree was added
    instead of using the existing root tree:
    
    The first approach was to not create another tree that holds UUID
    items. Instead, the items should just go into the top root tree.
    Unfortunately this confused the algorithm to assign the objectid
    of subvolumes and snapshots. The reason is that
    btrfs_find_free_objectid() calls btrfs_find_highest_objectid() for
    the first created subvol or snapshot after mounting a filesystem,
    and this function simply searches for the largest used objectid in
    the root tree keys to pick the next objectid to assign. Of course,
    the UUID keys have always been the ones with the highest offset
    value, and the next assigned subvol ID was wastefully huge.
    
    To use any other existing tree did not look proper. To apply a
    workaround such as setting the objectid to zero in the UUID item
    key and to implement collision handling would either add
    limitations (in case of a btrfs_extend_item() approach to handle
    the collisions) or a lot of complexity and source code (in case a
    key would be looked up that is free of collisions). Adding new code
    that introduces limitations is not good, and adding code that is
    complex and lengthy for no good reason is also not good. That's the
    justification why a completely new tree was introduced.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f697d00819b8..429c54ac1a65 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -91,6 +91,9 @@ struct btrfs_ordered_sum;
 /* holds quota configuration and tracking */
 #define BTRFS_QUOTA_TREE_OBJECTID 8ULL
 
+/* for storing items that use the BTRFS_UUID_KEY* types */
+#define BTRFS_UUID_TREE_OBJECTID 9ULL
+
 /* for storing balance parameters in the root tree */
 #define BTRFS_BALANCE_OBJECTID -4ULL
 
@@ -1942,6 +1945,19 @@ struct btrfs_ioctl_defrag_range_args {
  */
 #define BTRFS_DEV_REPLACE_KEY	250
 
+/*
+ * Stores items that allow to quickly map UUIDs to something else.
+ * These items are part of the filesystem UUID tree.
+ * The key is built like this:
+ * (UUID_upper_64_bits, BTRFS_UUID_KEY*, UUID_lower_64_bits).
+ */
+#if BTRFS_UUID_SIZE != 16
+#error "UUID items require BTRFS_UUID_SIZE == 16!"
+#endif
+#define BTRFS_UUID_KEY_SUBVOL	251	/* for UUIDs assigned to subvols */
+#define BTRFS_UUID_KEY_RECEIVED_SUBVOL	252	/* for UUIDs assigned to
+						 * received subvols */
+
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
@@ -3481,6 +3497,14 @@ void btrfs_check_and_init_root_item(struct btrfs_root_item *item);
 void btrfs_update_root_times(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
 
+/* uuid-tree.c */
+int btrfs_uuid_tree_add(struct btrfs_trans_handle *trans,
+			struct btrfs_root *uuid_root, u8 *uuid, u8 type,
+			u64 subid);
+int btrfs_uuid_tree_rem(struct btrfs_trans_handle *trans,
+			struct btrfs_root *uuid_root, u8 *uuid, u8 type,
+			u64 subid);
+
 /* dir-item.c */
 int btrfs_check_dir_item_collision(struct btrfs_root *root, u64 dir,
 			  const char *name, int name_len);

commit 171170c1c5625cab9687ecf6714e09e0c8a6ed3c
Author: Sergei Trofimovich <slyfox@gentoo.org>
Date:   Wed Aug 14 23:27:46 2013 +0300

    btrfs: mark some local function as 'static'
    
    Cc: Josef Bacik <jbacik@fusionio.com>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Signed-off-by: Sergei Trofimovich <slyfox@gentoo.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 56f8c1b1016a..f697d00819b8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3471,8 +3471,6 @@ int __must_check btrfs_update_root(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root,
 				   struct btrfs_key *key,
 				   struct btrfs_root_item *item);
-void btrfs_read_root_item(struct extent_buffer *eb, int slot,
-			  struct btrfs_root_item *item);
 int btrfs_find_root(struct btrfs_root *root, struct btrfs_key *search_key,
 		    struct btrfs_path *path, struct btrfs_root_item *root_item,
 		    struct btrfs_key *root_key);

commit 35a3621beb3e2face3e7954eaee20a8fa0043fac
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Aug 14 18:12:25 2013 +0200

    Btrfs: get rid of sparse warnings
    
    make C=2 fs/btrfs/ CF=-D__CHECK_ENDIAN__
    
    I tried to filter out the warnings for which patches have already
    been sent to the mailing list, pending for inclusion in btrfs-next.
    
    All these changes should be obviously safe.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9766e9f04024..56f8c1b1016a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3706,6 +3706,9 @@ int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      u64 newer_than, unsigned long max_pages);
 void btrfs_get_block_group_info(struct list_head *groups_list,
 				struct btrfs_ioctl_space_info *space);
+void update_ioctl_balance_args(struct btrfs_fs_info *fs_info, int lock,
+			       struct btrfs_ioctl_balance_args *bargs);
+
 
 /* file.c */
 int btrfs_auto_defrag_init(void);

commit ba5e8f2e2d3074bf151dd222dae9bb400e621b82
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Aug 16 16:52:55 2013 -0400

    Btrfs: fix send issues related to inode number reuse
    
    If you are sending a snapshot and specifying a parent snapshot we will walk the
    trees and figure out where they differ and send the differences only.  The way
    we check for differences are if the leaves aren't the same and if the keys are
    not the same within the leaves.  So if neither leaf is the same (ie the leaf has
    been cow'ed from the parent snapshot) we walk each item in the send root and
    check it against the parent root.  If the items match exactly then we don't do
    anything.  This doesn't quite work for inode refs, since they will just have the
    name and the parent objectid.  If you move the file from a directory and then
    remove that directory and re-create a directory with the same inode number as
    the old directory and then move that file back into that directory we will
    assume that nothing changed and you will get errors when you try to receive.
    
    In order to fix this we need to do extra checking to see if the inode ref really
    is the same or not.  So do this by passing down BTRFS_COMPARE_TREE_SAME if the
    items match.  Then if the key type is an inode ref we can do some extra
    checking, otherwise we just keep processing.  The extra checking is to look up
    the generation of the directory in the parent volume and compare it to the
    generation of the send volume.  If they match then they are the same directory
    and we are good to go.  If they don't we have to add them to the changed refs
    list.
    
    This means we have to track the generation of the ref we're trying to lookup
    when we iterate all the refs for a particular inode.  So in the case of looking
    for new refs we have to get the generation from the parent volume, and in the
    case of looking for deleted refs we have to get the generation from the send
    volume to compare with.
    
    There was also the issue of using a ulist to keep track of the directories we
    needed to check.  Because we can get a deleted ref and a new ref for the same
    inode number the ulist won't work since it indexes based on the value.  So
    instead just dup any directory ref we find and add it to a local list, and then
    process that list as normal and do away with using a ulist for this altogether.
    
    Before we would fail all of the tests in the far-progs that related to moving
    directories (test group 32).  With this patch we now pass these tests, and all
    of the tests in the far-progs send testing suite.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7c93d9f13812..9766e9f04024 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3301,6 +3301,7 @@ enum btrfs_compare_tree_result {
 	BTRFS_COMPARE_TREE_NEW,
 	BTRFS_COMPARE_TREE_DELETED,
 	BTRFS_COMPARE_TREE_CHANGED,
+	BTRFS_COMPARE_TREE_SAME,
 };
 typedef int (*btrfs_changed_cb_t)(struct btrfs_root *left_root,
 				  struct btrfs_root *right_root,

commit 00361589d2eebd90fca022148c763e40d3e90871
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 14 14:02:47 2013 -0400

    Btrfs: avoid starting a transaction in the write path
    
    I noticed while looking at a deadlock that we are always starting a transaction
    in cow_file_range().  This isn't really needed since we only need a transaction
    if we are doing an inline extent, or if the allocator needs to allocate a chunk.
    So push down all the transaction start stuff to be closer to where we actually
    need a transaction in all of these cases.  This will hopefully reduce our write
    latency when we are committing often.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 063e48587126..7c93d9f13812 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3165,11 +3165,9 @@ int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root,
 				   u64 root_objectid, u64 owner, u64 offset,
 				   struct btrfs_key *ins);
-int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
-				  struct btrfs_root *root,
-				  u64 num_bytes, u64 min_alloc_size,
-				  u64 empty_size, u64 hint_byte,
-				  struct btrfs_key *ins, int is_data);
+int btrfs_reserve_extent(struct btrfs_root *root, u64 num_bytes,
+			 u64 min_alloc_size, u64 empty_size, u64 hint_byte,
+			 struct btrfs_key *ins, int is_data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf, int full_backref, int for_cow);
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -3612,8 +3610,7 @@ void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
 struct extent_map *btrfs_get_extent_fiemap(struct inode *inode, struct page *page,
 					   size_t pg_offset, u64 start, u64 len,
 					   int create);
-noinline int can_nocow_extent(struct btrfs_trans_handle *trans,
-			      struct inode *inode, u64 offset, u64 *len,
+noinline int can_nocow_extent(struct inode *inode, u64 offset, u64 *len,
 			      u64 *orig_start, u64 *orig_block_len,
 			      u64 *ram_bytes);
 

commit 9ffba8cda917c0158857426f0e74b64d0206aaa9
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 14 11:33:56 2013 -0400

    Btrfs: fix heavy delalloc related deadlock
    
    I added a patch where we started taking the ordered operations mutex when we
    waited on ordered extents.  We need this because we splice the list and process
    it, so if a flusher came in during this scenario it would think the list was
    empty and we'd usually get an early ENOSPC.  The problem with this is that this
    lock is used in transaction committing.  So we end up with something like this
    
    Transaction commit
            -> wait on writers
    
    Delalloc flusher
            -> run_ordered_operations (holds mutex)
                    ->wait for filemap-flush to do its thing
    
    flush task
            -> cow_file_range
                    ->wait on btrfs_join_transaction because we're commiting
    
    some other task
            -> commit_transaction because we notice trans->transaction->flush is set
                    -> run_ordered_operations (hang on mutex)
    
    We need to disentangle the ordered operations flushing from the delalloc
    flushing, since they are separate things.  This solves the deadlock issue I was
    seeing.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0632832d4446..063e48587126 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1413,6 +1413,13 @@ struct btrfs_fs_info {
 	 * before jumping into the main commit.
 	 */
 	struct mutex ordered_operations_mutex;
+
+	/*
+	 * Same as ordered_operations_mutex except this is for ordered extents
+	 * and not the operations.
+	 */
+	struct mutex ordered_extent_flush_mutex;
+
 	struct rw_semaphore extent_commit_sem;
 
 	struct rw_semaphore cleanup_work_sem;

commit 8b87dc17fbc7443bf4c6c096279c35e89fb51326
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Aug 1 18:14:52 2013 +0200

    btrfs: add mount option to set commit interval
    
    I'ts hardcoded to 30 seconds which is fine for most users. Higher values
    defer data being synced to permanent storage with obvious consequences
    when the system crashes. The upper bound is not forced, but a warning is
    printed if it's more than 300 seconds (5 minutes).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c17acbce5bc3..0632832d4446 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1351,6 +1351,7 @@ struct btrfs_fs_info {
 	u64 last_trans_log_full_commit;
 	unsigned long mount_opt;
 	unsigned long compress_type:4;
+	int commit_interval;
 	/*
 	 * It is a suggestive number, the read side is safe even it gets a
 	 * wrong number because we will write out the data into a regular
@@ -1969,6 +1970,8 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)
 #define BTRFS_MOUNT_PANIC_ON_FATAL_ERROR	(1 << 22)
 
+#define BTRFS_DEFAULT_COMMIT_INTERVAL	(30)
+
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
 #define btrfs_raw_test_opt(o, opt)	((o) & BTRFS_MOUNT_##opt)

commit 36cce922875563a1e2a4b6a53fbe1147f652a51e
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Aug 5 11:15:21 2013 -0400

    Btrfs: handle errors when doing slow caching
    
    Alex Lyakas reported a bug where wait_block_group_cache_progress() would wait
    forever if a drive failed.  This is because we just bail out if there is an
    error while trying to cache a block group, we don't update anybody who may be
    waiting.  So this introduces a new enum for the cache state in case of error and
    makes everybody bail out if we have an error.  Alex tested and verified this
    patch fixed his problem.  This fixes bz 59431.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cbb1263752f8..c17acbce5bc3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1188,6 +1188,7 @@ enum btrfs_caching_type {
 	BTRFS_CACHE_STARTED	= 1,
 	BTRFS_CACHE_FAST	= 2,
 	BTRFS_CACHE_FINISHED	= 3,
+	BTRFS_CACHE_ERROR	= 4,
 };
 
 enum btrfs_disk_cache_state {

commit facc8a2247340a9735fe8cc123c5da2102f5ef1b
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jul 25 19:22:34 2013 +0800

    Btrfs: don't cache the csum value into the extent state tree
    
    Before applying this patch, we cached the csum value into the extent state
    tree when reading some data from the disk, this operation increased the lock
    contention of the state tree.
    
    Now, we just store the csum value into the bio structure or other unshared
    structure, so we can reduce the lock contention.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dda60e9f6b89..cbb1263752f8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3556,12 +3556,14 @@ int btrfs_find_name_in_ext_backref(struct btrfs_path *path,
 				   struct btrfs_inode_extref **extref_ret);
 
 /* file-item.c */
+struct btrfs_dio_private;
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, u64 bytenr, u64 len);
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio, u32 *dst);
 int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct bio *bio, u64 logical_offset);
+			      struct btrfs_dio_private *dip, struct bio *bio,
+			      u64 logical_offset);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,

commit 3cae210fa529d69cb25c2a3c491f29dab687b245
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jul 16 11:19:18 2013 +0800

    btrfs: Cleanup for using BTRFS_SETGET_STACK instead of raw convert
    
    Some codes still use the cpu_to_lexx instead of the
    BTRFS_SETGET_STACK_FUNCS declared in ctree.h.
    
    Also added some BTRFS_SETGET_STACK_FUNCS for btrfs_header btrfs_timespec
    and other structures.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Miao Xie <miaoxie@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8cc03321a368..dda60e9f6b89 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2240,6 +2240,23 @@ BTRFS_SETGET_FUNCS(inode_gid, struct btrfs_inode_item, gid, 32);
 BTRFS_SETGET_FUNCS(inode_mode, struct btrfs_inode_item, mode, 32);
 BTRFS_SETGET_FUNCS(inode_rdev, struct btrfs_inode_item, rdev, 64);
 BTRFS_SETGET_FUNCS(inode_flags, struct btrfs_inode_item, flags, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_generation, struct btrfs_inode_item,
+			 generation, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_sequence, struct btrfs_inode_item,
+			 sequence, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_transid, struct btrfs_inode_item,
+			 transid, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_size, struct btrfs_inode_item, size, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_nbytes, struct btrfs_inode_item,
+			 nbytes, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_block_group, struct btrfs_inode_item,
+			 block_group, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_nlink, struct btrfs_inode_item, nlink, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_uid, struct btrfs_inode_item, uid, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_gid, struct btrfs_inode_item, gid, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_mode, struct btrfs_inode_item, mode, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_rdev, struct btrfs_inode_item, rdev, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_inode_flags, struct btrfs_inode_item, flags, 64);
 
 static inline struct btrfs_timespec *
 btrfs_inode_atime(struct btrfs_inode_item *inode_item)
@@ -2267,6 +2284,8 @@ btrfs_inode_ctime(struct btrfs_inode_item *inode_item)
 
 BTRFS_SETGET_FUNCS(timespec_sec, struct btrfs_timespec, sec, 64);
 BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_timespec, nsec, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_timespec_sec, struct btrfs_timespec, sec, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_timespec_nsec, struct btrfs_timespec, nsec, 32);
 
 /* struct btrfs_dev_extent */
 BTRFS_SETGET_FUNCS(dev_extent_chunk_tree, struct btrfs_dev_extent,
@@ -2348,6 +2367,10 @@ BTRFS_SETGET_FUNCS(ref_count_v0, struct btrfs_extent_ref_v0, count, 32);
 /* struct btrfs_node */
 BTRFS_SETGET_FUNCS(key_blockptr, struct btrfs_key_ptr, blockptr, 64);
 BTRFS_SETGET_FUNCS(key_generation, struct btrfs_key_ptr, generation, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_key_blockptr, struct btrfs_key_ptr,
+			 blockptr, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_key_generation, struct btrfs_key_ptr,
+			 generation, 64);
 
 static inline u64 btrfs_node_blockptr(struct extent_buffer *eb, int nr)
 {
@@ -2404,6 +2427,8 @@ static inline void btrfs_set_node_key(struct extent_buffer *eb,
 /* struct btrfs_item */
 BTRFS_SETGET_FUNCS(item_offset, struct btrfs_item, offset, 32);
 BTRFS_SETGET_FUNCS(item_size, struct btrfs_item, size, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_item_offset, struct btrfs_item, offset, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_item_size, struct btrfs_item, size, 32);
 
 static inline unsigned long btrfs_item_nr_offset(int nr)
 {
@@ -2466,6 +2491,13 @@ BTRFS_SETGET_FUNCS(dir_data_len, struct btrfs_dir_item, data_len, 16);
 BTRFS_SETGET_FUNCS(dir_type, struct btrfs_dir_item, type, 8);
 BTRFS_SETGET_FUNCS(dir_name_len, struct btrfs_dir_item, name_len, 16);
 BTRFS_SETGET_FUNCS(dir_transid, struct btrfs_dir_item, transid, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dir_type, struct btrfs_dir_item, type, 8);
+BTRFS_SETGET_STACK_FUNCS(stack_dir_data_len, struct btrfs_dir_item,
+			 data_len, 16);
+BTRFS_SETGET_STACK_FUNCS(stack_dir_name_len, struct btrfs_dir_item,
+			 name_len, 16);
+BTRFS_SETGET_STACK_FUNCS(stack_dir_transid, struct btrfs_dir_item,
+			 transid, 64);
 
 static inline void btrfs_dir_item_key(struct extent_buffer *eb,
 				      struct btrfs_dir_item *item,
@@ -2568,6 +2600,12 @@ BTRFS_SETGET_HEADER_FUNCS(header_owner, struct btrfs_header, owner, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_nritems, struct btrfs_header, nritems, 32);
 BTRFS_SETGET_HEADER_FUNCS(header_flags, struct btrfs_header, flags, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_level, struct btrfs_header, level, 8);
+BTRFS_SETGET_STACK_FUNCS(stack_header_generation, struct btrfs_header,
+			 generation, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_header_owner, struct btrfs_header, owner, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_header_nritems, struct btrfs_header,
+			 nritems, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_header_bytenr, struct btrfs_header, bytenr, 64);
 
 static inline int btrfs_header_flag(struct extent_buffer *eb, u64 flag)
 {
@@ -2830,6 +2868,7 @@ BTRFS_SETGET_STACK_FUNCS(super_csum_type, struct btrfs_super_block,
 			 csum_type, 16);
 BTRFS_SETGET_STACK_FUNCS(super_cache_generation, struct btrfs_super_block,
 			 cache_generation, 64);
+BTRFS_SETGET_STACK_FUNCS(super_magic, struct btrfs_super_block, magic, 64);
 
 static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
 {
@@ -2847,6 +2886,14 @@ static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 
 /* struct btrfs_file_extent_item */
 BTRFS_SETGET_FUNCS(file_extent_type, struct btrfs_file_extent_item, type, 8);
+BTRFS_SETGET_STACK_FUNCS(stack_file_extent_disk_bytenr,
+			 struct btrfs_file_extent_item, disk_bytenr, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_file_extent_offset,
+			 struct btrfs_file_extent_item, offset, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_file_extent_generation,
+			 struct btrfs_file_extent_item, generation, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_file_extent_num_bytes,
+			 struct btrfs_file_extent_item, num_bytes, 64);
 
 static inline unsigned long
 btrfs_file_extent_inline_start(struct btrfs_file_extent_item *e)

commit ee3441b49092000402748f5345ee0a3d4c8ac04e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jul 9 16:37:21 2013 -0400

    btrfs: fall back to global reservation when removing subvolumes
    
    I recently did some ENOSPC testing that involved filling the disk
    while create and removing snapshots in a loop. During the test cycle,
    I ran into an ENOSPC when trying to remove a snapshot, leaving the fs
    stuck in ENOSPC even after a umount/mount cycle.
    
    This patch allow subvolume removal to fall back onto the global
    block reservation in order to succeed when it would have failed
    otherwise.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e795bf135e80..8cc03321a368 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3175,7 +3175,7 @@ void btrfs_orphan_release_metadata(struct inode *inode);
 int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
 				     struct btrfs_block_rsv *rsv,
 				     int nitems,
-				     u64 *qgroup_reserved);
+				     u64 *qgroup_reserved, bool use_global_rsv);
 void btrfs_subvolume_release_metadata(struct btrfs_root *root,
 				      struct btrfs_block_rsv *rsv,
 				      u64 qgroup_reserved);

commit 7ee9e4405f264e9eda808aa5ca4522746a1af9c1
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Jun 21 16:37:03 2013 -0400

    Btrfs: check if we can nocow if we don't have data space
    
    We always just try and reserve data space when we write, but if we are out of
    space but have prealloc'ed extents we should still successfully write.  This
    patch will try and see if we can write to prealloc'ed space and if we can go
    ahead and allow the write to continue.  With this patch we now pass xfstests
    generic/274.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b528a5509cb8..e795bf135e80 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3552,6 +3552,10 @@ void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
 struct extent_map *btrfs_get_extent_fiemap(struct inode *inode, struct page *page,
 					   size_t pg_offset, u64 start, u64 len,
 					   int create);
+noinline int can_nocow_extent(struct btrfs_trans_handle *trans,
+			      struct inode *inode, u64 offset, u64 *len,
+			      u64 *orig_start, u64 *orig_block_len,
+			      u64 *ram_bytes);
 
 /* RHEL and EL kernels have a patch that renames PG_checked to FsMisc */
 #if defined(ClearPageFsMisc) && !defined(ClearPageChecked)

commit b150a4f10d8786a204db1ae3dccada17f950cf54
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Jun 19 15:00:04 2013 -0400

    Btrfs: use a percpu to keep track of possibly pinned bytes
    
    There are all of these checks in the ENOSPC code to see if committing the
    transaction would free up enough space to make the allocation.  This is because
    early on we just committed the transaction and hoped and prayed, which resulted
    in cases where it took _forever_ to get an ENOSPC when we really were out of
    space.  So we check space_info->bytes_pinned, except this isn't completely true
    because it doesn't account for space we may free but are stuck in delayed refs.
    So tests like xfstests 226 would fail because we wouldn't commit the transaction
    to free up the data space.  So instead add a percpu counter that will be a
    little fuzzier, it will add bytes as soon as we try to free up the space, and
    remove any space it doesn't actually free up when we get around to doing the
    actual free.  We then 0 out this counter every transaction period so we have a
    better idea of how much space we will actually free up by committing this
    transaction.  With this patch we now pass xfstests 226.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 76e4983b39ea..b528a5509cb8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1101,6 +1101,18 @@ struct btrfs_space_info {
 	u64 disk_total;		/* total bytes on disk, takes mirrors into
 				   account */
 
+	/*
+	 * bytes_pinned is kept in line with what is actually pinned, as in
+	 * we've called update_block_group and dropped the bytes_used counter
+	 * and increased the bytes_pinned counter.  However this means that
+	 * bytes_pinned does not reflect the bytes that will be pinned once the
+	 * delayed refs are flushed, so this counter is inc'ed everytime we call
+	 * btrfs_free_extent so it is a realtime count of what will be freed
+	 * once the transaction is committed.  It will be zero'ed everytime the
+	 * transaction commits.
+	 */
+	struct percpu_counter total_bytes_pinned;
+
 	/*
 	 * we bump reservation progress every time we decrement
 	 * bytes_reserved.  This way people waiting for reservations

commit 1be41b78bc688fc634bf30965d2be692c99fd11d
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Jun 12 13:56:06 2013 -0400

    Btrfs: fix transaction throttling for delayed refs
    
    Dave has this fs_mark script that can make btrfs abort with sufficient amount of
    ram.  This is because with more ram we can keep more dirty metadata in cache
    which in a round about way makes for many more pending delayed refs.  What
    happens is we end up not throttling the transaction enough so when we go to
    commit the transaction when we've completely filled the file system we'll
    abort() because we use all of the space in the global reserve and we still have
    delayed refs to run.  To fix this we need to make the delayed ref flushing and
    the transaction throttling dependant upon the number of delayed refs that we
    have instead of how much reserved space is left in the global reserve.  With
    this patch we not only stop aborting transactions but we also get a smoother run
    speed with fs_mark and it makes us about 10% faster.  Thanks,
    
    Reported-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0049fe0f3f74..76e4983b39ea 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3056,6 +3056,8 @@ static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_root *root,
 		num_items;
 }
 
+int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,
+				       struct btrfs_root *root);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);

commit 8c2a1a3028d560cfb95f1c583e872c65ed2f0b3d
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Jun 6 13:19:32 2013 -0400

    Btrfs: exclude logged extents before replying when we are mixed
    
    With non-mixed block groups we replay the logs before we're allowed to do any
    writes, so we get away with not pinning/removing the data extents until right
    when we replay them.  However with mixed block groups we allocate out of the
    same pool, so we could easily allocate a metadata block that was logged in our
    tree log.  To deal with this we just need to notice that we have mixed block
    groups and do the normal excluding/removal dance during the pin stage of the log
    replay and that way we don't allocate metadata blocks from areas we have logged
    data extents.  With this patch we now pass xfstests generic/311 with mixed
    block groups turned on.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 80ab1a6f4fe3..0049fe0f3f74 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3067,6 +3067,8 @@ int btrfs_pin_extent(struct btrfs_root *root,
 		     u64 bytenr, u64 num, int reserved);
 int btrfs_pin_extent_for_log_replay(struct btrfs_root *root,
 				    u64 bytenr, u64 num_bytes);
+int btrfs_exclude_logged_extents(struct btrfs_root *root,
+				 struct extent_buffer *eb);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset, u64 bytenr);

commit b382a324b60f4923e9fc8e11f023e4f493c51318
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Tue May 28 15:47:24 2013 +0000

    Btrfs: fix qgroup rescan resume on mount
    
    When called during mount, we cannot start the rescan worker thread until
    open_ctree is done. This commit restuctures the qgroup rescan internals to
    enable a clean deferral of the rescan resume operation.
    
    First of all, the struct qgroup_rescan is removed, saving us a malloc and
    some initialization synchronizations problems. Its only element (the worker
    struct) now lives within fs_info just as the rest of the rescan code.
    
    Then setting up a rescan worker is split into several reusable stages.
    Currently we have three different rescan startup scenarios:
            (A) rescan ioctl
            (B) rescan resume by mount
            (C) rescan by quota enable
    
    Each case needs its own combination of the four following steps:
            (1) set the progress [A, C: zero; B: state of umount]
            (2) commit the transaction [A]
            (3) set the counters [A, C: zero; B: state of umount]
            (4) start worker [A, B, C]
    
    qgroup_rescan_init does step (1). There's no extra function added to commit
    a transaction, we've got that already. qgroup_rescan_zero_tracking does
    step (3). Step (4) is nothing more than a call to the generic
    btrfs_queue_worker.
    
    We also get rid of a double check for the rescan progress during
    btrfs_qgroup_account_ref, which is no longer required due to having step 2
    from the list above.
    
    As a side effect, this commit prepares to move the rescan start code from
    btrfs_run_qgroups (which is run during commit) to a less time critical
    section.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a07b8c0a260d..80ab1a6f4fe3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1609,6 +1609,7 @@ struct btrfs_fs_info {
 	struct btrfs_key qgroup_rescan_progress;
 	struct btrfs_workers qgroup_rescan_workers;
 	struct completion qgroup_rescan_completion;
+	struct btrfs_work qgroup_rescan_work;
 
 	/* filesystem state */
 	unsigned long fs_state;
@@ -3858,6 +3859,7 @@ int btrfs_quota_enable(struct btrfs_trans_handle *trans,
 int btrfs_quota_disable(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
+void btrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info);
 int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);

commit d52be818e618bd252601b340ca6df760d77410e8
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed May 29 14:54:47 2013 -0400

    Btrfs: simplify unlink reservations
    
    Dave pointed out a problem where if you filled up a file system as much as
    possible you couldn't remove any files.  The whole unlink reservation thing is
    convoluted because it tries to guess if it's going to add space to unlink
    something or not, and has all these odd uncommented cases where it simply does
    not try.  So to fix this I've added a way to conditionally steal from the global
    reserve if we can't make our normal reservation.  If we have more than half the
    space in the global reserve free we will go ahead and steal from the global
    reserve.  With this patch Dave's reproducer now works and I can rm all the files
    on the file system.  Thanks,
    
    Reported-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fd62aa856d1b..a07b8c0a260d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1495,7 +1495,6 @@ struct btrfs_fs_info {
 	int do_barriers;
 	int closing;
 	int log_root_recovering;
-	int enospc_unlink;
 
 	u64 total_pinned;
 
@@ -3183,6 +3182,9 @@ int btrfs_block_rsv_refill(struct btrfs_root *root,
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 			    struct btrfs_block_rsv *dst_rsv,
 			    u64 num_bytes);
+int btrfs_cond_migrate_bytes(struct btrfs_fs_info *fs_info,
+			     struct btrfs_block_rsv *dest, u64 num_bytes,
+			     int min_factor);
 void btrfs_block_rsv_release(struct btrfs_root *root,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);

commit 4a9d8bdee368de78ace8b36da4eb2186afea162d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri May 17 03:53:43 2013 +0000

    Btrfs: make the state of the transaction more readable
    
    We used 3 variants to track the state of the transaction, it was complex
    and wasted the memory space. Besides that, it was hard to understand that
    which types of the transaction handles should be blocked in each transaction
    state, so the developers often made mistakes.
    
    This patch improved the above problem. In this patch, we define 6 states
    for the transaction,
      enum btrfs_trans_state {
            TRANS_STATE_RUNNING             = 0,
            TRANS_STATE_BLOCKED             = 1,
            TRANS_STATE_COMMIT_START        = 2,
            TRANS_STATE_COMMIT_DOING        = 3,
            TRANS_STATE_UNBLOCKED           = 4,
            TRANS_STATE_COMPLETED           = 5,
            TRANS_STATE_MAX                 = 6,
      }
    and just use 1 variant to track those state.
    
    In order to make the blocked handle types for each state more clear,
    we introduce a array:
      unsigned int btrfs_blocked_trans_types[TRANS_STATE_MAX] = {
            [TRANS_STATE_RUNNING]           = 0U,
            [TRANS_STATE_BLOCKED]           = (__TRANS_USERSPACE |
                                               __TRANS_START),
            [TRANS_STATE_COMMIT_START]      = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH),
            [TRANS_STATE_COMMIT_DOING]      = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN),
            [TRANS_STATE_UNBLOCKED]         = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN |
                                               __TRANS_JOIN_NOLOCK),
            [TRANS_STATE_COMPLETED]         = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN |
                                               __TRANS_JOIN_NOLOCK),
      }
    it is very intuitionistic.
    
    Besides that, because we remove ->in_commit in transaction structure, so
    the lock ->commit_lock which was used to protect it is unnecessary, remove
    ->commit_lock.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 905f7c6c82f3..fd62aa856d1b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1496,7 +1496,6 @@ struct btrfs_fs_info {
 	int closing;
 	int log_root_recovering;
 	int enospc_unlink;
-	int trans_no_join;
 
 	u64 total_pinned;
 

commit 199c2a9c3d1389db7f7a211e64f6809d352ce5f6
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:23 2013 +0000

    Btrfs: introduce per-subvolume ordered extent list
    
    The reason we introduce per-subvolume ordered extent list is the same
    as the per-subvolume delalloc inode list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 43c073533940..905f7c6c82f3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1437,17 +1437,18 @@ struct btrfs_fs_info {
 	atomic_t open_ioctl_trans;
 
 	/*
-	 * this is used by the balancing code to wait for all the pending
-	 * ordered extents
+	 * this is used to protect the following list -- ordered_roots.
 	 */
-	spinlock_t ordered_extent_lock;
+	spinlock_t ordered_root_lock;
 
 	/*
-	 * all of the data=ordered extents pending writeback
+	 * all fs/file tree roots in which there are data=ordered extents
+	 * pending writeback are added into this list.
+	 *
 	 * these can span multiple transactions and basically include
 	 * every dirty data page that isn't from nodatacow
 	 */
-	struct list_head ordered_extents;
+	struct list_head ordered_roots;
 
 	spinlock_t delalloc_root_lock;
 	/* all fs/file tree roots that have delalloc inodes. */
@@ -1753,6 +1754,20 @@ struct btrfs_root {
 	struct list_head delalloc_inodes;
 	struct list_head delalloc_root;
 	u64 nr_delalloc_inodes;
+	/*
+	 * this is used by the balancing code to wait for all the pending
+	 * ordered extents
+	 */
+	spinlock_t ordered_extent_lock;
+
+	/*
+	 * all of the data=ordered extents pending writeback
+	 * these can span multiple transactions and basically include
+	 * every dirty data page that isn't from nodatacow
+	 */
+	struct list_head ordered_extents;
+	struct list_head ordered_root;
+	u64 nr_ordered_extents;
 };
 
 struct btrfs_ioctl_defrag_range_args {

commit eb73c1b7cea7d533288ef5297a0ea0e159db85b0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:22 2013 +0000

    Btrfs: introduce per-subvolume delalloc inode list
    
    When we create a snapshot, we need flush all delalloc inodes in the
    fs, just flushing the inodes in the source tree is OK. So we introduce
    per-subvolume delalloc inode list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 91a8ca7af77e..43c073533940 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1449,13 +1449,9 @@ struct btrfs_fs_info {
 	 */
 	struct list_head ordered_extents;
 
-	spinlock_t delalloc_lock;
-	/*
-	 * all of the inodes that have delalloc bytes.  It is possible for
-	 * this list to be empty even when there is still dirty data=ordered
-	 * extents waiting to finish IO.
-	 */
-	struct list_head delalloc_inodes;
+	spinlock_t delalloc_root_lock;
+	/* all fs/file tree roots that have delalloc inodes. */
+	struct list_head delalloc_roots;
 
 	/*
 	 * there is a pool of worker threads for checksumming during writes
@@ -1747,6 +1743,16 @@ struct btrfs_root {
 
 	spinlock_t root_item_lock;
 	atomic_t refs;
+
+	spinlock_t delalloc_lock;
+	/*
+	 * all of the inodes that have delalloc bytes.  It is possible for
+	 * this list to be empty even when there is still dirty data=ordered
+	 * extents waiting to finish IO.
+	 */
+	struct list_head delalloc_inodes;
+	struct list_head delalloc_root;
+	u64 nr_delalloc_inodes;
 };
 
 struct btrfs_ioctl_defrag_range_args {
@@ -3550,6 +3556,8 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
+int btrfs_start_all_delalloc_inodes(struct btrfs_fs_info *fs_info,
+				    int delay_iput);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,

commit b0feb9d96e71a88d7eec56f41b8f23e92af889b0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:20 2013 +0000

    Btrfs: introduce grab/put functions for the root of the fs/file tree
    
    The grab/put funtions will be used in the next patch, which need grab
    the root object and ensure it is not freed. We use reference counter
    instead of the srcu lock is to aovid blocking the memory reclaim task,
    which invokes synchronize_srcu().
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a84e59b7b006..91a8ca7af77e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1746,6 +1746,7 @@ struct btrfs_root {
 	int force_cow;
 
 	spinlock_t root_item_lock;
+	atomic_t refs;
 };
 
 struct btrfs_ioctl_defrag_range_args {

commit cb517eabba4f109810dba2e5f37b0dcf22103065
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:19 2013 +0000

    Btrfs: cleanup the similar code of the fs root read
    
    There are several functions whose code is similar, such as
      btrfs_find_last_root()
      btrfs_read_fs_root_no_radix()
    
    Besides that, some functions are invoked twice, it is unnecessary,
    for example, we are sure that all roots which is found in
      btrfs_find_orphan_roots()
    have their orphan items, so it is unnecessary to check the orphan
    item again.
    
    So cleanup it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d9ff585aadba..a84e59b7b006 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3376,9 +3376,9 @@ int __must_check btrfs_update_root(struct btrfs_trans_handle *trans,
 				   struct btrfs_root_item *item);
 void btrfs_read_root_item(struct extent_buffer *eb, int slot,
 			  struct btrfs_root_item *item);
-int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
-			 btrfs_root_item *item, struct btrfs_key *key);
-int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);
+int btrfs_find_root(struct btrfs_root *root, struct btrfs_key *search_key,
+		    struct btrfs_path *path, struct btrfs_root_item *root_item,
+		    struct btrfs_key *root_key);
 int btrfs_find_orphan_roots(struct btrfs_root *tree_root);
 void btrfs_set_root_node(struct btrfs_root_item *item,
 			 struct extent_buffer *node);

commit babbf170c781f24095336c82ebf18ad272ddb773
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue May 14 10:20:43 2013 +0000

    Btrfs: make the snap/subv deletion end more early when the fs is R/O
    
    The snapshot/subvolume deletion might spend lots of time, it would make
    the remount task wait for a long time. This patch improve this problem,
    we will break the deletion if the fs is remounted to be R/O. It will make
    the users happy.
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d354de31b81b..d9ff585aadba 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3318,6 +3318,18 @@ static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
 	smp_mb();
 	return fs_info->closing;
 }
+
+/*
+ * If we remount the fs to be R/O or umount the fs, the cleaner needn't do
+ * anything except sleeping. This function is used to check the status of
+ * the fs.
+ */
+static inline int btrfs_need_cleaner_sleep(struct btrfs_root *root)
+{
+	return (root->fs_info->sb->s_flags & MS_RDONLY ||
+		btrfs_fs_closing(root->fs_info));
+}
+
 static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 {
 	kfree(fs_info->balance_ctl);

commit 1c89cdd1ce1b8b9ff7bca64bc9beea2c917e5693
Author: Andreas Philipp <philipp.andreas@gmail.com>
Date:   Sat May 11 11:12:54 2013 +0000

    Minor format cleanup.
    
    Clean up the format of the definitions of BTRFS_BLOCK_GROUP_RAID5 and
    BTRFS_BLOCK_GROUP_RAID6.
    
    Signed-off-by: Andreas Philipp <philipp.andreas@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e36e97b473a8..d354de31b81b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -961,8 +961,8 @@ struct btrfs_dev_replace_item {
 #define BTRFS_BLOCK_GROUP_RAID1		(1ULL << 4)
 #define BTRFS_BLOCK_GROUP_DUP		(1ULL << 5)
 #define BTRFS_BLOCK_GROUP_RAID10	(1ULL << 6)
-#define BTRFS_BLOCK_GROUP_RAID5    (1 << 7)
-#define BTRFS_BLOCK_GROUP_RAID6    (1 << 8)
+#define BTRFS_BLOCK_GROUP_RAID5         (1ULL << 7)
+#define BTRFS_BLOCK_GROUP_RAID6         (1ULL << 8)
 #define BTRFS_BLOCK_GROUP_RESERVED	BTRFS_AVAIL_ALLOC_BIT_SINGLE
 
 enum btrfs_raid_types {

commit 57254b6ebce4ceca02d9c8b615f6059c56c19238
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon May 6 19:14:17 2013 +0000

    Btrfs: add ioctl to wait for qgroup rescan completion
    
    btrfs_qgroup_wait_for_completion waits until the currently running qgroup
    operation completes. It returns immediately when no rescan process is in
    progress. This is useful to automate things around the rescan process (e.g.
    testing).
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a365400e38da..e36e97b473a8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1613,6 +1613,7 @@ struct btrfs_fs_info {
 	struct mutex qgroup_rescan_lock; /* protects the progress item */
 	struct btrfs_key qgroup_rescan_progress;
 	struct btrfs_workers qgroup_rescan_workers;
+	struct completion qgroup_rescan_completion;
 
 	/* filesystem state */
 	unsigned long fs_state;
@@ -3820,6 +3821,7 @@ int btrfs_quota_enable(struct btrfs_trans_handle *trans,
 int btrfs_quota_disable(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info);
 int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
 int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,

commit 1e8f915868c59be4d6e49d9aff928454a5d5d569
Author: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
Date:   Mon May 6 11:03:27 2013 +0000

    Btrfs: introduce qgroup_ulist to avoid frequently allocating/freeing ulist
    
    When doing qgroup accounting, we call ulist_alloc()/ulist_free() every time
    when we want to walk qgroup tree.
    
    By introducing 'qgroup_ulist', we only need to call ulist_alloc()/ulist_free()
    once. This reduce some sys time to allocate memory, see the measurements below
    
    fsstress -p 4 -n 10000 -d $dir
    
    With this patch:
    
    real    0m50.153s
    user    0m0.081s
    sys     0m6.294s
    
    real    0m51.113s
    user    0m0.092s
    sys     0m6.220s
    
    real    0m52.610s
    user    0m0.096s
    sys     0m6.125s        avg 6.213
    -----------------------------------------------------
    Without the patch:
    
    real    0m54.825s
    user    0m0.061s
    sys     0m10.665s
    
    real    1m6.401s
    user    0m0.089s
    sys     0m11.218s
    
    real    1m13.768s
    user    0m0.087s
    sys     0m10.665s       avg 10.849
    
    we can see the sys time reduce ~43%.
    
    Signed-off-by: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d6dd49b51ba8..a365400e38da 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1594,6 +1594,12 @@ struct btrfs_fs_info {
 	struct rb_root qgroup_tree;
 	spinlock_t qgroup_lock;
 
+	/*
+	 * used to avoid frequently calling ulist_alloc()/ulist_free()
+	 * when doing qgroup accounting, it must be protected by qgroup_lock.
+	 */
+	struct ulist *qgroup_ulist;
+
 	/* protect user change for quota operations */
 	struct mutex qgroup_ioctl_lock;
 

commit b1c79e0947e0c190f865e2eb7b84a0fea0021cec
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu May 9 13:49:30 2013 -0400

    Btrfs: handle running extent ops with skinny metadata
    
    Chris hit a bug where we weren't finding extent records when running extent ops.
    This is because we use the delayed_ref_head when running the extent op, which
    means we can't use the ->type checks to see if we are metadata.  We also lose
    the level of the metadata we are working on.  So to fix this we can just check
    the ->is_data section of the extent_op, and we can store the level of the buffer
    we were modifying in the extent_op.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2720d5555883..d6dd49b51ba8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3075,7 +3075,7 @@ int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 bytenr, u64 num_bytes, u64 flags,
-				int is_data);
+				int level, int is_data);
 int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,

commit 60b62978bc5e903cd487de34972fb30f76c74a2e
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 30 17:29:29 2013 +0000

    btrfs: annotate quota tree for lockdep
    
    Quota tree has been missing from lockdep annotations, though no warning
    has been seen in the wild.
    
    There's currently one entry that does not belong there,
    BTRFS_ORPHAN_OBJECTID.  No such tree exists, it's probably a copy &
    paste mistake, the id is defined among tree ids.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 63c328a9ce95..2720d5555883 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -88,12 +88,12 @@ struct btrfs_ordered_sum;
 /* holds checksums of all the data extents */
 #define BTRFS_CSUM_TREE_OBJECTID 7ULL
 
-/* for storing balance parameters in the root tree */
-#define BTRFS_BALANCE_OBJECTID -4ULL
-
 /* holds quota configuration and tracking */
 #define BTRFS_QUOTA_TREE_OBJECTID 8ULL
 
+/* for storing balance parameters in the root tree */
+#define BTRFS_BALANCE_OBJECTID -4ULL
+
 /* orhpan objectid for tracking unlinked/truncated files */
 #define BTRFS_ORPHAN_OBJECTID -5ULL
 

commit 1104a8855109a4051d74977f819a13b4516aa11e
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Mar 6 15:57:46 2013 +0100

    btrfs: enhance superblock checks
    
    The superblock checksum is not verified upon mount. <awkward silence>
    
    Add that check and also reorder existing checks to a more logical
    order.
    
    Current mkfs.btrfs does not calculate the correct checksum of
    super_block and thus a freshly created filesytem will fail to mount when
    this patch is applied.
    
    First transaction commit calculates correct superblock checksum and
    saves it to disk.
    
    Reproducer:
    $ mfks.btrfs /dev/sda
    $ mount /dev/sda /mnt
    $ btrfs scrub start /mnt
    $ sleep 5
    $ btrfs scrub status /mnt
    ... super:2 ...
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 78b9d457d723..63c328a9ce95 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2793,8 +2793,10 @@ BTRFS_SETGET_STACK_FUNCS(super_cache_generation, struct btrfs_super_block,
 
 static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
 {
-	int t = btrfs_super_csum_type(s);
-	BUG_ON(t >= ARRAY_SIZE(btrfs_csum_sizes));
+	u16 t = btrfs_super_csum_type(s);
+	/*
+	 * csum type is validated at mount time
+	 */
 	return btrfs_csum_sizes[t];
 }
 

commit b6919a58f09db5daaa29b0326d53513ee418b84b
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Apr 29 13:39:40 2013 +0000

    btrfs: fix misleading variable name for flags
    
    The variable was named 'data' in btrfs_reserve_extent and that's the
    only function that actually uses it to let btrfs_get_alloc_profile know
    what profile we want. Then it's passed down as u64 flags.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4272fbb08732..78b9d457d723 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3065,7 +3065,7 @@ int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  struct btrfs_root *root,
 				  u64 num_bytes, u64 min_alloc_size,
 				  u64 empty_size, u64 hint_byte,
-				  struct btrfs_key *ins, u64 data);
+				  struct btrfs_key *ins, int is_data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf, int full_backref, int for_cow);
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,

commit 48a3b6366f6913683563d934eb16fea67dead9c1
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Apr 25 20:41:01 2013 +0000

    btrfs: make static code static & remove dead code
    
    Big patch, but all it does is add statics to functions which
    are in fact static, then remove the associated dead-code fallout.
    
    removed functions:
    
    btrfs_iref_to_path()
    __btrfs_lookup_delayed_deletion_item()
    __btrfs_search_delayed_insertion_item()
    __btrfs_search_delayed_deletion_item()
    find_eb_for_page()
    btrfs_find_block_group()
    range_straddles_pages()
    extent_range_uptodate()
    btrfs_file_extent_length()
    btrfs_scrub_cancel_devid()
    btrfs_start_transaction_lflush()
    
    btrfs_print_tree() is left because it is used for debugging.
    btrfs_start_transaction_lflush() and btrfs_reada_detach() are
    left for symmetry.
    
    ulist.c functions are left, another patch will take care of those.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d9bed5fd3347..4272fbb08732 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3044,8 +3044,6 @@ struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 struct btrfs_fs_info *info,
 						 u64 bytenr);
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
-u64 btrfs_find_block_group(struct btrfs_root *root,
-			   u64 search_start, u64 search_hint, int owner);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					struct btrfs_root *root, u32 blocksize,
 					u64 parent, u64 root_objectid,
@@ -3055,10 +3053,6 @@ void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct extent_buffer *buf,
 			   u64 parent, int last_ref);
-struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
-					    struct btrfs_root *root,
-					    u64 bytenr, u32 blocksize,
-					    int level);
 int btrfs_alloc_reserved_file_extent(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root,
 				     u64 root_objectid, u64 owner,
@@ -3111,7 +3105,6 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
 void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
 				       struct btrfs_root *root);
-u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
@@ -3300,7 +3293,6 @@ static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
 {
 	return btrfs_next_old_item(root, p, 0);
 }
-int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
 int __must_check btrfs_drop_snapshot(struct btrfs_root *root,
 				     struct btrfs_block_rsv *block_rsv,
@@ -3395,9 +3387,6 @@ struct btrfs_dir_item *
 btrfs_search_dir_index_item(struct btrfs_root *root,
 			    struct btrfs_path *path, u64 dirid,
 			    const char *name, int name_len);
-struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,
-			      struct btrfs_path *path,
-			      const char *name, int name_len);
 int btrfs_delete_one_dir_name(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct btrfs_path *path,
@@ -3475,16 +3464,11 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
 			     u64 bytenr, int mod);
-u64 btrfs_file_extent_length(struct btrfs_path *path);
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums);
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig);
-struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
-					  struct btrfs_root *root,
-					  struct btrfs_path *path,
-					  u64 bytenr, int cow);
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
@@ -3546,8 +3530,6 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
-int btrfs_writepages(struct address_space *mapping,
-		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root, u64 new_dirid);
 int btrfs_merge_bio_hook(int rw, struct page *page, unsigned long offset,
@@ -3557,7 +3539,6 @@ int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
-int btrfs_dirty_inode(struct inode *inode);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);
@@ -3575,7 +3556,6 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 int btrfs_update_inode_fallback(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root, struct inode *inode);
 int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
-int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_cleanup(struct btrfs_root *root);
 void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root);
@@ -3626,7 +3606,6 @@ int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);
-void btrfs_drop_pages(struct page **pages, size_t num_pages);
 int btrfs_dirty_pages(struct btrfs_root *root, struct inode *inode,
 		      struct page **pages, size_t num_pages,
 		      loff_t pos, size_t write_bytes,
@@ -3802,7 +3781,6 @@ void btrfs_scrub_continue_super(struct btrfs_root *root);
 int btrfs_scrub_cancel(struct btrfs_fs_info *info);
 int btrfs_scrub_cancel_dev(struct btrfs_fs_info *info,
 			   struct btrfs_device *dev);
-int btrfs_scrub_cancel_devid(struct btrfs_root *root, u64 devid);
 int btrfs_scrub_progress(struct btrfs_root *root, u64 devid,
 			 struct btrfs_scrub_progress *progress);
 

commit 2f2320360b0c35b86938bfc561124474f0dac6e4
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Thu Apr 25 16:04:51 2013 +0000

    Btrfs: rescan for qgroups
    
    If qgroup tracking is out of sync, a rescan operation can be started. It
    iterates the complete extent tree and recalculates all qgroup tracking data.
    This is an expensive operation and should not be used unless required.
    
    A filesystem under rescan can still be umounted. The rescan continues on the
    next mount.  Status information is provided with a separate ioctl while a
    rescan operation is in progress.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2c48f52aba40..d9bed5fd3347 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1021,9 +1021,9 @@ struct btrfs_block_group_item {
  */
 #define BTRFS_QGROUP_STATUS_FLAG_ON		(1ULL << 0)
 /*
- * SCANNING is set during the initialization phase
+ * RESCAN is set during the initialization phase
  */
-#define BTRFS_QGROUP_STATUS_FLAG_SCANNING	(1ULL << 1)
+#define BTRFS_QGROUP_STATUS_FLAG_RESCAN		(1ULL << 1)
 /*
  * Some qgroup entries are known to be out of date,
  * either because the configuration has changed in a way that
@@ -1052,7 +1052,7 @@ struct btrfs_qgroup_status_item {
 	 * only used during scanning to record the progress
 	 * of the scan. It contains a logical address
 	 */
-	__le64 scan;
+	__le64 rescan;
 } __attribute__ ((__packed__));
 
 struct btrfs_qgroup_info_item {
@@ -1603,6 +1603,11 @@ struct btrfs_fs_info {
 	/* used by btrfs_qgroup_record_ref for an efficient tree traversal */
 	u64 qgroup_seq;
 
+	/* qgroup rescan items */
+	struct mutex qgroup_rescan_lock; /* protects the progress item */
+	struct btrfs_key qgroup_rescan_progress;
+	struct btrfs_workers qgroup_rescan_workers;
+
 	/* filesystem state */
 	unsigned long fs_state;
 
@@ -2886,8 +2891,8 @@ BTRFS_SETGET_FUNCS(qgroup_status_version, struct btrfs_qgroup_status_item,
 		   version, 64);
 BTRFS_SETGET_FUNCS(qgroup_status_flags, struct btrfs_qgroup_status_item,
 		   flags, 64);
-BTRFS_SETGET_FUNCS(qgroup_status_scan, struct btrfs_qgroup_status_item,
-		   scan, 64);
+BTRFS_SETGET_FUNCS(qgroup_status_rescan, struct btrfs_qgroup_status_item,
+		   rescan, 64);
 
 /* btrfs_qgroup_info_item */
 BTRFS_SETGET_FUNCS(qgroup_info_generation, struct btrfs_qgroup_info_item,
@@ -3828,7 +3833,7 @@ int btrfs_quota_enable(struct btrfs_trans_handle *trans,
 		       struct btrfs_fs_info *fs_info);
 int btrfs_quota_disable(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info);
-int btrfs_quota_rescan(struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
 int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
 int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,

commit fc36ed7e0b13955ba66fc56dc5067e67ac105150
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed Apr 24 16:57:33 2013 +0000

    Btrfs: separate sequence numbers for delayed ref tracking and tree mod log
    
    Sequence numbers for delayed refs have been introduced in the first version
    of the qgroup patch set. To solve the problem of find_all_roots on a busy
    file system, the tree mod log was introduced. The sequence numbers for that
    were simply shared between those two users.
    
    However, at one point in qgroup's quota accounting, there's a statement
    accessing the previous sequence number, that's still just doing (seq - 1)
    just as it would have to in the very first version.
    
    To satisfy that requirement, this patch makes the sequence number counter 64
    bit and splits it into a major part (used for qgroup sequence number
    counting) and a minor part (incremented for each tree modification in the
    log). This enables us to go exactly one major step backwards, as required
    for qgroups, while still incrementing the sequence counter for tree mod log
    insertions to keep track of their order. Keeping them in a single variable
    means there's no need to change all the code dealing with comparisons of two
    sequence numbers.
    
    The sequence number is reset to 0 on commit (not new in this patch), which
    ensures we won't overflow the two 32 bit counters.
    
    Without this fix, the qgroup tracking can occasionally go wrong and WARN_ONs
    from the tree mod log code may happen.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 37c4da3403d0..2c48f52aba40 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1422,7 +1422,7 @@ struct btrfs_fs_info {
 
 	/* this protects tree_mod_seq_list */
 	spinlock_t tree_mod_seq_lock;
-	atomic_t tree_mod_seq;
+	atomic64_t tree_mod_seq;
 	struct list_head tree_mod_seq_list;
 	struct seq_list tree_mod_seq_elem;
 
@@ -3332,10 +3332,7 @@ u64 btrfs_get_tree_mod_seq(struct btrfs_fs_info *fs_info,
 			   struct seq_list *elem);
 void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
 			    struct seq_list *elem);
-static inline u64 btrfs_inc_tree_mod_seq(struct btrfs_fs_info *fs_info)
-{
-	return atomic_inc_return(&fs_info->tree_mod_seq);
-}
+u64 btrfs_tree_mod_seq_prev(u64 seq);
 int btrfs_old_root_level(struct btrfs_root *root, u64 time_seq);
 
 /* root-item.c */

commit 5fbf83c10c323cbee61483a06ea61883e3c83e6b
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Apr 19 15:08:04 2013 +0000

    Btrfs: delete unused parameter to btrfs_read_root_item()
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 974687808153..37c4da3403d0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3359,9 +3359,8 @@ int __must_check btrfs_update_root(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root,
 				   struct btrfs_key *key,
 				   struct btrfs_root_item *item);
-void btrfs_read_root_item(struct btrfs_root *root,
-			 struct extent_buffer *eb, int slot,
-			 struct btrfs_root_item *item);
+void btrfs_read_root_item(struct extent_buffer *eb, int slot,
+			  struct btrfs_root_item *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);

commit 4b90c68015a7c0863292d6306501552d4ffa33ff
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Tue Apr 16 05:18:49 2013 +0000

    Btrfs: remove unused argument of btrfs_extend_item()
    
    Argument 'trans' is not used in btrfs_extend_item().
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84d6d5cb02f6..974687808153 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3219,8 +3219,7 @@ int btrfs_copy_root(struct btrfs_trans_handle *trans,
 		      struct extent_buffer **cow_ret, u64 new_root_objectid);
 int btrfs_block_can_be_shared(struct btrfs_root *root,
 			      struct extent_buffer *buf);
-void btrfs_extend_item(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *root, struct btrfs_path *path,
+void btrfs_extend_item(struct btrfs_root *root, struct btrfs_path *path,
 		       u32 data_size);
 void btrfs_truncate_item(struct btrfs_root *root, struct btrfs_path *path,
 			 u32 new_size, int from_end);

commit afe5fea72bd50b1df2e6a721ef50559427d42f2b
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Tue Apr 16 05:18:22 2013 +0000

    Btrfs: cleanup of function where fixup_low_keys() is called
    
    If argument 'trans' is unnecessary in the function where
    fixup_low_keys() is called, 'trans' is deleted.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c3b15f8dca00..84d6d5cb02f6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3183,8 +3183,7 @@ int btrfs_comp_cpu_keys(struct btrfs_key *k1, struct btrfs_key *k2);
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
-void btrfs_set_item_key_safe(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *root, struct btrfs_path *path,
+void btrfs_set_item_key_safe(struct btrfs_root *root, struct btrfs_path *path,
 			     struct btrfs_key *new_key);
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
@@ -3223,9 +3222,7 @@ int btrfs_block_can_be_shared(struct btrfs_root *root,
 void btrfs_extend_item(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct btrfs_path *path,
 		       u32 data_size);
-void btrfs_truncate_item(struct btrfs_trans_handle *trans,
-			 struct btrfs_root *root,
-			 struct btrfs_path *path,
+void btrfs_truncate_item(struct btrfs_root *root, struct btrfs_path *path,
 			 u32 new_size, int from_end);
 int btrfs_split_item(struct btrfs_trans_handle *trans,
 		     struct btrfs_root *root,
@@ -3265,8 +3262,7 @@ static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 	return btrfs_del_items(trans, root, path, path->slots[0], 1);
 }
 
-void setup_items_for_insert(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root, struct btrfs_path *path,
+void setup_items_for_insert(struct btrfs_root *root, struct btrfs_path *path,
 			    struct btrfs_key *cpu_key, u32 *data_size,
 			    u32 total_data, u32 total_size, int nr);
 int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root

commit ceda08642459e31673d24d7968d864390d2ce5fa
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Apr 11 10:30:16 2013 +0000

    Btrfs: use a lock to protect incompat/compat flag of the super block
    
    The following case will make the incompat/compat flag of the super block
    be recovered.
     Task1                                  |Task2
     flags = btrfs_super_incompat_flags();  |
                                            |flags = btrfs_super_incompat_flags();
     flags |= new_flag1;                    |
                                            |flags |= new_flag2;
     btrfs_set_super_incompat_flags(flags); |
                                            |btrfs_set_super_incompat_flags(flags);
    the new_flag1 is recovered.
    
    In order to avoid this problem, we introduce a lock named super_lock into
    the btrfs_fs_info structure. If we want to update incompat/compat flags
    of the super block, we must hold it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1a850402937d..c3b15f8dca00 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1362,6 +1362,17 @@ struct btrfs_fs_info {
 	wait_queue_head_t transaction_blocked_wait;
 	wait_queue_head_t async_submit_wait;
 
+	/*
+	 * Used to protect the incompat_flags, compat_flags, compat_ro_flags
+	 * when they are updated.
+	 *
+	 * Because we do not clear the flags for ever, so we needn't use
+	 * the lock on the read side.
+	 *
+	 * We also needn't use the lock when we mount the fs, because
+	 * there is no other task which will update the flag.
+	 */
+	spinlock_t super_lock;
 	struct btrfs_super_block *super_copy;
 	struct btrfs_super_block *super_for_commit;
 	struct block_device *__bdev;
@@ -3688,8 +3699,15 @@ static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
 	disk_super = fs_info->super_copy;
 	features = btrfs_super_incompat_flags(disk_super);
 	if (!(features & flag)) {
-		features |= flag;
-		btrfs_set_super_incompat_flags(disk_super, features);
+		spin_lock(&fs_info->super_lock);
+		features = btrfs_super_incompat_flags(disk_super);
+		if (!(features & flag)) {
+			features |= flag;
+			btrfs_set_super_incompat_flags(disk_super, features);
+			printk(KERN_INFO "btrfs: setting %llu feature flag\n",
+					 flag);
+		}
+		spin_unlock(&fs_info->super_lock);
 	}
 }
 

commit f2f6ed3d54648ec19dcdeec30f66843cf7a38487
Author: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
Date:   Sun Apr 7 10:50:16 2013 +0000

    Btrfs: introduce a mutex lock for btrfs quota operations
    
    The original code has one spin_lock 'qgroup_lock' to protect quota
    configurations in memory. If we want to add a BTRFS_QGROUP_INFO_KEY,
    it will be added to Btree firstly, and then update configurations in
    memory,however, a race condition may happen between these operations.
    For example:
            ->add_qgroup_info_item()
                    ->add_qgroup_rb()
    
    For the above case, del_qgroup_info_item() may happen just before
    add_qgroup_rb().
    
    What's worse, when we want to add a qgroup relation:
            ->add_qgroup_relation_item()
                    ->add_qgroup_relations()
    
    We don't have any checks whether 'src' and 'dst' exist before
    add_qgroup_relation_item(), a race condition can also happen for
    the above case.
    
    To avoid race condition and have all the necessary checks, we introduce
    a mutex lock 'qgroup_ioctl_lock', and we make all the user change operations
    protected by the mutex lock.
    
    Signed-off-by: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
    Reviewed-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 075a8a0e49c4..1a850402937d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1583,6 +1583,9 @@ struct btrfs_fs_info {
 	struct rb_root qgroup_tree;
 	spinlock_t qgroup_lock;
 
+	/* protect user change for quota operations */
+	struct mutex qgroup_ioctl_lock;
+
 	/* list of dirty qgroups to be written at next commit */
 	struct list_head dirty_qgroups;
 

commit 09a2a8f96e3009273bed1833b3f210e2c68728a5
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Apr 5 16:51:15 2013 -0400

    Btrfs: fix bad extent logging
    
    A user sent me a btrfs-image of a file system that was panicing on mount during
    the log recovery.  I had originally thought these problems were from a bug in
    the free space cache code, but that was just a symptom of the problem.  The
    problem is if your application does something like this
    
    [prealloc][prealloc][prealloc]
    
    the internal extent maps will merge those all together into one extent map, even
    though on disk they are 3 separate extents.  So if you go to write into one of
    these ranges the extent map will be right since we use the physical extent when
    doing the write, but when we log the extents they will use the wrong sizes for
    the remainder prealloc space.  If this doesn't happen to trip up the free space
    cache (which it won't in a lot of cases) then you will get bogus entries in your
    extent tree which will screw stuff up later.  The data and such will still work,
    but everything else is broken.  This patch fixes this by not allowing extents
    that are on the modified list to be merged.  This has the side effect that we
    are no longer adding everything to the modified list all the time, which means
    we now have to call btrfs_drop_extents every time we log an extent into the
    tree.  So this allows me to drop all this speciality code I was using to get
    around calling btrfs_drop_extents.  With this patch the testcase I've created no
    longer creates a bogus file system after replaying the log.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5060990336a8..075a8a0e49c4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -586,7 +586,6 @@ struct btrfs_path {
 	unsigned int skip_locking:1;
 	unsigned int leave_spinning:1;
 	unsigned int search_commit_root:1;
-	unsigned int really_keep_locks:1;
 };
 
 /*
@@ -3273,9 +3272,6 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 }
 
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
-int btrfs_next_leaf_write(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root, struct btrfs_path *path,
-			  int del);
 int btrfs_next_old_leaf(struct btrfs_root *root, struct btrfs_path *path,
 			u64 time_seq);
 static inline int btrfs_next_old_item(struct btrfs_root *root,

commit c2cf52eb71aeb902682e0c1fa29e4e9e4a7f4ffc
Author: Simon Kirby <sim@hostway.ca>
Date:   Tue Mar 19 22:41:23 2013 +0000

    Btrfs: Include the device in most error printk()s
    
    With more than one btrfs volume mounted, it can be very difficult to find
    out which volume is hitting an error. btrfs_error() will print this, but
    it is currently rigged as more of a fatal error handler, while many of
    the printk()s are currently for debugging and yet-unhandled cases.
    
    This patch just changes the functions where the device information is
    already available. Some cases remain where the root or fs_info is not
    passed to the function emitting the error.
    
    This may introduce some confusion with volumes backed by multiple devices
    emitting errors referring to the primary device in the set instead of the
    one on which the error occurred.
    
    Use btrfs_printk(fs_info, format, ...) rather than writing the device
    string every time, and introduce macro wrappers ala XFS for brevity.
    Since the function already cannot be used for continuations, print a
    newline as part of the btrfs_printk() message rather than at each caller.
    
    Signed-off-by: Simon Kirby <sim@hostway.ca>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index efb2feb7cd4a..5060990336a8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3643,14 +3643,31 @@ int btrfs_sync_fs(struct super_block *sb, int wait);
 
 #ifdef CONFIG_PRINTK
 __printf(2, 3)
-void btrfs_printk(struct btrfs_fs_info *fs_info, const char *fmt, ...);
+void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...);
 #else
 static inline __printf(2, 3)
-void btrfs_printk(struct btrfs_fs_info *fs_info, const char *fmt, ...)
+void btrfs_printk(const struct btrfs_fs_info *fs_info, const char *fmt, ...)
 {
 }
 #endif
 
+#define btrfs_emerg(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_EMERG fmt, ##args)
+#define btrfs_alert(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_ALERT fmt, ##args)
+#define btrfs_crit(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_CRIT fmt, ##args)
+#define btrfs_err(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_ERR fmt, ##args)
+#define btrfs_warn(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_WARNING fmt, ##args)
+#define btrfs_notice(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_NOTICE fmt, ##args)
+#define btrfs_info(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_INFO fmt, ##args)
+#define btrfs_debug(fs_info, fmt, args...) \
+	btrfs_printk(fs_info, KERN_DEBUG fmt, ##args)
+
 __printf(5, 6)
 void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);

commit 3173a18f70554fe7880bb2d85c7da566e364eb3c
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Mar 7 14:22:04 2013 -0500

    Btrfs: add a incompatible format change for smaller metadata extent refs
    
    We currently store the first key of the tree block inside the reference for the
    tree block in the extent tree.  This takes up quite a bit of space.  Make a new
    key type for metadata which holds the level as the offset and completely removes
    storing the btrfs_tree_block_info inside the extent ref.  This reduces the size
    from 51 bytes to 33 bytes per extent reference for each tree block.  In practice
    this results in a 30-35% decrease in the size of our extent tree, which means we
    COW less and can keep more of the extent tree in memory which makes our heavy
    metadata operations go much faster.  This is not an automatic format change, you
    must enable it at mkfs time or with btrfstune.  This patch deals with having
    metadata stored as either the old format or the new format so it is easy to
    convert.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e2f14b5258b6..efb2feb7cd4a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -509,6 +509,7 @@ struct btrfs_super_block {
 
 #define BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF	(1ULL << 6)
 #define BTRFS_FEATURE_INCOMPAT_RAID56		(1ULL << 7)
+#define BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA	(1ULL << 8)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
@@ -519,7 +520,8 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_BIG_METADATA |		\
 	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO |		\
 	 BTRFS_FEATURE_INCOMPAT_RAID56 |		\
-	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF)
+	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF |		\
+	 BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
 
 /*
  * A leaf is full of items. offset and size tell us where to find
@@ -1809,6 +1811,12 @@ struct btrfs_ioctl_defrag_range_args {
  */
 #define BTRFS_EXTENT_ITEM_KEY	168
 
+/*
+ * The same as the BTRFS_EXTENT_ITEM_KEY, except it's metadata we already know
+ * the length, so we save the level in key->offset instead of the length.
+ */
+#define BTRFS_METADATA_ITEM_KEY	169
+
 #define BTRFS_TREE_BLOCK_REF_KEY	176
 
 #define BTRFS_EXTENT_DATA_REF_KEY	178
@@ -3006,7 +3014,7 @@ int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 bytenr,
-			     u64 num_bytes, u64 *refs, u64 *flags);
+			     u64 offset, int metadata, u64 *refs, u64 *flags);
 int btrfs_pin_extent(struct btrfs_root *root,
 		     u64 bytenr, u64 num, int reserved);
 int btrfs_pin_extent_for_log_replay(struct btrfs_root *root,
@@ -3669,6 +3677,16 @@ static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
 	}
 }
 
+#define btrfs_fs_incompat(fs_info, opt) \
+	__btrfs_fs_incompat((fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
+
+static inline int __btrfs_fs_incompat(struct btrfs_fs_info *fs_info, u64 flag)
+{
+	struct btrfs_super_block *disk_super;
+	disk_super = fs_info->super_copy;
+	return !!(btrfs_super_incompat_flags(disk_super) & flag);
+}
+
 /*
  * Call btrfs_abort_transaction as early as possible when an error condition is
  * detected, that way the exact line number is reported.

commit 087488109afb4cc1bbdd3557779129c34045609a
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Mar 12 14:46:08 2013 +0000

    btrfs: clean up transaction abort messages
    
    The transaction abort stacktrace is printed only once per module
    lifetime, but we'd like to see it each time it happens per mounted
    filesystem.  Introduce a fs_state flag that records it.
    
    Tweak the messages around abort:
    * add error number to the first abort
    * print the exact negative errno from btrfs_decode_error
    * clean up btrfs_decode_error and callers
    * no dots at the end of the messages
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0d82922179db..e2f14b5258b6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -340,6 +340,7 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
  */
 #define BTRFS_FS_STATE_ERROR		0
 #define BTRFS_FS_STATE_REMOUNTING	1
+#define BTRFS_FS_STATE_TRANS_ABORTED	2
 
 /* Super block flags */
 /* Errors detected */

commit d5c1207017cd8387b4d3224dd7ab6cf5cd7f1c9a
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 28 10:04:33 2013 +0000

    Btrfs: fix wrong reserved space in qgroup during snap/subv creation
    
    There are two problems in the space reservation of the snapshot/
    subvolume creation.
    - don't reserve the space for the root item insertion
    - the space which is reserved in the qgroup is different with
      the free space reservation. we need reserve free space for
      7 items, but in qgroup reservation, we need reserve space only
      for 3 items.
    
    So we implement new metadata reservation functions for the
    snapshot/subvolume creation.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ae8dcc406805..0d82922179db 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3106,8 +3106,13 @@ void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
 				  struct inode *inode);
 void btrfs_orphan_release_metadata(struct inode *inode);
-int btrfs_snap_reserve_metadata(struct btrfs_trans_handle *trans,
-				struct btrfs_pending_snapshot *pending);
+int btrfs_subvolume_reserve_metadata(struct btrfs_root *root,
+				     struct btrfs_block_rsv *rsv,
+				     int nitems,
+				     u64 *qgroup_reserved);
+void btrfs_subvolume_release_metadata(struct btrfs_root *root,
+				      struct btrfs_block_rsv *rsv,
+				      u64 qgroup_reserved);
 int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode, u64 num_bytes);

commit dc81cdc58ad2f413b96b9004f8d681e5dc554473
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Feb 20 23:32:52 2013 -0700

    Btrfs: fix remount vs autodefrag
    
    If we remount the fs to close the auto defragment or make the fs R/O,
    we should stop the auto defragment.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3dcedfe4f759..ae8dcc406805 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -339,6 +339,7 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
  * File system states
  */
 #define BTRFS_FS_STATE_ERROR		0
+#define BTRFS_FS_STATE_REMOUNTING	1
 
 /* Super block flags */
 /* Errors detected */
@@ -1902,6 +1903,7 @@ struct btrfs_ioctl_defrag_range_args {
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
+#define btrfs_raw_test_opt(o, opt)	((o) & BTRFS_MOUNT_##opt)
 #define btrfs_test_opt(root, opt)	((root)->fs_info->mount_opt & \
 					 BTRFS_MOUNT_##opt)
 /*

commit e942f883bc6651d50be139477baf6fb0eed3d5bb
Merge: b2c6b3e0611c 0e4e02636611
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Feb 20 14:06:05 2013 -0500

    Merge branch 'raid56-experimental' into for-linus-3.9
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    
    Conflicts:
            fs/btrfs/ctree.h
            fs/btrfs/extent-tree.c
            fs/btrfs/inode.c
            fs/btrfs/volumes.c

commit cdb4c5748cb3ac533889a6b0b95aa10651e68785
Author: Zach Brown <zab@redhat.com>
Date:   Wed Feb 20 00:55:13 2013 +0000

    btrfs: define BTRFS_MAGIC as a u64 value
    
    super.magic is an le64 but it's treated as an unterminated string when
    compared against BTRFS_MAGIC which is defined as a string.  Instead
    define BTRFS_MAGIC as a normal hex value and use endian helpers to
    compare it to the super's magic.
    
    I tested this by mounting an fs made before the change and made sure
    that it didn't introduce sparse errors.  This matches a similar cleanup
    that is pending in btrfs-progs.  David Sterba pointed out that we should
    fix the kernel side as well :).
    
    Signed-off-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 961ff2986341..1679051f4d39 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -46,7 +46,7 @@ extern struct kmem_cache *btrfs_path_cachep;
 extern struct kmem_cache *btrfs_free_space_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_BHRfS_M"
+#define BTRFS_MAGIC 0x4D5F53665248425FULL /* ascii _BHRfS_M, no null */
 
 #define BTRFS_MAX_MIRRORS 3
 

commit 569e0f358c0c37f6733702d4a5d2c412860f7169
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Feb 13 11:09:14 2013 -0500

    Btrfs: place ordered operations on a per transaction list
    
    Miao made the ordered operations stuff run async, which introduced a
    deadlock where we could get somebody (sync) racing in and committing the
    transaction while a commit was already happening.  The new committer would
    try and flush ordered operations which would hang waiting for the commit to
    finish because it is done asynchronously and no longer inherits the callers
    trans handle.  To fix this we need to make the ordered operations list a per
    transaction list.  We can get new inodes added to the ordered operation list
    by truncating them and then having another process writing to them, so this
    makes it so that anybody trying to add an ordered operation _must_ start a
    transaction in order to add itself to the list, which will keep new inodes
    from getting added to the ordered operations list after we start committing.
    This should fix the deadlock and also keeps us from doing a lot more work
    than we need to during commit.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 14f01dc70ea6..961ff2986341 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1407,13 +1407,6 @@ struct btrfs_fs_info {
 	 */
 	struct list_head delalloc_inodes;
 
-	/*
-	 * special rename and truncate targets that must be on disk before
-	 * we're allowed to commit.  This is basically the ext3 style
-	 * data=ordered list.
-	 */
-	struct list_head ordered_operations;
-
 	/*
 	 * there is a pool of worker threads for checksumming during writes
 	 * and a pool for checksumming after reads.  This is because readers

commit 210549ebe9047ae5a8cc47487203d3ee16a7749b
Author: David Sterba <dsterba@suse.cz>
Date:   Sat Feb 9 23:38:06 2013 +0000

    btrfs: add cancellation points to defrag
    
    The defrag operation can take very long, we want to have a way how to
    cancel it. The code checks for a pending signal at safe points in the
    defrag loops and returns EAGAIN. This means a user can press ^C after
    running 'btrfs fi defrag', woks for both defrag modes, files and root.
    
    Returning from the command was instant in my light tests, but may take
    longer depending on the aging factor of the filesystem.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f1cc247f3178..14f01dc70ea6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3786,4 +3786,11 @@ static inline int is_fstree(u64 rootid)
 		return 1;
 	return 0;
 }
+
+static inline int btrfs_defrag_cancelled(struct btrfs_fs_info *fs_info)
+{
+	return signal_pending(current);
+}
+
+
 #endif

commit 5d80366e9b5e56b3ffc1923b4995e83bbbf605e3
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Feb 7 16:06:02 2013 -0500

    Btrfs: steal from global reserve if we are cleaning up orphans
    
    Sometimes xfstest 83 will fail to remount the scratch device because we've
    gotten ourselves so full that we cannot cleanup the orphan items.  In this
    case check to see if we're doing the orphan cleanup and if we are allow us
    to steal our reservation from the global block rsv.  With this patch I've
    not been able to reproduce the failed mount problem.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7e2cffd2a5d8..f1cc247f3178 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1237,6 +1237,11 @@ struct seq_list {
 	u64 seq;
 };
 
+enum btrfs_orphan_cleanup_state {
+	ORPHAN_CLEANUP_STARTED	= 1,
+	ORPHAN_CLEANUP_DONE	= 2,
+};
+
 /* fs_info */
 struct reloc_control;
 struct btrfs_device;

commit de78b51a2852bddccd6535e9e12de65f92787a1e
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Jan 31 18:21:12 2013 +0000

    btrfs: remove cache only arguments from defrag path
    
    The entry point at the defrag ioctl always sets "cache only" to 0;
    the codepaths haven't run for a long time as far as I can
    tell.  Chris says they're dead code, so remove them.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e3a994e1899..7e2cffd2a5d8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3125,10 +3125,10 @@ struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
 int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
 			struct btrfs_key *key, int lowest_level,
-			int cache_only, u64 min_trans);
+			u64 min_trans);
 int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
 			 struct btrfs_key *max_key,
-			 struct btrfs_path *path, int cache_only,
+			 struct btrfs_path *path,
 			 u64 min_trans);
 enum btrfs_compare_tree_result {
 	BTRFS_COMPARE_TREE_NEW,
@@ -3181,7 +3181,7 @@ int btrfs_search_slot_for_read(struct btrfs_root *root,
 			       int find_higher, int return_any);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct extent_buffer *parent,
-		       int start_slot, int cache_only, u64 *last_ret,
+		       int start_slot, u64 *last_ret,
 		       struct btrfs_key *progress);
 void btrfs_release_path(struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
@@ -3576,7 +3576,7 @@ int btrfs_dirty_pages(struct btrfs_root *root, struct inode *inode,
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root, int cache_only);
+			struct btrfs_root *root);
 
 /* sysfs.c */
 int btrfs_init_sysfs(void);

commit aa43a17c21cf35329b1a495dd6876798dd8b016b
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Jan 31 00:54:55 2013 +0000

    btrfs: handle null fs_info in btrfs_panic()
    
    At least backref_tree_panic() can apparently pass
    in a null fs_info, so handle that in __btrfs_panic
    to get the message out on the console.
    
    The btrfs_panic macro also uses fs_info, but that's
    largely pointless; it's testing to see if
    BTRFS_MOUNT_PANIC_ON_FATAL_ERROR is not set.
    But if it *were* set, __btrfs_panic() would have,
    well, paniced and we wouldn't be here, testing it!
    So just BUG() at this point.
    
    And since we only use fs_info once now, just use it
    directly.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 78fba44ad3d9..1e3a994e1899 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3653,11 +3653,14 @@ __printf(5, 6)
 void __btrfs_panic(struct btrfs_fs_info *fs_info, const char *function,
 		   unsigned int line, int errno, const char *fmt, ...);
 
+/*
+ * If BTRFS_MOUNT_PANIC_ON_FATAL_ERROR is in mount_opt, __btrfs_panic
+ * will panic().  Otherwise we BUG() here.
+ */
 #define btrfs_panic(fs_info, errno, fmt, args...)			\
 do {									\
-	struct btrfs_fs_info *_i = (fs_info);				\
-	__btrfs_panic(_i, __func__, __LINE__, errno, fmt, ##args);	\
-	BUG_ON(!(_i->mount_opt & BTRFS_MOUNT_PANIC_ON_FATAL_ERROR));	\
+	__btrfs_panic(fs_info, __func__, __LINE__, errno, fmt, ##args);	\
+	BUG();								\
 } while (0)
 
 /* acl.c */

commit 87533c475187c1420794a2e164bc67a7974f1327
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:14:48 2013 +0000

    Btrfs: use bit operation for ->fs_state
    
    There is no lock to protect fs_info->fs_state, it will introduce
    some problems, such as the value may be covered by the other task
    when several tasks modify it. For example:
            Task0 - CPU0            Task1 - CPU1
            mov %fs_state rax
            or $0x1 rax
                                    mov %fs_state rax
                                    or $0x2 rax
            mov rax %fs_state
                                    mov rax %fs_state
    The expected value is 3, but in fact, it is 2.
    
    Though this problem doesn't happen now (because there is only one
    flag currently), the code is error prone, if we add other flags,
    the above problem will happen to a certainty.
    
    Now we use bit operation for it to fix the above problem.
    In this way, we can make the code more robust and be easy to
    add new flags.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5f5c30aaef36..78fba44ad3d9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -338,7 +338,9 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 /*
  * File system states
  */
+#define BTRFS_FS_STATE_ERROR		0
 
+/* Super block flags */
 /* Errors detected */
 #define BTRFS_SUPER_FLAG_ERROR		(1ULL << 2)
 
@@ -1549,7 +1551,7 @@ struct btrfs_fs_info {
 	u64 qgroup_seq;
 
 	/* filesystem state */
-	u64 fs_state;
+	unsigned long fs_state;
 
 	struct btrfs_delayed_root *delayed_root;
 

commit de98ced9e743656d108de41841797def0f5cb951
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:13:12 2013 +0000

    Btrfs: use seqlock to protect fs_info->avail_{data, metadata, system}_alloc_bits
    
    There is no lock to protect
      fs_info->avail_{data, metadata, system}_alloc_bits,
    it may introduce some problem, such as the wrong profile
    information, so we add a seqlock to protect them.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 50def99f5379..5f5c30aaef36 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1483,6 +1483,8 @@ struct btrfs_fs_info {
 	struct rb_root defrag_inodes;
 	atomic_t defrag_running;
 
+	/* Used to protect avail_{data, metadata, system}_alloc_bits */
+	seqlock_t profiles_lock;
 	/*
 	 * these three are in extended format (availability of single
 	 * chunks is denoted by BTRFS_AVAIL_ALLOC_BIT_SINGLE bit, other

commit 963d678b0f7649300e3a67f2513ca9d830c6e303
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:10:51 2013 +0000

    Btrfs: use percpu counter for fs_info->delalloc_bytes
    
    fs_info->delalloc_bytes is accessed very frequently, so use percpu
    counter instead of the u64 variant for it to reduce the lock
    contention.
    
    This patch also fixed the problem that we access the variant
    without the lock protection.At worst, we would not flush the
    delalloc inodes, and just return ENOSPC error when we still have
    some free space in the fs.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4c476281b66b..50def99f5379 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1392,6 +1392,7 @@ struct btrfs_fs_info {
 	 */
 	struct list_head ordered_extents;
 
+	spinlock_t delalloc_lock;
 	/*
 	 * all of the inodes that have delalloc bytes.  It is possible for
 	 * this list to be empty even when there is still dirty data=ordered
@@ -1452,7 +1453,10 @@ struct btrfs_fs_info {
 
 	/* used to keep from writing metadata until there is a nice batch */
 	struct percpu_counter dirty_metadata_bytes;
+	struct percpu_counter delalloc_bytes;
 	s32 dirty_metadata_batch;
+	s32 delalloc_batch;
+
 	struct list_head dirty_cowonly_roots;
 
 	struct btrfs_fs_devices *fs_devices;
@@ -1468,9 +1472,6 @@ struct btrfs_fs_info {
 
 	struct reloc_control *reloc_ctl;
 
-	spinlock_t delalloc_lock;
-	u64 delalloc_bytes;
-
 	/* data_alloc_cluster is only used in ssd mode */
 	struct btrfs_free_cluster data_alloc_cluster;
 

commit e2d845211eda9cf296e8edf6724b3d541f4fbfd5
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:09:20 2013 +0000

    Btrfs: use percpu counter for dirty metadata count
    
    ->dirty_metadata_bytes is accessed very frequently, so use percpu
    counter instead of the u64 variant to reduce the contention of
    the lock.
    
    This patch also fixed the problem that we access it without
    lock protection in __btrfs_btree_balance_dirty(), which may
    cause we skip the dirty pages flush.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d8e539fe5544..4c476281b66b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -191,6 +191,8 @@ static int btrfs_csum_sizes[] = { 4, 0 };
 /* ioprio of readahead is set to idle */
 #define BTRFS_IOPRIO_READA (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_IDLE, 0))
 
+#define BTRFS_DIRTY_METADATA_THRESH	(32 * 1024 * 1024)
+
 /*
  * The key defines the order in the tree, and so it also defines (optimal)
  * block layout.
@@ -1448,10 +1450,9 @@ struct btrfs_fs_info {
 
 	u64 total_pinned;
 
-	/* protected by the delalloc lock, used to keep from writing
-	 * metadata until there is a nice batch
-	 */
-	u64 dirty_metadata_bytes;
+	/* used to keep from writing metadata until there is a nice batch */
+	struct percpu_counter dirty_metadata_bytes;
+	s32 dirty_metadata_batch;
 	struct list_head dirty_cowonly_roots;
 
 	struct btrfs_fs_devices *fs_devices;

commit c018daecead7a46a575e2a1397fea850b83396c8
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:07:33 2013 +0000

    Btrfs: protect fs_info->alloc_start
    
    fs_info->alloc_start is a 64bits variant, can be accessed by
    multi-task, but it is not protected strictly, it can be changed
    while we are accessing it. On 32bit machine, we will get wrong
    value because we access it by two instructions.(In fact, it is
    also possible that the same problem happens on the 64bit machine,
    because the compiler may split the 64bit operation into two 32bit
    operation.)
    
    For example:
    Assuming -> alloc_start is 0x0000 0000 0001 0000 at the beginning,
    then we remount and set ->alloc_start to 0x0000 0100 0000 0000.
            Task0                   Task1
                                    load high 32 bits
            set high 32 bits
            set low 32 bits
                                    load low 32 bits
    
    Task1 will get 0.
    
    This patch fixes this problem by using two locks to protect it
            fs_info->chunk_mutex
            sb->s_umount
    On the read side, we just need get one of these two locks, and on
    the write side, we must lock all of them.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 169baa817d96..d8e539fe5544 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1304,6 +1304,16 @@ struct btrfs_fs_info {
 	 * so it is also safe.
 	 */
 	u64 max_inline;
+	/*
+	 * Protected by ->chunk_mutex and sb->s_umount.
+	 *
+	 * The reason that we use two lock to protect it is because only
+	 * remount and mount operations can change it and these two operations
+	 * are under sb->s_umount, but the read side (chunk allocation) can not
+	 * acquire sb->s_umount or the deadlock would happen. So we use two
+	 * locks to protect it. On the write side, we must acquire two locks,
+	 * and on the read side, we just need acquire one of them.
+	 */
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;
 	wait_queue_head_t transaction_throttle;

commit 8c6a3ee6dbd564d05019d396ecb5dc5b35cbc273
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:05:05 2013 +0000

    Btrfs: add a comment for fs_info->max_inline
    
    Though ->max_inline is a 64bit variant, and may be accessed by
    multi-task, but it is just suggestive number, so we needn't add
    anything to protect fs_info->max_inline, just add a comment to
    explain wny we don't use a lock to protect it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 69321013683c..169baa817d96 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1297,6 +1297,12 @@ struct btrfs_fs_info {
 	u64 last_trans_log_full_commit;
 	unsigned long mount_opt;
 	unsigned long compress_type:4;
+	/*
+	 * It is a suggestive number, the read side is safe even it gets a
+	 * wrong number because we will write out the data into a regular
+	 * extent. The write side(mount/remount) is under ->s_umount lock,
+	 * so it is also safe.
+	 */
 	u64 max_inline;
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;

commit 55e301fd57a6239ec14b91a1cf2e70b3dd135194
Author: Filipe Brandenburger <filbranden@google.com>
Date:   Tue Jan 29 06:04:50 2013 +0000

    Btrfs: move fs/btrfs/ioctl.h to include/uapi/linux/btrfs.h
    
    The header file will then be installed under /usr/include/linux so that
    userspace applications can refer to Btrfs ioctls by name and use the same
    structs used internally in the kernel.
    
    Signed-off-by: Filipe Brandenburger <filbranden@google.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 541ce9a9949e..69321013683c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -31,10 +31,10 @@
 #include <trace/events/btrfs.h>
 #include <asm/kmap_types.h>
 #include <linux/pagemap.h>
+#include <linux/btrfs.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
-#include "ioctl.h"
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;

commit e6ec716f0ddbe51741ef261d0804f0c28038dda4
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jan 17 05:38:51 2013 +0000

    Btrfs: make raid attr array more readable
    
    The current code of raid attr arry is hard to understand and it is easy to
    introduce some problem if we modify the array. So I changed it and made it
    more readable.
    
    Cc: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9ee099f3f834..541ce9a9949e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -953,7 +953,15 @@ struct btrfs_dev_replace_item {
 #define BTRFS_BLOCK_GROUP_DUP		(1ULL << 5)
 #define BTRFS_BLOCK_GROUP_RAID10	(1ULL << 6)
 #define BTRFS_BLOCK_GROUP_RESERVED	BTRFS_AVAIL_ALLOC_BIT_SINGLE
-#define BTRFS_NR_RAID_TYPES		5
+
+enum btrfs_raid_types {
+	BTRFS_RAID_RAID10,
+	BTRFS_RAID_RAID1,
+	BTRFS_RAID_DUP,
+	BTRFS_RAID_RAID0,
+	BTRFS_RAID_SINGLE,
+	BTRFS_NR_RAID_TYPES
+};
 
 #define BTRFS_BLOCK_GROUP_TYPE_MASK	(BTRFS_BLOCK_GROUP_DATA |    \
 					 BTRFS_BLOCK_GROUP_SYSTEM |  \

commit a1897fddd28daf6b23d05a30dc2a18836f77f8e3
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Dec 27 09:01:23 2012 +0000

    Btrfs: record first logical byte in memory
    
    This'd save us a rbtree search which may become expensive in large filesystem.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 22f012d41fd0..9ee099f3f834 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1250,6 +1250,7 @@ struct btrfs_fs_info {
 
 	/* block group cache stuff */
 	spinlock_t block_group_cache_lock;
+	u64 first_logical_byte;
 	struct rb_root block_group_cache_tree;
 
 	/* keep track of unallocated space */

commit dcfac4156fa102c1bab0e4e31df37e47278292f6
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Dec 27 09:01:20 2012 +0000

    Btrfs: kill unused argument of btrfs_pin_extent_for_log_replay
    
    Argument 'trans' is not used any more.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 411c8d97074e..22f012d41fd0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2939,8 +2939,7 @@ int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     u64 num_bytes, u64 *refs, u64 *flags);
 int btrfs_pin_extent(struct btrfs_root *root,
 		     u64 bytenr, u64 num, int reserved);
-int btrfs_pin_extent_for_log_replay(struct btrfs_trans_handle *trans,
-				    struct btrfs_root *root,
+int btrfs_pin_extent_for_log_replay(struct btrfs_root *root,
 				    u64 bytenr, u64 num_bytes);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,

commit 2ab28f322f9896782da904f5942f3873432addc8
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Oct 12 15:27:49 2012 -0400

    Btrfs: wait on ordered extents at the last possible moment
    
    Since we don't actually copy the extent information from the source tree in
    the fast case we don't need to wait for ordered io to be completed in order
    to fsync, we just need to wait for the io to be completed.  So when we're
    logging our file just attach all of the ordered extents to the log, and then
    when the log syncs just wait for IO_DONE on the ordered extents and then
    write the super.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 547b7b05727f..411c8d97074e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1623,6 +1623,9 @@ struct btrfs_root {
 
 	struct list_head root_list;
 
+	spinlock_t log_extents_lock[2];
+	struct list_head logged_list[2];
+
 	spinlock_t orphan_lock;
 	atomic_t orphan_inodes;
 	struct btrfs_block_rsv *orphan_block_rsv;

commit 4ae10b3a133e1147f3c818fe2ebaf005b217b7bf
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Thu Jan 31 14:42:09 2013 -0500

    Btrfs: Add a stripe cache to raid56
    
    The stripe cache allows us to avoid extra read/modify/write cycles
    by caching the pages we read off the disk.  Pages are cached when:
    
    * They are read in during a read/modify/write cycle
    
    * They are written during a read/modify/write cycle
    
    * They are involved in a parity rebuild
    
    Pages are not cached if we're doing a full stripe write.  We're
    assuming that a full stripe write won't be followed by another
    partial stripe write any time soon.
    
    This provides a substantial boost in performance for workloads that
    synchronously modify adjacent offsets in the file, and for the parity
    rebuild use case in general.
    
    The size of the stripe cache isn't tunable (yet) and is set at 1024
    entries.
    
    Example on flash: dd if=/dev/zero of=/mnt/xxx bs=4K oflag=direct
    
    Without the stripe cache  -- 2.1MB/s
    With the stripe cache 21MB/s
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0cce3aafbd62..e3a4fd70f55a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1244,7 +1244,10 @@ struct btrfs_stripe_hash {
 
 /* used by the raid56 code to lock stripes for read/modify/write */
 struct btrfs_stripe_hash_table {
-	struct btrfs_stripe_hash *table;
+	struct list_head stripe_cache;
+	spinlock_t cache_lock;
+	int cache_size;
+	struct btrfs_stripe_hash table[];
 };
 
 #define BTRFS_STRIPE_HASH_TABLE_BITS 11

commit 53b381b3abeb86f12787a6c40fee9b2f71edc23b
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Tue Jan 29 18:40:14 2013 -0500

    Btrfs: RAID5 and RAID6
    
    This builds on David Woodhouse's original Btrfs raid5/6 implementation.
    The code has changed quite a bit, blame Chris Mason for any bugs.
    
    Read/modify/write is done after the higher levels of the filesystem have
    prepared a given bio.  This means the higher layers are not responsible
    for building full stripes, and they don't need to query for the topology
    of the extents that may get allocated during delayed allocation runs.
    It also means different files can easily share the same stripe.
    
    But, it does expose us to incorrect parity if we crash or lose power
    while doing a read/modify/write cycle.  This will be addressed in a
    later commit.
    
    Scrub is unable to repair crc errors on raid5/6 chunks.
    
    Discard does not work on raid5/6 (yet)
    
    The stripe size is fixed at 64KiB per disk.  This will be tunable
    in a later commit.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0ab51be6879f..0cce3aafbd62 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -502,6 +502,7 @@ struct btrfs_super_block {
 #define BTRFS_FEATURE_INCOMPAT_BIG_METADATA	(1ULL << 5)
 
 #define BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF	(1ULL << 6)
+#define BTRFS_FEATURE_INCOMPAT_RAID56		(1ULL << 7)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
@@ -511,6 +512,7 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS |		\
 	 BTRFS_FEATURE_INCOMPAT_BIG_METADATA |		\
 	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO |		\
+	 BTRFS_FEATURE_INCOMPAT_RAID56 |		\
 	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF)
 
 /*
@@ -952,8 +954,10 @@ struct btrfs_dev_replace_item {
 #define BTRFS_BLOCK_GROUP_RAID1		(1ULL << 4)
 #define BTRFS_BLOCK_GROUP_DUP		(1ULL << 5)
 #define BTRFS_BLOCK_GROUP_RAID10	(1ULL << 6)
+#define BTRFS_BLOCK_GROUP_RAID5    (1 << 7)
+#define BTRFS_BLOCK_GROUP_RAID6    (1 << 8)
 #define BTRFS_BLOCK_GROUP_RESERVED	BTRFS_AVAIL_ALLOC_BIT_SINGLE
-#define BTRFS_NR_RAID_TYPES		5
+#define BTRFS_NR_RAID_TYPES		7
 
 #define BTRFS_BLOCK_GROUP_TYPE_MASK	(BTRFS_BLOCK_GROUP_DATA |    \
 					 BTRFS_BLOCK_GROUP_SYSTEM |  \
@@ -961,6 +965,8 @@ struct btrfs_dev_replace_item {
 
 #define BTRFS_BLOCK_GROUP_PROFILE_MASK	(BTRFS_BLOCK_GROUP_RAID0 |   \
 					 BTRFS_BLOCK_GROUP_RAID1 |   \
+					 BTRFS_BLOCK_GROUP_RAID5 |   \
+					 BTRFS_BLOCK_GROUP_RAID6 |   \
 					 BTRFS_BLOCK_GROUP_DUP |     \
 					 BTRFS_BLOCK_GROUP_RAID10)
 /*
@@ -1185,6 +1191,10 @@ struct btrfs_block_group_cache {
 	u64 flags;
 	u64 sectorsize;
 	u64 cache_generation;
+
+	/* for raid56, this is a full stripe, without parity */
+	unsigned long full_stripe_len;
+
 	unsigned int ro:1;
 	unsigned int dirty:1;
 	unsigned int iref:1;
@@ -1225,6 +1235,20 @@ struct seq_list {
 	u64 seq;
 };
 
+/* used by the raid56 code to lock stripes for read/modify/write */
+struct btrfs_stripe_hash {
+	struct list_head hash_list;
+	wait_queue_head_t wait;
+	spinlock_t lock;
+};
+
+/* used by the raid56 code to lock stripes for read/modify/write */
+struct btrfs_stripe_hash_table {
+	struct btrfs_stripe_hash *table;
+};
+
+#define BTRFS_STRIPE_HASH_TABLE_BITS 11
+
 /* fs_info */
 struct reloc_control;
 struct btrfs_device;
@@ -1307,6 +1331,13 @@ struct btrfs_fs_info {
 	struct mutex cleaner_mutex;
 	struct mutex chunk_mutex;
 	struct mutex volume_mutex;
+
+	/* this is used during read/modify/write to make sure
+	 * no two ios are trying to mod the same stripe at the same
+	 * time
+	 */
+	struct btrfs_stripe_hash_table *stripe_hash_table;
+
 	/*
 	 * this protects the ordered operations list only while we are
 	 * processing all of the entries on it.  This way we make
@@ -1395,6 +1426,8 @@ struct btrfs_fs_info {
 	struct btrfs_workers flush_workers;
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers endio_meta_workers;
+	struct btrfs_workers endio_raid56_workers;
+	struct btrfs_workers rmw_workers;
 	struct btrfs_workers endio_meta_write_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers endio_freespace_worker;

commit 64a167011bcabc1e855658387c8a4464b71f3138
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Jul 15 23:29:37 2009 +0100

    Btrfs: add rw argument to merge_bio_hook()
    
    We'll want to merge writes so they can fill a full RAID[56] stripe, but
    not necessarily reads.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 547b7b05727f..0ab51be6879f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3459,9 +3459,9 @@ int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *new_root, u64 new_dirid);
-int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
-			 size_t size, struct bio *bio, unsigned long bio_flags);
-
+int btrfs_merge_bio_hook(int rw, struct page *page, unsigned long offset,
+			 size_t size, struct bio *bio,
+			 unsigned long bio_flags);
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);

commit 9c52057c698fb96f8f07e7a4bcf4801a092bda89
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Mon Dec 17 14:26:57 2012 -0500

    Btrfs: fix hash overflow handling
    
    The handling for directory crc hash overflows was fairly obscure,
    split_leaf returns EOVERFLOW when we try to extend the item and that is
    supposed to bubble up to userland.  For a while it did so, but along the
    way we added better handling of errors and forced the FS readonly if we
    hit IO errors during the directory insertion.
    
    Along the way, we started testing only for EEXIST and the EOVERFLOW case
    was dropped.  The end result is that we may force the FS readonly if we
    catch a directory hash bucket overflow.
    
    This fixes a few problem spots.  First I add tests for EOVERFLOW in the
    places where we can safely just return the error up the chain.
    
    btrfs_rename is harder though, because it tries to insert the new
    directory item only after it has already unlinked anything the rename
    was going to overwrite.  Rather than adding very complex logic, I added
    a helper to test for the hash overflow case early while it is still safe
    to bail out.
    
    Snapshot and subvolume creation had a similar problem, so they are using
    the new helper now too.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    Reported-by: Pascal Junod <pascal@junod.info>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 44d9bc87e863..547b7b05727f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3283,6 +3283,8 @@ void btrfs_update_root_times(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
 
 /* dir-item.c */
+int btrfs_check_dir_item_collision(struct btrfs_root *root, u64 dir,
+			  const char *name, int name_len);
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, const char *name,
 			  int name_len, struct inode *dir,

commit 31e502298d80e2af9001d17dc419a3fd4b0bebef
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Nov 21 14:18:10 2012 +0000

    Btrfs: put raid properties into global table
    
    Raid properties can be shared among raid calculation code, we can put
    them into a global table to keep it simple.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cd02205f13c8..44d9bc87e863 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3077,6 +3077,7 @@ int btrfs_trim_fs(struct btrfs_root *root, struct fstrim_range *range);
 int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
+int __get_raid_index(u64 flags);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit ad9145596986b672d8c8235c92ed5307f82d045d
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Oct 15 13:39:33 2012 -0400

    Btrfs: don't memset new tokens
    
    Our token logic depends on token->kaddr being set, and if it is not it sets
    everything properly as needed.  So instead of memsetting just set
    token->kaddr to NULL.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 55aff6764bb9..cd02205f13c8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1860,7 +1860,7 @@ struct btrfs_map_token {
 
 static inline void btrfs_init_map_token (struct btrfs_map_token *token)
 {
-	memset(token, 0, sizeof(*token));
+	token->kaddr = NULL;
 }
 
 /* some macros to generate set/get funcs for the struct fields.  This

commit 70c8a91ce21b83ccd2d9e7c968775430ead4353d
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Oct 11 16:54:30 2012 -0400

    Btrfs: log changed inodes based on the extent map tree
    
    We don't really need to copy extents from the source tree since we have all
    of the information already available to us in the extent_map tree.  So
    instead just write the extents straight to the log tree and don't bother to
    copy the extent items from the source tree.
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9ed452f5d062..55aff6764bb9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3187,6 +3187,9 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 }
 
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
+int btrfs_next_leaf_write(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root, struct btrfs_path *path,
+			  int del);
 int btrfs_next_old_leaf(struct btrfs_root *root, struct btrfs_path *path,
 			u64 time_seq);
 static inline int btrfs_next_old_item(struct btrfs_root *root,

commit d6393786cd40f67709324bc4f08d7e4b911153fe
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Dec 12 17:00:01 2012 -0500

    Btrfs: add path->really_keep_locks
    
    You'd think path->keep_locks would keep all the locks wouldn't you?  You'd
    be wrong.  It only keeps them if the slot is pointing to the last item in
    the node.  This is for use with btrfs_next_leaf, which needs this sort of
    thing.  But the horrible horrible things I'm going to do to the tree log
    means I really need everything held from root to leaf so I can add and
    delete items in the same search.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 313a6adfde55..9ed452f5d062 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -576,6 +576,7 @@ struct btrfs_path {
 	unsigned int skip_locking:1;
 	unsigned int leave_spinning:1;
 	unsigned int search_commit_root:1;
+	unsigned int really_keep_locks:1;
 };
 
 /*

commit 5f3ab90a72f98adbf00c50ac2d4d2b47cf4a9685
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Dec 7 09:28:54 2012 +0000

    Btrfs: rename root_times_lock to root_item_lock
    
    Originally root_times_lock was introduced as part of send/receive
    code however newly developed patch to label the subvol reused
    the same lock, so renaming it for a meaningful name.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6ba56aea5b62..313a6adfde55 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1645,7 +1645,7 @@ struct btrfs_root {
 
 	int force_cow;
 
-	spinlock_t root_times_lock;
+	spinlock_t root_item_lock;
 };
 
 struct btrfs_ioctl_defrag_range_args {

commit 26176e7c2aa923327becdc25b5aca2cb907ac932
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Nov 26 09:26:20 2012 +0000

    Btrfs: restructure btrfs_run_defrag_inodes()
    
    This patch restructure btrfs_run_defrag_inodes() and make the code of the auto
    defragment more readable.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 389c05715eaa..6ba56aea5b62 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3510,6 +3510,7 @@ void btrfs_auto_defrag_exit(void);
 int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 			   struct inode *inode);
 int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
+void btrfs_cleanup_defrag_inodes(struct btrfs_fs_info *fs_info);
 int btrfs_sync_file(struct file *file, loff_t start, loff_t end, int datasync);
 void btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			     int skip_pinned);

commit 9247f3170b2c3d648707c93bbebcd763fac17c06
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Nov 26 09:24:43 2012 +0000

    Btrfs: use slabs for auto defrag allocation
    
    The auto defrag allocation is in the fast path of the IO, so use slabs
    to improve the speed of the allocation.
    
    And besides that, it can do check for leaked objects when the module is removed.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 91ff078e85df..389c05715eaa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3505,6 +3505,8 @@ void btrfs_get_block_group_info(struct list_head *groups_list,
 				struct btrfs_ioctl_space_info *space);
 
 /* file.c */
+int btrfs_auto_defrag_init(void);
+void btrfs_auto_defrag_exit(void);
 int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 			   struct inode *inode);
 int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);

commit 72d7aefccd512b66cd5543e652eae04be12085fc
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Nov 6 14:57:46 2012 +0100

    Btrfs: increase BTRFS_MAX_MIRRORS by one for dev replace
    
    This change of the define is effective in all modes, it
    is required and used only in the case when a device replace
    procedure is running. The reason is that during an active
    device replace procedure, the target device of the copy
    operation is a mirror for the filesystem data as well that
    can be used to read data in order to repair read errors on
    other disks.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 46bd7d5f504b..91ff078e85df 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -48,7 +48,7 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAGIC "_BHRfS_M"
 
-#define BTRFS_MAX_MIRRORS 2
+#define BTRFS_MAX_MIRRORS 3
 
 #define BTRFS_MAX_LEVEL 8
 

commit 29a8d9a0bce6a5abac1f313400c2e189e8d10e67
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Nov 6 14:16:24 2012 +0100

    Btrfs: introduce GET_READ_MIRRORS functionality for btrfs_map_block()
    
    Before this commit, btrfs_map_block() was called with REQ_WRITE
    in order to retrieve the list of mirrors for a disk block.
    This needs to be changed for the device replace procedure since
    it makes a difference whether you are asking for read mirrors
    or for locations to write to.
    GET_READ_MIRRORS is introduced as a new interface to call
    btrfs_map_block().
    In the current commit, the functionality is not yet changed,
    only the interface for GET_READ_MIRRORS is introduced and all
    the places that should use this new interface are adapted.
    
    The reason that REQ_WRITE cannot be abused anymore to retrieve
    a list of read mirrors is that during a running dev replace
    operation all write requests to the live filesystem are
    duplicated to also write to the target drive.
    Keep in mind that the target disk is only partially a valid
    copy of the source disk while the operation is ongoing. All
    writes go to the target disk, but not all reads would return
    valid data on the target disk. Therefore it is not possible
    anymore to abuse a REQ_WRITE interface to find valid mirrors
    for a REQ_READ.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 45e7f752b64a..46bd7d5f504b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -174,6 +174,9 @@ static int btrfs_csum_sizes[] = { 4, 0 };
 /* four bytes for CRC32 */
 #define BTRFS_EMPTY_DIR_SIZE 0
 
+/* spefic to btrfs_map_block(), therefore not in include/linux/blk_types.h */
+#define REQ_GET_READ_MIRRORS	(1 << 30)
+
 #define BTRFS_FT_UNKNOWN	0
 #define BTRFS_FT_REG_FILE	1
 #define BTRFS_FT_DIR		2

commit e93c89c1aaaaaec3487c4c18dd02360371790722
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 17:33:06 2012 +0100

    Btrfs: add new sources for device replace code
    
    This adds a new file to the sources together with the header file
    and the changes to ioctl.h and ctree.h that are required by the
    new C source file. Additionally, 4 new functions are added to
    volume.c that deal with device creation and destruction.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ded7caa0d304..45e7f752b64a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -142,6 +142,8 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_EMPTY_SUBVOL_DIR_OBJECTID 2
 
+#define BTRFS_DEV_REPLACE_DEVID 0
+
 /*
  * the max metadata block size.  This limit is somewhat artificial,
  * but the memmove costs go through the roof for larger blocks.

commit ff023aac31198e88507d626825379b28ea481d4d
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Nov 6 11:43:11 2012 +0100

    Btrfs: add code to scrub to copy read data to another disk
    
    The device replace procedure makes use of the scrub code. The scrub
    code is the most efficient code to read the allocated data of a disk,
    i.e. it reads sequentially in order to avoid disk head movements, it
    skips unallocated blocks, it uses read ahead mechanisms, and it
    contains all the code to detect and repair defects.
    This commit adds code to scrub to allow the scrub code to copy read
    data to another disk.
    One goal is to be able to perform as fast as possible. Therefore the
    write requests are collected until huge bios are built, and the
    write process is decoupled from the read process with some kind of
    flow control, of course, in order to limit the allocated memory.
    The best performance on spinning disks could by reached when the
    head movements are avoided as much as possible. Therefore a single
    worker is used to interface the read process with the write process.
    The regular scrub operation works as fast as before, it is not
    negatively influenced and actually it is more or less unchanged.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 746cb6aa1f62..ded7caa0d304 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1483,6 +1483,8 @@ struct btrfs_fs_info {
 	struct rw_semaphore scrub_super_lock;
 	int scrub_workers_refcnt;
 	struct btrfs_workers scrub_workers;
+	struct btrfs_workers scrub_wr_completion_workers;
+	struct btrfs_workers scrub_nocow_workers;
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	u32 check_integrity_print_mask;

commit 63a212abc2315972b245f93cb11ae3acf3c0b513
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 18:29:28 2012 +0100

    Btrfs: disallow some operations on the device replace target device
    
    This patch adds some code to disallow operations on the device that
    is used as the target for the device replace operation.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e9dc78014f09..746cb6aa1f62 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3649,7 +3649,7 @@ int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 /* scrub.c */
 int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,
 		    u64 end, struct btrfs_scrub_progress *progress,
-		    int readonly);
+		    int readonly, int is_dev_replace);
 void btrfs_scrub_pause(struct btrfs_root *root);
 void btrfs_scrub_pause_super(struct btrfs_root *root);
 void btrfs_scrub_continue(struct btrfs_root *root);

commit 5ac00addc7ac09110995fe967071d191b5981cc1
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 17:54:08 2012 +0100

    Btrfs: disallow mutually exclusive admin operations from user mode
    
    Btrfs admin operations that are manually started from user mode
    and that cannot be executed at the same time return -EINPROGRESS.
    A common way to enter and leave this locked section is introduced
    since it used to be specific to the balance operation.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 147406d0f9a9..e9dc78014f09 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1527,6 +1527,8 @@ struct btrfs_fs_info {
 
 	/* device replace state */
 	struct btrfs_dev_replace dev_replace;
+
+	atomic_t mutually_exclusive_operation_running;
 };
 
 /*

commit a2bff64025d7a707ac49155bb6678a636e55096e
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 17:32:20 2012 +0100

    Btrfs: introduce a btrfs_dev_replace_item type
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0781fd4a5c1a..147406d0f9a9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -921,6 +921,23 @@ struct btrfs_dev_replace {
 	struct btrfs_scrub_progress scrub_progress;
 };
 
+struct btrfs_dev_replace_item {
+	/*
+	 * grow this item struct at the end for future enhancements and keep
+	 * the existing values unchanged
+	 */
+	__le64 src_devid;
+	__le64 cursor_left;
+	__le64 cursor_right;
+	__le64 cont_reading_from_srcdev_mode;
+
+	__le64 replace_state;
+	__le64 time_started;
+	__le64 time_stopped;
+	__le64 num_write_errors;
+	__le64 num_uncorrectable_read_errors;
+} __attribute__ ((__packed__));
+
 /* different types of block groups (and chunks) */
 #define BTRFS_BLOCK_GROUP_DATA		(1ULL << 0)
 #define BTRFS_BLOCK_GROUP_SYSTEM	(1ULL << 1)
@@ -1762,6 +1779,12 @@ struct btrfs_ioctl_defrag_range_args {
  */
 #define BTRFS_DEV_STATS_KEY	249
 
+/*
+ * Persistantly stores the device replace state in the device tree.
+ * The key is built like this: (0, BTRFS_DEV_REPLACE_KEY, 0).
+ */
+#define BTRFS_DEV_REPLACE_KEY	250
+
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
@@ -2795,6 +2818,49 @@ BTRFS_SETGET_FUNCS(qgroup_limit_rsv_rfer, struct btrfs_qgroup_limit_item,
 BTRFS_SETGET_FUNCS(qgroup_limit_rsv_excl, struct btrfs_qgroup_limit_item,
 		   rsv_excl, 64);
 
+/* btrfs_dev_replace_item */
+BTRFS_SETGET_FUNCS(dev_replace_src_devid,
+		   struct btrfs_dev_replace_item, src_devid, 64);
+BTRFS_SETGET_FUNCS(dev_replace_cont_reading_from_srcdev_mode,
+		   struct btrfs_dev_replace_item, cont_reading_from_srcdev_mode,
+		   64);
+BTRFS_SETGET_FUNCS(dev_replace_replace_state, struct btrfs_dev_replace_item,
+		   replace_state, 64);
+BTRFS_SETGET_FUNCS(dev_replace_time_started, struct btrfs_dev_replace_item,
+		   time_started, 64);
+BTRFS_SETGET_FUNCS(dev_replace_time_stopped, struct btrfs_dev_replace_item,
+		   time_stopped, 64);
+BTRFS_SETGET_FUNCS(dev_replace_num_write_errors, struct btrfs_dev_replace_item,
+		   num_write_errors, 64);
+BTRFS_SETGET_FUNCS(dev_replace_num_uncorrectable_read_errors,
+		   struct btrfs_dev_replace_item, num_uncorrectable_read_errors,
+		   64);
+BTRFS_SETGET_FUNCS(dev_replace_cursor_left, struct btrfs_dev_replace_item,
+		   cursor_left, 64);
+BTRFS_SETGET_FUNCS(dev_replace_cursor_right, struct btrfs_dev_replace_item,
+		   cursor_right, 64);
+
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_src_devid,
+			 struct btrfs_dev_replace_item, src_devid, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cont_reading_from_srcdev_mode,
+			 struct btrfs_dev_replace_item,
+			 cont_reading_from_srcdev_mode, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_replace_state,
+			 struct btrfs_dev_replace_item, replace_state, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_time_started,
+			 struct btrfs_dev_replace_item, time_started, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_time_stopped,
+			 struct btrfs_dev_replace_item, time_stopped, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_num_write_errors,
+			 struct btrfs_dev_replace_item, num_write_errors, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_num_uncorrectable_read_errors,
+			 struct btrfs_dev_replace_item,
+			 num_uncorrectable_read_errors, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cursor_left,
+			 struct btrfs_dev_replace_item, cursor_left, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_dev_replace_cursor_right,
+			 struct btrfs_dev_replace_item, cursor_right, 64);
+
 static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;

commit e922e087a35c437acef3bc88ce31e59c699c38bd
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 17:26:40 2012 +0100

    Btrfs: enhance btrfs structures for device replace support
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f8bb62c82b0c..0781fd4a5c1a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -885,6 +885,42 @@ struct btrfs_dev_stats_item {
 	__le64 values[BTRFS_DEV_STAT_VALUES_MAX];
 } __attribute__ ((__packed__));
 
+#define BTRFS_DEV_REPLACE_ITEM_CONT_READING_FROM_SRCDEV_MODE_ALWAYS	0
+#define BTRFS_DEV_REPLACE_ITEM_CONT_READING_FROM_SRCDEV_MODE_AVOID	1
+#define BTRFS_DEV_REPLACE_ITEM_STATE_NEVER_STARTED	0
+#define BTRFS_DEV_REPLACE_ITEM_STATE_STARTED		1
+#define BTRFS_DEV_REPLACE_ITEM_STATE_SUSPENDED		2
+#define BTRFS_DEV_REPLACE_ITEM_STATE_FINISHED		3
+#define BTRFS_DEV_REPLACE_ITEM_STATE_CANCELED		4
+
+struct btrfs_dev_replace {
+	u64 replace_state;	/* see #define above */
+	u64 time_started;	/* seconds since 1-Jan-1970 */
+	u64 time_stopped;	/* seconds since 1-Jan-1970 */
+	atomic64_t num_write_errors;
+	atomic64_t num_uncorrectable_read_errors;
+
+	u64 cursor_left;
+	u64 committed_cursor_left;
+	u64 cursor_left_last_write_of_item;
+	u64 cursor_right;
+
+	u64 cont_reading_from_srcdev_mode;	/* see #define above */
+
+	int is_valid;
+	int item_needs_writeback;
+	struct btrfs_device *srcdev;
+	struct btrfs_device *tgtdev;
+
+	pid_t lock_owner;
+	atomic_t nesting_level;
+	struct mutex lock_finishing_cancel_unmount;
+	struct mutex lock_management_lock;
+	struct mutex lock;
+
+	struct btrfs_scrub_progress scrub_progress;
+};
+
 /* different types of block groups (and chunks) */
 #define BTRFS_BLOCK_GROUP_DATA		(1ULL << 0)
 #define BTRFS_BLOCK_GROUP_SYSTEM	(1ULL << 1)
@@ -1471,6 +1507,9 @@ struct btrfs_fs_info {
 	int backup_root_index;
 
 	int num_tolerated_disk_barrier_failures;
+
+	/* device replace state */
+	struct btrfs_dev_replace dev_replace;
 };
 
 /*

commit aa1b8cd409f05e1489ec77ff219eff6ed4b801b8
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 17:03:39 2012 +0100

    Btrfs: pass fs_info instead of root
    
    A small number of functions that are used in a device replace
    procedure when the operation is resumed at mount time are unable
    to pass the same root pointer that would be used in the regular
    (ioctl) context. And since the root pointer is not required, only
    the fs_info is, the root pointer argument is replaced with the
    fs_info pointer argument.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f9a078661ebc..f8bb62c82b0c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3540,15 +3540,16 @@ int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending);
 
 /* scrub.c */
-int btrfs_scrub_dev(struct btrfs_root *root, u64 devid, u64 start, u64 end,
-		    struct btrfs_scrub_progress *progress, int readonly);
+int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,
+		    u64 end, struct btrfs_scrub_progress *progress,
+		    int readonly);
 void btrfs_scrub_pause(struct btrfs_root *root);
 void btrfs_scrub_pause_super(struct btrfs_root *root);
 void btrfs_scrub_continue(struct btrfs_root *root);
 void btrfs_scrub_continue_super(struct btrfs_root *root);
-int __btrfs_scrub_cancel(struct btrfs_fs_info *info);
-int btrfs_scrub_cancel(struct btrfs_root *root);
-int btrfs_scrub_cancel_dev(struct btrfs_root *root, struct btrfs_device *dev);
+int btrfs_scrub_cancel(struct btrfs_fs_info *info);
+int btrfs_scrub_cancel_dev(struct btrfs_fs_info *info,
+			   struct btrfs_device *dev);
 int btrfs_scrub_cancel_devid(struct btrfs_root *root, u64 devid);
 int btrfs_scrub_progress(struct btrfs_root *root, u64 devid,
 			 struct btrfs_scrub_progress *progress);

commit 315a9850da2b89c83971b26fe54a60f22bdd91ad
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Nov 1 07:33:59 2012 +0000

    Btrfs: fix wrong file extent length
    
    There are two types of the file extent - inline extent and regular extent,
    When we log file extents, we didn't take inline extent into account, fix it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2d41cb25266b..f9a078661ebc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3263,6 +3263,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
 			     u64 bytenr, int mod);
+u64 btrfs_file_extent_length(struct btrfs_path *path);
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums);

commit d1423248734df6d9aff769abffd675dc034e0601
Author: Masanari Iida <standby24x7@gmail.com>
Date:   Wed Oct 31 15:16:32 2012 +0000

    Btrfs: Fix typo in fs/btrfs
    
    Correct spelling typo in btrfs.
    
    Signed-off-by: Masanari Iida <standby24x7@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cad16566da37..2d41cb25266b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -413,7 +413,7 @@ struct btrfs_root_backup {
 	__le64 bytes_used;
 	__le64 num_devices;
 	/* future */
-	__le64 unsed_64[4];
+	__le64 unused_64[4];
 
 	u8 tree_root_level;
 	u8 chunk_root_level;

commit 8ccf6f19b67f7e0921063cc309f4672a6afcb528
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Oct 25 09:28:04 2012 +0000

    Btrfs: make delalloc inodes be flushed by multi-task
    
    This patch introduce a new worker pool named "flush_workers", and if we
    want to force all the inode with pending delalloc to the disks, we can
    queue those inodes into the work queue of the worker pool, in this way,
    those inodes will be flushed by multi-task.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8fd9fe4282f5..cad16566da37 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1333,6 +1333,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers generic_worker;
 	struct btrfs_workers workers;
 	struct btrfs_workers delalloc_workers;
+	struct btrfs_workers flush_workers;
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers endio_meta_workers;
 	struct btrfs_workers endio_meta_write_workers;
@@ -3277,6 +3278,19 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit);
 /* inode.c */
+struct btrfs_delalloc_work {
+	struct inode *inode;
+	int wait;
+	int delay_iput;
+	struct completion completion;
+	struct list_head list;
+	struct btrfs_work work;
+};
+
+struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,
+						    int wait, int delay_iput);
+void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work);
+
 struct extent_map *btrfs_get_extent_fiemap(struct inode *inode, struct page *page,
 					   size_t pg_offset, u64 start, u64 len,
 					   int create);

commit 08e007d2e57744472a9424735a368ffe6d625597
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Oct 16 11:33:38 2012 +0000

    Btrfs: improve the noflush reservation
    
    In some places(such as: evicting inode), we just can not flush the reserved
    space of delalloc, flushing the delayed directory index and delayed inode
    is OK, but we don't try to flush those things and just go back when there is
    no enough space to be reserved. This patch fixes this problem.
    
    We defined 3 types of the flush operations: NO_FLUSH, FLUSH_LIMIT and FLUSH_ALL.
    If we can in the transaction, we should not flush anything, or the deadlock
    would happen, so use NO_FLUSH. If we flushing the reserved space of delalloc
    would cause deadlock, use FLUSH_LIMIT. In the other cases, FLUSH_ALL is used,
    and we will flush all things.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c72ead869507..8fd9fe4282f5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2900,6 +2900,18 @@ void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
+
+enum btrfs_reserve_flush_enum {
+	/* If we are in the transaction, we can't flush anything.*/
+	BTRFS_RESERVE_NO_FLUSH,
+	/*
+	 * Flushing delalloc may cause deadlock somewhere, in this
+	 * case, use FLUSH LIMIT
+	 */
+	BTRFS_RESERVE_FLUSH_LIMIT,
+	BTRFS_RESERVE_FLUSH_ALL,
+};
+
 int btrfs_check_data_free_space(struct inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
@@ -2919,19 +2931,13 @@ struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root,
 void btrfs_free_block_rsv(struct btrfs_root *root,
 			  struct btrfs_block_rsv *rsv);
 int btrfs_block_rsv_add(struct btrfs_root *root,
-			struct btrfs_block_rsv *block_rsv,
-			u64 num_bytes);
-int btrfs_block_rsv_add_noflush(struct btrfs_root *root,
-				struct btrfs_block_rsv *block_rsv,
-				u64 num_bytes);
+			struct btrfs_block_rsv *block_rsv, u64 num_bytes,
+			enum btrfs_reserve_flush_enum flush);
 int btrfs_block_rsv_check(struct btrfs_root *root,
 			  struct btrfs_block_rsv *block_rsv, int min_factor);
 int btrfs_block_rsv_refill(struct btrfs_root *root,
-			  struct btrfs_block_rsv *block_rsv,
-			  u64 min_reserved);
-int btrfs_block_rsv_refill_noflush(struct btrfs_root *root,
-				   struct btrfs_block_rsv *block_rsv,
-				   u64 min_reserved);
+			   struct btrfs_block_rsv *block_rsv, u64 min_reserved,
+			   enum btrfs_reserve_flush_enum flush);
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 			    struct btrfs_block_rsv *dst_rsv,
 			    u64 num_bytes);

commit f48d42773bd14cfb9f392f32eff1856f924a9e6a
Merge: b394209ce528 c37b2b6269ee
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 26 09:34:04 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This has our series of fixes for the next rc.  The biggest batch is
      from Jan Schmidt, fixing up some problems in our subvolume quota code
      and fixing btrfs send/receive to work with the new extended inode
      refs."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: do not bug when we fail to commit the transaction
      Btrfs: fix memory leak when cloning root's node
      Btrfs: Use btrfs_update_inode_fallback when creating a snapshot
      Btrfs: Send: preserve ownership (uid and gid) also for symlinks.
      Btrfs: fix deadlock caused by the nested chunk allocation
      btrfs: Return EINVAL when length to trim is less than FSB
      Btrfs: fix memory leak in btrfs_quota_enable()
      Btrfs: send correct rdev and mode in btrfs-send
      Btrfs: extended inode refs support for send mechanism
      Btrfs: Fix wrong error handling code
      Fix a sign bug causing invalid memory access in the ino_paths ioctl.
      Btrfs: comment for loop in tree_mod_log_insert_move
      Btrfs: fix extent buffer reference for tree mod log roots
      Btrfs: determine level of old roots
      Btrfs: tree mod log's old roots could still be part of the tree
      Btrfs: fix a tree mod logging issue for root replacement operations
      Btrfs: don't put removals from push_node_left into tree mod log twice

commit c657c3ef1adb2585ed7d2a6db73d0002926a6726
Merge: be6aef604920 01763a2e3742
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Thu Oct 25 15:53:10 2012 -0400

    Merge branch 'for-chris-fixed' of git://git.jan-o-sch.net/btrfs-unstable

commit be6aef604920406b348acf3be6e6e8db55696386
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Oct 22 15:43:12 2012 -0400

    Btrfs: Use btrfs_update_inode_fallback when creating a snapshot
    
    On a really full file system I was getting ENOSPC back from
    btrfs_update_inode when trying to update the parent inode when creating a
    snapshot.  Just use the fallback method so we can update the inode and not
    have to worry about having a delayed ref.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1630be831210..8a92ab1632a2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3338,6 +3338,8 @@ struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
 int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode);
+int btrfs_update_inode_fallback(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root, struct inode *inode);
 int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_cleanup(struct btrfs_root *root);

commit 5b6602e762cae17c8891d19698afea451e9c1d95
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Tue Oct 23 11:28:27 2012 +0200

    Btrfs: determine level of old roots
    
    In btrfs_find_all_roots' termination condition, we compare the level of the
    old buffer we got from btrfs_search_old_slot to the level of the current
    root node. We'd better compare it to the level of the rewinded root node.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1630be831210..34c5a442dd33 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3120,6 +3120,7 @@ static inline u64 btrfs_inc_tree_mod_seq(struct btrfs_fs_info *fs_info)
 {
 	return atomic_inc_return(&fs_info->tree_mod_seq);
 }
+int btrfs_old_root_level(struct btrfs_root *root, u64 time_seq);
 
 /* root-item.c */
 int btrfs_find_root_ref(struct btrfs_root *tree_root,

commit 72055425e53540d9d0e59a57ac8c9b8ce77b62d5
Merge: fc81c038c2d6 f46dbe3dee85
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 10 10:49:20 2012 +0900

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs update from Chris Mason:
     "This is a large pull, with the bulk of the updates coming from:
    
       - Hole punching
    
       - send/receive fixes
    
       - fsync performance
    
       - Disk format extension allowing more hardlinks inside a single
         directory (btrfs-progs patch required to enable the compat bit for
         this one)
    
      I'm cooking more unrelated RAID code, but I wanted to make sure this
      original batch makes it in.  The largest updates here are relatively
      old and have been in testing for some time."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (121 commits)
      btrfs: init ref_index to zero in add_inode_ref
      Btrfs: remove repeated eb->pages check in, disk-io.c/csum_dirty_buffer
      Btrfs: fix page leakage
      Btrfs: do not warn_on when we cannot alloc a page for an extent buffer
      Btrfs: don't bug on enomem in readpage
      Btrfs: cleanup pages properly when ENOMEM in compression
      Btrfs: make filesystem read-only when submitting barrier fails
      Btrfs: detect corrupted filesystem after write I/O errors
      Btrfs: make compress and nodatacow mount options mutually exclusive
      btrfs: fix message printing
      Btrfs: don't bother committing delayed inode updates when fsyncing
      btrfs: move inline function code to header file
      Btrfs: remove unnecessary IS_ERR in bio_readpage_error()
      btrfs: remove unused function btrfs_insert_some_items()
      Btrfs: don't commit instead of overcommitting
      Btrfs: confirmation of value is added before trace_btrfs_get_extent() is called
      Btrfs: be smarter about dropping things from the tree log
      Btrfs: don't lookup csums for prealloc extents
      Btrfs: cache extent state when writing out dirty metadata pages
      Btrfs: do not hold the file extent leaf locked when adding extent item
      ...

commit 5af3e8cce8b7ba0a2819e18c9146c8c0b452d479
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Aug 1 18:56:49 2012 +0200

    Btrfs: make filesystem read-only when submitting barrier fails
    
    So far the return code of barrier_all_devices() is ignored, which
    means that errors are ignored. The result can be a corrupt
    filesystem which is not consistent.
    This commit adds code to evaluate the return code of
    barrier_all_devices(). The normal btrfs_error() mechanism is used to
    switch the filesystem into read-only mode when errors are detected.
    
    In order to decide whether barrier_all_devices() should return
    error or success, the number of disks that are allowed to fail the
    barrier submission is calculated. This calculation accounts for the
    worst RAID level of metadata, system and data. If single, dup or
    RAID0 is in use, a single disk error is already considered to be
    fatal. Otherwise a single disk error is tolerated.
    
    The calculation of the number of disks that are tolerated to fail
    the barrier operation is performed when the filesystem gets mounted,
    when a balance operation is started and finished, and when devices
    are added or removed.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 50dcd0fbae11..1630be831210 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1468,6 +1468,8 @@ struct btrfs_fs_info {
 
 	/* next backup root to be overwritten */
 	int backup_root_index;
+
+	int num_tolerated_disk_barrier_failures;
 };
 
 /*
@@ -3361,6 +3363,9 @@ void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
 int btrfs_defrag_file(struct inode *inode, struct file *file,
 		      struct btrfs_ioctl_defrag_range_args *range,
 		      u64 newer_than, unsigned long max_pages);
+void btrfs_get_block_group_info(struct list_head *groups_list,
+				struct btrfs_ioctl_space_info *space);
+
 /* file.c */
 int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 			   struct inode *inode);

commit f186373fef005cee948a4a39e6a14c2e5f517298
Author: Mark Fasheh <mfasheh@suse.de>
Date:   Wed Aug 8 11:32:27 2012 -0700

    btrfs: extended inode refs
    
    This patch adds basic support for extended inode refs. This includes support
    for link and unlink of the refs, which basically gets us support for rename
    as well.
    
    Inode creation does not need changing - extended refs are only added after
    the ref array is full.
    
    Signed-off-by: Mark Fasheh <mfasheh@suse.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 399521ab61da..50dcd0fbae11 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -154,6 +154,13 @@ struct btrfs_ordered_sum;
  */
 #define BTRFS_NAME_LEN 255
 
+/*
+ * Theoretical limit is larger, but we keep this down to a sane
+ * value. That should limit greatly the possibility of collisions on
+ * inode ref items.
+ */
+#define BTRFS_LINK_MAX 65535U
+
 /* 32 bytes in various csum fields */
 #define BTRFS_CSUM_SIZE 32
 
@@ -489,6 +496,8 @@ struct btrfs_super_block {
  */
 #define BTRFS_FEATURE_INCOMPAT_BIG_METADATA	(1ULL << 5)
 
+#define BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF	(1ULL << 6)
+
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
 #define BTRFS_FEATURE_INCOMPAT_SUPP			\
@@ -496,7 +505,8 @@ struct btrfs_super_block {
 	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL |	\
 	 BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS |		\
 	 BTRFS_FEATURE_INCOMPAT_BIG_METADATA |		\
-	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO)
+	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO |		\
+	 BTRFS_FEATURE_INCOMPAT_EXTENDED_IREF)
 
 /*
  * A leaf is full of items. offset and size tell us where to find
@@ -643,6 +653,14 @@ struct btrfs_inode_ref {
 	/* name goes here */
 } __attribute__ ((__packed__));
 
+struct btrfs_inode_extref {
+	__le64 parent_objectid;
+	__le64 index;
+	__le16 name_len;
+	__u8   name[0];
+	/* name goes here */
+} __attribute__ ((__packed__));
+
 struct btrfs_timespec {
 	__le64 sec;
 	__le32 nsec;
@@ -1601,6 +1619,7 @@ struct btrfs_ioctl_defrag_range_args {
  */
 #define BTRFS_INODE_ITEM_KEY		1
 #define BTRFS_INODE_REF_KEY		12
+#define BTRFS_INODE_EXTREF_KEY		13
 #define BTRFS_XATTR_ITEM_KEY		24
 #define BTRFS_ORPHAN_ITEM_KEY		48
 /* reserve 2-15 close to the inode for later flexibility */
@@ -1987,6 +2006,13 @@ BTRFS_SETGET_STACK_FUNCS(block_group_flags,
 BTRFS_SETGET_FUNCS(inode_ref_name_len, struct btrfs_inode_ref, name_len, 16);
 BTRFS_SETGET_FUNCS(inode_ref_index, struct btrfs_inode_ref, index, 64);
 
+/* struct btrfs_inode_extref */
+BTRFS_SETGET_FUNCS(inode_extref_parent, struct btrfs_inode_extref,
+		   parent_objectid, 64);
+BTRFS_SETGET_FUNCS(inode_extref_name_len, struct btrfs_inode_extref,
+		   name_len, 16);
+BTRFS_SETGET_FUNCS(inode_extref_index, struct btrfs_inode_extref, index, 64);
+
 /* struct btrfs_inode_item */
 BTRFS_SETGET_FUNCS(inode_generation, struct btrfs_inode_item, generation, 64);
 BTRFS_SETGET_FUNCS(inode_sequence, struct btrfs_inode_item, sequence, 64);
@@ -3184,12 +3210,12 @@ int btrfs_del_inode_ref(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   const char *name, int name_len,
 			   u64 inode_objectid, u64 ref_objectid, u64 *index);
-struct btrfs_inode_ref *
-btrfs_lookup_inode_ref(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root,
-			struct btrfs_path *path,
-			const char *name, int name_len,
-			u64 inode_objectid, u64 ref_objectid, int mod);
+int btrfs_get_inode_ref_index(struct btrfs_trans_handle *trans,
+			      struct btrfs_root *root,
+			      struct btrfs_path *path,
+			      const char *name, int name_len,
+			      u64 inode_objectid, u64 ref_objectid, int mod,
+			      u64 *ret_index);
 int btrfs_insert_empty_inode(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid);
@@ -3197,6 +3223,19 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       *root, struct btrfs_path *path,
 		       struct btrfs_key *location, int mod);
 
+struct btrfs_inode_extref *
+btrfs_lookup_inode_extref(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root,
+			  struct btrfs_path *path,
+			  const char *name, int name_len,
+			  u64 inode_objectid, u64 ref_objectid, int ins_len,
+			  int cow);
+
+int btrfs_find_name_in_ext_backref(struct btrfs_path *path,
+				   u64 ref_objectid, const char *name,
+				   int name_len,
+				   struct btrfs_inode_extref **extref_ret);
+
 /* file-item.c */
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, u64 bytenr, u64 len);

commit 005d6427ac4f276d937a36ca6a1d62b181ed70bf
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Sep 18 07:52:32 2012 -0600

    btrfs: move transaction aborts to the point of failure
    
    Call btrfs_abort_transaction as early as possible when an error
    condition is detected, that way the line number reported is useful
    and we're not clueless anymore which error path led to the abort.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1372057e1ec1..399521ab61da 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3400,6 +3400,11 @@ static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
 	}
 }
 
+/*
+ * Call btrfs_abort_transaction as early as possible when an error condition is
+ * detected, that way the exact line number is reported.
+ */
+
 #define btrfs_abort_transaction(trans, root, errno)		\
 do {								\
 	__btrfs_abort_transaction(trans, root, __func__,	\

commit 2e90cf858fd2639eae2fb3f2173f7633cb15bf38
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Sep 14 02:58:06 2012 -0600

    Btrfs: cleanup fs_info->hashers
    
    fs_info->hashers is now an obsolete one.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d66dc1c6a40d..1372057e1ec1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1253,7 +1253,6 @@ struct btrfs_fs_info {
 	struct mutex reloc_mutex;
 
 	struct list_head trans_list;
-	struct list_head hashers;
 	struct list_head dead_roots;
 	struct list_head caching_block_groups;
 

commit ea658badc47e614e38ab4d98510488474c7e6d4b
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Sep 11 16:57:25 2012 -0400

    Btrfs: delay block group item insertion
    
    So we have lots of places where we try to preallocate chunks in order to
    make sure we have enough space as we make our allocations.  This has
    historically meant that we're constantly tweaking when we should allocate a
    new chunk, and historically we have gotten this horribly wrong so we way
    over allocate either metadata or data.  To try and keep this from happening
    we are going to make it so that the block group item insertion is done out
    of band at the end of a transaction.  This will allow us to create chunks
    even if we are trying to make an allocation for the extent tree.  With this
    patch my enospc tests run faster (didn't expect this) and more efficiently
    use the disk space (this is what I wanted).  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 305002b7bf3a..d66dc1c6a40d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1137,6 +1137,9 @@ struct btrfs_block_group_cache {
 	 * Today it will only have one thing on it, but that may change
 	 */
 	struct list_head cluster_list;
+
+	/* For delayed block group creation */
+	struct list_head new_bg_list;
 };
 
 /* delayed seq elem */
@@ -2865,6 +2868,8 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 size);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
+void btrfs_create_pending_block_groups(struct btrfs_trans_handle *trans,
+				       struct btrfs_root *root);
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);

commit 0647d6bd16c03c928a22d1b90c4c8684c5908f08
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Fri Sep 7 20:01:26 2012 -0600

    Btrfs: cleanup for unused ref cache stuff
    
    As ref cache has been removed from btrfs, there is no user on
    its lock and its check.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6923b9e4f90d..305002b7bf3a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1376,9 +1376,6 @@ struct btrfs_fs_info {
 	struct rb_root defrag_inodes;
 	atomic_t defrag_running;
 
-	spinlock_t ref_cache_lock;
-	u64 total_ref_cache_size;
-
 	/*
 	 * these three are in extended format (availability of single
 	 * chunks is denoted by BTRFS_AVAIL_ALLOC_BIT_SINGLE bit, other

commit 2ecb79239bcd04c9d410f4cdce16adb6840b19da
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 6 04:04:27 2012 -0600

    Btrfs: fix unprotected ->log_batch
    
    We forget to protect ->log_batch when syncing a file, this patch fix
    this problem by atomic operation. And ->log_batch is used to check
    if there are parallel sync operations or not, so it is unnecessary to
    reset it to 0 after the sync operation of the current log tree complete.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2990a7ea6248..6923b9e4f90d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1491,9 +1491,9 @@ struct btrfs_root {
 	wait_queue_head_t log_commit_wait[2];
 	atomic_t log_writers;
 	atomic_t log_commit[2];
+	atomic_t log_batch;
 	unsigned long log_transid;
 	unsigned long last_log_commit;
-	unsigned long log_batch;
 	pid_t log_start_pid;
 	bool log_multiple_pids;
 

commit 66d8f3dd1c87813d7f1cf8b774cb03e9b8d7e87e
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 6 04:02:28 2012 -0600

    Btrfs: add a new "type" field into the block reservation structure
    
    Sometimes we need choose the method of the reservation according to the type
    of the block reservation, such as the reservation for the delayed inode update.
    Now we identify the type just by comparing the address of the reservation
    variants, it is very ugly if it is a temporary one because we need compare it
    with all the common reservation variants. So we add a new "type" field to keep
    the type the reservation variants.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b7cd3adb5a58..2990a7ea6248 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1028,13 +1028,22 @@ struct btrfs_space_info {
 	wait_queue_head_t wait;
 };
 
+#define	BTRFS_BLOCK_RSV_GLOBAL		1
+#define	BTRFS_BLOCK_RSV_DELALLOC	2
+#define	BTRFS_BLOCK_RSV_TRANS		3
+#define	BTRFS_BLOCK_RSV_CHUNK		4
+#define	BTRFS_BLOCK_RSV_DELOPS		5
+#define	BTRFS_BLOCK_RSV_EMPTY		6
+#define	BTRFS_BLOCK_RSV_TEMP		7
+
 struct btrfs_block_rsv {
 	u64 size;
 	u64 reserved;
 	struct btrfs_space_info *space_info;
 	spinlock_t lock;
-	unsigned int full;
-	unsigned int failfast;
+	unsigned short full;
+	unsigned short type;
+	unsigned short failfast;
 };
 
 /*
@@ -2875,8 +2884,9 @@ int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
 int btrfs_delalloc_reserve_space(struct inode *inode, u64 num_bytes);
 void btrfs_delalloc_release_space(struct inode *inode, u64 num_bytes);
-void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv);
-struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root);
+void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv, unsigned short type);
+struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root,
+					      unsigned short type);
 void btrfs_free_block_rsv(struct btrfs_root *root,
 			  struct btrfs_block_rsv *rsv);
 int btrfs_block_rsv_add(struct btrfs_root *root,

commit 7014cdb49305eda0767d2ae6136f8c191ea8fd81
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Aug 30 20:06:49 2012 -0400

    Btrfs: btrfs_drop_extent_cache should never fail
    
    I noticed this when I was doing the fsync stuff, we allocate split extents if we
    drop an extent range that is in the middle of an existing extent.  This BUG()'s
    if we fail to allocate memory, but the fact is this is just a cache, we will
    just regenerate the cache if we need it, the important part is that we free the
    range we are given.  This can be done without allocations, so if we fail to
    allocate splits just skip the splitting stage and free our em and look for more
    extents to drop.  This also makes btrfs_drop_extent_cache a void since nobody
    was checking the return value anyway.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 88adfe638409..b7cd3adb5a58 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3316,8 +3316,8 @@ int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 			   struct inode *inode);
 int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
 int btrfs_sync_file(struct file *file, loff_t start, loff_t end, int datasync);
-int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
-			    int skip_pinned);
+void btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
+			     int skip_pinned);
 int btrfs_replace_extent_cache(struct inode *inode, struct extent_map *replace,
 			       u64 start, u64 end, int skip_pinned,
 			       int modified);

commit 2aaa66558172b017f36bf38ae69372813dedee9d
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 29 14:27:18 2012 -0400

    Btrfs: add hole punching
    
    This patch adds hole punching via fallocate.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 71d6ff13d76e..88adfe638409 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3250,6 +3250,8 @@ int btrfs_unlink_subvol(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct inode *dir, u64 objectid,
 			const char *name, int name_len);
+int btrfs_truncate_page(struct inode *inode, loff_t from, loff_t len,
+			int front);
 int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       struct inode *inode, u64 new_size,
@@ -3323,7 +3325,7 @@ extern const struct file_operations btrfs_file_operations;
 int __btrfs_drop_extents(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root, struct inode *inode,
 			 struct btrfs_path *path, u64 start, u64 end,
-			 int drop_cache);
+			 u64 *drop_end, int drop_cache);
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode, u64 start,
 		       u64 end, int drop_cache);

commit 2671485d395c07fca104c972785898d7c52fc942
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 29 12:24:27 2012 -0400

    Btrfs: remove unused hint byte argument for btrfs_drop_extents
    
    I audited all users of btrfs_drop_extents and found that nobody actually uses
    the hint_byte argument.  I'm sure it was used for something at some point but
    it's not used now, and the way the pinning works the disk bytenr would never be
    immediately useful anyway so lets just remove it.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 81c772b5dc8e..71d6ff13d76e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3323,10 +3323,10 @@ extern const struct file_operations btrfs_file_operations;
 int __btrfs_drop_extents(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root, struct inode *inode,
 			 struct btrfs_path *path, u64 start, u64 end,
-			 u64 *hint_byte, int drop_cache);
+			 int drop_cache);
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode, u64 start,
-		       u64 end, u64 *hint_byte, int drop_cache);
+		       u64 end, int drop_cache);
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);

commit ca7e70f59078046db28501519308c2061b0e7a6f
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Aug 27 17:48:15 2012 -0400

    Btrfs: do not needlessly restart the transaction for enospc
    
    We will stop and restart a transaction every time we move to a different leaf
    when truncating a file.  This is for enospc reasons, but really we could
    probably get away with doing this a little better by actually working until we
    hit an ENOSPC.  So add a ->failfast flag to the block_rsv and set it when we do
    truncates which will fail as soon as the block rsv runs out of space, and then
    at that point we can stop and restart the transaction and refill the block rsv
    and carry on.  This will make rm'ing of a file with lots of extents a bit
    faster.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4b81ea3fa1b2..81c772b5dc8e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1034,6 +1034,7 @@ struct btrfs_block_rsv {
 	struct btrfs_space_info *space_info;
 	spinlock_t lock;
 	unsigned int full;
+	unsigned int failfast;
 };
 
 /*

commit 5dc562c541e1026df9d43913c2f6b91156e22d32
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Aug 17 13:14:17 2012 -0400

    Btrfs: turbo charge fsync
    
    At least for the vm workload.  Currently on fsync we will
    
    1) Truncate all items in the log tree for the given inode if they exist
    
    and
    
    2) Copy all items for a given inode into the log
    
    The problem with this is that for things like VMs you can have lots of
    extents from the fragmented writing behavior, and worst yet you may have
    only modified a few extents, not the entire thing.  This patch fixes this
    problem by tracking which transid modified our extent, and then when we do
    the tree logging we find all of the extents we've modified in our current
    transaction, sort them and commit them.  We also only truncate up to the
    xattrs of the inode and copy that stuff in normally, and then just drop any
    extents in the range we have that exist in the log already.  Here are some
    numbers of a 50 meg fio job that does random writes and fsync()s after every
    write
    
                    Original        Patched
    SATA drive      82KB/s          140KB/s
    Fusion drive    431KB/s         2532KB/s
    
    So around 2-6 times faster depending on your hardware.  There are a few
    corner cases, for example if you truncate at all we have to do it the old
    way since there is no way to be sure what is in the log is ok.  This
    probably could be done smarter, but if you write-fsync-truncate-write-fsync
    you deserve what you get.  All this work is in RAM of course so if your
    inode gets evicted from cache and you read it in and fsync it we'll do it
    the slow way if we are still in the same transaction that we last modified
    the inode in.
    
    The biggest cool part of this is that it requires no changes to the recovery
    code, so if you fsync with this patch and crash and load an old kernel, it
    will run the recovery and be a-ok.  I have tested this pretty thoroughly
    with an fsync tester and everything comes back fine, as well as xfstests.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0d195b507660..4b81ea3fa1b2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3315,9 +3315,17 @@ int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
 int btrfs_sync_file(struct file *file, loff_t start, loff_t end, int datasync);
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			    int skip_pinned);
+int btrfs_replace_extent_cache(struct inode *inode, struct extent_map *replace,
+			       u64 start, u64 end, int skip_pinned,
+			       int modified);
 extern const struct file_operations btrfs_file_operations;
-int btrfs_drop_extents(struct btrfs_trans_handle *trans, struct inode *inode,
-		       u64 start, u64 end, u64 *hint_byte, int drop_cache);
+int __btrfs_drop_extents(struct btrfs_trans_handle *trans,
+			 struct btrfs_root *root, struct inode *inode,
+			 struct btrfs_path *path, u64 start, u64 end,
+			 u64 *hint_byte, int drop_cache);
+int btrfs_drop_extents(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root, struct inode *inode, u64 start,
+		       u64 end, u64 *hint_byte, int drop_cache);
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);

commit 99dbb1632f1165c2726056ebfce6edde0e5a0208
Merge: aae6f989c6e9 9c33c512b2d3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 1 09:06:36 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    Pull the trivial tree from Jiri Kosina:
     "Tiny usual fixes all over the place"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (34 commits)
      doc: fix old config name of kprobetrace
      fs/fs-writeback.c: cleanup riteback_sb_inodes kerneldoc
      btrfs: fix the commment for the action flags in delayed-ref.h
      btrfs: fix trivial typo for the comment of BTRFS_FREE_INO_OBJECTID
      vfs: fix kerneldoc for generic_fh_to_parent()
      treewide: fix comment/printk/variable typos
      ipr: fix small coding style issues
      doc: fix broken utf8 encoding
      nfs: comment fix
      platform/x86: fix asus_laptop.wled_type module parameter
      mfd: printk/comment fixes
      doc: getdelays.c: remember to close() socket on error in create_nl_socket()
      doc: aliasing-test: close fd on write error
      mmc: fix comment typos
      dma: fix comments
      spi: fix comment/printk typos in spi
      Coccinelle: fix typo in memdup_user.cocci
      tmiofb: missing NULL pointer checks
      tools: perf: Fix typo in tools/perf
      tools/testing: fix comment / output typos
      ...

commit 527a1361387cd132a577dc8a6ae676cfc1e8414b
Author: Wang Sheng-Hui <shhuiw@gmail.com>
Date:   Thu Sep 6 13:33:37 2012 +0800

    btrfs: fix trivial typo for the comment of BTRFS_FREE_INO_OBJECTID
    
    It should be storing, not sotring.
    
    Signed-off-by: Wang Sheng-Hui <shhuiw@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa5c45b39075..11d0e09e1616 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -113,7 +113,7 @@ struct btrfs_ordered_sum;
 #define BTRFS_FREE_SPACE_OBJECTID -11ULL
 
 /*
- * The inode number assigned to the special inode for sotring
+ * The inode number assigned to the special inode for storing
  * free ino cache
  */
 #define BTRFS_FREE_INO_OBJECTID -12ULL

commit 318e15101993c0fdc3f23f24ac61fc7769d27e68
Merge: a7ccbcf33070 256dd1bb3750
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 29 11:36:22 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "I've split out the big send/receive update from my last pull request
      and now have just the fixes in my for-linus branch.  The send/recv
      branch will wander over to linux-next shortly though.
    
      The largest patches in this pull are Josef's patches to fix DIO
      locking problems and his patch to fix a crash during balance.  They
      are both well tested.
    
      The rest are smaller fixes that we've had queued.  The last rc came
      out while I was hacking new and exciting ways to recover from a
      misplaced rm -rf on my dev box, so these missed rc3."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (25 commits)
      Btrfs: fix that repair code is spuriously executed for transid failures
      Btrfs: fix ordered extent leak when failing to start a transaction
      Btrfs: fix a dio write regression
      Btrfs: fix deadlock with freeze and sync V2
      Btrfs: revert checksum error statistic which can cause a BUG()
      Btrfs: remove superblock writing after fatal error
      Btrfs: allow delayed refs to be merged
      Btrfs: fix enospc problems when deleting a subvol
      Btrfs: fix wrong mtime and ctime when creating snapshots
      Btrfs: fix race in run_clustered_refs
      Btrfs: don't run __tree_mod_log_free_eb on leaves
      Btrfs: increase the size of the free space cache
      Btrfs: barrier before waitqueue_active
      Btrfs: fix deadlock in wait_for_more_refs
      btrfs: fix second lock in btrfs_delete_delayed_items()
      Btrfs: don't allocate a seperate csums array for direct reads
      Btrfs: do not strdup non existent strings
      Btrfs: do not use missing devices when showing devname
      Btrfs: fix that error value is changed by mistake
      Btrfs: lock extents as we map them in DIO
      ...

commit 1fa11e265fa2562fb713171b6a58e72bb7afd276
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon Aug 6 14:18:51 2012 -0600

    Btrfs: fix deadlock in wait_for_more_refs
    
    Commit a168650c introduced a waiting mechanism to prevent busy waiting in
    btrfs_run_delayed_refs. This can deadlock with btrfs_run_ordered_operations,
    where a tree_mod_seq is held while waiting for the io to complete, while
    the end_io calls btrfs_run_delayed_refs.
    This whole mechanism is unnecessary. If not enough runnable refs are
    available to satisfy count, just return as count is more like a guideline
    than a strict requirement.
    In case we have to run all refs, commit transaction makes sure that no
    other threads are working in the transaction anymore, so we just assert
    here that no refs are blocked.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 348196350bf0..c38734a07a65 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1252,7 +1252,6 @@ struct btrfs_fs_info {
 	atomic_t tree_mod_seq;
 	struct list_head tree_mod_seq_list;
 	struct seq_list tree_mod_seq_elem;
-	wait_queue_head_t tree_mod_seq_wait;
 
 	/* this protects tree_mod_log */
 	rwlock_t tree_mod_log_lock;

commit c329861da40623cd838b8c9ee31a850242fd88cf
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Aug 3 16:49:19 2012 -0400

    Btrfs: don't allocate a seperate csums array for direct reads
    
    We've been allocating a big array for csums instead of storing them in the
    io_tree like we do for buffered reads because previously we were locking the
    entire range, so we didn't have an extent state for each sector of the
    range.  But now that we do the range locking as we map the buffers we can
    limit the mapping lenght to sectorsize and use the private part of the
    io_tree for our csums.  This allows us to avoid an extra memory allocation
    for direct reads which could incur latency.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index adb1cd7ceb9b..348196350bf0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3192,7 +3192,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio, u32 *dst);
 int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct bio *bio, u64 logical_offset, u32 *dst);
+			      struct bio *bio, u64 logical_offset);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,

commit 533574c6bc30cf526cc1c41bde050c854a945efb
Author: Joe Perches <joe@perches.com>
Date:   Mon Jul 30 14:40:13 2012 -0700

    btrfs: use printk_get_level and printk_skip_level, add __printf, fix fallout
    
    Use the generic printk_get_level() to search a message for a kern_level.
    
    Add __printf to verify format and arguments.  Fix a few messages that
    had mismatches in format and arguments.  Add #ifdef CONFIG_PRINTK blocks
    to shrink the object size a bit when not using printk.
    
    [akpm@linux-foundation.org: whitespace tweak]
    Signed-off-by: Joe Perches <joe@perches.com>
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Cc: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index adb1cd7ceb9b..4bab807227ad 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3342,10 +3342,22 @@ ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 /* super.c */
 int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
+
+#ifdef CONFIG_PRINTK
+__printf(2, 3)
 void btrfs_printk(struct btrfs_fs_info *fs_info, const char *fmt, ...);
+#else
+static inline __printf(2, 3)
+void btrfs_printk(struct btrfs_fs_info *fs_info, const char *fmt, ...)
+{
+}
+#endif
+
+__printf(5, 6)
 void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);
 
+
 void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root, const char *function,
 			       unsigned int line, int errno);
@@ -3386,6 +3398,7 @@ do {								\
 			  (errno), fmt, ##args);		\
 } while (0)
 
+__printf(5, 6)
 void __btrfs_panic(struct btrfs_fs_info *fs_info, const char *function,
 		   unsigned int line, int errno, const char *fmt, ...);
 

commit 113c1cb530e10bcada93d88ffaa6b521aae2d251
Merge: cd1cfc49153b 31db9f7c23fb
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Jul 25 19:17:39 2012 -0400

    Merge branch 'send-v2' of git://github.com/ablock84/linux-btrfs into for-linus
    
    This is the kernel portion of btrfs send/receive
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/backref.h
            fs/btrfs/ctree.c
            fs/btrfs/ioctl.c
            fs/btrfs/ioctl.h
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

commit 7069830a9e381e33d44ded45095f764844c71d24
Author: Alexander Block <ablock84@googlemail.com>
Date:   Tue Jun 5 21:07:48 2012 +0200

    Btrfs: add btrfs_compare_trees function
    
    This function is used to find the differences between
    two trees. The tree compare skips whole subtrees if it
    detects shared tree blocks and thus is pretty fast.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>
    Reviewed-by: David Sterba <dave@jikos.cz>
    Reviewed-by: Arne Jansen <sensille@gmx.net>
    Reviewed-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Reviewed-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d5f6d7458676..2fbbe738caed 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2722,6 +2722,21 @@ int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
 			 struct btrfs_key *max_key,
 			 struct btrfs_path *path, int cache_only,
 			 u64 min_trans);
+enum btrfs_compare_tree_result {
+	BTRFS_COMPARE_TREE_NEW,
+	BTRFS_COMPARE_TREE_DELETED,
+	BTRFS_COMPARE_TREE_CHANGED,
+};
+typedef int (*btrfs_changed_cb_t)(struct btrfs_root *left_root,
+				  struct btrfs_root *right_root,
+				  struct btrfs_path *left_path,
+				  struct btrfs_path *right_path,
+				  struct btrfs_key *key,
+				  enum btrfs_compare_tree_result result,
+				  void *ctx);
+int btrfs_compare_trees(struct btrfs_root *left_root,
+			struct btrfs_root *right_root,
+			btrfs_changed_cb_t cb, void *ctx);
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,

commit 8ea05e3a4262b9e6871c349fa3486bcfc72ffd1a
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Jul 25 17:35:53 2012 +0200

    Btrfs: introduce subvol uuids and times
    
    This patch introduces uuids for subvolumes. Each
    subvolume has it's own uuid. In case it was snapshotted,
    it also contains parent_uuid. In case it was received,
    it also contains received_uuid.
    
    It also introduces subvolume ctime/otime/stime/rtime. The
    first two are comparable to the times found in inodes. otime
    is the origin/creation time and ctime is the change time.
    stime/rtime are only valid on received subvolumes.
    stime is the time of the subvolume when it was
    sent. rtime is the time of the subvolume when it was
    received.
    
    Additionally to the times, we have a transid for each
    time. They are updated at the same place as the times.
    
    btrfs receive uses stransid and rtransid to find out
    if a received subvolume changed in the meantime.
    
    If an older kernel mounts a filesystem with the
    extented fields, all fields become invalid. The next
    mount with a new kernel will detect this and reset the
    fields.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>
    Reviewed-by: David Sterba <dave@jikos.cz>
    Reviewed-by: Arne Jansen <sensille@gmx.net>
    Reviewed-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Reviewed-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8cfde9326dd6..d5f6d7458676 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -709,6 +709,36 @@ struct btrfs_root_item {
 	struct btrfs_disk_key drop_progress;
 	u8 drop_level;
 	u8 level;
+
+	/*
+	 * The following fields appear after subvol_uuids+subvol_times
+	 * were introduced.
+	 */
+
+	/*
+	 * This generation number is used to test if the new fields are valid
+	 * and up to date while reading the root item. Everytime the root item
+	 * is written out, the "generation" field is copied into this field. If
+	 * anyone ever mounted the fs with an older kernel, we will have
+	 * mismatching generation values here and thus must invalidate the
+	 * new fields. See btrfs_update_root and btrfs_find_last_root for
+	 * details.
+	 * the offset of generation_v2 is also used as the start for the memset
+	 * when invalidating the fields.
+	 */
+	__le64 generation_v2;
+	u8 uuid[BTRFS_UUID_SIZE];
+	u8 parent_uuid[BTRFS_UUID_SIZE];
+	u8 received_uuid[BTRFS_UUID_SIZE];
+	__le64 ctransid; /* updated when an inode changes */
+	__le64 otransid; /* trans when created */
+	__le64 stransid; /* trans when sent. non-zero for received subvol */
+	__le64 rtransid; /* trans when received. non-zero for received subvol */
+	struct btrfs_timespec ctime;
+	struct btrfs_timespec otime;
+	struct btrfs_timespec stime;
+	struct btrfs_timespec rtime;
+	__le64 reserved[8]; /* for future */
 } __attribute__ ((__packed__));
 
 /*
@@ -1416,6 +1446,8 @@ struct btrfs_root {
 	dev_t anon_dev;
 
 	int force_cow;
+
+	spinlock_t root_times_lock;
 };
 
 struct btrfs_ioctl_defrag_range_args {
@@ -2189,6 +2221,16 @@ BTRFS_SETGET_STACK_FUNCS(root_used, struct btrfs_root_item, bytes_used, 64);
 BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, byte_limit, 64);
 BTRFS_SETGET_STACK_FUNCS(root_last_snapshot, struct btrfs_root_item,
 			 last_snapshot, 64);
+BTRFS_SETGET_STACK_FUNCS(root_generation_v2, struct btrfs_root_item,
+			 generation_v2, 64);
+BTRFS_SETGET_STACK_FUNCS(root_ctransid, struct btrfs_root_item,
+			 ctransid, 64);
+BTRFS_SETGET_STACK_FUNCS(root_otransid, struct btrfs_root_item,
+			 otransid, 64);
+BTRFS_SETGET_STACK_FUNCS(root_stransid, struct btrfs_root_item,
+			 stransid, 64);
+BTRFS_SETGET_STACK_FUNCS(root_rtransid, struct btrfs_root_item,
+			 rtransid, 64);
 
 static inline bool btrfs_root_readonly(struct btrfs_root *root)
 {
@@ -2822,6 +2864,9 @@ int __must_check btrfs_update_root(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root,
 				   struct btrfs_key *key,
 				   struct btrfs_root_item *item);
+void btrfs_read_root_item(struct btrfs_root *root,
+			 struct extent_buffer *eb, int slot,
+			 struct btrfs_root_item *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);
@@ -2829,6 +2874,8 @@ int btrfs_find_orphan_roots(struct btrfs_root *tree_root);
 void btrfs_set_root_node(struct btrfs_root_item *item,
 			 struct extent_buffer *node);
 void btrfs_check_and_init_root_item(struct btrfs_root_item *item);
+void btrfs_update_root_times(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root);
 
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,

commit 2b0ce2c2909368d124a78a88e5c7106fdcba6221
Author: Mitch Harder <mitch.harder@sabayonlinux.org>
Date:   Tue Jul 24 11:58:43 2012 -0600

    Btrfs: Check INCOMPAT flags on remount and add helper function
    
    In support of the recently added capability to remount with lzo
    compression, provide a helper function to check the compression
    INCOMPAT flags when remounting with lzo compression, and set
    the flags if necessary.
    
    Also, implement the new helper function when defragmenting with
    explicit lzo compression and when setting the default subvolume.
    
    Signed-off-by: Mitch Harder <mitch.harder@sabayonlinux.org>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 00f9a50f986d..0f369da5cd97 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3288,6 +3288,23 @@ void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root, const char *function,
 			       unsigned int line, int errno);
 
+#define btrfs_set_fs_incompat(__fs_info, opt) \
+	__btrfs_set_fs_incompat((__fs_info), BTRFS_FEATURE_INCOMPAT_##opt)
+
+static inline void __btrfs_set_fs_incompat(struct btrfs_fs_info *fs_info,
+					   u64 flag)
+{
+	struct btrfs_super_block *disk_super;
+	u64 features;
+
+	disk_super = fs_info->super_copy;
+	features = btrfs_super_incompat_flags(disk_super);
+	if (!(features & flag)) {
+		features |= flag;
+		btrfs_set_super_incompat_flags(disk_super, features);
+	}
+}
+
 #define btrfs_abort_transaction(trans, root, errno)		\
 do {								\
 	__btrfs_abort_transaction(trans, root, __func__,	\

commit b478b2baa37ac99fc04a30809c780dd5dfd43595
Merge: 67c9684f48ea 6f72c7e20dba
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Jul 25 16:11:38 2012 -0400

    Merge branch 'qgroup' of git://git.jan-o-sch.net/btrfs-unstable into for-linus
    
    Conflicts:
            fs/btrfs/ioctl.c
            fs/btrfs/ioctl.h
            fs/btrfs/transaction.c
            fs/btrfs/transaction.h
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

commit e679376911d016b670c8cfc1645c178f77e8d1d3
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 11:18:10 2011 +0200

    Btrfs: add helper for tree enumeration
    
    Often no exact match is wanted but just the next lower or
    higher item. There's a lot of duplicated code throughout
    btrfs to deal with the corner cases. This patch adds a
    helper function that can facilitate searching.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa5c45b39075..8cfde9326dd6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2711,6 +2711,9 @@ int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      ins_len, int cow);
 int btrfs_search_old_slot(struct btrfs_root *root, struct btrfs_key *key,
 			  struct btrfs_path *p, u64 time_seq);
+int btrfs_search_slot_for_read(struct btrfs_root *root,
+			       struct btrfs_key *key, struct btrfs_path *p,
+			       int find_higher, int return_any);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct extent_buffer *parent,
 		       int start_slot, int cache_only, u64 *last_ret,

commit 18077bb413687f96bd168efcfb2b8778529e3b74
Author: Li Zefan <lizefan@huawei.com>
Date:   Mon Jul 9 20:22:35 2012 -0600

    Btrfs: rewrite BTRFS_SETGET_FUNCS
    
    BTRFS_SETGET_FUNCS macro is used to generate btrfs_set_foo() and
    btrfs_foo() functions, which read and write specific fields in the
    extent buffer.
    
    The total number of set/get functions is ~200, but in fact we only
    need 8 functions: 2 for u8 field, 2 for u16, 2 for u32 and 2 for u64.
    
    It results in redunction of ~37K bytes.
    
       text    data     bss     dec     hex filename
     629661   12489     216  642366   9cd3e fs/btrfs/btrfs.o.orig
     592637   12489     216  605342   93c9e fs/btrfs/btrfs.o
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6761490b91cd..a0ee2f8e0566 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1623,13 +1623,54 @@ static inline void btrfs_init_map_token (struct btrfs_map_token *token)
 			    offsetof(type, member),			\
 			   sizeof(((type *)0)->member)))
 
-#ifndef BTRFS_SETGET_FUNCS
+#define DECLARE_BTRFS_SETGET_BITS(bits)					\
+u##bits btrfs_get_token_##bits(struct extent_buffer *eb, void *ptr,	\
+			       unsigned long off,			\
+                              struct btrfs_map_token *token);		\
+void btrfs_set_token_##bits(struct extent_buffer *eb, void *ptr,	\
+			    unsigned long off, u##bits val,		\
+			    struct btrfs_map_token *token);		\
+static inline u##bits btrfs_get_##bits(struct extent_buffer *eb, void *ptr, \
+				       unsigned long off)		\
+{									\
+	return btrfs_get_token_##bits(eb, ptr, off, NULL);		\
+}									\
+static inline void btrfs_set_##bits(struct extent_buffer *eb, void *ptr, \
+				    unsigned long off, u##bits val)	\
+{									\
+       btrfs_set_token_##bits(eb, ptr, off, val, NULL);			\
+}
+
+DECLARE_BTRFS_SETGET_BITS(8)
+DECLARE_BTRFS_SETGET_BITS(16)
+DECLARE_BTRFS_SETGET_BITS(32)
+DECLARE_BTRFS_SETGET_BITS(64)
+
 #define BTRFS_SETGET_FUNCS(name, type, member, bits)			\
-u##bits btrfs_##name(struct extent_buffer *eb, type *s);		\
-u##bits btrfs_token_##name(struct extent_buffer *eb, type *s, struct btrfs_map_token *token);		\
-void btrfs_set_token_##name(struct extent_buffer *eb, type *s, u##bits val, struct btrfs_map_token *token);\
-void btrfs_set_##name(struct extent_buffer *eb, type *s, u##bits val);
-#endif
+static inline u##bits btrfs_##name(struct extent_buffer *eb, type *s)	\
+{									\
+	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
+	return btrfs_get_##bits(eb, s, offsetof(type, member));		\
+}									\
+static inline void btrfs_set_##name(struct extent_buffer *eb, type *s,	\
+				    u##bits val)			\
+{									\
+	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
+	btrfs_set_##bits(eb, s, offsetof(type, member), val);		\
+}									\
+static inline u##bits btrfs_token_##name(struct extent_buffer *eb, type *s, \
+					 struct btrfs_map_token *token)	\
+{									\
+	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
+	return btrfs_get_token_##bits(eb, s, offsetof(type, member), token); \
+}									\
+static inline void btrfs_set_token_##name(struct extent_buffer *eb,	\
+					  type *s, u##bits val,		\
+                                         struct btrfs_map_token *token)	\
+{									\
+	BUILD_BUG_ON(sizeof(u##bits) != sizeof(((type *)0))->member);	\
+	btrfs_set_token_##bits(eb, s, offsetof(type, member), val, token); \
+}
 
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
 static inline u##bits btrfs_##name(struct extent_buffer *eb)		\

commit b4d7c3c9456a311a45bc1ef8944b5ba5b176244f
Author: Li Zefan <lizefan@huawei.com>
Date:   Mon Jul 9 20:21:07 2012 -0600

    Btrfs: kill free_space pointer from inode structure
    
    Inodes always allocate free space with BTRFS_BLOCK_GROUP_DATA type,
    which means every inode has the same BTRFS_I(inode)->free_space pointer.
    
    This shrinks struct btrfs_inode by 4 bytes (or 8 bytes on 64 bits).
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa5c45b39075..6761490b91cd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1240,6 +1240,8 @@ struct btrfs_fs_info {
 	 */
 	struct list_head space_info;
 
+	struct btrfs_space_info *data_sinfo;
+
 	struct reloc_control *reloc_ctl;
 
 	spinlock_t delalloc_lock;
@@ -2607,7 +2609,6 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
-void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 int btrfs_check_data_free_space(struct inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);

commit bcef60f249034f69e89e544461cbfecb68975595
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 15:23:30 2011 +0200

    Btrfs: quota tree support and startup
    
    Init the quota tree along with the others on open_ctree
    and close_ctree. Add the quota tree to the list of well
    known trees in btrfs_read_fs_root_no_name.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ccba9b684c96..2ba03b96fbe0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2967,6 +2967,7 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->chunk_root);
 	kfree(fs_info->dev_root);
 	kfree(fs_info->csum_root);
+	kfree(fs_info->quota_root);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
 	kfree(fs_info);

commit bed92eae26ccf280d1a2168b7509447b56675a27
Author: Arne Jansen <sensille@gmx.net>
Date:   Thu Jun 28 18:03:02 2012 +0200

    Btrfs: qgroup implementation and prototypes
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a5269d4a164f..ccba9b684c96 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2830,6 +2830,8 @@ int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
 int btrfs_trim_fs(struct btrfs_root *root, struct fstrim_range *range);
 
 int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
+int btrfs_delayed_refs_qgroup_accounting(struct btrfs_trans_handle *trans,
+					 struct btrfs_fs_info *fs_info);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);
@@ -3339,6 +3341,50 @@ void btrfs_reada_detach(void *handle);
 int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 			 u64 start, int err);
 
+/* qgroup.c */
+struct qgroup_update {
+	struct list_head list;
+	struct btrfs_delayed_ref_node *node;
+	struct btrfs_delayed_extent_op *extent_op;
+};
+
+int btrfs_quota_enable(struct btrfs_trans_handle *trans,
+		       struct btrfs_fs_info *fs_info);
+int btrfs_quota_disable(struct btrfs_trans_handle *trans,
+			struct btrfs_fs_info *fs_info);
+int btrfs_quota_rescan(struct btrfs_fs_info *fs_info);
+int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
+			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
+int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,
+			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
+int btrfs_create_qgroup(struct btrfs_trans_handle *trans,
+			struct btrfs_fs_info *fs_info, u64 qgroupid,
+			char *name);
+int btrfs_remove_qgroup(struct btrfs_trans_handle *trans,
+			      struct btrfs_fs_info *fs_info, u64 qgroupid);
+int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,
+		       struct btrfs_fs_info *fs_info, u64 qgroupid,
+		       struct btrfs_qgroup_limit *limit);
+int btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info);
+void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);
+struct btrfs_delayed_extent_op;
+int btrfs_qgroup_record_ref(struct btrfs_trans_handle *trans,
+			    struct btrfs_delayed_ref_node *node,
+			    struct btrfs_delayed_extent_op *extent_op);
+int btrfs_qgroup_account_ref(struct btrfs_trans_handle *trans,
+			     struct btrfs_fs_info *fs_info,
+			     struct btrfs_delayed_ref_node *node,
+			     struct btrfs_delayed_extent_op *extent_op);
+int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
+		      struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
+			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
+			 struct btrfs_qgroup_inherit *inherit);
+int btrfs_qgroup_reserve(struct btrfs_root *root, u64 num_bytes);
+void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes);
+
+void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
+
 static inline int is_fstree(u64 rootid)
 {
 	if (rootid == BTRFS_FS_TREE_OBJECTID ||

commit 416ac51da90e98daaac17e1f359a6c5591f7f5bd
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 12:56:09 2011 +0200

    Btrfs: qgroup state and initialization
    
    Add state to fs_info.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 27cf995564ed..a5269d4a164f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1120,6 +1120,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *dev_root;
 	struct btrfs_root *fs_root;
 	struct btrfs_root *csum_root;
+	struct btrfs_root *quota_root;
 
 	/* the log root tree is a directory of all the other log roots */
 	struct btrfs_root *log_root_tree;
@@ -1374,6 +1375,29 @@ struct btrfs_fs_info {
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	u32 check_integrity_print_mask;
 #endif
+	/*
+	 * quota information
+	 */
+	unsigned int quota_enabled:1;
+
+	/*
+	 * quota_enabled only changes state after a commit. This holds the
+	 * next state.
+	 */
+	unsigned int pending_quota_state:1;
+
+	/* is qgroup tracking in a consistent state? */
+	u64 qgroup_flags;
+
+	/* holds configuration and tracking. Protected by qgroup_lock */
+	struct rb_root qgroup_tree;
+	spinlock_t qgroup_lock;
+
+	/* list of dirty qgroups to be written at next commit */
+	struct list_head dirty_qgroups;
+
+	/* used by btrfs_qgroup_record_ref for an efficient tree traversal */
+	u64 qgroup_seq;
 
 	/* filesystem state */
 	u64 fs_state;

commit 2f38b3e1900634e64a186873b3388b1bf85dabc0
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 11:18:10 2011 +0200

    Btrfs: add helper for tree enumeration
    
    Often no exact match is wanted but just the next lower or
    higher item. There's a lot of duplicated code throughout
    btrfs to deal with the corner cases. This patch adds a
    helper function that can facilitate searching.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 33088b0dbf3f..27cf995564ed 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2856,6 +2856,9 @@ int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      ins_len, int cow);
 int btrfs_search_old_slot(struct btrfs_root *root, struct btrfs_key *key,
 			  struct btrfs_path *p, u64 time_seq);
+int btrfs_search_slot_for_read(struct btrfs_root *root,
+			       struct btrfs_key *key, struct btrfs_path *p,
+			       int find_higher, int return_any);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct extent_buffer *parent,
 		       int start_slot, int cache_only, u64 *last_ret,

commit 630dc772ea51bca3ec6fac609f450cbe0cafd1d6
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 11:06:07 2011 +0200

    Btrfs: qgroup on-disk format
    
    Not all features are in use by the current version
    and thus may change in the future.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f8dc46f44e7..33088b0dbf3f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -91,6 +91,9 @@ struct btrfs_ordered_sum;
 /* for storing balance parameters in the root tree */
 #define BTRFS_BALANCE_OBJECTID -4ULL
 
+/* holds quota configuration and tracking */
+#define BTRFS_QUOTA_TREE_OBJECTID 8ULL
+
 /* orhpan objectid for tracking unlinked/truncated files */
 #define BTRFS_ORPHAN_OBJECTID -5ULL
 
@@ -883,6 +886,72 @@ struct btrfs_block_group_item {
 	__le64 flags;
 } __attribute__ ((__packed__));
 
+/*
+ * is subvolume quota turned on?
+ */
+#define BTRFS_QGROUP_STATUS_FLAG_ON		(1ULL << 0)
+/*
+ * SCANNING is set during the initialization phase
+ */
+#define BTRFS_QGROUP_STATUS_FLAG_SCANNING	(1ULL << 1)
+/*
+ * Some qgroup entries are known to be out of date,
+ * either because the configuration has changed in a way that
+ * makes a rescan necessary, or because the fs has been mounted
+ * with a non-qgroup-aware version.
+ * Turning qouta off and on again makes it inconsistent, too.
+ */
+#define BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT	(1ULL << 2)
+
+#define BTRFS_QGROUP_STATUS_VERSION        1
+
+struct btrfs_qgroup_status_item {
+	__le64 version;
+	/*
+	 * the generation is updated during every commit. As older
+	 * versions of btrfs are not aware of qgroups, it will be
+	 * possible to detect inconsistencies by checking the
+	 * generation on mount time
+	 */
+	__le64 generation;
+
+	/* flag definitions see above */
+	__le64 flags;
+
+	/*
+	 * only used during scanning to record the progress
+	 * of the scan. It contains a logical address
+	 */
+	__le64 scan;
+} __attribute__ ((__packed__));
+
+struct btrfs_qgroup_info_item {
+	__le64 generation;
+	__le64 rfer;
+	__le64 rfer_cmpr;
+	__le64 excl;
+	__le64 excl_cmpr;
+} __attribute__ ((__packed__));
+
+/* flags definition for qgroup limits */
+#define BTRFS_QGROUP_LIMIT_MAX_RFER	(1ULL << 0)
+#define BTRFS_QGROUP_LIMIT_MAX_EXCL	(1ULL << 1)
+#define BTRFS_QGROUP_LIMIT_RSV_RFER	(1ULL << 2)
+#define BTRFS_QGROUP_LIMIT_RSV_EXCL	(1ULL << 3)
+#define BTRFS_QGROUP_LIMIT_RFER_CMPR	(1ULL << 4)
+#define BTRFS_QGROUP_LIMIT_EXCL_CMPR	(1ULL << 5)
+
+struct btrfs_qgroup_limit_item {
+	/*
+	 * only updated when any of the other values change
+	 */
+	__le64 flags;
+	__le64 max_rfer;
+	__le64 max_excl;
+	__le64 rsv_rfer;
+	__le64 rsv_excl;
+} __attribute__ ((__packed__));
+
 struct btrfs_space_info {
 	u64 flags;
 
@@ -1534,6 +1603,30 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_DEV_ITEM_KEY	216
 #define BTRFS_CHUNK_ITEM_KEY	228
 
+/*
+ * Records the overall state of the qgroups.
+ * There's only one instance of this key present,
+ * (0, BTRFS_QGROUP_STATUS_KEY, 0)
+ */
+#define BTRFS_QGROUP_STATUS_KEY         240
+/*
+ * Records the currently used space of the qgroup.
+ * One key per qgroup, (0, BTRFS_QGROUP_INFO_KEY, qgroupid).
+ */
+#define BTRFS_QGROUP_INFO_KEY           242
+/*
+ * Contains the user configured limits for the qgroup.
+ * One key per qgroup, (0, BTRFS_QGROUP_LIMIT_KEY, qgroupid).
+ */
+#define BTRFS_QGROUP_LIMIT_KEY          244
+/*
+ * Records the child-parent relationship of qgroups. For
+ * each relation, 2 keys are present:
+ * (childid, BTRFS_QGROUP_RELATION_KEY, parentid)
+ * (parentid, BTRFS_QGROUP_RELATION_KEY, childid)
+ */
+#define BTRFS_QGROUP_RELATION_KEY       246
+
 #define BTRFS_BALANCE_ITEM_KEY	248
 
 /*
@@ -2474,6 +2567,49 @@ static inline void btrfs_set_dev_stats_value(struct extent_buffer *eb,
 			    sizeof(val));
 }
 
+/* btrfs_qgroup_status_item */
+BTRFS_SETGET_FUNCS(qgroup_status_generation, struct btrfs_qgroup_status_item,
+		   generation, 64);
+BTRFS_SETGET_FUNCS(qgroup_status_version, struct btrfs_qgroup_status_item,
+		   version, 64);
+BTRFS_SETGET_FUNCS(qgroup_status_flags, struct btrfs_qgroup_status_item,
+		   flags, 64);
+BTRFS_SETGET_FUNCS(qgroup_status_scan, struct btrfs_qgroup_status_item,
+		   scan, 64);
+
+/* btrfs_qgroup_info_item */
+BTRFS_SETGET_FUNCS(qgroup_info_generation, struct btrfs_qgroup_info_item,
+		   generation, 64);
+BTRFS_SETGET_FUNCS(qgroup_info_rfer, struct btrfs_qgroup_info_item, rfer, 64);
+BTRFS_SETGET_FUNCS(qgroup_info_rfer_cmpr, struct btrfs_qgroup_info_item,
+		   rfer_cmpr, 64);
+BTRFS_SETGET_FUNCS(qgroup_info_excl, struct btrfs_qgroup_info_item, excl, 64);
+BTRFS_SETGET_FUNCS(qgroup_info_excl_cmpr, struct btrfs_qgroup_info_item,
+		   excl_cmpr, 64);
+
+BTRFS_SETGET_STACK_FUNCS(stack_qgroup_info_generation,
+			 struct btrfs_qgroup_info_item, generation, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_qgroup_info_rfer, struct btrfs_qgroup_info_item,
+			 rfer, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_qgroup_info_rfer_cmpr,
+			 struct btrfs_qgroup_info_item, rfer_cmpr, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_qgroup_info_excl, struct btrfs_qgroup_info_item,
+			 excl, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_qgroup_info_excl_cmpr,
+			 struct btrfs_qgroup_info_item, excl_cmpr, 64);
+
+/* btrfs_qgroup_limit_item */
+BTRFS_SETGET_FUNCS(qgroup_limit_flags, struct btrfs_qgroup_limit_item,
+		   flags, 64);
+BTRFS_SETGET_FUNCS(qgroup_limit_max_rfer, struct btrfs_qgroup_limit_item,
+		   max_rfer, 64);
+BTRFS_SETGET_FUNCS(qgroup_limit_max_excl, struct btrfs_qgroup_limit_item,
+		   max_excl, 64);
+BTRFS_SETGET_FUNCS(qgroup_limit_rsv_rfer, struct btrfs_qgroup_limit_item,
+		   rsv_rfer, 64);
+BTRFS_SETGET_FUNCS(qgroup_limit_rsv_excl, struct btrfs_qgroup_limit_item,
+		   rsv_excl, 64);
+
 static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;

commit 097b8a7c9e48e2cb50fd0eb9315791921beaf484
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Thu Jun 21 11:08:04 2012 +0200

    Btrfs: join tree mod log code with the code holding back delayed refs
    
    We've got two mechanisms both required for reliable backref resolving (tree
    mod log and holding back delayed refs). You cannot make use of one without
    the other. So instead of requiring the user of this mechanism to setup both
    correctly, we join them into a single interface.
    
    Additionally, we stop inserting non-blockers into fs_info->tree_mod_seq_list
    as we did before, which was of no value.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 84ac723f58f8..8f8dc46f44e7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1030,6 +1030,13 @@ struct btrfs_block_group_cache {
 	struct list_head cluster_list;
 };
 
+/* delayed seq elem */
+struct seq_list {
+	struct list_head list;
+	u64 seq;
+};
+
+/* fs_info */
 struct reloc_control;
 struct btrfs_device;
 struct btrfs_fs_devices;
@@ -1144,6 +1151,8 @@ struct btrfs_fs_info {
 	spinlock_t tree_mod_seq_lock;
 	atomic_t tree_mod_seq;
 	struct list_head tree_mod_seq_list;
+	struct seq_list tree_mod_seq_elem;
+	wait_queue_head_t tree_mod_seq_wait;
 
 	/* this protects tree_mod_log */
 	rwlock_t tree_mod_log_lock;
@@ -2798,6 +2807,16 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info);
 }
 
+/* tree mod log functions from ctree.c */
+u64 btrfs_get_tree_mod_seq(struct btrfs_fs_info *fs_info,
+			   struct seq_list *elem);
+void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
+			    struct seq_list *elem);
+static inline u64 btrfs_inc_tree_mod_seq(struct btrfs_fs_info *fs_info)
+{
+	return atomic_inc_return(&fs_info->tree_mod_seq);
+}
+
 /* root-item.c */
 int btrfs_find_root_ref(struct btrfs_root *tree_root,
 			struct btrfs_path *path,
@@ -3157,18 +3176,6 @@ void btrfs_reada_detach(void *handle);
 int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 			 u64 start, int err);
 
-/* delayed seq elem */
-struct seq_list {
-	struct list_head list;
-	u64 seq;
-	u32 flags;
-};
-
-void btrfs_get_tree_mod_seq(struct btrfs_fs_info *fs_info,
-			    struct seq_list *elem);
-void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
-			    struct seq_list *elem);
-
 static inline int is_fstree(u64 rootid)
 {
 	if (rootid == BTRFS_FS_TREE_OBJECTID ||

commit 8874e812feb4926f4a51a82c4fca75c7daa05fc5
Merge: 7b8377862bd8 cb77fcd88569
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 21 13:41:07 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This is a small pull with btrfs fixes.  The biggest of the bunch is
      another fix for the new backref walking code.
    
      We're still hammering out one btrfs dio vs buffered reads problem, but
      that one will have to wait for the next rc."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: delay iput with async extents
      Btrfs: add a missing spin_lock
      Btrfs: don't assume to be on the correct extent in add_all_parents
      Btrfs: introduce btrfs_next_old_item

commit 1c8f52a5e9539600543347bcdefafa1854e07986
Author: Alexander Block <ablock84@googlemail.com>
Date:   Tue Jun 19 07:42:25 2012 -0600

    Btrfs: introduce btrfs_next_old_item
    
    We introduce btrfs_next_old_item that uses btrfs_next_old_leaf instead
    of btrfs_next_leaf.
    
    btrfs_next_item is also changed to simply call btrfs_next_old_item with
    time_seq being 0.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index db15e9e7b91c..84ac723f58f8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2755,13 +2755,18 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_next_old_leaf(struct btrfs_root *root, struct btrfs_path *path,
 			u64 time_seq);
-static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
+static inline int btrfs_next_old_item(struct btrfs_root *root,
+				      struct btrfs_path *p, u64 time_seq)
 {
 	++p->slots[0];
 	if (p->slots[0] >= btrfs_header_nritems(p->nodes[0]))
-		return btrfs_next_leaf(root, p);
+		return btrfs_next_old_leaf(root, p, time_seq);
 	return 0;
 }
+static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
+{
+	return btrfs_next_old_item(root, p, 0);
+}
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
 int __must_check btrfs_drop_snapshot(struct btrfs_root *root,

commit 718f58ad61810b7d4a6c9178185495f762e90807
Merge: 424d54d2dca0 9c106405ddf8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 15 16:04:37 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs update from Chris Mason:
     "The dates look like I had to rebase this morning because there was a
      compiler warning for a printk arg that I had missed earlier.
    
      These are all fixes, including one to prevent using stale pointers for
      device names, and lots of fixes around transaction abort cleanups
      (Josef, Liu Bo).
    
      Jan Schmidt also sent in a number of fixes for the new reference
      number tracking code.
    
      Liu Bo beat me to updating the MAINTAINERS file.  Since he thought to
      also fix the git url, I kept his commit."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (24 commits)
      Btrfs: update MAINTAINERS info for BTRFS FILE SYSTEM
      Btrfs: destroy the items of the delayed inodes in error handling routine
      Btrfs: make sure that we've made everything in pinned tree clean
      Btrfs: avoid memory leak of extent state in error handling routine
      Btrfs: do not resize a seeding device
      Btrfs: fix missing inherited flag in rename
      Btrfs: fix incompat flags setting
      Btrfs: fix defrag regression
      Btrfs: call filemap_fdatawrite twice for compression
      Btrfs: keep inode pinned when compressing writes
      Btrfs: implement ->show_devname
      Btrfs: use rcu to protect device->name
      Btrfs: unlock everything properly in the error case for nocow
      Btrfs: fix btrfs_destroy_marked_extents
      Btrfs: abort the transaction if the commit fails
      Btrfs: wake up transaction waiters when aborting a transaction
      Btrfs: fix locking in btrfs_destroy_delayed_refs
      Btrfs: pass locked_page into extent_clear_unlock_delalloc if theres an error
      Btrfs: fix race in tree mod log addition
      Btrfs: add btrfs_next_old_leaf
      ...

commit 3d7806eca43e73a9721d2e09369200ed93036bd0
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon Jun 11 08:29:29 2012 +0200

    Btrfs: add btrfs_next_old_leaf
    
    To make sense of the tree mod log, the backref walker not only needs
    btrfs_search_old_slot, but it also called btrfs_next_leaf, which in turn was
    calling btrfs_search_slot. This obviously didn't give the correct result.
    
    This commit adds btrfs_next_old_leaf, a drop-in replacement for
    btrfs_next_leaf with a time_seq parameter. If it is zero, it behaves exactly
    like btrfs_next_leaf. If it is non-zero, it will use btrfs_search_old_slot
    with this time_seq parameter.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0151ca1ac657..db15e9e7b91c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2753,6 +2753,8 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 }
 
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
+int btrfs_next_old_leaf(struct btrfs_root *root, struct btrfs_path *path,
+			u64 time_seq);
 static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
 {
 	++p->slots[0];

commit 1193755ac6328ad240ba987e6ec41d5e8baf0680
Merge: 4edebed86690 0ef97dcfce41
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 1 10:34:35 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs changes from Al Viro.
     "A lot of misc stuff.  The obvious groups:
       * Miklos' atomic_open series; kills the damn abuse of
         ->d_revalidate() by NFS, which was the major stumbling block for
         all work in that area.
       * ripping security_file_mmap() and dealing with deadlocks in the
         area; sanitizing the neighborhood of vm_mmap()/vm_munmap() in
         general.
       * ->encode_fh() switched to saner API; insane fake dentry in
         mm/cleancache.c gone.
       * assorted annotations in fs (endianness, __user)
       * parts of Artem's ->s_dirty work (jff2 and reiserfs parts)
       * ->update_time() work from Josef.
       * other bits and pieces all over the place.
    
      Normally it would've been in two or three pull requests, but
      signal.git stuff had eaten a lot of time during this cycle ;-/"
    
    Fix up trivial conflicts in Documentation/filesystems/vfs.txt (the
    'truncate_range' inode method was removed by the VM changes, the VFS
    update adds an 'update_time()' method), and in fs/btrfs/ulist.[ch] (due
    to sparse fix added twice, with other changes nearby).
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (95 commits)
      nfs: don't open in ->d_revalidate
      vfs: retry last component if opening stale dentry
      vfs: nameidata_to_filp(): don't throw away file on error
      vfs: nameidata_to_filp(): inline __dentry_open()
      vfs: do_dentry_open(): don't put filp
      vfs: split __dentry_open()
      vfs: do_last() common post lookup
      vfs: do_last(): add audit_inode before open
      vfs: do_last(): only return EISDIR for O_CREAT
      vfs: do_last(): check LOOKUP_DIRECTORY
      vfs: do_last(): make ENOENT exit RCU safe
      vfs: make follow_link check RCU safe
      vfs: do_last(): use inode variable
      vfs: do_last(): inline walk_component()
      vfs: do_last(): make exit RCU safe
      vfs: split do_lookup()
      Btrfs: move over to use ->update_time
      fs: introduce inode operation ->update_time
      reiserfs: get rid of resierfs_sync_super
      reiserfs: mark the superblock as dirty a bit later
      ...

commit e41f941a23115e84a8550b3d901a13a14b2edc2f
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Mar 26 09:46:47 2012 -0400

    Btrfs: move over to use ->update_time
    
    Btrfs had been doing it's own file_update_time so we could catch ENOSPC
    properly, so just update our btrfs_update_time to work with the new stuff and
    then we'll be fancy later.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8fd72331d600..ba8743b9a825 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2922,7 +2922,6 @@ int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
 int btrfs_dirty_inode(struct inode *inode);
-int btrfs_update_time(struct file *file);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);

commit 1e20932a23578bb1ec59107843574e259b96193f
Merge: cfc442b69696 c31931088fd6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 31 16:50:28 2012 -0400

    Merge branch 'for-chris' of git://git.jan-o-sch.net/btrfs-unstable into for-linus
    
    Conflicts:
            fs/btrfs/ulist.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 95a06077f7edbd00d32612562be4d857a5b7df54
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Tue May 29 17:06:54 2012 +0200

    Btrfs: use delayed ref sequence numbers for all fs-tree updates
    
    The sequence number for delayed refs is needed to postpone certain delayed
    refs for a very short period while walking backrefs. Before the tree
    modification log, we thought we'd only have to hold back those references
    that don't have a counter operation.
    
    While now we've the tree mod log, we're rewinding fs tree blocks to a
    defined consistent state. We cannot know in advance for which tree block
    we'll be doing rewind operations later. Therefore, we must postpone all the
    delayed refs for fs-tree blocks, even those having a counter operation.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6ba21b12cec4..f5f11a6c5e92 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3121,4 +3121,11 @@ void btrfs_get_tree_mod_seq(struct btrfs_fs_info *fs_info,
 void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
 			    struct seq_list *elem);
 
+static inline int is_fstree(u64 rootid)
+{
+	if (rootid == BTRFS_FS_TREE_OBJECTID ||
+	    (s64)rootid >= (s64)BTRFS_FIRST_FREE_OBJECTID)
+		return 1;
+	return 0;
+}
 #endif

commit 3d136a1131c66f7d26fb171e4c5b0b8baacd3129
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Feb 3 11:20:04 2012 +0100

    Btrfs: set ioprio of scrub readahead to idle
    
    Reduce ioprio class of scrub readahead threads to idle priority.
    This setting is fixed. This priority has shown the best performance
    during all measurements.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e176f8c551f7..1c665ebe47e0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -173,6 +173,9 @@ static int btrfs_csum_sizes[] = { 4, 0 };
 #define BTRFS_FT_XATTR		8
 #define BTRFS_FT_MAX		9
 
+/* ioprio of readahead is set to idle */
+#define BTRFS_IOPRIO_READA (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_IDLE, 0))
+
 /*
  * The key defines the order in the tree, and so it also defines (optimal)
  * block layout.

commit 733f4fbbc1083aa343da739f46ee839705d6cfe3
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri May 25 16:06:10 2012 +0200

    Btrfs: read device stats on mount, write modified ones during commit
    
    The device statistics are written into the device tree with each
    transaction commit. Only modified statistics are written.
    When a filesystem is mounted, the device statistics for each involved
    device are read from the device tree and used to initialize the
    counters.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aad2600718a3..e176f8c551f7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -823,6 +823,14 @@ struct btrfs_csum_item {
 	u8 csum;
 } __attribute__ ((__packed__));
 
+struct btrfs_dev_stats_item {
+	/*
+	 * grow this item struct at the end for future enhancements and keep
+	 * the existing values unchanged
+	 */
+	__le64 values[BTRFS_DEV_STAT_VALUES_MAX];
+} __attribute__ ((__packed__));
+
 /* different types of block groups (and chunks) */
 #define BTRFS_BLOCK_GROUP_DATA		(1ULL << 0)
 #define BTRFS_BLOCK_GROUP_SYSTEM	(1ULL << 1)
@@ -1507,6 +1515,12 @@ struct btrfs_ioctl_defrag_range_args {
 
 #define BTRFS_BALANCE_ITEM_KEY	248
 
+/*
+ * Persistantly stores the io stats in the device tree.
+ * One key for all stats, (0, BTRFS_DEV_STATS_KEY, devid).
+ */
+#define BTRFS_DEV_STATS_KEY	249
+
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
@@ -2415,6 +2429,30 @@ static inline u32 btrfs_file_extent_inline_item_len(struct extent_buffer *eb,
 	return btrfs_item_size(eb, e) - offset;
 }
 
+/* btrfs_dev_stats_item */
+static inline u64 btrfs_dev_stats_value(struct extent_buffer *eb,
+					struct btrfs_dev_stats_item *ptr,
+					int index)
+{
+	u64 val;
+
+	read_extent_buffer(eb, &val,
+			   offsetof(struct btrfs_dev_stats_item, values) +
+			    ((unsigned long)ptr) + (index * sizeof(u64)),
+			   sizeof(val));
+	return val;
+}
+
+static inline void btrfs_set_dev_stats_value(struct extent_buffer *eb,
+					     struct btrfs_dev_stats_item *ptr,
+					     int index, u64 val)
+{
+	write_extent_buffer(eb, &val,
+			    offsetof(struct btrfs_dev_stats_item, values) +
+			     ((unsigned long)ptr) + (index * sizeof(u64)),
+			    sizeof(val));
+}
+
 static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;

commit 8a35d95ff4680a456d3ce47df9638f33d4f54f20
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 23 14:26:42 2012 -0400

    Btrfs: fix how we deal with the orphan block rsv
    
    Ceph was hitting this race where we would remove an inode from the per-root
    orphan list before we would release the space we had reserved for the inode.
    We actually don't need a list or anything, we just need to make sure the
    root doesn't try to free up the orphan reserve until after the inodes have
    released their reservations.  So use an atomic counter instead of a list on
    the root and only decrement the counter after we've released our
    reservation.  I've tested this as well as several others and we no longer
    see the warnings that you would see while running ceph.  Thanks,
    Btrfs: fix how we deal with the orphan block rsv
    
    Ceph was hitting this race where we would remove an inode from the per-root
    orphan list before we would release the space we had reserved for the inode.
    We actually don't need a list or anything, we just need to make sure the
    root doesn't try to free up the orphan reserve until after the inodes have
    released their reservations.  So use an atomic counter instead of a list on
    the root and only decrement the counter after we've released our
    reservation.  I've tested this as well as several others and we no longer
    see the warnings that you would see while running ceph.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8fd72331d600..aad2600718a3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1375,7 +1375,7 @@ struct btrfs_root {
 	struct list_head root_list;
 
 	spinlock_t orphan_lock;
-	struct list_head orphan_list;
+	atomic_t orphan_inodes;
 	struct btrfs_block_rsv *orphan_block_rsv;
 	int orphan_item_inserted;
 	int orphan_cleanup_state;

commit 5d9e75c41d11ca79b1d1ff6ed17c88c9047d1fea
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 18:25:47 2012 +0200

    Btrfs: add btrfs_search_old_slot
    
    The tree modification log together with the current state of the tree gives
    a consistent, old version of the tree. btrfs_search_old_slot is used to
    search through this old version and return old (dummy!) extent buffers.
    Naturally, this function cannot do any tree modifications.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e53bfb9b3915..6ba21b12cec4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2668,6 +2668,8 @@ int btrfs_duplicate_item(struct btrfs_trans_handle *trans,
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
+int btrfs_search_old_slot(struct btrfs_root *root, struct btrfs_key *key,
+			  struct btrfs_path *p, u64 time_seq);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct extent_buffer *parent,
 		       int start_slot, int cache_only, u64 *last_ret,

commit bd989ba359f2acb8bc5f5490e19010fc0a6f8356
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 17:18:50 2012 +0200

    Btrfs: add tree modification log functions
    
    The tree mod log will log modifications made fs-tree nodes. Most
    modifications are done by autobalance of the tree. Such changes are recorded
    as long as a block entry exists. When released, the log is cleaned.
    
    With the tree modification log, it's possible to reconstruct a consistent
    old state of the tree. This is required to do backref walking on a busy
    file system.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 01639e100045..e53bfb9b3915 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3114,4 +3114,9 @@ struct seq_list {
 	u32 flags;
 };
 
+void btrfs_get_tree_mod_seq(struct btrfs_fs_info *fs_info,
+			    struct seq_list *elem);
+void btrfs_put_tree_mod_seq(struct btrfs_fs_info *fs_info,
+			    struct seq_list *elem);
+
 #endif

commit f29021b29a85701c08afadfd51d87163fb078059
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 17:55:38 2012 +0200

    Btrfs: add tree mod log to fs_info
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e0da6dbeb570..01639e100045 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1129,6 +1129,15 @@ struct btrfs_fs_info {
 	spinlock_t delayed_iput_lock;
 	struct list_head delayed_iputs;
 
+	/* this protects tree_mod_seq_list */
+	spinlock_t tree_mod_seq_lock;
+	atomic_t tree_mod_seq;
+	struct list_head tree_mod_seq_list;
+
+	/* this protects tree_mod_log */
+	rwlock_t tree_mod_log_lock;
+	struct rb_root tree_mod_log;
+
 	atomic_t nr_async_submits;
 	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;

commit 64947ec0d16dd20d6542b58cf82c8d5f9678cabf
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 16:57:09 2012 +0200

    Btrfs: move struct seq_list to ctree.h
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e863188a3f17..e0da6dbeb570 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3098,4 +3098,11 @@ void btrfs_reada_detach(void *handle);
 int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 			 u64 start, int err);
 
+/* delayed seq elem */
+struct seq_list {
+	struct list_head list;
+	u64 seq;
+	u32 flags;
+};
+
 #endif

commit 5581a51a59a1f5f51ac3d4bacafb738d35e0350b
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 17:04:52 2012 +0200

    Btrfs: don't set for_cow parameter for tree block functions
    
    Three callers of btrfs_free_tree_block or btrfs_alloc_tree_block passed
    parameter for_cow = 1. In fact, these two functions should never mark
    their tree modification operations as for_cow, because they can change
    the number of blocks referenced by a tree.
    
    Hence, we remove the extra for_cow parameter from these functions and
    make them pass a zero down.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ec42a24e935e..e863188a3f17 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2496,11 +2496,11 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					struct btrfs_root *root, u32 blocksize,
 					u64 parent, u64 root_objectid,
 					struct btrfs_disk_key *key, int level,
-					u64 hint, u64 empty_size, int for_cow);
+					u64 hint, u64 empty_size);
 void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct extent_buffer *buf,
-			   u64 parent, int last_ref, int for_cow);
+			   u64 parent, int last_ref);
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize,

commit f7b006931751f029620ad2f8310ac7a1484fbdb4
Merge: b990f9b3cb06 dc7fdde39e49
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 28 09:30:07 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This has our collection of bug fixes.  I missed the last rc because I
      thought our patches were making NFS crash during my xfs test runs.
      Turns out it was an NFS client bug fixed by someone else while I tried
      to bisect it.
    
      All of these fixes are small, but some are fairly high impact.  The
      biggest are fixes for our mount -o remount handling, a deadlock due to
      GFP_KERNEL allocations in readdir, and a RAID10 error handling bug.
    
      This was tested against both 3.3 and Linus' master as of this morning."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (26 commits)
      Btrfs: reduce lock contention during extent insertion
      Btrfs: avoid deadlocks from GFP_KERNEL allocations during btrfs_real_readdir
      Btrfs: Fix space checking during fs resize
      Btrfs: fix block_rsv and space_info lock ordering
      Btrfs: Prevent root_list corruption
      Btrfs: fix repair code for RAID10
      Btrfs: do not start delalloc inodes during sync
      Btrfs: fix that check_int_data mount option was ignored
      Btrfs: don't count CRC or header errors twice while scrubbing
      Btrfs: fix btrfs_ioctl_dev_info() crash on missing device
      btrfs: don't return EINTR
      Btrfs: double unlock bug in error handling
      Btrfs: always store the mirror we read the eb from
      fs/btrfs/volumes.c: add missing free_fs_devices
      btrfs: fix early abort in 'remount'
      Btrfs: fix max chunk size check in chunk allocator
      Btrfs: add missing read locks in backref.c
      Btrfs: don't call free_extent_buffer twice in iterate_irefs
      Btrfs: Make free_ipath() deal gracefully with NULL pointers
      Btrfs: avoid possible use-after-free in clear_extent_bit()
      ...

commit 25cd999e1a685dab65292afbe9fa24d790d8a859
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Mar 30 13:58:32 2012 +0200

    Btrfs: fix that check_int_data mount option was ignored
    
    The bitfield member mount_opt was too small by one bit to hold the mount
    option that enabled to include data extents in the integrity checker.
    Since the same issue happened when the BTRFS_MOUNT_PANIC_ON_FATAL_ERROR
    option was added (git rebase silently merges so that the increase of the
    size of the bitfield member is lost), the bit limit was removed entirely.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5b8ef8eb3521..ec42a24e935e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1078,7 +1078,7 @@ struct btrfs_fs_info {
 	 * is required instead of the faster short fsync log commits
 	 */
 	u64 last_trans_log_full_commit;
-	unsigned long mount_opt:21;
+	unsigned long mount_opt;
 	unsigned long compress_type:4;
 	u64 max_inline;
 	u64 alloc_start;

commit 6ed3cf2cdfce4c9f1d73171bd3f27d9cb77b734e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Apr 13 11:49:04 2012 -0400

    btrfs: btrfs_root_readonly() broken on big-endian
    
    ->root_flags is __le64 and all accesses to it go through the helpers
    that do proper conversions.  Except for btrfs_root_readonly(), which
    checks bit 0 as in host-endian...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5b8ef8eb3521..3f65a812e282 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2166,7 +2166,7 @@ BTRFS_SETGET_STACK_FUNCS(root_last_snapshot, struct btrfs_root_item,
 
 static inline bool btrfs_root_readonly(struct btrfs_root *root)
 {
-	return root->root_item.flags & BTRFS_ROOT_SUBVOL_RDONLY;
+	return (root->root_item.flags & cpu_to_le64(BTRFS_ROOT_SUBVOL_RDONLY)) != 0;
 }
 
 /* struct btrfs_root_backup */

commit 1c691b330a19a1344df89bcb0f4cacd99e8b289a
Merge: 1d4284bd6e8d 213e64da90d1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 20:32:46 2012 -0400

    Merge branch 'for-chris' of git://github.com/idryomov/btrfs-unstable into for-linus

commit 1d4284bd6e8d7dd1d5521a6747bdb6dc1caf0225
Merge: b5d67f64f9bc 65139ed99234
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 20:31:37 2012 -0400

    Merge branch 'error-handling' into for-linus
    
    Conflicts:
            fs/btrfs/ctree.c
            fs/btrfs/disk-io.c
            fs/btrfs/extent-tree.c
            fs/btrfs/extent_io.c
            fs/btrfs/extent_io.h
            fs/btrfs/inode.c
            fs/btrfs/scrub.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 94598ba8d8ff066115508fb99e593d2de1ca67e1
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Mar 27 14:21:26 2012 -0400

    Btrfs: introduce common define for max number of mirrors
    
    Readahead already has a define for the max number of mirrors. Scrub
    needs such a define now, the rest of the code will need something
    like this soon. Therefore the define was added to ctree.h and removed
    from the readahead code.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c2e17cd299b7..f7da8a8d13c1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -48,6 +48,8 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAGIC "_BHRfS_M"
 
+#define BTRFS_MAX_MIRRORS 2
+
 #define BTRFS_MAX_LEVEL 8
 
 #define BTRFS_COMPAT_EXTENT_TREE_V0

commit 0c460c0d70e10463e44bdf1d406e9c5ec03b1af6
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Tue Mar 27 17:09:17 2012 +0300

    Btrfs: move alloc_profile_is_valid() to volumes.c
    
    Header file is not a good place to define functions.  This also moves a
    call to alloc_profile_is_valid() down the stack and removes a redundant
    check from __btrfs_alloc_chunk() - alloc_profile_is_valid() takes it
    into account.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f057e92df39f..a56e1e00105f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2734,29 +2734,6 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->super_for_commit);
 	kfree(fs_info);
 }
-/**
- * alloc_profile_is_valid - see if a given profile is valid and reduced
- * @flags: profile to validate
- * @extended: if true @flags is treated as an extended profile
- */
-static inline int alloc_profile_is_valid(u64 flags, int extended)
-{
-	u64 mask = (extended ? BTRFS_EXTENDED_PROFILE_MASK :
-			       BTRFS_BLOCK_GROUP_PROFILE_MASK);
-
-	flags &= ~BTRFS_BLOCK_GROUP_TYPE_MASK;
-
-	/* 1) check that all other bits are zeroed */
-	if (flags & ~mask)
-		return 0;
-
-	/* 2) see if profile is reduced */
-	if (flags == 0)
-		return !extended; /* "0" is valid for usual profiles */
-
-	/* true if exactly one bit set */
-	return (flags & (flags - 1)) == 0;
-}
 
 /* root-item.c */
 int btrfs_find_root_ref(struct btrfs_root *tree_root,

commit e8920a640be5d4ebe3fee0670639a81d4ffc904c
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Tue Mar 27 17:09:17 2012 +0300

    Btrfs: make profile_is_valid() check more strict
    
    "0" is a valid value for an on-disk chunk profile, but it is not a valid
    extended profile.  (We have a separate bit for single chunks in extended
    case)
    
    Also rename it to alloc_profile_is_valid() for clarity.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aba7832a2285..f057e92df39f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2735,22 +2735,27 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info);
 }
 /**
- * profile_is_valid - tests whether a given profile is valid and reduced
+ * alloc_profile_is_valid - see if a given profile is valid and reduced
  * @flags: profile to validate
  * @extended: if true @flags is treated as an extended profile
  */
-static inline int profile_is_valid(u64 flags, int extended)
+static inline int alloc_profile_is_valid(u64 flags, int extended)
 {
-	u64 mask = ~BTRFS_BLOCK_GROUP_PROFILE_MASK;
+	u64 mask = (extended ? BTRFS_EXTENDED_PROFILE_MASK :
+			       BTRFS_BLOCK_GROUP_PROFILE_MASK);
 
 	flags &= ~BTRFS_BLOCK_GROUP_TYPE_MASK;
-	if (extended)
-		mask &= ~BTRFS_AVAIL_ALLOC_BIT_SINGLE;
 
-	if (flags & mask)
+	/* 1) check that all other bits are zeroed */
+	if (flags & ~mask)
 		return 0;
-	/* true if zero or exactly one bit set */
-	return (flags & (~flags + 1)) == flags;
+
+	/* 2) see if profile is reduced */
+	if (flags == 0)
+		return !extended; /* "0" is valid for usual profiles */
+
+	/* true if exactly one bit set */
+	return (flags & (flags - 1)) == 0;
 }
 
 /* root-item.c */

commit 899c81eac890bcfa5f3636f4c43f68e8393ac1f8
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Tue Mar 27 17:09:16 2012 +0300

    Btrfs: add wrappers for working with alloc profiles
    
    Add functions to abstract the conversion between chunk and extended
    allocation profile formats and switch everybody to use them.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c2e17cd299b7..aba7832a2285 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -849,6 +849,21 @@ struct btrfs_csum_item {
  */
 #define BTRFS_AVAIL_ALLOC_BIT_SINGLE	(1ULL << 48)
 
+#define BTRFS_EXTENDED_PROFILE_MASK	(BTRFS_BLOCK_GROUP_PROFILE_MASK | \
+					 BTRFS_AVAIL_ALLOC_BIT_SINGLE)
+
+static inline u64 chunk_to_extended(u64 flags)
+{
+	if ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0)
+		flags |= BTRFS_AVAIL_ALLOC_BIT_SINGLE;
+
+	return flags;
+}
+static inline u64 extended_to_chunk(u64 flags)
+{
+	return flags & ~BTRFS_AVAIL_ALLOC_BIT_SINGLE;
+}
+
 struct btrfs_block_group_item {
 	__le64 used;
 	__le64 chunk_objectid;

commit cfed81a04eb555f5606d1b6a54bdbabab0ee1ac3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Mar 3 07:40:03 2012 -0500

    Btrfs: add the ability to cache a pointer into the eb
    
    This cuts down on the CPU time used by map_private_extent_buffer
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 85ab1c5844a2..c2e17cd299b7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1546,6 +1546,17 @@ struct btrfs_ioctl_defrag_range_args {
 
 #define BTRFS_INODE_ROOT_ITEM_INIT	(1 << 31)
 
+struct btrfs_map_token {
+	struct extent_buffer *eb;
+	char *kaddr;
+	unsigned long offset;
+};
+
+static inline void btrfs_init_map_token (struct btrfs_map_token *token)
+{
+	memset(token, 0, sizeof(*token));
+}
+
 /* some macros to generate set/get funcs for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple
  * one for u8:
@@ -1569,6 +1580,8 @@ struct btrfs_ioctl_defrag_range_args {
 #ifndef BTRFS_SETGET_FUNCS
 #define BTRFS_SETGET_FUNCS(name, type, member, bits)			\
 u##bits btrfs_##name(struct extent_buffer *eb, type *s);		\
+u##bits btrfs_token_##name(struct extent_buffer *eb, type *s, struct btrfs_map_token *token);		\
+void btrfs_set_token_##name(struct extent_buffer *eb, type *s, u##bits val, struct btrfs_map_token *token);\
 void btrfs_set_##name(struct extent_buffer *eb, type *s, u##bits val);
 #endif
 

commit 727011e07cbdf87772fcc1999cccd15cc915eb62
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 6 13:21:20 2010 -0400

    Btrfs: allow metadata blocks larger than the page size
    
    A few years ago the btrfs code to support blocks lager than
    the page size was disabled to fix a few corner cases in the
    page cache handling.  This fixes the code to properly support
    large metadata blocks again.
    
    Since current kernels will crash early and often with larger
    metadata blocks, this adds an incompat bit so that older kernels
    can't mount it.
    
    This also does away with different blocksizes for nodes and leaves.
    You get a single block size for all tree blocks.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index edccc948e877..85ab1c5844a2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -137,6 +137,12 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_EMPTY_SUBVOL_DIR_OBJECTID 2
 
+/*
+ * the max metadata block size.  This limit is somewhat artificial,
+ * but the memmove costs go through the roof for larger blocks.
+ */
+#define BTRFS_MAX_METADATA_BLOCKSIZE 65536
+
 /*
  * we can actually store much bigger names, but lets not confuse the rest
  * of linux
@@ -461,6 +467,19 @@ struct btrfs_super_block {
 #define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(1ULL << 1)
 #define BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS	(1ULL << 2)
 #define BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO	(1ULL << 3)
+/*
+ * some patches floated around with a second compression method
+ * lets save that incompat here for when they do get in
+ * Note we don't actually support it, we're just reserving the
+ * number
+ */
+#define BTRFS_FEATURE_INCOMPAT_COMPRESS_LZOv2	(1ULL << 4)
+
+/*
+ * older kernels tried to do bigger metadata blocks, but the
+ * code was pretty buggy.  Lets not let them try anymore.
+ */
+#define BTRFS_FEATURE_INCOMPAT_BIG_METADATA	(1ULL << 5)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
@@ -468,6 +487,7 @@ struct btrfs_super_block {
 	(BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF |		\
 	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL |	\
 	 BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS |		\
+	 BTRFS_FEATURE_INCOMPAT_BIG_METADATA |		\
 	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO)
 
 /*
@@ -1555,14 +1575,14 @@ void btrfs_set_##name(struct extent_buffer *eb, type *s, u##bits val);
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
 static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
 {									\
-	type *p = page_address(eb->first_page);				\
+	type *p = page_address(eb->pages[0]);				\
 	u##bits res = le##bits##_to_cpu(p->member);			\
 	return res;							\
 }									\
 static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 				    u##bits val)			\
 {									\
-	type *p = page_address(eb->first_page);				\
+	type *p = page_address(eb->pages[0]);				\
 	p->member = cpu_to_le##bits(val);				\
 }
 

commit 81c9ad237c604adec79fd4d4034264c6669e0ab3
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Jan 18 10:56:06 2012 -0500

    Btrfs: remove search_start and search_end from find_free_extent and callers
    
    We have been passing nothing but (u64)-1 to find_free_extent for search_end in
    all of the callers, so it's completely useless, and we've always been passing 0
    in as search_start, so just remove them as function arguments and move
    search_start into find_free_extent.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 80b6486fd5e6..edccc948e877 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2466,8 +2466,7 @@ int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  struct btrfs_root *root,
 				  u64 num_bytes, u64 min_alloc_size,
 				  u64 empty_size, u64 hint_byte,
-				  u64 search_end, struct btrfs_key *ins,
-				  u64 data);
+				  struct btrfs_key *ins, u64 data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf, int full_backref, int for_cow);
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,

commit 49b25e0540904be0bf558b84475c69d72e4de66e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 17:24:58 2012 +0100

    btrfs: enhance transaction abort infrastructure
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8829f8099851..b6ebea5582c6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2968,6 +2968,16 @@ void btrfs_printk(struct btrfs_fs_info *fs_info, const char *fmt, ...);
 void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
 		     unsigned int line, int errno, const char *fmt, ...);
 
+void __btrfs_abort_transaction(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *root, const char *function,
+			       unsigned int line, int errno);
+
+#define btrfs_abort_transaction(trans, root, errno)		\
+do {								\
+	__btrfs_abort_transaction(trans, root, __func__,	\
+				  __LINE__, errno);		\
+} while (0)
+
 #define btrfs_std_error(fs_info, errno)				\
 do {								\
 	if ((errno))						\
@@ -3024,7 +3034,7 @@ void btrfs_reloc_cow_block(struct btrfs_trans_handle *trans,
 void btrfs_reloc_pre_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending,
 			      u64 *bytes_to_reserve);
-void btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
+int btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending);
 
 /* scrub.c */
@@ -3034,6 +3044,7 @@ void btrfs_scrub_pause(struct btrfs_root *root);
 void btrfs_scrub_pause_super(struct btrfs_root *root);
 void btrfs_scrub_continue(struct btrfs_root *root);
 void btrfs_scrub_continue_super(struct btrfs_root *root);
+int __btrfs_scrub_cancel(struct btrfs_fs_info *info);
 int btrfs_scrub_cancel(struct btrfs_root *root);
 int btrfs_scrub_cancel_dev(struct btrfs_root *root, struct btrfs_device *dev);
 int btrfs_scrub_cancel_devid(struct btrfs_root *root, u64 devid);

commit 4da35113426d16673aa1fb0613c14ca2e419e7fd
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:57:30 2012 +0100

    btrfs: add varargs to btrfs_error
    
     btrfs currently handles most errors with BUG_ON. This patch is a work-in-
     progress but aims to handle most errors other than internal logic
     errors and ENOMEM more gracefully.
    
     This iteration prevents most crashes but can run into lockups with
     the page lock on occasion when the timing "works out."
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f6bca05a4b4c..8829f8099851 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2964,13 +2964,21 @@ ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 /* super.c */
 int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
+void btrfs_printk(struct btrfs_fs_info *fs_info, const char *fmt, ...);
 void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
-		     unsigned int line, int errno);
+		     unsigned int line, int errno, const char *fmt, ...);
 
 #define btrfs_std_error(fs_info, errno)				\
 do {								\
 	if ((errno))						\
-		__btrfs_std_error((fs_info), __func__, __LINE__, (errno));\
+		__btrfs_std_error((fs_info), __func__,		\
+				   __LINE__, (errno), NULL);	\
+} while (0)
+
+#define btrfs_error(fs_info, errno, fmt, args...)		\
+do {								\
+	__btrfs_std_error((fs_info), __func__, __LINE__,	\
+			  (errno), fmt, ##args);		\
 } while (0)
 
 void __btrfs_panic(struct btrfs_fs_info *fs_info, const char *function,

commit 2c536799f1bde905bbacf7af3aa6be3f4de66005
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Oct 3 23:22:41 2011 -0400

    btrfs: btrfs_drop_snapshot should return int
    
    Commit cb1b69f4 (Btrfs: forced readonly when btrfs_drop_snapshot() fails)
    made btrfs_drop_snapshot return void because there were no callers checking
    the return value. That is the wrong order to handle error propogation since
    the caller will have no idea that an error has occured and continue on
    as if nothing went wrong.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 30c5a247ab2b..f6bca05a4b4c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2661,9 +2661,9 @@ static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
 }
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
-void btrfs_drop_snapshot(struct btrfs_root *root,
-			 struct btrfs_block_rsv *block_rsv, int update_ref,
-			 int for_reloc);
+int __must_check btrfs_drop_snapshot(struct btrfs_root *root,
+				     struct btrfs_block_rsv *block_rsv,
+				     int update_ref, int for_reloc);
 int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct extent_buffer *node,

commit 143bede527b054a271053f41bfaca2b57baa9408
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:56:26 2012 +0100

    btrfs: return void in functions without error conditions
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 339e637ab272..30c5a247ab2b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2485,8 +2485,8 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans,
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_free_and_pin_reserved_extent(struct btrfs_root *root,
 				       u64 start, u64 len);
-int btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root);
+void btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
+				 struct btrfs_root *root);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
@@ -2549,8 +2549,8 @@ void btrfs_block_rsv_release(struct btrfs_root *root,
 			     u64 num_bytes);
 int btrfs_set_block_group_ro(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
-int btrfs_set_block_group_rw(struct btrfs_root *root,
-			     struct btrfs_block_group_cache *cache);
+void btrfs_set_block_group_rw(struct btrfs_root *root,
+			      struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
 int btrfs_error_unpin_extent_range(struct btrfs_root *root,
@@ -2569,9 +2569,9 @@ int btrfs_comp_cpu_keys(struct btrfs_key *k1, struct btrfs_key *k2);
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
-int btrfs_set_item_key_safe(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root, struct btrfs_path *path,
-			    struct btrfs_key *new_key);
+void btrfs_set_item_key_safe(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root, struct btrfs_path *path,
+			     struct btrfs_key *new_key);
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
 int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
@@ -2591,12 +2591,13 @@ int btrfs_copy_root(struct btrfs_trans_handle *trans,
 		      struct extent_buffer **cow_ret, u64 new_root_objectid);
 int btrfs_block_can_be_shared(struct btrfs_root *root,
 			      struct extent_buffer *buf);
-int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, struct btrfs_path *path, u32 data_size);
-int btrfs_truncate_item(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root,
-			struct btrfs_path *path,
-			u32 new_size, int from_end);
+void btrfs_extend_item(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root, struct btrfs_path *path,
+		       u32 data_size);
+void btrfs_truncate_item(struct btrfs_trans_handle *trans,
+			 struct btrfs_root *root,
+			 struct btrfs_path *path,
+			 u32 new_size, int from_end);
 int btrfs_split_item(struct btrfs_trans_handle *trans,
 		     struct btrfs_root *root,
 		     struct btrfs_path *path,
@@ -2630,10 +2631,10 @@ static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 	return btrfs_del_items(trans, root, path, path->slots[0], 1);
 }
 
-int setup_items_for_insert(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, struct btrfs_path *path,
-			   struct btrfs_key *cpu_key, u32 *data_size,
-			   u32 total_data, u32 total_size, int nr);
+void setup_items_for_insert(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root, struct btrfs_path *path,
+			    struct btrfs_key *cpu_key, u32 *data_size,
+			    u32 total_data, u32 total_size, int nr);
 int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, void *data, u32 data_size);
 int btrfs_insert_empty_items(struct btrfs_trans_handle *trans,
@@ -2911,7 +2912,7 @@ int btrfs_orphan_cleanup(struct btrfs_root *root);
 void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t oldsize, loff_t size);
-int btrfs_invalidate_inodes(struct btrfs_root *root);
+void btrfs_invalidate_inodes(struct btrfs_root *root);
 void btrfs_add_delayed_iput(struct inode *inode);
 void btrfs_run_delayed_iputs(struct btrfs_root *root);
 int btrfs_prealloc_file_range(struct inode *inode, int mode,
@@ -3021,10 +3022,10 @@ void btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 /* scrub.c */
 int btrfs_scrub_dev(struct btrfs_root *root, u64 devid, u64 start, u64 end,
 		    struct btrfs_scrub_progress *progress, int readonly);
-int btrfs_scrub_pause(struct btrfs_root *root);
-int btrfs_scrub_pause_super(struct btrfs_root *root);
-int btrfs_scrub_continue(struct btrfs_root *root);
-int btrfs_scrub_continue_super(struct btrfs_root *root);
+void btrfs_scrub_pause(struct btrfs_root *root);
+void btrfs_scrub_pause_super(struct btrfs_root *root);
+void btrfs_scrub_continue(struct btrfs_root *root);
+void btrfs_scrub_continue_super(struct btrfs_root *root);
 int btrfs_scrub_cancel(struct btrfs_root *root);
 int btrfs_scrub_cancel_dev(struct btrfs_root *root, struct btrfs_device *dev);
 int btrfs_scrub_cancel_devid(struct btrfs_root *root, u64 devid);

commit b45a9d8b48e5ce534bd222007c43cbf374544f0b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Oct 3 23:22:44 2011 -0400

    btrfs: btrfs_update_root error push-up
    
    btrfs_update_root BUG's when it can't alloc a path, yet it can recover
    from a search error. This patch returns -ENOMEM instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a97a67089755..339e637ab272 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2724,9 +2724,10 @@ int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_root_item
 		      *item);
-int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, struct btrfs_key *key, struct btrfs_root_item
-		      *item);
+int __must_check btrfs_update_root(struct btrfs_trans_handle *trans,
+				   struct btrfs_root *root,
+				   struct btrfs_key *key,
+				   struct btrfs_root_item *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);

commit 8c3429300181be44b30f9f017d53dc717da56caa
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Oct 3 23:22:31 2011 -0400

    btrfs: Add btrfs_panic()
    
    As part of the effort to eliminate BUG_ON as an error handling
    technique, we need to determine which errors are actual logic errors,
    which are on-disk corruption, and which are normal runtime errors
    e.g. -ENOMEM.
    
    Annotating these error cases is helpful to understand and report them.
    
    This patch adds a btrfs_panic() routine that will either panic
    or BUG depending on the new -ofatal_errors={panic,bug} mount option.
    Since there are still so many BUG_ONs, it defaults to BUG for now but I
    expect that to change once the error handling effort has made
    significant progress.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 80b6486fd5e6..a97a67089755 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1503,6 +1503,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_SKIP_BALANCE	(1 << 19)
 #define BTRFS_MOUNT_CHECK_INTEGRITY	(1 << 20)
 #define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 21)
+#define BTRFS_MOUNT_PANIC_ON_FATAL_ERROR	(1 << 22)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
@@ -2970,6 +2971,16 @@ do {								\
 		__btrfs_std_error((fs_info), __func__, __LINE__, (errno));\
 } while (0)
 
+void __btrfs_panic(struct btrfs_fs_info *fs_info, const char *function,
+		   unsigned int line, int errno, const char *fmt, ...);
+
+#define btrfs_panic(fs_info, errno, fmt, args...)			\
+do {									\
+	struct btrfs_fs_info *_i = (fs_info);				\
+	__btrfs_panic(_i, __func__, __LINE__, errno, fmt, ##args);	\
+	BUG_ON(!(_i->mount_opt & BTRFS_MOUNT_PANIC_ON_FATAL_ERROR));	\
+} while (0)
+
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL
 struct posix_acl *btrfs_get_acl(struct inode *inode, int type);

commit 855a85f704026d5fe7de94fb1b765fe03404507f
Merge: ee3253241a92 e77266e4c4be
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 24 09:02:53 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Quoth Chris:
     "This is later than I wanted because I got backed up running through
      btrfs bugs from the Oracle QA teams.  But they are all bug fixes that
      we've queued and tested since rc1.
    
      Nothing in particular stands out, this just reflects bug fixing and QA
      done in parallel by all the btrfs developers.  The most user visible
      of these is:
    
        Btrfs: clear the extent uptodate bits during parent transid failures
    
      Because that helps deal with out of date drives (say an iscsi disk
      that has gone away and come back).  The old code wasn't always
      properly retrying the other mirror for this type of failure."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (24 commits)
      Btrfs: fix compiler warnings on 32 bit systems
      Btrfs: increase the global block reserve estimates
      Btrfs: clear the extent uptodate bits during parent transid failures
      Btrfs: add extra sanity checks on the path names in btrfs_mksubvol
      Btrfs: make sure we update latest_bdev
      Btrfs: improve error handling for btrfs_insert_dir_item callers
      Btrfs: be less strict on finding next node in clear_extent_bit
      Btrfs: fix a bug on overcommit stuff
      Btrfs: kick out redundant stuff in convert_extent_bit
      Btrfs: skip states when they does not contain bits to clear
      Btrfs: check return value of lookup_extent_mapping() correctly
      Btrfs: fix deadlock on page lock when doing auto-defragment
      Btrfs: fix return value check of extent_io_ops
      btrfs: honor umask when creating subvol root
      btrfs: silence warning in raid array setup
      btrfs: fix structs where bitfields and spinlock/atomic share 8B word
      btrfs: delalloc for page dirtied out-of-band in fixup worker
      Btrfs: fix memory leak in load_free_space_cache()
      btrfs: don't check DUP chunks twice
      Btrfs: fix trim 0 bytes after a device delete
      ...

commit c08782dacd7a098f2b8bca7f4a57a5b402e9e1e5
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jan 26 15:01:12 2012 -0500

    btrfs: fix structs where bitfields and spinlock/atomic share 8B word
    
    On ia64, powerpc64 and sparc64 the bitfield is modified through a RMW cycle and current
    gcc rewrites the adjacent 4B word, which in case of a spinlock or atomic has
    disaterous effect.
    
    https://lkml.org/lkml/2012/2/1/220
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3c2cbf7b6663..8e4457e0478e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -886,7 +886,7 @@ struct btrfs_block_rsv {
 	u64 reserved;
 	struct btrfs_space_info *space_info;
 	spinlock_t lock;
-	unsigned int full:1;
+	unsigned int full;
 };
 
 /*

commit d65773b22b749252b2805dcf96bdeb951a9481d8
Merge: f9156c7288e2 f84a8bd60e3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 17 15:52:51 2012 -0800

    Merge branch 'btrfs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    * 'btrfs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      btrfs: take allocation of ->tree_root into open_ctree()
      btrfs: let ->s_fs_info point to fs_info, not root...
      btrfs: consolidate failure exits in btrfs_mount() a bit
      btrfs: make free_fs_info() call ->kill_sb() unconditional
      btrfs: merge free_fs_info() calls on fill_super failures
      btrfs: kill pointless reassignment of ->s_fs_info in btrfs_fill_super()
      btrfs: make open_ctree() return int
      btrfs: sanitizing ->fs_info, part 5
      btrfs: sanitizing ->fs_info, part 4
      btrfs: sanitizing ->fs_info, part 3
      btrfs: sanitizing ->fs_info, part 2
      btrfs: sanitizing ->fs_info, part 1
      btrfs: fix a deadlock in btrfs_scan_one_device()
      btrfs: fix mount/umount race
      btrfs: get ->kill_sb() of its own
      btrfs: preparation to fixing mount/umount race

commit c126dea771be1b3c370c0ffc4a09e6a82d492a49
Merge: 9785dbdf265d 21adbd5cbb53
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 16 15:27:58 2012 -0500

    Merge branch 'integrity-check-patch-v2' of git://btrfs.giantdisaster.de/git/btrfs into integration
    
    Conflicts:
            fs/btrfs/ctree.h
            fs/btrfs/super.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 9785dbdf265ddc47d5c88267d89a97648c0dc14b
Merge: d756bd2d9339 6bf7e080d5bc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 16 15:26:31 2012 -0500

    Merge branch 'for-chris' of git://git.jan-o-sch.net/btrfs-unstable into integration

commit a7e99c691af553fc15ac46a51f130b7c59a65f76
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:49 2012 +0200

    Btrfs: allow for canceling restriper
    
    Implement an ioctl for canceling restriper.  Currently we wait until
    relocation of the current block group is finished, in future this can be
    done by triggering a commit.  Balance item is deleted and no memory
    about the interrupted balance is kept.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1afda75d5414..dfc136cc07d7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1216,6 +1216,7 @@ struct btrfs_fs_info {
 	struct mutex balance_mutex;
 	atomic_t balance_running;
 	atomic_t balance_pause_req;
+	atomic_t balance_cancel_req;
 	struct btrfs_balance_control *balance_ctl;
 	wait_queue_head_t balance_wait_q;
 

commit 837d5b6e46d1a4af5b6cc8f2fe83cb5de79a2961
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:49 2012 +0200

    Btrfs: allow for pausing restriper
    
    Implement an ioctl for pausing restriper.  This pauses the relocation,
    but balance is still considered to be "in progress": balance item is
    not deleted, other volume operations cannot be started, etc.  If paused
    in the middle of profile changing operation we will continue making
    allocations with the target profile.
    
    Add a hook to close_ctree() to pause restriper and free its data
    structures on unmount.  (It's safe to unmount when restriper is in
    "paused" state, we will resume with the same parameters on the next
    mount)
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 99eb2bcd9aa7..1afda75d5414 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1214,7 +1214,10 @@ struct btrfs_fs_info {
 	/* restriper state */
 	spinlock_t balance_lock;
 	struct mutex balance_mutex;
+	atomic_t balance_running;
+	atomic_t balance_pause_req;
 	struct btrfs_balance_control *balance_ctl;
+	wait_queue_head_t balance_wait_q;
 
 	unsigned data_chunk_allocations;
 	unsigned metadata_ratio;
@@ -2658,6 +2661,7 @@ static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
 }
 static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 {
+	kfree(fs_info->balance_ctl);
 	kfree(fs_info->delayed_root);
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);

commit 9555c6c180600b40f6e86bd4dc53bf47e06ed663
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:48 2012 +0200

    Btrfs: add skip_balance mount option
    
    Since restriper kthread starts involuntarily on mount and can suck cpu
    and memory bandwidth add a mount option to forcefully skip it.  The
    restriper in that case hangs around in paused state and can be resumed
    from userspace when it's convenient.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9997a59e4f58..99eb2bcd9aa7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1492,6 +1492,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_AUTO_DEFRAG		(1 << 16)
 #define BTRFS_MOUNT_INODE_MAP_CACHE	(1 << 17)
 #define BTRFS_MOUNT_RECOVERY		(1 << 18)
+#define BTRFS_MOUNT_SKIP_BALANCE	(1 << 19)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 0940ebf6b92ea10a6f30ae5ac3993a3b75745da6
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:48 2012 +0200

    Btrfs: save balance parameters to disk
    
    Introduce a new btree objectid for storing balance item.  The reason is
    to be able to resume restriper after a crash with the same parameters.
    Balance item has a very high objectid and goes into tree of tree roots.
    
    The key for the new item is as follows:
    
            [ BTRFS_BALANCE_OBJECTID ; BTRFS_BALANCE_ITEM_KEY ; 0 ]
    
    Older kernels simply ignore it so it's safe to mount with an older
    kernel and then go back to the newer one.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e7aea60da2b..9997a59e4f58 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -86,6 +86,9 @@ struct btrfs_ordered_sum;
 /* holds checksums of all the data extents */
 #define BTRFS_CSUM_TREE_OBJECTID 7ULL
 
+/* for storing balance parameters in the root tree */
+#define BTRFS_BALANCE_OBJECTID -4ULL
+
 /* orhpan objectid for tracking unlinked/truncated files */
 #define BTRFS_ORPHAN_OBJECTID -5ULL
 
@@ -692,6 +695,54 @@ struct btrfs_root_ref {
 	__le16 name_len;
 } __attribute__ ((__packed__));
 
+struct btrfs_disk_balance_args {
+	/*
+	 * profiles to operate on, single is denoted by
+	 * BTRFS_AVAIL_ALLOC_BIT_SINGLE
+	 */
+	__le64 profiles;
+
+	/* usage filter */
+	__le64 usage;
+
+	/* devid filter */
+	__le64 devid;
+
+	/* devid subset filter [pstart..pend) */
+	__le64 pstart;
+	__le64 pend;
+
+	/* btrfs virtual address space subset filter [vstart..vend) */
+	__le64 vstart;
+	__le64 vend;
+
+	/*
+	 * profile to convert to, single is denoted by
+	 * BTRFS_AVAIL_ALLOC_BIT_SINGLE
+	 */
+	__le64 target;
+
+	/* BTRFS_BALANCE_ARGS_* */
+	__le64 flags;
+
+	__le64 unused[8];
+} __attribute__ ((__packed__));
+
+/*
+ * store balance parameters to disk so that balance can be properly
+ * resumed after crash or unmount
+ */
+struct btrfs_balance_item {
+	/* BTRFS_BALANCE_* */
+	__le64 flags;
+
+	struct btrfs_disk_balance_args data;
+	struct btrfs_disk_balance_args meta;
+	struct btrfs_disk_balance_args sys;
+
+	__le64 unused[4];
+} __attribute__ ((__packed__));
+
 #define BTRFS_FILE_EXTENT_INLINE 0
 #define BTRFS_FILE_EXTENT_REG 1
 #define BTRFS_FILE_EXTENT_PREALLOC 2
@@ -1409,6 +1460,8 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_DEV_ITEM_KEY	216
 #define BTRFS_CHUNK_ITEM_KEY	228
 
+#define BTRFS_BALANCE_ITEM_KEY	248
+
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
@@ -2103,8 +2156,86 @@ BTRFS_SETGET_STACK_FUNCS(backup_bytes_used, struct btrfs_root_backup,
 BTRFS_SETGET_STACK_FUNCS(backup_num_devices, struct btrfs_root_backup,
 		   num_devices, 64);
 
-/* struct btrfs_super_block */
+/* struct btrfs_balance_item */
+BTRFS_SETGET_FUNCS(balance_flags, struct btrfs_balance_item, flags, 64);
+
+static inline void btrfs_balance_data(struct extent_buffer *eb,
+				      struct btrfs_balance_item *bi,
+				      struct btrfs_disk_balance_args *ba)
+{
+	read_eb_member(eb, bi, struct btrfs_balance_item, data, ba);
+}
+
+static inline void btrfs_set_balance_data(struct extent_buffer *eb,
+					  struct btrfs_balance_item *bi,
+					  struct btrfs_disk_balance_args *ba)
+{
+	write_eb_member(eb, bi, struct btrfs_balance_item, data, ba);
+}
+
+static inline void btrfs_balance_meta(struct extent_buffer *eb,
+				      struct btrfs_balance_item *bi,
+				      struct btrfs_disk_balance_args *ba)
+{
+	read_eb_member(eb, bi, struct btrfs_balance_item, meta, ba);
+}
+
+static inline void btrfs_set_balance_meta(struct extent_buffer *eb,
+					  struct btrfs_balance_item *bi,
+					  struct btrfs_disk_balance_args *ba)
+{
+	write_eb_member(eb, bi, struct btrfs_balance_item, meta, ba);
+}
+
+static inline void btrfs_balance_sys(struct extent_buffer *eb,
+				     struct btrfs_balance_item *bi,
+				     struct btrfs_disk_balance_args *ba)
+{
+	read_eb_member(eb, bi, struct btrfs_balance_item, sys, ba);
+}
+
+static inline void btrfs_set_balance_sys(struct extent_buffer *eb,
+					 struct btrfs_balance_item *bi,
+					 struct btrfs_disk_balance_args *ba)
+{
+	write_eb_member(eb, bi, struct btrfs_balance_item, sys, ba);
+}
 
+static inline void
+btrfs_disk_balance_args_to_cpu(struct btrfs_balance_args *cpu,
+			       struct btrfs_disk_balance_args *disk)
+{
+	memset(cpu, 0, sizeof(*cpu));
+
+	cpu->profiles = le64_to_cpu(disk->profiles);
+	cpu->usage = le64_to_cpu(disk->usage);
+	cpu->devid = le64_to_cpu(disk->devid);
+	cpu->pstart = le64_to_cpu(disk->pstart);
+	cpu->pend = le64_to_cpu(disk->pend);
+	cpu->vstart = le64_to_cpu(disk->vstart);
+	cpu->vend = le64_to_cpu(disk->vend);
+	cpu->target = le64_to_cpu(disk->target);
+	cpu->flags = le64_to_cpu(disk->flags);
+}
+
+static inline void
+btrfs_cpu_balance_args_to_disk(struct btrfs_disk_balance_args *disk,
+			       struct btrfs_balance_args *cpu)
+{
+	memset(disk, 0, sizeof(*disk));
+
+	disk->profiles = cpu_to_le64(cpu->profiles);
+	disk->usage = cpu_to_le64(cpu->usage);
+	disk->devid = cpu_to_le64(cpu->devid);
+	disk->pstart = cpu_to_le64(cpu->pstart);
+	disk->pend = cpu_to_le64(cpu->pend);
+	disk->vstart = cpu_to_le64(cpu->vstart);
+	disk->vend = cpu_to_le64(cpu->vend);
+	disk->target = cpu_to_le64(cpu->target);
+	disk->flags = cpu_to_le64(cpu->flags);
+}
+
+/* struct btrfs_super_block */
 BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);
 BTRFS_SETGET_STACK_FUNCS(super_flags, struct btrfs_super_block, flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_generation, struct btrfs_super_block,

commit 70922617b0099f420deceb53d5dc7f4fb30d08d0
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:48 2012 +0200

    Btrfs: do not reduce profile in do_chunk_alloc()
    
    Every caller of do_chunk_alloc() feeds it the reduced allocation
    profile, so stop trying to reduce it one more time.  Instead check the
    validity of the passed profile.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c4d98c8df5c5..1e7aea60da2b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2536,6 +2536,24 @@ static inline void free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->super_for_commit);
 	kfree(fs_info);
 }
+/**
+ * profile_is_valid - tests whether a given profile is valid and reduced
+ * @flags: profile to validate
+ * @extended: if true @flags is treated as an extended profile
+ */
+static inline int profile_is_valid(u64 flags, int extended)
+{
+	u64 mask = ~BTRFS_BLOCK_GROUP_PROFILE_MASK;
+
+	flags &= ~BTRFS_BLOCK_GROUP_TYPE_MASK;
+	if (extended)
+		mask &= ~BTRFS_AVAIL_ALLOC_BIT_SINGLE;
+
+	if (flags & mask)
+		return 0;
+	/* true if zero or exactly one bit set */
+	return (flags & (~flags + 1)) == flags;
+}
 
 /* root-item.c */
 int btrfs_find_root_ref(struct btrfs_root *tree_root,

commit c9e9f97bdfb64d06e9520f8e4f37674ac21cc9bc
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:47 2012 +0200

    Btrfs: add basic restriper infrastructure
    
    Add basic restriper infrastructure: extended balancing ioctl and all
    related ioctl data structures, add data structure for tracking
    restriper's state to fs_info, etc.  The semantics of the old balancing
    ioctl are fully preserved.
    
    Explicitly disallow any volume operations when balance is in progress.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3f8f11e18b53..c4d98c8df5c5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -934,6 +934,7 @@ struct btrfs_block_group_cache {
 struct reloc_control;
 struct btrfs_device;
 struct btrfs_fs_devices;
+struct btrfs_balance_control;
 struct btrfs_delayed_root;
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
@@ -1159,6 +1160,11 @@ struct btrfs_fs_info {
 	u64 avail_metadata_alloc_bits;
 	u64 avail_system_alloc_bits;
 
+	/* restriper state */
+	spinlock_t balance_lock;
+	struct mutex balance_mutex;
+	struct btrfs_balance_control *balance_ctl;
+
 	unsigned data_chunk_allocations;
 	unsigned metadata_ratio;
 

commit a46d11a8b06dd0431a3888fbc4856ea13a8e634f
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:47 2012 +0200

    Btrfs: add BTRFS_AVAIL_ALLOC_BIT_SINGLE bit
    
    Right now on-disk BTRFS_BLOCK_GROUP_* profile bits are used for
    avail_{data,metadata,system}_alloc_bits fields, which gather info about
    available allocation profiles in the FS.  When chunk is created or read
    from disk, its profile is OR'ed with the corresponding avail_alloc_bits
    field.  Since SINGLE is denoted by 0 in the on-disk format, currently
    there is no way to tell when such chunks become avaialble.  Restriper
    needs that information, so add a separate bit for SINGLE profile.
    
    This bit is going to be in-memory only, it should never be written out
    to disk, so it's not a disk format change.  However to avoid remappings
    in future, reserve corresponding on-disk bit.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4370a56fe81a..3f8f11e18b53 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -758,6 +758,7 @@ struct btrfs_csum_item {
 #define BTRFS_BLOCK_GROUP_RAID1		(1ULL << 4)
 #define BTRFS_BLOCK_GROUP_DUP		(1ULL << 5)
 #define BTRFS_BLOCK_GROUP_RAID10	(1ULL << 6)
+#define BTRFS_BLOCK_GROUP_RESERVED	BTRFS_AVAIL_ALLOC_BIT_SINGLE
 #define BTRFS_NR_RAID_TYPES		5
 
 #define BTRFS_BLOCK_GROUP_TYPE_MASK	(BTRFS_BLOCK_GROUP_DATA |    \
@@ -768,6 +769,15 @@ struct btrfs_csum_item {
 					 BTRFS_BLOCK_GROUP_RAID1 |   \
 					 BTRFS_BLOCK_GROUP_DUP |     \
 					 BTRFS_BLOCK_GROUP_RAID10)
+/*
+ * We need a bit for restriper to be able to tell when chunks of type
+ * SINGLE are available.  This "extended" profile format is used in
+ * fs_info->avail_*_alloc_bits (in-memory) and balance item fields
+ * (on-disk).  The corresponding on-disk bit in chunk.type is reserved
+ * to avoid remappings between two formats in future.
+ */
+#define BTRFS_AVAIL_ALLOC_BIT_SINGLE	(1ULL << 48)
+
 struct btrfs_block_group_item {
 	__le64 used;
 	__le64 chunk_objectid;
@@ -1140,6 +1150,11 @@ struct btrfs_fs_info {
 	spinlock_t ref_cache_lock;
 	u64 total_ref_cache_size;
 
+	/*
+	 * these three are in extended format (availability of single
+	 * chunks is denoted by BTRFS_AVAIL_ALLOC_BIT_SINGLE bit, other
+	 * types are denoted by corresponding BTRFS_BLOCK_GROUP_* bits)
+	 */
 	u64 avail_data_alloc_bits;
 	u64 avail_metadata_alloc_bits;
 	u64 avail_system_alloc_bits;

commit 52ba692972532f8d652080214b6599ece3dd51b9
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:47 2012 +0200

    Btrfs: introduce masks for chunk type and profile
    
    Chunk's type and profile are encoded in u64 flags field.  Introduce
    masks to easily access them.  Also fix the type of BTRFS_BLOCK_GROUP_*
    constants, it should be ULL.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f5434ad49b99..4370a56fe81a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -751,15 +751,23 @@ struct btrfs_csum_item {
 } __attribute__ ((__packed__));
 
 /* different types of block groups (and chunks) */
-#define BTRFS_BLOCK_GROUP_DATA     (1 << 0)
-#define BTRFS_BLOCK_GROUP_SYSTEM   (1 << 1)
-#define BTRFS_BLOCK_GROUP_METADATA (1 << 2)
-#define BTRFS_BLOCK_GROUP_RAID0    (1 << 3)
-#define BTRFS_BLOCK_GROUP_RAID1    (1 << 4)
-#define BTRFS_BLOCK_GROUP_DUP	   (1 << 5)
-#define BTRFS_BLOCK_GROUP_RAID10   (1 << 6)
-#define BTRFS_NR_RAID_TYPES	   5
-
+#define BTRFS_BLOCK_GROUP_DATA		(1ULL << 0)
+#define BTRFS_BLOCK_GROUP_SYSTEM	(1ULL << 1)
+#define BTRFS_BLOCK_GROUP_METADATA	(1ULL << 2)
+#define BTRFS_BLOCK_GROUP_RAID0		(1ULL << 3)
+#define BTRFS_BLOCK_GROUP_RAID1		(1ULL << 4)
+#define BTRFS_BLOCK_GROUP_DUP		(1ULL << 5)
+#define BTRFS_BLOCK_GROUP_RAID10	(1ULL << 6)
+#define BTRFS_NR_RAID_TYPES		5
+
+#define BTRFS_BLOCK_GROUP_TYPE_MASK	(BTRFS_BLOCK_GROUP_DATA |    \
+					 BTRFS_BLOCK_GROUP_SYSTEM |  \
+					 BTRFS_BLOCK_GROUP_METADATA)
+
+#define BTRFS_BLOCK_GROUP_PROFILE_MASK	(BTRFS_BLOCK_GROUP_RAID0 |   \
+					 BTRFS_BLOCK_GROUP_RAID1 |   \
+					 BTRFS_BLOCK_GROUP_DUP |     \
+					 BTRFS_BLOCK_GROUP_RAID10)
 struct btrfs_block_group_item {
 	__le64 used;
 	__le64 chunk_objectid;

commit 6fef8df1dcb9b586268caff66df1d71ce8610132
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:47 2012 +0200

    Btrfs: get rid of *_alloc_profile fields
    
    {data,metadata,system}_alloc_profile fields have been unused for a long
    time now.  Get rid of them.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 67385033323d..f5434ad49b99 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1135,9 +1135,6 @@ struct btrfs_fs_info {
 	u64 avail_data_alloc_bits;
 	u64 avail_metadata_alloc_bits;
 	u64 avail_system_alloc_bits;
-	u64 data_alloc_profile;
-	u64 metadata_alloc_profile;
-	u64 system_alloc_profile;
 
 	unsigned data_chunk_allocations;
 	unsigned metadata_ratio;

commit 815745cf3e46681241ad8025602ffbf2a452d514
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 15:40:49 2011 -0500

    btrfs: let ->s_fs_info point to fs_info, not root...
    
    the latter can be obtained from the former (by looking as ->tree_root)
    just as cheaply as we currently are doing the other way round.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 67385033323d..dbb999a38272 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2196,7 +2196,7 @@ static inline u32 btrfs_file_extent_inline_item_len(struct extent_buffer *eb,
 	return btrfs_item_size(eb, e) - offset;
 }
 
-static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
+static inline struct btrfs_fs_info *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;
 }

commit 66d7e7f09f77456fe68683247d77721032a00ee5
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon Sep 12 15:26:38 2011 +0200

    Btrfs: mark delayed refs as for cow
    
    Add a for_cow parameter to add_delayed_*_ref and pass the appropriate value
    from every call site. The for_cow parameter will later on be used to
    determine if a ref will change anything with respect to qgroups.
    
    Delayed refs coming from relocation are always counted as for_cow, as they
    don't change subvol quota.
    
    Also pass in the fs_info for later use.
    
    btrfs_find_all_roots() will use this as an optimization, as changes that are
    for_cow will not change anything with respect to which root points to a
    certain leaf. Thus, we don't need to add the current sequence number to
    those delayed refs.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3e4a07b79817..543f60bddb39 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2277,11 +2277,11 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					struct btrfs_root *root, u32 blocksize,
 					u64 parent, u64 root_objectid,
 					struct btrfs_disk_key *key, int level,
-					u64 hint, u64 empty_size);
+					u64 hint, u64 empty_size, int for_cow);
 void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct extent_buffer *buf,
-			   u64 parent, int last_ref);
+			   u64 parent, int last_ref, int for_cow);
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize,
@@ -2301,17 +2301,17 @@ int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  u64 search_end, struct btrfs_key *ins,
 				  u64 data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf, int full_backref);
+		  struct extent_buffer *buf, int full_backref, int for_cow);
 int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf, int full_backref);
+		  struct extent_buffer *buf, int full_backref, int for_cow);
 int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 bytenr, u64 num_bytes, u64 flags,
 				int is_data);
 int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
-		      u64 bytenr, u64 num_bytes, u64 parent,
-		      u64 root_objectid, u64 owner, u64 offset);
+		      u64 bytenr, u64 num_bytes, u64 parent, u64 root_objectid,
+		      u64 owner, u64 offset, int for_cow);
 
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_free_and_pin_reserved_extent(struct btrfs_root *root,
@@ -2323,7 +2323,7 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,
-			 u64 root_objectid, u64 owner, u64 offset);
+			 u64 root_objectid, u64 owner, u64 offset, int for_cow);
 
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
@@ -2492,7 +2492,8 @@ static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
 void btrfs_drop_snapshot(struct btrfs_root *root,
-			 struct btrfs_block_rsv *block_rsv, int update_ref);
+			 struct btrfs_block_rsv *block_rsv, int update_ref,
+			 int for_reloc);
 int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct extent_buffer *node,

commit c7d22a3c3cdb73d8a0151e2ccc8cf4a48c48310b
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Tue Nov 22 15:14:33 2011 +0100

    Btrfs: added helper btrfs_next_item()
    
    btrfs_next_item() makes the btrfs path point to the next item, crossing leaf
    boundaries if needed.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 50634abef9b4..3e4a07b79817 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2482,6 +2482,13 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 }
 
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
+static inline int btrfs_next_item(struct btrfs_root *root, struct btrfs_path *p)
+{
+	++p->slots[0];
+	if (p->slots[0] >= btrfs_header_nritems(p->nodes[0]))
+		return btrfs_next_leaf(root, p);
+	return 0;
+}
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
 void btrfs_drop_snapshot(struct btrfs_root *root,

commit 21adbd5cbb5344a3fca6bb7ddb2ab6cb03c44546
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Nov 9 13:44:05 2011 +0100

    Btrfs: integrate integrity check module into btrfs
    
    This is the last part of the patch series. It modifies the btrfs
    code to use the integrity check module if configured to do so
    with the define BTRFS_FS_CHECK_INTEGRITY. If this define is not set,
    the only effective change is that code is added that handles the
    mount option to activate the integrity check. If the mount option is
    set and the define BTRFS_FS_CHECK_INTEGRITY is not set, that code
    complains in the log and the mount fails with EINVAL.
    
    Add the mount option to activate the usage of the integrity check
    code.
    Add invocation of btrfs integrity check code init and cleanup
    function on mount and umount, respectively.
    Add hook to call btrfs integrity check code version of
    submit_bh/submit_bio.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 67385033323d..39f6188688e6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -971,7 +971,7 @@ struct btrfs_fs_info {
 	 * is required instead of the faster short fsync log commits
 	 */
 	u64 last_trans_log_full_commit;
-	unsigned long mount_opt:20;
+	unsigned long mount_opt:21;
 	unsigned long compress_type:4;
 	u64 max_inline;
 	u64 alloc_start;
@@ -1155,6 +1155,10 @@ struct btrfs_fs_info {
 	int scrub_workers_refcnt;
 	struct btrfs_workers scrub_workers;
 
+#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
+	u32 check_integrity_print_mask;
+#endif
+
 	/* filesystem state */
 	u64 fs_state;
 
@@ -1413,6 +1417,8 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_AUTO_DEFRAG		(1 << 16)
 #define BTRFS_MOUNT_INODE_MAP_CACHE	(1 << 17)
 #define BTRFS_MOUNT_RECOVERY		(1 << 18)
+#define BTRFS_MOUNT_CHECK_INTEGRITY	(1 << 19)
+#define BTRFS_MOUNT_CHECK_INTEGRITY_INCLUDING_EXTENT_DATA (1 << 20)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 22c44fe65adacd20a174f3f54686509ee94ef7be
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Nov 30 10:45:38 2011 -0500

    Btrfs: deal with enospc from dirtying inodes properly
    
    Now that we're properly keeping track of delayed inode space we've been getting
    a lot of warnings out of btrfs_dirty_inode() when running xfstest 83.  This is
    because a bunch of people call mark_inode_dirty, which is void so we can't
    return ENOSPC.  This needs to be fixed in a few areas
    
    1) file_update_time - this updates the mtime and such when writing to a file,
    which will call mark_inode_dirty.  So copy file_update_time into btrfs so we can
    call btrfs_dirty_inode directly and return an error if we get one appropriately.
    
    2) fix symlinks to use btrfs_setattr for ->setattr.  For some reason we weren't
    setting ->setattr for symlinks, even though we should have been.  This catches
    one of the cases where we were getting errors in mark_inode_dirty.
    
    3) Fix btrfs_setattr and btrfs_setsize to call btrfs_dirty_inode directly
    instead of mark_inode_dirty.  This lets us return errors properly for truncate
    and chown/anything related to setattr.
    
    4) Add a new btrfs_fs_dirty_inode which will just call btrfs_dirty_inode and
    print an error if we have one.  The only remaining user we can't control for
    this is touch_atime(), but we don't really want to keep people from walking
    down the tree if we don't have space to save the atime update, so just complain
    but don't worry about it.
    
    With this patch xfstests 83 complains a handful of times instead of hundreds of
    times.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 50634abef9b4..67385033323d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2692,7 +2692,8 @@ int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
-void btrfs_dirty_inode(struct inode *inode, int flags);
+int btrfs_dirty_inode(struct inode *inode);
+int btrfs_update_time(struct file *file);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);

commit aa38a711a893accf5b5192f3d705a120deaa81e0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Nov 18 17:43:00 2011 +0800

    Btrfs: fix deadlock on metadata reservation when evicting a inode
    
    When I ran the xfstests, I found the test tasks was blocked on meta-data
    reservation.
    
    By debugging, I found the reason of this bug:
       start transaction
            |
            v
       reserve meta-data space
            |
            v
       flush delay allocation -> iput inode -> evict inode
            ^                                       |
            |                                       v
       wait for delay allocation flush <- reserve meta-data space
    
    And besides that, the flush on evicting inode will block the thread, which
    is reclaiming the memory, and make oom happen easily.
    
    Fix this bug by skipping the flush step when evicting inode.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 04a5dfcee5a1..50634abef9b4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2369,6 +2369,9 @@ int btrfs_block_rsv_check(struct btrfs_root *root,
 int btrfs_block_rsv_refill(struct btrfs_root *root,
 			  struct btrfs_block_rsv *block_rsv,
 			  u64 min_reserved);
+int btrfs_block_rsv_refill_noflush(struct btrfs_root *root,
+				   struct btrfs_block_rsv *block_rsv,
+				   u64 min_reserved);
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 			    struct btrfs_block_rsv *dst_rsv,
 			    u64 num_bytes);

commit 291c7d2f577428f896daa5002e784959328a80aa
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Nov 14 13:52:14 2011 -0500

    Btrfs: wait on caching if we're loading the free space cache
    
    We've been hitting panics when running xfstest 13 in a loop for long periods of
    time.  And actually this problem has always existed so we've been hitting these
    things randomly for a while.  Basically what happens is we get a thread coming
    into the allocator and reading the space cache off of disk and adding the
    entries to the free space cache as we go.  Then we get another thread that comes
    in and tries to allocate from that block group.  Since block_group->cached !=
    BTRFS_CACHE_NO it goes ahead and tries to do the allocation.  We do this because
    if we're doing the old slow way of caching we don't want to hold people up and
    wait for everything to finish.  The problem with this is we could end up
    discarding the space cache at some arbitrary point in the future, which means we
    could very well end up allocating space that is either bad, or when the real
    caching happens it could end up thinking the space isn't in use when it really
    is and cause all sorts of other problems.
    
    The solution is to add a new flag to indicate we are loading the free space
    cache from disk, and always try to cache the block group if cache->cached !=
    BTRFS_CACHE_FINISHED.  That way if we are loading the space cache anybody else
    who tries to allocate from the block group will have to wait until it's finished
    to make sure it completes successfully.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b1cb3c052484..04a5dfcee5a1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -848,7 +848,8 @@ struct btrfs_free_cluster {
 enum btrfs_caching_type {
 	BTRFS_CACHE_NO		= 0,
 	BTRFS_CACHE_STARTED	= 1,
-	BTRFS_CACHE_FINISHED	= 2,
+	BTRFS_CACHE_FAST	= 2,
+	BTRFS_CACHE_FINISHED	= 3,
 };
 
 enum btrfs_disk_cache_state {

commit f1ebcc74d5b2159f44c96b479b6eb8afc7829095
Author: Liu Bo <liubo2009@cn.fujitsu.com>
Date:   Mon Nov 14 20:48:06 2011 -0500

    Btrfs: fix tree corruption after multi-thread snapshots and inode_cache flush
    
    The btrfs snapshotting code requires that once a root has been
    snapshotted, we don't change it during a commit.
    
    But there are two cases to lead to tree corruptions:
    
    1) multi-thread snapshots can commit serveral snapshots in a transaction,
       and this may change the src root when processing the following pending
       snapshots, which lead to the former snapshots corruptions;
    
    2) the free inode cache was changing the roots when it root the cache,
       which lead to corruptions.
    
    This fixes things by making sure we force COW the block after we create a
    snapshot during commiting a transaction, then any changes to the roots
    will result in COW, and we get all the fs roots and snapshot roots to be
    consistent.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b9ba59ff9292..b1cb3c052484 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1271,6 +1271,8 @@ struct btrfs_root {
 	 * for stat.  It may be used for more later
 	 */
 	dev_t anon_dev;
+
+	int force_cow;
 };
 
 struct btrfs_ioctl_defrag_range_args {

commit 531f4b1ae5e0fc8c9b3f03838218e5ea178f80d3
Merge: c06a0e120a4e 7a26285eea8e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 6 03:05:08 2011 -0500

    Merge branch 'for-chris' of git://github.com/sensille/linux into integration
    
    Conflicts:
            fs/btrfs/ctree.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit c06a0e120a4e381a1c291c1fce3c6155c5791cae
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Nov 4 19:56:02 2011 -0400

    Btrfs: fix delayed insertion reservation
    
    We all keep getting those stupid warnings from use_block_rsv when running
    stress.sh, and it's because the delayed insertion stuff is being stupid.  It's
    not the delayed insertion stuffs fault, it's all just stupid.  When marking an
    inode dirty for oh say updating the time on it, we just do a
    btrfs_join_transaction, which doesn't reserve any space.  This is stupid because
    we're going to have to have space reserve to make this change, but we do it
    because it's fast because chances are we're going to call it over and over again
    and it doesn't matter.  Well thanks to the delayed insertion stuff this is
    mostly the case, so we do actually need to make this reservation.  So if
    trans->bytes_reserved is 0 then try to do a normal reservation.  If not return
    ENOSPC which will make the btrfs_dirty_inode start a proper transaction which
    will let it do the whole ENOSPC dance and reserve enough space for the delayed
    insertion to steal the reservation from the transaction.
    
    The other stupid thing we do is not reserve space for the inode when writing to
    the thing.  Usually this is ok since we have to update the time so we'd have
    already done all this work before we get to the endio stuff, so it doesn't
    matter.  But this is stupid because we could write the data after the
    transaction commits where we changed the mtime of the inode so we have to cow
    all the way down to the inode anyway.  This used to be masked by the delalloc
    reservation stuff, but because we delay the update it doesn't get masked in this
    case.  So again the delayed insertion stuff bites us in the ass.  So if our
    trans->block_rsv is delalloc, just steal the reservation from the delalloc
    reserve.  Hopefully this won't bite us in the ass, but I've said that before.
    
    With this patch stress.sh no longer spits out those stupid warnings (famous last
    words).  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3002e5d4da0b..6bb34fc1ff22 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2353,6 +2353,9 @@ void btrfs_free_block_rsv(struct btrfs_root *root,
 int btrfs_block_rsv_add(struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv,
 			u64 num_bytes);
+int btrfs_block_rsv_add_noflush(struct btrfs_root *root,
+				struct btrfs_block_rsv *block_rsv,
+				u64 num_bytes);
 int btrfs_block_rsv_check(struct btrfs_root *root,
 			  struct btrfs_block_rsv *block_rsv, int min_factor);
 int btrfs_block_rsv_refill(struct btrfs_root *root,

commit 6d668dda0caec537fbf28c4d91e6d18181af3cff
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Nov 3 22:54:25 2011 -0400

    Btrfs: make a delayed_block_rsv for the delayed item insertion
    
    I've been hitting warnings in use_block_rsv when running the delayed insertion
    stuff.  It's because we will readjust global block rsv based on what is in use,
    which means we could end up discarding reservations that are for the delayed
    insertion stuff.  So instead create a seperate block rsv for the delayed
    insertion stuff.  This will also make it easier to debug problems with the
    delayed insertion reservations since we will know that only the delayed
    insertion code touches this block_rsv.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 78f43d1102a0..3002e5d4da0b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -957,6 +957,8 @@ struct btrfs_fs_info {
 	struct btrfs_block_rsv trans_block_rsv;
 	/* block reservation for chunk tree */
 	struct btrfs_block_rsv chunk_block_rsv;
+	/* block reservation for delayed operations */
+	struct btrfs_block_rsv delayed_block_rsv;
 
 	struct btrfs_block_rsv empty_block_rsv;
 

commit af31f5e5b84b5bf2bcec464153a5130b170b2770
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 3 15:17:42 2011 -0400

    Btrfs: add a log of past tree roots
    
    This takes some of the free space in the btrfs super block
    to record information about most of the roots in the last four
    commits.
    
    It also adds a -o recovery to use the root history log when
    we're not able to read the tree of tree roots, the extent
    tree root, the device tree root or the csum root.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5181c53c1124..78f43d1102a0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -360,6 +360,47 @@ struct btrfs_header {
 #define BTRFS_SYSTEM_CHUNK_ARRAY_SIZE 2048
 #define BTRFS_LABEL_SIZE 256
 
+/*
+ * just in case we somehow lose the roots and are not able to mount,
+ * we store an array of the roots from previous transactions
+ * in the super.
+ */
+#define BTRFS_NUM_BACKUP_ROOTS 4
+struct btrfs_root_backup {
+	__le64 tree_root;
+	__le64 tree_root_gen;
+
+	__le64 chunk_root;
+	__le64 chunk_root_gen;
+
+	__le64 extent_root;
+	__le64 extent_root_gen;
+
+	__le64 fs_root;
+	__le64 fs_root_gen;
+
+	__le64 dev_root;
+	__le64 dev_root_gen;
+
+	__le64 csum_root;
+	__le64 csum_root_gen;
+
+	__le64 total_bytes;
+	__le64 bytes_used;
+	__le64 num_devices;
+	/* future */
+	__le64 unsed_64[4];
+
+	u8 tree_root_level;
+	u8 chunk_root_level;
+	u8 extent_root_level;
+	u8 fs_root_level;
+	u8 dev_root_level;
+	u8 csum_root_level;
+	/* future and to align */
+	u8 unused_8[10];
+} __attribute__ ((__packed__));
+
 /*
  * the super block basically lists the main trees of the FS
  * it currently lacks any block count etc etc
@@ -406,6 +447,7 @@ struct btrfs_super_block {
 	/* future expansion */
 	__le64 reserved[31];
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
+	struct btrfs_root_backup super_roots[BTRFS_NUM_BACKUP_ROOTS];
 } __attribute__ ((__packed__));
 
 /*
@@ -1113,6 +1155,9 @@ struct btrfs_fs_info {
 	u64 fs_state;
 
 	struct btrfs_delayed_root *delayed_root;
+
+	/* next backup root to be overwritten */
+	int backup_root_index;
 };
 
 /*
@@ -1357,6 +1402,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_ENOSPC_DEBUG	 (1 << 15)
 #define BTRFS_MOUNT_AUTO_DEFRAG		(1 << 16)
 #define BTRFS_MOUNT_INODE_MAP_CACHE	(1 << 17)
+#define BTRFS_MOUNT_RECOVERY		(1 << 18)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
@@ -1972,6 +2018,55 @@ static inline bool btrfs_root_readonly(struct btrfs_root *root)
 	return root->root_item.flags & BTRFS_ROOT_SUBVOL_RDONLY;
 }
 
+/* struct btrfs_root_backup */
+BTRFS_SETGET_STACK_FUNCS(backup_tree_root, struct btrfs_root_backup,
+		   tree_root, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_tree_root_gen, struct btrfs_root_backup,
+		   tree_root_gen, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_tree_root_level, struct btrfs_root_backup,
+		   tree_root_level, 8);
+
+BTRFS_SETGET_STACK_FUNCS(backup_chunk_root, struct btrfs_root_backup,
+		   chunk_root, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_chunk_root_gen, struct btrfs_root_backup,
+		   chunk_root_gen, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_chunk_root_level, struct btrfs_root_backup,
+		   chunk_root_level, 8);
+
+BTRFS_SETGET_STACK_FUNCS(backup_extent_root, struct btrfs_root_backup,
+		   extent_root, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_extent_root_gen, struct btrfs_root_backup,
+		   extent_root_gen, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_extent_root_level, struct btrfs_root_backup,
+		   extent_root_level, 8);
+
+BTRFS_SETGET_STACK_FUNCS(backup_fs_root, struct btrfs_root_backup,
+		   fs_root, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_fs_root_gen, struct btrfs_root_backup,
+		   fs_root_gen, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_fs_root_level, struct btrfs_root_backup,
+		   fs_root_level, 8);
+
+BTRFS_SETGET_STACK_FUNCS(backup_dev_root, struct btrfs_root_backup,
+		   dev_root, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_dev_root_gen, struct btrfs_root_backup,
+		   dev_root_gen, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_dev_root_level, struct btrfs_root_backup,
+		   dev_root_level, 8);
+
+BTRFS_SETGET_STACK_FUNCS(backup_csum_root, struct btrfs_root_backup,
+		   csum_root, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_csum_root_gen, struct btrfs_root_backup,
+		   csum_root_gen, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_csum_root_level, struct btrfs_root_backup,
+		   csum_root_level, 8);
+BTRFS_SETGET_STACK_FUNCS(backup_total_bytes, struct btrfs_root_backup,
+		   total_bytes, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_bytes_used, struct btrfs_root_backup,
+		   bytes_used, 64);
+BTRFS_SETGET_STACK_FUNCS(backup_num_devices, struct btrfs_root_backup,
+		   num_devices, 64);
+
 /* struct btrfs_super_block */
 
 BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);

commit 6c41761fc6efe1503103a1afe03a6635c0b5d4ec
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Apr 13 15:41:04 2011 +0200

    btrfs: separate superblock items out of fs_info
    
    fs_info has now ~9kb, more than fits into one page. This will cause
    mount failure when memory is too fragmented. Top space consumers are
    super block structures super_copy and super_for_commit, ~2.8kb each.
    Allocate them dynamically. fs_info will be ~3.5kb. (measured on x86_64)
    
    Add a wrapper for freeing fs_info and all of it's dynamically allocated
    members.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f63c9b3f6e08..5181c53c1124 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -936,8 +936,8 @@ struct btrfs_fs_info {
 	wait_queue_head_t transaction_blocked_wait;
 	wait_queue_head_t async_submit_wait;
 
-	struct btrfs_super_block super_copy;
-	struct btrfs_super_block super_for_commit;
+	struct btrfs_super_block *super_copy;
+	struct btrfs_super_block *super_for_commit;
 	struct block_device *__bdev;
 	struct super_block *sb;
 	struct inode *btree_inode;
@@ -2387,6 +2387,18 @@ static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
 	smp_mb();
 	return fs_info->closing;
 }
+static inline void free_fs_info(struct btrfs_fs_info *fs_info)
+{
+	kfree(fs_info->delayed_root);
+	kfree(fs_info->extent_root);
+	kfree(fs_info->tree_root);
+	kfree(fs_info->chunk_root);
+	kfree(fs_info->dev_root);
+	kfree(fs_info->csum_root);
+	kfree(fs_info->super_copy);
+	kfree(fs_info->super_for_commit);
+	kfree(fs_info);
+}
 
 /* root-item.c */
 int btrfs_find_root_ref(struct btrfs_root *tree_root,

commit e688b7252f784c2479d559f9f70ca8354752c5e7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 31 20:52:39 2011 -0400

    Btrfs: fix extent pinning bugs in the tree log
    
    The tree log had two important bugs that could cause corruptions after a
    crash.  Sometimes we were allowing tree log blocks to be reused after
    the tree log was committed but before the transaction commit was done.
    
    This allowed a future metadata write to overwrite the tree log data.  It
    is fixed by adding a new variant of freeing reserved extents that always
    pins them.  Credit goes to Stefan Behrens and Arne Jansen for many many
    hours spent tracking this bug down.
    
    During tree log replay, we do a pass through the tree log and pin all
    the extents we find.  This makes sure the replay code won't go in and
    use any of those blocks for new allocations during replay.  The problem
    is the free space cache isn't honoring these pinned extents.  So the
    allocator can end up handing them out, leading to all kinds of problems
    during replay.
    
    The fix here is to force any free space cache to load while we pin the
    extents, and then to make sure we remove the pinned extents from the
    free space rbtree.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>
    Reported-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 227620993bce..f63c9b3f6e08 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2156,6 +2156,9 @@ int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     u64 num_bytes, u64 *refs, u64 *flags);
 int btrfs_pin_extent(struct btrfs_root *root,
 		     u64 bytenr, u64 num, int reserved);
+int btrfs_pin_extent_for_log_replay(struct btrfs_trans_handle *trans,
+				    struct btrfs_root *root,
+				    u64 bytenr, u64 num_bytes);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset, u64 bytenr);
@@ -2206,6 +2209,8 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      u64 root_objectid, u64 owner, u64 offset);
 
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_free_and_pin_reserved_extent(struct btrfs_root *root,
+				       u64 start, u64 len);
 int btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,

commit 36ba022ac0b748dd543f43430b03198e899426c9
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Oct 18 12:15:48 2011 -0400

    Btrfs: seperate out btrfs_block_rsv_check out into 2 different functions
    
    Currently btrfs_block_rsv_check does 2 things, it will either refill a block
    reserve like in the truncate or refill case, or it will check to see if there is
    enough space in the global reserve and possibly refill it.  However because of
    overcommit we could be well overcommitting ourselves just to try and refill the
    global reserve, when really we should just be committing the transaction.  So
    breack this out into btrfs_block_rsv_refill and btrfs_block_rsv_check.  Refill
    will try to reserve more metadata if it can and btrfs_block_rsv_check will not,
    it will only tell you if the factor of the total space is still reserved.
    Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ea60897a9171..227620993bce 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2252,8 +2252,10 @@ int btrfs_block_rsv_add(struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv,
 			u64 num_bytes);
 int btrfs_block_rsv_check(struct btrfs_root *root,
+			  struct btrfs_block_rsv *block_rsv, int min_factor);
+int btrfs_block_rsv_refill(struct btrfs_root *root,
 			  struct btrfs_block_rsv *block_rsv,
-			  u64 min_reserved, int min_factor, int flush);
+			  u64 min_reserved);
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 			    struct btrfs_block_rsv *dst_rsv,
 			    u64 num_bytes);

commit 5b0e95bf607ddd59b39f52d3d55e6581c817b530
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Oct 6 08:58:24 2011 -0400

    Btrfs: inline checksums into the disk free space cache
    
    Yeah yeah I know this is how we used to do it and then I changed it, but damnit
    I'm changing it back.  The fact is that writing out checksums will modify
    metadata, which could cause us to dirty a block group we've already written out,
    so we have to truncate it and all of it's checksums and re-write it which will
    write new checksums which could dirty a blockg roup that has already been
    written and you see where I'm going with this?  This can cause unmount or really
    anything that depends on a transaction to commit to take it's sweet damned time
    to happen.  So go back to the way it was, only this time we're specifically
    setting NODATACOW because we can't go through the COW pathway anyway and we're
    doing our own built-in cow'ing by truncating the free space cache.  The other
    new thing is once we truncate the old cache and preallocate the new space, we
    don't need to do that song and dance at all for the rest of the transaction, we
    can just overwrite the existing space with the new cache if the block group
    changes for whatever reason, and the NODATACOW will let us do this fine.  So
    keep track of which transaction we last cleared our cache in and if we cleared
    it in this transaction just say we're all setup and carry on.  This survives
    xfstests and stress.sh.
    
    The inode cache will continue to use the normal csum infrastructure since it
    only gets written once and there will be no more modifications to the fs tree in
    a transaction commit.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1eafccb162ee..ea60897a9171 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -838,6 +838,7 @@ struct btrfs_block_group_cache {
 	u64 bytes_super;
 	u64 flags;
 	u64 sectorsize;
+	u64 cache_generation;
 	unsigned int ro:1;
 	unsigned int dirty:1;
 	unsigned int iref:1;

commit 2bf64758fd6290797a5ce97d4b9c698a4ed1cbad
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Sep 26 17:12:22 2011 -0400

    Btrfs: allow us to overcommit our enospc reservations
    
    One of the things that kills us is the fact that our ENOSPC reservations are
    horribly over the top in most normal cases.  There isn't too much that can be
    done about this because when we are completely full we really need them to work
    like this so we don't under reserve.  However if there is plenty of unallocated
    chunks on the disk we can use that to gauge how much we can overcommit.  So this
    patch adds chunk free space accounting so we always know how much unallocated
    space we have.  Then if we fail to make a reservation within our allocated
    space, check to see if we can overcommit.  In the normal flushing case (like
    with delalloc metadata reservations) we'll take the free space and divide it by
    2 if our metadata profile is setup for DUP or any of those, and then divide it
    by 8 to make sure we don't overcommit too much.  Then if we're in a non-flushing
    case (we really need this reservation now!) we only limit ourselves to half of
    the free space.  This makes this fio test
    
    [torrent]
    filename=torrent-test
    rw=randwrite
    size=4g
    ioengine=sync
    directory=/mnt/btrfs-test
    
    go from taking around 45 minutes to 10 seconds on my freshly formatted 3 TiB
    file system.  This doesn't seem to break my other enospc tests, but could really
    use some more testing as this is a super scary change.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 47dea7118e0e..1eafccb162ee 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -893,6 +893,10 @@ struct btrfs_fs_info {
 	spinlock_t block_group_cache_lock;
 	struct rb_root block_group_cache_tree;
 
+	/* keep track of unallocated space */
+	spinlock_t free_chunk_lock;
+	u64 free_chunk_space;
+
 	struct extent_io_tree freed_extents[2];
 	struct extent_io_tree *pinned_extents;
 

commit 3b16a4e3c355ee3c790473decfcf83d4faeb8ce0
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Sep 21 15:05:58 2011 -0400

    Btrfs: use the inode's mapping mask for allocating pages
    
    Johannes pointed out we were allocating only kernel pages for doing writes,
    which is kind of a big deal if you are on 32bit and have more than a gig of ram.
    So fix our allocations to use the mapping's gfp but still clear __GFP_FS so we
    don't re-enter.  Thanks,
    
    Reported-by: Johannes Weiner <jweiner@redhat.com>
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a5faf8e33baa..47dea7118e0e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -30,6 +30,7 @@
 #include <linux/kobject.h>
 #include <trace/events/btrfs.h>
 #include <asm/kmap_types.h>
+#include <linux/pagemap.h>
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
@@ -2117,6 +2118,11 @@ static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
 		(space_info->flags & BTRFS_BLOCK_GROUP_DATA));
 }
 
+static inline gfp_t btrfs_alloc_write_mask(struct address_space *mapping)
+{
+	return mapping_gfp_mask(mapping) & ~__GFP_FS;
+}
+
 /* extent-tree.c */
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 						 unsigned num_items)

commit 4a92b1b8d2810db4ea0c34616b94c0b3810fa027
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Aug 30 12:34:28 2011 -0400

    Btrfs: stop passing a trans handle all around the reservation code
    
    The only thing that we need to have a trans handle for is in
    reserve_metadata_bytes and thats to know how much flushing we can do.  So
    instead of passing it around, just check current->journal_info for a
    trans_handle so we know if we can commit a transaction to try and free up space
    or not.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index caa73cd8c00a..a5faf8e33baa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2237,12 +2237,10 @@ void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root);
 void btrfs_free_block_rsv(struct btrfs_root *root,
 			  struct btrfs_block_rsv *rsv);
-int btrfs_block_rsv_add(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root,
+int btrfs_block_rsv_add(struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv,
 			u64 num_bytes);
-int btrfs_block_rsv_check(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root,
+int btrfs_block_rsv_check(struct btrfs_root *root,
 			  struct btrfs_block_rsv *block_rsv,
 			  u64 min_reserved, int min_factor, int flush);
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,

commit 482e6dc5261406fdb921946e70b51467b0305bad
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Aug 19 10:31:56 2011 -0400

    Btrfs: allow callers to specify if flushing can occur for btrfs_block_rsv_check
    
    If you run xfstest 224 it you will get lots of messages about not being able to
    delete inodes and that they will be cleaned up next mount.  This is because
    btrfs_block_rsv_check was not calling reserve_metadata_bytes with the ability to
    flush, so if there was not enough space, it simply failed.  But in truncate and
    evict case we could easily flush space to try and get enough space to do our
    work, so make btrfs_block_rsv_check take a flush argument to pass down to
    reserve_metadata_bytes.  Now xfstests 224 runs fine without all those
    complaints.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e18b068841b..caa73cd8c00a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2244,7 +2244,7 @@ int btrfs_block_rsv_add(struct btrfs_trans_handle *trans,
 int btrfs_block_rsv_check(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  struct btrfs_block_rsv *block_rsv,
-			  u64 min_reserved, int min_factor);
+			  u64 min_reserved, int min_factor, int flush);
 int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 			    struct btrfs_block_rsv *dst_rsv,
 			    u64 num_bytes);

commit 07127184efb629f1336c0592bfdacec258cab731
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Aug 19 10:29:59 2011 -0400

    Btrfs: reduce the amount of space needed for truncates
    
    With btrfs_truncate_inode_items we always return if we have to go to another
    leaf, which makes us do our reservation again.  This means we will only ever
    modify one leaf at a time, so we only need 1 items worth of slack space.  Also,
    since we are deleting we will not be creating nodes as we go down, if anything
    we'll be free'ing them as we merge them together, so make a different
    calculation for truncate which will only have the worst case useage of COW'ing
    the entire path down to the leaf.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 22a9347a3908..2e18b068841b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2125,6 +2125,17 @@ static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
 		3 * num_items;
 }
 
+/*
+ * Doing a truncate won't result in new nodes or leaves, just what we need for
+ * COW.
+ */
+static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_root *root,
+						 unsigned num_items)
+{
+	return (root->leafsize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
+		num_items;
+}
+
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);

commit 5e962c7850c273b483acc747b41bd5cddf631049
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Aug 8 14:03:37 2011 -0400

    Btrfs: kill btrfs_truncate_reserve_metadata
    
    Since we've optimized the truncate path, we no longer require this function.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 58a06dea4791..22a9347a3908 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2240,9 +2240,6 @@ int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 void btrfs_block_rsv_release(struct btrfs_root *root,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);
-int btrfs_truncate_reserve_metadata(struct btrfs_trans_handle *trans,
-				    struct btrfs_root *root,
-				    struct btrfs_block_rsv *rsv);
 int btrfs_set_block_group_ro(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
 int btrfs_set_block_group_rw(struct btrfs_root *root,

commit dabdb6408cb801644fa613c7432da012640b348c
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Aug 8 12:50:18 2011 -0400

    Btrfs: kill unused parts of block_rsv
    
    The priority and refill_used flags are not used anymore, and neither is the
    usage counter, so just remove them from btrfs_block_rsv.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c5ceba4078cc..58a06dea4791 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -774,9 +774,6 @@ struct btrfs_block_rsv {
 	u64 reserved;
 	struct btrfs_space_info *space_info;
 	spinlock_t lock;
-	atomic_t usage;
-	unsigned int priority:8;
-	unsigned int refill_used:1;
 	unsigned int full:1;
 };
 

commit 37be25bcb6d731914e126f8de59c4367f0d66b80
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Aug 5 10:25:38 2011 -0400

    Btrfs: kill the durable block rsv stuff
    
    This is confusing code and isn't used by anything anymore, so delete it.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4ef777e85c89..c5ceba4078cc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -772,13 +772,10 @@ struct btrfs_space_info {
 struct btrfs_block_rsv {
 	u64 size;
 	u64 reserved;
-	u64 freed[2];
 	struct btrfs_space_info *space_info;
-	struct list_head list;
 	spinlock_t lock;
 	atomic_t usage;
 	unsigned int priority:8;
-	unsigned int durable:1;
 	unsigned int refill_used:1;
 	unsigned int full:1;
 };
@@ -840,7 +837,6 @@ struct btrfs_block_group_cache {
 	spinlock_t lock;
 	u64 pinned;
 	u64 reserved;
-	u64 reserved_pinned;
 	u64 bytes_super;
 	u64 flags;
 	u64 sectorsize;
@@ -919,11 +915,6 @@ struct btrfs_fs_info {
 
 	struct btrfs_block_rsv empty_block_rsv;
 
-	/* list of block reservations that cross multiple transactions */
-	struct list_head durable_block_rsv_list;
-
-	struct mutex durable_block_rsv_mutex;
-
 	u64 generation;
 	u64 last_trans_committed;
 
@@ -2238,8 +2229,6 @@ void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root);
 void btrfs_free_block_rsv(struct btrfs_root *root,
 			  struct btrfs_block_rsv *rsv);
-void btrfs_add_durable_block_rsv(struct btrfs_fs_info *fs_info,
-				 struct btrfs_block_rsv *rsv);
 int btrfs_block_rsv_add(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv,

commit dba68306f3fae681b1005137f130f5bcfdfed34a
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Aug 4 15:34:57 2011 -0400

    Btrfs: kill the orphan space calculation for snapshots
    
    This patch kills off the calculation for the amount of space needed for the
    orphan operations during a snapshot.  The thing is we only do snapshots on
    commit, so any space that is in the block_rsv->freed[] isn't going to be in the
    new snapshot anyway, so there isn't any reason to require that space to be
    reserved for the snapshot to occur.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 332cbdc86ad4..4ef777e85c89 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2577,11 +2577,6 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_cleanup(struct btrfs_root *root);
-void btrfs_orphan_pre_snapshot(struct btrfs_trans_handle *trans,
-				struct btrfs_pending_snapshot *pending,
-				u64 *bytes_to_reserve);
-void btrfs_orphan_post_snapshot(struct btrfs_trans_handle *trans,
-				struct btrfs_pending_snapshot *pending);
 void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t oldsize, loff_t size);

commit fb25e9141ab843794d5cdef3936ccb58435e2371
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Jul 26 17:00:46 2011 -0400

    Btrfs: use bytes_may_use for all ENOSPC reservations
    
    We have been using bytes_reserved for metadata reservations, which is wrong
    since we use that to keep track of outstanding reservations from the allocator.
    This resulted in us doing a lot of silly things to make sure we don't allocate a
    bunch of metadata chunks since we never had a real view of how much space was
    actually in use by metadata.
    
    This passes Arne's enospc test and xfstests as well as my own enospc tests.
    Hopefully this will get us moving in the right direction.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 03912c5c6f49..332cbdc86ad4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2196,8 +2196,6 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      u64 root_objectid, u64 owner, u64 offset);
 
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
-int btrfs_update_reserved_bytes(struct btrfs_block_group_cache *cache,
-				u64 num_bytes, int reserve, int sinfo);
 int btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,

commit 7414a03fbf9e75fbbf2a3c16828cd862e572aa44
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon May 23 14:33:49 2011 +0200

    btrfs: initial readahead code and prototypes
    
    This is the implementation for the generic read ahead framework.
    
    To trigger a readahead, btrfs_reada_add must be called. It will start
    a read ahead for the given range [start, end) on tree root. The returned
    handle can either be used to wait on the readahead to finish
    (btrfs_reada_wait), or to send it to the background (btrfs_reada_detach).
    
    The read ahead works as follows:
    On btrfs_reada_add, the root of the tree is inserted into a radix_tree.
    reada_start_machine will then search for extents to prefetch and trigger
    some reads. When a read finishes for a node, all contained node/leaf
    pointers that lie in the given range will also be enqueued. The reads will
    be triggered in sequential order, thus giving a big win over a naive
    enumeration. It will also make use of multi-device layouts. Each disk
    will have its on read pointer and all disks will by utilized in parallel.
    Also will no two disks read both sides of a mirror simultaneously, as this
    would waste seeking capacity. Instead both disks will read different parts
    of the filesystem.
    Any number of readaheads can be started in parallel. The read order will be
    determined globally, i.e. 2 parallel readaheads will normally finish faster
    than the 2 started one after another.
    
    Changes v2:
     - protect root->node by transaction instead of node_lock
     - fix missed branches:
        The readahead had a too simple check to determine if a branch from
        a node should be checked or not. It now also records the upper bound
        of each node to see if the requested RA range lies within.
     - use KERN_CONT to debug output, to avoid line breaks
     - defer reada_start_machine to worker to avoid deadlock
    
    Changes v3:
     - protect root->node by rcu
    
    Changes v5:
     - changed EIO-semantics of reada_tree_block_flagged
     - remove spin_lock from reada_control and make elems an atomic_t
     - remove unused read_total from reada_control
     - kill reada_key_cmp, use btrfs_comp_cpu_keys instead
     - use kref-style release functions where possible
     - return struct reada_control * instead of void * from btrfs_reada_add
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f71fd24cc152..370af767440d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2702,4 +2702,20 @@ int btrfs_scrub_cancel_devid(struct btrfs_root *root, u64 devid);
 int btrfs_scrub_progress(struct btrfs_root *root, u64 devid,
 			 struct btrfs_scrub_progress *progress);
 
+/* reada.c */
+struct reada_control {
+	struct btrfs_root	*root;		/* tree to prefetch */
+	struct btrfs_key	key_start;
+	struct btrfs_key	key_end;	/* exclusive */
+	atomic_t		elems;
+	struct kref		refcnt;
+	wait_queue_head_t	wait;
+};
+struct reada_control *btrfs_reada_add(struct btrfs_root *root,
+			      struct btrfs_key *start, struct btrfs_key *end);
+int btrfs_reada_wait(void *handle);
+void btrfs_reada_detach(void *handle);
+int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
+			 u64 start, int err);
+
 #endif

commit 90519d66abbccc251d14719ac76f191f70826e40
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon May 23 14:30:00 2011 +0200

    btrfs: state information for readahead
    
    Add state information for readahead to btrfs_fs_info and btrfs_device
    
    Changes v2:
     - don't wait in radix_trees
     - add own set of workers for readahead
    
    Reviewed-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 03912c5c6f49..f71fd24cc152 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1036,6 +1036,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers endio_freespace_worker;
 	struct btrfs_workers submit_workers;
 	struct btrfs_workers caching_workers;
+	struct btrfs_workers readahead_workers;
 
 	/*
 	 * fixup workers take dirty pages that didn't properly go through
@@ -1119,6 +1120,10 @@ struct btrfs_fs_info {
 	u64 fs_state;
 
 	struct btrfs_delayed_root *delayed_root;
+
+	/* readahead tree */
+	spinlock_t reada_lock;
+	struct radix_tree_root reada_tree;
 };
 
 /*

commit 81d86e1b70961f4816f961875e0c706b0954acad
Merge: 9a4327ca1f45 f1e490a7ebe4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Aug 18 10:38:03 2011 -0400

    Merge branch 'btrfs-3.0' into for-linus

commit c97c2916e25c56e878e3e94efd449e2d688fcb31
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Aug 3 08:11:41 2011 +0000

    Btrfs: use plain page_address() in header fields setget functions
    
    We've stopped using highmem for extent buffers.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 884293642a6c..8b99c79ad1a7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1415,17 +1415,15 @@ void btrfs_set_##name(struct extent_buffer *eb, type *s, u##bits val);
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
 static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
 {									\
-	type *p = kmap_atomic(eb->first_page, KM_USER0);		\
+	type *p = page_address(eb->first_page);				\
 	u##bits res = le##bits##_to_cpu(p->member);			\
-	kunmap_atomic(p, KM_USER0);					\
 	return res;							\
 }									\
 static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 				    u##bits val)			\
 {									\
-	type *p = kmap_atomic(eb->first_page, KM_USER0);		\
+	type *p = page_address(eb->first_page);				\
 	p->member = cpu_to_le##bits(val);				\
-	kunmap_atomic(p, KM_USER0);					\
 }
 
 #define BTRFS_SETGET_STACK_FUNCS(name, type, member, bits)		\

commit cb1b69f4508a1e8c1a7907379eafceb7ae0325ef
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Tue Aug 9 07:11:13 2011 +0000

    Btrfs: forced readonly when btrfs_drop_snapshot() fails
    
    The filesystem turns readonly instead of returning the error to the
    caller when detected error in btrfs_drop_snapshot().
    and, because the caller doesn't check the error, the function type is
    changed to 'void'.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a6263bdab818..884293642a6c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2367,8 +2367,8 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
-int btrfs_drop_snapshot(struct btrfs_root *root,
-			struct btrfs_block_rsv *block_rsv, int update_ref);
+void btrfs_drop_snapshot(struct btrfs_root *root,
+			 struct btrfs_block_rsv *block_rsv, int update_ref);
 int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct extent_buffer *node,

commit ed8f37370d83e695c0a4fa5d5fc7a83ecb947526
Merge: a6b11f533889 0d10ee2e6deb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 2 21:14:05 2011 -1000

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (31 commits)
      Btrfs: don't call writepages from within write_full_page
      Btrfs: Remove unused variable 'last_index' in file.c
      Btrfs: clean up for find_first_extent_bit()
      Btrfs: clean up for wait_extent_bit()
      Btrfs: clean up for insert_state()
      Btrfs: remove unused members from struct extent_state
      Btrfs: clean up code for merging extent maps
      Btrfs: clean up code for extent_map lookup
      Btrfs: clean up search_extent_mapping()
      Btrfs: remove redundant code for dir item lookup
      Btrfs: make acl functions really no-op if acl is not enabled
      Btrfs: remove remaining ref-cache code
      Btrfs: remove a BUG_ON() in btrfs_commit_transaction()
      Btrfs: use wait_event()
      Btrfs: check the nodatasum flag when writing compressed files
      Btrfs: copy string correctly in INO_LOOKUP ioctl
      Btrfs: don't print the leaf if we had an error
      btrfs: make btrfs_set_root_node void
      Btrfs: fix oops while writing data to SSD partitions
      Btrfs: Protect the readonly flag of block group
      ...
    
    Fix up trivial conflicts (due to acl and writeback cleanups) in
     - fs/btrfs/acl.c
     - fs/btrfs/ctree.h
     - fs/btrfs/extent_io.c

commit 9b89d95a143bb0a9abc4ba0fdcdda78211930f1a
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Thu Jul 14 03:17:39 2011 +0000

    Btrfs: make acl functions really no-op if acl is not enabled
    
    So there's no overhead for something we don't use.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 34ce4140bb41..a6263bdab818 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2650,12 +2650,21 @@ do {								\
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL
 int btrfs_check_acl(struct inode *inode, int mask, unsigned int flags);
-#else
-#define btrfs_check_acl NULL
-#endif
 int btrfs_init_acl(struct btrfs_trans_handle *trans,
 		   struct inode *inode, struct inode *dir);
 int btrfs_acl_chmod(struct inode *inode);
+#else
+#define btrfs_check_acl NULL
+static inline int btrfs_init_acl(struct btrfs_trans_handle *trans,
+				 struct inode *inode, struct inode *dir)
+{
+	return 0;
+}
+static inline int btrfs_acl_chmod(struct inode *inode)
+{
+	return 0;
+}
+#endif
 
 /* relocation.c */
 int btrfs_relocate_block_group(struct btrfs_root *root, u64 group_start);

commit bf5f32ecb6caac52b4d1c083251b3dd4f40a0b7a
Author: Mark Fasheh <mfasheh@suse.com>
Date:   Thu Jul 14 21:23:06 2011 +0000

    btrfs: make btrfs_set_root_node void
    
    This is fairly trivial - btrfs_set_root_node() - always returns zero so we
    can just make it void.  All callers ignore the return code now anyway.  I
    also made sure to check that none of the functions that
    btrfs_set_root_node() calls returns an error that we might have needed to
    catch and pass back.
    
    Signed-off-by: Mark Fasheh <mfasheh@suse.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7ac4d25fd4f8..34ce4140bb41 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2406,8 +2406,8 @@ int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);
 int btrfs_find_orphan_roots(struct btrfs_root *tree_root);
-int btrfs_set_root_node(struct btrfs_root_item *item,
-			struct extent_buffer *node);
+void btrfs_set_root_node(struct btrfs_root_item *item,
+			 struct extent_buffer *node);
 void btrfs_check_and_init_root_item(struct btrfs_root_item *item);
 
 /* dir-item.c */

commit b6973aa62253f3791ef6fa5e9f9de099645fc2bd
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Jul 20 03:46:35 2011 +0000

    Btrfs: fix readahead in file defrag
    
    We passed the wrong value to btrfs_force_ra(). Fix this by changing
    the argument of btrfs_force_ra() from last_index to nr_page.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3be57c611040..7ac4d25fd4f8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2520,6 +2520,14 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 #define PageChecked PageFsMisc
 #endif
 
+/* This forces readahead on a given range of bytes in an inode */
+static inline void btrfs_force_ra(struct address_space *mapping,
+				  struct file_ra_state *ra, struct file *file,
+				  pgoff_t offset, unsigned long req_size)
+{
+	page_cache_sync_readahead(mapping, ra, file, offset, req_size);
+}
+
 struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry);
 int btrfs_set_inode_index(struct inode *dir, u64 *index);
 int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
@@ -2548,9 +2556,6 @@ int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio, unsigned long bio_flags);
 
-unsigned long btrfs_force_ra(struct address_space *mapping,
-			      struct file_ra_state *ra, struct file *file,
-			      pgoff_t offset, pgoff_t last_index);
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);

commit 22712200e175e0df5c7f9edfe6c6bf5c94c23b83
Merge: 597a67e0ba75 ff95acb6733d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 16:43:52 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: make sure reserve_metadata_bytes doesn't leak out strange errors
      Btrfs: use the commit_root for reading free_space_inode crcs
      Btrfs: reduce extent_state lock contention for metadata
      Btrfs: remove lockdep magic from btrfs_next_leaf
      Btrfs: make a lockdep class for each root
      Btrfs: switch the btrfs tree locks to reader/writer
      Btrfs: fix deadlock when throttling transactions
      Btrfs: stop using highmem for extent_buffers
      Btrfs: fix BUG_ON() caused by ENOSPC when relocating space
      Btrfs: tag pages for writeback in sync
      Btrfs: fix enospc problems with delalloc
      Btrfs: don't flush delalloc arbitrarily
      Btrfs: use find_or_create_page instead of grab_cache_page
      Btrfs: use a worker thread to do caching
      Btrfs: fix how we merge extent states and deal with cached states
      Btrfs: use the normal checksumming infrastructure for free space cache
      Btrfs: serialize flushers in reserve_metadata_bytes
      Btrfs: do transaction space reservation before joining the transaction
      Btrfs: try to only do one btrfs_search_slot in do_setxattr

commit ff95acb6733d41a8d45feb0e18b96df25e610e78
Merge: 02f8c6aee8df 75c195a2cac2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jul 27 16:13:10 2011 -0400

    Merge branch 'integration' into for-linus

commit bd681513fa6f2ff29aa391f01e413a2d1c59fd77
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Jul 16 15:23:14 2011 -0400

    Btrfs: switch the btrfs tree locks to reader/writer
    
    The btrfs metadata btree is the source of significant
    lock contention, especially in the root node.   This
    commit changes our locking to use a reader/writer
    lock.
    
    The lock is built on top of rw spinlocks, and it
    extends the lock tracking to remember if we have a
    read lock or a write lock when we go to blocking.  Atomics
    count the number of blocking readers or writers at any
    given time.
    
    It removes all of the adaptive spinning from the old code
    and uses only the spinning/blocking hints inside of btrfs
    to decide when it should continue spinning.
    
    In read heavy workloads this is dramatically faster.  In write
    heavy workloads we're still faster because of less contention
    on the root node lock.
    
    We suffer slightly in dbench because we schedule more often
    during write locks, but all other benchmarks so far are improved.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3063f21d3fc6..40235e10cfb9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2333,7 +2333,7 @@ struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
 void btrfs_set_path_blocking(struct btrfs_path *p);
 void btrfs_clear_path_blocking(struct btrfs_path *p,
-			       struct extent_buffer *held);
+			       struct extent_buffer *held, int held_rw);
 void btrfs_unlock_up_safe(struct btrfs_path *p, int level);
 
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,

commit 9e0baf60dea69f31ac3b1adeb35b03b02a53e8e1
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Jul 15 15:16:44 2011 +0000

    Btrfs: fix enospc problems with delalloc
    
    So I had this brilliant idea to use atomic counters for outstanding and reserved
    extents, but this turned out to be a bad idea.  Consider this where we have 1
    outstanding extent and 1 reserved extent
    
    Reserver                                Releaser
                                            atomic_dec(outstanding) now 0
    atomic_read(outstanding)+1 get 1
    atomic_read(reserved) get 1
    don't actually reserve anything because
    they are the same
                                            atomic_cmpxchg(reserved, 1, 0)
    atomic_inc(outstanding)
    atomic_add(0, reserved)
                                            free reserved space for 1 extent
    
    Then the reserver now has no actual space reserved for it, and when it goes to
    finish the ordered IO it won't have enough space to do it's allocation and you
    get those lovely warnings.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9f6f342900c9..3063f21d3fc6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2134,7 +2134,7 @@ static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
 
 /* extent-tree.c */
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
-						 int num_items)
+						 unsigned num_items)
 {
 	return (root->leafsize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
 		3 * num_items;

commit bab39bf998133510f2dad08158006197ec0dabea
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Jun 30 14:42:28 2011 -0400

    Btrfs: use a worker thread to do caching
    
    A user reported a deadlock when copying a bunch of files.  This is because they
    were low on memory and kthreadd got hung up trying to migrate pages for an
    allocation when starting the caching kthread.  The page was locked by the person
    starting the caching kthread.  To fix this we just need to use the async thread
    stuff so that the threads are already created and we don't have to worry about
    deadlocks.  Thanks,
    
    Reported-by: Roman Mamedov <rm@romanrm.ru>
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 406c33876605..9f6f342900c9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -767,7 +767,6 @@ struct btrfs_space_info {
 	struct list_head block_groups[BTRFS_NR_RAID_TYPES];
 	spinlock_t lock;
 	struct rw_semaphore groups_sem;
-	atomic_t caching_threads;
 	wait_queue_head_t wait;
 };
 
@@ -828,6 +827,7 @@ struct btrfs_caching_control {
 	struct list_head list;
 	struct mutex mutex;
 	wait_queue_head_t wait;
+	struct btrfs_work work;
 	struct btrfs_block_group_cache *block_group;
 	u64 progress;
 	atomic_t count;
@@ -1036,6 +1036,8 @@ struct btrfs_fs_info {
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers endio_freespace_worker;
 	struct btrfs_workers submit_workers;
+	struct btrfs_workers caching_workers;
+
 	/*
 	 * fixup workers take dirty pages that didn't properly go through
 	 * the cow mechanism and make them safe to write.  It happens

commit 4e34e719e457f2e031297175410fc0bd4016a085
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jul 23 17:37:31 2011 +0200

    fs: take the ACL checks to common code
    
    Replace the ->check_acl method with a ->get_acl method that simply reads an
    ACL from disk after having a cache miss.  This means we can replace the ACL
    checking boilerplate code with a single implementation in namei.c.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 82be74efbb26..fe9287b06496 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2645,9 +2645,9 @@ do {								\
 
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL
-int btrfs_check_acl(struct inode *inode, int mask);
+struct posix_acl *btrfs_get_acl(struct inode *inode, int type);
 #else
-#define btrfs_check_acl NULL
+#define btrfs_get_acl NULL
 #endif
 int btrfs_init_acl(struct btrfs_trans_handle *trans,
 		   struct inode *inode, struct inode *dir);

commit 02c24a82187d5a628c68edfe71ae60dc135cd178
Author: Josef Bacik <josef@redhat.com>
Date:   Sat Jul 16 20:44:56 2011 -0400

    fs: push i_mutex and filemap_write_and_wait down into ->fsync() handlers
    
    Btrfs needs to be able to control how filemap_write_and_wait_range() is called
    in fsync to make it less of a painful operation, so push down taking i_mutex and
    the calling of filemap_write_and_wait() down into the ->fsync() handlers.  Some
    file systems can drop taking the i_mutex altogether it seems, like ext3 and
    ocfs2.  For correctness sake I just pushed everything down in all cases to make
    sure that we keep the current behavior the same for everybody, and then each
    individual fs maintainer can make up their mind about what to do from there.
    Thanks,
    
    Acked-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f1ff62bff1b3..82be74efbb26 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2605,7 +2605,7 @@ int btrfs_defrag_file(struct inode *inode, struct file *file,
 int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
 			   struct inode *inode);
 int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
-int btrfs_sync_file(struct file *file, int datasync);
+int btrfs_sync_file(struct file *file, loff_t start, loff_t end, int datasync);
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			    int skip_pinned);
 extern const struct file_operations btrfs_file_operations;

commit b26751575a9aa55fd6dbf3febde3ff06dfadc44f
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 18 13:21:36 2011 -0400

    Btrfs: implement our own ->llseek
    
    In order to handle SEEK_HOLE/SEEK_DATA we need to implement our own llseek.
    Basically for the normal SEEK_*'s we will just defer to the generic helper, and
    for SEEK_HOLE/SEEK_DATA we will use our fiemap helper to figure out the nearest
    hole or data.  Currently this helper doesn't check for delalloc bytes for
    prealloc space, so for now treat prealloc as data until that is fixed.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9552afc24ef7..f1ff62bff1b3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2510,6 +2510,9 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit);
 /* inode.c */
+struct extent_map *btrfs_get_extent_fiemap(struct inode *inode, struct page *page,
+					   size_t pg_offset, u64 start, u64 len,
+					   int create);
 
 /* RHEL and EL kernels have a patch that renames PG_checked to FsMisc */
 #if defined(ClearPageFsMisc) && !defined(ClearPageChecked)

commit 0ee5dc676a5f8fadede608c7281dfedb1ae714ea
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Jul 7 15:44:25 2011 -0400

    btrfs: kill magical embedded struct superblock
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9864cec801ed..9552afc24ef7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1219,7 +1219,7 @@ struct btrfs_root {
 	 * right now this just gets used so that a root has its own devid
 	 * for stat.  It may be used for more later
 	 */
-	struct super_block anon_super;
+	dev_t anon_dev;
 };
 
 struct btrfs_ioctl_defrag_range_args {

commit 7e40145eb111a5192e6d819f764db9d6828d1abb
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 20 19:12:17 2011 -0400

    ->permission() sanitizing: don't pass flags to ->check_acl()
    
    not used in the instances anymore.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3b859a3e6a0e..9864cec801ed 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2642,7 +2642,7 @@ do {								\
 
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL
-int btrfs_check_acl(struct inode *inode, int mask, unsigned int flags);
+int btrfs_check_acl(struct inode *inode, int mask);
 #else
 #define btrfs_check_acl NULL
 #endif

commit fdb5effd5c2a7e01dc3a4217bb194e2d3a5b160f
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Jun 7 16:07:44 2011 -0400

    Btrfs: serialize flushers in reserve_metadata_bytes
    
    We keep having problems with early enospc, and that's because our method of
    making space is inherently racy.  The problem is we can have one guy trying to
    make space for himself, and in the meantime people come in and steal his
    reservation.  In order to stop this we make a waitqueue and put anybody who
    comes into reserve_metadata_bytes on that waitqueue if somebody is trying to
    make more space.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 28e170bcdcb5..406c33876605 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -756,6 +756,8 @@ struct btrfs_space_info {
 				   chunks for this space */
 	unsigned int chunk_alloc:1;	/* set if we are allocating a chunk */
 
+	unsigned int flush:1;		/* set if we are trying to make space */
+
 	unsigned int force_alloc;	/* set if we need to force a chunk
 					   alloc for this space */
 
@@ -766,6 +768,7 @@ struct btrfs_space_info {
 	spinlock_t lock;
 	struct rw_semaphore groups_sem;
 	atomic_t caching_threads;
+	wait_queue_head_t wait;
 };
 
 struct btrfs_block_rsv {

commit b5009945be18023942ce28327893c7bc1e58fe54
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Jun 7 15:07:51 2011 -0400

    Btrfs: do transaction space reservation before joining the transaction
    
    We have to do weird things when handling enospc in the transaction joining code.
    Because we've already joined the transaction we cannot commit the transaction
    within the reservation code since it will deadlock, so we have to return EAGAIN
    and then make sure we don't retry too many times.  Instead of doing this, just
    do the reservation the normal way before we join the transaction, that way we
    can do whatever we want to try and reclaim space, and then if it fails we know
    for sure we are out of space and we can return ENOSPC.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 60e13ef23a5e..28e170bcdcb5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2223,9 +2223,6 @@ void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 int btrfs_check_data_free_space(struct inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
-int btrfs_trans_reserve_metadata(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root,
-				int num_items);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,

commit 1acc9309eb2674533944f48dbaaa53e7750e3947
Merge: c2d197e82b62 149e2d76b488
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 8 23:25:45 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      btrfs: fix oops when doing space balance
      Btrfs: don't panic if we get an error while balancing V2
      btrfs: add missing options displayed in mount output

commit 0942caa373c676dca614ea8352ac77e0270aba73
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Jun 28 15:10:37 2011 +0000

    btrfs: add missing options displayed in mount output
    
    There are three missed mount options settable by user which are not
    currently displayed in mount output.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8e948ec1ee6b..60e13ef23a5e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1336,6 +1336,11 @@ struct btrfs_ioctl_defrag_range_args {
  */
 #define BTRFS_STRING_ITEM_KEY	253
 
+/*
+ * Flags for mount options.
+ *
+ * Note: don't forget to add new options to btrfs_show_options()
+ */
 #define BTRFS_MOUNT_NODATASUM		(1 << 0)
 #define BTRFS_MOUNT_NODATACOW		(1 << 1)
 #define BTRFS_MOUNT_NOBARRIER		(1 << 2)

commit 46e4edbf7ea9cf26665eb9f90c0fc7688d1a51ed
Author: Jesper Juhl <jj@chaosbits.net>
Date:   Thu Jun 23 23:59:32 2011 +0200

    Remove unneeded version.h includes from fs/
    
    It was pointed out by 'make versioncheck' that some includes of
    linux/version.h were not needed in fs/ (fs/btrfs/ctree.h and
    fs/omfs/file.c).
    
    This patch removes them.
    
    Signed-off-by: Jesper Juhl <jj@chaosbits.net>
    Acked-by: Bob Copeland <me@bobcopeland.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 300628795fdb..f30ac05dbda7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -19,7 +19,6 @@
 #ifndef __BTRFS_CTREE__
 #define __BTRFS_CTREE__
 
-#include <linux/version.h>
 #include <linux/mm.h>
 #include <linux/highmem.h>
 #include <linux/fs.h>

commit 90a800de0a29426ea900ecd53f2929d5f4bc4578
Merge: 10e18e62309a e999376f0941
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 20 08:58:53 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: avoid delayed metadata items during commits
      btrfs: fix uninitialized return value
      btrfs: fix wrong reservation when doing delayed inode operations
      btrfs: Remove unused sysfs code
      btrfs: fix dereference of ERR_PTR value
      Btrfs: fix relocation races
      Btrfs: set no_trans_join after trying to expand the transaction
      Btrfs: protect the pending_snapshots list with trans_lock
      Btrfs: fix path leakage on subvol deletion
      Btrfs: drop the delalloc_bytes check in shrink_delalloc
      Btrfs: check the return value from set_anon_super

commit 9fe6a50fb764f508dd2de47a66e62e51388791fb
Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
Date:   Thu Jun 16 09:04:57 2011 +0000

    btrfs: Remove unused sysfs code
    
    Removes code no longer used. The sysfs file itself is kept, because the
    btrfs developers expressed interest in putting new entries to sysfs.
    
    Signed-off-by: Maarten Lankhorst <m.b.lankhorst@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a2c91a102b72..8e948ec1ee6b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1195,7 +1195,6 @@ struct btrfs_root {
 	struct btrfs_key defrag_max;
 	int defrag_running;
 	char *name;
-	int in_sysfs;
 
 	/* the dirty list is only used by non-reference counted roots */
 	struct list_head dirty_list;

commit 7585717f304f5ed005cc4ad933a69aab3efbd136
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jun 13 20:00:16 2011 -0400

    Btrfs: fix relocation races
    
    The recent commit to get rid of our trans_mutex introduced
    some races with block group relocation.  The problem is that relocation
    needs to do some record keeping about each root, and it was relying
    on the transaction mutex to coordinate things in subtle ways.
    
    This fix adds a mutex just for the relocation code and makes sure
    it doesn't have a big impact on normal operations.  The race is
    really fixed in btrfs_record_root_in_trans, which is where we
    step back and wait for the relocation code to finish accounting
    setup.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8490ee063709..a2c91a102b72 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -967,6 +967,12 @@ struct btrfs_fs_info {
 	struct srcu_struct subvol_srcu;
 
 	spinlock_t trans_lock;
+	/*
+	 * the reloc mutex goes with the trans lock, it is taken
+	 * during commit to protect us from the relocation code
+	 */
+	struct mutex reloc_mutex;
+
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
@@ -1172,6 +1178,14 @@ struct btrfs_root {
 	u32 type;
 
 	u64 highest_objectid;
+
+	/* btrfs_record_root_in_trans is a multi-step process,
+	 * and it can race with the balancing code.   But the
+	 * race is very small, and only the first time the root
+	 * is added to each transaction.  So in_trans_setup
+	 * is used to tell us when more checks are required
+	 */
+	unsigned long in_trans_setup;
 	int ref_cows;
 	int track_dirty;
 	int in_radix;

commit e6ece70732b905742ad91a7b5489e0ca1362c0cd
Merge: 23c79d31a3dd aa0467d8d2a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jun 5 06:17:23 2011 +0900

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (25 commits)
      btrfs: fix uninitialized variable warning
      btrfs: add helper for fs_info->closing
      Btrfs: add mount -o inode_cache
      btrfs: scrub: add explicit plugging
      btrfs: use btrfs_ino to access inode number
      Btrfs: don't save the inode cache if we are deleting this root
      btrfs: false BUG_ON when degraded
      Btrfs: don't save the inode cache in non-FS roots
      Btrfs: make sure we don't overflow the free space cache crc page
      Btrfs: fix uninit variable in the delayed inode code
      btrfs: scrub: don't reuse bios and pages
      Btrfs: leave spinning on lookup and map the leaf
      Btrfs: check for duplicate entries in the free space cache
      Btrfs: don't try to allocate from a block group that doesn't have enough space
      Btrfs: don't always do readahead
      Btrfs: try not to sleep as much when doing slow caching
      Btrfs: kill BTRFS_I(inode)->block_group
      Btrfs: don't look at the extent buffer level 3 times in a row
      Btrfs: map the node block when looking for readahead targets
      Btrfs: set range_start to the right start in count_range_bits
      ...

commit 7841cb2898f66a73062c64d0ef5733dde7279e46
Author: David Sterba <dsterba@suse.cz>
Date:   Tue May 31 18:07:27 2011 +0200

    btrfs: add helper for fs_info->closing
    
    wrap checking of filesystem 'closing' flag and fix a few missing memory
    barriers.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4958ef5417d6..8490ee063709 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2354,6 +2354,15 @@ int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct extent_buffer *node,
 			struct extent_buffer *parent);
+static inline int btrfs_fs_closing(struct btrfs_fs_info *fs_info)
+{
+	/*
+	 * Get synced with close_ctree()
+	 */
+	smp_mb();
+	return fs_info->closing;
+}
+
 /* root-item.c */
 int btrfs_find_root_ref(struct btrfs_root *tree_root,
 			struct btrfs_path *path,

commit 4b9465cb9e3859186eefa1ca3b990a5849386320
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 3 09:36:29 2011 -0400

    Btrfs: add mount -o inode_cache
    
    This makes the inode map cache default to off until we
    fix the overflow problem when the free space crcs don't fit
    inside a single page.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f98c2005715..4958ef5417d6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1340,6 +1340,7 @@ struct btrfs_ioctl_defrag_range_args {
 #define BTRFS_MOUNT_USER_SUBVOL_RM_ALLOWED (1 << 14)
 #define BTRFS_MOUNT_ENOSPC_DEBUG	 (1 << 15)
 #define BTRFS_MOUNT_AUTO_DEFRAG		(1 << 16)
+#define BTRFS_MOUNT_INODE_MAP_CACHE	(1 << 17)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 36947a76826111e661a26cb0f668a5be6cc3ddb4
Merge: a947e23a8ec0 69b457329646
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat May 28 13:03:41 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6: (36 commits)
      Cache xattr security drop check for write v2
      fs: block_page_mkwrite should wait for writeback to finish
      mm: Wait for writeback when grabbing pages to begin a write
      configfs: remove unnecessary dentry_unhash on rmdir, dir rename
      fat: remove unnecessary dentry_unhash on rmdir, dir rename
      hpfs: remove unnecessary dentry_unhash on rmdir, dir rename
      minix: remove unnecessary dentry_unhash on rmdir, dir rename
      fuse: remove unnecessary dentry_unhash on rmdir, dir rename
      coda: remove unnecessary dentry_unhash on rmdir, dir rename
      afs: remove unnecessary dentry_unhash on rmdir, dir rename
      affs: remove unnecessary dentry_unhash on rmdir, dir rename
      9p: remove unnecessary dentry_unhash on rmdir, dir rename
      ncpfs: fix rename over directory with dangling references
      ncpfs: document dentry_unhash usage
      ecryptfs: remove unnecessary dentry_unhash on rmdir, dir rename
      hostfs: remove unnecessary dentry_unhash on rmdir, dir rename
      hfsplus: remove unnecessary dentry_unhash on rmdir, dir rename
      hfs: remove unnecessary dentry_unhash on rmdir, dir rename
      omfs: remove unnecessary dentry_unhash on rmdir, dir rneame
      udf: remove unnecessary dentry_unhash from rmdir, dir rename
      ...

commit ff5714cca971848963b87d6b477c16ca8abbaa54
Merge: 174ba50915b0 d90c732122a1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat May 28 07:00:39 2011 -0400

    Merge branch 'for-chris' of
    git://git.kernel.org/pub/scm/linux/kernel/git/josef/btrfs-work into for-linus
    
    Conflicts:
            fs/btrfs/disk-io.c
            fs/btrfs/extent-tree.c
            fs/btrfs/free-space-cache.c
            fs/btrfs/inode.c
            fs/btrfs/transaction.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit aa38572954ade525817fe88c54faebf85e5a61c0
Author: Christoph Hellwig <hch@infradead.org>
Date:   Fri May 27 06:53:02 2011 -0400

    fs: pass exact type of data dirties to ->dirty_inode
    
    Tell the filesystem if we just updated timestamp (I_DIRTY_SYNC) or
    anything else, so that the filesystem can track internally if it
    needs to push out a transaction for fdatasync or not.
    
    This is just the prototype change with no user for it yet.  I plan
    to push large XFS changes for the next merge window, and getting
    this trivial infrastructure in this window would help a lot to avoid
    tree interdependencies.
    
    Also remove incorrect comments that ->dirty_inode can't block.  That
    has been changed a long time ago, and many implementations rely on it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f4b81de3ae2..d2177e7ad647 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2522,7 +2522,7 @@ int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);
 void btrfs_put_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
-void btrfs_dirty_inode(struct inode *inode);
+void btrfs_dirty_inode(struct inode *inode, int flags);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_drop_inode(struct inode *inode);

commit 4cb5300bc839b8a943eb19c9f27f25470e22d0ca
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 24 15:35:30 2011 -0400

    Btrfs: add mount -o auto_defrag
    
    This will detect small random writes into files and
    queue the up for an auto defrag process.  It isn't well suited to
    database workloads yet, but works for smaller files such as rpm, sqlite
    or bdb databases.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 026fc47b42cf..332323e19dd1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1074,6 +1074,11 @@ struct btrfs_fs_info {
 	/* all metadata allocations go through this cluster */
 	struct btrfs_free_cluster meta_alloc_cluster;
 
+	/* auto defrag inodes go here */
+	spinlock_t defrag_inodes_lock;
+	struct rb_root defrag_inodes;
+	atomic_t defrag_running;
+
 	spinlock_t ref_cache_lock;
 	u64 total_ref_cache_size;
 
@@ -1205,6 +1210,38 @@ struct btrfs_root {
 	struct super_block anon_super;
 };
 
+struct btrfs_ioctl_defrag_range_args {
+	/* start of the defrag operation */
+	__u64 start;
+
+	/* number of bytes to defrag, use (u64)-1 to say all */
+	__u64 len;
+
+	/*
+	 * flags for the operation, which can include turning
+	 * on compression for this one defrag
+	 */
+	__u64 flags;
+
+	/*
+	 * any extent bigger than this will be considered
+	 * already defragged.  Use 0 to take the kernel default
+	 * Use 1 to say every single extent must be rewritten
+	 */
+	__u32 extent_thresh;
+
+	/*
+	 * which compression method to use if turning on compression
+	 * for this defrag operation.  If unspecified, zlib will
+	 * be used
+	 */
+	__u32 compress_type;
+
+	/* spare for later */
+	__u32 unused[4];
+};
+
+
 /*
  * inode items have the data typically returned from stat and store other
  * info about object characteristics.  There is one for every file and dir in
@@ -1302,6 +1339,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_CLEAR_CACHE		(1 << 13)
 #define BTRFS_MOUNT_USER_SUBVOL_RM_ALLOWED (1 << 14)
 #define BTRFS_MOUNT_ENOSPC_DEBUG	 (1 << 15)
+#define BTRFS_MOUNT_AUTO_DEFRAG		(1 << 16)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
@@ -2528,8 +2566,13 @@ extern const struct dentry_operations btrfs_dentry_operations;
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 void btrfs_update_iflags(struct inode *inode);
 void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
-
+int btrfs_defrag_file(struct inode *inode, struct file *file,
+		      struct btrfs_ioctl_defrag_range_args *range,
+		      u64 newer_than, unsigned long max_pages);
 /* file.c */
+int btrfs_add_inode_defrag(struct btrfs_trans_handle *trans,
+			   struct inode *inode);
+int btrfs_run_defrag_inodes(struct btrfs_fs_info *fs_info);
 int btrfs_sync_file(struct file *file, int datasync);
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			    int skip_pinned);

commit d6c0cb379c5198487e4ac124728cbb2346d63b1f
Merge: 8e531cdfeb75 1f78160ce1b1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 23 14:37:47 2011 -0400

    Merge branch 'cleanups_and_fixes' into inode_numbers
    
    Conflicts:
            fs/btrfs/tree-log.c
            fs/btrfs/volumes.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 0956c798ef8dbe0fc215870eb68bd2d8e789f86a
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed May 18 00:11:22 2011 +0000

    BTRFS: Remove unused node_lock
    
    240f62c8756 replaced the node_lock with rcu_read_lock, but forgot
    to remove the actual lock in the data structure. Remove it here.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f4b81de3ae2..f290b98e2fe6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1088,9 +1088,6 @@ struct btrfs_fs_info {
 struct btrfs_root {
 	struct extent_buffer *node;
 
-	/* the node lock is held while changing the node pointer */
-	spinlock_t node_lock;
-
 	struct extent_buffer *commit_root;
 	struct btrfs_root *log_root;
 	struct btrfs_root *reloc_root;

commit d82a6f1d7e8b61ed5996334d0db66651bb43641d
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 11 15:26:06 2011 -0400

    Btrfs: kill BTRFS_I(inode)->block_group
    
    Originally this was going to be used as a way to give hints to the allocator,
    but frankly we can get much better hints elsewhere and it's not even used at all
    for anything usefull.  In addition to be completely useless, when we initialize
    an inode we try and find a freeish block group to set as the inodes block group,
    and with a completely full 40gb fs this takes _forever_, so I imagine with say
    1tb fs this is just unbearable.  So just axe the thing altoghether, we don't
    need it and it saves us 8 bytes in the inode and saves us 500 microseconds per
    inode lookup in my testcase.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f31aed7fedd9..0f8c489bcc02 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2512,8 +2512,7 @@ int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *new_root,
-			     u64 new_dirid, u64 alloc_hint);
+			     struct btrfs_root *new_root, u64 new_dirid);
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio, unsigned long bio_flags);
 

commit fcb80c2affd63237cff5b34cba5756be7c976a5a
Author: Josef Bacik <josef@redhat.com>
Date:   Tue May 3 10:40:22 2011 -0400

    Btrfs: fix how we do space reservation for truncate
    
    The ceph guys keep running into problems where we have space reserved in our
    orphan block rsv when freeing it up.  This is because they tend to do snapshots
    alot, so their truncates tend to use a bunch of space, so when we go to do
    things like update the inode we have to steal reservation space in order to make
    the reservation happen.  This happens because truncate can use as much space as
    it freaking feels like, but we still have to hold space for removing the orphan
    item and updating the inode, which will definitely always happen.  So in order
    to fix this we need to split all of the reservation stuf up.  So with this patch
    we have
    
    1) The orphan block reserve which only holds the space for deleting our orphan
    item when everything is over.
    
    2) The truncate block reserve which gets allocated and used specifically for the
    space that the truncate will use on a per truncate basis.
    
    3) The transaction will always have 1 item's worth of data reserved so we can
    update the inode normally.
    
    Hopefully this will make the ceph problem go away.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 522a39b0033d..f31aed7fedd9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2224,6 +2224,9 @@ int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
 void btrfs_block_rsv_release(struct btrfs_root *root,
 			     struct btrfs_block_rsv *block_rsv,
 			     u64 num_bytes);
+int btrfs_truncate_reserve_metadata(struct btrfs_trans_handle *trans,
+				    struct btrfs_root *root,
+				    struct btrfs_block_rsv *rsv);
 int btrfs_set_block_group_ro(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
 int btrfs_set_block_group_rw(struct btrfs_root *root,

commit a4abeea41adfa3c143c289045f4625dfaeba2212
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 11 17:25:13 2011 -0400

    Btrfs: kill trans_mutex
    
    We use trans_mutex for lots of things, here's a basic list
    
    1) To serialize trans_handles joining the currently running transaction
    2) To make sure that no new trans handles are started while we are committing
    3) To protect the dead_roots list and the transaction lists
    
    Really the serializing trans_handles joining is not too hard, and can really get
    bogged down in acquiring a reference to the transaction.  So replace the
    trans_mutex with a trans_lock spinlock and use it to do the following
    
    1) Protect fs_info->running_transaction.  All trans handles have to do is check
    this, and then take a reference of the transaction and keep on going.
    2) Protect the fs_info->trans_list.  This doesn't get used too much, basically
    it just holds the current transactions, which will usually just be the currently
    committing transaction and the currently running transaction at most.
    3) Protect the dead roots list.  This is only ever processed by splicing the
    list so this is relatively simple.
    4) Protect the fs_info->reloc_ctl stuff.  This is very lightweight and was using
    the trans_mutex before, so this is a pretty straightforward change.
    5) Protect fs_info->no_trans_join.  Because we don't hold the trans_lock over
    the entirety of the commit we need to have a way to block new people from
    creating a new transaction while we're doing our work.  So we set no_trans_join
    and in join_transaction we test to see if that is set, and if it is we do a
    wait_on_commit.
    6) Make the transaction use count atomic so we don't need to take locks to
    modify it when we're dropping references.
    7) Add a commit_lock to the transaction to make sure multiple people trying to
    commit the same transaction don't race and commit at the same time.
    8) Make open_ioctl_trans an atomic so we don't have to take any locks for ioctl
    trans.
    
    I have tested this with xfstests, but obviously it is a pretty hairy change so
    lots of testing is greatly appreciated.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f4b81de3ae2..522a39b0033d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -919,7 +919,6 @@ struct btrfs_fs_info {
 	 * is required instead of the faster short fsync log commits
 	 */
 	u64 last_trans_log_full_commit;
-	u64 open_ioctl_trans;
 	unsigned long mount_opt:20;
 	unsigned long compress_type:4;
 	u64 max_inline;
@@ -936,7 +935,6 @@ struct btrfs_fs_info {
 	struct super_block *sb;
 	struct inode *btree_inode;
 	struct backing_dev_info bdi;
-	struct mutex trans_mutex;
 	struct mutex tree_log_mutex;
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;
@@ -957,6 +955,7 @@ struct btrfs_fs_info {
 	struct rw_semaphore subvol_sem;
 	struct srcu_struct subvol_srcu;
 
+	spinlock_t trans_lock;
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
@@ -969,6 +968,7 @@ struct btrfs_fs_info {
 	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;
 	atomic_t async_delalloc_pages;
+	atomic_t open_ioctl_trans;
 
 	/*
 	 * this is used by the balancing code to wait for all the pending
@@ -1032,6 +1032,7 @@ struct btrfs_fs_info {
 	int closing;
 	int log_root_recovering;
 	int enospc_unlink;
+	int trans_no_join;
 
 	u64 total_pinned;
 
@@ -1053,7 +1054,6 @@ struct btrfs_fs_info {
 	struct reloc_control *reloc_ctl;
 
 	spinlock_t delalloc_lock;
-	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
 
 	/* data_alloc_cluster is only used in ssd mode */

commit 712673339a0d085358fd1cd3a6477cc7979bb69f
Merge: aa2dfb372a2a 8628764e1a5e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 23 06:30:52 2011 -0400

    Merge branch 'for-chris' of git://git.kernel.org/pub/scm/linux/kernel/git/arne/btrfs-unstable-arne into inode_numbers
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/ctree.h
            fs/btrfs/volumes.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 945d8962ceee6bb273365d0bdf42f763225b290f
Merge: 0d0ca30f1809 4ea028859bbd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 22 12:33:42 2011 -0400

    Merge branch 'cleanups' of git://repo.or.cz/linux-2.6/btrfs-unstable into inode_numbers
    
    Conflicts:
            fs/btrfs/extent-tree.c
            fs/btrfs/free-space-cache.c
            fs/btrfs/inode.c
            fs/btrfs/tree-log.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit dcc6d073225b6b732a52477c91bd4edc9b4d5502
Merge: 0965537308ac 16cdcec736cd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 22 07:07:01 2011 -0400

    Merge branch 'delayed_inode' into inode_numbers
    
    Conflicts:
            fs/btrfs/inode.c
            fs/btrfs/ioctl.c
            fs/btrfs/transaction.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 16cdcec736cd214350cdb591bf1091f8beedefa0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Apr 22 18:12:22 2011 +0800

    btrfs: implement delayed inode items operation
    
    Changelog V5 -> V6:
    - Fix oom when the memory load is high, by storing the delayed nodes into the
      root's radix tree, and letting btrfs inodes go.
    
    Changelog V4 -> V5:
    - Fix the race on adding the delayed node to the inode, which is spotted by
      Chris Mason.
    - Merge Chris Mason's incremental patch into this patch.
    - Fix deadlock between readdir() and memory fault, which is reported by
      Itaru Kitayama.
    
    Changelog V3 -> V4:
    - Fix nested lock, which is reported by Itaru Kitayama, by updating space cache
      inode in time.
    
    Changelog V2 -> V3:
    - Fix the race between the delayed worker and the task which does delayed items
      balance, which is reported by Tsutomu Itoh.
    - Modify the patch address David Sterba's comment.
    - Fix the bug of the cpu recursion spinlock, reported by Chris Mason
    
    Changelog V1 -> V2:
    - break up the global rb-tree, use a list to manage the delayed nodes,
      which is created for every directory and file, and used to manage the
      delayed directory name index items and the delayed inode item.
    - introduce a worker to deal with the delayed nodes.
    
    Compare with Ext3/4, the performance of file creation and deletion on btrfs
    is very poor. the reason is that btrfs must do a lot of b+ tree insertions,
    such as inode item, directory name item, directory name index and so on.
    
    If we can do some delayed b+ tree insertion or deletion, we can improve the
    performance, so we made this patch which implemented delayed directory name
    index insertion/deletion and delayed inode update.
    
    Implementation:
    - introduce a delayed root object into the filesystem, that use two lists to
      manage the delayed nodes which are created for every file/directory.
      One is used to manage all the delayed nodes that have delayed items. And the
      other is used to manage the delayed nodes which is waiting to be dealt with
      by the work thread.
    - Every delayed node has two rb-tree, one is used to manage the directory name
      index which is going to be inserted into b+ tree, and the other is used to
      manage the directory name index which is going to be deleted from b+ tree.
    - introduce a worker to deal with the delayed operation. This worker is used
      to deal with the works of the delayed directory name index items insertion
      and deletion and the delayed inode update.
      When the delayed items is beyond the lower limit, we create works for some
      delayed nodes and insert them into the work queue of the worker, and then
      go back.
      When the delayed items is beyond the upper bound, we create works for all
      the delayed nodes that haven't been dealt with, and insert them into the work
      queue of the worker, and then wait for that the untreated items is below some
      threshold value.
    - When we want to insert a directory name index into b+ tree, we just add the
      information into the delayed inserting rb-tree.
      And then we check the number of the delayed items and do delayed items
      balance. (The balance policy is above.)
    - When we want to delete a directory name index from the b+ tree, we search it
      in the inserting rb-tree at first. If we look it up, just drop it. If not,
      add the key of it into the delayed deleting rb-tree.
      Similar to the delayed inserting rb-tree, we also check the number of the
      delayed items and do delayed items balance.
      (The same to inserting manipulation)
    - When we want to update the metadata of some inode, we cached the data of the
      inode into the delayed node. the worker will flush it into the b+ tree after
      dealing with the delayed insertion and deletion.
    - We will move the delayed node to the tail of the list after we access the
      delayed node, By this way, we can cache more delayed items and merge more
      inode updates.
    - If we want to commit transaction, we will deal with all the delayed node.
    - the delayed node will be freed when we free the btrfs inode.
    - Before we log the inode items, we commit all the directory name index items
      and the delayed inode update.
    
    I did a quick test by the benchmark tool[1] and found we can improve the
    performance of file creation by ~15%, and file deletion by ~20%.
    
    Before applying this patch:
    Create files:
            Total files: 50000
            Total time: 1.096108
            Average time: 0.000022
    Delete files:
            Total files: 50000
            Total time: 1.510403
            Average time: 0.000030
    
    After applying this patch:
    Create files:
            Total files: 50000
            Total time: 0.932899
            Average time: 0.000019
    Delete files:
            Total files: 50000
            Total time: 1.215732
            Average time: 0.000024
    
    [1] http://marc.info/?l=linux-btrfs&m=128212635122920&q=p3
    
    Many thanks for Kitayama-san's help!
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Reviewed-by: David Sterba <dave@jikos.cz>
    Tested-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Tested-by: Itaru Kitayama <kitayama@cl.bb4u.ne.jp>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f4b81de3ae2..5d25129d0116 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -869,6 +869,7 @@ struct btrfs_block_group_cache {
 struct reloc_control;
 struct btrfs_device;
 struct btrfs_fs_devices;
+struct btrfs_delayed_root;
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
 	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
@@ -895,7 +896,10 @@ struct btrfs_fs_info {
 	/* logical->physical extent mapping */
 	struct btrfs_mapping_tree mapping_tree;
 
-	/* block reservation for extent, checksum and root tree */
+	/*
+	 * block reservation for extent, checksum, root tree and
+	 * delayed dir index item
+	 */
 	struct btrfs_block_rsv global_block_rsv;
 	/* block reservation for delay allocation */
 	struct btrfs_block_rsv delalloc_block_rsv;
@@ -1022,6 +1026,7 @@ struct btrfs_fs_info {
 	 * for the sys_munmap function call path
 	 */
 	struct btrfs_workers fixup_workers;
+	struct btrfs_workers delayed_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
@@ -1079,6 +1084,8 @@ struct btrfs_fs_info {
 
 	/* filesystem state */
 	u64 fs_state;
+
+	struct btrfs_delayed_root *delayed_root;
 };
 
 /*
@@ -1161,6 +1168,11 @@ struct btrfs_root {
 	/* red-black tree that keeps track of in-memory inodes */
 	struct rb_root inode_tree;
 
+	/*
+	 * radix tree that keeps track of delayed nodes of every inode,
+	 * protected by inode_lock
+	 */
+	struct radix_tree_root delayed_nodes_tree;
 	/*
 	 * right now this just gets used so that a root has its own devid
 	 * for stat.  It may be used for more later
@@ -2099,6 +2111,13 @@ static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
 }
 
 /* extent-tree.c */
+static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_root *root,
+						 int num_items)
+{
+	return (root->leafsize + root->nodesize * (BTRFS_MAX_LEVEL - 1)) *
+		3 * num_items;
+}
+
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
@@ -2294,6 +2313,8 @@ void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
 void btrfs_set_path_blocking(struct btrfs_path *p);
+void btrfs_clear_path_blocking(struct btrfs_path *p,
+			       struct extent_buffer *held);
 void btrfs_unlock_up_safe(struct btrfs_path *p, int level);
 
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -2305,6 +2326,10 @@ static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 	return btrfs_del_items(trans, root, path, path->slots[0], 1);
 }
 
+int setup_items_for_insert(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, struct btrfs_path *path,
+			   struct btrfs_key *cpu_key, u32 *data_size,
+			   u32 total_data, u32 total_size, int nr);
 int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, void *data, u32 data_size);
 int btrfs_insert_some_items(struct btrfs_trans_handle *trans,
@@ -2368,7 +2393,7 @@ void btrfs_check_and_init_root_item(struct btrfs_root_item *item);
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, const char *name,
-			  int name_len, u64 dir,
+			  int name_len, struct inode *dir,
 			  struct btrfs_key *location, u8 type, u64 index);
 struct btrfs_dir_item *btrfs_lookup_dir_item(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,

commit 0965537308ac3b267ea16e731bd73870a51c53b8
Merge: 61c4f2c81c61 82d5902d9c68
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat May 21 09:27:38 2011 -0400

    Merge branch 'ino-alloc' of git://repo.or.cz/linux-btrfs-devel into inode_numbers
    
    Conflicts:
            fs/btrfs/free-space-cache.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 4ea028859bbdad34b84c9951fbb832ae10c6a96c
Author: David Sterba <dsterba@suse.cz>
Date:   Thu May 12 18:13:12 2011 +0200

    btrfs: use unsigned type for single bit bitfield
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e37d441617d2..343304dec6d1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -740,12 +740,12 @@ struct btrfs_space_info {
 	 */
 	unsigned long reservation_progress;
 
-	int full:1;		/* indicates that we cannot allocate any more
+	unsigned int full:1;	/* indicates that we cannot allocate any more
 				   chunks for this space */
-	int chunk_alloc:1;	/* set if we are allocating a chunk */
+	unsigned int chunk_alloc:1;	/* set if we are allocating a chunk */
 
-	int force_alloc;	/* set if we need to force a chunk alloc for
-				   this space */
+	unsigned int force_alloc;	/* set if we need to force a chunk
+					   alloc for this space */
 
 	struct list_head list;
 

commit 8628764e1a5e1998a42b9713e9edea7753653d01
Author: Arne Jansen <sensille@gmx.net>
Date:   Wed Mar 23 16:34:19 2011 +0100

    btrfs: add readonly flag
    
    setting the readonly flag prevents writes in case an error is detected
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b7373b14e4cd..ee904666b766 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2657,7 +2657,7 @@ void btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 
 /* scrub.c */
 int btrfs_scrub_dev(struct btrfs_root *root, u64 devid, u64 start, u64 end,
-		    struct btrfs_scrub_progress *progress);
+		    struct btrfs_scrub_progress *progress, int readonly);
 int btrfs_scrub_pause(struct btrfs_root *root);
 int btrfs_scrub_pause_super(struct btrfs_root *root);
 int btrfs_scrub_continue(struct btrfs_root *root);

commit 475f63874d739d7842a56da94687f18d583ae654
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Fri Mar 11 15:41:01 2011 +0100

    btrfs: new ioctls for scrub
    
    adds ioctls necessary to start and cancel scrubs, to get current
    progress and to get info about devices to be scrubbed.
    Note that the scrub is done per-device and that the ioctl only
    returns after the scrub for this devices is finished or has been
    canceled.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 31141ba6072d..b7373b14e4cd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -189,7 +189,6 @@ struct btrfs_mapping_tree {
 	struct extent_map_tree map_tree;
 };
 
-#define BTRFS_UUID_SIZE 16
 struct btrfs_dev_item {
 	/* the internal btrfs device id */
 	__le64 devid;
@@ -296,7 +295,6 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 		sizeof(struct btrfs_stripe) * (num_stripes - 1);
 }
 
-#define BTRFS_FSID_SIZE 16
 #define BTRFS_HEADER_FLAG_WRITTEN	(1ULL << 0)
 #define BTRFS_HEADER_FLAG_RELOC		(1ULL << 1)
 

commit a2de733c78fa7af51ba9670482fa7d392aa67c57
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Mar 8 14:14:00 2011 +0100

    btrfs: scrub
    
    This adds an initial implementation for scrub. It works quite
    straightforward. The usermode issues an ioctl for each device in the
    fs. For each device, it enumerates the allocated device chunks. For
    each chunk, the contained extents are enumerated and the data checksums
    fetched. The extents are read sequentially and the checksums verified.
    If an error occurs (checksum or EIO), a good copy is searched for. If
    one is found, the bad copy will be rewritten.
    All enumerations happen from the commit roots. During a transaction
    commit, the scrubs get paused and afterwards continue from the new
    roots.
    
    This commit is based on the series originally posted to linux-btrfs
    with some improvements that resulted from comments from David Sterba,
    Ilya Dryomov and Jan Schmidt.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e61fe1b6b8c..31141ba6072d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -23,6 +23,7 @@
 #include <linux/mm.h>
 #include <linux/highmem.h>
 #include <linux/fs.h>
+#include <linux/rwsem.h>
 #include <linux/completion.h>
 #include <linux/backing-dev.h>
 #include <linux/wait.h>
@@ -33,6 +34,7 @@
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"
+#include "ioctl.h"
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
@@ -510,6 +512,12 @@ struct btrfs_extent_item_v0 {
 /* use full backrefs for extent pointers in the block */
 #define BTRFS_BLOCK_FLAG_FULL_BACKREF	(1ULL << 8)
 
+/*
+ * this flag is only used internally by scrub and may be changed at any time
+ * it is only declared here to avoid collisions
+ */
+#define BTRFS_EXTENT_FLAG_SUPER		(1ULL << 48)
+
 struct btrfs_tree_block_info {
 	struct btrfs_disk_key key;
 	u8 level;
@@ -1077,6 +1085,17 @@ struct btrfs_fs_info {
 
 	void *bdev_holder;
 
+	/* private scrub information */
+	struct mutex scrub_lock;
+	atomic_t scrubs_running;
+	atomic_t scrub_pause_req;
+	atomic_t scrubs_paused;
+	atomic_t scrub_cancel_req;
+	wait_queue_head_t scrub_pause_wait;
+	struct rw_semaphore scrub_super_lock;
+	int scrub_workers_refcnt;
+	struct btrfs_workers scrub_workers;
+
 	/* filesystem state */
 	u64 fs_state;
 };
@@ -2472,8 +2491,8 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
-int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start,
-			     u64 end, struct list_head *list);
+int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
+			     struct list_head *list, int search_commit);
 /* inode.c */
 
 /* RHEL and EL kernels have a patch that renames PG_checked to FsMisc */
@@ -2637,4 +2656,18 @@ void btrfs_reloc_pre_snapshot(struct btrfs_trans_handle *trans,
 			      u64 *bytes_to_reserve);
 void btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
 			      struct btrfs_pending_snapshot *pending);
+
+/* scrub.c */
+int btrfs_scrub_dev(struct btrfs_root *root, u64 devid, u64 start, u64 end,
+		    struct btrfs_scrub_progress *progress);
+int btrfs_scrub_pause(struct btrfs_root *root);
+int btrfs_scrub_pause_super(struct btrfs_root *root);
+int btrfs_scrub_continue(struct btrfs_root *root);
+int btrfs_scrub_continue_super(struct btrfs_root *root);
+int btrfs_scrub_cancel(struct btrfs_root *root);
+int btrfs_scrub_cancel_dev(struct btrfs_root *root, struct btrfs_device *dev);
+int btrfs_scrub_cancel_devid(struct btrfs_root *root, u64 devid);
+int btrfs_scrub_progress(struct btrfs_root *root, u64 devid,
+			 struct btrfs_scrub_progress *progress);
+
 #endif

commit f2a97a9dbd86eb1ef956bdf20e05c507b32beb96
Author: David Sterba <dsterba@suse.cz>
Date:   Thu May 5 12:44:41 2011 +0200

    btrfs: remove all unused functions
    
    Remove static and global declarations and/or definitions. Reduces size
    of btrfs.ko by ~3.4kB.
    
      text    data     bss     dec     hex filename
    402081    7464     200  409745   64091 btrfs.ko.base
    398620    7144     200  405964   631cc btrfs.ko.remove-all
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b66216e636c2..e37d441617d2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1440,26 +1440,12 @@ static inline u64 btrfs_stripe_offset_nr(struct extent_buffer *eb,
 	return btrfs_stripe_offset(eb, btrfs_stripe_nr(c, nr));
 }
 
-static inline void btrfs_set_stripe_offset_nr(struct extent_buffer *eb,
-					     struct btrfs_chunk *c, int nr,
-					     u64 val)
-{
-	btrfs_set_stripe_offset(eb, btrfs_stripe_nr(c, nr), val);
-}
-
 static inline u64 btrfs_stripe_devid_nr(struct extent_buffer *eb,
 					 struct btrfs_chunk *c, int nr)
 {
 	return btrfs_stripe_devid(eb, btrfs_stripe_nr(c, nr));
 }
 
-static inline void btrfs_set_stripe_devid_nr(struct extent_buffer *eb,
-					     struct btrfs_chunk *c, int nr,
-					     u64 val)
-{
-	btrfs_set_stripe_devid(eb, btrfs_stripe_nr(c, nr), val);
-}
-
 /* struct btrfs_block_group_item */
 BTRFS_SETGET_STACK_FUNCS(block_group_used, struct btrfs_block_group_item,
 			 used, 64);
@@ -1517,14 +1503,6 @@ btrfs_inode_ctime(struct btrfs_inode_item *inode_item)
 	return (struct btrfs_timespec *)ptr;
 }
 
-static inline struct btrfs_timespec *
-btrfs_inode_otime(struct btrfs_inode_item *inode_item)
-{
-	unsigned long ptr = (unsigned long)inode_item;
-	ptr += offsetof(struct btrfs_inode_item, otime);
-	return (struct btrfs_timespec *)ptr;
-}
-
 BTRFS_SETGET_FUNCS(timespec_sec, struct btrfs_timespec, sec, 64);
 BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_timespec, nsec, 32);
 
@@ -1875,33 +1853,6 @@ static inline u8 *btrfs_header_chunk_tree_uuid(struct extent_buffer *eb)
 	return (u8 *)ptr;
 }
 
-static inline u8 *btrfs_super_fsid(struct extent_buffer *eb)
-{
-	unsigned long ptr = offsetof(struct btrfs_super_block, fsid);
-	return (u8 *)ptr;
-}
-
-static inline u8 *btrfs_header_csum(struct extent_buffer *eb)
-{
-	unsigned long ptr = offsetof(struct btrfs_header, csum);
-	return (u8 *)ptr;
-}
-
-static inline struct btrfs_node *btrfs_buffer_node(struct extent_buffer *eb)
-{
-	return NULL;
-}
-
-static inline struct btrfs_leaf *btrfs_buffer_leaf(struct extent_buffer *eb)
-{
-	return NULL;
-}
-
-static inline struct btrfs_header *btrfs_buffer_header(struct extent_buffer *eb)
-{
-	return NULL;
-}
-
 static inline int btrfs_is_leaf(struct extent_buffer *eb)
 {
 	return btrfs_header_level(eb) == 0;
@@ -2055,22 +2006,6 @@ static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 	return sb->s_fs_info;
 }
 
-static inline int btrfs_set_root_name(struct btrfs_root *root,
-				      const char *name, int len)
-{
-	/* if we already have a name just free it */
-	kfree(root->name);
-
-	root->name = kmalloc(len+1, GFP_KERNEL);
-	if (!root->name)
-		return -ENOMEM;
-
-	memcpy(root->name, name, len);
-	root->name[len] = '\0';
-
-	return 0;
-}
-
 static inline u32 btrfs_level_size(struct btrfs_root *root, int level)
 {
 	if (level == 0)
@@ -2304,11 +2239,6 @@ static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 
 int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, void *data, u32 data_size);
-int btrfs_insert_some_items(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root,
-			    struct btrfs_path *path,
-			    struct btrfs_key *cpu_key, u32 *data_size,
-			    int nr);
 int btrfs_insert_empty_items(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path,
@@ -2354,8 +2284,6 @@ int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
-int btrfs_search_root(struct btrfs_root *root, u64 search_start,
-		      u64 *found_objectid);
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);
 int btrfs_find_orphan_roots(struct btrfs_root *tree_root);
 int btrfs_set_root_node(struct btrfs_root_item *item,
@@ -2494,8 +2422,6 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
-int btrfs_start_one_delalloc_inode(struct btrfs_root *root, int delay_iput,
-				   int sync);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
 int btrfs_writepages(struct address_space *mapping,
@@ -2579,10 +2505,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 /* sysfs.c */
 int btrfs_init_sysfs(void);
 void btrfs_exit_sysfs(void);
-int btrfs_sysfs_add_super(struct btrfs_fs_info *fs);
-int btrfs_sysfs_add_root(struct btrfs_root *root);
-void btrfs_sysfs_del_root(struct btrfs_root *root);
-void btrfs_sysfs_del_super(struct btrfs_fs_info *root);
 
 /* xattr.c */
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);

commit 621496f4fd56195b7b273521f467c2945165481f
Author: David Sterba <dsterba@suse.cz>
Date:   Wed May 4 12:56:49 2011 +0200

    btrfs: remove unused function prototypes
    
    function prototypes without a body
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3f301f05099d..b66216e636c2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2108,12 +2108,9 @@ int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
 			     u64 num_bytes, u64 *refs, u64 *flags);
 int btrfs_pin_extent(struct btrfs_root *root,
 		     u64 bytenr, u64 num, int reserved);
-int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset, u64 bytenr);
-int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 struct btrfs_fs_info *info,
 						 u64 bytenr);
@@ -2463,15 +2460,10 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_ordered_sum *sums);
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig);
-int btrfs_csum_file_bytes(struct btrfs_root *root, struct inode *inode,
-			  u64 start, unsigned long len);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,
 					  u64 bytenr, int cow);
-int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root, struct btrfs_path *path,
-			u64 isize);
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start,
 			     u64 end, struct list_head *list);
 /* inode.c */
@@ -2520,7 +2512,6 @@ unsigned long btrfs_force_ra(struct address_space *mapping,
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_evict_inode(struct inode *inode);
-void btrfs_put_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
 void btrfs_dirty_inode(struct inode *inode);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
@@ -2531,8 +2522,6 @@ void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root, int *was_new);
-int btrfs_commit_write(struct file *file, struct page *page,
-		       unsigned from, unsigned to);
 struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
 				    size_t pg_offset, u64 start, u64 end,
 				    int create);
@@ -2571,7 +2560,6 @@ void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
 int btrfs_sync_file(struct file *file, int datasync);
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			    int skip_pinned);
-int btrfs_check_file(struct btrfs_root *root, struct inode *inode);
 extern const struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans, struct inode *inode,
 		       u64 start, u64 end, u64 *hint_byte, int drop_cache);

commit b3b4aa74b58bded927f579fff787fb6fa1c0393c
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 01:20:15 2011 +0200

    btrfs: drop unused parameter from btrfs_release_path
    
    parameter tree root it's not used since commit
    5f39d397dfbe140a14edecd4e73c34ce23c4f9ee ("Btrfs: Create extent_buffer
    interface for large blocksizes")
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b5433bbe7516..3f301f05099d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2290,7 +2290,7 @@ int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct extent_buffer *parent,
 		       int start_slot, int cache_only, u64 *last_ret,
 		       struct btrfs_key *progress);
-void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
+void btrfs_release_path(struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
 void btrfs_set_path_blocking(struct btrfs_path *p);

commit 306e16ce13c0f3d4fc071b45803b5b83c2606011
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 19 14:29:38 2011 +0200

    btrfs: rename variables clashing with global function names
    
    reported by gcc -Wshadow:
    page_index, page_offset, new_inode, dev_name
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f4b81de3ae2..b5433bbe7516 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2534,7 +2534,7 @@ struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 int btrfs_commit_write(struct file *file, struct page *page,
 		       unsigned from, unsigned to);
 struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
-				    size_t page_offset, u64 start, u64 end,
+				    size_t pg_offset, u64 start, u64 end,
 				    int create);
 int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,

commit e9c549998dc24209847007e1f209f3b6c88d21ba
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Tue Apr 26 23:28:26 2011 -0700

    Revert wrong fixes for common misspellings
    
    These changes were incorrectly fixed by codespell. They were now
    manually corrected.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e61fe1b6b8c..8f4b81de3ae2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -718,7 +718,7 @@ struct btrfs_space_info {
 	u64 total_bytes;	/* total bytes in the space,
 				   this doesn't take mirrors into account */
 	u64 bytes_used;		/* total bytes used,
-				   this does't take mirrors into account */
+				   this doesn't take mirrors into account */
 	u64 bytes_pinned;	/* total bytes pinned, will be freed when the
 				   transaction finishes */
 	u64 bytes_reserved;	/* total bytes the allocator has reserved for

commit 82d5902d9c681be37ffa9d70482907f9f0b7ec1f
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Apr 20 10:33:24 2011 +0800

    Btrfs: Support reading/writing on disk free ino cache
    
    This is similar to block group caching.
    
    We dedicate a special inode in fs tree to save free ino cache.
    
    At the very first time we create/delete a file after mount, the free ino
    cache will be loaded from disk into memory. When the fs tree is commited,
    the cache will be written back to disk.
    
    To keep compatibility, we check the root generation against the generation
    of the special inode when loading the cache, so the loading will fail
    if the btrfs filesystem was mounted in an older kernel before.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c96a4e4c5566..b20082e27a9f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -105,6 +105,12 @@ struct btrfs_ordered_sum;
 /* For storing free space cache */
 #define BTRFS_FREE_SPACE_OBJECTID -11ULL
 
+/*
+ * The inode number assigned to the special inode for sotring
+ * free ino cache
+ */
+#define BTRFS_FREE_INO_OBJECTID -12ULL
+
 /* dummy objectid represents multiple objectids */
 #define BTRFS_MULTIPLE_OBJECTIDS -255ULL
 
@@ -1110,6 +1116,7 @@ struct btrfs_root {
 	wait_queue_head_t cache_wait;
 	struct btrfs_free_space_ctl *free_ino_pinned;
 	u64 cache_progress;
+	struct inode *cache_inode;
 
 	struct mutex log_mutex;
 	wait_queue_head_t log_writer_wait;

commit 581bb050941b4f220f84d3e5ed6dace3d42dd382
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Apr 20 10:06:11 2011 +0800

    Btrfs: Cache free inode numbers in memory
    
    Currently btrfs stores the highest objectid of the fs tree, and it always
    returns (highest+1) inode number when we create a file, so inode numbers
    won't be reclaimed when we delete files, so we'll run out of inode numbers
    as we keep create/delete files in 32bits machines.
    
    This fixes it, and it works similarly to how we cache free space in block
    cgroups.
    
    We start a kernel thread to read the file tree. By scanning inode items,
    we know which chunks of inode numbers are free, and we cache them in
    an rb-tree.
    
    Because we are searching the commit root, we have to carefully handle the
    cross-transaction case.
    
    The rb-tree is a hybrid extent+bitmap tree, so if we have too many small
    chunks of inode numbers, we'll use bitmaps. Initially we allow 16K ram
    of extents, and a bitmap will be used if we exceed this threshold. The
    extents threshold is adjusted in runtime.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d17e4a3b8bf7..c96a4e4c5566 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1102,6 +1102,15 @@ struct btrfs_root {
 	spinlock_t accounting_lock;
 	struct btrfs_block_rsv *block_rsv;
 
+	/* free ino cache stuff */
+	struct mutex fs_commit_mutex;
+	struct btrfs_free_space_ctl *free_ino_ctl;
+	enum btrfs_caching_type cached;
+	spinlock_t cache_lock;
+	wait_queue_head_t cache_wait;
+	struct btrfs_free_space_ctl *free_ino_pinned;
+	u64 cache_progress;
+
 	struct mutex log_mutex;
 	wait_queue_head_t log_writer_wait;
 	wait_queue_head_t log_commit_wait[2];
@@ -2408,12 +2417,6 @@ int btrfs_del_orphan_item(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, u64 offset);
 int btrfs_find_orphan_item(struct btrfs_root *root, u64 offset);
 
-/* inode-map.c */
-int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *fs_root,
-			     u64 dirid, u64 *objectid);
-int btrfs_find_highest_inode(struct btrfs_root *fs_root, u64 *objectid);
-
 /* inode-item.c */
 int btrfs_insert_inode_ref(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,

commit 34d52cb6c50b5a43901709998f59fb1c5a43dc4a
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Mar 29 13:46:06 2011 +0800

    Btrfs: Make free space cache code generic
    
    So we can re-use the code to cache free inode numbers.
    
    The change is quite straightforward. Two new structures are introduced.
    
    - struct btrfs_free_space_ctl
    
      We move those variables that are used for caching free space from
      struct btrfs_block_group_cache to this new struct.
    
    - struct btrfs_free_space_op
    
      We do block group specific work (e.g. calculation of extents threshold)
      through functions registered in this struct.
    
    And then we can remove references to struct btrfs_block_group_cache.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2e61fe1b6b8c..d17e4a3b8bf7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -830,9 +830,6 @@ struct btrfs_block_group_cache {
 	u64 bytes_super;
 	u64 flags;
 	u64 sectorsize;
-	int extents_thresh;
-	int free_extents;
-	int total_bitmaps;
 	unsigned int ro:1;
 	unsigned int dirty:1;
 	unsigned int iref:1;
@@ -847,9 +844,7 @@ struct btrfs_block_group_cache {
 	struct btrfs_space_info *space_info;
 
 	/* free space cache stuff */
-	spinlock_t tree_lock;
-	struct rb_root free_space_offset;
-	u64 free_space;
+	struct btrfs_free_space_ctl *free_space_ctl;
 
 	/* block group cache stuff */
 	struct rb_node cache_node;

commit 6d74119f1a3efad9dc7f79a16c201242324b731f
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 11 20:20:11 2011 -0400

    Btrfs: avoid taking the chunk_mutex in do_chunk_alloc
    
    Everytime we try to allocate disk space we try and see if we can pre-emptively
    allocate a chunk, but in the common case we don't allocate anything, so there is
    no sense in taking the chunk_mutex at all.  So instead if we are allocating a
    chunk, mark it in the space_info so we don't get two people trying to allocate
    at the same time.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Reviewed-by: Liu Bo <liubo2009@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0d00a07b5b29..2e61fe1b6b8c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -740,8 +740,10 @@ struct btrfs_space_info {
 	 */
 	unsigned long reservation_progress;
 
-	int full;		/* indicates that we cannot allocate any more
+	int full:1;		/* indicates that we cannot allocate any more
 				   chunks for this space */
+	int chunk_alloc:1;	/* set if we are allocating a chunk */
+
 	int force_alloc;	/* set if we need to force a chunk alloc for
 				   this space */
 

commit be1a12a0dfed06cf1e62e35bf91620dc610a451a
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Apr 6 13:05:22 2011 -0400

    Btrfs: deal with the case that we run out of space in the cache
    
    Currently we don't handle running out of space in the cache, so to fix this we
    keep track of how far in the cache we are.  Then we only dirty the pages if we
    successfully modify all of them, otherwise if we have an error or run out of
    space we can just drop them and not worry about the vm writing them out.
    Thanks,
    
    Tested-by Johannes Hirte <johannes.hirte@fem.tu-ilmenau.de>
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3458b5725540..0d00a07b5b29 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2576,6 +2576,11 @@ int btrfs_drop_extents(struct btrfs_trans_handle *trans, struct inode *inode,
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);
+void btrfs_drop_pages(struct page **pages, size_t num_pages);
+int btrfs_dirty_pages(struct btrfs_root *root, struct inode *inode,
+		      struct page **pages, size_t num_pages,
+		      loff_t pos, size_t write_bytes,
+		      struct extent_state **cached);
 
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,

commit 08fe4db170b4193603d9d31f40ebaf652d07ac9c
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Mar 28 02:01:25 2011 +0000

    Btrfs: Fix uninitialized root flags for subvolumes
    
    root_item->flags and root_item->byte_limit are not initialized when
    a subvolume is created. This bug is not revealed until we added
    readonly snapshot support - now you mount a btrfs filesystem and you
    may find the subvolumes in it are readonly.
    
    To work around this problem, we steal a bit from root_item->inode_item->flags,
    and use it to indicate if those fields have been properly initialized.
    When we read a tree root from disk, we check if the bit is set, and if
    not we'll set the flag and initialize the two fields of the root item.
    
    Reported-by: Andreas Philipp <philipp.andreas@gmail.com>
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Tested-by: Andreas Philipp <philipp.andreas@gmail.com>
    cc: stable@kernel.org
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d47ce8307854..3458b5725540 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1284,6 +1284,8 @@ struct btrfs_root {
 #define BTRFS_INODE_DIRSYNC		(1 << 10)
 #define BTRFS_INODE_COMPRESS		(1 << 11)
 
+#define BTRFS_INODE_ROOT_ITEM_INIT	(1 << 31)
+
 /* some macros to generate set/get funcs for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple
  * one for u8:
@@ -2359,6 +2361,8 @@ int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);
 int btrfs_find_orphan_roots(struct btrfs_root *tree_root);
 int btrfs_set_root_node(struct btrfs_root_item *item,
 			struct extent_buffer *node);
+void btrfs_check_and_init_root_item(struct btrfs_root_item *item);
+
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, const char *name,

commit c59021f846881a957ac5afe456d0f59d6a517b61
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Mon Mar 7 02:13:14 2011 +0000

    Btrfs: fix OOPS of empty filesystem after balance
    
    btrfs will remove unused block groups after balance.
    When a empty filesystem is balanced, the block group with tag "DATA" may be
    dropped, and after umount and mount again, it will not find "DATA" space_info
    and lead to OOPS.
    So we initial the necessary space_infos(DATA, SYSTEM, METADATA) to avoid OOPS.
    
    Reported-by: Daniel J Blueman <daniel.blueman@gmail.com>
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 93a0191aded6..d47ce8307854 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2234,6 +2234,7 @@ int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root, u64 type);
 int btrfs_trim_fs(struct btrfs_root *root, struct fstrim_range *range);
 
+int btrfs_init_space_info(struct btrfs_fs_info *fs_info);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit f7039b1d5c32241f87a513e33120db36bf30264d
Author: Li Dongyang <lidongyang@novell.com>
Date:   Thu Mar 24 10:24:28 2011 +0000

    Btrfs: add btrfs_trim_fs() to handle FITRIM
    
    We take an free extent out from allocator, trim it, then put it back,
    but before we trim the block group, we should make sure the block group is
    cached, so plus a little change to make cache_block_group() run without a
    transaction.
    
    Signed-off-by: Li Dongyang <lidongyang@novell.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a18b7bc2b22c..93a0191aded6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2232,6 +2232,7 @@ int btrfs_error_discard_extent(struct btrfs_root *root, u64 bytenr,
 			       u64 num_bytes, u64 *actual_bytes);
 int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root, u64 type);
+int btrfs_trim_fs(struct btrfs_root *root, struct fstrim_range *range);
 
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,

commit 5378e60734f5b7bfe1b43dc191aaf6131c1befe7
Author: Li Dongyang <lidongyang@novell.com>
Date:   Thu Mar 24 10:24:27 2011 +0000

    Btrfs: adjust btrfs_discard_extent() return errors and trimmed bytes
    
    Callers of btrfs_discard_extent() should check if we are mounted with -o discard,
    as we want to make fitrim to work even the fs is not mounted with -o discard.
    Also we should use REQ_DISCARD to map the free extent to get a full mapping,
    last we only return errors if
    1. the error is not a EOPNOTSUPP
    2. no device supports discard
    
    Signed-off-by: Li Dongyang <lidongyang@novell.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9e21176cdf57..a18b7bc2b22c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2229,7 +2229,7 @@ u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
 int btrfs_error_unpin_extent_range(struct btrfs_root *root,
 				   u64 start, u64 end);
 int btrfs_error_discard_extent(struct btrfs_root *root, u64 bytenr,
-			       u64 num_bytes);
+			       u64 num_bytes, u64 *actual_bytes);
 int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root, u64 type);
 

commit b4d00d569a49fcef02195635dbf8d15904b1fb63
Author: Li Dongyang <lidongyang@novell.com>
Date:   Thu Mar 24 10:24:25 2011 +0000

    Btrfs: make update_reserved_bytes() public
    
    Make the function public as we should update the reserved extents calculations
    after taking out an extent for trimming.
    
    Signed-off-by: Li Dongyang <lidongyang@novell.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8302ecd4197f..9e21176cdf57 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2157,6 +2157,8 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      u64 root_objectid, u64 owner, u64 offset);
 
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_update_reserved_bytes(struct btrfs_block_group_cache *cache,
+				u64 num_bytes, int reserve, int sinfo);
 int btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,

commit 75e7cb7fe0c391561bd3af36515be3f3c64a04c6
Author: Liu Bo <liubo2009@cn.fujitsu.com>
Date:   Tue Mar 22 10:12:20 2011 +0000

    Btrfs: Per file/directory controls for COW and compression
    
    Data compression and data cow are controlled across the entire FS by mount
    options right now.  ioctls are needed to set this on a per file or per
    directory basis.  This has been proposed previously, but VFS developers
    wanted us to use generic ioctls rather than btrfs-specific ones.
    
    According to Chris's comment, there should be just one true compression
    method(probably LZO) stored in the super.  However, before this, we would
    wait for that one method is stable enough to be adopted into the super.
    So I list it as a long term goal, and just store it in ram today.
    
    After applying this patch, we can use the generic "FS_IOC_SETFLAGS" ioctl to
    control file and directory's datacow and compression attribute.
    
    NOTE:
     - The compression type is selected by such rules:
       If we mount btrfs with compress options, ie, zlib/lzo, the type is it.
       Otherwise, we'll use the default compress type (zlib today).
    
    v1->v2:
    - rebase to the latest btrfs.
    v2->v3:
    - fix a problem, i.e. when a file is set NOCOW via mount option, then this NOCOW
      will be screwed by inheritance from parent directory.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9d0f59142afa..8302ecd4197f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1282,6 +1282,7 @@ struct btrfs_root {
 #define BTRFS_INODE_NODUMP		(1 << 8)
 #define BTRFS_INODE_NOATIME		(1 << 9)
 #define BTRFS_INODE_DIRSYNC		(1 << 10)
+#define BTRFS_INODE_COMPRESS		(1 << 11)
 
 /* some macros to generate set/get funcs for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple

commit 1abe9b8a138c9988ba8f7bfded6453649a31541f
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Thu Mar 24 11:18:59 2011 +0000

    Btrfs: add initial tracepoint support for btrfs
    
    Tracepoints can provide insight into why btrfs hits bugs and be greatly
    helpful for debugging, e.g
                  dd-7822  [000]  2121.641088: btrfs_inode_request: root = 5(FS_TREE), gen = 4, ino = 256, blocks = 8, disk_i_size = 0, last_trans = 8, logged_trans = 0
                  dd-7822  [000]  2121.641100: btrfs_inode_new: root = 5(FS_TREE), gen = 8, ino = 257, blocks = 0, disk_i_size = 0, last_trans = 0, logged_trans = 0
     btrfs-transacti-7804  [001]  2146.935420: btrfs_cow_block: root = 2(EXTENT_TREE), refs = 2, orig_buf = 29368320 (orig_level = 0), cow_buf = 29388800 (cow_level = 0)
     btrfs-transacti-7804  [001]  2146.935473: btrfs_cow_block: root = 1(ROOT_TREE), refs = 2, orig_buf = 29364224 (orig_level = 0), cow_buf = 29392896 (cow_level = 0)
     btrfs-transacti-7804  [001]  2146.972221: btrfs_transaction_commit: root = 1(ROOT_TREE), gen = 8
       flush-btrfs-2-7821  [001]  2155.824210: btrfs_chunk_alloc: root = 3(CHUNK_TREE), offset = 1103101952, size = 1073741824, num_stripes = 1, sub_stripes = 0, type = DATA
       flush-btrfs-2-7821  [001]  2155.824241: btrfs_cow_block: root = 2(EXTENT_TREE), refs = 2, orig_buf = 29388800 (orig_level = 0), cow_buf = 29396992 (cow_level = 0)
       flush-btrfs-2-7821  [001]  2155.824255: btrfs_cow_block: root = 4(DEV_TREE), refs = 2, orig_buf = 29372416 (orig_level = 0), cow_buf = 29401088 (cow_level = 0)
       flush-btrfs-2-7821  [000]  2155.824329: btrfs_cow_block: root = 3(CHUNK_TREE), refs = 2, orig_buf = 20971520 (orig_level = 0), cow_buf = 20975616 (cow_level = 0)
     btrfs-endio-wri-7800  [001]  2155.898019: btrfs_cow_block: root = 5(FS_TREE), refs = 2, orig_buf = 29384704 (orig_level = 0), cow_buf = 29405184 (cow_level = 0)
     btrfs-endio-wri-7800  [001]  2155.898043: btrfs_cow_block: root = 7(CSUM_TREE), refs = 2, orig_buf = 29376512 (orig_level = 0), cow_buf = 29409280 (cow_level = 0)
    
    Here is what I have added:
    
    1) ordere_extent:
            btrfs_ordered_extent_add
            btrfs_ordered_extent_remove
            btrfs_ordered_extent_start
            btrfs_ordered_extent_put
    
    These provide critical information to understand how ordered_extents are
    updated.
    
    2) extent_map:
            btrfs_get_extent
    
    extent_map is used in both read and write cases, and it is useful for tracking
    how btrfs specific IO is running.
    
    3) writepage:
            __extent_writepage
            btrfs_writepage_end_io_hook
    
    Pages are cirtical resourses and produce a lot of corner cases during writeback,
    so it is valuable to know how page is written to disk.
    
    4) inode:
            btrfs_inode_new
            btrfs_inode_request
            btrfs_inode_evict
    
    These can show where and when a inode is created, when a inode is evicted.
    
    5) sync:
            btrfs_sync_file
            btrfs_sync_fs
    
    These show sync arguments.
    
    6) transaction:
            btrfs_transaction_commit
    
    In transaction based filesystem, it will be useful to know the generation and
    who does commit.
    
    7) back reference and cow:
            btrfs_delayed_tree_ref
            btrfs_delayed_data_ref
            btrfs_delayed_ref_head
            btrfs_cow_block
    
    Btrfs natively supports back references, these tracepoints are helpful on
    understanding btrfs's COW mechanism.
    
    8) chunk:
            btrfs_chunk_alloc
            btrfs_chunk_free
    
    Chunk is a link between physical offset and logical offset, and stands for space
    infomation in btrfs, and these are helpful on tracing space things.
    
    9) reserved_extent:
            btrfs_reserved_extent_alloc
            btrfs_reserved_extent_free
    
    These can show how btrfs uses its space.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0ee679b6c1b7..9d0f59142afa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -28,6 +28,7 @@
 #include <linux/wait.h>
 #include <linux/slab.h>
 #include <linux/kobject.h>
+#include <trace/events/btrfs.h>
 #include <asm/kmap_types.h>
 #include "extent_io.h"
 #include "extent_map.h"

commit 4e69b598f6cfb0940b75abf7e179d6020e94ad1e
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Mar 21 10:11:24 2011 -0400

    Btrfs: cleanup how we setup free space clusters
    
    This patch makes the free space cluster refilling code a little easier to
    understand, and fixes some things with the bitmap part of it.  Currently we
    either want to refill a cluster with
    
    1) All normal extent entries (those without bitmaps)
    2) A bitmap entry with enough space
    
    The current code has this ugly jump around logic that will first try and fill up
    the cluster with extent entries and then if it can't do that it will try and
    find a bitmap to use.  So instead split this out into two functions, one that
    tries to find only normal entries, and one that tries to find bitmaps.
    
    This also fixes a suboptimal thing we would do with bitmaps.  If we used a
    bitmap we would just tell the cluster that we were pointing at a bitmap and it
    would do the tree search in the block group for that entry every time we tried
    to make an allocation.  Instead of doing that now we just add it to the clusters
    group.
    
    I tested this with my ENOSPC tests and xfstests and it survived.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6036fdb88c53..0ee679b6c1b7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -783,9 +783,6 @@ struct btrfs_free_cluster {
 	/* first extent starting offset */
 	u64 window_start;
 
-	/* if this cluster simply points at a bitmap in the block group */
-	bool points_to_bitmap;
-
 	struct btrfs_block_group_cache *block_group;
 	/*
 	 * when a cluster is allocated from a block group, we put the

commit 22a94d44bd6876a90630338229da6c0436d46593
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Mar 16 16:47:17 2011 -0400

    Btrfs: add checks to verify dir items are correct
    
    We need to make sure the dir items we get are valid dir items.  So any time we
    try and read one check it with verify_dir_item, which will do various sanity
    checks to make sure it looks sane.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 841330f3d68d..6036fdb88c53 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2393,6 +2393,9 @@ struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
 					  struct btrfs_path *path, u64 dir,
 					  const char *name, u16 name_len,
 					  int mod);
+int verify_dir_item(struct btrfs_root *root,
+		    struct extent_buffer *leaf,
+		    struct btrfs_dir_item *dir_item);
 
 /* orphan.c */
 int btrfs_insert_orphan_item(struct btrfs_trans_handle *trans,

commit 66b4ffd110f9b48b8d8c1319ee446b53b8d073bf
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jan 31 16:22:42 2011 -0500

    Btrfs: handle errors in btrfs_orphan_cleanup
    
    If we cannot truncate an inode for some reason we will never delete the orphan
    item associated with that inode, which means that we will loop forever in
    btrfs_orphan_cleanup.  Instead of doing this just return error so we fail to
    mount.  It sucks, but hey it's better than hanging.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 34142d5647df..841330f3d68d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2529,7 +2529,7 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct inode *inode);
 int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
-void btrfs_orphan_cleanup(struct btrfs_root *root);
+int btrfs_orphan_cleanup(struct btrfs_root *root);
 void btrfs_orphan_pre_snapshot(struct btrfs_trans_handle *trans,
 				struct btrfs_pending_snapshot *pending,
 				u64 *bytes_to_reserve);

commit a41ad394a03b802497958d7c98a9dcf607266645
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jan 31 15:30:16 2011 -0500

    Btrfs: convert to the new truncate sequence
    
    ->truncate() is going away, instead all of the work needs to be done in
    ->setattr().  So this converts us over to do this.  It's fairly straightforward,
    just get rid of our .truncate inode operation and call btrfs_truncate() directly
    from btrfs_setsize.  This works out better for us since truncate can technically
    return ENOSPC, and before we had no way of letting anybody know.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2c98d209e6ac..34142d5647df 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2537,7 +2537,7 @@ void btrfs_orphan_post_snapshot(struct btrfs_trans_handle *trans,
 				struct btrfs_pending_snapshot *pending);
 void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root);
-int btrfs_cont_expand(struct inode *inode, loff_t size);
+int btrfs_cont_expand(struct inode *inode, loff_t oldsize, loff_t size);
 int btrfs_invalidate_inodes(struct btrfs_root *root);
 void btrfs_add_delayed_iput(struct inode *inode);
 void btrfs_run_delayed_iputs(struct btrfs_root *root);

commit dc89e9824464e91fa0b06267864ceabe3186fd8b
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Jan 28 17:05:48 2011 -0500

    Btrfs: use a slab for the free space entries
    
    Since we alloc/free free space entries a whole lot, lets use a slab to keep
    track of them.  This makes some of my tests slightly faster.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7f78cc78fdd0..2c98d209e6ac 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -40,6 +40,7 @@ extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
+extern struct kmem_cache *btrfs_free_space_cachep;
 struct btrfs_ordered_sum;
 
 #define BTRFS_MAGIC "_BHRfS_M"

commit 0e5b88cd9975dca6c191cc9bd11f233fac4ca882
Merge: eebea5d13d39 36e39c40b3fa
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Mar 13 16:00:49 2011 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: break out of shrink_delalloc earlier
      btrfs: fix not enough reserved space
      btrfs: fix dip leak
      Btrfs: make sure not to return overlapping extents to fiemap
      Btrfs: deal with short returns from copy_from_user
      Btrfs: fix regressions in copy_from_user handling

commit 36e39c40b3facc9b489a13f1d301fc53ff6960a3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Mar 12 07:08:42 2011 -0500

    Btrfs: break out of shrink_delalloc earlier
    
    Josef had changed shrink_delalloc to exit after three shrink
    attempts, which wasn't quite enough because new writers could
    race in and steal free space.
    
    But it also fixed deadlocks and stalls as we tried to recover
    delalloc reservations.  The code was tweaked to loop 1024
    times, and would reset the counter any time a small amount
    of progress was made.  This was too drastic, and with a
    lot of writers we can end up stuck in shrink_delalloc forever.
    
    The shrink_delalloc loop is fairly complex because the caller is looping
    too, and the caller will go ahead and force a transaction commit to make
    sure we reclaim space.
    
    This reworks things to exit shrink_delalloc when we've forced some
    writeback and the delalloc reservations have gone down.  This means
    the writeback has not just started but has also finished at
    least some of the metadata changes required to reclaim delalloc
    space.
    
    If we've got this wrong, we're returning ENOSPC too early, which
    is a big improvement over the current behavior of hanging the machine.
    
    Test 224 in xfstests hammers on this nicely, and with 1000 writers
    trying to fill a 1GB drive we get our first ENOSPC at 93% full.  The
    other writers are able to continue until we get 100%.
    
    This is a worst case test for btrfs because the 1000 writers are doing
    small IO, and the small FS size means we don't have a lot of room
    for metadata chunks.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 28188a786da0..8b4b9d158a0a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -729,6 +729,15 @@ struct btrfs_space_info {
 	u64 disk_total;		/* total bytes on disk, takes mirrors into
 				   account */
 
+	/*
+	 * we bump reservation progress every time we decrement
+	 * bytes_reserved.  This way people waiting for reservations
+	 * know something good has happened and they can check
+	 * for progress.  The number here isn't to be trusted, it
+	 * just shows reclaim activity
+	 */
+	unsigned long reservation_progress;
+
 	int full;		/* indicates that we cannot allocate any more
 				   chunks for this space */
 	int force_alloc;	/* set if we need to force a chunk alloc for

commit 4660ba63f1c4e07c20a435e084f12ba48a82bd2b
Merge: 958ede7f1b72 ec29ed5b407d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 25 14:03:39 2011 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: fix fiemap bugs with delalloc
      Btrfs: set FMODE_EXCL in btrfs_device->mode
      Btrfs: make btrfs_rm_device() fail gracefully
      Btrfs: Avoid accessing unmapped kernel address
      Btrfs: Fix BTRFS_IOC_SUBVOL_SETFLAGS ioctl
      Btrfs: allow balance to explicitly allocate chunks as it relocates
      Btrfs: put ENOSPC debugging under a mount option

commit c87f08ca44e83b2c8d28f63f9c33f3a270a04bbe
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 16 13:57:04 2011 -0500

    Btrfs: allow balance to explicitly allocate chunks as it relocates
    
    Btrfs device shrinking and balancing ends up reallocating all the blocks
    in order to allow COW to move them to new destinations.  It is somewhat
    awkward in terms of ENOSPC because most of the enospc code is built
    around the idea that some operation on a reference counted tree triggers
    allocations in the non-reference counted trees.
    
    This commit changes the balancing code to deal with enospc by trying to
    allocate a new chunk.  If that allocation succeeds, we go ahead and
    retry whatever failed due to enospc.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6297701bc19c..28188a786da0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2219,6 +2219,8 @@ int btrfs_error_unpin_extent_range(struct btrfs_root *root,
 				   u64 start, u64 end);
 int btrfs_error_discard_extent(struct btrfs_root *root, u64 bytenr,
 			       u64 num_bytes);
+int btrfs_force_chunk_alloc(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root, u64 type);
 
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,

commit 91435650c233b93e0da389db74f4b2c11c5ad2d4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 16 13:10:41 2011 -0500

    Btrfs: put ENOSPC debugging under a mount option
    
    ENOSPC in btrfs is getting to the point where the extra debugging isn't
    required.  I've put it under mount -o enospc_debug just in case someone
    is having difficult problems.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 72195378bef9..6297701bc19c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1254,6 +1254,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_SPACE_CACHE		(1 << 12)
 #define BTRFS_MOUNT_CLEAR_CACHE		(1 << 13)
 #define BTRFS_MOUNT_USER_SUBVOL_RM_ALLOWED (1 << 14)
+#define BTRFS_MOUNT_ENOSPC_DEBUG	 (1 << 15)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit eee2a817df7c5a6e569f353f8be78cc1b3604bb6
Merge: 83896fb5e515 acce952b0263
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 17 14:43:43 2011 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (25 commits)
      Btrfs: forced readonly mounts on errors
      btrfs: Require CAP_SYS_ADMIN for filesystem rebalance
      Btrfs: don't warn if we get ENOSPC in btrfs_block_rsv_check
      btrfs: Fix memory leak in btrfs_read_fs_root_no_radix()
      btrfs: check NULL or not
      btrfs: Don't pass NULL ptr to func that may deref it.
      btrfs: mount failure return value fix
      btrfs: Mem leak in btrfs_get_acl()
      btrfs: fix wrong free space information of btrfs
      btrfs: make the chunk allocator utilize the devices better
      btrfs: restructure find_free_dev_extent()
      btrfs: fix wrong calculation of stripe size
      btrfs: try to reclaim some space when chunk allocation fails
      btrfs: fix wrong data space statistics
      fs/btrfs: Fix build of ctree
      Btrfs: fix off by one while setting block groups readonly
      Btrfs: Add BTRFS_IOC_SUBVOL_GETFLAGS/SETFLAGS ioctls
      Btrfs: Add readonly snapshots support
      Btrfs: Refactor btrfs_ioctl_snap_create()
      btrfs: Extract duplicate decompress code
      ...

commit acce952b0263825da32cf10489413dec78053347
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Thu Jan 6 19:30:25 2011 +0800

    Btrfs: forced readonly mounts on errors
    
    This patch comes from "Forced readonly mounts on errors" ideas.
    
    As we know, this is the first step in being more fault tolerant of disk
    corruptions instead of just using BUG() statements.
    
    The major content:
    - add a framework for generating errors that should result in filesystems
      going readonly.
    - keep FS state in disk super block.
    - make sure that all of resource will be freed and released at umount time.
    - make sure that fter FS is forced readonly on error, there will be no more
      disk change before FS is corrected. For this, we should stop write operation.
    
    After this patch is applied, the conversion from BUG() to such a framework can
    happen incrementally.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0995f4f68d7a..72195378bef9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -295,6 +295,14 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 #define BTRFS_FSID_SIZE 16
 #define BTRFS_HEADER_FLAG_WRITTEN	(1ULL << 0)
 #define BTRFS_HEADER_FLAG_RELOC		(1ULL << 1)
+
+/*
+ * File system states
+ */
+
+/* Errors detected */
+#define BTRFS_SUPER_FLAG_ERROR		(1ULL << 2)
+
 #define BTRFS_SUPER_FLAG_SEEDING	(1ULL << 32)
 #define BTRFS_SUPER_FLAG_METADUMP	(1ULL << 33)
 
@@ -1058,6 +1066,9 @@ struct btrfs_fs_info {
 	unsigned metadata_ratio;
 
 	void *bdev_holder;
+
+	/* filesystem state */
+	u64 fs_state;
 };
 
 /*
@@ -2203,6 +2214,11 @@ int btrfs_set_block_group_rw(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
+int btrfs_error_unpin_extent_range(struct btrfs_root *root,
+				   u64 start, u64 end);
+int btrfs_error_discard_extent(struct btrfs_root *root, u64 bytenr,
+			       u64 num_bytes);
+
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);
@@ -2556,6 +2572,14 @@ ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 /* super.c */
 int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
+void __btrfs_std_error(struct btrfs_fs_info *fs_info, const char *function,
+		     unsigned int line, int errno);
+
+#define btrfs_std_error(fs_info, errno)				\
+do {								\
+	if ((errno))						\
+		__btrfs_std_error((fs_info), __func__, __LINE__, (errno));\
+} while (0)
 
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL

commit f8b18087fd3277e424a24e13ce0edf30abe97ce0
Author: Stefan Schmidt <stefan@datenfreihafen.org>
Date:   Wed Jan 12 10:30:42 2011 +0100

    fs/btrfs: Fix build of ctree
    
    Fix the build failure in some configurations:
    
         CC [M]  fs/btrfs/ctree.o
      In file included from fs/btrfs/ctree.c:21:0:
      fs/btrfs/ctree.h:1003:17: error: field 'super_kobj' has incomplete type
      fs/btrfs/ctree.h:1074:17: error: field 'root_kobj' has incomplete type
      make[2]: *** [fs/btrfs/ctree.o] Error 1
      make[1]: *** [fs/btrfs] Error 2
      make: *** [fs] Error 2
    
    caused by commit 57cc7215b708 ("headers: kobject.h redux")
    
    We need to include kobject.h here.
    
    Reported-by: Jeff Garzik <jeff@garzik.org>
    Fix-suggested-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a142d204b526..b875d445ea81 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -27,6 +27,7 @@
 #include <linux/backing-dev.h>
 #include <linux/wait.h>
 #include <linux/slab.h>
+#include <linux/kobject.h>
 #include <asm/kmap_types.h>
 #include "extent_io.h"
 #include "extent_map.h"

commit 6d07bcec969af335d4e35b3921131b7929bd634e
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Jan 5 10:07:31 2011 +0000

    btrfs: fix wrong free space information of btrfs
    
    When we store data by raid profile in btrfs with two or more different size
    disks, df command shows there is some free space in the filesystem, but the
    user can not write any data in fact, df command shows the wrong free space
    information of btrfs.
    
     # mkfs.btrfs -d raid1 /dev/sda9 /dev/sda10
     # btrfs-show
     Label: none  uuid: a95cd49e-6e33-45b8-8741-a36153ce4b64
            Total devices 2 FS bytes used 28.00KB
            devid    1 size 5.01GB used 2.03GB path /dev/sda9
            devid    2 size 10.00GB used 2.01GB path /dev/sda10
     # btrfs device scan /dev/sda9 /dev/sda10
     # mount /dev/sda9 /mnt
     # dd if=/dev/zero of=tmpfile0 bs=4K count=9999999999
       (fill the filesystem)
     # sync
     # df -TH
     Filesystem     Type    Size    Used    Avail   Use%    Mounted on
     /dev/sda9      btrfs   17G     8.6G    5.4G    62%     /mnt
     # btrfs-show
     Label: none  uuid: a95cd49e-6e33-45b8-8741-a36153ce4b64
            Total devices 2 FS bytes used 3.99GB
            devid    1 size 5.01GB used 5.01GB path /dev/sda9
            devid    2 size 10.00GB used 4.99GB path /dev/sda10
    
    It is because btrfs cannot allocate chunks when one of the pairing disks has
    no space, the free space on the other disks can not be used for ever, and should
    be subtracted from the total space, but btrfs doesn't subtract this space from
    the total. It is strange to the user.
    
    This patch fixes it by calcing the free space that can be used to allocate
    chunks.
    
    Implementation:
    1. get all the devices free space, and align them by stripe length.
    2. sort the devices by the free space.
    3. check the free space of the devices,
       3.1. if it is not zero, and then check the number of the devices that has
            more free space than this device,
            if the number of the devices is beyond the min stripe number, the free
            space can be used, and add into total free space.
            if the number of the devices is below the min stripe number, we can not
            use the free space, the check ends.
       3.2. if the free space is zero, check the next devices, goto 3.1
    
    This implementation is just likely fake chunk allocation.
    
    After appling this patch, df can show correct space information:
     # df -TH
     Filesystem     Type    Size    Used    Avail   Use%    Mounted on
     /dev/sda9      btrfs   17G     8.6G    0       100%    /mnt
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0cb322cc4fc0..0995f4f68d7a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2158,6 +2158,7 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
+u64 btrfs_get_alloc_profile(struct btrfs_root *root, int data);
 void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 int btrfs_check_data_free_space(struct inode *inode, u64 bytes);
@@ -2201,6 +2202,7 @@ int btrfs_set_block_group_ro(struct btrfs_root *root,
 int btrfs_set_block_group_rw(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
 void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
+u64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit f580eb0931fbcb6dc3916f094f471671facd1daa
Author: Stefan Schmidt <stefan@datenfreihafen.org>
Date:   Wed Jan 12 09:30:42 2011 +0000

    fs/btrfs: Fix build of ctree
    
    CC [M]  fs/btrfs/ctree.o
    In file included from fs/btrfs/ctree.c:21:0:
    fs/btrfs/ctree.h:1003:17: error: field <91>super_kobj<92> has incomplete type
    fs/btrfs/ctree.h:1074:17: error: field <91>root_kobj<92> has incomplete type
    make[2]: *** [fs/btrfs/ctree.o] Error 1
    make[1]: *** [fs/btrfs] Error 2
    make: *** [fs] Error 2
    
    We need to include kobject.h here.
    
    Reported-by: Jeff Garzik <jeff@garzik.org>
    Fix-suggested-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4acd4c611efa..0cb322cc4fc0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -27,6 +27,7 @@
 #include <linux/backing-dev.h>
 #include <linux/wait.h>
 #include <linux/slab.h>
+#include <linux/kobject.h>
 #include <asm/kmap_types.h>
 #include "extent_io.h"
 #include "extent_map.h"

commit f892436eb2c3223fecda614a64d51f36f6ec2245
Merge: 26c79f6ba0cc 3a39c18d63fe
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Jan 16 11:25:54 2011 -0500

    Merge branch 'lzo-support' of git://repo.or.cz/linux-btrfs-devel into btrfs-38

commit b74c79e99389cd79b31fcc08f82c24e492e63c7e
Author: Nick Piggin <npiggin@kernel.dk>
Date:   Fri Jan 7 17:49:58 2011 +1100

    fs: provide rcu-walk aware permission i_ops
    
    Signed-off-by: Nick Piggin <npiggin@kernel.dk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index af52f6d7a4d8..a142d204b526 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2544,7 +2544,7 @@ int btrfs_sync_fs(struct super_block *sb, int wait);
 
 /* acl.c */
 #ifdef CONFIG_BTRFS_FS_POSIX_ACL
-int btrfs_check_acl(struct inode *inode, int mask);
+int btrfs_check_acl(struct inode *inode, int mask, unsigned int flags);
 #else
 #define btrfs_check_acl NULL
 #endif

commit b83cc9693f39689490970c19f6c5b866f6719a70
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Dec 20 16:04:08 2010 +0800

    Btrfs: Add readonly snapshots support
    
    Usage:
    
    Set BTRFS_SUBVOL_RDONLY of btrfs_ioctl_vol_arg_v2->flags, and call
    ioctl(BTRFS_I0CTL_SNAP_CREATE_V2).
    
    Implementation:
    
    - Set readonly bit of btrfs_root_item->flags.
    - Add readonly checks in btrfs_permission (inode_permission),
    btrfs_setattr, btrfs_set/remove_xattr and some ioctls.
    
    Changelog for v3:
    
    - Eliminate btrfs_root->readonly, but check btrfs_root->root_item.flags.
    - Rename BTRFS_ROOT_SNAP_RDONLY to BTRFS_ROOT_SUBVOL_RDONLY.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index af52f6d7a4d8..4403e5643d43 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -597,6 +597,8 @@ struct btrfs_dir_item {
 	u8 type;
 } __attribute__ ((__packed__));
 
+#define BTRFS_ROOT_SUBVOL_RDONLY	(1ULL << 0)
+
 struct btrfs_root_item {
 	struct btrfs_inode_item inode;
 	__le64 generation;
@@ -1893,6 +1895,11 @@ BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, byte_limit, 64);
 BTRFS_SETGET_STACK_FUNCS(root_last_snapshot, struct btrfs_root_item,
 			 last_snapshot, 64);
 
+static inline bool btrfs_root_readonly(struct btrfs_root *root)
+{
+	return root->root_item.flags & BTRFS_ROOT_SUBVOL_RDONLY;
+}
+
 /* struct btrfs_super_block */
 
 BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);

commit a6fa6fae40ec336c7df6155255ae64ebef43a8bc
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Oct 25 15:12:26 2010 +0800

    btrfs: Add lzo compression support
    
    Lzo is a much faster compression algorithm than gzib, so would allow
    more users to enable transparent compression, and some users can
    choose from compression ratio and speed for different applications
    
    Usage:
    
     # mount -t btrfs -o compress[=<zlib,lzo>] dev /mnt
    or
     # mount -t btrfs -o compress-force[=<zlib,lzo>] dev /mnt
    
    "-o compress" without argument is still allowed for compatability.
    
    Compatibility:
    
    If we mount a filesystem with lzo compression, it will not be able be
    mounted in old kernels. One reason is, otherwise btrfs will directly
    dump compressed data, which sits in inline extent, to user.
    
    Performance:
    
    The test copied a linux source tarball (~400M) from an ext4 partition
    to the btrfs partition, and then extracted it.
    
    (time in second)
               lzo        zlib        nocompress
    copy:      10.6       21.7        14.9
    extract:   70.1       94.4        66.6
    
    (data size in MB)
               lzo        zlib        nocompress
    copy:      185.87     108.69      394.49
    extract:   193.80     132.36      381.21
    
    Changelog:
    
    v1 -> v2:
    - Select LZO_COMPRESS and LZO_DECOMPRESS in btrfs Kconfig.
    - Add incompability flag.
    - Fix error handling in compress code.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e06534438592..53b984623983 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -398,13 +398,15 @@ struct btrfs_super_block {
 #define BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF	(1ULL << 0)
 #define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(1ULL << 1)
 #define BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS	(1ULL << 2)
+#define BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO	(1ULL << 3)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
 #define BTRFS_FEATURE_INCOMPAT_SUPP			\
 	(BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF |		\
 	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL |	\
-	 BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS)
+	 BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS |		\
+	 BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO)
 
 /*
  * A leaf is full of items. offset and size tell us where to find
@@ -553,8 +555,9 @@ struct btrfs_timespec {
 enum btrfs_compression_type {
 	BTRFS_COMPRESS_NONE  = 0,
 	BTRFS_COMPRESS_ZLIB  = 1,
-	BTRFS_COMPRESS_TYPES = 1,
-	BTRFS_COMPRESS_LAST  = 2,
+	BTRFS_COMPRESS_LZO   = 2,
+	BTRFS_COMPRESS_TYPES = 2,
+	BTRFS_COMPRESS_LAST  = 3,
 };
 
 struct btrfs_inode_item {

commit 261507a02ccba9afda919852263b6bc1581ce1ef
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Dec 17 14:21:50 2010 +0800

    btrfs: Allow to add new compression algorithm
    
    Make the code aware of compression type, instead of always assuming
    zlib compression.
    
    Also make the zlib workspace function as common code for all
    compression types.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index af52f6d7a4d8..e06534438592 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -551,9 +551,10 @@ struct btrfs_timespec {
 } __attribute__ ((__packed__));
 
 enum btrfs_compression_type {
-	BTRFS_COMPRESS_NONE = 0,
-	BTRFS_COMPRESS_ZLIB = 1,
-	BTRFS_COMPRESS_LAST = 2,
+	BTRFS_COMPRESS_NONE  = 0,
+	BTRFS_COMPRESS_ZLIB  = 1,
+	BTRFS_COMPRESS_TYPES = 1,
+	BTRFS_COMPRESS_LAST  = 2,
 };
 
 struct btrfs_inode_item {
@@ -895,7 +896,8 @@ struct btrfs_fs_info {
 	 */
 	u64 last_trans_log_full_commit;
 	u64 open_ioctl_trans;
-	unsigned long mount_opt;
+	unsigned long mount_opt:20;
+	unsigned long compress_type:4;
 	u64 max_inline;
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;

commit 0410c94aff109c02b6774a0ed00114987cda7ce5
Author: Mariusz Kozlowski <mk@lab.zgora.pl>
Date:   Sat Nov 20 12:03:07 2010 +0000

    btrfs: make 1-bit signed fileds unsigned
    
    Fixes these sparse warnings:
    fs/btrfs/ctree.h:811:17: error: dubious one-bit signed bitfield
    fs/btrfs/ctree.h:812:20: error: dubious one-bit signed bitfield
    fs/btrfs/ctree.h:813:19: error: dubious one-bit signed bitfield
    
    Signed-off-by: Mariusz Kozlowski <mk@lab.zgora.pl>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8db9234f6b41..af52f6d7a4d8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -808,9 +808,9 @@ struct btrfs_block_group_cache {
 	int extents_thresh;
 	int free_extents;
 	int total_bitmaps;
-	int ro:1;
-	int dirty:1;
-	int iref:1;
+	unsigned int ro:1;
+	unsigned int dirty:1;
+	unsigned int iref:1;
 
 	int disk_cache_state;
 

commit 4260f7c7516f4c209cf0ca34fda99cc9a0847772
Author: Sage Weil <sage@newdream.net>
Date:   Fri Oct 29 15:46:43 2010 -0400

    Btrfs: allow subvol deletion by unprivileged user with -o user_subvol_rm_allowed
    
    Add a mount option user_subvol_rm_allowed that allows users to delete a
    (potentially non-empty!) subvol when they would otherwise we allowed to do
    an rmdir(2).  We duplicate the may_delete() checks from the core VFS code
    to implement identical security checks (minus the directory size check).
    We additionally require that the user has write+exec permission on the
    subvol root inode.
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e5d66b13c175..8db9234f6b41 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1234,6 +1234,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_FORCE_COMPRESS      (1 << 11)
 #define BTRFS_MOUNT_SPACE_CACHE		(1 << 12)
 #define BTRFS_MOUNT_CLEAR_CACHE		(1 << 13)
+#define BTRFS_MOUNT_USER_SUBVOL_RM_ALLOWED (1 << 14)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit bb9c12c945cbd1b0eaa1589546dde772ccabeeba
Author: Sage Weil <sage@newdream.net>
Date:   Fri Oct 29 15:37:34 2010 -0400

    Btrfs: async transaction commit
    
    Add support for an async transaction commit that is ordered such that any
    subsequent operations will join the following transaction, but does not
    wait until the current commit is fully on disk.  This avoids much of the
    latency associated with the btrfs_commit_transaction for callers concerned
    with serialization and not safety.
    
    The wait_for_unblock flag controls whether we wait for the 'middle' portion
    of commit_transaction to complete, which is necessary if the caller expects
    some of the modifications contained in the commit to be available (this is
    the case for subvol/snapshot creation).
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 88c0fb7e12d2..e5d66b13c175 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -901,6 +901,7 @@ struct btrfs_fs_info {
 	struct btrfs_transaction *running_transaction;
 	wait_queue_head_t transaction_throttle;
 	wait_queue_head_t transaction_wait;
+	wait_queue_head_t transaction_blocked_wait;
 	wait_queue_head_t async_submit_wait;
 
 	struct btrfs_super_block super_copy;

commit 6b5b817f103450444f3f658a498f435d92a197e5
Merge: 8216ef866df1 e9bb7f10d361
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Oct 29 09:27:49 2010 -0400

    Merge branch 'bug-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/josef/btrfs-work
    
    Conflicts:
            fs/btrfs/extent-tree.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 88c2ba3b069f1e0f4694124d02985fa7620a19f1
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Sep 21 14:21:34 2010 -0400

    Btrfs: Add a clear_cache mount option
    
    If something goes wrong with the free space cache we need a way to make sure
    it's not loaded on mount and that it's cleared for everybody.  When you pass the
    clear_cache option it will make it so all block groups are setup to be cleared,
    which keeps them from being loaded and then they will be truncated when the
    transaction is committed.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b155a0e49eeb..633e559e000e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1229,6 +1229,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_DISCARD		(1 << 10)
 #define BTRFS_MOUNT_FORCE_COMPRESS      (1 << 11)
 #define BTRFS_MOUNT_SPACE_CACHE		(1 << 12)
+#define BTRFS_MOUNT_CLEAR_CACHE		(1 << 13)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 67377734fd24c32cbdfeb697c2e2bd7fed519e75
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Sep 16 16:19:09 2010 -0400

    Btrfs: add support for mixed data+metadata block groups
    
    There are just a few things that need to be fixed in the kernel to support mixed
    data+metadata block groups.  Mostly we just need to make sure that if we are
    using mixed block groups that we continue to allocate mixed block groups as we
    need them.  Also we need to make sure __find_space_info will find our space info
    if we search for DATA or METADATA only.  Tested this with xfstests and it works
    nicely.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2c06b37cda75..b155a0e49eeb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -397,12 +397,14 @@ struct btrfs_super_block {
  */
 #define BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF	(1ULL << 0)
 #define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(1ULL << 1)
+#define BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS	(1ULL << 2)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
 #define BTRFS_FEATURE_INCOMPAT_SUPP			\
 	(BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF |		\
-	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL)
+	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL |	\
+	 BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS)
 
 /*
  * A leaf is full of items. offset and size tell us where to find
@@ -2046,6 +2048,12 @@ static inline struct dentry *fdentry(struct file *file)
 	return file->f_path.dentry;
 }
 
+static inline bool btrfs_mixed_space_info(struct btrfs_space_info *space_info)
+{
+	return ((space_info->flags & BTRFS_BLOCK_GROUP_METADATA) &&
+		(space_info->flags & BTRFS_BLOCK_GROUP_DATA));
+}
+
 /* extent-tree.c */
 void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,

commit 0cb59c9953171e9adf6da8142a5c85ceb77bb60d
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Jul 2 12:14:14 2010 -0400

    Btrfs: write out free space cache
    
    This is a simple bit, just dump the free space cache out to our preallocated
    inode when we're writing out dirty block groups.  There are a bunch of changes
    in inode.c in order to account for special cases.  Mostly when we're doing the
    writeout we're holding trans_mutex, so we need to use the nolock transacation
    functions.  Also we can't do asynchronous completions since the async thread
    could be blocked on already completed IO waiting for the transaction lock.  This
    has been tested with xfstests and btrfs filesystem balance, as well as my ENOSPC
    tests.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 46f52e1beade..2c06b37cda75 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -982,6 +982,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers endio_meta_workers;
 	struct btrfs_workers endio_meta_write_workers;
 	struct btrfs_workers endio_write_workers;
+	struct btrfs_workers endio_freespace_worker;
 	struct btrfs_workers submit_workers;
 	/*
 	 * fixup workers take dirty pages that didn't properly go through

commit 0af3d00bad38d3bb9912a60928ad0669f17bdb76
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jun 21 14:48:16 2010 -0400

    Btrfs: create special free space cache inode
    
    In order to save free space cache, we need an inode to hold the data, and we
    need a special item to point at the right inode for the right block group.  So
    first, create a special item that will point to the right inode, and the number
    of extent entries we will have and the number of bitmaps we will have.  We
    truncate and pre-allocate space everytime to make sure it's uptodate.
    
    This feature will be turned on as soon as you mount with -o space_cache, however
    it is safe to boot into old kernels, they will just generate the cache the old
    fashion way.  When you boot back into a newer kernel we will notice that we
    modified and not the cache and automatically discard the cache.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index eaf286abad17..46f52e1beade 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -99,6 +99,9 @@ struct btrfs_ordered_sum;
  */
 #define BTRFS_EXTENT_CSUM_OBJECTID -10ULL
 
+/* For storing free space cache */
+#define BTRFS_FREE_SPACE_OBJECTID -11ULL
+
 /* dummy objectid represents multiple objectids */
 #define BTRFS_MULTIPLE_OBJECTIDS -255ULL
 
@@ -265,6 +268,22 @@ struct btrfs_chunk {
 	/* additional stripes go here */
 } __attribute__ ((__packed__));
 
+#define BTRFS_FREE_SPACE_EXTENT	1
+#define BTRFS_FREE_SPACE_BITMAP	2
+
+struct btrfs_free_space_entry {
+	__le64 offset;
+	__le64 bytes;
+	u8 type;
+} __attribute__ ((__packed__));
+
+struct btrfs_free_space_header {
+	struct btrfs_disk_key location;
+	__le64 generation;
+	__le64 num_entries;
+	__le64 num_bitmaps;
+} __attribute__ ((__packed__));
+
 static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 {
 	BUG_ON(num_stripes == 0);
@@ -365,8 +384,10 @@ struct btrfs_super_block {
 
 	char label[BTRFS_LABEL_SIZE];
 
+	__le64 cache_generation;
+
 	/* future expansion */
-	__le64 reserved[32];
+	__le64 reserved[31];
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 } __attribute__ ((__packed__));
 
@@ -375,12 +396,12 @@ struct btrfs_super_block {
  * ones specified below then we will fail to mount
  */
 #define BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF	(1ULL << 0)
-#define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(2ULL << 0)
+#define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(1ULL << 1)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
-#define BTRFS_FEATURE_INCOMPAT_SUPP		\
-	(BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF |	\
+#define BTRFS_FEATURE_INCOMPAT_SUPP			\
+	(BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF |		\
 	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL)
 
 /*
@@ -750,6 +771,14 @@ enum btrfs_caching_type {
 	BTRFS_CACHE_FINISHED	= 2,
 };
 
+enum btrfs_disk_cache_state {
+	BTRFS_DC_WRITTEN	= 0,
+	BTRFS_DC_ERROR		= 1,
+	BTRFS_DC_CLEAR		= 2,
+	BTRFS_DC_SETUP		= 3,
+	BTRFS_DC_NEED_WRITE	= 4,
+};
+
 struct btrfs_caching_control {
 	struct list_head list;
 	struct mutex mutex;
@@ -763,6 +792,7 @@ struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
 	struct btrfs_fs_info *fs_info;
+	struct inode *inode;
 	spinlock_t lock;
 	u64 pinned;
 	u64 reserved;
@@ -773,8 +803,11 @@ struct btrfs_block_group_cache {
 	int extents_thresh;
 	int free_extents;
 	int total_bitmaps;
-	int ro;
-	int dirty;
+	int ro:1;
+	int dirty:1;
+	int iref:1;
+
+	int disk_cache_state;
 
 	/* cache tracking stuff */
 	int cached;
@@ -1192,6 +1225,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_NOSSD		(1 << 9)
 #define BTRFS_MOUNT_DISCARD		(1 << 10)
 #define BTRFS_MOUNT_FORCE_COMPRESS      (1 << 11)
+#define BTRFS_MOUNT_SPACE_CACHE		(1 << 12)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
@@ -1665,6 +1699,27 @@ static inline void btrfs_set_dir_item_key(struct extent_buffer *eb,
 	write_eb_member(eb, item, struct btrfs_dir_item, location, key);
 }
 
+BTRFS_SETGET_FUNCS(free_space_entries, struct btrfs_free_space_header,
+		   num_entries, 64);
+BTRFS_SETGET_FUNCS(free_space_bitmaps, struct btrfs_free_space_header,
+		   num_bitmaps, 64);
+BTRFS_SETGET_FUNCS(free_space_generation, struct btrfs_free_space_header,
+		   generation, 64);
+
+static inline void btrfs_free_space_key(struct extent_buffer *eb,
+					struct btrfs_free_space_header *h,
+					struct btrfs_disk_key *key)
+{
+	read_eb_member(eb, h, struct btrfs_free_space_header, location, key);
+}
+
+static inline void btrfs_set_free_space_key(struct extent_buffer *eb,
+					    struct btrfs_free_space_header *h,
+					    struct btrfs_disk_key *key)
+{
+	write_eb_member(eb, h, struct btrfs_free_space_header, location, key);
+}
+
 /* struct btrfs_disk_key */
 BTRFS_SETGET_STACK_FUNCS(disk_key_objectid, struct btrfs_disk_key,
 			 objectid, 64);
@@ -1876,6 +1931,8 @@ BTRFS_SETGET_STACK_FUNCS(super_incompat_flags, struct btrfs_super_block,
 			 incompat_flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_csum_type, struct btrfs_super_block,
 			 csum_type, 16);
+BTRFS_SETGET_STACK_FUNCS(super_cache_generation, struct btrfs_super_block,
+			 cache_generation, 64);
 
 static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
 {
@@ -2115,6 +2172,7 @@ int btrfs_set_block_group_ro(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
 int btrfs_set_block_group_rw(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *cache);
+void btrfs_put_block_group_cache(struct btrfs_fs_info *info);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);
@@ -2426,6 +2484,10 @@ void btrfs_run_delayed_iputs(struct btrfs_root *root);
 int btrfs_prealloc_file_range(struct inode *inode, int mode,
 			      u64 start, u64 num_bytes, u64 min_size,
 			      loff_t actual_len, u64 *alloc_hint);
+int btrfs_prealloc_file_range_trans(struct inode *inode,
+				    struct btrfs_trans_handle *trans, int mode,
+				    u64 start, u64 num_bytes, u64 min_size,
+				    loff_t actual_len, u64 *alloc_hint);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit 8bb8ab2e93f9c3c9453e13be0f37d344a32a3a6d
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Oct 15 16:52:49 2010 -0400

    Btrfs: rework how we reserve metadata bytes
    
    With multi-threaded writes we were getting ENOSPC early because somebody would
    come in, start flushing delalloc because they couldn't make their reservation,
    and in the meantime other threads would come in and use the space that was
    getting freed up, so when the original thread went to check to see if they had
    space they didn't and they'd return ENOSPC.  So instead if we have some free
    space but not enough for our reservation, take the reservation and then start
    doing the flushing.  The only time we don't take reservations is when we've
    already overcommitted our space, that way we don't have people who come late to
    the party way overcommitting ourselves.  This also moves all of the retrying and
    flushing code into reserve_metdata_bytes so it's all uniform.  This keeps my
    fs_mark test from returning -ENOSPC as soon as it starts and actually lets me
    fill up the disk.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f32404db2c5d..47bc66e34da7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2082,7 +2082,7 @@ int btrfs_check_data_free_space(struct inode *inode, u64 bytes);
 void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
 int btrfs_trans_reserve_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
-				int num_items, int *retries);
+				int num_items);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
@@ -2103,7 +2103,7 @@ void btrfs_add_durable_block_rsv(struct btrfs_fs_info *fs_info,
 int btrfs_block_rsv_add(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct btrfs_block_rsv *block_rsv,
-			u64 num_bytes, int *retries);
+			u64 num_bytes);
 int btrfs_block_rsv_check(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  struct btrfs_block_rsv *block_rsv,

commit 0019f10db6f596f3e14a19f9bd7059a1b85b0853
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Oct 15 15:18:40 2010 -0400

    Btrfs: re-work delalloc flushing
    
    Currently we try and flush delalloc, but we only do that in a sort of weak way,
    which works fine in most cases but if we're under heavy pressure we need to be
    able to wait for flushing to happen.  Also instead of checking the bytes
    reserved in the block_rsv, check the space info since it is more accurate.  The
    sync option will be used in a future patch.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 014fd52c01bf..f32404db2c5d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2376,7 +2376,8 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
-int btrfs_start_one_delalloc_inode(struct btrfs_root *root, int delay_iput);
+int btrfs_start_one_delalloc_inode(struct btrfs_root *root, int delay_iput,
+				   int sync);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
 int btrfs_writepages(struct address_space *mapping,

commit 89a55897a2fbbceb94480952784004bf23911d38
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Oct 14 14:52:27 2010 -0400

    Btrfs: fix df regression
    
    The new ENOSPC stuff breaks out the raid types which breaks the way we were
    reporting df to the system.  This fixes it back so that Available is the total
    space available to data and used is the actual bytes used by the filesystem.
    This means that Available is Total - data used - all of the metadata space.
    Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 29c20092847e..014fd52c01bf 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -675,7 +675,8 @@ struct btrfs_block_group_item {
 struct btrfs_space_info {
 	u64 flags;
 
-	u64 total_bytes;	/* total bytes in the space */
+	u64 total_bytes;	/* total bytes in the space,
+				   this doesn't take mirrors into account */
 	u64 bytes_used;		/* total bytes used,
 				   this does't take mirrors into account */
 	u64 bytes_pinned;	/* total bytes pinned, will be freed when the
@@ -687,6 +688,8 @@ struct btrfs_space_info {
 	u64 bytes_may_use;	/* number of bytes that may be used for
 				   delalloc/allocations */
 	u64 disk_used;		/* total bytes used on disk */
+	u64 disk_total;		/* total bytes on disk, takes mirrors into
+				   account */
 
 	int full;		/* indicates that we cannot allocate any more
 				   chunks for this space */

commit 45321ac54316eaeeebde0b5f728a1791e500974c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 7 13:43:19 2010 -0400

    Make ->drop_inode() just return whether inode needs to be dropped
    
    ... and let iput_final() do the actual eviction or retention
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 394d5422ab6a..eaf286abad17 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2395,7 +2395,7 @@ int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
 void btrfs_dirty_inode(struct inode *inode);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
-void btrfs_drop_inode(struct inode *inode);
+int btrfs_drop_inode(struct inode *inode);
 int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);

commit bd55597520a2eaa0d71dd7683513a14bfd1bdf5c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 7 11:35:40 2010 -0400

    convert btrfs to ->evict_inode()
    
    NB: do we want btrfs_wait_ordered_range() on eviction of
    inodes with positive i_nlink on subvolume with zero root_refs?
    If not, btrfs_evict_inode() can be simplified by unconditionally
    bailing out in case of i_nlink > 0 in the very beginning...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 29c20092847e..394d5422ab6a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2389,7 +2389,7 @@ unsigned long btrfs_force_ra(struct address_space *mapping,
 			      pgoff_t offset, pgoff_t last_index);
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
-void btrfs_delete_inode(struct inode *inode);
+void btrfs_evict_inode(struct inode *inode);
 void btrfs_put_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
 void btrfs_dirty_inode(struct inode *inode);

commit 7ea8085910ef3dd4f3cad6845aaa2b580d39b115
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 26 17:53:25 2010 +0200

    drop unused dentry argument to ->fsync
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e9bf86415e86..29c20092847e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2434,7 +2434,7 @@ void btrfs_update_iflags(struct inode *inode);
 void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
 
 /* file.c */
-int btrfs_sync_file(struct file *file, struct dentry *dentry, int datasync);
+int btrfs_sync_file(struct file *file, int datasync);
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			    int skip_pinned);
 int btrfs_check_file(struct btrfs_root *root, struct inode *inode);

commit 4b46fce23349bfca781a32e2707a18328ca5ae22
Author: Josef Bacik <josef@redhat.com>
Date:   Sun May 23 11:00:55 2010 -0400

    Btrfs: add basic DIO read/write support
    
    This provides basic DIO support for reading and writing.  It does not do the
    work to recover from mismatching checksums, that will come later.  A few design
    changes have been made from Jim's code (sorry Jim!)
    
    1) Use the generic direct-io code.  Jim originally re-wrote all the generic DIO
    code in order to account for all of BTRFS's oddities, but thanks to that work it
    seems like the best bet is to just ignore compression and such and just opt to
    fallback on buffered IO.
    
    2) Fallback on buffered IO for compressed or inline extents.  Jim's code did
    it's own buffering to make dio with compressed extents work.  Now we just
    fallback onto normal buffered IO.
    
    3) Use ordered extents for the writes so that all of the
    
    lock_extent()
    lookup_ordered()
    
    type checks continue to work.
    
    4) Do the lock_extent() lookup_ordered() loop in readpage so we don't race with
    DIO writes.
    
    I've tested this with fsx and everything works great.  This patch depends on my
    dio and filemap.c patches to work.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5ed0223d1cbe..e9bf86415e86 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2317,6 +2317,8 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, u64 bytenr, u64 len);
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio, u32 *dst);
+int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
+			      struct bio *bio, u64 logical_offset, u32 *dst);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,

commit 3fd0a5585eb98e074fb9934549c8d85c49756c0d
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:59 2010 -0400

    Btrfs: Metadata ENOSPC handling for balance
    
    This patch adds metadata ENOSPC handling for the balance code.
    It is consisted by following major changes:
    
    1. Avoid COW tree leave in the phrase of merging tree.
    
    2. Handle interaction with snapshot creation.
    
    3. make the backref cache can live across transactions.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 65530837d04b..5ed0223d1cbe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2205,7 +2205,8 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
-int btrfs_drop_snapshot(struct btrfs_root *root, int update_ref);
+int btrfs_drop_snapshot(struct btrfs_root *root,
+			struct btrfs_block_rsv *block_rsv, int update_ref);
 int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct extent_buffer *node,
@@ -2479,4 +2480,12 @@ int btrfs_update_reloc_root(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
 int btrfs_recover_relocation(struct btrfs_root *root);
 int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
+void btrfs_reloc_cow_block(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, struct extent_buffer *buf,
+			   struct extent_buffer *cow);
+void btrfs_reloc_pre_snapshot(struct btrfs_trans_handle *trans,
+			      struct btrfs_pending_snapshot *pending,
+			      u64 *bytes_to_reserve);
+void btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,
+			      struct btrfs_pending_snapshot *pending);
 #endif

commit efa56464562991b8c24f965199888806bd8c4b38
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:59 2010 -0400

    Btrfs: Pre-allocate space for data relocation
    
    Pre-allocate space for data relocation. This can detect ENOPSC
    condition caused by fragmentation of free space.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fc324f9fcb42..65530837d04b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2420,6 +2420,9 @@ int btrfs_cont_expand(struct inode *inode, loff_t size);
 int btrfs_invalidate_inodes(struct btrfs_root *root);
 void btrfs_add_delayed_iput(struct inode *inode);
 void btrfs_run_delayed_iputs(struct btrfs_root *root);
+int btrfs_prealloc_file_range(struct inode *inode, int mode,
+			      u64 start, u64 num_bytes, u64 min_size,
+			      loff_t actual_len, u64 *alloc_hint);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit d68fc57b7e3245cfacf2e3b47acfed1946a11786
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:58 2010 -0400

    Btrfs: Metadata reservation for orphan inodes
    
    reserve metadata space for handling orphan inodes
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 504d5daf2f1c..fc324f9fcb42 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1069,7 +1069,6 @@ struct btrfs_root {
 	int ref_cows;
 	int track_dirty;
 	int in_radix;
-	int clean_orphans;
 
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
@@ -1083,8 +1082,11 @@ struct btrfs_root {
 
 	struct list_head root_list;
 
-	spinlock_t list_lock;
+	spinlock_t orphan_lock;
 	struct list_head orphan_list;
+	struct btrfs_block_rsv *orphan_block_rsv;
+	int orphan_item_inserted;
+	int orphan_cleanup_state;
 
 	spinlock_t inode_lock;
 	/* red-black tree that keeps track of in-memory inodes */
@@ -2080,6 +2082,9 @@ int btrfs_trans_reserve_metadata(struct btrfs_trans_handle *trans,
 				int num_items, int *retries);
 void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
+int btrfs_orphan_reserve_metadata(struct btrfs_trans_handle *trans,
+				  struct inode *inode);
+void btrfs_orphan_release_metadata(struct inode *inode);
 int btrfs_snap_reserve_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_pending_snapshot *pending);
 int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
@@ -2404,6 +2409,13 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 void btrfs_orphan_cleanup(struct btrfs_root *root);
+void btrfs_orphan_pre_snapshot(struct btrfs_trans_handle *trans,
+				struct btrfs_pending_snapshot *pending,
+				u64 *bytes_to_reserve);
+void btrfs_orphan_post_snapshot(struct btrfs_trans_handle *trans,
+				struct btrfs_pending_snapshot *pending);
+void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,
+			      struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t size);
 int btrfs_invalidate_inodes(struct btrfs_root *root);
 void btrfs_add_delayed_iput(struct inode *inode);

commit 8929ecfa50f266163832eeacfbc3642ed5eb83b6
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:58 2010 -0400

    Btrfs: Introduce global metadata reservation
    
    Reserve metadata space for extent tree, checksum tree and root tree
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d4744192eada..504d5daf2f1c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -683,21 +683,15 @@ struct btrfs_space_info {
 	u64 bytes_reserved;	/* total bytes the allocator has reserved for
 				   current allocations */
 	u64 bytes_readonly;	/* total bytes that are read only */
-	u64 bytes_super;	/* total bytes reserved for the super blocks */
-	u64 bytes_root;		/* the number of bytes needed to commit a
-				   transaction */
+
 	u64 bytes_may_use;	/* number of bytes that may be used for
 				   delalloc/allocations */
-	u64 bytes_delalloc;	/* number of bytes currently reserved for
-				   delayed allocation */
 	u64 disk_used;		/* total bytes used on disk */
 
 	int full;		/* indicates that we cannot allocate any more
 				   chunks for this space */
 	int force_alloc;	/* set if we need to force a chunk alloc for
 				   this space */
-	int force_delalloc;	/* make people start doing filemap_flush until
-				   we're under a threshold */
 
 	struct list_head list;
 

commit 0ca1f7ceb1991099ed5273885ebcf4323948c72e
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:48:47 2010 -0400

    Btrfs: Update metadata reservation for delayed allocation
    
    Introduce metadata reservation context for delayed allocation
    and update various related functions.
    
    This patch also introduces EXTENT_FIRST_DELALLOC control bit for
    set/clear_extent_bit. It tells set/clear_bit_hook whether they
    are processing the first extent_state with EXTENT_DELALLOC bit
    set. This change is important if set/clear_extent_bit involves
    multiple extent_state.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e0aa9fb563e2..d4744192eada 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2079,19 +2079,8 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
-
-int btrfs_unreserve_metadata_for_delalloc(struct btrfs_root *root,
-					  struct inode *inode, int num_items);
-int btrfs_reserve_metadata_for_delalloc(struct btrfs_root *root,
-					struct inode *inode, int num_items);
-int btrfs_check_data_free_space(struct btrfs_root *root, struct inode *inode,
-				u64 bytes);
-void btrfs_free_reserved_data_space(struct btrfs_root *root,
-				    struct inode *inode, u64 bytes);
-void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
-				 u64 bytes);
-void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
-			      u64 bytes);
+int btrfs_check_data_free_space(struct inode *inode, u64 bytes);
+void btrfs_free_reserved_data_space(struct inode *inode, u64 bytes);
 int btrfs_trans_reserve_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				int num_items, int *retries);
@@ -2099,6 +2088,10 @@ void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_snap_reserve_metadata(struct btrfs_trans_handle *trans,
 				struct btrfs_pending_snapshot *pending);
+int btrfs_delalloc_reserve_metadata(struct inode *inode, u64 num_bytes);
+void btrfs_delalloc_release_metadata(struct inode *inode, u64 num_bytes);
+int btrfs_delalloc_reserve_space(struct inode *inode, u64 num_bytes);
+void btrfs_delalloc_release_space(struct inode *inode, u64 num_bytes);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root);
 void btrfs_free_block_rsv(struct btrfs_root *root,

commit a22285a6a32390195235171b89d157ed1a1fe932
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:48:46 2010 -0400

    Btrfs: Integrate metadata reservation with start_transaction
    
    Besides simplify the code, this change makes sure all metadata
    reservation for normal metadata operations are released after
    committing transaction.
    
    Changes since V1:
    
    Add code that check if unlink and rmdir will free space.
    
    Add ENOSPC handling for clone ioctl.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7d2479694a58..e0aa9fb563e2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -34,6 +34,7 @@
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
+struct btrfs_pending_snapshot;
 extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
@@ -970,6 +971,7 @@ struct btrfs_fs_info {
 	int do_barriers;
 	int closing;
 	int log_root_recovering;
+	int enospc_unlink;
 
 	u64 total_pinned;
 
@@ -1995,6 +1997,9 @@ void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_lookup_extent_info(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root, u64 bytenr,
+			     u64 num_bytes, u64 *refs, u64 *flags);
 int btrfs_pin_extent(struct btrfs_root *root,
 		     u64 bytenr, u64 num, int reserved);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
@@ -2075,8 +2080,6 @@ u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
-int btrfs_reserve_metadata_space(struct btrfs_root *root, int num_items);
-int btrfs_unreserve_metadata_space(struct btrfs_root *root, int num_items);
 int btrfs_unreserve_metadata_for_delalloc(struct btrfs_root *root,
 					  struct inode *inode, int num_items);
 int btrfs_reserve_metadata_for_delalloc(struct btrfs_root *root,
@@ -2089,6 +2092,13 @@ void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
 				 u64 bytes);
 void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
 			      u64 bytes);
+int btrfs_trans_reserve_metadata(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root,
+				int num_items, int *retries);
+void btrfs_trans_release_metadata(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root);
+int btrfs_snap_reserve_metadata(struct btrfs_trans_handle *trans,
+				struct btrfs_pending_snapshot *pending);
 void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv);
 struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root);
 void btrfs_free_block_rsv(struct btrfs_root *root,
@@ -2296,6 +2306,12 @@ int btrfs_del_inode_ref(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   const char *name, int name_len,
 			   u64 inode_objectid, u64 ref_objectid, u64 *index);
+struct btrfs_inode_ref *
+btrfs_lookup_inode_ref(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root,
+			struct btrfs_path *path,
+			const char *name, int name_len,
+			u64 inode_objectid, u64 ref_objectid, int mod);
 int btrfs_insert_empty_inode(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid);

commit f0486c68e4bd9a06a5904d3eeb3a0d73a83befb8
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:46:25 2010 -0400

    Btrfs: Introduce contexts for metadata reservation
    
    Introducing metadata reseravtion contexts has two major advantages.
    First, it makes metadata reseravtion more traceable. Second, it can
    reclaim freed space and re-add them to the itself after transaction
    committed.
    
    Besides add btrfs_block_rsv structure and related helper functions,
    This patch contains following changes:
    
    Move code that decides if freed tree block should be pinned into
    btrfs_free_tree_block().
    
    Make space accounting more accurate, mainly for handling read only
    block groups.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 85c7b95dd2fe..7d2479694a58 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -707,6 +707,20 @@ struct btrfs_space_info {
 	atomic_t caching_threads;
 };
 
+struct btrfs_block_rsv {
+	u64 size;
+	u64 reserved;
+	u64 freed[2];
+	struct btrfs_space_info *space_info;
+	struct list_head list;
+	spinlock_t lock;
+	atomic_t usage;
+	unsigned int priority:8;
+	unsigned int durable:1;
+	unsigned int refill_used:1;
+	unsigned int full:1;
+};
+
 /*
  * free clusters are used to claim free space in relatively large chunks,
  * allowing us to do less seeky writes.  They are used for all metadata
@@ -757,6 +771,7 @@ struct btrfs_block_group_cache {
 	spinlock_t lock;
 	u64 pinned;
 	u64 reserved;
+	u64 reserved_pinned;
 	u64 bytes_super;
 	u64 flags;
 	u64 sectorsize;
@@ -822,6 +837,22 @@ struct btrfs_fs_info {
 	/* logical->physical extent mapping */
 	struct btrfs_mapping_tree mapping_tree;
 
+	/* block reservation for extent, checksum and root tree */
+	struct btrfs_block_rsv global_block_rsv;
+	/* block reservation for delay allocation */
+	struct btrfs_block_rsv delalloc_block_rsv;
+	/* block reservation for metadata operations */
+	struct btrfs_block_rsv trans_block_rsv;
+	/* block reservation for chunk tree */
+	struct btrfs_block_rsv chunk_block_rsv;
+
+	struct btrfs_block_rsv empty_block_rsv;
+
+	/* list of block reservations that cross multiple transactions */
+	struct list_head durable_block_rsv_list;
+
+	struct mutex durable_block_rsv_mutex;
+
 	u64 generation;
 	u64 last_trans_committed;
 
@@ -1008,6 +1039,9 @@ struct btrfs_root {
 	struct completion kobj_unregister;
 	struct mutex objectid_mutex;
 
+	spinlock_t accounting_lock;
+	struct btrfs_block_rsv *block_rsv;
+
 	struct mutex log_mutex;
 	wait_queue_head_t log_writer_wait;
 	wait_queue_head_t log_commit_wait[2];
@@ -1980,10 +2014,10 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					u64 parent, u64 root_objectid,
 					struct btrfs_disk_key *key, int level,
 					u64 hint, u64 empty_size);
-int btrfs_free_tree_block(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root,
-			  u64 bytenr, u32 blocksize,
-			  u64 parent, u64 root_objectid, int level);
+void btrfs_free_tree_block(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root,
+			   struct extent_buffer *buf,
+			   u64 parent, int last_ref);
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize,
@@ -2037,9 +2071,6 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 size);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
-int btrfs_prepare_block_group_relocation(struct btrfs_root *root,
-				struct btrfs_block_group_cache *group);
-
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
@@ -2058,6 +2089,30 @@ void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
 				 u64 bytes);
 void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
 			      u64 bytes);
+void btrfs_init_block_rsv(struct btrfs_block_rsv *rsv);
+struct btrfs_block_rsv *btrfs_alloc_block_rsv(struct btrfs_root *root);
+void btrfs_free_block_rsv(struct btrfs_root *root,
+			  struct btrfs_block_rsv *rsv);
+void btrfs_add_durable_block_rsv(struct btrfs_fs_info *fs_info,
+				 struct btrfs_block_rsv *rsv);
+int btrfs_block_rsv_add(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root,
+			struct btrfs_block_rsv *block_rsv,
+			u64 num_bytes, int *retries);
+int btrfs_block_rsv_check(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root,
+			  struct btrfs_block_rsv *block_rsv,
+			  u64 min_reserved, int min_factor);
+int btrfs_block_rsv_migrate(struct btrfs_block_rsv *src_rsv,
+			    struct btrfs_block_rsv *dst_rsv,
+			    u64 num_bytes);
+void btrfs_block_rsv_release(struct btrfs_root *root,
+			     struct btrfs_block_rsv *block_rsv,
+			     u64 num_bytes);
+int btrfs_set_block_group_ro(struct btrfs_root *root,
+			     struct btrfs_block_group_cache *cache);
+int btrfs_set_block_group_rw(struct btrfs_root *root,
+			     struct btrfs_block_group_cache *cache);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit 5da9d01b66458b180a6bee0e637a1d0a3effc622
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:46:25 2010 -0400

    Btrfs: Shrink delay allocated space in a synchronized
    
    Shrink delayed allocation space in a synchronized manner is more
    controllable than flushing all delay allocated space in an async
    thread.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a68f34603b9d..85c7b95dd2fe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -700,10 +700,6 @@ struct btrfs_space_info {
 
 	struct list_head list;
 
-	/* for controlling how we free up space for allocations */
-	wait_queue_head_t flush_wait;
-	int flushing;
-
 	/* for block groups in our same type */
 	struct list_head block_groups[BTRFS_NR_RAID_TYPES];
 	spinlock_t lock;
@@ -928,7 +924,6 @@ struct btrfs_fs_info {
 	struct btrfs_workers endio_meta_write_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers submit_workers;
-	struct btrfs_workers enospc_workers;
 	/*
 	 * fixup workers take dirty pages that didn't properly go through
 	 * the cow mechanism and make them safe to write.  It happens
@@ -2312,6 +2307,7 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
+int btrfs_start_one_delalloc_inode(struct btrfs_root *root, int delay_iput);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
 			      struct extent_state **cached_state);
 int btrfs_writepages(struct address_space *mapping,

commit 424499dbd0c4d88742bf581b5714b27fb44b9fef
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:46:25 2010 -0400

    Btrfs: Kill allocate_wait in space_info
    
    We already have fs_info->chunk_mutex to avoid concurrent
    chunk creation.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6132088a577c..a68f34603b9d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -701,9 +701,7 @@ struct btrfs_space_info {
 	struct list_head list;
 
 	/* for controlling how we free up space for allocations */
-	wait_queue_head_t allocate_wait;
 	wait_queue_head_t flush_wait;
-	int allocating_chunk;
 	int flushing;
 
 	/* for block groups in our same type */

commit b742bb82f1676d50103ade0ba89bfb79debabe73
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:46:24 2010 -0400

    Btrfs: Link block groups of different raid types
    
    The size of reserved space is stored in space_info. If block groups
    of different raid types are linked to separate space_info, changing
    allocation profile will corrupt reserved space accounting.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 746a7248678e..6132088a577c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -663,6 +663,7 @@ struct btrfs_csum_item {
 #define BTRFS_BLOCK_GROUP_RAID1    (1 << 4)
 #define BTRFS_BLOCK_GROUP_DUP	   (1 << 5)
 #define BTRFS_BLOCK_GROUP_RAID10   (1 << 6)
+#define BTRFS_NR_RAID_TYPES	   5
 
 struct btrfs_block_group_item {
 	__le64 used;
@@ -674,7 +675,8 @@ struct btrfs_space_info {
 	u64 flags;
 
 	u64 total_bytes;	/* total bytes in the space */
-	u64 bytes_used;		/* total bytes used on disk */
+	u64 bytes_used;		/* total bytes used,
+				   this does't take mirrors into account */
 	u64 bytes_pinned;	/* total bytes pinned, will be freed when the
 				   transaction finishes */
 	u64 bytes_reserved;	/* total bytes the allocator has reserved for
@@ -687,6 +689,7 @@ struct btrfs_space_info {
 				   delalloc/allocations */
 	u64 bytes_delalloc;	/* number of bytes currently reserved for
 				   delayed allocation */
+	u64 disk_used;		/* total bytes used on disk */
 
 	int full;		/* indicates that we cannot allocate any more
 				   chunks for this space */
@@ -704,7 +707,7 @@ struct btrfs_space_info {
 	int flushing;
 
 	/* for block groups in our same type */
-	struct list_head block_groups;
+	struct list_head block_groups[BTRFS_NR_RAID_TYPES];
 	spinlock_t lock;
 	struct rw_semaphore groups_sem;
 	atomic_t caching_threads;

commit 795d580baec0d5386b83a8b557df47c20810e86b
Merge: 449cedf099b2 109f6aef5fc4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 5 13:21:15 2010 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: add check for changed leaves in setup_leaf_for_split
      Btrfs: create snapshot references in same commit as snapshot
      Btrfs: fix small race with delalloc flushing waitqueue's
      Btrfs: use add_to_page_cache_lru, use __page_cache_alloc
      Btrfs: fix chunk allocate size calculation
      Btrfs: kill max_extent mount option
      Btrfs: fail to mount if we have problems reading the block groups
      Btrfs: check btrfs_get_extent return for IS_ERR()
      Btrfs: handle kmalloc() failure in inode lookup ioctl
      Btrfs: dereferencing freed memory
      Btrfs: Simplify num_stripes's calculation logical for __btrfs_alloc_chunk()
      Btrfs: Add error handle for btrfs_search_slot() in btrfs_read_chunk_tree()
      Btrfs: Remove unnecessary finish_wait() in wait_current_trans()
      Btrfs: add NULL check for do_walk_down()
      Btrfs: remove duplicate include in ioctl.c
    
    Fix trivial conflict in fs/btrfs/compression.c due to slab.h include
    cleanups.

commit 287a0ab91d25ca982f895a76402e5893b47ed7a6
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Mar 19 18:07:23 2010 +0000

    Btrfs: kill max_extent mount option
    
    As Yan pointed out, theres not much reason for all this complicated math to
    account for file extents being split up into max_extent chunks, since they are
    likely to all end up in the same leaf anyway.  Since there isn't much reason to
    use max_extent, just remove the option altogether so we have one less thing we
    need to test.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 11115847d875..ae8c40922c54 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -834,7 +834,6 @@ struct btrfs_fs_info {
 	u64 last_trans_log_full_commit;
 	u64 open_ioctl_trans;
 	unsigned long mount_opt;
-	u64 max_extent;
 	u64 max_inline;
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0af2e3868573..8a6518a3f041 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -26,6 +26,7 @@
 #include <linux/completion.h>
 #include <linux/backing-dev.h>
 #include <linux/wait.h>
+#include <linux/slab.h>
 #include <asm/kmap_types.h>
 #include "extent_io.h"
 #include "extent_map.h"

commit 441f4058a04b2943685ff94e0f5f1992b0b3649e
Merge: 7c34691abe23 8ad6fcab564c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 18 16:50:55 2010 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (30 commits)
      Btrfs: fix the inode ref searches done by btrfs_search_path_in_tree
      Btrfs: allow treeid==0 in the inode lookup ioctl
      Btrfs: return keys for large items to the search ioctl
      Btrfs: fix key checks and advance in the search ioctl
      Btrfs: buffer results in the space_info ioctl
      Btrfs: use __u64 types in ioctl.h
      Btrfs: fix search_ioctl key advance
      Btrfs: fix gfp flags masking in the compression code
      Btrfs: don't look at bio flags after submit_bio
      btrfs: using btrfs_stack_device_id() get devid
      btrfs: use memparse
      Btrfs: add a "df" ioctl for btrfs
      Btrfs: cache the extent state everywhere we possibly can V2
      Btrfs: cache ordered extent when completing io
      Btrfs: cache extent state in find_delalloc_range
      Btrfs: change the ordered tree to use a spinlock instead of a mutex
      Btrfs: finish read pages in the order they are submitted
      btrfs: fix btrfs_mkdir goto for no free objectids
      Btrfs: flush data on snapshot creation
      Btrfs: make df be a little bit more understandable
      ...

commit 91748467a5c5884e44ad5cf58630c0c28474f1f6
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Sun Feb 28 10:59:11 2010 +0000

    btrfs: use memparse
    
    Use memparse() instead of its own private implementation.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: linux-btrfs@vger.kernel.org
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3f704a816137..11115847d875 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2388,7 +2388,6 @@ void btrfs_sysfs_del_super(struct btrfs_fs_info *root);
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 
 /* super.c */
-u64 btrfs_parse_size(char *str);
 int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 

commit 2ac55d41b5d6bf49e76bc85db5431240617e2f8f
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Feb 3 19:33:23 2010 +0000

    Btrfs: cache the extent state everywhere we possibly can V2
    
    This patch just goes through and fixes everybody that does
    
    lock_extent()
    blah
    unlock_extent()
    
    to use
    
    lock_extent_bits()
    blah
    unlock_extent_cached()
    
    and pass around a extent_state so we only have to do the searches once per
    function.  This gives me about a 3 mb/s boots on my random write test.  I have
    not converted some things, like the relocation and ioctl's, since they aren't
    heavily used and the relocation stuff is in the middle of being re-written.  I
    also changed the clear_extent_bit() to only unset the cached state if we are
    clearing EXTENT_LOCKED and related stuff, so we can do things like this
    
    lock_extent_bits()
    clear delalloc bits
    unlock_extent_cached()
    
    without losing our cached state.  I tested this thoroughly and turned on
    LEAK_DEBUG to make sure we weren't leaking extent states, everything worked out
    fine.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3a36b1fb553a..3f704a816137 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2311,7 +2311,8 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       u32 min_type);
 
 int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
-int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end);
+int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end,
+			      struct extent_state **cached_state);
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,

commit 1e701a3292e25a6c4939cad9f24951dc6b6ad853
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 11 09:42:04 2010 -0500

    Btrfs: add new defrag-range ioctl.
    
    The btrfs defrag ioctl was limited to doing the entire file.  This
    commit adds a new interface that can defrag a specific range inside
    the file.
    
    It can also force compression on the file, allowing you to selectively
    compress individual files after they were created, even when mount -o
    compress isn't turned on.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1166b15e9bf6..3a36b1fb553a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1184,7 +1184,6 @@ struct btrfs_root {
 #define BTRFS_INODE_NOATIME		(1 << 9)
 #define BTRFS_INODE_DIRSYNC		(1 << 10)
 
-
 /* some macros to generate set/get funcs for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple
  * one for u8:

commit 6ef5ed0d386be5c43ec66d6f2999919c0893558b
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Dec 11 21:11:29 2009 +0000

    Btrfs: add ioctl and incompat flag to set the default mount subvol
    
    This patch needs to go along with my previous patch.  This lets us set the
    default dir item's location to whatever root we want to use as our default
    mounting subvol.  With this we don't have to use mount -o subvol=<tree id>
    anymore to mount a different subvol, we can just set the new one and it will
    just magically work.  I've done some moderate testing with this, mostly just
    switching the default mount around, mounting subvols and the default mount at
    the same time and such, everything seems to work.  Thanks,
    
    Older kernels would generally be able to still mount the filesystem with the
    default subvolume set, but it would result in a different volume being mounted,
    which could be an even more unpleasant suprise for users.  So if you set your
    default subvolume, you can't go back to older kernels.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 07d956977a07..1166b15e9bf6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -373,11 +373,13 @@ struct btrfs_super_block {
  * ones specified below then we will fail to mount
  */
 #define BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF	(1ULL << 0)
+#define BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL	(2ULL << 0)
 
 #define BTRFS_FEATURE_COMPAT_SUPP		0ULL
 #define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
 #define BTRFS_FEATURE_INCOMPAT_SUPP		\
-	BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF
+	(BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF |	\
+	 BTRFS_FEATURE_INCOMPAT_DEFAULT_SUBVOL)
 
 /*
  * A leaf is full of items. offset and size tell us where to find

commit 73f73415caddbc01d9f10c03e0a677d5b3d11569
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Dec 4 17:38:27 2009 +0000

    Btrfs: change how we mount subvolumes
    
    This work is in preperation for being able to set a different root as the
    default mounting root.
    
    There is currently a problem with how we mount subvolumes.  We cannot currently
    mount a subvolume of a subvolume, you can only mount subvolumes/snapshots of the
    default subvolume.  So say you take a snapshot of the default subvolume and call
    it snap1, and then take a snapshot of snap1 and call it snap2, so now you have
    
    /
    /snap1
    /snap1/snap2
    
    as your available volumes.  Currently you can only mount / and /snap1,
    you cannot mount /snap1/snap2.  To fix this problem instead of passing
    subvolid=<name> you must pass in subvolid=<treeid>, where <treeid> is
    the tree id that gets spit out via the subvolume listing you get from
    the subvolume listing patches (btrfs filesystem list).  This allows us
    to mount /, /snap1 and /snap1/snap2 as the root volume.
    
    In addition to the above, we also now read the default dir item in the
    tree root to get the root key that it points to.  For now this just
    points at what has always been the default subvolme, but later on I plan
    to change it to point at whatever root you want to be the new default
    root, so you can just set the default mount and not have to mount with
    -o subvolid=<treeid>.  I tested this out with the above scenario and it
    worked perfectly.  Thanks,
    
    mount -o subvol operates inside the selected subvolid.  For example:
    
    mount -o subvol=snap1,subvolid=256 /dev/xxx /mnt
    
    /mnt will have the snap1 directory for the subvolume with id
    256.
    
    mount -o subvol=snap /dev/xxx /mnt
    
    /mnt will be the snap directory of whatever the default subvolume
    is.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index abbce4d90c1b..07d956977a07 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2335,7 +2335,7 @@ int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
-			 struct btrfs_root *root);
+			 struct btrfs_root *root, int *was_new);
 int btrfs_commit_write(struct file *file, struct page *page,
 		       unsigned from, unsigned to);
 struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,

commit 12534832cb7b0abc7369298246e8b7af03b863ca
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Dec 17 21:32:27 2009 +0000

    Btrfs: make set/get functions for the super compat_ro flags use compat_ro
    
    Our set/get functions for compat_ro_flags actually look at compat_flags.  This
    will mess any attempt to use compat flags up.  The fix is obvious.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2aa8ec6a0981..abbce4d90c1b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1842,7 +1842,7 @@ BTRFS_SETGET_STACK_FUNCS(super_num_devices, struct btrfs_super_block,
 BTRFS_SETGET_STACK_FUNCS(super_compat_flags, struct btrfs_super_block,
 			 compat_flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_compat_ro_flags, struct btrfs_super_block,
-			 compat_flags, 64);
+			 compat_ro_flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_incompat_flags, struct btrfs_super_block,
 			 incompat_flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_csum_type, struct btrfs_super_block,

commit a9185b41a4f84971b930c519f0c63bd450c4810d
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Mar 5 09:21:37 2010 +0100

    pass writeback_control to ->write_inode
    
    This gives the filesystem more information about the writeback that
    is happening.  Trond requested this for the NFS unstable write handling,
    and other filesystems might benefit from this too by beeing able to
    distinguish between the different callers in more detail.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2aa8ec6a0981..8b5cfdd4bfc1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2326,7 +2326,7 @@ int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);
 void btrfs_put_inode(struct inode *inode);
-int btrfs_write_inode(struct inode *inode, int wait);
+int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc);
 void btrfs_dirty_inode(struct inode *inode);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);

commit a555f810af6d63ea5960abaed88e150ad95c3011
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 28 16:18:15 2010 -0500

    Btrfs: Add mount -o compress-force
    
    The default btrfs mount -o compress mode will quickly back off
    compressing a file if it notices that compression does not reduce the
    size of the data being written.  This can save considerable CPU because
    all future writes to the file go through uncompressed.
    
    But some files are both very large and have mixed data stored in
    them.  In that case, we want to add the ability to always try
    compressing data before writing it.
    
    This commit adds mount -o compress-force.  A later commit will add
    a new inode flag that does the same thing.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9f806dd04c27..2aa8ec6a0981 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1161,6 +1161,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_SSD_SPREAD		(1 << 8)
 #define BTRFS_MOUNT_NOSSD		(1 << 9)
 #define BTRFS_MOUNT_DISCARD		(1 << 10)
+#define BTRFS_MOUNT_FORCE_COMPRESS      (1 << 11)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 86b9f2eca5e0984145e3c7698a7cd6dd65c2a93f
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:36:50 2009 +0000

    Btrfs: Fix per root used space accounting
    
    The bytes_used field in root item was originally planned to
    trace the amount of used data and tree blocks. But it never
    worked right since we can't trace freeing of data accurately.
    This patch changes it to only trace the amount of tree blocks.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1983c889bb1c..9f806dd04c27 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1982,6 +1982,10 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					u64 parent, u64 root_objectid,
 					struct btrfs_disk_key *key, int level,
 					u64 hint, u64 empty_size);
+int btrfs_free_tree_block(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root,
+			  u64 bytenr, u32 blocksize,
+			  u64 parent, u64 root_objectid, int level);
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize,

commit 24bbcf0442ee04660a5a030efdbb6d03f1c275cb
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:36:34 2009 +0000

    Btrfs: Add delayed iput
    
    iput() can trigger new transactions if we are dropping the
    final reference, so calling it in btrfs_commit_transaction
    may end up deadlock. This patch adds delayed iput to avoid
    the issue.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a7cac2148c7c..1983c889bb1c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -872,6 +872,9 @@ struct btrfs_fs_info {
 	struct list_head dead_roots;
 	struct list_head caching_block_groups;
 
+	spinlock_t delayed_iput_lock;
+	struct list_head delayed_iputs;
+
 	atomic_t nr_async_submits;
 	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;
@@ -2301,7 +2304,7 @@ int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       struct inode *inode, u64 new_size,
 			       u32 min_type);
 
-int btrfs_start_delalloc_inodes(struct btrfs_root *root);
+int btrfs_start_delalloc_inodes(struct btrfs_root *root, int delay_iput);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end);
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
@@ -2341,6 +2344,8 @@ int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 void btrfs_orphan_cleanup(struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t size);
 int btrfs_invalidate_inodes(struct btrfs_root *root);
+void btrfs_add_delayed_iput(struct inode *inode);
+void btrfs_run_delayed_iputs(struct btrfs_root *root);
 extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */

commit f34f57a3ab4e73304d78c125682f1a53cd3975f2
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:35:27 2009 +0000

    Btrfs: Pass transaction handle to security and ACL initialization functions
    
    Pass transaction handle down to security and ACL initialization
    functions, so we can avoid starting nested transactions
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fcfbefbbb685..a7cac2148c7c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -310,6 +310,9 @@ struct btrfs_header {
 #define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
 					sizeof(struct btrfs_item) - \
 					sizeof(struct btrfs_file_extent_item))
+#define BTRFS_MAX_XATTR_SIZE(r)	(BTRFS_LEAF_DATA_SIZE(r) - \
+				 sizeof(struct btrfs_item) -\
+				 sizeof(struct btrfs_dir_item))
 
 
 /*
@@ -2201,9 +2204,10 @@ int btrfs_delete_one_dir_name(struct btrfs_trans_handle *trans,
 			      struct btrfs_path *path,
 			      struct btrfs_dir_item *di);
 int btrfs_insert_xattr_item(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root, const char *name,
-			    u16 name_len, const void *data, u16 data_len,
-			    u64 dir);
+			    struct btrfs_root *root,
+			    struct btrfs_path *path, u64 objectid,
+			    const char *name, u16 name_len,
+			    const void *data, u16 data_len);
 struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path, u64 dir,
@@ -2382,7 +2386,8 @@ int btrfs_check_acl(struct inode *inode, int mask);
 #else
 #define btrfs_check_acl NULL
 #endif
-int btrfs_init_acl(struct inode *inode, struct inode *dir);
+int btrfs_init_acl(struct btrfs_trans_handle *trans,
+		   struct inode *inode, struct inode *dir);
 int btrfs_acl_chmod(struct inode *inode);
 
 /* relocation.c */

commit c71bf099abddf3e0fdc27f251ba76fca1461d49a
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:34:40 2009 +0000

    Btrfs: Avoid orphan inodes cleanup while replaying log
    
    We do log replay in a single transaction, so it's not good to do unbound
    operations. This patch cleans up orphan inodes cleanup after replaying
    the log. It also avoids doing other unbound operations such as truncating
    a file during replaying log. These unbound operations are postponed to
    the orphan inode cleanup stage.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ae5b0aaa9386..fcfbefbbb685 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -859,8 +859,9 @@ struct btrfs_fs_info {
 	struct mutex ordered_operations_mutex;
 	struct rw_semaphore extent_commit_sem;
 
-	struct rw_semaphore subvol_sem;
+	struct rw_semaphore cleanup_work_sem;
 
+	struct rw_semaphore subvol_sem;
 	struct srcu_struct subvol_srcu;
 
 	struct list_head trans_list;
@@ -1034,12 +1035,12 @@ struct btrfs_root {
 	int ref_cows;
 	int track_dirty;
 	int in_radix;
+	int clean_orphans;
 
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
 	int defrag_running;
-	int defrag_level;
 	char *name;
 	int in_sysfs;
 

commit 920bbbfb05c9fce22e088d20eb9dcb8f96342de9
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:34:08 2009 +0000

    Btrfs: Rewrite btrfs_drop_extents
    
    Rewrite btrfs_drop_extents by using btrfs_duplicate_item, so we can
    avoid calling lock_extent within transaction.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e3b58001162d..ae5b0aaa9386 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2349,12 +2349,9 @@ int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			    int skip_pinned);
 int btrfs_check_file(struct btrfs_root *root, struct inode *inode);
 extern const struct file_operations btrfs_file_operations;
-int btrfs_drop_extents(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *root, struct inode *inode,
-		       u64 start, u64 end, u64 locked_end,
-		       u64 inline_limit, u64 *hint_block, int drop_cache);
+int btrfs_drop_extents(struct btrfs_trans_handle *trans, struct inode *inode,
+		       u64 start, u64 end, u64 *hint_byte, int drop_cache);
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
-			      struct btrfs_root *root,
 			      struct inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);
 

commit ad48fd754676bfae4139be1a897b1ea58f9aaf21
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:33:58 2009 +0000

    Btrfs: Add btrfs_duplicate_item
    
    btrfs_duplicate_item duplicates item with new key, guaranteeing
    the source item and the new items are in the same tree leaf and
    contiguous. It allows us to split file extent in place, without
    using lock_extent to prevent bookend extent race.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 444b3e9b92a4..e3b58001162d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2089,6 +2089,10 @@ int btrfs_split_item(struct btrfs_trans_handle *trans,
 		     struct btrfs_path *path,
 		     struct btrfs_key *new_key,
 		     unsigned long split_offset);
+int btrfs_duplicate_item(struct btrfs_trans_handle *trans,
+			 struct btrfs_root *root,
+			 struct btrfs_path *path,
+			 struct btrfs_key *new_key);
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);

commit dcbeb0bec5f2695c3ff53f174efb8e03c209f3f3
Merge: 2b650df2cea9 444528b3e614
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 15 15:06:37 2009 -0700

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: always pin metadata in discard mode
      Btrfs: enable discard support
      Btrfs: add -o discard option
      Btrfs: properly wait log writers during log sync
      Btrfs: fix possible ENOSPC problems with truncate
      Btrfs: fix btrfs acl #ifdef checks
      Btrfs: streamline tree-log btree block writeout
      Btrfs: avoid tree log commit when there are no changes
      Btrfs: only write one super copy during fsync

commit e244a0aeb6a599c19a7c802cda6e2d67c847b154
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Oct 14 09:24:59 2009 -0400

    Btrfs: add -o discard option
    
    Enable discard by default is not a good idea given the the trim speed
    of SSD prototypes we've seen, and the carecteristics for many high-end
    arrays.  Turn of discards by default and require the -o discard option
    to enable them on.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dfd7e6fc66d3..e5dd628a526f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1153,6 +1153,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_FLUSHONCOMMIT       (1 << 7)
 #define BTRFS_MOUNT_SSD_SPREAD		(1 << 8)
 #define BTRFS_MOUNT_NOSSD		(1 << 9)
+#define BTRFS_MOUNT_DISCARD		(1 << 10)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 0eda294dfc980c1cbe4f8a0564bf543f86a01ddb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Oct 13 13:50:18 2009 -0400

    Btrfs: fix btrfs acl #ifdef checks
    
    The btrfs acl code was #ifdefing for a define
    that didn't exist.  This correctly matches it
    to the values used by the Kconfig file.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d0cede5ff25e..dfd7e6fc66d3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2374,7 +2374,7 @@ int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 
 /* acl.c */
-#ifdef CONFIG_BTRFS_POSIX_ACL
+#ifdef CONFIG_BTRFS_FS_POSIX_ACL
 int btrfs_check_acl(struct inode *inode, int mask);
 #else
 #define btrfs_check_acl NULL

commit 257c62e1bce03e5b9f3f069fd52ad73a56de71fd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Oct 13 13:21:08 2009 -0400

    Btrfs: avoid tree log commit when there are no changes
    
    rpm has a habit of running fdatasync when the file hasn't
    changed.  We already detect if a file hasn't been changed
    in the current transaction but it might have been sent to
    the tree-log in this transaction and not changed since
    the last call to fsync.
    
    In this case, we want to avoid a tree log sync, which includes
    a number of synchronous writes and barriers.  This commit
    extends the existing tracking of the last transaction to change
    a file to also track the last sub-transaction.
    
    The end result is that rpm -ivh and -Uvh are roughly twice as fast,
    and on par with ext3.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 36a19cd43e03..d0cede5ff25e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1009,6 +1009,7 @@ struct btrfs_root {
 	atomic_t log_writers;
 	atomic_t log_commit[2];
 	unsigned long log_transid;
+	unsigned long last_log_commit;
 	unsigned long log_batch;
 	pid_t log_start_pid;
 	bool log_multiple_pids;

commit 474a503d4bf77ae0cbe484dd0842a2648c0b1c28
Merge: d43c36dc6b35 ac6889cbb254
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Oct 11 11:23:13 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: fix file clone ioctl for bookend extents
      Btrfs: fix uninit compiler warning in cow_file_range_nocow
      Btrfs: constify dentry_operations
      Btrfs: optimize back reference update during btrfs_drop_snapshot
      Btrfs: remove negative dentry when deleting subvolumne
      Btrfs: optimize fsync for the single writer case
      Btrfs: async delalloc flushing under space pressure
      Btrfs: release delalloc reservations on extent item insertion
      Btrfs: delay clearing EXTENT_DELALLOC for compressed extents
      Btrfs: cleanup extent_clear_unlock_delalloc flags
      Btrfs: fix possible softlockup in the allocator
      Btrfs: fix deadlock on async thread startup

commit 82d339d9b3a6395f17d3253887653250b693b74b
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Fri Oct 9 09:54:36 2009 -0400

    Btrfs: constify dentry_operations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 16ddb19dda86..36a19cd43e03 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2330,7 +2330,7 @@ int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 void btrfs_orphan_cleanup(struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t size);
 int btrfs_invalidate_inodes(struct btrfs_root *root);
-extern struct dentry_operations btrfs_dentry_operations;
+extern const struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit ff782e0a131c7f669445c07fe5c7ba91e043b7ed
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Oct 8 15:30:04 2009 -0400

    Btrfs: optimize fsync for the single writer case
    
    This patch optimizes the tree logging stuff so it doesn't always wait 1 jiffie
    for new people to join the logging transaction if there is only ever 1 writer.
    This helps a little bit with latency where we have something like RPM where it
    will fdatasync every file it writes, and so waiting the 1 jiffie for every
    fdatasync really starts to add up.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a362dd617e97..16ddb19dda86 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1010,6 +1010,8 @@ struct btrfs_root {
 	atomic_t log_commit[2];
 	unsigned long log_transid;
 	unsigned long log_batch;
+	pid_t log_start_pid;
+	bool log_multiple_pids;
 
 	u64 objectid;
 	u64 last_trans;

commit e3ccfa989752c083ceb23c823a84f7ce3a081e61
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Oct 7 20:44:34 2009 -0400

    Btrfs: async delalloc flushing under space pressure
    
    This patch moves the delalloc flushing that occurs when we are under space
    pressure off to a async thread pool.  This helps since we only free up
    metadata space when we actually insert the extent item, which means it takes
    quite a while for space to be free'ed up if we wait on all ordered extents.
    However, if space is freed up due to inline extents being inserted, we can
    wake people who are waiting up early, and they can finish their work.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dbdada569507..a362dd617e97 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -691,17 +691,17 @@ struct btrfs_space_info {
 
 	struct list_head list;
 
+	/* for controlling how we free up space for allocations */
+	wait_queue_head_t allocate_wait;
+	wait_queue_head_t flush_wait;
+	int allocating_chunk;
+	int flushing;
+
 	/* for block groups in our same type */
 	struct list_head block_groups;
 	spinlock_t lock;
 	struct rw_semaphore groups_sem;
 	atomic_t caching_threads;
-
-	int allocating_chunk;
-	wait_queue_head_t wait;
-
-	int flushing;
-	wait_queue_head_t flush_wait;
 };
 
 /*
@@ -918,6 +918,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers endio_meta_write_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers submit_workers;
+	struct btrfs_workers enospc_workers;
 	/*
 	 * fixup workers take dirty pages that didn't properly go through
 	 * the cow mechanism and make them safe to write.  It happens

commit 32c00aff718bb54a214b39146bdd9ac01511cd25
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Oct 8 13:34:05 2009 -0400

    Btrfs: release delalloc reservations on extent item insertion
    
    This patch fixes an issue with the delalloc metadata space reservation
    code.  The problem is we used to free the reservation as soon as we
    allocated the delalloc region.  The problem with this is if we are not
    inserting an inline extent, we don't actually insert the extent item until
    after the ordered extent is written out.  This patch does 3 things,
    
    1) It moves the reservation clearing stuff into the ordered code, so when
    we remove the ordered extent we remove the reservation.
    2) It adds a EXTENT_DO_ACCOUNTING flag that gets passed when we clear
    delalloc bits in the cases where we want to clear the metadata reservation
    when we clear the delalloc extent, in the case that we do an inline extent
    or we invalidate the page.
    3) It adds another waitqueue to the space info so that when we start a fs
    wide delalloc flush, anybody else who also hits that area will simply wait
    for the flush to finish and then try to make their allocation.
    
    This has been tested thoroughly to make sure we did not regress on
    performance.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1b920ffc6a59..dbdada569507 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -699,6 +699,9 @@ struct btrfs_space_info {
 
 	int allocating_chunk;
 	wait_queue_head_t wait;
+
+	int flushing;
+	wait_queue_head_t flush_wait;
 };
 
 /*

commit 61d92c328c16419fc96dc50dd16f8b8c695409ec
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Oct 2 19:11:56 2009 -0400

    Btrfs: fix deadlock on async thread startup
    
    The btrfs async worker threads are used for a wide variety of things,
    including processing bio end_io functions.  This means that when
    the endio threads aren't running, the rest of the FS isn't
    able to do the final processing required to clear PageWriteback.
    
    The endio threads also try to exit as they become idle and
    start more as the work piles up.  The problem is that starting more
    threads means kthreadd may need to allocate ram, and that allocation
    may wait until the global number of writeback pages on the system is
    below a certain limit.
    
    The result of that throttling is that end IO threads wait on
    kthreadd, who is waiting on IO to end, which will never happen.
    
    This commit fixes the deadlock by handing off thread startup to a
    dedicated thread.  It also fixes a bug where the on-demand thread
    creation was creating far too many threads because it didn't take into
    account threads being started by other procs.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8184f2feb2f3..1b920ffc6a59 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -907,6 +907,7 @@ struct btrfs_fs_info {
 	 * A third pool does submit_bio to avoid deadlocking with the other
 	 * two
 	 */
+	struct btrfs_workers generic_worker;
 	struct btrfs_workers workers;
 	struct btrfs_workers delalloc_workers;
 	struct btrfs_workers endio_workers;

commit 0efe5e32c8729ef44b00d9a7203e4c99a6378b27
Merge: e6a0a8bfef10 9c2693c9243b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 1 20:23:15 2009 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: fix data space leak fix
      Btrfs: remove duplicates of filemap_ helpers
      Btrfs: take i_mutex before generic_write_checks
      Btrfs: fix arguments to btrfs_wait_on_page_writeback_range
      Btrfs: fix deadlock with free space handling and user transactions
      Btrfs: fix error cases for ioctl transactions
      Btrfs: Use CONFIG_BTRFS_POSIX_ACL to enable ACL code
      Btrfs: introduce missing kfree
      Btrfs: Fix setting umask when POSIX ACLs are not enabled
      Btrfs: proper -ENOSPC handling

commit 828c09509b9695271bcbdc53e9fc9a6a737148d2
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Thu Oct 1 15:43:56 2009 -0700

    const: constify remaining file_operations
    
    [akpm@linux-foundation.org: fix KVM]
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 80599b4e42bd..4484eb3408af 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2326,7 +2326,7 @@ int btrfs_sync_file(struct file *file, struct dentry *dentry, int datasync);
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
 			    int skip_pinned);
 int btrfs_check_file(struct btrfs_root *root, struct inode *inode);
-extern struct file_operations btrfs_file_operations;
+extern const struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
 		       u64 start, u64 end, u64 locked_end,

commit 3baf0bed0a5adab95c7599d2f27124c74692ef28
Author: Chris Ball <cjb@laptop.org>
Date:   Tue Sep 29 13:51:05 2009 -0400

    Btrfs: Use CONFIG_BTRFS_POSIX_ACL to enable ACL code
    
    We've already defined CONFIG_BTRFS_POSIX_ACL in Kconfig, but we're
    currently not using it and are testing CONFIG_FS_POSIX_ACL instead.
    CONFIG_FS_POSIX_ACL states "Never use this symbol for ifdefs".
    
    Signed-off-by: Chris Ball <cjb@laptop.org>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b3959a150c3b..8184f2feb2f3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2366,7 +2366,7 @@ int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 
 /* acl.c */
-#ifdef CONFIG_FS_POSIX_ACL
+#ifdef CONFIG_BTRFS_POSIX_ACL
 int btrfs_check_acl(struct inode *inode, int mask);
 #else
 #define btrfs_check_acl NULL

commit 9ed74f2dba6ebf9f30b80554290bfc73cc3ef083
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Sep 11 16:12:44 2009 -0400

    Btrfs: proper -ENOSPC handling
    
    At the start of a transaction we do a btrfs_reserve_metadata_space() and
    specify how many items we plan on modifying.  Then once we've done our
    modifications and such, just call btrfs_unreserve_metadata_space() for
    the same number of items we reserved.
    
    For keeping track of metadata needed for data I've had to add an extent_io op
    for when we merge extents.  This lets us track space properly when we are doing
    sequential writes, so we don't end up reserving way more metadata space than
    what we need.
    
    The only place where the metadata space accounting is not done is in the
    relocation code.  This is because Yan is going to be reworking that code in the
    near future, so running btrfs-vol -b could still possibly result in a ENOSPC
    related panic.  This patch also turns off the metadata_ratio stuff in order to
    allow users to more efficiently use their disk space.
    
    This patch makes it so we track how much metadata we need for an inode's
    delayed allocation extents by tracking how many extents are currently
    waiting for allocation.  It introduces two new callbacks for the
    extent_io tree's, merge_extent_hook and split_extent_hook.  These help
    us keep track of when we merge delalloc extents together and split them
    up.  Reservations are handled prior to any actually dirty'ing occurs,
    and then we unreserve after we dirty.
    
    btrfs_unreserve_metadata_for_delalloc() will make the appropriate
    unreservations as needed based on the number of reservations we
    currently have and the number of extents we currently have.  Doing the
    reservation outside of doing any of the actual dirty'ing lets us do
    things like filemap_flush() the inode to try and force delalloc to
    happen, or as a last resort actually start allocation on all delalloc
    inodes in the fs.  This has survived dbench, fs_mark and an fsx torture
    test.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 80599b4e42bd..b3959a150c3b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -675,18 +675,19 @@ struct btrfs_space_info {
 				   current allocations */
 	u64 bytes_readonly;	/* total bytes that are read only */
 	u64 bytes_super;	/* total bytes reserved for the super blocks */
-
-	/* delalloc accounting */
-	u64 bytes_delalloc;	/* number of bytes reserved for allocation,
-				   this space is not necessarily reserved yet
-				   by the allocator */
+	u64 bytes_root;		/* the number of bytes needed to commit a
+				   transaction */
 	u64 bytes_may_use;	/* number of bytes that may be used for
-				   delalloc */
+				   delalloc/allocations */
+	u64 bytes_delalloc;	/* number of bytes currently reserved for
+				   delayed allocation */
 
 	int full;		/* indicates that we cannot allocate any more
 				   chunks for this space */
 	int force_alloc;	/* set if we need to force a chunk alloc for
 				   this space */
+	int force_delalloc;	/* make people start doing filemap_flush until
+				   we're under a threshold */
 
 	struct list_head list;
 
@@ -695,6 +696,9 @@ struct btrfs_space_info {
 	spinlock_t lock;
 	struct rw_semaphore groups_sem;
 	atomic_t caching_threads;
+
+	int allocating_chunk;
+	wait_queue_head_t wait;
 };
 
 /*
@@ -2022,7 +2026,12 @@ u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
 
-int btrfs_check_metadata_free_space(struct btrfs_root *root);
+int btrfs_reserve_metadata_space(struct btrfs_root *root, int num_items);
+int btrfs_unreserve_metadata_space(struct btrfs_root *root, int num_items);
+int btrfs_unreserve_metadata_for_delalloc(struct btrfs_root *root,
+					  struct inode *inode, int num_items);
+int btrfs_reserve_metadata_for_delalloc(struct btrfs_root *root,
+					struct inode *inode, int num_items);
 int btrfs_check_data_free_space(struct btrfs_root *root, struct inode *inode,
 				u64 bytes);
 void btrfs_free_reserved_data_space(struct btrfs_root *root,

commit 1b2da372b0324b5c604fc8790e70a7efbeacb0b6
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Sep 11 16:11:20 2009 -0400

    Btrfs: account for space used by the super mirrors
    
    As we get closer to proper -ENOSPC handling in btrfs, we need more accurate
    space accounting for the space info's.  Currently we exclude the free space for
    the super mirrors, but the space they take up isn't accounted for in any of the
    counters.  This patch introduces bytes_super, which keeps track of the amount
    of bytes used for a super mirror in the block group cache and space info.  This
    makes sure that our free space caclucations will be completely accurate.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2b15fb97d23f..80599b4e42bd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -674,6 +674,7 @@ struct btrfs_space_info {
 	u64 bytes_reserved;	/* total bytes the allocator has reserved for
 				   current allocations */
 	u64 bytes_readonly;	/* total bytes that are read only */
+	u64 bytes_super;	/* total bytes reserved for the super blocks */
 
 	/* delalloc accounting */
 	u64 bytes_delalloc;	/* number of bytes reserved for allocation,
@@ -746,6 +747,7 @@ struct btrfs_block_group_cache {
 	spinlock_t lock;
 	u64 pinned;
 	u64 reserved;
+	u64 bytes_super;
 	u64 flags;
 	u64 sectorsize;
 	int extents_thresh;

commit ba1bf4818baf68d914ef9e3b06fbea6acb674fe4
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Sep 11 16:11:19 2009 -0400

    Btrfs: make balance code choose more wisely when relocating
    
    Currently, we can panic the box if the first block group we go to move is of a
    type where there is no space left to move those extents.  For example, if we
    fill the disk up with data, and then we try to balance and we have no room to
    move the data nor room to allocate new chunks, we will panic.  Change this by
    checking to see if we have room to move this chunk around, and if not, return
    -ENOSPC and move on to the next chunk.  This will make sure we remove block
    groups that are moveable, like if we have alot of empty metadata block groups,
    and then that way we make room to be able to balance our data chunks as well.
    Tested this with an fs that would panic on btrfs-vol -b normally, but no longer
    panics with this patch.
    
    V1->V2:
    -actually search for a free extent on the device to make sure we can allocate a
    chunk if need be.
    
    -fix btrfs_shrink_device to make sure we actually try to relocate all the
    chunks, and then if we can't return -ENOSPC so if we are doing a btrfs-vol -r
    we don't remove the device with data still on it.
    
    -check to make sure the block group we are going to relocate isn't the last one
    in that particular space
    
    -fix a bug in btrfs_shrink_device where we would change the device's size and
    not fix it if we fail to do our relocate
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bc57e236ac64..2b15fb97d23f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2006,6 +2006,7 @@ int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 int btrfs_extent_readonly(struct btrfs_root *root, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_root *root);
+int btrfs_can_relocate(struct btrfs_root *root, u64 bytenr);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, u64 bytes_used,
 			   u64 type, u64 chunk_objectid, u64 chunk_offset,

commit 76dda93c6ae2c1dc3e6cde34569d6aca26b0c918
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Mon Sep 21 16:00:26 2009 -0400

    Btrfs: add snapshot/subvolume destroy ioctl
    
    This patch adds snapshot/subvolume destroy ioctl.  A subvolume that isn't being
    used and doesn't contains links to other subvolumes can be destroyed.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6ade48b227e9..bc57e236ac64 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -839,9 +839,7 @@ struct btrfs_fs_info {
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;
 	struct mutex chunk_mutex;
-	struct mutex drop_mutex;
 	struct mutex volume_mutex;
-	struct mutex tree_reloc_mutex;
 	/*
 	 * this protects the ordered operations list only while we are
 	 * processing all of the entries on it.  This way we make
@@ -852,6 +850,10 @@ struct btrfs_fs_info {
 	struct mutex ordered_operations_mutex;
 	struct rw_semaphore extent_commit_sem;
 
+	struct rw_semaphore subvol_sem;
+
+	struct srcu_struct subvol_srcu;
+
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
@@ -2142,6 +2144,7 @@ int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 int btrfs_search_root(struct btrfs_root *root, u64 search_start,
 		      u64 *found_objectid);
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);
+int btrfs_find_orphan_roots(struct btrfs_root *tree_root);
 int btrfs_set_root_node(struct btrfs_root_item *item,
 			struct extent_buffer *node);
 /* dir-item.c */
@@ -2273,7 +2276,7 @@ int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end);
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *new_root, struct dentry *dentry,
+			     struct btrfs_root *new_root,
 			     u64 new_dirid, u64 alloc_hint);
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio, unsigned long bio_flags);
@@ -2289,6 +2292,7 @@ int btrfs_write_inode(struct inode *inode, int wait);
 void btrfs_dirty_inode(struct inode *inode);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
+void btrfs_drop_inode(struct inode *inode);
 int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
@@ -2306,6 +2310,8 @@ int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 void btrfs_orphan_cleanup(struct btrfs_root *root);
 int btrfs_cont_expand(struct inode *inode, loff_t size);
+int btrfs_invalidate_inodes(struct btrfs_root *root);
+extern struct dentry_operations btrfs_dentry_operations;
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit 4df27c4d5cc1dda54ed7d0a8389347f2df359cf9
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Mon Sep 21 15:56:00 2009 -0400

    Btrfs: change how subvolumes are organized
    
    btrfs allows subvolumes and snapshots anywhere in the directory tree.
    If we snapshot a subvolume that contains a link to other subvolume
    called subvolA, subvolA can be accessed through both the original
    subvolume and the snapshot. This is similar to creating hard link to
    directory, and has the very similar problems.
    
    The aim of this patch is enforcing there is only one access point to
    each subvolume. Only the first directory entry (the one added when
    the subvolume/snapshot was created) is treated as valid access point.
    The first directory entry is distinguished by checking root forward
    reference. If the corresponding root forward reference is missing,
    we know the entry is not the first one.
    
    This patch also adds snapshot/subvolume rename support, the code
    allows rename subvolume link across subvolumes.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 746a9acd2189..6ade48b227e9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -114,6 +114,10 @@ struct btrfs_ordered_sum;
  */
 #define BTRFS_DEV_ITEMS_OBJECTID 1ULL
 
+#define BTRFS_BTREE_INODE_OBJECTID 1
+
+#define BTRFS_EMPTY_SUBVOL_DIR_OBJECTID 2
+
 /*
  * we can actually store much bigger names, but lets not confuse the rest
  * of linux
@@ -792,6 +796,8 @@ struct btrfs_fs_info {
 
 	/* the log root tree is a directory of all the other log roots */
 	struct btrfs_root *log_root_tree;
+
+	spinlock_t fs_roots_radix_lock;
 	struct radix_tree_root fs_roots_radix;
 
 	/* block group cache stuff */
@@ -1011,6 +1017,8 @@ struct btrfs_root {
 	u64 highest_objectid;
 	int ref_cows;
 	int track_dirty;
+	int in_radix;
+
 	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
@@ -2111,12 +2119,15 @@ int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct extent_buffer *parent);
 /* root-item.c */
 int btrfs_find_root_ref(struct btrfs_root *tree_root,
-		   struct btrfs_path *path,
-		   u64 root_id, u64 ref_id);
+			struct btrfs_path *path,
+			u64 root_id, u64 ref_id);
 int btrfs_add_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *tree_root,
-		       u64 root_id, u8 type, u64 ref_id,
-		       u64 dirid, u64 sequence,
+		       u64 root_id, u64 ref_id, u64 dirid, u64 sequence,
+		       const char *name, int name_len);
+int btrfs_del_root_ref(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *tree_root,
+		       u64 root_id, u64 ref_id, u64 dirid, u64 *sequence,
 		       const char *name, int name_len);
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_key *key);
@@ -2149,6 +2160,10 @@ btrfs_lookup_dir_index_item(struct btrfs_trans_handle *trans,
 			    struct btrfs_path *path, u64 dir,
 			    u64 objectid, const char *name, int name_len,
 			    int mod);
+struct btrfs_dir_item *
+btrfs_search_dir_index_item(struct btrfs_root *root,
+			    struct btrfs_path *path, u64 dirid,
+			    const char *name, int name_len);
 struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,
 			      struct btrfs_path *path,
 			      const char *name, int name_len);
@@ -2171,6 +2186,7 @@ int btrfs_insert_orphan_item(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 offset);
 int btrfs_del_orphan_item(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, u64 offset);
+int btrfs_find_orphan_item(struct btrfs_root *root, u64 offset);
 
 /* inode-map.c */
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
@@ -2243,6 +2259,10 @@ int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
 int btrfs_add_link(struct btrfs_trans_handle *trans,
 		   struct inode *parent_inode, struct inode *inode,
 		   const char *name, int name_len, int add_backref, u64 index);
+int btrfs_unlink_subvol(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root,
+			struct inode *dir, u64 objectid,
+			const char *name, int name_len);
 int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       struct inode *inode, u64 new_size,

commit 13a8a7c8c47e542b3cdb45bec3f431f96af79361
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Mon Sep 21 15:56:00 2009 -0400

    Btrfs: do not reuse objectid of deleted snapshot/subvol
    
    The new back reference format does not allow reusing objectid of
    deleted snapshot/subvol. So we use ++highest_objectid to allocate
    objectid for new snapshot/subvol.
    
    Now we use ++highest_objectid to allocate objectid for both new inode
    and new snapshot/subvolume, so this patch removes 'find hole' code in
    btrfs_find_free_objectid.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3b6df7140575..746a9acd2189 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1007,8 +1007,8 @@ struct btrfs_root {
 	u32 stripesize;
 
 	u32 type;
-	u64 highest_inode;
-	u64 last_inode_alloc;
+
+	u64 highest_objectid;
 	int ref_cows;
 	int track_dirty;
 	u64 defrag_trans_start;

commit 11833d66be94b514652466802100378046c16b72
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Fri Sep 11 16:11:19 2009 -0400

    Btrfs: improve async block group caching
    
    This patch gets rid of two limitations of async block group caching.
    The old code delays handling pinned extents when block group is in
    caching. To allocate logged file extents, the old code need wait
    until block group is fully cached. To get rid of the limitations,
    This patch introduces a data structure to track the progress of
    caching. Base on the caching progress, we know which extents should
    be added to the free space cache when handling the pinned extents.
    The logged file extents are also handled in a similar way.
    
    This patch also changes how pinned extents are tracked. The old
    code uses one tree to track pinned extents, and copy the pinned
    extents tree at transaction commit time. This patch makes it use
    two trees to track pinned extents. One tree for extents that are
    pinned in the running transaction, one tree for extents that can
    be unpinned. At transaction commit time, we swap the two trees.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 732d5b884aa7..3b6df7140575 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -726,6 +726,15 @@ enum btrfs_caching_type {
 	BTRFS_CACHE_FINISHED	= 2,
 };
 
+struct btrfs_caching_control {
+	struct list_head list;
+	struct mutex mutex;
+	wait_queue_head_t wait;
+	struct btrfs_block_group_cache *block_group;
+	u64 progress;
+	atomic_t count;
+};
+
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
@@ -742,8 +751,9 @@ struct btrfs_block_group_cache {
 	int dirty;
 
 	/* cache tracking stuff */
-	wait_queue_head_t caching_q;
 	int cached;
+	struct btrfs_caching_control *caching_ctl;
+	u64 last_byte_to_unpin;
 
 	struct btrfs_space_info *space_info;
 
@@ -788,7 +798,8 @@ struct btrfs_fs_info {
 	spinlock_t block_group_cache_lock;
 	struct rb_root block_group_cache_tree;
 
-	struct extent_io_tree pinned_extents;
+	struct extent_io_tree freed_extents[2];
+	struct extent_io_tree *pinned_extents;
 
 	/* logical->physical extent mapping */
 	struct btrfs_mapping_tree mapping_tree;
@@ -825,8 +836,6 @@ struct btrfs_fs_info {
 	struct mutex drop_mutex;
 	struct mutex volume_mutex;
 	struct mutex tree_reloc_mutex;
-	struct rw_semaphore extent_commit_sem;
-
 	/*
 	 * this protects the ordered operations list only while we are
 	 * processing all of the entries on it.  This way we make
@@ -835,10 +844,12 @@ struct btrfs_fs_info {
 	 * before jumping into the main commit.
 	 */
 	struct mutex ordered_operations_mutex;
+	struct rw_semaphore extent_commit_sem;
 
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
+	struct list_head caching_block_groups;
 
 	atomic_t nr_async_submits;
 	atomic_t async_submit_draining;
@@ -1920,8 +1931,8 @@ void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
-int btrfs_update_pinned_extents(struct btrfs_root *root,
-				u64 bytenr, u64 num, int pin);
+int btrfs_pin_extent(struct btrfs_root *root,
+		     u64 bytenr, u64 num, int reserved);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
@@ -1971,9 +1982,10 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      u64 root_objectid, u64 owner, u64 offset);
 
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_prepare_extent_commit(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *root,
-			       struct extent_io_tree *unpin);
+			       struct btrfs_root *root);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,
@@ -2006,7 +2018,6 @@ void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
 				 u64 bytes);
 void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
 			      u64 bytes);
-void btrfs_free_pinned_extents(struct btrfs_fs_info *info);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit 83ebade34bc1a90d0c3f77b87b940f336d075fda
Merge: 74fca6a42863 93c82d575055
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 11 19:07:25 2009 -0400

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable

commit a1ed835e1ab5795f91b198d08c43e2f56848dcf3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 11 12:27:37 2009 -0400

    Btrfs: Fix extent replacment race
    
    Data COW means that whenever we write to a file, we replace any old
    extent pointers with new ones.  There was a window where a readpage
    might find the old extent pointers on disk and cache them in the
    extent_map tree in ram in the middle of a given write replacing them.
    
    Even though both the readpage and the write had their respective bytes
    in the file locked, the extent readpage inserts may cover more bytes than
    it had locked down.
    
    This commit closes the race by keeping the new extent pinned in the extent
    map tree until after the on-disk btree is properly setup with the new
    extent pointers.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 38eeb6c49c8a..1ceab8b4d6dc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2292,7 +2292,7 @@ extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
 		       u64 start, u64 end, u64 locked_end,
-		       u64 inline_limit, u64 *hint_block);
+		       u64 inline_limit, u64 *hint_block, int drop_cache);
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode, u64 start, u64 end);

commit ec6a8679fa8ce977c8b7f86238455b494699de74
Merge: db06816cb9ce f36f3042eae2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 30 16:46:48 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: be more polite in the async caching threads
      Btrfs: preserve commit_root for async caching

commit 276e680d192a67d222fcea51af37b056feffb665
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Jul 30 09:40:40 2009 -0400

    Btrfs: preserve commit_root for async caching
    
    The async block group caching code uses the commit_root pointer
    to get a stable version of the extent allocation tree for scanning.
    This copy of the tree root isn't going to change and it significantly
    reduces the complexity of the scanning code.
    
    During a commit, we have a loop where we update the extent allocation
    tree root.  We need to loop because updating the root pointer in
    the tree of tree roots may allocate blocks which may change the
    extent allocation tree.
    
    Right now the commit_root pointer is changed inside this loop.  It
    is more correct to change the commit_root pointer only after all the
    looping is done.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 17ad92c29cfd..38eeb6c49c8a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -827,6 +827,7 @@ struct btrfs_fs_info {
 	struct mutex drop_mutex;
 	struct mutex volume_mutex;
 	struct mutex tree_reloc_mutex;
+	struct rw_semaphore extent_commit_sem;
 
 	/*
 	 * this protects the ordered operations list only while we are
@@ -961,9 +962,6 @@ struct btrfs_root {
 	/* the node lock is held while changing the node pointer */
 	spinlock_t node_lock;
 
-	/* taken when updating the commit root */
-	struct rw_semaphore commit_root_sem;
-
 	struct extent_buffer *commit_root;
 	struct btrfs_root *log_root;
 	struct btrfs_root *reloc_root;

commit 655c5d8fc110a9d4f90cc831bd009936f3e8df28
Merge: ce4adcc6e532 f25784b35f59
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 28 14:27:06 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (22 commits)
      Btrfs: Fix async caching interaction with unmount
      Btrfs: change how we unpin extents
      Btrfs: Correct redundant test in add_inode_ref
      Btrfs: find smallest available device extent during chunk allocation
      Btrfs: clear all space_info->full after removing a block group
      Btrfs: make flushoncommit mount option correctly wait on ordered_extents
      Btrfs: Avoid delayed reference update looping
      Btrfs: Fix ordering of key field checks in btrfs_previous_item
      Btrfs: find_free_dev_extent doesn't handle holes at the start of the device
      Btrfs: Remove code duplication in comp_keys
      Btrfs: async block group caching
      Btrfs: use hybrid extents+bitmap rb tree for free space
      Btrfs: Fix crash on read failures at mount
      Btrfs: remove of redundant btrfs_header_level
      Btrfs: adjust NULL test
      Btrfs: Remove broken sanity check from btrfs_rmap_block()
      Btrfs: convert nested spin_lock_irqsave to spin_lock
      Btrfs: make sure all dirty blocks are written at commit time
      Btrfs: fix locking issue in btrfs_find_next_key
      Btrfs: fix double increment of path->slots[0] in btrfs_next_leaf
      ...

commit 68b38550ddbea13d296184bf69edff387618b1d3
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 27 13:57:01 2009 -0400

    Btrfs: change how we unpin extents
    
    We are racy with async block caching and unpinning extents.  This patch makes
    things much less complicated by only unpinning the extent if the block group is
    cached.  We check the block_group->cached var under the block_group->lock spin
    lock.  If it is set to BTRFS_CACHE_FINISHED then we update the pinned counters,
    and unpin the extent and add the free space back.  If it is not set to this, we
    start the caching of the block group so the next time we unpin extents we can
    unpin the extent.  This keeps us from racing with the async caching threads,
    lets us kill the fs wide async thread counter, and keeps us from having to set
    DELALLOC bits for every extent we hit if there are caching kthreads going.
    
    One thing that needed to be changed was btrfs_free_super_mirror_extents.  Now
    instead of just looking for LOCKED extents, we also look for DIRTY extents,
    since we could have left some extents pinned in the previous transaction that
    will never get freed now that we are unmounting, which would cause us to leak
    memory.  So btrfs_free_super_mirror_extents has been changed to
    btrfs_free_pinned_extents, and it will clear the extents locked for the super
    mirror, and any remaining pinned extents that may be present.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 42b03c4ee494..17ad92c29cfd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -845,7 +845,6 @@ struct btrfs_fs_info {
 	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;
 	atomic_t async_delalloc_pages;
-	atomic_t async_caching_threads;
 
 	/*
 	 * this is used by the balancing code to wait for all the pending
@@ -1926,7 +1925,7 @@ int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_update_pinned_extents(struct btrfs_root *root,
-				u64 bytenr, u64 num, int pin, int mark_free);
+				u64 bytenr, u64 num, int pin);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
@@ -2011,7 +2010,7 @@ void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
 				 u64 bytes);
 void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
 			      u64 bytes);
-void btrfs_free_super_mirror_extents(struct btrfs_fs_info *info);
+void btrfs_free_pinned_extents(struct btrfs_fs_info *info);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit 817d52f8dba26d0295c26035531c30ce5f1e3c3e
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 13 21:29:25 2009 -0400

    Btrfs: async block group caching
    
    This patch moves the caching of the block group off to a kthread in order to
    allow people to allocate sooner.  Instead of blocking up behind the caching
    mutex, we instead kick of the caching kthread, and then attempt to make an
    allocation.  If we cannot, we wait on the block groups caching waitqueue, which
    the caching kthread will wake the waiting threads up everytime it finds 2 meg
    worth of space, and then again when its finished caching.  This is how I tested
    the speedup from this
    
    mkfs the disk
    mount the disk
    fill the disk up with fs_mark
    unmount the disk
    mount the disk
    time touch /mnt/foo
    
    Without my changes this took 11 seconds on my box, with these changes it now
    takes 1 second.
    
    Another change thats been put in place is we lock the super mirror's in the
    pinned extent map in order to keep us from adding that stuff as free space when
    caching the block group.  This doesn't really change anything else as far as the
    pinned extent map is concerned, since for actual pinned extents we use
    EXTENT_DIRTY, but it does mean that when we unmount we have to go in and unlock
    those extents to keep from leaking memory.
    
    I've also added a check where when we are reading block groups from disk, if the
    amount of space used == the size of the block group, we go ahead and mark the
    block group as cached.  This drastically reduces the amount of time it takes to
    cache the block groups.  Using the same test as above, except doing a dd to a
    file and then unmounting, it used to take 33 seconds to umount, now it takes 3
    seconds.
    
    This version uses the commit_root in the caching kthread, and then keeps track
    of how many async caching threads are running at any given time so if one of the
    async threads is still running as we cross transactions we can wait until its
    finished before handling the pinned extents.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0cbf3491bb7c..42b03c4ee494 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -691,6 +691,7 @@ struct btrfs_space_info {
 	struct list_head block_groups;
 	spinlock_t lock;
 	struct rw_semaphore groups_sem;
+	atomic_t caching_threads;
 };
 
 /*
@@ -721,11 +722,17 @@ struct btrfs_free_cluster {
 	struct list_head block_group_list;
 };
 
+enum btrfs_caching_type {
+	BTRFS_CACHE_NO		= 0,
+	BTRFS_CACHE_STARTED	= 1,
+	BTRFS_CACHE_FINISHED	= 2,
+};
+
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
+	struct btrfs_fs_info *fs_info;
 	spinlock_t lock;
-	struct mutex cache_mutex;
 	u64 pinned;
 	u64 reserved;
 	u64 flags;
@@ -733,15 +740,19 @@ struct btrfs_block_group_cache {
 	int extents_thresh;
 	int free_extents;
 	int total_bitmaps;
-	int cached;
 	int ro;
 	int dirty;
 
+	/* cache tracking stuff */
+	wait_queue_head_t caching_q;
+	int cached;
+
 	struct btrfs_space_info *space_info;
 
 	/* free space cache stuff */
 	spinlock_t tree_lock;
 	struct rb_root free_space_offset;
+	u64 free_space;
 
 	/* block group cache stuff */
 	struct rb_node cache_node;
@@ -834,6 +845,7 @@ struct btrfs_fs_info {
 	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;
 	atomic_t async_delalloc_pages;
+	atomic_t async_caching_threads;
 
 	/*
 	 * this is used by the balancing code to wait for all the pending
@@ -950,6 +962,9 @@ struct btrfs_root {
 	/* the node lock is held while changing the node pointer */
 	spinlock_t node_lock;
 
+	/* taken when updating the commit root */
+	struct rw_semaphore commit_root_sem;
+
 	struct extent_buffer *commit_root;
 	struct btrfs_root *log_root;
 	struct btrfs_root *reloc_root;
@@ -1911,7 +1926,7 @@ int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_update_pinned_extents(struct btrfs_root *root,
-				u64 bytenr, u64 num, int pin);
+				u64 bytenr, u64 num, int pin, int mark_free);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
@@ -1996,6 +2011,7 @@ void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
 				 u64 bytes);
 void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
 			      u64 bytes);
+void btrfs_free_super_mirror_extents(struct btrfs_fs_info *info);
 /* ctree.c */
 int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
 		     int level, int *slot);

commit 963030817060e4f109be1993b9ae8f81dbf5e11a
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 13 21:29:25 2009 -0400

    Btrfs: use hybrid extents+bitmap rb tree for free space
    
    Currently btrfs has a problem where it can use a ridiculous amount of RAM simply
    tracking free space.  As free space gets fragmented, we end up with thousands of
    entries on an rb-tree per block group, which usually spans 1 gig of area.  Since
    we currently don't ever flush free space cache back to disk this gets to be a
    bit unweildly on large fs's with lots of fragmentation.
    
    This patch solves this problem by using PAGE_SIZE bitmaps for parts of the free
    space cache.  Initially we calculate a threshold of extent entries we can
    handle, which is however many extent entries we can cram into 16k of ram.  The
    maximum amount of RAM that should ever be used to track 1 gigabyte of diskspace
    will be 32k of RAM, which scales much better than we did before.
    
    Once we pass the extent threshold, we start adding bitmaps and using those
    instead for tracking the free space.  This patch also makes it so that any free
    space thats less than 4 * sectorsize we go ahead and put into a bitmap.  This is
    nice since we try and allocate out of the front of a block group, so if the
    front of a block group is heavily fragmented and then has a huge chunk of free
    space at the end, we go ahead and add the fragmented areas to bitmaps and use a
    normal extent entry to track the big chunk at the back of the block group.
    
    I've also taken the opportunity to revamp how we search for free space.
    Previously we indexed free space via an offset indexed rb tree and a bytes
    indexed rb tree.  I've dropped the bytes indexed rb tree and use only the offset
    indexed rb tree.  This cuts the number of tree operations we were doing
    previously down by half, and gives us a little bit of a better allocation
    pattern since we will always start from a specific offset and search forward
    from there, instead of searching for the size we need and try and get it as
    close as possible to the offset we want.
    
    I've given this a healthy amount of testing pre-new format stuff, as well as
    post-new format stuff.  I've booted up my fedora box which is installed on btrfs
    with this patch and ran with it for a few days without issues.  I've not seen
    any performance regressions in any of my tests.
    
    Since the last patch Yan Zheng fixed a problem where we could have overlapping
    entries, so updating their offset inline would cause problems.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index da0763135bf0..0cbf3491bb7c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -709,6 +709,9 @@ struct btrfs_free_cluster {
 	/* first extent starting offset */
 	u64 window_start;
 
+	/* if this cluster simply points at a bitmap in the block group */
+	bool points_to_bitmap;
+
 	struct btrfs_block_group_cache *block_group;
 	/*
 	 * when a cluster is allocated from a block group, we put the
@@ -726,6 +729,10 @@ struct btrfs_block_group_cache {
 	u64 pinned;
 	u64 reserved;
 	u64 flags;
+	u64 sectorsize;
+	int extents_thresh;
+	int free_extents;
+	int total_bitmaps;
 	int cached;
 	int ro;
 	int dirty;
@@ -734,7 +741,6 @@ struct btrfs_block_group_cache {
 
 	/* free space cache stuff */
 	spinlock_t tree_lock;
-	struct rb_root free_space_bytes;
 	struct rb_root free_space_offset;
 
 	/* block group cache stuff */

commit 1bec1aed1e7e632b3cc43b6807c2b4dcd1572e28
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jul 22 09:59:00 2009 -0400

    Btrfs: fix definition of struct btrfs_extent_inline_ref
    
    use __le64 instead of u64 in on-disk structure definition.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a404ecc53eb1..da0763135bf0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -483,7 +483,7 @@ struct btrfs_shared_data_ref {
 
 struct btrfs_extent_inline_ref {
 	u8 type;
-	u64 offset;
+	__le64 offset;
 } __attribute__ ((__packed__));
 
 /* old style backrefs item */

commit 5291a12f0503e31e0b8e90ee8e4997d59c1c3aad
Merge: c7cba0623fc1 68f5a38c3ea4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 2 16:52:38 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: fix error message formatting
      Btrfs: fix use after free in btrfs_start_workers fail path
      Btrfs: honor nodatacow/sum mount options for new files
      Btrfs: update backrefs while dropping snapshot
      Btrfs: account for space we may use in fallocate
      Btrfs: fix the file clone ioctl for preallocated extents
      Btrfs: don't log the inode in file_write while growing the file

commit 2c47e605a91dde6b0514f689645e7ab336c8592a
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Sat Jun 27 21:07:35 2009 -0400

    Btrfs: update backrefs while dropping snapshot
    
    The new backref format has restriction on type of backref item.  If a tree
    block isn't referenced by its owner tree, full backrefs must be used for the
    pointers in it. When a tree block loses its owner tree's reference, backrefs
    for the pointers in it should be updated to full backrefs. Current
    btrfs_drop_snapshot misses the code that updates backrefs, so it's unsafe for
    general use.
    
    This patch adds backrefs update code to btrfs_drop_snapshot.  It isn't a
    problem in the restricted form btrfs_drop_snapshot is used today, but for
    general snapshot deletion this update is required.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 03441a99ea38..a404ecc53eb1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2076,8 +2076,7 @@ static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
-int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
-			*root);
+int btrfs_drop_snapshot(struct btrfs_root *root, int update_ref);
 int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct extent_buffer *node,

commit 5affd88a104af43f0063a12ad1ee4c7a587945dc
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 8 19:55:32 2009 -0400

    switch btrfs to inode->i_acl
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 03441a99ea38..2779c2f5360a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -41,8 +41,6 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAGIC "_BHRfS_M"
 
-#define BTRFS_ACL_NOT_CACHED    ((void *)-1)
-
 #define BTRFS_MAX_LEVEL 8
 
 #define BTRFS_COMPAT_EXTENT_TREE_V0

commit 7df336ec1266dccbb253bac52c529d3dcc7c22d0
Author: Al Viro <viro@ZenIV.linux.org.uk>
Date:   Wed Jun 10 11:36:43 2009 -0400

    Fix btrfs when ACLs are configured out
    
    ... otherwise generic_permission() will allow *anything* for all
    files you don't own and that have some group permissions.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4d6e0b6f21ea..03441a99ea38 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2301,7 +2301,11 @@ int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 
 /* acl.c */
+#ifdef CONFIG_FS_POSIX_ACL
 int btrfs_check_acl(struct inode *inode, int mask);
+#else
+#define btrfs_check_acl NULL
+#endif
 int btrfs_init_acl(struct inode *inode, struct inode *dir);
 int btrfs_acl_chmod(struct inode *inode);
 

commit 6cbff00f4632c8060b06bfc9585805217f11e12e
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Apr 17 10:37:41 2009 +0200

    Btrfs: implement FS_IOC_GETFLAGS/SETFLAGS/GETVERSION
    
    Add support for the standard attributes set via chattr and read via
    lsattr.  Currently we store the attributes in the flags value in
    the btrfs inode, but I wonder whether we should split it into two so
    that we don't have to keep converting between the two formats.
    
    Remove the btrfs_clear_flag/btrfs_set_flag/btrfs_test_flag macros
    as they were confusing the existing code and got in the way of the
    new additions.
    
    Also add the FS_IOC_GETVERSION ioctl for getting i_generation as it's
    trivial.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5fa7d7d287a4..4d6e0b6f21ea 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1115,12 +1115,14 @@ struct btrfs_root {
 #define BTRFS_INODE_READONLY		(1 << 2)
 #define BTRFS_INODE_NOCOMPRESS		(1 << 3)
 #define BTRFS_INODE_PREALLOC		(1 << 4)
-#define btrfs_clear_flag(inode, flag)	(BTRFS_I(inode)->flags &= \
-					 ~BTRFS_INODE_##flag)
-#define btrfs_set_flag(inode, flag)	(BTRFS_I(inode)->flags |= \
-					 BTRFS_INODE_##flag)
-#define btrfs_test_flag(inode, flag)	(BTRFS_I(inode)->flags & \
-					 BTRFS_INODE_##flag)
+#define BTRFS_INODE_SYNC		(1 << 5)
+#define BTRFS_INODE_IMMUTABLE		(1 << 6)
+#define BTRFS_INODE_APPEND		(1 << 7)
+#define BTRFS_INODE_NODUMP		(1 << 8)
+#define BTRFS_INODE_NOATIME		(1 << 9)
+#define BTRFS_INODE_DIRSYNC		(1 << 10)
+
+
 /* some macros to generate set/get funcs for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple
  * one for u8:
@@ -2260,6 +2262,8 @@ int btrfs_cont_expand(struct inode *inode, loff_t size);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
+void btrfs_update_iflags(struct inode *inode);
+void btrfs_inherit_iflags(struct inode *inode, struct inode *dir);
 
 /* file.c */
 int btrfs_sync_file(struct file *file, struct dentry *dentry, int datasync);

commit c289811cc096c57ff35550ee8132793a4f9b5b59
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 10 09:51:32 2009 -0400

    Btrfs: autodetect SSD devices
    
    During mount, btrfs will check the queue nonrot flag
    for all the devices found in the FS.  If they are all
    non-rotating, SSD mode is enabled by default.
    
    If the FS was mounted with -o nossd, the non-rotating
    flag is ignored.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b9d8788b299e..5fa7d7d287a4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1101,6 +1101,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_NOTREELOG           (1 << 6)
 #define BTRFS_MOUNT_FLUSHONCOMMIT       (1 << 7)
 #define BTRFS_MOUNT_SSD_SPREAD		(1 << 8)
+#define BTRFS_MOUNT_NOSSD		(1 << 9)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 451d7585a8bb1b9bec0d676ce3dece1923164e55
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 9 20:28:34 2009 -0400

    Btrfs: add mount -o ssd_spread to spread allocations out
    
    Some SSDs perform best when reusing block numbers often, while
    others perform much better when clustering strictly allocates
    big chunks of unused space.
    
    The default mount -o ssd will find rough groupings of blocks
    where there are a bunch of free blocks that might have some
    allocated blocks mixed in.
    
    mount -o ssd_spread will make sure there are no allocated blocks
    mixed in.  It should perform better on lower end SSDs.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ce3ab4e13064..b9d8788b299e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1100,6 +1100,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_COMPRESS		(1 << 5)
 #define BTRFS_MOUNT_NOTREELOG           (1 << 6)
 #define BTRFS_MOUNT_FLUSHONCOMMIT       (1 << 7)
+#define BTRFS_MOUNT_SSD_SPREAD		(1 << 8)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 5d4f98a28c7d334091c1b7744f48a1acdd2a4ae0
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jun 10 10:45:14 2009 -0400

    Btrfs: Mixed back reference  (FORWARD ROLLING FORMAT CHANGE)
    
    This commit introduces a new kind of back reference for btrfs metadata.
    Once a filesystem has been mounted with this commit, IT WILL NO LONGER
    BE MOUNTABLE BY OLDER KERNELS.
    
    When a tree block in subvolume tree is cow'd, the reference counts of all
    extents it points to are increased by one.  At transaction commit time,
    the old root of the subvolume is recorded in a "dead root" data structure,
    and the btree it points to is later walked, dropping reference counts
    and freeing any blocks where the reference count goes to 0.
    
    The increments done during cow and decrements done after commit cancel out,
    and the walk is a very expensive way to go about freeing the blocks that
    are no longer referenced by the new btree root.  This commit reduces the
    transaction overhead by avoiding the need for dead root records.
    
    When a non-shared tree block is cow'd, we free the old block at once, and the
    new block inherits old block's references. When a tree block with reference
    count > 1 is cow'd, we increase the reference counts of all extents
    the new block points to by one, and decrease the old block's reference count by
    one.
    
    This dead tree avoidance code removes the need to modify the reference
    counts of lower level extents when a non-shared tree block is cow'd.
    But we still need to update back ref for all pointers in the block.
    This is because the location of the block is recorded in the back ref
    item.
    
    We can solve this by introducing a new type of back ref. The new
    back ref provides information about pointer's key, level and in which
    tree the pointer lives. This information allow us to find the pointer
    by searching the tree. The shortcoming of the new back ref is that it
    only works for pointers in tree blocks referenced by their owner trees.
    
    This is mostly a problem for snapshots, where resolving one of these
    fuzzy back references would be O(number_of_snapshots) and quite slow.
    The solution used here is to use the fuzzy back references in the common
    case where a given tree block is only referenced by one root,
    and use the full back references when multiple roots have a reference
    on a given block.
    
    This commit adds per subvolume red-black tree to keep trace of cached
    inodes. The red-black tree helps the balancing code to find cached
    inodes whose inode numbers within a given range.
    
    This commit improves the balancing code by introducing several data
    structures to keep the state of balancing. The most important one
    is the back ref cache. It caches how the upper level tree blocks are
    referenced. This greatly reduce the overhead of checking back ref.
    
    The improved balancing code scales significantly better with a large
    number of snapshots.
    
    This is a very large commit and was written in a number of
    pieces.  But, they depend heavily on the disk format change and were
    squashed together to make sure git bisect didn't end up in a
    bad state wrt space balancing or the format change.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4414a5d9983a..ce3ab4e13064 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -45,6 +45,8 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAX_LEVEL 8
 
+#define BTRFS_COMPAT_EXTENT_TREE_V0
+
 /*
  * files bigger than this get some pre-flushing when they are added
  * to the ordered operations list.  That way we limit the total
@@ -267,7 +269,18 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 }
 
 #define BTRFS_FSID_SIZE 16
-#define BTRFS_HEADER_FLAG_WRITTEN (1 << 0)
+#define BTRFS_HEADER_FLAG_WRITTEN	(1ULL << 0)
+#define BTRFS_HEADER_FLAG_RELOC		(1ULL << 1)
+#define BTRFS_SUPER_FLAG_SEEDING	(1ULL << 32)
+#define BTRFS_SUPER_FLAG_METADUMP	(1ULL << 33)
+
+#define BTRFS_BACKREF_REV_MAX		256
+#define BTRFS_BACKREF_REV_SHIFT		56
+#define BTRFS_BACKREF_REV_MASK		(((u64)BTRFS_BACKREF_REV_MAX - 1) << \
+					 BTRFS_BACKREF_REV_SHIFT)
+
+#define BTRFS_OLD_BACKREF_REV		0
+#define BTRFS_MIXED_BACKREF_REV		1
 
 /*
  * every tree block (leaf or node) starts with this header.
@@ -296,7 +309,6 @@ struct btrfs_header {
 					sizeof(struct btrfs_item) - \
 					sizeof(struct btrfs_file_extent_item))
 
-#define BTRFS_SUPER_FLAG_SEEDING (1ULL << 32)
 
 /*
  * this is a very generous portion of the super block, giving us
@@ -355,9 +367,12 @@ struct btrfs_super_block {
  * Compat flags that we support.  If any incompat flags are set other than the
  * ones specified below then we will fail to mount
  */
-#define BTRFS_FEATURE_COMPAT_SUPP	0x0
-#define BTRFS_FEATURE_COMPAT_RO_SUPP	0x0
-#define BTRFS_FEATURE_INCOMPAT_SUPP	0x0
+#define BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF	(1ULL << 0)
+
+#define BTRFS_FEATURE_COMPAT_SUPP		0ULL
+#define BTRFS_FEATURE_COMPAT_RO_SUPP		0ULL
+#define BTRFS_FEATURE_INCOMPAT_SUPP		\
+	BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF
 
 /*
  * A leaf is full of items. offset and size tell us where to find
@@ -421,23 +436,65 @@ struct btrfs_path {
 	unsigned int keep_locks:1;
 	unsigned int skip_locking:1;
 	unsigned int leave_spinning:1;
+	unsigned int search_commit_root:1;
 };
 
 /*
  * items in the extent btree are used to record the objectid of the
  * owner of the block and the number of references
  */
+
 struct btrfs_extent_item {
+	__le64 refs;
+	__le64 generation;
+	__le64 flags;
+} __attribute__ ((__packed__));
+
+struct btrfs_extent_item_v0 {
 	__le32 refs;
 } __attribute__ ((__packed__));
 
-struct btrfs_extent_ref {
+#define BTRFS_MAX_EXTENT_ITEM_SIZE(r) ((BTRFS_LEAF_DATA_SIZE(r) >> 4) - \
+					sizeof(struct btrfs_item))
+
+#define BTRFS_EXTENT_FLAG_DATA		(1ULL << 0)
+#define BTRFS_EXTENT_FLAG_TREE_BLOCK	(1ULL << 1)
+
+/* following flags only apply to tree blocks */
+
+/* use full backrefs for extent pointers in the block */
+#define BTRFS_BLOCK_FLAG_FULL_BACKREF	(1ULL << 8)
+
+struct btrfs_tree_block_info {
+	struct btrfs_disk_key key;
+	u8 level;
+} __attribute__ ((__packed__));
+
+struct btrfs_extent_data_ref {
+	__le64 root;
+	__le64 objectid;
+	__le64 offset;
+	__le32 count;
+} __attribute__ ((__packed__));
+
+struct btrfs_shared_data_ref {
+	__le32 count;
+} __attribute__ ((__packed__));
+
+struct btrfs_extent_inline_ref {
+	u8 type;
+	u64 offset;
+} __attribute__ ((__packed__));
+
+/* old style backrefs item */
+struct btrfs_extent_ref_v0 {
 	__le64 root;
 	__le64 generation;
 	__le64 objectid;
-	__le32 num_refs;
+	__le32 count;
 } __attribute__ ((__packed__));
 
+
 /* dev extents record free space on individual devices.  The owner
  * field points back to the chunk allocation mapping tree that allocated
  * the extent.  The chunk tree uuid field is a way to double check the owner
@@ -695,12 +752,7 @@ struct btrfs_block_group_cache {
 	struct list_head cluster_list;
 };
 
-struct btrfs_leaf_ref_tree {
-	struct rb_root root;
-	struct list_head list;
-	spinlock_t lock;
-};
-
+struct reloc_control;
 struct btrfs_device;
 struct btrfs_fs_devices;
 struct btrfs_fs_info {
@@ -831,18 +883,11 @@ struct btrfs_fs_info {
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
 
-	/* tree relocation relocated fields */
-	struct list_head dead_reloc_roots;
-	struct btrfs_leaf_ref_tree reloc_ref_tree;
-	struct btrfs_leaf_ref_tree shared_ref_tree;
-
 	struct kobject super_kobj;
 	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
 	int log_root_recovering;
-	atomic_t throttles;
-	atomic_t throttle_gen;
 
 	u64 total_pinned;
 
@@ -861,6 +906,8 @@ struct btrfs_fs_info {
 	 */
 	struct list_head space_info;
 
+	struct reloc_control *reloc_ctl;
+
 	spinlock_t delalloc_lock;
 	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
@@ -891,7 +938,6 @@ struct btrfs_fs_info {
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.
  */
-struct btrfs_dirty_root;
 struct btrfs_root {
 	struct extent_buffer *node;
 
@@ -899,9 +945,6 @@ struct btrfs_root {
 	spinlock_t node_lock;
 
 	struct extent_buffer *commit_root;
-	struct btrfs_leaf_ref_tree *ref_tree;
-	struct btrfs_leaf_ref_tree ref_tree_struct;
-	struct btrfs_dirty_root *dirty_root;
 	struct btrfs_root *log_root;
 	struct btrfs_root *reloc_root;
 
@@ -952,10 +995,15 @@ struct btrfs_root {
 	/* the dirty list is only used by non-reference counted roots */
 	struct list_head dirty_list;
 
+	struct list_head root_list;
+
 	spinlock_t list_lock;
-	struct list_head dead_list;
 	struct list_head orphan_list;
 
+	spinlock_t inode_lock;
+	/* red-black tree that keeps track of in-memory inodes */
+	struct rb_root inode_tree;
+
 	/*
 	 * right now this just gets used so that a root has its own devid
 	 * for stat.  It may be used for more later
@@ -1017,7 +1065,16 @@ struct btrfs_root {
  * are used, and how many references there are to each block
  */
 #define BTRFS_EXTENT_ITEM_KEY	168
-#define BTRFS_EXTENT_REF_KEY	180
+
+#define BTRFS_TREE_BLOCK_REF_KEY	176
+
+#define BTRFS_EXTENT_DATA_REF_KEY	178
+
+#define BTRFS_EXTENT_REF_V0_KEY		180
+
+#define BTRFS_SHARED_BLOCK_REF_KEY	182
+
+#define BTRFS_SHARED_DATA_REF_KEY	184
 
 /*
  * block groups give us hints into the extent allocation trees.  Which
@@ -1317,24 +1374,67 @@ static inline u8 *btrfs_dev_extent_chunk_tree_uuid(struct btrfs_dev_extent *dev)
 	return (u8 *)((unsigned long)dev + ptr);
 }
 
-/* struct btrfs_extent_ref */
-BTRFS_SETGET_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
-BTRFS_SETGET_FUNCS(ref_generation, struct btrfs_extent_ref, generation, 64);
-BTRFS_SETGET_FUNCS(ref_objectid, struct btrfs_extent_ref, objectid, 64);
-BTRFS_SETGET_FUNCS(ref_num_refs, struct btrfs_extent_ref, num_refs, 32);
+BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 64);
+BTRFS_SETGET_FUNCS(extent_generation, struct btrfs_extent_item,
+		   generation, 64);
+BTRFS_SETGET_FUNCS(extent_flags, struct btrfs_extent_item, flags, 64);
 
-BTRFS_SETGET_STACK_FUNCS(stack_ref_root, struct btrfs_extent_ref, root, 64);
-BTRFS_SETGET_STACK_FUNCS(stack_ref_generation, struct btrfs_extent_ref,
-			 generation, 64);
-BTRFS_SETGET_STACK_FUNCS(stack_ref_objectid, struct btrfs_extent_ref,
-			 objectid, 64);
-BTRFS_SETGET_STACK_FUNCS(stack_ref_num_refs, struct btrfs_extent_ref,
-			 num_refs, 32);
+BTRFS_SETGET_FUNCS(extent_refs_v0, struct btrfs_extent_item_v0, refs, 32);
+
+
+BTRFS_SETGET_FUNCS(tree_block_level, struct btrfs_tree_block_info, level, 8);
+
+static inline void btrfs_tree_block_key(struct extent_buffer *eb,
+					struct btrfs_tree_block_info *item,
+					struct btrfs_disk_key *key)
+{
+	read_eb_member(eb, item, struct btrfs_tree_block_info, key, key);
+}
+
+static inline void btrfs_set_tree_block_key(struct extent_buffer *eb,
+					    struct btrfs_tree_block_info *item,
+					    struct btrfs_disk_key *key)
+{
+	write_eb_member(eb, item, struct btrfs_tree_block_info, key, key);
+}
 
-/* struct btrfs_extent_item */
-BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
-BTRFS_SETGET_STACK_FUNCS(stack_extent_refs, struct btrfs_extent_item,
-			 refs, 32);
+BTRFS_SETGET_FUNCS(extent_data_ref_root, struct btrfs_extent_data_ref,
+		   root, 64);
+BTRFS_SETGET_FUNCS(extent_data_ref_objectid, struct btrfs_extent_data_ref,
+		   objectid, 64);
+BTRFS_SETGET_FUNCS(extent_data_ref_offset, struct btrfs_extent_data_ref,
+		   offset, 64);
+BTRFS_SETGET_FUNCS(extent_data_ref_count, struct btrfs_extent_data_ref,
+		   count, 32);
+
+BTRFS_SETGET_FUNCS(shared_data_ref_count, struct btrfs_shared_data_ref,
+		   count, 32);
+
+BTRFS_SETGET_FUNCS(extent_inline_ref_type, struct btrfs_extent_inline_ref,
+		   type, 8);
+BTRFS_SETGET_FUNCS(extent_inline_ref_offset, struct btrfs_extent_inline_ref,
+		   offset, 64);
+
+static inline u32 btrfs_extent_inline_ref_size(int type)
+{
+	if (type == BTRFS_TREE_BLOCK_REF_KEY ||
+	    type == BTRFS_SHARED_BLOCK_REF_KEY)
+		return sizeof(struct btrfs_extent_inline_ref);
+	if (type == BTRFS_SHARED_DATA_REF_KEY)
+		return sizeof(struct btrfs_shared_data_ref) +
+		       sizeof(struct btrfs_extent_inline_ref);
+	if (type == BTRFS_EXTENT_DATA_REF_KEY)
+		return sizeof(struct btrfs_extent_data_ref) +
+		       offsetof(struct btrfs_extent_inline_ref, offset);
+	BUG();
+	return 0;
+}
+
+BTRFS_SETGET_FUNCS(ref_root_v0, struct btrfs_extent_ref_v0, root, 64);
+BTRFS_SETGET_FUNCS(ref_generation_v0, struct btrfs_extent_ref_v0,
+		   generation, 64);
+BTRFS_SETGET_FUNCS(ref_objectid_v0, struct btrfs_extent_ref_v0, objectid, 64);
+BTRFS_SETGET_FUNCS(ref_count_v0, struct btrfs_extent_ref_v0, count, 32);
 
 /* struct btrfs_node */
 BTRFS_SETGET_FUNCS(key_blockptr, struct btrfs_key_ptr, blockptr, 64);
@@ -1558,6 +1658,21 @@ static inline int btrfs_clear_header_flag(struct extent_buffer *eb, u64 flag)
 	return (flags & flag) == flag;
 }
 
+static inline int btrfs_header_backref_rev(struct extent_buffer *eb)
+{
+	u64 flags = btrfs_header_flags(eb);
+	return flags >> BTRFS_BACKREF_REV_SHIFT;
+}
+
+static inline void btrfs_set_header_backref_rev(struct extent_buffer *eb,
+						int rev)
+{
+	u64 flags = btrfs_header_flags(eb);
+	flags &= ~BTRFS_BACKREF_REV_MASK;
+	flags |= (u64)rev << BTRFS_BACKREF_REV_SHIFT;
+	btrfs_set_header_flags(eb, flags);
+}
+
 static inline u8 *btrfs_header_fsid(struct extent_buffer *eb)
 {
 	unsigned long ptr = offsetof(struct btrfs_header, fsid);
@@ -1790,39 +1905,32 @@ int btrfs_update_pinned_extents(struct btrfs_root *root,
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root, u64 objectid, u64 bytenr);
+			  struct btrfs_root *root,
+			  u64 objectid, u64 offset, u64 bytenr);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 struct btrfs_fs_info *info,
 						 u64 bytenr);
+void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 u64 btrfs_find_block_group(struct btrfs_root *root,
 			   u64 search_start, u64 search_hint, int owner);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
-					     struct btrfs_root *root,
-					     u32 blocksize, u64 parent,
-					     u64 root_objectid,
-					     u64 ref_generation,
-					     int level,
-					     u64 hint,
-					     u64 empty_size);
+					struct btrfs_root *root, u32 blocksize,
+					u64 parent, u64 root_objectid,
+					struct btrfs_disk_key *key, int level,
+					u64 hint, u64 empty_size);
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize,
 					    int level);
-int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *root,
-		       u64 num_bytes, u64 parent, u64 min_bytes,
-		       u64 root_objectid, u64 ref_generation,
-		       u64 owner, u64 empty_size, u64 hint_byte,
-		       u64 search_end, struct btrfs_key *ins, u64 data);
-int btrfs_alloc_reserved_extent(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root, u64 parent,
-				u64 root_objectid, u64 ref_generation,
-				u64 owner, struct btrfs_key *ins);
-int btrfs_alloc_logged_extent(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root, u64 parent,
-				u64 root_objectid, u64 ref_generation,
-				u64 owner, struct btrfs_key *ins);
+int btrfs_alloc_reserved_file_extent(struct btrfs_trans_handle *trans,
+				     struct btrfs_root *root,
+				     u64 root_objectid, u64 owner,
+				     u64 offset, struct btrfs_key *ins);
+int btrfs_alloc_logged_file_extent(struct btrfs_trans_handle *trans,
+				   struct btrfs_root *root,
+				   u64 root_objectid, u64 owner, u64 offset,
+				   struct btrfs_key *ins);
 int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  struct btrfs_root *root,
 				  u64 num_bytes, u64 min_alloc_size,
@@ -1830,18 +1938,18 @@ int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  u64 search_end, struct btrfs_key *ins,
 				  u64 data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *orig_buf, struct extent_buffer *buf,
-		  u32 *nr_extents);
-int btrfs_cache_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		    struct extent_buffer *buf, u32 nr_extents);
-int btrfs_update_ref(struct btrfs_trans_handle *trans,
-		     struct btrfs_root *root, struct extent_buffer *orig_buf,
-		     struct extent_buffer *buf, int start_slot, int nr);
+		  struct extent_buffer *buf, int full_backref);
+int btrfs_dec_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		  struct extent_buffer *buf, int full_backref);
+int btrfs_set_disk_extent_flags(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root,
+				u64 bytenr, u64 num_bytes, u64 flags,
+				int is_data);
 int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      u64 bytenr, u64 num_bytes, u64 parent,
-		      u64 root_objectid, u64 ref_generation,
-		      u64 owner_objectid, int pin);
+		      u64 root_objectid, u64 owner, u64 offset);
+
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
@@ -1849,13 +1957,8 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,
-			 u64 root_objectid, u64 ref_generation,
-			 u64 owner_objectid);
-int btrfs_update_extent_ref(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root, u64 bytenr, u64 num_bytes,
-			    u64 orig_parent, u64 parent,
-			    u64 root_objectid, u64 ref_generation,
-			    u64 owner_objectid);
+			 u64 root_objectid, u64 owner, u64 offset);
+
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
 int btrfs_extent_readonly(struct btrfs_root *root, u64 bytenr);
@@ -1867,16 +1970,9 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   u64 size);
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
-int btrfs_relocate_block_group(struct btrfs_root *root, u64 group_start);
-int btrfs_free_reloc_root(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root);
-int btrfs_drop_dead_reloc_roots(struct btrfs_root *root);
-int btrfs_reloc_tree_cache_ref(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *root,
-			       struct extent_buffer *buf, u64 orig_start);
-int btrfs_add_dead_reloc_root(struct btrfs_root *root);
-int btrfs_cleanup_reloc_trees(struct btrfs_root *root);
-int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
+int btrfs_prepare_block_group_relocation(struct btrfs_root *root,
+				struct btrfs_block_group_cache *group);
+
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
 void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
@@ -1891,13 +1987,12 @@ void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
 void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
 			      u64 bytes);
 /* ctree.c */
+int btrfs_bin_search(struct extent_buffer *eb, struct btrfs_key *key,
+		     int level, int *slot);
+int btrfs_comp_cpu_keys(struct btrfs_key *k1, struct btrfs_key *k2);
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
-int btrfs_merge_path(struct btrfs_trans_handle *trans,
-		     struct btrfs_root *root,
-		     struct btrfs_key *node_keys,
-		     u64 *nodes, int lowest_level);
 int btrfs_set_item_key_safe(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root, struct btrfs_path *path,
 			    struct btrfs_key *new_key);
@@ -1918,6 +2013,8 @@ int btrfs_copy_root(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      struct extent_buffer *buf,
 		      struct extent_buffer **cow_ret, u64 new_root_objectid);
+int btrfs_block_can_be_shared(struct btrfs_root *root,
+			      struct extent_buffer *buf);
 int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_path *path, u32 data_size);
 int btrfs_truncate_item(struct btrfs_trans_handle *trans,
@@ -1944,9 +2041,6 @@ void btrfs_unlock_up_safe(struct btrfs_path *p, int level);
 
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_path *path, int slot, int nr);
-int btrfs_del_leaf(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root,
-			    struct btrfs_path *path, u64 bytenr);
 static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct btrfs_path *path)
@@ -2005,8 +2099,9 @@ int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
 int btrfs_search_root(struct btrfs_root *root, u64 search_start,
 		      u64 *found_objectid);
-int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid,
-			  struct btrfs_root *latest_root);
+int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid);
+int btrfs_set_root_node(struct btrfs_root_item *item,
+			struct extent_buffer *node);
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, const char *name,
@@ -2139,7 +2234,6 @@ int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);
 void btrfs_put_inode(struct inode *inode);
-void btrfs_read_locked_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, int wait);
 void btrfs_dirty_inode(struct inode *inode);
 struct inode *btrfs_alloc_inode(struct super_block *sb);
@@ -2147,12 +2241,8 @@ void btrfs_destroy_inode(struct inode *inode);
 int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
-struct inode *btrfs_ilookup(struct super_block *s, u64 objectid,
-			    struct btrfs_root *root, int wait);
-struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
-				struct btrfs_root *root);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
-			 struct btrfs_root *root, int *is_new);
+			 struct btrfs_root *root);
 int btrfs_commit_write(struct file *file, struct page *page,
 		       unsigned from, unsigned to);
 struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
@@ -2209,4 +2299,12 @@ int btrfs_check_acl(struct inode *inode, int mask);
 int btrfs_init_acl(struct inode *inode, struct inode *dir);
 int btrfs_acl_chmod(struct inode *inode);
 
+/* relocation.c */
+int btrfs_relocate_block_group(struct btrfs_root *root, u64 group_start);
+int btrfs_init_reloc_root(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root);
+int btrfs_update_reloc_root(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root);
+int btrfs_recover_relocation(struct btrfs_root *root);
+int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
 #endif

commit e980b50cda1610f1c17978d9b7fd311a9dd93877
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 24 14:39:24 2009 -0400

    Btrfs: fix fallocate deadlock on inode extent lock
    
    The btrfs fallocate call takes an extent lock on the entire range
    being fallocated, and then runs through insert_reserved_extent on each
    extent as they are allocated.
    
    The problem with this is that btrfs_drop_extents may decide to try
    and take the same extent lock fallocate was already holding.  The solution
    used here is to push down knowledge of the range that is already locked
    going into btrfs_drop_extents.
    
    It turns out that at least one other caller had the same bug.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 213535f45da2..4414a5d9983a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2177,7 +2177,8 @@ int btrfs_check_file(struct btrfs_root *root, struct inode *inode);
 extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
-		       u64 start, u64 end, u64 inline_limit, u64 *hint_block);
+		       u64 start, u64 end, u64 locked_end,
+		       u64 inline_limit, u64 *hint_block);
 int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode, u64 start, u64 end);

commit 97e728d4353f38c87bf0804cdfd79a9b13fc2c3e
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Apr 21 17:40:57 2009 -0400

    Btrfs: try to keep a healthy ratio of metadata vs data block groups
    
    This patch makes the chunk allocator keep a good ratio of metadata vs data
    block groups.  By default for every 8 data block groups, we'll allocate 1
    metadata chunk, or about 12% of the disk will be allocated for metadata.  This
    can be changed by specifying the metadata_ratio mount option.
    
    This is simply the number of data block groups that have to be allocated to
    force a metadata chunk allocation.  By making sure we allocate metadata chunks
    more often, we are less likely to get into situations where the whole disk
    has been allocated as data block groups.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ad96495dedc5..213535f45da2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -881,6 +881,9 @@ struct btrfs_fs_info {
 	u64 metadata_alloc_profile;
 	u64 system_alloc_profile;
 
+	unsigned data_chunk_allocations;
+	unsigned metadata_ratio;
+
 	void *bdev_holder;
 };
 

commit b983471794e568fd71fa767da77a62ba517c3e63
Merge: 5a3ae2760578 c293498be698
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 3 15:14:44 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: BUG to BUG_ON changes
      Btrfs: remove dead code
      Btrfs: remove dead code
      Btrfs: fix typos in comments
      Btrfs: remove unused ftrace include
      Btrfs: fix __ucmpdi2 compile bug on 32 bit builds
      Btrfs: free inode struct when btrfs_new_inode fails
      Btrfs: fix race in worker_loop
      Btrfs: add flushoncommit mount option
      Btrfs: notreelog mount option
      Btrfs: introduce btrfs_show_options
      Btrfs: rework allocation clustering
      Btrfs: Optimize locking in btrfs_next_leaf()
      Btrfs: break up btrfs_search_slot into smaller pieces
      Btrfs: kill the pinned_mutex
      Btrfs: kill the block group alloc mutex
      Btrfs: clean up find_free_extent
      Btrfs: free space cache cleanups
      Btrfs: unplug in the async bio submission threads
      Btrfs: keep processing bios for a given bdev if our proc is batching

commit d4a789474a6213d1b55b363fb1787b0abf877bba
Author: Wu Fengguang <fengguang.wu@intel.com>
Date:   Thu Apr 2 16:46:06 2009 -0400

    Btrfs: fix typos in comments
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bb6ac5b87652..8f4e152bb11b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -143,12 +143,15 @@ static int btrfs_csum_sizes[] = { 4, 0 };
 #define BTRFS_FT_MAX		9
 
 /*
- * the key defines the order in the tree, and so it also defines (optimal)
- * block layout.  objectid corresonds to the inode number.  The flags
- * tells us things about the object, and is a kind of stream selector.
- * so for a given inode, keys with flags of 1 might refer to the inode
- * data, flags of 2 may point to file data in the btree and flags == 3
- * may point to extents.
+ * The key defines the order in the tree, and so it also defines (optimal)
+ * block layout.
+ *
+ * objectid corresponds to the inode number.
+ *
+ * type tells us things about the object, and is a kind of stream selector.
+ * so for a given inode, keys with type of 1 might refer to the inode data,
+ * type of 2 may point to file data in the btree and type == 3 may point to
+ * extents.
  *
  * offset is the starting byte offset for this key in the stream.
  *
@@ -200,7 +203,7 @@ struct btrfs_dev_item {
 
 	/*
 	 * starting byte of this partition on the device,
-	 * to allowr for stripe alignment in the future
+	 * to allow for stripe alignment in the future
 	 */
 	__le64 start_offset;
 
@@ -958,7 +961,6 @@ struct btrfs_root {
 };
 
 /*
-
  * inode items have the data typically returned from stat and store other
  * info about object characteristics.  There is one for every file and dir in
  * the FS
@@ -989,7 +991,7 @@ struct btrfs_root {
 #define BTRFS_EXTENT_CSUM_KEY	128
 
 /*
- * root items point to tree roots.  There are typically in the root
+ * root items point to tree roots.  They are typically in the root
  * tree used by the super block to find all the other trees
  */
 #define BTRFS_ROOT_ITEM_KEY	132

commit dccae99995089641fbac452ebc7f0cab18751ddb
Author: Sage Weil <sage@newdream.net>
Date:   Thu Apr 2 16:59:01 2009 -0400

    Btrfs: add flushoncommit mount option
    
    The 'flushoncommit' mount option forces any data dirtied by a write in a
    prior transaction to commit as part of the current commit.  This makes
    the committed state a fully consistent view of the file system from the
    application's perspective (i.e., it includes all completed file system
    operations).  This was previously the behavior only when a snapshot is
    created.
    
    This is used by Ceph to ensure that completed writes make it to the
    platter along with the metadata operations they are bound to (by
    BTRFS_IOC_TRANS_{START,END}).
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e99a9948637..bb6ac5b87652 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1037,6 +1037,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_DEGRADED		(1 << 4)
 #define BTRFS_MOUNT_COMPRESS		(1 << 5)
 #define BTRFS_MOUNT_NOTREELOG           (1 << 6)
+#define BTRFS_MOUNT_FLUSHONCOMMIT       (1 << 7)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 3a5e14048a0a81276d284cbda441507a17e26147
Author: Sage Weil <sage@newdream.net>
Date:   Thu Apr 2 16:49:40 2009 -0400

    Btrfs: notreelog mount option
    
    Add a 'notreelog' mount option to disable the tree log (used by fsync,
    O_SYNC writes).  This is much slower, but the tree logging produces
    inconsistent views into the FS for ceph.
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b82931f97ef3..1e99a9948637 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1036,6 +1036,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_SSD			(1 << 3)
 #define BTRFS_MOUNT_DEGRADED		(1 << 4)
 #define BTRFS_MOUNT_COMPRESS		(1 << 5)
+#define BTRFS_MOUNT_NOTREELOG           (1 << 6)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit fa9c0d795f7b57c76560b7fac703f5d341210e28
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 3 09:47:43 2009 -0400

    Btrfs: rework allocation clustering
    
    Because btrfs is copy-on-write, we end up picking new locations for
    blocks very often.  This makes it fairly difficult to maintain perfect
    read patterns over time, but we can at least do some optimizations
    for writes.
    
    This is done today by remembering the last place we allocated and
    trying to find a free space hole big enough to hold more than just one
    allocation.  The end result is that we tend to write sequentially to
    the drive.
    
    This happens all the time for metadata and it happens for data
    when mounted -o ssd.  But, the way we record it is fairly racey
    and it tends to fragment the free space over time because we are trying
    to allocate fairly large areas at once.
    
    This commit gets rid of the races by adding a free space cluster object
    with dedicated locking to make sure that only one process at a time
    is out replacing the cluster.
    
    The free space fragmentation is somewhat solved by allowing a cluster
    to be comprised of smaller free space extents.  This part definitely
    adds some CPU time to the cluster allocations, but it allows the allocator
    to consume the small holes left behind by cow.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aaa049b8e134..b82931f97ef3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -633,11 +633,29 @@ struct btrfs_space_info {
 	struct rw_semaphore groups_sem;
 };
 
-struct btrfs_free_space {
-	struct rb_node bytes_index;
-	struct rb_node offset_index;
-	u64 offset;
-	u64 bytes;
+/*
+ * free clusters are used to claim free space in relatively large chunks,
+ * allowing us to do less seeky writes.  They are used for all metadata
+ * allocations and data allocations in ssd mode.
+ */
+struct btrfs_free_cluster {
+	spinlock_t lock;
+	spinlock_t refill_lock;
+	struct rb_root root;
+
+	/* largest extent in this cluster */
+	u64 max_size;
+
+	/* first extent starting offset */
+	u64 window_start;
+
+	struct btrfs_block_group_cache *block_group;
+	/*
+	 * when a cluster is allocated from a block group, we put the
+	 * cluster onto a list in the block group so that it can
+	 * be freed before the block group is freed.
+	 */
+	struct list_head block_group_list;
 };
 
 struct btrfs_block_group_cache {
@@ -667,6 +685,11 @@ struct btrfs_block_group_cache {
 
 	/* usage count */
 	atomic_t count;
+
+	/* List of struct btrfs_free_clusters for this block group.
+	 * Today it will only have one thing on it, but that may change
+	 */
+	struct list_head cluster_list;
 };
 
 struct btrfs_leaf_ref_tree {
@@ -838,8 +861,12 @@ struct btrfs_fs_info {
 	spinlock_t delalloc_lock;
 	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
-	u64 last_alloc;
-	u64 last_data_alloc;
+
+	/* data_alloc_cluster is only used in ssd mode */
+	struct btrfs_free_cluster data_alloc_cluster;
+
+	/* all metadata allocations go through this cluster */
+	struct btrfs_free_cluster meta_alloc_cluster;
 
 	spinlock_t ref_cache_lock;
 	u64 total_ref_cache_size;
@@ -1747,6 +1774,7 @@ static inline struct dentry *fdentry(struct file *file)
 }
 
 /* extent-tree.c */
+void btrfs_put_block_group(struct btrfs_block_group_cache *cache);
 int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, unsigned long count);
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
@@ -2173,16 +2201,4 @@ int btrfs_check_acl(struct inode *inode, int mask);
 int btrfs_init_acl(struct inode *inode, struct inode *dir);
 int btrfs_acl_chmod(struct inode *inode);
 
-/* free-space-cache.c */
-int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
-			 u64 bytenr, u64 size);
-int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
-			    u64 bytenr, u64 size);
-void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
-				   *block_group);
-u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
-			       u64 offset, u64 bytes, u64 empty_size);
-void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
-			   u64 bytes);
-u64 btrfs_block_group_free_space(struct btrfs_block_group_cache *block_group);
 #endif

commit 04018de5d41e6490840de9399e029fd30e78576f
Author: Josef Bacik <jbacik@redhat.com>
Date:   Fri Apr 3 10:14:18 2009 -0400

    Btrfs: kill the pinned_mutex
    
    This patch removes the pinned_mutex.  The extent io map has an internal tree
    lock that protects the tree itself, and since we only copy the extent io map
    when we are committing the transaction we don't need it there.  We also don't
    need it when caching the block group since searching through the tree is also
    protected by the internal map spin lock.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 527744561f93..aaa049b8e134 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -728,7 +728,6 @@ struct btrfs_fs_info {
 	struct mutex tree_log_mutex;
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;
-	struct mutex pinned_mutex;
 	struct mutex chunk_mutex;
 	struct mutex drop_mutex;
 	struct mutex volume_mutex;

commit 6226cb0a5ea3f6289883753c15d53f48a6c6bbfb
Author: Josef Bacik <jbacik@redhat.com>
Date:   Fri Apr 3 10:14:18 2009 -0400

    Btrfs: kill the block group alloc mutex
    
    This patch removes the block group alloc mutex used to protect the free space
    tree for allocations and replaces it with a spin lock which is used only to
    protect the free space rb tree.  This means we only take the lock when we are
    directly manipulating the tree, which makes us a touch faster with
    multi-threaded workloads.
    
    This patch also gets rid of btrfs_find_free_space and replaces it with
    btrfs_find_space_for_alloc, which takes the number of bytes you want to
    allocate, and empty_size, which is used to indicate how much free space should
    be at the end of the allocation.
    
    It will return an offset for the allocator to use.  If we don't end up using it
    we _must_ call btrfs_add_free_space to put it back.  This is the tradeoff to
    kill the alloc_mutex, since we need to make sure nobody else comes along and
    takes our space.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f48905ee5240..527744561f93 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -644,7 +644,6 @@ struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
 	spinlock_t lock;
-	struct mutex alloc_mutex;
 	struct mutex cache_mutex;
 	u64 pinned;
 	u64 reserved;
@@ -656,6 +655,7 @@ struct btrfs_block_group_cache {
 	struct btrfs_space_info *space_info;
 
 	/* free space cache stuff */
+	spinlock_t tree_lock;
 	struct rb_root free_space_bytes;
 	struct rb_root free_space_offset;
 
@@ -2177,17 +2177,12 @@ int btrfs_acl_chmod(struct inode *inode);
 /* free-space-cache.c */
 int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
 			 u64 bytenr, u64 size);
-int btrfs_add_free_space_lock(struct btrfs_block_group_cache *block_group,
-			      u64 offset, u64 bytes);
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
 			    u64 bytenr, u64 size);
-int btrfs_remove_free_space_lock(struct btrfs_block_group_cache *block_group,
-				 u64 offset, u64 bytes);
 void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
 				   *block_group);
-struct btrfs_free_space *btrfs_find_free_space(struct btrfs_block_group_cache
-					       *block_group, u64 offset,
-					       u64 bytes);
+u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
+			       u64 offset, u64 bytes, u64 empty_size);
 void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
 u64 btrfs_block_group_free_space(struct btrfs_block_group_cache *block_group);

commit c226fd659fa7b6a7b038df5ae6856a68514bacde
Merge: c09bca786ff9 d57e62b89796
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 1 10:20:44 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: try to free metadata pages when we free btree blocks
      Btrfs: add extra flushing for renames and truncates
      Btrfs: make sure btrfs_update_delayed_ref doesn't increase ref_mod
      Btrfs: optimize fsyncs on old files
      Btrfs: tree logging unlink/rename fixes
      Btrfs: Make sure i_nlink doesn't hit zero too soon during log replay
      Btrfs: limit balancing work while flushing delayed refs
      Btrfs: readahead checksums during btrfs_finish_ordered_io
      Btrfs: leave btree locks spinning more often
      Btrfs: Only let very young transactions grow during commit
      Btrfs: Check for a blocking lock before taking the spin
      Btrfs: reduce stack in cow_file_range
      Btrfs: reduce stalls during transaction commit
      Btrfs: process the delayed reference queue in clusters
      Btrfs: try to cleanup delayed refs while freeing extents
      Btrfs: reduce stack usage in some crucial tree balancing functions
      Btrfs: do extent allocation and reference count updates in the background
      Btrfs: don't preallocate metadata blocks during btrfs_search_slot

commit c2ec175c39f62949438354f603f4aa170846aabb
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Mar 31 15:23:21 2009 -0700

    mm: page_mkwrite change prototype to match fault
    
    Change the page_mkwrite prototype to take a struct vm_fault, and return
    VM_FAULT_xxx flags.  There should be no functional change.
    
    This makes it possible to return much more detailed error information to
    the VM (and also can provide more information eg.  virtual_address to the
    driver, which might be important in some special cases).
    
    This is required for a subsequent fix.  And will also make it easier to
    merge page_mkwrite() with fault() in future.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <joel.becker@oracle.com>
    Cc: Artem Bityutskiy <dedekind@infradead.org>
    Cc: Felix Blyakher <felixb@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5e1d4e30e9d8..7dd1b6d0bf32 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2060,7 +2060,7 @@ int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 unsigned long btrfs_force_ra(struct address_space *mapping,
 			      struct file_ra_state *ra, struct file *file,
 			      pgoff_t offset, pgoff_t last_index);
-int btrfs_page_mkwrite(struct vm_area_struct *vma, struct page *page);
+int btrfs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);
 void btrfs_put_inode(struct inode *inode);

commit 5a3f23d515a2ebf0c750db80579ca57b28cbce6d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 31 13:27:11 2009 -0400

    Btrfs: add extra flushing for renames and truncates
    
    Renames and truncates are both common ways to replace old data with new
    data.  The filesystem can make an effort to make sure the new data is
    on disk before actually replacing the old data.
    
    This is especially important for rename, which many application use as
    though it were atomic for both the data and the metadata involved.  The
    current btrfs code will happily replace a file that is fully on disk
    with one that was just created and still has pending IO.
    
    If we crash after transaction commit but before the IO is done, we'll end
    up replacing a good file with a zero length file.  The solution used
    here is to create a list of inodes that need special ordering and force
    them to disk before the commit is done.  This is similar to the
    ext3 style data=ordering, except it is only done on selected files.
    
    Btrfs is able to get away with this because it does not wait on commits
    very often, even for fsync (which use a sub-commit).
    
    For renames, we order the file when it wasn't already
    on disk and when it is replacing an existing file.  Larger files
    are sent to filemap_flush right away (before the transaction handle is
    opened).
    
    For truncates, we order if the file goes from non-zero size down to
    zero size.  This is a little different, because at the time of the
    truncate the file has no dirty bytes to order.  But, we flag the inode
    so that it is added to the ordered list on close (via release method).  We
    also immediately add it to the ordered list of the current transaction
    so that we can try to flush down any writes the application sneaks in
    before commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2737facbd341..f48905ee5240 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -45,6 +45,13 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAX_LEVEL 8
 
+/*
+ * files bigger than this get some pre-flushing when they are added
+ * to the ordered operations list.  That way we limit the total
+ * work done by the commit
+ */
+#define BTRFS_ORDERED_OPERATIONS_FLUSH_LIMIT (8 * 1024 * 1024)
+
 /* holds pointers to all of the tree roots */
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
 
@@ -727,6 +734,15 @@ struct btrfs_fs_info {
 	struct mutex volume_mutex;
 	struct mutex tree_reloc_mutex;
 
+	/*
+	 * this protects the ordered operations list only while we are
+	 * processing all of the entries on it.  This way we make
+	 * sure the commit code doesn't find the list temporarily empty
+	 * because another function happens to be doing non-waiting preflush
+	 * before jumping into the main commit.
+	 */
+	struct mutex ordered_operations_mutex;
+
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
@@ -741,9 +757,28 @@ struct btrfs_fs_info {
 	 * ordered extents
 	 */
 	spinlock_t ordered_extent_lock;
+
+	/*
+	 * all of the data=ordered extents pending writeback
+	 * these can span multiple transactions and basically include
+	 * every dirty data page that isn't from nodatacow
+	 */
 	struct list_head ordered_extents;
+
+	/*
+	 * all of the inodes that have delalloc bytes.  It is possible for
+	 * this list to be empty even when there is still dirty data=ordered
+	 * extents waiting to finish IO.
+	 */
 	struct list_head delalloc_inodes;
 
+	/*
+	 * special rename and truncate targets that must be on disk before
+	 * we're allowed to commit.  This is basically the ext3 style
+	 * data=ordered list.
+	 */
+	struct list_head ordered_operations;
+
 	/*
 	 * there is a pool of worker threads for checksumming during writes
 	 * and a pool for checksumming after reads.  This is because readers

commit 12fcfd22fe5bf4fe74710232098bc101af497995
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 24 10:24:20 2009 -0400

    Btrfs: tree logging unlink/rename fixes
    
    The tree logging code allows individual files or directories to be logged
    without including operations on other files and directories in the FS.
    It tries to commit the minimal set of changes to disk in order to
    fsync the single file or directory that was sent to fsync or O_SYNC.
    
    The tree logging code was allowing files and directories to be unlinked
    if they were part of a rename operation where only one directory
    in the rename was in the fsync log.  This patch adds a few new rules
    to the tree logging.
    
    1) on rename or unlink, if the inode being unlinked isn't in the fsync
    log, we must force a full commit before doing an fsync of the directory
    where the unlink was done.  The commit isn't done during the unlink,
    but it is forced the next time we try to log the parent directory.
    
    Solution: record transid of last unlink/rename per directory when the
    directory wasn't already logged.  For renames this is only done when
    renaming to a different directory.
    
    mkdir foo/some_dir
    normal commit
    rename foo/some_dir foo2/some_dir
    mkdir foo/some_dir
    fsync foo/some_dir/some_file
    
    The fsync above will unlink the original some_dir without recording
    it in its new location (foo2).  After a crash, some_dir will be gone
    unless the fsync of some_file forces a full commit
    
    2) we must log any new names for any file or dir that is in the fsync
    log.  This way we make sure not to lose files that are unlinked during
    the same transaction.
    
    2a) we must log any new names for any file or dir during rename
    when the directory they are being removed from was logged.
    
    2a is actually the more important variant.  Without the extra logging
    a crash might unlink the old name without recreating the new one
    
    3) after a crash, we must go through any directories with a link count
    of zero and redo the rm -rf
    
    mkdir f1/foo
    normal commit
    rm -rf f1/foo
    fsync(f1)
    
    The directory f1 was fully removed from the FS, but fsync was never
    called on f1, only its parent dir.  After a crash the rm -rf must
    be replayed.  This must be able to recurse down the entire
    directory tree.  The inode link count fixup code takes care of the
    ugly details.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4ddce91cf3f9..2737facbd341 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -695,7 +695,12 @@ struct btrfs_fs_info {
 
 	u64 generation;
 	u64 last_trans_committed;
-	u64 last_trans_new_blockgroup;
+
+	/*
+	 * this is updated to the current trans every time a full commit
+	 * is required instead of the faster short fsync log commits
+	 */
+	u64 last_trans_log_full_commit;
 	u64 open_ioctl_trans;
 	unsigned long mount_opt;
 	u64 max_extent;

commit b9473439d3e84d9fc1a0a83faca69cc1b7566341
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 11:00:37 2009 -0400

    Btrfs: leave btree locks spinning more often
    
    btrfs_mark_buffer dirty would set dirty bits in the extent_io tree
    for the buffers it was dirtying.  This may require a kmalloc and it
    was not atomic.  So, anyone who called btrfs_mark_buffer_dirty had to
    set any btree locks they were holding to blocking first.
    
    This commit changes dirty tracking for extent buffers to just use a flag
    in the extent buffer.  Now that we have one and only one extent buffer
    per page, this can be safely done without losing dirty bits along the way.
    
    This also introduces a path->leave_spinning flag that callers of
    btrfs_search_slot can use to indicate they will properly deal with a
    path returned where all the locks are spinning instead of blocking.
    
    Many of the btree search callers now expect spinning paths,
    resulting in better btree concurrency overall.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 08d9f8d15538..4ddce91cf3f9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -401,15 +401,16 @@ struct btrfs_path {
 	int locks[BTRFS_MAX_LEVEL];
 	int reada;
 	/* keep some upper locks as we walk down */
-	int keep_locks;
-	int skip_locking;
 	int lowest_level;
 
 	/*
 	 * set by btrfs_split_item, tells search_slot to keep all locks
 	 * and to force calls to keep space in the nodes
 	 */
-	int search_for_split;
+	unsigned int search_for_split:1;
+	unsigned int keep_locks:1;
+	unsigned int skip_locking:1;
+	unsigned int leave_spinning:1;
 };
 
 /*
@@ -779,6 +780,11 @@ struct btrfs_fs_info {
 	atomic_t throttle_gen;
 
 	u64 total_pinned;
+
+	/* protected by the delalloc lock, used to keep from writing
+	 * metadata until there is a nice batch
+	 */
+	u64 dirty_metadata_bytes;
 	struct list_head dirty_cowonly_roots;
 
 	struct btrfs_fs_devices *fs_devices;

commit c3e69d58e86c3917ae4e9e31b4acf490a7cafe60
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 10:17:05 2009 -0400

    Btrfs: process the delayed reference queue in clusters
    
    The delayed reference queue maintains pending operations that need to
    be done to the extent allocation tree.  These are processed by
    finding records in the tree that are not currently being processed one at
    a time.
    
    This is slow because it uses lots of time searching through the rbtree
    and because it creates lock contention on the extent allocation tree
    when lots of different procs are running delayed refs at the same time.
    
    This commit changes things to grab a cluster of refs for processing,
    using a cursor into the rbtree as the starting point of the next search.
    This way we walk smoothly through the rbtree.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ced5fd85dc36..08d9f8d15538 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -720,6 +720,7 @@ struct btrfs_fs_info {
 	struct mutex drop_mutex;
 	struct mutex volume_mutex;
 	struct mutex tree_reloc_mutex;
+
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;

commit 56bec294dea971335d4466b30f2d959f28f6e36d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 10:10:06 2009 -0400

    Btrfs: do extent allocation and reference count updates in the background
    
    The extent allocation tree maintains a reference count and full
    back reference information for every extent allocated in the
    filesystem.  For subvolume and snapshot trees, every time
    a block goes through COW, the new copy of the block adds a reference
    on every block it points to.
    
    If a btree node points to 150 leaves, then the COW code needs to go
    and add backrefs on 150 different extents, which might be spread all
    over the extent allocation tree.
    
    These updates currently happen during btrfs_cow_block, and most COWs
    happen during btrfs_search_slot.  btrfs_search_slot has locks held
    on both the parent and the node we are COWing, and so we really want
    to avoid IO during the COW if we can.
    
    This commit adds an rbtree of pending reference count updates and extent
    allocations.  The tree is ordered by byte number of the extent and byte number
    of the parent for the back reference.  The tree allows us to:
    
    1) Modify back references in something close to disk order, reducing seeks
    2) Significantly reduce the number of modifications made as block pointers
    are balanced around
    3) Do all of the extent insertion and back reference modifications outside
    of the performance critical btrfs_search_slot code.
    
    #3 has the added benefit of greatly reducing the btrfs stack footprint.
    The extent allocation tree modifications are done without the deep
    (and somewhat recursive) call chains used in the past.
    
    These delayed back reference updates must be done before the transaction
    commits, and so the rbtree is tied to the transaction.  Throttling is
    implemented to help keep the queue of backrefs at a reasonable size.
    
    Since there was a similar mechanism in place for the extent tree
    extents, that is removed and replaced by the delayed reference tree.
    
    Yan Zheng <yan.zheng@oracle.com> helped review and fixup this code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3a37ba7a8d65..ced5fd85dc36 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -688,8 +688,6 @@ struct btrfs_fs_info {
 	struct rb_root block_group_cache_tree;
 
 	struct extent_io_tree pinned_extents;
-	struct extent_io_tree pending_del;
-	struct extent_io_tree extent_ins;
 
 	/* logical->physical extent mapping */
 	struct btrfs_mapping_tree mapping_tree;
@@ -717,7 +715,6 @@ struct btrfs_fs_info {
 	struct mutex tree_log_mutex;
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;
-	struct mutex extent_ins_mutex;
 	struct mutex pinned_mutex;
 	struct mutex chunk_mutex;
 	struct mutex drop_mutex;
@@ -1704,18 +1701,15 @@ static inline struct dentry *fdentry(struct file *file)
 }
 
 /* extent-tree.c */
+int btrfs_run_delayed_refs(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, unsigned long count);
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
-int btrfs_lookup_extent_ref(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root, u64 bytenr,
-			    u64 num_bytes, u32 *refs);
 int btrfs_update_pinned_extents(struct btrfs_root *root,
 				u64 bytenr, u64 num, int pin);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root, u64 objectid, u64 bytenr);
-int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
-			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(
 						 struct btrfs_fs_info *info,
@@ -1777,7 +1771,7 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 u64 root_objectid, u64 ref_generation,
 			 u64 owner_objectid);
 int btrfs_update_extent_ref(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root, u64 bytenr,
+			    struct btrfs_root *root, u64 bytenr, u64 num_bytes,
 			    u64 orig_parent, u64 parent,
 			    u64 root_objectid, u64 ref_generation,
 			    u64 owner_objectid);

commit 9fa8cfe706f9c20067c042a064999d5825a35330
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 10:24:59 2009 -0400

    Btrfs: don't preallocate metadata blocks during btrfs_search_slot
    
    In order to avoid doing expensive extent management with tree locks held,
    btrfs_search_slot will preallocate tree blocks for use by COW without
    any tree locks held.
    
    A later commit moves all of the extent allocation work for COW into
    a delayed update mechanism, and this preallocation will no longer be
    required.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5e1d4e30e9d8..3a37ba7a8d65 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1838,7 +1838,7 @@ int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,
-		    struct extent_buffer **cow_ret, u64 prealloc_dest);
+		    struct extent_buffer **cow_ret);
 int btrfs_copy_root(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      struct extent_buffer *buf,

commit 4184ea7f908d95f329febc3665cf66da8568b467
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 10 12:39:20 2009 -0400

    Btrfs: Fix locking around adding new space_info
    
    Storage allocated to different raid levels in btrfs is tracked by
    a btrfs_space_info structure, and all of the current space_infos are
    collected into a list_head.
    
    Most filesystems have 3 or 4 of these structs total, and the list is
    only changed when new raid levels are added or at unmount time.
    
    This commit adds rcu locking on the list head, and properly frees
    things at unmount time.  It also clears the space_info->full flag
    whenever new space is added to the FS.
    
    The locking for the space info list goes like this:
    
    reads: protected by rcu_read_lock()
    writes: protected by the chunk_mutex
    
    At unmount time we don't need special locking because all the readers
    are gone.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 82491ba8fa40..5e1d4e30e9d8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -784,7 +784,14 @@ struct btrfs_fs_info {
 	struct list_head dirty_cowonly_roots;
 
 	struct btrfs_fs_devices *fs_devices;
+
+	/*
+	 * the space_info list is almost entirely read only.  It only changes
+	 * when we add a new raid type to the FS, and that happens
+	 * very rarely.  RCU is used to protect it.
+	 */
 	struct list_head space_info;
+
 	spinlock_t delalloc_lock;
 	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
@@ -1797,6 +1804,8 @@ int btrfs_cleanup_reloc_trees(struct btrfs_root *root);
 int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
+void btrfs_clear_space_info_full(struct btrfs_fs_info *info);
+
 int btrfs_check_metadata_free_space(struct btrfs_root *root);
 int btrfs_check_data_free_space(struct btrfs_root *root, struct inode *inode,
 				u64 bytes);

commit 6a63209fc02d5483371f07e4913ee8abad608051
Author: Josef Bacik <jbacik@redhat.com>
Date:   Fri Feb 20 11:00:09 2009 -0500

    Btrfs: add better -ENOSPC handling
    
    This is a step in the direction of better -ENOSPC handling.  Instead of
    checking the global bytes counter we check the space_info bytes counters to
    make sure we have enough space.
    
    If we don't we go ahead and try to allocate a new chunk, and then if that fails
    we return -ENOSPC.  This patch adds two counters to btrfs_space_info,
    bytes_delalloc and bytes_may_use.
    
    bytes_delalloc account for extents we've actually setup for delalloc and will
    be allocated at some point down the line.
    
    bytes_may_use is to keep track of how many bytes we may use for delalloc at
    some point.  When we actually set the extent_bit for the delalloc bytes we
    subtract the reserved bytes from the bytes_may_use counter.  This keeps us from
    not actually being able to allocate space for any delalloc bytes.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 766b31ae3186..82491ba8fa40 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -596,13 +596,27 @@ struct btrfs_block_group_item {
 
 struct btrfs_space_info {
 	u64 flags;
-	u64 total_bytes;
-	u64 bytes_used;
-	u64 bytes_pinned;
-	u64 bytes_reserved;
-	u64 bytes_readonly;
-	int full;
-	int force_alloc;
+
+	u64 total_bytes;	/* total bytes in the space */
+	u64 bytes_used;		/* total bytes used on disk */
+	u64 bytes_pinned;	/* total bytes pinned, will be freed when the
+				   transaction finishes */
+	u64 bytes_reserved;	/* total bytes the allocator has reserved for
+				   current allocations */
+	u64 bytes_readonly;	/* total bytes that are read only */
+
+	/* delalloc accounting */
+	u64 bytes_delalloc;	/* number of bytes reserved for allocation,
+				   this space is not necessarily reserved yet
+				   by the allocator */
+	u64 bytes_may_use;	/* number of bytes that may be used for
+				   delalloc */
+
+	int full;		/* indicates that we cannot allocate any more
+				   chunks for this space */
+	int force_alloc;	/* set if we need to force a chunk alloc for
+				   this space */
+
 	struct list_head list;
 
 	/* for block groups in our same type */
@@ -1782,6 +1796,16 @@ int btrfs_add_dead_reloc_root(struct btrfs_root *root);
 int btrfs_cleanup_reloc_trees(struct btrfs_root *root);
 int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
+void btrfs_set_inode_space_info(struct btrfs_root *root, struct inode *ionde);
+int btrfs_check_metadata_free_space(struct btrfs_root *root);
+int btrfs_check_data_free_space(struct btrfs_root *root, struct inode *inode,
+				u64 bytes);
+void btrfs_free_reserved_data_space(struct btrfs_root *root,
+				    struct inode *inode, u64 bytes);
+void btrfs_delalloc_reserve_space(struct btrfs_root *root, struct inode *inode,
+				 u64 bytes);
+void btrfs_delalloc_free_space(struct btrfs_root *root, struct inode *inode,
+			      u64 bytes);
 /* ctree.c */
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
@@ -2027,8 +2051,6 @@ int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 unsigned long btrfs_force_ra(struct address_space *mapping,
 			      struct file_ra_state *ra, struct file *file,
 			      pgoff_t offset, pgoff_t last_index);
-int btrfs_check_free_space(struct btrfs_root *root, u64 num_required,
-			   int for_del);
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct page *page);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);

commit 4008c04a07c73ec3cb1be4c1391d2159a8f75d6d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Feb 12 14:09:45 2009 -0500

    Btrfs: make a lockdep class for the extent buffer locks
    
    Btrfs is currently using spin_lock_nested with a nested value based
    on the tree depth of the block.  But, this doesn't quite work because
    the max tree depth is bigger than what spin_lock_nested can deal with,
    and because locks are sometimes taken before the level field is filled in.
    
    The solution here is to use lockdep_set_class_and_name instead, and to
    set the class before unlocking the pages when the block is read from the
    disk and just after init of a freshly allocated tree block.
    
    btrfs_clear_path_blocking is also changed to take the locks in the proper
    order, and it also makes sure all the locks currently held are properly
    set to blocking before it tries to retake the spinlocks.  Otherwise, lockdep
    gets upset about bad lock orderin.
    
    The lockdep magic cam from Peter Zijlstra <peterz@infradead.org>
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3f7a8058df2b..766b31ae3186 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -43,11 +43,7 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 
-#ifdef CONFIG_LOCKDEP
-# define BTRFS_MAX_LEVEL 7
-#else
-# define BTRFS_MAX_LEVEL 8
-#endif
+#define BTRFS_MAX_LEVEL 8
 
 /* holds pointers to all of the tree roots */
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
@@ -1715,7 +1711,8 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					     u64 empty_size);
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
-					    u64 bytenr, u32 blocksize);
+					    u64 bytenr, u32 blocksize,
+					    int level);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root,
 		       u64 num_bytes, u64 parent, u64 min_bytes,
@@ -1835,7 +1832,6 @@ void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
 void btrfs_set_path_blocking(struct btrfs_path *p);
-void btrfs_clear_path_blocking(struct btrfs_path *p);
 void btrfs_unlock_up_safe(struct btrfs_path *p, int level);
 
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,

commit e00f7308658622fbd483cb0d9fe41165bf9050d0
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Feb 12 14:11:25 2009 -0500

    Btrfs: remove btrfs_init_path
    
    btrfs_init_path was initially used when the path objects were on the
    stack.  Now all the work is done by btrfs_alloc_path and btrfs_init_path
    isn't required.
    
    This patch removes it, and just uses kmem_cache_zalloc to zero out the object.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 531db112c8bd..3f7a8058df2b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1834,7 +1834,6 @@ int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
-void btrfs_init_path(struct btrfs_path *p);
 void btrfs_set_path_blocking(struct btrfs_path *p);
 void btrfs_clear_path_blocking(struct btrfs_path *p);
 void btrfs_unlock_up_safe(struct btrfs_path *p, int level);

commit b4ce94de9b4d64e8ab3cf155d13653c666e22b9b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 4 09:25:08 2009 -0500

    Btrfs: Change btree locking to use explicit blocking points
    
    Most of the btrfs metadata operations can be protected by a spinlock,
    but some operations still need to schedule.
    
    So far, btrfs has been using a mutex along with a trylock loop,
    most of the time it is able to avoid going for the full mutex, so
    the trylock loop is a big performance gain.
    
    This commit is step one for getting rid of the blocking locks entirely.
    btrfs_tree_lock takes a spinlock, and the code explicitly switches
    to a blocking lock when it starts an operation that can schedule.
    
    We'll be able get rid of the blocking locks in smaller pieces over time.
    Tracing allows us to find the most common cause of blocking, so we
    can start with the hot spots first.
    
    The basic idea is:
    
    btrfs_tree_lock() returns with the spin lock held
    
    btrfs_set_lock_blocking() sets the EXTENT_BUFFER_BLOCKING bit in
    the extent buffer flags, and then drops the spin lock.  The buffer is
    still considered locked by all of the btrfs code.
    
    If btrfs_tree_lock gets the spinlock but finds the blocking bit set, it drops
    the spin lock and waits on a wait queue for the blocking bit to go away.
    
    Much of the code that needs to set the blocking bit finishes without actually
    blocking a good percentage of the time.  So, an adaptive spin is still
    used against the blocking bit to avoid very high context switch rates.
    
    btrfs_clear_lock_blocking() clears the blocking bit and returns
    with the spinlock held again.
    
    btrfs_tree_unlock() can be called on either blocking or spinning locks,
    it does the right thing based on the blocking bit.
    
    ctree.c has a helper function to set/clear all the locked buffers in a
    path as blocking.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f2b8d26b0472..531db112c8bd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1835,6 +1835,10 @@ void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
 void btrfs_init_path(struct btrfs_path *p);
+void btrfs_set_path_blocking(struct btrfs_path *p);
+void btrfs_clear_path_blocking(struct btrfs_path *p);
+void btrfs_unlock_up_safe(struct btrfs_path *p, int level);
+
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_path *path, int slot, int nr);
 int btrfs_del_leaf(struct btrfs_trans_handle *trans,

commit c487685d7c18a8481900755aa5c56a7a74193101
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 4 09:24:25 2009 -0500

    Btrfs: hash_lock is no longer needed
    
    Before metadata is written to disk, it is updated to reflect that writeout
    has begun.  Once this update is done, the block must be cow'd before it
    can be modified again.
    
    This update was originally synchronized by using a per-fs spinlock.  Today
    the buffers for the metadata blocks are locked before writeout begins,
    and everyone that tests the flag has the buffer locked as well.
    
    So, the per-fs spinlock (called hash_lock for no good reason) is no
    longer required.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index de103a8a815e..f2b8d26b0472 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -703,7 +703,6 @@ struct btrfs_fs_info {
 	struct super_block *sb;
 	struct inode *btree_inode;
 	struct backing_dev_info bdi;
-	spinlock_t hash_lock;
 	struct mutex trans_mutex;
 	struct mutex tree_log_mutex;
 	struct mutex transaction_kthread_mutex;

commit 7237f1833601dcc435a64176c2c347ec4bd959f9
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jan 21 12:54:03 2009 -0500

    Btrfs: fix tree logs parallel sync
    
    To improve performance, btrfs_sync_log merges tree log sync
    requests. But it wrongly merges sync requests for different
    tree logs. If multiple tree logs are synced at the same time,
    only one of them actually gets synced.
    
    This patch has following changes to fix the bug:
    
    Move most tree log related fields in btrfs_fs_info to
    btrfs_root. This allows merging sync requests separately
    for each tree log.
    
    Don't insert root item into the log root tree immediately
    after log tree is allocated. Root item for log tree is
    inserted when log tree get synced for the first time. This
    allows syncing the log root tree without first syncing all
    log trees.
    
    At tree-log sync, btrfs_sync_log first sync the log tree;
    then updates corresponding root item in the log root tree;
    sync the log root tree; then update the super block.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e1fec636f37f..de103a8a815e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -695,9 +695,7 @@ struct btrfs_fs_info {
 	struct btrfs_transaction *running_transaction;
 	wait_queue_head_t transaction_throttle;
 	wait_queue_head_t transaction_wait;
-
 	wait_queue_head_t async_submit_wait;
-	wait_queue_head_t tree_log_wait;
 
 	struct btrfs_super_block super_copy;
 	struct btrfs_super_block super_for_commit;
@@ -724,10 +722,6 @@ struct btrfs_fs_info {
 	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;
 	atomic_t async_delalloc_pages;
-	atomic_t tree_log_writers;
-	atomic_t tree_log_commit;
-	unsigned long tree_log_batch;
-	u64 tree_log_transid;
 
 	/*
 	 * this is used by the balancing code to wait for all the pending
@@ -827,7 +821,14 @@ struct btrfs_root {
 	struct kobject root_kobj;
 	struct completion kobj_unregister;
 	struct mutex objectid_mutex;
+
 	struct mutex log_mutex;
+	wait_queue_head_t log_writer_wait;
+	wait_queue_head_t log_commit_wait[2];
+	atomic_t log_writers;
+	atomic_t log_commit[2];
+	unsigned long log_transid;
+	unsigned long log_batch;
 
 	u64 objectid;
 	u64 last_trans;

commit 95029d7d598babf62276d9006e575992b1333ba5
Author: Jan Engelhardt <jengelh@medozas.de>
Date:   Wed Jan 21 10:49:16 2009 -0500

    Btrfs: change/remove typedef
    
    Change one typedef to a regular enum, and remove an unused one.
    
    Signed-off-by: Jan Engelhardt <jengelh@medozas.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index eee060f88113..e1fec636f37f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -454,17 +454,11 @@ struct btrfs_timespec {
 	__le32 nsec;
 } __attribute__ ((__packed__));
 
-typedef enum {
+enum btrfs_compression_type {
 	BTRFS_COMPRESS_NONE = 0,
 	BTRFS_COMPRESS_ZLIB = 1,
 	BTRFS_COMPRESS_LAST = 2,
-} btrfs_compression_type;
-
-/* we don't understand any encryption methods right now */
-typedef enum {
-	BTRFS_ENCRYPTION_NONE = 0,
-	BTRFS_ENCRYPTION_LAST = 1,
-} btrfs_encryption_type;
+};
 
 struct btrfs_inode_item {
 	/* nfs style generation number */

commit d397712bcc6a759a560fd247e6053ecae091f958
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 5 21:25:51 2009 -0500

    Btrfs: Fix checkpatch.pl warnings
    
    There were many, most are fixed now.  struct-funcs.c generates some warnings
    but these are bogus.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ccea0648e106..eee060f88113 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -126,7 +126,6 @@ struct btrfs_ordered_sum;
 static int btrfs_csum_sizes[] = { 4, 0 };
 
 /* four bytes for CRC32 */
-//#define BTRFS_CRC32_SIZE 4
 #define BTRFS_EMPTY_DIR_SIZE 0
 
 #define BTRFS_FT_UNKNOWN	0
@@ -283,8 +282,8 @@ struct btrfs_header {
 } __attribute__ ((__packed__));
 
 #define BTRFS_NODEPTRS_PER_BLOCK(r) (((r)->nodesize - \
-			        sizeof(struct btrfs_header)) / \
-			        sizeof(struct btrfs_key_ptr))
+				      sizeof(struct btrfs_header)) / \
+				     sizeof(struct btrfs_key_ptr))
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->leafsize))
 #define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
@@ -1512,7 +1511,7 @@ static inline struct btrfs_header *btrfs_buffer_header(struct extent_buffer *eb)
 
 static inline int btrfs_is_leaf(struct extent_buffer *eb)
 {
-	return (btrfs_header_level(eb) == 0);
+	return btrfs_header_level(eb) == 0;
 }
 
 /* struct btrfs_root_item */
@@ -1597,8 +1596,8 @@ static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 /* struct btrfs_file_extent_item */
 BTRFS_SETGET_FUNCS(file_extent_type, struct btrfs_file_extent_item, type, 8);
 
-static inline unsigned long btrfs_file_extent_inline_start(struct
-						   btrfs_file_extent_item *e)
+static inline unsigned long
+btrfs_file_extent_inline_start(struct btrfs_file_extent_item *e)
 {
 	unsigned long offset = (unsigned long)e;
 	offset += offsetof(struct btrfs_file_extent_item, disk_bytenr);
@@ -1660,20 +1659,20 @@ static inline int btrfs_set_root_name(struct btrfs_root *root,
 				      const char *name, int len)
 {
 	/* if we already have a name just free it */
-	if (root->name)
-		kfree(root->name);
+	kfree(root->name);
 
 	root->name = kmalloc(len+1, GFP_KERNEL);
 	if (!root->name)
 		return -ENOMEM;
 
 	memcpy(root->name, name, len);
-	root->name[len] ='\0';
+	root->name[len] = '\0';
 
 	return 0;
 }
 
-static inline u32 btrfs_level_size(struct btrfs_root *root, int level) {
+static inline u32 btrfs_level_size(struct btrfs_root *root, int level)
+{
 	if (level == 0)
 		return root->leafsize;
 	return root->nodesize;
@@ -1707,9 +1706,9 @@ int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);
-struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
-							 btrfs_fs_info *info,
-							 u64 bytenr);
+struct btrfs_block_group_cache *btrfs_lookup_block_group(
+						 struct btrfs_fs_info *info,
+						 u64 bytenr);
 u64 btrfs_find_block_group(struct btrfs_root *root,
 			   u64 search_start, u64 search_hint, int owner);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
@@ -1908,8 +1907,9 @@ int btrfs_search_root(struct btrfs_root *root, u64 search_start,
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid,
 			  struct btrfs_root *latest_root);
 /* dir-item.c */
-int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
-			  *root, const char *name, int name_len, u64 dir,
+int btrfs_insert_dir_item(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root, const char *name,
+			  int name_len, u64 dir,
 			  struct btrfs_key *location, u8 type, u64 index);
 struct btrfs_dir_item *btrfs_lookup_dir_item(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,

commit cad321ad529400c6ab24c501a67c3be720a0744c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Dec 17 14:51:42 2008 -0500

    Btrfs: shift all end_io work to thread pools
    
    bio_end_io for reads without checksumming on and btree writes were
    happening without using async thread pools.  This means the extent_io.c
    code had to use spin_lock_irq and friends on the rb tree locks for
    extent state.
    
    There were some irq safe vs unsafe lock inversions between the delallock
    lock and the extent state locks.  This patch gets rid of them by moving
    all end_io code into the thread pools.
    
    To avoid contention and deadlocks between the data end_io processing and the
    metadata end_io processing yet another thread pool is added to finish
    off metadata writes.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b89999de4564..ccea0648e106 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -758,6 +758,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers delalloc_workers;
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers endio_meta_workers;
+	struct btrfs_workers endio_meta_write_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers submit_workers;
 	/*

commit 17d217fe970d34720f4f1633dca73a6aa2f3d9d1
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Fri Dec 12 10:03:38 2008 -0500

    Btrfs: fix nodatasum handling in balancing code
    
    Checksums on data can be disabled by mount option, so it's
    possible some data extents don't have checksums or have
    invalid checksums. This causes trouble for data relocation.
    This patch contains following things to make data relocation
    work.
    
    1) make nodatasum/nodatacow mount option only affects new
    files. Checksums and COW on data are only controlled by the
    inode flags.
    
    2) check the existence of checksum in the nodatacow checker.
    If checksums exist, force COW the data extent. This ensure that
    checksum for a given block is either valid or does not exist.
    
    3) update data relocation code to properly handle the case
    of checksum missing.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8733081d97a3..b89999de4564 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1702,7 +1702,7 @@ int btrfs_update_pinned_extents(struct btrfs_root *root,
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root, u64 bytenr);
+			  struct btrfs_root *root, u64 objectid, u64 bytenr);
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);
@@ -1789,6 +1789,7 @@ int btrfs_reloc_tree_cache_ref(struct btrfs_trans_handle *trans,
 			       struct extent_buffer *buf, u64 orig_start);
 int btrfs_add_dead_reloc_root(struct btrfs_root *root);
 int btrfs_cleanup_reloc_trees(struct btrfs_root *root);
+int btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len);
 u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 /* ctree.c */
 int btrfs_previous_item(struct btrfs_root *root,
@@ -1994,6 +1995,8 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
+int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start,
+			     u64 end, struct list_head *list);
 /* inode.c */
 
 /* RHEL and EL kernels have a patch that renames PG_checked to FsMisc */

commit d2fb3437e4d8d12c73c587615ad187d5288547ec
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Dec 11 16:30:39 2008 -0500

    Btrfs: fix leaking block group on balance
    
    The block group structs are referenced in many different
    places, and it's not safe to free while balancing.  So, those block
    group structs were simply leaked instead.
    
    This patch replaces the block group pointer in the inode with the starting byte
    offset of the block group and adds reference counting to the block group
    struct.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5b0c79d22c09..8733081d97a3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -653,6 +653,9 @@ struct btrfs_block_group_cache {
 
 	/* for block groups in the same raid type */
 	struct list_head list;
+
+	/* usage count */
+	atomic_t count;
 };
 
 struct btrfs_leaf_ref_tree {
@@ -1706,10 +1709,8 @@ int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
 							 btrfs_fs_info *info,
 							 u64 bytenr);
-struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
-						 struct btrfs_block_group_cache
-						 *hint, u64 search_start,
-						 int data, int owner);
+u64 btrfs_find_block_group(struct btrfs_root *root,
+			   u64 search_start, u64 search_hint, int owner);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,
 					     u32 blocksize, u64 parent,
@@ -1770,6 +1771,7 @@ int btrfs_update_extent_ref(struct btrfs_trans_handle *trans,
 			    u64 owner_objectid);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
+int btrfs_extent_readonly(struct btrfs_root *root, u64 bytenr);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_root *root);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
@@ -2019,10 +2021,9 @@ int btrfs_start_delalloc_inodes(struct btrfs_root *root);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end);
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
-int btrfs_create_subvol_root(struct btrfs_root *new_root, struct dentry *dentry,
-		struct btrfs_trans_handle *trans, u64 new_dirid,
-		struct btrfs_block_group_cache *block_group);
-
+int btrfs_create_subvol_root(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *new_root, struct dentry *dentry,
+			     u64 new_dirid, u64 alloc_hint);
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio, unsigned long bio_flags);
 

commit 459931eca5f4b8c9ad259d07cc1ca49afed54804
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Dec 10 09:10:46 2008 -0500

    Btrfs: Delete csum items when freeing extents
    
    This finishes off the new checksumming code by removing csum items
    for extents that are no longer in use.
    
    The trick is doing it without racing because a single csum item may
    hold csums for more than one extent.  Extra checks are added to
    btrfs_csum_file_blocks to make sure that we are using the correct
    csum item after dropping locks.
    
    A new btrfs_split_item is added to split a single csum item so it
    can be split without dropping the leaf lock.  This is used to
    remove csum bytes from the middle of an item.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f72b43819349..5b0c79d22c09 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -409,6 +409,12 @@ struct btrfs_path {
 	int keep_locks;
 	int skip_locking;
 	int lowest_level;
+
+	/*
+	 * set by btrfs_split_item, tells search_slot to keep all locks
+	 * and to force calls to keep space in the nodes
+	 */
+	int search_for_split;
 };
 
 /*
@@ -1816,6 +1822,11 @@ int btrfs_truncate_item(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct btrfs_path *path,
 			u32 new_size, int from_end);
+int btrfs_split_item(struct btrfs_trans_handle *trans,
+		     struct btrfs_root *root,
+		     struct btrfs_path *path,
+		     struct btrfs_key *new_key,
+		     unsigned long split_offset);
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
@@ -1953,6 +1964,8 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       struct btrfs_key *location, int mod);
 
 /* file-item.c */
+int btrfs_del_csums(struct btrfs_trans_handle *trans,
+		    struct btrfs_root *root, u64 bytenr, u64 len);
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio, u32 *dst);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,

commit c3027eb5523d6983f12628f3fe13d8a7576db701
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 8 16:40:21 2008 -0500

    Btrfs: Add inode sequence number for NFS and reserved space in a few structs
    
    This adds a sequence number to the btrfs inode that is increased on
    every update.  NFS will be able to use that to detect when an inode has
    changed, without relying on inaccurate time fields.
    
    While we're here, this also:
    
    Puts reserved space into the super block and inode
    
    Adds a log root transid to the super so we can pick the newest super
    based on the fsync log as well as the main transaction ID.  For now
    the log root transid is always zero, but that'll get fixed.
    
    Adds a starting offset to the dev_item.  This will let us do better
    alignment calculations if we know the start of a partition on the disk.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 242b961ae6de..f72b43819349 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -196,6 +196,12 @@ struct btrfs_dev_item {
 	/* expected generation for this device */
 	__le64 generation;
 
+	/*
+	 * starting byte of this partition on the device,
+	 * to allowr for stripe alignment in the future
+	 */
+	__le64 start_offset;
+
 	/* grouping information for allocation decisions */
 	__le32 dev_group;
 
@@ -311,6 +317,9 @@ struct btrfs_super_block {
 	__le64 root;
 	__le64 chunk_root;
 	__le64 log_root;
+
+	/* this will help find the new super based on the log root */
+	__le64 log_root_transid;
 	__le64 total_bytes;
 	__le64 bytes_used;
 	__le64 root_dir_objectid;
@@ -329,7 +338,11 @@ struct btrfs_super_block {
 	u8 chunk_root_level;
 	u8 log_root_level;
 	struct btrfs_dev_item dev_item;
+
 	char label[BTRFS_LABEL_SIZE];
+
+	/* future expansion */
+	__le64 reserved[32];
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 } __attribute__ ((__packed__));
 
@@ -463,6 +476,14 @@ struct btrfs_inode_item {
 	__le64 rdev;
 	__le64 flags;
 
+	/* modification sequence number for NFS */
+	__le64 sequence;
+
+	/*
+	 * a little future expansion, for more than this we can
+	 * just grow the inode item and version it
+	 */
+	__le64 reserved[4];
 	struct btrfs_timespec atime;
 	struct btrfs_timespec ctime;
 	struct btrfs_timespec mtime;
@@ -1001,6 +1022,8 @@ BTRFS_SETGET_FUNCS(device_total_bytes, struct btrfs_dev_item, total_bytes, 64);
 BTRFS_SETGET_FUNCS(device_bytes_used, struct btrfs_dev_item, bytes_used, 64);
 BTRFS_SETGET_FUNCS(device_io_align, struct btrfs_dev_item, io_align, 32);
 BTRFS_SETGET_FUNCS(device_io_width, struct btrfs_dev_item, io_width, 32);
+BTRFS_SETGET_FUNCS(device_start_offset, struct btrfs_dev_item,
+		   start_offset, 64);
 BTRFS_SETGET_FUNCS(device_sector_size, struct btrfs_dev_item, sector_size, 32);
 BTRFS_SETGET_FUNCS(device_id, struct btrfs_dev_item, devid, 64);
 BTRFS_SETGET_FUNCS(device_group, struct btrfs_dev_item, dev_group, 32);
@@ -1135,6 +1158,7 @@ BTRFS_SETGET_FUNCS(inode_ref_index, struct btrfs_inode_ref, index, 64);
 
 /* struct btrfs_inode_item */
 BTRFS_SETGET_FUNCS(inode_generation, struct btrfs_inode_item, generation, 64);
+BTRFS_SETGET_FUNCS(inode_sequence, struct btrfs_inode_item, sequence, 64);
 BTRFS_SETGET_FUNCS(inode_transid, struct btrfs_inode_item, transid, 64);
 BTRFS_SETGET_FUNCS(inode_size, struct btrfs_inode_item, size, 64);
 BTRFS_SETGET_FUNCS(inode_nbytes, struct btrfs_inode_item, nbytes, 64);
@@ -1519,6 +1543,8 @@ BTRFS_SETGET_STACK_FUNCS(super_chunk_root_level, struct btrfs_super_block,
 			 chunk_root_level, 8);
 BTRFS_SETGET_STACK_FUNCS(super_log_root, struct btrfs_super_block,
 			 log_root, 64);
+BTRFS_SETGET_STACK_FUNCS(super_log_root_transid, struct btrfs_super_block,
+			 log_root_transid, 64);
 BTRFS_SETGET_STACK_FUNCS(super_log_root_level, struct btrfs_super_block,
 			 log_root_level, 8);
 BTRFS_SETGET_STACK_FUNCS(super_total_bytes, struct btrfs_super_block,

commit d20f7043fa65659136c1a7c3c456eeeb5c6f431f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 8 16:58:54 2008 -0500

    Btrfs: move data checksumming into a dedicated tree
    
    Btrfs stores checksums for each data block.  Until now, they have
    been stored in the subvolume trees, indexed by the inode that is
    referencing the data block.  This means that when we read the inode,
    we've probably read in at least some checksums as well.
    
    But, this has a few problems:
    
    * The checksums are indexed by logical offset in the file.  When
    compression is on, this means we have to do the expensive checksumming
    on the uncompressed data.  It would be faster if we could checksum
    the compressed data instead.
    
    * If we implement encryption, we'll be checksumming the plain text and
    storing that on disk.  This is significantly less secure.
    
    * For either compression or encryption, we have to get the plain text
    back before we can verify the checksum as correct.  This makes the raid
    layer balancing and extent moving much more expensive.
    
    * It makes the front end caching code more complex, as we have touch
    the subvolume and inodes as we cache extents.
    
    * There is potentitally one copy of the checksum in each subvolume
    referencing an extent.
    
    The solution used here is to store the extent checksums in a dedicated
    tree.  This allows us to index the checksums by phyiscal extent
    start and length.  It means:
    
    * The checksum is against the data stored on disk, after any compression
    or encryption is done.
    
    * The checksum is stored in a central location, and can be verified without
    following back references, or reading inodes.
    
    This makes compression significantly faster by reducing the amount of
    data that needs to be checksummed.  It will also allow much faster
    raid management code in general.
    
    The checksums are indexed by a key with a fixed objectid (a magic value
    in ctree.h) and offset set to the starting byte of the extent.  This
    allows us to copy the checksum items into the fsync log tree directly (or
    any other tree), without having to invent a second format for them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 96f2ec7ad5bd..242b961ae6de 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -73,6 +73,9 @@ struct btrfs_ordered_sum;
 /* directory objectid inside the root tree */
 #define BTRFS_ROOT_TREE_DIR_OBJECTID 6ULL
 
+/* holds checksums of all the data extents */
+#define BTRFS_CSUM_TREE_OBJECTID 7ULL
+
 /* orhpan objectid for tracking unlinked/truncated files */
 #define BTRFS_ORPHAN_OBJECTID -5ULL
 
@@ -84,6 +87,13 @@ struct btrfs_ordered_sum;
 #define BTRFS_TREE_RELOC_OBJECTID -8ULL
 #define BTRFS_DATA_RELOC_TREE_OBJECTID -9ULL
 
+/*
+ * extent checksums all have this objectid
+ * this allows them to share the logging tree
+ * for fsyncs
+ */
+#define BTRFS_EXTENT_CSUM_OBJECTID -10ULL
+
 /* dummy objectid represents multiple objectids */
 #define BTRFS_MULTIPLE_OBJECTIDS -255ULL
 
@@ -634,6 +644,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *chunk_root;
 	struct btrfs_root *dev_root;
 	struct btrfs_root *fs_root;
+	struct btrfs_root *csum_root;
 
 	/* the log root tree is a directory of all the other log roots */
 	struct btrfs_root *log_root_tree;
@@ -716,6 +727,7 @@ struct btrfs_fs_info {
 	struct btrfs_workers workers;
 	struct btrfs_workers delalloc_workers;
 	struct btrfs_workers endio_workers;
+	struct btrfs_workers endio_meta_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers submit_workers;
 	/*
@@ -858,13 +870,12 @@ struct btrfs_root {
  * extent data is for file data
  */
 #define BTRFS_EXTENT_DATA_KEY	108
+
 /*
- * csum items have the checksums for data in the extents
+ * extent csums are stored in a separate tree and hold csums for
+ * an entire extent on disk.
  */
-#define BTRFS_CSUM_ITEM_KEY	120
-
-
-/* reserve 21-31 for other file/dir stuff */
+#define BTRFS_EXTENT_CSUM_KEY	128
 
 /*
  * root items point to tree roots.  There are typically in the root
@@ -1917,7 +1928,7 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 
 /* file-item.c */
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
-			  struct bio *bio);
+			  struct bio *bio, u32 *dst);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,
@@ -1929,17 +1940,16 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_path *path, u64 objectid,
 			     u64 bytenr, int mod);
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, struct inode *inode,
+			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums);
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
-		       struct bio *bio);
+		       struct bio *bio, u64 file_start, int contig);
 int btrfs_csum_file_bytes(struct btrfs_root *root, struct inode *inode,
 			  u64 start, unsigned long len);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,
-					  u64 objectid, u64 offset,
-					  int cow);
+					  u64 bytenr, int cow);
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);

commit 2a7108ad89e1ea9a30afbbece8b581a0532afd12
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 2 09:58:02 2008 -0500

    Btrfs: rev the disk format for the inode compat and csum selection changes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6d8350332b1d..96f2ec7ad5bd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,7 +39,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_BFRfS_M"
+#define BTRFS_MAGIC "_BHRfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit 607d432da0542e84ddcd358adfddac6f68500e3d
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Dec 2 07:17:45 2008 -0500

    Btrfs: add support for multiple csum algorithms
    
    This patch gives us the space we will need in order to have different csum
    algorithims at some point in the future.  We save the csum algorithim type
    in the superblock, and use those instead of define's.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b5af1fc77c5d..6d8350332b1d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -109,8 +109,14 @@ struct btrfs_ordered_sum;
 
 /* 32 bytes in various csum fields */
 #define BTRFS_CSUM_SIZE 32
+
+/* csum types */
+#define BTRFS_CSUM_TYPE_CRC32	0
+
+static int btrfs_csum_sizes[] = { 4, 0 };
+
 /* four bytes for CRC32 */
-#define BTRFS_CRC32_SIZE 4
+//#define BTRFS_CRC32_SIZE 4
 #define BTRFS_EMPTY_DIR_SIZE 0
 
 #define BTRFS_FT_UNKNOWN	0
@@ -308,6 +314,7 @@ struct btrfs_super_block {
 	__le64 compat_flags;
 	__le64 compat_ro_flags;
 	__le64 incompat_flags;
+	__le16 csum_type;
 	u8 root_level;
 	u8 chunk_root_level;
 	u8 log_root_level;
@@ -1483,6 +1490,7 @@ BTRFS_SETGET_STACK_FUNCS(root_last_snapshot, struct btrfs_root_item,
 			 last_snapshot, 64);
 
 /* struct btrfs_super_block */
+
 BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);
 BTRFS_SETGET_STACK_FUNCS(super_flags, struct btrfs_super_block, flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_generation, struct btrfs_super_block,
@@ -1524,6 +1532,15 @@ BTRFS_SETGET_STACK_FUNCS(super_compat_ro_flags, struct btrfs_super_block,
 			 compat_flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_incompat_flags, struct btrfs_super_block,
 			 incompat_flags, 64);
+BTRFS_SETGET_STACK_FUNCS(super_csum_type, struct btrfs_super_block,
+			 csum_type, 16);
+
+static inline int btrfs_super_csum_size(struct btrfs_super_block *s)
+{
+	int t = btrfs_super_csum_type(s);
+	BUG_ON(t >= ARRAY_SIZE(btrfs_csum_sizes));
+	return btrfs_csum_sizes[t];
+}
 
 static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 {

commit f2b636e80d8206dd4012de6e973c2367259a7d22
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Dec 2 06:36:08 2008 -0500

    Btrfs: add support for compat flags to btrfs
    
    This adds the necessary disk format for handling compatibility flags
    in the future to handle disk format changes.  We have a compat_flags,
    compat_ro_flags and incompat_flags set for the super block.  Compat
    flags will be to hold the features that are compatible with older
    versions of btrfs, compat_ro flags have features that are compatible
    with older versions of btrfs if the fs is mounted read only, and
    incompat_flags has features that are incompatible with older versions
    of btrfs.  This also axes the compat_flags field for the inode and
    just makes the flags field a 64bit field, and changes the root item
    flags field to 64bit.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 166896dd44c2..b5af1fc77c5d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -305,6 +305,9 @@ struct btrfs_super_block {
 	__le32 stripesize;
 	__le32 sys_chunk_array_size;
 	__le64 chunk_root_generation;
+	__le64 compat_flags;
+	__le64 compat_ro_flags;
+	__le64 incompat_flags;
 	u8 root_level;
 	u8 chunk_root_level;
 	u8 log_root_level;
@@ -313,6 +316,14 @@ struct btrfs_super_block {
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 } __attribute__ ((__packed__));
 
+/*
+ * Compat flags that we support.  If any incompat flags are set other than the
+ * ones specified below then we will fail to mount
+ */
+#define BTRFS_FEATURE_COMPAT_SUPP	0x0
+#define BTRFS_FEATURE_COMPAT_RO_SUPP	0x0
+#define BTRFS_FEATURE_INCOMPAT_SUPP	0x0
+
 /*
  * A leaf is full of items. offset and size tell us where to find
  * the item in the leaf (relative to the start of the data area)
@@ -433,8 +444,7 @@ struct btrfs_inode_item {
 	__le32 gid;
 	__le32 mode;
 	__le64 rdev;
-	__le16 flags;
-	__le16 compat_flags;
+	__le64 flags;
 
 	struct btrfs_timespec atime;
 	struct btrfs_timespec ctime;
@@ -462,7 +472,7 @@ struct btrfs_root_item {
 	__le64 byte_limit;
 	__le64 bytes_used;
 	__le64 last_snapshot;
-	__le32 flags;
+	__le64 flags;
 	__le32 refs;
 	struct btrfs_disk_key drop_progress;
 	u8 drop_level;
@@ -1116,9 +1126,7 @@ BTRFS_SETGET_FUNCS(inode_uid, struct btrfs_inode_item, uid, 32);
 BTRFS_SETGET_FUNCS(inode_gid, struct btrfs_inode_item, gid, 32);
 BTRFS_SETGET_FUNCS(inode_mode, struct btrfs_inode_item, mode, 32);
 BTRFS_SETGET_FUNCS(inode_rdev, struct btrfs_inode_item, rdev, 64);
-BTRFS_SETGET_FUNCS(inode_flags, struct btrfs_inode_item, flags, 16);
-BTRFS_SETGET_FUNCS(inode_compat_flags, struct btrfs_inode_item,
-		   compat_flags, 16);
+BTRFS_SETGET_FUNCS(inode_flags, struct btrfs_inode_item, flags, 64);
 
 static inline struct btrfs_timespec *
 btrfs_inode_atime(struct btrfs_inode_item *inode_item)
@@ -1468,7 +1476,7 @@ BTRFS_SETGET_STACK_FUNCS(root_bytenr, struct btrfs_root_item, bytenr, 64);
 BTRFS_SETGET_STACK_FUNCS(root_level, struct btrfs_root_item, level, 8);
 BTRFS_SETGET_STACK_FUNCS(root_dirid, struct btrfs_root_item, root_dirid, 64);
 BTRFS_SETGET_STACK_FUNCS(root_refs, struct btrfs_root_item, refs, 32);
-BTRFS_SETGET_STACK_FUNCS(root_flags, struct btrfs_root_item, flags, 32);
+BTRFS_SETGET_STACK_FUNCS(root_flags, struct btrfs_root_item, flags, 64);
 BTRFS_SETGET_STACK_FUNCS(root_used, struct btrfs_root_item, bytes_used, 64);
 BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, byte_limit, 64);
 BTRFS_SETGET_STACK_FUNCS(root_last_snapshot, struct btrfs_root_item,
@@ -1510,6 +1518,12 @@ BTRFS_SETGET_STACK_FUNCS(super_root_dir, struct btrfs_super_block,
 			 root_dir_objectid, 64);
 BTRFS_SETGET_STACK_FUNCS(super_num_devices, struct btrfs_super_block,
 			 num_devices, 64);
+BTRFS_SETGET_STACK_FUNCS(super_compat_flags, struct btrfs_super_block,
+			 compat_flags, 64);
+BTRFS_SETGET_STACK_FUNCS(super_compat_ro_flags, struct btrfs_super_block,
+			 compat_flags, 64);
+BTRFS_SETGET_STACK_FUNCS(super_incompat_flags, struct btrfs_super_block,
+			 incompat_flags, 64);
 
 static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 {

commit ea6a478ed9758cb0f5af228104b9434840aa20ff
Author: Josef Bacik <jbacik@redhat.com>
Date:   Thu Nov 20 12:16:16 2008 -0500

    Btrfs: Fix for lockdep warnings with alloc_mutex and pinned_mutex
    
    This the lockdep complaint by having a different mutex to gaurd caching the
    block group, so you don't end up with this backwards dependancy.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0f2a9b584fb6..166896dd44c2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -580,6 +580,7 @@ struct btrfs_block_group_cache {
 	struct btrfs_block_group_item item;
 	spinlock_t lock;
 	struct mutex alloc_mutex;
+	struct mutex cache_mutex;
 	u64 pinned;
 	u64 reserved;
 	u64 flags;

commit 73e9f5beb16f568f797bba87f082556fac18dede
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 18 11:50:33 2008 -0500

    Btrfs: Update the disk format for the seed device and new root code
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 70b3dbb4de12..0f2a9b584fb6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,7 +39,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_BDRfS_M"
+#define BTRFS_MAGIC "_BFRfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit ea9e8b11bd1252dcbc23afefcf1a52ec6aa3c113
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 21:14:24 2008 -0500

    Btrfs: prevent loops in the directory tree when creating snapshots
    
    For a directory tree:
    
    /mnt/subvolA/subvolB
    
    btrfsctl -s /mnt/subvolA/subvolB /mnt
    
    Will create a directory loop with subvolA under subvolB.  This
    commit uses the forward refs for each subvol and snapshot to error out
    before creating the loop.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ad2cbe63503c..70b3dbb4de12 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1801,6 +1801,9 @@ int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct extent_buffer *node,
 			struct extent_buffer *parent);
 /* root-item.c */
+int btrfs_find_root_ref(struct btrfs_root *tree_root,
+		   struct btrfs_path *path,
+		   u64 root_id, u64 ref_id);
 int btrfs_add_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *tree_root,
 		       u64 root_id, u8 type, u64 ref_id,

commit 0660b5af3f7ac0fac69de975914e1f4a3a586fb3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 20:37:39 2008 -0500

    Btrfs: Add backrefs and forward refs for subvols and snapshots
    
    Subvols and snapshots can now be referenced from any point in the directory
    tree.  We need to maintain back refs for them so we can find lost
    subvols.
    
    Forward refs are added so that we know all of the subvols and
    snapshots referenced anywhere in the directory tree of a single subvol.  This
    can be used to do recursive snapshotting (but they aren't yet) and it is
    also used to detect and prevent directory loops when creating new snapshots.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b3bc65b08c6a..ad2cbe63503c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -469,6 +469,15 @@ struct btrfs_root_item {
 	u8 level;
 } __attribute__ ((__packed__));
 
+/*
+ * this is used for both forward and backward root refs
+ */
+struct btrfs_root_ref {
+	__le64 dirid;
+	__le64 sequence;
+	__le16 name_len;
+} __attribute__ ((__packed__));
+
 #define BTRFS_FILE_EXTENT_INLINE 0
 #define BTRFS_FILE_EXTENT_REG 1
 #define BTRFS_FILE_EXTENT_PREALLOC 2
@@ -814,27 +823,27 @@ struct btrfs_root {
  * the FS
  */
 #define BTRFS_INODE_ITEM_KEY		1
-#define BTRFS_INODE_REF_KEY		2
-#define BTRFS_XATTR_ITEM_KEY		8
-#define BTRFS_ORPHAN_ITEM_KEY		9
+#define BTRFS_INODE_REF_KEY		12
+#define BTRFS_XATTR_ITEM_KEY		24
+#define BTRFS_ORPHAN_ITEM_KEY		48
 /* reserve 2-15 close to the inode for later flexibility */
 
 /*
  * dir items are the name -> inode pointers in a directory.  There is one
  * for every name in a directory.
  */
-#define BTRFS_DIR_LOG_ITEM_KEY  14
-#define BTRFS_DIR_LOG_INDEX_KEY 15
-#define BTRFS_DIR_ITEM_KEY	16
-#define BTRFS_DIR_INDEX_KEY	17
+#define BTRFS_DIR_LOG_ITEM_KEY  60
+#define BTRFS_DIR_LOG_INDEX_KEY 72
+#define BTRFS_DIR_ITEM_KEY	84
+#define BTRFS_DIR_INDEX_KEY	96
 /*
  * extent data is for file data
  */
-#define BTRFS_EXTENT_DATA_KEY	18
+#define BTRFS_EXTENT_DATA_KEY	108
 /*
  * csum items have the checksums for data in the extents
  */
-#define BTRFS_CSUM_ITEM_KEY	19
+#define BTRFS_CSUM_ITEM_KEY	120
 
 
 /* reserve 21-31 for other file/dir stuff */
@@ -843,23 +852,37 @@ struct btrfs_root {
  * root items point to tree roots.  There are typically in the root
  * tree used by the super block to find all the other trees
  */
-#define BTRFS_ROOT_ITEM_KEY	32
+#define BTRFS_ROOT_ITEM_KEY	132
+
+/*
+ * root backrefs tie subvols and snapshots to the directory entries that
+ * reference them
+ */
+#define BTRFS_ROOT_BACKREF_KEY	144
+
+/*
+ * root refs make a fast index for listing all of the snapshots and
+ * subvolumes referenced by a given root.  They point directly to the
+ * directory item in the root that references the subvol
+ */
+#define BTRFS_ROOT_REF_KEY	156
+
 /*
  * extent items are in the extent map tree.  These record which blocks
  * are used, and how many references there are to each block
  */
-#define BTRFS_EXTENT_ITEM_KEY	33
-#define BTRFS_EXTENT_REF_KEY	34
+#define BTRFS_EXTENT_ITEM_KEY	168
+#define BTRFS_EXTENT_REF_KEY	180
 
 /*
  * block groups give us hints into the extent allocation trees.  Which
  * blocks are free etc etc
  */
-#define BTRFS_BLOCK_GROUP_ITEM_KEY 50
+#define BTRFS_BLOCK_GROUP_ITEM_KEY 192
 
-#define BTRFS_DEV_EXTENT_KEY	75
-#define BTRFS_DEV_ITEM_KEY	76
-#define BTRFS_CHUNK_ITEM_KEY	77
+#define BTRFS_DEV_EXTENT_KEY	204
+#define BTRFS_DEV_ITEM_KEY	216
+#define BTRFS_CHUNK_ITEM_KEY	228
 
 /*
  * string items are for debugging.  They just store a short string of
@@ -1274,6 +1297,13 @@ static inline void btrfs_set_item_key(struct extent_buffer *eb,
 
 BTRFS_SETGET_FUNCS(dir_log_end, struct btrfs_dir_log_item, end, 64);
 
+/*
+ * struct btrfs_root_ref
+ */
+BTRFS_SETGET_FUNCS(root_ref_dirid, struct btrfs_root_ref, dirid, 64);
+BTRFS_SETGET_FUNCS(root_ref_sequence, struct btrfs_root_ref, sequence, 64);
+BTRFS_SETGET_FUNCS(root_ref_name_len, struct btrfs_root_ref, name_len, 16);
+
 /* struct btrfs_dir_item */
 BTRFS_SETGET_FUNCS(dir_data_len, struct btrfs_dir_item, data_len, 16);
 BTRFS_SETGET_FUNCS(dir_type, struct btrfs_dir_item, type, 8);
@@ -1771,6 +1801,11 @@ int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
 			struct extent_buffer *node,
 			struct extent_buffer *parent);
 /* root-item.c */
+int btrfs_add_root_ref(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *tree_root,
+		       u64 root_id, u8 type, u64 ref_id,
+		       u64 dirid, u64 sequence,
+		       const char *name, int name_len);
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_key *key);
 int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root

commit 3394e1607eaf870ebba37d303fbd590a4c569908
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 20:42:26 2008 -0500

    Btrfs: Give each subvol and snapshot their own anonymous devid
    
    Each subvolume has its own private inode number space, and so we need
    to fill in different device numbers for each subvolume to avoid confusing
    applications.
    
    This commit puts a struct super_block into struct btrfs_root so it can
    call set_anon_super() and get a different device number generated for
    each root.
    
    btrfs_rename is changed to prevent renames across subvols.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5611f8e035a4..b3bc65b08c6a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -799,6 +799,12 @@ struct btrfs_root {
 	spinlock_t list_lock;
 	struct list_head dead_list;
 	struct list_head orphan_list;
+
+	/*
+	 * right now this just gets used so that a root has its own devid
+	 * for stat.  It may be used for more later
+	 */
+	struct super_block anon_super;
 };
 
 /*

commit 3de4586c5278a28107030c336956381f69ff7a9d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 21:02:50 2008 -0500

    Btrfs: Allow subvolumes and snapshots anywhere in the directory tree
    
    Before, all snapshots and subvolumes lived in a single flat directory.  This
    was awkward and confusing because the single flat directory was only writable
    with the ioctls.
    
    This commit changes the ioctls to create subvols and snapshots at any
    point in the directory tree.  This requires making separate ioctls for
    snapshot and subvol creation instead of a combining them into one.
    
    The subvol ioctl does:
    
    btrfsctl -S subvol_name parent_dir
    
    After the ioctl is done subvol_name lives inside parent_dir.
    
    The snapshot ioctl does:
    
    btrfsctl -s path_for_snapshot root_to_snapshot
    
    path_for_snapshot can be an absolute or relative path.  btrfsctl breaks it up
    into directory and basename components.
    
    root_to_snapshot can be any file or directory in the FS.  The snapshot
    is taken of the entire root where that file lives.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5ff74282a620..5611f8e035a4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -606,6 +606,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *tree_root;
 	struct btrfs_root *chunk_root;
 	struct btrfs_root *dev_root;
+	struct btrfs_root *fs_root;
 
 	/* the log root tree is a directory of all the other log roots */
 	struct btrfs_root *log_root_tree;
@@ -758,7 +759,6 @@ struct btrfs_root {
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
-	struct inode *inode;
 	struct extent_io_tree dirty_log_pages;
 
 	struct kobject root_kobj;
@@ -1876,6 +1876,8 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 #define PageChecked PageFsMisc
 #endif
 
+struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry);
+int btrfs_set_inode_index(struct inode *dir, u64 *index);
 int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root,
 		       struct inode *dir, struct inode *inode,
@@ -1896,9 +1898,6 @@ int btrfs_create_subvol_root(struct btrfs_root *new_root, struct dentry *dentry,
 		struct btrfs_trans_handle *trans, u64 new_dirid,
 		struct btrfs_block_group_cache *block_group);
 
-void btrfs_invalidate_dcache_root(struct btrfs_root *root, char *name,
-				  int namelen);
-
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio, unsigned long bio_flags);
 

commit 2b82032c34ec40515d3c45c36cd1961f37977de8
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Mon Nov 17 21:11:30 2008 -0500

    Btrfs: Seed device support
    
    Seed device is a special btrfs with SEEDING super flag
    set and can only be mounted in read-only mode. Seed
    devices allow people to create new btrfs on top of it.
    
    The new FS contains the same contents as the seed device,
    but it can be mounted in read-write mode.
    
    This patch does the following:
    
    1) split code in btrfs_alloc_chunk into two parts. The first part does makes
    the newly allocated chunk usable, but does not do any operation that modifies
    the chunk tree. The second part does the the chunk tree modifications. This
    division is for the bootstrap step of adding storage to the seed device.
    
    2) Update device management code to handle seed device.
    The basic idea is: For an FS grown from seed devices, its
    seed devices are put into a list. Seed devices are
    opened on demand at mounting time. If any seed device is
    missing or has been changed, btrfs kernel module will
    refuse to mount the FS.
    
    3) make btrfs_find_block_group not return NULL when all
    block groups are read-only.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c4c6c127323b..5ff74282a620 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -177,6 +177,9 @@ struct btrfs_dev_item {
 	/* type and info about this device */
 	__le64 type;
 
+	/* expected generation for this device */
+	__le64 generation;
+
 	/* grouping information for allocation decisions */
 	__le32 dev_group;
 
@@ -188,6 +191,9 @@ struct btrfs_dev_item {
 
 	/* btrfs generated uuid for this device */
 	u8 uuid[BTRFS_UUID_SIZE];
+
+	/* uuid of FS who owns this device */
+	u8 fsid[BTRFS_UUID_SIZE];
 } __attribute__ ((__packed__));
 
 struct btrfs_stripe {
@@ -263,6 +269,7 @@ struct btrfs_header {
 					sizeof(struct btrfs_item) - \
 					sizeof(struct btrfs_file_extent_item))
 
+#define BTRFS_SUPER_FLAG_SEEDING (1ULL << 32)
 
 /*
  * this is a very generous portion of the super block, giving us
@@ -278,7 +285,7 @@ struct btrfs_header {
 struct btrfs_super_block {
 	u8 csum[BTRFS_CSUM_SIZE];
 	/* the first 4 fields must match struct btrfs_header */
-	u8 fsid[16];    /* FS specific uuid */
+	u8 fsid[BTRFS_FSID_SIZE];    /* FS specific uuid */
 	__le64 bytenr; /* this block number */
 	__le64 flags;
 
@@ -941,6 +948,7 @@ BTRFS_SETGET_FUNCS(device_id, struct btrfs_dev_item, devid, 64);
 BTRFS_SETGET_FUNCS(device_group, struct btrfs_dev_item, dev_group, 32);
 BTRFS_SETGET_FUNCS(device_seek_speed, struct btrfs_dev_item, seek_speed, 8);
 BTRFS_SETGET_FUNCS(device_bandwidth, struct btrfs_dev_item, bandwidth, 8);
+BTRFS_SETGET_FUNCS(device_generation, struct btrfs_dev_item, generation, 64);
 
 BTRFS_SETGET_STACK_FUNCS(stack_device_type, struct btrfs_dev_item, type, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_device_total_bytes, struct btrfs_dev_item,
@@ -960,12 +968,19 @@ BTRFS_SETGET_STACK_FUNCS(stack_device_seek_speed, struct btrfs_dev_item,
 			 seek_speed, 8);
 BTRFS_SETGET_STACK_FUNCS(stack_device_bandwidth, struct btrfs_dev_item,
 			 bandwidth, 8);
+BTRFS_SETGET_STACK_FUNCS(stack_device_generation, struct btrfs_dev_item,
+			 generation, 64);
 
 static inline char *btrfs_device_uuid(struct btrfs_dev_item *d)
 {
 	return (char *)d + offsetof(struct btrfs_dev_item, uuid);
 }
 
+static inline char *btrfs_device_fsid(struct btrfs_dev_item *d)
+{
+	return (char *)d + offsetof(struct btrfs_dev_item, fsid);
+}
+
 BTRFS_SETGET_FUNCS(chunk_length, struct btrfs_chunk, length, 64);
 BTRFS_SETGET_FUNCS(chunk_owner, struct btrfs_chunk, owner, 64);
 BTRFS_SETGET_FUNCS(chunk_stripe_len, struct btrfs_chunk, stripe_len, 64);
@@ -1661,6 +1676,7 @@ int btrfs_reloc_tree_cache_ref(struct btrfs_trans_handle *trans,
 			       struct extent_buffer *buf, u64 orig_start);
 int btrfs_add_dead_reloc_root(struct btrfs_root *root);
 int btrfs_cleanup_reloc_trees(struct btrfs_root *root);
+u64 btrfs_reduce_alloc_profile(struct btrfs_root *root, u64 flags);
 /* ctree.c */
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,

commit c146afad2c7fea6a366d4945c1bab9b03880f526
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Nov 12 14:34:12 2008 -0500

    Btrfs: mount ro and remount support
    
    This patch adds mount ro and remount support. The main
    changes in patch are: adding btrfs_remount and related
    helper function; splitting the transaction related code
    out of close_ctree into btrfs_commit_super; updating
    allocator to properly handle read only block group.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f575939e0258..c4c6c127323b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -541,6 +541,7 @@ struct btrfs_space_info {
 	u64 bytes_used;
 	u64 bytes_pinned;
 	u64 bytes_reserved;
+	u64 bytes_readonly;
 	int full;
 	int force_alloc;
 	struct list_head list;

commit f3465ca44e2a51fd647c167045768a8ab5a96603
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Nov 12 14:19:50 2008 -0500

    Btrfs: batch extent inserts/updates/deletions on the extent root
    
    While profiling the allocator I noticed a good amount of time was being spent in
    finish_current_insert and del_pending_extents, and as the filesystem filled up
    more and more time was being spent in those functions.  This patch aims to try
    and reduce that problem.  This happens two ways
    
    1) track if we tried to delete an extent that we are going to update or insert.
    Once we get into finish_current_insert we discard any of the extents that were
    marked for deletion.  This saves us from doing unnecessary work almost every
    time finish_current_insert runs.
    
    2) Batch insertion/updates/deletions.  Instead of doing a btrfs_search_slot for
    each individual extent and doing the needed operation, we instead keep the leaf
    around and see if there is anything else we can do on that leaf.  On the insert
    case I introduced a btrfs_insert_some_items, which will take an array of keys
    with an array of data_sizes and try and squeeze in as many of those keys as
    possible, and then return how many keys it was able to insert.  In the update
    case we search for an extent ref, update the ref and then loop through the leaf
    to see if any of the other refs we are looking to update are on that leaf, and
    then once we are done we release the path and search for the next ref we need to
    update.  And finally for the deletion we try and delete the extent+ref in pairs,
    so we will try to find extent+ref pairs next to the extent we are trying to free
    and free them in bulk if possible.
    
    This along with the other cluster fix that Chris pushed out a bit ago helps make
    the allocator preform more uniformly as it fills up the disk.  There is still a
    slight drop as we fill up the disk since we start having to stick new blocks in
    odd places which results in more COW's than on a empty fs, but the drop is not
    nearly as severe as it was before.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c83cc5b2ded7..f575939e0258 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1719,6 +1719,11 @@ static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 
 int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, void *data, u32 data_size);
+int btrfs_insert_some_items(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root,
+			    struct btrfs_path *path,
+			    struct btrfs_key *cpu_key, u32 *data_size,
+			    int nr);
 int btrfs_insert_empty_items(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path,

commit 771ed689d2cd53439e28e095bc38fbe40a71429e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 6 22:02:51 2008 -0500

    Btrfs: Optimize compressed writeback and reads
    
    When reading compressed extents, try to put pages into the page cache
    for any pages covered by the compressed extent that readpages didn't already
    preload.
    
    Add an async work queue to handle transformations at delayed allocation processing
    time.  Right now this is just compression.  The workflow is:
    
    1) Find offsets in the file marked for delayed allocation
    2) Lock the pages
    3) Lock the state bits
    4) Call the async delalloc code
    
    The async delalloc code clears the state lock bits and delalloc bits.  It is
    important this happens before the range goes into the work queue because
    otherwise it might deadlock with other work queue items that try to lock
    those extent bits.
    
    The file pages are compressed, and if the compression doesn't work the
    pages are written back directly.
    
    An ordered work queue is used to make sure the inodes are written in the same
    order that pdflush or writepages sent them down.
    
    This changes extent_write_cache_pages to let the writepage function
    update the wbc nr_written count.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 689df070c8e9..c83cc5b2ded7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -625,8 +625,8 @@ struct btrfs_fs_info {
 	struct btrfs_transaction *running_transaction;
 	wait_queue_head_t transaction_throttle;
 	wait_queue_head_t transaction_wait;
-	wait_queue_head_t async_submit_wait;
 
+	wait_queue_head_t async_submit_wait;
 	wait_queue_head_t tree_log_wait;
 
 	struct btrfs_super_block super_copy;
@@ -653,6 +653,7 @@ struct btrfs_fs_info {
 	atomic_t nr_async_submits;
 	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;
+	atomic_t async_delalloc_pages;
 	atomic_t tree_log_writers;
 	atomic_t tree_log_commit;
 	unsigned long tree_log_batch;
@@ -677,6 +678,7 @@ struct btrfs_fs_info {
 	 * two
 	 */
 	struct btrfs_workers workers;
+	struct btrfs_workers delalloc_workers;
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers submit_workers;

commit 537fb0671549a9a6457ce42a25ab34b29d97a256
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Oct 31 12:54:14 2008 -0400

    Btrfs: rev the disk format for fallocate
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d5ba3d1aaf9a..689df070c8e9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,7 +39,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_BCRfS_M"
+#define BTRFS_MAGIC "_BDRfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit d899e05215178fed903ad0e7fc1cb4d8e0cc0a88
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Oct 30 14:25:28 2008 -0400

    Btrfs: Add fallocate support v2
    This patch updates btrfs-progs for fallocate support.
    
    fallocate is a little different in Btrfs because we need to tell the
    COW system that a given preallocated extent doesn't need to be
    cow'd as long as there are no snapshots of it.  This leverages the
    -o nodatacow checks.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8bf6a085a730..d5ba3d1aaf9a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -462,8 +462,9 @@ struct btrfs_root_item {
 	u8 level;
 } __attribute__ ((__packed__));
 
-#define BTRFS_FILE_EXTENT_REG 0
-#define BTRFS_FILE_EXTENT_INLINE 1
+#define BTRFS_FILE_EXTENT_INLINE 0
+#define BTRFS_FILE_EXTENT_REG 1
+#define BTRFS_FILE_EXTENT_PREALLOC 2
 
 struct btrfs_file_extent_item {
 	/*
@@ -868,6 +869,7 @@ struct btrfs_root {
 #define BTRFS_INODE_NODATACOW		(1 << 1)
 #define BTRFS_INODE_READONLY		(1 << 2)
 #define BTRFS_INODE_NOCOMPRESS		(1 << 3)
+#define BTRFS_INODE_PREALLOC		(1 << 4)
 #define btrfs_clear_flag(inode, flag)	(BTRFS_I(inode)->flags &= \
 					 ~BTRFS_INODE_##flag)
 #define btrfs_set_flag(inode, flag)	(BTRFS_I(inode)->flags |= \
@@ -1924,6 +1926,9 @@ extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
 		       u64 start, u64 end, u64 inline_limit, u64 *hint_block);
+int btrfs_mark_extent_written(struct btrfs_trans_handle *trans,
+			      struct btrfs_root *root,
+			      struct inode *inode, u64 start, u64 end);
 int btrfs_release_file(struct inode *inode, struct file *file);
 
 /* tree-defrag.c */

commit 80ff385665b7fca29fefe358a60ab0d09f9b8e87
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Oct 30 14:20:02 2008 -0400

    Btrfs: update nodatacow code v2
    
    This patch simplifies the nodatacow checker. If all references
    were created after the latest snapshot, then we can avoid COW
    safely. This patch also updates run_delalloc_nocow to do more
    fine-grained checking.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ca5547af6090..8bf6a085a730 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -454,6 +454,7 @@ struct btrfs_root_item {
 	__le64 bytenr;
 	__le64 byte_limit;
 	__le64 bytes_used;
+	__le64 last_snapshot;
 	__le32 flags;
 	__le32 refs;
 	struct btrfs_disk_key drop_progress;
@@ -1413,6 +1414,8 @@ BTRFS_SETGET_STACK_FUNCS(root_refs, struct btrfs_root_item, refs, 32);
 BTRFS_SETGET_STACK_FUNCS(root_flags, struct btrfs_root_item, flags, 32);
 BTRFS_SETGET_STACK_FUNCS(root_used, struct btrfs_root_item, bytes_used, 64);
 BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, byte_limit, 64);
+BTRFS_SETGET_STACK_FUNCS(root_last_snapshot, struct btrfs_root_item,
+			 last_snapshot, 64);
 
 /* struct btrfs_super_block */
 BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);
@@ -1564,9 +1567,8 @@ int btrfs_update_pinned_extents(struct btrfs_root *root,
 				u64 bytenr, u64 num, int pin);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct extent_buffer *leaf);
-int btrfs_cross_ref_exists(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root,
-			   struct btrfs_key *key, u64 bytenr);
+int btrfs_cross_ref_exist(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root, u64 bytenr);
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);

commit 9036c10208e1fc496cef7692ba66a78699b360dc
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Oct 30 14:19:41 2008 -0400

    Btrfs: update hole handling v2
    
    This patch splits the hole insertion code out of btrfs_setattr
    into btrfs_cont_expand and updates btrfs_get_extent to properly
    handle the case that file extent items are not continuous.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index abb27332c914..ca5547af6090 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1908,6 +1908,7 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
 int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
 void btrfs_orphan_cleanup(struct btrfs_root *root);
+int btrfs_cont_expand(struct inode *inode, loff_t size);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);

commit 09fde3c9ba360926ce021c184a1ee343f4d8fa19
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Oct 29 14:49:04 2008 -0400

    Btrfs: Rev the disk format for compression and root pointer generation fields

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0621ab90b1a5..abb27332c914 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,7 +39,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_BBRfS_M"
+#define BTRFS_MAGIC "_BCRfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit 84234f3a1f7c532e4afeba03cc8e7e4a8a5277ea
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: Add root tree pointer transaction ids
    
    This patch adds transaction IDs to root tree pointers.
    Transaction IDs in tree pointers are compared with the
    generation numbers in block headers when reading root
    blocks of trees. This can detect some types of IO errors.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fdba4f1b634e..0621ab90b1a5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -297,6 +297,7 @@ struct btrfs_super_block {
 	__le32 leafsize;
 	__le32 stripesize;
 	__le32 sys_chunk_array_size;
+	__le64 chunk_root_generation;
 	u8 root_level;
 	u8 chunk_root_level;
 	u8 log_root_level;
@@ -448,6 +449,7 @@ struct btrfs_dir_item {
 
 struct btrfs_root_item {
 	struct btrfs_inode_item inode;
+	__le64 generation;
 	__le64 root_dirid;
 	__le64 bytenr;
 	__le64 byte_limit;
@@ -1396,10 +1398,14 @@ static inline int btrfs_is_leaf(struct extent_buffer *eb)
 }
 
 /* struct btrfs_root_item */
+BTRFS_SETGET_FUNCS(disk_root_generation, struct btrfs_root_item,
+		   generation, 64);
 BTRFS_SETGET_FUNCS(disk_root_refs, struct btrfs_root_item, refs, 32);
 BTRFS_SETGET_FUNCS(disk_root_bytenr, struct btrfs_root_item, bytenr, 64);
 BTRFS_SETGET_FUNCS(disk_root_level, struct btrfs_root_item, level, 8);
 
+BTRFS_SETGET_STACK_FUNCS(root_generation, struct btrfs_root_item,
+			 generation, 64);
 BTRFS_SETGET_STACK_FUNCS(root_bytenr, struct btrfs_root_item, bytenr, 64);
 BTRFS_SETGET_STACK_FUNCS(root_level, struct btrfs_root_item, level, 8);
 BTRFS_SETGET_STACK_FUNCS(root_dirid, struct btrfs_root_item, root_dirid, 64);
@@ -1416,6 +1422,8 @@ BTRFS_SETGET_STACK_FUNCS(super_generation, struct btrfs_super_block,
 BTRFS_SETGET_STACK_FUNCS(super_root, struct btrfs_super_block, root, 64);
 BTRFS_SETGET_STACK_FUNCS(super_sys_array_size,
 			 struct btrfs_super_block, sys_chunk_array_size, 32);
+BTRFS_SETGET_STACK_FUNCS(super_chunk_root_generation,
+			 struct btrfs_super_block, chunk_root_generation, 64);
 BTRFS_SETGET_STACK_FUNCS(super_root_level, struct btrfs_super_block,
 			 root_level, 8);
 BTRFS_SETGET_STACK_FUNCS(super_chunk_root, struct btrfs_super_block,

commit 2517920135b0d29e70453e5b03d70d7b94207df3
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: nuke fs wide allocation mutex V2
    
    This patch removes the giant fs_info->alloc_mutex and replaces it with a bunch
    of little locks.
    
    There is now a pinned_mutex, which is used when messing with the pinned_extents
    extent io tree, and the extent_ins_mutex which is used with the pending_del and
    extent_ins extent io trees.
    
    The locking for the extent tree stuff was inspired by a patch that Yan Zheng
    wrote to fix a race condition, I cleaned it up some and changed the locking
    around a little bit, but the idea remains the same.  Basically instead of
    holding the extent_ins_mutex throughout the processing of an extent on the
    extent_ins or pending_del trees, we just hold it while we're searching and when
    we clear the bits on those trees, and lock the extent for the duration of the
    operations on the extent.
    
    Also to keep from getting hung up waiting to lock an extent, I've added a
    try_lock_extent so if we cannot lock the extent, move on to the next one in the
    tree and we'll come back to that one.  I have tested this heavily and it does
    not appear to break anything.  This has to be applied on top of my
    find_free_extent redo patch.
    
    I tested this patch on top of Yan's space reblancing code and it worked fine.
    The only thing that has changed since the last version is I pulled out all my
    debugging stuff, apparently I forgot to run guilt refresh before I sent the
    last patch out.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index caa860a1c3e5..fdba4f1b634e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -558,6 +558,7 @@ struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
 	spinlock_t lock;
+	struct mutex alloc_mutex;
 	u64 pinned;
 	u64 reserved;
 	u64 flags;
@@ -635,7 +636,8 @@ struct btrfs_fs_info {
 	struct mutex tree_log_mutex;
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;
-	struct mutex alloc_mutex;
+	struct mutex extent_ins_mutex;
+	struct mutex pinned_mutex;
 	struct mutex chunk_mutex;
 	struct mutex drop_mutex;
 	struct mutex volume_mutex;
@@ -1941,8 +1943,12 @@ int btrfs_acl_chmod(struct inode *inode);
 /* free-space-cache.c */
 int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
 			 u64 bytenr, u64 size);
+int btrfs_add_free_space_lock(struct btrfs_block_group_cache *block_group,
+			      u64 offset, u64 bytes);
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
 			    u64 bytenr, u64 size);
+int btrfs_remove_free_space_lock(struct btrfs_block_group_cache *block_group,
+				 u64 offset, u64 bytes);
 void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
 				   *block_group);
 struct btrfs_free_space *btrfs_find_free_space(struct btrfs_block_group_cache

commit 80eb234af09dbe6c97b2e3d60a13ec391e98fbba
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: fix enospc when there is plenty of space
    
    So there is an odd case where we can possibly return -ENOSPC when there is in
    fact space to be had.  It only happens with Metadata writes, and happens _very_
    infrequently.  What has to happen is we have to allocate have allocated out of
    the first logical byte on the disk, which would set last_alloc to
    first_logical_byte(root, 0), so search_start == orig_search_start.  We then
    need to allocate for normal metadata, so BTRFS_BLOCK_GROUP_METADATA |
    BTRFS_BLOCK_GROUP_DUP.  We will do a block lookup for the given search_start,
    block_group_bits() won't match and we'll go to choose another block group.
    However because search_start matches orig_search_start we go to see if we can
    allocate a chunk.
    
    If we are in the situation that we cannot allocate a chunk, we fail and ENOSPC.
    This is kind of a big flaw of the way find_free_extent works, as it along with
    find_free_space loop through _all_ of the block groups, not just the ones that
    we want to allocate out of.  This patch completely kills find_free_space and
    rolls it into find_free_extent.  I've introduced a sort of state machine into
    this, which will make it easier to get cache miss information out of the
    allocator, and will work well with my locking changes.
    
    The basic flow is this:  We have the variable loop which is 0, meaning we are
    in the hint phase.  We lookup the block group for the hint, and lookup the
    space_info for what we want to allocate out of.  If the block group we were
    pointed at by the hint either isn't of the correct type, or just doesn't have
    the space we need, we set head to space_info->block_groups, so we start at the
    beginning of the block groups for this particular space info, and loop through.
    
    This is also where we add the empty_cluster to total_needed.  At this point
    loop is set to 1 and we just loop through all of the block groups for this
    particular space_info looking for the space we need, just as find_free_space
    would have done, except we only hit the block groups we want and not _all_ of
    the block groups.  If we come full circle we see if we can allocate a chunk.
    If we cannot of course we exit with -ENOSPC and we are good.  If not we start
    over at space_info->block_groups and loop through again, with loop == 2.  If we
    come full circle and haven't found what we need then we exit with -ENOSPC.
    I've been running this for a couple of days now and it seems stable, and I
    haven't yet hit a -ENOSPC when there was plenty of space left.
    
    Also I've made a groups_sem to handle the group list for the space_info.  This
    is part of my locking changes, but is relatively safe and seems better than
    holding the space_info spinlock over that entire search time.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 117090995e7c..caa860a1c3e5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -544,6 +544,7 @@ struct btrfs_space_info {
 	/* for block groups in our same type */
 	struct list_head block_groups;
 	spinlock_t lock;
+	struct rw_semaphore groups_sem;
 };
 
 struct btrfs_free_space {

commit f82d02d9d8222183b7945e893111a6d1bf67ae4a
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: Improve space balancing code
    
    This patch improves the space balancing code to keep more sharing
    of tree blocks. The only case that breaks sharing of tree blocks is
    data extents get fragmented during balancing. The main changes in
    this patch are:
    
    Add a 'drop sub-tree' function. This solves the problem in old code
    that BTRFS_HEADER_FLAG_WRITTEN check breaks sharing of tree block.
    
    Remove relocation mapping tree. Relocation mappings are stored in
    struct btrfs_ref_path and updated dynamically during walking up/down
    the reference path. This reduces CPU usage and simplifies code.
    
    This patch also fixes a bug. Root items for reloc trees should be
    updated in btrfs_free_reloc_root.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 793d8fdda244..117090995e7c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -684,7 +684,6 @@ struct btrfs_fs_info {
 	int thread_pool_size;
 
 	/* tree relocation relocated fields */
-	struct extent_io_tree reloc_mapping_tree;
 	struct list_head dead_reloc_roots;
 	struct btrfs_leaf_ref_tree reloc_ref_tree;
 	struct btrfs_leaf_ref_tree shared_ref_tree;
@@ -1636,13 +1635,9 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root, u64 group_start);
 int btrfs_relocate_block_group(struct btrfs_root *root, u64 group_start);
-int btrfs_free_reloc_root(struct btrfs_root *root);
+int btrfs_free_reloc_root(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root);
 int btrfs_drop_dead_reloc_roots(struct btrfs_root *root);
-int btrfs_add_reloc_mapping(struct btrfs_root *root, u64 orig_bytenr,
-			    u64 num_bytes, u64 new_bytenr);
-int btrfs_get_reloc_mapping(struct btrfs_root *root, u64 orig_bytenr,
-			    u64 num_bytes, u64 *new_bytenr);
-void btrfs_free_reloc_mappings(struct btrfs_root *root);
 int btrfs_reloc_tree_cache_ref(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       struct extent_buffer *buf, u64 orig_start);
@@ -1726,6 +1721,10 @@ int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
 			*root);
+int btrfs_drop_subtree(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root,
+			struct extent_buffer *node,
+			struct extent_buffer *parent);
 /* root-item.c */
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_key *key);

commit c8b978188c9a0fd3d535c13debd19d522b726f1f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Oct 29 14:49:59 2008 -0400

    Btrfs: Add zlib compression support
    
    This is a large change for adding compression on reading and writing,
    both for inline and regular extents.  It does some fairly large
    surgery to the writeback paths.
    
    Compression is off by default and enabled by mount -o compress.  Even
    when the -o compress mount option is not used, it is possible to read
    compressed extents off the disk.
    
    If compression for a given set of pages fails to make them smaller, the
    file is flagged to avoid future compression attempts later.
    
    * While finding delalloc extents, the pages are locked before being sent down
    to the delalloc handler.  This allows the delalloc handler to do complex things
    such as cleaning the pages, marking them writeback and starting IO on their
    behalf.
    
    * Inline extents are inserted at delalloc time now.  This allows us to compress
    the data before inserting the inline extent, and it allows us to insert
    an inline extent that spans multiple pages.
    
    * All of the in-memory extent representations (extent_map.c, ordered-data.c etc)
    are changed to record both an in-memory size and an on disk size, as well
    as a flag for compression.
    
    From a disk format point of view, the extent pointers in the file are changed
    to record the on disk size of a given extent and some encoding flags.
    Space in the disk format is allocated for compression encoding, as well
    as encryption and a generic 'other' field.  Neither the encryption or the
    'other' field are currently used.
    
    In order to limit the amount of data read for a single random read in the
    file, the size of a compressed extent is limited to 128k.  This is a
    software only limit, the disk format supports u64 sized compressed extents.
    
    In order to limit the ram consumed while processing extents, the uncompressed
    size of a compressed extent is limited to 256k.  This is a software only limit
    and will be subject to tuning later.
    
    Checksumming is still done on compressed extents, and it is done on the
    uncompressed version of the data.  This way additional encodings can be
    layered on without having to figure out which encoding to checksum.
    
    Compression happens at delalloc time, which is basically singled threaded because
    it is usually done by a single pdflush thread.  This makes it tricky to
    spread the compression load across all the cpus on the box.  We'll have to
    look at parallel pdflush walks of dirty inodes at a later time.
    
    Decompression is hooked into readpages and it does spread across CPUs nicely.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8559f39fd47f..793d8fdda244 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -400,10 +400,18 @@ struct btrfs_timespec {
 	__le32 nsec;
 } __attribute__ ((__packed__));
 
-/*
- * there is no padding here on purpose.  If you want to extent the inode,
- * make a new item type
- */
+typedef enum {
+	BTRFS_COMPRESS_NONE = 0,
+	BTRFS_COMPRESS_ZLIB = 1,
+	BTRFS_COMPRESS_LAST = 2,
+} btrfs_compression_type;
+
+/* we don't understand any encryption methods right now */
+typedef enum {
+	BTRFS_ENCRYPTION_NONE = 0,
+	BTRFS_ENCRYPTION_LAST = 1,
+} btrfs_encryption_type;
+
 struct btrfs_inode_item {
 	/* nfs style generation number */
 	__le64 generation;
@@ -419,6 +427,7 @@ struct btrfs_inode_item {
 	__le64 rdev;
 	__le16 flags;
 	__le16 compat_flags;
+
 	struct btrfs_timespec atime;
 	struct btrfs_timespec ctime;
 	struct btrfs_timespec mtime;
@@ -454,8 +463,33 @@ struct btrfs_root_item {
 #define BTRFS_FILE_EXTENT_INLINE 1
 
 struct btrfs_file_extent_item {
+	/*
+	 * transaction id that created this extent
+	 */
 	__le64 generation;
+	/*
+	 * max number of bytes to hold this extent in ram
+	 * when we split a compressed extent we can't know how big
+	 * each of the resulting pieces will be.  So, this is
+	 * an upper limit on the size of the extent in ram instead of
+	 * an exact limit.
+	 */
+	__le64 ram_bytes;
+
+	/*
+	 * 32 bits for the various ways we might encode the data,
+	 * including compression and encryption.  If any of these
+	 * are set to something a given disk format doesn't understand
+	 * it is treated like an incompat flag for reading and writing,
+	 * but not for stat.
+	 */
+	u8 compression;
+	u8 encryption;
+	__le16 other_encoding; /* spare for later use */
+
+	/* are we inline data or a real extent? */
 	u8 type;
+
 	/*
 	 * disk space consumed by the extent, checksum blocks are included
 	 * in these numbers
@@ -471,9 +505,11 @@ struct btrfs_file_extent_item {
 	 */
 	__le64 offset;
 	/*
-	 * the logical number of file blocks (no csums included)
+	 * the logical number of file blocks (no csums included).  This
+	 * always reflects the size uncompressed and without encoding.
 	 */
 	__le64 num_bytes;
+
 } __attribute__ ((__packed__));
 
 struct btrfs_csum_item {
@@ -814,6 +850,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_NOBARRIER		(1 << 2)
 #define BTRFS_MOUNT_SSD			(1 << 3)
 #define BTRFS_MOUNT_DEGRADED		(1 << 4)
+#define BTRFS_MOUNT_COMPRESS		(1 << 5)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
@@ -825,6 +862,7 @@ struct btrfs_root {
 #define BTRFS_INODE_NODATASUM		(1 << 0)
 #define BTRFS_INODE_NODATACOW		(1 << 1)
 #define BTRFS_INODE_READONLY		(1 << 2)
+#define BTRFS_INODE_NOCOMPRESS		(1 << 3)
 #define btrfs_clear_flag(inode, flag)	(BTRFS_I(inode)->flags &= \
 					 ~BTRFS_INODE_##flag)
 #define btrfs_set_flag(inode, flag)	(BTRFS_I(inode)->flags |= \
@@ -1424,14 +1462,6 @@ static inline u32 btrfs_file_extent_calc_inline_size(u32 datasize)
 	return offsetof(struct btrfs_file_extent_item, disk_bytenr) + datasize;
 }
 
-static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
-					       struct btrfs_item *e)
-{
-	unsigned long offset;
-	offset = offsetof(struct btrfs_file_extent_item, disk_bytenr);
-	return btrfs_item_size(eb, e) - offset;
-}
-
 BTRFS_SETGET_FUNCS(file_extent_disk_bytenr, struct btrfs_file_extent_item,
 		   disk_bytenr, 64);
 BTRFS_SETGET_FUNCS(file_extent_generation, struct btrfs_file_extent_item,
@@ -1442,6 +1472,36 @@ BTRFS_SETGET_FUNCS(file_extent_offset, struct btrfs_file_extent_item,
 		  offset, 64);
 BTRFS_SETGET_FUNCS(file_extent_num_bytes, struct btrfs_file_extent_item,
 		   num_bytes, 64);
+BTRFS_SETGET_FUNCS(file_extent_ram_bytes, struct btrfs_file_extent_item,
+		   ram_bytes, 64);
+BTRFS_SETGET_FUNCS(file_extent_compression, struct btrfs_file_extent_item,
+		   compression, 8);
+BTRFS_SETGET_FUNCS(file_extent_encryption, struct btrfs_file_extent_item,
+		   encryption, 8);
+BTRFS_SETGET_FUNCS(file_extent_other_encoding, struct btrfs_file_extent_item,
+		   other_encoding, 16);
+
+/* this returns the number of file bytes represented by the inline item.
+ * If an item is compressed, this is the uncompressed size
+ */
+static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
+					       struct btrfs_file_extent_item *e)
+{
+	return btrfs_file_extent_ram_bytes(eb, e);
+}
+
+/*
+ * this returns the number of bytes used by the item on disk, minus the
+ * size of any extent headers.  If a file is compressed on disk, this is
+ * the compressed size
+ */
+static inline u32 btrfs_file_extent_inline_item_len(struct extent_buffer *eb,
+						    struct btrfs_item *e)
+{
+	unsigned long offset;
+	offset = offsetof(struct btrfs_file_extent_item, disk_bytenr);
+	return btrfs_item_size(eb, e) - offset;
+}
 
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
@@ -1745,10 +1805,11 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *root,
-			       u64 objectid, u64 pos, u64 disk_offset,
-			       u64 disk_num_bytes,
-			     u64 num_bytes, u64 offset);
+			     struct btrfs_root *root,
+			     u64 objectid, u64 pos,
+			     u64 disk_offset, u64 disk_num_bytes,
+			     u64 num_bytes, u64 offset, u64 ram_bytes,
+			     u8 compression, u8 encryption, u16 other_encoding);
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
@@ -1758,6 +1819,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_ordered_sum *sums);
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio);
+int btrfs_csum_file_bytes(struct btrfs_root *root, struct inode *inode,
+			  u64 start, unsigned long len);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,
@@ -1799,7 +1862,7 @@ void btrfs_invalidate_dcache_root(struct btrfs_root *root, char *name,
 				  int namelen);
 
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
-			 size_t size, struct bio *bio);
+			 size_t size, struct bio *bio, unsigned long bio_flags);
 
 unsigned long btrfs_force_ra(struct address_space *mapping,
 			      struct file_ra_state *ra, struct file *file,

commit cb8e70901d36f32017614f16d2cf7cc089544574
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 9 13:39:39 2008 -0400

    Btrfs: Fix subvolume creation locking rules
    
    Creating a subvolume is in many ways like a normal VFS ->mkdir, and we
    really need to play with the VFS topology locking rules.  So instead of
    just creating the snapshot on disk and then later getting rid of
    confliting aliases do it correctly from the start.  This will become
    especially important once we allow for subvolumes anywhere in the tree,
    and not just below a hidden root.
    
    Note that snapshots will need the same treatment, but do to the delay
    in creating them we can't do it currently.  Chris promised to fix that
    issue, so I'll wait on that.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3fa9b8d6751d..8559f39fd47f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1791,7 +1791,7 @@ int btrfs_start_delalloc_inodes(struct btrfs_root *root);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end);
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
-int btrfs_create_subvol_root(struct btrfs_root *new_root,
+int btrfs_create_subvol_root(struct btrfs_root *new_root, struct dentry *dentry,
 		struct btrfs_trans_handle *trans, u64 new_dirid,
 		struct btrfs_block_group_cache *block_group);
 

commit 833023e46c2a0180ff07d90252c24cb3fdea811d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Oct 9 11:55:03 2008 -0400

    Btrfs: Rev the disk format for the new back reference format
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a37fd783407c..3fa9b8d6751d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -39,7 +39,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_B9RfS_M"
+#define BTRFS_MAGIC "_BBRfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit 3bb1a1bc42f2ae9582c28adf620484efcd4da38d
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Oct 9 11:46:24 2008 -0400

    Btrfs: Remove offset field from struct btrfs_extent_ref
    
    The offset field in struct btrfs_extent_ref records the position
    inside file that file extent is referenced by. In the new back
    reference system, tree leaves holding references to file extent
    are recorded explicitly. We can scan these tree leaves very quickly, so the
    offset field is not required.
    
    This patch also makes the back reference system check the objectid
    when extents are in deleting.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 50fbcc9ec45f..a37fd783407c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -374,7 +374,6 @@ struct btrfs_extent_ref {
 	__le64 root;
 	__le64 generation;
 	__le64 objectid;
-	__le64 offset;
 	__le32 num_refs;
 } __attribute__ ((__packed__));
 
@@ -1082,7 +1081,6 @@ static inline u8 *btrfs_dev_extent_chunk_tree_uuid(struct btrfs_dev_extent *dev)
 BTRFS_SETGET_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
 BTRFS_SETGET_FUNCS(ref_generation, struct btrfs_extent_ref, generation, 64);
 BTRFS_SETGET_FUNCS(ref_objectid, struct btrfs_extent_ref, objectid, 64);
-BTRFS_SETGET_FUNCS(ref_offset, struct btrfs_extent_ref, offset, 64);
 BTRFS_SETGET_FUNCS(ref_num_refs, struct btrfs_extent_ref, num_refs, 32);
 
 BTRFS_SETGET_STACK_FUNCS(stack_ref_root, struct btrfs_extent_ref, root, 64);
@@ -1090,8 +1088,6 @@ BTRFS_SETGET_STACK_FUNCS(stack_ref_generation, struct btrfs_extent_ref,
 			 generation, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_ref_objectid, struct btrfs_extent_ref,
 			 objectid, 64);
-BTRFS_SETGET_STACK_FUNCS(stack_ref_offset, struct btrfs_extent_ref,
-			 offset, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_ref_num_refs, struct btrfs_extent_ref,
 			 num_refs, 32);
 
@@ -1522,29 +1518,20 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize);
-int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
-				 struct btrfs_root *root,
-				 struct btrfs_path *path,
-				 u64 bytenr, u64 parent,
-				 u64 root_objectid, u64 ref_generation,
-				 u64 owner, u64 owner_offset);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root,
 		       u64 num_bytes, u64 parent, u64 min_bytes,
 		       u64 root_objectid, u64 ref_generation,
-		       u64 owner, u64 owner_offset,
-		       u64 empty_size, u64 hint_byte,
+		       u64 owner, u64 empty_size, u64 hint_byte,
 		       u64 search_end, struct btrfs_key *ins, u64 data);
 int btrfs_alloc_reserved_extent(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root, u64 parent,
 				u64 root_objectid, u64 ref_generation,
-				u64 owner, u64 owner_offset,
-				struct btrfs_key *ins);
+				u64 owner, struct btrfs_key *ins);
 int btrfs_alloc_logged_extent(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root, u64 parent,
 				u64 root_objectid, u64 ref_generation,
-				u64 owner, u64 owner_offset,
-				struct btrfs_key *ins);
+				u64 owner, struct btrfs_key *ins);
 int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  struct btrfs_root *root,
 				  u64 num_bytes, u64 min_alloc_size,
@@ -1563,7 +1550,7 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      u64 bytenr, u64 num_bytes, u64 parent,
 		      u64 root_objectid, u64 ref_generation,
-		      u64 owner_objectid, u64 owner_offset, int pin);
+		      u64 owner_objectid, int pin);
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
@@ -1572,12 +1559,12 @@ int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root,
 			 u64 bytenr, u64 num_bytes, u64 parent,
 			 u64 root_objectid, u64 ref_generation,
-			 u64 owner, u64 owner_offset);
+			 u64 owner_objectid);
 int btrfs_update_extent_ref(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root, u64 bytenr,
 			    u64 orig_parent, u64 parent,
 			    u64 root_objectid, u64 ref_generation,
-			    u64 owner, u64 owner_offset);
+			    u64 owner_objectid);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);

commit a76a3cd40c1127ca199d4f7f37bf0d541bf44eb2
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Oct 9 11:46:29 2008 -0400

    Btrfs: Count space allocated to file in bytes
    
    This patch makes btrfs count space allocated to file in bytes instead
    of 512 byte sectors.
    
    Everything else in btrfs uses a byte count instead of sector sizes or
    blocks sizes, so this fits better.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8566eb30f567..50fbcc9ec45f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -411,7 +411,7 @@ struct btrfs_inode_item {
 	/* transid that last touched this inode */
 	__le64 transid;
 	__le64 size;
-	__le64 nblocks;
+	__le64 nbytes;
 	__le64 block_group;
 	__le32 nlink;
 	__le32 uid;
@@ -1017,7 +1017,7 @@ BTRFS_SETGET_FUNCS(inode_ref_index, struct btrfs_inode_ref, index, 64);
 BTRFS_SETGET_FUNCS(inode_generation, struct btrfs_inode_item, generation, 64);
 BTRFS_SETGET_FUNCS(inode_transid, struct btrfs_inode_item, transid, 64);
 BTRFS_SETGET_FUNCS(inode_size, struct btrfs_inode_item, size, 64);
-BTRFS_SETGET_FUNCS(inode_nblocks, struct btrfs_inode_item, nblocks, 64);
+BTRFS_SETGET_FUNCS(inode_nbytes, struct btrfs_inode_item, nbytes, 64);
 BTRFS_SETGET_FUNCS(inode_block_group, struct btrfs_inode_item, block_group, 64);
 BTRFS_SETGET_FUNCS(inode_nlink, struct btrfs_inode_item, nlink, 32);
 BTRFS_SETGET_FUNCS(inode_uid, struct btrfs_inode_item, uid, 32);
@@ -1814,15 +1814,6 @@ void btrfs_invalidate_dcache_root(struct btrfs_root *root, char *name,
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio);
 
-static inline void dec_i_blocks(struct inode *inode, u64 dec)
-{
-	dec = dec >> 9;
-	if (dec <= inode->i_blocks)
-		inode->i_blocks -= dec;
-	else
-		inode->i_blocks = 0;
-}
-
 unsigned long btrfs_force_ra(struct address_space *mapping,
 			      struct file_ra_state *ra, struct file *file,
 			      pgoff_t offset, pgoff_t last_index);

commit 30c43e2444c16afe3b2130f40ad273541bf3dc36
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Oct 3 12:24:01 2008 -0400

    Btrfs: remove last_log_alloc allocator optimization
    
    The tree logging code was trying to separate tree log allocations
    from normal metadata allocations to improve writeback patterns during
    an fsync.
    
    But, the code was not effective and ended up just mixing tree log
    blocks with regular metadata.  That seems to be working fairly well,
    so the last_log_alloc code can be removed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 94e0cdfddc0c..8566eb30f567 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -672,7 +672,6 @@ struct btrfs_fs_info {
 	u64 delalloc_bytes;
 	u64 last_alloc;
 	u64 last_data_alloc;
-	u64 last_log_alloc;
 
 	spinlock_t ref_cache_lock;
 	u64 total_ref_cache_size;

commit 323ac95bce442bbde514e3ce57e840402f80d909
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Oct 1 19:05:46 2008 -0400

    Btrfs: don't read leaf blocks containing only checksums during truncate
    
    Checksum items take up a significant portion of the metadata for large files.
    It is possible to avoid reading them during truncates by checking the keys in
    the higher level nodes.
    
    If a given leaf is followed by another leaf where the lowest key is a checksum
    item from the same file, we know we can safely delete the leaf without
    reading it.
    
    For a 32GB file on a 6 drive raid0 array, Btrfs needs 8s to delete
    the file with a cold cache.  It is read bound during the run.
    
    With this change, Btrfs is able to delete the file in 0.5s
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ded1643c0273..94e0cdfddc0c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1649,7 +1649,9 @@ void btrfs_free_path(struct btrfs_path *p);
 void btrfs_init_path(struct btrfs_path *p);
 int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_path *path, int slot, int nr);
-
+int btrfs_del_leaf(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root,
+			    struct btrfs_path *path, u64 bytenr);
 static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct btrfs_path *path)

commit d352ac68148b69937d39ca5d48bcc4478e118dbf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 29 15:18:18 2008 -0400

    Btrfs: add and improve comments
    
    This improves the comments at the top of many functions.  It didn't
    dive into the guts of functions because I was trying to
    avoid merging problems with the new allocator and back reference work.
    
    extent-tree.c and volumes.c were both skipped, and there is definitely
    more work todo in cleaning and commenting the code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0079b60b18f3..ded1643c0273 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -27,7 +27,6 @@
 #include <linux/backing-dev.h>
 #include <linux/wait.h>
 #include <asm/kmap_types.h>
-#include "bit-radix.h"
 #include "extent_io.h"
 #include "extent_map.h"
 #include "async-thread.h"

commit 8c8bee1d7ca47fc75b6bd24a8085c525a2394c02
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 29 11:19:10 2008 -0400

    Btrfs: Wait for IO on the block device inodes of newly added devices
    
    btrfs-vol -a /dev/xxx will zero the first and last two MB of the device.
    The kernel code needs to wait for this IO to finish before it adds
    the device.
    
    btrfs metadata IO does not happen through the block device inode.  A
    separate address space is used, allowing the zero filled buffer heads in
    the block device inode to be written to disk after FS metadata starts
    going down to the disk via the btrfs metadata inode.
    
    The end result is zero filled metadata blocks after adding new devices
    into the filesystem.
    
    The fix is a simple filemap_write_and_wait on the block device inode
    before actually inserting it into the pool of available devices.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2775e270881e..0079b60b18f3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -610,6 +610,7 @@ struct btrfs_fs_info {
 	struct list_head dead_roots;
 
 	atomic_t nr_async_submits;
+	atomic_t async_submit_draining;
 	atomic_t nr_async_bios;
 	atomic_t tree_log_writers;
 	atomic_t tree_log_commit;

commit 1a40e23b95da45051ee4d74374c58ae87a14051c
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 26 10:09:34 2008 -0400

    Btrfs: update space balancing code
    
    This patch updates the space balancing code to utilize the new
    backref format.  Before, btrfs-vol -b would break any COW links
    on data blocks or metadata.  This was slow and caused the amount
    of space used to explode if a large number of snapshots were present.
    
    The new code can keeps the sharing of all data extents and
    most of the tree blocks.
    
    To maintain the sharing of data extents, the space balance code uses
    a seperate inode hold data extent pointers, then updates the references
    to point to the new location.
    
    To maintain the sharing of tree blocks, the space balance code uses
    reloc trees to relocate tree blocks in reference counted roots.
    There is one reloc tree for each subvol, and all reloc trees share
    same root key objectid. Reloc trees are snapshots of the latest
    committed roots of subvols (root->commit_root).
    
    To relocate a tree block referenced by a subvol, there are two steps.
    COW the block through subvol's reloc tree, then update block pointer in
    the subvol to point to the new block. Since all reloc trees share
    same root key objectid, doing special handing for tree blocks
    owned by them is easy. Once a tree block has been COWed in one
    reloc tree, we can use the resulting new block directly when the
    same block is required to COW again through other reloc trees.
    In this way, relocated tree blocks are shared between reloc trees,
    so they are also shared between subvols.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3e62a1b0a1f7..2775e270881e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -604,6 +604,7 @@ struct btrfs_fs_info {
 	struct mutex chunk_mutex;
 	struct mutex drop_mutex;
 	struct mutex volume_mutex;
+	struct mutex tree_reloc_mutex;
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
@@ -647,6 +648,10 @@ struct btrfs_fs_info {
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
 
+	/* tree relocation relocated fields */
+	struct extent_io_tree reloc_mapping_tree;
+	struct list_head dead_reloc_roots;
+	struct btrfs_leaf_ref_tree reloc_ref_tree;
 	struct btrfs_leaf_ref_tree shared_ref_tree;
 
 	struct kobject super_kobj;
@@ -698,6 +703,7 @@ struct btrfs_root {
 	struct btrfs_leaf_ref_tree ref_tree_struct;
 	struct btrfs_dirty_root *dirty_root;
 	struct btrfs_root *log_root;
+	struct btrfs_root *reloc_root;
 
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
@@ -1517,7 +1523,6 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize);
-int btrfs_shrink_extent_tree(struct btrfs_root *root, u64 new_size);
 int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct btrfs_path *path,
@@ -1582,10 +1587,29 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, u64 bytes_used,
 			   u64 type, u64 chunk_objectid, u64 chunk_offset,
 			   u64 size);
+int btrfs_remove_block_group(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root, u64 group_start);
+int btrfs_relocate_block_group(struct btrfs_root *root, u64 group_start);
+int btrfs_free_reloc_root(struct btrfs_root *root);
+int btrfs_drop_dead_reloc_roots(struct btrfs_root *root);
+int btrfs_add_reloc_mapping(struct btrfs_root *root, u64 orig_bytenr,
+			    u64 num_bytes, u64 new_bytenr);
+int btrfs_get_reloc_mapping(struct btrfs_root *root, u64 orig_bytenr,
+			    u64 num_bytes, u64 *new_bytenr);
+void btrfs_free_reloc_mappings(struct btrfs_root *root);
+int btrfs_reloc_tree_cache_ref(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *root,
+			       struct extent_buffer *buf, u64 orig_start);
+int btrfs_add_dead_reloc_root(struct btrfs_root *root);
+int btrfs_cleanup_reloc_trees(struct btrfs_root *root);
 /* ctree.c */
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
+int btrfs_merge_path(struct btrfs_trans_handle *trans,
+		     struct btrfs_root *root,
+		     struct btrfs_key *node_keys,
+		     u64 *nodes, int lowest_level);
 int btrfs_set_item_key_safe(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root, struct btrfs_path *path,
 			    struct btrfs_key *new_key);

commit 5b21f2ed3f2947b5195b65c9fdbdd9e52904cc03
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 26 10:05:38 2008 -0400

    Btrfs: extent_map and data=ordered fixes for space balancing
    
    * Add an EXTENT_BOUNDARY state bit to keep the writepage code
    from merging data extents that are in the process of being
    relocated.  This allows us to do accounting for them properly.
    
    * The balancing code relocates data extents indepdent of the underlying
    inode.  The extent_map code was modified to properly account for
    things moving around (invalidating extent_map caches in the inode).
    
    * Don't take the drop_mutex in the create_subvol ioctl.  It isn't
    required.
    
    * Fix walking of the ordered extent list to avoid races with sys_unlink
    
    * Change the lock ordering rules.  Transaction start goes outside
    the drop_mutex.  This allows btrfs_commit_transaction to directly
    drop the relocation trees.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b9f9f815ed09..3e62a1b0a1f7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1486,6 +1486,9 @@ static inline struct dentry *fdentry(struct file *file)
 
 /* extent-tree.c */
 int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
+int btrfs_lookup_extent_ref(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root, u64 bytenr,
+			    u64 num_bytes, u32 *refs);
 int btrfs_update_pinned_extents(struct btrfs_root *root,
 				u64 bytenr, u64 num, int pin);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
@@ -1812,6 +1815,8 @@ void btrfs_destroy_inode(struct inode *inode);
 int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
+struct inode *btrfs_ilookup(struct super_block *s, u64 objectid,
+			    struct btrfs_root *root, int wait);
 struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
@@ -1824,13 +1829,17 @@ struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
 int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode);
+int btrfs_orphan_add(struct btrfs_trans_handle *trans, struct inode *inode);
+int btrfs_orphan_del(struct btrfs_trans_handle *trans, struct inode *inode);
+void btrfs_orphan_cleanup(struct btrfs_root *root);
 
 /* ioctl.c */
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 
 /* file.c */
 int btrfs_sync_file(struct file *file, struct dentry *dentry, int datasync);
-int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end);
+int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end,
+			    int skip_pinned);
 int btrfs_check_file(struct btrfs_root *root, struct inode *inode);
 extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,

commit e465768938f95388723b0fd3c50a0ae48173edb9
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 26 10:04:53 2008 -0400

    Btrfs: Add shared reference cache
    
    Btrfs has a cache of reference counts in leaves, allowing it to
    avoid reading tree leaves while deleting snapshots.  To reduce
    contention with multiple subvolumes, this cache is private to each
    subvolume.
    
    This patch adds shared reference cache support. The new space
    balancing code plays with multiple subvols at the same time, So
    the old per-subvol reference cache is not well suited.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c683aaa925fa..b9f9f815ed09 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -81,6 +81,10 @@ struct btrfs_ordered_sum;
 #define BTRFS_TREE_LOG_OBJECTID -6ULL
 #define BTRFS_TREE_LOG_FIXUP_OBJECTID -7ULL
 
+/* for space balancing */
+#define BTRFS_TREE_RELOC_OBJECTID -8ULL
+#define BTRFS_DATA_RELOC_TREE_OBJECTID -9ULL
+
 /* dummy objectid represents multiple objectids */
 #define BTRFS_MULTIPLE_OBJECTIDS -255ULL
 
@@ -539,6 +543,12 @@ struct btrfs_block_group_cache {
 	struct list_head list;
 };
 
+struct btrfs_leaf_ref_tree {
+	struct rb_root root;
+	struct list_head list;
+	spinlock_t lock;
+};
+
 struct btrfs_device;
 struct btrfs_fs_devices;
 struct btrfs_fs_info {
@@ -637,6 +647,8 @@ struct btrfs_fs_info {
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
 
+	struct btrfs_leaf_ref_tree shared_ref_tree;
+
 	struct kobject super_kobj;
 	struct completion kobj_unregister;
 	int do_barriers;
@@ -670,13 +682,6 @@ struct btrfs_fs_info {
 	void *bdev_holder;
 };
 
-struct btrfs_leaf_ref_tree {
-	struct rb_root root;
-	struct btrfs_leaf_ref *last;
-	struct list_head list;
-	spinlock_t lock;
-};
-
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.

commit e8569813849b5da394a195c7e76b4faa452b12d1
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 26 10:05:48 2008 -0400

    Btrfs: allocator fixes for space balancing update
    
    * Reserved extent accounting:  reserved extents have been
    allocated in the rbtrees that track free space but have not
    been allocated on disk.  They were never properly accounted for
    in the past, making it hard to know how much space was really free.
    
    * btrfs_find_block_group used to return NULL for block groups that
    had been removed by the space balancing code.  This made it hard
    to account for space during the final stages of a balance run.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3b3c1ca50c5d..c683aaa925fa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -498,6 +498,7 @@ struct btrfs_space_info {
 	u64 total_bytes;
 	u64 bytes_used;
 	u64 bytes_pinned;
+	u64 bytes_reserved;
 	int full;
 	int force_alloc;
 	struct list_head list;
@@ -519,6 +520,7 @@ struct btrfs_block_group_cache {
 	struct btrfs_block_group_item item;
 	spinlock_t lock;
 	u64 pinned;
+	u64 reserved;
 	u64 flags;
 	int cached;
 	int ro;

commit 2b1f55b0f0d0d1a66470ef4ea2696cd5dd741a12
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 24 11:48:04 2008 -0400

    Remove Btrfs compat code for older kernels
    
    Btrfs had compatibility code for kernels back to 2.6.18.  These have
    been removed, and will be maintained in a separate backport
    git tree from now on.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 138c157bbc45..3b3c1ca50c5d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1472,12 +1472,9 @@ static inline u32 btrfs_level_size(struct btrfs_root *root, int level) {
 	((unsigned long)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset_nr(leaf, slot)))
 
-static inline struct dentry *fdentry(struct file *file) {
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-	return file->f_dentry;
-#else
+static inline struct dentry *fdentry(struct file *file)
+{
 	return file->f_path.dentry;
-#endif
 }
 
 /* extent-tree.c */

commit 31840ae1a6b433ca0e6a8d341756ff478bbf959e
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Tue Sep 23 13:14:14 2008 -0400

    Btrfs: Full back reference support
    
    This patch makes the back reference system to explicit record the
    location of parent node for all types of extents. The location of
    parent node is placed into the offset field of backref key. Every
    time a tree block is balanced, the back references for the affected
    lower level extents are updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 730aae3bc181..138c157bbc45 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -40,7 +40,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_B8RfS_M"
+#define BTRFS_MAGIC "_B9RfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 
@@ -81,6 +81,9 @@ struct btrfs_ordered_sum;
 #define BTRFS_TREE_LOG_OBJECTID -6ULL
 #define BTRFS_TREE_LOG_FIXUP_OBJECTID -7ULL
 
+/* dummy objectid represents multiple objectids */
+#define BTRFS_MULTIPLE_OBJECTIDS -255ULL
+
 /*
  * All files have objectids in this range.
  */
@@ -369,6 +372,7 @@ struct btrfs_extent_ref {
 	__le64 generation;
 	__le64 objectid;
 	__le64 offset;
+	__le32 num_refs;
 } __attribute__ ((__packed__));
 
 /* dev extents record free space on individual devices.  The owner
@@ -1047,9 +1051,6 @@ btrfs_inode_otime(struct btrfs_inode_item *inode_item)
 BTRFS_SETGET_FUNCS(timespec_sec, struct btrfs_timespec, sec, 64);
 BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_timespec, nsec, 32);
 
-/* struct btrfs_extent_item */
-BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
-
 /* struct btrfs_dev_extent */
 BTRFS_SETGET_FUNCS(dev_extent_chunk_tree, struct btrfs_dev_extent,
 		   chunk_tree, 64);
@@ -1070,14 +1071,20 @@ BTRFS_SETGET_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
 BTRFS_SETGET_FUNCS(ref_generation, struct btrfs_extent_ref, generation, 64);
 BTRFS_SETGET_FUNCS(ref_objectid, struct btrfs_extent_ref, objectid, 64);
 BTRFS_SETGET_FUNCS(ref_offset, struct btrfs_extent_ref, offset, 64);
+BTRFS_SETGET_FUNCS(ref_num_refs, struct btrfs_extent_ref, num_refs, 32);
 
 BTRFS_SETGET_STACK_FUNCS(stack_ref_root, struct btrfs_extent_ref, root, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_ref_generation, struct btrfs_extent_ref,
 			 generation, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_ref_objectid, struct btrfs_extent_ref,
 			 objectid, 64);
-BTRFS_SETGET_STACK_FUNCS(stack_ref_offset, struct btrfs_extent_ref, offset, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_ref_offset, struct btrfs_extent_ref,
+			 offset, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_ref_num_refs, struct btrfs_extent_ref,
+			 num_refs, 32);
 
+/* struct btrfs_extent_item */
+BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
 BTRFS_SETGET_STACK_FUNCS(stack_extent_refs, struct btrfs_extent_item,
 			 refs, 32);
 
@@ -1474,8 +1481,7 @@ static inline struct dentry *fdentry(struct file *file) {
 }
 
 /* extent-tree.c */
-int btrfs_lookup_extent(struct btrfs_root *root, struct btrfs_path *path,
-			u64 start, u64 len);
+int btrfs_lookup_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_update_pinned_extents(struct btrfs_root *root,
 				u64 bytenr, u64 num, int pin);
 int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
@@ -1495,10 +1501,9 @@ struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 int data, int owner);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,
-					     u32 blocksize,
+					     u32 blocksize, u64 parent,
 					     u64 root_objectid,
 					     u64 ref_generation,
-					     u64 first_objectid,
 					     int level,
 					     u64 hint,
 					     u64 empty_size);
@@ -1508,23 +1513,24 @@ struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
 int btrfs_shrink_extent_tree(struct btrfs_root *root, u64 new_size);
 int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
-				 struct btrfs_path *path, u64 bytenr,
+				 struct btrfs_path *path,
+				 u64 bytenr, u64 parent,
 				 u64 root_objectid, u64 ref_generation,
 				 u64 owner, u64 owner_offset);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root,
-		       u64 num_bytes, u64 min_bytes,
+		       u64 num_bytes, u64 parent, u64 min_bytes,
 		       u64 root_objectid, u64 ref_generation,
 		       u64 owner, u64 owner_offset,
 		       u64 empty_size, u64 hint_byte,
 		       u64 search_end, struct btrfs_key *ins, u64 data);
 int btrfs_alloc_reserved_extent(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root,
+				struct btrfs_root *root, u64 parent,
 				u64 root_objectid, u64 ref_generation,
 				u64 owner, u64 owner_offset,
 				struct btrfs_key *ins);
 int btrfs_alloc_logged_extent(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root,
+				struct btrfs_root *root, u64 parent,
 				u64 root_objectid, u64 ref_generation,
 				u64 owner, u64 owner_offset,
 				struct btrfs_key *ins);
@@ -1535,9 +1541,16 @@ int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  u64 search_end, struct btrfs_key *ins,
 				  u64 data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf, int cache_ref);
-int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, u64 bytenr, u64 num_bytes,
+		  struct extent_buffer *orig_buf, struct extent_buffer *buf,
+		  u32 *nr_extents);
+int btrfs_cache_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		    struct extent_buffer *buf, u32 nr_extents);
+int btrfs_update_ref(struct btrfs_trans_handle *trans,
+		     struct btrfs_root *root, struct extent_buffer *orig_buf,
+		     struct extent_buffer *buf, int start_slot, int nr);
+int btrfs_free_extent(struct btrfs_trans_handle *trans,
+		      struct btrfs_root *root,
+		      u64 bytenr, u64 num_bytes, u64 parent,
 		      u64 root_objectid, u64 ref_generation,
 		      u64 owner_objectid, u64 owner_offset, int pin);
 int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
@@ -1545,10 +1558,15 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       struct extent_io_tree *unpin);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root,
-				u64 bytenr, u64 num_bytes,
-				u64 root_objectid, u64 ref_generation,
-				u64 owner, u64 owner_offset);
+			 struct btrfs_root *root,
+			 u64 bytenr, u64 num_bytes, u64 parent,
+			 u64 root_objectid, u64 ref_generation,
+			 u64 owner, u64 owner_offset);
+int btrfs_update_extent_ref(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root, u64 bytenr,
+			    u64 orig_parent, u64 parent,
+			    u64 root_objectid, u64 ref_generation,
+			    u64 owner, u64 owner_offset);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
@@ -1561,7 +1579,9 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
-
+int btrfs_set_item_key_safe(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root, struct btrfs_path *path,
+			    struct btrfs_key *new_key);
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
 int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,

commit 0f9dd46cda36b8de3b9f48bc42bd09d20b9c3b52
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Sep 23 13:14:11 2008 -0400

    Btrfs: free space accounting redo
    
    1) replace the per fs_info extent_io_tree that tracked free space with two
    rb-trees per block group to track free space areas via offset and size.  The
    reason to do this is because most allocations come with a hint byte where to
    start, so we can usually find a chunk of free space at that hint byte to satisfy
    the allocation and get good space packing.  If we cannot find free space at or
    after the given offset we fall back on looking for a chunk of the given size as
    close to that given offset as possible.  When we fall back on the size search we
    also try to find a slot as close to the size we want as possible, to avoid
    breaking small chunks off of huge areas if possible.
    
    2) remove the extent_io_tree that tracked the block group cache from fs_info and
    replaced it with an rb-tree thats tracks block group cache via offset.  also
    added a per space_info list that tracks the block group cache for the particular
    space so we can lookup related block groups easily.
    
    3) cleaned up the allocation code to make it a little easier to read and a
    little less complicated.  Basically there are 3 steps, first look from our
    provided hint.  If we couldn't find from that given hint, start back at our
    original search start and look for space from there.  If that fails try to
    allocate space if we can and start looking again.  If not we're screwed and need
    to start over again.
    
    4) small fixes.  there were some issues in volumes.c where we wouldn't allocate
    the rest of the disk.  fixed cow_file_range to actually pass the alloc_hint,
    which has helped a good bit in making the fs_mark test I run have semi-normal
    results as we run out of space.  Generally with data allocations we don't track
    where we last allocated from, so everytime we did a data allocation we'd search
    through every block group that we have looking for free space.  Now searching a
    block group with no free space isn't terribly time consuming, it was causing a
    slight degradation as we got more data block groups.  The alloc_hint has fixed
    this slight degredation and made things semi-normal.
    
    There is still one nagging problem I'm working on where we will get ENOSPC when
    there is definitely plenty of space.  This only happens with metadata
    allocations, and only when we are almost full.  So you generally hit the 85%
    mark first, but sometimes you'll hit the BUG before you hit the 85% wall.  I'm
    still tracking it down, but until then this seems to be pretty stable and make a
    significant performance gain.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index eb65fd808883..730aae3bc181 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -483,7 +483,6 @@ struct btrfs_csum_item {
 #define BTRFS_BLOCK_GROUP_DUP	   (1 << 5)
 #define BTRFS_BLOCK_GROUP_RAID10   (1 << 6)
 
-
 struct btrfs_block_group_item {
 	__le64 used;
 	__le64 chunk_objectid;
@@ -498,17 +497,40 @@ struct btrfs_space_info {
 	int full;
 	int force_alloc;
 	struct list_head list;
+
+	/* for block groups in our same type */
+	struct list_head block_groups;
+	spinlock_t lock;
+};
+
+struct btrfs_free_space {
+	struct rb_node bytes_index;
+	struct rb_node offset_index;
+	u64 offset;
+	u64 bytes;
 };
 
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
-	struct btrfs_space_info *space_info;
 	spinlock_t lock;
 	u64 pinned;
 	u64 flags;
 	int cached;
 	int ro;
+	int dirty;
+
+	struct btrfs_space_info *space_info;
+
+	/* free space cache stuff */
+	struct rb_root free_space_bytes;
+	struct rb_root free_space_offset;
+
+	/* block group cache stuff */
+	struct rb_node cache_node;
+
+	/* for block groups in the same raid type */
+	struct list_head list;
 };
 
 struct btrfs_device;
@@ -525,8 +547,10 @@ struct btrfs_fs_info {
 	struct btrfs_root *log_root_tree;
 	struct radix_tree_root fs_roots_radix;
 
-	struct extent_io_tree free_space_cache;
-	struct extent_io_tree block_group_cache;
+	/* block group cache stuff */
+	spinlock_t block_group_cache_lock;
+	struct rb_root block_group_cache_tree;
+
 	struct extent_io_tree pinned_extents;
 	struct extent_io_tree pending_del;
 	struct extent_io_tree extent_ins;
@@ -1814,4 +1838,18 @@ int btrfs_sync_fs(struct super_block *sb, int wait);
 int btrfs_check_acl(struct inode *inode, int mask);
 int btrfs_init_acl(struct inode *inode, struct inode *dir);
 int btrfs_acl_chmod(struct inode *inode);
+
+/* free-space-cache.c */
+int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
+			 u64 bytenr, u64 size);
+int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
+			    u64 bytenr, u64 size);
+void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
+				   *block_group);
+struct btrfs_free_space *btrfs_find_free_space(struct btrfs_block_group_cache
+					       *block_group, u64 offset,
+					       u64 bytes);
+void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
+			   u64 bytes);
+u64 btrfs_block_group_free_space(struct btrfs_block_group_cache *block_group);
 #endif

commit d0c803c4049c5ca322d4795d8b74f28768603e0e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Sep 11 16:17:57 2008 -0400

    Btrfs: Record dirty pages tree-log pages in an extent_io tree
    
    This is the same way the transaction code makes sure that all the
    other tree blocks are safely on disk.  There's an extent_io tree
    for each root, and any blocks allocated to the tree logs are
    recorded in that tree.
    
    At tree-log sync, the extent_io tree is walked to flush down the
    dirty pages and wait for them.
    
    The main benefit is less time spent walking the tree log and skipping
    clean pages, and getting sequential IO down to the drive.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2ed6918f32e5..eb65fd808883 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -668,6 +668,8 @@ struct btrfs_root {
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
 	struct inode *inode;
+	struct extent_io_tree dirty_log_pages;
+
 	struct kobject root_kobj;
 	struct completion kobj_unregister;
 	struct mutex objectid_mutex;

commit 6527cdbe68a27a2ee745f36d001aa32d0f46f370
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 5 16:43:53 2008 -0400

    Btrfs: Update find free objectid function for orphan cleanup code
    
    Orphan items use BTRFS_ORPHAN_OBJECTID (-5UUL) as key objectid. This
    affects the find free objectid functions, inode objectid can easily
    overflow after orphan file cleanup.
    
    ---
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 754c738ec2e8..2ed6918f32e5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -82,9 +82,10 @@ struct btrfs_ordered_sum;
 #define BTRFS_TREE_LOG_FIXUP_OBJECTID -7ULL
 
 /*
- * All files have objectids higher than this.
+ * All files have objectids in this range.
  */
 #define BTRFS_FIRST_FREE_OBJECTID 256ULL
+#define BTRFS_LAST_FREE_OBJECTID -256ULL
 #define BTRFS_FIRST_CHUNK_TREE_OBJECTID 256ULL
 
 

commit a237d2a2bd67eb2b57b87c1e1d3d802d078d4ba7
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 5 16:43:29 2008 -0400

    remove unused function btrfs_ilookup
    
    btrfs_ilookup is unused, which is good because a normal filesystem
    should never have to use ilookup anyway.  Remove it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f720b582fd5b..754c738ec2e8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1763,8 +1763,6 @@ void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
 struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
-struct inode *btrfs_ilookup(struct super_block *s, u64 objectid,
-			    u64 root_objectid);
 struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
 			 struct btrfs_root *root, int *is_new);
 int btrfs_commit_write(struct file *file, struct page *page,

commit 91c0827de247303c6dfc40a8ec9d8305e1d07986
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 5 16:43:06 2008 -0400

    Btrfs: Rev the disk format
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6532b60683ef..f720b582fd5b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -40,7 +40,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_B7RfS_M"
+#define BTRFS_MAGIC "_B8RfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit e02119d5a7b4396c5a872582fddc8bd6d305a70a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 5 16:13:11 2008 -0400

    Btrfs: Add a write ahead tree log to optimize synchronous operations
    
    File syncs and directory syncs are optimized by copying their
    items into a special (copy-on-write) log tree.  There is one log tree per
    subvolume and the btrfs super block points to a tree of log tree roots.
    
    After a crash, items are copied out of the log tree and back into the
    subvolume.  See tree-log.c for all the details.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b305ae7e10b0..6532b60683ef 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -77,6 +77,10 @@ struct btrfs_ordered_sum;
 /* orhpan objectid for tracking unlinked/truncated files */
 #define BTRFS_ORPHAN_OBJECTID -5ULL
 
+/* does write ahead logging to speed up fsyncs */
+#define BTRFS_TREE_LOG_OBJECTID -6ULL
+#define BTRFS_TREE_LOG_FIXUP_OBJECTID -7ULL
+
 /*
  * All files have objectids higher than this.
  */
@@ -276,6 +280,7 @@ struct btrfs_super_block {
 	__le64 generation;
 	__le64 root;
 	__le64 chunk_root;
+	__le64 log_root;
 	__le64 total_bytes;
 	__le64 bytes_used;
 	__le64 root_dir_objectid;
@@ -287,6 +292,7 @@ struct btrfs_super_block {
 	__le32 sys_chunk_array_size;
 	u8 root_level;
 	u8 chunk_root_level;
+	u8 log_root_level;
 	struct btrfs_dev_item dev_item;
 	char label[BTRFS_LABEL_SIZE];
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
@@ -392,7 +398,10 @@ struct btrfs_timespec {
  * make a new item type
  */
 struct btrfs_inode_item {
+	/* nfs style generation number */
 	__le64 generation;
+	/* transid that last touched this inode */
+	__le64 transid;
 	__le64 size;
 	__le64 nblocks;
 	__le64 block_group;
@@ -409,8 +418,13 @@ struct btrfs_inode_item {
 	struct btrfs_timespec otime;
 } __attribute__ ((__packed__));
 
+struct btrfs_dir_log_item {
+	__le64 end;
+} __attribute__ ((__packed__));
+
 struct btrfs_dir_item {
 	struct btrfs_disk_key location;
+	__le64 transid;
 	__le16 data_len;
 	__le16 name_len;
 	u8 type;
@@ -505,6 +519,9 @@ struct btrfs_fs_info {
 	struct btrfs_root *tree_root;
 	struct btrfs_root *chunk_root;
 	struct btrfs_root *dev_root;
+
+	/* the log root tree is a directory of all the other log roots */
+	struct btrfs_root *log_root_tree;
 	struct radix_tree_root fs_roots_radix;
 
 	struct extent_io_tree free_space_cache;
@@ -518,6 +535,7 @@ struct btrfs_fs_info {
 
 	u64 generation;
 	u64 last_trans_committed;
+	u64 last_trans_new_blockgroup;
 	u64 open_ioctl_trans;
 	unsigned long mount_opt;
 	u64 max_extent;
@@ -527,6 +545,9 @@ struct btrfs_fs_info {
 	wait_queue_head_t transaction_throttle;
 	wait_queue_head_t transaction_wait;
 	wait_queue_head_t async_submit_wait;
+
+	wait_queue_head_t tree_log_wait;
+
 	struct btrfs_super_block super_copy;
 	struct btrfs_super_block super_for_commit;
 	struct block_device *__bdev;
@@ -535,6 +556,7 @@ struct btrfs_fs_info {
 	struct backing_dev_info bdi;
 	spinlock_t hash_lock;
 	struct mutex trans_mutex;
+	struct mutex tree_log_mutex;
 	struct mutex transaction_kthread_mutex;
 	struct mutex cleaner_mutex;
 	struct mutex alloc_mutex;
@@ -544,8 +566,13 @@ struct btrfs_fs_info {
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
+
 	atomic_t nr_async_submits;
 	atomic_t nr_async_bios;
+	atomic_t tree_log_writers;
+	atomic_t tree_log_commit;
+	unsigned long tree_log_batch;
+	u64 tree_log_transid;
 
 	/*
 	 * this is used by the balancing code to wait for all the pending
@@ -583,6 +610,7 @@ struct btrfs_fs_info {
 	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
+	int log_root_recovering;
 	atomic_t throttles;
 	atomic_t throttle_gen;
 
@@ -596,6 +624,7 @@ struct btrfs_fs_info {
 	u64 delalloc_bytes;
 	u64 last_alloc;
 	u64 last_data_alloc;
+	u64 last_log_alloc;
 
 	spinlock_t ref_cache_lock;
 	u64 total_ref_cache_size;
@@ -632,6 +661,7 @@ struct btrfs_root {
 	struct btrfs_leaf_ref_tree *ref_tree;
 	struct btrfs_leaf_ref_tree ref_tree_struct;
 	struct btrfs_dirty_root *dirty_root;
+	struct btrfs_root *log_root;
 
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
@@ -640,6 +670,7 @@ struct btrfs_root {
 	struct kobject root_kobj;
 	struct completion kobj_unregister;
 	struct mutex objectid_mutex;
+	struct mutex log_mutex;
 
 	u64 objectid;
 	u64 last_trans;
@@ -692,6 +723,8 @@ struct btrfs_root {
  * dir items are the name -> inode pointers in a directory.  There is one
  * for every name in a directory.
  */
+#define BTRFS_DIR_LOG_ITEM_KEY  14
+#define BTRFS_DIR_LOG_INDEX_KEY 15
 #define BTRFS_DIR_ITEM_KEY	16
 #define BTRFS_DIR_INDEX_KEY	17
 /*
@@ -703,7 +736,8 @@ struct btrfs_root {
  */
 #define BTRFS_CSUM_ITEM_KEY	19
 
-/* reserve 20-31 for other file stuff */
+
+/* reserve 21-31 for other file/dir stuff */
 
 /*
  * root items point to tree roots.  There are typically in the root
@@ -938,6 +972,7 @@ BTRFS_SETGET_FUNCS(inode_ref_index, struct btrfs_inode_ref, index, 64);
 
 /* struct btrfs_inode_item */
 BTRFS_SETGET_FUNCS(inode_generation, struct btrfs_inode_item, generation, 64);
+BTRFS_SETGET_FUNCS(inode_transid, struct btrfs_inode_item, transid, 64);
 BTRFS_SETGET_FUNCS(inode_size, struct btrfs_inode_item, size, 64);
 BTRFS_SETGET_FUNCS(inode_nblocks, struct btrfs_inode_item, nblocks, 64);
 BTRFS_SETGET_FUNCS(inode_block_group, struct btrfs_inode_item, block_group, 64);
@@ -1126,10 +1161,13 @@ static inline void btrfs_set_item_key(struct extent_buffer *eb,
 	write_eb_member(eb, item, struct btrfs_item, key, disk_key);
 }
 
+BTRFS_SETGET_FUNCS(dir_log_end, struct btrfs_dir_log_item, end, 64);
+
 /* struct btrfs_dir_item */
 BTRFS_SETGET_FUNCS(dir_data_len, struct btrfs_dir_item, data_len, 16);
 BTRFS_SETGET_FUNCS(dir_type, struct btrfs_dir_item, type, 8);
 BTRFS_SETGET_FUNCS(dir_name_len, struct btrfs_dir_item, name_len, 16);
+BTRFS_SETGET_FUNCS(dir_transid, struct btrfs_dir_item, transid, 64);
 
 static inline void btrfs_dir_item_key(struct extent_buffer *eb,
 				      struct btrfs_dir_item *item,
@@ -1301,7 +1339,11 @@ BTRFS_SETGET_STACK_FUNCS(super_root_level, struct btrfs_super_block,
 BTRFS_SETGET_STACK_FUNCS(super_chunk_root, struct btrfs_super_block,
 			 chunk_root, 64);
 BTRFS_SETGET_STACK_FUNCS(super_chunk_root_level, struct btrfs_super_block,
-			 chunk_root_level, 64);
+			 chunk_root_level, 8);
+BTRFS_SETGET_STACK_FUNCS(super_log_root, struct btrfs_super_block,
+			 log_root, 64);
+BTRFS_SETGET_STACK_FUNCS(super_log_root_level, struct btrfs_super_block,
+			 log_root_level, 8);
 BTRFS_SETGET_STACK_FUNCS(super_total_bytes, struct btrfs_super_block,
 			 total_bytes, 64);
 BTRFS_SETGET_STACK_FUNCS(super_bytes_used, struct btrfs_super_block,
@@ -1405,6 +1447,12 @@ static inline struct dentry *fdentry(struct file *file) {
 }
 
 /* extent-tree.c */
+int btrfs_lookup_extent(struct btrfs_root *root, struct btrfs_path *path,
+			u64 start, u64 len);
+int btrfs_update_pinned_extents(struct btrfs_root *root,
+				u64 bytenr, u64 num, int pin);
+int btrfs_drop_leaf_ref(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_cross_ref_exists(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_key *key, u64 bytenr);
@@ -1448,6 +1496,11 @@ int btrfs_alloc_reserved_extent(struct btrfs_trans_handle *trans,
 				u64 root_objectid, u64 ref_generation,
 				u64 owner, u64 owner_offset,
 				struct btrfs_key *ins);
+int btrfs_alloc_logged_extent(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root,
+				u64 root_objectid, u64 ref_generation,
+				u64 owner, u64 owner_offset,
+				struct btrfs_key *ins);
 int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  struct btrfs_root *root,
 				  u64 num_bytes, u64 min_alloc_size,
@@ -1488,9 +1541,9 @@ int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
 			struct btrfs_key *key, int lowest_level,
 			int cache_only, u64 min_trans);
 int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
+			 struct btrfs_key *max_key,
 			 struct btrfs_path *path, int cache_only,
 			 u64 min_trans);
-
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,
@@ -1656,6 +1709,18 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 #define PageChecked PageFsMisc
 #endif
 
+int btrfs_unlink_inode(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root,
+		       struct inode *dir, struct inode *inode,
+		       const char *name, int name_len);
+int btrfs_add_link(struct btrfs_trans_handle *trans,
+		   struct inode *parent_inode, struct inode *inode,
+		   const char *name, int name_len, int add_backref, u64 index);
+int btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *root,
+			       struct inode *inode, u64 new_size,
+			       u32 min_type);
+
 int btrfs_start_delalloc_inodes(struct btrfs_root *root);
 int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end);
 int btrfs_writepages(struct address_space *mapping,
@@ -1715,6 +1780,7 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 
 /* file.c */
+int btrfs_sync_file(struct file *file, struct dentry *dentry, int datasync);
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end);
 int btrfs_check_file(struct btrfs_root *root, struct inode *inode);
 extern struct file_operations btrfs_file_operations;

commit f3f9931e3d0836509cfccdf473b34e34543a3272
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Aug 21 15:49:09 2008 -0400

    Btrfs: Rev the disk format
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cecf29e03630..b305ae7e10b0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -40,7 +40,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_B6RfS_M"
+#define BTRFS_MAGIC "_B7RfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit 1a54ef8c11a0eaef59ff418089f109c27f8bd48d
Author: Balaji Rao <balajirrao@gmail.com>
Date:   Mon Jul 21 02:01:04 2008 +0530

    Introduce btrfs_iget helper
    
    Date: Mon, 21 Jul 2008 02:01:04 +0530
    This patch introduces a btrfs_iget helper to be used in NFS support.
    
    Signed-off-by: Balaji Rao <balajirrao@gmail.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 040213359393..cecf29e03630 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1700,6 +1700,8 @@ struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
 struct inode *btrfs_ilookup(struct super_block *s, u64 objectid,
 			    u64 root_objectid);
+struct inode *btrfs_iget(struct super_block *s, struct btrfs_key *location,
+			 struct btrfs_root *root, int *is_new);
 int btrfs_commit_write(struct file *file, struct page *page,
 		       unsigned from, unsigned to);
 struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,

commit 4854ddd0ed0a687fc2d7c45a529c406232e31e7b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:17 2008 -0400

    Btrfs: Wait for kernel threads to make progress during async submission
    
    Before this change, btrfs would use a bdi congestion function to make
    sure there weren't too many pending async checksum work items.
    
    This change makes the process creating async work items wait instead,
    leading to fewer congestion returns from the bdi.  This improves
    pdflush background_writeout scanning.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index bb4a8d2200d0..040213359393 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -526,6 +526,7 @@ struct btrfs_fs_info {
 	struct btrfs_transaction *running_transaction;
 	wait_queue_head_t transaction_throttle;
 	wait_queue_head_t transaction_wait;
+	wait_queue_head_t async_submit_wait;
 	struct btrfs_super_block super_copy;
 	struct btrfs_super_block super_for_commit;
 	struct block_device *__bdev;

commit 0986fe9eac24fd186927c3b87af51d62f8ab92cd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:15 2008 -0400

    Btrfs: Count async bios separately from async checksum work items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c88f1e16ce2d..bb4a8d2200d0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -544,6 +544,7 @@ struct btrfs_fs_info {
 	struct list_head hashers;
 	struct list_head dead_roots;
 	atomic_t nr_async_submits;
+	atomic_t nr_async_bios;
 
 	/*
 	 * this is used by the balancing code to wait for all the pending

commit 5036f53868ae943704ae69a192d21225dc914c35
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Aug 7 11:19:42 2008 -0400

    Btrfs: fix RHEL test for ClearPageFsMisc
    
    Newer RHEL5 kernels define both ClearPageFSMisc and
    ClearPageChecked, so test for both before redefining.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    ---
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f90e5a7ac161..c88f1e16ce2d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1648,7 +1648,7 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 /* inode.c */
 
 /* RHEL and EL kernels have a patch that renames PG_checked to FsMisc */
-#ifdef ClearPageFsMisc
+#if defined(ClearPageFsMisc) && !defined(ClearPageChecked)
 #define ClearPageChecked ClearPageFsMisc
 #define SetPageChecked SetPageFsMisc
 #define PageChecked PageFsMisc

commit 7ea394f1192bee1af67ea4762c88ef4b7b0487a8
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Tue Aug 5 13:05:02 2008 -0400

    Btrfs: Fix nodatacow for the new data=ordered mode
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 116aee21bf77..f90e5a7ac161 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1403,7 +1403,8 @@ static inline struct dentry *fdentry(struct file *file) {
 }
 
 /* extent-tree.c */
-int btrfs_cross_ref_exists(struct btrfs_root *root,
+int btrfs_cross_ref_exists(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root,
 			   struct btrfs_key *key, u64 bytenr);
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);

commit ea8c281947950fac5f78818b767821d696c9512a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Aug 4 23:17:27 2008 -0400

    Btrfs: Maintain a list of inodes that are delalloc and a way to wait on them
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 62499dd761b7..116aee21bf77 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -551,6 +551,7 @@ struct btrfs_fs_info {
 	 */
 	spinlock_t ordered_extent_lock;
 	struct list_head ordered_extents;
+	struct list_head delalloc_inodes;
 
 	/*
 	 * there is a pool of worker threads for checksumming during writes
@@ -637,6 +638,7 @@ struct btrfs_root {
 	struct kobject root_kobj;
 	struct completion kobj_unregister;
 	struct mutex objectid_mutex;
+
 	u64 objectid;
 	u64 last_trans;
 
@@ -1651,6 +1653,8 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 #define PageChecked PageFsMisc
 #endif
 
+int btrfs_start_delalloc_inodes(struct btrfs_root *root);
+int btrfs_set_extent_delalloc(struct inode *inode, u64 start, u64 end);
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_root *new_root,

commit 9ca9ee09c176a814189063c8b88f75c8f8e4ad19
Author: Sage Weil <sage@newdream.net>
Date:   Mon Aug 4 10:41:27 2008 -0400

    Btrfs: fix ioctl-initiated transactions vs wait_current_trans()
    
    Commit 597:466b27332893 (btrfs_start_transaction: wait for commits in
    progress) breaks the transaction start/stop ioctls by making
    btrfs_start_transaction conditionally wait for the next transaction to
    start.  If an application artificially is holding a transaction open,
    things deadlock.
    
    This workaround maintains a count of open ioctl-initiated transactions in
    fs_info, and avoids wait_current_trans() if any are currently open (in
    start_transaction() and btrfs_throttle()).  The start transaction ioctl
    uses a new btrfs_start_ioctl_transaction() that _does_ call
    wait_current_trans(), effectively pushing the join/wait decision to the
    outer ioctl-initiated transaction.
    
    This more or less neuters btrfs_throttle() when ioctl-initiated
    transactions are in use, but that seems like a pretty fundamental
    consequence of wrapping lots of write()'s in a transaction.  Btrfs has no
    way to tell if the application considers a given operation as part of it's
    transaction.
    
    Obviously, if the transaction start/stop ioctls aren't being used, there
    is no effect on current behavior.
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    ---
     ctree.h       |    1 +
     ioctl.c       |   12 +++++++++++-
     transaction.c |   18 +++++++++++++-----
     transaction.h |    2 ++
     4 files changed, 27 insertions(+), 6 deletions(-)
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9b025960bbde..62499dd761b7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -518,6 +518,7 @@ struct btrfs_fs_info {
 
 	u64 generation;
 	u64 last_trans_committed;
+	u64 open_ioctl_trans;
 	unsigned long mount_opt;
 	u64 max_extent;
 	u64 max_inline;

commit 65b51a009e29e64c0951f21ea17fdc66bbb0fbd7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 1 15:11:20 2008 -0400

    btrfs_search_slot: reduce lock contention by cowing in two stages
    
    A btree block cow has two parts, the first is to allocate a destination
    block and the second is to copy the old bock over.
    
    The first part needs locks in the extent allocation tree, and may need to
    do IO.  This changeset splits that into a separate function that can be
    called without any tree locks held.
    
    btrfs_search_slot is changed to drop its path and start over if it has
    to COW a contended block.  This often means that many writers will
    pre-alloc a new destination for a the same contended block, but they
    cache their prealloc for later use on lower levels in the tree.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d788ab0dcd96..9b025960bbde 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1421,6 +1421,9 @@ struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					     int level,
 					     u64 hint,
 					     u64 empty_size);
+struct extent_buffer *btrfs_init_new_buffer(struct btrfs_trans_handle *trans,
+					    struct btrfs_root *root,
+					    u64 bytenr, u32 blocksize);
 int btrfs_shrink_extent_tree(struct btrfs_root *root, u64 new_size);
 int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
@@ -1451,6 +1454,7 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 bytenr, u64 num_bytes,
 		      u64 root_objectid, u64 ref_generation,
 		      u64 owner_objectid, u64 owner_offset, int pin);
+int btrfs_free_reserved_extent(struct btrfs_root *root, u64 start, u64 len);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       struct extent_io_tree *unpin);
@@ -1484,7 +1488,7 @@ int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,
-		    struct extent_buffer **cow_ret);
+		    struct extent_buffer **cow_ret, u64 prealloc_dest);
 int btrfs_copy_root(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root,
 		      struct extent_buffer *buf,

commit 61b4944018449003ac5f9757f4d125dce519cf51
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 31 15:42:53 2008 -0400

    Btrfs: Fix streaming read performance with checksumming on
    
    Large streaming reads make for large bios, which means each entry on the
    list async work queues represents a large amount of data.  IO
    congestion throttling on the device was kicking in before the async
    worker threads decided a single thread was busy and needed some help.
    
    The end result was that a streaming read would result in a single CPU
    running at 100% instead of balancing the work off to other CPUs.
    
    This patch also changes the pre-IO checksum lookup done by reads to
    work on a per-bio basis instead of a per-page.  This results in many
    extra btree lookups on large streaming reads.  Doing the checksum lookup
    right before bio submit allows us to reuse searches while processing
    adjacent offsets.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index be16cd49ef69..d788ab0dcd96 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1613,6 +1613,8 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       struct btrfs_key *location, int mod);
 
 /* file-item.c */
+int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
+			  struct bio *bio);
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       u64 objectid, u64 pos, u64 disk_offset,

commit bcc63abbf3e9bf948a1b0129b3e6120ec7d7f698
Author: Yan <zheng.yan@oracle.com>
Date:   Wed Jul 30 16:29:20 2008 -0400

    Btrfs: implement memory reclaim for leaf reference cache
    
    The memory reclaiming issue happens when snapshot exists. In that
    case, some cache entries may not be used during old snapshot dropping,
    so they will remain in the cache until umount.
    
    The patch adds a field to struct btrfs_leaf_ref to record create time. Besides,
    the patch makes all dead roots of a given snapshot linked together in order of
    create time. After a old snapshot was completely dropped, we check the dead
    root list and remove all cache entries created before the oldest dead root in
    the list.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 83422088c629..be16cd49ef69 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -666,7 +666,8 @@ struct btrfs_root {
 	/* the dirty list is only used by non-reference counted roots */
 	struct list_head dirty_list;
 
-	spinlock_t orphan_lock;
+	spinlock_t list_lock;
+	struct list_head dead_list;
 	struct list_head orphan_list;
 };
 

commit f321e4910398cf7922265d269fb17fd26f312571
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jul 30 09:26:11 2008 -0400

    Btrfs: Update and fix mount -o nodatacow
    
    To check whether a given file extent is referenced by multiple snapshots, the
    checker walks down the fs tree through dead root and checks all tree blocks in
    the path.
    
    We can easily detect whether a given tree block is directly referenced by other
    snapshot. We can also detect any indirect reference from other snapshot by
    checking reference's generation. The checker can always detect multiple
    references, but can't reliably detect cases of single reference. So btrfs may
    do file data cow even there is only one reference.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5517dfc6f71c..83422088c629 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -617,7 +617,7 @@ struct btrfs_leaf_ref_tree {
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.
  */
-struct dirty_root;
+struct btrfs_dirty_root;
 struct btrfs_root {
 	struct extent_buffer *node;
 
@@ -627,7 +627,7 @@ struct btrfs_root {
 	struct extent_buffer *commit_root;
 	struct btrfs_leaf_ref_tree *ref_tree;
 	struct btrfs_leaf_ref_tree ref_tree_struct;
-	struct dirty_root *dirty_root;
+	struct btrfs_dirty_root *dirty_root;
 
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
@@ -1399,9 +1399,8 @@ static inline struct dentry *fdentry(struct file *file) {
 }
 
 /* extent-tree.c */
-u32 btrfs_count_snapshots_in_path(struct btrfs_root *root,
-				  struct btrfs_path *count_path,
-				  u64 expected_owner, u64 first_extent);
+int btrfs_cross_ref_exists(struct btrfs_root *root,
+			   struct btrfs_key *key, u64 bytenr);
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);

commit ab78c84de1ce4db1b2a2cef361625ad80abbab3f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 29 16:15:18 2008 -0400

    Btrfs: Throttle operations if the reference cache gets too large
    
    A large reference cache is directly related to a lot of work pending
    for the cleaner thread.  This throttles back new operations based on
    the size of the reference cache so the cleaner thread will be able to keep
    up.
    
    Overall, this actually makes the FS faster because the cleaner thread will
    be more likely to find things in cache.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4eca0aa1ce74..5517dfc6f71c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -580,6 +580,7 @@ struct btrfs_fs_info {
 	int do_barriers;
 	int closing;
 	atomic_t throttles;
+	atomic_t throttle_gen;
 
 	u64 total_pinned;
 	struct list_head dirty_cowonly_roots;

commit 017e5369eb353559d68a11d4a718faa634533821
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jul 28 15:32:51 2008 -0400

    Btrfs: Leaf reference cache update
    
    This changes the reference cache to make a single cache per root
    instead of one cache per transaction, and to key by the byte number
    of the disk block instead of the keys inside.
    
    This makes it much less likely to have cache misses if a snapshot
    or something has an extra reference on a higher node or a leaf while
    the first transaction that added the leaf into the cache is dropping.
    
    Some throttling is added to functions that free blocks heavily so they
    wait for old transactions to drop.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 34ed23d64eb5..4eca0aa1ce74 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -594,7 +594,6 @@ struct btrfs_fs_info {
 
 	spinlock_t ref_cache_lock;
 	u64 total_ref_cache_size;
-	u64 running_ref_cache_size;
 
 	u64 avail_data_alloc_bits;
 	u64 avail_metadata_alloc_bits;
@@ -606,10 +605,18 @@ struct btrfs_fs_info {
 	void *bdev_holder;
 };
 
+struct btrfs_leaf_ref_tree {
+	struct rb_root root;
+	struct btrfs_leaf_ref *last;
+	struct list_head list;
+	spinlock_t lock;
+};
+
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.
  */
+struct dirty_root;
 struct btrfs_root {
 	struct extent_buffer *node;
 
@@ -618,6 +625,8 @@ struct btrfs_root {
 
 	struct extent_buffer *commit_root;
 	struct btrfs_leaf_ref_tree *ref_tree;
+	struct btrfs_leaf_ref_tree ref_tree_struct;
+	struct dirty_root *dirty_root;
 
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;

commit 31153d81284934601d08110ac7698fd9a535e4c0
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Mon Jul 28 15:32:19 2008 -0400

    Btrfs: Add a leaf reference cache
    
    Much of the IO done while dropping snapshots is done looking up
    leaves in the filesystem trees to see if they point to any extents and
    to drop the references on any extents found.
    
    This creates a cache so that IO isn't required.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 07d321552dbe..34ed23d64eb5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -592,6 +592,10 @@ struct btrfs_fs_info {
 	u64 last_alloc;
 	u64 last_data_alloc;
 
+	spinlock_t ref_cache_lock;
+	u64 total_ref_cache_size;
+	u64 running_ref_cache_size;
+
 	u64 avail_data_alloc_bits;
 	u64 avail_metadata_alloc_bits;
 	u64 avail_system_alloc_bits;
@@ -613,6 +617,8 @@ struct btrfs_root {
 	spinlock_t node_lock;
 
 	struct extent_buffer *commit_root;
+	struct btrfs_leaf_ref_tree *ref_tree;
+
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
@@ -1430,7 +1436,7 @@ int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
 				  u64 search_end, struct btrfs_key *ins,
 				  u64 data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct extent_buffer *buf);
+		  struct extent_buffer *buf, int cache_ref);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 bytenr, u64 num_bytes,
 		      u64 root_objectid, u64 ref_generation,

commit 3a115f520f391b4ab14041bdd6eedb370d944fa6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 24 12:25:50 2008 -0400

    Btrfs: Rev the disk format magic
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 012ad529cb18..07d321552dbe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -40,7 +40,7 @@ extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 struct btrfs_ordered_sum;
 
-#define BTRFS_MAGIC "_B5RfS_M"
+#define BTRFS_MAGIC "_B6RfS_M"
 
 #define BTRFS_ACL_NOT_CACHED    ((void *)-1)
 

commit 7b1287662304c3cb05cb38f5e3e2d69f386e8f10
Author: Josef Bacik <jbacik@redhat.com>
Date:   Thu Jul 24 12:17:14 2008 -0400

    Btrfs: Create orphan inode records to prevent lost files after a crash
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f87d7263f2d7..012ad529cb18 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -74,6 +74,9 @@ struct btrfs_ordered_sum;
 /* directory objectid inside the root tree */
 #define BTRFS_ROOT_TREE_DIR_OBJECTID 6ULL
 
+/* orhpan objectid for tracking unlinked/truncated files */
+#define BTRFS_ORPHAN_OBJECTID -5ULL
+
 /*
  * All files have objectids higher than this.
  */
@@ -646,6 +649,9 @@ struct btrfs_root {
 
 	/* the dirty list is only used by non-reference counted roots */
 	struct list_head dirty_list;
+
+	spinlock_t orphan_lock;
+	struct list_head orphan_list;
 };
 
 /*
@@ -657,6 +663,7 @@ struct btrfs_root {
 #define BTRFS_INODE_ITEM_KEY		1
 #define BTRFS_INODE_REF_KEY		2
 #define BTRFS_XATTR_ITEM_KEY		8
+#define BTRFS_ORPHAN_ITEM_KEY		9
 /* reserve 2-15 close to the inode for later flexibility */
 
 /*
@@ -1560,6 +1567,13 @@ struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
 					  struct btrfs_path *path, u64 dir,
 					  const char *name, u16 name_len,
 					  int mod);
+
+/* orphan.c */
+int btrfs_insert_orphan_item(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root, u64 offset);
+int btrfs_del_orphan_item(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root, u64 offset);
+
 /* inode-map.c */
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *fs_root,

commit 33268eaf0b3db5e2bd12c0ada81a8e8f87a46d68
Author: Josef Bacik <jbacik@redhat.com>
Date:   Thu Jul 24 12:16:36 2008 -0400

    Btrfs: Add ACL support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 53d315bdd16d..f87d7263f2d7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -42,6 +42,8 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAGIC "_B5RfS_M"
 
+#define BTRFS_ACL_NOT_CACHED    ((void *)-1)
+
 #ifdef CONFIG_LOCKDEP
 # define BTRFS_MAX_LEVEL 7
 #else
@@ -1694,4 +1696,9 @@ ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 u64 btrfs_parse_size(char *str);
 int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
+
+/* acl.c */
+int btrfs_check_acl(struct inode *inode, int mask);
+int btrfs_init_acl(struct inode *inode, struct inode *dir);
+int btrfs_acl_chmod(struct inode *inode);
 #endif

commit 6099afe88fe64b2f47c43a8a71c13be3a416bbf7
Author: Josef Bacik <jbacik@redhat.com>
Date:   Thu Jul 24 12:16:03 2008 -0400

    Btrfs: Remove unused xattr code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index beb05b1de54c..53d315bdd16d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1689,8 +1689,7 @@ void btrfs_sysfs_del_super(struct btrfs_fs_info *root);
 
 /* xattr.c */
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
-int btrfs_delete_xattrs(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root, struct inode *inode);
+
 /* super.c */
 u64 btrfs_parse_size(char *str);
 int btrfs_parse_options(struct btrfs_root *root, char *options);

commit aec7477b3b0e8ec93f6d274f25ba40b0665134d4
Author: Josef Bacik <jbacik@redhat.com>
Date:   Thu Jul 24 12:12:38 2008 -0400

    Btrfs: Implement new dir index format
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6675e916ebcd..beb05b1de54c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -372,6 +372,7 @@ struct btrfs_dev_extent {
 } __attribute__ ((__packed__));
 
 struct btrfs_inode_ref {
+	__le64 index;
 	__le16 name_len;
 	/* name goes here */
 } __attribute__ ((__packed__));
@@ -902,6 +903,7 @@ BTRFS_SETGET_STACK_FUNCS(block_group_flags,
 
 /* struct btrfs_inode_ref */
 BTRFS_SETGET_FUNCS(inode_ref_name_len, struct btrfs_inode_ref, name_len, 16);
+BTRFS_SETGET_FUNCS(inode_ref_index, struct btrfs_inode_ref, index, 64);
 
 /* struct btrfs_inode_item */
 BTRFS_SETGET_FUNCS(inode_generation, struct btrfs_inode_item, generation, 64);
@@ -1528,7 +1530,7 @@ int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid,
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, const char *name, int name_len, u64 dir,
-			  struct btrfs_key *location, u8 type);
+			  struct btrfs_key *location, u8 type, u64 index);
 struct btrfs_dir_item *btrfs_lookup_dir_item(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,
 					     struct btrfs_path *path, u64 dir,
@@ -1566,11 +1568,11 @@ int btrfs_find_highest_inode(struct btrfs_root *fs_root, u64 *objectid);
 int btrfs_insert_inode_ref(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   const char *name, int name_len,
-			   u64 inode_objectid, u64 ref_objectid);
+			   u64 inode_objectid, u64 ref_objectid, u64 index);
 int btrfs_del_inode_ref(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   const char *name, int name_len,
-			   u64 inode_objectid, u64 ref_objectid);
+			   u64 inode_objectid, u64 ref_objectid, u64 *index);
 int btrfs_insert_empty_inode(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid);

commit 3eaa2885276fd6dac7b076a793932428b7168e74
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 24 11:57:52 2008 -0400

    Btrfs: Fix the defragmention code and the block relocation code for data=ordered
    
    Before setting an extent to delalloc, the code needs to wait for
    pending ordered extents.
    
    Also, the relocation code needs to wait for ordered IO before scanning
    the block group again.  This is because the extents are not removed
    until the IO for the new extents is finished
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8ecac2e77a43..6675e916ebcd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -538,6 +538,13 @@ struct btrfs_fs_info {
 	struct list_head dead_roots;
 	atomic_t nr_async_submits;
 
+	/*
+	 * this is used by the balancing code to wait for all the pending
+	 * ordered extents
+	 */
+	spinlock_t ordered_extent_lock;
+	struct list_head ordered_extents;
+
 	/*
 	 * there is a pool of worker threads for checksumming during writes
 	 * and a pool for checksumming after reads.  This is because readers

commit 4881ee5a2e995c6a8999b56de70aa3834369d8ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 24 09:51:08 2008 -0400

    Btrfs: Fix some build problems on 2.6.18 based enterprise kernels
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 90504ba7f838..8ecac2e77a43 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1595,6 +1595,14 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+
+/* RHEL and EL kernels have a patch that renames PG_checked to FsMisc */
+#ifdef ClearPageFsMisc
+#define ClearPageChecked ClearPageFsMisc
+#define SetPageChecked SetPageFsMisc
+#define PageChecked PageFsMisc
+#endif
+
 int btrfs_writepages(struct address_space *mapping,
 		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_root *new_root,

commit c286ac48ed7aaf53586f575af6053ae2a0f8554a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 23:06:41 2008 -0400

    Btrfs: alloc_mutex latency reduction
    
    This releases the alloc_mutex in a few places that hold it for over long
    operations.  btrfs_lookup_block_group is changed so that it doesn't need
    the mutex at all.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index eeb5afa6e9b1..90504ba7f838 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -483,6 +483,7 @@ struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
 	struct btrfs_space_info *space_info;
+	spinlock_t lock;
 	u64 pinned;
 	u64 flags;
 	int cached;

commit 6dddcbeb28b34620ad033f1e8d9f6960bafdd7d2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 11:18:09 2008 -0400

    Btrfs: Use mutex_lock_nested for tree locking
    
    Lockdep has the notion of locking subclasses so that you can identify
    locks you expect to be taken after other locks of the same class.  This
    changes the per-extent buffer btree locking routines to use a subclass based
    on the level in the tree.
    
    Unfortunately, lockdep can only handle 8 total subclasses, and the btrfs
    max level is also 8.  So when lockdep is on, use a lower max level.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f8fccdac3055..eeb5afa6e9b1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -42,7 +42,11 @@ struct btrfs_ordered_sum;
 
 #define BTRFS_MAGIC "_B5RfS_M"
 
-#define BTRFS_MAX_LEVEL 8
+#ifdef CONFIG_LOCKDEP
+# define BTRFS_MAX_LEVEL 7
+#else
+# define BTRFS_MAX_LEVEL 8
+#endif
 
 /* holds pointers to all of the tree roots */
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL

commit f421950f86bf96a11fef932e167ab2e70d4c43a0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 11:18:09 2008 -0400

    Btrfs: Fix some data=ordered related data corruptions
    
    Stress testing was showing data checksum errors, most of which were caused
    by a lookup bug in the extent_map tree.  The tree was caching the last
    pointer returned, and searches would check the last pointer first.
    
    But, search callers also expect the search to return the very first
    matching extent in the range, which wasn't always true with the last
    pointer usage.
    
    For now, the code to cache the last return value is just removed.  It is
    easy to fix, but I think lookups are rare enough that it isn't required anymore.
    
    This commit also replaces do_sync_mapping_range with a local copy of the
    related functions.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 96ab2797c09a..f8fccdac3055 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1590,6 +1590,8 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+int btrfs_writepages(struct address_space *mapping,
+		     struct writeback_control *wbc);
 int btrfs_create_subvol_root(struct btrfs_root *new_root,
 		struct btrfs_trans_handle *trans, u64 new_dirid,
 		struct btrfs_block_group_cache *block_group);

commit 3edf7d33f4edb1e4a9bb0a4c0a84d95fb4d22a09
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jul 18 06:17:13 2008 -0400

    Btrfs: Handle data checksumming on bios that span multiple ordered extents
    
    Data checksumming is done right before the bio is sent down the IO stack,
    which means a single bio might span more than one ordered extent.  In
    this case, the checksumming data is split between two ordered extents.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index acbce542d291..96ab2797c09a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1579,8 +1579,8 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct inode *inode,
 			   struct btrfs_ordered_sum *sums);
-int btrfs_csum_one_bio(struct btrfs_root *root,
-		       struct bio *bio, struct btrfs_ordered_sum **sums_ret);
+int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
+		       struct bio *bio);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,

commit f9295749388f82c8d2f485e99c72cd7c7876a99b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:54:14 2008 -0400

    btrfs_start_transaction: wait for commits in progress to finish
    
    btrfs_commit_transaction has to loop waiting for any writers in the
    transaction to finish before it can proceed.  btrfs_start_transaction
    should be polite and not join a transaction that is in the process
    of being finished off.
    
    There are a few places that can't wait, basically the ones doing IO that
    might be needed to finish the transaction.  For them, btrfs_join_transaction
    is added.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4ddc8a8f82cd..acbce542d291 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -513,6 +513,7 @@ struct btrfs_fs_info {
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;
 	wait_queue_head_t transaction_throttle;
+	wait_queue_head_t transaction_wait;
 	struct btrfs_super_block super_copy;
 	struct btrfs_super_block super_for_commit;
 	struct block_device *__bdev;

commit 247e743cbe6e655768c3679f84821e03c1577902
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:51 2008 -0400

    Btrfs: Use async helpers to deal with pages that have been improperly dirtied
    
    Higher layers sometimes call set_page_dirty without asking the filesystem
    to help.  This causes many problems for the data=ordered and cow code.
    This commit detects pages that haven't been properly setup for IO and
    kicks off an async helper to deal with them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ceebc052ddcb..4ddc8a8f82cd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -546,6 +546,12 @@ struct btrfs_fs_info {
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers submit_workers;
+	/*
+	 * fixup workers take dirty pages that didn't properly go through
+	 * the cow mechanism and make them safe to write.  It happens
+	 * for the sys_munmap function call path
+	 */
+	struct btrfs_workers fixup_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
 	int thread_pool_size;

commit e6dcd2dc9c489108648e2ed543315dd134d50a9a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:50 2008 -0400

    Btrfs: New data=ordered implementation
    
    The old data=ordered code would force commit to wait until
    all the data extents from the transaction were fully on disk.  This
    introduced large latencies into the commit and stalled new writers
    in the transaction for a long time.
    
    The new code changes the way data allocations and extents work:
    
    * When delayed allocation is filled, data extents are reserved, and
      the extent bit EXTENT_ORDERED is set on the entire range of the extent.
      A struct btrfs_ordered_extent is allocated an inserted into a per-inode
      rbtree to track the pending extents.
    
    * As each page is written EXTENT_ORDERED is cleared on the bytes corresponding
      to that page.
    
    * When all of the bytes corresponding to a single struct btrfs_ordered_extent
      are written, The previously reserved extent is inserted into the FS
      btree and into the extent allocation trees.  The checksums for the file
      data are also updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f3783dbd9b60..ceebc052ddcb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -25,6 +25,7 @@
 #include <linux/fs.h>
 #include <linux/completion.h>
 #include <linux/backing-dev.h>
+#include <linux/wait.h>
 #include <asm/kmap_types.h>
 #include "bit-radix.h"
 #include "extent_io.h"
@@ -37,6 +38,7 @@ extern struct kmem_cache *btrfs_trans_handle_cachep;
 extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
+struct btrfs_ordered_sum;
 
 #define BTRFS_MAGIC "_B5RfS_M"
 
@@ -510,6 +512,7 @@ struct btrfs_fs_info {
 	u64 max_inline;
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;
+	wait_queue_head_t transaction_throttle;
 	struct btrfs_super_block super_copy;
 	struct btrfs_super_block super_for_commit;
 	struct block_device *__bdev;
@@ -541,6 +544,7 @@ struct btrfs_fs_info {
 	 */
 	struct btrfs_workers workers;
 	struct btrfs_workers endio_workers;
+	struct btrfs_workers endio_write_workers;
 	struct btrfs_workers submit_workers;
 	struct task_struct *transaction_kthread;
 	struct task_struct *cleaner_kthread;
@@ -1384,6 +1388,17 @@ int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       u64 owner, u64 owner_offset,
 		       u64 empty_size, u64 hint_byte,
 		       u64 search_end, struct btrfs_key *ins, u64 data);
+int btrfs_alloc_reserved_extent(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root,
+				u64 root_objectid, u64 ref_generation,
+				u64 owner, u64 owner_offset,
+				struct btrfs_key *ins);
+int btrfs_reserve_extent(struct btrfs_trans_handle *trans,
+				  struct btrfs_root *root,
+				  u64 num_bytes, u64 min_alloc_size,
+				  u64 empty_size, u64 hint_byte,
+				  u64 search_end, struct btrfs_key *ins,
+				  u64 data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
@@ -1556,9 +1571,9 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     u64 bytenr, int mod);
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct inode *inode,
-			   struct bio *bio, char *sums);
+			   struct btrfs_ordered_sum *sums);
 int btrfs_csum_one_bio(struct btrfs_root *root,
-		       struct bio *bio, char **sums_ret);
+		       struct bio *bio, struct btrfs_ordered_sum **sums_ret);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,

commit 7d9eb12c8739e7dc80c78c6b3596f912ecd8f941
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 8 14:19:17 2008 -0400

    Btrfs: Add locking around volume management (device add/remove/balance)
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a28796482b4a..f3783dbd9b60 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -523,6 +523,7 @@ struct btrfs_fs_info {
 	struct mutex alloc_mutex;
 	struct mutex chunk_mutex;
 	struct mutex drop_mutex;
+	struct mutex volume_mutex;
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;

commit 3f157a2fd2ad731e1ed9964fecdc5f459f04a4a4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Online btree defragmentation fixes
    
    The btree defragger wasn't making forward progress because the new key wasn't
    being saved by the btrfs_search_forward function.
    
    This also disables the automatic btree defrag, it wasn't scaling well to
    huge filesystems.  The auto-defrag needs to be done differently.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ca8e6f15859e..a28796482b4a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -609,6 +609,7 @@ struct btrfs_root {
 	u64 last_inode_alloc;
 	int ref_cows;
 	int track_dirty;
+	u64 defrag_trans_start;
 	struct btrfs_key defrag_progress;
 	struct btrfs_key defrag_max;
 	int defrag_running;
@@ -1412,7 +1413,11 @@ int btrfs_previous_item(struct btrfs_root *root,
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
 int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
-			struct btrfs_key *key, int lowest_level);
+			struct btrfs_key *key, int lowest_level,
+			int cache_only, u64 min_trans);
+int btrfs_search_forward(struct btrfs_root *root, struct btrfs_key *min_key,
+			 struct btrfs_path *path, int cache_only,
+			 u64 min_trans);
 
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,

commit e7a84565bcdb239caad29ccbe559ef978090ac7e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Add btree locking to the tree defragmentation code
    
    The online btree defragger is simplified and rewritten to use
    standard btree searches instead of a walk up / down mechanism.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 244fe86bcc55..ca8e6f15859e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1411,6 +1411,8 @@ int btrfs_previous_item(struct btrfs_root *root,
 
 struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
 struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
+int btrfs_find_next_key(struct btrfs_root *root, struct btrfs_path *path,
+			struct btrfs_key *key, int lowest_level);
 
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,

commit a74a4b97b61beede185b4b3ad359d7d378b0d312
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Replace the transaction work queue with kthreads
    
    This creates one kthread for commits and one kthread for
    deleting old snapshots.  All the work queues are removed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e9bbb53eda63..244fe86bcc55 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -23,7 +23,6 @@
 #include <linux/mm.h>
 #include <linux/highmem.h>
 #include <linux/fs.h>
-#include <linux/workqueue.h>
 #include <linux/completion.h>
 #include <linux/backing-dev.h>
 #include <asm/kmap_types.h>
@@ -519,15 +518,14 @@ struct btrfs_fs_info {
 	struct backing_dev_info bdi;
 	spinlock_t hash_lock;
 	struct mutex trans_mutex;
+	struct mutex transaction_kthread_mutex;
+	struct mutex cleaner_mutex;
 	struct mutex alloc_mutex;
 	struct mutex chunk_mutex;
 	struct mutex drop_mutex;
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
-	struct list_head end_io_work_list;
-	struct work_struct end_io_work;
-	spinlock_t end_io_work_lock;
 	atomic_t nr_async_submits;
 
 	/*
@@ -543,13 +541,10 @@ struct btrfs_fs_info {
 	struct btrfs_workers workers;
 	struct btrfs_workers endio_workers;
 	struct btrfs_workers submit_workers;
+	struct task_struct *transaction_kthread;
+	struct task_struct *cleaner_kthread;
 	int thread_pool_size;
 
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-	struct work_struct trans_work;
-#else
-	struct delayed_work trans_work;
-#endif
 	struct kobject super_kobj;
 	struct completion kobj_unregister;
 	int do_barriers;

commit 5cd57b2cbbb06a350df2698314e4e6a80805fc2f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Btrfs: Add a skip_locking parameter to struct path, and make various funcs honor it
    
    Allocations may need to read in block groups from the extent allocation tree,
    which will require a tree search and take locks on the extent allocation
    tree.  But, those locks might already be held in other places, leading
    to deadlocks.
    
    Since the alloc_mutex serializes everything right now, it is safe to
    skip the btree locking while caching block groups.  A better fix will be
    to either create a recursive lock or find a way to back off existing
    locks while caching block groups.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9ea12d42741c..e9bbb53eda63 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -335,6 +335,7 @@ struct btrfs_path {
 	int reada;
 	/* keep some upper locks as we walk down */
 	int keep_locks;
+	int skip_locking;
 	int lowest_level;
 };
 

commit 051e1b9f748ae673b7325d3fc049bb838606cffa
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Drop locks in btrfs_search_slot when reading a tree block.
    
    One lock per btree block can make for significant congestion if everyone
    has to wait for IO at the high levels of the btree.  This drops
    locks held by a path when doing reads during a tree search.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 692b8ea42de1..9ea12d42741c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -336,7 +336,6 @@ struct btrfs_path {
 	/* keep some upper locks as we walk down */
 	int keep_locks;
 	int lowest_level;
-	int skip_locking;
 };
 
 /*

commit a213501153fd66e2359e091b1612841305ba6551
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Btrfs: Replace the big fs_mutex with a collection of other locks
    
    Extent alloctions are still protected by a large alloc_mutex.
    Objectid allocations are covered by a objectid mutex
    Other btree operations are protected by a lock on individual btree nodes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 50891b39f366..692b8ea42de1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -519,9 +519,9 @@ struct btrfs_fs_info {
 	struct backing_dev_info bdi;
 	spinlock_t hash_lock;
 	struct mutex trans_mutex;
-	struct mutex fs_mutex;
 	struct mutex alloc_mutex;
 	struct mutex chunk_mutex;
+	struct mutex drop_mutex;
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
@@ -554,7 +554,7 @@ struct btrfs_fs_info {
 	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
-	unsigned long throttles;
+	atomic_t throttles;
 
 	u64 total_pinned;
 	struct list_head dirty_cowonly_roots;
@@ -594,6 +594,7 @@ struct btrfs_root {
 	struct inode *inode;
 	struct kobject root_kobj;
 	struct completion kobj_unregister;
+	struct mutex objectid_mutex;
 	u64 objectid;
 	u64 last_trans;
 

commit 925baeddc5b0764a53f2214a1253251bab0e0324
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Btrfs: Start btree concurrency work.
    
    The allocation trees and the chunk trees are serialized via their own
    dedicated mutexes.  This means allocation location is still not very
    fine grained.
    
    The main FS btree is protected by locks on each block in the btree.  Locks
    are taken top / down, and as processing finishes on a given level of the
    tree, the lock is released after locking the lower level.
    
    The end result of a search is now a path where only the lowest level
    is locked.  Releasing or freeing the path drops any locks held.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dcea9d706d9b..50891b39f366 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -330,8 +330,13 @@ struct btrfs_node {
 struct btrfs_path {
 	struct extent_buffer *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];
+	/* if there is real range locking, this locks field will change */
+	int locks[BTRFS_MAX_LEVEL];
 	int reada;
+	/* keep some upper locks as we walk down */
+	int keep_locks;
 	int lowest_level;
+	int skip_locking;
 };
 
 /*
@@ -515,6 +520,8 @@ struct btrfs_fs_info {
 	spinlock_t hash_lock;
 	struct mutex trans_mutex;
 	struct mutex fs_mutex;
+	struct mutex alloc_mutex;
+	struct mutex chunk_mutex;
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
@@ -576,6 +583,10 @@ struct btrfs_fs_info {
  */
 struct btrfs_root {
 	struct extent_buffer *node;
+
+	/* the node lock is held while changing the node pointer */
+	spinlock_t node_lock;
+
 	struct extent_buffer *commit_root;
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
@@ -1353,13 +1364,7 @@ struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 struct btrfs_block_group_cache
 						 *hint, u64 search_start,
 						 int data, int owner);
-int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *root, u64 owner_objectid);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
-					    struct btrfs_root *root, u32 size,
-					    u64 root_objectid,
-					    u64 hint, u64 empty_size);
-struct extent_buffer *__btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					     struct btrfs_root *root,
 					     u32 blocksize,
 					     u64 root_objectid,
@@ -1368,8 +1373,6 @@ struct extent_buffer *__btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					     int level,
 					     u64 hint,
 					     u64 empty_size);
-int btrfs_grow_extent_tree(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, u64 new_size);
 int btrfs_shrink_extent_tree(struct btrfs_root *root, u64 new_size);
 int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
@@ -1409,6 +1412,10 @@ int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 int btrfs_previous_item(struct btrfs_root *root,
 			struct btrfs_path *path, u64 min_objectid,
 			int type);
+
+struct extent_buffer *btrfs_root_node(struct btrfs_root *root);
+struct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root);
+
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,

commit 1cc127b5d1b71453091859301de4a7dd6ee96fa8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jun 12 14:46:17 2008 -0400

    Btrfs: Add a thread pool just for submit_bio
    
    If a bio submission is after a lock holder waiting for the bio
    on the work queue, it is possible to deadlock.  Move the bios
    into their own pool.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 181c81d29897..dcea9d706d9b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -529,9 +529,13 @@ struct btrfs_fs_info {
 	 * can run with FS locks held, and the writers may be waiting for
 	 * those locks.  We don't want ordering in the pending list to cause
 	 * deadlocks, and so the two are serviced separately.
+	 *
+	 * A third pool does submit_bio to avoid deadlocking with the other
+	 * two
 	 */
 	struct btrfs_workers workers;
 	struct btrfs_workers endio_workers;
+	struct btrfs_workers submit_workers;
 	int thread_pool_size;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)

commit f46b5a66b3316ef2f8febfe4c56e2d555e2c3979
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 11 21:53:53 2008 -0400

    Btrfs: split out ioctl.c
    
    Split the ioctl handling out of inode.c into a file of it's own.
    Also fix up checkpatch.pl warnings for the moved code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7ae4666103c0..181c81d29897 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1553,6 +1553,10 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+int btrfs_create_subvol_root(struct btrfs_root *new_root,
+		struct btrfs_trans_handle *trans, u64 new_dirid,
+		struct btrfs_block_group_cache *block_group);
+
 void btrfs_invalidate_dcache_root(struct btrfs_root *root, char *name,
 				  int namelen);
 
@@ -1585,7 +1589,6 @@ void btrfs_destroy_inode(struct inode *inode);
 int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
 long btrfs_ioctl_trans_end(struct file *file);
-long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
 struct inode *btrfs_ilookup(struct super_block *s, u64 objectid,
@@ -1598,6 +1601,10 @@ struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
 int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct inode *inode);
+
+/* ioctl.c */
+long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
+
 /* file.c */
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end);
 int btrfs_check_file(struct btrfs_root *root, struct inode *inode);

commit 4543df7ecc8ae4928c1e51d6e7dc188d650abee4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 11 21:47:56 2008 -0400

    Btrfs: Add a mount option to control worker thread pool size
    
    mount -o thread_pool_size changes the default, which is
    min(num_cpus + 2, 8).  Larger thread pools would make more sense on
    very large disk arrays.
    
    This mount option controls the max size of each thread pool.  There
    are multiple thread pools, so the total worker count will be larger
    than the mount option.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6c91a510c965..7ae4666103c0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -532,6 +532,7 @@ struct btrfs_fs_info {
 	 */
 	struct btrfs_workers workers;
 	struct btrfs_workers endio_workers;
+	int thread_pool_size;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	struct work_struct trans_work;

commit 8b7128429235d9bd72cfd5ed20c77c4f3118f744
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 11 16:50:36 2008 -0400

    Btrfs: Add async worker threads for pre and post IO checksumming
    
    Btrfs has been using workqueues to spread the checksumming load across
    other CPUs in the system.  But, workqueues only schedule work on the
    same CPU that queued the work, giving them a limited benefit for systems with
    higher CPU counts.
    
    This code adds a generic facility to schedule work with pools of kthreads,
    and changes the bio submission code to queue bios up.  The queueing is
    important to make sure large numbers of procs on the system don't
    turn streaming workloads into random workloads by sending IO down
    concurrently.
    
    The end result of all of this is much higher performance (and CPU usage) when
    doing checksumming on large machines.  Two worker pools are created,
    one for writes and one for endio processing.  The two could deadlock if
    we tried to service both from a single pool.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 49cbc62b42f9..6c91a510c965 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -30,6 +30,7 @@
 #include "bit-radix.h"
 #include "extent_io.h"
 #include "extent_map.h"
+#include "async-thread.h"
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
@@ -518,13 +519,20 @@ struct btrfs_fs_info {
 	struct list_head hashers;
 	struct list_head dead_roots;
 	struct list_head end_io_work_list;
-	struct list_head async_submit_work_list;
 	struct work_struct end_io_work;
-	struct work_struct async_submit_work;
 	spinlock_t end_io_work_lock;
-	spinlock_t async_submit_work_lock;
 	atomic_t nr_async_submits;
 
+	/*
+	 * there is a pool of worker threads for checksumming during writes
+	 * and a pool for checksumming after reads.  This is because readers
+	 * can run with FS locks held, and the writers may be waiting for
+	 * those locks.  We don't want ordering in the pending list to cause
+	 * deadlocks, and so the two are serviced separately.
+	 */
+	struct btrfs_workers workers;
+	struct btrfs_workers endio_workers;
+
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	struct work_struct trans_work;
 #else

commit edf24abe51493ccda384644d487fe2f796ac21c8
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jun 10 10:40:29 2008 -0400

    btrfs: sanity mount option parsing and early mount code
    
    Also adds lots of comments to describe what's going on here.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1dcf4fb5b688..49cbc62b42f9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1616,7 +1616,6 @@ int btrfs_delete_xattrs(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct inode *inode);
 /* super.c */
 u64 btrfs_parse_size(char *str);
-int btrfs_parse_options(char *options, struct btrfs_root *root,
-			char **subvol_name);
+int btrfs_parse_options(struct btrfs_root *root, char *options);
 int btrfs_sync_fs(struct super_block *sb, int wait);
 #endif

commit 6bf13c0cc833bf5ba013d6aa60379484bf48c4e6
Author: Sage Weil <sage@newdream.net>
Date:   Tue Jun 10 10:07:39 2008 -0400

    Btrfs: transaction ioctls
    
    These ioctls let a user application hold a transaction open while it
    performs a series of operations.  A final ioctl does a sync on the fs
    (closing the current transaction).  This is the main requirement for
    Ceph's OSD to be able to keep the data it's storing in a btrfs volume
    consistent, and AFAICS it works just fine.  The application would do
    something like
    
            fd = ::open("some/file", O_RDONLY);
            ::ioctl(fd, BTRFS_IOC_TRANS_START);
            /* do a bunch of stuff */
            ::ioctl(fd, BTRFS_IOC_TRANS_END);
    or just
            ::close(fd);
    
    And to ensure it commits to disk,
    
            ::ioctl(fd, BTRFS_IOC_SYNC);
    
    When a transaction is held open, the trans_handle is attached to the
    struct file (via private_data) so that it will get cleaned up if the
    process dies unexpectedly.  A held transaction is also ended on fsync() to
    avoid a deadlock.
    
    A misbehaving application could also deliberately hold a transaction open,
    effectively locking up the FS, so it may make sense to restrict something
    like this to root or something.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ad4eacca7f59..1dcf4fb5b688 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1575,6 +1575,7 @@ struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
+long btrfs_ioctl_trans_end(struct file *file);
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
@@ -1595,6 +1596,8 @@ extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
 		       u64 start, u64 end, u64 inline_limit, u64 *hint_block);
+int btrfs_release_file(struct inode *inode, struct file *file);
+
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only);
@@ -1615,4 +1618,5 @@ int btrfs_delete_xattrs(struct btrfs_trans_handle *trans,
 u64 btrfs_parse_size(char *str);
 int btrfs_parse_options(char *options, struct btrfs_root *root,
 			char **subvol_name);
+int btrfs_sync_fs(struct super_block *sb, int wait);
 #endif

commit 3b96362cc8d314c935c335d5c3c42eb93c23166b
Author: Sven Wegener <sven.wegener@stealer.net>
Date:   Mon Jun 9 21:57:42 2008 -0400

    Btrfs: Invalidate dcache entry after creating snapshot and
    
    We need to invalidate an existing dcache entry after creating a new
    snapshot or subvolume, because a negative dache entry will stop us from
    accessing the new snapshot or subvolume.
    
    ---
      ctree.h       |   23 +++++++++++++++++++++++
      inode.c       |    4 ++++
      transaction.c |    4 ++++
      3 files changed, 31 insertions(+)
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7b73a9c3d868..ad4eacca7f59 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1544,6 +1544,9 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+void btrfs_invalidate_dcache_root(struct btrfs_root *root, char *name,
+				  int namelen);
+
 int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
 			 size_t size, struct bio *bio);
 

commit 0ef3e66b6700eb8f052daa8b89443ff872fbbdfc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat May 24 14:04:53 2008 -0400

    Btrfs: Allocator fix variety pack
    
    * Force chunk allocation when find_free_extent has to do a full scan
    * Record the max key at the start of defrag so it doesn't run forever
    * Block groups might not be contiguous, make a forward search for the
      next block group in extent-tree.c
    * Get rid of extra checks for total fs size
    * Fix relocate_one_reference to avoid relocating the same file data block
      twice when referenced by an older transaction
    * Use the open device count when allocating chunks so that we don't
      try to allocate from devices that don't exist
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 293464c0c6ba..7b73a9c3d868 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -464,6 +464,7 @@ struct btrfs_space_info {
 	u64 bytes_used;
 	u64 bytes_pinned;
 	int full;
+	int force_alloc;
 	struct list_head list;
 };
 
@@ -589,6 +590,7 @@ struct btrfs_root {
 	int ref_cows;
 	int track_dirty;
 	struct btrfs_key defrag_progress;
+	struct btrfs_key defrag_max;
 	int defrag_running;
 	int defrag_level;
 	char *name;

commit cb03c743c6486e4efb8be6bdf7bf23177826d156
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 15 16:15:45 2008 -0400

    Btrfs: Change the congestion functions to meter the number of async submits as well
    
    The async submit workqueue was absorbing too many requests, leading to long
    stalls where the async submitters were stalling.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a9377fb16c37..293464c0c6ba 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -522,6 +522,7 @@ struct btrfs_fs_info {
 	struct work_struct async_submit_work;
 	spinlock_t end_io_work_lock;
 	spinlock_t async_submit_work_lock;
+	atomic_t nr_async_submits;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	struct work_struct trans_work;

commit dfe25020689bb2d318782d2c9c7141203583fc70
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 13 13:46:40 2008 -0400

    Btrfs: Add mount -o degraded to allow mounts to continue with missing devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6c2c2c4e4d2a..a9377fb16c37 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -657,6 +657,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_NODATACOW		(1 << 1)
 #define BTRFS_MOUNT_NOBARRIER		(1 << 2)
 #define BTRFS_MOUNT_SSD			(1 << 3)
+#define BTRFS_MOUNT_DEGRADED		(1 << 4)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
@@ -1606,4 +1607,6 @@ int btrfs_delete_xattrs(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct inode *inode);
 /* super.c */
 u64 btrfs_parse_size(char *str);
+int btrfs_parse_options(char *options, struct btrfs_root *root,
+			char **subvol_name);
 #endif

commit a68d5933a0e409592860229b35230c8e87155472
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 8 14:11:56 2008 -0400

    Btrfs: Update nodatacow mode to support cloned single files and resizing
    
    Before, nodatacow only checked to make sure multiple roots didn't have
    references on a single extent.  This check makes sure that multiple
    inodes don't have references.
    
    nodatacow needed an extra check to see if the block group was currently
    readonly.  This way cows forced by the chunk relocation code are honored.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f4b4677bec77..6c2c2c4e4d2a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1325,7 +1325,7 @@ static inline struct dentry *fdentry(struct file *file) {
 /* extent-tree.c */
 u32 btrfs_count_snapshots_in_path(struct btrfs_root *root,
 				  struct btrfs_path *count_path,
-				  u64 first_extent);
+				  u64 expected_owner, u64 first_extent);
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);

commit bf4ef67924d87b0addb32f084e83a9283496350e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 8 13:26:18 2008 -0400

    Btrfs: Properly find the root for snapshotted blocks during chunk relocation
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 33ab165591c5..f4b4677bec77 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1459,6 +1459,8 @@ int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
+int btrfs_search_root(struct btrfs_root *root, u64 search_start,
+		      u64 *found_objectid);
 int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid,
 			  struct btrfs_root *latest_root);
 /* dir-item.c */

commit a061fc8da7b990faa41ca503e66faef3ecdeead0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed May 7 11:43:44 2008 -0400

    Btrfs: Add support for online device removal
    
    This required a few structural changes to the code that manages bdev pointers:
    
    The VFS super block now gets an anon-bdev instead of a pointer to the
    lowest bdev.  This allows us to avoid swapping the super block bdev pointer
    around at run time.
    
    The code to read in the super block no longer goes through the extent
    buffer interface.  Things got ugly keeping the mapping constant.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3b6f8524a4ad..33ab165591c5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -505,7 +505,7 @@ struct btrfs_fs_info {
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block super_copy;
-	struct extent_buffer *sb_buffer;
+	struct btrfs_super_block super_for_commit;
 	struct block_device *__bdev;
 	struct super_block *sb;
 	struct inode *btree_inode;
@@ -1208,6 +1208,7 @@ BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, byte_limit, 64);
 
 /* struct btrfs_super_block */
 BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);
+BTRFS_SETGET_STACK_FUNCS(super_flags, struct btrfs_super_block, flags, 64);
 BTRFS_SETGET_STACK_FUNCS(super_generation, struct btrfs_super_block,
 			 generation, 64);
 BTRFS_SETGET_STACK_FUNCS(super_root, struct btrfs_super_block, root, 64);

commit f2eb0a241f0e5c135d93243b0236cb1f14c305e0
Author: Sage Weil <sage@newdream.net>
Date:   Fri May 2 14:43:14 2008 -0400

    Btrfs: Clone file data ioctl
    
    Add a new ioctl to clone file data
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 73b92dd150ff..3b6f8524a4ad 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1516,9 +1516,9 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 /* file-item.c */
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
-			       u64 objectid, u64 pos, u64 offset,
+			       u64 objectid, u64 pos, u64 disk_offset,
 			       u64 disk_num_bytes,
-			       u64 num_bytes);
+			     u64 num_bytes, u64 offset);
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,

commit ec44a35cbeb26ab2da84cb280d778260f2312feb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 28 15:29:52 2008 -0400

    Btrfs: Add balance ioctl to restripe the chunks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b9257b37bb96..73b92dd150ff 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1364,7 +1364,7 @@ int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       u64 root_objectid, u64 ref_generation,
 		       u64 owner, u64 owner_offset,
 		       u64 empty_size, u64 hint_byte,
-		       u64 search_end, struct btrfs_key *ins, int data);
+		       u64 search_end, struct btrfs_key *ins, u64 data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root

commit 788f20eb5affef584e75ea84bb80a4c3352a2c0e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 28 15:29:42 2008 -0400

    Btrfs: Add new ioctl to add devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ac7106ec5357..b9257b37bb96 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -551,6 +551,8 @@ struct btrfs_fs_info {
 	u64 data_alloc_profile;
 	u64 metadata_alloc_profile;
 	u64 system_alloc_profile;
+
+	void *bdev_holder;
 };
 
 /*

commit 8f18cf13396caae5a3d7ae91201cfb15181a9642
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 25 16:53:30 2008 -0400

    Btrfs: Make the resizer work based on shrinking and growing devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f00c4be59ad6..ac7106ec5357 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -474,6 +474,7 @@ struct btrfs_block_group_cache {
 	u64 pinned;
 	u64 flags;
 	int cached;
+	int ro;
 };
 
 struct btrfs_device;

commit 7ae9c09d8f001eb19ee2ba219dc5c3d4f6d60614
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 18 10:29:49 2008 -0400

    Btrfs: Add support for labels in the super block
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d119d95d139a..f00c4be59ad6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -247,6 +247,7 @@ struct btrfs_header {
  * room to translate 14 chunks with 3 stripes each.
  */
 #define BTRFS_SYSTEM_CHUNK_ARRAY_SIZE 2048
+#define BTRFS_LABEL_SIZE 256
 
 /*
  * the super block basically lists the main trees of the FS
@@ -276,6 +277,7 @@ struct btrfs_super_block {
 	u8 root_level;
 	u8 chunk_root_level;
 	struct btrfs_dev_item dev_item;
+	char label[BTRFS_LABEL_SIZE];
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 } __attribute__ ((__packed__));
 

commit a443755f1ca3e190e12e3a845ddecb3ee1782512
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 18 10:29:38 2008 -0400

    Btrfs: Check device uuids along with devids
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b56ae1950658..d119d95d139a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -800,6 +800,11 @@ static inline struct btrfs_stripe *btrfs_stripe_nr(struct btrfs_chunk *c,
 	return (struct btrfs_stripe *)offset;
 }
 
+static inline char *btrfs_stripe_dev_uuid_nr(struct btrfs_chunk *c, int nr)
+{
+	return btrfs_stripe_dev_uuid(btrfs_stripe_nr(c, nr));
+}
+
 static inline u64 btrfs_stripe_offset_nr(struct extent_buffer *eb,
 					 struct btrfs_chunk *c, int nr)
 {

commit e015640f9c4fa2417dcc3bbbb3b2b61ad4059ab0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 16 11:15:20 2008 -0400

    Btrfs: Write bio checksumming outside the FS mutex
    
    This significantly improves streaming write performance by allowing
    concurrency in the data checksumming.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ff15b8513f90..b56ae1950658 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1515,7 +1515,9 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     u64 bytenr, int mod);
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct inode *inode,
-			   struct bio *bio);
+			   struct bio *bio, char *sums);
+int btrfs_csum_one_bio(struct btrfs_root *root,
+		       struct bio *bio, char **sums_ret);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,

commit 44b8bd7edda4f63de180d0f7325c9fb704b3806b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 16 11:14:51 2008 -0400

    Btrfs: Create a work queue for bio writes
    
    This allows checksumming to happen in parallel among many cpus, and
    keeps us from bogging down pdflush with the checksumming code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a22edcf49174..ff15b8513f90 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -514,8 +514,11 @@ struct btrfs_fs_info {
 	struct list_head hashers;
 	struct list_head dead_roots;
 	struct list_head end_io_work_list;
+	struct list_head async_submit_work_list;
 	struct work_struct end_io_work;
+	struct work_struct async_submit_work;
 	spinlock_t end_io_work_lock;
+	spinlock_t async_submit_work_lock;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	struct work_struct trans_work;

commit 321aecc65671ae8136bd2ca6879b56f0221f8ac8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 16 10:49:51 2008 -0400

    Btrfs: Add RAID10 support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 82d67c3db8bc..a22edcf49174 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -197,6 +197,9 @@ struct btrfs_chunk {
 	 * item in the btree
 	 */
 	__le16 num_stripes;
+
+	/* sub stripes only matter for raid10 */
+	__le16 sub_stripes;
 	struct btrfs_stripe stripe;
 	/* additional stripes go here */
 } __attribute__ ((__packed__));
@@ -444,6 +447,7 @@ struct btrfs_csum_item {
 #define BTRFS_BLOCK_GROUP_RAID0    (1 << 3)
 #define BTRFS_BLOCK_GROUP_RAID1    (1 << 4)
 #define BTRFS_BLOCK_GROUP_DUP	   (1 << 5)
+#define BTRFS_BLOCK_GROUP_RAID10   (1 << 6)
 
 
 struct btrfs_block_group_item {
@@ -757,6 +761,7 @@ BTRFS_SETGET_FUNCS(chunk_io_width, struct btrfs_chunk, io_width, 32);
 BTRFS_SETGET_FUNCS(chunk_sector_size, struct btrfs_chunk, sector_size, 32);
 BTRFS_SETGET_FUNCS(chunk_type, struct btrfs_chunk, type, 64);
 BTRFS_SETGET_FUNCS(chunk_num_stripes, struct btrfs_chunk, num_stripes, 16);
+BTRFS_SETGET_FUNCS(chunk_sub_stripes, struct btrfs_chunk, sub_stripes, 16);
 BTRFS_SETGET_FUNCS(stripe_devid, struct btrfs_stripe, devid, 64);
 BTRFS_SETGET_FUNCS(stripe_offset, struct btrfs_stripe, offset, 64);
 
@@ -778,6 +783,8 @@ BTRFS_SETGET_STACK_FUNCS(stack_chunk_sector_size, struct btrfs_chunk,
 BTRFS_SETGET_STACK_FUNCS(stack_chunk_type, struct btrfs_chunk, type, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_chunk_num_stripes, struct btrfs_chunk,
 			 num_stripes, 16);
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_sub_stripes, struct btrfs_chunk,
+			 sub_stripes, 16);
 BTRFS_SETGET_STACK_FUNCS(stack_stripe_devid, struct btrfs_stripe, devid, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_stripe_offset, struct btrfs_stripe, offset, 64);
 

commit e17cade25ff8074101d653557a78df09c16ca276
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 15 15:41:47 2008 -0400

    Btrfs: Add chunk uuids and update multi-device back references
    
    Block headers now store the chunk tree uuid
    
    Chunk items records the device uuid for each stripes
    
    Device extent items record better back refs to the chunk tree
    
    Block groups record better back refs to the chunk tree
    
    The chunk tree format has also changed.  The objectid of BTRFS_CHUNK_ITEM_KEY
    used to be the logical offset of the chunk.  Now it is a chunk tree id,
    with the logical offset being stored in the offset field of the key.
    
    This allows a single chunk tree to record multiple logical address spaces,
    upping the number of bytes indexed by a chunk tree from 2^64 to
    2^128.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 09d614fcafb1..82d67c3db8bc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -70,6 +70,7 @@ extern struct kmem_cache *btrfs_path_cachep;
  * All files have objectids higher than this.
  */
 #define BTRFS_FIRST_FREE_OBJECTID 256ULL
+#define BTRFS_FIRST_CHUNK_TREE_OBJECTID 256ULL
 
 
 /*
@@ -131,7 +132,7 @@ struct btrfs_mapping_tree {
 	struct extent_map_tree map_tree;
 };
 
-#define BTRFS_DEV_UUID_SIZE 16
+#define BTRFS_UUID_SIZE 16
 struct btrfs_dev_item {
 	/* the internal btrfs device id */
 	__le64 devid;
@@ -154,17 +155,32 @@ struct btrfs_dev_item {
 	/* type and info about this device */
 	__le64 type;
 
+	/* grouping information for allocation decisions */
+	__le32 dev_group;
+
+	/* seek speed 0-100 where 100 is fastest */
+	u8 seek_speed;
+
+	/* bandwidth 0-100 where 100 is fastest */
+	u8 bandwidth;
+
 	/* btrfs generated uuid for this device */
-	u8 uuid[BTRFS_DEV_UUID_SIZE];
+	u8 uuid[BTRFS_UUID_SIZE];
 } __attribute__ ((__packed__));
 
 struct btrfs_stripe {
 	__le64 devid;
 	__le64 offset;
+	u8 dev_uuid[BTRFS_UUID_SIZE];
 } __attribute__ ((__packed__));
 
 struct btrfs_chunk {
+	/* size of this chunk in bytes */
+	__le64 length;
+
+	/* objectid of the root referencing this chunk */
 	__le64 owner;
+
 	__le64 stripe_len;
 	__le64 type;
 
@@ -199,10 +215,14 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
  * every tree block (leaf or node) starts with this header.
  */
 struct btrfs_header {
+	/* these first four must match the super block */
 	u8 csum[BTRFS_CSUM_SIZE];
 	u8 fsid[BTRFS_FSID_SIZE]; /* FS specific uuid */
 	__le64 bytenr; /* which block this node is supposed to live in */
 	__le64 flags;
+
+	/* allowed to be different from the super from here on down */
+	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
 	__le64 generation;
 	__le64 owner;
 	__le32 nritems;
@@ -235,6 +255,8 @@ struct btrfs_super_block {
 	u8 fsid[16];    /* FS specific uuid */
 	__le64 bytenr; /* this block number */
 	__le64 flags;
+
+	/* allowed to be different from the btrfs_header from here own down */
 	__le64 magic;
 	__le64 generation;
 	__le64 root;
@@ -323,14 +345,16 @@ struct btrfs_extent_ref {
 
 /* dev extents record free space on individual devices.  The owner
  * field points back to the chunk allocation mapping tree that allocated
- * the extent
+ * the extent.  The chunk tree uuid field is a way to double check the owner
  */
 struct btrfs_dev_extent {
-	__le64 owner;
+	__le64 chunk_tree;
+	__le64 chunk_objectid;
+	__le64 chunk_offset;
 	__le64 length;
+	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
 } __attribute__ ((__packed__));
 
-
 struct btrfs_inode_ref {
 	__le16 name_len;
 	/* name goes here */
@@ -424,7 +448,6 @@ struct btrfs_csum_item {
 
 struct btrfs_block_group_item {
 	__le64 used;
-	__le64 chunk_tree;
 	__le64 chunk_objectid;
 	__le64 flags;
 } __attribute__ ((__packed__));
@@ -451,6 +474,7 @@ struct btrfs_device;
 struct btrfs_fs_devices;
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
+	u8 chunk_tree_uuid[BTRFS_UUID_SIZE];
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct btrfs_root *chunk_root;
@@ -697,6 +721,9 @@ BTRFS_SETGET_FUNCS(device_io_align, struct btrfs_dev_item, io_align, 32);
 BTRFS_SETGET_FUNCS(device_io_width, struct btrfs_dev_item, io_width, 32);
 BTRFS_SETGET_FUNCS(device_sector_size, struct btrfs_dev_item, sector_size, 32);
 BTRFS_SETGET_FUNCS(device_id, struct btrfs_dev_item, devid, 64);
+BTRFS_SETGET_FUNCS(device_group, struct btrfs_dev_item, dev_group, 32);
+BTRFS_SETGET_FUNCS(device_seek_speed, struct btrfs_dev_item, seek_speed, 8);
+BTRFS_SETGET_FUNCS(device_bandwidth, struct btrfs_dev_item, bandwidth, 8);
 
 BTRFS_SETGET_STACK_FUNCS(stack_device_type, struct btrfs_dev_item, type, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_device_total_bytes, struct btrfs_dev_item,
@@ -710,12 +737,19 @@ BTRFS_SETGET_STACK_FUNCS(stack_device_io_width, struct btrfs_dev_item,
 BTRFS_SETGET_STACK_FUNCS(stack_device_sector_size, struct btrfs_dev_item,
 			 sector_size, 32);
 BTRFS_SETGET_STACK_FUNCS(stack_device_id, struct btrfs_dev_item, devid, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_device_group, struct btrfs_dev_item,
+			 dev_group, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_device_seek_speed, struct btrfs_dev_item,
+			 seek_speed, 8);
+BTRFS_SETGET_STACK_FUNCS(stack_device_bandwidth, struct btrfs_dev_item,
+			 bandwidth, 8);
 
 static inline char *btrfs_device_uuid(struct btrfs_dev_item *d)
 {
 	return (char *)d + offsetof(struct btrfs_dev_item, uuid);
 }
 
+BTRFS_SETGET_FUNCS(chunk_length, struct btrfs_chunk, length, 64);
 BTRFS_SETGET_FUNCS(chunk_owner, struct btrfs_chunk, owner, 64);
 BTRFS_SETGET_FUNCS(chunk_stripe_len, struct btrfs_chunk, stripe_len, 64);
 BTRFS_SETGET_FUNCS(chunk_io_align, struct btrfs_chunk, io_align, 32);
@@ -726,6 +760,12 @@ BTRFS_SETGET_FUNCS(chunk_num_stripes, struct btrfs_chunk, num_stripes, 16);
 BTRFS_SETGET_FUNCS(stripe_devid, struct btrfs_stripe, devid, 64);
 BTRFS_SETGET_FUNCS(stripe_offset, struct btrfs_stripe, offset, 64);
 
+static inline char *btrfs_stripe_dev_uuid(struct btrfs_stripe *s)
+{
+	return (char *)s + offsetof(struct btrfs_stripe, dev_uuid);
+}
+
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_length, struct btrfs_chunk, length, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_chunk_owner, struct btrfs_chunk, owner, 64);
 BTRFS_SETGET_STACK_FUNCS(stack_chunk_stripe_len, struct btrfs_chunk,
 			 stripe_len, 64);
@@ -781,13 +821,10 @@ BTRFS_SETGET_STACK_FUNCS(block_group_used, struct btrfs_block_group_item,
 			 used, 64);
 BTRFS_SETGET_FUNCS(disk_block_group_used, struct btrfs_block_group_item,
 			 used, 64);
-BTRFS_SETGET_STACK_FUNCS(block_group_chunk_tree, struct btrfs_block_group_item,
-			 chunk_tree, 64);
-BTRFS_SETGET_FUNCS(disk_block_group_chunk_tree, struct btrfs_block_group_item,
-			 chunk_tree, 64);
 BTRFS_SETGET_STACK_FUNCS(block_group_chunk_objectid,
 			struct btrfs_block_group_item, chunk_objectid, 64);
-BTRFS_SETGET_FUNCS(disk_block_group_chunk_objecitd,
+
+BTRFS_SETGET_FUNCS(disk_block_group_chunk_objectid,
 		   struct btrfs_block_group_item, chunk_objectid, 64);
 BTRFS_SETGET_FUNCS(disk_block_group_flags,
 		   struct btrfs_block_group_item, flags, 64);
@@ -850,9 +887,20 @@ BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_timespec, nsec, 32);
 BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
 
 /* struct btrfs_dev_extent */
-BTRFS_SETGET_FUNCS(dev_extent_owner, struct btrfs_dev_extent, owner, 64);
+BTRFS_SETGET_FUNCS(dev_extent_chunk_tree, struct btrfs_dev_extent,
+		   chunk_tree, 64);
+BTRFS_SETGET_FUNCS(dev_extent_chunk_objectid, struct btrfs_dev_extent,
+		   chunk_objectid, 64);
+BTRFS_SETGET_FUNCS(dev_extent_chunk_offset, struct btrfs_dev_extent,
+		   chunk_offset, 64);
 BTRFS_SETGET_FUNCS(dev_extent_length, struct btrfs_dev_extent, length, 64);
 
+static inline u8 *btrfs_dev_extent_chunk_tree_uuid(struct btrfs_dev_extent *dev)
+{
+	unsigned long ptr = offsetof(struct btrfs_dev_extent, chunk_tree_uuid);
+	return (u8 *)((unsigned long)dev + ptr);
+}
+
 /* struct btrfs_extent_ref */
 BTRFS_SETGET_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
 BTRFS_SETGET_FUNCS(ref_generation, struct btrfs_extent_ref, generation, 64);
@@ -1087,6 +1135,12 @@ static inline u8 *btrfs_header_fsid(struct extent_buffer *eb)
 	return (u8 *)ptr;
 }
 
+static inline u8 *btrfs_header_chunk_tree_uuid(struct extent_buffer *eb)
+{
+	unsigned long ptr = offsetof(struct btrfs_header, chunk_tree_uuid);
+	return (u8 *)ptr;
+}
+
 static inline u8 *btrfs_super_fsid(struct extent_buffer *eb)
 {
 	unsigned long ptr = offsetof(struct btrfs_super_block, fsid);
@@ -1311,7 +1365,7 @@ int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_root *root);
 int btrfs_make_block_group(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, u64 bytes_used,
-			   u64 type, u64 chunk_tree, u64 chunk_objectid,
+			   u64 type, u64 chunk_objectid, u64 chunk_offset,
 			   u64 size);
 /* ctree.c */
 int btrfs_previous_item(struct btrfs_root *root,

commit 98d20f67cf99ccda638dbcdf7b3a9ee0a428d932
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 14 09:46:10 2008 -0400

    Add a min size parameter to btrfs_alloc_extent
    
    On huge machines, delayed allocation may try to allocate massive extents.
    This change allows btrfs_alloc_extent to return something smaller than
    the caller asked for, and the data allocation routines will loop over
    the allocations until it fills the whole delayed alloc.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e803c4daad21..09d614fcafb1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1286,7 +1286,8 @@ int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
 				 u64 owner, u64 owner_offset);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root,
-		       u64 num_bytes, u64 root_objectid, u64 ref_generation,
+		       u64 num_bytes, u64 min_bytes,
+		       u64 root_objectid, u64 ref_generation,
 		       u64 owner, u64 owner_offset,
 		       u64 empty_size, u64 hint_byte,
 		       u64 search_end, struct btrfs_key *ins, int data);

commit ce9adaa5a792c2099a83246265eb4055bc38b6b8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Do metadata checksums for reads via a workqueue
    
    Before, metadata checksumming was done by the callers of read_tree_block,
    which would set EXTENT_CSUM bits in the extent tree to show that a given
    range of pages was already checksummed and didn't need to be verified
    again.
    
    But, those bits could go away via try_to_releasepage, and the end
    result was bogus checksum failures on pages that never left the cache.
    
    The new code validates checksums when the page is read.  It is a little
    tricky because metadata blocks can span pages and a single read may
    end up going via multiple bios.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4b3b20459f6e..e803c4daad21 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -485,6 +485,10 @@ struct btrfs_fs_info {
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
+	struct list_head end_io_work_list;
+	struct work_struct end_io_work;
+	spinlock_t end_io_work_lock;
+
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	struct work_struct trans_work;
 #else

commit d18a2c447524751137a12cc8ccaf9d1e0b7fa1b3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 4 15:40:00 2008 -0400

    Btrfs: Fix allocation profile init
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 72deae63ec28..4b3b20459f6e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -506,12 +506,13 @@ struct btrfs_fs_info {
 	u64 delalloc_bytes;
 	u64 last_alloc;
 	u64 last_data_alloc;
-	int avail_data_alloc_bits;
-	int avail_metadata_alloc_bits;
-	int avail_system_alloc_bits;
-	int data_alloc_profile;
-	int metadata_alloc_profile;
-	int system_alloc_profile;
+
+	u64 avail_data_alloc_bits;
+	u64 avail_metadata_alloc_bits;
+	u64 avail_system_alloc_bits;
+	u64 data_alloc_profile;
+	u64 metadata_alloc_profile;
+	u64 system_alloc_profile;
 };
 
 /*

commit 611f0e00a27fe0e5a571194a12443ecdc99a43ef
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 3 16:29:03 2008 -0400

    Btrfs: Add support for duplicate blocks on a single spindle
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0a207861472e..72deae63ec28 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -419,6 +419,7 @@ struct btrfs_csum_item {
 #define BTRFS_BLOCK_GROUP_METADATA (1 << 2)
 #define BTRFS_BLOCK_GROUP_RAID0    (1 << 3)
 #define BTRFS_BLOCK_GROUP_RAID1    (1 << 4)
+#define BTRFS_BLOCK_GROUP_DUP	   (1 << 5)
 
 
 struct btrfs_block_group_item {

commit 8790d502e4401a4a3a4175b83a3a47e8d595c771
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 3 16:29:03 2008 -0400

    Btrfs: Add support for mirroring across drives
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 67d533cf8f47..0a207861472e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -418,6 +418,7 @@ struct btrfs_csum_item {
 #define BTRFS_BLOCK_GROUP_SYSTEM   (1 << 1)
 #define BTRFS_BLOCK_GROUP_METADATA (1 << 2)
 #define BTRFS_BLOCK_GROUP_RAID0    (1 << 3)
+#define BTRFS_BLOCK_GROUP_RAID1    (1 << 4)
 
 
 struct btrfs_block_group_item {
@@ -504,8 +505,12 @@ struct btrfs_fs_info {
 	u64 delalloc_bytes;
 	u64 last_alloc;
 	u64 last_data_alloc;
-	int extra_data_alloc_bits;
-	int extra_alloc_bits;
+	int avail_data_alloc_bits;
+	int avail_metadata_alloc_bits;
+	int avail_system_alloc_bits;
+	int data_alloc_profile;
+	int metadata_alloc_profile;
+	int system_alloc_profile;
 };
 
 /*

commit 63b10fc4874a014e22bc4c64e3d92b71180661fe
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 1 11:21:32 2008 -0400

    Reorder the flags field in struct btrfs_header and record a flag on writeout
    
    This allows detection of blocks that have already been written in the
    running transaction so they can be recowed instead of modified again.
    It is step one in trusting the transid field of the block pointers.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fec96ba7c23b..67d533cf8f47 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -193,6 +193,8 @@ static inline unsigned long btrfs_chunk_item_size(int num_stripes)
 }
 
 #define BTRFS_FSID_SIZE 16
+#define BTRFS_HEADER_FLAG_WRITTEN (1 << 0)
+
 /*
  * every tree block (leaf or node) starts with this header.
  */
@@ -200,10 +202,10 @@ struct btrfs_header {
 	u8 csum[BTRFS_CSUM_SIZE];
 	u8 fsid[BTRFS_FSID_SIZE]; /* FS specific uuid */
 	__le64 bytenr; /* which block this node is supposed to live in */
+	__le64 flags;
 	__le64 generation;
 	__le64 owner;
 	__le32 nritems;
-	__le16 flags;
 	u8 level;
 } __attribute__ ((__packed__));
 
@@ -229,9 +231,10 @@ struct btrfs_header {
  */
 struct btrfs_super_block {
 	u8 csum[BTRFS_CSUM_SIZE];
-	/* the first 3 fields must match struct btrfs_header */
+	/* the first 4 fields must match struct btrfs_header */
 	u8 fsid[16];    /* FS specific uuid */
 	__le64 bytenr; /* this block number */
+	__le64 flags;
 	__le64 magic;
 	__le64 generation;
 	__le64 root;
@@ -1045,9 +1048,28 @@ BTRFS_SETGET_HEADER_FUNCS(header_generation, struct btrfs_header,
 			  generation, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_owner, struct btrfs_header, owner, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_nritems, struct btrfs_header, nritems, 32);
-BTRFS_SETGET_HEADER_FUNCS(header_flags, struct btrfs_header, flags, 16);
+BTRFS_SETGET_HEADER_FUNCS(header_flags, struct btrfs_header, flags, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_level, struct btrfs_header, level, 8);
 
+static inline int btrfs_header_flag(struct extent_buffer *eb, u64 flag)
+{
+	return (btrfs_header_flags(eb) & flag) == flag;
+}
+
+static inline int btrfs_set_header_flag(struct extent_buffer *eb, u64 flag)
+{
+	u64 flags = btrfs_header_flags(eb);
+	btrfs_set_header_flags(eb, flags | flag);
+	return (flags & flag) == flag;
+}
+
+static inline int btrfs_clear_header_flag(struct extent_buffer *eb, u64 flag)
+{
+	u64 flags = btrfs_header_flags(eb);
+	btrfs_set_header_flags(eb, flags & ~flag);
+	return (flags & flag) == flag;
+}
+
 static inline u8 *btrfs_header_fsid(struct extent_buffer *eb)
 {
 	unsigned long ptr = offsetof(struct btrfs_header, fsid);

commit 04160088141a6be06d5cb9e53e34076b51803ffc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 26 10:28:07 2008 -0400

    Create a btrfs backing dev info
    
    This allows intelligent versions of unplug and congestion functions
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f43dfe7ffe6d..fec96ba7c23b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -25,6 +25,7 @@
 #include <linux/fs.h>
 #include <linux/workqueue.h>
 #include <linux/completion.h>
+#include <linux/backing-dev.h>
 #include <asm/kmap_types.h>
 #include "bit-radix.h"
 #include "extent_io.h"
@@ -472,6 +473,7 @@ struct btrfs_fs_info {
 	struct block_device *__bdev;
 	struct super_block *sb;
 	struct inode *btree_inode;
+	struct backing_dev_info bdi;
 	spinlock_t hash_lock;
 	struct mutex trans_mutex;
 	struct mutex fs_mutex;

commit 593060d756e0c2382d59cf00d5f3b9e3a336c408
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 25 16:50:33 2008 -0400

    Btrfs: Implement raid0 when multiple devices are present
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7556f8319c60..f43dfe7ffe6d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -413,6 +413,7 @@ struct btrfs_csum_item {
 #define BTRFS_BLOCK_GROUP_DATA     (1 << 0)
 #define BTRFS_BLOCK_GROUP_SYSTEM   (1 << 1)
 #define BTRFS_BLOCK_GROUP_METADATA (1 << 2)
+#define BTRFS_BLOCK_GROUP_RAID0    (1 << 3)
 
 
 struct btrfs_block_group_item {
@@ -498,6 +499,8 @@ struct btrfs_fs_info {
 	u64 delalloc_bytes;
 	u64 last_alloc;
 	u64 last_data_alloc;
+	int extra_data_alloc_bits;
+	int extra_alloc_bits;
 };
 
 /*

commit 8a4b83cc8bd75fca29ac68615896d9e92820e7c2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Add support for device scanning and detection ioctls
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index acf22ad6115c..7556f8319c60 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -37,7 +37,7 @@ extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 
-#define BTRFS_MAGIC "_B4RfS_M"
+#define BTRFS_MAGIC "_B5RfS_M"
 
 #define BTRFS_MAX_LEVEL 8
 
@@ -238,6 +238,7 @@ struct btrfs_super_block {
 	__le64 total_bytes;
 	__le64 bytes_used;
 	__le64 root_dir_objectid;
+	__le64 num_devices;
 	__le32 sectorsize;
 	__le32 nodesize;
 	__le32 leafsize;
@@ -440,6 +441,7 @@ struct btrfs_block_group_cache {
 };
 
 struct btrfs_device;
+struct btrfs_fs_devices;
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
 	struct btrfs_root *extent_root;
@@ -489,7 +491,7 @@ struct btrfs_fs_info {
 	u64 total_pinned;
 	struct list_head dirty_cowonly_roots;
 
-	struct list_head devices;
+	struct btrfs_fs_devices *fs_devices;
 	struct list_head space_info;
 	spinlock_t delalloc_lock;
 	spinlock_t new_trans_lock;
@@ -677,6 +679,19 @@ BTRFS_SETGET_FUNCS(device_io_width, struct btrfs_dev_item, io_width, 32);
 BTRFS_SETGET_FUNCS(device_sector_size, struct btrfs_dev_item, sector_size, 32);
 BTRFS_SETGET_FUNCS(device_id, struct btrfs_dev_item, devid, 64);
 
+BTRFS_SETGET_STACK_FUNCS(stack_device_type, struct btrfs_dev_item, type, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_device_total_bytes, struct btrfs_dev_item,
+			 total_bytes, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_device_bytes_used, struct btrfs_dev_item,
+			 bytes_used, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_device_io_align, struct btrfs_dev_item,
+			 io_align, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_device_io_width, struct btrfs_dev_item,
+			 io_width, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_device_sector_size, struct btrfs_dev_item,
+			 sector_size, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_device_id, struct btrfs_dev_item, devid, 64);
+
 static inline char *btrfs_device_uuid(struct btrfs_dev_item *d)
 {
 	return (char *)d + offsetof(struct btrfs_dev_item, uuid);
@@ -1106,6 +1121,8 @@ BTRFS_SETGET_STACK_FUNCS(super_stripesize, struct btrfs_super_block,
 			 stripesize, 32);
 BTRFS_SETGET_STACK_FUNCS(super_root_dir, struct btrfs_super_block,
 			 root_dir_objectid, 64);
+BTRFS_SETGET_STACK_FUNCS(super_num_devices, struct btrfs_super_block,
+			 num_devices, 64);
 
 static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 {

commit 239b14b32dc39232ebf9cce29ff77c4c564355fd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Bring back mount -o ssd optimizations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 96a493217860..acf22ad6115c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1405,6 +1405,9 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+int btrfs_merge_bio_hook(struct page *page, unsigned long offset,
+			 size_t size, struct bio *bio);
+
 static inline void dec_i_blocks(struct inode *inode, u64 dec)
 {
 	dec = dec >> 9;

commit 0d81ba5dbedef0c3970d6aa318aa84920943e6e3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Move device information into the super block so it can be scanned
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 285fb7e46106..96a493217860 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -150,21 +150,11 @@ struct btrfs_dev_item {
 	/* minimal io size for this device */
 	__le32 sector_size;
 
-	/* the kernel device number */
-	__le64 rdev;
-
 	/* type and info about this device */
 	__le64 type;
 
-	/* partition number, 0 for whole dev */
-	__le32 partition;
-
-	/* length of the name data at the end of the item */
-	__le16 name_len;
-
-	/* physical drive uuid (or lvm uuid) */
+	/* btrfs generated uuid for this device */
 	u8 uuid[BTRFS_DEV_UUID_SIZE];
-	/* name goes here */
 } __attribute__ ((__packed__));
 
 struct btrfs_stripe {
@@ -255,6 +245,7 @@ struct btrfs_super_block {
 	__le32 sys_chunk_array_size;
 	u8 root_level;
 	u8 chunk_root_level;
+	struct btrfs_dev_item dev_item;
 	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 } __attribute__ ((__packed__));
 
@@ -685,20 +676,12 @@ BTRFS_SETGET_FUNCS(device_io_align, struct btrfs_dev_item, io_align, 32);
 BTRFS_SETGET_FUNCS(device_io_width, struct btrfs_dev_item, io_width, 32);
 BTRFS_SETGET_FUNCS(device_sector_size, struct btrfs_dev_item, sector_size, 32);
 BTRFS_SETGET_FUNCS(device_id, struct btrfs_dev_item, devid, 64);
-BTRFS_SETGET_FUNCS(device_rdev, struct btrfs_dev_item, rdev, 64);
-BTRFS_SETGET_FUNCS(device_partition, struct btrfs_dev_item, partition, 32);
-BTRFS_SETGET_FUNCS(device_name_len, struct btrfs_dev_item, name_len, 16);
 
 static inline char *btrfs_device_uuid(struct btrfs_dev_item *d)
 {
 	return (char *)d + offsetof(struct btrfs_dev_item, uuid);
 }
 
-static inline char *btrfs_device_name(struct btrfs_dev_item *d)
-{
-	return (char *)(d + 1);
-}
-
 BTRFS_SETGET_FUNCS(chunk_owner, struct btrfs_chunk, owner, 64);
 BTRFS_SETGET_FUNCS(chunk_stripe_len, struct btrfs_chunk, stripe_len, 64);
 BTRFS_SETGET_FUNCS(chunk_io_align, struct btrfs_chunk, io_align, 32);

commit e085def2c4cc2d7c0c316376b4b66b86b10e3a4b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Make the FS tree the last objectid in the tree of tree roots
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a877105f5c47..285fb7e46106 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -47,24 +47,23 @@ extern struct kmem_cache *btrfs_path_cachep;
 /* stores information about which extents are in use, and reference counts */
 #define BTRFS_EXTENT_TREE_OBJECTID 2ULL
 
-/* one per subvolume, storing files and directories */
-#define BTRFS_FS_TREE_OBJECTID 3ULL
-
-/* directory objectid inside the root tree */
-#define BTRFS_ROOT_TREE_DIR_OBJECTID 4ULL
-
-
 /*
  * chunk tree stores translations from logical -> physical block numbering
  * the super block points to the chunk tree
  */
-#define BTRFS_CHUNK_TREE_OBJECTID 5ULL
+#define BTRFS_CHUNK_TREE_OBJECTID 3ULL
 
 /*
  * stores information about which areas of a given device are in use.
  * one per device.  The tree of tree roots points to the device tree
  */
-#define BTRFS_DEV_TREE_OBJECTID 6ULL
+#define BTRFS_DEV_TREE_OBJECTID 4ULL
+
+/* one per subvolume, storing files and directories */
+#define BTRFS_FS_TREE_OBJECTID 5ULL
+
+/* directory objectid inside the root tree */
+#define BTRFS_ROOT_TREE_DIR_OBJECTID 6ULL
 
 /*
  * All files have objectids higher than this.

commit 6324fbf334f4586325057197da7752f4ffa409d3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:01:59 2008 -0400

    Btrfs: Dynamic chunk and block group allocation
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1453d995fef6..a877105f5c47 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -431,9 +431,19 @@ struct btrfs_block_group_item {
 	__le64 flags;
 } __attribute__ ((__packed__));
 
+struct btrfs_space_info {
+	u64 flags;
+	u64 total_bytes;
+	u64 bytes_used;
+	u64 bytes_pinned;
+	int full;
+	struct list_head list;
+};
+
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
+	struct btrfs_space_info *space_info;
 	u64 pinned;
 	u64 flags;
 	int cached;
@@ -490,7 +500,7 @@ struct btrfs_fs_info {
 	struct list_head dirty_cowonly_roots;
 
 	struct list_head devices;
-	struct list_head *last_device;
+	struct list_head space_info;
 	spinlock_t delalloc_lock;
 	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;

commit 0b86a832a1f38abec695864ec2eaedc9d2383f1b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:01:56 2008 -0400

    Btrfs: Add support for multiple devices per filesystem
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 92d892f92075..1453d995fef6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -40,12 +40,44 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_MAGIC "_B4RfS_M"
 
 #define BTRFS_MAX_LEVEL 8
+
+/* holds pointers to all of the tree roots */
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
+
+/* stores information about which extents are in use, and reference counts */
 #define BTRFS_EXTENT_TREE_OBJECTID 2ULL
+
+/* one per subvolume, storing files and directories */
 #define BTRFS_FS_TREE_OBJECTID 3ULL
+
+/* directory objectid inside the root tree */
 #define BTRFS_ROOT_TREE_DIR_OBJECTID 4ULL
+
+
+/*
+ * chunk tree stores translations from logical -> physical block numbering
+ * the super block points to the chunk tree
+ */
+#define BTRFS_CHUNK_TREE_OBJECTID 5ULL
+
+/*
+ * stores information about which areas of a given device are in use.
+ * one per device.  The tree of tree roots points to the device tree
+ */
+#define BTRFS_DEV_TREE_OBJECTID 6ULL
+
+/*
+ * All files have objectids higher than this.
+ */
 #define BTRFS_FIRST_FREE_OBJECTID 256ULL
 
+
+/*
+ * the device items go into the chunk tree.  The key is in the form
+ * [ 1 BTRFS_DEV_ITEM_KEY device_id ]
+ */
+#define BTRFS_DEV_ITEMS_OBJECTID 1ULL
+
 /*
  * we can actually store much bigger names, but lets not confuse the rest
  * of linux
@@ -95,6 +127,81 @@ struct btrfs_key {
 	u64 offset;
 } __attribute__ ((__packed__));
 
+struct btrfs_mapping_tree {
+	struct extent_map_tree map_tree;
+};
+
+#define BTRFS_DEV_UUID_SIZE 16
+struct btrfs_dev_item {
+	/* the internal btrfs device id */
+	__le64 devid;
+
+	/* size of the device */
+	__le64 total_bytes;
+
+	/* bytes used */
+	__le64 bytes_used;
+
+	/* optimal io alignment for this device */
+	__le32 io_align;
+
+	/* optimal io width for this device */
+	__le32 io_width;
+
+	/* minimal io size for this device */
+	__le32 sector_size;
+
+	/* the kernel device number */
+	__le64 rdev;
+
+	/* type and info about this device */
+	__le64 type;
+
+	/* partition number, 0 for whole dev */
+	__le32 partition;
+
+	/* length of the name data at the end of the item */
+	__le16 name_len;
+
+	/* physical drive uuid (or lvm uuid) */
+	u8 uuid[BTRFS_DEV_UUID_SIZE];
+	/* name goes here */
+} __attribute__ ((__packed__));
+
+struct btrfs_stripe {
+	__le64 devid;
+	__le64 offset;
+} __attribute__ ((__packed__));
+
+struct btrfs_chunk {
+	__le64 owner;
+	__le64 stripe_len;
+	__le64 type;
+
+	/* optimal io alignment for this chunk */
+	__le32 io_align;
+
+	/* optimal io width for this chunk */
+	__le32 io_width;
+
+	/* minimal io size for this chunk */
+	__le32 sector_size;
+
+	/* 2^16 stripes is quite a lot, a second limit is the size of a single
+	 * item in the btree
+	 */
+	__le16 num_stripes;
+	struct btrfs_stripe stripe;
+	/* additional stripes go here */
+} __attribute__ ((__packed__));
+
+static inline unsigned long btrfs_chunk_item_size(int num_stripes)
+{
+	BUG_ON(num_stripes == 0);
+	return sizeof(struct btrfs_chunk) +
+		sizeof(struct btrfs_stripe) * (num_stripes - 1);
+}
+
 #define BTRFS_FSID_SIZE 16
 /*
  * every tree block (leaf or node) starts with this header.
@@ -119,6 +226,13 @@ struct btrfs_header {
 					sizeof(struct btrfs_item) - \
 					sizeof(struct btrfs_file_extent_item))
 
+
+/*
+ * this is a very generous portion of the super block, giving us
+ * room to translate 14 chunks with 3 stripes each.
+ */
+#define BTRFS_SYSTEM_CHUNK_ARRAY_SIZE 2048
+
 /*
  * the super block basically lists the main trees of the FS
  * it currently lacks any block count etc etc
@@ -131,6 +245,7 @@ struct btrfs_super_block {
 	__le64 magic;
 	__le64 generation;
 	__le64 root;
+	__le64 chunk_root;
 	__le64 total_bytes;
 	__le64 bytes_used;
 	__le64 root_dir_objectid;
@@ -138,7 +253,10 @@ struct btrfs_super_block {
 	__le32 nodesize;
 	__le32 leafsize;
 	__le32 stripesize;
+	__le32 sys_chunk_array_size;
 	u8 root_level;
+	u8 chunk_root_level;
+	u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];
 } __attribute__ ((__packed__));
 
 /*
@@ -208,12 +326,22 @@ struct btrfs_extent_ref {
 	__le64 offset;
 } __attribute__ ((__packed__));
 
+/* dev extents record free space on individual devices.  The owner
+ * field points back to the chunk allocation mapping tree that allocated
+ * the extent
+ */
+struct btrfs_dev_extent {
+	__le64 owner;
+	__le64 length;
+} __attribute__ ((__packed__));
+
+
 struct btrfs_inode_ref {
 	__le16 name_len;
 	/* name goes here */
 } __attribute__ ((__packed__));
 
-struct btrfs_inode_timespec {
+struct btrfs_timespec {
 	__le64 sec;
 	__le32 nsec;
 } __attribute__ ((__packed__));
@@ -231,13 +359,13 @@ struct btrfs_inode_item {
 	__le32 uid;
 	__le32 gid;
 	__le32 mode;
-	__le32 rdev;
+	__le64 rdev;
 	__le16 flags;
 	__le16 compat_flags;
-	struct btrfs_inode_timespec atime;
-	struct btrfs_inode_timespec ctime;
-	struct btrfs_inode_timespec mtime;
-	struct btrfs_inode_timespec otime;
+	struct btrfs_timespec atime;
+	struct btrfs_timespec ctime;
+	struct btrfs_timespec mtime;
+	struct btrfs_timespec otime;
 } __attribute__ ((__packed__));
 
 struct btrfs_dir_item {
@@ -290,29 +418,34 @@ struct btrfs_csum_item {
 	u8 csum;
 } __attribute__ ((__packed__));
 
-/* tag for the radix tree of block groups in ram */
-#define BTRFS_BLOCK_GROUP_SIZE (256 * 1024 * 1024)
-
+/* different types of block groups (and chunks) */
+#define BTRFS_BLOCK_GROUP_DATA     (1 << 0)
+#define BTRFS_BLOCK_GROUP_SYSTEM   (1 << 1)
+#define BTRFS_BLOCK_GROUP_METADATA (1 << 2)
 
-#define BTRFS_BLOCK_GROUP_DATA 1
-#define BTRFS_BLOCK_GROUP_MIXED 2
 
 struct btrfs_block_group_item {
 	__le64 used;
-	u8 flags;
+	__le64 chunk_tree;
+	__le64 chunk_objectid;
+	__le64 flags;
 } __attribute__ ((__packed__));
 
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
-	int data;
-	int cached;
 	u64 pinned;
+	u64 flags;
+	int cached;
 };
+
+struct btrfs_device;
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
+	struct btrfs_root *chunk_root;
+	struct btrfs_root *dev_root;
 	struct radix_tree_root fs_roots_radix;
 
 	struct extent_io_tree free_space_cache;
@@ -321,6 +454,9 @@ struct btrfs_fs_info {
 	struct extent_io_tree pending_del;
 	struct extent_io_tree extent_ins;
 
+	/* logical->physical extent mapping */
+	struct btrfs_mapping_tree mapping_tree;
+
 	u64 generation;
 	u64 last_trans_committed;
 	unsigned long mount_opt;
@@ -330,6 +466,7 @@ struct btrfs_fs_info {
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block super_copy;
 	struct extent_buffer *sb_buffer;
+	struct block_device *__bdev;
 	struct super_block *sb;
 	struct inode *btree_inode;
 	spinlock_t hash_lock;
@@ -350,12 +487,17 @@ struct btrfs_fs_info {
 	unsigned long throttles;
 
 	u64 total_pinned;
+	struct list_head dirty_cowonly_roots;
+
+	struct list_head devices;
+	struct list_head *last_device;
 	spinlock_t delalloc_lock;
 	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
 	u64 last_alloc;
 	u64 last_data_alloc;
 };
+
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.
@@ -387,14 +529,19 @@ struct btrfs_root {
 	u64 highest_inode;
 	u64 last_inode_alloc;
 	int ref_cows;
+	int track_dirty;
 	struct btrfs_key defrag_progress;
 	int defrag_running;
 	int defrag_level;
 	char *name;
 	int in_sysfs;
+
+	/* the dirty list is only used by non-reference counted roots */
+	struct list_head dirty_list;
 };
 
 /*
+
  * inode items have the data typically returned from stat and store other
  * info about object characteristics.  There is one for every file and dir in
  * the FS
@@ -439,6 +586,10 @@ struct btrfs_root {
  */
 #define BTRFS_BLOCK_GROUP_ITEM_KEY 50
 
+#define BTRFS_DEV_EXTENT_KEY	75
+#define BTRFS_DEV_ITEM_KEY	76
+#define BTRFS_CHUNK_ITEM_KEY	77
+
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
@@ -518,13 +669,104 @@ static inline void btrfs_set_##name(type *s, u##bits val)		\
 	s->member = cpu_to_le##bits(val);				\
 }
 
+BTRFS_SETGET_FUNCS(device_type, struct btrfs_dev_item, type, 64);
+BTRFS_SETGET_FUNCS(device_total_bytes, struct btrfs_dev_item, total_bytes, 64);
+BTRFS_SETGET_FUNCS(device_bytes_used, struct btrfs_dev_item, bytes_used, 64);
+BTRFS_SETGET_FUNCS(device_io_align, struct btrfs_dev_item, io_align, 32);
+BTRFS_SETGET_FUNCS(device_io_width, struct btrfs_dev_item, io_width, 32);
+BTRFS_SETGET_FUNCS(device_sector_size, struct btrfs_dev_item, sector_size, 32);
+BTRFS_SETGET_FUNCS(device_id, struct btrfs_dev_item, devid, 64);
+BTRFS_SETGET_FUNCS(device_rdev, struct btrfs_dev_item, rdev, 64);
+BTRFS_SETGET_FUNCS(device_partition, struct btrfs_dev_item, partition, 32);
+BTRFS_SETGET_FUNCS(device_name_len, struct btrfs_dev_item, name_len, 16);
+
+static inline char *btrfs_device_uuid(struct btrfs_dev_item *d)
+{
+	return (char *)d + offsetof(struct btrfs_dev_item, uuid);
+}
+
+static inline char *btrfs_device_name(struct btrfs_dev_item *d)
+{
+	return (char *)(d + 1);
+}
+
+BTRFS_SETGET_FUNCS(chunk_owner, struct btrfs_chunk, owner, 64);
+BTRFS_SETGET_FUNCS(chunk_stripe_len, struct btrfs_chunk, stripe_len, 64);
+BTRFS_SETGET_FUNCS(chunk_io_align, struct btrfs_chunk, io_align, 32);
+BTRFS_SETGET_FUNCS(chunk_io_width, struct btrfs_chunk, io_width, 32);
+BTRFS_SETGET_FUNCS(chunk_sector_size, struct btrfs_chunk, sector_size, 32);
+BTRFS_SETGET_FUNCS(chunk_type, struct btrfs_chunk, type, 64);
+BTRFS_SETGET_FUNCS(chunk_num_stripes, struct btrfs_chunk, num_stripes, 16);
+BTRFS_SETGET_FUNCS(stripe_devid, struct btrfs_stripe, devid, 64);
+BTRFS_SETGET_FUNCS(stripe_offset, struct btrfs_stripe, offset, 64);
+
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_owner, struct btrfs_chunk, owner, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_stripe_len, struct btrfs_chunk,
+			 stripe_len, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_io_align, struct btrfs_chunk,
+			 io_align, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_io_width, struct btrfs_chunk,
+			 io_width, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_sector_size, struct btrfs_chunk,
+			 sector_size, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_type, struct btrfs_chunk, type, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_chunk_num_stripes, struct btrfs_chunk,
+			 num_stripes, 16);
+BTRFS_SETGET_STACK_FUNCS(stack_stripe_devid, struct btrfs_stripe, devid, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_stripe_offset, struct btrfs_stripe, offset, 64);
+
+static inline struct btrfs_stripe *btrfs_stripe_nr(struct btrfs_chunk *c,
+						   int nr)
+{
+	unsigned long offset = (unsigned long)c;
+	offset += offsetof(struct btrfs_chunk, stripe);
+	offset += nr * sizeof(struct btrfs_stripe);
+	return (struct btrfs_stripe *)offset;
+}
+
+static inline u64 btrfs_stripe_offset_nr(struct extent_buffer *eb,
+					 struct btrfs_chunk *c, int nr)
+{
+	return btrfs_stripe_offset(eb, btrfs_stripe_nr(c, nr));
+}
+
+static inline void btrfs_set_stripe_offset_nr(struct extent_buffer *eb,
+					     struct btrfs_chunk *c, int nr,
+					     u64 val)
+{
+	btrfs_set_stripe_offset(eb, btrfs_stripe_nr(c, nr), val);
+}
+
+static inline u64 btrfs_stripe_devid_nr(struct extent_buffer *eb,
+					 struct btrfs_chunk *c, int nr)
+{
+	return btrfs_stripe_devid(eb, btrfs_stripe_nr(c, nr));
+}
+
+static inline void btrfs_set_stripe_devid_nr(struct extent_buffer *eb,
+					     struct btrfs_chunk *c, int nr,
+					     u64 val)
+{
+	btrfs_set_stripe_devid(eb, btrfs_stripe_nr(c, nr), val);
+}
+
 /* struct btrfs_block_group_item */
 BTRFS_SETGET_STACK_FUNCS(block_group_used, struct btrfs_block_group_item,
 			 used, 64);
 BTRFS_SETGET_FUNCS(disk_block_group_used, struct btrfs_block_group_item,
 			 used, 64);
-BTRFS_SETGET_FUNCS(disk_block_group_flags, struct btrfs_block_group_item,
-		   flags, 8);
+BTRFS_SETGET_STACK_FUNCS(block_group_chunk_tree, struct btrfs_block_group_item,
+			 chunk_tree, 64);
+BTRFS_SETGET_FUNCS(disk_block_group_chunk_tree, struct btrfs_block_group_item,
+			 chunk_tree, 64);
+BTRFS_SETGET_STACK_FUNCS(block_group_chunk_objectid,
+			struct btrfs_block_group_item, chunk_objectid, 64);
+BTRFS_SETGET_FUNCS(disk_block_group_chunk_objecitd,
+		   struct btrfs_block_group_item, chunk_objectid, 64);
+BTRFS_SETGET_FUNCS(disk_block_group_flags,
+		   struct btrfs_block_group_item, flags, 64);
+BTRFS_SETGET_STACK_FUNCS(block_group_flags,
+			struct btrfs_block_group_item, flags, 64);
 
 /* struct btrfs_inode_ref */
 BTRFS_SETGET_FUNCS(inode_ref_name_len, struct btrfs_inode_ref, name_len, 16);
@@ -538,49 +780,53 @@ BTRFS_SETGET_FUNCS(inode_nlink, struct btrfs_inode_item, nlink, 32);
 BTRFS_SETGET_FUNCS(inode_uid, struct btrfs_inode_item, uid, 32);
 BTRFS_SETGET_FUNCS(inode_gid, struct btrfs_inode_item, gid, 32);
 BTRFS_SETGET_FUNCS(inode_mode, struct btrfs_inode_item, mode, 32);
-BTRFS_SETGET_FUNCS(inode_rdev, struct btrfs_inode_item, rdev, 32);
+BTRFS_SETGET_FUNCS(inode_rdev, struct btrfs_inode_item, rdev, 64);
 BTRFS_SETGET_FUNCS(inode_flags, struct btrfs_inode_item, flags, 16);
 BTRFS_SETGET_FUNCS(inode_compat_flags, struct btrfs_inode_item,
 		   compat_flags, 16);
 
-static inline struct btrfs_inode_timespec *
+static inline struct btrfs_timespec *
 btrfs_inode_atime(struct btrfs_inode_item *inode_item)
 {
 	unsigned long ptr = (unsigned long)inode_item;
 	ptr += offsetof(struct btrfs_inode_item, atime);
-	return (struct btrfs_inode_timespec *)ptr;
+	return (struct btrfs_timespec *)ptr;
 }
 
-static inline struct btrfs_inode_timespec *
+static inline struct btrfs_timespec *
 btrfs_inode_mtime(struct btrfs_inode_item *inode_item)
 {
 	unsigned long ptr = (unsigned long)inode_item;
 	ptr += offsetof(struct btrfs_inode_item, mtime);
-	return (struct btrfs_inode_timespec *)ptr;
+	return (struct btrfs_timespec *)ptr;
 }
 
-static inline struct btrfs_inode_timespec *
+static inline struct btrfs_timespec *
 btrfs_inode_ctime(struct btrfs_inode_item *inode_item)
 {
 	unsigned long ptr = (unsigned long)inode_item;
 	ptr += offsetof(struct btrfs_inode_item, ctime);
-	return (struct btrfs_inode_timespec *)ptr;
+	return (struct btrfs_timespec *)ptr;
 }
 
-static inline struct btrfs_inode_timespec *
+static inline struct btrfs_timespec *
 btrfs_inode_otime(struct btrfs_inode_item *inode_item)
 {
 	unsigned long ptr = (unsigned long)inode_item;
 	ptr += offsetof(struct btrfs_inode_item, otime);
-	return (struct btrfs_inode_timespec *)ptr;
+	return (struct btrfs_timespec *)ptr;
 }
 
-BTRFS_SETGET_FUNCS(timespec_sec, struct btrfs_inode_timespec, sec, 64);
-BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_inode_timespec, nsec, 32);
+BTRFS_SETGET_FUNCS(timespec_sec, struct btrfs_timespec, sec, 64);
+BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_timespec, nsec, 32);
 
 /* struct btrfs_extent_item */
 BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
 
+/* struct btrfs_dev_extent */
+BTRFS_SETGET_FUNCS(dev_extent_owner, struct btrfs_dev_extent, owner, 64);
+BTRFS_SETGET_FUNCS(dev_extent_length, struct btrfs_dev_extent, length, 64);
+
 /* struct btrfs_extent_ref */
 BTRFS_SETGET_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
 BTRFS_SETGET_FUNCS(ref_generation, struct btrfs_extent_ref, generation, 64);
@@ -846,8 +1092,14 @@ BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);
 BTRFS_SETGET_STACK_FUNCS(super_generation, struct btrfs_super_block,
 			 generation, 64);
 BTRFS_SETGET_STACK_FUNCS(super_root, struct btrfs_super_block, root, 64);
+BTRFS_SETGET_STACK_FUNCS(super_sys_array_size,
+			 struct btrfs_super_block, sys_chunk_array_size, 32);
 BTRFS_SETGET_STACK_FUNCS(super_root_level, struct btrfs_super_block,
 			 root_level, 8);
+BTRFS_SETGET_STACK_FUNCS(super_chunk_root, struct btrfs_super_block,
+			 chunk_root, 64);
+BTRFS_SETGET_STACK_FUNCS(super_chunk_root_level, struct btrfs_super_block,
+			 chunk_root_level, 64);
 BTRFS_SETGET_STACK_FUNCS(super_total_bytes, struct btrfs_super_block,
 			 total_bytes, 64);
 BTRFS_SETGET_STACK_FUNCS(super_bytes_used, struct btrfs_super_block,
@@ -1009,7 +1261,14 @@ int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_root *root);
+int btrfs_make_block_group(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, u64 bytes_used,
+			   u64 type, u64 chunk_tree, u64 chunk_objectid,
+			   u64 size);
 /* ctree.c */
+int btrfs_previous_item(struct btrfs_root *root,
+			struct btrfs_path *path, u64 min_objectid,
+			int type);
 int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,

commit 065631f6dccea07bfad48d8981369f6d9cfd6e2b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 20 12:07:25 2008 -0500

    Btrfs: checksum file data at bio submission time instead of during writepage
    
    When we checkum file data during writepage, the checksumming is done one
    page at a time, making it difficult to do bulk metadata modifications
    to insert checksums for large ranges of the file at once.
    
    This patch changes btrfs to checksum on a per-bio basis instead.  The
    bios are checksummed before they are handed off to the block layer, so
    each bio is contiguous and only has pages from the same inode.
    
    Checksumming on a bio basis allows us to insert and modify the file
    checksum items in large groups.  It also allows the checksumming to
    be done more easily by async worker threads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 086cb0525cd1..92d892f92075 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1142,11 +1142,9 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
 			     u64 bytenr, int mod);
-int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root,
-			  struct inode *inode,
-			  u64 objectid, u64 offset,
-			  char *data, size_t len);
+int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, struct inode *inode,
+			   struct bio *bio);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,

commit df68b8a7ad4a18c9e63f1c12015a59c3b7031adb
Author: David Miller <davem@davemloft.net>
Date:   Fri Feb 15 10:40:52 2008 -0500

    Btrfs: unaligned access fixes
    
    Btrfs set/get macros lose type information needed to avoid
    unaligned accesses on sparc64.
    ere is a patch for the kernel bits which fixes most of the
    unaligned accesses on sparc64.
    
    btrfs_name_hash is modified to return the hash value instead
    of getting a return location via a (potentially unaligned)
    pointer.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 52144b04f1af..086cb0525cd1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -495,22 +495,17 @@ void btrfs_set_##name(struct extent_buffer *eb, type *s, u##bits val);
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
 static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
 {									\
-	char *kaddr = kmap_atomic(eb->first_page, KM_USER0);		\
-	unsigned long offset = offsetof(type, member);			\
-	u##bits res;							\
-	__le##bits *tmp = (__le##bits *)(kaddr + offset);		\
-	res = le##bits##_to_cpu(*tmp);					\
-	kunmap_atomic(kaddr, KM_USER0);					\
+	type *p = kmap_atomic(eb->first_page, KM_USER0);		\
+	u##bits res = le##bits##_to_cpu(p->member);			\
+	kunmap_atomic(p, KM_USER0);					\
 	return res;							\
 }									\
 static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 				    u##bits val)			\
 {									\
-	char *kaddr = kmap_atomic(eb->first_page, KM_USER0);		\
-	unsigned long offset = offsetof(type, member);			\
-	__le##bits *tmp = (__le##bits *)(kaddr + offset);		\
-	*tmp = cpu_to_le##bits(val);					\
-	kunmap_atomic(kaddr, KM_USER0);					\
+	type *p = kmap_atomic(eb->first_page, KM_USER0);		\
+	p->member = cpu_to_le##bits(val);				\
+	kunmap_atomic(p, KM_USER0);					\
 }
 
 #define BTRFS_SETGET_STACK_FUNCS(name, type, member, bits)		\

commit 9069218d448ea547dbad5f1cbd537e88d6519d66
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Feb 8 13:49:28 2008 -0500

    Btrfs: Fix i_blocks accounting
    
    Now that delayed allocation accounting works, i_blocks accounting is changed
    to only modify i_blocks when extents inserted or removed.
    
    The fillattr call is changed to include the delayed allocation byte count
    in the i_blocks result.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dfb700efcd6b..52144b04f1af 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1161,6 +1161,15 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+static inline void dec_i_blocks(struct inode *inode, u64 dec)
+{
+	dec = dec >> 9;
+	if (dec <= inode->i_blocks)
+		inode->i_blocks -= dec;
+	else
+		inode->i_blocks = 0;
+}
+
 unsigned long btrfs_force_ra(struct address_space *mapping,
 			      struct file_ra_state *ra, struct file *file,
 			      pgoff_t offset, pgoff_t last_index);

commit 47b0c4f8c717890877058f30e07a30e05f74a7bb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Feb 4 10:10:43 2008 -0500

    Btrfs: Update magic
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 35e9a7af10a5..dfb700efcd6b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -37,7 +37,7 @@ extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 
-#define BTRFS_MAGIC "_B3RfS_M"
+#define BTRFS_MAGIC "_B4RfS_M"
 
 #define BTRFS_MAX_LEVEL 8
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL

commit 4529ba495c6fd0d79247784d0df55ae6512fa883
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 31 16:45:07 2008 -0500

    Btrfs: Add data block hints to SSD mode too
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8f93e066bf8b..35e9a7af10a5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -354,6 +354,7 @@ struct btrfs_fs_info {
 	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
 	u64 last_alloc;
+	u64 last_data_alloc;
 };
 /*
  * in ram representation of the tree.  extent_root is used for all allocations

commit 6f568d35a045dbb8a13fe71bfc32e85e39a986cb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 16:03:38 2008 -0500

    Btrfs: mount -o max_inline=size to control the maximum inline extent size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 127c86f795d0..8f93e066bf8b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -325,6 +325,7 @@ struct btrfs_fs_info {
 	u64 last_trans_committed;
 	unsigned long mount_opt;
 	u64 max_extent;
+	u64 max_inline;
 	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block super_copy;

commit 9c58309d6cf22471dacbcb6de54d00cef9ca20d4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 15:15:18 2008 -0500

    Btrfs: Add inode item and backref in one insert, reducing cpu usage
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 098cf0883150..127c86f795d0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1050,9 +1050,20 @@ static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
 
 int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, void *data, u32 data_size);
-int btrfs_insert_empty_item(struct btrfs_trans_handle *trans, struct btrfs_root
-			    *root, struct btrfs_path *path, struct btrfs_key
-			    *cpu_key, u32 data_size);
+int btrfs_insert_empty_items(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root,
+			     struct btrfs_path *path,
+			     struct btrfs_key *cpu_key, u32 *data_size, int nr);
+
+static inline int btrfs_insert_empty_item(struct btrfs_trans_handle *trans,
+					  struct btrfs_root *root,
+					  struct btrfs_path *path,
+					  struct btrfs_key *key,
+					  u32 data_size)
+{
+	return btrfs_insert_empty_items(trans, root, path, key, &data_size, 1);
+}
+
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);

commit 85e21bac165b4ba1f6f90431ad6fc658ffcbaf3a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 15:11:36 2008 -0500

    Btrfs: During deletes and truncate, remove many items at once from the tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6c65473e0fe3..098cf0883150 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1038,8 +1038,16 @@ void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
 void btrfs_init_path(struct btrfs_path *p);
-int btrfs_del_item(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		   struct btrfs_path *path);
+int btrfs_del_items(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		   struct btrfs_path *path, int slot, int nr);
+
+static inline int btrfs_del_item(struct btrfs_trans_handle *trans,
+				 struct btrfs_root *root,
+				 struct btrfs_path *path)
+{
+	return btrfs_del_items(trans, root, path, path->slots[0], 1);
+}
+
 int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, void *data, u32 data_size);
 int btrfs_insert_empty_item(struct btrfs_trans_handle *trans, struct btrfs_root

commit d1310b2e0cd98eb1348553e69b73827b436dca7b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 24 16:13:08 2008 -0500

    Btrfs: Split the extent_map code into two parts
    
    There is now extent_map for mapping offsets in the file to disk and
    extent_io for state tracking, IO submission and extent_bufers.
    
    The new extent_map code shifts from [start,end] pairs to [start,len], and
    pushes the locking out into the caller.  This allows a few performance
    optimizations and is easier to use.
    
    A number of extent_map usage bugs were fixed, mostly with failing
    to remove extent_map entries when changing the file.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b9f2975b55c9..6c65473e0fe3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -27,6 +27,7 @@
 #include <linux/completion.h>
 #include <asm/kmap_types.h>
 #include "bit-radix.h"
+#include "extent_io.h"
 #include "extent_map.h"
 
 struct btrfs_trans_handle;
@@ -314,11 +315,11 @@ struct btrfs_fs_info {
 	struct btrfs_root *tree_root;
 	struct radix_tree_root fs_roots_radix;
 
-	struct extent_map_tree free_space_cache;
-	struct extent_map_tree block_group_cache;
-	struct extent_map_tree pinned_extents;
-	struct extent_map_tree pending_del;
-	struct extent_map_tree extent_ins;
+	struct extent_io_tree free_space_cache;
+	struct extent_io_tree block_group_cache;
+	struct extent_io_tree pinned_extents;
+	struct extent_io_tree pending_del;
+	struct extent_io_tree extent_ins;
 
 	u64 generation;
 	u64 last_trans_committed;
@@ -956,7 +957,7 @@ u32 btrfs_count_snapshots_in_path(struct btrfs_root *root,
 				  u64 first_extent);
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
-int btrfs_copy_pinned(struct btrfs_root *root, struct extent_map_tree *copy);
+int btrfs_copy_pinned(struct btrfs_root *root, struct extent_io_tree *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
 							 btrfs_fs_info *info,
 							 u64 bytenr);
@@ -1001,7 +1002,7 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      u64 owner_objectid, u64 owner_offset, int pin);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
-			       struct extent_map_tree *unpin);
+			       struct extent_io_tree *unpin);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 bytenr, u64 num_bytes,

commit 5f56406aabdf5444d040c5955effc665b1d0dbaf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 22 16:47:59 2008 -0500

    Btrfs: Fix hole insertion corner cases
    
    There were a few places that could cause duplicate extent insertion,
    this adjusts the code that creates holes to avoid it.
    
    lookup_extent_map is changed to correctly return all of the extents in a
    range, even when there are none matching at the start of the range.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7a588ba2b747..b9f2975b55c9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1170,6 +1170,7 @@ int btrfs_update_inode(struct btrfs_trans_handle *trans,
 			      struct inode *inode);
 /* file.c */
 int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end);
+int btrfs_check_file(struct btrfs_root *root, struct inode *inode);
 extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,

commit e18e4809b10e6c9efb5fe10c1ddcb4ebb690d517
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jan 18 10:54:22 2008 -0500

    Btrfs: Add mount -o ssd, which includes optimizations for seek free storage
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fa65fe027e45..7a588ba2b747 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -351,6 +351,7 @@ struct btrfs_fs_info {
 	spinlock_t delalloc_lock;
 	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
+	u64 last_alloc;
 };
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
@@ -444,6 +445,7 @@ struct btrfs_root {
 #define BTRFS_MOUNT_NODATASUM		(1 << 0)
 #define BTRFS_MOUNT_NODATACOW		(1 << 1)
 #define BTRFS_MOUNT_NOBARRIER		(1 << 2)
+#define BTRFS_MOUNT_SSD			(1 << 3)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit 2da98f003f4788b0a72c5f87bc55b061f65f30fa
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jan 16 11:44:43 2008 -0500

    Btrfs: Run igrab on data=ordered inodes to prevent deadlocks during writeout
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e19f2d86334..fa65fe027e45 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1145,7 +1145,7 @@ int btrfs_check_free_space(struct btrfs_root *root, u64 num_required,
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct page *page);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);
-void btrfs_drop_inode(struct inode *inode);
+void btrfs_put_inode(struct inode *inode);
 void btrfs_read_locked_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, int wait);
 void btrfs_dirty_inode(struct inode *inode);

commit cee36a03e8f7c6e14aefd497d3acf01bcd3ef153
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 15 08:40:48 2008 -0500

    Rework btrfs_drop_inode to avoid scheduling
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a2c2d6d82c5e..1e19f2d86334 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -349,6 +349,7 @@ struct btrfs_fs_info {
 
 	u64 total_pinned;
 	spinlock_t delalloc_lock;
+	spinlock_t new_trans_lock;
 	u64 delalloc_bytes;
 };
 /*

commit 61295eb8665e723e77af91d0a1e655a4bd28344f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 14 16:24:38 2008 -0500

    Btrfs: Add drop inode func to avoid data=ordered deadlock
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f65b258344d4..a2c2d6d82c5e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1144,6 +1144,7 @@ int btrfs_check_free_space(struct btrfs_root *root, u64 num_required,
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct page *page);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);
+void btrfs_drop_inode(struct inode *inode);
 void btrfs_read_locked_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, int wait);
 void btrfs_dirty_inode(struct inode *inode);

commit 69a32ac5175ec9bcfb407e8619a024e5eaea87b7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 14 14:33:35 2008 -0500

    Btrfs: Change magic string to reflect new format
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 245952cf7650..f65b258344d4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -36,7 +36,7 @@ extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 
-#define BTRFS_MAGIC "_B2RfS_M"
+#define BTRFS_MAGIC "_B3RfS_M"
 
 #define BTRFS_MAX_LEVEL 8
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL

commit fdebe2bd70047e057827cba85ba31b2545e31900
Author: Yan <yanzheng@21cn.com>
Date:   Mon Jan 14 13:26:08 2008 -0500

    Btrfs: Add readonly inode flag
    
    This patch adds readonly inode flag support.  A file with this flag
    can't be modified, but can be deleted.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0c0edacbc14c..245952cf7650 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -451,9 +451,9 @@ struct btrfs_root {
 /*
  * Inode flags
  */
-#define BTRFS_INODE_NODATASUM 		0x1
-#define BTRFS_INODE_NODATACOW 		0x2
-
+#define BTRFS_INODE_NODATASUM		(1 << 0)
+#define BTRFS_INODE_NODATACOW		(1 << 1)
+#define BTRFS_INODE_READONLY		(1 << 2)
 #define btrfs_clear_flag(inode, flag)	(BTRFS_I(inode)->flags &= \
 					 ~BTRFS_INODE_##flag)
 #define btrfs_set_flag(inode, flag)	(BTRFS_I(inode)->flags |= \

commit 21ad10cf3e9c1ef42e725e5c3a593c49f779a16b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jan 9 09:23:21 2008 -0500

    Btrfs: Add flush barriers on commit
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7eda51542d17..0c0edacbc14c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -440,8 +440,9 @@ struct btrfs_root {
  */
 #define BTRFS_STRING_ITEM_KEY	253
 
-#define BTRFS_MOUNT_NODATASUM		0x1
-#define BTRFS_MOUNT_NODATACOW		0x2
+#define BTRFS_MOUNT_NODATASUM		(1 << 0)
+#define BTRFS_MOUNT_NODATACOW		(1 << 1)
+#define BTRFS_MOUNT_NOBARRIER		(1 << 2)
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)

commit b98b6767a0f6f9baa1d00eff64a43d58412ecdeb
Author: Yan <yanzheng@21cn.com>
Date:   Tue Jan 8 15:54:37 2008 -0500

    Btrfs: Add inode flags support
    
    This patch adds NODATASUM & NODATACOW inode flags support.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f0fb1978553c..7eda51542d17 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -447,7 +447,18 @@ struct btrfs_root {
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
 #define btrfs_test_opt(root, opt)	((root)->fs_info->mount_opt & \
 					 BTRFS_MOUNT_##opt)
-
+/*
+ * Inode flags
+ */
+#define BTRFS_INODE_NODATASUM 		0x1
+#define BTRFS_INODE_NODATACOW 		0x2
+
+#define btrfs_clear_flag(inode, flag)	(BTRFS_I(inode)->flags &= \
+					 ~BTRFS_INODE_##flag)
+#define btrfs_set_flag(inode, flag)	(BTRFS_I(inode)->flags |= \
+					 BTRFS_INODE_##flag)
+#define btrfs_test_flag(inode, flag)	(BTRFS_I(inode)->flags & \
+					 BTRFS_INODE_##flag)
 /* some macros to generate set/get funcs for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple
  * one for u8:

commit e2008b61401ecb467a8ce1788fcd2116ae1cfbc1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:30 2008 -0500

    Btrfs: Add some simple throttling to wait for data=ordered and snapshot deletion
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b55dba58dfaa..f0fb1978553c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -345,6 +345,7 @@ struct btrfs_fs_info {
 	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
+	unsigned long throttles;
 
 	u64 total_pinned;
 	spinlock_t delalloc_lock;

commit dc17ff8f11d129db9e83ab7244769e4eae05e14d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:30 2008 -0500

    Btrfs: Add data=ordered support
    
    This forces file data extents down the disk along with the metadata that
    references them.  The current implementation is fairly simple, and just
    writes out all of the dirty pages in an inode before the commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9873975ce0ee..b55dba58dfaa 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -16,8 +16,8 @@
  * Boston, MA 021110-1307, USA.
  */
 
-#ifndef __BTRFS__
-#define __BTRFS__
+#ifndef __BTRFS_CTREE__
+#define __BTRFS_CTREE__
 
 #include <linux/version.h>
 #include <linux/mm.h>
@@ -363,7 +363,6 @@ struct btrfs_root {
 	struct inode *inode;
 	struct kobject root_kobj;
 	struct completion kobj_unregister;
-	struct rw_semaphore snap_sem;
 	u64 objectid;
 	u64 last_trans;
 
@@ -1142,6 +1141,8 @@ void btrfs_destroy_cachep(void);
 long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
+struct inode *btrfs_ilookup(struct super_block *s, u64 objectid,
+			    u64 root_objectid);
 int btrfs_commit_write(struct file *file, struct page *page,
 		       unsigned from, unsigned to);
 struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,

commit 4313b3994d719fcdeb7e661473019ca3d62e829b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 3 09:08:48 2008 -0500

    Btrfs: Reduce stack usage in the resizer, fix 32 bit compiles
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d6e5c19969b0..9873975ce0ee 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -386,6 +386,7 @@ struct btrfs_root {
 	int defrag_running;
 	int defrag_level;
 	char *name;
+	int in_sysfs;
 };
 
 /*

commit 8f662a76c6af8eb367fa519e9bb9766040d9cea8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jan 2 10:01:11 2008 -0500

    Btrfs: Add readahead to the online shrinker, and a mount -o alloc_start= for testing
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b83a1bec346f..d6e5c19969b0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -324,6 +324,7 @@ struct btrfs_fs_info {
 	u64 last_trans_committed;
 	unsigned long mount_opt;
 	u64 max_extent;
+	u64 alloc_start;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block super_copy;
 	struct extent_buffer *sb_buffer;

commit edbd8d4efe4ddaf29a175ae504e2c9a05a96ebee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Dec 21 16:27:24 2007 -0500

    Btrfs: Support for online FS resize (grow and shrink)
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 10129cc6656f..b83a1bec346f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -508,6 +508,8 @@ BTRFS_SETGET_STACK_FUNCS(block_group_used, struct btrfs_block_group_item,
 			 used, 64);
 BTRFS_SETGET_FUNCS(disk_block_group_used, struct btrfs_block_group_item,
 			 used, 64);
+BTRFS_SETGET_FUNCS(disk_block_group_flags, struct btrfs_block_group_item,
+		   flags, 8);
 
 /* struct btrfs_inode_ref */
 BTRFS_SETGET_FUNCS(inode_ref_name_len, struct btrfs_inode_ref, name_len, 16);
@@ -960,6 +962,9 @@ struct extent_buffer *__btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					     int level,
 					     u64 hint,
 					     u64 empty_size);
+int btrfs_grow_extent_tree(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, u64 new_size);
+int btrfs_shrink_extent_tree(struct btrfs_root *root, u64 new_size);
 int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct btrfs_path *path, u64 bytenr,
@@ -1117,6 +1122,9 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+unsigned long btrfs_force_ra(struct address_space *mapping,
+			      struct file_ra_state *ra, struct file *file,
+			      pgoff_t offset, pgoff_t last_index);
 int btrfs_check_free_space(struct btrfs_root *root, u64 num_required,
 			   int for_del);
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct page *page);
@@ -1162,4 +1170,6 @@ void btrfs_sysfs_del_super(struct btrfs_fs_info *root);
 ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
 int btrfs_delete_xattrs(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct inode *inode);
+/* super.c */
+u64 btrfs_parse_size(char *str);
 #endif

commit 1832a6d5ee3b1af61001cadba9e10da9e91af4a4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Dec 21 16:27:21 2007 -0500

    Btrfs: Implement basic support for -ENOSPC
    
    This is intended to prevent accidentally filling the drive.  A determined
    user can still make things oops.
    
    It includes some accounting of the current bytes under delayed allocation,
    but this will change as things get optimized
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2559f5d5d00a..10129cc6656f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -346,6 +346,8 @@ struct btrfs_fs_info {
 	int closing;
 
 	u64 total_pinned;
+	spinlock_t delalloc_lock;
+	u64 delalloc_bytes;
 };
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
@@ -1115,6 +1117,8 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+int btrfs_check_free_space(struct btrfs_root *root, u64 num_required,
+			   int for_del);
 int btrfs_page_mkwrite(struct vm_area_struct *vma, struct page *page);
 int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);

commit 6da6abae027e2dbc59bca5f4168b0760f25068c7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 18 16:15:09 2007 -0500

    Btrfs: Back port to 2.6.18-el kernels
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 32b24460ec82..2559f5d5d00a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -19,6 +19,7 @@
 #ifndef __BTRFS__
 #define __BTRFS__
 
+#include <linux/version.h>
 #include <linux/mm.h>
 #include <linux/highmem.h>
 #include <linux/fs.h>
@@ -334,7 +335,11 @@ struct btrfs_fs_info {
 	struct list_head trans_list;
 	struct list_head hashers;
 	struct list_head dead_roots;
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+	struct work_struct trans_work;
+#else
 	struct delayed_work trans_work;
+#endif
 	struct kobject super_kobj;
 	struct completion kobj_unregister;
 	int do_barriers;
@@ -916,6 +921,14 @@ static inline u32 btrfs_level_size(struct btrfs_root *root, int level) {
 	((unsigned long)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset_nr(leaf, slot)))
 
+static inline struct dentry *fdentry(struct file *file) {
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+	return file->f_dentry;
+#else
+	return file->f_path.dentry;
+#endif
+}
+
 /* extent-tree.c */
 u32 btrfs_count_snapshots_in_path(struct btrfs_root *root,
 				  struct btrfs_path *count_path,

commit c59f8951d48c5eb000926935f3ab063d8181d1ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 17 20:14:04 2007 -0500

    Btrfs: Add mount option to enforce a max extent size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b51b021fff85..32b24460ec82 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -322,6 +322,7 @@ struct btrfs_fs_info {
 	u64 generation;
 	u64 last_trans_committed;
 	unsigned long mount_opt;
+	u64 max_extent;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block super_copy;
 	struct extent_buffer *sb_buffer;

commit be20aa9dbadc8c06283784ee12bbc0d97dea3418
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 17 20:14:01 2007 -0500

    Btrfs: Add mount option to turn off data cow
    
    A number of workloads do not require copy on write data or checksumming.
    mount -o nodatasum to disable checksums and -o nodatacow to disable
    both copy on write and checksumming.
    
    In nodatacow mode, copy on write is still performed when a given extent
    is under snapshot.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5e255cabfd10..b51b021fff85 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -431,6 +431,7 @@ struct btrfs_root {
 #define BTRFS_STRING_ITEM_KEY	253
 
 #define BTRFS_MOUNT_NODATASUM		0x1
+#define BTRFS_MOUNT_NODATACOW		0x2
 
 #define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
 #define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
@@ -915,6 +916,9 @@ static inline u32 btrfs_level_size(struct btrfs_root *root, int level) {
 	btrfs_item_offset_nr(leaf, slot)))
 
 /* extent-tree.c */
+u32 btrfs_count_snapshots_in_path(struct btrfs_root *root,
+				  struct btrfs_path *count_path,
+				  u64 first_extent);
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_map_tree *copy);
@@ -974,6 +978,10 @@ int btrfs_cow_block(struct btrfs_trans_handle *trans,
 		    struct btrfs_root *root, struct extent_buffer *buf,
 		    struct extent_buffer *parent, int parent_slot,
 		    struct extent_buffer **cow_ret);
+int btrfs_copy_root(struct btrfs_trans_handle *trans,
+		      struct btrfs_root *root,
+		      struct extent_buffer *buf,
+		      struct extent_buffer **cow_ret, u64 new_root_objectid);
 int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_path *path, u32 data_size);
 int btrfs_truncate_item(struct btrfs_trans_handle *trans,

commit b6cda9bcb4df7544c67fc3548a53bc1607d59f46
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Dec 14 15:30:32 2007 -0500

    Btrfs: Add mount -o nodatasum to turn of file data checksumming
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 052555ced44d..5e255cabfd10 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -321,6 +321,7 @@ struct btrfs_fs_info {
 
 	u64 generation;
 	u64 last_trans_committed;
+	unsigned long mount_opt;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block super_copy;
 	struct extent_buffer *sb_buffer;
@@ -429,6 +430,13 @@ struct btrfs_root {
  */
 #define BTRFS_STRING_ITEM_KEY	253
 
+#define BTRFS_MOUNT_NODATASUM		0x1
+
+#define btrfs_clear_opt(o, opt)		((o) &= ~BTRFS_MOUNT_##opt)
+#define btrfs_set_opt(o, opt)		((o) |= BTRFS_MOUNT_##opt)
+#define btrfs_test_opt(root, opt)	((root)->fs_info->mount_opt & \
+					 BTRFS_MOUNT_##opt)
+
 /* some macros to generate set/get funcs for the struct fields.  This
  * assumes there is a lefoo_to_cpu for every type, so lets make a simple
  * one for u8:
@@ -906,12 +914,6 @@ static inline u32 btrfs_level_size(struct btrfs_root *root, int level) {
 	((unsigned long)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset_nr(leaf, slot)))
 
-/* mount option defines and helpers */
-#define BTRFS_MOUNT_SUBVOL		0x000001
-#define btrfs_clear_opt(o, opt)		o &= ~BTRFS_MOUNT_##opt
-#define btrfs_set_opt(o, opt)		o |= BTRFS_MOUNT_##opt
-#define btrfs_test_opt(sb, opt)		(BTRFS_SB(sb)->s_mount_opt & \
-					 BTRFS_MOUNT_##opt)
 /* extent-tree.c */
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);

commit f6dbff55d77dee363c22873481db54d3bada3ea6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Dec 13 11:13:32 2007 -0500

    Btrfs: Reorder extent back refs to differentiate btree blocks from file data
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 035fa1550343..052555ced44d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -37,11 +37,12 @@ extern struct kmem_cache *btrfs_path_cachep;
 
 #define BTRFS_MAGIC "_B2RfS_M"
 
+#define BTRFS_MAX_LEVEL 8
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
 #define BTRFS_EXTENT_TREE_OBJECTID 2ULL
 #define BTRFS_FS_TREE_OBJECTID 3ULL
 #define BTRFS_ROOT_TREE_DIR_OBJECTID 4ULL
-#define BTRFS_FIRST_FREE_OBJECTID 5ULL
+#define BTRFS_FIRST_FREE_OBJECTID 256ULL
 
 /*
  * we can actually store much bigger names, but lets not confuse the rest
@@ -107,7 +108,6 @@ struct btrfs_header {
 	u8 level;
 } __attribute__ ((__packed__));
 
-#define BTRFS_MAX_LEVEL 8
 #define BTRFS_NODEPTRS_PER_BLOCK(r) (((r)->nodesize - \
 			        sizeof(struct btrfs_header)) / \
 			        sizeof(struct btrfs_key_ptr))

commit 3954401fa6013bb2f2c8758b903e9bffcf25b64b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Dec 12 14:38:19 2007 -0500

    Btrfs: Add back pointers from the inode to the directory that references it
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cb1b156d954e..035fa1550343 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -53,7 +53,7 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_CSUM_SIZE 32
 /* four bytes for CRC32 */
 #define BTRFS_CRC32_SIZE 4
-#define BTRFS_EMPTY_DIR_SIZE 6
+#define BTRFS_EMPTY_DIR_SIZE 0
 
 #define BTRFS_FT_UNKNOWN	0
 #define BTRFS_FT_REG_FILE	1
@@ -206,6 +206,11 @@ struct btrfs_extent_ref {
 	__le64 offset;
 } __attribute__ ((__packed__));
 
+struct btrfs_inode_ref {
+	__le16 name_len;
+	/* name goes here */
+} __attribute__ ((__packed__));
+
 struct btrfs_inode_timespec {
 	__le64 sec;
 	__le32 nsec;
@@ -379,7 +384,8 @@ struct btrfs_root {
  * the FS
  */
 #define BTRFS_INODE_ITEM_KEY		1
-#define BTRFS_XATTR_ITEM_KEY		2
+#define BTRFS_INODE_REF_KEY		2
+#define BTRFS_XATTR_ITEM_KEY		8
 /* reserve 2-15 close to the inode for later flexibility */
 
 /*
@@ -486,6 +492,9 @@ BTRFS_SETGET_STACK_FUNCS(block_group_used, struct btrfs_block_group_item,
 BTRFS_SETGET_FUNCS(disk_block_group_used, struct btrfs_block_group_item,
 			 used, 64);
 
+/* struct btrfs_inode_ref */
+BTRFS_SETGET_FUNCS(inode_ref_name_len, struct btrfs_inode_ref, name_len, 16);
+
 /* struct btrfs_inode_item */
 BTRFS_SETGET_FUNCS(inode_generation, struct btrfs_inode_item, generation, 64);
 BTRFS_SETGET_FUNCS(inode_size, struct btrfs_inode_item, size, 64);
@@ -1043,6 +1052,14 @@ int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 int btrfs_find_highest_inode(struct btrfs_root *fs_root, u64 *objectid);
 
 /* inode-item.c */
+int btrfs_insert_inode_ref(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root,
+			   const char *name, int name_len,
+			   u64 inode_objectid, u64 ref_objectid);
+int btrfs_del_inode_ref(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root,
+			   const char *name, int name_len,
+			   u64 inode_objectid, u64 ref_objectid);
 int btrfs_insert_empty_inode(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid);

commit 7bb86316c3961d1bc401ef184fd996f999556c7f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 11 09:25:06 2007 -0500

    Btrfs: Add back pointers from extents to the btree or file referencing them
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fd58dd846e61..cb1b156d954e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -544,11 +544,12 @@ BTRFS_SETGET_FUNCS(ref_generation, struct btrfs_extent_ref, generation, 64);
 BTRFS_SETGET_FUNCS(ref_objectid, struct btrfs_extent_ref, objectid, 64);
 BTRFS_SETGET_FUNCS(ref_offset, struct btrfs_extent_ref, offset, 64);
 
-BTRFS_SETGET_STACK_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
-BTRFS_SETGET_STACK_FUNCS(ref_generation, struct btrfs_extent_ref,
+BTRFS_SETGET_STACK_FUNCS(stack_ref_root, struct btrfs_extent_ref, root, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_ref_generation, struct btrfs_extent_ref,
 			 generation, 64);
-BTRFS_SETGET_STACK_FUNCS(ref_objectid, struct btrfs_extent_ref, objectid, 64);
-BTRFS_SETGET_STACK_FUNCS(ref_offset, struct btrfs_extent_ref, offset, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_ref_objectid, struct btrfs_extent_ref,
+			 objectid, 64);
+BTRFS_SETGET_STACK_FUNCS(stack_ref_offset, struct btrfs_extent_ref, offset, 64);
 
 BTRFS_SETGET_STACK_FUNCS(stack_extent_refs, struct btrfs_extent_item,
 			 refs, 32);
@@ -914,24 +915,45 @@ struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 *hint, u64 search_start,
 						 int data, int owner);
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *root);
+		       struct btrfs_root *root, u64 owner_objectid);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root, u32 size,
+					    u64 root_objectid,
 					    u64 hint, u64 empty_size);
+struct extent_buffer *__btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
+					     struct btrfs_root *root,
+					     u32 blocksize,
+					     u64 root_objectid,
+					     u64 ref_generation,
+					     u64 first_objectid,
+					     int level,
+					     u64 hint,
+					     u64 empty_size);
+int btrfs_insert_extent_backref(struct btrfs_trans_handle *trans,
+				 struct btrfs_root *root,
+				 struct btrfs_path *path, u64 bytenr,
+				 u64 root_objectid, u64 ref_generation,
+				 u64 owner, u64 owner_offset);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *root, u64 owner,
-		       u64 num_bytes, u64 empty_size, u64 search_start,
+		       struct btrfs_root *root,
+		       u64 num_bytes, u64 root_objectid, u64 ref_generation,
+		       u64 owner, u64 owner_offset,
+		       u64 empty_size, u64 hint_byte,
 		       u64 search_end, struct btrfs_key *ins, int data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, u64 bytenr, u64 num_bytes, int pin);
+		      *root, u64 bytenr, u64 num_bytes,
+		      u64 root_objectid, u64 ref_generation,
+		      u64 owner_objectid, u64 owner_offset, int pin);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       struct extent_map_tree *unpin);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
-				u64 bytenr, u64 num_bytes);
+				u64 bytenr, u64 num_bytes,
+				u64 root_objectid, u64 ref_generation,
+				u64 owner, u64 owner_offset);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
@@ -966,6 +988,7 @@ int btrfs_insert_empty_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			    *root, struct btrfs_path *path, struct btrfs_key
 			    *cpu_key, u32 data_size);
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
+int btrfs_prev_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
 			*root);

commit 74493f7a59bfd4d1c7029c74ab2cd0e400612c6b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 11 09:25:06 2007 -0500

    Btrfs: Implement generation numbers in block pointers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9bc1b0a8615f..fd58dd846e61 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -110,7 +110,7 @@ struct btrfs_header {
 #define BTRFS_MAX_LEVEL 8
 #define BTRFS_NODEPTRS_PER_BLOCK(r) (((r)->nodesize - \
 			        sizeof(struct btrfs_header)) / \
-			       (sizeof(struct btrfs_disk_key) + sizeof(u64)))
+			        sizeof(struct btrfs_key_ptr))
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->leafsize))
 #define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
@@ -168,6 +168,7 @@ struct btrfs_leaf {
 struct btrfs_key_ptr {
 	struct btrfs_disk_key key;
 	__le64 blockptr;
+	__le64 generation;
 } __attribute__ ((__packed__));
 
 struct btrfs_node {
@@ -196,7 +197,13 @@ struct btrfs_path {
  */
 struct btrfs_extent_item {
 	__le32 refs;
-	__le64 owner;
+} __attribute__ ((__packed__));
+
+struct btrfs_extent_ref {
+	__le64 root;
+	__le64 generation;
+	__le64 objectid;
+	__le64 offset;
 } __attribute__ ((__packed__));
 
 struct btrfs_inode_timespec {
@@ -402,12 +409,13 @@ struct btrfs_root {
  * are used, and how many references there are to each block
  */
 #define BTRFS_EXTENT_ITEM_KEY	33
+#define BTRFS_EXTENT_REF_KEY	34
 
 /*
  * block groups give us hints into the extent allocation trees.  Which
  * blocks are free etc etc
  */
-#define BTRFS_BLOCK_GROUP_ITEM_KEY 34
+#define BTRFS_BLOCK_GROUP_ITEM_KEY 50
 
 /*
  * string items are for debugging.  They just store a short string of
@@ -529,15 +537,25 @@ BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_inode_timespec, nsec, 32);
 
 /* struct btrfs_extent_item */
 BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
-BTRFS_SETGET_FUNCS(extent_owner, struct btrfs_extent_item, owner, 64);
+
+/* struct btrfs_extent_ref */
+BTRFS_SETGET_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
+BTRFS_SETGET_FUNCS(ref_generation, struct btrfs_extent_ref, generation, 64);
+BTRFS_SETGET_FUNCS(ref_objectid, struct btrfs_extent_ref, objectid, 64);
+BTRFS_SETGET_FUNCS(ref_offset, struct btrfs_extent_ref, offset, 64);
+
+BTRFS_SETGET_STACK_FUNCS(ref_root, struct btrfs_extent_ref, root, 64);
+BTRFS_SETGET_STACK_FUNCS(ref_generation, struct btrfs_extent_ref,
+			 generation, 64);
+BTRFS_SETGET_STACK_FUNCS(ref_objectid, struct btrfs_extent_ref, objectid, 64);
+BTRFS_SETGET_STACK_FUNCS(ref_offset, struct btrfs_extent_ref, offset, 64);
 
 BTRFS_SETGET_STACK_FUNCS(stack_extent_refs, struct btrfs_extent_item,
 			 refs, 32);
-BTRFS_SETGET_STACK_FUNCS(stack_extent_owner, struct btrfs_extent_item,
-			 owner, 64);
 
 /* struct btrfs_node */
 BTRFS_SETGET_FUNCS(key_blockptr, struct btrfs_key_ptr, blockptr, 64);
+BTRFS_SETGET_FUNCS(key_generation, struct btrfs_key_ptr, generation, 64);
 
 static inline u64 btrfs_node_blockptr(struct extent_buffer *eb, int nr)
 {
@@ -556,6 +574,23 @@ static inline void btrfs_set_node_blockptr(struct extent_buffer *eb,
 	btrfs_set_key_blockptr(eb, (struct btrfs_key_ptr *)ptr, val);
 }
 
+static inline u64 btrfs_node_ptr_generation(struct extent_buffer *eb, int nr)
+{
+	unsigned long ptr;
+	ptr = offsetof(struct btrfs_node, ptrs) +
+		sizeof(struct btrfs_key_ptr) * nr;
+	return btrfs_key_generation(eb, (struct btrfs_key_ptr *)ptr);
+}
+
+static inline void btrfs_set_node_ptr_generation(struct extent_buffer *eb,
+						 int nr, u64 val)
+{
+	unsigned long ptr;
+	ptr = offsetof(struct btrfs_node, ptrs) +
+		sizeof(struct btrfs_key_ptr) * nr;
+	btrfs_set_key_generation(eb, (struct btrfs_key_ptr *)ptr, val);
+}
+
 static inline unsigned long btrfs_node_key_ptr_offset(int nr)
 {
 	return offsetof(struct btrfs_node, ptrs) +

commit 87ee04eb0f2f0c63314cef4a76bd1adac748425e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Nov 30 11:30:34 2007 -0500

    Btrfs: Add simple stripe size parameter
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b29b911dd825..9bc1b0a8615f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -135,6 +135,7 @@ struct btrfs_super_block {
 	__le32 sectorsize;
 	__le32 nodesize;
 	__le32 leafsize;
+	__le32 stripesize;
 	u8 root_level;
 } __attribute__ ((__packed__));
 
@@ -353,6 +354,8 @@ struct btrfs_root {
 	/* leaf allocations are done in leafsize units */
 	u32 leafsize;
 
+	u32 stripesize;
+
 	u32 type;
 	u64 highest_inode;
 	u64 last_inode_alloc;
@@ -776,6 +779,8 @@ BTRFS_SETGET_STACK_FUNCS(super_nodesize, struct btrfs_super_block,
 			 nodesize, 32);
 BTRFS_SETGET_STACK_FUNCS(super_leafsize, struct btrfs_super_block,
 			 leafsize, 32);
+BTRFS_SETGET_STACK_FUNCS(super_stripesize, struct btrfs_super_block,
+			 stripesize, 32);
 BTRFS_SETGET_STACK_FUNCS(super_root_dir, struct btrfs_super_block,
 			 root_dir_objectid, 64);
 

commit 00f5c795fca47d038fedd3f0c9311da3be710c9f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Nov 30 10:09:33 2007 -0500

    btrfs_drop_extents: make sure the item is getting smaller before truncate
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 56b977ffe918..b29b911dd825 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1037,7 +1037,7 @@ int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end);
 extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
-		       u64 start, u64 end, u64 inline_end, u64 *hint_block);
+		       u64 start, u64 end, u64 inline_limit, u64 *hint_block);
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only);

commit 324ae4df00fdc1a6a179bf584d8addf027bb75fb
Author: Yan <yanzheng@21cn.com>
Date:   Fri Nov 16 14:57:08 2007 -0500

    Btrfs: Add block group pinned accounting back
    
    This patch adds a helper function 'update_pinned_extents' to
    extent-tree.c. The usage of the helper function is similar to
    'update_block_group',  the last parameter of the function indicates
    pin vs unpin.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 27cadae1af63..56b977ffe918 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -292,8 +292,8 @@ struct btrfs_block_group_cache {
 	struct btrfs_block_group_item item;
 	int data;
 	int cached;
+	u64 pinned;
 };
-
 struct btrfs_fs_info {
 	u8 fsid[BTRFS_FSID_SIZE];
 	struct btrfs_root *extent_root;
@@ -324,8 +324,9 @@ struct btrfs_fs_info {
 	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
-};
 
+	u64 total_pinned;
+};
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.

commit 5103e947b9b7ac18ddb21a04ee3486e94c6504d7
Author: Josef Bacik <jbacik@redhat.com>
Date:   Fri Nov 16 11:45:54 2007 -0500

    xattr support for btrfs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 030d21d7f98c..27cadae1af63 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -63,7 +63,8 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_FT_FIFO		5
 #define BTRFS_FT_SOCK		6
 #define BTRFS_FT_SYMLINK	7
-#define BTRFS_FT_MAX		8
+#define BTRFS_FT_XATTR		8
+#define BTRFS_FT_MAX		9
 
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
@@ -226,7 +227,7 @@ struct btrfs_inode_item {
 
 struct btrfs_dir_item {
 	struct btrfs_disk_key location;
-	__le16 flags;
+	__le16 data_len;
 	__le16 name_len;
 	u8 type;
 } __attribute__ ((__packed__));
@@ -367,7 +368,7 @@ struct btrfs_root {
  * the FS
  */
 #define BTRFS_INODE_ITEM_KEY		1
-
+#define BTRFS_XATTR_ITEM_KEY		2
 /* reserve 2-15 close to the inode for later flexibility */
 
 /*
@@ -621,7 +622,7 @@ static inline void btrfs_set_item_key(struct extent_buffer *eb,
 }
 
 /* struct btrfs_dir_item */
-BTRFS_SETGET_FUNCS(dir_flags, struct btrfs_dir_item, flags, 16);
+BTRFS_SETGET_FUNCS(dir_data_len, struct btrfs_dir_item, data_len, 16);
 BTRFS_SETGET_FUNCS(dir_type, struct btrfs_dir_item, type, 8);
 BTRFS_SETGET_FUNCS(dir_name_len, struct btrfs_dir_item, name_len, 16);
 
@@ -962,6 +963,15 @@ int btrfs_delete_one_dir_name(struct btrfs_trans_handle *trans,
 			      struct btrfs_root *root,
 			      struct btrfs_path *path,
 			      struct btrfs_dir_item *di);
+int btrfs_insert_xattr_item(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root, const char *name,
+			    u16 name_len, const void *data, u16 data_len,
+			    u64 dir);
+struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,
+					  struct btrfs_root *root,
+					  struct btrfs_path *path, u64 dir,
+					  const char *name, u16 name_len,
+					  int mod);
 /* inode-map.c */
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *fs_root,
@@ -1039,4 +1049,8 @@ int btrfs_sysfs_add_root(struct btrfs_root *root);
 void btrfs_sysfs_del_root(struct btrfs_root *root);
 void btrfs_sysfs_del_super(struct btrfs_fs_info *root);
 
+/* xattr.c */
+ssize_t btrfs_listxattr(struct dentry *dentry, char *buffer, size_t size);
+int btrfs_delete_xattrs(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root, struct inode *inode);
 #endif

commit e644d021e328d3902559e5db687383f2da85993c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 6 15:09:29 2007 -0500

    Fix recursive KM_USER1 usage in btrfs_realloc_node
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f7907b02fa77..030d21d7f98c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -557,14 +557,9 @@ static inline unsigned long btrfs_node_key_ptr_offset(int nr)
 		sizeof(struct btrfs_key_ptr) * nr;
 }
 
-static inline void btrfs_node_key(struct extent_buffer *eb,
-			   struct btrfs_disk_key *disk_key, int nr)
-{
-	unsigned long ptr;
-	ptr = btrfs_node_key_ptr_offset(nr);
-	read_eb_member(eb, (struct btrfs_key_ptr *)ptr,
-		       struct btrfs_key_ptr, key, disk_key);
-}
+void btrfs_node_key(struct extent_buffer *eb,
+		    struct btrfs_disk_key *disk_key, int nr);
+
 static inline void btrfs_set_node_key(struct extent_buffer *eb,
 				      struct btrfs_disk_key *disk_key, int nr)
 {

commit f84a8b362d9785ca1fa0598d8a90f35184bd8750
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 6 10:26:29 2007 -0500

    Btrfs: Optimize allocations as we need to mix data and metadata into one group
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d82afb618bf1..f7907b02fa77 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -279,6 +279,8 @@ struct btrfs_csum_item {
 
 
 #define BTRFS_BLOCK_GROUP_DATA 1
+#define BTRFS_BLOCK_GROUP_MIXED 2
+
 struct btrfs_block_group_item {
 	__le64 used;
 	u8 flags;

commit 179e29e488cc74f1e9bd67bc45f70b832740e9ec
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 1 11:28:41 2007 -0400

    Btrfs: Fix a number of inline extent problems that Yan Zheng reported.
    
    The fixes do a number of things:
    
    1) Most btrfs_drop_extent callers will try to leave the inline extents in
    place.  It can truncate bytes off the beginning of the inline extent if
    required.
    
    2) writepage can now update the inline extent, allowing mmap writes to
    go directly into the inline extent.
    
    3) btrfs_truncate_in_transaction truncates inline extents
    
    4) extent_map.c fixed to not merge inline extent mappings and hole
    mappings together
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 70e143b13577..d82afb618bf1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -907,7 +907,7 @@ int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_truncate_item(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root,
 			struct btrfs_path *path,
-			u32 new_size);
+			u32 new_size, int from_end);
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);

commit f578d4bd7e141dd03ca7e8695c1cc118c326e69e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Oct 25 15:42:56 2007 -0400

    Btrfs: Optimize csum insertion to create larger items when possible
    
    This reduces the number of calls to btrfs_extend_item and greatly lowers
    the cpu usage while writing large files.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1d2b54150075..70e143b13577 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -991,6 +991,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     u64 bytenr, int mod);
 int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
+			  struct inode *inode,
 			  u64 objectid, u64 offset,
 			  char *data, size_t len);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,

commit 6d7231f7d33fc14f2d41abc3b9cb28dcb208735d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Oct 19 09:22:49 2007 -0400

    Btrfs: Fix typo: owner is a 64 bit field
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 37bccb1a9a75..1d2b54150075 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -522,12 +522,12 @@ BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_inode_timespec, nsec, 32);
 
 /* struct btrfs_extent_item */
 BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
-BTRFS_SETGET_FUNCS(extent_owner, struct btrfs_extent_item, owner, 32);
+BTRFS_SETGET_FUNCS(extent_owner, struct btrfs_extent_item, owner, 64);
 
 BTRFS_SETGET_STACK_FUNCS(stack_extent_refs, struct btrfs_extent_item,
 			 refs, 32);
 BTRFS_SETGET_STACK_FUNCS(stack_extent_owner, struct btrfs_extent_item,
-			 owner, 32);
+			 owner, 64);
 
 /* struct btrfs_node */
 BTRFS_SETGET_FUNCS(key_blockptr, struct btrfs_key_ptr, blockptr, 64);

commit a6b6e75e096f436f0cc56edf5bca96301e194491
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:22:39 2007 -0400

    Btrfs: Defrag only leaves, and only when the parent node has a single objectid
    
    This allows us to defrag huge directories, but skip the expensive defrag
    case in more common usage, where it does not help as much.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1af0a966f85b..37bccb1a9a75 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -913,7 +913,8 @@ int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      ins_len, int cow);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct extent_buffer *parent,
-		       int cache_only, u64 *last_ret);
+		       int start_slot, int cache_only, u64 *last_ret,
+		       struct btrfs_key *progress);
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);

commit 19c00ddcc31ad4bdfb86b57085e06d6135b9b1d7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:19:22 2007 -0400

    Btrfs: Add back metadata checksumming
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d1c6f023a302..1af0a966f85b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -310,9 +310,11 @@ struct btrfs_fs_info {
 	struct extent_buffer *sb_buffer;
 	struct super_block *sb;
 	struct inode *btree_inode;
+	spinlock_t hash_lock;
 	struct mutex trans_mutex;
 	struct mutex fs_mutex;
 	struct list_head trans_list;
+	struct list_head hashers;
 	struct list_head dead_roots;
 	struct delayed_work trans_work;
 	struct kobject super_kobj;

commit 0f82731fc56448c2733f58e1f5db6c2cbfc90652
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:18:56 2007 -0400

    Breakout BTRFS_SETGET_FUNCS into a separate C file, the inlines were too big.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a942a2427228..d1c6f023a302 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -426,77 +426,11 @@ struct btrfs_root {
 			    offsetof(type, member),			\
 			   sizeof(((type *)0)->member)))
 
+#ifndef BTRFS_SETGET_FUNCS
 #define BTRFS_SETGET_FUNCS(name, type, member, bits)			\
-static inline u##bits btrfs_##name(struct extent_buffer *eb,		\
-				   type *s)				\
-{									\
-	int err;							\
-	char *map_token;						\
-	char *kaddr;							\
-	int unmap_on_exit = (eb->map_token == NULL);			\
-	unsigned long map_start;					\
-	unsigned long map_len;						\
-	unsigned long offset = (unsigned long)s +			\
-				offsetof(type, member);			\
-	if (eb->map_token && offset >= eb->map_start &&			\
-	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
-	    eb->map_len) {						\
-	    kaddr = eb->kaddr;						\
-	    map_start = eb->map_start;					\
-	    err = 0;							\
-	} else {							\
-		err = map_extent_buffer(eb, offset,			\
-			        sizeof(((type *)0)->member),		\
-				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER1);	\
-	}								\
-	if (!err) {							\
-		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
-					       map_start);		\
-		u##bits res = le##bits##_to_cpu(*tmp);			\
-		if (unmap_on_exit)					\
-			unmap_extent_buffer(eb, map_token, KM_USER1);	\
-		return res;						\
-	} else {							\
-		__le##bits res;						\
-		read_eb_member(eb, s, type, member, &res);		\
-		return le##bits##_to_cpu(res);				\
-	}								\
-}									\
-static inline void btrfs_set_##name(struct extent_buffer *eb,		\
-				    type *s, u##bits val)		\
-{									\
-	int err;							\
-	char *map_token;						\
-	char *kaddr;							\
-	unsigned long map_start;					\
-	unsigned long map_len;						\
-	int unmap_on_exit = (eb->map_token == NULL);			\
-	unsigned long offset = (unsigned long)s +			\
-				offsetof(type, member);			\
-	if (eb->map_token && offset >= eb->map_start &&			\
-	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
-	    eb->map_len) {						\
-	    kaddr = eb->kaddr;						\
-	    map_start = eb->map_start;					\
-	    err = 0;							\
-	} else {							\
-		err = map_extent_buffer(eb, offset,			\
-			        sizeof(((type *)0)->member),		\
-				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER1);	\
-	}								\
-	if (!err) {							\
-		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
-					       map_start);		\
-		*tmp = cpu_to_le##bits(val);				\
-		if (unmap_on_exit)					\
-			unmap_extent_buffer(eb, map_token, KM_USER1);	\
-	} else {							\
-		val = cpu_to_le##bits(val);				\
-		write_eb_member(eb, s, type, member, &val);		\
-	}								\
-}
+u##bits btrfs_##name(struct extent_buffer *eb, type *s);		\
+void btrfs_set_##name(struct extent_buffer *eb, type *s, u##bits val);
+#endif
 
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
 static inline u##bits btrfs_##name(struct extent_buffer *eb)		\

commit 810191ff3087e8143b41a944fcf4fd8c693f00e3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:18:55 2007 -0400

    Btrfs: extent_map optimizations to cut down on CPU usage
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 18994c53106c..a942a2427228 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -19,6 +19,8 @@
 #ifndef __BTRFS__
 #define __BTRFS__
 
+#include <linux/mm.h>
+#include <linux/highmem.h>
 #include <linux/fs.h>
 #include <linux/workqueue.h>
 #include <linux/completion.h>
@@ -499,70 +501,22 @@ static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
 static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
 {									\
-	int err;							\
-	char *map_token;						\
-	char *kaddr;							\
-	unsigned long map_start;					\
-	unsigned long map_len;						\
+	char *kaddr = kmap_atomic(eb->first_page, KM_USER0);		\
 	unsigned long offset = offsetof(type, member);			\
-	int unmap_on_exit = (eb->map_token == NULL);			\
-	if (eb->map_token && offset >= eb->map_start &&			\
-	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
-	    eb->map_len) {						\
-	    kaddr = eb->kaddr;						\
-	    map_start = eb->map_start;					\
-	    err = 0;							\
-	} else {							\
-		err = map_extent_buffer(eb, offset,			\
-			        sizeof(((type *)0)->member),		\
-				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER1);	\
-	}								\
-	if (!err) {							\
-		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
-					       map_start);		\
-		u##bits res = le##bits##_to_cpu(*tmp);			\
-		if (unmap_on_exit)					\
-			unmap_extent_buffer(eb, map_token, KM_USER1);	\
-		return res;						\
-	} else {							\
-		__le##bits res;						\
-		read_eb_member(eb, NULL, type, member, &res);		\
-		return le##bits##_to_cpu(res);				\
-	}								\
+	u##bits res;							\
+	__le##bits *tmp = (__le##bits *)(kaddr + offset);		\
+	res = le##bits##_to_cpu(*tmp);					\
+	kunmap_atomic(kaddr, KM_USER0);					\
+	return res;							\
 }									\
 static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 				    u##bits val)			\
 {									\
-	int err;							\
-	char *map_token;						\
-	char *kaddr;							\
-	unsigned long map_start;					\
-	unsigned long map_len;						\
+	char *kaddr = kmap_atomic(eb->first_page, KM_USER0);		\
 	unsigned long offset = offsetof(type, member);			\
-	int unmap_on_exit = (eb->map_token == NULL);			\
-	if (eb->map_token && offset >= eb->map_start &&			\
-	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
-	    eb->map_len) {						\
-	    kaddr = eb->kaddr;						\
-	    map_start = eb->map_start;					\
-	    err = 0;							\
-	} else {							\
-		err = map_extent_buffer(eb, offset,			\
-			        sizeof(((type *)0)->member),		\
-				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER1);	\
-	}								\
-	if (!err) {							\
-		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
-					       map_start);		\
-		*tmp = cpu_to_le##bits(val);				\
-		if (unmap_on_exit)					\
-			unmap_extent_buffer(eb, map_token, KM_USER1);	\
-	} else {							\
-		val = cpu_to_le##bits(val);				\
-		write_eb_member(eb, NULL, type, member, &val);		\
-	}								\
+	__le##bits *tmp = (__le##bits *)(kaddr + offset);		\
+	*tmp = cpu_to_le##bits(val);					\
+	kunmap_atomic(kaddr, KM_USER0);					\
 }
 
 #define BTRFS_SETGET_STACK_FUNCS(name, type, member, bits)		\
@@ -659,13 +613,13 @@ static inline void btrfs_set_node_blockptr(struct extent_buffer *eb,
 	btrfs_set_key_blockptr(eb, (struct btrfs_key_ptr *)ptr, val);
 }
 
-static unsigned long btrfs_node_key_ptr_offset(int nr)
+static inline unsigned long btrfs_node_key_ptr_offset(int nr)
 {
 	return offsetof(struct btrfs_node, ptrs) +
 		sizeof(struct btrfs_key_ptr) * nr;
 }
 
-static void btrfs_node_key(struct extent_buffer *eb,
+static inline void btrfs_node_key(struct extent_buffer *eb,
 			   struct btrfs_disk_key *disk_key, int nr)
 {
 	unsigned long ptr;

commit 3326d1b07c0cb6a2ff5b835b7a2cffa54124d074
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:18:25 2007 -0400

    Btrfs: Allow tails larger than one page
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 54c754dd9a14..18994c53106c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1137,7 +1137,7 @@ int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end);
 extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
-		       u64 start, u64 end, u64 *hint_block);
+		       u64 start, u64 end, u64 inline_end, u64 *hint_block);
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only);

commit 14048ed0c415b8729b194e92c16d31c61628d216
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:16:28 2007 -0400

    Btrfs: Cache extent buffer mappings
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4d05456ec32f..54c754dd9a14 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -436,10 +436,18 @@ static inline u##bits btrfs_##name(struct extent_buffer *eb,		\
 	unsigned long map_len;						\
 	unsigned long offset = (unsigned long)s +			\
 				offsetof(type, member);			\
-	err = map_extent_buffer(eb, offset,				\
+	if (eb->map_token && offset >= eb->map_start &&			\
+	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
+	    eb->map_len) {						\
+	    kaddr = eb->kaddr;						\
+	    map_start = eb->map_start;					\
+	    err = 0;							\
+	} else {							\
+		err = map_extent_buffer(eb, offset,			\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
 				&map_start, &map_len, KM_USER1);	\
+	}								\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\
@@ -464,10 +472,18 @@ static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 	int unmap_on_exit = (eb->map_token == NULL);			\
 	unsigned long offset = (unsigned long)s +			\
 				offsetof(type, member);			\
-	err = map_extent_buffer(eb, offset,				\
+	if (eb->map_token && offset >= eb->map_start &&			\
+	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
+	    eb->map_len) {						\
+	    kaddr = eb->kaddr;						\
+	    map_start = eb->map_start;					\
+	    err = 0;							\
+	} else {							\
+		err = map_extent_buffer(eb, offset,			\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
 				&map_start, &map_len, KM_USER1);	\
+	}								\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\
@@ -490,10 +506,18 @@ static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
 	unsigned long map_len;						\
 	unsigned long offset = offsetof(type, member);			\
 	int unmap_on_exit = (eb->map_token == NULL);			\
-	err = map_extent_buffer(eb, offset,				\
+	if (eb->map_token && offset >= eb->map_start &&			\
+	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
+	    eb->map_len) {						\
+	    kaddr = eb->kaddr;						\
+	    map_start = eb->map_start;					\
+	    err = 0;							\
+	} else {							\
+		err = map_extent_buffer(eb, offset,			\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
 				&map_start, &map_len, KM_USER1);	\
+	}								\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\
@@ -517,10 +541,18 @@ static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 	unsigned long map_len;						\
 	unsigned long offset = offsetof(type, member);			\
 	int unmap_on_exit = (eb->map_token == NULL);			\
-	err = map_extent_buffer(eb, offset,				\
+	if (eb->map_token && offset >= eb->map_start &&			\
+	    offset + sizeof(((type *)0)->member) <= eb->map_start +	\
+	    eb->map_len) {						\
+	    kaddr = eb->kaddr;						\
+	    map_start = eb->map_start;					\
+	    err = 0;							\
+	} else {							\
+		err = map_extent_buffer(eb, offset,			\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
 				&map_start, &map_len, KM_USER1);	\
+	}								\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\

commit db94535db75e67fab12ccbb7f5ee548e33fed891
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:53 2007 -0400

    Btrfs: Allow tree blocks larger than the page size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 256689551eb0..4d05456ec32f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -96,7 +96,7 @@ struct btrfs_key {
 struct btrfs_header {
 	u8 csum[BTRFS_CSUM_SIZE];
 	u8 fsid[BTRFS_FSID_SIZE]; /* FS specific uuid */
-	__le64 blocknr; /* which block this node is supposed to live in */
+	__le64 bytenr; /* which block this node is supposed to live in */
 	__le64 generation;
 	__le64 owner;
 	__le32 nritems;
@@ -122,16 +122,17 @@ struct btrfs_super_block {
 	u8 csum[BTRFS_CSUM_SIZE];
 	/* the first 3 fields must match struct btrfs_header */
 	u8 fsid[16];    /* FS specific uuid */
-	__le64 blocknr; /* this block number */
+	__le64 bytenr; /* this block number */
 	__le64 magic;
 	__le64 generation;
 	__le64 root;
-	__le64 total_blocks;
-	__le64 blocks_used;
+	__le64 total_bytes;
+	__le64 bytes_used;
 	__le64 root_dir_objectid;
 	__le32 sectorsize;
 	__le32 nodesize;
 	__le32 leafsize;
+	u8 root_level;
 } __attribute__ ((__packed__));
 
 /*
@@ -231,13 +232,14 @@ struct btrfs_dir_item {
 struct btrfs_root_item {
 	struct btrfs_inode_item inode;
 	__le64 root_dirid;
-	__le64 blocknr;
-	__le64 block_limit;
-	__le64 blocks_used;
+	__le64 bytenr;
+	__le64 byte_limit;
+	__le64 bytes_used;
 	__le32 flags;
 	__le32 refs;
 	struct btrfs_disk_key drop_progress;
 	u8 drop_level;
+	u8 level;
 } __attribute__ ((__packed__));
 
 #define BTRFS_FILE_EXTENT_REG 0
@@ -250,8 +252,8 @@ struct btrfs_file_extent_item {
 	 * disk space consumed by the extent, checksum blocks are included
 	 * in these numbers
 	 */
-	__le64 disk_blocknr;
-	__le64 disk_num_blocks;
+	__le64 disk_bytenr;
+	__le64 disk_num_bytes;
 	/*
 	 * the logical offset in file blocks (no csums)
 	 * this extent record is for.  This allows a file extent to point
@@ -263,7 +265,7 @@ struct btrfs_file_extent_item {
 	/*
 	 * the logical number of file blocks (no csums included)
 	 */
-	__le64 num_blocks;
+	__le64 num_bytes;
 } __attribute__ ((__packed__));
 
 struct btrfs_csum_item {
@@ -429,6 +431,7 @@ static inline u##bits btrfs_##name(struct extent_buffer *eb,		\
 	int err;							\
 	char *map_token;						\
 	char *kaddr;							\
+	int unmap_on_exit = (eb->map_token == NULL);			\
 	unsigned long map_start;					\
 	unsigned long map_len;						\
 	unsigned long offset = (unsigned long)s +			\
@@ -436,12 +439,13 @@ static inline u##bits btrfs_##name(struct extent_buffer *eb,		\
 	err = map_extent_buffer(eb, offset,				\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER0);	\
+				&map_start, &map_len, KM_USER1);	\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\
 		u##bits res = le##bits##_to_cpu(*tmp);			\
-		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+		if (unmap_on_exit)					\
+			unmap_extent_buffer(eb, map_token, KM_USER1);	\
 		return res;						\
 	} else {							\
 		__le##bits res;						\
@@ -457,17 +461,19 @@ static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 	char *kaddr;							\
 	unsigned long map_start;					\
 	unsigned long map_len;						\
+	int unmap_on_exit = (eb->map_token == NULL);			\
 	unsigned long offset = (unsigned long)s +			\
 				offsetof(type, member);			\
 	err = map_extent_buffer(eb, offset,				\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER0);	\
+				&map_start, &map_len, KM_USER1);	\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\
 		*tmp = cpu_to_le##bits(val);				\
-		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+		if (unmap_on_exit)					\
+			unmap_extent_buffer(eb, map_token, KM_USER1);	\
 	} else {							\
 		val = cpu_to_le##bits(val);				\
 		write_eb_member(eb, s, type, member, &val);		\
@@ -483,15 +489,17 @@ static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
 	unsigned long map_start;					\
 	unsigned long map_len;						\
 	unsigned long offset = offsetof(type, member);			\
+	int unmap_on_exit = (eb->map_token == NULL);			\
 	err = map_extent_buffer(eb, offset,				\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER0);	\
+				&map_start, &map_len, KM_USER1);	\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\
 		u##bits res = le##bits##_to_cpu(*tmp);			\
-		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+		if (unmap_on_exit)					\
+			unmap_extent_buffer(eb, map_token, KM_USER1);	\
 		return res;						\
 	} else {							\
 		__le##bits res;						\
@@ -508,15 +516,17 @@ static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 	unsigned long map_start;					\
 	unsigned long map_len;						\
 	unsigned long offset = offsetof(type, member);			\
+	int unmap_on_exit = (eb->map_token == NULL);			\
 	err = map_extent_buffer(eb, offset,				\
 			        sizeof(((type *)0)->member),		\
 				&map_token, &kaddr,			\
-				&map_start, &map_len, KM_USER0);	\
+				&map_start, &map_len, KM_USER1);	\
 	if (!err) {							\
 		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
 					       map_start);		\
 		*tmp = cpu_to_le##bits(val);				\
-		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+		if (unmap_on_exit)					\
+			unmap_extent_buffer(eb, map_token, KM_USER1);	\
 	} else {							\
 		val = cpu_to_le##bits(val);				\
 		write_eb_member(eb, NULL, type, member, &val);		\
@@ -769,7 +779,7 @@ static inline void btrfs_set_key_type(struct btrfs_key *key, u8 val)
 }
 
 /* struct btrfs_header */
-BTRFS_SETGET_HEADER_FUNCS(header_blocknr, struct btrfs_header, blocknr, 64);
+BTRFS_SETGET_HEADER_FUNCS(header_bytenr, struct btrfs_header, bytenr, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_generation, struct btrfs_header,
 			  generation, 64);
 BTRFS_SETGET_HEADER_FUNCS(header_owner, struct btrfs_header, owner, 64);
@@ -817,24 +827,28 @@ static inline int btrfs_is_leaf(struct extent_buffer *eb)
 
 /* struct btrfs_root_item */
 BTRFS_SETGET_FUNCS(disk_root_refs, struct btrfs_root_item, refs, 32);
-BTRFS_SETGET_FUNCS(disk_root_blocknr, struct btrfs_root_item, blocknr, 64);
+BTRFS_SETGET_FUNCS(disk_root_bytenr, struct btrfs_root_item, bytenr, 64);
+BTRFS_SETGET_FUNCS(disk_root_level, struct btrfs_root_item, level, 8);
 
-BTRFS_SETGET_STACK_FUNCS(root_blocknr, struct btrfs_root_item, blocknr, 64);
+BTRFS_SETGET_STACK_FUNCS(root_bytenr, struct btrfs_root_item, bytenr, 64);
+BTRFS_SETGET_STACK_FUNCS(root_level, struct btrfs_root_item, level, 8);
 BTRFS_SETGET_STACK_FUNCS(root_dirid, struct btrfs_root_item, root_dirid, 64);
 BTRFS_SETGET_STACK_FUNCS(root_refs, struct btrfs_root_item, refs, 32);
 BTRFS_SETGET_STACK_FUNCS(root_flags, struct btrfs_root_item, flags, 32);
-BTRFS_SETGET_STACK_FUNCS(root_used, struct btrfs_root_item, blocks_used, 64);
-BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, block_limit, 64);
+BTRFS_SETGET_STACK_FUNCS(root_used, struct btrfs_root_item, bytes_used, 64);
+BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, byte_limit, 64);
 
 /* struct btrfs_super_block */
-BTRFS_SETGET_STACK_FUNCS(super_blocknr, struct btrfs_super_block, blocknr, 64);
+BTRFS_SETGET_STACK_FUNCS(super_bytenr, struct btrfs_super_block, bytenr, 64);
 BTRFS_SETGET_STACK_FUNCS(super_generation, struct btrfs_super_block,
 			 generation, 64);
 BTRFS_SETGET_STACK_FUNCS(super_root, struct btrfs_super_block, root, 64);
-BTRFS_SETGET_STACK_FUNCS(super_total_blocks, struct btrfs_super_block,
-		   total_blocks, 64);
-BTRFS_SETGET_STACK_FUNCS(super_blocks_used, struct btrfs_super_block,
-		   blocks_used, 64);
+BTRFS_SETGET_STACK_FUNCS(super_root_level, struct btrfs_super_block,
+			 root_level, 8);
+BTRFS_SETGET_STACK_FUNCS(super_total_bytes, struct btrfs_super_block,
+			 total_bytes, 64);
+BTRFS_SETGET_STACK_FUNCS(super_bytes_used, struct btrfs_super_block,
+			 bytes_used, 64);
 BTRFS_SETGET_STACK_FUNCS(super_sectorsize, struct btrfs_super_block,
 			 sectorsize, 32);
 BTRFS_SETGET_STACK_FUNCS(super_nodesize, struct btrfs_super_block,
@@ -856,33 +870,33 @@ static inline unsigned long btrfs_file_extent_inline_start(struct
 						   btrfs_file_extent_item *e)
 {
 	unsigned long offset = (unsigned long)e;
-	offset += offsetof(struct btrfs_file_extent_item, disk_blocknr);
+	offset += offsetof(struct btrfs_file_extent_item, disk_bytenr);
 	return offset;
 }
 
 static inline u32 btrfs_file_extent_calc_inline_size(u32 datasize)
 {
-	return offsetof(struct btrfs_file_extent_item, disk_blocknr) + datasize;
+	return offsetof(struct btrfs_file_extent_item, disk_bytenr) + datasize;
 }
 
 static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
 					       struct btrfs_item *e)
 {
 	unsigned long offset;
-	offset = offsetof(struct btrfs_file_extent_item, disk_blocknr);
+	offset = offsetof(struct btrfs_file_extent_item, disk_bytenr);
 	return btrfs_item_size(eb, e) - offset;
 }
 
-BTRFS_SETGET_FUNCS(file_extent_disk_blocknr, struct btrfs_file_extent_item,
-		   disk_blocknr, 64);
+BTRFS_SETGET_FUNCS(file_extent_disk_bytenr, struct btrfs_file_extent_item,
+		   disk_bytenr, 64);
 BTRFS_SETGET_FUNCS(file_extent_generation, struct btrfs_file_extent_item,
 		   generation, 64);
-BTRFS_SETGET_FUNCS(file_extent_disk_num_blocks, struct btrfs_file_extent_item,
-		   disk_num_blocks, 64);
+BTRFS_SETGET_FUNCS(file_extent_disk_num_bytes, struct btrfs_file_extent_item,
+		   disk_num_bytes, 64);
 BTRFS_SETGET_FUNCS(file_extent_offset, struct btrfs_file_extent_item,
 		  offset, 64);
-BTRFS_SETGET_FUNCS(file_extent_num_blocks, struct btrfs_file_extent_item,
-		   num_blocks, 64);
+BTRFS_SETGET_FUNCS(file_extent_num_bytes, struct btrfs_file_extent_item,
+		   num_bytes, 64);
 
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
@@ -906,6 +920,12 @@ static inline int btrfs_set_root_name(struct btrfs_root *root,
 	return 0;
 }
 
+static inline u32 btrfs_level_size(struct btrfs_root *root, int level) {
+	if (level == 0)
+		return root->leafsize;
+	return root->nodesize;
+}
+
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
@@ -927,7 +947,7 @@ int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 int btrfs_copy_pinned(struct btrfs_root *root, struct extent_map_tree *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
 							 btrfs_fs_info *info,
-							 u64 blocknr);
+							 u64 bytenr);
 struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 struct btrfs_block_group_cache
 						 *hint, u64 search_start,
@@ -935,22 +955,22 @@ struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
 struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
-					    struct btrfs_root *root, u64 hint,
-					    u64 empty_size);
+					    struct btrfs_root *root, u32 size,
+					    u64 hint, u64 empty_size);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, u64 owner,
-		       u64 num_blocks, u64 empty_size, u64 search_start,
+		       u64 num_bytes, u64 empty_size, u64 search_start,
 		       u64 search_end, struct btrfs_key *ins, int data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct extent_buffer *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, u64 blocknr, u64 num_blocks, int pin);
+		      *root, u64 bytenr, u64 num_bytes, int pin);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       struct extent_map_tree *unpin);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
-				u64 blocknr, u64 num_blocks);
+				u64 bytenr, u64 num_bytes);
 int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 				    struct btrfs_root *root);
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
@@ -1040,12 +1060,12 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       u64 objectid, u64 pos, u64 offset,
-			       u64 disk_num_blocks,
-			       u64 num_blocks);
+			       u64 disk_num_bytes,
+			       u64 num_bytes);
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
-			     u64 blocknr, int mod);
+			     u64 bytenr, int mod);
 int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset,

commit 1a5bc167f6707542b79a55452075525620ed43f5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:26 2007 -0400

    Btrfs: Change the remaining radix trees used by extent-tree.c to extent_map trees
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c6174b27fd13..256689551eb0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -283,10 +283,6 @@ struct btrfs_block_group_item {
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
-	u64 first_free;
-	u64 last_alloc;
-	u64 pinned;
-	u64 last_prealloc;
 	int data;
 	int cached;
 };
@@ -296,11 +292,13 @@ struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct radix_tree_root fs_roots_radix;
-	struct radix_tree_root pending_del_radix;
-	struct radix_tree_root pinned_radix;
-	struct radix_tree_root extent_ins_radix;
+
 	struct extent_map_tree free_space_cache;
 	struct extent_map_tree block_group_cache;
+	struct extent_map_tree pinned_extents;
+	struct extent_map_tree pending_del;
+	struct extent_map_tree extent_ins;
+
 	u64 generation;
 	u64 last_trans_committed;
 	struct btrfs_transaction *running_transaction;
@@ -926,7 +924,7 @@ static inline int btrfs_set_root_name(struct btrfs_root *root,
 /* extent-tree.c */
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);
-int btrfs_copy_pinned(struct btrfs_root *root, struct radix_tree_root *copy);
+int btrfs_copy_pinned(struct btrfs_root *root, struct extent_map_tree *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
 							 btrfs_fs_info *info,
 							 u64 blocknr);
@@ -949,7 +947,7 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 blocknr, u64 num_blocks, int pin);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
-			       struct radix_tree_root *unpin_radix);
+			       struct extent_map_tree *unpin);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 blocknr, u64 num_blocks);

commit 96b5179d0d9b6368c203856f2ad6e8e12a8b2a2c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:19 2007 -0400

    Btrfs: Stop using radix trees for the block group cache
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5262b28f468c..c6174b27fd13 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -271,8 +271,6 @@ struct btrfs_csum_item {
 } __attribute__ ((__packed__));
 
 /* tag for the radix tree of block groups in ram */
-#define BTRFS_BLOCK_GROUP_DIRTY 0
-#define BTRFS_BLOCK_GROUP_AVAIL 1
 #define BTRFS_BLOCK_GROUP_SIZE (256 * 1024 * 1024)
 
 
@@ -285,7 +283,6 @@ struct btrfs_block_group_item {
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
-	struct radix_tree_root *radix;
 	u64 first_free;
 	u64 last_alloc;
 	u64 pinned;
@@ -301,10 +298,9 @@ struct btrfs_fs_info {
 	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
-	struct radix_tree_root block_group_radix;
-	struct radix_tree_root block_group_data_radix;
 	struct radix_tree_root extent_ins_radix;
 	struct extent_map_tree free_space_cache;
+	struct extent_map_tree block_group_cache;
 	u64 generation;
 	u64 last_trans_committed;
 	struct btrfs_transaction *running_transaction;

commit f510cfecfc98759d75283823cfccf0cc0d59a4c6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:48 2007 -0400

    Btrfs: Fix extent_buffer and extent_state leaks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index aed08618aca6..5262b28f468c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -303,8 +303,8 @@ struct btrfs_fs_info {
 	struct radix_tree_root pinned_radix;
 	struct radix_tree_root block_group_radix;
 	struct radix_tree_root block_group_data_radix;
-	struct radix_tree_root extent_map_radix;
 	struct radix_tree_root extent_ins_radix;
+	struct extent_map_tree free_space_cache;
 	u64 generation;
 	u64 last_trans_committed;
 	struct btrfs_transaction *running_transaction;

commit 6d36dcd48f1e4e7446d603a3df9638bd314a182d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:37 2007 -0400

    Btrfs: Avoid memcpy where possible in extent_buffers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 30fbbd7221a9..aed08618aca6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -483,15 +483,50 @@ static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
 static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
 {									\
-	__le##bits res;							\
-	read_eb_member(eb, NULL, type, member, &res);			\
-	return le##bits##_to_cpu(res);					\
+	int err;							\
+	char *map_token;						\
+	char *kaddr;							\
+	unsigned long map_start;					\
+	unsigned long map_len;						\
+	unsigned long offset = offsetof(type, member);			\
+	err = map_extent_buffer(eb, offset,				\
+			        sizeof(((type *)0)->member),		\
+				&map_token, &kaddr,			\
+				&map_start, &map_len, KM_USER0);	\
+	if (!err) {							\
+		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
+					       map_start);		\
+		u##bits res = le##bits##_to_cpu(*tmp);			\
+		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+		return res;						\
+	} else {							\
+		__le##bits res;						\
+		read_eb_member(eb, NULL, type, member, &res);		\
+		return le##bits##_to_cpu(res);				\
+	}								\
 }									\
 static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 				    u##bits val)			\
 {									\
-	val = cpu_to_le##bits(val);					\
-	write_eb_member(eb, NULL, type, member, &val);			\
+	int err;							\
+	char *map_token;						\
+	char *kaddr;							\
+	unsigned long map_start;					\
+	unsigned long map_len;						\
+	unsigned long offset = offsetof(type, member);			\
+	err = map_extent_buffer(eb, offset,				\
+			        sizeof(((type *)0)->member),		\
+				&map_token, &kaddr,			\
+				&map_start, &map_len, KM_USER0);	\
+	if (!err) {							\
+		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
+					       map_start);		\
+		*tmp = cpu_to_le##bits(val);				\
+		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+	} else {							\
+		val = cpu_to_le##bits(val);				\
+		write_eb_member(eb, NULL, type, member, &val);		\
+	}								\
 }
 
 #define BTRFS_SETGET_STACK_FUNCS(name, type, member, bits)		\

commit 479965d66e320f1a095bb76027171daa675a9c72
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:27 2007 -0400

    Btrfs: Optimizations for the extent_buffer code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c4b829806855..30fbbd7221a9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -22,6 +22,7 @@
 #include <linux/fs.h>
 #include <linux/workqueue.h>
 #include <linux/completion.h>
+#include <asm/kmap_types.h>
 #include "bit-radix.h"
 #include "extent_map.h"
 
@@ -431,15 +432,52 @@ struct btrfs_root {
 static inline u##bits btrfs_##name(struct extent_buffer *eb,		\
 				   type *s)				\
 {									\
-	__le##bits res;							\
-	read_eb_member(eb, s, type, member, &res);			\
-	return le##bits##_to_cpu(res);					\
+	int err;							\
+	char *map_token;						\
+	char *kaddr;							\
+	unsigned long map_start;					\
+	unsigned long map_len;						\
+	unsigned long offset = (unsigned long)s +			\
+				offsetof(type, member);			\
+	err = map_extent_buffer(eb, offset,				\
+			        sizeof(((type *)0)->member),		\
+				&map_token, &kaddr,			\
+				&map_start, &map_len, KM_USER0);	\
+	if (!err) {							\
+		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
+					       map_start);		\
+		u##bits res = le##bits##_to_cpu(*tmp);			\
+		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+		return res;						\
+	} else {							\
+		__le##bits res;						\
+		read_eb_member(eb, s, type, member, &res);		\
+		return le##bits##_to_cpu(res);				\
+	}								\
 }									\
 static inline void btrfs_set_##name(struct extent_buffer *eb,		\
 				    type *s, u##bits val)		\
 {									\
-	val = cpu_to_le##bits(val);					\
-	write_eb_member(eb, s, type, member, &val);			\
+	int err;							\
+	char *map_token;						\
+	char *kaddr;							\
+	unsigned long map_start;					\
+	unsigned long map_len;						\
+	unsigned long offset = (unsigned long)s +			\
+				offsetof(type, member);			\
+	err = map_extent_buffer(eb, offset,				\
+			        sizeof(((type *)0)->member),		\
+				&map_token, &kaddr,			\
+				&map_start, &map_len, KM_USER0);	\
+	if (!err) {							\
+		__le##bits *tmp = (__le##bits *)(kaddr + offset -	\
+					       map_start);		\
+		*tmp = cpu_to_le##bits(val);				\
+		unmap_extent_buffer(eb, map_token, KM_USER0);		\
+	} else {							\
+		val = cpu_to_le##bits(val);				\
+		write_eb_member(eb, s, type, member, &val);		\
+	}								\
 }
 
 #define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\

commit 5f39d397dfbe140a14edecd4e73c34ce23c4f9ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:19 2007 -0400

    Btrfs: Create extent_buffer interface for large blocksizes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 800a3499cc3f..c4b829806855 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -20,10 +20,10 @@
 #define __BTRFS__
 
 #include <linux/fs.h>
-#include <linux/buffer_head.h>
 #include <linux/workqueue.h>
 #include <linux/completion.h>
 #include "bit-radix.h"
+#include "extent_map.h"
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
@@ -32,7 +32,7 @@ extern struct kmem_cache *btrfs_transaction_cachep;
 extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 
-#define BTRFS_MAGIC "_BtRfS_M"
+#define BTRFS_MAGIC "_B2RfS_M"
 
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
 #define BTRFS_EXTENT_TREE_OBJECTID 2ULL
@@ -78,41 +78,41 @@ extern struct kmem_cache *btrfs_path_cachep;
  */
 struct btrfs_disk_key {
 	__le64 objectid;
-	__le32 flags;
+	u8 type;
 	__le64 offset;
 } __attribute__ ((__packed__));
 
 struct btrfs_key {
 	u64 objectid;
-	u32 flags;
+	u8 type;
 	u64 offset;
 } __attribute__ ((__packed__));
 
+#define BTRFS_FSID_SIZE 16
 /*
  * every tree block (leaf or node) starts with this header.
  */
 struct btrfs_header {
 	u8 csum[BTRFS_CSUM_SIZE];
-	u8 fsid[16]; /* FS specific uuid */
+	u8 fsid[BTRFS_FSID_SIZE]; /* FS specific uuid */
 	__le64 blocknr; /* which block this node is supposed to live in */
 	__le64 generation;
 	__le64 owner;
-	__le16 nritems;
+	__le32 nritems;
 	__le16 flags;
 	u8 level;
 } __attribute__ ((__packed__));
 
 #define BTRFS_MAX_LEVEL 8
-#define BTRFS_NODEPTRS_PER_BLOCK(r) (((r)->blocksize - \
+#define BTRFS_NODEPTRS_PER_BLOCK(r) (((r)->nodesize - \
 			        sizeof(struct btrfs_header)) / \
 			       (sizeof(struct btrfs_disk_key) + sizeof(u64)))
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
-#define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->blocksize))
+#define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->leafsize))
 #define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
 					sizeof(struct btrfs_item) - \
 					sizeof(struct btrfs_file_extent_item))
 
-struct buffer_head;
 /*
  * the super block basically lists the main trees of the FS
  * it currently lacks any block count etc etc
@@ -128,7 +128,9 @@ struct btrfs_super_block {
 	__le64 total_blocks;
 	__le64 blocks_used;
 	__le64 root_dir_objectid;
-	__le32 blocksize;
+	__le32 sectorsize;
+	__le32 nodesize;
+	__le32 leafsize;
 } __attribute__ ((__packed__));
 
 /*
@@ -138,7 +140,7 @@ struct btrfs_super_block {
 struct btrfs_item {
 	struct btrfs_disk_key key;
 	__le32 offset;
-	__le16 size;
+	__le32 size;
 } __attribute__ ((__packed__));
 
 /*
@@ -176,7 +178,7 @@ struct btrfs_node {
  * used while walking the tree.
  */
 struct btrfs_path {
-	struct buffer_head *nodes[BTRFS_MAX_LEVEL];
+	struct extent_buffer *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];
 	int reada;
 	int lowest_level;
@@ -292,6 +294,7 @@ struct btrfs_block_group_cache {
 };
 
 struct btrfs_fs_info {
+	u8 fsid[BTRFS_FSID_SIZE];
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct radix_tree_root fs_roots_radix;
@@ -304,9 +307,8 @@ struct btrfs_fs_info {
 	u64 generation;
 	u64 last_trans_committed;
 	struct btrfs_transaction *running_transaction;
-	struct btrfs_super_block *disk_super;
 	struct btrfs_super_block super_copy;
-	struct buffer_head *sb_buffer;
+	struct extent_buffer *sb_buffer;
 	struct super_block *sb;
 	struct inode *btree_inode;
 	struct mutex trans_mutex;
@@ -325,8 +327,8 @@ struct btrfs_fs_info {
  * and for the extent tree extent_root root.
  */
 struct btrfs_root {
-	struct buffer_head *node;
-	struct buffer_head *commit_root;
+	struct extent_buffer *node;
+	struct extent_buffer *commit_root;
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
@@ -336,7 +338,16 @@ struct btrfs_root {
 	struct rw_semaphore snap_sem;
 	u64 objectid;
 	u64 last_trans;
-	u32 blocksize;
+
+	/* data allocations are done in sectorsize units */
+	u32 sectorsize;
+
+	/* node allocations are done in nodesize units */
+	u32 nodesize;
+
+	/* leaf allocations are done in leafsize units */
+	u32 leafsize;
+
 	u32 type;
 	u64 highest_inode;
 	u64 last_inode_alloc;
@@ -347,12 +358,6 @@ struct btrfs_root {
 	char *name;
 };
 
-/* the lower bits in the key flags defines the item type */
-#define BTRFS_KEY_TYPE_MAX	256
-#define BTRFS_KEY_TYPE_SHIFT	24
-#define BTRFS_KEY_TYPE_MASK	(((u32)BTRFS_KEY_TYPE_MAX - 1) << \
-				  BTRFS_KEY_TYPE_SHIFT)
-
 /*
  * inode items have the data typically returned from stat and store other
  * info about object characteristics.  There is one for every file and dir in
@@ -402,246 +407,253 @@ struct btrfs_root {
  */
 #define BTRFS_STRING_ITEM_KEY	253
 
+/* some macros to generate set/get funcs for the struct fields.  This
+ * assumes there is a lefoo_to_cpu for every type, so lets make a simple
+ * one for u8:
+ */
+#define le8_to_cpu(v) (v)
+#define cpu_to_le8(v) (v)
+#define __le8 u8
+
+#define read_eb_member(eb, ptr, type, member, result) (			\
+	read_extent_buffer(eb, (char *)(result),			\
+			   ((unsigned long)(ptr)) +			\
+			    offsetof(type, member),			\
+			   sizeof(((type *)0)->member)))
+
+#define write_eb_member(eb, ptr, type, member, result) (		\
+	write_extent_buffer(eb, (char *)(result),			\
+			   ((unsigned long)(ptr)) +			\
+			    offsetof(type, member),			\
+			   sizeof(((type *)0)->member)))
+
+#define BTRFS_SETGET_FUNCS(name, type, member, bits)			\
+static inline u##bits btrfs_##name(struct extent_buffer *eb,		\
+				   type *s)				\
+{									\
+	__le##bits res;							\
+	read_eb_member(eb, s, type, member, &res);			\
+	return le##bits##_to_cpu(res);					\
+}									\
+static inline void btrfs_set_##name(struct extent_buffer *eb,		\
+				    type *s, u##bits val)		\
+{									\
+	val = cpu_to_le##bits(val);					\
+	write_eb_member(eb, s, type, member, &val);			\
+}
+
+#define BTRFS_SETGET_HEADER_FUNCS(name, type, member, bits)		\
+static inline u##bits btrfs_##name(struct extent_buffer *eb)		\
+{									\
+	__le##bits res;							\
+	read_eb_member(eb, NULL, type, member, &res);			\
+	return le##bits##_to_cpu(res);					\
+}									\
+static inline void btrfs_set_##name(struct extent_buffer *eb,		\
+				    u##bits val)			\
+{									\
+	val = cpu_to_le##bits(val);					\
+	write_eb_member(eb, NULL, type, member, &val);			\
+}
 
-static inline u64 btrfs_block_group_used(struct btrfs_block_group_item *bi)
-{
-	return le64_to_cpu(bi->used);
-}
-
-static inline void btrfs_set_block_group_used(struct
-						   btrfs_block_group_item *bi,
-						   u64 val)
-{
-	bi->used = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
-{
-	return le64_to_cpu(i->generation);
-}
-
-static inline void btrfs_set_inode_generation(struct btrfs_inode_item *i,
-					      u64 val)
-{
-	i->generation = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_inode_size(struct btrfs_inode_item *i)
-{
-	return le64_to_cpu(i->size);
-}
-
-static inline void btrfs_set_inode_size(struct btrfs_inode_item *i, u64 val)
-{
-	i->size = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_inode_nblocks(struct btrfs_inode_item *i)
-{
-	return le64_to_cpu(i->nblocks);
-}
-
-static inline void btrfs_set_inode_nblocks(struct btrfs_inode_item *i, u64 val)
-{
-	i->nblocks = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_inode_block_group(struct btrfs_inode_item *i)
-{
-	return le64_to_cpu(i->block_group);
-}
-
-static inline void btrfs_set_inode_block_group(struct btrfs_inode_item *i,
-						u64 val)
-{
-	i->block_group = cpu_to_le64(val);
-}
-
-static inline u32 btrfs_inode_nlink(struct btrfs_inode_item *i)
-{
-	return le32_to_cpu(i->nlink);
-}
-
-static inline void btrfs_set_inode_nlink(struct btrfs_inode_item *i, u32 val)
-{
-	i->nlink = cpu_to_le32(val);
-}
-
-static inline u32 btrfs_inode_uid(struct btrfs_inode_item *i)
-{
-	return le32_to_cpu(i->uid);
-}
-
-static inline void btrfs_set_inode_uid(struct btrfs_inode_item *i, u32 val)
-{
-	i->uid = cpu_to_le32(val);
-}
-
-static inline u32 btrfs_inode_gid(struct btrfs_inode_item *i)
-{
-	return le32_to_cpu(i->gid);
-}
-
-static inline void btrfs_set_inode_gid(struct btrfs_inode_item *i, u32 val)
-{
-	i->gid = cpu_to_le32(val);
-}
-
-static inline u32 btrfs_inode_mode(struct btrfs_inode_item *i)
-{
-	return le32_to_cpu(i->mode);
-}
-
-static inline void btrfs_set_inode_mode(struct btrfs_inode_item *i, u32 val)
-{
-	i->mode = cpu_to_le32(val);
+#define BTRFS_SETGET_STACK_FUNCS(name, type, member, bits)		\
+static inline u##bits btrfs_##name(type *s)				\
+{									\
+	return le##bits##_to_cpu(s->member);				\
+}									\
+static inline void btrfs_set_##name(type *s, u##bits val)		\
+{									\
+	s->member = cpu_to_le##bits(val);				\
 }
 
-static inline u32 btrfs_inode_rdev(struct btrfs_inode_item *i)
-{
-	return le32_to_cpu(i->rdev);
-}
+/* struct btrfs_block_group_item */
+BTRFS_SETGET_STACK_FUNCS(block_group_used, struct btrfs_block_group_item,
+			 used, 64);
+BTRFS_SETGET_FUNCS(disk_block_group_used, struct btrfs_block_group_item,
+			 used, 64);
 
-static inline void btrfs_set_inode_rdev(struct btrfs_inode_item *i, u32 val)
-{
-	i->rdev = cpu_to_le32(val);
-}
+/* struct btrfs_inode_item */
+BTRFS_SETGET_FUNCS(inode_generation, struct btrfs_inode_item, generation, 64);
+BTRFS_SETGET_FUNCS(inode_size, struct btrfs_inode_item, size, 64);
+BTRFS_SETGET_FUNCS(inode_nblocks, struct btrfs_inode_item, nblocks, 64);
+BTRFS_SETGET_FUNCS(inode_block_group, struct btrfs_inode_item, block_group, 64);
+BTRFS_SETGET_FUNCS(inode_nlink, struct btrfs_inode_item, nlink, 32);
+BTRFS_SETGET_FUNCS(inode_uid, struct btrfs_inode_item, uid, 32);
+BTRFS_SETGET_FUNCS(inode_gid, struct btrfs_inode_item, gid, 32);
+BTRFS_SETGET_FUNCS(inode_mode, struct btrfs_inode_item, mode, 32);
+BTRFS_SETGET_FUNCS(inode_rdev, struct btrfs_inode_item, rdev, 32);
+BTRFS_SETGET_FUNCS(inode_flags, struct btrfs_inode_item, flags, 16);
+BTRFS_SETGET_FUNCS(inode_compat_flags, struct btrfs_inode_item,
+		   compat_flags, 16);
 
-static inline u16 btrfs_inode_flags(struct btrfs_inode_item *i)
+static inline struct btrfs_inode_timespec *
+btrfs_inode_atime(struct btrfs_inode_item *inode_item)
 {
-	return le16_to_cpu(i->flags);
+	unsigned long ptr = (unsigned long)inode_item;
+	ptr += offsetof(struct btrfs_inode_item, atime);
+	return (struct btrfs_inode_timespec *)ptr;
 }
 
-static inline void btrfs_set_inode_flags(struct btrfs_inode_item *i, u16 val)
+static inline struct btrfs_inode_timespec *
+btrfs_inode_mtime(struct btrfs_inode_item *inode_item)
 {
-	i->flags = cpu_to_le16(val);
+	unsigned long ptr = (unsigned long)inode_item;
+	ptr += offsetof(struct btrfs_inode_item, mtime);
+	return (struct btrfs_inode_timespec *)ptr;
 }
 
-static inline u16 btrfs_inode_compat_flags(struct btrfs_inode_item *i)
+static inline struct btrfs_inode_timespec *
+btrfs_inode_ctime(struct btrfs_inode_item *inode_item)
 {
-	return le16_to_cpu(i->compat_flags);
+	unsigned long ptr = (unsigned long)inode_item;
+	ptr += offsetof(struct btrfs_inode_item, ctime);
+	return (struct btrfs_inode_timespec *)ptr;
 }
 
-static inline void btrfs_set_inode_compat_flags(struct btrfs_inode_item *i,
-						u16 val)
+static inline struct btrfs_inode_timespec *
+btrfs_inode_otime(struct btrfs_inode_item *inode_item)
 {
-	i->compat_flags = cpu_to_le16(val);
+	unsigned long ptr = (unsigned long)inode_item;
+	ptr += offsetof(struct btrfs_inode_item, otime);
+	return (struct btrfs_inode_timespec *)ptr;
 }
 
-static inline u64 btrfs_timespec_sec(struct btrfs_inode_timespec *ts)
-{
-	return le64_to_cpu(ts->sec);
-}
+BTRFS_SETGET_FUNCS(timespec_sec, struct btrfs_inode_timespec, sec, 64);
+BTRFS_SETGET_FUNCS(timespec_nsec, struct btrfs_inode_timespec, nsec, 32);
 
-static inline void btrfs_set_timespec_sec(struct btrfs_inode_timespec *ts,
-					  u64 val)
-{
-	ts->sec = cpu_to_le64(val);
-}
+/* struct btrfs_extent_item */
+BTRFS_SETGET_FUNCS(extent_refs, struct btrfs_extent_item, refs, 32);
+BTRFS_SETGET_FUNCS(extent_owner, struct btrfs_extent_item, owner, 32);
 
-static inline u32 btrfs_timespec_nsec(struct btrfs_inode_timespec *ts)
-{
-	return le32_to_cpu(ts->nsec);
-}
+BTRFS_SETGET_STACK_FUNCS(stack_extent_refs, struct btrfs_extent_item,
+			 refs, 32);
+BTRFS_SETGET_STACK_FUNCS(stack_extent_owner, struct btrfs_extent_item,
+			 owner, 32);
 
-static inline void btrfs_set_timespec_nsec(struct btrfs_inode_timespec *ts,
-					  u32 val)
-{
-	ts->nsec = cpu_to_le32(val);
-}
+/* struct btrfs_node */
+BTRFS_SETGET_FUNCS(key_blockptr, struct btrfs_key_ptr, blockptr, 64);
 
-static inline u32 btrfs_extent_refs(struct btrfs_extent_item *ei)
+static inline u64 btrfs_node_blockptr(struct extent_buffer *eb, int nr)
 {
-	return le32_to_cpu(ei->refs);
+	unsigned long ptr;
+	ptr = offsetof(struct btrfs_node, ptrs) +
+		sizeof(struct btrfs_key_ptr) * nr;
+	return btrfs_key_blockptr(eb, (struct btrfs_key_ptr *)ptr);
 }
 
-static inline void btrfs_set_extent_refs(struct btrfs_extent_item *ei, u32 val)
+static inline void btrfs_set_node_blockptr(struct extent_buffer *eb,
+					   int nr, u64 val)
 {
-	ei->refs = cpu_to_le32(val);
+	unsigned long ptr;
+	ptr = offsetof(struct btrfs_node, ptrs) +
+		sizeof(struct btrfs_key_ptr) * nr;
+	btrfs_set_key_blockptr(eb, (struct btrfs_key_ptr *)ptr, val);
 }
 
-static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
+static unsigned long btrfs_node_key_ptr_offset(int nr)
 {
-	return le64_to_cpu(ei->owner);
+	return offsetof(struct btrfs_node, ptrs) +
+		sizeof(struct btrfs_key_ptr) * nr;
 }
 
-static inline void btrfs_set_extent_owner(struct btrfs_extent_item *ei, u64 val)
+static void btrfs_node_key(struct extent_buffer *eb,
+			   struct btrfs_disk_key *disk_key, int nr)
 {
-	ei->owner = cpu_to_le64(val);
+	unsigned long ptr;
+	ptr = btrfs_node_key_ptr_offset(nr);
+	read_eb_member(eb, (struct btrfs_key_ptr *)ptr,
+		       struct btrfs_key_ptr, key, disk_key);
 }
-
-static inline u64 btrfs_node_blockptr(struct btrfs_node *n, int nr)
+static inline void btrfs_set_node_key(struct extent_buffer *eb,
+				      struct btrfs_disk_key *disk_key, int nr)
 {
-	return le64_to_cpu(n->ptrs[nr].blockptr);
+	unsigned long ptr;
+	ptr = btrfs_node_key_ptr_offset(nr);
+	write_eb_member(eb, (struct btrfs_key_ptr *)ptr,
+		       struct btrfs_key_ptr, key, disk_key);
 }
 
+/* struct btrfs_item */
+BTRFS_SETGET_FUNCS(item_offset, struct btrfs_item, offset, 32);
+BTRFS_SETGET_FUNCS(item_size, struct btrfs_item, size, 32);
 
-static inline void btrfs_set_node_blockptr(struct btrfs_node *n, int nr,
-					   u64 val)
+static inline unsigned long btrfs_item_nr_offset(int nr)
 {
-	n->ptrs[nr].blockptr = cpu_to_le64(val);
+	return offsetof(struct btrfs_leaf, items) +
+		sizeof(struct btrfs_item) * nr;
 }
 
-static inline u32 btrfs_item_offset(struct btrfs_item *item)
+static inline struct btrfs_item *btrfs_item_nr(struct extent_buffer *eb,
+					       int nr)
 {
-	return le32_to_cpu(item->offset);
+	return (struct btrfs_item *)btrfs_item_nr_offset(nr);
 }
 
-static inline void btrfs_set_item_offset(struct btrfs_item *item, u32 val)
+static inline u32 btrfs_item_end(struct extent_buffer *eb,
+				 struct btrfs_item *item)
 {
-	item->offset = cpu_to_le32(val);
+	return btrfs_item_offset(eb, item) + btrfs_item_size(eb, item);
 }
 
-static inline u32 btrfs_item_end(struct btrfs_item *item)
+static inline u32 btrfs_item_end_nr(struct extent_buffer *eb, int nr)
 {
-	return le32_to_cpu(item->offset) + le16_to_cpu(item->size);
+	return btrfs_item_end(eb, btrfs_item_nr(eb, nr));
 }
 
-static inline u16 btrfs_item_size(struct btrfs_item *item)
+static inline u32 btrfs_item_offset_nr(struct extent_buffer *eb, int nr)
 {
-	return le16_to_cpu(item->size);
+	return btrfs_item_offset(eb, btrfs_item_nr(eb, nr));
 }
 
-static inline void btrfs_set_item_size(struct btrfs_item *item, u16 val)
+static inline u32 btrfs_item_size_nr(struct extent_buffer *eb, int nr)
 {
-	item->size = cpu_to_le16(val);
+	return btrfs_item_size(eb, btrfs_item_nr(eb, nr));
 }
 
-static inline u16 btrfs_dir_flags(struct btrfs_dir_item *d)
+static inline void btrfs_item_key(struct extent_buffer *eb,
+			   struct btrfs_disk_key *disk_key, int nr)
 {
-	return le16_to_cpu(d->flags);
+	struct btrfs_item *item = btrfs_item_nr(eb, nr);
+	read_eb_member(eb, item, struct btrfs_item, key, disk_key);
 }
 
-static inline void btrfs_set_dir_flags(struct btrfs_dir_item *d, u16 val)
+static inline void btrfs_set_item_key(struct extent_buffer *eb,
+			       struct btrfs_disk_key *disk_key, int nr)
 {
-	d->flags = cpu_to_le16(val);
+	struct btrfs_item *item = btrfs_item_nr(eb, nr);
+	write_eb_member(eb, item, struct btrfs_item, key, disk_key);
 }
 
-static inline u8 btrfs_dir_type(struct btrfs_dir_item *d)
-{
-	return d->type;
-}
+/* struct btrfs_dir_item */
+BTRFS_SETGET_FUNCS(dir_flags, struct btrfs_dir_item, flags, 16);
+BTRFS_SETGET_FUNCS(dir_type, struct btrfs_dir_item, type, 8);
+BTRFS_SETGET_FUNCS(dir_name_len, struct btrfs_dir_item, name_len, 16);
 
-static inline void btrfs_set_dir_type(struct btrfs_dir_item *d, u8 val)
+static inline void btrfs_dir_item_key(struct extent_buffer *eb,
+				      struct btrfs_dir_item *item,
+				      struct btrfs_disk_key *key)
 {
-	d->type = val;
+	read_eb_member(eb, item, struct btrfs_dir_item, location, key);
 }
 
-static inline u16 btrfs_dir_name_len(struct btrfs_dir_item *d)
+static inline void btrfs_set_dir_item_key(struct extent_buffer *eb,
+					  struct btrfs_dir_item *item,
+					  struct btrfs_disk_key *key)
 {
-	return le16_to_cpu(d->name_len);
+	write_eb_member(eb, item, struct btrfs_dir_item, location, key);
 }
 
-static inline void btrfs_set_dir_name_len(struct btrfs_dir_item *d, u16 val)
-{
-	d->name_len = cpu_to_le16(val);
-}
+/* struct btrfs_disk_key */
+BTRFS_SETGET_STACK_FUNCS(disk_key_objectid, struct btrfs_disk_key,
+			 objectid, 64);
+BTRFS_SETGET_STACK_FUNCS(disk_key_offset, struct btrfs_disk_key, offset, 64);
+BTRFS_SETGET_STACK_FUNCS(disk_key_type, struct btrfs_disk_key, type, 8);
 
 static inline void btrfs_disk_key_to_cpu(struct btrfs_key *cpu,
 					 struct btrfs_disk_key *disk)
 {
 	cpu->offset = le64_to_cpu(disk->offset);
-	cpu->flags = le32_to_cpu(disk->flags);
+	cpu->type = disk->type;
 	cpu->objectid = le64_to_cpu(disk->objectid);
 }
 
@@ -649,400 +661,167 @@ static inline void btrfs_cpu_key_to_disk(struct btrfs_disk_key *disk,
 					 struct btrfs_key *cpu)
 {
 	disk->offset = cpu_to_le64(cpu->offset);
-	disk->flags = cpu_to_le32(cpu->flags);
+	disk->type = cpu->type;
 	disk->objectid = cpu_to_le64(cpu->objectid);
 }
 
-static inline u64 btrfs_disk_key_objectid(struct btrfs_disk_key *disk)
-{
-	return le64_to_cpu(disk->objectid);
-}
-
-static inline void btrfs_set_disk_key_objectid(struct btrfs_disk_key *disk,
-					       u64 val)
-{
-	disk->objectid = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_disk_key_offset(struct btrfs_disk_key *disk)
-{
-	return le64_to_cpu(disk->offset);
-}
-
-static inline void btrfs_set_disk_key_offset(struct btrfs_disk_key *disk,
-					     u64 val)
-{
-	disk->offset = cpu_to_le64(val);
-}
-
-static inline u32 btrfs_disk_key_flags(struct btrfs_disk_key *disk)
-{
-	return le32_to_cpu(disk->flags);
-}
-
-static inline void btrfs_set_disk_key_flags(struct btrfs_disk_key *disk,
-					    u32 val)
-{
-	disk->flags = cpu_to_le32(val);
-}
-
-static inline u32 btrfs_disk_key_type(struct btrfs_disk_key *key)
-{
-	return le32_to_cpu(key->flags) >> BTRFS_KEY_TYPE_SHIFT;
-}
-
-static inline void btrfs_set_disk_key_type(struct btrfs_disk_key *key,
-					       u32 val)
-{
-	u32 flags = btrfs_disk_key_flags(key);
-	BUG_ON(val >= BTRFS_KEY_TYPE_MAX);
-	val = val << BTRFS_KEY_TYPE_SHIFT;
-	flags = (flags & ~BTRFS_KEY_TYPE_MASK) | val;
-	btrfs_set_disk_key_flags(key, flags);
-}
-
-static inline u32 btrfs_key_type(struct btrfs_key *key)
-{
-	return key->flags >> BTRFS_KEY_TYPE_SHIFT;
-}
-
-static inline void btrfs_set_key_type(struct btrfs_key *key, u32 val)
-{
-	BUG_ON(val >= BTRFS_KEY_TYPE_MAX);
-	val = val << BTRFS_KEY_TYPE_SHIFT;
-	key->flags = (key->flags & ~(BTRFS_KEY_TYPE_MASK)) | val;
-}
-
-static inline u64 btrfs_header_blocknr(struct btrfs_header *h)
-{
-	return le64_to_cpu(h->blocknr);
-}
-
-static inline void btrfs_set_header_blocknr(struct btrfs_header *h, u64 blocknr)
-{
-	h->blocknr = cpu_to_le64(blocknr);
-}
-
-static inline u64 btrfs_header_generation(struct btrfs_header *h)
+static inline void btrfs_node_key_to_cpu(struct extent_buffer *eb,
+				  struct btrfs_key *key, int nr)
 {
-	return le64_to_cpu(h->generation);
+	struct btrfs_disk_key disk_key;
+	btrfs_node_key(eb, &disk_key, nr);
+	btrfs_disk_key_to_cpu(key, &disk_key);
 }
 
-static inline void btrfs_set_header_generation(struct btrfs_header *h,
-					       u64 val)
+static inline void btrfs_item_key_to_cpu(struct extent_buffer *eb,
+				  struct btrfs_key *key, int nr)
 {
-	h->generation = cpu_to_le64(val);
+	struct btrfs_disk_key disk_key;
+	btrfs_item_key(eb, &disk_key, nr);
+	btrfs_disk_key_to_cpu(key, &disk_key);
 }
 
-static inline u64 btrfs_header_owner(struct btrfs_header *h)
+static inline void btrfs_dir_item_key_to_cpu(struct extent_buffer *eb,
+				      struct btrfs_dir_item *item,
+				      struct btrfs_key *key)
 {
-	return le64_to_cpu(h->owner);
+	struct btrfs_disk_key disk_key;
+	btrfs_dir_item_key(eb, item, &disk_key);
+	btrfs_disk_key_to_cpu(key, &disk_key);
 }
 
-static inline void btrfs_set_header_owner(struct btrfs_header *h,
-					       u64 val)
-{
-	h->owner = cpu_to_le64(val);
-}
-
-static inline u16 btrfs_header_nritems(struct btrfs_header *h)
-{
-	return le16_to_cpu(h->nritems);
-}
-
-static inline void btrfs_set_header_nritems(struct btrfs_header *h, u16 val)
-{
-	h->nritems = cpu_to_le16(val);
-}
-
-static inline u16 btrfs_header_flags(struct btrfs_header *h)
-{
-	return le16_to_cpu(h->flags);
-}
-
-static inline void btrfs_set_header_flags(struct btrfs_header *h, u16 val)
-{
-	h->flags = cpu_to_le16(val);
-}
-
-static inline int btrfs_header_level(struct btrfs_header *h)
-{
-	return h->level;
-}
-
-static inline void btrfs_set_header_level(struct btrfs_header *h, int level)
-{
-	BUG_ON(level > BTRFS_MAX_LEVEL);
-	h->level = level;
-}
-
-static inline int btrfs_is_leaf(struct btrfs_node *n)
-{
-	return (btrfs_header_level(&n->header) == 0);
-}
-
-static inline u64 btrfs_root_blocknr(struct btrfs_root_item *item)
-{
-	return le64_to_cpu(item->blocknr);
-}
-
-static inline void btrfs_set_root_blocknr(struct btrfs_root_item *item, u64 val)
-{
-	item->blocknr = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_root_dirid(struct btrfs_root_item *item)
-{
-	return le64_to_cpu(item->root_dirid);
-}
-
-static inline void btrfs_set_root_dirid(struct btrfs_root_item *item, u64 val)
-{
-	item->root_dirid = cpu_to_le64(val);
-}
-
-static inline u32 btrfs_root_refs(struct btrfs_root_item *item)
-{
-	return le32_to_cpu(item->refs);
-}
-
-static inline void btrfs_set_root_refs(struct btrfs_root_item *item, u32 val)
-{
-	item->refs = cpu_to_le32(val);
-}
-
-static inline u32 btrfs_root_flags(struct btrfs_root_item *item)
-{
-	return le32_to_cpu(item->flags);
-}
-
-static inline void btrfs_set_root_flags(struct btrfs_root_item *item, u32 val)
-{
-	item->flags = cpu_to_le32(val);
-}
-
-static inline void btrfs_set_root_blocks_used(struct btrfs_root_item *item,
-						   u64 val)
-{
-	item->blocks_used = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_root_blocks_used(struct btrfs_root_item *item)
-{
-	return le64_to_cpu(item->blocks_used);
-}
-
-static inline void btrfs_set_root_block_limit(struct btrfs_root_item *item,
-						u64 val)
-{
-	item->block_limit = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_root_block_limit(struct btrfs_root_item *item)
-{
-	return le64_to_cpu(item->block_limit);
-}
 
-static inline u64 btrfs_super_blocknr(struct btrfs_super_block *s)
+static inline u8 btrfs_key_type(struct btrfs_key *key)
 {
-	return le64_to_cpu(s->blocknr);
+	return key->type;
 }
 
-static inline void btrfs_set_super_blocknr(struct btrfs_super_block *s, u64 val)
+static inline void btrfs_set_key_type(struct btrfs_key *key, u8 val)
 {
-	s->blocknr = cpu_to_le64(val);
+	key->type = val;
 }
 
-static inline u64 btrfs_super_generation(struct btrfs_super_block *s)
-{
-	return le64_to_cpu(s->generation);
-}
+/* struct btrfs_header */
+BTRFS_SETGET_HEADER_FUNCS(header_blocknr, struct btrfs_header, blocknr, 64);
+BTRFS_SETGET_HEADER_FUNCS(header_generation, struct btrfs_header,
+			  generation, 64);
+BTRFS_SETGET_HEADER_FUNCS(header_owner, struct btrfs_header, owner, 64);
+BTRFS_SETGET_HEADER_FUNCS(header_nritems, struct btrfs_header, nritems, 32);
+BTRFS_SETGET_HEADER_FUNCS(header_flags, struct btrfs_header, flags, 16);
+BTRFS_SETGET_HEADER_FUNCS(header_level, struct btrfs_header, level, 8);
 
-static inline void btrfs_set_super_generation(struct btrfs_super_block *s,
-					      u64 val)
+static inline u8 *btrfs_header_fsid(struct extent_buffer *eb)
 {
-	s->generation = cpu_to_le64(val);
+	unsigned long ptr = offsetof(struct btrfs_header, fsid);
+	return (u8 *)ptr;
 }
 
-static inline u64 btrfs_super_root(struct btrfs_super_block *s)
+static inline u8 *btrfs_super_fsid(struct extent_buffer *eb)
 {
-	return le64_to_cpu(s->root);
+	unsigned long ptr = offsetof(struct btrfs_super_block, fsid);
+	return (u8 *)ptr;
 }
 
-static inline void btrfs_set_super_root(struct btrfs_super_block *s, u64 val)
+static inline u8 *btrfs_header_csum(struct extent_buffer *eb)
 {
-	s->root = cpu_to_le64(val);
+	unsigned long ptr = offsetof(struct btrfs_header, csum);
+	return (u8 *)ptr;
 }
 
-static inline u64 btrfs_super_total_blocks(struct btrfs_super_block *s)
+static inline struct btrfs_node *btrfs_buffer_node(struct extent_buffer *eb)
 {
-	return le64_to_cpu(s->total_blocks);
+	return NULL;
 }
 
-static inline void btrfs_set_super_total_blocks(struct btrfs_super_block *s,
-						u64 val)
+static inline struct btrfs_leaf *btrfs_buffer_leaf(struct extent_buffer *eb)
 {
-	s->total_blocks = cpu_to_le64(val);
+	return NULL;
 }
 
-static inline u64 btrfs_super_blocks_used(struct btrfs_super_block *s)
+static inline struct btrfs_header *btrfs_buffer_header(struct extent_buffer *eb)
 {
-	return le64_to_cpu(s->blocks_used);
+	return NULL;
 }
 
-static inline void btrfs_set_super_blocks_used(struct btrfs_super_block *s,
-						u64 val)
+static inline int btrfs_is_leaf(struct extent_buffer *eb)
 {
-	s->blocks_used = cpu_to_le64(val);
+	return (btrfs_header_level(eb) == 0);
 }
 
-static inline u32 btrfs_super_blocksize(struct btrfs_super_block *s)
-{
-	return le32_to_cpu(s->blocksize);
-}
+/* struct btrfs_root_item */
+BTRFS_SETGET_FUNCS(disk_root_refs, struct btrfs_root_item, refs, 32);
+BTRFS_SETGET_FUNCS(disk_root_blocknr, struct btrfs_root_item, blocknr, 64);
 
-static inline void btrfs_set_super_blocksize(struct btrfs_super_block *s,
-						u32 val)
-{
-	s->blocksize = cpu_to_le32(val);
-}
+BTRFS_SETGET_STACK_FUNCS(root_blocknr, struct btrfs_root_item, blocknr, 64);
+BTRFS_SETGET_STACK_FUNCS(root_dirid, struct btrfs_root_item, root_dirid, 64);
+BTRFS_SETGET_STACK_FUNCS(root_refs, struct btrfs_root_item, refs, 32);
+BTRFS_SETGET_STACK_FUNCS(root_flags, struct btrfs_root_item, flags, 32);
+BTRFS_SETGET_STACK_FUNCS(root_used, struct btrfs_root_item, blocks_used, 64);
+BTRFS_SETGET_STACK_FUNCS(root_limit, struct btrfs_root_item, block_limit, 64);
 
-static inline u64 btrfs_super_root_dir(struct btrfs_super_block *s)
-{
-	return le64_to_cpu(s->root_dir_objectid);
-}
+/* struct btrfs_super_block */
+BTRFS_SETGET_STACK_FUNCS(super_blocknr, struct btrfs_super_block, blocknr, 64);
+BTRFS_SETGET_STACK_FUNCS(super_generation, struct btrfs_super_block,
+			 generation, 64);
+BTRFS_SETGET_STACK_FUNCS(super_root, struct btrfs_super_block, root, 64);
+BTRFS_SETGET_STACK_FUNCS(super_total_blocks, struct btrfs_super_block,
+		   total_blocks, 64);
+BTRFS_SETGET_STACK_FUNCS(super_blocks_used, struct btrfs_super_block,
+		   blocks_used, 64);
+BTRFS_SETGET_STACK_FUNCS(super_sectorsize, struct btrfs_super_block,
+			 sectorsize, 32);
+BTRFS_SETGET_STACK_FUNCS(super_nodesize, struct btrfs_super_block,
+			 nodesize, 32);
+BTRFS_SETGET_STACK_FUNCS(super_leafsize, struct btrfs_super_block,
+			 leafsize, 32);
+BTRFS_SETGET_STACK_FUNCS(super_root_dir, struct btrfs_super_block,
+			 root_dir_objectid, 64);
 
-static inline void btrfs_set_super_root_dir(struct btrfs_super_block *s, u64
-					    val)
+static inline unsigned long btrfs_leaf_data(struct extent_buffer *l)
 {
-	s->root_dir_objectid = cpu_to_le64(val);
+	return offsetof(struct btrfs_leaf, items);
 }
 
-static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
-{
-	return (u8 *)l->items;
-}
+/* struct btrfs_file_extent_item */
+BTRFS_SETGET_FUNCS(file_extent_type, struct btrfs_file_extent_item, type, 8);
 
-static inline int btrfs_file_extent_type(struct btrfs_file_extent_item *e)
-{
-	return e->type;
-}
-static inline void btrfs_set_file_extent_type(struct btrfs_file_extent_item *e,
-					      u8 val)
-{
-	e->type = val;
-}
-
-static inline char *btrfs_file_extent_inline_start(struct
+static inline unsigned long btrfs_file_extent_inline_start(struct
 						   btrfs_file_extent_item *e)
 {
-	return (char *)(&e->disk_blocknr);
+	unsigned long offset = (unsigned long)e;
+	offset += offsetof(struct btrfs_file_extent_item, disk_blocknr);
+	return offset;
 }
 
 static inline u32 btrfs_file_extent_calc_inline_size(u32 datasize)
 {
-	return (unsigned long)(&((struct
-		  btrfs_file_extent_item *)NULL)->disk_blocknr) + datasize;
-}
-
-static inline u32 btrfs_file_extent_inline_len(struct btrfs_item *e)
-{
-	struct btrfs_file_extent_item *fe = NULL;
-	return btrfs_item_size(e) - (unsigned long)(&fe->disk_blocknr);
-}
-
-static inline u64 btrfs_file_extent_disk_blocknr(struct btrfs_file_extent_item
-						 *e)
-{
-	return le64_to_cpu(e->disk_blocknr);
+	return offsetof(struct btrfs_file_extent_item, disk_blocknr) + datasize;
 }
 
-static inline void btrfs_set_file_extent_disk_blocknr(struct
-						      btrfs_file_extent_item
-						      *e, u64 val)
+static inline u32 btrfs_file_extent_inline_len(struct extent_buffer *eb,
+					       struct btrfs_item *e)
 {
-	e->disk_blocknr = cpu_to_le64(val);
+	unsigned long offset;
+	offset = offsetof(struct btrfs_file_extent_item, disk_blocknr);
+	return btrfs_item_size(eb, e) - offset;
 }
 
-static inline u64 btrfs_file_extent_generation(struct btrfs_file_extent_item *e)
-{
-	return le64_to_cpu(e->generation);
-}
-
-static inline void btrfs_set_file_extent_generation(struct
-						    btrfs_file_extent_item *e,
-						    u64 val)
-{
-	e->generation = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_file_extent_disk_num_blocks(struct
-						    btrfs_file_extent_item *e)
-{
-	return le64_to_cpu(e->disk_num_blocks);
-}
-
-static inline void btrfs_set_file_extent_disk_num_blocks(struct
-							 btrfs_file_extent_item
-							 *e, u64 val)
-{
-	e->disk_num_blocks = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_file_extent_offset(struct btrfs_file_extent_item *e)
-{
-	return le64_to_cpu(e->offset);
-}
-
-static inline void btrfs_set_file_extent_offset(struct btrfs_file_extent_item
-						*e, u64 val)
-{
-	e->offset = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_file_extent_num_blocks(struct btrfs_file_extent_item
-					       *e)
-{
-	return le64_to_cpu(e->num_blocks);
-}
-
-static inline void btrfs_set_file_extent_num_blocks(struct
-						    btrfs_file_extent_item *e,
-						    u64 val)
-{
-	e->num_blocks = cpu_to_le64(val);
-}
+BTRFS_SETGET_FUNCS(file_extent_disk_blocknr, struct btrfs_file_extent_item,
+		   disk_blocknr, 64);
+BTRFS_SETGET_FUNCS(file_extent_generation, struct btrfs_file_extent_item,
+		   generation, 64);
+BTRFS_SETGET_FUNCS(file_extent_disk_num_blocks, struct btrfs_file_extent_item,
+		   disk_num_blocks, 64);
+BTRFS_SETGET_FUNCS(file_extent_offset, struct btrfs_file_extent_item,
+		  offset, 64);
+BTRFS_SETGET_FUNCS(file_extent_num_blocks, struct btrfs_file_extent_item,
+		   num_blocks, 64);
 
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;
 }
 
-static inline void btrfs_check_bounds(void *vptr, size_t len,
-				     void *vcontainer, size_t container_len)
-{
-	char *ptr = vptr;
-	char *container = vcontainer;
-	WARN_ON(ptr < container);
-	WARN_ON(ptr + len > container + container_len);
-}
-
-static inline void btrfs_memcpy(struct btrfs_root *root,
-				void *dst_block,
-				void *dst, const void *src, size_t nr)
-{
-	btrfs_check_bounds(dst, nr, dst_block, root->fs_info->sb->s_blocksize);
-	memcpy(dst, src, nr);
-}
-
-static inline void btrfs_memmove(struct btrfs_root *root,
-				void *dst_block,
-				void *dst, void *src, size_t nr)
-{
-	btrfs_check_bounds(dst, nr, dst_block, root->fs_info->sb->s_blocksize);
-	memmove(dst, src, nr);
-}
-
 static inline int btrfs_set_root_name(struct btrfs_root *root,
 				      const char *name, int len)
 {
@@ -1063,7 +842,11 @@ static inline int btrfs_set_root_name(struct btrfs_root *root,
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
-	btrfs_item_offset((leaf)->items + (slot))))
+	btrfs_item_offset_nr(leaf, slot)))
+
+#define btrfs_item_ptr_offset(leaf, slot) \
+	((unsigned long)(btrfs_leaf_data(leaf) + \
+	btrfs_item_offset_nr(leaf, slot)))
 
 /* mount option defines and helpers */
 #define BTRFS_MOUNT_SUBVOL		0x000001
@@ -1084,7 +867,7 @@ struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 int data, int owner);
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
-struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
+struct extent_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root, u64 hint,
 					    u64 empty_size);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
@@ -1092,7 +875,7 @@ int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       u64 num_blocks, u64 empty_size, u64 search_start,
 		       u64 search_end, struct btrfs_key *ins, int data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct buffer_head *buf);
+		  struct extent_buffer *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 blocknr, u64 num_blocks, int pin);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
@@ -1106,10 +889,10 @@ int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_root *root);
 /* ctree.c */
-int btrfs_cow_block(struct btrfs_trans_handle *trans, struct btrfs_root
-			   *root, struct buffer_head *buf, struct buffer_head
-			   *parent, int parent_slot, struct buffer_head
-			   **cow_ret);
+int btrfs_cow_block(struct btrfs_trans_handle *trans,
+		    struct btrfs_root *root, struct extent_buffer *buf,
+		    struct extent_buffer *parent, int parent_slot,
+		    struct extent_buffer **cow_ret);
 int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_path *path, u32 data_size);
 int btrfs_truncate_item(struct btrfs_trans_handle *trans,
@@ -1120,7 +903,7 @@ int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
-		       struct btrfs_root *root, struct buffer_head *parent,
+		       struct btrfs_root *root, struct extent_buffer *parent,
 		       int cache_only, u64 *last_ret);
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
@@ -1134,7 +917,7 @@ int btrfs_insert_empty_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			    *root, struct btrfs_path *path, struct btrfs_key
 			    *cpu_key, u32 data_size);
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
-int btrfs_leaf_free_space(struct btrfs_root *root, struct btrfs_leaf *leaf);
+int btrfs_leaf_free_space(struct btrfs_root *root, struct extent_buffer *leaf);
 int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
 			*root);
 /* root-item.c */
@@ -1179,9 +962,9 @@ int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 int btrfs_find_highest_inode(struct btrfs_root *fs_root, u64 *objectid);
 
 /* inode-item.c */
-int btrfs_insert_inode(struct btrfs_trans_handle *trans, struct btrfs_root
-		       *root, u64 objectid, struct btrfs_inode_item
-		       *inode_item);
+int btrfs_insert_empty_inode(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root,
+			     struct btrfs_path *path, u64 objectid);
 int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       *root, struct btrfs_path *path,
 		       struct btrfs_key *location, int mod);
@@ -1224,8 +1007,6 @@ struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
 int btrfs_commit_write(struct file *file, struct page *page,
 		       unsigned from, unsigned to);
-int btrfs_get_block(struct inode *inode, sector_t iblock,
-		    struct buffer_head *result, int create);
 struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
 				    size_t page_offset, u64 start, u64 end,
 				    int create);

commit 34287aa3605d52ef5a4b6e5e2cca98667166508b
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 14 10:22:47 2007 -0400

    Btrfs: use unlocked_ioctl
    
    No reason to grab the BKL before calling into the btrfs ioctl code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6d6e94b63803..800a3499cc3f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1219,10 +1219,7 @@ struct inode *btrfs_alloc_inode(struct super_block *sb);
 void btrfs_destroy_inode(struct inode *inode);
 int btrfs_init_cachep(void);
 void btrfs_destroy_cachep(void);
-int btrfs_ioctl(struct inode *inode, struct file *filp, unsigned int cmd,
-		unsigned long arg);
-long btrfs_compat_ioctl(struct file *file, unsigned int cmd,
-			       unsigned long arg);
+long btrfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
 				struct btrfs_root *root);
 int btrfs_commit_write(struct file *file, struct page *page,

commit 5ce14bbcdd1b5d9233d26a1e89faf3a26c820c58
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Sep 11 11:15:39 2007 -0400

    Btrfs: Find and remove dead roots the first time a root is loaded.
    
    Dead roots are trees left over after a crash, and they were either in the
    process of being removed or were waiting to be removed when the box crashed.
    Before, a search of the entire tree of root pointers was done on mount
    looking for dead roots.  Now, the search is done the first time we load
    a root.
    
    This makes mount faster when there are a large number of snapshots, and it
    enables the block accounting code to properly update the block counts on
    the latest root as old versions of the root are reaped after a crash.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 03e1c4ad341b..6d6e94b63803 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1148,7 +1148,8 @@ int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
-int btrfs_find_dead_roots(struct btrfs_root *root);
+int btrfs_find_dead_roots(struct btrfs_root *root, u64 objectid,
+			  struct btrfs_root *latest_root);
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, const char *name, int name_len, u64 dir,

commit 011410bd859a481a335d7db1fb559542c5663fd5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 10 19:58:36 2007 -0400

    Btrfs: Add more synchronization before creating a snapshot
    
    File data checksums are only done during writepage, so we have to make sure
    all pages are written when the snapshot is taken.  This also adds some
    locking so that new writes don't race in and add new dirty pages.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cd75c906048f..03e1c4ad341b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -333,6 +333,7 @@ struct btrfs_root {
 	struct inode *inode;
 	struct kobject root_kobj;
 	struct completion kobj_unregister;
+	struct rw_semaphore snap_sem;
 	u64 objectid;
 	u64 last_trans;
 	u32 blocksize;

commit 95e0528919cb0c7635b37496e0ad1c41e4c0dd7c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 29 09:11:44 2007 -0400

    Btrfs: Use mount -o subvol to select the subvol directory instead of dev:
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ffeee546a0d7..cd75c906048f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1064,6 +1064,12 @@ static inline int btrfs_set_root_name(struct btrfs_root *root,
 	((type *)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset((leaf)->items + (slot))))
 
+/* mount option defines and helpers */
+#define BTRFS_MOUNT_SUBVOL		0x000001
+#define btrfs_clear_opt(o, opt)		o &= ~BTRFS_MOUNT_##opt
+#define btrfs_set_opt(o, opt)		o |= BTRFS_MOUNT_##opt
+#define btrfs_test_opt(sb, opt)		(BTRFS_SB(sb)->s_mount_opt & \
+					 BTRFS_MOUNT_##opt)
 /* extent-tree.c */
 int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
 			 struct btrfs_root *root);

commit 58176a9604c5db1784d2c979aea472b3be40b6f0
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Aug 29 15:47:34 2007 -0400

    Btrfs: Add per-root block accounting and sysfs entries
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 947f061ed118..ffeee546a0d7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -22,6 +22,7 @@
 #include <linux/fs.h>
 #include <linux/buffer_head.h>
 #include <linux/workqueue.h>
+#include <linux/completion.h>
 #include "bit-radix.h"
 
 struct btrfs_trans_handle;
@@ -313,6 +314,8 @@ struct btrfs_fs_info {
 	struct list_head trans_list;
 	struct list_head dead_roots;
 	struct delayed_work trans_work;
+	struct kobject super_kobj;
+	struct completion kobj_unregister;
 	int do_barriers;
 	int closing;
 };
@@ -328,6 +331,8 @@ struct btrfs_root {
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
 	struct inode *inode;
+	struct kobject root_kobj;
+	struct completion kobj_unregister;
 	u64 objectid;
 	u64 last_trans;
 	u32 blocksize;
@@ -338,6 +343,7 @@ struct btrfs_root {
 	struct btrfs_key defrag_progress;
 	int defrag_running;
 	int defrag_level;
+	char *name;
 };
 
 /* the lower bits in the key flags defines the item type */
@@ -814,6 +820,28 @@ static inline void btrfs_set_root_flags(struct btrfs_root_item *item, u32 val)
 	item->flags = cpu_to_le32(val);
 }
 
+static inline void btrfs_set_root_blocks_used(struct btrfs_root_item *item,
+						   u64 val)
+{
+	item->blocks_used = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_root_blocks_used(struct btrfs_root_item *item)
+{
+	return le64_to_cpu(item->blocks_used);
+}
+
+static inline void btrfs_set_root_block_limit(struct btrfs_root_item *item,
+						u64 val)
+{
+	item->block_limit = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_root_block_limit(struct btrfs_root_item *item)
+{
+	return le64_to_cpu(item->block_limit);
+}
+
 static inline u64 btrfs_super_blocknr(struct btrfs_super_block *s)
 {
 	return le64_to_cpu(s->blocknr);
@@ -1014,6 +1042,23 @@ static inline void btrfs_memmove(struct btrfs_root *root,
 	memmove(dst, src, nr);
 }
 
+static inline int btrfs_set_root_name(struct btrfs_root *root,
+				      const char *name, int len)
+{
+	/* if we already have a name just free it */
+	if (root->name)
+		kfree(root->name);
+
+	root->name = kmalloc(len+1, GFP_KERNEL);
+	if (!root->name)
+		return -ENOMEM;
+
+	memcpy(root->name, name, len);
+	root->name[len] ='\0';
+
+	return 0;
+}
+
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
@@ -1191,4 +1236,13 @@ int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 /* tree-defrag.c */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only);
+
+/* sysfs.c */
+int btrfs_init_sysfs(void);
+void btrfs_exit_sysfs(void);
+int btrfs_sysfs_add_super(struct btrfs_fs_info *fs);
+int btrfs_sysfs_add_root(struct btrfs_root *root);
+void btrfs_sysfs_del_root(struct btrfs_root *root);
+void btrfs_sysfs_del_super(struct btrfs_fs_info *root);
+
 #endif

commit a52d9a8033c454cd9b4697cfafb467509fc1693f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Aug 27 16:49:44 2007 -0400

    Btrfs: Extent based page cache code.  This uses an rbtree of extents and tests
    instead of buffer heads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c7f5161271d3..947f061ed118 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1176,7 +1176,14 @@ int btrfs_commit_write(struct file *file, struct page *page,
 		       unsigned from, unsigned to);
 int btrfs_get_block(struct inode *inode, sector_t iblock,
 		    struct buffer_head *result, int create);
+struct extent_map *btrfs_get_extent(struct inode *inode, struct page *page,
+				    size_t page_offset, u64 start, u64 end,
+				    int create);
+int btrfs_update_inode(struct btrfs_trans_handle *trans,
+			      struct btrfs_root *root,
+			      struct inode *inode);
 /* file.c */
+int btrfs_drop_extent_cache(struct inode *inode, u64 start, u64 end);
 extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,

commit 15ee9bc7ed171248d1405df5854da5fa91bfdc39
Author: Josef Bacik <jwhiter@redhat.com>
Date:   Fri Aug 10 16:22:09 2007 -0400

    Btrfs: delay commits during fsync to allow more writers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d3cd564b3b3f..c7f5161271d3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -301,6 +301,7 @@ struct btrfs_fs_info {
 	struct radix_tree_root extent_map_radix;
 	struct radix_tree_root extent_ins_radix;
 	u64 generation;
+	u64 last_trans_committed;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;
 	struct btrfs_super_block super_copy;

commit e9d0b13b5bbb58c9b840e407a8d181442f799966
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 10 14:06:19 2007 -0400

    Btrfs: Btree defrag on the extent-mapping tree as well
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 59e09e37ab93..d3cd564b3b3f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1019,6 +1019,8 @@ static inline void btrfs_memmove(struct btrfs_root *root,
 	btrfs_item_offset((leaf)->items + (slot))))
 
 /* extent-tree.c */
+int btrfs_extent_post_op(struct btrfs_trans_handle *trans,
+			 struct btrfs_root *root);
 int btrfs_copy_pinned(struct btrfs_root *root, struct radix_tree_root *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
 							 btrfs_fs_info *info,
@@ -1066,7 +1068,7 @@ int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      ins_len, int cow);
 int btrfs_realloc_node(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct buffer_head *parent,
-		       int cache_only);
+		       int cache_only, u64 *last_ret);
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);

commit 26b8003f10569a9155b7539ef5a7379ee0c6b050
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 8 20:17:12 2007 -0400

    Btrfs: Replace extent tree preallocation code with some bit radix magic.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8b7d01597f4f..59e09e37ab93 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -299,12 +299,7 @@ struct btrfs_fs_info {
 	struct radix_tree_root block_group_radix;
 	struct radix_tree_root block_group_data_radix;
 	struct radix_tree_root extent_map_radix;
-
-	u64 extent_tree_insert[BTRFS_MAX_LEVEL * 6];
-	int extent_tree_insert_nr;
-	u64 extent_tree_prealloc[BTRFS_MAX_LEVEL * 6];
-	int extent_tree_prealloc_nr;
-
+	struct radix_tree_root extent_ins_radix;
 	u64 generation;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;

commit f4468e94c86c2031f447788c4bfe7dfd2fcdc93a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 8 10:08:58 2007 -0400

    Btrfs: Let some locks go during defrag and snapshot dropping
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 42aa20301bc9..8b7d01597f4f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -300,9 +300,9 @@ struct btrfs_fs_info {
 	struct radix_tree_root block_group_data_radix;
 	struct radix_tree_root extent_map_radix;
 
-	u64 extent_tree_insert[BTRFS_MAX_LEVEL * 3];
+	u64 extent_tree_insert[BTRFS_MAX_LEVEL * 6];
 	int extent_tree_insert_nr;
-	u64 extent_tree_prealloc[BTRFS_MAX_LEVEL * 3];
+	u64 extent_tree_prealloc[BTRFS_MAX_LEVEL * 6];
 	int extent_tree_prealloc_nr;
 
 	u64 generation;

commit 6702ed490ca0bb44e17131818a5a18b773957c5a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 7 16:15:09 2007 -0400

    Btrfs: Add run time btree defrag, and an ioctl to force btree defrag
    
    This adds two types of btree defrag, a run time form that tries to
    defrag recently allocated blocks in the btree when they are still in ram,
    and an ioctl that forces defrag of all btree blocks.
    
    File data blocks are not defragged yet, but this can make a huge difference
    in sequential btree reads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c5a18d5d7f7c..42aa20301bc9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -178,6 +178,7 @@ struct btrfs_path {
 	struct buffer_head *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];
 	int reada;
+	int lowest_level;
 };
 
 /*
@@ -338,6 +339,9 @@ struct btrfs_root {
 	u64 highest_inode;
 	u64 last_inode_alloc;
 	int ref_cows;
+	struct btrfs_key defrag_progress;
+	int defrag_running;
+	int defrag_level;
 };
 
 /* the lower bits in the key flags defines the item type */
@@ -1031,10 +1035,11 @@ struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
-					    struct btrfs_root *root, u64 hint);
+					    struct btrfs_root *root, u64 hint,
+					    u64 empty_size);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, u64 owner,
-		       u64 num_blocks, u64 search_start,
+		       u64 num_blocks, u64 empty_size, u64 search_start,
 		       u64 search_end, struct btrfs_key *ins, int data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct buffer_head *buf);
@@ -1051,6 +1056,10 @@ int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
 int btrfs_free_block_groups(struct btrfs_fs_info *info);
 int btrfs_read_block_groups(struct btrfs_root *root);
 /* ctree.c */
+int btrfs_cow_block(struct btrfs_trans_handle *trans, struct btrfs_root
+			   *root, struct buffer_head *buf, struct buffer_head
+			   *parent, int parent_slot, struct buffer_head
+			   **cow_ret);
 int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_path *path, u32 data_size);
 int btrfs_truncate_item(struct btrfs_trans_handle *trans,
@@ -1060,6 +1069,9 @@ int btrfs_truncate_item(struct btrfs_trans_handle *trans,
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
+int btrfs_realloc_node(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root, struct buffer_head *parent,
+		       int cache_only);
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 struct btrfs_path *btrfs_alloc_path(void);
 void btrfs_free_path(struct btrfs_path *p);
@@ -1171,4 +1183,7 @@ extern struct file_operations btrfs_file_operations;
 int btrfs_drop_extents(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, struct inode *inode,
 		       u64 start, u64 end, u64 *hint_block);
+/* tree-defrag.c */
+int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root, int cache_only);
 #endif

commit 3c69faecb8d83cb2ef085a98b196a3fecea67725
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 7 15:52:22 2007 -0400

    Btrfs: Fold some btree readahead routines into something more generic.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 73c2e75a136d..c5a18d5d7f7c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -177,6 +177,7 @@ struct btrfs_node {
 struct btrfs_path {
 	struct buffer_head *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];
+	int reada;
 };
 
 /*

commit 9f3a742736cecda5a8778be70faa2f779458839f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 7 15:52:19 2007 -0400

    Btrfs: Do snapshot deletion in smaller chunks.
    
    Before, snapshot deletion was a single atomic unit.  This caused considerable
    lock contention and required an unbounded amount of space.  Now,
    the drop_progress field in the root item is used to indicate how far along
    snapshot deletion is, and to resume where it left off.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0287bd51d87c..73c2e75a136d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -333,10 +333,10 @@ struct btrfs_root {
 	u64 objectid;
 	u64 last_trans;
 	u32 blocksize;
-	int ref_cows;
 	u32 type;
 	u64 highest_inode;
 	u64 last_inode_alloc;
+	int ref_cows;
 };
 
 /* the lower bits in the key flags defines the item type */
@@ -1073,7 +1073,7 @@ int btrfs_insert_empty_item(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct btrfs_leaf *leaf);
 int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
-			*root, struct buffer_head *snap);
+			*root);
 /* root-item.c */
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_key *key);

commit ccd467d60e81b48cdbecae93532b66bcdedca91d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jun 28 15:57:36 2007 -0400

    Btrfs: crash recovery fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1998f86df08a..0287bd51d87c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1013,18 +1013,13 @@ static inline void btrfs_memmove(struct btrfs_root *root,
 	memmove(dst, src, nr);
 }
 
-static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
-{
-	WARN_ON(!atomic_read(&bh->b_count));
-	mark_buffer_dirty(bh);
-}
-
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset((leaf)->items + (slot))))
 
 /* extent-tree.c */
+int btrfs_copy_pinned(struct btrfs_root *root, struct radix_tree_root *copy);
 struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
 							 btrfs_fs_info *info,
 							 u64 blocknr);
@@ -1044,8 +1039,9 @@ int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct buffer_head *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 blocknr, u64 num_blocks, int pin);
-int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
-			       btrfs_root *root);
+int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *root,
+			       struct radix_tree_root *unpin_radix);
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 blocknr, u64 num_blocks);

commit 4b52dff6d371b9b93bc99f64c32831ea9a8ec3ac
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 26 10:06:50 2007 -0400

    Btrfs: Fix super block updates during transaction commit
    
    The super block written during commit was not consistent with the state of
    the trees.  This change adds an in-memory copy of the super so that we can
    make sure to write out consistent data during a commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index fb6fffb71dd0..1998f86df08a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -306,6 +306,7 @@ struct btrfs_fs_info {
 	u64 generation;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;
+	struct btrfs_super_block super_copy;
 	struct buffer_head *sb_buffer;
 	struct super_block *sb;
 	struct inode *btree_inode;

commit 5eda7b5e9b0bed864dd18284c7df9b3c8207dad7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:25 2007 -0400

    Btrfs: Add the ability to find and remove dead roots after a crash.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 77071f273977..fb6fffb71dd0 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -122,12 +122,12 @@ struct btrfs_super_block {
 	u8 fsid[16];    /* FS specific uuid */
 	__le64 blocknr; /* this block number */
 	__le64 magic;
-	__le32 blocksize;
 	__le64 generation;
 	__le64 root;
 	__le64 total_blocks;
 	__le64 blocks_used;
 	__le64 root_dir_objectid;
+	__le32 blocksize;
 } __attribute__ ((__packed__));
 
 /*
@@ -226,10 +226,12 @@ struct btrfs_root_item {
 	struct btrfs_inode_item inode;
 	__le64 root_dirid;
 	__le64 blocknr;
-	__le32 flags;
 	__le64 block_limit;
 	__le64 blocks_used;
+	__le32 flags;
 	__le32 refs;
+	struct btrfs_disk_key drop_progress;
+	u8 drop_level;
 } __attribute__ ((__packed__));
 
 #define BTRFS_FILE_EXTENT_REG 0
@@ -800,6 +802,16 @@ static inline void btrfs_set_root_refs(struct btrfs_root_item *item, u32 val)
 	item->refs = cpu_to_le32(val);
 }
 
+static inline u32 btrfs_root_flags(struct btrfs_root_item *item)
+{
+	return le32_to_cpu(item->flags);
+}
+
+static inline void btrfs_set_root_flags(struct btrfs_root_item *item, u32 val)
+{
+	item->flags = cpu_to_le32(val);
+}
+
 static inline u64 btrfs_super_blocknr(struct btrfs_super_block *s)
 {
 	return le64_to_cpu(s->blocknr);
@@ -1076,6 +1088,7 @@ int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
+int btrfs_find_dead_roots(struct btrfs_root *root);
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, const char *name, int name_len, u64 dir,

commit 54aa1f4dfdacd60a19c4471220b24e581be6f774
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:25 2007 -0400

    Btrfs: Audit callers and return codes to make sure -ENOSPC gets up the stack
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 19a1d998fca7..77071f273977 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1126,9 +1126,6 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset,
 			  char *data, size_t len);
-int btrfs_csum_verify_file_block(struct btrfs_root *root,
-				 u64 objectid, u64 offset,
-				 char *data, size_t len);
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,

commit 11bd143fc8243cf48c934dc1c4479a5aacf58ce3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:24 2007 -0400

    Btrfs: Switch to libcrc32c to avoid problems with cryptomgr on highmem machines
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1e83ad720b10..19a1d998fca7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -286,10 +286,7 @@ struct btrfs_block_group_cache {
 	int cached;
 };
 
-struct crypto_hash;
-
 struct btrfs_fs_info {
-	spinlock_t hash_lock;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct radix_tree_root fs_roots_radix;
@@ -314,7 +311,6 @@ struct btrfs_fs_info {
 	struct mutex fs_mutex;
 	struct list_head trans_list;
 	struct list_head dead_roots;
-	struct crypto_hash *hash_tfm;
 	struct delayed_work trans_work;
 	int do_barriers;
 	int closing;

commit 9ebefb180bad4914a31c4e1748ba187a30e1e990
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 15 13:50:00 2007 -0400

    Btrfs: patch queue: page_mkwrite
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4bd648d68e88..1e83ad720b10 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1142,6 +1142,8 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
 /* inode.c */
+int btrfs_page_mkwrite(struct vm_area_struct *vma, struct page *page);
+int btrfs_readpage(struct file *file, struct page *page);
 void btrfs_delete_inode(struct inode *inode);
 void btrfs_read_locked_inode(struct inode *inode);
 int btrfs_write_inode(struct inode *inode, int wait);

commit 6cbd55707802b98843f953d1ae6d8f5bcd9a76c0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 09:07:21 2007 -0400

    Btrfs: add GPLv2
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 24410d42e3ce..4bd648d68e88 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,3 +1,21 @@
+/*
+ * Copyright (C) 2007 Oracle.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
 #ifndef __BTRFS__
 #define __BTRFS__
 

commit 39279cc3d2704cfbf9c35dcb5bdd392159ae4625
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 06:35:45 2007 -0400

    Btrfs: split up super.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4e136b7b03ae..24410d42e3ce 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1123,5 +1123,28 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, struct btrfs_path *path,
 			u64 isize);
-/* super.c */
+/* inode.c */
+void btrfs_delete_inode(struct inode *inode);
+void btrfs_read_locked_inode(struct inode *inode);
+int btrfs_write_inode(struct inode *inode, int wait);
+void btrfs_dirty_inode(struct inode *inode);
+struct inode *btrfs_alloc_inode(struct super_block *sb);
+void btrfs_destroy_inode(struct inode *inode);
+int btrfs_init_cachep(void);
+void btrfs_destroy_cachep(void);
+int btrfs_ioctl(struct inode *inode, struct file *filp, unsigned int cmd,
+		unsigned long arg);
+long btrfs_compat_ioctl(struct file *file, unsigned int cmd,
+			       unsigned long arg);
+struct inode *btrfs_iget_locked(struct super_block *s, u64 objectid,
+				struct btrfs_root *root);
+int btrfs_commit_write(struct file *file, struct page *page,
+		       unsigned from, unsigned to);
+int btrfs_get_block(struct inode *inode, sector_t iblock,
+		    struct buffer_head *result, int create);
+/* file.c */
+extern struct file_operations btrfs_file_operations;
+int btrfs_drop_extents(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root, struct inode *inode,
+		       u64 start, u64 end, u64 *hint_block);
 #endif

commit 5276aedab0baacfb3c5483208b8be85a8416bd5f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jun 11 21:33:38 2007 -0400

    Btrfs: fix oops after block group lookup
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5ab25a0cb16a..4e136b7b03ae 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -998,6 +998,9 @@ static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
 	btrfs_item_offset((leaf)->items + (slot))))
 
 /* extent-tree.c */
+struct btrfs_block_group_cache *btrfs_lookup_block_group(struct
+							 btrfs_fs_info *info,
+							 u64 blocknr);
 struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 struct btrfs_block_group_cache
 						 *hint, u64 search_start,

commit 0cf6c620176a294bdf1bedddc492f6ae857e0019
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Jun 9 09:22:25 2007 -0400

    Btrfs: remove device tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e93ba1a5c812..5ab25a0cb16a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -16,11 +16,10 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_MAGIC "_BtRfS_M"
 
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
-#define BTRFS_DEV_TREE_OBJECTID 2ULL
-#define BTRFS_EXTENT_TREE_OBJECTID 3ULL
-#define BTRFS_FS_TREE_OBJECTID 4ULL
-#define BTRFS_ROOT_TREE_DIR_OBJECTID 5ULL
-#define BTRFS_FIRST_FREE_OBJECTID 6ULL
+#define BTRFS_EXTENT_TREE_OBJECTID 2ULL
+#define BTRFS_FS_TREE_OBJECTID 3ULL
+#define BTRFS_ROOT_TREE_DIR_OBJECTID 4ULL
+#define BTRFS_FIRST_FREE_OBJECTID 5ULL
 
 /*
  * we can actually store much bigger names, but lets not confuse the rest
@@ -111,12 +110,6 @@ struct btrfs_super_block {
 	__le64 total_blocks;
 	__le64 blocks_used;
 	__le64 root_dir_objectid;
-	__le64 last_device_id;
-	/* fields below here vary with the underlying disk */
-	__le64 device_block_start;
-	__le64 device_num_blocks;
-	__le64 device_root;
-	__le64 device_id;
 } __attribute__ ((__packed__));
 
 /*
@@ -251,11 +244,6 @@ struct btrfs_csum_item {
 	u8 csum;
 } __attribute__ ((__packed__));
 
-struct btrfs_device_item {
-	__le16 pathlen;
-	__le64 device_id;
-} __attribute__ ((__packed__));
-
 /* tag for the radix tree of block groups in ram */
 #define BTRFS_BLOCK_GROUP_DIRTY 0
 #define BTRFS_BLOCK_GROUP_AVAIL 1
@@ -286,11 +274,9 @@ struct btrfs_fs_info {
 	spinlock_t hash_lock;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
-	struct btrfs_root *dev_root;
 	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
-	struct radix_tree_root dev_radix;
 	struct radix_tree_root block_group_radix;
 	struct radix_tree_root block_group_data_radix;
 	struct radix_tree_root extent_map_radix;
@@ -385,11 +371,6 @@ struct btrfs_root {
  */
 #define BTRFS_BLOCK_GROUP_ITEM_KEY 34
 
-/*
- * dev items list the devices that make up the FS
- */
-#define BTRFS_DEV_ITEM_KEY	35
-
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
@@ -880,62 +861,6 @@ static inline void btrfs_set_super_root_dir(struct btrfs_super_block *s, u64
 	s->root_dir_objectid = cpu_to_le64(val);
 }
 
-static inline u64 btrfs_super_last_device_id(struct btrfs_super_block *s)
-{
-	return le64_to_cpu(s->last_device_id);
-}
-
-static inline void btrfs_set_super_last_device_id(struct btrfs_super_block *s,
-						  u64 val)
-{
-	s->last_device_id = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_super_device_id(struct btrfs_super_block *s)
-{
-	return le64_to_cpu(s->device_id);
-}
-
-static inline void btrfs_set_super_device_id(struct btrfs_super_block *s,
-						  u64 val)
-{
-	s->device_id = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_super_device_block_start(struct btrfs_super_block *s)
-{
-	return le64_to_cpu(s->device_block_start);
-}
-
-static inline void btrfs_set_super_device_block_start(struct btrfs_super_block
-						      *s, u64 val)
-{
-	s->device_block_start = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_super_device_num_blocks(struct btrfs_super_block *s)
-{
-	return le64_to_cpu(s->device_num_blocks);
-}
-
-static inline void btrfs_set_super_device_num_blocks(struct btrfs_super_block
-						     *s, u64 val)
-{
-	s->device_num_blocks = cpu_to_le64(val);
-}
-
-static inline u64 btrfs_super_device_root(struct btrfs_super_block *s)
-{
-	return le64_to_cpu(s->device_root);
-}
-
-static inline void btrfs_set_super_device_root(struct btrfs_super_block
-						      *s, u64 val)
-{
-	s->device_root = cpu_to_le64(val);
-}
-
-
 static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 {
 	return (u8 *)l->items;
@@ -1031,28 +956,6 @@ static inline void btrfs_set_file_extent_num_blocks(struct
 	e->num_blocks = cpu_to_le64(val);
 }
 
-static inline u16 btrfs_device_pathlen(struct btrfs_device_item *d)
-{
-	return le16_to_cpu(d->pathlen);
-}
-
-static inline void btrfs_set_device_pathlen(struct btrfs_device_item *d,
-						u16 val)
-{
-	d->pathlen = cpu_to_le16(val);
-}
-
-static inline u64 btrfs_device_id(struct btrfs_device_item *d)
-{
-	return le64_to_cpu(d->device_id);
-}
-
-static inline void btrfs_set_device_id(struct btrfs_device_item *d,
-						u64 val)
-{
-	d->device_id = cpu_to_le64(val);
-}
-
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;

commit facda1e787d43191a3368c322f682054991c41b8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 8 18:11:48 2007 -0400

    Btrfs: get forced transaction commits via workqueue
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 74e6aadf6bb7..e93ba1a5c812 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -283,6 +283,7 @@ struct btrfs_block_group_cache {
 struct crypto_hash;
 
 struct btrfs_fs_info {
+	spinlock_t hash_lock;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct btrfs_root *dev_root;
@@ -308,10 +309,11 @@ struct btrfs_fs_info {
 	struct mutex trans_mutex;
 	struct mutex fs_mutex;
 	struct list_head trans_list;
+	struct list_head dead_roots;
 	struct crypto_hash *hash_tfm;
 	struct delayed_work trans_work;
-	spinlock_t hash_lock;
 	int do_barriers;
+	int closing;
 };
 
 /*

commit 08607c1b182b3b8b54d7141a0c012cda17d201e6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 8 15:33:54 2007 -0400

    Btrfs: add compat ioctl
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a1c95c980fdc..74e6aadf6bb7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3,7 +3,7 @@
 
 #include <linux/fs.h>
 #include <linux/buffer_head.h>
-#include <linux/kobject.h>
+#include <linux/workqueue.h>
 #include "bit-radix.h"
 
 struct btrfs_trans_handle;
@@ -281,6 +281,7 @@ struct btrfs_block_group_cache {
 };
 
 struct crypto_hash;
+
 struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
@@ -308,9 +309,9 @@ struct btrfs_fs_info {
 	struct mutex fs_mutex;
 	struct list_head trans_list;
 	struct crypto_hash *hash_tfm;
+	struct delayed_work trans_work;
 	spinlock_t hash_lock;
 	int do_barriers;
-	struct kobject kobj;
 };
 
 /*

commit fabb568183de7996257080260d3537fa75b3667e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jun 7 22:13:21 2007 -0400

    Btrfs: d_type optimization
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1bb62867deda..a1c95c980fdc 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -34,6 +34,16 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_CRC32_SIZE 4
 #define BTRFS_EMPTY_DIR_SIZE 6
 
+#define BTRFS_FT_UNKNOWN	0
+#define BTRFS_FT_REG_FILE	1
+#define BTRFS_FT_DIR		2
+#define BTRFS_FT_CHRDEV		3
+#define BTRFS_FT_BLKDEV		4
+#define BTRFS_FT_FIFO		5
+#define BTRFS_FT_SOCK		6
+#define BTRFS_FT_SYMLINK	7
+#define BTRFS_FT_MAX		8
+
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
  * block layout.  objectid corresonds to the inode number.  The flags

commit 1e2677e000fbc7f1892b1ea9f952f1667f4443f1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 29 16:52:18 2007 -0400

    Btrfs: block group switching
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 756ea9d0123b..1bb62867deda 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -249,10 +249,13 @@ struct btrfs_device_item {
 /* tag for the radix tree of block groups in ram */
 #define BTRFS_BLOCK_GROUP_DIRTY 0
 #define BTRFS_BLOCK_GROUP_AVAIL 1
-#define BTRFS_BLOCK_GROUP_HINTS 8
 #define BTRFS_BLOCK_GROUP_SIZE (256 * 1024 * 1024)
+
+
+#define BTRFS_BLOCK_GROUP_DATA 1
 struct btrfs_block_group_item {
 	__le64 used;
+	u8 flags;
 } __attribute__ ((__packed__));
 
 struct btrfs_block_group_cache {

commit 1de037a43edf67f3a9f66dd197195b3c08febb16
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 29 15:17:08 2007 -0400

    Btrfs: fixup various fsx failures
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e8f741167c6b..756ea9d0123b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1198,5 +1198,8 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_path *path,
 					  u64 objectid, u64 offset,
 					  int cow);
+int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root, struct btrfs_path *path,
+			u64 isize);
 /* super.c */
 #endif

commit 3a686375629da5d2e2ad019265b66ef113c87455
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 24 13:35:57 2007 -0400

    Btrfs: sparse files!
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3330004af1a6..e8f741167c6b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1180,6 +1180,7 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       u64 objectid, u64 pos, u64 offset,
+			       u64 disk_num_blocks,
 			       u64 num_blocks);
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,

commit e06afa839e726959be2166bec4cb85c117e213f1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed May 23 15:44:28 2007 -0400

    Btrfs: rename
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index da12d8275817..3330004af1a6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -32,6 +32,7 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_CSUM_SIZE 32
 /* four bytes for CRC32 */
 #define BTRFS_CRC32_SIZE 4
+#define BTRFS_EMPTY_DIR_SIZE 6
 
 /*
  * the key defines the order in the tree, and so it also defines (optimal)

commit f9f3c6b666f717510b67036c314ec915b9059eaa
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 21 14:05:12 2007 -0400

    Btrfs: 2.6.21-git fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5830b4333d83..da12d8275817 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1197,6 +1197,4 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  u64 objectid, u64 offset,
 					  int cow);
 /* super.c */
-extern struct subsystem btrfs_subsys;
-
 #endif

commit de428b63b16f9c74a24228a517713e8c65f79475
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri May 18 13:28:27 2007 -0400

    Btrfs: allocator optimizations, truncate readahead
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d8caeba5d758..5830b4333d83 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1081,7 +1081,7 @@ static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
 struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 struct btrfs_block_group_cache
 						 *hint, u64 search_start,
-						 int data);
+						 int data, int owner);
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,

commit 509659cde578d891445afd67d87121dd13e71596
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 10 12:36:17 2007 -0400

    Btrfs: switch to crc32c instead of sha256
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 92a6078de827..d8caeba5d758 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -30,6 +30,8 @@ extern struct kmem_cache *btrfs_path_cachep;
 
 /* 32 bytes in various csum fields */
 #define BTRFS_CSUM_SIZE 32
+/* four bytes for CRC32 */
+#define BTRFS_CRC32_SIZE 4
 
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
@@ -235,7 +237,7 @@ struct btrfs_file_extent_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_csum_item {
-	u8 csum[BTRFS_CSUM_SIZE];
+	u8 csum;
 } __attribute__ ((__packed__));
 
 struct btrfs_device_item {

commit e37c9e6921207cf503634b06bee37ecb7904408d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed May 9 20:13:14 2007 -0400

    Btrfs: many allocator fixes, pretty solid
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index cdb7c23c41f9..92a6078de827 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -259,7 +259,9 @@ struct btrfs_block_group_cache {
 	u64 first_free;
 	u64 last_alloc;
 	u64 pinned;
+	u64 last_prealloc;
 	int data;
+	int cached;
 };
 
 struct crypto_hash;
@@ -273,6 +275,7 @@ struct btrfs_fs_info {
 	struct radix_tree_root dev_radix;
 	struct radix_tree_root block_group_radix;
 	struct radix_tree_root block_group_data_radix;
+	struct radix_tree_root extent_map_radix;
 
 	u64 extent_tree_insert[BTRFS_MAX_LEVEL * 3];
 	int extent_tree_insert_nr;

commit 3e1ad54fe2839319c1aa66b954da0753f5b1f906
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 7 20:03:49 2007 -0400

    Btrfs: allocator and tuning
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 086e7dea3c92..cdb7c23c41f9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -255,6 +255,7 @@ struct btrfs_block_group_item {
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
+	struct radix_tree_root *radix;
 	u64 first_free;
 	u64 last_alloc;
 	u64 pinned;

commit be74417553f4b2ee46be2088007a674ef2f02330
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 6 10:15:01 2007 -0400

    Btrfs: more allocator enhancements
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 179a046ce5a4..086e7dea3c92 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -257,6 +257,8 @@ struct btrfs_block_group_cache {
 	struct btrfs_block_group_item item;
 	u64 first_free;
 	u64 last_alloc;
+	u64 pinned;
+	int data;
 };
 
 struct crypto_hash;
@@ -264,12 +266,12 @@ struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct btrfs_root *dev_root;
-	struct btrfs_block_group_cache *block_group_cache;
 	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
 	struct radix_tree_root dev_radix;
 	struct radix_tree_root block_group_radix;
+	struct radix_tree_root block_group_data_radix;
 
 	u64 extent_tree_insert[BTRFS_MAX_LEVEL * 3];
 	int extent_tree_insert_nr;
@@ -1072,7 +1074,8 @@ static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
 /* extent-tree.c */
 struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
 						 struct btrfs_block_group_cache
-						 *hint, int data);
+						 *hint, u64 search_start,
+						 int data);
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,

commit be08c1b9f8e679d45e086728445ac36cf250e92e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 3 09:06:49 2007 -0400

    Btrfs: early metadata/data split
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b5855a5365ef..179a046ce5a4 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1080,7 +1080,7 @@ struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, u64 owner,
 		       u64 num_blocks, u64 search_start,
-		       u64 search_end, struct btrfs_key *ins);
+		       u64 search_end, struct btrfs_key *ins, int data);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct buffer_head *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root

commit 35b7e476107e3d54f03384e0f2fa3dfd68933353
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed May 2 15:53:43 2007 -0400

    Btrfs: fix page cache memory leak
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e6bf9919536a..b5855a5365ef 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -8,6 +8,9 @@
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
+extern struct kmem_cache *btrfs_trans_handle_cachep;
+extern struct kmem_cache *btrfs_transaction_cachep;
+extern struct kmem_cache *btrfs_bit_radix_cachep;
 extern struct kmem_cache *btrfs_path_cachep;
 
 #define BTRFS_MAGIC "_BtRfS_M"

commit 31f3c99b73483f7b738a886c552050cbd6128ff3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 30 15:25:45 2007 -0400

    Btrfs: allocator improvements, inode block groups
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c432222d40e3..e6bf9919536a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -174,6 +174,7 @@ struct btrfs_inode_item {
 	__le64 generation;
 	__le64 size;
 	__le64 nblocks;
+	__le64 block_group;
 	__le32 nlink;
 	__le32 uid;
 	__le32 gid;
@@ -241,6 +242,7 @@ struct btrfs_device_item {
 
 /* tag for the radix tree of block groups in ram */
 #define BTRFS_BLOCK_GROUP_DIRTY 0
+#define BTRFS_BLOCK_GROUP_AVAIL 1
 #define BTRFS_BLOCK_GROUP_HINTS 8
 #define BTRFS_BLOCK_GROUP_SIZE (256 * 1024 * 1024)
 struct btrfs_block_group_item {
@@ -410,6 +412,17 @@ static inline void btrfs_set_inode_nblocks(struct btrfs_inode_item *i, u64 val)
 	i->nblocks = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_inode_block_group(struct btrfs_inode_item *i)
+{
+	return le64_to_cpu(i->block_group);
+}
+
+static inline void btrfs_set_inode_block_group(struct btrfs_inode_item *i,
+						u64 val)
+{
+	i->block_group = cpu_to_le64(val);
+}
+
 static inline u32 btrfs_inode_nlink(struct btrfs_inode_item *i)
 {
 	return le32_to_cpu(i->nlink);
@@ -1054,10 +1067,13 @@ static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
 	btrfs_item_offset((leaf)->items + (slot))))
 
 /* extent-tree.c */
+struct btrfs_block_group_cache *btrfs_find_block_group(struct btrfs_root *root,
+						 struct btrfs_block_group_cache
+						 *hint, int data);
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
-					    struct btrfs_root *root);
+					    struct btrfs_root *root, u64 hint);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, u64 owner,
 		       u64 num_blocks, u64 search_start,

commit cd1bc4653dc37f6390f4d6df4f987044c64f700b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 27 10:08:34 2007 -0400

    Btrfs: more block allocator work
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 419917279e65..c432222d40e3 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -250,6 +250,8 @@ struct btrfs_block_group_item {
 struct btrfs_block_group_cache {
 	struct btrfs_key key;
 	struct btrfs_block_group_item item;
+	u64 first_free;
+	u64 last_alloc;
 };
 
 struct crypto_hash;
@@ -257,7 +259,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct btrfs_root *dev_root;
-	struct btrfs_key last_insert;
+	struct btrfs_block_group_cache *block_group_cache;
 	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;

commit 9078a3e1e4e489dddc636c7bb8780349d4298743
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 26 16:46:15 2007 -0400

    Btrfs: start of block group code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 26d0cdd46f49..419917279e65 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -239,6 +239,19 @@ struct btrfs_device_item {
 	__le64 device_id;
 } __attribute__ ((__packed__));
 
+/* tag for the radix tree of block groups in ram */
+#define BTRFS_BLOCK_GROUP_DIRTY 0
+#define BTRFS_BLOCK_GROUP_HINTS 8
+#define BTRFS_BLOCK_GROUP_SIZE (256 * 1024 * 1024)
+struct btrfs_block_group_item {
+	__le64 used;
+} __attribute__ ((__packed__));
+
+struct btrfs_block_group_cache {
+	struct btrfs_key key;
+	struct btrfs_block_group_item item;
+};
+
 struct crypto_hash;
 struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
@@ -249,6 +262,7 @@ struct btrfs_fs_info {
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
 	struct radix_tree_root dev_radix;
+	struct radix_tree_root block_group_radix;
 
 	u64 extent_tree_insert[BTRFS_MAX_LEVEL * 3];
 	int extent_tree_insert_nr;
@@ -301,49 +315,67 @@ struct btrfs_root {
  * info about object characteristics.  There is one for every file and dir in
  * the FS
  */
-#define BTRFS_INODE_ITEM_KEY	1
+#define BTRFS_INODE_ITEM_KEY		1
+
+/* reserve 2-15 close to the inode for later flexibility */
 
 /*
  * dir items are the name -> inode pointers in a directory.  There is one
  * for every name in a directory.
  */
-#define BTRFS_DIR_ITEM_KEY	2
-#define BTRFS_DIR_INDEX_KEY	3
+#define BTRFS_DIR_ITEM_KEY	16
+#define BTRFS_DIR_INDEX_KEY	17
 /*
- * inline data is file data that fits in the btree.
+ * extent data is for file data
  */
-#define BTRFS_INLINE_DATA_KEY	4
-/*
- * extent data is for data that can't fit in the btree.  It points to
- * a (hopefully) huge chunk of disk
- */
-#define BTRFS_EXTENT_DATA_KEY	5
+#define BTRFS_EXTENT_DATA_KEY	18
 /*
  * csum items have the checksums for data in the extents
  */
-#define BTRFS_CSUM_ITEM_KEY	6
+#define BTRFS_CSUM_ITEM_KEY	19
+
+/* reserve 20-31 for other file stuff */
 
 /*
  * root items point to tree roots.  There are typically in the root
  * tree used by the super block to find all the other trees
  */
-#define BTRFS_ROOT_ITEM_KEY	7
+#define BTRFS_ROOT_ITEM_KEY	32
 /*
  * extent items are in the extent map tree.  These record which blocks
  * are used, and how many references there are to each block
  */
-#define BTRFS_EXTENT_ITEM_KEY	8
+#define BTRFS_EXTENT_ITEM_KEY	33
+
+/*
+ * block groups give us hints into the extent allocation trees.  Which
+ * blocks are free etc etc
+ */
+#define BTRFS_BLOCK_GROUP_ITEM_KEY 34
 
 /*
  * dev items list the devices that make up the FS
  */
-#define BTRFS_DEV_ITEM_KEY	9
+#define BTRFS_DEV_ITEM_KEY	35
 
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
  */
-#define BTRFS_STRING_ITEM_KEY	10
+#define BTRFS_STRING_ITEM_KEY	253
+
+
+static inline u64 btrfs_block_group_used(struct btrfs_block_group_item *bi)
+{
+	return le64_to_cpu(bi->used);
+}
+
+static inline void btrfs_set_block_group_used(struct
+						   btrfs_block_group_item *bi,
+						   u64 val)
+{
+	bi->used = cpu_to_le64(val);
+}
 
 static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
 {
@@ -1037,6 +1069,10 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
 int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				u64 blocknr, u64 num_blocks);
+int btrfs_write_dirty_block_groups(struct btrfs_trans_handle *trans,
+				    struct btrfs_root *root);
+int btrfs_free_block_groups(struct btrfs_fs_info *info);
+int btrfs_read_block_groups(struct btrfs_root *root);
 /* ctree.c */
 int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_path *path, u32 data_size);

commit f2458e1d8c90958ed3631654cb7fd5ab01478505
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 25 15:52:25 2007 -0400

    Btrfs: change around extent-tree prealloc
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2d166ca8b104..26d0cdd46f49 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -244,12 +244,17 @@ struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct btrfs_root *dev_root;
-	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
 	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
 	struct radix_tree_root dev_radix;
+
+	u64 extent_tree_insert[BTRFS_MAX_LEVEL * 3];
+	int extent_tree_insert_nr;
+	u64 extent_tree_prealloc[BTRFS_MAX_LEVEL * 3];
+	int extent_tree_prealloc_nr;
+
 	u64 generation;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;
@@ -267,8 +272,7 @@ struct btrfs_fs_info {
 
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
- * and for the extent tree extent_root root.  current_insert is used
- * only for the extent tree.
+ * and for the extent tree extent_root root.
  */
 struct btrfs_root {
 	struct buffer_head *node;

commit c62a1920ced752e86f57ab1d4ad0ec65012bce4d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 24 12:07:39 2007 -0400

    Btrfs: get rid of the extent_item type field
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 78248d577290..2d166ca8b104 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -152,9 +152,6 @@ struct btrfs_path {
 	int slots[BTRFS_MAX_LEVEL];
 };
 
-/* values for the type field in btrfs_extent_item */
-#define BTRFS_EXTENT_TREE 1
-#define BTRFS_EXTENT_FILE 2
 /*
  * items in the extent btree are used to record the objectid of the
  * owner of the block and the number of references
@@ -162,7 +159,6 @@ struct btrfs_path {
 struct btrfs_extent_item {
 	__le32 refs;
 	__le64 owner;
-	u8 type;
 } __attribute__ ((__packed__));
 
 struct btrfs_inode_timespec {
@@ -489,16 +485,6 @@ static inline void btrfs_set_extent_owner(struct btrfs_extent_item *ei, u64 val)
 	ei->owner = cpu_to_le64(val);
 }
 
-static inline u8 btrfs_extent_type(struct btrfs_extent_item *ei)
-{
-	return ei->type;
-}
-
-static inline void btrfs_set_extent_type(struct btrfs_extent_item *ei, u8 val)
-{
-	ei->type = val;
-}
-
 static inline u64 btrfs_node_blockptr(struct btrfs_node *n, int nr)
 {
 	return le64_to_cpu(n->ptrs[nr].blockptr);
@@ -1036,7 +1022,7 @@ struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root, u64 owner,
-		       u8 type, u64 num_blocks, u64 search_start,
+		       u64 num_blocks, u64 search_start,
 		       u64 search_end, struct btrfs_key *ins);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct buffer_head *buf);

commit 4d775673091d43b39fa9d086071009f98dec289e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 20 20:23:12 2007 -0400

    Btrfs: add owner and type fields to the extents aand block headers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 681b23933d9b..78248d577290 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -62,6 +62,7 @@ struct btrfs_header {
 	u8 fsid[16]; /* FS specific uuid */
 	__le64 blocknr; /* which block this node is supposed to live in */
 	__le64 generation;
+	__le64 owner;
 	__le16 nritems;
 	__le16 flags;
 	u8 level;
@@ -151,12 +152,17 @@ struct btrfs_path {
 	int slots[BTRFS_MAX_LEVEL];
 };
 
+/* values for the type field in btrfs_extent_item */
+#define BTRFS_EXTENT_TREE 1
+#define BTRFS_EXTENT_FILE 2
 /*
  * items in the extent btree are used to record the objectid of the
  * owner of the block and the number of references
  */
 struct btrfs_extent_item {
 	__le32 refs;
+	__le64 owner;
+	u8 type;
 } __attribute__ ((__packed__));
 
 struct btrfs_inode_timespec {
@@ -473,11 +479,32 @@ static inline void btrfs_set_extent_refs(struct btrfs_extent_item *ei, u32 val)
 	ei->refs = cpu_to_le32(val);
 }
 
+static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
+{
+	return le64_to_cpu(ei->owner);
+}
+
+static inline void btrfs_set_extent_owner(struct btrfs_extent_item *ei, u64 val)
+{
+	ei->owner = cpu_to_le64(val);
+}
+
+static inline u8 btrfs_extent_type(struct btrfs_extent_item *ei)
+{
+	return ei->type;
+}
+
+static inline void btrfs_set_extent_type(struct btrfs_extent_item *ei, u8 val)
+{
+	ei->type = val;
+}
+
 static inline u64 btrfs_node_blockptr(struct btrfs_node *n, int nr)
 {
 	return le64_to_cpu(n->ptrs[nr].blockptr);
 }
 
+
 static inline void btrfs_set_node_blockptr(struct btrfs_node *n, int nr,
 					   u64 val)
 {
@@ -636,6 +663,17 @@ static inline void btrfs_set_header_generation(struct btrfs_header *h,
 	h->generation = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_header_owner(struct btrfs_header *h)
+{
+	return le64_to_cpu(h->owner);
+}
+
+static inline void btrfs_set_header_owner(struct btrfs_header *h,
+					       u64 val)
+{
+	h->owner = cpu_to_le64(val);
+}
+
 static inline u16 btrfs_header_nritems(struct btrfs_header *h)
 {
 	return le16_to_cpu(h->nritems);
@@ -996,9 +1034,10 @@ int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root);
-int btrfs_alloc_extent(struct btrfs_trans_handle *trans, struct btrfs_root
-			*root, u64 num_blocks, u64 search_start, u64
-			search_end, struct btrfs_key *ins);
+int btrfs_alloc_extent(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root, u64 owner,
+		       u8 type, u64 num_blocks, u64 search_start,
+		       u64 search_end, struct btrfs_key *ins);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct buffer_head *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root

commit e66f709b157ee8557166c14b67c01bae978ac32e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 20 13:16:02 2007 -0400

    Btrfs: write barriers on commit, balance level before split
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 047a84762d93..681b23933d9b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -259,6 +259,7 @@ struct btrfs_fs_info {
 	struct list_head trans_list;
 	struct crypto_hash *hash_tfm;
 	spinlock_t hash_lock;
+	int do_barriers;
 	struct kobject kobj;
 };
 

commit 8fd17795b2261ecb1bad2a6df09ef14c4957a3fb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 19 21:01:03 2007 -0400

    Btrfs: early fsync support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d628a3b9441c..047a84762d93 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -256,6 +256,7 @@ struct btrfs_fs_info {
 	struct inode *btree_inode;
 	struct mutex trans_mutex;
 	struct mutex fs_mutex;
+	struct list_head trans_list;
 	struct crypto_hash *hash_tfm;
 	spinlock_t hash_lock;
 	struct kobject kobj;

commit 7e38180e207c8707691c12395e990a5d583c5e71
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 19 15:36:27 2007 -0400

    Btrfs: directory inode index is back
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index f1800008be34..d628a3b9441c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -185,11 +185,6 @@ struct btrfs_inode_item {
 	struct btrfs_inode_timespec otime;
 } __attribute__ ((__packed__));
 
-/* inline data is just a blob of bytes */
-struct btrfs_inline_data_item {
-	u8 data;
-} __attribute__ ((__packed__));
-
 struct btrfs_dir_item {
 	struct btrfs_disk_key location;
 	__le16 flags;
@@ -293,9 +288,6 @@ struct btrfs_root {
 #define BTRFS_KEY_TYPE_MASK	(((u32)BTRFS_KEY_TYPE_MAX - 1) << \
 				  BTRFS_KEY_TYPE_SHIFT)
 
-#define BTRFS_KEY_OVERFLOW_MAX 128
-#define BTRFS_KEY_OVERFLOW_MASK ((u32)BTRFS_KEY_OVERFLOW_MAX - 1)
-
 /*
  * inode items have the data typically returned from stat and store other
  * info about object characteristics.  There is one for every file and dir in
@@ -621,31 +613,6 @@ static inline void btrfs_set_key_type(struct btrfs_key *key, u32 val)
 	key->flags = (key->flags & ~(BTRFS_KEY_TYPE_MASK)) | val;
 }
 
-static inline u32 btrfs_key_overflow(struct btrfs_key *key)
-{
-	return key->flags & BTRFS_KEY_OVERFLOW_MASK;
-}
-
-static inline void btrfs_set_key_overflow(struct btrfs_key *key, u32 over)
-{
-	BUG_ON(over >= BTRFS_KEY_OVERFLOW_MAX);
-	key->flags = (key->flags & ~BTRFS_KEY_OVERFLOW_MASK) | over;
-}
-
-static inline u32 btrfs_disk_key_overflow(struct btrfs_disk_key *key)
-{
-	return le32_to_cpu(key->flags) & BTRFS_KEY_OVERFLOW_MASK;
-}
-
-static inline void btrfs_set_disk_key_overflow(struct btrfs_disk_key *key,
-					       u32 over)
-{
-	u32 flags = btrfs_disk_key_flags(key);
-	BUG_ON(over >= BTRFS_KEY_OVERFLOW_MAX);
-	flags = (flags & ~BTRFS_KEY_OVERFLOW_MASK) | over;
-	btrfs_set_disk_key_flags(key, flags);
-}
-
 static inline u64 btrfs_header_blocknr(struct btrfs_header *h)
 {
 	return le64_to_cpu(h->blocknr);
@@ -1079,15 +1046,24 @@ int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, const char *name, int name_len, u64 dir,
 			  struct btrfs_key *location, u8 type);
-int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
-			  *root, struct btrfs_path *path, u64 dir,
-			  const char *name, int name_len, int mod);
-int btrfs_lookup_dir_index_item(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root,
-				struct btrfs_path *path, u64 dir,
-				u64 objectid, int mod);
-int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
+struct btrfs_dir_item *btrfs_lookup_dir_item(struct btrfs_trans_handle *trans,
+					     struct btrfs_root *root,
+					     struct btrfs_path *path, u64 dir,
+					     const char *name, int name_len,
+					     int mod);
+struct btrfs_dir_item *
+btrfs_lookup_dir_index_item(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root,
+			    struct btrfs_path *path, u64 dir,
+			    u64 objectid, const char *name, int name_len,
+			    int mod);
+struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,
+			      struct btrfs_path *path,
 			      const char *name, int name_len);
+int btrfs_delete_one_dir_name(struct btrfs_trans_handle *trans,
+			      struct btrfs_root *root,
+			      struct btrfs_path *path,
+			      struct btrfs_dir_item *di);
 /* inode-map.c */
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *fs_root,

commit 236454dfffb64a95ee01c50a215153f5de61c475
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 19 13:37:44 2007 -0400

    Btrfs: many file_write fixes, inline data
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8a329d3901a2..f1800008be34 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -73,6 +73,9 @@ struct btrfs_header {
 			       (sizeof(struct btrfs_disk_key) + sizeof(u64)))
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->blocksize))
+#define BTRFS_MAX_INLINE_DATA_SIZE(r) (BTRFS_LEAF_DATA_SIZE(r) - \
+					sizeof(struct btrfs_item) - \
+					sizeof(struct btrfs_file_extent_item))
 
 struct buffer_head;
 /*
@@ -204,8 +207,12 @@ struct btrfs_root_item {
 	__le32 refs;
 } __attribute__ ((__packed__));
 
+#define BTRFS_FILE_EXTENT_REG 0
+#define BTRFS_FILE_EXTENT_INLINE 1
+
 struct btrfs_file_extent_item {
 	__le64 generation;
+	u8 type;
 	/*
 	 * disk space consumed by the extent, checksum blocks are included
 	 * in these numbers
@@ -862,6 +869,34 @@ static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 	return (u8 *)l->items;
 }
 
+static inline int btrfs_file_extent_type(struct btrfs_file_extent_item *e)
+{
+	return e->type;
+}
+static inline void btrfs_set_file_extent_type(struct btrfs_file_extent_item *e,
+					      u8 val)
+{
+	e->type = val;
+}
+
+static inline char *btrfs_file_extent_inline_start(struct
+						   btrfs_file_extent_item *e)
+{
+	return (char *)(&e->disk_blocknr);
+}
+
+static inline u32 btrfs_file_extent_calc_inline_size(u32 datasize)
+{
+	return (unsigned long)(&((struct
+		  btrfs_file_extent_item *)NULL)->disk_blocknr) + datasize;
+}
+
+static inline u32 btrfs_file_extent_inline_len(struct btrfs_item *e)
+{
+	struct btrfs_file_extent_item *fe = NULL;
+	return btrfs_item_size(e) - (unsigned long)(&fe->disk_blocknr);
+}
+
 static inline u64 btrfs_file_extent_disk_blocknr(struct btrfs_file_extent_item
 						 *e)
 {

commit a429e51371eee3c989160c003ee40bc3947c6a76
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 18 16:15:28 2007 -0400

    Btrfs: working file_write, reorganized key flags
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d75a4d5bc010..8a329d3901a2 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -282,11 +282,12 @@ struct btrfs_root {
 
 /* the lower bits in the key flags defines the item type */
 #define BTRFS_KEY_TYPE_MAX	256
-#define BTRFS_KEY_TYPE_MASK	(BTRFS_KEY_TYPE_MAX - 1)
+#define BTRFS_KEY_TYPE_SHIFT	24
+#define BTRFS_KEY_TYPE_MASK	(((u32)BTRFS_KEY_TYPE_MAX - 1) << \
+				  BTRFS_KEY_TYPE_SHIFT)
 
 #define BTRFS_KEY_OVERFLOW_MAX 128
-#define BTRFS_KEY_OVERFLOW_SHIFT 8
-#define BTRFS_KEY_OVERFLOW_MASK (0x7FULL << BTRFS_KEY_OVERFLOW_SHIFT)
+#define BTRFS_KEY_OVERFLOW_MASK ((u32)BTRFS_KEY_OVERFLOW_MAX - 1)
 
 /*
  * inode items have the data typically returned from stat and store other
@@ -586,56 +587,55 @@ static inline void btrfs_set_disk_key_flags(struct btrfs_disk_key *disk,
 	disk->flags = cpu_to_le32(val);
 }
 
-static inline u32 btrfs_key_overflow(struct btrfs_key *key)
+static inline u32 btrfs_disk_key_type(struct btrfs_disk_key *key)
 {
-	u32 over = key->flags & BTRFS_KEY_OVERFLOW_MASK;
-	return over >> BTRFS_KEY_OVERFLOW_SHIFT;
+	return le32_to_cpu(key->flags) >> BTRFS_KEY_TYPE_SHIFT;
 }
 
-static inline void btrfs_set_key_overflow(struct btrfs_key *key, u32 over)
+static inline void btrfs_set_disk_key_type(struct btrfs_disk_key *key,
+					       u32 val)
 {
-	BUG_ON(over >= BTRFS_KEY_OVERFLOW_MAX);
-	over = over << BTRFS_KEY_OVERFLOW_SHIFT;
-	key->flags = (key->flags & ~((u64)BTRFS_KEY_OVERFLOW_MASK)) | over;
+	u32 flags = btrfs_disk_key_flags(key);
+	BUG_ON(val >= BTRFS_KEY_TYPE_MAX);
+	val = val << BTRFS_KEY_TYPE_SHIFT;
+	flags = (flags & ~BTRFS_KEY_TYPE_MASK) | val;
+	btrfs_set_disk_key_flags(key, flags);
 }
 
 static inline u32 btrfs_key_type(struct btrfs_key *key)
 {
-	return key->flags & BTRFS_KEY_TYPE_MASK;
+	return key->flags >> BTRFS_KEY_TYPE_SHIFT;
 }
 
-static inline u32 btrfs_disk_key_type(struct btrfs_disk_key *key)
+static inline void btrfs_set_key_type(struct btrfs_key *key, u32 val)
 {
-	return le32_to_cpu(key->flags) & BTRFS_KEY_TYPE_MASK;
+	BUG_ON(val >= BTRFS_KEY_TYPE_MAX);
+	val = val << BTRFS_KEY_TYPE_SHIFT;
+	key->flags = (key->flags & ~(BTRFS_KEY_TYPE_MASK)) | val;
 }
 
-static inline void btrfs_set_key_type(struct btrfs_key *key, u32 type)
+static inline u32 btrfs_key_overflow(struct btrfs_key *key)
 {
-	BUG_ON(type >= BTRFS_KEY_TYPE_MAX);
-	key->flags = (key->flags & ~((u64)BTRFS_KEY_TYPE_MASK)) | type;
+	return key->flags & BTRFS_KEY_OVERFLOW_MASK;
 }
 
-static inline void btrfs_set_disk_key_type(struct btrfs_disk_key *key, u32 type)
+static inline void btrfs_set_key_overflow(struct btrfs_key *key, u32 over)
 {
-	u32 flags = btrfs_disk_key_flags(key);
-	BUG_ON(type >= BTRFS_KEY_TYPE_MAX);
-	flags = (flags & ~((u64)BTRFS_KEY_TYPE_MASK)) | type;
-	btrfs_set_disk_key_flags(key, flags);
+	BUG_ON(over >= BTRFS_KEY_OVERFLOW_MAX);
+	key->flags = (key->flags & ~BTRFS_KEY_OVERFLOW_MASK) | over;
 }
 
 static inline u32 btrfs_disk_key_overflow(struct btrfs_disk_key *key)
 {
-	u32 over = le32_to_cpu(key->flags) & BTRFS_KEY_OVERFLOW_MASK;
-	return over >> BTRFS_KEY_OVERFLOW_SHIFT;
+	return le32_to_cpu(key->flags) & BTRFS_KEY_OVERFLOW_MASK;
 }
 
-static inline void btrfs_set_disK_key_overflow(struct btrfs_disk_key *key,
+static inline void btrfs_set_disk_key_overflow(struct btrfs_disk_key *key,
 					       u32 over)
 {
 	u32 flags = btrfs_disk_key_flags(key);
 	BUG_ON(over >= BTRFS_KEY_OVERFLOW_MAX);
-	over = over << BTRFS_KEY_OVERFLOW_SHIFT;
-	flags = (flags & ~((u64)BTRFS_KEY_OVERFLOW_MASK)) | over;
+	flags = (flags & ~BTRFS_KEY_OVERFLOW_MASK) | over;
 	btrfs_set_disk_key_flags(key, flags);
 }
 

commit 70b2befd0c8a4064715d8b340270650cc9d15af8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 17 15:39:32 2007 -0400

    Btrfs: rework csums and extent item ordering
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ca3ab160f460..d75a4d5bc010 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -44,14 +44,14 @@ extern struct kmem_cache *btrfs_path_cachep;
  */
 struct btrfs_disk_key {
 	__le64 objectid;
-	__le64 offset;
 	__le32 flags;
+	__le64 offset;
 } __attribute__ ((__packed__));
 
 struct btrfs_key {
 	u64 objectid;
-	u64 offset;
 	u32 flags;
+	u64 offset;
 } __attribute__ ((__packed__));
 
 /*
@@ -227,7 +227,6 @@ struct btrfs_file_extent_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_csum_item {
-	__le64 extent_offset;
 	u8 csum[BTRFS_CSUM_SIZE];
 } __attribute__ ((__packed__));
 
@@ -925,17 +924,6 @@ static inline void btrfs_set_file_extent_num_blocks(struct
 	e->num_blocks = cpu_to_le64(val);
 }
 
-static inline u64 btrfs_csum_extent_offset(struct btrfs_csum_item *c)
-{
-	return le64_to_cpu(c->extent_offset);
-}
-
-static inline void btrfs_set_csum_extent_offset(struct btrfs_csum_item *c,
-						u64 val)
-{
-	c->extent_offset = cpu_to_le64(val);
-}
-
 static inline u16 btrfs_device_pathlen(struct btrfs_device_item *d)
 {
 	return le16_to_cpu(d->pathlen);
@@ -1091,7 +1079,6 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset,
-			  u64 extent_offset,
 			  char *data, size_t len);
 int btrfs_csum_verify_file_block(struct btrfs_root *root,
 				 u64 objectid, u64 offset,

commit b18c6685810af8e6763760711aece31ccc7a8ea8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 17 13:26:50 2007 -0400

    Btrfs: progress on file_write
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 796f19d03ab5..ca3ab160f460 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -999,7 +999,7 @@ static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
 	((type *)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset((leaf)->items + (slot))))
 
-/* extent-item.c */
+/* extent-tree.c */
 int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root);
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
@@ -1013,9 +1013,16 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 blocknr, u64 num_blocks, int pin);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
 			       btrfs_root *root);
+int btrfs_inc_extent_ref(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root,
+				u64 blocknr, u64 num_blocks);
 /* ctree.c */
 int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_path *path, u32 data_size);
+int btrfs_truncate_item(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root,
+			struct btrfs_path *path,
+			u32 new_size);
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
@@ -1073,11 +1080,10 @@ int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       struct btrfs_key *location, int mod);
 
 /* file-item.c */
-int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
+int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
-			       u64 objectid, u64 offset,
-			       u64 num_blocks, u64 hint_block,
-			       u64 *result);
+			       u64 objectid, u64 pos, u64 offset,
+			       u64 num_blocks);
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
@@ -1090,6 +1096,11 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 int btrfs_csum_verify_file_block(struct btrfs_root *root,
 				 u64 objectid, u64 offset,
 				 char *data, size_t len);
+struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
+					  struct btrfs_root *root,
+					  struct btrfs_path *path,
+					  u64 objectid, u64 offset,
+					  int cow);
 /* super.c */
 extern struct subsystem btrfs_subsys;
 

commit 6567e837df07e43bffc08ac40858af8133a007bf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 16 09:22:45 2007 -0400

    Btrfs: early work to file_write in big extents
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ef3583cf74d6..796f19d03ab5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -227,6 +227,7 @@ struct btrfs_file_extent_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_csum_item {
+	__le64 extent_offset;
 	u8 csum[BTRFS_CSUM_SIZE];
 } __attribute__ ((__packed__));
 
@@ -924,6 +925,17 @@ static inline void btrfs_set_file_extent_num_blocks(struct
 	e->num_blocks = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_csum_extent_offset(struct btrfs_csum_item *c)
+{
+	return le64_to_cpu(c->extent_offset);
+}
+
+static inline void btrfs_set_csum_extent_offset(struct btrfs_csum_item *c,
+						u64 val)
+{
+	c->extent_offset = cpu_to_le64(val);
+}
+
 static inline u16 btrfs_device_pathlen(struct btrfs_device_item *d)
 {
 	return le16_to_cpu(d->pathlen);
@@ -1002,6 +1014,8 @@ int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
 			       btrfs_root *root);
 /* ctree.c */
+int btrfs_extend_item(struct btrfs_trans_handle *trans, struct btrfs_root
+		      *root, struct btrfs_path *path, u32 data_size);
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
@@ -1071,6 +1085,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset,
+			  u64 extent_offset,
 			  char *data, size_t len);
 int btrfs_csum_verify_file_block(struct btrfs_root *root,
 				 u64 objectid, u64 offset,

commit b4100d64241fed93a3f821ddf59d11ab4443a3ba
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 12 12:14:00 2007 -0400

    Btrfs: add a device id to device items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 454eb88611bb..ef3583cf74d6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -91,10 +91,12 @@ struct btrfs_super_block {
 	__le64 total_blocks;
 	__le64 blocks_used;
 	__le64 root_dir_objectid;
+	__le64 last_device_id;
 	/* fields below here vary with the underlying disk */
 	__le64 device_block_start;
 	__le64 device_num_blocks;
 	__le64 device_root;
+	__le64 device_id;
 } __attribute__ ((__packed__));
 
 /*
@@ -230,6 +232,7 @@ struct btrfs_csum_item {
 
 struct btrfs_device_item {
 	__le16 pathlen;
+	__le64 device_id;
 } __attribute__ ((__packed__));
 
 struct crypto_hash;
@@ -798,6 +801,28 @@ static inline void btrfs_set_super_root_dir(struct btrfs_super_block *s, u64
 	s->root_dir_objectid = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_super_last_device_id(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->last_device_id);
+}
+
+static inline void btrfs_set_super_last_device_id(struct btrfs_super_block *s,
+						  u64 val)
+{
+	s->last_device_id = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_super_device_id(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->device_id);
+}
+
+static inline void btrfs_set_super_device_id(struct btrfs_super_block *s,
+						  u64 val)
+{
+	s->device_id = cpu_to_le64(val);
+}
+
 static inline u64 btrfs_super_device_block_start(struct btrfs_super_block *s)
 {
 	return le64_to_cpu(s->device_block_start);
@@ -910,6 +935,17 @@ static inline void btrfs_set_device_pathlen(struct btrfs_device_item *d,
 	d->pathlen = cpu_to_le16(val);
 }
 
+static inline u64 btrfs_device_id(struct btrfs_device_item *d)
+{
+	return le64_to_cpu(d->device_id);
+}
+
+static inline void btrfs_set_device_id(struct btrfs_device_item *d,
+						u64 val)
+{
+	d->device_id = cpu_to_le64(val);
+}
+
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;

commit 7eccb903a817e890c947ba4bc90c6a9af9b4219a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 11 15:53:25 2007 -0400

    Btrfs: create a logical->phsyical block number mapping scheme
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 01310de2bf4a..454eb88611bb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -242,6 +242,7 @@ struct btrfs_fs_info {
 	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
+	struct radix_tree_root dev_radix;
 	u64 generation;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;

commit 0bd93ba022f5c1ddb4e5b722b02f3c4a4a8865ad
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 11 13:57:44 2007 -0400

    Btrfs: early support for multiple devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 3f3a23f52a3b..01310de2bf4a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -13,10 +13,11 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_MAGIC "_BtRfS_M"
 
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
-#define BTRFS_EXTENT_TREE_OBJECTID 2ULL
-#define BTRFS_FS_TREE_OBJECTID 3ULL
-#define BTRFS_ROOT_TREE_DIR_OBJECTID 4ULL
-#define BTRFS_FIRST_FREE_OBJECTID 5ULL
+#define BTRFS_DEV_TREE_OBJECTID 2ULL
+#define BTRFS_EXTENT_TREE_OBJECTID 3ULL
+#define BTRFS_FS_TREE_OBJECTID 4ULL
+#define BTRFS_ROOT_TREE_DIR_OBJECTID 5ULL
+#define BTRFS_FIRST_FREE_OBJECTID 6ULL
 
 /*
  * we can actually store much bigger names, but lets not confuse the rest
@@ -90,6 +91,10 @@ struct btrfs_super_block {
 	__le64 total_blocks;
 	__le64 blocks_used;
 	__le64 root_dir_objectid;
+	/* fields below here vary with the underlying disk */
+	__le64 device_block_start;
+	__le64 device_num_blocks;
+	__le64 device_root;
 } __attribute__ ((__packed__));
 
 /*
@@ -223,10 +228,15 @@ struct btrfs_csum_item {
 	u8 csum[BTRFS_CSUM_SIZE];
 } __attribute__ ((__packed__));
 
+struct btrfs_device_item {
+	__le16 pathlen;
+} __attribute__ ((__packed__));
+
 struct crypto_hash;
 struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
+	struct btrfs_root *dev_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
 	struct radix_tree_root fs_roots_radix;
@@ -312,11 +322,16 @@ struct btrfs_root {
  */
 #define BTRFS_EXTENT_ITEM_KEY	8
 
+/*
+ * dev items list the devices that make up the FS
+ */
+#define BTRFS_DEV_ITEM_KEY	9
+
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
  */
-#define BTRFS_STRING_ITEM_KEY	9
+#define BTRFS_STRING_ITEM_KEY	10
 
 static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
 {
@@ -782,6 +797,40 @@ static inline void btrfs_set_super_root_dir(struct btrfs_super_block *s, u64
 	s->root_dir_objectid = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_super_device_block_start(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->device_block_start);
+}
+
+static inline void btrfs_set_super_device_block_start(struct btrfs_super_block
+						      *s, u64 val)
+{
+	s->device_block_start = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_super_device_num_blocks(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->device_num_blocks);
+}
+
+static inline void btrfs_set_super_device_num_blocks(struct btrfs_super_block
+						     *s, u64 val)
+{
+	s->device_num_blocks = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_super_device_root(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->device_root);
+}
+
+static inline void btrfs_set_super_device_root(struct btrfs_super_block
+						      *s, u64 val)
+{
+	s->device_root = cpu_to_le64(val);
+}
+
+
 static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 {
 	return (u8 *)l->items;
@@ -849,6 +898,17 @@ static inline void btrfs_set_file_extent_num_blocks(struct
 	e->num_blocks = cpu_to_le64(val);
 }
 
+static inline u16 btrfs_device_pathlen(struct btrfs_device_item *d)
+{
+	return le16_to_cpu(d->pathlen);
+}
+
+static inline void btrfs_set_device_pathlen(struct btrfs_device_item *d,
+						u16 val)
+{
+	d->pathlen = cpu_to_le16(val);
+}
+
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;

commit cac87faa09f56776602d4b6f15c1bd44f6da300e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 11 08:59:20 2007 -0400

    Btrfs: use a dedicated inode num for root root dir
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0ba560f0d2a6..3f3a23f52a3b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -15,7 +15,8 @@ extern struct kmem_cache *btrfs_path_cachep;
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
 #define BTRFS_EXTENT_TREE_OBJECTID 2ULL
 #define BTRFS_FS_TREE_OBJECTID 3ULL
-#define BTRFS_FIRST_FREE_OBJECTID 4ULL
+#define BTRFS_ROOT_TREE_DIR_OBJECTID 4ULL
+#define BTRFS_FIRST_FREE_OBJECTID 5ULL
 
 /*
  * we can actually store much bigger names, but lets not confuse the rest

commit d0dbc6245cefa36e19dff49c557ccf05e3063e9c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 10 12:36:36 2007 -0400

    Btrfs: drop owner and parentid
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5103709bb2b9..0ba560f0d2a6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -60,7 +60,6 @@ struct btrfs_header {
 	u8 fsid[16]; /* FS specific uuid */
 	__le64 blocknr; /* which block this node is supposed to live in */
 	__le64 generation;
-	__le64 parentid; /* objectid of the tree root */
 	__le16 nritems;
 	__le16 flags;
 	u8 level;
@@ -147,7 +146,6 @@ struct btrfs_path {
  */
 struct btrfs_extent_item {
 	__le32 refs;
-	__le64 owner;
 } __attribute__ ((__packed__));
 
 struct btrfs_inode_timespec {
@@ -443,16 +441,6 @@ static inline void btrfs_set_timespec_nsec(struct btrfs_inode_timespec *ts,
 	ts->nsec = cpu_to_le32(val);
 }
 
-static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
-{
-	return le64_to_cpu(ei->owner);
-}
-
-static inline void btrfs_set_extent_owner(struct btrfs_extent_item *ei, u64 val)
-{
-	ei->owner = cpu_to_le64(val);
-}
-
 static inline u32 btrfs_extent_refs(struct btrfs_extent_item *ei)
 {
 	return le32_to_cpu(ei->refs);
@@ -652,17 +640,6 @@ static inline void btrfs_set_header_generation(struct btrfs_header *h,
 	h->generation = cpu_to_le64(val);
 }
 
-static inline u64 btrfs_header_parentid(struct btrfs_header *h)
-{
-	return le64_to_cpu(h->parentid);
-}
-
-static inline void btrfs_set_header_parentid(struct btrfs_header *h,
-					     u64 parentid)
-{
-	h->parentid = cpu_to_le64(parentid);
-}
-
 static inline u16 btrfs_header_nritems(struct btrfs_header *h)
 {
 	return le16_to_cpu(h->nritems);
@@ -919,7 +896,7 @@ struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 			*root, u64 num_blocks, u64 search_start, u64
-			search_end, u64 owner, struct btrfs_key *ins);
+			search_end, struct btrfs_key *ins);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct buffer_head *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root

commit 1b05da2ee6217e7d55460d04335813fec25be4ca
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 10 12:13:09 2007 -0400

    Btrfs: drop the inode map tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 2cbcaaeac9e5..5103709bb2b9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -14,9 +14,8 @@ extern struct kmem_cache *btrfs_path_cachep;
 
 #define BTRFS_ROOT_TREE_OBJECTID 1ULL
 #define BTRFS_EXTENT_TREE_OBJECTID 2ULL
-#define BTRFS_INODE_MAP_OBJECTID 3ULL
-#define BTRFS_FS_TREE_OBJECTID 4ULL
-#define BTRFS_FIRST_FREE_OBJECTID 5ULL
+#define BTRFS_FS_TREE_OBJECTID 3ULL
+#define BTRFS_FIRST_FREE_OBJECTID 4ULL
 
 /*
  * we can actually store much bigger names, but lets not confuse the rest
@@ -62,7 +61,6 @@ struct btrfs_header {
 	__le64 blocknr; /* which block this node is supposed to live in */
 	__le64 generation;
 	__le64 parentid; /* objectid of the tree root */
-	__le32 ham;
 	__le16 nritems;
 	__le16 flags;
 	u8 level;
@@ -226,23 +224,16 @@ struct btrfs_csum_item {
 	u8 csum[BTRFS_CSUM_SIZE];
 } __attribute__ ((__packed__));
 
-struct btrfs_inode_map_item {
-	u32 refs;
-} __attribute__ ((__packed__));
-
 struct crypto_hash;
 struct btrfs_fs_info {
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
-	struct btrfs_root *inode_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
 	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
-	u64 last_inode_alloc;
 	u64 generation;
-	u64 highest_inode;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;
 	struct buffer_head *sb_buffer;
@@ -272,6 +263,8 @@ struct btrfs_root {
 	u32 blocksize;
 	int ref_cows;
 	u32 type;
+	u64 highest_inode;
+	u64 last_inode_alloc;
 };
 
 /* the lower bits in the key flags defines the item type */
@@ -320,16 +313,11 @@ struct btrfs_root {
  */
 #define BTRFS_EXTENT_ITEM_KEY	8
 
-/*
- * the inode map records which inode numbers are in use and where
- * they actually live on disk
- */
-#define BTRFS_INODE_MAP_ITEM_KEY 9
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
  */
-#define BTRFS_STRING_ITEM_KEY	10
+#define BTRFS_STRING_ITEM_KEY	9
 
 static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
 {
@@ -883,17 +871,6 @@ static inline void btrfs_set_file_extent_num_blocks(struct
 	e->num_blocks = cpu_to_le64(val);
 }
 
-static inline u32 btrfs_inode_map_refs(struct btrfs_inode_map_item *m)
-{
-	return le32_to_cpu(m->refs);
-}
-
-static inline void btrfs_set_inode_map_refs(struct btrfs_inode_map_item *m,
-					    u32 val)
-{
-	m->refs = cpu_to_le32(val);
-}
-
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;
@@ -996,12 +973,6 @@ int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *fs_root,
 			     u64 dirid, u64 *objectid);
-int btrfs_insert_inode_map(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root,
-			   u64 objectid, struct btrfs_key *location);
-int btrfs_lookup_inode_map(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, struct btrfs_path *path,
-			   u64 objectid, int mod);
 int btrfs_find_highest_inode(struct btrfs_root *fs_root, u64 *objectid);
 
 /* inode-item.c */

commit c5739bba5260a59cebd20a51a55080592c8d3b07
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 10 09:27:04 2007 -0400

    Btrfs: snapshot progress
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5460030c9e6a..2cbcaaeac9e5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -227,7 +227,7 @@ struct btrfs_csum_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_inode_map_item {
-	struct btrfs_disk_key key;
+	u32 refs;
 } __attribute__ ((__packed__));
 
 struct crypto_hash;
@@ -883,6 +883,17 @@ static inline void btrfs_set_file_extent_num_blocks(struct
 	e->num_blocks = cpu_to_le64(val);
 }
 
+static inline u32 btrfs_inode_map_refs(struct btrfs_inode_map_item *m)
+{
+	return le32_to_cpu(m->refs);
+}
+
+static inline void btrfs_set_inode_map_refs(struct btrfs_inode_map_item *m,
+					    u32 val)
+{
+	m->refs = cpu_to_le32(val);
+}
+
 static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 {
 	return sb->s_fs_info;
@@ -925,6 +936,8 @@ static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
 	btrfs_item_offset((leaf)->items + (slot))))
 
 /* extent-item.c */
+int btrfs_inc_root_ref(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root);
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root);
 int btrfs_alloc_extent(struct btrfs_trans_handle *trans, struct btrfs_root

commit 0f7d52f4431c530b4f39c524448c688bb7754de5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 9 10:42:37 2007 -0400

    Btrfs: groundwork for subvolume and snapshot roots
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1ff5b99af682..5460030c9e6a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -232,12 +232,12 @@ struct btrfs_inode_map_item {
 
 struct crypto_hash;
 struct btrfs_fs_info {
-	struct btrfs_root *fs_root;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
 	struct btrfs_root *inode_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
+	struct radix_tree_root fs_roots_radix;
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
 	u64 last_inode_alloc;
@@ -266,6 +266,9 @@ struct btrfs_root {
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
+	struct inode *inode;
+	u64 objectid;
+	u64 last_trans;
 	u32 blocksize;
 	int ref_cows;
 	u32 type;
@@ -595,7 +598,7 @@ static inline u32 btrfs_key_overflow(struct btrfs_key *key)
 
 static inline void btrfs_set_key_overflow(struct btrfs_key *key, u32 over)
 {
-	BUG_ON(over > BTRFS_KEY_OVERFLOW_MAX);
+	BUG_ON(over >= BTRFS_KEY_OVERFLOW_MAX);
 	over = over << BTRFS_KEY_OVERFLOW_SHIFT;
 	key->flags = (key->flags & ~((u64)BTRFS_KEY_OVERFLOW_MASK)) | over;
 }
@@ -634,7 +637,7 @@ static inline void btrfs_set_disK_key_overflow(struct btrfs_disk_key *key,
 					       u32 over)
 {
 	u32 flags = btrfs_disk_key_flags(key);
-	BUG_ON(over > BTRFS_KEY_OVERFLOW_MAX);
+	BUG_ON(over >= BTRFS_KEY_OVERFLOW_MAX);
 	over = over << BTRFS_KEY_OVERFLOW_SHIFT;
 	flags = (flags & ~((u64)BTRFS_KEY_OVERFLOW_MASK)) | over;
 	btrfs_set_disk_key_flags(key, flags);
@@ -748,6 +751,17 @@ static inline void btrfs_set_super_blocknr(struct btrfs_super_block *s, u64 val)
 	s->blocknr = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_super_generation(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->generation);
+}
+
+static inline void btrfs_set_super_generation(struct btrfs_super_block *s,
+					      u64 val)
+{
+	s->generation = cpu_to_le64(val);
+}
+
 static inline u64 btrfs_super_root(struct btrfs_super_block *s)
 {
 	return le64_to_cpu(s->root);

commit d6e4a428eb8f92bbb3537ccabadfb1195efb432b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 6 15:37:36 2007 -0400

    Btrfs: start of support for many FS volumes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6d40758b893f..1ff5b99af682 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -3,6 +3,7 @@
 
 #include <linux/fs.h>
 #include <linux/buffer_head.h>
+#include <linux/kobject.h>
 #include "bit-radix.h"
 
 struct btrfs_trans_handle;
@@ -183,13 +184,15 @@ struct btrfs_inline_data_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_dir_item {
-	__le64 objectid;
+	struct btrfs_disk_key location;
 	__le16 flags;
 	__le16 name_len;
 	u8 type;
 } __attribute__ ((__packed__));
 
 struct btrfs_root_item {
+	struct btrfs_inode_item inode;
+	__le64 root_dirid;
 	__le64 blocknr;
 	__le32 flags;
 	__le64 block_limit;
@@ -249,6 +252,7 @@ struct btrfs_fs_info {
 	struct mutex fs_mutex;
 	struct crypto_hash *hash_tfm;
 	spinlock_t hash_lock;
+	struct kobject kobj;
 };
 
 /*
@@ -504,16 +508,6 @@ static inline void btrfs_set_item_size(struct btrfs_item *item, u16 val)
 	item->size = cpu_to_le16(val);
 }
 
-static inline u64 btrfs_dir_objectid(struct btrfs_dir_item *d)
-{
-	return le64_to_cpu(d->objectid);
-}
-
-static inline void btrfs_set_dir_objectid(struct btrfs_dir_item *d, u64 val)
-{
-	d->objectid = cpu_to_le64(val);
-}
-
 static inline u16 btrfs_dir_flags(struct btrfs_dir_item *d)
 {
 	return le16_to_cpu(d->flags);
@@ -724,6 +718,16 @@ static inline void btrfs_set_root_blocknr(struct btrfs_root_item *item, u64 val)
 	item->blocknr = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_root_dirid(struct btrfs_root_item *item)
+{
+	return le64_to_cpu(item->root_dirid);
+}
+
+static inline void btrfs_set_root_dirid(struct btrfs_root_item *item, u64 val)
+{
+	item->root_dirid = cpu_to_le64(val);
+}
+
 static inline u32 btrfs_root_refs(struct btrfs_root_item *item)
 {
 	return le32_to_cpu(item->refs);
@@ -950,8 +954,8 @@ int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
 /* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
-			  *root, const char *name, int name_len, u64 dir, u64
-			  objectid, u8 type);
+			  *root, const char *name, int name_len, u64 dir,
+			  struct btrfs_key *location, u8 type);
 int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, struct btrfs_path *path, u64 dir,
 			  const char *name, int name_len, int mod);
@@ -978,7 +982,8 @@ int btrfs_insert_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       *root, u64 objectid, struct btrfs_inode_item
 		       *inode_item);
 int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
-		       *root, struct btrfs_path *path, u64 objectid, int mod);
+		       *root, struct btrfs_path *path,
+		       struct btrfs_key *location, int mod);
 
 /* file-item.c */
 int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
@@ -997,4 +1002,7 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 int btrfs_csum_verify_file_block(struct btrfs_root *root,
 				 u64 objectid, u64 offset,
 				 char *data, size_t len);
+/* super.c */
+extern struct subsystem btrfs_subsys;
+
 #endif

commit 5be6f7f174146d91039a27ebb2f1b4ac599172b3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 5 13:35:25 2007 -0400

    Btrfs: dirindex optimizations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 794f7e4f1c07..6d40758b893f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -239,6 +239,7 @@ struct btrfs_fs_info {
 	struct radix_tree_root pinned_radix;
 	u64 last_inode_alloc;
 	u64 generation;
+	u64 highest_inode;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;
 	struct buffer_head *sb_buffer;
@@ -970,6 +971,8 @@ int btrfs_insert_inode_map(struct btrfs_trans_handle *trans,
 int btrfs_lookup_inode_map(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct btrfs_path *path,
 			   u64 objectid, int mod);
+int btrfs_find_highest_inode(struct btrfs_root *fs_root, u64 *objectid);
+
 /* inode-item.c */
 int btrfs_insert_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       *root, u64 objectid, struct btrfs_inode_item

commit 7fcde0e3298c00ee18e2ae7f01c67f99133ef7be
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 5 12:13:21 2007 -0400

    Btrfs: finish off inode indexing in dirs, add overflows
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 61d7b4738af6..794f7e4f1c07 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -270,6 +270,10 @@ struct btrfs_root {
 #define BTRFS_KEY_TYPE_MAX	256
 #define BTRFS_KEY_TYPE_MASK	(BTRFS_KEY_TYPE_MAX - 1)
 
+#define BTRFS_KEY_OVERFLOW_MAX 128
+#define BTRFS_KEY_OVERFLOW_SHIFT 8
+#define BTRFS_KEY_OVERFLOW_MASK (0x7FULL << BTRFS_KEY_OVERFLOW_SHIFT)
+
 /*
  * inode items have the data typically returned from stat and store other
  * info about object characteristics.  There is one for every file and dir in
@@ -588,6 +592,19 @@ static inline void btrfs_set_disk_key_flags(struct btrfs_disk_key *disk,
 	disk->flags = cpu_to_le32(val);
 }
 
+static inline u32 btrfs_key_overflow(struct btrfs_key *key)
+{
+	u32 over = key->flags & BTRFS_KEY_OVERFLOW_MASK;
+	return over >> BTRFS_KEY_OVERFLOW_SHIFT;
+}
+
+static inline void btrfs_set_key_overflow(struct btrfs_key *key, u32 over)
+{
+	BUG_ON(over > BTRFS_KEY_OVERFLOW_MAX);
+	over = over << BTRFS_KEY_OVERFLOW_SHIFT;
+	key->flags = (key->flags & ~((u64)BTRFS_KEY_OVERFLOW_MASK)) | over;
+}
+
 static inline u32 btrfs_key_type(struct btrfs_key *key)
 {
 	return key->flags & BTRFS_KEY_TYPE_MASK;
@@ -612,6 +629,22 @@ static inline void btrfs_set_disk_key_type(struct btrfs_disk_key *key, u32 type)
 	btrfs_set_disk_key_flags(key, flags);
 }
 
+static inline u32 btrfs_disk_key_overflow(struct btrfs_disk_key *key)
+{
+	u32 over = le32_to_cpu(key->flags) & BTRFS_KEY_OVERFLOW_MASK;
+	return over >> BTRFS_KEY_OVERFLOW_SHIFT;
+}
+
+static inline void btrfs_set_disK_key_overflow(struct btrfs_disk_key *key,
+					       u32 over)
+{
+	u32 flags = btrfs_disk_key_flags(key);
+	BUG_ON(over > BTRFS_KEY_OVERFLOW_MAX);
+	over = over << BTRFS_KEY_OVERFLOW_SHIFT;
+	flags = (flags & ~((u64)BTRFS_KEY_OVERFLOW_MASK)) | over;
+	btrfs_set_disk_key_flags(key, flags);
+}
+
 static inline u64 btrfs_header_blocknr(struct btrfs_header *h)
 {
 	return le64_to_cpu(h->blocknr);

commit 5f26f772e5c4e833ffcb0599f54deda466d2a3e5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 5 10:38:44 2007 -0400

    Btrfs: more inode indexed directory work
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 87c56222a620..61d7b4738af6 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -921,6 +921,10 @@ int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, struct btrfs_path *path, u64 dir,
 			  const char *name, int name_len, int mod);
+int btrfs_lookup_dir_index_item(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root,
+				struct btrfs_path *path, u64 dir,
+				u64 objectid, int mod);
 int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
 			      const char *name, int name_len);
 /* inode-map.c */

commit bae45de03c4d54a9893dedf8a015beb2608b896a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 4 21:22:22 2007 -0400

    Btrfs: add dir inode index
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 41cc013ef08d..87c56222a620 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -282,41 +282,42 @@ struct btrfs_root {
  * for every name in a directory.
  */
 #define BTRFS_DIR_ITEM_KEY	2
+#define BTRFS_DIR_INDEX_KEY	3
 /*
  * inline data is file data that fits in the btree.
  */
-#define BTRFS_INLINE_DATA_KEY	3
+#define BTRFS_INLINE_DATA_KEY	4
 /*
  * extent data is for data that can't fit in the btree.  It points to
  * a (hopefully) huge chunk of disk
  */
-#define BTRFS_EXTENT_DATA_KEY	4
+#define BTRFS_EXTENT_DATA_KEY	5
 /*
  * csum items have the checksums for data in the extents
  */
-#define BTRFS_CSUM_ITEM_KEY	5
+#define BTRFS_CSUM_ITEM_KEY	6
 
 /*
  * root items point to tree roots.  There are typically in the root
  * tree used by the super block to find all the other trees
  */
-#define BTRFS_ROOT_ITEM_KEY	6
+#define BTRFS_ROOT_ITEM_KEY	7
 /*
  * extent items are in the extent map tree.  These record which blocks
  * are used, and how many references there are to each block
  */
-#define BTRFS_EXTENT_ITEM_KEY	7
+#define BTRFS_EXTENT_ITEM_KEY	8
 
 /*
  * the inode map records which inode numbers are in use and where
  * they actually live on disk
  */
-#define BTRFS_INODE_MAP_ITEM_KEY 8
+#define BTRFS_INODE_MAP_ITEM_KEY 9
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
  */
-#define BTRFS_STRING_ITEM_KEY	9
+#define BTRFS_STRING_ITEM_KEY	10
 
 static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
 {

commit b1a4d96509a78ad234d94e0b914b289c60d2969d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 4 15:27:52 2007 -0400

    Btrfs: tweak the inode-map and free extent search starts on cold mount
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d8e03bd797ff..41cc013ef08d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -238,7 +238,6 @@ struct btrfs_fs_info {
 	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
 	u64 last_inode_alloc;
-	u64 last_inode_alloc_dirid;
 	u64 generation;
 	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;

commit 2c90e5d658424bc71b111eb5a972240d5d06fe86
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 2 10:50:19 2007 -0400

    Btrfs: still corruption hunting
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9ec0d65ebe9b..d8e03bd797ff 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -7,6 +7,7 @@
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
+extern struct kmem_cache *btrfs_path_cachep;
 
 #define BTRFS_MAGIC "_BtRfS_M"
 
@@ -888,6 +889,8 @@ int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
+struct btrfs_path *btrfs_alloc_path(void);
+void btrfs_free_path(struct btrfs_path *p);
 void btrfs_init_path(struct btrfs_path *p);
 int btrfs_del_item(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_path *path);

commit d6025579531b7ea170ba283b171ff7a6bf7d0e12
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 30 14:27:56 2007 -0400

    Btrfs: corruption hunt continues
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index df1a025a771c..9ec0d65ebe9b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2,6 +2,7 @@
 #define __BTRFS__
 
 #include <linux/fs.h>
+#include <linux/buffer_head.h>
 #include "bit-radix.h"
 
 struct btrfs_trans_handle;
@@ -834,6 +835,37 @@ static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 	return sb->s_fs_info;
 }
 
+static inline void btrfs_check_bounds(void *vptr, size_t len,
+				     void *vcontainer, size_t container_len)
+{
+	char *ptr = vptr;
+	char *container = vcontainer;
+	WARN_ON(ptr < container);
+	WARN_ON(ptr + len > container + container_len);
+}
+
+static inline void btrfs_memcpy(struct btrfs_root *root,
+				void *dst_block,
+				void *dst, const void *src, size_t nr)
+{
+	btrfs_check_bounds(dst, nr, dst_block, root->fs_info->sb->s_blocksize);
+	memcpy(dst, src, nr);
+}
+
+static inline void btrfs_memmove(struct btrfs_root *root,
+				void *dst_block,
+				void *dst, void *src, size_t nr)
+{
+	btrfs_check_bounds(dst, nr, dst_block, root->fs_info->sb->s_blocksize);
+	memmove(dst, src, nr);
+}
+
+static inline void btrfs_mark_buffer_dirty(struct buffer_head *bh)
+{
+	WARN_ON(!atomic_read(&bh->b_count));
+	mark_buffer_dirty(bh);
+}
+
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \

commit f254e52c1ce550fdaa0d31f5e068f0d67c2485d4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 29 15:15:27 2007 -0400

    Btrfs: verify csums on read
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6ff87f44c5d8..df1a025a771c 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -21,6 +21,9 @@ struct btrfs_transaction;
  */
 #define BTRFS_NAME_LEN 255
 
+/* 32 bytes in various csum fields */
+#define BTRFS_CSUM_SIZE 32
+
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
  * block layout.  objectid corresonds to the inode number.  The flags
@@ -37,21 +40,21 @@ struct btrfs_transaction;
  */
 struct btrfs_disk_key {
 	__le64 objectid;
-	__le32 flags;
 	__le64 offset;
+	__le32 flags;
 } __attribute__ ((__packed__));
 
 struct btrfs_key {
 	u64 objectid;
-	u32 flags;
 	u64 offset;
+	u32 flags;
 } __attribute__ ((__packed__));
 
 /*
  * every tree block (leaf or node) starts with this header.
  */
 struct btrfs_header {
-	__le32 csum[8];
+	u8 csum[BTRFS_CSUM_SIZE];
 	u8 fsid[16]; /* FS specific uuid */
 	__le64 blocknr; /* which block this node is supposed to live in */
 	__le64 generation;
@@ -75,7 +78,7 @@ struct buffer_head;
  * it currently lacks any block count etc etc
  */
 struct btrfs_super_block {
-	__le32 csum[8];
+	u8 csum[BTRFS_CSUM_SIZE];
 	/* the first 3 fields must match struct btrfs_header */
 	u8 fsid[16];    /* FS specific uuid */
 	__le64 blocknr; /* this block number */
@@ -147,7 +150,7 @@ struct btrfs_extent_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_inode_timespec {
-	__le32 sec;
+	__le64 sec;
 	__le32 nsec;
 } __attribute__ ((__packed__));
 
@@ -214,6 +217,10 @@ struct btrfs_file_extent_item {
 	__le64 num_blocks;
 } __attribute__ ((__packed__));
 
+struct btrfs_csum_item {
+	u8 csum[BTRFS_CSUM_SIZE];
+} __attribute__ ((__packed__));
+
 struct btrfs_inode_map_item {
 	struct btrfs_disk_key key;
 } __attribute__ ((__packed__));
@@ -283,27 +290,32 @@ struct btrfs_root {
  * a (hopefully) huge chunk of disk
  */
 #define BTRFS_EXTENT_DATA_KEY	4
+/*
+ * csum items have the checksums for data in the extents
+ */
+#define BTRFS_CSUM_ITEM_KEY	5
+
 /*
  * root items point to tree roots.  There are typically in the root
  * tree used by the super block to find all the other trees
  */
-#define BTRFS_ROOT_ITEM_KEY	5
+#define BTRFS_ROOT_ITEM_KEY	6
 /*
  * extent items are in the extent map tree.  These record which blocks
  * are used, and how many references there are to each block
  */
-#define BTRFS_EXTENT_ITEM_KEY	6
+#define BTRFS_EXTENT_ITEM_KEY	7
 
 /*
  * the inode map records which inode numbers are in use and where
  * they actually live on disk
  */
-#define BTRFS_INODE_MAP_ITEM_KEY 7
+#define BTRFS_INODE_MAP_ITEM_KEY 8
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
  */
-#define BTRFS_STRING_ITEM_KEY	8
+#define BTRFS_STRING_ITEM_KEY	9
 
 static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
 {
@@ -407,15 +419,15 @@ static inline void btrfs_set_inode_compat_flags(struct btrfs_inode_item *i,
 	i->compat_flags = cpu_to_le16(val);
 }
 
-static inline u32 btrfs_timespec_sec(struct btrfs_inode_timespec *ts)
+static inline u64 btrfs_timespec_sec(struct btrfs_inode_timespec *ts)
 {
-	return le32_to_cpu(ts->sec);
+	return le64_to_cpu(ts->sec);
 }
 
 static inline void btrfs_set_timespec_sec(struct btrfs_inode_timespec *ts,
-					  u32 val)
+					  u64 val)
 {
-	ts->sec = cpu_to_le32(val);
+	ts->sec = cpu_to_le64(val);
 }
 
 static inline u32 btrfs_timespec_nsec(struct btrfs_inode_timespec *ts)
@@ -429,8 +441,6 @@ static inline void btrfs_set_timespec_nsec(struct btrfs_inode_timespec *ts,
 	ts->nsec = cpu_to_le32(val);
 }
 
-
-
 static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
 {
 	return le64_to_cpu(ei->owner);
@@ -905,4 +915,11 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
 			     u64 blocknr, int mod);
+int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root,
+			  u64 objectid, u64 offset,
+			  char *data, size_t len);
+int btrfs_csum_verify_file_block(struct btrfs_root *root,
+				 u64 objectid, u64 offset,
+				 char *data, size_t len);
 #endif

commit 87cbda5c1f54aba67b1e318a4a4824c9e9f16324
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 19:44:27 2007 -0400

    Btrfs: sha256 csums on metadata
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b2ebed756c13..6ff87f44c5d8 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -51,11 +51,11 @@ struct btrfs_key {
  * every tree block (leaf or node) starts with this header.
  */
 struct btrfs_header {
+	__le32 csum[8];
 	u8 fsid[16]; /* FS specific uuid */
 	__le64 blocknr; /* which block this node is supposed to live in */
 	__le64 generation;
 	__le64 parentid; /* objectid of the tree root */
-	__le32 csum;
 	__le32 ham;
 	__le16 nritems;
 	__le16 flags;
@@ -75,9 +75,10 @@ struct buffer_head;
  * it currently lacks any block count etc etc
  */
 struct btrfs_super_block {
+	__le32 csum[8];
+	/* the first 3 fields must match struct btrfs_header */
 	u8 fsid[16];    /* FS specific uuid */
 	__le64 blocknr; /* this block number */
-	__le32 csum;
 	__le64 magic;
 	__le32 blocksize;
 	__le64 generation;
@@ -217,6 +218,7 @@ struct btrfs_inode_map_item {
 	struct btrfs_disk_key key;
 } __attribute__ ((__packed__));
 
+struct crypto_hash;
 struct btrfs_fs_info {
 	struct btrfs_root *fs_root;
 	struct btrfs_root *extent_root;
@@ -236,6 +238,8 @@ struct btrfs_fs_info {
 	struct inode *btree_inode;
 	struct mutex trans_mutex;
 	struct mutex fs_mutex;
+	struct crypto_hash *hash_tfm;
+	spinlock_t hash_lock;
 };
 
 /*

commit d98237b3ede7ab98892f7fa62201a13694c526e2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 13:57:48 2007 -0400

    Btrfs: use a btree inode instead of sb_getblk
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1897f3a65b4f..b2ebed756c13 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -233,6 +233,7 @@ struct btrfs_fs_info {
 	struct btrfs_super_block *disk_super;
 	struct buffer_head *sb_buffer;
 	struct super_block *sb;
+	struct inode *btree_inode;
 	struct mutex trans_mutex;
 	struct mutex fs_mutex;
 };

commit 9773a788681db1f5c2701b7433737fdca61a14ba
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 27 11:26:26 2007 -0400

    Btrfs: byte offsets for file keys
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c3fa12a6b59e..1897f3a65b4f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -899,5 +899,5 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
-			     u64 blocknr, u64 num_blocks, int mod);
+			     u64 blocknr, int mod);
 #endif

commit 71951f35a6e413f2bfbd41829af8cf10a890aeb6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 27 09:16:29 2007 -0400

    Btrfs: add generation field to file extent
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a4ad39b58a4b..c3fa12a6b59e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -192,6 +192,7 @@ struct btrfs_root_item {
 } __attribute__ ((__packed__));
 
 struct btrfs_file_extent_item {
+	__le64 generation;
 	/*
 	 * disk space consumed by the extent, checksum blocks are included
 	 * in these numbers
@@ -764,6 +765,18 @@ static inline void btrfs_set_file_extent_disk_blocknr(struct
 	e->disk_blocknr = cpu_to_le64(val);
 }
 
+static inline u64 btrfs_file_extent_generation(struct btrfs_file_extent_item *e)
+{
+	return le64_to_cpu(e->generation);
+}
+
+static inline void btrfs_set_file_extent_generation(struct
+						    btrfs_file_extent_item *e,
+						    u64 val)
+{
+	e->generation = cpu_to_le64(val);
+}
+
 static inline u64 btrfs_file_extent_disk_num_blocks(struct
 						    btrfs_file_extent_item *e)
 {

commit 9a6f11ed8f421fb1cc7b37390e32316ff4701f5d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 27 09:06:38 2007 -0400

    Btrfs: split out level field in struct header
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1a98952e0faf..a4ad39b58a4b 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -59,7 +59,7 @@ struct btrfs_header {
 	__le32 ham;
 	__le16 nritems;
 	__le16 flags;
-	/* generation flags to be added */
+	u8 level;
 } __attribute__ ((__packed__));
 
 #define BTRFS_MAX_LEVEL 8
@@ -648,15 +648,13 @@ static inline void btrfs_set_header_flags(struct btrfs_header *h, u16 val)
 
 static inline int btrfs_header_level(struct btrfs_header *h)
 {
-	return btrfs_header_flags(h) & (BTRFS_MAX_LEVEL - 1);
+	return h->level;
 }
 
 static inline void btrfs_set_header_level(struct btrfs_header *h, int level)
 {
-	u16 flags;
 	BUG_ON(level > BTRFS_MAX_LEVEL);
-	flags = btrfs_header_flags(h) & ~(BTRFS_MAX_LEVEL - 1);
-	btrfs_set_header_flags(h, flags | level);
+	h->level = level;
 }
 
 static inline int btrfs_is_leaf(struct btrfs_node *n)

commit 6407bf6d7c449cbfb0a39d985194e265eda3baf4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 27 06:33:00 2007 -0400

    Btrfs: reference counts on data extents
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7b7120d3ab42..1a98952e0faf 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -9,10 +9,11 @@ struct btrfs_transaction;
 
 #define BTRFS_MAGIC "_BtRfS_M"
 
-#define BTRFS_ROOT_TREE_OBJECTID 1
-#define BTRFS_EXTENT_TREE_OBJECTID 2
-#define BTRFS_INODE_MAP_OBJECTID 3
-#define BTRFS_FS_TREE_OBJECTID 4
+#define BTRFS_ROOT_TREE_OBJECTID 1ULL
+#define BTRFS_EXTENT_TREE_OBJECTID 2ULL
+#define BTRFS_INODE_MAP_OBJECTID 3ULL
+#define BTRFS_FS_TREE_OBJECTID 4ULL
+#define BTRFS_FIRST_FREE_OBJECTID 5ULL
 
 /*
  * we can actually store much bigger names, but lets not confuse the rest

commit dee26a9f7aab7ffe1193cd1415b23a69426acc9f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 26 16:00:06 2007 -0400

    btrfs_get_block, file read/write
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0aa1052d9f67..7b7120d3ab42 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -198,7 +198,7 @@ struct btrfs_file_extent_item {
 	__le64 disk_blocknr;
 	__le64 disk_num_blocks;
 	/*
-	 * the logical offset in file bytes (no csums)
+	 * the logical offset in file blocks (no csums)
 	 * this extent record is for.  This allows a file extent to point
 	 * into the middle of an existing extent on disk, sharing it
 	 * between two snapshots (useful if some bytes in the middle of the
@@ -812,12 +812,19 @@ static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
 	((type *)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset((leaf)->items + (slot))))
 
+/* extent-item.c */
 struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root);
+int btrfs_alloc_extent(struct btrfs_trans_handle *trans, struct btrfs_root
+			*root, u64 num_blocks, u64 search_start, u64
+			search_end, u64 owner, struct btrfs_key *ins);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		  struct buffer_head *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 blocknr, u64 num_blocks, int pin);
+int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
+			       btrfs_root *root);
+/* ctree.c */
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_key *key, struct btrfs_path *p, int
 		      ins_len, int cow);
@@ -834,8 +841,7 @@ int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct btrfs_leaf *leaf);
 int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
 			*root, struct buffer_head *snap);
-int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
-			       btrfs_root *root);
+/* root-item.c */
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		   struct btrfs_key *key);
 int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root
@@ -846,6 +852,7 @@ int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
+/* dir-item.c */
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, const char *name, int name_len, u64 dir, u64
 			  objectid, u8 type);
@@ -854,6 +861,7 @@ int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  const char *name, int name_len, int mod);
 int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
 			      const char *name, int name_len);
+/* inode-map.c */
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *fs_root,
 			     u64 dirid, u64 *objectid);
@@ -863,9 +871,21 @@ int btrfs_insert_inode_map(struct btrfs_trans_handle *trans,
 int btrfs_lookup_inode_map(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct btrfs_path *path,
 			   u64 objectid, int mod);
+/* inode-item.c */
 int btrfs_insert_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       *root, u64 objectid, struct btrfs_inode_item
 		       *inode_item);
 int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
 		       *root, struct btrfs_path *path, u64 objectid, int mod);
+
+/* file-item.c */
+int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *root,
+			       u64 objectid, u64 offset,
+			       u64 num_blocks, u64 hint_block,
+			       u64 *result);
+int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root,
+			     struct btrfs_path *path, u64 objectid,
+			     u64 blocknr, u64 num_blocks, int mod);
 #endif

commit 8ef97622caa2d5f78d1dc58ab918e2fbfa9b357a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 26 10:15:30 2007 -0400

    Btrfs: add a radix back bit tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 68cafae6a850..0aa1052d9f67 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,8 +1,8 @@
 #ifndef __BTRFS__
 #define __BTRFS__
 
-#include <linux/radix-tree.h>
 #include <linux/fs.h>
+#include "bit-radix.h"
 
 struct btrfs_trans_handle;
 struct btrfs_transaction;
@@ -222,6 +222,7 @@ struct btrfs_fs_info {
 	struct btrfs_root *inode_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
+	struct radix_tree_root pending_del_radix;
 	struct radix_tree_root pinned_radix;
 	u64 last_inode_alloc;
 	u64 last_inode_alloc_dirid;

commit d561c025ee3a0aee53a225bedce0ee35fe12f335
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 19:47:49 2007 -0400

    Btrfs: very minimal locking
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 96cec6352f12..68cafae6a850 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -231,6 +231,7 @@ struct btrfs_fs_info {
 	struct buffer_head *sb_buffer;
 	struct super_block *sb;
 	struct mutex trans_mutex;
+	struct mutex fs_mutex;
 };
 
 /*

commit 7f5c15160e1436a53d01f9190db11c2a3a4d788a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 15:56:19 2007 -0400

    Add generation number to btrfs_header, readdir fixes, hash collision fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 983e3cc9ae9f..96cec6352f12 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -52,6 +52,7 @@ struct btrfs_key {
 struct btrfs_header {
 	u8 fsid[16]; /* FS specific uuid */
 	__le64 blocknr; /* which block this node is supposed to live in */
+	__le64 generation;
 	__le64 parentid; /* objectid of the tree root */
 	__le32 csum;
 	__le32 ham;
@@ -600,6 +601,17 @@ static inline void btrfs_set_header_blocknr(struct btrfs_header *h, u64 blocknr)
 	h->blocknr = cpu_to_le64(blocknr);
 }
 
+static inline u64 btrfs_header_generation(struct btrfs_header *h)
+{
+	return le64_to_cpu(h->generation);
+}
+
+static inline void btrfs_set_header_generation(struct btrfs_header *h,
+					       u64 val)
+{
+	h->generation = cpu_to_le64(val);
+}
+
 static inline u64 btrfs_header_parentid(struct btrfs_header *h)
 {
 	return le64_to_cpu(h->parentid);
@@ -839,7 +851,7 @@ int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, struct btrfs_path *path, u64 dir,
 			  const char *name, int name_len, int mod);
 int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
-			      char *name, int name_len);
+			      const char *name, int name_len);
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *fs_root,
 			     u64 dirid, u64 *objectid);

commit d571976292839cec05a2820b08f7629b145ed157
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 10:01:08 2007 -0400

    btrfs_create, btrfs_write_super, btrfs_sync_fs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4c19a3f12afd..983e3cc9ae9f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -833,7 +833,7 @@ int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
 			 btrfs_root_item *item, struct btrfs_key *key);
 int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
-			  *root, char *name, int name_len, u64 dir, u64
+			  *root, const char *name, int name_len, u64 dir, u64
 			  objectid, u8 type);
 int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, struct btrfs_path *path, u64 dir,

commit 79154b1b5bcf87903db7ff16a30b360b78d6fe4f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 22 15:59:16 2007 -0400

    Btrfs: transaction rework
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7748eecd9304..4c19a3f12afd 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -5,6 +5,7 @@
 #include <linux/fs.h>
 
 struct btrfs_trans_handle;
+struct btrfs_transaction;
 
 #define BTRFS_MAGIC "_BtRfS_M"
 
@@ -224,10 +225,11 @@ struct btrfs_fs_info {
 	u64 last_inode_alloc;
 	u64 last_inode_alloc_dirid;
 	u64 generation;
-	struct btrfs_trans_handle *running_transaction;
+	struct btrfs_transaction *running_transaction;
 	struct btrfs_super_block *disk_super;
 	struct buffer_head *sb_buffer;
 	struct super_block *sb;
+	struct mutex trans_mutex;
 };
 
 /*

commit e20d96d64f9cf9288ffecc9ad4714e91c3b97ca8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 22 12:13:20 2007 -0400

    Mountable btrfs, with readdir
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index ae8518cb94bf..7748eecd9304 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,6 +1,9 @@
 #ifndef __BTRFS__
 #define __BTRFS__
 
+#include <linux/radix-tree.h>
+#include <linux/fs.h>
+
 struct btrfs_trans_handle;
 
 #define BTRFS_MAGIC "_BtRfS_M"
@@ -10,6 +13,12 @@ struct btrfs_trans_handle;
 #define BTRFS_INODE_MAP_OBJECTID 3
 #define BTRFS_FS_TREE_OBJECTID 4
 
+/*
+ * we can actually store much bigger names, but lets not confuse the rest
+ * of linux
+ */
+#define BTRFS_NAME_LEN 255
+
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
  * block layout.  objectid corresonds to the inode number.  The flags
@@ -57,7 +66,7 @@ struct btrfs_header {
 #define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->blocksize))
 
-struct btrfs_buffer;
+struct buffer_head;
 /*
  * the super block basically lists the main trees of the FS
  * it currently lacks any block count etc etc
@@ -120,7 +129,7 @@ struct btrfs_node {
  * used while walking the tree.
  */
 struct btrfs_path {
-	struct btrfs_buffer *nodes[BTRFS_MAX_LEVEL];
+	struct buffer_head *nodes[BTRFS_MAX_LEVEL];
 	int slots[BTRFS_MAX_LEVEL];
 };
 
@@ -211,17 +220,14 @@ struct btrfs_fs_info {
 	struct btrfs_root *inode_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
-	struct radix_tree_root cache_radix;
 	struct radix_tree_root pinned_radix;
-	struct list_head trans;
-	struct list_head cache;
 	u64 last_inode_alloc;
 	u64 last_inode_alloc_dirid;
 	u64 generation;
-	int cache_size;
-	int fp;
 	struct btrfs_trans_handle *running_transaction;
 	struct btrfs_super_block *disk_super;
+	struct buffer_head *sb_buffer;
+	struct super_block *sb;
 };
 
 /*
@@ -230,8 +236,8 @@ struct btrfs_fs_info {
  * only for the extent tree.
  */
 struct btrfs_root {
-	struct btrfs_buffer *node;
-	struct btrfs_buffer *commit_root;
+	struct buffer_head *node;
+	struct buffer_head *commit_root;
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
 	struct btrfs_fs_info *fs_info;
@@ -389,6 +395,29 @@ static inline void btrfs_set_inode_compat_flags(struct btrfs_inode_item *i,
 	i->compat_flags = cpu_to_le16(val);
 }
 
+static inline u32 btrfs_timespec_sec(struct btrfs_inode_timespec *ts)
+{
+	return le32_to_cpu(ts->sec);
+}
+
+static inline void btrfs_set_timespec_sec(struct btrfs_inode_timespec *ts,
+					  u32 val)
+{
+	ts->sec = cpu_to_le32(val);
+}
+
+static inline u32 btrfs_timespec_nsec(struct btrfs_inode_timespec *ts)
+{
+	return le32_to_cpu(ts->nsec);
+}
+
+static inline void btrfs_set_timespec_nsec(struct btrfs_inode_timespec *ts,
+					  u32 val)
+{
+	ts->nsec = cpu_to_le32(val);
+}
+
+
 
 static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
 {
@@ -757,15 +786,20 @@ static inline void btrfs_set_file_extent_num_blocks(struct
 	e->num_blocks = cpu_to_le64(val);
 }
 
+static inline struct btrfs_root *btrfs_sb(struct super_block *sb)
+{
+	return sb->s_fs_info;
+}
+
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset((leaf)->items + (slot))))
 
-struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
+struct buffer_head *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
 					    struct btrfs_root *root);
 int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		  struct btrfs_buffer *buf);
+		  struct buffer_head *buf);
 int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, u64 blocknr, u64 num_blocks, int pin);
 int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
@@ -783,7 +817,7 @@ int btrfs_insert_empty_item(struct btrfs_trans_handle *trans, struct btrfs_root
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct btrfs_leaf *leaf);
 int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
-			*root, struct btrfs_buffer *snap);
+			*root, struct buffer_head *snap);
 int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
 			       btrfs_root *root);
 int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -800,8 +834,8 @@ int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  *root, char *name, int name_len, u64 dir, u64
 			  objectid, u8 type);
 int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
-			  *root, struct btrfs_path *path, u64 dir, char *name,
-			  int name_len, int mod);
+			  *root, struct btrfs_path *path, u64 dir,
+			  const char *name, int name_len, int mod);
 int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
 			      char *name, int name_len);
 int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,

commit 2e635a278354a1a7951e16cfea4c247d6d0e7c99
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 21 11:12:56 2007 -0400

    Btrfs: initial move to kernel module land
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 1a4d1d6fa401..ae8518cb94bf 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,9 +1,6 @@
 #ifndef __BTRFS__
 #define __BTRFS__
 
-#include "list.h"
-#include "kerncompat.h"
-
 struct btrfs_trans_handle;
 
 #define BTRFS_MAGIC "_BtRfS_M"
@@ -75,6 +72,7 @@ struct btrfs_super_block {
 	__le64 root;
 	__le64 total_blocks;
 	__le64 blocks_used;
+	__le64 root_dir_objectid;
 } __attribute__ ((__packed__));
 
 /*
@@ -693,6 +691,17 @@ static inline void btrfs_set_super_blocksize(struct btrfs_super_block *s,
 	s->blocksize = cpu_to_le32(val);
 }
 
+static inline u64 btrfs_super_root_dir(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->root_dir_objectid);
+}
+
+static inline void btrfs_set_super_root_dir(struct btrfs_super_block *s, u64
+					    val)
+{
+	s->root_dir_objectid = cpu_to_le64(val);
+}
+
 static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 {
 	return (u8 *)l->items;

commit 1261ec42b3d3a3ad878bd172144940e3ac710749
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 20 20:35:03 2007 -0400

    Btrfs: Better block record keeping, real mkfs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b30b2ce72455..1a4d1d6fa401 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -223,6 +223,7 @@ struct btrfs_fs_info {
 	int cache_size;
 	int fp;
 	struct btrfs_trans_handle *running_transaction;
+	struct btrfs_super_block *disk_super;
 };
 
 /*

commit 293ffd5fd340428276fbbd24ce7b98bf6728466b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 20 15:57:25 2007 -0400

    Btrfs: change dir-test to insert inode_items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 68e3da274f17..b30b2ce72455 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -219,6 +219,7 @@ struct btrfs_fs_info {
 	struct list_head cache;
 	u64 last_inode_alloc;
 	u64 last_inode_alloc_dirid;
+	u64 generation;
 	int cache_size;
 	int fp;
 	struct btrfs_trans_handle *running_transaction;
@@ -802,4 +803,9 @@ int btrfs_insert_inode_map(struct btrfs_trans_handle *trans,
 int btrfs_lookup_inode_map(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct btrfs_path *path,
 			   u64 objectid, int mod);
+int btrfs_insert_inode(struct btrfs_trans_handle *trans, struct btrfs_root
+		       *root, u64 objectid, struct btrfs_inode_item
+		       *inode_item);
+int btrfs_lookup_inode(struct btrfs_trans_handle *trans, struct btrfs_root
+		       *root, struct btrfs_path *path, u64 objectid, int mod);
 #endif

commit 9f5fae2fe6dc35b46bf56183f11398451851cb3f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 20 14:38:32 2007 -0400

    Btrfs: Add inode map, and the start of file extent items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 68f0af39777f..68e3da274f17 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -10,7 +10,8 @@ struct btrfs_trans_handle;
 
 #define BTRFS_ROOT_TREE_OBJECTID 1
 #define BTRFS_EXTENT_TREE_OBJECTID 2
-#define BTRFS_FS_TREE_OBJECTID 3
+#define BTRFS_INODE_MAP_OBJECTID 3
+#define BTRFS_FS_TREE_OBJECTID 4
 
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
@@ -178,31 +179,65 @@ struct btrfs_root_item {
 	__le64 block_limit;
 	__le64 blocks_used;
 	__le32 refs;
-};
+} __attribute__ ((__packed__));
 
-/*
- * in ram representation of the tree.  extent_root is used for all allocations
- * and for the extent tree extent_root root.  current_insert is used
- * only for the extent tree.
- */
-struct btrfs_root {
-	struct btrfs_buffer *node;
-	struct btrfs_buffer *commit_root;
+struct btrfs_file_extent_item {
+	/*
+	 * disk space consumed by the extent, checksum blocks are included
+	 * in these numbers
+	 */
+	__le64 disk_blocknr;
+	__le64 disk_num_blocks;
+	/*
+	 * the logical offset in file bytes (no csums)
+	 * this extent record is for.  This allows a file extent to point
+	 * into the middle of an existing extent on disk, sharing it
+	 * between two snapshots (useful if some bytes in the middle of the
+	 * extent have changed
+	 */
+	__le64 offset;
+	/*
+	 * the logical number of file blocks (no csums included)
+	 */
+	__le64 num_blocks;
+} __attribute__ ((__packed__));
+
+struct btrfs_inode_map_item {
+	struct btrfs_disk_key key;
+} __attribute__ ((__packed__));
+
+struct btrfs_fs_info {
+	struct btrfs_root *fs_root;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *tree_root;
+	struct btrfs_root *inode_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
-	int fp;
 	struct radix_tree_root cache_radix;
 	struct radix_tree_root pinned_radix;
 	struct list_head trans;
 	struct list_head cache;
+	u64 last_inode_alloc;
+	u64 last_inode_alloc_dirid;
 	int cache_size;
-	int ref_cows;
+	int fp;
+	struct btrfs_trans_handle *running_transaction;
+};
+
+/*
+ * in ram representation of the tree.  extent_root is used for all allocations
+ * and for the extent tree extent_root root.  current_insert is used
+ * only for the extent tree.
+ */
+struct btrfs_root {
+	struct btrfs_buffer *node;
+	struct btrfs_buffer *commit_root;
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
+	struct btrfs_fs_info *fs_info;
 	u32 blocksize;
-	struct btrfs_trans_handle *running_transaction;
+	int ref_cows;
+	u32 type;
 };
 
 /* the lower bits in the key flags defines the item type */
@@ -240,11 +275,17 @@ struct btrfs_root {
  * are used, and how many references there are to each block
  */
 #define BTRFS_EXTENT_ITEM_KEY	6
+
+/*
+ * the inode map records which inode numbers are in use and where
+ * they actually live on disk
+ */
+#define BTRFS_INODE_MAP_ITEM_KEY 7
 /*
  * string items are for debugging.  They just store a short string of
  * data in the FS
  */
-#define BTRFS_STRING_ITEM_KEY	7
+#define BTRFS_STRING_ITEM_KEY	8
 
 static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
 {
@@ -654,6 +695,57 @@ static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 {
 	return (u8 *)l->items;
 }
+
+static inline u64 btrfs_file_extent_disk_blocknr(struct btrfs_file_extent_item
+						 *e)
+{
+	return le64_to_cpu(e->disk_blocknr);
+}
+
+static inline void btrfs_set_file_extent_disk_blocknr(struct
+						      btrfs_file_extent_item
+						      *e, u64 val)
+{
+	e->disk_blocknr = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_file_extent_disk_num_blocks(struct
+						    btrfs_file_extent_item *e)
+{
+	return le64_to_cpu(e->disk_num_blocks);
+}
+
+static inline void btrfs_set_file_extent_disk_num_blocks(struct
+							 btrfs_file_extent_item
+							 *e, u64 val)
+{
+	e->disk_num_blocks = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_file_extent_offset(struct btrfs_file_extent_item *e)
+{
+	return le64_to_cpu(e->offset);
+}
+
+static inline void btrfs_set_file_extent_offset(struct btrfs_file_extent_item
+						*e, u64 val)
+{
+	e->offset = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_file_extent_num_blocks(struct btrfs_file_extent_item
+					       *e)
+{
+	return le64_to_cpu(e->num_blocks);
+}
+
+static inline void btrfs_set_file_extent_num_blocks(struct
+						    btrfs_file_extent_item *e,
+						    u64 val)
+{
+	e->num_blocks = cpu_to_le64(val);
+}
+
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
@@ -701,4 +793,13 @@ int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
 			  int name_len, int mod);
 int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
 			      char *name, int name_len);
+int btrfs_find_free_objectid(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *fs_root,
+			     u64 dirid, u64 *objectid);
+int btrfs_insert_inode_map(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root,
+			   u64 objectid, struct btrfs_key *location);
+int btrfs_lookup_inode_map(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, struct btrfs_path *path,
+			   u64 objectid, int mod);
 #endif

commit e089f05c18ab36ed5fa7e2319052e03ab800d518
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 16 16:20:31 2007 -0400

    Btrfs: transaction handles everywhere
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index d15a2ed95076..68f0af39777f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4,6 +4,8 @@
 #include "list.h"
 #include "kerncompat.h"
 
+struct btrfs_trans_handle;
+
 #define BTRFS_MAGIC "_BtRfS_M"
 
 #define BTRFS_ROOT_TREE_OBJECTID 1
@@ -200,6 +202,7 @@ struct btrfs_root {
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
 	u32 blocksize;
+	struct btrfs_trans_handle *running_transaction;
 };
 
 /* the lower bits in the key flags defines the item type */
@@ -656,34 +659,46 @@ static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 	((type *)(btrfs_leaf_data(leaf) + \
 	btrfs_item_offset((leaf)->items + (slot))))
 
-struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_root *root);
-int btrfs_inc_ref(struct btrfs_root *root, struct btrfs_buffer *buf);
-int btrfs_free_extent(struct btrfs_root *root, u64 blocknr, u64 num_blocks,
-		      int pin);
-int btrfs_search_slot(struct btrfs_root *root, struct btrfs_key *key,
-		struct btrfs_path *p, int ins_len, int cow);
+struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_trans_handle *trans,
+					    struct btrfs_root *root);
+int btrfs_inc_ref(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		  struct btrfs_buffer *buf);
+int btrfs_free_extent(struct btrfs_trans_handle *trans, struct btrfs_root
+		      *root, u64 blocknr, u64 num_blocks, int pin);
+int btrfs_search_slot(struct btrfs_trans_handle *trans, struct btrfs_root
+		      *root, struct btrfs_key *key, struct btrfs_path *p, int
+		      ins_len, int cow);
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 void btrfs_init_path(struct btrfs_path *p);
-int btrfs_del_item(struct btrfs_root *root, struct btrfs_path *path);
-int btrfs_insert_item(struct btrfs_root *root, struct btrfs_key *key,
-		void *data, u32 data_size);
-int btrfs_insert_empty_item(struct btrfs_root *root, struct btrfs_path *path,
-			    struct btrfs_key *cpu_key, u32 data_size);
+int btrfs_del_item(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		   struct btrfs_path *path);
+int btrfs_insert_item(struct btrfs_trans_handle *trans, struct btrfs_root
+		      *root, struct btrfs_key *key, void *data, u32 data_size);
+int btrfs_insert_empty_item(struct btrfs_trans_handle *trans, struct btrfs_root
+			    *root, struct btrfs_path *path, struct btrfs_key
+			    *cpu_key, u32 data_size);
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct btrfs_leaf *leaf);
-int btrfs_drop_snapshot(struct btrfs_root *root, struct btrfs_buffer *snap);
-int btrfs_finish_extent_commit(struct btrfs_root *root);
-int btrfs_del_root(struct btrfs_root *root, struct btrfs_key *key);
-int btrfs_insert_root(struct btrfs_root *root, struct btrfs_key *key,
-		      struct btrfs_root_item *item);
-int btrfs_update_root(struct btrfs_root *root, struct btrfs_key *key,
-		      struct btrfs_root_item *item);
-int btrfs_find_last_root(struct btrfs_root *root, u64 objectid,
-			struct btrfs_root_item *item, struct btrfs_key *key);
-int btrfs_insert_dir_item(struct btrfs_root *root, char *name, int name_len,
-			  u64 dir, u64 objectid, u8 type);
-int btrfs_lookup_dir_item(struct btrfs_root *root, struct btrfs_path *path,
-			  u64 dir, char *name, int name_len, int mod);
+int btrfs_drop_snapshot(struct btrfs_trans_handle *trans, struct btrfs_root
+			*root, struct btrfs_buffer *snap);
+int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans, struct
+			       btrfs_root *root);
+int btrfs_del_root(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		   struct btrfs_key *key);
+int btrfs_insert_root(struct btrfs_trans_handle *trans, struct btrfs_root
+		      *root, struct btrfs_key *key, struct btrfs_root_item
+		      *item);
+int btrfs_update_root(struct btrfs_trans_handle *trans, struct btrfs_root
+		      *root, struct btrfs_key *key, struct btrfs_root_item
+		      *item);
+int btrfs_find_last_root(struct btrfs_root *root, u64 objectid, struct
+			 btrfs_root_item *item, struct btrfs_key *key);
+int btrfs_insert_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
+			  *root, char *name, int name_len, u64 dir, u64
+			  objectid, u8 type);
+int btrfs_lookup_dir_item(struct btrfs_trans_handle *trans, struct btrfs_root
+			  *root, struct btrfs_path *path, u64 dir, char *name,
+			  int name_len, int mod);
 int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
 			      char *name, int name_len);
 #endif

commit 88fd146c27da0f34c512f47e2b3776a0762ecd81
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 16 08:56:18 2007 -0400

    Btrfs: pin freed blocks from the FS tree too
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7c66b647ea24..d15a2ed95076 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -658,7 +658,8 @@ static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 
 struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_root *root);
 int btrfs_inc_ref(struct btrfs_root *root, struct btrfs_buffer *buf);
-int btrfs_free_extent(struct btrfs_root *root, u64 blocknr, u64 num_blocks);
+int btrfs_free_extent(struct btrfs_root *root, u64 blocknr, u64 num_blocks,
+		      int pin);
 int btrfs_search_slot(struct btrfs_root *root, struct btrfs_key *key,
 		struct btrfs_path *p, int ins_len, int cow);
 void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);

commit a8a2ee0c600a213d13170c2f4d7bd0b304bbec19
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 16 08:46:49 2007 -0400

    Btrfs: add a name_len to dir items, reorder key
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index dbf3917833fe..7c66b647ea24 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -26,14 +26,14 @@
  */
 struct btrfs_disk_key {
 	__le64 objectid;
-	__le64 offset;
 	__le32 flags;
+	__le64 offset;
 } __attribute__ ((__packed__));
 
 struct btrfs_key {
 	u64 objectid;
-	u64 offset;
 	u32 flags;
+	u64 offset;
 } __attribute__ ((__packed__));
 
 /*
@@ -166,6 +166,7 @@ struct btrfs_inline_data_item {
 struct btrfs_dir_item {
 	__le64 objectid;
 	__le16 flags;
+	__le16 name_len;
 	u8 type;
 } __attribute__ ((__packed__));
 
@@ -431,9 +432,14 @@ static inline void btrfs_set_dir_type(struct btrfs_dir_item *d, u8 val)
 	d->type = val;
 }
 
-static inline u32 btrfs_dir_name_len(struct btrfs_item *i)
+static inline u16 btrfs_dir_name_len(struct btrfs_dir_item *d)
+{
+	return le16_to_cpu(d->name_len);
+}
+
+static inline void btrfs_set_dir_name_len(struct btrfs_dir_item *d, u16 val)
 {
-	return btrfs_item_size(i) - sizeof(struct btrfs_dir_item);
+	d->name_len = cpu_to_le16(val);
 }
 
 static inline void btrfs_disk_key_to_cpu(struct btrfs_key *cpu,

commit 1e1d27017c5986c1ea81181506042cf9cba3f6ea
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 15 19:03:33 2007 -0400

    Btrfs: add inode item
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 7a3492d5888e..dbf3917833fe 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -132,6 +132,37 @@ struct btrfs_extent_item {
 	__le64 owner;
 } __attribute__ ((__packed__));
 
+struct btrfs_inode_timespec {
+	__le32 sec;
+	__le32 nsec;
+} __attribute__ ((__packed__));
+
+/*
+ * there is no padding here on purpose.  If you want to extent the inode,
+ * make a new item type
+ */
+struct btrfs_inode_item {
+	__le64 generation;
+	__le64 size;
+	__le64 nblocks;
+	__le32 nlink;
+	__le32 uid;
+	__le32 gid;
+	__le32 mode;
+	__le32 rdev;
+	__le16 flags;
+	__le16 compat_flags;
+	struct btrfs_inode_timespec atime;
+	struct btrfs_inode_timespec ctime;
+	struct btrfs_inode_timespec mtime;
+	struct btrfs_inode_timespec otime;
+} __attribute__ ((__packed__));
+
+/* inline data is just a blob of bytes */
+struct btrfs_inline_data_item {
+	u8 data;
+} __attribute__ ((__packed__));
+
 struct btrfs_dir_item {
 	__le64 objectid;
 	__le16 flags;
@@ -170,15 +201,149 @@ struct btrfs_root {
 	u32 blocksize;
 };
 
-
 /* the lower bits in the key flags defines the item type */
 #define BTRFS_KEY_TYPE_MAX	256
 #define BTRFS_KEY_TYPE_MASK	(BTRFS_KEY_TYPE_MAX - 1)
+
+/*
+ * inode items have the data typically returned from stat and store other
+ * info about object characteristics.  There is one for every file and dir in
+ * the FS
+ */
 #define BTRFS_INODE_ITEM_KEY	1
+
+/*
+ * dir items are the name -> inode pointers in a directory.  There is one
+ * for every name in a directory.
+ */
 #define BTRFS_DIR_ITEM_KEY	2
-#define BTRFS_ROOT_ITEM_KEY	3
-#define BTRFS_EXTENT_ITEM_KEY	4
-#define BTRFS_STRING_ITEM_KEY	5
+/*
+ * inline data is file data that fits in the btree.
+ */
+#define BTRFS_INLINE_DATA_KEY	3
+/*
+ * extent data is for data that can't fit in the btree.  It points to
+ * a (hopefully) huge chunk of disk
+ */
+#define BTRFS_EXTENT_DATA_KEY	4
+/*
+ * root items point to tree roots.  There are typically in the root
+ * tree used by the super block to find all the other trees
+ */
+#define BTRFS_ROOT_ITEM_KEY	5
+/*
+ * extent items are in the extent map tree.  These record which blocks
+ * are used, and how many references there are to each block
+ */
+#define BTRFS_EXTENT_ITEM_KEY	6
+/*
+ * string items are for debugging.  They just store a short string of
+ * data in the FS
+ */
+#define BTRFS_STRING_ITEM_KEY	7
+
+static inline u64 btrfs_inode_generation(struct btrfs_inode_item *i)
+{
+	return le64_to_cpu(i->generation);
+}
+
+static inline void btrfs_set_inode_generation(struct btrfs_inode_item *i,
+					      u64 val)
+{
+	i->generation = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_inode_size(struct btrfs_inode_item *i)
+{
+	return le64_to_cpu(i->size);
+}
+
+static inline void btrfs_set_inode_size(struct btrfs_inode_item *i, u64 val)
+{
+	i->size = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_inode_nblocks(struct btrfs_inode_item *i)
+{
+	return le64_to_cpu(i->nblocks);
+}
+
+static inline void btrfs_set_inode_nblocks(struct btrfs_inode_item *i, u64 val)
+{
+	i->nblocks = cpu_to_le64(val);
+}
+
+static inline u32 btrfs_inode_nlink(struct btrfs_inode_item *i)
+{
+	return le32_to_cpu(i->nlink);
+}
+
+static inline void btrfs_set_inode_nlink(struct btrfs_inode_item *i, u32 val)
+{
+	i->nlink = cpu_to_le32(val);
+}
+
+static inline u32 btrfs_inode_uid(struct btrfs_inode_item *i)
+{
+	return le32_to_cpu(i->uid);
+}
+
+static inline void btrfs_set_inode_uid(struct btrfs_inode_item *i, u32 val)
+{
+	i->uid = cpu_to_le32(val);
+}
+
+static inline u32 btrfs_inode_gid(struct btrfs_inode_item *i)
+{
+	return le32_to_cpu(i->gid);
+}
+
+static inline void btrfs_set_inode_gid(struct btrfs_inode_item *i, u32 val)
+{
+	i->gid = cpu_to_le32(val);
+}
+
+static inline u32 btrfs_inode_mode(struct btrfs_inode_item *i)
+{
+	return le32_to_cpu(i->mode);
+}
+
+static inline void btrfs_set_inode_mode(struct btrfs_inode_item *i, u32 val)
+{
+	i->mode = cpu_to_le32(val);
+}
+
+static inline u32 btrfs_inode_rdev(struct btrfs_inode_item *i)
+{
+	return le32_to_cpu(i->rdev);
+}
+
+static inline void btrfs_set_inode_rdev(struct btrfs_inode_item *i, u32 val)
+{
+	i->rdev = cpu_to_le32(val);
+}
+
+static inline u16 btrfs_inode_flags(struct btrfs_inode_item *i)
+{
+	return le16_to_cpu(i->flags);
+}
+
+static inline void btrfs_set_inode_flags(struct btrfs_inode_item *i, u16 val)
+{
+	i->flags = cpu_to_le16(val);
+}
+
+static inline u16 btrfs_inode_compat_flags(struct btrfs_inode_item *i)
+{
+	return le16_to_cpu(i->compat_flags);
+}
+
+static inline void btrfs_set_inode_compat_flags(struct btrfs_inode_item *i,
+						u16 val)
+{
+	i->compat_flags = cpu_to_le16(val);
+}
+
 
 static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
 {
@@ -344,8 +509,6 @@ static inline void btrfs_set_disk_key_type(struct btrfs_disk_key *key, u32 type)
 	btrfs_set_disk_key_flags(key, flags);
 }
 
-
-
 static inline u64 btrfs_header_blocknr(struct btrfs_header *h)
 {
 	return le64_to_cpu(h->blocknr);

commit 1d4f6404de26df49eb8452f8fdf7672b59f407fc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 15 15:18:43 2007 -0400

    Btrfs: directory testing code and dir item fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e8a26fd8ea9f..7a3492d5888e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -180,37 +180,6 @@ struct btrfs_root {
 #define BTRFS_EXTENT_ITEM_KEY	4
 #define BTRFS_STRING_ITEM_KEY	5
 
-static inline u64 btrfs_dir_objectid(struct btrfs_dir_item *d)
-{
-	return le64_to_cpu(d->objectid);
-}
-
-static inline void btrfs_set_dir_objectid(struct btrfs_dir_item *d, u64 val)
-{
-	d->objectid = cpu_to_le64(val);
-}
-
-static inline u16 btrfs_dir_flags(struct btrfs_dir_item *d)
-{
-	return le16_to_cpu(d->flags);
-}
-
-static inline void btrfs_set_dir_flags(struct btrfs_dir_item *d, u16 val)
-{
-	d->flags = cpu_to_le16(val);
-}
-
-static inline u8 btrfs_dir_type(struct btrfs_dir_item *d)
-{
-	return d->type;
-}
-
-static inline void btrfs_set_dir_type(struct btrfs_dir_item *d, u8 val)
-{
-	d->type = val;
-}
-
-
 static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
 {
 	return le64_to_cpu(ei->owner);
@@ -267,6 +236,41 @@ static inline void btrfs_set_item_size(struct btrfs_item *item, u16 val)
 	item->size = cpu_to_le16(val);
 }
 
+static inline u64 btrfs_dir_objectid(struct btrfs_dir_item *d)
+{
+	return le64_to_cpu(d->objectid);
+}
+
+static inline void btrfs_set_dir_objectid(struct btrfs_dir_item *d, u64 val)
+{
+	d->objectid = cpu_to_le64(val);
+}
+
+static inline u16 btrfs_dir_flags(struct btrfs_dir_item *d)
+{
+	return le16_to_cpu(d->flags);
+}
+
+static inline void btrfs_set_dir_flags(struct btrfs_dir_item *d, u16 val)
+{
+	d->flags = cpu_to_le16(val);
+}
+
+static inline u8 btrfs_dir_type(struct btrfs_dir_item *d)
+{
+	return d->type;
+}
+
+static inline void btrfs_set_dir_type(struct btrfs_dir_item *d, u8 val)
+{
+	d->type = val;
+}
+
+static inline u32 btrfs_dir_name_len(struct btrfs_item *i)
+{
+	return btrfs_item_size(i) - sizeof(struct btrfs_dir_item);
+}
+
 static inline void btrfs_disk_key_to_cpu(struct btrfs_key *cpu,
 					 struct btrfs_disk_key *disk)
 {
@@ -506,4 +510,10 @@ int btrfs_update_root(struct btrfs_root *root, struct btrfs_key *key,
 		      struct btrfs_root_item *item);
 int btrfs_find_last_root(struct btrfs_root *root, u64 objectid,
 			struct btrfs_root_item *item, struct btrfs_key *key);
+int btrfs_insert_dir_item(struct btrfs_root *root, char *name, int name_len,
+			  u64 dir, u64 objectid, u8 type);
+int btrfs_lookup_dir_item(struct btrfs_root *root, struct btrfs_path *path,
+			  u64 dir, char *name, int name_len, int mod);
+int btrfs_match_dir_item_name(struct btrfs_root *root, struct btrfs_path *path,
+			      char *name, int name_len);
 #endif

commit 62e2749e03a855d98855f9ce032dbe72d5fad148
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 15 12:56:47 2007 -0400

    Btrfs: Use a chunk of the key flags to record the item type.
    Add (untested and simple) directory item code
    Fix comp_keys to use the new key ordering
    Add btrfs_insert_empty_item
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 73ebc824924a..e8a26fd8ea9f 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -58,39 +58,6 @@ struct btrfs_header {
 #define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->blocksize))
 
 struct btrfs_buffer;
-
-struct btrfs_root_item {
-	__le64 blocknr;
-	__le32 flags;
-	__le64 block_limit;
-	__le64 blocks_used;
-	__le32 refs;
-};
-
-/*
- * in ram representation of the tree.  extent_root is used for all allocations
- * and for the extent tree extent_root root.  current_insert is used
- * only for the extent tree.
- */
-struct btrfs_root {
-	struct btrfs_buffer *node;
-	struct btrfs_buffer *commit_root;
-	struct btrfs_root *extent_root;
-	struct btrfs_root *tree_root;
-	struct btrfs_key current_insert;
-	struct btrfs_key last_insert;
-	int fp;
-	struct radix_tree_root cache_radix;
-	struct radix_tree_root pinned_radix;
-	struct list_head trans;
-	struct list_head cache;
-	int cache_size;
-	int ref_cows;
-	struct btrfs_root_item root_item;
-	struct btrfs_key root_key;
-	u32 blocksize;
-};
-
 /*
  * the super block basically lists the main trees of the FS
  * it currently lacks any block count etc etc
@@ -108,8 +75,7 @@ struct btrfs_super_block {
 } __attribute__ ((__packed__));
 
 /*
- * A leaf is full of items.  The exact type of item is defined by
- * the key flags parameter.  offset and size tell us where to find
+ * A leaf is full of items. offset and size tell us where to find
  * the item in the leaf (relative to the start of the data area)
  */
 struct btrfs_item {
@@ -144,15 +110,6 @@ struct btrfs_node {
 	struct btrfs_key_ptr ptrs[];
 } __attribute__ ((__packed__));
 
-/*
- * items in the extent btree are used to record the objectid of the
- * owner of the block and the number of references
- */
-struct btrfs_extent_item {
-	__le32 refs;
-	__le64 owner;
-} __attribute__ ((__packed__));
-
 /*
  * btrfs_paths remember the path taken from the root down to the leaf.
  * level 0 is always the leaf, and nodes[1...BTRFS_MAX_LEVEL] will point
@@ -166,6 +123,94 @@ struct btrfs_path {
 	int slots[BTRFS_MAX_LEVEL];
 };
 
+/*
+ * items in the extent btree are used to record the objectid of the
+ * owner of the block and the number of references
+ */
+struct btrfs_extent_item {
+	__le32 refs;
+	__le64 owner;
+} __attribute__ ((__packed__));
+
+struct btrfs_dir_item {
+	__le64 objectid;
+	__le16 flags;
+	u8 type;
+} __attribute__ ((__packed__));
+
+struct btrfs_root_item {
+	__le64 blocknr;
+	__le32 flags;
+	__le64 block_limit;
+	__le64 blocks_used;
+	__le32 refs;
+};
+
+/*
+ * in ram representation of the tree.  extent_root is used for all allocations
+ * and for the extent tree extent_root root.  current_insert is used
+ * only for the extent tree.
+ */
+struct btrfs_root {
+	struct btrfs_buffer *node;
+	struct btrfs_buffer *commit_root;
+	struct btrfs_root *extent_root;
+	struct btrfs_root *tree_root;
+	struct btrfs_key current_insert;
+	struct btrfs_key last_insert;
+	int fp;
+	struct radix_tree_root cache_radix;
+	struct radix_tree_root pinned_radix;
+	struct list_head trans;
+	struct list_head cache;
+	int cache_size;
+	int ref_cows;
+	struct btrfs_root_item root_item;
+	struct btrfs_key root_key;
+	u32 blocksize;
+};
+
+
+/* the lower bits in the key flags defines the item type */
+#define BTRFS_KEY_TYPE_MAX	256
+#define BTRFS_KEY_TYPE_MASK	(BTRFS_KEY_TYPE_MAX - 1)
+#define BTRFS_INODE_ITEM_KEY	1
+#define BTRFS_DIR_ITEM_KEY	2
+#define BTRFS_ROOT_ITEM_KEY	3
+#define BTRFS_EXTENT_ITEM_KEY	4
+#define BTRFS_STRING_ITEM_KEY	5
+
+static inline u64 btrfs_dir_objectid(struct btrfs_dir_item *d)
+{
+	return le64_to_cpu(d->objectid);
+}
+
+static inline void btrfs_set_dir_objectid(struct btrfs_dir_item *d, u64 val)
+{
+	d->objectid = cpu_to_le64(val);
+}
+
+static inline u16 btrfs_dir_flags(struct btrfs_dir_item *d)
+{
+	return le16_to_cpu(d->flags);
+}
+
+static inline void btrfs_set_dir_flags(struct btrfs_dir_item *d, u16 val)
+{
+	d->flags = cpu_to_le16(val);
+}
+
+static inline u8 btrfs_dir_type(struct btrfs_dir_item *d)
+{
+	return d->type;
+}
+
+static inline void btrfs_set_dir_type(struct btrfs_dir_item *d, u8 val)
+{
+	d->type = val;
+}
+
+
 static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
 {
 	return le64_to_cpu(ei->owner);
@@ -238,39 +283,65 @@ static inline void btrfs_cpu_key_to_disk(struct btrfs_disk_key *disk,
 	disk->objectid = cpu_to_le64(cpu->objectid);
 }
 
-static inline u64 btrfs_key_objectid(struct btrfs_disk_key *disk)
+static inline u64 btrfs_disk_key_objectid(struct btrfs_disk_key *disk)
 {
 	return le64_to_cpu(disk->objectid);
 }
 
-static inline void btrfs_set_key_objectid(struct btrfs_disk_key *disk,
-					  u64 val)
+static inline void btrfs_set_disk_key_objectid(struct btrfs_disk_key *disk,
+					       u64 val)
 {
 	disk->objectid = cpu_to_le64(val);
 }
 
-static inline u64 btrfs_key_offset(struct btrfs_disk_key *disk)
+static inline u64 btrfs_disk_key_offset(struct btrfs_disk_key *disk)
 {
 	return le64_to_cpu(disk->offset);
 }
 
-static inline void btrfs_set_key_offset(struct btrfs_disk_key *disk,
-					  u64 val)
+static inline void btrfs_set_disk_key_offset(struct btrfs_disk_key *disk,
+					     u64 val)
 {
 	disk->offset = cpu_to_le64(val);
 }
 
-static inline u32 btrfs_key_flags(struct btrfs_disk_key *disk)
+static inline u32 btrfs_disk_key_flags(struct btrfs_disk_key *disk)
 {
 	return le32_to_cpu(disk->flags);
 }
 
-static inline void btrfs_set_key_flags(struct btrfs_disk_key *disk,
-					  u32 val)
+static inline void btrfs_set_disk_key_flags(struct btrfs_disk_key *disk,
+					    u32 val)
 {
 	disk->flags = cpu_to_le32(val);
 }
 
+static inline u32 btrfs_key_type(struct btrfs_key *key)
+{
+	return key->flags & BTRFS_KEY_TYPE_MASK;
+}
+
+static inline u32 btrfs_disk_key_type(struct btrfs_disk_key *key)
+{
+	return le32_to_cpu(key->flags) & BTRFS_KEY_TYPE_MASK;
+}
+
+static inline void btrfs_set_key_type(struct btrfs_key *key, u32 type)
+{
+	BUG_ON(type >= BTRFS_KEY_TYPE_MAX);
+	key->flags = (key->flags & ~((u64)BTRFS_KEY_TYPE_MASK)) | type;
+}
+
+static inline void btrfs_set_disk_key_type(struct btrfs_disk_key *key, u32 type)
+{
+	u32 flags = btrfs_disk_key_flags(key);
+	BUG_ON(type >= BTRFS_KEY_TYPE_MAX);
+	flags = (flags & ~((u64)BTRFS_KEY_TYPE_MASK)) | type;
+	btrfs_set_disk_key_flags(key, flags);
+}
+
+
+
 static inline u64 btrfs_header_blocknr(struct btrfs_header *h)
 {
 	return le64_to_cpu(h->blocknr);
@@ -407,7 +478,6 @@ static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 {
 	return (u8 *)l->items;
 }
-
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
 	((type *)(btrfs_leaf_data(leaf) + \
@@ -422,7 +492,9 @@ void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
 void btrfs_init_path(struct btrfs_path *p);
 int btrfs_del_item(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_insert_item(struct btrfs_root *root, struct btrfs_key *key,
-		void *data, int data_size);
+		void *data, u32 data_size);
+int btrfs_insert_empty_item(struct btrfs_root *root, struct btrfs_path *path,
+			    struct btrfs_key *cpu_key, u32 data_size);
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_root *root, struct btrfs_leaf *leaf);
 int btrfs_drop_snapshot(struct btrfs_root *root, struct btrfs_buffer *snap);

commit a1516c8921ce2c148b69493e858d95bc79c92f01
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 14 14:26:53 2007 -0400

    Btrfs: reorder key offset and flags
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index c61ad0f69be9..73ebc824924a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -26,14 +26,14 @@
  */
 struct btrfs_disk_key {
 	__le64 objectid;
-	__le32 flags;
 	__le64 offset;
+	__le32 flags;
 } __attribute__ ((__packed__));
 
 struct btrfs_key {
 	u64 objectid;
-	u32 flags;
 	u64 offset;
+	u32 flags;
 } __attribute__ ((__packed__));
 
 /*

commit 123abc88c9087b9c5605566ee3491aaef17fd837
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 14 14:14:43 2007 -0400

    Btrfs: variable block size support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 05c7707263f5..c61ad0f69be9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -5,7 +5,6 @@
 #include "kerncompat.h"
 
 #define BTRFS_MAGIC "_BtRfS_M"
-#define BTRFS_BLOCKSIZE 1024
 
 #define BTRFS_ROOT_TREE_OBJECTID 1
 #define BTRFS_EXTENT_TREE_OBJECTID 2
@@ -52,8 +51,11 @@ struct btrfs_header {
 } __attribute__ ((__packed__));
 
 #define BTRFS_MAX_LEVEL 8
-#define NODEPTRS_PER_BLOCK ((BTRFS_BLOCKSIZE - sizeof(struct btrfs_header)) / \
-			    (sizeof(struct btrfs_disk_key) + sizeof(u64)))
+#define BTRFS_NODEPTRS_PER_BLOCK(r) (((r)->blocksize - \
+			        sizeof(struct btrfs_header)) / \
+			       (sizeof(struct btrfs_disk_key) + sizeof(u64)))
+#define __BTRFS_LEAF_DATA_SIZE(bs) ((bs) - sizeof(struct btrfs_header))
+#define BTRFS_LEAF_DATA_SIZE(r) (__BTRFS_LEAF_DATA_SIZE(r->blocksize))
 
 struct btrfs_buffer;
 
@@ -86,6 +88,7 @@ struct btrfs_root {
 	int ref_cows;
 	struct btrfs_root_item root_item;
 	struct btrfs_key root_key;
+	u32 blocksize;
 };
 
 /*
@@ -97,7 +100,7 @@ struct btrfs_super_block {
 	__le64 blocknr; /* this block number */
 	__le32 csum;
 	__le64 magic;
-	__le16 blocksize;
+	__le32 blocksize;
 	__le64 generation;
 	__le64 root;
 	__le64 total_blocks;
@@ -111,7 +114,7 @@ struct btrfs_super_block {
  */
 struct btrfs_item {
 	struct btrfs_disk_key key;
-	__le16 offset;
+	__le32 offset;
 	__le16 size;
 } __attribute__ ((__packed__));
 
@@ -122,24 +125,23 @@ struct btrfs_item {
  * The data is separate from the items to get the keys closer together
  * during searches.
  */
-#define LEAF_DATA_SIZE (BTRFS_BLOCKSIZE - sizeof(struct btrfs_header))
 struct btrfs_leaf {
 	struct btrfs_header header;
-	union {
-		struct btrfs_item items[LEAF_DATA_SIZE/
-				        sizeof(struct btrfs_item)];
-		u8 data[BTRFS_BLOCKSIZE - sizeof(struct btrfs_header)];
-	};
+	struct btrfs_item items[];
 } __attribute__ ((__packed__));
 
 /*
  * all non-leaf blocks are nodes, they hold only keys and pointers to
  * other blocks
  */
+struct btrfs_key_ptr {
+	struct btrfs_disk_key key;
+	__le64 blockptr;
+} __attribute__ ((__packed__));
+
 struct btrfs_node {
 	struct btrfs_header header;
-	struct btrfs_disk_key keys[NODEPTRS_PER_BLOCK];
-	__le64 blockptrs[NODEPTRS_PER_BLOCK];
+	struct btrfs_key_ptr ptrs[];
 } __attribute__ ((__packed__));
 
 /*
@@ -186,28 +188,28 @@ static inline void btrfs_set_extent_refs(struct btrfs_extent_item *ei, u32 val)
 
 static inline u64 btrfs_node_blockptr(struct btrfs_node *n, int nr)
 {
-	return le64_to_cpu(n->blockptrs[nr]);
+	return le64_to_cpu(n->ptrs[nr].blockptr);
 }
 
 static inline void btrfs_set_node_blockptr(struct btrfs_node *n, int nr,
 					   u64 val)
 {
-	n->blockptrs[nr] = cpu_to_le64(val);
+	n->ptrs[nr].blockptr = cpu_to_le64(val);
 }
 
-static inline u16 btrfs_item_offset(struct btrfs_item *item)
+static inline u32 btrfs_item_offset(struct btrfs_item *item)
 {
-	return le16_to_cpu(item->offset);
+	return le32_to_cpu(item->offset);
 }
 
-static inline void btrfs_set_item_offset(struct btrfs_item *item, u16 val)
+static inline void btrfs_set_item_offset(struct btrfs_item *item, u32 val)
 {
-	item->offset = cpu_to_le16(val);
+	item->offset = cpu_to_le32(val);
 }
 
-static inline u16 btrfs_item_end(struct btrfs_item *item)
+static inline u32 btrfs_item_end(struct btrfs_item *item)
 {
-	return le16_to_cpu(item->offset) + le16_to_cpu(item->size);
+	return le32_to_cpu(item->offset) + le16_to_cpu(item->size);
 }
 
 static inline u16 btrfs_item_size(struct btrfs_item *item)
@@ -390,20 +392,26 @@ static inline void btrfs_set_super_blocks_used(struct btrfs_super_block *s,
 	s->blocks_used = cpu_to_le64(val);
 }
 
-static inline u16 btrfs_super_blocksize(struct btrfs_super_block *s)
+static inline u32 btrfs_super_blocksize(struct btrfs_super_block *s)
 {
-	return le16_to_cpu(s->blocksize);
+	return le32_to_cpu(s->blocksize);
 }
 
 static inline void btrfs_set_super_blocksize(struct btrfs_super_block *s,
-						u16 val)
+						u32 val)
+{
+	s->blocksize = cpu_to_le32(val);
+}
+
+static inline u8 *btrfs_leaf_data(struct btrfs_leaf *l)
 {
-	s->blocksize = cpu_to_le16(val);
+	return (u8 *)l->items;
 }
 
 /* helper function to cast into the data area of the leaf. */
 #define btrfs_item_ptr(leaf, slot, type) \
-	((type *)((leaf)->data + btrfs_item_offset((leaf)->items + (slot))))
+	((type *)(btrfs_leaf_data(leaf) + \
+	btrfs_item_offset((leaf)->items + (slot))))
 
 struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_root *root);
 int btrfs_inc_ref(struct btrfs_root *root, struct btrfs_buffer *buf);
@@ -416,7 +424,7 @@ int btrfs_del_item(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_insert_item(struct btrfs_root *root, struct btrfs_key *key,
 		void *data, int data_size);
 int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
-int btrfs_leaf_free_space(struct btrfs_leaf *leaf);
+int btrfs_leaf_free_space(struct btrfs_root *root, struct btrfs_leaf *leaf);
 int btrfs_drop_snapshot(struct btrfs_root *root, struct btrfs_buffer *snap);
 int btrfs_finish_extent_commit(struct btrfs_root *root);
 int btrfs_del_root(struct btrfs_root *root, struct btrfs_key *key);

commit 4beb1b8b75a86373f6020103ab840448d14c8880
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 14 10:31:29 2007 -0400

    Btrfs: add leaf data casting helper
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 0968899fb7f9..05c7707263f5 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -401,6 +401,10 @@ static inline void btrfs_set_super_blocksize(struct btrfs_super_block *s,
 	s->blocksize = cpu_to_le16(val);
 }
 
+/* helper function to cast into the data area of the leaf. */
+#define btrfs_item_ptr(leaf, slot, type) \
+	((type *)((leaf)->data + btrfs_item_offset((leaf)->items + (slot))))
+
 struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_root *root);
 int btrfs_inc_ref(struct btrfs_root *root, struct btrfs_buffer *buf);
 int btrfs_free_extent(struct btrfs_root *root, u64 blocknr, u64 num_blocks);

commit 3768f3689fc76ecea17414936dff7a02746a4355
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 13 16:47:54 2007 -0400

    Btrfs: Change the super to point to a tree of trees to enable persistent snapshots
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 5dfcc90812c1..0968899fb7f9 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -4,8 +4,13 @@
 #include "list.h"
 #include "kerncompat.h"
 
+#define BTRFS_MAGIC "_BtRfS_M"
 #define BTRFS_BLOCKSIZE 1024
 
+#define BTRFS_ROOT_TREE_OBJECTID 1
+#define BTRFS_EXTENT_TREE_OBJECTID 2
+#define BTRFS_FS_TREE_OBJECTID 3
+
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
  * block layout.  objectid corresonds to the inode number.  The flags
@@ -36,7 +41,7 @@ struct btrfs_key {
  * every tree block (leaf or node) starts with this header.
  */
 struct btrfs_header {
-	__le64 fsid[2]; /* FS specific uuid */
+	u8 fsid[16]; /* FS specific uuid */
 	__le64 blocknr; /* which block this node is supposed to live in */
 	__le64 parentid; /* objectid of the tree root */
 	__le32 csum;
@@ -52,6 +57,14 @@ struct btrfs_header {
 
 struct btrfs_buffer;
 
+struct btrfs_root_item {
+	__le64 blocknr;
+	__le32 flags;
+	__le64 block_limit;
+	__le64 blocks_used;
+	__le32 refs;
+};
+
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.  current_insert is used
@@ -61,6 +74,7 @@ struct btrfs_root {
 	struct btrfs_buffer *node;
 	struct btrfs_buffer *commit_root;
 	struct btrfs_root *extent_root;
+	struct btrfs_root *tree_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
 	int fp;
@@ -69,28 +83,25 @@ struct btrfs_root {
 	struct list_head trans;
 	struct list_head cache;
 	int cache_size;
+	int ref_cows;
+	struct btrfs_root_item root_item;
+	struct btrfs_key root_key;
 };
 
-/*
- * describes a tree on disk
- */
-struct btrfs_root_info {
-	u64 fsid[2]; /* FS specific uuid */
-	u64 blocknr; /* blocknr of this block */
-	u64 objectid; /* inode number of this root */
-	u64 tree_root; /* the tree root block */
-	u32 csum;
-	u32 ham;
-	u64 snapuuid[2]; /* root specific uuid */
-} __attribute__ ((__packed__));
-
 /*
  * the super block basically lists the main trees of the FS
  * it currently lacks any block count etc etc
  */
 struct btrfs_super_block {
-	struct btrfs_root_info root_info;
-	struct btrfs_root_info extent_info;
+	u8 fsid[16];    /* FS specific uuid */
+	__le64 blocknr; /* this block number */
+	__le32 csum;
+	__le64 magic;
+	__le16 blocksize;
+	__le64 generation;
+	__le64 root;
+	__le64 total_blocks;
+	__le64 blocks_used;
 } __attribute__ ((__packed__));
 
 /*
@@ -317,6 +328,79 @@ static inline int btrfs_is_leaf(struct btrfs_node *n)
 	return (btrfs_header_level(&n->header) == 0);
 }
 
+static inline u64 btrfs_root_blocknr(struct btrfs_root_item *item)
+{
+	return le64_to_cpu(item->blocknr);
+}
+
+static inline void btrfs_set_root_blocknr(struct btrfs_root_item *item, u64 val)
+{
+	item->blocknr = cpu_to_le64(val);
+}
+
+static inline u32 btrfs_root_refs(struct btrfs_root_item *item)
+{
+	return le32_to_cpu(item->refs);
+}
+
+static inline void btrfs_set_root_refs(struct btrfs_root_item *item, u32 val)
+{
+	item->refs = cpu_to_le32(val);
+}
+
+static inline u64 btrfs_super_blocknr(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->blocknr);
+}
+
+static inline void btrfs_set_super_blocknr(struct btrfs_super_block *s, u64 val)
+{
+	s->blocknr = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_super_root(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->root);
+}
+
+static inline void btrfs_set_super_root(struct btrfs_super_block *s, u64 val)
+{
+	s->root = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_super_total_blocks(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->total_blocks);
+}
+
+static inline void btrfs_set_super_total_blocks(struct btrfs_super_block *s,
+						u64 val)
+{
+	s->total_blocks = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_super_blocks_used(struct btrfs_super_block *s)
+{
+	return le64_to_cpu(s->blocks_used);
+}
+
+static inline void btrfs_set_super_blocks_used(struct btrfs_super_block *s,
+						u64 val)
+{
+	s->blocks_used = cpu_to_le64(val);
+}
+
+static inline u16 btrfs_super_blocksize(struct btrfs_super_block *s)
+{
+	return le16_to_cpu(s->blocksize);
+}
+
+static inline void btrfs_set_super_blocksize(struct btrfs_super_block *s,
+						u16 val)
+{
+	s->blocksize = cpu_to_le16(val);
+}
+
 struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_root *root);
 int btrfs_inc_ref(struct btrfs_root *root, struct btrfs_buffer *buf);
 int btrfs_free_extent(struct btrfs_root *root, u64 blocknr, u64 num_blocks);
@@ -331,4 +415,11 @@ int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
 int btrfs_leaf_free_space(struct btrfs_leaf *leaf);
 int btrfs_drop_snapshot(struct btrfs_root *root, struct btrfs_buffer *snap);
 int btrfs_finish_extent_commit(struct btrfs_root *root);
+int btrfs_del_root(struct btrfs_root *root, struct btrfs_key *key);
+int btrfs_insert_root(struct btrfs_root *root, struct btrfs_key *key,
+		      struct btrfs_root_item *item);
+int btrfs_update_root(struct btrfs_root *root, struct btrfs_key *key,
+		      struct btrfs_root_item *item);
+int btrfs_find_last_root(struct btrfs_root *root, u64 objectid,
+			struct btrfs_root_item *item, struct btrfs_key *key);
 #endif

commit 234b63a091e1df6bd4261dd7b3a7490074830628
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 13 10:46:10 2007 -0400

    rename funcs and structs to btrfs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 90cc2c9bd79e..5dfcc90812c1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,10 +1,10 @@
-#ifndef __CTREE__
-#define __CTREE__
+#ifndef __BTRFS__
+#define __BTRFS__
 
 #include "list.h"
 #include "kerncompat.h"
 
-#define CTREE_BLOCKSIZE 1024
+#define BTRFS_BLOCKSIZE 1024
 
 /*
  * the key defines the order in the tree, and so it also defines (optimal)
@@ -46,21 +46,21 @@ struct btrfs_header {
 	/* generation flags to be added */
 } __attribute__ ((__packed__));
 
-#define MAX_LEVEL 8
-#define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct btrfs_header)) / \
+#define BTRFS_MAX_LEVEL 8
+#define NODEPTRS_PER_BLOCK ((BTRFS_BLOCKSIZE - sizeof(struct btrfs_header)) / \
 			    (sizeof(struct btrfs_disk_key) + sizeof(u64)))
 
-struct tree_buffer;
+struct btrfs_buffer;
 
 /*
  * in ram representation of the tree.  extent_root is used for all allocations
  * and for the extent tree extent_root root.  current_insert is used
  * only for the extent tree.
  */
-struct ctree_root {
-	struct tree_buffer *node;
-	struct tree_buffer *commit_root;
-	struct ctree_root *extent_root;
+struct btrfs_root {
+	struct btrfs_buffer *node;
+	struct btrfs_buffer *commit_root;
+	struct btrfs_root *extent_root;
 	struct btrfs_key current_insert;
 	struct btrfs_key last_insert;
 	int fp;
@@ -74,7 +74,7 @@ struct ctree_root {
 /*
  * describes a tree on disk
  */
-struct ctree_root_info {
+struct btrfs_root_info {
 	u64 fsid[2]; /* FS specific uuid */
 	u64 blocknr; /* blocknr of this block */
 	u64 objectid; /* inode number of this root */
@@ -88,9 +88,9 @@ struct ctree_root_info {
  * the super block basically lists the main trees of the FS
  * it currently lacks any block count etc etc
  */
-struct ctree_super_block {
-	struct ctree_root_info root_info;
-	struct ctree_root_info extent_info;
+struct btrfs_super_block {
+	struct btrfs_root_info root_info;
+	struct btrfs_root_info extent_info;
 } __attribute__ ((__packed__));
 
 /*
@@ -111,13 +111,13 @@ struct btrfs_item {
  * The data is separate from the items to get the keys closer together
  * during searches.
  */
-#define LEAF_DATA_SIZE (CTREE_BLOCKSIZE - sizeof(struct btrfs_header))
-struct leaf {
+#define LEAF_DATA_SIZE (BTRFS_BLOCKSIZE - sizeof(struct btrfs_header))
+struct btrfs_leaf {
 	struct btrfs_header header;
 	union {
 		struct btrfs_item items[LEAF_DATA_SIZE/
 				        sizeof(struct btrfs_item)];
-		u8 data[CTREE_BLOCKSIZE-sizeof(struct btrfs_header)];
+		u8 data[BTRFS_BLOCKSIZE - sizeof(struct btrfs_header)];
 	};
 } __attribute__ ((__packed__));
 
@@ -125,7 +125,7 @@ struct leaf {
  * all non-leaf blocks are nodes, they hold only keys and pointers to
  * other blocks
  */
-struct node {
+struct btrfs_node {
 	struct btrfs_header header;
 	struct btrfs_disk_key keys[NODEPTRS_PER_BLOCK];
 	__le64 blockptrs[NODEPTRS_PER_BLOCK];
@@ -135,50 +135,51 @@ struct node {
  * items in the extent btree are used to record the objectid of the
  * owner of the block and the number of references
  */
-struct extent_item {
+struct btrfs_extent_item {
 	__le32 refs;
 	__le64 owner;
 } __attribute__ ((__packed__));
 
 /*
- * ctree_paths remember the path taken from the root down to the leaf.
- * level 0 is always the leaf, and nodes[1...MAX_LEVEL] will point
+ * btrfs_paths remember the path taken from the root down to the leaf.
+ * level 0 is always the leaf, and nodes[1...BTRFS_MAX_LEVEL] will point
  * to any other levels that are present.
  *
  * The slots array records the index of the item or block pointer
  * used while walking the tree.
  */
-struct ctree_path {
-	struct tree_buffer *nodes[MAX_LEVEL];
-	int slots[MAX_LEVEL];
+struct btrfs_path {
+	struct btrfs_buffer *nodes[BTRFS_MAX_LEVEL];
+	int slots[BTRFS_MAX_LEVEL];
 };
 
-static inline u64 btrfs_extent_owner(struct extent_item *ei)
+static inline u64 btrfs_extent_owner(struct btrfs_extent_item *ei)
 {
 	return le64_to_cpu(ei->owner);
 }
 
-static inline void btrfs_set_extent_owner(struct extent_item *ei, u64 val)
+static inline void btrfs_set_extent_owner(struct btrfs_extent_item *ei, u64 val)
 {
 	ei->owner = cpu_to_le64(val);
 }
 
-static inline u32 btrfs_extent_refs(struct extent_item *ei)
+static inline u32 btrfs_extent_refs(struct btrfs_extent_item *ei)
 {
 	return le32_to_cpu(ei->refs);
 }
 
-static inline void btrfs_set_extent_refs(struct extent_item *ei, u32 val)
+static inline void btrfs_set_extent_refs(struct btrfs_extent_item *ei, u32 val)
 {
 	ei->refs = cpu_to_le32(val);
 }
 
-static inline u64 btrfs_node_blockptr(struct node *n, int nr)
+static inline u64 btrfs_node_blockptr(struct btrfs_node *n, int nr)
 {
 	return le64_to_cpu(n->blockptrs[nr]);
 }
 
-static inline void btrfs_set_node_blockptr(struct node *n, int nr, u64 val)
+static inline void btrfs_set_node_blockptr(struct btrfs_node *n, int nr,
+					   u64 val)
 {
 	n->blockptrs[nr] = cpu_to_le64(val);
 }
@@ -300,34 +301,34 @@ static inline void btrfs_set_header_flags(struct btrfs_header *h, u16 val)
 
 static inline int btrfs_header_level(struct btrfs_header *h)
 {
-	return btrfs_header_flags(h) & (MAX_LEVEL - 1);
+	return btrfs_header_flags(h) & (BTRFS_MAX_LEVEL - 1);
 }
 
 static inline void btrfs_set_header_level(struct btrfs_header *h, int level)
 {
 	u16 flags;
-	BUG_ON(level > MAX_LEVEL);
-	flags = btrfs_header_flags(h) & ~(MAX_LEVEL - 1);
+	BUG_ON(level > BTRFS_MAX_LEVEL);
+	flags = btrfs_header_flags(h) & ~(BTRFS_MAX_LEVEL - 1);
 	btrfs_set_header_flags(h, flags | level);
 }
 
-static inline int btrfs_is_leaf(struct node *n)
+static inline int btrfs_is_leaf(struct btrfs_node *n)
 {
 	return (btrfs_header_level(&n->header) == 0);
 }
 
-struct tree_buffer *alloc_free_block(struct ctree_root *root);
-int btrfs_inc_ref(struct ctree_root *root, struct tree_buffer *buf);
-int free_extent(struct ctree_root *root, u64 blocknr, u64 num_blocks);
-int search_slot(struct ctree_root *root, struct btrfs_key *key,
-		struct ctree_path *p, int ins_len, int cow);
-void release_path(struct ctree_root *root, struct ctree_path *p);
-void init_path(struct ctree_path *p);
-int del_item(struct ctree_root *root, struct ctree_path *path);
-int insert_item(struct ctree_root *root, struct btrfs_key *key,
+struct btrfs_buffer *btrfs_alloc_free_block(struct btrfs_root *root);
+int btrfs_inc_ref(struct btrfs_root *root, struct btrfs_buffer *buf);
+int btrfs_free_extent(struct btrfs_root *root, u64 blocknr, u64 num_blocks);
+int btrfs_search_slot(struct btrfs_root *root, struct btrfs_key *key,
+		struct btrfs_path *p, int ins_len, int cow);
+void btrfs_release_path(struct btrfs_root *root, struct btrfs_path *p);
+void btrfs_init_path(struct btrfs_path *p);
+int btrfs_del_item(struct btrfs_root *root, struct btrfs_path *path);
+int btrfs_insert_item(struct btrfs_root *root, struct btrfs_key *key,
 		void *data, int data_size);
-int next_leaf(struct ctree_root *root, struct ctree_path *path);
-int leaf_free_space(struct leaf *leaf);
-int btrfs_drop_snapshot(struct ctree_root *root, struct tree_buffer *snap);
-int btrfs_finish_extent_commit(struct ctree_root *root);
+int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path);
+int btrfs_leaf_free_space(struct btrfs_leaf *leaf);
+int btrfs_drop_snapshot(struct btrfs_root *root, struct btrfs_buffer *snap);
+int btrfs_finish_extent_commit(struct btrfs_root *root);
 #endif

commit cf27e1eec063fa68a89c57ae0a83f93aa38851d6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 13 09:49:06 2007 -0400

    Btrfs: struct extent_item endian
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index a8454c401cee..90cc2c9bd79e 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -136,8 +136,8 @@ struct node {
  * owner of the block and the number of references
  */
 struct extent_item {
-	u32 refs;
-	u64 owner;
+	__le32 refs;
+	__le64 owner;
 } __attribute__ ((__packed__));
 
 /*
@@ -153,6 +153,26 @@ struct ctree_path {
 	int slots[MAX_LEVEL];
 };
 
+static inline u64 btrfs_extent_owner(struct extent_item *ei)
+{
+	return le64_to_cpu(ei->owner);
+}
+
+static inline void btrfs_set_extent_owner(struct extent_item *ei, u64 val)
+{
+	ei->owner = cpu_to_le64(val);
+}
+
+static inline u32 btrfs_extent_refs(struct extent_item *ei)
+{
+	return le32_to_cpu(ei->refs);
+}
+
+static inline void btrfs_set_extent_refs(struct extent_item *ei, u32 val)
+{
+	ei->refs = cpu_to_le32(val);
+}
+
 static inline u64 btrfs_node_blockptr(struct node *n, int nr)
 {
 	return le64_to_cpu(n->blockptrs[nr]);

commit 1d4f8a0c1eca5586134b56a4114a7cd5e85e3560
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 13 09:28:32 2007 -0400

    Btrfs: node->blockptrs endian fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b03df154dcdb..a8454c401cee 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -128,7 +128,7 @@ struct leaf {
 struct node {
 	struct btrfs_header header;
 	struct btrfs_disk_key keys[NODEPTRS_PER_BLOCK];
-	u64 blockptrs[NODEPTRS_PER_BLOCK];
+	__le64 blockptrs[NODEPTRS_PER_BLOCK];
 } __attribute__ ((__packed__));
 
 /*
@@ -153,6 +153,16 @@ struct ctree_path {
 	int slots[MAX_LEVEL];
 };
 
+static inline u64 btrfs_node_blockptr(struct node *n, int nr)
+{
+	return le64_to_cpu(n->blockptrs[nr]);
+}
+
+static inline void btrfs_set_node_blockptr(struct node *n, int nr, u64 val)
+{
+	n->blockptrs[nr] = cpu_to_le64(val);
+}
+
 static inline u16 btrfs_item_offset(struct btrfs_item *item)
 {
 	return le16_to_cpu(item->offset);

commit 0783fcfc4dc19b8bb99bd51b7afa669ba4cbd377
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 12 20:12:07 2007 -0400

    Btrfs: struct item endian fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 58e03e90f23a..b03df154dcdb 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -98,10 +98,10 @@ struct ctree_super_block {
  * the key flags parameter.  offset and size tell us where to find
  * the item in the leaf (relative to the start of the data area)
  */
-struct item {
+struct btrfs_item {
 	struct btrfs_disk_key key;
-	u16 offset;
-	u16 size;
+	__le16 offset;
+	__le16 size;
 } __attribute__ ((__packed__));
 
 /*
@@ -115,7 +115,8 @@ struct item {
 struct leaf {
 	struct btrfs_header header;
 	union {
-		struct item items[LEAF_DATA_SIZE/sizeof(struct item)];
+		struct btrfs_item items[LEAF_DATA_SIZE/
+				        sizeof(struct btrfs_item)];
 		u8 data[CTREE_BLOCKSIZE-sizeof(struct btrfs_header)];
 	};
 } __attribute__ ((__packed__));
@@ -152,6 +153,31 @@ struct ctree_path {
 	int slots[MAX_LEVEL];
 };
 
+static inline u16 btrfs_item_offset(struct btrfs_item *item)
+{
+	return le16_to_cpu(item->offset);
+}
+
+static inline void btrfs_set_item_offset(struct btrfs_item *item, u16 val)
+{
+	item->offset = cpu_to_le16(val);
+}
+
+static inline u16 btrfs_item_end(struct btrfs_item *item)
+{
+	return le16_to_cpu(item->offset) + le16_to_cpu(item->size);
+}
+
+static inline u16 btrfs_item_size(struct btrfs_item *item)
+{
+	return le16_to_cpu(item->size);
+}
+
+static inline void btrfs_set_item_size(struct btrfs_item *item, u16 val)
+{
+	item->size = cpu_to_le16(val);
+}
+
 static inline void btrfs_disk_key_to_cpu(struct btrfs_key *cpu,
 					 struct btrfs_disk_key *disk)
 {

commit e2fa7227cdf132d72e7410dd0679dc573a1c2618
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 12 16:22:34 2007 -0400

    Btrfs: struct key endian fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index e1aaca66d590..58e03e90f23a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2,6 +2,7 @@
 #define __CTREE__
 
 #include "list.h"
+#include "kerncompat.h"
 
 #define CTREE_BLOCKSIZE 1024
 
@@ -14,8 +15,18 @@
  * may point to extents.
  *
  * offset is the starting byte offset for this key in the stream.
+ *
+ * btrfs_disk_key is in disk byte order.  struct btrfs_key is always
+ * in cpu native order.  Otherwise they are identical and their sizes
+ * should be the same (ie both packed)
  */
-struct key {
+struct btrfs_disk_key {
+	__le64 objectid;
+	__le32 flags;
+	__le64 offset;
+} __attribute__ ((__packed__));
+
+struct btrfs_key {
 	u64 objectid;
 	u32 flags;
 	u64 offset;
@@ -37,7 +48,7 @@ struct btrfs_header {
 
 #define MAX_LEVEL 8
 #define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct btrfs_header)) / \
-			    (sizeof(struct key) + sizeof(u64)))
+			    (sizeof(struct btrfs_disk_key) + sizeof(u64)))
 
 struct tree_buffer;
 
@@ -50,8 +61,8 @@ struct ctree_root {
 	struct tree_buffer *node;
 	struct tree_buffer *commit_root;
 	struct ctree_root *extent_root;
-	struct key current_insert;
-	struct key last_insert;
+	struct btrfs_key current_insert;
+	struct btrfs_key last_insert;
 	int fp;
 	struct radix_tree_root cache_radix;
 	struct radix_tree_root pinned_radix;
@@ -88,7 +99,7 @@ struct ctree_super_block {
  * the item in the leaf (relative to the start of the data area)
  */
 struct item {
-	struct key key;
+	struct btrfs_disk_key key;
 	u16 offset;
 	u16 size;
 } __attribute__ ((__packed__));
@@ -115,7 +126,7 @@ struct leaf {
  */
 struct node {
 	struct btrfs_header header;
-	struct key keys[NODEPTRS_PER_BLOCK];
+	struct btrfs_disk_key keys[NODEPTRS_PER_BLOCK];
 	u64 blockptrs[NODEPTRS_PER_BLOCK];
 } __attribute__ ((__packed__));
 
@@ -141,6 +152,55 @@ struct ctree_path {
 	int slots[MAX_LEVEL];
 };
 
+static inline void btrfs_disk_key_to_cpu(struct btrfs_key *cpu,
+					 struct btrfs_disk_key *disk)
+{
+	cpu->offset = le64_to_cpu(disk->offset);
+	cpu->flags = le32_to_cpu(disk->flags);
+	cpu->objectid = le64_to_cpu(disk->objectid);
+}
+
+static inline void btrfs_cpu_key_to_disk(struct btrfs_disk_key *disk,
+					 struct btrfs_key *cpu)
+{
+	disk->offset = cpu_to_le64(cpu->offset);
+	disk->flags = cpu_to_le32(cpu->flags);
+	disk->objectid = cpu_to_le64(cpu->objectid);
+}
+
+static inline u64 btrfs_key_objectid(struct btrfs_disk_key *disk)
+{
+	return le64_to_cpu(disk->objectid);
+}
+
+static inline void btrfs_set_key_objectid(struct btrfs_disk_key *disk,
+					  u64 val)
+{
+	disk->objectid = cpu_to_le64(val);
+}
+
+static inline u64 btrfs_key_offset(struct btrfs_disk_key *disk)
+{
+	return le64_to_cpu(disk->offset);
+}
+
+static inline void btrfs_set_key_offset(struct btrfs_disk_key *disk,
+					  u64 val)
+{
+	disk->offset = cpu_to_le64(val);
+}
+
+static inline u32 btrfs_key_flags(struct btrfs_disk_key *disk)
+{
+	return le32_to_cpu(disk->flags);
+}
+
+static inline void btrfs_set_key_flags(struct btrfs_disk_key *disk,
+					  u32 val)
+{
+	disk->flags = cpu_to_le32(val);
+}
+
 static inline u64 btrfs_header_blocknr(struct btrfs_header *h)
 {
 	return le64_to_cpu(h->blocknr);
@@ -203,11 +263,13 @@ static inline int btrfs_is_leaf(struct node *n)
 struct tree_buffer *alloc_free_block(struct ctree_root *root);
 int btrfs_inc_ref(struct ctree_root *root, struct tree_buffer *buf);
 int free_extent(struct ctree_root *root, u64 blocknr, u64 num_blocks);
-int search_slot(struct ctree_root *root, struct key *key, struct ctree_path *p, int ins_len, int cow);
+int search_slot(struct ctree_root *root, struct btrfs_key *key,
+		struct ctree_path *p, int ins_len, int cow);
 void release_path(struct ctree_root *root, struct ctree_path *p);
 void init_path(struct ctree_path *p);
 int del_item(struct ctree_root *root, struct ctree_path *path);
-int insert_item(struct ctree_root *root, struct key *key, void *data, int data_size);
+int insert_item(struct ctree_root *root, struct btrfs_key *key,
+		void *data, int data_size);
 int next_leaf(struct ctree_root *root, struct ctree_path *path);
 int leaf_free_space(struct leaf *leaf);
 int btrfs_drop_snapshot(struct ctree_root *root, struct tree_buffer *snap);

commit bb492bb0a5453222109a72859353728959c2539d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 12 12:29:44 2007 -0400

    Btrfs: Add sparse endian annotations to struct header
    rename struct header to btrfs_header
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 60c21fe1566a..e1aaca66d590 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -24,19 +24,19 @@ struct key {
 /*
  * every tree block (leaf or node) starts with this header.
  */
-struct header {
-	u64 fsid[2]; /* FS specific uuid */
-	u64 blocknr; /* which block this node is supposed to live in */
-	u64 parentid; /* objectid of the tree root */
-	u32 csum;
-	u32 ham;
-	u16 nritems;
-	u16 flags;
+struct btrfs_header {
+	__le64 fsid[2]; /* FS specific uuid */
+	__le64 blocknr; /* which block this node is supposed to live in */
+	__le64 parentid; /* objectid of the tree root */
+	__le32 csum;
+	__le32 ham;
+	__le16 nritems;
+	__le16 flags;
 	/* generation flags to be added */
 } __attribute__ ((__packed__));
 
 #define MAX_LEVEL 8
-#define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct header)) / \
+#define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct btrfs_header)) / \
 			    (sizeof(struct key) + sizeof(u64)))
 
 struct tree_buffer;
@@ -100,12 +100,12 @@ struct item {
  * The data is separate from the items to get the keys closer together
  * during searches.
  */
-#define LEAF_DATA_SIZE (CTREE_BLOCKSIZE - sizeof(struct header))
+#define LEAF_DATA_SIZE (CTREE_BLOCKSIZE - sizeof(struct btrfs_header))
 struct leaf {
-	struct header header;
+	struct btrfs_header header;
 	union {
 		struct item items[LEAF_DATA_SIZE/sizeof(struct item)];
-		u8 data[CTREE_BLOCKSIZE-sizeof(struct header)];
+		u8 data[CTREE_BLOCKSIZE-sizeof(struct btrfs_header)];
 	};
 } __attribute__ ((__packed__));
 
@@ -114,7 +114,7 @@ struct leaf {
  * other blocks
  */
 struct node {
-	struct header header;
+	struct btrfs_header header;
 	struct key keys[NODEPTRS_PER_BLOCK];
 	u64 blockptrs[NODEPTRS_PER_BLOCK];
 } __attribute__ ((__packed__));
@@ -141,54 +141,55 @@ struct ctree_path {
 	int slots[MAX_LEVEL];
 };
 
-static inline u64 btrfs_header_blocknr(struct header *h)
+static inline u64 btrfs_header_blocknr(struct btrfs_header *h)
 {
-	return h->blocknr;
+	return le64_to_cpu(h->blocknr);
 }
 
-static inline void btrfs_set_header_blocknr(struct header *h, u64 blocknr)
+static inline void btrfs_set_header_blocknr(struct btrfs_header *h, u64 blocknr)
 {
-	h->blocknr = blocknr;
+	h->blocknr = cpu_to_le64(blocknr);
 }
 
-static inline u64 btrfs_header_parentid(struct header *h)
+static inline u64 btrfs_header_parentid(struct btrfs_header *h)
 {
-	return h->parentid;
+	return le64_to_cpu(h->parentid);
 }
 
-static inline void btrfs_set_header_parentid(struct header *h, u64 parentid)
+static inline void btrfs_set_header_parentid(struct btrfs_header *h,
+					     u64 parentid)
 {
-	h->parentid = parentid;
+	h->parentid = cpu_to_le64(parentid);
 }
 
-static inline u32 btrfs_header_nritems(struct header *h)
+static inline u16 btrfs_header_nritems(struct btrfs_header *h)
 {
-	return h->nritems;
+	return le16_to_cpu(h->nritems);
 }
 
-static inline void btrfs_set_header_nritems(struct header *h, u32 val)
+static inline void btrfs_set_header_nritems(struct btrfs_header *h, u16 val)
 {
-	h->nritems = val;
+	h->nritems = cpu_to_le16(val);
 }
 
-static inline u32 btrfs_header_flags(struct header *h)
+static inline u16 btrfs_header_flags(struct btrfs_header *h)
 {
-	return h->flags;
+	return le16_to_cpu(h->flags);
 }
 
-static inline void btrfs_set_header_flags(struct header *h, u32 val)
+static inline void btrfs_set_header_flags(struct btrfs_header *h, u16 val)
 {
-	h->flags = val;
+	h->flags = cpu_to_le16(val);
 }
 
-static inline int btrfs_header_level(struct header *h)
+static inline int btrfs_header_level(struct btrfs_header *h)
 {
 	return btrfs_header_flags(h) & (MAX_LEVEL - 1);
 }
 
-static inline void btrfs_set_header_level(struct header *h, int level)
+static inline void btrfs_set_header_level(struct btrfs_header *h, int level)
 {
-	u32 flags;
+	u16 flags;
 	BUG_ON(level > MAX_LEVEL);
 	flags = btrfs_header_flags(h) & ~(MAX_LEVEL - 1);
 	btrfs_set_header_flags(h, flags | level);

commit 7518a238ea0152dc849d1ed76d3cae8b44e12f46
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 12 12:01:18 2007 -0400

    Btrfs: get/set for struct header fields
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 518326fa3694..60c21fe1566a 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -35,13 +35,10 @@ struct header {
 	/* generation flags to be added */
 } __attribute__ ((__packed__));
 
+#define MAX_LEVEL 8
 #define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct header)) / \
 			    (sizeof(struct key) + sizeof(u64)))
 
-#define MAX_LEVEL 8
-#define node_level(f) ((f) & (MAX_LEVEL-1))
-#define is_leaf(f) (node_level(f) == 0)
-
 struct tree_buffer;
 
 /*
@@ -144,6 +141,64 @@ struct ctree_path {
 	int slots[MAX_LEVEL];
 };
 
+static inline u64 btrfs_header_blocknr(struct header *h)
+{
+	return h->blocknr;
+}
+
+static inline void btrfs_set_header_blocknr(struct header *h, u64 blocknr)
+{
+	h->blocknr = blocknr;
+}
+
+static inline u64 btrfs_header_parentid(struct header *h)
+{
+	return h->parentid;
+}
+
+static inline void btrfs_set_header_parentid(struct header *h, u64 parentid)
+{
+	h->parentid = parentid;
+}
+
+static inline u32 btrfs_header_nritems(struct header *h)
+{
+	return h->nritems;
+}
+
+static inline void btrfs_set_header_nritems(struct header *h, u32 val)
+{
+	h->nritems = val;
+}
+
+static inline u32 btrfs_header_flags(struct header *h)
+{
+	return h->flags;
+}
+
+static inline void btrfs_set_header_flags(struct header *h, u32 val)
+{
+	h->flags = val;
+}
+
+static inline int btrfs_header_level(struct header *h)
+{
+	return btrfs_header_flags(h) & (MAX_LEVEL - 1);
+}
+
+static inline void btrfs_set_header_level(struct header *h, int level)
+{
+	u32 flags;
+	BUG_ON(level > MAX_LEVEL);
+	flags = btrfs_header_flags(h) & ~(MAX_LEVEL - 1);
+	btrfs_set_header_flags(h, flags | level);
+}
+
+static inline int btrfs_is_leaf(struct node *n)
+{
+	return (btrfs_header_level(&n->header) == 0);
+}
+
 struct tree_buffer *alloc_free_block(struct ctree_root *root);
 int btrfs_inc_ref(struct ctree_root *root, struct tree_buffer *buf);
 int free_extent(struct ctree_root *root, u64 blocknr, u64 num_blocks);

commit 0579da4280812f34f382fb0f8004d7b0219e7a33
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 7 16:15:30 2007 -0500

    Btrfs: Fixup last found extent caching
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 4a7bc4e6e747..518326fa3694 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -54,6 +54,7 @@ struct ctree_root {
 	struct tree_buffer *commit_root;
 	struct ctree_root *extent_root;
 	struct key current_insert;
+	struct key last_insert;
 	int fp;
 	struct radix_tree_root cache_radix;
 	struct radix_tree_root pinned_radix;

commit a28ec19775d62d673b034082128aca95780d3737
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 6 20:08:01 2007 -0500

    Btrfs: Fixup reference counting on cows
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 9fe8ba6e25c1..4a7bc4e6e747 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -51,10 +51,12 @@ struct tree_buffer;
  */
 struct ctree_root {
 	struct tree_buffer *node;
+	struct tree_buffer *commit_root;
 	struct ctree_root *extent_root;
 	struct key current_insert;
 	int fp;
 	struct radix_tree_root cache_radix;
+	struct radix_tree_root pinned_radix;
 	struct list_head trans;
 	struct list_head cache;
 	int cache_size;
@@ -151,4 +153,6 @@ int del_item(struct ctree_root *root, struct ctree_path *path);
 int insert_item(struct ctree_root *root, struct key *key, void *data, int data_size);
 int next_leaf(struct ctree_root *root, struct ctree_path *path);
 int leaf_free_space(struct leaf *leaf);
+int btrfs_drop_snapshot(struct ctree_root *root, struct tree_buffer *snap);
+int btrfs_finish_extent_commit(struct ctree_root *root);
 #endif

commit 02217ed299c6340a35696e0610047eb96826de2d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 2 16:08:05 2007 -0500

    Btrfs: early reference counting
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 6b4dabd47698..9fe8ba6e25c1 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -142,8 +142,9 @@ struct ctree_path {
 };
 
 struct tree_buffer *alloc_free_block(struct ctree_root *root);
+int btrfs_inc_ref(struct ctree_root *root, struct tree_buffer *buf);
 int free_extent(struct ctree_root *root, u64 blocknr, u64 num_blocks);
-int search_slot(struct ctree_root *root, struct key *key, struct ctree_path *p, int ins_len);
+int search_slot(struct ctree_root *root, struct key *key, struct ctree_path *p, int ins_len, int cow);
 void release_path(struct ctree_root *root, struct ctree_path *p);
 void init_path(struct ctree_path *p);
 int del_item(struct ctree_root *root, struct ctree_path *path);

commit ed2ff2cba766dfe7976a0113f667c9a0a50dff02
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 1 18:59:40 2007 -0500

    Btrfs: pretend page cache & commit code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 18daccd84535..6b4dabd47698 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,6 +1,8 @@
 #ifndef __CTREE__
 #define __CTREE__
 
+#include "list.h"
+
 #define CTREE_BLOCKSIZE 1024
 
 /*
@@ -53,6 +55,9 @@ struct ctree_root {
 	struct key current_insert;
 	int fp;
 	struct radix_tree_root cache_radix;
+	struct list_head trans;
+	struct list_head cache;
+	int cache_size;
 };
 
 /*

commit fec577fb7f516e0d12ff821b1af272fd754e120a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Feb 26 10:40:21 2007 -0500

    Btrfs: Add fsx-style randomized tree tester
    Add debug-tree command to print the tree
    Add extent-tree.c to the repo
    Comment ctree.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b92fbbb5ecd7..18daccd84535 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,22 +1,36 @@
 #ifndef __CTREE__
 #define __CTREE__
 
-#define CTREE_BLOCKSIZE 4096
+#define CTREE_BLOCKSIZE 1024
 
+/*
+ * the key defines the order in the tree, and so it also defines (optimal)
+ * block layout.  objectid corresonds to the inode number.  The flags
+ * tells us things about the object, and is a kind of stream selector.
+ * so for a given inode, keys with flags of 1 might refer to the inode
+ * data, flags of 2 may point to file data in the btree and flags == 3
+ * may point to extents.
+ *
+ * offset is the starting byte offset for this key in the stream.
+ */
 struct key {
 	u64 objectid;
 	u32 flags;
 	u64 offset;
 } __attribute__ ((__packed__));
 
+/*
+ * every tree block (leaf or node) starts with this header.
+ */
 struct header {
 	u64 fsid[2]; /* FS specific uuid */
-	u64 blocknr;
-	u64 parentid;
+	u64 blocknr; /* which block this node is supposed to live in */
+	u64 parentid; /* objectid of the tree root */
 	u32 csum;
 	u32 ham;
 	u16 nritems;
 	u16 flags;
+	/* generation flags to be added */
 } __attribute__ ((__packed__));
 
 #define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct header)) / \
@@ -28,6 +42,11 @@ struct header {
 
 struct tree_buffer;
 
+/*
+ * in ram representation of the tree.  extent_root is used for all allocations
+ * and for the extent tree extent_root root.  current_insert is used
+ * only for the extent tree.
+ */
 struct ctree_root {
 	struct tree_buffer *node;
 	struct ctree_root *extent_root;
@@ -36,27 +55,46 @@ struct ctree_root {
 	struct radix_tree_root cache_radix;
 };
 
+/*
+ * describes a tree on disk
+ */
 struct ctree_root_info {
 	u64 fsid[2]; /* FS specific uuid */
 	u64 blocknr; /* blocknr of this block */
 	u64 objectid; /* inode number of this root */
-	u64 tree_root; /* the tree root */
+	u64 tree_root; /* the tree root block */
 	u32 csum;
 	u32 ham;
 	u64 snapuuid[2]; /* root specific uuid */
 } __attribute__ ((__packed__));
 
+/*
+ * the super block basically lists the main trees of the FS
+ * it currently lacks any block count etc etc
+ */
 struct ctree_super_block {
 	struct ctree_root_info root_info;
 	struct ctree_root_info extent_info;
 } __attribute__ ((__packed__));
 
+/*
+ * A leaf is full of items.  The exact type of item is defined by
+ * the key flags parameter.  offset and size tell us where to find
+ * the item in the leaf (relative to the start of the data area)
+ */
 struct item {
 	struct key key;
 	u16 offset;
 	u16 size;
 } __attribute__ ((__packed__));
 
+/*
+ * leaves have an item area and a data area:
+ * [item0, item1....itemN] [free space] [dataN...data1, data0]
+ *
+ * The data is separate from the items to get the keys closer together
+ * during searches.
+ */
 #define LEAF_DATA_SIZE (CTREE_BLOCKSIZE - sizeof(struct header))
 struct leaf {
 	struct header header;
@@ -66,17 +104,33 @@ struct leaf {
 	};
 } __attribute__ ((__packed__));
 
+/*
+ * all non-leaf blocks are nodes, they hold only keys and pointers to
+ * other blocks
+ */
 struct node {
 	struct header header;
 	struct key keys[NODEPTRS_PER_BLOCK];
 	u64 blockptrs[NODEPTRS_PER_BLOCK];
 } __attribute__ ((__packed__));
 
+/*
+ * items in the extent btree are used to record the objectid of the
+ * owner of the block and the number of references
+ */
 struct extent_item {
 	u32 refs;
 	u64 owner;
 } __attribute__ ((__packed__));
 
+/*
+ * ctree_paths remember the path taken from the root down to the leaf.
+ * level 0 is always the leaf, and nodes[1...MAX_LEVEL] will point
+ * to any other levels that are present.
+ *
+ * The slots array records the index of the item or block pointer
+ * used while walking the tree.
+ */
 struct ctree_path {
 	struct tree_buffer *nodes[MAX_LEVEL];
 	int slots[MAX_LEVEL];

commit 5de08d7d50ba535b968d97101ed2ab07c2b8eb7d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Feb 24 06:24:44 2007 -0500

    Btrfs: Break up ctree.c a little
    Extent fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 8c32c0e9267d..b92fbbb5ecd7 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,7 +1,7 @@
 #ifndef __CTREE__
 #define __CTREE__
 
-#define CTREE_BLOCKSIZE 256
+#define CTREE_BLOCKSIZE 4096
 
 struct key {
 	u64 objectid;
@@ -81,4 +81,14 @@ struct ctree_path {
 	struct tree_buffer *nodes[MAX_LEVEL];
 	int slots[MAX_LEVEL];
 };
+
+struct tree_buffer *alloc_free_block(struct ctree_root *root);
+int free_extent(struct ctree_root *root, u64 blocknr, u64 num_blocks);
+int search_slot(struct ctree_root *root, struct key *key, struct ctree_path *p, int ins_len);
+void release_path(struct ctree_root *root, struct ctree_path *p);
+void init_path(struct ctree_path *p);
+int del_item(struct ctree_root *root, struct ctree_path *path);
+int insert_item(struct ctree_root *root, struct key *key, void *data, int data_size);
+int next_leaf(struct ctree_root *root, struct ctree_path *path);
+int leaf_free_space(struct leaf *leaf);
 #endif

commit 9a8dd1502de6aa683ae46cf0397e9b6e636416fb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Feb 23 08:38:36 2007 -0500

    Btrfs: Block sized tree extents and extent deletion
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 78407d32db78..8c32c0e9267d 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -28,21 +28,12 @@ struct header {
 
 struct tree_buffer;
 
-struct alloc_extent {
-	u64 blocknr;
-	u64 num_blocks;
-	u64 num_used;
-} __attribute__ ((__packed__));
-
 struct ctree_root {
 	struct tree_buffer *node;
 	struct ctree_root *extent_root;
-	struct alloc_extent *alloc_extent;
-	struct alloc_extent *reserve_extent;
+	struct key current_insert;
 	int fp;
 	struct radix_tree_root cache_radix;
-	struct alloc_extent ai1;
-	struct alloc_extent ai2;
 };
 
 struct ctree_root_info {
@@ -52,8 +43,6 @@ struct ctree_root_info {
 	u64 tree_root; /* the tree root */
 	u32 csum;
 	u32 ham;
-	struct alloc_extent alloc_extent;
-	struct alloc_extent reserve_extent;
 	u64 snapuuid[2]; /* root specific uuid */
 } __attribute__ ((__packed__));
 

commit cfaa72952fa7b44aa5d967cbc266110900552aef
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 21 17:04:57 2007 -0500

    Btrfs: extent fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index b737925be314..78407d32db78 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -57,6 +57,11 @@ struct ctree_root_info {
 	u64 snapuuid[2]; /* root specific uuid */
 } __attribute__ ((__packed__));
 
+struct ctree_super_block {
+	struct ctree_root_info root_info;
+	struct ctree_root_info extent_info;
+} __attribute__ ((__packed__));
+
 struct item {
 	struct key key;
 	u16 offset;

commit d97e63b69ef21c02b67e20e41d9968b0e503572e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Feb 20 16:40:44 2007 -0500

    Btrfs: early extent mapping support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
index 586bf1866042..b737925be314 100644
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -1,7 +1,7 @@
 #ifndef __CTREE__
 #define __CTREE__
 
-#define CTREE_BLOCKSIZE 4096
+#define CTREE_BLOCKSIZE 256
 
 struct key {
 	u64 objectid;
@@ -22,18 +22,41 @@ struct header {
 #define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct header)) / \
 			    (sizeof(struct key) + sizeof(u64)))
 
-#define LEVEL_BITS 3
-#define MAX_LEVEL (1 << LEVEL_BITS)
+#define MAX_LEVEL 8
 #define node_level(f) ((f) & (MAX_LEVEL-1))
 #define is_leaf(f) (node_level(f) == 0)
 
 struct tree_buffer;
+
+struct alloc_extent {
+	u64 blocknr;
+	u64 num_blocks;
+	u64 num_used;
+} __attribute__ ((__packed__));
+
 struct ctree_root {
 	struct tree_buffer *node;
+	struct ctree_root *extent_root;
+	struct alloc_extent *alloc_extent;
+	struct alloc_extent *reserve_extent;
 	int fp;
 	struct radix_tree_root cache_radix;
+	struct alloc_extent ai1;
+	struct alloc_extent ai2;
 };
 
+struct ctree_root_info {
+	u64 fsid[2]; /* FS specific uuid */
+	u64 blocknr; /* blocknr of this block */
+	u64 objectid; /* inode number of this root */
+	u64 tree_root; /* the tree root */
+	u32 csum;
+	u32 ham;
+	struct alloc_extent alloc_extent;
+	struct alloc_extent reserve_extent;
+	u64 snapuuid[2]; /* root specific uuid */
+} __attribute__ ((__packed__));
+
 struct item {
 	struct key key;
 	u16 offset;
@@ -55,6 +78,11 @@ struct node {
 	u64 blockptrs[NODEPTRS_PER_BLOCK];
 } __attribute__ ((__packed__));
 
+struct extent_item {
+	u32 refs;
+	u64 owner;
+} __attribute__ ((__packed__));
+
 struct ctree_path {
 	struct tree_buffer *nodes[MAX_LEVEL];
 	int slots[MAX_LEVEL];

commit eb60ceac0ebd11e9896ed1ca84fcad71a4b23601
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Feb 2 09:18:22 2007 -0500

    Btrfs: Add backing store, memory management
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h
new file mode 100644
index 000000000000..586bf1866042
--- /dev/null
+++ b/fs/btrfs/ctree.h
@@ -0,0 +1,62 @@
+#ifndef __CTREE__
+#define __CTREE__
+
+#define CTREE_BLOCKSIZE 4096
+
+struct key {
+	u64 objectid;
+	u32 flags;
+	u64 offset;
+} __attribute__ ((__packed__));
+
+struct header {
+	u64 fsid[2]; /* FS specific uuid */
+	u64 blocknr;
+	u64 parentid;
+	u32 csum;
+	u32 ham;
+	u16 nritems;
+	u16 flags;
+} __attribute__ ((__packed__));
+
+#define NODEPTRS_PER_BLOCK ((CTREE_BLOCKSIZE - sizeof(struct header)) / \
+			    (sizeof(struct key) + sizeof(u64)))
+
+#define LEVEL_BITS 3
+#define MAX_LEVEL (1 << LEVEL_BITS)
+#define node_level(f) ((f) & (MAX_LEVEL-1))
+#define is_leaf(f) (node_level(f) == 0)
+
+struct tree_buffer;
+struct ctree_root {
+	struct tree_buffer *node;
+	int fp;
+	struct radix_tree_root cache_radix;
+};
+
+struct item {
+	struct key key;
+	u16 offset;
+	u16 size;
+} __attribute__ ((__packed__));
+
+#define LEAF_DATA_SIZE (CTREE_BLOCKSIZE - sizeof(struct header))
+struct leaf {
+	struct header header;
+	union {
+		struct item items[LEAF_DATA_SIZE/sizeof(struct item)];
+		u8 data[CTREE_BLOCKSIZE-sizeof(struct header)];
+	};
+} __attribute__ ((__packed__));
+
+struct node {
+	struct header header;
+	struct key keys[NODEPTRS_PER_BLOCK];
+	u64 blockptrs[NODEPTRS_PER_BLOCK];
+} __attribute__ ((__packed__));
+
+struct ctree_path {
+	struct tree_buffer *nodes[MAX_LEVEL];
+	int slots[MAX_LEVEL];
+};
+#endif
