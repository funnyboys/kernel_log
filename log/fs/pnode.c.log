commit b0d3869ce9eeacbb1bbd541909beeef4126426d5
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Apr 27 10:26:22 2020 -0400

    propagate_one(): mnt_set_mountpoint() needs mount_lock
    
    ... to protect the modification of mp->m_count done by it.  Most of
    the places that modify that thing also have namespace_lock held,
    but not all of them can do so, so we really need mount_lock here.
    Kudos to Piotr Krysiuk <piotras@gmail.com>, who'd spotted a related
    bug in pivot_root(2) (fixed unnoticed in 5.3); search for other
    similar turds has caught out this one.
    
    Cc: stable@kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 49f6d7ff2139..1106137c747a 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -261,14 +261,13 @@ static int propagate_one(struct mount *m)
 	child = copy_tree(last_source, last_source->mnt.mnt_root, type);
 	if (IS_ERR(child))
 		return PTR_ERR(child);
+	read_seqlock_excl(&mount_lock);
 	mnt_set_mountpoint(m, mp, child);
+	if (m->mnt_master != dest_master)
+		SET_MNT_MARK(m->mnt_master);
+	read_sequnlock_excl(&mount_lock);
 	last_dest = m;
 	last_source = child;
-	if (m->mnt_master != dest_master) {
-		read_seqlock_excl(&mount_lock);
-		SET_MNT_MARK(m->mnt_master);
-		read_sequnlock_excl(&mount_lock);
-	}
 	hlist_add_head(&child->mnt_hash, list);
 	return count_mounts(m->mnt_ns, child);
 }

commit d728cf79164bb38e9628d15276e636539f857ef1
Author: Christian Brauner <christian@brauner.io>
Date:   Mon Jun 17 23:22:14 2019 +0200

    fs/namespace: fix unprivileged mount propagation
    
    When propagating mounts across mount namespaces owned by different user
    namespaces it is not possible anymore to move or umount the mount in the
    less privileged mount namespace.
    
    Here is a reproducer:
    
      sudo mount -t tmpfs tmpfs /mnt
      sudo --make-rshared /mnt
    
      # create unprivileged user + mount namespace and preserve propagation
      unshare -U -m --map-root --propagation=unchanged
    
      # now change back to the original mount namespace in another terminal:
      sudo mkdir /mnt/aaa
      sudo mount -t tmpfs tmpfs /mnt/aaa
    
      # now in the unprivileged user + mount namespace
      mount --move /mnt/aaa /opt
    
    Unfortunately, this is a pretty big deal for userspace since this is
    e.g. used to inject mounts into running unprivileged containers.
    So this regression really needs to go away rather quickly.
    
    The problem is that a recent change falsely locked the root of the newly
    added mounts by setting MNT_LOCKED. Fix this by only locking the mounts
    on copy_mnt_ns() and not when adding a new mount.
    
    Fixes: 3bd045cc9c4b ("separate copying and locking mount tree on cross-userns copies")
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: <stable@vger.kernel.org>
    Tested-by: Christian Brauner <christian@brauner.io>
    Acked-by: Christian Brauner <christian@brauner.io>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 595857a1883e..49f6d7ff2139 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -261,7 +261,6 @@ static int propagate_one(struct mount *m)
 	child = copy_tree(last_source, last_source->mnt.mnt_root, type);
 	if (IS_ERR(child))
 		return PTR_ERR(child);
-	child->mnt.mnt_flags &= ~MNT_LOCKED;
 	mnt_set_mountpoint(m, mp, child);
 	last_dest = m;
 	last_source = child;

commit 59bd9ded4d7803d9f1f4d947064693513d18e724
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue May 28 10:10:12 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 209
    
    Based on 1 normalized pattern(s):
    
      released under gpl v2
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 15 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Steve Winslow <swinslow@gmail.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190528171438.895196075@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 7ea6cfb65077..595857a1883e 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -1,10 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/fs/pnode.c
  *
  * (C) Copyright IBM Corporation 2005.
- *	Released under GPL v2.
  *	Author : Ram Pai (linuxram@us.ibm.com)
- *
  */
 #include <linux/mnt_namespace.h>
 #include <linux/mount.h>

commit 3bd045cc9c4be2049602b47505256b43908b4e2f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 30 13:15:45 2019 -0500

    separate copying and locking mount tree on cross-userns copies
    
    Rather than having propagate_mnt() check doing unprivileged copies,
    lock them before commit_tree().
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 1100e810d855..7ea6cfb65077 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -214,7 +214,6 @@ static struct mount *next_group(struct mount *m, struct mount *origin)
 }
 
 /* all accesses are serialized by namespace_sem */
-static struct user_namespace *user_ns;
 static struct mount *last_dest, *first_source, *last_source, *dest_master;
 static struct mountpoint *mp;
 static struct hlist_head *list;
@@ -260,9 +259,6 @@ static int propagate_one(struct mount *m)
 			type |= CL_MAKE_SHARED;
 	}
 		
-	/* Notice when we are propagating across user namespaces */
-	if (m->mnt_ns->user_ns != user_ns)
-		type |= CL_UNPRIVILEGED;
 	child = copy_tree(last_source, last_source->mnt.mnt_root, type);
 	if (IS_ERR(child))
 		return PTR_ERR(child);
@@ -303,7 +299,6 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 	 * propagate_one(); everything is serialized by namespace_sem,
 	 * so globals will do just fine.
 	 */
-	user_ns = current->nsproxy->mnt_ns->user_ns;
 	last_dest = dest_mnt;
 	first_source = source_mnt;
 	last_source = source_mnt;

commit e262e32d6bde0f77fb0c95d977482fc872c51996
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 1 23:07:23 2018 +0000

    vfs: Suppress MS_* flag defs within the kernel unless explicitly enabled
    
    Only the mount namespace code that implements mount(2) should be using the
    MS_* flags.  Suppress them inside the kernel unless uapi/linux/mount.h is
    included.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Reviewed-by: David Howells <dhowells@redhat.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 53d411a371ce..1100e810d855 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -10,6 +10,7 @@
 #include <linux/mount.h>
 #include <linux/fs.h>
 #include <linux/nsproxy.h>
+#include <uapi/linux/mount.h>
 #include "internal.h"
 #include "pnode.h"
 

commit 296990deb389c7da21c78030376ba244dc1badf5
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 24 17:25:19 2016 -0500

    mnt: Make propagate_umount less slow for overlapping mount propagation trees
    
    Andrei Vagin pointed out that time to executue propagate_umount can go
    non-linear (and take a ludicrious amount of time) when the mount
    propogation trees of the mounts to be unmunted by a lazy unmount
    overlap.
    
    Make the walk of the mount propagation trees nearly linear by
    remembering which mounts have already been visited, allowing
    subsequent walks to detect when walking a mount propgation tree or a
    subtree of a mount propgation tree would be duplicate work and to skip
    them entirely.
    
    Walk the list of mounts whose propgatation trees need to be traversed
    from the mount highest in the mount tree to mounts lower in the mount
    tree so that odds are higher that the code will walk the largest trees
    first, allowing later tree walks to be skipped entirely.
    
    Add cleanup_umount_visitation to remover the code's memory of which
    mounts have been visited.
    
    Add the functions last_slave and skip_propagation_subtree to allow
    skipping appropriate parts of the mount propagation tree without
    needing to change the logic of the rest of the code.
    
    A script to generate overlapping mount propagation trees:
    
    $ cat runs.h
    set -e
    mount -t tmpfs zdtm /mnt
    mkdir -p /mnt/1 /mnt/2
    mount -t tmpfs zdtm /mnt/1
    mount --make-shared /mnt/1
    mkdir /mnt/1/1
    
    iteration=10
    if [ -n "$1" ] ; then
            iteration=$1
    fi
    
    for i in $(seq $iteration); do
            mount --bind /mnt/1/1 /mnt/1/1
    done
    
    mount --rbind /mnt/1 /mnt/2
    
    TIMEFORMAT='%Rs'
    nr=$(( ( 2 ** ( $iteration + 1 ) ) + 1 ))
    echo -n "umount -l /mnt/1 -> $nr        "
    time umount -l /mnt/1
    
    nr=$(cat /proc/self/mountinfo | grep zdtm | wc -l )
    time umount -l /mnt/2
    
    $ for i in $(seq 9 19); do echo $i; unshare -Urm bash ./run.sh $i; done
    
    Here are the performance numbers with and without the patch:
    
         mhash |  8192   |  8192  | 1048576 | 1048576
        mounts | before  | after  |  before | after
        ------------------------------------------------
          1025 |  0.040s | 0.016s |  0.038s | 0.019s
          2049 |  0.094s | 0.017s |  0.080s | 0.018s
          4097 |  0.243s | 0.019s |  0.206s | 0.023s
          8193 |  1.202s | 0.028s |  1.562s | 0.032s
         16385 |  9.635s | 0.036s |  9.952s | 0.041s
         32769 | 60.928s | 0.063s | 44.321s | 0.064s
         65537 |         | 0.097s |         | 0.097s
        131073 |         | 0.233s |         | 0.176s
        262145 |         | 0.653s |         | 0.344s
        524289 |         | 2.305s |         | 0.735s
       1048577 |         | 7.107s |         | 2.603s
    
    Andrei Vagin reports fixing the performance problem is part of the
    work to fix CVE-2016-6213.
    
    Cc: stable@vger.kernel.org
    Fixes: a05964f3917c ("[PATCH] shared mounts handling: umount")
    Reported-by: Andrei Vagin <avagin@openvz.org>
    Reviewed-by: Andrei Vagin <avagin@virtuozzo.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index fbaca7df2eb0..53d411a371ce 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -24,6 +24,11 @@ static inline struct mount *first_slave(struct mount *p)
 	return list_entry(p->mnt_slave_list.next, struct mount, mnt_slave);
 }
 
+static inline struct mount *last_slave(struct mount *p)
+{
+	return list_entry(p->mnt_slave_list.prev, struct mount, mnt_slave);
+}
+
 static inline struct mount *next_slave(struct mount *p)
 {
 	return list_entry(p->mnt_slave.next, struct mount, mnt_slave);
@@ -162,6 +167,19 @@ static struct mount *propagation_next(struct mount *m,
 	}
 }
 
+static struct mount *skip_propagation_subtree(struct mount *m,
+						struct mount *origin)
+{
+	/*
+	 * Advance m such that propagation_next will not return
+	 * the slaves of m.
+	 */
+	if (!IS_MNT_NEW(m) && !list_empty(&m->mnt_slave_list))
+		m = last_slave(m);
+
+	return m;
+}
+
 static struct mount *next_group(struct mount *m, struct mount *origin)
 {
 	while (1) {
@@ -505,6 +523,15 @@ static void restore_mounts(struct list_head *to_restore)
 	}
 }
 
+static void cleanup_umount_visitations(struct list_head *visited)
+{
+	while (!list_empty(visited)) {
+		struct mount *mnt =
+			list_first_entry(visited, struct mount, mnt_umounting);
+		list_del_init(&mnt->mnt_umounting);
+	}
+}
+
 /*
  * collect all mounts that receive propagation from the mount in @list,
  * and return these additional mounts in the same list.
@@ -517,11 +544,23 @@ int propagate_umount(struct list_head *list)
 	struct mount *mnt;
 	LIST_HEAD(to_restore);
 	LIST_HEAD(to_umount);
+	LIST_HEAD(visited);
 
-	list_for_each_entry(mnt, list, mnt_list) {
+	/* Find candidates for unmounting */
+	list_for_each_entry_reverse(mnt, list, mnt_list) {
 		struct mount *parent = mnt->mnt_parent;
 		struct mount *m;
 
+		/*
+		 * If this mount has already been visited it is known that it's
+		 * entire peer group and all of their slaves in the propagation
+		 * tree for the mountpoint has already been visited and there is
+		 * no need to visit them again.
+		 */
+		if (!list_empty(&mnt->mnt_umounting))
+			continue;
+
+		list_add_tail(&mnt->mnt_umounting, &visited);
 		for (m = propagation_next(parent, parent); m;
 		     m = propagation_next(m, parent)) {
 			struct mount *child = __lookup_mnt(&m->mnt,
@@ -529,6 +568,27 @@ int propagate_umount(struct list_head *list)
 			if (!child)
 				continue;
 
+			if (!list_empty(&child->mnt_umounting)) {
+				/*
+				 * If the child has already been visited it is
+				 * know that it's entire peer group and all of
+				 * their slaves in the propgation tree for the
+				 * mountpoint has already been visited and there
+				 * is no need to visit this subtree again.
+				 */
+				m = skip_propagation_subtree(m, parent);
+				continue;
+			} else if (child->mnt.mnt_flags & MNT_UMOUNT) {
+				/*
+				 * We have come accross an partially unmounted
+				 * mount in list that has not been visited yet.
+				 * Remember it has been visited and continue
+				 * about our merry way.
+				 */
+				list_add_tail(&child->mnt_umounting, &visited);
+				continue;
+			}
+
 			/* Check the child and parents while progress is made */
 			while (__propagate_umount(child,
 						  &to_umount, &to_restore)) {
@@ -542,6 +602,7 @@ int propagate_umount(struct list_head *list)
 
 	umount_list(&to_umount, &to_restore);
 	restore_mounts(&to_restore);
+	cleanup_umount_visitations(&visited);
 	list_splice_tail(&to_umount, list);
 
 	return 0;

commit 99b19d16471e9c3faa85cad38abc9cbbe04c6d55
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 24 16:16:13 2016 -0500

    mnt: In propgate_umount handle visiting mounts in any order
    
    While investigating some poor umount performance I realized that in
    the case of overlapping mount trees where some of the mounts are locked
    the code has been failing to unmount all of the mounts it should
    have been unmounting.
    
    This failure to unmount all of the necessary
    mounts can be reproduced with:
    
    $ cat locked_mounts_test.sh
    
    mount -t tmpfs test-base /mnt
    mount --make-shared /mnt
    mkdir -p /mnt/b
    
    mount -t tmpfs test1 /mnt/b
    mount --make-shared /mnt/b
    mkdir -p /mnt/b/10
    
    mount -t tmpfs test2 /mnt/b/10
    mount --make-shared /mnt/b/10
    mkdir -p /mnt/b/10/20
    
    mount --rbind /mnt/b /mnt/b/10/20
    
    unshare -Urm --propagation unchaged /bin/sh -c 'sleep 5; if [ $(grep test /proc/self/mountinfo | wc -l) -eq 1 ] ; then echo SUCCESS ; else echo FAILURE ; fi'
    sleep 1
    umount -l /mnt/b
    wait %%
    
    $ unshare -Urm ./locked_mounts_test.sh
    
    This failure is corrected by removing the prepass that marks mounts
    that may be umounted.
    
    A first pass is added that umounts mounts if possible and if not sets
    mount mark if they could be unmounted if they weren't locked and adds
    them to a list to umount possibilities.  This first pass reconsiders
    the mounts parent if it is on the list of umount possibilities, ensuring
    that information of umoutability will pass from child to mount parent.
    
    A second pass then walks through all mounts that are umounted and processes
    their children unmounting them or marking them for reparenting.
    
    A last pass cleans up the state on the mounts that could not be umounted
    and if applicable reparents them to their first parent that remained
    mounted.
    
    While a bit longer than the old code this code is much more robust
    as it allows information to flow up from the leaves and down
    from the trunk making the order in which mounts are encountered
    in the umount propgation tree irrelevant.
    
    Cc: stable@vger.kernel.org
    Fixes: 0c56fe31420c ("mnt: Don't propagate unmounts to locked mounts")
    Reviewed-by: Andrei Vagin <avagin@virtuozzo.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 52aca0a118ff..fbaca7df2eb0 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -413,86 +413,95 @@ void propagate_mount_unlock(struct mount *mnt)
 	}
 }
 
-/*
- * Mark all mounts that the MNT_LOCKED logic will allow to be unmounted.
- */
-static void mark_umount_candidates(struct mount *mnt)
+static void umount_one(struct mount *mnt, struct list_head *to_umount)
 {
-	struct mount *parent = mnt->mnt_parent;
-	struct mount *m;
-
-	BUG_ON(parent == mnt);
-
-	for (m = propagation_next(parent, parent); m;
-			m = propagation_next(m, parent)) {
-		struct mount *child = __lookup_mnt(&m->mnt,
-						mnt->mnt_mountpoint);
-		if (!child || (child->mnt.mnt_flags & MNT_UMOUNT))
-			continue;
-		if (!IS_MNT_LOCKED(child) || IS_MNT_MARKED(m)) {
-			SET_MNT_MARK(child);
-		}
-	}
+	CLEAR_MNT_MARK(mnt);
+	mnt->mnt.mnt_flags |= MNT_UMOUNT;
+	list_del_init(&mnt->mnt_child);
+	list_del_init(&mnt->mnt_umounting);
+	list_move_tail(&mnt->mnt_list, to_umount);
 }
 
 /*
  * NOTE: unmounting 'mnt' naturally propagates to all other mounts its
  * parent propagates to.
  */
-static void __propagate_umount(struct mount *mnt, struct list_head *to_reparent)
+static bool __propagate_umount(struct mount *mnt,
+			       struct list_head *to_umount,
+			       struct list_head *to_restore)
 {
-	struct mount *parent = mnt->mnt_parent;
-	struct mount *m;
+	bool progress = false;
+	struct mount *child;
 
-	BUG_ON(parent == mnt);
+	/*
+	 * The state of the parent won't change if this mount is
+	 * already unmounted or marked as without children.
+	 */
+	if (mnt->mnt.mnt_flags & (MNT_UMOUNT | MNT_MARKED))
+		goto out;
 
-	for (m = propagation_next(parent, parent); m;
-			m = propagation_next(m, parent)) {
-		struct mount *topper;
-		struct mount *child = __lookup_mnt(&m->mnt,
-						mnt->mnt_mountpoint);
-		/*
-		 * umount the child only if the child has no children
-		 * and the child is marked safe to unmount.
-		 */
-		if (!child || !IS_MNT_MARKED(child))
+	/* Verify topper is the only grandchild that has not been
+	 * speculatively unmounted.
+	 */
+	list_for_each_entry(child, &mnt->mnt_mounts, mnt_child) {
+		if (child->mnt_mountpoint == mnt->mnt.mnt_root)
 			continue;
-		CLEAR_MNT_MARK(child);
+		if (!list_empty(&child->mnt_umounting) && IS_MNT_MARKED(child))
+			continue;
+		/* Found a mounted child */
+		goto children;
+	}
 
-		/* If there is exactly one mount covering all of child
-		 * replace child with that mount.
-		 */
-		topper = find_topper(child);
-		if (topper)
-			list_add_tail(&topper->mnt_reparent, to_reparent);
+	/* Mark mounts that can be unmounted if not locked */
+	SET_MNT_MARK(mnt);
+	progress = true;
 
-		if (topper || list_empty(&child->mnt_mounts)) {
-			list_del_init(&child->mnt_child);
-			list_del_init(&child->mnt_reparent);
-			child->mnt.mnt_flags |= MNT_UMOUNT;
-			list_move_tail(&child->mnt_list, &mnt->mnt_list);
+	/* If a mount is without children and not locked umount it. */
+	if (!IS_MNT_LOCKED(mnt)) {
+		umount_one(mnt, to_umount);
+	} else {
+children:
+		list_move_tail(&mnt->mnt_umounting, to_restore);
+	}
+out:
+	return progress;
+}
+
+static void umount_list(struct list_head *to_umount,
+			struct list_head *to_restore)
+{
+	struct mount *mnt, *child, *tmp;
+	list_for_each_entry(mnt, to_umount, mnt_list) {
+		list_for_each_entry_safe(child, tmp, &mnt->mnt_mounts, mnt_child) {
+			/* topper? */
+			if (child->mnt_mountpoint == mnt->mnt.mnt_root)
+				list_move_tail(&child->mnt_umounting, to_restore);
+			else
+				umount_one(child, to_umount);
 		}
 	}
 }
 
-static void reparent_mounts(struct list_head *to_reparent)
+static void restore_mounts(struct list_head *to_restore)
 {
-	while (!list_empty(to_reparent)) {
+	/* Restore mounts to a clean working state */
+	while (!list_empty(to_restore)) {
 		struct mount *mnt, *parent;
 		struct mountpoint *mp;
 
-		mnt = list_first_entry(to_reparent, struct mount, mnt_reparent);
-		list_del_init(&mnt->mnt_reparent);
+		mnt = list_first_entry(to_restore, struct mount, mnt_umounting);
+		CLEAR_MNT_MARK(mnt);
+		list_del_init(&mnt->mnt_umounting);
 
-		/* Where should this mount be reparented to? */
+		/* Should this mount be reparented? */
 		mp = mnt->mnt_mp;
 		parent = mnt->mnt_parent;
 		while (parent->mnt.mnt_flags & MNT_UMOUNT) {
 			mp = parent->mnt_mp;
 			parent = parent->mnt_parent;
 		}
-
-		mnt_change_mountpoint(parent, mp, mnt);
+		if (parent != mnt->mnt_parent)
+			mnt_change_mountpoint(parent, mp, mnt);
 	}
 }
 
@@ -506,15 +515,34 @@ static void reparent_mounts(struct list_head *to_reparent)
 int propagate_umount(struct list_head *list)
 {
 	struct mount *mnt;
-	LIST_HEAD(to_reparent);
+	LIST_HEAD(to_restore);
+	LIST_HEAD(to_umount);
 
-	list_for_each_entry_reverse(mnt, list, mnt_list)
-		mark_umount_candidates(mnt);
+	list_for_each_entry(mnt, list, mnt_list) {
+		struct mount *parent = mnt->mnt_parent;
+		struct mount *m;
 
-	list_for_each_entry(mnt, list, mnt_list)
-		__propagate_umount(mnt, &to_reparent);
+		for (m = propagation_next(parent, parent); m;
+		     m = propagation_next(m, parent)) {
+			struct mount *child = __lookup_mnt(&m->mnt,
+							   mnt->mnt_mountpoint);
+			if (!child)
+				continue;
+
+			/* Check the child and parents while progress is made */
+			while (__propagate_umount(child,
+						  &to_umount, &to_restore)) {
+				/* Is the parent a umount candidate? */
+				child = child->mnt_parent;
+				if (list_empty(&child->mnt_umounting))
+					break;
+			}
+		}
+	}
 
-	reparent_mounts(&to_reparent);
+	umount_list(&to_umount, &to_restore);
+	restore_mounts(&to_restore);
+	list_splice_tail(&to_umount, list);
 
 	return 0;
 }

commit 570487d3faf2a1d8a220e6ee10f472163123d7da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon May 15 14:42:07 2017 -0500

    mnt: In umount propagation reparent in a separate pass
    
    It was observed that in some pathlogical cases that the current code
    does not unmount everything it should.  After investigation it
    was determined that the issue is that mnt_change_mntpoint can
    can change which mounts are available to be unmounted during mount
    propagation which is wrong.
    
    The trivial reproducer is:
    $ cat ./pathological.sh
    
    mount -t tmpfs test-base /mnt
    cd /mnt
    mkdir 1 2 1/1
    mount --bind 1 1
    mount --make-shared 1
    mount --bind 1 2
    mount --bind 1/1 1/1
    mount --bind 1/1 1/1
    echo
    grep test-base /proc/self/mountinfo
    umount 1/1
    echo
    grep test-base /proc/self/mountinfo
    
    $ unshare -Urm ./pathological.sh
    
    The expected output looks like:
    46 31 0:25 / /mnt rw,relatime - tmpfs test-base rw,uid=1000,gid=1000
    47 46 0:25 /1 /mnt/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    48 46 0:25 /1 /mnt/2 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    49 54 0:25 /1/1 /mnt/1/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    50 53 0:25 /1/1 /mnt/2/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    51 49 0:25 /1/1 /mnt/1/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    54 47 0:25 /1/1 /mnt/1/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    53 48 0:25 /1/1 /mnt/2/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    52 50 0:25 /1/1 /mnt/2/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    
    46 31 0:25 / /mnt rw,relatime - tmpfs test-base rw,uid=1000,gid=1000
    47 46 0:25 /1 /mnt/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    48 46 0:25 /1 /mnt/2 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    
    The output without the fix looks like:
    46 31 0:25 / /mnt rw,relatime - tmpfs test-base rw,uid=1000,gid=1000
    47 46 0:25 /1 /mnt/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    48 46 0:25 /1 /mnt/2 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    49 54 0:25 /1/1 /mnt/1/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    50 53 0:25 /1/1 /mnt/2/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    51 49 0:25 /1/1 /mnt/1/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    54 47 0:25 /1/1 /mnt/1/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    53 48 0:25 /1/1 /mnt/2/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    52 50 0:25 /1/1 /mnt/2/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    
    46 31 0:25 / /mnt rw,relatime - tmpfs test-base rw,uid=1000,gid=1000
    47 46 0:25 /1 /mnt/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    48 46 0:25 /1 /mnt/2 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    52 48 0:25 /1/1 /mnt/2/1 rw,relatime shared:1 - tmpfs test-base rw,uid=1000,gid=1000
    
    That last mount in the output was in the propgation tree to be unmounted but
    was missed because the mnt_change_mountpoint changed it's parent before the walk
    through the mount propagation tree observed it.
    
    Cc: stable@vger.kernel.org
    Fixes: 1064f874abc0 ("mnt: Tuck mounts under others instead of creating shadow/side mounts.")
    Acked-by: Andrei Vagin <avagin@virtuozzo.com>
    Reviewed-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 5bc7896d122a..52aca0a118ff 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -439,7 +439,7 @@ static void mark_umount_candidates(struct mount *mnt)
  * NOTE: unmounting 'mnt' naturally propagates to all other mounts its
  * parent propagates to.
  */
-static void __propagate_umount(struct mount *mnt)
+static void __propagate_umount(struct mount *mnt, struct list_head *to_reparent)
 {
 	struct mount *parent = mnt->mnt_parent;
 	struct mount *m;
@@ -464,17 +464,38 @@ static void __propagate_umount(struct mount *mnt)
 		 */
 		topper = find_topper(child);
 		if (topper)
-			mnt_change_mountpoint(child->mnt_parent, child->mnt_mp,
-					      topper);
+			list_add_tail(&topper->mnt_reparent, to_reparent);
 
-		if (list_empty(&child->mnt_mounts)) {
+		if (topper || list_empty(&child->mnt_mounts)) {
 			list_del_init(&child->mnt_child);
+			list_del_init(&child->mnt_reparent);
 			child->mnt.mnt_flags |= MNT_UMOUNT;
 			list_move_tail(&child->mnt_list, &mnt->mnt_list);
 		}
 	}
 }
 
+static void reparent_mounts(struct list_head *to_reparent)
+{
+	while (!list_empty(to_reparent)) {
+		struct mount *mnt, *parent;
+		struct mountpoint *mp;
+
+		mnt = list_first_entry(to_reparent, struct mount, mnt_reparent);
+		list_del_init(&mnt->mnt_reparent);
+
+		/* Where should this mount be reparented to? */
+		mp = mnt->mnt_mp;
+		parent = mnt->mnt_parent;
+		while (parent->mnt.mnt_flags & MNT_UMOUNT) {
+			mp = parent->mnt_mp;
+			parent = parent->mnt_parent;
+		}
+
+		mnt_change_mountpoint(parent, mp, mnt);
+	}
+}
+
 /*
  * collect all mounts that receive propagation from the mount in @list,
  * and return these additional mounts in the same list.
@@ -485,11 +506,15 @@ static void __propagate_umount(struct mount *mnt)
 int propagate_umount(struct list_head *list)
 {
 	struct mount *mnt;
+	LIST_HEAD(to_reparent);
 
 	list_for_each_entry_reverse(mnt, list, mnt_list)
 		mark_umount_candidates(mnt);
 
 	list_for_each_entry(mnt, list, mnt_list)
-		__propagate_umount(mnt);
+		__propagate_umount(mnt, &to_reparent);
+
+	reparent_mounts(&to_reparent);
+
 	return 0;
 }

commit 1064f874abc0d05eeed8993815f584d847b72486
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jan 20 18:28:35 2017 +1300

    mnt: Tuck mounts under others instead of creating shadow/side mounts.
    
    Ever since mount propagation was introduced in cases where a mount in
    propagated to parent mount mountpoint pair that is already in use the
    code has placed the new mount behind the old mount in the mount hash
    table.
    
    This implementation detail is problematic as it allows creating
    arbitrary length mount hash chains.
    
    Furthermore it invalidates the constraint maintained elsewhere in the
    mount code that a parent mount and a mountpoint pair will have exactly
    one mount upon them.  Making it hard to deal with and to talk about
    this special case in the mount code.
    
    Modify mount propagation to notice when there is already a mount at
    the parent mount and mountpoint where a new mount is propagating to
    and place that preexisting mount on top of the new mount.
    
    Modify unmount propagation to notice when a mount that is being
    unmounted has another mount on top of it (and no other children), and
    to replace the unmounted mount with the mount on top of it.
    
    Move the MNT_UMUONT test from __lookup_mnt_last into
    __propagate_umount as that is the only call of __lookup_mnt_last where
    MNT_UMOUNT may be set on any mount visible in the mount hash table.
    
    These modifications allow:
     - __lookup_mnt_last to be removed.
     - attach_shadows to be renamed __attach_mnt and its shadow
       handling to be removed.
     - commit_tree to be simplified
     - copy_tree to be simplified
    
    The result is an easier to understand tree of mounts that does not
    allow creation of arbitrary length hash chains in the mount hash table.
    
    The result is also a very slight userspace visible difference in semantics.
    The following two cases now behave identically, where before order
    mattered:
    
    case 1: (explicit user action)
            B is a slave of A
            mount something on A/a , it will propagate to B/a
            and than mount something on B/a
    
    case 2: (tucked mount)
            B is a slave of A
            mount something on B/a
            and than mount something on A/a
    
    Histroically umount A/a would fail in case 1 and succeed in case 2.
    Now umount A/a succeeds in both configurations.
    
    This very small change in semantics appears if anything to be a bug
    fix to me and my survey of userspace leads me to believe that no programs
    will notice or care of this subtle semantic change.
    
    v2: Updated to mnt_change_mountpoint to not call dput or mntput
    and instead to decrement the counts directly.  It is guaranteed
    that there will be other references when mnt_change_mountpoint is
    called so this is safe.
    
    v3: Moved put_mountpoint under mount_lock in attach_recursive_mnt
        As the locking in fs/namespace.c changed between v2 and v3.
    
    v4: Reworked the logic in propagate_mount_busy and __propagate_umount
        that detects when a mount completely covers another mount.
    
    v5: Removed unnecessary tests whose result is alwasy true in
        find_topper and attach_recursive_mnt.
    
    v6: Document the user space visible semantic difference.
    
    Cc: stable@vger.kernel.org
    Fixes: b90fa9ae8f51 ("[PATCH] shared mount handling: bind and rbind")
    Tested-by: Andrei Vagin <avagin@virtuozzo.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 06a793f4ae38..5bc7896d122a 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -322,6 +322,21 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 	return ret;
 }
 
+static struct mount *find_topper(struct mount *mnt)
+{
+	/* If there is exactly one mount covering mnt completely return it. */
+	struct mount *child;
+
+	if (!list_is_singular(&mnt->mnt_mounts))
+		return NULL;
+
+	child = list_first_entry(&mnt->mnt_mounts, struct mount, mnt_child);
+	if (child->mnt_mountpoint != mnt->mnt.mnt_root)
+		return NULL;
+
+	return child;
+}
+
 /*
  * return true if the refcount is greater than count
  */
@@ -342,9 +357,8 @@ static inline int do_refcount_check(struct mount *mnt, int count)
  */
 int propagate_mount_busy(struct mount *mnt, int refcnt)
 {
-	struct mount *m, *child;
+	struct mount *m, *child, *topper;
 	struct mount *parent = mnt->mnt_parent;
-	int ret = 0;
 
 	if (mnt == parent)
 		return do_refcount_check(mnt, refcnt);
@@ -359,12 +373,24 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 
 	for (m = propagation_next(parent, parent); m;
 	     		m = propagation_next(m, parent)) {
-		child = __lookup_mnt_last(&m->mnt, mnt->mnt_mountpoint);
-		if (child && list_empty(&child->mnt_mounts) &&
-		    (ret = do_refcount_check(child, 1)))
-			break;
+		int count = 1;
+		child = __lookup_mnt(&m->mnt, mnt->mnt_mountpoint);
+		if (!child)
+			continue;
+
+		/* Is there exactly one mount on the child that covers
+		 * it completely whose reference should be ignored?
+		 */
+		topper = find_topper(child);
+		if (topper)
+			count += 1;
+		else if (!list_empty(&child->mnt_mounts))
+			continue;
+
+		if (do_refcount_check(child, count))
+			return 1;
 	}
-	return ret;
+	return 0;
 }
 
 /*
@@ -381,7 +407,7 @@ void propagate_mount_unlock(struct mount *mnt)
 
 	for (m = propagation_next(parent, parent); m;
 			m = propagation_next(m, parent)) {
-		child = __lookup_mnt_last(&m->mnt, mnt->mnt_mountpoint);
+		child = __lookup_mnt(&m->mnt, mnt->mnt_mountpoint);
 		if (child)
 			child->mnt.mnt_flags &= ~MNT_LOCKED;
 	}
@@ -399,9 +425,11 @@ static void mark_umount_candidates(struct mount *mnt)
 
 	for (m = propagation_next(parent, parent); m;
 			m = propagation_next(m, parent)) {
-		struct mount *child = __lookup_mnt_last(&m->mnt,
+		struct mount *child = __lookup_mnt(&m->mnt,
 						mnt->mnt_mountpoint);
-		if (child && (!IS_MNT_LOCKED(child) || IS_MNT_MARKED(m))) {
+		if (!child || (child->mnt.mnt_flags & MNT_UMOUNT))
+			continue;
+		if (!IS_MNT_LOCKED(child) || IS_MNT_MARKED(m)) {
 			SET_MNT_MARK(child);
 		}
 	}
@@ -420,8 +448,8 @@ static void __propagate_umount(struct mount *mnt)
 
 	for (m = propagation_next(parent, parent); m;
 			m = propagation_next(m, parent)) {
-
-		struct mount *child = __lookup_mnt_last(&m->mnt,
+		struct mount *topper;
+		struct mount *child = __lookup_mnt(&m->mnt,
 						mnt->mnt_mountpoint);
 		/*
 		 * umount the child only if the child has no children
@@ -430,6 +458,15 @@ static void __propagate_umount(struct mount *mnt)
 		if (!child || !IS_MNT_MARKED(child))
 			continue;
 		CLEAR_MNT_MARK(child);
+
+		/* If there is exactly one mount covering all of child
+		 * replace child with that mount.
+		 */
+		topper = find_topper(child);
+		if (topper)
+			mnt_change_mountpoint(child->mnt_parent, child->mnt_mp,
+					      topper);
+
 		if (list_empty(&child->mnt_mounts)) {
 			list_del_init(&child->mnt_child);
 			child->mnt.mnt_flags |= MNT_UMOUNT;

commit 5235d448c48e1f5a4a34bf90d412775cb75ffb32
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Nov 20 19:33:09 2016 -0500

    reorganize do_make_slave()
    
    Make sure that clone_mnt() never returns a mount with MNT_SHARED in
    flags, but without a valid ->mnt_group_id.  That allows to demystify
    do_make_slave() quite a bit, among other things.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 234a9ac49958..06a793f4ae38 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -67,49 +67,47 @@ int get_dominating_id(struct mount *mnt, const struct path *root)
 
 static int do_make_slave(struct mount *mnt)
 {
-	struct mount *peer_mnt = mnt, *master = mnt->mnt_master;
-	struct mount *slave_mnt;
+	struct mount *master, *slave_mnt;
 
-	/*
-	 * slave 'mnt' to a peer mount that has the
-	 * same root dentry. If none is available then
-	 * slave it to anything that is available.
-	 */
-	while ((peer_mnt = next_peer(peer_mnt)) != mnt &&
-	       peer_mnt->mnt.mnt_root != mnt->mnt.mnt_root) ;
-
-	if (peer_mnt == mnt) {
-		peer_mnt = next_peer(mnt);
-		if (peer_mnt == mnt)
-			peer_mnt = NULL;
-	}
-	if (mnt->mnt_group_id && IS_MNT_SHARED(mnt) &&
-	    list_empty(&mnt->mnt_share))
-		mnt_release_group_id(mnt);
-
-	list_del_init(&mnt->mnt_share);
-	mnt->mnt_group_id = 0;
-
-	if (peer_mnt)
-		master = peer_mnt;
-
-	if (master) {
-		list_for_each_entry(slave_mnt, &mnt->mnt_slave_list, mnt_slave)
-			slave_mnt->mnt_master = master;
-		list_move(&mnt->mnt_slave, &master->mnt_slave_list);
-		list_splice(&mnt->mnt_slave_list, master->mnt_slave_list.prev);
-		INIT_LIST_HEAD(&mnt->mnt_slave_list);
+	if (list_empty(&mnt->mnt_share)) {
+		if (IS_MNT_SHARED(mnt)) {
+			mnt_release_group_id(mnt);
+			CLEAR_MNT_SHARED(mnt);
+		}
+		master = mnt->mnt_master;
+		if (!master) {
+			struct list_head *p = &mnt->mnt_slave_list;
+			while (!list_empty(p)) {
+				slave_mnt = list_first_entry(p,
+						struct mount, mnt_slave);
+				list_del_init(&slave_mnt->mnt_slave);
+				slave_mnt->mnt_master = NULL;
+			}
+			return 0;
+		}
 	} else {
-		struct list_head *p = &mnt->mnt_slave_list;
-		while (!list_empty(p)) {
-                        slave_mnt = list_first_entry(p,
-					struct mount, mnt_slave);
-			list_del_init(&slave_mnt->mnt_slave);
-			slave_mnt->mnt_master = NULL;
+		struct mount *m;
+		/*
+		 * slave 'mnt' to a peer mount that has the
+		 * same root dentry. If none is available then
+		 * slave it to anything that is available.
+		 */
+		for (m = master = next_peer(mnt); m != mnt; m = next_peer(m)) {
+			if (m->mnt.mnt_root == mnt->mnt.mnt_root) {
+				master = m;
+				break;
+			}
 		}
+		list_del_init(&mnt->mnt_share);
+		mnt->mnt_group_id = 0;
+		CLEAR_MNT_SHARED(mnt);
 	}
+	list_for_each_entry(slave_mnt, &mnt->mnt_slave_list, mnt_slave)
+		slave_mnt->mnt_master = master;
+	list_move(&mnt->mnt_slave, &master->mnt_slave_list);
+	list_splice(&mnt->mnt_slave_list, master->mnt_slave_list.prev);
+	INIT_LIST_HEAD(&mnt->mnt_slave_list);
 	mnt->mnt_master = master;
-	CLEAR_MNT_SHARED(mnt);
 	return 0;
 }
 

commit d29216842a85c7970c536108e093963f02714498
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Sep 28 00:27:17 2016 -0500

    mnt: Add a per mount namespace limit on the number of mounts
    
    CAI Qian <caiqian@redhat.com> pointed out that the semantics
    of shared subtrees make it possible to create an exponentially
    increasing number of mounts in a mount namespace.
    
        mkdir /tmp/1 /tmp/2
        mount --make-rshared /
        for i in $(seq 1 20) ; do mount --bind /tmp/1 /tmp/2 ; done
    
    Will create create 2^20 or 1048576 mounts, which is a practical problem
    as some people have managed to hit this by accident.
    
    As such CVE-2016-6213 was assigned.
    
    Ian Kent <raven@themaw.net> described the situation for autofs users
    as follows:
    
    > The number of mounts for direct mount maps is usually not very large because of
    > the way they are implemented, large direct mount maps can have performance
    > problems. There can be anywhere from a few (likely case a few hundred) to less
    > than 10000, plus mounts that have been triggered and not yet expired.
    >
    > Indirect mounts have one autofs mount at the root plus the number of mounts that
    > have been triggered and not yet expired.
    >
    > The number of autofs indirect map entries can range from a few to the common
    > case of several thousand and in rare cases up to between 30000 and 50000. I've
    > not heard of people with maps larger than 50000 entries.
    >
    > The larger the number of map entries the greater the possibility for a large
    > number of active mounts so it's not hard to expect cases of a 1000 or somewhat
    > more active mounts.
    
    So I am setting the default number of mounts allowed per mount
    namespace at 100,000.  This is more than enough for any use case I
    know of, but small enough to quickly stop an exponential increase
    in mounts.  Which should be perfect to catch misconfigurations and
    malfunctioning programs.
    
    For anyone who needs a higher limit this can be changed by writing
    to the new /proc/sys/fs/mount-max sysctl.
    
    Tested-by: CAI Qian <caiqian@redhat.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 99899705b105..234a9ac49958 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -259,7 +259,7 @@ static int propagate_one(struct mount *m)
 		read_sequnlock_excl(&mount_lock);
 	}
 	hlist_add_head(&child->mnt_hash, list);
-	return 0;
+	return count_mounts(m->mnt_ns, child);
 }
 
 /*

commit 5ec0811d30378ae104f250bfc9b3640242d81e3f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 5 09:29:29 2016 -0500

    propogate_mnt: Handle the first propogated copy being a slave
    
    When the first propgated copy was a slave the following oops would result:
    > BUG: unable to handle kernel NULL pointer dereference at 0000000000000010
    > IP: [<ffffffff811fba4e>] propagate_one+0xbe/0x1c0
    > PGD bacd4067 PUD bac66067 PMD 0
    > Oops: 0000 [#1] SMP
    > Modules linked in:
    > CPU: 1 PID: 824 Comm: mount Not tainted 4.6.0-rc5userns+ #1523
    > Hardware name: Bochs Bochs, BIOS Bochs 01/01/2007
    > task: ffff8800bb0a8000 ti: ffff8800bac3c000 task.ti: ffff8800bac3c000
    > RIP: 0010:[<ffffffff811fba4e>]  [<ffffffff811fba4e>] propagate_one+0xbe/0x1c0
    > RSP: 0018:ffff8800bac3fd38  EFLAGS: 00010283
    > RAX: 0000000000000000 RBX: ffff8800bb77ec00 RCX: 0000000000000010
    > RDX: 0000000000000000 RSI: ffff8800bb58c000 RDI: ffff8800bb58c480
    > RBP: ffff8800bac3fd48 R08: 0000000000000001 R09: 0000000000000000
    > R10: 0000000000001ca1 R11: 0000000000001c9d R12: 0000000000000000
    > R13: ffff8800ba713800 R14: ffff8800bac3fda0 R15: ffff8800bb77ec00
    > FS:  00007f3c0cd9b7e0(0000) GS:ffff8800bfb00000(0000) knlGS:0000000000000000
    > CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    > CR2: 0000000000000010 CR3: 00000000bb79d000 CR4: 00000000000006e0
    > Stack:
    >  ffff8800bb77ec00 0000000000000000 ffff8800bac3fd88 ffffffff811fbf85
    >  ffff8800bac3fd98 ffff8800bb77f080 ffff8800ba713800 ffff8800bb262b40
    >  0000000000000000 0000000000000000 ffff8800bac3fdd8 ffffffff811f1da0
    > Call Trace:
    >  [<ffffffff811fbf85>] propagate_mnt+0x105/0x140
    >  [<ffffffff811f1da0>] attach_recursive_mnt+0x120/0x1e0
    >  [<ffffffff811f1ec3>] graft_tree+0x63/0x70
    >  [<ffffffff811f1f6b>] do_add_mount+0x9b/0x100
    >  [<ffffffff811f2c1a>] do_mount+0x2aa/0xdf0
    >  [<ffffffff8117efbe>] ? strndup_user+0x4e/0x70
    >  [<ffffffff811f3a45>] SyS_mount+0x75/0xc0
    >  [<ffffffff8100242b>] do_syscall_64+0x4b/0xa0
    >  [<ffffffff81988f3c>] entry_SYSCALL64_slow_path+0x25/0x25
    > Code: 00 00 75 ec 48 89 0d 02 22 22 01 8b 89 10 01 00 00 48 89 05 fd 21 22 01 39 8e 10 01 00 00 0f 84 e0 00 00 00 48 8b 80 d8 00 00 00 <48> 8b 50 10 48 89 05 df 21 22 01 48 89 15 d0 21 22 01 8b 53 30
    > RIP  [<ffffffff811fba4e>] propagate_one+0xbe/0x1c0
    >  RSP <ffff8800bac3fd38>
    > CR2: 0000000000000010
    > ---[ end trace 2725ecd95164f217 ]---
    
    This oops happens with the namespace_sem held and can be triggered by
    non-root users.  An all around not pleasant experience.
    
    To avoid this scenario when finding the appropriate source mount to
    copy stop the walk up the mnt_master chain when the first source mount
    is encountered.
    
    Further rewrite the walk up the last_source mnt_master chain so that
    it is clear what is going on.
    
    The reason why the first source mount is special is that it it's
    mnt_parent is not a mount in the dest_mnt propagation tree, and as
    such termination conditions based up on the dest_mnt mount propgation
    tree do not make sense.
    
    To avoid other kinds of confusion last_dest is not changed when
    computing last_source.  last_dest is only used once in propagate_one
    and that is above the point of the code being modified, so changing
    the global variable is meaningless and confusing.
    
    Cc: stable@vger.kernel.org
    fixes: f2ebb3a921c1ca1e2ddd9242e95a1989a50c4c68 ("smarter propagate_mnt()")
    Reported-by: Tycho Andersen <tycho.andersen@canonical.com>
    Reviewed-by: Seth Forshee <seth.forshee@canonical.com>
    Tested-by: Seth Forshee <seth.forshee@canonical.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index c524fdddc7fb..99899705b105 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -198,7 +198,7 @@ static struct mount *next_group(struct mount *m, struct mount *origin)
 
 /* all accesses are serialized by namespace_sem */
 static struct user_namespace *user_ns;
-static struct mount *last_dest, *last_source, *dest_master;
+static struct mount *last_dest, *first_source, *last_source, *dest_master;
 static struct mountpoint *mp;
 static struct hlist_head *list;
 
@@ -221,20 +221,22 @@ static int propagate_one(struct mount *m)
 		type = CL_MAKE_SHARED;
 	} else {
 		struct mount *n, *p;
+		bool done;
 		for (n = m; ; n = p) {
 			p = n->mnt_master;
-			if (p == dest_master || IS_MNT_MARKED(p)) {
-				while (last_dest->mnt_master != p) {
-					last_source = last_source->mnt_master;
-					last_dest = last_source->mnt_parent;
-				}
-				if (!peers(n, last_dest)) {
-					last_source = last_source->mnt_master;
-					last_dest = last_source->mnt_parent;
-				}
+			if (p == dest_master || IS_MNT_MARKED(p))
 				break;
-			}
 		}
+		do {
+			struct mount *parent = last_source->mnt_parent;
+			if (last_source == first_source)
+				break;
+			done = parent->mnt_master == p;
+			if (done && peers(n, parent))
+				break;
+			last_source = last_source->mnt_master;
+		} while (!done);
+
 		type = CL_SLAVE;
 		/* beginning of peer group among the slaves? */
 		if (IS_MNT_SHARED(m))
@@ -286,6 +288,7 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 	 */
 	user_ns = current->nsproxy->mnt_ns->user_ns;
 	last_dest = dest_mnt;
+	first_source = source_mnt;
 	last_source = source_mnt;
 	mp = dest_mp;
 	list = tree_list;

commit 7ae8fd0351f912b075149a1e03a017be8b903b9a
Author: Maxim Patlasov <mpatlasov@virtuozzo.com>
Date:   Tue Feb 16 11:45:33 2016 -0800

    fs/pnode.c: treat zero mnt_group_id-s as unequal
    
    propagate_one(m) calculates "type" argument for copy_tree() like this:
    
    >    if (m->mnt_group_id == last_dest->mnt_group_id) {
    >        type = CL_MAKE_SHARED;
    >    } else {
    >        type = CL_SLAVE;
    >        if (IS_MNT_SHARED(m))
    >           type |= CL_MAKE_SHARED;
    >   }
    
    The "type" argument then governs clone_mnt() behavior with respect to flags
    and mnt_master of new mount. When we iterate through a slave group, it is
    possible that both current "m" and "last_dest" are not shared (although,
    both are slaves, i.e. have non-NULL mnt_master-s). Then the comparison
    above erroneously makes new mount shared and sets its mnt_master to
    last_source->mnt_master. The patch fixes the problem by handling zero
    mnt_group_id-s as though they are unequal.
    
    The similar problem exists in the implementation of "else" clause above
    when we have to ascend upward in the master/slave tree by calling:
    
    >    last_source = last_source->mnt_master;
    >    last_dest = last_source->mnt_parent;
    
    proper number of times. The last step is governed by
    "n->mnt_group_id != last_dest->mnt_group_id" condition that may lie if
    both are zero. The patch fixes this case in the same way as the former one.
    
    [AV: don't open-code an obvious helper...]
    
    Signed-off-by: Maxim Patlasov <mpatlasov@virtuozzo.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 6367e1e435c6..c524fdddc7fb 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -202,6 +202,11 @@ static struct mount *last_dest, *last_source, *dest_master;
 static struct mountpoint *mp;
 static struct hlist_head *list;
 
+static inline bool peers(struct mount *m1, struct mount *m2)
+{
+	return m1->mnt_group_id == m2->mnt_group_id && m1->mnt_group_id;
+}
+
 static int propagate_one(struct mount *m)
 {
 	struct mount *child;
@@ -212,7 +217,7 @@ static int propagate_one(struct mount *m)
 	/* skip if mountpoint isn't covered by it */
 	if (!is_subdir(mp->m_dentry, m->mnt.mnt_root))
 		return 0;
-	if (m->mnt_group_id == last_dest->mnt_group_id) {
+	if (peers(m, last_dest)) {
 		type = CL_MAKE_SHARED;
 	} else {
 		struct mount *n, *p;
@@ -223,7 +228,7 @@ static int propagate_one(struct mount *m)
 					last_source = last_source->mnt_master;
 					last_dest = last_source->mnt_parent;
 				}
-				if (n->mnt_group_id != last_dest->mnt_group_id) {
+				if (!peers(n, last_dest)) {
 					last_source = last_source->mnt_master;
 					last_dest = last_source->mnt_parent;
 				}

commit 0c56fe31420ca599c90240315f7959bf1b4eb6ce
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jan 5 13:38:04 2015 -0600

    mnt: Don't propagate unmounts to locked mounts
    
    If the first mount in shared subtree is locked don't unmount the
    shared subtree.
    
    This is ensured by walking through the mounts parents before children
    and marking a mount as unmountable if it is not locked or it is locked
    but it's parent is marked.
    
    This allows recursive mount detach to propagate through a set of
    mounts when unmounting them would not reveal what is under any locked
    mount.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 89890293dd0a..6367e1e435c6 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -381,6 +381,26 @@ void propagate_mount_unlock(struct mount *mnt)
 	}
 }
 
+/*
+ * Mark all mounts that the MNT_LOCKED logic will allow to be unmounted.
+ */
+static void mark_umount_candidates(struct mount *mnt)
+{
+	struct mount *parent = mnt->mnt_parent;
+	struct mount *m;
+
+	BUG_ON(parent == mnt);
+
+	for (m = propagation_next(parent, parent); m;
+			m = propagation_next(m, parent)) {
+		struct mount *child = __lookup_mnt_last(&m->mnt,
+						mnt->mnt_mountpoint);
+		if (child && (!IS_MNT_LOCKED(child) || IS_MNT_MARKED(m))) {
+			SET_MNT_MARK(child);
+		}
+	}
+}
+
 /*
  * NOTE: unmounting 'mnt' naturally propagates to all other mounts its
  * parent propagates to.
@@ -398,10 +418,13 @@ static void __propagate_umount(struct mount *mnt)
 		struct mount *child = __lookup_mnt_last(&m->mnt,
 						mnt->mnt_mountpoint);
 		/*
-		 * umount the child only if the child has no
-		 * other children
+		 * umount the child only if the child has no children
+		 * and the child is marked safe to unmount.
 		 */
-		if (child && list_empty(&child->mnt_mounts)) {
+		if (!child || !IS_MNT_MARKED(child))
+			continue;
+		CLEAR_MNT_MARK(child);
+		if (list_empty(&child->mnt_mounts)) {
 			list_del_init(&child->mnt_child);
 			child->mnt.mnt_flags |= MNT_UMOUNT;
 			list_move_tail(&child->mnt_list, &mnt->mnt_list);
@@ -420,6 +443,9 @@ int propagate_umount(struct list_head *list)
 {
 	struct mount *mnt;
 
+	list_for_each_entry_reverse(mnt, list, mnt_list)
+		mark_umount_candidates(mnt);
+
 	list_for_each_entry(mnt, list, mnt_list)
 		__propagate_umount(mnt);
 	return 0;

commit 5d88457eb5b86b475422dc882f089203faaeedb5
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Jan 3 05:39:35 2015 -0600

    mnt: On an unmount propagate clearing of MNT_LOCKED
    
    A prerequisite of calling umount_tree is that the point where the tree
    is mounted at is valid to unmount.
    
    If we are propagating the effect of the unmount clear MNT_LOCKED in
    every instance where the same filesystem is mounted on the same
    mountpoint in the mount tree, as we know (by virtue of the fact
    that umount_tree was called) that it is safe to reveal what
    is at that mountpoint.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index c27ae38ee250..89890293dd0a 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -361,6 +361,26 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 	return ret;
 }
 
+/*
+ * Clear MNT_LOCKED when it can be shown to be safe.
+ *
+ * mount_lock lock must be held for write
+ */
+void propagate_mount_unlock(struct mount *mnt)
+{
+	struct mount *parent = mnt->mnt_parent;
+	struct mount *m, *child;
+
+	BUG_ON(parent == mnt);
+
+	for (m = propagation_next(parent, parent); m;
+			m = propagation_next(m, parent)) {
+		child = __lookup_mnt_last(&m->mnt, mnt->mnt_mountpoint);
+		if (child)
+			child->mnt.mnt_flags &= ~MNT_LOCKED;
+	}
+}
+
 /*
  * NOTE: unmounting 'mnt' naturally propagates to all other mounts its
  * parent propagates to.

commit 411a938b5abc9cb126c41cccf5975ae464fe0f3e
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Dec 22 19:12:07 2014 -0600

    mnt: Delay removal from the mount hash.
    
    - Modify __lookup_mnt_hash_last to ignore mounts that have MNT_UMOUNTED set.
    - Don't remove mounts from the mount hash table in propogate_umount
    - Don't remove mounts from the mount hash table in umount_tree before
      the entire list of mounts to be umounted is selected.
    - Remove mounts from the mount hash table as the last thing that
      happens in the case where a mount has a parent in umount_tree.
      Mounts without parents are not hashed (by definition).
    
    This paves the way for delaying removal from the mount hash table even
    farther and fixing the MNT_LOCKED vs MNT_DETACH issue.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index ac3aa0d43b90..c27ae38ee250 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -383,7 +383,6 @@ static void __propagate_umount(struct mount *mnt)
 		 */
 		if (child && list_empty(&child->mnt_mounts)) {
 			list_del_init(&child->mnt_child);
-			hlist_del_init_rcu(&child->mnt_hash);
 			child->mnt.mnt_flags |= MNT_UMOUNT;
 			list_move_tail(&child->mnt_list, &mnt->mnt_list);
 		}

commit 590ce4bcbfb4e0462a720a4ad901e84416080bba
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Dec 22 18:30:08 2014 -0600

    mnt: Add MNT_UMOUNT flag
    
    In some instances it is necessary to know if the the unmounting
    process has begun on a mount.  Add MNT_UMOUNT to make that reliably
    testable.
    
    This fix gets used in fixing locked mounts in MNT_DETACH
    
    Cc: stable@vger.kernel.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index bf012af709dd..ac3aa0d43b90 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -384,6 +384,7 @@ static void __propagate_umount(struct mount *mnt)
 		if (child && list_empty(&child->mnt_mounts)) {
 			list_del_init(&child->mnt_child);
 			hlist_del_init_rcu(&child->mnt_hash);
+			child->mnt.mnt_flags |= MNT_UMOUNT;
 			list_move_tail(&child->mnt_list, &mnt->mnt_list);
 		}
 	}

commit c003b26ff98ca04a180ff34c38c007a3998d62f9
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Dec 18 13:10:48 2014 -0600

    mnt: In umount_tree reuse mnt_list instead of mnt_hash
    
    umount_tree builds a list of mounts that need to be unmounted.
    Utilize mnt_list for this purpose instead of mnt_hash.  This begins to
    allow keeping a mount on the mnt_hash after it is unmounted, which is
    necessary for a properly functioning MNT_LOCKED implementation.
    
    The fact that mnt_list is an ordinary list makding available list_move
    is nice bonus.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 260ac8f898a4..bf012af709dd 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -384,7 +384,7 @@ static void __propagate_umount(struct mount *mnt)
 		if (child && list_empty(&child->mnt_mounts)) {
 			list_del_init(&child->mnt_child);
 			hlist_del_init_rcu(&child->mnt_hash);
-			hlist_add_before_rcu(&child->mnt_hash, &mnt->mnt_hash);
+			list_move_tail(&child->mnt_list, &mnt->mnt_list);
 		}
 	}
 }
@@ -396,11 +396,11 @@ static void __propagate_umount(struct mount *mnt)
  *
  * vfsmount lock must be held for write
  */
-int propagate_umount(struct hlist_head *list)
+int propagate_umount(struct list_head *list)
 {
 	struct mount *mnt;
 
-	hlist_for_each_entry(mnt, list, mnt_hash)
+	list_for_each_entry(mnt, list, mnt_list)
 		__propagate_umount(mnt);
 	return 0;
 }

commit 8486a7882b5ba906992fd78bbfcefaae7fe285cc
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Oct 7 16:22:52 2014 -0700

    mnt: Move the clear of MNT_LOCKED from copy_tree to it's callers.
    
    Clear MNT_LOCKED in the callers of copy_tree except copy_mnt_ns, and
    collect_mounts.  In copy_mnt_ns it is necessary to create an exact
    copy of a mount tree, so not clearing MNT_LOCKED is important.
    Similarly collect_mounts is used to take a snapshot of the mount tree
    for audit logging purposes and auditing using a faithful copy of the
    tree is important.
    
    This becomes particularly significant when we start setting MNT_LOCKED
    on rootfs to prevent it from being unmounted.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index aae331a5d03b..260ac8f898a4 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -242,6 +242,7 @@ static int propagate_one(struct mount *m)
 	child = copy_tree(last_source, last_source->mnt.mnt_root, type);
 	if (IS_ERR(child))
 		return PTR_ERR(child);
+	child->mnt.mnt_flags &= ~MNT_LOCKED;
 	mnt_set_mountpoint(m, mp, child);
 	last_dest = m;
 	last_source = child;

commit 88b368f27a094277143d8ecd5a056116f6a41520
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Aug 18 15:09:26 2014 -0400

    get rid of propagate_umount() mistakenly treating slaves as busy.
    
    The check in __propagate_umount() ("has somebody explicitly mounted
    something on that slave?") is done *before* taking the already doomed
    victims out of the child lists.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 302bf22c4a30..aae331a5d03b 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -381,6 +381,7 @@ static void __propagate_umount(struct mount *mnt)
 		 * other children
 		 */
 		if (child && list_empty(&child->mnt_mounts)) {
+			list_del_init(&child->mnt_child);
 			hlist_del_init_rcu(&child->mnt_hash);
 			hlist_add_before_rcu(&child->mnt_hash, &mnt->mnt_hash);
 		}

commit f2ebb3a921c1ca1e2ddd9242e95a1989a50c4c68
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Feb 27 09:35:45 2014 -0500

    smarter propagate_mnt()
    
    The current mainline has copies propagated to *all* nodes, then
    tears down the copies we made for nodes that do not contain
    counterparts of the desired mountpoint.  That sets the right
    propagation graph for the copies (at teardown time we move
    the slaves of removed node to a surviving peer or directly
    to master), but we end up paying a fairly steep price in
    useless allocations.  It's fairly easy to create a situation
    where N calls of mount(2) create exactly N bindings, with
    O(N^2) vfsmounts allocated and freed in process.
    
    Fortunately, it is possible to avoid those allocations/freeings.
    The trick is to create copies in the right order and find which
    one would've eventually become a master with the current algorithm.
    It turns out to be possible in O(nodes getting propagation) time
    and with no extra allocations at all.
    
    One part is that we need to make sure that eventual master will be
    created before its slaves, so we need to walk the propagation
    tree in a different order - by peer groups.  And iterate through
    the peers before dealing with the next group.
    
    Another thing is finding the (earlier) copy that will be a master
    of one we are about to create; to do that we are (temporary) marking
    the masters of mountpoints we are attaching the copies to.
    
    Either we are in a peer of the last mountpoint we'd dealt with,
    or we have the following situation: we are attaching to mountpoint M,
    the last copy S_0 had been attached to M_0 and there are sequences
    S_0...S_n, M_0...M_n such that S_{i+1} is a master of S_{i},
    S_{i} mounted on M{i} and we need to create a slave of the first S_{k}
    such that M is getting propagation from M_{k}.  It means that the master
    of M_{k} will be among the sequence of masters of M.  On the
    other hand, the nearest marked node in that sequence will either
    be the master of M_{k} or the master of M_{k-1} (the latter -
    in the case if M_{k-1} is a slave of something M gets propagation
    from, but in a wrong peer group).
    
    So we go through the sequence of masters of M until we find
    a marked one (P).  Let N be the one before it.  Then we go through
    the sequence of masters of S_0 until we find one (say, S) mounted
    on a node D that has P as master and check if D is a peer of N.
    If it is, S will be the master of new copy, if not - the master of S
    will be.
    
    That's it for the hard part; the rest is fairly simple.  Iterator
    is in next_group(), handling of one prospective mountpoint is
    propagate_one().
    
    It seems to survive all tests and gives a noticably better performance
    than the current mainline for setups that are seriously using shared
    subtrees.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 88396df725b4..302bf22c4a30 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -164,46 +164,94 @@ static struct mount *propagation_next(struct mount *m,
 	}
 }
 
-/*
- * return the source mount to be used for cloning
- *
- * @dest 	the current destination mount
- * @last_dest  	the last seen destination mount
- * @last_src  	the last seen source mount
- * @type	return CL_SLAVE if the new mount has to be
- * 		cloned as a slave.
- */
-static struct mount *get_source(struct mount *dest,
-				struct mount *last_dest,
-				struct mount *last_src,
-				int *type)
+static struct mount *next_group(struct mount *m, struct mount *origin)
 {
-	struct mount *p_last_src = NULL;
-	struct mount *p_last_dest = NULL;
-
-	while (last_dest != dest->mnt_master) {
-		p_last_dest = last_dest;
-		p_last_src = last_src;
-		last_dest = last_dest->mnt_master;
-		last_src = last_src->mnt_master;
+	while (1) {
+		while (1) {
+			struct mount *next;
+			if (!IS_MNT_NEW(m) && !list_empty(&m->mnt_slave_list))
+				return first_slave(m);
+			next = next_peer(m);
+			if (m->mnt_group_id == origin->mnt_group_id) {
+				if (next == origin)
+					return NULL;
+			} else if (m->mnt_slave.next != &next->mnt_slave)
+				break;
+			m = next;
+		}
+		/* m is the last peer */
+		while (1) {
+			struct mount *master = m->mnt_master;
+			if (m->mnt_slave.next != &master->mnt_slave_list)
+				return next_slave(m);
+			m = next_peer(master);
+			if (master->mnt_group_id == origin->mnt_group_id)
+				break;
+			if (master->mnt_slave.next == &m->mnt_slave)
+				break;
+			m = master;
+		}
+		if (m == origin)
+			return NULL;
 	}
+}
 
-	if (p_last_dest) {
-		do {
-			p_last_dest = next_peer(p_last_dest);
-		} while (IS_MNT_NEW(p_last_dest));
-		/* is that a peer of the earlier? */
-		if (dest == p_last_dest) {
-			*type = CL_MAKE_SHARED;
-			return p_last_src;
+/* all accesses are serialized by namespace_sem */
+static struct user_namespace *user_ns;
+static struct mount *last_dest, *last_source, *dest_master;
+static struct mountpoint *mp;
+static struct hlist_head *list;
+
+static int propagate_one(struct mount *m)
+{
+	struct mount *child;
+	int type;
+	/* skip ones added by this propagate_mnt() */
+	if (IS_MNT_NEW(m))
+		return 0;
+	/* skip if mountpoint isn't covered by it */
+	if (!is_subdir(mp->m_dentry, m->mnt.mnt_root))
+		return 0;
+	if (m->mnt_group_id == last_dest->mnt_group_id) {
+		type = CL_MAKE_SHARED;
+	} else {
+		struct mount *n, *p;
+		for (n = m; ; n = p) {
+			p = n->mnt_master;
+			if (p == dest_master || IS_MNT_MARKED(p)) {
+				while (last_dest->mnt_master != p) {
+					last_source = last_source->mnt_master;
+					last_dest = last_source->mnt_parent;
+				}
+				if (n->mnt_group_id != last_dest->mnt_group_id) {
+					last_source = last_source->mnt_master;
+					last_dest = last_source->mnt_parent;
+				}
+				break;
+			}
 		}
+		type = CL_SLAVE;
+		/* beginning of peer group among the slaves? */
+		if (IS_MNT_SHARED(m))
+			type |= CL_MAKE_SHARED;
 	}
-	/* slave of the earlier, then */
-	*type = CL_SLAVE;
-	/* beginning of peer group among the slaves? */
-	if (IS_MNT_SHARED(dest))
-		*type |= CL_MAKE_SHARED;
-	return last_src;
+		
+	/* Notice when we are propagating across user namespaces */
+	if (m->mnt_ns->user_ns != user_ns)
+		type |= CL_UNPRIVILEGED;
+	child = copy_tree(last_source, last_source->mnt.mnt_root, type);
+	if (IS_ERR(child))
+		return PTR_ERR(child);
+	mnt_set_mountpoint(m, mp, child);
+	last_dest = m;
+	last_source = child;
+	if (m->mnt_master != dest_master) {
+		read_seqlock_excl(&mount_lock);
+		SET_MNT_MARK(m->mnt_master);
+		read_sequnlock_excl(&mount_lock);
+	}
+	hlist_add_head(&child->mnt_hash, list);
+	return 0;
 }
 
 /*
@@ -222,56 +270,48 @@ static struct mount *get_source(struct mount *dest,
 int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 		    struct mount *source_mnt, struct hlist_head *tree_list)
 {
-	struct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;
-	struct mount *m, *child;
+	struct mount *m, *n;
 	int ret = 0;
-	struct mount *prev_dest_mnt = dest_mnt;
-	struct mount *prev_src_mnt  = source_mnt;
-	HLIST_HEAD(tmp_list);
-
-	for (m = propagation_next(dest_mnt, dest_mnt); m;
-			m = propagation_next(m, dest_mnt)) {
-		int type;
-		struct mount *source;
-
-		if (IS_MNT_NEW(m))
-			continue;
-
-		source =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);
-
-		/* Notice when we are propagating across user namespaces */
-		if (m->mnt_ns->user_ns != user_ns)
-			type |= CL_UNPRIVILEGED;
-
-		child = copy_tree(source, source->mnt.mnt_root, type);
-		if (IS_ERR(child)) {
-			ret = PTR_ERR(child);
-			tmp_list = *tree_list;
-			tmp_list.first->pprev = &tmp_list.first;
-			INIT_HLIST_HEAD(tree_list);
+
+	/*
+	 * we don't want to bother passing tons of arguments to
+	 * propagate_one(); everything is serialized by namespace_sem,
+	 * so globals will do just fine.
+	 */
+	user_ns = current->nsproxy->mnt_ns->user_ns;
+	last_dest = dest_mnt;
+	last_source = source_mnt;
+	mp = dest_mp;
+	list = tree_list;
+	dest_master = dest_mnt->mnt_master;
+
+	/* all peers of dest_mnt, except dest_mnt itself */
+	for (n = next_peer(dest_mnt); n != dest_mnt; n = next_peer(n)) {
+		ret = propagate_one(n);
+		if (ret)
 			goto out;
-		}
+	}
 
-		if (is_subdir(dest_mp->m_dentry, m->mnt.mnt_root)) {
-			mnt_set_mountpoint(m, dest_mp, child);
-			hlist_add_head(&child->mnt_hash, tree_list);
-		} else {
-			/*
-			 * This can happen if the parent mount was bind mounted
-			 * on some subdirectory of a shared/slave mount.
-			 */
-			hlist_add_head(&child->mnt_hash, &tmp_list);
-		}
-		prev_dest_mnt = m;
-		prev_src_mnt  = child;
+	/* all slave groups */
+	for (m = next_group(dest_mnt, dest_mnt); m;
+			m = next_group(m, dest_mnt)) {
+		/* everything in that slave group */
+		n = m;
+		do {
+			ret = propagate_one(n);
+			if (ret)
+				goto out;
+			n = next_peer(n);
+		} while (n != m);
 	}
 out:
-	lock_mount_hash();
-	while (!hlist_empty(&tmp_list)) {
-		child = hlist_entry(tmp_list.first, struct mount, mnt_hash);
-		umount_tree(child, 0);
+	read_seqlock_excl(&mount_lock);
+	hlist_for_each_entry(n, tree_list, mnt_hash) {
+		m = n->mnt_parent;
+		if (m->mnt_master != dest_mnt->mnt_master)
+			CLEAR_MNT_MARK(m->mnt_master);
 	}
-	unlock_mount_hash();
+	read_sequnlock_excl(&mount_lock);
 	return ret;
 }
 

commit 38129a13e6e71f666e0468e99fdd932a687b4d7e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Mar 20 21:10:51 2014 -0400

    switch mnt_hash to hlist
    
    fixes RCU bug - walking through hlist is safe in face of element moves,
    since it's self-terminating.  Cyclic lists are not - if we end up jumping
    to another hash chain, we'll loop infinitely without ever hitting the
    original list head.
    
    [fix for dumb braino folded]
    
    Spotted by: Max Kellermann <mk@cm4all.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index c7221bb19801..88396df725b4 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -220,14 +220,14 @@ static struct mount *get_source(struct mount *dest,
  * @tree_list : list of heads of trees to be attached.
  */
 int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
-		    struct mount *source_mnt, struct list_head *tree_list)
+		    struct mount *source_mnt, struct hlist_head *tree_list)
 {
 	struct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;
 	struct mount *m, *child;
 	int ret = 0;
 	struct mount *prev_dest_mnt = dest_mnt;
 	struct mount *prev_src_mnt  = source_mnt;
-	LIST_HEAD(tmp_list);
+	HLIST_HEAD(tmp_list);
 
 	for (m = propagation_next(dest_mnt, dest_mnt); m;
 			m = propagation_next(m, dest_mnt)) {
@@ -246,27 +246,29 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 		child = copy_tree(source, source->mnt.mnt_root, type);
 		if (IS_ERR(child)) {
 			ret = PTR_ERR(child);
-			list_splice(tree_list, tmp_list.prev);
+			tmp_list = *tree_list;
+			tmp_list.first->pprev = &tmp_list.first;
+			INIT_HLIST_HEAD(tree_list);
 			goto out;
 		}
 
 		if (is_subdir(dest_mp->m_dentry, m->mnt.mnt_root)) {
 			mnt_set_mountpoint(m, dest_mp, child);
-			list_add_tail(&child->mnt_hash, tree_list);
+			hlist_add_head(&child->mnt_hash, tree_list);
 		} else {
 			/*
 			 * This can happen if the parent mount was bind mounted
 			 * on some subdirectory of a shared/slave mount.
 			 */
-			list_add_tail(&child->mnt_hash, &tmp_list);
+			hlist_add_head(&child->mnt_hash, &tmp_list);
 		}
 		prev_dest_mnt = m;
 		prev_src_mnt  = child;
 	}
 out:
 	lock_mount_hash();
-	while (!list_empty(&tmp_list)) {
-		child = list_first_entry(&tmp_list, struct mount, mnt_hash);
+	while (!hlist_empty(&tmp_list)) {
+		child = hlist_entry(tmp_list.first, struct mount, mnt_hash);
 		umount_tree(child, 0);
 	}
 	unlock_mount_hash();
@@ -338,8 +340,10 @@ static void __propagate_umount(struct mount *mnt)
 		 * umount the child only if the child has no
 		 * other children
 		 */
-		if (child && list_empty(&child->mnt_mounts))
-			list_move_tail(&child->mnt_hash, &mnt->mnt_hash);
+		if (child && list_empty(&child->mnt_mounts)) {
+			hlist_del_init_rcu(&child->mnt_hash);
+			hlist_add_before_rcu(&child->mnt_hash, &mnt->mnt_hash);
+		}
 	}
 }
 
@@ -350,11 +354,11 @@ static void __propagate_umount(struct mount *mnt)
  *
  * vfsmount lock must be held for write
  */
-int propagate_umount(struct list_head *list)
+int propagate_umount(struct hlist_head *list)
 {
 	struct mount *mnt;
 
-	list_for_each_entry(mnt, list, mnt_hash)
+	hlist_for_each_entry(mnt, list, mnt_hash)
 		__propagate_umount(mnt);
 	return 0;
 }

commit 474279dc0f7745124fc76b474c8dc1294f8e87ce
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Oct 1 16:11:26 2013 -0400

    split __lookup_mnt() in two functions
    
    Instead of passing the direction as argument (and checking it on every
    step through the hash chain), just have separate __lookup_mnt() and
    __lookup_mnt_last().  And use the standard iterators...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 58933fd149ad..c7221bb19801 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -310,7 +310,7 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 
 	for (m = propagation_next(parent, parent); m;
 	     		m = propagation_next(m, parent)) {
-		child = __lookup_mnt(&m->mnt, mnt->mnt_mountpoint, 0);
+		child = __lookup_mnt_last(&m->mnt, mnt->mnt_mountpoint);
 		if (child && list_empty(&child->mnt_mounts) &&
 		    (ret = do_refcount_check(child, 1)))
 			break;
@@ -332,8 +332,8 @@ static void __propagate_umount(struct mount *mnt)
 	for (m = propagation_next(parent, parent); m;
 			m = propagation_next(m, parent)) {
 
-		struct mount *child = __lookup_mnt(&m->mnt,
-					mnt->mnt_mountpoint, 0);
+		struct mount *child = __lookup_mnt_last(&m->mnt,
+						mnt->mnt_mountpoint);
 		/*
 		 * umount the child only if the child has no
 		 * other children

commit 719ea2fbb553ab3f61a174a4b5861289dcc46cb1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 29 11:24:49 2013 -0400

    new helpers: lock_mount_hash/unlock_mount_hash
    
    aka br_write_{lock,unlock} of vfsmount_lock.  Inlines in fs/mount.h,
    vfsmount_lock extern moved over there as well.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 3cfd48cf887e..58933fd149ad 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -264,12 +264,12 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 		prev_src_mnt  = child;
 	}
 out:
-	br_write_lock(&vfsmount_lock);
+	lock_mount_hash();
 	while (!list_empty(&tmp_list)) {
 		child = list_first_entry(&tmp_list, struct mount, mnt_hash);
 		umount_tree(child, 0);
 	}
-	br_write_unlock(&vfsmount_lock);
+	unlock_mount_hash();
 	return ret;
 }
 

commit aba809cf0944fdc5a83ef8b5864cdce2a99b2513
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Sep 28 23:10:55 2013 -0400

    namespace.c: get rid of mnt_ghosts
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 9af0df15256e..3cfd48cf887e 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -278,8 +278,7 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
  */
 static inline int do_refcount_check(struct mount *mnt, int count)
 {
-	int mycount = mnt_get_count(mnt) - mnt->mnt_ghosts;
-	return (mycount > count);
+	return mnt_get_count(mnt) > count;
 }
 
 /*

commit 5d477b6079619910dab882fa229cce1f14f86cf8
Author: Takashi Iwai <tiwai@suse.de>
Date:   Fri May 10 14:04:11 2013 +0200

    vfs: Fix invalid ida_remove() call
    
    When the group id of a shared mount is not allocated, the umount still
    tries to call mnt_release_group_id(), which eventually hits a kernel
    warning at ida_remove() spewing a message like:
      ida_remove called for id=0 which is not allocated.
    
    This patch fixes the bug simply checking the group id in the caller.
    
    Reported-by: Cristian Rodríguez <crrodriguez@opensuse.org>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 3d2a7141b87a..9af0df15256e 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -83,7 +83,8 @@ static int do_make_slave(struct mount *mnt)
 		if (peer_mnt == mnt)
 			peer_mnt = NULL;
 	}
-	if (IS_MNT_SHARED(mnt) && list_empty(&mnt->mnt_share))
+	if (mnt->mnt_group_id && IS_MNT_SHARED(mnt) &&
+	    list_empty(&mnt->mnt_share))
 		mnt_release_group_id(mnt);
 
 	list_del_init(&mnt->mnt_share);

commit 20b4fb485227404329e41ad15588afad3df23050
Merge: b9394d8a657c ac3e3c5b1164
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 1 17:51:54 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull VFS updates from Al Viro,
    
    Misc cleanups all over the place, mainly wrt /proc interfaces (switch
    create_proc_entry to proc_create(), get rid of the deprecated
    create_proc_read_entry() in favor of using proc_create_data() and
    seq_file etc).
    
    7kloc removed.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (204 commits)
      don't bother with deferred freeing of fdtables
      proc: Move non-public stuff from linux/proc_fs.h to fs/proc/internal.h
      proc: Make the PROC_I() and PDE() macros internal to procfs
      proc: Supply a function to remove a proc entry by PDE
      take cgroup_open() and cpuset_open() to fs/proc/base.c
      ppc: Clean up scanlog
      ppc: Clean up rtas_flash driver somewhat
      hostap: proc: Use remove_proc_subtree()
      drm: proc: Use remove_proc_subtree()
      drm: proc: Use minor->index to label things, not PDE->name
      drm: Constify drm_proc_list[]
      zoran: Don't print proc_dir_entry data in debug
      reiserfs: Don't access the proc_dir_entry in r_open(), r_start() r_show()
      proc: Supply an accessor for getting the data from a PDE's parent
      airo: Use remove_proc_subtree()
      rtl8192u: Don't need to save device proc dir PDE
      rtl8187se: Use a dir under /proc/net/r8180/
      proc: Add proc_mkdir_data()
      proc: Move some bits from linux/proc_fs.h to linux/{of.h,signal.h,tty.h}
      proc: Move PDE_NET() to fs/proc/proc_net.c
      ...

commit 328e6d9014636afc2b3c979403b36faadb412657
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 16 14:49:45 2013 -0400

    switch unlock_mount() to namespace_unlock(), convert all umount_tree() callers
    
    which allows to kill the last argument of umount_tree() and make release_mounts()
    static.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 98e0d3a23fac..43617258fa6a 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -225,7 +225,6 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 	struct mount *prev_dest_mnt = dest_mnt;
 	struct mount *prev_src_mnt  = source_mnt;
 	LIST_HEAD(tmp_list);
-	LIST_HEAD(umount_list);
 
 	for (m = propagation_next(dest_mnt, dest_mnt); m;
 			m = propagation_next(m, dest_mnt)) {
@@ -261,10 +260,9 @@ int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 	br_write_lock(&vfsmount_lock);
 	while (!list_empty(&tmp_list)) {
 		child = list_first_entry(&tmp_list, struct mount, mnt_hash);
-		umount_tree(child, 0, &umount_list);
+		umount_tree(child, 0);
 	}
 	br_write_unlock(&vfsmount_lock);
-	release_mounts(&umount_list);
 	return ret;
 }
 

commit 84d17192d2afd52aeba88c71ae4959a015f56a38
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Mar 15 10:53:28 2013 -0400

    get rid of full-hash scan on detaching vfsmounts
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 3e000a51ac0d..98e0d3a23fac 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -217,7 +217,7 @@ static struct mount *get_source(struct mount *dest,
  * @source_mnt: source mount.
  * @tree_list : list of heads of trees to be attached.
  */
-int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
+int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,
 		    struct mount *source_mnt, struct list_head *tree_list)
 {
 	struct mount *m, *child;
@@ -244,8 +244,8 @@ int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
 			goto out;
 		}
 
-		if (is_subdir(dest_dentry, m->mnt.mnt_root)) {
-			mnt_set_mountpoint(m, dest_dentry, child);
+		if (is_subdir(dest_mp->m_dentry, m->mnt.mnt_root)) {
+			mnt_set_mountpoint(m, dest_mp, child);
 			list_add_tail(&child->mnt_hash, tree_list);
 		} else {
 			/*

commit 132c94e31b8bca8ea921f9f96a57d684fa4ae0a9
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Mar 22 04:08:05 2013 -0700

    vfs: Carefully propogate mounts across user namespaces
    
    As a matter of policy MNT_READONLY should not be changable if the
    original mounter had more privileges than creator of the mount
    namespace.
    
    Add the flag CL_UNPRIVILEGED to note when we are copying a mount from
    a mount namespace that requires more privileges to a mount namespace
    that requires fewer privileges.
    
    When the CL_UNPRIVILEGED flag is set cause clone_mnt to set MNT_NO_REMOUNT
    if any of the mnt flags that should never be changed are set.
    
    This protects both mount propagation and the initial creation of a less
    privileged mount namespace.
    
    Cc: stable@vger.kernel.org
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Reported-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/pnode.c b/fs/pnode.c
index 3e000a51ac0d..8b29d2164da6 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -9,6 +9,7 @@
 #include <linux/mnt_namespace.h>
 #include <linux/mount.h>
 #include <linux/fs.h>
+#include <linux/nsproxy.h>
 #include "internal.h"
 #include "pnode.h"
 
@@ -220,6 +221,7 @@ static struct mount *get_source(struct mount *dest,
 int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
 		    struct mount *source_mnt, struct list_head *tree_list)
 {
+	struct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;
 	struct mount *m, *child;
 	int ret = 0;
 	struct mount *prev_dest_mnt = dest_mnt;
@@ -237,6 +239,10 @@ int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
 
 		source =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);
 
+		/* Notice when we are propagating across user namespaces */
+		if (m->mnt_ns->user_ns != user_ns)
+			type |= CL_UNPRIVILEGED;
+
 		child = copy_tree(source, source->mnt.mnt_root, type);
 		if (IS_ERR(child)) {
 			ret = PTR_ERR(child);

commit be34d1a3bc4b6f357a49acb55ae870c81337e4f0
Author: David Howells <dhowells@redhat.com>
Date:   Mon Jun 25 12:55:18 2012 +0100

    VFS: Make clone_mnt()/copy_tree()/collect_mounts() return errors
    
    copy_tree() can theoretically fail in a case other than ENOMEM, but always
    returns NULL which is interpreted by callers as -ENOMEM.  Change it to return
    an explicit error.
    
    Also change clone_mnt() for consistency and because union mounts will add new
    error cases.
    
    Thanks to Andreas Gruenbacher <agruen@suse.de> for a bug fix.
    [AV: folded braino fix by Dan Carpenter]
    
    Original-author: Valerie Aurora <vaurora@redhat.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Cc: Valerie Aurora <valerie.aurora@gmail.com>
    Cc: Andreas Gruenbacher <agruen@suse.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index bed378db0758..3e000a51ac0d 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -237,8 +237,9 @@ int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
 
 		source =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);
 
-		if (!(child = copy_tree(source, source->mnt.mnt_root, type))) {
-			ret = -ENOMEM;
+		child = copy_tree(source, source->mnt.mnt_root, type);
+		if (IS_ERR(child)) {
+			ret = PTR_ERR(child);
 			list_splice(tree_list, tmp_list.prev);
 			goto out;
 		}

commit 962830df366b66e71849040770ae6ba55a8b4aec
Author: Andi Kleen <ak@linux.intel.com>
Date:   Tue May 8 13:32:02 2012 +0930

    brlocks/lglocks: API cleanups
    
    lglocks and brlocks are currently generated with some complicated macros
    in lglock.h.  But there's no reason to not just use common utility
    functions and put all the data into a common data structure.
    
    In preparation, this patch changes the API to look more like normal
    function calls with pointers, not magic macros.
    
    The patch is rather large because I move over all users in one go to keep
    it bisectable.  This impacts the VFS somewhat in terms of lines changed.
    But no actual behaviour change.
    
    [akpm@linux-foundation.org: checkpatch fixes]
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index ab5fa9e1a79a..bed378db0758 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -257,12 +257,12 @@ int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
 		prev_src_mnt  = child;
 	}
 out:
-	br_write_lock(vfsmount_lock);
+	br_write_lock(&vfsmount_lock);
 	while (!list_empty(&tmp_list)) {
 		child = list_first_entry(&tmp_list, struct mount, mnt_hash);
 		umount_tree(child, 0, &umount_list);
 	}
-	br_write_unlock(vfsmount_lock);
+	br_write_unlock(&vfsmount_lock);
 	release_mounts(&umount_list);
 	return ret;
 }

commit fc7be130c7e91cf693d4bc2d9b11f08a5a4893d0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 01:05:37 2011 -0500

    vfs: switch pnode.h macros to struct mount *
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index a40abf20f35e..ab5fa9e1a79a 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -82,7 +82,7 @@ static int do_make_slave(struct mount *mnt)
 		if (peer_mnt == mnt)
 			peer_mnt = NULL;
 	}
-	if (IS_MNT_SHARED(&mnt->mnt) && list_empty(&mnt->mnt_share))
+	if (IS_MNT_SHARED(mnt) && list_empty(&mnt->mnt_share))
 		mnt_release_group_id(mnt);
 
 	list_del_init(&mnt->mnt_share);
@@ -107,7 +107,7 @@ static int do_make_slave(struct mount *mnt)
 		}
 	}
 	mnt->mnt_master = master;
-	CLEAR_MNT_SHARED(&mnt->mnt);
+	CLEAR_MNT_SHARED(mnt);
 	return 0;
 }
 
@@ -199,7 +199,7 @@ static struct mount *get_source(struct mount *dest,
 	/* slave of the earlier, then */
 	*type = CL_SLAVE;
 	/* beginning of peer group among the slaves? */
-	if (IS_MNT_SHARED(&dest->mnt))
+	if (IS_MNT_SHARED(dest))
 		*type |= CL_MAKE_SHARED;
 	return last_src;
 }

commit 863d684f946eb240c7dd57d265d88315950ca5cc
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 00:57:42 2011 -0500

    vfs: move the rest of int fields to struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 001c8b0df379..a40abf20f35e 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -272,7 +272,7 @@ int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
  */
 static inline int do_refcount_check(struct mount *mnt, int count)
 {
-	int mycount = mnt_get_count(mnt) - mnt->mnt.mnt_ghosts;
+	int mycount = mnt_get_count(mnt) - mnt->mnt_ghosts;
 	return (mycount > count);
 }
 

commit 15169fe784a9846b24cdb0840329d41aebc23249
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 00:50:41 2011 -0500

    vfs: mnt_id/mnt_group_id moved
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index cec329822a16..001c8b0df379 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -58,7 +58,7 @@ int get_dominating_id(struct mount *mnt, const struct path *root)
 	for (m = mnt->mnt_master; m != NULL; m = m->mnt_master) {
 		struct mount *d = get_peer_under_root(m, mnt->mnt_ns, root);
 		if (d)
-			return d->mnt.mnt_group_id;
+			return d->mnt_group_id;
 	}
 
 	return 0;
@@ -86,7 +86,7 @@ static int do_make_slave(struct mount *mnt)
 		mnt_release_group_id(mnt);
 
 	list_del_init(&mnt->mnt_share);
-	mnt->mnt.mnt_group_id = 0;
+	mnt->mnt_group_id = 0;
 
 	if (peer_mnt)
 		master = peer_mnt;

commit 143c8c91cee7efdd732ec5f61b3471fc46192f20
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 00:46:35 2011 -0500

    vfs: mnt_ns moved to struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 12cc1518e0cd..cec329822a16 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -36,7 +36,7 @@ static struct mount *get_peer_under_root(struct mount *mnt,
 
 	do {
 		/* Check the namespace first for optimization */
-		if (m->mnt.mnt_ns == ns && is_path_reachable(m, m->mnt.mnt_root, root))
+		if (m->mnt_ns == ns && is_path_reachable(m, m->mnt.mnt_root, root))
 			return m;
 
 		m = next_peer(m);
@@ -56,7 +56,7 @@ int get_dominating_id(struct mount *mnt, const struct path *root)
 	struct mount *m;
 
 	for (m = mnt->mnt_master; m != NULL; m = m->mnt_master) {
-		struct mount *d = get_peer_under_root(m, mnt->mnt.mnt_ns, root);
+		struct mount *d = get_peer_under_root(m, mnt->mnt_ns, root);
 		if (d)
 			return d->mnt.mnt_group_id;
 	}
@@ -145,7 +145,7 @@ static struct mount *propagation_next(struct mount *m,
 					 struct mount *origin)
 {
 	/* are there any slaves of this mount? */
-	if (!IS_MNT_NEW(&m->mnt) && !list_empty(&m->mnt_slave_list))
+	if (!IS_MNT_NEW(m) && !list_empty(&m->mnt_slave_list))
 		return first_slave(m);
 
 	while (1) {
@@ -189,7 +189,7 @@ static struct mount *get_source(struct mount *dest,
 	if (p_last_dest) {
 		do {
 			p_last_dest = next_peer(p_last_dest);
-		} while (IS_MNT_NEW(&p_last_dest->mnt));
+		} while (IS_MNT_NEW(p_last_dest));
 		/* is that a peer of the earlier? */
 		if (dest == p_last_dest) {
 			*type = CL_MAKE_SHARED;
@@ -232,7 +232,7 @@ int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
 		int type;
 		struct mount *source;
 
-		if (IS_MNT_NEW(&m->mnt))
+		if (IS_MNT_NEW(m))
 			continue;
 
 		source =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);

commit 6776db3d32b2a59198ec7ac6d32be0b9fdbd8a68
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 00:22:05 2011 -0500

    vfs: take mnt_share/mnt_slave/mnt_slave_list and mnt_expire to struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 9bf22b61f8fb..12cc1518e0cd 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -15,17 +15,17 @@
 /* return the next shared peer mount of @p */
 static inline struct mount *next_peer(struct mount *p)
 {
-	return list_entry(p->mnt.mnt_share.next, struct mount, mnt.mnt_share);
+	return list_entry(p->mnt_share.next, struct mount, mnt_share);
 }
 
 static inline struct mount *first_slave(struct mount *p)
 {
-	return list_entry(p->mnt.mnt_slave_list.next, struct mount, mnt.mnt_slave);
+	return list_entry(p->mnt_slave_list.next, struct mount, mnt_slave);
 }
 
 static inline struct mount *next_slave(struct mount *p)
 {
-	return list_entry(p->mnt.mnt_slave.next, struct mount, mnt.mnt_slave);
+	return list_entry(p->mnt_slave.next, struct mount, mnt_slave);
 }
 
 static struct mount *get_peer_under_root(struct mount *mnt,
@@ -82,27 +82,27 @@ static int do_make_slave(struct mount *mnt)
 		if (peer_mnt == mnt)
 			peer_mnt = NULL;
 	}
-	if (IS_MNT_SHARED(&mnt->mnt) && list_empty(&mnt->mnt.mnt_share))
+	if (IS_MNT_SHARED(&mnt->mnt) && list_empty(&mnt->mnt_share))
 		mnt_release_group_id(mnt);
 
-	list_del_init(&mnt->mnt.mnt_share);
+	list_del_init(&mnt->mnt_share);
 	mnt->mnt.mnt_group_id = 0;
 
 	if (peer_mnt)
 		master = peer_mnt;
 
 	if (master) {
-		list_for_each_entry(slave_mnt, &mnt->mnt.mnt_slave_list, mnt.mnt_slave)
+		list_for_each_entry(slave_mnt, &mnt->mnt_slave_list, mnt_slave)
 			slave_mnt->mnt_master = master;
-		list_move(&mnt->mnt.mnt_slave, &master->mnt.mnt_slave_list);
-		list_splice(&mnt->mnt.mnt_slave_list, master->mnt.mnt_slave_list.prev);
-		INIT_LIST_HEAD(&mnt->mnt.mnt_slave_list);
+		list_move(&mnt->mnt_slave, &master->mnt_slave_list);
+		list_splice(&mnt->mnt_slave_list, master->mnt_slave_list.prev);
+		INIT_LIST_HEAD(&mnt->mnt_slave_list);
 	} else {
-		struct list_head *p = &mnt->mnt.mnt_slave_list;
+		struct list_head *p = &mnt->mnt_slave_list;
 		while (!list_empty(p)) {
                         slave_mnt = list_first_entry(p,
-					struct mount, mnt.mnt_slave);
-			list_del_init(&slave_mnt->mnt.mnt_slave);
+					struct mount, mnt_slave);
+			list_del_init(&slave_mnt->mnt_slave);
 			slave_mnt->mnt_master = NULL;
 		}
 	}
@@ -122,7 +122,7 @@ void change_mnt_propagation(struct mount *mnt, int type)
 	}
 	do_make_slave(mnt);
 	if (type != MS_SLAVE) {
-		list_del_init(&mnt->mnt.mnt_slave);
+		list_del_init(&mnt->mnt_slave);
 		mnt->mnt_master = NULL;
 		if (type == MS_UNBINDABLE)
 			mnt->mnt.mnt_flags |= MNT_UNBINDABLE;
@@ -145,7 +145,7 @@ static struct mount *propagation_next(struct mount *m,
 					 struct mount *origin)
 {
 	/* are there any slaves of this mount? */
-	if (!IS_MNT_NEW(&m->mnt) && !list_empty(&m->mnt.mnt_slave_list))
+	if (!IS_MNT_NEW(&m->mnt) && !list_empty(&m->mnt_slave_list))
 		return first_slave(m);
 
 	while (1) {
@@ -154,7 +154,7 @@ static struct mount *propagation_next(struct mount *m,
 		if (master == origin->mnt_master) {
 			struct mount *next = next_peer(m);
 			return (next == origin) ? NULL : next;
-		} else if (m->mnt.mnt_slave.next != &master->mnt.mnt_slave_list)
+		} else if (m->mnt_slave.next != &master->mnt_slave_list)
 			return next_slave(m);
 
 		/* back at master */

commit 32301920f44a9334f57dd94bebfc6e593b99ad47
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 00:10:28 2011 -0500

    vfs: and now we can make ->mnt_master point to struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 3ac44d15fe58..9bf22b61f8fb 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -55,7 +55,7 @@ int get_dominating_id(struct mount *mnt, const struct path *root)
 {
 	struct mount *m;
 
-	for (m = real_mount(mnt->mnt_master); m != NULL; m = real_mount(m->mnt_master)) {
+	for (m = mnt->mnt_master; m != NULL; m = m->mnt_master) {
 		struct mount *d = get_peer_under_root(m, mnt->mnt.mnt_ns, root);
 		if (d)
 			return d->mnt.mnt_group_id;
@@ -66,7 +66,7 @@ int get_dominating_id(struct mount *mnt, const struct path *root)
 
 static int do_make_slave(struct mount *mnt)
 {
-	struct mount *peer_mnt = mnt, *master = real_mount(mnt->mnt_master);
+	struct mount *peer_mnt = mnt, *master = mnt->mnt_master;
 	struct mount *slave_mnt;
 
 	/*
@@ -93,7 +93,7 @@ static int do_make_slave(struct mount *mnt)
 
 	if (master) {
 		list_for_each_entry(slave_mnt, &mnt->mnt.mnt_slave_list, mnt.mnt_slave)
-			slave_mnt->mnt_master = &master->mnt;
+			slave_mnt->mnt_master = master;
 		list_move(&mnt->mnt.mnt_slave, &master->mnt.mnt_slave_list);
 		list_splice(&mnt->mnt.mnt_slave_list, master->mnt.mnt_slave_list.prev);
 		INIT_LIST_HEAD(&mnt->mnt.mnt_slave_list);
@@ -106,7 +106,7 @@ static int do_make_slave(struct mount *mnt)
 			slave_mnt->mnt_master = NULL;
 		}
 	}
-	mnt->mnt_master = &master->mnt;
+	mnt->mnt_master = master;
 	CLEAR_MNT_SHARED(&mnt->mnt);
 	return 0;
 }
@@ -149,9 +149,9 @@ static struct mount *propagation_next(struct mount *m,
 		return first_slave(m);
 
 	while (1) {
-		struct mount *master = real_mount(m->mnt_master);
+		struct mount *master = m->mnt_master;
 
-		if (&master->mnt == origin->mnt_master) {
+		if (master == origin->mnt_master) {
 			struct mount *next = next_peer(m);
 			return (next == origin) ? NULL : next;
 		} else if (m->mnt.mnt_slave.next != &master->mnt.mnt_slave_list)
@@ -179,11 +179,11 @@ static struct mount *get_source(struct mount *dest,
 	struct mount *p_last_src = NULL;
 	struct mount *p_last_dest = NULL;
 
-	while (&last_dest->mnt != dest->mnt_master) {
+	while (last_dest != dest->mnt_master) {
 		p_last_dest = last_dest;
 		p_last_src = last_src;
-		last_dest = real_mount(last_dest->mnt_master);
-		last_src = real_mount(last_src->mnt_master);
+		last_dest = last_dest->mnt_master;
+		last_src = last_src->mnt_master;
 	}
 
 	if (p_last_dest) {

commit d10e8def07fc87488c396d2eff2c26c43bb541dd
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 00:07:16 2011 -0500

    vfs: take mnt_master to struct mount
    
    make IS_MNT_SLAVE take struct mount * at the same time
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 0e1de28b1b2e..3ac44d15fe58 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -55,7 +55,7 @@ int get_dominating_id(struct mount *mnt, const struct path *root)
 {
 	struct mount *m;
 
-	for (m = real_mount(mnt->mnt.mnt_master); m != NULL; m = real_mount(m->mnt.mnt_master)) {
+	for (m = real_mount(mnt->mnt_master); m != NULL; m = real_mount(m->mnt_master)) {
 		struct mount *d = get_peer_under_root(m, mnt->mnt.mnt_ns, root);
 		if (d)
 			return d->mnt.mnt_group_id;
@@ -66,8 +66,8 @@ int get_dominating_id(struct mount *mnt, const struct path *root)
 
 static int do_make_slave(struct mount *mnt)
 {
-	struct mount *peer_mnt = mnt, *master = real_mount(mnt->mnt.mnt_master);
-	struct vfsmount *slave_mnt;
+	struct mount *peer_mnt = mnt, *master = real_mount(mnt->mnt_master);
+	struct mount *slave_mnt;
 
 	/*
 	 * slave 'mnt' to a peer mount that has the
@@ -92,7 +92,7 @@ static int do_make_slave(struct mount *mnt)
 		master = peer_mnt;
 
 	if (master) {
-		list_for_each_entry(slave_mnt, &mnt->mnt.mnt_slave_list, mnt_slave)
+		list_for_each_entry(slave_mnt, &mnt->mnt.mnt_slave_list, mnt.mnt_slave)
 			slave_mnt->mnt_master = &master->mnt;
 		list_move(&mnt->mnt.mnt_slave, &master->mnt.mnt_slave_list);
 		list_splice(&mnt->mnt.mnt_slave_list, master->mnt.mnt_slave_list.prev);
@@ -101,12 +101,12 @@ static int do_make_slave(struct mount *mnt)
 		struct list_head *p = &mnt->mnt.mnt_slave_list;
 		while (!list_empty(p)) {
                         slave_mnt = list_first_entry(p,
-					struct vfsmount, mnt_slave);
-			list_del_init(&slave_mnt->mnt_slave);
+					struct mount, mnt.mnt_slave);
+			list_del_init(&slave_mnt->mnt.mnt_slave);
 			slave_mnt->mnt_master = NULL;
 		}
 	}
-	mnt->mnt.mnt_master = &master->mnt;
+	mnt->mnt_master = &master->mnt;
 	CLEAR_MNT_SHARED(&mnt->mnt);
 	return 0;
 }
@@ -123,7 +123,7 @@ void change_mnt_propagation(struct mount *mnt, int type)
 	do_make_slave(mnt);
 	if (type != MS_SLAVE) {
 		list_del_init(&mnt->mnt.mnt_slave);
-		mnt->mnt.mnt_master = NULL;
+		mnt->mnt_master = NULL;
 		if (type == MS_UNBINDABLE)
 			mnt->mnt.mnt_flags |= MNT_UNBINDABLE;
 		else
@@ -149,9 +149,9 @@ static struct mount *propagation_next(struct mount *m,
 		return first_slave(m);
 
 	while (1) {
-		struct mount *master = real_mount(m->mnt.mnt_master);
+		struct mount *master = real_mount(m->mnt_master);
 
-		if (&master->mnt == origin->mnt.mnt_master) {
+		if (&master->mnt == origin->mnt_master) {
 			struct mount *next = next_peer(m);
 			return (next == origin) ? NULL : next;
 		} else if (m->mnt.mnt_slave.next != &master->mnt.mnt_slave_list)
@@ -179,11 +179,11 @@ static struct mount *get_source(struct mount *dest,
 	struct mount *p_last_src = NULL;
 	struct mount *p_last_dest = NULL;
 
-	while (&last_dest->mnt != dest->mnt.mnt_master) {
+	while (&last_dest->mnt != dest->mnt_master) {
 		p_last_dest = last_dest;
 		p_last_src = last_src;
-		last_dest = real_mount(last_dest->mnt.mnt_master);
-		last_src = real_mount(last_src->mnt.mnt_master);
+		last_dest = real_mount(last_dest->mnt_master);
+		last_src = real_mount(last_src->mnt_master);
 	}
 
 	if (p_last_dest) {

commit 14cf1fa8f54353d9caf6174c1e4280c8c4dcfd7a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Nov 25 00:01:17 2011 -0500

    vfs: spread struct mount - remaining argument of mnt_set_mountpoint()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 6519b3b4eb15..0e1de28b1b2e 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -244,7 +244,7 @@ int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
 		}
 
 		if (is_subdir(dest_dentry, m->mnt.mnt_root)) {
-			mnt_set_mountpoint(&m->mnt, dest_dentry, child);
+			mnt_set_mountpoint(m, dest_dentry, child);
 			list_add_tail(&child->mnt_hash, tree_list);
 		} else {
 			/*

commit a8d56d8e4fa0cb9a023834363f8d79415d277a1d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 23:59:29 2011 -0500

    vfs: spread struct mount - propagate_mnt()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index f86cd4bc31ce..6519b3b4eb15 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -217,18 +217,18 @@ static struct mount *get_source(struct mount *dest,
  * @source_mnt: source mount.
  * @tree_list : list of heads of trees to be attached.
  */
-int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
-		    struct vfsmount *source_mnt, struct list_head *tree_list)
+int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,
+		    struct mount *source_mnt, struct list_head *tree_list)
 {
 	struct mount *m, *child;
 	int ret = 0;
-	struct mount *prev_dest_mnt = real_mount(dest_mnt);
-	struct mount *prev_src_mnt  = real_mount(source_mnt);
+	struct mount *prev_dest_mnt = dest_mnt;
+	struct mount *prev_src_mnt  = source_mnt;
 	LIST_HEAD(tmp_list);
 	LIST_HEAD(umount_list);
 
-	for (m = propagation_next(real_mount(dest_mnt), real_mount(dest_mnt)); m;
-			m = propagation_next(m, real_mount(dest_mnt))) {
+	for (m = propagation_next(dest_mnt, dest_mnt); m;
+			m = propagation_next(m, dest_mnt)) {
 		int type;
 		struct mount *source;
 

commit c937135d98f2306157fb8d8a03a4d8b0f1e3b511
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 23:56:26 2011 -0500

    vfs: spread struct mount - shared subtree iterators
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 29e366dec024..f86cd4bc31ce 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -13,19 +13,19 @@
 #include "pnode.h"
 
 /* return the next shared peer mount of @p */
-static inline struct vfsmount *next_peer(struct vfsmount *p)
+static inline struct mount *next_peer(struct mount *p)
 {
-	return list_entry(p->mnt_share.next, struct vfsmount, mnt_share);
+	return list_entry(p->mnt.mnt_share.next, struct mount, mnt.mnt_share);
 }
 
-static inline struct vfsmount *first_slave(struct vfsmount *p)
+static inline struct mount *first_slave(struct mount *p)
 {
-	return list_entry(p->mnt_slave_list.next, struct vfsmount, mnt_slave);
+	return list_entry(p->mnt.mnt_slave_list.next, struct mount, mnt.mnt_slave);
 }
 
-static inline struct vfsmount *next_slave(struct vfsmount *p)
+static inline struct mount *next_slave(struct mount *p)
 {
-	return list_entry(p->mnt_slave.next, struct vfsmount, mnt_slave);
+	return list_entry(p->mnt.mnt_slave.next, struct mount, mnt.mnt_slave);
 }
 
 static struct mount *get_peer_under_root(struct mount *mnt,
@@ -39,7 +39,7 @@ static struct mount *get_peer_under_root(struct mount *mnt,
 		if (m->mnt.mnt_ns == ns && is_path_reachable(m, m->mnt.mnt_root, root))
 			return m;
 
-		m = real_mount(next_peer(&m->mnt));
+		m = next_peer(m);
 	} while (m != mnt);
 
 	return NULL;
@@ -74,11 +74,11 @@ static int do_make_slave(struct mount *mnt)
 	 * same root dentry. If none is available then
 	 * slave it to anything that is available.
 	 */
-	while ((peer_mnt = real_mount(next_peer(&peer_mnt->mnt))) != mnt &&
+	while ((peer_mnt = next_peer(peer_mnt)) != mnt &&
 	       peer_mnt->mnt.mnt_root != mnt->mnt.mnt_root) ;
 
 	if (peer_mnt == mnt) {
-		peer_mnt = real_mount(next_peer(&mnt->mnt));
+		peer_mnt = next_peer(mnt);
 		if (peer_mnt == mnt)
 			peer_mnt = NULL;
 	}
@@ -141,21 +141,20 @@ void change_mnt_propagation(struct mount *mnt, int type)
  * vfsmount found while iterating with propagation_next() is
  * a peer of one we'd found earlier.
  */
-static struct vfsmount *propagation_next(struct vfsmount *m,
-					 struct vfsmount *origin)
+static struct mount *propagation_next(struct mount *m,
+					 struct mount *origin)
 {
 	/* are there any slaves of this mount? */
-	if (!IS_MNT_NEW(m) && !list_empty(&m->mnt_slave_list))
+	if (!IS_MNT_NEW(&m->mnt) && !list_empty(&m->mnt.mnt_slave_list))
 		return first_slave(m);
 
 	while (1) {
-		struct vfsmount *next;
-		struct vfsmount *master = m->mnt_master;
+		struct mount *master = real_mount(m->mnt.mnt_master);
 
-		if (master == origin->mnt_master) {
-			next = next_peer(m);
-			return ((next == origin) ? NULL : next);
-		} else if (m->mnt_slave.next != &master->mnt_slave_list)
+		if (&master->mnt == origin->mnt.mnt_master) {
+			struct mount *next = next_peer(m);
+			return (next == origin) ? NULL : next;
+		} else if (m->mnt.mnt_slave.next != &master->mnt.mnt_slave_list)
 			return next_slave(m);
 
 		/* back at master */
@@ -172,25 +171,25 @@ static struct vfsmount *propagation_next(struct vfsmount *m,
  * @type	return CL_SLAVE if the new mount has to be
  * 		cloned as a slave.
  */
-static struct vfsmount *get_source(struct vfsmount *dest,
-					struct vfsmount *last_dest,
-					struct vfsmount *last_src,
-					int *type)
+static struct mount *get_source(struct mount *dest,
+				struct mount *last_dest,
+				struct mount *last_src,
+				int *type)
 {
-	struct vfsmount *p_last_src = NULL;
-	struct vfsmount *p_last_dest = NULL;
+	struct mount *p_last_src = NULL;
+	struct mount *p_last_dest = NULL;
 
-	while (last_dest != dest->mnt_master) {
+	while (&last_dest->mnt != dest->mnt.mnt_master) {
 		p_last_dest = last_dest;
 		p_last_src = last_src;
-		last_dest = last_dest->mnt_master;
-		last_src = last_src->mnt_master;
+		last_dest = real_mount(last_dest->mnt.mnt_master);
+		last_src = real_mount(last_src->mnt.mnt_master);
 	}
 
 	if (p_last_dest) {
 		do {
 			p_last_dest = next_peer(p_last_dest);
-		} while (IS_MNT_NEW(p_last_dest));
+		} while (IS_MNT_NEW(&p_last_dest->mnt));
 		/* is that a peer of the earlier? */
 		if (dest == p_last_dest) {
 			*type = CL_MAKE_SHARED;
@@ -200,7 +199,7 @@ static struct vfsmount *get_source(struct vfsmount *dest,
 	/* slave of the earlier, then */
 	*type = CL_SLAVE;
 	/* beginning of peer group among the slaves? */
-	if (IS_MNT_SHARED(dest))
+	if (IS_MNT_SHARED(&dest->mnt))
 		*type |= CL_MAKE_SHARED;
 	return last_src;
 }
@@ -221,32 +220,31 @@ static struct vfsmount *get_source(struct vfsmount *dest,
 int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 		    struct vfsmount *source_mnt, struct list_head *tree_list)
 {
-	struct vfsmount *m;
-	struct mount *child;
+	struct mount *m, *child;
 	int ret = 0;
-	struct vfsmount *prev_dest_mnt = dest_mnt;
-	struct vfsmount *prev_src_mnt  = source_mnt;
+	struct mount *prev_dest_mnt = real_mount(dest_mnt);
+	struct mount *prev_src_mnt  = real_mount(source_mnt);
 	LIST_HEAD(tmp_list);
 	LIST_HEAD(umount_list);
 
-	for (m = propagation_next(dest_mnt, dest_mnt); m;
-			m = propagation_next(m, dest_mnt)) {
+	for (m = propagation_next(real_mount(dest_mnt), real_mount(dest_mnt)); m;
+			m = propagation_next(m, real_mount(dest_mnt))) {
 		int type;
-		struct vfsmount *source;
+		struct mount *source;
 
-		if (IS_MNT_NEW(m))
+		if (IS_MNT_NEW(&m->mnt))
 			continue;
 
 		source =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);
 
-		if (!(child = copy_tree(real_mount(source), source->mnt_root, type))) {
+		if (!(child = copy_tree(source, source->mnt.mnt_root, type))) {
 			ret = -ENOMEM;
 			list_splice(tree_list, tmp_list.prev);
 			goto out;
 		}
 
-		if (is_subdir(dest_dentry, m->mnt_root)) {
-			mnt_set_mountpoint(m, dest_dentry, child);
+		if (is_subdir(dest_dentry, m->mnt.mnt_root)) {
+			mnt_set_mountpoint(&m->mnt, dest_dentry, child);
 			list_add_tail(&child->mnt_hash, tree_list);
 		} else {
 			/*
@@ -256,7 +254,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 			list_add_tail(&child->mnt_hash, &tmp_list);
 		}
 		prev_dest_mnt = m;
-		prev_src_mnt  = &child->mnt;
+		prev_src_mnt  = child;
 	}
 out:
 	br_write_lock(vfsmount_lock);
@@ -290,8 +288,7 @@ static inline int do_refcount_check(struct mount *mnt, int count)
  */
 int propagate_mount_busy(struct mount *mnt, int refcnt)
 {
-	struct vfsmount *m;
-	struct mount *child;
+	struct mount *m, *child;
 	struct mount *parent = mnt->mnt_parent;
 	int ret = 0;
 
@@ -306,9 +303,9 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 	if (!list_empty(&mnt->mnt_mounts) || do_refcount_check(mnt, refcnt))
 		return 1;
 
-	for (m = propagation_next(&parent->mnt, &parent->mnt); m;
-	     		m = propagation_next(m, &parent->mnt)) {
-		child = __lookup_mnt(m, mnt->mnt_mountpoint, 0);
+	for (m = propagation_next(parent, parent); m;
+	     		m = propagation_next(m, parent)) {
+		child = __lookup_mnt(&m->mnt, mnt->mnt_mountpoint, 0);
 		if (child && list_empty(&child->mnt_mounts) &&
 		    (ret = do_refcount_check(child, 1)))
 			break;
@@ -323,14 +320,14 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 static void __propagate_umount(struct mount *mnt)
 {
 	struct mount *parent = mnt->mnt_parent;
-	struct vfsmount *m;
+	struct mount *m;
 
 	BUG_ON(parent == mnt);
 
-	for (m = propagation_next(&parent->mnt, &parent->mnt); m;
-			m = propagation_next(m, &parent->mnt)) {
+	for (m = propagation_next(parent, parent); m;
+			m = propagation_next(m, parent)) {
 
-		struct mount *child = __lookup_mnt(m,
+		struct mount *child = __lookup_mnt(&m->mnt,
 					mnt->mnt_mountpoint, 0);
 		/*
 		 * umount the child only if the child has no

commit 6fc7871fed915914ef441efbe0f9a7c3d0f3bff1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 23:35:54 2011 -0500

    vfs: spread struct mount - get_dominating_id / do_make_slave
    
    next pile of horrors, similar to mnt_parent one; this time it's
    mnt_master.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 8cd90d2ec05e..29e366dec024 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -28,19 +28,19 @@ static inline struct vfsmount *next_slave(struct vfsmount *p)
 	return list_entry(p->mnt_slave.next, struct vfsmount, mnt_slave);
 }
 
-static struct vfsmount *get_peer_under_root(struct vfsmount *mnt,
-					    struct mnt_namespace *ns,
-					    const struct path *root)
+static struct mount *get_peer_under_root(struct mount *mnt,
+					 struct mnt_namespace *ns,
+					 const struct path *root)
 {
-	struct mount *m = real_mount(mnt);
+	struct mount *m = mnt;
 
 	do {
 		/* Check the namespace first for optimization */
 		if (m->mnt.mnt_ns == ns && is_path_reachable(m, m->mnt.mnt_root, root))
-			return &m->mnt;
+			return m;
 
 		m = real_mount(next_peer(&m->mnt));
-	} while (&m->mnt != mnt);
+	} while (m != mnt);
 
 	return NULL;
 }
@@ -51,22 +51,22 @@ static struct vfsmount *get_peer_under_root(struct vfsmount *mnt,
  *
  * Caller must hold namespace_sem
  */
-int get_dominating_id(struct vfsmount *mnt, const struct path *root)
+int get_dominating_id(struct mount *mnt, const struct path *root)
 {
-	struct vfsmount *m;
+	struct mount *m;
 
-	for (m = mnt->mnt_master; m != NULL; m = m->mnt_master) {
-		struct vfsmount *d = get_peer_under_root(m, mnt->mnt_ns, root);
+	for (m = real_mount(mnt->mnt.mnt_master); m != NULL; m = real_mount(m->mnt.mnt_master)) {
+		struct mount *d = get_peer_under_root(m, mnt->mnt.mnt_ns, root);
 		if (d)
-			return d->mnt_group_id;
+			return d->mnt.mnt_group_id;
 	}
 
 	return 0;
 }
 
-static int do_make_slave(struct vfsmount *mnt)
+static int do_make_slave(struct mount *mnt)
 {
-	struct vfsmount *peer_mnt = mnt, *master = mnt->mnt_master;
+	struct mount *peer_mnt = mnt, *master = real_mount(mnt->mnt.mnt_master);
 	struct vfsmount *slave_mnt;
 
 	/*
@@ -74,31 +74,31 @@ static int do_make_slave(struct vfsmount *mnt)
 	 * same root dentry. If none is available then
 	 * slave it to anything that is available.
 	 */
-	while ((peer_mnt = next_peer(peer_mnt)) != mnt &&
-	       peer_mnt->mnt_root != mnt->mnt_root) ;
+	while ((peer_mnt = real_mount(next_peer(&peer_mnt->mnt))) != mnt &&
+	       peer_mnt->mnt.mnt_root != mnt->mnt.mnt_root) ;
 
 	if (peer_mnt == mnt) {
-		peer_mnt = next_peer(mnt);
+		peer_mnt = real_mount(next_peer(&mnt->mnt));
 		if (peer_mnt == mnt)
 			peer_mnt = NULL;
 	}
-	if (IS_MNT_SHARED(mnt) && list_empty(&mnt->mnt_share))
-		mnt_release_group_id(real_mount(mnt));
+	if (IS_MNT_SHARED(&mnt->mnt) && list_empty(&mnt->mnt.mnt_share))
+		mnt_release_group_id(mnt);
 
-	list_del_init(&mnt->mnt_share);
-	mnt->mnt_group_id = 0;
+	list_del_init(&mnt->mnt.mnt_share);
+	mnt->mnt.mnt_group_id = 0;
 
 	if (peer_mnt)
 		master = peer_mnt;
 
 	if (master) {
-		list_for_each_entry(slave_mnt, &mnt->mnt_slave_list, mnt_slave)
-			slave_mnt->mnt_master = master;
-		list_move(&mnt->mnt_slave, &master->mnt_slave_list);
-		list_splice(&mnt->mnt_slave_list, master->mnt_slave_list.prev);
-		INIT_LIST_HEAD(&mnt->mnt_slave_list);
+		list_for_each_entry(slave_mnt, &mnt->mnt.mnt_slave_list, mnt_slave)
+			slave_mnt->mnt_master = &master->mnt;
+		list_move(&mnt->mnt.mnt_slave, &master->mnt.mnt_slave_list);
+		list_splice(&mnt->mnt.mnt_slave_list, master->mnt.mnt_slave_list.prev);
+		INIT_LIST_HEAD(&mnt->mnt.mnt_slave_list);
 	} else {
-		struct list_head *p = &mnt->mnt_slave_list;
+		struct list_head *p = &mnt->mnt.mnt_slave_list;
 		while (!list_empty(p)) {
                         slave_mnt = list_first_entry(p,
 					struct vfsmount, mnt_slave);
@@ -106,8 +106,8 @@ static int do_make_slave(struct vfsmount *mnt)
 			slave_mnt->mnt_master = NULL;
 		}
 	}
-	mnt->mnt_master = master;
-	CLEAR_MNT_SHARED(mnt);
+	mnt->mnt.mnt_master = &master->mnt;
+	CLEAR_MNT_SHARED(&mnt->mnt);
 	return 0;
 }
 
@@ -120,7 +120,7 @@ void change_mnt_propagation(struct mount *mnt, int type)
 		set_mnt_shared(mnt);
 		return;
 	}
-	do_make_slave(&mnt->mnt);
+	do_make_slave(mnt);
 	if (type != MS_SLAVE) {
 		list_del_init(&mnt->mnt.mnt_slave);
 		mnt->mnt.mnt_master = NULL;

commit 6b41d536f7c84e7cb1c1462073150277e46f6ea8
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 23:24:33 2011 -0500

    vfs: take mnt_child/mnt_mounts to struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 50fdb29eebfe..8cd90d2ec05e 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -303,13 +303,13 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 	 * If not, we don't have to go checking for all other
 	 * mounts
 	 */
-	if (!list_empty(&mnt->mnt.mnt_mounts) || do_refcount_check(mnt, refcnt))
+	if (!list_empty(&mnt->mnt_mounts) || do_refcount_check(mnt, refcnt))
 		return 1;
 
 	for (m = propagation_next(&parent->mnt, &parent->mnt); m;
 	     		m = propagation_next(m, &parent->mnt)) {
 		child = __lookup_mnt(m, mnt->mnt_mountpoint, 0);
-		if (child && list_empty(&child->mnt.mnt_mounts) &&
+		if (child && list_empty(&child->mnt_mounts) &&
 		    (ret = do_refcount_check(child, 1)))
 			break;
 	}
@@ -336,7 +336,7 @@ static void __propagate_umount(struct mount *mnt)
 		 * umount the child only if the child has no
 		 * other children
 		 */
-		if (child && list_empty(&child->mnt.mnt_mounts))
+		if (child && list_empty(&child->mnt_mounts))
 			list_move_tail(&child->mnt_hash, &mnt->mnt_hash);
 	}
 }

commit 83adc7532229f1909cf37c429780f02f06fe05ee
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 22:37:54 2011 -0500

    vfs: spread struct mount - work with counters
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index bd280200bd37..50fdb29eebfe 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -274,7 +274,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
  */
 static inline int do_refcount_check(struct mount *mnt, int count)
 {
-	int mycount = mnt_get_count(&mnt->mnt) - mnt->mnt.mnt_ghosts;
+	int mycount = mnt_get_count(mnt) - mnt->mnt.mnt_ghosts;
 	return (mycount > count);
 }
 

commit a73324da7af4052e1d1ddec6a5980f552420e58b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 22:25:07 2011 -0500

    vfs: move mnt_mountpoint to struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 7fddc671f729..bd280200bd37 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -308,7 +308,7 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 
 	for (m = propagation_next(&parent->mnt, &parent->mnt); m;
 	     		m = propagation_next(m, &parent->mnt)) {
-		child = __lookup_mnt(m, mnt->mnt.mnt_mountpoint, 0);
+		child = __lookup_mnt(m, mnt->mnt_mountpoint, 0);
 		if (child && list_empty(&child->mnt.mnt_mounts) &&
 		    (ret = do_refcount_check(child, 1)))
 			break;
@@ -331,7 +331,7 @@ static void __propagate_umount(struct mount *mnt)
 			m = propagation_next(m, &parent->mnt)) {
 
 		struct mount *child = __lookup_mnt(m,
-					mnt->mnt.mnt_mountpoint, 0);
+					mnt->mnt_mountpoint, 0);
 		/*
 		 * umount the child only if the child has no
 		 * other children

commit 0714a533805a0f8ebfc6fdb6bda9f129b8c7c6d7
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 22:19:58 2011 -0500

    vfs: now it can be done - make mnt_parent point to struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 2ff4dfa018e1..7fddc671f729 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -292,10 +292,10 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 {
 	struct vfsmount *m;
 	struct mount *child;
-	struct vfsmount *parent = mnt->mnt_parent;
+	struct mount *parent = mnt->mnt_parent;
 	int ret = 0;
 
-	if (&mnt->mnt == parent)
+	if (mnt == parent)
 		return do_refcount_check(mnt, refcnt);
 
 	/*
@@ -306,8 +306,8 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 	if (!list_empty(&mnt->mnt.mnt_mounts) || do_refcount_check(mnt, refcnt))
 		return 1;
 
-	for (m = propagation_next(parent, parent); m;
-	     		m = propagation_next(m, parent)) {
+	for (m = propagation_next(&parent->mnt, &parent->mnt); m;
+	     		m = propagation_next(m, &parent->mnt)) {
 		child = __lookup_mnt(m, mnt->mnt.mnt_mountpoint, 0);
 		if (child && list_empty(&child->mnt.mnt_mounts) &&
 		    (ret = do_refcount_check(child, 1)))
@@ -322,13 +322,13 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
  */
 static void __propagate_umount(struct mount *mnt)
 {
-	struct vfsmount *parent = mnt->mnt_parent;
+	struct mount *parent = mnt->mnt_parent;
 	struct vfsmount *m;
 
-	BUG_ON(parent == &mnt->mnt);
+	BUG_ON(parent == mnt);
 
-	for (m = propagation_next(parent, parent); m;
-			m = propagation_next(m, parent)) {
+	for (m = propagation_next(&parent->mnt, &parent->mnt); m;
+			m = propagation_next(m, &parent->mnt)) {
 
 		struct mount *child = __lookup_mnt(m,
 					mnt->mnt.mnt_mountpoint, 0);

commit 3376f34fff5be9954fd9a9c4fd68f4a0a36d480e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 22:05:19 2011 -0500

    vfs: mnt_parent moved to struct mount
    
    the second victim...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 25f74b53dea6..2ff4dfa018e1 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -292,7 +292,7 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
 {
 	struct vfsmount *m;
 	struct mount *child;
-	struct vfsmount *parent = mnt->mnt.mnt_parent;
+	struct vfsmount *parent = mnt->mnt_parent;
 	int ret = 0;
 
 	if (&mnt->mnt == parent)
@@ -322,7 +322,7 @@ int propagate_mount_busy(struct mount *mnt, int refcnt)
  */
 static void __propagate_umount(struct mount *mnt)
 {
-	struct vfsmount *parent = mnt->mnt.mnt_parent;
+	struct vfsmount *parent = mnt->mnt_parent;
 	struct vfsmount *m;
 
 	BUG_ON(parent == &mnt->mnt);

commit 643822b41e5e0f133438883b0be574cdaf168a2a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 22:00:28 2011 -0500

    vfs: spread struct mount - is_path_reachable
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 3105cca197ec..25f74b53dea6 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -32,15 +32,15 @@ static struct vfsmount *get_peer_under_root(struct vfsmount *mnt,
 					    struct mnt_namespace *ns,
 					    const struct path *root)
 {
-	struct vfsmount *m = mnt;
+	struct mount *m = real_mount(mnt);
 
 	do {
 		/* Check the namespace first for optimization */
-		if (m->mnt_ns == ns && is_path_reachable(m, m->mnt_root, root))
-			return m;
+		if (m->mnt.mnt_ns == ns && is_path_reachable(m, m->mnt.mnt_root, root))
+			return &m->mnt;
 
-		m = next_peer(m);
-	} while (m != mnt);
+		m = real_mount(next_peer(&m->mnt));
+	} while (&m->mnt != mnt);
 
 	return NULL;
 }

commit 1ab597386205f8dc757cf8750465502aeae65154
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 21:35:16 2011 -0500

    vfs: spread struct mount - do_umount/propagate_mount_busy
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 89ea50dc2af3..3105cca197ec 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -272,9 +272,9 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 /*
  * return true if the refcount is greater than count
  */
-static inline int do_refcount_check(struct vfsmount *mnt, int count)
+static inline int do_refcount_check(struct mount *mnt, int count)
 {
-	int mycount = mnt_get_count(mnt) - mnt->mnt_ghosts;
+	int mycount = mnt_get_count(&mnt->mnt) - mnt->mnt.mnt_ghosts;
 	return (mycount > count);
 }
 
@@ -288,14 +288,14 @@ static inline int do_refcount_check(struct vfsmount *mnt, int count)
  *
  * vfsmount lock must be held for write
  */
-int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
+int propagate_mount_busy(struct mount *mnt, int refcnt)
 {
 	struct vfsmount *m;
 	struct mount *child;
-	struct vfsmount *parent = mnt->mnt_parent;
+	struct vfsmount *parent = mnt->mnt.mnt_parent;
 	int ret = 0;
 
-	if (mnt == parent)
+	if (&mnt->mnt == parent)
 		return do_refcount_check(mnt, refcnt);
 
 	/*
@@ -303,14 +303,14 @@ int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
 	 * If not, we don't have to go checking for all other
 	 * mounts
 	 */
-	if (!list_empty(&mnt->mnt_mounts) || do_refcount_check(mnt, refcnt))
+	if (!list_empty(&mnt->mnt.mnt_mounts) || do_refcount_check(mnt, refcnt))
 		return 1;
 
 	for (m = propagation_next(parent, parent); m;
 	     		m = propagation_next(m, parent)) {
-		child = __lookup_mnt(m, mnt->mnt_mountpoint, 0);
+		child = __lookup_mnt(m, mnt->mnt.mnt_mountpoint, 0);
 		if (child && list_empty(&child->mnt.mnt_mounts) &&
-		    (ret = do_refcount_check(&child->mnt, 1)))
+		    (ret = do_refcount_check(child, 1)))
 			break;
 	}
 	return ret;

commit 44d964d609c7c11b330a3d1caf30767fa13c7be3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 21:28:22 2011 -0500

    vfs: spread struct mount mnt_set_mountpoint child argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 5d79f38e3e8a..89ea50dc2af3 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -246,7 +246,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 		}
 
 		if (is_subdir(dest_dentry, m->mnt_root)) {
-			mnt_set_mountpoint(m, dest_dentry, &child->mnt);
+			mnt_set_mountpoint(m, dest_dentry, child);
 			list_add_tail(&child->mnt_hash, tree_list);
 		} else {
 			/*

commit 87129cc0e3fcd89a1db3e99d62dc710e05749f77
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 21:24:27 2011 -0500

    vfs: spread struct mount - clone_mnt/copy_tree argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index efbe0c0d3f0d..5d79f38e3e8a 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -239,7 +239,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 
 		source =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);
 
-		if (!(child = copy_tree(source, source->mnt_root, type))) {
+		if (!(child = copy_tree(real_mount(source), source->mnt_root, type))) {
 			ret = -ENOMEM;
 			list_splice(tree_list, tmp_list.prev);
 			goto out;

commit 761d5c38eb3d8e2aa7394726dccab245bfe2f41c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 21:07:43 2011 -0500

    vfs: spread struct mount - umount_tree argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index a2f0f3e0e127..efbe0c0d3f0d 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -262,7 +262,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 	br_write_lock(vfsmount_lock);
 	while (!list_empty(&tmp_list)) {
 		child = list_first_entry(&tmp_list, struct mount, mnt_hash);
-		umount_tree(&child->mnt, 0, &umount_list);
+		umount_tree(child, 0, &umount_list);
 	}
 	br_write_unlock(vfsmount_lock);
 	release_mounts(&umount_list);

commit 1b8e5564b9d34cbeb3047dd2be8ec9cd5e2785e2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 21:01:32 2011 -0500

    vfs: the first spoils - mnt_hash moved
    
    taken out of struct vfsmount into struct mount
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 916c8e87cf4e..a2f0f3e0e127 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -247,13 +247,13 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 
 		if (is_subdir(dest_dentry, m->mnt_root)) {
 			mnt_set_mountpoint(m, dest_dentry, &child->mnt);
-			list_add_tail(&child->mnt.mnt_hash, tree_list);
+			list_add_tail(&child->mnt_hash, tree_list);
 		} else {
 			/*
 			 * This can happen if the parent mount was bind mounted
 			 * on some subdirectory of a shared/slave mount.
 			 */
-			list_add_tail(&child->mnt.mnt_hash, &tmp_list);
+			list_add_tail(&child->mnt_hash, &tmp_list);
 		}
 		prev_dest_mnt = m;
 		prev_src_mnt  = &child->mnt;
@@ -261,7 +261,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 out:
 	br_write_lock(vfsmount_lock);
 	while (!list_empty(&tmp_list)) {
-		child = list_first_entry(&tmp_list, struct mount, mnt.mnt_hash);
+		child = list_first_entry(&tmp_list, struct mount, mnt_hash);
 		umount_tree(&child->mnt, 0, &umount_list);
 	}
 	br_write_unlock(vfsmount_lock);
@@ -337,7 +337,7 @@ static void __propagate_umount(struct mount *mnt)
 		 * other children
 		 */
 		if (child && list_empty(&child->mnt.mnt_mounts))
-			list_move_tail(&child->mnt.mnt_hash, &mnt->mnt.mnt_hash);
+			list_move_tail(&child->mnt_hash, &mnt->mnt_hash);
 	}
 }
 
@@ -352,7 +352,7 @@ int propagate_umount(struct list_head *list)
 {
 	struct mount *mnt;
 
-	list_for_each_entry(mnt, list, mnt.mnt_hash)
+	list_for_each_entry(mnt, list, mnt_hash)
 		__propagate_umount(mnt);
 	return 0;
 }

commit cb338d06e9716c92d5a7855e7c67b8f111ced722
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 20:55:08 2011 -0500

    vfs: spread struct mount - clone_mnt/copy_tree result
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 4bd3721867a7..916c8e87cf4e 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -221,7 +221,8 @@ static struct vfsmount *get_source(struct vfsmount *dest,
 int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 		    struct vfsmount *source_mnt, struct list_head *tree_list)
 {
-	struct vfsmount *m, *child;
+	struct vfsmount *m;
+	struct mount *child;
 	int ret = 0;
 	struct vfsmount *prev_dest_mnt = dest_mnt;
 	struct vfsmount *prev_src_mnt  = source_mnt;
@@ -245,23 +246,23 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 		}
 
 		if (is_subdir(dest_dentry, m->mnt_root)) {
-			mnt_set_mountpoint(m, dest_dentry, child);
-			list_add_tail(&child->mnt_hash, tree_list);
+			mnt_set_mountpoint(m, dest_dentry, &child->mnt);
+			list_add_tail(&child->mnt.mnt_hash, tree_list);
 		} else {
 			/*
 			 * This can happen if the parent mount was bind mounted
 			 * on some subdirectory of a shared/slave mount.
 			 */
-			list_add_tail(&child->mnt_hash, &tmp_list);
+			list_add_tail(&child->mnt.mnt_hash, &tmp_list);
 		}
 		prev_dest_mnt = m;
-		prev_src_mnt  = child;
+		prev_src_mnt  = &child->mnt;
 	}
 out:
 	br_write_lock(vfsmount_lock);
 	while (!list_empty(&tmp_list)) {
-		child = list_first_entry(&tmp_list, struct vfsmount, mnt_hash);
-		umount_tree(child, 0, &umount_list);
+		child = list_first_entry(&tmp_list, struct mount, mnt.mnt_hash);
+		umount_tree(&child->mnt, 0, &umount_list);
 	}
 	br_write_unlock(vfsmount_lock);
 	release_mounts(&umount_list);

commit 0f0afb1dcf01afc44581b3c0da251ac07dfb6e4a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 20:43:10 2011 -0500

    vfs: spread struct mount - change_mnt_propagation/set_mnt_shared
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index a824a097b523..4bd3721867a7 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -114,20 +114,20 @@ static int do_make_slave(struct vfsmount *mnt)
 /*
  * vfsmount lock must be held for write
  */
-void change_mnt_propagation(struct vfsmount *mnt, int type)
+void change_mnt_propagation(struct mount *mnt, int type)
 {
 	if (type == MS_SHARED) {
 		set_mnt_shared(mnt);
 		return;
 	}
-	do_make_slave(mnt);
+	do_make_slave(&mnt->mnt);
 	if (type != MS_SLAVE) {
-		list_del_init(&mnt->mnt_slave);
-		mnt->mnt_master = NULL;
+		list_del_init(&mnt->mnt.mnt_slave);
+		mnt->mnt.mnt_master = NULL;
 		if (type == MS_UNBINDABLE)
-			mnt->mnt_flags |= MNT_UNBINDABLE;
+			mnt->mnt.mnt_flags |= MNT_UNBINDABLE;
 		else
-			mnt->mnt_flags &= ~MNT_UNBINDABLE;
+			mnt->mnt.mnt_flags &= ~MNT_UNBINDABLE;
 	}
 }
 

commit 4b8b21f4fe16ee15eec5c69ea5fb41b30e428e59
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 19:54:23 2011 -0500

    vfs: spread struct mount - mount group id handling
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index ae5b1bda31ba..a824a097b523 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -83,7 +83,7 @@ static int do_make_slave(struct vfsmount *mnt)
 			peer_mnt = NULL;
 	}
 	if (IS_MNT_SHARED(mnt) && list_empty(&mnt->mnt_share))
-		mnt_release_group_id(mnt);
+		mnt_release_group_id(real_mount(mnt));
 
 	list_del_init(&mnt->mnt_share);
 	mnt->mnt_group_id = 0;

commit 61ef47b1e4ba9f2b939e6772e2f96082df0ae7eb
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 18:25:28 2011 -0500

    vfs: spread struct mount - __propagate_umount() argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index e996d039c0f2..ae5b1bda31ba 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -319,24 +319,24 @@ int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
  * NOTE: unmounting 'mnt' naturally propagates to all other mounts its
  * parent propagates to.
  */
-static void __propagate_umount(struct vfsmount *mnt)
+static void __propagate_umount(struct mount *mnt)
 {
-	struct vfsmount *parent = mnt->mnt_parent;
+	struct vfsmount *parent = mnt->mnt.mnt_parent;
 	struct vfsmount *m;
 
-	BUG_ON(parent == mnt);
+	BUG_ON(parent == &mnt->mnt);
 
 	for (m = propagation_next(parent, parent); m;
 			m = propagation_next(m, parent)) {
 
 		struct mount *child = __lookup_mnt(m,
-					mnt->mnt_mountpoint, 0);
+					mnt->mnt.mnt_mountpoint, 0);
 		/*
 		 * umount the child only if the child has no
 		 * other children
 		 */
 		if (child && list_empty(&child->mnt.mnt_mounts))
-			list_move_tail(&child->mnt.mnt_hash, &mnt->mnt_hash);
+			list_move_tail(&child->mnt.mnt_hash, &mnt->mnt.mnt_hash);
 	}
 }
 
@@ -349,9 +349,9 @@ static void __propagate_umount(struct vfsmount *mnt)
  */
 int propagate_umount(struct list_head *list)
 {
-	struct vfsmount *mnt;
+	struct mount *mnt;
 
-	list_for_each_entry(mnt, list, mnt_hash)
+	list_for_each_entry(mnt, list, mnt.mnt_hash)
 		__propagate_umount(mnt);
 	return 0;
 }

commit c71053659e3bb27d44b79da0bb4abf5838c2060a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 24 18:22:03 2011 -0500

    vfs: spread struct mount - __lookup_mnt() result
    
    switch __lookup_mnt() to returning struct mount *; callers adjusted.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 4d5a06ea57a2..e996d039c0f2 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -289,7 +289,8 @@ static inline int do_refcount_check(struct vfsmount *mnt, int count)
  */
 int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
 {
-	struct vfsmount *m, *child;
+	struct vfsmount *m;
+	struct mount *child;
 	struct vfsmount *parent = mnt->mnt_parent;
 	int ret = 0;
 
@@ -307,8 +308,8 @@ int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
 	for (m = propagation_next(parent, parent); m;
 	     		m = propagation_next(m, parent)) {
 		child = __lookup_mnt(m, mnt->mnt_mountpoint, 0);
-		if (child && list_empty(&child->mnt_mounts) &&
-		    (ret = do_refcount_check(child, 1)))
+		if (child && list_empty(&child->mnt.mnt_mounts) &&
+		    (ret = do_refcount_check(&child->mnt, 1)))
 			break;
 	}
 	return ret;
@@ -328,14 +329,14 @@ static void __propagate_umount(struct vfsmount *mnt)
 	for (m = propagation_next(parent, parent); m;
 			m = propagation_next(m, parent)) {
 
-		struct vfsmount *child = __lookup_mnt(m,
+		struct mount *child = __lookup_mnt(m,
 					mnt->mnt_mountpoint, 0);
 		/*
 		 * umount the child only if the child has no
 		 * other children
 		 */
-		if (child && list_empty(&child->mnt_mounts))
-			list_move_tail(&child->mnt_hash, &mnt->mnt_hash);
+		if (child && list_empty(&child->mnt.mnt_mounts))
+			list_move_tail(&child->mnt.mnt_hash, &mnt->mnt_hash);
 	}
 }
 

commit afac7cba7ed31968a95e181dc25e204e45009ea8
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Nov 23 19:34:49 2011 -0500

    vfs: more mnt_parent cleanups
    
    a) mount --move is checking that ->mnt_parent is non-NULL before
    looking if that parent happens to be shared; ->mnt_parent is never
    NULL and it's not even an misspelled !mnt_has_parent()
    
    b) pivot_root open-codes is_path_reachable(), poorly.
    
    c) so does path_is_under(), while we are at it.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index f1cd958b92e5..4d5a06ea57a2 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -28,21 +28,6 @@ static inline struct vfsmount *next_slave(struct vfsmount *p)
 	return list_entry(p->mnt_slave.next, struct vfsmount, mnt_slave);
 }
 
-/*
- * Return true if path is reachable from root
- *
- * namespace_sem is held, and mnt is attached
- */
-static bool is_path_reachable(struct vfsmount *mnt, struct dentry *dentry,
-			 const struct path *root)
-{
-	while (mnt != root->mnt && mnt_has_parent(mnt)) {
-		dentry = mnt->mnt_mountpoint;
-		mnt = mnt->mnt_parent;
-	}
-	return mnt == root->mnt && is_subdir(dentry, root->dentry);
-}
-
 static struct vfsmount *get_peer_under_root(struct vfsmount *mnt,
 					    struct mnt_namespace *ns,
 					    const struct path *root)

commit b2dba1af3c4157040303a76d25216b1713d333d0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Nov 23 19:26:23 2011 -0500

    vfs: new internal helper: mnt_has_parent(mnt)
    
    vfsmounts have ->mnt_parent pointing either to a different vfsmount
    or to itself; it's never NULL and termination condition in loops
    traversing the tree towards root is mnt == mnt->mnt_parent.  At least
    one place (see the next patch) is confused about what's going on;
    let's add an explicit helper checking it right way and use it in
    all places where we need it.  Not that there had been too many,
    but...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index d42514e32380..f1cd958b92e5 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -36,7 +36,7 @@ static inline struct vfsmount *next_slave(struct vfsmount *p)
 static bool is_path_reachable(struct vfsmount *mnt, struct dentry *dentry,
 			 const struct path *root)
 {
-	while (mnt != root->mnt && mnt->mnt_parent != mnt) {
+	while (mnt != root->mnt && mnt_has_parent(mnt)) {
 		dentry = mnt->mnt_mountpoint;
 		mnt = mnt->mnt_parent;
 	}

commit b3e19d924b6eaf2ca7d22cba99a517c5171007b6
Author: Nick Piggin <npiggin@kernel.dk>
Date:   Fri Jan 7 17:50:11 2011 +1100

    fs: scale mntget/mntput
    
    The problem that this patch aims to fix is vfsmount refcounting scalability.
    We need to take a reference on the vfsmount for every successful path lookup,
    which often go to the same mount point.
    
    The fundamental difficulty is that a "simple" reference count can never be made
    scalable, because any time a reference is dropped, we must check whether that
    was the last reference. To do that requires communication with all other CPUs
    that may have taken a reference count.
    
    We can make refcounts more scalable in a couple of ways, involving keeping
    distributed counters, and checking for the global-zero condition less
    frequently.
    
    - check the global sum once every interval (this will delay zero detection
      for some interval, so it's probably a showstopper for vfsmounts).
    
    - keep a local count and only taking the global sum when local reaches 0 (this
      is difficult for vfsmounts, because we can't hold preempt off for the life of
      a reference, so a counter would need to be per-thread or tied strongly to a
      particular CPU which requires more locking).
    
    - keep a local difference of increments and decrements, which allows us to sum
      the total difference and hence find the refcount when summing all CPUs. Then,
      keep a single integer "long" refcount for slow and long lasting references,
      and only take the global sum of local counters when the long refcount is 0.
    
    This last scheme is what I implemented here. Attached mounts and process root
    and working directory references are "long" references, and everything else is
    a short reference.
    
    This allows scalable vfsmount references during path walking over mounted
    subtrees and unattached (lazy umounted) mounts with processes still running
    in them.
    
    This results in one fewer atomic op in the fastpath: mntget is now just a
    per-CPU inc, rather than an atomic inc; and mntput just requires a spinlock
    and non-atomic decrement in the common case. However code is otherwise bigger
    and heavier, so single threaded performance is basically a wash.
    
    Signed-off-by: Nick Piggin <npiggin@kernel.dk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 8066b8dd748f..d42514e32380 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -288,7 +288,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
  */
 static inline int do_refcount_check(struct vfsmount *mnt, int count)
 {
-	int mycount = atomic_read(&mnt->mnt_count) - mnt->mnt_ghosts;
+	int mycount = mnt_get_count(mnt) - mnt->mnt_ghosts;
 	return (mycount > count);
 }
 
@@ -300,7 +300,7 @@ static inline int do_refcount_check(struct vfsmount *mnt, int count)
  * Check if any of these mounts that **do not have submounts**
  * have more references than 'refcnt'. If so return busy.
  *
- * vfsmount lock must be held for read or write
+ * vfsmount lock must be held for write
  */
 int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
 {

commit 99b7db7b8ffd6bb755eb0a175596421a0b581cb2
Author: Nick Piggin <npiggin@kernel.dk>
Date:   Wed Aug 18 04:37:39 2010 +1000

    fs: brlock vfsmount_lock
    
    fs: brlock vfsmount_lock
    
    Use a brlock for the vfsmount lock. It must be taken for write whenever
    modifying the mount hash or associated fields, and may be taken for read when
    performing mount hash lookups.
    
    A new lock is added for the mnt-id allocator, so it doesn't need to take
    the heavy vfsmount write-lock.
    
    The number of atomics should remain the same for fastpath rlock cases, though
    code would be slightly slower due to per-cpu access. Scalability is not not be
    much improved in common cases yet, due to other locks (ie. dcache_lock) getting
    in the way. However path lookups crossing mountpoints should be one case where
    scalability is improved (currently requiring the global lock).
    
    The slowpath is slower due to use of brlock. On a 64 core, 64 socket, 32 node
    Altix system (high latency to remote nodes), a simple umount microbenchmark
    (mount --bind mnt mnt2 ; umount mnt2 loop 1000 times), before this patch it
    took 6.8s, afterwards took 7.1s, about 5% slower.
    
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Nick Piggin <npiggin@kernel.dk>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 5cc564a83149..8066b8dd748f 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -126,6 +126,9 @@ static int do_make_slave(struct vfsmount *mnt)
 	return 0;
 }
 
+/*
+ * vfsmount lock must be held for write
+ */
 void change_mnt_propagation(struct vfsmount *mnt, int type)
 {
 	if (type == MS_SHARED) {
@@ -270,12 +273,12 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 		prev_src_mnt  = child;
 	}
 out:
-	spin_lock(&vfsmount_lock);
+	br_write_lock(vfsmount_lock);
 	while (!list_empty(&tmp_list)) {
 		child = list_first_entry(&tmp_list, struct vfsmount, mnt_hash);
 		umount_tree(child, 0, &umount_list);
 	}
-	spin_unlock(&vfsmount_lock);
+	br_write_unlock(vfsmount_lock);
 	release_mounts(&umount_list);
 	return ret;
 }
@@ -296,6 +299,8 @@ static inline int do_refcount_check(struct vfsmount *mnt, int count)
  * other mounts its parent propagates to.
  * Check if any of these mounts that **do not have submounts**
  * have more references than 'refcnt'. If so return busy.
+ *
+ * vfsmount lock must be held for read or write
  */
 int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
 {
@@ -353,6 +358,8 @@ static void __propagate_umount(struct vfsmount *mnt)
  * collect all mounts that receive propagation from the mount in @list,
  * and return these additional mounts in the same list.
  * @list: the list of mounts to be unmounted.
+ *
+ * vfsmount lock must be held for write
  */
 int propagate_umount(struct list_head *list)
 {

commit 796a6b521d0eadb338adf8cf7e482351c3a8a7b4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jan 16 13:28:47 2010 -0500

    Kill CL_PROPAGATION, sanitize fs/pnode.c:get_source()
    
    First of all, get_source() never results in CL_PROPAGATION
    alone.  We either get CL_MAKE_SHARED (for the continuation
    of peer group) or CL_SLAVE (slave that is not shared) or both
    (beginning of peer group among slaves).  Massage the code to
    make that explicit, kill CL_PROPAGATION test in clone_mnt()
    (nothing sets CL_MAKE_SHARED without CL_PROPAGATION and in
    clone_mnt() we are checking CL_PROPAGATION after we'd found
    that there's no CL_SLAVE, so the check for CL_MAKE_SHARED
    would do just as well).
    
    Fix comments, while we are at it...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 8d5f392ec3d3..5cc564a83149 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -86,7 +86,7 @@ static int do_make_slave(struct vfsmount *mnt)
 
 	/*
 	 * slave 'mnt' to a peer mount that has the
-	 * same root dentry. If none is available than
+	 * same root dentry. If none is available then
 	 * slave it to anything that is available.
 	 */
 	while ((peer_mnt = next_peer(peer_mnt)) != mnt &&
@@ -147,6 +147,11 @@ void change_mnt_propagation(struct vfsmount *mnt, int type)
  * get the next mount in the propagation tree.
  * @m: the mount seen last
  * @origin: the original mount from where the tree walk initiated
+ *
+ * Note that peer groups form contiguous segments of slave lists.
+ * We rely on that in get_source() to be able to find out if
+ * vfsmount found while iterating with propagation_next() is
+ * a peer of one we'd found earlier.
  */
 static struct vfsmount *propagation_next(struct vfsmount *m,
 					 struct vfsmount *origin)
@@ -186,10 +191,6 @@ static struct vfsmount *get_source(struct vfsmount *dest,
 {
 	struct vfsmount *p_last_src = NULL;
 	struct vfsmount *p_last_dest = NULL;
-	*type = CL_PROPAGATION;
-
-	if (IS_MNT_SHARED(dest))
-		*type |= CL_MAKE_SHARED;
 
 	while (last_dest != dest->mnt_master) {
 		p_last_dest = last_dest;
@@ -202,13 +203,18 @@ static struct vfsmount *get_source(struct vfsmount *dest,
 		do {
 			p_last_dest = next_peer(p_last_dest);
 		} while (IS_MNT_NEW(p_last_dest));
+		/* is that a peer of the earlier? */
+		if (dest == p_last_dest) {
+			*type = CL_MAKE_SHARED;
+			return p_last_src;
+		}
 	}
-
-	if (dest != p_last_dest) {
-		*type |= CL_SLAVE;
-		return last_src;
-	} else
-		return p_last_src;
+	/* slave of the earlier, then */
+	*type = CL_SLAVE;
+	/* beginning of peer group among the slaves? */
+	if (IS_MNT_SHARED(dest))
+		*type |= CL_MAKE_SHARED;
+	return last_src;
 }
 
 /*

commit 97e7e0f71d6d948c25f11f0a33878d9356d9579e
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Thu Mar 27 13:06:26 2008 +0100

    [patch 7/7] vfs: mountinfo: show dominating group id
    
    Show peer group ID of nearest dominating group that has intersection
    with the mount's namespace.
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index d18d66491a01..8d5f392ec3d3 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -28,6 +28,57 @@ static inline struct vfsmount *next_slave(struct vfsmount *p)
 	return list_entry(p->mnt_slave.next, struct vfsmount, mnt_slave);
 }
 
+/*
+ * Return true if path is reachable from root
+ *
+ * namespace_sem is held, and mnt is attached
+ */
+static bool is_path_reachable(struct vfsmount *mnt, struct dentry *dentry,
+			 const struct path *root)
+{
+	while (mnt != root->mnt && mnt->mnt_parent != mnt) {
+		dentry = mnt->mnt_mountpoint;
+		mnt = mnt->mnt_parent;
+	}
+	return mnt == root->mnt && is_subdir(dentry, root->dentry);
+}
+
+static struct vfsmount *get_peer_under_root(struct vfsmount *mnt,
+					    struct mnt_namespace *ns,
+					    const struct path *root)
+{
+	struct vfsmount *m = mnt;
+
+	do {
+		/* Check the namespace first for optimization */
+		if (m->mnt_ns == ns && is_path_reachable(m, m->mnt_root, root))
+			return m;
+
+		m = next_peer(m);
+	} while (m != mnt);
+
+	return NULL;
+}
+
+/*
+ * Get ID of closest dominating peer group having a representative
+ * under the given root.
+ *
+ * Caller must hold namespace_sem
+ */
+int get_dominating_id(struct vfsmount *mnt, const struct path *root)
+{
+	struct vfsmount *m;
+
+	for (m = mnt->mnt_master; m != NULL; m = m->mnt_master) {
+		struct vfsmount *d = get_peer_under_root(m, mnt->mnt_ns, root);
+		if (d)
+			return d->mnt_group_id;
+	}
+
+	return 0;
+}
+
 static int do_make_slave(struct vfsmount *mnt)
 {
 	struct vfsmount *peer_mnt = mnt, *master = mnt->mnt_master;

commit 719f5d7f0b90ac2c8f8ca4232eb322b266fea01e
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Thu Mar 27 13:06:23 2008 +0100

    [patch 4/7] vfs: mountinfo: add mount peer group ID
    
    Add a unique ID to each peer group using the IDR infrastructure.  The
    identifiers are reused after the peer group dissolves.
    
    The IDR structures are protected by holding namepspace_sem for write
    while allocating or deallocating IDs.
    
    IDs are allocated when a previously unshared vfsmount becomes the
    first member of a peer group.  When a new member is added to an
    existing group, the ID is copied from one of the old members.
    
    IDs are freed when the last member of a peer group is unshared.
    
    Setting the MNT_SHARED flag on members of a subtree is done as a
    separate step, after all the IDs have been allocated.  This way an
    allocation failure can be cleaned up easilty, without affecting the
    propagation state.
    
    Based on design sketch by Al Viro.
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index f968e35d9785..d18d66491a01 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -46,7 +46,11 @@ static int do_make_slave(struct vfsmount *mnt)
 		if (peer_mnt == mnt)
 			peer_mnt = NULL;
 	}
+	if (IS_MNT_SHARED(mnt) && list_empty(&mnt->mnt_share))
+		mnt_release_group_id(mnt);
+
 	list_del_init(&mnt->mnt_share);
+	mnt->mnt_group_id = 0;
 
 	if (peer_mnt)
 		master = peer_mnt;
@@ -68,7 +72,6 @@ static int do_make_slave(struct vfsmount *mnt)
 	}
 	mnt->mnt_master = master;
 	CLEAR_MNT_SHARED(mnt);
-	INIT_LIST_HEAD(&mnt->mnt_slave_list);
 	return 0;
 }
 

commit 4e1b36fb485dd81b0818ef1bc8fb5c0f2923a283
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Mar 24 00:16:03 2008 -0400

    [PATCH] umount_tree() will unhash everything itself
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index a9e0d6fadbcd..f968e35d9785 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -212,8 +212,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 out:
 	spin_lock(&vfsmount_lock);
 	while (!list_empty(&tmp_list)) {
-		child = list_entry(tmp_list.next, struct vfsmount, mnt_hash);
-		list_del_init(&child->mnt_hash);
+		child = list_first_entry(&tmp_list, struct vfsmount, mnt_hash);
 		umount_tree(child, 0, &umount_list);
 	}
 	spin_unlock(&vfsmount_lock);

commit 6d59e7f582ef1c1988542d0fc3b36d0087b757ce
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 22 15:48:17 2008 -0400

    [PATCH] move a bunch of declarations to fs/internal.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 1d8f5447f3f7..a9e0d6fadbcd 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -9,6 +9,7 @@
 #include <linux/mnt_namespace.h>
 #include <linux/mount.h>
 #include <linux/fs.h>
+#include "internal.h"
 #include "pnode.h"
 
 /* return the next shared peer mount of @p */

commit 7c4b93d8269b9d35971a8239426b1f6ddc3d5ef7
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Mar 21 23:59:49 2008 -0400

    [PATCH] count ghost references to vfsmounts
    
    make propagate_mount_busy() exclude references from the vfsmounts
    that had been isolated by umount_tree() and are just waiting for
    release_mounts() to dispose of their ->mnt_parent/->mnt_mountpoint.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/pnode.c b/fs/pnode.c
index 05ba692bc540..1d8f5447f3f7 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -225,7 +225,7 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
  */
 static inline int do_refcount_check(struct vfsmount *mnt, int count)
 {
-	int mycount = atomic_read(&mnt->mnt_count);
+	int mycount = atomic_read(&mnt->mnt_count) - mnt->mnt_ghosts;
 	return (mycount > count);
 }
 

commit 0b03cfb25fa944bc106e816146846dcb48b2e907
Author: Andries E. Brouwer <Andries.Brouwer@cwi.nl>
Date:   Wed Feb 6 01:36:32 2008 -0800

    MNT_UNBINDABLE fix
    
    Some time ago ( http://lkml.org/lkml/2007/6/19/128 ) I wrote about
    MNT_UNBINDABLE that it felt like a bug that it is not reset by "mount
    --make-private".
    
    Today I happened to see mount(8) and Documentation/sharedsubtree.txt and
    both document the version obtained by applying the little patch given in
    the above (and again below).
    
    So, the present kernel code is not according to specs and must be regarded
    as buggy.
    
    Specification in Documentation/sharedsubtree.txt:
    See state diagram: unbindable should become private upon make-private.
    
    Specification in mount(8):
        ...  It's
        also possible to  set  up  uni-directional  propagation  (with  --make-
        slave),  to  make  a  mount  point unavailable for --bind/--rbind (with
        --make-unbindable), and to undo any  of  these  (with  --make-private).
    
    Repeat of old fix-shared-subtrees-make-private.patch
    (due to Dirk Gerrits, René Gabriëls, Peter Kooijmans):
    
    Acked-by: Ram Pai <linuxram@us.ibm.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 89940f243fc2..05ba692bc540 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -83,6 +83,8 @@ void change_mnt_propagation(struct vfsmount *mnt, int type)
 		mnt->mnt_master = NULL;
 		if (type == MS_UNBINDABLE)
 			mnt->mnt_flags |= MNT_UNBINDABLE;
+		else
+			mnt->mnt_flags &= ~MNT_UNBINDABLE;
 	}
 }
 

commit b5e618181a927210f8be1d3d2249d31904ba358d
Author: Pavel Emelianov <xemul@sw.ru>
Date:   Tue May 8 00:30:19 2007 -0700

    Introduce a handy list_first_entry macro
    
    There are many places in the kernel where the construction like
    
       foo = list_entry(head->next, struct foo_struct, list);
    
    are used.
    The code might look more descriptive and neat if using the macro
    
       list_first_entry(head, type, member) \
                 list_entry((head)->next, type, member)
    
    Here is the macro itself and the examples of its usage in the generic code.
     If it will turn out to be useful, I can prepare the set of patches to
    inject in into arch-specific code, drivers, networking, etc.
    
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Signed-off-by: Kirill Korotaev <dev@openvz.org>
    Cc: Randy Dunlap <randy.dunlap@oracle.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Zach Brown <zach.brown@oracle.com>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: John McCutchan <ttb@tentacle.dhs.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 56aacead8362..89940f243fc2 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -59,7 +59,7 @@ static int do_make_slave(struct vfsmount *mnt)
 	} else {
 		struct list_head *p = &mnt->mnt_slave_list;
 		while (!list_empty(p)) {
-                        slave_mnt = list_entry(p->next,
+                        slave_mnt = list_first_entry(p,
 					struct vfsmount, mnt_slave);
 			list_del_init(&slave_mnt->mnt_slave);
 			slave_mnt->mnt_master = NULL;

commit 6b3286ed1169d74fea401367d6d4d6c6ec758a81
Author: Kirill Korotaev <dev@sw.ru>
Date:   Fri Dec 8 02:37:56 2006 -0800

    [PATCH] rename struct namespace to struct mnt_namespace
    
    Rename 'struct namespace' to 'struct mnt_namespace' to avoid confusion with
    other namespaces being developped for the containers : pid, uts, ipc, etc.
    'namespace' variables and attributes are also renamed to 'mnt_ns'
    
    Signed-off-by: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index da42ee61c1df..56aacead8362 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -6,7 +6,7 @@
  *	Author : Ram Pai (linuxram@us.ibm.com)
  *
  */
-#include <linux/namespace.h>
+#include <linux/mnt_namespace.h>
 #include <linux/mount.h>
 #include <linux/fs.h>
 #include "pnode.h"

commit 1bfba4e8ea0e555e3a0296051517d96253660ccc
Author: Akinobu Mita <mita@miraclelinux.com>
Date:   Mon Jun 26 00:24:40 2006 -0700

    [PATCH] core: use list_move()
    
    This patch converts the combination of list_del(A) and list_add(A, B) to
    list_move(A, B).
    
    Cc: Greg Kroah-Hartman <gregkh@suse.de>
    Cc: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Akinobu Mita <mita@miraclelinux.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 37b568ed0e05..da42ee61c1df 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -53,8 +53,7 @@ static int do_make_slave(struct vfsmount *mnt)
 	if (master) {
 		list_for_each_entry(slave_mnt, &mnt->mnt_slave_list, mnt_slave)
 			slave_mnt->mnt_master = master;
-		list_del(&mnt->mnt_slave);
-		list_add(&mnt->mnt_slave, &master->mnt_slave_list);
+		list_move(&mnt->mnt_slave, &master->mnt_slave_list);
 		list_splice(&mnt->mnt_slave_list, master->mnt_slave_list.prev);
 		INIT_LIST_HEAD(&mnt->mnt_slave_list);
 	} else {
@@ -283,10 +282,8 @@ static void __propagate_umount(struct vfsmount *mnt)
 		 * umount the child only if the child has no
 		 * other children
 		 */
-		if (child && list_empty(&child->mnt_mounts)) {
-			list_del(&child->mnt_hash);
-			list_add_tail(&child->mnt_hash, &mnt->mnt_hash);
-		}
+		if (child && list_empty(&child->mnt_mounts))
+			list_move_tail(&child->mnt_hash, &mnt->mnt_hash);
 	}
 }
 

commit 53b3531bbbf70ac7551b32d1acc229d94de52658
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Fri Mar 24 03:16:13 2006 -0800

    [PATCH] s/;;/;/g
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index f1871f773f64..37b568ed0e05 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -130,7 +130,7 @@ static struct vfsmount *get_source(struct vfsmount *dest,
 {
 	struct vfsmount *p_last_src = NULL;
 	struct vfsmount *p_last_dest = NULL;
-	*type = CL_PROPAGATION;;
+	*type = CL_PROPAGATION;
 
 	if (IS_MNT_SHARED(dest))
 		*type |= CL_MAKE_SHARED;

commit bf066c7db775a04bd761f8ea206f5522d0cf40ff
Author: Miklos Szeredi <miklos@szeredi.hu>
Date:   Sun Jan 8 01:03:19 2006 -0800

    [PATCH] shared mounts: cleanup
    
    Small cleanups in shared mounts code.
    
    Signed-off-by: Miklos Szeredi <miklos@szeredi.hu>
    Cc: Ram Pai <linuxram@us.ibm.com>
    Cc: <viro@parcelfarce.linux.theplanet.co.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index aeeec8ba8dd2..f1871f773f64 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -103,7 +103,7 @@ static struct vfsmount *propagation_next(struct vfsmount *m,
 		struct vfsmount *next;
 		struct vfsmount *master = m->mnt_master;
 
-		if ( master == origin->mnt_master ) {
+		if (master == origin->mnt_master) {
 			next = next_peer(m);
 			return ((next == origin) ? NULL : next);
 		} else if (m->mnt_slave.next != &master->mnt_slave_list)

commit 9676f0c6389b62bd6b24d77d4b3abdbcfa32d0f2
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Nov 7 17:21:20 2005 -0500

    [PATCH] unbindable mounts
    
    An unbindable mount does not forward or receive propagation.  Also
    unbindable mount disallows bind mounts.  The semantics is as follows.
    
    Bind semantics:
      It is invalid to bind mount an unbindable mount.
    
    Move semantics:
      It is invalid to move an unbindable mount under shared mount.
    
    Clone-namespace semantics:
      If a mount is unbindable in the parent namespace, the corresponding
      cloned mount in the child namespace becomes unbindable too.  Note:
      there is subtle difference, unbindable mounts cannot be bind mounted
      but can be cloned during clone-namespace.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 3e266c5a3071..aeeec8ba8dd2 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -82,6 +82,8 @@ void change_mnt_propagation(struct vfsmount *mnt, int type)
 	if (type != MS_SLAVE) {
 		list_del_init(&mnt->mnt_slave);
 		mnt->mnt_master = NULL;
+		if (type == MS_UNBINDABLE)
+			mnt->mnt_flags |= MNT_UNBINDABLE;
 	}
 }
 

commit 5afe00221389998a25d611dc7941c06580c29eb6
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Nov 7 17:21:01 2005 -0500

    [PATCH] handling of slave mounts
    
    This makes bind, rbind, move, clone namespace and umount operations
    aware of the semantics of slave mount (see Documentation/sharedsubtree.txt
    in the last patch of the series for detailed description).
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index f73eba24f1d1..3e266c5a3071 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -17,6 +17,16 @@ static inline struct vfsmount *next_peer(struct vfsmount *p)
 	return list_entry(p->mnt_share.next, struct vfsmount, mnt_share);
 }
 
+static inline struct vfsmount *first_slave(struct vfsmount *p)
+{
+	return list_entry(p->mnt_slave_list.next, struct vfsmount, mnt_slave);
+}
+
+static inline struct vfsmount *next_slave(struct vfsmount *p)
+{
+	return list_entry(p->mnt_slave.next, struct vfsmount, mnt_slave);
+}
+
 static int do_make_slave(struct vfsmount *mnt)
 {
 	struct vfsmount *peer_mnt = mnt, *master = mnt->mnt_master;
@@ -83,10 +93,64 @@ void change_mnt_propagation(struct vfsmount *mnt, int type)
 static struct vfsmount *propagation_next(struct vfsmount *m,
 					 struct vfsmount *origin)
 {
-	m = next_peer(m);
-	if (m == origin)
-		return NULL;
-	return m;
+	/* are there any slaves of this mount? */
+	if (!IS_MNT_NEW(m) && !list_empty(&m->mnt_slave_list))
+		return first_slave(m);
+
+	while (1) {
+		struct vfsmount *next;
+		struct vfsmount *master = m->mnt_master;
+
+		if ( master == origin->mnt_master ) {
+			next = next_peer(m);
+			return ((next == origin) ? NULL : next);
+		} else if (m->mnt_slave.next != &master->mnt_slave_list)
+			return next_slave(m);
+
+		/* back at master */
+		m = master;
+	}
+}
+
+/*
+ * return the source mount to be used for cloning
+ *
+ * @dest 	the current destination mount
+ * @last_dest  	the last seen destination mount
+ * @last_src  	the last seen source mount
+ * @type	return CL_SLAVE if the new mount has to be
+ * 		cloned as a slave.
+ */
+static struct vfsmount *get_source(struct vfsmount *dest,
+					struct vfsmount *last_dest,
+					struct vfsmount *last_src,
+					int *type)
+{
+	struct vfsmount *p_last_src = NULL;
+	struct vfsmount *p_last_dest = NULL;
+	*type = CL_PROPAGATION;;
+
+	if (IS_MNT_SHARED(dest))
+		*type |= CL_MAKE_SHARED;
+
+	while (last_dest != dest->mnt_master) {
+		p_last_dest = last_dest;
+		p_last_src = last_src;
+		last_dest = last_dest->mnt_master;
+		last_src = last_src->mnt_master;
+	}
+
+	if (p_last_dest) {
+		do {
+			p_last_dest = next_peer(p_last_dest);
+		} while (IS_MNT_NEW(p_last_dest));
+	}
+
+	if (dest != p_last_dest) {
+		*type |= CL_SLAVE;
+		return last_src;
+	} else
+		return p_last_src;
 }
 
 /*
@@ -114,16 +178,15 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 
 	for (m = propagation_next(dest_mnt, dest_mnt); m;
 			m = propagation_next(m, dest_mnt)) {
-		int type = CL_PROPAGATION;
+		int type;
+		struct vfsmount *source;
 
 		if (IS_MNT_NEW(m))
 			continue;
 
-		if (IS_MNT_SHARED(m))
-			type |= CL_MAKE_SHARED;
+		source =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);
 
-		if (!(child = copy_tree(source_mnt, source_mnt->mnt_root,
-						type))) {
+		if (!(child = copy_tree(source, source->mnt_root, type))) {
 			ret = -ENOMEM;
 			list_splice(tree_list, tmp_list.prev);
 			goto out;

commit a58b0eb8e64b78d9315a5491955e78b1391d42e5
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Nov 7 17:20:48 2005 -0500

    [PATCH] introduce slave mounts
    
    A slave mount always has a master mount from which it receives
    mount/umount events.  Unlike shared mount the event propagation does not
    flow from the slave mount to the master.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 7bc942d047cd..f73eba24f1d1 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -17,13 +17,61 @@ static inline struct vfsmount *next_peer(struct vfsmount *p)
 	return list_entry(p->mnt_share.next, struct vfsmount, mnt_share);
 }
 
+static int do_make_slave(struct vfsmount *mnt)
+{
+	struct vfsmount *peer_mnt = mnt, *master = mnt->mnt_master;
+	struct vfsmount *slave_mnt;
+
+	/*
+	 * slave 'mnt' to a peer mount that has the
+	 * same root dentry. If none is available than
+	 * slave it to anything that is available.
+	 */
+	while ((peer_mnt = next_peer(peer_mnt)) != mnt &&
+	       peer_mnt->mnt_root != mnt->mnt_root) ;
+
+	if (peer_mnt == mnt) {
+		peer_mnt = next_peer(mnt);
+		if (peer_mnt == mnt)
+			peer_mnt = NULL;
+	}
+	list_del_init(&mnt->mnt_share);
+
+	if (peer_mnt)
+		master = peer_mnt;
+
+	if (master) {
+		list_for_each_entry(slave_mnt, &mnt->mnt_slave_list, mnt_slave)
+			slave_mnt->mnt_master = master;
+		list_del(&mnt->mnt_slave);
+		list_add(&mnt->mnt_slave, &master->mnt_slave_list);
+		list_splice(&mnt->mnt_slave_list, master->mnt_slave_list.prev);
+		INIT_LIST_HEAD(&mnt->mnt_slave_list);
+	} else {
+		struct list_head *p = &mnt->mnt_slave_list;
+		while (!list_empty(p)) {
+                        slave_mnt = list_entry(p->next,
+					struct vfsmount, mnt_slave);
+			list_del_init(&slave_mnt->mnt_slave);
+			slave_mnt->mnt_master = NULL;
+		}
+	}
+	mnt->mnt_master = master;
+	CLEAR_MNT_SHARED(mnt);
+	INIT_LIST_HEAD(&mnt->mnt_slave_list);
+	return 0;
+}
+
 void change_mnt_propagation(struct vfsmount *mnt, int type)
 {
 	if (type == MS_SHARED) {
 		set_mnt_shared(mnt);
-	} else {
-		list_del_init(&mnt->mnt_share);
-		mnt->mnt_flags &= ~MNT_PNODE_MASK;
+		return;
+	}
+	do_make_slave(mnt);
+	if (type != MS_SLAVE) {
+		list_del_init(&mnt->mnt_slave);
+		mnt->mnt_master = NULL;
 	}
 }
 

commit a05964f3917c7c55368c229d7985f8e7c9977e97
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Nov 7 17:20:17 2005 -0500

    [PATCH] shared mounts handling: umount
    
    An unmount of a mount creates a umount event on the parent.  If the
    parent is a shared mount, it gets propagated to all mounts in the peer
    group.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 2d572b88e6f6..7bc942d047cd 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -99,9 +99,94 @@ int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
 	while (!list_empty(&tmp_list)) {
 		child = list_entry(tmp_list.next, struct vfsmount, mnt_hash);
 		list_del_init(&child->mnt_hash);
-		umount_tree(child, &umount_list);
+		umount_tree(child, 0, &umount_list);
 	}
 	spin_unlock(&vfsmount_lock);
 	release_mounts(&umount_list);
 	return ret;
 }
+
+/*
+ * return true if the refcount is greater than count
+ */
+static inline int do_refcount_check(struct vfsmount *mnt, int count)
+{
+	int mycount = atomic_read(&mnt->mnt_count);
+	return (mycount > count);
+}
+
+/*
+ * check if the mount 'mnt' can be unmounted successfully.
+ * @mnt: the mount to be checked for unmount
+ * NOTE: unmounting 'mnt' would naturally propagate to all
+ * other mounts its parent propagates to.
+ * Check if any of these mounts that **do not have submounts**
+ * have more references than 'refcnt'. If so return busy.
+ */
+int propagate_mount_busy(struct vfsmount *mnt, int refcnt)
+{
+	struct vfsmount *m, *child;
+	struct vfsmount *parent = mnt->mnt_parent;
+	int ret = 0;
+
+	if (mnt == parent)
+		return do_refcount_check(mnt, refcnt);
+
+	/*
+	 * quickly check if the current mount can be unmounted.
+	 * If not, we don't have to go checking for all other
+	 * mounts
+	 */
+	if (!list_empty(&mnt->mnt_mounts) || do_refcount_check(mnt, refcnt))
+		return 1;
+
+	for (m = propagation_next(parent, parent); m;
+	     		m = propagation_next(m, parent)) {
+		child = __lookup_mnt(m, mnt->mnt_mountpoint, 0);
+		if (child && list_empty(&child->mnt_mounts) &&
+		    (ret = do_refcount_check(child, 1)))
+			break;
+	}
+	return ret;
+}
+
+/*
+ * NOTE: unmounting 'mnt' naturally propagates to all other mounts its
+ * parent propagates to.
+ */
+static void __propagate_umount(struct vfsmount *mnt)
+{
+	struct vfsmount *parent = mnt->mnt_parent;
+	struct vfsmount *m;
+
+	BUG_ON(parent == mnt);
+
+	for (m = propagation_next(parent, parent); m;
+			m = propagation_next(m, parent)) {
+
+		struct vfsmount *child = __lookup_mnt(m,
+					mnt->mnt_mountpoint, 0);
+		/*
+		 * umount the child only if the child has no
+		 * other children
+		 */
+		if (child && list_empty(&child->mnt_mounts)) {
+			list_del(&child->mnt_hash);
+			list_add_tail(&child->mnt_hash, &mnt->mnt_hash);
+		}
+	}
+}
+
+/*
+ * collect all mounts that receive propagation from the mount in @list,
+ * and return these additional mounts in the same list.
+ * @list: the list of mounts to be unmounted.
+ */
+int propagate_umount(struct list_head *list)
+{
+	struct vfsmount *mnt;
+
+	list_for_each_entry(mnt, list, mnt_hash)
+		__propagate_umount(mnt);
+	return 0;
+}

commit b90fa9ae8f51f098ee480bbaabd6867992e9fc58
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Nov 7 17:19:50 2005 -0500

    [PATCH] shared mount handling: bind and rbind
    
    Implement handling of MS_BIND in presense of shared mounts (see
    Documentation/sharedsubtree.txt in the end of patch series for detailed
    description).
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index 1e22165ea41f..2d572b88e6f6 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -20,9 +20,88 @@ static inline struct vfsmount *next_peer(struct vfsmount *p)
 void change_mnt_propagation(struct vfsmount *mnt, int type)
 {
 	if (type == MS_SHARED) {
-		mnt->mnt_flags |= MNT_SHARED;
+		set_mnt_shared(mnt);
 	} else {
 		list_del_init(&mnt->mnt_share);
 		mnt->mnt_flags &= ~MNT_PNODE_MASK;
 	}
 }
+
+/*
+ * get the next mount in the propagation tree.
+ * @m: the mount seen last
+ * @origin: the original mount from where the tree walk initiated
+ */
+static struct vfsmount *propagation_next(struct vfsmount *m,
+					 struct vfsmount *origin)
+{
+	m = next_peer(m);
+	if (m == origin)
+		return NULL;
+	return m;
+}
+
+/*
+ * mount 'source_mnt' under the destination 'dest_mnt' at
+ * dentry 'dest_dentry'. And propagate that mount to
+ * all the peer and slave mounts of 'dest_mnt'.
+ * Link all the new mounts into a propagation tree headed at
+ * source_mnt. Also link all the new mounts using ->mnt_list
+ * headed at source_mnt's ->mnt_list
+ *
+ * @dest_mnt: destination mount.
+ * @dest_dentry: destination dentry.
+ * @source_mnt: source mount.
+ * @tree_list : list of heads of trees to be attached.
+ */
+int propagate_mnt(struct vfsmount *dest_mnt, struct dentry *dest_dentry,
+		    struct vfsmount *source_mnt, struct list_head *tree_list)
+{
+	struct vfsmount *m, *child;
+	int ret = 0;
+	struct vfsmount *prev_dest_mnt = dest_mnt;
+	struct vfsmount *prev_src_mnt  = source_mnt;
+	LIST_HEAD(tmp_list);
+	LIST_HEAD(umount_list);
+
+	for (m = propagation_next(dest_mnt, dest_mnt); m;
+			m = propagation_next(m, dest_mnt)) {
+		int type = CL_PROPAGATION;
+
+		if (IS_MNT_NEW(m))
+			continue;
+
+		if (IS_MNT_SHARED(m))
+			type |= CL_MAKE_SHARED;
+
+		if (!(child = copy_tree(source_mnt, source_mnt->mnt_root,
+						type))) {
+			ret = -ENOMEM;
+			list_splice(tree_list, tmp_list.prev);
+			goto out;
+		}
+
+		if (is_subdir(dest_dentry, m->mnt_root)) {
+			mnt_set_mountpoint(m, dest_dentry, child);
+			list_add_tail(&child->mnt_hash, tree_list);
+		} else {
+			/*
+			 * This can happen if the parent mount was bind mounted
+			 * on some subdirectory of a shared/slave mount.
+			 */
+			list_add_tail(&child->mnt_hash, &tmp_list);
+		}
+		prev_dest_mnt = m;
+		prev_src_mnt  = child;
+	}
+out:
+	spin_lock(&vfsmount_lock);
+	while (!list_empty(&tmp_list)) {
+		child = list_entry(tmp_list.next, struct vfsmount, mnt_hash);
+		list_del_init(&child->mnt_hash);
+		umount_tree(child, &umount_list);
+	}
+	spin_unlock(&vfsmount_lock);
+	release_mounts(&umount_list);
+	return ret;
+}

commit 03e06e68ff76294e53ffa898cb844d2a997b043e
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Nov 7 17:19:33 2005 -0500

    [PATCH] introduce shared mounts
    
    This creates shared mounts.  A shared mount when bind-mounted to some
    mountpoint, propagates mount/umount events to each other.  All the
    shared mounts that propagate events to each other belong to the same
    peer-group.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
index aaa0dffda12a..1e22165ea41f 100644
--- a/fs/pnode.c
+++ b/fs/pnode.c
@@ -11,7 +11,18 @@
 #include <linux/fs.h>
 #include "pnode.h"
 
+/* return the next shared peer mount of @p */
+static inline struct vfsmount *next_peer(struct vfsmount *p)
+{
+	return list_entry(p->mnt_share.next, struct vfsmount, mnt_share);
+}
+
 void change_mnt_propagation(struct vfsmount *mnt, int type)
 {
-	mnt->mnt_flags &= ~MNT_PNODE_MASK;
+	if (type == MS_SHARED) {
+		mnt->mnt_flags |= MNT_SHARED;
+	} else {
+		list_del_init(&mnt->mnt_share);
+		mnt->mnt_flags &= ~MNT_PNODE_MASK;
+	}
 }

commit 07b20889e3052c7e77d6a6a54e7e83446eb1ba84
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Nov 7 17:19:07 2005 -0500

    [PATCH] beginning of the shared-subtree proper
    
    A private mount does not forward or receive propagation.  This patch
    provides user the ability to convert any mount to private.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/pnode.c b/fs/pnode.c
new file mode 100644
index 000000000000..aaa0dffda12a
--- /dev/null
+++ b/fs/pnode.c
@@ -0,0 +1,17 @@
+/*
+ *  linux/fs/pnode.c
+ *
+ * (C) Copyright IBM Corporation 2005.
+ *	Released under GPL v2.
+ *	Author : Ram Pai (linuxram@us.ibm.com)
+ *
+ */
+#include <linux/namespace.h>
+#include <linux/mount.h>
+#include <linux/fs.h>
+#include "pnode.h"
+
+void change_mnt_propagation(struct vfsmount *mnt, int type)
+{
+	mnt->mnt_flags &= ~MNT_PNODE_MASK;
+}
