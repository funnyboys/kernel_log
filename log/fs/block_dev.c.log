commit 3373a3461aa15b7f9a871fa4cb2c9ef21ac20b47
Author: Zheng Bin <zhengbin13@huawei.com>
Date:   Thu Jun 18 12:21:38 2020 +0800

    block: make function 'kill_bdev' static
    
    kill_bdev does not have any external user, so make it static.
    
    Signed-off-by: Zheng Bin <zhengbin13@huawei.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 08c87db3a92b..0ae656e022fd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -75,7 +75,7 @@ static void bdev_write_inode(struct block_device *bdev)
 }
 
 /* Kill _all_ buffers and pagecache , dirty or not.. */
-void kill_bdev(struct block_device *bdev)
+static void kill_bdev(struct block_device *bdev)
 {
 	struct address_space *mapping = bdev->bd_inode->i_mapping;
 
@@ -84,8 +84,7 @@ void kill_bdev(struct block_device *bdev)
 
 	invalidate_bh_lrus();
 	truncate_inode_pages(mapping, 0);
-}	
-EXPORT_SYMBOL(kill_bdev);
+}
 
 /* Invalidate clean unused buffers and pagecache. */
 void invalidate_bdev(struct block_device *bdev)

commit 2d3a8e2deddea6c89961c422ec0c5b851e648c14
Author: Jason Yan <yanaijie@huawei.com>
Date:   Tue Jun 16 20:16:55 2020 +0800

    block: Fix use-after-free in blkdev_get()
    
    In blkdev_get() we call __blkdev_get() to do some internal jobs and if
    there is some errors in __blkdev_get(), the bdput() is called which
    means we have released the refcount of the bdev (actually the refcount of
    the bdev inode). This means we cannot access bdev after that point. But
    acctually bdev is still accessed in blkdev_get() after calling
    __blkdev_get(). This results in use-after-free if the refcount is the
    last one we released in __blkdev_get(). Let's take a look at the
    following scenerio:
    
      CPU0            CPU1                    CPU2
    blkdev_open     blkdev_open           Remove disk
                      bd_acquire
                      blkdev_get
                        __blkdev_get      del_gendisk
                                            bdev_unhash_inode
      bd_acquire          bdev_get_gendisk
        bd_forget           failed because of unhashed
              bdput
                          bdput (the last one)
                            bdev_evict_inode
    
                        access bdev => use after free
    
    [  459.350216] BUG: KASAN: use-after-free in __lock_acquire+0x24c1/0x31b0
    [  459.351190] Read of size 8 at addr ffff88806c815a80 by task syz-executor.0/20132
    [  459.352347]
    [  459.352594] CPU: 0 PID: 20132 Comm: syz-executor.0 Not tainted 4.19.90 #2
    [  459.353628] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014
    [  459.354947] Call Trace:
    [  459.355337]  dump_stack+0x111/0x19e
    [  459.355879]  ? __lock_acquire+0x24c1/0x31b0
    [  459.356523]  print_address_description+0x60/0x223
    [  459.357248]  ? __lock_acquire+0x24c1/0x31b0
    [  459.357887]  kasan_report.cold+0xae/0x2d8
    [  459.358503]  __lock_acquire+0x24c1/0x31b0
    [  459.359120]  ? _raw_spin_unlock_irq+0x24/0x40
    [  459.359784]  ? lockdep_hardirqs_on+0x37b/0x580
    [  459.360465]  ? _raw_spin_unlock_irq+0x24/0x40
    [  459.361123]  ? finish_task_switch+0x125/0x600
    [  459.361812]  ? finish_task_switch+0xee/0x600
    [  459.362471]  ? mark_held_locks+0xf0/0xf0
    [  459.363108]  ? __schedule+0x96f/0x21d0
    [  459.363716]  lock_acquire+0x111/0x320
    [  459.364285]  ? blkdev_get+0xce/0xbe0
    [  459.364846]  ? blkdev_get+0xce/0xbe0
    [  459.365390]  __mutex_lock+0xf9/0x12a0
    [  459.365948]  ? blkdev_get+0xce/0xbe0
    [  459.366493]  ? bdev_evict_inode+0x1f0/0x1f0
    [  459.367130]  ? blkdev_get+0xce/0xbe0
    [  459.367678]  ? destroy_inode+0xbc/0x110
    [  459.368261]  ? mutex_trylock+0x1a0/0x1a0
    [  459.368867]  ? __blkdev_get+0x3e6/0x1280
    [  459.369463]  ? bdev_disk_changed+0x1d0/0x1d0
    [  459.370114]  ? blkdev_get+0xce/0xbe0
    [  459.370656]  blkdev_get+0xce/0xbe0
    [  459.371178]  ? find_held_lock+0x2c/0x110
    [  459.371774]  ? __blkdev_get+0x1280/0x1280
    [  459.372383]  ? lock_downgrade+0x680/0x680
    [  459.373002]  ? lock_acquire+0x111/0x320
    [  459.373587]  ? bd_acquire+0x21/0x2c0
    [  459.374134]  ? do_raw_spin_unlock+0x4f/0x250
    [  459.374780]  blkdev_open+0x202/0x290
    [  459.375325]  do_dentry_open+0x49e/0x1050
    [  459.375924]  ? blkdev_get_by_dev+0x70/0x70
    [  459.376543]  ? __x64_sys_fchdir+0x1f0/0x1f0
    [  459.377192]  ? inode_permission+0xbe/0x3a0
    [  459.377818]  path_openat+0x148c/0x3f50
    [  459.378392]  ? kmem_cache_alloc+0xd5/0x280
    [  459.379016]  ? entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  459.379802]  ? path_lookupat.isra.0+0x900/0x900
    [  459.380489]  ? __lock_is_held+0xad/0x140
    [  459.381093]  do_filp_open+0x1a1/0x280
    [  459.381654]  ? may_open_dev+0xf0/0xf0
    [  459.382214]  ? find_held_lock+0x2c/0x110
    [  459.382816]  ? lock_downgrade+0x680/0x680
    [  459.383425]  ? __lock_is_held+0xad/0x140
    [  459.384024]  ? do_raw_spin_unlock+0x4f/0x250
    [  459.384668]  ? _raw_spin_unlock+0x1f/0x30
    [  459.385280]  ? __alloc_fd+0x448/0x560
    [  459.385841]  do_sys_open+0x3c3/0x500
    [  459.386386]  ? filp_open+0x70/0x70
    [  459.386911]  ? trace_hardirqs_on_thunk+0x1a/0x1c
    [  459.387610]  ? trace_hardirqs_off_caller+0x55/0x1c0
    [  459.388342]  ? do_syscall_64+0x1a/0x520
    [  459.388930]  do_syscall_64+0xc3/0x520
    [  459.389490]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  459.390248] RIP: 0033:0x416211
    [  459.390720] Code: 75 14 b8 02 00 00 00 0f 05 48 3d 01 f0 ff ff 0f 83
    04 19 00 00 c3 48 83 ec 08 e8 0a fa ff ff 48 89 04 24 b8 02 00 00 00 0f
       05 <48> 8b 3c 24 48 89 c2 e8 53 fa ff ff 48 89 d0 48 83 c4 08 48 3d
          01
    [  459.393483] RSP: 002b:00007fe45dfe9a60 EFLAGS: 00000293 ORIG_RAX: 0000000000000002
    [  459.394610] RAX: ffffffffffffffda RBX: 00007fe45dfea6d4 RCX: 0000000000416211
    [  459.395678] RDX: 00007fe45dfe9b0a RSI: 0000000000000002 RDI: 00007fe45dfe9b00
    [  459.396758] RBP: 000000000076bf20 R08: 0000000000000000 R09: 000000000000000a
    [  459.397930] R10: 0000000000000075 R11: 0000000000000293 R12: 00000000ffffffff
    [  459.399022] R13: 0000000000000bd9 R14: 00000000004cdb80 R15: 000000000076bf2c
    [  459.400168]
    [  459.400430] Allocated by task 20132:
    [  459.401038]  kasan_kmalloc+0xbf/0xe0
    [  459.401652]  kmem_cache_alloc+0xd5/0x280
    [  459.402330]  bdev_alloc_inode+0x18/0x40
    [  459.402970]  alloc_inode+0x5f/0x180
    [  459.403510]  iget5_locked+0x57/0xd0
    [  459.404095]  bdget+0x94/0x4e0
    [  459.404607]  bd_acquire+0xfa/0x2c0
    [  459.405113]  blkdev_open+0x110/0x290
    [  459.405702]  do_dentry_open+0x49e/0x1050
    [  459.406340]  path_openat+0x148c/0x3f50
    [  459.406926]  do_filp_open+0x1a1/0x280
    [  459.407471]  do_sys_open+0x3c3/0x500
    [  459.408010]  do_syscall_64+0xc3/0x520
    [  459.408572]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  459.409415]
    [  459.409679] Freed by task 1262:
    [  459.410212]  __kasan_slab_free+0x129/0x170
    [  459.410919]  kmem_cache_free+0xb2/0x2a0
    [  459.411564]  rcu_process_callbacks+0xbb2/0x2320
    [  459.412318]  __do_softirq+0x225/0x8ac
    
    Fix this by delaying bdput() to the end of blkdev_get() which means we
    have finished accessing bdev.
    
    Fixes: 77ea887e433a ("implement in-kernel gendisk events handling")
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Jason Yan <yanaijie@huawei.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Dan Carpenter <dan.carpenter@oracle.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Ming Lei <ming.lei@redhat.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 47860e589388..08c87db3a92b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1565,10 +1565,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	 */
 	if (!for_part) {
 		ret = devcgroup_inode_permission(bdev->bd_inode, perm);
-		if (ret != 0) {
-			bdput(bdev);
+		if (ret != 0)
 			return ret;
-		}
 	}
 
  restart:
@@ -1637,8 +1635,10 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_clear;
 			BUG_ON(for_part);
 			ret = __blkdev_get(whole, mode, 1);
-			if (ret)
+			if (ret) {
+				bdput(whole);
 				goto out_clear;
+			}
 			bdev->bd_contains = whole;
 			bdev->bd_part = disk_get_part(disk, partno);
 			if (!(disk->flags & GENHD_FL_UP) ||
@@ -1688,7 +1688,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	disk_unblock_events(disk);
 	put_disk_and_module(disk);
  out:
-	bdput(bdev);
 
 	return ret;
 }
@@ -1755,6 +1754,9 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 		bdput(whole);
 	}
 
+	if (res)
+		bdput(bdev);
+
 	return res;
 }
 EXPORT_SYMBOL(blkdev_get);

commit bce159d734091fe31340976081577333f52a85e4
Merge: 750a02ab8d3c 0c8d3fceade2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 15:37:03 2020 -0700

    Merge tag 'for-5.8/drivers-2020-06-01' of git://git.kernel.dk/linux-block
    
    Pull block driver updates from Jens Axboe:
     "On top of the core changes, here are the block driver changes for this
      merge window:
    
       - NVMe changes:
            - NVMe over Fibre Channel protocol updates, which also reach
              over to drivers/scsi/lpfc (James Smart)
            - namespace revalidation support on the target (Anthony
              Iliopoulos)
            - gcc zero length array fix (Arnd Bergmann)
            - nvmet cleanups (Chaitanya Kulkarni)
            - misc cleanups and fixes (me, Keith Busch, Sagi Grimberg)
            - use a SRQ per completion vector (Max Gurtovoy)
            - fix handling of runtime changes to the queue count (Weiping
              Zhang)
            - t10 protection information support for nvme-rdma and
              nvmet-rdma (Israel Rukshin and Max Gurtovoy)
            - target side AEN improvements (Chaitanya Kulkarni)
            - various fixes and minor improvements all over, icluding the
              nvme part of the lpfc driver"
    
       - Floppy code cleanup series (Willy, Denis)
    
       - Floppy contention fix (Jiri)
    
       - Loop CONFIGURE support (Martijn)
    
       - bcache fixes/improvements (Coly, Joe, Colin)
    
       - q->queuedata cleanups (Christoph)
    
       - Get rid of ioctl_by_bdev (Christoph, Stefan)
    
       - md/raid5 allocation fixes (Coly)
    
       - zero length array fixes (Gustavo)
    
       - swim3 task state fix (Xu)"
    
    * tag 'for-5.8/drivers-2020-06-01' of git://git.kernel.dk/linux-block: (166 commits)
      bcache: configure the asynchronous registertion to be experimental
      bcache: asynchronous devices registration
      bcache: fix refcount underflow in bcache_device_free()
      bcache: Convert pr_<level> uses to a more typical style
      bcache: remove redundant variables i and n
      lpfc: Fix return value in __lpfc_nvme_ls_abort
      lpfc: fix axchg pointer reference after free and double frees
      lpfc: Fix pointer checks and comments in LS receive refactoring
      nvme: set dma alignment to qword
      nvmet: cleanups the loop in nvmet_async_events_process
      nvmet: fix memory leak when removing namespaces and controllers concurrently
      nvmet-rdma: add metadata/T10-PI support
      nvmet: add metadata support for block devices
      nvmet: add metadata/T10-PI support
      nvme: add Metadata Capabilities enumerations
      nvmet: rename nvmet_check_data_len to nvmet_check_transfer_len
      nvmet: rename nvmet_rw_len to nvmet_rw_data_len
      nvmet: add metadata characteristics for a namespace
      nvme-rdma: add metadata/T10-PI support
      nvme-rdma: introduce nvme_rdma_sgl structure
      ...

commit 750a02ab8d3c49ca7d23102be90d3d1db19e2827
Merge: 1966391fa576 abb30460bda2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 15:29:19 2020 -0700

    Merge tag 'for-5.8/block-2020-06-01' of git://git.kernel.dk/linux-block
    
    Pull block updates from Jens Axboe:
     "Core block changes that have been queued up for this release:
    
       - Remove dead blk-throttle and blk-wbt code (Guoqing)
    
       - Include pid in blktrace note traces (Jan)
    
       - Don't spew I/O errors on wouldblock termination (me)
    
       - Zone append addition (Johannes, Keith, Damien)
    
       - IO accounting improvements (Konstantin, Christoph)
    
       - blk-mq hardware map update improvements (Ming)
    
       - Scheduler dispatch improvement (Salman)
    
       - Inline block encryption support (Satya)
    
       - Request map fixes and improvements (Weiping)
    
       - blk-iocost tweaks (Tejun)
    
       - Fix for timeout failing with error injection (Keith)
    
       - Queue re-run fixes (Douglas)
    
       - CPU hotplug improvements (Christoph)
    
       - Queue entry/exit improvements (Christoph)
    
       - Move DMA drain handling to the few drivers that use it (Christoph)
    
       - Partition handling cleanups (Christoph)"
    
    * tag 'for-5.8/block-2020-06-01' of git://git.kernel.dk/linux-block: (127 commits)
      block: mark bio_wouldblock_error() bio with BIO_QUIET
      blk-wbt: rename __wbt_update_limits to wbt_update_limits
      blk-wbt: remove wbt_update_limits
      blk-throttle: remove tg_drain_bios
      blk-throttle: remove blk_throtl_drain
      null_blk: force complete for timeout request
      blk-mq: drain I/O when all CPUs in a hctx are offline
      blk-mq: add blk_mq_all_tag_iter
      blk-mq: open code __blk_mq_alloc_request in blk_mq_alloc_request_hctx
      blk-mq: use BLK_MQ_NO_TAG in more places
      blk-mq: rename BLK_MQ_TAG_FAIL to BLK_MQ_NO_TAG
      blk-mq: move more request initialization to blk_mq_rq_ctx_init
      blk-mq: simplify the blk_mq_get_request calling convention
      blk-mq: remove the bio argument to ->prepare_request
      nvme: force complete cancelled requests
      blk-mq: blk-mq: provide forced completion method
      block: fix a warning when blkdev.h is included for !CONFIG_BLOCK builds
      block: blk-crypto-fallback: remove redundant initialization of variable err
      block: reduce part_stat_lock() scope
      block: use __this_cpu_add() instead of access by smp_processor_id()
      ...

commit 355ba37d756c38962fe9bb616f5f48eb12a7e11e
Merge: a5a82e0a5918 a34024d98eea
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 13:17:23 2020 -0700

    Merge tag 'pm-5.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management updates from Rafael Wysocki:
     "These rework the system-wide PM driver flags, make runtime switching
      of cpuidle governors easier, improve the user space hibernation
      interface code, add intel-speed-select interface documentation, add
      more debug messages to the ACPI code handling suspend to idle, update
      the cpufreq core and drivers, fix a minor issue in the cpuidle core
      and update two cpuidle drivers, improve the PM-runtime framework,
      update the Intel RAPL power capping driver, update devfreq core and
      drivers, and clean up the cpupower utility.
    
      Specifics:
    
       - Rework the system-wide PM driver flags to make them easier to
         understand and use and update their documentation (Rafael Wysocki,
         Alan Stern).
    
       - Allow cpuidle governors to be switched at run time regardless of
         the kernel configuration and update the related documentation
         accordingly (Hanjun Guo).
    
       - Improve the resume device handling in the user space hibernarion
         interface code (Domenico Andreoli).
    
       - Document the intel-speed-select sysfs interface (Srinivas
         Pandruvada).
    
       - Make the ACPI code handing suspend to idle print more debug
         messages to help diagnose issues with it (Rafael Wysocki).
    
       - Fix a helper routine in the cpufreq core and correct a typo in the
         struct cpufreq_driver kerneldoc comment (Rafael Wysocki, Wang
         Wenhu).
    
       - Update cpufreq drivers:
    
          - Make the intel_pstate driver start in the passive mode by
            default on systems without HWP (Rafael Wysocki).
    
          - Add i.MX7ULP support to the imx-cpufreq-dt driver and add
            i.MX7ULP to the cpufreq-dt-platdev blacklist (Peng Fan).
    
          - Convert the qoriq cpufreq driver to a platform one, make the
            platform code create a suitable device object for it and add
            platform dependencies to it (Mian Yousaf Kaukab, Geert
            Uytterhoeven).
    
          - Fix wrong compatible binding in the qcom driver (Ansuel Smith).
    
          - Build the omap driver by default for ARCH_OMAP2PLUS (Anders
            Roxell).
    
          - Add r8a7742 SoC support to the dt cpufreq driver (Lad
            Prabhakar).
    
       - Update cpuidle core and drivers:
    
          - Fix three reference count leaks in error code paths in the
            cpuidle core (Qiushi Wu).
    
          - Convert Qualcomm SPM to a generic cpuidle driver (Stephan
            Gerhold).
    
          - Fix up the execution order when entering a domain idle state in
            the PSCI driver (Ulf Hansson).
    
       - Fix a reference counting issue related to clock management and
         clean up two oddities in the PM-runtime framework (Rafael Wysocki,
         Andy Shevchenko).
    
       - Add ElkhartLake support to the Intel RAPL power capping driver and
         remove an unused local MSR definition from it (Jacob Pan, Sumeet
         Pawnikar).
    
       - Update devfreq core and drivers:
    
          - Replace strncpy() with strscpy() in the devfreq core and use
            lockdep asserts instead of manual checks for a locked mutex in
            it (Dmitry Osipenko, Krzysztof Kozlowski).
    
          - Add a generic imx bus scaling driver and make it register an
            interconnect device (Leonard Crestez, Gustavo A. R. Silva).
    
          - Make the cpufreq notifier in the tegra30 driver take boosting
            into account and delete an unuseful error message from that
            driver (Dmitry Osipenko, Markus Elfring).
    
       - Remove unneeded semicolon from the cpupower code (Zou Wei)"
    
    * tag 'pm-5.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (51 commits)
      cpuidle: Fix three reference count leaks
      PM: runtime: Replace pm_runtime_callbacks_present()
      PM / devfreq: Use lockdep asserts instead of manual checks for locked mutex
      PM / devfreq: imx-bus: Fix inconsistent IS_ERR and PTR_ERR
      PM / devfreq: Replace strncpy with strscpy
      PM / devfreq: imx: Register interconnect device
      PM / devfreq: Add generic imx bus scaling driver
      PM / devfreq: tegra30: Delete an error message in tegra_devfreq_probe()
      PM / devfreq: tegra30: Make CPUFreq notifier to take into account boosting
      PM: hibernate: Restrict writes to the resume device
      PM: runtime: clk: Fix clk_pm_runtime_get() error path
      cpuidle: Convert Qualcomm SPM driver to a generic CPUidle driver
      ACPI: EC: PM: s2idle: Extend GPE dispatching debug message
      ACPI: PM: s2idle: Print type of wakeup debug messages
      powercap: RAPL: remove unused local MSR define
      PM: runtime: Make clear what we do when conditions are wrong in rpm_suspend()
      Documentation: admin-guide: pm: Document intel-speed-select
      PM: hibernate: Split off snapshot dev option
      PM: hibernate: Incorporate concurrency handling
      Documentation: ABI: make current_governer_ro as a candidate for removal
      ...

commit d4388340ae0bc8397ef5b24342279f7739982918
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Mon Jun 1 21:47:02 2020 -0700

    fs: convert mpage_readpages to mpage_readahead
    
    Implement the new readahead aop and convert all callers (block_dev,
    exfat, ext2, fat, gfs2, hpfs, isofs, jfs, nilfs2, ocfs2, omfs, qnx6,
    reiserfs & udf).
    
    The callers are all trivial except for GFS2 & OCFS2.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Junxiao Bi <junxiao.bi@oracle.com> # ocfs2
    Reviewed-by: Joseph Qi <joseph.qi@linux.alibaba.com> # ocfs2
    Reviewed-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: John Hubbard <jhubbard@nvidia.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: William Kucharski <william.kucharski@oracle.com>
    Cc: Chao Yu <yuchao0@huawei.com>
    Cc: Cong Wang <xiyou.wangcong@gmail.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Eric Biggers <ebiggers@google.com>
    Cc: Gao Xiang <gaoxiang25@huawei.com>
    Cc: Jaegeuk Kim <jaegeuk@kernel.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Cc: Miklos Szeredi <mszeredi@redhat.com>
    Link: http://lkml.kernel.org/r/20200414150233.24495-17-willy@infradead.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 93672c3f1c78..f05e2f2c898d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -614,10 +614,9 @@ static int blkdev_readpage(struct file * file, struct page * page)
 	return block_read_full_page(page, blkdev_get_block);
 }
 
-static int blkdev_readpages(struct file *file, struct address_space *mapping,
-			struct list_head *pages, unsigned nr_pages)
+static void blkdev_readahead(struct readahead_control *rac)
 {
-	return mpage_readpages(mapping, pages, nr_pages, blkdev_get_block);
+	mpage_readahead(rac, blkdev_get_block);
 }
 
 static int blkdev_write_begin(struct file *file, struct address_space *mapping,
@@ -2085,7 +2084,7 @@ static int blkdev_writepages(struct address_space *mapping,
 
 static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
-	.readpages	= blkdev_readpages,
+	.readahead	= blkdev_readahead,
 	.writepage	= blkdev_writepage,
 	.write_begin	= blkdev_write_begin,
 	.write_end	= blkdev_write_end,

commit ad1e4f74c072eaa2c6d77dd710db31aafecd614f
Author: Domenico Andreoli <domenico.andreoli@linux.com>
Date:   Tue May 19 20:14:10 2020 +0200

    PM: hibernate: Restrict writes to the resume device
    
    Hibernation via snapshot device requires write permission to the swap
    block device, the one that more often (but not necessarily) is used to
    store the hibernation image.
    
    With this patch, such permissions are granted iff:
    
     1) snapshot device config option is enabled
     2) swap partition is used as resume device
    
    In other circumstances the swap device is not writable from userspace.
    
    In order to achieve this, every write attempt to a swap device is
    checked against the device configured as part of the uswsusp API [0]
    using a pointer to the inode struct in memory. If the swap device being
    written was not configured for resuming, the write request is denied.
    
    NOTE: this implementation works only for swap block devices, where the
    inode configured by swapon (which sets S_SWAPFILE) is the same used
    by SNAPSHOT_SET_SWAP_AREA.
    
    In case of swap file, SNAPSHOT_SET_SWAP_AREA indeed receives the inode
    of the block device containing the filesystem where the swap file is
    located (+ offset in it) which is never passed to swapon and then has
    not set S_SWAPFILE.
    
    As result, the swap file itself (as a file) has never an option to be
    written from userspace. Instead it remains writable if accessed directly
    from the containing block device, which is always writeable from root.
    
    [0] Documentation/power/userland-swsusp.rst
    
    v2:
     - rename is_hibernate_snapshot_dev() to is_hibernate_resume_dev()
     - fix description so to correctly refer to the resume device
    
    Signed-off-by: Domenico Andreoli <domenico.andreoli@linux.com>
    Acked-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 93672c3f1c78..608a7b9173f4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -2023,8 +2023,7 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 	if (bdev_read_only(I_BDEV(bd_inode)))
 		return -EPERM;
 
-	/* uswsusp needs write permission to the swap */
-	if (IS_SWAPFILE(bd_inode) && !hibernation_available())
+	if (IS_SWAPFILE(bd_inode) && !is_hibernate_resume_dev(bd_inode))
 		return -ETXTBSY;
 
 	if (!iov_iter_count(from))

commit 9398554fb3979852512ff4f1405e759889b45c16
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 13 14:36:00 2020 +0200

    block: remove the error_sector argument to blkdev_issue_flush
    
    The argument isn't used by any caller, and drivers don't fill out
    bi_sector for flush requests either.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ebd1507789d2..d1e08bba925a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -672,7 +672,7 @@ int blkdev_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 	 * i_mutex and doing so causes performance issues with concurrent
 	 * O_SYNC writers to a block device.
 	 */
-	error = blkdev_issue_flush(bdev, GFP_KERNEL, NULL);
+	error = blkdev_issue_flush(bdev, GFP_KERNEL);
 	if (error == -EOPNOTSUPP)
 		error = 0;
 

commit 3783daeb1d24696ff00125050353cfce4f5b6239
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 19 16:33:21 2020 +0200

    block: remove ioctl_by_bdev
    
    No callers left.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7cbb7b79935e..3003831c771d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -2166,18 +2166,6 @@ const struct file_operations def_blk_fops = {
 	.fallocate	= blkdev_fallocate,
 };
 
-int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)
-{
-	int res;
-	mm_segment_t old_fs = get_fs();
-	set_fs(KERNEL_DS);
-	res = blkdev_ioctl(bdev, 0, cmd, arg);
-	set_fs(old_fs);
-	return res;
-}
-
-EXPORT_SYMBOL(ioctl_by_bdev);
-
 /**
  * lookup_bdev  - lookup a struct block_device by name
  * @pathname:	special file representing the block device

commit e6249cdd46e43a7d3bdb8cce5fe24565d6c11e94
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sun May 3 09:54:22 2020 +0800

    block: add blk_io_schedule() for avoiding task hung in sync dio
    
    Sync dio could be big, or may take long time in discard or in case of
    IO failure.
    
    We have prevented task hung in submit_bio_wait() and blk_execute_rq(),
    so apply the same trick for prevent task hung from happening in sync dio.
    
    Add helper of blk_io_schedule() and use io_schedule_timeout() to prevent
    task hung warning.
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Cc: Salman Qazi <sqazi@google.com>
    Cc: Jesse Barnes <jsbarnes@google.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Cc: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7cbb7b79935e..ebd1507789d2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -255,7 +255,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 			break;
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
 		    !blk_poll(bdev_get_queue(bdev), qc, true))
-			io_schedule();
+			blk_io_schedule();
 	}
 	__set_current_state(TASK_RUNNING);
 
@@ -449,7 +449,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
 		    !blk_poll(bdev_get_queue(bdev), qc, true))
-			io_schedule();
+			blk_io_schedule();
 	}
 	__set_current_state(TASK_RUNNING);
 

commit 873f1c8df7e0dac2156a722f3c7848a30693a242
Merge: 8b075e5ba459 59c7c3caaaf8
Author: Jens Axboe <axboe@kernel.dk>
Date:   Sat May 9 16:13:58 2020 -0600

    Merge branch 'block-5.7' into for-5.8/block
    
    Pull in block-5.7 fixes for 5.8. Mostly to resolve a conflict with
    the blk-iocost changes, but we also need the base of the bdi
    use-after-free as well as we build on top of it.
    
    * block-5.7:
      nvme: fix possible hang when ns scanning fails during error recovery
      nvme-pci: fix "slimmer CQ head update"
      bdi: add a ->dev_name field to struct backing_dev_info
      bdi: use bdi_dev_name() to get device name
      bdi: move bdi_dev_name out of line
      vboxsf: don't use the source name in the bdi name
      iocost: protect iocg->abs_vdebt with iocg->waitq.lock
      block: remove the bd_openers checks in blk_drop_partitions
      nvme: prevent double free in nvme_alloc_ns() error handling
      null_blk: Cleanup zoned device initialization
      null_blk: Fix zoned command handling
      block: remove unused header
      blk-iocost: Fix error on iocost_ioc_vrate_adj
      bdev: Reduce time holding bd_mutex in sync in blkdev_close()
      buffer: remove useless comment and WB_REASON_FREE_MORE_MEM, reason.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 895d47759bdc4a8452e36ad3f7bc4324c9251932
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Apr 24 12:56:34 2020 +0200

    block: unexport bdev_read_page and bdev_write_page
    
    Each one just has two callers, both in always built-in code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 998820174d3e..5eb30a474f6d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -714,7 +714,6 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 	blk_queue_exit(bdev->bd_queue);
 	return result;
 }
-EXPORT_SYMBOL_GPL(bdev_read_page);
 
 /**
  * bdev_write_page() - Start writing a page to a block device
@@ -759,7 +758,6 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 	blk_queue_exit(bdev->bd_queue);
 	return result;
 }
-EXPORT_SYMBOL_GPL(bdev_write_page);
 
 /*
  * pseudo-fs

commit d56deb1e4e6696b2c70815beb8d1d39fc0063b1c
Author: Ma, Jianpeng <jianpeng.ma@intel.com>
Date:   Tue Apr 21 11:48:08 2020 +0000

    block: remove unused header
    
    Dax related code already removed from this file.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jianpeng Ma <jianpeng.ma@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 59435f07911a..93672c3f1c78 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -19,7 +19,6 @@
 #include <linux/module.h>
 #include <linux/blkpg.h>
 #include <linux/magic.h>
-#include <linux/dax.h>
 #include <linux/buffer_head.h>
 #include <linux/swap.h>
 #include <linux/pagevec.h>

commit 9bc5c397d8384b50c8202f4400bf2f87fe8291d9
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 14 09:29:02 2020 +0200

    block: fold bdev_unhash_inode into invalidate_partition
    
    invalidate_partition and bdev_unhash_inode are always paired, and
    invalidate_partition already does an icache lookup for the block device
    inode.  Piggy back on that to remove the inode from the hash.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9c8de54fa0c9..998820174d3e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -883,21 +883,6 @@ static int bdev_set(struct inode *inode, void *data)
 
 static LIST_HEAD(all_bdevs);
 
-/*
- * If there is a bdev inode for this device, unhash it so that it gets evicted
- * as soon as last inode reference is dropped.
- */
-void bdev_unhash_inode(dev_t dev)
-{
-	struct inode *inode;
-
-	inode = ilookup5(blockdev_superblock, hash(dev), bdev_test, &dev);
-	if (inode) {
-		remove_inode_hash(inode);
-		iput(inode);
-	}
-}
-
 struct block_device *bdget(dev_t dev)
 {
 	struct block_device *bdev;

commit d46430bf5a2298f55e20f59a90ebe3545d273b2f
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 14 09:28:57 2020 +0200

    block: remove the disk argument from blk_drop_partitions
    
    The gendisk can be trivially deducted from the block_device.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 52b6f646cdbd..9c8de54fa0c9 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1517,7 +1517,7 @@ int bdev_disk_changed(struct block_device *bdev, bool invalidate)
 	lockdep_assert_held(&bdev->bd_mutex);
 
 rescan:
-	ret = blk_drop_partitions(disk, bdev);
+	ret = blk_drop_partitions(bdev);
 	if (ret)
 		return ret;
 

commit b849dd84b6ccfe32622988b79b7b073861fcf9f7
Author: Douglas Anderson <dianders@chromium.org>
Date:   Tue Mar 24 14:48:27 2020 -0700

    bdev: Reduce time holding bd_mutex in sync in blkdev_close()
    
    While trying to "dd" to the block device for a USB stick, I
    encountered a hung task warning (blocked for > 120 seconds).  I
    managed to come up with an easy way to reproduce this on my system
    (where /dev/sdb is the block device for my USB stick) with:
    
      while true; do dd if=/dev/zero of=/dev/sdb bs=4M; done
    
    With my reproduction here are the relevant bits from the hung task
    detector:
    
     INFO: task udevd:294 blocked for more than 122 seconds.
     ...
     udevd           D    0   294      1 0x00400008
     Call trace:
      ...
      mutex_lock_nested+0x40/0x50
      __blkdev_get+0x7c/0x3d4
      blkdev_get+0x118/0x138
      blkdev_open+0x94/0xa8
      do_dentry_open+0x268/0x3a0
      vfs_open+0x34/0x40
      path_openat+0x39c/0xdf4
      do_filp_open+0x90/0x10c
      do_sys_open+0x150/0x3c8
      ...
    
     ...
     Showing all locks held in the system:
     ...
     1 lock held by dd/2798:
      #0: ffffff814ac1a3b8 (&bdev->bd_mutex){+.+.}, at: __blkdev_put+0x50/0x204
     ...
     dd              D    0  2798   2764 0x00400208
     Call trace:
      ...
      schedule+0x8c/0xbc
      io_schedule+0x1c/0x40
      wait_on_page_bit_common+0x238/0x338
      __lock_page+0x5c/0x68
      write_cache_pages+0x194/0x500
      generic_writepages+0x64/0xa4
      blkdev_writepages+0x24/0x30
      do_writepages+0x48/0xa8
      __filemap_fdatawrite_range+0xac/0xd8
      filemap_write_and_wait+0x30/0x84
      __blkdev_put+0x88/0x204
      blkdev_put+0xc4/0xe4
      blkdev_close+0x28/0x38
      __fput+0xe0/0x238
      ____fput+0x1c/0x28
      task_work_run+0xb0/0xe4
      do_notify_resume+0xfc0/0x14bc
      work_pending+0x8/0x14
    
    The problem appears related to the fact that my USB disk is terribly
    slow and that I have a lot of RAM in my system to cache things.
    Specifically my writes seem to be happening at ~15 MB/s and I've got
    ~4 GB of RAM in my system that can be used for buffering.  To write 4
    GB of buffer to disk thus takes ~4000 MB / ~15 MB/s = ~267 seconds.
    
    The 267 second number is a problem because in __blkdev_put() we call
    sync_blockdev() while holding the bd_mutex.  Any other callers who
    want the bd_mutex will be blocked for the whole time.
    
    The problem is made worse because I believe blkdev_put() specifically
    tells other tasks (namely udev) to go try to access the device at right
    around the same time we're going to hold the mutex for a long time.
    
    Putting some traces around this (after disabling the hung task detector),
    I could confirm:
     dd:    437.608600: __blkdev_put() right before sync_blockdev() for sdb
     udevd: 437.623901: blkdev_open() right before blkdev_get() for sdb
     dd:    661.468451: __blkdev_put() right after sync_blockdev() for sdb
     udevd: 663.820426: blkdev_open() right after blkdev_get() for sdb
    
    A simple fix for this is to realize that sync_blockdev() works fine if
    you're not holding the mutex.  Also, it's not the end of the world if
    you sync a little early (though it can have performance impacts).
    Thus we can make a guess that we're going to need to do the sync and
    then do it without holding the mutex.  We still do one last sync with
    the mutex but it should be much, much faster.
    
    With this, my hung task warnings for my test case are gone.
    
    Signed-off-by: Douglas Anderson <dianders@chromium.org>
    Reviewed-by: Guenter Roeck <groeck@chromium.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 52b6f646cdbd..59435f07911a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1893,6 +1893,16 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 	struct gendisk *disk = bdev->bd_disk;
 	struct block_device *victim = NULL;
 
+	/*
+	 * Sync early if it looks like we're the last one.  If someone else
+	 * opens the block device between now and the decrement of bd_openers
+	 * then we did a sync that we didn't need to, but that's not the end
+	 * of the world and we want to avoid long (could be several minute)
+	 * syncs while holding the mutex.
+	 */
+	if (bdev->bd_openers == 1)
+		sync_blockdev(bdev);
+
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (for_part)
 		bdev->bd_part_count--;

commit 7db83c070bd29e73c8bb42d4b48c976be76f1dbe
Merge: 35a9fafe230b 56939e014a6c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 2 12:59:36 2020 -0700

    Merge tag 'vfs-5.7-merge-1' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux
    
    Pull hibernation fix from Darrick Wong:
     "Fix a regression where we broke the userspace hibernation driver by
      disallowing writes to the swap device"
    
    * tag 'vfs-5.7-merge-1' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux:
      hibernate: Allow uswsusp to write to swap

commit 56939e014a6c212b317414faa307029e2e80c3b9
Author: Domenico Andreoli <domenico.andreoli@linux.com>
Date:   Mon Mar 23 08:22:15 2020 -0700

    hibernate: Allow uswsusp to write to swap
    
    It turns out that there is one use case for programs being able to
    write to swap devices, and that is the userspace hibernation code.
    
    Quick fix: disable the S_SWAPFILE check if hibernation is configured.
    
    Fixes: dc617f29dbe5 ("vfs: don't allow writes to swap files")
    Reported-by: Domenico Andreoli <domenico.andreoli@linux.com>
    Reported-by: Marian Klein <mkleinsoft@gmail.com>
    Signed-off-by: Domenico Andreoli <domenico.andreoli@linux.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 69bf2fb6f7cd..84fe0162ff13 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -34,6 +34,7 @@
 #include <linux/task_io_accounting_ops.h>
 #include <linux/falloc.h>
 #include <linux/uaccess.h>
+#include <linux/suspend.h>
 #include "internal.h"
 
 struct bdev_inode {
@@ -2001,7 +2002,8 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 	if (bdev_read_only(I_BDEV(bd_inode)))
 		return -EPERM;
 
-	if (IS_SWAPFILE(bd_inode))
+	/* uswsusp needs write permission to the swap */
+	if (IS_SWAPFILE(bd_inode) && !hibernation_available())
 		return -ETXTBSY;
 
 	if (!iov_iter_count(from))

commit d981cb5b9fa0da9da6a6c8b9ae7cbe789c3b3214
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Mar 18 09:12:06 2020 +0100

    block: fix a device invalidation regression
    
    Historically we only set the capacity to zero for devices that support
    partitions (independ of actually having partitions created).  Doing that
    is rather inconsistent, but changing it broke legacy udisks polling for
    legacy ide-cdrom devices.  Use the crude a crude check for devices that
    either are non-removable or partitionable to get the sane behavior for
    most device while not breaking userspace for this particular setup.
    
    Fixes: a1548b674403 ("block: move rescan_partitions to fs/block_dev.c")
    Reported-by: He Zhe <zhe.he@windriver.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Tested-by: He Zhe <zhe.he@windriver.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 69bf2fb6f7cd..9501880dff5e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1520,10 +1520,22 @@ int bdev_disk_changed(struct block_device *bdev, bool invalidate)
 	if (ret)
 		return ret;
 
-	if (invalidate)
-		set_capacity(disk, 0);
-	else if (disk->fops->revalidate_disk)
-		disk->fops->revalidate_disk(disk);
+	/*
+	 * Historically we only set the capacity to zero for devices that
+	 * support partitions (independ of actually having partitions created).
+	 * Doing that is rather inconsistent, but changing it broke legacy
+	 * udisks polling for legacy ide-cdrom devices.  Use the crude check
+	 * below to get the sane behavior for most device while not breaking
+	 * userspace for this particular setup.
+	 */
+	if (invalidate) {
+		if (disk_part_scan_enabled(disk) ||
+		    !(disk->flags & GENHD_FL_REMOVABLE))
+			set_capacity(disk, 0);
+	} else {
+		if (disk->fops->revalidate_disk)
+			disk->fops->revalidate_disk(disk);
+	}
 
 	check_disk_size_change(disk, bdev, !invalidate);
 

commit 490547ca2df66b8413bce97cb651630f2c531487
Author: Eric Biggers <ebiggers@google.com>
Date:   Mon Dec 2 10:21:34 2019 -0800

    block: don't send uevent for empty disk when not invalidating
    
    Commit 6917d0689993 ("block: merge invalidate_partitions into
    rescan_partitions") caused a regression where systemd-udevd spins
    forever using max CPU starting at boot time.
    
    It's caused by a behavior change where a KOBJ_CHANGE uevent is now sent
    in a case where previously it wasn't.
    
    Restore the old behavior.
    
    Fixes: 6917d0689993 ("block: merge invalidate_partitions into rescan_partitions")
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ee63c2732fa2..69bf2fb6f7cd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1531,7 +1531,7 @@ int bdev_disk_changed(struct block_device *bdev, bool invalidate)
 		ret = blk_add_partitions(disk, bdev);
 		if (ret == -EAGAIN)
 			goto rescan;
-	} else {
+	} else if (invalidate) {
 		/*
 		 * Tell userspace that the media / partition table may have
 		 * changed.

commit 979c690d9a017db14b7759a099478e3faad991ac
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 14 15:34:37 2019 +0100

    block: move clearing bd_invalidated into check_disk_size_change
    
    Both callers of check_disk_size_change clear bd_invalidate directly
    after the call, so move the clearing into check_disk_size_change
    itself.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9558a2f064b1..ee63c2732fa2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1433,6 +1433,7 @@ static void check_disk_size_change(struct gendisk *disk,
 		if (bdev_size > disk_size)
 			flush_disk(bdev, false);
 	}
+	bdev->bd_invalidated = 0;
 }
 
 /**
@@ -1462,7 +1463,6 @@ int revalidate_disk(struct gendisk *disk)
 
 		mutex_lock(&bdev->bd_mutex);
 		check_disk_size_change(disk, bdev, ret == 0);
-		bdev->bd_invalidated = 0;
 		mutex_unlock(&bdev->bd_mutex);
 		bdput(bdev);
 	}
@@ -1526,7 +1526,6 @@ int bdev_disk_changed(struct block_device *bdev, bool invalidate)
 		disk->fops->revalidate_disk(disk);
 
 	check_disk_size_change(disk, bdev, !invalidate);
-	bdev->bd_invalidated = 0;
 
 	if (get_capacity(disk)) {
 		ret = blk_add_partitions(disk, bdev);

commit f0b870df80bc70dad432fd0c142bb709a49964f5
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 14 15:34:36 2019 +0100

    block: remove (__)blkdev_reread_part as an exported API
    
    In general drivers should never mess with partition tables directly.
    Unfortunately s390 and loop do for somewhat historic reasons, but they
    can use bdev_disk_changed directly instead when we export it as they
    satisfy the sanity checks we have in __blkdev_reread_part.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Stefan Haberland <sth@linux.ibm.com>       [dasd]
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ae16466a67f7..9558a2f064b1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1513,6 +1513,8 @@ int bdev_disk_changed(struct block_device *bdev, bool invalidate)
 	struct gendisk *disk = bdev->bd_disk;
 	int ret;
 
+	lockdep_assert_held(&bdev->bd_mutex);
+
 rescan:
 	ret = blk_drop_partitions(disk, bdev);
 	if (ret)
@@ -1540,6 +1542,11 @@ int bdev_disk_changed(struct block_device *bdev, bool invalidate)
 
 	return ret;
 }
+/*
+ * Only exported for for loop and dasd for historic reasons.  Don't use in new
+ * code!
+ */
+EXPORT_SYMBOL_GPL(bdev_disk_changed);
 
 /*
  * bd_mutex locking:

commit 142fe8f4bb169e8632024d51c64653a8bf140561
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 14 15:34:35 2019 +0100

    block: fix bdev_disk_changed for non-partitioned devices
    
    We still have to set the capacity to 0 if invalidating or call
    revalidate_disk if not even if the disk has no partitions.  Fix
    that by merging rescan_partitions into bdev_disk_changed and just
    stubbing out blk_add_partitions and blk_drop_partitions for
    non-partitioned devices.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ec10dacd18d0..ae16466a67f7 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1508,9 +1508,9 @@ EXPORT_SYMBOL(bd_set_size);
 
 static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
-static int rescan_partitions(struct gendisk *disk, struct block_device *bdev,
-		bool invalidate)
+int bdev_disk_changed(struct block_device *bdev, bool invalidate)
 {
+	struct gendisk *disk = bdev->bd_disk;
 	int ret;
 
 rescan:
@@ -1526,32 +1526,21 @@ static int rescan_partitions(struct gendisk *disk, struct block_device *bdev,
 	check_disk_size_change(disk, bdev, !invalidate);
 	bdev->bd_invalidated = 0;
 
-	if (!get_capacity(disk)) {
+	if (get_capacity(disk)) {
+		ret = blk_add_partitions(disk, bdev);
+		if (ret == -EAGAIN)
+			goto rescan;
+	} else {
 		/*
 		 * Tell userspace that the media / partition table may have
 		 * changed.
 		 */
 		kobject_uevent(&disk_to_dev(disk)->kobj, KOBJ_CHANGE);
-		return 0;
 	}
 
-	ret = blk_add_partitions(disk, bdev);
-	if (ret == -EAGAIN)
-		goto rescan;
 	return ret;
 }
 
-
-static void bdev_disk_changed(struct block_device *bdev, bool invalidate)
-{
-	if (disk_part_scan_enabled(bdev->bd_disk)) {
-		rescan_partitions(bdev->bd_disk, bdev, invalidate);
-	} else {
-		check_disk_size_change(bdev->bd_disk, bdev, !invalidate);
-		bdev->bd_invalidated = 0;
-	}
-}
-
 /*
  * bd_mutex locking:
  *

commit a1548b674403c0de70cc29a1575689917ba60157
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 14 15:34:34 2019 +0100

    block: move rescan_partitions to fs/block_dev.c
    
    Large parts of rescan_partitions aren't about partitions, and
    moving it to block_dev.c will allow for some further cleanups by
    merging it into its only caller.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0af62b76d031..ec10dacd18d0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1416,8 +1416,8 @@ static void flush_disk(struct block_device *bdev, bool kill_dirty)
  * and adjusts it if it differs. When shrinking the bdev size, its all caches
  * are freed.
  */
-void check_disk_size_change(struct gendisk *disk, struct block_device *bdev,
-		bool verbose)
+static void check_disk_size_change(struct gendisk *disk,
+		struct block_device *bdev, bool verbose)
 {
 	loff_t disk_size, bdev_size;
 
@@ -1508,6 +1508,40 @@ EXPORT_SYMBOL(bd_set_size);
 
 static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
+static int rescan_partitions(struct gendisk *disk, struct block_device *bdev,
+		bool invalidate)
+{
+	int ret;
+
+rescan:
+	ret = blk_drop_partitions(disk, bdev);
+	if (ret)
+		return ret;
+
+	if (invalidate)
+		set_capacity(disk, 0);
+	else if (disk->fops->revalidate_disk)
+		disk->fops->revalidate_disk(disk);
+
+	check_disk_size_change(disk, bdev, !invalidate);
+	bdev->bd_invalidated = 0;
+
+	if (!get_capacity(disk)) {
+		/*
+		 * Tell userspace that the media / partition table may have
+		 * changed.
+		 */
+		kobject_uevent(&disk_to_dev(disk)->kobj, KOBJ_CHANGE);
+		return 0;
+	}
+
+	ret = blk_add_partitions(disk, bdev);
+	if (ret == -EAGAIN)
+		goto rescan;
+	return ret;
+}
+
+
 static void bdev_disk_changed(struct block_device *bdev, bool invalidate)
 {
 	if (disk_part_scan_enabled(bdev->bd_disk)) {

commit 6917d0689993f46d97d40dd66c601d0fd5b1dbdd
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 14 15:34:33 2019 +0100

    block: merge invalidate_partitions into rescan_partitions
    
    A lot of the logic in invalidate_partitions and rescan_partitions is
    shared.  Merge the two functions to simplify things.  There is a small
    behavior change in that we now send the kevent change notice also if we
    were not invalidating but no partitions were found, which seems like
    the right thing to do.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d612468ee66b..0af62b76d031 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1511,10 +1511,7 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 static void bdev_disk_changed(struct block_device *bdev, bool invalidate)
 {
 	if (disk_part_scan_enabled(bdev->bd_disk)) {
-		if (invalidate)
-			invalidate_partitions(bdev->bd_disk, bdev);
-		else
-			rescan_partitions(bdev->bd_disk, bdev);
+		rescan_partitions(bdev->bd_disk, bdev, invalidate);
 	} else {
 		check_disk_size_change(bdev->bd_disk, bdev, !invalidate);
 		bdev->bd_invalidated = 0;

commit cba22d86e0a10b7070d2e6a7379dbea51aa0883c
Author: Jan Kara <jack@suse.cz>
Date:   Mon Oct 21 10:38:00 2019 +0200

    bdev: Refresh bdev size for disks without partitioning
    
    Currently, block device size in not updated on second and further open
    for block devices where partition scan is disabled. This is particularly
    annoying for example for DVD drives as that means block device size does
    not get updated once the media is inserted into a drive if the device is
    already open when inserting the media. This is actually always the case
    for example when pktcdvd is in use.
    
    Fix the problem by revalidating block device size on every open even for
    devices with partition scan disabled.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 88c6d35ec71d..d612468ee66b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1403,11 +1403,7 @@ static void flush_disk(struct block_device *bdev, bool kill_dirty)
 		       "resized disk %s\n",
 		       bdev->bd_disk ? bdev->bd_disk->disk_name : "");
 	}
-
-	if (!bdev->bd_disk)
-		return;
-	if (disk_part_scan_enabled(bdev->bd_disk))
-		bdev->bd_invalidated = 1;
+	bdev->bd_invalidated = 1;
 }
 
 /**
@@ -1514,10 +1510,15 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
 static void bdev_disk_changed(struct block_device *bdev, bool invalidate)
 {
-	if (invalidate)
-		invalidate_partitions(bdev->bd_disk, bdev);
-	else
-		rescan_partitions(bdev->bd_disk, bdev);
+	if (disk_part_scan_enabled(bdev->bd_disk)) {
+		if (invalidate)
+			invalidate_partitions(bdev->bd_disk, bdev);
+		else
+			rescan_partitions(bdev->bd_disk, bdev);
+	} else {
+		check_disk_size_change(bdev->bd_disk, bdev, !invalidate);
+		bdev->bd_invalidated = 0;
+	}
 }
 
 /*

commit 731dc4868311ee097757b8746eaa1b4f8b2b4f1c
Author: Jan Kara <jack@suse.cz>
Date:   Mon Oct 21 10:37:59 2019 +0200

    bdev: Factor out bdev revalidation into a common helper
    
    Factor out code handling revalidation of bdev on disk change into a
    common helper.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9c073dbdc1b0..88c6d35ec71d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1512,6 +1512,14 @@ EXPORT_SYMBOL(bd_set_size);
 
 static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
+static void bdev_disk_changed(struct block_device *bdev, bool invalidate)
+{
+	if (invalidate)
+		invalidate_partitions(bdev->bd_disk, bdev);
+	else
+		rescan_partitions(bdev->bd_disk, bdev);
+}
+
 /*
  * bd_mutex locking:
  *
@@ -1594,12 +1602,9 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			 * The latter is necessary to prevent ghost
 			 * partitions on a removed medium.
 			 */
-			if (bdev->bd_invalidated) {
-				if (!ret)
-					rescan_partitions(disk, bdev);
-				else if (ret == -ENOMEDIUM)
-					invalidate_partitions(disk, bdev);
-			}
+			if (bdev->bd_invalidated &&
+			    (!ret || ret == -ENOMEDIUM))
+				bdev_disk_changed(bdev, ret == -ENOMEDIUM);
 
 			if (ret)
 				goto out_clear;
@@ -1632,12 +1637,9 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (bdev->bd_disk->fops->open)
 				ret = bdev->bd_disk->fops->open(bdev, mode);
 			/* the same as first opener case, read comment there */
-			if (bdev->bd_invalidated) {
-				if (!ret)
-					rescan_partitions(bdev->bd_disk, bdev);
-				else if (ret == -ENOMEDIUM)
-					invalidate_partitions(bdev->bd_disk, bdev);
-			}
+			if (bdev->bd_invalidated &&
+			    (!ret || ret == -ENOMEDIUM))
+				bdev_disk_changed(bdev, ret == -ENOMEDIUM);
 			if (ret)
 				goto out_unlock_bdev;
 		}

commit e6bc9de714972cac34daa1dc1567ee48a47a9342
Merge: b6c0d3577246 dc617f29dbe5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 18 17:35:20 2019 -0700

    Merge tag 'vfs-5.4-merge-1' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux
    
    Pull swap access updates from Darrick Wong:
     "Prohibit writing to active swap files and swap partitions.
    
      There's no non-malicious use case for allowing userspace to scribble
      on storage that the kernel thinks it owns"
    
    * tag 'vfs-5.4-merge-1' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux:
      vfs: don't allow writes to swap files
      mm: set S_SWAPFILE on blockdev swap devices

commit dc617f29dbe5ef0c8ced65ce62c464af1daaab3d
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Tue Aug 20 07:55:16 2019 -0700

    vfs: don't allow writes to swap files
    
    Don't let userspace write to an active swap file because the kernel
    effectively has a long term lease on the storage and things could get
    seriously corrupted if we let this happen.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c2a85b587922..d9bab63a9b81 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1978,6 +1978,9 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 	if (bdev_read_only(I_BDEV(bd_inode)))
 		return -EPERM;
 
+	if (IS_SWAPFILE(bd_inode))
+		return -ETXTBSY;
+
 	if (!iov_iter_count(from))
 		return 0;
 

commit 7b6620d7db566a46f49b4b9deab9fa061fd4b59b
Author: Jens Axboe <axboe@kernel.dk>
Date:   Thu Aug 15 11:09:16 2019 -0600

    block: remove REQ_NOWAIT_INLINE
    
    We had a few issues with this code, and there's still a problem around
    how we deal with error handling for chained/split bios. For now, just
    revert the code and we'll try again with a thoroug solution. This
    reverts commits:
    
    e15c2ffa1091 ("block: fix O_DIRECT error handling for bio fragments")
    0eb6ddfb865c ("block: Fix __blkdev_direct_IO() for bio fragments")
    6a43074e2f46 ("block: properly handle IOCB_NOWAIT for async O_DIRECT IO")
    893a1c97205a ("blk-mq: allow REQ_NOWAIT to return an error inline")
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index eb657ab94060..677cb364d33f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -345,24 +345,15 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	struct bio *bio;
 	bool is_poll = (iocb->ki_flags & IOCB_HIPRI) != 0;
 	bool is_read = (iov_iter_rw(iter) == READ), is_sync;
-	bool nowait = (iocb->ki_flags & IOCB_NOWAIT) != 0;
 	loff_t pos = iocb->ki_pos;
 	blk_qc_t qc = BLK_QC_T_NONE;
-	gfp_t gfp;
-	int ret;
+	int ret = 0;
 
 	if ((pos | iov_iter_alignment(iter)) &
 	    (bdev_logical_block_size(bdev) - 1))
 		return -EINVAL;
 
-	if (nowait)
-		gfp = GFP_NOWAIT;
-	else
-		gfp = GFP_KERNEL;
-
-	bio = bio_alloc_bioset(gfp, nr_pages, &blkdev_dio_pool);
-	if (!bio)
-		return -EAGAIN;
+	bio = bio_alloc_bioset(GFP_KERNEL, nr_pages, &blkdev_dio_pool);
 
 	dio = container_of(bio, struct blkdev_dio, bio);
 	dio->is_sync = is_sync = is_sync_kiocb(iocb);
@@ -384,7 +375,6 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	if (!is_poll)
 		blk_start_plug(&plug);
 
-	ret = 0;
 	for (;;) {
 		bio_set_dev(bio, bdev);
 		bio->bi_iter.bi_sector = pos >> 9;
@@ -409,14 +399,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			task_io_account_write(bio->bi_iter.bi_size);
 		}
 
-		/*
-		 * Tell underlying layer to not block for resource shortage.
-		 * And if we would have blocked, return error inline instead
-		 * of through the bio->bi_end_io() callback.
-		 */
-		if (nowait)
-			bio->bi_opf |= (REQ_NOWAIT | REQ_NOWAIT_INLINE);
-
+		dio->size += bio->bi_iter.bi_size;
 		pos += bio->bi_iter.bi_size;
 
 		nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES);
@@ -428,13 +411,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 				polled = true;
 			}
 
-			dio->size += bio->bi_iter.bi_size;
 			qc = submit_bio(bio);
-			if (qc == BLK_QC_T_EAGAIN) {
-				dio->size -= bio->bi_iter.bi_size;
-				ret = -EAGAIN;
-				goto error;
-			}
 
 			if (polled)
 				WRITE_ONCE(iocb->ki_cookie, qc);
@@ -455,19 +432,8 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			atomic_inc(&dio->ref);
 		}
 
-		dio->size += bio->bi_iter.bi_size;
-		qc = submit_bio(bio);
-		if (qc == BLK_QC_T_EAGAIN) {
-			dio->size -= bio->bi_iter.bi_size;
-			ret = -EAGAIN;
-			goto error;
-		}
-
-		bio = bio_alloc(gfp, nr_pages);
-		if (!bio) {
-			ret = -EAGAIN;
-			goto error;
-		}
+		submit_bio(bio);
+		bio = bio_alloc(GFP_KERNEL, nr_pages);
 	}
 
 	if (!is_poll)
@@ -487,7 +453,6 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	}
 	__set_current_state(TASK_RUNNING);
 
-out:
 	if (!ret)
 		ret = blk_status_to_errno(dio->bio.bi_status);
 	if (likely(!ret))
@@ -495,10 +460,6 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 	bio_put(&dio->bio);
 	return ret;
-error:
-	if (!is_poll)
-		blk_finish_plug(&plug);
-	goto out;
 }
 
 static ssize_t

commit e91455bad5cff40a8c232f2204a5104127e3fec2
Author: Jan Kara <jack@suse.cz>
Date:   Wed Aug 7 11:36:47 2019 +0200

    bdev: Fixup error handling in blkdev_get()
    
    Commit 89e524c04fa9 ("loop: Fix mount(2) failure due to race with
    LOOP_SET_FD") converted blkdev_get() to use the new helpers for
    finishing claiming of a block device. However the conversion botched the
    error handling in blkdev_get() and thus the bdev has been marked as held
    even in case __blkdev_get() returned error. This led to occasional
    warnings with block/001 test from blktests like:
    
    kernel: WARNING: CPU: 5 PID: 907 at fs/block_dev.c:1899 __blkdev_put+0x396/0x3a0
    
    Correct the error handling.
    
    CC: stable@vger.kernel.org
    Fixes: 89e524c04fa9 ("loop: Fix mount(2) failure due to race with LOOP_SET_FD")
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 131e2e0582a6..eb657ab94060 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1750,7 +1750,10 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 
 		/* finish claiming */
 		mutex_lock(&bdev->bd_mutex);
-		bd_finish_claiming(bdev, whole, holder);
+		if (!res)
+			bd_finish_claiming(bdev, whole, holder);
+		else
+			bd_abort_claiming(bdev, whole, holder);
 		/*
 		 * Block event polling for write claims if requested.  Any
 		 * write holder makes the write_holder state stick until

commit e15c2ffa1091c4f72370f01af4de8f9dddeb17a6
Author: Jens Axboe <axboe@kernel.dk>
Date:   Tue Aug 6 13:34:31 2019 -0600

    block: fix O_DIRECT error handling for bio fragments
    
    0eb6ddfb865c tried to fix this up, but introduced a use-after-free
    of dio. Additionally, we still had an issue with error handling,
    as reported by Darrick:
    
    "I noticed a regression in xfs/747 (an unreleased xfstest for the
    xfs_scrub media scanning feature) on 5.3-rc3.  I'll condense that down
    to a simpler reproducer:
    
    error-test: 0 209 linear 8:48 0
    error-test: 209 1 error
    error-test: 210 6446894 linear 8:48 210
    
    Basically we have a ~3G /dev/sdd and we set up device mapper to fail IO
    for sector 209 and to pass the io to the scsi device everywhere else.
    
    On 5.3-rc3, performing a directio pread of this range with a < 1M buffer
    (in other words, a request for fewer than MAX_BIO_PAGES bytes) yields
    EIO like you'd expect:
    
    pread64(3, 0x7f880e1c7000, 1048576, 0)  = -1 EIO (Input/output error)
    pread: Input/output error
    +++ exited with 0 +++
    
    But doing it with a larger buffer succeeds(!):
    
    pread64(3, "XFSB\0\0\20\0\0\0\0\0\0\fL\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"..., 1146880, 0) = 1146880
    read 1146880/1146880 bytes at offset 0
    1 MiB, 1 ops; 0.0009 sec (1.124 GiB/sec and 1052.6316 ops/sec)
    +++ exited with 0 +++
    
    (Note that the part of the buffer corresponding to the dm-error area is
    uninitialized)
    
    On 5.3-rc2, both commands would fail with EIO like you'd expect.  The
    only change between rc2 and rc3 is commit 0eb6ddfb865c ("block: Fix
    __blkdev_direct_IO() for bio fragments").
    
    AFAICT we end up in __blkdev_direct_IO with a 1120K buffer, which gets
    split into two bios: one for the first BIO_MAX_PAGES worth of data (1MB)
    and a second one for the 96k after that."
    
    Fix this by noting that it's always safe to dereference dio if we get
    BLK_QC_T_EAGAIN returned, as end_io hasn't been run for that case. So
    we can safely increment the dio size before calling submit_bio(), and
    then decrement it on failure (not that it really matters, as the bio
    and dio are going away).
    
    For error handling, return to the original method of just using 'ret'
    for tracking the error, and the size tracking in dio->size.
    
    Fixes: 0eb6ddfb865c ("block: Fix __blkdev_direct_IO() for bio fragments")
    Fixes: 6a43074e2f46 ("block: properly handle IOCB_NOWAIT for async O_DIRECT IO")
    Reported-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a6f7c892cb4a..131e2e0582a6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -349,7 +349,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	loff_t pos = iocb->ki_pos;
 	blk_qc_t qc = BLK_QC_T_NONE;
 	gfp_t gfp;
-	ssize_t ret;
+	int ret;
 
 	if ((pos | iov_iter_alignment(iter)) &
 	    (bdev_logical_block_size(bdev) - 1))
@@ -386,8 +386,6 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 	ret = 0;
 	for (;;) {
-		int err;
-
 		bio_set_dev(bio, bdev);
 		bio->bi_iter.bi_sector = pos >> 9;
 		bio->bi_write_hint = iocb->ki_hint;
@@ -395,10 +393,8 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		bio->bi_end_io = blkdev_bio_end_io;
 		bio->bi_ioprio = iocb->ki_ioprio;
 
-		err = bio_iov_iter_get_pages(bio, iter);
-		if (unlikely(err)) {
-			if (!ret)
-				ret = err;
+		ret = bio_iov_iter_get_pages(bio, iter);
+		if (unlikely(ret)) {
 			bio->bi_status = BLK_STS_IOERR;
 			bio_endio(bio);
 			break;
@@ -421,7 +417,6 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		if (nowait)
 			bio->bi_opf |= (REQ_NOWAIT | REQ_NOWAIT_INLINE);
 
-		dio->size += bio->bi_iter.bi_size;
 		pos += bio->bi_iter.bi_size;
 
 		nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES);
@@ -433,13 +428,13 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 				polled = true;
 			}
 
+			dio->size += bio->bi_iter.bi_size;
 			qc = submit_bio(bio);
 			if (qc == BLK_QC_T_EAGAIN) {
-				if (!ret)
-					ret = -EAGAIN;
+				dio->size -= bio->bi_iter.bi_size;
+				ret = -EAGAIN;
 				goto error;
 			}
-			ret = dio->size;
 
 			if (polled)
 				WRITE_ONCE(iocb->ki_cookie, qc);
@@ -460,18 +455,17 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			atomic_inc(&dio->ref);
 		}
 
+		dio->size += bio->bi_iter.bi_size;
 		qc = submit_bio(bio);
 		if (qc == BLK_QC_T_EAGAIN) {
-			if (!ret)
-				ret = -EAGAIN;
+			dio->size -= bio->bi_iter.bi_size;
+			ret = -EAGAIN;
 			goto error;
 		}
-		ret = dio->size;
 
 		bio = bio_alloc(gfp, nr_pages);
 		if (!bio) {
-			if (!ret)
-				ret = -EAGAIN;
+			ret = -EAGAIN;
 			goto error;
 		}
 	}
@@ -496,6 +490,8 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 out:
 	if (!ret)
 		ret = blk_status_to_errno(dio->bio.bi_status);
+	if (likely(!ret))
+		ret = dio->size;
 
 	bio_put(&dio->bio);
 	return ret;

commit 0eb6ddfb865c7d7ec05cb330050671363515e67f
Author: Damien Le Moal <damien.lemoal@wdc.com>
Date:   Thu Aug 1 19:21:51 2019 +0900

    block: Fix __blkdev_direct_IO() for bio fragments
    
    The recent fix to properly handle IOCB_NOWAIT for async O_DIRECT IO
    (patch 6a43074e2f46) introduced two problems with BIO fragment handling
    for direct IOs:
    1) The dio size processed is calculated by incrementing the ret variable
    by the size of the bio fragment issued for the dio. However, this size
    is obtained directly from bio->bi_iter.bi_size AFTER the bio submission
    which may result in referencing the bi_size value after the bio
    completed, resulting in an incorrect value use.
    2) The ret variable is not incremented by the size of the last bio
    fragment issued for the bio, leading to an invalid IO size being
    returned to the user.
    
    Fix both problem by using dio->size (which is incremented before the bio
    submission) to update the value of ret after bio submissions, including
    for the last bio fragment issued.
    
    Fixes: 6a43074e2f46 ("block: properly handle IOCB_NOWAIT for async O_DIRECT IO")
    Reported-by: Masato Suzuki <masato.suzuki@wdc.com>
    Signed-off-by: Damien Le Moal <damien.lemoal@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 22591bad9353..a6f7c892cb4a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -439,6 +439,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 					ret = -EAGAIN;
 				goto error;
 			}
+			ret = dio->size;
 
 			if (polled)
 				WRITE_ONCE(iocb->ki_cookie, qc);
@@ -465,7 +466,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 				ret = -EAGAIN;
 			goto error;
 		}
-		ret += bio->bi_iter.bi_size;
+		ret = dio->size;
 
 		bio = bio_alloc(gfp, nr_pages);
 		if (!bio) {

commit 89e524c04fa966330e2e80ab2bc50b9944c5847a
Author: Jan Kara <jack@suse.cz>
Date:   Tue Jul 30 13:10:14 2019 +0200

    loop: Fix mount(2) failure due to race with LOOP_SET_FD
    
    Commit 33ec3e53e7b1 ("loop: Don't change loop device under exclusive
    opener") made LOOP_SET_FD ioctl acquire exclusive block device reference
    while it updates loop device binding. However this can make perfectly
    valid mount(2) fail with EBUSY due to racing LOOP_SET_FD holding
    temporarily the exclusive bdev reference in cases like this:
    
    for i in {a..z}{a..z}; do
            dd if=/dev/zero of=$i.image bs=1k count=0 seek=1024
            mkfs.ext2 $i.image
            mkdir mnt$i
    done
    
    echo "Run"
    for i in {a..z}{a..z}; do
            mount -o loop -t ext2 $i.image mnt$i &
    done
    
    Fix the problem by not getting full exclusive bdev reference in
    LOOP_SET_FD but instead just mark the bdev as being claimed while we
    update the binding information. This just blocks new exclusive openers
    instead of failing them with EBUSY thus fixing the problem.
    
    Fixes: 33ec3e53e7b1 ("loop: Don't change loop device under exclusive opener")
    Cc: stable@vger.kernel.org
    Tested-by: Kai-Heng Feng <kai.heng.feng@canonical.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c2a85b587922..22591bad9353 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1181,8 +1181,7 @@ static struct gendisk *bdev_get_gendisk(struct block_device *bdev, int *partno)
  * Pointer to the block device containing @bdev on success, ERR_PTR()
  * value on failure.
  */
-static struct block_device *bd_start_claiming(struct block_device *bdev,
-					      void *holder)
+struct block_device *bd_start_claiming(struct block_device *bdev, void *holder)
 {
 	struct gendisk *disk;
 	struct block_device *whole;
@@ -1229,6 +1228,62 @@ static struct block_device *bd_start_claiming(struct block_device *bdev,
 		return ERR_PTR(err);
 	}
 }
+EXPORT_SYMBOL(bd_start_claiming);
+
+static void bd_clear_claiming(struct block_device *whole, void *holder)
+{
+	lockdep_assert_held(&bdev_lock);
+	/* tell others that we're done */
+	BUG_ON(whole->bd_claiming != holder);
+	whole->bd_claiming = NULL;
+	wake_up_bit(&whole->bd_claiming, 0);
+}
+
+/**
+ * bd_finish_claiming - finish claiming of a block device
+ * @bdev: block device of interest
+ * @whole: whole block device (returned from bd_start_claiming())
+ * @holder: holder that has claimed @bdev
+ *
+ * Finish exclusive open of a block device. Mark the device as exlusively
+ * open by the holder and wake up all waiters for exclusive open to finish.
+ */
+void bd_finish_claiming(struct block_device *bdev, struct block_device *whole,
+			void *holder)
+{
+	spin_lock(&bdev_lock);
+	BUG_ON(!bd_may_claim(bdev, whole, holder));
+	/*
+	 * Note that for a whole device bd_holders will be incremented twice,
+	 * and bd_holder will be set to bd_may_claim before being set to holder
+	 */
+	whole->bd_holders++;
+	whole->bd_holder = bd_may_claim;
+	bdev->bd_holders++;
+	bdev->bd_holder = holder;
+	bd_clear_claiming(whole, holder);
+	spin_unlock(&bdev_lock);
+}
+EXPORT_SYMBOL(bd_finish_claiming);
+
+/**
+ * bd_abort_claiming - abort claiming of a block device
+ * @bdev: block device of interest
+ * @whole: whole block device (returned from bd_start_claiming())
+ * @holder: holder that has claimed @bdev
+ *
+ * Abort claiming of a block device when the exclusive open failed. This can be
+ * also used when exclusive open is not actually desired and we just needed
+ * to block other exclusive openers for a while.
+ */
+void bd_abort_claiming(struct block_device *bdev, struct block_device *whole,
+		       void *holder)
+{
+	spin_lock(&bdev_lock);
+	bd_clear_claiming(whole, holder);
+	spin_unlock(&bdev_lock);
+}
+EXPORT_SYMBOL(bd_abort_claiming);
 
 #ifdef CONFIG_SYSFS
 struct bd_holder_disk {
@@ -1698,29 +1753,7 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 
 		/* finish claiming */
 		mutex_lock(&bdev->bd_mutex);
-		spin_lock(&bdev_lock);
-
-		if (!res) {
-			BUG_ON(!bd_may_claim(bdev, whole, holder));
-			/*
-			 * Note that for a whole device bd_holders
-			 * will be incremented twice, and bd_holder
-			 * will be set to bd_may_claim before being
-			 * set to holder
-			 */
-			whole->bd_holders++;
-			whole->bd_holder = bd_may_claim;
-			bdev->bd_holders++;
-			bdev->bd_holder = holder;
-		}
-
-		/* tell others that we're done */
-		BUG_ON(whole->bd_claiming != holder);
-		whole->bd_claiming = NULL;
-		wake_up_bit(&whole->bd_claiming, 0);
-
-		spin_unlock(&bdev_lock);
-
+		bd_finish_claiming(bdev, whole, holder);
 		/*
 		 * Block event polling for write claims if requested.  Any
 		 * write holder makes the write_holder state stick until

commit 04412819652fe30f900d11e96c67b4adfdf17f6b
Merge: 750c930b085b 9c0b2596f2ac
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 26 10:32:12 2019 -0700

    Merge tag 'for-linus-20190726' of git://git.kernel.dk/linux-block
    
    Pull block fixes from Jens Axboe:
    
     - Several io_uring fixes/improvements:
         - Blocking fix for O_DIRECT (me)
         - Latter page slowness for registered buffers (me)
         - Fix poll hang under certain conditions (me)
         - Defer sequence check fix for wrapped rings (Zhengyuan)
         - Mismatch in async inc/dec accounting (Zhengyuan)
         - Memory ordering issue that could cause stall (Zhengyuan)
          - Track sequential defer in bytes, not pages (Zhengyuan)
    
     - NVMe pull request from Christoph
    
     - Set of hang fixes for wbt (Josef)
    
     - Redundant error message kill for libahci (Ding)
    
     - Remove unused blk_mq_sched_started_request() and related ops (Marcos)
    
     - drbd dynamic alloc shash descriptor to reduce stack use (Arnd)
    
     - blkcg ->pd_stat() non-debug print (Tejun)
    
     - bcache memory leak fix (Wei)
    
     - Comment fix (Akinobu)
    
     - BFQ perf regression fix (Paolo)
    
    * tag 'for-linus-20190726' of git://git.kernel.dk/linux-block: (24 commits)
      io_uring: ensure ->list is initialized for poll commands
      Revert "nvme-pci: don't create a read hctx mapping without read queues"
      nvme: fix multipath crash when ANA is deactivated
      nvme: fix memory leak caused by incorrect subsystem free
      nvme: ignore subnqn for ADATA SX6000LNP
      drbd: dynamically allocate shash descriptor
      block: blk-mq: Remove blk_mq_sched_started_request and started_request
      bcache: fix possible memory leak in bch_cached_dev_run()
      io_uring: track io length in async_list based on bytes
      io_uring: don't use iov_iter_advance() for fixed buffers
      block: properly handle IOCB_NOWAIT for async O_DIRECT IO
      blk-mq: allow REQ_NOWAIT to return an error inline
      io_uring: add a memory barrier before atomic_read
      rq-qos: use a mb for got_token
      rq-qos: set ourself TASK_UNINTERRUPTIBLE after we schedule
      rq-qos: don't reset has_sleepers on spurious wakeups
      rq-qos: fix missed wake-ups in rq_qos_throttle
      wait: add wq_has_single_sleeper helper
      block, bfq: check also in-flight I/O in dispatch plugging
      block: fix sysfs module parameters directory path in comment
      ...

commit 6a43074e2f461c2c49a607f9f6f5218d53f97d1e
Author: Jens Axboe <axboe@kernel.dk>
Date:   Tue Jul 16 13:56:42 2019 -0600

    block: properly handle IOCB_NOWAIT for async O_DIRECT IO
    
    A caller is supposed to pass in REQ_NOWAIT if we can't block for any
    given operation, but O_DIRECT for block devices just ignore this. Hence
    we'll block for various resource shortages on the block layer side,
    like having to wait for requests.
    
    Use the new REQ_NOWAIT_INLINE to ask for this error to be returned
    inline, so we can handle it appropriately and return -EAGAIN to the
    caller.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f00b569a9f89..5dc613eec4d2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -344,15 +344,24 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	struct bio *bio;
 	bool is_poll = (iocb->ki_flags & IOCB_HIPRI) != 0;
 	bool is_read = (iov_iter_rw(iter) == READ), is_sync;
+	bool nowait = (iocb->ki_flags & IOCB_NOWAIT) != 0;
 	loff_t pos = iocb->ki_pos;
 	blk_qc_t qc = BLK_QC_T_NONE;
-	int ret = 0;
+	gfp_t gfp;
+	ssize_t ret;
 
 	if ((pos | iov_iter_alignment(iter)) &
 	    (bdev_logical_block_size(bdev) - 1))
 		return -EINVAL;
 
-	bio = bio_alloc_bioset(GFP_KERNEL, nr_pages, &blkdev_dio_pool);
+	if (nowait)
+		gfp = GFP_NOWAIT;
+	else
+		gfp = GFP_KERNEL;
+
+	bio = bio_alloc_bioset(gfp, nr_pages, &blkdev_dio_pool);
+	if (!bio)
+		return -EAGAIN;
 
 	dio = container_of(bio, struct blkdev_dio, bio);
 	dio->is_sync = is_sync = is_sync_kiocb(iocb);
@@ -374,7 +383,10 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	if (!is_poll)
 		blk_start_plug(&plug);
 
+	ret = 0;
 	for (;;) {
+		int err;
+
 		bio_set_dev(bio, bdev);
 		bio->bi_iter.bi_sector = pos >> 9;
 		bio->bi_write_hint = iocb->ki_hint;
@@ -382,8 +394,10 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		bio->bi_end_io = blkdev_bio_end_io;
 		bio->bi_ioprio = iocb->ki_ioprio;
 
-		ret = bio_iov_iter_get_pages(bio, iter);
-		if (unlikely(ret)) {
+		err = bio_iov_iter_get_pages(bio, iter);
+		if (unlikely(err)) {
+			if (!ret)
+				ret = err;
 			bio->bi_status = BLK_STS_IOERR;
 			bio_endio(bio);
 			break;
@@ -398,6 +412,14 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			task_io_account_write(bio->bi_iter.bi_size);
 		}
 
+		/*
+		 * Tell underlying layer to not block for resource shortage.
+		 * And if we would have blocked, return error inline instead
+		 * of through the bio->bi_end_io() callback.
+		 */
+		if (nowait)
+			bio->bi_opf |= (REQ_NOWAIT | REQ_NOWAIT_INLINE);
+
 		dio->size += bio->bi_iter.bi_size;
 		pos += bio->bi_iter.bi_size;
 
@@ -411,6 +433,11 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			}
 
 			qc = submit_bio(bio);
+			if (qc == BLK_QC_T_EAGAIN) {
+				if (!ret)
+					ret = -EAGAIN;
+				goto error;
+			}
 
 			if (polled)
 				WRITE_ONCE(iocb->ki_cookie, qc);
@@ -431,8 +458,20 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			atomic_inc(&dio->ref);
 		}
 
-		submit_bio(bio);
-		bio = bio_alloc(GFP_KERNEL, nr_pages);
+		qc = submit_bio(bio);
+		if (qc == BLK_QC_T_EAGAIN) {
+			if (!ret)
+				ret = -EAGAIN;
+			goto error;
+		}
+		ret += bio->bi_iter.bi_size;
+
+		bio = bio_alloc(gfp, nr_pages);
+		if (!bio) {
+			if (!ret)
+				ret = -EAGAIN;
+			goto error;
+		}
 	}
 
 	if (!is_poll)
@@ -452,13 +491,16 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	}
 	__set_current_state(TASK_RUNNING);
 
+out:
 	if (!ret)
 		ret = blk_status_to_errno(dio->bio.bi_status);
-	if (likely(!ret))
-		ret = dio->size;
 
 	bio_put(&dio->bio);
 	return ret;
+error:
+	if (!is_poll)
+		blk_finish_plug(&plug);
+	goto out;
 }
 
 static ssize_t

commit 933a90bf4f3505f8ec83bda21a3c7d70d7c2b426
Merge: 5f4fc6d440d7 037f11b4752f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 19 10:42:02 2019 -0700

    Merge branch 'work.mount0' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs mount updates from Al Viro:
     "The first part of mount updates.
    
      Convert filesystems to use the new mount API"
    
    * 'work.mount0' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (63 commits)
      mnt_init(): call shmem_init() unconditionally
      constify ksys_mount() string arguments
      don't bother with registering rootfs
      init_rootfs(): don't bother with init_ramfs_fs()
      vfs: Convert smackfs to use the new mount API
      vfs: Convert selinuxfs to use the new mount API
      vfs: Convert securityfs to use the new mount API
      vfs: Convert apparmorfs to use the new mount API
      vfs: Convert openpromfs to use the new mount API
      vfs: Convert xenfs to use the new mount API
      vfs: Convert gadgetfs to use the new mount API
      vfs: Convert oprofilefs to use the new mount API
      vfs: Convert ibmasmfs to use the new mount API
      vfs: Convert qib_fs/ipathfs to use the new mount API
      vfs: Convert efivarfs to use the new mount API
      vfs: Convert configfs to use the new mount API
      vfs: Convert binfmt_misc to use the new mount API
      convenience helper: get_tree_single()
      convenience helper get_tree_nodev()
      vfs: Kill sget_userns()
      ...

commit 9fec4a21886e67c3337e1762eda9f71a1822cba8
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 26 15:49:26 2019 +0200

    block_dev: use bio_release_pages in bio_unmap_user
    
    Use bio_release_pages instead of duplicating it.
    
    Reviewed-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a6572a811880..f00b569a9f89 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -203,13 +203,12 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 {
 	struct file *file = iocb->ki_filp;
 	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
-	struct bio_vec inline_vecs[DIO_INLINE_BIO_VECS], *vecs, *bvec;
+	struct bio_vec inline_vecs[DIO_INLINE_BIO_VECS], *vecs;
 	loff_t pos = iocb->ki_pos;
 	bool should_dirty = false;
 	struct bio bio;
 	ssize_t ret;
 	blk_qc_t qc;
-	struct bvec_iter_all iter_all;
 
 	if ((pos | iov_iter_alignment(iter)) &
 	    (bdev_logical_block_size(bdev) - 1))
@@ -259,13 +258,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	}
 	__set_current_state(TASK_RUNNING);
 
-	bio_for_each_segment_all(bvec, &bio, iter_all) {
-		if (should_dirty && !PageCompound(bvec->bv_page))
-			set_page_dirty_lock(bvec->bv_page);
-		if (!bio_flagged(&bio, BIO_NO_PAGE_REF))
-			put_page(bvec->bv_page);
-	}
-
+	bio_release_pages(&bio, should_dirty);
 	if (unlikely(bio.bi_status))
 		ret = blk_status_to_errno(bio.bi_status);
 

commit 57dfe3ce10e5cecfb3d073e90c0454f432a86873
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 26 15:49:25 2019 +0200

    block_dev: use bio_release_pages in blkdev_bio_end_io
    
    Use bio_release_pages instead of duplicating it.
    
    Reviewed-by: Minwoo Im <minwoo.im.dev@gmail.com>
    Reviewed-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 749f5984425d..a6572a811880 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -335,13 +335,7 @@ static void blkdev_bio_end_io(struct bio *bio)
 	if (should_dirty) {
 		bio_check_pages_dirty(bio);
 	} else {
-		if (!bio_flagged(bio, BIO_NO_PAGE_REF)) {
-			struct bvec_iter_all iter_all;
-			struct bio_vec *bvec;
-
-			bio_for_each_segment_all(bvec, bio, iter_all)
-				put_page(bvec->bv_page);
-		}
+		bio_release_pages(bio, false);
 		bio_put(bio);
 	}
 }

commit 31cb1d64da4ebd214348cad9d86e663c831c45fc
Author: Jan Kara <jack@suse.cz>
Date:   Wed May 15 08:57:40 2019 +0200

    block: Don't revalidate bdev of hidden gendisk
    
    When hidden gendisk is revalidated, there's no point in revalidating
    associated block device as there's none. We would thus just create new
    bdev inode, report "detected capacity change from 0 to XXX" message and
    evict the bdev inode again. Avoid this pointless dance and confusing
    message in the kernel log.
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e6886c93c89d..749f5984425d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1406,20 +1406,27 @@ void check_disk_size_change(struct gendisk *disk, struct block_device *bdev,
  */
 int revalidate_disk(struct gendisk *disk)
 {
-	struct block_device *bdev;
 	int ret = 0;
 
 	if (disk->fops->revalidate_disk)
 		ret = disk->fops->revalidate_disk(disk);
-	bdev = bdget_disk(disk, 0);
-	if (!bdev)
-		return ret;
 
-	mutex_lock(&bdev->bd_mutex);
-	check_disk_size_change(disk, bdev, ret == 0);
-	bdev->bd_invalidated = 0;
-	mutex_unlock(&bdev->bd_mutex);
-	bdput(bdev);
+	/*
+	 * Hidden disks don't have associated bdev so there's no point in
+	 * revalidating it.
+	 */
+	if (!(disk->flags & GENHD_FL_HIDDEN)) {
+		struct block_device *bdev = bdget_disk(disk, 0);
+
+		if (!bdev)
+			return ret;
+
+		mutex_lock(&bdev->bd_mutex);
+		check_disk_size_change(disk, bdev, ret == 0);
+		bdev->bd_invalidated = 0;
+		mutex_unlock(&bdev->bd_mutex);
+		bdput(bdev);
+	}
 	return ret;
 }
 EXPORT_SYMBOL(revalidate_disk);

commit 9030d16eb8adcbf9e80d20b909856c6fdabfdec4
Author: David Howells <dhowells@redhat.com>
Date:   Mon Mar 25 16:38:23 2019 +0000

    vfs: Convert bdev to use the new mount API
    
    Convert the bdev filesystem to the new internal mount API as the old
    one will be obsoleted and removed.  This allows greater flexibility in
    communication of mount parameters between userspace, the VFS and the
    filesystem.
    
    See Documentation/filesystems/mount_api.txt for more information.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Jens Axboe <axboe@kernel.dk>
    cc: linux-fsdevel@vger.kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 3143da7b0998..1d051b962159 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -25,6 +25,7 @@
 #include <linux/writeback.h>
 #include <linux/mpage.h>
 #include <linux/mount.h>
+#include <linux/pseudo_fs.h>
 #include <linux/uio.h>
 #include <linux/namei.h>
 #include <linux/log2.h>
@@ -833,19 +834,19 @@ static const struct super_operations bdev_sops = {
 	.evict_inode = bdev_evict_inode,
 };
 
-static struct dentry *bd_mount(struct file_system_type *fs_type,
-	int flags, const char *dev_name, void *data)
+static int bd_init_fs_context(struct fs_context *fc)
 {
-	struct dentry *dent;
-	dent = mount_pseudo(fs_type, &bdev_sops, NULL, BDEVFS_MAGIC);
-	if (!IS_ERR(dent))
-		dent->d_sb->s_iflags |= SB_I_CGROUPWB;
-	return dent;
+	struct pseudo_fs_context *ctx = init_pseudo(fc, BDEVFS_MAGIC);
+	if (!ctx)
+		return -ENOMEM;
+	fc->s_iflags |= SB_I_CGROUPWB;
+	ctx->ops = &bdev_sops;
+	return 0;
 }
 
 static struct file_system_type bd_type = {
 	.name		= "bdev",
-	.mount		= bd_mount,
+	.init_fs_context = bd_init_fs_context,
 	.kill_sb	= kill_anon_super,
 };
 

commit 1f58bb18f6f28d1df0b7144d90bc90ee5672416d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon May 20 13:44:57 2019 +0100

    mount_pseudo(): drop 'name' argument, switch to d_make_root()
    
    Once upon a time we used to set ->d_name of e.g. pipefs root
    so that d_path() on pipes would work.  These days it's
    completely pointless - dentries of pipes are not even connected
    to pipefs root.  However, mount_pseudo() had set the root
    dentry name (passed as the second argument) and callers
    kept inventing names to pass to it.  Including those that
    didn't *have* any non-root dentries to start with...
    
    All of that had been pointless for about 8 years now; it's
    time to get rid of that cargo-culting...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0f7552a87d54..3143da7b0998 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -837,7 +837,7 @@ static struct dentry *bd_mount(struct file_system_type *fs_type,
 	int flags, const char *dev_name, void *data)
 {
 	struct dentry *dent;
-	dent = mount_pseudo(fs_type, "bdev:", &bdev_sops, NULL, BDEVFS_MAGIC);
+	dent = mount_pseudo(fs_type, &bdev_sops, NULL, BDEVFS_MAGIC);
 	if (!IS_ERR(dent))
 		dent->d_sb->s_iflags |= SB_I_CGROUPWB;
 	return dent;

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0f7552a87d54..e6886c93c89d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/fs/block_dev.c
  *

commit 3813393f5a24f684fa0a716bdf8875039133c02b
Author: Sabyasachi Gupta <sabyasachi.linux@gmail.com>
Date:   Tue May 14 15:46:48 2019 -0700

    fs/block_dev.c: Remove duplicate header
    
    linux/dax.h is included more than once.
    
    Link: http://lkml.kernel.org/r/5c867e95.1c69fb81.4f15a.e5e4@mx.google.com
    Signed-off-by: Sabyasachi Gupta <sabyasachi.linux@gmail.com>
    Acked-by: Souptick Joarder <jrdr.linux@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f80045048bb7..0f7552a87d54 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -29,7 +29,6 @@
 #include <linux/namei.h>
 #include <linux/log2.h>
 #include <linux/cleancache.h>
-#include <linux/dax.h>
 #include <linux/task_io_accounting_ops.h>
 #include <linux/falloc.h>
 #include <linux/uaccess.h>

commit 149e703cb8bfcbdae46140b108bb6f7d2407df8f
Merge: d897166d8598 6ee9706aa22e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 20:50:27 2019 -0700

    Merge branch 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull misc vfs updates from Al Viro:
     "Assorted stuff, with no common topic whatsoever..."
    
    * 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      libfs: document simple_get_link()
      Documentation/filesystems/Locking: fix ->get_link() prototype
      Documentation/filesystems/vfs.txt: document how ->i_link works
      Documentation/filesystems/vfs.txt: remove bogus "Last updated" date
      fs: use timespec64 in relatime_need_update
      fs/block_dev.c: remove unused include

commit 67a242223958d628f0ba33283668e3ddd192d057
Merge: 8b35ad6232c4 b8753433fc61
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 18:14:36 2019 -0700

    Merge tag 'for-5.2/block-20190507' of git://git.kernel.dk/linux-block
    
    Pull block updates from Jens Axboe:
     "Nothing major in this series, just fixes and improvements all over the
      map. This contains:
    
       - Series of fixes for sed-opal (David, Jonas)
    
       - Fixes and performance tweaks for BFQ (via Paolo)
    
       - Set of fixes for bcache (via Coly)
    
       - Set of fixes for md (via Song)
    
       - Enabling multi-page for passthrough requests (Ming)
    
       - Queue release fix series (Ming)
    
       - Device notification improvements (Martin)
    
       - Propagate underlying device rotational status in loop (Holger)
    
       - Removal of mtip32xx trim support, which has been disabled for years
         (Christoph)
    
       - Improvement and cleanup of nvme command handling (Christoph)
    
       - Add block SPDX tags (Christoph)
    
       - Cleanup/hardening of bio/bvec iteration (Christoph)
    
       - A few NVMe pull requests (Christoph)
    
       - Removal of CONFIG_LBDAF (Christoph)
    
       - Various little fixes here and there"
    
    * tag 'for-5.2/block-20190507' of git://git.kernel.dk/linux-block: (164 commits)
      block: fix mismerge in bvec_advance
      block: don't drain in-progress dispatch in blk_cleanup_queue()
      blk-mq: move cancel of hctx->run_work into blk_mq_hw_sysfs_release
      blk-mq: always free hctx after request queue is freed
      blk-mq: split blk_mq_alloc_and_init_hctx into two parts
      blk-mq: free hw queue's resource in hctx's release handler
      blk-mq: move cancel of requeue_work into blk_mq_release
      blk-mq: grab .q_usage_counter when queuing request from plug code path
      block: fix function name in comment
      nvmet: protect discovery change log event list iteration
      nvme: mark nvme_core_init and nvme_core_exit static
      nvme: move command size checks to the core
      nvme-fabrics: check more command sizes
      nvme-pci: check more command sizes
      nvme-pci: remove an unneeded variable initialization
      nvme-pci: unquiesce admin queue on shutdown
      nvme-pci: shutdown on timeout during deletion
      nvme-pci: fix psdt field for single segment sgls
      nvme-multipath: don't print ANA group state by default
      nvme-multipath: split bios with the ns_head bio_set before submitting
      ...

commit 168e153d5ebbdd6a3fa85db1cc4879ed4b7030e0
Merge: 8ff468c29e9a f276ae0dd6d0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 10:57:05 2019 -0700

    Merge branch 'work.icache' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs inode freeing updates from Al Viro:
     "Introduction of separate method for RCU-delayed part of
      ->destroy_inode() (if any).
    
      Pretty much as posted, except that destroy_inode() stashes
      ->free_inode into the victim (anon-unioned with ->i_fops) before
      scheduling i_callback() and the last two patches (sockfs conversion
      and folding struct socket_wq into struct socket) are excluded - that
      pair should go through netdev once davem reopens his tree"
    
    * 'work.icache' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (58 commits)
      orangefs: make use of ->free_inode()
      shmem: make use of ->free_inode()
      hugetlb: make use of ->free_inode()
      overlayfs: make use of ->free_inode()
      jfs: switch to ->free_inode()
      fuse: switch to ->free_inode()
      ext4: make use of ->free_inode()
      ecryptfs: make use of ->free_inode()
      ceph: use ->free_inode()
      btrfs: use ->free_inode()
      afs: switch to use of ->free_inode()
      dax: make use of ->free_inode()
      ntfs: switch to ->free_inode()
      securityfs: switch to ->free_inode()
      apparmor: switch to ->free_inode()
      rpcpipe: switch to ->free_inode()
      bpf: switch to ->free_inode()
      mqueue: switch to ->free_inode()
      ufs: switch to ->free_inode()
      coda: switch to ->free_inode()
      ...

commit 41149cb08aebd4533f5d9019ff2656919779b27b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 10 15:12:38 2019 -0400

    bdev: switch to ->free_inode()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 78d3257435c0..9d5fd05dd643 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -789,17 +789,9 @@ static struct inode *bdev_alloc_inode(struct super_block *sb)
 	return &ei->vfs_inode;
 }
 
-static void bdev_i_callback(struct rcu_head *head)
+static void bdev_free_inode(struct inode *inode)
 {
-	struct inode *inode = container_of(head, struct inode, i_rcu);
-	struct bdev_inode *bdi = BDEV_I(inode);
-
-	kmem_cache_free(bdev_cachep, bdi);
-}
-
-static void bdev_destroy_inode(struct inode *inode)
-{
-	call_rcu(&inode->i_rcu, bdev_i_callback);
+	kmem_cache_free(bdev_cachep, BDEV_I(inode));
 }
 
 static void init_once(void *foo)
@@ -839,7 +831,7 @@ static void bdev_evict_inode(struct inode *inode)
 static const struct super_operations bdev_sops = {
 	.statfs = simple_statfs,
 	.alloc_inode = bdev_alloc_inode,
-	.destroy_inode = bdev_destroy_inode,
+	.free_inode = bdev_free_inode,
 	.drop_inode = generic_delete_inode,
 	.evict_inode = bdev_evict_inode,
 };

commit 60a27b906d1a372474669c914c10d6c993858a4a
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Apr 26 18:45:20 2019 +0800

    block: fix handling for BIO_NO_PAGE_REF
    
    Commit 399254aaf489211 ("block: add BIO_NO_PAGE_REF flag") introduces
    BIO_NO_PAGE_REF, and once this flag is set for one bio, all pages
    in the bio won't be get/put during IO.
    
    However, if one bio is submitted via __blkdev_direct_IO_simple(),
    even though BIO_NO_PAGE_REF is set, pages still may be put.
    
    Fixes this issue by avoiding to put pages if BIO_NO_PAGE_REF is
    set.
    
    Fixes: 399254aaf489211 ("block: add BIO_NO_PAGE_REF flag")
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 24615c76c1d0..bb28e2ead679 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -264,7 +264,8 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	bio_for_each_segment_all(bvec, &bio, i, iter_all) {
 		if (should_dirty && !PageCompound(bvec->bv_page))
 			set_page_dirty_lock(bvec->bv_page);
-		put_page(bvec->bv_page);
+		if (!bio_flagged(&bio, BIO_NO_PAGE_REF))
+			put_page(bvec->bv_page);
 	}
 
 	if (unlikely(bio.bi_status))

commit 2b070cfe582b8e99fec6ada57d2e59e194aae202
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 25 09:03:00 2019 +0200

    block: remove the i argument to bio_for_each_segment_all
    
    We only have two callers that need the integer loop iterator, and they
    can easily maintain it themselves.
    
    Suggested-by: Matthew Wilcox <willy@infradead.org>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Acked-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Acked-by: Coly Li <colyli@suse.de>
    Reviewed-by: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 24615c76c1d0..8abc6570d29f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -210,7 +210,6 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	struct bio bio;
 	ssize_t ret;
 	blk_qc_t qc;
-	int i;
 	struct bvec_iter_all iter_all;
 
 	if ((pos | iov_iter_alignment(iter)) &
@@ -261,7 +260,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	}
 	__set_current_state(TASK_RUNNING);
 
-	bio_for_each_segment_all(bvec, &bio, i, iter_all) {
+	bio_for_each_segment_all(bvec, &bio, iter_all) {
 		if (should_dirty && !PageCompound(bvec->bv_page))
 			set_page_dirty_lock(bvec->bv_page);
 		put_page(bvec->bv_page);
@@ -339,9 +338,8 @@ static void blkdev_bio_end_io(struct bio *bio)
 		if (!bio_flagged(bio, BIO_NO_PAGE_REF)) {
 			struct bvec_iter_all iter_all;
 			struct bio_vec *bvec;
-			int i;
 
-			bio_for_each_segment_all(bvec, bio, i, iter_all)
+			bio_for_each_segment_all(bvec, bio, iter_all)
 				put_page(bvec->bv_page);
 		}
 		bio_put(bio);

commit a89afe58f1a74aac768a5eb77af95ef4ee15beaa
Author: Jason Yan <yanaijie@huawei.com>
Date:   Fri Apr 12 10:09:16 2019 +0800

    block: fix the return errno for direct IO
    
    If the last bio returned is not dio->bio, the status of the bio will
    not assigned to dio->bio if it is error. This will cause the whole IO
    status wrong.
    
        ksoftirqd/21-117   [021] ..s.  4017.966090:   8,0    C   N 4883648 [0]
              <idle>-0     [018] ..s.  4017.970888:   8,0    C  WS 4924800 + 1024 [0]
              <idle>-0     [018] ..s.  4017.970909:   8,0    D  WS 4935424 + 1024 [<idle>]
              <idle>-0     [018] ..s.  4017.970924:   8,0    D  WS 4936448 + 321 [<idle>]
        ksoftirqd/21-117   [021] ..s.  4017.995033:   8,0    C   R 4883648 + 336 [65475]
        ksoftirqd/21-117   [021] d.s.  4018.001988: myprobe1: (blkdev_bio_end_io+0x0/0x168) bi_status=7
        ksoftirqd/21-117   [021] d.s.  4018.001992: myprobe: (aio_complete_rw+0x0/0x148) x0=0xffff802f2595ad80 res=0x12a000 res2=0x0
    
    We always have to assign bio->bi_status to dio->bio.bi_status because we
    will only check dio->bio.bi_status when we return the whole IO to
    the upper layer.
    
    Fixes: 542ff7bf18c6 ("block: new direct I/O implementation")
    Cc: stable@vger.kernel.org
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jason Yan <yanaijie@huawei.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 78d3257435c0..24615c76c1d0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -307,10 +307,10 @@ static void blkdev_bio_end_io(struct bio *bio)
 	struct blkdev_dio *dio = bio->bi_private;
 	bool should_dirty = dio->should_dirty;
 
-	if (dio->multi_bio && !atomic_dec_and_test(&dio->ref)) {
-		if (bio->bi_status && !dio->bio.bi_status)
-			dio->bio.bi_status = bio->bi_status;
-	} else {
+	if (bio->bi_status && !dio->bio.bi_status)
+		dio->bio.bi_status = bio->bi_status;
+
+	if (!dio->multi_bio || atomic_dec_and_test(&dio->ref)) {
 		if (!dio->is_sync) {
 			struct kiocb *iocb = dio->iocb;
 			ssize_t ret;

commit 6d46d2934aeab54bd560e68bf5c73f016f9317a2
Author: Chengguang Xu <cgxu519@gmx.com>
Date:   Tue Apr 9 18:37:52 2019 +0800

    fs/block_dev.c: remove unused include
    
    Just remove unused include <linux/badblocks.h> from
    fs/block_dev.c.
    
    Signed-off-by: Chengguang Xu <cgxu519@gmx.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 78d3257435c0..6b584817d461 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -30,7 +30,6 @@
 #include <linux/log2.h>
 #include <linux/cleancache.h>
 #include <linux/dax.h>
-#include <linux/badblocks.h>
 #include <linux/task_io_accounting_ops.h>
 #include <linux/falloc.h>
 #include <linux/uaccess.h>

commit 399254aaf4892113c806816f7e64cf40c804d46d
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Feb 27 13:13:23 2019 -0700

    block: add BIO_NO_PAGE_REF flag
    
    If bio_iov_iter_get_pages() is called on an iov_iter that is flagged
    with NO_REF, then we don't need to add a page reference for the pages
    that we add.
    
    Add BIO_NO_PAGE_REF to track this in the bio, so IO completion knows
    not to drop a reference to these pages.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e9faa52bb489..78d3257435c0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -336,12 +336,14 @@ static void blkdev_bio_end_io(struct bio *bio)
 	if (should_dirty) {
 		bio_check_pages_dirty(bio);
 	} else {
-		struct bio_vec *bvec;
-		int i;
-		struct bvec_iter_all iter_all;
+		if (!bio_flagged(bio, BIO_NO_PAGE_REF)) {
+			struct bvec_iter_all iter_all;
+			struct bio_vec *bvec;
+			int i;
 
-		bio_for_each_segment_all(bvec, bio, i, iter_all)
-			put_page(bvec->bv_page);
+			bio_for_each_segment_all(bvec, bio, i, iter_all)
+				put_page(bvec->bv_page);
+		}
 		bio_put(bio);
 	}
 }

commit 0bbb280d7b767e7c86a5adfc87c76a6f09ab0423
Author: Jens Axboe <axboe@kernel.dk>
Date:   Fri Dec 21 09:10:46 2018 -0700

    block: add bio_set_polled() helper
    
    For the upcoming async polled IO, we can't sleep allocating requests.
    If we do, then we introduce a deadlock where the submitter already
    has async polled IO in-flight, but can't wait for them to complete
    since polled requests must be active found and reaped.
    
    Utilize the helper in the blockdev DIRECT_IO code.
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1fe498b08f1b..e9faa52bb489 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -248,7 +248,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 		task_io_account_write(ret);
 	}
 	if (iocb->ki_flags & IOCB_HIPRI)
-		bio.bi_opf |= REQ_HIPRI;
+		bio_set_polled(&bio, iocb);
 
 	qc = submit_bio(&bio);
 	for (;;) {
@@ -419,7 +419,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			bool polled = false;
 
 			if (iocb->ki_flags & IOCB_HIPRI) {
-				bio->bi_opf |= REQ_HIPRI;
+				bio_set_polled(bio, iocb);
 				polled = true;
 			}
 

commit eae83ce10b4713d9f4f3419af16436f89c1a7172
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 30 08:31:52 2018 -0700

    block: wire up block device iopoll method
    
    Just call blk_poll on the iocb cookie, we can derive the block device
    from the inode trivially.
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7758adee6efe..1fe498b08f1b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -294,6 +294,14 @@ struct blkdev_dio {
 
 static struct bio_set blkdev_dio_pool;
 
+static int blkdev_iopoll(struct kiocb *kiocb, bool wait)
+{
+	struct block_device *bdev = I_BDEV(kiocb->ki_filp->f_mapping->host);
+	struct request_queue *q = bdev_get_queue(bdev);
+
+	return blk_poll(q, READ_ONCE(kiocb->ki_cookie), wait);
+}
+
 static void blkdev_bio_end_io(struct bio *bio)
 {
 	struct blkdev_dio *dio = bio->bi_private;
@@ -408,10 +416,17 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 		nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES);
 		if (!nr_pages) {
-			if (iocb->ki_flags & IOCB_HIPRI)
+			bool polled = false;
+
+			if (iocb->ki_flags & IOCB_HIPRI) {
 				bio->bi_opf |= REQ_HIPRI;
+				polled = true;
+			}
 
 			qc = submit_bio(bio);
+
+			if (polled)
+				WRITE_ONCE(iocb->ki_cookie, qc);
 			break;
 		}
 
@@ -2078,6 +2093,7 @@ const struct file_operations def_blk_fops = {
 	.llseek		= block_llseek,
 	.read_iter	= blkdev_read_iter,
 	.write_iter	= blkdev_write_iter,
+	.iopoll		= blkdev_iopoll,
 	.mmap		= generic_file_mmap,
 	.fsync		= blkdev_fsync,
 	.unlocked_ioctl	= block_ioctl,

commit 6dc4f100c175dd0511ae8674786e7c9006cdfbfa
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Feb 15 19:13:19 2019 +0800

    block: allow bio_for_each_segment_all() to iterate over multi-page bvec
    
    This patch introduces one extra iterator variable to bio_for_each_segment_all(),
    then we can allow bio_for_each_segment_all() to iterate over multi-page bvec.
    
    Given it is just one mechannical & simple change on all bio_for_each_segment_all()
    users, this patch does tree-wide change in one single patch, so that we can
    avoid to use a temporary helper for this conversion.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 58a4c1217fa8..7758adee6efe 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -211,6 +211,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	ssize_t ret;
 	blk_qc_t qc;
 	int i;
+	struct bvec_iter_all iter_all;
 
 	if ((pos | iov_iter_alignment(iter)) &
 	    (bdev_logical_block_size(bdev) - 1))
@@ -260,7 +261,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	}
 	__set_current_state(TASK_RUNNING);
 
-	bio_for_each_segment_all(bvec, &bio, i) {
+	bio_for_each_segment_all(bvec, &bio, i, iter_all) {
 		if (should_dirty && !PageCompound(bvec->bv_page))
 			set_page_dirty_lock(bvec->bv_page);
 		put_page(bvec->bv_page);
@@ -329,8 +330,9 @@ static void blkdev_bio_end_io(struct bio *bio)
 	} else {
 		struct bio_vec *bvec;
 		int i;
+		struct bvec_iter_all iter_all;
 
-		bio_for_each_segment_all(bvec, bio, i)
+		bio_for_each_segment_all(bvec, bio, i, iter_all)
 			put_page(bvec->bv_page);
 		bio_put(bio);
 	}

commit 04906b2f542c23626b0ef6219b808406f8dddbe9
Author: Jan Kara <jack@suse.cz>
Date:   Mon Jan 14 09:48:10 2019 +0100

    blockdev: Fix livelocks on loop device
    
    bd_set_size() updates also block device's block size. This is somewhat
    unexpected from its name and at this point, only blkdev_open() uses this
    functionality. Furthermore, this can result in changing block size under
    a filesystem mounted on a loop device which leads to livelocks inside
    __getblk_gfp() like:
    
    Sending NMI from CPU 0 to CPUs 1:
    NMI backtrace for cpu 1
    CPU: 1 PID: 10863 Comm: syz-executor0 Not tainted 4.18.0-rc5+ #151
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google
    01/01/2011
    RIP: 0010:__sanitizer_cov_trace_pc+0x3f/0x50 kernel/kcov.c:106
    ...
    Call Trace:
     init_page_buffers+0x3e2/0x530 fs/buffer.c:904
     grow_dev_page fs/buffer.c:947 [inline]
     grow_buffers fs/buffer.c:1009 [inline]
     __getblk_slow fs/buffer.c:1036 [inline]
     __getblk_gfp+0x906/0xb10 fs/buffer.c:1313
     __bread_gfp+0x2d/0x310 fs/buffer.c:1347
     sb_bread include/linux/buffer_head.h:307 [inline]
     fat12_ent_bread+0x14e/0x3d0 fs/fat/fatent.c:75
     fat_ent_read_block fs/fat/fatent.c:441 [inline]
     fat_alloc_clusters+0x8ce/0x16e0 fs/fat/fatent.c:489
     fat_add_cluster+0x7a/0x150 fs/fat/inode.c:101
     __fat_get_block fs/fat/inode.c:148 [inline]
    ...
    
    Trivial reproducer for the problem looks like:
    
    truncate -s 1G /tmp/image
    losetup /dev/loop0 /tmp/image
    mkfs.ext4 -b 1024 /dev/loop0
    mount -t ext4 /dev/loop0 /mnt
    losetup -c /dev/loop0
    l /mnt
    
    Fix the problem by moving initialization of a block device block size
    into a separate function and call it when needed.
    
    Thanks to Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp> for help with
    debugging the problem.
    
    Reported-by: syzbot+9933e4476f365f5d5a1b@syzkaller.appspotmail.com
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c546cdce77e6..58a4c1217fa8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -104,6 +104,20 @@ void invalidate_bdev(struct block_device *bdev)
 }
 EXPORT_SYMBOL(invalidate_bdev);
 
+static void set_init_blocksize(struct block_device *bdev)
+{
+	unsigned bsize = bdev_logical_block_size(bdev);
+	loff_t size = i_size_read(bdev->bd_inode);
+
+	while (bsize < PAGE_SIZE) {
+		if (size & bsize)
+			break;
+		bsize <<= 1;
+	}
+	bdev->bd_block_size = bsize;
+	bdev->bd_inode->i_blkbits = blksize_bits(bsize);
+}
+
 int set_blocksize(struct block_device *bdev, int size)
 {
 	/* Size must be a power of two, and between 512 and PAGE_SIZE */
@@ -1431,18 +1445,9 @@ EXPORT_SYMBOL(check_disk_change);
 
 void bd_set_size(struct block_device *bdev, loff_t size)
 {
-	unsigned bsize = bdev_logical_block_size(bdev);
-
 	inode_lock(bdev->bd_inode);
 	i_size_write(bdev->bd_inode, size);
 	inode_unlock(bdev->bd_inode);
-	while (bsize < PAGE_SIZE) {
-		if (size & bsize)
-			break;
-		bsize <<= 1;
-	}
-	bdev->bd_block_size = bsize;
-	bdev->bd_inode->i_blkbits = blksize_bits(bsize);
 }
 EXPORT_SYMBOL(bd_set_size);
 
@@ -1519,8 +1524,10 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				}
 			}
 
-			if (!ret)
+			if (!ret) {
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
+				set_init_blocksize(bdev);
+			}
 
 			/*
 			 * If the device is invalidated, rescan partition
@@ -1555,6 +1562,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_clear;
 			}
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
+			set_init_blocksize(bdev);
 		}
 
 		if (bdev->bd_bdi == &noop_backing_dev_info)

commit 1ac5cd4978794bd060d448acc0305e9fc996ba92
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 2 10:46:03 2019 -0800

    block: don't use un-ordered __set_current_state(TASK_UNINTERRUPTIBLE)
    
    This mostly reverts commit 849a370016a5 ("block: avoid ordered task
    state change for polled IO").  It was wrongly claiming that the ordering
    wasn't necessary.  The memory barrier _is_ necessary.
    
    If something is truly polling and not going to sleep, it's the whole
    state setting that is unnecessary, not the memory barrier.  Whenever you
    set your state to a sleeping state, you absolutely need the memory
    barrier.
    
    Note that sometimes the memory barrier can be elsewhere.  For example,
    the ordering might be provided by an external lock, or by setting the
    process state to sleeping before adding yourself to the wait queue list
    that is used for waking up (where the wait queue lock itself will
    guarantee that any wakeup will correctly see the sleeping state).
    
    But none of those cases were true here.
    
    NOTE! Some of the polling paths may indeed be able to drop the state
    setting entirely, at which point the memory barrier also goes away.
    
    (Also note that this doesn't revert the TASK_RUNNING cases: there is no
    race between a wakeup and setting the process state to TASK_RUNNING,
    since the end result doesn't depend on ordering).
    
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 450be88cffef..c546cdce77e6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -237,11 +237,9 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 
 	qc = submit_bio(&bio);
 	for (;;) {
-		__set_current_state(TASK_UNINTERRUPTIBLE);
-
+		set_current_state(TASK_UNINTERRUPTIBLE);
 		if (!READ_ONCE(bio.bi_private))
 			break;
-
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
 		    !blk_poll(bdev_get_queue(bdev), qc, true))
 			io_schedule();
@@ -426,8 +424,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		return -EIOCBQUEUED;
 
 	for (;;) {
-		__set_current_state(TASK_UNINTERRUPTIBLE);
-
+		set_current_state(TASK_UNINTERRUPTIBLE);
 		if (!READ_ONCE(dio->waiter))
 			break;
 

commit f346b0becb1bc62e45495f9cdbae3eef35d0b635
Merge: 00d59fde8532 0f4991e8fd48
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 28 16:55:46 2018 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Merge misc updates from Andrew Morton:
    
     - large KASAN update to use arm's "software tag-based mode"
    
     - a few misc things
    
     - sh updates
    
     - ocfs2 updates
    
     - just about all of MM
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (167 commits)
      kernel/fork.c: mark 'stack_vm_area' with __maybe_unused
      memcg, oom: notify on oom killer invocation from the charge path
      mm, swap: fix swapoff with KSM pages
      include/linux/gfp.h: fix typo
      mm/hmm: fix memremap.h, move dev_page_fault_t callback to hmm
      hugetlbfs: Use i_mmap_rwsem to fix page fault/truncate race
      hugetlbfs: use i_mmap_rwsem for more pmd sharing synchronization
      memory_hotplug: add missing newlines to debugging output
      mm: remove __hugepage_set_anon_rmap()
      include/linux/vmstat.h: remove unused page state adjustment macro
      mm/page_alloc.c: allow error injection
      mm: migrate: drop unused argument of migrate_page_move_mapping()
      blkdev: avoid migration stalls for blkdev pages
      mm: migrate: provide buffer_migrate_page_norefs()
      mm: migrate: move migrate_page_lock_buffers()
      mm: migrate: lock buffers before migrate_page_move_mapping()
      mm: migration: factor out code to compute expected number of page references
      mm, page_alloc: enable pcpu_drain with zone capability
      kmemleak: add config to select auto scan
      mm/page_alloc.c: don't call kasan_free_pages() at deferred mem init
      ...

commit 88dbcbb3a4847f5e6dfeae952d3105497700c128
Author: Jan Kara <jack@suse.cz>
Date:   Fri Dec 28 00:39:16 2018 -0800

    blkdev: avoid migration stalls for blkdev pages
    
    Currently, block device pages don't provide a ->migratepage callback and
    thus fallback_migrate_page() is used for them.  This handler cannot deal
    with dirty pages in async mode and also with the case a buffer head is in
    the LRU buffer head cache (as it has elevated b_count).  Thus such page
    can block memory offlining.
    
    Fix the problem by using buffer_migrate_page_norefs() for migrating block
    device pages.  That function takes care of dropping bh LRU in case
    migration would fail due to elevated buffer refcount to avoid stalls and
    can also migrate dirty pages without writing them.
    
    Link: http://lkml.kernel.org/r/20181211172143.7358-6-jack@suse.cz
    Signed-off-by: Jan Kara <jack@suse.cz>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a80b4f0ee7c4..de2135178e62 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1966,6 +1966,7 @@ static const struct address_space_operations def_blk_aops = {
 	.writepages	= blkdev_writepages,
 	.releasepage	= blkdev_releasepage,
 	.direct_IO	= blkdev_direct_IO,
+	.migratepage	= buffer_migrate_page_norefs,
 	.is_dirty_writeback = buffer_check_dirty_writeback,
 };
 

commit 531724abc3bfb556c1dd68086cf9cb51f76464e3
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 30 09:23:48 2018 +0100

    block: avoid extra bio reference for async O_DIRECT
    
    The bio referencing has a trick that doesn't do any actual atomic
    inc/dec on the reference count until we have to elevator to > 1. For the
    async IO O_DIRECT case, we can't use the simple DIO variants, so we use
    __blkdev_direct_IO(). It always grabs an extra reference to the bio
    after allocation, which means we then enter the slower path of actually
    having to do atomic_inc/dec on the count.
    
    We don't need to do that for the async case, unless we end up going
    multi-bio, in which case we're already doing huge amounts of IO. For the
    smaller IO case (< BIO_MAX_PAGES), we can do without the extra ref.
    
    Based on an earlier patch (and commit log) from Jens Axboe.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d233a59ea364..e1886cc7048f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -302,7 +302,8 @@ static void blkdev_bio_end_io(struct bio *bio)
 			}
 
 			dio->iocb->ki_complete(iocb, ret, 0);
-			bio_put(&dio->bio);
+			if (dio->multi_bio)
+				bio_put(&dio->bio);
 		} else {
 			struct task_struct *waiter = dio->waiter;
 
@@ -343,14 +344,15 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		return -EINVAL;
 
 	bio = bio_alloc_bioset(GFP_KERNEL, nr_pages, &blkdev_dio_pool);
-	bio_get(bio); /* extra ref for the completion handler */
 
 	dio = container_of(bio, struct blkdev_dio, bio);
 	dio->is_sync = is_sync = is_sync_kiocb(iocb);
-	if (dio->is_sync)
+	if (dio->is_sync) {
 		dio->waiter = current;
-	else
+		bio_get(bio);
+	} else {
 		dio->iocb = iocb;
+	}
 
 	dio->size = 0;
 	dio->multi_bio = false;
@@ -400,6 +402,13 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		}
 
 		if (!dio->multi_bio) {
+			/*
+			 * AIO needs an extra reference to ensure the dio
+			 * structure which is embedded into the first bio
+			 * stays around.
+			 */
+			if (!is_sync)
+				bio_get(bio);
 			dio->multi_bio = true;
 			atomic_set(&dio->ref, 2);
 		} else {

commit 0a1b8b87d064a47fad9ec475316002da28559207
Author: Jens Axboe <axboe@kernel.dk>
Date:   Mon Nov 26 08:24:43 2018 -0700

    block: make blk_poll() take a parameter on whether to spin or not
    
    blk_poll() has always kept spinning until it found an IO. This is
    fine for SYNC polling, since we need to find one request we have
    pending, but in preparation for ASYNC polling it can be beneficial
    to just check if we have any entries available or not.
    
    Existing callers are converted to pass in 'spin == true', to retain
    the old behavior.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 64ba27b8b754..d233a59ea364 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -243,7 +243,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 			break;
 
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
-		    !blk_poll(bdev_get_queue(bdev), qc))
+		    !blk_poll(bdev_get_queue(bdev), qc, true))
 			io_schedule();
 	}
 	__set_current_state(TASK_RUNNING);
@@ -423,7 +423,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			break;
 
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
-		    !blk_poll(bdev_get_queue(bdev), qc))
+		    !blk_poll(bdev_get_queue(bdev), qc, true))
 			io_schedule();
 	}
 	__set_current_state(TASK_RUNNING);

commit 849a370016a5489c49253338507ee6cc4a08df4b
Author: Jens Axboe <axboe@kernel.dk>
Date:   Fri Nov 16 08:37:34 2018 -0700

    block: avoid ordered task state change for polled IO
    
    For the core poll helper, the task state setting don't need to imply any
    atomics, as it's the current task itself that is being modified and
    we're not going to sleep.
    
    For IRQ driven, the wakeup path have the necessary barriers to not need
    us using the heavy handed version of the task state setting.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4d79bc80fb41..64ba27b8b754 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -237,9 +237,11 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 
 	qc = submit_bio(&bio);
 	for (;;) {
-		set_current_state(TASK_UNINTERRUPTIBLE);
+		__set_current_state(TASK_UNINTERRUPTIBLE);
+
 		if (!READ_ONCE(bio.bi_private))
 			break;
+
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
 		    !blk_poll(bdev_get_queue(bdev), qc))
 			io_schedule();
@@ -415,7 +417,8 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		return -EIOCBQUEUED;
 
 	for (;;) {
-		set_current_state(TASK_UNINTERRUPTIBLE);
+		__set_current_state(TASK_UNINTERRUPTIBLE);
+
 		if (!READ_ONCE(dio->waiter))
 			break;
 

commit cb700eb3faa488fbb4b60689adec84032d7cf24a
Author: Jens Axboe <axboe@kernel.dk>
Date:   Thu Nov 15 19:56:53 2018 -0700

    block: don't plug for aio/O_DIRECT HIPRI IO
    
    Those will go straight to issue inside blk-mq, so don't bother
    setting up a block plug for them.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e72b119ede84..4d79bc80fb41 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -330,6 +330,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	struct blk_plug plug;
 	struct blkdev_dio *dio;
 	struct bio *bio;
+	bool is_poll = (iocb->ki_flags & IOCB_HIPRI) != 0;
 	bool is_read = (iov_iter_rw(iter) == READ), is_sync;
 	loff_t pos = iocb->ki_pos;
 	blk_qc_t qc = BLK_QC_T_NONE;
@@ -353,7 +354,13 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	dio->multi_bio = false;
 	dio->should_dirty = is_read && iter_is_iovec(iter);
 
-	blk_start_plug(&plug);
+	/*
+	 * Don't plug for HIPRI/polled IO, as those should go straight
+	 * to issue
+	 */
+	if (!is_poll)
+		blk_start_plug(&plug);
+
 	for (;;) {
 		bio_set_dev(bio, bdev);
 		bio->bi_iter.bi_sector = pos >> 9;
@@ -400,7 +407,9 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		submit_bio(bio);
 		bio = bio_alloc(GFP_KERNEL, nr_pages);
 	}
-	blk_finish_plug(&plug);
+
+	if (!is_poll)
+		blk_finish_plug(&plug);
 
 	if (!is_sync)
 		return -EIOCBQUEUED;

commit d34513d384487e8022f143a3a6b791e6d7f0dad6
Author: Jens Axboe <axboe@kernel.dk>
Date:   Tue Nov 6 14:29:11 2018 -0700

    block: for async O_DIRECT, mark us as polling if asked to
    
    Inherit the iocb IOCB_HIPRI flag, and pass on REQ_HIPRI for
    those kinds of requests.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9fe56672cfe5..e72b119ede84 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -383,6 +383,9 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 		nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES);
 		if (!nr_pages) {
+			if (iocb->ki_flags & IOCB_HIPRI)
+				bio->bi_opf |= REQ_HIPRI;
+
 			qc = submit_bio(bio);
 			break;
 		}

commit 0619317ff8baa2da9238191ad5167ed3618c16d9
Author: Jens Axboe <axboe@kernel.dk>
Date:   Tue Nov 13 21:16:54 2018 -0700

    block: add polled wakeup task helper
    
    If we're polling for IO on a device that doesn't use interrupts, then
    IO completion loop (and wake of task) is done by submitting task itself.
    If that is the case, then we don't need to enter the wake_up_process()
    function, we can simply mark ourselves as TASK_RUNNING.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c039abfb2052..9fe56672cfe5 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -181,7 +181,7 @@ static void blkdev_bio_end_io_simple(struct bio *bio)
 	struct task_struct *waiter = bio->bi_private;
 
 	WRITE_ONCE(bio->bi_private, NULL);
-	wake_up_process(waiter);
+	blk_wake_io_task(waiter);
 }
 
 static ssize_t
@@ -305,7 +305,7 @@ static void blkdev_bio_end_io(struct bio *bio)
 			struct task_struct *waiter = dio->waiter;
 
 			WRITE_ONCE(dio->waiter, NULL);
-			wake_up_process(waiter);
+			blk_wake_io_task(waiter);
 		}
 	}
 

commit d1e36282b0bbd5de6a9c4d5275e94ef3b3438f48
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Aug 29 10:36:56 2018 -0600

    block: add REQ_HIPRI and inherit it from IOCB_HIPRI
    
    We use IOCB_HIPRI to poll for IO in the caller instead of scheduling.
    This information is not available for (or after) IO submission. The
    driver may make different queue choices based on the type of IO, so
    make the fact that we will poll for this IO known to the lower layers
    as well.
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a80b4f0ee7c4..c039abfb2052 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -232,6 +232,8 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 		bio.bi_opf = dio_bio_write_op(iocb);
 		task_io_account_write(ret);
 	}
+	if (iocb->ki_flags & IOCB_HIPRI)
+		bio.bi_opf |= REQ_HIPRI;
 
 	qc = submit_bio(&bio);
 	for (;;) {

commit 00e23707442a75b404392cef1405ab4fd498de6b
Author: David Howells <dhowells@redhat.com>
Date:   Mon Oct 22 13:07:28 2018 +0100

    iov_iter: Use accessor function
    
    Use accessor functions to access an iterator's type and direction.  This
    allows for the possibility of using some other method of determining the
    type of iterator than if-chains with bitwise-AND conditions.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 38b8ce05cbc7..a80b4f0ee7c4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -349,7 +349,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 	dio->size = 0;
 	dio->multi_bio = false;
-	dio->should_dirty = is_read && (iter->type == ITER_IOVEC);
+	dio->should_dirty = is_read && iter_is_iovec(iter);
 
 	blk_start_plug(&plug);
 	for (;;) {

commit 73ba2fb33c492916853dfe63e3b3163da0be661d
Merge: 958f338e96f8 b86d865cb1ca
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 14 10:23:25 2018 -0700

    Merge tag 'for-4.19/block-20180812' of git://git.kernel.dk/linux-block
    
    Pull block updates from Jens Axboe:
     "First pull request for this merge window, there will also be a
      followup request with some stragglers.
    
      This pull request contains:
    
       - Fix for a thundering heard issue in the wbt block code (Anchal
         Agarwal)
    
       - A few NVMe pull requests:
          * Improved tracepoints (Keith)
          * Larger inline data support for RDMA (Steve Wise)
          * RDMA setup/teardown fixes (Sagi)
          * Effects log suppor for NVMe target (Chaitanya Kulkarni)
          * Buffered IO suppor for NVMe target (Chaitanya Kulkarni)
          * TP4004 (ANA) support (Christoph)
          * Various NVMe fixes
    
       - Block io-latency controller support. Much needed support for
         properly containing block devices. (Josef)
    
       - Series improving how we handle sense information on the stack
         (Kees)
    
       - Lightnvm fixes and updates/improvements (Mathias/Javier et al)
    
       - Zoned device support for null_blk (Matias)
    
       - AIX partition fixes (Mauricio Faria de Oliveira)
    
       - DIF checksum code made generic (Max Gurtovoy)
    
       - Add support for discard in iostats (Michael Callahan / Tejun)
    
       - Set of updates for BFQ (Paolo)
    
       - Removal of async write support for bsg (Christoph)
    
       - Bio page dirtying and clone fixups (Christoph)
    
       - Set of bcache fix/changes (via Coly)
    
       - Series improving blk-mq queue setup/teardown speed (Ming)
    
       - Series improving merging performance on blk-mq (Ming)
    
       - Lots of other fixes and cleanups from a slew of folks"
    
    * tag 'for-4.19/block-20180812' of git://git.kernel.dk/linux-block: (190 commits)
      blkcg: Make blkg_root_lookup() work for queues in bypass mode
      bcache: fix error setting writeback_rate through sysfs interface
      null_blk: add lock drop/acquire annotation
      Blk-throttle: reduce tail io latency when iops limit is enforced
      block: paride: pd: mark expected switch fall-throughs
      block: Ensure that a request queue is dissociated from the cgroup controller
      block: Introduce blk_exit_queue()
      blkcg: Introduce blkg_root_lookup()
      block: Remove two superfluous #include directives
      blk-mq: count the hctx as active before allocating tag
      block: bvec_nr_vecs() returns value for wrong slab
      bcache: trivial - remove tailing backslash in macro BTREE_FLAG
      bcache: make the pr_err statement used for ENOENT only in sysfs_attatch section
      bcache: set max writeback rate when I/O request is idle
      bcache: add code comments for bset.c
      bcache: fix mistaken comments in request.c
      bcache: fix mistaken code comments in bcache.h
      bcache: add a comment in super.c
      bcache: avoid unncessary cache prefetch bch_btree_node_get()
      bcache: display rate debug parameters to 0 when writeback is not running
      ...

commit eb181a814c98255b32d30b383baca00e6ebec72e
Merge: 864af0d40cdc 5151842b9d87
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 27 12:51:00 2018 -0700

    Merge tag 'for-linus-20180727' of git://git.kernel.dk/linux-block
    
    Pull block fixes from Jens Axboe:
     "Bigger than usual at this time, mostly due to the O_DIRECT corruption
      issue and the fact that I was on vacation last week. This contains:
    
       - NVMe pull request with two fixes for the FC code, and two target
         fixes (Christoph)
    
       - a DIF bio reset iteration fix (Greg Edwards)
    
       - two nbd reply and requeue fixes (Josef)
    
       - SCSI timeout fixup (Keith)
    
       - a small series that fixes an issue with bio_iov_iter_get_pages(),
         which ended up causing corruption for larger sized O_DIRECT writes
         that ended up racing with buffered writes (Martin Wilck)"
    
    * tag 'for-linus-20180727' of git://git.kernel.dk/linux-block:
      block: reset bi_iter.bi_done after splitting bio
      block: bio_iov_iter_get_pages: pin more pages for multi-segment IOs
      blkdev: __blkdev_direct_IO_simple: fix leak in error case
      block: bio_iov_iter_get_pages: fix size of last iovec
      nvmet: only check for filebacking on -ENOTBLK
      nvmet: fixup crash on NULL device path
      scsi: set timed out out mq requests to complete
      blk-mq: export setting request completion state
      nvme: if_ready checks to fail io to deleting controller
      nvmet-fc: fix target sgl list on large transfers
      nbd: handle unexpected replies better
      nbd: don't requeue the same request twice.

commit 9362dd1109f87a9d0a798fbc890cb339c171ed35
Author: Martin Wilck <mwilck@suse.com>
Date:   Wed Jul 25 23:15:08 2018 +0200

    blkdev: __blkdev_direct_IO_simple: fix leak in error case
    
    Fixes: 72ecad22d9f1 ("block: support a full bio worth of IO for simplified bdev direct-io")
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin Wilck <mwilck@suse.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 05e12aea2404..192005376884 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -220,7 +220,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 
 	ret = bio_iov_iter_get_pages(&bio, iter);
 	if (unlikely(ret))
-		return ret;
+		goto out;
 	ret = bio.bi_iter.bi_size;
 
 	if (iov_iter_rw(iter) == READ) {
@@ -249,12 +249,13 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 		put_page(bvec->bv_page);
 	}
 
-	if (vecs != inline_vecs)
-		kfree(vecs);
-
 	if (unlikely(bio.bi_status))
 		ret = blk_status_to_errno(bio.bi_status);
 
+out:
+	if (vecs != inline_vecs)
+		kfree(vecs);
+
 	bio_uninit(&bio);
 
 	return ret;

commit 3f289dcb4b265416a57ca79cf4a324060bb09060
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jul 18 04:47:36 2018 -0700

    block: make bdev_ops->rw_page() take a REQ_OP instead of bool
    
    c11f0c0b5bb9 ("block/mm: make bdev_ops->rw_page() take a bool for
    read/write") replaced @op with boolean @is_write, which limited the
    amount of information going into ->rw_page() and more importantly
    page_endio(), which removed the need to expose block internals to mm.
    
    Unfortunately, we want to track discards separately and @is_write
    isn't enough information.  This patch updates bdev_ops->rw_page() to
    take REQ_OP instead but leaves page_endio() to take bool @is_write.
    This allows the block part of operations to have enough information
    while not leaking it to mm.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Mike Christie <mchristi@redhat.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0dd87aaeb39a..496fb51a1e1a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -665,7 +665,8 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 	result = blk_queue_enter(bdev->bd_queue, 0);
 	if (result)
 		return result;
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, false);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
+			      REQ_OP_READ);
 	blk_queue_exit(bdev->bd_queue);
 	return result;
 }
@@ -703,7 +704,8 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 		return result;
 
 	set_page_writeback(page);
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, true);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
+			      REQ_OP_WRITE);
 	if (result) {
 		end_page_writeback(page);
 	} else {

commit 6da2ec56059c3c7a7e5f729e6349e74ace1e5c57
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jun 12 13:55:00 2018 -0700

    treewide: kmalloc() -> kmalloc_array()
    
    The kmalloc() function has a 2-factor argument form, kmalloc_array(). This
    patch replaces cases of:
    
            kmalloc(a * b, gfp)
    
    with:
            kmalloc_array(a * b, gfp)
    
    as well as handling cases of:
    
            kmalloc(a * b * c, gfp)
    
    with:
    
            kmalloc(array3_size(a, b, c), gfp)
    
    as it's slightly less ugly than:
    
            kmalloc_array(array_size(a, b), c, gfp)
    
    This does, however, attempt to ignore constant size factors like:
    
            kmalloc(4 * 1024, gfp)
    
    though any constants defined via macros get caught up in the conversion.
    
    Any factors with a sizeof() of "unsigned char", "char", and "u8" were
    dropped, since they're redundant.
    
    The tools/ directory was manually excluded, since it has its own
    implementation of kmalloc().
    
    The Coccinelle script used for this was:
    
    // Fix redundant parens around sizeof().
    @@
    type TYPE;
    expression THING, E;
    @@
    
    (
      kmalloc(
    -       (sizeof(TYPE)) * E
    +       sizeof(TYPE) * E
      , ...)
    |
      kmalloc(
    -       (sizeof(THING)) * E
    +       sizeof(THING) * E
      , ...)
    )
    
    // Drop single-byte sizes and redundant parens.
    @@
    expression COUNT;
    typedef u8;
    typedef __u8;
    @@
    
    (
      kmalloc(
    -       sizeof(u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(__u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(char) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(unsigned char) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(u8) * COUNT
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(__u8) * COUNT
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(char) * COUNT
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(unsigned char) * COUNT
    +       COUNT
      , ...)
    )
    
    // 2-factor product with sizeof(type/expression) and identifier or constant.
    @@
    type TYPE;
    expression THING;
    identifier COUNT_ID;
    constant COUNT_CONST;
    @@
    
    (
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * (COUNT_ID)
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * COUNT_ID
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * COUNT_CONST
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * (COUNT_ID)
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * COUNT_ID
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * COUNT_CONST
    +       COUNT_CONST, sizeof(THING)
      , ...)
    )
    
    // 2-factor product, only identifiers.
    @@
    identifier SIZE, COUNT;
    @@
    
    - kmalloc
    + kmalloc_array
      (
    -       SIZE * COUNT
    +       COUNT, SIZE
      , ...)
    
    // 3-factor product with 1 sizeof(type) or sizeof(expression), with
    // redundant parens removed.
    @@
    expression THING;
    identifier STRIDE, COUNT;
    type TYPE;
    @@
    
    (
      kmalloc(
    -       sizeof(TYPE) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    )
    
    // 3-factor product with 2 sizeof(variable), with redundant parens removed.
    @@
    expression THING1, THING2;
    identifier COUNT;
    type TYPE1, TYPE2;
    @@
    
    (
      kmalloc(
    -       sizeof(TYPE1) * sizeof(TYPE2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kmalloc(
    -       sizeof(THING1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kmalloc(
    -       sizeof(THING1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    )
    
    // 3-factor product, only identifiers, with redundant parens removed.
    @@
    identifier STRIDE, SIZE, COUNT;
    @@
    
    (
      kmalloc(
    -       (COUNT) * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       (COUNT) * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       (COUNT) * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       (COUNT) * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    )
    
    // Any remaining multi-factor products, first at least 3-factor products,
    // when they're not all constants...
    @@
    expression E1, E2, E3;
    constant C1, C2, C3;
    @@
    
    (
      kmalloc(C1 * C2 * C3, ...)
    |
      kmalloc(
    -       (E1) * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kmalloc(
    -       (E1) * (E2) * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kmalloc(
    -       (E1) * (E2) * (E3)
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kmalloc(
    -       E1 * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    )
    
    // And then all remaining 2 factors products when they're not all constants,
    // keeping sizeof() as the second factor argument.
    @@
    expression THING, E1, E2;
    type TYPE;
    constant C1, C2, C3;
    @@
    
    (
      kmalloc(sizeof(THING) * C2, ...)
    |
      kmalloc(sizeof(TYPE) * C2, ...)
    |
      kmalloc(C1 * C2 * C3, ...)
    |
      kmalloc(C1 * C2, ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * (E2)
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * E2
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * (E2)
    +       E2, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * E2
    +       E2, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       (E1) * E2
    +       E1, E2
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       (E1) * (E2)
    +       E1, E2
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       E1 * E2
    +       E1, E2
      , ...)
    )
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 05e12aea2404..0dd87aaeb39a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -205,7 +205,8 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	if (nr_pages <= DIO_INLINE_BIO_VECS)
 		vecs = inline_vecs;
 	else {
-		vecs = kmalloc(nr_pages * sizeof(struct bio_vec), GFP_KERNEL);
+		vecs = kmalloc_array(nr_pages, sizeof(struct bio_vec),
+				     GFP_KERNEL);
 		if (!vecs)
 			return -ENOMEM;
 	}

commit 4a189982e293e662d719f5dd3ba6eec247d7bbc2
Merge: 4189b863ba32 9a6d9a62e0fd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 8 10:00:20 2018 -0700

    Merge branch 'work.aio' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull aio iopriority support from Al Viro:
     "The rest of aio stuff for this cycle - Adam's aio ioprio series"
    
    * 'work.aio' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      fs: aio ioprio use ioprio_check_cap ret val
      fs: aio ioprio add explicit block layer dependence
      fs: iomap dio set bio prio from kiocb prio
      fs: blkdev set bio prio from kiocb prio
      fs: Add aio iopriority support
      fs: Convert kiocb rw_hint from enum to u16
      block: add ioprio_check_cap function

commit 074111ca5f713e4db9d370d2502c493b8e8568c6
Author: Adam Manzanares <adam.manzanares@wdc.com>
Date:   Tue May 22 10:52:20 2018 -0700

    fs: blkdev set bio prio from kiocb prio
    
    Now that kiocb has an ioprio field copy this over to the bio when it is
    created from the kiocb.
    
    Signed-off-by: Adam Manzanares <adam.manzanares@wdc.com>
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7ec920e27065..11ba99e79d2a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -216,6 +216,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	bio.bi_write_hint = iocb->ki_hint;
 	bio.bi_private = current;
 	bio.bi_end_io = blkdev_bio_end_io_simple;
+	bio.bi_ioprio = iocb->ki_ioprio;
 
 	ret = bio_iov_iter_get_pages(&bio, iter);
 	if (unlikely(ret))
@@ -355,6 +356,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		bio->bi_write_hint = iocb->ki_hint;
 		bio->bi_private = dio;
 		bio->bi_end_io = blkdev_bio_end_io;
+		bio->bi_ioprio = iocb->ki_ioprio;
 
 		ret = bio_iov_iter_get_pages(bio, iter);
 		if (unlikely(ret)) {

commit 52190f8abe7f2bf2b4e5f9760cbcc1427ca2136b
Author: Kent Overstreet <kent.overstreet@gmail.com>
Date:   Sun May 20 18:25:55 2018 -0400

    fs: convert block_dev.c to bioset_init()
    
    Convert block DIO code to embedded bio sets.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Kent Overstreet <kent.overstreet@gmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 81c57c14fae8..bef6934b6189 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -272,7 +272,7 @@ struct blkdev_dio {
 	struct bio		bio;
 };
 
-static struct bio_set *blkdev_dio_pool __read_mostly;
+static struct bio_set blkdev_dio_pool;
 
 static void blkdev_bio_end_io(struct bio *bio)
 {
@@ -334,7 +334,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	    (bdev_logical_block_size(bdev) - 1))
 		return -EINVAL;
 
-	bio = bio_alloc_bioset(GFP_KERNEL, nr_pages, blkdev_dio_pool);
+	bio = bio_alloc_bioset(GFP_KERNEL, nr_pages, &blkdev_dio_pool);
 	bio_get(bio); /* extra ref for the completion handler */
 
 	dio = container_of(bio, struct blkdev_dio, bio);
@@ -432,10 +432,7 @@ blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
 
 static __init int blkdev_init(void)
 {
-	blkdev_dio_pool = bioset_create(4, offsetof(struct blkdev_dio, bio), BIOSET_NEED_BVECS);
-	if (!blkdev_dio_pool)
-		return -ENOMEM;
-	return 0;
+	return bioset_init(&blkdev_dio_pool, 4, offsetof(struct blkdev_dio, bio), BIOSET_NEED_BVECS);
 }
 module_init(blkdev_init);
 

commit 5afb78356cead66db2203061fed6fc8957527ed4
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 29 16:42:59 2018 +0200

    block: don't print a message when the device went away
    
    The information about a size change in this case just creates confusion.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 771ddfa29dc9..81c57c14fae8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1322,21 +1322,25 @@ static void flush_disk(struct block_device *bdev, bool kill_dirty)
  * check_disk_size_change - checks for disk size change and adjusts bdev size.
  * @disk: struct gendisk to check
  * @bdev: struct bdev to adjust.
+ * @verbose: if %true log a message about a size change if there is any
  *
  * This routine checks to see if the bdev size does not match the disk size
  * and adjusts it if it differs. When shrinking the bdev size, its all caches
  * are freed.
  */
-void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
+void check_disk_size_change(struct gendisk *disk, struct block_device *bdev,
+		bool verbose)
 {
 	loff_t disk_size, bdev_size;
 
 	disk_size = (loff_t)get_capacity(disk) << 9;
 	bdev_size = i_size_read(bdev->bd_inode);
 	if (disk_size != bdev_size) {
-		printk(KERN_INFO
-		       "%s: detected capacity change from %lld to %lld\n",
-		       disk->disk_name, bdev_size, disk_size);
+		if (verbose) {
+			printk(KERN_INFO
+			       "%s: detected capacity change from %lld to %lld\n",
+			       disk->disk_name, bdev_size, disk_size);
+		}
 		i_size_write(bdev->bd_inode, disk_size);
 		if (bdev_size > disk_size)
 			flush_disk(bdev, false);
@@ -1363,7 +1367,7 @@ int revalidate_disk(struct gendisk *disk)
 		return ret;
 
 	mutex_lock(&bdev->bd_mutex);
-	check_disk_size_change(disk, bdev);
+	check_disk_size_change(disk, bdev, ret == 0);
 	bdev->bd_invalidated = 0;
 	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);

commit 4163a0398434a9b705399ae2c48fb4fb14008434
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 29 16:42:58 2018 +0200

    block: unexport check_disk_size_change
    
    Only used in block_dev.c and the partitions code, and it should remain
    that way..
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7ec920e27065..771ddfa29dc9 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1342,7 +1342,6 @@ void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
 			flush_disk(bdev, false);
 	}
 }
-EXPORT_SYMBOL(check_disk_size_change);
 
 /**
  * revalidate_disk - wrapper for lower-level driver's revalidate_disk call-back

commit 9f3a0941fb5efaa4d27911e251dc595034d58baa
Merge: fbe173e3ffbd e13e75b86ef2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 10 10:25:57 2018 -0700

    Merge tag 'libnvdimm-for-4.17' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "This cycle was was not something I ever want to repeat as there were
      several late changes that have only now just settled.
    
      Half of the branch up to commit d2c997c0f145 ("fs, dax: use
      page->mapping to warn...") have been in -next for several releases.
      The of_pmem driver and the address range scrub rework were late
      arrivals, and the dax work was scaled back at the last moment.
    
      The of_pmem driver missed a previous merge window due to an oversight.
      A sense of obligation to rectify that miss is why it is included for
      4.17. It has acks from PowerPC folks. Stephen reported a build failure
      that only occurs when merging it with your latest tree, for now I have
      fixed that up by disabling modular builds of of_pmem. A test merge
      with your tree has received a build success report from the 0day robot
      over 156 configs.
    
      An initial version of the ARS rework was submitted before the merge
      window. It is self contained to libnvdimm, a net code reduction, and
      passing all unit tests.
    
      The filesystem-dax changes are based on the wait_var_event()
      functionality from tip/sched/core. However, late review feedback
      showed that those changes regressed truncate performance to a large
      degree. The branch was rewound to drop the truncate behavior change
      and now only includes preparation patches and cleanups (with full acks
      and reviews). The finalization of this dax-dma-vs-trnucate work will
      need to wait for 4.18.
    
      Summary:
    
       - A rework of the filesytem-dax implementation provides for detection
         of unmap operations (truncate / hole punch) colliding with
         in-progress device-DMA. A fix for these collisions remains a
         work-in-progress pending resolution of truncate latency and
         starvation regressions.
    
       - The of_pmem driver expands the users of libnvdimm outside of x86
         and ACPI to describe an implementation of persistent memory on
         PowerPC with Open Firmware / Device tree.
    
       - Address Range Scrub (ARS) handling is completely rewritten to
         account for the fact that ARS may run for 100s of seconds and there
         is no platform defined way to cancel it. ARS will now no longer
         block namespace initialization.
    
       - The NVDIMM Namespace Label implementation is updated to handle
         label areas as small as 1K, down from 128K.
    
       - Miscellaneous cleanups and updates to unit test infrastructure"
    
    * tag 'libnvdimm-for-4.17' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (39 commits)
      libnvdimm, of_pmem: workaround OF_NUMA=n build error
      nfit, address-range-scrub: add module option to skip initial ars
      nfit, address-range-scrub: rework and simplify ARS state machine
      nfit, address-range-scrub: determine one platform max_ars value
      powerpc/powernv: Create platform devs for nvdimm buses
      doc/devicetree: Persistent memory region bindings
      libnvdimm: Add device-tree based driver
      libnvdimm: Add of_node to region and bus descriptors
      libnvdimm, region: quiet region probe
      libnvdimm, namespace: use a safe lookup for dimm device name
      libnvdimm, dimm: fix dpa reservation vs uninitialized label area
      libnvdimm, testing: update the default smart ctrl_temperature
      libnvdimm, testing: Add emulation for smart injection commands
      nfit, address-range-scrub: introduce nfit_spa->ars_state
      libnvdimm: add an api to cast a 'struct nd_region' to its 'struct device'
      nfit, address-range-scrub: fix scrub in-progress reporting
      dax, dm: allow device-mapper to operate without dax support
      dax: introduce CONFIG_DAX_DRIVER
      fs, dax: use page->mapping to warn if truncate collides with a busy page
      ext2, dax: introduce ext2_dax_aops
      ...

commit 849cf55963dfd877ad92996195e0fe7218eaf0e9
Author: shunki-fujita <shunki-fujita@cybozu.co.jp>
Date:   Thu Apr 5 16:20:07 2018 -0700

    fs: don't flush pagecache when expanding block device
    
    When changing the size of a block device, its all caches are freed.
    It's necessary on shrinking to prevent spurious I/Os to the disappeared
    region.  However, on expanding, such kind of I/Os doesn't happen.
    
    Similar things can be considered for btrfs filesystem resize and
    resize2fs, but they are designed not to drop caches when expanding.
    Therefore this patch removes unnecessary cache drop.
    
    Link: http://lkml.kernel.org/r/1521457240-153390-1-git-send-email-shunki-fujita@cybozu.co.jp
    Signed-off-by: Shunki Fujita <shunki-fujita@cybozu.co.jp>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fe09ef9c21f3..7a506c55a993 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1324,7 +1324,8 @@ static void flush_disk(struct block_device *bdev, bool kill_dirty)
  * @bdev: struct bdev to adjust.
  *
  * This routine checks to see if the bdev size does not match the disk size
- * and adjusts it if it differs.
+ * and adjusts it if it differs. When shrinking the bdev size, its all caches
+ * are freed.
  */
 void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
 {
@@ -1337,7 +1338,8 @@ void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
 		       "%s: detected capacity change from %lld to %lld\n",
 		       disk->disk_name, bdev_size, disk_size);
 		i_size_write(bdev->bd_inode, disk_size);
-		flush_disk(bdev, false);
+		if (bdev_size > disk_size)
+			flush_disk(bdev, false);
 	}
 }
 EXPORT_SYMBOL(check_disk_size_change);

commit 15aa8a01189b7399d085cceae6775cc6899b1909
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun Mar 11 12:03:08 2018 -0700

    block, dax: remove dead code in blkdev_writepages()
    
    Block device inodes never have S_DAX set, so kill the check for DAX and
    diversion to dax_writeback_mapping_range().
    
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fe09ef9c21f3..846ee2d31781 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1946,11 +1946,6 @@ static int blkdev_releasepage(struct page *page, gfp_t wait)
 static int blkdev_writepages(struct address_space *mapping,
 			     struct writeback_control *wbc)
 {
-	if (dax_mapping(mapping)) {
-		struct block_device *bdev = I_BDEV(mapping->host);
-
-		return dax_writeback_mapping_range(mapping, bdev, wbc);
-	}
 	return generic_writepages(mapping, wbc);
 }
 

commit 560e7cb2f3c7f09bbfb36cd0b900e24fddd20282
Author: Jan Kara <jack@suse.cz>
Date:   Mon Feb 26 13:01:42 2018 +0100

    blockdev: Avoid two active bdev inodes for one device
    
    When blkdev_open() races with device removal and creation it can happen
    that unhashed bdev inode gets associated with newly created gendisk
    like:
    
    CPU0                                    CPU1
    blkdev_open()
      bdev = bd_acquire()
                                            del_gendisk()
                                              bdev_unhash_inode(bdev);
                                            remove device
                                            create new device with the same number
      __blkdev_get()
        disk = get_gendisk()
          - gets reference to gendisk of the new device
    
    Now another blkdev_open() will not find original 'bdev' as it got
    unhashed, create a new one and associate it with the same 'disk' at
    which point problems start as we have two independent page caches for
    one device.
    
    Fix the problem by verifying that the bdev inode didn't get unhashed
    before we acquired gendisk reference. That way we make sure gendisk can
    get associated only with visible bdev inodes.
    
    Tested-by: Hou Tao <houtao1@huawei.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fe41a76769fa..fe09ef9c21f3 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1058,6 +1058,27 @@ static int bd_prepare_to_claim(struct block_device *bdev,
 	return 0;
 }
 
+static struct gendisk *bdev_get_gendisk(struct block_device *bdev, int *partno)
+{
+	struct gendisk *disk = get_gendisk(bdev->bd_dev, partno);
+
+	if (!disk)
+		return NULL;
+	/*
+	 * Now that we hold gendisk reference we make sure bdev we looked up is
+	 * not stale. If it is, it means device got removed and created before
+	 * we looked up gendisk and we fail open in such case. Associating
+	 * unhashed bdev with newly created gendisk could lead to two bdevs
+	 * (and thus two independent caches) being associated with one device
+	 * which is bad.
+	 */
+	if (inode_unhashed(bdev->bd_inode)) {
+		put_disk_and_module(disk);
+		return NULL;
+	}
+	return disk;
+}
+
 /**
  * bd_start_claiming - start claiming a block device
  * @bdev: block device of interest
@@ -1094,7 +1115,7 @@ static struct block_device *bd_start_claiming(struct block_device *bdev,
 	 * @bdev might not have been initialized properly yet, look up
 	 * and grab the outer block device the hard way.
 	 */
-	disk = get_gendisk(bdev->bd_dev, &partno);
+	disk = bdev_get_gendisk(bdev, &partno);
 	if (!disk)
 		return ERR_PTR(-ENXIO);
 
@@ -1429,7 +1450,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
  restart:
 
 	ret = -ENXIO;
-	disk = get_gendisk(bdev->bd_dev, &partno);
+	disk = bdev_get_gendisk(bdev, &partno);
 	if (!disk)
 		goto out;
 

commit 897366537fb65e87755b822360c230354c3fc73b
Author: Jan Kara <jack@suse.cz>
Date:   Mon Feb 26 13:01:40 2018 +0100

    genhd: Fix use after free in __blkdev_get()
    
    When two blkdev_open() calls race with device removal and recreation,
    __blkdev_get() can use looked up gendisk after it is freed:
    
    CPU0                            CPU1                    CPU2
                                                            del_gendisk(disk);
                                                              bdev_unhash_inode(inode);
    blkdev_open()                   blkdev_open()
      bdev = bd_acquire(inode);
        - creates and returns new inode
                                      bdev = bd_acquire(inode);
                                        - returns the same inode
      __blkdev_get(devt)              __blkdev_get(devt)
        disk = get_gendisk(devt);
          - got structure of device going away
                                                            <finish device removal>
                                                            <new device gets
                                                             created under the same
                                                             device number>
                                      disk = get_gendisk(devt);
                                        - got new device structure
                                      if (!bdev->bd_openers) {
                                        does the first open
                                      }
        if (!bdev->bd_openers)
          - false
        } else {
          put_disk_and_module(disk)
            - remember this was old device - this was last ref and disk is
              now freed
        }
        disk_unblock_events(disk); -> oops
    
    Fix the problem by making sure we drop reference to disk in
    __blkdev_get() only after we are really done with it.
    
    Reported-by: Hou Tao <houtao1@huawei.com>
    Tested-by: Hou Tao <houtao1@huawei.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1dbbf847911a..fe41a76769fa 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1409,6 +1409,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	int ret;
 	int partno;
 	int perm = 0;
+	bool first_open = false;
 
 	if (mode & FMODE_READ)
 		perm |= MAY_READ;
@@ -1435,6 +1436,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	disk_block_events(disk);
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (!bdev->bd_openers) {
+		first_open = true;
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
@@ -1520,14 +1522,15 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (ret)
 				goto out_unlock_bdev;
 		}
-		/* only one opener holds refs to the module and disk */
-		put_disk_and_module(disk);
 	}
 	bdev->bd_openers++;
 	if (for_part)
 		bdev->bd_part_count++;
 	mutex_unlock(&bdev->bd_mutex);
 	disk_unblock_events(disk);
+	/* only one opener holds refs to the module and disk */
+	if (!first_open)
+		put_disk_and_module(disk);
 	return 0;
 
  out_clear:

commit 9df6c29912315186fef1c79cc15b758ace84175b
Author: Jan Kara <jack@suse.cz>
Date:   Mon Feb 26 13:01:39 2018 +0100

    genhd: Add helper put_disk_and_module()
    
    Add a proper counterpart to get_disk_and_module() -
    put_disk_and_module(). Currently it is opencoded in several places.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4a181fcb5175..1dbbf847911a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1111,8 +1111,7 @@ static struct block_device *bd_start_claiming(struct block_device *bdev,
 	else
 		whole = bdgrab(bdev);
 
-	module_put(disk->fops->owner);
-	put_disk(disk);
+	put_disk_and_module(disk);
 	if (!whole)
 		return ERR_PTR(-ENOMEM);
 
@@ -1407,7 +1406,6 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 {
 	struct gendisk *disk;
-	struct module *owner;
 	int ret;
 	int partno;
 	int perm = 0;
@@ -1433,7 +1431,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	disk = get_gendisk(bdev->bd_dev, &partno);
 	if (!disk)
 		goto out;
-	owner = disk->fops->owner;
 
 	disk_block_events(disk);
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
@@ -1463,8 +1460,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 					bdev->bd_queue = NULL;
 					mutex_unlock(&bdev->bd_mutex);
 					disk_unblock_events(disk);
-					put_disk(disk);
-					module_put(owner);
+					put_disk_and_module(disk);
 					goto restart;
 				}
 			}
@@ -1525,8 +1521,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_unlock_bdev;
 		}
 		/* only one opener holds refs to the module and disk */
-		put_disk(disk);
-		module_put(owner);
+		put_disk_and_module(disk);
 	}
 	bdev->bd_openers++;
 	if (for_part)
@@ -1546,8 +1541,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
  out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
 	disk_unblock_events(disk);
-	put_disk(disk);
-	module_put(owner);
+	put_disk_and_module(disk);
  out:
 	bdput(bdev);
 
@@ -1770,8 +1764,6 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 			disk->fops->release(disk, mode);
 	}
 	if (!bdev->bd_openers) {
-		struct module *owner = disk->fops->owner;
-
 		disk_put_part(bdev->bd_part);
 		bdev->bd_part = NULL;
 		bdev->bd_disk = NULL;
@@ -1779,8 +1771,7 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 			victim = bdev->bd_contains;
 		bdev->bd_contains = NULL;
 
-		put_disk(disk);
-		module_put(owner);
+		put_disk_and_module(disk);
 	}
 	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);

commit e2c5923c349c1738fe8fda980874d93f6fb2e5b6
Merge: abc36be23635 a04b5de5050a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 15:32:19 2017 -0800

    Merge branch 'for-4.15/block' of git://git.kernel.dk/linux-block
    
    Pull core block layer updates from Jens Axboe:
     "This is the main pull request for block storage for 4.15-rc1.
    
      Nothing out of the ordinary in here, and no API changes or anything
      like that. Just various new features for drivers, core changes, etc.
      In particular, this pull request contains:
    
       - A patch series from Bart, closing the whole on blk/scsi-mq queue
         quescing.
    
       - A series from Christoph, building towards hidden gendisks (for
         multipath) and ability to move bio chains around.
    
       - NVMe
            - Support for native multipath for NVMe (Christoph).
            - Userspace notifications for AENs (Keith).
            - Command side-effects support (Keith).
            - SGL support (Chaitanya Kulkarni)
            - FC fixes and improvements (James Smart)
            - Lots of fixes and tweaks (Various)
    
       - bcache
            - New maintainer (Michael Lyle)
            - Writeback control improvements (Michael)
            - Various fixes (Coly, Elena, Eric, Liang, et al)
    
       - lightnvm updates, mostly centered around the pblk interface
         (Javier, Hans, and Rakesh).
    
       - Removal of unused bio/bvec kmap atomic interfaces (me, Christoph)
    
       - Writeback series that fix the much discussed hundreds of millions
         of sync-all units. This goes all the way, as discussed previously
         (me).
    
       - Fix for missing wakeup on writeback timer adjustments (Yafang
         Shao).
    
       - Fix laptop mode on blk-mq (me).
    
       - {mq,name} tupple lookup for IO schedulers, allowing us to have
         alias names. This means you can use 'deadline' on both !mq and on
         mq (where it's called mq-deadline). (me).
    
       - blktrace race fix, oopsing on sg load (me).
    
       - blk-mq optimizations (me).
    
       - Obscure waitqueue race fix for kyber (Omar).
    
       - NBD fixes (Josef).
    
       - Disable writeback throttling by default on bfq, like we do on cfq
         (Luca Miccio).
    
       - Series from Ming that enable us to treat flush requests on blk-mq
         like any other request. This is a really nice cleanup.
    
       - Series from Ming that improves merging on blk-mq with schedulers,
         getting us closer to flipping the switch on scsi-mq again.
    
       - BFQ updates (Paolo).
    
       - blk-mq atomic flags memory ordering fixes (Peter Z).
    
       - Loop cgroup support (Shaohua).
    
       - Lots of minor fixes from lots of different folks, both for core and
         driver code"
    
    * 'for-4.15/block' of git://git.kernel.dk/linux-block: (294 commits)
      nvme: fix visibility of "uuid" ns attribute
      blk-mq: fixup some comment typos and lengths
      ide: ide-atapi: fix compile error with defining macro DEBUG
      blk-mq: improve tag waiting setup for non-shared tags
      brd: remove unused brd_mutex
      blk-mq: only run the hardware queue if IO is pending
      block: avoid null pointer dereference on null disk
      fs: guard_bio_eod() needs to consider partitions
      xtensa/simdisk: fix compile error
      nvme: expose subsys attribute to sysfs
      nvme: create 'slaves' and 'holders' entries for hidden controllers
      block: create 'slaves' and 'holders' entries for hidden gendisks
      nvme: also expose the namespace identification sysfs files for mpath nodes
      nvme: implement multipath access to nvme subsystems
      nvme: track shared namespaces
      nvme: introduce a nvme_ns_ids structure
      nvme: track subsystems
      block, nvme: Introduce blk_mq_req_flags_t
      block, scsi: Make SCSI quiesce and resume work reliably
      block: Add the QUEUE_FLAG_PREEMPT_ONLY request queue flag
      ...

commit 3a0a529971ec4e2d933e9c7798db101dfb6b1aec
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Nov 9 10:49:58 2017 -0800

    block, scsi: Make SCSI quiesce and resume work reliably
    
    The contexts from which a SCSI device can be quiesced or resumed are:
    * Writing into /sys/class/scsi_device/*/device/state.
    * SCSI parallel (SPI) domain validation.
    * The SCSI device power management methods. See also scsi_bus_pm_ops.
    
    It is essential during suspend and resume that neither the filesystem
    state nor the filesystem metadata in RAM changes. This is why while
    the hibernation image is being written or restored that SCSI devices
    are quiesced. The SCSI core quiesces devices through scsi_device_quiesce()
    and scsi_device_resume(). In the SDEV_QUIESCE state execution of
    non-preempt requests is deferred. This is realized by returning
    BLKPREP_DEFER from inside scsi_prep_state_check() for quiesced SCSI
    devices. Avoid that a full queue prevents power management requests
    to be submitted by deferring allocation of non-preempt requests for
    devices in the quiesced state. This patch has been tested by running
    the following commands and by verifying that after each resume the
    fio job was still running:
    
    for ((i=0; i<10; i++)); do
      (
        cd /sys/block/md0/md &&
        while true; do
          [ "$(<sync_action)" = "idle" ] && echo check > sync_action
          sleep 1
        done
      ) &
      pids=($!)
      for d in /sys/class/block/sd*[a-z]; do
        bdev=${d#/sys/class/block/}
        hcil=$(readlink "$d/device")
        hcil=${hcil#../../../}
        echo 4 > "$d/queue/nr_requests"
        echo 1 > "/sys/class/scsi_device/$hcil/device/queue_depth"
        fio --name="$bdev" --filename="/dev/$bdev" --buffered=0 --bs=512 \
          --rw=randread --ioengine=libaio --numjobs=4 --iodepth=16       \
          --iodepth_batch=1 --thread --loops=$((2**31)) &
        pids+=($!)
      done
      sleep 1
      echo "$(date) Hibernating ..." >>hibernate-test-log.txt
      systemctl hibernate
      sleep 10
      kill "${pids[@]}"
      echo idle > /sys/block/md0/md/sync_action
      wait
      echo "$(date) Done." >>hibernate-test-log.txt
    done
    
    Reported-by: Oleksandr Natalenko <oleksandr@natalenko.name>
    References: "I/O hangs after resuming from suspend-to-ram" (https://marc.info/?l=linux-block&m=150340235201348).
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Tested-by: Martin Steigerwald <martin@lichtvoll.de>
    Tested-by: Oleksandr Natalenko <oleksandr@natalenko.name>
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: Ming Lei <ming.lei@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4afa4d5ff969..04973f484422 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -662,7 +662,7 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return result;
 
-	result = blk_queue_enter(bdev->bd_queue, false);
+	result = blk_queue_enter(bdev->bd_queue, 0);
 	if (result)
 		return result;
 	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, false);
@@ -698,7 +698,7 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 
 	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return -EOPNOTSUPP;
-	result = blk_queue_enter(bdev->bd_queue, false);
+	result = blk_queue_enter(bdev->bd_queue, 0);
 	if (result)
 		return result;
 

commit ea435e1b9392a33deceaea2a16ebaa3397bead93
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 2 21:29:54 2017 +0300

    block: add a poll_fn callback to struct request_queue
    
    That we we can also poll non blk-mq queues.  Mostly needed for
    the NVMe multipath code, but could also be useful elsewhere.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 07ddccd17801..4afa4d5ff969 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -237,7 +237,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 		if (!READ_ONCE(bio.bi_private))
 			break;
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
-		    !blk_mq_poll(bdev_get_queue(bdev), qc))
+		    !blk_poll(bdev_get_queue(bdev), qc))
 			io_schedule();
 	}
 	__set_current_state(TASK_RUNNING);
@@ -402,7 +402,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 			break;
 
 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
-		    !blk_mq_poll(bdev_get_queue(bdev), qc))
+		    !blk_poll(bdev_get_queue(bdev), qc))
 			io_schedule();
 	}
 	__set_current_state(TASK_RUNNING);

commit f892760aa66a2d657deaf59538fb69433036767c
Author: Matthew Wilcox <willy@infradead.org>
Date:   Fri Oct 13 15:58:15 2017 -0700

    fs/mpage.c: fix mpage_writepage() for pages with buffers
    
    When using FAT on a block device which supports rw_page, we can hit
    BUG_ON(!PageLocked(page)) in try_to_free_buffers().  This is because we
    call clean_buffers() after unlocking the page we've written.  Introduce
    a new clean_page_buffers() which cleans all buffers associated with a
    page and call it from within bdev_write_page().
    
    [akpm@linux-foundation.org: s/PAGE_SIZE/~0U/ per Linus and Matthew]
    Link: http://lkml.kernel.org/r/20171006211541.GA7409@bombadil.infradead.org
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Reported-by: Toshi Kani <toshi.kani@hpe.com>
    Reported-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Tested-by: Toshi Kani <toshi.kani@hpe.com>
    Acked-by: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 93d088ffc05c..789f55e851ae 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -716,10 +716,12 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 
 	set_page_writeback(page);
 	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, true);
-	if (result)
+	if (result) {
 		end_page_writeback(page);
-	else
+	} else {
+		clean_page_buffers(page);
 		unlock_page(page);
+	}
 	blk_queue_exit(bdev->bd_queue);
 	return result;
 }

commit 7f66721a7d5bf6251f9c49aada9200c61ddcecc5
Author: Rakesh Pandit <rakesh@tuxera.com>
Date:   Thu Oct 12 19:58:10 2017 +0300

    fs/block_dev: remove vfs_msg() interface
    
    Replaced by pr_err usage in commit ef51042472f5 ("block, dax: move
    "select DAX" from BLOCK to FS_DAX")
    
    Signed-off-by: Rakesh Pandit <rakesh@tuxera.com>
    Acked-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 93d088ffc05c..07ddccd17801 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -54,18 +54,6 @@ struct block_device *I_BDEV(struct inode *inode)
 }
 EXPORT_SYMBOL(I_BDEV);
 
-void __vfs_msg(struct super_block *sb, const char *prefix, const char *fmt, ...)
-{
-	struct va_format vaf;
-	va_list args;
-
-	va_start(args, fmt);
-	vaf.fmt = fmt;
-	vaf.va = &args;
-	printk_ratelimited("%sVFS (%s): %pV\n", prefix, sb->s_id, &vaf);
-	va_end(args);
-}
-
 static void bdev_write_inode(struct block_device *bdev)
 {
 	struct inode *inode = bdev->bd_inode;

commit e253d98f5babbec7e6ced810f7335b265a7f7e83
Merge: 0f0d12728e56 c35fc7a5abae
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 19:29:55 2017 -0700

    Merge branch 'work.read_write' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull nowait read support from Al Viro:
     "Support IOCB_NOWAIT for buffered reads and block devices"
    
    * 'work.read_write' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      block_dev: support RFW_NOWAIT on block device nodes
      fs: support RWF_NOWAIT for buffered reads
      fs: support IOCB_NOWAIT in generic_file_buffered_read
      fs: pass iocb to do_generic_file_read

commit c35fc7a5abae9c154dd6f8c0b288462342facd45
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Aug 29 16:13:21 2017 +0200

    block_dev: support RFW_NOWAIT on block device nodes
    
    All support is already there in the generic code, we just need to wire
    it up.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9941dc8342df..ea21d18d8e79 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1739,6 +1739,8 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	 */
 	filp->f_flags |= O_LARGEFILE;
 
+	filp->f_mode |= FMODE_NOWAIT;
+
 	if (filp->f_flags & O_NDELAY)
 		filp->f_mode |= FMODE_NDELAY;
 	if (filp->f_flags & O_EXCL)
@@ -1891,6 +1893,9 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 	if (iocb->ki_pos >= size)
 		return -ENOSPC;
 
+	if ((iocb->ki_flags & (IOCB_NOWAIT | IOCB_DIRECT)) == IOCB_NOWAIT)
+		return -EOPNOTSUPP;
+
 	iov_iter_truncate(from, size - iocb->ki_pos);
 
 	blk_start_plug(&plug);

commit 74d46992e0d9dee7f1f376de0d56d31614c8a17a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 23 19:10:32 2017 +0200

    block: replace bi_bdev with a gendisk pointer and partitions index
    
    This way we don't need a block_device structure to submit I/O.  The
    block_device has different life time rules from the gendisk and
    request_queue and is usually only available when the block device node
    is open.  Other callers need to explicitly create one (e.g. the lightnvm
    passthrough code, or the new nvme multipathing code).
    
    For the actual I/O path all that we need is the gendisk, which exists
    once per block device.  But given that the block layer also does
    partition remapping we additionally need a partition index, which is
    used for said remapping in generic_make_request.
    
    Note that all the block drivers generally want request_queue or
    sometimes the gendisk, so this removes a layer of indirection all
    over the stack.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d29d1c70f833..bb715b2fcfb8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -223,7 +223,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	}
 
 	bio_init(&bio, vecs, nr_pages);
-	bio.bi_bdev = bdev;
+	bio_set_dev(&bio, bdev);
 	bio.bi_iter.bi_sector = pos >> 9;
 	bio.bi_write_hint = iocb->ki_hint;
 	bio.bi_private = current;
@@ -362,7 +362,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 	blk_start_plug(&plug);
 	for (;;) {
-		bio->bi_bdev = bdev;
+		bio_set_dev(bio, bdev);
 		bio->bi_iter.bi_sector = pos >> 9;
 		bio->bi_write_hint = iocb->ki_hint;
 		bio->bi_private = dio;

commit c2ee070fb00365d7841f6661dcdc7fbe6620bdf8
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 23 19:10:31 2017 +0200

    block: cache the partition index in struct block_device
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9941dc8342df..d29d1c70f833 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1451,6 +1451,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
+		bdev->bd_partno = partno;
 
 		if (!partno) {
 			ret = -ENXIO;

commit 088737f44bbf6378745f5b57b035e57ee3dc4750
Merge: 33198c165b7a 333427a505be
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 7 19:38:17 2017 -0700

    Merge tag 'for-linus-v4.13-2' of git://git.kernel.org/pub/scm/linux/kernel/git/jlayton/linux
    
    Pull Writeback error handling updates from Jeff Layton:
     "This pile represents the bulk of the writeback error handling fixes
      that I have for this cycle. Some of the earlier patches in this pile
      may look trivial but they are prerequisites for later patches in the
      series.
    
      The aim of this set is to improve how we track and report writeback
      errors to userland. Most applications that care about data integrity
      will periodically call fsync/fdatasync/msync to ensure that their
      writes have made it to the backing store.
    
      For a very long time, we have tracked writeback errors using two flags
      in the address_space: AS_EIO and AS_ENOSPC. Those flags are set when a
      writeback error occurs (via mapping_set_error) and are cleared as a
      side-effect of filemap_check_errors (as you noted yesterday). This
      model really sucks for userland.
    
      Only the first task to call fsync (or msync or fdatasync) will see the
      error. Any subsequent task calling fsync on a file will get back 0
      (unless another writeback error occurs in the interim). If I have
      several tasks writing to a file and calling fsync to ensure that their
      writes got stored, then I need to have them coordinate with one
      another. That's difficult enough, but in a world of containerized
      setups that coordination may even not be possible.
    
      But wait...it gets worse!
    
      The calls to filemap_check_errors can be buried pretty far down in the
      call stack, and there are internal callers of filemap_write_and_wait
      and the like that also end up clearing those errors. Many of those
      callers ignore the error return from that function or return it to
      userland at nonsensical times (e.g. truncate() or stat()). If I get
      back -EIO on a truncate, there is no reason to think that it was
      because some previous writeback failed, and a subsequent fsync() will
      (incorrectly) return 0.
    
      This pile aims to do three things:
    
       1) ensure that when a writeback error occurs that that error will be
          reported to userland on a subsequent fsync/fdatasync/msync call,
          regardless of what internal callers are doing
    
       2) report writeback errors on all file descriptions that were open at
          the time that the error occurred. This is a user-visible change,
          but I think most applications are written to assume this behavior
          anyway. Those that aren't are unlikely to be hurt by it.
    
       3) document what filesystems should do when there is a writeback
          error. Today, there is very little consistency between them, and a
          lot of cargo-cult copying. We need to make it very clear what
          filesystems should do in this situation.
    
      To achieve this, the set adds a new data type (errseq_t) and then
      builds new writeback error tracking infrastructure around that. Once
      all of that is in place, we change the filesystems to use the new
      infrastructure for reporting wb errors to userland.
    
      Note that this is just the initial foray into cleaning up this mess.
      There is a lot of work remaining here:
    
       1) convert the rest of the filesystems in a similar fashion. Once the
          initial set is in, then I think most other fs' will be fairly
          simple to convert. Hopefully most of those can in via individual
          filesystem trees.
    
       2) convert internal waiters on writeback to use errseq_t for
          detecting errors instead of relying on the AS_* flags. I have some
          draft patches for this for ext4, but they are not quite ready for
          prime time yet.
    
      This was a discussion topic this year at LSF/MM too. If you're
      interested in the gory details, LWN has some good articles about this:
    
          https://lwn.net/Articles/718734/
          https://lwn.net/Articles/724307/"
    
    * tag 'for-linus-v4.13-2' of git://git.kernel.org/pub/scm/linux/kernel/git/jlayton/linux:
      btrfs: minimal conversion to errseq_t writeback error reporting on fsync
      xfs: minimal conversion to errseq_t writeback error reporting
      ext4: use errseq_t based error handling for reporting data writeback errors
      fs: convert __generic_file_fsync to use errseq_t based reporting
      block: convert to errseq_t based writeback error tracking
      dax: set errors in mapping when writeback fails
      Documentation: flesh out the section in vfs.txt on storing and reporting writeback errors
      mm: set both AS_EIO/AS_ENOSPC and errseq_t in mapping_set_error
      fs: new infrastructure for writeback error handling and reporting
      lib: add errseq_t type and infrastructure for handling it
      mm: don't TestClearPageError in __filemap_fdatawait_range
      mm: clear AS_EIO/AS_ENOSPC when writeback initiation fails
      jbd2: don't clear and reset errors after waiting on writeback
      buffer: set errors in mapping at the time that the error occurs
      fs: check for writeback errors after syncing out buffers in generic_file_fsync
      buffer: use mapping_set_error instead of setting the flag
      mm: fix mapping_set_error call in me_pagecache_dirty

commit 372cf243ea9a36d88ff67ae44f4512f64a6bca81
Author: Jeff Layton <jlayton@redhat.com>
Date:   Thu Jul 6 07:02:28 2017 -0400

    block: convert to errseq_t based writeback error tracking
    
    This is a very minimal conversion to errseq_t based error tracking
    for raw block device access. Just have it use the standard
    file_write_and_wait_range call.
    
    Note that there are internal callers that call sync_blockdev
    and the like that are not affected by this. They'll continue
    to use the AS_EIO/AS_ENOSPC flags for error reporting like
    they always have for now.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jeff Layton <jlayton@redhat.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4d62fe771587..bcb0be6e423a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -624,7 +624,7 @@ int blkdev_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 	struct block_device *bdev = I_BDEV(bd_inode);
 	int error;
 	
-	error = filemap_write_and_wait_range(filp->f_mapping, start, end);
+	error = file_write_and_wait_range(filp, start, end);
 	if (error)
 		return error;
 

commit 5660e13d2fd6af1903d4b0b98020af95ca2d638a
Author: Jeff Layton <jlayton@redhat.com>
Date:   Thu Jul 6 07:02:25 2017 -0400

    fs: new infrastructure for writeback error handling and reporting
    
    Most filesystems currently use mapping_set_error and
    filemap_check_errors for setting and reporting/clearing writeback errors
    at the mapping level. filemap_check_errors is indirectly called from
    most of the filemap_fdatawait_* functions and from
    filemap_write_and_wait*. These functions are called from all sorts of
    contexts to wait on writeback to finish -- e.g. mostly in fsync, but
    also in truncate calls, getattr, etc.
    
    The non-fsync callers are problematic. We should be reporting writeback
    errors during fsync, but many places spread over the tree clear out
    errors before they can be properly reported, or report errors at
    nonsensical times.
    
    If I get -EIO on a stat() call, there is no reason for me to assume that
    it is because some previous writeback failed. The fact that it also
    clears out the error such that a subsequent fsync returns 0 is a bug,
    and a nasty one since that's potentially silent data corruption.
    
    This patch adds a small bit of new infrastructure for setting and
    reporting errors during address_space writeback. While the above was my
    original impetus for adding this, I think it's also the case that
    current fsync semantics are just problematic for userland. Most
    applications that call fsync do so to ensure that the data they wrote
    has hit the backing store.
    
    In the case where there are multiple writers to the file at the same
    time, this is really hard to determine. The first one to call fsync will
    see any stored error, and the rest get back 0. The processes with open
    fds may not be associated with one another in any way. They could even
    be in different containers, so ensuring coordination between all fsync
    callers is not really an option.
    
    One way to remedy this would be to track what file descriptor was used
    to dirty the file, but that's rather cumbersome and would likely be
    slow. However, there is a simpler way to improve the semantics here
    without incurring too much overhead.
    
    This set adds an errseq_t to struct address_space, and a corresponding
    one is added to struct file. Writeback errors are recorded in the
    mapping's errseq_t, and the one in struct file is used as the "since"
    value.
    
    This changes the semantics of the Linux fsync implementation such that
    applications can now use it to determine whether there were any
    writeback errors since fsync(fd) was last called (or since the file was
    opened in the case of fsync having never been called).
    
    Note that those writeback errors may have occurred when writing data
    that was dirtied via an entirely different fd, but that's the case now
    with the current mapping_set_error/filemap_check_error infrastructure.
    This will at least prevent you from getting a false report of success.
    
    The new behavior is still consistent with the POSIX spec, and is more
    reliable for application developers. This patch just adds some basic
    infrastructure for doing this, and ensures that the f_wb_err "cursor"
    is properly set when a file is opened. Later patches will change the
    existing code to use this new infrastructure for reporting errors at
    fsync time.
    
    Signed-off-by: Jeff Layton <jlayton@redhat.com>
    Reviewed-by: Jan Kara <jack@suse.cz>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 519599dddd36..4d62fe771587 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1743,6 +1743,7 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 		return -ENOMEM;
 
 	filp->f_mapping = bdev->bd_inode->i_mapping;
+	filp->f_wb_err = filemap_sample_wb_err(filp->f_mapping);
 
 	return blkdev_get(bdev, filp->f_mode, filp);
 }

commit c6b1e36c8fa04a6680c44fe0321d0370400e90b6
Merge: 81e3e044897b a84ebb837b41
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 3 10:34:51 2017 -0700

    Merge branch 'for-4.13/block' of git://git.kernel.dk/linux-block
    
    Pull core block/IO updates from Jens Axboe:
     "This is the main pull request for the block layer for 4.13. Not a huge
      round in terms of features, but there's a lot of churn related to some
      core cleanups.
    
      Note this depends on the UUID tree pull request, that Christoph
      already sent out.
    
      This pull request contains:
    
       - A series from Christoph, unifying the error/stats codes in the
         block layer. We now use blk_status_t everywhere, instead of using
         different schemes for different places.
    
       - Also from Christoph, some cleanups around request allocation and IO
         scheduler interactions in blk-mq.
    
       - And yet another series from Christoph, cleaning up how we handle
         and do bounce buffering in the block layer.
    
       - A blk-mq debugfs series from Bart, further improving on the support
         we have for exporting internal information to aid debugging IO
         hangs or stalls.
    
       - Also from Bart, a series that cleans up the request initialization
         differences across types of devices.
    
       - A series from Goldwyn Rodrigues, allowing the block layer to return
         failure if we will block and the user asked for non-blocking.
    
       - Patch from Hannes for supporting setting loop devices block size to
         that of the underlying device.
    
       - Two series of patches from Javier, fixing various issues with
         lightnvm, particular around pblk.
    
       - A series from me, adding support for write hints. This comes with
         NVMe support as well, so applications can help guide data placement
         on flash to improve performance, latencies, and write
         amplification.
    
       - A series from Ming, improving and hardening blk-mq support for
         stopping/starting and quiescing hardware queues.
    
       - Two pull requests for NVMe updates. Nothing major on the feature
         side, but lots of cleanups and bug fixes. From the usual crew.
    
       - A series from Neil Brown, greatly improving the bio rescue set
         support. Most notably, this kills the bio rescue work queues, if we
         don't really need them.
    
       - Lots of other little bug fixes that are all over the place"
    
    * 'for-4.13/block' of git://git.kernel.dk/linux-block: (217 commits)
      lightnvm: pblk: set line bitmap check under debug
      lightnvm: pblk: verify that cache read is still valid
      lightnvm: pblk: add initialization check
      lightnvm: pblk: remove target using async. I/Os
      lightnvm: pblk: use vmalloc for GC data buffer
      lightnvm: pblk: use right metadata buffer for recovery
      lightnvm: pblk: schedule if data is not ready
      lightnvm: pblk: remove unused return variable
      lightnvm: pblk: fix double-free on pblk init
      lightnvm: pblk: fix bad le64 assignations
      nvme: Makefile: remove dead build rule
      blk-mq: map all HWQ also in hyperthreaded system
      nvmet-rdma: register ib_client to not deadlock in device removal
      nvme_fc: fix error recovery on link down.
      nvmet_fc: fix crashes on bad opcodes
      nvme_fc: Fix crash when nvme controller connection fails.
      nvme_fc: replace ioabort msleep loop with completion
      nvme_fc: fix double calls to nvme_cleanup_cmd()
      nvme-fabrics: verify that a controller returns the correct NQN
      nvme: simplify nvme_dev_attrs_are_visible
      ...

commit 9ae3b3f52c62ddd5eb12c57f195f4f38121faa01
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Jun 28 15:30:13 2017 -0600

    block: provide bio_uninit() free freeing integrity/task associations
    
    Wen reports significant memory leaks with DIF and O_DIRECT:
    
    "With nvme devive + T10 enabled, On a system it has 256GB and started
    logging /proc/meminfo & /proc/slabinfo for every minute and in an hour
    it increased by 15968128 kB or ~15+GB.. Approximately 256 MB / minute
    leaking.
    
    /proc/meminfo | grep SUnreclaim...
    
    SUnreclaim:      6752128 kB
    SUnreclaim:      6874880 kB
    SUnreclaim:      7238080 kB
    ....
    SUnreclaim:     22307264 kB
    SUnreclaim:     22485888 kB
    SUnreclaim:     22720256 kB
    
    When testcases with T10 enabled call into __blkdev_direct_IO_simple,
    code doesn't free memory allocated by bio_integrity_alloc. The patch
    fixes the issue. HTX has been run with +60 hours without failure."
    
    Since __blkdev_direct_IO_simple() allocates the bio on the stack, it
    doesn't go through the regular bio free. This means that any ancillary
    data allocated with the bio through the stack is not freed. Hence, we
    can leak the integrity data associated with the bio, if the device is
    using DIF/DIX.
    
    Fix this by providing a bio_uninit() and export it, so that we can use
    it to free this data. Note that this is a minimal fix for this issue.
    Any current user of bio's that are allocated outside of
    bio_alloc_bioset() suffers from this issue, most notably some drivers.
    We will fix those in a more comprehensive patch for 4.13. This also
    means that the commit marked as being fixed by this isn't the real
    culprit, it's just the most obvious one out there.
    
    Fixes: 542ff7bf18c6 ("block: new direct I/O implementation")
    Reported-by: Wen Xiong <wenxiong@linux.vnet.ibm.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 519599dddd36..0a7404ef9335 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -263,7 +263,10 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 		kfree(vecs);
 
 	if (unlikely(bio.bi_error))
-		return bio.bi_error;
+		ret = bio.bi_error;
+
+	bio_uninit(&bio);
+
 	return ret;
 }
 

commit 45d06cf701a3866e0d246789039a46370af60223
Author: Jens Axboe <axboe@kernel.dk>
Date:   Tue Jun 27 11:01:22 2017 -0600

    fs: add O_DIRECT and aio support for sending down write life time hints
    
    Reviewed-by: Andreas Dilger <adilger@dilger.ca>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index dd91c99e9ba0..2c5f08696fff 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -225,6 +225,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	bio_init(&bio, vecs, nr_pages);
 	bio.bi_bdev = bdev;
 	bio.bi_iter.bi_sector = pos >> 9;
+	bio.bi_write_hint = iocb->ki_hint;
 	bio.bi_private = current;
 	bio.bi_end_io = blkdev_bio_end_io_simple;
 
@@ -360,6 +361,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	for (;;) {
 		bio->bi_bdev = bdev;
 		bio->bi_iter.bi_sector = pos >> 9;
+		bio->bi_write_hint = iocb->ki_hint;
 		bio->bi_private = dio;
 		bio->bi_end_io = blkdev_bio_end_io;
 

commit 011067b05668b05aae88e5a24cff0ca0a67ca0b0
Author: NeilBrown <neilb@suse.com>
Date:   Sun Jun 18 14:38:57 2017 +1000

    blk: replace bioset_create_nobvec() with a flags arg to bioset_create()
    
    "flags" arguments are often seen as good API design as they allow
    easy extensibility.
    bioset_create_nobvec() is implemented internally as a variation in
    flags passed to __bioset_create().
    
    To support future extension, make the internal structure part of the
    API.
    i.e. add a 'flags' argument to bioset_create() and discard
    bioset_create_nobvec().
    
    Note that the bio_split allocations in drivers/md/raid* do not need
    the bvec mempool - they should have used bioset_create_nobvec().
    
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Reviewed-by: Christoph Hellwig <hch@infradead.org>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index bcd8e16a34e1..dd91c99e9ba0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -439,7 +439,7 @@ blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
 
 static __init int blkdev_init(void)
 {
-	blkdev_dio_pool = bioset_create(4, offsetof(struct blkdev_dio, bio));
+	blkdev_dio_pool = bioset_create(4, offsetof(struct blkdev_dio, bio), BIOSET_NEED_BVECS);
 	if (!blkdev_dio_pool)
 		return -ENOMEM;
 	return 0;

commit 4e4cbee93d56137ebff722be022cae5f70ef84fb
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:06 2017 +0200

    block: switch bios to blk_status_t
    
    Replace bi_error with a new bi_status to allow for a clear conversion.
    Note that device mapper overloaded bi_error with a private value, which
    we'll have to keep arround at least for now and thus propagate to a
    proper blk_status_t value.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c1dc393ad6b9..bcd8e16a34e1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -262,8 +262,8 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	if (vecs != inline_vecs)
 		kfree(vecs);
 
-	if (unlikely(bio.bi_error))
-		return bio.bi_error;
+	if (unlikely(bio.bi_status))
+		return blk_status_to_errno(bio.bi_status);
 	return ret;
 }
 
@@ -288,16 +288,18 @@ static void blkdev_bio_end_io(struct bio *bio)
 	bool should_dirty = dio->should_dirty;
 
 	if (dio->multi_bio && !atomic_dec_and_test(&dio->ref)) {
-		if (bio->bi_error && !dio->bio.bi_error)
-			dio->bio.bi_error = bio->bi_error;
+		if (bio->bi_status && !dio->bio.bi_status)
+			dio->bio.bi_status = bio->bi_status;
 	} else {
 		if (!dio->is_sync) {
 			struct kiocb *iocb = dio->iocb;
-			ssize_t ret = dio->bio.bi_error;
+			ssize_t ret;
 
-			if (likely(!ret)) {
+			if (likely(!dio->bio.bi_status)) {
 				ret = dio->size;
 				iocb->ki_pos += ret;
+			} else {
+				ret = blk_status_to_errno(dio->bio.bi_status);
 			}
 
 			dio->iocb->ki_complete(iocb, ret, 0);
@@ -363,7 +365,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 		ret = bio_iov_iter_get_pages(bio, iter);
 		if (unlikely(ret)) {
-			bio->bi_error = -EIO;
+			bio->bi_status = BLK_STS_IOERR;
 			bio_endio(bio);
 			break;
 		}
@@ -413,7 +415,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	__set_current_state(TASK_RUNNING);
 
 	if (!ret)
-		ret = dio->bio.bi_error;
+		ret = blk_status_to_errno(dio->bio.bi_status);
 	if (likely(!ret))
 		ret = dio->size;
 

commit 36ffc6c1c0e67acdacb53348350d0a37206dbadf
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:00 2017 +0200

    block_dev: propagate bio_iov_iter_get_pages error in __blkdev_direct_IO
    
    Once we move the block layer to its own status code we'll still want to
    propagate the bio_iov_iter_get_pages, so restructure __blkdev_direct_IO
    to take ret into account when returning the errno.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 519599dddd36..c1dc393ad6b9 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -334,7 +334,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	bool is_read = (iov_iter_rw(iter) == READ), is_sync;
 	loff_t pos = iocb->ki_pos;
 	blk_qc_t qc = BLK_QC_T_NONE;
-	int ret;
+	int ret = 0;
 
 	if ((pos | iov_iter_alignment(iter)) &
 	    (bdev_logical_block_size(bdev) - 1))
@@ -363,7 +363,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 		ret = bio_iov_iter_get_pages(bio, iter);
 		if (unlikely(ret)) {
-			bio->bi_error = ret;
+			bio->bi_error = -EIO;
 			bio_endio(bio);
 			break;
 		}
@@ -412,7 +412,8 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	}
 	__set_current_state(TASK_RUNNING);
 
-	ret = dio->bio.bi_error;
+	if (!ret)
+		ret = dio->bio.bi_error;
 	if (likely(!ret))
 		ret = dio->size;
 

commit 0fcc3ab23d7395f58e8ab0834e7913e2e4314a83
Merge: deac8429d62c e84b83b9ee21
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 12 15:43:10 2017 -0700

    Merge branch 'libnvdimm-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm fixes from Dan Williams:
     "Incremental fixes and a small feature addition on top of the main
      libnvdimm 4.12 pull request:
    
       - Geert noticed that tinyconfig was bloated by BLOCK selecting DAX.
         The size regression is fixed by moving all dax helpers into the
         dax-core and only specifying "select DAX" for FS_DAX and
         dax-capable drivers. He also asked for clarification of the
         NR_DEV_DAX config option which, on closer look, does not need to be
         a config option at all. Mike also throws in a DEV_DAX_PMEM fixup
         for good measure.
    
       - Ben's attention to detail on -stable patch submissions caught a
         case where the recent fixes to arch_copy_from_iter_pmem() missed a
         condition where we strand dirty data in the cache. This is tagged
         for -stable and will also be included in the rework of the pmem api
         to a proposed {memcpy,copy_user}_flushcache() interface for 4.13.
    
       - Vishal adds a feature that missed the initial pull due to pending
         review feedback. It allows the kernel to clear media errors when
         initializing a BTT (atomic sector update driver) instance on a pmem
         namespace.
    
       - Ross noticed that the dax_device + dax_operations conversion broke
         __dax_zero_page_range(). The nvdimm unit tests fail to check this
         path, but xfstests immediately trips over it. No excuse for missing
         this before submitting the 4.12 pull request.
    
      These all pass the nvdimm unit tests and an xfstests spot check. The
      set has received a build success notification from the kbuild robot"
    
    * 'libnvdimm-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm:
      filesystem-dax: fix broken __dax_zero_page_range() conversion
      libnvdimm, btt: ensure that initializing metadata clears poison
      libnvdimm: add an atomic vs process context flag to rw_bytes
      x86, pmem: Fix cache flushing for iovec write < 8 bytes
      device-dax: kill NR_DEV_DAX
      block, dax: move "select DAX" from BLOCK to FS_DAX
      device-dax: Tell kbuild DEV_DAX_PMEM depends on DEV_DAX

commit ef51042472f55b325fd7f2b26a2e29fd89757234
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon May 8 10:55:27 2017 -0700

    block, dax: move "select DAX" from BLOCK to FS_DAX
    
    For configurations that do not enable DAX filesystems or drivers, do not
    require the DAX core to be built.
    
    Given that the 'direct_access' method has been removed from
    'block_device_operations', we can also go ahead and remove the
    block-related dax helper functions from fs/block_dev.c to
    drivers/dax/super.c. This keeps dax details out of the block layer and
    lets the DAX core be built as a module in the FS_DAX=n case.
    
    Filesystems need to include dax.h to call bdev_dax_supported().
    
    Cc: linux-xfs@vger.kernel.org
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: "Darrick J. Wong" <darrick.wong@oracle.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Jan Kara <jack@suse.com>
    Reported-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 666367e13711..3096ecd48304 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -718,72 +718,6 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 }
 EXPORT_SYMBOL_GPL(bdev_write_page);
 
-int bdev_dax_pgoff(struct block_device *bdev, sector_t sector, size_t size,
-		pgoff_t *pgoff)
-{
-	phys_addr_t phys_off = (get_start_sect(bdev) + sector) * 512;
-
-	if (pgoff)
-		*pgoff = PHYS_PFN(phys_off);
-	if (phys_off % PAGE_SIZE || size % PAGE_SIZE)
-		return -EINVAL;
-	return 0;
-}
-EXPORT_SYMBOL(bdev_dax_pgoff);
-
-/**
- * bdev_dax_supported() - Check if the device supports dax for filesystem
- * @sb: The superblock of the device
- * @blocksize: The block size of the device
- *
- * This is a library function for filesystems to check if the block device
- * can be mounted with dax option.
- *
- * Return: negative errno if unsupported, 0 if supported.
- */
-int bdev_dax_supported(struct super_block *sb, int blocksize)
-{
-	struct block_device *bdev = sb->s_bdev;
-	struct dax_device *dax_dev;
-	pgoff_t pgoff;
-	int err, id;
-	void *kaddr;
-	pfn_t pfn;
-	long len;
-
-	if (blocksize != PAGE_SIZE) {
-		vfs_msg(sb, KERN_ERR, "error: unsupported blocksize for dax");
-		return -EINVAL;
-	}
-
-	err = bdev_dax_pgoff(bdev, 0, PAGE_SIZE, &pgoff);
-	if (err) {
-		vfs_msg(sb, KERN_ERR, "error: unaligned partition for dax");
-		return err;
-	}
-
-	dax_dev = dax_get_by_host(bdev->bd_disk->disk_name);
-	if (!dax_dev) {
-		vfs_msg(sb, KERN_ERR, "error: device does not support dax");
-		return -EOPNOTSUPP;
-	}
-
-	id = dax_read_lock();
-	len = dax_direct_access(dax_dev, pgoff, 1, &kaddr, &pfn);
-	dax_read_unlock(id);
-
-	put_dax(dax_dev);
-
-	if (len < 1) {
-		vfs_msg(sb, KERN_ERR,
-				"error: dax access failed (%ld)", len);
-		return len < 0 ? len : -EIO;
-	}
-
-	return 0;
-}
-EXPORT_SYMBOL_GPL(bdev_dax_supported);
-
 /*
  * pseudo-fs
  */

commit 53ef7d0e208fa38c3f63d287e0c3ab174f1e1235
Merge: c6a677c6f37b 736163671bcb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 5 18:49:20 2017 -0700

    Merge tag 'libnvdimm-for-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "The bulk of this has been in multiple -next releases. There were a few
      late breaking fixes and small features that got added in the last
      couple days, but the whole set has received a build success
      notification from the kbuild robot.
    
      Change summary:
    
       - Region media error reporting: A libnvdimm region device is the
         parent to one or more namespaces. To date, media errors have been
         reported via the "badblocks" attribute attached to pmem block
         devices for namespaces in "raw" or "memory" mode. Given that
         namespaces can be in "device-dax" or "btt-sector" mode this new
         interface reports media errors generically, i.e. independent of
         namespace modes or state.
    
         This subsequently allows userspace tooling to craft "ACPI 6.1
         Section 9.20.7.6 Function Index 4 - Clear Uncorrectable Error"
         requests and submit them via the ioctl path for NVDIMM root bus
         devices.
    
       - Introduce 'struct dax_device' and 'struct dax_operations': Prompted
         by a request from Linus and feedback from Christoph this allows for
         dax capable drivers to publish their own custom dax operations.
         This fixes the broken assumption that all dax operations are
         related to a persistent memory device, and makes it easier for
         other architectures and platforms to add customized persistent
         memory support.
    
       - 'libnvdimm' core updates: A new "deep_flush" sysfs attribute is
         available for storage appliance applications to manually trigger
         memory controllers to drain write-pending buffers that would
         otherwise be flushed automatically by the platform ADR
         (asynchronous-DRAM-refresh) mechanism at a power loss event.
         Support for "locked" DIMMs is included to prevent namespaces from
         surfacing when the namespace label data area is locked. Finally,
         fixes for various reported deadlocks and crashes, also tagged for
         -stable.
    
       - ACPI / nfit driver updates: General updates of the nfit driver to
         add DSM command overrides, ACPI 6.1 health state flags support, DSM
         payload debug available by default, and various fixes.
    
      Acknowledgements that came after the branch was pushed:
    
       - commmit 565851c972b5 "device-dax: fix sysfs attribute deadlock":
         Tested-by: Yi Zhang <yizhan@redhat.com>
    
       - commit 23f498448362 "libnvdimm: rework region badblocks clearing"
         Tested-by: Toshi Kani <toshi.kani@hpe.com>"
    
    * tag 'libnvdimm-for-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (52 commits)
      libnvdimm, pfn: fix 'npfns' vs section alignment
      libnvdimm: handle locked label storage areas
      libnvdimm: convert NDD_ flags to use bitops, introduce NDD_LOCKED
      brd: fix uninitialized use of brd->dax_dev
      block, dax: use correct format string in bdev_dax_supported
      device-dax: fix sysfs attribute deadlock
      libnvdimm: restore "libnvdimm: band aid btt vs clear poison locking"
      libnvdimm: fix nvdimm_bus_lock() vs device_lock() ordering
      libnvdimm: rework region badblocks clearing
      acpi, nfit: kill ACPI_NFIT_DEBUG
      libnvdimm: fix clear length of nvdimm_forget_poison()
      libnvdimm, pmem: fix a NULL pointer BUG in nd_pmem_notify
      libnvdimm, region: sysfs trigger for nvdimm_flush()
      libnvdimm: fix phys_addr for nvdimm_clear_poison
      x86, dax, pmem: remove indirection around memcpy_from_pmem()
      block: remove block_device_operations ->direct_access()
      block, dax: convert bdev_dax_supported() to dax_direct_access()
      filesystem-dax: convert to dax_direct_access()
      Revert "block: use DAX for partition table reads"
      ext2, ext4, xfs: retrieve dax_device for iomap operations
      ...

commit a5f6a6a9c72eac38a7fadd1a038532bc8516337c
Author: Andrey Ryabinin <aryabinin@virtuozzo.com>
Date:   Wed May 3 14:56:02 2017 -0700

    fs/block_dev: always invalidate cleancache in invalidate_bdev()
    
    invalidate_bdev() calls cleancache_invalidate_inode() iff ->nrpages != 0
    which doen't make any sense.
    
    Make sure that invalidate_bdev() always calls cleancache_invalidate_inode()
    regardless of mapping->nrpages value.
    
    Fixes: c515e1fd361c ("mm/fs: add hooks to support cleancache")
    Link: http://lkml.kernel.org/r/20170424164135.22350-3-aryabinin@virtuozzo.com
    Signed-off-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Alexey Kuznetsov <kuznet@virtuozzo.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Nikolay Borisov <n.borisov.lkml@gmail.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9ccabe3bb7de..0d435c794d76 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -103,12 +103,11 @@ void invalidate_bdev(struct block_device *bdev)
 {
 	struct address_space *mapping = bdev->bd_inode->i_mapping;
 
-	if (mapping->nrpages == 0)
-		return;
-
-	invalidate_bh_lrus();
-	lru_add_drain_all();	/* make sure all lru add caches are flushed */
-	invalidate_mapping_pages(mapping, 0, -1);
+	if (mapping->nrpages) {
+		invalidate_bh_lrus();
+		lru_add_drain_all();	/* make sure all lru add caches are flushed */
+		invalidate_mapping_pages(mapping, 0, -1);
+	}
 	/* 99% of the time, we don't need to flush the cleancache on the bdev.
 	 * But, for the strange corners, lets be cautious
 	 */

commit 67fd38973513c341c84654ae2f819089b840a39b
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Apr 27 16:30:41 2017 +0200

    block, dax: use correct format string in bdev_dax_supported
    
    The new message has an incorrect format string, causing a warning in some
    configurations:
    
    fs/block_dev.c: In function 'bdev_dax_supported':
    fs/block_dev.c:779:5: error: format '%d' expects argument of type 'int', but argument 2 has type 'long int' [-Werror=format=]
         "error: dax access failed (%d)", len);
    
    This changes it to use the correct %ld instead of %d.
    
    Fixes: 2093f2e9dfec ("block, dax: convert bdev_dax_supported() to dax_direct_access()")
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 10e21465d5a9..666367e13711 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -776,7 +776,7 @@ int bdev_dax_supported(struct super_block *sb, int blocksize)
 
 	if (len < 1) {
 		vfs_msg(sb, KERN_ERR,
-				"error: dax access failed (%d)", len);
+				"error: dax access failed (%ld)", len);
 		return len < 0 ? len : -EIO;
 	}
 

commit d4b29fd78ea6fc2be219be3af1a992149b4ff0f6
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jan 27 17:22:03 2017 -0800

    block: remove block_device_operations ->direct_access()
    
    Now that all the producers and consumers of dax interfaces have been
    converted to using dax_operations on a dax_device, remove the block
    device direct_access enabling.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ecbdc8f9f718..10e21465d5a9 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -718,51 +718,6 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 }
 EXPORT_SYMBOL_GPL(bdev_write_page);
 
-/**
- * bdev_direct_access() - Get the address for directly-accessibly memory
- * @bdev: The device containing the memory
- * @dax: control and output parameters for ->direct_access
- *
- * If a block device is made up of directly addressable memory, this function
- * will tell the caller the PFN and the address of the memory.  The address
- * may be directly dereferenced within the kernel without the need to call
- * ioremap(), kmap() or similar.  The PFN is suitable for inserting into
- * page tables.
- *
- * Return: negative errno if an error occurs, otherwise the number of bytes
- * accessible at this address.
- */
-long bdev_direct_access(struct block_device *bdev, struct blk_dax_ctl *dax)
-{
-	sector_t sector = dax->sector;
-	long avail, size = dax->size;
-	const struct block_device_operations *ops = bdev->bd_disk->fops;
-
-	/*
-	 * The device driver is allowed to sleep, in order to make the
-	 * memory directly accessible.
-	 */
-	might_sleep();
-
-	if (size < 0)
-		return size;
-	if (!blk_queue_dax(bdev_get_queue(bdev)) || !ops->direct_access)
-		return -EOPNOTSUPP;
-	if ((sector + DIV_ROUND_UP(size, 512)) >
-					part_nr_sects_read(bdev->bd_part))
-		return -ERANGE;
-	sector += get_start_sect(bdev);
-	if (sector % (PAGE_SIZE / 512))
-		return -EINVAL;
-	avail = ops->direct_access(bdev, sector, &dax->addr, &dax->pfn, size);
-	if (!avail)
-		return -ERANGE;
-	if (avail > 0 && avail & ~PAGE_MASK)
-		return -ENXIO;
-	return min(avail, size);
-}
-EXPORT_SYMBOL_GPL(bdev_direct_access);
-
 int bdev_dax_pgoff(struct block_device *bdev, sector_t sector, size_t size,
 		pgoff_t *pgoff)
 {

commit 2093f2e9dfec98e561c83e807910267bcbd8bb7b
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Apr 1 16:02:38 2017 -0700

    block, dax: convert bdev_dax_supported() to dax_direct_access()
    
    Kill of the final user of bdev_direct_access() and struct blk_dax_ctl.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2f7885712575..ecbdc8f9f718 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -788,35 +788,43 @@ EXPORT_SYMBOL(bdev_dax_pgoff);
  */
 int bdev_dax_supported(struct super_block *sb, int blocksize)
 {
-	struct blk_dax_ctl dax = {
-		.sector = 0,
-		.size = PAGE_SIZE,
-	};
-	int err;
+	struct block_device *bdev = sb->s_bdev;
+	struct dax_device *dax_dev;
+	pgoff_t pgoff;
+	int err, id;
+	void *kaddr;
+	pfn_t pfn;
+	long len;
 
 	if (blocksize != PAGE_SIZE) {
 		vfs_msg(sb, KERN_ERR, "error: unsupported blocksize for dax");
 		return -EINVAL;
 	}
 
-	err = bdev_direct_access(sb->s_bdev, &dax);
-	if (err < 0) {
-		switch (err) {
-		case -EOPNOTSUPP:
-			vfs_msg(sb, KERN_ERR,
-				"error: device does not support dax");
-			break;
-		case -EINVAL:
-			vfs_msg(sb, KERN_ERR,
-				"error: unaligned partition for dax");
-			break;
-		default:
-			vfs_msg(sb, KERN_ERR,
-				"error: dax access failed (%d)", err);
-		}
+	err = bdev_dax_pgoff(bdev, 0, PAGE_SIZE, &pgoff);
+	if (err) {
+		vfs_msg(sb, KERN_ERR, "error: unaligned partition for dax");
 		return err;
 	}
 
+	dax_dev = dax_get_by_host(bdev->bd_disk->disk_name);
+	if (!dax_dev) {
+		vfs_msg(sb, KERN_ERR, "error: device does not support dax");
+		return -EOPNOTSUPP;
+	}
+
+	id = dax_read_lock();
+	len = dax_direct_access(dax_dev, pgoff, 1, &kaddr, &pfn);
+	dax_read_unlock(id);
+
+	put_dax(dax_dev);
+
+	if (len < 1) {
+		vfs_msg(sb, KERN_ERR,
+				"error: dax access failed (%d)", len);
+		return len < 0 ? len : -EIO;
+	}
+
 	return 0;
 }
 EXPORT_SYMBOL_GPL(bdev_dax_supported);

commit 19b7ccf8651df09d274671b53039c672a52ad84d
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Tue Apr 18 18:43:20 2017 +0200

    block: get rid of blk_integrity_revalidate()
    
    Commit 25520d55cdb6 ("block: Inline blk_integrity in struct gendisk")
    introduced blk_integrity_revalidate(), which seems to assume ownership
    of the stable pages flag and unilaterally clears it if no blk_integrity
    profile is registered:
    
        if (bi->profile)
                disk->queue->backing_dev_info->capabilities |=
                        BDI_CAP_STABLE_WRITES;
        else
                disk->queue->backing_dev_info->capabilities &=
                        ~BDI_CAP_STABLE_WRITES;
    
    It's called from revalidate_disk() and rescan_partitions(), making it
    impossible to enable stable pages for drivers that support partitions
    and don't use blk_integrity: while the call in revalidate_disk() can be
    trivially worked around (see zram, which doesn't support partitions and
    hence gets away with zram_revalidate_disk()), rescan_partitions() can
    be triggered from userspace at any time.  This breaks rbd, where the
    ceph messenger is responsible for generating/verifying CRCs.
    
    Since blk_integrity_{un,}register() "must" be used for (un)registering
    the integrity profile with the block layer, move BDI_CAP_STABLE_WRITES
    setting there.  This way drivers that call blk_integrity_register() and
    use integrity infrastructure won't interfere with drivers that don't
    but still want stable pages.
    
    Fixes: 25520d55cdb6 ("block: Inline blk_integrity in struct gendisk")
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: stable@vger.kernel.org # 4.4+, needs backporting
    Tested-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e405d8e58e31..9ccabe3bb7de 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1453,7 +1453,6 @@ int revalidate_disk(struct gendisk *disk)
 
 	if (disk->fops->revalidate_disk)
 		ret = disk->fops->revalidate_disk(disk);
-	blk_integrity_revalidate(disk);
 	bdev = bdget_disk(disk, 0);
 	if (!bdev)
 		return ret;

commit b0686260fecaa924d8eff2ace94bee70506bc308
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jan 26 20:37:35 2017 -0800

    dax: introduce dax_direct_access()
    
    Replace bdev_direct_access() with dax_direct_access() that uses
    dax_device and dax_operations instead of a block_device and
    block_device_operations for dax. Once all consumers of the old api have
    been converted bdev_direct_access() will be deleted.
    
    Given that block device partitioning decisions can cause dax page
    alignment constraints to be violated this also introduces the
    bdev_dax_pgoff() helper. It handles calculating a logical pgoff relative
    to the dax_device and also checks for page alignment.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7f40ea2f0875..2f7885712575 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -18,6 +18,7 @@
 #include <linux/module.h>
 #include <linux/blkpg.h>
 #include <linux/magic.h>
+#include <linux/dax.h>
 #include <linux/buffer_head.h>
 #include <linux/swap.h>
 #include <linux/pagevec.h>
@@ -762,6 +763,19 @@ long bdev_direct_access(struct block_device *bdev, struct blk_dax_ctl *dax)
 }
 EXPORT_SYMBOL_GPL(bdev_direct_access);
 
+int bdev_dax_pgoff(struct block_device *bdev, sector_t sector, size_t size,
+		pgoff_t *pgoff)
+{
+	phys_addr_t phys_off = (get_start_sect(bdev) + sector) * 512;
+
+	if (pgoff)
+		*pgoff = PHYS_PFN(phys_off);
+	if (phys_off % PAGE_SIZE || size % PAGE_SIZE)
+		return -EINVAL;
+	return 0;
+}
+EXPORT_SYMBOL(bdev_dax_pgoff);
+
 /**
  * bdev_dax_supported() - Check if the device supports dax for filesystem
  * @sb: The superblock of the device

commit d8f07aee3f2fd959878bf614d4e984900018eb9e
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jan 26 23:30:05 2017 -0800

    block: kill bdev_dax_capable()
    
    This is leftover dead code that has since been replaced by
    bdev_dax_supported().
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2eca00ec4370..7f40ea2f0875 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -807,30 +807,6 @@ int bdev_dax_supported(struct super_block *sb, int blocksize)
 }
 EXPORT_SYMBOL_GPL(bdev_dax_supported);
 
-/**
- * bdev_dax_capable() - Return if the raw device is capable for dax
- * @bdev: The device for raw block device access
- */
-bool bdev_dax_capable(struct block_device *bdev)
-{
-	struct blk_dax_ctl dax = {
-		.size = PAGE_SIZE,
-	};
-
-	if (!IS_ENABLED(CONFIG_FS_DAX))
-		return false;
-
-	dax.sector = 0;
-	if (bdev_direct_access(bdev, &dax) < 0)
-		return false;
-
-	dax.sector = bdev->bd_part->nr_sects - (PAGE_SIZE / 512);
-	if (bdev_direct_access(bdev, &dax) < 0)
-		return false;
-
-	return true;
-}
-
 /*
  * pseudo-fs
  */

commit 34045129b128fb3c0237b6af7c5a84b1ca9c0bf5
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 5 19:21:11 2017 +0200

    block_dev: use blkdev_issue_zerout for hole punches
    
    This gets us support for non-discard efficient write of zeroes (e.g. NVMe)
    and prepares for removing the discard_zeroes_data flag.
    
    Also remove a pointless discard support check, which is done in
    blkdev_issue_discard already.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2f704c3a816f..e405d8e58e31 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -2069,7 +2069,6 @@ static long blkdev_fallocate(struct file *file, int mode, loff_t start,
 			     loff_t len)
 {
 	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
-	struct request_queue *q = bdev_get_queue(bdev);
 	struct address_space *mapping;
 	loff_t end = start + len - 1;
 	loff_t isize;
@@ -2108,15 +2107,10 @@ static long blkdev_fallocate(struct file *file, int mode, loff_t start,
 					    GFP_KERNEL, BLKDEV_ZERO_NOUNMAP);
 		break;
 	case FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE:
-		/* Only punch if the device can do zeroing discard. */
-		if (!blk_queue_discard(q) || !q->limits.discard_zeroes_data)
-			return -EOPNOTSUPP;
-		error = blkdev_issue_discard(bdev, start >> 9, len >> 9,
-					     GFP_KERNEL, 0);
+		error = blkdev_issue_zeroout(bdev, start >> 9, len >> 9,
+					     GFP_KERNEL, BLKDEV_ZERO_NOFALLBACK);
 		break;
 	case FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE | FALLOC_FL_NO_HIDE_STALE:
-		if (!blk_queue_discard(q))
-			return -EOPNOTSUPP;
 		error = blkdev_issue_discard(bdev, start >> 9, len >> 9,
 					     GFP_KERNEL, 0);
 		break;

commit ee472d835c264a4cb77f8cf878603e1e40f3559e
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 5 19:21:08 2017 +0200

    block: add a flags argument to (__)blkdev_issue_zeroout
    
    Turn the existing discard flag into a new BLKDEV_ZERO_UNMAP flag with
    similar semantics, but without referring to dicard.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f2d59f143ef4..2f704c3a816f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -2105,7 +2105,7 @@ static long blkdev_fallocate(struct file *file, int mode, loff_t start,
 	case FALLOC_FL_ZERO_RANGE:
 	case FALLOC_FL_ZERO_RANGE | FALLOC_FL_KEEP_SIZE:
 		error = blkdev_issue_zeroout(bdev, start >> 9, len >> 9,
-					    GFP_KERNEL, false);
+					    GFP_KERNEL, BLKDEV_ZERO_NOUNMAP);
 		break;
 	case FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE:
 		/* Only punch if the device can do zeroing discard. */

commit f759741d9d913eb57784a94b9bca78b376fc26a9
Author: Jan Kara <jack@suse.cz>
Date:   Thu Mar 23 01:37:00 2017 +0100

    block: Fix oops in locked_inode_to_wb_and_lock_list()
    
    When block device is closed, we call inode_detach_wb() in __blkdev_put()
    which sets inode->i_wb to NULL. That is contrary to expectations that
    inode->i_wb stays valid once set during the whole inode's lifetime and
    leads to oops in wb_get() in locked_inode_to_wb_and_lock_list() because
    inode_to_wb() returned NULL.
    
    The reason why we called inode_detach_wb() is not valid anymore though.
    BDI is guaranteed to stay along until we call bdi_put() from
    bdev_evict_inode() so we can postpone calling inode_detach_wb() to that
    moment.
    
    Also add a warning to catch if someone uses inode_detach_wb() in a
    dangerous way.
    
    Reported-by: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 53e2389ae4d4..f2d59f143ef4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -885,6 +885,8 @@ static void bdev_evict_inode(struct inode *inode)
 	spin_lock(&bdev_lock);
 	list_del_init(&bdev->bd_list);
 	spin_unlock(&bdev_lock);
+	/* Detach inode from wb early as bdi_put() may free bdi->wb */
+	inode_detach_wb(inode);
 	if (bdev->bd_bdi != &noop_backing_dev_info) {
 		bdi_put(bdev->bd_bdi);
 		bdev->bd_bdi = &noop_backing_dev_info;
@@ -1875,12 +1877,6 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		kill_bdev(bdev);
 
 		bdev_write_inode(bdev);
-		/*
-		 * Detaching bdev inode from its wb in __destroy_inode()
-		 * is too late: the queue which embeds its bdi (along with
-		 * root wb) can be gone as soon as we put_disk() below.
-		 */
-		inode_detach_wb(bdev->bd_inode);
 	}
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)

commit 03e262798884b0a5f948b17433afd80606cb3497
Author: Jan Kara <jack@suse.cz>
Date:   Thu Mar 23 01:36:53 2017 +0100

    block: Fix bdi assignment to bdev inode when racing with disk delete
    
    When disk->fops->open() in __blkdev_get() returns -ERESTARTSYS, we
    restart the process of opening the block device. However we forget to
    switch bdev->bd_bdi back to noop_backing_dev_info and as a result bdev
    inode will be pointing to a stale bdi. Fix the problem by setting
    bdev->bd_bdi later when __blkdev_get() is already guaranteed to succeed.
    
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2eca00ec4370..53e2389ae4d4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1556,8 +1556,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
-		if (bdev->bd_bdi == &noop_backing_dev_info)
-			bdev->bd_bdi = bdi_get(disk->queue->backing_dev_info);
 
 		if (!partno) {
 			ret = -ENXIO;
@@ -1622,6 +1620,9 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			}
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
 		}
+
+		if (bdev->bd_bdi == &noop_backing_dev_info)
+			bdev->bd_bdi = bdi_get(disk->queue->backing_dev_info);
 	} else {
 		if (bdev->bd_contains == bdev) {
 			ret = 0;
@@ -1653,8 +1654,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	bdev->bd_disk = NULL;
 	bdev->bd_part = NULL;
 	bdev->bd_queue = NULL;
-	bdi_put(bdev->bd_bdi);
-	bdev->bd_bdi = &noop_backing_dev_info;
 	if (bdev != bdev->bd_contains)
 		__blkdev_put(bdev->bd_contains, mode, 1);
 	bdev->bd_contains = NULL;

commit a5a79d00017c9eee68a9bcb40d5dfd6f45f17461
Author: Jan Kara <jack@suse.cz>
Date:   Thu Mar 2 16:50:13 2017 +0100

    block: Initialize bd_bdi on inode initialization
    
    So far we initialized bd_bdi only in bdget(). That is fine for normal
    bdev inodes however for the special case of the root inode of
    blockdev_superblock that function is never called and thus bd_bdi is
    left uninitialized. As a result bdev_evict_inode() may oops doing
    bdi_put(root->bd_bdi) on that inode as can be seen when doing:
    
    mount -t bdev none /mnt
    
    Fix the problem by initializing bd_bdi when first allocating the inode
    and then reinitializing bd_bdi in bdev_evict_inode().
    
    Thanks to syzkaller team for finding the problem.
    
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Fixes: b1d2dc5659b4 ("block: Make blk_get_backing_dev_info() safe without open bdev")
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 77c30f15a02c..2eca00ec4370 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -870,6 +870,7 @@ static void init_once(void *foo)
 #ifdef CONFIG_SYSFS
 	INIT_LIST_HEAD(&bdev->bd_holder_disks);
 #endif
+	bdev->bd_bdi = &noop_backing_dev_info;
 	inode_init_once(&ei->vfs_inode);
 	/* Initialize mutex for freeze. */
 	mutex_init(&bdev->bd_fsfreeze_mutex);
@@ -884,8 +885,10 @@ static void bdev_evict_inode(struct inode *inode)
 	spin_lock(&bdev_lock);
 	list_del_init(&bdev->bd_list);
 	spin_unlock(&bdev_lock);
-	if (bdev->bd_bdi != &noop_backing_dev_info)
+	if (bdev->bd_bdi != &noop_backing_dev_info) {
 		bdi_put(bdev->bd_bdi);
+		bdev->bd_bdi = &noop_backing_dev_info;
+	}
 }
 
 static const struct super_operations bdev_sops = {
@@ -988,7 +991,6 @@ struct block_device *bdget(dev_t dev)
 		bdev->bd_contains = NULL;
 		bdev->bd_super = NULL;
 		bdev->bd_inode = inode;
-		bdev->bd_bdi = &noop_backing_dev_info;
 		bdev->bd_block_size = i_blocksize(inode);
 		bdev->bd_part_count = 0;
 		bdev->bd_invalidated = 0;

commit 93407472a21b82f39c955ea7787e5bc7da100642
Author: Fabian Frederick <fabf@skynet.be>
Date:   Mon Feb 27 14:28:32 2017 -0800

    fs: add i_blocksize()
    
    Replace all 1 << inode->i_blkbits and (1 << inode->i_blkbits) in fs
    branch.
    
    This patch also fixes multiple checkpatch warnings: WARNING: Prefer
    'unsigned int' to bare use of 'unsigned'
    
    Thanks to Andrew Morton for suggesting more appropriate function instead
    of macro.
    
    [geliangtang@gmail.com: truncate: use i_blocksize()]
      Link: http://lkml.kernel.org/r/9c8b2cd83c8f5653805d43debde9fa8817e02fc4.1484895804.git.geliangtang@gmail.com
    Link: http://lkml.kernel.org/r/1481319905-10126-1-git-send-email-fabf@skynet.be
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Signed-off-by: Geliang Tang <geliangtang@gmail.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1c62845a72c7..77c30f15a02c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -989,7 +989,7 @@ struct block_device *bdget(dev_t dev)
 		bdev->bd_super = NULL;
 		bdev->bd_inode = inode;
 		bdev->bd_bdi = &noop_backing_dev_info;
-		bdev->bd_block_size = (1 << inode->i_blkbits);
+		bdev->bd_block_size = i_blocksize(inode);
 		bdev->bd_part_count = 0;
 		bdev->bd_invalidated = 0;
 		inode->i_mode = S_IFBLK;

commit cccd9fb9ec960e343b2f354c4613e49f5a1d8371
Author: Jan Kara <jack@suse.cz>
Date:   Tue Feb 21 18:09:48 2017 +0100

    block: Revalidate i_bdev reference in bd_aquire()
    
    When a device gets removed, block device inode unhashed so that it is not
    used anymore (bdget() will not find it anymore). Later when a new device
    gets created with the same device number, we create new block device
    inode. However there may be file system device inodes whose i_bdev still
    points to the original block device inode and thus we get two active
    block device inodes for the same device. They will share the same
    gendisk so the only visible differences will be that page caches will
    not be coherent and BDIs will be different (the old block device inode
    still points to unregistered BDI).
    
    Fix the problem by checking in bd_acquire() whether i_bdev still points
    to active block device inode and re-lookup the block device if not. That
    way any open of a block device happening after the old device has been
    removed will get correct block device inode.
    
    Tested-by: Lekshmi Pillai <lekshmicpillai@in.ibm.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 73031ec54a7b..1c62845a72c7 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1043,13 +1043,22 @@ static struct block_device *bd_acquire(struct inode *inode)
 
 	spin_lock(&bdev_lock);
 	bdev = inode->i_bdev;
-	if (bdev) {
+	if (bdev && !inode_unhashed(bdev->bd_inode)) {
 		bdgrab(bdev);
 		spin_unlock(&bdev_lock);
 		return bdev;
 	}
 	spin_unlock(&bdev_lock);
 
+	/*
+	 * i_bdev references block device inode that was already shut down
+	 * (corresponding device got removed).  Remove the reference and look
+	 * up block device inode again just in case new device got
+	 * reestablished under the same device number.
+	 */
+	if (bdev)
+		bd_forget(inode);
+
 	bdev = bdget(inode->i_rdev);
 	if (bdev) {
 		spin_lock(&bdev_lock);

commit 818551e2b2c662a1b26de6b4f7d6b8411a838d18
Merge: 6010720da8aa 7520872c0cf4
Author: Jens Axboe <axboe@fb.com>
Date:   Fri Feb 17 14:08:19 2017 -0700

    Merge branch 'for-4.11/next' into for-4.11/linus-merge
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

commit b1d2dc5659b41741f5a29b2ade76ffb4e5bb13d8
Author: Jan Kara <jack@suse.cz>
Date:   Thu Feb 2 15:56:52 2017 +0100

    block: Make blk_get_backing_dev_info() safe without open bdev
    
    Currenly blk_get_backing_dev_info() is not safe to be called when the
    block device is not open as bdev->bd_disk is NULL in that case. However
    inode_to_bdi() uses this function and may be call called from flusher
    worker or other writeback related functions without bdev being open
    which leads to crashes such as:
    
    [113031.075540] Unable to handle kernel paging request for data at address 0x00000000
    [113031.075614] Faulting instruction address: 0xc0000000003692e0
    0:mon> t
    [c0000000fb65f900] c00000000036cb6c writeback_sb_inodes+0x30c/0x590
    [c0000000fb65fa10] c00000000036ced4 __writeback_inodes_wb+0xe4/0x150
    [c0000000fb65fa70] c00000000036d33c wb_writeback+0x30c/0x450
    [c0000000fb65fb40] c00000000036e198 wb_workfn+0x268/0x580
    [c0000000fb65fc50] c0000000000f3470 process_one_work+0x1e0/0x590
    [c0000000fb65fce0] c0000000000f38c8 worker_thread+0xa8/0x660
    [c0000000fb65fd80] c0000000000fc4b0 kthread+0x110/0x130
    [c0000000fb65fe30] c0000000000098f0 ret_from_kernel_thread+0x5c/0x6c
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ed6a34be7a1e..601b71b76d7f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -884,6 +884,8 @@ static void bdev_evict_inode(struct inode *inode)
 	spin_lock(&bdev_lock);
 	list_del_init(&bdev->bd_list);
 	spin_unlock(&bdev_lock);
+	if (bdev->bd_bdi != &noop_backing_dev_info)
+		bdi_put(bdev->bd_bdi);
 }
 
 static const struct super_operations bdev_sops = {
@@ -986,6 +988,7 @@ struct block_device *bdget(dev_t dev)
 		bdev->bd_contains = NULL;
 		bdev->bd_super = NULL;
 		bdev->bd_inode = inode;
+		bdev->bd_bdi = &noop_backing_dev_info;
 		bdev->bd_block_size = (1 << inode->i_blkbits);
 		bdev->bd_part_count = 0;
 		bdev->bd_invalidated = 0;
@@ -1542,6 +1545,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
+		if (bdev->bd_bdi == &noop_backing_dev_info)
+			bdev->bd_bdi = bdi_get(disk->queue->backing_dev_info);
 
 		if (!partno) {
 			ret = -ENXIO;
@@ -1637,6 +1642,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	bdev->bd_disk = NULL;
 	bdev->bd_part = NULL;
 	bdev->bd_queue = NULL;
+	bdi_put(bdev->bd_bdi);
+	bdev->bd_bdi = &noop_backing_dev_info;
 	if (bdev != bdev->bd_contains)
 		__blkdev_put(bdev->bd_contains, mode, 1);
 	bdev->bd_contains = NULL;

commit f44f1ab5a2dcd4e16eab850fd08e40ff2d0c28d4
Author: Jan Kara <jack@suse.cz>
Date:   Thu Feb 2 15:56:49 2017 +0100

    block: Unhash block device inodes on gendisk destruction
    
    Currently, block device inodes stay around after corresponding gendisk
    hash died until memory reclaim finds them and frees them. Since we will
    make block device inode pin the bdi, we want to free the block device
    inode as soon as the device goes away so that bdi does not stay around
    unnecessarily. Furthermore we need to avoid issues when new device with
    the same major,minor pair gets created since reusing the bdi structure
    would be rather difficult in this case.
    
    Unhashing block device inode on gendisk destruction nicely deals with
    these problems. Once last block device inode reference is dropped (which
    may be directly in del_gendisk()), the inode gets evicted. Furthermore if
    the major,minor pair gets reallocated, we are guaranteed to get new
    block device inode even if old block device inode is not yet evicted and
    thus we avoid issues with possible reuse of bdi.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 5db5d1340d69..ed6a34be7a1e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -954,6 +954,21 @@ static int bdev_set(struct inode *inode, void *data)
 
 static LIST_HEAD(all_bdevs);
 
+/*
+ * If there is a bdev inode for this device, unhash it so that it gets evicted
+ * as soon as last inode reference is dropped.
+ */
+void bdev_unhash_inode(dev_t dev)
+{
+	struct inode *inode;
+
+	inode = ilookup5(blockdev_superblock, hash(dev), bdev_test, &dev);
+	if (inode) {
+		remove_inode_hash(inode);
+		iput(inode);
+	}
+}
+
 struct block_device *bdget(dev_t dev)
 {
 	struct block_device *bdev;

commit 690e5325b8c7d5db05fc569c0f7b888bb4248272
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jan 24 14:50:19 2017 +0100

    block: fix use after free in __blkdev_direct_IO
    
    We can't dereference the dio structure after submitting the last bio for
    this request, as I/O completion might have happened before the code is
    run. Introduce a local is_sync variable instead.
    
    Fixes: 542ff7bf ("block: new direct I/O implementation")
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reported-by: Matias Bjrling <m@bjorling.me>
    Tested-by: Matias Bjrling <m@bjorling.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 5db5d1340d69..3c47614a4b32 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -331,7 +331,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	struct blk_plug plug;
 	struct blkdev_dio *dio;
 	struct bio *bio;
-	bool is_read = (iov_iter_rw(iter) == READ);
+	bool is_read = (iov_iter_rw(iter) == READ), is_sync;
 	loff_t pos = iocb->ki_pos;
 	blk_qc_t qc = BLK_QC_T_NONE;
 	int ret;
@@ -344,7 +344,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	bio_get(bio); /* extra ref for the completion handler */
 
 	dio = container_of(bio, struct blkdev_dio, bio);
-	dio->is_sync = is_sync_kiocb(iocb);
+	dio->is_sync = is_sync = is_sync_kiocb(iocb);
 	if (dio->is_sync)
 		dio->waiter = current;
 	else
@@ -398,7 +398,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	}
 	blk_finish_plug(&plug);
 
-	if (!dio->is_sync)
+	if (!is_sync)
 		return -EIOCBQUEUED;
 
 	for (;;) {

commit 62f8c40592172a9c3bc2658e63e6e76ba00b3b45
Merge: 9f7445197a26 7158339d4c1e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 4 09:03:37 2017 -0800

    Merge branch 'for-linus' of git://git.kernel.dk/linux-block
    
    Pull block layer fixes from Jens Axboe:
     "A set of fixes for the current series, one fixing a regression with
      block size < page cache size in the alias series from Jan. Outside of
      that, two small cleanups for wbt from Bart, a nvme pull request from
      Christoph, and a few small fixes of documentation updates"
    
    * 'for-linus' of git://git.kernel.dk/linux-block:
      block: fix up io_poll documentation
      block: Avoid that sparse complains about context imbalance in __wbt_wait()
      block: Make wbt_wait() definition consistent with declaration
      clean_bdev_aliases: Prevent cleaning blocks that are not in block range
      genhd: remove dead and duplicated scsi code
      block: add back plugging in __blkdev_direct_IO
      nvmet/fcloop: remove some logically dead code performing redundant ret checks
      nvmet: fix KATO offset in Set Features
      nvme/fc: simplify error handling of nvme_fc_create_hw_io_queues
      nvme/fc: correct some printk information
      nvme/scsi: Remove START STOP emulation
      nvme/pci: Delete misleading queue-wrap comment
      nvme/pci: Fix whitespace problem
      nvme: simplify stripe quirk
      nvme: update maintainers information

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7c4507224ed6..6254cee8f8f3 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -32,7 +32,7 @@
 #include <linux/badblocks.h>
 #include <linux/task_io_accounting_ops.h>
 #include <linux/falloc.h>
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include "internal.h"
 
 struct bdev_inode {

commit 64d656a162d7ba49d6d1863e41407b0f95e19258
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 22 19:20:45 2016 +0100

    block: add back plugging in __blkdev_direct_IO
    
    This allows sending larger than 1 MB requests to devices that support
    large I/O sizes.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reported-by: Laurence Oberman <loberman@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7c4507224ed6..206a92aab52e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -328,6 +328,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = bdev_file_inode(file);
 	struct block_device *bdev = I_BDEV(inode);
+	struct blk_plug plug;
 	struct blkdev_dio *dio;
 	struct bio *bio;
 	bool is_read = (iov_iter_rw(iter) == READ);
@@ -353,6 +354,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	dio->multi_bio = false;
 	dio->should_dirty = is_read && (iter->type == ITER_IOVEC);
 
+	blk_start_plug(&plug);
 	for (;;) {
 		bio->bi_bdev = bdev;
 		bio->bi_iter.bi_sector = pos >> 9;
@@ -394,6 +396,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 		submit_bio(bio);
 		bio = bio_alloc(GFP_KERNEL, nr_pages);
 	}
+	blk_finish_plug(&plug);
 
 	if (!dio->is_sync)
 		return -EIOCBQUEUED;

commit 7a62a52333f8b5b82753d9529c11b3404bc5c183
Author: Shaohua Li <shli@fb.com>
Date:   Tue Dec 13 19:07:55 2016 -0800

    block_dev: don't update file access position for sync direct IO
    
    For sync direct IO, generic_file_direct_write/generic_file_read_iter
    will update file access position. Don't duplicate the update in
    .direct_IO. This cause my raid array can't assemble.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jens Axboe <axboe@fb.com>
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d4f23353ee4d..7c4507224ed6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -264,7 +264,6 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 
 	if (unlikely(bio.bi_error))
 		return bio.bi_error;
-	iocb->ki_pos += ret;
 	return ret;
 }
 
@@ -411,10 +410,8 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	__set_current_state(TASK_RUNNING);
 
 	ret = dio->bio.bi_error;
-	if (likely(!ret)) {
+	if (likely(!ret))
 		ret = dio->size;
-		iocb->ki_pos += ret;
-	}
 
 	bio_put(&dio->bio);
 	return ret;

commit bcc7f5b4bee8e327689a4d994022765855c807ff
Author: NeilBrown <neilb@suse.com>
Date:   Mon Dec 12 08:21:51 2016 -0700

    block_dev: don't test bdev->bd_contains when it is not stable
    
    bdev->bd_contains is not stable before calling __blkdev_get().
    When __blkdev_get() is called on a parition with ->bd_openers == 0
    it sets
      bdev->bd_contains = bdev;
    which is not correct for a partition.
    After a call to __blkdev_get() succeeds, ->bd_openers will be > 0
    and then ->bd_contains is stable.
    
    When FMODE_EXCL is used, blkdev_get() calls
       bd_start_claiming() ->  bd_prepare_to_claim() -> bd_may_claim()
    
    This call happens before __blkdev_get() is called, so ->bd_contains
    is not stable.  So bd_may_claim() cannot safely use ->bd_contains.
    It currently tries to use it, and this can lead to a BUG_ON().
    
    This happens when a whole device is already open with a bd_holder (in
    use by dm in my particular example) and two threads race to open a
    partition of that device for the first time, one opening with O_EXCL and
    one without.
    
    The thread that doesn't use O_EXCL gets through blkdev_get() to
    __blkdev_get(), gains the ->bd_mutex, and sets bdev->bd_contains = bdev;
    
    Immediately thereafter the other thread, using FMODE_EXCL, calls
    bd_start_claiming() from blkdev_get().  This should fail because the
    whole device has a holder, but because bdev->bd_contains == bdev
    bd_may_claim() incorrectly reports success.
    This thread continues and blocks on bd_mutex.
    
    The first thread then sets bdev->bd_contains correctly and drops the mutex.
    The thread using FMODE_EXCL then continues and when it calls bd_may_claim()
    again in:
                            BUG_ON(!bd_may_claim(bdev, whole, holder));
    The BUG_ON fires.
    
    Fix this by removing the dependency on ->bd_contains in
    bd_may_claim().  As bd_may_claim() has direct access to the whole
    device, it can simply test if the target bdev is the whole device.
    
    Fixes: 6b4517a7913a ("block: implement bd_claiming and claiming block")
    Cc: stable@vger.kernel.org (v2.6.35+)
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 95acbd2ebc5d..d4f23353ee4d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1089,7 +1089,7 @@ static bool bd_may_claim(struct block_device *bdev, struct block_device *whole,
 		return true;	 /* already a holder */
 	else if (bdev->bd_holder != NULL)
 		return false; 	 /* held by someone else */
-	else if (bdev->bd_contains == bdev)
+	else if (whole == bdev)
 		return true;  	 /* is a whole device which isn't held */
 
 	else if (whole->bd_holder == bd_may_claim)

commit af309226db916e2c6e08d3eba3fa5c34225200c4
Author: Rabin Vincent <rabinv@axis.com>
Date:   Thu Dec 1 09:18:28 2016 +0100

    block: protect iterate_bdevs() against concurrent close
    
    If a block device is closed while iterate_bdevs() is handling it, the
    following NULL pointer dereference occurs because bdev->b_disk is NULL
    in bdev_get_queue(), which is called from blk_get_backing_dev_info() (in
    turn called by the mapping_cap_writeback_dirty() call in
    __filemap_fdatawrite_range()):
    
     BUG: unable to handle kernel NULL pointer dereference at 0000000000000508
     IP: [<ffffffff81314790>] blk_get_backing_dev_info+0x10/0x20
     PGD 9e62067 PUD 9ee8067 PMD 0
     Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
     Modules linked in:
     CPU: 1 PID: 2422 Comm: sync Not tainted 4.5.0-rc7+ #400
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996)
     task: ffff880009f4d700 ti: ffff880009f5c000 task.ti: ffff880009f5c000
     RIP: 0010:[<ffffffff81314790>]  [<ffffffff81314790>] blk_get_backing_dev_info+0x10/0x20
     RSP: 0018:ffff880009f5fe68  EFLAGS: 00010246
     RAX: 0000000000000000 RBX: ffff88000ec17a38 RCX: ffffffff81a4e940
     RDX: 7fffffffffffffff RSI: 0000000000000000 RDI: ffff88000ec176c0
     RBP: ffff880009f5fe68 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000001 R11: 0000000000000000 R12: ffff88000ec17860
     R13: ffffffff811b25c0 R14: ffff88000ec178e0 R15: ffff88000ec17a38
     FS:  00007faee505d700(0000) GS:ffff88000fb00000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
     CR2: 0000000000000508 CR3: 0000000009e8a000 CR4: 00000000000006e0
     Stack:
      ffff880009f5feb8 ffffffff8112e7f5 0000000000000000 7fffffffffffffff
      0000000000000000 0000000000000000 7fffffffffffffff 0000000000000001
      ffff88000ec178e0 ffff88000ec17860 ffff880009f5fec8 ffffffff8112e81f
     Call Trace:
      [<ffffffff8112e7f5>] __filemap_fdatawrite_range+0x85/0x90
      [<ffffffff8112e81f>] filemap_fdatawrite+0x1f/0x30
      [<ffffffff811b25d6>] fdatawrite_one_bdev+0x16/0x20
      [<ffffffff811bc402>] iterate_bdevs+0xf2/0x130
      [<ffffffff811b2763>] sys_sync+0x63/0x90
      [<ffffffff815d4272>] entry_SYSCALL_64_fastpath+0x12/0x76
     Code: 0f 1f 44 00 00 48 8b 87 f0 00 00 00 55 48 89 e5 <48> 8b 80 08 05 00 00 5d
     RIP  [<ffffffff81314790>] blk_get_backing_dev_info+0x10/0x20
      RSP <ffff880009f5fe68>
     CR2: 0000000000000508
     ---[ end trace 2487336ceb3de62d ]---
    
    The crash is easily reproducible by running the following command, if an
    msleep(100) is inserted before the call to func() in iterate_devs():
    
     while :; do head -c1 /dev/nullb0; done > /dev/null & while :; do sync; done
    
    Fix it by holding the bd_mutex across the func() call and only calling
    func() if the bdev is opened.
    
    Cc: stable@vger.kernel.org
    Fixes: 5c0d6b60a0ba ("vfs: Create function for iterating over block devices")
    Reported-and-tested-by: Wei Fang <fangwei1@huawei.com>
    Signed-off-by: Rabin Vincent <rabinv@axis.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7022ddc55b12..95acbd2ebc5d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -2207,6 +2207,7 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 	spin_lock(&blockdev_superblock->s_inode_list_lock);
 	list_for_each_entry(inode, &blockdev_superblock->s_inodes, i_sb_list) {
 		struct address_space *mapping = inode->i_mapping;
+		struct block_device *bdev;
 
 		spin_lock(&inode->i_lock);
 		if (inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW) ||
@@ -2227,8 +2228,12 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 		 */
 		iput(old_inode);
 		old_inode = inode;
+		bdev = I_BDEV(inode);
 
-		func(I_BDEV(inode), arg);
+		mutex_lock(&bdev->bd_mutex);
+		if (bdev->bd_openers)
+			func(bdev, arg);
+		mutex_unlock(&bdev->bd_mutex);
 
 		spin_lock(&blockdev_superblock->s_inode_list_lock);
 	}

commit 3a83f4677539bce8eaa2bca9ee9c20e172d7ab04
Author: Ming Lei <tom.leiming@gmail.com>
Date:   Tue Nov 22 08:57:21 2016 -0700

    block: bio: pass bvec table to bio_init()
    
    Some drivers often use external bvec table, so introduce
    this helper for this case. It is always safe to access the
    bio->bi_io_vec in this way for this case.
    
    After converting to this usage, it will becomes a bit easier
    to evaluate the remaining direct access to bio->bi_io_vec,
    so it can help to prepare for the following multipage bvec
    support.
    
    Signed-off-by: Ming Lei <tom.leiming@gmail.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    
    Fixed up the new O_DIRECT cases.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b0c790a19db9..7022ddc55b12 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -222,9 +222,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 			return -ENOMEM;
 	}
 
-	bio_init(&bio);
-	bio.bi_max_vecs = nr_pages;
-	bio.bi_io_vec = vecs;
+	bio_init(&bio, vecs, nr_pages);
 	bio.bi_bdev = bdev;
 	bio.bi_iter.bi_sector = pos >> 9;
 	bio.bi_private = current;

commit 9a794fb9bddeda0b8c8c13858038318f3cbd4b7e
Author: Jens Axboe <axboe@fb.com>
Date:   Tue Nov 22 08:12:39 2016 -0700

    block_dev: get rid of blksize bits calculation
    
    We store the bits in the bdev sector size locally, but we don't use
    the calculation anymore. All we do with it is shift it back up to
    the bdev sector size. So let's just use that directly and kill the
    variable and bits calculation.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e49fb797e447..b0c790a19db9 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -202,7 +202,6 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 {
 	struct file *file = iocb->ki_filp;
 	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
-	unsigned blkbits = blksize_bits(bdev_logical_block_size(bdev));
 	struct bio_vec inline_vecs[DIO_INLINE_BIO_VECS], *vecs, *bvec;
 	loff_t pos = iocb->ki_pos;
 	bool should_dirty = false;
@@ -211,7 +210,8 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	blk_qc_t qc;
 	int i;
 
-	if ((pos | iov_iter_alignment(iter)) & ((1 << blkbits) - 1))
+	if ((pos | iov_iter_alignment(iter)) &
+	    (bdev_logical_block_size(bdev) - 1))
 		return -EINVAL;
 
 	if (nr_pages <= DIO_INLINE_BIO_VECS)
@@ -331,7 +331,6 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = bdev_file_inode(file);
 	struct block_device *bdev = I_BDEV(inode);
-	unsigned blkbits = blksize_bits(bdev_logical_block_size(bdev));
 	struct blkdev_dio *dio;
 	struct bio *bio;
 	bool is_read = (iov_iter_rw(iter) == READ);
@@ -339,7 +338,8 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 	blk_qc_t qc = BLK_QC_T_NONE;
 	int ret;
 
-	if ((pos | iov_iter_alignment(iter)) & ((1 << blkbits) - 1))
+	if ((pos | iov_iter_alignment(iter)) &
+	    (bdev_logical_block_size(bdev) - 1))
 		return -EINVAL;
 
 	bio = bio_alloc_bioset(GFP_KERNEL, nr_pages, blkdev_dio_pool);

commit 4d1a4765426fb57439164089b3cb537ec65356eb
Author: Damien Le Moal <damien.lemoal@wdc.com>
Date:   Tue Nov 22 15:38:49 2016 +0900

    block_dev: Fixed direct I/O bio sector calculation
    
    A direct I/O alignment must be always checked against the device blocks size,
    but the I/O offset (bio->bi_iter.bi_sector must always use 512B sector unit, and
    not the actual logical block size.
    
    Signed-off-by: Damien Le Moal <damien.lemoal@wdc.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 35cc494f2e1a..e49fb797e447 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -226,7 +226,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	bio.bi_max_vecs = nr_pages;
 	bio.bi_io_vec = vecs;
 	bio.bi_bdev = bdev;
-	bio.bi_iter.bi_sector = pos >> blkbits;
+	bio.bi_iter.bi_sector = pos >> 9;
 	bio.bi_private = current;
 	bio.bi_end_io = blkdev_bio_end_io_simple;
 
@@ -358,7 +358,7 @@ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 
 	for (;;) {
 		bio->bi_bdev = bdev;
-		bio->bi_iter.bi_sector = pos >> blkbits;
+		bio->bi_iter.bi_sector = pos >> 9;
 		bio->bi_private = dio;
 		bio->bi_end_io = blkdev_bio_end_io;
 

commit 542ff7bf18c63cf403e36a4a1c71d86dc120d924
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Nov 16 23:14:22 2016 -0700

    block: new direct I/O implementation
    
    Similar to the simple fast path, but we now need a dio structure to
    track multiple-bio completions.  It's basically a cut-down version
    of the new iomap-based direct I/O code for filesystems, but without
    all the logic to call into the filesystem for extent lookup or
    allocation, and without the complex I/O completion workqueue handler
    for AIO - instead we just use the FUA bit on the bios to ensure
    data is flushed to stable storage.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a1b9abe6231c..35cc494f2e1a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -270,11 +270,161 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	return ret;
 }
 
+struct blkdev_dio {
+	union {
+		struct kiocb		*iocb;
+		struct task_struct	*waiter;
+	};
+	size_t			size;
+	atomic_t		ref;
+	bool			multi_bio : 1;
+	bool			should_dirty : 1;
+	bool			is_sync : 1;
+	struct bio		bio;
+};
+
+static struct bio_set *blkdev_dio_pool __read_mostly;
+
+static void blkdev_bio_end_io(struct bio *bio)
+{
+	struct blkdev_dio *dio = bio->bi_private;
+	bool should_dirty = dio->should_dirty;
+
+	if (dio->multi_bio && !atomic_dec_and_test(&dio->ref)) {
+		if (bio->bi_error && !dio->bio.bi_error)
+			dio->bio.bi_error = bio->bi_error;
+	} else {
+		if (!dio->is_sync) {
+			struct kiocb *iocb = dio->iocb;
+			ssize_t ret = dio->bio.bi_error;
+
+			if (likely(!ret)) {
+				ret = dio->size;
+				iocb->ki_pos += ret;
+			}
+
+			dio->iocb->ki_complete(iocb, ret, 0);
+			bio_put(&dio->bio);
+		} else {
+			struct task_struct *waiter = dio->waiter;
+
+			WRITE_ONCE(dio->waiter, NULL);
+			wake_up_process(waiter);
+		}
+	}
+
+	if (should_dirty) {
+		bio_check_pages_dirty(bio);
+	} else {
+		struct bio_vec *bvec;
+		int i;
+
+		bio_for_each_segment_all(bvec, bio, i)
+			put_page(bvec->bv_page);
+		bio_put(bio);
+	}
+}
+
 static ssize_t
-blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
+__blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
 {
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = bdev_file_inode(file);
+	struct block_device *bdev = I_BDEV(inode);
+	unsigned blkbits = blksize_bits(bdev_logical_block_size(bdev));
+	struct blkdev_dio *dio;
+	struct bio *bio;
+	bool is_read = (iov_iter_rw(iter) == READ);
+	loff_t pos = iocb->ki_pos;
+	blk_qc_t qc = BLK_QC_T_NONE;
+	int ret;
+
+	if ((pos | iov_iter_alignment(iter)) & ((1 << blkbits) - 1))
+		return -EINVAL;
+
+	bio = bio_alloc_bioset(GFP_KERNEL, nr_pages, blkdev_dio_pool);
+	bio_get(bio); /* extra ref for the completion handler */
+
+	dio = container_of(bio, struct blkdev_dio, bio);
+	dio->is_sync = is_sync_kiocb(iocb);
+	if (dio->is_sync)
+		dio->waiter = current;
+	else
+		dio->iocb = iocb;
+
+	dio->size = 0;
+	dio->multi_bio = false;
+	dio->should_dirty = is_read && (iter->type == ITER_IOVEC);
+
+	for (;;) {
+		bio->bi_bdev = bdev;
+		bio->bi_iter.bi_sector = pos >> blkbits;
+		bio->bi_private = dio;
+		bio->bi_end_io = blkdev_bio_end_io;
+
+		ret = bio_iov_iter_get_pages(bio, iter);
+		if (unlikely(ret)) {
+			bio->bi_error = ret;
+			bio_endio(bio);
+			break;
+		}
+
+		if (is_read) {
+			bio->bi_opf = REQ_OP_READ;
+			if (dio->should_dirty)
+				bio_set_pages_dirty(bio);
+		} else {
+			bio->bi_opf = dio_bio_write_op(iocb);
+			task_io_account_write(bio->bi_iter.bi_size);
+		}
+
+		dio->size += bio->bi_iter.bi_size;
+		pos += bio->bi_iter.bi_size;
+
+		nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES);
+		if (!nr_pages) {
+			qc = submit_bio(bio);
+			break;
+		}
+
+		if (!dio->multi_bio) {
+			dio->multi_bio = true;
+			atomic_set(&dio->ref, 2);
+		} else {
+			atomic_inc(&dio->ref);
+		}
+
+		submit_bio(bio);
+		bio = bio_alloc(GFP_KERNEL, nr_pages);
+	}
+
+	if (!dio->is_sync)
+		return -EIOCBQUEUED;
+
+	for (;;) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		if (!READ_ONCE(dio->waiter))
+			break;
+
+		if (!(iocb->ki_flags & IOCB_HIPRI) ||
+		    !blk_mq_poll(bdev_get_queue(bdev), qc))
+			io_schedule();
+	}
+	__set_current_state(TASK_RUNNING);
+
+	ret = dio->bio.bi_error;
+	if (likely(!ret)) {
+		ret = dio->size;
+		iocb->ki_pos += ret;
+	}
+
+	bio_put(&dio->bio);
+	return ret;
+}
+
+static ssize_t
+blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
+{
 	int nr_pages;
 
 	nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES + 1);
@@ -282,10 +432,18 @@ blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
 		return 0;
 	if (is_sync_kiocb(iocb) && nr_pages <= BIO_MAX_PAGES)
 		return __blkdev_direct_IO_simple(iocb, iter, nr_pages);
-	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter,
-				    blkdev_get_block, NULL, NULL,
-				    DIO_SKIP_DIO_COUNT);
+
+	return __blkdev_direct_IO(iocb, iter, min(nr_pages, BIO_MAX_PAGES));
+}
+
+static __init int blkdev_init(void)
+{
+	blkdev_dio_pool = bioset_create(4, offsetof(struct blkdev_dio, bio));
+	if (!blkdev_dio_pool)
+		return -ENOMEM;
+	return 0;
 }
+module_init(blkdev_init);
 
 int __sync_blockdev(struct block_device *bdev, int wait)
 {

commit 78250c02d9739b5b20f1884f8c1b30efc2f861e4
Author: Jens Axboe <axboe@fb.com>
Date:   Thu Nov 17 17:50:47 2016 +0100

    block: make __blkdev_direct_IO_sync() support O_SYNC/DSYNC
    
    Split the op setting code into a helper, use it in both places.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index dad97e19bb1f..a1b9abe6231c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -176,6 +176,16 @@ static struct inode *bdev_file_inode(struct file *file)
 	return file->f_mapping->host;
 }
 
+static unsigned int dio_bio_write_op(struct kiocb *iocb)
+{
+	unsigned int op = REQ_OP_WRITE | REQ_SYNC | REQ_IDLE;
+
+	/* avoid the need for a I/O completion work item */
+	if (iocb->ki_flags & IOCB_DSYNC)
+		op |= REQ_FUA;
+	return op;
+}
+
 #define DIO_INLINE_BIO_VECS 4
 
 static void blkdev_bio_end_io_simple(struct bio *bio)
@@ -226,11 +236,11 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	ret = bio.bi_iter.bi_size;
 
 	if (iov_iter_rw(iter) == READ) {
-		bio_set_op_attrs(&bio, REQ_OP_READ, 0);
+		bio.bi_opf = REQ_OP_READ;
 		if (iter_is_iovec(iter))
 			should_dirty = true;
 	} else {
-		bio_set_op_attrs(&bio, REQ_OP_WRITE, REQ_SYNC | REQ_IDLE);
+		bio.bi_opf = dio_bio_write_op(iocb);
 		task_io_account_write(ret);
 	}
 

commit 72ecad22d9f198aafee64218512e02ffa7818671
Author: Jens Axboe <axboe@fb.com>
Date:   Wed Nov 16 23:11:42 2016 -0700

    block: support a full bio worth of IO for simplified bdev direct-io
    
    Just alloc the bio_vec array if we exceed the inline limit.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7c3ec6049073..dad97e19bb1f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -193,7 +193,7 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	struct file *file = iocb->ki_filp;
 	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
 	unsigned blkbits = blksize_bits(bdev_logical_block_size(bdev));
-	struct bio_vec inline_vecs[DIO_INLINE_BIO_VECS], *bvec;
+	struct bio_vec inline_vecs[DIO_INLINE_BIO_VECS], *vecs, *bvec;
 	loff_t pos = iocb->ki_pos;
 	bool should_dirty = false;
 	struct bio bio;
@@ -204,9 +204,17 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 	if ((pos | iov_iter_alignment(iter)) & ((1 << blkbits) - 1))
 		return -EINVAL;
 
+	if (nr_pages <= DIO_INLINE_BIO_VECS)
+		vecs = inline_vecs;
+	else {
+		vecs = kmalloc(nr_pages * sizeof(struct bio_vec), GFP_KERNEL);
+		if (!vecs)
+			return -ENOMEM;
+	}
+
 	bio_init(&bio);
 	bio.bi_max_vecs = nr_pages;
-	bio.bi_io_vec = inline_vecs;
+	bio.bi_io_vec = vecs;
 	bio.bi_bdev = bdev;
 	bio.bi_iter.bi_sector = pos >> blkbits;
 	bio.bi_private = current;
@@ -243,6 +251,9 @@ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
 		put_page(bvec->bv_page);
 	}
 
+	if (vecs != inline_vecs)
+		kfree(vecs);
+
 	if (unlikely(bio.bi_error))
 		return bio.bi_error;
 	iocb->ki_pos += ret;
@@ -256,10 +267,10 @@ blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
 	struct inode *inode = bdev_file_inode(file);
 	int nr_pages;
 
-	nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES);
+	nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES + 1);
 	if (!nr_pages)
 		return 0;
-	if (is_sync_kiocb(iocb) && nr_pages <= DIO_INLINE_BIO_VECS)
+	if (is_sync_kiocb(iocb) && nr_pages <= BIO_MAX_PAGES)
 		return __blkdev_direct_IO_simple(iocb, iter, nr_pages);
 	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter,
 				    blkdev_get_block, NULL, NULL,

commit 189ce2b9dcc3494410a576fbecbedbb6b21e51e0
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Oct 31 11:59:25 2016 -0600

    block: fast-path for small and simple direct I/O requests
    
    This patch adds a small and simple fast patch for small direct I/O
    requests on block devices that don't use AIO.  Between the neat
    bio_iov_iter_get_pages helper that avoids allocating a page array
    for get_user_pages and the on-stack bio and biovec this avoid memory
    allocations and atomic operations entirely in the direct I/O code
    (lower levels might still do memory allocations and will usually
    have at least some atomic operations, though).
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>
    Tested-By: Stephen Bates <sbates@raithlin.com>
    Reviewed-By: Stephen Bates <sbates@raithlin.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 05b553368bb4..7c3ec6049073 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -30,6 +30,7 @@
 #include <linux/cleancache.h>
 #include <linux/dax.h>
 #include <linux/badblocks.h>
+#include <linux/task_io_accounting_ops.h>
 #include <linux/falloc.h>
 #include <asm/uaccess.h>
 #include "internal.h"
@@ -175,12 +176,91 @@ static struct inode *bdev_file_inode(struct file *file)
 	return file->f_mapping->host;
 }
 
+#define DIO_INLINE_BIO_VECS 4
+
+static void blkdev_bio_end_io_simple(struct bio *bio)
+{
+	struct task_struct *waiter = bio->bi_private;
+
+	WRITE_ONCE(bio->bi_private, NULL);
+	wake_up_process(waiter);
+}
+
+static ssize_t
+__blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
+		int nr_pages)
+{
+	struct file *file = iocb->ki_filp;
+	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
+	unsigned blkbits = blksize_bits(bdev_logical_block_size(bdev));
+	struct bio_vec inline_vecs[DIO_INLINE_BIO_VECS], *bvec;
+	loff_t pos = iocb->ki_pos;
+	bool should_dirty = false;
+	struct bio bio;
+	ssize_t ret;
+	blk_qc_t qc;
+	int i;
+
+	if ((pos | iov_iter_alignment(iter)) & ((1 << blkbits) - 1))
+		return -EINVAL;
+
+	bio_init(&bio);
+	bio.bi_max_vecs = nr_pages;
+	bio.bi_io_vec = inline_vecs;
+	bio.bi_bdev = bdev;
+	bio.bi_iter.bi_sector = pos >> blkbits;
+	bio.bi_private = current;
+	bio.bi_end_io = blkdev_bio_end_io_simple;
+
+	ret = bio_iov_iter_get_pages(&bio, iter);
+	if (unlikely(ret))
+		return ret;
+	ret = bio.bi_iter.bi_size;
+
+	if (iov_iter_rw(iter) == READ) {
+		bio_set_op_attrs(&bio, REQ_OP_READ, 0);
+		if (iter_is_iovec(iter))
+			should_dirty = true;
+	} else {
+		bio_set_op_attrs(&bio, REQ_OP_WRITE, REQ_SYNC | REQ_IDLE);
+		task_io_account_write(ret);
+	}
+
+	qc = submit_bio(&bio);
+	for (;;) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		if (!READ_ONCE(bio.bi_private))
+			break;
+		if (!(iocb->ki_flags & IOCB_HIPRI) ||
+		    !blk_mq_poll(bdev_get_queue(bdev), qc))
+			io_schedule();
+	}
+	__set_current_state(TASK_RUNNING);
+
+	bio_for_each_segment_all(bvec, &bio, i) {
+		if (should_dirty && !PageCompound(bvec->bv_page))
+			set_page_dirty_lock(bvec->bv_page);
+		put_page(bvec->bv_page);
+	}
+
+	if (unlikely(bio.bi_error))
+		return bio.bi_error;
+	iocb->ki_pos += ret;
+	return ret;
+}
+
 static ssize_t
 blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
 {
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = bdev_file_inode(file);
+	int nr_pages;
 
+	nr_pages = iov_iter_npages(iter, BIO_MAX_PAGES);
+	if (!nr_pages)
+		return 0;
+	if (is_sync_kiocb(iocb) && nr_pages <= DIO_INLINE_BIO_VECS)
+		return __blkdev_direct_IO_simple(iocb, iter, nr_pages);
 	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter,
 				    blkdev_get_block, NULL, NULL,
 				    DIO_SKIP_DIO_COUNT);

commit 25f4c41415e513f0e9fb1f3fce2ce98fcba8d263
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Tue Oct 11 13:51:11 2016 -0700

    block: implement (some of) fallocate for block devices
    
    After much discussion, it seems that the fallocate feature flag
    FALLOC_FL_ZERO_RANGE maps nicely to SCSI WRITE SAME; and the feature
    FALLOC_FL_PUNCH_HOLE maps nicely to the devices that have been whitelisted
    for zeroing SCSI UNMAP.  Punch still requires that FALLOC_FL_KEEP_SIZE is
    set.  A length that goes past the end of the device will be clamped to the
    device size if KEEP_SIZE is set; or will return -EINVAL if not.  Both
    start and length must be aligned to the device's logical block size.
    
    Since the semantics of fallocate are fairly well established already, wire
    up the two pieces.  The other fallocate variants (collapse range, insert
    range, and allocate blocks) are not supported.
    
    Link: http://lkml.kernel.org/r/147518379992.22791.8849838163218235007.stgit@birch.djwong.org
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: Mike Snitzer <snitzer@redhat.com> # tweaked header
    Cc: Brian Foster <bfoster@redhat.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 376e4e426324..05b553368bb4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -30,6 +30,7 @@
 #include <linux/cleancache.h>
 #include <linux/dax.h>
 #include <linux/badblocks.h>
+#include <linux/falloc.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 
@@ -1775,6 +1776,81 @@ static const struct address_space_operations def_blk_aops = {
 	.is_dirty_writeback = buffer_check_dirty_writeback,
 };
 
+#define	BLKDEV_FALLOC_FL_SUPPORTED					\
+		(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE |		\
+		 FALLOC_FL_ZERO_RANGE | FALLOC_FL_NO_HIDE_STALE)
+
+static long blkdev_fallocate(struct file *file, int mode, loff_t start,
+			     loff_t len)
+{
+	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
+	struct request_queue *q = bdev_get_queue(bdev);
+	struct address_space *mapping;
+	loff_t end = start + len - 1;
+	loff_t isize;
+	int error;
+
+	/* Fail if we don't recognize the flags. */
+	if (mode & ~BLKDEV_FALLOC_FL_SUPPORTED)
+		return -EOPNOTSUPP;
+
+	/* Don't go off the end of the device. */
+	isize = i_size_read(bdev->bd_inode);
+	if (start >= isize)
+		return -EINVAL;
+	if (end >= isize) {
+		if (mode & FALLOC_FL_KEEP_SIZE) {
+			len = isize - start;
+			end = start + len - 1;
+		} else
+			return -EINVAL;
+	}
+
+	/*
+	 * Don't allow IO that isn't aligned to logical block size.
+	 */
+	if ((start | len) & (bdev_logical_block_size(bdev) - 1))
+		return -EINVAL;
+
+	/* Invalidate the page cache, including dirty pages. */
+	mapping = bdev->bd_inode->i_mapping;
+	truncate_inode_pages_range(mapping, start, end);
+
+	switch (mode) {
+	case FALLOC_FL_ZERO_RANGE:
+	case FALLOC_FL_ZERO_RANGE | FALLOC_FL_KEEP_SIZE:
+		error = blkdev_issue_zeroout(bdev, start >> 9, len >> 9,
+					    GFP_KERNEL, false);
+		break;
+	case FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE:
+		/* Only punch if the device can do zeroing discard. */
+		if (!blk_queue_discard(q) || !q->limits.discard_zeroes_data)
+			return -EOPNOTSUPP;
+		error = blkdev_issue_discard(bdev, start >> 9, len >> 9,
+					     GFP_KERNEL, 0);
+		break;
+	case FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE | FALLOC_FL_NO_HIDE_STALE:
+		if (!blk_queue_discard(q))
+			return -EOPNOTSUPP;
+		error = blkdev_issue_discard(bdev, start >> 9, len >> 9,
+					     GFP_KERNEL, 0);
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+	if (error)
+		return error;
+
+	/*
+	 * Invalidate again; if someone wandered in and dirtied a page,
+	 * the caller will be given -EBUSY.  The third argument is
+	 * inclusive, so the rounding here is safe.
+	 */
+	return invalidate_inode_pages2_range(mapping,
+					     start >> PAGE_SHIFT,
+					     end >> PAGE_SHIFT);
+}
+
 const struct file_operations def_blk_fops = {
 	.open		= blkdev_open,
 	.release	= blkdev_close,
@@ -1789,6 +1865,7 @@ const struct file_operations def_blk_fops = {
 #endif
 	.splice_read	= generic_file_splice_read,
 	.splice_write	= iter_file_splice_write,
+	.fallocate	= blkdev_fallocate,
 };
 
 int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)

commit 997198ba1ed691c09457120576c27dbd953d0557
Author: Pierre Morel <pmorel@linux.vnet.ibm.com>
Date:   Tue Oct 4 10:53:40 2016 +0200

    fs/block_dev.c: return the right error in thaw_bdev()
    
    When triggering thaw-filesystems via magic sysrq, the system enters a
    loop in do_thaw_one(), as thaw_bdev() still returns success if
    bd_fsfreeze_count == 0. To fix this, let thaw_bdev() always return
    error (and simplify the code a bit at the same time).
    
    Reviewed-by: Eric Farman <farman@linux.vnet.ibm.com>
    Reviewed-by: Cornelia Huck <cornelia.huck@de.ibm.com>
    Signed-off-by: Pierre Morel <pmorel@linux.vnet.ibm.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a516568f63b6..376e4e426324 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -299,14 +299,11 @@ int thaw_bdev(struct block_device *bdev, struct super_block *sb)
 		error = sb->s_op->thaw_super(sb);
 	else
 		error = thaw_super(sb);
-	if (error) {
+	if (error)
 		bdev->bd_fsfreeze_count++;
-		mutex_unlock(&bdev->bd_fsfreeze_mutex);
-		return error;
-	}
 out:
 	mutex_unlock(&bdev->bd_fsfreeze_mutex);
-	return 0;
+	return error;
 }
 EXPORT_SYMBOL(thaw_bdev);
 

commit 223757016837d5bc8546c5683e13fbafe6cb374d
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Sep 14 11:56:13 2016 +0200

    block_dev: remove DAX leftovers
    
    DAX support for block devices was removed in commits 03cdad
    ("block: disable block device DAX by default") and 99a01cd
    ("block: remove BLK_DEV_DAX config option"), but we still kept a call to
    dax_do_io and some uneeded i_flags manipulations introduced in commit
    bbab37 ("block: Add support for DAX reads/writes to block devices").
    
    Remove those leftovers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 08ae99343d92..a516568f63b6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -180,9 +180,6 @@ blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = bdev_file_inode(file);
 
-	if (IS_DAX(inode))
-		return dax_do_io(iocb, inode, iter, blkdev_get_block,
-				NULL, DIO_SKIP_DIO_COUNT);
 	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter,
 				    blkdev_get_block, NULL, NULL,
 				    DIO_SKIP_DIO_COUNT);
@@ -1275,7 +1272,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
-		bdev->bd_inode->i_flags = 0;
 
 		if (!partno) {
 			ret = -ENXIO;
@@ -1303,11 +1299,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				}
 			}
 
-			if (!ret) {
+			if (!ret)
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
-				if (!bdev_dax_capable(bdev))
-					bdev->bd_inode->i_flags &= ~S_DAX;
-			}
 
 			/*
 			 * If the device is invalidated, rescan partition
@@ -1342,8 +1335,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_clear;
 			}
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
-			if (!bdev_dax_capable(bdev))
-				bdev->bd_inode->i_flags &= ~S_DAX;
 		}
 	} else {
 		if (bdev->bd_contains == bdev) {

commit 5bb53c0fb8e0fc2e34287d5d0fcadc784de913e1
Author: Andrey Ryabinin <aryabinin@virtuozzo.com>
Date:   Tue Aug 23 18:55:31 2016 +0300

    fs/block_dev: fix potential NULL ptr deref in freeze_bdev()
    
    Calling freeze_bdev() twice on the same block device without mounted
    filesystem get_super() will return NULL, which will lead to NULL-ptr
    dereference later in drop_super().
    
    Check get_super() result to fix that.
    
    Note, that this is a purely theoretical issue. We have only 3
    freeze_bdev() callers. 2 of them are in filesystem code and used on a
    device with mounted fs. The third one in lock_fs() has protection in
    upper-layer code against freezing block device the second time without
    thawing it first.
    
    Signed-off-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e17bdbdfe9b1..08ae99343d92 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -249,7 +249,8 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 		 * thaw_bdev drops it.
 		 */
 		sb = get_super(bdev);
-		drop_super(sb);
+		if (sb)
+			drop_super(sb);
 		mutex_unlock(&bdev->bd_fsfreeze_mutex);
 		return sb;
 	}

commit e9e5e3fae8da7e237049e00e0bfc9e32fd808fe8
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Mon Aug 22 12:47:43 2016 +0200

    bdev: fix NULL pointer dereference
    
    I got this:
    
        kasan: GPF could be caused by NULL-ptr deref or user memory access
        general protection fault: 0000 [#1] PREEMPT SMP KASAN
        Dumping ftrace buffer:
           (ftrace buffer empty)
        CPU: 0 PID: 5505 Comm: syz-executor Not tainted 4.8.0-rc2+ #161
        Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.3-0-ge2fc41e-prebuilt.qemu-project.org 04/01/2014
        task: ffff880113415940 task.stack: ffff880118350000
        RIP: 0010:[<ffffffff8172cb32>]  [<ffffffff8172cb32>] bd_mount+0x52/0xa0
        RSP: 0018:ffff880118357ca0  EFLAGS: 00010207
        RAX: dffffc0000000000 RBX: ffffffffffffffff RCX: ffffc90000bb6000
        RDX: 0000000000000018 RSI: ffffffff846d6b20 RDI: 00000000000000c7
        RBP: ffff880118357cb0 R08: ffff880115967c68 R09: 0000000000000000
        R10: 0000000000000000 R11: 0000000000000000 R12: ffff8801188211e8
        R13: ffffffff847baa20 R14: ffff8801139cb000 R15: 0000000000000080
        FS:  00007fa3ff6c0700(0000) GS:ffff88011aa00000(0000) knlGS:0000000000000000
        CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
        CR2: 00007fc1d8cc7e78 CR3: 0000000109f20000 CR4: 00000000000006f0
        DR0: 000000000000001e DR1: 000000000000001e DR2: 0000000000000000
        DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000600
        Stack:
         ffff880112cfd6c0 ffff8801188211e8 ffff880118357cf0 ffffffff8167f207
         ffffffff816d7a1e ffff880112a413c0 ffffffff847baa20 ffff8801188211e8
         0000000000000080 ffff880112cfd6c0 ffff880118357d38 ffffffff816dce0a
        Call Trace:
         [<ffffffff8167f207>] mount_fs+0x97/0x2e0
         [<ffffffff816d7a1e>] ? alloc_vfsmnt+0x55e/0x760
         [<ffffffff816dce0a>] vfs_kern_mount+0x7a/0x300
         [<ffffffff83c3247c>] ? _raw_read_unlock+0x2c/0x50
         [<ffffffff816dfc87>] do_mount+0x3d7/0x2730
         [<ffffffff81235fd4>] ? trace_do_page_fault+0x1f4/0x3a0
         [<ffffffff816df8b0>] ? copy_mount_string+0x40/0x40
         [<ffffffff8161ea81>] ? memset+0x31/0x40
         [<ffffffff816df73e>] ? copy_mount_options+0x1ee/0x320
         [<ffffffff816e2a02>] SyS_mount+0xb2/0x120
         [<ffffffff816e2950>] ? copy_mnt_ns+0x970/0x970
         [<ffffffff81005524>] do_syscall_64+0x1c4/0x4e0
         [<ffffffff83c3282a>] entry_SYSCALL64_slow_path+0x25/0x25
        Code: 83 e8 63 1b fc ff 48 85 c0 48 89 c3 74 4c e8 56 35 d1 ff 48 8d bb c8 00 00 00 48 b8 00 00 00 00 00 fc ff df 48 89 fa 48 c1 ea 03 <80> 3c 02 00 75 36 4c 8b a3 c8 00 00 00 48 b8 00 00 00 00 00 fc
        RIP  [<ffffffff8172cb32>] bd_mount+0x52/0xa0
         RSP <ffff880118357ca0>
        ---[ end trace 13690ad962168b98 ]---
    
    mount_pseudo() returns ERR_PTR(), not NULL, on error.
    
    Fixes: 3684aa7099e0 ("block-dev: enable writeback cgroup support")
    Cc: Shaohua Li <shli@fb.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c3cdde87cc8c..e17bdbdfe9b1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -646,7 +646,7 @@ static struct dentry *bd_mount(struct file_system_type *fs_type,
 {
 	struct dentry *dent;
 	dent = mount_pseudo(fs_type, "bdev:", &bdev_sops, NULL, BDEVFS_MAGIC);
-	if (dent)
+	if (!IS_ERR(dent))
 		dent->d_sb->s_iflags |= SB_I_CGROUPWB;
 	return dent;
 }

commit c11f0c0b5bb949673e4fc16c742f0316ae4ced20
Author: Jens Axboe <axboe@fb.com>
Date:   Fri Aug 5 08:11:04 2016 -0600

    block/mm: make bdev_ops->rw_page() take a bool for read/write
    
    Commit abf545484d31 changed it from an 'rw' flags type to the
    newer ops based interface, but now we're effectively leaking
    some bdev internals to the rest of the kernel. Since we only
    care about whether it's a read or a write at that level, just
    pass in a bool 'is_write' parameter instead.
    
    Then we can also move op_is_write() and friends back under
    CONFIG_BLOCK protection.
    
    Reviewed-by: Mike Christie <mchristi@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d402899ba135..c3cdde87cc8c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -416,8 +416,7 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 	result = blk_queue_enter(bdev->bd_queue, false);
 	if (result)
 		return result;
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
-			      REQ_OP_READ);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, false);
 	blk_queue_exit(bdev->bd_queue);
 	return result;
 }
@@ -455,8 +454,7 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 		return result;
 
 	set_page_writeback(page);
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
-			      REQ_OP_WRITE);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, true);
 	if (result)
 		end_page_writeback(page);
 	else

commit abf545484d31b68777a85c5c8f5b4bcde08283eb
Author: Mike Christie <mchristi@redhat.com>
Date:   Thu Aug 4 14:23:34 2016 -0600

    mm/block: convert rw_page users to bio op use
    
    The rw_page users were not converted to use bio/req ops. As a result
    bdev_write_page is not passing down REQ_OP_WRITE and the IOs will
    be sent down as reads.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Fixes: 4e1b2d52a80d ("block, fs, drivers: remove REQ_OP compat defs and related code")
    
    Modified by me to:
    
    1) Drop op_flags passing into ->rw_page(), as we don't use it.
    2) Make op_is_write() and friends safe to use for !CONFIG_BLOCK
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2033a3f91d58..d402899ba135 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -416,7 +416,8 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 	result = blk_queue_enter(bdev->bd_queue, false);
 	if (result)
 		return result;
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, READ);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
+			      REQ_OP_READ);
 	blk_queue_exit(bdev->bd_queue);
 	return result;
 }
@@ -445,7 +446,6 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 			struct page *page, struct writeback_control *wbc)
 {
 	int result;
-	int rw = (wbc->sync_mode == WB_SYNC_ALL) ? WRITE_SYNC : WRITE;
 	const struct block_device_operations *ops = bdev->bd_disk->fops;
 
 	if (!ops->rw_page || bdev_get_integrity(bdev))
@@ -455,7 +455,8 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 		return result;
 
 	set_page_writeback(page);
-	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, rw);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page,
+			      REQ_OP_WRITE);
 	if (result)
 		end_page_writeback(page);
 	else

commit 99a01cdf9d572e91c2805a2b89d459797864e3ca
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Wed Aug 3 13:46:15 2016 -0700

    block: remove BLK_DEV_DAX config option
    
    The functionality for block device DAX was already removed with commit
    acc93d30d7d4 ("Revert "block: enable dax for raw block devices"")
    
    However, we still had a config option hanging around that was always
    disabled because it depended on CONFIG_BROKEN.  This config option was
    introduced in commit 03cdadb04077 ("block: disable block device DAX by
    default")
    
    This change reverts that commit, removing the dead config option.
    
    Link: http://lkml.kernel.org/r/20160729182314.6368-1-ross.zwisler@linux.intel.com
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ada42cf42d06..2033a3f91d58 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1275,11 +1275,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
-		if (IS_ENABLED(CONFIG_BLK_DEV_DAX) &&
-		    blk_queue_dax(disk->queue))
-			bdev->bd_inode->i_flags = S_DAX;
-		else
-			bdev->bd_inode->i_flags = 0;
+		bdev->bd_inode->i_flags = 0;
 
 		if (!partno) {
 			ret = -ENXIO;

commit a867d7349e94b6409b08629886a819f802377e91
Merge: 601f887d6105 aeaa4a79ff6a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 29 15:54:19 2016 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull userns vfs updates from Eric Biederman:
     "This tree contains some very long awaited work on generalizing the
      user namespace support for mounting filesystems to include filesystems
      with a backing store.  The real world target is fuse but the goal is
      to update the vfs to allow any filesystem to be supported.  This
      patchset is based on a lot of code review and testing to approach that
      goal.
    
      While looking at what is needed to support the fuse filesystem it
      became clear that there were things like xattrs for security modules
      that needed special treatment.  That the resolution of those concerns
      would not be fuse specific.  That sorting out these general issues
      made most sense at the generic level, where the right people could be
      drawn into the conversation, and the issues could be solved for
      everyone.
    
      At a high level what this patchset does a couple of simple things:
    
       - Add a user namespace owner (s_user_ns) to struct super_block.
    
       - Teach the vfs to handle filesystem uids and gids not mapping into
         to kuids and kgids and being reported as INVALID_UID and
         INVALID_GID in vfs data structures.
    
      By assigning a user namespace owner filesystems that are mounted with
      only user namespace privilege can be detected.  This allows security
      modules and the like to know which mounts may not be trusted.  This
      also allows the set of uids and gids that are communicated to the
      filesystem to be capped at the set of kuids and kgids that are in the
      owning user namespace of the filesystem.
    
      One of the crazier corner casees this handles is the case of inodes
      whose i_uid or i_gid are not mapped into the vfs.  Most of the code
      simply doesn't care but it is easy to confuse the inode writeback path
      so no operation that could cause an inode write-back is permitted for
      such inodes (aka only reads are allowed).
    
      This set of changes starts out by cleaning up the code paths involved
      in user namespace permirted mounts.  Then when things are clean enough
      adds code that cleanly sets s_user_ns.  Then additional restrictions
      are added that are possible now that the filesystem superblock
      contains owner information.
    
      These changes should not affect anyone in practice, but there are some
      parts of these restrictions that are changes in behavior.
    
       - Andy's restriction on suid executables that does not honor the
         suid bit when the path is from another mount namespace (think
         /proc/[pid]/fd/) or when the filesystem was mounted by a less
         privileged user.
    
       - The replacement of the user namespace implicit setting of MNT_NODEV
         with implicitly setting SB_I_NODEV on the filesystem superblock
         instead.
    
         Using SB_I_NODEV is a stronger form that happens to make this state
         user invisible.  The user visibility can be managed but it caused
         problems when it was introduced from applications reasonably
         expecting mount flags to be what they were set to.
    
      There is a little bit of work remaining before it is safe to support
      mounting filesystems with backing store in user namespaces, beyond
      what is in this set of changes.
    
       - Verifying the mounter has permission to read/write the block device
         during mount.
    
       - Teaching the integrity modules IMA and EVM to handle filesystems
         mounted with only user namespace root and to reduce trust in their
         security xattrs accordingly.
    
       - Capturing the mounters credentials and using that for permission
         checks in d_automount and the like.  (Given that overlayfs already
         does this, and we need the work in d_automount it make sense to
         generalize this case).
    
      Furthermore there are a few changes that are on the wishlist:
    
       - Get all filesystems supporting posix acls using the generic posix
         acls so that posix_acl_fix_xattr_from_user and
         posix_acl_fix_xattr_to_user may be removed.  [Maintainability]
    
       - Reducing the permission checks in places such as remount to allow
         the superblock owner to perform them.
    
       - Allowing the superblock owner to chown files with unmapped uids and
         gids to something that is mapped so the files may be treated
         normally.
    
      I am not considering even obvious relaxations of permission checks
      until it is clear there are no more corner cases that need to be
      locked down and handled generically.
    
      Many thanks to Seth Forshee who kept this code alive, and putting up
      with me rewriting substantial portions of what he did to handle more
      corner cases, and for his diligent testing and reviewing of my
      changes"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (30 commits)
      fs: Call d_automount with the filesystems creds
      fs: Update i_[ug]id_(read|write) to translate relative to s_user_ns
      evm: Translate user/group ids relative to s_user_ns when computing HMAC
      dquot: For now explicitly don't support filesystems outside of init_user_ns
      quota: Handle quota data stored in s_user_ns in quota_setxquota
      quota: Ensure qids map to the filesystem
      vfs: Don't create inodes with a uid or gid unknown to the vfs
      vfs: Don't modify inodes with a uid or gid unknown to the vfs
      cred: Reject inodes with invalid ids in set_create_file_as()
      fs: Check for invalid i_uid in may_follow_link()
      vfs: Verify acls are valid within superblock's s_user_ns.
      userns: Handle -1 in k[ug]id_has_mapping when !CONFIG_USER_NS
      fs: Refuse uid/gid changes which don't map into s_user_ns
      selinux: Add support for unprivileged mounts from user namespaces
      Smack: Handle labels consistently in untrusted mounts
      Smack: Add support for unprivileged mounts from user namespaces
      fs: Treat foreign mounts as nosuid
      fs: Limit file caps to the user namespace of the super block
      userns: Remove the now unnecessary FS_USERNS_DEV_MOUNT flag
      userns: Remove implicit MNT_NODEV fragility.
      ...

commit 6784725ab0b9473ce44bfad91a256bd72b5cddc1
Merge: 554828ee0db4 47be61845c77
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 28 12:59:05 2016 -0700

    Merge branch 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "Assorted cleanups and fixes.
    
      Probably the most interesting part long-term is ->d_init() - that will
      have a bunch of followups in (at least) ceph and lustre, but we'll
      need to sort the barrier-related rules before it can get used for
      really non-trivial stuff.
    
      Another fun thing is the merge of ->d_iput() callers (dentry_iput()
      and dentry_unlink_inode()) and a bunch of ->d_compare() ones (all
      except the one in __d_lookup_lru())"
    
    * 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (26 commits)
      fs/dcache.c: avoid soft-lockup in dput()
      vfs: new d_init method
      vfs: Update lookup_dcache() comment
      bdev: get rid of ->bd_inodes
      Remove last traces of ->sync_page
      new helper: d_same_name()
      dentry_cmp(): use lockless_dereference() instead of smp_read_barrier_depends()
      vfs: clean up documentation
      vfs: document ->d_real()
      vfs: merge .d_select_inode() into .d_real()
      unify dentry_iput() and dentry_unlink_inode()
      binfmt_misc: ->s_root is not going anywhere
      drop redundant ->owner initializations
      ufs: get rid of redundant checks
      orangefs: constify inode_operations
      missed comment updates from ->direct_IO() prototype change
      file_inode(f)->i_mapping is f->f_mapping
      trim fsnotify hooks a bit
      9p: new helper - v9fs_parent_fid()
      debugfs: ->d_parent is never NULL or negative
      ...

commit 163d4baaebe39c0e56d9c08597eab7b3ae0bf334
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Thu Jun 23 17:05:50 2016 -0400

    block: add QUEUE_FLAG_DAX for devices to advertise their DAX support
    
    Currently, presence of direct_access() in block_device_operations
    indicates support of DAX on its block device.  Because
    block_device_operations is instantiated with 'const', this DAX
    capablity may not be enabled conditinally.
    
    In preparation for supporting DAX to device-mapper devices, add
    QUEUE_FLAG_DAX to request_queue flags to advertise their DAX
    support.  This will allow to set the DAX capability based on how
    mapped device is composed.
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: <linux-s390@vger.kernel.org>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 71ccab1d22c6..d012be4ab977 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -493,7 +493,7 @@ long bdev_direct_access(struct block_device *bdev, struct blk_dax_ctl *dax)
 
 	if (size < 0)
 		return size;
-	if (!ops->direct_access)
+	if (!blk_queue_dax(bdev_get_queue(bdev)) || !ops->direct_access)
 		return -EOPNOTSUPP;
 	if ((sector + DIV_ROUND_UP(size, 512)) >
 					part_nr_sects_read(bdev->bd_part))
@@ -1287,7 +1287,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
-		if (IS_ENABLED(CONFIG_BLK_DEV_DAX) && disk->fops->direct_access)
+		if (IS_ENABLED(CONFIG_BLK_DEV_DAX) &&
+		    blk_queue_dax(disk->queue))
 			bdev->bd_inode->i_flags = S_DAX;
 		else
 			bdev->bd_inode->i_flags = 0;

commit a4a4f9439c73b921ef246368fc6f2d7c0281e99d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jul 19 13:16:52 2016 -0400

    bdev: get rid of ->bd_inodes
    
    Since 2006 we have ->i_bdev pinning bdev in question, so there's no
    way to get to bdev ->evict_inode() while there's an aliasing inode
    anywhere.  In other words, the only place walking the list of aliases
    is guaranteed to do it only when the list is empty...
    
    Remove the detritus; it should've been done in "[PATCH] Fix a race
    condition between ->i_mapping and iput()", but nobody had noticed it
    back then.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 71ccab1d22c6..73130dad30e4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -614,7 +614,6 @@ static void init_once(void *foo)
 
 	memset(bdev, 0, sizeof(*bdev));
 	mutex_init(&bdev->bd_mutex);
-	INIT_LIST_HEAD(&bdev->bd_inodes);
 	INIT_LIST_HEAD(&bdev->bd_list);
 #ifdef CONFIG_SYSFS
 	INIT_LIST_HEAD(&bdev->bd_holder_disks);
@@ -624,24 +623,13 @@ static void init_once(void *foo)
 	mutex_init(&bdev->bd_fsfreeze_mutex);
 }
 
-static inline void __bd_forget(struct inode *inode)
-{
-	list_del_init(&inode->i_devices);
-	inode->i_bdev = NULL;
-	inode->i_mapping = &inode->i_data;
-}
-
 static void bdev_evict_inode(struct inode *inode)
 {
 	struct block_device *bdev = &BDEV_I(inode)->bdev;
-	struct list_head *p;
 	truncate_inode_pages_final(&inode->i_data);
 	invalidate_inode_buffers(inode); /* is it needed here? */
 	clear_inode(inode);
 	spin_lock(&bdev_lock);
-	while ( (p = bdev->bd_inodes.next) != &bdev->bd_inodes ) {
-		__bd_forget(list_entry(p, struct inode, i_devices));
-	}
 	list_del_init(&bdev->bd_list);
 	spin_unlock(&bdev_lock);
 }
@@ -805,7 +793,6 @@ static struct block_device *bd_acquire(struct inode *inode)
 			bdgrab(bdev);
 			inode->i_bdev = bdev;
 			inode->i_mapping = bdev->bd_inode->i_mapping;
-			list_add(&inode->i_devices, &bdev->bd_inodes);
 		}
 		spin_unlock(&bdev_lock);
 	}
@@ -821,7 +808,8 @@ void bd_forget(struct inode *inode)
 	spin_lock(&bdev_lock);
 	if (!sb_is_blkdev_sb(inode->i_sb))
 		bdev = inode->i_bdev;
-	__bd_forget(inode);
+	inode->i_bdev = NULL;
+	inode->i_mapping = &inode->i_data;
 	spin_unlock(&bdev_lock);
 
 	if (bdev)

commit a2982cc922c3068783eb9a1f77a5626a1ec36a1f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Jun 9 15:34:02 2016 -0500

    vfs: Generalize filesystem nodev handling.
    
    Introduce a function may_open_dev that tests MNT_NODEV and a new
    superblock flab SB_I_NODEV.  Use this new function in all of the
    places where MNT_NODEV was previously tested.
    
    Add the new SB_I_NODEV s_iflag to proc, sysfs, and mqueuefs as those
    filesystems should never support device nodes, and a simple superblock
    flags makes that very hard to get wrong.  With SB_I_NODEV set if any
    device nodes somehow manage to show up on on a filesystem those
    device nodes will be unopenable.
    
    Acked-by: Seth Forshee <seth.forshee@canonical.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 71ccab1d22c6..30b8d568203a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1857,7 +1857,7 @@ struct block_device *lookup_bdev(const char *pathname)
 	if (!S_ISBLK(inode->i_mode))
 		goto fail;
 	error = -EACCES;
-	if (path.mnt->mnt_flags & MNT_NODEV)
+	if (!may_open_dev(&path))
 		goto fail;
 	error = -ENOMEM;
 	bdev = bd_acquire(inode);

commit 315227f6da389f3a560f27f7777080857278e1b4
Merge: a10c38a4f385 40543f62cbdc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 26 19:34:26 2016 -0700

    Merge tag 'dax-misc-for-4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull misc DAX updates from Vishal Verma:
     "DAX error handling for 4.7
    
       - Until now, dax has been disabled if media errors were found on any
         device.  This enables the use of DAX in the presence of these
         errors by making all sector-aligned zeroing go through the driver.
    
       - The driver (already) has the ability to clear errors on writes that
         are sent through the block layer using 'DSMs' defined in ACPI 6.1.
    
      Other misc changes:
    
       - When mounting DAX filesystems, check to make sure the partition is
         page aligned.  This is a requirement for DAX, and previously, we
         allowed such unaligned mounts to succeed, but subsequent
         reads/writes would fail.
    
       - Misc/cleanup fixes from Jan that remove unused code from DAX
         related to zeroing, writeback, and some size checks"
    
    * tag 'dax-misc-for-4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm:
      dax: fix a comment in dax_zero_page_range and dax_truncate_page
      dax: for truncate/hole-punch, do zeroing through the driver if possible
      dax: export a low-level __dax_zero_page_range helper
      dax: use sb_issue_zerout instead of calling dax_clear_sectors
      dax: enable dax in the presence of known media errors (badblocks)
      dax: fallback from pmd to pte on error
      block: Update blkdev_dax_capable() for consistency
      xfs: Add alignment check for DAX mount
      ext2: Add alignment check for DAX mount
      ext4: Add alignment check for DAX mount
      block: Add bdev_dax_supported() for dax mount checks
      block: Add vfs_msg() interface
      dax: Remove redundant inode size checks
      dax: Remove pointless writeback from dax_do_io()
      dax: Remove zeroing from dax_io()
      dax: Remove dead zeroing code from fault handlers
      ext2: Avoid DAX zeroing to corrupt data
      ext2: Fix block zeroing in ext2_get_blocks() for DAX
      dax: Remove complete_unwritten argument
      DAX: move RADIX_DAX_ definitions to dax.c

commit 1f40c49570eb01436786a9b5845c4469a9a1f362
Merge: 7639dad93a55 36092ee8ba69
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 23 11:18:01 2016 -0700

    Merge tag 'libnvdimm-for-4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "The bulk of this update was stabilized before the merge window and
      appeared in -next.  The "device dax" implementation was revised this
      week in response to review feedback, and to address failures detected
      by the recently expanded ndctl unit test suite.
    
      Not included in this pull request are two dax topic branches (dax
      error handling, and dax radix-tree locking).  These topics were
      deferred to get a few more days of -next integration testing, and to
      coordinate a branch baseline with Ted and the ext4 tree.  Vishal and
      Ross will send the error handling and locking topics respectively in
      the next few days.
    
      This branch has received a positive build result from the kbuild robot
      across 226 configs.
    
      Summary:
    
       - Device DAX for persistent memory: Device DAX is the device-centric
         analogue of Filesystem DAX (CONFIG_FS_DAX).  It allows memory
         ranges to be allocated and mapped without need of an intervening
         file system.  Device DAX is strict, precise and predictable.
         Specifically this interface:
    
          a) Guarantees fault granularity with respect to a given page size
             (pte, pmd, or pud) set at configuration time.
    
          b) Enforces deterministic behavior by being strict about what
             fault scenarios are supported.
    
         Persistent memory is the first target, but the mechanism is also
         targeted for exclusive allocations of performance/feature
         differentiated memory ranges.
    
       - Support for the HPE DSM (device specific method) command formats.
         This enables management of these first generation devices until a
         unified DSM specification materializes.
    
       - Further ACPI 6.1 compliance with support for the common dimm
         identifier format.
    
       - Various fixes and cleanups across the subsystem"
    
    * tag 'libnvdimm-for-4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (40 commits)
      libnvdimm, dax: fix deletion
      libnvdimm, dax: fix alignment validation
      libnvdimm, dax: autodetect support
      libnvdimm: release ida resources
      Revert "block: enable dax for raw block devices"
      /dev/dax, core: file operations and dax-mmap
      /dev/dax, pmem: direct access to persistent memory
      libnvdimm: stop requiring a driver ->remove() method
      libnvdimm, dax: record the specified alignment of a dax-device instance
      libnvdimm, dax: reserve space to store labels for device-dax
      libnvdimm, dax: introduce device-dax infrastructure
      nfit: add sysfs dimm 'family' and 'dsm_mask' attributes
      tools/testing/nvdimm: ND_CMD_CALL support
      nfit: disable vendor specific commands
      nfit: export subsystem ids as attributes
      nfit: fix format interface code byte order per ACPI6.1
      nfit, libnvdimm: limited/whitelisted dimm command marshaling mechanism
      nfit, libnvdimm: clarify "commands" vs "_DSMs"
      libnvdimm: increase max envelope size for ioctl
      acpi/nfit: Add sysfs "id" for NVDIMM ID
      ...

commit acc93d30d7d43f428272c20a047389c4cbca82ba
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat May 7 11:40:28 2016 -0700

    Revert "block: enable dax for raw block devices"
    
    This reverts commit 5a023cdba50c5f5f2bc351783b3131699deb3937.
    
    The functionality is superseded by the new "Device DAX" facility.
    
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 20a2c02b77c4..36ee10ca503e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -29,6 +29,7 @@
 #include <linux/log2.h>
 #include <linux/cleancache.h>
 #include <linux/dax.h>
+#include <linux/badblocks.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 
@@ -1159,6 +1160,33 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
+static bool blkdev_dax_capable(struct block_device *bdev)
+{
+	struct gendisk *disk = bdev->bd_disk;
+
+	if (!disk->fops->direct_access || !IS_ENABLED(CONFIG_FS_DAX))
+		return false;
+
+	/*
+	 * If the partition is not aligned on a page boundary, we can't
+	 * do dax I/O to it.
+	 */
+	if ((bdev->bd_part->start_sect % (PAGE_SIZE / 512))
+			|| (bdev->bd_part->nr_sects % (PAGE_SIZE / 512)))
+		return false;
+
+	/*
+	 * If the device has known bad blocks, force all I/O through the
+	 * driver / page cache.
+	 *
+	 * TODO: support finer grained dax error handling
+	 */
+	if (disk->bb && disk->bb->count)
+		return false;
+
+	return true;
+}
+
 static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
 /*
@@ -1724,79 +1752,13 @@ static const struct address_space_operations def_blk_aops = {
 	.is_dirty_writeback = buffer_check_dirty_writeback,
 };
 
-#ifdef CONFIG_FS_DAX
-/*
- * In the raw block case we do not need to contend with truncation nor
- * unwritten file extents.  Without those concerns there is no need for
- * additional locking beyond the mmap_sem context that these routines
- * are already executing under.
- *
- * Note, there is no protection if the block device is dynamically
- * resized (partition grow/shrink) during a fault. A stable block device
- * size is already not enforced in the blkdev_direct_IO path.
- *
- * For DAX, it is the responsibility of the block device driver to
- * ensure the whole-disk device size is stable while requests are in
- * flight.
- *
- * Finally, unlike the filemap_page_mkwrite() case there is no
- * filesystem superblock to sync against freezing.  We still include a
- * pfn_mkwrite callback for dax drivers to receive write fault
- * notifications.
- */
-static int blkdev_dax_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
-{
-	return __dax_fault(vma, vmf, blkdev_get_block, NULL);
-}
-
-static int blkdev_dax_pfn_mkwrite(struct vm_area_struct *vma,
-		struct vm_fault *vmf)
-{
-	return dax_pfn_mkwrite(vma, vmf);
-}
-
-static int blkdev_dax_pmd_fault(struct vm_area_struct *vma, unsigned long addr,
-		pmd_t *pmd, unsigned int flags)
-{
-	return __dax_pmd_fault(vma, addr, pmd, flags, blkdev_get_block, NULL);
-}
-
-static const struct vm_operations_struct blkdev_dax_vm_ops = {
-	.fault		= blkdev_dax_fault,
-	.pmd_fault	= blkdev_dax_pmd_fault,
-	.pfn_mkwrite	= blkdev_dax_pfn_mkwrite,
-};
-
-static const struct vm_operations_struct blkdev_default_vm_ops = {
-	.fault		= filemap_fault,
-	.map_pages	= filemap_map_pages,
-};
-
-static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
-{
-	struct inode *bd_inode = bdev_file_inode(file);
-
-	file_accessed(file);
-	if (IS_DAX(bd_inode)) {
-		vma->vm_ops = &blkdev_dax_vm_ops;
-		vma->vm_flags |= VM_MIXEDMAP | VM_HUGEPAGE;
-	} else {
-		vma->vm_ops = &blkdev_default_vm_ops;
-	}
-
-	return 0;
-}
-#else
-#define blkdev_mmap generic_file_mmap
-#endif
-
 const struct file_operations def_blk_fops = {
 	.open		= blkdev_open,
 	.release	= blkdev_close,
 	.llseek		= block_llseek,
 	.read_iter	= blkdev_read_iter,
 	.write_iter	= blkdev_write_iter,
-	.mmap		= blkdev_mmap,
+	.mmap		= generic_file_mmap,
 	.fsync		= blkdev_fsync,
 	.unlocked_ioctl	= block_ioctl,
 #ifdef CONFIG_COMPAT

commit 0a70bd43053331d99881211e1d09f32de531432f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Feb 24 14:02:11 2016 -0800

    dax: enable dax in the presence of known media errors (badblocks)
    
    1/ If a mapping overlaps a bad sector fail the request.
    
    2/ Do not opportunistically report more dax-capable capacity than is
       requested when errors present.
    
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    [vishal: fix a conflict with system RAM collision patches]
    [vishal: add a 'size' parameter to ->direct_access]
    [vishal: fix a conflict with DAX alignment check patches]
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8477d4501b1e..45839b27972c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -29,7 +29,6 @@
 #include <linux/log2.h>
 #include <linux/cleancache.h>
 #include <linux/dax.h>
-#include <linux/badblocks.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 
@@ -501,7 +500,7 @@ long bdev_direct_access(struct block_device *bdev, struct blk_dax_ctl *dax)
 	sector += get_start_sect(bdev);
 	if (sector % (PAGE_SIZE / 512))
 		return -EINVAL;
-	avail = ops->direct_access(bdev, sector, &dax->addr, &dax->pfn);
+	avail = ops->direct_access(bdev, sector, &dax->addr, &dax->pfn, size);
 	if (!avail)
 		return -ERANGE;
 	if (avail > 0 && avail & ~PAGE_MASK)
@@ -561,7 +560,6 @@ EXPORT_SYMBOL_GPL(bdev_dax_supported);
  */
 bool bdev_dax_capable(struct block_device *bdev)
 {
-	struct gendisk *disk = bdev->bd_disk;
 	struct blk_dax_ctl dax = {
 		.size = PAGE_SIZE,
 	};
@@ -577,15 +575,6 @@ bool bdev_dax_capable(struct block_device *bdev)
 	if (bdev_direct_access(bdev, &dax) < 0)
 		return false;
 
-	/*
-	 * If the device has known bad blocks, force all I/O through the
-	 * driver / page cache.
-	 *
-	 * TODO: support finer grained dax error handling
-	 */
-	if (disk->bb && disk->bb->count)
-		return false;
-
 	return true;
 }
 

commit a8078b1fc616da6112eb95f0063cd34531d4ccf0
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Tue May 10 10:23:57 2016 -0600

    block: Update blkdev_dax_capable() for consistency
    
    blkdev_dax_capable() is similar to bdev_dax_supported(), but needs
    to remain as a separate interface for checking dax capability of
    a raw block device.
    
    Rename and relocate blkdev_dax_capable() to keep them maintained
    consistently, and call bdev_direct_access() for the dax capability
    check.
    
    There is no change in the behavior.
    
    Link: https://lkml.org/lkml/2016/5/9/950
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 518cde62c01c..8477d4501b1e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -29,6 +29,7 @@
 #include <linux/log2.h>
 #include <linux/cleancache.h>
 #include <linux/dax.h>
+#include <linux/badblocks.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 
@@ -554,6 +555,40 @@ int bdev_dax_supported(struct super_block *sb, int blocksize)
 }
 EXPORT_SYMBOL_GPL(bdev_dax_supported);
 
+/**
+ * bdev_dax_capable() - Return if the raw device is capable for dax
+ * @bdev: The device for raw block device access
+ */
+bool bdev_dax_capable(struct block_device *bdev)
+{
+	struct gendisk *disk = bdev->bd_disk;
+	struct blk_dax_ctl dax = {
+		.size = PAGE_SIZE,
+	};
+
+	if (!IS_ENABLED(CONFIG_FS_DAX))
+		return false;
+
+	dax.sector = 0;
+	if (bdev_direct_access(bdev, &dax) < 0)
+		return false;
+
+	dax.sector = bdev->bd_part->nr_sects - (PAGE_SIZE / 512);
+	if (bdev_direct_access(bdev, &dax) < 0)
+		return false;
+
+	/*
+	 * If the device has known bad blocks, force all I/O through the
+	 * driver / page cache.
+	 *
+	 * TODO: support finer grained dax error handling
+	 */
+	if (disk->bb && disk->bb->count)
+		return false;
+
+	return true;
+}
+
 /*
  * pseudo-fs
  */
@@ -1295,7 +1330,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 
 			if (!ret) {
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
-				if (!blkdev_dax_capable(bdev))
+				if (!bdev_dax_capable(bdev))
 					bdev->bd_inode->i_flags &= ~S_DAX;
 			}
 
@@ -1332,7 +1367,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_clear;
 			}
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
-			if (!blkdev_dax_capable(bdev))
+			if (!bdev_dax_capable(bdev))
 				bdev->bd_inode->i_flags &= ~S_DAX;
 		}
 	} else {

commit 2d96afc8f70ef86c66a0b5d80c24a27d6dd13df3
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Tue May 10 10:23:53 2016 -0600

    block: Add bdev_dax_supported() for dax mount checks
    
    DAX imposes additional requirements to a device.  Add
    bdev_dax_supported() which performs all the precondition checks
    necessary for filesystem to mount the device with dax option.
    
    Also add a new check to verify if a partition is aligned by 4KB.
    When a partition is unaligned, any dax read/write access fails,
    except for metadata update.
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 91e0ec0233c0..518cde62c01c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -509,6 +509,51 @@ long bdev_direct_access(struct block_device *bdev, struct blk_dax_ctl *dax)
 }
 EXPORT_SYMBOL_GPL(bdev_direct_access);
 
+/**
+ * bdev_dax_supported() - Check if the device supports dax for filesystem
+ * @sb: The superblock of the device
+ * @blocksize: The block size of the device
+ *
+ * This is a library function for filesystems to check if the block device
+ * can be mounted with dax option.
+ *
+ * Return: negative errno if unsupported, 0 if supported.
+ */
+int bdev_dax_supported(struct super_block *sb, int blocksize)
+{
+	struct blk_dax_ctl dax = {
+		.sector = 0,
+		.size = PAGE_SIZE,
+	};
+	int err;
+
+	if (blocksize != PAGE_SIZE) {
+		vfs_msg(sb, KERN_ERR, "error: unsupported blocksize for dax");
+		return -EINVAL;
+	}
+
+	err = bdev_direct_access(sb->s_bdev, &dax);
+	if (err < 0) {
+		switch (err) {
+		case -EOPNOTSUPP:
+			vfs_msg(sb, KERN_ERR,
+				"error: device does not support dax");
+			break;
+		case -EINVAL:
+			vfs_msg(sb, KERN_ERR,
+				"error: unaligned partition for dax");
+			break;
+		default:
+			vfs_msg(sb, KERN_ERR,
+				"error: dax access failed (%d)", err);
+		}
+		return err;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(bdev_dax_supported);
+
 /*
  * pseudo-fs
  */

commit 2af3a8159cd204fc8437ed2f75863f0fb930f0d0
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Tue May 10 10:23:52 2016 -0600

    block: Add vfs_msg() interface
    
    In preparation of moving DAX capability checks to the block layer
    from filesystem code, add a VFS message interface that aligns with
    filesystem's message format.
    
    For instance, a vfs_msg() message followed by XFS messages in case
    of a dax mount error may look like:
    
      VFS (pmem0p1): error: unaligned partition for dax
      XFS (pmem0p1): DAX unsupported by block device. Turning off DAX.
      XFS (pmem0p1): Mounting V5 Filesystem
       :
    
    vfs_msg() is largely based on ext4_msg().
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b25bb230b28a..91e0ec0233c0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -50,6 +50,18 @@ struct block_device *I_BDEV(struct inode *inode)
 }
 EXPORT_SYMBOL(I_BDEV);
 
+void __vfs_msg(struct super_block *sb, const char *prefix, const char *fmt, ...)
+{
+	struct va_format vaf;
+	va_list args;
+
+	va_start(args, fmt);
+	vaf.fmt = fmt;
+	vaf.va = &args;
+	printk_ratelimited("%sVFS (%s): %pV\n", prefix, sb->s_id, &vaf);
+	va_end(args);
+}
+
 static void bdev_write_inode(struct block_device *bdev)
 {
 	struct inode *inode = bdev->bd_inode;

commit 02fbd139759feb1f331cebd858523b5d774082e6
Author: Jan Kara <jack@suse.cz>
Date:   Wed May 11 11:58:48 2016 +0200

    dax: Remove complete_unwritten argument
    
    Fault handlers currently take complete_unwritten argument to convert
    unwritten extents after PTEs are updated. However no filesystem uses
    this anymore as the code is racy. Remove the unused argument.
    
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 20a2c02b77c4..b25bb230b28a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1746,7 +1746,7 @@ static const struct address_space_operations def_blk_aops = {
  */
 static int blkdev_dax_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 {
-	return __dax_fault(vma, vmf, blkdev_get_block, NULL);
+	return __dax_fault(vma, vmf, blkdev_get_block);
 }
 
 static int blkdev_dax_pfn_mkwrite(struct vm_area_struct *vma,
@@ -1758,7 +1758,7 @@ static int blkdev_dax_pfn_mkwrite(struct vm_area_struct *vma,
 static int blkdev_dax_pmd_fault(struct vm_area_struct *vma, unsigned long addr,
 		pmd_t *pmd, unsigned int flags)
 {
-	return __dax_pmd_fault(vma, addr, pmd, flags, blkdev_get_block, NULL);
+	return __dax_pmd_fault(vma, addr, pmd, flags, blkdev_get_block);
 }
 
 static const struct vm_operations_struct blkdev_dax_vm_ops = {

commit e259221763a40403d5bb232209998e8c45804ab8
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 7 08:52:01 2016 -0700

    fs: simplify the generic_write_sync prototype
    
    The kiocb already has the new position, so use that.  The only interesting
    case is AIO, where we currently don't bother updating ki_pos.  We're about
    to free the kiocb after we're done, so we might as well update it to make
    everyone's life simpler.
    
    While we're at it also return the bytes written argument passed in if
    we were successful so that the boilerplate error switch code in the
    callers can go away.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d8dc3512e927..a063d4d8ac39 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1660,12 +1660,8 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 
 	blk_start_plug(&plug);
 	ret = __generic_file_write_iter(iocb, from);
-	if (ret > 0) {
-		ssize_t err;
-		err = generic_write_sync(iocb, iocb->ki_pos - ret, ret);
-		if (err < 0)
-			ret = err;
-	}
+	if (ret > 0)
+		ret = generic_write_sync(iocb, ret);
 	blk_finish_plug(&plug);
 	return ret;
 }

commit dde0c2e79848298cc25621ad080d47f94dbd7cce
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 7 08:52:00 2016 -0700

    fs: add IOCB_SYNC and IOCB_DSYNC
    
    This will allow us to do per-I/O sync file writes, as required by a lot
    of fileservers or storage targets.
    
    XXX: Will need a few additional audits for O_DSYNC
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9e1f3fe25753..d8dc3512e927 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1662,7 +1662,7 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 	ret = __generic_file_write_iter(iocb, from);
 	if (ret > 0) {
 		ssize_t err;
-		err = generic_write_sync(file, iocb->ki_pos - ret, ret);
+		err = generic_write_sync(iocb, iocb->ki_pos - ret, ret);
 		if (err < 0)
 			ret = err;
 	}

commit c8b8e32d700fe943a935e435ae251364d016c497
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 7 08:51:58 2016 -0700

    direct-io: eliminate the offset argument to ->direct_IO
    
    Including blkdev_direct_IO and dax_do_io.  It has to be ki_pos to actually
    work, so eliminate the superflous argument.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 20a2c02b77c4..9e1f3fe25753 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -162,15 +162,15 @@ static struct inode *bdev_file_inode(struct file *file)
 }
 
 static ssize_t
-blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, loff_t offset)
+blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter)
 {
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = bdev_file_inode(file);
 
 	if (IS_DAX(inode))
-		return dax_do_io(iocb, inode, iter, offset, blkdev_get_block,
+		return dax_do_io(iocb, inode, iter, blkdev_get_block,
 				NULL, DIO_SKIP_DIO_COUNT);
-	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter, offset,
+	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter,
 				    blkdev_get_block, NULL, NULL,
 				    DIO_SKIP_DIO_COUNT);
 }

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 3172c4e2f502..20a2c02b77c4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -331,7 +331,7 @@ static int blkdev_write_end(struct file *file, struct address_space *mapping,
 	ret = block_write_end(file, mapping, pos, len, copied, page, fsdata);
 
 	unlock_page(page);
-	page_cache_release(page);
+	put_page(page);
 
 	return ret;
 }
@@ -1149,7 +1149,7 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 	inode_lock(bdev->bd_inode);
 	i_size_write(bdev->bd_inode, size);
 	inode_unlock(bdev->bd_inode);
-	while (bsize < PAGE_CACHE_SIZE) {
+	while (bsize < PAGE_SIZE) {
 		if (size & bsize)
 			break;
 		bsize <<= 1;

commit 35d88d97bee90fc09286d28209a64a991291a64a
Merge: 040e3abbb958 4ee86babe09f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 18 16:43:11 2016 -0700

    Merge branch 'for-4.6/core' of git://git.kernel.dk/linux-block
    
    Pull core block updates from Jens Axboe:
     "Here are the core block changes for this merge window.  Not a lot of
      exciting stuff going on in this round, most of the changes have been
      on the driver side of things.  That pull request is coming next.  This
      pull request contains:
    
       - A set of fixes for chained bio handling from Christoph.
    
       - A tag bounds check for blk-mq from Hannes, ensuring that we don't
         do something stupid if a device reports an invalid tag value.
    
       - A set of fixes/updates for the CFQ IO scheduler from Jan Kara.
    
       - A set of blk-mq fixes from Keith, adding support for dynamic
         hardware queues, and fixing init of max_dev_sectors for stacking
         devices.
    
       - A fix for the dynamic hw context from Ming.
    
       - Enabling of cgroup writeback support on a block device, from
         Shaohua"
    
    * 'for-4.6/core' of git://git.kernel.dk/linux-block:
      blk-mq: add bounds check on tag-to-rq conversion
      block: bio_remaining_done() isn't unlikely
      block: cleanup bio_endio
      block: factor out chained bio completion
      block: don't unecessarily clobber bi_error for chained bios
      block-dev: enable writeback cgroup support
      blk-mq: Fix NULL pointer updating nr_requests
      blk-mq: mark request queue as mq asap
      block: Initialize max_dev_sectors to 0
      blk-mq: dynamic h/w context count
      cfq-iosched: Allow parent cgroup to preempt its child
      cfq-iosched: Allow sync noidle workloads to preempt each other
      cfq-iosched: Reorder checks in cfq_should_preempt()
      cfq-iosched: Don't group_idle if cfqq has big thinktime

commit 3684aa7099e0ab1038a1a1bf717ae60ffc3018d1
Author: Shaohua Li <shli@fb.com>
Date:   Mon Feb 22 15:27:40 2016 -0700

    block-dev: enable writeback cgroup support
    
    block_dev's .writepages/.writepage already handles
    wbc_init_bio/wbc_account_io. We only set the SB_I_CGROUPWB bit to
    suppport writeback cgroup support.
    
    Signed-off-by: Shaohua Li <shli@fb.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7b9cd49622b1..548ded7ccbde 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -575,7 +575,11 @@ static const struct super_operations bdev_sops = {
 static struct dentry *bd_mount(struct file_system_type *fs_type,
 	int flags, const char *dev_name, void *data)
 {
-	return mount_pseudo(fs_type, "bdev:", &bdev_sops, NULL, BDEVFS_MAGIC);
+	struct dentry *dent;
+	dent = mount_pseudo(fs_type, "bdev:", &bdev_sops, NULL, BDEVFS_MAGIC);
+	if (dent)
+		dent->d_sb->s_iflags |= SB_I_CGROUPWB;
+	return dent;
 }
 
 static struct file_system_type bd_type = {

commit 7f6d5b529b7dfe2fca30cbf4bc81e16575090025
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri Feb 26 15:19:55 2016 -0800

    dax: move writeback calls into the filesystems
    
    Previously calls to dax_writeback_mapping_range() for all DAX filesystems
    (ext2, ext4 & xfs) were centralized in filemap_write_and_wait_range().
    
    dax_writeback_mapping_range() needs a struct block_device, and it used
    to get that from inode->i_sb->s_bdev.  This is correct for normal inodes
    mounted on ext2, ext4 and XFS filesystems, but is incorrect for DAX raw
    block devices and for XFS real-time files.
    
    Instead, call dax_writeback_mapping_range() directly from the filesystem
    ->writepages function so that it can supply us with a valid block
    device.  This also fixes DAX code to properly flush caches in response
    to sync(2).
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Cc: Al Viro <viro@ftp.linux.org.uk>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 31c6d1090f11..826b164a4b5b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1697,13 +1697,24 @@ static int blkdev_releasepage(struct page *page, gfp_t wait)
 	return try_to_free_buffers(page);
 }
 
+static int blkdev_writepages(struct address_space *mapping,
+			     struct writeback_control *wbc)
+{
+	if (dax_mapping(mapping)) {
+		struct block_device *bdev = I_BDEV(mapping->host);
+
+		return dax_writeback_mapping_range(mapping, bdev, wbc);
+	}
+	return generic_writepages(mapping, wbc);
+}
+
 static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
 	.readpages	= blkdev_readpages,
 	.writepage	= blkdev_writepage,
 	.write_begin	= blkdev_write_begin,
 	.write_end	= blkdev_write_end,
-	.writepages	= generic_writepages,
+	.writepages	= blkdev_writepages,
 	.releasepage	= blkdev_releasepage,
 	.direct_IO	= blkdev_direct_IO,
 	.is_dirty_writeback = buffer_check_dirty_writeback,

commit 03cdadb04077b9311bbc67d98cc5401aff76482d
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Feb 26 15:19:43 2016 -0800

    block: disable block device DAX by default
    
    The recent *sync enabling discovered that we are inserting into the
    block_device pagecache counter to the expectations of the dirty data
    tracking for dax mappings.  This can lead to data corruption.
    
    We want to support DAX for block devices eventually, but it requires
    wider changes to properly manage the pagecache.
    
       dump_stack+0x85/0xc2
       dax_writeback_mapping_range+0x60/0xe0
       blkdev_writepages+0x3f/0x50
       do_writepages+0x21/0x30
       __filemap_fdatawrite_range+0xc6/0x100
       filemap_write_and_wait+0x4a/0xa0
       set_blocksize+0x70/0xd0
       sb_set_blocksize+0x1d/0x50
       ext4_fill_super+0x75b/0x3360
       mount_bdev+0x180/0x1b0
       ext4_mount+0x15/0x20
       mount_fs+0x38/0x170
    
    Mark the support broken so its disabled by default, but otherwise still
    available for testing.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reported-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Suggested-by: Dave Chinner <david@fromorbit.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Cc: Al Viro <viro@ftp.linux.org.uk>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 39b3a174a425..31c6d1090f11 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1201,7 +1201,11 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
-		bdev->bd_inode->i_flags = disk->fops->direct_access ? S_DAX : 0;
+		if (IS_ENABLED(CONFIG_BLK_DEV_DAX) && disk->fops->direct_access)
+			bdev->bd_inode->i_flags = S_DAX;
+		else
+			bdev->bd_inode->i_flags = 0;
+
 		if (!partno) {
 			ret = -ENXIO;
 			bdev->bd_part = disk_get_part(disk, partno);

commit 9c5a05bc350c29285a89d6e1f3b68c8c7f308207
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri Feb 5 15:36:08 2016 -0800

    block: fix pfn_mkwrite() DAX fault handler
    
    Previously the pfn_mkwrite() fault handler for raw block devices called
    bldev_dax_fault() -> __dax_fault() to do a full DAX page fault.
    
    Really what the pfn_mkwrite() fault handler needs to do is call
    dax_pfn_mkwrite() to make sure that the radix tree entry for the given
    PTE is marked as dirty so that a follow-up fsync or msync call will
    flush it durably to media.
    
    Fixes: 5a023cdba50c ("block: enable dax for raw block devices")
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index afb437484362..39b3a174a425 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1730,6 +1730,12 @@ static int blkdev_dax_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 	return __dax_fault(vma, vmf, blkdev_get_block, NULL);
 }
 
+static int blkdev_dax_pfn_mkwrite(struct vm_area_struct *vma,
+		struct vm_fault *vmf)
+{
+	return dax_pfn_mkwrite(vma, vmf);
+}
+
 static int blkdev_dax_pmd_fault(struct vm_area_struct *vma, unsigned long addr,
 		pmd_t *pmd, unsigned int flags)
 {
@@ -1739,7 +1745,7 @@ static int blkdev_dax_pmd_fault(struct vm_area_struct *vma, unsigned long addr,
 static const struct vm_operations_struct blkdev_dax_vm_ops = {
 	.fault		= blkdev_dax_fault,
 	.pmd_fault	= blkdev_dax_pmd_fault,
-	.pfn_mkwrite	= blkdev_dax_fault,
+	.pfn_mkwrite	= blkdev_dax_pfn_mkwrite,
 };
 
 static const struct vm_operations_struct blkdev_default_vm_ops = {

commit 9f4736fe7ca804aa79b5916221bb13dfc6221a0f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jan 28 20:13:39 2016 -0800

    block: revert runtime dax control of the raw block device
    
    Dynamically enabling DAX requires that the page cache first be flushed
    and invalidated.  This must occur atomically with the change of DAX mode
    otherwise we confuse the fsync/msync tracking and violate data
    durability guarantees.  Eliminate the possibilty of DAX-disabled to
    DAX-enabled transitions for now and revisit this for the next cycle.
    
    Cc: Jan Kara <jack@suse.com>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7b9cd49622b1..afb437484362 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1736,37 +1736,13 @@ static int blkdev_dax_pmd_fault(struct vm_area_struct *vma, unsigned long addr,
 	return __dax_pmd_fault(vma, addr, pmd, flags, blkdev_get_block, NULL);
 }
 
-static void blkdev_vm_open(struct vm_area_struct *vma)
-{
-	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
-	struct block_device *bdev = I_BDEV(bd_inode);
-
-	inode_lock(bd_inode);
-	bdev->bd_map_count++;
-	inode_unlock(bd_inode);
-}
-
-static void blkdev_vm_close(struct vm_area_struct *vma)
-{
-	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
-	struct block_device *bdev = I_BDEV(bd_inode);
-
-	inode_lock(bd_inode);
-	bdev->bd_map_count--;
-	inode_unlock(bd_inode);
-}
-
 static const struct vm_operations_struct blkdev_dax_vm_ops = {
-	.open		= blkdev_vm_open,
-	.close		= blkdev_vm_close,
 	.fault		= blkdev_dax_fault,
 	.pmd_fault	= blkdev_dax_pmd_fault,
 	.pfn_mkwrite	= blkdev_dax_fault,
 };
 
 static const struct vm_operations_struct blkdev_default_vm_ops = {
-	.open		= blkdev_vm_open,
-	.close		= blkdev_vm_close,
 	.fault		= filemap_fault,
 	.map_pages	= filemap_map_pages,
 };
@@ -1774,18 +1750,14 @@ static const struct vm_operations_struct blkdev_default_vm_ops = {
 static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
 {
 	struct inode *bd_inode = bdev_file_inode(file);
-	struct block_device *bdev = I_BDEV(bd_inode);
 
 	file_accessed(file);
-	inode_lock(bd_inode);
-	bdev->bd_map_count++;
 	if (IS_DAX(bd_inode)) {
 		vma->vm_ops = &blkdev_dax_vm_ops;
 		vma->vm_flags |= VM_MIXEDMAP | VM_HUGEPAGE;
 	} else {
 		vma->vm_ops = &blkdev_default_vm_ops;
 	}
-	inode_unlock(bd_inode);
 
 	return 0;
 }

commit cc673757e24d018d64ff8038e28835db1e2902c4
Merge: fa7d9a1d286e e62e560fc8b6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 23 12:24:56 2016 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull final vfs updates from Al Viro:
    
     - The ->i_mutex wrappers (with small prereq in lustre)
    
     - a fix for too early freeing of symlink bodies on shmem (they need to
       be RCU-delayed) (-stable fodder)
    
     - followup to dedupe stuff merged this cycle
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      vfs: abort dedupe loop if fatal signals are pending
      make sure that freeing shmem fast symlinks is RCU-delayed
      wrappers for ->i_mutex access
      lustre: remove unused declaration

commit f9fe48bece3af2d60e1bad65db4825f5a025dd36
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri Jan 22 15:10:40 2016 -0800

    dax: support dirty DAX entries in radix tree
    
    Add support for tracking dirty DAX entries in the struct address_space
    radix tree.  This tree is already used for dirty page writeback, and it
    already supports the use of exceptional (non struct page*) entries.
    
    In order to properly track dirty DAX pages we will insert new
    exceptional entries into the radix tree that represent dirty DAX PTE or
    PMD pages.  These exceptional entries will also contain the writeback
    addresses for the PTE or PMD faults that we can use at fsync/msync time.
    
    There are currently two types of exceptional entries (shmem and shadow)
    that can be placed into the radix tree, and this adds a third.  We rely
    on the fact that only one type of exceptional entry can be found in a
    given radix tree based on its usage.  This happens for free with DAX vs
    shmem but we explicitly prevent shadow entries from being added to radix
    trees for DAX mappings.
    
    The only shadow entries that would be generated for DAX radix trees
    would be to track zero page mappings that were created for holes.  These
    pages would receive minimal benefit from having shadow entries, and the
    choice to have only one type of exceptional entry in a given radix tree
    makes the logic simpler both in clear_exceptional_entry() and in the
    rest of DAX.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "J. Bruce Fields" <bfields@fieldses.org>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Jeff Layton <jlayton@poochiereds.net>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ba762ea07f67..60895e500e15 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -75,7 +75,7 @@ void kill_bdev(struct block_device *bdev)
 {
 	struct address_space *mapping = bdev->bd_inode->i_mapping;
 
-	if (mapping->nrpages == 0 && mapping->nrshadows == 0)
+	if (mapping->nrpages == 0 && mapping->nrexceptional == 0)
 		return;
 
 	invalidate_bh_lrus();

commit 5955102c9984fa081b2d570cfac75c97eecf8f3b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jan 22 15:40:57 2016 -0500

    wrappers for ->i_mutex access
    
    parallel to mutex_{lock,unlock,trylock,is_locked,lock_nested},
    inode_foo(inode) being mutex_foo(&inode->i_mutex).
    
    Please, use those for access to ->i_mutex; over the coming cycle
    ->i_mutex will become rwsem, with ->lookup() done with it held
    only shared.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ba762ea07f67..2c3aeab17e20 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -346,9 +346,9 @@ static loff_t block_llseek(struct file *file, loff_t offset, int whence)
 	struct inode *bd_inode = bdev_file_inode(file);
 	loff_t retval;
 
-	mutex_lock(&bd_inode->i_mutex);
+	inode_lock(bd_inode);
 	retval = fixed_size_llseek(file, offset, whence, i_size_read(bd_inode));
-	mutex_unlock(&bd_inode->i_mutex);
+	inode_unlock(bd_inode);
 	return retval;
 }
 	
@@ -1142,9 +1142,9 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 {
 	unsigned bsize = bdev_logical_block_size(bdev);
 
-	mutex_lock(&bdev->bd_inode->i_mutex);
+	inode_lock(bdev->bd_inode);
 	i_size_write(bdev->bd_inode, size);
-	mutex_unlock(&bdev->bd_inode->i_mutex);
+	inode_unlock(bdev->bd_inode);
 	while (bsize < PAGE_CACHE_SIZE) {
 		if (size & bsize)
 			break;
@@ -1741,9 +1741,9 @@ static void blkdev_vm_open(struct vm_area_struct *vma)
 	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
 	struct block_device *bdev = I_BDEV(bd_inode);
 
-	mutex_lock(&bd_inode->i_mutex);
+	inode_lock(bd_inode);
 	bdev->bd_map_count++;
-	mutex_unlock(&bd_inode->i_mutex);
+	inode_unlock(bd_inode);
 }
 
 static void blkdev_vm_close(struct vm_area_struct *vma)
@@ -1751,9 +1751,9 @@ static void blkdev_vm_close(struct vm_area_struct *vma)
 	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
 	struct block_device *bdev = I_BDEV(bd_inode);
 
-	mutex_lock(&bd_inode->i_mutex);
+	inode_lock(bd_inode);
 	bdev->bd_map_count--;
-	mutex_unlock(&bd_inode->i_mutex);
+	inode_unlock(bd_inode);
 }
 
 static const struct vm_operations_struct blkdev_dax_vm_ops = {
@@ -1777,7 +1777,7 @@ static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
 	struct block_device *bdev = I_BDEV(bd_inode);
 
 	file_accessed(file);
-	mutex_lock(&bd_inode->i_mutex);
+	inode_lock(bd_inode);
 	bdev->bd_map_count++;
 	if (IS_DAX(bd_inode)) {
 		vma->vm_ops = &blkdev_dax_vm_ops;
@@ -1785,7 +1785,7 @@ static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
 	} else {
 		vma->vm_ops = &blkdev_default_vm_ops;
 	}
-	mutex_unlock(&bd_inode->i_mutex);
+	inode_unlock(bd_inode);
 
 	return 0;
 }

commit 7c24d9f3b27b198c3c4dfc8327a25fb077a96219
Merge: 99e38df89223 ed8a9d2c816e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 19 15:03:34 2016 -0800

    Merge branch 'for-4.5/core' of git://git.kernel.dk/linux-block
    
    Pull core block updates from Jens Axboe:
     "We don't have a lot of core changes this time around, it's mostly in
      drivers, which will come in a subsequent pull.
    
      The cores changes include:
    
       - blk-mq
            - Prep patch from Christoph, changing blk_mq_alloc_request() to
              take flags instead of just using gfp_t for sleep/nosleep.
            - Doc patch from me, clarifying the difference between legacy
              and blk-mq for timer usage.
            - Fixes from Raghavendra for memory-less numa nodes, and a reuse
              of CPU masks.
    
       - Cleanup from Geliang Tang, using offset_in_page() instead of open
         coding it.
    
       - From Ilya, rename request_queue slab to it reflects what it holds,
         and a fix for proper use of bdgrab/put.
    
       - A real fix for the split across stripe boundaries from Keith.  We
         yanked a broken version of this from 4.4-rc final, this one works.
    
       - From Mike Krinkin, emit a trace message when we split.
    
       - From Wei Tang, two small cleanups, not explicitly clearing memory
         that is already cleared"
    
    * 'for-4.5/core' of git://git.kernel.dk/linux-block:
      block: use bd{grab,put}() instead of open-coding
      block: split bios to max possible length
      block: add call to split trace point
      blk-mq: Avoid memoryless numa node encoded in hctx numa_node
      blk-mq: Reuse hardware context cpumask for tags
      blk-mq: add a flags parameter to blk_mq_alloc_request
      Revert "blk-flush: Queue through IO scheduler when flush not required"
      block: clarify blk_add_timer() use case for blk-mq
      bio: use offset_in_page macro
      block: do not initialise statics to 0 or NULL
      block: do not initialise globals to 0 or NULL
      block: rename request_queue slab cache

commit b2e0d1625e193b40cbbd45b799f82d54d34e015c
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jan 15 16:55:59 2016 -0800

    dax: fix lifetime of in-kernel dax mappings with dax_map_atomic()
    
    The DAX implementation needs to protect new calls to ->direct_access()
    and usage of its return value against the driver for the underlying
    block device being disabled.  Use blk_queue_enter()/blk_queue_exit() to
    hold off blk_cleanup_queue() from proceeding, or otherwise fail new
    mapping requests if the request_queue is being torn down.
    
    This also introduces blk_dax_ctl to simplify the interface from fs/dax.c
    through dax_map_atomic() to bdev_direct_access().
    
    [willy@linux.intel.com: fix read() of a hole]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ddc6cdd1860b..530145b607c4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -455,10 +455,7 @@ EXPORT_SYMBOL_GPL(bdev_write_page);
 /**
  * bdev_direct_access() - Get the address for directly-accessibly memory
  * @bdev: The device containing the memory
- * @sector: The offset within the device
- * @addr: Where to put the address of the memory
- * @pfn: The Page Frame Number for the memory
- * @size: The number of bytes requested
+ * @dax: control and output parameters for ->direct_access
  *
  * If a block device is made up of directly addressable memory, this function
  * will tell the caller the PFN and the address of the memory.  The address
@@ -469,10 +466,10 @@ EXPORT_SYMBOL_GPL(bdev_write_page);
  * Return: negative errno if an error occurs, otherwise the number of bytes
  * accessible at this address.
  */
-long bdev_direct_access(struct block_device *bdev, sector_t sector,
-			void __pmem **addr, unsigned long *pfn, long size)
+long bdev_direct_access(struct block_device *bdev, struct blk_dax_ctl *dax)
 {
-	long avail;
+	sector_t sector = dax->sector;
+	long avail, size = dax->size;
 	const struct block_device_operations *ops = bdev->bd_disk->fops;
 
 	/*
@@ -491,7 +488,7 @@ long bdev_direct_access(struct block_device *bdev, sector_t sector,
 	sector += get_start_sect(bdev);
 	if (sector % (PAGE_SIZE / 512))
 		return -EINVAL;
-	avail = ops->direct_access(bdev, sector, addr, pfn);
+	avail = ops->direct_access(bdev, sector, &dax->addr, &dax->pfn);
 	if (!avail)
 		return -ERANGE;
 	if (avail > 0 && avail & ~PAGE_MASK)

commit fe683adabfe6629c0b6db32bbbc1ce6cacbf2117
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jan 15 16:55:56 2016 -0800

    dax: guarantee page aligned results from bdev_direct_access()
    
    If a ->direct_access() implementation ever returns a map count less than
    PAGE_SIZE, catch the error in bdev_direct_access().  This simplifies
    error checking in upper layers.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Reported-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 81c0705558be..ddc6cdd1860b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -494,6 +494,8 @@ long bdev_direct_access(struct block_device *bdev, sector_t sector,
 	avail = ops->direct_access(bdev, sector, addr, pfn);
 	if (!avail)
 		return -ERANGE;
+	if (avail > 0 && avail & ~PAGE_MASK)
+		return -ENXIO;
 	return min(avail, size);
 }
 EXPORT_SYMBOL_GPL(bdev_direct_access);

commit b832861cca231c0ef27e238b28788045da3262f2
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Thu Jan 14 15:19:44 2016 -0800

    fs/block_dev.c:bdev_write_page(): use blk_queue_enter(..., GFP_NOIO)
    
    bdev_write_page() is used by swapout and by writepage where we cannot
    use __GFP_FS or __GFP_IO.  So it is misleading to mention GFP_KERNEL
    here.
    
    blk_queue_enter() only actually looks at __GFP_DIRECT_RECLAIM, so no
    bugs were harmed in the making of this patch.
    
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Jens Axboe <axboe@fb.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d33071dd683e..81c0705558be 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -437,7 +437,7 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 
 	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return -EOPNOTSUPP;
-	result = blk_queue_enter(bdev->bd_queue, GFP_KERNEL);
+	result = blk_queue_enter(bdev->bd_queue, GFP_NOIO);
 	if (result)
 		return result;
 

commit 5d097056c9a017a3b720849efb5432f37acabbac
Author: Vladimir Davydov <vdavydov@virtuozzo.com>
Date:   Thu Jan 14 15:18:21 2016 -0800

    kmemcg: account certain kmem allocations to memcg
    
    Mark those kmem allocations that are known to be easily triggered from
    userspace as __GFP_ACCOUNT/SLAB_ACCOUNT, which makes them accounted to
    memcg.  For the list, see below:
    
     - threadinfo
     - task_struct
     - task_delay_info
     - pid
     - cred
     - mm_struct
     - vm_area_struct and vm_region (nommu)
     - anon_vma and anon_vma_chain
     - signal_struct
     - sighand_struct
     - fs_struct
     - files_struct
     - fdtable and fdtable->full_fds_bits
     - dentry and external_name
     - inode for all filesystems. This is the most tedious part, because
       most filesystems overwrite the alloc_inode method.
    
    The list is far from complete, so feel free to add more objects.
    Nevertheless, it should be close to "account everything" approach and
    keep most workloads within bounds.  Malevolent users will be able to
    breach the limit, but this was possible even with the former "account
    everything" approach (simply because it did not account everything in
    fact).
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Vladimir Davydov <vdavydov@virtuozzo.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d878e4860fb7..d33071dd683e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -595,7 +595,7 @@ void __init bdev_cache_init(void)
 
 	bdev_cachep = kmem_cache_create("bdev_cache", sizeof(struct bdev_inode),
 			0, (SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|
-				SLAB_MEM_SPREAD|SLAB_PANIC),
+				SLAB_MEM_SPREAD|SLAB_ACCOUNT|SLAB_PANIC),
 			init_once);
 	err = register_filesystem(&bd_type);
 	if (err)

commit d080827f850ba4df5b955d5ca8c8c0fc92fe18c0
Merge: cbd88cd4c07f 8b63b6bfc1a5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 13 19:15:14 2016 -0800

    Merge tag 'libnvdimm-for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "The bulk of this has appeared in -next and independently received a
      build success notification from the kbuild robot.  The 'for-4.5/block-
      dax' topic branch was rebased over the weekend to drop the "block
      device end-of-life" rework that Al would like to see re-implemented
      with a notifier, and to address bug reports against the badblocks
      integration.
    
      There is pending feedback against "libnvdimm: Add a poison list and
      export badblocks" received last week.  Linda identified some localized
      fixups that we will handle incrementally.
    
      Summary:
    
       - Media error handling: The 'badblocks' implementation that
         originated in md-raid is up-levelled to a generic capability of a
         block device.  This initial implementation is limited to being
         consulted in the pmem block-i/o path.  Later, 'badblocks' will be
         consulted when creating dax mappings.
    
       - Raw block device dax: For virtualization and other cases that want
         large contiguous mappings of persistent memory, add the capability
         to dax-mmap a block device directly.
    
       - Increased /dev/mem restrictions: Add an option to treat all
         io-memory as IORESOURCE_EXCLUSIVE, i.e. disable /dev/mem access
         while a driver is actively using an address range.  This behavior
         is controlled via the new CONFIG_IO_STRICT_DEVMEM option and can be
         overridden by the existing "iomem=relaxed" kernel command line
         option.
    
       - Miscellaneous fixes include a 'pfn'-device huge page alignment fix,
         block device shutdown crash fix, and other small libnvdimm fixes"
    
    * tag 'libnvdimm-for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (32 commits)
      block: kill disk_{check|set|clear|alloc}_badblocks
      libnvdimm, pmem: nvdimm_read_bytes() badblocks support
      pmem, dax: disable dax in the presence of bad blocks
      pmem: fail io-requests to known bad blocks
      libnvdimm: convert to statically allocated badblocks
      libnvdimm: don't fail init for full badblocks list
      block, badblocks: introduce devm_init_badblocks
      block: clarify badblocks lifetime
      badblocks: rename badblocks_free to badblocks_exit
      libnvdimm, pmem: move definition of nvdimm_namespace_add_poison to nd.h
      libnvdimm: Add a poison list and export badblocks
      nfit_test: Enable DSMs for all test NFITs
      md: convert to use the generic badblocks code
      block: Add badblock management for gendisks
      badblocks: Add core badblock management code
      block: fix del_gendisk() vs blkdev_ioctl crash
      block: enable dax for raw block devices
      block: introduce bdev_file_inode()
      restrict /dev/mem to idle io memory ranges
      arch: consolidate CONFIG_STRICT_DEVM in lib/Kconfig.debug
      ...

commit ed8a9d2c816e0b0a2c5a605505e0f09ae9010dd6
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Nov 20 22:18:43 2015 +0100

    block: use bd{grab,put}() instead of open-coding
    
    - bd_acquire() and bd_forget() open-code bdgrab() and bdput()
    - raw driver uses igrab() but never checks its return value and always
      holds another ref from bind_set() while calling it, so it's
      equivalent to bdgrab()
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index aa1a45985889..8b02c90ced87 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -696,7 +696,7 @@ static struct block_device *bd_acquire(struct inode *inode)
 	spin_lock(&bdev_lock);
 	bdev = inode->i_bdev;
 	if (bdev) {
-		ihold(bdev->bd_inode);
+		bdgrab(bdev);
 		spin_unlock(&bdev_lock);
 		return bdev;
 	}
@@ -712,7 +712,7 @@ static struct block_device *bd_acquire(struct inode *inode)
 			 * So, we can access it via ->i_mapping always
 			 * without igrab().
 			 */
-			ihold(bdev->bd_inode);
+			bdgrab(bdev);
 			inode->i_bdev = bdev;
 			inode->i_mapping = bdev->bd_inode->i_mapping;
 			list_add(&inode->i_devices, &bdev->bd_inodes);
@@ -735,7 +735,7 @@ void bd_forget(struct inode *inode)
 	spin_unlock(&bdev_lock);
 
 	if (bdev)
-		iput(bdev->bd_inode);
+		bdput(bdev);
 }
 
 /**

commit 5a023cdba50c5f5f2bc351783b3131699deb3937
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Nov 30 10:20:29 2015 -0800

    block: enable dax for raw block devices
    
    If an application wants exclusive access to all of the persistent memory
    provided by an NVDIMM namespace it can use this raw-block-dax facility
    to forgo establishing a filesystem.  This capability is targeted
    primarily to hypervisors wanting to provision persistent memory for
    guests.  It can be disabled / enabled dynamically via the new BLKDAXSET
    ioctl.
    
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Reviewed-by: Jan Kara <jack@suse.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 52248bce42d2..5c0b2cba870e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1235,8 +1235,11 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				}
 			}
 
-			if (!ret)
+			if (!ret) {
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
+				if (!blkdev_dax_capable(bdev))
+					bdev->bd_inode->i_flags &= ~S_DAX;
+			}
 
 			/*
 			 * If the device is invalidated, rescan partition
@@ -1250,6 +1253,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				else if (ret == -ENOMEDIUM)
 					invalidate_partitions(disk, bdev);
 			}
+
 			if (ret)
 				goto out_clear;
 		} else {
@@ -1270,12 +1274,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_clear;
 			}
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
-			/*
-			 * If the partition is not aligned on a page
-			 * boundary, we can't do dax I/O to it.
-			 */
-			if ((bdev->bd_part->start_sect % (PAGE_SIZE / 512)) ||
-			    (bdev->bd_part->nr_sects % (PAGE_SIZE / 512)))
+			if (!blkdev_dax_capable(bdev))
 				bdev->bd_inode->i_flags &= ~S_DAX;
 		}
 	} else {
@@ -1713,13 +1712,101 @@ static const struct address_space_operations def_blk_aops = {
 	.is_dirty_writeback = buffer_check_dirty_writeback,
 };
 
+#ifdef CONFIG_FS_DAX
+/*
+ * In the raw block case we do not need to contend with truncation nor
+ * unwritten file extents.  Without those concerns there is no need for
+ * additional locking beyond the mmap_sem context that these routines
+ * are already executing under.
+ *
+ * Note, there is no protection if the block device is dynamically
+ * resized (partition grow/shrink) during a fault. A stable block device
+ * size is already not enforced in the blkdev_direct_IO path.
+ *
+ * For DAX, it is the responsibility of the block device driver to
+ * ensure the whole-disk device size is stable while requests are in
+ * flight.
+ *
+ * Finally, unlike the filemap_page_mkwrite() case there is no
+ * filesystem superblock to sync against freezing.  We still include a
+ * pfn_mkwrite callback for dax drivers to receive write fault
+ * notifications.
+ */
+static int blkdev_dax_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+{
+	return __dax_fault(vma, vmf, blkdev_get_block, NULL);
+}
+
+static int blkdev_dax_pmd_fault(struct vm_area_struct *vma, unsigned long addr,
+		pmd_t *pmd, unsigned int flags)
+{
+	return __dax_pmd_fault(vma, addr, pmd, flags, blkdev_get_block, NULL);
+}
+
+static void blkdev_vm_open(struct vm_area_struct *vma)
+{
+	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
+	struct block_device *bdev = I_BDEV(bd_inode);
+
+	mutex_lock(&bd_inode->i_mutex);
+	bdev->bd_map_count++;
+	mutex_unlock(&bd_inode->i_mutex);
+}
+
+static void blkdev_vm_close(struct vm_area_struct *vma)
+{
+	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
+	struct block_device *bdev = I_BDEV(bd_inode);
+
+	mutex_lock(&bd_inode->i_mutex);
+	bdev->bd_map_count--;
+	mutex_unlock(&bd_inode->i_mutex);
+}
+
+static const struct vm_operations_struct blkdev_dax_vm_ops = {
+	.open		= blkdev_vm_open,
+	.close		= blkdev_vm_close,
+	.fault		= blkdev_dax_fault,
+	.pmd_fault	= blkdev_dax_pmd_fault,
+	.pfn_mkwrite	= blkdev_dax_fault,
+};
+
+static const struct vm_operations_struct blkdev_default_vm_ops = {
+	.open		= blkdev_vm_open,
+	.close		= blkdev_vm_close,
+	.fault		= filemap_fault,
+	.map_pages	= filemap_map_pages,
+};
+
+static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	struct inode *bd_inode = bdev_file_inode(file);
+	struct block_device *bdev = I_BDEV(bd_inode);
+
+	file_accessed(file);
+	mutex_lock(&bd_inode->i_mutex);
+	bdev->bd_map_count++;
+	if (IS_DAX(bd_inode)) {
+		vma->vm_ops = &blkdev_dax_vm_ops;
+		vma->vm_flags |= VM_MIXEDMAP | VM_HUGEPAGE;
+	} else {
+		vma->vm_ops = &blkdev_default_vm_ops;
+	}
+	mutex_unlock(&bd_inode->i_mutex);
+
+	return 0;
+}
+#else
+#define blkdev_mmap generic_file_mmap
+#endif
+
 const struct file_operations def_blk_fops = {
 	.open		= blkdev_open,
 	.release	= blkdev_close,
 	.llseek		= block_llseek,
 	.read_iter	= blkdev_read_iter,
 	.write_iter	= blkdev_write_iter,
-	.mmap		= generic_file_mmap,
+	.mmap		= blkdev_mmap,
 	.fsync		= blkdev_fsync,
 	.unlocked_ioctl	= block_ioctl,
 #ifdef CONFIG_COMPAT

commit 4ebb16ca9a06a54cdb2e7f2ce1e506fa4d432445
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Oct 28 07:48:19 2015 +0900

    block: introduce bdev_file_inode()
    
    Similar to the file_inode() helper, provide a helper to lookup the inode for a
    raw block device itself.
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Suggested-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 44d4a1e9244e..52248bce42d2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -156,11 +156,16 @@ blkdev_get_block(struct inode *inode, sector_t iblock,
 	return 0;
 }
 
+static struct inode *bdev_file_inode(struct file *file)
+{
+	return file->f_mapping->host;
+}
+
 static ssize_t
 blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, loff_t offset)
 {
 	struct file *file = iocb->ki_filp;
-	struct inode *inode = file->f_mapping->host;
+	struct inode *inode = bdev_file_inode(file);
 
 	if (IS_DAX(inode))
 		return dax_do_io(iocb, inode, iter, offset, blkdev_get_block,
@@ -338,7 +343,7 @@ static int blkdev_write_end(struct file *file, struct address_space *mapping,
  */
 static loff_t block_llseek(struct file *file, loff_t offset, int whence)
 {
-	struct inode *bd_inode = file->f_mapping->host;
+	struct inode *bd_inode = bdev_file_inode(file);
 	loff_t retval;
 
 	mutex_lock(&bd_inode->i_mutex);
@@ -349,7 +354,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int whence)
 	
 int blkdev_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 {
-	struct inode *bd_inode = filp->f_mapping->host;
+	struct inode *bd_inode = bdev_file_inode(filp);
 	struct block_device *bdev = I_BDEV(bd_inode);
 	int error;
 	
@@ -1605,14 +1610,14 @@ EXPORT_SYMBOL(blkdev_put);
 
 static int blkdev_close(struct inode * inode, struct file * filp)
 {
-	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
+	struct block_device *bdev = I_BDEV(bdev_file_inode(filp));
 	blkdev_put(bdev, filp->f_mode);
 	return 0;
 }
 
 static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 {
-	struct block_device *bdev = I_BDEV(file->f_mapping->host);
+	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
 	fmode_t mode = file->f_mode;
 
 	/*
@@ -1637,7 +1642,7 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 {
 	struct file *file = iocb->ki_filp;
-	struct inode *bd_inode = file->f_mapping->host;
+	struct inode *bd_inode = bdev_file_inode(file);
 	loff_t size = i_size_read(bd_inode);
 	struct blk_plug plug;
 	ssize_t ret;
@@ -1669,7 +1674,7 @@ EXPORT_SYMBOL_GPL(blkdev_write_iter);
 ssize_t blkdev_read_iter(struct kiocb *iocb, struct iov_iter *to)
 {
 	struct file *file = iocb->ki_filp;
-	struct inode *bd_inode = file->f_mapping->host;
+	struct inode *bd_inode = bdev_file_inode(file);
 	loff_t size = i_size_read(bd_inode);
 	loff_t pos = iocb->ki_pos;
 

commit 424081f3c881ca3aef50cfa571e91863c10d952a
Author: Dmitry Monakhov <dmonakhov@openvz.org>
Date:   Mon Apr 13 16:31:34 2015 +0400

    fs: use gendisk->disk_name where possible
    
    gendisk with part==0 is obviously gendisk->disk_name.
    
    Signed-off-by: Dmitry Monakhov <dmonakhov@openvz.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 44d4a1e9244e..01b8e0d4b4ff 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1042,12 +1042,9 @@ EXPORT_SYMBOL_GPL(bd_unlink_disk_holder);
 static void flush_disk(struct block_device *bdev, bool kill_dirty)
 {
 	if (__invalidate_device(bdev, kill_dirty)) {
-		char name[BDEVNAME_SIZE] = "";
-
-		if (bdev->bd_disk)
-			disk_name(bdev->bd_disk, 0, name);
 		printk(KERN_WARNING "VFS: busy inodes on changed media or "
-		       "resized disk %s\n", name);
+		       "resized disk %s\n",
+		       bdev->bd_disk ? bdev->bd_disk->disk_name : "");
 	}
 
 	if (!bdev->bd_disk)
@@ -1071,12 +1068,9 @@ void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
 	disk_size = (loff_t)get_capacity(disk) << 9;
 	bdev_size = i_size_read(bdev->bd_inode);
 	if (disk_size != bdev_size) {
-		char name[BDEVNAME_SIZE];
-
-		disk_name(disk, 0, name);
 		printk(KERN_INFO
 		       "%s: detected capacity change from %lld to %lld\n",
-		       name, bdev_size, disk_size);
+		       disk->disk_name, bdev_size, disk_size);
 		i_size_write(bdev->bd_inode, disk_size);
 		flush_disk(bdev, false);
 	}

commit 43d1c0eb7e11919f85200d2fce211173526f7304
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Nov 20 22:22:34 2015 +0100

    block: detach bdev inode from its wb in __blkdev_put()
    
    Since 52ebea749aae ("writeback: make backing_dev_info host
    cgroup-specific bdi_writebacks") inode, at some point in its lifetime,
    gets attached to a wb (struct bdi_writeback).  Detaching happens on
    evict, in inode_detach_wb() called from __destroy_inode(), and involves
    updating wb.
    
    However, detaching an internal bdev inode from its wb in
    __destroy_inode() is too late.  Its bdi and by extension root wb are
    embedded into struct request_queue, which has different lifetime rules
    and can be freed long before the final bdput() is called (can be from
    __fput() of a corresponding /dev inode, through dput() - evict() -
    bd_forget().  bdevs hold onto the underlying disk/queue pair only while
    opened; as soon as bdev is closed all bets are off.  In fact,
    disk/queue can be gone before __blkdev_put() even returns:
    
    1499 static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
    1500 {
    ...
    1518         if (bdev->bd_contains == bdev) {
    1519                 if (disk->fops->release)
    1520                         disk->fops->release(disk, mode);
    
    [ Driver puts its references to disk/queue ]
    
    1521         }
    1522         if (!bdev->bd_openers) {
    1523                 struct module *owner = disk->fops->owner;
    1524
    1525                 disk_put_part(bdev->bd_part);
    1526                 bdev->bd_part = NULL;
    1527                 bdev->bd_disk = NULL;
    1528                 if (bdev != bdev->bd_contains)
    1529                         victim = bdev->bd_contains;
    1530                 bdev->bd_contains = NULL;
    1531
    1532                 put_disk(disk);
    
    [ We put ours, the queue is gone
      The last bdput() would result in a write to invalid memory ]
    
    1533                 module_put(owner);
    ...
    1539 }
    
    Since bdev inodes are special anyway, detach them in __blkdev_put()
    after clearing inode's dirty bits, turning the problematic
    inode_detach_wb() in __destroy_inode() into a noop.
    
    add_disk() grabs its disk->queue since 523e1d399ce0 ("block: make
    gendisk hold a reference to its queue"), so the old ->release comment
    is removed in favor of the new inode_detach_wb() comment.
    
    Cc: stable@vger.kernel.org # 4.2+, needs backporting
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Tested-by: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c25639e907bd..44d4a1e9244e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1523,11 +1523,14 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		WARN_ON_ONCE(bdev->bd_holders);
 		sync_blockdev(bdev);
 		kill_bdev(bdev);
+
+		bdev_write_inode(bdev);
 		/*
-		 * ->release can cause the queue to disappear, so flush all
-		 * dirty data before.
+		 * Detaching bdev inode from its wb in __destroy_inode()
+		 * is too late: the queue which embeds its bdi (along with
+		 * root wb) can be gone as soon as we put_disk() below.
 		 */
-		bdev_write_inode(bdev);
+		inode_detach_wb(bdev->bd_inode);
 	}
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)

commit 6f3b0e8bcf3cbb87a7459b3ed018d31d918df3f8
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 26 09:13:05 2015 +0100

    blk-mq: add a flags parameter to blk_mq_alloc_request
    
    We already have the reserved flag, and a nowait flag awkwardly encoded as
    a gfp_t.  Add a real flags argument to make the scheme more extensible and
    allow for a nicer calling convention.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c25639e907bd..aa1a45985889 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -395,7 +395,7 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return result;
 
-	result = blk_queue_enter(bdev->bd_queue, GFP_KERNEL);
+	result = blk_queue_enter(bdev->bd_queue, false);
 	if (result)
 		return result;
 	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, READ);
@@ -432,7 +432,7 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 
 	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return -EOPNOTSUPP;
-	result = blk_queue_enter(bdev->bd_queue, GFP_KERNEL);
+	result = blk_queue_enter(bdev->bd_queue, false);
 	if (result)
 		return result;
 

commit 2e6edc95382cc36423aff18a237173ad62d5ab52
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Nov 19 13:29:28 2015 -0800

    block: protect rw_page against device teardown
    
    Fix use after free crashes like the following:
    
     general protection fault: 0000 [#1] SMP
     Call Trace:
      [<ffffffffa0050216>] ? pmem_do_bvec.isra.12+0xa6/0xf0 [nd_pmem]
      [<ffffffffa0050ba2>] pmem_rw_page+0x42/0x80 [nd_pmem]
      [<ffffffff8128fd90>] bdev_read_page+0x50/0x60
      [<ffffffff812972f0>] do_mpage_readpage+0x510/0x770
      [<ffffffff8128fd20>] ? I_BDEV+0x20/0x20
      [<ffffffff811d86dc>] ? lru_cache_add+0x1c/0x50
      [<ffffffff81297657>] mpage_readpages+0x107/0x170
      [<ffffffff8128fd20>] ? I_BDEV+0x20/0x20
      [<ffffffff8128fd20>] ? I_BDEV+0x20/0x20
      [<ffffffff8129058d>] blkdev_readpages+0x1d/0x20
      [<ffffffff811d615f>] __do_page_cache_readahead+0x28f/0x310
      [<ffffffff811d6039>] ? __do_page_cache_readahead+0x169/0x310
      [<ffffffff811c5abd>] ? pagecache_get_page+0x2d/0x1d0
      [<ffffffff811c76f6>] filemap_fault+0x396/0x530
      [<ffffffff811f816e>] __do_fault+0x4e/0xf0
      [<ffffffff811fce7d>] handle_mm_fault+0x11bd/0x1b50
    
    Cc: <stable@vger.kernel.org>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Reported-by: kbuild test robot <lkp@intel.com>
    Acked-by: Matthew Wilcox <willy@linux.intel.com>
    [willy: symmetry fixups]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index bb0dfb1c7af1..c25639e907bd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -390,9 +390,17 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 			struct page *page)
 {
 	const struct block_device_operations *ops = bdev->bd_disk->fops;
+	int result = -EOPNOTSUPP;
+
 	if (!ops->rw_page || bdev_get_integrity(bdev))
-		return -EOPNOTSUPP;
-	return ops->rw_page(bdev, sector + get_start_sect(bdev), page, READ);
+		return result;
+
+	result = blk_queue_enter(bdev->bd_queue, GFP_KERNEL);
+	if (result)
+		return result;
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, READ);
+	blk_queue_exit(bdev->bd_queue);
+	return result;
 }
 EXPORT_SYMBOL_GPL(bdev_read_page);
 
@@ -421,14 +429,20 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 	int result;
 	int rw = (wbc->sync_mode == WB_SYNC_ALL) ? WRITE_SYNC : WRITE;
 	const struct block_device_operations *ops = bdev->bd_disk->fops;
+
 	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return -EOPNOTSUPP;
+	result = blk_queue_enter(bdev->bd_queue, GFP_KERNEL);
+	if (result)
+		return result;
+
 	set_page_writeback(page);
 	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, rw);
 	if (result)
 		end_page_writeback(page);
 	else
 		unlock_page(page);
+	blk_queue_exit(bdev->bd_queue);
 	return result;
 }
 EXPORT_SYMBOL_GPL(bdev_write_page);

commit dbd3ca50753e70e09cad747dce23b1a7683a3342
Author: Vivek Goyal <vgoyal@redhat.com>
Date:   Mon Nov 9 09:23:40 2015 -0700

    fs/block_dev.c: Remove WARN_ON() when inode writeback fails
    
    If a block device is hot removed and later last reference to device
    is put, we try to writeback the dirty inode. But device is gone and
    that writeback fails.
    
    Currently we do a WARN_ON() which does not seem to be the right thing.
    Convert it to a ratelimited kernel warning.
    
    Reported-by: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    [jmoyer@redhat.com: get rid of unnecessary name initialization, 80 cols]
    Signed-off-by: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0a793c7930eb..bb0dfb1c7af1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -50,12 +50,21 @@ struct block_device *I_BDEV(struct inode *inode)
 }
 EXPORT_SYMBOL(I_BDEV);
 
-static void bdev_write_inode(struct inode *inode)
+static void bdev_write_inode(struct block_device *bdev)
 {
+	struct inode *inode = bdev->bd_inode;
+	int ret;
+
 	spin_lock(&inode->i_lock);
 	while (inode->i_state & I_DIRTY) {
 		spin_unlock(&inode->i_lock);
-		WARN_ON_ONCE(write_inode_now(inode, true));
+		ret = write_inode_now(inode, true);
+		if (ret) {
+			char name[BDEVNAME_SIZE];
+			pr_warn_ratelimited("VFS: Dirty inode writeback failed "
+					    "for block device %s (err=%d).\n",
+					    bdevname(bdev, name), ret);
+		}
 		spin_lock(&inode->i_lock);
 	}
 	spin_unlock(&inode->i_lock);
@@ -1504,7 +1513,7 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		 * ->release can cause the queue to disappear, so flush all
 		 * dirty data before.
 		 */
-		bdev_write_inode(bdev->bd_inode);
+		bdev_write_inode(bdev);
 	}
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)

commit 25520d55cdb6ee289abc68f553d364d22478ff54
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Wed Oct 21 13:19:49 2015 -0400

    block: Inline blk_integrity in struct gendisk
    
    Up until now the_integrity profile has been dynamically allocated and
    attached to struct gendisk after the disk has been made active.
    
    This causes problems because NVMe devices need to register the profile
    prior to the partition table being read due to a mandatory metadata
    buffer requirement. In addition, DM goes through hoops to deal with
    preallocating, but not initializing integrity profiles.
    
    Since the integrity profile is small (4 bytes + a pointer), Christoph
    suggested moving it to struct gendisk proper. This requires several
    changes:
    
     - Moving the blk_integrity definition to genhd.h.
    
     - Inlining blk_integrity in struct gendisk.
    
     - Removing the dynamic allocation code.
    
     - Adding helper functions which allow gendisk to set up and tear down
       the integrity sysfs dir when a disk is added/deleted.
    
     - Adding a blk_integrity_revalidate() callback for updating the stable
       pages bdi setting.
    
     - The calls that depend on whether a device has an integrity profile or
       not now key off of the bi->profile pointer.
    
     - Simplifying the integrity support routines in DM (Mike Snitzer).
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reported-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 073bb57adab1..0a793c7930eb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1075,7 +1075,7 @@ int revalidate_disk(struct gendisk *disk)
 
 	if (disk->fops->revalidate_disk)
 		ret = disk->fops->revalidate_disk(disk);
-
+	blk_integrity_revalidate(disk);
 	bdev = bdget_disk(disk, 0);
 	if (!bdev)
 		return ret;

commit f0b2e563bc419df7c1b3d2f494574c25125f6aed
Author: Jeff Moyer <jmoyer@redhat.com>
Date:   Fri Aug 14 16:15:32 2015 -0400

    blockdev: don't set S_DAX for misaligned partitions
    
    The dax code doesn't currently support misaligned partitions,
    so disable O_DIRECT via dax until such time as that support
    materializes.
    
    Cc: <stable@vger.kernel.org>
    Suggested-by: Boaz Harrosh <boaz@plexistor.com>
    Signed-off-by: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 22ea424ee741..073bb57adab1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1242,6 +1242,13 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_clear;
 			}
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
+			/*
+			 * If the partition is not aligned on a page
+			 * boundary, we can't do dax I/O to it.
+			 */
+			if ((bdev->bd_part->start_sect % (PAGE_SIZE / 512)) ||
+			    (bdev->bd_part->nr_sects % (PAGE_SIZE / 512)))
+				bdev->bd_inode->i_flags &= ~S_DAX;
 		}
 	} else {
 		if (bdev->bd_contains == bdev) {

commit f6f7a6369203fa3e07efb7f35cfd81efe9f25b07
Merge: 839fe9156fbe df69f52d990b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 8 17:52:23 2015 -0700

    Merge branch 'akpm' (patches from Andrew)
    
    Merge second patch-bomb from Andrew Morton:
     "Almost all of the rest of MM.  There was an unusually large amount of
      MM material this time"
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (141 commits)
      zpool: remove no-op module init/exit
      mm: zbud: constify the zbud_ops
      mm: zpool: constify the zpool_ops
      mm: swap: zswap: maybe_preload & refactoring
      zram: unify error reporting
      zsmalloc: remove null check from destroy_handle_cache()
      zsmalloc: do not take class lock in zs_shrinker_count()
      zsmalloc: use class->pages_per_zspage
      zsmalloc: consider ZS_ALMOST_FULL as migrate source
      zsmalloc: partial page ordering within a fullness_list
      zsmalloc: use shrinker to trigger auto-compaction
      zsmalloc: account the number of compacted pages
      zsmalloc/zram: introduce zs_pool_stats api
      zsmalloc: cosmetic compaction code adjustments
      zsmalloc: introduce zs_can_compact() function
      zsmalloc: always keep per-class stats
      zsmalloc: drop unused variable `nr_to_migrate'
      mm/memblock.c: fix comment in __next_mem_range()
      mm/page_alloc.c: fix type information of memoryless node
      memory-hotplug: fix comments in zone_spanned_pages_in_node() and zone_spanned_pages_in_node()
      ...

commit c94c2acf84dc16cf4b989bb0bc849785b7ff52f5
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Tue Sep 8 14:58:40 2015 -0700

    dax: move DAX-related functions to a new header
    
    In order to handle the !CONFIG_TRANSPARENT_HUGEPAGES case, we need to
    return VM_FAULT_FALLBACK from the inlined dax_pmd_fault(), which is
    defined in linux/mm.h.  Given that we don't want to include <linux/mm.h>
    in <linux/fs.h>, the easiest solution is to move the DAX-related
    functions to a new header, <linux/dax.h>.  We could also have moved
    VM_FAULT_* definitions to a new header, or a different header that isn't
    quite such a boil-the-ocean header as <linux/mm.h>, but this felt like
    the best option.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Hillf Danton <dhillf@gmail.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 33b813e04f79..28cc525b8d59 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -28,6 +28,7 @@
 #include <linux/namei.h>
 #include <linux/log2.h>
 #include <linux/cleancache.h>
+#include <linux/dax.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 

commit 12f03ee606914317e7e6a0815e53a48205c31dae
Merge: d9241b22b58e 004f1afbe199
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 8 14:35:59 2015 -0700

    Merge tag 'libnvdimm-for-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "This update has successfully completed a 0day-kbuild run and has
      appeared in a linux-next release.  The changes outside of the typical
      drivers/nvdimm/ and drivers/acpi/nfit.[ch] paths are related to the
      removal of IORESOURCE_CACHEABLE, the introduction of memremap(), and
      the introduction of ZONE_DEVICE + devm_memremap_pages().
    
      Summary:
    
       - Introduce ZONE_DEVICE and devm_memremap_pages() as a generic
         mechanism for adding device-driver-discovered memory regions to the
         kernel's direct map.
    
         This facility is used by the pmem driver to enable pfn_to_page()
         operations on the page frames returned by DAX ('direct_access' in
         'struct block_device_operations').
    
         For now, the 'memmap' allocation for these "device" pages comes
         from "System RAM".  Support for allocating the memmap from device
         memory will arrive in a later kernel.
    
       - Introduce memremap() to replace usages of ioremap_cache() and
         ioremap_wt().  memremap() drops the __iomem annotation for these
         mappings to memory that do not have i/o side effects.  The
         replacement of ioremap_cache() with memremap() is limited to the
         pmem driver to ease merging the api change in v4.3.
    
         Completion of the conversion is targeted for v4.4.
    
       - Similar to the usage of memcpy_to_pmem() + wmb_pmem() in the pmem
         driver, update the VFS DAX implementation and PMEM api to provide
         persistence guarantees for kernel operations on a DAX mapping.
    
       - Convert the ACPI NFIT 'BLK' driver to map the block apertures as
         cacheable to improve performance.
    
       - Miscellaneous updates and fixes to libnvdimm including support for
         issuing "address range scrub" commands, clarifying the optimal
         'sector size' of pmem devices, a clarification of the usage of the
         ACPI '_STA' (status) property for DIMM devices, and other minor
         fixes"
    
    * tag 'libnvdimm-for-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (34 commits)
      libnvdimm, pmem: direct map legacy pmem by default
      libnvdimm, pmem: 'struct page' for pmem
      libnvdimm, pfn: 'struct page' provider infrastructure
      x86, pmem: clarify that ARCH_HAS_PMEM_API implies PMEM mapped WB
      add devm_memremap_pages
      mm: ZONE_DEVICE for "device memory"
      mm: move __phys_to_pfn and __pfn_to_phys to asm/generic/memory_model.h
      dax: drop size parameter to ->direct_access()
      nd_blk: change aperture mapping from WC to WB
      nvdimm: change to use generic kvfree()
      pmem, dax: have direct_access use __pmem annotation
      dax: update I/O path to do proper PMEM flushing
      pmem: add copy_from_iter_pmem() and clear_pmem()
      pmem, x86: clean up conditional pmem includes
      pmem: remove layer when calling arch_has_wmb_pmem()
      pmem, x86: move x86 PMEM API to new pmem.h header
      libnvdimm, e820: make CONFIG_X86_PMEM_LEGACY a tristate option
      pmem: switch to devm_ allocations
      devres: add devm_memremap
      libnvdimm, btt: write and validate parent_uuid
      ...

commit cb389b9c0e00c30c9daf20287f7d91e2466edbb1
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Aug 7 17:41:00 2015 -0400

    dax: drop size parameter to ->direct_access()
    
    None of the implementations currently use it.  The common
    bdev_direct_access() entry point handles all the size checks before
    calling ->direct_access().
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2345a9870e2c..3831e5691b32 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -462,7 +462,7 @@ long bdev_direct_access(struct block_device *bdev, sector_t sector,
 	sector += get_start_sect(bdev);
 	if (sector % (PAGE_SIZE / 512))
 		return -EINVAL;
-	avail = ops->direct_access(bdev, sector, addr, pfn, size);
+	avail = ops->direct_access(bdev, sector, addr, pfn);
 	if (!avail)
 		return -ERANGE;
 	return min(avail, size);

commit e2e05394e4a3420dab96f728df4531893494e15d
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Tue Aug 18 13:55:41 2015 -0600

    pmem, dax: have direct_access use __pmem annotation
    
    Update the annotation for the kaddr pointer returned by direct_access()
    so that it is a __pmem pointer.  This is consistent with the PMEM driver
    and with how this direct_access() pointer is used in the DAX code.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 198243717da5..2345a9870e2c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -441,7 +441,7 @@ EXPORT_SYMBOL_GPL(bdev_write_page);
  * accessible at this address.
  */
 long bdev_direct_access(struct block_device *bdev, sector_t sector,
-			void **addr, unsigned long *pfn, long size)
+			void __pmem **addr, unsigned long *pfn, long size)
 {
 	long avail;
 	const struct block_device_operations *ops = bdev->bd_disk->fops;

commit 74278da9f70d84d715601fe794567a6d2bfdf078
Author: Dave Chinner <dchinner@redhat.com>
Date:   Wed Mar 4 12:37:22 2015 -0500

    inode: convert inode_sb_list_lock to per-sb
    
    The process of reducing contention on per-superblock inode lists
    starts with moving the locking to match the per-superblock inode
    list. This takes the global lock out of the picture and reduces the
    contention problems to within a single filesystem. This doesn't get
    rid of contention as the locks still have global CPU scope, but it
    does isolate operations on different superblocks form each other.
    
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Dave Chinner <dchinner@redhat.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 198243717da5..33b813e04f79 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1769,7 +1769,7 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 {
 	struct inode *inode, *old_inode = NULL;
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&blockdev_superblock->s_inode_list_lock);
 	list_for_each_entry(inode, &blockdev_superblock->s_inodes, i_sb_list) {
 		struct address_space *mapping = inode->i_mapping;
 
@@ -1781,13 +1781,13 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 		}
 		__iget(inode);
 		spin_unlock(&inode->i_lock);
-		spin_unlock(&inode_sb_list_lock);
+		spin_unlock(&blockdev_superblock->s_inode_list_lock);
 		/*
 		 * We hold a reference to 'inode' so it couldn't have been
 		 * removed from s_inodes list while we dropped the
-		 * inode_sb_list_lock.  We cannot iput the inode now as we can
+		 * s_inode_list_lock  We cannot iput the inode now as we can
 		 * be holding the last reference and we cannot iput it under
-		 * inode_sb_list_lock. So we keep the reference and iput it
+		 * s_inode_list_lock. So we keep the reference and iput it
 		 * later.
 		 */
 		iput(old_inode);
@@ -1795,8 +1795,8 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 
 		func(I_BDEV(inode), arg);
 
-		spin_lock(&inode_sb_list_lock);
+		spin_lock(&blockdev_superblock->s_inode_list_lock);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&blockdev_superblock->s_inode_list_lock);
 	iput(old_inode);
 }

commit 1dc51b8288007753ad7cd7d08bb8fa930fc8bb10
Merge: 9b284cbdb5de 0f1db7dee200
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 4 19:36:06 2015 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull more vfs updates from Al Viro:
     "Assorted VFS fixes and related cleanups (IMO the most interesting in
      that part are f_path-related things and Eric's descriptor-related
      stuff).  UFS regression fixes (it got broken last cycle).  9P fixes.
      fs-cache series, DAX patches, Jan's file_remove_suid() work"
    
    [ I'd say this is much more than "fixes and related cleanups".  The
      file_table locking rule change by Eric Dumazet is a rather big and
      fundamental update even if the patch isn't huge.   - Linus ]
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (49 commits)
      9p: cope with bogus responses from server in p9_client_{read,write}
      p9_client_write(): avoid double p9_free_req()
      9p: forgetting to cancel request on interrupted zero-copy RPC
      dax: bdev_direct_access() may sleep
      block: Add support for DAX reads/writes to block devices
      dax: Use copy_from_iter_nocache
      dax: Add block size note to documentation
      fs/file.c: __fget() and dup2() atomicity rules
      fs/file.c: don't acquire files->file_lock in fd_install()
      fs:super:get_anon_bdev: fix race condition could cause dev exceed its upper limitation
      vfs: avoid creation of inode number 0 in get_next_ino
      namei: make set_root_rcu() return void
      make simple_positive() public
      ufs: use dir_pages instead of ufs_dir_pages()
      pagemap.h: move dir_pages() over there
      remove the pointless include of lglock.h
      fs: cleanup slight list_entry abuse
      xfs: Correctly lock inode when removing suid and file capabilities
      fs: Call security_ops->inode_killpriv on truncate
      fs: Provide function telling whether file_remove_privs() will do anything
      ...

commit 43c3dd08da890e458f670b4fc0630513fb405620
Author: Matthew Wilcox <matthew.r.wilcox@intel.com>
Date:   Fri Jul 3 10:40:43 2015 -0400

    dax: bdev_direct_access() may sleep
    
    The brd driver is the only in-tree driver that may sleep currently.
    After some discussion on linux-fsdevel, we decided that any driver
    may choose to sleep in its ->direct_access method.  To ensure that all
    callers of bdev_direct_access() are prepared for this, add a call
    to might_sleep().
    
    Signed-off-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 5dde6dff4940..12b22ddb22ef 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -445,6 +445,12 @@ long bdev_direct_access(struct block_device *bdev, sector_t sector,
 	long avail;
 	const struct block_device_operations *ops = bdev->bd_disk->fops;
 
+	/*
+	 * The device driver is allowed to sleep, in order to make the
+	 * memory directly accessible.
+	 */
+	might_sleep();
+
 	if (size < 0)
 		return size;
 	if (!ops->direct_access)

commit bbab37ddc20bae4709bca8745c128c4f46fe63c5
Author: Matthew Wilcox <matthew.r.wilcox@intel.com>
Date:   Fri Jul 3 10:40:42 2015 -0400

    block: Add support for DAX reads/writes to block devices
    
    If a block device supports the ->direct_access methods, bypass the normal
    DIO path and use DAX to go straight to memcpy() instead of allocating
    a DIO and a BIO.
    
    Includes support for the DIO_SKIP_DIO_COUNT flag in DAX, as is done in
    do_blockdev_direct_IO().
    
    Signed-off-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c7e4163ede87..5dde6dff4940 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -151,6 +151,9 @@ blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, loff_t offset)
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = file->f_mapping->host;
 
+	if (IS_DAX(inode))
+		return dax_do_io(iocb, inode, iter, offset, blkdev_get_block,
+				NULL, DIO_SKIP_DIO_COUNT);
 	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter, offset,
 				    blkdev_get_block, NULL, NULL,
 				    DIO_SKIP_DIO_COUNT);
@@ -1173,6 +1176,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_disk = disk;
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
+		bdev->bd_inode->i_flags = disk->fops->direct_access ? S_DAX : 0;
 		if (!partno) {
 			ret = -ENXIO;
 			bdev->bd_part = disk_get_part(disk, partno);

commit 43baed34bc6b22fdd433b63ec6738f2d28925b1a
Merge: 6aaf0da8728c e44ac588cd61
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 30 19:46:34 2015 -0700

    Merge branch 'for-linus' of git://git.kernel.dk/linux-block
    
    Pull more block layer patches from Jens Axboe:
     "A few later arrivers that I didn't fold into the first pull request,
      so we had a chance to run some testing.  This contains:
    
       - NVMe:
            - Set of fixes from Keith
            - 4.4 and earlier gcc build fix from Andrew
    
       - small set of xen-blk{back,front} fixes from Bob Liu.
    
       - warnings fix for bogus inline statement in I_BDEV() from Geert.
    
       - error code fixup for SG_IO ioctl from Paolo Bonzini"
    
    * 'for-linus' of git://git.kernel.dk/linux-block:
      drivers/block/nvme-core.c: fix build with gcc-4.4.4
      bdi: Remove "inline" keyword from exported I_BDEV() implementation
      block: fix bogus EFAULT error from SG_IO ioctl
      NVMe: Fix filesystem deadlock on removal
      NVMe: Failed controller initialization fixes
      NVMe: Unify controller probe and resume
      NVMe: Don't use fake status on cancelled command
      NVMe: Fix device cleanup on initialization failure
      drivers: xen-blkfront: only talk_to_blkback() when in XenbusStateInitialising
      xen/block: add multi-page ring support
      driver: xen-blkfront: move talk_to_blkback to a more suitable place
      drivers: xen-blkback: delay pending_req allocation to connect_ring

commit 88793e5c774ec69351ef6b5200bb59f532e41bca
Merge: 1bc5e157ed2b 61031952f4c8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 29 10:34:42 2015 -0700

    Merge tag 'libnvdimm-for-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/djbw/nvdimm
    
    Pull libnvdimm subsystem from Dan Williams:
     "The libnvdimm sub-system introduces, in addition to the
      libnvdimm-core, 4 drivers / enabling modules:
    
      NFIT:
        Instantiates an "nvdimm bus" with the core and registers memory
        devices (NVDIMMs) enumerated by the ACPI 6.0 NFIT (NVDIMM Firmware
        Interface table).
    
        After registering NVDIMMs the NFIT driver then registers "region"
        devices.  A libnvdimm-region defines an access mode and the
        boundaries of persistent memory media.  A region may span multiple
        NVDIMMs that are interleaved by the hardware memory controller.  In
        turn, a libnvdimm-region can be carved into a "namespace" device and
        bound to the PMEM or BLK driver which will attach a Linux block
        device (disk) interface to the memory.
    
      PMEM:
        Initially merged in v4.1 this driver for contiguous spans of
        persistent memory address ranges is re-worked to drive
        PMEM-namespaces emitted by the libnvdimm-core.
    
        In this update the PMEM driver, on x86, gains the ability to assert
        that writes to persistent memory have been flushed all the way
        through the caches and buffers in the platform to persistent media.
        See memcpy_to_pmem() and wmb_pmem().
    
      BLK:
        This new driver enables access to persistent memory media through
        "Block Data Windows" as defined by the NFIT.  The primary difference
        of this driver to PMEM is that only a small window of persistent
        memory is mapped into system address space at any given point in
        time.
    
        Per-NVDIMM windows are reprogrammed at run time, per-I/O, to access
        different portions of the media.  BLK-mode, by definition, does not
        support DAX.
    
      BTT:
        This is a library, optionally consumed by either PMEM or BLK, that
        converts a byte-accessible namespace into a disk with atomic sector
        update semantics (prevents sector tearing on crash or power loss).
    
        The sinister aspect of sector tearing is that most applications do
        not know they have a atomic sector dependency.  At least today's
        disk's rarely ever tear sectors and if they do one almost certainly
        gets a CRC error on access.  NVDIMMs will always tear and always
        silently.  Until an application is audited to be robust in the
        presence of sector-tearing the usage of BTT is recommended.
    
      Thanks to: Ross Zwisler, Jeff Moyer, Vishal Verma, Christoph Hellwig,
      Ingo Molnar, Neil Brown, Boaz Harrosh, Robert Elliott, Matthew Wilcox,
      Andy Rudoff, Linda Knippers, Toshi Kani, Nicholas Moulin, Rafael
      Wysocki, and Bob Moore"
    
    * tag 'libnvdimm-for-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/djbw/nvdimm: (33 commits)
      arch, x86: pmem api for ensuring durability of persistent memory updates
      libnvdimm: Add sysfs numa_node to NVDIMM devices
      libnvdimm: Set numa_node to NVDIMM devices
      acpi: Add acpi_map_pxm_to_online_node()
      libnvdimm, nfit: handle unarmed dimms, mark namespaces read-only
      pmem: flag pmem block devices as non-rotational
      libnvdimm: enable iostat
      pmem: make_request cleanups
      libnvdimm, pmem: fix up max_hw_sectors
      libnvdimm, blk: add support for blk integrity
      libnvdimm, btt: add support for blk integrity
      fs/block_dev.c: skip rw_page if bdev has integrity
      libnvdimm: Non-Volatile Devices
      tools/testing/nvdimm: libnvdimm unit test infrastructure
      libnvdimm, nfit, nd_blk: driver for BLK-mode access persistent memory
      nd_btt: atomic sector updates
      libnvdimm: infrastructure for btt devices
      libnvdimm: write blk label set
      libnvdimm: write pmem label set
      libnvdimm: blk labels and namespace instantiation
      ...

commit ff5053f66677b046cb85695b2a93d4eb07029fa7
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Fri Jun 26 13:58:32 2015 +0200

    bdi: Remove "inline" keyword from exported I_BDEV() implementation
    
    With gcc 3.4.6/4.1.2/4.2.4 (not with 4.4.7/4.6.4/4.8.4):
    
          CC      fs/block_dev.o
        include/linux/fs.h:804: warning: I_BDEV declared inline after being called
        include/linux/fs.h:804: warning: previous declaration of I_BDEV was here
    
    Commit a212b105b07d75b4 ("bdi: make inode_to_bdi() inline") added a
    caller of I_BDEV() in a header file, exposing the bogus "inline" on the
    exported implementation.
    
    Drop the "inline" keyword to fix this.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f04c873a7365..f839c339565e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -43,7 +43,7 @@ static inline struct bdev_inode *BDEV_I(struct inode *inode)
 	return container_of(inode, struct bdev_inode, vfs_inode);
 }
 
-inline struct block_device *I_BDEV(struct inode *inode)
+struct block_device *I_BDEV(struct inode *inode)
 {
 	return &BDEV_I(inode)->bdev;
 }

commit f68eb1e71a92765ffd8eb68466a41b48f2fbba04
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Tue May 12 13:48:53 2015 -0400

    fs/block_dev.c: skip rw_page if bdev has integrity
    
    If a block device has bio integrity enabled, rw_page will bypass the
    integrity payload, which is undesirable. Skip rw_page if this is the
    case.
    
    Currently brd and zram provide rw_page, and the proposed 'nd' drivers
    will too.
    
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Suggested-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c7e4163ede87..054ef1bbb821 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -376,7 +376,7 @@ int bdev_read_page(struct block_device *bdev, sector_t sector,
 			struct page *page)
 {
 	const struct block_device_operations *ops = bdev->bd_disk->fops;
-	if (!ops->rw_page)
+	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return -EOPNOTSUPP;
 	return ops->rw_page(bdev, sector + get_start_sect(bdev), page, READ);
 }
@@ -407,7 +407,7 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 	int result;
 	int rw = (wbc->sync_mode == WB_SYNC_ALL) ? WRITE_SYNC : WRITE;
 	const struct block_device_operations *ops = bdev->bd_disk->fops;
-	if (!ops->rw_page)
+	if (!ops->rw_page || bdev_get_integrity(bdev))
 		return -EOPNOTSUPP;
 	set_page_writeback(page);
 	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, rw);

commit a212b105b07d75b48b1a166378282e8a77fbf53d
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 22 17:13:33 2015 -0400

    bdi: make inode_to_bdi() inline
    
    Now that bdi definitions are moved to backing-dev-defs.h,
    backing-dev.h can include blkdev.h and inline inode_to_bdi() without
    worrying about introducing circular include dependency.  The function
    gets called from hot paths and fairly trivial.
    
    This patch makes inode_to_bdi() and sb_is_blkdev_sb() that the
    function calls inline.  blockdev_superblock and noop_backing_dev_info
    are EXPORT_GPL'd to allow the inline functions to be used from
    modules.
    
    While at it, make sb_is_blkdev_sb() return bool instead of int.
    
    v2: Fixed typo in description as suggested by Jan.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jens Axboe <axboe@kernel.dk>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e545cbfbe5b2..f04c873a7365 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -547,7 +547,8 @@ static struct file_system_type bd_type = {
 	.kill_sb	= kill_anon_super,
 };
 
-static struct super_block *blockdev_superblock __read_mostly;
+struct super_block *blockdev_superblock __read_mostly;
+EXPORT_SYMBOL_GPL(blockdev_superblock);
 
 void __init bdev_cache_init(void)
 {
@@ -688,11 +689,6 @@ static struct block_device *bd_acquire(struct inode *inode)
 	return bdev;
 }
 
-int sb_is_blkdev_sb(struct super_block *sb)
-{
-	return sb == blockdev_superblock;
-}
-
 /* Call when you free inode */
 
 void bd_forget(struct inode *inode)

commit 66114cad64bf76a155fec1f0fff0de771cf909d5
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 22 17:13:32 2015 -0400

    writeback: separate out include/linux/backing-dev-defs.h
    
    With the planned cgroup writeback support, backing-dev related
    declarations will be more widely used across block and cgroup;
    unfortunately, including backing-dev.h from include/linux/blkdev.h
    makes cyclic include dependency quite likely.
    
    This patch separates out backing-dev-defs.h which only has the
    essential definitions and updates blkdev.h to include it.  c files
    which need access to more backing-dev details now include
    backing-dev.h directly.  This takes backing-dev.h off the common
    include dependency chain making it a lot easier to use it across block
    and cgroup.
    
    v2: fs/fat build failure fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c7e4163ede87..e545cbfbe5b2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -14,6 +14,7 @@
 #include <linux/device_cgroup.h>
 #include <linux/highmem.h>
 #include <linux/blkdev.h>
+#include <linux/backing-dev.h>
 #include <linux/module.h>
 #include <linux/blkpg.h>
 #include <linux/magic.h>

commit fe0f07d08ee35fb13d2cb048970072fe4f71ad14
Author: Jens Axboe <axboe@fb.com>
Date:   Wed Apr 15 17:05:48 2015 -0600

    direct-io: only inc/dec inode->i_dio_count for file systems
    
    do_blockdev_direct_IO() increments and decrements the inode
    ->i_dio_count for each IO operation. It does this to protect against
    truncate of a file. Block devices don't need this sort of protection.
    
    For a capable multiqueue setup, this atomic int is the only shared
    state between applications accessing the device for O_DIRECT, and it
    presents a scaling wall for that. In my testing, as much as 30% of
    system time is spent incrementing and decrementing this value. A mixed
    read/write workload improved from ~2.5M IOPS to ~9.6M IOPS, with
    better latencies too. Before:
    
    clat percentiles (usec):
     |  1.00th=[   33],  5.00th=[   34], 10.00th=[   34], 20.00th=[   34],
     | 30.00th=[   34], 40.00th=[   34], 50.00th=[   35], 60.00th=[   35],
     | 70.00th=[   35], 80.00th=[   35], 90.00th=[   37], 95.00th=[   80],
     | 99.00th=[   98], 99.50th=[  151], 99.90th=[  155], 99.95th=[  155],
     | 99.99th=[  165]
    
    After:
    
    clat percentiles (usec):
     |  1.00th=[   95],  5.00th=[  108], 10.00th=[  129], 20.00th=[  149],
     | 30.00th=[  155], 40.00th=[  161], 50.00th=[  167], 60.00th=[  171],
     | 70.00th=[  177], 80.00th=[  185], 90.00th=[  201], 95.00th=[  270],
     | 99.00th=[  390], 99.50th=[  398], 99.90th=[  418], 99.95th=[  422],
     | 99.99th=[  438]
    
    In other setups, Robert Elliott reported seeing good performance
    improvements:
    
    https://lkml.org/lkml/2015/4/3/557
    
    The more applications accessing the device, the worse it gets.
    
    Add a new direct-io flags, DIO_SKIP_DIO_COUNT, which tells
    do_blockdev_direct_IO() that it need not worry about incrementing
    or decrementing the inode i_dio_count for this caller.
    
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Elliott, Robert (Server Storage) <elliott@hp.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Jens Axboe <axboe@fb.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 79b4fa3b391d..c7e4163ede87 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -152,7 +152,8 @@ blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, loff_t offset)
 	struct inode *inode = file->f_mapping->host;
 
 	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter, offset,
-				    blkdev_get_block, NULL, NULL, 0);
+				    blkdev_get_block, NULL, NULL,
+				    DIO_SKIP_DIO_COUNT);
 }
 
 int __sync_blockdev(struct block_device *bdev, int wait)

commit bb668734c4c960c8f61f017585b323b97e5f47b5
Author: David Howells <dhowells@redhat.com>
Date:   Tue Mar 17 22:26:21 2015 +0000

    VFS: assorted d_backing_inode() annotations
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 897ee0503932..79b4fa3b391d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1716,7 +1716,7 @@ struct block_device *lookup_bdev(const char *pathname)
 	if (error)
 		return ERR_PTR(error);
 
-	inode = path.dentry->d_inode;
+	inode = d_backing_inode(path.dentry);
 	error = -ENOTBLK;
 	if (!S_ISBLK(inode->i_mode))
 		goto fail;

commit 7ec7b94a3339756dfbb88234e3e45a428e8c08fb
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Apr 7 11:35:14 2015 -0400

    blkdev_write_iter: expand generic_file_checks() call in there
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index bcd7f97beab9..897ee0503932 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1595,18 +1595,21 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 {
 	struct file *file = iocb->ki_filp;
+	struct inode *bd_inode = file->f_mapping->host;
+	loff_t size = i_size_read(bd_inode);
 	struct blk_plug plug;
 	ssize_t ret;
-	size_t count = iov_iter_count(from);
 
-	ret = generic_write_checks(file, &iocb->ki_pos, &count, 1);
-	if (ret)
-		return ret;
+	if (bdev_read_only(I_BDEV(bd_inode)))
+		return -EPERM;
 
-	if (count == 0)
+	if (!iov_iter_count(from))
 		return 0;
 
-	iov_iter_truncate(from, count);
+	if (iocb->ki_pos >= size)
+		return -ENOSPC;
+
+	iov_iter_truncate(from, size - iocb->ki_pos);
 
 	blk_start_plug(&plug);
 	ret = __generic_file_write_iter(iocb, from);

commit 5f380c7fa7e01f15ca0816bd241ece9a64a73192
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Apr 7 11:28:12 2015 -0400

    lift generic_write_checks() into callers of __generic_file_write_iter()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 6e3de63c3055..bcd7f97beab9 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1597,6 +1597,16 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 	struct file *file = iocb->ki_filp;
 	struct blk_plug plug;
 	ssize_t ret;
+	size_t count = iov_iter_count(from);
+
+	ret = generic_write_checks(file, &iocb->ki_pos, &count, 1);
+	if (ret)
+		return ret;
+
+	if (count == 0)
+		return 0;
+
+	iov_iter_truncate(from, count);
 
 	blk_start_plug(&plug);
 	ret = __generic_file_write_iter(iocb, from);

commit 22c6186ecea0be9eff1c399298ad36e94a59995f
Author: Omar Sandoval <osandov@osandov.com>
Date:   Mon Mar 16 04:33:53 2015 -0700

    direct_IO: remove rw from a_ops->direct_IO()
    
    Now that no one is using rw, remove it completely.
    
    Signed-off-by: Omar Sandoval <osandov@osandov.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index bc23afd35fdb..6e3de63c3055 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -146,8 +146,7 @@ blkdev_get_block(struct inode *inode, sector_t iblock,
 }
 
 static ssize_t
-blkdev_direct_IO(int rw, struct kiocb *iocb, struct iov_iter *iter,
-			loff_t offset)
+blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, loff_t offset)
 {
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = file->f_mapping->host;

commit 17f8c842d24ac054e4212c82b5bd6ae455a334f3
Author: Omar Sandoval <osandov@osandov.com>
Date:   Mon Mar 16 04:33:50 2015 -0700

    Remove rw from {,__,do_}blockdev_direct_IO()
    
    Most filesystems call through to these at some point, so we'll start
    here.
    
    Signed-off-by: Omar Sandoval <osandov@osandov.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b5e87896f517..bc23afd35fdb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -152,9 +152,8 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, struct iov_iter *iter,
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = file->f_mapping->host;
 
-	return __blockdev_direct_IO(rw, iocb, inode, I_BDEV(inode), iter,
-				    offset, blkdev_get_block,
-				    NULL, NULL, 0);
+	return __blockdev_direct_IO(iocb, inode, I_BDEV(inode), iter, offset,
+				    blkdev_get_block, NULL, NULL, 0);
 }
 
 int __sync_blockdev(struct block_device *bdev, int wait)

commit 5d5d568975307877e9195f5305f4240e506a2807
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Apr 3 15:41:18 2015 -0400

    make new_sync_{read,write}() static
    
    All places outside of core VFS that checked ->read and ->write for being NULL or
    called the methods directly are gone now, so NULL {read,write} with non-NULL
    {read,write}_iter will do the right thing in all cases.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2e522aed6584..b5e87896f517 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1659,8 +1659,6 @@ const struct file_operations def_blk_fops = {
 	.open		= blkdev_open,
 	.release	= blkdev_close,
 	.llseek		= block_llseek,
-	.read		= new_sync_read,
-	.write		= new_sync_write,
 	.read_iter	= blkdev_read_iter,
 	.write_iter	= blkdev_write_iter,
 	.mmap		= generic_file_mmap,

commit e2e40f2c1ed433c5e224525c8c862fd32e5d3df2
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Feb 22 08:58:50 2015 -0800

    fs: move struct kiocb to fs.h
    
    struct kiocb now is a generic I/O container, so move it to fs.h.
    Also do a #include diet for aio.h while we're at it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 975266be67d3..2e522aed6584 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -27,7 +27,6 @@
 #include <linux/namei.h>
 #include <linux/log2.h>
 #include <linux/cleancache.h>
-#include <linux/aio.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 

commit 3e12cefbe143b4947171ff92dd50024c4841e291
Merge: 6bec00352861 d427e3c82ef4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 12 14:13:23 2015 -0800

    Merge branch 'for-3.20/core' of git://git.kernel.dk/linux-block
    
    Pull core block IO changes from Jens Axboe:
     "This contains:
    
       - A series from Christoph that cleans up and refactors various parts
         of the REQ_BLOCK_PC handling.  Contributions in that series from
         Dongsu Park and Kent Overstreet as well.
    
       - CFQ:
            - A bug fix for cfq for realtime IO scheduling from Jeff Moyer.
            - A stable patch fixing a potential crash in CFQ in OOM
              situations.  From Konstantin Khlebnikov.
    
       - blk-mq:
            - Add support for tag allocation policies, from Shaohua. This is
              a prep patch enabling libata (and other SCSI parts) to use the
              blk-mq tagging, instead of rolling their own.
            - Various little tweaks from Keith and Mike, in preparation for
              DM blk-mq support.
            - Minor little fixes or tweaks from me.
            - A double free error fix from Tony Battersby.
    
       - The partition 4k issue fixes from Matthew and Boaz.
    
       - Add support for zero+unprovision for blkdev_issue_zeroout() from
         Martin"
    
    * 'for-3.20/core' of git://git.kernel.dk/linux-block: (27 commits)
      block: remove unused function blk_bio_map_sg
      block: handle the null_mapped flag correctly in blk_rq_map_user_iov
      blk-mq: fix double-free in error path
      block: prevent request-to-request merging with gaps if not allowed
      blk-mq: make blk_mq_run_queues() static
      dm: fix multipath regression due to initializing wrong request
      cfq-iosched: handle failure of cfq group allocation
      block: Quiesce zeroout wrapper
      block: rewrite and split __bio_copy_iov()
      block: merge __bio_map_user_iov into bio_map_user_iov
      block: merge __bio_map_kern into bio_map_kern
      block: pass iov_iter to the BLOCK_PC mapping functions
      block: add a helper to free bio bounce buffer pages
      block: use blk_rq_map_user_iov to implement blk_rq_map_user
      block: simplify bio_map_kern
      block: mark blk-mq devices as stackable
      block: keep established cmd_flags when cloning into a blk-mq request
      block: add blk-mq support to blk_insert_cloned_request()
      block: require blk_rq_prep_clone() be given an initialized clone request
      blk-mq: add tag allocation policy
      ...

commit b83ae6d421435c6204150300f1c25bfbd39cd62b
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 14 10:42:37 2015 +0100

    fs: remove mapping->backing_dev_info
    
    Now that we never use the backing_dev_info pointer in struct address_space
    we can simply remove it and save 4 to 8 bytes in every inode.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 026ca7b8431c..a9f92794d7a0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -60,19 +60,6 @@ static void bdev_write_inode(struct inode *inode)
 	spin_unlock(&inode->i_lock);
 }
 
-/*
- * Move the inode from its current bdi to a new bdi.  Make sure the inode
- * is clean before moving so that it doesn't linger on the old bdi.
- */
-static void bdev_inode_switch_bdi(struct inode *inode,
-			struct backing_dev_info *dst)
-{
-	spin_lock(&inode->i_lock);
-	WARN_ON_ONCE(inode->i_state & I_DIRTY);
-	inode->i_data.backing_dev_info = dst;
-	spin_unlock(&inode->i_lock);
-}
-
 /* Kill _all_ buffers and pagecache , dirty or not.. */
 void kill_bdev(struct block_device *bdev)
 {
@@ -589,7 +576,6 @@ struct block_device *bdget(dev_t dev)
 		inode->i_bdev = bdev;
 		inode->i_data.a_ops = &def_blk_aops;
 		mapping_set_gfp_mask(&inode->i_data, GFP_USER);
-		inode->i_data.backing_dev_info = &default_backing_dev_info;
 		spin_lock(&bdev_lock);
 		list_add(&bdev->bd_list, &all_bdevs);
 		spin_unlock(&bdev_lock);
@@ -1150,8 +1136,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
 		if (!partno) {
-			struct backing_dev_info *bdi;
-
 			ret = -ENXIO;
 			bdev->bd_part = disk_get_part(disk, partno);
 			if (!bdev->bd_part)
@@ -1177,11 +1161,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				}
 			}
 
-			if (!ret) {
+			if (!ret)
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
-				bdi = blk_get_backing_dev_info(bdev);
-				bdev_inode_switch_bdi(bdev->bd_inode, bdi);
-			}
 
 			/*
 			 * If the device is invalidated, rescan partition
@@ -1208,8 +1189,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (ret)
 				goto out_clear;
 			bdev->bd_contains = whole;
-			bdev_inode_switch_bdi(bdev->bd_inode,
-				whole->bd_inode->i_data.backing_dev_info);
 			bdev->bd_part = disk_get_part(disk, partno);
 			if (!(disk->flags & GENHD_FL_UP) ||
 			    !bdev->bd_part || !bdev->bd_part->nr_sects) {
@@ -1249,7 +1228,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	bdev->bd_disk = NULL;
 	bdev->bd_part = NULL;
 	bdev->bd_queue = NULL;
-	bdev_inode_switch_bdi(bdev->bd_inode, &default_backing_dev_info);
 	if (bdev != bdev->bd_contains)
 		__blkdev_put(bdev->bd_contains, mode, 1);
 	bdev->bd_contains = NULL;
@@ -1474,8 +1452,6 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		 * dirty data before.
 		 */
 		bdev_write_inode(bdev->bd_inode);
-		bdev_inode_switch_bdi(bdev->bd_inode,
-					&default_backing_dev_info);
 	}
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)

commit 564f00f6c03a9339c259eb71a5b3aa8ef7ff1c2e
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 14 10:42:33 2015 +0100

    block_dev: only write bdev inode on close
    
    Since 018a17bdc865 ("bdi: reimplement bdev_inode_switch_bdi()") the
    block device code writes out all dirty data whenever switching the
    backing_dev_info for a block device inode.  But a block device inode can
    only be dirtied when it is in use, which means we only have to write it
    out on the final blkdev_put, but not when doing a blkdev_get.
    
    Factoring out the write out from the bdi list switch prepares from
    removing the list switch later in the series.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b48c41bf0f86..026ca7b8431c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -49,6 +49,17 @@ inline struct block_device *I_BDEV(struct inode *inode)
 }
 EXPORT_SYMBOL(I_BDEV);
 
+static void bdev_write_inode(struct inode *inode)
+{
+	spin_lock(&inode->i_lock);
+	while (inode->i_state & I_DIRTY) {
+		spin_unlock(&inode->i_lock);
+		WARN_ON_ONCE(write_inode_now(inode, true));
+		spin_lock(&inode->i_lock);
+	}
+	spin_unlock(&inode->i_lock);
+}
+
 /*
  * Move the inode from its current bdi to a new bdi.  Make sure the inode
  * is clean before moving so that it doesn't linger on the old bdi.
@@ -56,16 +67,10 @@ EXPORT_SYMBOL(I_BDEV);
 static void bdev_inode_switch_bdi(struct inode *inode,
 			struct backing_dev_info *dst)
 {
-	while (true) {
-		spin_lock(&inode->i_lock);
-		if (!(inode->i_state & I_DIRTY)) {
-			inode->i_data.backing_dev_info = dst;
-			spin_unlock(&inode->i_lock);
-			return;
-		}
-		spin_unlock(&inode->i_lock);
-		WARN_ON_ONCE(write_inode_now(inode, true));
-	}
+	spin_lock(&inode->i_lock);
+	WARN_ON_ONCE(inode->i_state & I_DIRTY);
+	inode->i_data.backing_dev_info = dst;
+	spin_unlock(&inode->i_lock);
 }
 
 /* Kill _all_ buffers and pagecache , dirty or not.. */
@@ -1464,9 +1469,11 @@ static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		WARN_ON_ONCE(bdev->bd_holders);
 		sync_blockdev(bdev);
 		kill_bdev(bdev);
-		/* ->release can cause the old bdi to disappear,
-		 * so must switch it out first
+		/*
+		 * ->release can cause the queue to disappear, so flush all
+		 * dirty data before.
 		 */
+		bdev_write_inode(bdev->bd_inode);
 		bdev_inode_switch_bdi(bdev->bd_inode,
 					&default_backing_dev_info);
 	}

commit dd22f551ac0ad366f92f601835f6623b83adc331
Author: Matthew Wilcox <matthew.r.wilcox@intel.com>
Date:   Wed Jan 7 18:05:34 2015 +0200

    block: Change direct_access calling convention
    
    In order to support accesses to larger chunks of memory, pass in a
    'size' parameter (counted in bytes), and return the amount available at
    that address.
    
    Add a new helper function, bdev_direct_access(), to handle common
    functionality including partition handling, checking the length requested
    is positive, checking for the sector being page-aligned, and checking
    the length of the request does not pass the end of the partition.
    
    Signed-off-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Boaz Harrosh <boaz@plexistor.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b48c41bf0f86..f314c2c0567d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -429,6 +429,46 @@ int bdev_write_page(struct block_device *bdev, sector_t sector,
 }
 EXPORT_SYMBOL_GPL(bdev_write_page);
 
+/**
+ * bdev_direct_access() - Get the address for directly-accessibly memory
+ * @bdev: The device containing the memory
+ * @sector: The offset within the device
+ * @addr: Where to put the address of the memory
+ * @pfn: The Page Frame Number for the memory
+ * @size: The number of bytes requested
+ *
+ * If a block device is made up of directly addressable memory, this function
+ * will tell the caller the PFN and the address of the memory.  The address
+ * may be directly dereferenced within the kernel without the need to call
+ * ioremap(), kmap() or similar.  The PFN is suitable for inserting into
+ * page tables.
+ *
+ * Return: negative errno if an error occurs, otherwise the number of bytes
+ * accessible at this address.
+ */
+long bdev_direct_access(struct block_device *bdev, sector_t sector,
+			void **addr, unsigned long *pfn, long size)
+{
+	long avail;
+	const struct block_device_operations *ops = bdev->bd_disk->fops;
+
+	if (size < 0)
+		return size;
+	if (!ops->direct_access)
+		return -EOPNOTSUPP;
+	if ((sector + DIV_ROUND_UP(size, 512)) >
+					part_nr_sects_read(bdev->bd_part))
+		return -ERANGE;
+	sector += get_start_sect(bdev);
+	if (sector % (PAGE_SIZE / 512))
+		return -EINVAL;
+	avail = ops->direct_access(bdev, sector, addr, pfn, size);
+	if (!avail)
+		return -ERANGE;
+	return min(avail, size);
+}
+EXPORT_SYMBOL_GPL(bdev_direct_access);
+
 /*
  * pseudo-fs
  */

commit 48b6bca6b7b8309697fc8a101793befe92d249d9
Author: Benjamin Marzinski <bmarzins@redhat.com>
Date:   Thu Nov 13 20:42:03 2014 -0600

    fs: add freeze_super/thaw_super fs hooks
    
    Currently, freezing a filesystem involves calling freeze_super, which locks
    sb->s_umount and then calls the fs-specific freeze_fs hook. This makes it
    hard for gfs2 (and potentially other cluster filesystems) to use the vfs
    freezing code to do freezes on all the cluster nodes.
    
    In order to communicate that a freeze has been requested, and to make sure
    that only one node is trying to freeze at a time, gfs2 uses a glock
    (sd_freeze_gl). The problem is that there is no hook for gfs2 to acquire
    this lock before calling freeze_super. This means that two nodes can
    attempt to freeze the filesystem by both calling freeze_super, acquiring
    the sb->s_umount lock, and then attempting to grab the cluster glock
    sd_freeze_gl. Only one will succeed, and the other will be stuck in
    freeze_super, making it impossible to finish freezing the node.
    
    To solve this problem, this patch adds the freeze_super and thaw_super
    hooks.  If a filesystem implements these hooks, they are called instead of
    the vfs freeze_super and thaw_super functions. This means that every
    filesystem that implements these hooks must call the vfs freeze_super and
    thaw_super functions itself within the hook function to make use of the vfs
    freezing code.
    
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Benjamin Marzinski <bmarzins@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1d9c9f3754f8..b48c41bf0f86 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -235,7 +235,10 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 	sb = get_active_super(bdev);
 	if (!sb)
 		goto out;
-	error = freeze_super(sb);
+	if (sb->s_op->freeze_super)
+		error = sb->s_op->freeze_super(sb);
+	else
+		error = freeze_super(sb);
 	if (error) {
 		deactivate_super(sb);
 		bdev->bd_fsfreeze_count--;
@@ -272,7 +275,10 @@ int thaw_bdev(struct block_device *bdev, struct super_block *sb)
 	if (!sb)
 		goto out;
 
-	error = thaw_super(sb);
+	if (sb->s_op->thaw_super)
+		error = sb->s_op->thaw_super(sb);
+	else
+		error = thaw_super(sb);
 	if (error) {
 		bdev->bd_fsfreeze_count++;
 		mutex_unlock(&bdev->bd_fsfreeze_mutex);

commit b2de525f095708b2adbadaec3f1e4017a23d1e09
Author: David Jeffery <djeffery@redhat.com>
Date:   Mon Sep 29 10:21:10 2014 -0400

    Return short read or 0 at end of a raw device, not EIO
    
    Author: David Jeffery <djeffery@redhat.com>
    Changes to the basic direct I/O code have broken the raw driver when reading
    to the end of a raw device.  Instead of returning a short read for a read that
    extends partially beyond the device's end or 0 when at the end of the device,
    these reads now return EIO.
    
    The raw driver needs the same end of device handling as was added for normal
    block devices.  Using blkdev_read_iter, which has the needed size checks,
    prevents the EIO conditions at the end of the device.
    
    Signed-off-by: David Jeffery <djeffery@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index cc9d4114cda0..1d9c9f3754f8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1585,7 +1585,7 @@ ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 }
 EXPORT_SYMBOL_GPL(blkdev_write_iter);
 
-static ssize_t blkdev_read_iter(struct kiocb *iocb, struct iov_iter *to)
+ssize_t blkdev_read_iter(struct kiocb *iocb, struct iov_iter *to)
 {
 	struct file *file = iocb->ki_filp;
 	struct inode *bd_inode = file->f_mapping->host;
@@ -1599,6 +1599,7 @@ static ssize_t blkdev_read_iter(struct kiocb *iocb, struct iov_iter *to)
 	iov_iter_truncate(to, size);
 	return generic_file_read_iter(iocb, to);
 }
+EXPORT_SYMBOL_GPL(blkdev_read_iter);
 
 /*
  * Try to release a page associated with block device when the system

commit d3dc366bbaf07c125561e90d6da4bb147741101a
Merge: 511c41d9e666 e19a8a0ad2d2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Oct 18 11:53:51 2014 -0700

    Merge branch 'for-3.18/core' of git://git.kernel.dk/linux-block
    
    Pull core block layer changes from Jens Axboe:
     "This is the core block IO pull request for 3.18.  Apart from the new
      and improved flush machinery for blk-mq, this is all mostly bug fixes
      and cleanups.
    
       - blk-mq timeout updates and fixes from Christoph.
    
       - Removal of REQ_END, also from Christoph.  We pass it through the
         ->queue_rq() hook for blk-mq instead, freeing up one of the request
         bits.  The space was overly tight on 32-bit, so Martin also killed
         REQ_KERNEL since it's no longer used.
    
       - blk integrity updates and fixes from Martin and Gu Zheng.
    
       - Update to the flush machinery for blk-mq from Ming Lei.  Now we
         have a per hardware context flush request, which both cleans up the
         code should scale better for flush intensive workloads on blk-mq.
    
       - Improve the error printing, from Rob Elliott.
    
       - Backing device improvements and cleanups from Tejun.
    
       - Fixup of a misplaced rq_complete() tracepoint from Hannes.
    
       - Make blk_get_request() return error pointers, fixing up issues
         where we NULL deref when a device goes bad or missing.  From Joe
         Lawrence.
    
       - Prep work for drastically reducing the memory consumption of dm
         devices from Junichi Nomura.  This allows creating clone bio sets
         without preallocating a lot of memory.
    
       - Fix a blk-mq hang on certain combinations of queue depths and
         hardware queues from me.
    
       - Limit memory consumption for blk-mq devices for crash dump
         scenarios and drivers that use crazy high depths (certain SCSI
         shared tag setups).  We now just use a single queue and limited
         depth for that"
    
    * 'for-3.18/core' of git://git.kernel.dk/linux-block: (58 commits)
      block: Remove REQ_KERNEL
      blk-mq: allocate cpumask on the home node
      bio-integrity: remove the needless fail handle of bip_slab creating
      block: include func name in __get_request prints
      block: make blk_update_request print prefix match ratelimited prefix
      blk-merge: don't compute bi_phys_segments from bi_vcnt for cloned bio
      block: fix alignment_offset math that assumes io_min is a power-of-2
      blk-mq: Make bt_clear_tag() easier to read
      blk-mq: fix potential hang if rolling wakeup depth is too high
      block: add bioset_create_nobvec()
      block: use bio_clone_fast() in blk_rq_prep_clone()
      block: misplaced rq_complete tracepoint
      sd: Honor block layer integrity handling flags
      block: Replace strnicmp with strncasecmp
      block: Add T10 Protection Information functions
      block: Don't merge requests if integrity flags differ
      block: Integrity checksum flag
      block: Relocate bio integrity flags
      block: Add a disk flag to block integrity profile
      block: Add prefix to block integrity profile flags
      ...

commit 447f05bb488bff4282088259b04f47f0f9f76760
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Thu Oct 9 15:26:58 2014 -0700

    block_dev: implement readpages() to optimize sequential read
    
    Sequential read from a block device is expected to be equal or faster than
    from the file on a filesystem.  But it is not correct due to the lack of
    effective readpages() in the address space operations for block device.
    
    This implements readpages() operation for block device by using
    mpage_readpages() which can create multipage BIOs instead of BIOs for each
    page and reduce system CPU time consumption.
    
    Install 1GB of RAM disk storage:
    
            # modprobe scsi_debug dev_size_mb=1024 delay=0
    
    Sequential read from file on a filesystem:
    
            # mkfs.ext4 /dev/$DEV
            # mount /dev/$DEV /mnt
            # fio --name=t --size=512m --rw=read --filename=/mnt/file
            ...
              read : io=524288KB, bw=2133.4MB/s, iops=546133, runt=   240msec
    
    Sequential read from a block device:
            # fio --name=t --size=512m --rw=read --filename=/dev/$DEV
            ...
    (Without this commit)
              read : io=524288KB, bw=1700.2MB/s, iops=435455, runt=   301msec
    
    (With this commit)
              read : io=524288KB, bw=2160.4MB/s, iops=553046, runt=   237msec
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 6d7274619bf9..e2f3ad0879ce 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -304,6 +304,12 @@ static int blkdev_readpage(struct file * file, struct page * page)
 	return block_read_full_page(page, blkdev_get_block);
 }
 
+static int blkdev_readpages(struct file *file, struct address_space *mapping,
+			struct list_head *pages, unsigned nr_pages)
+{
+	return mpage_readpages(mapping, pages, nr_pages, blkdev_get_block);
+}
+
 static int blkdev_write_begin(struct file *file, struct address_space *mapping,
 			loff_t pos, unsigned len, unsigned flags,
 			struct page **pagep, void **fsdata)
@@ -1622,6 +1628,7 @@ static int blkdev_releasepage(struct page *page, gfp_t wait)
 
 static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
+	.readpages	= blkdev_readpages,
 	.writepage	= blkdev_writepage,
 	.write_begin	= blkdev_write_begin,
 	.write_end	= blkdev_write_end,

commit 018a17bdc8658ad448497c84d4ba21b6985820ec
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 8 08:04:01 2014 +0900

    bdi: reimplement bdev_inode_switch_bdi()
    
    A block_device may be attached to different gendisks and thus
    different bdis over time.  bdev_inode_switch_bdi() is used to switch
    the associated bdi.  The function assumes that the inode could be
    dirty and transfers it between bdis if so.  This is a bit nasty in
    that it reaches into bdi internals.
    
    This patch reimplements the function so that it writes out the inode
    if dirty.  This is a lot simpler and can be implemented without
    exposing bdi internals.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d3251eca6429..cc8d68ac29aa 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -50,32 +50,22 @@ inline struct block_device *I_BDEV(struct inode *inode)
 EXPORT_SYMBOL(I_BDEV);
 
 /*
- * Move the inode from its current bdi to a new bdi. If the inode is dirty we
- * need to move it onto the dirty list of @dst so that the inode is always on
- * the right list.
+ * Move the inode from its current bdi to a new bdi.  Make sure the inode
+ * is clean before moving so that it doesn't linger on the old bdi.
  */
 static void bdev_inode_switch_bdi(struct inode *inode,
 			struct backing_dev_info *dst)
 {
-	struct backing_dev_info *old = inode->i_data.backing_dev_info;
-	bool wakeup_bdi = false;
-
-	if (unlikely(dst == old))		/* deadlock avoidance */
-		return;
-	bdi_lock_two(&old->wb, &dst->wb);
-	spin_lock(&inode->i_lock);
-	inode->i_data.backing_dev_info = dst;
-	if (inode->i_state & I_DIRTY) {
-		if (bdi_cap_writeback_dirty(dst) && !wb_has_dirty_io(&dst->wb))
-			wakeup_bdi = true;
-		list_move(&inode->i_wb_list, &dst->wb.b_dirty);
+	while (true) {
+		spin_lock(&inode->i_lock);
+		if (!(inode->i_state & I_DIRTY)) {
+			inode->i_data.backing_dev_info = dst;
+			spin_unlock(&inode->i_lock);
+			return;
+		}
+		spin_unlock(&inode->i_lock);
+		WARN_ON_ONCE(write_inode_now(inode, true));
 	}
-	spin_unlock(&inode->i_lock);
-	spin_unlock(&old->wb.list_lock);
-	spin_unlock(&dst->wb.list_lock);
-
-	if (wakeup_bdi)
-		bdi_wakeup_thread_delayed(dst);
 }
 
 /* Kill _all_ buffers and pagecache , dirty or not.. */

commit ff9ea323816dc1c8ac7144afd4eab3ac97704430
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 8 08:03:56 2014 +0900

    block, bdi: an active gendisk always has a request_queue associated with it
    
    bdev_get_queue() returns the request_queue associated with the
    specified block_device.  blk_get_backing_dev_info() makes use of
    bdev_get_queue() to determine the associated bdi given a block_device.
    
    All the callers of bdev_get_queue() including
    blk_get_backing_dev_info() assume that bdev_get_queue() may return
    NULL and implement NULL handling; however, bdev_get_queue() requires
    the passed in block_device is opened and attached to its gendisk.
    Because an active gendisk always has a valid request_queue associated
    with it, bdev_get_queue() can never return NULL and neither can
    blk_get_backing_dev_info().
    
    Make it clear that neither of the two functions can return NULL and
    remove NULL handling from all the callers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Chris Mason <clm@fb.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 6d7274619bf9..d3251eca6429 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1173,8 +1173,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (!ret) {
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
 				bdi = blk_get_backing_dev_info(bdev);
-				if (bdi == NULL)
-					bdi = &default_backing_dev_info;
 				bdev_inode_switch_bdi(bdev->bd_inode, bdi);
 			}
 

commit 16b9057804c02e2d351e9c8f606e909b43cbd9e7
Merge: 5c02c392cd23 c2338f2dc7c1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 12 10:30:18 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "This the bunch that sat in -next + lock_parent() fix.  This is the
      minimal set; there's more pending stuff.
    
      In particular, I really hope to get acct.c fixes merged this cycle -
      we need that to deal sanely with delayed-mntput stuff.  In the next
      pile, hopefully - that series is fairly short and localized
      (kernel/acct.c, fs/super.c and fs/namespace.c).  In this pile: more
      iov_iter work.  Most of prereqs for ->splice_write with sane locking
      order are there and Kent's dio rewrite would also fit nicely on top of
      this pile"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (70 commits)
      lock_parent: don't step on stale ->d_parent of all-but-freed one
      kill generic_file_splice_write()
      ceph: switch to iter_file_splice_write()
      shmem: switch to iter_file_splice_write()
      nfs: switch to iter_splice_write_file()
      fs/splice.c: remove unneeded exports
      ocfs2: switch to iter_file_splice_write()
      ->splice_write() via ->write_iter()
      bio_vec-backed iov_iter
      optimize copy_page_{to,from}_iter()
      bury generic_file_aio_{read,write}
      lustre: get rid of messing with iovecs
      ceph: switch to ->write_iter()
      ceph_sync_direct_write: stop poking into iov_iter guts
      ceph_sync_read: stop poking into iov_iter guts
      new helper: copy_page_from_iter()
      fuse: switch to ->write_iter()
      btrfs: switch to ->write_iter()
      ocfs2: switch to ->write_iter()
      xfs: switch to ->write_iter()
      ...

commit 8d0207652cbe27d1f962050737848e5ad4671958
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Apr 5 04:27:08 2014 -0400

    ->splice_write() via ->write_iter()
    
    iter_file_splice_write() - a ->splice_write() instance that gathers the
    pipe buffers, builds a bio_vec-based iov_iter covering those and feeds
    it to ->write_iter().  A bunch of simple cases coverted to that...
    
    [AV: fixed the braino spotted by Cyrill]
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4e36b8ea8aa4..e68e150b1b16 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1583,7 +1583,7 @@ const struct file_operations def_blk_fops = {
 	.compat_ioctl	= compat_blkdev_ioctl,
 #endif
 	.splice_read	= generic_file_splice_read,
-	.splice_write	= generic_file_splice_write,
+	.splice_write	= iter_file_splice_write,
 };
 
 int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)

commit 47a191fd38ebddb1bd1510ec2bc1085c578c8868
Author: Matthew Wilcox <matthew.r.wilcox@intel.com>
Date:   Wed Jun 4 16:07:46 2014 -0700

    fs/block_dev.c: add bdev_read_page() and bdev_write_page()
    
    A block device driver may choose to provide a rw_page operation.  These
    will be called when the filesystem is attempting to do page sized I/O to
    page cache pages (ie not for direct I/O).  This does preclude I/Os that
    are larger than page size, so this may only be a performance gain for
    some devices.
    
    Signed-off-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Tested-by: Dheeraj Reddy <dheeraj.reddy@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 552a8d13bc32..83fba15cc394 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -363,6 +363,69 @@ int blkdev_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 }
 EXPORT_SYMBOL(blkdev_fsync);
 
+/**
+ * bdev_read_page() - Start reading a page from a block device
+ * @bdev: The device to read the page from
+ * @sector: The offset on the device to read the page to (need not be aligned)
+ * @page: The page to read
+ *
+ * On entry, the page should be locked.  It will be unlocked when the page
+ * has been read.  If the block driver implements rw_page synchronously,
+ * that will be true on exit from this function, but it need not be.
+ *
+ * Errors returned by this function are usually "soft", eg out of memory, or
+ * queue full; callers should try a different route to read this page rather
+ * than propagate an error back up the stack.
+ *
+ * Return: negative errno if an error occurs, 0 if submission was successful.
+ */
+int bdev_read_page(struct block_device *bdev, sector_t sector,
+			struct page *page)
+{
+	const struct block_device_operations *ops = bdev->bd_disk->fops;
+	if (!ops->rw_page)
+		return -EOPNOTSUPP;
+	return ops->rw_page(bdev, sector + get_start_sect(bdev), page, READ);
+}
+EXPORT_SYMBOL_GPL(bdev_read_page);
+
+/**
+ * bdev_write_page() - Start writing a page to a block device
+ * @bdev: The device to write the page to
+ * @sector: The offset on the device to write the page to (need not be aligned)
+ * @page: The page to write
+ * @wbc: The writeback_control for the write
+ *
+ * On entry, the page should be locked and not currently under writeback.
+ * On exit, if the write started successfully, the page will be unlocked and
+ * under writeback.  If the write failed already (eg the driver failed to
+ * queue the page to the device), the page will still be locked.  If the
+ * caller is a ->writepage implementation, it will need to unlock the page.
+ *
+ * Errors returned by this function are usually "soft", eg out of memory, or
+ * queue full; callers should try a different route to write this page rather
+ * than propagate an error back up the stack.
+ *
+ * Return: negative errno if an error occurs, 0 if submission was successful.
+ */
+int bdev_write_page(struct block_device *bdev, sector_t sector,
+			struct page *page, struct writeback_control *wbc)
+{
+	int result;
+	int rw = (wbc->sync_mode == WB_SYNC_ALL) ? WRITE_SYNC : WRITE;
+	const struct block_device_operations *ops = bdev->bd_disk->fops;
+	if (!ops->rw_page)
+		return -EOPNOTSUPP;
+	set_page_writeback(page);
+	result = ops->rw_page(bdev, sector + get_start_sect(bdev), page, rw);
+	if (result)
+		end_page_writeback(page);
+	else
+		unlock_page(page);
+	return result;
+}
+EXPORT_SYMBOL_GPL(bdev_write_page);
+
 /*
  * pseudo-fs
  */

commit 1456c0a87c4241d3a801651019e66983c69ad17d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Apr 3 03:21:50 2014 -0400

    blkdev_aio_write() - turn into blkdev_write_iter()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 3d97f4a257ff..4e36b8ea8aa4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1509,28 +1509,24 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
  * Does not take i_mutex for the write and thus is not for general purpose
  * use.
  */
-ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
-			 unsigned long nr_segs, loff_t pos)
+ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from)
 {
 	struct file *file = iocb->ki_filp;
 	struct blk_plug plug;
 	ssize_t ret;
 
-	BUG_ON(iocb->ki_pos != pos);
-
 	blk_start_plug(&plug);
-	ret = __generic_file_aio_write(iocb, iov, nr_segs);
+	ret = __generic_file_write_iter(iocb, from);
 	if (ret > 0) {
 		ssize_t err;
-
-		err = generic_write_sync(file, pos, ret);
+		err = generic_write_sync(file, iocb->ki_pos - ret, ret);
 		if (err < 0)
 			ret = err;
 	}
 	blk_finish_plug(&plug);
 	return ret;
 }
-EXPORT_SYMBOL_GPL(blkdev_aio_write);
+EXPORT_SYMBOL_GPL(blkdev_write_iter);
 
 static ssize_t blkdev_read_iter(struct kiocb *iocb, struct iov_iter *to)
 {
@@ -1577,9 +1573,9 @@ const struct file_operations def_blk_fops = {
 	.release	= blkdev_close,
 	.llseek		= block_llseek,
 	.read		= new_sync_read,
-	.write		= do_sync_write,
+	.write		= new_sync_write,
 	.read_iter	= blkdev_read_iter,
-	.aio_write	= blkdev_aio_write,
+	.write_iter	= blkdev_write_iter,
 	.mmap		= generic_file_mmap,
 	.fsync		= blkdev_fsync,
 	.unlocked_ioctl	= block_ioctl,

commit a886038baa48a17f2cf77fb5dcc204fd28659d8f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 2 20:02:21 2014 -0400

    fs/block_dev.c: switch to ->read_iter()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b140badb8184..3d97f4a257ff 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1532,23 +1532,19 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 }
 EXPORT_SYMBOL_GPL(blkdev_aio_write);
 
-static ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
-			 unsigned long nr_segs, loff_t pos)
+static ssize_t blkdev_read_iter(struct kiocb *iocb, struct iov_iter *to)
 {
 	struct file *file = iocb->ki_filp;
 	struct inode *bd_inode = file->f_mapping->host;
 	loff_t size = i_size_read(bd_inode);
-	size_t count = iocb->ki_nbytes;
-	struct iov_iter to;
-
-	iov_iter_init(&to, READ, iov, nr_segs, count);
+	loff_t pos = iocb->ki_pos;
 
 	if (pos >= size)
 		return 0;
 
 	size -= pos;
-	iov_iter_truncate(&to, size);
-	return generic_file_read_iter(iocb, &to);
+	iov_iter_truncate(to, size);
+	return generic_file_read_iter(iocb, to);
 }
 
 /*
@@ -1580,9 +1576,9 @@ const struct file_operations def_blk_fops = {
 	.open		= blkdev_open,
 	.release	= blkdev_close,
 	.llseek		= block_llseek,
-	.read		= do_sync_read,
+	.read		= new_sync_read,
 	.write		= do_sync_write,
-	.aio_read	= blkdev_aio_read,
+	.read_iter	= blkdev_read_iter,
 	.aio_write	= blkdev_aio_write,
 	.mmap		= generic_file_mmap,
 	.fsync		= blkdev_fsync,

commit 37938463540b075e9166cf774c59274379f7a8ca
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 22 06:57:37 2014 -0400

    blkdev_aio_read(): switch to generic_file_read_iter(), get rid of iov_shorten()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 937e3011ed58..b140badb8184 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1538,14 +1538,17 @@ static ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
 	struct file *file = iocb->ki_filp;
 	struct inode *bd_inode = file->f_mapping->host;
 	loff_t size = i_size_read(bd_inode);
+	size_t count = iocb->ki_nbytes;
+	struct iov_iter to;
+
+	iov_iter_init(&to, READ, iov, nr_segs, count);
 
 	if (pos >= size)
 		return 0;
 
 	size -= pos;
-	if (size < iocb->ki_nbytes)
-		nr_segs = iov_shorten((struct iovec *)iov, nr_segs, size);
-	return generic_file_aio_read(iocb, iov, nr_segs, pos);
+	iov_iter_truncate(&to, size);
+	return generic_file_read_iter(iocb, &to);
 }
 
 /*

commit 31b140398ce56ab41646eda7f02bcb78d6a4c916
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Mar 5 01:33:16 2014 -0500

    switch {__,}blockdev_direct_IO() to iov_iter
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 938fc707d769..937e3011ed58 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -171,8 +171,8 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, struct iov_iter *iter,
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = file->f_mapping->host;
 
-	return __blockdev_direct_IO(rw, iocb, inode, I_BDEV(inode), iter->iov,
-				    offset, iter->nr_segs, blkdev_get_block,
+	return __blockdev_direct_IO(rw, iocb, inode, I_BDEV(inode), iter,
+				    offset, blkdev_get_block,
 				    NULL, NULL, 0);
 }
 

commit d8d3d94b80aa1a1c0ca75c58b8abdc7356f38418
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Mar 4 21:27:34 2014 -0500

    pass iov_iter to ->direct_IO()
    
    unmodified, for now
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 552a8d13bc32..938fc707d769 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -165,14 +165,15 @@ blkdev_get_block(struct inode *inode, sector_t iblock,
 }
 
 static ssize_t
-blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
-			loff_t offset, unsigned long nr_segs)
+blkdev_direct_IO(int rw, struct kiocb *iocb, struct iov_iter *iter,
+			loff_t offset)
 {
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = file->f_mapping->host;
 
-	return __blockdev_direct_IO(rw, iocb, inode, I_BDEV(inode), iov, offset,
-				    nr_segs, blkdev_get_block, NULL, NULL, 0);
+	return __blockdev_direct_IO(rw, iocb, inode, I_BDEV(inode), iter->iov,
+				    offset, iter->nr_segs, blkdev_get_block,
+				    NULL, NULL, 0);
 }
 
 int __sync_blockdev(struct block_device *bdev, int wait)

commit 5166701b368caea89d57b14bf41cf39e819dad51
Merge: 0a7418f5f569 a786c06d9f27
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 12 14:49:50 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "The first vfs pile, with deep apologies for being very late in this
      window.
    
      Assorted cleanups and fixes, plus a large preparatory part of iov_iter
      work.  There's a lot more of that, but it'll probably go into the next
      merge window - it *does* shape up nicely, removes a lot of
      boilerplate, gets rid of locking inconsistencie between aio_write and
      splice_write and I hope to get Kent's direct-io rewrite merged into
      the same queue, but some of the stuff after this point is having
      (mostly trivial) conflicts with the things already merged into
      mainline and with some I want more testing.
    
      This one passes LTP and xfstests without regressions, in addition to
      usual beating.  BTW, readahead02 in ltp syscalls testsuite has started
      giving failures since "mm/readahead.c: fix readahead failure for
      memoryless NUMA nodes and limit readahead pages" - might be a false
      positive, might be a real regression..."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (63 commits)
      missing bits of "splice: fix racy pipe->buffers uses"
      cifs: fix the race in cifs_writev()
      ceph_sync_{,direct_}write: fix an oops on ceph_osdc_new_request() failure
      kill generic_file_buffered_write()
      ocfs2_file_aio_write(): switch to generic_perform_write()
      ceph_aio_write(): switch to generic_perform_write()
      xfs_file_buffered_aio_write(): switch to generic_perform_write()
      export generic_perform_write(), start getting rid of generic_file_buffer_write()
      generic_file_direct_write(): get rid of ppos argument
      btrfs_file_aio_write(): get rid of ppos
      kill the 5th argument of generic_file_buffered_write()
      kill the 4th argument of __generic_file_aio_write()
      lustre: don't open-code kernel_recvmsg()
      ocfs2: don't open-code kernel_recvmsg()
      drbd: don't open-code kernel_recvmsg()
      constify blk_rq_map_user_iov() and friends
      lustre: switch to kernel_sendmsg()
      ocfs2: don't open-code kernel_sendmsg()
      take iov_iter stuff to mm/iov_iter.c
      process_vm_access: tidy up a bit
      ...

commit 91b0abe36a7b2b3b02d7500925a5f8455334f0e5
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Apr 3 14:47:49 2014 -0700

    mm + fs: store shadow entries in page cache
    
    Reclaim will be leaving shadow entries in the page cache radix tree upon
    evicting the real page.  As those pages are found from the LRU, an
    iput() can lead to the inode being freed concurrently.  At this point,
    reclaim must no longer install shadow pages because the inode freeing
    code needs to ensure the page tree is really empty.
    
    Add an address_space flag, AS_EXITING, that the inode freeing code sets
    under the tree lock before doing the final truncate.  Reclaim will check
    for this flag before installing shadow pages.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Reviewed-by: Minchan Kim <minchan@kernel.org>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bob Liu <bob.liu@oracle.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Metin Doslu <metin@citusdata.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Ozgun Erdogan <ozgun@citusdata.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roman Gushchin <klamm@yandex-team.ru>
    Cc: Ryan Mallon <rmallon@gmail.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e4cba21a627e..ba0d2b05bb78 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -83,7 +83,7 @@ void kill_bdev(struct block_device *bdev)
 {
 	struct address_space *mapping = bdev->bd_inode->i_mapping;
 
-	if (mapping->nrpages == 0)
+	if (mapping->nrpages == 0 && mapping->nrshadows == 0)
 		return;
 
 	invalidate_bh_lrus();
@@ -419,7 +419,7 @@ static void bdev_evict_inode(struct inode *inode)
 {
 	struct block_device *bdev = &BDEV_I(inode)->bdev;
 	struct list_head *p;
-	truncate_inode_pages(&inode->i_data, 0);
+	truncate_inode_pages_final(&inode->i_data);
 	invalidate_inode_buffers(inode); /* is it needed here? */
 	clear_inode(inode);
 	spin_lock(&bdev_lock);

commit 45d4f855046631d63dab8832ba8a8369ed8e04bd
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu Apr 3 14:47:17 2014 -0700

    fs/direct-io.c: remove some left over checks
    
    We know that "ret > 0" is true here.  These tests were left over from
    commit 02afc27faec9 ('direct-io: Handle O_(D)SYNC AIO') and aren't
    needed any more.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1e86823a9cbd..e4cba21a627e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1523,7 +1523,7 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 		ssize_t err;
 
 		err = generic_write_sync(file, pos, ret);
-		if (err < 0 && ret > 0)
+		if (err < 0)
 			ret = err;
 	}
 	blk_finish_plug(&plug);

commit 41fc56d573c35a212688b12b48af8c303f9bb6d2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Feb 9 12:58:52 2014 -0500

    kill the 4th argument of __generic_file_aio_write()
    
    It's always equal to &iocb->ki_pos, where iocb is the value of the 1st
    argument.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1e86823a9cbd..764bd3b8d2fa 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1518,7 +1518,7 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 	BUG_ON(iocb->ki_pos != pos);
 
 	blk_start_plug(&plug);
-	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
+	ret = __generic_file_aio_write(iocb, iov, nr_segs);
 	if (ret > 0) {
 		ssize_t err;
 

commit 3711d86a2de17e967b576af8b8a1e9351a7d1466
Merge: 89dc77bcdabf a8855990e382
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 13 23:06:40 2013 -0400

    Merge tag 'writeback-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/wfg/linux
    
    Pull writeback fix from Wu Fengguang:
     "A trivial writeback fix"
    
    * tag 'writeback-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/wfg/linux:
      writeback: Do not sort b_io list only because of block device inode

commit 9bf12df31f282e845b3dfaac1e5d5376a041da22
Merge: 399a946edbbe d9b2c8714aef
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 13 10:55:58 2013 -0700

    Merge git://git.kvack.org/~bcrl/aio-next
    
    Pull aio changes from Ben LaHaise:
     "First off, sorry for this pull request being late in the merge window.
      Al had raised a couple of concerns about 2 items in the series below.
      I addressed the first issue (the race introduced by Gu's use of
      mm_populate()), but he has not provided any further details on how he
      wants to rework the anon_inode.c changes (which were sent out months
      ago but have yet to be commented on).
    
      The bulk of the changes have been sitting in the -next tree for a few
      months, with all the issues raised being addressed"
    
    * git://git.kvack.org/~bcrl/aio-next: (22 commits)
      aio: rcu_read_lock protection for new rcu_dereference calls
      aio: fix race in ring buffer page lookup introduced by page migration support
      aio: fix rcu sparse warnings introduced by ioctx table lookup patch
      aio: remove unnecessary debugging from aio_free_ring()
      aio: table lookup: verify ctx pointer
      staging/lustre: kiocb->ki_left is removed
      aio: fix error handling and rcu usage in "convert the ioctx list to table lookup v3"
      aio: be defensive to ensure request batching is non-zero instead of BUG_ON()
      aio: convert the ioctx list to table lookup v3
      aio: double aio_max_nr in calculations
      aio: Kill ki_dtor
      aio: Kill ki_users
      aio: Kill unneeded kiocb members
      aio: Kill aio_rw_vect_retry()
      aio: Don't use ctx->tail unnecessarily
      aio: io_cancel() no longer returns the io_event
      aio: percpu ioctx refcount
      aio: percpu reqs_available
      aio: reqs_active -> reqs_available
      aio: fix build when migration is disabled
      ...

commit 02afc27faec94c9e068517a22acf55400976c698
Author: Christoph Hellwig <hch@infradead.org>
Date:   Wed Sep 4 15:04:40 2013 +0200

    direct-io: Handle O_(D)SYNC AIO
    
    Call generic_write_sync() from the deferred I/O completion handler if
    O_DSYNC is set for a write request.  Also make sure various callers
    don't call generic_write_sync if the direct I/O code returns
    -EIOCBQUEUED.
    
    Based on an earlier patch from Jan Kara <jack@suse.cz> with updates from
    Jeff Moyer <jmoyer@redhat.com> and Darrick J. Wong <darrick.wong@oracle.com>.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c7bda5cd3da7..1173a4ee0830 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1519,7 +1519,7 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 
 	blk_start_plug(&plug);
 	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
-	if (ret > 0 || ret == -EIOCBQUEUED) {
+	if (ret > 0) {
 		ssize_t err;
 
 		err = generic_write_sync(file, pos, ret);

commit 73a7075e3f6ec63dc359064eea6fd84f406cf2a5
Author: Kent Overstreet <koverstreet@google.com>
Date:   Thu May 9 15:03:42 2013 -0700

    aio: Kill aio_rw_vect_retry()
    
    This code doesn't serve any purpose anymore, since the aio retry
    infrastructure has been removed.
    
    This change should be safe because aio_read/write are also used for
    synchronous IO, and called from do_sync_read()/do_sync_write() - and
    there's no looping done in the sync case (the read and write syscalls).
    
    Signed-off-by: Kent Overstreet <koverstreet@google.com>
    Cc: Zach Brown <zab@redhat.com>
    Cc: Felipe Balbi <balbi@ti.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Benjamin LaHaise <bcrl@kvack.org>
    Signed-off-by: Benjamin LaHaise <bcrl@kvack.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c7bda5cd3da7..8772b155cb30 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1542,7 +1542,7 @@ static ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
 		return 0;
 
 	size -= pos;
-	if (size < iocb->ki_left)
+	if (size < iocb->ki_nbytes)
 		nr_segs = iov_shorten((struct iovec *)iov, nr_segs, size);
 	return generic_file_aio_read(iocb, iov, nr_segs, pos);
 }

commit 36805aaea5ae3cf1bb32f1643e0a800bb69f0d5b
Merge: 6d2fa9e141ea d50235b7bc3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 11 13:03:24 2013 -0700

    Merge branch 'for-3.11/core' of git://git.kernel.dk/linux-block
    
    Pull core block IO updates from Jens Axboe:
     "Here are the core IO block bits for 3.11. It contains:
    
       - A tweak to the reserved tag logic from Jan, for weirdo devices with
         just 3 free tags.  But for those it improves things substantially
         for random writes.
    
       - Periodic writeback fix from Jan.  Marked for stable as well.
    
       - Fix for a race condition in IO scheduler switching from Jianpeng.
    
       - The hierarchical blk-cgroup support from Tejun.  This is the grunt
         of the series.
    
       - blk-throttle fix from Vivek.
    
      Just a note that I'm in the middle of a relocation, whole family is
      flying out tomorrow.  Hence I will be awal the remainder of this week,
      but back at work again on Monday the 15th.  CC'ing Tejun, since any
      potential "surprises" will most likely be from the blk-cgroup work.
      But it's been brewing for a while and sitting in my tree and
      linux-next for a long time, so should be solid."
    
    * 'for-3.11/core' of git://git.kernel.dk/linux-block: (36 commits)
      elevator: Fix a race in elevator switching
      block: Reserve only one queue tag for sync IO if only 3 tags are available
      writeback: Fix periodic writeback after fs mount
      blk-throttle: implement proper hierarchy support
      blk-throttle: implement throtl_grp->has_rules[]
      blk-throttle: Account for child group's start time in parent while bio climbs up
      blk-throttle: add throtl_qnode for dispatch fairness
      blk-throttle: make throtl_pending_timer_fn() ready for hierarchy
      blk-throttle: make tg_dispatch_one_bio() ready for hierarchy
      blk-throttle: make blk_throtl_bio() ready for hierarchy
      blk-throttle: make blk_throtl_drain() ready for hierarchy
      blk-throttle: dispatch from throtl_pending_timer_fn()
      blk-throttle: implement dispatch looping
      blk-throttle: separate out throtl_service_queue->pending_timer from throtl_data->dispatch_work
      blk-throttle: set REQ_THROTTLED from throtl_charge_bio() and gate stats update with it
      blk-throttle: implement sq_to_tg(), sq_to_td() and throtl_log()
      blk-throttle: add throtl_service_queue->parent_sq
      blk-throttle: generalize update_disptime optimization in blk_throtl_bio()
      blk-throttle: dispatch to throtl_data->service_queue.bio_lists[]
      blk-throttle: move bio_lists[] and friends to throtl_service_queue
      ...

commit a8855990e382fc81c04187c5fdb48743307baf32
Author: Jan Kara <jack@suse.cz>
Date:   Tue Jul 9 22:36:45 2013 +0800

    writeback: Do not sort b_io list only because of block device inode
    
    It is very likely that block device inode will be part of BDI dirty list
    as well. However it doesn't make sence to sort inodes on the b_io list
    just because of this inode (as it contains buffers all over the device
    anyway). So save some CPU cycles which is valuable since we hold relatively
    contented wb->list_lock.
    
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2091db8cdd78..256233098206 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -606,7 +606,7 @@ static struct block_device *bd_acquire(struct inode *inode)
 	return bdev;
 }
 
-static inline int sb_is_blkdev_sb(struct super_block *sb)
+int sb_is_blkdev_sb(struct super_block *sb)
 {
 	return sb == blockdev_superblock;
 }

commit b45972265f823ed01eae0867a176320071665787
Author: Mel Gorman <mgorman@suse.de>
Date:   Wed Jul 3 15:02:05 2013 -0700

    mm: vmscan: take page buffers dirty and locked state into account
    
    Page reclaim keeps track of dirty and under writeback pages and uses it
    to determine if wait_iff_congested() should stall or if kswapd should
    begin writing back pages.  This fails to account for buffer pages that
    can be under writeback but not PageWriteback which is the case for
    filesystems like ext3 ordered mode.  Furthermore, PageDirty buffer pages
    can have all the buffers clean and writepage does no IO so it should not
    be accounted as congested.
    
    This patch adds an address_space operation that filesystems may
    optionally use to check if a page is really dirty or really under
    writeback.  An implementation is provided for for buffer_heads is added
    and used for block operations and ext3 in ordered mode.  By default the
    page flags are obeyed.
    
    Credit goes to Jan Kara for identifying that the page flags alone are
    not sufficient for ext3 and sanity checking a number of ideas on how the
    problem could be addressed.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Valdis Kletnieks <Valdis.Kletnieks@vt.edu>
    Cc: Zlatko Calusic <zcalusic@bitsync.net>
    Cc: dormando <dormando@rydia.net>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 431b6a04ebfd..bb43ce081d6e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1562,6 +1562,7 @@ static const struct address_space_operations def_blk_aops = {
 	.writepages	= generic_writepages,
 	.releasepage	= blkdev_releasepage,
 	.direct_IO	= blkdev_direct_IO,
+	.is_dirty_writeback = buffer_check_dirty_writeback,
 };
 
 const struct file_operations def_blk_fops = {

commit 5d48f3a2de568ba2c9d06ecbdf995e0702748f22
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jun 23 21:34:45 2013 +0400

    block_dev: switch to fixed_size_llseek()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2091db8cdd78..431b6a04ebfd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -325,31 +325,10 @@ static int blkdev_write_end(struct file *file, struct address_space *mapping,
 static loff_t block_llseek(struct file *file, loff_t offset, int whence)
 {
 	struct inode *bd_inode = file->f_mapping->host;
-	loff_t size;
 	loff_t retval;
 
 	mutex_lock(&bd_inode->i_mutex);
-	size = i_size_read(bd_inode);
-
-	retval = -EINVAL;
-	switch (whence) {
-		case SEEK_END:
-			offset += size;
-			break;
-		case SEEK_CUR:
-			offset += file->f_pos;
-		case SEEK_SET:
-			break;
-		default:
-			goto out;
-	}
-	if (offset >= 0 && offset <= size) {
-		if (offset != file->f_pos) {
-			file->f_pos = offset;
-		}
-		retval = offset;
-	}
-out:
+	retval = fixed_size_llseek(file, offset, whence, i_size_read(bd_inode));
 	mutex_unlock(&bd_inode->i_mutex);
 	return retval;
 }

commit a5faeaf9109578e65e1a32e2a3e76c8b47e7dcb6
Author: Jan Kara <jack@suse.cz>
Date:   Fri Jun 28 16:04:02 2013 +0200

    writeback: Fix periodic writeback after fs mount
    
    Code in blkdev.c moves a device inode to default_backing_dev_info when
    the last reference to the device is put and moves the device inode back
    to its bdi when the first reference is acquired. This includes moving to
    wb.b_dirty list if the device inode is dirty. The code however doesn't
    setup timer to wake corresponding flusher thread and while wb.b_dirty
    list is non-empty __mark_inode_dirty() will not set it up either. Thus
    periodic writeback is effectively disabled until a sync(2) call which can
    lead to unexpected data loss in case of crash or power failure.
    
    Fix the problem by setting up a timer for periodic writeback in case we
    add the first dirty inode to wb.b_dirty list in bdev_inode_switch_bdi().
    
    Reported-by: Bert De Jonghe <Bert.DeJonghe@amplidata.com>
    CC: stable@vger.kernel.org # >= 3.0
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2091db8cdd78..85f5c85ec91c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -58,17 +58,24 @@ static void bdev_inode_switch_bdi(struct inode *inode,
 			struct backing_dev_info *dst)
 {
 	struct backing_dev_info *old = inode->i_data.backing_dev_info;
+	bool wakeup_bdi = false;
 
 	if (unlikely(dst == old))		/* deadlock avoidance */
 		return;
 	bdi_lock_two(&old->wb, &dst->wb);
 	spin_lock(&inode->i_lock);
 	inode->i_data.backing_dev_info = dst;
-	if (inode->i_state & I_DIRTY)
+	if (inode->i_state & I_DIRTY) {
+		if (bdi_cap_writeback_dirty(dst) && !wb_has_dirty_io(&dst->wb))
+			wakeup_bdi = true;
 		list_move(&inode->i_wb_list, &dst->wb.b_dirty);
+	}
 	spin_unlock(&inode->i_lock);
 	spin_unlock(&old->wb.list_lock);
 	spin_unlock(&dst->wb.list_lock);
+
+	if (wakeup_bdi)
+		bdi_wakeup_thread_delayed(dst);
 }
 
 /* Kill _all_ buffers and pagecache , dirty or not.. */

commit 4de13d7aa8f4d02f4dc99d4609575659f92b3c5a
Merge: 5af43c24ca59 b8d4a5bf6a04
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 8 10:13:35 2013 -0700

    Merge branch 'for-3.10/core' of git://git.kernel.dk/linux-block
    
    Pull block core updates from Jens Axboe:
    
     - Major bit is Kents prep work for immutable bio vecs.
    
     - Stable candidate fix for a scheduling-while-atomic in the queue
       bypass operation.
    
     - Fix for the hang on exceeded rq->datalen 32-bit unsigned when merging
       discard bios.
    
     - Tejuns changes to convert the writeback thread pool to the generic
       workqueue mechanism.
    
     - Runtime PM framework, SCSI patches exists on top of these in James'
       tree.
    
     - A few random fixes.
    
    * 'for-3.10/core' of git://git.kernel.dk/linux-block: (40 commits)
      relay: move remove_buf_file inside relay_close_buf
      partitions/efi.c: replace useless kzalloc's by kmalloc's
      fs/block_dev.c: fix iov_shorten() criteria in blkdev_aio_read()
      block: fix max discard sectors limit
      blkcg: fix "scheduling while atomic" in blk_queue_bypass_start
      Documentation: cfq-iosched: update documentation help for cfq tunables
      writeback: expose the bdi_wq workqueue
      writeback: replace custom worker pool implementation with unbound workqueue
      writeback: remove unused bdi_pending_list
      aoe: Fix unitialized var usage
      bio-integrity: Add explicit field for owner of bip_buf
      block: Add an explicit bio flag for bios that own their bvec
      block: Add bio_alloc_pages()
      block: Convert some code to bio_for_each_segment_all()
      block: Add bio_for_each_segment_all()
      bounce: Refactor __blk_queue_bounce to not use bi_io_vec
      raid1: use bio_copy_data()
      pktcdvd: Use bio_reset() in disabled code to kill bi_idx usage
      pktcdvd: use bio_copy_data()
      block: Add bio_copy_data()
      ...

commit 5af43c24ca59a448c9312dd4a4a51d27ec3b9a73
Merge: 9affd6becbfb a27bb332c04c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 20:49:51 2013 -0700

    Merge branch 'akpm' (incoming from Andrew)
    
    Merge more incoming from Andrew Morton:
    
     - Various fixes which were stalled or which I picked up recently
    
     - A large rotorooting of the AIO code.  Allegedly to improve
       performance but I don't really have good performance numbers (I might
       have lost the email) and I can't raise Kent today.  I held this out
       of 3.9 and we could give it another cycle if it's all too late/scary.
    
    I ended up taking only the first two thirds of the AIO rotorooting.  I
    left the percpu parts and the batch completion for later.  - Linus
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (33 commits)
      aio: don't include aio.h in sched.h
      aio: kill ki_retry
      aio: kill ki_key
      aio: give shared kioctx fields their own cachelines
      aio: kill struct aio_ring_info
      aio: kill batch allocation
      aio: change reqs_active to include unreaped completions
      aio: use cancellation list lazily
      aio: use flush_dcache_page()
      aio: make aio_read_evt() more efficient, convert to hrtimers
      wait: add wait_event_hrtimeout()
      aio: refcounting cleanup
      aio: make aio_put_req() lockless
      aio: do fget() after aio_get_req()
      aio: dprintk() -> pr_debug()
      aio: move private stuff out of aio.h
      aio: add kiocb_cancel()
      aio: kill return value of aio_complete()
      char: add aio_{read,write} to /dev/{null,zero}
      aio: remove retry-based AIO
      ...

commit a27bb332c04cec8c4afd7912df0dc7890db27560
Author: Kent Overstreet <koverstreet@google.com>
Date:   Tue May 7 16:19:08 2013 -0700

    aio: don't include aio.h in sched.h
    
    Faster kernel compiles by way of fewer unnecessary includes.
    
    [akpm@linux-foundation.org: fix fallout]
    [akpm@linux-foundation.org: fix build]
    Signed-off-by: Kent Overstreet <koverstreet@google.com>
    Cc: Zach Brown <zab@redhat.com>
    Cc: Felipe Balbi <balbi@ti.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Benjamin LaHaise <bcrl@kvack.org>
    Reviewed-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ce08de7467a3..95ff88b54e98 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -27,6 +27,7 @@
 #include <linux/namei.h>
 #include <linux/log2.h>
 #include <linux/cleancache.h>
+#include <linux/aio.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 

commit 4385bab128911df14ab25f0b5ae1a48d7b53dd94
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun May 5 22:11:03 2013 -0400

    make blkdev_put() return void
    
    same story as with the previous patches - note that return
    value of blkdev_close() is lost, since there's nowhere the
    caller (__fput()) could return it to.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ad2a14174ae0..3823d3ffb760 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1045,7 +1045,7 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
-static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
+static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
 /*
  * bd_mutex locking:
@@ -1400,9 +1400,8 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	return blkdev_get(bdev, filp->f_mode, filp);
 }
 
-static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
+static void __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 {
-	int ret = 0;
 	struct gendisk *disk = bdev->bd_disk;
 	struct block_device *victim = NULL;
 
@@ -1441,10 +1440,9 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 	bdput(bdev);
 	if (victim)
 		__blkdev_put(victim, mode, 1);
-	return ret;
 }
 
-int blkdev_put(struct block_device *bdev, fmode_t mode)
+void blkdev_put(struct block_device *bdev, fmode_t mode)
 {
 	mutex_lock(&bdev->bd_mutex);
 
@@ -1488,15 +1486,15 @@ int blkdev_put(struct block_device *bdev, fmode_t mode)
 
 	mutex_unlock(&bdev->bd_mutex);
 
-	return __blkdev_put(bdev, mode, 0);
+	__blkdev_put(bdev, mode, 0);
 }
 EXPORT_SYMBOL(blkdev_put);
 
 static int blkdev_close(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
-
-	return blkdev_put(bdev, filp->f_mode);
+	blkdev_put(bdev, filp->f_mode);
+	return 0;
 }
 
 static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)

commit db2a144bedd58b3dcf19950c2f476c58c9f39d18
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun May 5 21:52:57 2013 -0400

    block_device_operations->release() should return void
    
    The value passed is 0 in all but "it can never happen" cases (and those
    only in a couple of drivers) *and* it would've been lost on the way
    out anyway, even if something tried to pass something meaningful.
    Just don't bother.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ce08de7467a3..ad2a14174ae0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1422,7 +1422,7 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 	}
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)
-			ret = disk->fops->release(disk, mode);
+			disk->fops->release(disk, mode);
 	}
 	if (!bdev->bd_openers) {
 		struct module *owner = disk->fops->owner;

commit b4ea2eaa11fa2588c241a80d6d1e59f0f68f7b29
Author: Yan Hong <clouds.yan@gmail.com>
Date:   Tue Apr 30 15:26:47 2013 -0700

    fs/block_dev.c: no need to check inode->i_bdev in bd_forget()
    
    Its only caller evict() has promised a non-NULL inode->i_bdev.
    
    Signed-off-by: Yan Hong <clouds.yan@gmail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index aae187a7f94a..ce08de7467a3 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -617,11 +617,9 @@ void bd_forget(struct inode *inode)
 	struct block_device *bdev = NULL;
 
 	spin_lock(&bdev_lock);
-	if (inode->i_bdev) {
-		if (!sb_is_blkdev_sb(inode->i_sb))
-			bdev = inode->i_bdev;
-		__bd_forget(inode);
-	}
+	if (!sb_is_blkdev_sb(inode->i_sb))
+		bdev = inode->i_bdev;
+	__bd_forget(inode);
 	spin_unlock(&bdev_lock);
 
 	if (bdev)

commit 6f8f5c260af67fed49fe14efc3ad1f69654c260e
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Mon Apr 29 11:55:52 2013 -0700

    fs/block_dev.c: fix iov_shorten() criteria in blkdev_aio_read()
    
    blkdev_aio_read() test 'size' to see if it is equal or greater than the
    target count we request(iocb->ki_left).  If so there is no need to call
    iov_shorten() to reduce number of segments and the iovec's length.  So the
    judgement should be changed to 'if (size < iocb->ki_left)' instead.
    
    Signed-off-by: Jianpeng Ma <majianpeng@gmail.com>
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index aea605c98ba6..dc7f9836fb5e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1558,7 +1558,7 @@ static ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
 		return 0;
 
 	size -= pos;
-	if (size < INT_MAX)
+	if (size < iocb->ki_left)
 		nr_segs = iov_shorten((struct iovec *)iov, nr_segs, size);
 	return generic_file_aio_read(iocb, iov, nr_segs, pos);
 }

commit c1681bf8a7b1b98edee8b862a42c19c4e53205fd
Author: Anatol Pomozov <anatol.pomozov@gmail.com>
Date:   Mon Apr 1 09:47:56 2013 -0700

    loop: prevent bdev freeing while device in use
    
    struct block_device lifecycle is defined by its inode (see fs/block_dev.c) -
    block_device allocated first time we access /dev/loopXX and deallocated on
    bdev_destroy_inode. When we create the device "losetup /dev/loopXX afile"
    we want that block_device stay alive until we destroy the loop device
    with "losetup -d".
    
    But because we do not hold /dev/loopXX inode its counter goes 0, and
    inode/bdev can be destroyed at any moment. Usually it happens at memory
    pressure or when user drops inode cache (like in the test below). When later in
    loop_clr_fd() we want to use bdev we have use-after-free error with following
    stack:
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000280
      bd_set_size+0x10/0xa0
      loop_clr_fd+0x1f8/0x420 [loop]
      lo_ioctl+0x200/0x7e0 [loop]
      lo_compat_ioctl+0x47/0xe0 [loop]
      compat_blkdev_ioctl+0x341/0x1290
      do_filp_open+0x42/0xa0
      compat_sys_ioctl+0xc1/0xf20
      do_sys_open+0x16e/0x1d0
      sysenter_dispatch+0x7/0x1a
    
    To prevent use-after-free we need to grab the device in loop_set_fd()
    and put it later in loop_clr_fd().
    
    The issue is reprodusible on current Linus head and v3.3. Here is the test:
    
      dd if=/dev/zero of=loop.file bs=1M count=1
      while [ true ]; do
        losetup /dev/loop0 loop.file
        echo 2 > /proc/sys/vm/drop_caches
        losetup -d /dev/loop0
      done
    
    [ Doing bdgrab/bput in loop_set_fd/loop_clr_fd is safe, because every
      time we call loop_set_fd() we check that loop_device->lo_state is
      Lo_unbound and set it to Lo_bound If somebody will try to set_fd again
      it will get EBUSY.  And if we try to loop_clr_fd() on unbound loop
      device we'll get ENXIO.
    
      loop_set_fd/loop_clr_fd (and any other loop ioctl) is called under
      loop_device->lo_ctl_mutex. ]
    
    Signed-off-by: Anatol Pomozov <anatol.pomozov@gmail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index aea605c98ba6..aae187a7f94a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -551,6 +551,7 @@ struct block_device *bdgrab(struct block_device *bdev)
 	ihold(bdev->bd_inode);
 	return bdev;
 }
+EXPORT_SYMBOL(bdgrab);
 
 long nr_blockdev_pages(void)
 {

commit ee89f81252179dcbf6cd65bd48299f5e52292d88
Merge: 21f3b24da932 de33127d8d3f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 28 12:52:24 2013 -0800

    Merge branch 'for-3.9/core' of git://git.kernel.dk/linux-block
    
    Pull block IO core bits from Jens Axboe:
     "Below are the core block IO bits for 3.9.  It was delayed a few days
      since my workstation kept crashing every 2-8h after pulling it into
      current -git, but turns out it is a bug in the new pstate code (divide
      by zero, will report separately).  In any case, it contains:
    
       - The big cfq/blkcg update from Tejun and and Vivek.
    
       - Additional block and writeback tracepoints from Tejun.
    
       - Improvement of the should sort (based on queues) logic in the plug
         flushing.
    
       - _io() variants of the wait_for_completion() interface, using
         io_schedule() instead of schedule() to contribute to io wait
         properly.
    
       - Various little fixes.
    
      You'll get two trivial merge conflicts, which should be easy enough to
      fix up"
    
    Fix up the trivial conflicts due to hlist traversal cleanups (commit
    b67bfe0d42ca: "hlist: drop the node parameter from iterators").
    
    * 'for-3.9/core' of git://git.kernel.dk/linux-block: (39 commits)
      block: remove redundant check to bd_openers()
      block: use i_size_write() in bd_set_size()
      cfq: fix lock imbalance with failed allocations
      drivers/block/swim3.c: fix null pointer dereference
      block: don't select PERCPU_RWSEM
      block: account iowait time when waiting for completion of IO request
      sched: add wait_for_completion_io[_timeout]
      writeback: add more tracepoints
      block: add block_{touch|dirty}_buffer tracepoint
      buffer: make touch_buffer() an exported function
      block: add @req to bio_{front|back}_merge tracepoints
      block: add missing block_bio_complete() tracepoint
      block: Remove should_sort judgement when flush blk_plug
      block,elevator: use new hashtable implementation
      cfq-iosched: add hierarchical cfq_group statistics
      cfq-iosched: collect stats from dead cfqgs
      cfq-iosched: separate out cfqg_stats_reset() from cfq_pd_reset_stats()
      blkcg: make blkcg_print_blkgs() grab q locks instead of blkcg lock
      block: RCU free request_queue
      blkcg: implement blkg_[rw]stat_recursive_sum() and blkg_[rw]stat_merge()
      ...

commit d895cb1af15c04c522a25c79cc429076987c089b
Merge: 9626357371b5 d3d009cb965e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 26 20:16:07 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile (part one) from Al Viro:
     "Assorted stuff - cleaning namei.c up a bit, fixing ->d_name/->d_parent
      locking violations, etc.
    
      The most visible changes here are death of FS_REVAL_DOT (replaced with
      "has ->d_weak_revalidate()") and a new helper getting from struct file
      to inode.  Some bits of preparation to xattr method interface changes.
    
      Misc patches by various people sent this cycle *and* ocfs2 fixes from
      several cycles ago that should've been upstream right then.
    
      PS: the next vfs pile will be xattr stuff."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (46 commits)
      saner proc_get_inode() calling conventions
      proc: avoid extra pde_put() in proc_fill_super()
      fs: change return values from -EACCES to -EPERM
      fs/exec.c: make bprm_mm_init() static
      ocfs2/dlm: use GFP_ATOMIC inside a spin_lock
      ocfs2: fix possible use-after-free with AIO
      ocfs2: Fix oops in ocfs2_fast_symlink_readpage() code path
      get_empty_filp()/alloc_file() leave both ->f_pos and ->f_version zero
      target: writev() on single-element vector is pointless
      export kernel_write(), convert open-coded instances
      fs: encode_fh: return FILEID_INVALID if invalid fid_type
      kill f_vfsmnt
      vfs: kill FS_REVAL_DOT by adding a d_weak_revalidate dentry op
      nfsd: handle vfs_getattr errors in acl protocol
      switch vfs_getattr() to struct path
      default SET_PERSONALITY() in linux/elf.h
      ceph: prepopulate inodes only when request is aborted
      d_hash_and_lookup(): export, switch open-coded instances
      9p: switch v9fs_set_create_acl() to inode+fid, do it before d_instantiate()
      9p: split dropping the acls from v9fs_set_create_acl()
      ...

commit 496ad9aa8ef448058e36ca7a787c61f2e63f0f54
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 23 17:07:38 2013 -0500

    new helper: file_inode(file)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 172f8491a2bd..7d6bdfc6b7bc 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -318,7 +318,7 @@ static int blkdev_write_end(struct file *file, struct address_space *mapping,
 
 /*
  * private llseek:
- * for a block special file file->f_path.dentry->d_inode->i_size is zero
+ * for a block special file file_inode(file)->i_size is zero
  * so we compute the size by hand (just as in block_read/write above)
  */
 static loff_t block_llseek(struct file *file, loff_t offset, int whence)

commit de33127d8d3f1d570aad8c2223cd81b206636bc1
Author: Guo Chao <yan@linux.vnet.ibm.com>
Date:   Thu Feb 21 15:16:43 2013 -0800

    block: remove redundant check to bd_openers()
    
    bd_openers is stable under bd_mutex, no need to check it twice.
    
    Signed-off-by: Guo Chao <yan@linux.vnet.ibm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Guo Chao <yan@linux.vnet.ibm.com>
    Cc: M. Hindess <hindessm@uk.ibm.com>
    Cc: Nikanth Karthikesan <knikanth@suse.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 82b7c9ad29ac..2f7058421ffb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1119,7 +1119,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				}
 			}
 
-			if (!ret && !bdev->bd_openers) {
+			if (!ret) {
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
 				bdi = blk_get_backing_dev_info(bdev);
 				if (bdi == NULL)

commit d646a02a9d44d1421f273ae3923d97b47b918176
Author: Guo Chao <yan@linux.vnet.ibm.com>
Date:   Thu Feb 21 15:16:42 2013 -0800

    block: use i_size_write() in bd_set_size()
    
    blkdev_ioctl(GETBLKSIZE) uses i_size_read() to read size of block device.
    If we update block size directly, reader may see intermediate result in
    some machines and configurations.  Use i_size_write() instead.
    
    Signed-off-by: Guo Chao <yan@linux.vnet.ibm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Guo Chao <yan@linux.vnet.ibm.com>
    Cc: M. Hindess <hindessm@uk.ibm.com>
    Cc: Nikanth Karthikesan <knikanth@suse.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 172f8491a2bd..82b7c9ad29ac 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1032,7 +1032,9 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 {
 	unsigned bsize = bdev_logical_block_size(bdev);
 
-	bdev->bd_inode->i_size = size;
+	mutex_lock(&bdev->bd_inode->i_mutex);
+	i_size_write(bdev->bd_inode, size);
+	mutex_unlock(&bdev->bd_inode->i_mutex);
 	while (bsize < PAGE_CACHE_SIZE) {
 		if (size & bsize)
 			break;

commit 7630b661da330b35dd57b6f5d6d62b386f2dd751
Author: MITSUNARI Shigeo <herumi@nifty.com>
Date:   Thu Feb 21 16:42:01 2013 -0800

    fs/block_dev.c: page cache wrongly left invalidated after revalidate_disk()
    
    We found that bdev->bd_invalidated was left set once revalidate_disk()
    is called, which results in page cache flush every time that device is
    open.
    
    Specifically, we found this problem in MD block device.  Once we resize
    a MD device, mdadm --monitor periodically flush all page cache for that
    device every 60 or 1000 seconds when it opens the device.
    
    This bug lies since at least 3.2.0 till the latest kernel(3.6.2).  Patch
    is attached.
    
    The following steps will reproduce the problem.
    
    1. prepair a block device (eg /dev/sdb).
    
    2. create two partitions:
    
       sudo parted /dev/sdb
       mklabel gpt
       mkpart primary 0% 50%
       mkpart primary 50% 100%
    
    3. create a md device.
    
       sudo mdadm -C /dev/md/hoge -l 1 -n 2 -e 1.2 --assume-clean --auto=md --symlink=no /dev/sdb1 /dev/sdb2
    
    4. create file system and mount it
    
       sudo mkfs.ext3 /dev/md/hoge
       sudo mkdir /mnt/test
       sudo mount /dev/md/hoge /mnt/test
    
    5. try to resize the device
    
       sudo mdadm -G /dev/md/hoge --size=max
    
    6. create a file to fill file cache.
    
      sudo dd if=/dev/urandom of=/mnt/test/data bs=1M count=10
    
    and verify the current status of file by free command.
    
    7. mdadm monitor will open the md device every 1000 seconds and you
       will find all file cache on the device are cleared.
    
    The timing can be reduced by the following steps.
    
    a) kill mdadm and restart it with --delay option
    
       /sbin/mdadm --monitor --delay=30 --pid-file /var/run/mdadm/monitor.pid --daemonise --scan --syslog
    
    or open the md device directly.
    
       sudo dd if=/dev/md/hoge of=/dev/null bs=4096 count=1
    
    Signed-off-by: MITSUNARI Shigeo <herumi@nifty.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 172f8491a2bd..78333a37f49d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -994,6 +994,7 @@ int revalidate_disk(struct gendisk *disk)
 
 	mutex_lock(&bdev->bd_mutex);
 	check_disk_size_change(disk, bdev);
+	bdev->bd_invalidated = 0;
 	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);
 	return ret;

commit 965c8e59cfcf845ecde2265a1d1bfee5f011d302
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Mon Dec 17 15:59:39 2012 -0800

    lseek: the "whence" argument is called "whence"
    
    But the kernel decided to call it "origin" instead.  Fix most of the
    sites.
    
    Acked-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ab3a456f6650..172f8491a2bd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -321,7 +321,7 @@ static int blkdev_write_end(struct file *file, struct address_space *mapping,
  * for a block special file file->f_path.dentry->d_inode->i_size is zero
  * so we compute the size by hand (just as in block_read/write above)
  */
-static loff_t block_llseek(struct file *file, loff_t offset, int origin)
+static loff_t block_llseek(struct file *file, loff_t offset, int whence)
 {
 	struct inode *bd_inode = file->f_mapping->host;
 	loff_t size;
@@ -331,7 +331,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
 	size = i_size_read(bd_inode);
 
 	retval = -EINVAL;
-	switch (origin) {
+	switch (whence) {
 		case SEEK_END:
 			offset += size;
 			break;

commit 684c9aaebbb0ea3a9954d605d4908e650659e7db
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 7 16:48:39 2012 -0800

    vfs: fix O_DIRECT read past end of block device
    
    The direct-IO write path already had the i_size checks in mm/filemap.c,
    but it turns out the read path did not, and removing the block size
    checks in fs/block_dev.c (commit bbec0270bdd8: "blkdev_max_block: make
    private to fs/buffer.c") removed the magic "shrink IO to past the end of
    the device" code there.
    
    Fix it by truncating the IO to the size of the block device, like the
    write path already does.
    
    NOTE! I suspect the write path would be *much* better off doing it this
    way in fs/block_dev.c, rather than hidden deep in mm/filemap.c.  The
    mm/filemap.c code is extremely hard to follow, and has various
    conditionals on the target being a block device (ie the flag passed in
    to 'generic_write_checks()', along with a conditional update of the
    inode timestamp etc).
    
    It is also quite possible that we should treat this whole block device
    size as a "s_maxbytes" issue, and try to make the logic even more
    generic.  However, in the meantime this is the fairly minimal targeted
    fix.
    
    Noted by Milan Broz thanks to a regression test for the cryptsetup
    reencrypt tool.
    
    Reported-and-tested-by: Milan Broz <mbroz@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a1e09b4fe1ba..ab3a456f6650 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1544,6 +1544,22 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 }
 EXPORT_SYMBOL_GPL(blkdev_aio_write);
 
+static ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
+			 unsigned long nr_segs, loff_t pos)
+{
+	struct file *file = iocb->ki_filp;
+	struct inode *bd_inode = file->f_mapping->host;
+	loff_t size = i_size_read(bd_inode);
+
+	if (pos >= size)
+		return 0;
+
+	size -= pos;
+	if (size < INT_MAX)
+		nr_segs = iov_shorten((struct iovec *)iov, nr_segs, size);
+	return generic_file_aio_read(iocb, iov, nr_segs, pos);
+}
+
 /*
  * Try to release a page associated with block device when the system
  * is under memory pressure.
@@ -1574,7 +1590,7 @@ const struct file_operations def_blk_fops = {
 	.llseek		= block_llseek,
 	.read		= do_sync_read,
 	.write		= do_sync_write,
-	.aio_read	= generic_file_aio_read,
+	.aio_read	= blkdev_aio_read,
 	.aio_write	= blkdev_aio_write,
 	.mmap		= generic_file_mmap,
 	.fsync		= blkdev_fsync,

commit bbec0270bdd887f96377065ee38b8848b5afa395
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 29 12:31:52 2012 -0800

    blkdev_max_block: make private to fs/buffer.c
    
    We really don't want to look at the block size for the raw block device
    accesses in fs/block-dev.c, because it may be changing from under us.
    So get rid of the max_block logic entirely, since the caller should
    already have done it anyway.
    
    That leaves the only user of this function in fs/buffer.c, so move the
    whole function there and make it static.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 47a949d8a07e..a1e09b4fe1ba 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -70,19 +70,6 @@ static void bdev_inode_switch_bdi(struct inode *inode,
 	spin_unlock(&dst->wb.list_lock);
 }
 
-sector_t blkdev_max_block(struct block_device *bdev)
-{
-	sector_t retval = ~((sector_t)0);
-	loff_t sz = i_size_read(bdev->bd_inode);
-
-	if (sz) {
-		unsigned int size = block_size(bdev);
-		unsigned int sizebits = blksize_bits(size);
-		retval = (sz >> sizebits);
-	}
-	return retval;
-}
-
 /* Kill _all_ buffers and pagecache , dirty or not.. */
 void kill_bdev(struct block_device *bdev)
 {
@@ -163,52 +150,12 @@ static int
 blkdev_get_block(struct inode *inode, sector_t iblock,
 		struct buffer_head *bh, int create)
 {
-	if (iblock >= blkdev_max_block(I_BDEV(inode))) {
-		if (create)
-			return -EIO;
-
-		/*
-		 * for reads, we're just trying to fill a partial page.
-		 * return a hole, they will have to call get_block again
-		 * before they can fill it, and they will get -EIO at that
-		 * time
-		 */
-		return 0;
-	}
 	bh->b_bdev = I_BDEV(inode);
 	bh->b_blocknr = iblock;
 	set_buffer_mapped(bh);
 	return 0;
 }
 
-static int
-blkdev_get_blocks(struct inode *inode, sector_t iblock,
-		struct buffer_head *bh, int create)
-{
-	sector_t end_block = blkdev_max_block(I_BDEV(inode));
-	unsigned long max_blocks = bh->b_size >> inode->i_blkbits;
-
-	if ((iblock + max_blocks) > end_block) {
-		max_blocks = end_block - iblock;
-		if ((long)max_blocks <= 0) {
-			if (create)
-				return -EIO;	/* write fully beyond EOF */
-			/*
-			 * It is a read which is fully beyond EOF.  We return
-			 * a !buffer_mapped buffer
-			 */
-			max_blocks = 0;
-		}
-	}
-
-	bh->b_bdev = I_BDEV(inode);
-	bh->b_blocknr = iblock;
-	bh->b_size = max_blocks << inode->i_blkbits;
-	if (max_blocks)
-		set_buffer_mapped(bh);
-	return 0;
-}
-
 static ssize_t
 blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 			loff_t offset, unsigned long nr_segs)
@@ -217,7 +164,7 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 	struct inode *inode = file->f_mapping->host;
 
 	return __blockdev_direct_IO(rw, iocb, inode, I_BDEV(inode), iov, offset,
-				    nr_segs, blkdev_get_blocks, NULL, NULL, 0);
+				    nr_segs, blkdev_get_block, NULL, NULL, 0);
 }
 
 int __sync_blockdev(struct block_device *bdev, int wait)

commit 1e8b33328a5407b447ff80953655a47014a6dcb9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 29 10:49:50 2012 -0800

    blockdev: remove bd_block_size_semaphore again
    
    This reverts the block-device direct access code to the previous
    unlocked code, now that fs/buffer.c no longer needs external locking.
    
    With this, fs/block_dev.c is back to the original version, apart from a
    whitespace cleanup that I didn't want to revert.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1a1e5e3b1eaf..47a949d8a07e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -116,8 +116,6 @@ EXPORT_SYMBOL(invalidate_bdev);
 
 int set_blocksize(struct block_device *bdev, int size)
 {
-	struct address_space *mapping;
-
 	/* Size must be a power of two, and between 512 and PAGE_SIZE */
 	if (size > PAGE_SIZE || size < 512 || !is_power_of_2(size))
 		return -EINVAL;
@@ -126,19 +124,6 @@ int set_blocksize(struct block_device *bdev, int size)
 	if (size < bdev_logical_block_size(bdev))
 		return -EINVAL;
 
-	/* Prevent starting I/O or mapping the device */
-	percpu_down_write(&bdev->bd_block_size_semaphore);
-
-	/* Check that the block device is not memory mapped */
-	mapping = bdev->bd_inode->i_mapping;
-	mutex_lock(&mapping->i_mmap_mutex);
-	if (mapping_mapped(mapping)) {
-		mutex_unlock(&mapping->i_mmap_mutex);
-		percpu_up_write(&bdev->bd_block_size_semaphore);
-		return -EBUSY;
-	}
-	mutex_unlock(&mapping->i_mmap_mutex);
-
 	/* Don't change the size if it is same as current */
 	if (bdev->bd_block_size != size) {
 		sync_blockdev(bdev);
@@ -146,9 +131,6 @@ int set_blocksize(struct block_device *bdev, int size)
 		bdev->bd_inode->i_blkbits = blksize_bits(size);
 		kill_bdev(bdev);
 	}
-
-	percpu_up_write(&bdev->bd_block_size_semaphore);
-
 	return 0;
 }
 
@@ -459,12 +441,6 @@ static struct inode *bdev_alloc_inode(struct super_block *sb)
 	struct bdev_inode *ei = kmem_cache_alloc(bdev_cachep, GFP_KERNEL);
 	if (!ei)
 		return NULL;
-
-	if (unlikely(percpu_init_rwsem(&ei->bdev.bd_block_size_semaphore))) {
-		kmem_cache_free(bdev_cachep, ei);
-		return NULL;
-	}
-
 	return &ei->vfs_inode;
 }
 
@@ -473,8 +449,6 @@ static void bdev_i_callback(struct rcu_head *head)
 	struct inode *inode = container_of(head, struct inode, i_rcu);
 	struct bdev_inode *bdi = BDEV_I(inode);
 
-	percpu_free_rwsem(&bdi->bdev.bd_block_size_semaphore);
-
 	kmem_cache_free(bdev_cachep, bdi);
 }
 
@@ -1593,22 +1567,6 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 	return blkdev_ioctl(bdev, mode, cmd, arg);
 }
 
-ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
-			unsigned long nr_segs, loff_t pos)
-{
-	ssize_t ret;
-	struct block_device *bdev = I_BDEV(iocb->ki_filp->f_mapping->host);
-
-	percpu_down_read(&bdev->bd_block_size_semaphore);
-
-	ret = generic_file_aio_read(iocb, iov, nr_segs, pos);
-
-	percpu_up_read(&bdev->bd_block_size_semaphore);
-
-	return ret;
-}
-EXPORT_SYMBOL_GPL(blkdev_aio_read);
-
 /*
  * Write data to the block device.  Only intended for the block device itself
  * and the raw driver which basically is a fake block device.
@@ -1620,16 +1578,12 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 			 unsigned long nr_segs, loff_t pos)
 {
 	struct file *file = iocb->ki_filp;
-	struct block_device *bdev = I_BDEV(file->f_mapping->host);
 	struct blk_plug plug;
 	ssize_t ret;
 
 	BUG_ON(iocb->ki_pos != pos);
 
 	blk_start_plug(&plug);
-
-	percpu_down_read(&bdev->bd_block_size_semaphore);
-
 	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
 	if (ret > 0 || ret == -EIOCBQUEUED) {
 		ssize_t err;
@@ -1638,62 +1592,11 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 		if (err < 0 && ret > 0)
 			ret = err;
 	}
-
-	percpu_up_read(&bdev->bd_block_size_semaphore);
-
 	blk_finish_plug(&plug);
-
 	return ret;
 }
 EXPORT_SYMBOL_GPL(blkdev_aio_write);
 
-static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
-{
-	int ret;
-	struct block_device *bdev = I_BDEV(file->f_mapping->host);
-
-	percpu_down_read(&bdev->bd_block_size_semaphore);
-
-	ret = generic_file_mmap(file, vma);
-
-	percpu_up_read(&bdev->bd_block_size_semaphore);
-
-	return ret;
-}
-
-static ssize_t blkdev_splice_read(struct file *file, loff_t *ppos,
-				  struct pipe_inode_info *pipe, size_t len,
-				  unsigned int flags)
-{
-	ssize_t ret;
-	struct block_device *bdev = I_BDEV(file->f_mapping->host);
-
-	percpu_down_read(&bdev->bd_block_size_semaphore);
-
-	ret = generic_file_splice_read(file, ppos, pipe, len, flags);
-
-	percpu_up_read(&bdev->bd_block_size_semaphore);
-
-	return ret;
-}
-
-static ssize_t blkdev_splice_write(struct pipe_inode_info *pipe,
-				   struct file *file, loff_t *ppos, size_t len,
-				   unsigned int flags)
-{
-	ssize_t ret;
-	struct block_device *bdev = I_BDEV(file->f_mapping->host);
-
-	percpu_down_read(&bdev->bd_block_size_semaphore);
-
-	ret = generic_file_splice_write(pipe, file, ppos, len, flags);
-
-	percpu_up_read(&bdev->bd_block_size_semaphore);
-
-	return ret;
-}
-
-
 /*
  * Try to release a page associated with block device when the system
  * is under memory pressure.
@@ -1724,16 +1627,16 @@ const struct file_operations def_blk_fops = {
 	.llseek		= block_llseek,
 	.read		= do_sync_read,
 	.write		= do_sync_write,
-  	.aio_read	= blkdev_aio_read,
+	.aio_read	= generic_file_aio_read,
 	.aio_write	= blkdev_aio_write,
-	.mmap		= blkdev_mmap,
+	.mmap		= generic_file_mmap,
 	.fsync		= blkdev_fsync,
 	.unlocked_ioctl	= block_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl	= compat_blkdev_ioctl,
 #endif
-	.splice_read	= blkdev_splice_read,
-	.splice_write	= blkdev_splice_write,
+	.splice_read	= generic_file_splice_read,
+	.splice_write	= generic_file_splice_write,
 };
 
 int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)

commit 1a25b1c4ce189e3926f2981f3302352a930086db
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon Oct 15 17:20:17 2012 -0400

    Lock splice_read and splice_write functions
    
    Functions generic_file_splice_read and generic_file_splice_write access
    the pagecache directly. For block devices these functions must be locked
    so that block size is not changed while they are in progress.
    
    This patch is an additional fix for commit b87570f5d349 ("Fix a crash
    when block device is read and block size is changed at the same time")
    that locked aio_read, aio_write and mmap against block size change.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b3c1d3dae77d..1a1e5e3b1eaf 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1661,6 +1661,39 @@ static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
 	return ret;
 }
 
+static ssize_t blkdev_splice_read(struct file *file, loff_t *ppos,
+				  struct pipe_inode_info *pipe, size_t len,
+				  unsigned int flags)
+{
+	ssize_t ret;
+	struct block_device *bdev = I_BDEV(file->f_mapping->host);
+
+	percpu_down_read(&bdev->bd_block_size_semaphore);
+
+	ret = generic_file_splice_read(file, ppos, pipe, len, flags);
+
+	percpu_up_read(&bdev->bd_block_size_semaphore);
+
+	return ret;
+}
+
+static ssize_t blkdev_splice_write(struct pipe_inode_info *pipe,
+				   struct file *file, loff_t *ppos, size_t len,
+				   unsigned int flags)
+{
+	ssize_t ret;
+	struct block_device *bdev = I_BDEV(file->f_mapping->host);
+
+	percpu_down_read(&bdev->bd_block_size_semaphore);
+
+	ret = generic_file_splice_write(pipe, file, ppos, len, flags);
+
+	percpu_up_read(&bdev->bd_block_size_semaphore);
+
+	return ret;
+}
+
+
 /*
  * Try to release a page associated with block device when the system
  * is under memory pressure.
@@ -1699,8 +1732,8 @@ const struct file_operations def_blk_fops = {
 #ifdef CONFIG_COMPAT
 	.compat_ioctl	= compat_blkdev_ioctl,
 #endif
-	.splice_read	= generic_file_splice_read,
-	.splice_write	= generic_file_splice_write,
+	.splice_read	= blkdev_splice_read,
+	.splice_write	= blkdev_splice_write,
 };
 
 int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)

commit ce40be7a820bb393ac4ac69865f018d2f4038cf0
Merge: ba0a5a36f60e 02f3939e1a93
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 11 09:04:23 2012 +0900

    Merge branch 'for-3.7/core' of git://git.kernel.dk/linux-block
    
    Pull block IO update from Jens Axboe:
     "Core block IO bits for 3.7.  Not a huge round this time, it contains:
    
       - First series from Kent cleaning up and generalizing bio allocation
         and freeing.
    
       - WRITE_SAME support from Martin.
    
       - Mikulas patches to prevent O_DIRECT crashes when someone changes
         the block size of a device.
    
       - Make bio_split() work on data-less bio's (like trim/discards).
    
       - A few other minor fixups."
    
    Fixed up silent semantic mis-merge as per Mikulas Patocka and Andrew
    Morton.  It is due to the VM no longer using a prio-tree (see commit
    6b2dbba8b6ac: "mm: replace vma prio_tree with an interval tree").
    
    So make set_blocksize() use mapping_mapped() instead of open-coding the
    internal VM knowledge that has changed.
    
    * 'for-3.7/core' of git://git.kernel.dk/linux-block: (26 commits)
      block: makes bio_split support bio without data
      scatterlist: refactor the sg_nents
      scatterlist: add sg_nents
      fs: fix include/percpu-rwsem.h export error
      percpu-rw-semaphore: fix documentation typos
      fs/block_dev.c:1644:5: sparse: symbol 'blkdev_mmap' was not declared
      blockdev: turn a rw semaphore into a percpu rw semaphore
      Fix a crash when block device is read and block size is changed at the same time
      block: fix request_queue->flags initialization
      block: lift the initial queue bypass mode on blk_register_queue() instead of blk_init_allocated_queue()
      block: ioctl to zero block ranges
      block: Make blkdev_issue_zeroout use WRITE SAME
      block: Implement support for WRITE SAME
      block: Consolidate command flag and queue limit checks for merges
      block: Clean up special command handling logic
      block/blk-tag.c: Remove useless kfree
      block: remove the duplicated setting for congestion_threshold
      block: reject invalid queue attribute values
      block: Add bio_clone_bioset(), bio_clone_kmalloc()
      block: Consolidate bio_alloc_bioset(), bio_kmalloc()
      ...

commit 3eab7315c8dd6685f58acba00319dd8b80a21d7a
Author: Fengguang Wu <fengguang.wu@intel.com>
Date:   Wed Sep 26 09:57:55 2012 +0200

    fs/block_dev.c:1644:5: sparse: symbol 'blkdev_mmap' was not declared
    
    blkdev_mmap() isn't used outside of fs/block_dev.c, mark it as
    static.
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7eeb0635338b..37967bcea05c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1648,7 +1648,7 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 }
 EXPORT_SYMBOL_GPL(blkdev_aio_write);
 
-int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
+static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
 {
 	int ret;
 	struct block_device *bdev = I_BDEV(file->f_mapping->host);

commit 62ac665ff9fc07497ca524bd20d6a96893d11071
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Wed Sep 26 07:46:43 2012 +0200

    blockdev: turn a rw semaphore into a percpu rw semaphore
    
    This avoids cache line bouncing when many processes lock the semaphore
    for read.
    
    New percpu lock implementation
    
    The lock consists of an array of percpu unsigned integers, a boolean
    variable and a mutex.
    
    When we take the lock for read, we enter rcu read section, check for a
    "locked" variable. If it is false, we increase a percpu counter on the
    current cpu and exit the rcu section. If "locked" is true, we exit the
    rcu section, take the mutex and drop it (this waits until a writer
    finished) and retry.
    
    Unlocking for read just decreases percpu variable. Note that we can
    unlock on a difference cpu than where we locked, in this case the
    counter underflows. The sum of all percpu counters represents the number
    of processes that hold the lock for read.
    
    When we need to lock for write, we take the mutex, set "locked" variable
    to true and synchronize rcu. Since RCU has been synchronized, no
    processes can create new read locks. We wait until the sum of percpu
    counters is zero - when it is, there are no readers in the critical
    section.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index cdfb625824e2..7eeb0635338b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -127,7 +127,7 @@ int set_blocksize(struct block_device *bdev, int size)
 		return -EINVAL;
 
 	/* Prevent starting I/O or mapping the device */
-	down_write(&bdev->bd_block_size_semaphore);
+	percpu_down_write(&bdev->bd_block_size_semaphore);
 
 	/* Check that the block device is not memory mapped */
 	mapping = bdev->bd_inode->i_mapping;
@@ -135,7 +135,7 @@ int set_blocksize(struct block_device *bdev, int size)
 	if (!prio_tree_empty(&mapping->i_mmap) ||
 	    !list_empty(&mapping->i_mmap_nonlinear)) {
 		mutex_unlock(&mapping->i_mmap_mutex);
-		up_write(&bdev->bd_block_size_semaphore);
+		percpu_up_write(&bdev->bd_block_size_semaphore);
 		return -EBUSY;
 	}
 	mutex_unlock(&mapping->i_mmap_mutex);
@@ -148,7 +148,7 @@ int set_blocksize(struct block_device *bdev, int size)
 		kill_bdev(bdev);
 	}
 
-	up_write(&bdev->bd_block_size_semaphore);
+	percpu_up_write(&bdev->bd_block_size_semaphore);
 
 	return 0;
 }
@@ -460,6 +460,12 @@ static struct inode *bdev_alloc_inode(struct super_block *sb)
 	struct bdev_inode *ei = kmem_cache_alloc(bdev_cachep, GFP_KERNEL);
 	if (!ei)
 		return NULL;
+
+	if (unlikely(percpu_init_rwsem(&ei->bdev.bd_block_size_semaphore))) {
+		kmem_cache_free(bdev_cachep, ei);
+		return NULL;
+	}
+
 	return &ei->vfs_inode;
 }
 
@@ -468,6 +474,8 @@ static void bdev_i_callback(struct rcu_head *head)
 	struct inode *inode = container_of(head, struct inode, i_rcu);
 	struct bdev_inode *bdi = BDEV_I(inode);
 
+	percpu_free_rwsem(&bdi->bdev.bd_block_size_semaphore);
+
 	kmem_cache_free(bdev_cachep, bdi);
 }
 
@@ -491,7 +499,6 @@ static void init_once(void *foo)
 	inode_init_once(&ei->vfs_inode);
 	/* Initialize mutex for freeze. */
 	mutex_init(&bdev->bd_fsfreeze_mutex);
-	init_rwsem(&bdev->bd_block_size_semaphore);
 }
 
 static inline void __bd_forget(struct inode *inode)
@@ -1593,11 +1600,11 @@ ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
 	ssize_t ret;
 	struct block_device *bdev = I_BDEV(iocb->ki_filp->f_mapping->host);
 
-	down_read(&bdev->bd_block_size_semaphore);
+	percpu_down_read(&bdev->bd_block_size_semaphore);
 
 	ret = generic_file_aio_read(iocb, iov, nr_segs, pos);
 
-	up_read(&bdev->bd_block_size_semaphore);
+	percpu_up_read(&bdev->bd_block_size_semaphore);
 
 	return ret;
 }
@@ -1622,7 +1629,7 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 
 	blk_start_plug(&plug);
 
-	down_read(&bdev->bd_block_size_semaphore);
+	percpu_down_read(&bdev->bd_block_size_semaphore);
 
 	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
 	if (ret > 0 || ret == -EIOCBQUEUED) {
@@ -1633,7 +1640,7 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 			ret = err;
 	}
 
-	up_read(&bdev->bd_block_size_semaphore);
+	percpu_up_read(&bdev->bd_block_size_semaphore);
 
 	blk_finish_plug(&plug);
 
@@ -1646,11 +1653,11 @@ int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
 	int ret;
 	struct block_device *bdev = I_BDEV(file->f_mapping->host);
 
-	down_read(&bdev->bd_block_size_semaphore);
+	percpu_down_read(&bdev->bd_block_size_semaphore);
 
 	ret = generic_file_mmap(file, vma);
 
-	up_read(&bdev->bd_block_size_semaphore);
+	percpu_up_read(&bdev->bd_block_size_semaphore);
 
 	return ret;
 }

commit b87570f5d349661814b262dd5fc40787700f80d6
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Wed Sep 26 07:46:40 2012 +0200

    Fix a crash when block device is read and block size is changed at the same time
    
    The kernel may crash when block size is changed and I/O is issued
    simultaneously.
    
    Because some subsystems (udev or lvm) may read any block device anytime,
    the bug actually puts any code that changes a block device size in
    jeopardy.
    
    The crash can be reproduced if you place "msleep(1000)" to
    blkdev_get_blocks just before "bh->b_size = max_blocks <<
    inode->i_blkbits;".
    Then, run "dd if=/dev/ram0 of=/dev/null bs=4k count=1 iflag=direct"
    While it is waiting in msleep, run "blockdev --setbsz 2048 /dev/ram0"
    You get a BUG.
    
    The direct and non-direct I/O is written with the assumption that block
    size does not change. It doesn't seem practical to fix these crashes
    one-by-one there may be many crash possibilities when block size changes
    at a certain place and it is impossible to find them all and verify the
    code.
    
    This patch introduces a new rw-lock bd_block_size_semaphore. The lock is
    taken for read during I/O. It is taken for write when changing block
    size. Consequently, block size can't be changed while I/O is being
    submitted.
    
    For asynchronous I/O, the patch only prevents block size change while
    the I/O is being submitted. The block size can change when the I/O is in
    progress or when the I/O is being finished. This is acceptable because
    there are no accesses to block size when asynchronous I/O is being
    finished.
    
    The patch prevents block size changing while the device is mapped with
    mmap.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 38e721b35d45..cdfb625824e2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -116,6 +116,8 @@ EXPORT_SYMBOL(invalidate_bdev);
 
 int set_blocksize(struct block_device *bdev, int size)
 {
+	struct address_space *mapping;
+
 	/* Size must be a power of two, and between 512 and PAGE_SIZE */
 	if (size > PAGE_SIZE || size < 512 || !is_power_of_2(size))
 		return -EINVAL;
@@ -124,6 +126,20 @@ int set_blocksize(struct block_device *bdev, int size)
 	if (size < bdev_logical_block_size(bdev))
 		return -EINVAL;
 
+	/* Prevent starting I/O or mapping the device */
+	down_write(&bdev->bd_block_size_semaphore);
+
+	/* Check that the block device is not memory mapped */
+	mapping = bdev->bd_inode->i_mapping;
+	mutex_lock(&mapping->i_mmap_mutex);
+	if (!prio_tree_empty(&mapping->i_mmap) ||
+	    !list_empty(&mapping->i_mmap_nonlinear)) {
+		mutex_unlock(&mapping->i_mmap_mutex);
+		up_write(&bdev->bd_block_size_semaphore);
+		return -EBUSY;
+	}
+	mutex_unlock(&mapping->i_mmap_mutex);
+
 	/* Don't change the size if it is same as current */
 	if (bdev->bd_block_size != size) {
 		sync_blockdev(bdev);
@@ -131,6 +147,9 @@ int set_blocksize(struct block_device *bdev, int size)
 		bdev->bd_inode->i_blkbits = blksize_bits(size);
 		kill_bdev(bdev);
 	}
+
+	up_write(&bdev->bd_block_size_semaphore);
+
 	return 0;
 }
 
@@ -472,6 +491,7 @@ static void init_once(void *foo)
 	inode_init_once(&ei->vfs_inode);
 	/* Initialize mutex for freeze. */
 	mutex_init(&bdev->bd_fsfreeze_mutex);
+	init_rwsem(&bdev->bd_block_size_semaphore);
 }
 
 static inline void __bd_forget(struct inode *inode)
@@ -1567,6 +1587,22 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 	return blkdev_ioctl(bdev, mode, cmd, arg);
 }
 
+ssize_t blkdev_aio_read(struct kiocb *iocb, const struct iovec *iov,
+			unsigned long nr_segs, loff_t pos)
+{
+	ssize_t ret;
+	struct block_device *bdev = I_BDEV(iocb->ki_filp->f_mapping->host);
+
+	down_read(&bdev->bd_block_size_semaphore);
+
+	ret = generic_file_aio_read(iocb, iov, nr_segs, pos);
+
+	up_read(&bdev->bd_block_size_semaphore);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(blkdev_aio_read);
+
 /*
  * Write data to the block device.  Only intended for the block device itself
  * and the raw driver which basically is a fake block device.
@@ -1578,12 +1614,16 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 			 unsigned long nr_segs, loff_t pos)
 {
 	struct file *file = iocb->ki_filp;
+	struct block_device *bdev = I_BDEV(file->f_mapping->host);
 	struct blk_plug plug;
 	ssize_t ret;
 
 	BUG_ON(iocb->ki_pos != pos);
 
 	blk_start_plug(&plug);
+
+	down_read(&bdev->bd_block_size_semaphore);
+
 	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
 	if (ret > 0 || ret == -EIOCBQUEUED) {
 		ssize_t err;
@@ -1592,11 +1632,29 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 		if (err < 0 && ret > 0)
 			ret = err;
 	}
+
+	up_read(&bdev->bd_block_size_semaphore);
+
 	blk_finish_plug(&plug);
+
 	return ret;
 }
 EXPORT_SYMBOL_GPL(blkdev_aio_write);
 
+int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	int ret;
+	struct block_device *bdev = I_BDEV(file->f_mapping->host);
+
+	down_read(&bdev->bd_block_size_semaphore);
+
+	ret = generic_file_mmap(file, vma);
+
+	up_read(&bdev->bd_block_size_semaphore);
+
+	return ret;
+}
+
 /*
  * Try to release a page associated with block device when the system
  * is under memory pressure.
@@ -1627,9 +1685,9 @@ const struct file_operations def_blk_fops = {
 	.llseek		= block_llseek,
 	.read		= do_sync_read,
 	.write		= do_sync_write,
-  	.aio_read	= generic_file_aio_read,
+  	.aio_read	= blkdev_aio_read,
 	.aio_write	= blkdev_aio_write,
-	.mmap		= generic_file_mmap,
+	.mmap		= blkdev_mmap,
 	.fsync		= blkdev_fsync,
 	.unlocked_ioctl	= block_ioctl,
 #ifdef CONFIG_COMPAT

commit 53362a05ae683e12a20d9ffdf58a88094a0bed9d
Author: Jianpeng Ma <majianpeng@gmail.com>
Date:   Thu Aug 2 09:50:39 2012 +0200

    fs/block-dev.c:fix performance regression in O_DIRECT writes to md block devices
    
    For regular file, write operaion used blk_plug function.But for block
    file,write operation did not use blk_plug.
    This patch is also for write-cache mode for block-device.
    
    Signed-off-by: Jianpeng Ma <majianpeng@gmail.com>
    Reviewed-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1e519195d45b..38e721b35d45 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1578,10 +1578,12 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 			 unsigned long nr_segs, loff_t pos)
 {
 	struct file *file = iocb->ki_filp;
+	struct blk_plug plug;
 	ssize_t ret;
 
 	BUG_ON(iocb->ki_pos != pos);
 
+	blk_start_plug(&plug);
 	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
 	if (ret > 0 || ret == -EIOCBQUEUED) {
 		ssize_t err;
@@ -1590,6 +1592,7 @@ ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
 		if (err < 0 && ret > 0)
 			ret = err;
 	}
+	blk_finish_plug(&plug);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(blkdev_aio_write);

commit 5c0d6b60a0ba46d45020547eacf7199171920935
Author: Jan Kara <jack@suse.cz>
Date:   Tue Jul 3 16:45:31 2012 +0200

    vfs: Create function for iterating over block devices
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c2bbe1fb1326..1e519195d45b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1710,3 +1710,39 @@ int __invalidate_device(struct block_device *bdev, bool kill_dirty)
 	return res;
 }
 EXPORT_SYMBOL(__invalidate_device);
+
+void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
+{
+	struct inode *inode, *old_inode = NULL;
+
+	spin_lock(&inode_sb_list_lock);
+	list_for_each_entry(inode, &blockdev_superblock->s_inodes, i_sb_list) {
+		struct address_space *mapping = inode->i_mapping;
+
+		spin_lock(&inode->i_lock);
+		if (inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW) ||
+		    mapping->nrpages == 0) {
+			spin_unlock(&inode->i_lock);
+			continue;
+		}
+		__iget(inode);
+		spin_unlock(&inode->i_lock);
+		spin_unlock(&inode_sb_list_lock);
+		/*
+		 * We hold a reference to 'inode' so it couldn't have been
+		 * removed from s_inodes list while we dropped the
+		 * inode_sb_list_lock.  We cannot iput the inode now as we can
+		 * be holding the last reference and we cannot iput it under
+		 * inode_sb_list_lock. So we keep the reference and iput it
+		 * later.
+		 */
+		iput(old_inode);
+		old_inode = inode;
+
+		func(I_BDEV(inode), arg);
+
+		spin_lock(&inode_sb_list_lock);
+	}
+	spin_unlock(&inode_sb_list_lock);
+	iput(old_inode);
+}

commit 90324cc1b11a211e37eabd8cb863e1a1561d6b1d
Merge: fb8b00675eb6 169ebd90131b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 28 09:54:45 2012 -0700

    Merge tag 'writeback' of git://git.kernel.org/pub/scm/linux/kernel/git/wfg/linux
    
    Pull writeback tree from Wu Fengguang:
     "Mainly from Jan Kara to avoid iput() in the flusher threads."
    
    * tag 'writeback' of git://git.kernel.org/pub/scm/linux/kernel/git/wfg/linux:
      writeback: Avoid iput() from flusher thread
      vfs: Rename end_writeback() to clear_inode()
      vfs: Move waiting for inode writeback from end_writeback() to evict_inode()
      writeback: Refactor writeback_single_inode()
      writeback: Remove wb->list_lock from writeback_single_inode()
      writeback: Separate inode requeueing after writeback
      writeback: Move I_DIRTY_PAGES handling
      writeback: Move requeueing when I_SYNC set to writeback_sb_inodes()
      writeback: Move clearing of I_SYNC into inode_sync_complete()
      writeback: initialize global_dirty_limit
      fs: remove 8 bytes of padding from struct writeback_control on 64 bit builds
      mm: page-writeback.c: local functions should not be exposed globally

commit 080399aaaf3531f5b8761ec0ac30ff98891e8686
Author: Jeff Moyer <jmoyer@redhat.com>
Date:   Fri May 11 16:34:10 2012 +0200

    block: don't mark buffers beyond end of disk as mapped
    
    Hi,
    
    We have a bug report open where a squashfs image mounted on ppc64 would
    exhibit errors due to trying to read beyond the end of the disk.  It can
    easily be reproduced by doing the following:
    
    [root@ibm-p750e-02-lp3 ~]# ls -l install.img
    -rw-r--r-- 1 root root 142032896 Apr 30 16:46 install.img
    [root@ibm-p750e-02-lp3 ~]# mount -o loop ./install.img /mnt/test
    [root@ibm-p750e-02-lp3 ~]# dd if=/dev/loop0 of=/dev/null
    dd: reading `/dev/loop0': Input/output error
    277376+0 records in
    277376+0 records out
    142016512 bytes (142 MB) copied, 0.9465 s, 150 MB/s
    
    In dmesg, you'll find the following:
    
    squashfs: version 4.0 (2009/01/31) Phillip Lougher
    [   43.106012] attempt to access beyond end of device
    [   43.106029] loop0: rw=0, want=277410, limit=277408
    [   43.106039] Buffer I/O error on device loop0, logical block 138704
    [   43.106053] attempt to access beyond end of device
    [   43.106057] loop0: rw=0, want=277412, limit=277408
    [   43.106061] Buffer I/O error on device loop0, logical block 138705
    [   43.106066] attempt to access beyond end of device
    [   43.106070] loop0: rw=0, want=277414, limit=277408
    [   43.106073] Buffer I/O error on device loop0, logical block 138706
    [   43.106078] attempt to access beyond end of device
    [   43.106081] loop0: rw=0, want=277416, limit=277408
    [   43.106085] Buffer I/O error on device loop0, logical block 138707
    [   43.106089] attempt to access beyond end of device
    [   43.106093] loop0: rw=0, want=277418, limit=277408
    [   43.106096] Buffer I/O error on device loop0, logical block 138708
    [   43.106101] attempt to access beyond end of device
    [   43.106104] loop0: rw=0, want=277420, limit=277408
    [   43.106108] Buffer I/O error on device loop0, logical block 138709
    [   43.106112] attempt to access beyond end of device
    [   43.106116] loop0: rw=0, want=277422, limit=277408
    [   43.106120] Buffer I/O error on device loop0, logical block 138710
    [   43.106124] attempt to access beyond end of device
    [   43.106128] loop0: rw=0, want=277424, limit=277408
    [   43.106131] Buffer I/O error on device loop0, logical block 138711
    [   43.106135] attempt to access beyond end of device
    [   43.106139] loop0: rw=0, want=277426, limit=277408
    [   43.106143] Buffer I/O error on device loop0, logical block 138712
    [   43.106147] attempt to access beyond end of device
    [   43.106151] loop0: rw=0, want=277428, limit=277408
    [   43.106154] Buffer I/O error on device loop0, logical block 138713
    [   43.106158] attempt to access beyond end of device
    [   43.106162] loop0: rw=0, want=277430, limit=277408
    [   43.106166] attempt to access beyond end of device
    [   43.106169] loop0: rw=0, want=277432, limit=277408
    ...
    [   43.106307] attempt to access beyond end of device
    [   43.106311] loop0: rw=0, want=277470, limit=2774
    
    Squashfs manages to read in the end block(s) of the disk during the
    mount operation.  Then, when dd reads the block device, it leads to
    block_read_full_page being called with buffers that are beyond end of
    disk, but are marked as mapped.  Thus, it would end up submitting read
    I/O against them, resulting in the errors mentioned above.  I fixed the
    problem by modifying init_page_buffers to only set the buffer mapped if
    it fell inside of i_size.
    
    Cheers,
    Jeff
    
    Signed-off-by: Jeff Moyer <jmoyer@redhat.com>
    Acked-by: Nick Piggin <npiggin@kernel.dk>
    
    --
    
    Changes from v1->v2: re-used max_block, as suggested by Nick Piggin.
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e08f6a20a5bb..ba11c30f302d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -70,7 +70,7 @@ static void bdev_inode_switch_bdi(struct inode *inode,
 	spin_unlock(&dst->wb.list_lock);
 }
 
-static sector_t max_block(struct block_device *bdev)
+sector_t blkdev_max_block(struct block_device *bdev)
 {
 	sector_t retval = ~((sector_t)0);
 	loff_t sz = i_size_read(bdev->bd_inode);
@@ -163,7 +163,7 @@ static int
 blkdev_get_block(struct inode *inode, sector_t iblock,
 		struct buffer_head *bh, int create)
 {
-	if (iblock >= max_block(I_BDEV(inode))) {
+	if (iblock >= blkdev_max_block(I_BDEV(inode))) {
 		if (create)
 			return -EIO;
 
@@ -185,7 +185,7 @@ static int
 blkdev_get_blocks(struct inode *inode, sector_t iblock,
 		struct buffer_head *bh, int create)
 {
-	sector_t end_block = max_block(I_BDEV(inode));
+	sector_t end_block = blkdev_max_block(I_BDEV(inode));
 	unsigned long max_blocks = bh->b_size >> inode->i_blkbits;
 
 	if ((iblock + max_blocks) > end_block) {

commit dbd5768f87ff6fb0a4fe09c4d7b6c4a24de99430
Author: Jan Kara <jack@suse.cz>
Date:   Thu May 3 14:48:02 2012 +0200

    vfs: Rename end_writeback() to clear_inode()
    
    After we moved inode_sync_wait() from end_writeback() it doesn't make sense
    to call the function end_writeback() anymore. Rename it to clear_inode()
    which well says what the function really does - set I_CLEAR flag.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Fengguang Wu <fengguang.wu@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e08f6a20a5bb..d8a7959a9654 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -487,7 +487,7 @@ static void bdev_evict_inode(struct inode *inode)
 	struct list_head *p;
 	truncate_inode_pages(&inode->i_data, 0);
 	invalidate_inode_buffers(inode); /* is it needed here? */
-	end_writeback(inode);
+	clear_inode(inode);
 	spin_lock(&bdev_lock);
 	while ( (p = bdev->bd_inodes.next) != &bdev->bd_inodes ) {
 		__bd_forget(list_entry(p, struct inode, i_devices));

commit b502bd1152472dc1b98c60434f23c23b280c7b94
Author: Muthu Kumar <muthu.lkml@gmail.com>
Date:   Fri Mar 23 15:01:50 2012 -0700

    magic.h: move some FS magic numbers into magic.h
    
    - Move open-coded filesystem magic numbers into magic.h
    
    - Rearrange magic.h so that the filesystem-related constants are grouped
      together.
    
    Signed-off-by: Muthukumar R <muthur@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a9ff3000b83d..e08f6a20a5bb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -16,6 +16,7 @@
 #include <linux/blkdev.h>
 #include <linux/module.h>
 #include <linux/blkpg.h>
+#include <linux/magic.h>
 #include <linux/buffer_head.h>
 #include <linux/swap.h>
 #include <linux/pagevec.h>
@@ -506,7 +507,7 @@ static const struct super_operations bdev_sops = {
 static struct dentry *bd_mount(struct file_system_type *fs_type,
 	int flags, const char *dev_name, void *data)
 {
-	return mount_pseudo(fs_type, "bdev:", &bdev_sops, NULL, 0x62646576);
+	return mount_pseudo(fs_type, "bdev:", &bdev_sops, NULL, BDEVFS_MAGIC);
 }
 
 static struct file_system_type bd_type = {

commit 16c0cfa425b8e1488f7a1873bd112a7a099325f0
Merge: 94574d9a4c23 072611ed1f29
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Mon Mar 19 12:12:19 2012 -0400

    Merge branch 'stable/cleancache.v13' into linux-next
    
    * stable/cleancache.v13:
      mm: cleancache: Use __read_mostly as appropiate.
      mm: cleancache: report statistics via debugfs instead of sysfs.
      mm: zcache/tmem/cleancache: s/flush/invalidate/
      mm: cleancache: s/flush/invalidate/

commit fe316bf2d5847bc5dd975668671a7b1067603bc7
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Fri Mar 2 10:38:33 2012 +0100

    block: Fix NULL pointer dereference in sd_revalidate_disk
    
    Since 2.6.39 (1196f8b), when a driver returns -ENOMEDIUM for open(),
    __blkdev_get() calls rescan_partitions() to remove
    in-kernel partition structures and raise KOBJ_CHANGE uevent.
    
    However it ends up calling driver's revalidate_disk without open
    and could cause oops.
    
    In the case of SCSI:
    
      process A                  process B
      ----------------------------------------------
      sys_open
        __blkdev_get
          sd_open
            returns -ENOMEDIUM
                                 scsi_remove_device
                                   <scsi_device torn down>
          rescan_partitions
            sd_revalidate_disk
              <oops>
    Oopses are reported here:
    http://marc.info/?l=linux-scsi&m=132388619710052
    
    This patch separates the partition invalidation from rescan_partitions()
    and use it for -ENOMEDIUM case.
    
    Reported-by: Huajun Li <huajun.li.lee@gmail.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: stable@kernel.org
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0e575d1304b4..5e9f198f7712 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1183,8 +1183,12 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			 * The latter is necessary to prevent ghost
 			 * partitions on a removed medium.
 			 */
-			if (bdev->bd_invalidated && (!ret || ret == -ENOMEDIUM))
-				rescan_partitions(disk, bdev);
+			if (bdev->bd_invalidated) {
+				if (!ret)
+					rescan_partitions(disk, bdev);
+				else if (ret == -ENOMEDIUM)
+					invalidate_partitions(disk, bdev);
+			}
 			if (ret)
 				goto out_clear;
 		} else {
@@ -1214,8 +1218,12 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (bdev->bd_disk->fops->open)
 				ret = bdev->bd_disk->fops->open(bdev, mode);
 			/* the same as first opener case, read comment there */
-			if (bdev->bd_invalidated && (!ret || ret == -ENOMEDIUM))
-				rescan_partitions(bdev->bd_disk, bdev);
+			if (bdev->bd_invalidated) {
+				if (!ret)
+					rescan_partitions(bdev->bd_disk, bdev);
+				else if (ret == -ENOMEDIUM)
+					invalidate_partitions(bdev->bd_disk, bdev);
+			}
 			if (ret)
 				goto out_unlock_bdev;
 		}

commit 3167760f83899ccda312b9ad9306ec9e5dda06d4
Author: Dan Magenheimer <dan.magenheimer@oracle.com>
Date:   Wed Sep 21 11:56:28 2011 -0400

    mm: cleancache: s/flush/invalidate/
    
    Per akpm suggestions alter the use of the term flush to be
    invalidate. The next patch will do this across all MM.
    
    This change is completely cosmetic.
    
    [v9: akpm@linux-foundation.org: change "flush" to "invalidate", part 3]
    
    Signed-off-by: Dan Magenheimer <dan.magenheimer@oracle.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Jan Beulich <JBeulich@novell.com>
    Reviewed-by: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Rik Riel <riel@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    [v10: Fixed  fs: move code out of buffer.c conflict change]
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 69a5b6fbee2b..d6d5f29463cd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -110,7 +110,7 @@ void invalidate_bdev(struct block_device *bdev)
 	/* 99% of the time, we don't need to flush the cleancache on the bdev.
 	 * But, for the strange corners, lets be cautious
 	 */
-	cleancache_flush_inode(mapping);
+	cleancache_invalidate_inode(mapping);
 }
 EXPORT_SYMBOL(invalidate_bdev);
 

commit 87192a2a49c475cf322cb143e0fa63b0102d8567
Author: Andi Kleen <ak@linux.intel.com>
Date:   Thu Jan 12 17:20:34 2012 -0800

    vfs: cache request_queue in struct block_device
    
    This makes it possible to get from the inode to the request_queue with one
    less cache miss.  Used in followon optimization.
    
    The livetime of the pointer is the same as the gendisk.
    
    This assumes that the queue will always stay the same in the gendisk while
    it's visible to block_devices.  I think that's safe correct?
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jeff Moyer <jmoyer@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index afe74dda632b..0e575d1304b4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1139,6 +1139,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
+		bdev->bd_queue = disk->queue;
 		bdev->bd_contains = bdev;
 		if (!partno) {
 			struct backing_dev_info *bdi;
@@ -1159,6 +1160,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 					disk_put_part(bdev->bd_part);
 					bdev->bd_part = NULL;
 					bdev->bd_disk = NULL;
+					bdev->bd_queue = NULL;
 					mutex_unlock(&bdev->bd_mutex);
 					disk_unblock_events(disk);
 					put_disk(disk);
@@ -1232,6 +1234,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	disk_put_part(bdev->bd_part);
 	bdev->bd_disk = NULL;
 	bdev->bd_part = NULL;
+	bdev->bd_queue = NULL;
 	bdev_inode_switch_bdi(bdev->bd_inode, &default_backing_dev_info);
 	if (bdev != bdev->bd_contains)
 		__blkdev_put(bdev->bd_contains, mode, 1);

commit ace8577aeb438025ecf642f5eda3aa551d251951
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Tue Jan 10 02:43:59 2012 +0300

    block_dev: Suppress bdev_cache_init() kmemleak warninig
    
    Kmemleak reports the following warning in bdev_cache_init()
    [    0.003738] kmemleak: Object 0xffff880153035200 (size 256):
    [    0.003823] kmemleak:   comm "swapper/0", pid 0, jiffies 4294667299
    [    0.003909] kmemleak:   min_count = 1
    [    0.003988] kmemleak:   count = 0
    [    0.004066] kmemleak:   flags = 0x1
    [    0.004144] kmemleak:   checksum = 0
    [    0.004224] kmemleak:   backtrace:
    [    0.004303]      [<ffffffff814755ac>] kmemleak_alloc+0x21/0x3e
    [    0.004446]      [<ffffffff811100ba>] kmem_cache_alloc+0xca/0x1dc
    [    0.004592]      [<ffffffff811371b1>] alloc_vfsmnt+0x1f/0x198
    [    0.004736]      [<ffffffff811375c5>] vfs_kern_mount+0x36/0xd2
    [    0.004879]      [<ffffffff8113929a>] kern_mount_data+0x18/0x32
    [    0.005025]      [<ffffffff81ab9075>] bdev_cache_init+0x51/0x81
    [    0.005169]      [<ffffffff81ab8abf>] vfs_caches_init+0x101/0x10d
    [    0.005313]      [<ffffffff81a9bae3>] start_kernel+0x344/0x383
    [    0.005456]      [<ffffffff81a9b2a7>] x86_64_start_reservations+0xae/0xb2
    [    0.005602]      [<ffffffff81a9b3ad>] x86_64_start_kernel+0x102/0x111
    [    0.005747]      [<ffffffffffffffff>] 0xffffffffffffffff
    [    0.008653] kmemleak: Trying to color unknown object at 0xffff880153035220 as Grey
    [    0.008754] Pid: 0, comm: swapper/0 Not tainted 3.3.0-rc0-dbg-04200-g8180888-dirty #888
    [    0.008856] Call Trace:
    [    0.008934]  [<ffffffff81118704>] ? find_and_get_object+0x44/0x118
    [    0.009023]  [<ffffffff81118fe6>] paint_ptr+0x57/0x8f
    [    0.009109]  [<ffffffff81475935>] kmemleak_not_leak+0x23/0x42
    [    0.009195]  [<ffffffff81ab9096>] bdev_cache_init+0x72/0x81
    [    0.009282]  [<ffffffff81ab8abf>] vfs_caches_init+0x101/0x10d
    [    0.009368]  [<ffffffff81a9bae3>] start_kernel+0x344/0x383
    [    0.009466]  [<ffffffff81a9b2a7>] x86_64_start_reservations+0xae/0xb2
    [    0.009555]  [<ffffffff81a9b140>] ? early_idt_handlers+0x140/0x140
    [    0.009643]  [<ffffffff81a9b3ad>] x86_64_start_kernel+0x102/0x111
    
    due to attempt to mark pointer to `struct vfsmount' as a gray object, which
    is embedded into `struct mount' returned from alloc_vfsmnt().
    
    Make `bd_mnt' static, avoiding need to tell kmemleak to mark it gray, as
    suggested by Al Viro.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 69a5b6fbee2b..afe74dda632b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -25,7 +25,6 @@
 #include <linux/uio.h>
 #include <linux/namei.h>
 #include <linux/log2.h>
-#include <linux/kmemleak.h>
 #include <linux/cleancache.h>
 #include <asm/uaccess.h>
 #include "internal.h"
@@ -521,7 +520,7 @@ static struct super_block *blockdev_superblock __read_mostly;
 void __init bdev_cache_init(void)
 {
 	int err;
-	struct vfsmount *bd_mnt;
+	static struct vfsmount *bd_mnt;
 
 	bdev_cachep = kmem_cache_create("bdev_cache", sizeof(struct bdev_inode),
 			0, (SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|
@@ -533,12 +532,7 @@ void __init bdev_cache_init(void)
 	bd_mnt = kern_mount(&bd_type);
 	if (IS_ERR(bd_mnt))
 		panic("Cannot create bdev pseudo-fs");
-	/*
-	 * This vfsmount structure is only used to obtain the
-	 * blockdev_superblock, so tell kmemleak not to report it.
-	 */
-	kmemleak_not_leak(bd_mnt);
-	blockdev_superblock = bd_mnt->mnt_sb;	/* For writeback */
+	blockdev_superblock = bd_mnt->mnt_sb;   /* For writeback */
 }
 
 /*

commit ff01bb4832651c6d25ac509a06a10fcbd75c461c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Sep 16 02:31:11 2011 -0400

    fs: move code out of buffer.c
    
    Move invalidate_bdev, block_sync_page into fs/block_dev.c.  Export
    kill_bdev as well, so brd doesn't have to open code it.  Reduce
    buffer_head.h requirement accordingly.
    
    Removed a rather large comment from invalidate_bdev, as it looked a bit
    obsolete to bother moving.  The small comment replacing it says enough.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7866cdd9fe70..69a5b6fbee2b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -17,6 +17,7 @@
 #include <linux/module.h>
 #include <linux/blkpg.h>
 #include <linux/buffer_head.h>
+#include <linux/swap.h>
 #include <linux/pagevec.h>
 #include <linux/writeback.h>
 #include <linux/mpage.h>
@@ -25,6 +26,7 @@
 #include <linux/namei.h>
 #include <linux/log2.h>
 #include <linux/kmemleak.h>
+#include <linux/cleancache.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 
@@ -82,13 +84,35 @@ static sector_t max_block(struct block_device *bdev)
 }
 
 /* Kill _all_ buffers and pagecache , dirty or not.. */
-static void kill_bdev(struct block_device *bdev)
+void kill_bdev(struct block_device *bdev)
 {
-	if (bdev->bd_inode->i_mapping->nrpages == 0)
+	struct address_space *mapping = bdev->bd_inode->i_mapping;
+
+	if (mapping->nrpages == 0)
 		return;
+
 	invalidate_bh_lrus();
-	truncate_inode_pages(bdev->bd_inode->i_mapping, 0);
+	truncate_inode_pages(mapping, 0);
 }	
+EXPORT_SYMBOL(kill_bdev);
+
+/* Invalidate clean unused buffers and pagecache. */
+void invalidate_bdev(struct block_device *bdev)
+{
+	struct address_space *mapping = bdev->bd_inode->i_mapping;
+
+	if (mapping->nrpages == 0)
+		return;
+
+	invalidate_bh_lrus();
+	lru_add_drain_all();	/* make sure all lru add caches are flushed */
+	invalidate_mapping_pages(mapping, 0, -1);
+	/* 99% of the time, we don't need to flush the cleancache on the bdev.
+	 * But, for the strange corners, lets be cautious
+	 */
+	cleancache_flush_inode(mapping);
+}
+EXPORT_SYMBOL(invalidate_bdev);
 
 int set_blocksize(struct block_device *bdev, int size)
 {

commit 6b520e0565422966cdf1c3759bd73df77b0f248c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Dec 12 15:51:45 2011 -0500

    vfs: fix the stupidity with i_dentry in inode destructors
    
    Seeing that just about every destructor got that INIT_LIST_HEAD() copied into
    it, there is no point whatsoever keeping this INIT_LIST_HEAD in inode_init_once();
    the cost of taking it into inode_init_always() will be negligible for pipes
    and sockets and negative for everything else.  Not to mention the removal of
    boilerplate code from ->destroy_inode() instances...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4b322a58a513..7866cdd9fe70 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -425,7 +425,6 @@ static void bdev_i_callback(struct rcu_head *head)
 	struct inode *inode = container_of(head, struct inode, i_rcu);
 	struct bdev_inode *bdi = BDEV_I(inode);
 
-	INIT_LIST_HEAD(&inode->i_dentry);
 	kmem_cache_free(bdev_cachep, bdi);
 }
 

commit f47ec3f28354795f000c14bf18ed967ec81a3ec3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 21 21:15:42 2011 -0500

    trim fs/internal.h
    
    some stuff in there can actually become static; some belongs to pnode.h
    as it's a private interface between namespace.c and pnode.c...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b07f1da1de4e..4b322a58a513 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -493,7 +493,7 @@ static struct file_system_type bd_type = {
 	.kill_sb	= kill_anon_super,
 };
 
-struct super_block *blockdev_superblock __read_mostly;
+static struct super_block *blockdev_superblock __read_mostly;
 
 void __init bdev_cache_init(void)
 {
@@ -639,6 +639,11 @@ static struct block_device *bd_acquire(struct inode *inode)
 	return bdev;
 }
 
+static inline int sb_is_blkdev_sb(struct super_block *sb)
+{
+	return sb == blockdev_superblock;
+}
+
 /* Call when you free inode */
 
 void bd_forget(struct inode *inode)

commit 3d0a8d10cfb4cc3d1877c29a866ee7d8a46aa2fa
Merge: b4fdcb02f1e3 a0eda62552eb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 4 17:22:14 2011 -0700

    Merge branch 'for-3.2/drivers' of git://git.kernel.dk/linux-block
    
    * 'for-3.2/drivers' of git://git.kernel.dk/linux-block: (30 commits)
      virtio-blk: use ida to allocate disk index
      hpsa: add small delay when using PCI Power Management to reset for kump
      cciss: add small delay when using PCI Power Management to reset for kump
      xen/blkback: Fix two races in the handling of barrier requests.
      xen/blkback: Check for proper operation.
      xen/blkback: Fix the inhibition to map pages when discarding sector ranges.
      xen/blkback: Report VBD_WSECT (wr_sect) properly.
      xen/blkback: Support 'feature-barrier' aka old-style BARRIER requests.
      xen-blkfront: plug device number leak in xlblk_init() error path
      xen-blkfront: If no barrier or flush is supported, use invalid operation.
      xen-blkback: use kzalloc() in favor of kmalloc()+memset()
      xen-blkback: fixed indentation and comments
      xen-blkfront: fix a deadlock while handling discard response
      xen-blkfront: Handle discard requests.
      xen-blkback: Implement discard requests ('feature-discard')
      xen-blkfront: add BLKIF_OP_DISCARD and discard request struct
      drivers/block/loop.c: remove unnecessary bdev argument from loop_clr_fd()
      drivers/block/loop.c: emit uevent on auto release
      drivers/block/cpqarray.c: use pci_dev->revision
      loop: always allow userspace partitions and optionally support automatic scanning
      ...
    
    Fic up trivial header file includsion conflict in drivers/block/loop.c

commit 523e1d399ce0e23bec562abe2b2f8d297af81161
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Oct 19 14:31:07 2011 +0200

    block: make gendisk hold a reference to its queue
    
    The following command sequence triggers an oops.
    
    # mount /dev/sdb1 /mnt
    # echo 1 > /sys/class/scsi_device/0\:0\:1\:0/device/delete
    # umount /mnt
    
     general protection fault: 0000 [#1] PREEMPT SMP
     CPU 2
     Modules linked in:
    
     Pid: 791, comm: umount Not tainted 3.1.0-rc3-work+ #8 Bochs Bochs
     RIP: 0010:[<ffffffff810d0879>]  [<ffffffff810d0879>] __lock_acquire+0x389/0x1d60
    ...
     Call Trace:
      [<ffffffff810d2845>] lock_acquire+0x95/0x140
      [<ffffffff81aed87b>] _raw_spin_lock+0x3b/0x50
      [<ffffffff811573bc>] bdi_lock_two+0x5c/0x70
      [<ffffffff811c2f6c>] bdev_inode_switch_bdi+0x4c/0xf0
      [<ffffffff811c3fcb>] __blkdev_put+0x11b/0x1d0
      [<ffffffff811c4010>] __blkdev_put+0x160/0x1d0
      [<ffffffff811c40df>] blkdev_put+0x5f/0x190
      [<ffffffff8118f18d>] kill_block_super+0x4d/0x80
      [<ffffffff8118f4a5>] deactivate_locked_super+0x45/0x70
      [<ffffffff8119003a>] deactivate_super+0x4a/0x70
      [<ffffffff811ac4ad>] mntput_no_expire+0xed/0x130
      [<ffffffff811acf2e>] sys_umount+0x7e/0x3a0
      [<ffffffff81aeeeab>] system_call_fastpath+0x16/0x1b
    
    This is because bdev holds on to disk but disk doesn't pin the
    associated queue.  If a SCSI device is removed while the device is
    still open, the sdev puts the base reference to the queue on release.
    When the bdev is finally released, the associated queue is already
    gone along with the bdi and bdev_inode_switch_bdi() ends up
    dereferencing already freed bdi.
    
    Even if it were not for this bug, disk not holding onto the associated
    queue is very unusual and error-prone.
    
    Fix it by making add_disk() take an extra reference to its queue and
    put it on disk_release() and ensuring that disk and its fops owner are
    put in that order after all accesses to the disk and queue are
    complete.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: stable@kernel.org
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 95f786ec7f08..1c44b8d54504 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1085,6 +1085,7 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 {
 	struct gendisk *disk;
+	struct module *owner;
 	int ret;
 	int partno;
 	int perm = 0;
@@ -1110,6 +1111,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	disk = get_gendisk(bdev->bd_dev, &partno);
 	if (!disk)
 		goto out;
+	owner = disk->fops->owner;
 
 	disk_block_events(disk);
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
@@ -1137,8 +1139,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 					bdev->bd_disk = NULL;
 					mutex_unlock(&bdev->bd_mutex);
 					disk_unblock_events(disk);
-					module_put(disk->fops->owner);
 					put_disk(disk);
+					module_put(owner);
 					goto restart;
 				}
 			}
@@ -1194,8 +1196,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				goto out_unlock_bdev;
 		}
 		/* only one opener holds refs to the module and disk */
-		module_put(disk->fops->owner);
 		put_disk(disk);
+		module_put(owner);
 	}
 	bdev->bd_openers++;
 	if (for_part)
@@ -1215,8 +1217,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
  out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
 	disk_unblock_events(disk);
-	module_put(disk->fops->owner);
 	put_disk(disk);
+	module_put(owner);
  out:
 	bdput(bdev);
 
@@ -1442,14 +1444,15 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 	if (!bdev->bd_openers) {
 		struct module *owner = disk->fops->owner;
 
-		put_disk(disk);
-		module_put(owner);
 		disk_put_part(bdev->bd_part);
 		bdev->bd_part = NULL;
 		bdev->bd_disk = NULL;
 		if (bdev != bdev->bd_contains)
 			victim = bdev->bd_contains;
 		bdev->bd_contains = NULL;
+
+		put_disk(disk);
+		module_put(owner);
 	}
 	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);

commit 94007751bb02797ba87bac7aacee2731ac2039a3
Author: NeilBrown <neilb@suse.de>
Date:   Sat Sep 10 17:20:21 2011 +1000

    Avoid dereferencing a 'request_queue' after last close.
    
    On the last close of an 'md' device which as been stopped, the device
    is destroyed and in particular the request_queue is freed.  The free
    is done in a separate thread so it might happen a short time later.
    
    __blkdev_put calls bdev_inode_switch_bdi *after* ->release has been
    called.
    
    Since commit f758eeabeb96f878c860e8f110f94ec8820822a9
    bdev_inode_switch_bdi will dereference the 'old' bdi, which lives
    inside a request_queue, to get a spin lock.  This causes the last
    close on an md device to sometime take a spin_lock which lives in
    freed memory - which results in an oops.
    
    So move the called to bdev_inode_switch_bdi before the call to
    ->release.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Acked-by: Wu Fengguang <fengguang.wu@intel.com>
    Cc: stable@kernel.org
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ff77262e887c..95f786ec7f08 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1429,6 +1429,11 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		WARN_ON_ONCE(bdev->bd_holders);
 		sync_blockdev(bdev);
 		kill_bdev(bdev);
+		/* ->release can cause the old bdi to disappear,
+		 * so must switch it out first
+		 */
+		bdev_inode_switch_bdi(bdev->bd_inode,
+					&default_backing_dev_info);
 	}
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)
@@ -1442,8 +1447,6 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		disk_put_part(bdev->bd_part);
 		bdev->bd_part = NULL;
 		bdev->bd_disk = NULL;
-		bdev_inode_switch_bdi(bdev->bd_inode,
-					&default_backing_dev_info);
 		if (bdev != bdev->bd_contains)
 			victim = bdev->bd_contains;
 		bdev->bd_contains = NULL;

commit d27769ec3df1a8de9ca450d2dcd72d1ab259ba32
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 23 20:01:04 2011 +0200

    block: add GENHD_FL_NO_PART_SCAN
    
    There are cases where suppressing partition scan is useful - e.g. for
    lo devices and pseudo SATA devices which advertise to be a disk but
    get upset on partition scan (some port multiplier control devices show
    such behavior).
    
    This patch adds GENHD_FL_NO_PART_SCAN which suppresses partition scan
    regardless of the number of possible partitions.  disk_partitionable()
    is renamed to disk_part_scan_enabled() as suppressing partition scan
    doesn't imply the device can't be partitioned using
    BLKPG_ADD/DEL_PARTITION calls from userland.  show_partition() now
    directly tests disk_max_parts() to maintain backward-compatibility.
    
    -v2: Updated to make it clear that only partition scan is suppressed
         not partitioning itself as suggested by Kay Sievers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ff77262e887c..0bed0d4588dd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -971,7 +971,7 @@ static void flush_disk(struct block_device *bdev, bool kill_dirty)
 
 	if (!bdev->bd_disk)
 		return;
-	if (disk_partitionable(bdev->bd_disk))
+	if (disk_part_scan_enabled(bdev->bd_disk))
 		bdev->bd_invalidated = 1;
 }
 

commit da5aa861bea09197e6ae4d7c46618616064891e4
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Tue Aug 2 02:17:48 2011 +0200

    fix block device fallout from ->fsync() changes
    
    blkdev_fsync() needs to write pages in pagecache...
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f28680553288..ff77262e887c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -387,6 +387,10 @@ int blkdev_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 	struct inode *bd_inode = filp->f_mapping->host;
 	struct block_device *bdev = I_BDEV(bd_inode);
 	int error;
+	
+	error = filemap_write_and_wait_range(filp->f_mapping, start, end);
+	if (error)
+		return error;
 
 	/*
 	 * There is no need to serialise calls to blkdev_issue_flush with

commit 782b94cdf577b4df1feb376f372dccc28e66a771
Author: Lachlan McIlroy <lmcilroy@redhat.com>
Date:   Thu Jun 30 11:01:45 2011 +1000

    block: initialise bd_super in bdget()
    
    bd_super is currently reset to NULL in kill_block_super() so we rely on previous
    users of the block_device object to initialise this value for the next user.
    This quirk was exposed on RHEL5 when a third party filesystem did not always use
    kill_block_super() and therefore bd_super wasn't being reset when a block_device
    object was recycled within the cache.  This may not be a problem upstream but
    makes sense to be defensive.
    
    Signed-off-by: Lachlan McIlroy <lmcilroy@redhat.com>
    Reviewed-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f55aad4d1611..f28680553288 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -552,6 +552,7 @@ struct block_device *bdget(dev_t dev)
 
 	if (inode->i_state & I_NEW) {
 		bdev->bd_contains = NULL;
+		bdev->bd_super = NULL;
 		bdev->bd_inode = inode;
 		bdev->bd_block_size = (1 << inode->i_blkbits);
 		bdev->bd_part_count = 0;

commit f01ef569cddb1a8627b1c6b3a134998ad1cf4b22
Merge: a93a13292710 bcff25fc8aa4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 26 10:39:54 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/wfg/writeback
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/wfg/writeback: (27 commits)
      mm: properly reflect task dirty limits in dirty_exceeded logic
      writeback: don't busy retry writeback on new/freeing inodes
      writeback: scale IO chunk size up to half device bandwidth
      writeback: trace global_dirty_state
      writeback: introduce max-pause and pass-good dirty limits
      writeback: introduce smoothed global dirty limit
      writeback: consolidate variable names in balance_dirty_pages()
      writeback: show bdi write bandwidth in debugfs
      writeback: bdi write bandwidth estimation
      writeback: account per-bdi accumulated written pages
      writeback: make writeback_control.nr_to_write straight
      writeback: skip tmpfs early in balance_dirty_pages_ratelimited_nr()
      writeback: trace event writeback_queue_io
      writeback: trace event writeback_single_inode
      writeback: remove .nonblocking and .encountered_congestion
      writeback: remove writeback_control.more_io
      writeback: skip balance_dirty_pages() for in-memory fs
      writeback: add bdi_dirty_limit() kernel-doc
      writeback: avoid extra sync work at enqueue time
      writeback: elevate queue_io() into wb_writeback()
      ...
    
    Fix up trivial conflicts in fs/fs-writeback.c and mm/filemap.c

commit 096a705bbc080a4041636d07514560da8d78acbe
Merge: fea80311a939 5757a6d76cdf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 25 10:33:36 2011 -0700

    Merge branch 'for-3.1/core' of git://git.kernel.dk/linux-block
    
    * 'for-3.1/core' of git://git.kernel.dk/linux-block: (24 commits)
      block: strict rq_affinity
      backing-dev: use synchronize_rcu_expedited instead of synchronize_rcu
      block: fix patch import error in max_discard_sectors check
      block: reorder request_queue to remove 64 bit alignment padding
      CFQ: add think time check for group
      CFQ: add think time check for service tree
      CFQ: move think time check variables to a separate struct
      fixlet: Remove fs_excl from struct task.
      cfq: Remove special treatment for metadata rqs.
      block: document blk_plug list access
      block: avoid building too big plug list
      compat_ioctl: fix make headers_check regression
      block: eliminate potential for infinite loop in blkdev_issue_discard
      compat_ioctl: fix warning caused by qemu
      block: flush MEDIA_CHANGE from drivers on close(2)
      blk-throttle: Make total_nr_queued unsigned
      block: Add __attribute__((format(printf...) and fix fallout
      fs/partitions/check.c: make local symbols static
      block:remove some spare spaces in genhd.c
      block:fix the comment error in blkdev.h
      ...

commit 02c24a82187d5a628c68edfe71ae60dc135cd178
Author: Josef Bacik <josef@redhat.com>
Date:   Sat Jul 16 20:44:56 2011 -0400

    fs: push i_mutex and filemap_write_and_wait down into ->fsync() handlers
    
    Btrfs needs to be able to control how filemap_write_and_wait_range() is called
    in fsync to make it less of a painful operation, so push down taking i_mutex and
    the calling of filemap_write_and_wait() down into the ->fsync() handlers.  Some
    file systems can drop taking the i_mutex altogether it seems, like ext3 and
    ocfs2.  For correctness sake I just pushed everything down in all cases to make
    sure that we keep the current behavior the same for everybody, and then each
    individual fs maintainer can make up their mind about what to do from there.
    Thanks,
    
    Acked-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 966617a422d9..9fb0b15331d3 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -378,7 +378,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
 	return retval;
 }
 	
-int blkdev_fsync(struct file *filp, int datasync)
+int blkdev_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 {
 	struct inode *bd_inode = filp->f_mapping->host;
 	struct block_device *bdev = I_BDEV(bd_inode);
@@ -389,14 +389,10 @@ int blkdev_fsync(struct file *filp, int datasync)
 	 * i_mutex and doing so causes performance issues with concurrent
 	 * O_SYNC writers to a block device.
 	 */
-	mutex_unlock(&bd_inode->i_mutex);
-
 	error = blkdev_issue_flush(bdev, GFP_KERNEL, NULL);
 	if (error == -EOPNOTSUPP)
 		error = 0;
 
-	mutex_lock(&bd_inode->i_mutex);
-
 	return error;
 }
 EXPORT_SYMBOL(blkdev_fsync);

commit 06222e491e663dac939f04b125c9dc52126a75c4
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 18 13:21:38 2011 -0400

    fs: handle SEEK_HOLE/SEEK_DATA properly in all fs's that define their own llseek
    
    This converts everybody to handle SEEK_HOLE/SEEK_DATA properly.  In some cases
    we just return -EINVAL, in others we do the normal generic thing, and in others
    we're simply making sure that the properly due-dilligence is done.  For example
    in NFS/CIFS we need to make sure the file size is update properly for the
    SEEK_HOLE and SEEK_DATA case, but since it calls the generic llseek stuff itself
    that is all we have to do.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 610e8e0b04b8..966617a422d9 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -355,20 +355,25 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
 	mutex_lock(&bd_inode->i_mutex);
 	size = i_size_read(bd_inode);
 
+	retval = -EINVAL;
 	switch (origin) {
-		case 2:
+		case SEEK_END:
 			offset += size;
 			break;
-		case 1:
+		case SEEK_CUR:
 			offset += file->f_pos;
+		case SEEK_SET:
+			break;
+		default:
+			goto out;
 	}
-	retval = -EINVAL;
 	if (offset >= 0 && offset <= size) {
 		if (offset != file->f_pos) {
 			file->f_pos = offset;
 		}
 		retval = offset;
 	}
+out:
 	mutex_unlock(&bd_inode->i_mutex);
 	return retval;
 }

commit 85ef06d1d252f6a2e73b678591ab71caad4667bb
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jul 1 16:17:47 2011 +0200

    block: flush MEDIA_CHANGE from drivers on close(2)
    
    Currently, only open(2) is defined as the 'clearing' point.  It has
    two roles - first, it's an acknowledgement from userland indicating
    that the event has been received and kernel can clear pending states
    and proceed to generate more events.  Secondly, it's passed on to
    device drivers as a hint indicating that a synchronization point has
    been reached and it might want to take a deeper look at the device.
    
    The latter currently is only used by sr which uses two different
    mechanisms - GET_EVENT_MEDIA_STATUS_NOTIFICATION and TEST_UNIT_READY
    to discover events, where the former is lighter weight and safe to be
    used repeatedly but may not provide full coverage.  Among other
    things, GET_EVENT can't detect media removal while TUR can.
    
    This patch makes close(2) - blkdev_put() - indicate clearing hint for
    MEDIA_CHANGE to drivers.  disk_check_events() is renamed to
    disk_flush_events() and updated to take @mask for events to flush
    which is or'd to ev->clearing and will be passed to the driver on the
    next ->check_events() invocation.
    
    This change makes sr generate MEDIA_CHANGE when media is ejected from
    userland - e.g. with eject(1).
    
    Note: Given the current usage, it seems @clearing hint is needlessly
    complex.  disk_clear_events() can simply clear all events and the hint
    can be boolean @flush.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 610e8e0b04b8..6ff7f070016f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1447,6 +1447,8 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 
 int blkdev_put(struct block_device *bdev, fmode_t mode)
 {
+	mutex_lock(&bdev->bd_mutex);
+
 	if (mode & FMODE_EXCL) {
 		bool bdev_free;
 
@@ -1455,7 +1457,6 @@ int blkdev_put(struct block_device *bdev, fmode_t mode)
 		 * are protected with bdev_lock.  bd_mutex is to
 		 * synchronize disk_holder unlinking.
 		 */
-		mutex_lock(&bdev->bd_mutex);
 		spin_lock(&bdev_lock);
 
 		WARN_ON_ONCE(--bdev->bd_holders < 0);
@@ -1473,17 +1474,21 @@ int blkdev_put(struct block_device *bdev, fmode_t mode)
 		 * If this was the last claim, remove holder link and
 		 * unblock evpoll if it was a write holder.
 		 */
-		if (bdev_free) {
-			if (bdev->bd_write_holder) {
-				disk_unblock_events(bdev->bd_disk);
-				disk_check_events(bdev->bd_disk);
-				bdev->bd_write_holder = false;
-			}
+		if (bdev_free && bdev->bd_write_holder) {
+			disk_unblock_events(bdev->bd_disk);
+			bdev->bd_write_holder = false;
 		}
-
-		mutex_unlock(&bdev->bd_mutex);
 	}
 
+	/*
+	 * Trigger event checking and tell drivers to flush MEDIA_CHANGE
+	 * event.  This is to ensure detection of media removal commanded
+	 * from userland - e.g. eject(1).
+	 */
+	disk_flush_events(bdev->bd_disk, DISK_EVENT_MEDIA_CHANGE);
+
+	mutex_unlock(&bdev->bd_mutex);
+
 	return __blkdev_put(bdev, mode, 0);
 }
 EXPORT_SYMBOL(blkdev_put);

commit d4c208b86b8be4254eba0e74071496e599f94639
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Jun 13 12:45:48 2011 +0200

    block: use the passed in @bdev when claiming if partno is zero
    
    6b4517a791 (block: implement bd_claiming and claiming block)
    introduced claiming block to support O_EXCL blkdev opens properly.
    
    bd_start_claiming() looks up the part 0 bdev and starts claiming
    block.  The function assumed that there is only one part 0 bdev and
    always used bdget_disk(disk, 0) to look it up; unfortunately, this
    isn't true for some drivers (floppy) which use multiple block devices
    to denote different operating parameters for the same physical device.
    There can be multiple part 0 bdev's for the same device number.
    
    This incorrect assumption caused the wrong bdev to be used during
    claiming leading to unbalanced bd_holders as reported in the following
    bug.
    
      https://bugzilla.kernel.org/show_bug.cgi?id=28522
    
    This patch updates bd_start_claiming() such that it uses the bdev
    specified as argument if its partno is zero.
    
    Note that this means that different bdev's can be used for the same
    device and O_EXCL check can be effectively bypassed.  It has always
    been broken that way and floppy is fortunately on its way out.  Leave
    that breakage alone.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Alex Villacis Lasso <avillaci@ceibo.fiec.espol.edu.ec>
    Tested-by: Alex Villacis Lasso <avillaci@ceibo.fiec.espol.edu.ec>
    Cc: stable@kernel.org   # >= v2.6.36
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1a2421f908f0..610e8e0b04b8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -762,7 +762,19 @@ static struct block_device *bd_start_claiming(struct block_device *bdev,
 	if (!disk)
 		return ERR_PTR(-ENXIO);
 
-	whole = bdget_disk(disk, 0);
+	/*
+	 * Normally, @bdev should equal what's returned from bdget_disk()
+	 * if partno is 0; however, some drivers (floppy) use multiple
+	 * bdev's for the same physical device and @bdev may be one of the
+	 * aliases.  Keep @bdev if partno is 0.  This means claimer
+	 * tracking is broken for those devices but it has always been that
+	 * way.
+	 */
+	if (partno)
+		whole = bdget_disk(disk, 0);
+	else
+		whole = bdgrab(bdev);
+
 	module_put(disk->fops->owner);
 	put_disk(disk);
 	if (!whole)

commit f758eeabeb96f878c860e8f110f94ec8820822a9
Author: Christoph Hellwig <hch@infradead.org>
Date:   Thu Apr 21 18:19:44 2011 -0600

    writeback: split inode_wb_list_lock into bdi_writeback.list_lock
    
    Split the global inode_wb_list_lock into a per-bdi_writeback list_lock,
    as it's currently the most contended lock in the system for metadata
    heavy workloads.  It won't help for single-filesystem workloads for
    which we'll need the I/O-less balance_dirty_pages, but at least we
    can dedicate a cpu to spinning on each bdi now for larger systems.
    
    Based on earlier patches from Nick Piggin and Dave Chinner.
    
    It reduces lock contentions to 1/4 in this test case:
    10 HDD JBOD, 100 dd on each disk, XFS, 6GB ram
    
    lock_stat version 0.3
    -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                                  class name    con-bounces    contentions   waittime-min   waittime-max waittime-total    acq-bounces   acquisitions   holdtime-min   holdtime-max holdtime-total
    -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    vanilla 2.6.39-rc3:
                          inode_wb_list_lock:         42590          44433           0.12         147.74      144127.35         252274         886792           0.08         121.34      917211.23
                          ------------------
                          inode_wb_list_lock              2          [<ffffffff81165da5>] bdev_inode_switch_bdi+0x29/0x85
                          inode_wb_list_lock             34          [<ffffffff8115bd0b>] inode_wb_list_del+0x22/0x49
                          inode_wb_list_lock          12893          [<ffffffff8115bb53>] __mark_inode_dirty+0x170/0x1d0
                          inode_wb_list_lock          10702          [<ffffffff8115afef>] writeback_single_inode+0x16d/0x20a
                          ------------------
                          inode_wb_list_lock              2          [<ffffffff81165da5>] bdev_inode_switch_bdi+0x29/0x85
                          inode_wb_list_lock             19          [<ffffffff8115bd0b>] inode_wb_list_del+0x22/0x49
                          inode_wb_list_lock           5550          [<ffffffff8115bb53>] __mark_inode_dirty+0x170/0x1d0
                          inode_wb_list_lock           8511          [<ffffffff8115b4ad>] writeback_sb_inodes+0x10f/0x157
    
    2.6.39-rc3 + patch:
                    &(&wb->list_lock)->rlock:         11383          11657           0.14         151.69       40429.51          90825         527918           0.11         145.90      556843.37
                    ------------------------
                    &(&wb->list_lock)->rlock             10          [<ffffffff8115b189>] inode_wb_list_del+0x5f/0x86
                    &(&wb->list_lock)->rlock           1493          [<ffffffff8115b1ed>] writeback_inodes_wb+0x3d/0x150
                    &(&wb->list_lock)->rlock           3652          [<ffffffff8115a8e9>] writeback_sb_inodes+0x123/0x16f
                    &(&wb->list_lock)->rlock           1412          [<ffffffff8115a38e>] writeback_single_inode+0x17f/0x223
                    ------------------------
                    &(&wb->list_lock)->rlock              3          [<ffffffff8110b5af>] bdi_lock_two+0x46/0x4b
                    &(&wb->list_lock)->rlock              6          [<ffffffff8115b189>] inode_wb_list_del+0x5f/0x86
                    &(&wb->list_lock)->rlock           2061          [<ffffffff8115af97>] __mark_inode_dirty+0x173/0x1cf
                    &(&wb->list_lock)->rlock           2629          [<ffffffff8115a8e9>] writeback_sb_inodes+0x123/0x16f
    
    hughd@google.com: fix recursive lock when bdi_lock_two() is called with new the same as old
    akpm@linux-foundation.org: cleanup bdev_inode_switch_bdi() comment
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Wu Fengguang <fengguang.wu@intel.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1a2421f908f0..3c9a03e51b62 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -44,24 +44,28 @@ inline struct block_device *I_BDEV(struct inode *inode)
 {
 	return &BDEV_I(inode)->bdev;
 }
-
 EXPORT_SYMBOL(I_BDEV);
 
 /*
- * move the inode from it's current bdi to the a new bdi. if the inode is dirty
- * we need to move it onto the dirty list of @dst so that the inode is always
- * on the right list.
+ * Move the inode from its current bdi to a new bdi. If the inode is dirty we
+ * need to move it onto the dirty list of @dst so that the inode is always on
+ * the right list.
  */
 static void bdev_inode_switch_bdi(struct inode *inode,
 			struct backing_dev_info *dst)
 {
-	spin_lock(&inode_wb_list_lock);
+	struct backing_dev_info *old = inode->i_data.backing_dev_info;
+
+	if (unlikely(dst == old))		/* deadlock avoidance */
+		return;
+	bdi_lock_two(&old->wb, &dst->wb);
 	spin_lock(&inode->i_lock);
 	inode->i_data.backing_dev_info = dst;
 	if (inode->i_state & I_DIRTY)
 		list_move(&inode->i_wb_list, &dst->wb.b_dirty);
 	spin_unlock(&inode->i_lock);
-	spin_unlock(&inode_wb_list_lock);
+	spin_unlock(&old->wb.list_lock);
+	spin_unlock(&dst->wb.list_lock);
 }
 
 static sector_t max_block(struct block_device *bdev)

commit 4c49ff3fe128ca68dabd07537415c419ad7f82f9
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jun 1 08:27:41 2011 +0200

    block: blkdev_get() should access ->bd_disk only after success
    
    d4dc210f69 (block: don't block events on excl write for non-optical
    devices) added dereferencing of bdev->bd_disk to test
    GENHD_FL_BLOCK_EVENTS_ON_EXCL_WRITE; however, bdev->bd_disk can be
    %NULL if open failed which can lead to an oops.
    
    Test the flag after testing open was successful, not before.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: David Miller <davem@davemloft.net>
    Tested-by: David Miller <davem@davemloft.net>
    Cc: stable@kernel.org
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1f2b19978333..1a2421f908f0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1272,8 +1272,8 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 		 * individual writeable reference is too fragile given the
 		 * way @mode is used in blkdev_get/put().
 		 */
-		if ((disk->flags & GENHD_FL_BLOCK_EVENTS_ON_EXCL_WRITE) &&
-		    !res && (mode & FMODE_WRITE) && !bdev->bd_write_holder) {
+		if (!res && (mode & FMODE_WRITE) && !bdev->bd_write_holder &&
+		    (disk->flags & GENHD_FL_BLOCK_EVENTS_ON_EXCL_WRITE)) {
 			bdev->bd_write_holder = true;
 			disk_block_events(disk);
 		}

commit 7e69723fef8771a9d57bd27d36281d756130b4b5
Author: Tejun Heo <tj@kernel.org>
Date:   Mon May 23 13:26:07 2011 +0200

    block: move bd_set_size() above rescan_partitions() in __blkdev_get()
    
    02e352287a4 (block: rescan partitions on invalidated devices on
    -ENOMEDIA too) relocated partition rescan above explicit bd_set_size()
    to simplify condition check.  As rescan_partitions() does its own bdev
    size setting, this doesn't break anything; however,
    rescan_partitions() prints out the following messages when adjusting
    bdev size, which can be confusing.
    
      sda: detected capacity change from 0 to 146815737856
      sdb: detected capacity change from 0 to 146815737856
    
    This patch restores the original order and remove the warning
    messages.
    
    stable: Please apply together with 02e352287a4 (block: rescan
            partitions on invalidated devices on -ENOMEDIA too).
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Tony Luck <tony.luck@gmail.com>
    Tested-by: Tony Luck <tony.luck@gmail.com>
    Cc: stable@kernel.org
    
    Stable note: 2.6.39 only.
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d7c2e0fddc6f..1f2b19978333 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1120,6 +1120,15 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 					goto restart;
 				}
 			}
+
+			if (!ret && !bdev->bd_openers) {
+				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
+				bdi = blk_get_backing_dev_info(bdev);
+				if (bdi == NULL)
+					bdi = &default_backing_dev_info;
+				bdev_inode_switch_bdi(bdev->bd_inode, bdi);
+			}
+
 			/*
 			 * If the device is invalidated, rescan partition
 			 * if open succeeded or failed with -ENOMEDIUM.
@@ -1130,14 +1139,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				rescan_partitions(disk, bdev);
 			if (ret)
 				goto out_clear;
-
-			if (!bdev->bd_openers) {
-				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
-				bdi = blk_get_backing_dev_info(bdev);
-				if (bdi == NULL)
-					bdi = &default_backing_dev_info;
-				bdev_inode_switch_bdi(bdev->bd_inode, bdi);
-			}
 		} else {
 			struct block_device *whole;
 			whole = bdget_disk(disk, 0);

commit d4dc210f69bcb0b4bef5a83b1c323817be89bad1
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Apr 21 20:54:46 2011 +0200

    block: don't block events on excl write for non-optical devices
    
    Disk event code automatically blocks events on excl write.  This is
    primarily to avoid issuing polling commands while burning is in
    progress.  This behavior doesn't fit other types of devices with
    removeable media where polling commands don't have adverse side
    effects and door locking usually doesn't exist.
    
    This patch introduces new genhd flag which controls the auto-blocking
    behavior and uses it to enable auto-blocking only on optical devices.
    
    Note for stable: 2.6.38 and later only
    
    Cc: stable@kernel.org
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 257b00e98428..d7c2e0fddc6f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1237,6 +1237,8 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 	res = __blkdev_get(bdev, mode, 0);
 
 	if (whole) {
+		struct gendisk *disk = whole->bd_disk;
+
 		/* finish claiming */
 		mutex_lock(&bdev->bd_mutex);
 		spin_lock(&bdev_lock);
@@ -1263,15 +1265,16 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 		spin_unlock(&bdev_lock);
 
 		/*
-		 * Block event polling for write claims.  Any write
-		 * holder makes the write_holder state stick until all
-		 * are released.  This is good enough and tracking
-		 * individual writeable reference is too fragile given
-		 * the way @mode is used in blkdev_get/put().
+		 * Block event polling for write claims if requested.  Any
+		 * write holder makes the write_holder state stick until
+		 * all are released.  This is good enough and tracking
+		 * individual writeable reference is too fragile given the
+		 * way @mode is used in blkdev_get/put().
 		 */
-		if (!res && (mode & FMODE_WRITE) && !bdev->bd_write_holder) {
+		if ((disk->flags & GENHD_FL_BLOCK_EVENTS_ON_EXCL_WRITE) &&
+		    !res && (mode & FMODE_WRITE) && !bdev->bd_write_holder) {
 			bdev->bd_write_holder = true;
-			disk_block_events(bdev->bd_disk);
+			disk_block_events(disk);
 		}
 
 		mutex_unlock(&bdev->bd_mutex);

commit 1196f8b814f32cd04df334abf47648c2a9fd8324
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Apr 21 20:54:45 2011 +0200

    block: rescan partitions on invalidated devices on -ENOMEDIA too
    
    __blkdev_get() doesn't rescan partitions if disk->fops->open() fails,
    which leads to ghost partition devices lingering after medimum removal
    is known to both the kernel and userland.  The behavior also creates a
    subtle inconsistency where O_NONBLOCK open, which doesn't fail even if
    there's no medium, clears the ghots partitions, which is exploited to
    work around the problem from userland.
    
    Fix it by updating __blkdev_get() to issue partition rescan after
    -ENOMEDIA too.
    
    This was reported in the following bz.
    
     https://bugzilla.kernel.org/show_bug.cgi?id=13029
    
    Note for stable: 2.6.38 and later only
    
    Cc: stable@kernel.org
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: David Zeuthen <zeuthen@gmail.com>
    Reported-by: Martin Pitt <martin.pitt@ubuntu.com>
    Reported-by: Kay Sievers <kay.sievers@vrfy.org>
    Tested-by: Kay Sievers <kay.sievers@vrfy.org>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 5147bdd3b8e1..257b00e98428 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1102,6 +1102,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (!bdev->bd_part)
 				goto out_clear;
 
+			ret = 0;
 			if (disk->fops->open) {
 				ret = disk->fops->open(bdev, mode);
 				if (ret == -ERESTARTSYS) {
@@ -1118,9 +1119,18 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 					put_disk(disk);
 					goto restart;
 				}
-				if (ret)
-					goto out_clear;
 			}
+			/*
+			 * If the device is invalidated, rescan partition
+			 * if open succeeded or failed with -ENOMEDIUM.
+			 * The latter is necessary to prevent ghost
+			 * partitions on a removed medium.
+			 */
+			if (bdev->bd_invalidated && (!ret || ret == -ENOMEDIUM))
+				rescan_partitions(disk, bdev);
+			if (ret)
+				goto out_clear;
+
 			if (!bdev->bd_openers) {
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
 				bdi = blk_get_backing_dev_info(bdev);
@@ -1128,8 +1138,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 					bdi = &default_backing_dev_info;
 				bdev_inode_switch_bdi(bdev->bd_inode, bdi);
 			}
-			if (bdev->bd_invalidated)
-				rescan_partitions(disk, bdev);
 		} else {
 			struct block_device *whole;
 			whole = bdget_disk(disk, 0);
@@ -1153,13 +1161,14 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		}
 	} else {
 		if (bdev->bd_contains == bdev) {
-			if (bdev->bd_disk->fops->open) {
+			ret = 0;
+			if (bdev->bd_disk->fops->open)
 				ret = bdev->bd_disk->fops->open(bdev, mode);
-				if (ret)
-					goto out_unlock_bdev;
-			}
-			if (bdev->bd_invalidated)
+			/* the same as first opener case, read comment there */
+			if (bdev->bd_invalidated && (!ret || ret == -ENOMEDIUM))
 				rescan_partitions(bdev->bd_disk, bdev);
+			if (ret)
+				goto out_unlock_bdev;
 		}
 		/* only one opener holds refs to the module and disk */
 		module_put(disk->fops->owner);

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c1511c674f53..5147bdd3b8e1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -653,7 +653,7 @@ void bd_forget(struct inode *inode)
  * @whole: whole block device containing @bdev, may equal @bdev
  * @holder: holder trying to claim @bdev
  *
- * Test whther @bdev can be claimed by @holder.
+ * Test whether @bdev can be claimed by @holder.
  *
  * CONTEXT:
  * spin_lock(&bdev_lock).

commit d39dd11c3e6a7af5c20bfac40594db36cf270f42
Merge: 30f5b28e7f93 0b2d0724e26a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 24 19:01:30 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6:
      fs: simplify iget & friends
      fs: pull inode->i_lock up out of writeback_single_inode
      fs: rename inode_lock to inode_hash_lock
      fs: move i_wb_list out from under inode_lock
      fs: move i_sb_list out from under inode_lock
      fs: remove inode_lock from iput_final and prune_icache
      fs: Lock the inode LRU list separately
      fs: factor inode disposal
      fs: protect inode->i_state with inode->i_lock
      autofs4: Do not potentially dereference NULL pointer returned by fget() in autofs_dev_ioctl_setpipefd()
      autofs4 - remove autofs4_lock
      autofs4 - fix d_manage() return on rcu-walk
      autofs4 - fix autofs4_expire_indirect() traversal
      autofs4 - fix dentry leak in autofs4_expire_direct()
      autofs4 - reinstate last used update on access
      vfs - check non-mountpoint dentry might block in __follow_mount_rcu()

commit a66979abad090b2765a6c6790c9fdeab996833f2
Author: Dave Chinner <dchinner@redhat.com>
Date:   Tue Mar 22 22:23:41 2011 +1100

    fs: move i_wb_list out from under inode_lock
    
    Protect the inode writeback list with a new global lock
    inode_wb_list_lock and use it to protect the list manipulations and
    traversals. This lock replaces the inode_lock as the inodes on the
    list can be validity checked while holding the inode->i_lock and
    hence the inode_lock is no longer needed to protect the list.
    
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index bc39b18cf3d0..2bbc0e62102f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -55,13 +55,13 @@ EXPORT_SYMBOL(I_BDEV);
 static void bdev_inode_switch_bdi(struct inode *inode,
 			struct backing_dev_info *dst)
 {
-	spin_lock(&inode_lock);
+	spin_lock(&inode_wb_list_lock);
 	spin_lock(&inode->i_lock);
 	inode->i_data.backing_dev_info = dst;
 	if (inode->i_state & I_DIRTY)
 		list_move(&inode->i_wb_list, &dst->wb.b_dirty);
 	spin_unlock(&inode->i_lock);
-	spin_unlock(&inode_lock);
+	spin_unlock(&inode_wb_list_lock);
 }
 
 static sector_t max_block(struct block_device *bdev)

commit 250df6ed274d767da844a5d9f05720b804240197
Author: Dave Chinner <dchinner@redhat.com>
Date:   Tue Mar 22 22:23:36 2011 +1100

    fs: protect inode->i_state with inode->i_lock
    
    Protect inode state transitions and validity checks with the
    inode->i_lock. This enables us to make inode state transitions
    independently of the inode_lock and is the first step to peeling
    away the inode_lock from the code.
    
    This requires that __iget() is done atomically with i_state checks
    during list traversals so that we don't race with another thread
    marking the inode I_FREEING between the state check and grabbing the
    reference.
    
    Also remove the unlock_new_inode() memory barrier optimisation
    required to avoid taking the inode_lock when clearing I_NEW.
    Simplify the code by simply taking the inode->i_lock around the
    state change and wakeup. Because the wakeup is no longer tricky,
    remove the wake_up_inode() function and open code the wakeup where
    necessary.
    
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 889287019599..bc39b18cf3d0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -56,9 +56,11 @@ static void bdev_inode_switch_bdi(struct inode *inode,
 			struct backing_dev_info *dst)
 {
 	spin_lock(&inode_lock);
+	spin_lock(&inode->i_lock);
 	inode->i_data.backing_dev_info = dst;
 	if (inode->i_state & I_DIRTY)
 		list_move(&inode->i_wb_list, &dst->wb.b_dirty);
+	spin_unlock(&inode->i_lock);
 	spin_unlock(&inode_lock);
 }
 

commit 4345caba340f051e10847924fc078ae18ed6695c
Author: Dan Carpenter <error27@gmail.com>
Date:   Sat Mar 19 13:53:31 2011 +0100

    block: NULL dereference on error path in __blkdev_get()
    
    "disk" is always NULL when we goto out.  There was a check for this
    before, but it was removed in 69e02c59a7d9 "block: Don't check events
    while open is in progress".
    
    Signed-off-by: Dan Carpenter <error27@gmail.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@carl>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fbe05cbdd692..7d02afb2b7f4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1181,9 +1181,9 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
  out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
 	disk_unblock_events(disk);
- out:
 	module_put(disk->fops->owner);
 	put_disk(disk);
+ out:
 	bdput(bdev);
 
 	return ret;

commit 4c63f5646e405b5010cc9499419060bf2e838f5b
Merge: cafb0bfca1a7 69d60eb96ae8
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Thu Mar 10 08:58:35 2011 +0100

    Merge branch 'for-2.6.39/stack-plug' into for-2.6.39/core
    
    Conflicts:
            block/blk-core.c
            block/blk-flush.c
            drivers/md/raid1.c
            drivers/md/raid10.c
            drivers/md/raid5.c
            fs/nilfs2/btnode.c
            fs/nilfs2/mdt.c
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

commit 7eaceaccab5f40bbfda044629a6298616aeaed50
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Thu Mar 10 08:52:07 2011 +0100

    block: remove per-queue plugging
    
    Code has been converted over to the new explicit on-stack plugging,
    and delay users have been converted to use the new API for that.
    So lets kill off the old plugging along with aops->sync_page().
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4fb8a3431531..fffc2c672396 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1520,7 +1520,6 @@ static int blkdev_releasepage(struct page *page, gfp_t wait)
 static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
 	.writepage	= blkdev_writepage,
-	.sync_page	= block_sync_page,
 	.write_begin	= blkdev_write_begin,
 	.write_end	= blkdev_write_end,
 	.writepages	= generic_writepages,

commit 69e02c59a7d962dced8047401b81a8d897e1702e
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 9 19:54:27 2011 +0100

    block: Don't check events while open is in progress
    
    Not all block drivers clear events immediately after reporting.  Some
    do so in ->revalidate_disk() or other steps during ->open().  There is
    a slim chance event poll may happen between the clearing event check
    from check_disk_change() and the actual clearing of the events which
    would result in spurious events.
    
    Block event checks while block device open is in progress.  There is
    no need to kick explicit event check afterwards as events are always
    checked during open.
    
    -v2: The original patch could have called disk_unblock_events() with
         an already released or %NULL @disk causing oops.  Fixed by making
         sure references are put after disk_unblock_events() is called.
         It also makes the error path of __blkdev_get() a bit simpler.
         This problem was reported by Jens.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Kay Sievers <kay.sievers@vrfy.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7dd2c658d429..d42cad2757ae 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1087,6 +1087,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	if (!disk)
 		goto out;
 
+	disk_block_events(disk);
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
@@ -1108,10 +1109,11 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 					 */
 					disk_put_part(bdev->bd_part);
 					bdev->bd_part = NULL;
-					module_put(disk->fops->owner);
-					put_disk(disk);
 					bdev->bd_disk = NULL;
 					mutex_unlock(&bdev->bd_mutex);
+					disk_unblock_events(disk);
+					module_put(disk->fops->owner);
+					put_disk(disk);
 					goto restart;
 				}
 				if (ret)
@@ -1148,9 +1150,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
 		}
 	} else {
-		module_put(disk->fops->owner);
-		put_disk(disk);
-		disk = NULL;
 		if (bdev->bd_contains == bdev) {
 			if (bdev->bd_disk->fops->open) {
 				ret = bdev->bd_disk->fops->open(bdev, mode);
@@ -1160,11 +1159,15 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (bdev->bd_invalidated)
 				rescan_partitions(bdev->bd_disk, bdev);
 		}
+		/* only one opener holds refs to the module and disk */
+		module_put(disk->fops->owner);
+		put_disk(disk);
 	}
 	bdev->bd_openers++;
 	if (for_part)
 		bdev->bd_part_count++;
 	mutex_unlock(&bdev->bd_mutex);
+	disk_unblock_events(disk);
 	return 0;
 
  out_clear:
@@ -1177,9 +1180,9 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	bdev->bd_contains = NULL;
  out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
+	disk_unblock_events(disk);
  out:
-	if (disk)
-		module_put(disk->fops->owner);
+	module_put(disk->fops->owner);
 	put_disk(disk);
 	bdput(bdev);
 

commit 6936217cc7e58573026bdba25b1bfb778e8f2267
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 9 19:54:27 2011 +0100

    block: Don't check events on close unless it was blocked
    
    The block event mechanism currently always checks events when the
    device is being closed regardless of the open mode.  The intention was
    to allow detection of EJECT_REQUEST when a device is closed whether
    disk event polling is enabled or not.
    
    This is unnecessary as, for devices of interest, events are checked
    from either userland or kernel and in the former case ->check_events()
    is performed on open of each poll attempt anyway.  Furthermore, this
    unconditional event check on close makes the code susceptible to event
    loop if the block driver doesn't clear reported events correctly - an
    event triggers userland to open and close the device which in turn
    causes another event, rinse and repeat.
    
    Check events on close only if it was blocked by excl write open.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Kay Sievers <kay.sievers@vrfy.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fffdf86c1757..7dd2c658d429 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1448,13 +1448,11 @@ int blkdev_put(struct block_device *bdev, fmode_t mode)
 				disk_unblock_events(bdev->bd_disk);
 				disk_check_events(bdev->bd_disk);
 				bdev->bd_write_holder = false;
-			} else
-				disk_check_events(bdev->bd_disk);
+			}
 		}
 
 		mutex_unlock(&bdev->bd_mutex);
-	} else
-		disk_check_events(bdev->bd_disk);
+	}
 
 	return __blkdev_put(bdev, mode, 0);
 }

commit facc31ddc3570a3a0d8951c94f16b898e01b464d
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 9 19:54:27 2011 +0100

    block: Don't implicitly trigger event check on disk_unblock_events()
    
    Currently, disk_unblock_events() implicitly kick event check if the
    block count reaches zero.  This behavior is not described in the
    comment and hinders with future changes.  Make the unblocker
    explicitly check events by calling disk_check_events() as necessary.
    
    This patch doesn't cause any behavior difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Kay Sievers <kay.sievers@vrfy.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 889287019599..fffdf86c1757 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1446,6 +1446,7 @@ int blkdev_put(struct block_device *bdev, fmode_t mode)
 		if (bdev_free) {
 			if (bdev->bd_write_holder) {
 				disk_unblock_events(bdev->bd_disk);
+				disk_check_events(bdev->bd_disk);
 				bdev->bd_write_holder = false;
 			} else
 				disk_check_events(bdev->bd_disk);

commit e6eb5ce1b202ac9cdcfda5be559c9b9d8ec7542c
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Sat Feb 26 10:54:00 2011 -0800

    fs/block_dev.c: fix new kernel-doc warning
    
    Fix new kernel-doc warning in fs/block_dev.c:
    
    Warning(fs/block_dev.c:937): No description found for parameter 'kill_dirty'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f05bf16cd979..889287019599 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -928,6 +928,7 @@ EXPORT_SYMBOL_GPL(bd_unlink_disk_holder);
  * flush_disk - invalidates all buffer-cache entries on a disk
  *
  * @bdev:      struct block device to be flushed
+ * @kill_dirty: flag to guide handling of dirty inodes
  *
  * Invalidates all buffer-cache entries on a disk. It should be called
  * when a disk has been changed -- either by a media change or online

commit 638691a7a46a4ae9a7b56c603299e42d7f6e722e
Merge: 0a93ea2e897b f0b4f7e2f29a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 25 11:13:26 2011 -0800

    Merge branch 'for-linus' of git://neil.brown.name/md
    
    * 'for-linus' of git://neil.brown.name/md:
      md: Fix - again - partition detection when array becomes active
      Fix over-zealous flush_disk when changing device size.
      md: avoid spinlock problem in blk_throtl_exit
      md: correctly handle probe of an 'mdp' device.
      md: don't set_capacity before array is active.
      md: Fix raid1->raid0 takeover

commit e7407d1619713f4b1fdff3a485e1bd8e77bd480d
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Feb 24 09:56:32 2011 +0100

    block: bd_link_disk_holder() should hold on to holder_dir
    
    The new implementation of bd_link_disk_holder() added by 49731baa41d
    (block: restore multiple bd_link_disk_holder() support) didn't get an
    extra reference for the holder_dir kobject of the slave bdev; however,
    bdev kills holder_dir on removal, not release, so if the slave bdev is
    removed while there are holder links, the holder_dir will be destroyed
    while there still are holder links, which leads to oops later when
    bd_unlink_disk_order() tries to remove those links.
    
    Make bd_link_disk_holder() grab an extra reference for the slave's
    holder_dir and put it in bd_unlink_disk_holder().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: "Hawrylewicz Czarnowski, Przemyslaw" <przemyslaw.hawrylewicz.czarnowski@intel.com>
    Tested-by: "Hawrylewicz Czarnowski, Przemyslaw" <przemyslaw.hawrylewicz.czarnowski@intel.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4fb8a3431531..94d41db62004 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -873,6 +873,11 @@ int bd_link_disk_holder(struct block_device *bdev, struct gendisk *disk)
 	ret = add_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);
 	if (ret)
 		goto out_del;
+	/*
+	 * bdev could be deleted beneath us which would implicitly destroy
+	 * the holder directory.  Hold on to it.
+	 */
+	kobject_get(bdev->bd_part->holder_dir);
 
 	list_add(&holder->list, &bdev->bd_holder_disks);
 	goto out_unlock;
@@ -909,6 +914,7 @@ void bd_unlink_disk_holder(struct block_device *bdev, struct gendisk *disk)
 		del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
 		del_symlink(bdev->bd_part->holder_dir,
 			    &disk_to_dev(disk)->kobj);
+		kobject_put(bdev->bd_part->holder_dir);
 		list_del_init(&holder->list);
 		kfree(holder);
 	}

commit 93b270f76e7ef3b81001576860c2701931cdc78b
Author: NeilBrown <neilb@suse.de>
Date:   Thu Feb 24 17:25:47 2011 +1100

    Fix over-zealous flush_disk when changing device size.
    
    There are two cases when we call flush_disk.
    In one, the device has disappeared (check_disk_change) so any
    data will hold becomes irrelevant.
    In the oter, the device has changed size (check_disk_size_change)
    so data we hold may be irrelevant.
    
    In both cases it makes sense to discard any 'clean' buffers,
    so they will be read back from the device if needed.
    
    In the former case it makes sense to discard 'dirty' buffers
    as there will never be anywhere safe to write the data.  In the
    second case it *does*not* make sense to discard dirty buffers
    as that will lead to file system corruption when you simply enlarge
    the containing devices.
    
    flush_disk calls __invalidate_devices.
    __invalidate_device calls both invalidate_inodes and invalidate_bdev.
    
    invalidate_inodes *does* discard I_DIRTY inodes and this does lead
    to fs corruption.
    
    invalidate_bev *does*not* discard dirty pages, but I don't really care
    about that at present.
    
    So this patch adds a flag to __invalidate_device (calling it
    __invalidate_device2) to indicate whether dirty buffers should be
    killed, and this is passed to invalidate_inodes which can choose to
    skip dirty inodes.
    
    flusk_disk then passes true from check_disk_change and false from
    check_disk_size_change.
    
    dm avoids tripping over this problem by calling i_size_write directly
    rathher than using check_disk_size_change.
    
    md does use check_disk_size_change and so is affected.
    
    This regression was introduced by commit 608aeef17a which causes
    check_disk_size_change to call flush_disk, so it is suitable for any
    kernel since 2.6.27.
    
    Cc: stable@kernel.org
    Acked-by: Jeff Moyer <jmoyer@redhat.com>
    Cc: Andrew Patterson <andrew.patterson@hp.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 333a7bb4cb9c..5e23152d04ad 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -927,9 +927,9 @@ EXPORT_SYMBOL_GPL(bd_unlink_disk_holder);
  * when a disk has been changed -- either by a media change or online
  * resize.
  */
-static void flush_disk(struct block_device *bdev)
+static void flush_disk(struct block_device *bdev, bool kill_dirty)
 {
-	if (__invalidate_device(bdev)) {
+	if (__invalidate_device(bdev, kill_dirty)) {
 		char name[BDEVNAME_SIZE] = "";
 
 		if (bdev->bd_disk)
@@ -966,7 +966,7 @@ void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
 		       "%s: detected capacity change from %lld to %lld\n",
 		       name, bdev_size, disk_size);
 		i_size_write(bdev->bd_inode, disk_size);
-		flush_disk(bdev);
+		flush_disk(bdev, false);
 	}
 }
 EXPORT_SYMBOL(check_disk_size_change);
@@ -1019,7 +1019,7 @@ int check_disk_change(struct block_device *bdev)
 	if (!(events & DISK_EVENT_MEDIA_CHANGE))
 		return 0;
 
-	flush_disk(bdev);
+	flush_disk(bdev, true);
 	if (bdops->revalidate_disk)
 		bdops->revalidate_disk(bdev->bd_disk);
 	return 1;
@@ -1601,7 +1601,7 @@ struct block_device *lookup_bdev(const char *pathname)
 }
 EXPORT_SYMBOL(lookup_bdev);
 
-int __invalidate_device(struct block_device *bdev)
+int __invalidate_device(struct block_device *bdev, bool kill_dirty)
 {
 	struct super_block *sb = get_super(bdev);
 	int res = 0;
@@ -1614,7 +1614,7 @@ int __invalidate_device(struct block_device *bdev)
 		 * hold).
 		 */
 		shrink_dcache_sb(sb);
-		res = invalidate_inodes(sb);
+		res = invalidate_inodes(sb, kill_dirty);
 		drop_super(sb);
 	}
 	invalidate_bdev(bdev);

commit e51900f7d38cbcfb481d84567fd92540e7e1d23a
Author: Chuck Ebbert <cebbert@redhat.com>
Date:   Wed Feb 16 18:11:53 2011 -0500

    block: revert block_dev read-only check
    
    This reverts commit 75f1dc0d076d ("block: check bdev_read_only() from
    blkdev_get()").  That commit added stricter checking to make sure
    devices that were being used read-only were actually opened in that
    mode.
    
    It turns out that the change breaks a bunch of kernel code that opens
    block devices.  Affected systems include dm, md, and the loop device.
    Because strict checking for read-only opens of block devices was not
    done before this, the code that opens the devices was opening them
    read-write even if they were being used read-only.  Auditing all that
    code will take time, and new userspace packages for dm, mdadm, etc.
    will also be required.
    
    Signed-off-by: Chuck Ebbert <cebbert@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 333a7bb4cb9c..4fb8a3431531 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1215,12 +1215,6 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 
 	res = __blkdev_get(bdev, mode, 0);
 
-	/* __blkdev_get() may alter read only status, check it afterwards */
-	if (!res && (mode & FMODE_WRITE) && bdev_read_only(bdev)) {
-		__blkdev_put(bdev, mode, 0);
-		res = -EACCES;
-	}
-
 	if (whole) {
 		/* finish claiming */
 		mutex_lock(&bdev->bd_mutex);
@@ -1298,6 +1292,11 @@ struct block_device *blkdev_get_by_path(const char *path, fmode_t mode,
 	if (err)
 		return ERR_PTR(err);
 
+	if ((mode & FMODE_WRITE) && bdev_read_only(bdev)) {
+		blkdev_put(bdev, mode);
+		return ERR_PTR(-EACCES);
+	}
+
 	return bdev;
 }
 EXPORT_SYMBOL(blkdev_get_by_path);

commit 49731baa41df404c2c3f44555869ab387363af43
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jan 14 18:43:57 2011 +0100

    block: restore multiple bd_link_disk_holder() support
    
    Commit e09b457b (block: simplify holder symlink handling) incorrectly
    assumed that there is only one link at maximum.  dm may use multiple
    links and expects block layer to track reference count for each link,
    which is different from and unrelated to the exclusive device holder
    identified by @holder when the device is opened.
    
    Remove the single holder assumption and automatic removal of the link
    and revive the per-link reference count tracking.  The code
    essentially behaves the same as before commit e09b457b sans the
    unnecessary kobject reference count dancing.
    
    While at it, note that this facility should not be used by anyone else
    than the current ones.  Sysfs symlinks shouldn't be abused like this
    and the whole thing doesn't belong in the block layer at all.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Milan Broz <mbroz@redhat.com>
    Cc: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: linux-raid@vger.kernel.org
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fe3f59c14a02..333a7bb4cb9c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -432,6 +432,9 @@ static void init_once(void *foo)
 	mutex_init(&bdev->bd_mutex);
 	INIT_LIST_HEAD(&bdev->bd_inodes);
 	INIT_LIST_HEAD(&bdev->bd_list);
+#ifdef CONFIG_SYSFS
+	INIT_LIST_HEAD(&bdev->bd_holder_disks);
+#endif
 	inode_init_once(&ei->vfs_inode);
 	/* Initialize mutex for freeze. */
 	mutex_init(&bdev->bd_fsfreeze_mutex);
@@ -779,6 +782,23 @@ static struct block_device *bd_start_claiming(struct block_device *bdev,
 }
 
 #ifdef CONFIG_SYSFS
+struct bd_holder_disk {
+	struct list_head	list;
+	struct gendisk		*disk;
+	int			refcnt;
+};
+
+static struct bd_holder_disk *bd_find_holder_disk(struct block_device *bdev,
+						  struct gendisk *disk)
+{
+	struct bd_holder_disk *holder;
+
+	list_for_each_entry(holder, &bdev->bd_holder_disks, list)
+		if (holder->disk == disk)
+			return holder;
+	return NULL;
+}
+
 static int add_symlink(struct kobject *from, struct kobject *to)
 {
 	return sysfs_create_link(from, to, kobject_name(to));
@@ -794,6 +814,8 @@ static void del_symlink(struct kobject *from, struct kobject *to)
  * @bdev: the claimed slave bdev
  * @disk: the holding disk
  *
+ * DON'T USE THIS UNLESS YOU'RE ALREADY USING IT.
+ *
  * This functions creates the following sysfs symlinks.
  *
  * - from "slaves" directory of the holder @disk to the claimed @bdev
@@ -817,47 +839,83 @@ static void del_symlink(struct kobject *from, struct kobject *to)
  */
 int bd_link_disk_holder(struct block_device *bdev, struct gendisk *disk)
 {
+	struct bd_holder_disk *holder;
 	int ret = 0;
 
 	mutex_lock(&bdev->bd_mutex);
 
-	WARN_ON_ONCE(!bdev->bd_holder || bdev->bd_holder_disk);
+	WARN_ON_ONCE(!bdev->bd_holder);
 
 	/* FIXME: remove the following once add_disk() handles errors */
 	if (WARN_ON(!disk->slave_dir || !bdev->bd_part->holder_dir))
 		goto out_unlock;
 
-	ret = add_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
-	if (ret)
+	holder = bd_find_holder_disk(bdev, disk);
+	if (holder) {
+		holder->refcnt++;
 		goto out_unlock;
+	}
 
-	ret = add_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);
-	if (ret) {
-		del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
+	holder = kzalloc(sizeof(*holder), GFP_KERNEL);
+	if (!holder) {
+		ret = -ENOMEM;
 		goto out_unlock;
 	}
 
-	bdev->bd_holder_disk = disk;
+	INIT_LIST_HEAD(&holder->list);
+	holder->disk = disk;
+	holder->refcnt = 1;
+
+	ret = add_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
+	if (ret)
+		goto out_free;
+
+	ret = add_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);
+	if (ret)
+		goto out_del;
+
+	list_add(&holder->list, &bdev->bd_holder_disks);
+	goto out_unlock;
+
+out_del:
+	del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
+out_free:
+	kfree(holder);
 out_unlock:
 	mutex_unlock(&bdev->bd_mutex);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(bd_link_disk_holder);
 
-static void bd_unlink_disk_holder(struct block_device *bdev)
+/**
+ * bd_unlink_disk_holder - destroy symlinks created by bd_link_disk_holder()
+ * @bdev: the calimed slave bdev
+ * @disk: the holding disk
+ *
+ * DON'T USE THIS UNLESS YOU'RE ALREADY USING IT.
+ *
+ * CONTEXT:
+ * Might sleep.
+ */
+void bd_unlink_disk_holder(struct block_device *bdev, struct gendisk *disk)
 {
-	struct gendisk *disk = bdev->bd_holder_disk;
+	struct bd_holder_disk *holder;
 
-	bdev->bd_holder_disk = NULL;
-	if (!disk)
-		return;
+	mutex_lock(&bdev->bd_mutex);
 
-	del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
-	del_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);
+	holder = bd_find_holder_disk(bdev, disk);
+
+	if (!WARN_ON_ONCE(holder == NULL) && !--holder->refcnt) {
+		del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
+		del_symlink(bdev->bd_part->holder_dir,
+			    &disk_to_dev(disk)->kobj);
+		list_del_init(&holder->list);
+		kfree(holder);
+	}
+
+	mutex_unlock(&bdev->bd_mutex);
 }
-#else
-static inline void bd_unlink_disk_holder(struct block_device *bdev)
-{ }
+EXPORT_SYMBOL_GPL(bd_unlink_disk_holder);
 #endif
 
 /**
@@ -1380,7 +1438,6 @@ int blkdev_put(struct block_device *bdev, fmode_t mode)
 		 * unblock evpoll if it was a write holder.
 		 */
 		if (bdev_free) {
-			bd_unlink_disk_holder(bdev);
 			if (bdev->bd_write_holder) {
 				disk_unblock_events(bdev->bd_disk);
 				bdev->bd_write_holder = false;

commit 275220f0fcff1adf28a717076e00f575edf05fda
Merge: fe3c560b8a22 81c5e2ae33c4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 13 10:45:01 2011 -0800

    Merge branch 'for-2.6.38/core' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.38/core' of git://git.kernel.dk/linux-2.6-block: (43 commits)
      block: ensure that completion error gets properly traced
      blktrace: add missing probe argument to block_bio_complete
      block cfq: don't use atomic_t for cfq_group
      block cfq: don't use atomic_t for cfq_queue
      block: trace event block fix unassigned field
      block: add internal hd part table references
      block: fix accounting bug on cross partition merges
      kref: add kref_test_and_get
      bio-integrity: mark kintegrityd_wq highpri and CPU intensive
      block: make kblockd_workqueue smarter
      Revert "sd: implement sd_check_events()"
      block: Clean up exit_io_context() source code.
      Fix compile warnings due to missing removal of a 'ret' variable
      fs/block: type signature of major_to_index(int) to major_to_index(unsigned)
      block: convert !IS_ERR(p) && p to !IS_ERR_NOR_NULL(p)
      cfq-iosched: don't check cfqg in choose_service_tree()
      fs/splice: Pull buf->ops->confirm() from splice_from_pipe actors
      cdrom: export cdrom_check_events()
      sd: implement sd_check_events()
      sr: implement sr_check_events()
      ...

commit c74a1cbb3cac348f276fabc381758f5b0b4713b2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 12 16:59:34 2011 -0500

    pass default dentry_operations to mount_pseudo()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 771f23527010..88da70355aa3 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -473,7 +473,7 @@ static const struct super_operations bdev_sops = {
 static struct dentry *bd_mount(struct file_system_type *fs_type,
 	int flags, const char *dev_name, void *data)
 {
-	return mount_pseudo(fs_type, "bdev:", &bdev_sops, 0x62646576);
+	return mount_pseudo(fs_type, "bdev:", &bdev_sops, NULL, 0x62646576);
 }
 
 static struct file_system_type bd_type = {

commit fa0d7e3de6d6fc5004ad9dea0dd6b286af8f03e9
Author: Nick Piggin <npiggin@kernel.dk>
Date:   Fri Jan 7 17:49:49 2011 +1100

    fs: icache RCU free inodes
    
    RCU free the struct inode. This will allow:
    
    - Subsequent store-free path walking patch. The inode must be consulted for
      permissions when walking, so an RCU inode reference is a must.
    - sb_inode_list_lock to be moved inside i_lock because sb list walkers who want
      to take i_lock no longer need to take sb_inode_list_lock to walk the list in
      the first place. This will simplify and optimize locking.
    - Could remove some nested trylock loops in dcache code
    - Could potentially simplify things a bit in VM land. Do not need to take the
      page lock to follow page->mapping.
    
    The downsides of this is the performance cost of using RCU. In a simple
    creat/unlink microbenchmark, performance drops by about 10% due to inability to
    reuse cache-hot slab objects. As iterations increase and RCU freeing starts
    kicking over, this increases to about 20%.
    
    In cases where inode lifetimes are longer (ie. many inodes may be allocated
    during the average life span of a single inode), a lot of this cache reuse is
    not applicable, so the regression caused by this patch is smaller.
    
    The cache-hot regression could largely be avoided by using SLAB_DESTROY_BY_RCU,
    however this adds some complexity to list walking and store-free path walking,
    so I prefer to implement this at a later date, if it is shown to be a win in
    real situations. I haven't found a regression in any non-micro benchmark so I
    doubt it will be a problem.
    
    Signed-off-by: Nick Piggin <npiggin@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4230252fd689..771f23527010 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -409,13 +409,20 @@ static struct inode *bdev_alloc_inode(struct super_block *sb)
 	return &ei->vfs_inode;
 }
 
-static void bdev_destroy_inode(struct inode *inode)
+static void bdev_i_callback(struct rcu_head *head)
 {
+	struct inode *inode = container_of(head, struct inode, i_rcu);
 	struct bdev_inode *bdi = BDEV_I(inode);
 
+	INIT_LIST_HEAD(&inode->i_dentry);
 	kmem_cache_free(bdev_cachep, bdi);
 }
 
+static void bdev_destroy_inode(struct inode *inode)
+{
+	call_rcu(&inode->i_rcu, bdev_i_callback);
+}
+
 static void init_once(void *foo)
 {
 	struct bdev_inode *ei = (struct bdev_inode *) foo;

commit 77ea887e433ad8389d416826936c110fa7910f80
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Dec 8 20:57:37 2010 +0100

    implement in-kernel gendisk events handling
    
    Currently, media presence polling for removeable block devices is done
    from userland.  There are several issues with this.
    
    * Polling is done by periodically opening the device.  For SCSI
      devices, the command sequence generated by such action involves a
      few different commands including TEST_UNIT_READY.  This behavior,
      while perfectly legal, is different from Windows which only issues
      single command, GET_EVENT_STATUS_NOTIFICATION.  Unfortunately, some
      ATAPI devices lock up after being periodically queried such command
      sequences.
    
    * There is no reliable and unintrusive way for a userland program to
      tell whether the target device is safe for media presence polling.
      For example, polling for media presence during an on-going burning
      session can make it fail.  The polling program can avoid this by
      opening the device with O_EXCL but then it risks making a valid
      exclusive user of the device fail w/ -EBUSY.
    
    * Userland polling is unnecessarily heavy and in-kernel implementation
      is lighter and better coordinated (workqueue, timer slack).
    
    This patch implements framework for in-kernel disk event handling,
    which includes media presence polling.
    
    * bdops->check_events() is added, which supercedes ->media_changed().
      It should check whether there's any pending event and return if so.
      Currently, two events are defined - DISK_EVENT_MEDIA_CHANGE and
      DISK_EVENT_EJECT_REQUEST.  ->check_events() is guaranteed not to be
      called parallelly.
    
    * gendisk->events and ->async_events are added.  These should be
      initialized by block driver before passing the device to add_disk().
      The former contains the mask of all supported events and the latter
      the mask of all events which the device can report without polling.
      /sys/block/*/events[_async] export these to userland.
    
    * Kernel parameter block.events_dfl_poll_msecs controls the system
      polling interval (default is 0 which means disable) and
      /sys/block/*/events_poll_msecs control polling intervals for
      individual devices (default is -1 meaning use system setting).  Note
      that if a device can report all supported events asynchronously and
      its polling interval isn't explicitly set, the device won't be
      polled regardless of the system polling interval.
    
    * If a device is opened exclusively with write access, event checking
      is automatically disabled until all write exclusive accesses are
      released.
    
    * There are event 'clearing' events.  For example, both of currently
      defined events are cleared after the device has been successfully
      opened.  This information is passed to ->check_events() callback
      using @clearing argument as a hint.
    
    * Event checking is always performed from system_nrt_wq and timer
      slack is set to 25% for polling.
    
    * Nothing changes for drivers which implement ->media_changed() but
      not ->check_events().  Going forward, all drivers will be converted
      to ->check_events() and ->media_change() will be dropped.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Cc: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c1c1b8c3fb99..6017389711ee 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -948,10 +948,11 @@ int check_disk_change(struct block_device *bdev)
 {
 	struct gendisk *disk = bdev->bd_disk;
 	const struct block_device_operations *bdops = disk->fops;
+	unsigned int events;
 
-	if (!bdops->media_changed)
-		return 0;
-	if (!bdops->media_changed(bdev->bd_disk))
+	events = disk_clear_events(disk, DISK_EVENT_MEDIA_CHANGE |
+				   DISK_EVENT_EJECT_REQUEST);
+	if (!(events & DISK_EVENT_MEDIA_CHANGE))
 		return 0;
 
 	flush_disk(bdev);
@@ -1158,9 +1159,10 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 
 	if (whole) {
 		/* finish claiming */
+		mutex_lock(&bdev->bd_mutex);
 		spin_lock(&bdev_lock);
 
-		if (res == 0) {
+		if (!res) {
 			BUG_ON(!bd_may_claim(bdev, whole, holder));
 			/*
 			 * Note that for a whole device bd_holders
@@ -1180,6 +1182,20 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 		wake_up_bit(&whole->bd_claiming, 0);
 
 		spin_unlock(&bdev_lock);
+
+		/*
+		 * Block event polling for write claims.  Any write
+		 * holder makes the write_holder state stick until all
+		 * are released.  This is good enough and tracking
+		 * individual writeable reference is too fragile given
+		 * the way @mode is used in blkdev_get/put().
+		 */
+		if (!res && (mode & FMODE_WRITE) && !bdev->bd_write_holder) {
+			bdev->bd_write_holder = true;
+			disk_block_events(bdev->bd_disk);
+		}
+
+		mutex_unlock(&bdev->bd_mutex);
 		bdput(whole);
 	}
 
@@ -1353,12 +1369,23 @@ int blkdev_put(struct block_device *bdev, fmode_t mode)
 
 		spin_unlock(&bdev_lock);
 
-		/* if this was the last claim, holder link should go too */
-		if (bdev_free)
+		/*
+		 * If this was the last claim, remove holder link and
+		 * unblock evpoll if it was a write holder.
+		 */
+		if (bdev_free) {
 			bd_unlink_disk_holder(bdev);
+			if (bdev->bd_write_holder) {
+				disk_unblock_events(bdev->bd_disk);
+				bdev->bd_write_holder = false;
+			} else
+				disk_check_events(bdev->bd_disk);
+		}
 
 		mutex_unlock(&bdev->bd_mutex);
-	}
+	} else
+		disk_check_events(bdev->bd_disk);
+
 	return __blkdev_put(bdev, mode, 0);
 }
 EXPORT_SYMBOL(blkdev_put);

commit 451a3c24b0135bce54542009b5fde43846c7cf67
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Nov 17 16:26:55 2010 +0100

    BKL: remove extraneous #include <smp_lock.h>
    
    The big kernel lock has been removed from all these files at some point,
    leaving only the #include.
    
    Remove this too as a cleanup.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 06e8ff12b97c..4230252fd689 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -11,7 +11,6 @@
 #include <linux/slab.h>
 #include <linux/kmod.h>
 #include <linux/major.h>
-#include <linux/smp_lock.h>
 #include <linux/device_cgroup.h>
 #include <linux/highmem.h>
 #include <linux/blkdev.h>

commit d4d77629953eabd3c14f6fa5746f6b28babfc55f
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Nov 13 11:55:18 2010 +0100

    block: clean up blkdev_get() wrappers and their users
    
    After recent blkdev_get() modifications, open_by_devnum() and
    open_bdev_exclusive() are simple wrappers around blkdev_get().
    Replace them with blkdev_get_by_dev() and blkdev_get_by_path().
    
    blkdev_get_by_dev() is identical to open_by_devnum().
    blkdev_get_by_path() is slightly different in that it doesn't
    automatically add %FMODE_EXCL to @mode.
    
    All users are converted.  Most conversions are mechanical and don't
    introduce any behavior difference.  There are several exceptions.
    
    * btrfs now sets FMODE_EXCL in btrfs_device->mode, so there's no
      reason to OR it explicitly on blkdev_put().
    
    * gfs2, nilfs2 and the generic mount_bdev() now set FMODE_EXCL in
      sb->s_mode.
    
    * With the above changes, sb->s_mode now always should contain
      FMODE_EXCL.  WARN_ON_ONCE() added to kill_block_super() to detect
      errors.
    
    The new blkdev_get_*() functions are with proper docbook comments.
    While at it, add function description to blkdev_get() too.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Philipp Reisner <philipp.reisner@linbit.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Joern Engel <joern@lazybastard.org>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: KONISHI Ryusuke <konishi.ryusuke@lab.ntt.co.jp>
    Cc: reiserfs-devel@vger.kernel.org
    Cc: xfs-masters@oss.sgi.com
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 606a5259f87f..c1c1b8c3fb99 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -854,24 +854,6 @@ static inline void bd_unlink_disk_holder(struct block_device *bdev)
 { }
 #endif
 
-/*
- * Tries to open block device by device number.  Use it ONLY if you
- * really do not have anything better - i.e. when you are behind a
- * truly sucky interface and all you are given is a device number.  _Never_
- * to be used for internal purposes.  If you ever need it - reconsider
- * your API.
- */
-struct block_device *open_by_devnum(dev_t dev, fmode_t mode, void *holder)
-{
-	struct block_device *bdev = bdget(dev);
-	int err = -ENOMEM;
-	if (bdev)
-		err = blkdev_get(bdev, mode, holder);
-	return err ? ERR_PTR(err) : bdev;
-}
-
-EXPORT_SYMBOL(open_by_devnum);
-
 /**
  * flush_disk - invalidates all buffer-cache entries on a disk
  *
@@ -1132,6 +1114,25 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	return ret;
 }
 
+/**
+ * blkdev_get - open a block device
+ * @bdev: block_device to open
+ * @mode: FMODE_* mask
+ * @holder: exclusive holder identifier
+ *
+ * Open @bdev with @mode.  If @mode includes %FMODE_EXCL, @bdev is
+ * open with exclusive access.  Specifying %FMODE_EXCL with %NULL
+ * @holder is invalid.  Exclusive opens may nest for the same @holder.
+ *
+ * On success, the reference count of @bdev is unchanged.  On failure,
+ * @bdev is put.
+ *
+ * CONTEXT:
+ * Might sleep.
+ *
+ * RETURNS:
+ * 0 on success, -errno on failure.
+ */
 int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 {
 	struct block_device *whole = NULL;
@@ -1186,6 +1187,80 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 }
 EXPORT_SYMBOL(blkdev_get);
 
+/**
+ * blkdev_get_by_path - open a block device by name
+ * @path: path to the block device to open
+ * @mode: FMODE_* mask
+ * @holder: exclusive holder identifier
+ *
+ * Open the blockdevice described by the device file at @path.  @mode
+ * and @holder are identical to blkdev_get().
+ *
+ * On success, the returned block_device has reference count of one.
+ *
+ * CONTEXT:
+ * Might sleep.
+ *
+ * RETURNS:
+ * Pointer to block_device on success, ERR_PTR(-errno) on failure.
+ */
+struct block_device *blkdev_get_by_path(const char *path, fmode_t mode,
+					void *holder)
+{
+	struct block_device *bdev;
+	int err;
+
+	bdev = lookup_bdev(path);
+	if (IS_ERR(bdev))
+		return bdev;
+
+	err = blkdev_get(bdev, mode, holder);
+	if (err)
+		return ERR_PTR(err);
+
+	return bdev;
+}
+EXPORT_SYMBOL(blkdev_get_by_path);
+
+/**
+ * blkdev_get_by_dev - open a block device by device number
+ * @dev: device number of block device to open
+ * @mode: FMODE_* mask
+ * @holder: exclusive holder identifier
+ *
+ * Open the blockdevice described by device number @dev.  @mode and
+ * @holder are identical to blkdev_get().
+ *
+ * Use it ONLY if you really do not have anything better - i.e. when
+ * you are behind a truly sucky interface and all you are given is a
+ * device number.  _Never_ to be used for internal purposes.  If you
+ * ever need it - reconsider your API.
+ *
+ * On success, the returned block_device has reference count of one.
+ *
+ * CONTEXT:
+ * Might sleep.
+ *
+ * RETURNS:
+ * Pointer to block_device on success, ERR_PTR(-errno) on failure.
+ */
+struct block_device *blkdev_get_by_dev(dev_t dev, fmode_t mode, void *holder)
+{
+	struct block_device *bdev;
+	int err;
+
+	bdev = bdget(dev);
+	if (!bdev)
+		return ERR_PTR(-ENOMEM);
+
+	err = blkdev_get(bdev, mode, holder);
+	if (err)
+		return ERR_PTR(err);
+
+	return bdev;
+}
+EXPORT_SYMBOL(blkdev_get_by_dev);
+
 static int blkdev_open(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev;
@@ -1436,34 +1511,6 @@ struct block_device *lookup_bdev(const char *pathname)
 }
 EXPORT_SYMBOL(lookup_bdev);
 
-/**
- * open_bdev_exclusive  -  open a block device by name and set it up for use
- *
- * @path:	special file representing the block device
- * @mode:	FMODE_... combination to pass be used
- * @holder:	owner for exclusion
- *
- * Open the blockdevice described by the special file at @path, claim it
- * for the @holder.
- */
-struct block_device *open_bdev_exclusive(const char *path, fmode_t mode, void *holder)
-{
-	struct block_device *bdev;
-	int error;
-
-	bdev = lookup_bdev(path);
-	if (IS_ERR(bdev))
-		return bdev;
-
-	error = blkdev_get(bdev, mode | FMODE_EXCL, holder);
-	if (error)
-		return ERR_PTR(error);
-
-	return bdev;
-}
-
-EXPORT_SYMBOL(open_bdev_exclusive);
-
 int __invalidate_device(struct block_device *bdev)
 {
 	struct super_block *sb = get_super(bdev);

commit 75f1dc0d076d1c1168f2115f1941ea627d38bd5a
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Nov 13 11:55:17 2010 +0100

    block: check bdev_read_only() from blkdev_get()
    
    bdev read-only status can be queried using bdev_read_only() and may
    change while the device is being opened.  Enforce it by checking it
    from blkdev_get() after open succeeds.
    
    This makes bdev_read_only() check in open_bdev_exclusive() and
    fsg_lun_open() unnecessary.  Drop them.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: David Brownell <dbrownell@users.sourceforge.net>
    Cc: linux-usb@vger.kernel.org

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 269bfbbd10fc..606a5259f87f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1149,6 +1149,12 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 
 	res = __blkdev_get(bdev, mode, 0);
 
+	/* __blkdev_get() may alter read only status, check it afterwards */
+	if (!res && (mode & FMODE_WRITE) && bdev_read_only(bdev)) {
+		__blkdev_put(bdev, mode, 0);
+		res = -EACCES;
+	}
+
 	if (whole) {
 		/* finish claiming */
 		spin_lock(&bdev_lock);
@@ -1453,11 +1459,6 @@ struct block_device *open_bdev_exclusive(const char *path, fmode_t mode, void *h
 	if (error)
 		return ERR_PTR(error);
 
-	if ((mode & FMODE_WRITE) && bdev_read_only(bdev)) {
-		blkdev_put(bdev, mode);
-		return ERR_PTR(-EACCES);
-	}
-
 	return bdev;
 }
 

commit 6a027eff62f6ae32d49f2ae5dadd6f4eee1ddae2
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Nov 13 11:55:17 2010 +0100

    block: reorganize claim/release implementation
    
    With claim/release rolled into blkdev_get/put(), there's no reason to
    keep bd_abort/finish_claim(), __bd_claim() and bd_release() as
    separate functions.  It only makes the code difficult to follow.
    Collapse them into blkdev_get/put().  This will ease future changes
    around claim/release.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fc48912354d1..269bfbbd10fc 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -772,79 +772,6 @@ static struct block_device *bd_start_claiming(struct block_device *bdev,
 	}
 }
 
-/* releases bdev_lock */
-static void __bd_abort_claiming(struct block_device *whole, void *holder)
-{
-	BUG_ON(whole->bd_claiming != holder);
-	whole->bd_claiming = NULL;
-	wake_up_bit(&whole->bd_claiming, 0);
-
-	spin_unlock(&bdev_lock);
-	bdput(whole);
-}
-
-/**
- * bd_abort_claiming - abort claiming a block device
- * @whole: whole block device returned by bd_start_claiming()
- * @holder: holder trying to claim @bdev
- *
- * Abort a claiming block started by bd_start_claiming().  Note that
- * @whole is not the block device to be claimed but the whole device
- * returned by bd_start_claiming().
- *
- * CONTEXT:
- * Grabs and releases bdev_lock.
- */
-static void bd_abort_claiming(struct block_device *whole, void *holder)
-{
-	spin_lock(&bdev_lock);
-	__bd_abort_claiming(whole, holder);		/* releases bdev_lock */
-}
-
-/* increment holders when we have a legitimate claim. requires bdev_lock */
-static void __bd_claim(struct block_device *bdev, struct block_device *whole,
-					void *holder)
-{
-	/* note that for a whole device bd_holders
-	 * will be incremented twice, and bd_holder will
-	 * be set to bd_may_claim before being set to holder
-	 */
-	whole->bd_holders++;
-	whole->bd_holder = bd_may_claim;
-	bdev->bd_holders++;
-	bdev->bd_holder = holder;
-}
-
-/**
- * bd_finish_claiming - finish claiming a block device
- * @bdev: block device of interest (passed to bd_start_claiming())
- * @whole: whole block device returned by bd_start_claiming()
- * @holder: holder trying to claim @bdev
- *
- * Finish a claiming block started by bd_start_claiming().
- *
- * CONTEXT:
- * Grabs and releases bdev_lock.
- */
-static void bd_finish_claiming(struct block_device *bdev,
-				struct block_device *whole, void *holder)
-{
-	spin_lock(&bdev_lock);
-	BUG_ON(!bd_may_claim(bdev, whole, holder));
-	__bd_claim(bdev, whole, holder);
-	__bd_abort_claiming(whole, holder); /* not actually an abort */
-}
-
-static void bd_release(struct block_device *bdev)
-{
-	spin_lock(&bdev_lock);
-	if (!--bdev->bd_contains->bd_holders)
-		bdev->bd_contains->bd_holder = NULL;
-	if (!--bdev->bd_holders)
-		bdev->bd_holder = NULL;
-	spin_unlock(&bdev_lock);
-}
-
 #ifdef CONFIG_SYSFS
 static int add_symlink(struct kobject *from, struct kobject *to)
 {
@@ -1223,10 +1150,30 @@ int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 	res = __blkdev_get(bdev, mode, 0);
 
 	if (whole) {
-		if (res == 0)
-			bd_finish_claiming(bdev, whole, holder);
-		else
-			bd_abort_claiming(whole, holder);
+		/* finish claiming */
+		spin_lock(&bdev_lock);
+
+		if (res == 0) {
+			BUG_ON(!bd_may_claim(bdev, whole, holder));
+			/*
+			 * Note that for a whole device bd_holders
+			 * will be incremented twice, and bd_holder
+			 * will be set to bd_may_claim before being
+			 * set to holder
+			 */
+			whole->bd_holders++;
+			whole->bd_holder = bd_may_claim;
+			bdev->bd_holders++;
+			bdev->bd_holder = holder;
+		}
+
+		/* tell others that we're done */
+		BUG_ON(whole->bd_claiming != holder);
+		whole->bd_claiming = NULL;
+		wake_up_bit(&whole->bd_claiming, 0);
+
+		spin_unlock(&bdev_lock);
+		bdput(whole);
 	}
 
 	return res;
@@ -1272,6 +1219,7 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		bdev->bd_part_count--;
 
 	if (!--bdev->bd_openers) {
+		WARN_ON_ONCE(bdev->bd_holders);
 		sync_blockdev(bdev);
 		kill_bdev(bdev);
 	}
@@ -1303,10 +1251,31 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 int blkdev_put(struct block_device *bdev, fmode_t mode)
 {
 	if (mode & FMODE_EXCL) {
+		bool bdev_free;
+
+		/*
+		 * Release a claim on the device.  The holder fields
+		 * are protected with bdev_lock.  bd_mutex is to
+		 * synchronize disk_holder unlinking.
+		 */
 		mutex_lock(&bdev->bd_mutex);
-		bd_release(bdev);
-		if (!bdev->bd_holders)
+		spin_lock(&bdev_lock);
+
+		WARN_ON_ONCE(--bdev->bd_holders < 0);
+		WARN_ON_ONCE(--bdev->bd_contains->bd_holders < 0);
+
+		/* bd_contains might point to self, check in a separate step */
+		if ((bdev_free = !bdev->bd_holders))
+			bdev->bd_holder = NULL;
+		if (!bdev->bd_contains->bd_holders)
+			bdev->bd_contains->bd_holder = NULL;
+
+		spin_unlock(&bdev_lock);
+
+		/* if this was the last claim, holder link should go too */
+		if (bdev_free)
 			bd_unlink_disk_holder(bdev);
+
 		mutex_unlock(&bdev->bd_mutex);
 	}
 	return __blkdev_put(bdev, mode, 0);

commit e525fd89d380c4a94c0d63913a1dd1a593ed25e7
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Nov 13 11:55:17 2010 +0100

    block: make blkdev_get/put() handle exclusive access
    
    Over time, block layer has accumulated a set of APIs dealing with bdev
    open, close, claim and release.
    
    * blkdev_get/put() are the primary open and close functions.
    
    * bd_claim/release() deal with exclusive open.
    
    * open/close_bdev_exclusive() are combination of open and claim and
      the other way around, respectively.
    
    * bd_link/unlink_disk_holder() to create and remove holder/slave
      symlinks.
    
    * open_by_devnum() wraps bdget() + blkdev_get().
    
    The interface is a bit confusing and the decoupling of open and claim
    makes it impossible to properly guarantee exclusive access as
    in-kernel open + claim sequence can disturb the existing exclusive
    open even before the block layer knows the current open if for another
    exclusive access.  Reorganize the interface such that,
    
    * blkdev_get() is extended to include exclusive access management.
      @holder argument is added and, if is @FMODE_EXCL specified, it will
      gain exclusive access atomically w.r.t. other exclusive accesses.
    
    * blkdev_put() is similarly extended.  It now takes @mode argument and
      if @FMODE_EXCL is set, it releases an exclusive access.  Also, when
      the last exclusive claim is released, the holder/slave symlinks are
      removed automatically.
    
    * bd_claim/release() and close_bdev_exclusive() are no longer
      necessary and either made static or removed.
    
    * bd_link_disk_holder() remains the same but bd_unlink_disk_holder()
      is no longer necessary and removed.
    
    * open_bdev_exclusive() becomes a simple wrapper around lookup_bdev()
      and blkdev_get().  It also has an unexpected extra bdev_read_only()
      test which probably should be moved into blkdev_get().
    
    * open_by_devnum() is modified to take @holder argument and pass it to
      blkdev_get().
    
    Most of bdev open/close operations are unified into blkdev_get/put()
    and most exclusive accesses are tested atomically at the open time (as
    it should).  This cleans up code and removes some, both valid and
    invalid, but unnecessary all the same, corner cases.
    
    open_bdev_exclusive() and open_by_devnum() can use further cleanup -
    rename to blkdev_get_by_path() and blkdev_get_by_devt() and drop
    special features.  Well, let's leave them for another day.
    
    Most conversions are straight-forward.  drbd conversion is a bit more
    involved as there was some reordering, but the logic should stay the
    same.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Neil Brown <neilb@suse.de>
    Acked-by: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Acked-by: Philipp Reisner <philipp.reisner@linbit.com>
    Cc: Peter Osterlund <petero2@telia.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <joel.becker@oracle.com>
    Cc: Alex Elder <aelder@sgi.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: dm-devel@redhat.com
    Cc: drbd-dev@lists.linbit.com
    Cc: Leo Chen <leochen@broadcom.com>
    Cc: Scott Branden <sbranden@broadcom.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Cc: Joern Engel <joern@logfs.org>
    Cc: reiserfs-devel@vger.kernel.org
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9329068684d2..fc48912354d1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -660,7 +660,7 @@ static bool bd_may_claim(struct block_device *bdev, struct block_device *whole,
 	else if (bdev->bd_contains == bdev)
 		return true;  	 /* is a whole device which isn't held */
 
-	else if (whole->bd_holder == bd_claim)
+	else if (whole->bd_holder == bd_may_claim)
 		return true; 	 /* is a partition of a device that is being partitioned */
 	else if (whole->bd_holder != NULL)
 		return false;	 /* is a partition of a held device */
@@ -807,10 +807,10 @@ static void __bd_claim(struct block_device *bdev, struct block_device *whole,
 {
 	/* note that for a whole device bd_holders
 	 * will be incremented twice, and bd_holder will
-	 * be set to bd_claim before being set to holder
+	 * be set to bd_may_claim before being set to holder
 	 */
 	whole->bd_holders++;
-	whole->bd_holder = bd_claim;
+	whole->bd_holder = bd_may_claim;
 	bdev->bd_holders++;
 	bdev->bd_holder = holder;
 }
@@ -835,37 +835,7 @@ static void bd_finish_claiming(struct block_device *bdev,
 	__bd_abort_claiming(whole, holder); /* not actually an abort */
 }
 
-/**
- * bd_claim - claim a block device
- * @bdev: block device to claim
- * @holder: holder trying to claim @bdev
- *
- * Try to claim @bdev which must have been opened successfully.
- *
- * CONTEXT:
- * Might sleep.
- *
- * RETURNS:
- * 0 if successful, -EBUSY if @bdev is already claimed.
- */
-int bd_claim(struct block_device *bdev, void *holder)
-{
-	struct block_device *whole = bdev->bd_contains;
-	int res;
-
-	might_sleep();
-
-	spin_lock(&bdev_lock);
-	res = bd_prepare_to_claim(bdev, whole, holder);
-	if (res == 0)
-		__bd_claim(bdev, whole, holder);
-	spin_unlock(&bdev_lock);
-
-	return res;
-}
-EXPORT_SYMBOL(bd_claim);
-
-void bd_release(struct block_device *bdev)
+static void bd_release(struct block_device *bdev)
 {
 	spin_lock(&bdev_lock);
 	if (!--bdev->bd_contains->bd_holders)
@@ -875,8 +845,6 @@ void bd_release(struct block_device *bdev)
 	spin_unlock(&bdev_lock);
 }
 
-EXPORT_SYMBOL(bd_release);
-
 #ifdef CONFIG_SYSFS
 static int add_symlink(struct kobject *from, struct kobject *to)
 {
@@ -943,7 +911,7 @@ int bd_link_disk_holder(struct block_device *bdev, struct gendisk *disk)
 }
 EXPORT_SYMBOL_GPL(bd_link_disk_holder);
 
-void bd_unlink_disk_holder(struct block_device *bdev)
+static void bd_unlink_disk_holder(struct block_device *bdev)
 {
 	struct gendisk *disk = bdev->bd_holder_disk;
 
@@ -954,7 +922,9 @@ void bd_unlink_disk_holder(struct block_device *bdev)
 	del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
 	del_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);
 }
-EXPORT_SYMBOL_GPL(bd_unlink_disk_holder);
+#else
+static inline void bd_unlink_disk_holder(struct block_device *bdev)
+{ }
 #endif
 
 /*
@@ -964,12 +934,12 @@ EXPORT_SYMBOL_GPL(bd_unlink_disk_holder);
  * to be used for internal purposes.  If you ever need it - reconsider
  * your API.
  */
-struct block_device *open_by_devnum(dev_t dev, fmode_t mode)
+struct block_device *open_by_devnum(dev_t dev, fmode_t mode, void *holder)
 {
 	struct block_device *bdev = bdget(dev);
 	int err = -ENOMEM;
 	if (bdev)
-		err = blkdev_get(bdev, mode);
+		err = blkdev_get(bdev, mode, holder);
 	return err ? ERR_PTR(err) : bdev;
 }
 
@@ -1235,17 +1205,37 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	return ret;
 }
 
-int blkdev_get(struct block_device *bdev, fmode_t mode)
+int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
 {
-	return __blkdev_get(bdev, mode, 0);
+	struct block_device *whole = NULL;
+	int res;
+
+	WARN_ON_ONCE((mode & FMODE_EXCL) && !holder);
+
+	if ((mode & FMODE_EXCL) && holder) {
+		whole = bd_start_claiming(bdev, holder);
+		if (IS_ERR(whole)) {
+			bdput(bdev);
+			return PTR_ERR(whole);
+		}
+	}
+
+	res = __blkdev_get(bdev, mode, 0);
+
+	if (whole) {
+		if (res == 0)
+			bd_finish_claiming(bdev, whole, holder);
+		else
+			bd_abort_claiming(whole, holder);
+	}
+
+	return res;
 }
 EXPORT_SYMBOL(blkdev_get);
 
 static int blkdev_open(struct inode * inode, struct file * filp)
 {
-	struct block_device *whole = NULL;
 	struct block_device *bdev;
-	int res;
 
 	/*
 	 * Preserve backwards compatibility and allow large file access
@@ -1266,26 +1256,9 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	if (bdev == NULL)
 		return -ENOMEM;
 
-	if (filp->f_mode & FMODE_EXCL) {
-		whole = bd_start_claiming(bdev, filp);
-		if (IS_ERR(whole)) {
-			bdput(bdev);
-			return PTR_ERR(whole);
-		}
-	}
-
 	filp->f_mapping = bdev->bd_inode->i_mapping;
 
-	res = blkdev_get(bdev, filp->f_mode);
-
-	if (whole) {
-		if (res == 0)
-			bd_finish_claiming(bdev, whole, filp);
-		else
-			bd_abort_claiming(whole, filp);
-	}
-
-	return res;
+	return blkdev_get(bdev, filp->f_mode, filp);
 }
 
 static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
@@ -1329,6 +1302,13 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 
 int blkdev_put(struct block_device *bdev, fmode_t mode)
 {
+	if (mode & FMODE_EXCL) {
+		mutex_lock(&bdev->bd_mutex);
+		bd_release(bdev);
+		if (!bdev->bd_holders)
+			bd_unlink_disk_holder(bdev);
+		mutex_unlock(&bdev->bd_mutex);
+	}
 	return __blkdev_put(bdev, mode, 0);
 }
 EXPORT_SYMBOL(blkdev_put);
@@ -1336,8 +1316,7 @@ EXPORT_SYMBOL(blkdev_put);
 static int blkdev_close(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
-	if (bdev->bd_holder == filp)
-		bd_release(bdev);
+
 	return blkdev_put(bdev, filp->f_mode);
 }
 
@@ -1494,55 +1473,27 @@ EXPORT_SYMBOL(lookup_bdev);
  */
 struct block_device *open_bdev_exclusive(const char *path, fmode_t mode, void *holder)
 {
-	struct block_device *bdev, *whole;
+	struct block_device *bdev;
 	int error;
 
 	bdev = lookup_bdev(path);
 	if (IS_ERR(bdev))
 		return bdev;
 
-	whole = bd_start_claiming(bdev, holder);
-	if (IS_ERR(whole)) {
-		bdput(bdev);
-		return whole;
-	}
-
-	error = blkdev_get(bdev, mode);
+	error = blkdev_get(bdev, mode | FMODE_EXCL, holder);
 	if (error)
-		goto out_abort_claiming;
+		return ERR_PTR(error);
 
-	error = -EACCES;
-	if ((mode & FMODE_WRITE) && bdev_read_only(bdev))
-		goto out_blkdev_put;
+	if ((mode & FMODE_WRITE) && bdev_read_only(bdev)) {
+		blkdev_put(bdev, mode);
+		return ERR_PTR(-EACCES);
+	}
 
-	bd_finish_claiming(bdev, whole, holder);
 	return bdev;
-
-out_blkdev_put:
-	blkdev_put(bdev, mode);
-out_abort_claiming:
-	bd_abort_claiming(whole, holder);
-	return ERR_PTR(error);
 }
 
 EXPORT_SYMBOL(open_bdev_exclusive);
 
-/**
- * close_bdev_exclusive  -  close a blockdevice opened by open_bdev_exclusive()
- *
- * @bdev:	blockdevice to close
- * @mode:	mode, must match that used to open.
- *
- * This is the counterpart to open_bdev_exclusive().
- */
-void close_bdev_exclusive(struct block_device *bdev, fmode_t mode)
-{
-	bd_release(bdev);
-	blkdev_put(bdev, mode);
-}
-
-EXPORT_SYMBOL(close_bdev_exclusive);
-
 int __invalidate_device(struct block_device *bdev)
 {
 	struct super_block *sb = get_super(bdev);

commit e09b457bdb7e8d23fc54dcef0930ac697d8de895
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Nov 13 11:55:17 2010 +0100

    block: simplify holder symlink handling
    
    Code to manage symlinks in /sys/block/*/{holders|slaves} are overly
    complex with multiple holder considerations, redundant extra
    references to all involved kobjects, unused generic kobject holder
    support and unnecessary mixup with bd_claim/release functionalities.
    
    Strip it down to what's necessary (single gendisk holder) and make it
    use a separate interface.  This is a step for cleaning up
    bd_claim/release.  This patch makes dm-table slightly more complex but
    it will be simplified again with further changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Neil Brown <neilb@suse.de>
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Cc: dm-devel@redhat.com

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 06e8ff12b97c..9329068684d2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -426,9 +426,6 @@ static void init_once(void *foo)
 	mutex_init(&bdev->bd_mutex);
 	INIT_LIST_HEAD(&bdev->bd_inodes);
 	INIT_LIST_HEAD(&bdev->bd_list);
-#ifdef CONFIG_SYSFS
-	INIT_LIST_HEAD(&bdev->bd_holder_list);
-#endif
 	inode_init_once(&ei->vfs_inode);
 	/* Initialize mutex for freeze. */
 	mutex_init(&bdev->bd_fsfreeze_mutex);
@@ -881,314 +878,83 @@ void bd_release(struct block_device *bdev)
 EXPORT_SYMBOL(bd_release);
 
 #ifdef CONFIG_SYSFS
-/*
- * Functions for bd_claim_by_kobject / bd_release_from_kobject
- *
- *     If a kobject is passed to bd_claim_by_kobject()
- *     and the kobject has a parent directory,
- *     following symlinks are created:
- *        o from the kobject to the claimed bdev
- *        o from "holders" directory of the bdev to the parent of the kobject
- *     bd_release_from_kobject() removes these symlinks.
- *
- *     Example:
- *        If /dev/dm-0 maps to /dev/sda, kobject corresponding to
- *        /sys/block/dm-0/slaves is passed to bd_claim_by_kobject(), then:
- *           /sys/block/dm-0/slaves/sda --> /sys/block/sda
- *           /sys/block/sda/holders/dm-0 --> /sys/block/dm-0
- */
-
 static int add_symlink(struct kobject *from, struct kobject *to)
 {
-	if (!from || !to)
-		return 0;
 	return sysfs_create_link(from, to, kobject_name(to));
 }
 
 static void del_symlink(struct kobject *from, struct kobject *to)
 {
-	if (!from || !to)
-		return;
 	sysfs_remove_link(from, kobject_name(to));
 }
 
-/*
- * 'struct bd_holder' contains pointers to kobjects symlinked by
- * bd_claim_by_kobject.
- * It's connected to bd_holder_list which is protected by bdev->bd_sem.
- */
-struct bd_holder {
-	struct list_head list;	/* chain of holders of the bdev */
-	int count;		/* references from the holder */
-	struct kobject *sdir;	/* holder object, e.g. "/block/dm-0/slaves" */
-	struct kobject *hdev;	/* e.g. "/block/dm-0" */
-	struct kobject *hdir;	/* e.g. "/block/sda/holders" */
-	struct kobject *sdev;	/* e.g. "/block/sda" */
-};
-
-/*
- * Get references of related kobjects at once.
- * Returns 1 on success. 0 on failure.
- *
- * Should call bd_holder_release_dirs() after successful use.
- */
-static int bd_holder_grab_dirs(struct block_device *bdev,
-			struct bd_holder *bo)
-{
-	if (!bdev || !bo)
-		return 0;
-
-	bo->sdir = kobject_get(bo->sdir);
-	if (!bo->sdir)
-		return 0;
-
-	bo->hdev = kobject_get(bo->sdir->parent);
-	if (!bo->hdev)
-		goto fail_put_sdir;
-
-	bo->sdev = kobject_get(&part_to_dev(bdev->bd_part)->kobj);
-	if (!bo->sdev)
-		goto fail_put_hdev;
-
-	bo->hdir = kobject_get(bdev->bd_part->holder_dir);
-	if (!bo->hdir)
-		goto fail_put_sdev;
-
-	return 1;
-
-fail_put_sdev:
-	kobject_put(bo->sdev);
-fail_put_hdev:
-	kobject_put(bo->hdev);
-fail_put_sdir:
-	kobject_put(bo->sdir);
-
-	return 0;
-}
-
-/* Put references of related kobjects at once. */
-static void bd_holder_release_dirs(struct bd_holder *bo)
-{
-	kobject_put(bo->hdir);
-	kobject_put(bo->sdev);
-	kobject_put(bo->hdev);
-	kobject_put(bo->sdir);
-}
-
-static struct bd_holder *alloc_bd_holder(struct kobject *kobj)
-{
-	struct bd_holder *bo;
-
-	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
-	if (!bo)
-		return NULL;
-
-	bo->count = 1;
-	bo->sdir = kobj;
-
-	return bo;
-}
-
-static void free_bd_holder(struct bd_holder *bo)
-{
-	kfree(bo);
-}
-
 /**
- * find_bd_holder - find matching struct bd_holder from the block device
+ * bd_link_disk_holder - create symlinks between holding disk and slave bdev
+ * @bdev: the claimed slave bdev
+ * @disk: the holding disk
  *
- * @bdev:	struct block device to be searched
- * @bo:		target struct bd_holder
+ * This functions creates the following sysfs symlinks.
  *
- * Returns matching entry with @bo in @bdev->bd_holder_list.
- * If found, increment the reference count and return the pointer.
- * If not found, returns NULL.
- */
-static struct bd_holder *find_bd_holder(struct block_device *bdev,
-					struct bd_holder *bo)
-{
-	struct bd_holder *tmp;
-
-	list_for_each_entry(tmp, &bdev->bd_holder_list, list)
-		if (tmp->sdir == bo->sdir) {
-			tmp->count++;
-			return tmp;
-		}
-
-	return NULL;
-}
-
-/**
- * add_bd_holder - create sysfs symlinks for bd_claim() relationship
+ * - from "slaves" directory of the holder @disk to the claimed @bdev
+ * - from "holders" directory of the @bdev to the holder @disk
  *
- * @bdev:	block device to be bd_claimed
- * @bo:		preallocated and initialized by alloc_bd_holder()
+ * For example, if /dev/dm-0 maps to /dev/sda and disk for dm-0 is
+ * passed to bd_link_disk_holder(), then:
  *
- * Add @bo to @bdev->bd_holder_list, create symlinks.
+ *   /sys/block/dm-0/slaves/sda --> /sys/block/sda
+ *   /sys/block/sda/holders/dm-0 --> /sys/block/dm-0
  *
- * Returns 0 if symlinks are created.
- * Returns -ve if something fails.
- */
-static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
-{
-	int err;
-
-	if (!bo)
-		return -EINVAL;
-
-	if (!bd_holder_grab_dirs(bdev, bo))
-		return -EBUSY;
-
-	err = add_symlink(bo->sdir, bo->sdev);
-	if (err)
-		return err;
-
-	err = add_symlink(bo->hdir, bo->hdev);
-	if (err) {
-		del_symlink(bo->sdir, bo->sdev);
-		return err;
-	}
-
-	list_add_tail(&bo->list, &bdev->bd_holder_list);
-	return 0;
-}
-
-/**
- * del_bd_holder - delete sysfs symlinks for bd_claim() relationship
- *
- * @bdev:	block device to be bd_claimed
- * @kobj:	holder's kobject
- *
- * If there is matching entry with @kobj in @bdev->bd_holder_list
- * and no other bd_claim() from the same kobject,
- * remove the struct bd_holder from the list, delete symlinks for it.
- *
- * Returns a pointer to the struct bd_holder when it's removed from the list
- * and ready to be freed.
- * Returns NULL if matching claim isn't found or there is other bd_claim()
- * by the same kobject.
- */
-static struct bd_holder *del_bd_holder(struct block_device *bdev,
-					struct kobject *kobj)
-{
-	struct bd_holder *bo;
-
-	list_for_each_entry(bo, &bdev->bd_holder_list, list) {
-		if (bo->sdir == kobj) {
-			bo->count--;
-			BUG_ON(bo->count < 0);
-			if (!bo->count) {
-				list_del(&bo->list);
-				del_symlink(bo->sdir, bo->sdev);
-				del_symlink(bo->hdir, bo->hdev);
-				bd_holder_release_dirs(bo);
-				return bo;
-			}
-			break;
-		}
-	}
-
-	return NULL;
-}
-
-/**
- * bd_claim_by_kobject - bd_claim() with additional kobject signature
- *
- * @bdev:	block device to be claimed
- * @holder:	holder's signature
- * @kobj:	holder's kobject
+ * The caller must have claimed @bdev before calling this function and
+ * ensure that both @bdev and @disk are valid during the creation and
+ * lifetime of these symlinks.
  *
- * Do bd_claim() and if it succeeds, create sysfs symlinks between
- * the bdev and the holder's kobject.
- * Use bd_release_from_kobject() when relesing the claimed bdev.
+ * CONTEXT:
+ * Might sleep.
  *
- * Returns 0 on success. (same as bd_claim())
- * Returns errno on failure.
+ * RETURNS:
+ * 0 on success, -errno on failure.
  */
-static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
-				struct kobject *kobj)
+int bd_link_disk_holder(struct block_device *bdev, struct gendisk *disk)
 {
-	int err;
-	struct bd_holder *bo, *found;
-
-	if (!kobj)
-		return -EINVAL;
-
-	bo = alloc_bd_holder(kobj);
-	if (!bo)
-		return -ENOMEM;
+	int ret = 0;
 
 	mutex_lock(&bdev->bd_mutex);
 
-	err = bd_claim(bdev, holder);
-	if (err)
-		goto fail;
+	WARN_ON_ONCE(!bdev->bd_holder || bdev->bd_holder_disk);
 
-	found = find_bd_holder(bdev, bo);
-	if (found)
-		goto fail;
+	/* FIXME: remove the following once add_disk() handles errors */
+	if (WARN_ON(!disk->slave_dir || !bdev->bd_part->holder_dir))
+		goto out_unlock;
 
-	err = add_bd_holder(bdev, bo);
-	if (err)
-		bd_release(bdev);
-	else
-		bo = NULL;
-fail:
-	mutex_unlock(&bdev->bd_mutex);
-	free_bd_holder(bo);
-	return err;
-}
+	ret = add_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
+	if (ret)
+		goto out_unlock;
 
-/**
- * bd_release_from_kobject - bd_release() with additional kobject signature
- *
- * @bdev:	block device to be released
- * @kobj:	holder's kobject
- *
- * Do bd_release() and remove sysfs symlinks created by bd_claim_by_kobject().
- */
-static void bd_release_from_kobject(struct block_device *bdev,
-					struct kobject *kobj)
-{
-	if (!kobj)
-		return;
+	ret = add_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);
+	if (ret) {
+		del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
+		goto out_unlock;
+	}
 
-	mutex_lock(&bdev->bd_mutex);
-	bd_release(bdev);
-	free_bd_holder(del_bd_holder(bdev, kobj));
+	bdev->bd_holder_disk = disk;
+out_unlock:
 	mutex_unlock(&bdev->bd_mutex);
+	return ret;
 }
+EXPORT_SYMBOL_GPL(bd_link_disk_holder);
 
-/**
- * bd_claim_by_disk - wrapper function for bd_claim_by_kobject()
- *
- * @bdev:	block device to be claimed
- * @holder:	holder's signature
- * @disk:	holder's gendisk
- *
- * Call bd_claim_by_kobject() with getting @disk->slave_dir.
- */
-int bd_claim_by_disk(struct block_device *bdev, void *holder,
-			struct gendisk *disk)
+void bd_unlink_disk_holder(struct block_device *bdev)
 {
-	return bd_claim_by_kobject(bdev, holder, kobject_get(disk->slave_dir));
-}
-EXPORT_SYMBOL_GPL(bd_claim_by_disk);
+	struct gendisk *disk = bdev->bd_holder_disk;
 
-/**
- * bd_release_from_disk - wrapper function for bd_release_from_kobject()
- *
- * @bdev:	block device to be claimed
- * @disk:	holder's gendisk
- *
- * Call bd_release_from_kobject() and put @disk->slave_dir.
- */
-void bd_release_from_disk(struct block_device *bdev, struct gendisk *disk)
-{
-	bd_release_from_kobject(bdev, disk->slave_dir);
-	kobject_put(disk->slave_dir);
+	bdev->bd_holder_disk = NULL;
+	if (!disk)
+		return;
+
+	del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);
+	del_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);
 }
-EXPORT_SYMBOL_GPL(bd_release_from_disk);
+EXPORT_SYMBOL_GPL(bd_unlink_disk_holder);
 #endif
 
 /*

commit 51139adac92f7160ad3ca1cab2de1b4b8d19dc96
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jul 25 23:47:46 2010 +0400

    convert get_sb_pseudo() users
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index dea3b628a6ce..06e8ff12b97c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -464,15 +464,15 @@ static const struct super_operations bdev_sops = {
 	.evict_inode = bdev_evict_inode,
 };
 
-static int bd_get_sb(struct file_system_type *fs_type,
-	int flags, const char *dev_name, void *data, struct vfsmount *mnt)
+static struct dentry *bd_mount(struct file_system_type *fs_type,
+	int flags, const char *dev_name, void *data)
 {
-	return get_sb_pseudo(fs_type, "bdev:", &bdev_sops, 0x62646576, mnt);
+	return mount_pseudo(fs_type, "bdev:", &bdev_sops, 0x62646576);
 }
 
 static struct file_system_type bd_type = {
 	.name		= "bdev",
-	.get_sb		= bd_get_sb,
+	.mount		= bd_mount,
 	.kill_sb	= kill_anon_super,
 };
 

commit 7ccf19a8042e343f8159f8a5fdd6a9422aa90c78
Author: Nick Piggin <npiggin@suse.de>
Date:   Thu Oct 21 11:49:30 2010 +1100

    fs: inode split IO and LRU lists
    
    The use of the same inode list structure (inode->i_list) for two
    different list constructs with different lifecycles and purposes
    makes it impossible to separate the locking of the different
    operations. Therefore, to enable the separation of the locking of
    the writeback and reclaim lists, split the inode->i_list into two
    separate lists dedicated to their specific tracking functions.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4e847e53051f..dea3b628a6ce 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -59,7 +59,7 @@ static void bdev_inode_switch_bdi(struct inode *inode,
 	spin_lock(&inode_lock);
 	inode->i_data.backing_dev_info = dst;
 	if (inode->i_state & I_DIRTY)
-		list_move(&inode->i_list, &dst->wb.b_dirty);
+		list_move(&inode->i_wb_list, &dst->wb.b_dirty);
 	spin_unlock(&inode_lock);
 }
 

commit a5491e0c7bb7387e3e6ff9994d6dc2efc78af56c
Author: Dave Chinner <dchinner@redhat.com>
Date:   Thu Oct 21 11:49:26 2010 +1100

    fs: switch bdev inode bdi's correctly
    
    bdev inodes can remain dirty even after their last close. Hence the
    BDI associated with the bdev->inode gets modified duringthe last
    close to point to the default BDI. However, the bdev inode still
    needs to be moved to the dirty lists of the new BDI, otherwise it
    will corrupt the writeback list is was left on.
    
    Add a new function bdev_inode_switch_bdi() to move all the bdi state
    from the old bdi to the new one safely. This is only a temporary
    measure until the bdev inode<->bdi lifecycle problems are sorted
    out.
    
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 81972eb34b39..4e847e53051f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -48,6 +48,21 @@ inline struct block_device *I_BDEV(struct inode *inode)
 
 EXPORT_SYMBOL(I_BDEV);
 
+/*
+ * move the inode from it's current bdi to the a new bdi. if the inode is dirty
+ * we need to move it onto the dirty list of @dst so that the inode is always
+ * on the right list.
+ */
+static void bdev_inode_switch_bdi(struct inode *inode,
+			struct backing_dev_info *dst)
+{
+	spin_lock(&inode_lock);
+	inode->i_data.backing_dev_info = dst;
+	if (inode->i_state & I_DIRTY)
+		list_move(&inode->i_list, &dst->wb.b_dirty);
+	spin_unlock(&inode_lock);
+}
+
 static sector_t max_block(struct block_device *bdev)
 {
 	sector_t retval = ~((sector_t)0);
@@ -1390,7 +1405,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 				bdi = blk_get_backing_dev_info(bdev);
 				if (bdi == NULL)
 					bdi = &default_backing_dev_info;
-				bdev->bd_inode->i_data.backing_dev_info = bdi;
+				bdev_inode_switch_bdi(bdev->bd_inode, bdi);
 			}
 			if (bdev->bd_invalidated)
 				rescan_partitions(disk, bdev);
@@ -1405,8 +1420,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			if (ret)
 				goto out_clear;
 			bdev->bd_contains = whole;
-			bdev->bd_inode->i_data.backing_dev_info =
-			   whole->bd_inode->i_data.backing_dev_info;
+			bdev_inode_switch_bdi(bdev->bd_inode,
+				whole->bd_inode->i_data.backing_dev_info);
 			bdev->bd_part = disk_get_part(disk, partno);
 			if (!(disk->flags & GENHD_FL_UP) ||
 			    !bdev->bd_part || !bdev->bd_part->nr_sects) {
@@ -1439,7 +1454,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	disk_put_part(bdev->bd_part);
 	bdev->bd_disk = NULL;
 	bdev->bd_part = NULL;
-	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
+	bdev_inode_switch_bdi(bdev->bd_inode, &default_backing_dev_info);
 	if (bdev != bdev->bd_contains)
 		__blkdev_put(bdev->bd_contains, mode, 1);
 	bdev->bd_contains = NULL;
@@ -1533,7 +1548,8 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 		disk_put_part(bdev->bd_part);
 		bdev->bd_part = NULL;
 		bdev->bd_disk = NULL;
-		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
+		bdev_inode_switch_bdi(bdev->bd_inode,
+					&default_backing_dev_info);
 		if (bdev != bdev->bd_contains)
 			victim = bdev->bd_contains;
 		bdev->bd_contains = NULL;

commit 7de9c6ee3ecffd99e1628e81a5ea5468f7581a1f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Oct 23 11:11:40 2010 -0400

    new helper: ihold()
    
    Clones an existing reference to inode; caller must already hold one.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b737451e2e9d..81972eb34b39 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -550,7 +550,7 @@ EXPORT_SYMBOL(bdget);
  */
 struct block_device *bdgrab(struct block_device *bdev)
 {
-	atomic_inc(&bdev->bd_inode->i_count);
+	ihold(bdev->bd_inode);
 	return bdev;
 }
 
@@ -580,7 +580,7 @@ static struct block_device *bd_acquire(struct inode *inode)
 	spin_lock(&bdev_lock);
 	bdev = inode->i_bdev;
 	if (bdev) {
-		atomic_inc(&bdev->bd_inode->i_count);
+		ihold(bdev->bd_inode);
 		spin_unlock(&bdev_lock);
 		return bdev;
 	}
@@ -591,12 +591,12 @@ static struct block_device *bd_acquire(struct inode *inode)
 		spin_lock(&bdev_lock);
 		if (!inode->i_bdev) {
 			/*
-			 * We take an additional bd_inode->i_count for inode,
+			 * We take an additional reference to bd_inode,
 			 * and it's released in clear_inode() of inode.
 			 * So, we can access it via ->i_mapping always
 			 * without igrab().
 			 */
-			atomic_inc(&bdev->bd_inode->i_count);
+			ihold(bdev->bd_inode);
 			inode->i_bdev = bdev;
 			inode->i_mapping = bdev->bd_inode->i_mapping;
 			list_add(&inode->i_devices, &bdev->bd_inodes);

commit dd3932eddf428571762596e17b65f5dc92ca361b
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Sep 16 20:51:46 2010 +0200

    block: remove BLKDEV_IFL_WAIT
    
    All the blkdev_issue_* helpers can only sanely be used for synchronous
    caller.  To issue cache flushes or barriers asynchronously the caller needs
    to set up a bio by itself with a completion callback to move the asynchronous
    state machine ahead.  So drop the BLKDEV_IFL_WAIT flag that is always
    specified when calling blkdev_issue_* and also remove the now unused flags
    argument to blkdev_issue_flush and blkdev_issue_zeroout.  For
    blkdev_issue_discard we need to keep it for the secure discard flag, which
    gains a more descriptive name and loses the bitops vs flag confusion.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 50e8c8582faa..b737451e2e9d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -370,7 +370,7 @@ int blkdev_fsync(struct file *filp, int datasync)
 	 */
 	mutex_unlock(&bd_inode->i_mutex);
 
-	error = blkdev_issue_flush(bdev, GFP_KERNEL, NULL, BLKDEV_IFL_WAIT);
+	error = blkdev_issue_flush(bdev, GFP_KERNEL, NULL);
 	if (error == -EOPNOTSUPP)
 		error = 0;
 

commit b7300b78d1a87625975a799a109a2f98d77757c8
Author: Chris Wright <chrisw@sous-sol.org>
Date:   Tue Aug 10 18:02:55 2010 -0700

    blkdev: cgroup whitelist permission fix
    
    The cgroup device whitelist code gets confused when trying to grant
    permission to a disk partition that is not currently open.  Part of
    blkdev_open() includes __blkdev_get() on the whole disk.
    
    Basically, the only ways to reliably allow a cgroup access to a partition
    on a block device when using the whitelist are to 1) also give it access
    to the whole block device or 2) make sure the partition is already open in
    a different context.
    
    The patch avoids the cgroup check for the whole disk case when opening a
    partition.
    
    Addresses https://bugzilla.redhat.com/show_bug.cgi?id=589662
    
    Signed-off-by: Chris Wright <chrisw@sous-sol.org>
    Acked-by: Serge E. Hallyn <serue@us.ibm.com>
    Tested-by: Serge E. Hallyn <serue@us.ibm.com>
    Reported-by: Vivek Goyal <vgoyal@redhat.com>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: "Daniel P. Berrange" <berrange@redhat.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 66411463b734..50e8c8582faa 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1340,10 +1340,12 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	/*
 	 * hooks: /n/, see "layering violations".
 	 */
-	ret = devcgroup_inode_permission(bdev->bd_inode, perm);
-	if (ret != 0) {
-		bdput(bdev);
-		return ret;
+	if (!for_part) {
+		ret = devcgroup_inode_permission(bdev->bd_inode, perm);
+		if (ret != 0) {
+			bdput(bdev);
+			return ret;
+		}
 	}
 
  restart:

commit 2f9e825d3e0e2b407ae8f082de5c00afcf7378fb
Merge: 7ae0dea900b0 de75d60d5ea2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 10 15:22:42 2010 -0700

    Merge branch 'for-2.6.36' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.36' of git://git.kernel.dk/linux-2.6-block: (149 commits)
      block: make sure that REQ_* types are seen even with CONFIG_BLOCK=n
      xen-blkfront: fix missing out label
      blkdev: fix blkdev_issue_zeroout return value
      block: update request stacking methods to support discards
      block: fix missing export of blk_types.h
      writeback: fix bad _bh spinlock nesting
      drbd: revert "delay probes", feature is being re-implemented differently
      drbd: Initialize all members of sync_conf to their defaults [Bugz 315]
      drbd: Disable delay probes for the upcomming release
      writeback: cleanup bdi_register
      writeback: add new tracepoints
      writeback: remove unnecessary init_timer call
      writeback: optimize periodic bdi thread wakeups
      writeback: prevent unnecessary bdi threads wakeups
      writeback: move bdi threads exiting logic to the forker thread
      writeback: restructure bdi forker loop a little
      writeback: move last_active to bdi
      writeback: do not remove bdi from bdi_list
      writeback: simplify bdi code a little
      writeback: do not lose wake-ups in bdi threads
      ...
    
    Fixed up pretty trivial conflicts in drivers/block/virtio_blk.c and
    drivers/scsi/scsi_error.c as per Jens.

commit 5f248c9c251c60af3403902b26e08de43964ea0b
Merge: f6cec0ae58c1 dca332528bc6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 10 11:26:52 2010 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6: (96 commits)
      no need for list_for_each_entry_safe()/resetting with superblock list
      Fix sget() race with failing mount
      vfs: don't hold s_umount over close_bdev_exclusive() call
      sysv: do not mark superblock dirty on remount
      sysv: do not mark superblock dirty on mount
      btrfs: remove junk sb_dirt change
      BFS: clean up the superblock usage
      AFFS: wait for sb synchronization when needed
      AFFS: clean up dirty flag usage
      cifs: truncate fallout
      mbcache: fix shrinker function return value
      mbcache: Remove unused features
      add f_flags to struct statfs(64)
      pass a struct path to vfs_statfs
      update VFS documentation for method changes.
      All filesystems that need invalidate_inode_buffers() are doing that explicitly
      convert remaining ->clear_inode() to ->evict_inode()
      Make ->drop_inode() just return whether inode needs to be dropped
      fs/inode.c:clear_inode() is gone
      fs/inode.c:evict() doesn't care about delete vs. non-delete paths now
      ...
    
    Fix up trivial conflicts in fs/nilfs2/super.c

commit b57922d97fd6f79b6dbe6db0c4fd30d219fa08c1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 7 14:34:48 2010 -0400

    convert remaining ->clear_inode() to ->evict_inode()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 63c9d6076205..de7b4d0c7e30 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -426,10 +426,13 @@ static inline void __bd_forget(struct inode *inode)
 	inode->i_mapping = &inode->i_data;
 }
 
-static void bdev_clear_inode(struct inode *inode)
+static void bdev_evict_inode(struct inode *inode)
 {
 	struct block_device *bdev = &BDEV_I(inode)->bdev;
 	struct list_head *p;
+	truncate_inode_pages(&inode->i_data, 0);
+	invalidate_inode_buffers(inode); /* is it needed here? */
+	end_writeback(inode);
 	spin_lock(&bdev_lock);
 	while ( (p = bdev->bd_inodes.next) != &bdev->bd_inodes ) {
 		__bd_forget(list_entry(p, struct inode, i_devices));
@@ -443,7 +446,7 @@ static const struct super_operations bdev_sops = {
 	.alloc_inode = bdev_alloc_inode,
 	.destroy_inode = bdev_destroy_inode,
 	.drop_inode = generic_delete_inode,
-	.clear_inode = bdev_clear_inode,
+	.evict_inode = bdev_evict_inode,
 };
 
 static int bd_get_sb(struct file_system_type *fs_type,

commit 155130a4f7848b1aac439cab6bda1a175507c71c
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 4 11:29:58 2010 +0200

    get rid of block_write_begin_newtrunc
    
    Move the call to vmtruncate to get rid of accessive blocks to the callers
    in preparation of the new truncate sequence and rename the non-truncating
    version to block_write_begin.
    
    While we're at it also remove several unused arguments to block_write_begin.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 65a0c26508e5..63c9d6076205 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -308,9 +308,8 @@ static int blkdev_write_begin(struct file *file, struct address_space *mapping,
 			loff_t pos, unsigned len, unsigned flags,
 			struct page **pagep, void **fsdata)
 {
-	*pagep = NULL;
-	return block_write_begin_newtrunc(file, mapping, pos, len, flags,
-				pagep, fsdata, blkdev_get_block);
+	return block_write_begin(mapping, pos, len, flags, pagep,
+				 blkdev_get_block);
 }
 
 static int blkdev_write_end(struct file *file, struct address_space *mapping,

commit eafdc7d190a944c755a9fe68573c193e6e0217e7
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 4 11:29:53 2010 +0200

    sort out blockdev_direct_IO variants
    
    Move the call to vmtruncate to get rid of accessive blocks to the callers
    in prepearation of the new truncate calling sequence.  This was only done
    for DIO_LOCKING filesystems, so the __blockdev_direct_IO_newtrunc variant
    was not needed anyway.  Get rid of blockdev_direct_IO_no_locking and
    its _newtrunc variant while at it as just opencoding the two additional
    paramters is shorted than the name suffix.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 99d6af811747..65a0c26508e5 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -172,9 +172,8 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = file->f_mapping->host;
 
-	return blockdev_direct_IO_no_locking_newtrunc(rw, iocb, inode,
-				I_BDEV(inode), iov, offset, nr_segs,
-				blkdev_get_blocks, NULL);
+	return __blockdev_direct_IO(rw, iocb, inode, I_BDEV(inode), iov, offset,
+				    nr_segs, blkdev_get_blocks, NULL, NULL, 0);
 }
 
 int __sync_blockdev(struct block_device *bdev, int wait)

commit 6e9624b8caec290d28b4c6d9ec75749df6372b87
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Sat Aug 7 18:25:34 2010 +0200

    block: push down BKL into .open and .release
    
    The open and release block_device_operations are currently
    called with the BKL held. In order to change that, we must
    first make sure that all drivers that currently rely
    on this have no regressions.
    
    This blindly pushes the BKL into all .open and .release
    operations for all block drivers to prepare for the
    next step. The drivers can subsequently replace the BKL
    with their own locks or remove it completely when it can
    be shown that it is not needed.
    
    The functions blkdev_get and blkdev_put are the only
    remaining users of the big kernel lock in the block
    layer, besides a few uses in the ioctl code, none
    of which need to serialize with blkdev_{get,put}.
    
    Most of these two functions is also under the protection
    of bdev->bd_mutex, including the actual calls to
    ->open and ->release, and the common code does not
    access any global data structures that need the BKL.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 99d6af811747..693c2bf5d65e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1345,13 +1345,12 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		return ret;
 	}
 
-	lock_kernel();
  restart:
 
 	ret = -ENXIO;
 	disk = get_gendisk(bdev->bd_dev, &partno);
 	if (!disk)
-		goto out_unlock_kernel;
+		goto out;
 
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (!bdev->bd_openers) {
@@ -1431,7 +1430,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	if (for_part)
 		bdev->bd_part_count++;
 	mutex_unlock(&bdev->bd_mutex);
-	unlock_kernel();
 	return 0;
 
  out_clear:
@@ -1444,9 +1442,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	bdev->bd_contains = NULL;
  out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
- out_unlock_kernel:
-	unlock_kernel();
-
+ out:
 	if (disk)
 		module_put(disk->fops->owner);
 	put_disk(disk);
@@ -1515,7 +1511,6 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 	struct block_device *victim = NULL;
 
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
-	lock_kernel();
 	if (for_part)
 		bdev->bd_part_count--;
 
@@ -1540,7 +1535,6 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 			victim = bdev->bd_contains;
 		bdev->bd_contains = NULL;
 	}
-	unlock_kernel();
 	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);
 	if (victim)

commit e75aa85892b2ee78c79edac720868cbef16e62eb
Author: Tejun Heo <htejun@gmail.com>
Date:   Wed Aug 4 17:59:39 2010 +0200

    block_dev: always serialize exclusive open attempts
    
    bd_prepare_to_claim() incorrectly allowed multiple attempts for
    exclusive open to progress in parallel if the attempting holders are
    identical.  This triggered BUG_ON() as reported in the following bug.
    
      https://bugzilla.kernel.org/show_bug.cgi?id=16393
    
    __bd_abort_claiming() is used to finish claiming blocks and doesn't
    work if multiple openers are inside a claiming block.  Allowing
    multiple parallel open attempts to continue doesn't gain anything as
    those are serialized down in the call chain anyway.  Fix it by always
    allowing only single open attempt in a claiming block.
    
    This problem can easily be reproduced by adding a delay after
    bd_prepare_to_claim() and attempting to mount two partitions of a
    disk.
    
    stable: only applicable to v2.6.35
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 99d6af811747..b3171fb0dc9a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -681,8 +681,8 @@ static int bd_prepare_to_claim(struct block_device *bdev,
 	if (!bd_may_claim(bdev, whole, holder))
 		return -EBUSY;
 
-	/* if someone else is claiming, wait for it to finish */
-	if (whole->bd_claiming && whole->bd_claiming != holder) {
+	/* if claiming is already in progress, wait for it to finish */
+	if (whole->bd_claiming) {
 		wait_queue_head_t *wq = bit_waitqueue(&whole->bd_claiming, 0);
 		DEFINE_WAIT(wait);
 

commit 3e6c05052c262ebe7fdd85e75e9d4f956cdd8d82
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Mon Jun 7 20:17:38 2010 +0200

    block: remove duplicate BUG_ON() in bd_finish_claiming()
    
    We do the same BUG_ON() just a line later when calling into
    __bd_abort_claiming().
    
    Reported-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a1642ef60197..99d6af811747 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -817,7 +817,6 @@ static void bd_finish_claiming(struct block_device *bdev,
 				struct block_device *whole, void *holder)
 {
 	spin_lock(&bdev_lock);
-	BUG_ON(whole->bd_claiming != holder);
 	BUG_ON(!bd_may_claim(bdev, whole, holder));
 	__bd_claim(bdev, whole, holder);
 	__bd_abort_claiming(whole, holder); /* not actually an abort */

commit b0018361c3f934858592cbbb5e1a4f318c2a70ed
Author: Nick Piggin <npiggin@suse.de>
Date:   Wed May 26 01:51:19 2010 +1000

    block: bd_start_claiming cleanup
    
    I don't like the subtle multi-context code in bd_claim (ie.  detects where it
    has been called based on bd_claiming). It seems clearer to just require a new
    function to finish a 2-part claim.
    
    Also improve commentary in bd_start_claiming as to how it should
    be used.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 204a7632c511..a1642ef60197 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -706,8 +706,13 @@ static int bd_prepare_to_claim(struct block_device *bdev,
  * @bdev is about to be opened exclusively.  Check @bdev can be opened
  * exclusively and mark that an exclusive open is in progress.  Each
  * successful call to this function must be matched with a call to
- * either bd_claim() or bd_abort_claiming().  If this function
- * succeeds, the matching bd_claim() is guaranteed to succeed.
+ * either bd_finish_claiming() or bd_abort_claiming() (which do not
+ * fail).
+ *
+ * This function is used to gain exclusive access to the block device
+ * without actually causing other exclusive open attempts to fail. It
+ * should be used when the open sequence itself requires exclusive
+ * access but may subsequently fail.
  *
  * CONTEXT:
  * Might sleep.
@@ -783,15 +788,47 @@ static void bd_abort_claiming(struct block_device *whole, void *holder)
 	__bd_abort_claiming(whole, holder);		/* releases bdev_lock */
 }
 
+/* increment holders when we have a legitimate claim. requires bdev_lock */
+static void __bd_claim(struct block_device *bdev, struct block_device *whole,
+					void *holder)
+{
+	/* note that for a whole device bd_holders
+	 * will be incremented twice, and bd_holder will
+	 * be set to bd_claim before being set to holder
+	 */
+	whole->bd_holders++;
+	whole->bd_holder = bd_claim;
+	bdev->bd_holders++;
+	bdev->bd_holder = holder;
+}
+
+/**
+ * bd_finish_claiming - finish claiming a block device
+ * @bdev: block device of interest (passed to bd_start_claiming())
+ * @whole: whole block device returned by bd_start_claiming()
+ * @holder: holder trying to claim @bdev
+ *
+ * Finish a claiming block started by bd_start_claiming().
+ *
+ * CONTEXT:
+ * Grabs and releases bdev_lock.
+ */
+static void bd_finish_claiming(struct block_device *bdev,
+				struct block_device *whole, void *holder)
+{
+	spin_lock(&bdev_lock);
+	BUG_ON(whole->bd_claiming != holder);
+	BUG_ON(!bd_may_claim(bdev, whole, holder));
+	__bd_claim(bdev, whole, holder);
+	__bd_abort_claiming(whole, holder); /* not actually an abort */
+}
+
 /**
  * bd_claim - claim a block device
  * @bdev: block device to claim
  * @holder: holder trying to claim @bdev
  *
- * Try to claim @bdev which must have been opened successfully.  This
- * function may be called with or without preceding
- * blk_start_claiming().  In the former case, this function is always
- * successful and terminates the claiming block.
+ * Try to claim @bdev which must have been opened successfully.
  *
  * CONTEXT:
  * Might sleep.
@@ -807,23 +844,10 @@ int bd_claim(struct block_device *bdev, void *holder)
 	might_sleep();
 
 	spin_lock(&bdev_lock);
-
 	res = bd_prepare_to_claim(bdev, whole, holder);
-	if (res == 0) {
-		/* note that for a whole device bd_holders
-		 * will be incremented twice, and bd_holder will
-		 * be set to bd_claim before being set to holder
-		 */
-		whole->bd_holders++;
-		whole->bd_holder = bd_claim;
-		bdev->bd_holders++;
-		bdev->bd_holder = holder;
-	}
-
-	if (whole->bd_claiming)
-		__bd_abort_claiming(whole, holder);	/* releases bdev_lock */
-	else
-		spin_unlock(&bdev_lock);
+	if (res == 0)
+		__bd_claim(bdev, whole, holder);
+	spin_unlock(&bdev_lock);
 
 	return res;
 }
@@ -1477,7 +1501,7 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 
 	if (whole) {
 		if (res == 0)
-			BUG_ON(bd_claim(bdev, filp) != 0);
+			bd_finish_claiming(bdev, whole, filp);
 		else
 			bd_abort_claiming(whole, filp);
 	}
@@ -1713,7 +1737,7 @@ struct block_device *open_bdev_exclusive(const char *path, fmode_t mode, void *h
 	if ((mode & FMODE_WRITE) && bdev_read_only(bdev))
 		goto out_blkdev_put;
 
-	BUG_ON(bd_claim(bdev, holder) != 0);
+	bd_finish_claiming(bdev, whole, holder);
 	return bdev;
 
 out_blkdev_put:

commit cf3425707ed9ce0d5ebaba20bc3d22dd39e52f2f
Author: Nick Piggin <npiggin@suse.de>
Date:   Wed May 26 01:50:21 2010 +1000

    block: bd_start_claiming fix module refcount
    
    bd_start_claiming has an unbalanced module_put introduced in 6b4517a79.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7346c96308a5..204a7632c511 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -734,6 +734,7 @@ static struct block_device *bd_start_claiming(struct block_device *bdev,
 		return ERR_PTR(-ENXIO);
 
 	whole = bdget_disk(disk, 0);
+	module_put(disk->fops->owner);
 	put_disk(disk);
 	if (!whole)
 		return ERR_PTR(-ENOMEM);

commit 3322e79a3860fd0d50e3c1879b2e98ac582c0ff6
Author: Nick Piggin <npiggin@suse.de>
Date:   Thu May 27 22:42:19 2010 +1000

    fs: convert simple fs to new truncate
    
    Convert simple filesystems: ramfs, configfs, sysfs, block_dev to new truncate
    sequence.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d0b37e626a1a..7346c96308a5 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -172,8 +172,9 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 	struct file *file = iocb->ki_filp;
 	struct inode *inode = file->f_mapping->host;
 
-	return blockdev_direct_IO_no_locking(rw, iocb, inode, I_BDEV(inode),
-				iov, offset, nr_segs, blkdev_get_blocks, NULL);
+	return blockdev_direct_IO_no_locking_newtrunc(rw, iocb, inode,
+				I_BDEV(inode), iov, offset, nr_segs,
+				blkdev_get_blocks, NULL);
 }
 
 int __sync_blockdev(struct block_device *bdev, int wait)
@@ -309,8 +310,8 @@ static int blkdev_write_begin(struct file *file, struct address_space *mapping,
 			struct page **pagep, void **fsdata)
 {
 	*pagep = NULL;
-	return block_write_begin(file, mapping, pos, len, flags, pagep, fsdata,
-				blkdev_get_block);
+	return block_write_begin_newtrunc(file, mapping, pos, len, flags,
+				pagep, fsdata, blkdev_get_block);
 }
 
 static int blkdev_write_end(struct file *file, struct address_space *mapping,

commit 7ea8085910ef3dd4f3cad6845aaa2b580d39b115
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 26 17:53:25 2010 +0200

    drop unused dentry argument to ->fsync
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 26e5f5026620..d0b37e626a1a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -358,12 +358,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
 	return retval;
 }
 	
-/*
- *	Filp is never NULL; the only case when ->fsync() is called with
- *	NULL first argument is nfsd_sync_dir() and that's not a directory.
- */
- 
-int blkdev_fsync(struct file *filp, struct dentry *dentry, int datasync)
+int blkdev_fsync(struct file *filp, int datasync)
 {
 	struct inode *bd_inode = filp->f_mapping->host;
 	struct block_device *bdev = I_BDEV(bd_inode);

commit e8bebe2f71d26871b0970ae1d9cf0ed3cdd9569d
Merge: 6109e2ce2600 82f3952c02ad
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 21 19:37:45 2010 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6: (69 commits)
      fix handling of offsets in cris eeprom.c, get rid of fake on-stack files
      get rid of home-grown mutex in cris eeprom.c
      switch ecryptfs_write() to struct inode *, kill on-stack fake files
      switch ecryptfs_get_locked_page() to struct inode *
      simplify access to ecryptfs inodes in ->readpage() and friends
      AFS: Don't put struct file on the stack
      Ban ecryptfs over ecryptfs
      logfs: replace inode uid,gid,mode initialization with helper function
      ufs: replace inode uid,gid,mode initialization with helper function
      udf: replace inode uid,gid,mode init with helper
      ubifs: replace inode uid,gid,mode initialization with helper function
      sysv: replace inode uid,gid,mode initialization with helper function
      reiserfs: replace inode uid,gid,mode initialization with helper function
      ramfs: replace inode uid,gid,mode initialization with helper function
      omfs: replace inode uid,gid,mode initialization with helper function
      bfs: replace inode uid,gid,mode initialization with helper function
      ocfs2: replace inode uid,gid,mode initialization with helper function
      nilfs2: replace inode uid,gid,mode initialization with helper function
      minix: replace inode uid,gid,mode init with helper
      ext4: replace inode uid,gid,mode init with helper
      ...
    
    Trivial conflict in fs/fs-writeback.c (mark bitfields unsigned)

commit 18e9e5104fcd9a973ffe3eed3816c87f2a1b6cd2
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Mar 23 10:34:56 2010 -0400

    Introduce freeze_super and thaw_super for the fsfreeze ioctl
    
    Currently the way we do freezing is by passing sb>s_bdev to freeze_bdev and then
    letting it do all the work.  But freezing is more of an fs thing, and doesn't
    really have much to do with the bdev at all, all the work gets done with the
    super.  In btrfs we do not populate s_bdev, since we can have multiple bdev's
    for one fs and setting s_bdev makes removing devices from a pool kind of tricky.
    This means that freezing a btrfs filesystem fails, which causes us to corrupt
    with things like tux-on-ice which use the fsfreeze mechanism.  So instead of
    populating sb->s_bdev with a random bdev in our pool, I've broken the actual fs
    freezing stuff into freeze_super and thaw_super.  These just take the
    super_block that we're freezing and does the appropriate work.  It's basically
    just copy and pasted from freeze_bdev.  I've then converted freeze_bdev over to
    use the new super helpers.  I've tested this with ext4 and btrfs and verified
    everything continues to work the same as before.
    
    The only new gotcha is multiple calls to the fsfreeze ioctl will return EBUSY if
    the fs is already frozen.  I thought this was a better solution than adding a
    freeze counter to the super_block, but if everybody hates this idea I'm open to
    suggestions.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 39cb6591d37d..1aba036dcabf 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -245,38 +245,14 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 	sb = get_active_super(bdev);
 	if (!sb)
 		goto out;
-	down_write(&sb->s_umount);
-	if (sb->s_flags & MS_RDONLY) {
-		sb->s_frozen = SB_FREEZE_TRANS;
-		up_write(&sb->s_umount);
+	error = freeze_super(sb);
+	if (error) {
+		deactivate_super(sb);
+		bdev->bd_fsfreeze_count--;
 		mutex_unlock(&bdev->bd_fsfreeze_mutex);
-		return sb;
-	}
-
-	sb->s_frozen = SB_FREEZE_WRITE;
-	smp_wmb();
-
-	sync_filesystem(sb);
-
-	sb->s_frozen = SB_FREEZE_TRANS;
-	smp_wmb();
-
-	sync_blockdev(sb->s_bdev);
-
-	if (sb->s_op->freeze_fs) {
-		error = sb->s_op->freeze_fs(sb);
-		if (error) {
-			printk(KERN_ERR
-				"VFS:Filesystem freeze failed\n");
-			sb->s_frozen = SB_UNFROZEN;
-			deactivate_locked_super(sb);
-			bdev->bd_fsfreeze_count--;
-			mutex_unlock(&bdev->bd_fsfreeze_mutex);
-			return ERR_PTR(error);
-		}
+		return ERR_PTR(error);
 	}
-	up_write(&sb->s_umount);
-
+	deactivate_super(sb);
  out:
 	sync_blockdev(bdev);
 	mutex_unlock(&bdev->bd_fsfreeze_mutex);
@@ -297,40 +273,22 @@ int thaw_bdev(struct block_device *bdev, struct super_block *sb)
 
 	mutex_lock(&bdev->bd_fsfreeze_mutex);
 	if (!bdev->bd_fsfreeze_count)
-		goto out_unlock;
+		goto out;
 
 	error = 0;
 	if (--bdev->bd_fsfreeze_count > 0)
-		goto out_unlock;
+		goto out;
 
 	if (!sb)
-		goto out_unlock;
-
-	BUG_ON(sb->s_bdev != bdev);
-	down_write(&sb->s_umount);
-	if (sb->s_flags & MS_RDONLY)
-		goto out_unfrozen;
-
-	if (sb->s_op->unfreeze_fs) {
-		error = sb->s_op->unfreeze_fs(sb);
-		if (error) {
-			printk(KERN_ERR
-				"VFS:Filesystem thaw failed\n");
-			sb->s_frozen = SB_FREEZE_TRANS;
-			bdev->bd_fsfreeze_count++;
-			mutex_unlock(&bdev->bd_fsfreeze_mutex);
-			return error;
-		}
-	}
-
-out_unfrozen:
-	sb->s_frozen = SB_UNFROZEN;
-	smp_wmb();
-	wake_up(&sb->s_wait_unfrozen);
+		goto out;
 
-	if (sb)
-		deactivate_locked_super(sb);
-out_unlock:
+	error = thaw_super(sb);
+	if (error) {
+		bdev->bd_fsfreeze_count++;
+		mutex_unlock(&bdev->bd_fsfreeze_mutex);
+		return error;
+	}
+out:
 	mutex_unlock(&bdev->bd_fsfreeze_mutex);
 	return 0;
 }

commit d3f2147307cce9eac56dd91d381709aa3f1615b3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Mar 23 11:11:05 2010 -0400

    Move grabbing s_umount to callers of grab_super()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 6dcee88c2e5d..39cb6591d37d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -245,6 +245,7 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 	sb = get_active_super(bdev);
 	if (!sb)
 		goto out;
+	down_write(&sb->s_umount);
 	if (sb->s_flags & MS_RDONLY) {
 		sb->s_frozen = SB_FREEZE_TRANS;
 		up_write(&sb->s_umount);

commit 7407cf355fdf5500430be966dbbde84a27293bad
Merge: 6a47dc141868 79dba2eaa771
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Thu Apr 29 09:36:24 2010 +0200

    Merge branch 'master' into for-2.6.35
    
    Conflicts:
            fs/block_dev.c
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

commit fbd9b09a177a481eda256447c881f014f29034fe
Author: Dmitry Monakhov <dmonakhov@openvz.org>
Date:   Wed Apr 28 17:55:06 2010 +0400

    blkdev: generalize flags for blkdev_issue_fn functions
    
    The patch just convert all blkdev_issue_xxx function to common
    set of flags. Wait/allocation semantics preserved.
    
    Signed-off-by: Dmitry Monakhov <dmonakhov@openvz.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ea8385ea58ab..dd769304382e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -413,7 +413,8 @@ int blkdev_fsync(struct file *filp, struct dentry *dentry, int datasync)
 	if (error)
 		return error;
 	
-	error = blkdev_issue_flush(bdev, NULL);
+	error = blkdev_issue_flush(bdev, GFP_KERNEL, NULL,
+				(BLKDEV_IFL_WAIT));
 	if (error == -EOPNOTSUPP)
 		error = 0;
 	return error;

commit 6b4517a7913a09d3259bb1d21c9cb300f12294bd
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 7 18:53:59 2010 +0900

    block: implement bd_claiming and claiming block
    
    Currently, device claiming for exclusive open is done after low level
    open - disk->fops->open() - has completed successfully.  This means
    that exclusive open attempts while a device is already exclusively
    open will fail only after disk->fops->open() is called.
    
    cdrom driver issues commands during open() which means that O_EXCL
    open attempt can unintentionally inject commands to in-progress
    command stream for burning thus disturbing burning process.  In most
    cases, this doesn't cause problems because the first command to be
    issued is TUR which most devices can process in the middle of burning.
    However, depending on how a device replies to TUR during burning,
    cdrom driver may end up issuing further commands.
    
    This can't be resolved trivially by moving bd_claim() before doing
    actual open() because that means an open attempt which will end up
    failing could interfere other legit O_EXCL open attempts.
    ie. unconfirmed open attempts can fail others.
    
    This patch resolves the problem by introducing claiming block which is
    started by bd_start_claiming() and terminated either by bd_claim() or
    bd_abort_claiming().  bd_claim() from inside a claiming block is
    guaranteed to succeed and once a claiming block is started, other
    bd_start_claiming() or bd_claim() attempts block till the current
    claiming block is terminated.
    
    bd_claim() can still be used standalone although now it always
    synchronizes against claiming blocks, so the existing users will keep
    working without any change.
    
    blkdev_open() and open_bdev_exclusive() are converted to use claiming
    blocks so that exclusive open attempts from these functions don't
    interfere with the existing exclusive open.
    
    This problem was discovered while investigating bko#15403.
    
      https://bugzilla.kernel.org/show_bug.cgi?id=15403
    
    The burning problem itself can be resolved by updating userspace
    probing tools to always open w/ O_EXCL.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Matthias-Christian Ott <ott@mirix.org>
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e59440c7e1cf..ea8385ea58ab 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -693,12 +693,145 @@ static bool bd_may_claim(struct block_device *bdev, struct block_device *whole,
 		return true;	 /* is a partition of an un-held device */
 }
 
+/**
+ * bd_prepare_to_claim - prepare to claim a block device
+ * @bdev: block device of interest
+ * @whole: the whole device containing @bdev, may equal @bdev
+ * @holder: holder trying to claim @bdev
+ *
+ * Prepare to claim @bdev.  This function fails if @bdev is already
+ * claimed by another holder and waits if another claiming is in
+ * progress.  This function doesn't actually claim.  On successful
+ * return, the caller has ownership of bd_claiming and bd_holder[s].
+ *
+ * CONTEXT:
+ * spin_lock(&bdev_lock).  Might release bdev_lock, sleep and regrab
+ * it multiple times.
+ *
+ * RETURNS:
+ * 0 if @bdev can be claimed, -EBUSY otherwise.
+ */
+static int bd_prepare_to_claim(struct block_device *bdev,
+			       struct block_device *whole, void *holder)
+{
+retry:
+	/* if someone else claimed, fail */
+	if (!bd_may_claim(bdev, whole, holder))
+		return -EBUSY;
+
+	/* if someone else is claiming, wait for it to finish */
+	if (whole->bd_claiming && whole->bd_claiming != holder) {
+		wait_queue_head_t *wq = bit_waitqueue(&whole->bd_claiming, 0);
+		DEFINE_WAIT(wait);
+
+		prepare_to_wait(wq, &wait, TASK_UNINTERRUPTIBLE);
+		spin_unlock(&bdev_lock);
+		schedule();
+		finish_wait(wq, &wait);
+		spin_lock(&bdev_lock);
+		goto retry;
+	}
+
+	/* yay, all mine */
+	return 0;
+}
+
+/**
+ * bd_start_claiming - start claiming a block device
+ * @bdev: block device of interest
+ * @holder: holder trying to claim @bdev
+ *
+ * @bdev is about to be opened exclusively.  Check @bdev can be opened
+ * exclusively and mark that an exclusive open is in progress.  Each
+ * successful call to this function must be matched with a call to
+ * either bd_claim() or bd_abort_claiming().  If this function
+ * succeeds, the matching bd_claim() is guaranteed to succeed.
+ *
+ * CONTEXT:
+ * Might sleep.
+ *
+ * RETURNS:
+ * Pointer to the block device containing @bdev on success, ERR_PTR()
+ * value on failure.
+ */
+static struct block_device *bd_start_claiming(struct block_device *bdev,
+					      void *holder)
+{
+	struct gendisk *disk;
+	struct block_device *whole;
+	int partno, err;
+
+	might_sleep();
+
+	/*
+	 * @bdev might not have been initialized properly yet, look up
+	 * and grab the outer block device the hard way.
+	 */
+	disk = get_gendisk(bdev->bd_dev, &partno);
+	if (!disk)
+		return ERR_PTR(-ENXIO);
+
+	whole = bdget_disk(disk, 0);
+	put_disk(disk);
+	if (!whole)
+		return ERR_PTR(-ENOMEM);
+
+	/* prepare to claim, if successful, mark claiming in progress */
+	spin_lock(&bdev_lock);
+
+	err = bd_prepare_to_claim(bdev, whole, holder);
+	if (err == 0) {
+		whole->bd_claiming = holder;
+		spin_unlock(&bdev_lock);
+		return whole;
+	} else {
+		spin_unlock(&bdev_lock);
+		bdput(whole);
+		return ERR_PTR(err);
+	}
+}
+
+/* releases bdev_lock */
+static void __bd_abort_claiming(struct block_device *whole, void *holder)
+{
+	BUG_ON(whole->bd_claiming != holder);
+	whole->bd_claiming = NULL;
+	wake_up_bit(&whole->bd_claiming, 0);
+
+	spin_unlock(&bdev_lock);
+	bdput(whole);
+}
+
+/**
+ * bd_abort_claiming - abort claiming a block device
+ * @whole: whole block device returned by bd_start_claiming()
+ * @holder: holder trying to claim @bdev
+ *
+ * Abort a claiming block started by bd_start_claiming().  Note that
+ * @whole is not the block device to be claimed but the whole device
+ * returned by bd_start_claiming().
+ *
+ * CONTEXT:
+ * Grabs and releases bdev_lock.
+ */
+static void bd_abort_claiming(struct block_device *whole, void *holder)
+{
+	spin_lock(&bdev_lock);
+	__bd_abort_claiming(whole, holder);		/* releases bdev_lock */
+}
+
 /**
  * bd_claim - claim a block device
  * @bdev: block device to claim
  * @holder: holder trying to claim @bdev
  *
- * Try to claim @bdev.
+ * Try to claim @bdev which must have been opened successfully.  This
+ * function may be called with or without preceding
+ * blk_start_claiming().  In the former case, this function is always
+ * successful and terminates the claiming block.
+ *
+ * CONTEXT:
+ * Might sleep.
  *
  * RETURNS:
  * 0 if successful, -EBUSY if @bdev is already claimed.
@@ -706,11 +839,14 @@ static bool bd_may_claim(struct block_device *bdev, struct block_device *whole,
 int bd_claim(struct block_device *bdev, void *holder)
 {
 	struct block_device *whole = bdev->bd_contains;
-	int res = -EBUSY;
+	int res;
+
+	might_sleep();
 
 	spin_lock(&bdev_lock);
 
-	if (bd_may_claim(bdev, whole, holder)) {
+	res = bd_prepare_to_claim(bdev, whole, holder);
+	if (res == 0) {
 		/* note that for a whole device bd_holders
 		 * will be incremented twice, and bd_holder will
 		 * be set to bd_claim before being set to holder
@@ -719,10 +855,13 @@ int bd_claim(struct block_device *bdev, void *holder)
 		whole->bd_holder = bd_claim;
 		bdev->bd_holders++;
 		bdev->bd_holder = holder;
-		res = 0;
 	}
 
-	spin_unlock(&bdev_lock);
+	if (whole->bd_claiming)
+		__bd_abort_claiming(whole, holder);	/* releases bdev_lock */
+	else
+		spin_unlock(&bdev_lock);
+
 	return res;
 }
 EXPORT_SYMBOL(bd_claim);
@@ -1338,6 +1477,7 @@ EXPORT_SYMBOL(blkdev_get);
 
 static int blkdev_open(struct inode * inode, struct file * filp)
 {
+	struct block_device *whole = NULL;
 	struct block_device *bdev;
 	int res;
 
@@ -1360,22 +1500,25 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	if (bdev == NULL)
 		return -ENOMEM;
 
+	if (filp->f_mode & FMODE_EXCL) {
+		whole = bd_start_claiming(bdev, filp);
+		if (IS_ERR(whole)) {
+			bdput(bdev);
+			return PTR_ERR(whole);
+		}
+	}
+
 	filp->f_mapping = bdev->bd_inode->i_mapping;
 
 	res = blkdev_get(bdev, filp->f_mode);
-	if (res)
-		return res;
 
-	if (filp->f_mode & FMODE_EXCL) {
-		res = bd_claim(bdev, filp);
-		if (res)
-			goto out_blkdev_put;
+	if (whole) {
+		if (res == 0)
+			BUG_ON(bd_claim(bdev, filp) != 0);
+		else
+			bd_abort_claiming(whole, filp);
 	}
 
-	return 0;
-
- out_blkdev_put:
-	blkdev_put(bdev, filp->f_mode);
 	return res;
 }
 
@@ -1586,27 +1729,34 @@ EXPORT_SYMBOL(lookup_bdev);
  */
 struct block_device *open_bdev_exclusive(const char *path, fmode_t mode, void *holder)
 {
-	struct block_device *bdev;
-	int error = 0;
+	struct block_device *bdev, *whole;
+	int error;
 
 	bdev = lookup_bdev(path);
 	if (IS_ERR(bdev))
 		return bdev;
 
+	whole = bd_start_claiming(bdev, holder);
+	if (IS_ERR(whole)) {
+		bdput(bdev);
+		return whole;
+	}
+
 	error = blkdev_get(bdev, mode);
 	if (error)
-		return ERR_PTR(error);
+		goto out_abort_claiming;
+
 	error = -EACCES;
 	if ((mode & FMODE_WRITE) && bdev_read_only(bdev))
-		goto blkdev_put;
-	error = bd_claim(bdev, holder);
-	if (error)
-		goto blkdev_put;
+		goto out_blkdev_put;
 
+	BUG_ON(bd_claim(bdev, holder) != 0);
 	return bdev;
-	
-blkdev_put:
+
+out_blkdev_put:
 	blkdev_put(bdev, mode);
+out_abort_claiming:
+	bd_abort_claiming(whole, holder);
 	return ERR_PTR(error);
 }
 

commit 1a3cbbc5a5e8a66934aa0947896a4aca6fd77298
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 7 18:52:29 2010 +0900

    block: factor out bd_may_claim()
    
    Factor out bd_may_claim() from bd_claim(), add comments and apply a
    couple of cosmetic edits.  This is to prepare for further updates to
    claim path.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2a6d0193f139..e59440c7e1cf 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -661,41 +661,70 @@ void bd_forget(struct inode *inode)
 		iput(bdev->bd_inode);
 }
 
-int bd_claim(struct block_device *bdev, void *holder)
+/**
+ * bd_may_claim - test whether a block device can be claimed
+ * @bdev: block device of interest
+ * @whole: whole block device containing @bdev, may equal @bdev
+ * @holder: holder trying to claim @bdev
+ *
+ * Test whther @bdev can be claimed by @holder.
+ *
+ * CONTEXT:
+ * spin_lock(&bdev_lock).
+ *
+ * RETURNS:
+ * %true if @bdev can be claimed, %false otherwise.
+ */
+static bool bd_may_claim(struct block_device *bdev, struct block_device *whole,
+			 void *holder)
 {
-	int res;
-	spin_lock(&bdev_lock);
-
-	/* first decide result */
 	if (bdev->bd_holder == holder)
-		res = 0;	 /* already a holder */
+		return true;	 /* already a holder */
 	else if (bdev->bd_holder != NULL)
-		res = -EBUSY; 	 /* held by someone else */
+		return false; 	 /* held by someone else */
 	else if (bdev->bd_contains == bdev)
-		res = 0;  	 /* is a whole device which isn't held */
+		return true;  	 /* is a whole device which isn't held */
 
-	else if (bdev->bd_contains->bd_holder == bd_claim)
-		res = 0; 	 /* is a partition of a device that is being partitioned */
-	else if (bdev->bd_contains->bd_holder != NULL)
-		res = -EBUSY;	 /* is a partition of a held device */
+	else if (whole->bd_holder == bd_claim)
+		return true; 	 /* is a partition of a device that is being partitioned */
+	else if (whole->bd_holder != NULL)
+		return false;	 /* is a partition of a held device */
 	else
-		res = 0;	 /* is a partition of an un-held device */
+		return true;	 /* is a partition of an un-held device */
+}
 
-	/* now impose change */
-	if (res==0) {
+/**
+ * bd_claim - claim a block device
+ * @bdev: block device to claim
+ * @holder: holder trying to claim @bdev
+ *
+ * Try to claim @bdev.
+ *
+ * RETURNS:
+ * 0 if successful, -EBUSY if @bdev is already claimed.
+ */
+int bd_claim(struct block_device *bdev, void *holder)
+{
+	struct block_device *whole = bdev->bd_contains;
+	int res = -EBUSY;
+
+	spin_lock(&bdev_lock);
+
+	if (bd_may_claim(bdev, whole, holder)) {
 		/* note that for a whole device bd_holders
 		 * will be incremented twice, and bd_holder will
 		 * be set to bd_claim before being set to holder
 		 */
-		bdev->bd_contains->bd_holders ++;
-		bdev->bd_contains->bd_holder = bd_claim;
+		whole->bd_holders++;
+		whole->bd_holder = bd_claim;
 		bdev->bd_holders++;
 		bdev->bd_holder = holder;
+		res = 0;
 	}
+
 	spin_unlock(&bdev_lock);
 	return res;
 }
-
 EXPORT_SYMBOL(bd_claim);
 
 void bd_release(struct block_device *bdev)

commit b8af67e2681c693a21f3933e3bdfce4cf66596d3
Author: Anton Blanchard <anton@samba.org>
Date:   Fri Apr 23 13:18:06 2010 -0400

    fs/block_dev.c: fix performance regression in O_DIRECT|O_SYNC writes to block devices
    
    We are seeing a large regression in database performance on recent
    kernels.  The database opens a block device with O_DIRECT|O_SYNC and a
    number of threads write to different regions of the file at the same time.
    
    A simple test case is below.  I haven't defined DEVICE since getting it
    wrong will destroy your data :) On an 3 disk LVM with a 64k chunk size we
    see about 17MB/sec and only a few threads in IO wait:
    
    procs  -----io---- -system-- -----cpu------
     r  b     bi    bo   in   cs us sy id wa st
     0  3      0 16170  656 2259  0  0 86 14  0
     0  2      0 16704  695 2408  0  0 92  8  0
     0  2      0 17308  744 2653  0  0 86 14  0
     0  2      0 17933  759 2777  0  0 89 10  0
    
    Most threads are blocking in vfs_fsync_range, which has:
    
            mutex_lock(&mapping->host->i_mutex);
            err = fop->fsync(file, dentry, datasync);
            if (!ret)
                    ret = err;
            mutex_unlock(&mapping->host->i_mutex);
    
    commit 148f948ba877f4d3cdef036b1ff6d9f68986706a (vfs: Introduce new
    helpers for syncing after writing to O_SYNC file or IS_SYNC inode) offers
    some explanation of what is going on:
    
        Use these new helpers for syncing from generic VFS functions. This makes
        O_SYNC writes to block devices acquire i_mutex for syncing. If we really
        care about this, we can make block_fsync() drop the i_mutex and reacquire
        it before it returns.
    
    Thanks Jan for such a good commit message!  As well as dropping i_mutex,
    Christoph suggests we should remove the call to sync_blockdev():
    
    > sync_blockdev is an overcomplicated alias for filemap_write_and_wait on
    > the block device inode, which is exactly what we did just before calling
    > into ->fsync
    
    The patch below incorporates both suggestions. With it the testcase improves
    from 17MB/s to 68M/sec:
    
    procs  -----io---- -system-- -----cpu------
     r  b     bi    bo   in   cs us sy id wa st
     0  7      0 65536 1000 3878  0  0 70 30  0
     0 34      0 69632 1016 3921  0  1 46 53  0
     0 57      0 69632 1000 3921  0  0 55 45  0
     0 53      0 69640  754 4111  0  0 81 19  0
    
    Testcase:
    
    #define _GNU_SOURCE
    #include <stdio.h>
    #include <pthread.h>
    #include <unistd.h>
    #include <stdlib.h>
    #include <string.h>
    #include <sys/types.h>
    #include <sys/stat.h>
    #include <fcntl.h>
    
    #define NR_THREADS 64
    #define BUFSIZE (64 * 1024)
    
    #define DEVICE "/dev/mapper/XXXXXX"
    
    #define ALIGN(VAL, SIZE) (((VAL)+(SIZE)-1) & ~((SIZE)-1))
    
    static int fd;
    
    static void *doit(void *arg)
    {
            unsigned long offset = (long)arg;
            char *b, *buf;
    
            b = malloc(BUFSIZE + 1024);
            buf = (char *)ALIGN((unsigned long)b, 1024);
            memset(buf, 0, BUFSIZE);
    
            while (1)
                    pwrite(fd, buf, BUFSIZE, offset);
    }
    
    int main(int argc, char *argv[])
    {
            int flags = O_RDWR|O_DIRECT;
            int i;
            unsigned long offset = 0;
    
            if (argc > 1 && !strcmp(argv[1], "O_SYNC"))
                    flags |= O_SYNC;
    
            fd = open(DEVICE, flags);
            if (fd == -1) {
                    perror("open");
                    exit(1);
            }
    
            for (i = 0; i < NR_THREADS-1; i++) {
                    pthread_t tid;
                    pthread_create(&tid, NULL, doit, (void *)offset);
                    offset += BUFSIZE;
            }
            doit((void *)offset);
    
            return 0;
    }
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Acked-by: Jan Kara <jack@suse.cz>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2a6d0193f139..6dcee88c2e5d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -406,16 +406,23 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
  
 int blkdev_fsync(struct file *filp, struct dentry *dentry, int datasync)
 {
-	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
+	struct inode *bd_inode = filp->f_mapping->host;
+	struct block_device *bdev = I_BDEV(bd_inode);
 	int error;
 
-	error = sync_blockdev(bdev);
-	if (error)
-		return error;
-	
+	/*
+	 * There is no need to serialise calls to blkdev_issue_flush with
+	 * i_mutex and doing so causes performance issues with concurrent
+	 * O_SYNC writers to a block device.
+	 */
+	mutex_unlock(&bd_inode->i_mutex);
+
 	error = blkdev_issue_flush(bdev, NULL);
 	if (error == -EOPNOTSUPP)
 		error = 0;
+
+	mutex_lock(&bd_inode->i_mutex);
+
 	return error;
 }
 EXPORT_SYMBOL(blkdev_fsync);

commit b1dd3b2843b3b73b7fc2ee47d96310cd1c051371
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Tue Apr 6 14:35:00 2010 -0700

    vfs: rename block_fsync() to blkdev_fsync()
    
    Requested by hch, for consistency now it is exported.
    
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8db62b2b6df8..2a6d0193f139 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -404,7 +404,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
  *	NULL first argument is nfsd_sync_dir() and that's not a directory.
  */
  
-int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
+int blkdev_fsync(struct file *filp, struct dentry *dentry, int datasync)
 {
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
 	int error;
@@ -418,7 +418,7 @@ int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
 		error = 0;
 	return error;
 }
-EXPORT_SYMBOL(block_fsync);
+EXPORT_SYMBOL(blkdev_fsync);
 
 /*
  * pseudo-fs
@@ -1482,7 +1482,7 @@ const struct file_operations def_blk_fops = {
   	.aio_read	= generic_file_aio_read,
 	.aio_write	= blkdev_aio_write,
 	.mmap		= generic_file_mmap,
-	.fsync		= block_fsync,
+	.fsync		= blkdev_fsync,
 	.unlocked_ioctl	= block_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl	= compat_blkdev_ioctl,

commit 55ab3a1ff843e3f0e24d2da44e71bffa5d853010
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Apr 6 14:34:58 2010 -0700

    raw: fsync method is now required
    
    Commit 148f948ba877f4d3cdef036b1ff6d9f68986706a (vfs: Introduce new
    helpers for syncing after writing to O_SYNC file or IS_SYNC inode) broke
    the raw driver.
    
    We now call through generic_file_aio_write -> generic_write_sync ->
    vfs_fsync_range.  vfs_fsync_range has:
    
            if (!fop || !fop->fsync) {
                    ret = -EINVAL;
                    goto out;
            }
    
    But drivers/char/raw.c doesn't set an fsync method.
    
    We have two options: fix it or remove the raw driver completely.  I'm
    happy to do either, the fact this has been broken for so long suggests it
    is rarely used.
    
    The patch below adds an fsync method to the raw driver.  My knowledge of
    the block layer is pretty sketchy so this could do with a once over.
    
    If we instead decide to remove the raw driver, this patch might still be
    useful as a backport to 2.6.33 and 2.6.32.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jens Axboe <jens.axboe@oracle.com>
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Tested-by: Jeff Moyer <jmoyer@redhat.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d11d0289f3d2..8db62b2b6df8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -404,7 +404,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
  *	NULL first argument is nfsd_sync_dir() and that's not a directory.
  */
  
-static int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
+int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
 {
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
 	int error;
@@ -418,6 +418,7 @@ static int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
 		error = 0;
 	return error;
 }
+EXPORT_SYMBOL(block_fsync);
 
 /*
  * pseudo-fs

commit 4b06e5b9ad8abb20105b2b25e42c509ebe9b2d76
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Fri Jan 29 09:56:22 2010 +0900

    freeze_bdev: don't deactivate successfully frozen MS_RDONLY sb
    
    Thanks Thomas and Christoph for testing and review.
    I removed 'smp_wmb()' before up_write from the previous patch,
    since up_write() should have necessary ordering constraints.
    (I.e. the change of s_frozen is visible to others after up_write)
    I'm quite sure the change is harmless but if you are uncomfortable
    with Tested-by/Reviewed-by on the modified patch, please remove them.
    
    If MS_RDONLY, freeze_bdev should just up_write(s_umount) instead of
    deactivate_locked_super().
    Also, keep sb->s_frozen consistent so that remount can check the frozen state.
    
    Otherwise a crash reported here can happen:
    http://lkml.org/lkml/2010/1/16/37
    http://lkml.org/lkml/2010/1/28/53
    
    This patch should be applied for 2.6.32 stable series, too.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Thomas Backlund <tmb@mandriva.org>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: stable@kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 73d6a735b8f3..d11d0289f3d2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -246,7 +246,8 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 	if (!sb)
 		goto out;
 	if (sb->s_flags & MS_RDONLY) {
-		deactivate_locked_super(sb);
+		sb->s_frozen = SB_FREEZE_TRANS;
+		up_write(&sb->s_umount);
 		mutex_unlock(&bdev->bd_fsfreeze_mutex);
 		return sb;
 	}
@@ -307,7 +308,7 @@ int thaw_bdev(struct block_device *bdev, struct super_block *sb)
 	BUG_ON(sb->s_bdev != bdev);
 	down_write(&sb->s_umount);
 	if (sb->s_flags & MS_RDONLY)
-		goto out_deactivate;
+		goto out_unfrozen;
 
 	if (sb->s_op->unfreeze_fs) {
 		error = sb->s_op->unfreeze_fs(sb);
@@ -321,11 +322,11 @@ int thaw_bdev(struct block_device *bdev, struct super_block *sb)
 		}
 	}
 
+out_unfrozen:
 	sb->s_frozen = SB_UNFROZEN;
 	smp_wmb();
 	wake_up(&sb->s_wait_unfrozen);
 
-out_deactivate:
 	if (sb)
 		deactivate_locked_super(sb);
 out_unlock:

commit 2058297d2d045cb57138c33b87cfabcc80e65186
Merge: 150e6c67f4bf 4b27e1bb442e
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Nov 3 21:14:39 2009 +0100

    Merge branch 'for-linus' into for-2.6.33
    
    Conflicts:
            block/cfq-iosched.c
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

commit ab0a9735e06914ce4d2a94ffa41497dbc142fe7f
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 29 14:14:04 2009 +0100

    blkdev: flush disk cache on ->fsync
    
    Currently there is no barrier support in the block device code.  That
    means we cannot guarantee any sort of data integerity when using the
    block device node with dis kwrite caches enabled.  Using the raw block
    device node is a typical use case for virtualization (and I assume
    databases, too).  This patch changes block_fsync to issue a cache flush
    and thus make fsync on block device nodes actually useful.
    
    Note that in mainline we would also need to add such code to the
    ->aio_write method for O_SYNC handling, but assuming that Jan's patch
    series for the O_SYNC rewrite goes in it will also call into ->fsync
    for 2.6.32.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9cf4b926f8e4..dde91e7e1c3a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -405,7 +405,17 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
  
 static int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
 {
-	return sync_blockdev(I_BDEV(filp->f_mapping->host));
+	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
+	int error;
+
+	error = sync_blockdev(bdev);
+	if (error)
+		return error;
+	
+	error = blkdev_issue_flush(bdev, NULL);
+	if (error == -EOPNOTSUPP)
+		error = 0;
+	return error;
 }
 
 /*

commit 960cc0f4fef607baabc2232fbd7cce5368a9dcfd
Author: Neil Brown <neilb@suse.de>
Date:   Mon Oct 26 08:59:17 2009 +0100

    block: use after free bug in __blkdev_get
    
    commit 0762b8bde9729f10f8e6249809660ff2ec3ad735
    (from 14 months ago) introduced a use-after-free bug which has just
    recently started manifesting in my md testing.
    I tried git bisect to find out what caused the bug to start
    manifesting, and it could have been the recent change to
    blk_unregister_queue (48c0d4d4c04) but the results were inconclusive.
    
    This patch certainly fixes my symptoms and looks correct as the two
    calls are now in the same order as elsewhere in that function.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9cf4b926f8e4..8bed0557d88c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1248,8 +1248,8 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
 		}
 	} else {
-		put_disk(disk);
 		module_put(disk->fops->owner);
+		put_disk(disk);
 		disk = NULL;
 		if (bdev->bd_contains == bdev) {
 			if (bdev->bd_disk->fops->open) {

commit 4504230a71566785a05d3e6b53fa1ee071b864eb
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Aug 3 23:28:35 2009 +0200

    freeze_bdev: grab active reference to frozen superblocks
    
    Currently we held s_umount while a filesystem is frozen, despite that we
    might return to userspace and unlock it from a different process.  Instead
    grab an active reference to keep the file system busy and add an explicit
    check for frozen filesystems in remount and reject the remount instead
    of blocking on s_umount.
    
    Add a new get_active_super helper to super.c for use by freeze_bdev that
    grabs an active reference to a superblock from a given block device.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 22506eb4a58e..9cf4b926f8e4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -230,43 +230,54 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 	int error = 0;
 
 	mutex_lock(&bdev->bd_fsfreeze_mutex);
-	if (bdev->bd_fsfreeze_count > 0) {
-		bdev->bd_fsfreeze_count++;
+	if (++bdev->bd_fsfreeze_count > 1) {
+		/*
+		 * We don't even need to grab a reference - the first call
+		 * to freeze_bdev grab an active reference and only the last
+		 * thaw_bdev drops it.
+		 */
 		sb = get_super(bdev);
+		drop_super(sb);
 		mutex_unlock(&bdev->bd_fsfreeze_mutex);
 		return sb;
 	}
-	bdev->bd_fsfreeze_count++;
-
-	sb = get_super(bdev);
-	if (sb && !(sb->s_flags & MS_RDONLY)) {
-		sb->s_frozen = SB_FREEZE_WRITE;
-		smp_wmb();
-
-		sync_filesystem(sb);
-
-		sb->s_frozen = SB_FREEZE_TRANS;
-		smp_wmb();
-
-		sync_blockdev(sb->s_bdev);
-
-		if (sb->s_op->freeze_fs) {
-			error = sb->s_op->freeze_fs(sb);
-			if (error) {
-				printk(KERN_ERR
-					"VFS:Filesystem freeze failed\n");
-				sb->s_frozen = SB_UNFROZEN;
-				drop_super(sb);
-				bdev->bd_fsfreeze_count--;
-				mutex_unlock(&bdev->bd_fsfreeze_mutex);
-				return ERR_PTR(error);
-			}
+
+	sb = get_active_super(bdev);
+	if (!sb)
+		goto out;
+	if (sb->s_flags & MS_RDONLY) {
+		deactivate_locked_super(sb);
+		mutex_unlock(&bdev->bd_fsfreeze_mutex);
+		return sb;
+	}
+
+	sb->s_frozen = SB_FREEZE_WRITE;
+	smp_wmb();
+
+	sync_filesystem(sb);
+
+	sb->s_frozen = SB_FREEZE_TRANS;
+	smp_wmb();
+
+	sync_blockdev(sb->s_bdev);
+
+	if (sb->s_op->freeze_fs) {
+		error = sb->s_op->freeze_fs(sb);
+		if (error) {
+			printk(KERN_ERR
+				"VFS:Filesystem freeze failed\n");
+			sb->s_frozen = SB_UNFROZEN;
+			deactivate_locked_super(sb);
+			bdev->bd_fsfreeze_count--;
+			mutex_unlock(&bdev->bd_fsfreeze_mutex);
+			return ERR_PTR(error);
 		}
 	}
+	up_write(&sb->s_umount);
 
+ out:
 	sync_blockdev(bdev);
 	mutex_unlock(&bdev->bd_fsfreeze_mutex);
-
 	return sb;	/* thaw_bdev releases s->s_umount */
 }
 EXPORT_SYMBOL(freeze_bdev);
@@ -280,43 +291,44 @@ EXPORT_SYMBOL(freeze_bdev);
  */
 int thaw_bdev(struct block_device *bdev, struct super_block *sb)
 {
-	int error = 0;
+	int error = -EINVAL;
 
 	mutex_lock(&bdev->bd_fsfreeze_mutex);
-	if (!bdev->bd_fsfreeze_count) {
-		mutex_unlock(&bdev->bd_fsfreeze_mutex);
-		return -EINVAL;
-	}
-
-	bdev->bd_fsfreeze_count--;
-	if (bdev->bd_fsfreeze_count > 0) {
-		if (sb)
-			drop_super(sb);
-		mutex_unlock(&bdev->bd_fsfreeze_mutex);
-		return 0;
-	}
-
-	if (sb) {
-		BUG_ON(sb->s_bdev != bdev);
-		if (!(sb->s_flags & MS_RDONLY)) {
-			if (sb->s_op->unfreeze_fs) {
-				error = sb->s_op->unfreeze_fs(sb);
-				if (error) {
-					printk(KERN_ERR
-						"VFS:Filesystem thaw failed\n");
-					sb->s_frozen = SB_FREEZE_TRANS;
-					bdev->bd_fsfreeze_count++;
-					mutex_unlock(&bdev->bd_fsfreeze_mutex);
-					return error;
-				}
-			}
-			sb->s_frozen = SB_UNFROZEN;
-			smp_wmb();
-			wake_up(&sb->s_wait_unfrozen);
+	if (!bdev->bd_fsfreeze_count)
+		goto out_unlock;
+
+	error = 0;
+	if (--bdev->bd_fsfreeze_count > 0)
+		goto out_unlock;
+
+	if (!sb)
+		goto out_unlock;
+
+	BUG_ON(sb->s_bdev != bdev);
+	down_write(&sb->s_umount);
+	if (sb->s_flags & MS_RDONLY)
+		goto out_deactivate;
+
+	if (sb->s_op->unfreeze_fs) {
+		error = sb->s_op->unfreeze_fs(sb);
+		if (error) {
+			printk(KERN_ERR
+				"VFS:Filesystem thaw failed\n");
+			sb->s_frozen = SB_FREEZE_TRANS;
+			bdev->bd_fsfreeze_count++;
+			mutex_unlock(&bdev->bd_fsfreeze_mutex);
+			return error;
 		}
-		drop_super(sb);
 	}
 
+	sb->s_frozen = SB_UNFROZEN;
+	smp_wmb();
+	wake_up(&sb->s_wait_unfrozen);
+
+out_deactivate:
+	if (sb)
+		deactivate_locked_super(sb);
+out_unlock:
 	mutex_unlock(&bdev->bd_fsfreeze_mutex);
 	return 0;
 }

commit 4fadd7bb20a1e7c774ed88dc703d8fbcd00ff917
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Aug 3 23:28:06 2009 +0200

    freeze_bdev: kill bd_mount_sem
    
    Now that we have the freeze count there is not much reason for bd_mount_sem
    anymore.  The actual freeze/thaw operations are serialized using the
    bd_fsfreeze_mutex, and the only other place we take bd_mount_sem is
    get_sb_bdev which tries to prevent mounting a filesystem while the block
    device is frozen.  Instead of add a check for bd_fsfreeze_count and
    return -EBUSY if a filesystem is frozen.  While that is a change in user
    visible behaviour a failing mount is much better for this case rather
    than having the mount process stuck uninterruptible for a long time.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 5d1ed50bd46c..22506eb4a58e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -216,8 +216,6 @@ EXPORT_SYMBOL(fsync_bdev);
  * freeze_bdev  --  lock a filesystem and force it into a consistent state
  * @bdev:	blockdevice to lock
  *
- * This takes the block device bd_mount_sem to make sure no new mounts
- * happen on bdev until thaw_bdev() is called.
  * If a superblock is found on this device, we take the s_umount semaphore
  * on it to make sure nobody unmounts until the snapshot creation is done.
  * The reference counter (bd_fsfreeze_count) guarantees that only the last
@@ -240,7 +238,6 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 	}
 	bdev->bd_fsfreeze_count++;
 
-	down(&bdev->bd_mount_sem);
 	sb = get_super(bdev);
 	if (sb && !(sb->s_flags & MS_RDONLY)) {
 		sb->s_frozen = SB_FREEZE_WRITE;
@@ -260,7 +257,6 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 					"VFS:Filesystem freeze failed\n");
 				sb->s_frozen = SB_UNFROZEN;
 				drop_super(sb);
-				up(&bdev->bd_mount_sem);
 				bdev->bd_fsfreeze_count--;
 				mutex_unlock(&bdev->bd_fsfreeze_mutex);
 				return ERR_PTR(error);
@@ -271,7 +267,7 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 	sync_blockdev(bdev);
 	mutex_unlock(&bdev->bd_fsfreeze_mutex);
 
-	return sb;	/* thaw_bdev releases s->s_umount and bd_mount_sem */
+	return sb;	/* thaw_bdev releases s->s_umount */
 }
 EXPORT_SYMBOL(freeze_bdev);
 
@@ -321,7 +317,6 @@ int thaw_bdev(struct block_device *bdev, struct super_block *sb)
 		drop_super(sb);
 	}
 
-	up(&bdev->bd_mount_sem);
 	mutex_unlock(&bdev->bd_fsfreeze_mutex);
 	return 0;
 }
@@ -430,7 +425,6 @@ static void init_once(void *foo)
 
 	memset(bdev, 0, sizeof(*bdev));
 	mutex_init(&bdev->bd_mutex);
-	sema_init(&bdev->bd_mount_sem, 1);
 	INIT_LIST_HEAD(&bdev->bd_inodes);
 	INIT_LIST_HEAD(&bdev->bd_list);
 #ifdef CONFIG_SYSFS

commit 83d5cde47dedf01b6a4a4331882cbc0a7eea3c2e
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Mon Sep 21 17:01:13 2009 -0700

    const: make block_device_operations const
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 71e7e03ac343..5d1ed50bd46c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1114,7 +1114,7 @@ EXPORT_SYMBOL(revalidate_disk);
 int check_disk_change(struct block_device *bdev)
 {
 	struct gendisk *disk = bdev->bd_disk;
-	struct block_device_operations * bdops = disk->fops;
+	const struct block_device_operations *bdops = disk->fops;
 
 	if (!bdops->media_changed)
 		return 0;

commit 2c96ce9f2084c1e04d02883e622f74a537a63aea
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Sep 15 09:43:56 2009 +0200

    fs: remove bdev->bd_inode_backing_dev_info
    
    It has been unused since it was introduced in:
    
    commit 520808bf20e90fdbdb320264ba7dd5cf9d47dcac
    Author: Andrew Morton <akpm@osdl.org>
    Date:   Fri May 21 00:46:17 2004 -0700
    
        [PATCH] block device layer: separate backing_dev_info infrastructure
    
    So lets just kill it.
    
    Acked-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 3581a4e53942..71e7e03ac343 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -420,7 +420,6 @@ static void bdev_destroy_inode(struct inode *inode)
 {
 	struct bdev_inode *bdi = BDEV_I(inode);
 
-	bdi->bdev.bd_inode_backing_dev_info = NULL;
 	kmem_cache_free(bdev_cachep, bdi);
 }
 

commit eef99380679e20e7edc096aa4d8a98b875404d79
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Aug 20 17:43:41 2009 +0200

    vfs: Rename generic_file_aio_write_nolock
    
    generic_file_aio_write_nolock() is now used only by block devices and raw
    character device. Filesystems should use __generic_file_aio_write() in case
    generic_file_aio_write() doesn't suit them. So rename the function to
    blkdev_aio_write() and move it to fs/blockdev.c.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 94dfda24c06e..3581a4e53942 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1404,6 +1404,33 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 	return blkdev_ioctl(bdev, mode, cmd, arg);
 }
 
+/*
+ * Write data to the block device.  Only intended for the block device itself
+ * and the raw driver which basically is a fake block device.
+ *
+ * Does not take i_mutex for the write and thus is not for general purpose
+ * use.
+ */
+ssize_t blkdev_aio_write(struct kiocb *iocb, const struct iovec *iov,
+			 unsigned long nr_segs, loff_t pos)
+{
+	struct file *file = iocb->ki_filp;
+	ssize_t ret;
+
+	BUG_ON(iocb->ki_pos != pos);
+
+	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
+	if (ret > 0 || ret == -EIOCBQUEUED) {
+		ssize_t err;
+
+		err = generic_write_sync(file, pos, ret);
+		if (err < 0 && ret > 0)
+			ret = err;
+	}
+	return ret;
+}
+EXPORT_SYMBOL_GPL(blkdev_aio_write);
+
 /*
  * Try to release a page associated with block device when the system
  * is under memory pressure.
@@ -1436,7 +1463,7 @@ const struct file_operations def_blk_fops = {
 	.read		= do_sync_read,
 	.write		= do_sync_write,
   	.aio_read	= generic_file_aio_read,
-  	.aio_write	= generic_file_aio_write_nolock,
+	.aio_write	= blkdev_aio_write,
 	.mmap		= generic_file_mmap,
 	.fsync		= block_fsync,
 	.unlocked_ioctl	= block_ioctl,

commit dddac6a7b445de95515f64fdf82fe5dc36c02f26
Author: Alan Jenkins <alan-jenkins@tuffmail.co.uk>
Date:   Wed Jul 29 21:07:55 2009 +0200

    PM / Hibernate: Replace bdget call with simple atomic_inc of i_count
    
    Create bdgrab().  This function copies an existing reference to a
    block_device.  It is safe to call from any context.
    
    Hibernation code wishes to copy a reference to the active swap device.
    Right now it calls bdget() under a spinlock, but this is wrong because
    bdget() can sleep.  It doesn't need a full bdget() because we already
    hold a reference to active swap devices (and the spinlock protects
    against swapoff).
    
    Fixes http://bugzilla.kernel.org/show_bug.cgi?id=13827
    
    Signed-off-by: Alan Jenkins <alan-jenkins@tuffmail.co.uk>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 3a6d4fb2a329..94dfda24c06e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -564,6 +564,16 @@ struct block_device *bdget(dev_t dev)
 
 EXPORT_SYMBOL(bdget);
 
+/**
+ * bdgrab -- Grab a reference to an already referenced block device
+ * @bdev:	Block device to grab a reference to.
+ */
+struct block_device *bdgrab(struct block_device *bdev)
+{
+	atomic_inc(&bdev->bd_inode->i_count);
+	return bdev;
+}
+
 long nr_blockdev_pages(void)
 {
 	struct block_device *bdev;

commit 60b0680fa236ac4e17ce31a50048c9d75f9ec831
Author: Jan Kara <jack@suse.cz>
Date:   Mon Apr 27 16:43:53 2009 +0200

    vfs: Rename fsync_super() to sync_filesystem() (version 4)
    
    Rename the function so that it better describe what it really does. Also
    remove the unnecessary include of buffer_head.h.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4b6a3b9d01ef..3a6d4fb2a329 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -204,7 +204,7 @@ int fsync_bdev(struct block_device *bdev)
 {
 	struct super_block *sb = get_super(bdev);
 	if (sb) {
-		int res = fsync_super(sb);
+		int res = sync_filesystem(sb);
 		drop_super(sb);
 		return res;
 	}
@@ -246,7 +246,7 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 		sb->s_frozen = SB_FREEZE_WRITE;
 		smp_wmb();
 
-		fsync_super(sb);
+		sync_filesystem(sb);
 
 		sb->s_frozen = SB_FREEZE_TRANS;
 		smp_wmb();

commit 5cee5815d1564bbbd505fea86f4550f1efdb5cd0
Author: Jan Kara <jack@suse.cz>
Date:   Mon Apr 27 16:43:51 2009 +0200

    vfs: Make sys_sync() use fsync_super() (version 4)
    
    It is unnecessarily fragile to have two places (fsync_super() and do_sync())
    doing data integrity sync of the filesystem. Alter __fsync_super() to
    accommodate needs of both callers and use it. So after this patch
    __fsync_super() is the only place where we gather all the calls needed to
    properly send all data on a filesystem to disk.
    
    Nice bonus is that we get a complete livelock avoidance and write_supers()
    is now only used for periodic writeback of superblocks.
    
    sync_blockdevs() introduced a couple of patches ago is gone now.
    
    [build fixes folded]
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fe47f7227618..4b6a3b9d01ef 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -176,17 +176,22 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 				iov, offset, nr_segs, blkdev_get_blocks, NULL);
 }
 
+int __sync_blockdev(struct block_device *bdev, int wait)
+{
+	if (!bdev)
+		return 0;
+	if (!wait)
+		return filemap_flush(bdev->bd_inode->i_mapping);
+	return filemap_write_and_wait(bdev->bd_inode->i_mapping);
+}
+
 /*
  * Write out and wait upon all the dirty data associated with a block
  * device via its mapping.  Does not take the superblock lock.
  */
 int sync_blockdev(struct block_device *bdev)
 {
-	int ret = 0;
-
-	if (bdev)
-		ret = filemap_write_and_wait(bdev->bd_inode->i_mapping);
-	return ret;
+	return __sync_blockdev(bdev, 1);
 }
 EXPORT_SYMBOL(sync_blockdev);
 

commit 429479f031322a0cc5c921ffb2321a51718dc875
Author: Jan Kara <jack@suse.cz>
Date:   Mon Apr 27 16:43:50 2009 +0200

    vfs: Make __fsync_super() a static function (version 4)
    
    __fsync_super() does the same thing as fsync_super(). So change the only
    caller to use fsync_super() and make __fsync_super() static. This removes
    unnecessarily duplicated call to sync_blockdev() and prepares ground
    for the changes to __fsync_super() in the following patches.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 931f6b8c4b2f..fe47f7227618 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -241,7 +241,7 @@ struct super_block *freeze_bdev(struct block_device *bdev)
 		sb->s_frozen = SB_FREEZE_WRITE;
 		smp_wmb();
 
-		__fsync_super(sb);
+		fsync_super(sb);
 
 		sb->s_frozen = SB_FREEZE_TRANS;
 		smp_wmb();

commit 512626a04e72aca60effe111fa0333ed0b195d21
Merge: 8a1ca8cedd10 3aa27bbe7a65
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 11 14:15:57 2009 -0700

    Merge branch 'for-linus' of git://linux-arm.org/linux-2.6
    
    * 'for-linus' of git://linux-arm.org/linux-2.6:
      kmemleak: Add the corresponding MAINTAINERS entry
      kmemleak: Simple testing module for kmemleak
      kmemleak: Enable the building of the memory leak detector
      kmemleak: Remove some of the kmemleak false positives
      kmemleak: Add modules support
      kmemleak: Add kmemleak_alloc callback from alloc_large_system_hash
      kmemleak: Add the vmalloc memory allocation/freeing hooks
      kmemleak: Add the slub memory allocation/freeing hooks
      kmemleak: Add the slob memory allocation/freeing hooks
      kmemleak: Add the slab memory allocation/freeing hooks
      kmemleak: Add documentation on the memory leak detector
      kmemleak: Add the base support
    
    Manual conflict resolution (with the slab/earlyboot changes) in:
            drivers/char/vt.c
            init/main.c
            mm/slab.c

commit 2e1483c995bbd0fa6cbd055ad76088a520799ba4
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Jun 11 13:24:13 2009 +0100

    kmemleak: Remove some of the kmemleak false positives
    
    There are allocations for which the main pointer cannot be found but
    they are not memory leaks. This patch fixes some of them. For more
    information on false positives, see Documentation/kmemleak.txt.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f45dbc18dd17..d250f807fd83 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -25,6 +25,7 @@
 #include <linux/uio.h>
 #include <linux/namei.h>
 #include <linux/log2.h>
+#include <linux/kmemleak.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 
@@ -492,6 +493,11 @@ void __init bdev_cache_init(void)
 	bd_mnt = kern_mount(&bd_type);
 	if (IS_ERR(bd_mnt))
 		panic("Cannot create bdev pseudo-fs");
+	/*
+	 * This vfsmount structure is only used to obtain the
+	 * blockdev_superblock, so tell kmemleak not to report it.
+	 */
+	kmemleak_not_leak(bd_mnt);
 	blockdev_superblock = bd_mnt->mnt_sb;	/* For writeback */
 }
 

commit 172124e220f1854acc99ee394671781b8b5e2120
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Thu Jun 4 22:34:44 2009 +0200

    Revert "block: implement blkdev_readpages"
    
    This reverts commit db2dbb12dc47a50c7a4c5678f526014063e486f6.
    
    It apparently causes problems with partition table read-ahead
    on archs with large page sizes. Until that problem is diagnosed
    further, just drop the readpages support on block devices.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a29b4dcc1bca..2dfc6cdcebbe 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -331,12 +331,6 @@ static int blkdev_readpage(struct file * file, struct page * page)
 	return block_read_full_page(page, blkdev_get_block);
 }
 
-static int blkdev_readpages(struct file *file, struct address_space *mapping,
-			struct list_head *pages, unsigned nr_pages)
-{
-	return mpage_readpages(mapping, pages, nr_pages, blkdev_get_block);
-}
-
 static int blkdev_write_begin(struct file *file, struct address_space *mapping,
 			loff_t pos, unsigned len, unsigned flags,
 			struct page **pagep, void **fsdata)
@@ -1405,7 +1399,6 @@ static int blkdev_releasepage(struct page *page, gfp_t wait)
 
 static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
-	.readpages	= blkdev_readpages,
 	.writepage	= blkdev_writepage,
 	.sync_page	= block_sync_page,
 	.write_begin	= blkdev_write_begin,

commit e1defc4ff0cf57aca6c5e3ff99fa503f5943c1f1
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Fri May 22 17:17:49 2009 -0400

    block: Do away with the notion of hardsect_size
    
    Until now we have had a 1:1 mapping between storage device physical
    block size and the logical block sized used when addressing the device.
    With SATA 4KB drives coming out that will no longer be the case.  The
    sector size will be 4KB but the logical block size will remain
    512-bytes.  Hence we need to distinguish between the physical block size
    and the logical ditto.
    
    This patch renames hardsect_size to logical_block_size.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a85fe310fc6f..a29b4dcc1bca 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -76,7 +76,7 @@ int set_blocksize(struct block_device *bdev, int size)
 		return -EINVAL;
 
 	/* Size cannot be smaller than the size supported by the device */
-	if (size < bdev_hardsect_size(bdev))
+	if (size < bdev_logical_block_size(bdev))
 		return -EINVAL;
 
 	/* Don't change the size if it is same as current */
@@ -106,7 +106,7 @@ EXPORT_SYMBOL(sb_set_blocksize);
 
 int sb_min_blocksize(struct super_block *sb, int size)
 {
-	int minsize = bdev_hardsect_size(sb->s_bdev);
+	int minsize = bdev_logical_block_size(sb->s_bdev);
 	if (size < minsize)
 		size = minsize;
 	return sb_set_blocksize(sb, size);
@@ -1117,7 +1117,7 @@ EXPORT_SYMBOL(check_disk_change);
 
 void bd_set_size(struct block_device *bdev, loff_t size)
 {
-	unsigned bsize = bdev_hardsect_size(bdev);
+	unsigned bsize = bdev_logical_block_size(bdev);
 
 	bdev->bd_inode->i_size = size;
 	while (bsize < PAGE_CACHE_SIZE) {

commit db2dbb12dc47a50c7a4c5678f526014063e486f6
Author: Jeff Moyer <jmoyer@redhat.com>
Date:   Wed Apr 22 14:08:13 2009 +0200

    block: implement blkdev_readpages
    
    Doing a proper block dev ->readpages() speeds up the crazy dump(8)
    approach of using interleaved process IO.
    
    Signed-off-by: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f45dbc18dd17..a85fe310fc6f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -331,6 +331,12 @@ static int blkdev_readpage(struct file * file, struct page * page)
 	return block_read_full_page(page, blkdev_get_block);
 }
 
+static int blkdev_readpages(struct file *file, struct address_space *mapping,
+			struct list_head *pages, unsigned nr_pages)
+{
+	return mpage_readpages(mapping, pages, nr_pages, blkdev_get_block);
+}
+
 static int blkdev_write_begin(struct file *file, struct address_space *mapping,
 			loff_t pos, unsigned len, unsigned flags,
 			struct page **pagep, void **fsdata)
@@ -1399,6 +1405,7 @@ static int blkdev_releasepage(struct page *page, gfp_t wait)
 
 static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
+	.readpages	= blkdev_readpages,
 	.writepage	= blkdev_writepage,
 	.sync_page	= block_sync_page,
 	.write_begin	= blkdev_write_begin,

commit 47e4491b40df73c3b117e3d80b31b5b512a4b19f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 1 07:07:16 2009 -0400

    Cleanup after commit 585d3bc06f4ca57f975a5a1f698f65a45ea66225
    
    fsync_bdev() export and a bunch of stubs for !CONFIG_BLOCK case had
    been left behind
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8c3c6899ccf3..f45dbc18dd17 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -204,6 +204,7 @@ int fsync_bdev(struct block_device *bdev)
 	}
 	return sync_blockdev(bdev);
 }
+EXPORT_SYMBOL(fsync_bdev);
 
 /**
  * freeze_bdev  --  lock a filesystem and force it into a consistent state

commit 585d3bc06f4ca57f975a5a1f698f65a45ea66225
Author: Nick Piggin <npiggin@suse.de>
Date:   Wed Feb 25 10:44:19 2009 +0100

    fs: move bdev code out of buffer.c
    
    Move some block device related code out from buffer.c and put it in
    block_dev.c. I'm trying to move non-buffer_head code out of buffer.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b3c1efff5e1d..8c3c6899ccf3 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -18,6 +18,7 @@
 #include <linux/module.h>
 #include <linux/blkpg.h>
 #include <linux/buffer_head.h>
+#include <linux/pagevec.h>
 #include <linux/writeback.h>
 #include <linux/mpage.h>
 #include <linux/mount.h>
@@ -174,6 +175,151 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 				iov, offset, nr_segs, blkdev_get_blocks, NULL);
 }
 
+/*
+ * Write out and wait upon all the dirty data associated with a block
+ * device via its mapping.  Does not take the superblock lock.
+ */
+int sync_blockdev(struct block_device *bdev)
+{
+	int ret = 0;
+
+	if (bdev)
+		ret = filemap_write_and_wait(bdev->bd_inode->i_mapping);
+	return ret;
+}
+EXPORT_SYMBOL(sync_blockdev);
+
+/*
+ * Write out and wait upon all dirty data associated with this
+ * device.   Filesystem data as well as the underlying block
+ * device.  Takes the superblock lock.
+ */
+int fsync_bdev(struct block_device *bdev)
+{
+	struct super_block *sb = get_super(bdev);
+	if (sb) {
+		int res = fsync_super(sb);
+		drop_super(sb);
+		return res;
+	}
+	return sync_blockdev(bdev);
+}
+
+/**
+ * freeze_bdev  --  lock a filesystem and force it into a consistent state
+ * @bdev:	blockdevice to lock
+ *
+ * This takes the block device bd_mount_sem to make sure no new mounts
+ * happen on bdev until thaw_bdev() is called.
+ * If a superblock is found on this device, we take the s_umount semaphore
+ * on it to make sure nobody unmounts until the snapshot creation is done.
+ * The reference counter (bd_fsfreeze_count) guarantees that only the last
+ * unfreeze process can unfreeze the frozen filesystem actually when multiple
+ * freeze requests arrive simultaneously. It counts up in freeze_bdev() and
+ * count down in thaw_bdev(). When it becomes 0, thaw_bdev() will unfreeze
+ * actually.
+ */
+struct super_block *freeze_bdev(struct block_device *bdev)
+{
+	struct super_block *sb;
+	int error = 0;
+
+	mutex_lock(&bdev->bd_fsfreeze_mutex);
+	if (bdev->bd_fsfreeze_count > 0) {
+		bdev->bd_fsfreeze_count++;
+		sb = get_super(bdev);
+		mutex_unlock(&bdev->bd_fsfreeze_mutex);
+		return sb;
+	}
+	bdev->bd_fsfreeze_count++;
+
+	down(&bdev->bd_mount_sem);
+	sb = get_super(bdev);
+	if (sb && !(sb->s_flags & MS_RDONLY)) {
+		sb->s_frozen = SB_FREEZE_WRITE;
+		smp_wmb();
+
+		__fsync_super(sb);
+
+		sb->s_frozen = SB_FREEZE_TRANS;
+		smp_wmb();
+
+		sync_blockdev(sb->s_bdev);
+
+		if (sb->s_op->freeze_fs) {
+			error = sb->s_op->freeze_fs(sb);
+			if (error) {
+				printk(KERN_ERR
+					"VFS:Filesystem freeze failed\n");
+				sb->s_frozen = SB_UNFROZEN;
+				drop_super(sb);
+				up(&bdev->bd_mount_sem);
+				bdev->bd_fsfreeze_count--;
+				mutex_unlock(&bdev->bd_fsfreeze_mutex);
+				return ERR_PTR(error);
+			}
+		}
+	}
+
+	sync_blockdev(bdev);
+	mutex_unlock(&bdev->bd_fsfreeze_mutex);
+
+	return sb;	/* thaw_bdev releases s->s_umount and bd_mount_sem */
+}
+EXPORT_SYMBOL(freeze_bdev);
+
+/**
+ * thaw_bdev  -- unlock filesystem
+ * @bdev:	blockdevice to unlock
+ * @sb:		associated superblock
+ *
+ * Unlocks the filesystem and marks it writeable again after freeze_bdev().
+ */
+int thaw_bdev(struct block_device *bdev, struct super_block *sb)
+{
+	int error = 0;
+
+	mutex_lock(&bdev->bd_fsfreeze_mutex);
+	if (!bdev->bd_fsfreeze_count) {
+		mutex_unlock(&bdev->bd_fsfreeze_mutex);
+		return -EINVAL;
+	}
+
+	bdev->bd_fsfreeze_count--;
+	if (bdev->bd_fsfreeze_count > 0) {
+		if (sb)
+			drop_super(sb);
+		mutex_unlock(&bdev->bd_fsfreeze_mutex);
+		return 0;
+	}
+
+	if (sb) {
+		BUG_ON(sb->s_bdev != bdev);
+		if (!(sb->s_flags & MS_RDONLY)) {
+			if (sb->s_op->unfreeze_fs) {
+				error = sb->s_op->unfreeze_fs(sb);
+				if (error) {
+					printk(KERN_ERR
+						"VFS:Filesystem thaw failed\n");
+					sb->s_frozen = SB_FREEZE_TRANS;
+					bdev->bd_fsfreeze_count++;
+					mutex_unlock(&bdev->bd_fsfreeze_mutex);
+					return error;
+				}
+			}
+			sb->s_frozen = SB_UNFROZEN;
+			smp_wmb();
+			wake_up(&sb->s_wait_unfrozen);
+		}
+		drop_super(sb);
+	}
+
+	up(&bdev->bd_mount_sem);
+	mutex_unlock(&bdev->bd_fsfreeze_mutex);
+	return 0;
+}
+EXPORT_SYMBOL(thaw_bdev);
+
 static int blkdev_writepage(struct page *page, struct writeback_control *wbc)
 {
 	return block_write_full_page(page, blkdev_get_block, wbc);

commit fcccf502540e3d752d33b2d8e976034dee81f9f7
Author: Takashi Sato <t-sato@yk.jp.nec.com>
Date:   Fri Jan 9 16:40:59 2009 -0800

    filesystem freeze: implement generic freeze feature
    
    The ioctls for the generic freeze feature are below.
    o Freeze the filesystem
      int ioctl(int fd, int FIFREEZE, arg)
        fd: The file descriptor of the mountpoint
        FIFREEZE: request code for the freeze
        arg: Ignored
        Return value: 0 if the operation succeeds. Otherwise, -1
    
    o Unfreeze the filesystem
      int ioctl(int fd, int FITHAW, arg)
        fd: The file descriptor of the mountpoint
        FITHAW: request code for unfreeze
        arg: Ignored
        Return value: 0 if the operation succeeds. Otherwise, -1
        Error number: If the filesystem has already been unfrozen,
                      errno is set to EINVAL.
    
    [akpm@linux-foundation.org: fix CONFIG_BLOCK=n]
    Signed-off-by: Takashi Sato <t-sato@yk.jp.nec.com>
    Signed-off-by: Masayuki Hamaguchi <m-hamaguchi@ys.jp.nec.com>
    Cc: <xfs-masters@oss.sgi.com>
    Cc: <linux-ext4@vger.kernel.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dave Kleikamp <shaggy@austin.ibm.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Alasdair G Kergon <agk@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ac7031f12ea5..b3c1efff5e1d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -285,6 +285,8 @@ static void init_once(void *foo)
 	INIT_LIST_HEAD(&bdev->bd_holder_list);
 #endif
 	inode_init_once(&ei->vfs_inode);
+	/* Initialize mutex for freeze. */
+	mutex_init(&bdev->bd_fsfreeze_mutex);
 }
 
 static inline void __bd_forget(struct inode *inode)

commit 2150edc6c5cf00f7adb54538b9ea2a3e9cedca3f
Merge: cd764695b673 4b905671d2ea
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 8 17:14:59 2009 -0800

    Merge branch 'for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4
    
    * 'for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4: (57 commits)
      jbd2: Fix oops in jbd2_journal_init_inode() on corrupted fs
      ext4: Remove "extents" mount option
      block: Add Kconfig help which notes that ext4 needs CONFIG_LBD
      ext4: Make printk's consistently prefixed with "EXT4-fs: "
      ext4: Add sanity checks for the superblock before mounting the filesystem
      ext4: Add mount option to set kjournald's I/O priority
      jbd2: Submit writes to the journal using WRITE_SYNC
      jbd2: Add pid and journal device name to the "kjournald2 starting" message
      ext4: Add markers for better debuggability
      ext4: Remove code to create the journal inode
      ext4: provide function to release metadata pages under memory pressure
      ext3: provide function to release metadata pages under memory pressure
      add releasepage hooks to block devices which can be used by file systems
      ext4: Fix s_dirty_blocks_counter if block allocation failed with nodelalloc
      ext4: Init the complete page while building buddy cache
      ext4: Don't allow new groups to be added during block allocation
      ext4: mark the blocks/inode bitmap beyond end of group as used
      ext4: Use new buffer_head flag to check uninit group bitmaps initialization
      ext4: Fix the race between read_inode_bitmap() and ext4_new_inode()
      ext4: code cleanup
      ...

commit d3374825ce57ba2214d375023979f6197ccc1385
Author: NeilBrown <neilb@suse.de>
Date:   Fri Jan 9 08:31:10 2009 +1100

    md: make devices disappear when they are no longer needed.
    
    Currently md devices, once created, never disappear until the module
    is unloaded.  This is essentially because the gendisk holds a
    reference to the mddev, and the mddev holds a reference to the
    gendisk, this a circular reference.
    
    If we drop the reference from mddev to gendisk, then we need to ensure
    that the mddev is destroyed when the gendisk is destroyed.  However it
    is not possible to hook into the gendisk destruction process to enable
    this.
    
    So we drop the reference from the gendisk to the mddev and destroy the
    gendisk when the mddev gets destroyed.  However this has a
    complication.
    Between the call
       __blkdev_get->get_gendisk->kobj_lookup->md_probe
    and the call
       __blkdev_get->md_open
    
    there is no obvious way to hold a reference on the mddev any more, so
    unless something is done, it will disappear and gendisk will be
    destroyed prematurely.
    
    Also, once we decide to destroy the mddev, there will be an unlockable
    moment before the gendisk is unlinked (blk_unregister_region) during
    which a new reference to the gendisk can be created.  We need to
    ensure that this reference can not be used.  i.e. the ->open must
    fail.
    
    So:
     1/  in md_probe we set a flag in the mddev (hold_active) which
         indicates that the array should be treated as active, even
         though there are no references, and no appearance of activity.
         This is cleared by md_release when the device is closed if it
         is no longer needed.
         This ensures that the gendisk will survive between md_probe and
         md_open.
    
     2/  In md_open we check if the mddev we expect to open matches
         the gendisk that we did open.
         If there is a mismatch we return -ERESTARTSYS and modify
         __blkdev_get to retry from the top in that case.
         In the -ERESTARTSYS sys case we make sure to wait until
         the old gendisk (that we succeeded in opening) is really gone so
         we loop at most once.
    
    Some udev configurations will always open an md device when it first
    appears.   If we allow an md device that was just created by an open
    to disappear on an immediate close, then this can race with such udev
    configurations and result in an infinite loop the device being opened
    and closed, then re-open due to the 'ADD' even from the first open,
    and then close and so on.
    So we make sure an md device, once created by an open, remains active
    at least until some md 'ioctl' has been made on it.  This means that
    all normal usage of md devices will allow them to disappear promptly
    when not needed, but the worst that an incorrect usage will do it
    cause an inactive md device to be left in existence (it can easily be
    removed).
    
    As an array can be stopped by writing to a sysfs attribute
      echo clear > /sys/block/mdXXX/md/array_state
    we need to use scheduled work for deleting the gendisk and other
    kobjects.  This allows us to wait for any pending gendisk deletion to
    complete by simply calling flush_scheduled_work().
    
    
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b957717e25ab..8ebbfdf708c2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1005,6 +1005,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	}
 
 	lock_kernel();
+ restart:
 
 	ret = -ENXIO;
 	disk = get_gendisk(bdev->bd_dev, &partno);
@@ -1025,6 +1026,19 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 
 			if (disk->fops->open) {
 				ret = disk->fops->open(bdev, mode);
+				if (ret == -ERESTARTSYS) {
+					/* Lost a race with 'disk' being
+					 * deleted, try again.
+					 * See md.c
+					 */
+					disk_put_part(bdev->bd_part);
+					bdev->bd_part = NULL;
+					module_put(disk->fops->owner);
+					put_disk(disk);
+					bdev->bd_disk = NULL;
+					mutex_unlock(&bdev->bd_mutex);
+					goto restart;
+				}
 				if (ret)
 					goto out_clear;
 			}

commit 94e2959e7a6a4ef0969932c30349ce6f4469a3cf
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue Jan 6 14:41:15 2009 -0800

    fs: fix function param name in kernel-doc
    
    Fix function parameter name in kernel-doc:
    
    Warning(linux-2.6.28-git5//fs/block_dev.c:1272): No description found for parameter 'pathname'
    Warning(linux-2.6.28-git5//fs/block_dev.c:1272): Excess function parameter 'path' description in 'lookup_bdev'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 349a26c10001..b957717e25ab 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1262,7 +1262,7 @@ EXPORT_SYMBOL(ioctl_by_bdev);
 
 /**
  * lookup_bdev  - lookup a struct block_device by name
- * @path:	special file representing the block device
+ * @pathname:	special file representing the block device
  *
  * Get a reference to the blockdevice at @pathname in the current
  * namespace if possible and return it.  Return ERR_PTR(error)

commit 87d8fe1ee6b8d2f95076142d58c440dba4e7bdc2
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jan 3 09:47:09 2009 -0500

    add releasepage hooks to block devices which can be used by file systems
    
    Implement blkdev_releasepage() to release the buffer_heads and pages
    after we release private data belonging to a mounted filesystem.
    
    Cc: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Cc: linux-fsdevel@vger.kernel.org
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 349a26c10001..1dd07e66e98a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1220,6 +1220,20 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 	return blkdev_ioctl(bdev, mode, cmd, arg);
 }
 
+/*
+ * Try to release a page associated with block device when the system
+ * is under memory pressure.
+ */
+static int blkdev_releasepage(struct page *page, gfp_t wait)
+{
+	struct super_block *super = BDEV_I(page->mapping->host)->bdev.bd_super;
+
+	if (super && super->s_op->bdev_try_to_free_page)
+		return super->s_op->bdev_try_to_free_page(super, page, wait);
+
+	return try_to_free_buffers(page);
+}
+
 static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
 	.writepage	= blkdev_writepage,
@@ -1227,6 +1241,7 @@ static const struct address_space_operations def_blk_aops = {
 	.write_begin	= blkdev_write_begin,
 	.write_end	= blkdev_write_end,
 	.writepages	= generic_writepages,
+	.releasepage	= blkdev_releasepage,
 	.direct_IO	= blkdev_direct_IO,
 };
 

commit c2acf7b90821785fe812cc0aa05148e5a1f84204
Author: Denis ChengRq <crquan@gmail.com>
Date:   Mon Dec 1 14:34:56 2008 -0800

    fs/block_dev.c: __read_mostly improvement and sb_is_blkdev_sb utilization
    
    - iget5_locked in bdget really needs blockdev_superblock, instead of
      bd_mnt, so bd_mnt could be just a local variable;
    
    - blockdev_superblock really needs __read_mostly, while local var bd_mnt
      not;
    
    - make use of sb_is_blkdev_sb in bd_forget, instead of direct reference
      to blockdev_superblock.
    
    Signed-off-by: Denis ChengRq <crquan@gmail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 99e0ae1a4c78..349a26c10001 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -326,12 +326,13 @@ static struct file_system_type bd_type = {
 	.kill_sb	= kill_anon_super,
 };
 
-static struct vfsmount *bd_mnt __read_mostly;
-struct super_block *blockdev_superblock;
+struct super_block *blockdev_superblock __read_mostly;
 
 void __init bdev_cache_init(void)
 {
 	int err;
+	struct vfsmount *bd_mnt;
+
 	bdev_cachep = kmem_cache_create("bdev_cache", sizeof(struct bdev_inode),
 			0, (SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|
 				SLAB_MEM_SPREAD|SLAB_PANIC),
@@ -373,7 +374,7 @@ struct block_device *bdget(dev_t dev)
 	struct block_device *bdev;
 	struct inode *inode;
 
-	inode = iget5_locked(bd_mnt->mnt_sb, hash(dev),
+	inode = iget5_locked(blockdev_superblock, hash(dev),
 			bdev_test, bdev_set, &dev);
 
 	if (!inode)
@@ -463,7 +464,7 @@ void bd_forget(struct inode *inode)
 
 	spin_lock(&bdev_lock);
 	if (inode->i_bdev) {
-		if (inode->i_sb != blockdev_superblock)
+		if (!sb_is_blkdev_sb(inode->i_sb))
 			bdev = inode->i_bdev;
 		__bd_forget(inode);
 	}

commit fd4ce1acd0f8558033b1a6968001552bd7671e6d
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Nov 5 14:58:42 2008 +0100

    [PATCH 1/2] kill FMODE_NDELAY_NOW
    
    Update FMODE_NDELAY before each ioctl call so that we can kill the
    magic FMODE_NDELAY_NOW.  It would be even better to do this directly
    in setfl(), but for that we'd need to have FMODE_NDELAY for all files,
    not just block special files.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7c727523bc54..99e0ae1a4c78 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1206,8 +1206,16 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 {
 	struct block_device *bdev = I_BDEV(file->f_mapping->host);
 	fmode_t mode = file->f_mode;
+
+	/*
+	 * O_NDELAY can be altered using fcntl(.., F_SETFL, ..), so we have
+	 * to updated it before every ioctl.
+	 */
 	if (file->f_flags & O_NDELAY)
-		mode |= FMODE_NDELAY_NOW;
+		mode |= FMODE_NDELAY;
+	else
+		mode &= ~FMODE_NDELAY;
+
 	return blkdev_ioctl(bdev, mode, cmd, arg);
 }
 

commit ebbefc011e56bd85b4745d01e5b8d7d05d95ed5d
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Nov 5 14:54:41 2008 +0100

    [PATCH] clean up blkdev_get a little bit
    
    The way the bd_claim for the FMODE_EXCL case is implemented is rather
    confusing.  Clean it up to the most logical style.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index db831efbdbbd..7c727523bc54 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1135,12 +1135,15 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	if (res)
 		return res;
 
-	if (!(filp->f_mode & FMODE_EXCL))
-		return 0;
+	if (filp->f_mode & FMODE_EXCL) {
+		res = bd_claim(bdev, filp);
+		if (res)
+			goto out_blkdev_put;
+	}
 
-	if (!(res = bd_claim(bdev, filp)))
-		return 0;
+	return 0;
 
+ out_blkdev_put:
 	blkdev_put(bdev, filp->f_mode);
 	return res;
 }

commit 89f97496e81d2112b5e41416fe3020688c443818
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Nov 5 10:21:06 2008 +0100

    block: fix __blkdev_get() for removable devices
    
    Commit 0762b8bde9729f10f8e6249809660ff2ec3ad735 moved disk_get_part()
    in front of recursive get on the whole disk, which caused removable
    devices to try disk_get_part() before rescanning after a new media is
    inserted, which might fail legit open attempts or give the old
    partition.
    
    This patch fixes the problem by moving disk_get_part() after
    __blkdev_get() on the whole disk.
    
    This problem was spotted by Borislav Petkov.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Tested-by: Borislav Petkov <petkovbb@gmail.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 88a776fa0ef6..db831efbdbbd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -986,7 +986,6 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 {
 	struct gendisk *disk;
-	struct hd_struct *part = NULL;
 	int ret;
 	int partno;
 	int perm = 0;
@@ -1004,24 +1003,25 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 		return ret;
 	}
 
-	ret = -ENXIO;
-
 	lock_kernel();
 
+	ret = -ENXIO;
 	disk = get_gendisk(bdev->bd_dev, &partno);
 	if (!disk)
 		goto out_unlock_kernel;
-	part = disk_get_part(disk, partno);
-	if (!part)
-		goto out_unlock_kernel;
 
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
-		bdev->bd_part = part;
 		bdev->bd_contains = bdev;
 		if (!partno) {
 			struct backing_dev_info *bdi;
+
+			ret = -ENXIO;
+			bdev->bd_part = disk_get_part(disk, partno);
+			if (!bdev->bd_part)
+				goto out_clear;
+
 			if (disk->fops->open) {
 				ret = disk->fops->open(bdev, mode);
 				if (ret)
@@ -1049,18 +1049,17 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 			bdev->bd_contains = whole;
 			bdev->bd_inode->i_data.backing_dev_info =
 			   whole->bd_inode->i_data.backing_dev_info;
+			bdev->bd_part = disk_get_part(disk, partno);
 			if (!(disk->flags & GENHD_FL_UP) ||
-			    !part || !part->nr_sects) {
+			    !bdev->bd_part || !bdev->bd_part->nr_sects) {
 				ret = -ENXIO;
 				goto out_clear;
 			}
-			bd_set_size(bdev, (loff_t)part->nr_sects << 9);
+			bd_set_size(bdev, (loff_t)bdev->bd_part->nr_sects << 9);
 		}
 	} else {
-		disk_put_part(part);
 		put_disk(disk);
 		module_put(disk->fops->owner);
-		part = NULL;
 		disk = NULL;
 		if (bdev->bd_contains == bdev) {
 			if (bdev->bd_disk->fops->open) {
@@ -1080,6 +1079,7 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 	return 0;
 
  out_clear:
+	disk_put_part(bdev->bd_part);
 	bdev->bd_disk = NULL;
 	bdev->bd_part = NULL;
 	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
@@ -1091,7 +1091,6 @@ static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
  out_unlock_kernel:
 	unlock_kernel();
 
-	disk_put_part(part);
 	if (disk)
 		module_put(disk->fops->owner);
 	put_disk(disk);

commit 22484856402bfa1ff3defe47f6029ab0418240d9
Merge: 5ed487bc2c44 56b26add02b4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 23 10:23:07 2008 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/viro/bdev
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/viro/bdev: (66 commits)
      [PATCH] kill the rest of struct file propagation in block ioctls
      [PATCH] get rid of struct file use in blkdev_ioctl() BLKBSZSET
      [PATCH] get rid of blkdev_locked_ioctl()
      [PATCH] get rid of blkdev_driver_ioctl()
      [PATCH] sanitize blkdev_get() and friends
      [PATCH] remember mode of reiserfs journal
      [PATCH] propagate mode through swsusp_close()
      [PATCH] propagate mode through open_bdev_excl/close_bdev_excl
      [PATCH] pass fmode_t to blkdev_put()
      [PATCH] kill the unused bsize on the send side of /dev/loop
      [PATCH] trim file propagation in block/compat_ioctl.c
      [PATCH] end of methods switch: remove the old ones
      [PATCH] switch sr
      [PATCH] switch sd
      [PATCH] switch ide-scsi
      [PATCH] switch tape_block
      [PATCH] switch dcssblk
      [PATCH] switch dasd
      [PATCH] switch mtd_blkdevs
      [PATCH] switch mmc
      ...

commit 421748ecde8e69a6364e5ae66eb3bf87e1f995c0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Aug 2 01:04:36 2008 -0400

    [PATCH] assorted path_lookup() -> kern_path() conversions
    
    more nameidata eviction
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 218408eed1bb..d06fe3c3dd3f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1268,33 +1268,33 @@ EXPORT_SYMBOL(ioctl_by_bdev);
  * namespace if possible and return it.  Return ERR_PTR(error)
  * otherwise.
  */
-struct block_device *lookup_bdev(const char *path)
+struct block_device *lookup_bdev(const char *pathname)
 {
 	struct block_device *bdev;
 	struct inode *inode;
-	struct nameidata nd;
+	struct path path;
 	int error;
 
-	if (!path || !*path)
+	if (!pathname || !*pathname)
 		return ERR_PTR(-EINVAL);
 
-	error = path_lookup(path, LOOKUP_FOLLOW, &nd);
+	error = kern_path(pathname, LOOKUP_FOLLOW, &path);
 	if (error)
 		return ERR_PTR(error);
 
-	inode = nd.path.dentry->d_inode;
+	inode = path.dentry->d_inode;
 	error = -ENOTBLK;
 	if (!S_ISBLK(inode->i_mode))
 		goto fail;
 	error = -EACCES;
-	if (nd.path.mnt->mnt_flags & MNT_NODEV)
+	if (path.mnt->mnt_flags & MNT_NODEV)
 		goto fail;
 	error = -ENOMEM;
 	bdev = bd_acquire(inode);
 	if (!bdev)
 		goto fail;
 out:
-	path_put(&nd.path);
+	path_put(&path);
 	return bdev;
 fail:
 	bdev = ERR_PTR(error);

commit 56b26add02b4bdea81d5e0ebda60db1fe3311ad4
Author: Al Viro <al@aretha.pdmi.ras.ru>
Date:   Fri Sep 19 03:17:36 2008 -0400

    [PATCH] kill the rest of struct file propagation in block ioctls
    
    Now we can switch blkdev_ioctl() block_device/mode
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b89c956e04f6..05865b93f7e1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1202,7 +1202,11 @@ static int blkdev_close(struct inode * inode, struct file * filp)
 
 static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 {
-	return blkdev_ioctl(file->f_mapping->host, file, cmd, arg);
+	struct block_device *bdev = I_BDEV(file->f_mapping->host);
+	fmode_t mode = file->f_mode;
+	if (file->f_flags & O_NDELAY)
+		mode |= FMODE_NDELAY_NOW;
+	return blkdev_ioctl(bdev, mode, cmd, arg);
 }
 
 static const struct address_space_operations def_blk_aops = {
@@ -1238,7 +1242,7 @@ int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)
 	int res;
 	mm_segment_t old_fs = get_fs();
 	set_fs(KERNEL_DS);
-	res = blkdev_ioctl(bdev->bd_inode, NULL, cmd, arg);
+	res = blkdev_ioctl(bdev, 0, cmd, arg);
 	set_fs(old_fs);
 	return res;
 }

commit 572c48921574dbe6dceb958cf965aa962baefde4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Oct 8 13:24:05 2007 -0400

    [PATCH] sanitize blkdev_get() and friends
    
    * get rid of fake struct file/struct dentry in __blkdev_get()
    * merge __blkdev_get() and do_open()
    * get rid of flags argument of blkdev_get()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4b595904cefd..b89c956e04f6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -844,9 +844,8 @@ struct block_device *open_by_devnum(dev_t dev, fmode_t mode)
 {
 	struct block_device *bdev = bdget(dev);
 	int err = -ENOMEM;
-	int flags = mode & FMODE_WRITE ? O_RDWR : O_RDONLY;
 	if (bdev)
-		err = blkdev_get(bdev, mode, flags);
+		err = blkdev_get(bdev, mode);
 	return err ? ERR_PTR(err) : bdev;
 }
 
@@ -975,8 +974,6 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
-static int __blkdev_get(struct block_device *bdev, fmode_t mode, unsigned flags,
-			int for_part);
 static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
 /*
@@ -986,7 +983,7 @@ static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
  *    mutex_lock_nested(whole->bd_mutex, 1)
  */
 
-static int do_open(struct block_device *bdev, struct file *file, int for_part)
+static int __blkdev_get(struct block_device *bdev, fmode_t mode, int for_part)
 {
 	struct gendisk *disk;
 	struct hd_struct *part = NULL;
@@ -994,9 +991,9 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	int partno;
 	int perm = 0;
 
-	if (file->f_mode & FMODE_READ)
+	if (mode & FMODE_READ)
 		perm |= MAY_READ;
-	if (file->f_mode & FMODE_WRITE)
+	if (mode & FMODE_WRITE)
 		perm |= MAY_WRITE;
 	/*
 	 * hooks: /n/, see "layering violations".
@@ -1007,15 +1004,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		return ret;
 	}
 
-	if (file->f_flags & O_NDELAY)
-		file->f_mode |= FMODE_NDELAY;
-	if (file->f_flags & O_EXCL)
-		file->f_mode |= FMODE_EXCL;
-	if ((file->f_flags & O_ACCMODE) == 3)
-		file->f_mode |= FMODE_WRITE_IOCTL;
-
 	ret = -ENXIO;
-	file->f_mapping = bdev->bd_inode->i_mapping;
 
 	lock_kernel();
 
@@ -1034,7 +1023,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		if (!partno) {
 			struct backing_dev_info *bdi;
 			if (disk->fops->open) {
-				ret = disk->fops->open(bdev, file->f_mode);
+				ret = disk->fops->open(bdev, mode);
 				if (ret)
 					goto out_clear;
 			}
@@ -1054,7 +1043,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 			if (!whole)
 				goto out_clear;
 			BUG_ON(for_part);
-			ret = __blkdev_get(whole, file->f_mode, file->f_flags, 1);
+			ret = __blkdev_get(whole, mode, 1);
 			if (ret)
 				goto out_clear;
 			bdev->bd_contains = whole;
@@ -1075,7 +1064,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		disk = NULL;
 		if (bdev->bd_contains == bdev) {
 			if (bdev->bd_disk->fops->open) {
-				ret = bdev->bd_disk->fops->open(bdev, file->f_mode);
+				ret = bdev->bd_disk->fops->open(bdev, mode);
 				if (ret)
 					goto out_unlock_bdev;
 			}
@@ -1095,7 +1084,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	bdev->bd_part = NULL;
 	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
 	if (bdev != bdev->bd_contains)
-		__blkdev_put(bdev->bd_contains, file->f_mode, 1);
+		__blkdev_put(bdev->bd_contains, mode, 1);
 	bdev->bd_contains = NULL;
  out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
@@ -1111,28 +1100,9 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	return ret;
 }
 
-static int __blkdev_get(struct block_device *bdev, fmode_t mode, unsigned flags,
-			int for_part)
-{
-	/*
-	 * This crockload is due to bad choice of ->open() type.
-	 * It will go away.
-	 * For now, block device ->open() routine must _not_
-	 * examine anything in 'inode' argument except ->i_rdev.
-	 */
-	struct file fake_file = {};
-	struct dentry fake_dentry = {};
-	fake_file.f_mode = mode;
-	fake_file.f_flags = flags;
-	fake_file.f_path.dentry = &fake_dentry;
-	fake_dentry.d_inode = bdev->bd_inode;
-
-	return do_open(bdev, &fake_file, for_part);
-}
-
-int blkdev_get(struct block_device *bdev, fmode_t mode, unsigned flags)
+int blkdev_get(struct block_device *bdev, fmode_t mode)
 {
-	return __blkdev_get(bdev, mode, flags, 0);
+	return __blkdev_get(bdev, mode, 0);
 }
 EXPORT_SYMBOL(blkdev_get);
 
@@ -1149,15 +1119,24 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	 */
 	filp->f_flags |= O_LARGEFILE;
 
+	if (filp->f_flags & O_NDELAY)
+		filp->f_mode |= FMODE_NDELAY;
+	if (filp->f_flags & O_EXCL)
+		filp->f_mode |= FMODE_EXCL;
+	if ((filp->f_flags & O_ACCMODE) == 3)
+		filp->f_mode |= FMODE_WRITE_IOCTL;
+
 	bdev = bd_acquire(inode);
 	if (bdev == NULL)
 		return -ENOMEM;
 
-	res = do_open(bdev, filp, 0);
+	filp->f_mapping = bdev->bd_inode->i_mapping;
+
+	res = blkdev_get(bdev, filp->f_mode);
 	if (res)
 		return res;
 
-	if (!(filp->f_flags & O_EXCL) )
+	if (!(filp->f_mode & FMODE_EXCL))
 		return 0;
 
 	if (!(res = bd_claim(bdev, filp)))
@@ -1327,7 +1306,7 @@ struct block_device *open_bdev_exclusive(const char *path, fmode_t mode, void *h
 	if (IS_ERR(bdev))
 		return bdev;
 
-	error = blkdev_get(bdev, mode, 0);
+	error = blkdev_get(bdev, mode);
 	if (error)
 		return ERR_PTR(error);
 	error = -EACCES;

commit 30c40d2c01f68c7eb1a41ab3552bdaf5dbf300d4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 22 19:50:45 2008 -0500

    [PATCH] propagate mode through open_bdev_excl/close_bdev_excl
    
    replace open_bdev_excl/close_bdev_excl with variants taking fmode_t.
    superblock gets the value used to mount it stored in sb->s_mode
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 05131baf3cf8..4b595904cefd 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1309,32 +1309,29 @@ struct block_device *lookup_bdev(const char *path)
 EXPORT_SYMBOL(lookup_bdev);
 
 /**
- * open_bdev_excl  -  open a block device by name and set it up for use
+ * open_bdev_exclusive  -  open a block device by name and set it up for use
  *
  * @path:	special file representing the block device
- * @flags:	%MS_RDONLY for opening read-only
+ * @mode:	FMODE_... combination to pass be used
  * @holder:	owner for exclusion
  *
  * Open the blockdevice described by the special file at @path, claim it
  * for the @holder.
  */
-struct block_device *open_bdev_excl(const char *path, int flags, void *holder)
+struct block_device *open_bdev_exclusive(const char *path, fmode_t mode, void *holder)
 {
 	struct block_device *bdev;
-	fmode_t mode = FMODE_READ;
 	int error = 0;
 
 	bdev = lookup_bdev(path);
 	if (IS_ERR(bdev))
 		return bdev;
 
-	if (!(flags & MS_RDONLY))
-		mode |= FMODE_WRITE;
 	error = blkdev_get(bdev, mode, 0);
 	if (error)
 		return ERR_PTR(error);
 	error = -EACCES;
-	if (!(flags & MS_RDONLY) && bdev_read_only(bdev))
+	if ((mode & FMODE_WRITE) && bdev_read_only(bdev))
 		goto blkdev_put;
 	error = bd_claim(bdev, holder);
 	if (error)
@@ -1347,22 +1344,23 @@ struct block_device *open_bdev_excl(const char *path, int flags, void *holder)
 	return ERR_PTR(error);
 }
 
-EXPORT_SYMBOL(open_bdev_excl);
+EXPORT_SYMBOL(open_bdev_exclusive);
 
 /**
- * close_bdev_excl  -  release a blockdevice openen by open_bdev_excl()
+ * close_bdev_exclusive  -  close a blockdevice opened by open_bdev_exclusive()
  *
  * @bdev:	blockdevice to close
+ * @mode:	mode, must match that used to open.
  *
- * This is the counterpart to open_bdev_excl().
+ * This is the counterpart to open_bdev_exclusive().
  */
-void close_bdev_excl(struct block_device *bdev)
+void close_bdev_exclusive(struct block_device *bdev, fmode_t mode)
 {
 	bd_release(bdev);
-	blkdev_put(bdev, 0);	/* move up in the next patches */
+	blkdev_put(bdev, mode);
 }
 
-EXPORT_SYMBOL(close_bdev_excl);
+EXPORT_SYMBOL(close_bdev_exclusive);
 
 int __invalidate_device(struct block_device *bdev)
 {

commit 9a1c3542768b5a58e45a9216921cd10a3bae1205
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 22 20:40:24 2008 -0500

    [PATCH] pass fmode_t to blkdev_put()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 55124ac8c7ad..05131baf3cf8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -977,7 +977,7 @@ EXPORT_SYMBOL(bd_set_size);
 
 static int __blkdev_get(struct block_device *bdev, fmode_t mode, unsigned flags,
 			int for_part);
-static int __blkdev_put(struct block_device *bdev, int for_part);
+static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part);
 
 /*
  * bd_mutex locking:
@@ -1095,7 +1095,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	bdev->bd_part = NULL;
 	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
 	if (bdev != bdev->bd_contains)
-		__blkdev_put(bdev->bd_contains, 1);
+		__blkdev_put(bdev->bd_contains, file->f_mode, 1);
 	bdev->bd_contains = NULL;
  out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
@@ -1163,11 +1163,11 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	if (!(res = bd_claim(bdev, filp)))
 		return 0;
 
-	blkdev_put(bdev);
+	blkdev_put(bdev, filp->f_mode);
 	return res;
 }
 
-static int __blkdev_put(struct block_device *bdev, int for_part)
+static int __blkdev_put(struct block_device *bdev, fmode_t mode, int for_part)
 {
 	int ret = 0;
 	struct gendisk *disk = bdev->bd_disk;
@@ -1184,7 +1184,7 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 	}
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)
-			ret = disk->fops->release(disk, 0);
+			ret = disk->fops->release(disk, mode);
 	}
 	if (!bdev->bd_openers) {
 		struct module *owner = disk->fops->owner;
@@ -1203,13 +1203,13 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);
 	if (victim)
-		__blkdev_put(victim, 1);
+		__blkdev_put(victim, mode, 1);
 	return ret;
 }
 
-int blkdev_put(struct block_device *bdev)
+int blkdev_put(struct block_device *bdev, fmode_t mode)
 {
-	return __blkdev_put(bdev, 0);
+	return __blkdev_put(bdev, mode, 0);
 }
 EXPORT_SYMBOL(blkdev_put);
 
@@ -1218,7 +1218,7 @@ static int blkdev_close(struct inode * inode, struct file * filp)
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
 	if (bdev->bd_holder == filp)
 		bd_release(bdev);
-	return blkdev_put(bdev);
+	return blkdev_put(bdev, filp->f_mode);
 }
 
 static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
@@ -1343,7 +1343,7 @@ struct block_device *open_bdev_excl(const char *path, int flags, void *holder)
 	return bdev;
 	
 blkdev_put:
-	blkdev_put(bdev);
+	blkdev_put(bdev, mode);
 	return ERR_PTR(error);
 }
 
@@ -1359,7 +1359,7 @@ EXPORT_SYMBOL(open_bdev_excl);
 void close_bdev_excl(struct block_device *bdev)
 {
 	bd_release(bdev);
-	blkdev_put(bdev);
+	blkdev_put(bdev, 0);	/* move up in the next patches */
 }
 
 EXPORT_SYMBOL(close_bdev_excl);

commit 90b8f2824ce68dd87d304641a1d5a048dfff39f5
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Mar 2 10:43:36 2008 -0500

    [PATCH] end of methods switch: remove the old ones
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 73b6ce47c861..55124ac8c7ad 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1033,11 +1033,6 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		bdev->bd_contains = bdev;
 		if (!partno) {
 			struct backing_dev_info *bdi;
-			if (disk->fops->__open) {
-				ret = disk->fops->__open(bdev->bd_inode, file);
-				if (ret)
-					goto out_first;
-			}
 			if (disk->fops->open) {
 				ret = disk->fops->open(bdev, file->f_mode);
 				if (ret)
@@ -1079,11 +1074,6 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		part = NULL;
 		disk = NULL;
 		if (bdev->bd_contains == bdev) {
-			if (bdev->bd_disk->fops->__open) {
-				ret = bdev->bd_disk->fops->__open(bdev->bd_inode, file);
-				if (ret)
-					goto out;
-			}
 			if (bdev->bd_disk->fops->open) {
 				ret = bdev->bd_disk->fops->open(bdev, file->f_mode);
 				if (ret)
@@ -1180,7 +1170,6 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 static int __blkdev_put(struct block_device *bdev, int for_part)
 {
 	int ret = 0;
-	struct inode *bd_inode = bdev->bd_inode;
 	struct gendisk *disk = bdev->bd_disk;
 	struct block_device *victim = NULL;
 
@@ -1194,8 +1183,6 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 		kill_bdev(bdev);
 	}
 	if (bdev->bd_contains == bdev) {
-		if (disk->fops->__release)
-			ret = disk->fops->__release(bd_inode, NULL);
 		if (disk->fops->release)
 			ret = disk->fops->release(disk, 0);
 	}

commit d4430d62fa77208824a37fe6f85ab2831d274769
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Mar 2 09:09:22 2008 -0500

    [PATCH] beginning of methods conversion
    
    To keep the size of changesets sane we split the switch by drivers;
    to keep the damn thing bisectable we do the following:
            1) rename the affected methods, add ones with correct
    prototypes, make (few) callers handle both.  That's this changeset.
            2) for each driver convert to new methods.  *ALL* drivers
    are converted in this series.
            3) kill the old (renamed) methods.
    
    Note that it _is_ a flagday; all in-tree drivers are converted and by the
    end of this series no trace of old methods remain.  The only reason why
    we do that this way is to keep the damn thing bisectable and allow per-driver
    debugging if anything goes wrong.
    
    New methods:
            open(bdev, mode)
            release(disk, mode)
            ioctl(bdev, mode, cmd, arg)             /* Called without BKL */
            compat_ioctl(bdev, mode, cmd, arg)
            locked_ioctl(bdev, mode, cmd, arg)      /* Called with BKL, legacy */
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b9022694e9f7..73b6ce47c861 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1033,8 +1033,13 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		bdev->bd_contains = bdev;
 		if (!partno) {
 			struct backing_dev_info *bdi;
+			if (disk->fops->__open) {
+				ret = disk->fops->__open(bdev->bd_inode, file);
+				if (ret)
+					goto out_first;
+			}
 			if (disk->fops->open) {
-				ret = disk->fops->open(bdev->bd_inode, file);
+				ret = disk->fops->open(bdev, file->f_mode);
 				if (ret)
 					goto out_clear;
 			}
@@ -1074,8 +1079,13 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		part = NULL;
 		disk = NULL;
 		if (bdev->bd_contains == bdev) {
+			if (bdev->bd_disk->fops->__open) {
+				ret = bdev->bd_disk->fops->__open(bdev->bd_inode, file);
+				if (ret)
+					goto out;
+			}
 			if (bdev->bd_disk->fops->open) {
-				ret = bdev->bd_disk->fops->open(bdev->bd_inode, file);
+				ret = bdev->bd_disk->fops->open(bdev, file->f_mode);
 				if (ret)
 					goto out_unlock_bdev;
 			}
@@ -1184,8 +1194,10 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 		kill_bdev(bdev);
 	}
 	if (bdev->bd_contains == bdev) {
+		if (disk->fops->__release)
+			ret = disk->fops->__release(bd_inode, NULL);
 		if (disk->fops->release)
-			ret = disk->fops->release(bd_inode, NULL);
+			ret = disk->fops->release(disk, 0);
 	}
 	if (!bdev->bd_openers) {
 		struct module *owner = disk->fops->owner;

commit 86d434dede14108dd917b25af0f29c0cb28b8d18
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 26 19:50:05 2007 -0400

    [PATCH] eliminate use of ->f_flags in block methods
    
    store needed information in f_mode
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8897f3b02e98..b9022694e9f7 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1007,6 +1007,13 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		return ret;
 	}
 
+	if (file->f_flags & O_NDELAY)
+		file->f_mode |= FMODE_NDELAY;
+	if (file->f_flags & O_EXCL)
+		file->f_mode |= FMODE_EXCL;
+	if ((file->f_flags & O_ACCMODE) == 3)
+		file->f_mode |= FMODE_WRITE_IOCTL;
+
 	ret = -ENXIO;
 	file->f_mapping = bdev->bd_inode->i_mapping;
 

commit aeb5d727062a0238a2f96c9c380fbd2be4640c6f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Sep 2 15:28:45 2008 -0400

    [PATCH] introduce fmode_t, do annotations
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 218408eed1bb..8897f3b02e98 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -840,7 +840,7 @@ EXPORT_SYMBOL_GPL(bd_release_from_disk);
  * to be used for internal purposes.  If you ever need it - reconsider
  * your API.
  */
-struct block_device *open_by_devnum(dev_t dev, unsigned mode)
+struct block_device *open_by_devnum(dev_t dev, fmode_t mode)
 {
 	struct block_device *bdev = bdget(dev);
 	int err = -ENOMEM;
@@ -975,7 +975,7 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
-static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
+static int __blkdev_get(struct block_device *bdev, fmode_t mode, unsigned flags,
 			int for_part);
 static int __blkdev_put(struct block_device *bdev, int for_part);
 
@@ -1104,7 +1104,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	return ret;
 }
 
-static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
+static int __blkdev_get(struct block_device *bdev, fmode_t mode, unsigned flags,
 			int for_part)
 {
 	/*
@@ -1123,7 +1123,7 @@ static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
 	return do_open(bdev, &fake_file, for_part);
 }
 
-int blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags)
+int blkdev_get(struct block_device *bdev, fmode_t mode, unsigned flags)
 {
 	return __blkdev_get(bdev, mode, flags, 0);
 }
@@ -1315,7 +1315,7 @@ EXPORT_SYMBOL(lookup_bdev);
 struct block_device *open_bdev_excl(const char *path, int flags, void *holder)
 {
 	struct block_device *bdev;
-	mode_t mode = FMODE_READ;
+	fmode_t mode = FMODE_READ;
 	int error = 0;
 
 	bdev = lookup_bdev(path);

commit 496aa8a98f5ab22ced46be5dc2087cdf3d029bd7
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Thu Oct 16 07:46:23 2008 +0200

    block: fix current kernel-doc warnings
    
    Fix block kernel-doc warnings:
    
    Warning(linux-2.6.27-git4//fs/block_dev.c:1272): No description found for parameter 'path'
    Warning(linux-2.6.27-git4//block/blk-core.c:1021): No description found for parameter 'cpu'
    Warning(linux-2.6.27-git4//block/blk-core.c:1021): No description found for parameter 'part'
    Warning(/var/linsrc/linux-2.6.27-git4//block/genhd.c:544): No description found for parameter 'partno'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d84f0469a016..218408eed1bb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1262,7 +1262,7 @@ EXPORT_SYMBOL(ioctl_by_bdev);
 
 /**
  * lookup_bdev  - lookup a struct block_device by name
- * @pathname:	special file representing the block device
+ * @path:	special file representing the block device
  *
  * Get a reference to the blockdevice at @pathname in the current
  * namespace if possible and return it.  Return ERR_PTR(error)

commit 57d1b5366f46fe434e565b710baf683daff78dd8
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Thu Oct 9 10:42:38 2008 +0200

    block_dev: fix kernel-doc in new functions
    
    Fix kernel-doc in new functions:
    
    Error(mmotm-2008-1002-1617//fs/block_dev.c:895): duplicate section name 'Description'
    Error(mmotm-2008-1002-1617//fs/block_dev.c:924): duplicate section name 'Description'
    Warning(mmotm-2008-1002-1617//fs/block_dev.c:1282): No description found for parameter 'pathname'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    cc: Andrew Patterson <andrew.patterson@hp.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 57e2786dd2a5..d84f0469a016 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -879,9 +879,7 @@ static void flush_disk(struct block_device *bdev)
 }
 
 /**
- * check_disk_size_change - checks for disk size change and adjusts
- *                          bdev size.
- *
+ * check_disk_size_change - checks for disk size change and adjusts bdev size.
  * @disk: struct gendisk to check
  * @bdev: struct bdev to adjust.
  *
@@ -908,9 +906,7 @@ void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
 EXPORT_SYMBOL(check_disk_size_change);
 
 /**
- * revalidate_disk - wrapper for lower-level driver's revalidate_disk
- *                   call-back
- *
+ * revalidate_disk - wrapper for lower-level driver's revalidate_disk call-back
  * @disk: struct gendisk to be revalidated
  *
  * This routine is a wrapper for lower-level driver's revalidate_disk
@@ -1266,10 +1262,9 @@ EXPORT_SYMBOL(ioctl_by_bdev);
 
 /**
  * lookup_bdev  - lookup a struct block_device by name
+ * @pathname:	special file representing the block device
  *
- * @path:	special file representing the block device
- *
- * Get a reference to the blockdevice at @path in the current
+ * Get a reference to the blockdevice at @pathname in the current
  * namespace if possible and return it.  Return ERR_PTR(error)
  * otherwise.
  */

commit 608aeef17a91747d6303de4df5e2c2e6899a95e8
Author: Andrew Patterson <andrew.patterson@hp.com>
Date:   Thu Sep 4 14:27:45 2008 -0600

    Call flush_disk() after detecting an online resize.
    
    We call flush_disk() to make sure the buffer cache for the disk is
    flushed after a disk resize. There are two resize cases, growing and
    shrinking. Given that users can shrink/then grow a disk before
    revalidate_disk() is called, we treat the grow case identically to
    shrinking. We need to flush the buffer cache after an online shrink
    because, as James Bottomley puts it,
    
         The two use cases for shrinking I can see are
    
         1. planned: the fs is already shrunk to within the new boundaries
            and all data is relocated, so invalidate is fine (any dirty
            buffers that might exist in the shrunk region are there only
            because they were relocated but not yet written to their
            original location).
         2. unplanned:  In this case, the fs is probably toast, so whether
            we invalidate or not isn't going to make a whole lot of
            difference; it's still going to try to read or write from
            sectors beyond the new size and get I/O errors.
    
    Immediately invalidating shrunk disks will cause errors for outstanding
    I/Os for reads/write beyond the new end of the disk to be generated
    earlier then if we waited for the normal buffer cache operation. It also
    removes a potential security hole where we might keep old data around
    from beyond the end of the shrunk disk if the disk was not invalidated.
    
    Signed-off-by: Andrew Patterson <andrew.patterson@hp.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 33650fc537c4..57e2786dd2a5 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -902,6 +902,7 @@ void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
 		       "%s: detected capacity change from %lld to %lld\n",
 		       name, bdev_size, disk_size);
 		i_size_write(bdev->bd_inode, disk_size);
+		flush_disk(bdev);
 	}
 }
 EXPORT_SYMBOL(check_disk_size_change);

commit 56ade44b46780fa291fa68b824f1dafdcb11b0ca
Author: Andrew Patterson <andrew.patterson@hp.com>
Date:   Thu Sep 4 14:27:40 2008 -0600

    Added flush_disk to factor out common buffer cache flushing code.
    
    We need to be able to flush the buffer cache for for more than
    just when a disk is changed, so we factor out common cache flush code
    in check_disk_change() to an internal flush_disk() routine.  This
    routine will then be used for both disk changes and disk resizes (in a
    later patch).
    
    Include the disk name in the text indicating that there are busy
    inodes on the device and increase the KERN severity of the message.
    
    Signed-off-by: Andrew Patterson <andrew.patterson@hp.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b721955d382e..33650fc537c4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -852,6 +852,32 @@ struct block_device *open_by_devnum(dev_t dev, unsigned mode)
 
 EXPORT_SYMBOL(open_by_devnum);
 
+/**
+ * flush_disk - invalidates all buffer-cache entries on a disk
+ *
+ * @bdev:      struct block device to be flushed
+ *
+ * Invalidates all buffer-cache entries on a disk. It should be called
+ * when a disk has been changed -- either by a media change or online
+ * resize.
+ */
+static void flush_disk(struct block_device *bdev)
+{
+	if (__invalidate_device(bdev)) {
+		char name[BDEVNAME_SIZE] = "";
+
+		if (bdev->bd_disk)
+			disk_name(bdev->bd_disk, 0, name);
+		printk(KERN_WARNING "VFS: busy inodes on changed media or "
+		       "resized disk %s\n", name);
+	}
+
+	if (!bdev->bd_disk)
+		return;
+	if (disk_partitionable(bdev->bd_disk))
+		bdev->bd_invalidated = 1;
+}
+
 /**
  * check_disk_size_change - checks for disk size change and adjusts
  *                          bdev size.
@@ -929,13 +955,9 @@ int check_disk_change(struct block_device *bdev)
 	if (!bdops->media_changed(bdev->bd_disk))
 		return 0;
 
-	if (__invalidate_device(bdev))
-		printk("VFS: busy inodes on changed media.\n");
-
+	flush_disk(bdev);
 	if (bdops->revalidate_disk)
 		bdops->revalidate_disk(bdev->bd_disk);
-	if (disk_partitionable(bdev->bd_disk))
-		bdev->bd_invalidated = 1;
 	return 1;
 }
 

commit c3279d1454cdfed02a557d789d8a6d08ab4cbe70
Author: Andrew Patterson <andrew.patterson@hp.com>
Date:   Thu Sep 4 14:27:25 2008 -0600

    Adjust block device size after an online resize of a disk.
    
    The revalidate_disk routine now checks if a disk has been resized by
    comparing the gendisk capacity to the bdev inode size.  If they are
    different (usually because the disk has been resized underneath the kernel)
    the bdev inode size is adjusted to match the capacity.
    
    Signed-off-by: Andrew Patterson <andrew.patterson@hp.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4eeb69a88734..b721955d382e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -852,6 +852,34 @@ struct block_device *open_by_devnum(dev_t dev, unsigned mode)
 
 EXPORT_SYMBOL(open_by_devnum);
 
+/**
+ * check_disk_size_change - checks for disk size change and adjusts
+ *                          bdev size.
+ *
+ * @disk: struct gendisk to check
+ * @bdev: struct bdev to adjust.
+ *
+ * This routine checks to see if the bdev size does not match the disk size
+ * and adjusts it if it differs.
+ */
+void check_disk_size_change(struct gendisk *disk, struct block_device *bdev)
+{
+	loff_t disk_size, bdev_size;
+
+	disk_size = (loff_t)get_capacity(disk) << 9;
+	bdev_size = i_size_read(bdev->bd_inode);
+	if (disk_size != bdev_size) {
+		char name[BDEVNAME_SIZE];
+
+		disk_name(disk, 0, name);
+		printk(KERN_INFO
+		       "%s: detected capacity change from %lld to %lld\n",
+		       name, bdev_size, disk_size);
+		i_size_write(bdev->bd_inode, disk_size);
+	}
+}
+EXPORT_SYMBOL(check_disk_size_change);
+
 /**
  * revalidate_disk - wrapper for lower-level driver's revalidate_disk
  *                   call-back
@@ -864,11 +892,20 @@ EXPORT_SYMBOL(open_by_devnum);
  */
 int revalidate_disk(struct gendisk *disk)
 {
+	struct block_device *bdev;
 	int ret = 0;
 
 	if (disk->fops->revalidate_disk)
 		ret = disk->fops->revalidate_disk(disk);
 
+	bdev = bdget_disk(disk, 0);
+	if (!bdev)
+		return ret;
+
+	mutex_lock(&bdev->bd_mutex);
+	check_disk_size_change(disk, bdev);
+	mutex_unlock(&bdev->bd_mutex);
+	bdput(bdev);
 	return ret;
 }
 EXPORT_SYMBOL(revalidate_disk);

commit 0c002c2f74e10baa9021d3ecc50585c6eafea568
Author: Andrew Patterson <andrew.patterson@hp.com>
Date:   Thu Sep 4 14:27:20 2008 -0600

    Wrapper for lower-level revalidate_disk routines.
    
    This is a wrapper for the lower-level revalidate_disk call-backs such
    as sd_revalidate_disk(). It allows us to perform pre and post
    operations when calling them.
    
    We will use this wrapper in a later patch to adjust block device sizes
    after an online resize (a _post_ operation).
    
    Signed-off-by: Andrew Patterson <andrew.patterson@hp.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c3fa19bd64df..4eeb69a88734 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -852,6 +852,27 @@ struct block_device *open_by_devnum(dev_t dev, unsigned mode)
 
 EXPORT_SYMBOL(open_by_devnum);
 
+/**
+ * revalidate_disk - wrapper for lower-level driver's revalidate_disk
+ *                   call-back
+ *
+ * @disk: struct gendisk to be revalidated
+ *
+ * This routine is a wrapper for lower-level driver's revalidate_disk
+ * call-backs.  It is used to do common pre and post operations needed
+ * for all revalidate_disk operations.
+ */
+int revalidate_disk(struct gendisk *disk)
+{
+	int ret = 0;
+
+	if (disk->fops->revalidate_disk)
+		ret = disk->fops->revalidate_disk(disk);
+
+	return ret;
+}
+EXPORT_SYMBOL(revalidate_disk);
+
 /*
  * This routine checks whether a removable media has been changed,
  * and invalidates all buffer-cache-entries in that case. This

commit 0762b8bde9729f10f8e6249809660ff2ec3ad735
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Aug 25 19:56:12 2008 +0900

    block: always set bdev->bd_part
    
    Till now, bdev->bd_part is set only if the bdev was for parts other
    than part0.  This patch makes bdev->bd_part always set so that code
    paths don't have to differenciate common handling.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 57d572642854..c3fa19bd64df 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -540,14 +540,6 @@ EXPORT_SYMBOL(bd_release);
  *           /sys/block/sda/holders/dm-0 --> /sys/block/dm-0
  */
 
-static struct kobject *bdev_get_kobj(struct block_device *bdev)
-{
-	if (bdev->bd_contains != bdev)
-		return kobject_get(&part_to_dev(bdev->bd_part)->kobj);
-	else
-		return kobject_get(&disk_to_dev(bdev->bd_disk)->kobj);
-}
-
 static int add_symlink(struct kobject *from, struct kobject *to)
 {
 	if (!from || !to)
@@ -596,7 +588,7 @@ static int bd_holder_grab_dirs(struct block_device *bdev,
 	if (!bo->hdev)
 		goto fail_put_sdir;
 
-	bo->sdev = bdev_get_kobj(bdev);
+	bo->sdev = kobject_get(&part_to_dev(bdev->bd_part)->kobj);
 	if (!bo->sdev)
 		goto fail_put_hdev;
 
@@ -919,7 +911,6 @@ static int __blkdev_put(struct block_device *bdev, int for_part);
 
 static int do_open(struct block_device *bdev, struct file *file, int for_part)
 {
-	struct module *owner = NULL;
 	struct gendisk *disk;
 	struct hd_struct *part = NULL;
 	int ret;
@@ -941,25 +932,27 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 
 	ret = -ENXIO;
 	file->f_mapping = bdev->bd_inode->i_mapping;
+
 	lock_kernel();
+
 	disk = get_gendisk(bdev->bd_dev, &partno);
-	if (!disk) {
-		unlock_kernel();
-		bdput(bdev);
-		return ret;
-	}
-	owner = disk->fops->owner;
+	if (!disk)
+		goto out_unlock_kernel;
+	part = disk_get_part(disk, partno);
+	if (!part)
+		goto out_unlock_kernel;
 
 	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
+		bdev->bd_part = part;
 		bdev->bd_contains = bdev;
 		if (!partno) {
 			struct backing_dev_info *bdi;
 			if (disk->fops->open) {
 				ret = disk->fops->open(bdev->bd_inode, file);
 				if (ret)
-					goto out_first;
+					goto out_clear;
 			}
 			if (!bdev->bd_openers) {
 				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
@@ -975,31 +968,32 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 			whole = bdget_disk(disk, 0);
 			ret = -ENOMEM;
 			if (!whole)
-				goto out_first;
+				goto out_clear;
 			BUG_ON(for_part);
 			ret = __blkdev_get(whole, file->f_mode, file->f_flags, 1);
 			if (ret)
-				goto out_first;
+				goto out_clear;
 			bdev->bd_contains = whole;
-			part = disk_get_part(disk, partno);
 			bdev->bd_inode->i_data.backing_dev_info =
 			   whole->bd_inode->i_data.backing_dev_info;
 			if (!(disk->flags & GENHD_FL_UP) ||
 			    !part || !part->nr_sects) {
 				ret = -ENXIO;
-				goto out_first;
+				goto out_clear;
 			}
-			bdev->bd_part = part;
 			bd_set_size(bdev, (loff_t)part->nr_sects << 9);
 		}
 	} else {
+		disk_put_part(part);
 		put_disk(disk);
-		module_put(owner);
+		module_put(disk->fops->owner);
+		part = NULL;
+		disk = NULL;
 		if (bdev->bd_contains == bdev) {
 			if (bdev->bd_disk->fops->open) {
 				ret = bdev->bd_disk->fops->open(bdev->bd_inode, file);
 				if (ret)
-					goto out;
+					goto out_unlock_bdev;
 			}
 			if (bdev->bd_invalidated)
 				rescan_partitions(bdev->bd_disk, bdev);
@@ -1012,20 +1006,24 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	unlock_kernel();
 	return 0;
 
-out_first:
+ out_clear:
 	bdev->bd_disk = NULL;
+	bdev->bd_part = NULL;
 	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
 	if (bdev != bdev->bd_contains)
 		__blkdev_put(bdev->bd_contains, 1);
 	bdev->bd_contains = NULL;
-	put_disk(disk);
-	disk_put_part(part);
-	module_put(owner);
-out:
+ out_unlock_bdev:
 	mutex_unlock(&bdev->bd_mutex);
+ out_unlock_kernel:
 	unlock_kernel();
-	if (ret)
-		bdput(bdev);
+
+	disk_put_part(part);
+	if (disk)
+		module_put(disk->fops->owner);
+	put_disk(disk);
+	bdput(bdev);
+
 	return ret;
 }
 
@@ -1110,11 +1108,8 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 
 		put_disk(disk);
 		module_put(owner);
-
-		if (bdev->bd_contains != bdev) {
-			disk_put_part(bdev->bd_part);
-			bdev->bd_part = NULL;
-		}
+		disk_put_part(bdev->bd_part);
+		bdev->bd_part = NULL;
 		bdev->bd_disk = NULL;
 		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
 		if (bdev != bdev->bd_contains)

commit 4c46501d1659475dc6c89554af6ce7fe6ecf615c
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Aug 25 19:56:11 2008 +0900

    block: move holder_dir from disk to part0
    
    Move disk->holder_dir to part0->holder_dir.  Kill now mostly
    superflous bdev_get_holder().
    
    While at it, kill superflous kobject_get/put() around holder_dir,
    slave_dir and cmd_filter creation and collapse
    disk_sysfs_add_subdirs() into register_disk().  These serve no purpose
    but obfuscating the code.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c982a9107979..57d572642854 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -548,14 +548,6 @@ static struct kobject *bdev_get_kobj(struct block_device *bdev)
 		return kobject_get(&disk_to_dev(bdev->bd_disk)->kobj);
 }
 
-static struct kobject *bdev_get_holder(struct block_device *bdev)
-{
-	if (bdev->bd_contains != bdev)
-		return kobject_get(bdev->bd_part->holder_dir);
-	else
-		return kobject_get(bdev->bd_disk->holder_dir);
-}
-
 static int add_symlink(struct kobject *from, struct kobject *to)
 {
 	if (!from || !to)
@@ -608,7 +600,7 @@ static int bd_holder_grab_dirs(struct block_device *bdev,
 	if (!bo->sdev)
 		goto fail_put_hdev;
 
-	bo->hdir = bdev_get_holder(bdev);
+	bo->hdir = kobject_get(bdev->bd_part->holder_dir);
 	if (!bo->hdir)
 		goto fail_put_sdev;
 

commit b5d0b9df0ba5d9a044f3a21e7544f53d90bd1465
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Sep 3 09:06:42 2008 +0200

    block: introduce partition 0
    
    genhd and partition code handled disk and partitions separately.  All
    information about the whole disk was in struct genhd and partitions in
    struct hd_struct.  However, the whole disk (part0) and other
    partitions have a lot in common and the data structures end up having
    good number of common fields and thus separate code paths doing the
    same thing.  Also, the partition array was indexed by partno - 1 which
    gets pretty confusing at times.
    
    This patch introduces partition 0 and makes the partition array
    indexed by partno.  Following patches will unify the handling of disk
    and parts piece-by-piece.
    
    This patch also implements disk_partitionable() which tests whether a
    disk is partitionable.  With coming dynamic partition array change,
    the most common usage of disk_max_parts() will be testing whether a
    disk is partitionable and the number of max partitions will become
    much less important.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index a02df22f37c3..c982a9107979 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -892,7 +892,7 @@ int check_disk_change(struct block_device *bdev)
 
 	if (bdops->revalidate_disk)
 		bdops->revalidate_disk(bdev->bd_disk);
-	if (disk_max_parts(bdev->bd_disk))
+	if (disk_partitionable(bdev->bd_disk))
 		bdev->bd_invalidated = 1;
 	return 1;
 }

commit ed9e1982347b36573cd622ee5f4e2a7ccd79b3fd
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Aug 25 19:56:05 2008 +0900

    block: implement and use {disk|part}_to_dev()
    
    Implement {disk|part}_to_dev() and use them to access generic device
    instead of directly dereferencing {disk|part}->dev.  To make sure no
    user is left behind, rename generic devices fields to __dev.
    
    This is in preparation of unifying partition 0 handling with other
    partitions.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2f2873b9a041..a02df22f37c3 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -543,9 +543,9 @@ EXPORT_SYMBOL(bd_release);
 static struct kobject *bdev_get_kobj(struct block_device *bdev)
 {
 	if (bdev->bd_contains != bdev)
-		return kobject_get(&bdev->bd_part->dev.kobj);
+		return kobject_get(&part_to_dev(bdev->bd_part)->kobj);
 	else
-		return kobject_get(&bdev->bd_disk->dev.kobj);
+		return kobject_get(&disk_to_dev(bdev->bd_disk)->kobj);
 }
 
 static struct kobject *bdev_get_holder(struct block_device *bdev)

commit e71bf0d0ee89e51b92776391c5634938236977d5
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Sep 3 09:03:02 2008 +0200

    block: fix disk->part[] dereferencing race
    
    disk->part[] is protected by its matching bdev's lock.  However,
    non-critical accesses like collecting stats and printing out sysfs and
    proc information used to be performed without any locking.  As
    partitions can come and go dynamically, partitions can go away
    underneath those non-critical accesses.  As some of those accesses are
    writes, this theoretically can lead to silent corruption.
    
    This patch fixes the race by using RCU for the partition array and dev
    reference counter to hold partitions.
    
    * Rename disk->part[] to disk->__part[] to make sure no one outside
      genhd layer proper accesses it directly.
    
    * Use RCU for disk->__part[] dereferencing.
    
    * Implement disk_{get|put}_part() which can be used to get and put
      partitions from gendisk respectively.
    
    * Iterators are implemented to help iterate through all partitions
      safely.
    
    * Functions which require RCU readlock are marked with _rcu suffix.
    
    * Use disk_put_part() in __blkdev_put() instead of directly putting
      the contained kobject.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 72e0a2887cb7..2f2873b9a041 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -929,6 +929,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 {
 	struct module *owner = NULL;
 	struct gendisk *disk;
+	struct hd_struct *part = NULL;
 	int ret;
 	int partno;
 	int perm = 0;
@@ -978,7 +979,6 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 			if (bdev->bd_invalidated)
 				rescan_partitions(disk, bdev);
 		} else {
-			struct hd_struct *p;
 			struct block_device *whole;
 			whole = bdget_disk(disk, 0);
 			ret = -ENOMEM;
@@ -989,16 +989,16 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 			if (ret)
 				goto out_first;
 			bdev->bd_contains = whole;
-			p = disk->part[partno - 1];
+			part = disk_get_part(disk, partno);
 			bdev->bd_inode->i_data.backing_dev_info =
 			   whole->bd_inode->i_data.backing_dev_info;
-			if (!(disk->flags & GENHD_FL_UP) || !p || !p->nr_sects) {
+			if (!(disk->flags & GENHD_FL_UP) ||
+			    !part || !part->nr_sects) {
 				ret = -ENXIO;
 				goto out_first;
 			}
-			kobject_get(&p->dev.kobj);
-			bdev->bd_part = p;
-			bd_set_size(bdev, (loff_t) p->nr_sects << 9);
+			bdev->bd_part = part;
+			bd_set_size(bdev, (loff_t)part->nr_sects << 9);
 		}
 	} else {
 		put_disk(disk);
@@ -1027,6 +1027,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 		__blkdev_put(bdev->bd_contains, 1);
 	bdev->bd_contains = NULL;
 	put_disk(disk);
+	disk_put_part(part);
 	module_put(owner);
 out:
 	mutex_unlock(&bdev->bd_mutex);
@@ -1119,7 +1120,7 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 		module_put(owner);
 
 		if (bdev->bd_contains != bdev) {
-			kobject_put(&bdev->bd_part->dev.kobj);
+			disk_put_part(bdev->bd_part);
 			bdev->bd_part = NULL;
 		}
 		bdev->bd_disk = NULL;

commit f331c0296f2a9fee0d396a70598b954062603015
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Sep 3 09:01:48 2008 +0200

    block: don't depend on consecutive minor space
    
    * Implement disk_devt() and part_devt() and use them to directly
      access devt instead of computing it from ->major and ->first_minor.
    
      Note that all references to ->major and ->first_minor outside of
      block layer is used to determine devt of the disk (the part0) and as
      ->major and ->first_minor will continue to represent devt for the
      disk, converting these users aren't strictly necessary.  However,
      convert them for consistency.
    
    * Implement disk_max_parts() to avoid directly deferencing
      genhd->minors.
    
    * Update bdget_disk() such that it doesn't assume consecutive minor
      space.
    
    * Move devt computation from register_disk() to add_disk() and make it
      the only one (all other usages use the initially determined value).
    
    These changes clean up the code and will help disk->part dereference
    fix and extended block device numbers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index de0776cd7215..72e0a2887cb7 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -892,7 +892,7 @@ int check_disk_change(struct block_device *bdev)
 
 	if (bdops->revalidate_disk)
 		bdops->revalidate_disk(bdev->bd_disk);
-	if (bdev->bd_disk->minors > 1)
+	if (disk_max_parts(bdev->bd_disk))
 		bdev->bd_invalidated = 1;
 	return 1;
 }

commit cf771cb5a7b716f3f9e532fd42a1e3a0a75adec5
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Sep 3 09:01:09 2008 +0200

    block: make variable and argument names more consistent
    
    In hd_struct, @partno is used to denote partition number and a number
    of other places use @part to denote hd_struct.  Functions use @part
    and @index instead.  This causes confusion and makes it difficult to
    use consistent variable names for hd_struct.  Always use @partno if a
    variable represents partition number.
    
    Also, print out functions use @f or @part for seq_file argument.  Use
    @seqf uniformly instead.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index aff54219e049..de0776cd7215 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -930,7 +930,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	struct module *owner = NULL;
 	struct gendisk *disk;
 	int ret;
-	int part;
+	int partno;
 	int perm = 0;
 
 	if (file->f_mode & FMODE_READ)
@@ -949,7 +949,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	ret = -ENXIO;
 	file->f_mapping = bdev->bd_inode->i_mapping;
 	lock_kernel();
-	disk = get_gendisk(bdev->bd_dev, &part);
+	disk = get_gendisk(bdev->bd_dev, &partno);
 	if (!disk) {
 		unlock_kernel();
 		bdput(bdev);
@@ -961,7 +961,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
 		bdev->bd_contains = bdev;
-		if (!part) {
+		if (!partno) {
 			struct backing_dev_info *bdi;
 			if (disk->fops->open) {
 				ret = disk->fops->open(bdev->bd_inode, file);
@@ -989,7 +989,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 			if (ret)
 				goto out_first;
 			bdev->bd_contains = whole;
-			p = disk->part[part - 1];
+			p = disk->part[partno - 1];
 			bdev->bd_inode->i_data.backing_dev_info =
 			   whole->bd_inode->i_data.backing_dev_info;
 			if (!(disk->flags & GENHD_FL_UP) || !p || !p->nr_sects) {

commit d5686b444ff3f72808d2b3fbd58672a86cdf38e7
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Aug 1 05:00:11 2008 -0400

    [PATCH] switch mtd and dm-table to lookup_bdev()
    
    No need to open-code it...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e664b0b70489..aff54219e049 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1236,6 +1236,7 @@ struct block_device *lookup_bdev(const char *path)
 	bdev = ERR_PTR(error);
 	goto out;
 }
+EXPORT_SYMBOL(lookup_bdev);
 
 /**
  * open_bdev_excl  -  open a block device by name and set it up for use

commit 8266602033d6adc6d10cb8811c1fd694767909b0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Aug 1 05:32:04 2008 -0400

    [PATCH] fix bdev leak in block_dev.c do_open()
    
    Callers expect it to drop reference to bdev on all failure exits.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index dcf37cada369..e664b0b70489 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -941,8 +941,10 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	 * hooks: /n/, see "layering violations".
 	 */
 	ret = devcgroup_inode_permission(bdev->bd_inode, perm);
-	if (ret != 0)
+	if (ret != 0) {
+		bdput(bdev);
 		return ret;
+	}
 
 	ret = -ENXIO;
 	file->f_mapping = bdev->bd_inode->i_mapping;

commit 51cc50685a4275c6a02653670af9f108a64e01cf
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Fri Jul 25 19:45:34 2008 -0700

    SL*B: drop kmem cache argument from constructor
    
    Kmem cache passed to constructor is only needed for constructors that are
    themselves multiplexeres.  Nobody uses this "feature", nor does anybody uses
    passed kmem cache in non-trivial way, so pass only pointer to object.
    
    Non-trivial places are:
            arch/powerpc/mm/init_64.c
            arch/powerpc/mm/hugetlbpage.c
    
    This is flag day, yes.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Acked-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Jon Tollefson <kniht@linux.vnet.ibm.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Matt Mackall <mpm@selenic.com>
    [akpm@linux-foundation.org: fix arch/powerpc/mm/hugetlbpage.c]
    [akpm@linux-foundation.org: fix mm/slab.c]
    [akpm@linux-foundation.org: fix ubifs]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 10d8a0aa871a..dcf37cada369 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -271,7 +271,7 @@ static void bdev_destroy_inode(struct inode *inode)
 	kmem_cache_free(bdev_cachep, bdi);
 }
 
-static void init_once(struct kmem_cache * cachep, void *foo)
+static void init_once(void *foo)
 {
 	struct bdev_inode *ei = (struct bdev_inode *) foo;
 	struct block_device *bdev = &ei->bdev;

commit fe6e9c1f25ac01f848bd084ee0ee62a5a0966ff3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 23 08:30:55 2008 -0400

    [PATCH] fix cgroup-inflicted breakage in block_dev.c
    
    devcgroup_inode_permission() expects MAY_FOO, not FMODE_FOO; kindly
    keep your misdesign consistent if you positively have to inflict it
    on the kernel.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 470c10ceb0fb..10d8a0aa871a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -931,8 +931,16 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	struct gendisk *disk;
 	int ret;
 	int part;
+	int perm = 0;
 
-	ret = devcgroup_inode_permission(bdev->bd_inode, file->f_mode);
+	if (file->f_mode & FMODE_READ)
+		perm |= MAY_READ;
+	if (file->f_mode & FMODE_WRITE)
+		perm |= MAY_WRITE;
+	/*
+	 * hooks: /n/, see "layering violations".
+	 */
+	ret = devcgroup_inode_permission(bdev->bd_inode, perm);
 	if (ret != 0)
 		return ret;
 

commit 7db9cfd380205f6b50afdc3bc3619f876a5eaf0d
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Jun 5 22:46:27 2008 -0700

    devscgroup: check for device permissions at mount time
    
    Currently even if a task sits in an all-denied cgroup it can still mount
    any block device in any mode it wants.
    
    Put a proper check in do_open for block device to prevent this.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Tested-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 7d822fae7765..470c10ceb0fb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -12,6 +12,7 @@
 #include <linux/kmod.h>
 #include <linux/major.h>
 #include <linux/smp_lock.h>
+#include <linux/device_cgroup.h>
 #include <linux/highmem.h>
 #include <linux/blkdev.h>
 #include <linux/module.h>
@@ -928,9 +929,14 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 {
 	struct module *owner = NULL;
 	struct gendisk *disk;
-	int ret = -ENXIO;
+	int ret;
 	int part;
 
+	ret = devcgroup_inode_permission(bdev->bd_inode, file->f_mode);
+	if (ret != 0)
+		return ret;
+
+	ret = -ENXIO;
 	file->f_mapping = bdev->bd_inode->i_mapping;
 	lock_kernel();
 	disk = get_gendisk(bdev->bd_dev, &part);

commit 86b6c7a7f78feca58d2d8615e53aee4d59ab9dc6
Author: Adrian Bunk <bunk@kernel.org>
Date:   Mon Feb 18 13:48:32 2008 +0100

    fs/block_dev.c: remove #if 0'ed code
    
    Commit b2e895dbd80c420bfc0937c3729b4afe073b3848 #if 0'ed this code stating:
    
    <--  snip  -->
    
        [PATCH] revert blockdev direct io back to 2.6.19 version
    
        Andrew Vasquez is reporting as-iosched oopses and a 65% throughput
        slowdown due to the recent special-casing of direct-io against
        blockdevs.  We don't know why either of these things are occurring.
    
        The patch minimally reverts us back to the 2.6.19 code for a 2.6.20
        release.
    
    <--  snip  -->
    
    It has since been dead code, and unless someone wants to revive it now
    it's time to remove it.
    
    This patch also makes bio_release_pages() static again and removes the
    ki_bio_count member from struct kiocb, reverting changes that had been
    done for this dead code.
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: Jens Axboe <axboe@carl.home.kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8335f0e1b0fb..7d822fae7765 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -173,203 +173,6 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 				iov, offset, nr_segs, blkdev_get_blocks, NULL);
 }
 
-#if 0
-static void blk_end_aio(struct bio *bio, int error)
-{
-	struct kiocb *iocb = bio->bi_private;
-	atomic_t *bio_count = &iocb->ki_bio_count;
-
-	if (bio_data_dir(bio) == READ)
-		bio_check_pages_dirty(bio);
-	else {
-		bio_release_pages(bio);
-		bio_put(bio);
-	}
-
-	/* iocb->ki_nbytes stores error code from LLDD */
-	if (error)
-		iocb->ki_nbytes = -EIO;
-
-	if (atomic_dec_and_test(bio_count)) {
-		if ((long)iocb->ki_nbytes < 0)
-			aio_complete(iocb, iocb->ki_nbytes, 0);
-		else
-			aio_complete(iocb, iocb->ki_left, 0);
-	}
-
-	return 0;
-}
-
-#define VEC_SIZE	16
-struct pvec {
-	unsigned short nr;
-	unsigned short idx;
-	struct page *page[VEC_SIZE];
-};
-
-#define PAGES_SPANNED(addr, len)	\
-	(DIV_ROUND_UP((addr) + (len), PAGE_SIZE) - (addr) / PAGE_SIZE);
-
-/*
- * get page pointer for user addr, we internally cache struct page array for
- * (addr, count) range in pvec to avoid frequent call to get_user_pages.  If
- * internal page list is exhausted, a batch count of up to VEC_SIZE is used
- * to get next set of page struct.
- */
-static struct page *blk_get_page(unsigned long addr, size_t count, int rw,
-				 struct pvec *pvec)
-{
-	int ret, nr_pages;
-	if (pvec->idx == pvec->nr) {
-		nr_pages = PAGES_SPANNED(addr, count);
-		nr_pages = min(nr_pages, VEC_SIZE);
-		down_read(&current->mm->mmap_sem);
-		ret = get_user_pages(current, current->mm, addr, nr_pages,
-				     rw == READ, 0, pvec->page, NULL);
-		up_read(&current->mm->mmap_sem);
-		if (ret < 0)
-			return ERR_PTR(ret);
-		pvec->nr = ret;
-		pvec->idx = 0;
-	}
-	return pvec->page[pvec->idx++];
-}
-
-/* return a page back to pvec array */
-static void blk_unget_page(struct page *page, struct pvec *pvec)
-{
-	pvec->page[--pvec->idx] = page;
-}
-
-static ssize_t
-blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
-		 loff_t pos, unsigned long nr_segs)
-{
-	struct inode *inode = iocb->ki_filp->f_mapping->host;
-	unsigned blkbits = blksize_bits(bdev_hardsect_size(I_BDEV(inode)));
-	unsigned blocksize_mask = (1 << blkbits) - 1;
-	unsigned long seg = 0;	/* iov segment iterator */
-	unsigned long nvec;	/* number of bio vec needed */
-	unsigned long cur_off;	/* offset into current page */
-	unsigned long cur_len;	/* I/O len of current page, up to PAGE_SIZE */
-
-	unsigned long addr;	/* user iovec address */
-	size_t count;		/* user iovec len */
-	size_t nbytes = iocb->ki_nbytes = iocb->ki_left; /* total xfer size */
-	loff_t size;		/* size of block device */
-	struct bio *bio;
-	atomic_t *bio_count = &iocb->ki_bio_count;
-	struct page *page;
-	struct pvec pvec;
-
-	pvec.nr = 0;
-	pvec.idx = 0;
-
-	if (pos & blocksize_mask)
-		return -EINVAL;
-
-	size = i_size_read(inode);
-	if (pos + nbytes > size) {
-		nbytes = size - pos;
-		iocb->ki_left = nbytes;
-	}
-
-	/*
-	 * check first non-zero iov alignment, the remaining
-	 * iov alignment is checked inside bio loop below.
-	 */
-	do {
-		addr = (unsigned long) iov[seg].iov_base;
-		count = min(iov[seg].iov_len, nbytes);
-		if (addr & blocksize_mask || count & blocksize_mask)
-			return -EINVAL;
-	} while (!count && ++seg < nr_segs);
-	atomic_set(bio_count, 1);
-
-	while (nbytes) {
-		/* roughly estimate number of bio vec needed */
-		nvec = (nbytes + PAGE_SIZE - 1) / PAGE_SIZE;
-		nvec = max(nvec, nr_segs - seg);
-		nvec = min(nvec, (unsigned long) BIO_MAX_PAGES);
-
-		/* bio_alloc should not fail with GFP_KERNEL flag */
-		bio = bio_alloc(GFP_KERNEL, nvec);
-		bio->bi_bdev = I_BDEV(inode);
-		bio->bi_end_io = blk_end_aio;
-		bio->bi_private = iocb;
-		bio->bi_sector = pos >> blkbits;
-same_bio:
-		cur_off = addr & ~PAGE_MASK;
-		cur_len = PAGE_SIZE - cur_off;
-		if (count < cur_len)
-			cur_len = count;
-
-		page = blk_get_page(addr, count, rw, &pvec);
-		if (unlikely(IS_ERR(page)))
-			goto backout;
-
-		if (bio_add_page(bio, page, cur_len, cur_off)) {
-			pos += cur_len;
-			addr += cur_len;
-			count -= cur_len;
-			nbytes -= cur_len;
-
-			if (count)
-				goto same_bio;
-			while (++seg < nr_segs) {
-				addr = (unsigned long) iov[seg].iov_base;
-				count = iov[seg].iov_len;
-				if (!count)
-					continue;
-				if (unlikely(addr & blocksize_mask ||
-					     count & blocksize_mask)) {
-					page = ERR_PTR(-EINVAL);
-					goto backout;
-				}
-				count = min(count, nbytes);
-				goto same_bio;
-			}
-		} else {
-			blk_unget_page(page, &pvec);
-		}
-
-		/* bio is ready, submit it */
-		if (rw == READ)
-			bio_set_pages_dirty(bio);
-		atomic_inc(bio_count);
-		submit_bio(rw, bio);
-	}
-
-completion:
-	iocb->ki_left -= nbytes;
-	nbytes = iocb->ki_left;
-	iocb->ki_pos += nbytes;
-
-	blk_run_address_space(inode->i_mapping);
-	if (atomic_dec_and_test(bio_count))
-		aio_complete(iocb, nbytes, 0);
-
-	return -EIOCBQUEUED;
-
-backout:
-	/*
-	 * back out nbytes count constructed so far for this bio,
-	 * we will throw away current bio.
-	 */
-	nbytes += bio->bi_size;
-	bio_release_pages(bio);
-	bio_put(bio);
-
-	/*
-	 * if no bio was submmitted, return the error code.
-	 * otherwise, proceed with pending I/O completion.
-	 */
-	if (atomic_read(bio_count) == 1)
-		return PTR_ERR(page);
-	goto completion;
-}
-#endif
-
 static int blkdev_writepage(struct page *page, struct writeback_control *wbc)
 {
 	return block_write_full_page(page, blkdev_get_block, wbc);

commit 4c54ac62dceecedd82d4a865017bba0b738e2897
Author: Adrian Bunk <bunk@kernel.org>
Date:   Mon Feb 18 13:48:31 2008 +0100

    make struct def_blk_aops static
    
    This patch makes the needlessly global struct def_blk_aops static.
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: Jens Axboe <axboe@carl.home.kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 67fe72ce6ac7..8335f0e1b0fb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -31,6 +31,8 @@ struct bdev_inode {
 	struct inode vfs_inode;
 };
 
+static const struct address_space_operations def_blk_aops;
+
 static inline struct bdev_inode *BDEV_I(struct inode *inode)
 {
 	return container_of(inode, struct bdev_inode, vfs_inode);
@@ -1334,7 +1336,7 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 	return blkdev_ioctl(file->f_mapping->host, file, cmd, arg);
 }
 
-const struct address_space_operations def_blk_aops = {
+static const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
 	.writepage	= blkdev_writepage,
 	.sync_page	= block_sync_page,

commit 1d957f9bf87da74f420424d16ece005202bbebd3
Author: Jan Blunck <jblunck@suse.de>
Date:   Thu Feb 14 19:34:35 2008 -0800

    Introduce path_put()
    
    * Add path_put() functions for releasing a reference to the dentry and
      vfsmount of a struct path in the right order
    
    * Switch from path_release(nd) to path_put(&nd->path)
    
    * Rename dput_path() to path_put_conditional()
    
    [akpm@linux-foundation.org: fix cifs]
    Signed-off-by: Jan Blunck <jblunck@suse.de>
    Signed-off-by: Andreas Gruenbacher <agruen@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Cc: <linux-fsdevel@vger.kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Steven French <sfrench@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 5f4721fdbdb6..67fe72ce6ac7 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1409,7 +1409,7 @@ struct block_device *lookup_bdev(const char *path)
 	if (!bdev)
 		goto fail;
 out:
-	path_release(&nd);
+	path_put(&nd.path);
 	return bdev;
 fail:
 	bdev = ERR_PTR(error);

commit 4ac9137858e08a19f29feac4e1f4df7c268b0ba5
Author: Jan Blunck <jblunck@suse.de>
Date:   Thu Feb 14 19:34:32 2008 -0800

    Embed a struct path into struct nameidata instead of nd->{dentry,mnt}
    
    This is the central patch of a cleanup series. In most cases there is no good
    reason why someone would want to use a dentry for itself. This series reflects
    that fact and embeds a struct path into nameidata.
    
    Together with the other patches of this series
    - it enforced the correct order of getting/releasing the reference count on
      <dentry,vfsmount> pairs
    - it prepares the VFS for stacking support since it is essential to have a
      struct path in every place where the stack can be traversed
    - it reduces the overall code size:
    
    without patch series:
       text    data     bss     dec     hex filename
    5321639  858418  715768 6895825  6938d1 vmlinux
    
    with patch series:
       text    data     bss     dec     hex filename
    5320026  858418  715768 6894212  693284 vmlinux
    
    This patch:
    
    Switch from nd->{dentry,mnt} to nd->path.{dentry,mnt} everywhere.
    
    [akpm@linux-foundation.org: coding-style fixes]
    [akpm@linux-foundation.org: fix cifs]
    [akpm@linux-foundation.org: fix smack]
    Signed-off-by: Jan Blunck <jblunck@suse.de>
    Signed-off-by: Andreas Gruenbacher <agruen@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Casey Schaufler <casey@schaufler-ca.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e63067d25cdb..5f4721fdbdb6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1397,12 +1397,12 @@ struct block_device *lookup_bdev(const char *path)
 	if (error)
 		return ERR_PTR(error);
 
-	inode = nd.dentry->d_inode;
+	inode = nd.path.dentry->d_inode;
 	error = -ENOTBLK;
 	if (!S_ISBLK(inode->i_mode))
 		goto fail;
 	error = -EACCES;
-	if (nd.mnt->mnt_flags & MNT_NODEV)
+	if (nd.path.mnt->mnt_flags & MNT_NODEV)
 		goto fail;
 	error = -ENOMEM;
 	bdev = bd_acquire(inode);

commit ba6f867f114760d4e43f0f93abe280ee0a0d696e
Author: Qi Yong <qiyong@fc-cn.com>
Date:   Wed Feb 6 01:37:23 2008 -0800

    kill an unused PTR_ERR in bdev_cache_init()
    
    Signed-off-by: Qi Yong <qiyong@fc-cn.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e48a630ae266..e63067d25cdb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -534,7 +534,6 @@ void __init bdev_cache_init(void)
 	if (err)
 		panic("Cannot register bdev pseudo-fs");
 	bd_mnt = kern_mount(&bd_type);
-	err = PTR_ERR(bd_mnt);
 	if (IS_ERR(bd_mnt))
 		panic("Cannot create bdev pseudo-fs");
 	blockdev_superblock = bd_mnt->mnt_sb;	/* For writeback */

commit edfaa7c36574f1bf09c65ad602412db9da5f96bf
Author: Kay Sievers <kay.sievers@vrfy.org>
Date:   Mon May 21 22:08:01 2007 +0200

    Driver core: convert block from raw kobjects to core devices
    
    This moves the block devices to /sys/class/block. It will create a
    flat list of all block devices, with the disks and partitions in one
    directory. For compatibility /sys/block is created and contains symlinks
    to the disks.
    
      /sys/class/block
      |-- sda -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda
      |-- sda1 -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda/sda1
      |-- sda10 -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda/sda10
      |-- sda5 -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda/sda5
      |-- sda6 -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda/sda6
      |-- sda7 -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda/sda7
      |-- sda8 -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda/sda8
      |-- sda9 -> ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda/sda9
      `-- sr0 -> ../../devices/pci0000:00/0000:00:1f.2/host1/target1:0:0/1:0:0:0/block/sr0
    
      /sys/block/
      |-- sda -> ../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda
      `-- sr0 -> ../devices/pci0000:00/0000:00:1f.2/host1/target1:0:0/1:0:0:0/block/sr0
    
    Signed-off-by: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 993f78c55221..e48a630ae266 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -738,9 +738,9 @@ EXPORT_SYMBOL(bd_release);
 static struct kobject *bdev_get_kobj(struct block_device *bdev)
 {
 	if (bdev->bd_contains != bdev)
-		return kobject_get(&bdev->bd_part->kobj);
+		return kobject_get(&bdev->bd_part->dev.kobj);
 	else
-		return kobject_get(&bdev->bd_disk->kobj);
+		return kobject_get(&bdev->bd_disk->dev.kobj);
 }
 
 static struct kobject *bdev_get_holder(struct block_device *bdev)
@@ -1176,7 +1176,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 				ret = -ENXIO;
 				goto out_first;
 			}
-			kobject_get(&p->kobj);
+			kobject_get(&p->dev.kobj);
 			bdev->bd_part = p;
 			bd_set_size(bdev, (loff_t) p->nr_sects << 9);
 		}
@@ -1299,7 +1299,7 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 		module_put(owner);
 
 		if (bdev->bd_contains != bdev) {
-			kobject_put(&bdev->bd_part->kobj);
+			kobject_put(&bdev->bd_part->dev.kobj);
 			bdev->bd_part = NULL;
 		}
 		bdev->bd_disk = NULL;

commit 4ba9b9d0ba0a49d91fa6417c7510ee36f48cf957
Author: Christoph Lameter <clameter@sgi.com>
Date:   Tue Oct 16 23:25:51 2007 -0700

    Slab API: remove useless ctor parameter and reorder parameters
    
    Slab constructors currently have a flags parameter that is never used.  And
    the order of the arguments is opposite to other slab functions.  The object
    pointer is placed before the kmem_cache pointer.
    
    Convert
    
            ctor(void *object, struct kmem_cache *s, unsigned long flags)
    
    to
    
            ctor(struct kmem_cache *s, void *object)
    
    throughout the kernel
    
    [akpm@linux-foundation.org: coupla fixes]
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 379a446e243e..993f78c55221 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -465,7 +465,7 @@ static void bdev_destroy_inode(struct inode *inode)
 	kmem_cache_free(bdev_cachep, bdi);
 }
 
-static void init_once(void * foo, struct kmem_cache * cachep, unsigned long flags)
+static void init_once(struct kmem_cache * cachep, void *foo)
 {
 	struct bdev_inode *ei = (struct bdev_inode *) foo;
 	struct block_device *bdev = &ei->bdev;

commit 6272b5a5868f3d5fbf9815f9984891ced343dabc
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Oct 16 01:25:04 2007 -0700

    block_dev: convert to new aops
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 6339a30879b7..379a446e243e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -378,14 +378,26 @@ static int blkdev_readpage(struct file * file, struct page * page)
 	return block_read_full_page(page, blkdev_get_block);
 }
 
-static int blkdev_prepare_write(struct file *file, struct page *page, unsigned from, unsigned to)
+static int blkdev_write_begin(struct file *file, struct address_space *mapping,
+			loff_t pos, unsigned len, unsigned flags,
+			struct page **pagep, void **fsdata)
 {
-	return block_prepare_write(page, from, to, blkdev_get_block);
+	*pagep = NULL;
+	return block_write_begin(file, mapping, pos, len, flags, pagep, fsdata,
+				blkdev_get_block);
 }
 
-static int blkdev_commit_write(struct file *file, struct page *page, unsigned from, unsigned to)
+static int blkdev_write_end(struct file *file, struct address_space *mapping,
+			loff_t pos, unsigned len, unsigned copied,
+			struct page *page, void *fsdata)
 {
-	return block_commit_write(page, from, to);
+	int ret;
+	ret = block_write_end(file, mapping, pos, len, copied, page, fsdata);
+
+	unlock_page(page);
+	page_cache_release(page);
+
+	return ret;
 }
 
 /*
@@ -1327,8 +1339,8 @@ const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
 	.writepage	= blkdev_writepage,
 	.sync_page	= block_sync_page,
-	.prepare_write	= blkdev_prepare_write,
-	.commit_write	= blkdev_commit_write,
+	.write_begin	= blkdev_write_begin,
+	.write_end	= blkdev_write_end,
 	.writepages	= generic_writepages,
 	.direct_IO	= blkdev_direct_IO,
 };

commit 6712ecf8f648118c3363c142196418f89a510b90
Author: NeilBrown <neilb@suse.de>
Date:   Thu Sep 27 12:47:43 2007 +0200

    Drop 'size' argument from bio_endio and bi_end_io
    
    As bi_end_io is only called once when the reqeust is complete,
    the 'size' argument is now redundant.  Remove it.
    
    Now there is no need for bio_endio to subtract the size completed
    from bi_size.  So don't do that either.
    
    While we are at it, change bi_end_io to return void.
    
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2980eabe5779..6339a30879b7 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -172,7 +172,7 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 }
 
 #if 0
-static int blk_end_aio(struct bio *bio, unsigned int bytes_done, int error)
+static void blk_end_aio(struct bio *bio, int error)
 {
 	struct kiocb *iocb = bio->bi_private;
 	atomic_t *bio_count = &iocb->ki_bio_count;

commit 20c2df83d25c6a95affe6157a4c9cac4cf5ffaac
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Jul 20 10:11:58 2007 +0900

    mm: Remove slab destructors from kmem_cache_create().
    
    Slab destructors were no longer supported after Christoph's
    c59def9f222d44bb7e2f0a559f2906191a0862d7 change. They've been
    BUGs for both slab and slub, and slob never supported them
    either.
    
    This rips out support for the dtor pointer from kmem_cache_create()
    completely and fixes up every single callsite in the kernel (there were
    about 224, not including the slab allocator definitions themselves,
    or the documentation references).
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 3635315e3b99..2980eabe5779 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -517,7 +517,7 @@ void __init bdev_cache_init(void)
 	bdev_cachep = kmem_cache_create("bdev_cache", sizeof(struct bdev_inode),
 			0, (SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|
 				SLAB_MEM_SPREAD|SLAB_PANIC),
-			init_once, NULL);
+			init_once);
 	err = register_filesystem(&bd_type);
 	if (err)
 		panic("Cannot register bdev pseudo-fs");

commit 4210df283cc703bc494f450c91b8311bdf7fe5ee
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Sun Jul 15 23:41:28 2007 -0700

    bd_claim_by_disk: fix warning
    
    Fix this:
    
    fs/block_dev.c: In function 'bd_claim_by_disk':
    fs/block_dev.c:970: warning: 'found' may be used uninitialized in this function
    
    and given that free_bd_holder() now needs free(NULL)-is-legal behaviour, we
    can simplify bd_release_from_kobject().
    
    Cc: Bjorn Steinbrink <B.Steinbrink@gmx.de>
    Cc: Johannes Weiner <hannes-kernel@saeurebad.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 75c47a21b2f0..3635315e3b99 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -963,20 +963,20 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 
 	err = bd_claim(bdev, holder);
 	if (err)
-		goto out;
+		goto fail;
 
 	found = find_bd_holder(bdev, bo);
 	if (found)
-		goto out;
+		goto fail;
 
 	err = add_bd_holder(bdev, bo);
 	if (err)
 		bd_release(bdev);
-
-out:
-	if (err || found)
-		free_bd_holder(bo);
+	else
+		bo = NULL;
+fail:
 	mutex_unlock(&bdev->bd_mutex);
+	free_bd_holder(bo);
 	return err;
 }
 
@@ -991,15 +991,12 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 static void bd_release_from_kobject(struct block_device *bdev,
 					struct kobject *kobj)
 {
-	struct bd_holder *bo;
-
 	if (!kobj)
 		return;
 
 	mutex_lock(&bdev->bd_mutex);
 	bd_release(bdev);
-	if ((bo = del_bd_holder(bdev, kobj)))
-		free_bd_holder(bo);
+	free_bd_holder(del_bd_holder(bdev, kobj));
 	mutex_unlock(&bdev->bd_mutex);
 }
 

commit 4e91672c76319aaed24ea3e784e238cf445c57cb
Author: Johannes Weiner <hannes-kernel@saeurebad.de>
Date:   Sun Jul 15 23:41:25 2007 -0700

    Replace obscure constructs in fs/block_dev.c
    
    Replace some funky codepaths in fs/block_dev.c with cleaner versions of the
    affected places.
    
    [akpm@linux-foundation.org: fix return value]
    Signed-off-by: Johannes Weiner <hannes-kernel@saeurebad.de>
    Cc: Bjorn Steinbrink <B.Steinbrink@gmx.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index da5f0515e8eb..75c47a21b2f0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -872,7 +872,7 @@ static struct bd_holder *find_bd_holder(struct block_device *bdev,
  */
 static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
 {
-	int ret;
+	int err;
 
 	if (!bo)
 		return -EINVAL;
@@ -880,15 +880,18 @@ static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
 	if (!bd_holder_grab_dirs(bdev, bo))
 		return -EBUSY;
 
-	ret = add_symlink(bo->sdir, bo->sdev);
-	if (ret == 0) {
-		ret = add_symlink(bo->hdir, bo->hdev);
-		if (ret)
-			del_symlink(bo->sdir, bo->sdev);
+	err = add_symlink(bo->sdir, bo->sdev);
+	if (err)
+		return err;
+
+	err = add_symlink(bo->hdir, bo->hdev);
+	if (err) {
+		del_symlink(bo->sdir, bo->sdev);
+		return err;
 	}
-	if (ret == 0)
-		list_add_tail(&bo->list, &bdev->bd_holder_list);
-	return ret;
+
+	list_add_tail(&bo->list, &bdev->bd_holder_list);
+	return 0;
 }
 
 /**
@@ -946,7 +949,7 @@ static struct bd_holder *del_bd_holder(struct block_device *bdev,
 static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 				struct kobject *kobj)
 {
-	int res;
+	int err;
 	struct bd_holder *bo, *found;
 
 	if (!kobj)
@@ -957,21 +960,24 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 		return -ENOMEM;
 
 	mutex_lock(&bdev->bd_mutex);
-	res = bd_claim(bdev, holder);
-	if (res == 0) {
-		found = find_bd_holder(bdev, bo);
-		if (found == NULL) {
-			res = add_bd_holder(bdev, bo);
-			if (res)
-				bd_release(bdev);
-		}
-	}
 
-	if (res || found)
+	err = bd_claim(bdev, holder);
+	if (err)
+		goto out;
+
+	found = find_bd_holder(bdev, bo);
+	if (found)
+		goto out;
+
+	err = add_bd_holder(bdev, bo);
+	if (err)
+		bd_release(bdev);
+
+out:
+	if (err || found)
 		free_bd_holder(bo);
 	mutex_unlock(&bdev->bd_mutex);
-
-	return res;
+	return err;
 }
 
 /**

commit 203a2935c734c054bfd4665fb5d8835498af50a8
Author: Matthias Kaehlcke <matthias.kaehlcke@gmail.com>
Date:   Sun Jul 15 23:40:23 2007 -0700

    fs/block_dev.c: use list_for_each_entry()
    
    fs/block_dev.c: Use list_for_each_entry() instead of list_for_each()
    in nr_blockdev_pages()
    
    Signed-off-by: Matthias Kaehlcke <matthias.kaehlcke@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b3e9bfa748cf..da5f0515e8eb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -588,12 +588,10 @@ EXPORT_SYMBOL(bdget);
 
 long nr_blockdev_pages(void)
 {
-	struct list_head *p;
+	struct block_device *bdev;
 	long ret = 0;
 	spin_lock(&bdev_lock);
-	list_for_each(p, &all_bdevs) {
-		struct block_device *bdev;
-		bdev = list_entry(p, struct block_device, bd_list);
+	list_for_each_entry(bdev, &all_bdevs, bd_list) {
 		ret += bdev->bd_inode->i_mapping->nrpages;
 	}
 	spin_unlock(&bdev_lock);

commit 5ffc4ef45b3b0a57872f631b4e4ceb8ace0d7496
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 1 11:49:19 2007 +0200

    sendfile: remove .sendfile from filesystems that use generic_file_sendfile()
    
    They can use generic_file_splice_read() instead. Since sys_sendfile() now
    prefers that, there should be no change in behaviour.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index ea1480a16f51..b3e9bfa748cf 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1346,7 +1346,6 @@ const struct file_operations def_blk_fops = {
 #ifdef CONFIG_COMPAT
 	.compat_ioctl	= compat_blkdev_ioctl,
 #endif
-	.sendfile	= generic_file_sendfile,
 	.splice_read	= generic_file_splice_read,
 	.splice_write	= generic_file_splice_write,
 };

commit a35afb830f8d71ec211531aeb9a621b09a2efb39
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed May 16 22:10:57 2007 -0700

    Remove SLAB_CTOR_CONSTRUCTOR
    
    SLAB_CTOR_CONSTRUCTOR is always specified. No point in checking it.
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Jens Axboe <jens.axboe@oracle.com>
    Cc: Steven French <sfrench@us.ibm.com>
    Cc: Michael Halcrow <mhalcrow@us.ibm.com>
    Cc: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Dave Kleikamp <shaggy@austin.ibm.com>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: "J. Bruce Fields" <bfields@fieldses.org>
    Cc: Anton Altaparmakov <aia21@cantab.net>
    Cc: Mark Fasheh <mark.fasheh@oracle.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jan Kara <jack@ucw.cz>
    Cc: David Chinner <dgc@sgi.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 742899240872..ea1480a16f51 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -458,17 +458,15 @@ static void init_once(void * foo, struct kmem_cache * cachep, unsigned long flag
 	struct bdev_inode *ei = (struct bdev_inode *) foo;
 	struct block_device *bdev = &ei->bdev;
 
-	if (flags & SLAB_CTOR_CONSTRUCTOR) {
-		memset(bdev, 0, sizeof(*bdev));
-		mutex_init(&bdev->bd_mutex);
-		sema_init(&bdev->bd_mount_sem, 1);
-		INIT_LIST_HEAD(&bdev->bd_inodes);
-		INIT_LIST_HEAD(&bdev->bd_list);
+	memset(bdev, 0, sizeof(*bdev));
+	mutex_init(&bdev->bd_mutex);
+	sema_init(&bdev->bd_mount_sem, 1);
+	INIT_LIST_HEAD(&bdev->bd_inodes);
+	INIT_LIST_HEAD(&bdev->bd_list);
 #ifdef CONFIG_SYSFS
-		INIT_LIST_HEAD(&bdev->bd_holder_list);
+	INIT_LIST_HEAD(&bdev->bd_holder_list);
 #endif
-		inode_init_once(&ei->vfs_inode);
-	}
+	inode_init_once(&ei->vfs_inode);
 }
 
 static inline void __bd_forget(struct inode *inode)

commit 1368c4f2482c9e06bcb297217433818b171cc9e3
Author: Vignesh Babu BM <vignesh.babu@wipro.com>
Date:   Tue May 8 00:24:32 2007 -0700

    is_power_of_2 in fs/block_dev.c
    
    Replace (n & (n-1)) in the context of power of 2 checks with is_power_of_2
    
    Signed-off-by: vignesh babu <vignesh.babu@wipro.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f02b7bdd9864..742899240872 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -22,6 +22,7 @@
 #include <linux/mount.h>
 #include <linux/uio.h>
 #include <linux/namei.h>
+#include <linux/log2.h>
 #include <asm/uaccess.h>
 #include "internal.h"
 
@@ -67,7 +68,7 @@ static void kill_bdev(struct block_device *bdev)
 int set_blocksize(struct block_device *bdev, int size)
 {
 	/* Size must be a power of two, and between 512 and PAGE_SIZE */
-	if (size > PAGE_SIZE || size < 512 || (size & (size-1)))
+	if (size > PAGE_SIZE || size < 512 || !is_power_of_2(size))
 		return -EINVAL;
 
 	/* Size cannot be smaller than the size supported by the device */

commit 50953fe9e00ebbeffa032a565ab2f08312d51a87
Author: Christoph Lameter <clameter@sgi.com>
Date:   Sun May 6 14:50:16 2007 -0700

    slab allocators: Remove SLAB_DEBUG_INITIAL flag
    
    I have never seen a use of SLAB_DEBUG_INITIAL.  It is only supported by
    SLAB.
    
    I think its purpose was to have a callback after an object has been freed
    to verify that the state is the constructor state again?  The callback is
    performed before each freeing of an object.
    
    I would think that it is much easier to check the object state manually
    before the free.  That also places the check near the code object
    manipulation of the object.
    
    Also the SLAB_DEBUG_INITIAL callback is only performed if the kernel was
    compiled with SLAB debugging on.  If there would be code in a constructor
    handling SLAB_DEBUG_INITIAL then it would have to be conditional on
    SLAB_DEBUG otherwise it would just be dead code.  But there is no such code
    in the kernel.  I think SLUB_DEBUG_INITIAL is too problematic to make real
    use of, difficult to understand and there are easier ways to accomplish the
    same effect (i.e.  add debug code before kfree).
    
    There is a related flag SLAB_CTOR_VERIFY that is frequently checked to be
    clear in fs inode caches.  Remove the pointless checks (they would even be
    pointless without removeal of SLAB_DEBUG_INITIAL) from the fs constructors.
    
    This is the last slab flag that SLUB did not support.  Remove the check for
    unimplemented flags from SLUB.
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 6fe49b9349ea..f02b7bdd9864 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -457,9 +457,7 @@ static void init_once(void * foo, struct kmem_cache * cachep, unsigned long flag
 	struct bdev_inode *ei = (struct bdev_inode *) foo;
 	struct block_device *bdev = &ei->bdev;
 
-	if ((flags & (SLAB_CTOR_VERIFY|SLAB_CTOR_CONSTRUCTOR)) ==
-	    SLAB_CTOR_CONSTRUCTOR)
-	{
+	if (flags & SLAB_CTOR_CONSTRUCTOR) {
 		memset(bdev, 0, sizeof(*bdev));
 		mutex_init(&bdev->bd_mutex);
 		sema_init(&bdev->bd_mount_sem, 1);

commit f9a14399aea13830d8af6798a53207bb0a900945
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Sun May 6 14:49:55 2007 -0700

    mm: optimize kill_bdev()
    
    Remove duplicate work in kill_bdev().
    
    It currently invalidates and then truncates the bdev's mapping.
    invalidate_mapping_pages() will opportunistically remove pages from the
    mapping.  And truncate_inode_pages() will forcefully remove all pages.
    
    The only thing truncate doesn't do is flush the bh lrus.  So do that
    explicitly.  This avoids (very unlikely) but possible invalid lookup
    results if the same bdev is quickly re-issued.
    
    It also will prevent extreme kernel latencies which are observed when
    blockdevs which have a large amount of pagecache are unmounted, by avoiding
    invalidate_mapping_pages() on that path.  invalidate_mapping_pages() has no
    cond_resched (it can be called under spinlock), whereas truncate_inode_pages()
    has one.
    
    [akpm@linux-foundation.org: restore nrpages==0 optimisation]
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 21e59acbcfdf..6fe49b9349ea 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -55,10 +55,12 @@ static sector_t max_block(struct block_device *bdev)
 	return retval;
 }
 
-/* Kill _all_ buffers, dirty or not.. */
+/* Kill _all_ buffers and pagecache , dirty or not.. */
 static void kill_bdev(struct block_device *bdev)
 {
-	invalidate_bdev(bdev);
+	if (bdev->bd_inode->i_mapping->nrpages == 0)
+		return;
+	invalidate_bh_lrus();
 	truncate_inode_pages(bdev->bd_inode->i_mapping, 0);
 }	
 

commit f98393a64ca1392130724c3acb4e3f325801d2b6
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Sun May 6 14:49:54 2007 -0700

    mm: remove destroy_dirty_buffers from invalidate_bdev()
    
    Remove the destroy_dirty_buffers argument from invalidate_bdev(), it hasn't
    been used in 6 years (so akpm says).
    
    find * -name \*.[ch] | xargs grep -l invalidate_bdev |
    while read file; do
            quilt add $file;
            sed -ie 's/invalidate_bdev(\([^,]*\),[^)]*)/invalidate_bdev(\1)/g' $file;
    done
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 575076c018f4..21e59acbcfdf 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -58,7 +58,7 @@ static sector_t max_block(struct block_device *bdev)
 /* Kill _all_ buffers, dirty or not.. */
 static void kill_bdev(struct block_device *bdev)
 {
-	invalidate_bdev(bdev, 1);
+	invalidate_bdev(bdev);
 	truncate_inode_pages(bdev->bd_inode->i_mapping, 0);
 }	
 
@@ -1478,7 +1478,7 @@ int __invalidate_device(struct block_device *bdev)
 		res = invalidate_inodes(sb);
 		drop_super(sb);
 	}
-	invalidate_bdev(bdev, 0);
+	invalidate_bdev(bdev);
 	return res;
 }
 EXPORT_SYMBOL(__invalidate_device);

commit 6d740cd5b18bc8128e70f98cfde8c74ebd21cea1
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue Feb 20 13:58:18 2007 -0800

    [PATCH] lockdep: annotate BLKPG_DEL_PARTITION
    
    >=============================================
    >[ INFO: possible recursive locking detected ]
    >2.6.19-1.2909.fc7 #1
    >---------------------------------------------
    >anaconda/587 is trying to acquire lock:
    > (&bdev->bd_mutex){--..}, at: [<c05fb380>] mutex_lock+0x21/0x24
    >
    >but task is already holding lock:
    > (&bdev->bd_mutex){--..}, at: [<c05fb380>] mutex_lock+0x21/0x24
    >
    >other info that might help us debug this:
    >1 lock held by anaconda/587:
    > #0:  (&bdev->bd_mutex){--..}, at: [<c05fb380>] mutex_lock+0x21/0x24
    >
    >stack backtrace:
    > [<c0405812>] show_trace_log_lvl+0x1a/0x2f
    > [<c0405db2>] show_trace+0x12/0x14
    > [<c0405e36>] dump_stack+0x16/0x18
    > [<c043bd84>] __lock_acquire+0x116/0xa09
    > [<c043c960>] lock_acquire+0x56/0x6f
    > [<c05fb1fa>] __mutex_lock_slowpath+0xe5/0x24a
    > [<c05fb380>] mutex_lock+0x21/0x24
    > [<c04d82fb>] blkdev_ioctl+0x600/0x76d
    > [<c04946b1>] block_ioctl+0x1b/0x1f
    > [<c047ed5a>] do_ioctl+0x22/0x68
    > [<c047eff2>] vfs_ioctl+0x252/0x265
    > [<c047f04e>] sys_ioctl+0x49/0x63
    > [<c0404070>] syscall_call+0x7/0xb
    
    Annotate BLKPG_DEL_PARTITION's bd_mutex locking and add a little comment
    clarifying the bd_mutex locking, because I confused myself and initially
    thought the lock order was wrong too.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0c59b703e9d5..575076c018f4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1101,6 +1101,13 @@ static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
 			int for_part);
 static int __blkdev_put(struct block_device *bdev, int for_part);
 
+/*
+ * bd_mutex locking:
+ *
+ *  mutex_lock(part->bd_mutex)
+ *    mutex_lock_nested(whole->bd_mutex, 1)
+ */
+
 static int do_open(struct block_device *bdev, struct file *file, int for_part)
 {
 	struct module *owner = NULL;

commit ee9b6d61a2a43c5952eb43283f8db284a4e70b8a
Author: Josef 'Jeff' Sipek <jsipek@cs.sunysb.edu>
Date:   Mon Feb 12 00:55:41 2007 -0800

    [PATCH] Mark struct super_operations const
    
    This patch is inspired by Arjan's "Patch series to mark struct
    file_operations and struct inode_operations const".
    
    Compile tested with gcc & sparse.
    
    Signed-off-by: Josef 'Jeff' Sipek <jsipek@cs.sunysb.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index fc7028b685f2..0c59b703e9d5 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -489,7 +489,7 @@ static void bdev_clear_inode(struct inode *inode)
 	spin_unlock(&bdev_lock);
 }
 
-static struct super_operations bdev_sops = {
+static const struct super_operations bdev_sops = {
 	.statfs = simple_statfs,
 	.alloc_inode = bdev_alloc_inode,
 	.destroy_inode = bdev_destroy_inode,

commit b2e895dbd80c420bfc0937c3729b4afe073b3848
Author: Andrew Morton <akpm@osdl.org>
Date:   Sat Feb 3 01:14:01 2007 -0800

    [PATCH] revert blockdev direct io back to 2.6.19 version
    
    Andrew Vasquez is reporting as-iosched oopses and a 65% throughput
    slowdown due to the recent special-casing of direct-io against
    blockdevs.  We don't know why either of these things are occurring.
    
    The patch minimally reverts us back to the 2.6.19 code for a 2.6.20
    release.
    
    Cc: Andrew Vasquez <andrew.vasquez@qlogic.com>
    Cc: Ken Chen <kenchen@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d9bdf2b3ade2..fc7028b685f2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -129,6 +129,46 @@ blkdev_get_block(struct inode *inode, sector_t iblock,
 	return 0;
 }
 
+static int
+blkdev_get_blocks(struct inode *inode, sector_t iblock,
+		struct buffer_head *bh, int create)
+{
+	sector_t end_block = max_block(I_BDEV(inode));
+	unsigned long max_blocks = bh->b_size >> inode->i_blkbits;
+
+	if ((iblock + max_blocks) > end_block) {
+		max_blocks = end_block - iblock;
+		if ((long)max_blocks <= 0) {
+			if (create)
+				return -EIO;	/* write fully beyond EOF */
+			/*
+			 * It is a read which is fully beyond EOF.  We return
+			 * a !buffer_mapped buffer
+			 */
+			max_blocks = 0;
+		}
+	}
+
+	bh->b_bdev = I_BDEV(inode);
+	bh->b_blocknr = iblock;
+	bh->b_size = max_blocks << inode->i_blkbits;
+	if (max_blocks)
+		set_buffer_mapped(bh);
+	return 0;
+}
+
+static ssize_t
+blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
+			loff_t offset, unsigned long nr_segs)
+{
+	struct file *file = iocb->ki_filp;
+	struct inode *inode = file->f_mapping->host;
+
+	return blockdev_direct_IO_no_locking(rw, iocb, inode, I_BDEV(inode),
+				iov, offset, nr_segs, blkdev_get_blocks, NULL);
+}
+
+#if 0
 static int blk_end_aio(struct bio *bio, unsigned int bytes_done, int error)
 {
 	struct kiocb *iocb = bio->bi_private;
@@ -323,6 +363,7 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 		return PTR_ERR(page);
 	goto completion;
 }
+#endif
 
 static int blkdev_writepage(struct page *page, struct writeback_control *wbc)
 {

commit cda9205da24aeaa8fb086b0fb85cdf39571ecc3f
Author: Chen, Kenneth W <kenneth.w.chen@intel.com>
Date:   Mon Jan 22 20:40:43 2007 -0800

    [PATCH] fix blk_direct_IO bio preparation
    
    For large size DIO that needs multiple bio, one full page worth of data was
    lost at the boundary of bio's maximum sector or segment limits.  After a
    bio is full and got submitted.  The outer while (nbytes) { ...  } loop will
    allocate a new bio and just march on to index into next page.  It just
    forgets about the page that bio_add_page() rejected when previous bio is
    full.  Fix it by put the rejected page back to pvec so we pick it up again
    for the next bio.
    
    Signed-off-by: Ken Chen <kenneth.w.chen@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index da020be25dd2..d9bdf2b3ade2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -190,6 +190,12 @@ static struct page *blk_get_page(unsigned long addr, size_t count, int rw,
 	return pvec->page[pvec->idx++];
 }
 
+/* return a page back to pvec array */
+static void blk_unget_page(struct page *page, struct pvec *pvec)
+{
+	pvec->page[--pvec->idx] = page;
+}
+
 static ssize_t
 blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 		 loff_t pos, unsigned long nr_segs)
@@ -278,6 +284,8 @@ blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 				count = min(count, nbytes);
 				goto same_bio;
 			}
+		} else {
+			blk_unget_page(page, &pvec);
 		}
 
 		/* bio is ready, submit it */

commit 790816dd54e22827f63c8cbb30bd623d3d45e594
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Jan 22 20:40:35 2007 -0800

    [PATCH] blockdev direct_io: fix signedness bug
    
    size_t is unsigned.  IO errors aren't getting through.
    
    Cc: "Chen, Kenneth W" <kenneth.w.chen@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8b18e43b82fe..da020be25dd2 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -146,7 +146,7 @@ static int blk_end_aio(struct bio *bio, unsigned int bytes_done, int error)
 		iocb->ki_nbytes = -EIO;
 
 	if (atomic_dec_and_test(bio_count)) {
-		if (iocb->ki_nbytes < 0)
+		if ((long)iocb->ki_nbytes < 0)
 			aio_complete(iocb, iocb->ki_nbytes, 0);
 		else
 			aio_complete(iocb, iocb->ki_left, 0);

commit f73ca1b76c6880b934d3ef566c1592efc80bb759
Author: David Chinner <dgc@sgi.com>
Date:   Wed Jan 10 23:15:41 2007 -0800

    [PATCH] Revert bd_mount_mutex back to a semaphore
    
    Revert bd_mount_mutex back to a semaphore so that xfs_freeze -f /mnt/newtest;
    xfs_freeze -u /mnt/newtest works safely and doesn't produce lockdep warnings.
    
    (XFS unlocks the semaphore from a different task, by design.  The mutex
    code warns about this)
    
    Signed-off-by: Dave Chinner <dgc@sgi.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 1715d6b5f411..8b18e43b82fe 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -411,7 +411,7 @@ static void init_once(void * foo, struct kmem_cache * cachep, unsigned long flag
 	{
 		memset(bdev, 0, sizeof(*bdev));
 		mutex_init(&bdev->bd_mutex);
-		mutex_init(&bdev->bd_mount_mutex);
+		sema_init(&bdev->bd_mount_sem, 1);
 		INIT_LIST_HEAD(&bdev->bd_inodes);
 		INIT_LIST_HEAD(&bdev->bd_list);
 #ifdef CONFIG_SYSFS

commit e61c90188b9956edae1105eef361d8981a352fcd
Author: Chen, Kenneth W <kenneth.w.chen@intel.com>
Date:   Wed Dec 13 00:34:36 2006 -0800

    [PATCH] optimize o_direct on block devices
    
    Implement block device specific .direct_IO method instead of going through
    generic direct_io_worker for block device.
    
    direct_io_worker() is fairly complex because it needs to handle O_DIRECT on
    file system, where it needs to perform block allocation, hole detection,
    extents file on write, and tons of other corner cases.  The end result is
    that it takes tons of CPU time to submit an I/O.
    
    For block device, the block allocation is much simpler and a tight triple
    loop can be written to iterate each iovec and each page within the iovec in
    order to construct/prepare bio structure and then subsequently submit it to
    the block layer.  This significantly speeds up O_D on block device.
    
    [akpm@osdl.org: small speedup]
    Signed-off-by: Ken Chen <kenneth.w.chen@intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Zach Brown <zach.brown@oracle.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 197f93921847..1715d6b5f411 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -129,43 +129,191 @@ blkdev_get_block(struct inode *inode, sector_t iblock,
 	return 0;
 }
 
-static int
-blkdev_get_blocks(struct inode *inode, sector_t iblock,
-		struct buffer_head *bh, int create)
+static int blk_end_aio(struct bio *bio, unsigned int bytes_done, int error)
 {
-	sector_t end_block = max_block(I_BDEV(inode));
-	unsigned long max_blocks = bh->b_size >> inode->i_blkbits;
+	struct kiocb *iocb = bio->bi_private;
+	atomic_t *bio_count = &iocb->ki_bio_count;
 
-	if ((iblock + max_blocks) > end_block) {
-		max_blocks = end_block - iblock;
-		if ((long)max_blocks <= 0) {
-			if (create)
-				return -EIO;	/* write fully beyond EOF */
-			/*
-			 * It is a read which is fully beyond EOF.  We return
-			 * a !buffer_mapped buffer
-			 */
-			max_blocks = 0;
-		}
+	if (bio_data_dir(bio) == READ)
+		bio_check_pages_dirty(bio);
+	else {
+		bio_release_pages(bio);
+		bio_put(bio);
+	}
+
+	/* iocb->ki_nbytes stores error code from LLDD */
+	if (error)
+		iocb->ki_nbytes = -EIO;
+
+	if (atomic_dec_and_test(bio_count)) {
+		if (iocb->ki_nbytes < 0)
+			aio_complete(iocb, iocb->ki_nbytes, 0);
+		else
+			aio_complete(iocb, iocb->ki_left, 0);
 	}
 
-	bh->b_bdev = I_BDEV(inode);
-	bh->b_blocknr = iblock;
-	bh->b_size = max_blocks << inode->i_blkbits;
-	if (max_blocks)
-		set_buffer_mapped(bh);
 	return 0;
 }
 
+#define VEC_SIZE	16
+struct pvec {
+	unsigned short nr;
+	unsigned short idx;
+	struct page *page[VEC_SIZE];
+};
+
+#define PAGES_SPANNED(addr, len)	\
+	(DIV_ROUND_UP((addr) + (len), PAGE_SIZE) - (addr) / PAGE_SIZE);
+
+/*
+ * get page pointer for user addr, we internally cache struct page array for
+ * (addr, count) range in pvec to avoid frequent call to get_user_pages.  If
+ * internal page list is exhausted, a batch count of up to VEC_SIZE is used
+ * to get next set of page struct.
+ */
+static struct page *blk_get_page(unsigned long addr, size_t count, int rw,
+				 struct pvec *pvec)
+{
+	int ret, nr_pages;
+	if (pvec->idx == pvec->nr) {
+		nr_pages = PAGES_SPANNED(addr, count);
+		nr_pages = min(nr_pages, VEC_SIZE);
+		down_read(&current->mm->mmap_sem);
+		ret = get_user_pages(current, current->mm, addr, nr_pages,
+				     rw == READ, 0, pvec->page, NULL);
+		up_read(&current->mm->mmap_sem);
+		if (ret < 0)
+			return ERR_PTR(ret);
+		pvec->nr = ret;
+		pvec->idx = 0;
+	}
+	return pvec->page[pvec->idx++];
+}
+
 static ssize_t
 blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
-			loff_t offset, unsigned long nr_segs)
-{
-	struct file *file = iocb->ki_filp;
-	struct inode *inode = file->f_mapping->host;
+		 loff_t pos, unsigned long nr_segs)
+{
+	struct inode *inode = iocb->ki_filp->f_mapping->host;
+	unsigned blkbits = blksize_bits(bdev_hardsect_size(I_BDEV(inode)));
+	unsigned blocksize_mask = (1 << blkbits) - 1;
+	unsigned long seg = 0;	/* iov segment iterator */
+	unsigned long nvec;	/* number of bio vec needed */
+	unsigned long cur_off;	/* offset into current page */
+	unsigned long cur_len;	/* I/O len of current page, up to PAGE_SIZE */
+
+	unsigned long addr;	/* user iovec address */
+	size_t count;		/* user iovec len */
+	size_t nbytes = iocb->ki_nbytes = iocb->ki_left; /* total xfer size */
+	loff_t size;		/* size of block device */
+	struct bio *bio;
+	atomic_t *bio_count = &iocb->ki_bio_count;
+	struct page *page;
+	struct pvec pvec;
+
+	pvec.nr = 0;
+	pvec.idx = 0;
+
+	if (pos & blocksize_mask)
+		return -EINVAL;
+
+	size = i_size_read(inode);
+	if (pos + nbytes > size) {
+		nbytes = size - pos;
+		iocb->ki_left = nbytes;
+	}
+
+	/*
+	 * check first non-zero iov alignment, the remaining
+	 * iov alignment is checked inside bio loop below.
+	 */
+	do {
+		addr = (unsigned long) iov[seg].iov_base;
+		count = min(iov[seg].iov_len, nbytes);
+		if (addr & blocksize_mask || count & blocksize_mask)
+			return -EINVAL;
+	} while (!count && ++seg < nr_segs);
+	atomic_set(bio_count, 1);
+
+	while (nbytes) {
+		/* roughly estimate number of bio vec needed */
+		nvec = (nbytes + PAGE_SIZE - 1) / PAGE_SIZE;
+		nvec = max(nvec, nr_segs - seg);
+		nvec = min(nvec, (unsigned long) BIO_MAX_PAGES);
+
+		/* bio_alloc should not fail with GFP_KERNEL flag */
+		bio = bio_alloc(GFP_KERNEL, nvec);
+		bio->bi_bdev = I_BDEV(inode);
+		bio->bi_end_io = blk_end_aio;
+		bio->bi_private = iocb;
+		bio->bi_sector = pos >> blkbits;
+same_bio:
+		cur_off = addr & ~PAGE_MASK;
+		cur_len = PAGE_SIZE - cur_off;
+		if (count < cur_len)
+			cur_len = count;
+
+		page = blk_get_page(addr, count, rw, &pvec);
+		if (unlikely(IS_ERR(page)))
+			goto backout;
+
+		if (bio_add_page(bio, page, cur_len, cur_off)) {
+			pos += cur_len;
+			addr += cur_len;
+			count -= cur_len;
+			nbytes -= cur_len;
+
+			if (count)
+				goto same_bio;
+			while (++seg < nr_segs) {
+				addr = (unsigned long) iov[seg].iov_base;
+				count = iov[seg].iov_len;
+				if (!count)
+					continue;
+				if (unlikely(addr & blocksize_mask ||
+					     count & blocksize_mask)) {
+					page = ERR_PTR(-EINVAL);
+					goto backout;
+				}
+				count = min(count, nbytes);
+				goto same_bio;
+			}
+		}
 
-	return blockdev_direct_IO_no_locking(rw, iocb, inode, I_BDEV(inode),
-				iov, offset, nr_segs, blkdev_get_blocks, NULL);
+		/* bio is ready, submit it */
+		if (rw == READ)
+			bio_set_pages_dirty(bio);
+		atomic_inc(bio_count);
+		submit_bio(rw, bio);
+	}
+
+completion:
+	iocb->ki_left -= nbytes;
+	nbytes = iocb->ki_left;
+	iocb->ki_pos += nbytes;
+
+	blk_run_address_space(inode->i_mapping);
+	if (atomic_dec_and_test(bio_count))
+		aio_complete(iocb, nbytes, 0);
+
+	return -EIOCBQUEUED;
+
+backout:
+	/*
+	 * back out nbytes count constructed so far for this bio,
+	 * we will throw away current bio.
+	 */
+	nbytes += bio->bi_size;
+	bio_release_pages(bio);
+	bio_put(bio);
+
+	/*
+	 * if no bio was submmitted, return the error code.
+	 * otherwise, proceed with pending I/O completion.
+	 */
+	if (atomic_read(bio_count) == 1)
+		return PTR_ERR(page);
+	goto completion;
 }
 
 static int blkdev_writepage(struct page *page, struct writeback_control *wbc)

commit 0f7fc9e4d03987fe29f6dd4aa67e4c56eb7ecb05
Author: Josef "Jeff" Sipek <jsipek@cs.sunysb.edu>
Date:   Fri Dec 8 02:36:35 2006 -0800

    [PATCH] VFS: change struct file to use struct path
    
    This patch changes struct file to use struct path instead of having
    independent pointers to struct dentry and struct vfsmount, and converts all
    users of f_{dentry,vfsmnt} in fs/ to use f_path.{dentry,mnt}.
    
    Additionally, it adds two #define's to make the transition easier for users of
    the f_dentry and f_vfsmnt.
    
    Signed-off-by: Josef "Jeff" Sipek <jsipek@cs.sunysb.edu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f3c3a44dd8b6..197f93921847 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -190,7 +190,7 @@ static int blkdev_commit_write(struct file *file, struct page *page, unsigned fr
 
 /*
  * private llseek:
- * for a block special file file->f_dentry->d_inode->i_size is zero
+ * for a block special file file->f_path.dentry->d_inode->i_size is zero
  * so we compute the size by hand (just as in block_read/write above)
  */
 static loff_t block_llseek(struct file *file, loff_t offset, int origin)
@@ -1013,7 +1013,7 @@ static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
 	struct dentry fake_dentry = {};
 	fake_file.f_mode = mode;
 	fake_file.f_flags = flags;
-	fake_file.f_dentry = &fake_dentry;
+	fake_file.f_path.dentry = &fake_dentry;
 	fake_dentry.d_inode = bdev->bd_inode;
 
 	return do_open(bdev, &fake_file, for_part);

commit c48f70c3d046f021b1c22438604ef2a583380eca
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Fri Dec 8 02:36:18 2006 -0800

    [PATCH] bdev: fix ->bd_part_count leak
    
    Don't leak a ->bd_part_count when the partition open fails with -ENXIO.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 846f32d51be7..f3c3a44dd8b6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -902,6 +902,7 @@ EXPORT_SYMBOL(bd_set_size);
 
 static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
 			int for_part);
+static int __blkdev_put(struct block_device *bdev, int for_part);
 
 static int do_open(struct block_device *bdev, struct file *file, int for_part)
 {
@@ -987,7 +988,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	bdev->bd_disk = NULL;
 	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
 	if (bdev != bdev->bd_contains)
-		blkdev_put(bdev->bd_contains);
+		__blkdev_put(bdev->bd_contains, 1);
 	bdev->bd_contains = NULL;
 	put_disk(disk);
 	module_put(owner);

commit 6796bf54a64df36f96a42ae222423fffe36c58a5
Author: NeilBrown <neilb@suse.de>
Date:   Fri Dec 8 02:36:16 2006 -0800

    [PATCH] lockdep: use mutex_lock_nested for bd_mutex to avoid lockdep warning
    
    Now that the nesting in blkdev_{get,put} is simpler, adding mutex_lock_nested
    is trivial.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 19f5f153ddb8..846f32d51be7 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -920,7 +920,7 @@ static int do_open(struct block_device *bdev, struct file *file, int for_part)
 	}
 	owner = disk->fops->owner;
 
-	mutex_lock(&bdev->bd_mutex);
+	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
 		bdev->bd_contains = bdev;
@@ -1062,7 +1062,7 @@ static int __blkdev_put(struct block_device *bdev, int for_part)
 	struct gendisk *disk = bdev->bd_disk;
 	struct block_device *victim = NULL;
 
-	mutex_lock(&bdev->bd_mutex);
+	mutex_lock_nested(&bdev->bd_mutex, for_part);
 	lock_kernel();
 	if (for_part)
 		bdev->bd_part_count--;

commit 37be41241f43109c55d92cdbf303399eea642f14
Author: NeilBrown <neilb@suse.de>
Date:   Fri Dec 8 02:36:16 2006 -0800

    [PATCH] lockdep: simplify some aspects of bd_mutex nesting
    
    When we open (actually blkdev_get) a partition we need to also open (get) the
    whole device that holds the partition.  The involves some limited recursion.
    This patch tries to simplify some aspects of this.
    
    As well as opening the whole device, we need to increment ->bd_part_count when
    a partition is opened (this is used by rescan_partitions to avoid a rescan if
    any partition is active, as that would be confusing).
    
    The main change this patch makes is to move the inc/dec of bd_part_count into
    blkdev_{get,put} for the whole rather than doing it in blkdev_{get,put} for
    the partition.
    
    More specifically, we introduce __blkdev_get and __blkdev_put which do exactly
    what blkdev_{get,put} did, only with an extra "for_part" argument
    (blkget_{get,put} then call the __ version with a '0' for the extra argument).
    
    If for_part is 1, then the blkdev is being get(put) because a partition is
    being opened(closed) for the first(last) time, and so bd_part_count should be
    updated (on success).  The particular advantage of pushing this function down
    is that the bd_mutex lock (which is needed to update bd_part_count) is already
    held at the lower level.
    
    Note that this slightly changes the semantics of bd_part_count.  Instead of
    updating it whenever a partition is opened or released, it is now only updated
    on the first open or last release.  This is an adequate semantic as it is only
    ever tested for "== 0".
    
    Having introduced these functions we remove the current bd_part_count updates
    from do_open (which is really the body of blkdev_get) and call
    __blkdev_get(...  1).  Similarly in blkget_put we remove the old bd_part_count
    updates and call __blkget_put(..., 1).  This call is moved to the end of
    __blkdev_put to avoid nested locks of bd_mutex.
    
    Finally the mutex_lock on whole->bd_mutex in do_open can be removed.  It was
    only really needed to protect bd_part_count, and that is now managed (and
    protected) within the recursive call.
    
    The observation that bd_part_count is central to the locking issues, and the
    modifications to create __blkdev_put are from Peter Zijlstra.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 36c38f48a4ed..19f5f153ddb8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -900,7 +900,10 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
-static int do_open(struct block_device *bdev, struct file *file)
+static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
+			int for_part);
+
+static int do_open(struct block_device *bdev, struct file *file, int for_part)
 {
 	struct module *owner = NULL;
 	struct gendisk *disk;
@@ -944,25 +947,21 @@ static int do_open(struct block_device *bdev, struct file *file)
 			ret = -ENOMEM;
 			if (!whole)
 				goto out_first;
-			ret = blkdev_get(whole, file->f_mode, file->f_flags);
+			BUG_ON(for_part);
+			ret = __blkdev_get(whole, file->f_mode, file->f_flags, 1);
 			if (ret)
 				goto out_first;
 			bdev->bd_contains = whole;
-			mutex_lock(&whole->bd_mutex);
-			whole->bd_part_count++;
 			p = disk->part[part - 1];
 			bdev->bd_inode->i_data.backing_dev_info =
 			   whole->bd_inode->i_data.backing_dev_info;
 			if (!(disk->flags & GENHD_FL_UP) || !p || !p->nr_sects) {
-				whole->bd_part_count--;
-				mutex_unlock(&whole->bd_mutex);
 				ret = -ENXIO;
 				goto out_first;
 			}
 			kobject_get(&p->kobj);
 			bdev->bd_part = p;
 			bd_set_size(bdev, (loff_t) p->nr_sects << 9);
-			mutex_unlock(&whole->bd_mutex);
 		}
 	} else {
 		put_disk(disk);
@@ -975,13 +974,11 @@ static int do_open(struct block_device *bdev, struct file *file)
 			}
 			if (bdev->bd_invalidated)
 				rescan_partitions(bdev->bd_disk, bdev);
-		} else {
-			mutex_lock(&bdev->bd_contains->bd_mutex);
-			bdev->bd_contains->bd_part_count++;
-			mutex_unlock(&bdev->bd_contains->bd_mutex);
 		}
 	}
 	bdev->bd_openers++;
+	if (for_part)
+		bdev->bd_part_count++;
 	mutex_unlock(&bdev->bd_mutex);
 	unlock_kernel();
 	return 0;
@@ -1002,7 +999,8 @@ static int do_open(struct block_device *bdev, struct file *file)
 	return ret;
 }
 
-int blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags)
+static int __blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags,
+			int for_part)
 {
 	/*
 	 * This crockload is due to bad choice of ->open() type.
@@ -1017,9 +1015,13 @@ int blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags)
 	fake_file.f_dentry = &fake_dentry;
 	fake_dentry.d_inode = bdev->bd_inode;
 
-	return do_open(bdev, &fake_file);
+	return do_open(bdev, &fake_file, for_part);
 }
 
+int blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags)
+{
+	return __blkdev_get(bdev, mode, flags, 0);
+}
 EXPORT_SYMBOL(blkdev_get);
 
 static int blkdev_open(struct inode * inode, struct file * filp)
@@ -1039,7 +1041,7 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	if (bdev == NULL)
 		return -ENOMEM;
 
-	res = do_open(bdev, filp);
+	res = do_open(bdev, filp, 0);
 	if (res)
 		return res;
 
@@ -1053,14 +1055,18 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	return res;
 }
 
-int blkdev_put(struct block_device *bdev)
+static int __blkdev_put(struct block_device *bdev, int for_part)
 {
 	int ret = 0;
 	struct inode *bd_inode = bdev->bd_inode;
 	struct gendisk *disk = bdev->bd_disk;
+	struct block_device *victim = NULL;
 
 	mutex_lock(&bdev->bd_mutex);
 	lock_kernel();
+	if (for_part)
+		bdev->bd_part_count--;
+
 	if (!--bdev->bd_openers) {
 		sync_blockdev(bdev);
 		kill_bdev(bdev);
@@ -1068,10 +1074,6 @@ int blkdev_put(struct block_device *bdev)
 	if (bdev->bd_contains == bdev) {
 		if (disk->fops->release)
 			ret = disk->fops->release(bd_inode, NULL);
-	} else {
-		mutex_lock(&bdev->bd_contains->bd_mutex);
-		bdev->bd_contains->bd_part_count--;
-		mutex_unlock(&bdev->bd_contains->bd_mutex);
 	}
 	if (!bdev->bd_openers) {
 		struct module *owner = disk->fops->owner;
@@ -1085,17 +1087,22 @@ int blkdev_put(struct block_device *bdev)
 		}
 		bdev->bd_disk = NULL;
 		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
-		if (bdev != bdev->bd_contains) {
-			blkdev_put(bdev->bd_contains);
-		}
+		if (bdev != bdev->bd_contains)
+			victim = bdev->bd_contains;
 		bdev->bd_contains = NULL;
 	}
 	unlock_kernel();
 	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);
+	if (victim)
+		__blkdev_put(victim, 1);
 	return ret;
 }
 
+int blkdev_put(struct block_device *bdev)
+{
+	return __blkdev_put(bdev, 0);
+}
 EXPORT_SYMBOL(blkdev_put);
 
 static int blkdev_close(struct inode * inode, struct file * filp)

commit fd27c7a1bfa9801544ca961cdb4ca0b4998580b8
Author: NeilBrown <neilb@suse.de>
Date:   Fri Dec 8 02:36:14 2006 -0800

    [PATCH] lockdep: remove lock_key approach to managing nested bd_mutex locks
    
    The extra call to get_gendisk is not good.  It causes a ->probe and possible
    module load before it is really appropriate to do this.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 528cf053ce96..36c38f48a4ed 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -355,14 +355,10 @@ static int bdev_set(struct inode *inode, void *data)
 
 static LIST_HEAD(all_bdevs);
 
-static struct lock_class_key bdev_part_lock_key;
-
 struct block_device *bdget(dev_t dev)
 {
 	struct block_device *bdev;
 	struct inode *inode;
-	struct gendisk *disk;
-	int part = 0;
 
 	inode = iget5_locked(bd_mnt->mnt_sb, hash(dev),
 			bdev_test, bdev_set, &dev);
@@ -388,11 +384,6 @@ struct block_device *bdget(dev_t dev)
 		list_add(&bdev->bd_list, &all_bdevs);
 		spin_unlock(&bdev_lock);
 		unlock_new_inode(inode);
-		mutex_init(&bdev->bd_mutex);
-		disk = get_gendisk(dev, &part);
-		if (part)
-			lockdep_set_class(&bdev->bd_mutex, &bdev_part_lock_key);
-		put_disk(disk);
 	}
 	return bdev;
 }

commit 35a6027f1ab6594068cb8bca7705e4567753946b
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Fri Dec 8 02:36:14 2006 -0800

    [PATCH] new bd_mutex lockdep annotation
    
    Use the gendisk partition number to set a lock class.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Jason Baron <jbaron@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 36c38f48a4ed..528cf053ce96 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -355,10 +355,14 @@ static int bdev_set(struct inode *inode, void *data)
 
 static LIST_HEAD(all_bdevs);
 
+static struct lock_class_key bdev_part_lock_key;
+
 struct block_device *bdget(dev_t dev)
 {
 	struct block_device *bdev;
 	struct inode *inode;
+	struct gendisk *disk;
+	int part = 0;
 
 	inode = iget5_locked(bd_mnt->mnt_sb, hash(dev),
 			bdev_test, bdev_set, &dev);
@@ -384,6 +388,11 @@ struct block_device *bdget(dev_t dev)
 		list_add(&bdev->bd_list, &all_bdevs);
 		spin_unlock(&bdev_lock);
 		unlock_new_inode(inode);
+		mutex_init(&bdev->bd_mutex);
+		disk = get_gendisk(dev, &part);
+		if (part)
+			lockdep_set_class(&bdev->bd_mutex, &bdev_part_lock_key);
+		put_disk(disk);
 	}
 	return bdev;
 }

commit 2e7b651df113c8a463853e4169951c52c39f9d19
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Fri Dec 8 02:36:13 2006 -0800

    [PATCH] remove the old bd_mutex lockdep annotation
    
    Remove the old complex and crufty bd_mutex annotation.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Jason Baron <jbaron@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 13816b4d76f6..36c38f48a4ed 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -762,7 +762,7 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 	if (!bo)
 		return -ENOMEM;
 
-	mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_PARTITION);
+	mutex_lock(&bdev->bd_mutex);
 	res = bd_claim(bdev, holder);
 	if (res == 0) {
 		found = find_bd_holder(bdev, bo);
@@ -796,7 +796,7 @@ static void bd_release_from_kobject(struct block_device *bdev,
 	if (!kobj)
 		return;
 
-	mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_PARTITION);
+	mutex_lock(&bdev->bd_mutex);
 	bd_release(bdev);
 	if ((bo = del_bd_holder(bdev, kobj)))
 		free_bd_holder(bo);
@@ -854,22 +854,6 @@ struct block_device *open_by_devnum(dev_t dev, unsigned mode)
 
 EXPORT_SYMBOL(open_by_devnum);
 
-static int
-blkdev_get_partition(struct block_device *bdev, mode_t mode, unsigned flags);
-
-struct block_device *open_partition_by_devnum(dev_t dev, unsigned mode)
-{
-	struct block_device *bdev = bdget(dev);
-	int err = -ENOMEM;
-	int flags = mode & FMODE_WRITE ? O_RDWR : O_RDONLY;
-	if (bdev)
-		err = blkdev_get_partition(bdev, mode, flags);
-	return err ? ERR_PTR(err) : bdev;
-}
-
-EXPORT_SYMBOL(open_partition_by_devnum);
-
-
 /*
  * This routine checks whether a removable media has been changed,
  * and invalidates all buffer-cache-entries in that case. This
@@ -916,66 +900,7 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
-static int __blkdev_put(struct block_device *bdev, unsigned int subclass)
-{
-	int ret = 0;
-	struct inode *bd_inode = bdev->bd_inode;
-	struct gendisk *disk = bdev->bd_disk;
-
-	mutex_lock_nested(&bdev->bd_mutex, subclass);
-	lock_kernel();
-	if (!--bdev->bd_openers) {
-		sync_blockdev(bdev);
-		kill_bdev(bdev);
-	}
-	if (bdev->bd_contains == bdev) {
-		if (disk->fops->release)
-			ret = disk->fops->release(bd_inode, NULL);
-	} else {
-		mutex_lock_nested(&bdev->bd_contains->bd_mutex,
-				  subclass + 1);
-		bdev->bd_contains->bd_part_count--;
-		mutex_unlock(&bdev->bd_contains->bd_mutex);
-	}
-	if (!bdev->bd_openers) {
-		struct module *owner = disk->fops->owner;
-
-		put_disk(disk);
-		module_put(owner);
-
-		if (bdev->bd_contains != bdev) {
-			kobject_put(&bdev->bd_part->kobj);
-			bdev->bd_part = NULL;
-		}
-		bdev->bd_disk = NULL;
-		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
-		if (bdev != bdev->bd_contains)
-			__blkdev_put(bdev->bd_contains, subclass + 1);
-		bdev->bd_contains = NULL;
-	}
-	unlock_kernel();
-	mutex_unlock(&bdev->bd_mutex);
-	bdput(bdev);
-	return ret;
-}
-
-int blkdev_put(struct block_device *bdev)
-{
-	return __blkdev_put(bdev, BD_MUTEX_NORMAL);
-}
-EXPORT_SYMBOL(blkdev_put);
-
-int blkdev_put_partition(struct block_device *bdev)
-{
-	return __blkdev_put(bdev, BD_MUTEX_PARTITION);
-}
-EXPORT_SYMBOL(blkdev_put_partition);
-
-static int
-blkdev_get_whole(struct block_device *bdev, mode_t mode, unsigned flags);
-
-static int
-do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
+static int do_open(struct block_device *bdev, struct file *file)
 {
 	struct module *owner = NULL;
 	struct gendisk *disk;
@@ -992,8 +917,7 @@ do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
 	}
 	owner = disk->fops->owner;
 
-	mutex_lock_nested(&bdev->bd_mutex, subclass);
-
+	mutex_lock(&bdev->bd_mutex);
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
 		bdev->bd_contains = bdev;
@@ -1020,11 +944,11 @@ do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
 			ret = -ENOMEM;
 			if (!whole)
 				goto out_first;
-			ret = blkdev_get_whole(whole, file->f_mode, file->f_flags);
+			ret = blkdev_get(whole, file->f_mode, file->f_flags);
 			if (ret)
 				goto out_first;
 			bdev->bd_contains = whole;
-			mutex_lock_nested(&whole->bd_mutex, BD_MUTEX_WHOLE);
+			mutex_lock(&whole->bd_mutex);
 			whole->bd_part_count++;
 			p = disk->part[part - 1];
 			bdev->bd_inode->i_data.backing_dev_info =
@@ -1052,8 +976,7 @@ do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
 			if (bdev->bd_invalidated)
 				rescan_partitions(bdev->bd_disk, bdev);
 		} else {
-			mutex_lock_nested(&bdev->bd_contains->bd_mutex,
-					  BD_MUTEX_WHOLE);
+			mutex_lock(&bdev->bd_contains->bd_mutex);
 			bdev->bd_contains->bd_part_count++;
 			mutex_unlock(&bdev->bd_contains->bd_mutex);
 		}
@@ -1067,7 +990,7 @@ do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
 	bdev->bd_disk = NULL;
 	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
 	if (bdev != bdev->bd_contains)
-		__blkdev_put(bdev->bd_contains, BD_MUTEX_WHOLE);
+		blkdev_put(bdev->bd_contains);
 	bdev->bd_contains = NULL;
 	put_disk(disk);
 	module_put(owner);
@@ -1094,49 +1017,11 @@ int blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags)
 	fake_file.f_dentry = &fake_dentry;
 	fake_dentry.d_inode = bdev->bd_inode;
 
-	return do_open(bdev, &fake_file, BD_MUTEX_NORMAL);
+	return do_open(bdev, &fake_file);
 }
 
 EXPORT_SYMBOL(blkdev_get);
 
-static int
-blkdev_get_whole(struct block_device *bdev, mode_t mode, unsigned flags)
-{
-	/*
-	 * This crockload is due to bad choice of ->open() type.
-	 * It will go away.
-	 * For now, block device ->open() routine must _not_
-	 * examine anything in 'inode' argument except ->i_rdev.
-	 */
-	struct file fake_file = {};
-	struct dentry fake_dentry = {};
-	fake_file.f_mode = mode;
-	fake_file.f_flags = flags;
-	fake_file.f_dentry = &fake_dentry;
-	fake_dentry.d_inode = bdev->bd_inode;
-
-	return do_open(bdev, &fake_file, BD_MUTEX_WHOLE);
-}
-
-static int
-blkdev_get_partition(struct block_device *bdev, mode_t mode, unsigned flags)
-{
-	/*
-	 * This crockload is due to bad choice of ->open() type.
-	 * It will go away.
-	 * For now, block device ->open() routine must _not_
-	 * examine anything in 'inode' argument except ->i_rdev.
-	 */
-	struct file fake_file = {};
-	struct dentry fake_dentry = {};
-	fake_file.f_mode = mode;
-	fake_file.f_flags = flags;
-	fake_file.f_dentry = &fake_dentry;
-	fake_dentry.d_inode = bdev->bd_inode;
-
-	return do_open(bdev, &fake_file, BD_MUTEX_PARTITION);
-}
-
 static int blkdev_open(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev;
@@ -1154,7 +1039,7 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	if (bdev == NULL)
 		return -ENOMEM;
 
-	res = do_open(bdev, filp, BD_MUTEX_NORMAL);
+	res = do_open(bdev, filp);
 	if (res)
 		return res;
 
@@ -1168,6 +1053,51 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	return res;
 }
 
+int blkdev_put(struct block_device *bdev)
+{
+	int ret = 0;
+	struct inode *bd_inode = bdev->bd_inode;
+	struct gendisk *disk = bdev->bd_disk;
+
+	mutex_lock(&bdev->bd_mutex);
+	lock_kernel();
+	if (!--bdev->bd_openers) {
+		sync_blockdev(bdev);
+		kill_bdev(bdev);
+	}
+	if (bdev->bd_contains == bdev) {
+		if (disk->fops->release)
+			ret = disk->fops->release(bd_inode, NULL);
+	} else {
+		mutex_lock(&bdev->bd_contains->bd_mutex);
+		bdev->bd_contains->bd_part_count--;
+		mutex_unlock(&bdev->bd_contains->bd_mutex);
+	}
+	if (!bdev->bd_openers) {
+		struct module *owner = disk->fops->owner;
+
+		put_disk(disk);
+		module_put(owner);
+
+		if (bdev->bd_contains != bdev) {
+			kobject_put(&bdev->bd_part->kobj);
+			bdev->bd_part = NULL;
+		}
+		bdev->bd_disk = NULL;
+		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
+		if (bdev != bdev->bd_contains) {
+			blkdev_put(bdev->bd_contains);
+		}
+		bdev->bd_contains = NULL;
+	}
+	unlock_kernel();
+	mutex_unlock(&bdev->bd_mutex);
+	bdput(bdev);
+	return ret;
+}
+
+EXPORT_SYMBOL(blkdev_put);
+
 static int blkdev_close(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);

commit e18b890bb0881bbab6f4f1a6cd20d9c60d66b003
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Dec 6 20:33:20 2006 -0800

    [PATCH] slab: remove kmem_cache_t
    
    Replace all uses of kmem_cache_t with struct kmem_cache.
    
    The patch was generated using the following script:
    
            #!/bin/sh
            #
            # Replace one string by another in all the kernel sources.
            #
    
            set -e
    
            for file in `find * -name "*.c" -o -name "*.h"|xargs grep -l $1`; do
                    quilt add $file
                    sed -e "1,\$s/$1/$2/g" $file >/tmp/$$
                    mv /tmp/$$ $file
                    quilt refresh
            done
    
    The script was run like this
    
            sh replace kmem_cache_t "struct kmem_cache"
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 063506705f27..13816b4d76f6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -235,7 +235,7 @@ static int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
  */
 
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(bdev_lock);
-static kmem_cache_t * bdev_cachep __read_mostly;
+static struct kmem_cache * bdev_cachep __read_mostly;
 
 static struct inode *bdev_alloc_inode(struct super_block *sb)
 {
@@ -253,7 +253,7 @@ static void bdev_destroy_inode(struct inode *inode)
 	kmem_cache_free(bdev_cachep, bdi);
 }
 
-static void init_once(void * foo, kmem_cache_t * cachep, unsigned long flags)
+static void init_once(void * foo, struct kmem_cache * cachep, unsigned long flags)
 {
 	struct bdev_inode *ei = (struct bdev_inode *) foo;
 	struct block_device *bdev = &ei->bdev;

commit e94b1766097d53e6f3ccfb36c8baa562ffeda3fc
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Dec 6 20:33:17 2006 -0800

    [PATCH] slab: remove SLAB_KERNEL
    
    SLAB_KERNEL is an alias of GFP_KERNEL.
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 36c0e7af9d0f..063506705f27 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -239,7 +239,7 @@ static kmem_cache_t * bdev_cachep __read_mostly;
 
 static struct inode *bdev_alloc_inode(struct super_block *sb)
 {
-	struct bdev_inode *ei = kmem_cache_alloc(bdev_cachep, SLAB_KERNEL);
+	struct bdev_inode *ei = kmem_cache_alloc(bdev_cachep, GFP_KERNEL);
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;

commit 36a561d6a95c4b89ae4845bf91456b4f784b6eec
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Oct 30 22:07:03 2006 -0800

    [PATCH] find_bd_holder() fix
    
    fs/block_dev.c: In function 'find_bd_holder':
    fs/block_dev.c:666: warning: return makes integer from pointer without a cast
    fs/block_dev.c:669: warning: return makes integer from pointer without a cast
    fs/block_dev.c: In function 'add_bd_holder':
    fs/block_dev.c:685: warning: unused variable 'tmp'
    fs/block_dev.c: In function 'bd_claim_by_kobject':
    fs/block_dev.c:773: warning: assignment makes pointer from integer without a cast
    
    Acked-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index aaa8301f43f1..36c0e7af9d0f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -651,7 +651,8 @@ static void free_bd_holder(struct bd_holder *bo)
  * If found, increment the reference count and return the pointer.
  * If not found, returns NULL.
  */
-static int find_bd_holder(struct block_device *bdev, struct bd_holder *bo)
+static struct bd_holder *find_bd_holder(struct block_device *bdev,
+					struct bd_holder *bo)
 {
 	struct bd_holder *tmp;
 
@@ -677,7 +678,6 @@ static int find_bd_holder(struct block_device *bdev, struct bd_holder *bo)
  */
 static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
 {
-	struct bd_holder *tmp;
 	int ret;
 
 	if (!bo)

commit df6c0cd9a872ebf2298f5d66d8c789f62dbe35fc
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Mon Oct 30 16:23:56 2006 -0500

    [PATCH] clean up add_bd_holder()
    
    add_bd_holder() is called from bd_claim_by_kobject to put a given struct
    bd_holder in the list if there is no matching entry.
    
    There are 3 possible results of add_bd_holder():
      1. there is no matching entry and add the given one to the list
      2. there is matching entry, so just increment reference count of
         the existing one
      3. something failed during its course
    
    1 and 2 are successful cases.  But for case 2, someone has to free the
    unused struct bd_holder.
    
    The current code frees it inside of add_bd_holder and returns same value
    0 for both cases 1 and 2.  However, it's natural and less error-prone if
    caller frees it since it's allocated by the caller.
    
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index b54b0a1b7c68..aaa8301f43f1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -641,17 +641,39 @@ static void free_bd_holder(struct bd_holder *bo)
 	kfree(bo);
 }
 
+/**
+ * find_bd_holder - find matching struct bd_holder from the block device
+ *
+ * @bdev:	struct block device to be searched
+ * @bo:		target struct bd_holder
+ *
+ * Returns matching entry with @bo in @bdev->bd_holder_list.
+ * If found, increment the reference count and return the pointer.
+ * If not found, returns NULL.
+ */
+static int find_bd_holder(struct block_device *bdev, struct bd_holder *bo)
+{
+	struct bd_holder *tmp;
+
+	list_for_each_entry(tmp, &bdev->bd_holder_list, list)
+		if (tmp->sdir == bo->sdir) {
+			tmp->count++;
+			return tmp;
+		}
+
+	return NULL;
+}
+
 /**
  * add_bd_holder - create sysfs symlinks for bd_claim() relationship
  *
  * @bdev:	block device to be bd_claimed
  * @bo:		preallocated and initialized by alloc_bd_holder()
  *
- * If there is no matching entry with @bo in @bdev->bd_holder_list,
- * add @bo to the list, create symlinks.
+ * Add @bo to @bdev->bd_holder_list, create symlinks.
  *
- * Returns 0 if symlinks are created or already there.
- * Returns -ve if something fails and @bo can be freed.
+ * Returns 0 if symlinks are created.
+ * Returns -ve if something fails.
  */
 static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
 {
@@ -661,15 +683,6 @@ static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
 	if (!bo)
 		return -EINVAL;
 
-	list_for_each_entry(tmp, &bdev->bd_holder_list, list) {
-		if (tmp->sdir == bo->sdir) {
-			tmp->count++;
-			/* We've already done what we need to do here. */
-			free_bd_holder(bo);
-			return 0;
-		}
-	}
-
 	if (!bd_holder_grab_dirs(bdev, bo))
 		return -EBUSY;
 
@@ -740,7 +753,7 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 				struct kobject *kobj)
 {
 	int res;
-	struct bd_holder *bo;
+	struct bd_holder *bo, *found;
 
 	if (!kobj)
 		return -EINVAL;
@@ -752,11 +765,15 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 	mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_PARTITION);
 	res = bd_claim(bdev, holder);
 	if (res == 0) {
-		res = add_bd_holder(bdev, bo);
-		if (res)
-			bd_release(bdev);
+		found = find_bd_holder(bdev, bo);
+		if (found == NULL) {
+			res = add_bd_holder(bdev, bo);
+			if (res)
+				bd_release(bdev);
+		}
 	}
-	if (res)
+
+	if (res || found)
 		free_bd_holder(bo);
 	mutex_unlock(&bdev->bd_mutex);
 

commit bcb55165d3d1ae3ec95807d118fd6d5956cd127b
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Mon Oct 30 16:23:45 2006 -0500

    [PATCH] fix bd_claim_by_kobject error handling
    
    This fixes bd_claim_by_kobject to release bdev correctly in case that
    bd_claim succeeds but following add_bd_holder fails.
    
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 702b88cbd91d..b54b0a1b7c68 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -751,8 +751,11 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 
 	mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_PARTITION);
 	res = bd_claim(bdev, holder);
-	if (res == 0)
+	if (res == 0) {
 		res = add_bd_holder(bdev, bo);
+		if (res)
+			bd_release(bdev);
+	}
 	if (res)
 		free_bd_holder(bo);
 	mutex_unlock(&bdev->bd_mutex);

commit 6a2aae06cc1e87e9712a26a639f6a2f3442e2027
Author: Pavel Emelianov <xemul@openvz.org>
Date:   Sat Oct 28 10:38:33 2006 -0700

    [PATCH] Fix potential OOPs in blkdev_open()
    
    blkdev_open() calls bc_acquire() to get a struct block_device.  Since
    bc_acquire() may return NULL when system is out of memory an appropriate
    check is required.
    
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index bc8f27cc4483..702b88cbd91d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1131,6 +1131,8 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	filp->f_flags |= O_LARGEFILE;
 
 	bdev = bd_acquire(inode);
+	if (bdev == NULL)
+		return -ENOMEM;
 
 	res = do_open(bdev, filp, BD_MUTEX_NORMAL);
 	if (res)

commit 543ade1fc901db4c3dbe9fb27241fb977f1f3eea
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sat Sep 30 23:28:48 2006 -0700

    [PATCH] Streamline generic_file_* interfaces and filemap cleanups
    
    This patch cleans up generic_file_*_read/write() interfaces.  Christoph
    Hellwig gave me the idea for this clean ups.
    
    In a nutshell, all filesystems should set .aio_read/.aio_write methods and use
    do_sync_read/ do_sync_write() as their .read/.write methods.  This allows us
    to cleanup all variants of generic_file_* routines.
    
    Final available interfaces:
    
    generic_file_aio_read() - read handler
    generic_file_aio_write() - write handler
    generic_file_aio_write_nolock() - no lock write handler
    
    __generic_file_aio_write_nolock() - internal worker routine
    
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0f143094ef1d..bc8f27cc4483 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1154,14 +1154,6 @@ static int blkdev_close(struct inode * inode, struct file * filp)
 	return blkdev_put(bdev);
 }
 
-static ssize_t blkdev_file_write(struct file *file, const char __user *buf,
-				   size_t count, loff_t *ppos)
-{
-	struct iovec local_iov = { .iov_base = (void __user *)buf, .iov_len = count };
-
-	return generic_file_write_nolock(file, &local_iov, 1, ppos);
-}
-
 static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 {
 	return blkdev_ioctl(file->f_mapping->host, file, cmd, arg);
@@ -1181,8 +1173,8 @@ const struct file_operations def_blk_fops = {
 	.open		= blkdev_open,
 	.release	= blkdev_close,
 	.llseek		= block_llseek,
-	.read		= generic_file_read,
-	.write		= blkdev_file_write,
+	.read		= do_sync_read,
+	.write		= do_sync_write,
   	.aio_read	= generic_file_aio_read,
   	.aio_write	= generic_file_aio_write_nolock,
 	.mmap		= generic_file_mmap,

commit ee0b3e671baff681d69fbf0db33b47603c0a8280
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sat Sep 30 23:28:47 2006 -0700

    [PATCH] Remove readv/writev methods and use aio_read/aio_write instead
    
    This patch removes readv() and writev() methods and replaces them with
    aio_read()/aio_write() methods.
    
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8c819117310b..0f143094ef1d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1191,8 +1191,6 @@ const struct file_operations def_blk_fops = {
 #ifdef CONFIG_COMPAT
 	.compat_ioctl	= compat_blkdev_ioctl,
 #endif
-	.readv		= generic_file_readv,
-	.writev		= generic_file_write_nolock,
 	.sendfile	= generic_file_sendfile,
 	.splice_read	= generic_file_splice_read,
 	.splice_write	= generic_file_splice_write,

commit 027445c37282bc1ed26add45e573ad2d3e4860a5
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sat Sep 30 23:28:46 2006 -0700

    [PATCH] Vectorize aio_read/aio_write fileop methods
    
    This patch vectorizes aio_read() and aio_write() methods to prepare for
    collapsing all aio & vectored operations into one interface - which is
    aio_read()/aio_write().
    
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Michael Holzheu <HOLZHEU@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 0c361ea7e5a6..8c819117310b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1162,14 +1162,6 @@ static ssize_t blkdev_file_write(struct file *file, const char __user *buf,
 	return generic_file_write_nolock(file, &local_iov, 1, ppos);
 }
 
-static ssize_t blkdev_file_aio_write(struct kiocb *iocb, const char __user *buf,
-				   size_t count, loff_t pos)
-{
-	struct iovec local_iov = { .iov_base = (void __user *)buf, .iov_len = count };
-
-	return generic_file_aio_write_nolock(iocb, &local_iov, 1, &iocb->ki_pos);
-}
-
 static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 {
 	return blkdev_ioctl(file->f_mapping->host, file, cmd, arg);
@@ -1192,7 +1184,7 @@ const struct file_operations def_blk_fops = {
 	.read		= generic_file_read,
 	.write		= blkdev_file_write,
   	.aio_read	= generic_file_aio_read,
-  	.aio_write	= blkdev_file_aio_write, 
+  	.aio_write	= generic_file_aio_write_nolock,
 	.mmap		= generic_file_mmap,
 	.fsync		= block_fsync,
 	.unlocked_ioctl	= block_ioctl,

commit b71e8a4ce03b3098c7801ee5e6e08d1a39a226c2
Author: David Howells <dhowells@redhat.com>
Date:   Tue Aug 29 19:06:11 2006 +0100

    [PATCH] BLOCK: Move __invalidate_device() to block_dev.c [try #6]
    
    Move __invalidate_device() from fs/inode.c to fs/block_dev.c so that it can
    more easily be disabled when the block layer is disabled.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 335c38bb86eb..0c361ea7e5a6 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1315,3 +1315,24 @@ void close_bdev_excl(struct block_device *bdev)
 }
 
 EXPORT_SYMBOL(close_bdev_excl);
+
+int __invalidate_device(struct block_device *bdev)
+{
+	struct super_block *sb = get_super(bdev);
+	int res = 0;
+
+	if (sb) {
+		/*
+		 * no need to lock the super, get_super holds the
+		 * read mutex so the filesystem cannot go away
+		 * under us (->put_super runs with the write lock
+		 * hold).
+		 */
+		shrink_dcache_sb(sb);
+		res = invalidate_inodes(sb);
+		drop_super(sb);
+	}
+	invalidate_bdev(bdev, 0);
+	return res;
+}
+EXPORT_SYMBOL(__invalidate_device);

commit 811d736f9e8013966e1a5a930c0db09508bdbb15
Author: David Howells <dhowells@redhat.com>
Date:   Tue Aug 29 19:06:09 2006 +0100

    [PATCH] BLOCK: Dissociate generic_writepages() from mpage stuff [try #6]
    
    Dissociate the generic_writepages() function from the mpage stuff, moving its
    declaration to linux/mm.h and actually emitting a full implementation into
    mm/page-writeback.c.
    
    The implementation is a partial duplicate of mpage_writepages() with all BIO
    references removed.
    
    It is used by NFS to do writeback.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 20f7333ba372..335c38bb86eb 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -17,6 +17,7 @@
 #include <linux/module.h>
 #include <linux/blkpg.h>
 #include <linux/buffer_head.h>
+#include <linux/writeback.h>
 #include <linux/mpage.h>
 #include <linux/mount.h>
 #include <linux/uio.h>

commit 07f3f05c1e3052b8656129b2a5aca9f888241a34
Author: David Howells <dhowells@redhat.com>
Date:   Sat Sep 30 20:52:18 2006 +0200

    [PATCH] BLOCK: Move extern declarations out of fs/*.c into header files [try #6]
    
    Create a new header file, fs/internal.h, for common definitions local to the
    sources in the fs/ directory.
    
    Move extern definitions that should be in header files from fs/*.c to
    fs/internal.h or other main header files where they span directories.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 4346468139e8..20f7333ba372 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -22,6 +22,7 @@
 #include <linux/uio.h>
 #include <linux/namei.h>
 #include <asm/uaccess.h>
+#include "internal.h"
 
 struct bdev_inode {
 	struct block_device bdev;

commit 87d7c8aca8670a772f74766c19e0345a606b67a9
Author: Jason Baron <jbaron@redhat.com>
Date:   Fri Sep 29 02:01:01 2006 -0700

    [PATCH] block_dev.c mutex_lock_nested() fix
    
    In the case below we are locking the whole disk not a partition.  This
    change simply brings the code in line with the piece above where when we
    are the 'first' opener, and we are a partition.
    
    Signed-off-by: Jason Baron <jbaron@redhat.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 8cc144ffc382..4346468139e8 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1031,7 +1031,7 @@ do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
 				rescan_partitions(bdev->bd_disk, bdev);
 		} else {
 			mutex_lock_nested(&bdev->bd_contains->bd_mutex,
-					  BD_MUTEX_PARTITION);
+					  BD_MUTEX_WHOLE);
 			bdev->bd_contains->bd_part_count++;
 			mutex_unlock(&bdev->bd_contains->bd_mutex);
 		}

commit 4d7dd8fd9557840162b724a8ac1366dd78a12dff
Author: Andrew Morton <akpm@osdl.org>
Date:   Fri Sep 29 01:58:56 2006 -0700

    [PATCH] blockdev.c: check driver layer errors
    
    Check driver layer errors.
    
    Fix from: "Jun'ichi Nomura" <j-nomura@ce.jp.nec.com>
    
    In blockdevc-check-errors.patch, add_bd_holder() is modified to return error
    values when some of its operation failed.  Among them, it returns -EEXIST when
    a given bd_holder object already exists in the list.
    
    However, in this case, the function completed its work successfully and need
    no action by its caller other than freeing unused bd_holder object.  So I
    think it's better to return success after freeing by itself.
    
    Otherwise, bd_claim-ing with same claim pointer will fail.
    Typically, lvresize will fails with following message:
      device-mapper: reload ioctl failed: Invalid argument
    and you'll see messages like below in kernel log:
      device-mapper: table: 254:13: linear: dm-linear: Device lookup failed
      device-mapper: ioctl: error adding target to table
    
    Similarly, it should not add bd_holder to the list if either one of symlinking
    fails.  I don't have a test case for this to happen but it should cause
    dereference of freed pointer.
    
    If a matching bd_holder is found in bd_holder_list, add_bd_holder() completes
    its job by just incrementing the reference count.  In this case, it should be
    considered as success but it used to return 'fail' to let the caller free
    temporary bd_holder.  Fixed it to return success and free given object by
    itself.
    
    Also, if either one of symlinking fails, the bd_holder should not be added to
    the list so that it can be discarded later.  Otherwise, the caller will free
    bd_holder which is in the list.
    
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: "Randy.Dunlap" <rdunlap@xenotime.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 045f98854f14..8cc144ffc382 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -543,11 +543,11 @@ static struct kobject *bdev_get_holder(struct block_device *bdev)
 		return kobject_get(bdev->bd_disk->holder_dir);
 }
 
-static void add_symlink(struct kobject *from, struct kobject *to)
+static int add_symlink(struct kobject *from, struct kobject *to)
 {
 	if (!from || !to)
-		return;
-	sysfs_create_link(from, to, kobject_name(to));
+		return 0;
+	return sysfs_create_link(from, to, kobject_name(to));
 }
 
 static void del_symlink(struct kobject *from, struct kobject *to)
@@ -648,30 +648,38 @@ static void free_bd_holder(struct bd_holder *bo)
  * If there is no matching entry with @bo in @bdev->bd_holder_list,
  * add @bo to the list, create symlinks.
  *
- * Returns 1 if @bo was added to the list.
- * Returns 0 if @bo wasn't used by any reason and should be freed.
+ * Returns 0 if symlinks are created or already there.
+ * Returns -ve if something fails and @bo can be freed.
  */
 static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
 {
 	struct bd_holder *tmp;
+	int ret;
 
 	if (!bo)
-		return 0;
+		return -EINVAL;
 
 	list_for_each_entry(tmp, &bdev->bd_holder_list, list) {
 		if (tmp->sdir == bo->sdir) {
 			tmp->count++;
+			/* We've already done what we need to do here. */
+			free_bd_holder(bo);
 			return 0;
 		}
 	}
 
 	if (!bd_holder_grab_dirs(bdev, bo))
-		return 0;
+		return -EBUSY;
 
-	add_symlink(bo->sdir, bo->sdev);
-	add_symlink(bo->hdir, bo->hdev);
-	list_add_tail(&bo->list, &bdev->bd_holder_list);
-	return 1;
+	ret = add_symlink(bo->sdir, bo->sdev);
+	if (ret == 0) {
+		ret = add_symlink(bo->hdir, bo->hdev);
+		if (ret)
+			del_symlink(bo->sdir, bo->sdev);
+	}
+	if (ret == 0)
+		list_add_tail(&bo->list, &bdev->bd_holder_list);
+	return ret;
 }
 
 /**
@@ -741,7 +749,9 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 
 	mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_PARTITION);
 	res = bd_claim(bdev, holder);
-	if (res || !add_bd_holder(bdev, bo))
+	if (res == 0)
+		res = add_bd_holder(bdev, bo);
+	if (res)
 		free_bd_holder(bo);
 	mutex_unlock(&bdev->bd_mutex);
 

commit 6946bd636364effce06ea46fe8f8cd6e2edb004e
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Sun Aug 27 01:23:31 2006 -0700

    [PATCH] lockdep: fix blkdev_open() warning
    
    On Wed, 2006-08-09 at 07:57 +0200, Rolf Eike Beer wrote:
    > =============================================
    > [ INFO: possible recursive locking detected ]
    > ---------------------------------------------
    > parted/7929 is trying to acquire lock:
    >  (&bdev->bd_mutex){--..}, at: [<c105eb8d>] __blkdev_put+0x1e/0x13c
    >
    > but task is already holding lock:
    >  (&bdev->bd_mutex){--..}, at: [<c105eec6>] do_open+0x72/0x3a8
    >
    > other info that might help us debug this:
    > 1 lock held by parted/7929:
    >  #0:  (&bdev->bd_mutex){--..}, at: [<c105eec6>] do_open+0x72/0x3a8
    > stack backtrace:
    >  [<c1003aad>] show_trace_log_lvl+0x58/0x15b
    >  [<c100495f>] show_trace+0xd/0x10
    >  [<c1004979>] dump_stack+0x17/0x1a
    >  [<c102dee5>] __lock_acquire+0x753/0x99c
    >  [<c102e3b0>] lock_acquire+0x4a/0x6a
    >  [<c1204501>] mutex_lock_nested+0xc8/0x20c
    >  [<c105eb8d>] __blkdev_put+0x1e/0x13c
    >  [<c105ecc4>] blkdev_put+0xa/0xc
    >  [<c105f18a>] do_open+0x336/0x3a8
    >  [<c105f21b>] blkdev_open+0x1f/0x4c
    >  [<c1057b40>] __dentry_open+0xc7/0x1aa
    >  [<c1057c91>] nameidata_to_filp+0x1c/0x2e
    >  [<c1057cd1>] do_filp_open+0x2e/0x35
    >  [<c1057dd7>] do_sys_open+0x38/0x68
    >  [<c1057e33>] sys_open+0x16/0x18
    >  [<c1002845>] sysenter_past_esp+0x56/0x8d
    
    OK, I'm having a look here; its all new to me so bear with me.
    
    blkdev_open() calls
      do_open(bdev, ...,BD_MUTEX_NORMAL) and takes
        mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_NORMAL)
    
    then something fails, and we're thrown to:
    
    out_first: where
        if (bdev != bdev->bd_contains)
          blkdev_put(bdev->bd_contains) which is
            __blkdev_put(bdev->bd_contains, BD_MUTEX_NORMAL) which does
              mutex_lock_nested(&bdev->bd_contains->bd_mutex, BD_MUTEX_NORMAL) <--- lockdep trigger
    
    When going to out_first, dbev->bd_contains is either bdev or whole, and
    since we take the branch it must be whole. So it seems to me the
    following patch would be the right one:
    
    [akpm@osdl.org: compile fix]
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 37534573960b..045f98854f14 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -884,6 +884,61 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
+static int __blkdev_put(struct block_device *bdev, unsigned int subclass)
+{
+	int ret = 0;
+	struct inode *bd_inode = bdev->bd_inode;
+	struct gendisk *disk = bdev->bd_disk;
+
+	mutex_lock_nested(&bdev->bd_mutex, subclass);
+	lock_kernel();
+	if (!--bdev->bd_openers) {
+		sync_blockdev(bdev);
+		kill_bdev(bdev);
+	}
+	if (bdev->bd_contains == bdev) {
+		if (disk->fops->release)
+			ret = disk->fops->release(bd_inode, NULL);
+	} else {
+		mutex_lock_nested(&bdev->bd_contains->bd_mutex,
+				  subclass + 1);
+		bdev->bd_contains->bd_part_count--;
+		mutex_unlock(&bdev->bd_contains->bd_mutex);
+	}
+	if (!bdev->bd_openers) {
+		struct module *owner = disk->fops->owner;
+
+		put_disk(disk);
+		module_put(owner);
+
+		if (bdev->bd_contains != bdev) {
+			kobject_put(&bdev->bd_part->kobj);
+			bdev->bd_part = NULL;
+		}
+		bdev->bd_disk = NULL;
+		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
+		if (bdev != bdev->bd_contains)
+			__blkdev_put(bdev->bd_contains, subclass + 1);
+		bdev->bd_contains = NULL;
+	}
+	unlock_kernel();
+	mutex_unlock(&bdev->bd_mutex);
+	bdput(bdev);
+	return ret;
+}
+
+int blkdev_put(struct block_device *bdev)
+{
+	return __blkdev_put(bdev, BD_MUTEX_NORMAL);
+}
+EXPORT_SYMBOL(blkdev_put);
+
+int blkdev_put_partition(struct block_device *bdev)
+{
+	return __blkdev_put(bdev, BD_MUTEX_PARTITION);
+}
+EXPORT_SYMBOL(blkdev_put_partition);
+
 static int
 blkdev_get_whole(struct block_device *bdev, mode_t mode, unsigned flags);
 
@@ -980,7 +1035,7 @@ do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
 	bdev->bd_disk = NULL;
 	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
 	if (bdev != bdev->bd_contains)
-		blkdev_put(bdev->bd_contains);
+		__blkdev_put(bdev->bd_contains, BD_MUTEX_WHOLE);
 	bdev->bd_contains = NULL;
 	put_disk(disk);
 	module_put(owner);
@@ -1079,63 +1134,6 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	return res;
 }
 
-static int __blkdev_put(struct block_device *bdev, unsigned int subclass)
-{
-	int ret = 0;
-	struct inode *bd_inode = bdev->bd_inode;
-	struct gendisk *disk = bdev->bd_disk;
-
-	mutex_lock_nested(&bdev->bd_mutex, subclass);
-	lock_kernel();
-	if (!--bdev->bd_openers) {
-		sync_blockdev(bdev);
-		kill_bdev(bdev);
-	}
-	if (bdev->bd_contains == bdev) {
-		if (disk->fops->release)
-			ret = disk->fops->release(bd_inode, NULL);
-	} else {
-		mutex_lock_nested(&bdev->bd_contains->bd_mutex,
-				  subclass + 1);
-		bdev->bd_contains->bd_part_count--;
-		mutex_unlock(&bdev->bd_contains->bd_mutex);
-	}
-	if (!bdev->bd_openers) {
-		struct module *owner = disk->fops->owner;
-
-		put_disk(disk);
-		module_put(owner);
-
-		if (bdev->bd_contains != bdev) {
-			kobject_put(&bdev->bd_part->kobj);
-			bdev->bd_part = NULL;
-		}
-		bdev->bd_disk = NULL;
-		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
-		if (bdev != bdev->bd_contains)
-			__blkdev_put(bdev->bd_contains, subclass + 1);
-		bdev->bd_contains = NULL;
-	}
-	unlock_kernel();
-	mutex_unlock(&bdev->bd_mutex);
-	bdput(bdev);
-	return ret;
-}
-
-int blkdev_put(struct block_device *bdev)
-{
-	return __blkdev_put(bdev, BD_MUTEX_NORMAL);
-}
-
-EXPORT_SYMBOL(blkdev_put);
-
-int blkdev_put_partition(struct block_device *bdev)
-{
-	return __blkdev_put(bdev, BD_MUTEX_PARTITION);
-}
-
-EXPORT_SYMBOL(blkdev_put_partition);
-
 static int blkdev_close(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);

commit 663d440eaa496db903cc58be04b9b602ba45e43b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jul 3 00:25:33 2006 -0700

    [PATCH] lockdep: annotate blkdev nesting
    
    Teach special (recursive) locking code to the lock validator.
    
    Effects on non-lockdep kernels:
    
    - the introduction of the following function variants:
    
      extern struct block_device *open_partition_by_devnum(dev_t, unsigned);
    
      extern int blkdev_put_partition(struct block_device *);
    
      static int
      blkdev_get_whole(struct block_device *bdev, mode_t mode, unsigned flags);
    
     which on non-lockdep are the same as open_by_devnum(), blkdev_put()
     and blkdev_get().
    
    - a subclass parameter to do_open(). [unused on non-lockdep]
    
    - a subclass parameter to __blkdev_put(), which is a new internal
      function for the main blkdev_put*() functions. [parameter unused
      on non-lockdep kernels, except for two sanity check WARN_ON()s]
    
    these functions carry no semantical difference - they only express
    object dependencies towards the lockdep subsystem.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9633a490dab0..37534573960b 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -739,7 +739,7 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 	if (!bo)
 		return -ENOMEM;
 
-	mutex_lock(&bdev->bd_mutex);
+	mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_PARTITION);
 	res = bd_claim(bdev, holder);
 	if (res || !add_bd_holder(bdev, bo))
 		free_bd_holder(bo);
@@ -764,7 +764,7 @@ static void bd_release_from_kobject(struct block_device *bdev,
 	if (!kobj)
 		return;
 
-	mutex_lock(&bdev->bd_mutex);
+	mutex_lock_nested(&bdev->bd_mutex, BD_MUTEX_PARTITION);
 	bd_release(bdev);
 	if ((bo = del_bd_holder(bdev, kobj)))
 		free_bd_holder(bo);
@@ -822,6 +822,22 @@ struct block_device *open_by_devnum(dev_t dev, unsigned mode)
 
 EXPORT_SYMBOL(open_by_devnum);
 
+static int
+blkdev_get_partition(struct block_device *bdev, mode_t mode, unsigned flags);
+
+struct block_device *open_partition_by_devnum(dev_t dev, unsigned mode)
+{
+	struct block_device *bdev = bdget(dev);
+	int err = -ENOMEM;
+	int flags = mode & FMODE_WRITE ? O_RDWR : O_RDONLY;
+	if (bdev)
+		err = blkdev_get_partition(bdev, mode, flags);
+	return err ? ERR_PTR(err) : bdev;
+}
+
+EXPORT_SYMBOL(open_partition_by_devnum);
+
+
 /*
  * This routine checks whether a removable media has been changed,
  * and invalidates all buffer-cache-entries in that case. This
@@ -868,7 +884,11 @@ void bd_set_size(struct block_device *bdev, loff_t size)
 }
 EXPORT_SYMBOL(bd_set_size);
 
-static int do_open(struct block_device *bdev, struct file *file)
+static int
+blkdev_get_whole(struct block_device *bdev, mode_t mode, unsigned flags);
+
+static int
+do_open(struct block_device *bdev, struct file *file, unsigned int subclass)
 {
 	struct module *owner = NULL;
 	struct gendisk *disk;
@@ -885,7 +905,8 @@ static int do_open(struct block_device *bdev, struct file *file)
 	}
 	owner = disk->fops->owner;
 
-	mutex_lock(&bdev->bd_mutex);
+	mutex_lock_nested(&bdev->bd_mutex, subclass);
+
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
 		bdev->bd_contains = bdev;
@@ -912,11 +933,11 @@ static int do_open(struct block_device *bdev, struct file *file)
 			ret = -ENOMEM;
 			if (!whole)
 				goto out_first;
-			ret = blkdev_get(whole, file->f_mode, file->f_flags);
+			ret = blkdev_get_whole(whole, file->f_mode, file->f_flags);
 			if (ret)
 				goto out_first;
 			bdev->bd_contains = whole;
-			mutex_lock(&whole->bd_mutex);
+			mutex_lock_nested(&whole->bd_mutex, BD_MUTEX_WHOLE);
 			whole->bd_part_count++;
 			p = disk->part[part - 1];
 			bdev->bd_inode->i_data.backing_dev_info =
@@ -944,7 +965,8 @@ static int do_open(struct block_device *bdev, struct file *file)
 			if (bdev->bd_invalidated)
 				rescan_partitions(bdev->bd_disk, bdev);
 		} else {
-			mutex_lock(&bdev->bd_contains->bd_mutex);
+			mutex_lock_nested(&bdev->bd_contains->bd_mutex,
+					  BD_MUTEX_PARTITION);
 			bdev->bd_contains->bd_part_count++;
 			mutex_unlock(&bdev->bd_contains->bd_mutex);
 		}
@@ -985,11 +1007,49 @@ int blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags)
 	fake_file.f_dentry = &fake_dentry;
 	fake_dentry.d_inode = bdev->bd_inode;
 
-	return do_open(bdev, &fake_file);
+	return do_open(bdev, &fake_file, BD_MUTEX_NORMAL);
 }
 
 EXPORT_SYMBOL(blkdev_get);
 
+static int
+blkdev_get_whole(struct block_device *bdev, mode_t mode, unsigned flags)
+{
+	/*
+	 * This crockload is due to bad choice of ->open() type.
+	 * It will go away.
+	 * For now, block device ->open() routine must _not_
+	 * examine anything in 'inode' argument except ->i_rdev.
+	 */
+	struct file fake_file = {};
+	struct dentry fake_dentry = {};
+	fake_file.f_mode = mode;
+	fake_file.f_flags = flags;
+	fake_file.f_dentry = &fake_dentry;
+	fake_dentry.d_inode = bdev->bd_inode;
+
+	return do_open(bdev, &fake_file, BD_MUTEX_WHOLE);
+}
+
+static int
+blkdev_get_partition(struct block_device *bdev, mode_t mode, unsigned flags)
+{
+	/*
+	 * This crockload is due to bad choice of ->open() type.
+	 * It will go away.
+	 * For now, block device ->open() routine must _not_
+	 * examine anything in 'inode' argument except ->i_rdev.
+	 */
+	struct file fake_file = {};
+	struct dentry fake_dentry = {};
+	fake_file.f_mode = mode;
+	fake_file.f_flags = flags;
+	fake_file.f_dentry = &fake_dentry;
+	fake_dentry.d_inode = bdev->bd_inode;
+
+	return do_open(bdev, &fake_file, BD_MUTEX_PARTITION);
+}
+
 static int blkdev_open(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev;
@@ -1005,7 +1065,7 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 
 	bdev = bd_acquire(inode);
 
-	res = do_open(bdev, filp);
+	res = do_open(bdev, filp, BD_MUTEX_NORMAL);
 	if (res)
 		return res;
 
@@ -1019,13 +1079,13 @@ static int blkdev_open(struct inode * inode, struct file * filp)
 	return res;
 }
 
-int blkdev_put(struct block_device *bdev)
+static int __blkdev_put(struct block_device *bdev, unsigned int subclass)
 {
 	int ret = 0;
 	struct inode *bd_inode = bdev->bd_inode;
 	struct gendisk *disk = bdev->bd_disk;
 
-	mutex_lock(&bdev->bd_mutex);
+	mutex_lock_nested(&bdev->bd_mutex, subclass);
 	lock_kernel();
 	if (!--bdev->bd_openers) {
 		sync_blockdev(bdev);
@@ -1035,7 +1095,8 @@ int blkdev_put(struct block_device *bdev)
 		if (disk->fops->release)
 			ret = disk->fops->release(bd_inode, NULL);
 	} else {
-		mutex_lock(&bdev->bd_contains->bd_mutex);
+		mutex_lock_nested(&bdev->bd_contains->bd_mutex,
+				  subclass + 1);
 		bdev->bd_contains->bd_part_count--;
 		mutex_unlock(&bdev->bd_contains->bd_mutex);
 	}
@@ -1051,9 +1112,8 @@ int blkdev_put(struct block_device *bdev)
 		}
 		bdev->bd_disk = NULL;
 		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
-		if (bdev != bdev->bd_contains) {
-			blkdev_put(bdev->bd_contains);
-		}
+		if (bdev != bdev->bd_contains)
+			__blkdev_put(bdev->bd_contains, subclass + 1);
 		bdev->bd_contains = NULL;
 	}
 	unlock_kernel();
@@ -1062,8 +1122,20 @@ int blkdev_put(struct block_device *bdev)
 	return ret;
 }
 
+int blkdev_put(struct block_device *bdev)
+{
+	return __blkdev_put(bdev, BD_MUTEX_NORMAL);
+}
+
 EXPORT_SYMBOL(blkdev_put);
 
+int blkdev_put_partition(struct block_device *bdev)
+{
+	return __blkdev_put(bdev, BD_MUTEX_PARTITION);
+}
+
+EXPORT_SYMBOL(blkdev_put_partition);
+
 static int blkdev_close(struct inode * inode, struct file * filp)
 {
 	struct block_device *bdev = I_BDEV(filp->f_mapping->host);

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jrn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jrn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 909cb0595b4e..9633a490dab0 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -5,7 +5,6 @@
  *  Copyright (C) 2001  Andrea Arcangeli <andrea@suse.de> SuSE
  */
 
-#include <linux/config.h>
 #include <linux/init.h>
 #include <linux/mm.h>
 #include <linux/fcntl.h>

commit 602cada851b28c5792339786efe872fbdc1f5d41
Merge: 82991c6f2c36 fee68d1cc0d9
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Thu Jun 29 14:19:21 2006 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/devfs-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/devfs-2.6: (22 commits)
      [PATCH] devfs: Remove it from the feature_removal.txt file
      [PATCH] devfs: Last little devfs cleanups throughout the kernel tree.
      [PATCH] devfs: Rename TTY_DRIVER_NO_DEVFS to TTY_DRIVER_DYNAMIC_DEV
      [PATCH] devfs: Remove the tty_driver devfs_name field as it's no longer needed
      [PATCH] devfs: Remove the line_driver devfs_name field as it's no longer needed
      [PATCH] devfs: Remove the videodevice devfs_name field as it's no longer needed
      [PATCH] devfs: Remove the gendisk devfs_name field as it's no longer needed
      [PATCH] devfs: Remove the miscdevice devfs_name field as it's no longer needed
      [PATCH] devfs: Remove the devfs_fs_kernel.h file from the tree
      [PATCH] devfs: Remove devfs_remove() function from the kernel tree
      [PATCH] devfs: Remove devfs_mk_cdev() function from the kernel tree
      [PATCH] devfs: Remove devfs_mk_bdev() function from the kernel tree
      [PATCH] devfs: Remove devfs_mk_symlink() function from the kernel tree
      [PATCH] devfs: Remove devfs_mk_dir() function from the kernel tree
      [PATCH] devfs: Remove devfs_*_tape() functions from the kernel tree
      [PATCH] devfs: Remove devfs support from the sound subsystem
      [PATCH] devfs: Remove devfs support from the ide subsystem.
      [PATCH] devfs: Remove devfs support from the serial subsystem
      [PATCH] devfs: Remove devfs from the init code
      [PATCH] devfs: Remove devfs from the partition code
      ...

commit f5e54d6e53a20cef45af7499e86164f0e0d16bb2
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 28 04:26:44 2006 -0700

    [PATCH] mark address_space_operations const
    
    Same as with already do with the file operations: keep them in .rodata and
    prevents people from doing runtime patching.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Steven French <sfrench@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 028d9fb9c2d5..7f7600e2381c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1095,7 +1095,7 @@ static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 	return blkdev_ioctl(file->f_mapping->host, file, cmd, arg);
 }
 
-struct address_space_operations def_blk_aops = {
+const struct address_space_operations def_blk_aops = {
 	.readpage	= blkdev_readpage,
 	.writepage	= blkdev_writepage,
 	.sync_page	= block_sync_page,

commit ff23eca3e8f613034e0d20ff86f6a89b62f5a14e
Author: Greg Kroah-Hartman <gregkh@suse.de>
Date:   Mon Jun 20 21:15:16 2005 -0700

    [PATCH] devfs: Remove the devfs_fs_kernel.h file from the tree
    
    Also fixes up all files that #include it.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 028d9fb9c2d5..ddb305eebf90 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -12,7 +12,6 @@
 #include <linux/slab.h>
 #include <linux/kmod.h>
 #include <linux/major.h>
-#include <linux/devfs_fs_kernel.h>
 #include <linux/smp_lock.h>
 #include <linux/highmem.h>
 #include <linux/blkdev.h>

commit 454e2398be9b9fa30433fccc548db34d19aa9958
Author: David Howells <dhowells@redhat.com>
Date:   Fri Jun 23 02:02:57 2006 -0700

    [PATCH] VFS: Permit filesystem to override root dentry on mount
    
    Extend the get_sb() filesystem operation to take an extra argument that
    permits the VFS to pass in the target vfsmount that defines the mountpoint.
    
    The filesystem is then required to manually set the superblock and root dentry
    pointers.  For most filesystems, this should be done with simple_set_mnt()
    which will set the superblock pointer and then set the root dentry to the
    superblock's s_root (as per the old default behaviour).
    
    The get_sb() op now returns an integer as there's now no need to return the
    superblock pointer.
    
    This patch permits a superblock to be implicitly shared amongst several mount
    points, such as can be done with NFS to avoid potential inode aliasing.  In
    such a case, simple_set_mnt() would not be called, and instead the mnt_root
    and mnt_sb would be set directly.
    
    The patch also makes the following changes:
    
     (*) the get_sb_*() convenience functions in the core kernel now take a vfsmount
         pointer argument and return an integer, so most filesystems have to change
         very little.
    
     (*) If one of the convenience function is not used, then get_sb() should
         normally call simple_set_mnt() to instantiate the vfsmount. This will
         always return 0, and so can be tail-called from get_sb().
    
     (*) generic_shutdown_super() now calls shrink_dcache_sb() to clean up the
         dcache upon superblock destruction rather than shrink_dcache_anon().
    
         This is required because the superblock may now have multiple trees that
         aren't actually bound to s_root, but that still need to be cleaned up. The
         currently called functions assume that the whole tree is rooted at s_root,
         and that anonymous dentries are not the roots of trees which results in
         dentries being left unculled.
    
         However, with the way NFS superblock sharing are currently set to be
         implemented, these assumptions are violated: the root of the filesystem is
         simply a dummy dentry and inode (the real inode for '/' may well be
         inaccessible), and all the vfsmounts are rooted on anonymous[*] dentries
         with child trees.
    
         [*] Anonymous until discovered from another tree.
    
     (*) The documentation has been adjusted, including the additional bit of
         changing ext2_* into foo_* in the documentation.
    
    [akpm@osdl.org: convert ipath_fs, do other stuff]
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Nathan Scott <nathans@sgi.com>
    Cc: Roland Dreier <rolandd@cisco.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 44aaba202f78..028d9fb9c2d5 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -300,10 +300,10 @@ static struct super_operations bdev_sops = {
 	.clear_inode = bdev_clear_inode,
 };
 
-static struct super_block *bd_get_sb(struct file_system_type *fs_type,
-	int flags, const char *dev_name, void *data)
+static int bd_get_sb(struct file_system_type *fs_type,
+	int flags, const char *dev_name, void *data, struct vfsmount *mnt)
 {
-	return get_sb_pseudo(fs_type, "bdev:", &bdev_sops, 0x62646576);
+	return get_sb_pseudo(fs_type, "bdev:", &bdev_sops, 0x62646576, mnt);
 }
 
 static struct file_system_type bd_type = {

commit 09d967c6f32b35eab15b45862ae16e4f06259d8e
Author: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
Date:   Thu Jun 22 14:47:21 2006 -0700

    [PATCH] Fix a race condition between ->i_mapping and iput()
    
    This race became a cause of oops, and can reproduce by the following.
    
        while true; do
            dd if=/dev/zero of=/dev/.static/dev/hdg1 bs=512 count=1000 & sync
        done
    
    This race condition was between __sync_single_inode() and iput().
    
              cpu0 (fs's inode)                 cpu1 (bdev's inode)
              -----------------                 -------------------
                                           close("/dev/hda2")
                                           [...]
    __sync_single_inode()
       /* copy the bdev's ->i_mapping */
       mapping = inode->i_mapping;
    
                                           generic_forget_inode()
                                              bdev_clear_inode()
                                                 /* restre the fs's ->i_mapping */
                                                 inode->i_mapping = &inode->i_data;
                                              /* bdev's inode was freed */
                                              destroy_inode(inode);
    
       if (wait) {
          /* dereference a freed bdev's mapping->host */
          filemap_fdatawait(mapping);  /* Oops */
    
    Since __sync_single_inode() is only taking a ref-count of fs's inode, the
    another process can be close() and freeing the bdev's inode while writing
    fs's inode.  So, __sync_signle_inode() accesses the freed ->i_mapping,
    oops.
    
    This patch takes a ref-count on the bdev's inode for the fs's inode before
    setting a ->i_mapping, and the clear_inode() of the fs's inode does iput() on
    the bdev's inode.  So if the fs's inode is still living, bdev's inode
    shouldn't be freed.
    
    Signed-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index f5958f413bd1..44aaba202f78 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -414,21 +414,31 @@ EXPORT_SYMBOL(bdput);
 static struct block_device *bd_acquire(struct inode *inode)
 {
 	struct block_device *bdev;
+
 	spin_lock(&bdev_lock);
 	bdev = inode->i_bdev;
-	if (bdev && igrab(bdev->bd_inode)) {
+	if (bdev) {
+		atomic_inc(&bdev->bd_inode->i_count);
 		spin_unlock(&bdev_lock);
 		return bdev;
 	}
 	spin_unlock(&bdev_lock);
+
 	bdev = bdget(inode->i_rdev);
 	if (bdev) {
 		spin_lock(&bdev_lock);
-		if (inode->i_bdev)
-			__bd_forget(inode);
-		inode->i_bdev = bdev;
-		inode->i_mapping = bdev->bd_inode->i_mapping;
-		list_add(&inode->i_devices, &bdev->bd_inodes);
+		if (!inode->i_bdev) {
+			/*
+			 * We take an additional bd_inode->i_count for inode,
+			 * and it's released in clear_inode() of inode.
+			 * So, we can access it via ->i_mapping always
+			 * without igrab().
+			 */
+			atomic_inc(&bdev->bd_inode->i_count);
+			inode->i_bdev = bdev;
+			inode->i_mapping = bdev->bd_inode->i_mapping;
+			list_add(&inode->i_devices, &bdev->bd_inodes);
+		}
 		spin_unlock(&bdev_lock);
 	}
 	return bdev;
@@ -438,10 +448,18 @@ static struct block_device *bd_acquire(struct inode *inode)
 
 void bd_forget(struct inode *inode)
 {
+	struct block_device *bdev = NULL;
+
 	spin_lock(&bdev_lock);
-	if (inode->i_bdev)
+	if (inode->i_bdev) {
+		if (inode->i_sb != blockdev_superblock)
+			bdev = inode->i_bdev;
 		__bd_forget(inode);
+	}
 	spin_unlock(&bdev_lock);
+
+	if (bdev)
+		iput(bdev->bd_inode);
 }
 
 int bd_claim(struct block_device *bdev, void *holder)

commit 7f9c51f0d9783c78db5c2aa16806d0c256ac667f
Author: Jens Axboe <axboe@suse.de>
Date:   Mon May 1 19:59:32 2006 +0200

    [PATCH] Add ->splice_read/splice_write to def_blk_fops
    
    It can use the generic handlers.
    
    Signed-off-by: Jens Axboe <axboe@suse.de>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index af88c43043d5..f5958f413bd1 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1104,6 +1104,8 @@ const struct file_operations def_blk_fops = {
 	.readv		= generic_file_readv,
 	.writev		= generic_file_write_nolock,
 	.sendfile	= generic_file_sendfile,
+	.splice_read	= generic_file_splice_read,
+	.splice_write	= generic_file_splice_write,
 };
 
 int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)

commit 4b6f5d20b04dcbc3d888555522b90ba6d36c4106
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Tue Mar 28 01:56:42 2006 -0800

    [PATCH] Make most file operations structs in fs/ const
    
    This is a conversion to make the various file_operations structs in fs/
    const.  Basically a regexp job, with a few manual fixups
    
    The goal is both to increase correctness (harder to accidentally write to
    shared datastructures) and reducing the false sharing of cachelines with
    things that get dirty in .data (while .rodata is nicely read only and thus
    cache clean)
    
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 17c76182f389..af88c43043d5 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1087,7 +1087,7 @@ struct address_space_operations def_blk_aops = {
 	.direct_IO	= blkdev_direct_IO,
 };
 
-struct file_operations def_blk_fops = {
+const struct file_operations def_blk_fops = {
 	.open		= blkdev_open,
 	.release	= blkdev_close,
 	.llseek		= block_llseek,

commit b4cf1b72eec0e197257a5b07dc9ec53552cdd123
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Mon Mar 27 01:18:00 2006 -0800

    [PATCH] dm/md dependency tree in sysfs: convert bd_sem to bd_mutex
    
    Convert bd_sem to bd_mutex
    
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 3f36df7e037c..17c76182f389 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -723,11 +723,11 @@ static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
 	if (!bo)
 		return -ENOMEM;
 
-	down(&bdev->bd_sem);
+	mutex_lock(&bdev->bd_mutex);
 	res = bd_claim(bdev, holder);
 	if (res || !add_bd_holder(bdev, bo))
 		free_bd_holder(bo);
-	up(&bdev->bd_sem);
+	mutex_unlock(&bdev->bd_mutex);
 
 	return res;
 }
@@ -748,11 +748,11 @@ static void bd_release_from_kobject(struct block_device *bdev,
 	if (!kobj)
 		return;
 
-	down(&bdev->bd_sem);
+	mutex_lock(&bdev->bd_mutex);
 	bd_release(bdev);
 	if ((bo = del_bd_holder(bdev, kobj)))
 		free_bd_holder(bo);
-	up(&bdev->bd_sem);
+	mutex_unlock(&bdev->bd_mutex);
 }
 
 /**

commit 641dc636b0475582e48584340b774bd1e90d40d9
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Mon Mar 27 01:17:57 2006 -0800

    [PATCH] dm/md dependency tree in sysfs: bd_claim_by_kobject
    
    Adding bd_claim_by_kobject() function which takes kobject as additional
    signature of holder device and creates sysfs symlinks between holder device
    and claimed device.  bd_release_from_kobject() is a counterpart of
    bd_claim_by_kobject.
    
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 5983d42df015..3f36df7e037c 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -266,6 +266,9 @@ static void init_once(void * foo, kmem_cache_t * cachep, unsigned long flags)
 		mutex_init(&bdev->bd_mount_mutex);
 		INIT_LIST_HEAD(&bdev->bd_inodes);
 		INIT_LIST_HEAD(&bdev->bd_list);
+#ifdef CONFIG_SYSFS
+		INIT_LIST_HEAD(&bdev->bd_holder_list);
+#endif
 		inode_init_once(&ei->vfs_inode);
 	}
 }
@@ -490,6 +493,300 @@ void bd_release(struct block_device *bdev)
 
 EXPORT_SYMBOL(bd_release);
 
+#ifdef CONFIG_SYSFS
+/*
+ * Functions for bd_claim_by_kobject / bd_release_from_kobject
+ *
+ *     If a kobject is passed to bd_claim_by_kobject()
+ *     and the kobject has a parent directory,
+ *     following symlinks are created:
+ *        o from the kobject to the claimed bdev
+ *        o from "holders" directory of the bdev to the parent of the kobject
+ *     bd_release_from_kobject() removes these symlinks.
+ *
+ *     Example:
+ *        If /dev/dm-0 maps to /dev/sda, kobject corresponding to
+ *        /sys/block/dm-0/slaves is passed to bd_claim_by_kobject(), then:
+ *           /sys/block/dm-0/slaves/sda --> /sys/block/sda
+ *           /sys/block/sda/holders/dm-0 --> /sys/block/dm-0
+ */
+
+static struct kobject *bdev_get_kobj(struct block_device *bdev)
+{
+	if (bdev->bd_contains != bdev)
+		return kobject_get(&bdev->bd_part->kobj);
+	else
+		return kobject_get(&bdev->bd_disk->kobj);
+}
+
+static struct kobject *bdev_get_holder(struct block_device *bdev)
+{
+	if (bdev->bd_contains != bdev)
+		return kobject_get(bdev->bd_part->holder_dir);
+	else
+		return kobject_get(bdev->bd_disk->holder_dir);
+}
+
+static void add_symlink(struct kobject *from, struct kobject *to)
+{
+	if (!from || !to)
+		return;
+	sysfs_create_link(from, to, kobject_name(to));
+}
+
+static void del_symlink(struct kobject *from, struct kobject *to)
+{
+	if (!from || !to)
+		return;
+	sysfs_remove_link(from, kobject_name(to));
+}
+
+/*
+ * 'struct bd_holder' contains pointers to kobjects symlinked by
+ * bd_claim_by_kobject.
+ * It's connected to bd_holder_list which is protected by bdev->bd_sem.
+ */
+struct bd_holder {
+	struct list_head list;	/* chain of holders of the bdev */
+	int count;		/* references from the holder */
+	struct kobject *sdir;	/* holder object, e.g. "/block/dm-0/slaves" */
+	struct kobject *hdev;	/* e.g. "/block/dm-0" */
+	struct kobject *hdir;	/* e.g. "/block/sda/holders" */
+	struct kobject *sdev;	/* e.g. "/block/sda" */
+};
+
+/*
+ * Get references of related kobjects at once.
+ * Returns 1 on success. 0 on failure.
+ *
+ * Should call bd_holder_release_dirs() after successful use.
+ */
+static int bd_holder_grab_dirs(struct block_device *bdev,
+			struct bd_holder *bo)
+{
+	if (!bdev || !bo)
+		return 0;
+
+	bo->sdir = kobject_get(bo->sdir);
+	if (!bo->sdir)
+		return 0;
+
+	bo->hdev = kobject_get(bo->sdir->parent);
+	if (!bo->hdev)
+		goto fail_put_sdir;
+
+	bo->sdev = bdev_get_kobj(bdev);
+	if (!bo->sdev)
+		goto fail_put_hdev;
+
+	bo->hdir = bdev_get_holder(bdev);
+	if (!bo->hdir)
+		goto fail_put_sdev;
+
+	return 1;
+
+fail_put_sdev:
+	kobject_put(bo->sdev);
+fail_put_hdev:
+	kobject_put(bo->hdev);
+fail_put_sdir:
+	kobject_put(bo->sdir);
+
+	return 0;
+}
+
+/* Put references of related kobjects at once. */
+static void bd_holder_release_dirs(struct bd_holder *bo)
+{
+	kobject_put(bo->hdir);
+	kobject_put(bo->sdev);
+	kobject_put(bo->hdev);
+	kobject_put(bo->sdir);
+}
+
+static struct bd_holder *alloc_bd_holder(struct kobject *kobj)
+{
+	struct bd_holder *bo;
+
+	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
+	if (!bo)
+		return NULL;
+
+	bo->count = 1;
+	bo->sdir = kobj;
+
+	return bo;
+}
+
+static void free_bd_holder(struct bd_holder *bo)
+{
+	kfree(bo);
+}
+
+/**
+ * add_bd_holder - create sysfs symlinks for bd_claim() relationship
+ *
+ * @bdev:	block device to be bd_claimed
+ * @bo:		preallocated and initialized by alloc_bd_holder()
+ *
+ * If there is no matching entry with @bo in @bdev->bd_holder_list,
+ * add @bo to the list, create symlinks.
+ *
+ * Returns 1 if @bo was added to the list.
+ * Returns 0 if @bo wasn't used by any reason and should be freed.
+ */
+static int add_bd_holder(struct block_device *bdev, struct bd_holder *bo)
+{
+	struct bd_holder *tmp;
+
+	if (!bo)
+		return 0;
+
+	list_for_each_entry(tmp, &bdev->bd_holder_list, list) {
+		if (tmp->sdir == bo->sdir) {
+			tmp->count++;
+			return 0;
+		}
+	}
+
+	if (!bd_holder_grab_dirs(bdev, bo))
+		return 0;
+
+	add_symlink(bo->sdir, bo->sdev);
+	add_symlink(bo->hdir, bo->hdev);
+	list_add_tail(&bo->list, &bdev->bd_holder_list);
+	return 1;
+}
+
+/**
+ * del_bd_holder - delete sysfs symlinks for bd_claim() relationship
+ *
+ * @bdev:	block device to be bd_claimed
+ * @kobj:	holder's kobject
+ *
+ * If there is matching entry with @kobj in @bdev->bd_holder_list
+ * and no other bd_claim() from the same kobject,
+ * remove the struct bd_holder from the list, delete symlinks for it.
+ *
+ * Returns a pointer to the struct bd_holder when it's removed from the list
+ * and ready to be freed.
+ * Returns NULL if matching claim isn't found or there is other bd_claim()
+ * by the same kobject.
+ */
+static struct bd_holder *del_bd_holder(struct block_device *bdev,
+					struct kobject *kobj)
+{
+	struct bd_holder *bo;
+
+	list_for_each_entry(bo, &bdev->bd_holder_list, list) {
+		if (bo->sdir == kobj) {
+			bo->count--;
+			BUG_ON(bo->count < 0);
+			if (!bo->count) {
+				list_del(&bo->list);
+				del_symlink(bo->sdir, bo->sdev);
+				del_symlink(bo->hdir, bo->hdev);
+				bd_holder_release_dirs(bo);
+				return bo;
+			}
+			break;
+		}
+	}
+
+	return NULL;
+}
+
+/**
+ * bd_claim_by_kobject - bd_claim() with additional kobject signature
+ *
+ * @bdev:	block device to be claimed
+ * @holder:	holder's signature
+ * @kobj:	holder's kobject
+ *
+ * Do bd_claim() and if it succeeds, create sysfs symlinks between
+ * the bdev and the holder's kobject.
+ * Use bd_release_from_kobject() when relesing the claimed bdev.
+ *
+ * Returns 0 on success. (same as bd_claim())
+ * Returns errno on failure.
+ */
+static int bd_claim_by_kobject(struct block_device *bdev, void *holder,
+				struct kobject *kobj)
+{
+	int res;
+	struct bd_holder *bo;
+
+	if (!kobj)
+		return -EINVAL;
+
+	bo = alloc_bd_holder(kobj);
+	if (!bo)
+		return -ENOMEM;
+
+	down(&bdev->bd_sem);
+	res = bd_claim(bdev, holder);
+	if (res || !add_bd_holder(bdev, bo))
+		free_bd_holder(bo);
+	up(&bdev->bd_sem);
+
+	return res;
+}
+
+/**
+ * bd_release_from_kobject - bd_release() with additional kobject signature
+ *
+ * @bdev:	block device to be released
+ * @kobj:	holder's kobject
+ *
+ * Do bd_release() and remove sysfs symlinks created by bd_claim_by_kobject().
+ */
+static void bd_release_from_kobject(struct block_device *bdev,
+					struct kobject *kobj)
+{
+	struct bd_holder *bo;
+
+	if (!kobj)
+		return;
+
+	down(&bdev->bd_sem);
+	bd_release(bdev);
+	if ((bo = del_bd_holder(bdev, kobj)))
+		free_bd_holder(bo);
+	up(&bdev->bd_sem);
+}
+
+/**
+ * bd_claim_by_disk - wrapper function for bd_claim_by_kobject()
+ *
+ * @bdev:	block device to be claimed
+ * @holder:	holder's signature
+ * @disk:	holder's gendisk
+ *
+ * Call bd_claim_by_kobject() with getting @disk->slave_dir.
+ */
+int bd_claim_by_disk(struct block_device *bdev, void *holder,
+			struct gendisk *disk)
+{
+	return bd_claim_by_kobject(bdev, holder, kobject_get(disk->slave_dir));
+}
+EXPORT_SYMBOL_GPL(bd_claim_by_disk);
+
+/**
+ * bd_release_from_disk - wrapper function for bd_release_from_kobject()
+ *
+ * @bdev:	block device to be claimed
+ * @disk:	holder's gendisk
+ *
+ * Call bd_release_from_kobject() and put @disk->slave_dir.
+ */
+void bd_release_from_disk(struct block_device *bdev, struct gendisk *disk)
+{
+	bd_release_from_kobject(bdev, disk->slave_dir);
+	kobject_put(disk->slave_dir);
+}
+EXPORT_SYMBOL_GPL(bd_release_from_disk);
+#endif
+
 /*
  * Tries to open block device by device number.  Use it ONLY if you
  * really do not have anything better - i.e. when you are behind a

commit 1d8fa7a2b9a39d18727acc5c468e870df606c852
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sun Mar 26 01:38:02 2006 -0800

    [PATCH] remove ->get_blocks() support
    
    Now that get_block() can handle mapping multiple disk blocks, no need to have
    ->get_blocks().  This patch removes fs specific ->get_blocks() added for DIO
    and makes it users use get_block() instead.
    
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 9a451a9ffad4..5983d42df015 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -131,9 +131,10 @@ blkdev_get_block(struct inode *inode, sector_t iblock,
 
 static int
 blkdev_get_blocks(struct inode *inode, sector_t iblock,
-		unsigned long max_blocks, struct buffer_head *bh, int create)
+		struct buffer_head *bh, int create)
 {
 	sector_t end_block = max_block(I_BDEV(inode));
+	unsigned long max_blocks = bh->b_size >> inode->i_blkbits;
 
 	if ((iblock + max_blocks) > end_block) {
 		max_blocks = end_block - iblock;

commit fa3536cc144c1298f2ed9416c33f3b77fa2cd37a
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Sun Mar 26 01:37:24 2006 -0800

    [PATCH] Use __read_mostly on some hot fs variables
    
    I discovered on oprofile hunting on a SMP platform that dentry lookups were
    slowed down because d_hash_mask, d_hash_shift and dentry_hashtable were in
    a cache line that contained inodes_stat.  So each time inodes_stats is
    changed by a cpu, other cpus have to refill their cache line.
    
    This patch moves some variables to the __read_mostly section, in order to
    avoid false sharing.  RCU dentry lookups can go full speed.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 573fc8e0b67a..9a451a9ffad4 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -234,7 +234,7 @@ static int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
  */
 
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(bdev_lock);
-static kmem_cache_t * bdev_cachep;
+static kmem_cache_t * bdev_cachep __read_mostly;
 
 static struct inode *bdev_alloc_inode(struct super_block *sb)
 {
@@ -308,7 +308,7 @@ static struct file_system_type bd_type = {
 	.kill_sb	= kill_anon_super,
 };
 
-static struct vfsmount *bd_mnt;
+static struct vfsmount *bd_mnt __read_mostly;
 struct super_block *blockdev_superblock;
 
 void __init bdev_cache_init(void)

commit 38885bd4c2a4b59ddb22271d3e6c621859c76f02
Author: Coywolf Qi Hunt <qiyong@fc-cn.com>
Date:   Fri Mar 24 03:18:05 2006 -0800

    [PATCH] sb_set_blocksize cleanup
    
    sb_set_blocksize() cleanup: make sb_set_blocksize() use blksize_bits().
    
    Signed-off-by: Coywolf Qi Hunt <qiyong@fc-cn.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 2d096057ab53..573fc8e0b67a 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -86,16 +86,12 @@ EXPORT_SYMBOL(set_blocksize);
 
 int sb_set_blocksize(struct super_block *sb, int size)
 {
-	int bits = 9; /* 2^9 = 512 */
-
 	if (set_blocksize(sb->s_bdev, size))
 		return 0;
 	/* If we get here, we know size is power of two
 	 * and it's value is between 512 and PAGE_SIZE */
 	sb->s_blocksize = size;
-	for (size >>= 10; size; size >>= 1)
-		++bits;
-	sb->s_blocksize_bits = bits;
+	sb->s_blocksize_bits = blksize_bits(size);
 	return sb->s_blocksize;
 }
 

commit fffb60f93ce5880aade88e01d7133b52a4879710
Author: Paul Jackson <pj@sgi.com>
Date:   Fri Mar 24 03:16:06 2006 -0800

    [PATCH] cpuset memory spread: slab cache format
    
    Rewrap the overly long source code lines resulting from the previous
    patch's addition of the slab cache flag SLAB_MEM_SPREAD.  This patch
    contains only formatting changes, and no function change.
    
    Signed-off-by: Paul Jackson <pj@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 80f97729e57f..2d096057ab53 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -319,7 +319,8 @@ void __init bdev_cache_init(void)
 {
 	int err;
 	bdev_cachep = kmem_cache_create("bdev_cache", sizeof(struct bdev_inode),
-			0, SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|SLAB_MEM_SPREAD|SLAB_PANIC,
+			0, (SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|
+				SLAB_MEM_SPREAD|SLAB_PANIC),
 			init_once, NULL);
 	err = register_filesystem(&bd_type);
 	if (err)

commit 4b6a9316fab51af611dc8671f296734089f6a22a
Author: Paul Jackson <pj@sgi.com>
Date:   Fri Mar 24 03:16:05 2006 -0800

    [PATCH] cpuset memory spread: slab cache filesystems
    
    Mark file system inode and similar slab caches subject to SLAB_MEM_SPREAD
    memory spreading.
    
    If a slab cache is marked SLAB_MEM_SPREAD, then anytime that a task that's
    in a cpuset with the 'memory_spread_slab' option enabled goes to allocate
    from such a slab cache, the allocations are spread evenly over all the
    memory nodes (task->mems_allowed) allowed to that task, instead of favoring
    allocation on the node local to the current cpu.
    
    The following inode and similar caches are marked SLAB_MEM_SPREAD:
    
        file                               cache
        ====                               =====
        fs/adfs/super.c                    adfs_inode_cache
        fs/affs/super.c                    affs_inode_cache
        fs/befs/linuxvfs.c                 befs_inode_cache
        fs/bfs/inode.c                     bfs_inode_cache
        fs/block_dev.c                     bdev_cache
        fs/cifs/cifsfs.c                   cifs_inode_cache
        fs/coda/inode.c                    coda_inode_cache
        fs/dquot.c                         dquot
        fs/efs/super.c                     efs_inode_cache
        fs/ext2/super.c                    ext2_inode_cache
        fs/ext2/xattr.c (fs/mbcache.c)     ext2_xattr
        fs/ext3/super.c                    ext3_inode_cache
        fs/ext3/xattr.c (fs/mbcache.c)     ext3_xattr
        fs/fat/cache.c                     fat_cache
        fs/fat/inode.c                     fat_inode_cache
        fs/freevxfs/vxfs_super.c           vxfs_inode
        fs/hpfs/super.c                    hpfs_inode_cache
        fs/isofs/inode.c                   isofs_inode_cache
        fs/jffs/inode-v23.c                jffs_fm
        fs/jffs2/super.c                   jffs2_i
        fs/jfs/super.c                     jfs_ip
        fs/minix/inode.c                   minix_inode_cache
        fs/ncpfs/inode.c                   ncp_inode_cache
        fs/nfs/direct.c                    nfs_direct_cache
        fs/nfs/inode.c                     nfs_inode_cache
        fs/ntfs/super.c                    ntfs_big_inode_cache_name
        fs/ntfs/super.c                    ntfs_inode_cache
        fs/ocfs2/dlm/dlmfs.c               dlmfs_inode_cache
        fs/ocfs2/super.c                   ocfs2_inode_cache
        fs/proc/inode.c                    proc_inode_cache
        fs/qnx4/inode.c                    qnx4_inode_cache
        fs/reiserfs/super.c                reiser_inode_cache
        fs/romfs/inode.c                   romfs_inode_cache
        fs/smbfs/inode.c                   smb_inode_cache
        fs/sysv/inode.c                    sysv_inode_cache
        fs/udf/super.c                     udf_inode_cache
        fs/ufs/super.c                     ufs_inode_cache
        net/socket.c                       sock_inode_cache
        net/sunrpc/rpc_pipe.c              rpc_inode_cache
    
    The choice of which slab caches to so mark was quite simple.  I marked
    those already marked SLAB_RECLAIM_ACCOUNT, except for fs/xfs, dentry_cache,
    inode_cache, and buffer_head, which were marked in a previous patch.  Even
    though SLAB_RECLAIM_ACCOUNT is for a different purpose, it marks the same
    potentially large file system i/o related slab caches as we need for memory
    spreading.
    
    Given that the rule now becomes "wherever you would have used a
    SLAB_RECLAIM_ACCOUNT slab cache flag before (usually the inode cache), use
    the SLAB_MEM_SPREAD flag too", this should be easy enough to maintain.
    Future file system writers will just copy one of the existing file system
    slab cache setups and tend to get it right without thinking.
    
    Signed-off-by: Paul Jackson <pj@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 44d05e6e34db..80f97729e57f 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -319,7 +319,7 @@ void __init bdev_cache_init(void)
 {
 	int err;
 	bdev_cachep = kmem_cache_create("bdev_cache", sizeof(struct bdev_inode),
-			0, SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|SLAB_PANIC,
+			0, SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|SLAB_MEM_SPREAD|SLAB_PANIC,
 			init_once, NULL);
 	err = register_filesystem(&bd_type);
 	if (err)

commit c039e3134ae62863bbc8e8429b29e3c43cf21b2a
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Thu Mar 23 03:00:28 2006 -0800

    [PATCH] sem2mutex: blockdev #2
    
    Semaphore to mutex conversion.
    
    The conversion was generated via scripts, and the result was validated
    automatically via a script as well.
    
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Jens Axboe <axboe@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index 6e50346fb1ee..44d05e6e34db 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -265,8 +265,8 @@ static void init_once(void * foo, kmem_cache_t * cachep, unsigned long flags)
 	    SLAB_CTOR_CONSTRUCTOR)
 	{
 		memset(bdev, 0, sizeof(*bdev));
-		sema_init(&bdev->bd_sem, 1);
-		sema_init(&bdev->bd_mount_sem, 1);
+		mutex_init(&bdev->bd_mutex);
+		mutex_init(&bdev->bd_mount_mutex);
 		INIT_LIST_HEAD(&bdev->bd_inodes);
 		INIT_LIST_HEAD(&bdev->bd_list);
 		inode_init_once(&ei->vfs_inode);
@@ -574,7 +574,7 @@ static int do_open(struct block_device *bdev, struct file *file)
 	}
 	owner = disk->fops->owner;
 
-	down(&bdev->bd_sem);
+	mutex_lock(&bdev->bd_mutex);
 	if (!bdev->bd_openers) {
 		bdev->bd_disk = disk;
 		bdev->bd_contains = bdev;
@@ -605,21 +605,21 @@ static int do_open(struct block_device *bdev, struct file *file)
 			if (ret)
 				goto out_first;
 			bdev->bd_contains = whole;
-			down(&whole->bd_sem);
+			mutex_lock(&whole->bd_mutex);
 			whole->bd_part_count++;
 			p = disk->part[part - 1];
 			bdev->bd_inode->i_data.backing_dev_info =
 			   whole->bd_inode->i_data.backing_dev_info;
 			if (!(disk->flags & GENHD_FL_UP) || !p || !p->nr_sects) {
 				whole->bd_part_count--;
-				up(&whole->bd_sem);
+				mutex_unlock(&whole->bd_mutex);
 				ret = -ENXIO;
 				goto out_first;
 			}
 			kobject_get(&p->kobj);
 			bdev->bd_part = p;
 			bd_set_size(bdev, (loff_t) p->nr_sects << 9);
-			up(&whole->bd_sem);
+			mutex_unlock(&whole->bd_mutex);
 		}
 	} else {
 		put_disk(disk);
@@ -633,13 +633,13 @@ static int do_open(struct block_device *bdev, struct file *file)
 			if (bdev->bd_invalidated)
 				rescan_partitions(bdev->bd_disk, bdev);
 		} else {
-			down(&bdev->bd_contains->bd_sem);
+			mutex_lock(&bdev->bd_contains->bd_mutex);
 			bdev->bd_contains->bd_part_count++;
-			up(&bdev->bd_contains->bd_sem);
+			mutex_unlock(&bdev->bd_contains->bd_mutex);
 		}
 	}
 	bdev->bd_openers++;
-	up(&bdev->bd_sem);
+	mutex_unlock(&bdev->bd_mutex);
 	unlock_kernel();
 	return 0;
 
@@ -652,7 +652,7 @@ static int do_open(struct block_device *bdev, struct file *file)
 	put_disk(disk);
 	module_put(owner);
 out:
-	up(&bdev->bd_sem);
+	mutex_unlock(&bdev->bd_mutex);
 	unlock_kernel();
 	if (ret)
 		bdput(bdev);
@@ -714,7 +714,7 @@ int blkdev_put(struct block_device *bdev)
 	struct inode *bd_inode = bdev->bd_inode;
 	struct gendisk *disk = bdev->bd_disk;
 
-	down(&bdev->bd_sem);
+	mutex_lock(&bdev->bd_mutex);
 	lock_kernel();
 	if (!--bdev->bd_openers) {
 		sync_blockdev(bdev);
@@ -724,9 +724,9 @@ int blkdev_put(struct block_device *bdev)
 		if (disk->fops->release)
 			ret = disk->fops->release(bd_inode, NULL);
 	} else {
-		down(&bdev->bd_contains->bd_sem);
+		mutex_lock(&bdev->bd_contains->bd_mutex);
 		bdev->bd_contains->bd_part_count--;
-		up(&bdev->bd_contains->bd_sem);
+		mutex_unlock(&bdev->bd_contains->bd_mutex);
 	}
 	if (!bdev->bd_openers) {
 		struct module *owner = disk->fops->owner;
@@ -746,7 +746,7 @@ int blkdev_put(struct block_device *bdev)
 		bdev->bd_contains = NULL;
 	}
 	unlock_kernel();
-	up(&bdev->bd_sem);
+	mutex_unlock(&bdev->bd_mutex);
 	bdput(bdev);
 	return ret;
 }

commit 1b1dcc1b57a49136f118a0f16367256ff9994a69
Author: Jes Sorensen <jes@sgi.com>
Date:   Mon Jan 9 15:59:24 2006 -0800

    [PATCH] mutex subsystem, semaphore to mutex: VFS, ->i_sem
    
    This patch converts the inode semaphore to a mutex. I have tested it on
    XFS and compiled as much as one can consider on an ia64. Anyway your
    luck with it might be different.
    
    Modified-by: Ingo Molnar <mingo@elte.hu>
    
    (finished the conversion)
    
    Signed-off-by: Jes Sorensen <jes@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index e0df94c37b7e..6e50346fb1ee 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -202,7 +202,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
 	loff_t size;
 	loff_t retval;
 
-	down(&bd_inode->i_sem);
+	mutex_lock(&bd_inode->i_mutex);
 	size = i_size_read(bd_inode);
 
 	switch (origin) {
@@ -219,7 +219,7 @@ static loff_t block_llseek(struct file *file, loff_t offset, int origin)
 		}
 		retval = offset;
 	}
-	up(&bd_inode->i_sem);
+	mutex_unlock(&bd_inode->i_mutex);
 	return retval;
 }
 	

commit bb93e3a52f8db7210258a1a2134cced0b78a46e1
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Jun 23 00:10:15 2005 -0700

    [PATCH] block: add unlocked_ioctl support for block devices
    
    This patch allows block device drivers to convert their ioctl functions to
    unlocked_ioctl() like character devices and other subsystems.  All
    functions that were called with the BKL held before are still used that
    way, but I would not be surprised if it could be removed from the ioctl
    functions in drivers/block/ioctl.c themselves.
    
    As a side note, I found that compat_blkdev_ioctl() acquires the BKL as
    well, which looks like a bug.  I have checked that every user of
    disk->fops->compat_ioctl() in the current git tree gets the BKL itself, so
    it could easily be removed from compat_blkdev_ioctl().
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index c0cbd1bc1a02..e0df94c37b7e 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -777,8 +777,7 @@ static ssize_t blkdev_file_aio_write(struct kiocb *iocb, const char __user *buf,
 	return generic_file_aio_write_nolock(iocb, &local_iov, 1, &iocb->ki_pos);
 }
 
-static int block_ioctl(struct inode *inode, struct file *file, unsigned cmd,
-			unsigned long arg)
+static long block_ioctl(struct file *file, unsigned cmd, unsigned long arg)
 {
 	return blkdev_ioctl(file->f_mapping->host, file, cmd, arg);
 }
@@ -803,7 +802,7 @@ struct file_operations def_blk_fops = {
   	.aio_write	= blkdev_file_aio_write, 
 	.mmap		= generic_file_mmap,
 	.fsync		= block_fsync,
-	.ioctl		= block_ioctl,
+	.unlocked_ioctl	= block_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl	= compat_blkdev_ioctl,
 #endif

commit 2ef41634def0fcb0def3e3c90220c651ca478cb3
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu May 5 16:15:59 2005 -0700

    [PATCH] remove do_sync parameter from __invalidate_device
    
    The only caller that ever sets it can call fsync_bdev itself easily.  Also
    update some comments.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: <viro@parcelfarce.linux.theplanet.co.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/block_dev.c b/fs/block_dev.c
index d19d07c49ad3..c0cbd1bc1a02 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -530,7 +530,7 @@ int check_disk_change(struct block_device *bdev)
 	if (!bdops->media_changed(bdev->bd_disk))
 		return 0;
 
-	if (__invalidate_device(bdev, 0))
+	if (__invalidate_device(bdev))
 		printk("VFS: busy inodes on changed media.\n");
 
 	if (bdops->revalidate_disk)

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/fs/block_dev.c b/fs/block_dev.c
new file mode 100644
index 000000000000..d19d07c49ad3
--- /dev/null
+++ b/fs/block_dev.c
@@ -0,0 +1,923 @@
+/*
+ *  linux/fs/block_dev.c
+ *
+ *  Copyright (C) 1991, 1992  Linus Torvalds
+ *  Copyright (C) 2001  Andrea Arcangeli <andrea@suse.de> SuSE
+ */
+
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/fcntl.h>
+#include <linux/slab.h>
+#include <linux/kmod.h>
+#include <linux/major.h>
+#include <linux/devfs_fs_kernel.h>
+#include <linux/smp_lock.h>
+#include <linux/highmem.h>
+#include <linux/blkdev.h>
+#include <linux/module.h>
+#include <linux/blkpg.h>
+#include <linux/buffer_head.h>
+#include <linux/mpage.h>
+#include <linux/mount.h>
+#include <linux/uio.h>
+#include <linux/namei.h>
+#include <asm/uaccess.h>
+
+struct bdev_inode {
+	struct block_device bdev;
+	struct inode vfs_inode;
+};
+
+static inline struct bdev_inode *BDEV_I(struct inode *inode)
+{
+	return container_of(inode, struct bdev_inode, vfs_inode);
+}
+
+inline struct block_device *I_BDEV(struct inode *inode)
+{
+	return &BDEV_I(inode)->bdev;
+}
+
+EXPORT_SYMBOL(I_BDEV);
+
+static sector_t max_block(struct block_device *bdev)
+{
+	sector_t retval = ~((sector_t)0);
+	loff_t sz = i_size_read(bdev->bd_inode);
+
+	if (sz) {
+		unsigned int size = block_size(bdev);
+		unsigned int sizebits = blksize_bits(size);
+		retval = (sz >> sizebits);
+	}
+	return retval;
+}
+
+/* Kill _all_ buffers, dirty or not.. */
+static void kill_bdev(struct block_device *bdev)
+{
+	invalidate_bdev(bdev, 1);
+	truncate_inode_pages(bdev->bd_inode->i_mapping, 0);
+}	
+
+int set_blocksize(struct block_device *bdev, int size)
+{
+	/* Size must be a power of two, and between 512 and PAGE_SIZE */
+	if (size > PAGE_SIZE || size < 512 || (size & (size-1)))
+		return -EINVAL;
+
+	/* Size cannot be smaller than the size supported by the device */
+	if (size < bdev_hardsect_size(bdev))
+		return -EINVAL;
+
+	/* Don't change the size if it is same as current */
+	if (bdev->bd_block_size != size) {
+		sync_blockdev(bdev);
+		bdev->bd_block_size = size;
+		bdev->bd_inode->i_blkbits = blksize_bits(size);
+		kill_bdev(bdev);
+	}
+	return 0;
+}
+
+EXPORT_SYMBOL(set_blocksize);
+
+int sb_set_blocksize(struct super_block *sb, int size)
+{
+	int bits = 9; /* 2^9 = 512 */
+
+	if (set_blocksize(sb->s_bdev, size))
+		return 0;
+	/* If we get here, we know size is power of two
+	 * and it's value is between 512 and PAGE_SIZE */
+	sb->s_blocksize = size;
+	for (size >>= 10; size; size >>= 1)
+		++bits;
+	sb->s_blocksize_bits = bits;
+	return sb->s_blocksize;
+}
+
+EXPORT_SYMBOL(sb_set_blocksize);
+
+int sb_min_blocksize(struct super_block *sb, int size)
+{
+	int minsize = bdev_hardsect_size(sb->s_bdev);
+	if (size < minsize)
+		size = minsize;
+	return sb_set_blocksize(sb, size);
+}
+
+EXPORT_SYMBOL(sb_min_blocksize);
+
+static int
+blkdev_get_block(struct inode *inode, sector_t iblock,
+		struct buffer_head *bh, int create)
+{
+	if (iblock >= max_block(I_BDEV(inode))) {
+		if (create)
+			return -EIO;
+
+		/*
+		 * for reads, we're just trying to fill a partial page.
+		 * return a hole, they will have to call get_block again
+		 * before they can fill it, and they will get -EIO at that
+		 * time
+		 */
+		return 0;
+	}
+	bh->b_bdev = I_BDEV(inode);
+	bh->b_blocknr = iblock;
+	set_buffer_mapped(bh);
+	return 0;
+}
+
+static int
+blkdev_get_blocks(struct inode *inode, sector_t iblock,
+		unsigned long max_blocks, struct buffer_head *bh, int create)
+{
+	sector_t end_block = max_block(I_BDEV(inode));
+
+	if ((iblock + max_blocks) > end_block) {
+		max_blocks = end_block - iblock;
+		if ((long)max_blocks <= 0) {
+			if (create)
+				return -EIO;	/* write fully beyond EOF */
+			/*
+			 * It is a read which is fully beyond EOF.  We return
+			 * a !buffer_mapped buffer
+			 */
+			max_blocks = 0;
+		}
+	}
+
+	bh->b_bdev = I_BDEV(inode);
+	bh->b_blocknr = iblock;
+	bh->b_size = max_blocks << inode->i_blkbits;
+	if (max_blocks)
+		set_buffer_mapped(bh);
+	return 0;
+}
+
+static ssize_t
+blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
+			loff_t offset, unsigned long nr_segs)
+{
+	struct file *file = iocb->ki_filp;
+	struct inode *inode = file->f_mapping->host;
+
+	return blockdev_direct_IO_no_locking(rw, iocb, inode, I_BDEV(inode),
+				iov, offset, nr_segs, blkdev_get_blocks, NULL);
+}
+
+static int blkdev_writepage(struct page *page, struct writeback_control *wbc)
+{
+	return block_write_full_page(page, blkdev_get_block, wbc);
+}
+
+static int blkdev_readpage(struct file * file, struct page * page)
+{
+	return block_read_full_page(page, blkdev_get_block);
+}
+
+static int blkdev_prepare_write(struct file *file, struct page *page, unsigned from, unsigned to)
+{
+	return block_prepare_write(page, from, to, blkdev_get_block);
+}
+
+static int blkdev_commit_write(struct file *file, struct page *page, unsigned from, unsigned to)
+{
+	return block_commit_write(page, from, to);
+}
+
+/*
+ * private llseek:
+ * for a block special file file->f_dentry->d_inode->i_size is zero
+ * so we compute the size by hand (just as in block_read/write above)
+ */
+static loff_t block_llseek(struct file *file, loff_t offset, int origin)
+{
+	struct inode *bd_inode = file->f_mapping->host;
+	loff_t size;
+	loff_t retval;
+
+	down(&bd_inode->i_sem);
+	size = i_size_read(bd_inode);
+
+	switch (origin) {
+		case 2:
+			offset += size;
+			break;
+		case 1:
+			offset += file->f_pos;
+	}
+	retval = -EINVAL;
+	if (offset >= 0 && offset <= size) {
+		if (offset != file->f_pos) {
+			file->f_pos = offset;
+		}
+		retval = offset;
+	}
+	up(&bd_inode->i_sem);
+	return retval;
+}
+	
+/*
+ *	Filp is never NULL; the only case when ->fsync() is called with
+ *	NULL first argument is nfsd_sync_dir() and that's not a directory.
+ */
+ 
+static int block_fsync(struct file *filp, struct dentry *dentry, int datasync)
+{
+	return sync_blockdev(I_BDEV(filp->f_mapping->host));
+}
+
+/*
+ * pseudo-fs
+ */
+
+static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(bdev_lock);
+static kmem_cache_t * bdev_cachep;
+
+static struct inode *bdev_alloc_inode(struct super_block *sb)
+{
+	struct bdev_inode *ei = kmem_cache_alloc(bdev_cachep, SLAB_KERNEL);
+	if (!ei)
+		return NULL;
+	return &ei->vfs_inode;
+}
+
+static void bdev_destroy_inode(struct inode *inode)
+{
+	struct bdev_inode *bdi = BDEV_I(inode);
+
+	bdi->bdev.bd_inode_backing_dev_info = NULL;
+	kmem_cache_free(bdev_cachep, bdi);
+}
+
+static void init_once(void * foo, kmem_cache_t * cachep, unsigned long flags)
+{
+	struct bdev_inode *ei = (struct bdev_inode *) foo;
+	struct block_device *bdev = &ei->bdev;
+
+	if ((flags & (SLAB_CTOR_VERIFY|SLAB_CTOR_CONSTRUCTOR)) ==
+	    SLAB_CTOR_CONSTRUCTOR)
+	{
+		memset(bdev, 0, sizeof(*bdev));
+		sema_init(&bdev->bd_sem, 1);
+		sema_init(&bdev->bd_mount_sem, 1);
+		INIT_LIST_HEAD(&bdev->bd_inodes);
+		INIT_LIST_HEAD(&bdev->bd_list);
+		inode_init_once(&ei->vfs_inode);
+	}
+}
+
+static inline void __bd_forget(struct inode *inode)
+{
+	list_del_init(&inode->i_devices);
+	inode->i_bdev = NULL;
+	inode->i_mapping = &inode->i_data;
+}
+
+static void bdev_clear_inode(struct inode *inode)
+{
+	struct block_device *bdev = &BDEV_I(inode)->bdev;
+	struct list_head *p;
+	spin_lock(&bdev_lock);
+	while ( (p = bdev->bd_inodes.next) != &bdev->bd_inodes ) {
+		__bd_forget(list_entry(p, struct inode, i_devices));
+	}
+	list_del_init(&bdev->bd_list);
+	spin_unlock(&bdev_lock);
+}
+
+static struct super_operations bdev_sops = {
+	.statfs = simple_statfs,
+	.alloc_inode = bdev_alloc_inode,
+	.destroy_inode = bdev_destroy_inode,
+	.drop_inode = generic_delete_inode,
+	.clear_inode = bdev_clear_inode,
+};
+
+static struct super_block *bd_get_sb(struct file_system_type *fs_type,
+	int flags, const char *dev_name, void *data)
+{
+	return get_sb_pseudo(fs_type, "bdev:", &bdev_sops, 0x62646576);
+}
+
+static struct file_system_type bd_type = {
+	.name		= "bdev",
+	.get_sb		= bd_get_sb,
+	.kill_sb	= kill_anon_super,
+};
+
+static struct vfsmount *bd_mnt;
+struct super_block *blockdev_superblock;
+
+void __init bdev_cache_init(void)
+{
+	int err;
+	bdev_cachep = kmem_cache_create("bdev_cache", sizeof(struct bdev_inode),
+			0, SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|SLAB_PANIC,
+			init_once, NULL);
+	err = register_filesystem(&bd_type);
+	if (err)
+		panic("Cannot register bdev pseudo-fs");
+	bd_mnt = kern_mount(&bd_type);
+	err = PTR_ERR(bd_mnt);
+	if (IS_ERR(bd_mnt))
+		panic("Cannot create bdev pseudo-fs");
+	blockdev_superblock = bd_mnt->mnt_sb;	/* For writeback */
+}
+
+/*
+ * Most likely _very_ bad one - but then it's hardly critical for small
+ * /dev and can be fixed when somebody will need really large one.
+ * Keep in mind that it will be fed through icache hash function too.
+ */
+static inline unsigned long hash(dev_t dev)
+{
+	return MAJOR(dev)+MINOR(dev);
+}
+
+static int bdev_test(struct inode *inode, void *data)
+{
+	return BDEV_I(inode)->bdev.bd_dev == *(dev_t *)data;
+}
+
+static int bdev_set(struct inode *inode, void *data)
+{
+	BDEV_I(inode)->bdev.bd_dev = *(dev_t *)data;
+	return 0;
+}
+
+static LIST_HEAD(all_bdevs);
+
+struct block_device *bdget(dev_t dev)
+{
+	struct block_device *bdev;
+	struct inode *inode;
+
+	inode = iget5_locked(bd_mnt->mnt_sb, hash(dev),
+			bdev_test, bdev_set, &dev);
+
+	if (!inode)
+		return NULL;
+
+	bdev = &BDEV_I(inode)->bdev;
+
+	if (inode->i_state & I_NEW) {
+		bdev->bd_contains = NULL;
+		bdev->bd_inode = inode;
+		bdev->bd_block_size = (1 << inode->i_blkbits);
+		bdev->bd_part_count = 0;
+		bdev->bd_invalidated = 0;
+		inode->i_mode = S_IFBLK;
+		inode->i_rdev = dev;
+		inode->i_bdev = bdev;
+		inode->i_data.a_ops = &def_blk_aops;
+		mapping_set_gfp_mask(&inode->i_data, GFP_USER);
+		inode->i_data.backing_dev_info = &default_backing_dev_info;
+		spin_lock(&bdev_lock);
+		list_add(&bdev->bd_list, &all_bdevs);
+		spin_unlock(&bdev_lock);
+		unlock_new_inode(inode);
+	}
+	return bdev;
+}
+
+EXPORT_SYMBOL(bdget);
+
+long nr_blockdev_pages(void)
+{
+	struct list_head *p;
+	long ret = 0;
+	spin_lock(&bdev_lock);
+	list_for_each(p, &all_bdevs) {
+		struct block_device *bdev;
+		bdev = list_entry(p, struct block_device, bd_list);
+		ret += bdev->bd_inode->i_mapping->nrpages;
+	}
+	spin_unlock(&bdev_lock);
+	return ret;
+}
+
+void bdput(struct block_device *bdev)
+{
+	iput(bdev->bd_inode);
+}
+
+EXPORT_SYMBOL(bdput);
+ 
+static struct block_device *bd_acquire(struct inode *inode)
+{
+	struct block_device *bdev;
+	spin_lock(&bdev_lock);
+	bdev = inode->i_bdev;
+	if (bdev && igrab(bdev->bd_inode)) {
+		spin_unlock(&bdev_lock);
+		return bdev;
+	}
+	spin_unlock(&bdev_lock);
+	bdev = bdget(inode->i_rdev);
+	if (bdev) {
+		spin_lock(&bdev_lock);
+		if (inode->i_bdev)
+			__bd_forget(inode);
+		inode->i_bdev = bdev;
+		inode->i_mapping = bdev->bd_inode->i_mapping;
+		list_add(&inode->i_devices, &bdev->bd_inodes);
+		spin_unlock(&bdev_lock);
+	}
+	return bdev;
+}
+
+/* Call when you free inode */
+
+void bd_forget(struct inode *inode)
+{
+	spin_lock(&bdev_lock);
+	if (inode->i_bdev)
+		__bd_forget(inode);
+	spin_unlock(&bdev_lock);
+}
+
+int bd_claim(struct block_device *bdev, void *holder)
+{
+	int res;
+	spin_lock(&bdev_lock);
+
+	/* first decide result */
+	if (bdev->bd_holder == holder)
+		res = 0;	 /* already a holder */
+	else if (bdev->bd_holder != NULL)
+		res = -EBUSY; 	 /* held by someone else */
+	else if (bdev->bd_contains == bdev)
+		res = 0;  	 /* is a whole device which isn't held */
+
+	else if (bdev->bd_contains->bd_holder == bd_claim)
+		res = 0; 	 /* is a partition of a device that is being partitioned */
+	else if (bdev->bd_contains->bd_holder != NULL)
+		res = -EBUSY;	 /* is a partition of a held device */
+	else
+		res = 0;	 /* is a partition of an un-held device */
+
+	/* now impose change */
+	if (res==0) {
+		/* note that for a whole device bd_holders
+		 * will be incremented twice, and bd_holder will
+		 * be set to bd_claim before being set to holder
+		 */
+		bdev->bd_contains->bd_holders ++;
+		bdev->bd_contains->bd_holder = bd_claim;
+		bdev->bd_holders++;
+		bdev->bd_holder = holder;
+	}
+	spin_unlock(&bdev_lock);
+	return res;
+}
+
+EXPORT_SYMBOL(bd_claim);
+
+void bd_release(struct block_device *bdev)
+{
+	spin_lock(&bdev_lock);
+	if (!--bdev->bd_contains->bd_holders)
+		bdev->bd_contains->bd_holder = NULL;
+	if (!--bdev->bd_holders)
+		bdev->bd_holder = NULL;
+	spin_unlock(&bdev_lock);
+}
+
+EXPORT_SYMBOL(bd_release);
+
+/*
+ * Tries to open block device by device number.  Use it ONLY if you
+ * really do not have anything better - i.e. when you are behind a
+ * truly sucky interface and all you are given is a device number.  _Never_
+ * to be used for internal purposes.  If you ever need it - reconsider
+ * your API.
+ */
+struct block_device *open_by_devnum(dev_t dev, unsigned mode)
+{
+	struct block_device *bdev = bdget(dev);
+	int err = -ENOMEM;
+	int flags = mode & FMODE_WRITE ? O_RDWR : O_RDONLY;
+	if (bdev)
+		err = blkdev_get(bdev, mode, flags);
+	return err ? ERR_PTR(err) : bdev;
+}
+
+EXPORT_SYMBOL(open_by_devnum);
+
+/*
+ * This routine checks whether a removable media has been changed,
+ * and invalidates all buffer-cache-entries in that case. This
+ * is a relatively slow routine, so we have to try to minimize using
+ * it. Thus it is called only upon a 'mount' or 'open'. This
+ * is the best way of combining speed and utility, I think.
+ * People changing diskettes in the middle of an operation deserve
+ * to lose :-)
+ */
+int check_disk_change(struct block_device *bdev)
+{
+	struct gendisk *disk = bdev->bd_disk;
+	struct block_device_operations * bdops = disk->fops;
+
+	if (!bdops->media_changed)
+		return 0;
+	if (!bdops->media_changed(bdev->bd_disk))
+		return 0;
+
+	if (__invalidate_device(bdev, 0))
+		printk("VFS: busy inodes on changed media.\n");
+
+	if (bdops->revalidate_disk)
+		bdops->revalidate_disk(bdev->bd_disk);
+	if (bdev->bd_disk->minors > 1)
+		bdev->bd_invalidated = 1;
+	return 1;
+}
+
+EXPORT_SYMBOL(check_disk_change);
+
+void bd_set_size(struct block_device *bdev, loff_t size)
+{
+	unsigned bsize = bdev_hardsect_size(bdev);
+
+	bdev->bd_inode->i_size = size;
+	while (bsize < PAGE_CACHE_SIZE) {
+		if (size & bsize)
+			break;
+		bsize <<= 1;
+	}
+	bdev->bd_block_size = bsize;
+	bdev->bd_inode->i_blkbits = blksize_bits(bsize);
+}
+EXPORT_SYMBOL(bd_set_size);
+
+static int do_open(struct block_device *bdev, struct file *file)
+{
+	struct module *owner = NULL;
+	struct gendisk *disk;
+	int ret = -ENXIO;
+	int part;
+
+	file->f_mapping = bdev->bd_inode->i_mapping;
+	lock_kernel();
+	disk = get_gendisk(bdev->bd_dev, &part);
+	if (!disk) {
+		unlock_kernel();
+		bdput(bdev);
+		return ret;
+	}
+	owner = disk->fops->owner;
+
+	down(&bdev->bd_sem);
+	if (!bdev->bd_openers) {
+		bdev->bd_disk = disk;
+		bdev->bd_contains = bdev;
+		if (!part) {
+			struct backing_dev_info *bdi;
+			if (disk->fops->open) {
+				ret = disk->fops->open(bdev->bd_inode, file);
+				if (ret)
+					goto out_first;
+			}
+			if (!bdev->bd_openers) {
+				bd_set_size(bdev,(loff_t)get_capacity(disk)<<9);
+				bdi = blk_get_backing_dev_info(bdev);
+				if (bdi == NULL)
+					bdi = &default_backing_dev_info;
+				bdev->bd_inode->i_data.backing_dev_info = bdi;
+			}
+			if (bdev->bd_invalidated)
+				rescan_partitions(disk, bdev);
+		} else {
+			struct hd_struct *p;
+			struct block_device *whole;
+			whole = bdget_disk(disk, 0);
+			ret = -ENOMEM;
+			if (!whole)
+				goto out_first;
+			ret = blkdev_get(whole, file->f_mode, file->f_flags);
+			if (ret)
+				goto out_first;
+			bdev->bd_contains = whole;
+			down(&whole->bd_sem);
+			whole->bd_part_count++;
+			p = disk->part[part - 1];
+			bdev->bd_inode->i_data.backing_dev_info =
+			   whole->bd_inode->i_data.backing_dev_info;
+			if (!(disk->flags & GENHD_FL_UP) || !p || !p->nr_sects) {
+				whole->bd_part_count--;
+				up(&whole->bd_sem);
+				ret = -ENXIO;
+				goto out_first;
+			}
+			kobject_get(&p->kobj);
+			bdev->bd_part = p;
+			bd_set_size(bdev, (loff_t) p->nr_sects << 9);
+			up(&whole->bd_sem);
+		}
+	} else {
+		put_disk(disk);
+		module_put(owner);
+		if (bdev->bd_contains == bdev) {
+			if (bdev->bd_disk->fops->open) {
+				ret = bdev->bd_disk->fops->open(bdev->bd_inode, file);
+				if (ret)
+					goto out;
+			}
+			if (bdev->bd_invalidated)
+				rescan_partitions(bdev->bd_disk, bdev);
+		} else {
+			down(&bdev->bd_contains->bd_sem);
+			bdev->bd_contains->bd_part_count++;
+			up(&bdev->bd_contains->bd_sem);
+		}
+	}
+	bdev->bd_openers++;
+	up(&bdev->bd_sem);
+	unlock_kernel();
+	return 0;
+
+out_first:
+	bdev->bd_disk = NULL;
+	bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
+	if (bdev != bdev->bd_contains)
+		blkdev_put(bdev->bd_contains);
+	bdev->bd_contains = NULL;
+	put_disk(disk);
+	module_put(owner);
+out:
+	up(&bdev->bd_sem);
+	unlock_kernel();
+	if (ret)
+		bdput(bdev);
+	return ret;
+}
+
+int blkdev_get(struct block_device *bdev, mode_t mode, unsigned flags)
+{
+	/*
+	 * This crockload is due to bad choice of ->open() type.
+	 * It will go away.
+	 * For now, block device ->open() routine must _not_
+	 * examine anything in 'inode' argument except ->i_rdev.
+	 */
+	struct file fake_file = {};
+	struct dentry fake_dentry = {};
+	fake_file.f_mode = mode;
+	fake_file.f_flags = flags;
+	fake_file.f_dentry = &fake_dentry;
+	fake_dentry.d_inode = bdev->bd_inode;
+
+	return do_open(bdev, &fake_file);
+}
+
+EXPORT_SYMBOL(blkdev_get);
+
+static int blkdev_open(struct inode * inode, struct file * filp)
+{
+	struct block_device *bdev;
+	int res;
+
+	/*
+	 * Preserve backwards compatibility and allow large file access
+	 * even if userspace doesn't ask for it explicitly. Some mkfs
+	 * binary needs it. We might want to drop this workaround
+	 * during an unstable branch.
+	 */
+	filp->f_flags |= O_LARGEFILE;
+
+	bdev = bd_acquire(inode);
+
+	res = do_open(bdev, filp);
+	if (res)
+		return res;
+
+	if (!(filp->f_flags & O_EXCL) )
+		return 0;
+
+	if (!(res = bd_claim(bdev, filp)))
+		return 0;
+
+	blkdev_put(bdev);
+	return res;
+}
+
+int blkdev_put(struct block_device *bdev)
+{
+	int ret = 0;
+	struct inode *bd_inode = bdev->bd_inode;
+	struct gendisk *disk = bdev->bd_disk;
+
+	down(&bdev->bd_sem);
+	lock_kernel();
+	if (!--bdev->bd_openers) {
+		sync_blockdev(bdev);
+		kill_bdev(bdev);
+	}
+	if (bdev->bd_contains == bdev) {
+		if (disk->fops->release)
+			ret = disk->fops->release(bd_inode, NULL);
+	} else {
+		down(&bdev->bd_contains->bd_sem);
+		bdev->bd_contains->bd_part_count--;
+		up(&bdev->bd_contains->bd_sem);
+	}
+	if (!bdev->bd_openers) {
+		struct module *owner = disk->fops->owner;
+
+		put_disk(disk);
+		module_put(owner);
+
+		if (bdev->bd_contains != bdev) {
+			kobject_put(&bdev->bd_part->kobj);
+			bdev->bd_part = NULL;
+		}
+		bdev->bd_disk = NULL;
+		bdev->bd_inode->i_data.backing_dev_info = &default_backing_dev_info;
+		if (bdev != bdev->bd_contains) {
+			blkdev_put(bdev->bd_contains);
+		}
+		bdev->bd_contains = NULL;
+	}
+	unlock_kernel();
+	up(&bdev->bd_sem);
+	bdput(bdev);
+	return ret;
+}
+
+EXPORT_SYMBOL(blkdev_put);
+
+static int blkdev_close(struct inode * inode, struct file * filp)
+{
+	struct block_device *bdev = I_BDEV(filp->f_mapping->host);
+	if (bdev->bd_holder == filp)
+		bd_release(bdev);
+	return blkdev_put(bdev);
+}
+
+static ssize_t blkdev_file_write(struct file *file, const char __user *buf,
+				   size_t count, loff_t *ppos)
+{
+	struct iovec local_iov = { .iov_base = (void __user *)buf, .iov_len = count };
+
+	return generic_file_write_nolock(file, &local_iov, 1, ppos);
+}
+
+static ssize_t blkdev_file_aio_write(struct kiocb *iocb, const char __user *buf,
+				   size_t count, loff_t pos)
+{
+	struct iovec local_iov = { .iov_base = (void __user *)buf, .iov_len = count };
+
+	return generic_file_aio_write_nolock(iocb, &local_iov, 1, &iocb->ki_pos);
+}
+
+static int block_ioctl(struct inode *inode, struct file *file, unsigned cmd,
+			unsigned long arg)
+{
+	return blkdev_ioctl(file->f_mapping->host, file, cmd, arg);
+}
+
+struct address_space_operations def_blk_aops = {
+	.readpage	= blkdev_readpage,
+	.writepage	= blkdev_writepage,
+	.sync_page	= block_sync_page,
+	.prepare_write	= blkdev_prepare_write,
+	.commit_write	= blkdev_commit_write,
+	.writepages	= generic_writepages,
+	.direct_IO	= blkdev_direct_IO,
+};
+
+struct file_operations def_blk_fops = {
+	.open		= blkdev_open,
+	.release	= blkdev_close,
+	.llseek		= block_llseek,
+	.read		= generic_file_read,
+	.write		= blkdev_file_write,
+  	.aio_read	= generic_file_aio_read,
+  	.aio_write	= blkdev_file_aio_write, 
+	.mmap		= generic_file_mmap,
+	.fsync		= block_fsync,
+	.ioctl		= block_ioctl,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl	= compat_blkdev_ioctl,
+#endif
+	.readv		= generic_file_readv,
+	.writev		= generic_file_write_nolock,
+	.sendfile	= generic_file_sendfile,
+};
+
+int ioctl_by_bdev(struct block_device *bdev, unsigned cmd, unsigned long arg)
+{
+	int res;
+	mm_segment_t old_fs = get_fs();
+	set_fs(KERNEL_DS);
+	res = blkdev_ioctl(bdev->bd_inode, NULL, cmd, arg);
+	set_fs(old_fs);
+	return res;
+}
+
+EXPORT_SYMBOL(ioctl_by_bdev);
+
+/**
+ * lookup_bdev  - lookup a struct block_device by name
+ *
+ * @path:	special file representing the block device
+ *
+ * Get a reference to the blockdevice at @path in the current
+ * namespace if possible and return it.  Return ERR_PTR(error)
+ * otherwise.
+ */
+struct block_device *lookup_bdev(const char *path)
+{
+	struct block_device *bdev;
+	struct inode *inode;
+	struct nameidata nd;
+	int error;
+
+	if (!path || !*path)
+		return ERR_PTR(-EINVAL);
+
+	error = path_lookup(path, LOOKUP_FOLLOW, &nd);
+	if (error)
+		return ERR_PTR(error);
+
+	inode = nd.dentry->d_inode;
+	error = -ENOTBLK;
+	if (!S_ISBLK(inode->i_mode))
+		goto fail;
+	error = -EACCES;
+	if (nd.mnt->mnt_flags & MNT_NODEV)
+		goto fail;
+	error = -ENOMEM;
+	bdev = bd_acquire(inode);
+	if (!bdev)
+		goto fail;
+out:
+	path_release(&nd);
+	return bdev;
+fail:
+	bdev = ERR_PTR(error);
+	goto out;
+}
+
+/**
+ * open_bdev_excl  -  open a block device by name and set it up for use
+ *
+ * @path:	special file representing the block device
+ * @flags:	%MS_RDONLY for opening read-only
+ * @holder:	owner for exclusion
+ *
+ * Open the blockdevice described by the special file at @path, claim it
+ * for the @holder.
+ */
+struct block_device *open_bdev_excl(const char *path, int flags, void *holder)
+{
+	struct block_device *bdev;
+	mode_t mode = FMODE_READ;
+	int error = 0;
+
+	bdev = lookup_bdev(path);
+	if (IS_ERR(bdev))
+		return bdev;
+
+	if (!(flags & MS_RDONLY))
+		mode |= FMODE_WRITE;
+	error = blkdev_get(bdev, mode, 0);
+	if (error)
+		return ERR_PTR(error);
+	error = -EACCES;
+	if (!(flags & MS_RDONLY) && bdev_read_only(bdev))
+		goto blkdev_put;
+	error = bd_claim(bdev, holder);
+	if (error)
+		goto blkdev_put;
+
+	return bdev;
+	
+blkdev_put:
+	blkdev_put(bdev);
+	return ERR_PTR(error);
+}
+
+EXPORT_SYMBOL(open_bdev_excl);
+
+/**
+ * close_bdev_excl  -  release a blockdevice openen by open_bdev_excl()
+ *
+ * @bdev:	blockdevice to close
+ *
+ * This is the counterpart to open_bdev_excl().
+ */
+void close_bdev_excl(struct block_device *bdev)
+{
+	bd_release(bdev);
+	blkdev_put(bdev);
+}
+
+EXPORT_SYMBOL(close_bdev_excl);
