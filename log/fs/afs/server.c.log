commit 5481fc6eb8a7f4b76d8ad1be371d2e11b22bfb55
Author: David Howells <dhowells@redhat.com>
Date:   Fri Jun 19 23:39:36 2020 +0100

    afs: Fix hang on rmmod due to outstanding timer
    
    The fileserver probe timer, net->fs_probe_timer, isn't cancelled when
    the kafs module is being removed and so the count it holds on
    net->servers_outstanding doesn't get dropped..
    
    This causes rmmod to wait forever.  The hung process shows a stack like:
    
            afs_purge_servers+0x1b5/0x23c [kafs]
            afs_net_exit+0x44/0x6e [kafs]
            ops_exit_list+0x72/0x93
            unregister_pernet_operations+0x14c/0x1ba
            unregister_pernet_subsys+0x1d/0x2a
            afs_exit+0x29/0x6f [kafs]
            __do_sys_delete_module.isra.0+0x1a2/0x24b
            do_syscall_64+0x51/0x95
            entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fix this by:
    
     (1) Attempting to cancel the probe timer and, if successful, drop the
         count that the timer was holding.
    
     (2) Make the timer function just drop the count and not schedule the
         prober if the afs portion of net namespace is being destroyed.
    
    Also, whilst we're at it, make the following changes:
    
     (3) Initialise net->servers_outstanding to 1 and decrement it before
         waiting on it so that it doesn't generate wake up events by being
         decremented to 0 until we're cleaning up.
    
     (4) Switch the atomic_dec() on ->servers_outstanding for ->fs_timer in
         afs_purge_servers() to use the helper function for that.
    
    Fixes: f6cbb368bcb0 ("afs: Actively poll fileservers to maintain NAT or firewall openings")
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 039e3488511c..e82e452e2612 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -605,11 +605,12 @@ void afs_purge_servers(struct afs_net *net)
 	_enter("");
 
 	if (del_timer_sync(&net->fs_timer))
-		atomic_dec(&net->servers_outstanding);
+		afs_dec_servers_outstanding(net);
 
 	afs_queue_server_manager(net);
 
 	_debug("wait");
+	atomic_dec(&net->servers_outstanding);
 	wait_var_event(&net->servers_outstanding,
 		       !atomic_read(&net->servers_outstanding));
 	_leave("");

commit f3c130e6e6d15822e1553531f91ecc8f3375bac3
Author: David Howells <dhowells@redhat.com>
Date:   Sat May 2 13:39:57 2020 +0100

    afs: Don't use probe running state to make decisions outside probe code
    
    Don't use the running state for fileserver probes to make decisions about
    which server to use as the state is cleared at the start of a probe and
    also intermediate values might be misleading.
    
    Instead, add a separate 'latest known' rtt in the afs_server struct and a
    flag to indicate if the server is known to be responding and update these
    as and when we know what to change them to.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 88593ffcb54e..039e3488511c 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -239,6 +239,7 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 	INIT_LIST_HEAD(&server->probe_link);
 	spin_lock_init(&server->probe_lock);
 	server->cell = cell;
+	server->rtt = UINT_MAX;
 
 	afs_inc_servers_outstanding(net);
 	trace_afs_server(server, 1, 1, afs_server_trace_alloc);

commit 3c4c4075fc61f5c37a0112b1dc8398025dc3e26a
Author: David Howells <dhowells@redhat.com>
Date:   Wed May 27 15:51:30 2020 +0100

    afs: Fix the by-UUID server tree to allow servers with the same UUID
    
    Whilst it shouldn't happen, it is possible for multiple fileservers to
    share a UUID, particularly if an entire cell has been duplicated, UUIDs and
    all.  In such a case, it's not necessarily possible to map the effect of
    the CB.InitCallBackState3 incoming RPC to a specific server unambiguously
    by UUID and thus to a specific cell.
    
    Indeed, there's a problem whereby multiple server records may need to
    occupy the same spot in the rb_tree rooted in the afs_net struct.
    
    Fix this by allowing servers to form a list, with the head of the list in
    the tree.  When the front entry in the list is removed, the second in the
    list just replaces it.  afs_init_callback_state() then just goes down the
    line, poking each server in the list.
    
    This means that some servers will be unnecessarily poked, unfortunately.
    An alternative would be to route by call parameters.
    
    Reported-by: Jeffrey Altman <jaltman@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")

diff --git a/fs/afs/server.c b/fs/afs/server.c
index c51039a077cd..88593ffcb54e 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -130,13 +130,15 @@ struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uu
 }
 
 /*
- * Install a server record in the namespace tree
+ * Install a server record in the namespace tree.  If there's a clash, we stick
+ * it into a list anchored on whichever afs_server struct is actually in the
+ * tree.
  */
 static struct afs_server *afs_install_server(struct afs_cell *cell,
 					     struct afs_server *candidate)
 {
 	const struct afs_addr_list *alist;
-	struct afs_server *server;
+	struct afs_server *server, *next;
 	struct afs_net *net = cell->net;
 	struct rb_node **pp, *p;
 	int diff;
@@ -153,12 +155,30 @@ static struct afs_server *afs_install_server(struct afs_cell *cell,
 		_debug("- consider %p", p);
 		server = rb_entry(p, struct afs_server, uuid_rb);
 		diff = memcmp(&candidate->uuid, &server->uuid, sizeof(uuid_t));
-		if (diff < 0)
+		if (diff < 0) {
 			pp = &(*pp)->rb_left;
-		else if (diff > 0)
+		} else if (diff > 0) {
 			pp = &(*pp)->rb_right;
-		else
-			goto exists;
+		} else {
+			if (server->cell == cell)
+				goto exists;
+
+			/* We have the same UUID representing servers in
+			 * different cells.  Append the new server to the list.
+			 */
+			for (;;) {
+				next = rcu_dereference_protected(
+					server->uuid_next,
+					lockdep_is_held(&net->fs_lock.lock));
+				if (!next)
+					break;
+				server = next;
+			}
+			rcu_assign_pointer(server->uuid_next, candidate);
+			candidate->uuid_prev = server;
+			server = candidate;
+			goto added_dup;
+		}
 	}
 
 	server = candidate;
@@ -166,6 +186,7 @@ static struct afs_server *afs_install_server(struct afs_cell *cell,
 	rb_insert_color(&server->uuid_rb, &net->fs_servers);
 	hlist_add_head_rcu(&server->proc_link, &net->fs_proc);
 
+added_dup:
 	write_seqlock(&net->fs_addr_lock);
 	alist = rcu_dereference_protected(server->addresses,
 					  lockdep_is_held(&net->fs_addr_lock.lock));
@@ -453,7 +474,7 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
  */
 static void afs_gc_servers(struct afs_net *net, struct afs_server *gc_list)
 {
-	struct afs_server *server;
+	struct afs_server *server, *next, *prev;
 	int active;
 
 	while ((server = gc_list)) {
@@ -465,7 +486,26 @@ static void afs_gc_servers(struct afs_net *net, struct afs_server *gc_list)
 		if (active == 0) {
 			trace_afs_server(server, atomic_read(&server->ref),
 					 active, afs_server_trace_gc);
-			rb_erase(&server->uuid_rb, &net->fs_servers);
+			next = rcu_dereference_protected(
+				server->uuid_next, lockdep_is_held(&net->fs_lock.lock));
+			prev = server->uuid_prev;
+			if (!prev) {
+				/* The one at the front is in the tree */
+				if (!next) {
+					rb_erase(&server->uuid_rb, &net->fs_servers);
+				} else {
+					rb_replace_node_rcu(&server->uuid_rb,
+							    &next->uuid_rb,
+							    &net->fs_servers);
+					next->uuid_prev = NULL;
+				}
+			} else {
+				/* This server is not at the front */
+				rcu_assign_pointer(prev->uuid_next, next);
+				if (next)
+					next->uuid_prev = prev;
+			}
+
 			list_del(&server->probe_link);
 			hlist_del_rcu(&server->proc_link);
 			if (!hlist_unhashed(&server->addr4_link))

commit 20325960f8750165964a6891a733e4cc15d19076
Author: David Howells <dhowells@redhat.com>
Date:   Thu Apr 30 01:03:49 2020 +0100

    afs: Reorganise volume and server trees to be rooted on the cell
    
    Reorganise afs_volume objects such that they're in a tree keyed on volume
    ID, rooted at on an afs_cell object rather than being in multiple trees,
    each of which is rooted on an afs_server object.
    
    afs_server structs become per-cell and acquire a pointer to the cell.
    
    The process of breaking a callback then starts with finding the server by
    its network address, following that to the cell and then looking up each
    volume ID in the volume tree.
    
    This is simpler than the afs_vol_interest/afs_cb_interest N:M mapping web
    and allows those structs and the code for maintaining them to be simplified
    or removed.
    
    It does make a couple of things a bit more tricky, though:
    
     (1) Operations now start with a volume, not a server, so there can be more
         than one answer as to whether or not the server we'll end up using
         supports the FS.InlineBulkStatus RPC.
    
     (2) CB RPC operations that specify the server UUID.  There's still a tree
         of servers by UUID on the afs_net struct, but the UUIDs in it aren't
         guaranteed unique.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 1c1e315094ae..c51039a077cd 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -132,11 +132,12 @@ struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uu
 /*
  * Install a server record in the namespace tree
  */
-static struct afs_server *afs_install_server(struct afs_net *net,
+static struct afs_server *afs_install_server(struct afs_cell *cell,
 					     struct afs_server *candidate)
 {
 	const struct afs_addr_list *alist;
 	struct afs_server *server;
+	struct afs_net *net = cell->net;
 	struct rb_node **pp, *p;
 	int diff;
 
@@ -193,11 +194,12 @@ static struct afs_server *afs_install_server(struct afs_net *net,
 /*
  * Allocate a new server record and mark it active.
  */
-static struct afs_server *afs_alloc_server(struct afs_net *net,
+static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 					   const uuid_t *uuid,
 					   struct afs_addr_list *alist)
 {
 	struct afs_server *server;
+	struct afs_net *net = cell->net;
 
 	_enter("");
 
@@ -212,11 +214,10 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	server->addr_version = alist->version;
 	server->uuid = *uuid;
 	rwlock_init(&server->fs_lock);
-	server->cb_volumes = RB_ROOT;
-	seqlock_init(&server->cb_break_lock);
 	init_waitqueue_head(&server->probe_wq);
 	INIT_LIST_HEAD(&server->probe_link);
 	spin_lock_init(&server->probe_lock);
+	server->cell = cell;
 
 	afs_inc_servers_outstanding(net);
 	trace_afs_server(server, 1, 1, afs_server_trace_alloc);
@@ -275,13 +276,13 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell, struct key *key,
 	if (IS_ERR(alist))
 		return ERR_CAST(alist);
 
-	candidate = afs_alloc_server(cell->net, uuid, alist);
+	candidate = afs_alloc_server(cell, uuid, alist);
 	if (!candidate) {
 		afs_put_addrlist(alist);
 		return ERR_PTR(-ENOMEM);
 	}
 
-	server = afs_install_server(cell->net, candidate);
+	server = afs_install_server(cell, candidate);
 	if (server != candidate) {
 		afs_put_addrlist(alist);
 		kfree(candidate);

commit e49c7b2f6de7ff81ca34c56e4eeb4fa740c099f2
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 10 20:51:51 2020 +0100

    afs: Build an abstraction around an "operation" concept
    
    Turn the afs_operation struct into the main way that most fileserver
    operations are managed.  Various things are added to the struct, including
    the following:
    
     (1) All the parameters and results of the relevant operations are moved
         into it, removing corresponding fields from the afs_call struct.
         afs_call gets a pointer to the op.
    
     (2) The target volume is made the main focus of the operation, rather than
         the target vnode(s), and a bunch of op->vnode->volume are made
         op->volume instead.
    
     (3) Two vnode records are defined (op->file[]) for the vnode(s) involved
         in most operations.  The vnode record (struct afs_vnode_param)
         contains:
    
            - The vnode pointer.
    
            - The fid of the vnode to be included in the parameters or that was
              returned in the reply (eg. FS.MakeDir).
    
            - The status and callback information that may be returned in the
              reply about the vnode.
    
            - Callback break and data version tracking for detecting
              simultaneous third-parth changes.
    
     (4) Pointers to dentries to be updated with new inodes.
    
     (5) An operations table pointer.  The table includes pointers to functions
         for issuing AFS and YFS-variant RPCs, handling the success and abort
         of an operation and handling post-I/O-lock local editing of a
         directory.
    
    To make this work, the following function restructuring is made:
    
     (A) The rotation loop that issues calls to fileservers that can be found
         in each function that wants to issue an RPC (such as afs_mkdir()) is
         extracted out into common code, in a new file called fs_operation.c.
    
     (B) The rotation loops, such as the one in afs_mkdir(), are replaced with
         a much smaller piece of code that allocates an operation, sets the
         parameters and then calls out to the common code to do the actual
         work.
    
     (C) The code for handling the success and failure of an operation are
         moved into operation functions (as (5) above) and these are called
         from the core code at appropriate times.
    
     (D) The pseudo inode getting stuff used by the dynamic root code is moved
         over into dynroot.c.
    
     (E) struct afs_iget_data is absorbed into the operation struct and
         afs_iget() expects to be given an op pointer and a vnode record.
    
     (F) Point (E) doesn't work for the root dir of a volume, but we know the
         FID in advance (it's always vnode 1, unique 1), so a separate inode
         getter, afs_root_iget(), is provided to special-case that.
    
     (G) The inode status init/update functions now also take an op and a vnode
         record.
    
     (H) The RPC marshalling functions now, for the most part, just take an
         afs_operation struct as their only argument.  All the data they need
         is held there.  The result delivery functions write their answers
         there as well.
    
     (I) The call is attached to the operation and then the operation core does
         the waiting.
    
    And then the new operation code is, for the moment, made to just initialise
    the operation, get the appropriate vnode I/O locks and do the same rotation
    loop as before.
    
    This lays the foundation for the following changes in the future:
    
     (*) Overhauling the rotation (again).
    
     (*) Support for asynchronous I/O, where the fileserver rotation must be
         done asynchronously also.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 3008f2ecfeee..1c1e315094ae 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -424,10 +424,7 @@ static void __afs_put_server(struct afs_net *net, struct afs_server *server)
 	afs_dec_servers_outstanding(net);
 }
 
-/*
- * destroy a dead server
- */
-static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
+static void afs_give_up_callbacks(struct afs_net *net, struct afs_server *server)
 {
 	struct afs_addr_list *alist = rcu_access_pointer(server->addresses);
 	struct afs_addr_cursor ac = {
@@ -436,8 +433,16 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 		.error	= 0,
 	};
 
+	afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
+}
+
+/*
+ * destroy a dead server
+ */
+static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
+{
 	if (test_bit(AFS_SERVER_FL_MAY_HAVE_CB, &server->flags))
-		afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
+		afs_give_up_callbacks(net, server);
 
 	afs_put_server(net, server, afs_server_trace_destroy);
 }
@@ -571,7 +576,8 @@ void afs_purge_servers(struct afs_net *net)
 /*
  * Get an update for a server's address list.
  */
-static noinline bool afs_update_server_record(struct afs_operation *fc, struct afs_server *server)
+static noinline bool afs_update_server_record(struct afs_operation *op,
+					      struct afs_server *server)
 {
 	struct afs_addr_list *alist, *discard;
 
@@ -580,18 +586,17 @@ static noinline bool afs_update_server_record(struct afs_operation *fc, struct a
 	trace_afs_server(server, atomic_read(&server->ref), atomic_read(&server->active),
 			 afs_server_trace_update);
 
-	alist = afs_vl_lookup_addrs(fc->vnode->volume->cell, fc->key,
-				    &server->uuid);
+	alist = afs_vl_lookup_addrs(op->volume->cell, op->key, &server->uuid);
 	if (IS_ERR(alist)) {
 		if ((PTR_ERR(alist) == -ERESTARTSYS ||
 		     PTR_ERR(alist) == -EINTR) &&
-		    !(fc->flags & AFS_OPERATION_INTR) &&
+		    (op->flags & AFS_OPERATION_UNINTR) &&
 		    server->addresses) {
 			_leave(" = t [intr]");
 			return true;
 		}
-		fc->error = PTR_ERR(alist);
-		_leave(" = f [%d]", fc->error);
+		op->error = PTR_ERR(alist);
+		_leave(" = f [%d]", op->error);
 		return false;
 	}
 
@@ -613,7 +618,7 @@ static noinline bool afs_update_server_record(struct afs_operation *fc, struct a
 /*
  * See if a server's address list needs updating.
  */
-bool afs_check_server_record(struct afs_operation *fc, struct afs_server *server)
+bool afs_check_server_record(struct afs_operation *op, struct afs_server *server)
 {
 	bool success;
 	int ret, retries = 0;
@@ -633,7 +638,7 @@ bool afs_check_server_record(struct afs_operation *fc, struct afs_server *server
 update:
 	if (!test_and_set_bit_lock(AFS_SERVER_FL_UPDATING, &server->flags)) {
 		clear_bit(AFS_SERVER_FL_NEEDS_UPDATE, &server->flags);
-		success = afs_update_server_record(fc, server);
+		success = afs_update_server_record(op, server);
 		clear_bit_unlock(AFS_SERVER_FL_UPDATING, &server->flags);
 		wake_up_bit(&server->flags, AFS_SERVER_FL_UPDATING);
 		_leave(" = %d", success);
@@ -642,10 +647,10 @@ bool afs_check_server_record(struct afs_operation *fc, struct afs_server *server
 
 wait:
 	ret = wait_on_bit(&server->flags, AFS_SERVER_FL_UPDATING,
-			  (fc->flags & AFS_OPERATION_INTR) ?
-			  TASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);
+			  (op->flags & AFS_OPERATION_UNINTR) ?
+			  TASK_UNINTERRUPTIBLE : TASK_INTERRUPTIBLE);
 	if (ret == -ERESTARTSYS) {
-		fc->error = ret;
+		op->error = ret;
 		_leave(" = f [intr]");
 		return false;
 	}

commit a310082f6d0afe28797e148726cd52118a8a4428
Author: David Howells <dhowells@redhat.com>
Date:   Fri Mar 20 09:32:50 2020 +0000

    afs: Rename struct afs_fs_cursor to afs_operation
    
    As a prelude to implementing asynchronous fileserver operations in the afs
    filesystem, rename struct afs_fs_cursor to afs_operation.
    
    This struct is going to form the core of the operation management and is
    going to acquire more members in later.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 5ed90f419c54..3008f2ecfeee 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -571,7 +571,7 @@ void afs_purge_servers(struct afs_net *net)
 /*
  * Get an update for a server's address list.
  */
-static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct afs_server *server)
+static noinline bool afs_update_server_record(struct afs_operation *fc, struct afs_server *server)
 {
 	struct afs_addr_list *alist, *discard;
 
@@ -585,7 +585,7 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
 	if (IS_ERR(alist)) {
 		if ((PTR_ERR(alist) == -ERESTARTSYS ||
 		     PTR_ERR(alist) == -EINTR) &&
-		    !(fc->flags & AFS_FS_CURSOR_INTR) &&
+		    !(fc->flags & AFS_OPERATION_INTR) &&
 		    server->addresses) {
 			_leave(" = t [intr]");
 			return true;
@@ -613,7 +613,7 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
 /*
  * See if a server's address list needs updating.
  */
-bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server)
+bool afs_check_server_record(struct afs_operation *fc, struct afs_server *server)
 {
 	bool success;
 	int ret, retries = 0;
@@ -642,7 +642,7 @@ bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server
 
 wait:
 	ret = wait_on_bit(&server->flags, AFS_SERVER_FL_UPDATING,
-			  (fc->flags & AFS_FS_CURSOR_INTR) ?
+			  (fc->flags & AFS_OPERATION_INTR) ?
 			  TASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);
 	if (ret == -ERESTARTSYS) {
 		fc->error = ret;

commit 8230fd8217b7ea76f838ae88e4a5a8e54f37099f
Author: David Howells <dhowells@redhat.com>
Date:   Fri Mar 27 15:02:44 2020 +0000

    afs: Make callback processing more efficient.
    
    afs_vol_interest objects represent the volume IDs currently being accessed
    from a fileserver.  These hold lists of afs_cb_interest objects that
    repesent the superblocks using that volume ID on that server.
    
    When a callback notification from the server telling of a modification by
    another client arrives, the volume ID specified in the notification is
    looked up in the server's afs_vol_interest list.  Through the
    afs_cb_interest list, the relevant superblocks can be iterated over and the
    specific inode looked up and marked in each one.
    
    Make the following efficiency improvements:
    
     (1) Hold rcu_read_lock() over the entire processing rather than locking it
         each time.
    
     (2) Do all the callbacks for each vid together rather than individually.
         Each volume then only needs to be looked up once.
    
     (3) afs_vol_interest objects are now stored in an rb_tree rather than a
         flat list to reduce the lookup step count.
    
     (4) afs_vol_interest lookup is now done with RCU, but because it's in an
         rb_tree which may rotate under us, a seqlock is used so that if it
         changes during the walk, we repeat the walk with a lock held.
    
    With this and the preceding patch which adds RCU-based lookups in the inode
    cache, target volumes/vnodes can be taken without the need to take any
    locks, except on the target itself.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 3f707b5ecb62..5ed90f419c54 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -212,8 +212,8 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	server->addr_version = alist->version;
 	server->uuid = *uuid;
 	rwlock_init(&server->fs_lock);
-	INIT_HLIST_HEAD(&server->cb_volumes);
-	rwlock_init(&server->cb_break_lock);
+	server->cb_volumes = RB_ROOT;
+	seqlock_init(&server->cb_break_lock);
 	init_waitqueue_head(&server->probe_wq);
 	INIT_LIST_HEAD(&server->probe_link);
 	spin_lock_init(&server->probe_lock);

commit f6cbb368bcb0bc4fa7c11554d5293658bb4b26a2
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 24 15:10:00 2020 +0100

    afs: Actively poll fileservers to maintain NAT or firewall openings
    
    When an AFS client accesses a file, it receives a limited-duration callback
    promise that the server will notify it if another client changes a file.
    This callback duration can be a few hours in length.
    
    If a client mounts a volume and then an application prevents it from being
    unmounted, say by chdir'ing into it, but then does nothing for some time,
    the rxrpc_peer record will expire and rxrpc-level keepalive will cease.
    
    If there is NAT or a firewall between the client and the server, the route
    back for the server may close after a comparatively short duration, meaning
    that attempts by the server to notify the client may then bounce.
    
    The client, however, may (so far as it knows) still have a valid unexpired
    promise and will then rely on its cached data and will not see changes made
    on the server by a third party until it incidentally rechecks the status or
    the promise needs renewal.
    
    To deal with this, the client needs to regularly probe the server.  This
    has two effects: firstly, it keeps a route open back for the server, and
    secondly, it causes the server to disgorge any notifications that got
    queued up because they couldn't be sent.
    
    Fix this by adding a mechanism to emit regular probes.
    
    Two levels of probing are made available: Under normal circumstances the
    'slow' queue will be used for a fileserver - this just probes the preferred
    address once every 5 mins or so; however, if server fails to respond to any
    probes, the server will shift to the 'fast' queue from which all its
    interfaces will be probed every 30s.  When it finally responds, the record
    will switch back to the slow queue.
    
    Further notes:
    
     (1) Probing is now no longer driven from the fileserver rotation
         algorithm.
    
     (2) Probes are dispatched to all interfaces on a fileserver when that an
         afs_server object is set up to record it.
    
     (3) The afs_server object is removed from the probe queues when we start
         to probe it.  afs_is_probing_server() returns true if it's not listed
         - ie. it's undergoing probing.
    
     (4) The afs_server object is added back on to the probe queue when the
         final outstanding probe completes, but the probed_at time is set when
         we're about to launch a probe so that it's not dependent on the probe
         duration.
    
     (5) The timer and the work item added for this must be handed a count on
         net->servers_outstanding, which they hand on or release.  This makes
         sure that network namespace cleanup waits for them.
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Reported-by: Dave Botsch <botsch@cnf.cornell.edu>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 4969a681f8f5..3f707b5ecb62 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -14,17 +14,6 @@
 static unsigned afs_server_gc_delay = 10;	/* Server record timeout in seconds */
 static atomic_t afs_server_debug_id;
 
-static void afs_inc_servers_outstanding(struct afs_net *net)
-{
-	atomic_inc(&net->servers_outstanding);
-}
-
-static void afs_dec_servers_outstanding(struct afs_net *net)
-{
-	if (atomic_dec_and_test(&net->servers_outstanding))
-		wake_up_var(&net->servers_outstanding);
-}
-
 static struct afs_server *afs_maybe_use_server(struct afs_server *,
 					       enum afs_server_trace);
 static void __afs_put_server(struct afs_net *, struct afs_server *);
@@ -226,6 +215,7 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	INIT_HLIST_HEAD(&server->cb_volumes);
 	rwlock_init(&server->cb_break_lock);
 	init_waitqueue_head(&server->probe_wq);
+	INIT_LIST_HEAD(&server->probe_link);
 	spin_lock_init(&server->probe_lock);
 
 	afs_inc_servers_outstanding(net);
@@ -295,6 +285,12 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell, struct key *key,
 	if (server != candidate) {
 		afs_put_addrlist(alist);
 		kfree(candidate);
+	} else {
+		/* Immediately dispatch an asynchronous probe to each interface
+		 * on the fileserver.  This will make sure the repeat-probing
+		 * service is started.
+		 */
+		afs_fs_probe_fileserver(cell->net, server, key, true);
 	}
 
 	return server;
@@ -464,6 +460,7 @@ static void afs_gc_servers(struct afs_net *net, struct afs_server *gc_list)
 			trace_afs_server(server, atomic_read(&server->ref),
 					 active, afs_server_trace_gc);
 			rb_erase(&server->uuid_rb, &net->fs_servers);
+			list_del(&server->probe_link);
 			hlist_del_rcu(&server->proc_link);
 			if (!hlist_unhashed(&server->addr4_link))
 				hlist_del_rcu(&server->addr4_link);

commit 977e5f8ed0ab2786755f8d2a96b78a3c7320f7c4
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 17 17:31:26 2020 +0100

    afs: Split the usage count on struct afs_server
    
    Split the usage count on the afs_server struct to have an active count that
    registers who's actually using it separately from the reference count on
    the object.
    
    This allows a future patch to dispatch polling probes without advancing the
    "unuse" time into the future each time we emit a probe, which would
    otherwise prevent unused server records from expiring.
    
    Included in this:
    
     (1) The latter part of afs_destroy_server() in which the RCU destruction
         of afs_server objects is invoked and the outstanding server count is
         decremented is split out into __afs_put_server().
    
     (2) afs_put_server() now calls __afs_put_server() rather then setting the
         management timer.
    
     (3) The calls begun by afs_fs_give_up_all_callbacks() and
         afs_fs_get_capabilities() can now take a ref on the server record, so
         afs_destroy_server() can just drop its ref and needn't wait for the
         completion of these calls.  They'll put the ref when they're done.
    
     (4) Because of (3), afs_fs_probe_done() no longer needs to wake up
         afs_destroy_server() with server->probe_outstanding.
    
     (5) afs_gc_servers can be simplified.  It only needs to check if
         server->active is 0 rather than playing games with the refcount.
    
     (6) afs_manage_servers() can propose a server for gc if usage == 0 rather
         than if ref == 1.  The gc is effected by (5).
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 9e50ccde5d37..4969a681f8f5 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -25,6 +25,10 @@ static void afs_dec_servers_outstanding(struct afs_net *net)
 		wake_up_var(&net->servers_outstanding);
 }
 
+static struct afs_server *afs_maybe_use_server(struct afs_server *,
+					       enum afs_server_trace);
+static void __afs_put_server(struct afs_net *, struct afs_server *);
+
 /*
  * Find a server by one of its addresses.
  */
@@ -40,7 +44,7 @@ struct afs_server *afs_find_server(struct afs_net *net,
 
 	do {
 		if (server)
-			afs_put_server(net, server, afs_server_trace_put_find_rsq);
+			afs_unuse_server_notime(net, server, afs_server_trace_put_find_rsq);
 		server = NULL;
 		read_seqbegin_or_lock(&net->fs_addr_lock, &seq);
 
@@ -78,9 +82,9 @@ struct afs_server *afs_find_server(struct afs_net *net,
 		}
 
 		server = NULL;
+		continue;
 	found:
-		if (server && !atomic_inc_not_zero(&server->usage))
-			server = NULL;
+		server = afs_maybe_use_server(server, afs_server_trace_get_by_addr);
 
 	} while (need_seqretry(&net->fs_addr_lock, seq));
 
@@ -91,7 +95,7 @@ struct afs_server *afs_find_server(struct afs_net *net,
 }
 
 /*
- * Look up a server by its UUID
+ * Look up a server by its UUID and mark it active.
  */
 struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uuid)
 {
@@ -107,7 +111,7 @@ struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uu
 		 * changes.
 		 */
 		if (server)
-			afs_put_server(net, server, afs_server_trace_put_uuid_rsq);
+			afs_unuse_server(net, server, afs_server_trace_put_uuid_rsq);
 		server = NULL;
 
 		read_seqbegin_or_lock(&net->fs_lock, &seq);
@@ -122,7 +126,7 @@ struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uu
 			} else if (diff > 0) {
 				p = p->rb_right;
 			} else {
-				afs_get_server(server, afs_server_trace_get_by_uuid);
+				afs_use_server(server, afs_server_trace_get_by_uuid);
 				break;
 			}
 
@@ -198,7 +202,7 @@ static struct afs_server *afs_install_server(struct afs_net *net,
 }
 
 /*
- * allocate a new server record
+ * Allocate a new server record and mark it active.
  */
 static struct afs_server *afs_alloc_server(struct afs_net *net,
 					   const uuid_t *uuid,
@@ -212,7 +216,8 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	if (!server)
 		goto enomem;
 
-	atomic_set(&server->usage, 1);
+	atomic_set(&server->ref, 1);
+	atomic_set(&server->active, 1);
 	server->debug_id = atomic_inc_return(&afs_server_debug_id);
 	RCU_INIT_POINTER(server->addresses, alist);
 	server->addr_version = alist->version;
@@ -224,7 +229,7 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	spin_lock_init(&server->probe_lock);
 
 	afs_inc_servers_outstanding(net);
-	trace_afs_server(server, 1, afs_server_trace_alloc);
+	trace_afs_server(server, 1, 1, afs_server_trace_alloc);
 	_leave(" = %p", server);
 	return server;
 
@@ -292,7 +297,6 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell, struct key *key,
 		kfree(candidate);
 	}
 
-	_leave(" = %p{%d}", server, atomic_read(&server->usage));
 	return server;
 }
 
@@ -328,9 +332,38 @@ void afs_servers_timer(struct timer_list *timer)
 struct afs_server *afs_get_server(struct afs_server *server,
 				  enum afs_server_trace reason)
 {
-	unsigned int u = atomic_inc_return(&server->usage);
+	unsigned int u = atomic_inc_return(&server->ref);
+
+	trace_afs_server(server, u, atomic_read(&server->active), reason);
+	return server;
+}
+
+/*
+ * Try to get a reference on a server object.
+ */
+static struct afs_server *afs_maybe_use_server(struct afs_server *server,
+					       enum afs_server_trace reason)
+{
+	unsigned int r = atomic_fetch_add_unless(&server->ref, 1, 0);
+	unsigned int a;
+
+	if (r == 0)
+		return NULL;
+
+	a = atomic_inc_return(&server->active);
+	trace_afs_server(server, r, a, reason);
+	return server;
+}
+
+/*
+ * Get an active count on a server object.
+ */
+struct afs_server *afs_use_server(struct afs_server *server, enum afs_server_trace reason)
+{
+	unsigned int r = atomic_inc_return(&server->ref);
+	unsigned int a = atomic_inc_return(&server->active);
 
-	trace_afs_server(server, u, reason);
+	trace_afs_server(server, r, a, reason);
 	return server;
 }
 
@@ -345,28 +378,56 @@ void afs_put_server(struct afs_net *net, struct afs_server *server,
 	if (!server)
 		return;
 
-	server->put_time = ktime_get_real_seconds();
-
-	usage = atomic_dec_return(&server->usage);
+	usage = atomic_dec_return(&server->ref);
+	trace_afs_server(server, usage, atomic_read(&server->active), reason);
+	if (unlikely(usage == 0))
+		__afs_put_server(net, server);
+}
 
-	trace_afs_server(server, usage, reason);
+/*
+ * Drop an active count on a server object without updating the last-unused
+ * time.
+ */
+void afs_unuse_server_notime(struct afs_net *net, struct afs_server *server,
+			     enum afs_server_trace reason)
+{
+	if (server) {
+		unsigned int active = atomic_dec_return(&server->active);
 
-	if (likely(usage > 0))
-		return;
+		if (active == 0)
+			afs_set_server_timer(net, afs_server_gc_delay);
+		afs_put_server(net, server, reason);
+	}
+}
 
-	afs_set_server_timer(net, afs_server_gc_delay);
+/*
+ * Drop an active count on a server object.
+ */
+void afs_unuse_server(struct afs_net *net, struct afs_server *server,
+		      enum afs_server_trace reason)
+{
+	if (server) {
+		server->unuse_time = ktime_get_real_seconds();
+		afs_unuse_server_notime(net, server, reason);
+	}
 }
 
 static void afs_server_rcu(struct rcu_head *rcu)
 {
 	struct afs_server *server = container_of(rcu, struct afs_server, rcu);
 
-	trace_afs_server(server, atomic_read(&server->usage),
-			 afs_server_trace_free);
+	trace_afs_server(server, atomic_read(&server->ref),
+			 atomic_read(&server->active), afs_server_trace_free);
 	afs_put_addrlist(rcu_access_pointer(server->addresses));
 	kfree(server);
 }
 
+static void __afs_put_server(struct afs_net *net, struct afs_server *server)
+{
+	call_rcu(&server->rcu, afs_server_rcu);
+	afs_dec_servers_outstanding(net);
+}
+
 /*
  * destroy a dead server
  */
@@ -379,19 +440,10 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 		.error	= 0,
 	};
 
-	trace_afs_server(server, atomic_read(&server->usage),
-			 afs_server_trace_give_up_cb);
-
 	if (test_bit(AFS_SERVER_FL_MAY_HAVE_CB, &server->flags))
 		afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
 
-	wait_var_event(&server->probe_outstanding,
-		       atomic_read(&server->probe_outstanding) == 0);
-
-	trace_afs_server(server, atomic_read(&server->usage),
-			 afs_server_trace_destroy);
-	call_rcu(&server->rcu, afs_server_rcu);
-	afs_dec_servers_outstanding(net);
+	afs_put_server(net, server, afs_server_trace_destroy);
 }
 
 /*
@@ -400,31 +452,28 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 static void afs_gc_servers(struct afs_net *net, struct afs_server *gc_list)
 {
 	struct afs_server *server;
-	bool deleted;
-	int usage;
+	int active;
 
 	while ((server = gc_list)) {
 		gc_list = server->gc_next;
 
 		write_seqlock(&net->fs_lock);
-		usage = 1;
-		deleted = atomic_try_cmpxchg(&server->usage, &usage, 0);
-		trace_afs_server(server, usage, afs_server_trace_gc);
-		if (deleted) {
+
+		active = atomic_read(&server->active);
+		if (active == 0) {
+			trace_afs_server(server, atomic_read(&server->ref),
+					 active, afs_server_trace_gc);
 			rb_erase(&server->uuid_rb, &net->fs_servers);
 			hlist_del_rcu(&server->proc_link);
-		}
-		write_sequnlock(&net->fs_lock);
-
-		if (deleted) {
-			write_seqlock(&net->fs_addr_lock);
 			if (!hlist_unhashed(&server->addr4_link))
 				hlist_del_rcu(&server->addr4_link);
 			if (!hlist_unhashed(&server->addr6_link))
 				hlist_del_rcu(&server->addr6_link);
-			write_sequnlock(&net->fs_addr_lock);
-			afs_destroy_server(net, server);
 		}
+		write_sequnlock(&net->fs_lock);
+
+		if (active == 0)
+			afs_destroy_server(net, server);
 	}
 }
 
@@ -453,15 +502,14 @@ void afs_manage_servers(struct work_struct *work)
 	for (cursor = rb_first(&net->fs_servers); cursor; cursor = rb_next(cursor)) {
 		struct afs_server *server =
 			rb_entry(cursor, struct afs_server, uuid_rb);
-		int usage = atomic_read(&server->usage);
+		int active = atomic_read(&server->active);
 
-		_debug("manage %pU %u", &server->uuid, usage);
+		_debug("manage %pU %u", &server->uuid, active);
 
-		ASSERTCMP(usage, >=, 1);
-		ASSERTIFCMP(purging, usage, ==, 1);
+		ASSERTIFCMP(purging, active, ==, 0);
 
-		if (usage == 1) {
-			time64_t expire_at = server->put_time;
+		if (active == 0) {
+			time64_t expire_at = server->unuse_time;
 
 			if (!test_bit(AFS_SERVER_FL_VL_FAIL, &server->flags) &&
 			    !test_bit(AFS_SERVER_FL_NOT_FOUND, &server->flags))
@@ -532,7 +580,8 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
 
 	_enter("");
 
-	trace_afs_server(server, atomic_read(&server->usage), afs_server_trace_update);
+	trace_afs_server(server, atomic_read(&server->ref), atomic_read(&server->active),
+			 afs_server_trace_update);
 
 	alist = afs_vl_lookup_addrs(fc->vnode->volume->cell, fc->key,
 				    &server->uuid);

commit 810068059234551b6973b46ca572e654f0c5e665
Author: David Howells <dhowells@redhat.com>
Date:   Thu Apr 16 17:05:28 2020 +0100

    afs: Use the serverUnique field in the UVLDB record to reduce rpc ops
    
    The U-version VLDB volume record retrieved by the VL.GetEntryByNameU rpc op
    carries a change counter (the serverUnique field) for each fileserver
    listed in the record as backing that volume.  This is incremented whenever
    the registration details for a fileserver change (such as its address
    list).  Note that the same value will be seen in all UVLDB records that
    refer to that fileserver.
    
    This should be checked before calling the VL server to re-query the address
    list for a fileserver.  If it's the same, there's no point doing the query.
    
    Reported-by: Jeffrey Altman <jaltman@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 11b90ac7ea30..9e50ccde5d37 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -12,7 +12,6 @@
 #include "protocol_yfs.h"
 
 static unsigned afs_server_gc_delay = 10;	/* Server record timeout in seconds */
-static unsigned afs_server_update_delay = 30;	/* Time till VLDB recheck in secs */
 static atomic_t afs_server_debug_id;
 
 static void afs_inc_servers_outstanding(struct afs_net *net)
@@ -218,7 +217,6 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	RCU_INIT_POINTER(server->addresses, alist);
 	server->addr_version = alist->version;
 	server->uuid = *uuid;
-	server->update_at = ktime_get_real_seconds() + afs_server_update_delay;
 	rwlock_init(&server->fs_lock);
 	INIT_HLIST_HEAD(&server->cb_volumes);
 	rwlock_init(&server->cb_break_lock);
@@ -264,7 +262,7 @@ static struct afs_addr_list *afs_vl_lookup_addrs(struct afs_cell *cell,
  * Get or create a fileserver record.
  */
 struct afs_server *afs_lookup_server(struct afs_cell *cell, struct key *key,
-				     const uuid_t *uuid)
+				     const uuid_t *uuid, u32 addr_version)
 {
 	struct afs_addr_list *alist;
 	struct afs_server *server, *candidate;
@@ -272,8 +270,11 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell, struct key *key,
 	_enter("%p,%pU", cell->net, uuid);
 
 	server = afs_find_server_by_uuid(cell->net, uuid);
-	if (server)
+	if (server) {
+		if (server->addr_version != addr_version)
+			set_bit(AFS_SERVER_FL_NEEDS_UPDATE, &server->flags);
 		return server;
+	}
 
 	alist = afs_vl_lookup_addrs(cell, key, uuid);
 	if (IS_ERR(alist))
@@ -558,7 +559,6 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
 		write_unlock(&server->fs_lock);
 	}
 
-	server->update_at = ktime_get_real_seconds() + afs_server_update_delay;
 	afs_put_addrlist(discard);
 	_leave(" = t");
 	return true;
@@ -569,8 +569,6 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
  */
 bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server)
 {
-	time64_t now = ktime_get_real_seconds();
-	long diff;
 	bool success;
 	int ret, retries = 0;
 
@@ -579,13 +577,16 @@ bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server
 	ASSERT(server);
 
 retry:
-	diff = READ_ONCE(server->update_at) - now;
-	if (diff > 0) {
-		_leave(" = t [not now %ld]", diff);
-		return true;
-	}
+	if (test_bit(AFS_SERVER_FL_UPDATING, &server->flags))
+		goto wait;
+	if (test_bit(AFS_SERVER_FL_NEEDS_UPDATE, &server->flags))
+		goto update;
+	_leave(" = t [good]");
+	return true;
 
+update:
 	if (!test_and_set_bit_lock(AFS_SERVER_FL_UPDATING, &server->flags)) {
+		clear_bit(AFS_SERVER_FL_NEEDS_UPDATE, &server->flags);
 		success = afs_update_server_record(fc, server);
 		clear_bit_unlock(AFS_SERVER_FL_UPDATING, &server->flags);
 		wake_up_bit(&server->flags, AFS_SERVER_FL_UPDATING);
@@ -593,6 +594,7 @@ bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server
 		return success;
 	}
 
+wait:
 	ret = wait_on_bit(&server->flags, AFS_SERVER_FL_UPDATING,
 			  (fc->flags & AFS_FS_CURSOR_INTR) ?
 			  TASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);

commit c4bfda16d1b40d1c5941c61b5aa336bdd2d9904a
Author: David Howells <dhowells@redhat.com>
Date:   Thu Apr 16 18:17:13 2020 +0100

    afs: Make record checking use TASK_UNINTERRUPTIBLE when appropriate
    
    When an operation is meant to be done uninterruptibly (such as
    FS.StoreData), we should not be allowing volume and server record checking
    to be interrupted.
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index b7f3cb2130ca..11b90ac7ea30 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -594,12 +594,9 @@ bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server
 	}
 
 	ret = wait_on_bit(&server->flags, AFS_SERVER_FL_UPDATING,
-			  TASK_INTERRUPTIBLE);
+			  (fc->flags & AFS_FS_CURSOR_INTR) ?
+			  TASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);
 	if (ret == -ERESTARTSYS) {
-		if (!(fc->flags & AFS_FS_CURSOR_INTR) && server->addresses) {
-			_leave(" = t [intr]");
-			return true;
-		}
 		fc->error = ret;
 		_leave(" = f [intr]");
 		return false;

commit 9bd0160d12370a076e44f8d1320cde9c83f2c647
Author: Marc Dionne <marc.dionne@auristor.com>
Date:   Mon Dec 9 15:04:43 2019 +0000

    afs: Fix afs_find_server lookups for ipv4 peers
    
    afs_find_server tries to find a server that has an address that
    matches the transport address of an rxrpc peer.  The code assumes
    that the transport address is always ipv6, with ipv4 represented
    as ipv4 mapped addresses, but that's not the case.  If the transport
    family is AF_INET, srx->transport.sin6.sin6_addr.s6_addr32[] will
    be beyond the actual ipv4 address and will always be 0, and all
    ipv4 addresses will be seen as matching.
    
    As a result, the first ipv4 address seen on any server will be
    considered a match, and the server returned may be the wrong one.
    
    One of the consequences is that callbacks received over ipv4 will
    only be correctly applied for the server that happens to have the
    first ipv4 address on the fs_addresses4 list.  Callbacks over ipv4
    from all other servers are dropped, causing the client to serve stale
    data.
    
    This is fixed by looking at the transport family, and comparing ipv4
    addresses based on a sockaddr_in structure rather than a sockaddr_in6.
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Signed-off-by: Marc Dionne <marc.dionne@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 1686bf188ccd..b7f3cb2130ca 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -32,18 +32,11 @@ static void afs_dec_servers_outstanding(struct afs_net *net)
 struct afs_server *afs_find_server(struct afs_net *net,
 				   const struct sockaddr_rxrpc *srx)
 {
-	const struct sockaddr_in6 *a = &srx->transport.sin6, *b;
 	const struct afs_addr_list *alist;
 	struct afs_server *server = NULL;
 	unsigned int i;
-	bool ipv6 = true;
 	int seq = 0, diff;
 
-	if (srx->transport.sin6.sin6_addr.s6_addr32[0] == 0 ||
-	    srx->transport.sin6.sin6_addr.s6_addr32[1] == 0 ||
-	    srx->transport.sin6.sin6_addr.s6_addr32[2] == htonl(0xffff))
-		ipv6 = false;
-
 	rcu_read_lock();
 
 	do {
@@ -52,7 +45,8 @@ struct afs_server *afs_find_server(struct afs_net *net,
 		server = NULL;
 		read_seqbegin_or_lock(&net->fs_addr_lock, &seq);
 
-		if (ipv6) {
+		if (srx->transport.family == AF_INET6) {
+			const struct sockaddr_in6 *a = &srx->transport.sin6, *b;
 			hlist_for_each_entry_rcu(server, &net->fs_addresses6, addr6_link) {
 				alist = rcu_dereference(server->addresses);
 				for (i = alist->nr_ipv4; i < alist->nr_addrs; i++) {
@@ -68,15 +62,16 @@ struct afs_server *afs_find_server(struct afs_net *net,
 				}
 			}
 		} else {
+			const struct sockaddr_in *a = &srx->transport.sin, *b;
 			hlist_for_each_entry_rcu(server, &net->fs_addresses4, addr4_link) {
 				alist = rcu_dereference(server->addresses);
 				for (i = 0; i < alist->nr_ipv4; i++) {
-					b = &alist->addrs[i].transport.sin6;
-					diff = ((u16 __force)a->sin6_port -
-						(u16 __force)b->sin6_port);
+					b = &alist->addrs[i].transport.sin;
+					diff = ((u16 __force)a->sin_port -
+						(u16 __force)b->sin_port);
 					if (diff == 0)
-						diff = ((u32 __force)a->sin6_addr.s6_addr32[3] -
-							(u32 __force)b->sin6_addr.s6_addr32[3]);
+						diff = ((u32 __force)a->sin_addr.s_addr -
+							(u32 __force)b->sin_addr.s_addr);
 					if (diff == 0)
 						goto found;
 				}

commit 4fe171bb81b13b40bf568330ec3716dfb304ced1
Author: zhengbin <zhengbin13@huawei.com>
Date:   Thu Nov 21 09:12:18 2019 +0000

    afs: Remove set but not used variable 'ret'
    
    Fixes gcc '-Wunused-but-set-variable' warning:
    
    fs/afs/server.c: In function afs_install_server:
    fs/afs/server.c:157:6: warning: variable ret set but not used [-Wunused-but-set-variable]
    
    It is not used since commit d2ddc776a458 ("afs:
    Overhaul volume and server record caching and fileserver rotation")
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: zhengbin <zhengbin13@huawei.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 64d440aaabc0..1686bf188ccd 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -151,7 +151,7 @@ static struct afs_server *afs_install_server(struct afs_net *net,
 	const struct afs_addr_list *alist;
 	struct afs_server *server;
 	struct rb_node **pp, *p;
-	int ret = -EEXIST, diff;
+	int diff;
 
 	_enter("%p", candidate);
 
@@ -196,7 +196,6 @@ static struct afs_server *afs_install_server(struct afs_net *net,
 		hlist_add_head_rcu(&server->addr6_link, &net->fs_addresses6);
 
 	write_sequnlock(&net->fs_addr_lock);
-	ret = 0;
 
 exists:
 	afs_get_server(server, afs_server_trace_get_install);

commit 8dda9957e3a1c871dfbabf84c4760f9b26032442
Merge: 25cd6f355dab 1eda8bab70ca
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 10 20:55:33 2019 -0700

    Merge tag 'afs-next-20190628' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-fs
    
    Pull afs updates from David Howells:
     "A set of minor changes for AFS:
    
       - Remove an unnecessary check in afs_unlink()
    
       - Add a tracepoint for tracking callback management
    
       - Add a tracepoint for afs_server object usage
    
       - Use struct_size()
    
       - Add mappings for AFS UAE abort codes to Linux error codes, using
         symbolic names rather than hex numbers in the .c file"
    
    * tag 'afs-next-20190628' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-fs:
      afs: Add support for the UAE error table
      fs/afs: use struct_size() in kzalloc()
      afs: Trace afs_server usage
      afs: Add some callback management tracepoints
      afs: afs_unlink() doesn't need to check dentry->d_inode

commit 452181936931f0f08923aba5e04e1e9ef58c389f
Author: David Howells <dhowells@redhat.com>
Date:   Thu Jun 20 18:12:17 2019 +0100

    afs: Trace afs_server usage
    
    Add a tracepoint (afs_server) to track the afs_server object usage count.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 52c170b59cfd..b69571bb9d37 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -17,6 +17,7 @@
 
 static unsigned afs_server_gc_delay = 10;	/* Server record timeout in seconds */
 static unsigned afs_server_update_delay = 30;	/* Time till VLDB recheck in secs */
+static atomic_t afs_server_debug_id;
 
 static void afs_inc_servers_outstanding(struct afs_net *net)
 {
@@ -51,7 +52,7 @@ struct afs_server *afs_find_server(struct afs_net *net,
 
 	do {
 		if (server)
-			afs_put_server(net, server);
+			afs_put_server(net, server, afs_server_trace_put_find_rsq);
 		server = NULL;
 		read_seqbegin_or_lock(&net->fs_addr_lock, &seq);
 
@@ -116,7 +117,7 @@ struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uu
 		 * changes.
 		 */
 		if (server)
-			afs_put_server(net, server);
+			afs_put_server(net, server, afs_server_trace_put_uuid_rsq);
 		server = NULL;
 
 		read_seqbegin_or_lock(&net->fs_lock, &seq);
@@ -131,7 +132,7 @@ struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uu
 			} else if (diff > 0) {
 				p = p->rb_right;
 			} else {
-				afs_get_server(server);
+				afs_get_server(server, afs_server_trace_get_by_uuid);
 				break;
 			}
 
@@ -202,7 +203,7 @@ static struct afs_server *afs_install_server(struct afs_net *net,
 	ret = 0;
 
 exists:
-	afs_get_server(server);
+	afs_get_server(server, afs_server_trace_get_install);
 	write_sequnlock(&net->fs_lock);
 	return server;
 }
@@ -223,6 +224,7 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 		goto enomem;
 
 	atomic_set(&server->usage, 1);
+	server->debug_id = atomic_inc_return(&afs_server_debug_id);
 	RCU_INIT_POINTER(server->addresses, alist);
 	server->addr_version = alist->version;
 	server->uuid = *uuid;
@@ -234,6 +236,7 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	spin_lock_init(&server->probe_lock);
 
 	afs_inc_servers_outstanding(net);
+	trace_afs_server(server, 1, afs_server_trace_alloc);
 	_leave(" = %p", server);
 	return server;
 
@@ -328,10 +331,23 @@ void afs_servers_timer(struct timer_list *timer)
 		afs_dec_servers_outstanding(net);
 }
 
+/*
+ * Get a reference on a server object.
+ */
+struct afs_server *afs_get_server(struct afs_server *server,
+				  enum afs_server_trace reason)
+{
+	unsigned int u = atomic_inc_return(&server->usage);
+
+	trace_afs_server(server, u, reason);
+	return server;
+}
+
 /*
  * Release a reference on a server record.
  */
-void afs_put_server(struct afs_net *net, struct afs_server *server)
+void afs_put_server(struct afs_net *net, struct afs_server *server,
+		    enum afs_server_trace reason)
 {
 	unsigned int usage;
 
@@ -342,7 +358,7 @@ void afs_put_server(struct afs_net *net, struct afs_server *server)
 
 	usage = atomic_dec_return(&server->usage);
 
-	_enter("{%u}", usage);
+	trace_afs_server(server, usage, reason);
 
 	if (likely(usage > 0))
 		return;
@@ -354,6 +370,8 @@ static void afs_server_rcu(struct rcu_head *rcu)
 {
 	struct afs_server *server = container_of(rcu, struct afs_server, rcu);
 
+	trace_afs_server(server, atomic_read(&server->usage),
+			 afs_server_trace_free);
 	afs_put_addrlist(rcu_access_pointer(server->addresses));
 	kfree(server);
 }
@@ -369,7 +387,9 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 		.index	= alist->preferred,
 		.error	= 0,
 	};
-	_enter("%p", server);
+
+	trace_afs_server(server, atomic_read(&server->usage),
+			 afs_server_trace_give_up_cb);
 
 	if (test_bit(AFS_SERVER_FL_MAY_HAVE_CB, &server->flags))
 		afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
@@ -377,6 +397,8 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 	wait_var_event(&server->probe_outstanding,
 		       atomic_read(&server->probe_outstanding) == 0);
 
+	trace_afs_server(server, atomic_read(&server->usage),
+			 afs_server_trace_destroy);
 	call_rcu(&server->rcu, afs_server_rcu);
 	afs_dec_servers_outstanding(net);
 }
@@ -396,6 +418,7 @@ static void afs_gc_servers(struct afs_net *net, struct afs_server *gc_list)
 		write_seqlock(&net->fs_lock);
 		usage = 1;
 		deleted = atomic_try_cmpxchg(&server->usage, &usage, 0);
+		trace_afs_server(server, usage, afs_server_trace_gc);
 		if (deleted) {
 			rb_erase(&server->uuid_rb, &net->fs_servers);
 			hlist_del_rcu(&server->proc_link);
@@ -518,6 +541,8 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
 
 	_enter("");
 
+	trace_afs_server(server, atomic_read(&server->usage), afs_server_trace_update);
+
 	alist = afs_vl_lookup_addrs(fc->vnode->volume->cell, fc->key,
 				    &server->uuid);
 	if (IS_ERR(alist)) {

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 52c170b59cfd..e900cd74361b 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -1,12 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /* AFS server record management
  *
  * Copyright (C) 2002, 2007 Red Hat, Inc. All Rights Reserved.
  * Written by David Howells (dhowells@redhat.com)
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #include <linux/sched.h>

commit 20b8391fff56f64893233a772a81adc392a69121
Author: David Howells <dhowells@redhat.com>
Date:   Wed May 8 16:16:31 2019 +0100

    afs: Make some RPC operations non-interruptible
    
    Make certain RPC operations non-interruptible, including:
    
     (*) Set attributes
     (*) Store data
    
         We don't want to get interrupted during a flush on close, flush on
         unlock, writeback or an inode update, leaving us in a state where we
         still need to do the writeback or update.
    
     (*) Extend lock
     (*) Release lock
    
         We don't want to get lock extension interrupted as the file locks on
         the server are time-limited.  Interruption during lock release is less
         of an issue since the lock is time-limited, but it's better to
         complete the release to avoid a several-minute wait to recover it.
    
         *Setting* the lock isn't a problem if it's interrupted since we can
          just return to the user and tell them they were interrupted - at
          which point they can elect to retry.
    
     (*) Silly unlink
    
         We want to remove silly unlink files if we can, rather than leaving
         them for the salvager to clear up.
    
    Note that whilst these calls are no longer interruptible, they do have
    timeouts on them, so if the server stops responding the call will fail with
    something like ETIME or ECONNRESET.
    
    Without this, the following:
    
            kAFS: Unexpected error from FS.StoreData -512
    
    appears in dmesg when a pending store data gets interrupted and some
    processes may just hang.
    
    Additionally, make the code that checks/updates the server record ignore
    failure due to interruption if the main call is uninterruptible and if the
    server has an address list.  The next op will check it again since the
    expiration time on the old list has past.
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Reported-by: Jonathan Billings <jsbillings@jsbillings.org>
    Reported-by: Marc Dionne <marc.dionne@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 454c6357f51f..52c170b59cfd 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -521,6 +521,13 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
 	alist = afs_vl_lookup_addrs(fc->vnode->volume->cell, fc->key,
 				    &server->uuid);
 	if (IS_ERR(alist)) {
+		if ((PTR_ERR(alist) == -ERESTARTSYS ||
+		     PTR_ERR(alist) == -EINTR) &&
+		    !(fc->flags & AFS_FS_CURSOR_INTR) &&
+		    server->addresses) {
+			_leave(" = t [intr]");
+			return true;
+		}
 		fc->error = PTR_ERR(alist);
 		_leave(" = f [%d]", fc->error);
 		return false;
@@ -574,6 +581,10 @@ bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server
 	ret = wait_on_bit(&server->flags, AFS_SERVER_FL_UPDATING,
 			  TASK_INTERRUPTIBLE);
 	if (ret == -ERESTARTSYS) {
+		if (!(fc->flags & AFS_FS_CURSOR_INTR) && server->addresses) {
+			_leave(" = t [intr]");
+			return true;
+		}
 		fc->error = ret;
 		_leave(" = f [intr]");
 		return false;

commit 0ab4c9594812c4bc5606daf0677ae304bf7ec8c8
Author: David Howells <dhowells@redhat.com>
Date:   Thu May 16 14:51:48 2019 +0100

    afs: Fix error propagation from server record check/update
    
    afs_check/update_server_record() should be setting fc->error rather than
    fc->ac.error as they're called from within the cursor iteration function.
    
    afs_fs_cursor::error is where the error code of the attempt to call the
    operation on multiple servers is integrated and is the final result,
    whereas afs_addr_cursor::error is used to hold the error from individual
    iterations of the call loop.  (Note there's also an afs_vl_cursor which
    also wraps afs_addr_cursor for accessing VL servers rather than file
    servers).
    
    Fix this by setting fc->error in the afs_check/update_server_record() so
    that any error incurred whilst talking to the VL server correctly
    propagates to the final result.
    
    This results in:
    
            kAFS: Unexpected error from FS.StoreData -512
    
    being seen, even though the store-data op is non-interruptible.  The error
    is actually coming from the server record update getting interrupted.
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 65b33b6da48b..454c6357f51f 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -521,8 +521,8 @@ static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct a
 	alist = afs_vl_lookup_addrs(fc->vnode->volume->cell, fc->key,
 				    &server->uuid);
 	if (IS_ERR(alist)) {
-		fc->ac.error = PTR_ERR(alist);
-		_leave(" = f [%d]", fc->ac.error);
+		fc->error = PTR_ERR(alist);
+		_leave(" = f [%d]", fc->error);
 		return false;
 	}
 
@@ -574,7 +574,7 @@ bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server
 	ret = wait_on_bit(&server->flags, AFS_SERVER_FL_UPDATING,
 			  TASK_INTERRUPTIBLE);
 	if (ret == -ERESTARTSYS) {
-		fc->ac.error = ret;
+		fc->error = ret;
 		_leave(" = f [intr]");
 		return false;
 	}

commit eeba1e9cf31d064284dd1fa7bd6cfe01395bd03d
Author: David Howells <dhowells@redhat.com>
Date:   Sat Apr 13 08:37:37 2019 +0100

    afs: Fix in-progess ops to ignore server-level callback invalidation
    
    The in-kernel afs filesystem client counts the number of server-level
    callback invalidation events (CB.InitCallBackState* RPC operations) that it
    receives from the server.  This is stored in cb_s_break in various
    structures, including afs_server and afs_vnode.
    
    If an inode is examined by afs_validate(), say, the afs_server copy is
    compared, along with other break counters, to those in afs_vnode, and if
    one or more of the counters do not match, it is considered that the
    server's callback promise is broken.  At points where this happens,
    AFS_VNODE_CB_PROMISED is cleared to indicate that the status must be
    refetched from the server.
    
    afs_validate() issues an FS.FetchStatus operation to get updated metadata -
    and based on the updated data_version may invalidate the pagecache too.
    
    However, the break counters are also used to determine whether to note a
    new callback in the vnode (which would set the AFS_VNODE_CB_PROMISED flag)
    and whether to cache the permit data included in the YFSFetchStatus record
    by the server.
    
    
    The problem comes when the server sends us a CB.InitCallBackState op.  The
    first such instance doesn't cause cb_s_break to be incremented, but rather
    causes AFS_SERVER_FL_NEW to be cleared - but thereafter, say some hours
    after last use and all the volumes have been automatically unmounted and
    the server has forgotten about the client[*], this *will* likely cause an
    increment.
    
     [*] There are other circumstances too, such as the server restarting or
         needing to make space in its callback table.
    
    Note that the server won't send us a CB.InitCallBackState op until we talk
    to it again.
    
    So what happens is:
    
     (1) A mount for a new volume is attempted, a inode is created for the root
         vnode and vnode->cb_s_break and AFS_VNODE_CB_PROMISED aren't set
         immediately, as we don't have a nominated server to talk to yet - and
         we may iterate through a few to find one.
    
     (2) Before the operation happens, afs_fetch_status(), say, notes in the
         cursor (fc.cb_break) the break counter sum from the vnode, volume and
         server counters, but the server->cb_s_break is currently 0.
    
     (3) We send FS.FetchStatus to the server.  The server sends us back
         CB.InitCallBackState.  We increment server->cb_s_break.
    
     (4) Our FS.FetchStatus completes.  The reply includes a callback record.
    
     (5) xdr_decode_AFSCallBack()/xdr_decode_YFSCallBack() check to see whether
         the callback promise was broken by checking the break counter sum from
         step (2) against the current sum.
    
         This fails because of step (3), so we don't set the callback record
         and, importantly, don't set AFS_VNODE_CB_PROMISED on the vnode.
    
    This does not preclude the syscall from progressing, and we don't loop here
    rechecking the status, but rather assume it's good enough for one round
    only and will need to be rechecked next time.
    
     (6) afs_validate() it triggered on the vnode, probably called from
         d_revalidate() checking the parent directory.
    
     (7) afs_validate() notes that AFS_VNODE_CB_PROMISED isn't set, so doesn't
         update vnode->cb_s_break and assumes the vnode to be invalid.
    
     (8) afs_validate() needs to calls afs_fetch_status().  Go back to step (2)
         and repeat, every time the vnode is validated.
    
    This primarily affects volume root dir vnodes.  Everything subsequent to
    those inherit an already incremented cb_s_break upon mounting.
    
    
    The issue is that we assume that the callback record and the cached permit
    information in a reply from the server can't be trusted after getting a
    server break - but this is wrong since the server makes sure things are
    done in the right order, holding up our ops if necessary[*].
    
     [*] There is an extremely unlikely scenario where a reply from before the
         CB.InitCallBackState could get its delivery deferred till after - at
         which point we think we have a promise when we don't.  This, however,
         requires unlucky mass packet loss to one call.
    
    AFS_SERVER_FL_NEW tries to paper over the cracks for the initial mount from
    a server we've never contacted before, but this should be unnecessary.
    It's also further insulated from the problem on an initial mount by
    querying the server first with FS.GetCapabilities, which triggers the
    CB.InitCallBackState.
    
    
    Fix this by
    
     (1) Remove AFS_SERVER_FL_NEW.
    
     (2) In afs_calc_vnode_cb_break(), don't include cb_s_break in the
         calculation.
    
     (3) In afs_cb_is_broken(), don't include cb_s_break in the check.
    
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 642afa2e9783..65b33b6da48b 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -226,7 +226,6 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	RCU_INIT_POINTER(server->addresses, alist);
 	server->addr_version = alist->version;
 	server->uuid = *uuid;
-	server->flags = (1UL << AFS_SERVER_FL_NEW);
 	server->update_at = ktime_get_real_seconds() + afs_server_update_delay;
 	rwlock_init(&server->fs_lock);
 	INIT_HLIST_HEAD(&server->cb_volumes);

commit 3bf0fb6f33dd545693da5e65f5b1b9b9f0bfc35e
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 20 00:57:59 2018 +0100

    afs: Probe multiple fileservers simultaneously
    
    Send probes to all the unprobed fileservers in a fileserver list on all
    addresses simultaneously in an attempt to find out the fastest route whilst
    not getting stuck for 20s on any server or address that we don't get a
    reply from.
    
    This alleviates the problem whereby attempting to access a new server can
    take a long time because the rotation algorithm ends up rotating through
    all servers and addresses until it finds one that responds.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 7c1be8b4dc9a..642afa2e9783 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -231,6 +231,8 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	rwlock_init(&server->fs_lock);
 	INIT_HLIST_HEAD(&server->cb_volumes);
 	rwlock_init(&server->cb_break_lock);
+	init_waitqueue_head(&server->probe_wq);
+	spin_lock_init(&server->probe_lock);
 
 	afs_inc_servers_outstanding(net);
 	_leave(" = %p", server);
@@ -254,7 +256,7 @@ static struct afs_addr_list *afs_vl_lookup_addrs(struct afs_cell *cell,
 	ret = -ERESTARTSYS;
 	if (afs_begin_vlserver_operation(&vc, cell, key)) {
 		while (afs_select_vlserver(&vc)) {
-			if (test_bit(vc.ac.index, &vc.ac.alist->yfs))
+			if (test_bit(AFS_VLSERVER_FL_IS_YFS, &vc.server->flags))
 				alist = afs_yfsvl_get_endpoints(&vc, uuid);
 			else
 				alist = afs_vl_get_addrs_u(&vc, uuid);
@@ -365,8 +367,7 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 	struct afs_addr_list *alist = rcu_access_pointer(server->addresses);
 	struct afs_addr_cursor ac = {
 		.alist	= alist,
-		.start	= alist->index,
-		.index	= 0,
+		.index	= alist->preferred,
 		.error	= 0,
 	};
 	_enter("%p", server);
@@ -374,6 +375,9 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 	if (test_bit(AFS_SERVER_FL_MAY_HAVE_CB, &server->flags))
 		afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
 
+	wait_var_event(&server->probe_outstanding,
+		       atomic_read(&server->probe_outstanding) == 0);
+
 	call_rcu(&server->rcu, afs_server_rcu);
 	afs_dec_servers_outstanding(net);
 }
@@ -506,105 +510,6 @@ void afs_purge_servers(struct afs_net *net)
 	_leave("");
 }
 
-/*
- * Probe a fileserver to find its capabilities.
- *
- * TODO: Try service upgrade.
- */
-static bool afs_do_probe_fileserver(struct afs_fs_cursor *fc)
-{
-	int i;
-
-	_enter("");
-
-	fc->ac.start = READ_ONCE(fc->ac.alist->index);
-	fc->ac.index = fc->ac.start;
-	fc->ac.error = 0;
-	fc->ac.begun = false;
-
-	while (afs_iterate_addresses(&fc->ac)) {
-		afs_fs_get_capabilities(afs_v2net(fc->vnode), fc->cbi->server,
-					&fc->ac, fc->key);
-		switch (fc->ac.error) {
-		case 0:
-			if (test_bit(AFS_SERVER_FL_IS_YFS, &fc->cbi->server->flags)) {
-				for (i = 0; i < fc->ac.alist->nr_addrs; i++)
-					fc->ac.alist->addrs[i].srx_service =
-						YFS_FS_SERVICE;
-			}
-			afs_end_cursor(&fc->ac);
-			set_bit(AFS_SERVER_FL_PROBED, &fc->cbi->server->flags);
-			return true;
-		case -ECONNABORTED:
-			fc->ac.error = afs_abort_to_error(fc->ac.abort_code);
-			goto error;
-		case -ENOMEM:
-		case -ENONET:
-			goto error;
-		case -ENETUNREACH:
-		case -EHOSTUNREACH:
-		case -ECONNREFUSED:
-		case -ETIMEDOUT:
-		case -ETIME:
-			break;
-		default:
-			fc->ac.error = afs_io_error(NULL, afs_io_error_fs_probe_fail);
-			goto error;
-		}
-	}
-
-error:
-	afs_end_cursor(&fc->ac);
-	return false;
-}
-
-/*
- * If we haven't already, try probing the fileserver to get its capabilities.
- * We try not to instigate parallel probes, but it's possible that the parallel
- * probes will fail due to authentication failure when ours would succeed.
- *
- * TODO: Try sending an anonymous probe if an authenticated probe fails.
- */
-bool afs_probe_fileserver(struct afs_fs_cursor *fc)
-{
-	bool success;
-	int ret, retries = 0;
-
-	_enter("");
-
-retry:
-	if (test_bit(AFS_SERVER_FL_PROBED, &fc->cbi->server->flags)) {
-		_leave(" = t");
-		return true;
-	}
-
-	if (!test_and_set_bit_lock(AFS_SERVER_FL_PROBING, &fc->cbi->server->flags)) {
-		success = afs_do_probe_fileserver(fc);
-		clear_bit_unlock(AFS_SERVER_FL_PROBING, &fc->cbi->server->flags);
-		wake_up_bit(&fc->cbi->server->flags, AFS_SERVER_FL_PROBING);
-		_leave(" = t");
-		return success;
-	}
-
-	_debug("wait");
-	ret = wait_on_bit(&fc->cbi->server->flags, AFS_SERVER_FL_PROBING,
-			  TASK_INTERRUPTIBLE);
-	if (ret == -ERESTARTSYS) {
-		fc->ac.error = ret;
-		_leave(" = f [%d]", ret);
-		return false;
-	}
-
-	retries++;
-	if (retries == 4) {
-		fc->ac.error = -ESTALE;
-		_leave(" = f [stale]");
-		return false;
-	}
-	_debug("retry");
-	goto retry;
-}
-
 /*
  * Get an update for a server's address list.
  */

commit 2feeaf8433c8e68de3d0a06a0ffe7742bcd13c1a
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 20 00:57:59 2018 +0100

    afs: Eliminate the address pointer from the address list cursor
    
    Eliminate the address pointer from the address list cursor as it's
    redundant (ac->addrs[ac->index] can be used to find the same address) and
    address lists must be replaced rather than being rearranged, so is of
    limited value.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index aa35cfae5440..7c1be8b4dc9a 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -367,7 +367,6 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 		.alist	= alist,
 		.start	= alist->index,
 		.index	= 0,
-		.addr	= &alist->addrs[alist->index],
 		.error	= 0,
 	};
 	_enter("%p", server);
@@ -518,7 +517,6 @@ static bool afs_do_probe_fileserver(struct afs_fs_cursor *fc)
 
 	_enter("");
 
-	fc->ac.addr = NULL;
 	fc->ac.start = READ_ONCE(fc->ac.alist->index);
 	fc->ac.index = fc->ac.start;
 	fc->ac.error = 0;

commit 30062bd13e3659a309d249a06d5f4ebb4a5c5251
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 20 00:57:58 2018 +0100

    afs: Implement YFS support in the fs client
    
    Implement support for talking to YFS-variant fileservers in the cache
    manager and the filesystem client.  These implement upgraded services on
    the same port as their AFS services.
    
    YFS fileservers provide expanded capabilities over AFS.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 1a087eb8f2d7..aa35cfae5440 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -13,6 +13,7 @@
 #include <linux/slab.h>
 #include "afs_fs.h"
 #include "internal.h"
+#include "protocol_yfs.h"
 
 static unsigned afs_server_gc_delay = 10;	/* Server record timeout in seconds */
 static unsigned afs_server_update_delay = 30;	/* Time till VLDB recheck in secs */
@@ -513,6 +514,8 @@ void afs_purge_servers(struct afs_net *net)
  */
 static bool afs_do_probe_fileserver(struct afs_fs_cursor *fc)
 {
+	int i;
+
 	_enter("");
 
 	fc->ac.addr = NULL;
@@ -526,6 +529,11 @@ static bool afs_do_probe_fileserver(struct afs_fs_cursor *fc)
 					&fc->ac, fc->key);
 		switch (fc->ac.error) {
 		case 0:
+			if (test_bit(AFS_SERVER_FL_IS_YFS, &fc->cbi->server->flags)) {
+				for (i = 0; i < fc->ac.alist->nr_addrs; i++)
+					fc->ac.alist->addrs[i].srx_service =
+						YFS_FS_SERVICE;
+			}
 			afs_end_cursor(&fc->ac);
 			set_bit(AFS_SERVER_FL_PROBED, &fc->cbi->server->flags);
 			return true;

commit f51375cd9e1ad75e9e38186aa0d3749ade7d52a5
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 20 00:57:57 2018 +0100

    afs: Add a couple of tracepoints to log I/O errors
    
    Add a couple of tracepoints to log the production of I/O errors within the AFS
    filesystem.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 6102ea9ee3fb..1a087eb8f2d7 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -542,7 +542,7 @@ static bool afs_do_probe_fileserver(struct afs_fs_cursor *fc)
 		case -ETIME:
 			break;
 		default:
-			fc->ac.error = -EIO;
+			fc->ac.error = afs_io_error(NULL, afs_io_error_fs_probe_fail);
 			goto error;
 		}
 	}

commit 0a5143f2f89cc88d8a3eada8e8ccd86c1e988257
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 20 00:57:57 2018 +0100

    afs: Implement VL server rotation
    
    Track VL servers as independent entities rather than lumping all their
    addresses together into one set and implement server-level rotation by:
    
     (1) Add the concept of a VL server list, where each server has its own
         separate address list.  This code is similar to the FS server list.
    
     (2) Use the DNS resolver to retrieve a set of servers and their associated
         addresses, ports, preference and weight ratings.
    
     (3) In the case of a legacy DNS resolver or an address list given directly
         through /proc/net/afs/cells, create a list containing just a dummy
         server record and attach all the addresses to that.
    
     (4) Implement a simple rotation policy, for the moment ignoring the
         priorities and weights assigned to the servers.
    
     (5) Show the address list through /proc/net/afs/<cell>/vlservers.  This
         also displays the source and status of the data as indicated by the
         upcall.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 1d329e6981d5..6102ea9ee3fb 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -246,41 +246,23 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 static struct afs_addr_list *afs_vl_lookup_addrs(struct afs_cell *cell,
 						 struct key *key, const uuid_t *uuid)
 {
-	struct afs_addr_cursor ac;
-	struct afs_addr_list *alist;
+	struct afs_vl_cursor vc;
+	struct afs_addr_list *alist = NULL;
 	int ret;
 
-	ret = afs_set_vl_cursor(&ac, cell);
-	if (ret < 0)
-		return ERR_PTR(ret);
-
-	while (afs_iterate_addresses(&ac)) {
-		if (test_bit(ac.index, &ac.alist->yfs))
-			alist = afs_yfsvl_get_endpoints(cell->net, &ac, key, uuid);
-		else
-			alist = afs_vl_get_addrs_u(cell->net, &ac, key, uuid);
-		switch (ac.error) {
-		case 0:
-			afs_end_cursor(&ac);
-			return alist;
-		case -ECONNABORTED:
-			ac.error = afs_abort_to_error(ac.abort_code);
-			goto error;
-		case -ENOMEM:
-		case -ENONET:
-			goto error;
-		case -ENETUNREACH:
-		case -EHOSTUNREACH:
-		case -ECONNREFUSED:
-			break;
-		default:
-			ac.error = -EIO;
-			goto error;
+	ret = -ERESTARTSYS;
+	if (afs_begin_vlserver_operation(&vc, cell, key)) {
+		while (afs_select_vlserver(&vc)) {
+			if (test_bit(vc.ac.index, &vc.ac.alist->yfs))
+				alist = afs_yfsvl_get_endpoints(&vc, uuid);
+			else
+				alist = afs_vl_get_addrs_u(&vc, uuid);
 		}
+
+		ret = afs_end_vlserver_operation(&vc);
 	}
 
-error:
-	return ERR_PTR(afs_end_cursor(&ac));
+	return ret < 0 ? ERR_PTR(ret) : alist;
 }
 
 /*

commit f0a7d1883d9f78ae7bf15fc258bf9a2b20f35b76
Author: David Howells <dhowells@redhat.com>
Date:   Mon Oct 15 12:43:02 2018 +0100

    afs: Fix clearance of reply
    
    The recent patch to fix the afs_server struct leak didn't actually fix the
    bug, but rather fixed some of the symptoms.  The problem is that an
    asynchronous call that holds a resource pointed to by call->reply[0] will
    find the pointer cleared in the call destructor, thereby preventing the
    resource from being cleaned up.
    
    In the case of the server record leak, the afs_fs_get_capabilities()
    function in devel code sets up a call with reply[0] pointing at the server
    record that should be altered when the result is obtained, but this was
    being cleared before the destructor was called, so the put in the
    destructor does nothing and the record is leaked.
    
    Commit f014ffb025c1 removed the additional ref obtained by
    afs_install_server(), but the removal of this ref is actually used by the
    garbage collector to mark a server record as being defunct after the record
    has expired through lack of use.
    
    The offending clearance of call->reply[0] upon completion in
    afs_process_async_call() has been there from the origin of the code, but
    none of the asynchronous calls actually use that pointer currently, so it
    should be safe to remove (note that synchronous calls don't involve this
    function).
    
    Fix this by the following means:
    
     (1) Revert commit f014ffb025c1.
    
     (2) Remove the clearance of reply[0] from afs_process_async_call().
    
    Without this, afs_manage_servers() will suffer an assertion failure if it
    sees a server record that didn't get used because the usage count is not 1.
    
    Fixes: f014ffb025c1 ("afs: Fix afs_server struct leak")
    Fixes: 08e0e7c82eea ("[AF_RXRPC]: Make the in-kernel AFS filesystem use AF_RXRPC.")
    Signed-off-by: David Howells <dhowells@redhat.com>
    Cc: stable <stable@vger.kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 2f306c0cc4ee..1d329e6981d5 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -199,11 +199,9 @@ static struct afs_server *afs_install_server(struct afs_net *net,
 
 	write_sequnlock(&net->fs_addr_lock);
 	ret = 0;
-	goto out;
 
 exists:
 	afs_get_server(server);
-out:
 	write_sequnlock(&net->fs_lock);
 	return server;
 }

commit f014ffb025c159fd51d19af8af0022a991aaa4f8
Author: David Howells <dhowells@redhat.com>
Date:   Fri Oct 12 14:00:57 2018 +0100

    afs: Fix afs_server struct leak
    
    Fix a leak of afs_server structs.  The routine that installs them in the
    various lookup lists and trees gets a ref on leaving the function, whether
    it added the server or a server already exists.  It shouldn't increment
    the refcount if it added the server.
    
    The effect of this that "rmmod kafs" will hang waiting for the leaked
    server to become unused.
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 1d329e6981d5..2f306c0cc4ee 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -199,9 +199,11 @@ static struct afs_server *afs_install_server(struct afs_net *net,
 
 	write_sequnlock(&net->fs_addr_lock);
 	ret = 0;
+	goto out;
 
 exists:
 	afs_get_server(server);
+out:
 	write_sequnlock(&net->fs_lock);
 	return server;
 }

commit 47ea0f2ebffd400d36ab5946ec8d6d6e08a67d53
Author: David Howells <dhowells@redhat.com>
Date:   Fri Jun 15 15:24:50 2018 +0100

    afs: Optimise callback breaking by not repeating volume lookup
    
    At the moment, afs_break_callbacks calls afs_break_one_callback() for each
    separate FID it was given, and the latter looks up the volume individually
    for each one.
    
    However, this is inefficient if two or more FIDs have the same vid as we
    could reuse the volume.  This is complicated by cell aliasing whereby we
    may have multiple cells sharing a volume and can therefore have multiple
    callback interests for any particular volume ID.
    
    At the moment afs_break_one_callback() scans the entire list of volumes
    we're getting from a server and breaks the appropriate callback in every
    matching volume, regardless of cell.  This scan is done for every FID.
    
    Optimise callback breaking by the following means:
    
     (1) Sort the FID list by vid so that all FIDs belonging to the same volume
         are clumped together.
    
         This is done through the use of an indirection table as we cannot do
         an insertion sort on the afs_callback_break array as we decode FIDs
         into it as we subsequently also have to decode callback info into it
         that corresponds by array index only.
    
         We also don't really want to bubblesort afterwards if we can avoid it.
    
     (2) Sort the server->cb_interests array by vid so that all the matching
         volumes are grouped together.  This permits the scan to stop after
         finding a record that has a higher vid.
    
     (3) When breaking FIDs, we try to keep server->cb_break_lock as long as
         possible, caching the start point in the array for that volume group
         as long as possible.
    
         It might make sense to add another layer in that list and have a
         refcounted volume ID anchor that has the matching interests attached
         to it rather than being in the list.  This would allow the lock to be
         dropped without losing the cursor.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 3af4625e2f8c..1d329e6981d5 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -228,7 +228,7 @@ static struct afs_server *afs_alloc_server(struct afs_net *net,
 	server->flags = (1UL << AFS_SERVER_FL_NEW);
 	server->update_at = ktime_get_real_seconds() + afs_server_update_delay;
 	rwlock_init(&server->fs_lock);
-	INIT_LIST_HEAD(&server->cb_interests);
+	INIT_HLIST_HEAD(&server->cb_volumes);
 	rwlock_init(&server->cb_break_lock);
 
 	afs_inc_servers_outstanding(net);

commit f9c1bba3d392843f046d2ee27b4dfcec989d8a4b
Author: Marc Dionne <marc.dionne@auristor.com>
Date:   Fri May 11 21:35:06 2018 -0300

    afs: Fix afs_find_server search loop
    
    The code that looks up servers by addresses makes the assumption
    that the list of addresses for a server is sorted.  It exits the
    loop if it finds that the target address is larger than the
    current candidate.  As the list is not currently sorted, this
    can lead to a failure to find a matching server, which can cause
    callbacks from that server to be ignored.
    
    Remove the early exit case so that the complete list is searched.
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Signed-off-by: Marc Dionne <marc.dionne@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 2c5cff60e34d..3af4625e2f8c 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -67,12 +67,6 @@ struct afs_server *afs_find_server(struct afs_net *net,
 							      sizeof(struct in6_addr));
 					if (diff == 0)
 						goto found;
-					if (diff < 0) {
-						// TODO: Sort the list
-						//if (i == alist->nr_ipv4)
-						//	goto not_found;
-						break;
-					}
 				}
 			}
 		} else {
@@ -87,17 +81,10 @@ struct afs_server *afs_find_server(struct afs_net *net,
 							(u32 __force)b->sin6_addr.s6_addr32[3]);
 					if (diff == 0)
 						goto found;
-					if (diff < 0) {
-						// TODO: Sort the list
-						//if (i == 0)
-						//	goto not_found;
-						break;
-					}
 				}
 			}
 		}
 
-	//not_found:
 		server = NULL;
 	found:
 		if (server && !atomic_inc_not_zero(&server->usage))

commit f2686b09269ec1a6f23028b5675d87c3b4579a4c
Author: David Howells <dhowells@redhat.com>
Date:   Thu May 10 14:12:50 2018 +0100

    afs: Fix giving up callbacks on server destruction
    
    When a server record is destroyed, we want to send a message to the server
    telling it that we're giving up all the callbacks it has promised us.
    
    Apply two fixes to this:
    
     (1) Only send the FS.GiveUpAllCallBacks message if we actually got a
         callback from that server.  We assume this to be the case if we
         performed at least one successful FS operation on that server.
    
     (2) Send it to the address last used for that server rather than always
         picking the first address in the list (which might be unreachable).
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 629c74986cff..2c5cff60e34d 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -395,14 +395,16 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 	struct afs_addr_list *alist = rcu_access_pointer(server->addresses);
 	struct afs_addr_cursor ac = {
 		.alist	= alist,
-		.addr	= &alist->addrs[0],
 		.start	= alist->index,
-		.index	= alist->index,
+		.index	= 0,
+		.addr	= &alist->addrs[alist->index],
 		.error	= 0,
 	};
 	_enter("%p", server);
 
-	afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
+	if (test_bit(AFS_SERVER_FL_MAY_HAVE_CB, &server->flags))
+		afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
+
 	call_rcu(&server->rcu, afs_server_rcu);
 	afs_dec_servers_outstanding(net);
 }

commit 660625922b3d9fcb376e5870299bc5c1086e1d32
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 18 09:38:34 2018 +0100

    afs: Fix server record deletion
    
    AFS server records get removed from the net->fs_servers tree when
    they're deleted, but not from the net->fs_addresses{4,6} lists, which
    can lead to an oops in afs_find_server() when a server record has been
    removed, for instance during rmmod.
    
    Fix this by deleting the record from the by-address lists before posting
    it for RCU destruction.
    
    The reason this hasn't been noticed before is that the fileserver keeps
    probing the local cache manager, thereby keeping the service record
    alive, so the oops would only happen when a fileserver eventually gets
    bored and stops pinging or if the module gets rmmod'd and a call comes
    in from the fileserver during the window between the server records
    being destroyed and the socket being closed.
    
    The oops looks something like:
    
      BUG: unable to handle kernel NULL pointer dereference at 000000000000001c
      ...
      Workqueue: kafsd afs_process_async_call [kafs]
      RIP: 0010:afs_find_server+0x271/0x36f [kafs]
      ...
      Call Trace:
       afs_deliver_cb_init_call_back_state3+0x1f2/0x21f [kafs]
       afs_deliver_to_call+0x1ee/0x5e8 [kafs]
       afs_process_async_call+0x5b/0xd0 [kafs]
       process_one_work+0x2c2/0x504
       worker_thread+0x1d4/0x2ac
       kthread+0x11f/0x127
       ret_from_fork+0x24/0x30
    
    Fixes: d2ddc776a458 ("afs: Overhaul volume and server record caching and fileserver rotation")
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index e23be63998a8..629c74986cff 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -428,8 +428,15 @@ static void afs_gc_servers(struct afs_net *net, struct afs_server *gc_list)
 		}
 		write_sequnlock(&net->fs_lock);
 
-		if (deleted)
+		if (deleted) {
+			write_seqlock(&net->fs_addr_lock);
+			if (!hlist_unhashed(&server->addr4_link))
+				hlist_del_rcu(&server->addr4_link);
+			if (!hlist_unhashed(&server->addr6_link))
+				hlist_del_rcu(&server->addr6_link);
+			write_sequnlock(&net->fs_addr_lock);
 			afs_destroy_server(net, server);
+		}
 	}
 }
 

commit fe342cf77bc3c3ba89e8bb1e4eddbe614df4efa4
Author: David Howells <dhowells@redhat.com>
Date:   Mon Apr 9 21:12:31 2018 +0100

    afs: Fix checker warnings
    
    Fix warnings raised by checker, including:
    
     (*) Warnings raised by unequal comparison for the purposes of sorting,
         where the endianness doesn't matter:
    
    fs/afs/addr_list.c:246:21: warning: restricted __be16 degrades to integer
    fs/afs/addr_list.c:246:30: warning: restricted __be16 degrades to integer
    fs/afs/addr_list.c:248:21: warning: restricted __be32 degrades to integer
    fs/afs/addr_list.c:248:49: warning: restricted __be32 degrades to integer
    fs/afs/addr_list.c:283:21: warning: restricted __be16 degrades to integer
    fs/afs/addr_list.c:283:30: warning: restricted __be16 degrades to integer
    
     (*) afs_set_cb_interest() is not actually used and can be removed.
    
     (*) afs_cell_gc_delay() should be provided with a sysctl.
    
     (*) afs_cell_destroy() needs to use rcu_access_pointer() to read
         cell->vl_addrs.
    
     (*) afs_init_fs_cursor() should be static.
    
     (*) struct afs_vnode::permit_cache needs to be marked __rcu.
    
     (*) afs_server_rcu() needs to use rcu_access_pointer().
    
     (*) afs_destroy_server() should use rcu_access_pointer() on
         server->addresses as the server object is no longer accessible.
    
     (*) afs_find_server() casts __be16/__be32 values to int in order to
         directly compare them for the purpose of finding a match in a list,
         but is should also annotate the cast with __force to avoid checker
         warnings.
    
     (*) afs_check_permit() accesses vnode->permit_cache outside of the RCU
         readlock, though it doesn't then access the value; the extraneous
         access is deleted.
    
    False positives:
    
     (*) Conditional locking around the code in xdr_decode_AFSFetchStatus.  This
         can be dealt with in a separate patch.
    
    fs/afs/fsclient.c:148:9: warning: context imbalance in 'xdr_decode_AFSFetchStatus' - different lock contexts for basic block
    
     (*) Incorrect handling of seq-retry lock context balance:
    
    fs/afs/inode.c:455:38: warning: context imbalance in 'afs_getattr' - different
    lock contexts for basic block
    fs/afs/server.c:52:17: warning: context imbalance in 'afs_find_server' - different lock contexts for basic block
    fs/afs/server.c:128:17: warning: context imbalance in 'afs_find_server_by_uuid' - different lock contexts for basic block
    
    Errors:
    
     (*) afs_lookup_cell_rcu() needs to break out of the seq-retry loop, not go
         round again if it successfully found the workstation cell.
    
     (*) Fix UUID decode in afs_deliver_cb_probe_uuid().
    
     (*) afs_cache_permit() has a missing rcu_read_unlock() before one of the
         jumps to the someone_else_changed_it label.  Move the unlock to after
         the label.
    
     (*) afs_vl_get_addrs_u() is using ntohl() rather than htonl() when
         encoding to XDR.
    
     (*) afs_deliver_yfsvl_get_endpoints() is using htonl() rather than ntohl()
         when decoding from XDR.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index a43ef77dabae..e23be63998a8 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -59,7 +59,8 @@ struct afs_server *afs_find_server(struct afs_net *net,
 				alist = rcu_dereference(server->addresses);
 				for (i = alist->nr_ipv4; i < alist->nr_addrs; i++) {
 					b = &alist->addrs[i].transport.sin6;
-					diff = (u16)a->sin6_port - (u16)b->sin6_port;
+					diff = ((u16 __force)a->sin6_port -
+						(u16 __force)b->sin6_port);
 					if (diff == 0)
 						diff = memcmp(&a->sin6_addr,
 							      &b->sin6_addr,
@@ -79,10 +80,11 @@ struct afs_server *afs_find_server(struct afs_net *net,
 				alist = rcu_dereference(server->addresses);
 				for (i = 0; i < alist->nr_ipv4; i++) {
 					b = &alist->addrs[i].transport.sin6;
-					diff = (u16)a->sin6_port - (u16)b->sin6_port;
+					diff = ((u16 __force)a->sin6_port -
+						(u16 __force)b->sin6_port);
 					if (diff == 0)
-						diff = ((u32)a->sin6_addr.s6_addr32[3] -
-							(u32)b->sin6_addr.s6_addr32[3]);
+						diff = ((u32 __force)a->sin6_addr.s6_addr32[3] -
+							(u32 __force)b->sin6_addr.s6_addr32[3]);
 					if (diff == 0)
 						goto found;
 					if (diff < 0) {
@@ -381,7 +383,7 @@ static void afs_server_rcu(struct rcu_head *rcu)
 {
 	struct afs_server *server = container_of(rcu, struct afs_server, rcu);
 
-	afs_put_addrlist(server->addresses);
+	afs_put_addrlist(rcu_access_pointer(server->addresses));
 	kfree(server);
 }
 
@@ -390,7 +392,7 @@ static void afs_server_rcu(struct rcu_head *rcu)
  */
 static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 {
-	struct afs_addr_list *alist = server->addresses;
+	struct afs_addr_list *alist = rcu_access_pointer(server->addresses);
 	struct afs_addr_cursor ac = {
 		.alist	= alist,
 		.addr	= &alist->addrs[0],

commit ab1fbe32477619b99921a203d16de9e66526b22a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Mar 15 11:42:28 2018 +0100

    sched/wait, fs/afs: Convert wait_on_atomic_t() usage to the new wait_var_event() API
    
    The old wait_on_atomic_t() is going to get removed, use the more
    flexible wait_var_event() API instead.
    
    No change in functionality.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 1880f1b6a9f1..a43ef77dabae 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -25,7 +25,7 @@ static void afs_inc_servers_outstanding(struct afs_net *net)
 static void afs_dec_servers_outstanding(struct afs_net *net)
 {
 	if (atomic_dec_and_test(&net->servers_outstanding))
-		wake_up_atomic_t(&net->servers_outstanding);
+		wake_up_var(&net->servers_outstanding);
 }
 
 /*
@@ -521,8 +521,8 @@ void afs_purge_servers(struct afs_net *net)
 	afs_queue_server_manager(net);
 
 	_debug("wait");
-	wait_on_atomic_t(&net->servers_outstanding, atomic_t_wait,
-			 TASK_UNINTERRUPTIBLE);
+	wait_var_event(&net->servers_outstanding,
+		       !atomic_read(&net->servers_outstanding));
 	_leave("");
 }
 

commit bf99a53ce22a29d64d3190093edf52f1d44d53b3
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:51 2017 +0000

    afs: Make use of the YFS service upgrade to fully support IPv6
    
    YFS VL servers offer an upgraded Volume Location service that can return
    IPv6 addresses to fileservers and volume servers in addition to IPv4
    addresses using the YFSVL.GetEndpoints operation which we should use if
    it's available.
    
    To this end:
    
     (1) Make rxrpc_kernel_recv_data() return the call's current service ID so
         that the caller can detect service upgrade and see what the service
         was upgraded to.
    
     (2) When we see a VL server address we haven't seen before, send a
         VL.GetCapabilities operation to it with the service upgrade bit set.
    
         If we get an upgrade to the YFS VL service, change the service ID in
         the address list for that address to use the upgraded service and set
         a flag to note that this appears to be a YFS-compatible server.
    
     (3) If, when a server's addresses are being looked up, we note that we
         previously detected a YFS-compatible server, then send the
         YFSVL.GetEndpoints operation rather than VL.GetAddrsU.
    
     (4) Build a fileserver address list from the reply of YFSVL.GetEndpoints,
         including both IPv4 and IPv6 addresses.  Volume server addresses are
         discarded.
    
     (5) The address list is sorted by address and port now, instead of just
         address.  This allows multiple servers on the same host sitting on
         different ports.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index a6c860bcf391..1880f1b6a9f1 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -266,7 +266,10 @@ static struct afs_addr_list *afs_vl_lookup_addrs(struct afs_cell *cell,
 		return ERR_PTR(ret);
 
 	while (afs_iterate_addresses(&ac)) {
-		alist = afs_vl_get_addrs_u(cell->net, &ac, key, uuid);
+		if (test_bit(ac.index, &ac.alist->yfs))
+			alist = afs_yfsvl_get_endpoints(cell->net, &ac, key, uuid);
+		else
+			alist = afs_vl_get_addrs_u(cell->net, &ac, key, uuid);
 		switch (ac.error) {
 		case 0:
 			afs_end_cursor(&ac);

commit d2ddc776a4581d900fc3bdc7803b403daae64d88
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:50 2017 +0000

    afs: Overhaul volume and server record caching and fileserver rotation
    
    The current code assumes that volumes and servers are per-cell and are
    never shared, but this is not enforced, and, indeed, public cells do exist
    that are aliases of each other.  Further, an organisation can, say, set up
    a public cell and a private cell with overlapping, but not identical, sets
    of servers.  The difference is purely in the database attached to the VL
    servers.
    
    The current code will malfunction if it sees a server in two cells as it
    assumes global address -> server record mappings and that each server is in
    just one cell.
    
    Further, each server may have multiple addresses - and may have addresses
    of different families (IPv4 and IPv6, say).
    
    To this end, the following structural changes are made:
    
     (1) Server record management is overhauled:
    
         (a) Server records are made independent of cell.  The namespace keeps
             track of them, volume records have lists of them and each vnode
             has a server on which its callback interest currently resides.
    
         (b) The cell record no longer keeps a list of servers known to be in
             that cell.
    
         (c) The server records are now kept in a flat list because there's no
             single address to sort on.
    
         (d) Server records are now keyed by their UUID within the namespace.
    
         (e) The addresses for a server are obtained with the VL.GetAddrsU
             rather than with VL.GetEntryByName, using the server's UUID as a
             parameter.
    
         (f) Cached server records are garbage collected after a period of
             non-use and are counted out of existence before purging is allowed
             to complete.  This protects the work functions against rmmod.
    
         (g) The servers list is now in /proc/fs/afs/servers.
    
     (2) Volume record management is overhauled:
    
         (a) An RCU-replaceable server list is introduced.  This tracks both
             servers and their coresponding callback interests.
    
         (b) The superblock is now keyed on cell record and numeric volume ID.
    
         (c) The volume record is now tied to the superblock which mounts it,
             and is activated when mounted and deactivated when unmounted.
             This makes it easier to handle the cache cookie without causing a
             double-use in fscache.
    
         (d) The volume record is loaded from the VLDB using VL.GetEntryByNameU
             to get the server UUID list.
    
         (e) The volume name is updated if it is seen to have changed when the
             volume is updated (the update is keyed on the volume ID).
    
     (3) The vlocation record is got rid of and VLDB records are no longer
         cached.  Sufficient information is stored in the volume record, though
         an update to a volume record is now no longer shared between related
         volumes (volumes come in bundles of three: R/W, R/O and backup).
    
    and the following procedural changes are made:
    
     (1) The fileserver cursor introduced previously is now fleshed out and
         used to iterate over fileservers and their addresses.
    
     (2) Volume status is checked during iteration, and the server list is
         replaced if a change is detected.
    
     (3) Server status is checked during iteration, and the address list is
         replaced if a change is detected.
    
     (4) The abort code is saved into the address list cursor and -ECONNABORTED
         returned in afs_make_call() if a remote abort happened rather than
         translating the abort into an error message.  This allows actions to
         be taken depending on the abort code more easily.
    
         (a) If a VMOVED abort is seen then this is handled by rechecking the
             volume and restarting the iteration.
    
         (b) If a VBUSY, VRESTARTING or VSALVAGING abort is seen then this is
             handled by sleeping for a short period and retrying and/or trying
             other servers that might serve that volume.  A message is also
             displayed once until the condition has cleared.
    
         (c) If a VOFFLINE abort is seen, then this is handled as VBUSY for the
             moment.
    
         (d) If a VNOVOL abort is seen, the volume is rechecked in the VLDB to
             see if it has been deleted; if not, the fileserver is probably
             indicating that the volume couldn't be attached and needs
             salvaging.
    
         (e) If statfs() sees one of these aborts, it does not sleep, but
             rather returns an error, so as not to block the umount program.
    
     (5) The fileserver iteration functions in vnode.c are now merged into
         their callers and more heavily macroised around the cursor.  vnode.c
         is removed.
    
     (6) Operations on a particular vnode are serialised on that vnode because
         the server will lock that vnode whilst it operates on it, so a second
         op sent will just have to wait.
    
     (7) Fileservers are probed with FS.GetCapabilities before being used.
         This is where service upgrade will be done.
    
     (8) A callback interest on a fileserver is set up before an FS operation
         is performed and passed through to afs_make_call() so that it can be
         set on the vnode if the operation returns a callback.  The callback
         interest is passed through to afs_iget() also so that it can be set
         there too.
    
    In general, record updating is done on an as-needed basis when we try to
    access servers, volumes or vnodes rather than offloading it to work items
    and special threads.
    
    Notes:
    
     (1) Pre AFS-3.4 servers are no longer supported, though this can be added
         back if necessary (AFS-3.4 was released in 1998).
    
     (2) VBUSY is retried forever for the moment at intervals of 1s.
    
     (3) /proc/fs/afs/<cell>/servers no longer exists.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 9ca174b24f5b..a6c860bcf391 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -14,7 +14,8 @@
 #include "afs_fs.h"
 #include "internal.h"
 
-static unsigned afs_server_timeout = 10;	/* server timeout in seconds */
+static unsigned afs_server_gc_delay = 10;	/* Server record timeout in seconds */
+static unsigned afs_server_update_delay = 30;	/* Time till VLDB recheck in secs */
 
 static void afs_inc_servers_outstanding(struct afs_net *net)
 {
@@ -27,60 +28,201 @@ static void afs_dec_servers_outstanding(struct afs_net *net)
 		wake_up_atomic_t(&net->servers_outstanding);
 }
 
-void afs_server_timer(struct timer_list *timer)
+/*
+ * Find a server by one of its addresses.
+ */
+struct afs_server *afs_find_server(struct afs_net *net,
+				   const struct sockaddr_rxrpc *srx)
 {
-	struct afs_net *net = container_of(timer, struct afs_net, server_timer);
+	const struct sockaddr_in6 *a = &srx->transport.sin6, *b;
+	const struct afs_addr_list *alist;
+	struct afs_server *server = NULL;
+	unsigned int i;
+	bool ipv6 = true;
+	int seq = 0, diff;
+
+	if (srx->transport.sin6.sin6_addr.s6_addr32[0] == 0 ||
+	    srx->transport.sin6.sin6_addr.s6_addr32[1] == 0 ||
+	    srx->transport.sin6.sin6_addr.s6_addr32[2] == htonl(0xffff))
+		ipv6 = false;
+
+	rcu_read_lock();
+
+	do {
+		if (server)
+			afs_put_server(net, server);
+		server = NULL;
+		read_seqbegin_or_lock(&net->fs_addr_lock, &seq);
+
+		if (ipv6) {
+			hlist_for_each_entry_rcu(server, &net->fs_addresses6, addr6_link) {
+				alist = rcu_dereference(server->addresses);
+				for (i = alist->nr_ipv4; i < alist->nr_addrs; i++) {
+					b = &alist->addrs[i].transport.sin6;
+					diff = (u16)a->sin6_port - (u16)b->sin6_port;
+					if (diff == 0)
+						diff = memcmp(&a->sin6_addr,
+							      &b->sin6_addr,
+							      sizeof(struct in6_addr));
+					if (diff == 0)
+						goto found;
+					if (diff < 0) {
+						// TODO: Sort the list
+						//if (i == alist->nr_ipv4)
+						//	goto not_found;
+						break;
+					}
+				}
+			}
+		} else {
+			hlist_for_each_entry_rcu(server, &net->fs_addresses4, addr4_link) {
+				alist = rcu_dereference(server->addresses);
+				for (i = 0; i < alist->nr_ipv4; i++) {
+					b = &alist->addrs[i].transport.sin6;
+					diff = (u16)a->sin6_port - (u16)b->sin6_port;
+					if (diff == 0)
+						diff = ((u32)a->sin6_addr.s6_addr32[3] -
+							(u32)b->sin6_addr.s6_addr32[3]);
+					if (diff == 0)
+						goto found;
+					if (diff < 0) {
+						// TODO: Sort the list
+						//if (i == 0)
+						//	goto not_found;
+						break;
+					}
+				}
+			}
+		}
 
-	if (!queue_work(afs_wq, &net->server_reaper))
-		afs_dec_servers_outstanding(net);
+	//not_found:
+		server = NULL;
+	found:
+		if (server && !atomic_inc_not_zero(&server->usage))
+			server = NULL;
+
+	} while (need_seqretry(&net->fs_addr_lock, seq));
+
+	done_seqretry(&net->fs_addr_lock, seq);
+
+	rcu_read_unlock();
+	return server;
 }
 
 /*
- * install a server record in the master tree
+ * Look up a server by its UUID
  */
-static int afs_install_server(struct afs_server *server)
+struct afs_server *afs_find_server_by_uuid(struct afs_net *net, const uuid_t *uuid)
 {
-	struct afs_server *xserver;
-	struct afs_net *net = server->cell->net;
+	struct afs_server *server = NULL;
+	struct rb_node *p;
+	int diff, seq = 0;
+
+	_enter("%pU", uuid);
+
+	do {
+		/* Unfortunately, rbtree walking doesn't give reliable results
+		 * under just the RCU read lock, so we have to check for
+		 * changes.
+		 */
+		if (server)
+			afs_put_server(net, server);
+		server = NULL;
+
+		read_seqbegin_or_lock(&net->fs_lock, &seq);
+
+		p = net->fs_servers.rb_node;
+		while (p) {
+			server = rb_entry(p, struct afs_server, uuid_rb);
+
+			diff = memcmp(uuid, &server->uuid, sizeof(*uuid));
+			if (diff < 0) {
+				p = p->rb_left;
+			} else if (diff > 0) {
+				p = p->rb_right;
+			} else {
+				afs_get_server(server);
+				break;
+			}
+
+			server = NULL;
+		}
+	} while (need_seqretry(&net->fs_lock, seq));
+
+	done_seqretry(&net->fs_lock, seq);
+
+	_leave(" = %p", server);
+	return server;
+}
+
+/*
+ * Install a server record in the namespace tree
+ */
+static struct afs_server *afs_install_server(struct afs_net *net,
+					     struct afs_server *candidate)
+{
+	const struct afs_addr_list *alist;
+	struct afs_server *server;
 	struct rb_node **pp, *p;
-	int ret, diff;
+	int ret = -EEXIST, diff;
 
-	_enter("%p", server);
+	_enter("%p", candidate);
 
-	write_lock(&net->servers_lock);
+	write_seqlock(&net->fs_lock);
 
-	ret = -EEXIST;
-	pp = &net->servers.rb_node;
+	/* Firstly install the server in the UUID lookup tree */
+	pp = &net->fs_servers.rb_node;
 	p = NULL;
 	while (*pp) {
 		p = *pp;
 		_debug("- consider %p", p);
-		xserver = rb_entry(p, struct afs_server, master_rb);
-		diff = memcmp(&server->addrs->addrs[0],
-			      &xserver->addrs->addrs[0],
-			      sizeof(sizeof(server->addrs->addrs[0])));
+		server = rb_entry(p, struct afs_server, uuid_rb);
+		diff = memcmp(&candidate->uuid, &server->uuid, sizeof(uuid_t));
 		if (diff < 0)
 			pp = &(*pp)->rb_left;
 		else if (diff > 0)
 			pp = &(*pp)->rb_right;
 		else
-			goto error;
+			goto exists;
 	}
 
-	rb_link_node(&server->master_rb, p, pp);
-	rb_insert_color(&server->master_rb, &net->servers);
+	server = candidate;
+	rb_link_node(&server->uuid_rb, p, pp);
+	rb_insert_color(&server->uuid_rb, &net->fs_servers);
+	hlist_add_head_rcu(&server->proc_link, &net->fs_proc);
+
+	write_seqlock(&net->fs_addr_lock);
+	alist = rcu_dereference_protected(server->addresses,
+					  lockdep_is_held(&net->fs_addr_lock.lock));
+
+	/* Secondly, if the server has any IPv4 and/or IPv6 addresses, install
+	 * it in the IPv4 and/or IPv6 reverse-map lists.
+	 *
+	 * TODO: For speed we want to use something other than a flat list
+	 * here; even sorting the list in terms of lowest address would help a
+	 * bit, but anything we might want to do gets messy and memory
+	 * intensive.
+	 */
+	if (alist->nr_ipv4 > 0)
+		hlist_add_head_rcu(&server->addr4_link, &net->fs_addresses4);
+	if (alist->nr_addrs > alist->nr_ipv4)
+		hlist_add_head_rcu(&server->addr6_link, &net->fs_addresses6);
+
+	write_sequnlock(&net->fs_addr_lock);
 	ret = 0;
 
-error:
-	write_unlock(&net->servers_lock);
-	return ret;
+exists:
+	afs_get_server(server);
+	write_sequnlock(&net->fs_lock);
+	return server;
 }
 
 /*
  * allocate a new server record
  */
-static struct afs_server *afs_alloc_server(struct afs_cell *cell,
-					   const struct sockaddr_rxrpc *addr)
+static struct afs_server *afs_alloc_server(struct afs_net *net,
+					   const uuid_t *uuid,
+					   struct afs_addr_list *alist)
 {
 	struct afs_server *server;
 
@@ -89,194 +231,155 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 	server = kzalloc(sizeof(struct afs_server), GFP_KERNEL);
 	if (!server)
 		goto enomem;
-	server->addrs = kzalloc(sizeof(struct afs_addr_list) +
-				sizeof(struct sockaddr_rxrpc),
-				GFP_KERNEL);
-	if (!server->addrs)
-		goto enomem_server;
 
 	atomic_set(&server->usage, 1);
-	server->net = cell->net;
-	server->cell = cell;
-
-	INIT_LIST_HEAD(&server->link);
-	INIT_LIST_HEAD(&server->grave);
-	init_rwsem(&server->sem);
-	spin_lock_init(&server->fs_lock);
+	RCU_INIT_POINTER(server->addresses, alist);
+	server->addr_version = alist->version;
+	server->uuid = *uuid;
+	server->flags = (1UL << AFS_SERVER_FL_NEW);
+	server->update_at = ktime_get_real_seconds() + afs_server_update_delay;
+	rwlock_init(&server->fs_lock);
 	INIT_LIST_HEAD(&server->cb_interests);
 	rwlock_init(&server->cb_break_lock);
 
-	refcount_set(&server->addrs->usage, 1);
-	server->addrs->nr_addrs = 1;
-	server->addrs->addrs[0] = *addr;
-	afs_inc_servers_outstanding(cell->net);
-
-	_leave(" = %p{%d}", server, atomic_read(&server->usage));
+	afs_inc_servers_outstanding(net);
+	_leave(" = %p", server);
 	return server;
 
-enomem_server:
-	kfree(server);
 enomem:
 	_leave(" = NULL [nomem]");
 	return NULL;
 }
 
 /*
- * get an FS-server record for a cell
+ * Look up an address record for a server
  */
-struct afs_server *afs_lookup_server(struct afs_cell *cell,
-				     struct sockaddr_rxrpc *addr)
+static struct afs_addr_list *afs_vl_lookup_addrs(struct afs_cell *cell,
+						 struct key *key, const uuid_t *uuid)
 {
-	struct afs_server *server, *candidate;
-
-	_enter("%p,%pIS", cell, &addr->transport);
-
-	/* quick scan of the list to see if we already have the server */
-	read_lock(&cell->servers_lock);
-
-	list_for_each_entry(server, &cell->servers, link) {
-		if (memcmp(&server->addrs->addrs[0], addr, sizeof(*addr)) == 0)
-			goto found_server_quickly;
-	}
-	read_unlock(&cell->servers_lock);
-
-	candidate = afs_alloc_server(cell, addr);
-	if (!candidate) {
-		_leave(" = -ENOMEM");
-		return ERR_PTR(-ENOMEM);
-	}
-
-	write_lock(&cell->servers_lock);
-
-	/* check the cell's server list again */
-	list_for_each_entry(server, &cell->servers, link) {
-		if (memcmp(&server->addrs->addrs[0], addr, sizeof(*addr)) == 0)
-			goto found_server;
-	}
-
-	_debug("new");
-	server = candidate;
-	if (afs_install_server(server) < 0)
-		goto server_in_two_cells;
-
-	afs_get_cell(cell);
-	list_add_tail(&server->link, &cell->servers);
-
-	write_unlock(&cell->servers_lock);
-	_leave(" = %p{%d}", server, atomic_read(&server->usage));
-	return server;
-
-	/* found a matching server quickly */
-found_server_quickly:
-	_debug("found quickly");
-	afs_get_server(server);
-	read_unlock(&cell->servers_lock);
-no_longer_unused:
-	if (!list_empty(&server->grave)) {
-		spin_lock(&cell->net->server_graveyard_lock);
-		list_del_init(&server->grave);
-		spin_unlock(&cell->net->server_graveyard_lock);
+	struct afs_addr_cursor ac;
+	struct afs_addr_list *alist;
+	int ret;
+
+	ret = afs_set_vl_cursor(&ac, cell);
+	if (ret < 0)
+		return ERR_PTR(ret);
+
+	while (afs_iterate_addresses(&ac)) {
+		alist = afs_vl_get_addrs_u(cell->net, &ac, key, uuid);
+		switch (ac.error) {
+		case 0:
+			afs_end_cursor(&ac);
+			return alist;
+		case -ECONNABORTED:
+			ac.error = afs_abort_to_error(ac.abort_code);
+			goto error;
+		case -ENOMEM:
+		case -ENONET:
+			goto error;
+		case -ENETUNREACH:
+		case -EHOSTUNREACH:
+		case -ECONNREFUSED:
+			break;
+		default:
+			ac.error = -EIO;
+			goto error;
+		}
 	}
-	_leave(" = %p{%d}", server, atomic_read(&server->usage));
-	return server;
 
-	/* found a matching server on the second pass */
-found_server:
-	_debug("found");
-	afs_get_server(server);
-	write_unlock(&cell->servers_lock);
-	kfree(candidate);
-	goto no_longer_unused;
-
-	/* found a server that seems to be in two cells */
-server_in_two_cells:
-	write_unlock(&cell->servers_lock);
-	kfree(candidate);
-	afs_dec_servers_outstanding(cell->net);
-	printk(KERN_NOTICE "kAFS: Server %pI4 appears to be in two cells\n",
-	       addr);
-	_leave(" = -EEXIST");
-	return ERR_PTR(-EEXIST);
+error:
+	return ERR_PTR(afs_end_cursor(&ac));
 }
 
 /*
- * look up a server by its IP address
+ * Get or create a fileserver record.
  */
-struct afs_server *afs_find_server(struct afs_net *net,
-				   const struct sockaddr_rxrpc *srx)
+struct afs_server *afs_lookup_server(struct afs_cell *cell, struct key *key,
+				     const uuid_t *uuid)
 {
-	struct afs_server *server = NULL;
-	struct rb_node *p;
-	int diff;
+	struct afs_addr_list *alist;
+	struct afs_server *server, *candidate;
 
-	_enter("{%d,%pIS}", srx->transport.family, &srx->transport);
+	_enter("%p,%pU", cell->net, uuid);
 
-	read_lock(&net->servers_lock);
+	server = afs_find_server_by_uuid(cell->net, uuid);
+	if (server)
+		return server;
 
-	p = net->servers.rb_node;
-	while (p) {
-		server = rb_entry(p, struct afs_server, master_rb);
+	alist = afs_vl_lookup_addrs(cell, key, uuid);
+	if (IS_ERR(alist))
+		return ERR_CAST(alist);
 
-		_debug("- consider %p", p);
+	candidate = afs_alloc_server(cell->net, uuid, alist);
+	if (!candidate) {
+		afs_put_addrlist(alist);
+		return ERR_PTR(-ENOMEM);
+	}
 
-		diff = memcmp(srx, &server->addrs->addrs[0], sizeof(*srx));
-		if (diff < 0) {
-			p = p->rb_left;
-		} else if (diff > 0) {
-			p = p->rb_right;
-		} else {
-			afs_get_server(server);
-			goto found;
-		}
+	server = afs_install_server(cell->net, candidate);
+	if (server != candidate) {
+		afs_put_addrlist(alist);
+		kfree(candidate);
 	}
 
-	server = NULL;
-found:
-	read_unlock(&net->servers_lock);
-	_leave(" = %p", server);
+	_leave(" = %p{%d}", server, atomic_read(&server->usage));
 	return server;
 }
 
+/*
+ * Set the server timer to fire after a given delay, assuming it's not already
+ * set for an earlier time.
+ */
 static void afs_set_server_timer(struct afs_net *net, time64_t delay)
 {
-	afs_inc_servers_outstanding(net);
 	if (net->live) {
-		if (timer_reduce(&net->server_timer, jiffies + delay * HZ))
-			afs_dec_servers_outstanding(net);
-	} else {
-		if (!queue_work(afs_wq, &net->server_reaper))
+		afs_inc_servers_outstanding(net);
+		if (timer_reduce(&net->fs_timer, jiffies + delay * HZ))
 			afs_dec_servers_outstanding(net);
 	}
 }
 
 /*
- * destroy a server record
- * - removes from the cell list
+ * Server management timer.  We have an increment on fs_outstanding that we
+ * need to pass along to the work item.
+ */
+void afs_servers_timer(struct timer_list *timer)
+{
+	struct afs_net *net = container_of(timer, struct afs_net, fs_timer);
+
+	_enter("");
+	if (!queue_work(afs_wq, &net->fs_manager))
+		afs_dec_servers_outstanding(net);
+}
+
+/*
+ * Release a reference on a server record.
  */
 void afs_put_server(struct afs_net *net, struct afs_server *server)
 {
+	unsigned int usage;
+
 	if (!server)
 		return;
 
-	_enter("%p{%d}", server, atomic_read(&server->usage));
+	server->put_time = ktime_get_real_seconds();
 
-	_debug("PUT SERVER %d", atomic_read(&server->usage));
+	usage = atomic_dec_return(&server->usage);
 
-	ASSERTCMP(atomic_read(&server->usage), >, 0);
+	_enter("{%u}", usage);
 
-	if (likely(!atomic_dec_and_test(&server->usage))) {
-		_leave("");
+	if (likely(usage > 0))
 		return;
-	}
 
-	spin_lock(&net->server_graveyard_lock);
-	if (atomic_read(&server->usage) == 0) {
-		list_move_tail(&server->grave, &net->server_graveyard);
-		server->time_of_death = ktime_get_real_seconds();
-		afs_set_server_timer(net, afs_server_timeout);
-	}
-	spin_unlock(&net->server_graveyard_lock);
-	_leave(" [dead]");
+	afs_set_server_timer(net, afs_server_gc_delay);
+}
+
+static void afs_server_rcu(struct rcu_head *rcu)
+{
+	struct afs_server *server = container_of(rcu, struct afs_server, rcu);
+
+	afs_put_addrlist(server->addresses);
+	kfree(server);
 }
 
 /*
@@ -284,7 +387,7 @@ void afs_put_server(struct afs_net *net, struct afs_server *server)
  */
 static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 {
-	struct afs_addr_list *alist = server->addrs;
+	struct afs_addr_list *alist = server->addresses;
 	struct afs_addr_cursor ac = {
 		.alist	= alist,
 		.addr	= &alist->addrs[0],
@@ -294,79 +397,300 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 	};
 	_enter("%p", server);
 
-	afs_fs_give_up_all_callbacks(server, &ac, NULL, false);
-	afs_put_cell(net, server->cell);
-	afs_put_addrlist(server->addrs);
-	kfree(server);
+	afs_fs_give_up_all_callbacks(net, server, &ac, NULL);
+	call_rcu(&server->rcu, afs_server_rcu);
 	afs_dec_servers_outstanding(net);
 }
 
 /*
- * reap dead server records
+ * Garbage collect any expired servers.
  */
-void afs_reap_server(struct work_struct *work)
+static void afs_gc_servers(struct afs_net *net, struct afs_server *gc_list)
 {
-	LIST_HEAD(corpses);
 	struct afs_server *server;
-	struct afs_net *net = container_of(work, struct afs_net, server_reaper);
-	unsigned long delay, expiry;
-	time64_t now;
-
-	now = ktime_get_real_seconds();
-	spin_lock(&net->server_graveyard_lock);
-
-	while (!list_empty(&net->server_graveyard)) {
-		server = list_entry(net->server_graveyard.next,
-				    struct afs_server, grave);
-
-		/* the queue is ordered most dead first */
-		if (net->live) {
-			expiry = server->time_of_death + afs_server_timeout;
-			if (expiry > now) {
-				delay = (expiry - now);
-				afs_set_server_timer(net, delay);
-				break;
-			}
+	bool deleted;
+	int usage;
+
+	while ((server = gc_list)) {
+		gc_list = server->gc_next;
+
+		write_seqlock(&net->fs_lock);
+		usage = 1;
+		deleted = atomic_try_cmpxchg(&server->usage, &usage, 0);
+		if (deleted) {
+			rb_erase(&server->uuid_rb, &net->fs_servers);
+			hlist_del_rcu(&server->proc_link);
 		}
+		write_sequnlock(&net->fs_lock);
 
-		write_lock(&server->cell->servers_lock);
-		write_lock(&net->servers_lock);
-		if (atomic_read(&server->usage) > 0) {
-			list_del_init(&server->grave);
-		} else {
-			list_move_tail(&server->grave, &corpses);
-			list_del_init(&server->link);
-			rb_erase(&server->master_rb, &net->servers);
+		if (deleted)
+			afs_destroy_server(net, server);
+	}
+}
+
+/*
+ * Manage the records of servers known to be within a network namespace.  This
+ * includes garbage collecting unused servers.
+ *
+ * Note also that we were given an increment on net->servers_outstanding by
+ * whoever queued us that we need to deal with before returning.
+ */
+void afs_manage_servers(struct work_struct *work)
+{
+	struct afs_net *net = container_of(work, struct afs_net, fs_manager);
+	struct afs_server *gc_list = NULL;
+	struct rb_node *cursor;
+	time64_t now = ktime_get_real_seconds(), next_manage = TIME64_MAX;
+	bool purging = !net->live;
+
+	_enter("");
+
+	/* Trawl the server list looking for servers that have expired from
+	 * lack of use.
+	 */
+	read_seqlock_excl(&net->fs_lock);
+
+	for (cursor = rb_first(&net->fs_servers); cursor; cursor = rb_next(cursor)) {
+		struct afs_server *server =
+			rb_entry(cursor, struct afs_server, uuid_rb);
+		int usage = atomic_read(&server->usage);
+
+		_debug("manage %pU %u", &server->uuid, usage);
+
+		ASSERTCMP(usage, >=, 1);
+		ASSERTIFCMP(purging, usage, ==, 1);
+
+		if (usage == 1) {
+			time64_t expire_at = server->put_time;
+
+			if (!test_bit(AFS_SERVER_FL_VL_FAIL, &server->flags) &&
+			    !test_bit(AFS_SERVER_FL_NOT_FOUND, &server->flags))
+				expire_at += afs_server_gc_delay;
+			if (purging || expire_at <= now) {
+				server->gc_next = gc_list;
+				gc_list = server;
+			} else if (expire_at < next_manage) {
+				next_manage = expire_at;
+			}
 		}
-		write_unlock(&net->servers_lock);
-		write_unlock(&server->cell->servers_lock);
 	}
 
-	spin_unlock(&net->server_graveyard_lock);
+	read_sequnlock_excl(&net->fs_lock);
 
-	/* now reap the corpses we've extracted */
-	while (!list_empty(&corpses)) {
-		server = list_entry(corpses.next, struct afs_server, grave);
-		list_del(&server->grave);
-		afs_destroy_server(net, server);
+	/* Update the timer on the way out.  We have to pass an increment on
+	 * servers_outstanding in the namespace that we are in to the timer or
+	 * the work scheduler.
+	 */
+	if (!purging && next_manage < TIME64_MAX) {
+		now = ktime_get_real_seconds();
+
+		if (next_manage - now <= 0) {
+			if (queue_work(afs_wq, &net->fs_manager))
+				afs_inc_servers_outstanding(net);
+		} else {
+			afs_set_server_timer(net, next_manage - now);
+		}
 	}
 
+	afs_gc_servers(net, gc_list);
+
 	afs_dec_servers_outstanding(net);
+	_leave(" [%d]", atomic_read(&net->servers_outstanding));
+}
+
+static void afs_queue_server_manager(struct afs_net *net)
+{
+	afs_inc_servers_outstanding(net);
+	if (!queue_work(afs_wq, &net->fs_manager))
+		afs_dec_servers_outstanding(net);
 }
 
 /*
- * Discard all the server records from a net namespace when it is destroyed or
- * the afs module is removed.
+ * Purge list of servers.
  */
-void __net_exit afs_purge_servers(struct afs_net *net)
+void afs_purge_servers(struct afs_net *net)
 {
-	if (del_timer_sync(&net->server_timer))
+	_enter("");
+
+	if (del_timer_sync(&net->fs_timer))
 		atomic_dec(&net->servers_outstanding);
 
-	afs_inc_servers_outstanding(net);
-	if (!queue_work(afs_wq, &net->server_reaper))
-		afs_dec_servers_outstanding(net);
+	afs_queue_server_manager(net);
 
+	_debug("wait");
 	wait_on_atomic_t(&net->servers_outstanding, atomic_t_wait,
 			 TASK_UNINTERRUPTIBLE);
+	_leave("");
+}
+
+/*
+ * Probe a fileserver to find its capabilities.
+ *
+ * TODO: Try service upgrade.
+ */
+static bool afs_do_probe_fileserver(struct afs_fs_cursor *fc)
+{
+	_enter("");
+
+	fc->ac.addr = NULL;
+	fc->ac.start = READ_ONCE(fc->ac.alist->index);
+	fc->ac.index = fc->ac.start;
+	fc->ac.error = 0;
+	fc->ac.begun = false;
+
+	while (afs_iterate_addresses(&fc->ac)) {
+		afs_fs_get_capabilities(afs_v2net(fc->vnode), fc->cbi->server,
+					&fc->ac, fc->key);
+		switch (fc->ac.error) {
+		case 0:
+			afs_end_cursor(&fc->ac);
+			set_bit(AFS_SERVER_FL_PROBED, &fc->cbi->server->flags);
+			return true;
+		case -ECONNABORTED:
+			fc->ac.error = afs_abort_to_error(fc->ac.abort_code);
+			goto error;
+		case -ENOMEM:
+		case -ENONET:
+			goto error;
+		case -ENETUNREACH:
+		case -EHOSTUNREACH:
+		case -ECONNREFUSED:
+		case -ETIMEDOUT:
+		case -ETIME:
+			break;
+		default:
+			fc->ac.error = -EIO;
+			goto error;
+		}
+	}
+
+error:
+	afs_end_cursor(&fc->ac);
+	return false;
+}
+
+/*
+ * If we haven't already, try probing the fileserver to get its capabilities.
+ * We try not to instigate parallel probes, but it's possible that the parallel
+ * probes will fail due to authentication failure when ours would succeed.
+ *
+ * TODO: Try sending an anonymous probe if an authenticated probe fails.
+ */
+bool afs_probe_fileserver(struct afs_fs_cursor *fc)
+{
+	bool success;
+	int ret, retries = 0;
+
+	_enter("");
+
+retry:
+	if (test_bit(AFS_SERVER_FL_PROBED, &fc->cbi->server->flags)) {
+		_leave(" = t");
+		return true;
+	}
+
+	if (!test_and_set_bit_lock(AFS_SERVER_FL_PROBING, &fc->cbi->server->flags)) {
+		success = afs_do_probe_fileserver(fc);
+		clear_bit_unlock(AFS_SERVER_FL_PROBING, &fc->cbi->server->flags);
+		wake_up_bit(&fc->cbi->server->flags, AFS_SERVER_FL_PROBING);
+		_leave(" = t");
+		return success;
+	}
+
+	_debug("wait");
+	ret = wait_on_bit(&fc->cbi->server->flags, AFS_SERVER_FL_PROBING,
+			  TASK_INTERRUPTIBLE);
+	if (ret == -ERESTARTSYS) {
+		fc->ac.error = ret;
+		_leave(" = f [%d]", ret);
+		return false;
+	}
+
+	retries++;
+	if (retries == 4) {
+		fc->ac.error = -ESTALE;
+		_leave(" = f [stale]");
+		return false;
+	}
+	_debug("retry");
+	goto retry;
+}
+
+/*
+ * Get an update for a server's address list.
+ */
+static noinline bool afs_update_server_record(struct afs_fs_cursor *fc, struct afs_server *server)
+{
+	struct afs_addr_list *alist, *discard;
+
+	_enter("");
+
+	alist = afs_vl_lookup_addrs(fc->vnode->volume->cell, fc->key,
+				    &server->uuid);
+	if (IS_ERR(alist)) {
+		fc->ac.error = PTR_ERR(alist);
+		_leave(" = f [%d]", fc->ac.error);
+		return false;
+	}
+
+	discard = alist;
+	if (server->addr_version != alist->version) {
+		write_lock(&server->fs_lock);
+		discard = rcu_dereference_protected(server->addresses,
+						    lockdep_is_held(&server->fs_lock));
+		rcu_assign_pointer(server->addresses, alist);
+		server->addr_version = alist->version;
+		write_unlock(&server->fs_lock);
+	}
+
+	server->update_at = ktime_get_real_seconds() + afs_server_update_delay;
+	afs_put_addrlist(discard);
+	_leave(" = t");
+	return true;
+}
+
+/*
+ * See if a server's address list needs updating.
+ */
+bool afs_check_server_record(struct afs_fs_cursor *fc, struct afs_server *server)
+{
+	time64_t now = ktime_get_real_seconds();
+	long diff;
+	bool success;
+	int ret, retries = 0;
+
+	_enter("");
+
+	ASSERT(server);
+
+retry:
+	diff = READ_ONCE(server->update_at) - now;
+	if (diff > 0) {
+		_leave(" = t [not now %ld]", diff);
+		return true;
+	}
+
+	if (!test_and_set_bit_lock(AFS_SERVER_FL_UPDATING, &server->flags)) {
+		success = afs_update_server_record(fc, server);
+		clear_bit_unlock(AFS_SERVER_FL_UPDATING, &server->flags);
+		wake_up_bit(&server->flags, AFS_SERVER_FL_UPDATING);
+		_leave(" = %d", success);
+		return success;
+	}
+
+	ret = wait_on_bit(&server->flags, AFS_SERVER_FL_UPDATING,
+			  TASK_INTERRUPTIBLE);
+	if (ret == -ERESTARTSYS) {
+		fc->ac.error = ret;
+		_leave(" = f [intr]");
+		return false;
+	}
+
+	retries++;
+	if (retries == 4) {
+		_leave(" = f [stale]");
+		ret = -ESTALE;
+		return false;
+	}
+	goto retry;
 }

commit 8b2a464ced77fe35be72ab7d38152a9439daf8d3
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:50 2017 +0000

    afs: Add an address list concept
    
    Add an RCU replaceable address list structure to hold a list of server
    addresses.  The list also holds the
    
    To this end:
    
     (1) A cell's VL server address list can be loaded directly via insmod or
         echo to /proc/fs/afs/cells or dynamically from a DNS query for AFSDB
         or SRV records.
    
     (2) Anyone wanting to use a cell's VL server address must wait until the
         cell record comes online and has tried to obtain some addresses.
    
     (3) An FS server's address list, for the moment, has a single entry that
         is the key to the server list.  This will change in the future when a
         server is instead keyed on its UUID and the VL.GetAddrsU operation is
         used.
    
     (4) An 'address cursor' concept is introduced to handle iteration through
         the address list.  This is passed to the afs_make_call() as, in the
         future, stuff (such as abort code) that doesn't outlast the call will
         be returned in it.
    
    In the future, we might want to annotate the list with information about
    how each address fares.  We might then want to propagate such annotations
    over address list replacement.
    
    Whilst we're at it, we allow IPv6 addresses to be specified in
    colon-delimited lists by enclosing them in square brackets.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 4e66608fc805..9ca174b24f5b 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -56,7 +56,9 @@ static int afs_install_server(struct afs_server *server)
 		p = *pp;
 		_debug("- consider %p", p);
 		xserver = rb_entry(p, struct afs_server, master_rb);
-		diff = memcmp(&server->addr, &xserver->addr, sizeof(server->addr));
+		diff = memcmp(&server->addrs->addrs[0],
+			      &xserver->addrs->addrs[0],
+			      sizeof(sizeof(server->addrs->addrs[0])));
 		if (diff < 0)
 			pp = &(*pp)->rb_left;
 		else if (diff > 0)
@@ -85,25 +87,38 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 	_enter("");
 
 	server = kzalloc(sizeof(struct afs_server), GFP_KERNEL);
-	if (server) {
-		atomic_set(&server->usage, 1);
-		server->net = cell->net;
-		server->cell = cell;
-
-		INIT_LIST_HEAD(&server->link);
-		INIT_LIST_HEAD(&server->grave);
-		init_rwsem(&server->sem);
-		spin_lock_init(&server->fs_lock);
-		INIT_LIST_HEAD(&server->cb_interests);
-		rwlock_init(&server->cb_break_lock);
-
-		server->addr = *addr;
-		afs_inc_servers_outstanding(cell->net);
-		_leave(" = %p{%d}", server, atomic_read(&server->usage));
-	} else {
-		_leave(" = NULL [nomem]");
-	}
+	if (!server)
+		goto enomem;
+	server->addrs = kzalloc(sizeof(struct afs_addr_list) +
+				sizeof(struct sockaddr_rxrpc),
+				GFP_KERNEL);
+	if (!server->addrs)
+		goto enomem_server;
+
+	atomic_set(&server->usage, 1);
+	server->net = cell->net;
+	server->cell = cell;
+
+	INIT_LIST_HEAD(&server->link);
+	INIT_LIST_HEAD(&server->grave);
+	init_rwsem(&server->sem);
+	spin_lock_init(&server->fs_lock);
+	INIT_LIST_HEAD(&server->cb_interests);
+	rwlock_init(&server->cb_break_lock);
+
+	refcount_set(&server->addrs->usage, 1);
+	server->addrs->nr_addrs = 1;
+	server->addrs->addrs[0] = *addr;
+	afs_inc_servers_outstanding(cell->net);
+
+	_leave(" = %p{%d}", server, atomic_read(&server->usage));
 	return server;
+
+enomem_server:
+	kfree(server);
+enomem:
+	_leave(" = NULL [nomem]");
+	return NULL;
 }
 
 /*
@@ -120,7 +135,7 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 	read_lock(&cell->servers_lock);
 
 	list_for_each_entry(server, &cell->servers, link) {
-		if (memcmp(&server->addr, addr, sizeof(*addr)) == 0)
+		if (memcmp(&server->addrs->addrs[0], addr, sizeof(*addr)) == 0)
 			goto found_server_quickly;
 	}
 	read_unlock(&cell->servers_lock);
@@ -135,7 +150,7 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 
 	/* check the cell's server list again */
 	list_for_each_entry(server, &cell->servers, link) {
-		if (memcmp(&server->addr, addr, sizeof(*addr)) == 0)
+		if (memcmp(&server->addrs->addrs[0], addr, sizeof(*addr)) == 0)
 			goto found_server;
 	}
 
@@ -204,7 +219,7 @@ struct afs_server *afs_find_server(struct afs_net *net,
 
 		_debug("- consider %p", p);
 
-		diff = memcmp(srx, &server->addr, sizeof(*srx));
+		diff = memcmp(srx, &server->addrs->addrs[0], sizeof(*srx));
 		if (diff < 0) {
 			p = p->rb_left;
 		} else if (diff > 0) {
@@ -269,10 +284,19 @@ void afs_put_server(struct afs_net *net, struct afs_server *server)
  */
 static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 {
+	struct afs_addr_list *alist = server->addrs;
+	struct afs_addr_cursor ac = {
+		.alist	= alist,
+		.addr	= &alist->addrs[0],
+		.start	= alist->index,
+		.index	= alist->index,
+		.error	= 0,
+	};
 	_enter("%p", server);
 
-	afs_fs_give_up_all_callbacks(server, NULL, false);
+	afs_fs_give_up_all_callbacks(server, &ac, NULL, false);
 	afs_put_cell(net, server->cell);
+	afs_put_addrlist(server->addrs);
 	kfree(server);
 	afs_dec_servers_outstanding(net);
 }

commit c435ee34551e1f5a02a253ca8e235287efd2727c
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:49 2017 +0000

    afs: Overhaul the callback handling
    
    Overhaul the AFS callback handling by the following means:
    
     (1) Don't give up callback promises on vnodes that we are no longer using,
         rather let them just expire on the server or let the server break
         them.  This is actually more efficient for the server as the callback
         lookup is expensive if there are lots of extant callbacks.
    
     (2) Only give up the callback promises we have from a server when the
         server record is destroyed.  Then we can just give up *all* the
         callback promises on it in one go.
    
     (3) Servers can end up being shared between cells if cells are aliased, so
         don't add all the vnodes being backed by a particular server into a
         big FID-indexed tree on that server as there may be duplicates.
    
         Instead have each volume instance (~= superblock) register an interest
         in a server as it starts to make use of it and use this to allow the
         processor for callbacks from the server to find the superblock and
         thence the inode corresponding to the FID being broken by means of
         ilookup_nowait().
    
     (4) Rather than iterating over the entire callback list when a mass-break
         comes in from the server, maintain a counter of mass-breaks in
         afs_server (cb_seq) and make afs_validate() check it against the copy
         in afs_vnode.
    
         It would be nice not to have to take a read_lock whilst doing this,
         but that's tricky without using RCU.
    
     (5) Save a ref on the fileserver we're using for a call in the afs_call
         struct so that we can access its cb_s_break during call decoding.
    
     (6) Write-lock around callback and status storage in a vnode and read-lock
         around getattr so that we don't see the status mid-update.
    
    This has the following consequences:
    
     (1) Data invalidation isn't seen until someone calls afs_validate() on a
         vnode.  Unfortunately, we need to use a key to query the server, but
         getting one from a background thread is tricky without caching loads
         of keys all over the place.
    
     (2) Mass invalidation isn't seen until someone calls afs_validate().
    
     (3) Callback breaking is going to hit the inode_hash_lock quite a bit.
         Could this be replaced with rcu_read_lock() since inodes are destroyed
         under RCU conditions.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index c63974f06385..4e66608fc805 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -94,12 +94,8 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 		INIT_LIST_HEAD(&server->grave);
 		init_rwsem(&server->sem);
 		spin_lock_init(&server->fs_lock);
-		server->fs_vnodes = RB_ROOT;
-		server->cb_promises = RB_ROOT;
-		spin_lock_init(&server->cb_lock);
-		init_waitqueue_head(&server->cb_break_waitq);
-		INIT_DELAYED_WORK(&server->cb_break_work,
-				  afs_dispatch_give_up_callbacks);
+		INIT_LIST_HEAD(&server->cb_interests);
+		rwlock_init(&server->cb_break_lock);
 
 		server->addr = *addr;
 		afs_inc_servers_outstanding(cell->net);
@@ -258,8 +254,6 @@ void afs_put_server(struct afs_net *net, struct afs_server *server)
 		return;
 	}
 
-	afs_flush_callback_breaks(server);
-
 	spin_lock(&net->server_graveyard_lock);
 	if (atomic_read(&server->usage) == 0) {
 		list_move_tail(&server->grave, &net->server_graveyard);
@@ -277,15 +271,8 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 {
 	_enter("%p", server);
 
-	ASSERTIF(server->cb_break_head != server->cb_break_tail,
-		 delayed_work_pending(&server->cb_break_work));
-
-	ASSERTCMP(server->fs_vnodes.rb_node, ==, NULL);
-	ASSERTCMP(server->cb_promises.rb_node, ==, NULL);
-	ASSERTCMP(server->cb_break_head, ==, server->cb_break_tail);
-	ASSERTCMP(atomic_read(&server->cb_break_n), ==, 0);
-
-	afs_put_cell(server->net, server->cell);
+	afs_fs_give_up_all_callbacks(server, NULL, false);
+	afs_put_cell(net, server->cell);
 	kfree(server);
 	afs_dec_servers_outstanding(net);
 }

commit 3838d3ecdea496699a8c13c183d4df5dfe8e1a3e
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:47 2017 +0000

    afs: Allow IPv6 address specification of VL servers
    
    Allow VL server specifications to be given IPv6 addresses as well as IPv4
    addresses, for example as:
    
            echo add foo.org 1111:2222:3333:0:4444:5555:6666:7777 >/proc/fs/afs/cells
    
    Note that ':' is the expected separator for separating IPv4 addresses, but
    if a ',' is detected or no '.' is detected in the string, the delimiter is
    switched to ','.
    
    This also works with DNS AFSDB or SRV record strings fetched by upcall from
    userspace.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 662f7fbf5d05..c63974f06385 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -200,11 +200,6 @@ struct afs_server *afs_find_server(struct afs_net *net,
 
 	_enter("{%d,%pIS}", srx->transport.family, &srx->transport);
 
-	if (srx->transport.family != AF_INET) {
-		WARN(true, "AFS does not yes support non-IPv4 addresses\n");
-		return NULL;
-	}
-
 	read_lock(&net->servers_lock);
 
 	p = net->servers.rb_node;

commit 4d9df9868f31df6725481135c10ac6419ce58d44
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:47 2017 +0000

    afs: Keep and pass sockaddr_rxrpc addresses rather than in_addr
    
    Keep and pass sockaddr_rxrpc addresses around rather than keeping and
    passing in_addr addresses to allow for the use of IPv6 and non-standard
    port numbers in future.
    
    This also allows the port and service_id fields to be removed from the
    afs_call struct.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index d8044be913f0..662f7fbf5d05 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -11,6 +11,7 @@
 
 #include <linux/sched.h>
 #include <linux/slab.h>
+#include "afs_fs.h"
 #include "internal.h"
 
 static unsigned afs_server_timeout = 10;	/* server timeout in seconds */
@@ -42,7 +43,7 @@ static int afs_install_server(struct afs_server *server)
 	struct afs_server *xserver;
 	struct afs_net *net = server->cell->net;
 	struct rb_node **pp, *p;
-	int ret;
+	int ret, diff;
 
 	_enter("%p", server);
 
@@ -55,9 +56,10 @@ static int afs_install_server(struct afs_server *server)
 		p = *pp;
 		_debug("- consider %p", p);
 		xserver = rb_entry(p, struct afs_server, master_rb);
-		if (server->addr.s_addr < xserver->addr.s_addr)
+		diff = memcmp(&server->addr, &xserver->addr, sizeof(server->addr));
+		if (diff < 0)
 			pp = &(*pp)->rb_left;
-		else if (server->addr.s_addr > xserver->addr.s_addr)
+		else if (diff > 0)
 			pp = &(*pp)->rb_right;
 		else
 			goto error;
@@ -76,7 +78,7 @@ static int afs_install_server(struct afs_server *server)
  * allocate a new server record
  */
 static struct afs_server *afs_alloc_server(struct afs_cell *cell,
-					   const struct in_addr *addr)
+					   const struct sockaddr_rxrpc *addr)
 {
 	struct afs_server *server;
 
@@ -99,8 +101,7 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 		INIT_DELAYED_WORK(&server->cb_break_work,
 				  afs_dispatch_give_up_callbacks);
 
-		memcpy(&server->addr, addr, sizeof(struct in_addr));
-		server->addr.s_addr = addr->s_addr;
+		server->addr = *addr;
 		afs_inc_servers_outstanding(cell->net);
 		_leave(" = %p{%d}", server, atomic_read(&server->usage));
 	} else {
@@ -113,17 +114,17 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
  * get an FS-server record for a cell
  */
 struct afs_server *afs_lookup_server(struct afs_cell *cell,
-				     const struct in_addr *addr)
+				     struct sockaddr_rxrpc *addr)
 {
 	struct afs_server *server, *candidate;
 
-	_enter("%p,%pI4", cell, &addr->s_addr);
+	_enter("%p,%pIS", cell, &addr->transport);
 
 	/* quick scan of the list to see if we already have the server */
 	read_lock(&cell->servers_lock);
 
 	list_for_each_entry(server, &cell->servers, link) {
-		if (server->addr.s_addr == addr->s_addr)
+		if (memcmp(&server->addr, addr, sizeof(*addr)) == 0)
 			goto found_server_quickly;
 	}
 	read_unlock(&cell->servers_lock);
@@ -138,7 +139,7 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 
 	/* check the cell's server list again */
 	list_for_each_entry(server, &cell->servers, link) {
-		if (server->addr.s_addr == addr->s_addr)
+		if (memcmp(&server->addr, addr, sizeof(*addr)) == 0)
 			goto found_server;
 	}
 
@@ -195,9 +196,9 @@ struct afs_server *afs_find_server(struct afs_net *net,
 {
 	struct afs_server *server = NULL;
 	struct rb_node *p;
-	struct in_addr addr = srx->transport.sin.sin_addr;
+	int diff;
 
-	_enter("{%d,%pI4}", srx->transport.family, &addr.s_addr);
+	_enter("{%d,%pIS}", srx->transport.family, &srx->transport);
 
 	if (srx->transport.family != AF_INET) {
 		WARN(true, "AFS does not yes support non-IPv4 addresses\n");
@@ -212,9 +213,10 @@ struct afs_server *afs_find_server(struct afs_net *net,
 
 		_debug("- consider %p", p);
 
-		if (addr.s_addr < server->addr.s_addr) {
+		diff = memcmp(srx, &server->addr, sizeof(*srx));
+		if (diff < 0) {
 			p = p->rb_left;
-		} else if (addr.s_addr > server->addr.s_addr) {
+		} else if (diff > 0) {
 			p = p->rb_right;
 		} else {
 			afs_get_server(server);
@@ -225,7 +227,6 @@ struct afs_server *afs_find_server(struct afs_net *net,
 	server = NULL;
 found:
 	read_unlock(&net->servers_lock);
-	ASSERTIFCMP(server, server->addr.s_addr, ==, addr.s_addr);
 	_leave(" = %p", server);
 	return server;
 }

commit 9ed900b1160ef306bc74ad0228d7ab199234c758
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:46 2017 +0000

    afs: Push the net ns pointer to more places
    
    Push the network namespace pointer to more places in AFS, including the
    afs_server structure (which doesn't hold a ref on the netns).
    
    In particular, afs_put_cell() now takes requires a net ns parameter so that
    it can safely alter the netns after decrementing the cell usage count - the
    cell will be deallocated by a background thread after being cached for a
    period, which means that it's not safe to access it after reducing its
    usage count.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 33aeb527ac7e..d8044be913f0 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -85,6 +85,7 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 	server = kzalloc(sizeof(struct afs_server), GFP_KERNEL);
 	if (server) {
 		atomic_set(&server->usage, 1);
+		server->net = cell->net;
 		server->cell = cell;
 
 		INIT_LIST_HEAD(&server->link);
@@ -245,10 +246,8 @@ static void afs_set_server_timer(struct afs_net *net, time64_t delay)
  * destroy a server record
  * - removes from the cell list
  */
-void afs_put_server(struct afs_server *server)
+void afs_put_server(struct afs_net *net, struct afs_server *server)
 {
-	struct afs_net *net = server->cell->net;
-
 	if (!server)
 		return;
 
@@ -290,7 +289,7 @@ static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 	ASSERTCMP(server->cb_break_head, ==, server->cb_break_tail);
 	ASSERTCMP(atomic_read(&server->cb_break_n), ==, 0);
 
-	afs_put_cell(server->cell);
+	afs_put_cell(server->net, server->cell);
 	kfree(server);
 	afs_dec_servers_outstanding(net);
 }

commit 59fa1c4a9f528c2a1556f4b2cd4e055b560c1c0a
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:45 2017 +0000

    afs: Fix server reaping
    
    Fix server reaping and make sure it's all done before we start trying to
    purge cells, given that servers currently pin cells.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index e47fd9bc0ddc..33aeb527ac7e 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -15,6 +15,25 @@
 
 static unsigned afs_server_timeout = 10;	/* server timeout in seconds */
 
+static void afs_inc_servers_outstanding(struct afs_net *net)
+{
+	atomic_inc(&net->servers_outstanding);
+}
+
+static void afs_dec_servers_outstanding(struct afs_net *net)
+{
+	if (atomic_dec_and_test(&net->servers_outstanding))
+		wake_up_atomic_t(&net->servers_outstanding);
+}
+
+void afs_server_timer(struct timer_list *timer)
+{
+	struct afs_net *net = container_of(timer, struct afs_net, server_timer);
+
+	if (!queue_work(afs_wq, &net->server_reaper))
+		afs_dec_servers_outstanding(net);
+}
+
 /*
  * install a server record in the master tree
  */
@@ -81,6 +100,7 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 
 		memcpy(&server->addr, addr, sizeof(struct in_addr));
 		server->addr.s_addr = addr->s_addr;
+		afs_inc_servers_outstanding(cell->net);
 		_leave(" = %p{%d}", server, atomic_read(&server->usage));
 	} else {
 		_leave(" = NULL [nomem]");
@@ -159,6 +179,7 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 server_in_two_cells:
 	write_unlock(&cell->servers_lock);
 	kfree(candidate);
+	afs_dec_servers_outstanding(cell->net);
 	printk(KERN_NOTICE "kAFS: Server %pI4 appears to be in two cells\n",
 	       addr);
 	_leave(" = -EEXIST");
@@ -208,6 +229,18 @@ struct afs_server *afs_find_server(struct afs_net *net,
 	return server;
 }
 
+static void afs_set_server_timer(struct afs_net *net, time64_t delay)
+{
+	afs_inc_servers_outstanding(net);
+	if (net->live) {
+		if (timer_reduce(&net->server_timer, jiffies + delay * HZ))
+			afs_dec_servers_outstanding(net);
+	} else {
+		if (!queue_work(afs_wq, &net->server_reaper))
+			afs_dec_servers_outstanding(net);
+	}
+}
+
 /*
  * destroy a server record
  * - removes from the cell list
@@ -236,8 +269,7 @@ void afs_put_server(struct afs_server *server)
 	if (atomic_read(&server->usage) == 0) {
 		list_move_tail(&server->grave, &net->server_graveyard);
 		server->time_of_death = ktime_get_real_seconds();
-		queue_delayed_work(afs_wq, &net->server_reaper,
-				   net->live ? afs_server_timeout * HZ : 0);
+		afs_set_server_timer(net, afs_server_timeout);
 	}
 	spin_unlock(&net->server_graveyard_lock);
 	_leave(" [dead]");
@@ -246,7 +278,7 @@ void afs_put_server(struct afs_server *server)
 /*
  * destroy a dead server
  */
-static void afs_destroy_server(struct afs_server *server)
+static void afs_destroy_server(struct afs_net *net, struct afs_server *server)
 {
 	_enter("%p", server);
 
@@ -260,6 +292,7 @@ static void afs_destroy_server(struct afs_server *server)
 
 	afs_put_cell(server->cell);
 	kfree(server);
+	afs_dec_servers_outstanding(net);
 }
 
 /*
@@ -269,7 +302,7 @@ void afs_reap_server(struct work_struct *work)
 {
 	LIST_HEAD(corpses);
 	struct afs_server *server;
-	struct afs_net *net = container_of(work, struct afs_net, server_reaper.work);
+	struct afs_net *net = container_of(work, struct afs_net, server_reaper);
 	unsigned long delay, expiry;
 	time64_t now;
 
@@ -284,8 +317,8 @@ void afs_reap_server(struct work_struct *work)
 		if (net->live) {
 			expiry = server->time_of_death + afs_server_timeout;
 			if (expiry > now) {
-				delay = (expiry - now) * HZ;
-				mod_delayed_work(afs_wq, &net->server_reaper, delay);
+				delay = (expiry - now);
+				afs_set_server_timer(net, delay);
 				break;
 			}
 		}
@@ -309,8 +342,10 @@ void afs_reap_server(struct work_struct *work)
 	while (!list_empty(&corpses)) {
 		server = list_entry(corpses.next, struct afs_server, grave);
 		list_del(&server->grave);
-		afs_destroy_server(server);
+		afs_destroy_server(net, server);
 	}
+
+	afs_dec_servers_outstanding(net);
 }
 
 /*
@@ -319,5 +354,13 @@ void afs_reap_server(struct work_struct *work)
  */
 void __net_exit afs_purge_servers(struct afs_net *net)
 {
-	mod_delayed_work(afs_wq, &net->server_reaper, 0);
+	if (del_timer_sync(&net->server_timer))
+		atomic_dec(&net->servers_outstanding);
+
+	afs_inc_servers_outstanding(net);
+	if (!queue_work(afs_wq, &net->server_reaper))
+		afs_dec_servers_outstanding(net);
+
+	wait_on_atomic_t(&net->servers_outstanding, atomic_t_wait,
+			 TASK_UNINTERRUPTIBLE);
 }

commit f044c8847bb61eff5e1e95b6f6bb950e7f4a73a4
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:45 2017 +0000

    afs: Lay the groundwork for supporting network namespaces
    
    Lay the groundwork for supporting network namespaces (netns) to the AFS
    filesystem by moving various global features to a network-namespace struct
    (afs_net) and providing an instance of this as a temporary global variable
    that everything uses via accessor functions for the moment.
    
    The following changes have been made:
    
     (1) Store the netns in the superblock info.  This will be obtained from
         the mounter's nsproxy on a manual mount and inherited from the parent
         superblock on an automount.
    
     (2) The cell list is made per-netns.  It can be viewed through
         /proc/net/afs/cells and also be modified by writing commands to that
         file.
    
     (3) The local workstation cell is set per-ns in /proc/net/afs/rootcell.
         This is unset by default.
    
     (4) The 'rootcell' module parameter, which sets a cell and VL server list
         modifies the init net namespace, thereby allowing an AFS root fs to be
         theoretically used.
    
     (5) The volume location lists and the file lock manager are made
         per-netns.
    
     (6) The AF_RXRPC socket and associated I/O bits are made per-ns.
    
    The various workqueues remain global for the moment.
    
    Changes still to be made:
    
     (1) /proc/fs/afs/ should be moved to /proc/net/afs/ and a symlink emplaced
         from the old name.
    
     (2) A per-netns subsys needs to be registered for AFS into which it can
         store its per-netns data.
    
     (3) Rather than the AF_RXRPC socket being opened on module init, it needs
         to be opened on the creation of a superblock in that netns.
    
     (4) The socket needs to be closed when the last superblock using it is
         destroyed and all outstanding client calls on it have been completed.
         This prevents a reference loop on the namespace.
    
     (5) It is possible that several namespaces will want to use AFS, in which
         case each one will need its own UDP port.  These can either be set
         through /proc/net/afs/cm_port or the kernel can pick one at random.
         The init_ns gets 7001 by default.
    
    Other issues that need resolving:
    
     (1) The DNS keyring needs net-namespacing.
    
     (2) Where do upcalls go (eg. DNS request-key upcall)?
    
     (3) Need something like open_socket_in_file_ns() syscall so that AFS
         command line tools attempting to operate on an AFS file/volume have
         their RPC calls go to the right place.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index c001b1f2455f..e47fd9bc0ddc 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -15,32 +15,22 @@
 
 static unsigned afs_server_timeout = 10;	/* server timeout in seconds */
 
-static void afs_reap_server(struct work_struct *);
-
-/* tree of all the servers, indexed by IP address */
-static struct rb_root afs_servers = RB_ROOT;
-static DEFINE_RWLOCK(afs_servers_lock);
-
-/* LRU list of all the servers not currently in use */
-static LIST_HEAD(afs_server_graveyard);
-static DEFINE_SPINLOCK(afs_server_graveyard_lock);
-static DECLARE_DELAYED_WORK(afs_server_reaper, afs_reap_server);
-
 /*
  * install a server record in the master tree
  */
 static int afs_install_server(struct afs_server *server)
 {
 	struct afs_server *xserver;
+	struct afs_net *net = server->cell->net;
 	struct rb_node **pp, *p;
 	int ret;
 
 	_enter("%p", server);
 
-	write_lock(&afs_servers_lock);
+	write_lock(&net->servers_lock);
 
 	ret = -EEXIST;
-	pp = &afs_servers.rb_node;
+	pp = &net->servers.rb_node;
 	p = NULL;
 	while (*pp) {
 		p = *pp;
@@ -55,11 +45,11 @@ static int afs_install_server(struct afs_server *server)
 	}
 
 	rb_link_node(&server->master_rb, p, pp);
-	rb_insert_color(&server->master_rb, &afs_servers);
+	rb_insert_color(&server->master_rb, &net->servers);
 	ret = 0;
 
 error:
-	write_unlock(&afs_servers_lock);
+	write_unlock(&net->servers_lock);
 	return ret;
 }
 
@@ -150,9 +140,9 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 	read_unlock(&cell->servers_lock);
 no_longer_unused:
 	if (!list_empty(&server->grave)) {
-		spin_lock(&afs_server_graveyard_lock);
+		spin_lock(&cell->net->server_graveyard_lock);
 		list_del_init(&server->grave);
-		spin_unlock(&afs_server_graveyard_lock);
+		spin_unlock(&cell->net->server_graveyard_lock);
 	}
 	_leave(" = %p{%d}", server, atomic_read(&server->usage));
 	return server;
@@ -178,7 +168,8 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 /*
  * look up a server by its IP address
  */
-struct afs_server *afs_find_server(const struct sockaddr_rxrpc *srx)
+struct afs_server *afs_find_server(struct afs_net *net,
+				   const struct sockaddr_rxrpc *srx)
 {
 	struct afs_server *server = NULL;
 	struct rb_node *p;
@@ -191,9 +182,9 @@ struct afs_server *afs_find_server(const struct sockaddr_rxrpc *srx)
 		return NULL;
 	}
 
-	read_lock(&afs_servers_lock);
+	read_lock(&net->servers_lock);
 
-	p = afs_servers.rb_node;
+	p = net->servers.rb_node;
 	while (p) {
 		server = rb_entry(p, struct afs_server, master_rb);
 
@@ -211,7 +202,7 @@ struct afs_server *afs_find_server(const struct sockaddr_rxrpc *srx)
 
 	server = NULL;
 found:
-	read_unlock(&afs_servers_lock);
+	read_unlock(&net->servers_lock);
 	ASSERTIFCMP(server, server->addr.s_addr, ==, addr.s_addr);
 	_leave(" = %p", server);
 	return server;
@@ -223,6 +214,8 @@ struct afs_server *afs_find_server(const struct sockaddr_rxrpc *srx)
  */
 void afs_put_server(struct afs_server *server)
 {
+	struct afs_net *net = server->cell->net;
+
 	if (!server)
 		return;
 
@@ -239,14 +232,14 @@ void afs_put_server(struct afs_server *server)
 
 	afs_flush_callback_breaks(server);
 
-	spin_lock(&afs_server_graveyard_lock);
+	spin_lock(&net->server_graveyard_lock);
 	if (atomic_read(&server->usage) == 0) {
-		list_move_tail(&server->grave, &afs_server_graveyard);
+		list_move_tail(&server->grave, &net->server_graveyard);
 		server->time_of_death = ktime_get_real_seconds();
-		queue_delayed_work(afs_wq, &afs_server_reaper,
-				   afs_server_timeout * HZ);
+		queue_delayed_work(afs_wq, &net->server_reaper,
+				   net->live ? afs_server_timeout * HZ : 0);
 	}
-	spin_unlock(&afs_server_graveyard_lock);
+	spin_unlock(&net->server_graveyard_lock);
 	_leave(" [dead]");
 }
 
@@ -272,42 +265,45 @@ static void afs_destroy_server(struct afs_server *server)
 /*
  * reap dead server records
  */
-static void afs_reap_server(struct work_struct *work)
+void afs_reap_server(struct work_struct *work)
 {
 	LIST_HEAD(corpses);
 	struct afs_server *server;
+	struct afs_net *net = container_of(work, struct afs_net, server_reaper.work);
 	unsigned long delay, expiry;
 	time64_t now;
 
 	now = ktime_get_real_seconds();
-	spin_lock(&afs_server_graveyard_lock);
+	spin_lock(&net->server_graveyard_lock);
 
-	while (!list_empty(&afs_server_graveyard)) {
-		server = list_entry(afs_server_graveyard.next,
+	while (!list_empty(&net->server_graveyard)) {
+		server = list_entry(net->server_graveyard.next,
 				    struct afs_server, grave);
 
 		/* the queue is ordered most dead first */
-		expiry = server->time_of_death + afs_server_timeout;
-		if (expiry > now) {
-			delay = (expiry - now) * HZ;
-			mod_delayed_work(afs_wq, &afs_server_reaper, delay);
-			break;
+		if (net->live) {
+			expiry = server->time_of_death + afs_server_timeout;
+			if (expiry > now) {
+				delay = (expiry - now) * HZ;
+				mod_delayed_work(afs_wq, &net->server_reaper, delay);
+				break;
+			}
 		}
 
 		write_lock(&server->cell->servers_lock);
-		write_lock(&afs_servers_lock);
+		write_lock(&net->servers_lock);
 		if (atomic_read(&server->usage) > 0) {
 			list_del_init(&server->grave);
 		} else {
 			list_move_tail(&server->grave, &corpses);
 			list_del_init(&server->link);
-			rb_erase(&server->master_rb, &afs_servers);
+			rb_erase(&server->master_rb, &net->servers);
 		}
-		write_unlock(&afs_servers_lock);
+		write_unlock(&net->servers_lock);
 		write_unlock(&server->cell->servers_lock);
 	}
 
-	spin_unlock(&afs_server_graveyard_lock);
+	spin_unlock(&net->server_graveyard_lock);
 
 	/* now reap the corpses we've extracted */
 	while (!list_empty(&corpses)) {
@@ -318,10 +314,10 @@ static void afs_reap_server(struct work_struct *work)
 }
 
 /*
- * discard all the server records for rmmod
+ * Discard all the server records from a net namespace when it is destroyed or
+ * the afs module is removed.
  */
-void __exit afs_purge_servers(void)
+void __net_exit afs_purge_servers(struct afs_net *net)
 {
-	afs_server_timeout = 0;
-	mod_delayed_work(afs_wq, &afs_server_reaper, 0);
+	mod_delayed_work(afs_wq, &net->server_reaper, 0);
 }

commit 8a79790bf0b7da216627ffb85f52cfb4adbf1e4e
Author: Tina Ruchandani <ruchandani.tina@gmail.com>
Date:   Thu Mar 16 16:27:46 2017 +0000

    afs: Migrate vlocation fields to 64-bit
    
    get_seconds() returns real wall-clock seconds. On 32-bit systems
    this value will overflow in year 2038 and beyond. This patch changes
    afs's vlocation record to use ktime_get_real_seconds() instead, for the
    fields time_of_death and update_at.
    
    Signed-off-by: Tina Ruchandani <ruchandani.tina@gmail.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index d4066ab7dd55..c001b1f2455f 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -242,7 +242,7 @@ void afs_put_server(struct afs_server *server)
 	spin_lock(&afs_server_graveyard_lock);
 	if (atomic_read(&server->usage) == 0) {
 		list_move_tail(&server->grave, &afs_server_graveyard);
-		server->time_of_death = get_seconds();
+		server->time_of_death = ktime_get_real_seconds();
 		queue_delayed_work(afs_wq, &afs_server_reaper,
 				   afs_server_timeout * HZ);
 	}
@@ -277,9 +277,9 @@ static void afs_reap_server(struct work_struct *work)
 	LIST_HEAD(corpses);
 	struct afs_server *server;
 	unsigned long delay, expiry;
-	time_t now;
+	time64_t now;
 
-	now = get_seconds();
+	now = ktime_get_real_seconds();
 	spin_lock(&afs_server_graveyard_lock);
 
 	while (!list_empty(&afs_server_graveyard)) {

commit 8324f0bcfbfc645cf248e4b93ab58341b7d3b135
Author: David Howells <dhowells@redhat.com>
Date:   Tue Aug 30 09:49:29 2016 +0100

    rxrpc: Provide a way for AFS to ask for the peer address of a call
    
    Provide a function so that kernel users, such as AFS, can ask for the peer
    address of a call:
    
       void rxrpc_kernel_get_peer(struct rxrpc_call *call,
                                  struct sockaddr_rxrpc *_srx);
    
    In the future the kernel service won't get sk_buffs to look inside.
    Further, this allows us to hide any canonicalisation inside AF_RXRPC for
    when IPv6 support is added.
    
    Also propagate this through to afs_find_server() and issue a warning if we
    can't handle the address family yet.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index f342acf3547d..d4066ab7dd55 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -178,13 +178,18 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 /*
  * look up a server by its IP address
  */
-struct afs_server *afs_find_server(const struct in_addr *_addr)
+struct afs_server *afs_find_server(const struct sockaddr_rxrpc *srx)
 {
 	struct afs_server *server = NULL;
 	struct rb_node *p;
-	struct in_addr addr = *_addr;
+	struct in_addr addr = srx->transport.sin.sin_addr;
 
-	_enter("%pI4", &addr.s_addr);
+	_enter("{%d,%pI4}", srx->transport.family, &addr.s_addr);
+
+	if (srx->transport.family != AF_INET) {
+		WARN(true, "AFS does not yes support non-IPv4 addresses\n");
+		return NULL;
+	}
 
 	read_lock(&afs_servers_lock);
 

commit 41f63c5359d14ca995172b8f6eaffd93f60fec54
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Aug 3 10:30:47 2012 -0700

    workqueue: use mod_delayed_work() instead of cancel + queue
    
    Convert delayed_work users doing cancel_delayed_work() followed by
    queue_delayed_work() to mod_delayed_work().
    
    Most conversions are straight-forward.  Ones worth mentioning are,
    
    * drivers/edac/edac_mc.c: edac_mc_workq_setup() converted to always
      use mod_delayed_work() and cancel loop in
      edac_mc_reset_delay_period() is dropped.
    
    * drivers/platform/x86/thinkpad_acpi.c: No need to remember whether
      watchdog is active or not.  @fan_watchdog_active and related code
      dropped.
    
    * drivers/power/charger-manager.c: Seemingly a lot of
      delayed_work_pending() abuse going on here.
      [delayed_]work_pending() are unsynchronized and racy when used like
      this.  I converted one instance in fullbatt_handler().  Please
      conver the rest so that it invokes workqueue APIs for the intended
      target state rather than trying to game work item pending state
      transitions.  e.g. if timer should be modified - call
      mod_delayed_work(), canceled - call cancel_delayed_work[_sync]().
    
    * drivers/thermal/thermal_sys.c: thermal_zone_device_set_polling()
      simplified.  Note that round_jiffies() calls in this function are
      meaningless.  round_jiffies() work on absolute jiffies not delta
      delay used by delayed_work.
    
    v2: Tomi pointed out that __cancel_delayed_work() users can't be
        safely converted to mod_delayed_work().  They could be calling it
        from irq context and if that happens while delayed_work_timer_fn()
        is running, it could deadlock.  __cancel_delayed_work() users are
        dropped.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Henrique de Moraes Holschuh <hmh@hmh.eng.br>
    Acked-by: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Acked-by: Anton Vorontsov <cbouatmailru@gmail.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Tomi Valkeinen <tomi.valkeinen@ti.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Doug Thompson <dougthompson@xmission.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Roland Dreier <roland@kernel.org>
    Cc: "John W. Linville" <linville@tuxdriver.com>
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: "J. Bruce Fields" <bfields@fieldses.org>
    Cc: Johannes Berg <johannes@sipsolutions.net>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index d59b7516e943..f342acf3547d 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -285,12 +285,7 @@ static void afs_reap_server(struct work_struct *work)
 		expiry = server->time_of_death + afs_server_timeout;
 		if (expiry > now) {
 			delay = (expiry - now) * HZ;
-			if (!queue_delayed_work(afs_wq, &afs_server_reaper,
-						delay)) {
-				cancel_delayed_work(&afs_server_reaper);
-				queue_delayed_work(afs_wq, &afs_server_reaper,
-						   delay);
-			}
+			mod_delayed_work(afs_wq, &afs_server_reaper, delay);
 			break;
 		}
 
@@ -323,6 +318,5 @@ static void afs_reap_server(struct work_struct *work)
 void __exit afs_purge_servers(void)
 {
 	afs_server_timeout = 0;
-	cancel_delayed_work(&afs_server_reaper);
-	queue_delayed_work(afs_wq, &afs_server_reaper, 0);
+	mod_delayed_work(afs_wq, &afs_server_reaper, 0);
 }

commit 0ad53eeefcbb2620b6a71ffdaad4add20b450b8b
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jan 14 15:56:37 2011 +0000

    afs: add afs_wq and use it instead of the system workqueue
    
    flush_scheduled_work() is going away.  afs needs to make sure all the
    works it has queued have finished before being unloaded and there can
    be arbitrary number of pending works.  Add afs_wq and use it as the
    flush domain instead of the system workqueue.
    
    Also, convert cancel_delayed_work() + flush_scheduled_work() to
    cancel_delayed_work_sync() in afs_mntpt_kill_timer().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Cc: linux-afs@lists.infradead.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 9fdc7fe3a7bc..d59b7516e943 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -238,8 +238,8 @@ void afs_put_server(struct afs_server *server)
 	if (atomic_read(&server->usage) == 0) {
 		list_move_tail(&server->grave, &afs_server_graveyard);
 		server->time_of_death = get_seconds();
-		schedule_delayed_work(&afs_server_reaper,
-				      afs_server_timeout * HZ);
+		queue_delayed_work(afs_wq, &afs_server_reaper,
+				   afs_server_timeout * HZ);
 	}
 	spin_unlock(&afs_server_graveyard_lock);
 	_leave(" [dead]");
@@ -285,10 +285,11 @@ static void afs_reap_server(struct work_struct *work)
 		expiry = server->time_of_death + afs_server_timeout;
 		if (expiry > now) {
 			delay = (expiry - now) * HZ;
-			if (!schedule_delayed_work(&afs_server_reaper, delay)) {
+			if (!queue_delayed_work(afs_wq, &afs_server_reaper,
+						delay)) {
 				cancel_delayed_work(&afs_server_reaper);
-				schedule_delayed_work(&afs_server_reaper,
-						      delay);
+				queue_delayed_work(afs_wq, &afs_server_reaper,
+						   delay);
 			}
 			break;
 		}
@@ -323,5 +324,5 @@ void __exit afs_purge_servers(void)
 {
 	afs_server_timeout = 0;
 	cancel_delayed_work(&afs_server_reaper);
-	schedule_delayed_work(&afs_server_reaper, 0);
+	queue_delayed_work(afs_wq, &afs_server_reaper, 0);
 }

commit 037776fcbe73236408f6c9ca97c782457efd6b53
Author: Denis Kirjanov <dkirjanov@hera.kernel.org>
Date:   Tue Jun 1 17:15:39 2010 +0100

    AFS: Fix possible null pointer dereference in afs_alloc_server()
    
    Fix a possible null pointer dereference in afs_alloc_server(): the server
    pointer is NULL if there was an allocation failure, and under such a
    condition, we can't dereference it in the _leave() statement.
    
    Signed-off-by: Denis Kirjanov <dkirjanov@kernel.org>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index f49099516675..9fdc7fe3a7bc 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -91,9 +91,10 @@ static struct afs_server *afs_alloc_server(struct afs_cell *cell,
 
 		memcpy(&server->addr, addr, sizeof(struct in_addr));
 		server->addr.s_addr = addr->s_addr;
+		_leave(" = %p{%d}", server, atomic_read(&server->usage));
+	} else {
+		_leave(" = NULL [nomem]");
 	}
-
-	_leave(" = %p{%d}", server, atomic_read(&server->usage));
 	return server;
 }
 

commit be859405487324ed548f1ba11dc949b8230ab991
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Fri Oct 31 00:56:28 2008 -0700

    fs: replace NIPQUAD()
    
    Using NIPQUAD() with NIPQUAD_FMT, %d.%d.%d.%d or %u.%u.%u.%u
    can be replaced with %pI4
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 28f2451419e1..f49099516675 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -105,7 +105,7 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 {
 	struct afs_server *server, *candidate;
 
-	_enter("%p,"NIPQUAD_FMT, cell, NIPQUAD(addr->s_addr));
+	_enter("%p,%pI4", cell, &addr->s_addr);
 
 	/* quick scan of the list to see if we already have the server */
 	read_lock(&cell->servers_lock);
@@ -168,9 +168,8 @@ struct afs_server *afs_lookup_server(struct afs_cell *cell,
 server_in_two_cells:
 	write_unlock(&cell->servers_lock);
 	kfree(candidate);
-	printk(KERN_NOTICE "kAFS:"
-	       " Server "NIPQUAD_FMT" appears to be in two cells\n",
-	       NIPQUAD(*addr));
+	printk(KERN_NOTICE "kAFS: Server %pI4 appears to be in two cells\n",
+	       addr);
 	_leave(" = -EEXIST");
 	return ERR_PTR(-EEXIST);
 }
@@ -184,7 +183,7 @@ struct afs_server *afs_find_server(const struct in_addr *_addr)
 	struct rb_node *p;
 	struct in_addr addr = *_addr;
 
-	_enter(NIPQUAD_FMT, NIPQUAD(addr.s_addr));
+	_enter("%pI4", &addr.s_addr);
 
 	read_lock(&afs_servers_lock);
 

commit c1206a2c6d87def4af5379e6fef64e928d882ab2
Author: Adrian Bunk <bunk@stusta.de>
Date:   Tue Oct 16 23:26:41 2007 -0700

    fs/afs/: possible cleanups
    
    This patch contains the following possible cleanups:
    - make the following needlessly global functions static:
      - rxrpc.c: afs_send_pages()
      - vlocation.c: afs_vlocation_queue_for_updates()
      - write.c: afs_writepages_region()
    - make the following needlessly global variables static:
      - mntpt.c: afs_mntpt_expiry_timeout
      - proc.c: afs_vlocation_states[]
      - server.c: afs_server_timeout
      - vlocation.c: afs_vlocation_timeout
      - vlocation.c: afs_vlocation_update_timeout
    - #if 0 the following unused function:
      - cell.c: afs_get_cell_maybe()
    - #if 0 the following unused variables:
      - callback.c: afs_vnode_update_timeout
      - cmservice.c: struct afs_cm_workqueue
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 231ae4150279..28f2451419e1 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -13,7 +13,7 @@
 #include <linux/slab.h>
 #include "internal.h"
 
-unsigned afs_server_timeout = 10;	/* server timeout in seconds */
+static unsigned afs_server_timeout = 10;	/* server timeout in seconds */
 
 static void afs_reap_server(struct work_struct *);
 

commit 416351f28d2b31d15ff73e9aff699b2163704c95
Author: David Howells <dhowells@redhat.com>
Date:   Wed May 9 02:33:45 2007 -0700

    AFS: AFS fixups
    
    Make some miscellaneous changes to the AFS filesystem:
    
     (1) Assert RCU barriers on module exit to make sure RCU has finished with
         callbacks in this module.
    
     (2) Correctly handle the AFS server returning a zero-length read.
    
     (3) Split out data zapping calls into one function (afs_zap_data).
    
     (4) Rename some afs_file_*() functions to afs_*() where they apply to
         non-regular files too.
    
     (5) Be consistent about the presentation of volume ID:vnode ID in debugging
         output.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 96bb23b476a2..231ae4150279 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -252,6 +252,9 @@ static void afs_destroy_server(struct afs_server *server)
 {
 	_enter("%p", server);
 
+	ASSERTIF(server->cb_break_head != server->cb_break_tail,
+		 delayed_work_pending(&server->cb_break_work));
+
 	ASSERTCMP(server->fs_vnodes.rb_node, ==, NULL);
 	ASSERTCMP(server->cb_promises.rb_node, ==, NULL);
 	ASSERTCMP(server->cb_break_head, ==, server->cb_break_tail);

commit 260a980317dac80182dd76140cf67c6e81d6d3dd
Author: David Howells <dhowells@redhat.com>
Date:   Thu Apr 26 15:59:35 2007 -0700

    [AFS]: Add "directory write" support.
    
    Add support for the create, link, symlink, unlink, mkdir, rmdir and
    rename VFS operations to the in-kernel AFS filesystem.
    
    Also:
    
     (1) Fix dentry and inode revalidation.  d_revalidate should only look at
         state of the dentry.  Revalidation of the contents of an inode pointed to
         by a dentry is now separate.
    
     (2) Fix afs_lookup() to hash negative dentries as well as positive ones.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index bde6125c2f22..96bb23b476a2 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -223,6 +223,8 @@ void afs_put_server(struct afs_server *server)
 
 	_enter("%p{%d}", server, atomic_read(&server->usage));
 
+	_debug("PUT SERVER %d", atomic_read(&server->usage));
+
 	ASSERTCMP(atomic_read(&server->usage), >, 0);
 
 	if (likely(!atomic_dec_and_test(&server->usage))) {

commit 08e0e7c82eeadec6f4871a386b86bf0f0fbcb4eb
Author: David Howells <dhowells@redhat.com>
Date:   Thu Apr 26 15:55:03 2007 -0700

    [AF_RXRPC]: Make the in-kernel AFS filesystem use AF_RXRPC.
    
    Make the in-kernel AFS filesystem use AF_RXRPC instead of the old RxRPC code.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 44b0ce53e913..bde6125c2f22 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -1,6 +1,6 @@
 /* AFS server record management
  *
- * Copyright (C) 2002 Red Hat, Inc. All Rights Reserved.
+ * Copyright (C) 2002, 2007 Red Hat, Inc. All Rights Reserved.
  * Written by David Howells (dhowells@redhat.com)
  *
  * This program is free software; you can redistribute it and/or
@@ -11,127 +11,205 @@
 
 #include <linux/sched.h>
 #include <linux/slab.h>
-#include <rxrpc/peer.h>
-#include <rxrpc/connection.h>
-#include "volume.h"
-#include "cell.h"
-#include "server.h"
-#include "transport.h"
-#include "vlclient.h"
-#include "kafstimod.h"
 #include "internal.h"
 
-DEFINE_SPINLOCK(afs_server_peer_lock);
+unsigned afs_server_timeout = 10;	/* server timeout in seconds */
 
-#define FS_SERVICE_ID		1	/* AFS Volume Location Service ID */
-#define VL_SERVICE_ID		52	/* AFS Volume Location Service ID */
+static void afs_reap_server(struct work_struct *);
 
-static void __afs_server_timeout(struct afs_timer *timer)
+/* tree of all the servers, indexed by IP address */
+static struct rb_root afs_servers = RB_ROOT;
+static DEFINE_RWLOCK(afs_servers_lock);
+
+/* LRU list of all the servers not currently in use */
+static LIST_HEAD(afs_server_graveyard);
+static DEFINE_SPINLOCK(afs_server_graveyard_lock);
+static DECLARE_DELAYED_WORK(afs_server_reaper, afs_reap_server);
+
+/*
+ * install a server record in the master tree
+ */
+static int afs_install_server(struct afs_server *server)
 {
-	struct afs_server *server =
-		list_entry(timer, struct afs_server, timeout);
+	struct afs_server *xserver;
+	struct rb_node **pp, *p;
+	int ret;
+
+	_enter("%p", server);
 
-	_debug("SERVER TIMEOUT [%p{u=%d}]",
-	       server, atomic_read(&server->usage));
+	write_lock(&afs_servers_lock);
+
+	ret = -EEXIST;
+	pp = &afs_servers.rb_node;
+	p = NULL;
+	while (*pp) {
+		p = *pp;
+		_debug("- consider %p", p);
+		xserver = rb_entry(p, struct afs_server, master_rb);
+		if (server->addr.s_addr < xserver->addr.s_addr)
+			pp = &(*pp)->rb_left;
+		else if (server->addr.s_addr > xserver->addr.s_addr)
+			pp = &(*pp)->rb_right;
+		else
+			goto error;
+	}
 
-	afs_server_do_timeout(server);
-}
+	rb_link_node(&server->master_rb, p, pp);
+	rb_insert_color(&server->master_rb, &afs_servers);
+	ret = 0;
 
-static const struct afs_timer_ops afs_server_timer_ops = {
-	.timed_out	= __afs_server_timeout,
-};
+error:
+	write_unlock(&afs_servers_lock);
+	return ret;
+}
 
 /*
- * lookup a server record in a cell
- * - TODO: search the cell's server list
+ * allocate a new server record
  */
-int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
-		      struct afs_server **_server)
+static struct afs_server *afs_alloc_server(struct afs_cell *cell,
+					   const struct in_addr *addr)
 {
-	struct afs_server *server, *active, *zombie;
-	int loop;
+	struct afs_server *server;
 
-	_enter("%p,%08x,", cell, ntohl(addr->s_addr));
+	_enter("");
 
-	/* allocate and initialise a server record */
 	server = kzalloc(sizeof(struct afs_server), GFP_KERNEL);
-	if (!server) {
-		_leave(" = -ENOMEM");
-		return -ENOMEM;
+	if (server) {
+		atomic_set(&server->usage, 1);
+		server->cell = cell;
+
+		INIT_LIST_HEAD(&server->link);
+		INIT_LIST_HEAD(&server->grave);
+		init_rwsem(&server->sem);
+		spin_lock_init(&server->fs_lock);
+		server->fs_vnodes = RB_ROOT;
+		server->cb_promises = RB_ROOT;
+		spin_lock_init(&server->cb_lock);
+		init_waitqueue_head(&server->cb_break_waitq);
+		INIT_DELAYED_WORK(&server->cb_break_work,
+				  afs_dispatch_give_up_callbacks);
+
+		memcpy(&server->addr, addr, sizeof(struct in_addr));
+		server->addr.s_addr = addr->s_addr;
 	}
 
-	atomic_set(&server->usage, 1);
-
-	INIT_LIST_HEAD(&server->link);
-	init_rwsem(&server->sem);
-	INIT_LIST_HEAD(&server->fs_callq);
-	spin_lock_init(&server->fs_lock);
-	INIT_LIST_HEAD(&server->cb_promises);
-	spin_lock_init(&server->cb_lock);
-
-	for (loop = 0; loop < AFS_SERVER_CONN_LIST_SIZE; loop++)
-		server->fs_conn_cnt[loop] = 4;
+	_leave(" = %p{%d}", server, atomic_read(&server->usage));
+	return server;
+}
 
-	memcpy(&server->addr, addr, sizeof(struct in_addr));
-	server->addr.s_addr = addr->s_addr;
+/*
+ * get an FS-server record for a cell
+ */
+struct afs_server *afs_lookup_server(struct afs_cell *cell,
+				     const struct in_addr *addr)
+{
+	struct afs_server *server, *candidate;
 
-	afs_timer_init(&server->timeout, &afs_server_timer_ops);
+	_enter("%p,"NIPQUAD_FMT, cell, NIPQUAD(addr->s_addr));
 
-	/* add to the cell */
-	write_lock(&cell->sv_lock);
+	/* quick scan of the list to see if we already have the server */
+	read_lock(&cell->servers_lock);
 
-	/* check the active list */
-	list_for_each_entry(active, &cell->sv_list, link) {
-		if (active->addr.s_addr == addr->s_addr)
-			goto use_active_server;
+	list_for_each_entry(server, &cell->servers, link) {
+		if (server->addr.s_addr == addr->s_addr)
+			goto found_server_quickly;
 	}
+	read_unlock(&cell->servers_lock);
 
-	/* check the inactive list */
-	spin_lock(&cell->sv_gylock);
-	list_for_each_entry(zombie, &cell->sv_graveyard, link) {
-		if (zombie->addr.s_addr == addr->s_addr)
-			goto resurrect_server;
+	candidate = afs_alloc_server(cell, addr);
+	if (!candidate) {
+		_leave(" = -ENOMEM");
+		return ERR_PTR(-ENOMEM);
 	}
-	spin_unlock(&cell->sv_gylock);
 
-	afs_get_cell(cell);
-	server->cell = cell;
-	list_add_tail(&server->link, &cell->sv_list);
+	write_lock(&cell->servers_lock);
 
-	write_unlock(&cell->sv_lock);
+	/* check the cell's server list again */
+	list_for_each_entry(server, &cell->servers, link) {
+		if (server->addr.s_addr == addr->s_addr)
+			goto found_server;
+	}
+
+	_debug("new");
+	server = candidate;
+	if (afs_install_server(server) < 0)
+		goto server_in_two_cells;
 
-	*_server = server;
-	_leave(" = 0 (%p)", server);
-	return 0;
+	afs_get_cell(cell);
+	list_add_tail(&server->link, &cell->servers);
+
+	write_unlock(&cell->servers_lock);
+	_leave(" = %p{%d}", server, atomic_read(&server->usage));
+	return server;
+
+	/* found a matching server quickly */
+found_server_quickly:
+	_debug("found quickly");
+	afs_get_server(server);
+	read_unlock(&cell->servers_lock);
+no_longer_unused:
+	if (!list_empty(&server->grave)) {
+		spin_lock(&afs_server_graveyard_lock);
+		list_del_init(&server->grave);
+		spin_unlock(&afs_server_graveyard_lock);
+	}
+	_leave(" = %p{%d}", server, atomic_read(&server->usage));
+	return server;
+
+	/* found a matching server on the second pass */
+found_server:
+	_debug("found");
+	afs_get_server(server);
+	write_unlock(&cell->servers_lock);
+	kfree(candidate);
+	goto no_longer_unused;
+
+	/* found a server that seems to be in two cells */
+server_in_two_cells:
+	write_unlock(&cell->servers_lock);
+	kfree(candidate);
+	printk(KERN_NOTICE "kAFS:"
+	       " Server "NIPQUAD_FMT" appears to be in two cells\n",
+	       NIPQUAD(*addr));
+	_leave(" = -EEXIST");
+	return ERR_PTR(-EEXIST);
+}
 
-	/* found a matching active server */
-use_active_server:
-	_debug("active server");
-	afs_get_server(active);
-	write_unlock(&cell->sv_lock);
+/*
+ * look up a server by its IP address
+ */
+struct afs_server *afs_find_server(const struct in_addr *_addr)
+{
+	struct afs_server *server = NULL;
+	struct rb_node *p;
+	struct in_addr addr = *_addr;
 
-	kfree(server);
+	_enter(NIPQUAD_FMT, NIPQUAD(addr.s_addr));
 
-	*_server = active;
-	_leave(" = 0 (%p)", active);
-	return 0;
+	read_lock(&afs_servers_lock);
 
-	/* found a matching server in the graveyard, so resurrect it and
-	 * dispose of the new record */
-resurrect_server:
-	_debug("resurrecting server");
+	p = afs_servers.rb_node;
+	while (p) {
+		server = rb_entry(p, struct afs_server, master_rb);
 
-	list_move_tail(&zombie->link, &cell->sv_list);
-	afs_get_server(zombie);
-	afs_kafstimod_del_timer(&zombie->timeout);
-	spin_unlock(&cell->sv_gylock);
-	write_unlock(&cell->sv_lock);
+		_debug("- consider %p", p);
 
-	kfree(server);
+		if (addr.s_addr < server->addr.s_addr) {
+			p = p->rb_left;
+		} else if (addr.s_addr > server->addr.s_addr) {
+			p = p->rb_right;
+		} else {
+			afs_get_server(server);
+			goto found;
+		}
+	}
 
-	*_server = zombie;
-	_leave(" = 0 (%p)", zombie);
-	return 0;
+	server = NULL;
+found:
+	read_unlock(&afs_servers_lock);
+	ASSERTIFCMP(server, server->addr.s_addr, ==, addr.s_addr);
+	_leave(" = %p", server);
+	return server;
 }
 
 /*
@@ -140,347 +218,105 @@ int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
  */
 void afs_put_server(struct afs_server *server)
 {
-	struct afs_cell *cell;
-
 	if (!server)
 		return;
 
-	_enter("%p", server);
-
-	cell = server->cell;
+	_enter("%p{%d}", server, atomic_read(&server->usage));
 
-	/* sanity check */
-	BUG_ON(atomic_read(&server->usage) <= 0);
-
-	/* to prevent a race, the decrement and the dequeue must be effectively
-	 * atomic */
-	write_lock(&cell->sv_lock);
+	ASSERTCMP(atomic_read(&server->usage), >, 0);
 
 	if (likely(!atomic_dec_and_test(&server->usage))) {
-		write_unlock(&cell->sv_lock);
 		_leave("");
 		return;
 	}
 
-	spin_lock(&cell->sv_gylock);
-	list_move_tail(&server->link, &cell->sv_graveyard);
-
-	/* time out in 10 secs */
-	afs_kafstimod_add_timer(&server->timeout, 10 * HZ);
-
-	spin_unlock(&cell->sv_gylock);
-	write_unlock(&cell->sv_lock);
+	afs_flush_callback_breaks(server);
 
-	_leave(" [killed]");
+	spin_lock(&afs_server_graveyard_lock);
+	if (atomic_read(&server->usage) == 0) {
+		list_move_tail(&server->grave, &afs_server_graveyard);
+		server->time_of_death = get_seconds();
+		schedule_delayed_work(&afs_server_reaper,
+				      afs_server_timeout * HZ);
+	}
+	spin_unlock(&afs_server_graveyard_lock);
+	_leave(" [dead]");
 }
 
 /*
- * timeout server record
- * - removes from the cell's graveyard if the usage count is zero
+ * destroy a dead server
  */
-void afs_server_do_timeout(struct afs_server *server)
+static void afs_destroy_server(struct afs_server *server)
 {
-	struct rxrpc_peer *peer;
-	struct afs_cell *cell;
-	int loop;
-
 	_enter("%p", server);
 
-	cell = server->cell;
-
-	BUG_ON(atomic_read(&server->usage) < 0);
-
-	/* remove from graveyard if still dead */
-	spin_lock(&cell->vl_gylock);
-	if (atomic_read(&server->usage) == 0)
-		list_del_init(&server->link);
-	else
-		server = NULL;
-	spin_unlock(&cell->vl_gylock);
-
-	if (!server) {
-		_leave("");
-		return; /* resurrected */
-	}
-
-	/* we can now destroy it properly */
-	afs_put_cell(cell);
-
-	/* uncross-point the structs under a global lock */
-	spin_lock(&afs_server_peer_lock);
-	peer = server->peer;
-	if (peer) {
-		server->peer = NULL;
-		peer->user = NULL;
-	}
-	spin_unlock(&afs_server_peer_lock);
-
-	/* finish cleaning up the server */
-	for (loop = AFS_SERVER_CONN_LIST_SIZE - 1; loop >= 0; loop--)
-		if (server->fs_conn[loop])
-			rxrpc_put_connection(server->fs_conn[loop]);
-
-	if (server->vlserver)
-		rxrpc_put_connection(server->vlserver);
+	ASSERTCMP(server->fs_vnodes.rb_node, ==, NULL);
+	ASSERTCMP(server->cb_promises.rb_node, ==, NULL);
+	ASSERTCMP(server->cb_break_head, ==, server->cb_break_tail);
+	ASSERTCMP(atomic_read(&server->cb_break_n), ==, 0);
 
+	afs_put_cell(server->cell);
 	kfree(server);
-
-	_leave(" [destroyed]");
 }
 
 /*
- * get a callslot on a connection to the fileserver on the specified server
+ * reap dead server records
  */
-int afs_server_request_callslot(struct afs_server *server,
-				struct afs_server_callslot *callslot)
+static void afs_reap_server(struct work_struct *work)
 {
-	struct afs_server_callslot *pcallslot;
-	struct rxrpc_connection *conn;
-	int nconn, ret;
-
-	_enter("%p,",server);
-
-	INIT_LIST_HEAD(&callslot->link);
-	callslot->task = current;
-	callslot->conn = NULL;
-	callslot->nconn = -1;
-	callslot->ready = 0;
-
-	ret = 0;
-	conn = NULL;
-
-	/* get hold of a callslot first */
-	spin_lock(&server->fs_lock);
-
-	/* resurrect the server if it's death timeout has expired */
-	if (server->fs_state) {
-		if (time_before(jiffies, server->fs_dead_jif)) {
-			ret = server->fs_state;
-			spin_unlock(&server->fs_lock);
-			_leave(" = %d [still dead]", ret);
-			return ret;
+	LIST_HEAD(corpses);
+	struct afs_server *server;
+	unsigned long delay, expiry;
+	time_t now;
+
+	now = get_seconds();
+	spin_lock(&afs_server_graveyard_lock);
+
+	while (!list_empty(&afs_server_graveyard)) {
+		server = list_entry(afs_server_graveyard.next,
+				    struct afs_server, grave);
+
+		/* the queue is ordered most dead first */
+		expiry = server->time_of_death + afs_server_timeout;
+		if (expiry > now) {
+			delay = (expiry - now) * HZ;
+			if (!schedule_delayed_work(&afs_server_reaper, delay)) {
+				cancel_delayed_work(&afs_server_reaper);
+				schedule_delayed_work(&afs_server_reaper,
+						      delay);
+			}
+			break;
 		}
 
-		server->fs_state = 0;
-	}
-
-	/* try and find a connection that has spare callslots */
-	for (nconn = 0; nconn < AFS_SERVER_CONN_LIST_SIZE; nconn++) {
-		if (server->fs_conn_cnt[nconn] > 0) {
-			server->fs_conn_cnt[nconn]--;
-			spin_unlock(&server->fs_lock);
-			callslot->nconn = nconn;
-			goto obtained_slot;
+		write_lock(&server->cell->servers_lock);
+		write_lock(&afs_servers_lock);
+		if (atomic_read(&server->usage) > 0) {
+			list_del_init(&server->grave);
+		} else {
+			list_move_tail(&server->grave, &corpses);
+			list_del_init(&server->link);
+			rb_erase(&server->master_rb, &afs_servers);
 		}
+		write_unlock(&afs_servers_lock);
+		write_unlock(&server->cell->servers_lock);
 	}
 
-	/* none were available - wait interruptibly for one to become
-	 * available */
-	set_current_state(TASK_INTERRUPTIBLE);
-	list_add_tail(&callslot->link, &server->fs_callq);
-	spin_unlock(&server->fs_lock);
-
-	while (!callslot->ready && !signal_pending(current)) {
-		schedule();
-		set_current_state(TASK_INTERRUPTIBLE);
-	}
-
-	set_current_state(TASK_RUNNING);
-
-	/* even if we were interrupted we may still be queued */
-	if (!callslot->ready) {
-		spin_lock(&server->fs_lock);
-		list_del_init(&callslot->link);
-		spin_unlock(&server->fs_lock);
-	}
-
-	nconn = callslot->nconn;
-
-	/* if interrupted, we must release any slot we also got before
-	 * returning an error */
-	if (signal_pending(current)) {
-		ret = -EINTR;
-		goto error_release;
-	}
-
-	/* if we were woken up with an error, then pass that error back to the
-	 * called */
-	if (nconn < 0) {
-		_leave(" = %d", callslot->errno);
-		return callslot->errno;
-	}
-
-	/* were we given a connection directly? */
-	if (callslot->conn) {
-		/* yes - use it */
-		_leave(" = 0 (nc=%d)", nconn);
-		return 0;
-	}
+	spin_unlock(&afs_server_graveyard_lock);
 
-	/* got a callslot, but no connection */
-obtained_slot:
-
-	/* need to get hold of the RxRPC connection */
-	down_write(&server->sem);
-
-	/* quick check to see if there's an outstanding error */
-	ret = server->fs_state;
-	if (ret)
-		goto error_release_upw;
-
-	if (server->fs_conn[nconn]) {
-		/* reuse an existing connection */
-		rxrpc_get_connection(server->fs_conn[nconn]);
-		callslot->conn = server->fs_conn[nconn];
-	} else {
-		/* create a new connection */
-		ret = rxrpc_create_connection(afs_transport,
-					      htons(7000),
-					      server->addr.s_addr,
-					      FS_SERVICE_ID,
-					      NULL,
-					      &server->fs_conn[nconn]);
-
-		if (ret < 0)
-			goto error_release_upw;
-
-		callslot->conn = server->fs_conn[0];
-		rxrpc_get_connection(callslot->conn);
+	/* now reap the corpses we've extracted */
+	while (!list_empty(&corpses)) {
+		server = list_entry(corpses.next, struct afs_server, grave);
+		list_del(&server->grave);
+		afs_destroy_server(server);
 	}
-
-	up_write(&server->sem);
-
- 	_leave(" = 0");
-	return 0;
-
-	/* handle an error occurring */
-error_release_upw:
-	up_write(&server->sem);
-
-error_release:
-	/* either release the callslot or pass it along to another deserving
-	 * task */
-	spin_lock(&server->fs_lock);
-
-	if (nconn < 0) {
-		/* no callslot allocated */
-	} else if (list_empty(&server->fs_callq)) {
-		/* no one waiting */
-		server->fs_conn_cnt[nconn]++;
-		spin_unlock(&server->fs_lock);
-	} else {
-		/* someone's waiting - dequeue them and wake them up */
-		pcallslot = list_entry(server->fs_callq.next,
-				       struct afs_server_callslot, link);
-		list_del_init(&pcallslot->link);
-
-		pcallslot->errno = server->fs_state;
-		if (!pcallslot->errno) {
-			/* pass them out callslot details */
-			callslot->conn = xchg(&pcallslot->conn,
-					      callslot->conn);
-			pcallslot->nconn = nconn;
-			callslot->nconn = nconn = -1;
-		}
-		pcallslot->ready = 1;
-		wake_up_process(pcallslot->task);
-		spin_unlock(&server->fs_lock);
-	}
-
-	rxrpc_put_connection(callslot->conn);
-	callslot->conn = NULL;
-
-	_leave(" = %d", ret);
-	return ret;
 }
 
 /*
- * release a callslot back to the server
- * - transfers the RxRPC connection to the next pending callslot if possible
+ * discard all the server records for rmmod
  */
-void afs_server_release_callslot(struct afs_server *server,
-				 struct afs_server_callslot *callslot)
+void __exit afs_purge_servers(void)
 {
-	struct afs_server_callslot *pcallslot;
-
-	_enter("{ad=%08x,cnt=%u},{%d}",
-	       ntohl(server->addr.s_addr),
-	       server->fs_conn_cnt[callslot->nconn],
-	       callslot->nconn);
-
-	BUG_ON(callslot->nconn < 0);
-
-	spin_lock(&server->fs_lock);
-
-	if (list_empty(&server->fs_callq)) {
-		/* no one waiting */
-		server->fs_conn_cnt[callslot->nconn]++;
-		spin_unlock(&server->fs_lock);
-	} else {
-		/* someone's waiting - dequeue them and wake them up */
-		pcallslot = list_entry(server->fs_callq.next,
-				       struct afs_server_callslot, link);
-		list_del_init(&pcallslot->link);
-
-		pcallslot->errno = server->fs_state;
-		if (!pcallslot->errno) {
-			/* pass them out callslot details */
-			callslot->conn = xchg(&pcallslot->conn, callslot->conn);
-			pcallslot->nconn = callslot->nconn;
-			callslot->nconn = -1;
-		}
-
-		pcallslot->ready = 1;
-		wake_up_process(pcallslot->task);
-		spin_unlock(&server->fs_lock);
-	}
-
-	rxrpc_put_connection(callslot->conn);
-
-	_leave("");
-}
-
-/*
- * get a handle to a connection to the vlserver (volume location) on the
- * specified server
- */
-int afs_server_get_vlconn(struct afs_server *server,
-			  struct rxrpc_connection **_conn)
-{
-	struct rxrpc_connection *conn;
-	int ret;
-
-	_enter("%p,", server);
-
-	ret = 0;
-	conn = NULL;
-	down_read(&server->sem);
-
-	if (server->vlserver) {
-		/* reuse an existing connection */
-		rxrpc_get_connection(server->vlserver);
-		conn = server->vlserver;
-		up_read(&server->sem);
-	} else {
-		/* create a new connection */
-		up_read(&server->sem);
-		down_write(&server->sem);
-		if (!server->vlserver) {
-			ret = rxrpc_create_connection(afs_transport,
-						      htons(7003),
-						      server->addr.s_addr,
-						      VL_SERVICE_ID,
-						      NULL,
-						      &server->vlserver);
-		}
-		if (ret == 0) {
-			rxrpc_get_connection(server->vlserver);
-			conn = server->vlserver;
-		}
-		up_write(&server->sem);
-	}
-
-	*_conn = conn;
-	_leave(" = %d", ret);
-	return ret;
+	afs_server_timeout = 0;
+	cancel_delayed_work(&afs_server_reaper);
+	schedule_delayed_work(&afs_server_reaper, 0);
 }

commit ec26815ad847dbf74a1e27aa5515fb7d5dc6ee6f
Author: David Howells <dhowells@redhat.com>
Date:   Thu Apr 26 15:49:28 2007 -0700

    [AFS]: Clean up the AFS sources
    
    Clean up the AFS sources.
    
    Also remove references to AFS keys.  RxRPC keys are used instead.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 44aff81dc6a7..44b0ce53e913 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -1,4 +1,4 @@
-/* server.c: AFS server record management
+/* AFS server record management
  *
  * Copyright (C) 2002 Red Hat, Inc. All Rights Reserved.
  * Written by David Howells (dhowells@redhat.com)
@@ -41,7 +41,6 @@ static const struct afs_timer_ops afs_server_timer_ops = {
 	.timed_out	= __afs_server_timeout,
 };
 
-/*****************************************************************************/
 /*
  * lookup a server record in a cell
  * - TODO: search the cell's server list
@@ -106,7 +105,7 @@ int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
 	return 0;
 
 	/* found a matching active server */
- use_active_server:
+use_active_server:
 	_debug("active server");
 	afs_get_server(active);
 	write_unlock(&cell->sv_lock);
@@ -119,7 +118,7 @@ int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
 
 	/* found a matching server in the graveyard, so resurrect it and
 	 * dispose of the new record */
- resurrect_server:
+resurrect_server:
 	_debug("resurrecting server");
 
 	list_move_tail(&zombie->link, &cell->sv_list);
@@ -133,10 +132,8 @@ int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
 	*_server = zombie;
 	_leave(" = 0 (%p)", zombie);
 	return 0;
+}
 
-} /* end afs_server_lookup() */
-
-/*****************************************************************************/
 /*
  * destroy a server record
  * - removes from the cell list
@@ -175,9 +172,8 @@ void afs_put_server(struct afs_server *server)
 	write_unlock(&cell->sv_lock);
 
 	_leave(" [killed]");
-} /* end afs_put_server() */
+}
 
-/*****************************************************************************/
 /*
  * timeout server record
  * - removes from the cell's graveyard if the usage count is zero
@@ -230,9 +226,8 @@ void afs_server_do_timeout(struct afs_server *server)
 	kfree(server);
 
 	_leave(" [destroyed]");
-} /* end afs_server_do_timeout() */
+}
 
-/*****************************************************************************/
 /*
  * get a callslot on a connection to the fileserver on the specified server
  */
@@ -323,7 +318,7 @@ int afs_server_request_callslot(struct afs_server *server,
 	}
 
 	/* got a callslot, but no connection */
- obtained_slot:
+obtained_slot:
 
 	/* need to get hold of the RxRPC connection */
 	down_write(&server->sem);
@@ -337,8 +332,7 @@ int afs_server_request_callslot(struct afs_server *server,
 		/* reuse an existing connection */
 		rxrpc_get_connection(server->fs_conn[nconn]);
 		callslot->conn = server->fs_conn[nconn];
-	}
-	else {
+	} else {
 		/* create a new connection */
 		ret = rxrpc_create_connection(afs_transport,
 					      htons(7000),
@@ -360,23 +354,21 @@ int afs_server_request_callslot(struct afs_server *server,
 	return 0;
 
 	/* handle an error occurring */
- error_release_upw:
+error_release_upw:
 	up_write(&server->sem);
 
- error_release:
+error_release:
 	/* either release the callslot or pass it along to another deserving
 	 * task */
 	spin_lock(&server->fs_lock);
 
 	if (nconn < 0) {
 		/* no callslot allocated */
-	}
-	else if (list_empty(&server->fs_callq)) {
+	} else if (list_empty(&server->fs_callq)) {
 		/* no one waiting */
 		server->fs_conn_cnt[nconn]++;
 		spin_unlock(&server->fs_lock);
-	}
-	else {
+	} else {
 		/* someone's waiting - dequeue them and wake them up */
 		pcallslot = list_entry(server->fs_callq.next,
 				       struct afs_server_callslot, link);
@@ -400,10 +392,8 @@ int afs_server_request_callslot(struct afs_server *server,
 
 	_leave(" = %d", ret);
 	return ret;
+}
 
-} /* end afs_server_request_callslot() */
-
-/*****************************************************************************/
 /*
  * release a callslot back to the server
  * - transfers the RxRPC connection to the next pending callslot if possible
@@ -426,8 +416,7 @@ void afs_server_release_callslot(struct afs_server *server,
 		/* no one waiting */
 		server->fs_conn_cnt[callslot->nconn]++;
 		spin_unlock(&server->fs_lock);
-	}
-	else {
+	} else {
 		/* someone's waiting - dequeue them and wake them up */
 		pcallslot = list_entry(server->fs_callq.next,
 				       struct afs_server_callslot, link);
@@ -449,9 +438,8 @@ void afs_server_release_callslot(struct afs_server *server,
 	rxrpc_put_connection(callslot->conn);
 
 	_leave("");
-} /* end afs_server_release_callslot() */
+}
 
-/*****************************************************************************/
 /*
  * get a handle to a connection to the vlserver (volume location) on the
  * specified server
@@ -473,8 +461,7 @@ int afs_server_get_vlconn(struct afs_server *server,
 		rxrpc_get_connection(server->vlserver);
 		conn = server->vlserver;
 		up_read(&server->sem);
-	}
-	else {
+	} else {
 		/* create a new connection */
 		up_read(&server->sem);
 		down_write(&server->sem);
@@ -496,4 +483,4 @@ int afs_server_get_vlconn(struct afs_server *server,
 	*_conn = conn;
 	_leave(" = %d", ret);
 	return ret;
-} /* end afs_server_get_vlconn() */
+}

commit b593e48d2bf09c40c0f5165f2f2a10cc3983ea51
Author: Yan Burman <burman.yan@gmail.com>
Date:   Wed Dec 6 20:40:32 2006 -0800

    [PATCH] affs: replace kmalloc+memset with kzalloc
    
    Replace kmalloc+memset with kzalloc
    
    Signed-off-by: Yan Burman <burman.yan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 22afaae1a4ce..44aff81dc6a7 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -55,13 +55,12 @@ int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
 	_enter("%p,%08x,", cell, ntohl(addr->s_addr));
 
 	/* allocate and initialise a server record */
-	server = kmalloc(sizeof(struct afs_server), GFP_KERNEL);
+	server = kzalloc(sizeof(struct afs_server), GFP_KERNEL);
 	if (!server) {
 		_leave(" = -ENOMEM");
 		return -ENOMEM;
 	}
 
-	memset(server, 0, sizeof(struct afs_server));
 	atomic_set(&server->usage, 1);
 
 	INIT_LIST_HEAD(&server->link);

commit f116629d03655adaf7832b93b03c99391d09d4a7
Author: Akinobu Mita <mita@miraclelinux.com>
Date:   Mon Jun 26 00:24:46 2006 -0700

    [PATCH] fs: use list_move()
    
    This patch converts the combination of list_del(A) and list_add(A, B) to
    list_move(A, B) under fs/.
    
    Cc: Ian Kent <raven@themaw.net>
    Acked-by: Joel Becker <joel.becker@oracle.com>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Cc: Hans Reiser <reiserfs-dev@namesys.com>
    Cc: Urban Widmark <urban@teststation.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Acked-by: Mark Fasheh <mark.fasheh@oracle.com>
    Signed-off-by: Akinobu Mita <mita@miraclelinux.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/afs/server.c b/fs/afs/server.c
index 62b093aa41c6..22afaae1a4ce 100644
--- a/fs/afs/server.c
+++ b/fs/afs/server.c
@@ -123,8 +123,7 @@ int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
  resurrect_server:
 	_debug("resurrecting server");
 
-	list_del(&zombie->link);
-	list_add_tail(&zombie->link, &cell->sv_list);
+	list_move_tail(&zombie->link, &cell->sv_list);
 	afs_get_server(zombie);
 	afs_kafstimod_del_timer(&zombie->timeout);
 	spin_unlock(&cell->sv_gylock);
@@ -168,8 +167,7 @@ void afs_put_server(struct afs_server *server)
 	}
 
 	spin_lock(&cell->sv_gylock);
-	list_del(&server->link);
-	list_add_tail(&server->link, &cell->sv_graveyard);
+	list_move_tail(&server->link, &cell->sv_graveyard);
 
 	/* time out in 10 secs */
 	afs_kafstimod_add_timer(&server->timeout, 10 * HZ);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/fs/afs/server.c b/fs/afs/server.c
new file mode 100644
index 000000000000..62b093aa41c6
--- /dev/null
+++ b/fs/afs/server.c
@@ -0,0 +1,502 @@
+/* server.c: AFS server record management
+ *
+ * Copyright (C) 2002 Red Hat, Inc. All Rights Reserved.
+ * Written by David Howells (dhowells@redhat.com)
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <rxrpc/peer.h>
+#include <rxrpc/connection.h>
+#include "volume.h"
+#include "cell.h"
+#include "server.h"
+#include "transport.h"
+#include "vlclient.h"
+#include "kafstimod.h"
+#include "internal.h"
+
+DEFINE_SPINLOCK(afs_server_peer_lock);
+
+#define FS_SERVICE_ID		1	/* AFS Volume Location Service ID */
+#define VL_SERVICE_ID		52	/* AFS Volume Location Service ID */
+
+static void __afs_server_timeout(struct afs_timer *timer)
+{
+	struct afs_server *server =
+		list_entry(timer, struct afs_server, timeout);
+
+	_debug("SERVER TIMEOUT [%p{u=%d}]",
+	       server, atomic_read(&server->usage));
+
+	afs_server_do_timeout(server);
+}
+
+static const struct afs_timer_ops afs_server_timer_ops = {
+	.timed_out	= __afs_server_timeout,
+};
+
+/*****************************************************************************/
+/*
+ * lookup a server record in a cell
+ * - TODO: search the cell's server list
+ */
+int afs_server_lookup(struct afs_cell *cell, const struct in_addr *addr,
+		      struct afs_server **_server)
+{
+	struct afs_server *server, *active, *zombie;
+	int loop;
+
+	_enter("%p,%08x,", cell, ntohl(addr->s_addr));
+
+	/* allocate and initialise a server record */
+	server = kmalloc(sizeof(struct afs_server), GFP_KERNEL);
+	if (!server) {
+		_leave(" = -ENOMEM");
+		return -ENOMEM;
+	}
+
+	memset(server, 0, sizeof(struct afs_server));
+	atomic_set(&server->usage, 1);
+
+	INIT_LIST_HEAD(&server->link);
+	init_rwsem(&server->sem);
+	INIT_LIST_HEAD(&server->fs_callq);
+	spin_lock_init(&server->fs_lock);
+	INIT_LIST_HEAD(&server->cb_promises);
+	spin_lock_init(&server->cb_lock);
+
+	for (loop = 0; loop < AFS_SERVER_CONN_LIST_SIZE; loop++)
+		server->fs_conn_cnt[loop] = 4;
+
+	memcpy(&server->addr, addr, sizeof(struct in_addr));
+	server->addr.s_addr = addr->s_addr;
+
+	afs_timer_init(&server->timeout, &afs_server_timer_ops);
+
+	/* add to the cell */
+	write_lock(&cell->sv_lock);
+
+	/* check the active list */
+	list_for_each_entry(active, &cell->sv_list, link) {
+		if (active->addr.s_addr == addr->s_addr)
+			goto use_active_server;
+	}
+
+	/* check the inactive list */
+	spin_lock(&cell->sv_gylock);
+	list_for_each_entry(zombie, &cell->sv_graveyard, link) {
+		if (zombie->addr.s_addr == addr->s_addr)
+			goto resurrect_server;
+	}
+	spin_unlock(&cell->sv_gylock);
+
+	afs_get_cell(cell);
+	server->cell = cell;
+	list_add_tail(&server->link, &cell->sv_list);
+
+	write_unlock(&cell->sv_lock);
+
+	*_server = server;
+	_leave(" = 0 (%p)", server);
+	return 0;
+
+	/* found a matching active server */
+ use_active_server:
+	_debug("active server");
+	afs_get_server(active);
+	write_unlock(&cell->sv_lock);
+
+	kfree(server);
+
+	*_server = active;
+	_leave(" = 0 (%p)", active);
+	return 0;
+
+	/* found a matching server in the graveyard, so resurrect it and
+	 * dispose of the new record */
+ resurrect_server:
+	_debug("resurrecting server");
+
+	list_del(&zombie->link);
+	list_add_tail(&zombie->link, &cell->sv_list);
+	afs_get_server(zombie);
+	afs_kafstimod_del_timer(&zombie->timeout);
+	spin_unlock(&cell->sv_gylock);
+	write_unlock(&cell->sv_lock);
+
+	kfree(server);
+
+	*_server = zombie;
+	_leave(" = 0 (%p)", zombie);
+	return 0;
+
+} /* end afs_server_lookup() */
+
+/*****************************************************************************/
+/*
+ * destroy a server record
+ * - removes from the cell list
+ */
+void afs_put_server(struct afs_server *server)
+{
+	struct afs_cell *cell;
+
+	if (!server)
+		return;
+
+	_enter("%p", server);
+
+	cell = server->cell;
+
+	/* sanity check */
+	BUG_ON(atomic_read(&server->usage) <= 0);
+
+	/* to prevent a race, the decrement and the dequeue must be effectively
+	 * atomic */
+	write_lock(&cell->sv_lock);
+
+	if (likely(!atomic_dec_and_test(&server->usage))) {
+		write_unlock(&cell->sv_lock);
+		_leave("");
+		return;
+	}
+
+	spin_lock(&cell->sv_gylock);
+	list_del(&server->link);
+	list_add_tail(&server->link, &cell->sv_graveyard);
+
+	/* time out in 10 secs */
+	afs_kafstimod_add_timer(&server->timeout, 10 * HZ);
+
+	spin_unlock(&cell->sv_gylock);
+	write_unlock(&cell->sv_lock);
+
+	_leave(" [killed]");
+} /* end afs_put_server() */
+
+/*****************************************************************************/
+/*
+ * timeout server record
+ * - removes from the cell's graveyard if the usage count is zero
+ */
+void afs_server_do_timeout(struct afs_server *server)
+{
+	struct rxrpc_peer *peer;
+	struct afs_cell *cell;
+	int loop;
+
+	_enter("%p", server);
+
+	cell = server->cell;
+
+	BUG_ON(atomic_read(&server->usage) < 0);
+
+	/* remove from graveyard if still dead */
+	spin_lock(&cell->vl_gylock);
+	if (atomic_read(&server->usage) == 0)
+		list_del_init(&server->link);
+	else
+		server = NULL;
+	spin_unlock(&cell->vl_gylock);
+
+	if (!server) {
+		_leave("");
+		return; /* resurrected */
+	}
+
+	/* we can now destroy it properly */
+	afs_put_cell(cell);
+
+	/* uncross-point the structs under a global lock */
+	spin_lock(&afs_server_peer_lock);
+	peer = server->peer;
+	if (peer) {
+		server->peer = NULL;
+		peer->user = NULL;
+	}
+	spin_unlock(&afs_server_peer_lock);
+
+	/* finish cleaning up the server */
+	for (loop = AFS_SERVER_CONN_LIST_SIZE - 1; loop >= 0; loop--)
+		if (server->fs_conn[loop])
+			rxrpc_put_connection(server->fs_conn[loop]);
+
+	if (server->vlserver)
+		rxrpc_put_connection(server->vlserver);
+
+	kfree(server);
+
+	_leave(" [destroyed]");
+} /* end afs_server_do_timeout() */
+
+/*****************************************************************************/
+/*
+ * get a callslot on a connection to the fileserver on the specified server
+ */
+int afs_server_request_callslot(struct afs_server *server,
+				struct afs_server_callslot *callslot)
+{
+	struct afs_server_callslot *pcallslot;
+	struct rxrpc_connection *conn;
+	int nconn, ret;
+
+	_enter("%p,",server);
+
+	INIT_LIST_HEAD(&callslot->link);
+	callslot->task = current;
+	callslot->conn = NULL;
+	callslot->nconn = -1;
+	callslot->ready = 0;
+
+	ret = 0;
+	conn = NULL;
+
+	/* get hold of a callslot first */
+	spin_lock(&server->fs_lock);
+
+	/* resurrect the server if it's death timeout has expired */
+	if (server->fs_state) {
+		if (time_before(jiffies, server->fs_dead_jif)) {
+			ret = server->fs_state;
+			spin_unlock(&server->fs_lock);
+			_leave(" = %d [still dead]", ret);
+			return ret;
+		}
+
+		server->fs_state = 0;
+	}
+
+	/* try and find a connection that has spare callslots */
+	for (nconn = 0; nconn < AFS_SERVER_CONN_LIST_SIZE; nconn++) {
+		if (server->fs_conn_cnt[nconn] > 0) {
+			server->fs_conn_cnt[nconn]--;
+			spin_unlock(&server->fs_lock);
+			callslot->nconn = nconn;
+			goto obtained_slot;
+		}
+	}
+
+	/* none were available - wait interruptibly for one to become
+	 * available */
+	set_current_state(TASK_INTERRUPTIBLE);
+	list_add_tail(&callslot->link, &server->fs_callq);
+	spin_unlock(&server->fs_lock);
+
+	while (!callslot->ready && !signal_pending(current)) {
+		schedule();
+		set_current_state(TASK_INTERRUPTIBLE);
+	}
+
+	set_current_state(TASK_RUNNING);
+
+	/* even if we were interrupted we may still be queued */
+	if (!callslot->ready) {
+		spin_lock(&server->fs_lock);
+		list_del_init(&callslot->link);
+		spin_unlock(&server->fs_lock);
+	}
+
+	nconn = callslot->nconn;
+
+	/* if interrupted, we must release any slot we also got before
+	 * returning an error */
+	if (signal_pending(current)) {
+		ret = -EINTR;
+		goto error_release;
+	}
+
+	/* if we were woken up with an error, then pass that error back to the
+	 * called */
+	if (nconn < 0) {
+		_leave(" = %d", callslot->errno);
+		return callslot->errno;
+	}
+
+	/* were we given a connection directly? */
+	if (callslot->conn) {
+		/* yes - use it */
+		_leave(" = 0 (nc=%d)", nconn);
+		return 0;
+	}
+
+	/* got a callslot, but no connection */
+ obtained_slot:
+
+	/* need to get hold of the RxRPC connection */
+	down_write(&server->sem);
+
+	/* quick check to see if there's an outstanding error */
+	ret = server->fs_state;
+	if (ret)
+		goto error_release_upw;
+
+	if (server->fs_conn[nconn]) {
+		/* reuse an existing connection */
+		rxrpc_get_connection(server->fs_conn[nconn]);
+		callslot->conn = server->fs_conn[nconn];
+	}
+	else {
+		/* create a new connection */
+		ret = rxrpc_create_connection(afs_transport,
+					      htons(7000),
+					      server->addr.s_addr,
+					      FS_SERVICE_ID,
+					      NULL,
+					      &server->fs_conn[nconn]);
+
+		if (ret < 0)
+			goto error_release_upw;
+
+		callslot->conn = server->fs_conn[0];
+		rxrpc_get_connection(callslot->conn);
+	}
+
+	up_write(&server->sem);
+
+ 	_leave(" = 0");
+	return 0;
+
+	/* handle an error occurring */
+ error_release_upw:
+	up_write(&server->sem);
+
+ error_release:
+	/* either release the callslot or pass it along to another deserving
+	 * task */
+	spin_lock(&server->fs_lock);
+
+	if (nconn < 0) {
+		/* no callslot allocated */
+	}
+	else if (list_empty(&server->fs_callq)) {
+		/* no one waiting */
+		server->fs_conn_cnt[nconn]++;
+		spin_unlock(&server->fs_lock);
+	}
+	else {
+		/* someone's waiting - dequeue them and wake them up */
+		pcallslot = list_entry(server->fs_callq.next,
+				       struct afs_server_callslot, link);
+		list_del_init(&pcallslot->link);
+
+		pcallslot->errno = server->fs_state;
+		if (!pcallslot->errno) {
+			/* pass them out callslot details */
+			callslot->conn = xchg(&pcallslot->conn,
+					      callslot->conn);
+			pcallslot->nconn = nconn;
+			callslot->nconn = nconn = -1;
+		}
+		pcallslot->ready = 1;
+		wake_up_process(pcallslot->task);
+		spin_unlock(&server->fs_lock);
+	}
+
+	rxrpc_put_connection(callslot->conn);
+	callslot->conn = NULL;
+
+	_leave(" = %d", ret);
+	return ret;
+
+} /* end afs_server_request_callslot() */
+
+/*****************************************************************************/
+/*
+ * release a callslot back to the server
+ * - transfers the RxRPC connection to the next pending callslot if possible
+ */
+void afs_server_release_callslot(struct afs_server *server,
+				 struct afs_server_callslot *callslot)
+{
+	struct afs_server_callslot *pcallslot;
+
+	_enter("{ad=%08x,cnt=%u},{%d}",
+	       ntohl(server->addr.s_addr),
+	       server->fs_conn_cnt[callslot->nconn],
+	       callslot->nconn);
+
+	BUG_ON(callslot->nconn < 0);
+
+	spin_lock(&server->fs_lock);
+
+	if (list_empty(&server->fs_callq)) {
+		/* no one waiting */
+		server->fs_conn_cnt[callslot->nconn]++;
+		spin_unlock(&server->fs_lock);
+	}
+	else {
+		/* someone's waiting - dequeue them and wake them up */
+		pcallslot = list_entry(server->fs_callq.next,
+				       struct afs_server_callslot, link);
+		list_del_init(&pcallslot->link);
+
+		pcallslot->errno = server->fs_state;
+		if (!pcallslot->errno) {
+			/* pass them out callslot details */
+			callslot->conn = xchg(&pcallslot->conn, callslot->conn);
+			pcallslot->nconn = callslot->nconn;
+			callslot->nconn = -1;
+		}
+
+		pcallslot->ready = 1;
+		wake_up_process(pcallslot->task);
+		spin_unlock(&server->fs_lock);
+	}
+
+	rxrpc_put_connection(callslot->conn);
+
+	_leave("");
+} /* end afs_server_release_callslot() */
+
+/*****************************************************************************/
+/*
+ * get a handle to a connection to the vlserver (volume location) on the
+ * specified server
+ */
+int afs_server_get_vlconn(struct afs_server *server,
+			  struct rxrpc_connection **_conn)
+{
+	struct rxrpc_connection *conn;
+	int ret;
+
+	_enter("%p,", server);
+
+	ret = 0;
+	conn = NULL;
+	down_read(&server->sem);
+
+	if (server->vlserver) {
+		/* reuse an existing connection */
+		rxrpc_get_connection(server->vlserver);
+		conn = server->vlserver;
+		up_read(&server->sem);
+	}
+	else {
+		/* create a new connection */
+		up_read(&server->sem);
+		down_write(&server->sem);
+		if (!server->vlserver) {
+			ret = rxrpc_create_connection(afs_transport,
+						      htons(7003),
+						      server->addr.s_addr,
+						      VL_SERVICE_ID,
+						      NULL,
+						      &server->vlserver);
+		}
+		if (ret == 0) {
+			rxrpc_get_connection(server->vlserver);
+			conn = server->vlserver;
+		}
+		up_write(&server->sem);
+	}
+
+	*_conn = conn;
+	_leave(" = %d", ret);
+	return ret;
+} /* end afs_server_get_vlconn() */
