commit 623ba664b74a20f22a2ef7ebd71e171d2d7c626f
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Thu Jun 25 13:30:52 2020 -0500

    gfs2: When freezing gfs2, use GL_EXACT and not GL_NOCACHE
    
    Before this patch, the freeze code in gfs2 specified GL_NOCACHE in
    several places. That's wrong because we always want to know the state
    of whether the file system is frozen.
    
    There was also a problem with freeze/thaw transitioning the glock from
    frozen (EX) to thawed (SH) because gfs2 will normally grant glocks in EX
    to processes that request it in SH mode, unless GL_EXACT is specified.
    Therefore, the freeze/thaw code, which tried to reacquire the glock in
    SH mode would get the glock in EX mode, and miss the transition from EX
    to SH. That made it think the thaw had completed normally, but since the
    glock was still cached in EX, other nodes could not freeze again.
    
    This patch removes the GL_NOCACHE flag to allow the freeze glock to be
    cached. It also adds the GL_EXACT flag so the glock is fully transitioned
    from EX to SH, thereby allowing future freeze operations.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 96c345f49273..390ea79d682c 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -364,8 +364,8 @@ void gfs2_recover_func(struct work_struct *work)
 		/* Acquire a shared hold on the freeze lock */
 
 		error = gfs2_glock_nq_init(sdp->sd_freeze_gl, LM_ST_SHARED,
-					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY,
-					   &thaw_gh);
+					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY |
+					   GL_EXACT, &thaw_gh);
 		if (error)
 			goto fail_gunlock_ji;
 

commit c953a735c7d4d0d1b092b5c594258a07a84149db
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Thu Mar 26 12:22:05 2020 -0500

    gfs2: change from write to read lock for sd_log_flush_lock in journal replay
    
    Function gfs2_recover_func grabs the sd_log_flush_lock rw_semaphore in
    write mode. This is unnecessary because we only need to prevent log flush
    from using sd_log_bio bio while it does. Therefore, a read lock will be
    enough. This is a small step in cleaning up log flush.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 34dfdb211439..96c345f49273 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -401,7 +401,7 @@ void gfs2_recover_func(struct work_struct *work)
 		/* We take the sd_log_flush_lock here primarily to prevent log
 		 * flushes and simultaneous journal replays from stomping on
 		 * each other wrt sd_log_bio. */
-		down_write(&sdp->sd_log_flush_lock);
+		down_read(&sdp->sd_log_flush_lock);
 		for (pass = 0; pass < 2; pass++) {
 			lops_before_scan(jd, &head, pass);
 			error = foreach_descriptor(jd, head.lh_tail,
@@ -412,7 +412,7 @@ void gfs2_recover_func(struct work_struct *work)
 		}
 
 		clean_journal(jd, &head);
-		up_write(&sdp->sd_log_flush_lock);
+		up_read(&sdp->sd_log_flush_lock);
 
 		gfs2_glock_dq_uninit(&thaw_gh);
 		t_rep = ktime_get();

commit 969183bc68bc27d637d6d29e81d71cf854d0ca61
Author: Andreas Gruenbacher <agruenba@redhat.com>
Date:   Mon Feb 3 19:22:45 2020 +0100

    gfs2: Switch to list_{first,last}_entry
    
    Replace open-coded versions of list_first_entry and list_last_entry with those
    functions.
    
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 21fc44b31863..34dfdb211439 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -111,7 +111,7 @@ void gfs2_revoke_clean(struct gfs2_jdesc *jd)
 	struct gfs2_revoke_replay *rr;
 
 	while (!list_empty(head)) {
-		rr = list_entry(head->next, struct gfs2_revoke_replay, rr_list);
+		rr = list_first_entry(head, struct gfs2_revoke_replay, rr_list);
 		list_del(&rr->rr_list);
 		kfree(rr);
 	}

commit c9ebc4b737999ab1f3264c42431f7be80ac2efbf
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Mon Feb 17 14:15:05 2020 -0600

    gfs2: allow journal replay to hold sd_log_flush_lock
    
    Before this patch, journal replays could stomp on log flushes
    and each other because both log flushes and journal replays used
    the same sd_log_bio. Function gfs2_log_flush prevents other log
    flushes from interfering by taking the sd_log_flush_lock rwsem
    during the flush. However, it does not protect against journal
    replays. This patch allows the journal replay to take the same
    sd_log_flush_lock rwsem so use of the sd_log_bio is not stomped.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 8cc26bef4e64..21fc44b31863 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -398,6 +398,10 @@ void gfs2_recover_func(struct work_struct *work)
 		fs_info(sdp, "jid=%u: Replaying journal...0x%x to 0x%x\n",
 			jd->jd_jid, head.lh_tail, head.lh_blkno);
 
+		/* We take the sd_log_flush_lock here primarily to prevent log
+		 * flushes and simultaneous journal replays from stomping on
+		 * each other wrt sd_log_bio. */
+		down_write(&sdp->sd_log_flush_lock);
 		for (pass = 0; pass < 2; pass++) {
 			lops_before_scan(jd, &head, pass);
 			error = foreach_descriptor(jd, head.lh_tail,
@@ -408,6 +412,7 @@ void gfs2_recover_func(struct work_struct *work)
 		}
 
 		clean_journal(jd, &head);
+		up_write(&sdp->sd_log_flush_lock);
 
 		gfs2_glock_dq_uninit(&thaw_gh);
 		t_rep = ktime_get();

commit 03678a99d13831b938fdc9d81b5a7608fc6ef416
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Tue Feb 12 13:58:40 2019 -0700

    gfs2: Ignore dlm recovery requests if gfs2 is withdrawn
    
    When a node fails, user space informs dlm of the node failure,
    and dlm instructs gfs2 on the surviving nodes to perform journal
    recovery. It does this by calling various callback functions in
    lock_dlm.c. To mark its progress, it keeps generation numbers
    and recover bits in a dlm "control" lock lvb, which is seen by
    all nodes to determine which journals need to be replayed.
    
    The gfs2 on all nodes get the same recovery requests from dlm,
    so they all try to do the recovery, but only one will be
    granted the exclusive lock on the journal. The others fail
    with a "Busy" message on their "try lock."
    
    However, when a node is withdrawn, it cannot safely do any
    recovery or replay any journals. To make matters worse,
    gfs2 might withdraw as a result of attempting recovery. For
    example, this might happen if the device goes offline, or if
    an hba fails. But in today's gfs2 code, it doesn't check for
    being withdrawn at any step in the recovery process. What's
    worse is that these callbacks from dlm have no return code,
    so there is no way to indicate failure back to dlm. We can
    send a "Recovery failed" uevent eventually, but that tells
    user space what happened, not dlm's kernel code.
    
    Before this patch, lock_dlm would perform its recovery steps but
    ignore the result, and eventually it would still update its
    generation number in the lvb, despite the fact that it may have
    withdrawn or encountered an error. The other nodes would then
    see the newer generation number in the lvb and conclude that
    they don't need to do recovery because the generation number
    is newer than the last one they saw. They think a different
    node has already recovered the journal.
    
    This patch adds checks to several of the callbacks used by dlm
    in its recovery state machine so that the functions are ignored
    and skipped if an io error has occurred or if the file system
    is withdrawn. That prevents the lvb bits from being updated, and
    therefore dlm and user space still see the need for recovery to
    take place.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Reviewed-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 85f830e56945..8cc26bef4e64 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -305,6 +305,11 @@ void gfs2_recover_func(struct work_struct *work)
 	int error = 0;
 	int jlocked = 0;
 
+	if (gfs2_withdrawn(sdp)) {
+		fs_err(sdp, "jid=%u: Recovery not attempted due to withdraw.\n",
+		       jd->jd_jid);
+		goto fail;
+	}
 	t_start = ktime_get();
 	if (sdp->sd_args.ar_spectator)
 		goto fail;

commit 19ebc050e48c3ae05b9c854001c0893127d118d6
Author: Andreas Gruenbacher <agruenba@redhat.com>
Date:   Wed Aug 28 22:21:34 2019 +0200

    gfs2: Remove active journal side effect from gfs2_write_log_header
    
    Function gfs2_write_log_header can be used to write a log header into any of
    the journals of a filesystem.  When used on the node's own journal,
    gfs2_write_log_header advances the current position in the log
    (sdp->sd_log_flush_head) as a side effect, through function gfs2_log_bmap.
    
    This is confusing, and it also means that we can't use gfs2_log_bmap for other
    journals even if they have an extent map.  So clean this mess up by not
    advancing sdp->sd_log_flush_head in gfs2_write_log_header or gfs2_log_bmap
    anymore and making that a responsibility of the callers instead.
    
    This is related to commit 7c70b896951c ("gfs2: clean_journal improperly set
    sd_log_flush_head").
    
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index f4aa8551277b..85f830e56945 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -263,11 +263,13 @@ static void clean_journal(struct gfs2_jdesc *jd,
 	u32 lblock = head->lh_blkno;
 
 	gfs2_replay_incr_blk(jd, &lblock);
-	if (jd->jd_jid == sdp->sd_lockstruct.ls_jid)
-		sdp->sd_log_flush_head = lblock;
 	gfs2_write_log_header(sdp, jd, head->lh_sequence + 1, 0, lblock,
 			      GFS2_LOG_HEAD_UNMOUNT | GFS2_LOG_HEAD_RECOVERY,
 			      REQ_PREFLUSH | REQ_FUA | REQ_META | REQ_SYNC);
+	if (jd->jd_jid == sdp->sd_lockstruct.ls_jid) {
+		sdp->sd_log_flush_head = lblock;
+		gfs2_log_incr_head(sdp);
+	}
 }
 
 

commit 098b9c1453629be7e637498f3ca8bb3c592eb394
Author: Aliasgar Surti <aliasgar.surti500@gmail.com>
Date:   Fri Oct 4 10:55:29 2019 -0500

    gfs2: removed unnecessary semicolon
    
    There is use of unnecessary semicolon after switch case.
    Removed the semicolon.
    
    Signed-off-by: Aliasgar Surti <aliasgar.surti500@gmail.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index c529f8749a89..f4aa8551277b 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -326,7 +326,7 @@ void gfs2_recover_func(struct work_struct *work)
 
 		default:
 			goto fail;
-		};
+		}
 
 		error = gfs2_glock_nq_init(ip->i_gl, LM_ST_SHARED,
 					   LM_FLAG_NOEXP | GL_NOCACHE, &ji_gh);

commit 49eb776ed9d92a91d3b1a24d83755e051bce96ff
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Feb 27 13:32:36 2019 -0700

    gfs2: log which portion of the journal is replayed
    
    When a journal is replayed, gfs2 logs a message similar to:
    
    jid=X: Replaying journal...
    
    This patch adds the tail and block number so that the range of the
    replayed block is also printed. These values will match the values
    shown if the journal is dumped with gfs2_edit -p journalX. The
    resulting output looks something like this:
    
    jid=1: Replaying journal...0x28b7 to 0x2beb
    
    This will allow us to better debug file system corruption problems.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 2299a3fa1911..c529f8749a89 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -388,7 +388,8 @@ void gfs2_recover_func(struct work_struct *work)
 		}
 
 		t_tlck = ktime_get();
-		fs_info(sdp, "jid=%u: Replaying journal...\n", jd->jd_jid);
+		fs_info(sdp, "jid=%u: Replaying journal...0x%x to 0x%x\n",
+			jd->jd_jid, head.lh_tail, head.lh_blkno);
 
 		for (pass = 0; pass < 2; pass++) {
 			lops_before_scan(jd, &head, pass);

commit 7336d0e654f7acc0ecee33a8ae68c4fd1c1c44b5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri May 31 01:09:56 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 398
    
    Based on 1 normalized pattern(s):
    
      this copyrighted material is made available to anyone wishing to use
      modify copy or redistribute it subject to the terms and conditions
      of the gnu general public license version 2
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 44 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190531081038.653000175@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 389b3ef77e20..2299a3fa1911 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -1,10 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  * Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
- *
- * This copyrighted material is made available to anyone wishing to use,
- * modify, copy, or redistribute it subject to the terms and conditions
- * of the GNU General Public License version 2.
  */
 
 #include <linux/module.h>

commit f4686c26ecc34e8e458b8235f0af5198c9b13bfd
Author: Abhi Das <adas@redhat.com>
Date:   Thu May 2 14:17:40 2019 -0500

    gfs2: read journal in large chunks
    
    Use bios to read in the journal into the address space of the journal inode
    (jd_inode), sequentially and in large chunks.  This is faster for locating the
    journal head that the previous binary search approach.  When performing
    recovery, we keep the journal in the address space until recovery is done,
    which further speeds up things.
    
    Signed-off-by: Abhi Das <adas@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index fa575d1676b9..389b3ef77e20 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -181,129 +181,6 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 	return error;
 }
 
-/**
- * find_good_lh - find a good log header
- * @jd: the journal
- * @blk: the segment to start searching from
- * @lh: the log header to fill in
- * @forward: if true search forward in the log, else search backward
- *
- * Call get_log_header() to get a log header for a segment, but if the
- * segment is bad, either scan forward or backward until we find a good one.
- *
- * Returns: errno
- */
-
-static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
-			struct gfs2_log_header_host *head)
-{
-	unsigned int orig_blk = *blk;
-	int error;
-
-	for (;;) {
-		error = get_log_header(jd, *blk, head);
-		if (error <= 0)
-			return error;
-
-		if (++*blk == jd->jd_blocks)
-			*blk = 0;
-
-		if (*blk == orig_blk) {
-			gfs2_consist_inode(GFS2_I(jd->jd_inode));
-			return -EIO;
-		}
-	}
-}
-
-/**
- * jhead_scan - make sure we've found the head of the log
- * @jd: the journal
- * @head: this is filled in with the log descriptor of the head
- *
- * At this point, seg and lh should be either the head of the log or just
- * before.  Scan forward until we find the head.
- *
- * Returns: errno
- */
-
-static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
-{
-	unsigned int blk = head->lh_blkno;
-	struct gfs2_log_header_host lh;
-	int error;
-
-	for (;;) {
-		if (++blk == jd->jd_blocks)
-			blk = 0;
-
-		error = get_log_header(jd, blk, &lh);
-		if (error < 0)
-			return error;
-		if (error == 1)
-			continue;
-
-		if (lh.lh_sequence == head->lh_sequence) {
-			gfs2_consist_inode(GFS2_I(jd->jd_inode));
-			return -EIO;
-		}
-		if (lh.lh_sequence < head->lh_sequence)
-			break;
-
-		*head = lh;
-	}
-
-	return 0;
-}
-
-/**
- * gfs2_find_jhead - find the head of a log
- * @jd: the journal
- * @head: the log descriptor for the head of the log is returned here
- *
- * Do a binary search of a journal and find the valid log entry with the
- * highest sequence number.  (i.e. the log head)
- *
- * Returns: errno
- */
-
-int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
-{
-	struct gfs2_log_header_host lh_1, lh_m;
-	u32 blk_1, blk_2, blk_m;
-	int error;
-
-	blk_1 = 0;
-	blk_2 = jd->jd_blocks - 1;
-
-	for (;;) {
-		blk_m = (blk_1 + blk_2) / 2;
-
-		error = find_good_lh(jd, &blk_1, &lh_1);
-		if (error)
-			return error;
-
-		error = find_good_lh(jd, &blk_m, &lh_m);
-		if (error)
-			return error;
-
-		if (blk_1 == blk_m || blk_m == blk_2)
-			break;
-
-		if (lh_1.lh_sequence <= lh_m.lh_sequence)
-			blk_1 = blk_m;
-		else
-			blk_2 = blk_m;
-	}
-
-	error = jhead_scan(jd, &lh_1);
-	if (error)
-		return error;
-
-	*head = lh_1;
-
-	return error;
-}
-
 /**
  * foreach_descriptor - go through the active part of the log
  * @jd: the journal
@@ -469,7 +346,7 @@ void gfs2_recover_func(struct work_struct *work)
 	if (error)
 		goto fail_gunlock_ji;
 
-	error = gfs2_find_jhead(jd, &head);
+	error = gfs2_find_jhead(jd, &head, true);
 	if (error)
 		goto fail_gunlock_ji;
 	t_jhd = ktime_get();

commit 7c70b896951c84d63e6d71b82668f9c8b8bbd440
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Mon Mar 25 09:34:19 2019 -0600

    gfs2: clean_journal improperly set sd_log_flush_head
    
    This patch fixes regressions in 588bff95c94efc05f9e1a0b19015c9408ed7c0ef.
    Due to that patch, function clean_journal was setting the value of
    sd_log_flush_head, but that's only valid if it is replaying the node's
    own journal. If it's replaying another node's journal, that's completely
    wrong and will lead to multiple problems. This patch tries to clean up
    the mess by passing the value of the logical journal block number into
    gfs2_write_log_header so the function can treat non-owned journals
    generically. For the local journal, the journal extent map is used for
    best performance. For other nodes from other journals, new function
    gfs2_lblk_to_dblk is called to figure it out using gfs2_iomap_get.
    
    This patch also tries to establish more consistency when passing journal
    block parameters by changing several unsigned int types to a consistent
    u32.
    
    Fixes: 588bff95c94e ("GFS2: Reduce code redundancy writing log headers")
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 2dac43065382..fa575d1676b9 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -316,7 +316,7 @@ int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
  * Returns: errno
  */
 
-static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
+static int foreach_descriptor(struct gfs2_jdesc *jd, u32 start,
 			      unsigned int end, int pass)
 {
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
@@ -386,10 +386,12 @@ static void clean_journal(struct gfs2_jdesc *jd,
 			  struct gfs2_log_header_host *head)
 {
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
+	u32 lblock = head->lh_blkno;
 
-	sdp->sd_log_flush_head = head->lh_blkno;
-	gfs2_replay_incr_blk(jd, &sdp->sd_log_flush_head);
-	gfs2_write_log_header(sdp, jd, head->lh_sequence + 1, 0,
+	gfs2_replay_incr_blk(jd, &lblock);
+	if (jd->jd_jid == sdp->sd_lockstruct.ls_jid)
+		sdp->sd_log_flush_head = lblock;
+	gfs2_write_log_header(sdp, jd, head->lh_sequence + 1, 0, lblock,
 			      GFS2_LOG_HEAD_UNMOUNT | GFS2_LOG_HEAD_RECOVERY,
 			      REQ_PREFLUSH | REQ_FUA | REQ_META | REQ_SYNC);
 }

commit 23e93c9b2cde73f9912d0d8534adbddd3dcc48f4
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Feb 13 15:12:17 2019 -0500

    Revert "gfs2: read journal in large chunks to locate the head"
    
    This reverts commit 2a5f14f279f59143139bcd1606903f2f80a34241.
    
    This patch causes xfstests generic/311 to fail. Reverting this for
    now until we have a proper fix.
    
    Signed-off-by: Abhi Das <adas@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 7389e445a7a7..2dac43065382 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -181,6 +181,129 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 	return error;
 }
 
+/**
+ * find_good_lh - find a good log header
+ * @jd: the journal
+ * @blk: the segment to start searching from
+ * @lh: the log header to fill in
+ * @forward: if true search forward in the log, else search backward
+ *
+ * Call get_log_header() to get a log header for a segment, but if the
+ * segment is bad, either scan forward or backward until we find a good one.
+ *
+ * Returns: errno
+ */
+
+static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
+			struct gfs2_log_header_host *head)
+{
+	unsigned int orig_blk = *blk;
+	int error;
+
+	for (;;) {
+		error = get_log_header(jd, *blk, head);
+		if (error <= 0)
+			return error;
+
+		if (++*blk == jd->jd_blocks)
+			*blk = 0;
+
+		if (*blk == orig_blk) {
+			gfs2_consist_inode(GFS2_I(jd->jd_inode));
+			return -EIO;
+		}
+	}
+}
+
+/**
+ * jhead_scan - make sure we've found the head of the log
+ * @jd: the journal
+ * @head: this is filled in with the log descriptor of the head
+ *
+ * At this point, seg and lh should be either the head of the log or just
+ * before.  Scan forward until we find the head.
+ *
+ * Returns: errno
+ */
+
+static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
+{
+	unsigned int blk = head->lh_blkno;
+	struct gfs2_log_header_host lh;
+	int error;
+
+	for (;;) {
+		if (++blk == jd->jd_blocks)
+			blk = 0;
+
+		error = get_log_header(jd, blk, &lh);
+		if (error < 0)
+			return error;
+		if (error == 1)
+			continue;
+
+		if (lh.lh_sequence == head->lh_sequence) {
+			gfs2_consist_inode(GFS2_I(jd->jd_inode));
+			return -EIO;
+		}
+		if (lh.lh_sequence < head->lh_sequence)
+			break;
+
+		*head = lh;
+	}
+
+	return 0;
+}
+
+/**
+ * gfs2_find_jhead - find the head of a log
+ * @jd: the journal
+ * @head: the log descriptor for the head of the log is returned here
+ *
+ * Do a binary search of a journal and find the valid log entry with the
+ * highest sequence number.  (i.e. the log head)
+ *
+ * Returns: errno
+ */
+
+int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
+{
+	struct gfs2_log_header_host lh_1, lh_m;
+	u32 blk_1, blk_2, blk_m;
+	int error;
+
+	blk_1 = 0;
+	blk_2 = jd->jd_blocks - 1;
+
+	for (;;) {
+		blk_m = (blk_1 + blk_2) / 2;
+
+		error = find_good_lh(jd, &blk_1, &lh_1);
+		if (error)
+			return error;
+
+		error = find_good_lh(jd, &blk_m, &lh_m);
+		if (error)
+			return error;
+
+		if (blk_1 == blk_m || blk_m == blk_2)
+			break;
+
+		if (lh_1.lh_sequence <= lh_m.lh_sequence)
+			blk_1 = blk_m;
+		else
+			blk_2 = blk_m;
+	}
+
+	error = jhead_scan(jd, &lh_1);
+	if (error)
+		return error;
+
+	*head = lh_1;
+
+	return error;
+}
+
 /**
  * foreach_descriptor - go through the active part of the log
  * @jd: the journal

commit 2a5f14f279f59143139bcd1606903f2f80a34241
Author: Abhi Das <adas@redhat.com>
Date:   Fri Nov 9 09:57:20 2018 -0600

    gfs2: read journal in large chunks to locate the head
    
    Use bio(s) to read in the journal sequentially in large chunks and
    locate the head of the journal.
    
    This version addresses the issues Christoph pointed out w.r.t error handling
    and using deprecated API.
    
    Signed-off-by: Abhi Das <adas@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Cc: Christoph Hellwig <hch@infradead.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 2dac43065382..7389e445a7a7 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -181,129 +181,6 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 	return error;
 }
 
-/**
- * find_good_lh - find a good log header
- * @jd: the journal
- * @blk: the segment to start searching from
- * @lh: the log header to fill in
- * @forward: if true search forward in the log, else search backward
- *
- * Call get_log_header() to get a log header for a segment, but if the
- * segment is bad, either scan forward or backward until we find a good one.
- *
- * Returns: errno
- */
-
-static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
-			struct gfs2_log_header_host *head)
-{
-	unsigned int orig_blk = *blk;
-	int error;
-
-	for (;;) {
-		error = get_log_header(jd, *blk, head);
-		if (error <= 0)
-			return error;
-
-		if (++*blk == jd->jd_blocks)
-			*blk = 0;
-
-		if (*blk == orig_blk) {
-			gfs2_consist_inode(GFS2_I(jd->jd_inode));
-			return -EIO;
-		}
-	}
-}
-
-/**
- * jhead_scan - make sure we've found the head of the log
- * @jd: the journal
- * @head: this is filled in with the log descriptor of the head
- *
- * At this point, seg and lh should be either the head of the log or just
- * before.  Scan forward until we find the head.
- *
- * Returns: errno
- */
-
-static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
-{
-	unsigned int blk = head->lh_blkno;
-	struct gfs2_log_header_host lh;
-	int error;
-
-	for (;;) {
-		if (++blk == jd->jd_blocks)
-			blk = 0;
-
-		error = get_log_header(jd, blk, &lh);
-		if (error < 0)
-			return error;
-		if (error == 1)
-			continue;
-
-		if (lh.lh_sequence == head->lh_sequence) {
-			gfs2_consist_inode(GFS2_I(jd->jd_inode));
-			return -EIO;
-		}
-		if (lh.lh_sequence < head->lh_sequence)
-			break;
-
-		*head = lh;
-	}
-
-	return 0;
-}
-
-/**
- * gfs2_find_jhead - find the head of a log
- * @jd: the journal
- * @head: the log descriptor for the head of the log is returned here
- *
- * Do a binary search of a journal and find the valid log entry with the
- * highest sequence number.  (i.e. the log head)
- *
- * Returns: errno
- */
-
-int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
-{
-	struct gfs2_log_header_host lh_1, lh_m;
-	u32 blk_1, blk_2, blk_m;
-	int error;
-
-	blk_1 = 0;
-	blk_2 = jd->jd_blocks - 1;
-
-	for (;;) {
-		blk_m = (blk_1 + blk_2) / 2;
-
-		error = find_good_lh(jd, &blk_1, &lh_1);
-		if (error)
-			return error;
-
-		error = find_good_lh(jd, &blk_m, &lh_m);
-		if (error)
-			return error;
-
-		if (blk_1 == blk_m || blk_m == blk_2)
-			break;
-
-		if (lh_1.lh_sequence <= lh_m.lh_sequence)
-			blk_1 = blk_m;
-		else
-			blk_2 = blk_m;
-	}
-
-	error = jhead_scan(jd, &lh_1);
-	if (error)
-		return error;
-
-	*head = lh_1;
-
-	return error;
-}
-
 /**
  * foreach_descriptor - go through the active part of the log
  * @jd: the journal

commit 40e0e61e366bed56b71edb3b970245165090ec9a
Author: Abhi Das <adas@redhat.com>
Date:   Fri Nov 9 09:54:18 2018 -0600

    gfs2: add a helper function to get_log_header that can be used elsewhere
    
    Move and re-order the error checks and hash/crc computations into another
    function __get_log_header() so it can be used in scenarios where buffer_heads
    are not being used for the log header.
    
    Signed-off-by: Abhi Das <adas@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index b0717a074543..2dac43065382 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -120,6 +120,35 @@ void gfs2_revoke_clean(struct gfs2_jdesc *jd)
 	}
 }
 
+int __get_log_header(struct gfs2_sbd *sdp, const struct gfs2_log_header *lh,
+		     unsigned int blkno, struct gfs2_log_header_host *head)
+{
+	u32 hash, crc;
+
+	if (lh->lh_header.mh_magic != cpu_to_be32(GFS2_MAGIC) ||
+	    lh->lh_header.mh_type != cpu_to_be32(GFS2_METATYPE_LH) ||
+	    (blkno && be32_to_cpu(lh->lh_blkno) != blkno))
+		return 1;
+
+	hash = crc32(~0, lh, LH_V1_SIZE - 4);
+	hash = ~crc32_le_shift(hash, 4); /* assume lh_hash is zero */
+
+	if (be32_to_cpu(lh->lh_hash) != hash)
+		return 1;
+
+	crc = crc32c(~0, (void *)lh + LH_V1_SIZE + 4,
+		     sdp->sd_sb.sb_bsize - LH_V1_SIZE - 4);
+
+	if ((lh->lh_crc != 0 && be32_to_cpu(lh->lh_crc) != crc))
+		return 1;
+
+	head->lh_sequence = be64_to_cpu(lh->lh_sequence);
+	head->lh_flags = be32_to_cpu(lh->lh_flags);
+	head->lh_tail = be32_to_cpu(lh->lh_tail);
+	head->lh_blkno = be32_to_cpu(lh->lh_blkno);
+
+	return 0;
+}
 /**
  * get_log_header - read the log header for a given segment
  * @jd: the journal
@@ -137,36 +166,18 @@ void gfs2_revoke_clean(struct gfs2_jdesc *jd)
 static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 			  struct gfs2_log_header_host *head)
 {
-	struct gfs2_log_header *lh;
+	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	struct buffer_head *bh;
-	u32 hash, crc;
 	int error;
 
 	error = gfs2_replay_read_block(jd, blk, &bh);
 	if (error)
 		return error;
-	lh = (void *)bh->b_data;
-
-	hash = crc32(~0, lh, LH_V1_SIZE - 4);
-	hash = ~crc32_le_shift(hash, 4);  /* assume lh_hash is zero */
-
-	crc = crc32c(~0, (void *)lh + LH_V1_SIZE + 4,
-		     bh->b_size - LH_V1_SIZE - 4);
-
-	error = lh->lh_header.mh_magic != cpu_to_be32(GFS2_MAGIC) ||
-		lh->lh_header.mh_type != cpu_to_be32(GFS2_METATYPE_LH) ||
-		be32_to_cpu(lh->lh_blkno) != blk ||
-		be32_to_cpu(lh->lh_hash) != hash ||
-		(lh->lh_crc != 0 && be32_to_cpu(lh->lh_crc) != crc);
 
+	error = __get_log_header(sdp, (const struct gfs2_log_header *)bh->b_data,
+				 blk, head);
 	brelse(bh);
 
-	if (!error) {
-		head->lh_sequence = be64_to_cpu(lh->lh_sequence);
-		head->lh_flags = be32_to_cpu(lh->lh_flags);
-		head->lh_tail = be32_to_cpu(lh->lh_tail);
-		head->lh_blkno = be32_to_cpu(lh->lh_blkno);
-	}
 	return error;
 }
 

commit 98583b3e87303e5941c30d4cf0c117cbfaa89116
Author: Abhi Das <adas@redhat.com>
Date:   Fri Nov 9 09:35:14 2018 -0600

    gfs2: add more timing info to journal recovery process
    
    Tells you how many milliseconds map_journal_extents and find_jhead
    take.
    
    Signed-off-by: Abhi Das <adas@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 0f501f938d1c..b0717a074543 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -460,6 +460,8 @@ void gfs2_recover_func(struct work_struct *work)
 	if (error)
 		goto fail_gunlock_ji;
 	t_jhd = ktime_get();
+	fs_info(sdp, "jid=%u: Journal head lookup took %lldms\n", jd->jd_jid,
+		ktime_ms_delta(t_jhd, t_jlck));
 
 	if (!(head.lh_flags & GFS2_LOG_HEAD_UNMOUNT)) {
 		fs_info(sdp, "jid=%u: Acquiring the transaction lock...\n",

commit 4a7727725dc7d73769c5ab24c566df454093285f
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Thu Jul 5 14:40:46 2018 -0500

    GFS2: Fix recovery issues for spectators
    
    This patch fixes a couple problems dealing with spectators who
    remain with gfs2 mounts after the last non-spectator node fails.
    
    Before this patch, spectator mounts would try to acquire the dlm's
    mounted lock EX as part of its normal recovery sequence.
    The mounted lock is only used to determine whether the node is
    the first mounter, the first node to mount the file system, for
    the purposes of file system recovery and journal replay.
    
    It's not necessary for spectators: they should never do journal
    recovery. If they acquire the lock it will prevent another "real"
    first-mounter from acquiring the lock in EX mode, which means it
    also cannot do journal recovery because it doesn't think it's the
    first node to mount the file system.
    
    This patch checks if the mounter is a spectator, and if so, avoids
    grabbing the mounted lock. This allows a secondary mounter who is
    really the first non-spectator mounter, to do journal recovery:
    since the spectator doesn't acquire the lock, it can grab it in
    EX mode, and therefore consider itself to be the first mounter
    both as a "real" first mount, and as a first-real-after-spectator.
    
    Note that the control lock still needs to be taken in PR mode
    in order to fetch the lvb value so it has the current status of
    all journal's recovery. This is used as it is today by a first
    mounter to replay the journals. For spectators, it's merely
    used to fetch the status bits. All recovery is bypassed and the
    node waits until recovery is completed by a non-spectator node.
    
    I also improved the cryptic message given by control_mount when
    a spectator is waiting for a non-spectator to perform recovery.
    
    It also fixes a problem in gfs2_recover_set whereby spectators
    were never queueing recovery work for their own journal.
    They cannot do recovery themselves, but they still need to queue
    the work so they can check the recovery bits and clear the
    DFL_BLOCK_LOCKS bit once the recovery happens on another node.
    
    When the work queue runs on a spectator, it bypasses most of the
    work so it won't print a bunch of annoying messages. All it will
    print is a bunch of messages that look like this until recovery
    completes on the non-spectator node:
    
    GFS2: fsid=mycluster:scratch.s: recover generation 3 jid 0
    GFS2: fsid=mycluster:scratch.s: recover jid 0 result busy
    
    These continue every 1.5 seconds until the recovery is done by
    the non-spectator, at which time it says:
    
    GFS2: fsid=mycluster:scratch.s: recover generation 4 done
    
    Then it proceeds with its mount.
    
    If the file system is mounted in spectator node and the last
    remaining non-spectator is fenced, any IO to the file system is
    blocked by dlm and the spectator waits until recovery is
    performed by a non-spectator.
    
    If a spectator tries to mount the file system before any
    non-spectators, it blocks and repeatedly gives this kernel
    message:
    
    GFS2: fsid=mycluster:scratch: Recovery is required. Waiting for a non-spectator to mount.
    GFS2: fsid=mycluster:scratch: Recovery is required. Waiting for a non-spectator to mount.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index d8b622c375ab..0f501f938d1c 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -413,12 +413,13 @@ void gfs2_recover_func(struct work_struct *work)
 	ktime_t t_start, t_jlck, t_jhd, t_tlck, t_rep;
 	int ro = 0;
 	unsigned int pass;
-	int error;
+	int error = 0;
 	int jlocked = 0;
 
 	t_start = ktime_get();
-	if (sdp->sd_args.ar_spectator ||
-	    (jd->jd_jid != sdp->sd_lockstruct.ls_jid)) {
+	if (sdp->sd_args.ar_spectator)
+		goto fail;
+	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid) {
 		fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n",
 			jd->jd_jid);
 		jlocked = 1;

commit 5e86d9d122d0d6fae00d9dff41c22d6f4d09f566
Author: Abhi Das <adas@redhat.com>
Date:   Thu Mar 29 10:41:27 2018 -0700

    gfs2: time journal recovery steps accurately
    
    This patch spits out the time taken by the various steps in the
    journal recover process. Previously, the journal recovery time
    didn't account for finding the journal head in the log which takes
    up a significant portion of time.
    
    Signed-off-by: Abhi Das <adas@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index b6b258998bcd..d8b622c375ab 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -15,6 +15,7 @@
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
 #include <linux/crc32c.h>
+#include <linux/ktime.h>
 
 #include "gfs2.h"
 #include "incore.h"
@@ -409,12 +410,13 @@ void gfs2_recover_func(struct work_struct *work)
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	struct gfs2_log_header_host head;
 	struct gfs2_holder j_gh, ji_gh, thaw_gh;
-	unsigned long t;
+	ktime_t t_start, t_jlck, t_jhd, t_tlck, t_rep;
 	int ro = 0;
 	unsigned int pass;
 	int error;
 	int jlocked = 0;
 
+	t_start = ktime_get();
 	if (sdp->sd_args.ar_spectator ||
 	    (jd->jd_jid != sdp->sd_lockstruct.ls_jid)) {
 		fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n",
@@ -446,6 +448,7 @@ void gfs2_recover_func(struct work_struct *work)
 		fs_info(sdp, "jid=%u, already locked for use\n", jd->jd_jid);
 	}
 
+	t_jlck = ktime_get();
 	fs_info(sdp, "jid=%u: Looking at journal...\n", jd->jd_jid);
 
 	error = gfs2_jdesc_check(jd);
@@ -455,13 +458,12 @@ void gfs2_recover_func(struct work_struct *work)
 	error = gfs2_find_jhead(jd, &head);
 	if (error)
 		goto fail_gunlock_ji;
+	t_jhd = ktime_get();
 
 	if (!(head.lh_flags & GFS2_LOG_HEAD_UNMOUNT)) {
 		fs_info(sdp, "jid=%u: Acquiring the transaction lock...\n",
 			jd->jd_jid);
 
-		t = jiffies;
-
 		/* Acquire a shared hold on the freeze lock */
 
 		error = gfs2_glock_nq_init(sdp->sd_freeze_gl, LM_ST_SHARED,
@@ -495,6 +497,7 @@ void gfs2_recover_func(struct work_struct *work)
 			goto fail_gunlock_thaw;
 		}
 
+		t_tlck = ktime_get();
 		fs_info(sdp, "jid=%u: Replaying journal...\n", jd->jd_jid);
 
 		for (pass = 0; pass < 2; pass++) {
@@ -509,9 +512,14 @@ void gfs2_recover_func(struct work_struct *work)
 		clean_journal(jd, &head);
 
 		gfs2_glock_dq_uninit(&thaw_gh);
-		t = DIV_ROUND_UP(jiffies - t, HZ);
-		fs_info(sdp, "jid=%u: Journal replayed in %lus\n",
-			jd->jd_jid, t);
+		t_rep = ktime_get();
+		fs_info(sdp, "jid=%u: Journal replayed in %lldms [jlck:%lldms, "
+			"jhead:%lldms, tlck:%lldms, replay:%lldms]\n",
+			jd->jd_jid, ktime_ms_delta(t_rep, t_start),
+			ktime_ms_delta(t_jlck, t_start),
+			ktime_ms_delta(t_jhd, t_jlck),
+			ktime_ms_delta(t_tlck, t_jhd),
+			ktime_ms_delta(t_rep, t_tlck));
 	}
 
 	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_SUCCESS);

commit c1696fb85d33194cf65c7ebfc82a75696299c3a3
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Jan 17 00:01:33 2018 +0100

    GFS2: Introduce new gfs2_log_header_v2
    
    This patch adds a new structure called gfs2_log_header_v2 which is used
    to store expanded fields into previously unused areas of the log headers
    (i.e., this change is backwards compatible).  Some of these are used for
    debug purposes so we can backtrack when problems occur.  Others are
    reserved for future expansion.
    
    This patch is based on a prototype from Steve Whitehouse.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 975f32166dfe..b6b258998bcd 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -14,6 +14,7 @@
 #include <linux/buffer_head.h>
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
+#include <linux/crc32c.h>
 
 #include "gfs2.h"
 #include "incore.h"
@@ -137,7 +138,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 {
 	struct gfs2_log_header *lh;
 	struct buffer_head *bh;
-	u32 hash;
+	u32 hash, crc;
 	int error;
 
 	error = gfs2_replay_read_block(jd, blk, &bh);
@@ -145,13 +146,17 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 		return error;
 	lh = (void *)bh->b_data;
 
-	hash = crc32(~0, lh, sizeof(*lh) - 4);
+	hash = crc32(~0, lh, LH_V1_SIZE - 4);
 	hash = ~crc32_le_shift(hash, 4);  /* assume lh_hash is zero */
 
+	crc = crc32c(~0, (void *)lh + LH_V1_SIZE + 4,
+		     bh->b_size - LH_V1_SIZE - 4);
+
 	error = lh->lh_header.mh_magic != cpu_to_be32(GFS2_MAGIC) ||
 		lh->lh_header.mh_type != cpu_to_be32(GFS2_METATYPE_LH) ||
 		be32_to_cpu(lh->lh_blkno) != blk ||
-		be32_to_cpu(lh->lh_hash) != hash;
+		be32_to_cpu(lh->lh_hash) != hash ||
+		(lh->lh_crc != 0 && be32_to_cpu(lh->lh_crc) != crc);
 
 	brelse(bh);
 
@@ -372,9 +377,9 @@ static void clean_journal(struct gfs2_jdesc *jd,
 
 	sdp->sd_log_flush_head = head->lh_blkno;
 	gfs2_replay_incr_blk(jd, &sdp->sd_log_flush_head);
-	gfs2_write_log_header(sdp, head->lh_sequence + 1, 0,
-			      GFS2_LOG_HEAD_UNMOUNT, REQ_PREFLUSH |
-			      REQ_FUA | REQ_META | REQ_SYNC);
+	gfs2_write_log_header(sdp, jd, head->lh_sequence + 1, 0,
+			      GFS2_LOG_HEAD_UNMOUNT | GFS2_LOG_HEAD_RECOVERY,
+			      REQ_PREFLUSH | REQ_FUA | REQ_META | REQ_SYNC);
 }
 
 

commit 0ff5916ad4eb857e03e7586665d1c022ef3277f6
Author: Andreas Gruenbacher <agruenba@redhat.com>
Date:   Tue Jan 16 23:07:57 2018 +0100

    gfs2: Get rid of gfs2_log_header_in
    
    Get rid of gfs2_log_header_in by integrating it into get_log_header.
    Clean up the crc32 computations and use the same functions for encoding
    and decoding to make things less confusing.  Eliminate lh_hash from
    gfs2_log_header_host which is completely useless.
    
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 5d3431219425..975f32166dfe 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -118,22 +118,6 @@ void gfs2_revoke_clean(struct gfs2_jdesc *jd)
 	}
 }
 
-static int gfs2_log_header_in(struct gfs2_log_header_host *lh, const void *buf)
-{
-	const struct gfs2_log_header *str = buf;
-
-	if (str->lh_header.mh_magic != cpu_to_be32(GFS2_MAGIC) ||
-	    str->lh_header.mh_type != cpu_to_be32(GFS2_METATYPE_LH))
-		return 1;
-
-	lh->lh_sequence = be64_to_cpu(str->lh_sequence);
-	lh->lh_flags = be32_to_cpu(str->lh_flags);
-	lh->lh_tail = be32_to_cpu(str->lh_tail);
-	lh->lh_blkno = be32_to_cpu(str->lh_blkno);
-	lh->lh_hash = be32_to_cpu(str->lh_hash);
-	return 0;
-}
-
 /**
  * get_log_header - read the log header for a given segment
  * @jd: the journal
@@ -151,29 +135,33 @@ static int gfs2_log_header_in(struct gfs2_log_header_host *lh, const void *buf)
 static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 			  struct gfs2_log_header_host *head)
 {
+	struct gfs2_log_header *lh;
 	struct buffer_head *bh;
-	struct gfs2_log_header_host uninitialized_var(lh);
-	const u32 nothing = 0;
 	u32 hash;
 	int error;
 
 	error = gfs2_replay_read_block(jd, blk, &bh);
 	if (error)
 		return error;
+	lh = (void *)bh->b_data;
 
-	hash = crc32_le((u32)~0, bh->b_data, sizeof(struct gfs2_log_header) -
-					     sizeof(u32));
-	hash = crc32_le(hash, (unsigned char const *)&nothing, sizeof(nothing));
-	hash ^= (u32)~0;
-	error = gfs2_log_header_in(&lh, bh->b_data);
-	brelse(bh);
+	hash = crc32(~0, lh, sizeof(*lh) - 4);
+	hash = ~crc32_le_shift(hash, 4);  /* assume lh_hash is zero */
 
-	if (error || lh.lh_blkno != blk || lh.lh_hash != hash)
-		return 1;
+	error = lh->lh_header.mh_magic != cpu_to_be32(GFS2_MAGIC) ||
+		lh->lh_header.mh_type != cpu_to_be32(GFS2_METATYPE_LH) ||
+		be32_to_cpu(lh->lh_blkno) != blk ||
+		be32_to_cpu(lh->lh_hash) != hash;
 
-	*head = lh;
+	brelse(bh);
 
-	return 0;
+	if (!error) {
+		head->lh_sequence = be64_to_cpu(lh->lh_sequence);
+		head->lh_flags = be32_to_cpu(lh->lh_flags);
+		head->lh_tail = be32_to_cpu(lh->lh_tail);
+		head->lh_blkno = be32_to_cpu(lh->lh_blkno);
+	}
+	return error;
 }
 
 /**

commit 588bff95c94efc05f9e1a0b19015c9408ed7c0ef
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Mon Dec 18 12:48:29 2017 -0600

    GFS2: Reduce code redundancy writing log headers
    
    Before this patch, there was a lot of code redundancy between functions
    log_write_header (which uses bio) and clean_journal (which uses
    buffer_head). This patch reduces the redundancy to simplify the code
    and make log header writing more consistent. We want more consistency
    and reduced redundancy because we plan to add a bunch of new fields
    to improve performance (by eliminating the local statfs and quota files)
    improve metadata integrity (by adding new crcs and such) and for better
    debugging (by adding new fields to track when and where metadata was
    pushed through the journals.) We don't want to duplicate setting these
    new fields, nor allow for human error in the process.
    
    This reduction in code redundancy is accomplished by introducing a new
    helper function, gfs2_write_log_header which uses bio rather than bh.
    That simplifies recovery function clean_journal() to use the new helper
    function and iomap rather than redundancy and block_map (and eventually
    we can maybe remove block_map). It also reduces our dependency on
    buffer_heads.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 9395a3db1a60..5d3431219425 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -20,6 +20,7 @@
 #include "bmap.h"
 #include "glock.h"
 #include "glops.h"
+#include "log.h"
 #include "lops.h"
 #include "meta_io.h"
 #include "recovery.h"
@@ -370,62 +371,22 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 
 /**
  * clean_journal - mark a dirty journal as being clean
- * @sdp: the filesystem
  * @jd: the journal
- * @gl: the journal's glock
  * @head: the head journal to start from
  *
  * Returns: errno
  */
 
-static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
+static void clean_journal(struct gfs2_jdesc *jd,
+			  struct gfs2_log_header_host *head)
 {
-	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
-	unsigned int lblock;
-	struct gfs2_log_header *lh;
-	u32 hash;
-	struct buffer_head *bh;
-	int error;
-	struct buffer_head bh_map = { .b_state = 0, .b_blocknr = 0 };
-
-	lblock = head->lh_blkno;
-	gfs2_replay_incr_blk(jd, &lblock);
-	bh_map.b_size = 1 << ip->i_inode.i_blkbits;
-	error = gfs2_block_map(&ip->i_inode, lblock, &bh_map, 0);
-	if (error)
-		return error;
-	if (!bh_map.b_blocknr) {
-		gfs2_consist_inode(ip);
-		return -EIO;
-	}
-
-	bh = sb_getblk(sdp->sd_vfs, bh_map.b_blocknr);
-	lock_buffer(bh);
-	memset(bh->b_data, 0, bh->b_size);
-	set_buffer_uptodate(bh);
-	clear_buffer_dirty(bh);
-	unlock_buffer(bh);
-
-	lh = (struct gfs2_log_header *)bh->b_data;
-	memset(lh, 0, sizeof(struct gfs2_log_header));
-	lh->lh_header.mh_magic = cpu_to_be32(GFS2_MAGIC);
-	lh->lh_header.mh_type = cpu_to_be32(GFS2_METATYPE_LH);
-	lh->lh_header.__pad0 = cpu_to_be64(0);
-	lh->lh_header.mh_format = cpu_to_be32(GFS2_FORMAT_LH);
-	lh->lh_header.mh_jid = cpu_to_be32(sdp->sd_jdesc->jd_jid);
-	lh->lh_sequence = cpu_to_be64(head->lh_sequence + 1);
-	lh->lh_flags = cpu_to_be32(GFS2_LOG_HEAD_UNMOUNT);
-	lh->lh_blkno = cpu_to_be32(lblock);
-	hash = gfs2_disk_hash((const char *)lh, sizeof(struct gfs2_log_header));
-	lh->lh_hash = cpu_to_be32(hash);
-
-	set_buffer_dirty(bh);
-	if (sync_dirty_buffer(bh))
-		gfs2_io_error_bh(sdp, bh);
-	brelse(bh);
 
-	return error;
+	sdp->sd_log_flush_head = head->lh_blkno;
+	gfs2_replay_incr_blk(jd, &sdp->sd_log_flush_head);
+	gfs2_write_log_header(sdp, head->lh_sequence + 1, 0,
+			      GFS2_LOG_HEAD_UNMOUNT, REQ_PREFLUSH |
+			      REQ_FUA | REQ_META | REQ_SYNC);
 }
 
 
@@ -552,9 +513,7 @@ void gfs2_recover_func(struct work_struct *work)
 				goto fail_gunlock_thaw;
 		}
 
-		error = clean_journal(jd, &head);
-		if (error)
-			goto fail_gunlock_thaw;
+		clean_journal(jd, &head);
 
 		gfs2_glock_dq_uninit(&thaw_gh);
 		t = DIV_ROUND_UP(jiffies - t, HZ);

commit bc98a42c1f7d0f886c0c1b75a92a004976a46d9f
Author: David Howells <dhowells@redhat.com>
Date:   Mon Jul 17 08:45:34 2017 +0100

    VFS: Convert sb->s_flags & MS_RDONLY to sb_rdonly(sb)
    
    Firstly by applying the following with coccinelle's spatch:
    
            @@ expression SB; @@
            -SB->s_flags & MS_RDONLY
            +sb_rdonly(SB)
    
    to effect the conversion to sb_rdonly(sb), then by applying:
    
            @@ expression A, SB; @@
            (
            -(!sb_rdonly(SB)) && A
            +!sb_rdonly(SB) && A
            |
            -A != (sb_rdonly(SB))
            +A != sb_rdonly(SB)
            |
            -A == (sb_rdonly(SB))
            +A == sb_rdonly(SB)
            |
            -!(sb_rdonly(SB))
            +!sb_rdonly(SB)
            |
            -A && (sb_rdonly(SB))
            +A && sb_rdonly(SB)
            |
            -A || (sb_rdonly(SB))
            +A || sb_rdonly(SB)
            |
            -(sb_rdonly(SB)) != A
            +sb_rdonly(SB) != A
            |
            -(sb_rdonly(SB)) == A
            +sb_rdonly(SB) == A
            |
            -(sb_rdonly(SB)) && A
            +sb_rdonly(SB) && A
            |
            -(sb_rdonly(SB)) || A
            +sb_rdonly(SB) || A
            )
    
            @@ expression A, B, SB; @@
            (
            -(sb_rdonly(SB)) ? 1 : 0
            +sb_rdonly(SB)
            |
            -(sb_rdonly(SB)) ? A : B
            +sb_rdonly(SB) ? A : B
            )
    
    to remove left over excess bracketage and finally by applying:
    
            @@ expression A, SB; @@
            (
            -(A & MS_RDONLY) != sb_rdonly(SB)
            +(bool)(A & MS_RDONLY) != sb_rdonly(SB)
            |
            -(A & MS_RDONLY) == sb_rdonly(SB)
            +(bool)(A & MS_RDONLY) == sb_rdonly(SB)
            )
    
    to make comparisons against the result of sb_rdonly() (which is a bool)
    work correctly.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 113b6095a58d..9395a3db1a60 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -522,7 +522,7 @@ void gfs2_recover_func(struct work_struct *work)
 			if (!test_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags))
 				ro = 1;
 		} else {
-			if (sdp->sd_vfs->s_flags & MS_RDONLY) {
+			if (sb_rdonly(sdp->sd_vfs)) {
 				/* check if device itself is read-only */
 				ro = bdev_read_only(sdp->sd_vfs->s_bdev);
 				if (!ro) {

commit e1cb6be9e142e6cc6246f3ab2776b4d7a2b3d9f0
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Thu Jul 21 13:02:44 2016 -0500

    GFS2: Fix gfs2_replay_incr_blk for multiple journal sizes
    
    Before this patch, if you used gfs2_jadd to add new journals of a
    size smaller than the existing journals, replaying those new journals
    would withdraw. That's because function gfs2_replay_incr_blk was
    using the number of journal blocks (jd_block) from the superblock's
    journal pointer. In other words, "My journal's max size" rather than
    "the journal we're replaying's size." This patch changes the function
    to use the size of the pertinent journal rather than always using the
    journal we happen to be using.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 1b645773c98e..113b6095a58d 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -338,7 +338,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 			struct gfs2_log_header_host lh;
 			error = get_log_header(jd, start, &lh);
 			if (!error) {
-				gfs2_replay_incr_blk(sdp, &start);
+				gfs2_replay_incr_blk(jd, &start);
 				brelse(bh);
 				continue;
 			}
@@ -360,7 +360,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 		}
 
 		while (length--)
-			gfs2_replay_incr_blk(sdp, &start);
+			gfs2_replay_incr_blk(jd, &start);
 
 		brelse(bh);
 	}
@@ -390,7 +390,7 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *hea
 	struct buffer_head bh_map = { .b_state = 0, .b_blocknr = 0 };
 
 	lblock = head->lh_blkno;
-	gfs2_replay_incr_blk(sdp, &lblock);
+	gfs2_replay_incr_blk(jd, &lblock);
 	bh_map.b_size = 1 << ip->i_inode.i_blkbits;
 	error = gfs2_block_map(&ip->i_inode, lblock, &bh_map, 0);
 	if (error)

commit 3566c964767811f3965979fa9598027b6550026d
Author: alex chen <alex.chen@huawei.com>
Date:   Mon Jan 12 19:01:03 2015 +0800

    GFS2: fix sprintf format specifier
    
    Sprintf format specifier "%d" and "%u" are mixed up in
    gfs2_recovery_done() and freeze_show(). So correct them.
    
    Signed-off-by: Alex Chen <alex.chen@huawei.com>
    Reviewed-by: Joseph Qi <joseph.qi@huawei.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 573bd3b758fa..1b645773c98e 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -439,7 +439,7 @@ static void gfs2_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
 
         ls->ls_recover_jid_done = jid;
         ls->ls_recover_jid_status = message;
-	sprintf(env_jid, "JID=%d", jid);
+	sprintf(env_jid, "JID=%u", jid);
 	sprintf(env_status, "RECOVERY=%s",
 		message == LM_RD_SUCCESS ? "Done" : "Failed");
         kobject_uevent_env(&sdp->sd_kobj, KOBJ_CHANGE, envp);

commit 743162013d40ca612b4cb53d3a200dff2d9ab26e
Author: NeilBrown <neilb@suse.de>
Date:   Mon Jul 7 15:16:04 2014 +1000

    sched: Remove proliferation of wait_on_bit() action functions
    
    The current "wait_on_bit" interface requires an 'action'
    function to be provided which does the actual waiting.
    There are over 20 such functions, many of them identical.
    Most cases can be satisfied by one of just two functions, one
    which uses io_schedule() and one which just uses schedule().
    
    So:
     Rename wait_on_bit and        wait_on_bit_lock to
            wait_on_bit_action and wait_on_bit_lock_action
     to make it explicit that they need an action function.
    
     Introduce new wait_on_bit{,_lock} and wait_on_bit{,_lock}_io
     which are *not* given an action function but implicitly use
     a standard one.
     The decision to error-out if a signal is pending is now made
     based on the 'mode' argument rather than being encoded in the action
     function.
    
     All instances of the old wait_on_bit and wait_on_bit_lock which
     can use the new version have been changed accordingly and their
     action functions have been discarded.
     wait_on_bit{_lock} does not return any specific error code in the
     event of a signal so the caller must check for non-zero and
     interpolate their own error code as appropriate.
    
    The wait_on_bit() call in __fscache_wait_on_invalidate() was
    ambiguous as it specified TASK_UNINTERRUPTIBLE but used
    fscache_wait_bit_interruptible as an action function.
    David Howells confirms this should be uniformly
    "uninterruptible"
    
    The main remaining user of wait_on_bit{,_lock}_action is NFS
    which needs to use a freezer-aware schedule() call.
    
    A comment in fs/gfs2/glock.c notes that having multiple 'action'
    functions is useful as they display differently in the 'wchan'
    field of 'ps'. (and /proc/$PID/wchan).
    As the new bit_wait{,_io} functions are tagged "__sched", they
    will not show up at all, but something higher in the stack.  So
    the distinction will still be visible, only with different
    function names (gds2_glock_wait versus gfs2_glock_dq_wait in the
    gfs2/glock.c case).
    
    Since first version of this patch (against 3.15) two new action
    functions appeared, on in NFS and one in CIFS.  CIFS also now
    uses an action function that makes the same freezer aware
    schedule call as NFS.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Acked-by: David Howells <dhowells@redhat.com> (fscache, keys)
    Acked-by: Steven Whitehouse <swhiteho@redhat.com> (gfs2)
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Steve French <sfrench@samba.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20140707051603.28027.72349.stgit@notabene.brown
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 94555d4c5698..573bd3b758fa 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -591,12 +591,6 @@ void gfs2_recover_func(struct work_struct *work)
 	wake_up_bit(&jd->jd_flags, JDF_RECOVERY);
 }
 
-static int gfs2_recovery_wait(void *word)
-{
-	schedule();
-	return 0;
-}
-
 int gfs2_recover_journal(struct gfs2_jdesc *jd, bool wait)
 {
 	int rv;
@@ -609,7 +603,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd, bool wait)
 	BUG_ON(!rv);
 
 	if (wait)
-		wait_on_bit(&jd->jd_flags, JDF_RECOVERY, gfs2_recovery_wait,
+		wait_on_bit(&jd->jd_flags, JDF_RECOVERY,
 			    TASK_UNINTERRUPTIBLE);
 
 	return wait ? jd->jd_recover_error : 0;

commit ba1bdefec36c45eef1f8aa44bd845c9ea3190506
Merge: 74efa045f4e2 0e48e055a7df
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 4 08:30:10 2014 -0700

    Merge tag 'gfs2-merge-window' of git://git.kernel.org/pub/scm/linux/kernel/git/steve/gfs2-3.0-nmw into next
    
    Pull gfs2 updates from Steven Whitehouse:
     "This must be about the smallest merge window patch set ever for GFS2.
      It is probably also the first one without a single patch from me.
      That is down to a combination of factors, and I have some things in
      the works that are not quite ready yet, that I hope to put in next
      time around.
    
      Returning to what is here this time...  we have 3 patches which fix
      various warnings.  Two are bug fixes (for quotas and also a rare
      recovery race condition).  The final patch, from Ben Marzinski, is an
      important change in the freeze code which has been in progress for
      some time.  This removes the need to take and drop the transaction
      lock for every single transaction, when the only time it was used, was
      at file system freeze time.  Ben's patch integrates the freeze
      operation into the journal flush code as an alternative with lower
      overheads and also lands up resolving some difficult to fix races at
      the same time"
    
    * tag 'gfs2-merge-window' of git://git.kernel.org/pub/scm/linux/kernel/git/steve/gfs2-3.0-nmw:
      GFS2: Prevent recovery before the local journal is set
      GFS2: fs/gfs2/file.c: kernel-doc warning fixes
      GFS2: fs/gfs2/bmap.c: kernel-doc warning fixes
      GFS2: remove transaction glock
      GFS2: lops.c: replace 0 by NULL for pointers
      GFS2: quotas not being refreshed in gfs2_adjust_quota

commit 24972557b12ce8fd5b6c6847d0e2ee1837ddc13b
Author: Benjamin Marzinski <bmarzins@redhat.com>
Date:   Thu May 1 22:26:55 2014 -0500

    GFS2: remove transaction glock
    
    GFS2 has a transaction glock, which must be grabbed for every
    transaction, whose purpose is to deal with freezing the filesystem.
    Aside from this involving a large amount of locking, it is very easy to
    make the current fsfreeze code hang on unfreezing.
    
    This patch rewrites how gfs2 handles freezing the filesystem. The
    transaction glock is removed. In it's place is a freeze glock, which is
    cached (but not held) in a shared state by every node in the cluster
    when the filesystem is mounted. This lock only needs to be grabbed on
    freezing, and actions which need to be safe from freezing, like
    recovery.
    
    When a node wants to freeze the filesystem, it grabs this glock
    exclusively.  When the freeze glock state changes on the nodes (either
    from shared to unlocked, or shared to exclusive), the filesystem does a
    special log flush.  gfs2_log_flush() does all the work for flushing out
    the and shutting down the incore log, and then it tries to grab the
    freeze glock in a shared state again.  Since the filesystem is stuck in
    gfs2_log_flush, no new transaction can start, and nothing can be written
    to disk. Unfreezing the filesytem simply involes dropping the freeze
    glock, allowing gfs2_log_flush() to grab and then release the shared
    lock, so it is cached for next time.
    
    However, in order for the unfreezing ioctl to occur, gfs2 needs to get a
    shared lock on the filesystem root directory inode to check permissions.
    If that glock has already been grabbed exclusively, fsfreeze will be
    unable to get the shared lock and unfreeze the filesystem.
    
    In order to allow the unfreeze, this patch makes gfs2 grab a shared lock
    on the filesystem root directory during the freeze, and hold it until it
    unfreezes the filesystem.  The functions which need to grab a shared
    lock in order to allow the unfreeze ioctl to be issued now use the lock
    grabbed by the freeze code instead.
    
    The freeze and unfreeze code take care to make sure that this shared
    lock will not be dropped while another process is using it.
    
    Signed-off-by: Benjamin Marzinski <bmarzins@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 7ad4094d68c0..a4ed78b5f47e 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -454,7 +454,7 @@ void gfs2_recover_func(struct work_struct *work)
 	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	struct gfs2_log_header_host head;
-	struct gfs2_holder j_gh, ji_gh, t_gh;
+	struct gfs2_holder j_gh, ji_gh, thaw_gh;
 	unsigned long t;
 	int ro = 0;
 	unsigned int pass;
@@ -508,11 +508,11 @@ void gfs2_recover_func(struct work_struct *work)
 
 		t = jiffies;
 
-		/* Acquire a shared hold on the transaction lock */
+		/* Acquire a shared hold on the freeze lock */
 
-		error = gfs2_glock_nq_init(sdp->sd_trans_gl, LM_ST_SHARED,
-					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY |
-					   GL_NOCACHE, &t_gh);
+		error = gfs2_glock_nq_init(sdp->sd_freeze_gl, LM_ST_SHARED,
+					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY,
+					   &thaw_gh);
 		if (error)
 			goto fail_gunlock_ji;
 
@@ -538,7 +538,7 @@ void gfs2_recover_func(struct work_struct *work)
 			fs_warn(sdp, "jid=%u: Can't replay: read-only block "
 				"device\n", jd->jd_jid);
 			error = -EROFS;
-			goto fail_gunlock_tr;
+			goto fail_gunlock_thaw;
 		}
 
 		fs_info(sdp, "jid=%u: Replaying journal...\n", jd->jd_jid);
@@ -549,14 +549,14 @@ void gfs2_recover_func(struct work_struct *work)
 						   head.lh_blkno, pass);
 			lops_after_scan(jd, error, pass);
 			if (error)
-				goto fail_gunlock_tr;
+				goto fail_gunlock_thaw;
 		}
 
 		error = clean_journal(jd, &head);
 		if (error)
-			goto fail_gunlock_tr;
+			goto fail_gunlock_thaw;
 
-		gfs2_glock_dq_uninit(&t_gh);
+		gfs2_glock_dq_uninit(&thaw_gh);
 		t = DIV_ROUND_UP(jiffies - t, HZ);
 		fs_info(sdp, "jid=%u: Journal replayed in %lus\n",
 			jd->jd_jid, t);
@@ -572,8 +572,8 @@ void gfs2_recover_func(struct work_struct *work)
 	fs_info(sdp, "jid=%u: Done\n", jd->jd_jid);
 	goto done;
 
-fail_gunlock_tr:
-	gfs2_glock_dq_uninit(&t_gh);
+fail_gunlock_thaw:
+	gfs2_glock_dq_uninit(&thaw_gh);
 fail_gunlock_ji:
 	if (jlocked) {
 		gfs2_glock_dq_uninit(&ji_gh);

commit 4e857c58efeb99393cba5a5d0d8ec7117183137c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Mar 17 18:06:10 2014 +0100

    arch: Mass conversion of smp_mb__*()
    
    Mostly scripted conversion of the smp_mb__* barriers.
    
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/n/tip-55dhyhocezdw1dg7u19hmh1u@git.kernel.org
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 7ad4094d68c0..fe7a56fb6084 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -587,7 +587,7 @@ void gfs2_recover_func(struct work_struct *work)
 	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
 done:
 	clear_bit(JDF_RECOVERY, &jd->jd_flags);
-	smp_mb__after_clear_bit();
+	smp_mb__after_atomic();
 	wake_up_bit(&jd->jd_flags, JDF_RECOVERY);
 }
 

commit a17d758b661d6fa01a0d466d7bdda3c131bb68f9
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Thu Mar 6 17:19:15 2014 -0500

    GFS2: Move recovery variables to journal structure in memory
    
    If multiple nodes fail and their recovery work runs simultaneously, they
    would use the same unprotected variables in the superblock. For example,
    they would stomp on each other's revoked blocks lists, which resulted
    in file system metadata corruption. This patch moves the necessary
    variables so that each journal has its own separate area for tracking
    its journal replay.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 963b2d75200c..7ad4094d68c0 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -52,9 +52,9 @@ int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 	return error;
 }
 
-int gfs2_revoke_add(struct gfs2_sbd *sdp, u64 blkno, unsigned int where)
+int gfs2_revoke_add(struct gfs2_jdesc *jd, u64 blkno, unsigned int where)
 {
-	struct list_head *head = &sdp->sd_revoke_list;
+	struct list_head *head = &jd->jd_revoke_list;
 	struct gfs2_revoke_replay *rr;
 	int found = 0;
 
@@ -81,13 +81,13 @@ int gfs2_revoke_add(struct gfs2_sbd *sdp, u64 blkno, unsigned int where)
 	return 1;
 }
 
-int gfs2_revoke_check(struct gfs2_sbd *sdp, u64 blkno, unsigned int where)
+int gfs2_revoke_check(struct gfs2_jdesc *jd, u64 blkno, unsigned int where)
 {
 	struct gfs2_revoke_replay *rr;
 	int wrap, a, b, revoke;
 	int found = 0;
 
-	list_for_each_entry(rr, &sdp->sd_revoke_list, rr_list) {
+	list_for_each_entry(rr, &jd->jd_revoke_list, rr_list) {
 		if (rr->rr_blkno == blkno) {
 			found = 1;
 			break;
@@ -97,17 +97,17 @@ int gfs2_revoke_check(struct gfs2_sbd *sdp, u64 blkno, unsigned int where)
 	if (!found)
 		return 0;
 
-	wrap = (rr->rr_where < sdp->sd_replay_tail);
-	a = (sdp->sd_replay_tail < where);
+	wrap = (rr->rr_where < jd->jd_replay_tail);
+	a = (jd->jd_replay_tail < where);
 	b = (where < rr->rr_where);
 	revoke = (wrap) ? (a || b) : (a && b);
 
 	return revoke;
 }
 
-void gfs2_revoke_clean(struct gfs2_sbd *sdp)
+void gfs2_revoke_clean(struct gfs2_jdesc *jd)
 {
-	struct list_head *head = &sdp->sd_revoke_list;
+	struct list_head *head = &jd->jd_revoke_list;
 	struct gfs2_revoke_replay *rr;
 
 	while (!list_empty(head)) {

commit 376d37788b56bc2800e5bd56b7a36b3544d89f97
Author: David Teigland <teigland@redhat.com>
Date:   Mon Jan 9 15:29:20 2012 -0500

    GFS2: fail mount if journal recovery fails
    
    If the first mounter fails to recover one of the journals
    during mount, the mount should fail.
    
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 80701d1566a1..963b2d75200c 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -583,6 +583,7 @@ void gfs2_recover_func(struct work_struct *work)
 
 	fs_info(sdp, "jid=%u: %s\n", jd->jd_jid, (error) ? "Failed" : "Done");
 fail:
+	jd->jd_recover_error = error;
 	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
 done:
 	clear_bit(JDF_RECOVERY, &jd->jd_flags);
@@ -611,6 +612,6 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd, bool wait)
 		wait_on_bit(&jd->jd_flags, JDF_RECOVERY, gfs2_recovery_wait,
 			    TASK_UNINTERRUPTIBLE);
 
-	return 0;
+	return wait ? jd->jd_recover_error : 0;
 }
 

commit e8ca5cc571a60339491f8c273a01093096ff8704
Author: David Teigland <teigland@redhat.com>
Date:   Mon Jan 9 14:40:06 2012 -0500

    GFS2: let spectator mount do read only recovery
    
    Previously, a spectator mount would not even attempt to do
    journal recovery for a failed node.  This meant that if all
    mounted nodes were spectators, everyone would be stuck after
    a node failed, all waiting for recovery to be performed.
    This is unnecessary since the failed node had a clean journal.
    
    Instead, allow a spectator mount to do a partial "read only"
    recovery, which means it will check if the failed journal is
    clean, and if so, report a successful recovery.  If the failed
    journal is not clean, it reports that journal recovery failed.
    This makes it work the same as a read only mount on a read only
    block device.
    
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index af49e8f432fe..80701d1566a1 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -516,7 +516,9 @@ void gfs2_recover_func(struct work_struct *work)
 		if (error)
 			goto fail_gunlock_ji;
 
-		if (test_bit(SDF_JOURNAL_CHECKED, &sdp->sd_flags)) {
+		if (test_bit(SDF_RORECOVERY, &sdp->sd_flags)) {
+			ro = 1;
+		} else if (test_bit(SDF_JOURNAL_CHECKED, &sdp->sd_flags)) {
 			if (!test_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags))
 				ro = 1;
 		} else {

commit e0c2a9aa1e68455dc3439e95d85cabcaff073666
Author: David Teigland <teigland@redhat.com>
Date:   Mon Jan 9 17:18:05 2012 -0500

    GFS2: dlm based recovery coordination
    
    This new method of managing recovery is an alternative to
    the previous approach of using the userland gfs_controld.
    
    - use dlm slot numbers to assign journal id's
    - use dlm recovery callbacks to initiate journal recovery
    - use a dlm lock to determine the first node to mount fs
    - use a dlm lock to track journals that need recovery
    
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index f2a02edcac8f..af49e8f432fe 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -436,12 +436,16 @@ static void gfs2_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
 	char env_status[20];
 	char *envp[] = { env_jid, env_status, NULL };
 	struct lm_lockstruct *ls = &sdp->sd_lockstruct;
+
         ls->ls_recover_jid_done = jid;
         ls->ls_recover_jid_status = message;
 	sprintf(env_jid, "JID=%d", jid);
 	sprintf(env_status, "RECOVERY=%s",
 		message == LM_RD_SUCCESS ? "Done" : "Failed");
         kobject_uevent_env(&sdp->sd_kobj, KOBJ_CHANGE, envp);
+
+	if (sdp->sd_lockstruct.ls_ops->lm_recovery_result)
+		sdp->sd_lockstruct.ls_ops->lm_recovery_result(sdp, jid, message);
 }
 
 void gfs2_recover_func(struct work_struct *work)

commit c741c4551237f9c1bdcd3b1b39b0883bd19a3723
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed Sep 29 14:20:52 2010 +0100

    GFS2: Fix spectator umount issue
    
    The tests further down the recovery function relating to
    unlocking the journal need to be updated to match the
    intial test. Also, a test in the umount code which was
    surplus to requirements has been removed. Umounting
    spectator mounts now works correctly, as expected.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 666548e14596..f2a02edcac8f 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -455,12 +455,13 @@ void gfs2_recover_func(struct work_struct *work)
 	int ro = 0;
 	unsigned int pass;
 	int error;
+	int jlocked = 0;
 
 	if (sdp->sd_args.ar_spectator ||
 	    (jd->jd_jid != sdp->sd_lockstruct.ls_jid)) {
 		fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n",
 			jd->jd_jid);
-
+		jlocked = 1;
 		/* Acquire the journal lock so we can do recovery */
 
 		error = gfs2_glock_nq_num(sdp, jd->jd_jid, &gfs2_journal_glops,
@@ -555,13 +556,12 @@ void gfs2_recover_func(struct work_struct *work)
 			jd->jd_jid, t);
 	}
 
-	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid)
-		gfs2_glock_dq_uninit(&ji_gh);
-
 	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_SUCCESS);
 
-	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid)
+	if (jlocked) {
+		gfs2_glock_dq_uninit(&ji_gh);
 		gfs2_glock_dq_uninit(&j_gh);
+	}
 
 	fs_info(sdp, "jid=%u: Done\n", jd->jd_jid);
 	goto done;
@@ -569,7 +569,7 @@ void gfs2_recover_func(struct work_struct *work)
 fail_gunlock_tr:
 	gfs2_glock_dq_uninit(&t_gh);
 fail_gunlock_ji:
-	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid) {
+	if (jlocked) {
 		gfs2_glock_dq_uninit(&ji_gh);
 fail_gunlock_j:
 		gfs2_glock_dq_uninit(&j_gh);

commit d0795f912318f65b800c6b619d749c3bf7c930fb
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Sep 27 15:58:11 2010 +0100

    GFS2: Fix journal check for spectator mounts
    
    When checking journals for spectator mounts, we cannot rely on the
    journal being locked, whatever its jid might be. This patch
    ensures that we always get the journal locks when checking
    journals for a spectator mount.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index f7f89a94a5a4..666548e14596 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -456,7 +456,8 @@ void gfs2_recover_func(struct work_struct *work)
 	unsigned int pass;
 	int error;
 
-	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid) {
+	if (sdp->sd_args.ar_spectator ||
+	    (jd->jd_jid != sdp->sd_lockstruct.ls_jid)) {
 		fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n",
 			jd->jd_jid);
 

commit 6ecd7c2dd9f5dd4f6e8f65c8027159f9c73b0e4c
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 20 22:09:02 2010 +0200

    gfs2: use workqueue instead of slow-work
    
    Workqueue can now handle high concurrency.  Convert gfs to use
    workqueue instead of slow-work.
    
    * Steven pointed out that recovery path might be run from allocation
      path and thus requires forward progress guarantee without memory
      allocation.  Create and use gfs_recovery_wq with rescuer.  Please
      note that forward progress wasn't guaranteed with slow-work.
    
    * Updated to use non-reentrant workqueue.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 4b9bece3d437..f7f89a94a5a4 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -14,7 +14,6 @@
 #include <linux/buffer_head.h>
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
-#include <linux/slow-work.h>
 
 #include "gfs2.h"
 #include "incore.h"
@@ -28,6 +27,8 @@
 #include "util.h"
 #include "dir.h"
 
+struct workqueue_struct *gfs_recovery_wq;
+
 int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 			   struct buffer_head **bh)
 {
@@ -443,23 +444,7 @@ static void gfs2_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
         kobject_uevent_env(&sdp->sd_kobj, KOBJ_CHANGE, envp);
 }
 
-static int gfs2_recover_get_ref(struct slow_work *work)
-{
-	struct gfs2_jdesc *jd = container_of(work, struct gfs2_jdesc, jd_work);
-	if (test_and_set_bit(JDF_RECOVERY, &jd->jd_flags))
-		return -EBUSY;
-	return 0;
-}
-
-static void gfs2_recover_put_ref(struct slow_work *work)
-{
-	struct gfs2_jdesc *jd = container_of(work, struct gfs2_jdesc, jd_work);
-	clear_bit(JDF_RECOVERY, &jd->jd_flags);
-	smp_mb__after_clear_bit();
-	wake_up_bit(&jd->jd_flags, JDF_RECOVERY);
-}
-
-static void gfs2_recover_work(struct slow_work *work)
+void gfs2_recover_func(struct work_struct *work)
 {
 	struct gfs2_jdesc *jd = container_of(work, struct gfs2_jdesc, jd_work);
 	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
@@ -578,7 +563,7 @@ static void gfs2_recover_work(struct slow_work *work)
 		gfs2_glock_dq_uninit(&j_gh);
 
 	fs_info(sdp, "jid=%u: Done\n", jd->jd_jid);
-	return;
+	goto done;
 
 fail_gunlock_tr:
 	gfs2_glock_dq_uninit(&t_gh);
@@ -590,32 +575,35 @@ static void gfs2_recover_work(struct slow_work *work)
 	}
 
 	fs_info(sdp, "jid=%u: %s\n", jd->jd_jid, (error) ? "Failed" : "Done");
-
 fail:
 	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
+done:
+	clear_bit(JDF_RECOVERY, &jd->jd_flags);
+	smp_mb__after_clear_bit();
+	wake_up_bit(&jd->jd_flags, JDF_RECOVERY);
 }
 
-struct slow_work_ops gfs2_recover_ops = {
-	.owner	 = THIS_MODULE,
-	.get_ref = gfs2_recover_get_ref,
-	.put_ref = gfs2_recover_put_ref,
-	.execute = gfs2_recover_work,
-};
-
-
 static int gfs2_recovery_wait(void *word)
 {
 	schedule();
 	return 0;
 }
 
-int gfs2_recover_journal(struct gfs2_jdesc *jd)
+int gfs2_recover_journal(struct gfs2_jdesc *jd, bool wait)
 {
 	int rv;
-	rv = slow_work_enqueue(&jd->jd_work);
-	if (rv)
-		return rv;
-	wait_on_bit(&jd->jd_flags, JDF_RECOVERY, gfs2_recovery_wait, TASK_UNINTERRUPTIBLE);
+
+	if (test_and_set_bit(JDF_RECOVERY, &jd->jd_flags))
+		return -EBUSY;
+
+	/* we have JDF_RECOVERY, queue should always succeed */
+	rv = queue_work(gfs_recovery_wq, &jd->jd_work);
+	BUG_ON(!rv);
+
+	if (wait)
+		wait_on_bit(&jd->jd_flags, JDF_RECOVERY, gfs2_recovery_wait,
+			    TASK_UNINTERRUPTIBLE);
+
 	return 0;
 }
 

commit 0ab7d13fcbd7ce1658c563e345990ba453719deb
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Fri Nov 6 16:20:51 2009 +0000

    GFS2: Tag all metadata with jid
    
    There are two spare field in the header common to all GFS2
    metadata. One is just the right size to fit a journal id
    in it, and this patch updates the journal code so that each
    time a metadata block is modified, we tag it with the journal
    id of the node which is performing the modification.
    
    The reason for this is that it should make it much easier to
    debug issues which arise if we can tell which node was the
    last to modify a particular metadata block.
    
    Since the field is updated before the block is written into
    the journal, each journal should only contain metadata which
    is tagged with its own journal id. The one exception to this
    is the journal header block, which might have a different node's
    id in it, if that journal was recovered by another node in the
    cluster.
    
    Thus each journal will contain a record of which nodes recovered
    it, via the journal header.
    
    The other field in the metadata header could potentially be
    used to hold information about what kind of operation was
    performed, but for the time being we just zero it on each
    transaction so that if we use it for that in future, we'll
    know that the information (where it exists) is reliable.
    
    I did consider using the other field to hold the journal
    sequence number, however since in GFS2's journaling we write
    the modified data into the journal and not the original
    data, this gives no information as to what action caused the
    modification, so I think we can probably come up with a better
    use for those 64 bits in the future.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 09fa31965576..4b9bece3d437 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -410,7 +410,9 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *hea
 	memset(lh, 0, sizeof(struct gfs2_log_header));
 	lh->lh_header.mh_magic = cpu_to_be32(GFS2_MAGIC);
 	lh->lh_header.mh_type = cpu_to_be32(GFS2_METATYPE_LH);
+	lh->lh_header.__pad0 = cpu_to_be64(0);
 	lh->lh_header.mh_format = cpu_to_be32(GFS2_FORMAT_LH);
+	lh->lh_header.mh_jid = cpu_to_be32(sdp->sd_jdesc->jd_jid);
 	lh->lh_sequence = cpu_to_be64(head->lh_sequence + 1);
 	lh->lh_flags = cpu_to_be32(GFS2_LOG_HEAD_UNMOUNT);
 	lh->lh_blkno = cpu_to_be32(lblock);

commit 1c2ea8a2c0b71cc5e07f518370d458d692c9b21a
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 20 21:50:40 2009 +0000

    SLOW_WORK: Fix GFS2 to #include <linux/module.h> before using THIS_MODULE
    
    GFS2 has been altered to pass THIS_MODULE to slow_work_register_user(), but
    hasn't been altered to #include <linux/module.h> to provide it, resulting in
    the following error:
    
            fs/gfs2/recovery.c:596: error: 'THIS_MODULE' undeclared here (not in a function)
    
    Add the missing #include.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index b2bb779f09ed..09fa31965576 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -7,6 +7,7 @@
  * of the GNU General Public License version 2.
  */
 
+#include <linux/module.h>
 #include <linux/slab.h>
 #include <linux/spinlock.h>
 #include <linux/completion.h>

commit 3d7a641e544e428191667e8b1f83f96fa46dbd65
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:10:23 2009 +0000

    SLOW_WORK: Wait for outstanding work items belonging to a module to clear
    
    Wait for outstanding slow work items belonging to a module to clear when
    unregistering that module as a user of the facility.  This prevents the put_ref
    code of a work item from being taken away before it returns.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 59d2695509d3..b2bb779f09ed 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -593,6 +593,7 @@ static void gfs2_recover_work(struct slow_work *work)
 }
 
 struct slow_work_ops gfs2_recover_ops = {
+	.owner	 = THIS_MODULE,
 	.get_ref = gfs2_recover_get_ref,
 	.put_ref = gfs2_recover_put_ref,
 	.execute = gfs2_recover_work,

commit fe64d517df0970a68417184a12fcd4ba0589cc28
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Tue May 19 10:01:18 2009 +0100

    GFS2: Umount recovery race fix
    
    This patch fixes a race condition where we can receive recovery
    requests part way through processing a umount. This was causing
    problems since the recovery thread had already gone away.
    
    Looking in more detail at the recovery code, it was really trying
    to implement a slight variation on a work queue, and that happens to
    align nicely with the recently introduced slow-work subsystem. As a
    result I've updated the code to use slow-work, rather than its own home
    grown variety of work queue.
    
    When using the wait_on_bit() function, I noticed that the wait function
    that was supplied as an argument was appearing in the WCHAN field, so
    I've updated the function names in order to produce more meaningful
    output.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 247e8f7d6b3d..59d2695509d3 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -13,8 +13,7 @@
 #include <linux/buffer_head.h>
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
-#include <linux/kthread.h>
-#include <linux/freezer.h>
+#include <linux/slow-work.h>
 
 #include "gfs2.h"
 #include "incore.h"
@@ -441,18 +440,25 @@ static void gfs2_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
         kobject_uevent_env(&sdp->sd_kobj, KOBJ_CHANGE, envp);
 }
 
-/**
- * gfs2_recover_journal - recover a given journal
- * @jd: the struct gfs2_jdesc describing the journal
- *
- * Acquire the journal's lock, check to see if the journal is clean, and
- * do recovery if necessary.
- *
- * Returns: errno
- */
+static int gfs2_recover_get_ref(struct slow_work *work)
+{
+	struct gfs2_jdesc *jd = container_of(work, struct gfs2_jdesc, jd_work);
+	if (test_and_set_bit(JDF_RECOVERY, &jd->jd_flags))
+		return -EBUSY;
+	return 0;
+}
 
-int gfs2_recover_journal(struct gfs2_jdesc *jd)
+static void gfs2_recover_put_ref(struct slow_work *work)
+{
+	struct gfs2_jdesc *jd = container_of(work, struct gfs2_jdesc, jd_work);
+	clear_bit(JDF_RECOVERY, &jd->jd_flags);
+	smp_mb__after_clear_bit();
+	wake_up_bit(&jd->jd_flags, JDF_RECOVERY);
+}
+
+static void gfs2_recover_work(struct slow_work *work)
 {
+	struct gfs2_jdesc *jd = container_of(work, struct gfs2_jdesc, jd_work);
 	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	struct gfs2_log_header_host head;
@@ -569,7 +575,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 		gfs2_glock_dq_uninit(&j_gh);
 
 	fs_info(sdp, "jid=%u: Done\n", jd->jd_jid);
-	return 0;
+	return;
 
 fail_gunlock_tr:
 	gfs2_glock_dq_uninit(&t_gh);
@@ -584,70 +590,28 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 
 fail:
 	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
-	return error;
 }
 
-static struct gfs2_jdesc *gfs2_jdesc_find_dirty(struct gfs2_sbd *sdp)
-{
-	struct gfs2_jdesc *jd;
-	int found = 0;
-
-	spin_lock(&sdp->sd_jindex_spin);
+struct slow_work_ops gfs2_recover_ops = {
+	.get_ref = gfs2_recover_get_ref,
+	.put_ref = gfs2_recover_put_ref,
+	.execute = gfs2_recover_work,
+};
 
-	list_for_each_entry(jd, &sdp->sd_jindex_list, jd_list) {
-		if (jd->jd_dirty) {
-			jd->jd_dirty = 0;
-			found = 1;
-			break;
-		}
-	}
-	spin_unlock(&sdp->sd_jindex_spin);
-
-	if (!found)
-		jd = NULL;
 
-	return jd;
-}
-
-/**
- * gfs2_check_journals - Recover any dirty journals
- * @sdp: the filesystem
- *
- */
-
-static void gfs2_check_journals(struct gfs2_sbd *sdp)
+static int gfs2_recovery_wait(void *word)
 {
-	struct gfs2_jdesc *jd;
-
-	for (;;) {
-		jd = gfs2_jdesc_find_dirty(sdp);
-		if (!jd)
-			break;
-
-		if (jd != sdp->sd_jdesc)
-			gfs2_recover_journal(jd);
-	}
+	schedule();
+	return 0;
 }
 
-/**
- * gfs2_recoverd - Recover dead machine's journals
- * @sdp: Pointer to GFS2 superblock
- *
- */
-
-int gfs2_recoverd(void *data)
+int gfs2_recover_journal(struct gfs2_jdesc *jd)
 {
-	struct gfs2_sbd *sdp = data;
-	unsigned long t;
-
-	while (!kthread_should_stop()) {
-		gfs2_check_journals(sdp);
-		t = gfs2_tune_get(sdp,  gt_recoverd_secs) * HZ;
-		if (freezing(current))
-			refrigerator();
-		schedule_timeout_interruptible(t);
-	}
-
+	int rv;
+	rv = slow_work_enqueue(&jd->jd_work);
+	if (rv)
+		return rv;
+	wait_on_bit(&jd->jd_flags, JDF_RECOVERY, gfs2_recovery_wait, TASK_UNINTERRUPTIBLE);
 	return 0;
 }
 

commit f057f6cdf64175db1151b1f5d110e29904f119a1
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Jan 12 10:43:39 2009 +0000

    GFS2: Merge lock_dlm module into GFS2
    
    This is the big patch that I've been working on for some time
    now. There are many reasons for wanting to make this change
    such as:
     o Reducing overhead by eliminating duplicated fields between structures
     o Simplifcation of the code (reduces the code size by a fair bit)
     o The locking interface is now the DLM interface itself as proposed
       some time ago.
     o Fewer lookups of glocks when processing replies from the DLM
     o Fewer memory allocations/deallocations for each glock
     o Scope to do further optimisations in the future (but this patch is
       more than big enough for now!)
    
    Please note that (a) this patch relates to the lock_dlm module and
    not the DLM itself, that is still a separate module; and (b) that
    we retain the ability to build GFS2 as a standalone single node
    filesystem with out requiring the DLM.
    
    This patch needs a lot of testing, hence my keeping it I restarted
    my -git tree after the last merge window. That way, this has the maximum
    exposure before its merged. This is (modulo a few minor bug fixes) the
    same patch that I've been posting on and off the the last three months
    and its passed a number of different tests so far.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index efd09c3d2b26..247e8f7d6b3d 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -13,7 +13,6 @@
 #include <linux/buffer_head.h>
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
-#include <linux/lm_interface.h>
 #include <linux/kthread.h>
 #include <linux/freezer.h>
 
@@ -427,20 +426,23 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *hea
 }
 
 
-static void gfs2_lm_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
-				  unsigned int message)
+static void gfs2_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
+                               unsigned int message)
 {
-	if (!sdp->sd_lockstruct.ls_ops->lm_recovery_done)
-		return;
-
-	if (likely(!test_bit(SDF_SHUTDOWN, &sdp->sd_flags)))
-		sdp->sd_lockstruct.ls_ops->lm_recovery_done(
-			sdp->sd_lockstruct.ls_lockspace, jid, message);
+	char env_jid[20];
+	char env_status[20];
+	char *envp[] = { env_jid, env_status, NULL };
+	struct lm_lockstruct *ls = &sdp->sd_lockstruct;
+        ls->ls_recover_jid_done = jid;
+        ls->ls_recover_jid_status = message;
+	sprintf(env_jid, "JID=%d", jid);
+	sprintf(env_status, "RECOVERY=%s",
+		message == LM_RD_SUCCESS ? "Done" : "Failed");
+        kobject_uevent_env(&sdp->sd_kobj, KOBJ_CHANGE, envp);
 }
 
-
 /**
- * gfs2_recover_journal - recovery a given journal
+ * gfs2_recover_journal - recover a given journal
  * @jd: the struct gfs2_jdesc describing the journal
  *
  * Acquire the journal's lock, check to see if the journal is clean, and
@@ -561,7 +563,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid)
 		gfs2_glock_dq_uninit(&ji_gh);
 
-	gfs2_lm_recovery_done(sdp, jd->jd_jid, LM_RD_SUCCESS);
+	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_SUCCESS);
 
 	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid)
 		gfs2_glock_dq_uninit(&j_gh);
@@ -581,7 +583,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 	fs_info(sdp, "jid=%u: %s\n", jd->jd_jid, (error) ? "Failed" : "Done");
 
 fail:
-	gfs2_lm_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
+	gfs2_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
 	return error;
 }
 

commit 2bfb6449b7a1f29a2a63e1d869103b5811c3b69f
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed Nov 26 13:30:49 2008 +0000

    GFS2: Move four functions from super.c
    
    The functions which are being moved can all be marked
    static in their new locations, since they only have
    a single caller each. Their new locations are more
    logical than before and some of the functions are
    small enough that the compiler might well inline them.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index b56ba3db7771..efd09c3d2b26 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -585,6 +585,28 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 	return error;
 }
 
+static struct gfs2_jdesc *gfs2_jdesc_find_dirty(struct gfs2_sbd *sdp)
+{
+	struct gfs2_jdesc *jd;
+	int found = 0;
+
+	spin_lock(&sdp->sd_jindex_spin);
+
+	list_for_each_entry(jd, &sdp->sd_jindex_list, jd_list) {
+		if (jd->jd_dirty) {
+			jd->jd_dirty = 0;
+			found = 1;
+			break;
+		}
+	}
+	spin_unlock(&sdp->sd_jindex_spin);
+
+	if (!found)
+		jd = NULL;
+
+	return jd;
+}
+
 /**
  * gfs2_check_journals - Recover any dirty journals
  * @sdp: the filesystem

commit 9ac1b4d9b6f885ccd7d8f56bceb609003a920ff7
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed Nov 19 10:08:22 2008 +0000

    GFS2: Move gfs2_recoverd into recovery.c
    
    By moving gfs2_recoverd, we can make an additional function static
    and it also leaves only (the already scheduled for removal) gfs2_glockd
    in daemon.c.
    
    At the same time the declaration of gfs2_quotad is moved to quota.h
    to reflect the new location of gfs2_quotad in a previous patch. Also
    the recovery.h and quota.h headers are cleaned up.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index d5e91f4f6a0b..b56ba3db7771 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -14,6 +14,8 @@
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
 #include <linux/lm_interface.h>
+#include <linux/kthread.h>
+#include <linux/freezer.h>
 
 #include "gfs2.h"
 #include "incore.h"
@@ -589,7 +591,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
  *
  */
 
-void gfs2_check_journals(struct gfs2_sbd *sdp)
+static void gfs2_check_journals(struct gfs2_sbd *sdp)
 {
 	struct gfs2_jdesc *jd;
 
@@ -603,3 +605,25 @@ void gfs2_check_journals(struct gfs2_sbd *sdp)
 	}
 }
 
+/**
+ * gfs2_recoverd - Recover dead machine's journals
+ * @sdp: Pointer to GFS2 superblock
+ *
+ */
+
+int gfs2_recoverd(void *data)
+{
+	struct gfs2_sbd *sdp = data;
+	unsigned long t;
+
+	while (!kthread_should_stop()) {
+		gfs2_check_journals(sdp);
+		t = gfs2_tune_get(sdp,  gt_recoverd_secs) * HZ;
+		if (freezing(current))
+			refrigerator();
+		schedule_timeout_interruptible(t);
+	}
+
+	return 0;
+}
+

commit 048bca223739368aa5b9ce7cfb1d576c32d66cc7
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Fri May 23 14:46:04 2008 +0100

    [GFS2] No lock_nolock
    
    This patch merges the lock_nolock module into GFS2 itself. As well as removing
    some of the overhead of the module, it also means that its now impossible to
    build GFS2 without a lock module (which would be a pointless thing to do
    anyway).
    
    We also plan to merge lock_dlm into GFS2 in the future, but that is a more
    tricky task, and will therefore be a separate patch.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>
    Cc: David Teigland <teigland@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index fdd3f0f16d0d..d5e91f4f6a0b 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -428,6 +428,9 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *hea
 static void gfs2_lm_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
 				  unsigned int message)
 {
+	if (!sdp->sd_lockstruct.ls_ops->lm_recovery_done)
+		return;
+
 	if (likely(!test_bit(SDF_SHUTDOWN, &sdp->sd_flags)))
 		sdp->sd_lockstruct.ls_ops->lm_recovery_done(
 			sdp->sd_lockstruct.ls_lockspace, jid, message);

commit 6802e3400ff4549525930ee744030c36fce9cc73
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed May 21 17:03:22 2008 +0100

    [GFS2] Clean up the glock core
    
    This patch implements a number of cleanups to the core of the
    GFS2 glock code. As a result a lot of code is removed. It looks
    like a really big change, but actually a large part of this patch
    is either removing or moving existing code.
    
    There are some new bits too though, such as the new run_queue()
    function which is considerably streamlined. Highlights of this
    patch include:
    
     o Fixes a cluster coherency bug during SH -> EX lock conversions
     o Removes the "glmutex" code in favour of a single bit lock
     o Removes the ->go_xmote_bh() for inodes since it was duplicating
       ->go_lock()
     o We now only use the ->lm_lock() function for both locks and
       unlocks (i.e. unlock is a lock with target mode LM_ST_UNLOCKED)
     o The fast path is considerably shortly, giving performance gains
       especially with lock_nolock
     o The glock_workqueue is now used for all the callbacks from the DLM
       which allows us to simplify the lock_dlm module (see following patch)
     o The way is now open to make further changes such as eliminating the two
       threads (gfs2_glockd and gfs2_scand) in favour of a more efficient
       scheme.
    
    This patch has undergone extensive testing with various test suites
    so it should be pretty stable by now.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Bob Peterson <rpeterso@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 2888e4b4b1c5..fdd3f0f16d0d 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -505,7 +505,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 
 		error = gfs2_glock_nq_init(sdp->sd_trans_gl, LM_ST_SHARED,
 					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY |
-					   GL_NOCANCEL | GL_NOCACHE, &t_gh);
+					   GL_NOCACHE, &t_gh);
 		if (error)
 			goto fail_gunlock_ji;
 

commit 16c5f06f15ad4e5a5d6e90b78ffb1ac14319e445
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Apr 9 09:33:41 2008 -0400

    [GFS2] fix GFP_KERNEL misuses
    
    There are several places where GFP_KERNEL allocations happen under a glock,
    which will result in hangs if we're under memory pressure and go to re-enter the
    fs in order to flush stuff out.  This patch changes the culprits to GFS_NOFS to
    keep this problem from happening.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 06dcdc04627d..2888e4b4b1c5 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -68,7 +68,7 @@ int gfs2_revoke_add(struct gfs2_sbd *sdp, u64 blkno, unsigned int where)
 		return 0;
 	}
 
-	rr = kmalloc(sizeof(struct gfs2_revoke_replay), GFP_KERNEL);
+	rr = kmalloc(sizeof(struct gfs2_revoke_replay), GFP_NOFS);
 	if (!rr)
 		return -ENOMEM;
 

commit f5a8cd020173c455705fc0095b7d299da6f8f87b
Author: akpm@linux-foundation.org <akpm@linux-foundation.org>
Date:   Wed Mar 12 14:01:29 2008 -0700

    [GFS2] fs/gfs2/recovery.c: suppress warnings
    
    fs/gfs2/recovery.c: In function 'get_log_header':
    fs/gfs2/recovery.c:152: warning: 'lh.lh_sequence' may be used uninitialized in this function
    fs/gfs2/recovery.c:152: warning: 'lh.lh_flags' may be used uninitialized in this function
    fs/gfs2/recovery.c:152: warning: 'lh.lh_tail' may be used uninitialized in this function
    fs/gfs2/recovery.c:152: warning: 'lh.lh_blkno' may be used uninitialized in this function
    fs/gfs2/recovery.c:152: warning: 'lh.lh_hash' may be used uninitialized in this function
    
    Cc: David Teigland <teigland@redhat.com>
    Cc: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index b17d3b8b2321..06dcdc04627d 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -149,7 +149,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 			  struct gfs2_log_header_host *head)
 {
 	struct buffer_head *bh;
-	struct gfs2_log_header_host lh;
+	struct gfs2_log_header_host uninitialized_var(lh);
 	const u32 nothing = 0;
 	u32 hash;
 	int error;

commit da755fdb414470d6dce3df12ad188de9131cf96c
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed Jan 30 15:34:04 2008 +0000

    [GFS2] Remove lm.[ch] and distribute content
    
    The functions in lm.c were just wrappers which were mostly
    only used in one other file. By moving the functions to
    the files where they are being used, they can be marked
    static and also this will usually result in them being inlined
    since they are often only used from one point in the code.
    
    A couple of really trivial functions have been inlined by hand
    into the function which called them as it makes the code clearer
    to do that.
    
    We also gain from one fewer function call in the glock lock and
    unlock paths.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 6fb07d67ca8a..b17d3b8b2321 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -20,7 +20,6 @@
 #include "bmap.h"
 #include "glock.h"
 #include "glops.h"
-#include "lm.h"
 #include "lops.h"
 #include "meta_io.h"
 #include "recovery.h"
@@ -425,6 +424,16 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *hea
 	return error;
 }
 
+
+static void gfs2_lm_recovery_done(struct gfs2_sbd *sdp, unsigned int jid,
+				  unsigned int message)
+{
+	if (likely(!test_bit(SDF_SHUTDOWN, &sdp->sd_flags)))
+		sdp->sd_lockstruct.ls_ops->lm_recovery_done(
+			sdp->sd_lockstruct.ls_lockspace, jid, message);
+}
+
+
 /**
  * gfs2_recover_journal - recovery a given journal
  * @jd: the struct gfs2_jdesc describing the journal

commit c78bad11fbf1272ea021f56458025dc98486d6f4
Author: Joe Perches <joe@perches.com>
Date:   Sun Feb 3 17:33:42 2008 +0200

    fs/: Spelling fixes
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Adrian Bunk <bunk@kernel.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index b249e294a95b..6fb07d67ca8a 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -450,7 +450,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 		fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n",
 			jd->jd_jid);
 
-		/* Aquire the journal lock so we can do recovery */
+		/* Acquire the journal lock so we can do recovery */
 
 		error = gfs2_glock_nq_num(sdp, jd->jd_jid, &gfs2_journal_glops,
 					  LM_ST_EXCLUSIVE,

commit 7bc5c414fe6627ec518c82d154c796f0981f5b02
Author: Abhijith Das <adas@redhat.com>
Date:   Fri Jan 18 14:06:37 2008 -0600

    [GFS2] Allow journal recovery on read-only mount
    
    This patch allows gfs2 to perform journal recovery even if it is mounted
    read-only. Strictly speaking, a read-only mount should not be writing to
    the filesystem, but we do this only to perform journal recovery. A
    read-only mount will fail if we don't recover the dirty journal. Also,
    when gfs2 is used as a root filesystem, it will be mounted read-only
    before being mounted read-write during the boot sequence. A failed
    read-only mount will panic the machine during bootup.
    
    Signed-off-by: Abhijith Das <adas@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 27c994f2d1f0..b249e294a95b 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -504,13 +504,21 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 			if (!test_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags))
 				ro = 1;
 		} else {
-			if (sdp->sd_vfs->s_flags & MS_RDONLY)
-				ro = 1;
+			if (sdp->sd_vfs->s_flags & MS_RDONLY) {
+				/* check if device itself is read-only */
+				ro = bdev_read_only(sdp->sd_vfs->s_bdev);
+				if (!ro) {
+					fs_info(sdp, "recovery required on "
+						"read-only filesystem.\n");
+					fs_info(sdp, "write access will be "
+						"enabled during recovery.\n");
+				}
+			}
 		}
 
 		if (ro) {
-			fs_warn(sdp, "jid=%u: Can't replay: read-only FS\n",
-				jd->jd_jid);
+			fs_warn(sdp, "jid=%u: Can't replay: read-only block "
+				"device\n", jd->jd_jid);
 			error = -EROFS;
 			goto fail_gunlock_tr;
 		}

commit e9e1ef2b6ee401d7c1e1eb38052857b4b206d172
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Mon Dec 10 14:13:27 2007 -0600

    [GFS2] Remove function gfs2_get_block
    
    This patch is just a cleanup.  Function gfs2_get_block() just calls
    function gfs2_block_map reversing the last two parameters.  By
    reversing the parameters, gfs2_block_map() may be called directly
    and function gfs2_get_block may be eliminated altogether.
    Since this function is done for every block operation,
    this streamlines the code and makes it a little bit more efficient.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index beb6c7ac0086..27c994f2d1f0 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -391,7 +391,7 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *hea
 	lblock = head->lh_blkno;
 	gfs2_replay_incr_blk(sdp, &lblock);
 	bh_map.b_size = 1 << ip->i_inode.i_blkbits;
-	error = gfs2_block_map(&ip->i_inode, lblock, 0, &bh_map);
+	error = gfs2_block_map(&ip->i_inode, lblock, &bh_map, 0);
 	if (error)
 		return error;
 	if (!bh_map.b_blocknr) {

commit 75be73a8246ef96f7fa3f05a6a1450159fbb7a64
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Aug 8 17:08:14 2007 -0500

    [GFS2] Ensure journal file cache is flushed after recovery
    
    This is for bugzilla bug #248176: GFS2: invalid metadata block
    
    Patches 1 thru 3 were accepted upstream, but there were problems
    with 4 and 5.  Those issues have been resolved and now the recovery
    tests are passing without errors.  This code has gone through
    41 * 3 successful gfs2 recovery tests before it hit an
    unrelated (openais) problem.  I'm continuing to test it.
    
    This is a complete rewrite of patch 5 for bug #248176, written by
    Steve Whitehouse.  This is referred to in the bugzilla record as
    "new 6" and "a different solution".
    
    The problem was that the journal inodes, although protected by
    a glock, were not synched with the other nodes because they don't
    use the inode glock synch operations (i.e. no "glops" were defined).
    Therefore, journal recovery on a journal-recovering node were causing
    the blocks to get out of sync with the node that was actually trying
    to use that journal as it comes back up from a reboot.
    
    There are two possible solutions: (1) To make the journals use the
    normal inode glock sync operations, or (2) To make the journal
    operations take effect immediately (i.e. no caching).  Although
    option 1 works, it turns out to be a lot more code.  Steve opted
    for option 2, which is much simpler and therefore less prone to
    regression errors.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>
    
    --

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 5ada38c99a2c..beb6c7ac0086 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -469,7 +469,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 		};
 
 		error = gfs2_glock_nq_init(ip->i_gl, LM_ST_SHARED,
-					   LM_FLAG_NOEXP, &ji_gh);
+					   LM_FLAG_NOEXP | GL_NOCACHE, &ji_gh);
 		if (error)
 			goto fail_gunlock_j;
 	} else {

commit bb8d8a6f54c1c84d7c74623491bab043b36a38c5
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Fri Jun 1 14:11:58 2007 +0100

    [GFS2] Fix sign problem in quota/statfs and cleanup _host structures
    
    This patch fixes some sign issues which were accidentally introduced
    into the quota & statfs code during the endianess annotation process.
    Also included is a general clean up which moves all of the _host
    structures out of gfs2_ondisk.h (where they should not have been to
    start with) and into the places where they are actually used (often only
    one place). Also those _host structures which are not required any more
    are removed entirely (which is the eventual plan for all of them).
    
    The conversion routines from ondisk.c are also moved into the places
    where they are actually used, which for almost every one, was just one
    single place, so all those are now static functions. This also cleans up
    the end of gfs2_ondisk.h which no longer needs the #ifdef __KERNEL__.
    
    The net result is a reduction of about 100 lines of code, many functions
    now marked static plus the bug fixes as mentioned above. For good
    measure I ran the code through sparse after making these changes to
    check that there are no warnings generated.
    
    This fixes Red Hat bz #239686
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 8bc182c7e2ef..5ada38c99a2c 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -116,6 +116,22 @@ void gfs2_revoke_clean(struct gfs2_sbd *sdp)
 	}
 }
 
+static int gfs2_log_header_in(struct gfs2_log_header_host *lh, const void *buf)
+{
+	const struct gfs2_log_header *str = buf;
+
+	if (str->lh_header.mh_magic != cpu_to_be32(GFS2_MAGIC) ||
+	    str->lh_header.mh_type != cpu_to_be32(GFS2_METATYPE_LH))
+		return 1;
+
+	lh->lh_sequence = be64_to_cpu(str->lh_sequence);
+	lh->lh_flags = be32_to_cpu(str->lh_flags);
+	lh->lh_tail = be32_to_cpu(str->lh_tail);
+	lh->lh_blkno = be32_to_cpu(str->lh_blkno);
+	lh->lh_hash = be32_to_cpu(str->lh_hash);
+	return 0;
+}
+
 /**
  * get_log_header - read the log header for a given segment
  * @jd: the journal
@@ -147,12 +163,10 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 					     sizeof(u32));
 	hash = crc32_le(hash, (unsigned char const *)&nothing, sizeof(nothing));
 	hash ^= (u32)~0;
-	gfs2_log_header_in(&lh, bh->b_data);
+	error = gfs2_log_header_in(&lh, bh->b_data);
 	brelse(bh);
 
-	if (lh.lh_header.mh_magic != GFS2_MAGIC ||
-	    lh.lh_header.mh_type != GFS2_METATYPE_LH ||
-	    lh.lh_blkno != blk || lh.lh_hash != hash)
+	if (error || lh.lh_blkno != blk || lh.lh_hash != hash)
 		return 1;
 
 	*head = lh;

commit cd354f1ae75e6466a7e31b727faede57a1f89ca5
Author: Tim Schmielau <tim@physik3.uni-rostock.de>
Date:   Wed Feb 14 00:33:14 2007 -0800

    [PATCH] remove many unneeded #includes of sched.h
    
    After Al Viro (finally) succeeded in removing the sched.h #include in module.h
    recently, it makes sense again to remove other superfluous sched.h includes.
    There are quite a lot of files which include it but don't actually need
    anything defined in there.  Presumably these includes were once needed for
    macros that used to live in sched.h, but moved to other header files in the
    course of cleaning it up.
    
    To ease the pain, this time I did not fiddle with any header files and only
    removed #includes from .c-files, which tend to cause less trouble.
    
    Compile tested against 2.6.20-rc2 and 2.6.20-rc2-mm2 (with offsets) on alpha,
    arm, i386, ia64, mips, powerpc, and x86_64 with allnoconfig, defconfig,
    allmodconfig, and allyesconfig as well as a few randconfigs on x86_64 and all
    configs in arch/arm/configs on arm.  I also checked that no new warnings were
    introduced by the patch (actually, some warnings are removed that were emitted
    by unnecessarily included header files).
    
    Signed-off-by: Tim Schmielau <tim@physik3.uni-rostock.de>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index d0c806b85c86..8bc182c7e2ef 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -7,7 +7,6 @@
  * of the GNU General Public License version 2.
  */
 
-#include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/spinlock.h>
 #include <linux/completion.h>

commit 887bc5d00c02b32763845247024e8db5243ef857
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Tue Dec 5 13:34:17 2006 -0500

    [GFS2] Fix indent in recovery.c
    
    As per comments from Andrew Morton and Jan Engelhardt, this fixes the
    indent and removes the "static" from a variable declaration since its
    not needed in this case (now allocated on the stack of the function
    in question).
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Jan Engelhardt <jengelh@linux01.gwdg.de>
    Cc: Andrew Morton <akpm@osdl.org>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 4acf238e1db6..d0c806b85c86 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -136,7 +136,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 {
 	struct buffer_head *bh;
 	struct gfs2_log_header_host lh;
-static const u32 nothing = 0;
+	const u32 nothing = 0;
 	u32 hash;
 	int error;
 

commit 2a2c98247b822db8df037a56c27201f9d716ac66
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Tue Oct 31 14:44:50 2006 -0500

    [GFS2] Fix crc32 calculation in recovery.c
    
    Commit "[GFS2] split and annotate gfs2_log_head" resulted in an incorrect
    checksum calculation for log headers. This patch corrects the
    problem without resorting to copying the whole log header as
    the previous code used to.
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 447816241626..4acf238e1db6 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -136,6 +136,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 {
 	struct buffer_head *bh;
 	struct gfs2_log_header_host lh;
+static const u32 nothing = 0;
 	u32 hash;
 	int error;
 
@@ -143,11 +144,11 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 	if (error)
 		return error;
 
-	memcpy(&lh, bh->b_data, sizeof(struct gfs2_log_header));	/* XXX */
-	lh.lh_hash = 0;
-	hash = gfs2_disk_hash((char *)&lh, sizeof(struct gfs2_log_header));
+	hash = crc32_le((u32)~0, bh->b_data, sizeof(struct gfs2_log_header) -
+					     sizeof(u32));
+	hash = crc32_le(hash, (unsigned char const *)&nothing, sizeof(nothing));
+	hash ^= (u32)~0;
 	gfs2_log_header_in(&lh, bh->b_data);
-
 	brelse(bh);
 
 	if (lh.lh_header.mh_magic != GFS2_MAGIC ||

commit 551676226163379c217e8ec54bd287eab9b8521e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Oct 13 21:47:13 2006 -0400

    [GFS2] split and annotate gfs2_log_head
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 62cd223819b7..447816241626 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -132,10 +132,10 @@ void gfs2_revoke_clean(struct gfs2_sbd *sdp)
  */
 
 static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
-			  struct gfs2_log_header *head)
+			  struct gfs2_log_header_host *head)
 {
 	struct buffer_head *bh;
-	struct gfs2_log_header lh;
+	struct gfs2_log_header_host lh;
 	u32 hash;
 	int error;
 
@@ -143,7 +143,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 	if (error)
 		return error;
 
-	memcpy(&lh, bh->b_data, sizeof(struct gfs2_log_header));
+	memcpy(&lh, bh->b_data, sizeof(struct gfs2_log_header));	/* XXX */
 	lh.lh_hash = 0;
 	hash = gfs2_disk_hash((char *)&lh, sizeof(struct gfs2_log_header));
 	gfs2_log_header_in(&lh, bh->b_data);
@@ -174,7 +174,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
  */
 
 static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
-			struct gfs2_log_header *head)
+			struct gfs2_log_header_host *head)
 {
 	unsigned int orig_blk = *blk;
 	int error;
@@ -205,10 +205,10 @@ static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
  * Returns: errno
  */
 
-static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
+static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
 {
 	unsigned int blk = head->lh_blkno;
-	struct gfs2_log_header lh;
+	struct gfs2_log_header_host lh;
 	int error;
 
 	for (;;) {
@@ -245,9 +245,9 @@ static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
  * Returns: errno
  */
 
-int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
+int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
 {
-	struct gfs2_log_header lh_1, lh_m;
+	struct gfs2_log_header_host lh_1, lh_m;
 	u32 blk_1, blk_2, blk_m;
 	int error;
 
@@ -320,7 +320,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 		length = be32_to_cpu(ld->ld_length);
 
 		if (be32_to_cpu(ld->ld_header.mh_type) == GFS2_METATYPE_LH) {
-			struct gfs2_log_header lh;
+			struct gfs2_log_header_host lh;
 			error = get_log_header(jd, start, &lh);
 			if (!error) {
 				gfs2_replay_incr_blk(sdp, &start);
@@ -363,7 +363,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
  * Returns: errno
  */
 
-static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
+static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head)
 {
 	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
@@ -425,7 +425,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 {
 	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
-	struct gfs2_log_header head;
+	struct gfs2_log_header_host head;
 	struct gfs2_holder j_gh, ji_gh, t_gh;
 	unsigned long t;
 	int ro = 0;

commit 23591256d61354e20f12e98d7a496ad5c23de74c
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Fri Oct 13 17:25:45 2006 -0400

    [GFS2] Fix bmap to map extents properly
    
    This fix means that bmap will map extents of the length requested
    by the VFS rather than guessing at it, or just mapping one block
    at a time. The other callers of gfs2_block_map are audited to ensure
    they send the correct max extent lengths (i.e. set bh->b_size correctly).
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 0a8a4b87dcc6..62cd223819b7 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -372,11 +372,12 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 	u32 hash;
 	struct buffer_head *bh;
 	int error;
-	struct buffer_head bh_map;
+	struct buffer_head bh_map = { .b_state = 0, .b_blocknr = 0 };
 
 	lblock = head->lh_blkno;
 	gfs2_replay_incr_blk(sdp, &lblock);
-	error = gfs2_block_map(&ip->i_inode, lblock, 0, &bh_map, 1);
+	bh_map.b_size = 1 << ip->i_inode.i_blkbits;
+	error = gfs2_block_map(&ip->i_inode, lblock, 0, &bh_map);
 	if (error)
 		return error;
 	if (!bh_map.b_blocknr) {

commit 907b9bceb41fa46beae93f79cc4a2247df502c0f
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Sep 25 09:26:04 2006 -0400

    [GFS2/DLM] Fix trailing whitespace
    
    As per Andrew Morton's request, removed trailing whitespace.
    
    Cc: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 4d4ea7e66edc..0a8a4b87dcc6 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -444,11 +444,11 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 		switch (error) {
 		case 0:
 			break;
-	
+
 		case GLR_TRYFAILED:
 			fs_info(sdp, "jid=%u: Busy\n", jd->jd_jid);
 			error = 0;
-	
+
 		default:
 			goto fail;
 		};

commit 7276b3b0c77101f8b3f4e45e89a29cf9045e831a
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Thu Sep 21 17:05:23 2006 -0400

    [GFS2] Tidy up meta_io code
    
    Fix a bug in the directory reading code, where we might have dereferenced
    a NULL pointer in case of OOM. Updated the directory code to use the new
    & improved version of gfs2_meta_ra() which now returns the first block
    that was being read. Previously it was releasing it requiring following
    code to grab the block again at each point it was called.
    
    Also turned off readahead on directory lookups since we are reading a
    hash table, and therefore reading the entries in order is very
    unlikely. Readahead is still used for all other calls to the
    directory reading function (e.g. when growing the hash table).
    
    Removed the DIO_START constant. Everywhere this was used, it was
    used to unconditionally start i/o aside from a couple of places, so
    I've removed it and made the couple of exceptions to this rule into
    separate functions.
    
    Also hunted through the other DIO flags and removed them as arguments
    from functions which were always called with the same combination of
    arguments.
    
    Updated gfs2_meta_indirect_buffer to be a bit more efficient and
    hopefully also be a bit easier to read.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 518f9128137e..4d4ea7e66edc 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -47,8 +47,7 @@ int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 		return -EIO;
 	}
 
-	gfs2_meta_ra(gl, dblock, extlen);
-	error = gfs2_meta_read(gl, dblock, DIO_START | DIO_WAIT, bh);
+	*bh = gfs2_meta_ra(gl, dblock, extlen);
 
 	return error;
 }

commit 7d308590ae60d1f038a54a94e78a385c5c163452
Author: Fabio Massimo Di Nitto <fabbione@ubuntu.com>
Date:   Tue Sep 19 07:56:29 2006 +0200

    [GFS2] Export lm_interface to kernel headers
    
    
    lm_interface.h has a few out of the tree clients such as GFS1
    and userland tools.
    
    Right now, these clients keeps a copy of the file in their build tree
    that can go out of sync.
    
    Move lm_interface.h to include/linux, export it to userland and
    clean up fs/gfs2 to use the new location.
    
    Signed-off-by: Fabio M. Di Nitto <fabbione@ubuntu.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 130e9fbf9692..518f9128137e 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -14,9 +14,9 @@
 #include <linux/buffer_head.h>
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
+#include <linux/lm_interface.h>
 
 #include "gfs2.h"
-#include "lm_interface.h"
 #include "incore.h"
 #include "bmap.h"
 #include "glock.h"

commit 7a6bbacbb8dec6fbd1242c959250388f907d429e
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Sep 18 17:18:23 2006 -0400

    [GFS2] Map multiple blocks at once where possible
    
    This is a tidy up of the GFS2 bmap code. The main change is that the
    bh is passed to gfs2_block_map allowing the flags to be set directly
    rather than having to repeat that code several times in ops_address.c.
    
    At the same time, the extent mapping code from gfs2_extent_map has
    been moved into gfs2_block_map. This allows all calls to gfs2_block_map
    to map extents in the case that no allocation is taking place. As a
    result reads and non-allocating writes should be faster. A quick test
    with postmark appears to support this.
    
    There is a limit on the number of blocks mapped in a single bmap
    call in that it will only ever map blocks which are pointed to
    from a single pointer block. So in other words, it will never try
    to do additional i/o in order to satisfy read-ahead. The maximum
    number of blocks is thus somewhat less than 512 (the GFS2 4k block
    size minus the header divided by sizeof(u64)). I've further limited
    the mapping of "normal" blocks to 32 blocks (to avoid extra work)
    since readpages() will currently read a maximum of 32 blocks ahead (128k).
    
    Some further work will probably be needed to set a suitable value
    for DIO as well, but for now thats left at the maximum 512 (see
    ops_address.c:gfs2_get_block_direct).
    
    There is probably a lot more that can be done to improve bmap for GFS2,
    but this is a good first step.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index a27569c5d85e..130e9fbf9692 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -369,25 +369,23 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	unsigned int lblock;
-	int new = 0;
-	u64 dblock;
 	struct gfs2_log_header *lh;
 	u32 hash;
 	struct buffer_head *bh;
 	int error;
-	int boundary;
+	struct buffer_head bh_map;
 
 	lblock = head->lh_blkno;
 	gfs2_replay_incr_blk(sdp, &lblock);
-	error = gfs2_block_map(&ip->i_inode, lblock, &new, &dblock, &boundary);
+	error = gfs2_block_map(&ip->i_inode, lblock, 0, &bh_map, 1);
 	if (error)
 		return error;
-	if (!dblock) {
+	if (!bh_map.b_blocknr) {
 		gfs2_consist_inode(ip);
 		return -EIO;
 	}
 
-	bh = sb_getblk(sdp->sd_vfs, dblock);
+	bh = sb_getblk(sdp->sd_vfs, bh_map.b_blocknr);
 	lock_buffer(bh);
 	memset(bh->b_data, 0, bh->b_size);
 	set_buffer_uptodate(bh);

commit a67cdbd4579c387c021a17c7447da8b88f2a94f4
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Tue Sep 5 14:41:30 2006 -0400

    [GFS2] Style changes in logging code
    
    As per Jan Engelhardt's comments, removed some unused code and
    removed some brackets which were not required.
    
    Cc: Jan Engelhardt <jengelh@linux01.gwdg.de>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index ab55191926c3..a27569c5d85e 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -306,8 +306,8 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 	u32 length;
 	__be64 *ptr;
 	unsigned int offset = sizeof(struct gfs2_log_descriptor);
-	offset += (sizeof(__be64)-1);
-	offset &= ~(sizeof(__be64)-1);
+	offset += sizeof(__be64) - 1;
+	offset &= ~(sizeof(__be64) - 1);
 
 	while (start != end) {
 		error = gfs2_replay_read_block(jd, start, &bh);

commit cd915493fce912f1bd838ee1250737ecf33b8fae
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Sep 4 12:49:07 2006 -0400

    [GFS2] Change all types to uX style
    
    This makes all fixed size types have consistent names.
    
    Cc: Jan Engelhardt <jengelh@linux01.gwdg.de>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index acafe4b4d6f0..ab55191926c3 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -35,8 +35,8 @@ int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_glock *gl = ip->i_gl;
 	int new = 0;
-	uint64_t dblock;
-	uint32_t extlen;
+	u64 dblock;
+	u32 extlen;
 	int error;
 
 	error = gfs2_extent_map(&ip->i_inode, blk, &new, &dblock, &extlen);
@@ -53,7 +53,7 @@ int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 	return error;
 }
 
-int gfs2_revoke_add(struct gfs2_sbd *sdp, uint64_t blkno, unsigned int where)
+int gfs2_revoke_add(struct gfs2_sbd *sdp, u64 blkno, unsigned int where)
 {
 	struct list_head *head = &sdp->sd_revoke_list;
 	struct gfs2_revoke_replay *rr;
@@ -82,7 +82,7 @@ int gfs2_revoke_add(struct gfs2_sbd *sdp, uint64_t blkno, unsigned int where)
 	return 1;
 }
 
-int gfs2_revoke_check(struct gfs2_sbd *sdp, uint64_t blkno, unsigned int where)
+int gfs2_revoke_check(struct gfs2_sbd *sdp, u64 blkno, unsigned int where)
 {
 	struct gfs2_revoke_replay *rr;
 	int wrap, a, b, revoke;
@@ -137,7 +137,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 {
 	struct buffer_head *bh;
 	struct gfs2_log_header lh;
-	uint32_t hash;
+	u32 hash;
 	int error;
 
 	error = gfs2_replay_read_block(jd, blk, &bh);
@@ -249,7 +249,7 @@ static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 {
 	struct gfs2_log_header lh_1, lh_m;
-	uint32_t blk_1, blk_2, blk_m;
+	u32 blk_1, blk_2, blk_m;
 	int error;
 
 	blk_1 = 0;
@@ -370,9 +370,9 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	unsigned int lblock;
 	int new = 0;
-	uint64_t dblock;
+	u64 dblock;
 	struct gfs2_log_header *lh;
-	uint32_t hash;
+	u32 hash;
 	struct buffer_head *bh;
 	int error;
 	int boundary;

commit e9fc2aa091ab8fa46e60d4c9d06a89305c441652
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Fri Sep 1 11:05:15 2006 -0400

    [GFS2] Update copyright, tidy up incore.h
    
    As per comments from Jan Engelhardt <jengelh@linux01.gwdg.de> this
    updates the copyright message to say "version" in full rather than
    "v.2". Also incore.h has been updated to remove forward structure
    declarations which are not required.
    
    The gfs2_quota_lvb structure has now had endianess annotations added
    to it. Also quota.c has been updated so that we now store the
    lvb data locally in endian independant format to avoid needing
    a structure in host endianess too. As a result the endianess
    conversions are done as required at various points and thus the
    conversion routines in lvb.[ch] are no longer required. I've
    moved the one remaining constant in lvb.h thats used into lm.h
    and removed the unused lvb.[ch].
    
    I have not changed the HIF_ constants. That is left to a later patch
    which I hope will unify the gh_flags and gh_iflags fields of the
    struct gfs2_holder.
    
    Cc: Jan Engelhardt <jengelh@linux01.gwdg.de>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 8fe518cfb3de..acafe4b4d6f0 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -4,7 +4,7 @@
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
- * of the GNU General Public License v.2.
+ * of the GNU General Public License version 2.
  */
 
 #include <linux/sched.h>

commit 8872187780f6104216c67e7b60c11f708b513c38
Author: Russell Cattelan <cattelan@redhat.com>
Date:   Thu Aug 10 11:08:40 2006 -0500

    [GFS2] Fix a couple of refcount leaks.
    
    recovery.c add a brelse to deal with gfs2_replay_read_block being called
    twice on the same block.
    
    add a dput to drop the ref count on the root inode.
    This was causing lingering glocks and thus causing
    a mount failure to hang.
    
    Fix a endian conversion macro that was was swizzling
    16bits when it should have been swizzling 32.
    
    Signed-off-by: Russell Cattelan <cattelan@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index bbd44a4b1a1f..8fe518cfb3de 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -325,6 +325,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 			error = get_log_header(jd, start, &lh);
 			if (!error) {
 				gfs2_replay_incr_blk(sdp, &start);
+				brelse(bh);
 				continue;
 			}
 			if (error == 1) {
@@ -396,7 +397,7 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 	lh = (struct gfs2_log_header *)bh->b_data;
 	memset(lh, 0, sizeof(struct gfs2_log_header));
 	lh->lh_header.mh_magic = cpu_to_be32(GFS2_MAGIC);
-	lh->lh_header.mh_type = cpu_to_be16(GFS2_METATYPE_LH);
+	lh->lh_header.mh_type = cpu_to_be32(GFS2_METATYPE_LH);
 	lh->lh_header.mh_format = cpu_to_be32(GFS2_FORMAT_LH);
 	lh->lh_sequence = cpu_to_be64(head->lh_sequence + 1);
 	lh->lh_flags = cpu_to_be32(GFS2_LOG_HEAD_UNMOUNT);

commit 59a1cc6bdabf5ed148b48808ad1a418d87f5e6bf
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Fri Aug 4 15:41:22 2006 -0400

    [GFS2] Fix lock ordering bug in page fault path
    
    Mmapped files were able to trigger a lock ordering bug. Private
    maps do not need to take the glock so early on. Shared maps do
    unfortunately, however we can get around that by adding a flag
    into the flags for the struct gfs2_file. This only works because
    we are taking an exclusive lock at this point, so we know that
    nobody else can be racing with us.
    
    Fixes Red Hat bugzilla: #201196
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 7aabc03e4abd..bbd44a4b1a1f 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -153,8 +153,7 @@ static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
 
 	if (lh.lh_header.mh_magic != GFS2_MAGIC ||
 	    lh.lh_header.mh_type != GFS2_METATYPE_LH ||
-	    lh.lh_blkno != blk ||
-	    lh.lh_hash != hash)
+	    lh.lh_blkno != blk || lh.lh_hash != hash)
 		return 1;
 
 	*head = lh;
@@ -482,11 +481,9 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 
 		/* Acquire a shared hold on the transaction lock */
 
-		error = gfs2_glock_nq_init(sdp->sd_trans_gl,
-					   LM_ST_SHARED,
+		error = gfs2_glock_nq_init(sdp->sd_trans_gl, LM_ST_SHARED,
 					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY |
-					   GL_NOCANCEL | GL_NOCACHE,
-					   &t_gh);
+					   GL_NOCANCEL | GL_NOCACHE, &t_gh);
 		if (error)
 			goto fail_gunlock_ji;
 

commit feaa7bba026c181ce071d5a4884f7f9dd26207a1
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed Jun 14 15:32:57 2006 -0400

    [GFS2] Fix unlinked file handling
    
    This patch fixes the way we have been dealing with unlinked,
    but still open files. It removes all limits (other than memory
    for inodes, as per every other filesystem) on numbers of these
    which we can support on GFS2. It also means that (like other
    fs) its the responsibility of the last process to close the file
    to deallocate the storage, rather than the person who did the
    unlinking. Note that with GFS2, those two events might take place
    on different nodes.
    
    Also there are a number of other changes:
    
     o We use the Linux inode subsystem as it was intended to be
    used, wrt allocating GFS2 inodes
     o The Linux inode cache is now the point which we use for
    local enforcement of only holding one copy of the inode in
    core at once (previous to this we used the glock layer).
     o We no longer use the unlinked "special" file. We just ignore it
    completely. This makes unlinking more efficient.
     o We now use the 4th block allocation state. The previously unused
    state is used to track unlinked but still open inodes.
     o gfs2_inoded is no longer needed
     o Several fields are now no longer needed (and removed) from the in
    core struct gfs2_inode
     o Several fields are no longer needed (and removed) from the in core
    superblock
    
    There are a number of future possible optimisations and clean ups
    which have been made possible by this patch.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index c504ac1b831d..7aabc03e4abd 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -32,14 +32,14 @@
 int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 			   struct buffer_head **bh)
 {
-	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
+	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
 	struct gfs2_glock *gl = ip->i_gl;
 	int new = 0;
 	uint64_t dblock;
 	uint32_t extlen;
 	int error;
 
-	error = gfs2_extent_map(ip->i_vnode, blk, &new, &dblock, &extlen);
+	error = gfs2_extent_map(&ip->i_inode, blk, &new, &dblock, &extlen);
 	if (error)
 		return error;
 	if (!dblock) {
@@ -190,7 +190,7 @@ static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
 			*blk = 0;
 
 		if (*blk == orig_blk) {
-			gfs2_consist_inode(jd->jd_inode->u.generic_ip);
+			gfs2_consist_inode(GFS2_I(jd->jd_inode));
 			return -EIO;
 		}
 	}
@@ -224,7 +224,7 @@ static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 			continue;
 
 		if (lh.lh_sequence == head->lh_sequence) {
-			gfs2_consist_inode(jd->jd_inode->u.generic_ip);
+			gfs2_consist_inode(GFS2_I(jd->jd_inode));
 			return -EIO;
 		}
 		if (lh.lh_sequence < head->lh_sequence)
@@ -300,8 +300,7 @@ int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 			      unsigned int end, int pass)
 {
-	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
-	struct gfs2_sbd *sdp = ip->i_sbd;
+	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	struct buffer_head *bh;
 	struct gfs2_log_descriptor *ld;
 	int error = 0;
@@ -330,7 +329,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 				continue;
 			}
 			if (error == 1) {
-				gfs2_consist_inode(jd->jd_inode->u.generic_ip);
+				gfs2_consist_inode(GFS2_I(jd->jd_inode));
 				error = -EIO;
 			}
 			brelse(bh);
@@ -367,8 +366,8 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 
 static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 {
-	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
-	struct gfs2_sbd *sdp = ip->i_sbd;
+	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
+	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	unsigned int lblock;
 	int new = 0;
 	uint64_t dblock;
@@ -380,7 +379,7 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 
 	lblock = head->lh_blkno;
 	gfs2_replay_incr_blk(sdp, &lblock);
-	error = gfs2_block_map(ip->i_vnode, lblock, &new, &dblock, &boundary);
+	error = gfs2_block_map(&ip->i_inode, lblock, &new, &dblock, &boundary);
 	if (error)
 		return error;
 	if (!dblock) {
@@ -426,8 +425,8 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 
 int gfs2_recover_journal(struct gfs2_jdesc *jd)
 {
-	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
-	struct gfs2_sbd *sdp = ip->i_sbd;
+	struct gfs2_inode *ip = GFS2_I(jd->jd_inode);
+	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
 	struct gfs2_log_header head;
 	struct gfs2_holder j_gh, ji_gh, t_gh;
 	unsigned long t;

commit 3a8a9a1034813aa99f5ae3150f652d490c5ff10d
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Thu May 18 15:09:15 2006 -0400

    [GFS2] Update copyright date to 2006
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 527544b68a6f..c504ac1b831d 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -1,6 +1,6 @@
 /*
  * Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
- * Copyright (C) 2004-2005 Red Hat, Inc.  All rights reserved.
+ * Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions

commit bd8968010a9a08e67a0ddb3ddee9feb8882e8c2f
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Thu May 18 14:54:58 2006 -0400

    [GFS2] Remove semaphore.h from C files
    
    We no longer use semaphores, everything has been converted to
    mutex or rwsem, so we don't need to include this header any more.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 87adebea3bc3..527544b68a6f 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -14,7 +14,6 @@
 #include <linux/buffer_head.h>
 #include <linux/gfs2_ondisk.h>
 #include <linux/crc32.h>
-#include <asm/semaphore.h>
 
 #include "gfs2.h"
 #include "lm_interface.h"

commit fd88de569b802c4a04aaa6ee74667775f4aed8c6
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Fri May 5 16:59:11 2006 -0400

    [GFS2] Readpages support
    
    This adds readpages support (and also corrects a small bug in
    the readpage error path at the same time). Hopefully this will
    improve performance by allowing GFS to submit larger lumps of
    I/O at a time.
    
    In order to simplify the setting of BH_Boundary, it currently gets
    set when we hit the end of a indirect pointer block. There is
    always a boundary at this point with the current allocation code.
    It doesn't get all the boundaries right though, so there is still
    room for improvement in this.
    
    See comments in fs/gfs2/ops_address.c for further information about
    readpages with GFS2.
    
    Signed-off-by: Steven Whitehouse

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index d916817fb6e3..87adebea3bc3 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -40,8 +40,7 @@ int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 	uint32_t extlen;
 	int error;
 
-	error = gfs2_block_map(ip, blk, &new, &dblock,
-			       &extlen);
+	error = gfs2_extent_map(ip->i_vnode, blk, &new, &dblock, &extlen);
 	if (error)
 		return error;
 	if (!dblock) {
@@ -378,10 +377,11 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 	uint32_t hash;
 	struct buffer_head *bh;
 	int error;
-	
+	int boundary;
+
 	lblock = head->lh_blkno;
 	gfs2_replay_incr_blk(sdp, &lblock);
-	error = gfs2_block_map(ip, lblock, &new, &dblock, NULL);
+	error = gfs2_block_map(ip->i_vnode, lblock, &new, &dblock, &boundary);
 	if (error)
 		return error;
 	if (!dblock) {

commit 579b78a43b366d51f9c888afaf1eab1f4ea599fa
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed Apr 26 14:58:26 2006 -0400

    [GFS2] Remove GL_NEVER_RECURSE flag
    
    There is no point in keeping this flag since recursion is not
    now allowed for any glock.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 7d467966f92c..d916817fb6e3 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -487,8 +487,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 		error = gfs2_glock_nq_init(sdp->sd_trans_gl,
 					   LM_ST_SHARED,
 					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY |
-					   GL_NEVER_RECURSE | GL_NOCANCEL |
-					   GL_NOCACHE,
+					   GL_NOCANCEL | GL_NOCACHE,
 					   &t_gh);
 		if (error)
 			goto fail_gunlock_ji;

commit 5965b1f4792a1a9364b4e1ed6be8778a50eb981b
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Wed Apr 26 13:21:55 2006 -0400

    [GFS2] Don't do recursive locking in glock layer
    
    This patch changes the last user of recursive locking so that
    it no longer needs this feature and removes it from the glock
    layer. This makes the glock code a lot simpler and easier to
    understand. Its also a prerequsite to adding support for the
    AOP_TRUNCATED_PAGE return code (or at least it is if you don't
    want your brain to melt in the process)
    
    I've left in a couple of checks just in case there is some place
    else in the code which is still using this feature that I didn't
    spot yet, but they can probably be removed long term.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index e91c2bda6c32..7d467966f92c 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -436,30 +436,35 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 	unsigned int pass;
 	int error;
 
-	fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n", jd->jd_jid);
-
-	/* Aquire the journal lock so we can do recovery */
-
-	error = gfs2_glock_nq_num(sdp, jd->jd_jid, &gfs2_journal_glops,
-				  LM_ST_EXCLUSIVE,
-				  LM_FLAG_NOEXP | LM_FLAG_TRY | GL_NOCACHE,
-				  &j_gh);
-	switch (error) {
-	case 0:
-		break;
+	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid) {
+		fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n",
+			jd->jd_jid);
 
-	case GLR_TRYFAILED:
-		fs_info(sdp, "jid=%u: Busy\n", jd->jd_jid);
-		error = 0;
+		/* Aquire the journal lock so we can do recovery */
 
-	default:
-		goto fail;
-	};
+		error = gfs2_glock_nq_num(sdp, jd->jd_jid, &gfs2_journal_glops,
+					  LM_ST_EXCLUSIVE,
+					  LM_FLAG_NOEXP | LM_FLAG_TRY | GL_NOCACHE,
+					  &j_gh);
+		switch (error) {
+		case 0:
+			break;
+	
+		case GLR_TRYFAILED:
+			fs_info(sdp, "jid=%u: Busy\n", jd->jd_jid);
+			error = 0;
+	
+		default:
+			goto fail;
+		};
 
-	error = gfs2_glock_nq_init(ip->i_gl, LM_ST_SHARED,
-				   LM_FLAG_NOEXP, &ji_gh);
-	if (error)
-		goto fail_gunlock_j;
+		error = gfs2_glock_nq_init(ip->i_gl, LM_ST_SHARED,
+					   LM_FLAG_NOEXP, &ji_gh);
+		if (error)
+			goto fail_gunlock_j;
+	} else {
+		fs_info(sdp, "jid=%u, already locked for use\n", jd->jd_jid);
+	}
 
 	fs_info(sdp, "jid=%u: Looking at journal...\n", jd->jd_jid);
 
@@ -481,10 +486,8 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 
 		error = gfs2_glock_nq_init(sdp->sd_trans_gl,
 					   LM_ST_SHARED,
-					   LM_FLAG_NOEXP |
-					   LM_FLAG_PRIORITY |
-					   GL_NEVER_RECURSE |
-					   GL_NOCANCEL |
+					   LM_FLAG_NOEXP | LM_FLAG_PRIORITY |
+					   GL_NEVER_RECURSE | GL_NOCANCEL |
 					   GL_NOCACHE,
 					   &t_gh);
 		if (error)
@@ -521,37 +524,35 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd)
 			goto fail_gunlock_tr;
 
 		gfs2_glock_dq_uninit(&t_gh);
-
 		t = DIV_ROUND_UP(jiffies - t, HZ);
-		
 		fs_info(sdp, "jid=%u: Journal replayed in %lus\n",
 			jd->jd_jid, t);
 	}
 
-	gfs2_glock_dq_uninit(&ji_gh);
+	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid)
+		gfs2_glock_dq_uninit(&ji_gh);
 
 	gfs2_lm_recovery_done(sdp, jd->jd_jid, LM_RD_SUCCESS);
 
-	gfs2_glock_dq_uninit(&j_gh);
+	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid)
+		gfs2_glock_dq_uninit(&j_gh);
 
 	fs_info(sdp, "jid=%u: Done\n", jd->jd_jid);
-
 	return 0;
 
- fail_gunlock_tr:
+fail_gunlock_tr:
 	gfs2_glock_dq_uninit(&t_gh);
-
- fail_gunlock_ji:
-	gfs2_glock_dq_uninit(&ji_gh);
-
- fail_gunlock_j:
-	gfs2_glock_dq_uninit(&j_gh);
+fail_gunlock_ji:
+	if (jd->jd_jid != sdp->sd_lockstruct.ls_jid) {
+		gfs2_glock_dq_uninit(&ji_gh);
+fail_gunlock_j:
+		gfs2_glock_dq_uninit(&j_gh);
+	}
 
 	fs_info(sdp, "jid=%u: %s\n", jd->jd_jid, (error) ? "Failed" : "Done");
 
- fail:
+fail:
 	gfs2_lm_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
-
 	return error;
 }
 

commit c63e31c2cc1ec67372920b5e1aff8204d04dd172
Author: David Teigland <teigland@redhat.com>
Date:   Thu Apr 20 17:03:48 2006 -0400

    [GFS2] journal recovery patch
    
    This is one of the changes related to journal recovery I mentioned a
    couple weeks ago.  We can get into a situation where there are only
    readonly nodes currently mounting the fs, but there are journals that need
    to be recovered.  Since the readonly nodes can't recover journals, the
    next rw mounter needs to go through and check all journals and recover any
    that are dirty (i.e. what the first node to mount the fs does).  This rw
    mounter needs to skip the journals held by the existing readonly nodes.
    Skipping those journals amounts to using the TRY flag on the journal locks
    so acquiring the lock of a journal held by a readonly node will fail
    instead of blocking indefinately.
    
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 68c85610fb5b..e91c2bda6c32 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -418,7 +418,6 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 /**
  * gfs2_recover_journal - recovery a given journal
  * @jd: the struct gfs2_jdesc describing the journal
- * @wait: Don't return until the journal is clean (or an error is encountered)
  *
  * Acquire the journal's lock, check to see if the journal is clean, and
  * do recovery if necessary.
@@ -426,7 +425,7 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
  * Returns: errno
  */
 
-int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
+int gfs2_recover_journal(struct gfs2_jdesc *jd)
 {
 	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
 	struct gfs2_sbd *sdp = ip->i_sbd;
@@ -441,12 +440,10 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
 
 	/* Aquire the journal lock so we can do recovery */
 
-	error = gfs2_glock_nq_num(sdp,
-				  jd->jd_jid, &gfs2_journal_glops,
+	error = gfs2_glock_nq_num(sdp, jd->jd_jid, &gfs2_journal_glops,
 				  LM_ST_EXCLUSIVE,
-				  LM_FLAG_NOEXP |
-				  ((wait) ? 0 : LM_FLAG_TRY) |
-				  GL_NOCACHE, &j_gh);
+				  LM_FLAG_NOEXP | LM_FLAG_TRY | GL_NOCACHE,
+				  &j_gh);
 	switch (error) {
 	case 0:
 		break;
@@ -574,7 +571,7 @@ void gfs2_check_journals(struct gfs2_sbd *sdp)
 			break;
 
 		if (jd != sdp->sd_jdesc)
-			gfs2_recover_journal(jd, NO_WAIT);
+			gfs2_recover_journal(jd);
 	}
 }
 

commit e3167ded1f1b16424bc14d5673cdc5414f179970
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Thu Mar 30 15:46:23 2006 -0500

    [GFS] Fix bug in endian conversion for metadata header
    
    In some cases 16 bit functions were being used rather than 32 bit
    functions.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 6c7e2e880e32..68c85610fb5b 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -324,7 +324,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 		ld = (struct gfs2_log_descriptor *)bh->b_data;
 		length = be32_to_cpu(ld->ld_length);
 
-		if (be16_to_cpu(ld->ld_header.mh_type) == GFS2_METATYPE_LH) {
+		if (be32_to_cpu(ld->ld_header.mh_type) == GFS2_METATYPE_LH) {
 			struct gfs2_log_header lh;
 			error = get_log_header(jd, start, &lh);
 			if (!error) {
@@ -400,7 +400,7 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 	memset(lh, 0, sizeof(struct gfs2_log_header));
 	lh->lh_header.mh_magic = cpu_to_be32(GFS2_MAGIC);
 	lh->lh_header.mh_type = cpu_to_be16(GFS2_METATYPE_LH);
-	lh->lh_header.mh_format = cpu_to_be16(GFS2_FORMAT_LH);
+	lh->lh_header.mh_format = cpu_to_be32(GFS2_FORMAT_LH);
 	lh->lh_sequence = cpu_to_be64(head->lh_sequence + 1);
 	lh->lh_flags = cpu_to_be32(GFS2_LOG_HEAD_UNMOUNT);
 	lh->lh_blkno = cpu_to_be32(lblock);

commit 71b86f562b5eb6f94ea00bba060caa64d0137969
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Tue Mar 28 14:14:04 2006 -0500

    [GFS2] Further updates to dir and logging code
    
    This reduces the size of the directory code by about 3k and gets
    readdir() to use the functions which were introduced in the previous
    directory code update.
    
    Two memory allocations are merged into one. Eliminates zeroing of some
    buffers which were never used before they were initialised by
    other data.
    
    There is still scope for further improvement in the directory code.
    
    On the logging side, a hand created mutex has been replaced by a
    standard Linux mutex in the log allocation code.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 2df450e2f433..6c7e2e880e32 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -13,6 +13,7 @@
 #include <linux/completion.h>
 #include <linux/buffer_head.h>
 #include <linux/gfs2_ondisk.h>
+#include <linux/crc32.h>
 #include <asm/semaphore.h>
 
 #include "gfs2.h"
@@ -27,6 +28,7 @@
 #include "recovery.h"
 #include "super.h"
 #include "util.h"
+#include "dir.h"
 
 int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 			   struct buffer_head **bh)

commit 5c676f6d359b0404d53f542f02e1359583cb2895
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Feb 27 17:23:27 2006 -0500

    [GFS2] Macros removal in gfs2.h
    
    As suggested by Pekka Enberg <penberg@cs.helsinki.fi>.
    
    The DIV_RU macro is renamed DIV_ROUND_UP and and moved to kernel.h
    The other macros are gone from gfs2.h as (although not requested
    by Pekka Enberg) are a number of included header file which are now
    included individually. The inode number comparison function is
    now an inline function.
    
    The DT2IF and IF2DT may be addressed in a future patch.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index e5f2b284fa54..2df450e2f433 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -12,9 +12,12 @@
 #include <linux/spinlock.h>
 #include <linux/completion.h>
 #include <linux/buffer_head.h>
+#include <linux/gfs2_ondisk.h>
 #include <asm/semaphore.h>
 
 #include "gfs2.h"
+#include "lm_interface.h"
+#include "incore.h"
 #include "bmap.h"
 #include "glock.h"
 #include "glops.h"
@@ -23,22 +26,24 @@
 #include "meta_io.h"
 #include "recovery.h"
 #include "super.h"
+#include "util.h"
 
 int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 			   struct buffer_head **bh)
 {
-	struct gfs2_glock *gl = get_v2ip(jd->jd_inode)->i_gl;
+	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
+	struct gfs2_glock *gl = ip->i_gl;
 	int new = 0;
 	uint64_t dblock;
 	uint32_t extlen;
 	int error;
 
-	error = gfs2_block_map(get_v2ip(jd->jd_inode), blk, &new, &dblock,
+	error = gfs2_block_map(ip, blk, &new, &dblock,
 			       &extlen);
 	if (error)
 		return error;
 	if (!dblock) {
-		gfs2_consist_inode(get_v2ip(jd->jd_inode));
+		gfs2_consist_inode(ip);
 		return -EIO;
 	}
 
@@ -185,7 +190,7 @@ static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
 			*blk = 0;
 
 		if (*blk == orig_blk) {
-			gfs2_consist_inode(get_v2ip(jd->jd_inode));
+			gfs2_consist_inode(jd->jd_inode->u.generic_ip);
 			return -EIO;
 		}
 	}
@@ -219,7 +224,7 @@ static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 			continue;
 
 		if (lh.lh_sequence == head->lh_sequence) {
-			gfs2_consist_inode(get_v2ip(jd->jd_inode));
+			gfs2_consist_inode(jd->jd_inode->u.generic_ip);
 			return -EIO;
 		}
 		if (lh.lh_sequence < head->lh_sequence)
@@ -295,7 +300,8 @@ int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 			      unsigned int end, int pass)
 {
-	struct gfs2_sbd *sdp = get_v2ip(jd->jd_inode)->i_sbd;
+	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
+	struct gfs2_sbd *sdp = ip->i_sbd;
 	struct buffer_head *bh;
 	struct gfs2_log_descriptor *ld;
 	int error = 0;
@@ -324,7 +330,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 				continue;
 			}
 			if (error == 1) {
-				gfs2_consist_inode(get_v2ip(jd->jd_inode));
+				gfs2_consist_inode(jd->jd_inode->u.generic_ip);
 				error = -EIO;
 			}
 			brelse(bh);
@@ -361,7 +367,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 
 static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 {
-	struct gfs2_inode *ip = get_v2ip(jd->jd_inode);
+	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
 	struct gfs2_sbd *sdp = ip->i_sbd;
 	unsigned int lblock;
 	int new = 0;
@@ -420,7 +426,8 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 
 int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
 {
-	struct gfs2_sbd *sdp = get_v2ip(jd->jd_inode)->i_sbd;
+	struct gfs2_inode *ip = jd->jd_inode->u.generic_ip;
+	struct gfs2_sbd *sdp = ip->i_sbd;
 	struct gfs2_log_header head;
 	struct gfs2_holder j_gh, ji_gh, t_gh;
 	unsigned long t;
@@ -450,7 +457,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
 		goto fail;
 	};
 
-	error = gfs2_glock_nq_init(get_v2ip(jd->jd_inode)->i_gl, LM_ST_SHARED,
+	error = gfs2_glock_nq_init(ip->i_gl, LM_ST_SHARED,
 				   LM_FLAG_NOEXP, &ji_gh);
 	if (error)
 		goto fail_gunlock_j;
@@ -516,7 +523,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
 
 		gfs2_glock_dq_uninit(&t_gh);
 
-		t = DIV_RU(jiffies - t, HZ);
+		t = DIV_ROUND_UP(jiffies - t, HZ);
 		
 		fs_info(sdp, "jid=%u: Journal replayed in %lus\n",
 			jd->jd_jid, t);

commit 568f4c9659a2225b0d29cf86feecbcf25c9045c8
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Feb 27 12:00:42 2006 -0500

    [GFS2] 80 Column audit of GFS2
    
    Requested by:
    Prarit Bhargava <prarit@redhat.com>
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index bcb81c768c8b..e5f2b284fa54 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -33,7 +33,8 @@ int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 	uint32_t extlen;
 	int error;
 
-	error = gfs2_block_map(get_v2ip(jd->jd_inode), blk, &new, &dblock, &extlen);
+	error = gfs2_block_map(get_v2ip(jd->jd_inode), blk, &new, &dblock,
+			       &extlen);
 	if (error)
 		return error;
 	if (!dblock) {

commit 7359a19cc758946aba0e45233b8641256b194884
Author: Steven Whitehouse <swhiteho@redhat.com>
Date:   Mon Feb 13 12:27:43 2006 +0000

    [GFS2] Fix for root inode ref count bug
    
    Umount is now working correctly again. The bug was due to
    not getting an extra ref count when mounting the fs. We
    should have bumped it by two (once for the internal pointer
    to the root inode from the super block and once for the
    inode hanging off the dcache entry for root).
    
    Also this patch tidys up the code dealing with looking up
    and creating inodes. We now pass Linux inodes (with gfs2_inodes
    attached) rather than the other way around and this reduces code
    duplication in various places.
    
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
index 15cd26fbcff9..bcb81c768c8b 100644
--- a/fs/gfs2/recovery.c
+++ b/fs/gfs2/recovery.c
@@ -27,17 +27,17 @@
 int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
 			   struct buffer_head **bh)
 {
-	struct gfs2_glock *gl = jd->jd_inode->i_gl;
+	struct gfs2_glock *gl = get_v2ip(jd->jd_inode)->i_gl;
 	int new = 0;
 	uint64_t dblock;
 	uint32_t extlen;
 	int error;
 
-	error = gfs2_block_map(jd->jd_inode, blk, &new, &dblock, &extlen);
+	error = gfs2_block_map(get_v2ip(jd->jd_inode), blk, &new, &dblock, &extlen);
 	if (error)
 		return error;
 	if (!dblock) {
-		gfs2_consist_inode(jd->jd_inode);
+		gfs2_consist_inode(get_v2ip(jd->jd_inode));
 		return -EIO;
 	}
 
@@ -184,7 +184,7 @@ static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
 			*blk = 0;
 
 		if (*blk == orig_blk) {
-			gfs2_consist_inode(jd->jd_inode);
+			gfs2_consist_inode(get_v2ip(jd->jd_inode));
 			return -EIO;
 		}
 	}
@@ -218,7 +218,7 @@ static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 			continue;
 
 		if (lh.lh_sequence == head->lh_sequence) {
-			gfs2_consist_inode(jd->jd_inode);
+			gfs2_consist_inode(get_v2ip(jd->jd_inode));
 			return -EIO;
 		}
 		if (lh.lh_sequence < head->lh_sequence)
@@ -294,7 +294,7 @@ int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 			      unsigned int end, int pass)
 {
-	struct gfs2_sbd *sdp = jd->jd_inode->i_sbd;
+	struct gfs2_sbd *sdp = get_v2ip(jd->jd_inode)->i_sbd;
 	struct buffer_head *bh;
 	struct gfs2_log_descriptor *ld;
 	int error = 0;
@@ -323,7 +323,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 				continue;
 			}
 			if (error == 1) {
-				gfs2_consist_inode(jd->jd_inode);
+				gfs2_consist_inode(get_v2ip(jd->jd_inode));
 				error = -EIO;
 			}
 			brelse(bh);
@@ -360,7 +360,7 @@ static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
 
 static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 {
-	struct gfs2_inode *ip = jd->jd_inode;
+	struct gfs2_inode *ip = get_v2ip(jd->jd_inode);
 	struct gfs2_sbd *sdp = ip->i_sbd;
 	unsigned int lblock;
 	int new = 0;
@@ -419,7 +419,7 @@ static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
 
 int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
 {
-	struct gfs2_sbd *sdp = jd->jd_inode->i_sbd;
+	struct gfs2_sbd *sdp = get_v2ip(jd->jd_inode)->i_sbd;
 	struct gfs2_log_header head;
 	struct gfs2_holder j_gh, ji_gh, t_gh;
 	unsigned long t;
@@ -449,7 +449,7 @@ int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
 		goto fail;
 	};
 
-	error = gfs2_glock_nq_init(jd->jd_inode->i_gl, LM_ST_SHARED,
+	error = gfs2_glock_nq_init(get_v2ip(jd->jd_inode)->i_gl, LM_ST_SHARED,
 				   LM_FLAG_NOEXP, &ji_gh);
 	if (error)
 		goto fail_gunlock_j;

commit b3b94faa5fe5968827ba0640ee9fba4b3e7f736e
Author: David Teigland <teigland@redhat.com>
Date:   Mon Jan 16 16:50:04 2006 +0000

    [GFS2] The core of GFS2
    
    This patch contains all the core files for GFS2.
    
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Steven Whitehouse <swhiteho@redhat.com>

diff --git a/fs/gfs2/recovery.c b/fs/gfs2/recovery.c
new file mode 100644
index 000000000000..15cd26fbcff9
--- /dev/null
+++ b/fs/gfs2/recovery.c
@@ -0,0 +1,570 @@
+/*
+ * Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
+ * Copyright (C) 2004-2005 Red Hat, Inc.  All rights reserved.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU General Public License v.2.
+ */
+
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/completion.h>
+#include <linux/buffer_head.h>
+#include <asm/semaphore.h>
+
+#include "gfs2.h"
+#include "bmap.h"
+#include "glock.h"
+#include "glops.h"
+#include "lm.h"
+#include "lops.h"
+#include "meta_io.h"
+#include "recovery.h"
+#include "super.h"
+
+int gfs2_replay_read_block(struct gfs2_jdesc *jd, unsigned int blk,
+			   struct buffer_head **bh)
+{
+	struct gfs2_glock *gl = jd->jd_inode->i_gl;
+	int new = 0;
+	uint64_t dblock;
+	uint32_t extlen;
+	int error;
+
+	error = gfs2_block_map(jd->jd_inode, blk, &new, &dblock, &extlen);
+	if (error)
+		return error;
+	if (!dblock) {
+		gfs2_consist_inode(jd->jd_inode);
+		return -EIO;
+	}
+
+	gfs2_meta_ra(gl, dblock, extlen);
+	error = gfs2_meta_read(gl, dblock, DIO_START | DIO_WAIT, bh);
+
+	return error;
+}
+
+int gfs2_revoke_add(struct gfs2_sbd *sdp, uint64_t blkno, unsigned int where)
+{
+	struct list_head *head = &sdp->sd_revoke_list;
+	struct gfs2_revoke_replay *rr;
+	int found = 0;
+
+	list_for_each_entry(rr, head, rr_list) {
+		if (rr->rr_blkno == blkno) {
+			found = 1;
+			break;
+		}
+	}
+
+	if (found) {
+		rr->rr_where = where;
+		return 0;
+	}
+
+	rr = kmalloc(sizeof(struct gfs2_revoke_replay), GFP_KERNEL);
+	if (!rr)
+		return -ENOMEM;
+
+	rr->rr_blkno = blkno;
+	rr->rr_where = where;
+	list_add(&rr->rr_list, head);
+
+	return 1;
+}
+
+int gfs2_revoke_check(struct gfs2_sbd *sdp, uint64_t blkno, unsigned int where)
+{
+	struct gfs2_revoke_replay *rr;
+	int wrap, a, b, revoke;
+	int found = 0;
+
+	list_for_each_entry(rr, &sdp->sd_revoke_list, rr_list) {
+		if (rr->rr_blkno == blkno) {
+			found = 1;
+			break;
+		}
+	}
+
+	if (!found)
+		return 0;
+
+	wrap = (rr->rr_where < sdp->sd_replay_tail);
+	a = (sdp->sd_replay_tail < where);
+	b = (where < rr->rr_where);
+	revoke = (wrap) ? (a || b) : (a && b);
+
+	return revoke;
+}
+
+void gfs2_revoke_clean(struct gfs2_sbd *sdp)
+{
+	struct list_head *head = &sdp->sd_revoke_list;
+	struct gfs2_revoke_replay *rr;
+
+	while (!list_empty(head)) {
+		rr = list_entry(head->next, struct gfs2_revoke_replay, rr_list);
+		list_del(&rr->rr_list);
+		kfree(rr);
+	}
+}
+
+/**
+ * get_log_header - read the log header for a given segment
+ * @jd: the journal
+ * @blk: the block to look at
+ * @lh: the log header to return
+ *
+ * Read the log header for a given segement in a given journal.  Do a few
+ * sanity checks on it.
+ *
+ * Returns: 0 on success,
+ *          1 if the header was invalid or incomplete,
+ *          errno on error
+ */
+
+static int get_log_header(struct gfs2_jdesc *jd, unsigned int blk,
+			  struct gfs2_log_header *head)
+{
+	struct buffer_head *bh;
+	struct gfs2_log_header lh;
+	uint32_t hash;
+	int error;
+
+	error = gfs2_replay_read_block(jd, blk, &bh);
+	if (error)
+		return error;
+
+	memcpy(&lh, bh->b_data, sizeof(struct gfs2_log_header));
+	lh.lh_hash = 0;
+	hash = gfs2_disk_hash((char *)&lh, sizeof(struct gfs2_log_header));
+	gfs2_log_header_in(&lh, bh->b_data);
+
+	brelse(bh);
+
+	if (lh.lh_header.mh_magic != GFS2_MAGIC ||
+	    lh.lh_header.mh_type != GFS2_METATYPE_LH ||
+	    lh.lh_blkno != blk ||
+	    lh.lh_hash != hash)
+		return 1;
+
+	*head = lh;
+
+	return 0;
+}
+
+/**
+ * find_good_lh - find a good log header
+ * @jd: the journal
+ * @blk: the segment to start searching from
+ * @lh: the log header to fill in
+ * @forward: if true search forward in the log, else search backward
+ *
+ * Call get_log_header() to get a log header for a segment, but if the
+ * segment is bad, either scan forward or backward until we find a good one.
+ *
+ * Returns: errno
+ */
+
+static int find_good_lh(struct gfs2_jdesc *jd, unsigned int *blk,
+			struct gfs2_log_header *head)
+{
+	unsigned int orig_blk = *blk;
+	int error;
+
+	for (;;) {
+		error = get_log_header(jd, *blk, head);
+		if (error <= 0)
+			return error;
+
+		if (++*blk == jd->jd_blocks)
+			*blk = 0;
+
+		if (*blk == orig_blk) {
+			gfs2_consist_inode(jd->jd_inode);
+			return -EIO;
+		}
+	}
+}
+
+/**
+ * jhead_scan - make sure we've found the head of the log
+ * @jd: the journal
+ * @head: this is filled in with the log descriptor of the head
+ *
+ * At this point, seg and lh should be either the head of the log or just
+ * before.  Scan forward until we find the head.
+ *
+ * Returns: errno
+ */
+
+static int jhead_scan(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
+{
+	unsigned int blk = head->lh_blkno;
+	struct gfs2_log_header lh;
+	int error;
+
+	for (;;) {
+		if (++blk == jd->jd_blocks)
+			blk = 0;
+
+		error = get_log_header(jd, blk, &lh);
+		if (error < 0)
+			return error;
+		if (error == 1)
+			continue;
+
+		if (lh.lh_sequence == head->lh_sequence) {
+			gfs2_consist_inode(jd->jd_inode);
+			return -EIO;
+		}
+		if (lh.lh_sequence < head->lh_sequence)
+			break;
+
+		*head = lh;
+	}
+
+	return 0;
+}
+
+/**
+ * gfs2_find_jhead - find the head of a log
+ * @jd: the journal
+ * @head: the log descriptor for the head of the log is returned here
+ *
+ * Do a binary search of a journal and find the valid log entry with the
+ * highest sequence number.  (i.e. the log head)
+ *
+ * Returns: errno
+ */
+
+int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
+{
+	struct gfs2_log_header lh_1, lh_m;
+	uint32_t blk_1, blk_2, blk_m;
+	int error;
+
+	blk_1 = 0;
+	blk_2 = jd->jd_blocks - 1;
+
+	for (;;) {
+		blk_m = (blk_1 + blk_2) / 2;
+
+		error = find_good_lh(jd, &blk_1, &lh_1);
+		if (error)
+			return error;
+
+		error = find_good_lh(jd, &blk_m, &lh_m);
+		if (error)
+			return error;
+
+		if (blk_1 == blk_m || blk_m == blk_2)
+			break;
+
+		if (lh_1.lh_sequence <= lh_m.lh_sequence)
+			blk_1 = blk_m;
+		else
+			blk_2 = blk_m;
+	}
+
+	error = jhead_scan(jd, &lh_1);
+	if (error)
+		return error;
+
+	*head = lh_1;
+
+	return error;
+}
+
+/**
+ * foreach_descriptor - go through the active part of the log
+ * @jd: the journal
+ * @start: the first log header in the active region
+ * @end: the last log header (don't process the contents of this entry))
+ *
+ * Call a given function once for every log descriptor in the active
+ * portion of the log.
+ *
+ * Returns: errno
+ */
+
+static int foreach_descriptor(struct gfs2_jdesc *jd, unsigned int start,
+			      unsigned int end, int pass)
+{
+	struct gfs2_sbd *sdp = jd->jd_inode->i_sbd;
+	struct buffer_head *bh;
+	struct gfs2_log_descriptor *ld;
+	int error = 0;
+	u32 length;
+	__be64 *ptr;
+	unsigned int offset = sizeof(struct gfs2_log_descriptor);
+	offset += (sizeof(__be64)-1);
+	offset &= ~(sizeof(__be64)-1);
+
+	while (start != end) {
+		error = gfs2_replay_read_block(jd, start, &bh);
+		if (error)
+			return error;
+		if (gfs2_meta_check(sdp, bh)) {
+			brelse(bh);
+			return -EIO;
+		}
+		ld = (struct gfs2_log_descriptor *)bh->b_data;
+		length = be32_to_cpu(ld->ld_length);
+
+		if (be16_to_cpu(ld->ld_header.mh_type) == GFS2_METATYPE_LH) {
+			struct gfs2_log_header lh;
+			error = get_log_header(jd, start, &lh);
+			if (!error) {
+				gfs2_replay_incr_blk(sdp, &start);
+				continue;
+			}
+			if (error == 1) {
+				gfs2_consist_inode(jd->jd_inode);
+				error = -EIO;
+			}
+			brelse(bh);
+			return error;
+		} else if (gfs2_metatype_check(sdp, bh, GFS2_METATYPE_LD)) {
+			brelse(bh);
+			return -EIO;
+		}
+		ptr = (__be64 *)(bh->b_data + offset);
+		error = lops_scan_elements(jd, start, ld, ptr, pass);
+		if (error) {
+			brelse(bh);
+			return error;
+		}
+
+		while (length--)
+			gfs2_replay_incr_blk(sdp, &start);
+
+		brelse(bh);
+	}
+
+	return 0;
+}
+
+/**
+ * clean_journal - mark a dirty journal as being clean
+ * @sdp: the filesystem
+ * @jd: the journal
+ * @gl: the journal's glock
+ * @head: the head journal to start from
+ *
+ * Returns: errno
+ */
+
+static int clean_journal(struct gfs2_jdesc *jd, struct gfs2_log_header *head)
+{
+	struct gfs2_inode *ip = jd->jd_inode;
+	struct gfs2_sbd *sdp = ip->i_sbd;
+	unsigned int lblock;
+	int new = 0;
+	uint64_t dblock;
+	struct gfs2_log_header *lh;
+	uint32_t hash;
+	struct buffer_head *bh;
+	int error;
+	
+	lblock = head->lh_blkno;
+	gfs2_replay_incr_blk(sdp, &lblock);
+	error = gfs2_block_map(ip, lblock, &new, &dblock, NULL);
+	if (error)
+		return error;
+	if (!dblock) {
+		gfs2_consist_inode(ip);
+		return -EIO;
+	}
+
+	bh = sb_getblk(sdp->sd_vfs, dblock);
+	lock_buffer(bh);
+	memset(bh->b_data, 0, bh->b_size);
+	set_buffer_uptodate(bh);
+	clear_buffer_dirty(bh);
+	unlock_buffer(bh);
+
+	lh = (struct gfs2_log_header *)bh->b_data;
+	memset(lh, 0, sizeof(struct gfs2_log_header));
+	lh->lh_header.mh_magic = cpu_to_be32(GFS2_MAGIC);
+	lh->lh_header.mh_type = cpu_to_be16(GFS2_METATYPE_LH);
+	lh->lh_header.mh_format = cpu_to_be16(GFS2_FORMAT_LH);
+	lh->lh_sequence = cpu_to_be64(head->lh_sequence + 1);
+	lh->lh_flags = cpu_to_be32(GFS2_LOG_HEAD_UNMOUNT);
+	lh->lh_blkno = cpu_to_be32(lblock);
+	hash = gfs2_disk_hash((const char *)lh, sizeof(struct gfs2_log_header));
+	lh->lh_hash = cpu_to_be32(hash);
+
+	set_buffer_dirty(bh);
+	if (sync_dirty_buffer(bh))
+		gfs2_io_error_bh(sdp, bh);
+	brelse(bh);
+
+	return error;
+}
+
+/**
+ * gfs2_recover_journal - recovery a given journal
+ * @jd: the struct gfs2_jdesc describing the journal
+ * @wait: Don't return until the journal is clean (or an error is encountered)
+ *
+ * Acquire the journal's lock, check to see if the journal is clean, and
+ * do recovery if necessary.
+ *
+ * Returns: errno
+ */
+
+int gfs2_recover_journal(struct gfs2_jdesc *jd, int wait)
+{
+	struct gfs2_sbd *sdp = jd->jd_inode->i_sbd;
+	struct gfs2_log_header head;
+	struct gfs2_holder j_gh, ji_gh, t_gh;
+	unsigned long t;
+	int ro = 0;
+	unsigned int pass;
+	int error;
+
+	fs_info(sdp, "jid=%u: Trying to acquire journal lock...\n", jd->jd_jid);
+
+	/* Aquire the journal lock so we can do recovery */
+
+	error = gfs2_glock_nq_num(sdp,
+				  jd->jd_jid, &gfs2_journal_glops,
+				  LM_ST_EXCLUSIVE,
+				  LM_FLAG_NOEXP |
+				  ((wait) ? 0 : LM_FLAG_TRY) |
+				  GL_NOCACHE, &j_gh);
+	switch (error) {
+	case 0:
+		break;
+
+	case GLR_TRYFAILED:
+		fs_info(sdp, "jid=%u: Busy\n", jd->jd_jid);
+		error = 0;
+
+	default:
+		goto fail;
+	};
+
+	error = gfs2_glock_nq_init(jd->jd_inode->i_gl, LM_ST_SHARED,
+				   LM_FLAG_NOEXP, &ji_gh);
+	if (error)
+		goto fail_gunlock_j;
+
+	fs_info(sdp, "jid=%u: Looking at journal...\n", jd->jd_jid);
+
+	error = gfs2_jdesc_check(jd);
+	if (error)
+		goto fail_gunlock_ji;
+
+	error = gfs2_find_jhead(jd, &head);
+	if (error)
+		goto fail_gunlock_ji;
+
+	if (!(head.lh_flags & GFS2_LOG_HEAD_UNMOUNT)) {
+		fs_info(sdp, "jid=%u: Acquiring the transaction lock...\n",
+			jd->jd_jid);
+
+		t = jiffies;
+
+		/* Acquire a shared hold on the transaction lock */
+
+		error = gfs2_glock_nq_init(sdp->sd_trans_gl,
+					   LM_ST_SHARED,
+					   LM_FLAG_NOEXP |
+					   LM_FLAG_PRIORITY |
+					   GL_NEVER_RECURSE |
+					   GL_NOCANCEL |
+					   GL_NOCACHE,
+					   &t_gh);
+		if (error)
+			goto fail_gunlock_ji;
+
+		if (test_bit(SDF_JOURNAL_CHECKED, &sdp->sd_flags)) {
+			if (!test_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags))
+				ro = 1;
+		} else {
+			if (sdp->sd_vfs->s_flags & MS_RDONLY)
+				ro = 1;
+		}
+
+		if (ro) {
+			fs_warn(sdp, "jid=%u: Can't replay: read-only FS\n",
+				jd->jd_jid);
+			error = -EROFS;
+			goto fail_gunlock_tr;
+		}
+
+		fs_info(sdp, "jid=%u: Replaying journal...\n", jd->jd_jid);
+
+		for (pass = 0; pass < 2; pass++) {
+			lops_before_scan(jd, &head, pass);
+			error = foreach_descriptor(jd, head.lh_tail,
+						   head.lh_blkno, pass);
+			lops_after_scan(jd, error, pass);
+			if (error)
+				goto fail_gunlock_tr;
+		}
+
+		error = clean_journal(jd, &head);
+		if (error)
+			goto fail_gunlock_tr;
+
+		gfs2_glock_dq_uninit(&t_gh);
+
+		t = DIV_RU(jiffies - t, HZ);
+		
+		fs_info(sdp, "jid=%u: Journal replayed in %lus\n",
+			jd->jd_jid, t);
+	}
+
+	gfs2_glock_dq_uninit(&ji_gh);
+
+	gfs2_lm_recovery_done(sdp, jd->jd_jid, LM_RD_SUCCESS);
+
+	gfs2_glock_dq_uninit(&j_gh);
+
+	fs_info(sdp, "jid=%u: Done\n", jd->jd_jid);
+
+	return 0;
+
+ fail_gunlock_tr:
+	gfs2_glock_dq_uninit(&t_gh);
+
+ fail_gunlock_ji:
+	gfs2_glock_dq_uninit(&ji_gh);
+
+ fail_gunlock_j:
+	gfs2_glock_dq_uninit(&j_gh);
+
+	fs_info(sdp, "jid=%u: %s\n", jd->jd_jid, (error) ? "Failed" : "Done");
+
+ fail:
+	gfs2_lm_recovery_done(sdp, jd->jd_jid, LM_RD_GAVEUP);
+
+	return error;
+}
+
+/**
+ * gfs2_check_journals - Recover any dirty journals
+ * @sdp: the filesystem
+ *
+ */
+
+void gfs2_check_journals(struct gfs2_sbd *sdp)
+{
+	struct gfs2_jdesc *jd;
+
+	for (;;) {
+		jd = gfs2_jdesc_find_dirty(sdp);
+		if (!jd)
+			break;
+
+		if (jd != sdp->sd_jdesc)
+			gfs2_recover_journal(jd, NO_WAIT);
+	}
+}
+
