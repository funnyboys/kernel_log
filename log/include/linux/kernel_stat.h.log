commit 74722bb223d0f236303b60c9509ff924a9713780
Author: Frederic Weisbecker <frederic@kernel.org>
Date:   Thu Nov 21 03:44:26 2019 +0100

    sched/vtime: Bring up complete kcpustat accessor
    
    Many callsites want to fetch the values of system, user, user_nice, guest
    or guest_nice kcpustat fields altogether or at least a pair of these.
    
    In that case calling kcpustat_field() for each requested field brings
    unecessary overhead when we could fetch all of them in a row.
    
    So provide kcpustat_cpu_fetch() that fetches the whole kcpustat array
    in a vtime safe way under the same RCU and seqcount block.
    
    Signed-off-by: Frederic Weisbecker <frederic@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wanpeng Li <wanpengli@tencent.com>
    Cc: Yauheni Kaliuta <yauheni.kaliuta@redhat.com>
    Link: https://lkml.kernel.org/r/20191121024430.19938-3-frederic@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 79781196eb25..89f0745c096d 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -81,12 +81,19 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 #ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
 extern u64 kcpustat_field(struct kernel_cpustat *kcpustat,
 			  enum cpu_usage_stat usage, int cpu);
+extern void kcpustat_cpu_fetch(struct kernel_cpustat *dst, int cpu);
 #else
 static inline u64 kcpustat_field(struct kernel_cpustat *kcpustat,
 				 enum cpu_usage_stat usage, int cpu)
 {
 	return kcpustat->cpustat[usage];
 }
+
+static inline void kcpustat_cpu_fetch(struct kernel_cpustat *dst, int cpu)
+{
+	*dst = kcpustat_cpu(cpu);
+}
+
 #endif
 
 extern void account_user_time(struct task_struct *, u64);

commit 64eea63c19a2c386a96638f4e54a1355510709e3
Author: Frederic Weisbecker <frederic@kernel.org>
Date:   Fri Oct 25 04:03:03 2019 +0200

    sched/kcpustat: Introduce vtime-aware kcpustat accessor for CPUTIME_SYSTEM
    
    Kcpustat is not correctly supported on nohz_full CPUs. The tick doesn't
    fire and the cputime therefore doesn't move forward. The issue has shown
    up after the vanishing of the remaining 1Hz which has made the stall
    visible.
    
    We are solving that with checking the task running on a CPU through RCU
    and reading its vtime delta that we add to the raw kcpustat values.
    
    We make sure that we fetch a coherent raw-kcpustat/vtime-delta couple
    sequence while checking that the CPU referred by the target vtime is the
    correct one, under the locked vtime seqcount.
    
    Only CPUTIME_SYSTEM is handled here as a start because it's the trivial
    case. User and guest time will require more preparation work to
    correctly handle niceness.
    
    Reported-by: Yauheni Kaliuta <yauheni.kaliuta@redhat.com>
    Signed-off-by: Frederic Weisbecker <frederic@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wanpeng Li <wanpengli@tencent.com>
    Link: https://lkml.kernel.org/r/20191025020303.19342-1-frederic@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 7ee2bb43b251..79781196eb25 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -78,6 +78,17 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 	return kstat_cpu(cpu).irqs_sum;
 }
 
+#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
+extern u64 kcpustat_field(struct kernel_cpustat *kcpustat,
+			  enum cpu_usage_stat usage, int cpu);
+#else
+static inline u64 kcpustat_field(struct kernel_cpustat *kcpustat,
+				 enum cpu_usage_stat usage, int cpu)
+{
+	return kcpustat->cpustat[usage];
+}
+#endif
+
 extern void account_user_time(struct task_struct *, u64);
 extern void account_guest_time(struct task_struct *, u64);
 extern void account_system_time(struct task_struct *, int, u64);

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 66be8b6beceb..7ee2bb43b251 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LINUX_KERNEL_STAT_H
 #define _LINUX_KERNEL_STAT_H
 

commit fb8b049c988f1ff460b063b8a41ea9a3c79921c2
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:40 2017 +0100

    sched/cputime: Push time to account_system_time() in nsecs
    
    This is one more step toward converting cputime accounting to pure nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-25-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index e1cd8970e096..66be8b6beceb 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -9,7 +9,6 @@
 #include <linux/sched.h>
 #include <linux/vtime.h>
 #include <asm/irq.h>
-#include <linux/cputime.h>
 
 /*
  * 'kernel_stat.h' contains the definitions needed for doing
@@ -79,9 +78,9 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 }
 
 extern void account_user_time(struct task_struct *, u64);
-extern void account_guest_time(struct task_struct *, cputime_t);
-extern void account_system_time(struct task_struct *, int, cputime_t);
-extern void account_system_index_time(struct task_struct *, cputime_t,
+extern void account_guest_time(struct task_struct *, u64);
+extern void account_system_time(struct task_struct *, int, u64);
+extern void account_system_index_time(struct task_struct *, u64,
 				      enum cpu_usage_stat);
 extern void account_steal_time(u64);
 extern void account_idle_time(u64);

commit 18b43a9bd7ae91185e398dd983fb4fffb9e81b3a
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:39 2017 +0100

    sched/cputime: Push time to account_idle_time() in nsecs
    
    This is one more step toward converting cputime accounting to pure nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-24-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 1d55d10abf9d..e1cd8970e096 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -84,7 +84,7 @@ extern void account_system_time(struct task_struct *, int, cputime_t);
 extern void account_system_index_time(struct task_struct *, cputime_t,
 				      enum cpu_usage_stat);
 extern void account_steal_time(u64);
-extern void account_idle_time(cputime_t);
+extern void account_idle_time(u64);
 
 #ifdef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
 static inline void account_process_tick(struct task_struct *tsk, int user)

commit be9095ed4fb3cf69e9fdf64e28ff6b5bd0ec7215
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:38 2017 +0100

    sched/cputime: Push time to account_steal_time() in nsecs
    
    This is one more step toward converting cputime accounting to pure nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-23-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index b716001ac23e..1d55d10abf9d 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -83,7 +83,7 @@ extern void account_guest_time(struct task_struct *, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t);
 extern void account_system_index_time(struct task_struct *, cputime_t,
 				      enum cpu_usage_stat);
-extern void account_steal_time(cputime_t);
+extern void account_steal_time(u64);
 extern void account_idle_time(cputime_t);
 
 #ifdef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE

commit 23244a5c8003d4154161a8289a7d3783b0237c08
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:37 2017 +0100

    sched/cputime: Push time to account_user_time() in nsecs
    
    This is one more step toward converting cputime accounting to pure nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-22-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index c3e38ded2d73..b716001ac23e 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -78,7 +78,7 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 	return kstat_cpu(cpu).irqs_sum;
 }
 
-extern void account_user_time(struct task_struct *, cputime_t);
+extern void account_user_time(struct task_struct *, u64);
 extern void account_guest_time(struct task_struct *, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t);
 extern void account_system_index_time(struct task_struct *, cputime_t,

commit c8d7dabf8f91fadd265e6eb87afb201d14ea299b
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:50 2017 +0100

    sched/cputime: Rename vtime_account_user() to vtime_flush()
    
    CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y used to accumulate user time and
    account it on ticks and context switches only through the
    vtime_account_user() function.
    
    Now this model has been generalized on the 3 archs for all kind of
    cputime (system, irq, ...) and all the cputime flushing happens under
    vtime_account_user().
    
    So let's rename this function to better reflect its new role.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-11-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index cfd6c0c6d4e8..c3e38ded2d73 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -89,7 +89,7 @@ extern void account_idle_time(cputime_t);
 #ifdef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
 static inline void account_process_tick(struct task_struct *tsk, int user)
 {
-	vtime_account_user(tsk);
+	vtime_flush(tsk);
 }
 #else
 extern void account_process_tick(struct task_struct *, int user);

commit 1213699ab426608ff1925ab263dd6925102bb92a
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:44 2017 +0100

    sched/cputime: Export account_guest_time()
    
    In order to prepare for CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y to delay
    cputime accounting to the tick, let's allow archs to account cputime
    directly to gtime.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-5-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 14b63bb714d4..cfd6c0c6d4e8 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -79,6 +79,7 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 }
 
 extern void account_user_time(struct task_struct *, cputime_t);
+extern void account_guest_time(struct task_struct *, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t);
 extern void account_system_index_time(struct task_struct *, cputime_t,
 				      enum cpu_usage_stat);

commit c31cc6a5187e8b09ccee34f81728a90f80e872e7
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:43 2017 +0100

    sched/cputime: Allow accounting system time using cpustat index
    
    In order to prepare for CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y to delay
    cputime accounting to the tick, let's provide APIs to account system
    time to precise contexts: hardirq, softirq, pure system, ...
    
    Inspired-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-4-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 00f776816aa3..14b63bb714d4 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -80,6 +80,8 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 
 extern void account_user_time(struct task_struct *, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t);
+extern void account_system_index_time(struct task_struct *, cputime_t,
+				      enum cpu_usage_stat);
 extern void account_steal_time(cputime_t);
 extern void account_idle_time(cputime_t);
 

commit 40565b5aedd6d0ca88b7dfd3859d709d2f6f8cf9
Author: Stanislaw Gruszka <sgruszka@redhat.com>
Date:   Tue Nov 15 03:06:51 2016 +0100

    sched/cputime, powerpc, s390: Make scaled cputime arch specific
    
    Only s390 and powerpc have hardware facilities allowing to measure
    cputimes scaled by frequency. On all other architectures
    utimescaled/stimescaled are equal to utime/stime (however they are
    accounted separately).
    
    Remove {u,s}timescaled accounting on all architectures except
    powerpc and s390, where those values are explicitly accounted
    in the proper places.
    
    Signed-off-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Paul Mackerras <paulus@ozlabs.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20161031162143.GB12646@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 44fda64ad434..00f776816aa3 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -78,8 +78,8 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 	return kstat_cpu(cpu).irqs_sum;
 }
 
-extern void account_user_time(struct task_struct *, cputime_t, cputime_t);
-extern void account_system_time(struct task_struct *, int, cputime_t, cputime_t);
+extern void account_user_time(struct task_struct *, cputime_t);
+extern void account_system_time(struct task_struct *, int, cputime_t);
 extern void account_steal_time(cputime_t);
 extern void account_idle_time(cputime_t);
 

commit ecb23dc6f2eff0ce64dd60351a81f376f13b12cc
Author: Juergen Gross <jgross@suse.com>
Date:   Fri May 20 09:26:48 2016 +0200

    xen: add steal_clock support on x86
    
    The pv_time_ops structure contains a function pointer for the
    "steal_clock" functionality used only by KVM and Xen on ARM. Xen on x86
    uses its own mechanism to account for the "stolen" time a thread wasn't
    able to run due to hypervisor scheduling.
    
    Add support in Xen arch independent time handling for this feature by
    moving it out of the arm arch into drivers/xen and remove the x86 Xen
    hack.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Reviewed-by: Stefano Stabellini <sstabellini@kernel.org>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 25a822f6f000..44fda64ad434 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -92,7 +92,6 @@ static inline void account_process_tick(struct task_struct *tsk, int user)
 extern void account_process_tick(struct task_struct *, int user);
 #endif
 
-extern void account_steal_ticks(unsigned long ticks);
 extern void account_idle_ticks(unsigned long ticks);
 
 #endif /* _LINUX_KERNEL_STAT_H */

commit c291ee622165cb2c8d4e7af63fffd499354a23be
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 11 23:01:41 2014 +0100

    genirq: Prevent proc race against freeing of irq descriptors
    
    Since the rework of the sparse interrupt code to actually free the
    unused interrupt descriptors there exists a race between the /proc
    interfaces to the irq subsystem and the code which frees the interrupt
    descriptor.
    
    CPU0                            CPU1
                                    show_interrupts()
                                      desc = irq_to_desc(X);
    free_desc(desc)
      remove_from_radix_tree();
      kfree(desc);
                                      raw_spinlock_irq(&desc->lock);
    
    /proc/interrupts is the only interface which can actively corrupt
    kernel memory via the lock access. /proc/stat can only read from freed
    memory. Extremly hard to trigger, but possible.
    
    The interfaces in /proc/irq/N/ are not affected by this because the
    removal of the proc file is serialized in procfs against concurrent
    readers/writers. The removal happens before the descriptor is freed.
    
    For architectures which have CONFIG_SPARSE_IRQ=n this is a non issue
    as the descriptor is never freed. It's merely cleared out with the irq
    descriptor lock held. So any concurrent proc access will either see
    the old correct value or the cleared out ones.
    
    Protect the lookup and access to the irq descriptor in
    show_interrupts() with the sparse_irq_lock.
    
    Provide kstat_irqs_usr() which is protecting the lookup and access
    with sparse_irq_lock and switch /proc/stat to use it.
    
    Document the existing kstat_irqs interfaces so it's clear that the
    caller needs to take care about protection. The users of these
    interfaces are either not affected due to SPARSE_IRQ=n or already
    protected against removal.
    
    Fixes: 1f5a5b87f78f "genirq: Implement a sane sparse_irq allocator"
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index b9376cd5a187..25a822f6f000 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -68,6 +68,7 @@ static inline unsigned int kstat_softirqs_cpu(unsigned int irq, int cpu)
  * Number of interrupts per specific IRQ source, since bootup
  */
 extern unsigned int kstat_irqs(unsigned int irq);
+extern unsigned int kstat_irqs_usr(unsigned int irq);
 
 /*
  * Number of interrupts per cpu, since bootup

commit 23cfa361f3e54a3e184a5e126bbbdd95f984881a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed Nov 12 12:37:37 2014 +0100

    sched/cputime: Fix cpu_timer_sample_group() double accounting
    
    While looking over the cpu-timer code I found that we appear to add
    the delta for the calling task twice, through:
    
      cpu_timer_sample_group()
        thread_group_cputimer()
          thread_group_cputime()
            times->sum_exec_runtime += task_sched_runtime();
    
        *sample = cputime.sum_exec_runtime + task_delta_exec();
    
    Which would make the sample run ahead, making the sleep short.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Link: http://lkml.kernel.org/r/20141112113737.GI10476@twins.programming.kicks-ass.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 8422b4ed6882..b9376cd5a187 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -77,11 +77,6 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
 	return kstat_cpu(cpu).irqs_sum;
 }
 
-/*
- * Lock/unlock the current runqueue - to extract task statistics:
- */
-extern unsigned long long task_delta_exec(struct task_struct *);
-
 extern void account_user_time(struct task_struct *, cputime_t, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t, cputime_t);
 extern void account_steal_time(cputime_t);

commit 4a32fea9d78f2d2315c0072757b197d5a304dc8b
Author: Christoph Lameter <cl@linux.com>
Date:   Sun Aug 17 12:30:27 2014 -0500

    scheduler: Replace __get_cpu_var with this_cpu_ptr
    
    Convert all uses of __get_cpu_var for address calculation to use
    this_cpu_ptr instead.
    
    [Uses of __get_cpu_var with cpumask_var_t are no longer
    handled by this patch]
    
    Cc: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index ecbc52f9ff77..8422b4ed6882 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -44,8 +44,8 @@ DECLARE_PER_CPU(struct kernel_stat, kstat);
 DECLARE_PER_CPU(struct kernel_cpustat, kernel_cpustat);
 
 /* Must have preemption disabled for this to be meaningful. */
-#define kstat_this_cpu (&__get_cpu_var(kstat))
-#define kcpustat_this_cpu (&__get_cpu_var(kernel_cpustat))
+#define kstat_this_cpu this_cpu_ptr(&kstat)
+#define kcpustat_this_cpu this_cpu_ptr(&kernel_cpustat)
 #define kstat_cpu(cpu) per_cpu(kstat, cpu)
 #define kcpustat_cpu(cpu) per_cpu(kernel_cpustat, cpu)
 

commit 683b6c6f82a60fabf47012581c2cfbf1b037ab95
Merge: 1ead65812486 1b422ecd2786
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 1 11:22:57 2014 -0700

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull irq code updates from Thomas Gleixner:
     "The irq department proudly presents:
    
       - Another tree wide sweep of irq infrastructure abuse.  Clear winner
         of the trainwreck engineering contest was:
             #include "../../../kernel/irq/settings.h"
    
       - Tree wide update of irq_set_affinity() callbacks which miss a cpu
         online check when picking a single cpu out of the affinity mask.
    
       - Tree wide consolidation of interrupt statistics.
    
       - Updates to the threaded interrupt infrastructure to allow explicit
         wakeup of the interrupt thread and a variant of synchronize_irq()
         which synchronizes only the hard interrupt handler.  Both are
         needed to replace the homebrewn thread handling in the mmc/sdhci
         code.
    
       - New irq chip callbacks to allow proper support for GPIO based irqs.
         The GPIO based interrupts need to request/release GPIO resources
         from request/free_irq.
    
       - A few new ARM interrupt chips.  No revolutionary new hardware, just
         differently wreckaged variations of the scheme.
    
       - Small improvments, cleanups and updates all over the place"
    
    I was hoping that that trainwreck engineering contest was a April Fools'
    joke.  But no.
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (68 commits)
      irqchip: sun7i/sun6i: Disable NMI before registering the handler
      ARM: sun7i/sun6i: dts: Fix IRQ number for sun6i NMI controller
      ARM: sun7i/sun6i: irqchip: Update the documentation
      ARM: sun7i/sun6i: dts: Add NMI irqchip support
      ARM: sun7i/sun6i: irqchip: Add irqchip driver for NMI controller
      genirq: Export symbol no_action()
      arm: omap: Fix typo in ams-delta-fiq.c
      m68k: atari: Fix the last kernel_stat.h fallout
      irqchip: sun4i: Simplify sun4i_irq_ack
      irqchip: sun4i: Use handle_fasteoi_irq for all interrupts
      genirq: procfs: Make smp_affinity values go+r
      softirq: Add linux/irq.h to make it compile again
      m68k: amiga: Add linux/irq.h to make it compile again
      irqchip: sun4i: Don't ack IRQs > 0, fix acking of IRQ 0
      irqchip: sun4i: Fix a comment about mask register initialization
      irqchip: sun4i: Fix irq 0 not working
      genirq: Add a new IRQCHIP_EOI_THREADED flag
      genirq: Document IRQCHIP_ONESHOT_SAFE flag
      ARM: sunxi: dt: Convert to the new irq controller compatibles
      irqchip: sunxi: Change compatibles
      ...

commit bfc3f0281e08066fa8111c3972cff6edc1049864
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Mar 5 16:33:42 2014 +0100

    cputime: Default implementation of nsecs -> cputime conversion
    
    The architectures that override cputime_t (s390, ppc) don't provide
    any version of nsecs_to_cputime(). Indeed this cputime_t implementation
    by backend only happens when CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y under
    which the core code doesn't make any use of nsecs_to_cputime().
    
    At least for now.
    
    We are going to make a broader use of it so lets provide a default
    version with a per usecs granularity. It should be good enough for most
    usecases.
    
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 51c72be4a7c3..d7c61317db86 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -9,7 +9,7 @@
 #include <linux/sched.h>
 #include <linux/vtime.h>
 #include <asm/irq.h>
-#include <asm/cputime.h>
+#include <linux/cputime.h>
 
 /*
  * 'kernel_stat.h' contains the definitions needed for doing

commit 8f945a3325bbe0dd651e2f496a53df9b06fc6d07
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 23 21:40:23 2014 +0000

    genirq: Move kstat_incr_irqs_this_cpu() to core
    
    No more users outside the core code. Put it into the poison
    cabinet. That also gets rid of the linux/irq.h include in
    kernel_stat.h
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20140223212739.124207133@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 54ec7e0a7d72..c3fbda7690d6 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -51,15 +51,7 @@ DECLARE_PER_CPU(struct kernel_cpustat, kernel_cpustat);
 
 extern unsigned long long nr_context_switches(void);
 
-#include <linux/irq.h>
 extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
-
-static inline void kstat_incr_irqs_this_cpu(unsigned int irq, struct irq_desc *desc)
-{
-	__this_cpu_inc(*desc->kstat_irqs);
-	__this_cpu_inc(kstat.irqs_sum);
-}
-
 extern void kstat_incr_irq_this_cpu(unsigned int irq);
 
 static inline void kstat_incr_softirqs_this_cpu(unsigned int irq)

commit 792d0018a5fe31ef8ef9d07a7a02081d4abdf6b7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 23 21:40:14 2014 +0000

    genirq: Add a kstat helper to increment irq stats
    
    There is a common pattern all over the place:
    
          kstat_incr_irqs_this_cpu(irq, irq_to_desc(irq));
    
    This results in a call to core code anyway. So provide a function
    which does the same thing in core.
    
    While at it, replace the butt ugly macro with an inline.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20140223212737.422068876@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 51c72be4a7c3..54ec7e0a7d72 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -54,11 +54,13 @@ extern unsigned long long nr_context_switches(void);
 #include <linux/irq.h>
 extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
 
-#define kstat_incr_irqs_this_cpu(irqno, DESC)		\
-do {							\
-	__this_cpu_inc(*(DESC)->kstat_irqs);		\
-	__this_cpu_inc(kstat.irqs_sum);			\
-} while (0)
+static inline void kstat_incr_irqs_this_cpu(unsigned int irq, struct irq_desc *desc)
+{
+	__this_cpu_inc(*desc->kstat_irqs);
+	__this_cpu_inc(kstat.irqs_sum);
+}
+
+extern void kstat_incr_irq_this_cpu(unsigned int irq);
 
 static inline void kstat_incr_softirqs_this_cpu(unsigned int irq)
 {

commit 0244ad004a54e39308d495fee0a2e637f8b5c317
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Aug 30 09:39:53 2013 +0200

    Remove GENERIC_HARDIRQ config option
    
    After the last architecture switched to generic hard irqs the config
    options HAVE_GENERIC_HARDIRQS & GENERIC_HARDIRQS and the related code
    for !CONFIG_GENERIC_HARDIRQS can be removed.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index ed5f6ed6eb77..51c72be4a7c3 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -36,9 +36,6 @@ struct kernel_cpustat {
 };
 
 struct kernel_stat {
-#ifndef CONFIG_GENERIC_HARDIRQS
-       unsigned int irqs[NR_IRQS];
-#endif
 	unsigned long irqs_sum;
 	unsigned int softirqs[NR_SOFTIRQS];
 };
@@ -54,22 +51,6 @@ DECLARE_PER_CPU(struct kernel_cpustat, kernel_cpustat);
 
 extern unsigned long long nr_context_switches(void);
 
-#ifndef CONFIG_GENERIC_HARDIRQS
-
-struct irq_desc;
-
-static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
-					    struct irq_desc *desc)
-{
-	__this_cpu_inc(kstat.irqs[irq]);
-	__this_cpu_inc(kstat.irqs_sum);
-}
-
-static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
-{
-       return kstat_cpu(cpu).irqs[irq];
-}
-#else
 #include <linux/irq.h>
 extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
 
@@ -79,8 +60,6 @@ do {							\
 	__this_cpu_inc(kstat.irqs_sum);			\
 } while (0)
 
-#endif
-
 static inline void kstat_incr_softirqs_this_cpu(unsigned int irq)
 {
 	__this_cpu_inc(kstat.softirqs[irq]);
@@ -94,20 +73,7 @@ static inline unsigned int kstat_softirqs_cpu(unsigned int irq, int cpu)
 /*
  * Number of interrupts per specific IRQ source, since bootup
  */
-#ifndef CONFIG_GENERIC_HARDIRQS
-static inline unsigned int kstat_irqs(unsigned int irq)
-{
-	unsigned int sum = 0;
-	int cpu;
-
-	for_each_possible_cpu(cpu)
-		sum += kstat_irqs_cpu(irq, cpu);
-
-	return sum;
-}
-#else
 extern unsigned int kstat_irqs(unsigned int irq);
-#endif
 
 /*
  * Number of interrupts per cpu, since bootup

commit abf917cd91cbb73952758f9741e2fa65002a48ee
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Jul 25 07:56:04 2012 +0200

    cputime: Generic on-demand virtual cputime accounting
    
    If we want to stop the tick further idle, we need to be
    able to account the cputime without using the tick.
    
    Virtual based cputime accounting solves that problem by
    hooking into kernel/user boundaries.
    
    However implementing CONFIG_VIRT_CPU_ACCOUNTING require
    low level hooks and involves more overhead. But we already
    have a generic context tracking subsystem that is required
    for RCU needs by archs which plan to shut down the tick
    outside idle.
    
    This patch implements a generic virtual based cputime
    accounting that relies on these generic kernel/user hooks.
    
    There are some upsides of doing this:
    
    - This requires no arch code to implement CONFIG_VIRT_CPU_ACCOUNTING
    if context tracking is already built (already necessary for RCU in full
    tickless mode).
    
    - We can rely on the generic context tracking subsystem to dynamically
    (de)activate the hooks, so that we can switch anytime between virtual
    and tick based accounting. This way we don't have the overhead
    of the virtual accounting when the tick is running periodically.
    
    And one downside:
    
    - There is probably more overhead than a native virtual based cputime
    accounting. But this relies on hooks that are already set anyway.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Li Zhong <zhong@linux.vnet.ibm.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 66b70780e910..ed5f6ed6eb77 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -127,7 +127,7 @@ extern void account_system_time(struct task_struct *, int, cputime_t, cputime_t)
 extern void account_steal_time(cputime_t);
 extern void account_idle_time(cputime_t);
 
-#ifdef CONFIG_VIRT_CPU_ACCOUNTING
+#ifdef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
 static inline void account_process_tick(struct task_struct *tsk, int user)
 {
 	vtime_account_user(tsk);

commit bcebdf846522056a84ba0b0cba5f5413868c9394
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Nov 13 23:51:06 2012 +0100

    vtime: Explicitly account pending user time on process tick
    
    All vtime implementations just flush the user time on process
    tick. Consolidate that in generic code by calling a user time
    accounting helper. This avoids an indirect call in ia64 and
    prepare to also consolidate vtime context switch code.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 1865b1f29770..66b70780e910 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -127,7 +127,15 @@ extern void account_system_time(struct task_struct *, int, cputime_t, cputime_t)
 extern void account_steal_time(cputime_t);
 extern void account_idle_time(cputime_t);
 
+#ifdef CONFIG_VIRT_CPU_ACCOUNTING
+static inline void account_process_tick(struct task_struct *tsk, int user)
+{
+	vtime_account_user(tsk);
+}
+#else
 extern void account_process_tick(struct task_struct *, int user);
+#endif
+
 extern void account_steal_ticks(unsigned long ticks);
 extern void account_idle_ticks(unsigned long ticks);
 

commit dcbf832e5823156e8f155359b47bd108cac8ad68
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 5 23:07:19 2012 +0200

    vtime: Gather vtime declarations to their own header file
    
    These APIs are scattered around and are going to expand a bit.
    Let's create a dedicated header file for sanity.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 36d12f0884c3..1865b1f29770 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -7,6 +7,7 @@
 #include <linux/cpumask.h>
 #include <linux/interrupt.h>
 #include <linux/sched.h>
+#include <linux/vtime.h>
 #include <asm/irq.h>
 #include <asm/cputime.h>
 
@@ -130,12 +131,4 @@ extern void account_process_tick(struct task_struct *, int user);
 extern void account_steal_ticks(unsigned long ticks);
 extern void account_idle_ticks(unsigned long ticks);
 
-#ifdef CONFIG_VIRT_CPU_ACCOUNTING
-extern void vtime_task_switch(struct task_struct *prev);
-extern void vtime_account_system(struct task_struct *tsk);
-extern void vtime_account_idle(struct task_struct *tsk);
-#else
-static inline void vtime_task_switch(struct task_struct *prev) { }
-#endif
-
 #endif /* _LINUX_KERNEL_STAT_H */

commit a7e1a9e3af71b45ecae2dae35851f238117b317d
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Sep 8 16:14:02 2012 +0200

    vtime: Consolidate system/idle context detection
    
    Move the code that finds out to which context we account the
    cputime into generic layer.
    
    Archs that consider the whole time spent in the idle task as idle
    time (ia64, powerpc) can rely on the generic vtime_account()
    and implement vtime_account_system() and vtime_account_idle(),
    letting the generic code to decide when to call which API.
    
    Archs that have their own meaning of idle time, such as s390
    that only considers the time spent in CPU low power mode as idle
    time, can just override vtime_account().
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index ca0944b92f4a..36d12f0884c3 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -132,6 +132,8 @@ extern void account_idle_ticks(unsigned long ticks);
 
 #ifdef CONFIG_VIRT_CPU_ACCOUNTING
 extern void vtime_task_switch(struct task_struct *prev);
+extern void vtime_account_system(struct task_struct *tsk);
+extern void vtime_account_idle(struct task_struct *tsk);
 #else
 static inline void vtime_task_switch(struct task_struct *prev) { }
 #endif

commit bf9fae9f5e4ca8dce4708812f9ad6281e61df109
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Sep 8 15:23:11 2012 +0200

    cputime: Use a proper subsystem naming for vtime related APIs
    
    Use a naming based on vtime as a prefix for virtual based
    cputime accounting APIs:
    
    - account_system_vtime() -> vtime_account()
    - account_switch_vtime() -> vtime_task_switch()
    
    It makes it easier to allow for further declension such
    as vtime_account_system(), vtime_account_idle(), ... if we
    want to find out the context we account to from generic code.
    
    This also make it better to know on which subsystem these APIs
    refer to.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index bbe5d15d6597..ca0944b92f4a 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -131,9 +131,9 @@ extern void account_steal_ticks(unsigned long ticks);
 extern void account_idle_ticks(unsigned long ticks);
 
 #ifdef CONFIG_VIRT_CPU_ACCOUNTING
-extern void account_switch_vtime(struct task_struct *prev);
+extern void vtime_task_switch(struct task_struct *prev);
 #else
-static inline void account_switch_vtime(struct task_struct *prev) { }
+static inline void vtime_task_switch(struct task_struct *prev) { }
 #endif
 
 #endif /* _LINUX_KERNEL_STAT_H */

commit baa36046d09ea6dbc122c795566992318663d9eb
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Jun 18 17:54:14 2012 +0200

    cputime: Consolidate vtime handling on context switch
    
    The archs that implement virtual cputime accounting all
    flush the cputime of a task when it gets descheduled
    and sometimes set up some ground initialization for the
    next task to account its cputime.
    
    These archs all put their own hooks in their context
    switch callbacks and handle the off-case themselves.
    
    Consolidate this by creating a new account_switch_vtime()
    callback called in generic code right after a context switch
    and that these archs must implement to flush the prev task
    cputime and initialize the next task cputime related state.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 2fbd9053c2df..bbe5d15d6597 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -130,4 +130,10 @@ extern void account_process_tick(struct task_struct *, int user);
 extern void account_steal_ticks(unsigned long ticks);
 extern void account_idle_ticks(unsigned long ticks);
 
+#ifdef CONFIG_VIRT_CPU_ACCOUNTING
+extern void account_switch_vtime(struct task_struct *prev);
+#else
+static inline void account_switch_vtime(struct task_struct *prev) { }
+#endif
+
 #endif /* _LINUX_KERNEL_STAT_H */

commit 3292beb340c76884427faa1f5d6085719477d889
Author: Glauber Costa <glommer@parallels.com>
Date:   Mon Nov 28 14:45:17 2011 -0200

    sched/accounting: Change cpustat fields to an array
    
    This patch changes fields in cpustat from a structure, to an
    u64 array. Math gets easier, and the code is more flexible.
    
    Signed-off-by: Glauber Costa <glommer@parallels.com>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Paul Tuner <pjt@google.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1322498719-2255-2-git-send-email-glommer@parallels.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 0cce2db580c3..2fbd9053c2df 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -6,6 +6,7 @@
 #include <linux/percpu.h>
 #include <linux/cpumask.h>
 #include <linux/interrupt.h>
+#include <linux/sched.h>
 #include <asm/irq.h>
 #include <asm/cputime.h>
 
@@ -15,21 +16,25 @@
  * used by rstatd/perfmeter
  */
 
-struct cpu_usage_stat {
-	cputime64_t user;
-	cputime64_t nice;
-	cputime64_t system;
-	cputime64_t softirq;
-	cputime64_t irq;
-	cputime64_t idle;
-	cputime64_t iowait;
-	cputime64_t steal;
-	cputime64_t guest;
-	cputime64_t guest_nice;
+enum cpu_usage_stat {
+	CPUTIME_USER,
+	CPUTIME_NICE,
+	CPUTIME_SYSTEM,
+	CPUTIME_SOFTIRQ,
+	CPUTIME_IRQ,
+	CPUTIME_IDLE,
+	CPUTIME_IOWAIT,
+	CPUTIME_STEAL,
+	CPUTIME_GUEST,
+	CPUTIME_GUEST_NICE,
+	NR_STATS,
+};
+
+struct kernel_cpustat {
+	u64 cpustat[NR_STATS];
 };
 
 struct kernel_stat {
-	struct cpu_usage_stat	cpustat;
 #ifndef CONFIG_GENERIC_HARDIRQS
        unsigned int irqs[NR_IRQS];
 #endif
@@ -38,10 +43,13 @@ struct kernel_stat {
 };
 
 DECLARE_PER_CPU(struct kernel_stat, kstat);
+DECLARE_PER_CPU(struct kernel_cpustat, kernel_cpustat);
 
-#define kstat_cpu(cpu)	per_cpu(kstat, cpu)
 /* Must have preemption disabled for this to be meaningful. */
-#define kstat_this_cpu	__get_cpu_var(kstat)
+#define kstat_this_cpu (&__get_cpu_var(kstat))
+#define kcpustat_this_cpu (&__get_cpu_var(kernel_cpustat))
+#define kstat_cpu(cpu) per_cpu(kstat, cpu)
+#define kcpustat_cpu(cpu) per_cpu(kernel_cpustat, cpu)
 
 extern unsigned long long nr_context_switches(void);
 

commit 6c9ae009b298753a3baf71298d676a68b5a10c8f
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Jan 13 15:45:38 2011 -0800

    irq: use per_cpu kstat_irqs
    
    Use modern per_cpu API to increment {soft|hard}irq counters, and use
    per_cpu allocation for (struct irq_desc)->kstats_irq instead of an array.
    
    This gives better SMP/NUMA locality and saves few instructions per irq.
    
    With small nr_cpuids values (8 for example), kstats_irq was a small array
    (less than L1_CACHE_BYTES), potentially source of false sharing.
    
    In the !CONFIG_SPARSE_IRQ case, remove the huge, NUMA/cache unfriendly
    kstat_irqs_all[NR_IRQS][NR_CPUS] array.
    
    Note: we still populate kstats_irq for all possible irqs in
    early_irq_init().  We probably could use on-demand allocations.  (Code
    included in alloc_descs()).  Problem is not all IRQS are used with a prior
    alloc_descs() call.
    
    kstat_irqs_this_cpu() is not used anymore, remove it.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Reviewed-by: Christoph Lameter <cl@linux.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 44e83ba12b5b..0cce2db580c3 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -46,16 +46,14 @@ DECLARE_PER_CPU(struct kernel_stat, kstat);
 extern unsigned long long nr_context_switches(void);
 
 #ifndef CONFIG_GENERIC_HARDIRQS
-#define kstat_irqs_this_cpu(irq) \
-	(this_cpu_read(kstat.irqs[irq])
 
 struct irq_desc;
 
 static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
 					    struct irq_desc *desc)
 {
-	kstat_this_cpu.irqs[irq]++;
-	kstat_this_cpu.irqs_sum++;
+	__this_cpu_inc(kstat.irqs[irq]);
+	__this_cpu_inc(kstat.irqs_sum);
 }
 
 static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
@@ -65,17 +63,18 @@ static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 #else
 #include <linux/irq.h>
 extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
-#define kstat_irqs_this_cpu(DESC) \
-	((DESC)->kstat_irqs[smp_processor_id()])
-#define kstat_incr_irqs_this_cpu(irqno, DESC) do {\
-	((DESC)->kstat_irqs[smp_processor_id()]++);\
-	kstat_this_cpu.irqs_sum++; } while (0)
+
+#define kstat_incr_irqs_this_cpu(irqno, DESC)		\
+do {							\
+	__this_cpu_inc(*(DESC)->kstat_irqs);		\
+	__this_cpu_inc(kstat.irqs_sum);			\
+} while (0)
 
 #endif
 
 static inline void kstat_incr_softirqs_this_cpu(unsigned int irq)
 {
-	kstat_this_cpu.softirqs[irq]++;
+	__this_cpu_inc(kstat.softirqs[irq]);
 }
 
 static inline unsigned int kstat_softirqs_cpu(unsigned int irq, int cpu)

commit 909ea96468096b07fbb41aaf69be060d92bd9271
Author: Christoph Lameter <cl@linux.com>
Date:   Wed Dec 8 16:22:55 2010 +0100

    core: Replace __get_cpu_var with __this_cpu_read if not used for an address.
    
    __get_cpu_var() can be replaced with this_cpu_read and will then use a
    single read instruction with implied address calculation to access the
    correct per cpu instance.
    
    However, the address of a per cpu variable passed to __this_cpu_read()
    cannot be determined (since it's an implied address conversion through
    segment prefixes).  Therefore apply this only to uses of __get_cpu_var
    where the address of the variable is not used.
    
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index ad54c846911b..44e83ba12b5b 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -47,7 +47,7 @@ extern unsigned long long nr_context_switches(void);
 
 #ifndef CONFIG_GENERIC_HARDIRQS
 #define kstat_irqs_this_cpu(irq) \
-	(kstat_this_cpu.irqs[irq])
+	(this_cpu_read(kstat.irqs[irq])
 
 struct irq_desc;
 

commit 478735e38887077ac77a9756121b6ce0cb956e2f
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Wed Oct 27 15:34:15 2010 -0700

    /proc/stat: fix scalability of irq sum of all cpu
    
    In /proc/stat, the number of per-IRQ event is shown by making a sum each
    irq's events on all cpus.  But we can make use of kstat_irqs().
    
    kstat_irqs() do the same calculation, If !CONFIG_GENERIC_HARDIRQ,
    it's not a big cost. (Both of the number of cpus and irqs are small.)
    
    If a system is very big and CONFIG_GENERIC_HARDIRQ, it does
    
            for_each_irq()
                    for_each_cpu()
                            - look up a radix tree
                            - read desc->irq_stat[cpu]
    This seems not efficient. This patch adds kstat_irqs() for
    CONFIG_GENRIC_HARDIRQ and change the calculation as
    
            for_each_irq()
                    look up radix tree
                    for_each_cpu()
                            - read desc->irq_stat[cpu]
    
    This reduces cost.
    
    A test on (4096cpusp, 256 nodes, 4592 irqs) host (by Jack Steiner)
    
    %time cat /proc/stat > /dev/null
    
    Before Patch:    2.459 sec
    After Patch :     .561 sec
    
    [akpm@linux-foundation.org: unexport kstat_irqs, coding-style tweaks]
    [akpm@linux-foundation.org: fix unused variable 'per_irq_sum']
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Tested-by: Jack Steiner <steiner@sgi.com>
    Acked-by: Jack Steiner <steiner@sgi.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 8b9b89085530..ad54c846911b 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -86,6 +86,7 @@ static inline unsigned int kstat_softirqs_cpu(unsigned int irq, int cpu)
 /*
  * Number of interrupts per specific IRQ source, since bootup
  */
+#ifndef CONFIG_GENERIC_HARDIRQS
 static inline unsigned int kstat_irqs(unsigned int irq)
 {
 	unsigned int sum = 0;
@@ -96,6 +97,9 @@ static inline unsigned int kstat_irqs(unsigned int irq)
 
 	return sum;
 }
+#else
+extern unsigned int kstat_irqs(unsigned int irq);
+#endif
 
 /*
  * Number of interrupts per cpu, since bootup

commit f2c66cd8eeddedb440f33bc0f5cec1ed7ae376cb
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Wed Oct 27 15:34:13 2010 -0700

    /proc/stat: scalability of irq num per cpu
    
    /proc/stat shows the total number of all interrupts to each cpu.  But when
    the number of IRQs are very large, it take very long time and 'cat
    /proc/stat' takes more than 10 secs.  This is because sum of all irq
    events are counted when /proc/stat is read.  This patch adds "sum of all
    irq" counter percpu and reduce read costs.
    
    The cost of reading /proc/stat is important because it's used by major
    applications as 'top', 'ps', 'w', etc....
    
    A test on a mechin (4096cpu, 256 nodes, 4592 irqs) shows
    
     %time cat /proc/stat > /dev/null
     Before Patch:  12.627 sec
     After  Patch:  2.459 sec
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Tested-by: Jack Steiner <steiner@sgi.com>
    Acked-by: Jack Steiner <steiner@sgi.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index c059044bc6dc..8b9b89085530 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -33,6 +33,7 @@ struct kernel_stat {
 #ifndef CONFIG_GENERIC_HARDIRQS
        unsigned int irqs[NR_IRQS];
 #endif
+	unsigned long irqs_sum;
 	unsigned int softirqs[NR_SOFTIRQS];
 };
 
@@ -54,6 +55,7 @@ static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
 					    struct irq_desc *desc)
 {
 	kstat_this_cpu.irqs[irq]++;
+	kstat_this_cpu.irqs_sum++;
 }
 
 static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
@@ -65,8 +67,9 @@ static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
 #define kstat_irqs_this_cpu(DESC) \
 	((DESC)->kstat_irqs[smp_processor_id()])
-#define kstat_incr_irqs_this_cpu(irqno, DESC) \
-	((DESC)->kstat_irqs[smp_processor_id()]++)
+#define kstat_incr_irqs_this_cpu(irqno, DESC) do {\
+	((DESC)->kstat_irqs[smp_processor_id()]++);\
+	kstat_this_cpu.irqs_sum++; } while (0)
 
 #endif
 
@@ -94,6 +97,13 @@ static inline unsigned int kstat_irqs(unsigned int irq)
 	return sum;
 }
 
+/*
+ * Number of interrupts per cpu, since bootup
+ */
+static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
+{
+	return kstat_cpu(cpu).irqs_sum;
+}
 
 /*
  * Lock/unlock the current runqueue - to extract task statistics:

commit ce0e7b28fb75cb003cfc8d0238613aaf1c55e797
Author: Ryota Ozaki <ozaki.ryota@gmail.com>
Date:   Sat Oct 24 01:20:10 2009 +0900

    sched, cpuacct: Fix niced guest time accounting
    
    CPU time of a guest is always accounted in 'user' time
    without concern for the nice value of its counterpart
    process although the guest is scheduled under the nice
    value.
    
    This patch fixes the defect and accounts cpu time of
    a niced guest in 'nice' time as same as a niced process.
    
    And also the patch adds 'guest_nice' to cpuacct. The
    value provides niced guest cpu time which is like 'nice'
    to 'user'.
    
    The original discussions can be found here:
    
      http://www.mail-archive.com/kvm@vger.kernel.org/msg23982.html
      http://www.mail-archive.com/kvm@vger.kernel.org/msg23860.html
    
    Signed-off-by: Ryota Ozaki <ozaki.ryota@gmail.com>
    Acked-by: Avi Kivity <avi@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <1256314810-7897-1-git-send-email-ozaki.ryota@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 348fa8874b52..c059044bc6dc 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -25,6 +25,7 @@ struct cpu_usage_stat {
 	cputime64_t iowait;
 	cputime64_t steal;
 	cputime64_t guest;
+	cputime64_t guest_nice;
 };
 
 struct kernel_stat {

commit aa0ce5bbc2dbb1853bd0c6d13f17716fcc38ac5a
Author: Keika Kobayashi <kobayashi.kk@ncos.nec.co.jp>
Date:   Wed Jun 17 16:25:52 2009 -0700

    softirq: introduce statistics for softirq
    
    Statistics for softirq doesn't exist.
    It will be helpful like statistics for interrupts.
    This patch introduces counting the number of softirq,
    which will be exported in /proc/softirqs.
    
    When softirq handler consumes much CPU time,
    /proc/stat is like the following.
    
    $ while :; do  cat /proc/stat | head -n1 ; sleep 10 ; done
    cpu  88 0 408 739665 583 28 2 0 0
    cpu  450 0 1090 740970 594 28 1294 0 0
                                  ^^^^
                                 softirq
    
    In such a situation,
    /proc/softirqs shows us which softirq handler is invoked.
    We can see the increase rate of softirqs.
    
    <before>
    $ cat /proc/softirqs
                    CPU0       CPU1       CPU2       CPU3
    HI                 0          0          0          0
    TIMER         462850     462805     462782     462718
    NET_TX             0          0          0        365
    NET_RX          2472          2          2         40
    BLOCK              0          0        381       1164
    TASKLET            0          0          0        224
    SCHED         462654     462689     462698     462427
    RCU             3046       2423       3367       3173
    
    <after>
    $ cat /proc/softirqs
                    CPU0       CPU1       CPU2       CPU3
    HI                 0          0          0          0
    TIMER         463361     465077     465056     464991
    NET_TX            53          0          1        365
    NET_RX          3757          2          2         40
    BLOCK              0          0        398       1170
    TASKLET            0          0          0        224
    SCHED         463074     464318     464612     463330
    RCU             3505       2948       3947       3673
    
    When CPU TIME of softirq is high,
    the rates of increase is the following.
      TIMER  : 220/sec     : CPU1-3
      NET_TX : 5/sec       : CPU0
      NET_RX : 120/sec     : CPU0
      SCHED  : 40-200/sec  : all CPU
      RCU    : 45-58/sec   : all CPU
    
    The rates of increase in an idle mode is the following.
      TIMER  : 250/sec
      SCHED  : 250/sec
      RCU    : 2/sec
    
    It seems many softirqs for receiving packets and rcu are invoked.  This
    gives us help for checking system.
    
    Signed-off-by: Keika Kobayashi <kobayashi.kk@ncos.nec.co.jp>
    Reviewed-by: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Eric Dumazet <dada1@cosmosbay.com>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index a77c6007dc99..348fa8874b52 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -5,6 +5,7 @@
 #include <linux/threads.h>
 #include <linux/percpu.h>
 #include <linux/cpumask.h>
+#include <linux/interrupt.h>
 #include <asm/irq.h>
 #include <asm/cputime.h>
 
@@ -31,6 +32,7 @@ struct kernel_stat {
 #ifndef CONFIG_GENERIC_HARDIRQS
        unsigned int irqs[NR_IRQS];
 #endif
+	unsigned int softirqs[NR_SOFTIRQS];
 };
 
 DECLARE_PER_CPU(struct kernel_stat, kstat);
@@ -67,6 +69,16 @@ extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
 
 #endif
 
+static inline void kstat_incr_softirqs_this_cpu(unsigned int irq)
+{
+	kstat_this_cpu.softirqs[irq]++;
+}
+
+static inline unsigned int kstat_softirqs_cpu(unsigned int irq, int cpu)
+{
+       return kstat_cpu(cpu).softirqs[irq];
+}
+
 /*
  * Number of interrupts per specific IRQ source, since bootup
  */

commit f1f9b3b1795da8625e0e6096813c9d18d4a344ce
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Apr 20 20:38:21 2009 +0200

    perfcounters, sched: remove __task_delta_exec()
    
    This function was left orphan by the latest round of sw-counter
    cleanups.
    
    [ Impact: remove unused kernel function ]
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 080d1fd461d7..a77c6007dc99 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -85,7 +85,6 @@ static inline unsigned int kstat_irqs(unsigned int irq)
 /*
  * Lock/unlock the current runqueue - to extract task statistics:
  */
-extern unsigned long long __task_delta_exec(struct task_struct *tsk, int update);
 extern unsigned long long task_delta_exec(struct task_struct *);
 
 extern void account_user_time(struct task_struct *, cputime_t, cputime_t);

commit 849691a6cd40270ff5f4a8846d5f6bf8df663ffc
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Apr 6 11:45:12 2009 +0200

    perf_counter: remove rq->lock usage
    
    Now that all the task runtime clock users are gone, remove the ugly
    rq->lock usage from perf counters, which solves the nasty deadlock
    seen when a software task clock counter was read from an NMI overflow
    context.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    LKML-Reference: <20090406094518.531137582@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index b6d2887a5d88..080d1fd461d7 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -85,8 +85,6 @@ static inline unsigned int kstat_irqs(unsigned int irq)
 /*
  * Lock/unlock the current runqueue - to extract task statistics:
  */
-extern void curr_rq_lock_irq_save(unsigned long *flags);
-extern void curr_rq_unlock_irq_restore(unsigned long *flags);
 extern unsigned long long __task_delta_exec(struct task_struct *tsk, int update);
 extern unsigned long long task_delta_exec(struct task_struct *);
 

commit f541ae326fa120fa5c57433e4d9a133df212ce41
Merge: e255357764f9 0221c81b1b8e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Apr 6 09:02:57 2009 +0200

    Merge branch 'linus' into perfcounters/core-v2
    
    Merge reason: we have gathered quite a few conflicts, need to merge upstream
    
    Conflicts:
            arch/powerpc/kernel/Makefile
            arch/x86/ia32/ia32entry.S
            arch/x86/include/asm/hardirq.h
            arch/x86/include/asm/unistd_32.h
            arch/x86/include/asm/unistd_64.h
            arch/x86/kernel/cpu/common.c
            arch/x86/kernel/irq.c
            arch/x86/kernel/syscall_table_32.S
            arch/x86/mm/iomap_32.c
            include/linux/sched.h
            kernel/Makefile
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit d52a61c04c6c0814ca270a088feedb126436598e
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 22 00:38:56 2009 -0800

    irq: clean up irq stat methods
    
    David Miller suggested, related to a kstat_irqs related build breakage:
    
    > Either linux/kernel_stat.h provides the kstat_incr_irqs_this_cpu
    > interface or linux/irq.h does, not both.
    
    So move them to kernel_stat.h.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index a3431b164bea..0c8b89f28a95 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -52,16 +52,19 @@ static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
 {
 	kstat_this_cpu.irqs[irq]++;
 }
-#endif
-
 
-#ifndef CONFIG_GENERIC_HARDIRQS
 static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 {
        return kstat_cpu(cpu).irqs[irq];
 }
 #else
+#include <linux/irq.h>
 extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
+#define kstat_irqs_this_cpu(DESC) \
+	((DESC)->kstat_irqs[smp_processor_id()])
+#define kstat_incr_irqs_this_cpu(irqno, DESC) \
+	((DESC)->kstat_irqs[smp_processor_id()]++)
+
 #endif
 
 /*

commit d7e51e66899f95dabc89b4d4c6674a6e50fa37fc
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Jan 7 15:03:13 2009 -0800

    sparseirq: make some func to be used with genirq
    
    Impact: clean up sparseirq fallout on random.c
    
    Ingo suggested to change some ifdef from SPARSE_IRQ to GENERIC_HARDIRQS
    so we could some #ifdef later if all arch support genirq
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Matt Mackall <mpm@selenic.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 570d20413119..a3431b164bea 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -28,7 +28,7 @@ struct cpu_usage_stat {
 
 struct kernel_stat {
 	struct cpu_usage_stat	cpustat;
-#ifndef CONFIG_SPARSE_IRQ
+#ifndef CONFIG_GENERIC_HARDIRQS
        unsigned int irqs[NR_IRQS];
 #endif
 };
@@ -41,7 +41,7 @@ DECLARE_PER_CPU(struct kernel_stat, kstat);
 
 extern unsigned long long nr_context_switches(void);
 
-#ifndef CONFIG_SPARSE_IRQ
+#ifndef CONFIG_GENERIC_HARDIRQS
 #define kstat_irqs_this_cpu(irq) \
 	(kstat_this_cpu.irqs[irq])
 
@@ -55,7 +55,7 @@ static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
 #endif
 
 
-#ifndef CONFIG_SPARSE_IRQ
+#ifndef CONFIG_GENERIC_HARDIRQS
 static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 {
        return kstat_cpu(cpu).irqs[irq];

commit 506c10f26c481b7f8ef27c1c79290f68989b2e9e
Merge: e1df957670ae c59765042f53
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 11 02:42:53 2009 +0100

    Merge commit 'v2.6.29-rc1' into perfcounters/core
    
    Conflicts:
            include/linux/kernel_stat.h

commit 79741dd35713ff4f6fd0eafd59fa94e8a4ba922d
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Dec 31 15:11:38 2008 +0100

    [PATCH] idle cputime accounting
    
    The cpu time spent by the idle process actually doing something is
    currently accounted as idle time. This is plain wrong, the architectures
    that support VIRT_CPU_ACCOUNTING=y can do better: distinguish between the
    time spent doing nothing and the time spent by idle doing work. The first
    is accounted with account_idle_time and the second with account_system_time.
    The architectures that use the account_xxx_time interface directly and not
    the account_xxx_ticks interface now need to do the check for the idle
    process in their arch code. In particular to improve the system vs true
    idle time accounting the arch code needs to measure the true idle time
    instead of just testing for the idle process.
    To improve the tick based accounting as well we would need an architecture
    primitive that can tell us if the pt_regs of the interrupted context
    points to the magic instruction that halts the cpu.
    
    In addition idle time is no more added to the stime of the idle process.
    This field now contains the system time of the idle process as it should
    be. On systems without VIRT_CPU_ACCOUNTING this will always be zero as
    every tick that occurs while idle is running will be accounted as idle
    time.
    
    This patch contains the necessary common code changes to be able to
    distinguish idle system time and true idle time. The architectures with
    support for VIRT_CPU_ACCOUNTING need some changes to exploit this.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index c78a459662a6..570d20413119 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -81,6 +81,11 @@ static inline unsigned int kstat_irqs(unsigned int irq)
 extern unsigned long long task_delta_exec(struct task_struct *);
 extern void account_user_time(struct task_struct *, cputime_t, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t, cputime_t);
-extern void account_steal_time(struct task_struct *, cputime_t);
+extern void account_steal_time(cputime_t);
+extern void account_idle_time(cputime_t);
+
+extern void account_process_tick(struct task_struct *, int user);
+extern void account_steal_ticks(unsigned long ticks);
+extern void account_idle_ticks(unsigned long ticks);
 
 #endif /* _LINUX_KERNEL_STAT_H */

commit 457533a7d3402d1d91fbc125c8bd1bd16dcd3cd4
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Dec 31 15:11:37 2008 +0100

    [PATCH] fix scaled & unscaled cputime accounting
    
    The utimescaled / stimescaled fields in the task structure and the
    global cpustat should be set on all architectures. On s390 the calls
    to account_user_time_scaled and account_system_time_scaled never have
    been added. In addition system time that is accounted as guest time
    to the user time of a process is accounted to the scaled system time
    instead of the scaled user time.
    To fix the bugs and to prevent future forgetfulness this patch merges
    account_system_time_scaled into account_system_time and
    account_user_time_scaled into account_user_time.
    
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Cc: Michael Neuling <mikey@neuling.org>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 4ee4b3d2316f..c78a459662a6 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -79,10 +79,8 @@ static inline unsigned int kstat_irqs(unsigned int irq)
 }
 
 extern unsigned long long task_delta_exec(struct task_struct *);
-extern void account_user_time(struct task_struct *, cputime_t);
-extern void account_user_time_scaled(struct task_struct *, cputime_t);
-extern void account_system_time(struct task_struct *, int, cputime_t);
-extern void account_system_time_scaled(struct task_struct *, cputime_t);
+extern void account_user_time(struct task_struct *, cputime_t, cputime_t);
+extern void account_system_time(struct task_struct *, int, cputime_t, cputime_t);
 extern void account_steal_time(struct task_struct *, cputime_t);
 
 #endif /* _LINUX_KERNEL_STAT_H */

commit aa9c4c0f967fdb482ea95e8473ec3d201e6e0781
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Dec 17 14:10:57 2008 +0100

    perfcounters: fix task clock counter
    
    Impact: fix per task clock counter precision
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 4a145caeee07..1b2e3242497c 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -66,7 +66,15 @@ static inline unsigned int kstat_irqs(unsigned int irq)
 	return sum;
 }
 
+
+/*
+ * Lock/unlock the current runqueue - to extract task statistics:
+ */
+extern void curr_rq_lock_irq_save(unsigned long *flags);
+extern void curr_rq_unlock_irq_restore(unsigned long *flags);
+extern unsigned long long __task_delta_exec(struct task_struct *tsk, int update);
 extern unsigned long long task_delta_exec(struct task_struct *);
+
 extern void account_user_time(struct task_struct *, cputime_t);
 extern void account_user_time_scaled(struct task_struct *, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t);

commit 0b8f1efad30bd58f89961b82dfe68b9edf8fd2ac
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Dec 5 18:58:31 2008 -0800

    sparse irq_desc[] array: core kernel and x86 changes
    
    Impact: new feature
    
    Problem on distro kernels: irq_desc[NR_IRQS] takes megabytes of RAM with
    NR_CPUS set to large values. The goal is to be able to scale up to much
    larger NR_IRQS value without impacting the (important) common case.
    
    To solve this, we generalize irq_desc[NR_IRQS] to an (optional) array of
    irq_desc pointers.
    
    When CONFIG_SPARSE_IRQ=y is used, we use kzalloc_node to get irq_desc,
    this also makes the IRQ descriptors NUMA-local (to the site that calls
    request_irq()).
    
    This gets rid of the irq_cfg[] static array on x86 as well: irq_cfg now
    uses desc->chip_data for x86 to store irq_cfg.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 4a145caeee07..4ee4b3d2316f 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -28,7 +28,9 @@ struct cpu_usage_stat {
 
 struct kernel_stat {
 	struct cpu_usage_stat	cpustat;
-	unsigned int irqs[NR_IRQS];
+#ifndef CONFIG_SPARSE_IRQ
+       unsigned int irqs[NR_IRQS];
+#endif
 };
 
 DECLARE_PER_CPU(struct kernel_stat, kstat);
@@ -39,6 +41,10 @@ DECLARE_PER_CPU(struct kernel_stat, kstat);
 
 extern unsigned long long nr_context_switches(void);
 
+#ifndef CONFIG_SPARSE_IRQ
+#define kstat_irqs_this_cpu(irq) \
+	(kstat_this_cpu.irqs[irq])
+
 struct irq_desc;
 
 static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
@@ -46,11 +52,17 @@ static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
 {
 	kstat_this_cpu.irqs[irq]++;
 }
+#endif
+
 
+#ifndef CONFIG_SPARSE_IRQ
 static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 {
        return kstat_cpu(cpu).irqs[irq];
 }
+#else
+extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
+#endif
 
 /*
  * Number of interrupts per specific IRQ source, since bootup

commit 9301975ec251bab1ad7cfcb84a688b26187e4e4a
Merge: 7110879cf2af dd3a1db900f2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 20 13:22:50 2008 -0700

    Merge branch 'genirq-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    This merges branches irq/genirq, irq/sparseirq-v4, timers/hpet-percpu
    and x86/uv.
    
    The sparseirq branch is just preliminary groundwork: no sparse IRQs are
    actually implemented by this tree anymore - just the new APIs are added
    while keeping the old way intact as well (the new APIs map 1:1 to
    irq_desc[]).  The 'real' sparse IRQ support will then be a relatively
    small patch ontop of this - with a v2.6.29 merge target.
    
    * 'genirq-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (178 commits)
      genirq: improve include files
      intr_remapping: fix typo
      io_apic: make irq_mis_count available on 64-bit too
      genirq: fix name space collisions of nr_irqs in arch/*
      genirq: fix name space collision of nr_irqs in autoprobe.c
      genirq: use iterators for irq_desc loops
      proc: fixup irq iterator
      genirq: add reverse iterator for irq_desc
      x86: move ack_bad_irq() to irq.c
      x86: unify show_interrupts() and proc helpers
      x86: cleanup show_interrupts
      genirq: cleanup the sparseirq modifications
      genirq: remove artifacts from sparseirq removal
      genirq: revert dynarray
      genirq: remove irq_to_desc_alloc
      genirq: remove sparse irq code
      genirq: use inline function for irq_to_desc
      genirq: consolidate nr_irqs and for_each_irq_desc()
      x86: remove sparse irq from Kconfig
      genirq: define nr_irqs for architectures with GENERIC_HARDIRQS=n
      ...

commit a1aca5de08a0cb840a90fb3f729a5940f8d21185
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Oct 15 19:29:15 2008 +0200

    genirq: remove artifacts from sparseirq removal
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index a9d0d360b776..89b6ecd41473 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -28,7 +28,7 @@ struct cpu_usage_stat {
 
 struct kernel_stat {
 	struct cpu_usage_stat	cpustat;
-       unsigned int irqs[NR_IRQS];
+	unsigned int irqs[NR_IRQS];
 };
 
 DECLARE_PER_CPU(struct kernel_stat, kstat);

commit d6c88a507ef0b6afdb013cba4e7804ba7324d99a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Oct 15 15:27:23 2008 +0200

    genirq: revert dynarray
    
    Revert the dynarray changes. They need more thought and polishing.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 21249d8c1293..a9d0d360b776 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -28,9 +28,7 @@ struct cpu_usage_stat {
 
 struct kernel_stat {
 	struct cpu_usage_stat	cpustat;
-#ifndef CONFIG_HAVE_DYN_ARRAY
        unsigned int irqs[NR_IRQS];
-#endif
 };
 
 DECLARE_PER_CPU(struct kernel_stat, kstat);
@@ -41,20 +39,18 @@ DECLARE_PER_CPU(struct kernel_stat, kstat);
 
 extern unsigned long long nr_context_switches(void);
 
-#ifndef CONFIG_HAVE_DYN_ARRAY
-#define kstat_irqs_this_cpu(irq) \
-	(kstat_this_cpu.irqs[irq])
-#endif
+struct irq_desc;
 
+static inline void kstat_incr_irqs_this_cpu(unsigned int irq,
+					    struct irq_desc *desc)
+{
+	kstat_this_cpu.irqs[irq]++;
+}
 
-#ifndef CONFIG_HAVE_DYN_ARRAY
 static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 {
        return kstat_cpu(cpu).irqs[irq];
 }
-#else
-extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
-#endif
 
 /*
  * Number of interrupts per specific IRQ source, since bootup

commit 8c464a4b23ca283b414022ebc77787f3c7040fa7
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Mon Aug 25 12:41:19 2008 -0700

    sparseirq: move kstat_irqs from kstat to irq_desc - fix
    
    fix non-sparseirq architectures.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index f10616712de5..21249d8c1293 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -28,7 +28,7 @@ struct cpu_usage_stat {
 
 struct kernel_stat {
 	struct cpu_usage_stat	cpustat;
-#ifndef CONFIG_GENERIC_HARDIRQS
+#ifndef CONFIG_HAVE_DYN_ARRAY
        unsigned int irqs[NR_IRQS];
 #endif
 };
@@ -41,7 +41,13 @@ DECLARE_PER_CPU(struct kernel_stat, kstat);
 
 extern unsigned long long nr_context_switches(void);
 
-#ifndef CONFIG_GENERIC_HARDIRQS
+#ifndef CONFIG_HAVE_DYN_ARRAY
+#define kstat_irqs_this_cpu(irq) \
+	(kstat_this_cpu.irqs[irq])
+#endif
+
+
+#ifndef CONFIG_HAVE_DYN_ARRAY
 static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 {
        return kstat_cpu(cpu).irqs[irq];

commit 7f95ec9e4c12fd067febfd57532da1166d75d858
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:09 2008 -0700

    x86: move kstat_irqs from kstat to irq_desc
    
    based on Eric's patch ...
    
    together mold it with dyn_array for irq_desc, will allcate kstat_irqs for
    nr_irq_desc alltogether if needed. -- at that point nr_cpus is known already.
    
    v2: make sure system without generic_hardirqs works they don't have irq_desc
    v3: fix merging
    v4: [mingo@elte.hu] fix typo
    
    [ mingo@elte.hu ] irq: build fix
    
    fix:
    
     arch/x86/xen/spinlock.c: In function 'xen_spin_lock_slow':
     arch/x86/xen/spinlock.c:90: error: 'struct kernel_stat' has no member named 'irqs'
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index fe1f7fe534b4..f10616712de5 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -28,10 +28,8 @@ struct cpu_usage_stat {
 
 struct kernel_stat {
 	struct cpu_usage_stat	cpustat;
-#ifdef CONFIG_HAVE_DYN_ARRAY
-	unsigned int *irqs;
-#else
-	unsigned int irqs[NR_IRQS];
+#ifndef CONFIG_GENERIC_HARDIRQS
+       unsigned int irqs[NR_IRQS];
 #endif
 };
 
@@ -43,15 +41,25 @@ DECLARE_PER_CPU(struct kernel_stat, kstat);
 
 extern unsigned long long nr_context_switches(void);
 
+#ifndef CONFIG_GENERIC_HARDIRQS
+static inline unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
+{
+       return kstat_cpu(cpu).irqs[irq];
+}
+#else
+extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
+#endif
+
 /*
  * Number of interrupts per specific IRQ source, since bootup
  */
-static inline int kstat_irqs(int irq)
+static inline unsigned int kstat_irqs(unsigned int irq)
 {
-	int cpu, sum = 0;
+	unsigned int sum = 0;
+	int cpu;
 
 	for_each_possible_cpu(cpu)
-		sum += kstat_cpu(cpu).irqs[irq];
+		sum += kstat_irqs_cpu(irq, cpu);
 
 	return sum;
 }

commit d17a55ded3393ad3878010bb3a8243a15a8d8df5
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:01 2008 -0700

    irq: make irqs in kernel stat use per_cpu_dyn_array
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index cf9f40a91c9c..fe1f7fe534b4 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -28,7 +28,11 @@ struct cpu_usage_stat {
 
 struct kernel_stat {
 	struct cpu_usage_stat	cpustat;
+#ifdef CONFIG_HAVE_DYN_ARRAY
+	unsigned int *irqs;
+#else
 	unsigned int irqs[NR_IRQS];
+#endif
 };
 
 DECLARE_PER_CPU(struct kernel_stat, kstat);

commit bb34d92f643086d546b49cef680f6f305ed84414
Author: Frank Mayhar <fmayhar@google.com>
Date:   Fri Sep 12 09:54:39 2008 -0700

    timers: fix itimer/many thread hang, v2
    
    This is the second resubmission of the posix timer rework patch, posted
    a few days ago.
    
    This includes the changes from the previous resubmittion, which addressed
    Oleg Nesterov's comments, removing the RCU stuff from the patch and
    un-inlining the thread_group_cputime() function for SMP.
    
    In addition, per Ingo Molnar it simplifies the UP code, consolidating much
    of it with the SMP version and depending on lower-level SMP/UP handling to
    take care of the differences.
    
    It also cleans up some UP compile errors, moves the scheduler stats-related
    macros into kernel/sched_stats.h, cleans up a merge error in
    kernel/fork.c and has a few other minor fixes and cleanups as suggested
    by Oleg and Ingo. Thanks for the review, guys.
    
    Signed-off-by: Frank Mayhar <fmayhar@google.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index cf9f40a91c9c..cac3750cd65e 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -52,6 +52,7 @@ static inline int kstat_irqs(int irq)
 	return sum;
 }
 
+extern unsigned long long task_delta_exec(struct task_struct *);
 extern void account_user_time(struct task_struct *, cputime_t);
 extern void account_user_time_scaled(struct task_struct *, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t);

commit 6859a8402945cf1d74af75a2e1aa4e327a506ab4
Author: Alan Mayer <ajm@sgi.com>
Date:   Wed Mar 26 16:11:31 2008 -0500

    x86: resize NR_IRQS for large machines
    
    On machines with very large numbers of cpus, tables that are dimensioned
    by NR_IRQS get very large, especially the irq_desc table.  They are also
    very sparsely used.  When the cpu count is > MAX_IO_APICS, use MAX_IO_APICS
    to set NR_IRQS, otherwise use NR_CPUS.
    
    Signed-off-by: Alan Mayer <ajm@sgi.com>
    Reviewed-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index e8ffce898bf9..cf9f40a91c9c 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -1,11 +1,11 @@
 #ifndef _LINUX_KERNEL_STAT_H
 #define _LINUX_KERNEL_STAT_H
 
-#include <asm/irq.h>
 #include <linux/smp.h>
 #include <linux/threads.h>
 #include <linux/percpu.h>
 #include <linux/cpumask.h>
+#include <asm/irq.h>
 #include <asm/cputime.h>
 
 /*

commit c66f08be7e3ad0a28bcd9a0aef766fdf08ea0ec6
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Oct 18 03:06:34 2007 -0700

    Add scaled time to taskstats based process accounting
    
    This adds items to the taststats struct to account for user and system
    time based on scaling the CPU frequency and instruction issue rates.
    
    Adds account_(user|system)_time_scaled callbacks which architectures
    can use to account for time using this mechanism.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Jay Lan <jlan@engr.sgi.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 12bf44f083f5..e8ffce898bf9 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -53,7 +53,9 @@ static inline int kstat_irqs(int irq)
 }
 
 extern void account_user_time(struct task_struct *, cputime_t);
+extern void account_user_time_scaled(struct task_struct *, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t);
+extern void account_system_time_scaled(struct task_struct *, cputime_t);
 extern void account_steal_time(struct task_struct *, cputime_t);
 
 #endif /* _LINUX_KERNEL_STAT_H */

commit 5e84cfde51cf303d368fcb48f22059f37b3872de
Author: Laurent Vivier <Laurent.Vivier@bull.net>
Date:   Mon Oct 15 17:00:19 2007 +0200

    sched: guest CPU accounting: add guest-CPU /proc/stat field
    
    as recent CPUs introduce a third running state, after "user" and
    "system", we need a new field, "guest", in cpustat to store the time
    used by the CPU to run virtual CPU. Modify /proc/stat to display this
    new field.
    
    Signed-off-by: Laurent Vivier <Laurent.Vivier@bull.net>
    Acked-by: Avi Kivity <avi@qumranet.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 43e895f1cabe..12bf44f083f5 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -23,6 +23,7 @@ struct cpu_usage_stat {
 	cputime64_t idle;
 	cputime64_t iowait;
 	cputime64_t steal;
+	cputime64_t guest;
 };
 
 struct kernel_stat {

commit 62c4f0a2d5a188f73a94f2cb8ea0dba3e7cf0a7f
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Wed Apr 26 12:56:16 2006 +0100

    Don't include linux/config.h from anywhere else in include/
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index b46249082cca..43e895f1cabe 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -1,7 +1,6 @@
 #ifndef _LINUX_KERNEL_STAT_H
 #define _LINUX_KERNEL_STAT_H
 
-#include <linux/config.h>
 #include <asm/irq.h>
 #include <linux/smp.h>
 #include <linux/threads.h>

commit 0a945022778f100115d0cb6234eb28fc1b15ccaf
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Tue Mar 28 01:56:37 2006 -0800

    [PATCH] for_each_possible_cpu: fixes for generic part
    
    replaces for_each_cpu with for_each_possible_cpu().
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index a484572c302e..b46249082cca 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -46,7 +46,7 @@ static inline int kstat_irqs(int irq)
 {
 	int cpu, sum = 0;
 
-	for_each_cpu(cpu)
+	for_each_possible_cpu(cpu)
 		sum += kstat_cpu(cpu).irqs[irq];
 
 	return sum;

commit 28ef35845f2c8da8e1bed068277d2fab1e8c8979
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Nov 7 00:59:29 2005 -0800

    [PATCH] small kernel_stat.h cleanup
    
    cleanup: use for_each_cpu() instead of an open-coded NR_CPUS loop.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index dba27749b428..a484572c302e 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -6,6 +6,7 @@
 #include <linux/smp.h>
 #include <linux/threads.h>
 #include <linux/percpu.h>
+#include <linux/cpumask.h>
 #include <asm/cputime.h>
 
 /*
@@ -43,11 +44,10 @@ extern unsigned long long nr_context_switches(void);
  */
 static inline int kstat_irqs(int irq)
 {
-	int i, sum=0;
+	int cpu, sum = 0;
 
-	for (i = 0; i < NR_CPUS; i++)
-		if (cpu_possible(i))
-			sum += kstat_cpu(i).irqs[irq];
+	for_each_cpu(cpu)
+		sum += kstat_cpu(cpu).irqs[irq];
 
 	return sum;
 }

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
new file mode 100644
index 000000000000..dba27749b428
--- /dev/null
+++ b/include/linux/kernel_stat.h
@@ -0,0 +1,59 @@
+#ifndef _LINUX_KERNEL_STAT_H
+#define _LINUX_KERNEL_STAT_H
+
+#include <linux/config.h>
+#include <asm/irq.h>
+#include <linux/smp.h>
+#include <linux/threads.h>
+#include <linux/percpu.h>
+#include <asm/cputime.h>
+
+/*
+ * 'kernel_stat.h' contains the definitions needed for doing
+ * some kernel statistics (CPU usage, context switches ...),
+ * used by rstatd/perfmeter
+ */
+
+struct cpu_usage_stat {
+	cputime64_t user;
+	cputime64_t nice;
+	cputime64_t system;
+	cputime64_t softirq;
+	cputime64_t irq;
+	cputime64_t idle;
+	cputime64_t iowait;
+	cputime64_t steal;
+};
+
+struct kernel_stat {
+	struct cpu_usage_stat	cpustat;
+	unsigned int irqs[NR_IRQS];
+};
+
+DECLARE_PER_CPU(struct kernel_stat, kstat);
+
+#define kstat_cpu(cpu)	per_cpu(kstat, cpu)
+/* Must have preemption disabled for this to be meaningful. */
+#define kstat_this_cpu	__get_cpu_var(kstat)
+
+extern unsigned long long nr_context_switches(void);
+
+/*
+ * Number of interrupts per specific IRQ source, since bootup
+ */
+static inline int kstat_irqs(int irq)
+{
+	int i, sum=0;
+
+	for (i = 0; i < NR_CPUS; i++)
+		if (cpu_possible(i))
+			sum += kstat_cpu(i).irqs[irq];
+
+	return sum;
+}
+
+extern void account_user_time(struct task_struct *, cputime_t);
+extern void account_system_time(struct task_struct *, int, cputime_t);
+extern void account_steal_time(struct task_struct *, cputime_t);
+
+#endif /* _LINUX_KERNEL_STAT_H */
