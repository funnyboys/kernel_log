commit 7b59435a2afed12dc9b2ec1b930efa2e94f1c397
Author: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
Date:   Mon Jun 1 21:48:03 2020 -0700

    buffer_head.h: remove attach_page_buffers
    
    All the callers have replaced attach_page_buffers with the new function
    attach_page_private, so remove it.
    
    Signed-off-by: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Roman Gushchin <guro@fb.com>
    Cc: Andreas Dilger <adilger@dilger.ca>
    Link: http://lkml.kernel.org/r/20200517214718.468-10-guoqing.jiang@cloud.ionos.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 15b765a181b8..22fb11e2d2e0 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -272,14 +272,6 @@ void buffer_init(void);
  * inline definitions
  */
 
-static inline void attach_page_buffers(struct page *page,
-		struct buffer_head *head)
-{
-	get_page(page);
-	SetPagePrivate(page);
-	set_page_private(page, (unsigned long)head);
-}
-
 static inline void get_bh(struct buffer_head *bh)
 {
         atomic_inc(&bh->b_count);

commit d87f639258a6a5980183f11876c884931ad93da2
Author: Roman Gushchin <guro@fb.com>
Date:   Fri Feb 28 16:14:11 2020 -0800

    ext4: use non-movable memory for superblock readahead
    
    Since commit a8ac900b8163 ("ext4: use non-movable memory for the
    superblock") buffers for ext4 superblock were allocated using
    the sb_bread_unmovable() helper which allocated buffer heads
    out of non-movable memory blocks. It was necessarily to not block
    page migrations and do not cause cma allocation failures.
    
    However commit 85c8f176a611 ("ext4: preload block group descriptors")
    broke this by introducing pre-reading of the ext4 superblock.
    The problem is that __breadahead() is using __getblk() underneath,
    which allocates buffer heads out of movable memory.
    
    It resulted in page migration failures I've seen on a machine
    with an ext4 partition and a preallocated cma area.
    
    Fix this by introducing sb_breadahead_unmovable() and
    __breadahead_gfp() helpers which use non-movable memory for buffer
    head allocations and use them for the ext4 superblock readahead.
    
    Reviewed-by: Andreas Dilger <adilger@dilger.ca>
    Fixes: 85c8f176a611 ("ext4: preload block group descriptors")
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Link: https://lore.kernel.org/r/20200229001411.128010-1-guro@fb.com
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index e0b020eaf32e..15b765a181b8 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -189,6 +189,8 @@ struct buffer_head *__getblk_gfp(struct block_device *bdev, sector_t block,
 void __brelse(struct buffer_head *);
 void __bforget(struct buffer_head *);
 void __breadahead(struct block_device *, sector_t block, unsigned int size);
+void __breadahead_gfp(struct block_device *, sector_t block, unsigned int size,
+		  gfp_t gfp);
 struct buffer_head *__bread_gfp(struct block_device *,
 				sector_t block, unsigned size, gfp_t gfp);
 void invalidate_bh_lrus(void);
@@ -319,6 +321,12 @@ sb_breadahead(struct super_block *sb, sector_t block)
 	__breadahead(sb->s_bdev, block, sb->s_blocksize);
 }
 
+static inline void
+sb_breadahead_unmovable(struct super_block *sb, sector_t block)
+{
+	__breadahead_gfp(sb->s_bdev, block, sb->s_blocksize, 0);
+}
+
 static inline struct buffer_head *
 sb_getblk(struct super_block *sb, sector_t block)
 {

commit f1e67e355c2aafeddf1eac31335709236996d2fe
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Nov 18 14:28:24 2019 +0100

    fs/buffer: Make BH_Uptodate_Lock bit_spin_lock a regular spinlock_t
    
    Bit spinlocks are problematic if PREEMPT_RT is enabled, because they
    disable preemption, which is undesired for latency reasons and breaks when
    regular spinlocks are taken within the bit_spinlock locked region because
    regular spinlocks are converted to 'sleeping spinlocks' on RT.
    
    PREEMPT_RT replaced the bit spinlocks with regular spinlocks to avoid this
    problem. The replacement was done conditionaly at compile time, but
    Christoph requested to do an unconditional conversion.
    
    Jan suggested to move the spinlock into a existing padding hole which
    avoids a size increase of struct buffer_head on production kernels.
    
    As a benefit the lock gains lockdep coverage.
    
    [ bigeasy: Remove the wrapper and use always spinlock_t and move it into
               the padding hole ]
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Christoph Hellwig <hch@infradead.org>
    Link: https://lkml.kernel.org/r/20191118132824.rclhrbujqh4b4g4d@linutronix.de

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 7b73ef7f902d..e0b020eaf32e 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -22,9 +22,6 @@ enum bh_state_bits {
 	BH_Dirty,	/* Is dirty */
 	BH_Lock,	/* Is locked */
 	BH_Req,		/* Has been submitted for I/O */
-	BH_Uptodate_Lock,/* Used by the first bh in a page, to serialise
-			  * IO completion of other buffers in the page
-			  */
 
 	BH_Mapped,	/* Has a disk mapping */
 	BH_New,		/* Disk mapping was newly created by get_block */
@@ -76,6 +73,9 @@ struct buffer_head {
 	struct address_space *b_assoc_map;	/* mapping this buffer is
 						   associated with */
 	atomic_t b_count;		/* users using this buffer_head */
+	spinlock_t b_uptodate_lock;	/* Used by the first bh in a page, to
+					 * serialise IO completion of other
+					 * buffers in the page */
 };
 
 /*

commit 401b25aa1a75e7fe4e3202a6336604269697d705
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Tue Oct 2 22:20:50 2018 -0400

    ext4: convert fault handler to use vm_fault_t type
    
    Return type of ext4_page_mkwrite and ext4_filemap_fault are
    changed to use vm_fault_t type.
    
    With this patch all the callers of block_page_mkwrite_return()
    are changed to handle vm_fault_t. So converting the return type
    of block_page_mkwrite_return() to vm_fault_t.
    
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Reviewed-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 96225a77c112..7b73ef7f902d 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -242,7 +242,7 @@ int block_commit_write(struct page *page, unsigned from, unsigned to);
 int block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
 				get_block_t get_block);
 /* Convert errno to return value from ->page_mkwrite() call */
-static inline int block_page_mkwrite_return(int err)
+static inline vm_fault_t block_page_mkwrite_return(int err)
 {
 	if (err == 0)
 		return VM_FAULT_LOCKED;

commit 8a78cb1f1b98e5ea970674e0f049832d19e76ace
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 1 09:04:40 2018 -0700

    fs: move page_cache_seek_hole_data to iomap.c
    
    This function is only used by the iomap code, depends on being called
    from it, and will soon stop poking into buffer head internals.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Andreas Gruenbacher <agruenba@redhat.com>
    Reviewed-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 894e5d125de6..96225a77c112 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -205,8 +205,6 @@ void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);
 int bh_uptodate_or_lock(struct buffer_head *bh);
 int bh_submit_read(struct buffer_head *bh);
-loff_t page_cache_seek_hole_data(struct inode *inode, loff_t offset,
-				 loff_t length, int whence);
 
 extern int buffer_heads_over_limit;
 

commit 64b28683deba132f301d1cecfc25c32e295f53a1
Merge: d3658c226601 1d5187757879
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Feb 4 11:16:35 2018 -0800

    Merge tag 'for-linus-20180204' of git://git.kernel.dk/linux-block
    
    Pull more block updates from Jens Axboe:
     "Most of this is fixes and not new code/features:
    
       - skd fix from Arnd, fixing a build error dependent on sla allocator
         type.
    
       - blk-mq scheduler discard merging fixes, one from me and one from
         Keith. This fixes a segment miscalculation for blk-mq-sched, where
         we mistakenly think two segments are physically contigious even
         though the request isn't carrying real data. Also fixes a bio-to-rq
         merge case.
    
       - Don't re-set a bit on the buffer_head flags, if it's already set.
         This can cause scalability concerns on bigger machines and
         workloads. From Kemi Wang.
    
       - Add BLK_STS_DEV_RESOURCE return value to blk-mq, allowing us to
         distuingish between a local (device related) resource starvation
         and a global one. The latter might happen without IO being in
         flight, so it has to be handled a bit differently. From Ming"
    
    * tag 'for-linus-20180204' of git://git.kernel.dk/linux-block:
      block: skd: fix incorrect linux/slab_def.h inclusion
      buffer: Avoid setting buffer bits that are already set
      blk-mq-sched: Enable merging discard bio into request
      blk-mq: fix discard merge with scheduler attached
      blk-mq: introduce BLK_STS_DEV_RESOURCE

commit 60f91826ca62bcf85d6d5fc90941337282787671
Author: Kemi Wang <kemi.wang@intel.com>
Date:   Tue Oct 24 09:16:42 2017 +0800

    buffer: Avoid setting buffer bits that are already set
    
    It's expensive to set buffer flags that are already set, because that
    causes a costly cache line transition.
    
    A common case is setting the "verified" flag during ext4 writes.
    This patch checks for the flag being set first.
    
    With the AIM7/creat-clo benchmark testing on a 48G ramdisk based-on ext4
    file system, we see 3.3%(15431->15936) improvement of aim7.jobs-per-min on
    a 2-sockets broadwell platform.
    
    What the benchmark does is: it forks 3000 processes, and each  process do
    the following:
    a) open a new file
    b) close the file
    c) delete the file
    until loop=100*1000 times.
    
    The original patch is contributed by Andi Kleen.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Tested-by: Kemi Wang <kemi.wang@intel.com>
    Signed-off-by: Kemi Wang <kemi.wang@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 8b1bf8d3d4a2..06797ef10fd9 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -81,11 +81,14 @@ struct buffer_head {
 /*
  * macro tricks to expand the set_buffer_foo(), clear_buffer_foo()
  * and buffer_foo() functions.
+ * To avoid reset buffer flags that are already set, because that causes
+ * a costly cache line transition, check the flag first.
  */
 #define BUFFER_FNS(bit, name)						\
 static __always_inline void set_buffer_##name(struct buffer_head *bh)	\
 {									\
-	set_bit(BH_##bit, &(bh)->b_state);				\
+	if (!test_bit(BH_##bit, &(bh)->b_state))			\
+		set_bit(BH_##bit, &(bh)->b_state);			\
 }									\
 static __always_inline void clear_buffer_##name(struct buffer_head *bh)	\
 {									\

commit 01950a349ec254f28bf9ad06e74a166521d213e1
Author: Eric Biggers <ebiggers@google.com>
Date:   Tue Jan 16 22:25:12 2018 -0800

    fs/buffer.c: fold init_buffer() into init_page_buffers()
    
    Since commit e76004093db1 ("fs/buffer.c: remove unnecessary init
    operation after allocating buffer_head"), there are no callers of
    init_buffer() outside of init_page_buffers().  So just fold it into
    init_page_buffers().
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 8b1bf8d3d4a2..58a82f58e44e 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -151,7 +151,6 @@ void buffer_check_dirty_writeback(struct page *page,
 
 void mark_buffer_dirty(struct buffer_head *bh);
 void mark_buffer_write_io_error(struct buffer_head *bh);
-void init_buffer(struct buffer_head *, bh_end_io_t *, void *);
 void touch_buffer(struct buffer_head *bh);
 void set_bh_page(struct buffer_head *bh,
 		struct page *page, unsigned long offset);

commit e2c5923c349c1738fe8fda980874d93f6fb2e5b6
Merge: abc36be23635 a04b5de5050a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 15:32:19 2017 -0800

    Merge branch 'for-4.15/block' of git://git.kernel.dk/linux-block
    
    Pull core block layer updates from Jens Axboe:
     "This is the main pull request for block storage for 4.15-rc1.
    
      Nothing out of the ordinary in here, and no API changes or anything
      like that. Just various new features for drivers, core changes, etc.
      In particular, this pull request contains:
    
       - A patch series from Bart, closing the whole on blk/scsi-mq queue
         quescing.
    
       - A series from Christoph, building towards hidden gendisks (for
         multipath) and ability to move bio chains around.
    
       - NVMe
            - Support for native multipath for NVMe (Christoph).
            - Userspace notifications for AENs (Keith).
            - Command side-effects support (Keith).
            - SGL support (Chaitanya Kulkarni)
            - FC fixes and improvements (James Smart)
            - Lots of fixes and tweaks (Various)
    
       - bcache
            - New maintainer (Michael Lyle)
            - Writeback control improvements (Michael)
            - Various fixes (Coly, Elena, Eric, Liang, et al)
    
       - lightnvm updates, mostly centered around the pblk interface
         (Javier, Hans, and Rakesh).
    
       - Removal of unused bio/bvec kmap atomic interfaces (me, Christoph)
    
       - Writeback series that fix the much discussed hundreds of millions
         of sync-all units. This goes all the way, as discussed previously
         (me).
    
       - Fix for missing wakeup on writeback timer adjustments (Yafang
         Shao).
    
       - Fix laptop mode on blk-mq (me).
    
       - {mq,name} tupple lookup for IO schedulers, allowing us to have
         alias names. This means you can use 'deadline' on both !mq and on
         mq (where it's called mq-deadline). (me).
    
       - blktrace race fix, oopsing on sg load (me).
    
       - blk-mq optimizations (me).
    
       - Obscure waitqueue race fix for kyber (Omar).
    
       - NBD fixes (Josef).
    
       - Disable writeback throttling by default on bfq, like we do on cfq
         (Luca Miccio).
    
       - Series from Ming that enable us to treat flush requests on blk-mq
         like any other request. This is a really nice cleanup.
    
       - Series from Ming that improves merging on blk-mq with schedulers,
         getting us closer to flipping the switch on scsi-mq again.
    
       - BFQ updates (Paolo).
    
       - blk-mq atomic flags memory ordering fixes (Peter Z).
    
       - Loop cgroup support (Shaohua).
    
       - Lots of minor fixes from lots of different folks, both for core and
         driver code"
    
    * 'for-4.15/block' of git://git.kernel.dk/linux-block: (294 commits)
      nvme: fix visibility of "uuid" ns attribute
      blk-mq: fixup some comment typos and lengths
      ide: ide-atapi: fix compile error with defining macro DEBUG
      blk-mq: improve tag waiting setup for non-shared tags
      brd: remove unused brd_mutex
      blk-mq: only run the hardware queue if IO is pending
      block: avoid null pointer dereference on null disk
      fs: guard_bio_eod() needs to consider partitions
      xtensa/simdisk: fix compile error
      nvme: expose subsys attribute to sysfs
      nvme: create 'slaves' and 'holders' entries for hidden controllers
      block: create 'slaves' and 'holders' entries for hidden gendisks
      nvme: also expose the namespace identification sysfs files for mpath nodes
      nvme: implement multipath access to nvme subsystems
      nvme: track shared namespaces
      nvme: introduce a nvme_ns_ids structure
      nvme: track subsystems
      block, nvme: Introduce blk_mq_req_flags_t
      block, scsi: Make SCSI quiesce and resume work reliably
      block: Add the QUEUE_FLAG_PREEMPT_ONLY request queue flag
      ...

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 446b24cac67d..afa37f807f12 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * include/linux/buffer_head.h
  *

commit f892760aa66a2d657deaf59538fb69433036767c
Author: Matthew Wilcox <willy@infradead.org>
Date:   Fri Oct 13 15:58:15 2017 -0700

    fs/mpage.c: fix mpage_writepage() for pages with buffers
    
    When using FAT on a block device which supports rw_page, we can hit
    BUG_ON(!PageLocked(page)) in try_to_free_buffers().  This is because we
    call clean_buffers() after unlocking the page we've written.  Introduce
    a new clean_page_buffers() which cleans all buffers associated with a
    page and call it from within bdev_write_page().
    
    [akpm@linux-foundation.org: s/PAGE_SIZE/~0U/ per Linus and Matthew]
    Link: http://lkml.kernel.org/r/20171006211541.GA7409@bombadil.infradead.org
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Reported-by: Toshi Kani <toshi.kani@hpe.com>
    Reported-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Tested-by: Toshi Kani <toshi.kani@hpe.com>
    Acked-by: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index c8dae555eccf..446b24cac67d 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -232,6 +232,7 @@ int generic_write_end(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page *, void *);
 void page_zero_new_buffers(struct page *page, unsigned from, unsigned to);
+void clean_page_buffers(struct page *page);
 int cont_write_begin(struct file *, struct address_space *, loff_t,
 			unsigned, unsigned, struct page **, void **,
 			get_block_t *, loff_t *);

commit 640ab98fb3629c0f8417b9b2532eca596495f3bb
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Sep 27 05:40:16 2017 -0600

    buffer: have alloc_page_buffers() use __GFP_NOFAIL
    
    Instead of adding weird retry logic in that function, utilize
    __GFP_NOFAIL to ensure that the vm takes care of handling any
    potential retries appropriately. This means we don't have to
    call free_more_memory() from here.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index c8dae555eccf..ae2d25f01b98 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -156,7 +156,7 @@ void set_bh_page(struct buffer_head *bh,
 		struct page *page, unsigned long offset);
 int try_to_free_buffers(struct page *);
 struct buffer_head *alloc_page_buffers(struct page *page, unsigned long size,
-		int retry);
+		bool retry);
 void create_empty_buffers(struct page *, unsigned long,
 			unsigned long b_state);
 void end_buffer_read_sync(struct buffer_head *bh, int uptodate);

commit 642338ba33c5331f2b94ca3944845741fbbf8b89
Merge: 6618a24ab231 cd87d8679201
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 10 10:51:53 2017 -0700

    Merge tag 'xfs-4.13-merge-5' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux
    
    Pull XFS updates from Darrick Wong:
     "Here are some changes for you for 4.13. For the most part it's fixes
      for bugs and deadlock problems, and preparation for online fsck in
      some future merge window.
    
       - Avoid quotacheck deadlocks
    
       - Fix transaction overflows when bunmapping fragmented files
    
       - Refactor directory readahead
    
       - Allow admin to configure if ASSERT is fatal
    
       - Improve transaction usage detail logging during overflows
    
       - Minor cleanups
    
       - Don't leak log items when the log shuts down
    
       - Remove double-underscore typedefs
    
       - Various preparation for online scrubbing
    
       - Introduce new error injection configuration sysfs knobs
    
       - Refactor dq_get_next to use extent map directly
    
       - Fix problems with iterating the page cache for unwritten data
    
       - Implement SEEK_{HOLE,DATA} via iomap
    
       - Refactor XFS to use iomap SEEK_HOLE and SEEK_DATA
    
       - Don't use MAXPATHLEN to check on-disk symlink target lengths"
    
    * tag 'xfs-4.13-merge-5' of git://git.kernel.org/pub/scm/fs/xfs/xfs-linux: (48 commits)
      xfs: don't crash on unexpected holes in dir/attr btrees
      xfs: rename MAXPATHLEN to XFS_SYMLINK_MAXLEN
      xfs: fix contiguous dquot chunk iteration livelock
      xfs: Switch to iomap for SEEK_HOLE / SEEK_DATA
      vfs: Add iomap_seek_hole and iomap_seek_data helpers
      vfs: Add page_cache_seek_hole_data helper
      xfs: remove a whitespace-only line from xfs_fs_get_nextdqblk
      xfs: rewrite xfs_dq_get_next_id using xfs_iext_lookup_extent
      xfs: Check for m_errortag initialization in xfs_errortag_test
      xfs: grab dquots without taking the ilock
      xfs: fix semicolon.cocci warnings
      xfs: Don't clear SGID when inheriting ACLs
      xfs: free cowblocks and retry on buffered write ENOSPC
      xfs: replace log_badcrc_factor knob with error injection tag
      xfs: convert drop_writes to use the errortag mechanism
      xfs: remove unneeded parameter from XFS_TEST_ERROR
      xfs: expose errortag knobs via sysfs
      xfs: make errortag a per-mountpoint structure
      xfs: free uncommitted transactions during log recovery
      xfs: don't allow bmap on rt files
      ...

commit 87354e5de04fe727227ff619af164202adcfa4d4
Author: Jeff Layton <jlayton@redhat.com>
Date:   Thu Jul 6 07:02:21 2017 -0400

    buffer: set errors in mapping at the time that the error occurs
    
    I noticed on xfs that I could still sometimes get back an error on fsync
    on a fd that was opened after the error condition had been cleared.
    
    The problem is that the buffer code sets the write_io_error flag and
    then later checks that flag to set the error in the mapping. That flag
    perisists for quite a while however. If the file is later opened with
    O_TRUNC, the buffers will then be invalidated and the mapping's error
    set such that a subsequent fsync will return error. I think this is
    incorrect, as there was no writeback between the open and fsync.
    
    Add a new mark_buffer_write_io_error operation that sets the flag and
    the error in the mapping at the same time. Replace all calls to
    set_buffer_write_io_error with mark_buffer_write_io_error, and remove
    the places that check this flag in order to set the error in the
    mapping.
    
    This sets the error in the mapping earlier, at the time that it's first
    detected.
    
    Signed-off-by: Jeff Layton <jlayton@redhat.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Carlos Maiolino <cmaiolino@redhat.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index bd029e52ef5e..e0abeba3ced7 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -149,6 +149,7 @@ void buffer_check_dirty_writeback(struct page *page,
  */
 
 void mark_buffer_dirty(struct buffer_head *bh);
+void mark_buffer_write_io_error(struct buffer_head *bh);
 void init_buffer(struct buffer_head *, bh_end_io_t *, void *);
 void touch_buffer(struct buffer_head *bh);
 void set_bh_page(struct buffer_head *bh,

commit 334fd34d76f237c0ee58dfc400d2c4e34d660544
Author: Andreas Gruenbacher <agruenba@redhat.com>
Date:   Thu Jun 29 11:43:20 2017 -0700

    vfs: Add page_cache_seek_hole_data helper
    
    Both ext4 and xfs implement seeking for the next hole or piece of data
    in unwritten extents by scanning the page cache, and both versions share
    the same bug when iterating the buffers of a page: the start offset into
    the page isn't taken into account, so when a page fits more than two
    filesystem blocks, things will go wrong.  For example, on a filesystem
    with a block size of 1k, the following command will fail:
    
      xfs_io -f -c "falloc 0 4k" \
                -c "pwrite 1k 1k" \
                -c "pwrite 3k 1k" \
                -c "seek -a -r 0" foo
    
    In this example, neither lseek(fd, 1024, SEEK_HOLE) nor lseek(fd, 2048,
    SEEK_DATA) will return the correct result.
    
    Introduce a generic vfs helper for seeking in the page cache that gets
    this right.  The next commits will replace the filesystem specific
    implementations.
    
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    [hch: dropped the export]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index bd029e52ef5e..ad4e024ce17e 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -201,6 +201,8 @@ void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);
 int bh_uptodate_or_lock(struct buffer_head *bh);
 int bh_submit_read(struct buffer_head *bh);
+loff_t page_cache_seek_hole_data(struct inode *inode, loff_t offset,
+				 loff_t length, int whence);
 
 extern int buffer_heads_over_limit;
 

commit 020c2833dbc76b4069c9a9886b71511052d160df
Author: Eric Biggers <ebiggers@google.com>
Date:   Sat Mar 25 21:02:18 2017 -0700

    fs: remove _submit_bh()
    
    _submit_bh() allowed submitting a buffer_head for I/O using custom
    bio_flags.  It used to be used by jbd to set BIO_SNAP_STABLE, introduced
    by commit 713685111774 ("mm: make snapshotting pages for stable writes a
    per-bio operation").  However, the code and flag has since been removed
    and no _submit_bh() users remain.
    
    These days, bio_flags are mostly used internally by the block layer to
    track the state of bio's.  As such, it doesn't really make sense for
    filesystems to use them instead of op_flags when wanting special
    behavior for block requests.
    
    Therefore, remove _submit_bh() and trim the bio_flags argument from
    submit_bh_wbc().
    
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 79591c3660cc..bd029e52ef5e 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -196,8 +196,6 @@ void ll_rw_block(int, int, int, struct buffer_head * bh[]);
 int sync_dirty_buffer(struct buffer_head *bh);
 int __sync_dirty_buffer(struct buffer_head *bh, int op_flags);
 void write_dirty_buffer(struct buffer_head *bh, int op_flags);
-int _submit_bh(int op, int op_flags, struct buffer_head *bh,
-	       unsigned long bio_flags);
 int submit_bh(int, int, struct buffer_head *);
 void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);

commit 0911d0041c22922228ca52a977d7b0b0159fee4b
Author: Jan Kara <jack@suse.cz>
Date:   Wed Feb 8 14:30:53 2017 -0800

    mm: avoid returning VM_FAULT_RETRY from ->page_mkwrite handlers
    
    Some ->page_mkwrite handlers may return VM_FAULT_RETRY as its return
    code (GFS2 or Lustre can definitely do this).  However VM_FAULT_RETRY
    from ->page_mkwrite is completely unhandled by the mm code and results
    in locking and writeably mapping the page which definitely is not what
    the caller wanted.
    
    Fix Lustre and block_page_mkwrite_ret() used by other filesystems
    (notably GFS2) to return VM_FAULT_NOPAGE instead which results in
    bailing out from the fault code, the CPU then retries the access, and we
    fault again effectively doing what the handler wanted.
    
    Link: http://lkml.kernel.org/r/20170203150729.15863-1-jack@suse.cz
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Reviewed-by: Jinshan Xiong <jinshan.xiong@intel.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index d67ab83823ad..79591c3660cc 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -243,12 +243,10 @@ static inline int block_page_mkwrite_return(int err)
 {
 	if (err == 0)
 		return VM_FAULT_LOCKED;
-	if (err == -EFAULT)
+	if (err == -EFAULT || err == -EAGAIN)
 		return VM_FAULT_NOPAGE;
 	if (err == -ENOMEM)
 		return VM_FAULT_OOM;
-	if (err == -EAGAIN)
-		return VM_FAULT_RETRY;
 	/* -ENOSPC, -EDQUOT, -EIO ... */
 	return VM_FAULT_SIGBUS;
 }

commit ce98321bf7d274a470642ef99e1d82512673ce7c
Author: Jan Kara <jack@suse.cz>
Date:   Fri Nov 4 18:08:16 2016 +0100

    fs: Remove unmap_underlying_metadata
    
    Nobody is using this function anymore. Remove it.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index d1ab91fc6d43..d67ab83823ad 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -168,7 +168,6 @@ int inode_has_buffers(struct inode *);
 void invalidate_inode_buffers(struct inode *);
 int remove_inode_buffers(struct inode *inode);
 int sync_mapping_buffers(struct address_space *mapping);
-void unmap_underlying_metadata(struct block_device *bdev, sector_t block);
 void clean_bdev_aliases(struct block_device *bdev, sector_t block,
 			sector_t len);
 static inline void clean_bdev_bh_alias(struct buffer_head *bh)

commit e64855c6cfaa0a80c1b71c5f647cb792dc436668
Author: Jan Kara <jack@suse.cz>
Date:   Fri Nov 4 18:08:15 2016 +0100

    fs: Add helper to clean bdev aliases under a bh and use it
    
    Add a helper function that clears buffer heads from a block device
    aliasing passed bh. Use this helper function from filesystems instead of
    the original unmap_underlying_metadata() to save some boiler plate code
    and also have a better name for the functionalily since it is not
    unmapping anything for a *long* time.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 9c9c73ce7d4f..d1ab91fc6d43 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -171,6 +171,10 @@ int sync_mapping_buffers(struct address_space *mapping);
 void unmap_underlying_metadata(struct block_device *bdev, sector_t block);
 void clean_bdev_aliases(struct block_device *bdev, sector_t block,
 			sector_t len);
+static inline void clean_bdev_bh_alias(struct buffer_head *bh)
+{
+	clean_bdev_aliases(bh->b_bdev, bh->b_blocknr, 1);
+}
 
 void mark_buffer_async_write(struct buffer_head *bh);
 void __wait_on_buffer(struct buffer_head *);

commit 29f3ad7d8380364c86556eedf4eedd3b3d4921dc
Author: Jan Kara <jack@suse.cz>
Date:   Fri Nov 4 18:08:11 2016 +0100

    fs: Provide function to unmap metadata for a range of blocks
    
    Provide function equivalent to unmap_underlying_metadata() for a range
    of blocks. We somewhat optimize the function to use pagevec lookups
    instead of looking up buffer heads one by one and use page lock to pin
    buffer heads instead of mapping's private_lock to improve scalability.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index ebbacd14d450..9c9c73ce7d4f 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -169,6 +169,8 @@ void invalidate_inode_buffers(struct inode *);
 int remove_inode_buffers(struct inode *inode);
 int sync_mapping_buffers(struct address_space *mapping);
 void unmap_underlying_metadata(struct block_device *bdev, sector_t block);
+void clean_bdev_aliases(struct block_device *bdev, sector_t block,
+			sector_t len);
 
 void mark_buffer_async_write(struct buffer_head *bh);
 void __wait_on_buffer(struct buffer_head *);

commit d05d7f40791ccbb6e543cc5dd6a6aa08fc71d635
Merge: 75a442efb1ca 17007f3994cd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 26 15:03:07 2016 -0700

    Merge branch 'for-4.8/core' of git://git.kernel.dk/linux-block
    
    Pull core block updates from Jens Axboe:
    
       - the big change is the cleanup from Mike Christie, cleaning up our
         uses of command types and modified flags.  This is what will throw
         some merge conflicts
    
       - regression fix for the above for btrfs, from Vincent
    
       - following up to the above, better packing of struct request from
         Christoph
    
       - a 2038 fix for blktrace from Arnd
    
       - a few trivial/spelling fixes from Bart Van Assche
    
       - a front merge check fix from Damien, which could cause issues on
         SMR drives
    
       - Atari partition fix from Gabriel
    
       - convert cfq to highres timers, since jiffies isn't granular enough
         for some devices these days.  From Jan and Jeff
    
       - CFQ priority boost fix idle classes, from me
    
       - cleanup series from Ming, improving our bio/bvec iteration
    
       - a direct issue fix for blk-mq from Omar
    
       - fix for plug merging not involving the IO scheduler, like we do for
         other types of merges.  From Tahsin
    
       - expose DAX type internally and through sysfs.  From Toshi and Yigal
    
    * 'for-4.8/core' of git://git.kernel.dk/linux-block: (76 commits)
      block: Fix front merge check
      block: do not merge requests without consulting with io scheduler
      block: Fix spelling in a source code comment
      block: expose QUEUE_FLAG_DAX in sysfs
      block: add QUEUE_FLAG_DAX for devices to advertise their DAX support
      Btrfs: fix comparison in __btrfs_map_block()
      block: atari: Return early for unsupported sector size
      Doc: block: Fix a typo in queue-sysfs.txt
      cfq-iosched: Charge at least 1 jiffie instead of 1 ns
      cfq-iosched: Fix regression in bonnie++ rewrite performance
      cfq-iosched: Convert slice_resid from u64 to s64
      block: Convert fifo_time from ulong to u64
      blktrace: avoid using timespec
      block/blk-cgroup.c: Declare local symbols static
      block/bio-integrity.c: Add #include "blk.h"
      block/partition-generic.c: Remove a set-but-not-used variable
      block: bio: kill BIO_MAX_SIZE
      cfq-iosched: temporarily boost queue priority for idle classes
      block: drbd: avoid to use BIO_MAX_SIZE
      block: bio: remove BIO_MAX_SECTORS
      ...

commit b4bba38909c21689de21355e84259cb7b38f25ac
Author: Benjamin Marzinski <bmarzins@redhat.com>
Date:   Mon Jun 27 09:58:40 2016 -0500

    fs: export __block_write_full_page
    
    gfs2 needs to be able to skip the check to see if a page is outside of
    the file size when writing it out. gfs2 can get into a situation where
    it needs to flush its in-memory log to disk while a truncate is in
    progress. If the file being trucated has data journaling enabled, it is
    possible that there are data blocks in the log that are past the end of
    the file. gfs can't finish the log flush without either writing these
    blocks out or revoking them. Otherwise, if the node crashed, it could
    overwrite subsequent changes made by other nodes in the cluster when
    it's journal was replayed.
    
    Unfortunately, there is no way to add log entries to the log during a
    flush. So gfs2 simply writes out the page instead. This situation can
    only occur when the truncate code still has the file locked exclusively,
    and hasn't marked this block as free in the metadata (which happens
    later in truc_dealloc).  After gfs2 writes this page out, the truncation
    code will shortly invalidate it and write out any revokes if necessary.
    
    In order to make this work, gfs2 needs to be able to skip the check for
    writes outside the file size. Since the check exists in
    block_write_full_page, this patch exports __block_write_full_page, which
    doesn't have the check.
    
    Signed-off-by: Benjamin Marzinski <bmarzins@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index d48daa3f6f20..7e14e545c4b6 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -208,6 +208,9 @@ void block_invalidatepage(struct page *page, unsigned int offset,
 			  unsigned int length);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
+int __block_write_full_page(struct inode *inode, struct page *page,
+			get_block_t *get_block, struct writeback_control *wbc,
+			bh_end_io_t *handler);
 int block_read_full_page(struct page*, get_block_t*);
 int block_is_partially_uptodate(struct page *page, unsigned long from,
 				unsigned long count);

commit dfec8a14fc9043039e3c04807caf39dc71102816
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:44 2016 -0500

    fs: have ll_rw_block users pass in op and flags separately
    
    This has ll_rw_block users pass in the operation and flags separately,
    so ll_rw_block can setup the bio op and bi_rw flags on the bio that
    is submitted.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index bc9a45d1e3af..d1dd29338ba0 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -187,7 +187,7 @@ struct buffer_head *alloc_buffer_head(gfp_t gfp_flags);
 void free_buffer_head(struct buffer_head * bh);
 void unlock_buffer(struct buffer_head *bh);
 void __lock_buffer(struct buffer_head *bh);
-void ll_rw_block(int, int, struct buffer_head * bh[]);
+void ll_rw_block(int, int, int, struct buffer_head * bh[]);
 int sync_dirty_buffer(struct buffer_head *bh);
 int __sync_dirty_buffer(struct buffer_head *bh, int op_flags);
 void write_dirty_buffer(struct buffer_head *bh, int op_flags);

commit 2a222ca992c35aee1e83af428f3dd26a3f5d5d94
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:43 2016 -0500

    fs: have submit_bh users pass in op and flags separately
    
    This has submit_bh users pass in the operation and flags separately,
    so submit_bh_wbc can setup the bio op and bi_rw flags on the bio that
    is submitted.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index d48daa3f6f20..bc9a45d1e3af 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -189,10 +189,11 @@ void unlock_buffer(struct buffer_head *bh);
 void __lock_buffer(struct buffer_head *bh);
 void ll_rw_block(int, int, struct buffer_head * bh[]);
 int sync_dirty_buffer(struct buffer_head *bh);
-int __sync_dirty_buffer(struct buffer_head *bh, int rw);
-void write_dirty_buffer(struct buffer_head *bh, int rw);
-int _submit_bh(int rw, struct buffer_head *bh, unsigned long bio_flags);
-int submit_bh(int, struct buffer_head *);
+int __sync_dirty_buffer(struct buffer_head *bh, int op_flags);
+void write_dirty_buffer(struct buffer_head *bh, int op_flags);
+int _submit_bh(int op, int op_flags, struct buffer_head *bh,
+	       unsigned long bio_flags);
+int submit_bh(int, int, struct buffer_head *);
 void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);
 int bh_uptodate_or_lock(struct buffer_head *bh);

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index c67f052cc5e5..d48daa3f6f20 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -43,7 +43,7 @@ enum bh_state_bits {
 			 */
 };
 
-#define MAX_BUF_PER_PAGE (PAGE_CACHE_SIZE / 512)
+#define MAX_BUF_PER_PAGE (PAGE_SIZE / 512)
 
 struct page;
 struct buffer_head;
@@ -263,7 +263,7 @@ void buffer_init(void);
 static inline void attach_page_buffers(struct page *page,
 		struct buffer_head *head)
 {
-	page_cache_get(page);
+	get_page(page);
 	SetPagePrivate(page);
 	set_page_private(page, (unsigned long)head);
 }

commit ee91ef6173e81819f5ff610c2485802081635657
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Thu Mar 17 14:18:21 2016 -0700

    bufferhead: force inlining of buffer head flag operations
    
    With both gcc 4.7.2 and 4.9.2, sometimes gcc mysteriously doesn't inline
    very small functions we expect to be inlined.  See
    
        https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66122
    
    With this .config:
    http://busybox.net/~vda/kernel_config_OPTIMIZE_INLINING_and_Os,
    set_buffer_foo(), clear_buffer_foo() and similar functions get deinlined
    about 60 times. Examples of disassembly:
    
    <set_buffer_mapped> (14 copies, 43 calls):
           55                      push   %rbp
           48 89 e5                mov    %rsp,%rbp
           f0 80 0f 20             lock orb $0x20,(%rdi)
           5d                      pop    %rbp
           c3                      retq
    <buffer_mapped> (3 copies, 34 calls):
           48 8b 07                mov    (%rdi),%rax
           55                      push   %rbp
           48 89 e5                mov    %rsp,%rbp
           48 c1 e8 05             shr    $0x5,%rax
           83 e0 01                and    $0x1,%eax
           5d                      pop    %rbp
           c3                      retq
    <set_buffer_new> (5 copies, 13 calls):
           55                      push   %rbp
           48 89 e5                mov    %rsp,%rbp
           f0 80 0f 40             lock orb $0x40,(%rdi)
           5d                      pop    %rbp
           c3                      retq
    
    This patch fixes this via s/inline/__always_inline/.
    This decreases vmlinux by about 3 kbytes.
    
        text            data             bss              dec           hex filename
    88200439        19905208        36421632        144527279       89d4faf vmlinux2
    88197239        19905240        36421632        144524111       89d434f vmlinux
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Graf <tgraf@suug.ch>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 89d9aa9e79bf..c67f052cc5e5 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -82,15 +82,15 @@ struct buffer_head {
  * and buffer_foo() functions.
  */
 #define BUFFER_FNS(bit, name)						\
-static inline void set_buffer_##name(struct buffer_head *bh)		\
+static __always_inline void set_buffer_##name(struct buffer_head *bh)	\
 {									\
 	set_bit(BH_##bit, &(bh)->b_state);				\
 }									\
-static inline void clear_buffer_##name(struct buffer_head *bh)		\
+static __always_inline void clear_buffer_##name(struct buffer_head *bh)	\
 {									\
 	clear_bit(BH_##bit, &(bh)->b_state);				\
 }									\
-static inline int buffer_##name(const struct buffer_head *bh)		\
+static __always_inline int buffer_##name(const struct buffer_head *bh)	\
 {									\
 	return test_bit(BH_##bit, &(bh)->b_state);			\
 }
@@ -99,11 +99,11 @@ static inline int buffer_##name(const struct buffer_head *bh)		\
  * test_set_buffer_foo() and test_clear_buffer_foo()
  */
 #define TAS_BUFFER_FNS(bit, name)					\
-static inline int test_set_buffer_##name(struct buffer_head *bh)	\
+static __always_inline int test_set_buffer_##name(struct buffer_head *bh) \
 {									\
 	return test_and_set_bit(BH_##bit, &(bh)->b_state);		\
 }									\
-static inline int test_clear_buffer_##name(struct buffer_head *bh)	\
+static __always_inline int test_clear_buffer_##name(struct buffer_head *bh) \
 {									\
 	return test_and_clear_bit(BH_##bit, &(bh)->b_state);		\
 }									\

commit 5c50002963369c7c622b18ff751719eadbe225c5
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Tue Oct 13 16:51:02 2015 -0600

    vfs: remove unused wrapper block_page_mkwrite()
    
    The function currently called "__block_page_mkwrite()" used to be called
    "block_page_mkwrite()" until a wrapper for this function was added by:
    
    commit 24da4fab5a61 ("vfs: Create __block_page_mkwrite() helper passing
            error values back")
    
    This wrapper, the current "block_page_mkwrite()", is currently unused.
    __block_page_mkwrite() is used directly by ext4, nilfs2 and xfs.
    
    Remove the unused wrapper, rename __block_page_mkwrite() back to
    block_page_mkwrite() and update the comment above block_page_mkwrite().
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Jan Kara <jack@suse.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index e6797ded700e..89d9aa9e79bf 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -227,8 +227,6 @@ int cont_write_begin(struct file *, struct address_space *, loff_t,
 			get_block_t *, loff_t *);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
-int __block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
-				get_block_t get_block);
 int block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
 				get_block_t get_block);
 /* Convert errno to return value from ->page_mkwrite() call */

commit bd7ade3cd9b0850264306f5c2b79024a417b6396
Author: Nikolay Borisov <kernel@kyup.com>
Date:   Thu Jul 2 01:32:44 2015 -0400

    bufferhead: Add _gfp version for sb_getblk()
    
    sb_getblk() is used during ext4 (and possibly other FSes) writeback
    paths. Sometimes such path require allocating memory and guaranteeing
    that such allocation won't block. Currently, however, there is no way
    to provide user flags for sb_getblk which could lead to deadlocks.
    
    This patch implements a sb_getblk_gfp with the only difference it can
    accept user-provided GFP flags.
    
    Signed-off-by: Nikolay Borisov <kernel@kyup.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@vger.kernel.org

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 73b45225a7ca..e6797ded700e 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -317,6 +317,13 @@ sb_getblk(struct super_block *sb, sector_t block)
 	return __getblk_gfp(sb->s_bdev, block, sb->s_blocksize, __GFP_MOVABLE);
 }
 
+
+static inline struct buffer_head *
+sb_getblk_gfp(struct super_block *sb, sector_t block, gfp_t gfp)
+{
+	return __getblk_gfp(sb->s_bdev, block, sb->s_blocksize, gfp);
+}
+
 static inline struct buffer_head *
 sb_find_get_block(struct super_block *sb, sector_t block)
 {

commit 3b5e6454aaf6b4439b19400d8365e2ec2d24e411
Author: Gioh Kim <gioh.kim@lge.com>
Date:   Thu Sep 4 22:04:42 2014 -0400

    fs/buffer.c: support buffer cache allocations with gfp modifiers
    
    A buffer cache is allocated from movable area because it is referred
    for a while and released soon.  But some filesystems are taking buffer
    cache for a long time and it can disturb page migration.
    
    New APIs are introduced to allocate buffer cache with user specific
    flag.  *_gfp APIs are for user want to set page allocation flag for
    page cache allocation.  And *_unmovable APIs are for the user wants to
    allocate page cache from non-movable area.
    
    Signed-off-by: Gioh Kim <gioh.kim@lge.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Reviewed-by: Jan Kara <jack@suse.cz>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 324329ceea1e..73b45225a7ca 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -175,12 +175,13 @@ void __wait_on_buffer(struct buffer_head *);
 wait_queue_head_t *bh_waitq_head(struct buffer_head *bh);
 struct buffer_head *__find_get_block(struct block_device *bdev, sector_t block,
 			unsigned size);
-struct buffer_head *__getblk(struct block_device *bdev, sector_t block,
-			unsigned size);
+struct buffer_head *__getblk_gfp(struct block_device *bdev, sector_t block,
+				  unsigned size, gfp_t gfp);
 void __brelse(struct buffer_head *);
 void __bforget(struct buffer_head *);
 void __breadahead(struct block_device *, sector_t block, unsigned int size);
-struct buffer_head *__bread(struct block_device *, sector_t block, unsigned size);
+struct buffer_head *__bread_gfp(struct block_device *,
+				sector_t block, unsigned size, gfp_t gfp);
 void invalidate_bh_lrus(void);
 struct buffer_head *alloc_buffer_head(gfp_t gfp_flags);
 void free_buffer_head(struct buffer_head * bh);
@@ -295,7 +296,13 @@ static inline void bforget(struct buffer_head *bh)
 static inline struct buffer_head *
 sb_bread(struct super_block *sb, sector_t block)
 {
-	return __bread(sb->s_bdev, block, sb->s_blocksize);
+	return __bread_gfp(sb->s_bdev, block, sb->s_blocksize, __GFP_MOVABLE);
+}
+
+static inline struct buffer_head *
+sb_bread_unmovable(struct super_block *sb, sector_t block)
+{
+	return __bread_gfp(sb->s_bdev, block, sb->s_blocksize, 0);
 }
 
 static inline void
@@ -307,7 +314,7 @@ sb_breadahead(struct super_block *sb, sector_t block)
 static inline struct buffer_head *
 sb_getblk(struct super_block *sb, sector_t block)
 {
-	return __getblk(sb->s_bdev, block, sb->s_blocksize);
+	return __getblk_gfp(sb->s_bdev, block, sb->s_blocksize, __GFP_MOVABLE);
 }
 
 static inline struct buffer_head *
@@ -344,6 +351,36 @@ static inline void lock_buffer(struct buffer_head *bh)
 		__lock_buffer(bh);
 }
 
+static inline struct buffer_head *getblk_unmovable(struct block_device *bdev,
+						   sector_t block,
+						   unsigned size)
+{
+	return __getblk_gfp(bdev, block, size, 0);
+}
+
+static inline struct buffer_head *__getblk(struct block_device *bdev,
+					   sector_t block,
+					   unsigned size)
+{
+	return __getblk_gfp(bdev, block, size, __GFP_MOVABLE);
+}
+
+/**
+ *  __bread() - reads a specified block and returns the bh
+ *  @bdev: the block_device to read from
+ *  @block: number of block
+ *  @size: size (in bytes) to read
+ *
+ *  Reads a specified block, and returns buffer head that contains it.
+ *  The page cache is allocated from movable area so that it can be migrated.
+ *  It returns NULL if the block was unreadable.
+ */
+static inline struct buffer_head *
+__bread(struct block_device *bdev, sector_t block, unsigned size)
+{
+	return __bread_gfp(bdev, block, size, __GFP_MOVABLE);
+}
+
 extern int __set_page_dirty_buffers(struct page *page);
 
 #else /* CONFIG_BLOCK */

commit 1b938c0827478df268d2336469ec48d400a2eb3e
Author: Matthew Wilcox <matthew.r.wilcox@intel.com>
Date:   Wed Jun 4 16:07:43 2014 -0700

    fs/buffer.c: remove block_write_full_page_endio()
    
    The last in-tree caller of block_write_full_page_endio() was removed in
    January 2013.  It's time to remove the EXPORT_SYMBOL, which leaves
    block_write_full_page() as the only caller of
    block_write_full_page_endio(), so inline block_write_full_page_endio()
    into block_write_full_page().
    
    Signed-off-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dheeraj Reddy <dheeraj.reddy@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 7cbf837a279c..324329ceea1e 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -207,8 +207,6 @@ void block_invalidatepage(struct page *page, unsigned int offset,
 			  unsigned int length);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
-int block_write_full_page_endio(struct page *page, get_block_t *get_block,
-			struct writeback_control *wbc, bh_end_io_t *handler);
 int block_read_full_page(struct page*, get_block_t*);
 int block_is_partially_uptodate(struct page *page, unsigned long from,
 				unsigned long count);

commit 4e857c58efeb99393cba5a5d0d8ec7117183137c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Mar 17 18:06:10 2014 +0100

    arch: Mass conversion of smp_mb__*()
    
    Mostly scripted conversion of the smp_mb__* barriers.
    
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/n/tip-55dhyhocezdw1dg7u19hmh1u@git.kernel.org
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index c40302f909ce..7cbf837a279c 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -278,7 +278,7 @@ static inline void get_bh(struct buffer_head *bh)
 
 static inline void put_bh(struct buffer_head *bh)
 {
-        smp_mb__before_atomic_dec();
+        smp_mb__before_atomic();
         atomic_dec(&bh->b_count);
 }
 

commit c186afb4dbd0050a537b96c7fbee2dba3b57fc38
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Feb 2 21:16:54 2014 -0500

    switch ->is_partially_uptodate() to saner arguments
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index d77797a52b7b..c40302f909ce 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -210,8 +210,8 @@ int block_write_full_page(struct page *page, get_block_t *get_block,
 int block_write_full_page_endio(struct page *page, get_block_t *get_block,
 			struct writeback_control *wbc, bh_end_io_t *handler);
 int block_read_full_page(struct page*, get_block_t*);
-int block_is_partially_uptodate(struct page *page, read_descriptor_t *desc,
-				unsigned long from);
+int block_is_partially_uptodate(struct page *page, unsigned long from,
+				unsigned long count);
 int block_write_begin(struct address_space *mapping, loff_t pos, unsigned len,
 		unsigned flags, struct page **pagep, get_block_t *get_block);
 int __block_write_begin(struct page *page, loff_t pos, unsigned len,

commit 7b7a8665edd8db733980389b098530f9e4f630b2
Author: Christoph Hellwig <hch@infradead.org>
Date:   Wed Sep 4 15:04:39 2013 +0200

    direct-io: Implement generic deferred AIO completions
    
    Add support to the core direct-io code to defer AIO completions to user
    context using a workqueue.  This replaces opencoded and less efficient
    code in XFS and ext4 (we save a memory allocation for each direct IO)
    and will be needed to properly support O_(D)SYNC for AIO.
    
    The communication between the filesystem and the direct I/O code requires
    a new buffer head flag, which is a bit ugly but not avoidable until the
    direct I/O code stops abusing the buffer_head structure for communicating
    with the filesystems.
    
    Currently this creates a per-superblock unbound workqueue for these
    completions, which is taken from an earlier patch by Jan Kara.  I'm
    not really convinced about this use and would prefer a "normal" global
    workqueue with a high concurrency limit, but this needs further discussion.
    
    JK: Fixed ext4 part, dynamic allocation of the workqueue.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 91fa9a94ae92..d77797a52b7b 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -36,6 +36,7 @@ enum bh_state_bits {
 	BH_Quiet,	/* Buffer Error Prinks to be quiet */
 	BH_Meta,	/* Buffer contains metadata */
 	BH_Prio,	/* Buffer should be submitted with REQ_PRIO */
+	BH_Defer_Completion, /* Defer AIO completion to workqueue */
 
 	BH_PrivateStart,/* not a state bit, but the first bit available
 			 * for private allocation by other entities
@@ -128,6 +129,7 @@ BUFFER_FNS(Write_EIO, write_io_error)
 BUFFER_FNS(Unwritten, unwritten)
 BUFFER_FNS(Meta, meta)
 BUFFER_FNS(Prio, prio)
+BUFFER_FNS(Defer_Completion, defer_completion)
 
 #define bh_offset(bh)		((unsigned long)(bh)->b_data & ~PAGE_MASK)
 

commit b45972265f823ed01eae0867a176320071665787
Author: Mel Gorman <mgorman@suse.de>
Date:   Wed Jul 3 15:02:05 2013 -0700

    mm: vmscan: take page buffers dirty and locked state into account
    
    Page reclaim keeps track of dirty and under writeback pages and uses it
    to determine if wait_iff_congested() should stall or if kswapd should
    begin writing back pages.  This fails to account for buffer pages that
    can be under writeback but not PageWriteback which is the case for
    filesystems like ext3 ordered mode.  Furthermore, PageDirty buffer pages
    can have all the buffers clean and writepage does no IO so it should not
    be accounted as congested.
    
    This patch adds an address_space operation that filesystems may
    optionally use to check if a page is really dirty or really under
    writeback.  An implementation is provided for for buffer_heads is added
    and used for block operations and ext3 in ordered mode.  By default the
    page flags are obeyed.
    
    Credit goes to Jan Kara for identifying that the page flags alone are
    not sufficient for ext3 and sanity checking a number of ideas on how the
    problem could be addressed.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Valdis Kletnieks <Valdis.Kletnieks@vt.edu>
    Cc: Zlatko Calusic <zcalusic@bitsync.net>
    Cc: dormando <dormando@rydia.net>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index f5a3b838ddb0..91fa9a94ae92 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -139,6 +139,9 @@ BUFFER_FNS(Prio, prio)
 	})
 #define page_has_buffers(page)	PagePrivate(page)
 
+void buffer_check_dirty_writeback(struct page *page,
+				     bool *dirty, bool *writeback);
+
 /*
  * Declarations
  */

commit d47992f86b307985b3215bcf141d56d1849d71df
Author: Lukas Czerner <lczerner@redhat.com>
Date:   Tue May 21 23:17:23 2013 -0400

    mm: change invalidatepage prototype to accept length
    
    Currently there is no way to truncate partial page where the end
    truncate point is not at the end of the page. This is because it was not
    needed and the functionality was enough for file system truncate
    operation to work properly. However more file systems now support punch
    hole feature and it can benefit from mm supporting truncating page just
    up to the certain point.
    
    Specifically, with this functionality truncate_inode_pages_range() can
    be changed so it supports truncating partial page at the end of the
    range (currently it will BUG_ON() if 'end' is not at the end of the
    page).
    
    This commit changes the invalidatepage() address space operation
    prototype to accept range to be invalidated and update all the instances
    for it.
    
    We also change the block_invalidatepage() in the same way and actually
    make a use of the new length argument implementing range invalidation.
    
    Actual file system implementations will follow except the file systems
    where the changes are really simple and should not change the behaviour
    in any way .Implementation for truncate_page_range() which will be able
    to accept page unaligned ranges will follow as well.
    
    Signed-off-by: Lukas Czerner <lczerner@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Hugh Dickins <hughd@google.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 9e52b0626b39..f5a3b838ddb0 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -198,7 +198,8 @@ extern int buffer_heads_over_limit;
  * Generic address_space_operations implementations for buffer_head-backed
  * address_spaces.
  */
-void block_invalidatepage(struct page *page, unsigned long offset);
+void block_invalidatepage(struct page *page, unsigned int offset,
+			  unsigned int length);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
 int block_write_full_page_endio(struct page *page, get_block_t *get_block,

commit 149b306089b88e186942a8d6647028ae6683aaf9
Merge: b0ca4d012360 0d606e2c9fcc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 1 08:04:12 2013 -0700

    Merge tag 'ext4_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4
    
    Pull ext4 updates from Ted Ts'o:
     "Mostly performance and bug fixes, plus some cleanups.  The one new
      feature this merge window is a new ioctl EXT4_IOC_SWAP_BOOT which
      allows installation of a hidden inode designed for boot loaders."
    
    * tag 'ext4_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4: (50 commits)
      ext4: fix type-widening bug in inode table readahead code
      ext4: add check for inodes_count overflow in new resize ioctl
      ext4: fix Kconfig documentation for CONFIG_EXT4_DEBUG
      ext4: fix online resizing for ext3-compat file systems
      jbd2: trace when lock_buffer in do_get_write_access takes a long time
      ext4: mark metadata blocks using bh flags
      buffer: add BH_Prio and BH_Meta flags
      ext4: mark all metadata I/O with REQ_META
      ext4: fix readdir error in case inline_data+^dir_index.
      ext4: fix readdir error in the case of inline_data+dir_index
      jbd2: use kmem_cache_zalloc instead of kmem_cache_alloc/memset
      ext4: mext_insert_extents should update extent block checksum
      ext4: move quota initialization out of inode allocation transaction
      ext4: reserve xattr index for Rich ACL support
      jbd2: reduce journal_head size
      ext4: clear buffer_uninit flag when submitting IO
      ext4: use io_end for multiple bios
      ext4: make ext4_bio_write_page() use BH_Async_Write flags
      ext4: Use kstrtoul() instead of parse_strtoul()
      ext4: defragmentation code cleanup
      ...

commit 7136851117744f1d291bed6d307432699d405109
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Mon Apr 29 15:07:25 2013 -0700

    mm: make snapshotting pages for stable writes a per-bio operation
    
    Walking a bio's page mappings has proved problematic, so create a new
    bio flag to indicate that a bio's data needs to be snapshotted in order
    to guarantee stable pages during writeback.  Next, for the one user
    (ext3/jbd) of snapshotting, hook all the places where writes can be
    initiated without PG_writeback set, and set BIO_SNAP_STABLE there.
    
    We must also flag journal "metadata" bios for stable writeout, since
    file data can be written through the journal.  Finally, the
    MS_SNAP_STABLE mount flag (only used by ext3) is now superfluous, so get
    rid of it.
    
    [akpm@linux-foundation.org: rename _submit_bh()'s `flags' to `bio_flags', delobotomize the _submit_bh declaration]
    [akpm@linux-foundation.org: teeny cleanup]
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Artem Bityutskiy <dedekind1@gmail.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 5afc4f94d110..4c16c4a88d47 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -181,6 +181,7 @@ void ll_rw_block(int, int, struct buffer_head * bh[]);
 int sync_dirty_buffer(struct buffer_head *bh);
 int __sync_dirty_buffer(struct buffer_head *bh, int rw);
 void write_dirty_buffer(struct buffer_head *bh, int rw);
+int _submit_bh(int rw, struct buffer_head *bh, unsigned long bio_flags);
 int submit_bh(int, struct buffer_head *);
 void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);

commit 877f962c5edacfef60ab21cfed6d8d54ce25b8a6
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Apr 20 19:58:37 2013 -0400

    buffer: add BH_Prio and BH_Meta flags
    
    Add buffer_head flags so that buffer cache writebacks can be marked
    with the the appropriate request flags, so that metadata blocks can be
    marked appropriately in blktrace.
    
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 5afc4f94d110..33c0f8103fe4 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -34,6 +34,8 @@ enum bh_state_bits {
 	BH_Write_EIO,	/* I/O error on write */
 	BH_Unwritten,	/* Buffer is allocated on disk but not written */
 	BH_Quiet,	/* Buffer Error Prinks to be quiet */
+	BH_Meta,	/* Buffer contains metadata */
+	BH_Prio,	/* Buffer should be submitted with REQ_PRIO */
 
 	BH_PrivateStart,/* not a state bit, but the first bit available
 			 * for private allocation by other entities
@@ -124,6 +126,8 @@ BUFFER_FNS(Delay, delay)
 BUFFER_FNS(Boundary, boundary)
 BUFFER_FNS(Write_EIO, write_io_error)
 BUFFER_FNS(Unwritten, unwritten)
+BUFFER_FNS(Meta, meta)
+BUFFER_FNS(Prio, prio)
 
 #define bh_offset(bh)		((unsigned long)(bh)->b_data & ~PAGE_MASK)
 

commit f0059afd3e6e7aa1a0ffc23468b74c43d47660b8
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jan 11 13:06:35 2013 -0800

    buffer: make touch_buffer() an exported function
    
    We want to add a trace point to touch_buffer() but macros and inline
    functions defined in header files can't have tracing points.  Move
    touch_buffer() to fs/buffer.c and make it a proper function.
    
    The new exported function is also declared inline.  As most uses of
    touch_buffer() are inside buffer.c with nilfs2 as the only other user,
    the effect of this change should be negligible.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 458f497738a4..5afc4f94d110 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -126,7 +126,6 @@ BUFFER_FNS(Write_EIO, write_io_error)
 BUFFER_FNS(Unwritten, unwritten)
 
 #define bh_offset(bh)		((unsigned long)(bh)->b_data & ~PAGE_MASK)
-#define touch_buffer(bh)	mark_page_accessed(bh->b_page)
 
 /* If we *know* page->private refers to buffer_heads */
 #define page_buffers(page)					\
@@ -142,6 +141,7 @@ BUFFER_FNS(Unwritten, unwritten)
 
 void mark_buffer_dirty(struct buffer_head *bh);
 void init_buffer(struct buffer_head *, bh_end_io_t *, void *);
+void touch_buffer(struct buffer_head *bh);
 void set_bh_page(struct buffer_head *bh,
 		struct page *page, unsigned long offset);
 int try_to_free_buffers(struct page *);

commit 60063497a95e716c9a689af3be2687d261f115b4
Author: Arun Sharma <asharma@fb.com>
Date:   Tue Jul 26 16:09:06 2011 -0700

    atomic: use <linux/atomic.h>
    
    This allows us to move duplicated code in <asm/atomic.h>
    (atomic_inc_not_zero() for now) to <linux/atomic.h>
    
    Signed-off-by: Arun Sharma <asharma@fb.com>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 503c8a6b3079..458f497738a4 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -12,7 +12,7 @@
 #include <linux/linkage.h>
 #include <linux/pagemap.h>
 #include <linux/wait.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 
 #ifdef CONFIG_BLOCK
 

commit ea13a86463fd0c26c2c209c53dc46b8eff81bad4
Author: Jan Kara <jack@suse.cz>
Date:   Tue May 24 00:23:35 2011 +0200

    vfs: Block mmapped writes while the fs is frozen
    
    We should not allow file modification via mmap while the filesystem is
    frozen. So block in block_page_mkwrite() while the filesystem is frozen.
    We cannot do the blocking wait in __block_page_mkwrite() since e.g. ext4
    will want to call that function with transaction started in some cases
    and that would deadlock. But we can at least do the non-blocking reliable
    check in __block_page_mkwrite() which is the hardest part anyway.
    
    We have to check for frozen filesystem with the page marked dirty and under
    page lock with which we then return from ->page_mkwrite(). Only that way we
    cannot race with writeback done by freezing code - either we mark the page
    dirty after the writeback has started, see freezing in progress and block, or
    writeback will wait for our page lock which is released only when the fault is
    done and then writeback will writeout and writeprotect the page again.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 2bf6a9136a94..503c8a6b3079 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -230,6 +230,8 @@ static inline int block_page_mkwrite_return(int err)
 		return VM_FAULT_NOPAGE;
 	if (err == -ENOMEM)
 		return VM_FAULT_OOM;
+	if (err == -EAGAIN)
+		return VM_FAULT_RETRY;
 	/* -ENOSPC, -EDQUOT, -EIO ... */
 	return VM_FAULT_SIGBUS;
 }

commit 24da4fab5a617ecbf0f0c64e7ba7703383faa411
Author: Jan Kara <jack@suse.cz>
Date:   Tue May 24 00:23:34 2011 +0200

    vfs: Create __block_page_mkwrite() helper passing error values back
    
    Create __block_page_mkwrite() helper which does all what block_page_mkwrite()
    does except that it passes back errors from __block_write_begin /
    block_commit_write calls.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index f5df23561b96..2bf6a9136a94 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -217,8 +217,22 @@ int cont_write_begin(struct file *, struct address_space *, loff_t,
 			get_block_t *, loff_t *);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
+int __block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
+				get_block_t get_block);
 int block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
 				get_block_t get_block);
+/* Convert errno to return value from ->page_mkwrite() call */
+static inline int block_page_mkwrite_return(int err)
+{
+	if (err == 0)
+		return VM_FAULT_LOCKED;
+	if (err == -EFAULT)
+		return VM_FAULT_NOPAGE;
+	if (err == -ENOMEM)
+		return VM_FAULT_OOM;
+	/* -ENOSPC, -EDQUOT, -EIO ... */
+	return VM_FAULT_SIGBUS;
+}
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
 int nobh_write_begin(struct address_space *, loff_t, unsigned, unsigned,

commit 7eaceaccab5f40bbfda044629a6298616aeaed50
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Thu Mar 10 08:52:07 2011 +0100

    block: remove per-queue plugging
    
    Code has been converted over to the new explicit on-stack plugging,
    and delay users have been converted to use the new API for that.
    So lets kill off the old plugging along with aops->sync_page().
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 68d1fe7b877c..f5df23561b96 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -219,7 +219,6 @@ int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
 int block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
 				get_block_t get_block);
-void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
 int nobh_write_begin(struct address_space *, loff_t, unsigned, unsigned,

commit ebdec241d509cf69f6ebf1ecdc036359d3dbe154
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Oct 6 10:47:23 2010 +0200

    fs: kill block_prepare_write
    
    __block_write_begin and block_prepare_write are identical except for slightly
    different calling conventions.  Convert all callers to the __block_write_begin
    calling conventions and drop block_prepare_write.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index dd1b25b2641c..68d1fe7b877c 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -212,7 +212,6 @@ int generic_write_end(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page *, void *);
 void page_zero_new_buffers(struct page *page, unsigned from, unsigned to);
-int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
 int cont_write_begin(struct file *, struct address_space *, loff_t,
 			unsigned, unsigned, struct page **, void **,
 			get_block_t *, loff_t *);

commit 0edd55faea7c8081bc826234b917501738a6218f
Author: Christoph Hellwig <hch@infradead.org>
Date:   Wed Aug 18 05:29:23 2010 -0400

    block: remove the BH_Eopnotsupp flag
    
    This flag was only set for barrier buffers, which we don't submit
    anymore.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index fc999f583fda..dd1b25b2641c 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -32,7 +32,6 @@ enum bh_state_bits {
 	BH_Delay,	/* Buffer is not yet allocated on disk */
 	BH_Boundary,	/* Block is followed by a discontiguity */
 	BH_Write_EIO,	/* I/O error on write */
-	BH_Eopnotsupp,	/* DEPRECATED: operation not supported (barrier) */
 	BH_Unwritten,	/* Buffer is allocated on disk but not written */
 	BH_Quiet,	/* Buffer Error Prinks to be quiet */
 
@@ -124,7 +123,6 @@ BUFFER_FNS(Async_Write, async_write)
 BUFFER_FNS(Delay, delay)
 BUFFER_FNS(Boundary, boundary)
 BUFFER_FNS(Write_EIO, write_io_error)
-BUFFER_FNS(Eopnotsupp, eopnotsupp)
 BUFFER_FNS(Unwritten, unwritten)
 
 #define bh_offset(bh)		((unsigned long)(bh)->b_data & ~PAGE_MASK)

commit 4fed947cb311e5aa51781d316cefca836352f6ce
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Sep 3 11:56:17 2010 +0200

    block: implement REQ_FLUSH/FUA based interface for FLUSH/FUA requests
    
    Now that the backend conversion is complete, export sequenced
    FLUSH/FUA capability through REQ_FLUSH/FUA flags.  REQ_FLUSH means the
    device cache should be flushed before executing the request.  REQ_FUA
    means that the data in the request should be on non-volatile media on
    completion.
    
    Block layer will choose the correct way of implementing the semantics
    and execute it.  The request may be passed to the device directly if
    the device can handle it; otherwise, it will be sequenced using one or
    more proxy requests.  Devices will never see REQ_FLUSH and/or FUA
    which it doesn't support.
    
    Also, unlike the original REQ_HARDBARRIER, REQ_FLUSH/FUA requests are
    never failed with -EOPNOTSUPP.  If the underlying device doesn't
    support FLUSH/FUA, the block layer simply make those noop.  IOW, it no
    longer distinguishes between writeback cache which doesn't support
    cache flush and writethrough/no cache.  Devices which have WB cache
    w/o flush are very difficult to come by these days and there's nothing
    much we can do anyway, so it doesn't make sense to require everyone to
    implement -EOPNOTSUPP handling.  This will simplify filesystems and
    block drivers as they can drop -EOPNOTSUPP retry logic for barriers.
    
    * QUEUE_ORDERED_* are removed and QUEUE_FSEQ_* are moved into
      blk-flush.c.
    
    * REQ_FLUSH w/o data can also be directly passed to drivers without
      sequencing but some drivers assume that zero length requests don't
      have rq->bio which isn't true for these requests requiring the use
      of proxy requests.
    
    * REQ_COMMON_MASK now includes REQ_FLUSH | REQ_FUA so that they are
      copied from bio to request.
    
    * WRITE_BARRIER is marked deprecated and WRITE_FLUSH, WRITE_FUA and
      WRITE_FLUSH_FUA are added.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index ec94c12f21da..fc999f583fda 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -32,7 +32,7 @@ enum bh_state_bits {
 	BH_Delay,	/* Buffer is not yet allocated on disk */
 	BH_Boundary,	/* Block is followed by a discontiguity */
 	BH_Write_EIO,	/* I/O error on write */
-	BH_Eopnotsupp,	/* operation not supported (barrier) */
+	BH_Eopnotsupp,	/* DEPRECATED: operation not supported (barrier) */
 	BH_Unwritten,	/* Buffer is allocated on disk but not written */
 	BH_Quiet,	/* Buffer Error Prinks to be quiet */
 

commit 9cb569d601e0b93e01c20a22872270ec663b75f6
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 11 17:06:24 2010 +0200

    remove SWRITE* I/O types
    
    These flags aren't real I/O types, but tell ll_rw_block to always
    lock the buffer instead of giving up on a failed trylock.
    
    Instead add a new write_dirty_buffer helper that implements this semantic
    and use it from the existing SWRITE* callers.  Note that the ll_rw_block
    code had a bug where it didn't promote WRITE_SYNC_PLUG properly, which
    this patch fixes.
    
    In the ufs code clean up the helper that used to call ll_rw_block
    to mirror sync_dirty_buffer, which is the function it implements for
    compound buffers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 72c1cf83eb85..ec94c12f21da 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -182,6 +182,7 @@ void __lock_buffer(struct buffer_head *bh);
 void ll_rw_block(int, int, struct buffer_head * bh[]);
 int sync_dirty_buffer(struct buffer_head *bh);
 int __sync_dirty_buffer(struct buffer_head *bh, int rw);
+void write_dirty_buffer(struct buffer_head *bh, int rw);
 int submit_bh(int, struct buffer_head *);
 void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);

commit 87e99511ea54510ffb60b98001d108794d5037f8
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 11 17:05:45 2010 +0200

    kill BH_Ordered flag
    
    Instead of abusing a buffer_head flag just add a variant of
    sync_dirty_buffer which allows passing the exact type of write
    flag required.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 43e649a72529..72c1cf83eb85 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -32,7 +32,6 @@ enum bh_state_bits {
 	BH_Delay,	/* Buffer is not yet allocated on disk */
 	BH_Boundary,	/* Block is followed by a discontiguity */
 	BH_Write_EIO,	/* I/O error on write */
-	BH_Ordered,	/* ordered write */
 	BH_Eopnotsupp,	/* operation not supported (barrier) */
 	BH_Unwritten,	/* Buffer is allocated on disk but not written */
 	BH_Quiet,	/* Buffer Error Prinks to be quiet */
@@ -125,7 +124,6 @@ BUFFER_FNS(Async_Write, async_write)
 BUFFER_FNS(Delay, delay)
 BUFFER_FNS(Boundary, boundary)
 BUFFER_FNS(Write_EIO, write_io_error)
-BUFFER_FNS(Ordered, ordered)
 BUFFER_FNS(Eopnotsupp, eopnotsupp)
 BUFFER_FNS(Unwritten, unwritten)
 
@@ -183,6 +181,7 @@ void unlock_buffer(struct buffer_head *bh);
 void __lock_buffer(struct buffer_head *bh);
 void ll_rw_block(int, int, struct buffer_head * bh[]);
 int sync_dirty_buffer(struct buffer_head *bh);
+int __sync_dirty_buffer(struct buffer_head *bh, int rw);
 int submit_bh(int, struct buffer_head *);
 void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);

commit 5f248c9c251c60af3403902b26e08de43964ea0b
Merge: f6cec0ae58c1 dca332528bc6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 10 11:26:52 2010 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6: (96 commits)
      no need for list_for_each_entry_safe()/resetting with superblock list
      Fix sget() race with failing mount
      vfs: don't hold s_umount over close_bdev_exclusive() call
      sysv: do not mark superblock dirty on remount
      sysv: do not mark superblock dirty on mount
      btrfs: remove junk sb_dirt change
      BFS: clean up the superblock usage
      AFFS: wait for sb synchronization when needed
      AFFS: clean up dirty flag usage
      cifs: truncate fallout
      mbcache: fix shrinker function return value
      mbcache: Remove unused features
      add f_flags to struct statfs(64)
      pass a struct path to vfs_statfs
      update VFS documentation for method changes.
      All filesystems that need invalidate_inode_buffers() are doing that explicitly
      convert remaining ->clear_inode() to ->evict_inode()
      Make ->drop_inode() just return whether inode needs to be dropped
      fs/inode.c:clear_inode() is gone
      fs/inode.c:evict() doesn't care about delete vs. non-delete paths now
      ...
    
    Fix up trivial conflicts in fs/nilfs2/super.c

commit a9877cc2937889e5669114f28612b494384152a4
Author: Richard Kennedy <richard@rsk.demon.co.uk>
Date:   Mon Aug 9 17:18:42 2010 -0700

    buffer_head: remove redundant test from wait_on_buffer
    
    The comment suggests that when b_count equals zero it is calling
    __wait_no_buffer to trigger some debug, but as there is no debug in
    __wait_on_buffer the whole thing is redundant.
    
    AFAICT from the git log this has been the case for at least 5 years, so
    it seems safe just to remove this.
    
    Signed-off-by: Richard Kennedy <richard@rsk.demon.co.uk>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 1b9ba193b789..2ce51fac7d3d 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -314,15 +314,10 @@ map_bh(struct buffer_head *bh, struct super_block *sb, sector_t block)
 	bh->b_size = sb->s_blocksize;
 }
 
-/*
- * Calling wait_on_buffer() for a zero-ref buffer is illegal, so we call into
- * __wait_on_buffer() just to trip a debug check.  Because debug code in inline
- * functions is bloaty.
- */
 static inline void wait_on_buffer(struct buffer_head *bh)
 {
 	might_sleep();
-	if (buffer_locked(bh) || atomic_read(&bh->b_count) == 0)
+	if (buffer_locked(bh))
 		__wait_on_buffer(bh);
 }
 

commit b5fc510c48f631882ccec3c0f02a25d5b67de09f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jul 4 12:24:09 2010 +0400

    get rid of file_fsync()
    
    Copy and simplify in the only two users remaining.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 3f69054f86d9..620f1d1088cb 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -225,7 +225,6 @@ int block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
 void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
-int file_fsync(struct file *, int);
 int nobh_write_begin(struct address_space *, loff_t, unsigned, unsigned,
 				struct page **, void **, get_block_t*);
 int nobh_write_end(struct file *, struct address_space *,

commit 155130a4f7848b1aac439cab6bda1a175507c71c
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 4 11:29:58 2010 +0200

    get rid of block_write_begin_newtrunc
    
    Move the call to vmtruncate to get rid of accessive blocks to the callers
    in preparation of the new truncate sequence and rename the non-truncating
    version to block_write_begin.
    
    While we're at it also remove several unused arguments to block_write_begin.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index accc9f81bb63..3f69054f86d9 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -203,12 +203,8 @@ int block_write_full_page_endio(struct page *page, get_block_t *get_block,
 int block_read_full_page(struct page*, get_block_t*);
 int block_is_partially_uptodate(struct page *page, read_descriptor_t *desc,
 				unsigned long from);
-int block_write_begin_newtrunc(struct file *, struct address_space *,
-				loff_t, unsigned, unsigned,
-				struct page **, void **, get_block_t*);
-int block_write_begin(struct file *, struct address_space *,
-				loff_t, unsigned, unsigned,
-				struct page **, void **, get_block_t*);
+int block_write_begin(struct address_space *mapping, loff_t pos, unsigned len,
+		unsigned flags, struct page **pagep, get_block_t *get_block);
 int __block_write_begin(struct page *page, loff_t pos, unsigned len,
 		get_block_t *get_block);
 int block_write_end(struct file *, struct address_space *,

commit 6e1db88d536adcbbfe562b2d4b7d6425784fff12
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 4 11:29:57 2010 +0200

    introduce __block_write_begin
    
    Split up the block_write_begin implementation - __block_write_begin is a new
    trivial wrapper for block_prepare_write that always takes an already
    allocated page and can be either called from block_write_begin or filesystem
    code that already has a page allocated.  Remove the handling of already
    allocated pages from block_write_begin after switching all callers that
    do it to __block_write_begin.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 7638647f0424..accc9f81bb63 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -209,6 +209,8 @@ int block_write_begin_newtrunc(struct file *, struct address_space *,
 int block_write_begin(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page **, void **, get_block_t*);
+int __block_write_begin(struct page *page, loff_t pos, unsigned len,
+		get_block_t *get_block);
 int block_write_end(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page *, void *);

commit 282dc178849882289d30e58b54be6b2799b351aa
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 4 11:29:55 2010 +0200

    get rid of cont_write_begin_newtrunc
    
    Move the call to vmtruncate to get rid of accessive blocks to the callers
    in preparation of the new truncate sequence and rename the non-truncating
    version to cont_write_begin.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index cfda5f0b2a4b..7638647f0424 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -217,9 +217,6 @@ int generic_write_end(struct file *, struct address_space *,
 				struct page *, void *);
 void page_zero_new_buffers(struct page *page, unsigned from, unsigned to);
 int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
-int cont_write_begin_newtrunc(struct file *, struct address_space *, loff_t,
-			unsigned, unsigned, struct page **, void **,
-			get_block_t *, loff_t *);
 int cont_write_begin(struct file *, struct address_space *, loff_t,
 			unsigned, unsigned, struct page **, void **,
 			get_block_t *, loff_t *);

commit ea0f04e59543bafb3d2cbe37a0d375acb0bb2c34
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 4 11:29:54 2010 +0200

    get rid of nobh_write_begin_newtrunc
    
    Move the call to vmtruncate to get rid of accessive blocks to the only
    remaining caller and rename the non-truncating version to nobh_write_begin.
    
    Get rid of the superflous file argument to it while we're at it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 1b9ba193b789..cfda5f0b2a4b 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -231,11 +231,7 @@ void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
 int file_fsync(struct file *, int);
-int nobh_write_begin_newtrunc(struct file *, struct address_space *,
-				loff_t, unsigned, unsigned,
-				struct page **, void **, get_block_t*);
-int nobh_write_begin(struct file *, struct address_space *,
-				loff_t, unsigned, unsigned,
+int nobh_write_begin(struct address_space *, loff_t, unsigned, unsigned,
 				struct page **, void **, get_block_t*);
 int nobh_write_end(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,

commit 7bb46a6734a7e1ad4beaecc11cae7ed3ff81d30f
Author: npiggin@suse.de <npiggin@suse.de>
Date:   Thu May 27 01:05:33 2010 +1000

    fs: introduce new truncate sequence
    
    Introduce a new truncate calling sequence into fs/mm subsystems. Rather than
    setattr > vmtruncate > truncate, have filesystems call their truncate sequence
    from ->setattr if filesystem specific operations are required. vmtruncate is
    deprecated, and truncate_pagecache and inode_newsize_ok helpers introduced
    previously should be used.
    
    simple_setattr is introduced for simple in-ram filesystems to implement
    the new truncate sequence. Eventually all filesystems should be converted
    to implement a setattr, and the default code in notify_change should go
    away.
    
    simple_setsize is also introduced to perform just the ATTR_SIZE portion
    of simple_setattr (ie. changing i_size and trimming pagecache).
    
    To implement the new truncate sequence:
    - filesystem specific manipulations (eg freeing blocks) must be done in
      the setattr method rather than ->truncate.
    - vmtruncate can not be used by core code to trim blocks past i_size in
      the event of write failure after allocation, so this must be performed
      in the fs code.
    - convert usage of helpers block_write_begin, nobh_write_begin,
      cont_write_begin, and *blockdev_direct_IO* to use _newtrunc postfixed
      variants. These avoid calling vmtruncate to trim blocks (see previous).
    - inode_setattr should not be used. generic_setattr is a new function
      to be used to copy simple attributes into the generic inode.
    - make use of the better opportunity to handle errors with the new sequence.
    
    Big problem with the previous calling sequence: the filesystem is not called
    until i_size has already changed.  This means it is not allowed to fail the
    call, and also it does not know what the previous i_size was. Also, generic
    code calling vmtruncate to truncate allocated blocks in case of error had
    no good way to return a meaningful error (or, for example, atomically handle
    block deallocation).
    
    Cc: Christoph Hellwig <hch@lst.de>
    Acked-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 05e5f5996216..1b9ba193b789 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -203,6 +203,9 @@ int block_write_full_page_endio(struct page *page, get_block_t *get_block,
 int block_read_full_page(struct page*, get_block_t*);
 int block_is_partially_uptodate(struct page *page, read_descriptor_t *desc,
 				unsigned long from);
+int block_write_begin_newtrunc(struct file *, struct address_space *,
+				loff_t, unsigned, unsigned,
+				struct page **, void **, get_block_t*);
 int block_write_begin(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page **, void **, get_block_t*);
@@ -214,6 +217,9 @@ int generic_write_end(struct file *, struct address_space *,
 				struct page *, void *);
 void page_zero_new_buffers(struct page *page, unsigned from, unsigned to);
 int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
+int cont_write_begin_newtrunc(struct file *, struct address_space *, loff_t,
+			unsigned, unsigned, struct page **, void **,
+			get_block_t *, loff_t *);
 int cont_write_begin(struct file *, struct address_space *, loff_t,
 			unsigned, unsigned, struct page **, void **,
 			get_block_t *, loff_t *);
@@ -225,6 +231,9 @@ void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
 int file_fsync(struct file *, int);
+int nobh_write_begin_newtrunc(struct file *, struct address_space *,
+				loff_t, unsigned, unsigned,
+				struct page **, void **, get_block_t*);
 int nobh_write_begin(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page **, void **, get_block_t*);

commit 7ea8085910ef3dd4f3cad6845aaa2b580d39b115
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 26 17:53:25 2010 +0200

    drop unused dentry argument to ->fsync
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 16ed0284d780..05e5f5996216 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -224,7 +224,7 @@ int block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
 void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
-int file_fsync(struct file *, struct dentry *, int);
+int file_fsync(struct file *, int);
 int nobh_write_begin(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page **, void **, get_block_t*);

commit 35c80d5f400f68f2eccf3069d1c068e154bde9c9
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 15 13:22:38 2009 -0400

    Add block_write_full_page_endio for passing endio handler
    
    block_write_full_page doesn't allow the caller to control what happens
    when the IO is over.  This adds a new call named block_write_full_page_endio
    so the buffer head end_io handler can be provided by the caller.
    
    This will be used by the ext3 data=guarded mode to do i_size updates in
    a workqueue based end_io handler.  end_buffer_async_write is also
    exported so it can be called to do the dirty work of managing page
    writeback for the higher level end_io handler.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>
    Acked-by: Theodore Tso <tytso@mit.edu>
    Acked-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 7b73bb8f1970..16ed0284d780 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -155,6 +155,7 @@ void create_empty_buffers(struct page *, unsigned long,
 			unsigned long b_state);
 void end_buffer_read_sync(struct buffer_head *bh, int uptodate);
 void end_buffer_write_sync(struct buffer_head *bh, int uptodate);
+void end_buffer_async_write(struct buffer_head *bh, int uptodate);
 
 /* Things to do with buffers at mapping->private_list */
 void mark_buffer_dirty_inode(struct buffer_head *bh, struct inode *inode);
@@ -197,6 +198,8 @@ extern int buffer_heads_over_limit;
 void block_invalidatepage(struct page *page, unsigned long offset);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
+int block_write_full_page_endio(struct page *page, get_block_t *get_block,
+			struct writeback_control *wbc, bh_end_io_t *handler);
 int block_read_full_page(struct page*, get_block_t*);
 int block_is_partially_uptodate(struct page *page, read_descriptor_t *desc,
 				unsigned long from);

commit 8fe74cf053de7ad2124a894996f84fa890a81093
Merge: c2eb2fa6d2b6 ced117c73edc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 2 21:09:10 2009 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6:
      Remove two unneeded exports and make two symbols static in fs/mpage.c
      Cleanup after commit 585d3bc06f4ca57f975a5a1f698f65a45ea66225
      Trim includes of fdtable.h
      Don't crap into descriptor table in binfmt_som
      Trim includes in binfmt_elf
      Don't mess with descriptor table in load_elf_binary()
      Get rid of indirect include of fs_struct.h
      New helper - current_umask()
      check_unsafe_exec() doesn't care about signal handlers sharing
      New locking/refcounting for fs_struct
      Take fs_struct handling to new file (fs/fs_struct.c)
      Get rid of bumping fs_struct refcount in pivot_root(2)
      Kill unsharing fs_struct in __set_personality()

commit c2ec175c39f62949438354f603f4aa170846aabb
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Mar 31 15:23:21 2009 -0700

    mm: page_mkwrite change prototype to match fault
    
    Change the page_mkwrite prototype to take a struct vm_fault, and return
    VM_FAULT_xxx flags.  There should be no functional change.
    
    This makes it possible to return much more detailed error information to
    the VM (and also can provide more information eg.  virtual_address to the
    driver, which might be important in some special cases).
    
    This is required for a subsequent fix.  And will also make it easier to
    merge page_mkwrite() with fault() in future.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <joel.becker@oracle.com>
    Cc: Artem Bityutskiy <dedekind@infradead.org>
    Cc: Felix Blyakher <felixb@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index f19fd9045ea0..3d7bcde2e332 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -216,7 +216,7 @@ int cont_write_begin(struct file *, struct address_space *, loff_t,
 			get_block_t *, loff_t *);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
-int block_page_mkwrite(struct vm_area_struct *vma, struct page *page,
+int block_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf,
 				get_block_t get_block);
 void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);

commit 47e4491b40df73c3b117e3d80b31b5b512a4b19f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 1 07:07:16 2009 -0400

    Cleanup after commit 585d3bc06f4ca57f975a5a1f698f65a45ea66225
    
    fsync_bdev() export and a bunch of stubs for !CONFIG_BLOCK case had
    been left behind
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index f19fd9045ea0..fc91665d39d0 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -332,22 +332,10 @@ extern int __set_page_dirty_buffers(struct page *page);
 
 static inline void buffer_init(void) {}
 static inline int try_to_free_buffers(struct page *page) { return 1; }
-static inline int sync_blockdev(struct block_device *bdev) { return 0; }
 static inline int inode_has_buffers(struct inode *inode) { return 0; }
 static inline void invalidate_inode_buffers(struct inode *inode) {}
 static inline int remove_inode_buffers(struct inode *inode) { return 1; }
 static inline int sync_mapping_buffers(struct address_space *mapping) { return 0; }
-static inline void invalidate_bdev(struct block_device *bdev) {}
-
-static inline struct super_block *freeze_bdev(struct block_device *sb)
-{
-	return NULL;
-}
-
-static inline int thaw_bdev(struct block_device *bdev, struct super_block *sb)
-{
-	return 0;
-}
 
 #endif /* CONFIG_BLOCK */
 #endif /* _LINUX_BUFFER_HEAD_H */

commit 585d3bc06f4ca57f975a5a1f698f65a45ea66225
Author: Nick Piggin <npiggin@suse.de>
Date:   Wed Feb 25 10:44:19 2009 +0100

    fs: move bdev code out of buffer.c
    
    Move some block device related code out from buffer.c and put it in
    block_dev.c. I'm trying to move non-buffer_head code out of buffer.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index bd7ac793be19..f19fd9045ea0 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -165,15 +165,8 @@ int sync_mapping_buffers(struct address_space *mapping);
 void unmap_underlying_metadata(struct block_device *bdev, sector_t block);
 
 void mark_buffer_async_write(struct buffer_head *bh);
-void invalidate_bdev(struct block_device *);
-int sync_blockdev(struct block_device *bdev);
 void __wait_on_buffer(struct buffer_head *);
 wait_queue_head_t *bh_waitq_head(struct buffer_head *bh);
-int fsync_bdev(struct block_device *);
-struct super_block *freeze_bdev(struct block_device *);
-int thaw_bdev(struct block_device *, struct super_block *);
-int fsync_super(struct super_block *);
-int fsync_no_super(struct block_device *);
 struct buffer_head *__find_get_block(struct block_device *bdev, sector_t block,
 			unsigned size);
 struct buffer_head *__getblk(struct block_device *bdev, sector_t block,

commit fcccf502540e3d752d33b2d8e976034dee81f9f7
Author: Takashi Sato <t-sato@yk.jp.nec.com>
Date:   Fri Jan 9 16:40:59 2009 -0800

    filesystem freeze: implement generic freeze feature
    
    The ioctls for the generic freeze feature are below.
    o Freeze the filesystem
      int ioctl(int fd, int FIFREEZE, arg)
        fd: The file descriptor of the mountpoint
        FIFREEZE: request code for the freeze
        arg: Ignored
        Return value: 0 if the operation succeeds. Otherwise, -1
    
    o Unfreeze the filesystem
      int ioctl(int fd, int FITHAW, arg)
        fd: The file descriptor of the mountpoint
        FITHAW: request code for unfreeze
        arg: Ignored
        Return value: 0 if the operation succeeds. Otherwise, -1
        Error number: If the filesystem has already been unfrozen,
                      errno is set to EINVAL.
    
    [akpm@linux-foundation.org: fix CONFIG_BLOCK=n]
    Signed-off-by: Takashi Sato <t-sato@yk.jp.nec.com>
    Signed-off-by: Masayuki Hamaguchi <m-hamaguchi@ys.jp.nec.com>
    Cc: <xfs-masters@oss.sgi.com>
    Cc: <linux-ext4@vger.kernel.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dave Kleikamp <shaggy@austin.ibm.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Alasdair G Kergon <agk@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 8605f8a74df9..bd7ac793be19 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -171,7 +171,7 @@ void __wait_on_buffer(struct buffer_head *);
 wait_queue_head_t *bh_waitq_head(struct buffer_head *bh);
 int fsync_bdev(struct block_device *);
 struct super_block *freeze_bdev(struct block_device *);
-void thaw_bdev(struct block_device *, struct super_block *);
+int thaw_bdev(struct block_device *, struct super_block *);
 int fsync_super(struct super_block *);
 int fsync_no_super(struct block_device *);
 struct buffer_head *__find_get_block(struct block_device *bdev, sector_t block,
@@ -346,6 +346,15 @@ static inline int remove_inode_buffers(struct inode *inode) { return 1; }
 static inline int sync_mapping_buffers(struct address_space *mapping) { return 0; }
 static inline void invalidate_bdev(struct block_device *bdev) {}
 
+static inline struct super_block *freeze_bdev(struct block_device *sb)
+{
+	return NULL;
+}
+
+static inline int thaw_bdev(struct block_device *bdev, struct super_block *sb)
+{
+	return 0;
+}
 
 #endif /* CONFIG_BLOCK */
 #endif /* _LINUX_BUFFER_HEAD_H */

commit 08bafc0341f2f7920e9045bc32c40299cac8c21b
Author: Keith Mannthey <kmannth@us.ibm.com>
Date:   Tue Nov 25 10:24:35 2008 +0100

    block: Supress Buffer I/O errors when SCSI REQ_QUIET flag set
    
    Allow the scsi request REQ_QUIET flag to be propagated to the buffer
    file system layer. The basic ideas is to pass the flag from the scsi
    request to the bio (block IO) and then to the buffer layer.  The buffer
    layer can then suppress needless printks.
    
    This patch declutters the kernel log by removed the 40-50 (per lun)
    buffer io error messages seen during a boot in my multipath setup . It
    is a good chance any real errors will be missed in the "noise" it the
    logs without this patch.
    
    During boot I see blocks of messages like
    "
    __ratelimit: 211 callbacks suppressed
    Buffer I/O error on device sdm, logical block 5242879
    Buffer I/O error on device sdm, logical block 5242879
    Buffer I/O error on device sdm, logical block 5242847
    Buffer I/O error on device sdm, logical block 1
    Buffer I/O error on device sdm, logical block 5242878
    Buffer I/O error on device sdm, logical block 5242879
    Buffer I/O error on device sdm, logical block 5242879
    Buffer I/O error on device sdm, logical block 5242879
    Buffer I/O error on device sdm, logical block 5242879
    Buffer I/O error on device sdm, logical block 5242872
    "
    in my logs.
    
    My disk environment is multipath fiber channel using the SCSI_DH_RDAC
    code and multipathd.  This topology includes an "active" and "ghost"
    path for each lun. IO's to the "ghost" path will never complete and the
    SCSI layer, via the scsi device handler rdac code, quick returns the IOs
    to theses paths and sets the REQ_QUIET scsi flag to suppress the scsi
    layer messages.
    
     I am wanting to extend the QUIET behavior to include the buffer file
    system layer to deal with these errors as well. I have been running this
    patch for a while now on several boxes without issue.  A few runs of
    bonnie++ show no noticeable difference in performance in my setup.
    
    Thanks for John Stultz for the quiet_error finalization.
    
    Submitted-by:  Keith Mannthey <kmannth@us.ibm.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 3ce64b90118c..8605f8a74df9 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -35,6 +35,7 @@ enum bh_state_bits {
 	BH_Ordered,	/* ordered write */
 	BH_Eopnotsupp,	/* operation not supported (barrier) */
 	BH_Unwritten,	/* Buffer is allocated on disk but not written */
+	BH_Quiet,	/* Buffer Error Prinks to be quiet */
 
 	BH_PrivateStart,/* not a state bit, but the first bit available
 			 * for private allocation by other entities

commit 51b07fc3c5c830bb49c80fc5eac041e1f66a72e7
Author: Nick Piggin <npiggin@suse.de>
Date:   Sat Oct 18 20:27:00 2008 -0700

    fs: buffer lock use lock bitops
    
    trylock_buffer and unlock_buffer open and close a critical section.
    Hence, we can use the lock bitops to get the desired memory ordering.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index eadaab44015f..3ce64b90118c 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -322,7 +322,7 @@ static inline void wait_on_buffer(struct buffer_head *bh)
 
 static inline int trylock_buffer(struct buffer_head *bh)
 {
-	return likely(!test_and_set_bit(BH_Lock, &bh->b_state));
+	return likely(!test_and_set_bit_lock(BH_Lock, &bh->b_state));
 }
 
 static inline void lock_buffer(struct buffer_head *bh)

commit ca5de404ff036a29b25e9a83f6919c9f606c5841
Author: Nick Piggin <npiggin@suse.de>
Date:   Sat Aug 2 12:02:13 2008 +0200

    fs: rename buffer trylock
    
    Like the page lock change, this also requires name change, so convert the
    raw test_and_set bitop to a trylock.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 50cfe8ceb478..eadaab44015f 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -115,7 +115,6 @@ BUFFER_FNS(Uptodate, uptodate)
 BUFFER_FNS(Dirty, dirty)
 TAS_BUFFER_FNS(Dirty, dirty)
 BUFFER_FNS(Lock, locked)
-TAS_BUFFER_FNS(Lock, locked)
 BUFFER_FNS(Req, req)
 TAS_BUFFER_FNS(Req, req)
 BUFFER_FNS(Mapped, mapped)
@@ -321,10 +320,15 @@ static inline void wait_on_buffer(struct buffer_head *bh)
 		__wait_on_buffer(bh);
 }
 
+static inline int trylock_buffer(struct buffer_head *bh)
+{
+	return likely(!test_and_set_bit(BH_Lock, &bh->b_state));
+}
+
 static inline void lock_buffer(struct buffer_head *bh)
 {
 	might_sleep();
-	if (test_set_buffer_locked(bh))
+	if (!trylock_buffer(bh))
 		__lock_buffer(bh);
 }
 

commit 8ab22b9abb5c55413802e4adc9aa6223324547c3
Author: Hisashi Hifumi <hifumi.hisashi@oss.ntt.co.jp>
Date:   Mon Jul 28 15:46:36 2008 -0700

    vfs: pagecache usage optimization for pagesize!=blocksize
    
    When we read some part of a file through pagecache, if there is a
    pagecache of corresponding index but this page is not uptodate, read IO
    is issued and this page will be uptodate.
    
    I think this is good for pagesize == blocksize environment but there is
    room for improvement on pagesize != blocksize environment.  Because in
    this case a page can have multiple buffers and even if a page is not
    uptodate, some buffers can be uptodate.
    
    So I suggest that when all buffers which correspond to a part of a file
    that we want to read are uptodate, use this pagecache and copy data from
    this pagecache to user buffer even if a page is not uptodate.  This can
    reduce read IO and improve system throughput.
    
    I wrote a benchmark program and got result number with this program.
    
    This benchmark do:
    
      1: mount and open a test file.
    
      2: create a 512MB file.
    
      3: close a file and umount.
    
      4: mount and again open a test file.
    
      5: pwrite randomly 300000 times on a test file.  offset is aligned
         by IO size(1024bytes).
    
      6: measure time of preading randomly 100000 times on a test file.
    
    The result was:
            2.6.26
            330 sec
    
            2.6.26-patched
            226 sec
    
    Arch:i386
    Filesystem:ext3
    Blocksize:1024 bytes
    Memory: 1GB
    
    On ext3/4, a file is written through buffer/block.  So random read/write
    mixed workloads or random read after random write workloads are optimized
    with this patch under pagesize != blocksize environment.  This test result
    showed this.
    
    The benchmark program is as follows:
    
    #include <stdio.h>
    #include <sys/types.h>
    #include <sys/stat.h>
    #include <fcntl.h>
    #include <unistd.h>
    #include <time.h>
    #include <stdlib.h>
    #include <string.h>
    #include <sys/mount.h>
    
    #define LEN 1024
    #define LOOP 1024*512 /* 512MB */
    
    main(void)
    {
            unsigned long i, offset, filesize;
            int fd;
            char buf[LEN];
            time_t t1, t2;
    
            if (mount("/dev/sda1", "/root/test1/", "ext3", 0, 0) < 0) {
                    perror("cannot mount\n");
                    exit(1);
            }
            memset(buf, 0, LEN);
            fd = open("/root/test1/testfile", O_CREAT|O_RDWR|O_TRUNC);
            if (fd < 0) {
                    perror("cannot open file\n");
                    exit(1);
            }
            for (i = 0; i < LOOP; i++)
                    write(fd, buf, LEN);
            close(fd);
            if (umount("/root/test1/") < 0) {
                    perror("cannot umount\n");
                    exit(1);
            }
            if (mount("/dev/sda1", "/root/test1/", "ext3", 0, 0) < 0) {
                    perror("cannot mount\n");
                    exit(1);
            }
            fd = open("/root/test1/testfile", O_RDWR);
            if (fd < 0) {
                    perror("cannot open file\n");
                    exit(1);
            }
    
            filesize = LEN * LOOP;
            for (i = 0; i < 300000; i++){
                    offset = (random() % filesize) & (~(LEN - 1));
                    pwrite(fd, buf, LEN, offset);
            }
            printf("start test\n");
            time(&t1);
            for (i = 0; i < 100000; i++){
                    offset = (random() % filesize) & (~(LEN - 1));
                    pread(fd, buf, LEN, offset);
            }
            time(&t2);
            printf("%ld sec\n", t2-t1);
            close(fd);
            if (umount("/root/test1/") < 0) {
                    perror("cannot umount\n");
                    exit(1);
            }
    }
    
    Signed-off-by: Hisashi Hifumi <hifumi.hisashi@oss.ntt.co.jp>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Jan Kara <jack@ucw.cz>
    Cc: <linux-ext4@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 82aa36c53ea7..50cfe8ceb478 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -205,6 +205,8 @@ void block_invalidatepage(struct page *page, unsigned long offset);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
 int block_read_full_page(struct page*, get_block_t*);
+int block_is_partially_uptodate(struct page *page, read_descriptor_t *desc,
+				unsigned long from);
 int block_write_begin(struct file *, struct address_space *,
 				loff_t, unsigned, unsigned,
 				struct page **, void **, get_block_t*);

commit 946a57b526a16e5662235cb8f573337bc8ecdc48
Author: Adrian Bunk <bunk@kernel.org>
Date:   Tue Apr 29 00:59:00 2008 -0700

    remove generic_commit_write()
    
    Remove the obsolete and no longer used generic_commit_write().
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 932eb02a2753..82aa36c53ea7 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -225,7 +225,6 @@ int block_page_mkwrite(struct vm_area_struct *vma, struct page *page,
 				get_block_t get_block);
 void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
-int generic_commit_write(struct file *, struct page *, unsigned, unsigned);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
 int file_fsync(struct file *, struct dentry *, int);
 int nobh_write_begin(struct file *, struct address_space *,

commit b3c97528689619fc66569b30bf83d09d9929521a
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Wed Feb 13 15:03:15 2008 -0800

    include/linux: Remove all users of FASTCALL() macro
    
    FASTCALL() is always expanded to empty, remove it.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index e98801f06dcc..932eb02a2753 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -144,7 +144,7 @@ BUFFER_FNS(Unwritten, unwritten)
  * Declarations
  */
 
-void FASTCALL(mark_buffer_dirty(struct buffer_head *bh));
+void mark_buffer_dirty(struct buffer_head *bh);
 void init_buffer(struct buffer_head *, bh_end_io_t *, void *);
 void set_bh_page(struct buffer_head *bh,
 		struct page *page, unsigned long offset);
@@ -185,8 +185,8 @@ struct buffer_head *__bread(struct block_device *, sector_t block, unsigned size
 void invalidate_bh_lrus(void);
 struct buffer_head *alloc_buffer_head(gfp_t gfp_flags);
 void free_buffer_head(struct buffer_head * bh);
-void FASTCALL(unlock_buffer(struct buffer_head *bh));
-void FASTCALL(__lock_buffer(struct buffer_head *bh));
+void unlock_buffer(struct buffer_head *bh);
+void __lock_buffer(struct buffer_head *bh);
 void ll_rw_block(int, int, struct buffer_head * bh[]);
 int sync_dirty_buffer(struct buffer_head *bh);
 int submit_bh(int, struct buffer_head *);

commit 389d1b083c767a360ec84b27a95da06244becec8
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Mon Jan 28 23:58:26 2008 -0500

    Add buffer head related helper functions
    
    Add buffer head related helper function bh_uptodate_or_lock and
    bh_submit_read which can be used by file system
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index da0d83fbadc0..e98801f06dcc 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -192,6 +192,8 @@ int sync_dirty_buffer(struct buffer_head *bh);
 int submit_bh(int, struct buffer_head *);
 void write_boundary_block(struct block_device *bdev,
 			sector_t bblock, unsigned blocksize);
+int bh_uptodate_or_lock(struct buffer_head *bh);
+int bh_submit_read(struct buffer_head *bh);
 
 extern int buffer_heads_over_limit;
 

commit 03158cd7eb3374843de68421142ca5900df845d9
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Oct 16 01:25:25 2007 -0700

    fs: restore nobh
    
    Implement nobh in new aops.  This is a bit tricky.  FWIW, nobh_truncate is
    now implemented in a way that does not create blocks in sparse regions,
    which is a silly thing for it to have been doing (isn't it?)
    
    ext2 survives fsx and fsstress. jfs is converted as well... ext3
    should be easy to do (but not done yet).
    
    [akpm@linux-foundation.org: coding-style fixes]
    Cc: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index f4ef547fc609..da0d83fbadc0 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -226,9 +226,13 @@ sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int generic_commit_write(struct file *, struct page *, unsigned, unsigned);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
 int file_fsync(struct file *, struct dentry *, int);
-int nobh_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
-int nobh_commit_write(struct file *, struct page *, unsigned, unsigned);
-int nobh_truncate_page(struct address_space *, loff_t);
+int nobh_write_begin(struct file *, struct address_space *,
+				loff_t, unsigned, unsigned,
+				struct page **, void **, get_block_t*);
+int nobh_write_end(struct file *, struct address_space *,
+				loff_t, unsigned, unsigned,
+				struct page *, void *);
+int nobh_truncate_page(struct address_space *, loff_t, get_block_t *);
 int nobh_writepage(struct page *page, get_block_t *get_block,
                         struct writeback_control *wbc);
 

commit a20fa20c549ed569885d871f689a59cfd2f6ff77
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Oct 16 01:25:15 2007 -0700

    With reiserfs no longer using the weird generic_cont_expand, remove it completely.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 1caa71d4c95f..f4ef547fc609 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -217,7 +217,6 @@ int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
 int cont_write_begin(struct file *, struct address_space *, loff_t,
 			unsigned, unsigned, struct page **, void **,
 			get_block_t *, loff_t *);
-int generic_cont_expand(struct inode *inode, loff_t size);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
 int block_page_mkwrite(struct vm_area_struct *vma, struct page *page,

commit 89e107877b65bf6eff1d63a1302dee9a091586f5
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Oct 16 01:25:07 2007 -0700

    fs: new cont helpers
    
    Rework the generic block "cont" routines to handle the new aops.  Supporting
    cont_prepare_write would take quite a lot of code to support, so remove it
    instead (and we later convert all filesystems to use it).
    
    write_begin gets passed AOP_FLAG_CONT_EXPAND when called from
    generic_cont_expand, so filesystems can avoid the old hacks they used.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index a562ecfb1a14..1caa71d4c95f 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -214,8 +214,9 @@ int generic_write_end(struct file *, struct address_space *,
 				struct page *, void *);
 void page_zero_new_buffers(struct page *page, unsigned from, unsigned to);
 int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
-int cont_prepare_write(struct page*, unsigned, unsigned, get_block_t*,
-				loff_t *);
+int cont_write_begin(struct file *, struct address_space *, loff_t,
+			unsigned, unsigned, struct page **, void **,
+			get_block_t *, loff_t *);
 int generic_cont_expand(struct inode *inode, loff_t size);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);

commit afddba49d18f346e5cc2938b6ed7c512db18ca68
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Oct 16 01:25:01 2007 -0700

    fs: introduce write_begin, write_end, and perform_write aops
    
    These are intended to replace prepare_write and commit_write with more
    flexible alternatives that are also able to avoid the buffered write
    deadlock problems efficiently (which prepare_write is unable to do).
    
    [mark.fasheh@oracle.com: API design contributions, code review and fixes]
    [akpm@linux-foundation.org: various fixes]
    [dmonakhov@sw.ru: new aop block_write_begin fix]
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Mark Fasheh <mark.fasheh@oracle.com>
    Signed-off-by: Dmitriy Monakhov <dmonakhov@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 35cadad84b14..a562ecfb1a14 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -203,6 +203,16 @@ void block_invalidatepage(struct page *page, unsigned long offset);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
 int block_read_full_page(struct page*, get_block_t*);
+int block_write_begin(struct file *, struct address_space *,
+				loff_t, unsigned, unsigned,
+				struct page **, void **, get_block_t*);
+int block_write_end(struct file *, struct address_space *,
+				loff_t, unsigned, unsigned,
+				struct page *, void *);
+int generic_write_end(struct file *, struct address_space *,
+				loff_t, unsigned, unsigned,
+				struct page *, void *);
+void page_zero_new_buffers(struct page *page, unsigned from, unsigned to);
 int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
 int cont_prepare_write(struct page*, unsigned, unsigned, get_block_t*,
 				loff_t *);

commit 5417169026c3df151adf5a65eb061278b0a72e69
Author: David Chinner <dgc@sgi.com>
Date:   Thu Jul 19 17:39:55 2007 +1000

    [FS] Implement block_page_mkwrite.
    
    Many filesystems need a ->page-mkwrite callout to correctly
    set up pages that have been written to by mmap. This is especially
    important when mmap is writing into holes as it allows filesystems
    to correctly account for and allocate space before the mmap
    write is allowed to proceed.
    
    Protection against truncate races is provided by locking the page
    and checking to see whether the page mapping is correct and whether
    it is beyond EOF so we don't end up allowing allocations beyond
    the current EOF or changing EOF as a result of a mmap write.
    
    SGI-PV: 940392
    SGI-Modid: 2.6.x-xfs-melb:linux:29146a
    
    Signed-off-by: David Chinner <dgc@sgi.com>
    Signed-off-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Tim Shimmin <tes@sgi.com>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 5c6e12853a9b..35cadad84b14 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -209,6 +209,8 @@ int cont_prepare_write(struct page*, unsigned, unsigned, get_block_t*,
 int generic_cont_expand(struct inode *inode, loff_t size);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
+int block_page_mkwrite(struct vm_area_struct *vma, struct page *page,
+				get_block_t get_block);
 void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int generic_commit_write(struct file *, struct page *, unsigned, unsigned);

commit f9a14399aea13830d8af6798a53207bb0a900945
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Sun May 6 14:49:55 2007 -0700

    mm: optimize kill_bdev()
    
    Remove duplicate work in kill_bdev().
    
    It currently invalidates and then truncates the bdev's mapping.
    invalidate_mapping_pages() will opportunistically remove pages from the
    mapping.  And truncate_inode_pages() will forcefully remove all pages.
    
    The only thing truncate doesn't do is flush the bh lrus.  So do that
    explicitly.  This avoids (very unlikely) but possible invalid lookup
    results if the same bdev is quickly re-issued.
    
    It also will prevent extreme kernel latencies which are observed when
    blockdevs which have a large amount of pagecache are unmounted, by avoiding
    invalidate_mapping_pages() on that path.  invalidate_mapping_pages() has no
    cond_resched (it can be called under spinlock), whereas truncate_inode_pages()
    has one.
    
    [akpm@linux-foundation.org: restore nrpages==0 optimisation]
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 632c50b21386..5c6e12853a9b 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -182,6 +182,7 @@ void __brelse(struct buffer_head *);
 void __bforget(struct buffer_head *);
 void __breadahead(struct block_device *, sector_t block, unsigned int size);
 struct buffer_head *__bread(struct block_device *, sector_t block, unsigned size);
+void invalidate_bh_lrus(void);
 struct buffer_head *alloc_buffer_head(gfp_t gfp_flags);
 void free_buffer_head(struct buffer_head * bh);
 void FASTCALL(unlock_buffer(struct buffer_head *bh));

commit f98393a64ca1392130724c3acb4e3f325801d2b6
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Sun May 6 14:49:54 2007 -0700

    mm: remove destroy_dirty_buffers from invalidate_bdev()
    
    Remove the destroy_dirty_buffers argument from invalidate_bdev(), it hasn't
    been used in 6 years (so akpm says).
    
    find * -name \*.[ch] | xargs grep -l invalidate_bdev |
    while read file; do
            quilt add $file;
            sed -ie 's/invalidate_bdev(\([^,]*\),[^)]*)/invalidate_bdev(\1)/g' $file;
    done
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index dd27b1c7227f..632c50b21386 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -165,7 +165,7 @@ int sync_mapping_buffers(struct address_space *mapping);
 void unmap_underlying_metadata(struct block_device *bdev, sector_t block);
 
 void mark_buffer_async_write(struct buffer_head *bh);
-void invalidate_bdev(struct block_device *, int);
+void invalidate_bdev(struct block_device *);
 int sync_blockdev(struct block_device *bdev);
 void __wait_on_buffer(struct buffer_head *);
 wait_queue_head_t *bh_waitq_head(struct buffer_head *bh);
@@ -319,7 +319,7 @@ static inline int inode_has_buffers(struct inode *inode) { return 0; }
 static inline void invalidate_inode_buffers(struct inode *inode) {}
 static inline int remove_inode_buffers(struct inode *inode) { return 1; }
 static inline int sync_mapping_buffers(struct address_space *mapping) { return 0; }
-static inline void invalidate_bdev(struct block_device *bdev, int destroy_dirty_buffers) {}
+static inline void invalidate_bdev(struct block_device *bdev) {}
 
 
 #endif /* CONFIG_BLOCK */

commit 3991d3bd1506391d8feec209b1d22ccb1c03a0bf
Author: Tomasz Kvarsin <kvarsin@gmail.com>
Date:   Mon Feb 12 00:52:14 2007 -0800

    [PATCH] warning fix: unsigned->signed
    
    While compiling my code with -Wconversion using gcc-trunk, I always get a
    bunch of warrning from headers, here is fix for them:
    
    __getblk is alawys called with unsigned argument,
    but it takes signed, the same story with __bread,__breadahead and so on.
    
    Signed-off-by: Tomasz Kvarsin
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index ffbdb6621f52..dd27b1c7227f 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -174,12 +174,14 @@ struct super_block *freeze_bdev(struct block_device *);
 void thaw_bdev(struct block_device *, struct super_block *);
 int fsync_super(struct super_block *);
 int fsync_no_super(struct block_device *);
-struct buffer_head *__find_get_block(struct block_device *, sector_t, int);
-struct buffer_head * __getblk(struct block_device *, sector_t, int);
+struct buffer_head *__find_get_block(struct block_device *bdev, sector_t block,
+			unsigned size);
+struct buffer_head *__getblk(struct block_device *bdev, sector_t block,
+			unsigned size);
 void __brelse(struct buffer_head *);
 void __bforget(struct buffer_head *);
-void __breadahead(struct block_device *, sector_t block, int size);
-struct buffer_head *__bread(struct block_device *, sector_t block, int size);
+void __breadahead(struct block_device *, sector_t block, unsigned int size);
+struct buffer_head *__bread(struct block_device *, sector_t block, unsigned size);
 struct buffer_head *alloc_buffer_head(gfp_t gfp_flags);
 void free_buffer_head(struct buffer_head * bh);
 void FASTCALL(unlock_buffer(struct buffer_head *bh));

commit 33a266dda9fbbe72dd978a451a8ee33c59da5e9c
Author: David Chinner <dgc@sgi.com>
Date:   Mon Feb 12 00:51:41 2007 -0800

    [PATCH] Make BH_Unwritten a first class bufferhead flag V2
    
    Currently, XFS uses BH_PrivateStart for flagging unwritten extent state in a
    bufferhead.  Recently, I found the long standing mmap/unwritten extent
    conversion bug, and it was to do with partial page invalidation not clearing
    the unwritten flag from bufferheads attached to the page but beyond EOF.  See
    here for a full explaination:
    
    http://oss.sgi.com/archives/xfs/2006-12/msg00196.html
    
    The solution I have checked into the XFS dev tree involves duplicating code
    from block_invalidatepage to clear the unwritten flag from the bufferhead(s),
    and then calling block_invalidatepage() to do the rest.
    
    Christoph suggested that this would be better solved by pushing the unwritten
    flag into the common buffer head flags and just adding the call to
    discard_buffer():
    
    http://oss.sgi.com/archives/xfs/2006-12/msg00239.html
    
    The following patch makes BH_Unwritten a first class citizen.
    
    Signed-off-by: Dave Chinner <dgc@sgi.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 5d9fb0e94156..ffbdb6621f52 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -34,6 +34,7 @@ enum bh_state_bits {
 	BH_Write_EIO,	/* I/O error on write */
 	BH_Ordered,	/* ordered write */
 	BH_Eopnotsupp,	/* operation not supported (barrier) */
+	BH_Unwritten,	/* Buffer is allocated on disk but not written */
 
 	BH_PrivateStart,/* not a state bit, but the first bit available
 			 * for private allocation by other entities
@@ -126,6 +127,7 @@ BUFFER_FNS(Boundary, boundary)
 BUFFER_FNS(Write_EIO, write_io_error)
 BUFFER_FNS(Ordered, ordered)
 BUFFER_FNS(Eopnotsupp, eopnotsupp)
+BUFFER_FNS(Unwritten, unwritten)
 
 #define bh_offset(bh)		((unsigned long)(bh)->b_data & ~PAGE_MASK)
 #define touch_buffer(bh)	mark_page_accessed(bh->b_page)

commit 58ff407bee5a55f9c1188a3f9d70ffc79485183c
Author: Jan Kara <jack@suse.cz>
Date:   Tue Oct 17 00:10:19 2006 -0700

    [PATCH] Fix IO error reporting on fsync()
    
    When IO error happens on metadata buffer, buffer is freed from memory and
    later fsync() is called, filesystems like ext2 fail to report EIO.  We
    
    solve the problem by introducing a pointer to associated address space into
    the buffer_head.  When a buffer is removed from a list of metadata buffers
    associated with an address space, IO error is transferred from the buffer to
    the address space, so that fsync can later report it.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 131ffd37e716..5d9fb0e94156 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -69,6 +69,8 @@ struct buffer_head {
 	bh_end_io_t *b_end_io;		/* I/O completion */
  	void *b_private;		/* reserved for b_end_io */
 	struct list_head b_assoc_buffers; /* associated with another mapping */
+	struct address_space *b_assoc_map;	/* mapping this buffer is
+						   associated with */
 	atomic_t b_count;		/* users using this buffer_head */
 };
 

commit 9361401eb7619c033e2394e4f9f6d410d6719ac7
Author: David Howells <dhowells@redhat.com>
Date:   Sat Sep 30 20:45:40 2006 +0200

    [PATCH] BLOCK: Make it possible to disable the block layer [try #6]
    
    Make it possible to disable the block layer.  Not all embedded devices require
    it, some can make do with just JFFS2, NFS, ramfs, etc - none of which require
    the block layer to be present.
    
    This patch does the following:
    
     (*) Introduces CONFIG_BLOCK to disable the block layer, buffering and blockdev
         support.
    
     (*) Adds dependencies on CONFIG_BLOCK to any configuration item that controls
         an item that uses the block layer.  This includes:
    
         (*) Block I/O tracing.
    
         (*) Disk partition code.
    
         (*) All filesystems that are block based, eg: Ext3, ReiserFS, ISOFS.
    
         (*) The SCSI layer.  As far as I can tell, even SCSI chardevs use the
             block layer to do scheduling.  Some drivers that use SCSI facilities -
             such as USB storage - end up disabled indirectly from this.
    
         (*) Various block-based device drivers, such as IDE and the old CDROM
             drivers.
    
         (*) MTD blockdev handling and FTL.
    
         (*) JFFS - which uses set_bdev_super(), something it could avoid doing by
             taking a leaf out of JFFS2's book.
    
     (*) Makes most of the contents of linux/blkdev.h, linux/buffer_head.h and
         linux/elevator.h contingent on CONFIG_BLOCK being set.  sector_div() is,
         however, still used in places, and so is still available.
    
     (*) Also made contingent are the contents of linux/mpage.h, linux/genhd.h and
         parts of linux/fs.h.
    
     (*) Makes a number of files in fs/ contingent on CONFIG_BLOCK.
    
     (*) Makes mm/bounce.c (bounce buffering) contingent on CONFIG_BLOCK.
    
     (*) set_page_dirty() doesn't call __set_page_dirty_buffers() if CONFIG_BLOCK
         is not enabled.
    
     (*) fs/no-block.c is created to hold out-of-line stubs and things that are
         required when CONFIG_BLOCK is not set:
    
         (*) Default blockdev file operations (to give error ENODEV on opening).
    
     (*) Makes some /proc changes:
    
         (*) /proc/devices does not list any blockdevs.
    
         (*) /proc/diskstats and /proc/partitions are contingent on CONFIG_BLOCK.
    
     (*) Makes some compat ioctl handling contingent on CONFIG_BLOCK.
    
     (*) If CONFIG_BLOCK is not defined, makes sys_quotactl() return -ENODEV if
         given command other than Q_SYNC or if a special device is specified.
    
     (*) In init/do_mounts.c, no reference is made to the blockdev routines if
         CONFIG_BLOCK is not defined.  This does not prohibit NFS roots or JFFS2.
    
     (*) The bdflush, ioprio_set and ioprio_get syscalls can now be absent (return
         error ENOSYS by way of cond_syscall if so).
    
     (*) The seclvl_bd_claim() and seclvl_bd_release() security calls do nothing if
         CONFIG_BLOCK is not set, since they can't then happen.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 64b508e35d2a..131ffd37e716 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -14,6 +14,8 @@
 #include <linux/wait.h>
 #include <asm/atomic.h>
 
+#ifdef CONFIG_BLOCK
+
 enum bh_state_bits {
 	BH_Uptodate,	/* Contains valid data */
 	BH_Dirty,	/* Is dirty */
@@ -301,4 +303,18 @@ static inline void lock_buffer(struct buffer_head *bh)
 }
 
 extern int __set_page_dirty_buffers(struct page *page);
+
+#else /* CONFIG_BLOCK */
+
+static inline void buffer_init(void) {}
+static inline int try_to_free_buffers(struct page *page) { return 1; }
+static inline int sync_blockdev(struct block_device *bdev) { return 0; }
+static inline int inode_has_buffers(struct inode *inode) { return 0; }
+static inline void invalidate_inode_buffers(struct inode *inode) {}
+static inline int remove_inode_buffers(struct inode *inode) { return 1; }
+static inline int sync_mapping_buffers(struct address_space *mapping) { return 0; }
+static inline void invalidate_bdev(struct block_device *bdev, int destroy_dirty_buffers) {}
+
+
+#endif /* CONFIG_BLOCK */
 #endif /* _LINUX_BUFFER_HEAD_H */

commit cf9a2ae8d49948f861b56e5333530e491a9da190
Author: David Howells <dhowells@redhat.com>
Date:   Tue Aug 29 19:05:54 2006 +0100

    [PATCH] BLOCK: Move functions out of buffer code [try #6]
    
    Move some functions out of the buffering code that aren't strictly buffering
    specific.  This is a precursor to being able to disable the block layer.
    
     (*) Moved some stuff out of fs/buffer.c:
    
         (*) The file sync and general sync stuff moved to fs/sync.c.
    
         (*) The superblock sync stuff moved to fs/super.c.
    
         (*) do_invalidatepage() moved to mm/truncate.c.
    
         (*) try_to_release_page() moved to mm/filemap.c.
    
     (*) Moved some related declarations between header files:
    
         (*) declarations for do_invalidatepage() and try_to_release_page() moved
             to linux/mm.h.
    
         (*) __set_page_dirty_buffers() moved to linux/buffer_head.h.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 737e407d0cd1..64b508e35d2a 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -190,9 +190,7 @@ extern int buffer_heads_over_limit;
  * Generic address_space_operations implementations for buffer_head-backed
  * address_spaces.
  */
-int try_to_release_page(struct page * page, gfp_t gfp_mask);
 void block_invalidatepage(struct page *page, unsigned long offset);
-void do_invalidatepage(struct page *page, unsigned long offset);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
 int block_read_full_page(struct page*, get_block_t*);
@@ -302,4 +300,5 @@ static inline void lock_buffer(struct buffer_head *bh)
 		__lock_buffer(bh);
 }
 
+extern int __set_page_dirty_buffers(struct page *page);
 #endif /* _LINUX_BUFFER_HEAD_H */

commit b6cd0b772dcc5dc9b4c03d53946474dee399fa72
Author: Adrian Bunk <bunk@stusta.de>
Date:   Tue Jun 27 02:53:54 2006 -0700

    [PATCH] fs/buffer.c: cleanups
    
    - add a proper prototype for the following global function:
      - buffer_init()
    
    - make the following needlessly global function static:
      - end_buffer_async_write()
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index fb7e9b7ccbe3..737e407d0cd1 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -149,7 +149,6 @@ void create_empty_buffers(struct page *, unsigned long,
 			unsigned long b_state);
 void end_buffer_read_sync(struct buffer_head *bh, int uptodate);
 void end_buffer_write_sync(struct buffer_head *bh, int uptodate);
-void end_buffer_async_write(struct buffer_head *bh, int uptodate);
 
 /* Things to do with buffers at mapping->private_list */
 void mark_buffer_dirty_inode(struct buffer_head *bh, struct inode *inode);
@@ -214,6 +213,7 @@ int nobh_truncate_page(struct address_space *, loff_t);
 int nobh_writepage(struct page *page, get_block_t *get_block,
                         struct writeback_control *wbc);
 
+void buffer_init(void);
 
 /*
  * inline definitions

commit b0cf2321c6599138f860517745503691556d8453
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sun Mar 26 01:38:00 2006 -0800

    [PATCH] pass b_size to ->get_block()
    
    Pass amount of disk needs to be mapped to get_block().  This way one can
    modify the fs ->get_block() functions to map multiple blocks at the same time.
    
    [akpm@osdl.org: performance tweak]
    [akpm@osdl.org: remove unneeded assignments]
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 464f068f8b16..fb7e9b7ccbe3 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -280,6 +280,7 @@ map_bh(struct buffer_head *bh, struct super_block *sb, sector_t block)
 	set_buffer_mapped(bh);
 	bh->b_bdev = sb->s_bdev;
 	bh->b_blocknr = block;
+	bh->b_size = sb->s_blocksize;
 }
 
 /*

commit 205f87f6b342444f722e4559d33318686f7df2ca
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sun Mar 26 01:38:00 2006 -0800

    [PATCH] change buffer_head.b_size to size_t
    
    Increase the size of the buffer_head b_size field (only) for 64 bit platforms.
    Update some old and moldy comments in and around the structure as well.
    
    The b_size increase allows us to perform larger mappings and allocations for
    large I/O requests from userspace, which tie in with other changes allowing
    the get_block_t() interface to map multiple blocks at once.
    
    Signed-off-by: Nathan Scott <nathans@sgi.com>
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index da917ed096a3..464f068f8b16 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -46,25 +46,28 @@ struct address_space;
 typedef void (bh_end_io_t)(struct buffer_head *bh, int uptodate);
 
 /*
- * Keep related fields in common cachelines.  The most commonly accessed
- * field (b_state) goes at the start so the compiler does not generate
- * indexed addressing for it.
+ * Historically, a buffer_head was used to map a single block
+ * within a page, and of course as the unit of I/O through the
+ * filesystem and block layers.  Nowadays the basic I/O unit
+ * is the bio, and buffer_heads are used for extracting block
+ * mappings (via a get_block_t call), for tracking state within
+ * a page (via a page_mapping) and for wrapping bio submission
+ * for backward compatibility reasons (e.g. submit_bh).
  */
 struct buffer_head {
-	/* First cache line: */
 	unsigned long b_state;		/* buffer state bitmap (see above) */
 	struct buffer_head *b_this_page;/* circular list of page's buffers */
 	struct page *b_page;		/* the page this bh is mapped to */
-	atomic_t b_count;		/* users using this block */
-	u32 b_size;			/* block size */
 
-	sector_t b_blocknr;		/* block number */
-	char *b_data;			/* pointer to data block */
+	sector_t b_blocknr;		/* start block number */
+	size_t b_size;			/* size of mapping */
+	char *b_data;			/* pointer to data within the page */
 
 	struct block_device *b_bdev;
 	bh_end_io_t *b_end_io;		/* I/O completion */
  	void *b_private;		/* reserved for b_end_io */
 	struct list_head b_assoc_buffers; /* associated with another mapping */
+	atomic_t b_count;		/* users using this buffer_head */
 };
 
 /*

commit 2ff28e22bdb8727fbc7d7889807bc5a73aae56c5
Author: NeilBrown <neilb@suse.de>
Date:   Sun Mar 26 01:37:18 2006 -0800

    [PATCH] Make address_space_operations->invalidatepage return void
    
    The return value of this function is never used, so let's be honest and
    declare it as void.
    
    Some places where invalidatepage returned 0, I have inserted comments
    suggesting a BUG_ON.
    
    [akpm@osdl.org: JBD BUG fix]
    [akpm@osdl.org: rework for git-nfs]
    [akpm@osdl.org: don't go BUG in block_invalidate_page()]
    Signed-off-by: Neil Brown <neilb@suse.de>
    Acked-by: Dave Kleikamp <shaggy@austin.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 27dd97b3fce9..da917ed096a3 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -189,8 +189,8 @@ extern int buffer_heads_over_limit;
  * address_spaces.
  */
 int try_to_release_page(struct page * page, gfp_t gfp_mask);
-int block_invalidatepage(struct page *page, unsigned long offset);
-int do_invalidatepage(struct page *page, unsigned long offset);
+void block_invalidatepage(struct page *page, unsigned long offset);
+void do_invalidatepage(struct page *page, unsigned long offset);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
 int block_read_full_page(struct page*, get_block_t*);

commit 3978d7179d3849848df8a37dd0a5acc20bcb8750
Author: NeilBrown <neilb@suse.de>
Date:   Sun Mar 26 01:37:17 2006 -0800

    [PATCH] Make address_space_operations->sync_page return void
    
    The only user ignores the return value, and the only instanace
    (block_sync_page) always returns 0...
    
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 9f159baf153f..27dd97b3fce9 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -200,7 +200,7 @@ int cont_prepare_write(struct page*, unsigned, unsigned, get_block_t*,
 int generic_cont_expand(struct inode *inode, loff_t size);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
-int block_sync_page(struct page *);
+void block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
 int generic_commit_write(struct file *, struct page *, unsigned, unsigned);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);

commit 05eb0b51fb46430050d5873458612f53e0234f2e
Author: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
Date:   Sun Jan 8 01:02:13 2006 -0800

    [PATCH] fat: support a truncate() for expanding size (generic_cont_expand)
    
    This patch changes generic_cont_expand(), in order to share the code
    with fatfs.
    
      - Use vmtruncate() if ->prepare_write() returns a error.
    
    Even if ->prepare_write() returns an error, it may already have added some
    blocks.  So, this truncates blocks outside of ->i_size by vmtruncate().
    
      - Add generic_cont_expand_simple().
    
    The generic_cont_expand_simple() assumes that ->prepare_write() can handle
    the block boundary.  With this, we don't need to care the extra byte.
    
    And for expanding a file size by truncate(), fatfs uses the
    added generic_cont_expand_simple().
    
    Signed-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 1db061bb6b08..9f159baf153f 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -197,7 +197,8 @@ int block_read_full_page(struct page*, get_block_t*);
 int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
 int cont_prepare_write(struct page*, unsigned, unsigned, get_block_t*,
 				loff_t *);
-int generic_cont_expand(struct inode *inode, loff_t size) ;
+int generic_cont_expand(struct inode *inode, loff_t size);
+int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
 int block_sync_page(struct page *);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);

commit aaa4059bc2dca7fa816624a28db1958c3a22df9b
Author: Jan Kara <jack@suse.cz>
Date:   Sun Oct 30 15:00:16 2005 -0800

    [PATCH] ext3: Fix unmapped buffers in transaction's lists
    
    Fix the problem (BUG 4964) with unmapped buffers in transaction's
    t_sync_data list.  The problem is we need to call filesystem's own
    invalidatepage() from block_write_full_page().
    
    block_write_full_page() must call filesystem's invalidatepage().  Otherwise
    following nasty race can happen:
    
       proc 1                                        proc 2
       ------                                        ------
    - write some new data to 'offset'
      => bh gets to the transactions data list
                                                  - starts truncate
                                                    => i_size set to new size
    - mpage_writepages()
      - ext3_ordered_writepage() to 'offset'
        - block_write_full_page()
          - page->index > end_index+1
            - block_invalidatepage()
              - discard_buffer()
                - clear_buffer_mapped()
    
    - commit triggers and finds unmapped buffer - BOOM!
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index c937d6e65502..1db061bb6b08 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -190,6 +190,7 @@ extern int buffer_heads_over_limit;
  */
 int try_to_release_page(struct page * page, gfp_t gfp_mask);
 int block_invalidatepage(struct page *page, unsigned long offset);
+int do_invalidatepage(struct page *page, unsigned long offset);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);
 int block_read_full_page(struct page*, get_block_t*);

commit 4c21e2f2441dc5fbb957b030333f5a3f2d02dea7
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sat Oct 29 18:16:40 2005 -0700

    [PATCH] mm: split page table lock
    
    Christoph Lameter demonstrated very poor scalability on the SGI 512-way, with
    a many-threaded application which concurrently initializes different parts of
    a large anonymous area.
    
    This patch corrects that, by using a separate spinlock per page table page, to
    guard the page table entries in that page, instead of using the mm's single
    page_table_lock.  (But even then, page_table_lock is still used to guard page
    table allocation, and anon_vma allocation.)
    
    In this implementation, the spinlock is tucked inside the struct page of the
    page table page: with a BUILD_BUG_ON in case it overflows - which it would in
    the case of 32-bit PA-RISC with spinlock debugging enabled.
    
    Splitting the lock is not quite for free: another cacheline access.  Ideally,
    I suppose we would use split ptlock only for multi-threaded processes on
    multi-cpu machines; but deciding that dynamically would have its own costs.
    So for now enable it by config, at some number of cpus - since the Kconfig
    language doesn't support inequalities, let preprocessor compare that with
    NR_CPUS.  But I don't think it's worth being user-configurable: for good
    testing of both split and unsplit configs, split now at 4 cpus, and perhaps
    change that to 8 later.
    
    There is a benefit even for singly threaded processes: kswapd can be attacking
    one part of the mm while another part is busy faulting.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 88af42f5e04a..c937d6e65502 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -126,8 +126,8 @@ BUFFER_FNS(Eopnotsupp, eopnotsupp)
 /* If we *know* page->private refers to buffer_heads */
 #define page_buffers(page)					\
 	({							\
-		BUG_ON(!PagePrivate(page));		\
-		((struct buffer_head *)(page)->private);	\
+		BUG_ON(!PagePrivate(page));			\
+		((struct buffer_head *)page_private(page));	\
 	})
 #define page_has_buffers(page)	PagePrivate(page)
 
@@ -219,7 +219,7 @@ static inline void attach_page_buffers(struct page *page,
 {
 	page_cache_get(page);
 	SetPagePrivate(page);
-	page->private = (unsigned long)head;
+	set_page_private(page, (unsigned long)head);
 }
 
 static inline void get_bh(struct buffer_head *bh)

commit 27496a8c67bef4d789d8e3c8317ca35813a507ae
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Oct 21 03:20:48 2005 -0400

    [PATCH] gfp_t: fs/*
    
     - ->releasepage() annotated (s/int/gfp_t), instances updated
     - missing gfp_t in fs/* added
     - fixed misannotation from the original sweep caught by bitwise checks:
       XFS used __nocast both for gfp_t and for flags used by XFS allocator.
       The latter left with unsigned int __nocast; we might want to add a
       different type for those but for now let's leave them alone.  That,
       BTW, is a case when __nocast use had been actively confusing - it had
       been used in the same code for two different and similar types, with
       no way to catch misuses.  Switch of gfp_t to bitwise had caught that
       immediately...
    
    One tricky bit is left alone to be dealt with later - mapping->flags is
    a mix of gfp_t and error indications.  Left alone for now.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 6a1d154c0825..88af42f5e04a 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -188,7 +188,7 @@ extern int buffer_heads_over_limit;
  * Generic address_space_operations implementations for buffer_head-backed
  * address_spaces.
  */
-int try_to_release_page(struct page * page, int gfp_mask);
+int try_to_release_page(struct page * page, gfp_t gfp_mask);
 int block_invalidatepage(struct page *page, unsigned long offset);
 int block_write_full_page(struct page *page, get_block_t *get_block,
 				struct writeback_control *wbc);

commit dd0fc66fb33cd610bc1a5db8a5e232d34879b4d7
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Fri Oct 7 07:46:04 2005 +0100

    [PATCH] gfp flags annotations - part 1
    
     - added typedef unsigned int __nocast gfp_t;
    
     - replaced __nocast uses for gfp flags with gfp_t - it gives exactly
       the same warnings as far as sparse is concerned, doesn't change
       generated code (from gcc point of view we replaced unsigned int with
       typedef) and documents what's going on far better.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 90828493791f..6a1d154c0825 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -172,7 +172,7 @@ void __brelse(struct buffer_head *);
 void __bforget(struct buffer_head *);
 void __breadahead(struct block_device *, sector_t block, int size);
 struct buffer_head *__bread(struct block_device *, sector_t block, int size);
-struct buffer_head *alloc_buffer_head(unsigned int __nocast gfp_flags);
+struct buffer_head *alloc_buffer_head(gfp_t gfp_flags);
 void free_buffer_head(struct buffer_head * bh);
 void FASTCALL(unlock_buffer(struct buffer_head *bh));
 void FASTCALL(__lock_buffer(struct buffer_head *bh));

commit a39722034ae37f80a1803bf781fe3fe1b03e20bc
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Thu Jul 7 17:56:56 2005 -0700

    [PATCH] page_uptodate locking scalability
    
    Use a bit spin lock in the first buffer of the page to synchronise asynch
    IO buffer completions, instead of the global page_uptodate_lock, which is
    showing some scalabilty problems.
    
    Signed-off-by: Nick Piggin <nickpiggin@yahoo.com.au>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 802c91e9b3da..90828493791f 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -19,6 +19,9 @@ enum bh_state_bits {
 	BH_Dirty,	/* Is dirty */
 	BH_Lock,	/* Is locked */
 	BH_Req,		/* Has been submitted for I/O */
+	BH_Uptodate_Lock,/* Used by the first bh in a page, to serialise
+			  * IO completion of other buffers in the page
+			  */
 
 	BH_Mapped,	/* Has a disk mapping */
 	BH_New,		/* Disk mapping was newly created by get_block */

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
new file mode 100644
index 000000000000..802c91e9b3da
--- /dev/null
+++ b/include/linux/buffer_head.h
@@ -0,0 +1,296 @@
+/*
+ * include/linux/buffer_head.h
+ *
+ * Everything to do with buffer_heads.
+ */
+
+#ifndef _LINUX_BUFFER_HEAD_H
+#define _LINUX_BUFFER_HEAD_H
+
+#include <linux/types.h>
+#include <linux/fs.h>
+#include <linux/linkage.h>
+#include <linux/pagemap.h>
+#include <linux/wait.h>
+#include <asm/atomic.h>
+
+enum bh_state_bits {
+	BH_Uptodate,	/* Contains valid data */
+	BH_Dirty,	/* Is dirty */
+	BH_Lock,	/* Is locked */
+	BH_Req,		/* Has been submitted for I/O */
+
+	BH_Mapped,	/* Has a disk mapping */
+	BH_New,		/* Disk mapping was newly created by get_block */
+	BH_Async_Read,	/* Is under end_buffer_async_read I/O */
+	BH_Async_Write,	/* Is under end_buffer_async_write I/O */
+	BH_Delay,	/* Buffer is not yet allocated on disk */
+	BH_Boundary,	/* Block is followed by a discontiguity */
+	BH_Write_EIO,	/* I/O error on write */
+	BH_Ordered,	/* ordered write */
+	BH_Eopnotsupp,	/* operation not supported (barrier) */
+
+	BH_PrivateStart,/* not a state bit, but the first bit available
+			 * for private allocation by other entities
+			 */
+};
+
+#define MAX_BUF_PER_PAGE (PAGE_CACHE_SIZE / 512)
+
+struct page;
+struct buffer_head;
+struct address_space;
+typedef void (bh_end_io_t)(struct buffer_head *bh, int uptodate);
+
+/*
+ * Keep related fields in common cachelines.  The most commonly accessed
+ * field (b_state) goes at the start so the compiler does not generate
+ * indexed addressing for it.
+ */
+struct buffer_head {
+	/* First cache line: */
+	unsigned long b_state;		/* buffer state bitmap (see above) */
+	struct buffer_head *b_this_page;/* circular list of page's buffers */
+	struct page *b_page;		/* the page this bh is mapped to */
+	atomic_t b_count;		/* users using this block */
+	u32 b_size;			/* block size */
+
+	sector_t b_blocknr;		/* block number */
+	char *b_data;			/* pointer to data block */
+
+	struct block_device *b_bdev;
+	bh_end_io_t *b_end_io;		/* I/O completion */
+ 	void *b_private;		/* reserved for b_end_io */
+	struct list_head b_assoc_buffers; /* associated with another mapping */
+};
+
+/*
+ * macro tricks to expand the set_buffer_foo(), clear_buffer_foo()
+ * and buffer_foo() functions.
+ */
+#define BUFFER_FNS(bit, name)						\
+static inline void set_buffer_##name(struct buffer_head *bh)		\
+{									\
+	set_bit(BH_##bit, &(bh)->b_state);				\
+}									\
+static inline void clear_buffer_##name(struct buffer_head *bh)		\
+{									\
+	clear_bit(BH_##bit, &(bh)->b_state);				\
+}									\
+static inline int buffer_##name(const struct buffer_head *bh)		\
+{									\
+	return test_bit(BH_##bit, &(bh)->b_state);			\
+}
+
+/*
+ * test_set_buffer_foo() and test_clear_buffer_foo()
+ */
+#define TAS_BUFFER_FNS(bit, name)					\
+static inline int test_set_buffer_##name(struct buffer_head *bh)	\
+{									\
+	return test_and_set_bit(BH_##bit, &(bh)->b_state);		\
+}									\
+static inline int test_clear_buffer_##name(struct buffer_head *bh)	\
+{									\
+	return test_and_clear_bit(BH_##bit, &(bh)->b_state);		\
+}									\
+
+/*
+ * Emit the buffer bitops functions.   Note that there are also functions
+ * of the form "mark_buffer_foo()".  These are higher-level functions which
+ * do something in addition to setting a b_state bit.
+ */
+BUFFER_FNS(Uptodate, uptodate)
+BUFFER_FNS(Dirty, dirty)
+TAS_BUFFER_FNS(Dirty, dirty)
+BUFFER_FNS(Lock, locked)
+TAS_BUFFER_FNS(Lock, locked)
+BUFFER_FNS(Req, req)
+TAS_BUFFER_FNS(Req, req)
+BUFFER_FNS(Mapped, mapped)
+BUFFER_FNS(New, new)
+BUFFER_FNS(Async_Read, async_read)
+BUFFER_FNS(Async_Write, async_write)
+BUFFER_FNS(Delay, delay)
+BUFFER_FNS(Boundary, boundary)
+BUFFER_FNS(Write_EIO, write_io_error)
+BUFFER_FNS(Ordered, ordered)
+BUFFER_FNS(Eopnotsupp, eopnotsupp)
+
+#define bh_offset(bh)		((unsigned long)(bh)->b_data & ~PAGE_MASK)
+#define touch_buffer(bh)	mark_page_accessed(bh->b_page)
+
+/* If we *know* page->private refers to buffer_heads */
+#define page_buffers(page)					\
+	({							\
+		BUG_ON(!PagePrivate(page));		\
+		((struct buffer_head *)(page)->private);	\
+	})
+#define page_has_buffers(page)	PagePrivate(page)
+
+/*
+ * Declarations
+ */
+
+void FASTCALL(mark_buffer_dirty(struct buffer_head *bh));
+void init_buffer(struct buffer_head *, bh_end_io_t *, void *);
+void set_bh_page(struct buffer_head *bh,
+		struct page *page, unsigned long offset);
+int try_to_free_buffers(struct page *);
+struct buffer_head *alloc_page_buffers(struct page *page, unsigned long size,
+		int retry);
+void create_empty_buffers(struct page *, unsigned long,
+			unsigned long b_state);
+void end_buffer_read_sync(struct buffer_head *bh, int uptodate);
+void end_buffer_write_sync(struct buffer_head *bh, int uptodate);
+void end_buffer_async_write(struct buffer_head *bh, int uptodate);
+
+/* Things to do with buffers at mapping->private_list */
+void mark_buffer_dirty_inode(struct buffer_head *bh, struct inode *inode);
+int inode_has_buffers(struct inode *);
+void invalidate_inode_buffers(struct inode *);
+int remove_inode_buffers(struct inode *inode);
+int sync_mapping_buffers(struct address_space *mapping);
+void unmap_underlying_metadata(struct block_device *bdev, sector_t block);
+
+void mark_buffer_async_write(struct buffer_head *bh);
+void invalidate_bdev(struct block_device *, int);
+int sync_blockdev(struct block_device *bdev);
+void __wait_on_buffer(struct buffer_head *);
+wait_queue_head_t *bh_waitq_head(struct buffer_head *bh);
+int fsync_bdev(struct block_device *);
+struct super_block *freeze_bdev(struct block_device *);
+void thaw_bdev(struct block_device *, struct super_block *);
+int fsync_super(struct super_block *);
+int fsync_no_super(struct block_device *);
+struct buffer_head *__find_get_block(struct block_device *, sector_t, int);
+struct buffer_head * __getblk(struct block_device *, sector_t, int);
+void __brelse(struct buffer_head *);
+void __bforget(struct buffer_head *);
+void __breadahead(struct block_device *, sector_t block, int size);
+struct buffer_head *__bread(struct block_device *, sector_t block, int size);
+struct buffer_head *alloc_buffer_head(unsigned int __nocast gfp_flags);
+void free_buffer_head(struct buffer_head * bh);
+void FASTCALL(unlock_buffer(struct buffer_head *bh));
+void FASTCALL(__lock_buffer(struct buffer_head *bh));
+void ll_rw_block(int, int, struct buffer_head * bh[]);
+int sync_dirty_buffer(struct buffer_head *bh);
+int submit_bh(int, struct buffer_head *);
+void write_boundary_block(struct block_device *bdev,
+			sector_t bblock, unsigned blocksize);
+
+extern int buffer_heads_over_limit;
+
+/*
+ * Generic address_space_operations implementations for buffer_head-backed
+ * address_spaces.
+ */
+int try_to_release_page(struct page * page, int gfp_mask);
+int block_invalidatepage(struct page *page, unsigned long offset);
+int block_write_full_page(struct page *page, get_block_t *get_block,
+				struct writeback_control *wbc);
+int block_read_full_page(struct page*, get_block_t*);
+int block_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
+int cont_prepare_write(struct page*, unsigned, unsigned, get_block_t*,
+				loff_t *);
+int generic_cont_expand(struct inode *inode, loff_t size) ;
+int block_commit_write(struct page *page, unsigned from, unsigned to);
+int block_sync_page(struct page *);
+sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
+int generic_commit_write(struct file *, struct page *, unsigned, unsigned);
+int block_truncate_page(struct address_space *, loff_t, get_block_t *);
+int file_fsync(struct file *, struct dentry *, int);
+int nobh_prepare_write(struct page*, unsigned, unsigned, get_block_t*);
+int nobh_commit_write(struct file *, struct page *, unsigned, unsigned);
+int nobh_truncate_page(struct address_space *, loff_t);
+int nobh_writepage(struct page *page, get_block_t *get_block,
+                        struct writeback_control *wbc);
+
+
+/*
+ * inline definitions
+ */
+
+static inline void attach_page_buffers(struct page *page,
+		struct buffer_head *head)
+{
+	page_cache_get(page);
+	SetPagePrivate(page);
+	page->private = (unsigned long)head;
+}
+
+static inline void get_bh(struct buffer_head *bh)
+{
+        atomic_inc(&bh->b_count);
+}
+
+static inline void put_bh(struct buffer_head *bh)
+{
+        smp_mb__before_atomic_dec();
+        atomic_dec(&bh->b_count);
+}
+
+static inline void brelse(struct buffer_head *bh)
+{
+	if (bh)
+		__brelse(bh);
+}
+
+static inline void bforget(struct buffer_head *bh)
+{
+	if (bh)
+		__bforget(bh);
+}
+
+static inline struct buffer_head *
+sb_bread(struct super_block *sb, sector_t block)
+{
+	return __bread(sb->s_bdev, block, sb->s_blocksize);
+}
+
+static inline void
+sb_breadahead(struct super_block *sb, sector_t block)
+{
+	__breadahead(sb->s_bdev, block, sb->s_blocksize);
+}
+
+static inline struct buffer_head *
+sb_getblk(struct super_block *sb, sector_t block)
+{
+	return __getblk(sb->s_bdev, block, sb->s_blocksize);
+}
+
+static inline struct buffer_head *
+sb_find_get_block(struct super_block *sb, sector_t block)
+{
+	return __find_get_block(sb->s_bdev, block, sb->s_blocksize);
+}
+
+static inline void
+map_bh(struct buffer_head *bh, struct super_block *sb, sector_t block)
+{
+	set_buffer_mapped(bh);
+	bh->b_bdev = sb->s_bdev;
+	bh->b_blocknr = block;
+}
+
+/*
+ * Calling wait_on_buffer() for a zero-ref buffer is illegal, so we call into
+ * __wait_on_buffer() just to trip a debug check.  Because debug code in inline
+ * functions is bloaty.
+ */
+static inline void wait_on_buffer(struct buffer_head *bh)
+{
+	might_sleep();
+	if (buffer_locked(bh) || atomic_read(&bh->b_count) == 0)
+		__wait_on_buffer(bh);
+}
+
+static inline void lock_buffer(struct buffer_head *bh)
+{
+	might_sleep();
+	if (test_set_buffer_locked(bh))
+		__lock_buffer(bh);
+}
+
+#endif /* _LINUX_BUFFER_HEAD_H */
