commit ca5999fde0a1761665a38e4c9a72dbcd7d190a81
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:38 2020 -0700

    mm: introduce include/linux/pgtable.h
    
    The include/linux/pgtable.h is going to be the home of generic page table
    manipulation functions.
    
    Start with moving asm-generic/pgtable.h to include/linux/pgtable.h and
    make the latter include asm/pgtable.h.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-3-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index b59f1b6be3e9..ca09a4e07d2d 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -3,7 +3,7 @@
 #define _LINUX_DMA_NONCOHERENT_H 1
 
 #include <linux/dma-mapping.h>
-#include <asm/pgtable.h>
+#include <linux/pgtable.h>
 
 #ifdef CONFIG_ARCH_HAS_DMA_COHERENCE_H
 #include <asm/dma-coherence.h>

commit 999a5d1203baa7cff00586361feae263ee3f23a5
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Feb 21 12:35:05 2020 -0800

    dma-direct: provide a arch_dma_clear_uncached hook
    
    This allows the arch code to reset the page tables to cached access when
    freeing a dma coherent allocation that was set to uncached using
    arch_dma_set_uncached.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 1a4039506673..b59f1b6be3e9 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -109,5 +109,6 @@ static inline void arch_dma_prep_coherent(struct page *page, size_t size)
 #endif /* CONFIG_ARCH_HAS_DMA_PREP_COHERENT */
 
 void *arch_dma_set_uncached(void *addr, size_t size);
+void arch_dma_clear_uncached(void *addr, size_t size);
 
 #endif /* _LINUX_DMA_NONCOHERENT_H */

commit fa7e2247c5729f990c7456fe09f3af99c8f2571b
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Feb 21 15:55:43 2020 -0800

    dma-direct: make uncached_kernel_address more general
    
    Rename the symbol to arch_dma_set_uncached, and pass a size to it as
    well as allow an error return.  That will allow reusing this hook for
    in-place pagetable remapping.
    
    As the in-place remap doesn't always require an explicit cache flush,
    also detangle ARCH_HAS_DMA_PREP_COHERENT from ARCH_HAS_DMA_SET_UNCACHED.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index b6b72e19b0cd..1a4039506673 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -108,6 +108,6 @@ static inline void arch_dma_prep_coherent(struct page *page, size_t size)
 }
 #endif /* CONFIG_ARCH_HAS_DMA_PREP_COHERENT */
 
-void *uncached_kernel_address(void *addr);
+void *arch_dma_set_uncached(void *addr, size_t size);
 
 #endif /* _LINUX_DMA_NONCOHERENT_H */

commit 4f8232bbf887123f78bcdca3dfd2b3dfa52a0112
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Feb 21 12:24:02 2020 -0800

    dma-direct: remove the cached_kernel_address hook
    
    dma-direct now finds the kernel address for coherent allocations based
    on the dma address, so the cached_kernel_address hooks is unused and
    can be removed entirely.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index ca9b5770caee..b6b72e19b0cd 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -109,6 +109,5 @@ static inline void arch_dma_prep_coherent(struct page *page, size_t size)
 #endif /* CONFIG_ARCH_HAS_DMA_PREP_COHERENT */
 
 void *uncached_kernel_address(void *addr);
-void *cached_kernel_address(void *addr);
 
 #endif /* _LINUX_DMA_NONCOHERENT_H */

commit 56e35f9c5b87ec1ae93e483284e189c84388de16
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 7 18:03:11 2019 +0100

    dma-mapping: drop the dev argument to arch_sync_dma_for_*
    
    These are pure cache maintainance routines, so drop the unused
    struct device argument.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Suggested-by: Daniel Vetter <daniel.vetter@ffwll.ch>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index e30fca1f1b12..ca9b5770caee 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -73,29 +73,29 @@ static inline void arch_dma_cache_sync(struct device *dev, void *vaddr,
 #endif /* CONFIG_DMA_NONCOHERENT_CACHE_SYNC */
 
 #ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE
-void arch_sync_dma_for_device(struct device *dev, phys_addr_t paddr,
-		size_t size, enum dma_data_direction dir);
+void arch_sync_dma_for_device(phys_addr_t paddr, size_t size,
+		enum dma_data_direction dir);
 #else
-static inline void arch_sync_dma_for_device(struct device *dev,
-		phys_addr_t paddr, size_t size, enum dma_data_direction dir)
+static inline void arch_sync_dma_for_device(phys_addr_t paddr, size_t size,
+		enum dma_data_direction dir)
 {
 }
 #endif /* ARCH_HAS_SYNC_DMA_FOR_DEVICE */
 
 #ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU
-void arch_sync_dma_for_cpu(struct device *dev, phys_addr_t paddr,
-		size_t size, enum dma_data_direction dir);
+void arch_sync_dma_for_cpu(phys_addr_t paddr, size_t size,
+		enum dma_data_direction dir);
 #else
-static inline void arch_sync_dma_for_cpu(struct device *dev,
-		phys_addr_t paddr, size_t size, enum dma_data_direction dir)
+static inline void arch_sync_dma_for_cpu(phys_addr_t paddr, size_t size,
+		enum dma_data_direction dir)
 {
 }
 #endif /* ARCH_HAS_SYNC_DMA_FOR_CPU */
 
 #ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL
-void arch_sync_dma_for_cpu_all(struct device *dev);
+void arch_sync_dma_for_cpu_all(void);
 #else
-static inline void arch_sync_dma_for_cpu_all(struct device *dev)
+static inline void arch_sync_dma_for_cpu_all(void)
 {
 }
 #endif /* CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL */

commit 34dc0ea6bc960f1f57b2148f01a3f4da23f87013
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Oct 29 11:01:37 2019 +0100

    dma-direct: provide mmap and get_sgtable method overrides
    
    For dma-direct we know that the DMA address is an encoding of the
    physical address that we can trivially decode.  Use that fact to
    provide implementations that do not need the arch_dma_coherent_to_pfn
    architecture hook.  Note that we still can only support mmap of
    non-coherent memory only if the architecture provides a way to set an
    uncached bit in the page tables.  This must be true for architectures
    that use the generic remap helpers, but other architectures can also
    manually select it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Max Filippov <jcmvbkbc@gmail.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index dd3de6d88fc0..e30fca1f1b12 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -41,8 +41,6 @@ void *arch_dma_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		gfp_t gfp, unsigned long attrs);
 void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,
 		dma_addr_t dma_addr, unsigned long attrs);
-long arch_dma_coherent_to_pfn(struct device *dev, void *cpu_addr,
-		dma_addr_t dma_addr);
 
 #ifdef CONFIG_MMU
 /*

commit 419e2f1838819e954071dfa1d1f820ab3386ada1
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Aug 26 09:03:44 2019 +0200

    dma-mapping: remove arch_dma_mmap_pgprot
    
    arch_dma_mmap_pgprot is used for two things:
    
     1) to override the "normal" uncached page attributes for mapping
        memory coherent to devices that can't snoop the CPU caches
     2) to provide the special DMA_ATTR_WRITE_COMBINE semantics on older
        arm systems and some mips platforms
    
    Replace one with the pgprot_dmacoherent macro that is already provided
    by arm and much simpler to use, and lift the DMA_ATTR_WRITE_COMBINE
    handling to common code with an explicit arch opt-in.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>     # m68k
    Acked-by: Paul Burton <paul.burton@mips.com>            # mips

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 0bff3d7fac92..dd3de6d88fc0 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -3,6 +3,7 @@
 #define _LINUX_DMA_NONCOHERENT_H 1
 
 #include <linux/dma-mapping.h>
+#include <asm/pgtable.h>
 
 #ifdef CONFIG_ARCH_HAS_DMA_COHERENCE_H
 #include <asm/dma-coherence.h>
@@ -42,10 +43,18 @@ void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,
 		dma_addr_t dma_addr, unsigned long attrs);
 long arch_dma_coherent_to_pfn(struct device *dev, void *cpu_addr,
 		dma_addr_t dma_addr);
-pgprot_t arch_dma_mmap_pgprot(struct device *dev, pgprot_t prot,
-		unsigned long attrs);
 
 #ifdef CONFIG_MMU
+/*
+ * Page protection so that devices that can't snoop CPU caches can use the
+ * memory coherently.  We default to pgprot_noncached which is usually used
+ * for ioremap as a safe bet, but architectures can override this with less
+ * strict semantics if possible.
+ */
+#ifndef pgprot_dmacoherent
+#define pgprot_dmacoherent(prot)	pgprot_noncached(prot)
+#endif
+
 pgprot_t dma_pgprot(struct device *dev, pgprot_t prot, unsigned long attrs);
 #else
 static inline pgprot_t dma_pgprot(struct device *dev, pgprot_t prot,

commit 33dcb37cef741294b481f4d889a465b8091f11bf
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jul 26 09:26:40 2019 +0200

    dma-mapping: fix page attributes for dma_mmap_*
    
    All the way back to introducing dma_common_mmap we've defaulted to mark
    the pages as uncached.  But this is wrong for DMA coherent devices.
    Later on DMA_ATTR_WRITE_COMBINE also got incorrect treatment as that
    flag is only treated special on the alloc side for non-coherent devices.
    
    Introduce a new dma_pgprot helper that deals with the check for coherent
    devices so that only the remapping cases ever reach arch_dma_mmap_pgprot
    and we thus ensure no aliasing of page attributes happens, which makes
    the powerpc version of arch_dma_mmap_pgprot obsolete and simplifies the
    remaining ones.
    
    Note that this means arch_dma_mmap_pgprot is a bit misnamed now, but
    we'll phase it out soon.
    
    Fixes: 64ccc9c033c6 ("common: dma-mapping: add support for generic dma_mmap_* calls")
    Reported-by: Shawn Anastasio <shawn@anastas.io>
    Reported-by: Gavin Li <git@thegavinli.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com> # arm64

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 3813211a9aad..0bff3d7fac92 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -42,13 +42,18 @@ void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,
 		dma_addr_t dma_addr, unsigned long attrs);
 long arch_dma_coherent_to_pfn(struct device *dev, void *cpu_addr,
 		dma_addr_t dma_addr);
-
-#ifdef CONFIG_ARCH_HAS_DMA_MMAP_PGPROT
 pgprot_t arch_dma_mmap_pgprot(struct device *dev, pgprot_t prot,
 		unsigned long attrs);
+
+#ifdef CONFIG_MMU
+pgprot_t dma_pgprot(struct device *dev, pgprot_t prot, unsigned long attrs);
 #else
-# define arch_dma_mmap_pgprot(dev, prot, attrs)	pgprot_noncached(prot)
-#endif
+static inline pgprot_t dma_pgprot(struct device *dev, pgprot_t prot,
+		unsigned long attrs)
+{
+	return prot;	/* no protection bits supported without page tables */
+}
+#endif /* CONFIG_MMU */
 
 #ifdef CONFIG_DMA_NONCOHERENT_CACHE_SYNC
 void arch_dma_cache_sync(struct device *dev, void *vaddr, size_t size,

commit 15ffe5e1acf5fe1512e98b20702e46ce9f25e2f7
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jul 8 12:55:27 2019 -0700

    dma-mapping: mark dma_alloc_need_uncached as __always_inline
    
    Without the __always_inline at least i386 configs that have
    CONFIG_OPTIMIZE_INLINING set seem fail to inline
    dma_alloc_need_uncached, leading to a linker error because of
    undefined symbols.
    
    Reported-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Randy Dunlap <rdunlap@infradead.org> # build-tested

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 53ee36ecdf37..3813211a9aad 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -23,7 +23,7 @@ static inline bool dev_is_dma_coherent(struct device *dev)
 /*
  * Check if an allocation needs to be marked uncached to be coherent.
  */
-static inline bool dma_alloc_need_uncached(struct device *dev,
+static __always_inline bool dma_alloc_need_uncached(struct device *dev,
 		unsigned long attrs)
 {
 	if (dev_is_dma_coherent(dev))

commit d98849aff87911013aadb730138ab728b52fc547
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 14 16:17:27 2019 +0200

    dma-direct: handle DMA_ATTR_NO_KERNEL_MAPPING in common code
    
    DMA_ATTR_NO_KERNEL_MAPPING is generally implemented by allocating
    normal cacheable pages or CMA memory, and then returning the page
    pointer as the opaque handle.  Lift that code from the xtensa and
    generic dma remapping implementations into the generic dma-direct
    code so that we don't even call arch_dma_alloc for these allocations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 732919ac5c11..53ee36ecdf37 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -28,6 +28,8 @@ static inline bool dma_alloc_need_uncached(struct device *dev,
 {
 	if (dev_is_dma_coherent(dev))
 		return false;
+	if (attrs & DMA_ATTR_NO_KERNEL_MAPPING)
+		return false;
 	if (IS_ENABLED(CONFIG_DMA_NONCOHERENT_CACHE_SYNC) &&
 	    (attrs & DMA_ATTR_NON_CONSISTENT))
 		return false;

commit 4b85faed211ccfbcc7f3adf1cd62f0b00d1a172b
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 14 16:06:10 2019 +0200

    dma-mapping: add a dma_alloc_need_uncached helper
    
    Check if we need to allocate uncached memory for a device given the
    allocation flags.  Switch over the uncached segment check to this helper
    to deal with architectures that do not support the dma_cache_sync
    operation and thus should not returned cacheable memory for
    DMA_ATTR_NON_CONSISTENT allocations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 7e0126a04e02..732919ac5c11 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -20,6 +20,20 @@ static inline bool dev_is_dma_coherent(struct device *dev)
 }
 #endif /* CONFIG_ARCH_HAS_DMA_COHERENCE_H */
 
+/*
+ * Check if an allocation needs to be marked uncached to be coherent.
+ */
+static inline bool dma_alloc_need_uncached(struct device *dev,
+		unsigned long attrs)
+{
+	if (dev_is_dma_coherent(dev))
+		return false;
+	if (IS_ENABLED(CONFIG_DMA_NONCOHERENT_CACHE_SYNC) &&
+	    (attrs & DMA_ATTR_NON_CONSISTENT))
+		return false;
+	return true;
+}
+
 void *arch_dma_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		gfp_t gfp, unsigned long attrs);
 void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,

commit c30700db9eaabb35e0b123301df35a6846e6b6b4
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 3 08:43:51 2019 +0200

    dma-direct: provide generic support for uncached kernel segments
    
    A few architectures support uncached kernel segments.  In that case we get
    an uncached mapping for a given physica address by using an offset in the
    uncached segement.  Implement support for this scheme in the generic
    dma-direct code instead of duplicating it in arch hooks.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 9741767e400f..7e0126a04e02 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -80,4 +80,7 @@ static inline void arch_dma_prep_coherent(struct page *page, size_t size)
 }
 #endif /* CONFIG_ARCH_HAS_DMA_PREP_COHERENT */
 
+void *uncached_kernel_address(void *addr);
+void *cached_kernel_address(void *addr);
+
 #endif /* _LINUX_DMA_NONCOHERENT_H */

commit 13bf5ced93775ffccb53527a9d862e023a9daa03
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Mar 25 15:44:06 2019 +0100

    dma-mapping: add a Kconfig symbol to indicate arch_dma_prep_coherent presence
    
    Add a Kconfig symbol that indicates an architecture provides a
    arch_dma_prep_coherent implementation, and provide a stub otherwise.
    
    This will allow the generic dma-iommu code to use it while still
    allowing to be built for cache coherent architectures.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 69b36ed31a99..9741767e400f 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -72,6 +72,12 @@ static inline void arch_sync_dma_for_cpu_all(struct device *dev)
 }
 #endif /* CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL */
 
+#ifdef CONFIG_ARCH_HAS_DMA_PREP_COHERENT
 void arch_dma_prep_coherent(struct page *page, size_t size);
+#else
+static inline void arch_dma_prep_coherent(struct page *page, size_t size)
+{
+}
+#endif /* CONFIG_ARCH_HAS_DMA_PREP_COHERENT */
 
 #endif /* _LINUX_DMA_NONCOHERENT_H */

commit 356da6d0cde3323236977fce54c1f9612a742036
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 6 13:39:32 2018 -0800

    dma-mapping: bypass indirect calls for dma-direct
    
    Avoid expensive indirect calls in the fast path DMA mapping
    operations by directly calling the dma_direct_* ops if we are using
    the directly mapped DMA operations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Tested-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Tested-by: Tony Luck <tony.luck@intel.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 306557331d7d..69b36ed31a99 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -38,7 +38,10 @@ pgprot_t arch_dma_mmap_pgprot(struct device *dev, pgprot_t prot,
 void arch_dma_cache_sync(struct device *dev, void *vaddr, size_t size,
 		enum dma_data_direction direction);
 #else
-#define arch_dma_cache_sync NULL
+static inline void arch_dma_cache_sync(struct device *dev, void *vaddr,
+		size_t size, enum dma_data_direction direction)
+{
+}
 #endif /* CONFIG_DMA_NONCOHERENT_CACHE_SYNC */
 
 #ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE

commit 0c3b3171ceccb8830c2bb5adff1b4e9b204c1450
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Nov 4 20:29:28 2018 +0100

    dma-mapping: move the arm64 noncoherent alloc/free support to common code
    
    The arm64 codebase to implement coherent dma allocation for architectures
    with non-coherent DMA is a good start for a generic implementation, given
    that is uses the generic remap helpers, provides the atomic pool for
    allocations that can't sleep and still is realtively simple and well
    tested.  Move it to kernel/dma and allow architectures to opt into it
    using a config symbol.  Architectures just need to provide a new
    arch_dma_prep_coherent helper to writeback an invalidate the caches
    for any memory that gets remapped for uncached access.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 9051b055beec..306557331d7d 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -69,4 +69,6 @@ static inline void arch_sync_dma_for_cpu_all(struct device *dev)
 }
 #endif /* CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL */
 
+void arch_dma_prep_coherent(struct page *page, size_t size);
+
 #endif /* _LINUX_DMA_NONCOHERENT_H */

commit 58b0440663ec11372befb8ead0ee7099d8878590
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Sep 11 08:55:28 2018 +0200

    dma-mapping: consolidate the dma mmap implementations
    
    The only functional differences (modulo a few missing fixes in the arch
    code) is that architectures without coherent caches need a hook to
    convert a virtual or dma address into a pfn, given that we don't have
    the kernel linear mapping available for the otherwise easy virt_to_page
    call.  As a side effect we can support mmap of the per-device coherent
    area even on architectures not providing the callback, and we make
    previous dangerous default methods dma_common_mmap actually save for
    non-coherent architectures by rejecting it without the right helper.
    
    In addition to that we need a hook so that some architectures can
    override the protection bits when mmaping a dma coherent allocations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Paul Burton <paul.burton@mips.com> # MIPS parts

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 3f503025a0cd..9051b055beec 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -24,9 +24,15 @@ void *arch_dma_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		gfp_t gfp, unsigned long attrs);
 void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,
 		dma_addr_t dma_addr, unsigned long attrs);
-int arch_dma_mmap(struct device *dev, struct vm_area_struct *vma,
-		void *cpu_addr, dma_addr_t dma_addr, size_t size,
+long arch_dma_coherent_to_pfn(struct device *dev, void *cpu_addr,
+		dma_addr_t dma_addr);
+
+#ifdef CONFIG_ARCH_HAS_DMA_MMAP_PGPROT
+pgprot_t arch_dma_mmap_pgprot(struct device *dev, pgprot_t prot,
 		unsigned long attrs);
+#else
+# define arch_dma_mmap_pgprot(dev, prot, attrs)	pgprot_noncached(prot)
+#endif
 
 #ifdef CONFIG_DMA_NONCOHERENT_CACHE_SYNC
 void arch_dma_cache_sync(struct device *dev, void *vaddr, size_t size,

commit bc3ec75de5452db59b683487867ba562b950708a
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Sep 8 11:22:43 2018 +0200

    dma-mapping: merge direct and noncoherent ops
    
    All the cache maintainance is already stubbed out when not enabled,
    but merging the two allows us to nicely handle the case where
    cache maintainance is required for some devices, but not others.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Paul Burton <paul.burton@mips.com> # MIPS parts

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index ce9732506ef4..3f503025a0cd 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -24,14 +24,9 @@ void *arch_dma_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		gfp_t gfp, unsigned long attrs);
 void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,
 		dma_addr_t dma_addr, unsigned long attrs);
-
-#ifdef CONFIG_DMA_NONCOHERENT_MMAP
 int arch_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		void *cpu_addr, dma_addr_t dma_addr, size_t size,
 		unsigned long attrs);
-#else
-#define arch_dma_mmap NULL
-#endif /* CONFIG_DMA_NONCOHERENT_MMAP */
 
 #ifdef CONFIG_DMA_NONCOHERENT_CACHE_SYNC
 void arch_dma_cache_sync(struct device *dev, void *vaddr, size_t size,

commit f3ecc0ff0457eae93503792c6fc35921fa8a6204
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Aug 19 14:53:20 2018 +0200

    dma-mapping: move the dma_coherent flag to struct device
    
    Various architectures support both coherent and non-coherent dma on a
    per-device basis.  Move the dma_noncoherent flag from the mips archdata
    field to struct device proper to prepare the infrastructure for reuse on
    other architectures.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Paul Burton <paul.burton@mips.com>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index a0aa00cc909d..ce9732506ef4 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -4,6 +4,22 @@
 
 #include <linux/dma-mapping.h>
 
+#ifdef CONFIG_ARCH_HAS_DMA_COHERENCE_H
+#include <asm/dma-coherence.h>
+#elif defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \
+	defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
+	defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)
+static inline bool dev_is_dma_coherent(struct device *dev)
+{
+	return dev->dma_coherent;
+}
+#else
+static inline bool dev_is_dma_coherent(struct device *dev)
+{
+	return true;
+}
+#endif /* CONFIG_ARCH_HAS_DMA_COHERENCE_H */
+
 void *arch_dma_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		gfp_t gfp, unsigned long attrs);
 void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,

commit faef87723ace12e5f685437c1e68cbecb69a7a89
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 15 13:08:51 2018 +0200

    dma-noncoherent: add a arch_sync_dma_for_cpu_all hook
    
    The MIPS bmips platform needs a global flush when transferring ownership
    back to the CPU.  Add a hook for that to the dma-noncoherent
    implementation.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Patchwork: https://patchwork.linux-mips.org/patch/19549/
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: Florian Fainelli <f.fainelli@gmail.com>
    Cc: David Daney <david.daney@cavium.com>
    Cc: Kevin Cernekee <cernekee@gmail.com>
    Cc: Jiaxun Yang <jiaxun.yang@flygoat.com>
    Cc: Tom Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Huacai Chen <chenhc@lemote.com>
    Cc: iommu@lists.linux-foundation.org
    Cc: linux-mips@linux-mips.org

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 10b2654d549b..a0aa00cc909d 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -44,4 +44,12 @@ static inline void arch_sync_dma_for_cpu(struct device *dev,
 }
 #endif /* ARCH_HAS_SYNC_DMA_FOR_CPU */
 
+#ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL
+void arch_sync_dma_for_cpu_all(struct device *dev);
+#else
+static inline void arch_sync_dma_for_cpu_all(struct device *dev)
+{
+}
+#endif /* CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL */
+
 #endif /* _LINUX_DMA_NONCOHERENT_H */

commit 782e6769c0df744e773dc2acff71c974b3bba4e9
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 16 15:24:51 2018 +0200

    dma-mapping: provide a generic dma-noncoherent implementation
    
    Add a new dma_map_ops implementation that uses dma-direct for the
    address mapping of streaming mappings, and which requires arch-specific
    implemenations of coherent allocate/free.
    
    Architectures have to provide flushing helpers to ownership trasnfers
    to the device and/or CPU, and can provide optional implementations of
    the coherent mmap functionality, and the cache_flush routines for
    non-coherent long term allocations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Alexey Brodkin <abrodkin@synopsys.com>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
new file mode 100644
index 000000000000..10b2654d549b
--- /dev/null
+++ b/include/linux/dma-noncoherent.h
@@ -0,0 +1,47 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _LINUX_DMA_NONCOHERENT_H
+#define _LINUX_DMA_NONCOHERENT_H 1
+
+#include <linux/dma-mapping.h>
+
+void *arch_dma_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle,
+		gfp_t gfp, unsigned long attrs);
+void arch_dma_free(struct device *dev, size_t size, void *cpu_addr,
+		dma_addr_t dma_addr, unsigned long attrs);
+
+#ifdef CONFIG_DMA_NONCOHERENT_MMAP
+int arch_dma_mmap(struct device *dev, struct vm_area_struct *vma,
+		void *cpu_addr, dma_addr_t dma_addr, size_t size,
+		unsigned long attrs);
+#else
+#define arch_dma_mmap NULL
+#endif /* CONFIG_DMA_NONCOHERENT_MMAP */
+
+#ifdef CONFIG_DMA_NONCOHERENT_CACHE_SYNC
+void arch_dma_cache_sync(struct device *dev, void *vaddr, size_t size,
+		enum dma_data_direction direction);
+#else
+#define arch_dma_cache_sync NULL
+#endif /* CONFIG_DMA_NONCOHERENT_CACHE_SYNC */
+
+#ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE
+void arch_sync_dma_for_device(struct device *dev, phys_addr_t paddr,
+		size_t size, enum dma_data_direction dir);
+#else
+static inline void arch_sync_dma_for_device(struct device *dev,
+		phys_addr_t paddr, size_t size, enum dma_data_direction dir)
+{
+}
+#endif /* ARCH_HAS_SYNC_DMA_FOR_DEVICE */
+
+#ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU
+void arch_sync_dma_for_cpu(struct device *dev, phys_addr_t paddr,
+		size_t size, enum dma_data_direction dir);
+#else
+static inline void arch_sync_dma_for_cpu(struct device *dev,
+		phys_addr_t paddr, size_t size, enum dma_data_direction dir)
+{
+}
+#endif /* ARCH_HAS_SYNC_DMA_FOR_CPU */
+
+#endif /* _LINUX_DMA_NONCOHERENT_H */
