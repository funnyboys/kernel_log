commit cfa6705d89b6562f79c40c249f8d94073c4276e4
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed May 27 22:11:14 2020 +0200

    radix-tree: Use local_lock for protection
    
    The radix-tree and idr preload mechanisms use preempt_disable() to protect
    the complete operation between xxx_preload() and xxx_preload_end().
    
    As the code inside the preempt disabled section acquires regular spinlocks,
    which are converted to 'sleeping' spinlocks on a PREEMPT_RT kernel and
    eventually calls into a memory allocator, this conflicts with the RT
    semantics.
    
    Convert it to a local_lock which allows RT kernels to substitute them with
    a real per CPU lock. On non RT kernels this maps to preempt_disable() as
    before, but provides also lockdep coverage of the critical region.
    No functional change.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20200527201119.1692513-3-bigeasy@linutronix.de

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 63e62372443a..c2a9f7c90727 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -16,11 +16,20 @@
 #include <linux/spinlock.h>
 #include <linux/types.h>
 #include <linux/xarray.h>
+#include <linux/local_lock.h>
 
 /* Keep unconverted code working */
 #define radix_tree_root		xarray
 #define radix_tree_node		xa_node
 
+struct radix_tree_preload {
+	local_lock_t lock;
+	unsigned nr;
+	/* nodes->parent points to next preallocated node */
+	struct radix_tree_node *nodes;
+};
+DECLARE_PER_CPU(struct radix_tree_preload, radix_tree_preloads);
+
 /*
  * The bottom two bits of the slot determine how the remaining bits in the
  * slot are interpreted:
@@ -245,7 +254,7 @@ int radix_tree_tagged(const struct radix_tree_root *, unsigned int tag);
 
 static inline void radix_tree_preload_end(void)
 {
-	preempt_enable();
+	local_unlock(&radix_tree_preloads.lock);
 }
 
 void __rcu **idr_get_free(struct radix_tree_root *root,

commit 797060ec427c83ce4a64a0278a1e6077dfed683a
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Fri Nov 1 22:21:54 2019 -0400

    radix tree: Remove radix_tree_iter_find
    
    This API is unsafe to use under the RCU lock.  With no in-tree users
    remaining, remove it to prevent future bugs.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index b5116013f27e..63e62372443a 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -315,24 +315,6 @@ radix_tree_iter_lookup(const struct radix_tree_root *root,
 	return radix_tree_next_chunk(root, iter, RADIX_TREE_ITER_CONTIG);
 }
 
-/**
- * radix_tree_iter_find - find a present entry
- * @root: radix tree root
- * @iter: iterator state
- * @index: start location
- *
- * This function returns the slot containing the entry with the lowest index
- * which is at least @index.  If @index is larger than any present entry, this
- * function returns NULL.  The @iter is updated to describe the entry found.
- */
-static inline void __rcu **
-radix_tree_iter_find(const struct radix_tree_root *root,
-			struct radix_tree_iter *iter, unsigned long index)
-{
-	radix_tree_iter_init(iter, index);
-	return radix_tree_next_chunk(root, iter, 0);
-}
-
 /**
  * radix_tree_iter_retry - retry this chunk of the iteration
  * @iter:	iterator state

commit de6cc6515a445d5d81cad2dee899a0be1a6317f8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:02 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 153
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 or at your option any
      later version this program is distributed in the hope that it will
      be useful but without any warranty without even the implied warranty
      of merchantability or fitness for a particular purpose see the gnu
      general public license for more details you should have received a
      copy of the gnu general public license along with this program if
      not write to the free software foundation inc 675 mass ave cambridge
      ma 02139 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 77 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Armijn Hemel <armijn@tjaldur.nl>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.837555891@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 06c4c7a6c09c..b5116013f27e 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -1,22 +1,9 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Copyright (C) 2001 Momchil Velikov
  * Portions Copyright (C) 2001 Christoph Hellwig
  * Copyright (C) 2006 Nick Piggin
  * Copyright (C) 2012 Konstantin Khlebnikov
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2, or (at
- * your option) any later version.
- * 
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- * 
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 #ifndef _LINUX_RADIX_TREE_H
 #define _LINUX_RADIX_TREE_H

commit 3a08cd52c37c793ffc199f6fc2ecfc368e284b2d
Author: Matthew Wilcox <willy@infradead.org>
Date:   Sat Sep 22 16:14:30 2018 -0400

    radix tree: Remove multiorder support
    
    All users have now been converted to the XArray.  Removing the support
    reduces code size and ensures new users will use the XArray instead.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 9a1460488163..06c4c7a6c09c 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -96,7 +96,6 @@ static inline bool radix_tree_empty(const struct radix_tree_root *root)
  * @next_index:	one beyond the last index for this chunk
  * @tags:	bit-mask for tag-iterating
  * @node:	node that contains current slot
- * @shift:	shift for the node that holds our slots
  *
  * This radix tree iterator works in terms of "chunks" of slots.  A chunk is a
  * subinterval of slots contained within one radix tree leaf node.  It is
@@ -110,20 +109,8 @@ struct radix_tree_iter {
 	unsigned long	next_index;
 	unsigned long	tags;
 	struct radix_tree_node *node;
-#ifdef CONFIG_RADIX_TREE_MULTIORDER
-	unsigned int	shift;
-#endif
 };
 
-static inline unsigned int iter_shift(const struct radix_tree_iter *iter)
-{
-#ifdef CONFIG_RADIX_TREE_MULTIORDER
-	return iter->shift;
-#else
-	return 0;
-#endif
-}
-
 /**
  * Radix-tree synchronization
  *
@@ -230,13 +217,8 @@ static inline int radix_tree_exception(void *arg)
 	return unlikely((unsigned long)arg & RADIX_TREE_ENTRY_MASK);
 }
 
-int __radix_tree_insert(struct radix_tree_root *, unsigned long index,
-			unsigned order, void *);
-static inline int radix_tree_insert(struct radix_tree_root *root,
-			unsigned long index, void *entry)
-{
-	return __radix_tree_insert(root, index, 0, entry);
-}
+int radix_tree_insert(struct radix_tree_root *, unsigned long index,
+			void *);
 void *__radix_tree_lookup(const struct radix_tree_root *, unsigned long index,
 			  struct radix_tree_node **nodep, void __rcu ***slotp);
 void *radix_tree_lookup(const struct radix_tree_root *, unsigned long);
@@ -384,7 +366,7 @@ void __rcu **radix_tree_iter_retry(struct radix_tree_iter *iter)
 static inline unsigned long
 __radix_tree_iter_add(struct radix_tree_iter *iter, unsigned long slots)
 {
-	return iter->index + (slots << iter_shift(iter));
+	return iter->index + slots;
 }
 
 /**
@@ -409,20 +391,8 @@ void __rcu **__must_check radix_tree_iter_resume(void __rcu **slot,
 static __always_inline long
 radix_tree_chunk_size(struct radix_tree_iter *iter)
 {
-	return (iter->next_index - iter->index) >> iter_shift(iter);
-}
-
-#ifdef CONFIG_RADIX_TREE_MULTIORDER
-void __rcu **__radix_tree_next_slot(void __rcu **slot,
-				struct radix_tree_iter *iter, unsigned flags);
-#else
-/* Can't happen without sibling entries, but the compiler can't tell that */
-static inline void __rcu **__radix_tree_next_slot(void __rcu **slot,
-				struct radix_tree_iter *iter, unsigned flags)
-{
-	return slot;
+	return iter->next_index - iter->index;
 }
-#endif
 
 /**
  * radix_tree_next_slot - find next slot in chunk
@@ -482,8 +452,6 @@ static __always_inline void __rcu **radix_tree_next_slot(void __rcu **slot,
 	return NULL;
 
  found:
-	if (unlikely(radix_tree_is_internal_node(rcu_dereference_raw(*slot))))
-		return __radix_tree_next_slot(slot, iter, flags);
 	return slot;
 }
 

commit 372266ba0267803564824b1c09f1bb7f3f3fc761
Author: Matthew Wilcox <willy@infradead.org>
Date:   Sat Aug 18 07:09:22 2018 -0400

    radix tree test suite: Convert tag_tagged_items to XArray
    
    The tag_tagged_items() function is supposed to test the page-writeback
    tagging code.  Since that has been converted to the XArray, there's
    not much point in testing the radix tree's tagging code.  This requires
    using the pthread mutex embedded in the xarray instead of an external
    lock, so remove the pthread mutexes which protect xarrays/radix trees.
    Also remove radix_tree_iter_tag_set() as this was the last user.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 7b009af3bb1e..9a1460488163 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -264,8 +264,6 @@ void *radix_tree_tag_clear(struct radix_tree_root *,
 			unsigned long index, unsigned int tag);
 int radix_tree_tag_get(const struct radix_tree_root *,
 			unsigned long index, unsigned int tag);
-void radix_tree_iter_tag_set(struct radix_tree_root *,
-		const struct radix_tree_iter *iter, unsigned int tag);
 void radix_tree_iter_tag_clear(struct radix_tree_root *,
 		const struct radix_tree_iter *iter, unsigned int tag);
 unsigned int radix_tree_gang_lookup_tag(const struct radix_tree_root *,

commit adb9d9c4ccb1ff0bf1d376e65f36aa5573c75c1a
Author: Matthew Wilcox <willy@infradead.org>
Date:   Mon Apr 9 16:52:21 2018 -0400

    radix tree: Remove radix_tree_clear_tags
    
    The page cache was the only user of this interface and it has now
    been converted to the XArray.  Transform the test into a test of
    xas_init_marks().
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 664d50c5c2ff..7b009af3bb1e 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -252,8 +252,6 @@ void radix_tree_iter_delete(struct radix_tree_root *,
 			struct radix_tree_iter *iter, void __rcu **slot);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
-void radix_tree_clear_tags(struct radix_tree_root *, struct radix_tree_node *,
-			   void __rcu **slot);
 unsigned int radix_tree_gang_lookup(const struct radix_tree_root *,
 			void **results, unsigned long first_index,
 			unsigned int max_items);

commit 8cf2f98411e3a0865026a1061af637161b16d32b
Author: Matthew Wilcox <willy@infradead.org>
Date:   Sat May 19 16:47:47 2018 -0400

    radix tree: Remove radix_tree_maybe_preload_order
    
    This function was only used by the page cache which is now converted
    to the XArray.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 44f9abdcb5ab..664d50c5c2ff 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -259,7 +259,6 @@ unsigned int radix_tree_gang_lookup(const struct radix_tree_root *,
 			unsigned int max_items);
 int radix_tree_preload(gfp_t gfp_mask);
 int radix_tree_maybe_preload(gfp_t gfp_mask);
-int radix_tree_maybe_preload_order(gfp_t gfp_mask, int order);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *,
 			unsigned long index, unsigned int tag);

commit 2956c6644bfd9aab9f6b21a12e1bd75876d9dd73
Author: Matthew Wilcox <willy@infradead.org>
Date:   Sat May 19 16:47:47 2018 -0400

    radix tree: Remove split/join code
    
    radix_tree_split and radix_tree_join were never used upstream.  Remove
    them; if they're needed in future they will be replaced by XArray
    equivalents.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 7513d0df984b..44f9abdcb5ab 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -284,12 +284,6 @@ static inline void radix_tree_preload_end(void)
 	preempt_enable();
 }
 
-int radix_tree_split_preload(unsigned old_order, unsigned new_order, gfp_t);
-int radix_tree_split(struct radix_tree_root *, unsigned long index,
-			unsigned new_order);
-int radix_tree_join(struct radix_tree_root *, unsigned long index,
-			unsigned new_order, void *);
-
 void __rcu **idr_get_free(struct radix_tree_root *root,
 			      struct radix_tree_iter *iter, gfp_t gfp,
 			      unsigned long max);

commit 1cf56f9d670b88b2e947a7ccdb8ba32e6477915d
Author: Matthew Wilcox <willy@infradead.org>
Date:   Mon Apr 9 16:24:45 2018 -0400

    radix tree: Remove radix_tree_update_node_t
    
    The only user of this functionality was the workingset code, and it's
    now been converted to the XArray.  Remove __radix_tree_delete_node()
    entirely as it was also only used by the workingset code.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 8a4280bc350f..7513d0df984b 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -242,17 +242,12 @@ void *__radix_tree_lookup(const struct radix_tree_root *, unsigned long index,
 void *radix_tree_lookup(const struct radix_tree_root *, unsigned long);
 void __rcu **radix_tree_lookup_slot(const struct radix_tree_root *,
 					unsigned long index);
-typedef void (*radix_tree_update_node_t)(struct radix_tree_node *);
 void __radix_tree_replace(struct radix_tree_root *, struct radix_tree_node *,
-			  void __rcu **slot, void *entry,
-			  radix_tree_update_node_t update_node);
+			  void __rcu **slot, void *entry);
 void radix_tree_iter_replace(struct radix_tree_root *,
 		const struct radix_tree_iter *, void __rcu **slot, void *entry);
 void radix_tree_replace_slot(struct radix_tree_root *,
 			     void __rcu **slot, void *entry);
-void __radix_tree_delete_node(struct radix_tree_root *,
-			      struct radix_tree_node *,
-			      radix_tree_update_node_t update_node);
 void radix_tree_iter_delete(struct radix_tree_root *,
 			struct radix_tree_iter *iter, void __rcu **slot);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);

commit 7b8d046fba91d62beb8a8f78244aaa3c23a60cdd
Author: Matthew Wilcox <willy@infradead.org>
Date:   Fri Dec 1 22:13:06 2017 -0500

    shmem: Convert shmem_alloc_hugepage to XArray
    
    xa_find() is a slightly easier API to use than
    radix_tree_gang_lookup_slot() because it contains its own RCU locking.
    This commit removes the last user of radix_tree_gang_lookup_slot()
    so remove the function too.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 023e888e1163..8a4280bc350f 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -147,12 +147,11 @@ static inline unsigned int iter_shift(const struct radix_tree_iter *iter)
  * radix_tree_lookup_slot
  * radix_tree_tag_get
  * radix_tree_gang_lookup
- * radix_tree_gang_lookup_slot
  * radix_tree_gang_lookup_tag
  * radix_tree_gang_lookup_tag_slot
  * radix_tree_tagged
  *
- * The first 8 functions are able to be called locklessly, using RCU. The
+ * The first 7 functions are able to be called locklessly, using RCU. The
  * caller must ensure calls to these functions are made within rcu_read_lock()
  * regions. Other readers (lock-free or otherwise) and modifications may be
  * running concurrently.
@@ -263,9 +262,6 @@ void radix_tree_clear_tags(struct radix_tree_root *, struct radix_tree_node *,
 unsigned int radix_tree_gang_lookup(const struct radix_tree_root *,
 			void **results, unsigned long first_index,
 			unsigned int max_items);
-unsigned int radix_tree_gang_lookup_slot(const struct radix_tree_root *,
-			void __rcu ***results, unsigned long *indices,
-			unsigned long first_index, unsigned int max_items);
 int radix_tree_preload(gfp_t gfp_mask);
 int radix_tree_maybe_preload(gfp_t gfp_mask);
 int radix_tree_maybe_preload_order(gfp_t gfp_mask, int order);

commit 3ece58a270cd1e5026282abe778bd50db7a11d08
Author: Matthew Wilcox <willy@infradead.org>
Date:   Wed May 16 18:00:33 2018 -0400

    page cache: Convert find_get_pages_contig to XArray
    
    There's no direct replacement for radix_tree_for_each_contig()
    in the XArray API as it's an unusual thing to do.  Instead,
    open-code a loop using xas_next().  This removes the only user of
    radix_tree_for_each_contig() so delete the iterator from the API and
    the test suite code for it.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index d55de428a589..023e888e1163 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -522,23 +522,6 @@ static __always_inline void __rcu **radix_tree_next_slot(void __rcu **slot,
 	     slot || (slot = radix_tree_next_chunk(root, iter, 0)) ;	\
 	     slot = radix_tree_next_slot(slot, iter, 0))
 
-/**
- * radix_tree_for_each_contig - iterate over contiguous slots
- *
- * @slot:	the void** variable for pointer to slot
- * @root:	the struct radix_tree_root pointer
- * @iter:	the struct radix_tree_iter pointer
- * @start:	iteration starting index
- *
- * @slot points to radix tree slot, @iter->index contains its index.
- */
-#define radix_tree_for_each_contig(slot, root, iter, start)		\
-	for (slot = radix_tree_iter_init(iter, start) ;			\
-	     slot || (slot = radix_tree_next_chunk(root, iter,		\
-				RADIX_TREE_ITER_CONTIG)) ;		\
-	     slot = radix_tree_next_slot(slot, iter,			\
-				RADIX_TREE_ITER_CONTIG))
-
 /**
  * radix_tree_for_each_tagged - iterate over tagged slots
  *

commit 74d609585d8bd6083bd9d75bc1fd2c0d3851bcc5
Author: Matthew Wilcox <willy@infradead.org>
Date:   Fri Nov 17 10:01:45 2017 -0500

    page cache: Add and replace pages using the XArray
    
    Use the XArray APIs to add and replace pages in the page cache.  This
    removes two uses of the radix tree preload API and is significantly
    shorter code.  It also removes the last user of __radix_tree_create()
    outside radix-tree.c itself, so make it static.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 15388b7e38b9..d55de428a589 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -231,9 +231,6 @@ static inline int radix_tree_exception(void *arg)
 	return unlikely((unsigned long)arg & RADIX_TREE_ENTRY_MASK);
 }
 
-int __radix_tree_create(struct radix_tree_root *, unsigned long index,
-			unsigned order, struct radix_tree_node **nodep,
-			void __rcu ***slotp);
 int __radix_tree_insert(struct radix_tree_root *, unsigned long index,
 			unsigned order, void *);
 static inline int radix_tree_insert(struct radix_tree_root *root,

commit 01959dfe771c6893365482ec78dc1d9cbbbe6de8
Author: Matthew Wilcox <willy@infradead.org>
Date:   Thu Nov 9 09:23:56 2017 -0500

    xarray: Define struct xa_node
    
    This is a direct replacement for struct radix_tree_node.  A couple of
    struct members have changed name, so convert those.  Use a #define so
    that radix tree users continue to work without change.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 0b080bd88ab7..15388b7e38b9 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -32,6 +32,7 @@
 
 /* Keep unconverted code working */
 #define radix_tree_root		xarray
+#define radix_tree_node		xa_node
 
 /*
  * The bottom two bits of the slot determine how the remaining bits in the
@@ -60,41 +61,17 @@ static inline bool radix_tree_is_internal_node(void *ptr)
 
 /*** radix-tree API starts here ***/
 
-#define RADIX_TREE_MAX_TAGS 3
-
 #define RADIX_TREE_MAP_SHIFT	XA_CHUNK_SHIFT
 #define RADIX_TREE_MAP_SIZE	(1UL << RADIX_TREE_MAP_SHIFT)
 #define RADIX_TREE_MAP_MASK	(RADIX_TREE_MAP_SIZE-1)
 
-#define RADIX_TREE_TAG_LONGS	\
-	((RADIX_TREE_MAP_SIZE + BITS_PER_LONG - 1) / BITS_PER_LONG)
+#define RADIX_TREE_MAX_TAGS	XA_MAX_MARKS
+#define RADIX_TREE_TAG_LONGS	XA_MARK_LONGS
 
 #define RADIX_TREE_INDEX_BITS  (8 /* CHAR_BIT */ * sizeof(unsigned long))
 #define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \
 					  RADIX_TREE_MAP_SHIFT))
 
-/*
- * @count is the count of every non-NULL element in the ->slots array
- * whether that is a value entry, a retry entry, a user pointer,
- * a sibling entry or a pointer to the next level of the tree.
- * @exceptional is the count of every element in ->slots which is
- * either a value entry or a sibling of a value entry.
- */
-struct radix_tree_node {
-	unsigned char	shift;		/* Bits remaining in each slot */
-	unsigned char	offset;		/* Slot offset in parent */
-	unsigned char	count;		/* Total entry count */
-	unsigned char	exceptional;	/* Exceptional entry count */
-	struct radix_tree_node *parent;		/* Used when ascending tree */
-	struct radix_tree_root *root;		/* The tree we belong to */
-	union {
-		struct list_head private_list;	/* For tree user */
-		struct rcu_head	rcu_head;	/* Used when freeing node */
-	};
-	void __rcu	*slots[RADIX_TREE_MAP_SIZE];
-	unsigned long	tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];
-};
-
 /* The IDR tag is stored in the low bits of xa_flags */
 #define ROOT_IS_IDR	((__force gfp_t)4)
 /* The top bits of xa_flags are used to store the root tags */

commit f8d5d0cc145cc21bfc56ef807dc28102aebbf228
Author: Matthew Wilcox <willy@infradead.org>
Date:   Tue Nov 7 16:30:10 2017 -0500

    xarray: Add definition of struct xarray
    
    This is a direct replacement for struct radix_tree_root.  Some of the
    struct members have changed name; convert those, and use a #define so
    that radix_tree users continue to work without change.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 60f3d8eb2cb7..0b080bd88ab7 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -30,6 +30,9 @@
 #include <linux/types.h>
 #include <linux/xarray.h>
 
+/* Keep unconverted code working */
+#define radix_tree_root		xarray
+
 /*
  * The bottom two bits of the slot determine how the remaining bits in the
  * slot are interpreted:
@@ -92,36 +95,21 @@ struct radix_tree_node {
 	unsigned long	tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];
 };
 
-/* The IDR tag is stored in the low bits of the GFP flags */
+/* The IDR tag is stored in the low bits of xa_flags */
 #define ROOT_IS_IDR	((__force gfp_t)4)
-/* The top bits of gfp_mask are used to store the root tags */
+/* The top bits of xa_flags are used to store the root tags */
 #define ROOT_TAG_SHIFT	(__GFP_BITS_SHIFT)
 
-struct radix_tree_root {
-	spinlock_t		xa_lock;
-	gfp_t			gfp_mask;
-	struct radix_tree_node	__rcu *rnode;
-};
-
-#define RADIX_TREE_INIT(name, mask)	{				\
-	.xa_lock = __SPIN_LOCK_UNLOCKED(name.xa_lock),			\
-	.gfp_mask = (mask),						\
-	.rnode = NULL,							\
-}
+#define RADIX_TREE_INIT(name, mask)	XARRAY_INIT(name, mask)
 
 #define RADIX_TREE(name, mask) \
 	struct radix_tree_root name = RADIX_TREE_INIT(name, mask)
 
-#define INIT_RADIX_TREE(root, mask)					\
-do {									\
-	spin_lock_init(&(root)->xa_lock);				\
-	(root)->gfp_mask = (mask);					\
-	(root)->rnode = NULL;						\
-} while (0)
+#define INIT_RADIX_TREE(root, mask) xa_init_flags(root, mask)
 
 static inline bool radix_tree_empty(const struct radix_tree_root *root)
 {
-	return root->rnode == NULL;
+	return root->xa_head == NULL;
 }
 
 /**

commit 02c02bf12c5d838603eed44195d3e91f094e2ab2
Author: Matthew Wilcox <willy@infradead.org>
Date:   Fri Nov 3 23:09:45 2017 -0400

    xarray: Change definition of sibling entries
    
    Instead of storing a pointer to the slot containing the canonical entry,
    store the offset of the slot.  Produces slightly more efficient code
    (~300 bytes) and simplifies the implementation.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index e9e76ab4fbbf..60f3d8eb2cb7 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -59,10 +59,7 @@ static inline bool radix_tree_is_internal_node(void *ptr)
 
 #define RADIX_TREE_MAX_TAGS 3
 
-#ifndef RADIX_TREE_MAP_SHIFT
-#define RADIX_TREE_MAP_SHIFT	(CONFIG_BASE_SMALL ? 4 : 6)
-#endif
-
+#define RADIX_TREE_MAP_SHIFT	XA_CHUNK_SHIFT
 #define RADIX_TREE_MAP_SIZE	(1UL << RADIX_TREE_MAP_SHIFT)
 #define RADIX_TREE_MAP_MASK	(RADIX_TREE_MAP_SIZE-1)
 

commit 3159f943aafdbacb2f94c38fdaadabf2bbde2a14
Author: Matthew Wilcox <willy@infradead.org>
Date:   Fri Nov 3 13:30:42 2017 -0400

    xarray: Replace exceptional entries
    
    Introduce xarray value entries and tagged pointers to replace radix
    tree exceptional entries.  This is a slight change in encoding to allow
    the use of an extra bit (we can now store BITS_PER_LONG - 1 bits in a
    value entry).  It is also a change in emphasis; exceptional entries are
    intimidating and different.  As the comment explains, you can choose
    to store values or pointers in the xarray and they are both first-class
    citizens.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 34149e8b5f73..e9e76ab4fbbf 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -28,34 +28,26 @@
 #include <linux/rcupdate.h>
 #include <linux/spinlock.h>
 #include <linux/types.h>
+#include <linux/xarray.h>
 
 /*
  * The bottom two bits of the slot determine how the remaining bits in the
  * slot are interpreted:
  *
  * 00 - data pointer
- * 01 - internal entry
- * 10 - exceptional entry
- * 11 - this bit combination is currently unused/reserved
+ * 10 - internal entry
+ * x1 - value entry
  *
  * The internal entry may be a pointer to the next level in the tree, a
  * sibling entry, or an indicator that the entry in this slot has been moved
  * to another location in the tree and the lookup should be restarted.  While
  * NULL fits the 'data pointer' pattern, it means that there is no entry in
  * the tree for this index (no matter what level of the tree it is found at).
- * This means that you cannot store NULL in the tree as a value for the index.
+ * This means that storing a NULL entry in the tree is the same as deleting
+ * the entry from the tree.
  */
 #define RADIX_TREE_ENTRY_MASK		3UL
-#define RADIX_TREE_INTERNAL_NODE	1UL
-
-/*
- * Most users of the radix tree store pointers but shmem/tmpfs stores swap
- * entries in the same tree.  They are marked as exceptional entries to
- * distinguish them from pointers to struct page.
- * EXCEPTIONAL_ENTRY tests the bit, EXCEPTIONAL_SHIFT shifts content past it.
- */
-#define RADIX_TREE_EXCEPTIONAL_ENTRY	2
-#define RADIX_TREE_EXCEPTIONAL_SHIFT	2
+#define RADIX_TREE_INTERNAL_NODE	2UL
 
 static inline bool radix_tree_is_internal_node(void *ptr)
 {
@@ -83,11 +75,10 @@ static inline bool radix_tree_is_internal_node(void *ptr)
 
 /*
  * @count is the count of every non-NULL element in the ->slots array
- * whether that is an exceptional entry, a retry entry, a user pointer,
+ * whether that is a value entry, a retry entry, a user pointer,
  * a sibling entry or a pointer to the next level of the tree.
  * @exceptional is the count of every element in ->slots which is
- * either radix_tree_exceptional_entry() or is a sibling entry for an
- * exceptional entry.
+ * either a value entry or a sibling of a value entry.
  */
 struct radix_tree_node {
 	unsigned char	shift;		/* Bits remaining in each slot */
@@ -268,17 +259,6 @@ static inline int radix_tree_deref_retry(void *arg)
 	return unlikely(radix_tree_is_internal_node(arg));
 }
 
-/**
- * radix_tree_exceptional_entry	- radix_tree_deref_slot gave exceptional entry?
- * @arg:	value returned by radix_tree_deref_slot
- * Returns:	0 if well-aligned pointer, non-0 if exceptional entry.
- */
-static inline int radix_tree_exceptional_entry(void *arg)
-{
-	/* Not unlikely because radix_tree_exception often tested first */
-	return (unsigned long)arg & RADIX_TREE_EXCEPTIONAL_ENTRY;
-}
-
 /**
  * radix_tree_exception	- radix_tree_deref_slot returned either exception?
  * @arg:	value returned by radix_tree_deref_slot

commit f6bb2a2c0b81c47282ddb7883f92e65a063c27dd
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Tue Apr 10 16:36:52 2018 -0700

    xarray: add the xa_lock to the radix_tree_root
    
    This results in no change in structure size on 64-bit machines as it
    fits in the padding between the gfp_t and the void *.  32-bit machines
    will grow the structure from 8 to 12 bytes.  Almost all radix trees are
    protected with (at least) a spinlock, so as they are converted from
    radix trees to xarrays, the data structures will shrink again.
    
    Initialising the spinlock requires a name for the benefit of lockdep, so
    RADIX_TREE_INIT() now needs to know the name of the radix tree it's
    initialising, and so do IDR_INIT() and IDA_INIT().
    
    Also add the xa_lock() and xa_unlock() family of wrappers to make it
    easier to use the lock.  If we could rely on -fplan9-extensions in the
    compiler, we could avoid all of this syntactic sugar, but that wasn't
    added until gcc 4.6.
    
    Link: http://lkml.kernel.org/r/20180313132639.17387-8-willy@infradead.org
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Reviewed-by: Jeff Layton <jlayton@kernel.org>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 6c4e2e716dac..34149e8b5f73 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -110,20 +110,23 @@ struct radix_tree_node {
 #define ROOT_TAG_SHIFT	(__GFP_BITS_SHIFT)
 
 struct radix_tree_root {
+	spinlock_t		xa_lock;
 	gfp_t			gfp_mask;
 	struct radix_tree_node	__rcu *rnode;
 };
 
-#define RADIX_TREE_INIT(mask)	{					\
+#define RADIX_TREE_INIT(name, mask)	{				\
+	.xa_lock = __SPIN_LOCK_UNLOCKED(name.xa_lock),			\
 	.gfp_mask = (mask),						\
 	.rnode = NULL,							\
 }
 
 #define RADIX_TREE(name, mask) \
-	struct radix_tree_root name = RADIX_TREE_INIT(mask)
+	struct radix_tree_root name = RADIX_TREE_INIT(name, mask)
 
 #define INIT_RADIX_TREE(root, mask)					\
 do {									\
+	spin_lock_init(&(root)->xa_lock);				\
 	(root)->gfp_mask = (mask);					\
 	(root)->rnode = NULL;						\
 } while (0)

commit fa290cda102c096f5ca394277d65d3dbd689930b
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Tue Apr 10 16:36:28 2018 -0700

    radix tree: use GFP_ZONEMASK bits of gfp_t for flags
    
    Patch series "XArray", v9.  (First part thereof).
    
    This patchset is, I believe, appropriate for merging for 4.17.  It
    contains the XArray implementation, to eventually replace the radix
    tree, and converts the page cache to use it.
    
    This conversion keeps the radix tree and XArray data structures in sync
    at all times.  That allows us to convert the page cache one function at
    a time and should allow for easier bisection.  Other than renaming some
    elements of the structures, the data structures are fundamentally
    unchanged; a radix tree walk and an XArray walk will touch the same
    number of cachelines.  I have changes planned to the XArray data
    structure, but those will happen in future patches.
    
    Improvements the XArray has over the radix tree:
    
     - The radix tree provides operations like other trees do; 'insert' and
       'delete'. But what most users really want is an automatically
       resizing array, and so it makes more sense to give users an API that
       is like an array -- 'load' and 'store'. We still have an 'insert'
       operation for users that really want that semantic.
    
     - The XArray considers locking as part of its API. This simplifies a
       lot of users who formerly had to manage their own locking just for
       the radix tree. It also improves code generation as we can now tell
       RCU that we're holding a lock and it doesn't need to generate as much
       fencing code. The other advantage is that tree nodes can be moved
       (not yet implemented).
    
     - GFP flags are now parameters to calls which may need to allocate
       memory. The radix tree forced users to decide what the allocation
       flags would be at creation time. It's much clearer to specify them at
       allocation time.
    
     - Memory is not preloaded; we don't tie up dozens of pages on the off
       chance that the slab allocator fails. Instead, we drop the lock,
       allocate a new node and retry the operation. We have to convert all
       the radix tree, IDA and IDR preload users before we can realise this
       benefit, but I have not yet found a user which cannot be converted.
    
     - The XArray provides a cmpxchg operation. The radix tree forces users
       to roll their own (and at least four have).
    
     - Iterators take a 'max' parameter. That simplifies many users and will
       reduce the amount of iteration done.
    
     - Iteration can proceed backwards. We only have one user for this, but
       since it's called as part of the pagefault readahead algorithm, that
       seemed worth mentioning.
    
     - RCU-protected pointers are not exposed as part of the API. There are
       some fun bugs where the page cache forgets to use rcu_dereference()
       in the current codebase.
    
     - Value entries gain an extra bit compared to radix tree exceptional
       entries. That gives us the extra bit we need to put huge page swap
       entries in the page cache.
    
     - Some iterators now take a 'filter' argument instead of having
       separate iterators for tagged/untagged iterations.
    
    The page cache is improved by this:
    
     - Shorter, easier to read code
    
     - More efficient iterations
    
     - Reduction in size of struct address_space
    
     - Fewer walks from the top of the data structure; the XArray API
       encourages staying at the leaf node and conducting operations there.
    
    This patch (of 8):
    
    None of these bits may be used for slab allocations, so we can use them
    as radix tree flags as long as we mask them off before passing them to
    the slab allocator. Move the IDR flag from the high bits to the
    GFP_ZONEMASK bits.
    
    Link: http://lkml.kernel.org/r/20180313132639.17387-3-willy@infradead.org
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Acked-by: Jeff Layton <jlayton@kernel.org>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index fc55ff31eca7..6c4e2e716dac 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -104,9 +104,10 @@ struct radix_tree_node {
 	unsigned long	tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];
 };
 
-/* The top bits of gfp_mask are used to store the root tags and the IDR flag */
-#define ROOT_IS_IDR	((__force gfp_t)(1 << __GFP_BITS_SHIFT))
-#define ROOT_TAG_SHIFT	(__GFP_BITS_SHIFT + 1)
+/* The IDR tag is stored in the low bits of the GFP flags */
+#define ROOT_IS_IDR	((__force gfp_t)4)
+/* The top bits of gfp_mask are used to store the root tags */
+#define ROOT_TAG_SHIFT	(__GFP_BITS_SHIFT)
 
 struct radix_tree_root {
 	gfp_t			gfp_mask;

commit 460488c58ca8b9167463ac22ec9a2e33db351962
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Tue Nov 28 15:16:24 2017 -0500

    idr: Remove idr_alloc_ext
    
    It has no more users, so remove it.  Move idr_alloc() back into idr.c,
    move the guts of idr_alloc_cmn() into idr_alloc_u32(), remove the
    wrappers around idr_get_free_cmn() and rename it to idr_get_free().
    While there is now no interface to allocate IDs larger than a u32,
    the IDR internals remain ready to handle a larger ID should a need arise.
    
    These changes make it possible to provide the guarantee that, if the
    nextid pointer points into the object, the object's ID will be initialised
    before a concurrent lookup can find the object.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 23a9c89c7ad9..fc55ff31eca7 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -356,24 +356,9 @@ int radix_tree_split(struct radix_tree_root *, unsigned long index,
 int radix_tree_join(struct radix_tree_root *, unsigned long index,
 			unsigned new_order, void *);
 
-void __rcu **idr_get_free_cmn(struct radix_tree_root *root,
+void __rcu **idr_get_free(struct radix_tree_root *root,
 			      struct radix_tree_iter *iter, gfp_t gfp,
 			      unsigned long max);
-static inline void __rcu **idr_get_free(struct radix_tree_root *root,
-					struct radix_tree_iter *iter,
-					gfp_t gfp,
-					int end)
-{
-	return idr_get_free_cmn(root, iter, gfp, end > 0 ? end - 1 : INT_MAX);
-}
-
-static inline void __rcu **idr_get_free_ext(struct radix_tree_root *root,
-					    struct radix_tree_iter *iter,
-					    gfp_t gfp,
-					    unsigned long end)
-{
-	return idr_get_free_cmn(root, iter, gfp, end - 1);
-}
 
 enum {
 	RADIX_TREE_ITER_TAG_MASK = 0x0f,	/* tag index in lower nybble */

commit f5bba9d11a256ad2a1c2f8e7fc6aabe6416b7890
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Fri Nov 17 15:27:53 2017 -0800

    include/linux/radix-tree.h: remove unneeded #include <linux/bug.h>
    
    This include was added by commit 187f1882b5b0 ("BUG: headers with
    BUG/BUG_ON etc. need linux/bug.h") because BUG_ON() was used in this
    header at that time.
    
    Some time later, commit 6d75f366b924 ("lib: radix-tree: check accounting
    of existing slot replacement users") removed the use of BUG_ON() from
    this header.
    
    Since then, there is no reason to include <linux/bug.h>.
    
    Link: http://lkml.kernel.org/r/1505660151-4383-1-git-send-email-yamada.masahiro@socionext.com
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Chris Mi <chrism@mellanox.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 0ca448c1cb42..23a9c89c7ad9 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -22,7 +22,6 @@
 #define _LINUX_RADIX_TREE_H
 
 #include <linux/bitops.h>
-#include <linux/bug.h>
 #include <linux/kernel.h>
 #include <linux/list.h>
 #include <linux/preempt.h>

commit c7df8ad2910e965a6241b6d8f52fd122e26b0315
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Wed Nov 15 17:37:41 2017 -0800

    mm, truncate: do not check mapping for every page being truncated
    
    During truncation, the mapping has already been checked for shmem and
    dax so it's known that workingset_update_node is required.
    
    This patch avoids the checks on mapping for each page being truncated.
    In all other cases, a lookup helper is used to determine if
    workingset_update_node() needs to be called.  The one danger is that the
    API is slightly harder to use as calling workingset_update_node directly
    without checking for dax or shmem mappings could lead to surprises.
    However, the API rarely needs to be used and hopefully the comment is
    enough to give people the hint.
    
    sparsetruncate (tiny)
                                  4.14.0-rc4             4.14.0-rc4
                                 oneirq-v1r1        pickhelper-v1r1
    Min          Time      141.00 (   0.00%)      140.00 (   0.71%)
    1st-qrtle    Time      142.00 (   0.00%)      141.00 (   0.70%)
    2nd-qrtle    Time      142.00 (   0.00%)      142.00 (   0.00%)
    3rd-qrtle    Time      143.00 (   0.00%)      143.00 (   0.00%)
    Max-90%      Time      144.00 (   0.00%)      144.00 (   0.00%)
    Max-95%      Time      147.00 (   0.00%)      145.00 (   1.36%)
    Max-99%      Time      195.00 (   0.00%)      191.00 (   2.05%)
    Max          Time      230.00 (   0.00%)      205.00 (  10.87%)
    Amean        Time      144.37 (   0.00%)      143.82 (   0.38%)
    Stddev       Time       10.44 (   0.00%)        9.00 (  13.74%)
    Coeff        Time        7.23 (   0.00%)        6.26 (  13.41%)
    Best99%Amean Time      143.72 (   0.00%)      143.34 (   0.26%)
    Best95%Amean Time      142.37 (   0.00%)      142.00 (   0.26%)
    Best90%Amean Time      142.19 (   0.00%)      141.85 (   0.24%)
    Best75%Amean Time      141.92 (   0.00%)      141.58 (   0.24%)
    Best50%Amean Time      141.69 (   0.00%)      141.31 (   0.27%)
    Best25%Amean Time      141.38 (   0.00%)      140.97 (   0.29%)
    
    As you'd expect, the gain is marginal but it can be detected.  The
    differences in bonnie are all within the noise which is not surprising
    given the impact on the microbenchmark.
    
    radix_tree_update_node_t is a callback for some radix operations that
    optionally passes in a private field.  The only user of the callback is
    workingset_update_node and as it no longer requires a mapping, the
    private field is removed.
    
    Link: http://lkml.kernel.org/r/20171018075952.10627-3-mgorman@techsingularity.net
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 567ebb5eaab0..0ca448c1cb42 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -301,18 +301,17 @@ void *__radix_tree_lookup(const struct radix_tree_root *, unsigned long index,
 void *radix_tree_lookup(const struct radix_tree_root *, unsigned long);
 void __rcu **radix_tree_lookup_slot(const struct radix_tree_root *,
 					unsigned long index);
-typedef void (*radix_tree_update_node_t)(struct radix_tree_node *, void *);
+typedef void (*radix_tree_update_node_t)(struct radix_tree_node *);
 void __radix_tree_replace(struct radix_tree_root *, struct radix_tree_node *,
 			  void __rcu **slot, void *entry,
-			  radix_tree_update_node_t update_node, void *private);
+			  radix_tree_update_node_t update_node);
 void radix_tree_iter_replace(struct radix_tree_root *,
 		const struct radix_tree_iter *, void __rcu **slot, void *entry);
 void radix_tree_replace_slot(struct radix_tree_root *,
 			     void __rcu **slot, void *entry);
 void __radix_tree_delete_node(struct radix_tree_root *,
 			      struct radix_tree_node *,
-			      radix_tree_update_node_t update_node,
-			      void *private);
+			      radix_tree_update_node_t update_node);
 void radix_tree_iter_delete(struct radix_tree_root *,
 			struct radix_tree_iter *iter, void __rcu **slot);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);

commit 388f79fda74fd3d8700ed5d899573ec58c2e0253
Author: Chris Mi <chrism@mellanox.com>
Date:   Wed Aug 30 02:31:57 2017 -0400

    idr: Add new APIs to support unsigned long
    
    The following new APIs are added:
    
    int idr_alloc_ext(struct idr *idr, void *ptr, unsigned long *index,
                      unsigned long start, unsigned long end, gfp_t gfp);
    void *idr_remove_ext(struct idr *idr, unsigned long id);
    void *idr_find_ext(const struct idr *idr, unsigned long id);
    void *idr_replace_ext(struct idr *idr, void *ptr, unsigned long id);
    void *idr_get_next_ext(struct idr *idr, unsigned long *nextid);
    
    Signed-off-by: Chris Mi <chrism@mellanox.com>
    Signed-off-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 3e5735064b71..567ebb5eaab0 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -357,8 +357,25 @@ int radix_tree_split(struct radix_tree_root *, unsigned long index,
 			unsigned new_order);
 int radix_tree_join(struct radix_tree_root *, unsigned long index,
 			unsigned new_order, void *);
-void __rcu **idr_get_free(struct radix_tree_root *, struct radix_tree_iter *,
-			gfp_t, int end);
+
+void __rcu **idr_get_free_cmn(struct radix_tree_root *root,
+			      struct radix_tree_iter *iter, gfp_t gfp,
+			      unsigned long max);
+static inline void __rcu **idr_get_free(struct radix_tree_root *root,
+					struct radix_tree_iter *iter,
+					gfp_t gfp,
+					int end)
+{
+	return idr_get_free_cmn(root, iter, gfp, end > 0 ? end - 1 : INT_MAX);
+}
+
+static inline void __rcu **idr_get_free_ext(struct radix_tree_root *root,
+					    struct radix_tree_iter *iter,
+					    gfp_t gfp,
+					    unsigned long end)
+{
+	return idr_get_free_cmn(root, iter, gfp, end - 1);
+}
 
 enum {
 	RADIX_TREE_ITER_TAG_MASK = 0x0f,	/* tag index in lower nybble */

commit d7b627277b57370223d682cede979a279284b12a
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Mon Feb 13 15:58:24 2017 -0500

    radix-tree: Fix __rcu annotations
    
    Many places were missing __rcu annotations.  A few places needed a few
    lines of explanation about why it was safe to not use RCU accessors.
    Add a custom CFLAGS setting to the Makefile to ensure that new patches
    don't miss RCU annotations.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 0b502de7d23a..3e5735064b71 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -221,10 +221,8 @@ static inline unsigned int iter_shift(const struct radix_tree_iter *iter)
  */
 
 /**
- * radix_tree_deref_slot	- dereference a slot
- * @pslot:	pointer to slot, returned by radix_tree_lookup_slot
- * Returns:	item that was stored in that slot with any direct pointer flag
- *		removed.
+ * radix_tree_deref_slot - dereference a slot
+ * @slot: slot pointer, returned by radix_tree_lookup_slot
  *
  * For use with radix_tree_lookup_slot().  Caller must hold tree at least read
  * locked across slot lookup and dereference. Not required if write lock is
@@ -232,26 +230,27 @@ static inline unsigned int iter_shift(const struct radix_tree_iter *iter)
  *
  * radix_tree_deref_retry must be used to confirm validity of the pointer if
  * only the read lock is held.
+ *
+ * Return: entry stored in that slot.
  */
-static inline void *radix_tree_deref_slot(void **pslot)
+static inline void *radix_tree_deref_slot(void __rcu **slot)
 {
-	return rcu_dereference(*pslot);
+	return rcu_dereference(*slot);
 }
 
 /**
- * radix_tree_deref_slot_protected	- dereference a slot without RCU lock but with tree lock held
- * @pslot:	pointer to slot, returned by radix_tree_lookup_slot
- * Returns:	item that was stored in that slot with any direct pointer flag
- *		removed.
- *
- * Similar to radix_tree_deref_slot but only used during migration when a pages
- * mapping is being moved. The caller does not hold the RCU read lock but it
- * must hold the tree lock to prevent parallel updates.
+ * radix_tree_deref_slot_protected - dereference a slot with tree lock held
+ * @slot: slot pointer, returned by radix_tree_lookup_slot
+ *
+ * Similar to radix_tree_deref_slot.  The caller does not hold the RCU read
+ * lock but it must hold the tree lock to prevent parallel updates.
+ *
+ * Return: entry stored in that slot.
  */
-static inline void *radix_tree_deref_slot_protected(void **pslot,
+static inline void *radix_tree_deref_slot_protected(void __rcu **slot,
 							spinlock_t *treelock)
 {
-	return rcu_dereference_protected(*pslot, lockdep_is_held(treelock));
+	return rcu_dereference_protected(*slot, lockdep_is_held(treelock));
 }
 
 /**
@@ -287,9 +286,9 @@ static inline int radix_tree_exception(void *arg)
 	return unlikely((unsigned long)arg & RADIX_TREE_ENTRY_MASK);
 }
 
-int __radix_tree_create(struct radix_tree_root *root, unsigned long index,
+int __radix_tree_create(struct radix_tree_root *, unsigned long index,
 			unsigned order, struct radix_tree_node **nodep,
-			void ***slotp);
+			void __rcu ***slotp);
 int __radix_tree_insert(struct radix_tree_root *, unsigned long index,
 			unsigned order, void *);
 static inline int radix_tree_insert(struct radix_tree_root *root,
@@ -298,42 +297,41 @@ static inline int radix_tree_insert(struct radix_tree_root *root,
 	return __radix_tree_insert(root, index, 0, entry);
 }
 void *__radix_tree_lookup(const struct radix_tree_root *, unsigned long index,
-			  struct radix_tree_node **nodep, void ***slotp);
+			  struct radix_tree_node **nodep, void __rcu ***slotp);
 void *radix_tree_lookup(const struct radix_tree_root *, unsigned long);
-void **radix_tree_lookup_slot(const struct radix_tree_root *, unsigned long);
+void __rcu **radix_tree_lookup_slot(const struct radix_tree_root *,
+					unsigned long index);
 typedef void (*radix_tree_update_node_t)(struct radix_tree_node *, void *);
-void __radix_tree_replace(struct radix_tree_root *root,
-			  struct radix_tree_node *node,
-			  void **slot, void *item,
+void __radix_tree_replace(struct radix_tree_root *, struct radix_tree_node *,
+			  void __rcu **slot, void *entry,
 			  radix_tree_update_node_t update_node, void *private);
 void radix_tree_iter_replace(struct radix_tree_root *,
-		const struct radix_tree_iter *, void **slot, void *item);
-void radix_tree_replace_slot(struct radix_tree_root *root,
-			     void **slot, void *item);
-void __radix_tree_delete_node(struct radix_tree_root *root,
-			      struct radix_tree_node *node,
+		const struct radix_tree_iter *, void __rcu **slot, void *entry);
+void radix_tree_replace_slot(struct radix_tree_root *,
+			     void __rcu **slot, void *entry);
+void __radix_tree_delete_node(struct radix_tree_root *,
+			      struct radix_tree_node *,
 			      radix_tree_update_node_t update_node,
 			      void *private);
 void radix_tree_iter_delete(struct radix_tree_root *,
-				struct radix_tree_iter *iter, void **slot);
+			struct radix_tree_iter *iter, void __rcu **slot);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
-void radix_tree_clear_tags(struct radix_tree_root *root,
-			   struct radix_tree_node *node,
-			   void **slot);
+void radix_tree_clear_tags(struct radix_tree_root *, struct radix_tree_node *,
+			   void __rcu **slot);
 unsigned int radix_tree_gang_lookup(const struct radix_tree_root *,
 			void **results, unsigned long first_index,
 			unsigned int max_items);
 unsigned int radix_tree_gang_lookup_slot(const struct radix_tree_root *,
-			void ***results, unsigned long *indices,
+			void __rcu ***results, unsigned long *indices,
 			unsigned long first_index, unsigned int max_items);
 int radix_tree_preload(gfp_t gfp_mask);
 int radix_tree_maybe_preload(gfp_t gfp_mask);
 int radix_tree_maybe_preload_order(gfp_t gfp_mask, int order);
 void radix_tree_init(void);
-void *radix_tree_tag_set(struct radix_tree_root *root,
+void *radix_tree_tag_set(struct radix_tree_root *,
 			unsigned long index, unsigned int tag);
-void *radix_tree_tag_clear(struct radix_tree_root *root,
+void *radix_tree_tag_clear(struct radix_tree_root *,
 			unsigned long index, unsigned int tag);
 int radix_tree_tag_get(const struct radix_tree_root *,
 			unsigned long index, unsigned int tag);
@@ -341,15 +339,13 @@ void radix_tree_iter_tag_set(struct radix_tree_root *,
 		const struct radix_tree_iter *iter, unsigned int tag);
 void radix_tree_iter_tag_clear(struct radix_tree_root *,
 		const struct radix_tree_iter *iter, unsigned int tag);
-unsigned int
-radix_tree_gang_lookup_tag(const struct radix_tree_root *, void **results,
-		unsigned long first_index, unsigned int max_items,
-		unsigned int tag);
-unsigned int
-radix_tree_gang_lookup_tag_slot(const struct radix_tree_root *, void ***results,
-		unsigned long first_index, unsigned int max_items,
-		unsigned int tag);
-int radix_tree_tagged(const struct radix_tree_root *root, unsigned int tag);
+unsigned int radix_tree_gang_lookup_tag(const struct radix_tree_root *,
+		void **results, unsigned long first_index,
+		unsigned int max_items, unsigned int tag);
+unsigned int radix_tree_gang_lookup_tag_slot(const struct radix_tree_root *,
+		void __rcu ***results, unsigned long first_index,
+		unsigned int max_items, unsigned int tag);
+int radix_tree_tagged(const struct radix_tree_root *, unsigned int tag);
 
 static inline void radix_tree_preload_end(void)
 {
@@ -361,7 +357,7 @@ int radix_tree_split(struct radix_tree_root *, unsigned long index,
 			unsigned new_order);
 int radix_tree_join(struct radix_tree_root *, unsigned long index,
 			unsigned new_order, void *);
-void **idr_get_free(struct radix_tree_root *, struct radix_tree_iter *,
+void __rcu **idr_get_free(struct radix_tree_root *, struct radix_tree_iter *,
 			gfp_t, int end);
 
 enum {
@@ -377,7 +373,7 @@ enum {
  * @start:	iteration starting index
  * Returns:	NULL
  */
-static __always_inline void **
+static __always_inline void __rcu **
 radix_tree_iter_init(struct radix_tree_iter *iter, unsigned long start)
 {
 	/*
@@ -406,7 +402,7 @@ radix_tree_iter_init(struct radix_tree_iter *iter, unsigned long start)
  * Also it fills @iter with data about chunk: position in the tree (index),
  * its end (next_index), and constructs a bit mask for tagged iterating (tags).
  */
-void **radix_tree_next_chunk(const struct radix_tree_root *,
+void __rcu **radix_tree_next_chunk(const struct radix_tree_root *,
 			     struct radix_tree_iter *iter, unsigned flags);
 
 /**
@@ -419,7 +415,8 @@ void **radix_tree_next_chunk(const struct radix_tree_root *,
  * containing it and updates @iter to describe the entry.  If @index is not
  * present, it returns NULL.
  */
-static inline void **radix_tree_iter_lookup(const struct radix_tree_root *root,
+static inline void __rcu **
+radix_tree_iter_lookup(const struct radix_tree_root *root,
 			struct radix_tree_iter *iter, unsigned long index)
 {
 	radix_tree_iter_init(iter, index);
@@ -436,7 +433,8 @@ static inline void **radix_tree_iter_lookup(const struct radix_tree_root *root,
  * which is at least @index.  If @index is larger than any present entry, this
  * function returns NULL.  The @iter is updated to describe the entry found.
  */
-static inline void **radix_tree_iter_find(const struct radix_tree_root *root,
+static inline void __rcu **
+radix_tree_iter_find(const struct radix_tree_root *root,
 			struct radix_tree_iter *iter, unsigned long index)
 {
 	radix_tree_iter_init(iter, index);
@@ -453,7 +451,7 @@ static inline void **radix_tree_iter_find(const struct radix_tree_root *root,
  * and continue the iteration.
  */
 static inline __must_check
-void **radix_tree_iter_retry(struct radix_tree_iter *iter)
+void __rcu **radix_tree_iter_retry(struct radix_tree_iter *iter)
 {
 	iter->next_index = iter->index;
 	iter->tags = 0;
@@ -476,7 +474,7 @@ __radix_tree_iter_add(struct radix_tree_iter *iter, unsigned long slots)
  * have been invalidated by an insertion or deletion.  Call this function
  * before releasing the lock to continue the iteration from the next index.
  */
-void **__must_check radix_tree_iter_resume(void **slot,
+void __rcu **__must_check radix_tree_iter_resume(void __rcu **slot,
 					struct radix_tree_iter *iter);
 
 /**
@@ -492,11 +490,11 @@ radix_tree_chunk_size(struct radix_tree_iter *iter)
 }
 
 #ifdef CONFIG_RADIX_TREE_MULTIORDER
-void ** __radix_tree_next_slot(void **slot, struct radix_tree_iter *iter,
-				unsigned flags);
+void __rcu **__radix_tree_next_slot(void __rcu **slot,
+				struct radix_tree_iter *iter, unsigned flags);
 #else
 /* Can't happen without sibling entries, but the compiler can't tell that */
-static inline void ** __radix_tree_next_slot(void **slot,
+static inline void __rcu **__radix_tree_next_slot(void __rcu **slot,
 				struct radix_tree_iter *iter, unsigned flags)
 {
 	return slot;
@@ -522,8 +520,8 @@ static inline void ** __radix_tree_next_slot(void **slot,
  * b) we are doing non-tagged iteration, and iter->index and iter->next_index
  *    have been set up so that radix_tree_chunk_size() returns 1 or 0.
  */
-static __always_inline void **
-radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
+static __always_inline void __rcu **radix_tree_next_slot(void __rcu **slot,
+				struct radix_tree_iter *iter, unsigned flags)
 {
 	if (flags & RADIX_TREE_ITER_TAGGED) {
 		iter->tags >>= 1;

commit 12320d0ff1c9d5582f5c35e4bb8b9c70c475fd71
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Mon Feb 13 15:22:48 2017 -0500

    radix-tree: Add rcu_dereference and rcu_assign_pointer calls
    
    Some of these have been missing for many years.  Others were recently
    introduced by me.  Fortunately, we have tools that help us find such
    things.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index d250059bbfa4..0b502de7d23a 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -561,7 +561,7 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 	return NULL;
 
  found:
-	if (unlikely(radix_tree_is_internal_node(*slot)))
+	if (unlikely(radix_tree_is_internal_node(rcu_dereference_raw(*slot))))
 		return __radix_tree_next_slot(slot, iter, flags);
 	return slot;
 }

commit d58275bc96ae933b1b3888af80920dd6b020c505
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Mon Jan 16 17:10:21 2017 -0500

    radix-tree: Store a pointer to the root in each node
    
    Instead of having this mysterious private_data in each radix_tree_node,
    store a pointer to the root, which can be useful for debugging.  This also
    relieves the mm code from the duty of updating it.
    
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 2ba0c1f46c84..d250059bbfa4 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -96,7 +96,7 @@ struct radix_tree_node {
 	unsigned char	count;		/* Total entry count */
 	unsigned char	exceptional;	/* Exceptional entry count */
 	struct radix_tree_node *parent;		/* Used when ascending tree */
-	void *private_data;			/* For tree user */
+	struct radix_tree_root *root;		/* The tree we belong to */
 	union {
 		struct list_head private_list;	/* For tree user */
 		struct rcu_head	rcu_head;	/* Used when freeing node */

commit 0a835c4f090af2c76fc2932c539c3b32fd21fbbb
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Tue Dec 20 10:27:56 2016 -0500

    Reimplement IDR and IDA using the radix tree
    
    The IDR is very similar to the radix tree.  It has some functionality that
    the radix tree did not have (alloc next free, cyclic allocation, a
    callback-based for_each, destroy tree), which is readily implementable on
    top of the radix tree.  A few small changes were needed in order to use a
    tag to represent nodes with free space below them.  More extensive
    changes were needed to support storing NULL as a valid entry in an IDR.
    Plain radix trees still interpret NULL as a not-present entry.
    
    The IDA is reimplemented as a client of the newly enhanced radix tree.  As
    in the current implementation, it uses a bitmap at the last level of the
    tree.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 05f715cb8062..2ba0c1f46c84 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -105,7 +105,10 @@ struct radix_tree_node {
 	unsigned long	tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];
 };
 
-/* root tags are stored in gfp_mask, shifted by __GFP_BITS_SHIFT */
+/* The top bits of gfp_mask are used to store the root tags and the IDR flag */
+#define ROOT_IS_IDR	((__force gfp_t)(1 << __GFP_BITS_SHIFT))
+#define ROOT_TAG_SHIFT	(__GFP_BITS_SHIFT + 1)
+
 struct radix_tree_root {
 	gfp_t			gfp_mask;
 	struct radix_tree_node	__rcu *rnode;
@@ -358,10 +361,14 @@ int radix_tree_split(struct radix_tree_root *, unsigned long index,
 			unsigned new_order);
 int radix_tree_join(struct radix_tree_root *, unsigned long index,
 			unsigned new_order, void *);
+void **idr_get_free(struct radix_tree_root *, struct radix_tree_iter *,
+			gfp_t, int end);
 
-#define RADIX_TREE_ITER_TAG_MASK	0x00FF	/* tag index in lower byte */
-#define RADIX_TREE_ITER_TAGGED		0x0100	/* lookup tagged slots */
-#define RADIX_TREE_ITER_CONTIG		0x0200	/* stop at first hole */
+enum {
+	RADIX_TREE_ITER_TAG_MASK = 0x0f,	/* tag index in lower nybble */
+	RADIX_TREE_ITER_TAGGED   = 0x10,	/* lookup tagged slots */
+	RADIX_TREE_ITER_CONTIG   = 0x20,	/* stop at first hole */
+};
 
 /**
  * radix_tree_iter_init - initialize radix tree iterator
@@ -402,6 +409,40 @@ radix_tree_iter_init(struct radix_tree_iter *iter, unsigned long start)
 void **radix_tree_next_chunk(const struct radix_tree_root *,
 			     struct radix_tree_iter *iter, unsigned flags);
 
+/**
+ * radix_tree_iter_lookup - look up an index in the radix tree
+ * @root: radix tree root
+ * @iter: iterator state
+ * @index: key to look up
+ *
+ * If @index is present in the radix tree, this function returns the slot
+ * containing it and updates @iter to describe the entry.  If @index is not
+ * present, it returns NULL.
+ */
+static inline void **radix_tree_iter_lookup(const struct radix_tree_root *root,
+			struct radix_tree_iter *iter, unsigned long index)
+{
+	radix_tree_iter_init(iter, index);
+	return radix_tree_next_chunk(root, iter, RADIX_TREE_ITER_CONTIG);
+}
+
+/**
+ * radix_tree_iter_find - find a present entry
+ * @root: radix tree root
+ * @iter: iterator state
+ * @index: start location
+ *
+ * This function returns the slot containing the entry with the lowest index
+ * which is at least @index.  If @index is larger than any present entry, this
+ * function returns NULL.  The @iter is updated to describe the entry found.
+ */
+static inline void **radix_tree_iter_find(const struct radix_tree_root *root,
+			struct radix_tree_iter *iter, unsigned long index)
+{
+	radix_tree_iter_init(iter, index);
+	return radix_tree_next_chunk(root, iter, 0);
+}
+
 /**
  * radix_tree_iter_retry - retry this chunk of the iteration
  * @iter:	iterator state

commit 0ac398ef391b53122976325ab6953456ce8e8310
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Sat Jan 28 09:56:22 2017 -0500

    radix-tree: Add radix_tree_iter_delete
    
    Factor the deletion code out into __radix_tree_delete() and provide a
    nice iterator-based wrapper around it.  If we free the node, advance
    the iterator to avoid reading from freed memory.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 8bf4ef448ce1..05f715cb8062 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -311,6 +311,8 @@ void __radix_tree_delete_node(struct radix_tree_root *root,
 			      struct radix_tree_node *node,
 			      radix_tree_update_node_t update_node,
 			      void *private);
+void radix_tree_iter_delete(struct radix_tree_root *,
+				struct radix_tree_iter *iter, void **slot);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 void radix_tree_clear_tags(struct radix_tree_root *root,

commit 30b888ba950d9f77326b50a4aa2d7d99557d5718
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Sat Jan 28 09:55:20 2017 -0500

    radix-tree: Add radix_tree_iter_tag_clear()
    
    The counterpart to radix_tree_iter_tag_set(), used by the IDR code
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Reviewed-by: Rehas Sachdeva <aquannie@gmail.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 32683c7c2e0d..8bf4ef448ce1 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -332,7 +332,9 @@ void *radix_tree_tag_clear(struct radix_tree_root *root,
 			unsigned long index, unsigned int tag);
 int radix_tree_tag_get(const struct radix_tree_root *,
 			unsigned long index, unsigned int tag);
-void radix_tree_iter_tag_set(struct radix_tree_root *root,
+void radix_tree_iter_tag_set(struct radix_tree_root *,
+		const struct radix_tree_iter *iter, unsigned int tag);
+void radix_tree_iter_tag_clear(struct radix_tree_root *,
 		const struct radix_tree_iter *iter, unsigned int tag);
 unsigned int
 radix_tree_gang_lookup_tag(const struct radix_tree_root *, void **results,

commit 35534c869c62f59203c1822769bbef14e894a9e9
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Mon Dec 19 17:43:19 2016 -0500

    radix tree: constify some pointers
    
    If we're just getting the value of a tag, or looking up an entry,
    we won't modify the radix tree, so we can declare these functions as
    taking a const pointer.  Mostly for documentation purposes, though it
    might help code generation.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 13d8d741ca34..32683c7c2e0d 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -125,7 +125,7 @@ do {									\
 	(root)->rnode = NULL;						\
 } while (0)
 
-static inline bool radix_tree_empty(struct radix_tree_root *root)
+static inline bool radix_tree_empty(const struct radix_tree_root *root)
 {
 	return root->rnode == NULL;
 }
@@ -294,10 +294,10 @@ static inline int radix_tree_insert(struct radix_tree_root *root,
 {
 	return __radix_tree_insert(root, index, 0, entry);
 }
-void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,
+void *__radix_tree_lookup(const struct radix_tree_root *, unsigned long index,
 			  struct radix_tree_node **nodep, void ***slotp);
-void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
-void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
+void *radix_tree_lookup(const struct radix_tree_root *, unsigned long);
+void **radix_tree_lookup_slot(const struct radix_tree_root *, unsigned long);
 typedef void (*radix_tree_update_node_t)(struct radix_tree_node *, void *);
 void __radix_tree_replace(struct radix_tree_root *root,
 			  struct radix_tree_node *node,
@@ -316,10 +316,10 @@ void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 void radix_tree_clear_tags(struct radix_tree_root *root,
 			   struct radix_tree_node *node,
 			   void **slot);
-unsigned int radix_tree_gang_lookup(struct radix_tree_root *root,
+unsigned int radix_tree_gang_lookup(const struct radix_tree_root *,
 			void **results, unsigned long first_index,
 			unsigned int max_items);
-unsigned int radix_tree_gang_lookup_slot(struct radix_tree_root *root,
+unsigned int radix_tree_gang_lookup_slot(const struct radix_tree_root *,
 			void ***results, unsigned long *indices,
 			unsigned long first_index, unsigned int max_items);
 int radix_tree_preload(gfp_t gfp_mask);
@@ -330,19 +330,19 @@ void *radix_tree_tag_set(struct radix_tree_root *root,
 			unsigned long index, unsigned int tag);
 void *radix_tree_tag_clear(struct radix_tree_root *root,
 			unsigned long index, unsigned int tag);
-int radix_tree_tag_get(struct radix_tree_root *root,
+int radix_tree_tag_get(const struct radix_tree_root *,
 			unsigned long index, unsigned int tag);
 void radix_tree_iter_tag_set(struct radix_tree_root *root,
 		const struct radix_tree_iter *iter, unsigned int tag);
 unsigned int
-radix_tree_gang_lookup_tag(struct radix_tree_root *root, void **results,
+radix_tree_gang_lookup_tag(const struct radix_tree_root *, void **results,
 		unsigned long first_index, unsigned int max_items,
 		unsigned int tag);
 unsigned int
-radix_tree_gang_lookup_tag_slot(struct radix_tree_root *root, void ***results,
+radix_tree_gang_lookup_tag_slot(const struct radix_tree_root *, void ***results,
 		unsigned long first_index, unsigned int max_items,
 		unsigned int tag);
-int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);
+int radix_tree_tagged(const struct radix_tree_root *root, unsigned int tag);
 
 static inline void radix_tree_preload_end(void)
 {
@@ -395,7 +395,7 @@ radix_tree_iter_init(struct radix_tree_iter *iter, unsigned long start)
  * Also it fills @iter with data about chunk: position in the tree (index),
  * its end (next_index), and constructs a bit mask for tagged iterating (tags).
  */
-void **radix_tree_next_chunk(struct radix_tree_root *root,
+void **radix_tree_next_chunk(const struct radix_tree_root *,
 			     struct radix_tree_iter *iter, unsigned flags);
 
 /**

commit 15f2e88ddd4bc9b2c6b6236162993b5caa80abb9
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Fri Dec 16 14:46:09 2016 -0500

    radix tree: Add some implicit includes
    
    We were using spinlock_t and INIT_LIST_HEAD without including spinlock.h
    or list.h.  They were being implicitly included through some other header
    file, but that's fragile.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 52bda854593b..13d8d741ca34 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -22,11 +22,13 @@
 #define _LINUX_RADIX_TREE_H
 
 #include <linux/bitops.h>
-#include <linux/preempt.h>
-#include <linux/types.h>
 #include <linux/bug.h>
 #include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/preempt.h>
 #include <linux/rcupdate.h>
+#include <linux/spinlock.h>
+#include <linux/types.h>
 
 /*
  * The bottom two bits of the slot determine how the remaining bits in the

commit ea07b862ac8ef9b8c8358517d2e39f847dda6659
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Fri Jan 6 19:21:43 2017 -0500

    mm: workingset: fix use-after-free in shadow node shrinker
    
    Several people report seeing warnings about inconsistent radix tree
    nodes followed by crashes in the workingset code, which all looked like
    use-after-free access from the shadow node shrinker.
    
    Dave Jones managed to reproduce the issue with a debug patch applied,
    which confirmed that the radix tree shrinking indeed frees shadow nodes
    while they are still linked to the shadow LRU:
    
      WARNING: CPU: 2 PID: 53 at lib/radix-tree.c:643 delete_node+0x1e4/0x200
      CPU: 2 PID: 53 Comm: kswapd0 Not tainted 4.10.0-rc2-think+ #3
      Call Trace:
         delete_node+0x1e4/0x200
         __radix_tree_delete_node+0xd/0x10
         shadow_lru_isolate+0xe6/0x220
         __list_lru_walk_one.isra.4+0x9b/0x190
         list_lru_walk_one+0x23/0x30
         scan_shadow_nodes+0x2e/0x40
         shrink_slab.part.44+0x23d/0x5d0
         shrink_node+0x22c/0x330
         kswapd+0x392/0x8f0
    
    This is the WARN_ON_ONCE(!list_empty(&node->private_list)) placed in the
    inlined radix_tree_shrink().
    
    The problem is with 14b468791fa9 ("mm: workingset: move shadow entry
    tracking to radix tree exceptional tracking"), which passes an update
    callback into the radix tree to link and unlink shadow leaf nodes when
    tree entries change, but forgot to pass the callback when reclaiming a
    shadow node.
    
    While the reclaimed shadow node itself is unlinked by the shrinker, its
    deletion from the tree can cause the left-most leaf node in the tree to
    be shrunk.  If that happens to be a shadow node as well, we don't unlink
    it from the LRU as we should.
    
    Consider this tree, where the s are shadow entries:
    
           root->rnode
                |
           [0       n]
            |       |
         [s    ] [sssss]
    
    Now the shadow node shrinker reclaims the rightmost leaf node through
    the shadow node LRU:
    
           root->rnode
                |
           [0        ]
            |
        [s     ]
    
    Because the parent of the deleted node is the first level below the
    root and has only one child in the left-most slot, the intermediate
    level is shrunk and the node containing the single shadow is put in
    its place:
    
           root->rnode
                |
           [s        ]
    
    The shrinker again sees a single left-most slot in a first level node
    and thus decides to store the shadow in root->rnode directly and free
    the node - which is a leaf node on the shadow node LRU.
    
      root->rnode
           |
           s
    
    Without the update callback, the freed node remains on the shadow LRU,
    where it causes later shrinker runs to crash.
    
    Pass the node updater callback into __radix_tree_delete_node() in case
    the deletion causes the left-most branch in the tree to collapse too.
    
    Also add warnings when linked nodes are freed right away, rather than
    wait for the use-after-free when the list is scanned much later.
    
    Fixes: 14b468791fa9 ("mm: workingset: move shadow entry tracking to radix tree exceptional tracking")
    Reported-by: Dave Chinner <david@fromorbit.com>
    Reported-by: Hugh Dickins <hughd@google.com>
    Reported-by: Andrea Arcangeli <aarcange@redhat.com>
    Reported-and-tested-by: Dave Jones <davej@codemonkey.org.uk>
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Chris Leech <cleech@redhat.com>
    Cc: Lee Duncan <lduncan@suse.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@linuxonhyperv.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 5dea8f6440e4..52bda854593b 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -306,7 +306,9 @@ void radix_tree_iter_replace(struct radix_tree_root *,
 void radix_tree_replace_slot(struct radix_tree_root *root,
 			     void **slot, void *item);
 void __radix_tree_delete_node(struct radix_tree_root *root,
-			      struct radix_tree_node *node);
+			      struct radix_tree_node *node,
+			      radix_tree_update_node_t update_node,
+			      void *private);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 void radix_tree_clear_tags(struct radix_tree_root *root,

commit 2791653a6814d170fa893344618563a7b1da95c6
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Wed Dec 14 15:09:04 2016 -0800

    radix-tree: add radix_tree_split_preload()
    
    Calculate how many nodes we need to allocate to split an old_order entry
    into multiple entries, each of size new_order.  The test suite checks
    that we allocated exactly the right number of nodes; neither too many
    (checked by rtp->nr == 0), nor too few (checked by comparing
    nr_allocated before and after the call to radix_tree_split()).
    
    Link: http://lkml.kernel.org/r/1480369871-5271-60-git-send-email-mawilcox@linuxonhyperv.com
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 1f4b56120de8..5dea8f6440e4 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -345,6 +345,7 @@ static inline void radix_tree_preload_end(void)
 	preempt_enable();
 }
 
+int radix_tree_split_preload(unsigned old_order, unsigned new_order, gfp_t);
 int radix_tree_split(struct radix_tree_root *, unsigned long index,
 			unsigned new_order);
 int radix_tree_join(struct radix_tree_root *, unsigned long index,

commit e157b555945fb16ddc6cce605a1eb6b4135ea5f1
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Wed Dec 14 15:09:01 2016 -0800

    radix-tree: add radix_tree_split
    
    This new function splits a larger multiorder entry into smaller entries
    (potentially multi-order entries).  These entries are initialised to
    RADIX_TREE_RETRY to ensure that RCU walkers who see this state aren't
    confused.  The caller should then call radix_tree_for_each_slot() and
    radix_tree_replace_slot() in order to turn these retry entries into the
    intended new entries.  Tags are replicated from the original multiorder
    entry into each new entry.
    
    Link: http://lkml.kernel.org/r/1480369871-5271-59-git-send-email-mawilcox@linuxonhyperv.com
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 935293a24f7d..1f4b56120de8 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -80,6 +80,14 @@ static inline bool radix_tree_is_internal_node(void *ptr)
 #define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \
 					  RADIX_TREE_MAP_SHIFT))
 
+/*
+ * @count is the count of every non-NULL element in the ->slots array
+ * whether that is an exceptional entry, a retry entry, a user pointer,
+ * a sibling entry or a pointer to the next level of the tree.
+ * @exceptional is the count of every element in ->slots which is
+ * either radix_tree_exceptional_entry() or is a sibling entry for an
+ * exceptional entry.
+ */
 struct radix_tree_node {
 	unsigned char	shift;		/* Bits remaining in each slot */
 	unsigned char	offset;		/* Slot offset in parent */
@@ -293,6 +301,8 @@ void __radix_tree_replace(struct radix_tree_root *root,
 			  struct radix_tree_node *node,
 			  void **slot, void *item,
 			  radix_tree_update_node_t update_node, void *private);
+void radix_tree_iter_replace(struct radix_tree_root *,
+		const struct radix_tree_iter *, void **slot, void *item);
 void radix_tree_replace_slot(struct radix_tree_root *root,
 			     void **slot, void *item);
 void __radix_tree_delete_node(struct radix_tree_root *root,
@@ -335,6 +345,8 @@ static inline void radix_tree_preload_end(void)
 	preempt_enable();
 }
 
+int radix_tree_split(struct radix_tree_root *, unsigned long index,
+			unsigned new_order);
 int radix_tree_join(struct radix_tree_root *, unsigned long index,
 			unsigned new_order, void *);
 

commit 175542f575723e43f897ddb09d0011c13f7cf0ec
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Wed Dec 14 15:08:58 2016 -0800

    radix-tree: add radix_tree_join
    
    This new function allows for the replacement of many smaller entries in
    the radix tree with one larger multiorder entry.  From the point of view
    of an RCU walker, they may see a mixture of the smaller entries and the
    large entry during the same walk, but they will never see NULL for an
    index which was populated before the join.
    
    Link: http://lkml.kernel.org/r/1480369871-5271-58-git-send-email-mawilcox@linuxonhyperv.com
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 7a8d2516c73a..935293a24f7d 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -335,6 +335,9 @@ static inline void radix_tree_preload_end(void)
 	preempt_enable();
 }
 
+int radix_tree_join(struct radix_tree_root *, unsigned long index,
+			unsigned new_order, void *);
+
 #define RADIX_TREE_ITER_TAG_MASK	0x00FF	/* tag index in lower byte */
 #define RADIX_TREE_ITER_TAGGED		0x0100	/* lookup tagged slots */
 #define RADIX_TREE_ITER_CONTIG		0x0200	/* stop at first hole */

commit 268f42de718128cd0301293177e79c08c38e39a6
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Wed Dec 14 15:08:55 2016 -0800

    radix-tree: delete radix_tree_range_tag_if_tagged()
    
    This is an exceptionally complicated function with just one caller
    (tag_pages_for_writeback).  We devote a large portion of the runtime of
    the test suite to testing this one function which has one caller.  By
    introducing the new function radix_tree_iter_tag_set(), we can eliminate
    all of the complexity while keeping the performance.  The caller can now
    use a fairly standard radix_tree_for_each() loop, and it doesn't need to
    worry about tricksy things like 'start' wrapping.
    
    The test suite continues to spend a large amount of time investigating
    this function, but now it's testing the underlying primitives such as
    radix_tree_iter_resume() and the radix_tree_for_each_tagged() iterator
    which are also used by other parts of the kernel.
    
    Link: http://lkml.kernel.org/r/1480369871-5271-57-git-send-email-mawilcox@linuxonhyperv.com
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index a13d3f7c6c65..7a8d2516c73a 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -120,6 +120,41 @@ static inline bool radix_tree_empty(struct radix_tree_root *root)
 	return root->rnode == NULL;
 }
 
+/**
+ * struct radix_tree_iter - radix tree iterator state
+ *
+ * @index:	index of current slot
+ * @next_index:	one beyond the last index for this chunk
+ * @tags:	bit-mask for tag-iterating
+ * @node:	node that contains current slot
+ * @shift:	shift for the node that holds our slots
+ *
+ * This radix tree iterator works in terms of "chunks" of slots.  A chunk is a
+ * subinterval of slots contained within one radix tree leaf node.  It is
+ * described by a pointer to its first slot and a struct radix_tree_iter
+ * which holds the chunk's position in the tree and its size.  For tagged
+ * iteration radix_tree_iter also holds the slots' bit-mask for one chosen
+ * radix tree tag.
+ */
+struct radix_tree_iter {
+	unsigned long	index;
+	unsigned long	next_index;
+	unsigned long	tags;
+	struct radix_tree_node *node;
+#ifdef CONFIG_RADIX_TREE_MULTIORDER
+	unsigned int	shift;
+#endif
+};
+
+static inline unsigned int iter_shift(const struct radix_tree_iter *iter)
+{
+#ifdef CONFIG_RADIX_TREE_MULTIORDER
+	return iter->shift;
+#else
+	return 0;
+#endif
+}
+
 /**
  * Radix-tree synchronization
  *
@@ -283,6 +318,8 @@ void *radix_tree_tag_clear(struct radix_tree_root *root,
 			unsigned long index, unsigned int tag);
 int radix_tree_tag_get(struct radix_tree_root *root,
 			unsigned long index, unsigned int tag);
+void radix_tree_iter_tag_set(struct radix_tree_root *root,
+		const struct radix_tree_iter *iter, unsigned int tag);
 unsigned int
 radix_tree_gang_lookup_tag(struct radix_tree_root *root, void **results,
 		unsigned long first_index, unsigned int max_items,
@@ -291,10 +328,6 @@ unsigned int
 radix_tree_gang_lookup_tag_slot(struct radix_tree_root *root, void ***results,
 		unsigned long first_index, unsigned int max_items,
 		unsigned int tag);
-unsigned long radix_tree_range_tag_if_tagged(struct radix_tree_root *root,
-		unsigned long *first_indexp, unsigned long last_index,
-		unsigned long nr_to_tag,
-		unsigned int fromtag, unsigned int totag);
 int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);
 
 static inline void radix_tree_preload_end(void)
@@ -302,39 +335,6 @@ static inline void radix_tree_preload_end(void)
 	preempt_enable();
 }
 
-/**
- * struct radix_tree_iter - radix tree iterator state
- *
- * @index:	index of current slot
- * @next_index:	one beyond the last index for this chunk
- * @tags:	bit-mask for tag-iterating
- * @shift:	shift for the node that holds our slots
- *
- * This radix tree iterator works in terms of "chunks" of slots.  A chunk is a
- * subinterval of slots contained within one radix tree leaf node.  It is
- * described by a pointer to its first slot and a struct radix_tree_iter
- * which holds the chunk's position in the tree and its size.  For tagged
- * iteration radix_tree_iter also holds the slots' bit-mask for one chosen
- * radix tree tag.
- */
-struct radix_tree_iter {
-	unsigned long	index;
-	unsigned long	next_index;
-	unsigned long	tags;
-#ifdef CONFIG_RADIX_TREE_MULTIORDER
-	unsigned int	shift;
-#endif
-};
-
-static inline unsigned int iter_shift(struct radix_tree_iter *iter)
-{
-#ifdef CONFIG_RADIX_TREE_MULTIORDER
-	return iter->shift;
-#else
-	return 0;
-#endif
-}
-
 #define RADIX_TREE_ITER_TAG_MASK	0x00FF	/* tag index in lower byte */
 #define RADIX_TREE_ITER_TAGGED		0x0100	/* lookup tagged slots */
 #define RADIX_TREE_ITER_CONTIG		0x0200	/* stop at first hole */

commit 478922e2b0f41567e4a530771bfb3f693f857d45
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Wed Dec 14 15:08:52 2016 -0800

    radix-tree: delete radix_tree_locate_item()
    
    This rather complicated function can be better implemented as an
    iterator.  It has only one caller, so move the functionality to the only
    place that needs it.  Update the test suite to follow the same pattern.
    
    Link: http://lkml.kernel.org/r/1480369871-5271-56-git-send-email-mawilcox@linuxonhyperv.com
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Acked-by: Konstantin Khlebnikov <koct9i@gmail.com>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 289d007d487b..a13d3f7c6c65 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -296,7 +296,6 @@ unsigned long radix_tree_range_tag_if_tagged(struct radix_tree_root *root,
 		unsigned long nr_to_tag,
 		unsigned int fromtag, unsigned int totag);
 int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);
-unsigned long radix_tree_locate_item(struct radix_tree_root *root, void *item);
 
 static inline void radix_tree_preload_end(void)
 {

commit 148deab223b23734069abcacb5c7118b0e7deadc
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Wed Dec 14 15:08:49 2016 -0800

    radix-tree: improve multiorder iterators
    
    This fixes several interlinked problems with the iterators in the
    presence of multiorder entries.
    
    1. radix_tree_iter_next() would only advance by one slot, which would
       result in the iterators returning the same entry more than once if
       there were sibling entries.
    
    2. radix_tree_next_slot() could return an internal pointer instead of
       a user pointer if a tagged multiorder entry was immediately followed by
       an entry of lower order.
    
    3. radix_tree_next_slot() expanded to a lot more code than it used to
       when multiorder support was compiled in.  And I wasn't comfortable with
       entry_to_node() being in a header file.
    
    Fixing radix_tree_iter_next() for the presence of sibling entries
    necessarily involves examining the contents of the radix tree, so we now
    need to pass 'slot' to radix_tree_iter_next(), and we need to change the
    calling convention so it is called *before* dropping the lock which
    protects the tree.  Also rename it to radix_tree_iter_resume(), as some
    people thought it was necessary to call radix_tree_iter_next() each time
    around the loop.
    
    radix_tree_next_slot() becomes closer to how it looked before multiorder
    support was introduced.  It only checks to see if the next entry in the
    chunk is a sibling entry or a pointer to a node; this should be rare
    enough that handling this case out of line is not a performance impact
    (and such impact is amortised by the fact that the entry we just
    processed was a multiorder entry).  Also, radix_tree_next_slot() used to
    force a new chunk lookup for untagged entries, which is more expensive
    than the out of line sibling entry skipping.
    
    Link: http://lkml.kernel.org/r/1480369871-5271-55-git-send-email-mawilcox@linuxonhyperv.com
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index d04073ac3a9f..289d007d487b 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -403,20 +403,17 @@ __radix_tree_iter_add(struct radix_tree_iter *iter, unsigned long slots)
 }
 
 /**
- * radix_tree_iter_next - resume iterating when the chunk may be invalid
- * @iter:	iterator state
+ * radix_tree_iter_resume - resume iterating when the chunk may be invalid
+ * @slot: pointer to current slot
+ * @iter: iterator state
+ * Returns: New slot pointer
  *
  * If the iterator needs to release then reacquire a lock, the chunk may
  * have been invalidated by an insertion or deletion.  Call this function
- * to continue the iteration from the next index.
+ * before releasing the lock to continue the iteration from the next index.
  */
-static inline __must_check
-void **radix_tree_iter_next(struct radix_tree_iter *iter)
-{
-	iter->next_index = __radix_tree_iter_add(iter, 1);
-	iter->tags = 0;
-	return NULL;
-}
+void **__must_check radix_tree_iter_resume(void **slot,
+					struct radix_tree_iter *iter);
 
 /**
  * radix_tree_chunk_size - get current chunk size
@@ -430,10 +427,17 @@ radix_tree_chunk_size(struct radix_tree_iter *iter)
 	return (iter->next_index - iter->index) >> iter_shift(iter);
 }
 
-static inline struct radix_tree_node *entry_to_node(void *ptr)
+#ifdef CONFIG_RADIX_TREE_MULTIORDER
+void ** __radix_tree_next_slot(void **slot, struct radix_tree_iter *iter,
+				unsigned flags);
+#else
+/* Can't happen without sibling entries, but the compiler can't tell that */
+static inline void ** __radix_tree_next_slot(void **slot,
+				struct radix_tree_iter *iter, unsigned flags)
 {
-	return (void *)((unsigned long)ptr & ~RADIX_TREE_INTERNAL_NODE);
+	return slot;
 }
+#endif
 
 /**
  * radix_tree_next_slot - find next slot in chunk
@@ -447,7 +451,7 @@ static inline struct radix_tree_node *entry_to_node(void *ptr)
  * For tagged lookup it also eats @iter->tags.
  *
  * There are several cases where 'slot' can be passed in as NULL to this
- * function.  These cases result from the use of radix_tree_iter_next() or
+ * function.  These cases result from the use of radix_tree_iter_resume() or
  * radix_tree_iter_retry().  In these cases we don't end up dereferencing
  * 'slot' because either:
  * a) we are doing tagged iteration and iter->tags has been set to 0, or
@@ -458,51 +462,31 @@ static __always_inline void **
 radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 {
 	if (flags & RADIX_TREE_ITER_TAGGED) {
-		void *canon = slot;
-
 		iter->tags >>= 1;
 		if (unlikely(!iter->tags))
 			return NULL;
-		while (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
-					radix_tree_is_internal_node(slot[1])) {
-			if (entry_to_node(slot[1]) == canon) {
-				iter->tags >>= 1;
-				iter->index = __radix_tree_iter_add(iter, 1);
-				slot++;
-				continue;
-			}
-			iter->next_index = __radix_tree_iter_add(iter, 1);
-			return NULL;
-		}
 		if (likely(iter->tags & 1ul)) {
 			iter->index = __radix_tree_iter_add(iter, 1);
-			return slot + 1;
+			slot++;
+			goto found;
 		}
 		if (!(flags & RADIX_TREE_ITER_CONTIG)) {
 			unsigned offset = __ffs(iter->tags);
 
-			iter->tags >>= offset;
-			iter->index = __radix_tree_iter_add(iter, offset + 1);
-			return slot + offset + 1;
+			iter->tags >>= offset++;
+			iter->index = __radix_tree_iter_add(iter, offset);
+			slot += offset;
+			goto found;
 		}
 	} else {
 		long count = radix_tree_chunk_size(iter);
-		void *canon = slot;
 
 		while (--count > 0) {
 			slot++;
 			iter->index = __radix_tree_iter_add(iter, 1);
 
-			if (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
-			    radix_tree_is_internal_node(*slot)) {
-				if (entry_to_node(*slot) == canon)
-					continue;
-				iter->next_index = iter->index;
-				break;
-			}
-
 			if (likely(*slot))
-				return slot;
+				goto found;
 			if (flags & RADIX_TREE_ITER_CONTIG) {
 				/* forbid switching to the next chunk */
 				iter->next_index = 0;
@@ -511,6 +495,11 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 		}
 	}
 	return NULL;
+
+ found:
+	if (unlikely(radix_tree_is_internal_node(*slot)))
+		return __radix_tree_next_slot(slot, iter, flags);
+	return slot;
 }
 
 /**
@@ -561,6 +550,6 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 	     slot || (slot = radix_tree_next_chunk(root, iter,		\
 			      RADIX_TREE_ITER_TAGGED | tag)) ;		\
 	     slot = radix_tree_next_slot(slot, iter,			\
-				RADIX_TREE_ITER_TAGGED))
+				RADIX_TREE_ITER_TAGGED | tag))
 
 #endif /* _LINUX_RADIX_TREE_H */

commit 91d9c05ac6c788531136888d31ef18c6a0ec160f
Author: Matthew Wilcox <willy@infradead.org>
Date:   Wed Dec 14 15:08:34 2016 -0800

    radix-tree: move rcu_head into a union with private_list
    
    I want to be able to reference node->parent after freeing node.
    
    Currently node->parent is in a union with rcu_head, so it is overwritten
    when the node is put on the RCU list.  We know that private_list is not
    referenced after the node is freed, so it is safe for these two members
    to share space.
    
    Link: http://lkml.kernel.org/r/1480369871-5271-50-git-send-email-mawilcox@linuxonhyperv.com
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 744486057e9e..d04073ac3a9f 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -85,18 +85,12 @@ struct radix_tree_node {
 	unsigned char	offset;		/* Slot offset in parent */
 	unsigned char	count;		/* Total entry count */
 	unsigned char	exceptional;	/* Exceptional entry count */
+	struct radix_tree_node *parent;		/* Used when ascending tree */
+	void *private_data;			/* For tree user */
 	union {
-		struct {
-			/* Used when ascending tree */
-			struct radix_tree_node *parent;
-			/* For tree user */
-			void *private_data;
-		};
-		/* Used when freeing node */
-		struct rcu_head	rcu_head;
+		struct list_head private_list;	/* For tree user */
+		struct rcu_head	rcu_head;	/* Used when freeing node */
 	};
-	/* For tree user */
-	struct list_head private_list;
 	void __rcu	*slots[RADIX_TREE_MAP_SIZE];
 	unsigned long	tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];
 };

commit 14b468791fa955d442f962fdf5207dfd39a131c8
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Mon Dec 12 16:43:52 2016 -0800

    mm: workingset: move shadow entry tracking to radix tree exceptional tracking
    
    Currently, we track the shadow entries in the page cache in the upper
    bits of the radix_tree_node->count, behind the back of the radix tree
    implementation.  Because the radix tree code has no awareness of them,
    we rely on random subtleties throughout the implementation (such as the
    node->count != 1 check in the shrinking code, which is meant to exclude
    multi-entry nodes but also happens to skip nodes with only one shadow
    entry, as that's accounted in the upper bits).  This is error prone and
    has, in fact, caused the bug fixed in d3798ae8c6f3 ("mm: filemap: don't
    plant shadow entries without radix tree node").
    
    To remove these subtleties, this patch moves shadow entry tracking from
    the upper bits of node->count to the existing counter for exceptional
    entries.  node->count goes back to being a simple counter of valid
    entries in the tree node and can be shrunk to a single byte.
    
    This vastly simplifies the page cache code.  All accounting happens
    natively inside the radix tree implementation, and maintaining the LRU
    linkage of shadow nodes is consolidated into a single function in the
    workingset code that is called for leaf nodes affected by a change in
    the page cache tree.
    
    This also removes the last user of the __radix_delete_node() return
    value.  Eliminate it.
    
    Link: http://lkml.kernel.org/r/20161117193211.GE23430@cmpxchg.org
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Matthew Wilcox <mawilcox@linuxonhyperv.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 15c972ea9510..744486057e9e 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -80,14 +80,10 @@ static inline bool radix_tree_is_internal_node(void *ptr)
 #define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \
 					  RADIX_TREE_MAP_SHIFT))
 
-/* Internally used bits of node->count */
-#define RADIX_TREE_COUNT_SHIFT	(RADIX_TREE_MAP_SHIFT + 1)
-#define RADIX_TREE_COUNT_MASK	((1UL << RADIX_TREE_COUNT_SHIFT) - 1)
-
 struct radix_tree_node {
 	unsigned char	shift;		/* Bits remaining in each slot */
 	unsigned char	offset;		/* Slot offset in parent */
-	unsigned int	count;		/* Total entry count */
+	unsigned char	count;		/* Total entry count */
 	unsigned char	exceptional;	/* Exceptional entry count */
 	union {
 		struct {
@@ -270,7 +266,7 @@ void __radix_tree_replace(struct radix_tree_root *root,
 			  radix_tree_update_node_t update_node, void *private);
 void radix_tree_replace_slot(struct radix_tree_root *root,
 			     void **slot, void *item);
-bool __radix_tree_delete_node(struct radix_tree_root *root,
+void __radix_tree_delete_node(struct radix_tree_root *root,
 			      struct radix_tree_node *node);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);

commit 4d693d08607ab319095ec8942909df4b4aebdf66
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Mon Dec 12 16:43:49 2016 -0800

    lib: radix-tree: update callback for changing leaf nodes
    
    Support handing __radix_tree_replace() a callback that gets invoked for
    all leaf nodes that change or get freed as a result of the slot
    replacement, to assist users tracking nodes with node->private_list.
    
    This prepares for putting page cache shadow entries into the radix tree
    root again and drastically simplifying the shadow tracking.
    
    Link: http://lkml.kernel.org/r/20161117193134.GD23430@cmpxchg.org
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Suggested-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Matthew Wilcox <mawilcox@linuxonhyperv.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 2d1b9b8be983..15c972ea9510 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -263,9 +263,11 @@ void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,
 			  struct radix_tree_node **nodep, void ***slotp);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
+typedef void (*radix_tree_update_node_t)(struct radix_tree_node *, void *);
 void __radix_tree_replace(struct radix_tree_root *root,
 			  struct radix_tree_node *node,
-			  void **slot, void *item);
+			  void **slot, void *item,
+			  radix_tree_update_node_t update_node, void *private);
 void radix_tree_replace_slot(struct radix_tree_root *root,
 			     void **slot, void *item);
 bool __radix_tree_delete_node(struct radix_tree_root *root,

commit 6d75f366b9242f9b17ed7d0b0604d7460f818f21
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Mon Dec 12 16:43:43 2016 -0800

    lib: radix-tree: check accounting of existing slot replacement users
    
    The bug in khugepaged fixed earlier in this series shows that radix tree
    slot replacement is fragile; and it will become more so when not only
    NULL<->!NULL transitions need to be caught but transitions from and to
    exceptional entries as well.  We need checks.
    
    Re-implement radix_tree_replace_slot() on top of the sanity-checked
    __radix_tree_replace().  This requires existing callers to also pass the
    radix tree root, but it'll warn us when somebody replaces slots with
    contents that need proper accounting (transitions between NULL entries,
    real entries, exceptional entries) and where a replacement through the
    slot pointer would corrupt the radix tree node counts.
    
    Link: http://lkml.kernel.org/r/20161117193021.GB23430@cmpxchg.org
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Suggested-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Matthew Wilcox <mawilcox@linuxonhyperv.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 7ced8a70cc8b..2d1b9b8be983 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -249,20 +249,6 @@ static inline int radix_tree_exception(void *arg)
 	return unlikely((unsigned long)arg & RADIX_TREE_ENTRY_MASK);
 }
 
-/**
- * radix_tree_replace_slot	- replace item in a slot
- * @pslot:	pointer to slot, returned by radix_tree_lookup_slot
- * @item:	new item to store in the slot.
- *
- * For use with radix_tree_lookup_slot().  Caller must hold tree write locked
- * across slot lookup and replacement.
- */
-static inline void radix_tree_replace_slot(void **pslot, void *item)
-{
-	BUG_ON(radix_tree_is_internal_node(item));
-	rcu_assign_pointer(*pslot, item);
-}
-
 int __radix_tree_create(struct radix_tree_root *root, unsigned long index,
 			unsigned order, struct radix_tree_node **nodep,
 			void ***slotp);
@@ -280,6 +266,8 @@ void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
 void __radix_tree_replace(struct radix_tree_root *root,
 			  struct radix_tree_node *node,
 			  void **slot, void *item);
+void radix_tree_replace_slot(struct radix_tree_root *root,
+			     void **slot, void *item);
 bool __radix_tree_delete_node(struct radix_tree_root *root,
 			      struct radix_tree_node *node);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);

commit f7942430e40f14c6d2ca48a1875add509938c07d
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Mon Dec 12 16:43:41 2016 -0800

    lib: radix-tree: native accounting of exceptional entries
    
    The way the page cache is sneaking shadow entries of evicted pages into
    the radix tree past the node entry accounting and tracking them manually
    in the upper bits of node->count is fraught with problems.
    
    These shadow entries are marked in the tree as exceptional entries,
    which are a native concept to the radix tree.  Maintain an explicit
    counter of exceptional entries in the radix tree node.  Subsequent
    patches will switch shadow entry tracking over to that counter.
    
    DAX and shmem are the other users of exceptional entries.  Since slot
    replacements that change the entry type from regular to exceptional must
    now be accounted, introduce a __radix_tree_replace() function that does
    replacement and accounting, and switch DAX and shmem over.
    
    The increase in radix tree node size is temporary.  A followup patch
    switches the shadow tracking to this new scheme and we'll no longer need
    the upper bits in node->count and shrink that back to one byte.
    
    Link: http://lkml.kernel.org/r/20161117192945.GA23430@cmpxchg.org
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Matthew Wilcox <mawilcox@linuxonhyperv.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index af3581b8a451..7ced8a70cc8b 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -85,9 +85,10 @@ static inline bool radix_tree_is_internal_node(void *ptr)
 #define RADIX_TREE_COUNT_MASK	((1UL << RADIX_TREE_COUNT_SHIFT) - 1)
 
 struct radix_tree_node {
-	unsigned char	shift;	/* Bits remaining in each slot */
-	unsigned char	offset;	/* Slot offset in parent */
-	unsigned int	count;
+	unsigned char	shift;		/* Bits remaining in each slot */
+	unsigned char	offset;		/* Slot offset in parent */
+	unsigned int	count;		/* Total entry count */
+	unsigned char	exceptional;	/* Exceptional entry count */
 	union {
 		struct {
 			/* Used when ascending tree */
@@ -276,6 +277,9 @@ void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,
 			  struct radix_tree_node **nodep, void ***slotp);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
+void __radix_tree_replace(struct radix_tree_root *root,
+			  struct radix_tree_node *node,
+			  void **slot, void *item);
 bool __radix_tree_delete_node(struct radix_tree_root *root,
 			      struct radix_tree_node *node);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);

commit 915045fe15a5fc376f263d594aee4fca4fba5323
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Tue Oct 11 13:51:18 2016 -0700

    radix-tree: 'slot' can be NULL in radix_tree_next_slot()
    
    There are four cases I can see where we could end up with a NULL 'slot' in
    radix_tree_next_slot().  Yet radix_tree_next_slot() never actually checks
    whether 'slot' is NULL.  It just happens that for the cases where 'slot'
    is NULL, some other combination of factors prevents us from dereferencing
    it.
    
    It would be very easy for someone to unwittingly change one of these
    factors without realizing that we are implicitly depending on it to save
    us from a NULL pointer dereference.
    
    Add a comment documenting the things that allow 'slot' to be safely passed
    as NULL to radix_tree_next_slot().
    
    Here are details on the four cases:
    
    1) radix_tree_iter_retry() via a non-tagged iteration like
    radix_tree_for_each_slot().  In this case we currently aren't seeing a bug
    because radix_tree_iter_retry() sets
    
            iter->next_index = iter->index;
    
    which means that in in the else case in radix_tree_next_slot(), 'count' is
    zero, so we skip over the while() loop and effectively just return NULL
    without ever dereferencing 'slot'.
    
    2) radix_tree_iter_retry() via tagged iteration like
    radix_tree_for_each_tagged().  This case was giving us NULL pointer
    dereferences in testing, and was fixed with this commit:
    
    commit 3cb9185c6730 ("radix-tree: fix radix_tree_iter_retry() for tagged
    iterators.")
    
    This fix doesn't explicitly check for 'slot' being NULL, though, it works
    around the NULL pointer dereference by instead zeroing iter->tags in
    radix_tree_iter_retry(), which makes us bail out of the if() case in
    radix_tree_next_slot() before we dereference 'slot'.
    
    3) radix_tree_iter_next() via via a non-tagged iteration like
    radix_tree_for_each_slot().  This currently happens in shmem_tag_pins()
    and shmem_partial_swap_usage().
    
    As with non-tagged iteration, 'count' in the else case of
    radix_tree_next_slot() is zero, so we skip over the while() loop and
    effectively just return NULL without ever dereferencing 'slot'.
    
    4) radix_tree_iter_next() via tagged iteration like
    radix_tree_for_each_tagged().  This happens in shmem_wait_for_pins().
    
    radix_tree_iter_next() zeros out iter->tags, so we end up exiting
    radix_tree_next_slot() here:
    
            if (flags & RADIX_TREE_ITER_TAGGED) {
                    void *canon = slot;
    
                    iter->tags >>= 1;
                    if (unlikely(!iter->tags))
                            return NULL;
    
    Link: http://lkml.kernel.org/r/20160815194237.25967-2-ross.zwisler@linux.intel.com
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 52b97db93830..af3581b8a451 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -461,6 +461,14 @@ static inline struct radix_tree_node *entry_to_node(void *ptr)
  *
  * This function updates @iter->index in the case of a successful lookup.
  * For tagged lookup it also eats @iter->tags.
+ *
+ * There are several cases where 'slot' can be passed in as NULL to this
+ * function.  These cases result from the use of radix_tree_iter_next() or
+ * radix_tree_iter_retry().  In these cases we don't end up dereferencing
+ * 'slot' because either:
+ * a) we are doing tagged iteration and iter->tags has been set to 0, or
+ * b) we are doing non-tagged iteration, and iter->index and iter->next_index
+ *    have been set up so that radix_tree_chunk_size() returns 1 or 0.
  */
 static __always_inline void **
 radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)

commit d3798ae8c6f3767c726403c2ca6ecc317752c9dd
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Tue Oct 4 22:02:08 2016 +0200

    mm: filemap: don't plant shadow entries without radix tree node
    
    When the underflow checks were added to workingset_node_shadow_dec(),
    they triggered immediately:
    
      kernel BUG at ./include/linux/swap.h:276!
      invalid opcode: 0000 [#1] SMP
      Modules linked in: isofs usb_storage fuse xt_CHECKSUM ipt_MASQUERADE nf_nat_masquerade_ipv4 tun nf_conntrack_netbios_ns nf_conntrack_broadcast ip6t_REJECT nf_reject_ipv6
       soundcore wmi acpi_als pinctrl_sunrisepoint kfifo_buf tpm_tis industrialio acpi_pad pinctrl_intel tpm_tis_core tpm nfsd auth_rpcgss nfs_acl lockd grace sunrpc dm_crypt
      CPU: 0 PID: 20929 Comm: blkid Not tainted 4.8.0-rc8-00087-gbe67d60ba944 #1
      Hardware name: System manufacturer System Product Name/Z170-K, BIOS 1803 05/06/2016
      task: ffff8faa93ecd940 task.stack: ffff8faa7f478000
      RIP: page_cache_tree_insert+0xf1/0x100
      Call Trace:
        __add_to_page_cache_locked+0x12e/0x270
        add_to_page_cache_lru+0x4e/0xe0
        mpage_readpages+0x112/0x1d0
        blkdev_readpages+0x1d/0x20
        __do_page_cache_readahead+0x1ad/0x290
        force_page_cache_readahead+0xaa/0x100
        page_cache_sync_readahead+0x3f/0x50
        generic_file_read_iter+0x5af/0x740
        blkdev_read_iter+0x35/0x40
        __vfs_read+0xe1/0x130
        vfs_read+0x96/0x130
        SyS_read+0x55/0xc0
        entry_SYSCALL_64_fastpath+0x13/0x8f
      Code: 03 00 48 8b 5d d8 65 48 33 1c 25 28 00 00 00 44 89 e8 75 19 48 83 c4 18 5b 41 5c 41 5d 41 5e 5d c3 0f 0b 41 bd ef ff ff ff eb d7 <0f> 0b e8 88 68 ef ff 0f 1f 84 00
      RIP  page_cache_tree_insert+0xf1/0x100
    
    This is a long-standing bug in the way shadow entries are accounted in
    the radix tree nodes. The shrinker needs to know when radix tree nodes
    contain only shadow entries, no pages, so node->count is split in half
    to count shadows in the upper bits and pages in the lower bits.
    
    Unfortunately, the radix tree implementation doesn't know of this and
    assumes all entries are in node->count. When there is a shadow entry
    directly in root->rnode and the tree is later extended, the radix tree
    implementation will copy that entry into the new node and and bump its
    node->count, i.e. increases the page count bits. Once the shadow gets
    removed and we subtract from the upper counter, node->count underflows
    and triggers the warning. Afterwards, without node->count reaching 0
    again, the radix tree node is leaked.
    
    Limit shadow entries to when we have actual radix tree nodes and can
    count them properly. That means we lose the ability to detect refaults
    from files that had only the first page faulted in at eviction time.
    
    Fixes: 449dd6984d0e ("mm: keep page cache radix tree nodes in check")
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reported-and-tested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 4c45105dece3..52b97db93830 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -280,9 +280,9 @@ bool __radix_tree_delete_node(struct radix_tree_root *root,
 			      struct radix_tree_node *node);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
-struct radix_tree_node *radix_tree_replace_clear_tags(
-				struct radix_tree_root *root,
-				unsigned long index, void *entry);
+void radix_tree_clear_tags(struct radix_tree_root *root,
+			   struct radix_tree_node *node,
+			   void **slot);
 unsigned int radix_tree_gang_lookup(struct radix_tree_root *root,
 			void **results, unsigned long first_index,
 			unsigned int max_items);

commit a23216a2f1f8a30a3b6588c743681651e4a6aa94
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Tue Aug 2 14:04:19 2016 -0700

    radix-tree: fix comment about "exceptional" bits
    
    The bottom two bits of radix tree entries are reserved for special use
    by the radix tree code itself.  A comment detailing their usage was
    added by commit 3bcadd6fa6c4 ("radix-tree: free up the bottom bit of
    exceptional entries for reuse")
    
    This comment states that if the bottom two bits are '11', this means
    that this is a locked exceptional entry.
    
    It turns out that this bit combination was never actually used.  Radix
    tree locking for DAX was indeed implemented, but it actually used the
    third LSB:
    
      /* We use lowest available exceptional entry bit for locking */
      #define RADIX_DAX_ENTRY_LOCK (1 << RADIX_TREE_EXCEPTIONAL_SHIFT)
    
    This locking code was also made specific to the DAX code instead of
    being generally implemented in radix-tree.h.
    
    So, fix the comment.
    
    Link: http://lkml.kernel.org/r/1468997731-2155-1-git-send-email-ross.zwisler@linux.intel.com
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index cbfee507c839..4c45105dece3 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -35,7 +35,7 @@
  * 00 - data pointer
  * 01 - internal entry
  * 10 - exceptional entry
- * 11 - locked exceptional entry
+ * 11 - this bit combination is currently unused/reserved
  *
  * The internal entry may be a pointer to the next level in the tree, a
  * sibling entry, or an indicator that the entry in this slot has been moved

commit c78c66d1ddfdbd2353f3fcfeba0268524537b096
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:26:02 2016 -0700

    radix-tree: implement radix_tree_maybe_preload_order()
    
    The new helper is similar to radix_tree_maybe_preload(), but tries to
    preload number of nodes required to insert (1 << order) continuous
    naturally-aligned elements.
    
    This is required to push huge pages into pagecache.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-24-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index eca6f626c16e..cbfee507c839 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -291,6 +291,7 @@ unsigned int radix_tree_gang_lookup_slot(struct radix_tree_root *root,
 			unsigned long first_index, unsigned int max_items);
 int radix_tree_preload(gfp_t gfp_mask);
 int radix_tree_maybe_preload(gfp_t gfp_mask);
+int radix_tree_maybe_preload_order(gfp_t gfp_mask, int order);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *root,
 			unsigned long index, unsigned int tag);

commit 3cb9185c67304b2a7ea9be73e7d13df6fb2793a1
Author: Andrey Ryabinin <aryabinin@virtuozzo.com>
Date:   Wed Jul 20 15:45:00 2016 -0700

    radix-tree: fix radix_tree_iter_retry() for tagged iterators.
    
    radix_tree_iter_retry() resets slot to NULL, but it doesn't reset tags.
    Then NULL slot and non-zero iter.tags passed to radix_tree_next_slot()
    leading to crash:
    
      RIP: radix_tree_next_slot include/linux/radix-tree.h:473
        find_get_pages_tag+0x334/0x930 mm/filemap.c:1452
      ....
      Call Trace:
        pagevec_lookup_tag+0x3a/0x80 mm/swap.c:960
        mpage_prepare_extent_to_map+0x321/0xa90 fs/ext4/inode.c:2516
        ext4_writepages+0x10be/0x2b20 fs/ext4/inode.c:2736
        do_writepages+0x97/0x100 mm/page-writeback.c:2364
        __filemap_fdatawrite_range+0x248/0x2e0 mm/filemap.c:300
        filemap_write_and_wait_range+0x121/0x1b0 mm/filemap.c:490
        ext4_sync_file+0x34d/0xdb0 fs/ext4/fsync.c:115
        vfs_fsync_range+0x10a/0x250 fs/sync.c:195
        vfs_fsync fs/sync.c:209
        do_fsync+0x42/0x70 fs/sync.c:219
        SYSC_fdatasync fs/sync.c:232
        SyS_fdatasync+0x19/0x20 fs/sync.c:230
        entry_SYSCALL_64_fastpath+0x23/0xc1 arch/x86/entry/entry_64.S:207
    
    We must reset iterator's tags to bail out from radix_tree_next_slot()
    and go to the slow-path in radix_tree_next_chunk().
    
    Fixes: 46437f9a554f ("radix-tree: fix race in gang lookup")
    Link: http://lkml.kernel.org/r/1468495196-10604-1-git-send-email-aryabinin@virtuozzo.com
    Signed-off-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Acked-by: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index cb4b7e8cee81..eca6f626c16e 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -407,6 +407,7 @@ static inline __must_check
 void **radix_tree_iter_retry(struct radix_tree_iter *iter)
 {
 	iter->next_index = iter->index;
+	iter->tags = 0;
 	return NULL;
 }
 

commit 3bcadd6fa6c4fd07ace3626357c824eb532488a6
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:54 2016 -0700

    radix-tree: free up the bottom bit of exceptional entries for reuse
    
    We are guaranteed that pointers to radix_tree_nodes always have the
    bottom two bits clear (because they come from a slab cache, and slab
    caches have a minimum alignment of sizeof(void *)), so we can redefine
    'radix_tree_is_internal_node' to only return true if the bottom two bits
    have value '01'.  This frees up one quarter of the potential values for
    use by the user.
    
    Idea from Neil Brown.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Suggested-by: Neil Brown <neilb@suse.de>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index c2f69e25ba86..cb4b7e8cee81 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -29,28 +29,37 @@
 #include <linux/rcupdate.h>
 
 /*
- * Entries in the radix tree have the low bit set if they refer to a
- * radix_tree_node.  If the low bit is clear then the entry is user data.
- *
- * We also use the low bit to indicate that the slot will be freed in the
- * next RCU idle period, and users need to re-walk the tree to find the
- * new slot for the index that they were looking for.  See the comment in
- * radix_tree_shrink() for details.
+ * The bottom two bits of the slot determine how the remaining bits in the
+ * slot are interpreted:
+ *
+ * 00 - data pointer
+ * 01 - internal entry
+ * 10 - exceptional entry
+ * 11 - locked exceptional entry
+ *
+ * The internal entry may be a pointer to the next level in the tree, a
+ * sibling entry, or an indicator that the entry in this slot has been moved
+ * to another location in the tree and the lookup should be restarted.  While
+ * NULL fits the 'data pointer' pattern, it means that there is no entry in
+ * the tree for this index (no matter what level of the tree it is found at).
+ * This means that you cannot store NULL in the tree as a value for the index.
  */
-#define RADIX_TREE_INTERNAL_NODE	1
+#define RADIX_TREE_ENTRY_MASK		3UL
+#define RADIX_TREE_INTERNAL_NODE	1UL
 
 /*
- * A common use of the radix tree is to store pointers to struct pages;
- * but shmem/tmpfs needs also to store swap entries in the same tree:
- * those are marked as exceptional entries to distinguish them.
+ * Most users of the radix tree store pointers but shmem/tmpfs stores swap
+ * entries in the same tree.  They are marked as exceptional entries to
+ * distinguish them from pointers to struct page.
  * EXCEPTIONAL_ENTRY tests the bit, EXCEPTIONAL_SHIFT shifts content past it.
  */
 #define RADIX_TREE_EXCEPTIONAL_ENTRY	2
 #define RADIX_TREE_EXCEPTIONAL_SHIFT	2
 
-static inline int radix_tree_is_internal_node(void *ptr)
+static inline bool radix_tree_is_internal_node(void *ptr)
 {
-	return (int)((unsigned long)ptr & RADIX_TREE_INTERNAL_NODE);
+	return ((unsigned long)ptr & RADIX_TREE_ENTRY_MASK) ==
+				RADIX_TREE_INTERNAL_NODE;
 }
 
 /*** radix-tree API starts here ***/
@@ -236,8 +245,7 @@ static inline int radix_tree_exceptional_entry(void *arg)
  */
 static inline int radix_tree_exception(void *arg)
 {
-	return unlikely((unsigned long)arg &
-		(RADIX_TREE_INTERNAL_NODE | RADIX_TREE_EXCEPTIONAL_ENTRY));
+	return unlikely((unsigned long)arg & RADIX_TREE_ENTRY_MASK);
 }
 
 /**

commit 78a9be0a0a3367b94af242632c525d22b26f1a87
Author: NeilBrown <neilb@suse.com>
Date:   Fri May 20 17:03:51 2016 -0700

    dax: move RADIX_DAX_ definitions to dax.c
    
    These don't belong in radix-tree.h any more than PAGECACHE_TAG_* do.
    Let's try to maintain the idea that radix-tree simply implements an
    abstract data type.
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 11c8e7cc3920..c2f69e25ba86 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -48,15 +48,6 @@
 #define RADIX_TREE_EXCEPTIONAL_ENTRY	2
 #define RADIX_TREE_EXCEPTIONAL_SHIFT	2
 
-#define RADIX_DAX_MASK	0xf
-#define RADIX_DAX_SHIFT	4
-#define RADIX_DAX_PTE  (0x4 | RADIX_TREE_EXCEPTIONAL_ENTRY)
-#define RADIX_DAX_PMD  (0x8 | RADIX_TREE_EXCEPTIONAL_ENTRY)
-#define RADIX_DAX_TYPE(entry) ((unsigned long)entry & RADIX_DAX_MASK)
-#define RADIX_DAX_SECTOR(entry) (((unsigned long)entry >> RADIX_DAX_SHIFT))
-#define RADIX_DAX_ENTRY(sector, pmd) ((void *)((unsigned long)sector << \
-		RADIX_DAX_SHIFT | (pmd ? RADIX_DAX_PMD : RADIX_DAX_PTE)))
-
 static inline int radix_tree_is_internal_node(void *ptr)
 {
 	return (int)((unsigned long)ptr & RADIX_TREE_INTERNAL_NODE);

commit d604c324524bf61c68182bb27db64656a78fe911
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:45 2016 -0700

    radix-tree: introduce radix_tree_replace_clear_tags()
    
    In addition to replacing the entry, we also clear all associated tags.
    This is really a one-off special for page_cache_tree_delete() which had
    far too much detailed knowledge about how the radix tree works.
    
    For efficiency, factor node_tag_clear() out of radix_tree_tag_clear() It
    can be used by radix_tree_delete_item() as well as
    radix_tree_replace_clear_tags().
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index bad63105e37e..11c8e7cc3920 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -281,9 +281,12 @@ bool __radix_tree_delete_node(struct radix_tree_root *root,
 			      struct radix_tree_node *node);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
-unsigned int
-radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
-			unsigned long first_index, unsigned int max_items);
+struct radix_tree_node *radix_tree_replace_clear_tags(
+				struct radix_tree_root *root,
+				unsigned long index, void *entry);
+unsigned int radix_tree_gang_lookup(struct radix_tree_root *root,
+			void **results, unsigned long first_index,
+			unsigned int max_items);
 unsigned int radix_tree_gang_lookup_slot(struct radix_tree_root *root,
 			void ***results, unsigned long *indices,
 			unsigned long first_index, unsigned int max_items);

commit b194d16c27af905d6e3552f4851bc7d9fee4e90f
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:30 2016 -0700

    radix-tree: rename radix_tree_is_indirect_ptr()
    
    As with indirect_to_ptr(), ptr_to_indirect() and
    RADIX_TREE_INDIRECT_PTR, change radix_tree_is_indirect_ptr() to
    radix_tree_is_internal_node().
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index b94aa198dd6b..bad63105e37e 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -57,7 +57,7 @@
 #define RADIX_DAX_ENTRY(sector, pmd) ((void *)((unsigned long)sector << \
 		RADIX_DAX_SHIFT | (pmd ? RADIX_DAX_PMD : RADIX_DAX_PTE)))
 
-static inline int radix_tree_is_indirect_ptr(void *ptr)
+static inline int radix_tree_is_internal_node(void *ptr)
 {
 	return (int)((unsigned long)ptr & RADIX_TREE_INTERNAL_NODE);
 }
@@ -224,7 +224,7 @@ static inline void *radix_tree_deref_slot_protected(void **pslot,
  */
 static inline int radix_tree_deref_retry(void *arg)
 {
-	return unlikely(radix_tree_is_indirect_ptr(arg));
+	return unlikely(radix_tree_is_internal_node(arg));
 }
 
 /**
@@ -259,7 +259,7 @@ static inline int radix_tree_exception(void *arg)
  */
 static inline void radix_tree_replace_slot(void **pslot, void *item)
 {
-	BUG_ON(radix_tree_is_indirect_ptr(item));
+	BUG_ON(radix_tree_is_internal_node(item));
 	rcu_assign_pointer(*pslot, item);
 }
 
@@ -468,7 +468,7 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 		if (unlikely(!iter->tags))
 			return NULL;
 		while (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
-					radix_tree_is_indirect_ptr(slot[1])) {
+					radix_tree_is_internal_node(slot[1])) {
 			if (entry_to_node(slot[1]) == canon) {
 				iter->tags >>= 1;
 				iter->index = __radix_tree_iter_add(iter, 1);
@@ -498,7 +498,7 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 			iter->index = __radix_tree_iter_add(iter, 1);
 
 			if (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
-			    radix_tree_is_indirect_ptr(*slot)) {
+			    radix_tree_is_internal_node(*slot)) {
 				if (entry_to_node(*slot) == canon)
 					continue;
 				iter->next_index = iter->index;

commit 4dd6c0987ca43d6544f4f0a3f86f6ea3bfc60fc1
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:27 2016 -0700

    radix-tree: rename indirect_to_ptr() to entry_to_node()
    
    Mirrors the earlier commit introducing node_to_entry().
    
    Also change the type returned to be a struct radix_tree_node pointer.
    That lets us simplify a couple of places in the radix tree shrink &
    extend paths where we could convert an entry into a pointer, modify the
    node, then convert the pointer back into an entry.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index c8cc879046c7..b94aa198dd6b 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -442,7 +442,7 @@ radix_tree_chunk_size(struct radix_tree_iter *iter)
 	return (iter->next_index - iter->index) >> iter_shift(iter);
 }
 
-static inline void *indirect_to_ptr(void *ptr)
+static inline struct radix_tree_node *entry_to_node(void *ptr)
 {
 	return (void *)((unsigned long)ptr & ~RADIX_TREE_INTERNAL_NODE);
 }
@@ -469,7 +469,7 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 			return NULL;
 		while (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
 					radix_tree_is_indirect_ptr(slot[1])) {
-			if (indirect_to_ptr(slot[1]) == canon) {
+			if (entry_to_node(slot[1]) == canon) {
 				iter->tags >>= 1;
 				iter->index = __radix_tree_iter_add(iter, 1);
 				slot++;
@@ -499,12 +499,10 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 
 			if (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
 			    radix_tree_is_indirect_ptr(*slot)) {
-				if (indirect_to_ptr(*slot) == canon)
+				if (entry_to_node(*slot) == canon)
 					continue;
-				else {
-					iter->next_index = iter->index;
-					break;
-				}
+				iter->next_index = iter->index;
+				break;
 			}
 
 			if (likely(*slot))

commit 30ff46ccb303fb6f6c28b9aa9f2cdc4ba900ed3f
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:22 2016 -0700

    radix-tree: rename INDIRECT_PTR to INTERNAL_NODE
    
    The name RADIX_TREE_INDIRECT_PTR doesn't really match the meaning.
    RADIX_TREE_INTERNAL_NODE is a better name.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index c0d223cfac00..c8cc879046c7 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -29,20 +29,16 @@
 #include <linux/rcupdate.h>
 
 /*
- * An indirect pointer (root->rnode pointing to a radix_tree_node, rather
- * than a data item) is signalled by the low bit set in the root->rnode
- * pointer.
- *
- * In this case root->height is > 0, but the indirect pointer tests are
- * needed for RCU lookups (because root->height is unreliable). The only
- * time callers need worry about this is when doing a lookup_slot under
- * RCU.
- *
- * Indirect pointer in fact is also used to tag the last pointer of a node
- * when it is shrunk, before we rcu free the node. See shrink code for
- * details.
+ * Entries in the radix tree have the low bit set if they refer to a
+ * radix_tree_node.  If the low bit is clear then the entry is user data.
+ *
+ * We also use the low bit to indicate that the slot will be freed in the
+ * next RCU idle period, and users need to re-walk the tree to find the
+ * new slot for the index that they were looking for.  See the comment in
+ * radix_tree_shrink() for details.
  */
-#define RADIX_TREE_INDIRECT_PTR		1
+#define RADIX_TREE_INTERNAL_NODE	1
+
 /*
  * A common use of the radix tree is to store pointers to struct pages;
  * but shmem/tmpfs needs also to store swap entries in the same tree:
@@ -63,7 +59,7 @@
 
 static inline int radix_tree_is_indirect_ptr(void *ptr)
 {
-	return (int)((unsigned long)ptr & RADIX_TREE_INDIRECT_PTR);
+	return (int)((unsigned long)ptr & RADIX_TREE_INTERNAL_NODE);
 }
 
 /*** radix-tree API starts here ***/
@@ -228,7 +224,7 @@ static inline void *radix_tree_deref_slot_protected(void **pslot,
  */
 static inline int radix_tree_deref_retry(void *arg)
 {
-	return unlikely((unsigned long)arg & RADIX_TREE_INDIRECT_PTR);
+	return unlikely(radix_tree_is_indirect_ptr(arg));
 }
 
 /**
@@ -250,7 +246,7 @@ static inline int radix_tree_exceptional_entry(void *arg)
 static inline int radix_tree_exception(void *arg)
 {
 	return unlikely((unsigned long)arg &
-		(RADIX_TREE_INDIRECT_PTR | RADIX_TREE_EXCEPTIONAL_ENTRY));
+		(RADIX_TREE_INTERNAL_NODE | RADIX_TREE_EXCEPTIONAL_ENTRY));
 }
 
 /**
@@ -448,7 +444,7 @@ radix_tree_chunk_size(struct radix_tree_iter *iter)
 
 static inline void *indirect_to_ptr(void *ptr)
 {
-	return (void *)((unsigned long)ptr & ~RADIX_TREE_INDIRECT_PTR);
+	return (void *)((unsigned long)ptr & ~RADIX_TREE_INTERNAL_NODE);
 }
 
 /**

commit d0891265bbc988dc91ed8580b38eb3dac128581b
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:19 2016 -0700

    radix-tree: remove root->height
    
    The only remaining references to root->height were in extend and shrink,
    where it was updated.  Now we can remove it entirely.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 037458257e12..c0d223cfac00 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -110,13 +110,11 @@ struct radix_tree_node {
 
 /* root tags are stored in gfp_mask, shifted by __GFP_BITS_SHIFT */
 struct radix_tree_root {
-	unsigned int		height;
 	gfp_t			gfp_mask;
 	struct radix_tree_node	__rcu *rnode;
 };
 
 #define RADIX_TREE_INIT(mask)	{					\
-	.height = 0,							\
 	.gfp_mask = (mask),						\
 	.rnode = NULL,							\
 }
@@ -126,7 +124,6 @@ struct radix_tree_root {
 
 #define INIT_RADIX_TREE(root, mask)					\
 do {									\
-	(root)->height = 0;						\
 	(root)->gfp_mask = (mask);					\
 	(root)->rnode = NULL;						\
 } while (0)

commit c12e51b07b3ac4c188fd91a82f96840fdb9cca6f
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:10 2016 -0700

    radix-tree: replace node->height with node->shift
    
    node->shift represents the shift necessary for looking in the slots
    array at this level.  It is equal to the old (node->height - 1) *
    RADIX_TREE_MAP_SHIFT.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 2d2ad9d685a3..037458257e12 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -89,7 +89,7 @@ static inline int radix_tree_is_indirect_ptr(void *ptr)
 #define RADIX_TREE_COUNT_MASK	((1UL << RADIX_TREE_COUNT_SHIFT) - 1)
 
 struct radix_tree_node {
-	unsigned char	height;	/* From the bottom */
+	unsigned char	shift;	/* Bits remaining in each slot */
 	unsigned char	offset;	/* Slot offset in parent */
 	unsigned int	count;
 	union {

commit 0c7fa0a8418cbe0e8963fe36db9575d03b8589f7
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:03:07 2016 -0700

    radix-tree: split node->path into offset and height
    
    Neither piece of information we're storing in node->path can be larger
    than 64, so store each in its own unsigned char instead of shifting and
    masking to store them both in an unsigned int.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 8558d52e1c7b..2d2ad9d685a3 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -84,16 +84,13 @@ static inline int radix_tree_is_indirect_ptr(void *ptr)
 #define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \
 					  RADIX_TREE_MAP_SHIFT))
 
-/* Height component in node->path */
-#define RADIX_TREE_HEIGHT_SHIFT	(RADIX_TREE_MAX_PATH + 1)
-#define RADIX_TREE_HEIGHT_MASK	((1UL << RADIX_TREE_HEIGHT_SHIFT) - 1)
-
 /* Internally used bits of node->count */
 #define RADIX_TREE_COUNT_SHIFT	(RADIX_TREE_MAP_SHIFT + 1)
 #define RADIX_TREE_COUNT_MASK	((1UL << RADIX_TREE_COUNT_SHIFT) - 1)
 
 struct radix_tree_node {
-	unsigned int	path;	/* Offset in parent & height from the bottom */
+	unsigned char	height;	/* From the bottom */
+	unsigned char	offset;	/* Slot offset in parent */
 	unsigned int	count;
 	union {
 		struct {

commit 21ef533931f73a8e963a6107aa5ec51b192f28be
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 20 17:02:26 2016 -0700

    radix-tree: add support for multi-order iterating
    
    This enables the macros radix_tree_for_each_slot() and friends to be
    used with multi-order entries.
    
    The way that this works is that we treat all entries in a given slots[]
    array as a single chunk.  If the index given to radix_tree_next_chunk()
    happens to point us to a sibling entry, we will back up iter->index so
    that it points to the canonical entry, and that will be the place where
    we start our iteration.
    
    As we're processing a chunk in radix_tree_next_slot(), we process
    canonical entries, skip over sibling entries, and restart the chunk
    lookup if we find a non-sibling indirect pointer.  This drops back to
    the radix_tree_next_chunk() code, which will re-walk the tree and look
    for another chunk.
    
    This allows us to properly handle multi-order entries mixed with other
    entries that are at various heights in the radix tree.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index e1512a607709..8558d52e1c7b 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -330,8 +330,9 @@ static inline void radix_tree_preload_end(void)
  * struct radix_tree_iter - radix tree iterator state
  *
  * @index:	index of current slot
- * @next_index:	next-to-last index for this chunk
+ * @next_index:	one beyond the last index for this chunk
  * @tags:	bit-mask for tag-iterating
+ * @shift:	shift for the node that holds our slots
  *
  * This radix tree iterator works in terms of "chunks" of slots.  A chunk is a
  * subinterval of slots contained within one radix tree leaf node.  It is
@@ -344,8 +345,20 @@ struct radix_tree_iter {
 	unsigned long	index;
 	unsigned long	next_index;
 	unsigned long	tags;
+#ifdef CONFIG_RADIX_TREE_MULTIORDER
+	unsigned int	shift;
+#endif
 };
 
+static inline unsigned int iter_shift(struct radix_tree_iter *iter)
+{
+#ifdef CONFIG_RADIX_TREE_MULTIORDER
+	return iter->shift;
+#else
+	return 0;
+#endif
+}
+
 #define RADIX_TREE_ITER_TAG_MASK	0x00FF	/* tag index in lower byte */
 #define RADIX_TREE_ITER_TAGGED		0x0100	/* lookup tagged slots */
 #define RADIX_TREE_ITER_CONTIG		0x0200	/* stop at first hole */
@@ -405,6 +418,12 @@ void **radix_tree_iter_retry(struct radix_tree_iter *iter)
 	return NULL;
 }
 
+static inline unsigned long
+__radix_tree_iter_add(struct radix_tree_iter *iter, unsigned long slots)
+{
+	return iter->index + (slots << iter_shift(iter));
+}
+
 /**
  * radix_tree_iter_next - resume iterating when the chunk may be invalid
  * @iter:	iterator state
@@ -416,7 +435,7 @@ void **radix_tree_iter_retry(struct radix_tree_iter *iter)
 static inline __must_check
 void **radix_tree_iter_next(struct radix_tree_iter *iter)
 {
-	iter->next_index = iter->index + 1;
+	iter->next_index = __radix_tree_iter_add(iter, 1);
 	iter->tags = 0;
 	return NULL;
 }
@@ -430,7 +449,12 @@ void **radix_tree_iter_next(struct radix_tree_iter *iter)
 static __always_inline long
 radix_tree_chunk_size(struct radix_tree_iter *iter)
 {
-	return iter->next_index - iter->index;
+	return (iter->next_index - iter->index) >> iter_shift(iter);
+}
+
+static inline void *indirect_to_ptr(void *ptr)
+{
+	return (void *)((unsigned long)ptr & ~RADIX_TREE_INDIRECT_PTR);
 }
 
 /**
@@ -448,24 +472,51 @@ static __always_inline void **
 radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 {
 	if (flags & RADIX_TREE_ITER_TAGGED) {
+		void *canon = slot;
+
 		iter->tags >>= 1;
+		if (unlikely(!iter->tags))
+			return NULL;
+		while (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
+					radix_tree_is_indirect_ptr(slot[1])) {
+			if (indirect_to_ptr(slot[1]) == canon) {
+				iter->tags >>= 1;
+				iter->index = __radix_tree_iter_add(iter, 1);
+				slot++;
+				continue;
+			}
+			iter->next_index = __radix_tree_iter_add(iter, 1);
+			return NULL;
+		}
 		if (likely(iter->tags & 1ul)) {
-			iter->index++;
+			iter->index = __radix_tree_iter_add(iter, 1);
 			return slot + 1;
 		}
-		if (!(flags & RADIX_TREE_ITER_CONTIG) && likely(iter->tags)) {
+		if (!(flags & RADIX_TREE_ITER_CONTIG)) {
 			unsigned offset = __ffs(iter->tags);
 
 			iter->tags >>= offset;
-			iter->index += offset + 1;
+			iter->index = __radix_tree_iter_add(iter, offset + 1);
 			return slot + offset + 1;
 		}
 	} else {
-		long size = radix_tree_chunk_size(iter);
+		long count = radix_tree_chunk_size(iter);
+		void *canon = slot;
 
-		while (--size > 0) {
+		while (--count > 0) {
 			slot++;
-			iter->index++;
+			iter->index = __radix_tree_iter_add(iter, 1);
+
+			if (IS_ENABLED(CONFIG_RADIX_TREE_MULTIORDER) &&
+			    radix_tree_is_indirect_ptr(*slot)) {
+				if (indirect_to_ptr(*slot) == canon)
+					continue;
+				else {
+					iter->next_index = iter->index;
+					break;
+				}
+			}
+
 			if (likely(*slot))
 				return slot;
 			if (flags & RADIX_TREE_ITER_CONTIG) {

commit 6c4bd68a2962c03423a226d949caf64216d013cc
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 20 17:01:51 2016 -0700

    radix-tree: remove unused looping macros
    
    radix_tree_for_each_chunk() and radix_tree_for_each_chunk_slot() have
    never been used in the kernel since their introduction in 2012, so
    remove them.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 5ce5a1e0ecc5..e1512a607709 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -478,34 +478,6 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 	return NULL;
 }
 
-/**
- * radix_tree_for_each_chunk - iterate over chunks
- *
- * @slot:	the void** variable for pointer to chunk first slot
- * @root:	the struct radix_tree_root pointer
- * @iter:	the struct radix_tree_iter pointer
- * @start:	iteration starting index
- * @flags:	RADIX_TREE_ITER_* and tag index
- *
- * Locks can be released and reacquired between iterations.
- */
-#define radix_tree_for_each_chunk(slot, root, iter, start, flags)	\
-	for (slot = radix_tree_iter_init(iter, start) ;			\
-	      (slot = radix_tree_next_chunk(root, iter, flags)) ;)
-
-/**
- * radix_tree_for_each_chunk_slot - iterate over slots in one chunk
- *
- * @slot:	the void** variable, at the beginning points to chunk first slot
- * @iter:	the struct radix_tree_iter pointer
- * @flags:	RADIX_TREE_ITER_*, should be constant
- *
- * This macro is designed to be nested inside radix_tree_for_each_chunk().
- * @slot points to the radix tree slot, @iter->index contains its index.
- */
-#define radix_tree_for_each_chunk_slot(slot, iter, flags)		\
-	for (; slot ; slot = radix_tree_next_slot(slot, iter, flags))
-
 /**
  * radix_tree_for_each_slot - iterate over non-empty slots
  *

commit 97d778b2de9213c7a7483dad0f533c1af9f0810f
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 20 17:01:42 2016 -0700

    radix tree test suite: allow testing other fan-out values
    
    The defines in regression2.c are already in radix-tree.h and duplicating
    them in the test case makes experimenting with other values for the
    fan-out harder than necessary.  Allow the user of the radix tree to
    decide what the fan-out should be rather than fixing it to 8 for
    non-kernel uses.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 83f708e5db59..5ce5a1e0ecc5 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -70,10 +70,8 @@ static inline int radix_tree_is_indirect_ptr(void *ptr)
 
 #define RADIX_TREE_MAX_TAGS 3
 
-#ifdef __KERNEL__
+#ifndef RADIX_TREE_MAP_SHIFT
 #define RADIX_TREE_MAP_SHIFT	(CONFIG_BASE_SMALL ? 4 : 6)
-#else
-#define RADIX_TREE_MAP_SHIFT	3	/* For more stressful testing */
 #endif
 
 #define RADIX_TREE_MAP_SIZE	(1UL << RADIX_TREE_MAP_SHIFT)

commit e9256efcc8e390fa4fcf796a0c0b47d642d77d32
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Fri May 20 17:01:33 2016 -0700

    radix-tree: introduce radix_tree_empty
    
    Commit e61452365372 ("radix_tree: add support for multi-order entries")
    left the impression that the support for multiorder radix tree entries
    was functional.  As soon as Ross tried to use it, it became apparent
    that my testing was completely inadequate, and it didn't even work a
    little bit for orders that were not a multiple of shift.
    
    This series of patches is the result of about 6 weeks of redesign,
    reimplementation, testing, arguing and hair-pulling.  The great news is
    that the test-suite is now far better than it was.  That's reflected in
    the diffstat for the test-suite alone:
    
     12 files changed, 436 insertions(+), 28 deletions(-)
    
    The highlight for users of the tree is that the restriction on the order
    of inserted entries being >= RADIX_TREE_MAP_SHIFT is now gone; the radix
    tree now supports any order between 0 and 64.
    
    For those who are interested in how the tree works, patch 9 is probably
    the most interesting one as it introduces the new machinery for handling
    sibling entries.
    
    I've tried to be fair in attributing authorship to the person who
    contributed the majority of the code in each patch; Ross has been an
    invaluable partner in the development of this support and it's fair to
    say that each of us has code in every commit.
    
    I should also express my appreciation of the 0day testing.  It prompted
    me that I was bloating the tinyconfig in an unacceptable way, and it
    bisected to a commit which contained a rather nasty memory-corruption
    bug.
    
    This patch (of 29):
    
    The irqdomain code was checking for 0 or 1 entries, not 0 entries like
    the comment said they were.  Introduce a new helper that will actually
    check for an empty tree.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 51a97ac8bfbf..83f708e5db59 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -136,6 +136,11 @@ do {									\
 	(root)->rnode = NULL;						\
 } while (0)
 
+static inline bool radix_tree_empty(struct radix_tree_root *root)
+{
+	return root->rnode == NULL;
+}
+
 /**
  * Radix-tree synchronization
  *

commit 7165092fe5ca70bae722ac6cd78421cfd0eec18d
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Thu Mar 17 14:22:06 2016 -0700

    radix-tree,shmem: introduce radix_tree_iter_next()
    
    shmem likes to occasionally drop the lock, schedule, then reacqire the
    lock and continue with the iteration from the last place it left off.
    This is currently done with a pretty ugly goto.  Introduce
    radix_tree_iter_next() and use it throughout shmem.c.
    
    [koct9i@gmail.com: fix bug in radix_tree_iter_next() for tagged iteration]
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Konstantin Khlebnikov <koct9i@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index b211f145c811..51a97ac8bfbf 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -402,6 +402,22 @@ void **radix_tree_iter_retry(struct radix_tree_iter *iter)
 	return NULL;
 }
 
+/**
+ * radix_tree_iter_next - resume iterating when the chunk may be invalid
+ * @iter:	iterator state
+ *
+ * If the iterator needs to release then reacquire a lock, the chunk may
+ * have been invalidated by an insertion or deletion.  Call this function
+ * to continue the iteration from the next index.
+ */
+static inline __must_check
+void **radix_tree_iter_next(struct radix_tree_iter *iter)
+{
+	iter->next_index = iter->index + 1;
+	iter->tags = 0;
+	return NULL;
+}
+
 /**
  * radix_tree_chunk_size - get current chunk size
  *

commit e61452365372570253b2b1de84bab0cdb2e62c64
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Thu Mar 17 14:21:54 2016 -0700

    radix_tree: add support for multi-order entries
    
    With huge pages, it is convenient to have the radix tree be able to
    return an entry that covers multiple indices.  Previous attempts to deal
    with the problem have involved inserting N duplicate entries, which is a
    waste of memory and leads to problems trying to handle aliased tags, or
    probing the tree multiple times to find alternative entries which might
    cover the requested index.
    
    This approach inserts one canonical entry into the tree for a given
    range of indices, and may also insert other entries in order to ensure
    that lookups find the canonical entry.
    
    This solution only tolerates inserting powers of two that are greater
    than the fanout of the tree.  If we wish to expand the radix tree's
    abilities to support large-ish pages that is less than the fanout at the
    penultimate level of the tree, then we would need to add one more step
    in lookup to ensure that any sibling nodes in the final level of the
    tree are dereferenced and we return the canonical entry that they
    reference.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 39598b9cf1d9..b211f145c811 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -271,8 +271,15 @@ static inline void radix_tree_replace_slot(void **pslot, void *item)
 }
 
 int __radix_tree_create(struct radix_tree_root *root, unsigned long index,
-			struct radix_tree_node **nodep, void ***slotp);
-int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
+			unsigned order, struct radix_tree_node **nodep,
+			void ***slotp);
+int __radix_tree_insert(struct radix_tree_root *, unsigned long index,
+			unsigned order, void *);
+static inline int radix_tree_insert(struct radix_tree_root *root,
+			unsigned long index, void *entry)
+{
+	return __radix_tree_insert(root, index, 0, entry);
+}
 void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,
 			  struct radix_tree_node **nodep, void ***slotp);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);

commit f67c07f07fca95a7f330b8bb928eabaf9fcce75d
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Thu Mar 17 14:21:42 2016 -0700

    radix-tree: add an explicit include of bitops.h
    
    The radix-tree header uses the __ffs() function, which is defined in
    bitops.h.  The current kernel headers implicitly include bitops.h, but
    the userspace test harness does not.
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index f54be7082207..39598b9cf1d9 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -21,6 +21,7 @@
 #ifndef _LINUX_RADIX_TREE_H
 #define _LINUX_RADIX_TREE_H
 
+#include <linux/bitops.h>
 #include <linux/preempt.h>
 #include <linux/types.h>
 #include <linux/bug.h>

commit 732042821cfa106b3c20b9780e4c60fee9d68900
Author: Konstantin Khlebnikov <koct9i@gmail.com>
Date:   Fri Feb 5 15:37:01 2016 -0800

    radix-tree: fix oops after radix_tree_iter_retry
    
    Helper radix_tree_iter_retry() resets next_index to the current index.
    In following radix_tree_next_slot current chunk size becomes zero.  This
    isn't checked and it tries to dereference null pointer in slot.
    
    Tagged iterator is fine because retry happens only at slot 0 where tag
    bitmask in iter->tags is filled with single bit.
    
    Fixes: 46437f9a554f ("radix-tree: fix race in gang lookup")
    Signed-off-by: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Ohad Ben-Cohen <ohad@wizery.com>
    Cc: Jeremiah Mahler <jmmahler@gmail.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 00b17c526c1f..f54be7082207 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -400,7 +400,7 @@ void **radix_tree_iter_retry(struct radix_tree_iter *iter)
  * @iter:	pointer to radix tree iterator
  * Returns:	current chunk size
  */
-static __always_inline unsigned
+static __always_inline long
 radix_tree_chunk_size(struct radix_tree_iter *iter)
 {
 	return iter->next_index - iter->index;
@@ -434,9 +434,9 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 			return slot + offset + 1;
 		}
 	} else {
-		unsigned size = radix_tree_chunk_size(iter) - 1;
+		long size = radix_tree_chunk_size(iter);
 
-		while (size--) {
+		while (--size > 0) {
 			slot++;
 			iter->index++;
 			if (likely(*slot))

commit 46437f9a554fbe3e110580ca08ab703b59f2f95a
Author: Matthew Wilcox <willy@linux.intel.com>
Date:   Tue Feb 2 16:57:52 2016 -0800

    radix-tree: fix race in gang lookup
    
    If the indirect_ptr bit is set on a slot, that indicates we need to redo
    the lookup.  Introduce a new function radix_tree_iter_retry() which
    forces the loop to retry the lookup by setting 'slot' to NULL and
    turning the iterator back to point at the problematic entry.
    
    This is a pretty rare problem to hit at the moment; the lookup has to
    race with a grow of the radix tree from a height of 0.  The consequences
    of hitting this race are that gang lookup could return a pointer to a
    radix_tree_node instead of a pointer to whatever the user had inserted
    in the tree.
    
    Fixes: cebbd29e1c2f ("radix-tree: rewrite gang lookup using iterator")
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Ohad Ben-Cohen <ohad@wizery.com>
    Cc: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 7c88ad156a29..00b17c526c1f 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -378,6 +378,22 @@ radix_tree_iter_init(struct radix_tree_iter *iter, unsigned long start)
 void **radix_tree_next_chunk(struct radix_tree_root *root,
 			     struct radix_tree_iter *iter, unsigned flags);
 
+/**
+ * radix_tree_iter_retry - retry this chunk of the iteration
+ * @iter:	iterator state
+ *
+ * If we iterate over a tree protected only by the RCU lock, a race
+ * against deletion or creation may result in seeing a slot for which
+ * radix_tree_deref_retry() returns true.  If so, call this function
+ * and continue the iteration.
+ */
+static inline __must_check
+void **radix_tree_iter_retry(struct radix_tree_iter *iter)
+{
+	iter->next_index = iter->index;
+	return NULL;
+}
+
 /**
  * radix_tree_chunk_size - get current chunk size
  *

commit f9fe48bece3af2d60e1bad65db4825f5a025dd36
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri Jan 22 15:10:40 2016 -0800

    dax: support dirty DAX entries in radix tree
    
    Add support for tracking dirty DAX entries in the struct address_space
    radix tree.  This tree is already used for dirty page writeback, and it
    already supports the use of exceptional (non struct page*) entries.
    
    In order to properly track dirty DAX pages we will insert new
    exceptional entries into the radix tree that represent dirty DAX PTE or
    PMD pages.  These exceptional entries will also contain the writeback
    addresses for the PTE or PMD faults that we can use at fsync/msync time.
    
    There are currently two types of exceptional entries (shmem and shadow)
    that can be placed into the radix tree, and this adds a third.  We rely
    on the fact that only one type of exceptional entry can be found in a
    given radix tree based on its usage.  This happens for free with DAX vs
    shmem but we explicitly prevent shadow entries from being added to radix
    trees for DAX mappings.
    
    The only shadow entries that would be generated for DAX radix trees
    would be to track zero page mappings that were created for holes.  These
    pages would receive minimal benefit from having shadow entries, and the
    choice to have only one type of exceptional entry in a given radix tree
    makes the logic simpler both in clear_exceptional_entry() and in the
    rest of DAX.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "J. Bruce Fields" <bfields@fieldses.org>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Jeff Layton <jlayton@poochiereds.net>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 57e7d87d2d4c..7c88ad156a29 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -51,6 +51,15 @@
 #define RADIX_TREE_EXCEPTIONAL_ENTRY	2
 #define RADIX_TREE_EXCEPTIONAL_SHIFT	2
 
+#define RADIX_DAX_MASK	0xf
+#define RADIX_DAX_SHIFT	4
+#define RADIX_DAX_PTE  (0x4 | RADIX_TREE_EXCEPTIONAL_ENTRY)
+#define RADIX_DAX_PMD  (0x8 | RADIX_TREE_EXCEPTIONAL_ENTRY)
+#define RADIX_DAX_TYPE(entry) ((unsigned long)entry & RADIX_DAX_MASK)
+#define RADIX_DAX_SECTOR(entry) (((unsigned long)entry >> RADIX_DAX_SHIFT))
+#define RADIX_DAX_ENTRY(sector, pmd) ((void *)((unsigned long)sector << \
+		RADIX_DAX_SHIFT | (pmd ? RADIX_DAX_PMD : RADIX_DAX_PTE)))
+
 static inline int radix_tree_is_indirect_ptr(void *ptr)
 {
 	return (int)((unsigned long)ptr & RADIX_TREE_INDIRECT_PTR);

commit 243c2137cda52599f6112f52b6be5e61fa6536ae
Author: Adam Barth <aurorean@gmail.com>
Date:   Wed Jan 20 14:59:09 2016 -0800

    include/linux/radix-tree.h: fix error in docs about locks
    
    This text refers to the "first 7 functions", which was correct when
    written but became incorrect when Johannes Weiner added another function
    to the list in 139e561660fe ("lib: radix_tree: tree node interface").
    
    Change the text to correctly refer to the first 8 functions.
    
    Signed-off-by: Adam Barth <aurorean@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 33170dbd9db4..57e7d87d2d4c 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -154,7 +154,7 @@ do {									\
  * radix_tree_gang_lookup_tag_slot
  * radix_tree_tagged
  *
- * The first 7 functions are able to be called locklessly, using RCU. The
+ * The first 8 functions are able to be called locklessly, using RCU. The
  * caller must ensure calls to these functions are made within rcu_read_lock()
  * regions. Other readers (lock-free or otherwise) and modifications may be
  * running concurrently.

commit 449dd6984d0e47643c04c807f609dd56d48d5bcc
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Apr 3 14:47:56 2014 -0700

    mm: keep page cache radix tree nodes in check
    
    Previously, page cache radix tree nodes were freed after reclaim emptied
    out their page pointers.  But now reclaim stores shadow entries in their
    place, which are only reclaimed when the inodes themselves are
    reclaimed.  This is problematic for bigger files that are still in use
    after they have a significant amount of their cache reclaimed, without
    any of those pages actually refaulting.  The shadow entries will just
    sit there and waste memory.  In the worst case, the shadow entries will
    accumulate until the machine runs out of memory.
    
    To get this under control, the VM will track radix tree nodes
    exclusively containing shadow entries on a per-NUMA node list.  Per-NUMA
    rather than global because we expect the radix tree nodes themselves to
    be allocated node-locally and we want to reduce cross-node references of
    otherwise independent cache workloads.  A simple shrinker will then
    reclaim these nodes on memory pressure.
    
    A few things need to be stored in the radix tree node to implement the
    shadow node LRU and allow tree deletions coming from the list:
    
    1. There is no index available that would describe the reverse path
       from the node up to the tree root, which is needed to perform a
       deletion.  To solve this, encode in each node its offset inside the
       parent.  This can be stored in the unused upper bits of the same
       member that stores the node's height at no extra space cost.
    
    2. The number of shadow entries needs to be counted in addition to the
       regular entries, to quickly detect when the node is ready to go to
       the shadow node LRU list.  The current entry count is an unsigned
       int but the maximum number of entries is 64, so a shadow counter
       can easily be stored in the unused upper bits.
    
    3. Tree modification needs tree lock and tree root, which are located
       in the address space, so store an address_space backpointer in the
       node.  The parent pointer of the node is in a union with the 2-word
       rcu_head, so the backpointer comes at no extra cost as well.
    
    4. The node needs to be linked to an LRU list, which requires a list
       head inside the node.  This does increase the size of the node, but
       it does not change the number of objects that fit into a slab page.
    
    [akpm@linux-foundation.org: export the right function]
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Reviewed-by: Minchan Kim <minchan@kernel.org>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bob Liu <bob.liu@oracle.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Metin Doslu <metin@citusdata.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Ozgun Erdogan <ozgun@citusdata.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roman Gushchin <klamm@yandex-team.ru>
    Cc: Ryan Mallon <rmallon@gmail.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 13636c40bc42..33170dbd9db4 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -72,21 +72,37 @@ static inline int radix_tree_is_indirect_ptr(void *ptr)
 #define RADIX_TREE_TAG_LONGS	\
 	((RADIX_TREE_MAP_SIZE + BITS_PER_LONG - 1) / BITS_PER_LONG)
 
+#define RADIX_TREE_INDEX_BITS  (8 /* CHAR_BIT */ * sizeof(unsigned long))
+#define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \
+					  RADIX_TREE_MAP_SHIFT))
+
+/* Height component in node->path */
+#define RADIX_TREE_HEIGHT_SHIFT	(RADIX_TREE_MAX_PATH + 1)
+#define RADIX_TREE_HEIGHT_MASK	((1UL << RADIX_TREE_HEIGHT_SHIFT) - 1)
+
+/* Internally used bits of node->count */
+#define RADIX_TREE_COUNT_SHIFT	(RADIX_TREE_MAP_SHIFT + 1)
+#define RADIX_TREE_COUNT_MASK	((1UL << RADIX_TREE_COUNT_SHIFT) - 1)
+
 struct radix_tree_node {
-	unsigned int	height;		/* Height from the bottom */
+	unsigned int	path;	/* Offset in parent & height from the bottom */
 	unsigned int	count;
 	union {
-		struct radix_tree_node *parent;	/* Used when ascending tree */
-		struct rcu_head	rcu_head;	/* Used when freeing node */
+		struct {
+			/* Used when ascending tree */
+			struct radix_tree_node *parent;
+			/* For tree user */
+			void *private_data;
+		};
+		/* Used when freeing node */
+		struct rcu_head	rcu_head;
 	};
+	/* For tree user */
+	struct list_head private_list;
 	void __rcu	*slots[RADIX_TREE_MAP_SIZE];
 	unsigned long	tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];
 };
 
-#define RADIX_TREE_INDEX_BITS  (8 /* CHAR_BIT */ * sizeof(unsigned long))
-#define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \
-					  RADIX_TREE_MAP_SHIFT))
-
 /* root tags are stored in gfp_mask, shifted by __GFP_BITS_SHIFT */
 struct radix_tree_root {
 	unsigned int		height;
@@ -251,7 +267,7 @@ void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,
 			  struct radix_tree_node **nodep, void ***slotp);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
-bool __radix_tree_delete_node(struct radix_tree_root *root, unsigned long index,
+bool __radix_tree_delete_node(struct radix_tree_root *root,
 			      struct radix_tree_node *node);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);

commit 139e561660fe11e0fc35e142a800df3dd7d03e9d
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Apr 3 14:47:54 2014 -0700

    lib: radix_tree: tree node interface
    
    Make struct radix_tree_node part of the public interface and provide API
    functions to create, look up, and delete whole nodes.  Refactor the
    existing insert, look up, delete functions on top of these new node
    primitives.
    
    This will allow the VM to track and garbage collect page cache radix
    tree nodes.
    
    [sasha.levin@oracle.com: return correct error code on insertion failure]
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bob Liu <bob.liu@oracle.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Metin Doslu <metin@citusdata.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Ozgun Erdogan <ozgun@citusdata.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roman Gushchin <klamm@yandex-team.ru>
    Cc: Ryan Mallon <rmallon@gmail.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index e8be53ecfc45..13636c40bc42 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -60,6 +60,33 @@ static inline int radix_tree_is_indirect_ptr(void *ptr)
 
 #define RADIX_TREE_MAX_TAGS 3
 
+#ifdef __KERNEL__
+#define RADIX_TREE_MAP_SHIFT	(CONFIG_BASE_SMALL ? 4 : 6)
+#else
+#define RADIX_TREE_MAP_SHIFT	3	/* For more stressful testing */
+#endif
+
+#define RADIX_TREE_MAP_SIZE	(1UL << RADIX_TREE_MAP_SHIFT)
+#define RADIX_TREE_MAP_MASK	(RADIX_TREE_MAP_SIZE-1)
+
+#define RADIX_TREE_TAG_LONGS	\
+	((RADIX_TREE_MAP_SIZE + BITS_PER_LONG - 1) / BITS_PER_LONG)
+
+struct radix_tree_node {
+	unsigned int	height;		/* Height from the bottom */
+	unsigned int	count;
+	union {
+		struct radix_tree_node *parent;	/* Used when ascending tree */
+		struct rcu_head	rcu_head;	/* Used when freeing node */
+	};
+	void __rcu	*slots[RADIX_TREE_MAP_SIZE];
+	unsigned long	tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];
+};
+
+#define RADIX_TREE_INDEX_BITS  (8 /* CHAR_BIT */ * sizeof(unsigned long))
+#define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \
+					  RADIX_TREE_MAP_SHIFT))
+
 /* root tags are stored in gfp_mask, shifted by __GFP_BITS_SHIFT */
 struct radix_tree_root {
 	unsigned int		height;
@@ -101,6 +128,7 @@ do {									\
  *   concurrently with other readers.
  *
  * The notable exceptions to this rule are the following functions:
+ * __radix_tree_lookup
  * radix_tree_lookup
  * radix_tree_lookup_slot
  * radix_tree_tag_get
@@ -216,9 +244,15 @@ static inline void radix_tree_replace_slot(void **pslot, void *item)
 	rcu_assign_pointer(*pslot, item);
 }
 
+int __radix_tree_create(struct radix_tree_root *root, unsigned long index,
+			struct radix_tree_node **nodep, void ***slotp);
 int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
+void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,
+			  struct radix_tree_node **nodep, void ***slotp);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
+bool __radix_tree_delete_node(struct radix_tree_root *root, unsigned long index,
+			      struct radix_tree_node *node);
 void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int

commit e7b563bb2a6f4d974208da46200784b9c5b5a47e
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Apr 3 14:47:44 2014 -0700

    mm: filemap: move radix tree hole searching here
    
    The radix tree hole searching code is only used for page cache, for
    example the readahead code trying to get a a picture of the area
    surrounding a fault.
    
    It sufficed to rely on the radix tree definition of holes, which is
    "empty tree slot".  But this is about to change, though, as shadow page
    descriptors will be stored in the page cache after the actual pages get
    evicted from memory.
    
    Move the functions over to mm/filemap.c and make them native page cache
    operations, where they can later be adapted to handle the new definition
    of "page cache hole".
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Reviewed-by: Minchan Kim <minchan@kernel.org>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bob Liu <bob.liu@oracle.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Metin Doslu <metin@citusdata.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Ozgun Erdogan <ozgun@citusdata.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roman Gushchin <klamm@yandex-team.ru>
    Cc: Ryan Mallon <rmallon@gmail.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 1bf0a9c388d9..e8be53ecfc45 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -227,10 +227,6 @@ radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
 unsigned int radix_tree_gang_lookup_slot(struct radix_tree_root *root,
 			void ***results, unsigned long *indices,
 			unsigned long first_index, unsigned int max_items);
-unsigned long radix_tree_next_hole(struct radix_tree_root *root,
-				unsigned long index, unsigned long max_scan);
-unsigned long radix_tree_prev_hole(struct radix_tree_root *root,
-				unsigned long index, unsigned long max_scan);
 int radix_tree_preload(gfp_t gfp_mask);
 int radix_tree_maybe_preload(gfp_t gfp_mask);
 void radix_tree_init(void);

commit 53c59f262d747ea82e7414774c59a489501186a0
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Apr 3 14:47:39 2014 -0700

    lib: radix-tree: add radix_tree_delete_item()
    
    Provide a function that does not just delete an entry at a given index,
    but also allows passing in an expected item.  Delete only if that item
    is still located at the specified index.
    
    This is handy when lockless tree traversals want to delete entries as
    well because they don't have to do an second, locked lookup to verify
    the slot has not changed under them before deleting the entry.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bob Liu <bob.liu@oracle.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Metin Doslu <metin@citusdata.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Ozgun Erdogan <ozgun@citusdata.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roman Gushchin <klamm@yandex-team.ru>
    Cc: Ryan Mallon <rmallon@gmail.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 403940787be1..1bf0a9c388d9 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -219,6 +219,7 @@ static inline void radix_tree_replace_slot(void **pslot, void *item)
 int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
+void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int
 radix_tree_gang_lookup(struct radix_tree_root *root, void **results,

commit 5e4c0d974139a98741b829b27cf38dc8f9284490
Author: Jan Kara <jack@suse.cz>
Date:   Wed Sep 11 14:26:05 2013 -0700

    lib/radix-tree.c: make radix_tree_node_alloc() work correctly within interrupt
    
    With users of radix_tree_preload() run from interrupt (block/blk-ioc.c is
    one such possible user), the following race can happen:
    
    radix_tree_preload()
    ...
    radix_tree_insert()
      radix_tree_node_alloc()
        if (rtp->nr) {
          ret = rtp->nodes[rtp->nr - 1];
    <interrupt>
    ...
    radix_tree_preload()
    ...
    radix_tree_insert()
      radix_tree_node_alloc()
        if (rtp->nr) {
          ret = rtp->nodes[rtp->nr - 1];
    
    And we give out one radix tree node twice.  That clearly results in radix
    tree corruption with different results (usually OOPS) depending on which
    two users of radix tree race.
    
    We fix the problem by making radix_tree_node_alloc() always allocate fresh
    radix tree nodes when in interrupt.  Using preloading when in interrupt
    doesn't make sense since all the allocations have to be atomic anyway and
    we cannot steal nodes from process-context users because some users rely
    on radix_tree_insert() succeeding after radix_tree_preload().
    in_interrupt() check is somewhat ugly but we cannot simply key off passed
    gfp_mask as that is acquired from root_gfp_mask() and thus the same for
    all preload users.
    
    Another part of the fix is to avoid node preallocation in
    radix_tree_preload() when passed gfp_mask doesn't allow waiting.  Again,
    preallocation in such case doesn't make sense and when preallocation would
    happen in interrupt we could possibly leak some allocated nodes.  However,
    some users of radix_tree_preload() require following radix_tree_insert()
    to succeed.  To avoid unexpected effects for these users,
    radix_tree_preload() only warns if passed gfp mask doesn't allow waiting
    and we provide a new function radix_tree_maybe_preload() for those users
    which get different gfp mask from different call sites and which are
    prepared to handle radix_tree_insert() failure.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <jaxboe@fusionio.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index ffc444c38b0a..403940787be1 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -231,6 +231,7 @@ unsigned long radix_tree_next_hole(struct radix_tree_root *root,
 unsigned long radix_tree_prev_hole(struct radix_tree_root *root,
 				unsigned long index, unsigned long max_scan);
 int radix_tree_preload(gfp_t gfp_mask);
+int radix_tree_maybe_preload(gfp_t gfp_mask);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *root,
 			unsigned long index, unsigned int tag);

commit fffaee365fded09f9ebf2db19066065fa54323c3
Author: Konstantin Khlebnikov <khlebnikov@openvz.org>
Date:   Tue Jun 5 21:36:33 2012 +0400

    radix-tree: fix contiguous iterator
    
    This patch fixes bug in macro radix_tree_for_each_contig().
    
    If radix_tree_next_slot() sees NULL in next slot it returns NULL, but following
    radix_tree_next_chunk() switches iterating into next chunk. As result iterating
    becomes non-contiguous and breaks vfs "splice" and all its users.
    
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Reported-and-bisected-by: Hans de Bruin <jmdebruin@xmsnet.nl>
    Reported-and-bisected-by: Ondrej Zary <linux@rainbow-software.org>
    Reported-bisected-and-tested-by: Toralf Förster <toralf.foerster@gmx.de>
    Link: https://lkml.org/lkml/2012/6/5/64
    Cc: stable <stable@vger.kernel.org> # 3.4.x
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 0d04cd69ab9b..ffc444c38b0a 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -368,8 +368,11 @@ radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
 			iter->index++;
 			if (likely(*slot))
 				return slot;
-			if (flags & RADIX_TREE_ITER_CONTIG)
+			if (flags & RADIX_TREE_ITER_CONTIG) {
+				/* forbid switching to the next chunk */
+				iter->next_index = 0;
 				break;
+			}
 		}
 	}
 	return NULL;

commit 78c1d78488a3c45685d993130c9f17102dc79a54
Author: Konstantin Khlebnikov <khlebnikov@openvz.org>
Date:   Wed Mar 28 14:42:53 2012 -0700

    radix-tree: introduce bit-optimized iterator
    
    A series of radix tree cleanups, and usage of them in the core pagecache
    code.
    
    Micro-benchmark:
    
    lookup 14 slots (typical page-vector size)
    in radix-tree there earch <step> slot filled and tagged
    before/after - nsec per full scan through tree
    
    * Intel Sandy Bridge i7-2620M 4Mb L3
    New code always faster
    
    * AMD Athlon 6000+ 2x1Mb L2, without L3
    New code generally faster,
    Minor degradation (marked with "*") for huge sparse trees
    
    * i386 on Sandy Bridge
    New code faster for common cases: tagged and dense trees.
    Some degradations for non-tagged lookup on sparse trees.
    
    Ideally, there might help __ffs() analog for searching first non-zero
    long element in array, gcc sometimes cannot optimize this loop corretly.
    
    Numbers:
    
    CPU: Intel Sandy Bridge i7-2620M 4Mb L3
    
    radix-tree with 1024 slots:
    
    tagged lookup
    
    step  1      before  7156        after  3613
    step  2      before  5399        after  2696
    step  3      before  4779        after  1928
    step  4      before  4456        after  1429
    step  5      before  4292        after  1213
    step  6      before  4183        after  1052
    step  7      before  4157        after  951
    step  8      before  4016        after  812
    step  9      before  3952        after  851
    step  10     before  3937        after  732
    step  11     before  4023        after  709
    step  12     before  3872        after  657
    step  13     before  3892        after  633
    step  14     before  3720        after  591
    step  15     before  3879        after  578
    step  16     before  3561        after  513
    
    normal lookup
    
    step  1      before  4266       after  3301
    step  2      before  2695       after  2129
    step  3      before  2083       after  1712
    step  4      before  1801       after  1534
    step  5      before  1628       after  1313
    step  6      before  1551       after  1263
    step  7      before  1475       after  1185
    step  8      before  1432       after  1167
    step  9      before  1373       after  1092
    step  10     before  1339       after  1134
    step  11     before  1292       after  1056
    step  12     before  1319       after  1030
    step  13     before  1276       after  1004
    step  14     before  1256       after  987
    step  15     before  1228       after  992
    step  16     before  1247       after  999
    
    radix-tree with 1024*1024*128 slots:
    
    tagged lookup
    
    step  1      before  1086102841  after  674196409
    step  2      before  816839155   after  498138306
    step  7      before  599728907   after  240676762
    step  15     before  555729253   after  185219677
    step  63     before  606637748   after  128585664
    step  64     before  608384432   after  102945089
    step  65     before  596987114   after  123996019
    step  128    before  304459225   after  56783056
    step  256    before  158846855   after  31232481
    step  512    before  86085652    after  18950595
    step  12345  before  6517189     after  1674057
    
    normal lookup
    
    step  1      before  626064869  after  544418266
    step  2      before  418809975  after  336321473
    step  7      before  242303598  after  207755560
    step  15     before  208380563  after  176496355
    step  63     before  186854206  after  167283638
    step  64     before  176188060  after  170143976
    step  65     before  185139608  after  167487116
    step  128    before  88181865   after  86913490
    step  256    before  45733628   after  45143534
    step  512    before  24506038   after  23859036
    step  12345  before  2177425    after  2018662
    
    * AMD Athlon 6000+ 2x1Mb L2, without L3
    
    radix-tree with 1024 slots:
    
    tag-lookup
    
    step  1      before  8164        after  5379
    step  2      before  5818        after  5581
    step  3      before  4959        after  4213
    step  4      before  4371        after  3386
    step  5      before  4204        after  2997
    step  6      before  4950        after  2744
    step  7      before  4598        after  2480
    step  8      before  4251        after  2288
    step  9      before  4262        after  2243
    step  10     before  4175        after  2131
    step  11     before  3999        after  2024
    step  12     before  3979        after  1994
    step  13     before  3842        after  1929
    step  14     before  3750        after  1810
    step  15     before  3735        after  1810
    step  16     before  3532        after  1660
    
    normal-lookup
    
    step  1      before  7875        after  5847
    step  2      before  4808        after  4071
    step  3      before  4073        after  3462
    step  4      before  3677        after  3074
    step  5      before  4308        after  2978
    step  6      before  3911        after  3807
    step  7      before  3635        after  3522
    step  8      before  3313        after  3202
    step  9      before  3280        after  3257
    step  10     before  3166        after  3083
    step  11     before  3066        after  3026
    step  12     before  2985        after  2982
    step  13     before  2925        after  2924
    step  14     before  2834        after  2808
    step  15     before  2805        after  2803
    step  16     before  2647        after  2622
    
    radix-tree with 1024*1024*128 slots:
    
    tag-lookup
    
    step  1      before  1288059720  after  951736580
    step  2      before  961292300   after  884212140
    step  7      before  768905140   after  547267580
    step  15     before  771319480   after  456550640
    step  63     before  504847640   after  242704304
    step  64     before  392484800   after  177920786
    step  65     before  491162160   after  246895264
    step  128    before  208084064   after  97348392
    step  256    before  112401035   after  51408126
    step  512    before  75825834    after  29145070
    step  12345  before  5603166     after  2847330
    
    normal-lookup
    
    step  1      before  1025677120  after  861375100
    step  2      before  647220080   after  572258540
    step  7      before  505518960   after  484041813
    step  15     before  430483053   after  444815320       *
    step  63     before  388113453   after  404250546       *
    step  64     before  374154666   after  396027440       *
    step  65     before  381423973   after  396704853       *
    step  128    before  190078700   after  202619384       *
    step  256    before  100886756   after  102829108       *
    step  512    before  64074505    after  56158720
    step  12345  before  4237289     after  4422299         *
    
    * i686 on Sandy bridge
    
    radix-tree with 1024 slots:
    
    tagged lookup
    
    step  1      before  7990        after  4019
    step  2      before  5698        after  2897
    step  3      before  5013        after  2475
    step  4      before  4630        after  1721
    step  5      before  4346        after  1759
    step  6      before  4299        after  1556
    step  7      before  4098        after  1513
    step  8      before  4115        after  1222
    step  9      before  3983        after  1390
    step  10     before  4077        after  1207
    step  11     before  3921        after  1231
    step  12     before  3894        after  1116
    step  13     before  3840        after  1147
    step  14     before  3799        after  1090
    step  15     before  3797        after  1059
    step  16     before  3783        after  745
    
    normal lookup
    
    step  1      before  5103       after  3499
    step  2      before  3299       after  2550
    step  3      before  2489       after  2370
    step  4      before  2034       after  2302             *
    step  5      before  1846       after  2268             *
    step  6      before  1752       after  2249             *
    step  7      before  1679       after  2164             *
    step  8      before  1627       after  2153             *
    step  9      before  1542       after  2095             *
    step  10     before  1479       after  2109             *
    step  11     before  1469       after  2009             *
    step  12     before  1445       after  2039             *
    step  13     before  1411       after  2013             *
    step  14     before  1374       after  2046             *
    step  15     before  1340       after  1975             *
    step  16     before  1331       after  2000             *
    
    radix-tree with 1024*1024*128 slots:
    
    tagged lookup
    
    step  1      before  1225865377  after  667153553
    step  2      before  842427423   after  471533007
    step  7      before  609296153   after  276260116
    step  15     before  544232060   after  226859105
    step  63     before  519209199   after  141343043
    step  64     before  588980279   after  141951339
    step  65     before  521099710   after  138282060
    step  128    before  298476778   after  83390628
    step  256    before  149358342   after  43602609
    step  512    before  76994713    after  22911077
    step  12345  before  5328666     after  1472111
    
    normal lookup
    
    step  1      before  819284564  after  533635310
    step  2      before  512421605  after  364956155
    step  7      before  271443305  after  305721345        *
    step  15     before  223591630  after  273960216        *
    step  63     before  190320247  after  217770207        *
    step  64     before  178538168  after  267411372        *
    step  65     before  186400423  after  215347937        *
    step  128    before  88106045   after  140540612        *
    step  256    before  44812420   after  70660377         *
    step  512    before  24435438   after  36328275         *
    step  12345  before  2123924    after  2148062          *
    
    bloat-o-meter delta for this patchset + patchset with related shmem cleanups
    
    bloat-o-meter: x86_64
    
    add/remove: 4/3 grow/shrink: 5/6 up/down: 928/-939 (-11)
    function                                     old     new   delta
    radix_tree_next_chunk                          -     499    +499
    shmem_unuse                                  428     554    +126
    shmem_radix_tree_replace                     131     227     +96
    find_get_pages_tag                           354     419     +65
    find_get_pages_contig                        345     407     +62
    find_get_pages                               362     396     +34
    __kstrtab_radix_tree_next_chunk                -      22     +22
    __ksymtab_radix_tree_next_chunk                -      16     +16
    __kcrctab_radix_tree_next_chunk                -       8      +8
    radix_tree_gang_lookup_slot                  204     203      -1
    static.shmem_xattr_set                       384     381      -3
    radix_tree_gang_lookup_tag_slot              208     191     -17
    radix_tree_gang_lookup                       231     187     -44
    radix_tree_gang_lookup_tag                   247     199     -48
    shmem_unlock_mapping                         278     190     -88
    __lookup                                     217       -    -217
    __lookup_tag                                 242       -    -242
    radix_tree_locate_item                       279       -    -279
    
    bloat-o-meter: i386
    
    add/remove: 3/3 grow/shrink: 8/9 up/down: 1075/-1275 (-200)
    function                                     old     new   delta
    radix_tree_next_chunk                          -     757    +757
    shmem_unuse                                  352     449     +97
    find_get_pages_contig                        269     322     +53
    shmem_radix_tree_replace                     113     154     +41
    find_get_pages_tag                           277     318     +41
    dcache_dir_lseek                             426     458     +32
    __kstrtab_radix_tree_next_chunk                -      22     +22
    vc_do_resize                                 968     977      +9
    snd_pcm_lib_read1                            725     733      +8
    __ksymtab_radix_tree_next_chunk                -       8      +8
    netlbl_cipsov4_list                         1120    1127      +7
    find_get_pages                               293     291      -2
    new_slab                                     467     459      -8
    bitfill_unaligned_rev                        425     417      -8
    radix_tree_gang_lookup_tag_slot              177     146     -31
    blk_dump_cmd                                 267     229     -38
    radix_tree_gang_lookup_slot                  212     134     -78
    shmem_unlock_mapping                         221     128     -93
    radix_tree_gang_lookup_tag                   275     162    -113
    radix_tree_gang_lookup                       255     126    -129
    __lookup                                     227       -    -227
    __lookup_tag                                 271       -    -271
    radix_tree_locate_item                       277       -    -277
    
    This patch:
    
    Implement a clean, simple and effective radix-tree iteration routine.
    
    Iterating divided into two phases:
    * lookup next chunk in radix-tree leaf node
    * iterating through slots in this chunk
    
    Main iterator function radix_tree_next_chunk() returns pointer to first
    slot, and stores in the struct radix_tree_iter index of next-to-last slot.
     For tagged-iterating it also constuct bitmask of tags for retunted chunk.
     All additional logic implemented as static-inline functions and macroses.
    
    Also adds radix_tree_find_next_bit() static-inline variant of
    find_next_bit() optimized for small constant size arrays, because
    find_next_bit() too heavy for searching in an array with one/two long
    elements.
    
    [akpm@linux-foundation.org: rework comments a bit]
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Tested-by: Hugh Dickins <hughd@google.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index e9a48234e693..0d04cd69ab9b 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -2,6 +2,7 @@
  * Copyright (C) 2001 Momchil Velikov
  * Portions Copyright (C) 2001 Christoph Hellwig
  * Copyright (C) 2006 Nick Piggin
+ * Copyright (C) 2012 Konstantin Khlebnikov
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License as
@@ -257,4 +258,199 @@ static inline void radix_tree_preload_end(void)
 	preempt_enable();
 }
 
+/**
+ * struct radix_tree_iter - radix tree iterator state
+ *
+ * @index:	index of current slot
+ * @next_index:	next-to-last index for this chunk
+ * @tags:	bit-mask for tag-iterating
+ *
+ * This radix tree iterator works in terms of "chunks" of slots.  A chunk is a
+ * subinterval of slots contained within one radix tree leaf node.  It is
+ * described by a pointer to its first slot and a struct radix_tree_iter
+ * which holds the chunk's position in the tree and its size.  For tagged
+ * iteration radix_tree_iter also holds the slots' bit-mask for one chosen
+ * radix tree tag.
+ */
+struct radix_tree_iter {
+	unsigned long	index;
+	unsigned long	next_index;
+	unsigned long	tags;
+};
+
+#define RADIX_TREE_ITER_TAG_MASK	0x00FF	/* tag index in lower byte */
+#define RADIX_TREE_ITER_TAGGED		0x0100	/* lookup tagged slots */
+#define RADIX_TREE_ITER_CONTIG		0x0200	/* stop at first hole */
+
+/**
+ * radix_tree_iter_init - initialize radix tree iterator
+ *
+ * @iter:	pointer to iterator state
+ * @start:	iteration starting index
+ * Returns:	NULL
+ */
+static __always_inline void **
+radix_tree_iter_init(struct radix_tree_iter *iter, unsigned long start)
+{
+	/*
+	 * Leave iter->tags uninitialized. radix_tree_next_chunk() will fill it
+	 * in the case of a successful tagged chunk lookup.  If the lookup was
+	 * unsuccessful or non-tagged then nobody cares about ->tags.
+	 *
+	 * Set index to zero to bypass next_index overflow protection.
+	 * See the comment in radix_tree_next_chunk() for details.
+	 */
+	iter->index = 0;
+	iter->next_index = start;
+	return NULL;
+}
+
+/**
+ * radix_tree_next_chunk - find next chunk of slots for iteration
+ *
+ * @root:	radix tree root
+ * @iter:	iterator state
+ * @flags:	RADIX_TREE_ITER_* flags and tag index
+ * Returns:	pointer to chunk first slot, or NULL if there no more left
+ *
+ * This function looks up the next chunk in the radix tree starting from
+ * @iter->next_index.  It returns a pointer to the chunk's first slot.
+ * Also it fills @iter with data about chunk: position in the tree (index),
+ * its end (next_index), and constructs a bit mask for tagged iterating (tags).
+ */
+void **radix_tree_next_chunk(struct radix_tree_root *root,
+			     struct radix_tree_iter *iter, unsigned flags);
+
+/**
+ * radix_tree_chunk_size - get current chunk size
+ *
+ * @iter:	pointer to radix tree iterator
+ * Returns:	current chunk size
+ */
+static __always_inline unsigned
+radix_tree_chunk_size(struct radix_tree_iter *iter)
+{
+	return iter->next_index - iter->index;
+}
+
+/**
+ * radix_tree_next_slot - find next slot in chunk
+ *
+ * @slot:	pointer to current slot
+ * @iter:	pointer to interator state
+ * @flags:	RADIX_TREE_ITER_*, should be constant
+ * Returns:	pointer to next slot, or NULL if there no more left
+ *
+ * This function updates @iter->index in the case of a successful lookup.
+ * For tagged lookup it also eats @iter->tags.
+ */
+static __always_inline void **
+radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)
+{
+	if (flags & RADIX_TREE_ITER_TAGGED) {
+		iter->tags >>= 1;
+		if (likely(iter->tags & 1ul)) {
+			iter->index++;
+			return slot + 1;
+		}
+		if (!(flags & RADIX_TREE_ITER_CONTIG) && likely(iter->tags)) {
+			unsigned offset = __ffs(iter->tags);
+
+			iter->tags >>= offset;
+			iter->index += offset + 1;
+			return slot + offset + 1;
+		}
+	} else {
+		unsigned size = radix_tree_chunk_size(iter) - 1;
+
+		while (size--) {
+			slot++;
+			iter->index++;
+			if (likely(*slot))
+				return slot;
+			if (flags & RADIX_TREE_ITER_CONTIG)
+				break;
+		}
+	}
+	return NULL;
+}
+
+/**
+ * radix_tree_for_each_chunk - iterate over chunks
+ *
+ * @slot:	the void** variable for pointer to chunk first slot
+ * @root:	the struct radix_tree_root pointer
+ * @iter:	the struct radix_tree_iter pointer
+ * @start:	iteration starting index
+ * @flags:	RADIX_TREE_ITER_* and tag index
+ *
+ * Locks can be released and reacquired between iterations.
+ */
+#define radix_tree_for_each_chunk(slot, root, iter, start, flags)	\
+	for (slot = radix_tree_iter_init(iter, start) ;			\
+	      (slot = radix_tree_next_chunk(root, iter, flags)) ;)
+
+/**
+ * radix_tree_for_each_chunk_slot - iterate over slots in one chunk
+ *
+ * @slot:	the void** variable, at the beginning points to chunk first slot
+ * @iter:	the struct radix_tree_iter pointer
+ * @flags:	RADIX_TREE_ITER_*, should be constant
+ *
+ * This macro is designed to be nested inside radix_tree_for_each_chunk().
+ * @slot points to the radix tree slot, @iter->index contains its index.
+ */
+#define radix_tree_for_each_chunk_slot(slot, iter, flags)		\
+	for (; slot ; slot = radix_tree_next_slot(slot, iter, flags))
+
+/**
+ * radix_tree_for_each_slot - iterate over non-empty slots
+ *
+ * @slot:	the void** variable for pointer to slot
+ * @root:	the struct radix_tree_root pointer
+ * @iter:	the struct radix_tree_iter pointer
+ * @start:	iteration starting index
+ *
+ * @slot points to radix tree slot, @iter->index contains its index.
+ */
+#define radix_tree_for_each_slot(slot, root, iter, start)		\
+	for (slot = radix_tree_iter_init(iter, start) ;			\
+	     slot || (slot = radix_tree_next_chunk(root, iter, 0)) ;	\
+	     slot = radix_tree_next_slot(slot, iter, 0))
+
+/**
+ * radix_tree_for_each_contig - iterate over contiguous slots
+ *
+ * @slot:	the void** variable for pointer to slot
+ * @root:	the struct radix_tree_root pointer
+ * @iter:	the struct radix_tree_iter pointer
+ * @start:	iteration starting index
+ *
+ * @slot points to radix tree slot, @iter->index contains its index.
+ */
+#define radix_tree_for_each_contig(slot, root, iter, start)		\
+	for (slot = radix_tree_iter_init(iter, start) ;			\
+	     slot || (slot = radix_tree_next_chunk(root, iter,		\
+				RADIX_TREE_ITER_CONTIG)) ;		\
+	     slot = radix_tree_next_slot(slot, iter,			\
+				RADIX_TREE_ITER_CONTIG))
+
+/**
+ * radix_tree_for_each_tagged - iterate over tagged slots
+ *
+ * @slot:	the void** variable for pointer to slot
+ * @root:	the struct radix_tree_root pointer
+ * @iter:	the struct radix_tree_iter pointer
+ * @start:	iteration starting index
+ * @tag:	tag index
+ *
+ * @slot points to radix tree slot, @iter->index contains its index.
+ */
+#define radix_tree_for_each_tagged(slot, root, iter, start, tag)	\
+	for (slot = radix_tree_iter_init(iter, start) ;			\
+	     slot || (slot = radix_tree_next_chunk(root, iter,		\
+			      RADIX_TREE_ITER_TAGGED | tag)) ;		\
+	     slot = radix_tree_next_slot(slot, iter,			\
+				RADIX_TREE_ITER_TAGGED))
+
 #endif /* _LINUX_RADIX_TREE_H */

commit 187f1882b5b0748b3c4c22274663fdb372ac0452
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Nov 23 20:12:59 2011 -0500

    BUG: headers with BUG/BUG_ON etc. need linux/bug.h
    
    If a header file is making use of BUG, BUG_ON, BUILD_BUG_ON, or any
    other BUG variant in a static inline (i.e. not in a #define) then
    that header really should be including <linux/bug.h> and not just
    expecting it to be implicitly present.
    
    We can make this change risk-free, since if the files using these
    headers didn't have exposure to linux/bug.h already, they would have
    been causing compile failures/warnings.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 07e360b1b282..e9a48234e693 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -22,6 +22,7 @@
 
 #include <linux/preempt.h>
 #include <linux/types.h>
+#include <linux/bug.h>
 #include <linux/kernel.h>
 #include <linux/rcupdate.h>
 

commit 928da837aca77a9d3cb5076bf07b3224b1ba293b
Author: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
Date:   Thu Jan 12 17:20:39 2012 -0800

    radix_tree: remove radix_tree_indirect_to_ptr()
    
    It is not used anymore, remove it
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 9d4539c52e53..07e360b1b282 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -49,9 +49,6 @@
 #define RADIX_TREE_EXCEPTIONAL_ENTRY	2
 #define RADIX_TREE_EXCEPTIONAL_SHIFT	2
 
-#define radix_tree_indirect_to_ptr(ptr) \
-	radix_tree_indirect_to_ptr((void __force *)(ptr))
-
 static inline int radix_tree_is_indirect_ptr(void *ptr)
 {
 	return (int)((unsigned long)ptr & RADIX_TREE_INDIRECT_PTR);

commit e504f3fdd63d486d45b18009e5a65f2e329acb0a
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Aug 3 16:21:27 2011 -0700

    tmpfs radix_tree: locate_item to speed up swapoff
    
    We have already acknowledged that swapoff of a tmpfs file is slower than
    it was before conversion to the generic radix_tree: a little slower
    there will be acceptable, if the hotter paths are faster.
    
    But it was a shock to find swapoff of a 500MB file 20 times slower on my
    laptop, taking 10 minutes; and at that rate it significantly slows down
    my testing.
    
    Now, most of that turned out to be overhead from PROVE_LOCKING and
    PROVE_RCU: without those it was only 4 times slower than before; and
    more realistic tests on other machines don't fare as badly.
    
    I've tried a number of things to improve it, including tagging the swap
    entries, then doing lookup by tag: I'd expected that to halve the time,
    but in practice it's erratic, and often counter-productive.
    
    The only change I've so far found to make a consistent improvement, is
    to short-circuit the way we go back and forth, gang lookup packing
    entries into the array supplied, then shmem scanning that array for the
    target entry.  Scanning in place doubles the speed, so it's now only
    twice as slow as before (or three times slower when the PROVEs are on).
    
    So, add radix_tree_locate_item() as an expedient, once-off,
    single-caller hack to do the lookup directly in place.  #ifdef it on
    CONFIG_SHMEM and CONFIG_SWAP, as much to document its limited
    applicability as save space in other configurations.  And, sadly,
    #include sched.h for cond_resched().
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index b7edf8251455..9d4539c52e53 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -252,6 +252,7 @@ unsigned long radix_tree_range_tag_if_tagged(struct radix_tree_root *root,
 		unsigned long nr_to_tag,
 		unsigned int fromtag, unsigned int totag);
 int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);
+unsigned long radix_tree_locate_item(struct radix_tree_root *root, void *item);
 
 static inline void radix_tree_preload_end(void)
 {

commit 6328650bb4d854a7dc1498d1c0048b838b0d340c
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Aug 3 16:21:18 2011 -0700

    radix_tree: exceptional entries and indices
    
    A patchset to extend tmpfs to MAX_LFS_FILESIZE by abandoning its
    peculiar swap vector, instead keeping a file's swap entries in the same
    radix tree as its struct page pointers: thus saving memory, and
    simplifying its code and locking.
    
    This patch:
    
    The radix_tree is used by several subsystems for different purposes.  A
    major use is to store the struct page pointers of a file's pagecache for
    memory management.  But what if mm wanted to store something other than
    page pointers there too?
    
    The low bit of a radix_tree entry is already used to denote an indirect
    pointer, for internal use, and the unlikely radix_tree_deref_retry()
    case.
    
    Define the next bit as denoting an exceptional entry, and supply inline
    functions radix_tree_exception() to return non-0 in either unlikely
    case, and radix_tree_exceptional_entry() to return non-0 in the second
    case.
    
    If a subsystem already uses radix_tree with that bit set, no problem: it
    does not affect internal workings at all, but is defined for the
    convenience of those storing well-aligned pointers in the radix_tree.
    
    The radix_tree_gang_lookups have an implicit assumption that the caller
    can deduce the offset of each entry returned e.g.  by the page->index of
    a struct page.  But that may not be feasible for some kinds of item to
    be stored there.
    
    radix_tree_gang_lookup_slot() allow for an optional indices argument,
    output array in which to return those offsets.  The same could be added
    to other radix_tree_gang_lookups, but for now keep it to the only one
    for which we need it.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 23241c2fecce..b7edf8251455 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -39,7 +39,15 @@
  * when it is shrunk, before we rcu free the node. See shrink code for
  * details.
  */
-#define RADIX_TREE_INDIRECT_PTR	1
+#define RADIX_TREE_INDIRECT_PTR		1
+/*
+ * A common use of the radix tree is to store pointers to struct pages;
+ * but shmem/tmpfs needs also to store swap entries in the same tree:
+ * those are marked as exceptional entries to distinguish them.
+ * EXCEPTIONAL_ENTRY tests the bit, EXCEPTIONAL_SHIFT shifts content past it.
+ */
+#define RADIX_TREE_EXCEPTIONAL_ENTRY	2
+#define RADIX_TREE_EXCEPTIONAL_SHIFT	2
 
 #define radix_tree_indirect_to_ptr(ptr) \
 	radix_tree_indirect_to_ptr((void __force *)(ptr))
@@ -173,6 +181,28 @@ static inline int radix_tree_deref_retry(void *arg)
 	return unlikely((unsigned long)arg & RADIX_TREE_INDIRECT_PTR);
 }
 
+/**
+ * radix_tree_exceptional_entry	- radix_tree_deref_slot gave exceptional entry?
+ * @arg:	value returned by radix_tree_deref_slot
+ * Returns:	0 if well-aligned pointer, non-0 if exceptional entry.
+ */
+static inline int radix_tree_exceptional_entry(void *arg)
+{
+	/* Not unlikely because radix_tree_exception often tested first */
+	return (unsigned long)arg & RADIX_TREE_EXCEPTIONAL_ENTRY;
+}
+
+/**
+ * radix_tree_exception	- radix_tree_deref_slot returned either exception?
+ * @arg:	value returned by radix_tree_deref_slot
+ * Returns:	0 if well-aligned pointer, non-0 if either kind of exception.
+ */
+static inline int radix_tree_exception(void *arg)
+{
+	return unlikely((unsigned long)arg &
+		(RADIX_TREE_INDIRECT_PTR | RADIX_TREE_EXCEPTIONAL_ENTRY));
+}
+
 /**
  * radix_tree_replace_slot	- replace item in a slot
  * @pslot:	pointer to slot, returned by radix_tree_lookup_slot
@@ -194,8 +224,8 @@ void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int
 radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
 			unsigned long first_index, unsigned int max_items);
-unsigned int
-radix_tree_gang_lookup_slot(struct radix_tree_root *root, void ***results,
+unsigned int radix_tree_gang_lookup_slot(struct radix_tree_root *root,
+			void ***results, unsigned long *indices,
 			unsigned long first_index, unsigned int max_items);
 unsigned long radix_tree_next_hole(struct radix_tree_root *root,
 				unsigned long index, unsigned long max_scan);

commit 29c1f677d424e8c5683a837fc4f03fc9f19201d7
Author: Mel Gorman <mel@csn.ul.ie>
Date:   Thu Jan 13 15:47:21 2011 -0800

    mm: migration: use rcu_dereference_protected when dereferencing the radix tree slot during file page migration
    
    migrate_pages() -> unmap_and_move() only calls rcu_read_lock() for
    anonymous pages, as introduced by git commit
    989f89c57e6361e7d16fbd9572b5da7d313b073d ("fix rcu_read_lock() in page
    migraton").  The point of the RCU protection there is part of getting a
    stable reference to anon_vma and is only held for anon pages as file pages
    are locked which is sufficient protection against freeing.
    
    However, while a file page's mapping is being migrated, the radix tree is
    double checked to ensure it is the expected page.  This uses
    radix_tree_deref_slot() -> rcu_dereference() without the RCU lock held
    triggering the following warning.
    
    [  173.674290] ===================================================
    [  173.676016] [ INFO: suspicious rcu_dereference_check() usage. ]
    [  173.676016] ---------------------------------------------------
    [  173.676016] include/linux/radix-tree.h:145 invoked rcu_dereference_check() without protection!
    [  173.676016]
    [  173.676016] other info that might help us debug this:
    [  173.676016]
    [  173.676016]
    [  173.676016] rcu_scheduler_active = 1, debug_locks = 0
    [  173.676016] 1 lock held by hugeadm/2899:
    [  173.676016]  #0:  (&(&inode->i_data.tree_lock)->rlock){..-.-.}, at: [<c10e3d2b>] migrate_page_move_mapping+0x40/0x1ab
    [  173.676016]
    [  173.676016] stack backtrace:
    [  173.676016] Pid: 2899, comm: hugeadm Not tainted 2.6.37-rc5-autobuild
    [  173.676016] Call Trace:
    [  173.676016]  [<c128cc01>] ? printk+0x14/0x1b
    [  173.676016]  [<c1063502>] lockdep_rcu_dereference+0x7d/0x86
    [  173.676016]  [<c10e3db5>] migrate_page_move_mapping+0xca/0x1ab
    [  173.676016]  [<c10e41ad>] migrate_page+0x23/0x39
    [  173.676016]  [<c10e491b>] buffer_migrate_page+0x22/0x107
    [  173.676016]  [<c10e48f9>] ? buffer_migrate_page+0x0/0x107
    [  173.676016]  [<c10e425d>] move_to_new_page+0x9a/0x1ae
    [  173.676016]  [<c10e47e6>] migrate_pages+0x1e7/0x2fa
    
    This patch introduces radix_tree_deref_slot_protected() which calls
    rcu_dereference_protected().  Users of it must pass in the
    mapping->tree_lock that is protecting this dereference.  Holding the tree
    lock protects against parallel updaters of the radix tree meaning that
    rcu_dereference_protected is allowable.
    
    [akpm@linux-foundation.org: remove unneeded casts]
    Signed-off-by: Mel Gorman <mel@csn.ul.ie>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Milton Miller <miltonm@bga.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Cc: <stable@kernel.org>         [2.6.37.early]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index ab2baa5c4884..23241c2fecce 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -145,6 +145,22 @@ static inline void *radix_tree_deref_slot(void **pslot)
 	return rcu_dereference(*pslot);
 }
 
+/**
+ * radix_tree_deref_slot_protected	- dereference a slot without RCU lock but with tree lock held
+ * @pslot:	pointer to slot, returned by radix_tree_lookup_slot
+ * Returns:	item that was stored in that slot with any direct pointer flag
+ *		removed.
+ *
+ * Similar to radix_tree_deref_slot but only used during migration when a pages
+ * mapping is being moved. The caller does not hold the RCU read lock but it
+ * must hold the tree lock to prevent parallel updates.
+ */
+static inline void *radix_tree_deref_slot_protected(void **pslot,
+							spinlock_t *treelock)
+{
+	return rcu_dereference_protected(*pslot, lockdep_is_held(treelock));
+}
+
 /**
  * radix_tree_deref_retry	- check radix_tree_deref_slot
  * @arg:	pointer returned by radix_tree_deref_slot

commit 27d20fddc8af539464fc3ba499d6a830054c3bd6
Author: Nick Piggin <npiggin@kernel.dk>
Date:   Thu Nov 11 14:05:19 2010 -0800

    radix-tree: fix RCU bug
    
    Salman Qazi describes the following radix-tree bug:
    
    In the following case, we get can get a deadlock:
    
    0.  The radix tree contains two items, one has the index 0.
    1.  The reader (in this case find_get_pages) takes the rcu_read_lock.
    2.  The reader acquires slot(s) for item(s) including the index 0 item.
    3.  The non-zero index item is deleted, and as a consequence the other item is
        moved to the root of the tree. The place where it used to be is queued for
        deletion after the readers finish.
    3b. The zero item is deleted, removing it from the direct slot, it remains in
        the rcu-delayed indirect node.
    4.  The reader looks at the index 0 slot, and finds that the page has 0 ref
        count
    5.  The reader looks at it again, hoping that the item will either be freed or
        the ref count will increase. This never happens, as the slot it is looking
        at will never be updated. Also, this slot can never be reclaimed because
        the reader is holding rcu_read_lock and is in an infinite loop.
    
    The fix is to re-use the same "indirect" pointer case that requires a slot
    lookup retry into a general "retry the lookup" bit.
    
    Signed-off-by: Nick Piggin <npiggin@kernel.dk>
    Reported-by: Salman Qazi <sqazi@google.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index a39cbed9ee17..ab2baa5c4884 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -34,19 +34,13 @@
  * needed for RCU lookups (because root->height is unreliable). The only
  * time callers need worry about this is when doing a lookup_slot under
  * RCU.
+ *
+ * Indirect pointer in fact is also used to tag the last pointer of a node
+ * when it is shrunk, before we rcu free the node. See shrink code for
+ * details.
  */
 #define RADIX_TREE_INDIRECT_PTR	1
-#define RADIX_TREE_RETRY ((void *)-1UL)
-
-static inline void *radix_tree_ptr_to_indirect(void *ptr)
-{
-	return (void *)((unsigned long)ptr | RADIX_TREE_INDIRECT_PTR);
-}
 
-static inline void *radix_tree_indirect_to_ptr(void *ptr)
-{
-	return (void *)((unsigned long)ptr & ~RADIX_TREE_INDIRECT_PTR);
-}
 #define radix_tree_indirect_to_ptr(ptr) \
 	radix_tree_indirect_to_ptr((void __force *)(ptr))
 
@@ -140,16 +134,29 @@ do {									\
  *		removed.
  *
  * For use with radix_tree_lookup_slot().  Caller must hold tree at least read
- * locked across slot lookup and dereference.  More likely, will be used with
- * radix_tree_replace_slot(), as well, so caller will hold tree write locked.
+ * locked across slot lookup and dereference. Not required if write lock is
+ * held (ie. items cannot be concurrently inserted).
+ *
+ * radix_tree_deref_retry must be used to confirm validity of the pointer if
+ * only the read lock is held.
  */
 static inline void *radix_tree_deref_slot(void **pslot)
 {
-	void *ret = rcu_dereference(*pslot);
-	if (unlikely(radix_tree_is_indirect_ptr(ret)))
-		ret = RADIX_TREE_RETRY;
-	return ret;
+	return rcu_dereference(*pslot);
 }
+
+/**
+ * radix_tree_deref_retry	- check radix_tree_deref_slot
+ * @arg:	pointer returned by radix_tree_deref_slot
+ * Returns:	0 if retry is not required, otherwise retry is required
+ *
+ * radix_tree_deref_retry must be used with radix_tree_deref_slot.
+ */
+static inline int radix_tree_deref_retry(void *arg)
+{
+	return unlikely((unsigned long)arg & RADIX_TREE_INDIRECT_PTR);
+}
+
 /**
  * radix_tree_replace_slot	- replace item in a slot
  * @pslot:	pointer to slot, returned by radix_tree_lookup_slot

commit a1115570b31091f3e3ab9e6cf7ee8d320a42be84
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Feb 25 23:43:52 2010 +0100

    radix-tree: __rcu annotations
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Nick Piggin <npiggin@suse.de>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 634b8e674ac5..a39cbed9ee17 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -47,6 +47,8 @@ static inline void *radix_tree_indirect_to_ptr(void *ptr)
 {
 	return (void *)((unsigned long)ptr & ~RADIX_TREE_INDIRECT_PTR);
 }
+#define radix_tree_indirect_to_ptr(ptr) \
+	radix_tree_indirect_to_ptr((void __force *)(ptr))
 
 static inline int radix_tree_is_indirect_ptr(void *ptr)
 {
@@ -61,7 +63,7 @@ static inline int radix_tree_is_indirect_ptr(void *ptr)
 struct radix_tree_root {
 	unsigned int		height;
 	gfp_t			gfp_mask;
-	struct radix_tree_node	*rnode;
+	struct radix_tree_node	__rcu *rnode;
 };
 
 #define RADIX_TREE_INIT(mask)	{					\

commit f446daaea9d4a420d16c606f755f3689dcb2d0ce
Author: Jan Kara <jack@suse.cz>
Date:   Mon Aug 9 17:19:12 2010 -0700

    mm: implement writeback livelock avoidance using page tagging
    
    We try to avoid livelocks of writeback when some steadily creates dirty
    pages in a mapping we are writing out.  For memory-cleaning writeback,
    using nr_to_write works reasonably well but we cannot really use it for
    data integrity writeback.  This patch tries to solve the problem.
    
    The idea is simple: Tag all pages that should be written back with a
    special tag (TOWRITE) in the radix tree.  This can be done rather quickly
    and thus livelocks should not happen in practice.  Then we start doing the
    hard work of locking pages and sending them to disk only for those pages
    that have TOWRITE tag set.
    
    Note: Adding new radix tree tag grows radix tree node from 288 to 296
    bytes for 32-bit archs and from 552 to 560 bytes for 64-bit archs.
    However, the number of slab/slub items per page remains the same (13 and 7
    respectively).
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index a4b00e9cca90..634b8e674ac5 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -55,7 +55,7 @@ static inline int radix_tree_is_indirect_ptr(void *ptr)
 
 /*** radix-tree API starts here ***/
 
-#define RADIX_TREE_MAX_TAGS 2
+#define RADIX_TREE_MAX_TAGS 3
 
 /* root tags are stored in gfp_mask, shifted by __GFP_BITS_SHIFT */
 struct radix_tree_root {

commit ebf8aa44beed48cd17893a83d92a4403e5f9d9e2
Author: Jan Kara <jack@suse.cz>
Date:   Mon Aug 9 17:19:11 2010 -0700

    radix-tree: omplement function radix_tree_range_tag_if_tagged
    
    Implement function for setting one tag if another tag is set for each item
    in given range.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 55ca73cf25e5..a4b00e9cca90 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -192,6 +192,10 @@ unsigned int
 radix_tree_gang_lookup_tag_slot(struct radix_tree_root *root, void ***results,
 		unsigned long first_index, unsigned int max_items,
 		unsigned int tag);
+unsigned long radix_tree_range_tag_if_tagged(struct radix_tree_root *root,
+		unsigned long *first_indexp, unsigned long last_index,
+		unsigned long nr_to_tag,
+		unsigned int fromtag, unsigned int totag);
 int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);
 
 static inline void radix_tree_preload_end(void)

commit ce82653d6cfcc95ba88c25908664878459fb1b8d
Author: David Howells <dhowells@redhat.com>
Date:   Tue Apr 6 22:36:20 2010 +0100

    radix_tree_tag_get() is not as safe as the docs make out [ver #2]
    
    radix_tree_tag_get() is not safe to use concurrently with radix_tree_tag_set()
    or radix_tree_tag_clear().  The problem is that the double tag_get() in
    radix_tree_tag_get():
    
                    if (!tag_get(node, tag, offset))
                            saw_unset_tag = 1;
                    if (height == 1) {
                            int ret = tag_get(node, tag, offset);
    
    may see the value change due to the action of set/clear.  RCU is no protection
    against this as no pointers are being changed, no nodes are being replaced
    according to a COW protocol - set/clear alter the node directly.
    
    The documentation in linux/radix-tree.h, however, says that
    radix_tree_tag_get() is an exception to the rule that "any function modifying
    the tree or tags (...) must exclude other modifications, and exclude any
    functions reading the tree".
    
    The problem is that the next statement in radix_tree_tag_get() checks that the
    tag doesn't vary over time:
    
                            BUG_ON(ret && saw_unset_tag);
    
    This has been seen happening in FS-Cache:
    
            https://www.redhat.com/archives/linux-cachefs/2010-April/msg00013.html
    
    To this end, remove the BUG_ON() from radix_tree_tag_get() and note in various
    comments that the value of the tag may change whilst the RCU read lock is held,
    and thus that the return value of radix_tree_tag_get() may not be relied upon
    unless radix_tree_tag_set/clear() and radix_tree_delete() are excluded from
    running concurrently with it.
    
    Reported-by: Romain DEGEZ <romain.degez@smartjog.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index c5da74918096..55ca73cf25e5 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -121,6 +121,13 @@ do {									\
  * (Note, rcu_assign_pointer and rcu_dereference are not needed to control
  * access to data items when inserting into or looking up from the radix tree)
  *
+ * Note that the value returned by radix_tree_tag_get() may not be relied upon
+ * if only the RCU read lock is held.  Functions to set/clear tags and to
+ * delete nodes running concurrently with it may affect its result such that
+ * two consecutive reads in the same locked section may return different
+ * values.  If reliability is required, modification functions must also be
+ * excluded from concurrency.
+ *
  * radix_tree_tagged is able to be called without locking or RCU.
  */
 

commit dc566127dd161b6c997466a2349ac179527ea89b
Author: Wu Fengguang <fengguang.wu@intel.com>
Date:   Tue Jun 16 15:31:32 2009 -0700

    radix-tree: add radix_tree_prev_hole()
    
    The counterpart of radix_tree_next_hole(). To be used by context readahead.
    
    Signed-off-by: Wu Fengguang <fengguang.wu@intel.com>
    Cc: Vladislav Bolkhovitin <vst@vlnb.net>
    Cc: Jens Axboe <jens.axboe@oracle.com>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Ying Han <yinghan@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 355f6e80db0d..c5da74918096 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -167,6 +167,8 @@ radix_tree_gang_lookup_slot(struct radix_tree_root *root, void ***results,
 			unsigned long first_index, unsigned int max_items);
 unsigned long radix_tree_next_hole(struct radix_tree_root *root,
 				unsigned long index, unsigned long max_scan);
+unsigned long radix_tree_prev_hole(struct radix_tree_root *root,
+				unsigned long index, unsigned long max_scan);
 int radix_tree_preload(gfp_t gfp_mask);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *root,

commit e8c82c2e23e3527e0c9dc195e432c16784d270fa
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Jan 6 03:05:50 2009 +0100

    mm lockless pagecache barrier fix
    
    An XFS workload showed up a bug in the lockless pagecache patch. Basically it
    would go into an "infinite" loop, although it would sometimes be able to break
    out of the loop! The reason is a missing compiler barrier in the "increment
    reference count unless it was zero" case of the lockless pagecache protocol in
    the gang lookup functions.
    
    This would cause the compiler to use a cached value of struct page pointer to
    retry the operation with, rather than reload it. So the page might have been
    removed from pagecache and freed (refcount==0) but the lookup would not correctly
    notice the page is no longer in pagecache, and keep attempting to increment the
    refcount and failing, until the page gets reallocated for something else. This
    isn't a data corruption because the condition will be detected if the page has
    been reallocated. However it can result in a lockup.
    
    Linus points out that ACCESS_ONCE is also required in that pointer load, even
    if it's absence is not causing a bug on our particular build. The most general
    way to solve this is just to put an rcu_dereference in radix_tree_deref_slot.
    
    Assembly of find_get_pages,
    before:
    .L220:
            movq    (%rbx), %rax    #* ivtmp.1162, tmp82
            movq    (%rax), %rdi    #, prephitmp.1149
    .L218:
            testb   $1, %dil        #, prephitmp.1149
            jne     .L217   #,
            testq   %rdi, %rdi      # prephitmp.1149
            je      .L203   #,
            cmpq    $-1, %rdi       #, prephitmp.1149
            je      .L217   #,
            movl    8(%rdi), %esi   # <variable>._count.counter, c
            testl   %esi, %esi      # c
            je      .L218   #,
    
    after:
    .L212:
            movq    (%rbx), %rax    #* ivtmp.1109, tmp81
            movq    (%rax), %rdi    #, ret
            testb   $1, %dil        #, ret
            jne     .L211   #,
            testq   %rdi, %rdi      # ret
            je      .L197   #,
            cmpq    $-1, %rdi       #, ret
            je      .L211   #,
            movl    8(%rdi), %esi   # <variable>._count.counter, c
            testl   %esi, %esi      # c
            je      .L212   #,
    
    (notice the obvious infinite loop in the first example, if page->count remains 0)
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index a916c6660dfa..355f6e80db0d 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -136,7 +136,7 @@ do {									\
  */
 static inline void *radix_tree_deref_slot(void **pslot)
 {
-	void *ret = *pslot;
+	void *ret = rcu_dereference(*pslot);
 	if (unlikely(radix_tree_is_indirect_ptr(ret)))
 		ret = RADIX_TREE_RETRY;
 	return ret;

commit 47feff2c8eefe85099f87c43d3096855f0085ca0
Author: Nick Piggin <npiggin@suse.de>
Date:   Fri Jul 25 19:45:29 2008 -0700

    radix-tree: add gang_lookup_slot, gang_lookup_slot_tag
    
    Introduce gang_lookup_slot() and gang_lookup_slot_tag() functions, which
    are used by lockless pagecache.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Reviewed-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index b8ce2b444bb5..a916c6660dfa 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -99,12 +99,15 @@ do {									\
  *
  * The notable exceptions to this rule are the following functions:
  * radix_tree_lookup
+ * radix_tree_lookup_slot
  * radix_tree_tag_get
  * radix_tree_gang_lookup
+ * radix_tree_gang_lookup_slot
  * radix_tree_gang_lookup_tag
+ * radix_tree_gang_lookup_tag_slot
  * radix_tree_tagged
  *
- * The first 4 functions are able to be called locklessly, using RCU. The
+ * The first 7 functions are able to be called locklessly, using RCU. The
  * caller must ensure calls to these functions are made within rcu_read_lock()
  * regions. Other readers (lock-free or otherwise) and modifications may be
  * running concurrently.
@@ -159,6 +162,9 @@ void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int
 radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
 			unsigned long first_index, unsigned int max_items);
+unsigned int
+radix_tree_gang_lookup_slot(struct radix_tree_root *root, void ***results,
+			unsigned long first_index, unsigned int max_items);
 unsigned long radix_tree_next_hole(struct radix_tree_root *root,
 				unsigned long index, unsigned long max_scan);
 int radix_tree_preload(gfp_t gfp_mask);
@@ -173,6 +179,10 @@ unsigned int
 radix_tree_gang_lookup_tag(struct radix_tree_root *root, void **results,
 		unsigned long first_index, unsigned int max_items,
 		unsigned int tag);
+unsigned int
+radix_tree_gang_lookup_tag_slot(struct radix_tree_root *root, void ***results,
+		unsigned long first_index, unsigned int max_items,
+		unsigned int tag);
 int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);
 
 static inline void radix_tree_preload_end(void)

commit eb8dc5e7b58bfe56aa91bcc501b62f214bb401e8
Author: Tim Pepper <lnxninja@linux.vnet.ibm.com>
Date:   Sun Feb 3 16:12:47 2008 +0200

    radix_tree.h trivial comment correction
    
    There is an unmatched parenthesis in the locking commentary of radix_tree.h
    which is trivially fixed by the patch below.
    
    Signed-off-by: Tim Pepper <lnxninja@linux.vnet.ibm.com>
    Acked-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Adrian Bunk <bunk@kernel.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index b6116b4445c7..b8ce2b444bb5 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -91,7 +91,7 @@ do {									\
  *
  * For API usage, in general,
  * - any function _modifying_ the tree or tags (inserting or deleting
- *   items, setting or clearing tags must exclude other modifications, and
+ *   items, setting or clearing tags) must exclude other modifications, and
  *   exclude any functions reading the tree.
  * - any function _reading_ the tree or tags (looking up items or tags,
  *   gang lookups) must exclude modifications to the tree, but may occur

commit c0bc9875b701c588e448302d41181995c21e8040
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Oct 16 01:24:42 2007 -0700

    radix-tree: use indirect bit
    
    Rather than sign direct radix-tree pointers with a special bit, sign the
    indirect one that hangs off the root.  This means that, given a lookup_slot
    operation, the invalid result will be differentiated from the valid
    (previously, valid results could have the bit either set or clear).
    
    This does not affect slot lookups which occur under lock -- they can never
    return an invalid result.  Is needed in future for lockless pagecache.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 430e4a8c1382..b6116b4445c7 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -26,28 +26,31 @@
 #include <linux/rcupdate.h>
 
 /*
- * A direct pointer (root->rnode pointing directly to a data item,
- * rather than another radix_tree_node) is signalled by the low bit
- * set in the root->rnode pointer.
+ * An indirect pointer (root->rnode pointing to a radix_tree_node, rather
+ * than a data item) is signalled by the low bit set in the root->rnode
+ * pointer.
  *
- * In this case root->height is also NULL, but the direct pointer tests are
- * needed for RCU lookups when root->height is unreliable.
+ * In this case root->height is > 0, but the indirect pointer tests are
+ * needed for RCU lookups (because root->height is unreliable). The only
+ * time callers need worry about this is when doing a lookup_slot under
+ * RCU.
  */
-#define RADIX_TREE_DIRECT_PTR	1
+#define RADIX_TREE_INDIRECT_PTR	1
+#define RADIX_TREE_RETRY ((void *)-1UL)
 
-static inline void *radix_tree_ptr_to_direct(void *ptr)
+static inline void *radix_tree_ptr_to_indirect(void *ptr)
 {
-	return (void *)((unsigned long)ptr | RADIX_TREE_DIRECT_PTR);
+	return (void *)((unsigned long)ptr | RADIX_TREE_INDIRECT_PTR);
 }
 
-static inline void *radix_tree_direct_to_ptr(void *ptr)
+static inline void *radix_tree_indirect_to_ptr(void *ptr)
 {
-	return (void *)((unsigned long)ptr & ~RADIX_TREE_DIRECT_PTR);
+	return (void *)((unsigned long)ptr & ~RADIX_TREE_INDIRECT_PTR);
 }
 
-static inline int radix_tree_is_direct_ptr(void *ptr)
+static inline int radix_tree_is_indirect_ptr(void *ptr)
 {
-	return (int)((unsigned long)ptr & RADIX_TREE_DIRECT_PTR);
+	return (int)((unsigned long)ptr & RADIX_TREE_INDIRECT_PTR);
 }
 
 /*** radix-tree API starts here ***/
@@ -130,7 +133,10 @@ do {									\
  */
 static inline void *radix_tree_deref_slot(void **pslot)
 {
-	return radix_tree_direct_to_ptr(*pslot);
+	void *ret = *pslot;
+	if (unlikely(radix_tree_is_indirect_ptr(ret)))
+		ret = RADIX_TREE_RETRY;
+	return ret;
 }
 /**
  * radix_tree_replace_slot	- replace item in a slot
@@ -142,10 +148,8 @@ static inline void *radix_tree_deref_slot(void **pslot)
  */
 static inline void radix_tree_replace_slot(void **pslot, void *item)
 {
-	BUG_ON(radix_tree_is_direct_ptr(item));
-	rcu_assign_pointer(*pslot,
-		(void *)((unsigned long)item |
-			((unsigned long)*pslot & RADIX_TREE_DIRECT_PTR)));
+	BUG_ON(radix_tree_is_indirect_ptr(item));
+	rcu_assign_pointer(*pslot, item);
 }
 
 int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);

commit 6df8ba4f8a4c4abca9ccad10441d0dddbdff301c
Author: Fengguang Wu <wfg@mail.ustc.edu.cn>
Date:   Tue Oct 16 01:24:33 2007 -0700

    radixtree: introduce radix_tree_next_hole()
    
    Introduce radix_tree_next_hole(root, index, max_scan) to scan radix tree for
    the first hole.  It will be used in interleaved readahead.
    
    The implementation is dumb and obviously correct.  It can help debug(and
    document) the possible smart one in future.
    
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Signed-off-by: Fengguang Wu <wfg@mail.ustc.edu.cn>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index f9e77d2ee320..430e4a8c1382 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -155,6 +155,8 @@ void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int
 radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
 			unsigned long first_index, unsigned int max_items);
+unsigned long radix_tree_next_hole(struct radix_tree_root *root,
+				unsigned long index, unsigned long max_scan);
 int radix_tree_preload(gfp_t gfp_mask);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *root,

commit 59c51591a0ac7568824f541f57de967e88adaa07
Author: Michael Opdenacker <michael@free-electrons.com>
Date:   Wed May 9 08:57:56 2007 +0200

    Fix occurrences of "the the "
    
    Signed-off-by: Michael Opdenacker <michael@free-electrons.com>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 0deb842541ac..f9e77d2ee320 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -87,10 +87,10 @@ do {									\
  * management of their lifetimes must be completely managed by API users.
  *
  * For API usage, in general,
- * - any function _modifying_ the the tree or tags (inserting or deleting
+ * - any function _modifying_ the tree or tags (inserting or deleting
  *   items, setting or clearing tags must exclude other modifications, and
  *   exclude any functions reading the tree.
- * - any function _reading_ the the tree or tags (looking up items or tags,
+ * - any function _reading_ the tree or tags (looking up items or tags,
  *   gang lookups) must exclude modifications to the tree, but may occur
  *   concurrently with other readers.
  *

commit 7cf9c2c76c1a17b32f2da85b50cd4fe468ed44b5
Author: Nick Piggin <npiggin@suse.de>
Date:   Wed Dec 6 20:33:44 2006 -0800

    [PATCH] radix-tree: RCU lockless readside
    
    Make radix tree lookups safe to be performed without locks.  Readers are
    protected against nodes being deleted by using RCU based freeing.  Readers
    are protected against new node insertion by using memory barriers to ensure
    the node itself will be properly written before it is visible in the radix
    tree.
    
    Each radix tree node keeps a record of their height (above leaf nodes).
    This height does not change after insertion -- when the radix tree is
    extended, higher nodes are only inserted in the top.  So a lookup can take
    the pointer to what is *now* the root node, and traverse down it even if
    the tree is concurrently extended and this node becomes a subtree of a new
    root.
    
    "Direct" pointers (tree height of 0, where root->rnode points directly to
    the data item) are handled by using the low bit of the pointer to signal
    whether rnode is a direct pointer or a pointer to a radix tree node.
    
    When a reader wants to traverse the next branch, they will take a copy of
    the pointer.  This pointer will be either NULL (and the branch is empty) or
    non-NULL (and will point to a valid node).
    
    [akpm@osdl.org: cleanups]
    [Lee.Schermerhorn@hp.com: bugfixes, comments, simplifications]
    [clameter@sgi.com: build fix]
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Christoph Lameter <clameter@engr.sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index cbfa11537421..0deb842541ac 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -1,6 +1,7 @@
 /*
  * Copyright (C) 2001 Momchil Velikov
  * Portions Copyright (C) 2001 Christoph Hellwig
+ * Copyright (C) 2006 Nick Piggin
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License as
@@ -21,6 +22,35 @@
 
 #include <linux/preempt.h>
 #include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/rcupdate.h>
+
+/*
+ * A direct pointer (root->rnode pointing directly to a data item,
+ * rather than another radix_tree_node) is signalled by the low bit
+ * set in the root->rnode pointer.
+ *
+ * In this case root->height is also NULL, but the direct pointer tests are
+ * needed for RCU lookups when root->height is unreliable.
+ */
+#define RADIX_TREE_DIRECT_PTR	1
+
+static inline void *radix_tree_ptr_to_direct(void *ptr)
+{
+	return (void *)((unsigned long)ptr | RADIX_TREE_DIRECT_PTR);
+}
+
+static inline void *radix_tree_direct_to_ptr(void *ptr)
+{
+	return (void *)((unsigned long)ptr & ~RADIX_TREE_DIRECT_PTR);
+}
+
+static inline int radix_tree_is_direct_ptr(void *ptr)
+{
+	return (int)((unsigned long)ptr & RADIX_TREE_DIRECT_PTR);
+}
+
+/*** radix-tree API starts here ***/
 
 #define RADIX_TREE_MAX_TAGS 2
 
@@ -47,6 +77,77 @@ do {									\
 	(root)->rnode = NULL;						\
 } while (0)
 
+/**
+ * Radix-tree synchronization
+ *
+ * The radix-tree API requires that users provide all synchronisation (with
+ * specific exceptions, noted below).
+ *
+ * Synchronization of access to the data items being stored in the tree, and
+ * management of their lifetimes must be completely managed by API users.
+ *
+ * For API usage, in general,
+ * - any function _modifying_ the the tree or tags (inserting or deleting
+ *   items, setting or clearing tags must exclude other modifications, and
+ *   exclude any functions reading the tree.
+ * - any function _reading_ the the tree or tags (looking up items or tags,
+ *   gang lookups) must exclude modifications to the tree, but may occur
+ *   concurrently with other readers.
+ *
+ * The notable exceptions to this rule are the following functions:
+ * radix_tree_lookup
+ * radix_tree_tag_get
+ * radix_tree_gang_lookup
+ * radix_tree_gang_lookup_tag
+ * radix_tree_tagged
+ *
+ * The first 4 functions are able to be called locklessly, using RCU. The
+ * caller must ensure calls to these functions are made within rcu_read_lock()
+ * regions. Other readers (lock-free or otherwise) and modifications may be
+ * running concurrently.
+ *
+ * It is still required that the caller manage the synchronization and lifetimes
+ * of the items. So if RCU lock-free lookups are used, typically this would mean
+ * that the items have their own locks, or are amenable to lock-free access; and
+ * that the items are freed by RCU (or only freed after having been deleted from
+ * the radix tree *and* a synchronize_rcu() grace period).
+ *
+ * (Note, rcu_assign_pointer and rcu_dereference are not needed to control
+ * access to data items when inserting into or looking up from the radix tree)
+ *
+ * radix_tree_tagged is able to be called without locking or RCU.
+ */
+
+/**
+ * radix_tree_deref_slot	- dereference a slot
+ * @pslot:	pointer to slot, returned by radix_tree_lookup_slot
+ * Returns:	item that was stored in that slot with any direct pointer flag
+ *		removed.
+ *
+ * For use with radix_tree_lookup_slot().  Caller must hold tree at least read
+ * locked across slot lookup and dereference.  More likely, will be used with
+ * radix_tree_replace_slot(), as well, so caller will hold tree write locked.
+ */
+static inline void *radix_tree_deref_slot(void **pslot)
+{
+	return radix_tree_direct_to_ptr(*pslot);
+}
+/**
+ * radix_tree_replace_slot	- replace item in a slot
+ * @pslot:	pointer to slot, returned by radix_tree_lookup_slot
+ * @item:	new item to store in the slot.
+ *
+ * For use with radix_tree_lookup_slot().  Caller must hold tree write locked
+ * across slot lookup and replacement.
+ */
+static inline void radix_tree_replace_slot(void **pslot, void *item)
+{
+	BUG_ON(radix_tree_is_direct_ptr(item));
+	rcu_assign_pointer(*pslot,
+		(void *)((unsigned long)item |
+			((unsigned long)*pslot & RADIX_TREE_DIRECT_PTR)));
+}
+
 int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);

commit 914e26379decf1fd984b22e51fd2e4209b7a7f1b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Oct 18 13:55:46 2006 -0400

    [PATCH] severing fs.h, radix-tree.h -> sched.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 9158a68140c9..cbfa11537421 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -19,7 +19,6 @@
 #ifndef _LINUX_RADIX_TREE_H
 #define _LINUX_RADIX_TREE_H
 
-#include <linux/sched.h>
 #include <linux/preempt.h>
 #include <linux/types.h>
 

commit 612d6c19db2fd0dc97b0fa370613ecd4a305ffc3
Author: Nick Piggin <npiggin@suse.de>
Date:   Fri Jun 23 02:03:22 2006 -0700

    [PATCH] radix-tree: direct data
    
    The ability to have height 0 radix trees (a direct pointer to the data item
    rather than going through a full node->slot) quietly disappeared with
    old-2.6-bkcvs commit ffee171812d51652f9ba284302d9e5c5cc14bdfd.  On 64-bit
    machines this causes nearly 600 bytes to be used for every <= 4K file in
    pagecache.
    
    Re-introduce this feature, root tags stored in spare ->gfp_mask bits.
    
    Simplify radix_tree_delete's complex tag clearing arrangement (which would
    become even more complex) by just falling back to tag clearing functions
    (the pagecache radix-tree never uses this path anyway, so the icache
    savings will mean it's actually a speedup).
    
    On my 4GB G5, this saves 8MB RAM per kernel kernel source+object tree in
    pagecache.
    
    Pagecache lookup, insertion, and removal speed for small files will also be
    improved.
    
    This makes RCU radix tree harder, but it's worth it.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index dd83cca28001..9158a68140c9 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -23,6 +23,9 @@
 #include <linux/preempt.h>
 #include <linux/types.h>
 
+#define RADIX_TREE_MAX_TAGS 2
+
+/* root tags are stored in gfp_mask, shifted by __GFP_BITS_SHIFT */
 struct radix_tree_root {
 	unsigned int		height;
 	gfp_t			gfp_mask;
@@ -45,8 +48,6 @@ do {									\
 	(root)->rnode = NULL;						\
 } while (0)
 
-#define RADIX_TREE_MAX_TAGS 2
-
 int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);

commit daff89f324755f87a060d5125a205c0755811ea9
Author: Jonathan Corbet <corbet@lwn.net>
Date:   Sat Mar 25 03:08:05 2006 -0800

    [PATCH] radix-tree documentation cleanups
    
    Documentation changes to help radix tree users avoid overrunning the tags
    array.  RADIX_TREE_TAGS moves to linux/radix-tree.h and is now known as
    RADIX_TREE_MAX_TAGS (Nick Piggin's idea).  Tag parameters are changed to
    unsigned, and some comments are updated.
    
    Signed-off-by: Jonathan Corbet <corbet@lwn.net>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index c57ff2fcb30a..dd83cca28001 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -45,6 +45,8 @@ do {									\
 	(root)->rnode = NULL;						\
 } while (0)
 
+#define RADIX_TREE_MAX_TAGS 2
+
 int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
 void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
@@ -55,15 +57,16 @@ radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
 int radix_tree_preload(gfp_t gfp_mask);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *root,
-			unsigned long index, int tag);
+			unsigned long index, unsigned int tag);
 void *radix_tree_tag_clear(struct radix_tree_root *root,
-			unsigned long index, int tag);
+			unsigned long index, unsigned int tag);
 int radix_tree_tag_get(struct radix_tree_root *root,
-			unsigned long index, int tag);
+			unsigned long index, unsigned int tag);
 unsigned int
 radix_tree_gang_lookup_tag(struct radix_tree_root *root, void **results,
-		unsigned long first_index, unsigned int max_items, int tag);
-int radix_tree_tagged(struct radix_tree_root *root, int tag);
+		unsigned long first_index, unsigned int max_items,
+		unsigned int tag);
+int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);
 
 static inline void radix_tree_preload_end(void)
 {

commit 095975da26dba21698582e91e96be10f7417333f
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Sun Jan 8 01:02:19 2006 -0800

    [PATCH] rcu file: use atomic primitives
    
    Use atomic_inc_not_zero for rcu files instead of special case rcuref.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 36e5d269612f..c57ff2fcb30a 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -19,6 +19,7 @@
 #ifndef _LINUX_RADIX_TREE_H
 #define _LINUX_RADIX_TREE_H
 
+#include <linux/sched.h>
 #include <linux/preempt.h>
 #include <linux/types.h>
 

commit a43313668f62a06e14c915b8c8994fc8a1257394
Author: Hans Reiser <reiser@namesys.com>
Date:   Mon Nov 7 00:59:29 2005 -0800

    [PATCH] reiser4: add radix_tree_lookup_slot()
    
    Reiser4 uses radix trees to solve a trouble reiser4_readdir has serving nfs
    requests.
    
    Unfortunately, radix tree api lacks an operation suitable for modifying
    existing entry.  This patch adds radix_tree_lookup_slot which returns pointer
    to found item within the tree.  That location can be then updated.
    
    Both Nick and Christoph Lameter have patches which need this as well.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 9f0f9281f42a..36e5d269612f 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -46,6 +46,7 @@ do {									\
 
 int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
 void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
+void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);
 void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int
 radix_tree_gang_lookup(struct radix_tree_root *root, void **results,

commit fd4f2df24bc23e6b8fc069765b425c7dacf52347
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Oct 21 03:18:50 2005 -0400

    [PATCH] gfp_t: lib/*
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 045d4761febc..9f0f9281f42a 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -24,7 +24,7 @@
 
 struct radix_tree_root {
 	unsigned int		height;
-	unsigned int		gfp_mask;
+	gfp_t			gfp_mask;
 	struct radix_tree_node	*rnode;
 };
 

commit dd0fc66fb33cd610bc1a5db8a5e232d34879b4d7
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Fri Oct 7 07:46:04 2005 +0100

    [PATCH] gfp flags annotations - part 1
    
     - added typedef unsigned int __nocast gfp_t;
    
     - replaced __nocast uses for gfp flags with gfp_t - it gives exactly
       the same warnings as far as sparse is concerned, doesn't change
       generated code (from gcc point of view we replaced unsigned int with
       typedef) and documents what's going on far better.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 9c51917b1cce..045d4761febc 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -50,7 +50,7 @@ void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int
 radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
 			unsigned long first_index, unsigned int max_items);
-int radix_tree_preload(unsigned int __nocast gfp_mask);
+int radix_tree_preload(gfp_t gfp_mask);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *root,
 			unsigned long index, int tag);

commit 00b61f51922e432fd92a482ba1e0b5f8f326ef46
Author: Victor Fusco <victor@cetuc.puc-rio.br>
Date:   Sat Sep 10 00:26:48 2005 -0700

    [PATCH] lib/radix-tree: Fix "nocast type" warnings
    
    Fix the sparse warning "implicit cast to nocast type"
    
    Signed-off-by: Victor Fusco <victor@cetuc.puc-rio.br>
    Signed-off-by: Domen Puncer <domen@coderock.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
index 8081a281fa5e..9c51917b1cce 100644
--- a/include/linux/radix-tree.h
+++ b/include/linux/radix-tree.h
@@ -24,7 +24,7 @@
 
 struct radix_tree_root {
 	unsigned int		height;
-	int			gfp_mask;
+	unsigned int		gfp_mask;
 	struct radix_tree_node	*rnode;
 };
 
@@ -50,7 +50,7 @@ void *radix_tree_delete(struct radix_tree_root *, unsigned long);
 unsigned int
 radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
 			unsigned long first_index, unsigned int max_items);
-int radix_tree_preload(int gfp_mask);
+int radix_tree_preload(unsigned int __nocast gfp_mask);
 void radix_tree_init(void);
 void *radix_tree_tag_set(struct radix_tree_root *root,
 			unsigned long index, int tag);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/radix-tree.h b/include/linux/radix-tree.h
new file mode 100644
index 000000000000..8081a281fa5e
--- /dev/null
+++ b/include/linux/radix-tree.h
@@ -0,0 +1,71 @@
+/*
+ * Copyright (C) 2001 Momchil Velikov
+ * Portions Copyright (C) 2001 Christoph Hellwig
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2, or (at
+ * your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+#ifndef _LINUX_RADIX_TREE_H
+#define _LINUX_RADIX_TREE_H
+
+#include <linux/preempt.h>
+#include <linux/types.h>
+
+struct radix_tree_root {
+	unsigned int		height;
+	int			gfp_mask;
+	struct radix_tree_node	*rnode;
+};
+
+#define RADIX_TREE_INIT(mask)	{					\
+	.height = 0,							\
+	.gfp_mask = (mask),						\
+	.rnode = NULL,							\
+}
+
+#define RADIX_TREE(name, mask) \
+	struct radix_tree_root name = RADIX_TREE_INIT(mask)
+
+#define INIT_RADIX_TREE(root, mask)					\
+do {									\
+	(root)->height = 0;						\
+	(root)->gfp_mask = (mask);					\
+	(root)->rnode = NULL;						\
+} while (0)
+
+int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);
+void *radix_tree_lookup(struct radix_tree_root *, unsigned long);
+void *radix_tree_delete(struct radix_tree_root *, unsigned long);
+unsigned int
+radix_tree_gang_lookup(struct radix_tree_root *root, void **results,
+			unsigned long first_index, unsigned int max_items);
+int radix_tree_preload(int gfp_mask);
+void radix_tree_init(void);
+void *radix_tree_tag_set(struct radix_tree_root *root,
+			unsigned long index, int tag);
+void *radix_tree_tag_clear(struct radix_tree_root *root,
+			unsigned long index, int tag);
+int radix_tree_tag_get(struct radix_tree_root *root,
+			unsigned long index, int tag);
+unsigned int
+radix_tree_gang_lookup_tag(struct radix_tree_root *root, void **results,
+		unsigned long first_index, unsigned int max_items, int tag);
+int radix_tree_tagged(struct radix_tree_root *root, int tag);
+
+static inline void radix_tree_preload_end(void)
+{
+	preempt_enable();
+}
+
+#endif /* _LINUX_RADIX_TREE_H */
