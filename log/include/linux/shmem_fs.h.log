commit 396bcc5299c281e9cf1737ad0efcd97be9f83845
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Mon Apr 6 20:04:35 2020 -0700

    mm: remove CONFIG_TRANSPARENT_HUGE_PAGECACHE
    
    Commit e496cf3d7821 ("thp: introduce CONFIG_TRANSPARENT_HUGE_PAGECACHE")
    notes that it should be reverted when the PowerPC problem was fixed.  The
    commit fixing the PowerPC problem (953c66c2b22a) did not revert the
    commit; instead setting CONFIG_TRANSPARENT_HUGE_PAGECACHE to the same as
    CONFIG_TRANSPARENT_HUGEPAGE.  Checking with Kirill and Aneesh, this was an
    oversight, so remove the Kconfig symbol and undo the work of commit
    e496cf3d7821.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Pankaj Gupta <pankaj.gupta.linux@gmail.com>
    Link: http://lkml.kernel.org/r/20200318140253.6141-6-willy@infradead.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index d56fefef8905..7a35a6901221 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -78,6 +78,7 @@ extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);
 extern int shmem_unuse(unsigned int type, bool frontswap,
 		       unsigned long *fs_pages_to_unuse);
 
+extern bool shmem_huge_enabled(struct vm_area_struct *vma);
 extern unsigned long shmem_swap_usage(struct vm_area_struct *vma);
 extern unsigned long shmem_partial_swap_usage(struct address_space *mapping,
 						pgoff_t start, pgoff_t end);
@@ -114,15 +115,6 @@ static inline bool shmem_file(struct file *file)
 extern bool shmem_charge(struct inode *inode, long pages);
 extern void shmem_uncharge(struct inode *inode, long pages);
 
-#ifdef CONFIG_TRANSPARENT_HUGE_PAGECACHE
-extern bool shmem_huge_enabled(struct vm_area_struct *vma);
-#else
-static inline bool shmem_huge_enabled(struct vm_area_struct *vma)
-{
-	return false;
-}
-#endif
-
 #ifdef CONFIG_SHMEM
 extern int shmem_mcopy_atomic_pte(struct mm_struct *dst_mm, pmd_t *dst_pmd,
 				  struct vm_area_struct *dst_vma,

commit d7167b149943e38ad610191ecbb0800c78bbced9
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Sep 7 07:23:15 2019 -0400

    fs_parse: fold fs_parameter_desc/fs_parameter_spec
    
    The former contains nothing but a pointer to an array of the latter...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index de8e4b71e3ba..d56fefef8905 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -8,6 +8,7 @@
 #include <linux/pagemap.h>
 #include <linux/percpu_counter.h>
 #include <linux/xattr.h>
+#include <linux/fs_parser.h>
 
 /* inode in-kernel data */
 
@@ -49,7 +50,7 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 /*
  * Functions in mm/shmem.c called directly from elsewhere:
  */
-extern const struct fs_parameter_description shmem_fs_parameters;
+extern const struct fs_parameter_spec shmem_fs_parameters[];
 extern int shmem_init(void);
 extern int shmem_init_fs_context(struct fs_context *fc);
 extern struct file *shmem_file_setup(const char *name,

commit f32356261d44d580649a7abce1156d15d49cf20f
Author: David Howells <dhowells@redhat.com>
Date:   Mon Mar 25 16:38:31 2019 +0000

    vfs: Convert ramfs, shmem, tmpfs, devtmpfs, rootfs to use the new mount API
    
    Convert the ramfs, shmem, tmpfs, devtmpfs and rootfs filesystems to the new
    internal mount API as the old one will be obsoleted and removed.  This
    allows greater flexibility in communication of mount parameters between
    userspace, the VFS and the filesystem.
    
    See Documentation/filesystems/mount_api.txt for more information.
    
    Note that tmpfs is slightly tricky as it can contain embedded commas, so it
    can't be trivially split up using strsep() to break on commas in
    generic_parse_monolithic().  Instead, tmpfs has to supply its own generic
    parser.
    
    However, if tmpfs changes, then devtmpfs and rootfs, which are wrappers
    around tmpfs or ramfs, must change too - and thus so must ramfs, so these
    had to be converted also.
    
    [AV: rewritten]
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Hugh Dickins <hughd@google.com>
    cc: linux-mm@kvack.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 88cb98b0e49b..de8e4b71e3ba 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -49,9 +49,9 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 /*
  * Functions in mm/shmem.c called directly from elsewhere:
  */
+extern const struct fs_parameter_description shmem_fs_parameters;
 extern int shmem_init(void);
-extern struct dentry *shmem_mount(struct file_system_type *fs_type,
-	int flags, const char *dev_name, void *data);
+extern int shmem_init_fs_context(struct fs_context *fc);
 extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);
 extern struct file *shmem_kernel_file_setup(const char *name, loff_t size,

commit 7e30d2a5eb0b2d5853f06cb8a2d44937d80a6bd6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jun 1 18:56:53 2019 -0400

    make shmem_fill_super() static
    
    ... have callers use shmem_mount()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 20d815a33145..88cb98b0e49b 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -50,7 +50,8 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
  * Functions in mm/shmem.c called directly from elsewhere:
  */
 extern int shmem_init(void);
-extern int shmem_fill_super(struct super_block *sb, void *data, int silent);
+extern struct dentry *shmem_mount(struct file_system_type *fs_type,
+	int flags, const char *dev_name, void *data);
 extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);
 extern struct file *shmem_kernel_file_setup(const char *name, loff_t size,

commit af53d3e9e04024885de5b4fda51e5fa362ae2bd8
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Apr 18 17:50:13 2019 -0700

    mm: swapoff: shmem_unuse() stop eviction without igrab()
    
    The igrab() in shmem_unuse() looks good, but we forgot that it gives no
    protection against concurrent unmounting: a point made by Konstantin
    Khlebnikov eight years ago, and then fixed in 2.6.39 by 778dd893ae78
    ("tmpfs: fix race between umount and swapoff").  The current 5.1-rc
    swapoff is liable to hit "VFS: Busy inodes after unmount of tmpfs.
    Self-destruct in 5 seconds.  Have a nice day..." followed by GPF.
    
    Once again, give up on using igrab(); but don't go back to making such
    heavy-handed use of shmem_swaplist_mutex as last time: that would spoil
    the new design, and I expect could deadlock inside shmem_swapin_page().
    
    Instead, shmem_unuse() just raise a "stop_eviction" count in the shmem-
    specific inode, and shmem_evict_inode() wait for that to go down to 0.
    Call it "stop_eviction" rather than "swapoff_busy" because it can be put
    to use for others later (huge tmpfs patches expect to use it).
    
    That simplifies shmem_unuse(), protecting it from both unlink and
    unmount; and in practice lets it locate all the swap in its first try.
    But do not rely on that: there's still a theoretical case, when
    shmem_writepage() might have been preempted after its get_swap_page(),
    before making the swap entry visible to swapoff.
    
    [hughd@google.com: remove incorrect list_del()]
      Link: http://lkml.kernel.org/r/alpine.LSU.2.11.1904091133570.1898@eggly.anvils
    Link: http://lkml.kernel.org/r/alpine.LSU.2.11.1904081259400.1523@eggly.anvils
    Fixes: b56a2d8af914 ("mm: rid swapoff of quadratic complexity")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: "Alex Xu (Hello71)" <alex_y_xu@yahoo.ca>
    Cc: Huang Ying <ying.huang@intel.com>
    Cc: Kelley Nielsen <kelleynnn@gmail.com>
    Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Vineeth Pillai <vpillai@digitalocean.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index f3fb1edb3526..20d815a33145 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -21,6 +21,7 @@ struct shmem_inode_info {
 	struct list_head	swaplist;	/* chain of maybes on swap */
 	struct shared_policy	policy;		/* NUMA memory alloc policy */
 	struct simple_xattrs	xattrs;		/* list of xattrs */
+	atomic_t		stop_eviction;	/* hold when working on inode */
 	struct inode		vfs_inode;
 };
 

commit b56a2d8af9147a4efe4011b60d93779c0461ca97
Author: Vineeth Remanan Pillai <vpillai@digitalocean.com>
Date:   Tue Mar 5 15:47:03 2019 -0800

    mm: rid swapoff of quadratic complexity
    
    This patch was initially posted by Kelley Nielsen.  Reposting the patch
    with all review comments addressed and with minor modifications and
    optimizations.  Also, folding in the fixes offered by Hugh Dickins and
    Huang Ying.  Tests were rerun and commit message updated with new
    results.
    
    try_to_unuse() is of quadratic complexity, with a lot of wasted effort.
    It unuses swap entries one by one, potentially iterating over all the
    page tables for all the processes in the system for each one.
    
    This new proposed implementation of try_to_unuse simplifies its
    complexity to linear.  It iterates over the system's mms once, unusing
    all the affected entries as it walks each set of page tables.  It also
    makes similar changes to shmem_unuse.
    
    Improvement
    
    swapoff was called on a swap partition containing about 6G of data, in a
    VM(8cpu, 16G RAM), and calls to unuse_pte_range() were counted.
    
    Present implementation....about 1200M calls(8min, avg 80% cpu util).
    Prototype.................about  9.0K calls(3min, avg 5% cpu util).
    
    Details
    
    In shmem_unuse(), iterate over the shmem_swaplist and, for each
    shmem_inode_info that contains a swap entry, pass it to
    shmem_unuse_inode(), along with the swap type.  In shmem_unuse_inode(),
    iterate over its associated xarray, and store the index and value of
    each swap entry in an array for passing to shmem_swapin_page() outside
    of the RCU critical section.
    
    In try_to_unuse(), instead of iterating over the entries in the type and
    unusing them one by one, perhaps walking all the page tables for all the
    processes for each one, iterate over the mmlist, making one pass.  Pass
    each mm to unuse_mm() to begin its page table walk, and during the walk,
    unuse all the ptes that have backing store in the swap type received by
    try_to_unuse().  After the walk, check the type for orphaned swap
    entries with find_next_to_unuse(), and remove them from the swap cache.
    If find_next_to_unuse() starts over at the beginning of the type, repeat
    the check of the shmem_swaplist and the walk a maximum of three times.
    
    Change unuse_mm() and the intervening walk functions down to
    unuse_pte_range() to take the type as a parameter, and to iterate over
    their entire range, calling the next function down on every iteration.
    In unuse_pte_range(), make a swap entry from each pte in the range using
    the passed in type.  If it has backing store in the type, call
    swapin_readahead() to retrieve the page and pass it to unuse_pte().
    
    Pass the count of pages_to_unuse down the page table walks in
    try_to_unuse(), and return from the walk when the desired number of
    pages has been swapped back in.
    
    Link: http://lkml.kernel.org/r/20190114153129.4852-2-vpillai@digitalocean.com
    Signed-off-by: Vineeth Remanan Pillai <vpillai@digitalocean.com>
    Signed-off-by: Kelley Nielsen <kelleynnn@gmail.com>
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Cc: Rik van Riel <riel@surriel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index f155dc607112..f3fb1edb3526 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -72,7 +72,8 @@ extern void shmem_unlock_mapping(struct address_space *mapping);
 extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 					pgoff_t index, gfp_t gfp_mask);
 extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);
-extern int shmem_unuse(swp_entry_t entry, struct page *page);
+extern int shmem_unuse(unsigned int type, bool frontswap,
+		       unsigned long *fs_pages_to_unuse);
 
 extern unsigned long shmem_swap_usage(struct vm_area_struct *vma);
 extern unsigned long shmem_partial_swap_usage(struct address_space *mapping,

commit 5d752600a8c373382264392f5b573b2fc9c0e8ea
Author: Mike Kravetz <mike.kravetz@oracle.com>
Date:   Thu Jun 7 17:06:01 2018 -0700

    mm: restructure memfd code
    
    With the addition of memfd hugetlbfs support, we now have the situation
    where memfd depends on TMPFS -or- HUGETLBFS.  Previously, memfd was only
    supported on tmpfs, so it made sense that the code resided in shmem.c.
    In the current code, memfd is only functional if TMPFS is defined.  If
    HUGETLFS is defined and TMPFS is not defined, then memfd functionality
    will not be available for hugetlbfs.  This does not cause BUGs, just a
    lack of potentially desired functionality.
    
    Code is restructured in the following way:
    - include/linux/memfd.h is a new file containing memfd specific
      definitions previously contained in shmem_fs.h.
    - mm/memfd.c is a new file containing memfd specific code previously
      contained in shmem.c.
    - memfd specific code is removed from shmem_fs.h and shmem.c.
    - A new config option MEMFD_CREATE is added that is defined if TMPFS
      or HUGETLBFS is defined.
    
    No functional changes are made to the code: restructuring only.
    
    Link: http://lkml.kernel.org/r/20180415182119.4517-4-mike.kravetz@oracle.com
    Signed-off-by: Mike Kravetz <mike.kravetz@oracle.com>
    Reviewed-by: Khalid Aziz <khalid.aziz@oracle.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Herrmann <dh.herrmann@gmail.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marc-Andr Lureau <marcandre.lureau@gmail.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 73b5e655a76e..f155dc607112 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -110,19 +110,6 @@ static inline bool shmem_file(struct file *file)
 extern bool shmem_charge(struct inode *inode, long pages);
 extern void shmem_uncharge(struct inode *inode, long pages);
 
-#ifdef CONFIG_TMPFS
-
-extern long memfd_fcntl(struct file *file, unsigned int cmd, unsigned long arg);
-
-#else
-
-static inline long memfd_fcntl(struct file *f, unsigned int c, unsigned long a)
-{
-	return -EINVAL;
-}
-
-#endif
-
 #ifdef CONFIG_TRANSPARENT_HUGE_PAGECACHE
 extern bool shmem_huge_enabled(struct vm_area_struct *vma);
 #else

commit 5aadc431a593ac1f3a026dfbceaa16cc4d5e15ca
Author: Marc-André Lureau <marcandre.lureau@redhat.com>
Date:   Wed Jan 31 16:19:18 2018 -0800

    shmem: rename functions that are memfd-related
    
    Those functions are called for memfd files, backed by shmem or hugetlb
    (the next patches will handle hugetlb).
    
    Link: http://lkml.kernel.org/r/20171107122800.25517-3-marcandre.lureau@redhat.com
    Signed-off-by: Marc-André Lureau <marcandre.lureau@redhat.com>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: David Herrmann <dh.herrmann@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index e464815a7e4c..73b5e655a76e 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -112,11 +112,11 @@ extern void shmem_uncharge(struct inode *inode, long pages);
 
 #ifdef CONFIG_TMPFS
 
-extern long shmem_fcntl(struct file *file, unsigned int cmd, unsigned long arg);
+extern long memfd_fcntl(struct file *file, unsigned int cmd, unsigned long arg);
 
 #else
 
-static inline long shmem_fcntl(struct file *f, unsigned int c, unsigned long a)
+static inline long memfd_fcntl(struct file *f, unsigned int c, unsigned long a)
 {
 	return -EINVAL;
 }

commit e9d586a8217882eb4068e3ed94a5234ba6dead34
Author: Marc-André Lureau <marcandre.lureau@redhat.com>
Date:   Wed Jan 31 16:19:14 2018 -0800

    shmem: unexport shmem_add_seals()/shmem_get_seals()
    
    Patch series "memfd: add sealing to hugetlb-backed memory", v3.
    
    Recently, Mike Kravetz added hugetlbfs support to memfd.  However, he
    didn't add sealing support.  One of the reasons to use memfd is to have
    shared memory sealing when doing IPC or sharing memory with another
    process with some extra safety.  qemu uses shared memory & hugetables
    with vhost-user (used by dpdk), so it is reasonable to use memfd now
    instead for convenience and security reasons.
    
    This patch (of 9):
    
    The functions are called through shmem_fcntl() only.  And no danger in
    removing the EXPORTs as the routines only work with shmem file structs.
    
    Link: http://lkml.kernel.org/r/20171107122800.25517-2-marcandre.lureau@redhat.com
    Signed-off-by: Marc-André Lureau <marcandre.lureau@redhat.com>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: David Herrmann <dh.herrmann@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 06b295bec00d..e464815a7e4c 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -112,8 +112,6 @@ extern void shmem_uncharge(struct inode *inode, long pages);
 
 #ifdef CONFIG_TMPFS
 
-extern int shmem_add_seals(struct file *file, unsigned int seals);
-extern int shmem_get_seals(struct file *file);
 extern long shmem_fcntl(struct file *file, unsigned int cmd, unsigned long arg);
 
 #else

commit e60e1ee60630cafef5e430c2ae364877e061d980
Merge: 5d352e69c60e f150891fd987
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 15 20:42:10 2017 -0800

    Merge tag 'drm-for-v4.15' of git://people.freedesktop.org/~airlied/linux
    
    Pull drm updates from Dave Airlie:
     "This is the main drm pull request for v4.15.
    
      Core:
       - Atomic object lifetime fixes
       - Atomic iterator improvements
       - Sparse/smatch fixes
       - Legacy kms ioctls to be interruptible
       - EDID override improvements
       - fb/gem helper cleanups
       - Simple outreachy patches
       - Documentation improvements
       - Fix dma-buf rcu races
       - DRM mode object leasing for improving VR use cases.
       - vgaarb improvements for non-x86 platforms.
    
      New driver:
       - tve200: Faraday Technology TVE200 block.
    
         This "TV Encoder" encodes a ITU-T BT.656 stream and can be found in
         the StorLink SL3516 (later Cortina Systems CS3516) as well as the
         Grain Media GM8180.
    
      New bridges:
       - SiI9234 support
    
      New panels:
       - S6E63J0X03, OTM8009A, Seiko 43WVF1G, 7" rpi touch panel, Toshiba
         LT089AC19000, Innolux AT043TN24
    
      i915:
       - Remove Coffeelake from alpha support
       - Cannonlake workarounds
       - Infoframe refactoring for DisplayPort
       - VBT updates
       - DisplayPort vswing/emph/buffer translation refactoring
       - CCS fixes
       - Restore GPU clock boost on missed vblanks
       - Scatter list updates for userptr allocations
       - Gen9+ transition watermarks
       - Display IPC (Isochronous Priority Control)
       - Private PAT management
       - GVT: improved error handling and pci config sanitizing
       - Execlist refactoring
       - Transparent Huge Page support
       - User defined priorities support
       - HuC/GuC firmware refactoring
       - DP MST fixes
       - eDP power sequencing fixes
       - Use RCU instead of stop_machine
       - PSR state tracking support
       - Eviction fixes
       - BDW DP aux channel timeout fixes
       - LSPCON fixes
       - Cannonlake PLL fixes
    
      amdgpu:
       - Per VM BO support
       - Powerplay cleanups
       - CI powerplay support
       - PASID mgr for kfd
       - SR-IOV fixes
       - initial GPU reset for vega10
       - Prime mmap support
       - TTM updates
       - Clock query interface for Raven
       - Fence to handle ioctl
       - UVD encode ring support on Polaris
       - Transparent huge page DMA support
       - Compute LRU pipe tweaks
       - BO flag to allow buffers to opt out of implicit sync
       - CTX priority setting API
       - VRAM lost infrastructure plumbing
    
      qxl:
       - fix flicker since atomic rework
    
      amdkfd:
       - Further improvements from internal AMD tree
       - Usermode events
       - Drop radeon support
    
      nouveau:
       - Pascal temperature sensor support
       - Improved BAR2 handling
       - MMU rework to support Pascal MMU
    
      exynos:
       - Improved HDMI/mixer support
       - HDMI audio interface support
    
      tegra:
       - Prep work for tegra186
       - Cleanup/fixes
    
      msm:
       - Preemption support for a5xx
       - Display fixes for 8x96 (snapdragon 820)
       - Async cursor plane fixes
       - FW loading rework
       - GPU debugging improvements
    
      vc4:
       - Prep for DSI panels
       - fix T-format tiling scanout
       - New madvise ioctl
    
      Rockchip:
       - LVDS support
    
      omapdrm:
       - omap4 HDMI CEC support
    
      etnaviv:
       - GPU performance counters groundwork
    
      sun4i:
       - refactor driver load + TCON backend
       - HDMI improvements
       - A31 support
       - Misc fixes
    
      udl:
       - Probe/EDID read fixes.
    
      tilcdc:
       - Misc fixes.
    
      pl111:
       - Support more variants
    
      adv7511:
       - Improve EDID handling.
       - HDMI CEC support
    
      sii8620:
       - Add remote control support"
    
    * tag 'drm-for-v4.15' of git://people.freedesktop.org/~airlied/linux: (1480 commits)
      drm/rockchip: analogix_dp: Use mutex rather than spinlock
      drm/mode_object: fix documentation for object lookups.
      drm/i915: Reorder context-close to avoid calling i915_vma_close() under RCU
      drm/i915: Move init_clock_gating() back to where it was
      drm/i915: Prune the reservation shared fence array
      drm/i915: Idle the GPU before shinking everything
      drm/i915: Lock llist_del_first() vs llist_del_all()
      drm/i915: Calculate ironlake intermediate watermarks correctly, v2.
      drm/i915: Disable lazy PPGTT page table optimization for vGPU
      drm/i915/execlists: Remove the priority "optimisation"
      drm/i915: Filter out spurious execlists context-switch interrupts
      drm/amdgpu: use irq-safe lock for kiq->ring_lock
      drm/amdgpu: bypass lru touch for KIQ ring submission
      drm/amdgpu: Potential uninitialized variable in amdgpu_vm_update_directories()
      drm/amdgpu: potential uninitialized variable in amdgpu_vce_ring_parse_cs()
      drm/amd/powerplay: initialize a variable before using it
      drm/amd/powerplay: suppress KASAN out of bounds warning in vega10_populate_all_memory_levels
      drm/amd/amdgpu: fix evicted VRAM bo adjudgement condition
      drm/vblank: Tune drm_crtc_accurate_vblank_count() WARN down to a debug
      drm/rockchip: add CONFIG_OF dependency for lvds
      ...

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index b6c3540e07bc..ed91ce57c428 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __SHMEM_FS_H
 #define __SHMEM_FS_H
 

commit 703321b60b605b1f381f5dcf0bca42703b912e3e
Author: Matthew Auld <matthew.auld@intel.com>
Date:   Fri Oct 6 23:18:13 2017 +0100

    mm/shmem: introduce shmem_file_setup_with_mnt
    
    We are planning to use our own tmpfs mnt in i915 in place of the
    shm_mnt, such that we can control the mount options, in particular
    huge=, which we require to support huge-gtt-pages. So rather than roll
    our own version of __shmem_file_setup, it would be preferred if we could
    just give shmem our mnt, and let it do the rest.
    
    Signed-off-by: Matthew Auld <matthew.auld@intel.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Kirill A. Shutemov <kirill@shutemov.name>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: linux-mm@kvack.org
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20171006145041.21673-2-matthew.auld@intel.com
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Link: https://patchwork.freedesktop.org/patch/msgid/20171006221833.32439-1-chris@chris-wilson.co.uk

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index b6c3540e07bc..0937d9a7d8fb 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -53,6 +53,8 @@ extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);
 extern struct file *shmem_kernel_file_setup(const char *name, loff_t size,
 					    unsigned long flags);
+extern struct file *shmem_file_setup_with_mnt(struct vfsmount *mnt,
+		const char *name, loff_t size, unsigned long flags);
 extern int shmem_zero_setup(struct vm_area_struct *);
 extern unsigned long shmem_get_unmapped_area(struct file *, unsigned long addr,
 		unsigned long len, unsigned long pgoff, unsigned long flags);

commit 8d10396342063c79e92c4e46215370ab7b988569
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Wed Sep 6 16:23:02 2017 -0700

    userfaultfd: shmem: add shmem_mfill_zeropage_pte for userfaultfd support
    
    shmem_mfill_zeropage_pte is the low level routine that implements the
    userfaultfd UFFDIO_ZEROPAGE command.  Since for shmem mappings zero
    pages are always allocated and accounted, the new method is a slight
    extension of the existing shmem_mcopy_atomic_pte.
    
    Link: http://lkml.kernel.org/r/1497939652-16528-4-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Pavel Emelyanov <xemul@virtuozzo.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index a7d6bd2a918f..b6c3540e07bc 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -137,9 +137,15 @@ extern int shmem_mcopy_atomic_pte(struct mm_struct *dst_mm, pmd_t *dst_pmd,
 				  unsigned long dst_addr,
 				  unsigned long src_addr,
 				  struct page **pagep);
+extern int shmem_mfill_zeropage_pte(struct mm_struct *dst_mm,
+				    pmd_t *dst_pmd,
+				    struct vm_area_struct *dst_vma,
+				    unsigned long dst_addr);
 #else
 #define shmem_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma, dst_addr, \
 			       src_addr, pagep)        ({ BUG(); 0; })
+#define shmem_mfill_zeropage_pte(dst_mm, dst_pmd, dst_vma, \
+				 dst_addr)      ({ BUG(); 0; })
 #endif
 
 #endif

commit 3a4f8a0b3ffa733ffbb327685e83b63383127cf6
Author: Hugh Dickins <hughd@google.com>
Date:   Fri Feb 24 14:59:36 2017 -0800

    mm: remove shmem_mapping() shmem_zero_setup() duplicates
    
    Remove the prototypes for shmem_mapping() and shmem_zero_setup() from
    linux/mm.h, since they are already provided in linux/shmem_fs.h.  But
    shmem_fs.h must then provide the inline stub for shmem_mapping() when
    CONFIG_SHMEM is not set, and a few more cfiles now need to #include it.
    
    Link: http://lkml.kernel.org/r/alpine.LSU.2.11.1702081658250.1549@eggly.anvils
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index fdaac9d4d46d..a7d6bd2a918f 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -57,7 +57,14 @@ extern int shmem_zero_setup(struct vm_area_struct *);
 extern unsigned long shmem_get_unmapped_area(struct file *, unsigned long addr,
 		unsigned long len, unsigned long pgoff, unsigned long flags);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
+#ifdef CONFIG_SHMEM
 extern bool shmem_mapping(struct address_space *mapping);
+#else
+static inline bool shmem_mapping(struct address_space *mapping)
+{
+	return false;
+}
+#endif /* CONFIG_SHMEM */
 extern void shmem_unlock_mapping(struct address_space *mapping);
 extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 					pgoff_t index, gfp_t gfp_mask);

commit 4c27fe4c4c84f3afd504ecff2420cc1ad420d38e
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Wed Feb 22 15:43:25 2017 -0800

    userfaultfd: shmem: add shmem_mcopy_atomic_pte for userfaultfd support
    
    shmem_mcopy_atomic_pte is the low level routine that implements the
    userfaultfd UFFDIO_COPY command.  It is based on the existing
    mcopy_atomic_pte routine with modifications for shared memory pages.
    
    Link: http://lkml.kernel.org/r/20161216144821.5183-29-aarcange@redhat.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
    Cc: "Dr. David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
    Cc: Michael Rapoport <RAPOPORT@il.ibm.com>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index ff078e7043b6..fdaac9d4d46d 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -124,4 +124,15 @@ static inline bool shmem_huge_enabled(struct vm_area_struct *vma)
 }
 #endif
 
+#ifdef CONFIG_SHMEM
+extern int shmem_mcopy_atomic_pte(struct mm_struct *dst_mm, pmd_t *dst_pmd,
+				  struct vm_area_struct *dst_vma,
+				  unsigned long dst_addr,
+				  unsigned long src_addr,
+				  struct page **pagep);
+#else
+#define shmem_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma, dst_addr, \
+			       src_addr, pagep)        ({ BUG(); 0; })
+#endif
+
 #endif

commit 779750d20b93bb2e0c75dfe924f31b02f6a78bfa
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:26:38 2016 -0700

    shmem: split huge pages beyond i_size under memory pressure
    
    Even if user asked to allocate huge pages always (huge=always), we
    should be able to free up some memory by splitting pages which are
    partly byound i_size if memory presure comes or once we hit limit on
    filesystem size (-o size=).
    
    In order to do this we maintain per-superblock list of inodes, which
    potentially have huge pages on the border of file size.
    
    Per-fs shrinker can reclaim memory by splitting such pages.
    
    If we hit -ENOSPC during shmem_getpage_gfp(), we try to split a page to
    free up space on the filesystem and retry allocation if it succeed.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-37-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 54fa28dfbd89..ff078e7043b6 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -16,8 +16,9 @@ struct shmem_inode_info {
 	unsigned long		flags;
 	unsigned long		alloced;	/* data pages alloced to file */
 	unsigned long		swapped;	/* subtotal assigned to swap */
-	struct shared_policy	policy;		/* NUMA memory alloc policy */
+	struct list_head        shrinklist;     /* shrinkable hpage inodes */
 	struct list_head	swaplist;	/* chain of maybes on swap */
+	struct shared_policy	policy;		/* NUMA memory alloc policy */
 	struct simple_xattrs	xattrs;		/* list of xattrs */
 	struct inode		vfs_inode;
 };
@@ -33,6 +34,9 @@ struct shmem_sb_info {
 	kuid_t uid;		    /* Mount uid for root directory */
 	kgid_t gid;		    /* Mount gid for root directory */
 	struct mempolicy *mpol;     /* default memory policy for mappings */
+	spinlock_t shrinklist_lock;   /* Protects shrinklist */
+	struct list_head shrinklist;  /* List of shinkable inodes */
+	unsigned long shrinklist_len; /* Length of shrinklist */
 };
 
 static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)

commit e496cf3d782135c1cca0d154d4b924517ff58de0
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:26:35 2016 -0700

    thp: introduce CONFIG_TRANSPARENT_HUGE_PAGECACHE
    
    For file mappings, we don't deposit page tables on THP allocation
    because it's not strictly required to implement split_huge_pmd(): we can
    just clear pmd and let following page faults to reconstruct the page
    table.
    
    But Power makes use of deposited page table to address MMU quirk.
    
    Let's hide THP page cache, including huge tmpfs, under separate config
    option, so it can be forbidden on Power.
    
    We can revert the patch later once solution for Power found.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-36-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 0890f700a546..54fa28dfbd89 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -54,7 +54,6 @@ extern unsigned long shmem_get_unmapped_area(struct file *, unsigned long addr,
 		unsigned long len, unsigned long pgoff, unsigned long flags);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
 extern bool shmem_mapping(struct address_space *mapping);
-extern bool shmem_huge_enabled(struct vm_area_struct *vma);
 extern void shmem_unlock_mapping(struct address_space *mapping);
 extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 					pgoff_t index, gfp_t gfp_mask);
@@ -112,4 +111,13 @@ static inline long shmem_fcntl(struct file *f, unsigned int c, unsigned long a)
 
 #endif
 
+#ifdef CONFIG_TRANSPARENT_HUGE_PAGECACHE
+extern bool shmem_huge_enabled(struct vm_area_struct *vma);
+#else
+static inline bool shmem_huge_enabled(struct vm_area_struct *vma)
+{
+	return false;
+}
+#endif
+
 #endif

commit f3f0e1d2150b2b99da2cbdfaad000089efe9bf30
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:26:32 2016 -0700

    khugepaged: add support of collapse for tmpfs/shmem pages
    
    This patch extends khugepaged to support collapse of tmpfs/shmem pages.
    We share fair amount of infrastructure with anon-THP collapse.
    
    Few design points:
    
      - First we are looking for VMA which can be suitable for mapping huge
        page;
    
      - If the VMA maps shmem file, the rest scan/collapse operations
        operates on page cache, not on page tables as in anon VMA case.
    
      - khugepaged_scan_shmem() finds a range which is suitable for huge
        page. The scan is lockless and shouldn't disturb system too much.
    
      - once the candidate for collapse is found, collapse_shmem() attempts
        to create a huge page:
    
          + scan over radix tree, making the range point to new huge page;
    
          + new huge page is not-uptodate, locked and freezed (refcount
            is 0), so nobody can touch them until we say so.
    
          + we swap in pages during the scan. khugepaged_scan_shmem()
            filters out ranges with more than khugepaged_max_ptes_swap
            swapped out pages. It's HPAGE_PMD_NR/8 by default.
    
          + old pages are isolated, unmapped and put to local list in case
            to be restored back if collapse failed.
    
      - if collapse succeed, we retract pte page tables from VMAs where huge
        pages mapping is possible. The huge page will be mapped as PMD on
        next minor fault into the range.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-35-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 94eaaa2c6ad9..0890f700a546 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -54,6 +54,7 @@ extern unsigned long shmem_get_unmapped_area(struct file *, unsigned long addr,
 		unsigned long len, unsigned long pgoff, unsigned long flags);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
 extern bool shmem_mapping(struct address_space *mapping);
+extern bool shmem_huge_enabled(struct vm_area_struct *vma);
 extern void shmem_unlock_mapping(struct address_space *mapping);
 extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 					pgoff_t index, gfp_t gfp_mask);
@@ -64,6 +65,19 @@ extern unsigned long shmem_swap_usage(struct vm_area_struct *vma);
 extern unsigned long shmem_partial_swap_usage(struct address_space *mapping,
 						pgoff_t start, pgoff_t end);
 
+/* Flag allocation requirements to shmem_getpage */
+enum sgp_type {
+	SGP_READ,	/* don't exceed i_size, don't allocate page */
+	SGP_CACHE,	/* don't exceed i_size, may allocate page */
+	SGP_NOHUGE,	/* like SGP_CACHE, but no huge pages */
+	SGP_HUGE,	/* like SGP_CACHE, huge pages preferred */
+	SGP_WRITE,	/* may exceed i_size, may allocate !Uptodate page */
+	SGP_FALLOC,	/* like SGP_WRITE, but make existing page Uptodate */
+};
+
+extern int shmem_getpage(struct inode *inode, pgoff_t index,
+		struct page **pagep, enum sgp_type sgp);
+
 static inline struct page *shmem_read_mapping_page(
 				struct address_space *mapping, pgoff_t index)
 {
@@ -71,6 +85,15 @@ static inline struct page *shmem_read_mapping_page(
 					mapping_gfp_mask(mapping));
 }
 
+static inline bool shmem_file(struct file *file)
+{
+	if (!IS_ENABLED(CONFIG_SHMEM))
+		return false;
+	if (!file || !file->f_mapping)
+		return false;
+	return shmem_mapping(file->f_mapping);
+}
+
 extern bool shmem_charge(struct inode *inode, long pages);
 extern void shmem_uncharge(struct inode *inode, long pages);
 

commit 800d8c63b2e989c2e349632d1648119bf5862f01
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:26:18 2016 -0700

    shmem: add huge pages support
    
    Here's basic implementation of huge pages support for shmem/tmpfs.
    
    It's all pretty streight-forward:
    
      - shmem_getpage() allcoates huge page if it can and try to inserd into
        radix tree with shmem_add_to_page_cache();
    
      - shmem_add_to_page_cache() puts the page onto radix-tree if there's
        space for it;
    
      - shmem_undo_range() removes huge pages, if it fully within range.
        Partial truncate of huge pages zero out this part of THP.
    
        This have visible effect on fallocate(FALLOC_FL_PUNCH_HOLE)
        behaviour. As we don't really create hole in this case,
        lseek(SEEK_HOLE) may have inconsistent results depending what
        pages happened to be allocated.
    
      - no need to change shmem_fault: core-mm will map an compound page as
        huge if VMA is suitable;
    
    Link: http://lkml.kernel.org/r/1466021202-61880-30-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index ff2de4bab61f..94eaaa2c6ad9 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -71,6 +71,9 @@ static inline struct page *shmem_read_mapping_page(
 					mapping_gfp_mask(mapping));
 }
 
+extern bool shmem_charge(struct inode *inode, long pages);
+extern void shmem_uncharge(struct inode *inode, long pages);
+
 #ifdef CONFIG_TMPFS
 
 extern int shmem_add_seals(struct file *file, unsigned int seals);

commit c01d5b300774d130a24d787825b01eb24e6e20cb
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jul 26 15:26:15 2016 -0700

    shmem: get_unmapped_area align huge page
    
    Provide a shmem_get_unmapped_area method in file_operations, called at
    mmap time to decide the mapping address.  It could be conditional on
    CONFIG_TRANSPARENT_HUGEPAGE, but save #ifdefs in other places by making
    it unconditional.
    
    shmem_get_unmapped_area() first calls the usual mm->get_unmapped_area
    (which we treat as a black box, highly dependent on architecture and
    config and executable layout).  Lots of conditions, and in most cases it
    just goes with the address that chose; but when our huge stars are
    rightly aligned, yet that did not provide a suitable address, go back to
    ask for a larger arena, within which to align the mapping suitably.
    
    There have to be some direct calls to shmem_get_unmapped_area(), not via
    the file_operations: because of the way shmem_zero_setup() is called to
    create a shmem object late in the mmap sequence, when MAP_SHARED is
    requested with MAP_ANONYMOUS or /dev/zero.  Though this only matters
    when /proc/sys/vm/shmem_huge has been set.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-29-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 466f18c73a49..ff2de4bab61f 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -50,6 +50,8 @@ extern struct file *shmem_file_setup(const char *name,
 extern struct file *shmem_kernel_file_setup(const char *name, loff_t size,
 					    unsigned long flags);
 extern int shmem_zero_setup(struct vm_area_struct *);
+extern unsigned long shmem_get_unmapped_area(struct file *, unsigned long addr,
+		unsigned long len, unsigned long pgoff, unsigned long flags);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
 extern bool shmem_mapping(struct address_space *mapping);
 extern void shmem_unlock_mapping(struct address_space *mapping);

commit 5a6e75f8110c97e2a5488894d4e922187e6cb343
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:26:13 2016 -0700

    shmem: prepare huge= mount option and sysfs knob
    
    This patch adds new mount option "huge=".  It can have following values:
    
      - "always":
            Attempt to allocate huge pages every time we need a new page;
    
      - "never":
            Do not allocate huge pages;
    
      - "within_size":
            Only allocate huge page if it will be fully within i_size.
            Also respect fadvise()/madvise() hints;
    
      - "advise:
            Only allocate huge pages if requested with fadvise()/madvise();
    
    Default is "never" for now.
    
    "mount -o remount,huge= /mountpoint" works fine after mount: remounting
    huge=never will not attempt to break up huge pages at all, just stop
    more from being allocated.
    
    No new config option: put this under CONFIG_TRANSPARENT_HUGEPAGE, which
    is the appropriate option to protect those who don't want the new bloat,
    and with which we shall share some pmd code.
    
    Prohibit the option when !CONFIG_TRANSPARENT_HUGEPAGE, just as mpol is
    invalid without CONFIG_NUMA (was hidden in mpol_parse_str(): make it
    explicit).
    
    Allow enabling THP only if the machine has_transparent_hugepage().
    
    But what about Shmem with no user-visible mount? SysV SHM, memfds,
    shared anonymous mmaps (of /dev/zero or MAP_ANONYMOUS), GPU drivers' DRM
    objects, Ashmem.  Though unlikely to suit all usages, provide sysfs knob
    /sys/kernel/mm/transparent_hugepage/shmem_enabled to experiment with
    huge on those.
    
    And allow shmem_enabled two further values:
    
      - "deny":
            For use in emergencies, to force the huge option off from
            all mounts;
      - "force":
            Force the huge option on for all - very useful for testing;
    
    Based on patch by Hugh Dickins.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-28-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 4d4780c00d34..466f18c73a49 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -28,9 +28,10 @@ struct shmem_sb_info {
 	unsigned long max_inodes;   /* How many inodes are allowed */
 	unsigned long free_inodes;  /* How many are left for allocation */
 	spinlock_t stat_lock;	    /* Serialize shmem_sb_info changes */
+	umode_t mode;		    /* Mount mode for root directory */
+	unsigned char huge;	    /* Whether to try for hugepages */
 	kuid_t uid;		    /* Mount uid for root directory */
 	kgid_t gid;		    /* Mount gid for root directory */
-	umode_t mode;		    /* Mount mode for root directory */
 	struct mempolicy *mpol;     /* default memory policy for mappings */
 };
 

commit 3ed47db34f480df7caf44436e3e63e555351ae9a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jan 22 18:08:52 2016 -0500

    make sure that freeing shmem fast symlinks is RCU-delayed
    
    Cc: stable@vger.kernel.org # v4.2+
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index a43f41cb3c43..4d4780c00d34 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -15,10 +15,7 @@ struct shmem_inode_info {
 	unsigned int		seals;		/* shmem seals */
 	unsigned long		flags;
 	unsigned long		alloced;	/* data pages alloced to file */
-	union {
-		unsigned long	swapped;	/* subtotal assigned to swap */
-		char		*symlink;	/* unswappable short symlink */
-	};
+	unsigned long		swapped;	/* subtotal assigned to swap */
 	struct shared_policy	policy;		/* NUMA memory alloc policy */
 	struct list_head	swaplist;	/* chain of maybes on swap */
 	struct simple_xattrs	xattrs;		/* list of xattrs */

commit 48131e03ca4ed71d73fbe55c311a258c6fa2a090
Author: Vlastimil Babka <vbabka@suse.cz>
Date:   Thu Jan 14 15:19:23 2016 -0800

    mm, proc: reduce cost of /proc/pid/smaps for unpopulated shmem mappings
    
    Following the previous patch, further reduction of /proc/pid/smaps cost
    is possible for private writable shmem mappings with unpopulated areas
    where the page walk invokes the .pte_hole function.  We can use radix
    tree iterator for each such area instead of calling find_get_entry() in
    a loop.  This is possible at the extra maintenance cost of introducing
    another shmem function shmem_partial_swap_usage().
    
    To demonstrate the diference, I have measured this on a process that
    creates a private writable 2GB mapping of a partially swapped out
    /dev/shm/file (which cannot employ the optimizations from the prvious
    patch) and doesn't populate it at all.  I time how long does it take to
    cat /proc/pid/smaps of this process 100 times.
    
    Before this patch:
    
    real    0m3.831s
    user    0m0.180s
    sys     0m3.212s
    
    After this patch:
    
    real    0m1.176s
    user    0m0.180s
    sys     0m0.684s
    
    The time is similar to the case where a radix tree iterator is employed
    on the whole mapping.
    
    Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index bd58be5e7a2a..a43f41cb3c43 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -61,6 +61,8 @@ extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);
 extern int shmem_unuse(swp_entry_t entry, struct page *page);
 
 extern unsigned long shmem_swap_usage(struct vm_area_struct *vma);
+extern unsigned long shmem_partial_swap_usage(struct address_space *mapping,
+						pgoff_t start, pgoff_t end);
 
 static inline struct page *shmem_read_mapping_page(
 				struct address_space *mapping, pgoff_t index)

commit 6a15a37097c7e02390bb08d83dac433c9f10144f
Author: Vlastimil Babka <vbabka@suse.cz>
Date:   Thu Jan 14 15:19:20 2016 -0800

    mm, proc: reduce cost of /proc/pid/smaps for shmem mappings
    
    The previous patch has improved swap accounting for shmem mapping, which
    however made /proc/pid/smaps more expensive for shmem mappings, as we
    consult the radix tree for each pte_none entry, so the overal complexity
    is O(n*log(n)).
    
    We can reduce this significantly for mappings that cannot contain COWed
    pages, because then we can either use the statistics tha shmem object
    itself tracks (if the mapping contains the whole object, or the swap
    usage of the whole object is zero), or use the radix tree iterator,
    which is much more effective than repeated find_get_entry() calls.
    
    This patch therefore introduces a function shmem_swap_usage(vma) and
    makes /proc/pid/smaps use it when possible.  Only for writable private
    mappings of shmem objects (i.e.  tmpfs files) with the shmem object
    itself (partially) swapped outwe have to resort to the find_get_entry()
    approach.
    
    Hopefully such mappings are relatively uncommon.
    
    To demonstrate the diference, I have measured this on a process that
    creates a 2GB mapping and dirties single pages with a stride of 2MB, and
    time how long does it take to cat /proc/pid/smaps of this process 100
    times.
    
    Private writable mapping of a /dev/shm/file (the most complex case):
    
    real    0m3.831s
    user    0m0.180s
    sys     0m3.212s
    
    Shared mapping of an almost full mapping of a partially swapped /dev/shm/file
    (which needs to employ the radix tree iterator).
    
    real    0m1.351s
    user    0m0.096s
    sys     0m0.768s
    
    Same, but with /dev/shm/file not swapped (so no radix tree walk needed)
    
    real    0m0.935s
    user    0m0.128s
    sys     0m0.344s
    
    Private anonymous mapping:
    
    real    0m0.949s
    user    0m0.116s
    sys     0m0.348s
    
    The cost is now much closer to the private anonymous mapping case, unless
    the shmem mapping is private and writable.
    
    Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 50777b5b1e4c..bd58be5e7a2a 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -60,6 +60,8 @@ extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);
 extern int shmem_unuse(swp_entry_t entry, struct page *page);
 
+extern unsigned long shmem_swap_usage(struct vm_area_struct *vma);
+
 static inline struct page *shmem_read_mapping_page(
 				struct address_space *mapping, pgoff_t index)
 {

commit 40e041a2c858b3caefc757e26cb85bfceae5062b
Author: David Herrmann <dh.herrmann@gmail.com>
Date:   Fri Aug 8 14:25:27 2014 -0700

    shm: add sealing API
    
    If two processes share a common memory region, they usually want some
    guarantees to allow safe access. This often includes:
      - one side cannot overwrite data while the other reads it
      - one side cannot shrink the buffer while the other accesses it
      - one side cannot grow the buffer beyond previously set boundaries
    
    If there is a trust-relationship between both parties, there is no need
    for policy enforcement.  However, if there's no trust relationship (eg.,
    for general-purpose IPC) sharing memory-regions is highly fragile and
    often not possible without local copies.  Look at the following two
    use-cases:
    
      1) A graphics client wants to share its rendering-buffer with a
         graphics-server. The memory-region is allocated by the client for
         read/write access and a second FD is passed to the server. While
         scanning out from the memory region, the server has no guarantee that
         the client doesn't shrink the buffer at any time, requiring rather
         cumbersome SIGBUS handling.
      2) A process wants to perform an RPC on another process. To avoid huge
         bandwidth consumption, zero-copy is preferred. After a message is
         assembled in-memory and a FD is passed to the remote side, both sides
         want to be sure that neither modifies this shared copy, anymore. The
         source may have put sensible data into the message without a separate
         copy and the target may want to parse the message inline, to avoid a
         local copy.
    
    While SIGBUS handling, POSIX mandatory locking and MAP_DENYWRITE provide
    ways to achieve most of this, the first one is unproportionally ugly to
    use in libraries and the latter two are broken/racy or even disabled due
    to denial of service attacks.
    
    This patch introduces the concept of SEALING.  If you seal a file, a
    specific set of operations is blocked on that file forever.  Unlike locks,
    seals can only be set, never removed.  Hence, once you verified a specific
    set of seals is set, you're guaranteed that no-one can perform the blocked
    operations on this file, anymore.
    
    An initial set of SEALS is introduced by this patch:
      - SHRINK: If SEAL_SHRINK is set, the file in question cannot be reduced
                in size. This affects ftruncate() and open(O_TRUNC).
      - GROW: If SEAL_GROW is set, the file in question cannot be increased
              in size. This affects ftruncate(), fallocate() and write().
      - WRITE: If SEAL_WRITE is set, no write operations (besides resizing)
               are possible. This affects fallocate(PUNCH_HOLE), mmap() and
               write().
      - SEAL: If SEAL_SEAL is set, no further seals can be added to a file.
              This basically prevents the F_ADD_SEAL operation on a file and
              can be set to prevent others from adding further seals that you
              don't want.
    
    The described use-cases can easily use these seals to provide safe use
    without any trust-relationship:
    
      1) The graphics server can verify that a passed file-descriptor has
         SEAL_SHRINK set. This allows safe scanout, while the client is
         allowed to increase buffer size for window-resizing on-the-fly.
         Concurrent writes are explicitly allowed.
      2) For general-purpose IPC, both processes can verify that SEAL_SHRINK,
         SEAL_GROW and SEAL_WRITE are set. This guarantees that neither
         process can modify the data while the other side parses it.
         Furthermore, it guarantees that even with writable FDs passed to the
         peer, it cannot increase the size to hit memory-limits of the source
         process (in case the file-storage is accounted to the source).
    
    The new API is an extension to fcntl(), adding two new commands:
      F_GET_SEALS: Return a bitset describing the seals on the file. This
                   can be called on any FD if the underlying file supports
                   sealing.
      F_ADD_SEALS: Change the seals of a given file. This requires WRITE
                   access to the file and F_SEAL_SEAL may not already be set.
                   Furthermore, the underlying file must support sealing and
                   there may not be any existing shared mapping of that file.
                   Otherwise, EBADF/EPERM is returned.
                   The given seals are _added_ to the existing set of seals
                   on the file. You cannot remove seals again.
    
    The fcntl() handler is currently specific to shmem and disabled on all
    files. A file needs to explicitly support sealing for this interface to
    work. A separate syscall is added in a follow-up, which creates files that
    support sealing. There is no intention to support this on other
    file-systems. Semantics are unclear for non-volatile files and we lack any
    use-case right now. Therefore, the implementation is specific to shmem.
    
    Signed-off-by: David Herrmann <dh.herrmann@gmail.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Ryan Lortie <desrt@desrt.ca>
    Cc: Lennart Poettering <lennart@poettering.net>
    Cc: Daniel Mack <zonque@gmail.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 4d1771c2d29f..50777b5b1e4c 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -1,6 +1,7 @@
 #ifndef __SHMEM_FS_H
 #define __SHMEM_FS_H
 
+#include <linux/file.h>
 #include <linux/swap.h>
 #include <linux/mempolicy.h>
 #include <linux/pagemap.h>
@@ -11,6 +12,7 @@
 
 struct shmem_inode_info {
 	spinlock_t		lock;
+	unsigned int		seals;		/* shmem seals */
 	unsigned long		flags;
 	unsigned long		alloced;	/* data pages alloced to file */
 	union {
@@ -65,4 +67,19 @@ static inline struct page *shmem_read_mapping_page(
 					mapping_gfp_mask(mapping));
 }
 
+#ifdef CONFIG_TMPFS
+
+extern int shmem_add_seals(struct file *file, unsigned int seals);
+extern int shmem_get_seals(struct file *file);
+extern long shmem_fcntl(struct file *file, unsigned int cmd, unsigned long arg);
+
+#else
+
+static inline long shmem_fcntl(struct file *f, unsigned int c, unsigned long a)
+{
+	return -EINVAL;
+}
+
+#endif
+
 #endif

commit 0cd6144aadd2afd19d1aca880153530c52957604
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Apr 3 14:47:46 2014 -0700

    mm + fs: prepare for non-page entries in page cache radix trees
    
    shmem mappings already contain exceptional entries where swap slot
    information is remembered.
    
    To be able to store eviction information for regular page cache, prepare
    every site dealing with the radix trees directly to handle entries other
    than pages.
    
    The common lookup functions will filter out non-page entries and return
    NULL for page cache holes, just as before.  But provide a raw version of
    the API which returns non-page entries as well, and switch shmem over to
    use it.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Reviewed-by: Minchan Kim <minchan@kernel.org>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bob Liu <bob.liu@oracle.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Metin Doslu <metin@citusdata.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Ozgun Erdogan <ozgun@citusdata.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roman Gushchin <klamm@yandex-team.ru>
    Cc: Ryan Mallon <rmallon@gmail.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 9d55438bc4ad..4d1771c2d29f 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -51,6 +51,7 @@ extern struct file *shmem_kernel_file_setup(const char *name, loff_t size,
 					    unsigned long flags);
 extern int shmem_zero_setup(struct vm_area_struct *);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
+extern bool shmem_mapping(struct address_space *mapping);
 extern void shmem_unlock_mapping(struct address_space *mapping);
 extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 					pgoff_t index, gfp_t gfp_mask);

commit c7277090927a5e71871e799a355ed2940f6c8fc6
Author: Eric Paris <eparis@redhat.com>
Date:   Mon Dec 2 11:24:19 2013 +0000

    security: shmem: implement kernel private shmem inodes
    
    We have a problem where the big_key key storage implementation uses a
    shmem backed inode to hold the key contents.  Because of this detail of
    implementation LSM checks are being done between processes trying to
    read the keys and the tmpfs backed inode.  The LSM checks are already
    being handled on the key interface level and should not be enforced at
    the inode level (since the inode is an implementation detail, not a
    part of the security model)
    
    This patch implements a new function shmem_kernel_file_setup() which
    returns the equivalent to shmem_file_setup() only the underlying inode
    has S_PRIVATE set.  This means that all LSM checks for the inode in
    question are skipped.  It should only be used for kernel internal
    operations where the inode is not exposed to userspace without proper
    LSM checking.  It is possible that some other users of
    shmem_file_setup() should use the new interface, but this has not been
    explored.
    
    Reproducing this bug is a little bit difficult.  The steps I used on
    Fedora are:
    
     (1) Turn off selinux enforcing:
    
            setenforce 0
    
     (2) Create a huge key
    
            k=`dd if=/dev/zero bs=8192 count=1 | keyctl padd big_key test-key @s`
    
     (3) Access the key in another context:
    
            runcon system_u:system_r:httpd_t:s0-s0:c0.c1023 keyctl print $k >/dev/null
    
     (4) Examine the audit logs:
    
            ausearch -m AVC -i --subject httpd_t | audit2allow
    
    If the last command's output includes a line that looks like:
    
            allow httpd_t user_tmpfs_t:file { open read };
    
    There was an inode check between httpd and the tmpfs filesystem.  With
    this patch no such denial will be seen.  (NOTE! you should clear your
    audit log if you have tested for this previously)
    
    (Please return you box to enforcing)
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Hugh Dickins <hughd@google.com>
    cc: linux-mm@kvack.org

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 30aa0dc60d75..9d55438bc4ad 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -47,6 +47,8 @@ extern int shmem_init(void);
 extern int shmem_fill_super(struct super_block *sb, void *data, int silent);
 extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);
+extern struct file *shmem_kernel_file_setup(const char *name, loff_t size,
+					    unsigned long flags);
 extern int shmem_zero_setup(struct vm_area_struct *);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
 extern void shmem_unlock_mapping(struct address_space *mapping);

commit 38f38657444d15e1a8574eae80ed3de9f501737a
Author: Aristeu Rozanski <aris@redhat.com>
Date:   Thu Aug 23 16:53:28 2012 -0400

    xattr: extract simple_xattr code from tmpfs
    
    Extract in-memory xattr APIs from tmpfs. Will be used by cgroup.
    
    $ size vmlinux.o
       text    data     bss     dec     hex filename
    4658782  880729 5195032 10734543         a3cbcf vmlinux.o
    $ size vmlinux.o
       text    data     bss     dec     hex filename
    4658957  880729 5195032 10734718         a3cc7e vmlinux.o
    
    v7:
    - checkpatch warnings fixed
    - Implement the changes requested by Hugh Dickins:
            - make simple_xattrs_init and simple_xattrs_free inline
            - get rid of locking and list reinitialization in simple_xattrs_free,
              they're not needed
    v6:
    - no changes
    v5:
    - no changes
    v4:
    - move simple_xattrs_free() to fs/xattr.c
    v3:
    - in kmem_xattrs_free(), reinitialize the list
    - use simple_xattr_* prefix
    - introduce simple_xattr_add() to prevent direct list usage
    
    Original-patch-by: Li Zefan <lizefan@huawei.com>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Hillf Danton <dhillf@gmail.com>
    Cc: Lennart Poettering <lpoetter@redhat.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Aristeu Rozanski <aris@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index bef2cf00b3be..30aa0dc60d75 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -5,6 +5,7 @@
 #include <linux/mempolicy.h>
 #include <linux/pagemap.h>
 #include <linux/percpu_counter.h>
+#include <linux/xattr.h>
 
 /* inode in-kernel data */
 
@@ -18,7 +19,7 @@ struct shmem_inode_info {
 	};
 	struct shared_policy	policy;		/* NUMA memory alloc policy */
 	struct list_head	swaplist;	/* chain of maybes on swap */
-	struct list_head	xattr_list;	/* list of shmem_xattr */
+	struct simple_xattrs	xattrs;		/* list of xattrs */
 	struct inode		vfs_inode;
 };
 

commit 8751e03958f2adbfba6a0f186f4c5797c950c22a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 7 16:46:12 2012 -0800

    userns: Convert tmpfs to use kuid and kgid where appropriate
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 79ab2555b3b0..bef2cf00b3be 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -28,8 +28,8 @@ struct shmem_sb_info {
 	unsigned long max_inodes;   /* How many inodes are allowed */
 	unsigned long free_inodes;  /* How many are left for allocation */
 	spinlock_t stat_lock;	    /* Serialize shmem_sb_info changes */
-	uid_t uid;		    /* Mount uid for root directory */
-	gid_t gid;		    /* Mount gid for root directory */
+	kuid_t uid;		    /* Mount uid for root directory */
+	kgid_t gid;		    /* Mount gid for root directory */
 	umode_t mode;		    /* Mount mode for root directory */
 	struct mempolicy *mpol;     /* default memory policy for mappings */
 };

commit 245132643e1cfcd145bbc86a716c1818371fcb93
Author: Hugh Dickins <hughd@google.com>
Date:   Fri Jan 20 14:34:21 2012 -0800

    SHM_UNLOCK: fix Unevictable pages stranded after swap
    
    Commit cc39c6a9bbde ("mm: account skipped entries to avoid looping in
    find_get_pages") correctly fixed an infinite loop; but left a problem
    that find_get_pages() on shmem would return 0 (appearing to callers to
    mean end of tree) when it meets a run of nr_pages swap entries.
    
    The only uses of find_get_pages() on shmem are via pagevec_lookup(),
    called from invalidate_mapping_pages(), and from shmctl SHM_UNLOCK's
    scan_mapping_unevictable_pages().  The first is already commented, and
    not worth worrying about; but the second can leave pages on the
    Unevictable list after an unusual sequence of swapping and locking.
    
    Fix that by using shmem_find_get_pages_and_swap() (then ignoring the
    swap) instead of pagevec_lookup().
    
    But I don't want to contaminate vmscan.c with shmem internals, nor
    shmem.c with LRU locking.  So move scan_mapping_unevictable_pages() into
    shmem.c, renaming it shmem_unlock_mapping(); and rename
    check_move_unevictable_page() to check_move_unevictable_pages(), looping
    down an array of pages, oftentimes under the same lock.
    
    Leave out the "rotate unevictable list" block: that's a leftover from
    when this was used for /proc/sys/vm/scan_unevictable_pages, whose flawed
    handling involved looking at pages at tail of LRU.
    
    Was there significance to the sequence first ClearPageUnevictable, then
    test page_evictable, then SetPageUnevictable here? I think not, we're
    under LRU lock, and have no barriers between those.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Shaohua Li <shaohua.li@intel.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: <stable@vger.kernel.org> [back to 3.1 but will need respins]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index e4c711c6f321..79ab2555b3b0 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -48,6 +48,7 @@ extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);
 extern int shmem_zero_setup(struct vm_area_struct *);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
+extern void shmem_unlock_mapping(struct address_space *mapping);
 extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 					pgoff_t index, gfp_t gfp_mask);
 extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);

commit 09208d150b5cda009b666238a7102cb45ecec2ee
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jul 26 03:15:03 2011 -0400

    shmem, ramfs: propagate umode_t, open-coded S_ISREG
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 9291ac3cc627..e4c711c6f321 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -30,7 +30,7 @@ struct shmem_sb_info {
 	spinlock_t stat_lock;	    /* Serialize shmem_sb_info changes */
 	uid_t uid;		    /* Mount uid for root directory */
 	gid_t gid;		    /* Mount gid for root directory */
-	mode_t mode;		    /* Mount mode for root directory */
+	umode_t mode;		    /* Mount mode for root directory */
 	struct mempolicy *mpol;     /* default memory policy for mappings */
 };
 

commit 69f07ec938712b58755add82dd3d0b35f01317cc
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Aug 3 16:21:26 2011 -0700

    tmpfs: use kmemdup for short symlinks
    
    But we've not yet removed the old swp_entry_t i_direct[16] from
    shmem_inode_info.  That's because it was still being shared with the
    inline symlink.  Remove it now (saving 64 or 128 bytes from shmem inode
    size), and use kmemdup() for short symlinks, say, those up to 128 bytes.
    
    I wonder why mpol_free_shared_policy() is done in shmem_destroy_inode()
    rather than shmem_evict_inode(), where we usually do such freeing? I
    guess it doesn't matter, and I'm not into NUMA mpol testing right now.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 0c8e952df594..9291ac3cc627 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -8,20 +8,15 @@
 
 /* inode in-kernel data */
 
-#define SHMEM_NR_DIRECT 16
-
-#define SHMEM_SYMLINK_INLINE_LEN (SHMEM_NR_DIRECT * sizeof(swp_entry_t))
-
 struct shmem_inode_info {
 	spinlock_t		lock;
 	unsigned long		flags;
 	unsigned long		alloced;	/* data pages alloced to file */
-	unsigned long		swapped;	/* subtotal assigned to swap */
-	struct shared_policy	policy;		/* NUMA memory alloc policy */
 	union {
-		swp_entry_t	i_direct[SHMEM_NR_DIRECT]; /* first blocks */
-		char		inline_symlink[SHMEM_SYMLINK_INLINE_LEN];
+		unsigned long	swapped;	/* subtotal assigned to swap */
+		char		*symlink;	/* unswappable short symlink */
 	};
+	struct shared_policy	policy;		/* NUMA memory alloc policy */
 	struct list_head	swaplist;	/* chain of maybes on swap */
 	struct list_head	xattr_list;	/* list of shmem_xattr */
 	struct inode		vfs_inode;

commit aa3b189551ad8e5cc1d9c663735c131650238278
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Aug 3 16:21:24 2011 -0700

    tmpfs: convert mem_cgroup shmem to radix-swap
    
    Remove mem_cgroup_shmem_charge_fallback(): it was only required when we
    had to move swappage to filecache with GFP_NOWAIT.
    
    Remove the GFP_NOWAIT special case from mem_cgroup_cache_charge(), by
    moving its call out from shmem_add_to_page_cache() to two of thats three
    callers.  But leave it doing mem_cgroup_uncharge_cache_page() on error:
    although asymmetrical, it's easier for all 3 callers to handle.
    
    These two changes would also be appropriate if anyone were to start
    using shmem_read_mapping_page_gfp() with GFP_NOWAIT.
    
    Remove mem_cgroup_get_shmem_target(): mc_handle_file_pte() can test
    radix_tree_exceptional_entry() to get what it needs for itself.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 3f05795dcf7b..0c8e952df594 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -57,8 +57,6 @@ extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
 					pgoff_t index, gfp_t gfp_mask);
 extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);
 extern int shmem_unuse(swp_entry_t entry, struct page *page);
-extern void mem_cgroup_get_shmem_target(struct inode *inode, pgoff_t pgoff,
-					struct page **pagep, swp_entry_t *ent);
 
 static inline struct page *shmem_read_mapping_page(
 				struct address_space *mapping, pgoff_t index)

commit 41ffe5d5ceef7f7ff2ff18e320d88ca6d629efaf
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Aug 3 16:21:21 2011 -0700

    tmpfs: miscellaneous trivial cleanups
    
    While it's at its least, make a number of boring nitpicky cleanups to
    shmem.c, mostly for consistency of variable naming.  Things like "swap"
    instead of "entry", "pgoff_t index" instead of "unsigned long idx".
    
    And since everything else here is prefixed "shmem_", better change
    init_tmpfs() to shmem_init().
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 80b695213fdb..3f05795dcf7b 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -47,7 +47,7 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 /*
  * Functions in mm/shmem.c called directly from elsewhere:
  */
-extern int init_tmpfs(void);
+extern int shmem_init(void);
 extern int shmem_fill_super(struct super_block *sb, void *data, int silent);
 extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);

commit 285b2c4fdd69ea73b4762785d8c6be83b6c074a6
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Aug 3 16:21:20 2011 -0700

    tmpfs: demolish old swap vector support
    
    The maximum size of a shmem/tmpfs file has been limited by the maximum
    size of its triple-indirect swap vector.  With 4kB page size, maximum
    filesize was just over 2TB on a 32-bit kernel, but sadly one eighth of
    that on a 64-bit kernel.  (With 8kB page size, maximum filesize was just
    over 4TB on a 64-bit kernel, but 16TB on a 32-bit kernel,
    MAX_LFS_FILESIZE being then more restrictive than swap vector layout.)
    
    It's a shame that tmpfs should be more restrictive than ramfs, and this
    limitation has now been noticed.  Add another level to the swap vector?
    No, it became obscure and hard to maintain, once I complicated it to
    make use of highmem pages nine years ago: better choose another way.
    
    Surely, if 2.4 had had the radix tree pagecache introduced in 2.5, then
    tmpfs would never have invented its own peculiar radix tree: we would
    have fitted swap entries into the common radix tree instead, in much the
    same way as we fit swap entries into page tables.
    
    And why should each file have a separate radix tree for its pages and
    for its swap entries? The swap entries are required precisely where and
    when the pages are not.  We want to put them together in a single radix
    tree: which can then avoid much of the locking which was needed to
    prevent them from being exchanged underneath us.
    
    This also avoids the waste of memory devoted to swap vectors, first in
    the shmem_inode itself, then at least two more pages once a file grew
    beyond 16 data pages (pages accounted by df and du, but not by memcg).
    Allocated upfront, to avoid allocation when under swapping pressure, but
    pure waste when CONFIG_SWAP is not set - I have never spattered around
    the ifdefs to prevent that, preferring this move to sharing the common
    radix tree instead.
    
    There are three downsides to sharing the radix tree.  One, that it binds
    tmpfs more tightly to the rest of mm, either requiring knowledge of swap
    entries in radix tree there, or duplication of its code here in shmem.c.
    I believe that the simplications and memory savings (and probable higher
    performance, not yet measured) justify that.
    
    Two, that on HIGHMEM systems with SWAP enabled, it's the lowmem radix
    nodes that cannot be freed under memory pressure - whereas before it was
    the less precious highmem swap vector pages that could not be freed.
    I'm hoping that 64-bit has now been accessible for long enough, that the
    highmem argument has grown much less persuasive.
    
    Three, that swapoff is slower than it used to be on tmpfs files, since
    it's using a simple generic mechanism not tailored to it: I find this
    noticeable, and shall want to improve, but maybe nobody else will
    notice.
    
    So...  now remove most of the old swap vector code from shmem.c.  But,
    for the moment, keep the simple i_direct vector of 16 pages, with simple
    accessors shmem_put_swap() and shmem_get_swap(), as a toy implementation
    to help mark where swap needs to be handled in subsequent patches.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index aa08fa8fd79b..80b695213fdb 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -17,9 +17,7 @@ struct shmem_inode_info {
 	unsigned long		flags;
 	unsigned long		alloced;	/* data pages alloced to file */
 	unsigned long		swapped;	/* subtotal assigned to swap */
-	unsigned long		next_index;	/* highest alloced index + 1 */
 	struct shared_policy	policy;		/* NUMA memory alloc policy */
-	struct page		*i_indirect;	/* top indirect blocks page */
 	union {
 		swp_entry_t	i_direct[SHMEM_NR_DIRECT]; /* first blocks */
 		char		inline_symlink[SHMEM_SYMLINK_INLINE_LEN];

commit d9d90e5eb70e09903dadff42099b6c948f814050
Author: Hugh Dickins <hughd@google.com>
Date:   Mon Jun 27 16:18:04 2011 -0700

    tmpfs: add shmem_read_mapping_page_gfp
    
    Although it is used (by i915) on nothing but tmpfs, read_cache_page_gfp()
    is unsuited to tmpfs, because it inserts a page into pagecache before
    calling the filesystem's ->readpage: tmpfs may have pages in swapcache
    which only it knows how to locate and switch to filecache.
    
    At present tmpfs provides a ->readpage method, and copes with this by
    copying pages; but soon we can simplify it by removing its ->readpage.
    Provide shmem_read_mapping_page_gfp() now, ready for that transition,
    
    Export shmem_read_mapping_page_gfp() and add it to list in shmem_fs.h,
    with shmem_read_mapping_page() inline for the common mapping_gfp case.
    
    (shmem_read_mapping_page_gfp or shmem_read_cache_page_gfp? Generally the
    read_mapping_page functions use the mapping's ->readpage, and the
    read_cache_page functions use the supplied filler, so I think
    read_cache_page_gfp was slightly misnamed.)
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 22a20af4d785..aa08fa8fd79b 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -3,15 +3,9 @@
 
 #include <linux/swap.h>
 #include <linux/mempolicy.h>
+#include <linux/pagemap.h>
 #include <linux/percpu_counter.h>
 
-struct page;
-struct file;
-struct inode;
-struct super_block;
-struct user_struct;
-struct vm_area_struct;
-
 /* inode in-kernel data */
 
 #define SHMEM_NR_DIRECT 16
@@ -61,9 +55,18 @@ extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);
 extern int shmem_zero_setup(struct vm_area_struct *);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
+extern struct page *shmem_read_mapping_page_gfp(struct address_space *mapping,
+					pgoff_t index, gfp_t gfp_mask);
 extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);
 extern int shmem_unuse(swp_entry_t entry, struct page *page);
 extern void mem_cgroup_get_shmem_target(struct inode *inode, pgoff_t pgoff,
 					struct page **pagep, swp_entry_t *ent);
 
+static inline struct page *shmem_read_mapping_page(
+				struct address_space *mapping, pgoff_t index)
+{
+	return shmem_read_mapping_page_gfp(mapping, index,
+					mapping_gfp_mask(mapping));
+}
+
 #endif

commit 94c1e62df4494b79782cb9c7279f827212d1de70
Author: Hugh Dickins <hughd@google.com>
Date:   Mon Jun 27 16:18:03 2011 -0700

    tmpfs: take control of its truncate_range
    
    2.6.35's new truncate convention gave tmpfs the opportunity to control
    its file truncation, no longer enforced from outside by vmtruncate().
    We shall want to build upon that, to handle pagecache and swap together.
    
    Slightly redefine the ->truncate_range interface: let it now be called
    between the unmap_mapping_range()s, with the filesystem responsible for
    doing the truncate_inode_pages_range() from it - just as the filesystem
    is nowadays responsible for doing that from its ->setattr.
    
    Let's rename shmem_notify_change() to shmem_setattr().  Instead of
    calling the generic truncate_setsize(), bring that code in so we can
    call shmem_truncate_range() - which will later be updated to perform its
    own variant of truncate_inode_pages_range().
    
    Remove the punch_hole unmap_mapping_range() from shmem_truncate_range():
    now that the COW's unmap_mapping_range() comes after ->truncate_range,
    there is no need to call it a third time.
    
    Export shmem_truncate_range() and add it to the list in shmem_fs.h, so
    that i915_gem_object_truncate() can call it explicitly in future; get
    this patch in first, then update drm/i915 once this is available (until
    then, i915 will just be doing the truncate_inode_pages() twice).
    
    Though introduced five years ago, no other filesystem is implementing
    ->truncate_range, and its only other user is madvise(,,MADV_REMOVE): we
    expect to convert it to fallocate(,FALLOC_FL_PUNCH_HOLE,,) shortly,
    whereupon ->truncate_range can be removed from inode_operations -
    shmem_truncate_range() will help i915 across that transition too.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index cae65dc42bcc..22a20af4d785 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -61,6 +61,7 @@ extern struct file *shmem_file_setup(const char *name,
 					loff_t size, unsigned long flags);
 extern int shmem_zero_setup(struct vm_area_struct *);
 extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
+extern void shmem_truncate_range(struct inode *inode, loff_t start, loff_t end);
 extern int shmem_unuse(swp_entry_t entry, struct page *page);
 extern void mem_cgroup_get_shmem_target(struct inode *inode, pgoff_t pgoff,
 					struct page **pagep, swp_entry_t *ent);

commit 072441e21ddcd1140606b7d4ef6eab579a86b0b3
Author: Hugh Dickins <hughd@google.com>
Date:   Mon Jun 27 16:18:02 2011 -0700

    mm: move shmem prototypes to shmem_fs.h
    
    Before adding any more global entry points into shmem.c, gather such
    prototypes into shmem_fs.h.  Remove mm's own declarations from swap.h,
    but for now leave the ones in mm.h: because shmem_file_setup() and
    shmem_zero_setup() are called from various places, and we should not
    force other subsystems to update immediately.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 2b7fec840517..cae65dc42bcc 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -5,6 +5,13 @@
 #include <linux/mempolicy.h>
 #include <linux/percpu_counter.h>
 
+struct page;
+struct file;
+struct inode;
+struct super_block;
+struct user_struct;
+struct vm_area_struct;
+
 /* inode in-kernel data */
 
 #define SHMEM_NR_DIRECT 16
@@ -45,7 +52,17 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 	return container_of(inode, struct shmem_inode_info, vfs_inode);
 }
 
+/*
+ * Functions in mm/shmem.c called directly from elsewhere:
+ */
 extern int init_tmpfs(void);
 extern int shmem_fill_super(struct super_block *sb, void *data, int silent);
+extern struct file *shmem_file_setup(const char *name,
+					loff_t size, unsigned long flags);
+extern int shmem_zero_setup(struct vm_area_struct *);
+extern int shmem_lock(struct file *file, int lock, struct user_struct *user);
+extern int shmem_unuse(swp_entry_t entry, struct page *page);
+extern void mem_cgroup_get_shmem_target(struct inode *inode, pgoff_t pgoff,
+					struct page **pagep, swp_entry_t *ent);
 
 #endif

commit b09e0fa4b4ea66266058eead43350bd7d55fec67
Author: Eric Paris <eparis@redhat.com>
Date:   Tue May 24 17:12:39 2011 -0700

    tmpfs: implement generic xattr support
    
    Implement generic xattrs for tmpfs filesystems.  The Feodra project, while
    trying to replace suid apps with file capabilities, realized that tmpfs,
    which is used on the build systems, does not support file capabilities and
    thus cannot be used to build packages which use file capabilities.  Xattrs
    are also needed for overlayfs.
    
    The xattr interface is a bit odd.  If a filesystem does not implement any
    {get,set,list}xattr functions the VFS will call into some random LSM hooks
    and the running LSM can then implement some method for handling xattrs.
    SELinux for example provides a method to support security.selinux but no
    other security.* xattrs.
    
    As it stands today when one enables CONFIG_TMPFS_POSIX_ACL tmpfs will have
    xattr handler routines specifically to handle acls.  Because of this tmpfs
    would loose the VFS/LSM helpers to support the running LSM.  To make up
    for that tmpfs had stub functions that did nothing but call into the LSM
    hooks which implement the helpers.
    
    This new patch does not use the LSM fallback functions and instead just
    implements a native get/set/list xattr feature for the full security.* and
    trusted.* namespace like a normal filesystem.  This means that tmpfs can
    now support both security.selinux and security.capability, which was not
    previously possible.
    
    The basic implementation is that I attach a:
    
    struct shmem_xattr {
            struct list_head list; /* anchored by shmem_inode_info->xattr_list */
            char *name;
            size_t size;
            char value[0];
    };
    
    Into the struct shmem_inode_info for each xattr that is set.  This
    implementation could easily support the user.* namespace as well, except
    some care needs to be taken to prevent large amounts of unswappable memory
    being allocated for unprivileged users.
    
    [mszeredi@suse.cz: new config option, suport trusted.*, support symlinks]
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    Acked-by: Serge Hallyn <serge.hallyn@ubuntu.com>
    Tested-by: Serge Hallyn <serge.hallyn@ubuntu.com>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: Hugh Dickins <hughd@google.com>
    Tested-by: Jordi Pujol <jordipujolp@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 399be5ad2f99..2b7fec840517 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -9,6 +9,8 @@
 
 #define SHMEM_NR_DIRECT 16
 
+#define SHMEM_SYMLINK_INLINE_LEN (SHMEM_NR_DIRECT * sizeof(swp_entry_t))
+
 struct shmem_inode_info {
 	spinlock_t		lock;
 	unsigned long		flags;
@@ -17,8 +19,12 @@ struct shmem_inode_info {
 	unsigned long		next_index;	/* highest alloced index + 1 */
 	struct shared_policy	policy;		/* NUMA memory alloc policy */
 	struct page		*i_indirect;	/* top indirect blocks page */
-	swp_entry_t		i_direct[SHMEM_NR_DIRECT]; /* first blocks */
+	union {
+		swp_entry_t	i_direct[SHMEM_NR_DIRECT]; /* first blocks */
+		char		inline_symlink[SHMEM_SYMLINK_INLINE_LEN];
+	};
 	struct list_head	swaplist;	/* chain of maybes on swap */
+	struct list_head	xattr_list;	/* list of shmem_xattr */
 	struct inode		vfs_inode;
 };
 

commit 7e496299d4d2ad8083effed6c5a18313a919edc6
Author: Tim Chen <tim.c.chen@linux.intel.com>
Date:   Mon Aug 9 17:19:05 2010 -0700

    tmpfs: make tmpfs scalable with percpu_counter for used blocks
    
    The current implementation of tmpfs is not scalable.  We found that
    stat_lock is contended by multiple threads when we need to get a new page,
    leading to useless spinning inside this spin lock.
    
    This patch makes use of the percpu_counter library to maintain local count
    of used blocks to speed up getting and returning of pages.  So the
    acquisition of stat_lock is unnecessary for getting and returning blocks,
    improving the performance of tmpfs on system with large number of cpus.
    On a 4 socket 32 core NHM-EX system, we saw improvement of 270%.
    
    The implementation below has a slight chance of race between threads
    causing a slight overshoot of the maximum configured blocks.  However, any
    overshoot is small, and is bounded by the number of cpus.  This happens
    when the number of used blocks is slightly below the maximum configured
    blocks when a thread checks the used block count, and another thread
    allocates the last block before the current thread does.  This should not
    be a problem for tmpfs, as the overshoot is most likely to be a few blocks
    and bounded.  If a strict limit is really desired, then configured the max
    blocks to be the limit less the number of cpus in system.
    
    Signed-off-by: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index e164291fb3e7..399be5ad2f99 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -3,6 +3,7 @@
 
 #include <linux/swap.h>
 #include <linux/mempolicy.h>
+#include <linux/percpu_counter.h>
 
 /* inode in-kernel data */
 
@@ -23,7 +24,7 @@ struct shmem_inode_info {
 
 struct shmem_sb_info {
 	unsigned long max_blocks;   /* How many blocks are allowed */
-	unsigned long free_blocks;  /* How many are left for allocation */
+	struct percpu_counter used_blocks;  /* How many are allocated */
 	unsigned long max_inodes;   /* How many inodes are allowed */
 	unsigned long free_inodes;  /* How many are left for allocation */
 	spinlock_t stat_lock;	    /* Serialize shmem_sb_info changes */

commit 1c7c474c31aea6d5cb2fb35f31d9e9e91ae466b1
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 3 16:44:44 2009 +0100

    make generic_acl slightly more generic
    
    Now that we cache the ACL pointers in the generic inode all the generic_acl
    cruft can go away and generic_acl.c can directly implement xattr handlers
    dealing with the full Posix ACL semantics for in-memory filesystems.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index deee7afd8d66..e164291fb3e7 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -41,20 +41,4 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 extern int init_tmpfs(void);
 extern int shmem_fill_super(struct super_block *sb, void *data, int silent);
 
-#ifdef CONFIG_TMPFS_POSIX_ACL
-int shmem_check_acl(struct inode *, int);
-int shmem_acl_init(struct inode *, struct inode *);
-
-extern struct xattr_handler shmem_xattr_acl_access_handler;
-extern struct xattr_handler shmem_xattr_acl_default_handler;
-
-extern struct generic_acl_operations shmem_acl_ops;
-
-#else
-static inline int shmem_acl_init(struct inode *inode, struct inode *dir)
-{
-	return 0;
-}
-#endif  /* CONFIG_TMPFS_POSIX_ACL */
-
 #endif

commit 2b2af54a5bb6f7e80ccf78f20084b93c398c3a8b
Author: Kay Sievers <kay.sievers@vrfy.org>
Date:   Thu Apr 30 15:23:42 2009 +0200

    Driver Core: devtmpfs - kernel-maintained tmpfs-based /dev
    
    Devtmpfs lets the kernel create a tmpfs instance called devtmpfs
    very early at kernel initialization, before any driver-core device
    is registered. Every device with a major/minor will provide a
    device node in devtmpfs.
    
    Devtmpfs can be changed and altered by userspace at any time,
    and in any way needed - just like today's udev-mounted tmpfs.
    Unmodified udev versions will run just fine on top of it, and will
    recognize an already existing kernel-created device node and use it.
    The default node permissions are root:root 0600. Proper permissions
    and user/group ownership, meaningful symlinks, all other policy still
    needs to be applied by userspace.
    
    If a node is created by devtmps, devtmpfs will remove the device node
    when the device goes away. If the device node was created by
    userspace, or the devtmpfs created node was replaced by userspace, it
    will no longer be removed by devtmpfs.
    
    If it is requested to auto-mount it, it makes init=/bin/sh work
    without any further userspace support. /dev will be fully populated
    and dynamic, and always reflect the current device state of the kernel.
    With the commonly used dynamic device numbers, it solves the problem
    where static devices nodes may point to the wrong devices.
    
    It is intended to make the initial bootup logic simpler and more robust,
    by de-coupling the creation of the inital environment, to reliably run
    userspace processes, from a complex userspace bootstrap logic to provide
    a working /dev.
    
    Signed-off-by: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Jan Blunck <jblunck@suse.de>
    Tested-By: Harald Hoyer <harald@redhat.com>
    Tested-By: Scott James Remnant <scott@ubuntu.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 6d3f2f449ead..deee7afd8d66 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -38,6 +38,9 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 	return container_of(inode, struct shmem_inode_info, vfs_inode);
 }
 
+extern int init_tmpfs(void);
+extern int shmem_fill_super(struct super_block *sb, void *data, int silent);
+
 #ifdef CONFIG_TMPFS_POSIX_ACL
 int shmem_check_acl(struct inode *, int);
 int shmem_acl_init(struct inode *, struct inode *);

commit 6d848a488ad83cc3891bb274691118f45ce6aab9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 28 12:04:28 2009 -0700

    shmfs: use 'check_acl' instead of 'permission'
    
    shmfs wants purely standard POSIX ACL semantics, so we can use the new
    generic VFS layer POSIX ACL checking rather than cooking our own
    'permission()' function.
    
    Reviewed-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Acked-by: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index abff6c9b413c..6d3f2f449ead 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -39,7 +39,7 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 }
 
 #ifdef CONFIG_TMPFS_POSIX_ACL
-int shmem_permission(struct inode *, int);
+int shmem_check_acl(struct inode *, int);
 int shmem_acl_init(struct inode *, struct inode *);
 
 extern struct xattr_handler shmem_xattr_acl_access_handler;

commit 06b16e9f68edaa1e71aee943d3c030bcf7380af1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 8 19:56:00 2009 -0400

    switch shmem to inode->i_acl
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index fd83f2584b15..abff6c9b413c 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -19,10 +19,6 @@ struct shmem_inode_info {
 	swp_entry_t		i_direct[SHMEM_NR_DIRECT]; /* first blocks */
 	struct list_head	swaplist;	/* chain of maybes on swap */
 	struct inode		vfs_inode;
-#ifdef CONFIG_TMPFS_POSIX_ACL
-	struct posix_acl	*i_acl;
-	struct posix_acl	*i_default_acl;
-#endif
 };
 
 struct shmem_sb_info {
@@ -45,7 +41,6 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 #ifdef CONFIG_TMPFS_POSIX_ACL
 int shmem_permission(struct inode *, int);
 int shmem_acl_init(struct inode *, struct inode *);
-void shmem_acl_destroy_inode(struct inode *);
 
 extern struct xattr_handler shmem_xattr_acl_access_handler;
 extern struct xattr_handler shmem_xattr_acl_default_handler;
@@ -57,9 +52,6 @@ static inline int shmem_acl_init(struct inode *inode, struct inode *dir)
 {
 	return 0;
 }
-static inline void shmem_acl_destroy_inode(struct inode *inode)
-{
-}
 #endif  /* CONFIG_TMPFS_POSIX_ACL */
 
 #endif

commit e6305c43eda10ebfd2ad9e35d6e172ccc7bb3695
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jul 15 21:03:57 2008 -0400

    [PATCH] sanitize ->permission() prototype
    
    * kill nameidata * argument; map the 3 bits in ->flags anybody cares
      about to new MAY_... ones and pass with the mask.
    * kill redundant gfs2_iop_permission()
    * sanitize ecryptfs_permission()
    * fix remaining places where ->permission() instances might barf on new
      MAY_... found in mask.
    
    The obvious next target in that direction is permission(9)
    
    folded fix for nfs_permission() breakage from Miklos Szeredi <mszeredi@suse.cz>
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index f2d12d5a21b8..fd83f2584b15 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -43,7 +43,7 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 }
 
 #ifdef CONFIG_TMPFS_POSIX_ACL
-int shmem_permission(struct inode *, int, struct nameidata *);
+int shmem_permission(struct inode *, int);
 int shmem_acl_init(struct inode *, struct inode *);
 void shmem_acl_destroy_inode(struct inode *);
 

commit 71fe804b6d56d6a7aed680e096901434cef6a2c3
Author: Lee Schermerhorn <lee.schermerhorn@hp.com>
Date:   Mon Apr 28 02:13:26 2008 -0700

    mempolicy: use struct mempolicy pointer in shmem_sb_info
    
    This patch replaces the mempolicy mode, mode_flags, and nodemask in the
    shmem_sb_info struct with a struct mempolicy pointer, initialized to NULL.
    This removes dependency on the details of mempolicy from shmem.c and hugetlbfs
    inode.c and simplifies the interfaces.
    
    mpol_parse_str() in mempolicy.c is changed to return, via a pointer to a
    pointer arg, a struct mempolicy pointer on success.  For MPOL_DEFAULT, the
    returned pointer is NULL.  Further, mpol_parse_str() now takes a 'no_context'
    argument that causes the input nodemask to be stored in the w.user_nodemask of
    the created mempolicy for use when the mempolicy is installed in a tmpfs inode
    shared policy tree.  At that time, any cpuset contextualization is applied to
    the original input nodemask.  This preserves the previous behavior where the
    input nodemask was stored in the superblock.  We can think of the returned
    mempolicy as "context free".
    
    Because mpol_parse_str() is now calling mpol_new(), we can remove from
    mpol_to_str() the semantic checks that mpol_new() already performs.
    
    Add 'no_context' parameter to mpol_to_str() to specify that it should format
    the nodemask in w.user_nodemask for 'bind' and 'interleave' policies.
    
    Change mpol_shared_policy_init() to take a pointer to a "context free" struct
    mempolicy and to create a new, "contextualized" mempolicy using the mode,
    mode_flags and user_nodemask from the input mempolicy.
    
      Note: we know that the mempolicy passed to mpol_to_str() or
      mpol_shared_policy_init() from a tmpfs superblock is "context free".  This
      is currently the only instance thereof.  However, if we found more uses for
      this concept, and introduced any ambiguity as to whether a mempolicy was
      context free or not, we could add another internal mode flag to identify
      context free mempolicies.  Then, we could remove the 'no_context' argument
      from mpol_to_str().
    
    Added shmem_get_sbmpol() to return a reference counted superblock mempolicy,
    if one exists, to pass to mpol_shared_policy_init().  We must add the
    reference under the sb stat_lock to prevent races with replacement of the mpol
    by remount.  This reference is removed in mpol_shared_policy_init().
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: another build fix]
    [akpm@linux-foundation.org: yet another build fix]
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Christoph Lameter <clameter@sgi.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index d7699a628d78..f2d12d5a21b8 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -34,9 +34,7 @@ struct shmem_sb_info {
 	uid_t uid;		    /* Mount uid for root directory */
 	gid_t gid;		    /* Mount gid for root directory */
 	mode_t mode;		    /* Mount mode for root directory */
-	unsigned short policy;	    /* Default NUMA memory alloc policy */
-	unsigned short flags;	    /* Optional mempolicy flags */
-	nodemask_t policy_nodes;    /* nodemask for preferred and bind */
+	struct mempolicy *mpol;     /* default memory policy for mappings */
 };
 
 static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)

commit 028fec414d803117eb4b2ed12acb4dd5da65b32d
Author: David Rientjes <rientjes@google.com>
Date:   Mon Apr 28 02:12:25 2008 -0700

    mempolicy: support optional mode flags
    
    With the evolution of mempolicies, it is necessary to support mempolicy mode
    flags that specify how the policy shall behave in certain circumstances.  The
    most immediate need for mode flag support is to suppress remapping the
    nodemask of a policy at the time of rebind.
    
    Both the mempolicy mode and flags are passed by the user in the 'int policy'
    formal of either the set_mempolicy() or mbind() syscall.  A new constant,
    MPOL_MODE_FLAGS, represents the union of legal optional flags that may be
    passed as part of this int.  Mempolicies that include illegal flags as part of
    their policy are rejected as invalid.
    
    An additional member to struct mempolicy is added to support the mode flags:
    
            struct mempolicy {
                    ...
                    unsigned short policy;
                    unsigned short flags;
            }
    
    The splitting of the 'int' actual passed by the user is done in
    sys_set_mempolicy() and sys_mbind() for their respective syscalls.  This is
    done by intersecting the actual with MPOL_MODE_FLAGS, rejecting the syscall of
    there are additional flags, and storing it in the new 'flags' member of struct
    mempolicy.  The intersection of the actual with ~MPOL_MODE_FLAGS is stored in
    the 'policy' member of the struct and all current users of pol->policy remain
    unchanged.
    
    The union of the policy mode and optional mode flags is passed back to the
    user in get_mempolicy().
    
    This combination of mode and flags within the same actual does not break
    userspace code that relies on get_mempolicy(&policy, ...) and either
    
            switch (policy) {
            case MPOL_BIND:
                    ...
            case MPOL_INTERLEAVE:
                    ...
            };
    
    statements or
    
            if (policy == MPOL_INTERLEAVE) {
                    ...
            }
    
    statements.  Such applications would need to use optional mode flags when
    calling set_mempolicy() or mbind() for these previously implemented statements
    to stop working.  If an application does start using optional mode flags, it
    will need to mask the optional flags off the policy in switch and conditional
    statements that only test mode.
    
    An additional member is also added to struct shmem_sb_info to store the
    optional mode flags.
    
    [hugh@veritas.com: shmem mpol: fix build warning]
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Christoph Lameter <clameter@sgi.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 639a4070708e..d7699a628d78 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -35,6 +35,7 @@ struct shmem_sb_info {
 	gid_t gid;		    /* Mount gid for root directory */
 	mode_t mode;		    /* Mount mode for root directory */
 	unsigned short policy;	    /* Default NUMA memory alloc policy */
+	unsigned short flags;	    /* Optional mempolicy flags */
 	nodemask_t policy_nodes;    /* nodemask for preferred and bind */
 };
 

commit a3b51e0142d1be156ac697eaadadd6cfbb7ba32b
Author: David Rientjes <rientjes@google.com>
Date:   Mon Apr 28 02:12:23 2008 -0700

    mempolicy: convert MPOL constants to enum
    
    The mempolicy mode constants, MPOL_DEFAULT, MPOL_PREFERRED, MPOL_BIND, and
    MPOL_INTERLEAVE, are better declared as part of an enum since they are
    sequentially numbered and cannot be combined.
    
    The policy member of struct mempolicy is also converted from type short to
    type unsigned short.  A negative policy does not have any legitimate meaning,
    so it is possible to change its type in preparation for adding optional mode
    flags later.
    
    The equivalent member of struct shmem_sb_info is also changed from int to
    unsigned short.
    
    For compatibility, the policy formal to get_mempolicy() remains as a pointer
    to an int:
    
            int get_mempolicy(int *policy, unsigned long *nmask,
                              unsigned long maxnode, unsigned long addr,
                              unsigned long flags);
    
    although the only possible values is the range of type unsigned short.
    
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Christoph Lameter <clameter@sgi.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 8d5fb36ea047..639a4070708e 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -34,7 +34,7 @@ struct shmem_sb_info {
 	uid_t uid;		    /* Mount uid for root directory */
 	gid_t gid;		    /* Mount gid for root directory */
 	mode_t mode;		    /* Mount mode for root directory */
-	int policy;		    /* Default NUMA memory alloc policy */
+	unsigned short policy;	    /* Default NUMA memory alloc policy */
 	nodemask_t policy_nodes;    /* nodemask for preferred and bind */
 };
 

commit 680d794babebc74484c141448baa9b95b211cf5e
Author: akpm@linux-foundation.org <akpm@linux-foundation.org>
Date:   Fri Feb 8 04:21:48 2008 -0800

    mount options: fix tmpfs
    
    Add .show_options super operation to tmpfs.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index f3c51899117f..8d5fb36ea047 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -30,9 +30,12 @@ struct shmem_sb_info {
 	unsigned long free_blocks;  /* How many are left for allocation */
 	unsigned long max_inodes;   /* How many inodes are allowed */
 	unsigned long free_inodes;  /* How many are left for allocation */
+	spinlock_t stat_lock;	    /* Serialize shmem_sb_info changes */
+	uid_t uid;		    /* Mount uid for root directory */
+	gid_t gid;		    /* Mount gid for root directory */
+	mode_t mode;		    /* Mount mode for root directory */
 	int policy;		    /* Default NUMA memory alloc policy */
 	nodemask_t policy_nodes;    /* nodemask for preferred and bind */
-	spinlock_t    stat_lock;
 };
 
 static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)

commit 39f0247d3823e4e0bf8f6838a10362864b1e1053
Author: Andreas Gruenbacher <agruen@suse.de>
Date:   Fri Sep 29 02:01:35 2006 -0700

    [PATCH] Access Control Lists for tmpfs
    
    Add access control lists for tmpfs.
    
    Signed-off-by: Andreas Gruenbacher <agruen@suse.de>
    Cc: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index c057f0b32318..f3c51899117f 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -19,6 +19,10 @@ struct shmem_inode_info {
 	swp_entry_t		i_direct[SHMEM_NR_DIRECT]; /* first blocks */
 	struct list_head	swaplist;	/* chain of maybes on swap */
 	struct inode		vfs_inode;
+#ifdef CONFIG_TMPFS_POSIX_ACL
+	struct posix_acl	*i_acl;
+	struct posix_acl	*i_default_acl;
+#endif
 };
 
 struct shmem_sb_info {
@@ -36,4 +40,24 @@ static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
 	return container_of(inode, struct shmem_inode_info, vfs_inode);
 }
 
+#ifdef CONFIG_TMPFS_POSIX_ACL
+int shmem_permission(struct inode *, int, struct nameidata *);
+int shmem_acl_init(struct inode *, struct inode *);
+void shmem_acl_destroy_inode(struct inode *);
+
+extern struct xattr_handler shmem_xattr_acl_access_handler;
+extern struct xattr_handler shmem_xattr_acl_default_handler;
+
+extern struct generic_acl_operations shmem_acl_ops;
+
+#else
+static inline int shmem_acl_init(struct inode *inode, struct inode *dir)
+{
+	return 0;
+}
+static inline void shmem_acl_destroy_inode(struct inode *inode)
+{
+}
+#endif  /* CONFIG_TMPFS_POSIX_ACL */
+
 #endif

commit 7339ff8302fd70aabf5f1ae26e0c4905fa74a495
Author: Robin Holt <holt@sgi.com>
Date:   Sat Jan 14 13:20:48 2006 -0800

    [PATCH] Add tmpfs options for memory placement policies
    
    Anything that writes into a tmpfs filesystem is liable to disproportionately
    decrease the available memory on a particular node.  Since there's no telling
    what sort of application (e.g.  dd/cp/cat) might be dropping large files
    there, this lets the admin choose the appropriate default behavior for their
    site's situation.
    
    Introduce a tmpfs mount option which allows specifying a memory policy and
    a second option to specify the nodelist for that policy.  With the default
    policy, tmpfs will behave as it does today.  This patch adds support for
    preferred, bind, and interleave policies.
    
    The default policy will cause pages to be added to tmpfs files on the node
    which is doing the writing.  Some jobs expect a single process to create
    and manage the tmpfs files.  This results in a node which has a
    significantly reduced number of free pages.
    
    With this patch, the administrator can specify the policy and nodes for
    that policy where they would prefer allocations.
    
    This patch was originally written by Brent Casavant and Hugh Dickins.  I
    added support for the bind and preferred policies and the mpol_nodelist
    mount option.
    
    Signed-off-by: Brent Casavant <bcasavan@sgi.com>
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index c3e598276e78..c057f0b32318 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -26,6 +26,8 @@ struct shmem_sb_info {
 	unsigned long free_blocks;  /* How many are left for allocation */
 	unsigned long max_inodes;   /* How many inodes are allowed */
 	unsigned long free_inodes;  /* How many are left for allocation */
+	int policy;		    /* Default NUMA memory alloc policy */
+	nodemask_t policy_nodes;    /* nodemask for preferred and bind */
 	spinlock_t    stat_lock;
 };
 

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
new file mode 100644
index 000000000000..c3e598276e78
--- /dev/null
+++ b/include/linux/shmem_fs.h
@@ -0,0 +1,37 @@
+#ifndef __SHMEM_FS_H
+#define __SHMEM_FS_H
+
+#include <linux/swap.h>
+#include <linux/mempolicy.h>
+
+/* inode in-kernel data */
+
+#define SHMEM_NR_DIRECT 16
+
+struct shmem_inode_info {
+	spinlock_t		lock;
+	unsigned long		flags;
+	unsigned long		alloced;	/* data pages alloced to file */
+	unsigned long		swapped;	/* subtotal assigned to swap */
+	unsigned long		next_index;	/* highest alloced index + 1 */
+	struct shared_policy	policy;		/* NUMA memory alloc policy */
+	struct page		*i_indirect;	/* top indirect blocks page */
+	swp_entry_t		i_direct[SHMEM_NR_DIRECT]; /* first blocks */
+	struct list_head	swaplist;	/* chain of maybes on swap */
+	struct inode		vfs_inode;
+};
+
+struct shmem_sb_info {
+	unsigned long max_blocks;   /* How many blocks are allowed */
+	unsigned long free_blocks;  /* How many are left for allocation */
+	unsigned long max_inodes;   /* How many inodes are allowed */
+	unsigned long free_inodes;  /* How many are left for allocation */
+	spinlock_t    stat_lock;
+};
+
+static inline struct shmem_inode_info *SHMEM_I(struct inode *inode)
+{
+	return container_of(inode, struct shmem_inode_info, vfs_inode);
+}
+
+#endif
