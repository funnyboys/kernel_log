commit 35f4cd96f5551dc1b2641159e7bb7bf91de6600f
Author: Yangtao Li <tiny.windzz@gmail.com>
Date:   Sat Dec 28 16:19:12 2019 +0000

    stop_machine: Make stop_cpus() static
    
    The function stop_cpus() is only used internally by the
    stop_machine for stop multiple cpus.
    
    Make it static.
    
    Signed-off-by: Yangtao Li <tiny.windzz@gmail.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20191228161912.24082-1-tiny.windzz@gmail.com

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 648298f877da..76d8b09384a7 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -32,7 +32,6 @@ int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg);
 int stop_two_cpus(unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *arg);
 bool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 			 struct cpu_stop_work *work_buf);
-int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 void stop_machine_park(int cpu);
 void stop_machine_unpark(int cpu);
 void stop_machine_yield(const struct cpumask *cpumask);
@@ -81,14 +80,6 @@ static inline bool stop_one_cpu_nowait(unsigned int cpu,
 	return false;
 }
 
-static inline int stop_cpus(const struct cpumask *cpumask,
-			    cpu_stop_fn_t fn, void *arg)
-{
-	if (cpumask_test_cpu(raw_smp_processor_id(), cpumask))
-		return stop_one_cpu(raw_smp_processor_id(), fn, arg);
-	return -ENOENT;
-}
-
 #endif	/* CONFIG_SMP */
 
 /*

commit a5e37de90e67ac1072a9a44bd0cec9f5e98ded08
Author: Yangtao Li <tiny.windzz@gmail.com>
Date:   Sat Dec 14 19:51:07 2019 +0000

    stop_machine: remove try_stop_cpus helper
    
    try_stop_cpus is not used after this:
    
    commit c190c3b16c0f ("rcu: Switch synchronize_sched_expedited() to
    stop_one_cpu()")
    
    So remove it.
    
    Signed-off-by: Yangtao Li <tiny.windzz@gmail.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20191214195107.26480-1-tiny.windzz@gmail.com

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index f9a0c6189852..648298f877da 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -33,7 +33,6 @@ int stop_two_cpus(unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *
 bool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 			 struct cpu_stop_work *work_buf);
 int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
-int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 void stop_machine_park(int cpu);
 void stop_machine_unpark(int cpu);
 void stop_machine_yield(const struct cpumask *cpumask);
@@ -90,12 +89,6 @@ static inline int stop_cpus(const struct cpumask *cpumask,
 	return -ENOENT;
 }
 
-static inline int try_stop_cpus(const struct cpumask *cpumask,
-				cpu_stop_fn_t fn, void *arg)
-{
-	return stop_cpus(cpumask, fn, arg);
-}
-
 #endif	/* CONFIG_SMP */
 
 /*

commit 4ecf0a43e729a7e641d800c294faabe87378fc05
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sat Jun 8 12:13:57 2019 +0200

    processor: get rid of cpu_relax_yield
    
    stop_machine is the only user left of cpu_relax_yield. Given that it
    now has special semantics which are tied to stop_machine introduce a
    weak stop_machine_yield function which architectures can override, and
    get rid of the generic cpu_relax_yield implementation.
    
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 6d3635c86dbe..f9a0c6189852 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -36,6 +36,7 @@ int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 void stop_machine_park(int cpu);
 void stop_machine_unpark(int cpu);
+void stop_machine_yield(const struct cpumask *cpumask);
 
 #else	/* CONFIG_SMP */
 

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 3d60275e3ba9..6d3635c86dbe 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LINUX_STOP_MACHINE
 #define _LINUX_STOP_MACHINE
 

commit fe5595c074005bd94f0c7d1644175941149f6768
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed May 24 10:15:16 2017 +0200

    stop_machine: Provide stop_machine_cpuslocked()
    
    Some call sites of stop_machine() are within a get_online_cpus() protected
    region.
    
    stop_machine() calls get_online_cpus() as well, which is possible in the
    current implementation but prevents converting the hotplug locking to a
    percpu rwsem.
    
    Provide stop_machine_cpuslocked() to avoid nested calls to get_online_cpus().
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20170524081547.400700852@linutronix.de

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 3cc9632dcc2a..3d60275e3ba9 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -116,15 +116,29 @@ static inline int try_stop_cpus(const struct cpumask *cpumask,
  * @fn() runs.
  *
  * This can be thought of as a very heavy write lock, equivalent to
- * grabbing every spinlock in the kernel. */
+ * grabbing every spinlock in the kernel.
+ *
+ * Protects against CPU hotplug.
+ */
 int stop_machine(cpu_stop_fn_t fn, void *data, const struct cpumask *cpus);
 
+/**
+ * stop_machine_cpuslocked: freeze the machine on all CPUs and run this function
+ * @fn: the function to run
+ * @data: the data ptr for the @fn()
+ * @cpus: the cpus to run the @fn() on (NULL = any online cpu)
+ *
+ * Same as above. Must be called from with in a cpus_read_lock() protected
+ * region. Avoids nested calls to cpus_read_lock().
+ */
+int stop_machine_cpuslocked(cpu_stop_fn_t fn, void *data, const struct cpumask *cpus);
+
 int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,
 				   const struct cpumask *cpus);
 #else	/* CONFIG_SMP || CONFIG_HOTPLUG_CPU */
 
-static inline int stop_machine(cpu_stop_fn_t fn, void *data,
-				 const struct cpumask *cpus)
+static inline int stop_machine_cpuslocked(cpu_stop_fn_t fn, void *data,
+					  const struct cpumask *cpus)
 {
 	unsigned long flags;
 	int ret;
@@ -134,6 +148,12 @@ static inline int stop_machine(cpu_stop_fn_t fn, void *data,
 	return ret;
 }
 
+static inline int stop_machine(cpu_stop_fn_t fn, void *data,
+			       const struct cpumask *cpus)
+{
+	return stop_machine_cpuslocked(fn, data, cpus);
+}
+
 static inline int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,
 						 const struct cpumask *cpus)
 {

commit 567bee2803cb46caeb6011de5b738fde33dc3896
Merge: aa0b7ae06387 093e5840ae76
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Jan 6 11:02:29 2016 +0100

    Merge branch 'sched/urgent' into sched/core, to pick up fixes before merging new patches
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 86fffe4a61dd972d5a4e23260d530be6da02f614
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Fri Dec 11 13:40:46 2015 -0800

    kernel: remove stop_machine() Kconfig dependency
    
    Currently the full stop_machine() routine is only enabled on SMP if
    module unloading is enabled, or if the CPUs are hotpluggable.  This
    leads to configurations where stop_machine() is broken as it will then
    only run the callback on the local CPU with irqs disabled, and not stop
    the other CPUs or run the callback on them.
    
    For example, this breaks MTRR setup on x86 in certain configs since
    ea8596bb2d8d379 ("kprobes/x86: Remove unused text_poke_smp() and
    text_poke_smp_batch() functions") as the MTRR is only established on the
    boot CPU.
    
    This patch removes the Kconfig option for STOP_MACHINE and uses the SMP
    and HOTPLUG_CPU config options to compile the correct stop_machine() for
    the architecture, removing the false dependency on MODULE_UNLOAD in the
    process.
    
    Link: https://lkml.org/lkml/2014/10/8/124
    References: https://bugs.freedesktop.org/show_bug.cgi?id=84794
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Pranith Kumar <bobby.prani@gmail.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Vladimir Davydov <vdavydov@parallels.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Iulia Manda <iulia.manda21@gmail.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Chuck Ebbert <cebbert.lkml@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 0adedca24c5b..0e1b1540597a 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -99,7 +99,7 @@ static inline int try_stop_cpus(const struct cpumask *cpumask,
  * grabbing every spinlock (and more).  So the "read" side to such a
  * lock is anything which disables preemption.
  */
-#if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
+#if defined(CONFIG_SMP) || defined(CONFIG_HOTPLUG_CPU)
 
 /**
  * stop_machine: freeze the machine on all CPUs and run this function
@@ -118,7 +118,7 @@ int stop_machine(cpu_stop_fn_t fn, void *data, const struct cpumask *cpus);
 
 int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,
 				   const struct cpumask *cpus);
-#else	 /* CONFIG_STOP_MACHINE && CONFIG_SMP */
+#else	/* CONFIG_SMP || CONFIG_HOTPLUG_CPU */
 
 static inline int stop_machine(cpu_stop_fn_t fn, void *data,
 				 const struct cpumask *cpus)
@@ -137,5 +137,5 @@ static inline int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,
 	return stop_machine(fn, data, cpus);
 }
 
-#endif	/* CONFIG_STOP_MACHINE && CONFIG_SMP */
+#endif	/* CONFIG_SMP || CONFIG_HOTPLUG_CPU */
 #endif	/* _LINUX_STOP_MACHINE */

commit 1b034bd989aa4a396c13d305759c376c52595a97
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Nov 17 18:05:23 2015 +0100

    stop_machine: Make cpu_stop_queue_work() and stop_one_cpu_nowait() return bool
    
    Change cpu_stop_queue_work() to return true if the work was queued and
    change stop_one_cpu_nowait() to return the result of cpu_stop_queue_work().
    This makes it more useful, for example now you can alloc cpu_stop_work for
    stop_one_cpu_nowait() and free it in the callback or if stop_one_cpu_nowait()
    fails, currently this is impossible because you can't know if @fn will be
    called or not.
    
    Also, this allows to kill cpu_stop_done->executed, see the next changes.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Milos Vyletel <milos@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20151117170523.GA13955@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 0adedca24c5b..9ef42e1f0b3a 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -29,7 +29,7 @@ struct cpu_stop_work {
 
 int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg);
 int stop_two_cpus(unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *arg);
-void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
+bool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 			 struct cpu_stop_work *work_buf);
 int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
@@ -65,7 +65,7 @@ static void stop_one_cpu_nowait_workfn(struct work_struct *work)
 	preempt_enable();
 }
 
-static inline void stop_one_cpu_nowait(unsigned int cpu,
+static inline bool stop_one_cpu_nowait(unsigned int cpu,
 				       cpu_stop_fn_t fn, void *arg,
 				       struct cpu_stop_work *work_buf)
 {
@@ -74,7 +74,10 @@ static inline void stop_one_cpu_nowait(unsigned int cpu,
 		work_buf->fn = fn;
 		work_buf->arg = arg;
 		schedule_work(&work_buf->work);
+		return true;
 	}
+
+	return false;
 }
 
 static inline int stop_cpus(const struct cpumask *cpumask,

commit c00166d87e730088d919814020e96ffed129d0d1
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Oct 9 18:00:49 2015 +0200

    stop_machine: Kill smp_hotplug_thread->pre_unpark, introduce stop_machine_unpark()
    
    1. Change smpboot_unpark_thread() to check ->selfparking, just
       like smpboot_park_thread() does.
    
    2. Introduce stop_machine_unpark() which sets ->enabled and calls
       kthread_unpark().
    
    3. Change smpboot_thread_call() and cpu_stop_init() to call
       stop_machine_unpark() by hand.
    
    This way:
    
        - IMO the ->selfparking logic becomes more consistent.
    
        - We can kill the smp_hotplug_thread->pre_unpark() method.
    
        - We can easily unpark the stopper thread earlier. Say, we
          can move stop_machine_unpark() from smpboot_thread_call()
          to sched_cpu_active() as Peter suggests.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: heiko.carstens@de.ibm.com
    Link: http://lkml.kernel.org/r/20151009160049.GA10166@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 7b76362b381c..0adedca24c5b 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -34,6 +34,7 @@ void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 void stop_machine_park(int cpu);
+void stop_machine_unpark(int cpu);
 
 #else	/* CONFIG_SMP */
 

commit 233e7f267e580fefdeb36628b7efe8bfe056d27c
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Oct 8 16:51:31 2015 +0200

    stop_machine: Ensure that a queued callback will be called before cpu_stop_park()
    
    cpu_stop_queue_work() checks stopper->enabled before it queues the
    work, but ->enabled == T can only guarantee cpu_stop_signal_done()
    if we race with cpu_down().
    
    This is not enough for stop_two_cpus() or stop_machine(), they will
    deadlock if multi_cpu_stop() won't be called by one of the target
    CPU's. stop_machine/stop_cpus are fine, they rely on stop_cpus_mutex.
    But stop_two_cpus() has to check cpu_active() to avoid the same race
    with hotplug, and this check is very unobvious and probably not even
    correct if we race with cpu_up().
    
    Change cpu_down() pass to clear ->enabled before cpu_stopper_thread()
    flushes the pending ->works and returns with KTHREAD_SHOULD_PARK set.
    
    Note also that smpboot_thread_call() calls cpu_stop_unpark() which
    sets enabled == T at CPU_ONLINE stage, so this CPU can't go away until
    cpu_stopper_thread() is called at least once. This all means that if
    cpu_stop_queue_work() succeeds, we know that work->fn() will be called.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: heiko.carstens@de.ibm.com
    Link: http://lkml.kernel.org/r/20151008145131.GA18139@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 414d924318ce..7b76362b381c 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -33,6 +33,7 @@ void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 			 struct cpu_stop_work *work_buf);
 int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
+void stop_machine_park(int cpu);
 
 #else	/* CONFIG_SMP */
 

commit 9a301f22faac7fc2207ee49c1855a6b4ba9c5a52
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Jun 30 03:29:55 2015 +0200

    stop_machine: Use 'cpu_stop_fn_t' where possible
    
    Cosmetic, but 'cpu_stop_fn_t' actually makes the code more readable and
    it doesn't break cscope. And most of the declarations already use it.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: dave@stgolabs.net
    Cc: der.herr@hofr.at
    Cc: paulmck@linux.vnet.ibm.com
    Cc: riel@redhat.com
    Cc: viro@ZenIV.linux.org.uk
    Link: http://lkml.kernel.org/r/20150630012955.GA23937@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 0fca276a0537..414d924318ce 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -112,13 +112,13 @@ static inline int try_stop_cpus(const struct cpumask *cpumask,
  *
  * This can be thought of as a very heavy write lock, equivalent to
  * grabbing every spinlock in the kernel. */
-int stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
+int stop_machine(cpu_stop_fn_t fn, void *data, const struct cpumask *cpus);
 
-int stop_machine_from_inactive_cpu(int (*fn)(void *), void *data,
+int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,
 				   const struct cpumask *cpus);
 #else	 /* CONFIG_STOP_MACHINE && CONFIG_SMP */
 
-static inline int stop_machine(int (*fn)(void *), void *data,
+static inline int stop_machine(cpu_stop_fn_t fn, void *data,
 				 const struct cpumask *cpus)
 {
 	unsigned long flags;
@@ -129,7 +129,7 @@ static inline int stop_machine(int (*fn)(void *), void *data,
 	return ret;
 }
 
-static inline int stop_machine_from_inactive_cpu(int (*fn)(void *), void *data,
+static inline int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,
 						 const struct cpumask *cpus)
 {
 	return stop_machine(fn, data, cpus);

commit 7eeb088e72048bf4660f64fc3824c8066cf17591
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Jun 30 03:29:51 2015 +0200

    stop_machine: Unexport __stop_machine()
    
    The only caller outside of stop_machine.c is _cpu_down(), it can use
    stop_machine(). get_online_cpus() is fine under cpu_hotplug_begin().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: dave@stgolabs.net
    Cc: der.herr@hofr.at
    Cc: paulmck@linux.vnet.ibm.com
    Cc: riel@redhat.com
    Cc: viro@ZenIV.linux.org.uk
    Link: http://lkml.kernel.org/r/20150630012951.GA23934@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index d2abbdb8c6aa..0fca276a0537 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -114,23 +114,11 @@ static inline int try_stop_cpus(const struct cpumask *cpumask,
  * grabbing every spinlock in the kernel. */
 int stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
 
-/**
- * __stop_machine: freeze the machine on all CPUs and run this function
- * @fn: the function to run
- * @data: the data ptr for the @fn
- * @cpus: the cpus to run the @fn() on (NULL = any online cpu)
- *
- * Description: This is a special version of the above, which assumes cpus
- * won't come or go while it's being called.  Used by hotplug cpu.
- */
-int __stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
-
 int stop_machine_from_inactive_cpu(int (*fn)(void *), void *data,
 				   const struct cpumask *cpus);
-
 #else	 /* CONFIG_STOP_MACHINE && CONFIG_SMP */
 
-static inline int __stop_machine(int (*fn)(void *), void *data,
+static inline int stop_machine(int (*fn)(void *), void *data,
 				 const struct cpumask *cpus)
 {
 	unsigned long flags;
@@ -141,16 +129,10 @@ static inline int __stop_machine(int (*fn)(void *), void *data,
 	return ret;
 }
 
-static inline int stop_machine(int (*fn)(void *), void *data,
-			       const struct cpumask *cpus)
-{
-	return __stop_machine(fn, data, cpus);
-}
-
 static inline int stop_machine_from_inactive_cpu(int (*fn)(void *), void *data,
 						 const struct cpumask *cpus)
 {
-	return __stop_machine(fn, data, cpus);
+	return stop_machine(fn, data, cpus);
 }
 
 #endif	/* CONFIG_STOP_MACHINE && CONFIG_SMP */

commit 1be0bd77c5dd7c903f46abf52f9a3650face3c1d
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Oct 7 11:29:15 2013 +0100

    stop_machine: Introduce stop_two_cpus()
    
    Introduce stop_two_cpus() in order to allow controlled swapping of two
    tasks. It repurposes the stop_machine() state machine but only stops
    the two cpus which we can do with on-stack structures and avoid
    machine wide synchronization issues.
    
    The ordering of CPUs is important to avoid deadlocks. If unordered then
    two cpus calling stop_two_cpus on each other simultaneously would attempt
    to queue in the opposite order on each CPU causing an AB-BA style deadlock.
    By always having the lowest number CPU doing the queueing of works, we can
    guarantee that works are always queued in the same order, and deadlocks
    are avoided.
    
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    [ Implemented deadlock avoidance. ]
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Link: http://lkml.kernel.org/r/1381141781-10992-38-git-send-email-mgorman@suse.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 3b5e910d14ca..d2abbdb8c6aa 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -28,6 +28,7 @@ struct cpu_stop_work {
 };
 
 int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg);
+int stop_two_cpus(unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *arg);
 void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 			 struct cpu_stop_work *work_buf);
 int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);

commit 9ffc93f203c18a70623f21950f1dd473c9ec48cd
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:03 2012 +0100

    Remove all #inclusions of asm/system.h
    
    Remove all #inclusions of asm/system.h preparatory to splitting and killing
    it.  Performed with the following command:
    
    perl -p -i -e 's!^#\s*include\s*<asm/system[.]h>.*\n!!' `grep -Irl '^#\s*include\s*<asm/system[.]h>' *`
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index c170edc3bf5f..3b5e910d14ca 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -5,7 +5,6 @@
 #include <linux/cpumask.h>
 #include <linux/smp.h>
 #include <linux/list.h>
-#include <asm/system.h>
 
 /*
  * stop_cpu[s]() is simplistic per-cpu maximum priority cpu

commit bb2eac66ee0e8023432e8b0ff13b75e47be199e9
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sun Jul 17 17:11:26 2011 -0400

    stop_machine.h: fix implicit use of smp.h for smp_processor_id
    
    This will show up on MIPS when we fix all the implicit header presences
    that are because of module.h being everywhere.
    
    In file included from kernel/trace/ftrace.c:16:
    include/linux/stop_machine.h: In function 'stop_one_cpu':
    include/linux/stop_machine.h:50: error: implicit declaration of function 'smp_processor_id'
    include/linux/stop_machine.h: In function 'stop_cpus':
    include/linux/stop_machine.h:80: error: implicit declaration of function 'raw_smp_processor_id'
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 2d04ea916760..c170edc3bf5f 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -3,6 +3,7 @@
 
 #include <linux/cpu.h>
 #include <linux/cpumask.h>
+#include <linux/smp.h>
 #include <linux/list.h>
 #include <asm/system.h>
 

commit d3ec4844d449cf7af9e749f73ba2052fb7b72fc2
Merge: 0003230e8200 df2e301fee3c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 25 13:56:39 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (43 commits)
      fs: Merge split strings
      treewide: fix potentially dangerous trailing ';' in #defined values/expressions
      uwb: Fix misspelling of neighbourhood in comment
      net, netfilter: Remove redundant goto in ebt_ulog_packet
      trivial: don't touch files that are removed in the staging tree
      lib/vsprintf: replace link to Draft by final RFC number
      doc: Kconfig: `to be' -> `be'
      doc: Kconfig: Typo: square -> squared
      doc: Konfig: Documentation/power/{pm => apm-acpi}.txt
      drivers/net: static should be at beginning of declaration
      drivers/media: static should be at beginning of declaration
      drivers/i2c: static should be at beginning of declaration
      XTENSA: static should be at beginning of declaration
      SH: static should be at beginning of declaration
      MIPS: static should be at beginning of declaration
      ARM: static should be at beginning of declaration
      rcu: treewide: Do not use rcu_read_lock_held when calling rcu_dereference_check
      Update my e-mail address
      PCIe ASPM: forcedly -> forcibly
      gma500: push through device driver tree
      ...
    
    Fix up trivial conflicts:
     - arch/arm/mach-ep93xx/dma-m2p.c (deleted)
     - drivers/gpio/gpio-ep93xx.c (renamed and context nearby)
     - drivers/net/r8169.c (just context changes)

commit 192d8857427dd23707d5f0b86ca990c3af6f2d74
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Thu Jun 23 11:19:29 2011 -0700

    x86, mtrr: use stop_machine APIs for doing MTRR rendezvous
    
    MTRR rendezvous sequence is not implemened using stop_machine() before, as this
    gets called both from the process context aswell as the cpu online paths
    (where the cpu has not come online and the interrupts are disabled etc).
    
    Now that we have a new stop_machine_from_inactive_cpu() API, use it for
    rendezvous during mtrr init of a logical processor that is coming online.
    
    For the rest (runtime MTRR modification, system boot, resume paths), use
    stop_machine() to implement the rendezvous sequence. This will consolidate and
    cleanup the code.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Link: http://lkml.kernel.org/r/20110623182057.076997177@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index e0f2da25d751..4a9d0c7edc65 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -27,8 +27,6 @@ struct cpu_stop_work {
 	struct cpu_stop_done	*done;
 };
 
-extern struct mutex stop_cpus_mutex;
-
 int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg);
 void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 			 struct cpu_stop_work *work_buf);

commit f740e6cd0cb5e7468e46831aeb4d9c30e03d5ebc
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 23 11:19:28 2011 -0700

    stop_machine: implement stop_machine_from_inactive_cpu()
    
    Currently, mtrr wants stop_machine functionality while a CPU is being
    brought up.  As stop_machine() requires the calling CPU to be active,
    mtrr implements its own stop_machine using stop_one_cpu() on each
    online CPU.  This doesn't only unnecessarily duplicate complex logic
    but also introduces a possibility of deadlock when it races against
    the generic stop_machine().
    
    This patch implements stop_machine_from_inactive_cpu() to serve such
    use cases.  Its functionality is basically the same as stop_machine();
    however, it should be called from a CPU which isn't active and doesn't
    depend on working scheduling on the calling CPU.
    
    This is achieved by using busy loops for synchronization and
    open-coding stop_cpus queuing and waiting with direct invocation of
    fn() for local CPU inbetween.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Link: http://lkml.kernel.org/r/20110623182056.982526827@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 14d3524d1274..e0f2da25d751 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -126,15 +126,19 @@ int stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
  */
 int __stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
 
+int stop_machine_from_inactive_cpu(int (*fn)(void *), void *data,
+				   const struct cpumask *cpus);
+
 #else	 /* CONFIG_STOP_MACHINE && CONFIG_SMP */
 
 static inline int __stop_machine(int (*fn)(void *), void *data,
 				 const struct cpumask *cpus)
 {
+	unsigned long flags;
 	int ret;
-	local_irq_disable();
+	local_irq_save(flags);
 	ret = fn(data);
-	local_irq_enable();
+	local_irq_restore(flags);
 	return ret;
 }
 
@@ -144,5 +148,11 @@ static inline int stop_machine(int (*fn)(void *), void *data,
 	return __stop_machine(fn, data, cpus);
 }
 
+static inline int stop_machine_from_inactive_cpu(int (*fn)(void *), void *data,
+						 const struct cpumask *cpus)
+{
+	return __stop_machine(fn, data, cpus);
+}
+
 #endif	/* CONFIG_STOP_MACHINE && CONFIG_SMP */
 #endif	/* _LINUX_STOP_MACHINE */

commit 6d3321e8e2b3bf6a5892e2ef673c7bf536e3f904
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Thu Jun 23 11:19:26 2011 -0700

    x86, mtrr: lock stop machine during MTRR rendezvous sequence
    
    MTRR rendezvous sequence using stop_one_cpu_nowait() can potentially
    happen in parallel with another system wide rendezvous using
    stop_machine(). This can lead to deadlock (The order in which
    works are queued can be different on different cpu's. Some cpu's
    will be running the first rendezvous handler and others will be running
    the second rendezvous handler. Each set waiting for the other set to join
    for the system wide rendezvous, leading to a deadlock).
    
    MTRR rendezvous sequence is not implemented using stop_machine() as this
    gets called both from the process context aswell as the cpu online paths
    (where the cpu has not come online and the interrupts are disabled etc).
    stop_machine() works with only online cpus.
    
    For now, take the stop_machine mutex in the MTRR rendezvous sequence that
    gets called from an online cpu (here we are in the process context
    and can potentially sleep while taking the mutex). And the MTRR rendezvous
    that gets triggered during cpu online doesn't need to take this stop_machine
    lock (as the stop_machine() already ensures that there is no cpu hotplug
    going on in parallel by doing get_online_cpus())
    
        TBD: Pursue a cleaner solution of extending the stop_machine()
             infrastructure to handle the case where the calling cpu is
             still not online and use this for MTRR rendezvous sequence.
    
    fixes: https://bugzilla.novell.com/show_bug.cgi?id=672008
    
    Reported-by: Vadim Kotelnikov <vadimuzzz@inbox.ru>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Link: http://lkml.kernel.org/r/20110623182056.807230326@sbsiddha-MOBL3.sc.intel.com
    Cc: stable@kernel.org # 2.6.35+, backport a week or two after this gets more testing in mainline
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 092dc9b1ce7d..14d3524d1274 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -27,6 +27,8 @@ struct cpu_stop_work {
 	struct cpu_stop_done	*done;
 };
 
+extern struct mutex stop_cpus_mutex;
+
 int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg);
 void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 			 struct cpu_stop_work *work_buf);

commit 1816315b10862277a961a70ec394b6607983041d
Author: Jonathan Neuschäfer <j.neuschaefer@gmx.net>
Date:   Sun Jun 19 11:50:22 2011 +0200

    stop_machine.h: "disables preeempt" -> "disables preemption"
    
    Use the noun instead of a misspelled verb.
    
    Signed-off-by: Jonathan Neuschäfer <j.neuschaefer@gmx.net>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 092dc9b1ce7d..2d3f0b1b054c 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -94,7 +94,7 @@ static inline int try_stop_cpus(const struct cpumask *cpumask,
  * stop_machine "Bogolock": stop the entire machine, disable
  * interrupts.  This is a very heavy lock, which is equivalent to
  * grabbing every spinlock (and more).  So the "read" side to such a
- * lock is anything which disables preeempt.
+ * lock is anything which disables preemption.
  */
 #if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
 

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 1808960c5059..092dc9b1ce7d 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -105,7 +105,7 @@ static inline int try_stop_cpus(const struct cpumask *cpumask,
  * @cpus: the cpus to run the @fn() on (NULL = any online cpu)
  *
  * Description: This causes a thread to be scheduled on every cpu,
- * each of which disables interrupts.  The result is that noone is
+ * each of which disables interrupts.  The result is that no one is
  * holding a spinlock or inside any other preempt-disabled region when
  * @fn() runs.
  *

commit 087a4eb55971dfcc8df18312faf9393d0a479f3a
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Thu Oct 14 12:10:30 2010 +0900

    stopmachine: Define __stop_machine when CONFIG_STOP_MACHINE=n
    
    Define dummy __stop_machine() function even when
    CONFIG_STOP_MACHINE=n. This getcpu-required version of
    stop_machine() will be used from poke_text_smp().
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Cc: 2nddept-manager@sdl.hitachi.co.jp
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20101014031030.4100.34156.stgit@ltc236.sdl.hitachi.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 6b524a0d02e4..1808960c5059 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -126,8 +126,8 @@ int __stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
 
 #else	 /* CONFIG_STOP_MACHINE && CONFIG_SMP */
 
-static inline int stop_machine(int (*fn)(void *), void *data,
-			       const struct cpumask *cpus)
+static inline int __stop_machine(int (*fn)(void *), void *data,
+				 const struct cpumask *cpus)
 {
 	int ret;
 	local_irq_disable();
@@ -136,5 +136,11 @@ static inline int stop_machine(int (*fn)(void *), void *data,
 	return ret;
 }
 
+static inline int stop_machine(int (*fn)(void *), void *data,
+			       const struct cpumask *cpus)
+{
+	return __stop_machine(fn, data, cpus);
+}
+
 #endif	/* CONFIG_STOP_MACHINE && CONFIG_SMP */
 #endif	/* _LINUX_STOP_MACHINE */

commit bbf1bb3eee86f2eef2baa14e600be454d09109ee
Author: Tejun Heo <tj@kernel.org>
Date:   Sat May 8 16:20:53 2010 +0200

    cpu_stop: add dummy implementation for UP
    
    When !CONFIG_SMP, cpu_stop functions weren't defined at all which
    could lead to build failures if UP code uses cpu_stop facility.  Add
    dummy cpu_stop implementation for UP.  The waiting variants execute
    the work function directly with preempt disabled and
    stop_one_cpu_nowait() schedules a workqueue work.
    
    Makefile and ifdefs around stop_machine implementation are updated to
    accomodate CONFIG_SMP && !CONFIG_STOP_MACHINE case.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 0e552e72a4c4..6b524a0d02e4 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -6,8 +6,6 @@
 #include <linux/list.h>
 #include <asm/system.h>
 
-#if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
-
 /*
  * stop_cpu[s]() is simplistic per-cpu maximum priority cpu
  * monopolization mechanism.  The caller can specify a non-sleeping
@@ -18,9 +16,10 @@
  * up and requests are guaranteed to be served as long as the target
  * cpus are online.
  */
-
 typedef int (*cpu_stop_fn_t)(void *arg);
 
+#ifdef CONFIG_SMP
+
 struct cpu_stop_work {
 	struct list_head	list;		/* cpu_stopper->works */
 	cpu_stop_fn_t		fn;
@@ -34,12 +33,70 @@ void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
 int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
 
+#else	/* CONFIG_SMP */
+
+#include <linux/workqueue.h>
+
+struct cpu_stop_work {
+	struct work_struct	work;
+	cpu_stop_fn_t		fn;
+	void			*arg;
+};
+
+static inline int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg)
+{
+	int ret = -ENOENT;
+	preempt_disable();
+	if (cpu == smp_processor_id())
+		ret = fn(arg);
+	preempt_enable();
+	return ret;
+}
+
+static void stop_one_cpu_nowait_workfn(struct work_struct *work)
+{
+	struct cpu_stop_work *stwork =
+		container_of(work, struct cpu_stop_work, work);
+	preempt_disable();
+	stwork->fn(stwork->arg);
+	preempt_enable();
+}
+
+static inline void stop_one_cpu_nowait(unsigned int cpu,
+				       cpu_stop_fn_t fn, void *arg,
+				       struct cpu_stop_work *work_buf)
+{
+	if (cpu == smp_processor_id()) {
+		INIT_WORK(&work_buf->work, stop_one_cpu_nowait_workfn);
+		work_buf->fn = fn;
+		work_buf->arg = arg;
+		schedule_work(&work_buf->work);
+	}
+}
+
+static inline int stop_cpus(const struct cpumask *cpumask,
+			    cpu_stop_fn_t fn, void *arg)
+{
+	if (cpumask_test_cpu(raw_smp_processor_id(), cpumask))
+		return stop_one_cpu(raw_smp_processor_id(), fn, arg);
+	return -ENOENT;
+}
+
+static inline int try_stop_cpus(const struct cpumask *cpumask,
+				cpu_stop_fn_t fn, void *arg)
+{
+	return stop_cpus(cpumask, fn, arg);
+}
+
+#endif	/* CONFIG_SMP */
+
 /*
  * stop_machine "Bogolock": stop the entire machine, disable
  * interrupts.  This is a very heavy lock, which is equivalent to
  * grabbing every spinlock (and more).  So the "read" side to such a
  * lock is anything which disables preeempt.
  */
+#if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
 
 /**
  * stop_machine: freeze the machine on all CPUs and run this function
@@ -67,7 +124,7 @@ int stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
  */
 int __stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
 
-#else
+#else	 /* CONFIG_STOP_MACHINE && CONFIG_SMP */
 
 static inline int stop_machine(int (*fn)(void *), void *data,
 			       const struct cpumask *cpus)
@@ -79,5 +136,5 @@ static inline int stop_machine(int (*fn)(void *), void *data,
 	return ret;
 }
 
-#endif /* CONFIG_SMP */
-#endif /* _LINUX_STOP_MACHINE */
+#endif	/* CONFIG_STOP_MACHINE && CONFIG_SMP */
+#endif	/* _LINUX_STOP_MACHINE */

commit 3fc1f1e27a5b807791d72e5d992aa33b668a6626
Author: Tejun Heo <tj@kernel.org>
Date:   Thu May 6 18:49:20 2010 +0200

    stop_machine: reimplement using cpu_stop
    
    Reimplement stop_machine using cpu_stop.  As cpu stoppers are
    guaranteed to be available for all online cpus,
    stop_machine_create/destroy() are no longer necessary and removed.
    
    With resource management and synchronization handled by cpu_stop, the
    new implementation is much simpler.  Asking the cpu_stop to execute
    the stop_cpu() state machine on all online cpus with cpu hotplug
    disabled is enough.
    
    stop_machine itself doesn't need to manage any global resources
    anymore, so all per-instance information is rolled into struct
    stop_machine_data and the mutex and all static data variables are
    removed.
    
    The previous implementation created and destroyed RT workqueues as
    necessary which made stop_machine() calls highly expensive on very
    large machines.  According to Dimitri Sivanich, preventing the dynamic
    creation/destruction makes booting faster more than twice on very
    large machines.  cpu_stop resources are preallocated for all online
    cpus and should have the same effect.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Dimitri Sivanich <sivanich@sgi.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index efcbd6c37947..0e552e72a4c4 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -67,23 +67,6 @@ int stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
  */
 int __stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
 
-/**
- * stop_machine_create: create all stop_machine threads
- *
- * Description: This causes all stop_machine threads to be created before
- * stop_machine actually gets called. This can be used by subsystems that
- * need a non failing stop_machine infrastructure.
- */
-int stop_machine_create(void);
-
-/**
- * stop_machine_destroy: destroy all stop_machine threads
- *
- * Description: This causes all stop_machine threads which were created with
- * stop_machine_create to be destroyed again.
- */
-void stop_machine_destroy(void);
-
 #else
 
 static inline int stop_machine(int (*fn)(void *), void *data,
@@ -96,8 +79,5 @@ static inline int stop_machine(int (*fn)(void *), void *data,
 	return ret;
 }
 
-static inline int stop_machine_create(void) { return 0; }
-static inline void stop_machine_destroy(void) { }
-
 #endif /* CONFIG_SMP */
 #endif /* _LINUX_STOP_MACHINE */

commit 1142d810298e694754498dbb4983fcb6cb7fd884
Author: Tejun Heo <tj@kernel.org>
Date:   Thu May 6 18:49:20 2010 +0200

    cpu_stop: implement stop_cpu[s]()
    
    Implement a simplistic per-cpu maximum priority cpu monopolization
    mechanism.  A non-sleeping callback can be scheduled to run on one or
    multiple cpus with maximum priority monopolozing those cpus.  This is
    primarily to replace and unify RT workqueue usage in stop_machine and
    scheduler migration_thread which currently is serving multiple
    purposes.
    
    Four functions are provided - stop_one_cpu(), stop_one_cpu_nowait(),
    stop_cpus() and try_stop_cpus().
    
    This is to allow clean sharing of resources among stop_cpu and all the
    migration thread users.  One stopper thread per cpu is created which
    is currently named "stopper/CPU".  This will eventually replace the
    migration thread and take on its name.
    
    * This facility was originally named cpuhog and lived in separate
      files but Peter Zijlstra nacked the name and thus got renamed to
      cpu_stop and moved into stop_machine.c.
    
    * Better reporting of preemption leak as per Peter's suggestion.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Dimitri Sivanich <sivanich@sgi.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index baba3a23a814..efcbd6c37947 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -1,15 +1,46 @@
 #ifndef _LINUX_STOP_MACHINE
 #define _LINUX_STOP_MACHINE
-/* "Bogolock": stop the entire machine, disable interrupts.  This is a
-   very heavy lock, which is equivalent to grabbing every spinlock
-   (and more).  So the "read" side to such a lock is anything which
-   disables preeempt. */
+
 #include <linux/cpu.h>
 #include <linux/cpumask.h>
+#include <linux/list.h>
 #include <asm/system.h>
 
 #if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
 
+/*
+ * stop_cpu[s]() is simplistic per-cpu maximum priority cpu
+ * monopolization mechanism.  The caller can specify a non-sleeping
+ * function to be executed on a single or multiple cpus preempting all
+ * other processes and monopolizing those cpus until it finishes.
+ *
+ * Resources for this mechanism are preallocated when a cpu is brought
+ * up and requests are guaranteed to be served as long as the target
+ * cpus are online.
+ */
+
+typedef int (*cpu_stop_fn_t)(void *arg);
+
+struct cpu_stop_work {
+	struct list_head	list;		/* cpu_stopper->works */
+	cpu_stop_fn_t		fn;
+	void			*arg;
+	struct cpu_stop_done	*done;
+};
+
+int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg);
+void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
+			 struct cpu_stop_work *work_buf);
+int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
+int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);
+
+/*
+ * stop_machine "Bogolock": stop the entire machine, disable
+ * interrupts.  This is a very heavy lock, which is equivalent to
+ * grabbing every spinlock (and more).  So the "read" side to such a
+ * lock is anything which disables preeempt.
+ */
+
 /**
  * stop_machine: freeze the machine on all CPUs and run this function
  * @fn: the function to run

commit 9ea09af3bd3090e8349ca2899ca2011bd94cda85
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Dec 22 12:36:30 2008 +0100

    stop_machine: introduce stop_machine_create/destroy.
    
    Introduce stop_machine_create/destroy. With this interface subsystems
    that need a non-failing stop_machine environment can create the
    stop_machine machine threads before actually calling stop_machine.
    When the threads aren't needed anymore they can be killed with
    stop_machine_destroy again.
    
    When stop_machine gets called and the threads aren't present they
    will be created and destroyed automatically. This restores the old
    behaviour of stop_machine.
    
    This patch also converts cpu hotplug to the new interface since it
    is special: cpu_down calls __stop_machine instead of stop_machine.
    However the kstop threads will only be created when stop_machine
    gets called.
    
    Changing the code so that the threads would be created automatically
    on __stop_machine is currently not possible: when __stop_machine gets
    called we hold cpu_add_remove_lock, which is the same lock that
    create_rt_workqueue would take. So the workqueue needs to be created
    before the cpu hotplug code locks cpu_add_remove_lock.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 74d59a641362..baba3a23a814 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -35,6 +35,24 @@ int stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
  * won't come or go while it's being called.  Used by hotplug cpu.
  */
 int __stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
+
+/**
+ * stop_machine_create: create all stop_machine threads
+ *
+ * Description: This causes all stop_machine threads to be created before
+ * stop_machine actually gets called. This can be used by subsystems that
+ * need a non failing stop_machine infrastructure.
+ */
+int stop_machine_create(void);
+
+/**
+ * stop_machine_destroy: destroy all stop_machine threads
+ *
+ * Description: This causes all stop_machine threads which were created with
+ * stop_machine_create to be destroyed again.
+ */
+void stop_machine_destroy(void);
+
 #else
 
 static inline int stop_machine(int (*fn)(void *), void *data,
@@ -46,5 +64,9 @@ static inline int stop_machine(int (*fn)(void *), void *data,
 	local_irq_enable();
 	return ret;
 }
+
+static inline int stop_machine_create(void) { return 0; }
+static inline void stop_machine_destroy(void) { }
+
 #endif /* CONFIG_SMP */
 #endif /* _LINUX_STOP_MACHINE */

commit 41c7bb9588904eb060a95bcad47bd3804a1ece25
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Jan 1 10:12:28 2009 +1030

    cpumask: convert rest of files in kernel/
    
    Impact: Reduce stack usage, use new cpumask API.
    
    Mainly changing cpumask_t to 'struct cpumask' and similar simple API
    conversion.  Two conversions worth mentioning:
    
    1) we use cpumask_any_but to avoid a temporary in kernel/softlockup.c,
    2) Use cpumask_var_t in taskstats_user_cmd().
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index faf1519b5adc..74d59a641362 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -23,7 +23,7 @@
  *
  * This can be thought of as a very heavy write lock, equivalent to
  * grabbing every spinlock in the kernel. */
-int stop_machine(int (*fn)(void *), void *data, const cpumask_t *cpus);
+int stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
 
 /**
  * __stop_machine: freeze the machine on all CPUs and run this function
@@ -34,11 +34,11 @@ int stop_machine(int (*fn)(void *), void *data, const cpumask_t *cpus);
  * Description: This is a special version of the above, which assumes cpus
  * won't come or go while it's being called.  Used by hotplug cpu.
  */
-int __stop_machine(int (*fn)(void *), void *data, const cpumask_t *cpus);
+int __stop_machine(int (*fn)(void *), void *data, const struct cpumask *cpus);
 #else
 
 static inline int stop_machine(int (*fn)(void *), void *data,
-			       const cpumask_t *cpus)
+			       const struct cpumask *cpus)
 {
 	int ret;
 	local_irq_disable();

commit bf2002967775cbb233876d51ff94e8daa7e77858
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Tue Aug 26 00:19:27 2008 -0500

    stop_machine: Remove deprecated stop_machine_run
    
    Everyone should be using stop_machine() now.  The staged API
    transition helped life in linux-next.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index f1cb0ba6d715..faf1519b5adc 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -3,16 +3,13 @@
 /* "Bogolock": stop the entire machine, disable interrupts.  This is a
    very heavy lock, which is equivalent to grabbing every spinlock
    (and more).  So the "read" side to such a lock is anything which
-   diables preeempt. */
+   disables preeempt. */
 #include <linux/cpu.h>
 #include <linux/cpumask.h>
 #include <asm/system.h>
 
 #if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
 
-/* Deprecated, but useful for transition. */
-#define ALL_CPUS ~0U
-
 /**
  * stop_machine: freeze the machine on all CPUs and run this function
  * @fn: the function to run
@@ -50,18 +47,4 @@ static inline int stop_machine(int (*fn)(void *), void *data,
 	return ret;
 }
 #endif /* CONFIG_SMP */
-
-static inline int __deprecated stop_machine_run(int (*fn)(void *), void *data,
-						unsigned int cpu)
-{
-	/* If they don't care which cpu fn runs on, just pick one. */
-	if (cpu == NR_CPUS)
-		return stop_machine(fn, data, NULL);
-	else if (cpu == ~0U)
-		return stop_machine(fn, data, &cpu_possible_map);
-	else {
-		cpumask_t cpus = cpumask_of_cpu(cpu);
-		return stop_machine(fn, data, &cpus);
-	}
-}
 #endif /* _LINUX_STOP_MACHINE */

commit eeec4fad963490821348a331cca6102ae1c4a7a3
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Jul 28 12:16:30 2008 -0500

    stop_machine(): stop_machine_run() changed to use cpu mask
    
    Instead of a "cpu" arg with magic values NR_CPUS (any cpu) and ~0 (all
    cpus), pass a cpumask_t.  Allow NULL for the common case (where we
    don't care which CPU the function is run on): temporary cpumask_t's
    are usually considered bad for stack space.
    
    This deprecates stop_machine_run, to be removed soon when all the
    callers are dead.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 36c2c7284eb3..f1cb0ba6d715 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -5,19 +5,19 @@
    (and more).  So the "read" side to such a lock is anything which
    diables preeempt. */
 #include <linux/cpu.h>
+#include <linux/cpumask.h>
 #include <asm/system.h>
 
 #if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
 
+/* Deprecated, but useful for transition. */
 #define ALL_CPUS ~0U
 
 /**
- * stop_machine_run: freeze the machine on all CPUs and run this function
+ * stop_machine: freeze the machine on all CPUs and run this function
  * @fn: the function to run
  * @data: the data ptr for the @fn()
- * @cpu: if @cpu == n, run @fn() on cpu n
- *       if @cpu == NR_CPUS, run @fn() on any cpu
- *       if @cpu == ALL_CPUS, run @fn() on every online CPU.
+ * @cpus: the cpus to run the @fn() on (NULL = any online cpu)
  *
  * Description: This causes a thread to be scheduled on every cpu,
  * each of which disables interrupts.  The result is that noone is
@@ -26,22 +26,22 @@
  *
  * This can be thought of as a very heavy write lock, equivalent to
  * grabbing every spinlock in the kernel. */
-int stop_machine_run(int (*fn)(void *), void *data, unsigned int cpu);
+int stop_machine(int (*fn)(void *), void *data, const cpumask_t *cpus);
 
 /**
- * __stop_machine_run: freeze the machine on all CPUs and run this function
+ * __stop_machine: freeze the machine on all CPUs and run this function
  * @fn: the function to run
  * @data: the data ptr for the @fn
- * @cpu: the cpu to run @fn on (or any, if @cpu == NR_CPUS.
+ * @cpus: the cpus to run the @fn() on (NULL = any online cpu)
  *
  * Description: This is a special version of the above, which assumes cpus
  * won't come or go while it's being called.  Used by hotplug cpu.
  */
-int __stop_machine_run(int (*fn)(void *), void *data, unsigned int cpu);
+int __stop_machine(int (*fn)(void *), void *data, const cpumask_t *cpus);
 #else
 
-static inline int stop_machine_run(int (*fn)(void *), void *data,
-				   unsigned int cpu)
+static inline int stop_machine(int (*fn)(void *), void *data,
+			       const cpumask_t *cpus)
 {
 	int ret;
 	local_irq_disable();
@@ -50,4 +50,18 @@ static inline int stop_machine_run(int (*fn)(void *), void *data,
 	return ret;
 }
 #endif /* CONFIG_SMP */
+
+static inline int __deprecated stop_machine_run(int (*fn)(void *), void *data,
+						unsigned int cpu)
+{
+	/* If they don't care which cpu fn runs on, just pick one. */
+	if (cpu == NR_CPUS)
+		return stop_machine(fn, data, NULL);
+	else if (cpu == ~0U)
+		return stop_machine(fn, data, &cpu_possible_map);
+	else {
+		cpumask_t cpus = cpumask_of_cpu(cpu);
+		return stop_machine(fn, data, &cpus);
+	}
+}
 #endif /* _LINUX_STOP_MACHINE */

commit ffdb5976c47609c862917d4c186ecbb5706d2dda
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Jul 28 12:16:28 2008 -0500

    Simplify stop_machine
    
    stop_machine creates a kthread which creates kernel threads.  We can
    create those threads directly and simplify things a little.  Some care
    must be taken with CPU hotunplug, which has special needs, but that code
    seems more robust than it was in the past.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Christian Borntraeger <borntraeger@de.ibm.com>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 18af011c13af..36c2c7284eb3 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -17,13 +17,12 @@
  * @data: the data ptr for the @fn()
  * @cpu: if @cpu == n, run @fn() on cpu n
  *       if @cpu == NR_CPUS, run @fn() on any cpu
- *       if @cpu == ALL_CPUS, run @fn() first on the calling cpu, and then
- *       concurrently on all the other cpus
+ *       if @cpu == ALL_CPUS, run @fn() on every online CPU.
  *
- * Description: This causes a thread to be scheduled on every other cpu,
- * each of which disables interrupts, and finally interrupts are disabled
- * on the current CPU.  The result is that noone is holding a spinlock
- * or inside any other preempt-disabled region when @fn() runs.
+ * Description: This causes a thread to be scheduled on every cpu,
+ * each of which disables interrupts.  The result is that noone is
+ * holding a spinlock or inside any other preempt-disabled region when
+ * @fn() runs.
  *
  * This can be thought of as a very heavy write lock, equivalent to
  * grabbing every spinlock in the kernel. */
@@ -35,13 +34,10 @@ int stop_machine_run(int (*fn)(void *), void *data, unsigned int cpu);
  * @data: the data ptr for the @fn
  * @cpu: the cpu to run @fn on (or any, if @cpu == NR_CPUS.
  *
- * Description: This is a special version of the above, which returns the
- * thread which has run @fn(): kthread_stop will return the return value
- * of @fn().  Used by hotplug cpu.
+ * Description: This is a special version of the above, which assumes cpus
+ * won't come or go while it's being called.  Used by hotplug cpu.
  */
-struct task_struct *__stop_machine_run(int (*fn)(void *), void *data,
-				       unsigned int cpu);
-
+int __stop_machine_run(int (*fn)(void *), void *data, unsigned int cpu);
 #else
 
 static inline int stop_machine_run(int (*fn)(void *), void *data,

commit 5c2aed622571ac7c3c6ec182d6d3c318e4b45c8b
Author: Jason Baron <jbaron@redhat.com>
Date:   Thu Feb 28 11:33:03 2008 -0500

    stop_machine: add ALL_CPUS option
    
    -allow stop_mahcine_run() to call a function on all cpus. Calling
     stop_machine_run() with a 'ALL_CPUS' invokes this new behavior.
     stop_machine_run() proceeds as normal until the calling cpu has
     invoked 'fn'. Then, we tell all the other cpus to call 'fn'.
    
    Signed-off-by: Jason Baron <jbaron@redhat.com>
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    CC: Adrian Bunk <bunk@stusta.de>
    CC: Andi Kleen <andi@firstfloor.org>
    CC: Alexey Dobriyan <adobriyan@gmail.com>
    CC: Christoph Hellwig <hch@infradead.org>
    CC: mingo@elte.hu
    CC: akpm@osdl.org

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 5bfc553bdb21..18af011c13af 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -8,11 +8,17 @@
 #include <asm/system.h>
 
 #if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
+
+#define ALL_CPUS ~0U
+
 /**
  * stop_machine_run: freeze the machine on all CPUs and run this function
  * @fn: the function to run
  * @data: the data ptr for the @fn()
- * @cpu: the cpu to run @fn() on (or any, if @cpu == NR_CPUS.
+ * @cpu: if @cpu == n, run @fn() on cpu n
+ *       if @cpu == NR_CPUS, run @fn() on any cpu
+ *       if @cpu == ALL_CPUS, run @fn() first on the calling cpu, and then
+ *       concurrently on all the other cpus
  *
  * Description: This causes a thread to be scheduled on every other cpu,
  * each of which disables interrupts, and finally interrupts are disabled

commit 62c4f0a2d5a188f73a94f2cb8ea0dba3e7cf0a7f
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Wed Apr 26 12:56:16 2006 +0100

    Don't include linux/config.h from anywhere else in include/
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
index 151a803ed0ed..5bfc553bdb21 100644
--- a/include/linux/stop_machine.h
+++ b/include/linux/stop_machine.h
@@ -4,7 +4,6 @@
    very heavy lock, which is equivalent to grabbing every spinlock
    (and more).  So the "read" side to such a lock is anything which
    diables preeempt. */
-#include <linux/config.h>
 #include <linux/cpu.h>
 #include <asm/system.h>
 

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/stop_machine.h b/include/linux/stop_machine.h
new file mode 100644
index 000000000000..151a803ed0ed
--- /dev/null
+++ b/include/linux/stop_machine.h
@@ -0,0 +1,52 @@
+#ifndef _LINUX_STOP_MACHINE
+#define _LINUX_STOP_MACHINE
+/* "Bogolock": stop the entire machine, disable interrupts.  This is a
+   very heavy lock, which is equivalent to grabbing every spinlock
+   (and more).  So the "read" side to such a lock is anything which
+   diables preeempt. */
+#include <linux/config.h>
+#include <linux/cpu.h>
+#include <asm/system.h>
+
+#if defined(CONFIG_STOP_MACHINE) && defined(CONFIG_SMP)
+/**
+ * stop_machine_run: freeze the machine on all CPUs and run this function
+ * @fn: the function to run
+ * @data: the data ptr for the @fn()
+ * @cpu: the cpu to run @fn() on (or any, if @cpu == NR_CPUS.
+ *
+ * Description: This causes a thread to be scheduled on every other cpu,
+ * each of which disables interrupts, and finally interrupts are disabled
+ * on the current CPU.  The result is that noone is holding a spinlock
+ * or inside any other preempt-disabled region when @fn() runs.
+ *
+ * This can be thought of as a very heavy write lock, equivalent to
+ * grabbing every spinlock in the kernel. */
+int stop_machine_run(int (*fn)(void *), void *data, unsigned int cpu);
+
+/**
+ * __stop_machine_run: freeze the machine on all CPUs and run this function
+ * @fn: the function to run
+ * @data: the data ptr for the @fn
+ * @cpu: the cpu to run @fn on (or any, if @cpu == NR_CPUS.
+ *
+ * Description: This is a special version of the above, which returns the
+ * thread which has run @fn(): kthread_stop will return the return value
+ * of @fn().  Used by hotplug cpu.
+ */
+struct task_struct *__stop_machine_run(int (*fn)(void *), void *data,
+				       unsigned int cpu);
+
+#else
+
+static inline int stop_machine_run(int (*fn)(void *), void *data,
+				   unsigned int cpu)
+{
+	int ret;
+	local_irq_disable();
+	ret = fn(data);
+	local_irq_enable();
+	return ret;
+}
+#endif /* CONFIG_SMP */
+#endif /* _LINUX_STOP_MACHINE */
