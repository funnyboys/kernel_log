commit 88b3d5c90e9685be54dd5bc441970044020eca76
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Jun 22 09:03:31 2020 +0300

    net/mlx5e: Fix port buffers cell size value
    
    Device unit for port buffers size, xoff_threshold and xon_threshold is
    cells. Fix a bug in driver where cell unit size was hard-coded to
    128 bytes. This hard-coded value is buggy, as it is wrong for some hardware
    versions.
    
    Driver to read cell size from SBCAM register and translate bytes to cell
    units accordingly.
    
    In order to fix the bug, this patch exposes SBCAM (Shared buffer
    capabilities mask) layout and defines.
    
    If SBCAM.cap_cell_size is valid, use it for all bytes to cells
    calculations. If not valid, fallback to 128.
    
    Cell size do not change on the fly per device. Instead of issuing SBCAM
    access reg command every time such translation is needed, cache it in
    mlx5e_dcbx as part of mlx5e_dcbnl_initialize(). Pass dcbx.port_buff_cell_sz
    as a param to every function that needs bytes to cells translation.
    
    While fixing the bug, move MLX5E_BUFFER_CELL_SHIFT macro to
    en_dcbnl.c, as it is only used by that file.
    
    Fixes: 0696d60853d5 ("net/mlx5e: Receive buffer configuration")
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Reviewed-by: Huy Nguyen <huyn@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 13c0e4556eda..1e6ca716635a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -147,6 +147,7 @@ enum {
 	MLX5_REG_MCDA		 = 0x9063,
 	MLX5_REG_MCAM		 = 0x907f,
 	MLX5_REG_MIRC		 = 0x9162,
+	MLX5_REG_SBCAM		 = 0xB01F,
 	MLX5_REG_RESOURCE_DUMP   = 0xC000,
 };
 

commit 2553f421f44f4db7579f202b79b69046b579c7b5
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Wed May 27 23:16:02 2020 -0700

    net/mlx5: cmd: Fix memset with byte count warning
    
    Fix sparse warning:
    drivers/net/ethernet/mellanox/mlx5/core/cmd.c:1949:15:
    warning: memset with byte count of 271720
    
    mlx5_cmd_stats array is too big to be held inline in mlx5_cmd.
    Allocate it separately.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6aa6bbd60559..13c0e4556eda 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -298,7 +298,7 @@ struct mlx5_cmd {
 	struct mlx5_cmd_debug dbg;
 	struct cmd_msg_cache cache[MLX5_NUM_COMMAND_CACHES];
 	int checksum_disabled;
-	struct mlx5_cmd_stats stats[MLX5_CMD_OP_MAX];
+	struct mlx5_cmd_stats *stats;
 };
 
 struct mlx5_port_caps {

commit 971ae1ed0346658a70f5b411d59f528b94553009
Merge: c223c7f22cb1 6b646a7e4af6
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Fri May 29 14:38:02 2020 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
      net/mlx5: Add ability to read and write ECE options
      net/mlx5: Add support for RDMA TX FT headers modifying
      net/mlx5: Move iseg access helper routines close to mlx5_core driver
      net/mlx5: Cleanup mlx5_ifc_fte_match_set_misc2_bits
      net/mlx5: Add support in forward to namespace
      {IB/net}/mlx5: Simplify don't trap code
      net/mlx5: Replace zero-length array with flexible-array
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 13209a8f7304a34158f4366e8ea07a1965c05ac7
Merge: 316107119f47 98790bbac4db
Author: David S. Miller <davem@davemloft.net>
Date:   Sun May 24 13:47:27 2020 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net
    
    The MSCC bug fix in 'net' had to be slightly adjusted because the
    register accesses are done slightly differently in net-next.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f7936ddd35d8b849daf0372770c7c9dbe7910fca
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Thu Mar 19 21:43:13 2020 +0200

    net/mlx5: Avoid processing commands before cmdif is ready
    
    When driver is reloading during recovery flow, it can't get new commands
    till command interface is up again. Otherwise we may get to null pointer
    trying to access non initialized command structures.
    
    Add cmdif state to avoid processing commands while cmdif is not ready.
    
    Fixes: e126ba97dba9 ("mlx5: Add driver for Mellanox Connect-IB adapters")
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c03778c75dfa..8397b6558dc7 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -213,6 +213,12 @@ enum mlx5_port_status {
 	MLX5_PORT_DOWN      = 2,
 };
 
+enum mlx5_cmdif_state {
+	MLX5_CMDIF_STATE_UNINITIALIZED,
+	MLX5_CMDIF_STATE_UP,
+	MLX5_CMDIF_STATE_DOWN,
+};
+
 struct mlx5_cmd_first {
 	__be32		data[4];
 };
@@ -258,6 +264,7 @@ struct mlx5_cmd_stats {
 struct mlx5_cmd {
 	struct mlx5_nb    nb;
 
+	enum mlx5_cmdif_state	state;
 	void	       *cmd_alloc_buf;
 	dma_addr_t	alloc_dma;
 	int		alloc_size;
@@ -882,6 +889,8 @@ enum {
 
 int mlx5_cmd_init(struct mlx5_core_dev *dev);
 void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
+void mlx5_cmd_set_state(struct mlx5_core_dev *dev,
+			enum mlx5_cmdif_state cmdif_state);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
 void mlx5_cmd_allowed_opcode(struct mlx5_core_dev *dev, u16 opcode);

commit d43b7007dbd1195a5b6b83213e49b1516aaf6f5e
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Wed Mar 18 21:44:32 2020 +0200

    net/mlx5: Fix a race when moving command interface to events mode
    
    After driver creates (via FW command) an EQ for commands, the driver will
    be informed on new commands completion by EQE. However, due to a race in
    driver's internal command mode metadata update, some new commands will
    still be miss-handled by driver as if we are in polling mode. Such commands
    can get two non forced completion, leading to already freed command entry
    access.
    
    CREATE_EQ command, that maps EQ to the command queue must be posted to the
    command queue while it is empty and no other command should be posted.
    
    Add SW mechanism that once the CREATE_EQ command is about to be executed,
    all other commands will return error without being sent to the FW. Allow
    sending other commands only after successfully changing the driver's
    internal command mode metadata.
    We can safely return error to all other commands while creating the command
    EQ, as all other commands might be sent from the user/application during
    driver load. Application can rerun them later after driver's load was
    finished.
    
    Fixes: e126ba97dba9 ("mlx5: Add driver for Mellanox Connect-IB adapters")
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9b1f29f26c27..c03778c75dfa 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -284,6 +284,7 @@ struct mlx5_cmd {
 	struct semaphore sem;
 	struct semaphore pages_sem;
 	int	mode;
+	u16     allowed_opcode;
 	struct mlx5_cmd_work_ent *ent_arr[MLX5_MAX_COMMANDS];
 	struct dma_pool *pool;
 	struct mlx5_cmd_debug dbg;
@@ -875,10 +876,15 @@ mlx5_frag_buf_get_idx_last_contig_stride(struct mlx5_frag_buf_ctrl *fbc, u32 ix)
 	return min_t(u32, last_frag_stride_idx - fbc->strides_offset, fbc->sz_m1);
 }
 
+enum {
+	CMD_ALLOWED_OPCODE_ALL,
+};
+
 int mlx5_cmd_init(struct mlx5_core_dev *dev);
 void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
+void mlx5_cmd_allowed_opcode(struct mlx5_core_dev *dev, u16 opcode);
 
 struct mlx5_async_ctx {
 	struct mlx5_core_dev *dev;

commit 17d00e839d3b592da9659c1977d45f85b77f986a
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Fri Dec 27 07:01:53 2019 +0200

    net/mlx5: Add command entry handling completion
    
    When FW response to commands is very slow and all command entries in
    use are waiting for completion we can have a race where commands can get
    timeout before they get out of the queue and handled. Timeout
    completion on uninitialized command will cause releasing command's
    buffers before accessing it for initialization and then we will get NULL
    pointer exception while trying access it. It may also cause releasing
    buffers of another command since we may have timeout completion before
    even allocating entry index for this command.
    Add entry handling completion to avoid this race.
    
    Fixes: e126ba97dba9 ("mlx5: Add driver for Mellanox Connect-IB adapters")
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6f8f79ef829b..9b1f29f26c27 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -743,6 +743,7 @@ struct mlx5_cmd_work_ent {
 	struct delayed_work	cb_timeout_work;
 	void		       *context;
 	int			idx;
+	struct completion	handling;
 	struct completion	done;
 	struct mlx5_cmd        *cmd;
 	struct work_struct	work;

commit 555af0c3fa0b632be73c241cc932129af4b70d27
Author: Parav Pandit <parav@mellanox.com>
Date:   Fri May 15 15:16:53 2020 -0700

    net/mlx5: Move iseg access helper routines close to mlx5_core driver
    
    Only mlx5_core driver handles fw initialization check and command
    interface revision check.
    Hence move them inside the mlx5_core driver where it is used.
    This avoid exposing these helpers to all mlx5 drivers.
    
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 24e04901f92e..a988eb405aa6 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -823,11 +823,6 @@ static inline u16 fw_rev_sub(struct mlx5_core_dev *dev)
 	return ioread32be(&dev->iseg->cmdif_rev_fw_sub) & 0xffff;
 }
 
-static inline u16 cmdif_rev(struct mlx5_core_dev *dev)
-{
-	return ioread32be(&dev->iseg->cmdif_rev_fw_sub) >> 16;
-}
-
 static inline u32 mlx5_base_mkey(const u32 key)
 {
 	return key & 0xffffff00u;
@@ -1012,11 +1007,6 @@ int mlx5_core_roce_gid_set(struct mlx5_core_dev *dev, unsigned int index,
 			   u8 roce_version, u8 roce_l3_type, const u8 *gid,
 			   const u8 *mac, bool vlan, u16 vlan_id, u8 port_num);
 
-static inline int fw_initializing(struct mlx5_core_dev *dev)
-{
-	return ioread32be(&dev->iseg->initializing) >> 31;
-}
-
 static inline u32 mlx5_mkey_to_idx(u32 mkey)
 {
 	return mkey >> 8;

commit b6ca09cb156d349e6fdde8a8466ec15b902d1419
Author: Gustavo A. R. Silva <gustavoars@kernel.org>
Date:   Thu May 7 13:59:35 2020 -0500

    net/mlx5: Replace zero-length array with flexible-array
    
    The current codebase makes use of the zero-length array language
    extension to the C90 standard, but the preferred mechanism to declare
    variable-length types such as these ones is a flexible array member[1][2],
    introduced in C99:
    
    struct foo {
            int stuff;
            struct boo array[];
    };
    
    By making use of the mechanism above, we will get a compiler warning
    in case the flexible array does not occur last in the structure, which
    will help us prevent some kind of undefined behavior bugs from being
    inadvertently introduced[3] to the codebase from now on.
    
    Also, notice that, dynamic memory allocations won't be affected by
    this change:
    
    "Flexible array members have incomplete type, and so the sizeof operator
    may not be applied. As a quirk of the original implementation of
    zero-length arrays, sizeof evaluates to zero."[1]
    
    sizeof(flexible-array-member) triggers a warning because flexible array
    members have incomplete type[1]. There are some instances of code in
    which the sizeof operator is being incorrectly/erroneously applied to
    zero-length arrays and the result is zero. Such instances may be hiding
    some bugs. So, this work (flexible-array member conversions) will also
    help to get completely rid of those sorts of issues.
    
    This issue was found with the help of Coccinelle.
    
    [1] https://gcc.gnu.org/onlinedocs/gcc/Zero-Length.html
    [2] https://github.com/KSPP/linux/issues/21
    [3] commit 76497732932f ("cxgb3/l2t: Fix undefined behaviour")
    
    Signed-off-by: Gustavo A. R. Silva <gustavoars@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 267dfcc5493e..24e04901f92e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -201,7 +201,7 @@ struct mlx5_rsc_debug {
 	void		       *object;
 	enum dbg_rsc_type	type;
 	struct dentry	       *root;
-	struct mlx5_field_desc	fields[0];
+	struct mlx5_field_desc	fields[];
 };
 
 enum mlx5_dev_event {

commit c6bc6041b10f70b617f2d13894311fe62027d292
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Thu Apr 30 22:21:41 2020 +0300

    net/mlx5: Add support to get lag physical port
    
    Add function to get the device physical port of the lag slave.
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d82dbbab8179..267dfcc5493e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1074,6 +1074,8 @@ bool mlx5_lag_is_sriov(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_multipath(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
 struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
+u8 mlx5_lag_get_slave_port(struct mlx5_core_dev *dev,
+			   struct net_device *slave);
 int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,
 				 u64 *values,
 				 int num_counters,

commit 06939536263d684073a30543930622eede633af1
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Fri Apr 24 12:45:06 2020 -0700

    net/mlx5: Add structure layout and defines for MFRL register
    
    Add needed structure layouts and defines for MFRL (Management Firmware
    Reset Level) register. This structure will be used for the firmware
    upgrade and reset flow in the downstream patches.
    
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b46537a81703..d82dbbab8179 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -130,6 +130,7 @@ enum {
 	MLX5_REG_NODE_DESC	 = 0x6001,
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 	MLX5_REG_MCIA		 = 0x9014,
+	MLX5_REG_MFRL		 = 0x9028,
 	MLX5_REG_MLCR		 = 0x902b,
 	MLX5_REG_MTRC_CAP	 = 0x9040,
 	MLX5_REG_MTRC_CONF	 = 0x9041,

commit dff8e2d15283dd92582ddeec25ca86e4cf2618c7
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Fri Apr 24 12:45:04 2020 -0700

    net/mlx5: Use aligned variable while allocating ICM memory
    
    The alignment value is part of the input structure, so use it and spare
    extra memory allocation when is not needed.
    Now, using the new ability when allocating icm for Direct-Rule
    insertion.
    Signed-off-by: Ariel Levkovich <lariel@mellanox.com>
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b60e5ab7906b..b46537a81703 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1080,7 +1080,8 @@ int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,
 struct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev);
 void mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up);
 int mlx5_dm_sw_icm_alloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,
-			 u64 length, u16 uid, phys_addr_t *addr, u32 *obj_id);
+			 u64 length, u32 log_alignment, u16 uid,
+			 phys_addr_t *addr, u32 *obj_id);
 int mlx5_dm_sw_icm_dealloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,
 			   u64 length, u16 uid, phys_addr_t addr, u32 obj_id);
 

commit 333fbaa0255b8d471fc7ae767ef3a1766c732d6d
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Sat Apr 4 10:40:24 2020 +0300

    net/mlx5: Move QP logic to mlx5_ib
    
    The mlx5_core doesn't need any functionality coded in qp.c, so move
    that file to drivers/infiniband/ be under mlx5_ib responsibility.
    
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1caddfa85c4d..b60e5ab7906b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -541,7 +541,6 @@ struct mlx5_priv {
 	struct mlx5_core_health health;
 
 	/* start: qp staff */
-	struct mlx5_qp_table	qp_table;
 	struct dentry	       *qp_debugfs;
 	struct dentry	       *eq_debugfs;
 	struct dentry	       *cq_debugfs;
@@ -687,7 +686,6 @@ struct mlx5_core_dev {
 	unsigned long		intf_state;
 	struct mlx5_priv	priv;
 	struct mlx5_profile	*profile;
-	atomic_t		num_qps;
 	u32			issi;
 	struct mlx5e_resources  mlx5e_res;
 	struct mlx5_dm          *dm;

commit bb7fc863729b45f0fbcdea991d0465d855ffd831
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Sun Apr 5 20:57:00 2020 +0300

    net/mlx5: Provide simplified command interfaces
    
    Many mlx5_cmd_exec() callers are not interested in the output from that
    command or have standard in/out structures. Those callers simply allocate
    those structure on the stack and use sizeof() to provide in/out arguments.
    
    In this naive approach provide simplified versions of mlx5_cmd_exec().
    
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6f8f79ef829b..1caddfa85c4d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -903,6 +903,19 @@ int mlx5_cmd_exec_cb(struct mlx5_async_ctx *ctx, void *in, int in_size,
 
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 		  int out_size);
+
+#define mlx5_cmd_exec_inout(dev, ifc_cmd, in, out)                             \
+	({                                                                     \
+		mlx5_cmd_exec(dev, in, MLX5_ST_SZ_BYTES(ifc_cmd##_in), out,    \
+			      MLX5_ST_SZ_BYTES(ifc_cmd##_out));                \
+	})
+
+#define mlx5_cmd_exec_in(dev, ifc_cmd, in)                                     \
+	({                                                                     \
+		u32 _out[MLX5_ST_SZ_DW(ifc_cmd##_out)] = {};                   \
+		mlx5_cmd_exec_inout(dev, ifc_cmd, in, _out);                   \
+	})
+
 int mlx5_cmd_exec_polling(struct mlx5_core_dev *dev, void *in, int in_size,
 			  void *out, int out_size);
 void mlx5_cmd_mbox_status(void *out, u8 *status, u32 *syndrome);

commit 919dce24701f7b34681a6a1d3ef95c9f6c4fb1cc
Merge: 50a5de895dbe b4d8ddf8356d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 1 18:18:18 2020 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull rdma updates from Jason Gunthorpe:
     "The majority of the patches are cleanups, refactorings and clarity
      improvements.
    
      This cycle saw some more activity from Syzkaller, I think we are now
      clean on all but one of those bugs, including the long standing and
      obnoxious rdma_cm locking design defect. Continue to see many drivers
      getting cleanups, with a few new user visible features.
    
      Summary:
    
       - Various driver updates for siw, bnxt_re, rxe, efa, mlx5, hfi1
    
       - Lots of cleanup patches for hns
    
       - Convert more places to use refcount
    
       - Aggressively lock the RDMA CM code that syzkaller says isn't
         working
    
       - Work to clarify ib_cm
    
       - Use the new ib_device lifecycle model in bnxt_re
    
       - Fix mlx5's MR cache which seems to be failing more often with the
         new ODP code
    
       - mlx5 'dynamic uar' and 'tx steering' user interfaces"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma: (144 commits)
      RDMA/bnxt_re: make bnxt_re_ib_init static
      IB/qib: Delete struct qib_ivdev.qp_rnd
      RDMA/hns: Fix uninitialized variable bug
      RDMA/hns: Modify the mask of QP number for CQE of hip08
      RDMA/hns: Reduce the maximum number of extend SGE per WQE
      RDMA/hns: Reduce PFC frames in congestion scenarios
      RDMA/mlx5: Add support for RDMA TX flow table
      net/mlx5: Add support for RDMA TX steering
      IB/hfi1: Call kobject_put() when kobject_init_and_add() fails
      IB/hfi1: Fix memory leaks in sysfs registration and unregistration
      IB/mlx5: Move to fully dynamic UAR mode once user space supports it
      IB/mlx5: Limit the scope of struct mlx5_bfreg_info to mlx5_ib
      IB/mlx5: Extend QP creation to get uar page index from user space
      IB/mlx5: Extend CQ creation to get uar page index from user space
      IB/mlx5: Expose UAR object and its alloc/destroy commands
      IB/hfi1: Get rid of a warning
      RDMA/hns: Remove redundant judgment of qp_type
      RDMA/hns: Remove redundant assignment of wc->smac when polling cq
      RDMA/hns: Remove redundant qpc setup operations
      RDMA/hns: Remove meaningless prints
      ...

commit e999a7343da734f24643fcfcfa821e214126480f
Merge: c189b5483c1b 826096d84f50
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Sun Mar 29 23:41:50 2020 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    * 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux:
      mlx5: Remove uninitialized use of key in mlx5_core_create_mkey
      {IB,net}/mlx5: Move asynchronous mkey creation to mlx5_ib
      {IB,net}/mlx5: Assign mkey variant in mlx5_ib only
      {IB,net}/mlx5: Setup mkey variant before mr create command invocation
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 2152862298fbfd237d37c231dfca8ae8f3ed0e48
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Tue Mar 24 08:01:42 2020 +0200

    IB/mlx5: Limit the scope of struct mlx5_bfreg_info to mlx5_ib
    
    struct mlx5_bfreg_info is used by mlx5_ib only but is exposed to both RDMA
    and netdev parts of mlx5 driver. Move that struct to mlx5_ib namespace,
    clean vertical space alignment and convert lib_uar_4k from bool to
    bitfield.
    
    Link: https://lore.kernel.org/r/20200324060143.1569116-5-leon@kernel.org
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1de78f001d26..a30d834fdf7e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -213,23 +213,6 @@ enum mlx5_port_status {
 	MLX5_PORT_DOWN      = 2,
 };
 
-struct mlx5_bfreg_info {
-	u32		       *sys_pages;
-	int			num_low_latency_bfregs;
-	unsigned int	       *count;
-
-	/*
-	 * protect bfreg allocation data structs
-	 */
-	struct mutex		lock;
-	u32			ver;
-	bool			lib_uar_4k;
-	u32			num_sys_pages;
-	u32			num_static_sys_pages;
-	u32			total_num_bfregs;
-	u32			num_dyn_bfregs;
-};
-
 struct mlx5_cmd_first {
 	__be32		data[4];
 };

commit a3cfdd3928113012d0f2c5353277f4e27878a663
Author: Michael Guralnik <michaelgur@mellanox.com>
Date:   Tue Mar 10 10:22:30 2020 +0200

    {IB,net}/mlx5: Move asynchronous mkey creation to mlx5_ib
    
    As mlx5_ib is the only user of the mlx5_core_create_mkey_cb, move the
    logic inside mlx5_ib and cleanup the code in mlx5_core.
    
    Signed-off-by: Michael Guralnik <michaelgur@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index e044703c056b..1de78f001d26 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -943,12 +943,6 @@ struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 						      gfp_t flags, int npages);
 void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 				 struct mlx5_cmd_mailbox *head);
-int mlx5_core_create_mkey_cb(struct mlx5_core_dev *dev,
-			     struct mlx5_core_mkey *mkey,
-			     struct mlx5_async_ctx *async_ctx, u32 *in,
-			     int inlen, u32 *out, int outlen,
-			     mlx5_async_cbk_t callback,
-			     struct mlx5_async_work *context);
 int mlx5_core_create_mkey(struct mlx5_core_dev *dev,
 			  struct mlx5_core_mkey *mkey,
 			  u32 *in, int inlen);

commit fc6a9f86f08acd3665f788619afae0d2b2d5a480
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Mar 10 10:22:28 2020 +0200

    {IB,net}/mlx5: Assign mkey variant in mlx5_ib only
    
    mkey variant is not required for mlx5_core use, move the mkey variant
    counter to mlx5_ib.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index f2b4225ed650..e044703c056b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -575,10 +575,6 @@ struct mlx5_priv {
 	/* end: alloc staff */
 	struct dentry	       *dbg_root;
 
-	/* protect mkey key part */
-	spinlock_t		mkey_lock;
-	u8			mkey_key;
-
 	struct list_head        dev_list;
 	struct list_head        ctx_list;
 	spinlock_t              ctx_lock;

commit a70ed9d8ecf395ca7d15c2d13782cc0055398ed5
Merge: 34a568a244be e0ebd8eb36ed
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Mar 9 13:01:26 2020 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    This series adds some HW bits and definitions for mlx5 driver, to be
    used by downstream features in both rdma and netdev branches.
    
    * 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux:
      net/mlx5: HW bit for goto chain offload support
      net/mlx5: Expose link speed directly
      net/mlx5: Introduce TLS and IPSec objects enums
      net/mlx5: Introduce egress acl forward-to-vport capability
      net/mlx5: Expose raw packet pacing APIs
      net/mlx5e: Replace zero-length array with flexible-array member
      net/mlx5: fix spelling mistake "reserverd" -> "reserved"
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 1326034b3ce7073e3ed74bd0f4d24afee96a9e07
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Wed Feb 19 21:05:17 2020 +0200

    net/mlx5: Expose raw packet pacing APIs
    
    Expose raw packet pacing APIs to be used by DEVX based applications.
    The existing code was refactored to have a single flow with the new raw
    APIs.
    
    The new raw APIs considered the input of 'pp_rate_limit_context', uid,
    'dedicated', upon looking for an existing entry.
    
    This raw mode enables future device specification data in the raw
    context without changing the existing logic and code.
    
    The ability to ask for a dedicated entry gives control for application
    to allocate entries according to its needs.
    
    A dedicated entry may not be used by some other process and it also
    enables the process spreading its resources to some different entries
    for use different hardware resources as part of enforcing the rate.
    
    The counter per entry was changed to be u64 to prevent any option to
    overflow.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Acked-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 277a51d3ec40..f2b4225ed650 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -518,9 +518,11 @@ struct mlx5_rate_limit {
 };
 
 struct mlx5_rl_entry {
-	struct mlx5_rate_limit	rl;
-	u16                     index;
-	u16                     refcount;
+	u8 rl_raw[MLX5_ST_SZ_BYTES(set_pp_rate_limit_context)];
+	u16 index;
+	u64 refcount;
+	u16 uid;
+	u8 dedicated : 1;
 };
 
 struct mlx5_rl_table {
@@ -1007,6 +1009,9 @@ int mlx5_rl_add_rate(struct mlx5_core_dev *dev, u16 *index,
 		     struct mlx5_rate_limit *rl);
 void mlx5_rl_remove_rate(struct mlx5_core_dev *dev, struct mlx5_rate_limit *rl);
 bool mlx5_rl_is_in_range(struct mlx5_core_dev *dev, u32 rate);
+int mlx5_rl_add_rate_raw(struct mlx5_core_dev *dev, void *rl_in, u16 uid,
+			 bool dedicated_entry, u16 *index);
+void mlx5_rl_remove_rate_raw(struct mlx5_core_dev *dev, u16 index);
 bool mlx5_rl_are_equal(struct mlx5_rate_limit *rl_0,
 		       struct mlx5_rate_limit *rl_1);
 int mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,

commit 12206b17235aed1ca6390b3e516825ae276f8345
Author: Aya Levin <ayal@mellanox.com>
Date:   Tue Feb 11 14:32:43 2020 -0800

    net/mlx5: Add support for resource dump
    
    On driver load:
    - Initialize resource dump data structure and memory access tools (mkey
      & pd).
    - Read the resource dump's menu which contains the FW segment
      identifier. Each record is identified by the segment name (ASCII).
    
    During the driver's course of life, users (like reporters) may request
    dumps per segment. The user should create a command providing the
    segment identifier (SW enumeration) and command keys. In return, the
    user receives a command context. In order to receive the dump, the user
    should supply the command context and a memory (aligned to a PAGE) on
    which the dump content will be written. Since the dump may be larger
    than the given memory, the user may resubmit the command until received
    an indication of end-of-dump. It is the user's responsibility to destroy
    the command.
    
    Signed-off-by: Aya Levin <ayal@mellanox.com>
    Reviewed-by: Moshe Shemesh <moshe@mellanox.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 277a51d3ec40..f99cbe249425 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -722,6 +722,7 @@ struct mlx5_core_dev {
 	struct mlx5_clock        clock;
 	struct mlx5_ib_clock_info  *clock_info;
 	struct mlx5_fw_tracer   *tracer;
+	struct mlx5_rsc_dump    *rsc_dump;
 	u32                      vsc_addr;
 	struct mlx5_hv_vhca	*hv_vhca;
 };

commit 8fdd4019bcb2d824c5ab45c6fc340293cfed843f
Merge: 68b62e5d965a 8889f6fa3588
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 31 14:40:36 2020 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull rdma updates from Jason Gunthorpe:
     "A very quiet cycle with few notable changes. Mostly the usual list of
      one or two patches to drivers changing something that isn't quite rc
      worthy. The subsystem seems to be seeing a larger number of rework and
      cleanup style patches right now, I feel that several vendors are
      prepping their drivers for new silicon.
    
      Summary:
    
       - Driver updates and cleanup for qedr, bnxt_re, hns, siw, mlx5, mlx4,
         rxe, i40iw
    
       - Larger series doing cleanup and rework for hns and hfi1.
    
       - Some general reworking of the CM code to make it a little more
         understandable
    
       - Unify the different code paths connected to the uverbs FD scheme
    
       - New UAPI ioctls conversions for get context and get async fd
    
       - Trace points for CQ and CM portions of the RDMA stack
    
       - mlx5 driver support for virtio-net formatted rings as RDMA raw
         ethernet QPs
    
       - verbs support for setting the PCI-E relaxed ordering bit on DMA
         traffic connected to a MR
    
       - A couple of bug fixes that came too late to make rc7"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma: (108 commits)
      RDMA/core: Make the entire API tree static
      RDMA/efa: Mask access flags with the correct optional range
      RDMA/cma: Fix unbalanced cm_id reference count during address resolve
      RDMA/umem: Fix ib_umem_find_best_pgsz()
      IB/mlx4: Fix leak in id_map_find_del
      IB/opa_vnic: Spelling correction of 'erorr' to 'error'
      IB/hfi1: Fix logical condition in msix_request_irq
      RDMA/cm: Remove CM message structs
      RDMA/cm: Use IBA functions for complex structure members
      RDMA/cm: Use IBA functions for simple structure members
      RDMA/cm: Use IBA functions for swapping get/set acessors
      RDMA/cm: Use IBA functions for simple get/set acessors
      RDMA/cm: Add SET/GET implementations to hide IBA wire format
      RDMA/cm: Add accessors for CM_REQ transport_type
      IB/mlx5: Return the administrative GUID if exists
      RDMA/core: Ensure that rdma_user_mmap_entry_remove() is a fence
      IB/mlx4: Fix memory leak in add_gid error flow
      IB/mlx5: Expose RoCE accelerator counters
      RDMA/mlx5: Set relaxed ordering when requested
      RDMA/core: Add the core support field to METHOD_GET_CONTEXT
      ...

commit 4bbd4923d1f5627b0c47a9d7dfb5cc91224cfe0c
Author: Danit Goldberg <danitg@mellanox.com>
Date:   Thu Jan 16 14:00:48 2020 +0200

    IB/mlx5: Return the administrative GUID if exists
    
    A user can change the operational GUID (a.k.a affective GUID) through
    link/infiniband. Therefore it is preferred to return the currently set
    GUID if it exists instead of the operational.
    
    This way the PF can query which VF GUID will be set in the next bind.  In
    order to align with MAC address, zero is returned if administrative GUID
    is not set.
    
    For example, before setting administrative GUID:
     $ ip link show
     ib0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 4092 qdisc mq state UP mode DEFAULT group default qlen 256
     link/infiniband 00:00:00:08:fe:80:00:00:00:00:00:00:52:54:00:c0:fe:12:34:55 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
     vf 0     link/infiniband 00:00:00:08:fe:80:00:00:00:00:00:00:52:54:00:c0:fe:12:34:55 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff,
     spoof checking off, NODE_GUID 00:00:00:00:00:00:00:00, PORT_GUID 00:00:00:00:00:00:00:00, link-state auto, trust off, query_rss off
    
    Then:
    
     $ ip link set ib0 vf 0 node_guid 11:00:af:21:cb:05:11:00
     $ ip link set ib0 vf 0 port_guid 22:11:af:21:cb:05:11:00
    
    After setting administrative GUID:
     $ ip link show
     ib0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 4092 qdisc mq state UP mode DEFAULT group default qlen 256
     link/infiniband 00:00:00:08:fe:80:00:00:00:00:00:00:52:54:00:c0:fe:12:34:55 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
     vf 0     link/infiniband 00:00:00:08:fe:80:00:00:00:00:00:00:52:54:00:c0:fe:12:34:55 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff,
     spoof checking off, NODE_GUID 11:00:af:21:cb:05:11:00, PORT_GUID 22:11:af:21:cb:05:11:00, link-state auto, trust off, query_rss off
    
    Fixes: 9c0015ef0928 ("IB/mlx5: Implement callbacks for getting VFs GUID attributes")
    Link: https://lore.kernel.org/r/20200116120048.12744-1-leon@kernel.org
    Signed-off-by: Danit Goldberg <danitg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 27200dea0297..a24937fc56b9 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -461,6 +461,11 @@ struct mlx5_vf_context {
 	int	enabled;
 	u64	port_guid;
 	u64	node_guid;
+	/* Valid bits are used to validate administrative guid only.
+	 * Enabled after ndo_set_vf_guid
+	 */
+	u8	port_guid_valid:1;
+	u8	node_guid_valid:1;
 	enum port_state_policy	policy;
 };
 

commit 12e9e0d0d97cc4f2aa9a858ac8a5741f321b5287
Merge: 6bc803803526 61dc7b0141c5
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Jan 16 15:46:42 2020 -0800

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/saeed/linux
    
    This merge syncs with mlx5-next latest HW bits and layout updates for next
    features, in addition one patch that improves
    mlx5_create_auto_grouped_flow_table() API across all mlx5 users.
    
    * 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/saeed/linux:
      net/mlx5: Refactor mlx5_create_auto_grouped_flow_table
      net/mlx5e: Add discard counters per priority
      net/mlx5e: Expose FEC feilds and related capability bit
      net/mlx5: Add mlx5_ifc definitions for connection tracking support
      net/mlx5: Add copy header action struct layout
      net/mlx5: Expose resource dump register mapping
      net/mlx5: Add structures and defines for MIRC register
      net/mlx5: Read MCAM register groups 1 and 2
      net/mlx5: Add structures layout for new MCAM access reg groups
      net/mlx5: Expose vDPA emulation device capabilities
      net/mlx5: Add Virtio Emulation related device capabilities
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 609b82727f719b41b50440c4028d48d0b2e04913
Author: Aya Levin <ayal@mellanox.com>
Date:   Mon Nov 4 14:51:55 2019 +0200

    net/mlx5: Expose resource dump register mapping
    
    Add new register enumeration for resource dump. Add layout mapping for
    resource dump: access command and response.
    
    Signed-off-by: Aya Levin <ayal@mellanox.com>
    Reviewed-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7848b9858587..c821fa4d7475 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -146,6 +146,7 @@ enum {
 	MLX5_REG_MCDA		 = 0x9063,
 	MLX5_REG_MCAM		 = 0x907f,
 	MLX5_REG_MIRC		 = 0x9162,
+	MLX5_REG_RESOURCE_DUMP   = 0xC000,
 };
 
 enum mlx5_qpts_trust_state {

commit bab58ba10ecfa39c46d280d2acbca6054e1e863d
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Oct 7 10:30:32 2019 +0300

    net/mlx5: Add structures and defines for MIRC register
    
    Add needed structures, layouts and defines for MIRC (Management Image
    Re-activation Control) register. This structure will be used for the FSM
    reactivation flow in the downstream patches.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 54431256af42..7848b9858587 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -145,6 +145,7 @@ enum {
 	MLX5_REG_MCC		 = 0x9062,
 	MLX5_REG_MCDA		 = 0x9063,
 	MLX5_REG_MCAM		 = 0x907f,
+	MLX5_REG_MIRC		 = 0x9162,
 };
 
 enum mlx5_qpts_trust_state {

commit 932ef155117cc5caf1108bd27664dab974ba6e89
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Oct 7 10:31:42 2019 +0300

    net/mlx5: Read MCAM register groups 1 and 2
    
    On load, Driver caches MCAM (Management Capabilities Mask Register)
    registers. in addition to the only MCAM register group (0) the driver
    already reads, here we add support for reading groups 1 and 2.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 27200dea0297..54431256af42 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -684,7 +684,7 @@ struct mlx5_core_dev {
 		u32 hca_cur[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 		u32 hca_max[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 		u32 pcam[MLX5_ST_SZ_DW(pcam_reg)];
-		u32 mcam[MLX5_ST_SZ_DW(mcam_reg)];
+		u32 mcam[MLX5_MCAM_REGS_NUM][MLX5_ST_SZ_DW(mcam_reg)];
 		u32 fpga[MLX5_ST_SZ_DW(fpga_cap)];
 		u32 qcam[MLX5_ST_SZ_DW(qcam_reg)];
 		u8  embedded_cpu;

commit 8007880a2ca97c34e7ccd1fcf12daf854b792544
Author: Zhu Yanjun <zyjzyj2000@gmail.com>
Date:   Sat Dec 14 10:51:17 2019 +0200

    net/mlx5: limit the function in local scope
    
    The function mlx5_buf_alloc_node is only used by the function in the
    local scope. So it is appropriate to limit this function in the local
    scope.
    
    Signed-off-by: Zhu Yanjun <zyjzyj2000@gmail.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 27200dea0297..59cff380f41a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -928,8 +928,6 @@ void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev, bool disable_health);
 void mlx5_drain_health_wq(struct mlx5_core_dev *dev);
 void mlx5_trigger_health_work(struct mlx5_core_dev *dev);
-int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
-			struct mlx5_frag_buf *buf, int node);
 int mlx5_buf_alloc(struct mlx5_core_dev *dev,
 		   int size, struct mlx5_frag_buf *buf);
 void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_frag_buf *buf);

commit 3694e41e41517994664518ece6265f0bc04a840d
Merge: a25984f3baaa 9c0015ef0928
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Fri Nov 22 16:08:34 2019 -0400

    Merge branch 'ib-guids' into rdma.git for-next
    
    Danit Goldberg says:
    
    ====================
    This series extends RTNETLINK to provide IB port and node GUIDs, which
    were configured for Infiniband VFs.
    
    The functionality to set VF GUIDs already existed for a long time, and
    here we are adding the missing "get" so that netlink will be symmetric and
    various cloud orchestration tools will be able to manage such VFs more
    naturally.
    
    The iproute2 was extended too to present those GUIDs.
    
    - ip link show <device>
    
    For example:
    - ip link set ib4 vf 0 node_guid 22:44:33:00:33:11:00:33
    - ip link set ib4 vf 0 port_guid 10:21:33:12:00:11:22:10
    - ip link show ib4
        ib4: <BROADCAST,MULTICAST> mtu 4092 qdisc noop state DOWN mode DEFAULT group default qlen 256
        link/infiniband 00:00:0a:2d:fe:80:00:00:00:00:00:00:ec:0d:9a:03:00:44:36:8d brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
        vf 0     link/infiniband 00:00:0a:2d:fe:80:00:00:00:00:00:00:ec:0d:9a:03:00:44:36:8d brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff,
        spoof checking off, NODE_GUID 22:44:33:00:33:11:00:33, PORT_GUID 10:21:33:12:00:11:22:10, link-state disable, trust off, query_rss off
    ====================
    
    Based on the mlx5-next branch from
    git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux for
    dependencies
    
    * branch 'ib-guids': (35 commits)
      IB/mlx5: Implement callbacks for getting VFs GUID attributes
      IB/ipoib: Add ndo operation for getting VFs GUID attributes
      IB/core: Add interfaces to get VF node and port GUIDs
      net/core: Add support for getting VF GUIDs
    
      net/mlx5: Add new chain for netfilter flow table offload
      net/mlx5: Refactor creating fast path prio chains
      net/mlx5: Accumulate levels for chains prio namespaces
      net/mlx5: Define fdb tc levels per prio
      net/mlx5: Rename FDB_* tc related defines to FDB_TC_* defines
      net/mlx5: Simplify fdb chain and prio eswitch defines
      IB/mlx5: Load profile according to RoCE enablement state
      IB/mlx5: Rename profile and init methods
      net/mlx5: Handle "enable_roce" devlink param
      net/mlx5: Document flow_steering_mode devlink param
      devlink: Add new "enable_roce" generic device param
      net/mlx5: fix spelling mistake "metdata" -> "metadata"
      net/mlx5: fix kvfree of uninitialized pointer spec
      IB/mlx5: Introduce and use mlx5_core_is_vf()
      net/mlx5: E-switch, Enable metadata on own vport
      net/mlx5: Refactor ingress acl configuration
      ...
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit cc9defcbb8fae52810f7795b039223edae51ef95
Author: Michael Guralnik <michaelgur@mellanox.com>
Date:   Fri Nov 8 23:45:24 2019 +0000

    net/mlx5: Handle "enable_roce" devlink param
    
    Register "enable_roce" param, default value is RoCE enabled.
    Current configuration is stored on mlx5_core_dev and exposed to user
    through the cmode runtime devlink param.
    Changing configuration requires changing the cmode driverinit devlink
    param and calling devlink reload.
    
    Signed-off-by: Michael Guralnik <michaelgur@mellanox.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7b4801e96feb..1884513aac90 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1191,4 +1191,15 @@ enum {
 	MLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,
 };
 
+static inline bool mlx5_is_roce_enabled(struct mlx5_core_dev *dev)
+{
+	struct devlink *devlink = priv_to_devlink(dev);
+	union devlink_param_value val;
+
+	devlink_param_driverinit_value_get(devlink,
+					   DEVLINK_PARAM_GENERIC_ID_ENABLE_ROCE,
+					   &val);
+	return val.vbool;
+}
+
 #endif /* MLX5_DRIVER_H */

commit e53a9d26cf80565cfb7172fc52a0dfac73613a0f
Author: Parav Pandit <parav@mellanox.com>
Date:   Mon Oct 28 23:35:30 2019 +0000

    IB/mlx5: Introduce and use mlx5_core_is_vf()
    
    Instead of deciding a given device is virtual function or
    not based on a device is PF or not, use already defined
    MLX5_COREDEV_VF by introducing an helper API mlx5_core_is_vf().
    
    This enables to clearly identify PF, VF and non virtual functions.
    
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Reviewed-by: Vu Pham <vuhuong@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3e80f03a387f..7b4801e96feb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1121,6 +1121,11 @@ static inline bool mlx5_core_is_pf(const struct mlx5_core_dev *dev)
 	return dev->coredev_type == MLX5_COREDEV_PF;
 }
 
+static inline bool mlx5_core_is_vf(const struct mlx5_core_dev *dev)
+{
+	return dev->coredev_type == MLX5_COREDEV_VF;
+}
+
 static inline bool mlx5_core_is_ecpf(struct mlx5_core_dev *dev)
 {
 	return dev->caps.embedded_cpu;

commit 74bddb3682f60df16ba24be335c94de348ba1b07
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Wed Oct 9 13:09:24 2019 -0300

    RDMA/mlx5: Delete struct mlx5_priv->mkey_table
    
    No users are left, delete it.
    
    Link: https://lore.kernel.org/r/20191009160934.3143-5-jgg@ziepe.ca
    Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3e80f03a387f..8288b62b8f37 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -556,8 +556,6 @@ struct mlx5_priv {
 	struct dentry	       *cmdif_debugfs;
 	/* end: qp staff */
 
-	struct xarray           mkey_table;
-
 	/* start: alloc staff */
 	/* protect buffer alocation according to numa node */
 	struct mutex            alloc_mutex;
@@ -942,8 +940,6 @@ struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 						      gfp_t flags, int npages);
 void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 				 struct mlx5_cmd_mailbox *head);
-void mlx5_init_mkey_table(struct mlx5_core_dev *dev);
-void mlx5_cleanup_mkey_table(struct mlx5_core_dev *dev);
 int mlx5_core_create_mkey_cb(struct mlx5_core_dev *dev,
 			     struct mlx5_core_mkey *mkey,
 			     struct mlx5_async_ctx *async_ctx, u32 *in,

commit a06ebb8d953b4100236f3057be51d67640e06323
Merge: 4bc61b0b1695 fc603294267f
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Sun Sep 1 23:47:09 2019 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Merge mlx5-next patches needed for upcoming mlx5 software steering.
    
    1) Alex adds HW bits and definitions required for SW steering
    2) Ariel moves device memory management to mlx5_core (From mlx5_ib)
    3) Maor, Cleanups and fixups for eswitch mode and RoCE
    4) Mark, Set only stag for match untagged packets
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit c9b9dcb430b3cd0ad2b04c360c4e528d73430481
Author: Ariel Levkovich <lariel@mellanox.com>
Date:   Thu Aug 29 23:42:30 2019 +0000

    net/mlx5: Move device memory management to mlx5_core
    
    Move the device memory allocation and deallocation commands
    SW ICM memory to mlx5_core to expose this API for all
    mlx5_core users.
    
    This comes as preparation for supporting SW steering in kernel
    where it will be required to allocate and register device
    memory for direct rule insertion.
    
    In addition, an API to register this device memory for future
    remote access operations is introduced using the create_mkey
    commands.
    
    Signed-off-by: Ariel Levkovich <lariel@mellanox.com>
    Reviewed-by: Mark Bloch <markb@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0acd28f2e62c..72bc6ce44b55 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -622,6 +622,11 @@ struct mlx5e_resources {
 	struct mlx5_sq_bfreg       bfreg;
 };
 
+enum mlx5_sw_icm_type {
+	MLX5_SW_ICM_TYPE_STEERING,
+	MLX5_SW_ICM_TYPE_HEADER_MODIFY,
+};
+
 #define MLX5_MAX_RESERVED_GIDS 8
 
 struct mlx5_rsvd_gids {
@@ -653,10 +658,14 @@ struct mlx5_clock {
 	struct mlx5_pps            pps_info;
 };
 
+struct mlx5_dm;
 struct mlx5_fw_tracer;
 struct mlx5_vxlan;
 struct mlx5_geneve;
 
+#define MLX5_LOG_SW_ICM_BLOCK_SIZE(dev) (MLX5_CAP_DEV_MEM(dev, log_sw_icm_alloc_granularity))
+#define MLX5_SW_ICM_BLOCK_SIZE(dev) (1 << MLX5_LOG_SW_ICM_BLOCK_SIZE(dev))
+
 struct mlx5_core_dev {
 	struct device *device;
 	enum mlx5_coredev_type coredev_type;
@@ -690,6 +699,7 @@ struct mlx5_core_dev {
 	atomic_t		num_qps;
 	u32			issi;
 	struct mlx5e_resources  mlx5e_res;
+	struct mlx5_dm          *dm;
 	struct mlx5_vxlan       *vxlan;
 	struct mlx5_geneve      *geneve;
 	struct {
@@ -1072,6 +1082,10 @@ int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,
 				 size_t *offsets);
 struct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev);
 void mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up);
+int mlx5_dm_sw_icm_alloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,
+			 u64 length, u16 uid, phys_addr_t *addr, u32 *obj_id);
+int mlx5_dm_sw_icm_dealloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,
+			   u64 length, u16 uid, phys_addr_t addr, u32 obj_id);
 
 #ifdef CONFIG_MLX5_CORE_IPOIB
 struct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,

commit 537f321097d03c21f46c56741cda0dfa6eeffcdd
Merge: 00ebd4998b53 00679b631edd
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Wed Aug 28 11:45:03 2019 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    mlx5 HW spec and bits updates:
    1) Aya exposes IP-in-IP capability in mlx5_core.
    2) Maxim exposes lag tx port affinity capabilities.
    3) Moshe adds VNIC_ENV internal rq counter bits.
    4) ODP capabilities for DC transport
    
    Misc updates:
    5) Saeed, two compiler warnings cleanups
    6) Add XRQ legacy commands opcodes
    7) Use refcount_t for refcount
    8) fix a -Wstringop-truncation warning

commit 87175120defd2907d42592653c35feea9de0437a
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Thu Aug 22 05:05:51 2019 +0000

    net/mlx5: Add HV VHCA infrastructure
    
    HV VHCA is a layer which provides PF to VF communication channel based on
    HyperV PCI config channel. It implements Mellanox's Inter VHCA control
    communication protocol. The protocol contains control block in order to
    pass messages between the PF and VF drivers, and data blocks in order to
    pass actual data.
    
    The infrastructure is agent based. Each agent will be responsible of
    contiguous buffer blocks in the VHCA config space. This infrastructure will
    bind agents to their blocks, and those agents can only access read/write
    the buffer blocks assigned to them. Each agent will provide three
    callbacks (control, invalidate, cleanup). Control will be invoked when
    block-0 is invalidated with a command that concerns this agent. Invalidate
    callback will be invoked if one of the blocks assigned to this agent was
    invalidated. Cleanup will be invoked before the agent is being freed in
    order to clean all of its open resources or deferred works.
    
    Block-0 serves as the control block. All execution commands from the PF
    will be written by the PF over this block. VF will ack on those by
    writing on block-0 as well. Its format is described by struct
    mlx5_hv_vhca_control_block layout.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Haiyang Zhang <haiyangz@microsoft.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index df23f17eed64..13b4cf22f3ab 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -659,6 +659,7 @@ struct mlx5_clock {
 struct mlx5_fw_tracer;
 struct mlx5_vxlan;
 struct mlx5_geneve;
+struct mlx5_hv_vhca;
 
 struct mlx5_core_dev {
 	struct device *device;
@@ -706,6 +707,7 @@ struct mlx5_core_dev {
 	struct mlx5_ib_clock_info  *clock_info;
 	struct mlx5_fw_tracer   *tracer;
 	u32                      vsc_addr;
+	struct mlx5_hv_vhca	*hv_vhca;
 };
 
 struct mlx5_db {

commit 9f818c8a7388ad1a5c60ace50be6f658c058a5f2
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Sat Aug 10 12:17:18 2019 +0200

    mlx5: no need to check return value of debugfs_create functions
    
    When calling debugfs functions, there is no need to ever check the
    return value.  The function can work or not, but the code logic should
    never do something different based on this.
    
    This cleans up a lot of unneeded code and logic around the debugfs
    files, making all of this much simpler and easier to understand as we
    don't need to keep the dentries saved anymore.
    
    Cc: Saeed Mahameed <saeedm@mellanox.com>
    Cc: Leon Romanovsky <leon@kernel.org>
    Cc: netdev@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d8f348ef9c33..df23f17eed64 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -189,7 +189,6 @@ enum mlx5_coredev_type {
 };
 
 struct mlx5_field_desc {
-	struct dentry	       *dent;
 	int			i;
 };
 
@@ -242,11 +241,6 @@ struct mlx5_cmd_msg {
 
 struct mlx5_cmd_debug {
 	struct dentry	       *dbg_root;
-	struct dentry	       *dbg_in;
-	struct dentry	       *dbg_out;
-	struct dentry	       *dbg_outlen;
-	struct dentry	       *dbg_status;
-	struct dentry	       *dbg_run;
 	void		       *in_msg;
 	void		       *out_msg;
 	u8			status;
@@ -271,8 +265,6 @@ struct mlx5_cmd_stats {
 	u64		sum;
 	u64		n;
 	struct dentry  *root;
-	struct dentry  *avg;
-	struct dentry  *count;
 	/* protect command average calculations */
 	spinlock_t	lock;
 };
@@ -972,7 +964,7 @@ int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn,
 int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
 int mlx5_core_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
 
-int mlx5_qp_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_qp_debugfs_init(struct mlx5_core_dev *dev);
 void mlx5_qp_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
 			 int size_in, void *data_out, int size_out,
@@ -984,7 +976,7 @@ int mlx5_db_alloc_node(struct mlx5_core_dev *dev, struct mlx5_db *db,
 void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);
 
 const char *mlx5_command_str(int command);
-int mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev);
 void mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_core_create_psv(struct mlx5_core_dev *dev, u32 pdn,
 			 int npsvs, u32 *sig_index);

commit 94f3e14e00fd43024b1c4d8e0c1e442db9b4d964
Author: Chuhong Yuan <hslester96@gmail.com>
Date:   Tue Aug 6 09:59:50 2019 +0800

    mlx5: Use refcount_t for refcount
    
    Reference counters are preferred to use refcount_t instead of
    atomic_t.
    This is because the implementation of refcount_t can prevent
    overflows and detect possible use-after-free.
    So convert atomic_t ref counters to refcount_t.
    
    Signed-off-by: Chuhong Yuan <hslester96@gmail.com>
    Acked-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 267b2bc0ca4a..0acd28f2e62c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -47,6 +47,7 @@
 #include <linux/interrupt.h>
 #include <linux/idr.h>
 #include <linux/notifier.h>
+#include <linux/refcount.h>
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
@@ -398,7 +399,7 @@ enum mlx5_res_type {
 
 struct mlx5_core_rsc_common {
 	enum mlx5_res_type	res;
-	atomic_t		refcount;
+	refcount_t		refcount;
 	struct completion	free;
 };
 

commit 558101f1b9807b34d8eeefb352d11e642b7e98dd
Author: Gavi Teitz <gavi@mellanox.com>
Date:   Thu Jun 27 20:53:03 2019 +0300

    net/mlx5: Add flow counter pool
    
    Add a pool of flow counters, based on flow counter bulks, removing the
    need to allocate a new counter via a costly FW command during the flow
    creation process. The time it takes to acquire/release a flow counter
    is cut from ~50 [us] to ~50 [ns].
    
    The pool is part of the mlx5 driver instance, and provides flow
    counters for aging flows. mlx5_fc_create() was modified to provide
    counters for aging flows from the pool by default, and
    mlx5_destroy_fc() was modified to release counters back to the pool
    for later reuse. If bulk allocation is not supported or fails, and for
    non-aging flows, the fallback behavior is to allocate and free
    individual counters.
    
    The pool is comprised of three lists of flow counter bulks, one of
    fully used bulks, one of partially used bulks, and one of unused
    bulks. Counters are provided from the partially used bulks first, to
    help limit bulk fragmentation.
    
    The pool maintains a threshold, and strives to maintain the amount of
    available counters below it. The pool is increased in size when a
    counter acquisition request is made and there are no available
    counters, and it is decreased in size when the last counter in a bulk
    is released and there are more available counters than the threshold.
    All pool size changes are done in the context of the
    acquiring/releasing process.
    
    The value of the threshold is directly correlated to the amount of
    used counters the pool is providing, while constrained by a hard
    maximum, and is recalculated every time a bulk is allocated/freed.
    This ensures that the pool only consumes large amounts of memory for
    available counters if the pool is being used heavily. When fully
    populated and at the hard maximum, the buffer of available counters
    consumes ~40 [MB].
    
    Signed-off-by: Gavi Teitz <gavi@mellanox.com>
    Reviewed-by: Vlad Buslov <vladbu@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 267b2bc0ca4a..d8f348ef9c33 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -477,6 +477,17 @@ struct mlx5_core_sriov {
 	u16			max_vfs;
 };
 
+struct mlx5_fc_pool {
+	struct mlx5_core_dev *dev;
+	struct mutex pool_lock; /* protects pool lists */
+	struct list_head fully_used;
+	struct list_head partially_used;
+	struct list_head unused;
+	int available_fcs;
+	int used_fcs;
+	int threshold;
+};
+
 struct mlx5_fc_stats {
 	spinlock_t counters_idr_lock; /* protects counters_idr */
 	struct idr counters_idr;
@@ -489,6 +500,7 @@ struct mlx5_fc_stats {
 	unsigned long next_query;
 	unsigned long sampling_interval; /* jiffies */
 	u32 *bulk_query_out;
+	struct mlx5_fc_pool fc_pool;
 };
 
 struct mlx5_events;

commit 6f06e04b67baa1c9da61c8b15b1335a1dbb98bcb
Author: Gavi Teitz <gavi@mellanox.com>
Date:   Mon Jul 29 21:12:52 2019 +0000

    net/mlx5: Refactor and optimize flow counter bulk query
    
    Towards introducing the ability to allocate bulks of flow counters,
    refactor the flow counter bulk query process, removing functions and
    structs whose names indicated being used for flow counter bulk
    allocation FW commands, despite them actually only being used to
    support bulk querying, and migrate their functionality to correctly
    named functions in their natural location, fs_counters.c.
    
    Additionally, optimize the bulk query process by:
     * Extracting the memory used for the query to mlx5_fc_stats so
       that it is only allocated once, and not for each bulk query.
     * Querying all the counters in one function call.
    
    Signed-off-by: Gavi Teitz <gavi@mellanox.com>
    Reviewed-by: Vlad Buslov <vladbu@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0e6da1840c7d..267b2bc0ca4a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -488,6 +488,7 @@ struct mlx5_fc_stats {
 	struct delayed_work work;
 	unsigned long next_query;
 	unsigned long sampling_interval; /* jiffies */
+	u32 *bulk_query_out;
 };
 
 struct mlx5_events;

commit e08a976a16cafc20931db1d17aed9183202bfa8d
Merge: e2c746944e26 f8efee08dd9d
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Jul 4 16:40:32 2019 -0400

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Misc updates from mlx5-next branch:
    
    1) Add the required HW definitions and structures for upcoming TLS
       support.
    2) Add support for MCQI and MCQS hardware registers for fw version query.
    3) Added hardware bits and structures definitions for sub-functions
    4) Small code cleanup and improvement for PF pci driver.
    5) Bluefield (ECPF) updates and refactoring for better E-Switch
       management on ECPF embedded CPU NIC:
       5.1) Consolidate querying eswitch number of VFs
       5.2) Register event handler at the correct E-Switch init stage
       5.3) Setup PF's inline mode and vlan pop when the ECPF is the
            E-Swtich manager ( the host PF is basically a VF ).
       5.4) Handle Vport UC address changes in switchdev mode.
    
    6) Cleanup the rep and netdev reference when unloading IB rep.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    
    i# All conflicts fixed but you are still merging.

commit 2752b823169b216db142c4466b43269281962dcf
Author: Parav Pandit <parav@mellanox.com>
Date:   Wed May 15 00:04:27 2019 -0500

    net/mlx5: Introduce and use mlx5_eswitch_get_total_vports()
    
    Instead MLX5_TOTAL_VPORTS, use mlx5_eswitch_get_total_vports().
    mlx5_eswitch_get_total_vports() in subsequent patch accounts for SF
    vports as well.
    Expanding MLX5_TOTAL_VPORTS macro would require exposing SF internals to
    more generic vport.h header file. Such exposure is not desired.
    Hence a mlx5_eswitch_get_total_vports() is introduced.
    
    Given that mlx5_eswitch_get_total_vports() API wants to work on const
    mlx5_core_dev*, change its helper functions also to accept const *dev.
    
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 24b02ab206c3..031043341ed5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1085,7 +1085,7 @@ enum {
 	MLX5_PCI_DEV_IS_VF		= 1 << 0,
 };
 
-static inline bool mlx5_core_is_pf(struct mlx5_core_dev *dev)
+static inline bool mlx5_core_is_pf(const struct mlx5_core_dev *dev)
 {
 	return dev->coredev_type == MLX5_COREDEV_PF;
 }
@@ -1095,17 +1095,18 @@ static inline bool mlx5_core_is_ecpf(struct mlx5_core_dev *dev)
 	return dev->caps.embedded_cpu;
 }
 
-static inline bool mlx5_core_is_ecpf_esw_manager(struct mlx5_core_dev *dev)
+static inline bool
+mlx5_core_is_ecpf_esw_manager(const struct mlx5_core_dev *dev)
 {
 	return dev->caps.embedded_cpu && MLX5_CAP_GEN(dev, eswitch_manager);
 }
 
-static inline bool mlx5_ecpf_vport_exists(struct mlx5_core_dev *dev)
+static inline bool mlx5_ecpf_vport_exists(const struct mlx5_core_dev *dev)
 {
 	return mlx5_core_is_pf(dev) && MLX5_CAP_ESW(dev, ecpf_vport_exists);
 }
 
-static inline u16 mlx5_core_max_vfs(struct mlx5_core_dev *dev)
+static inline u16 mlx5_core_max_vfs(const struct mlx5_core_dev *dev)
 {
 	return dev->priv.sriov.max_vfs;
 }

commit c0670781f54839fb9d0b2c0eaee58862601981bf
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Sun Jun 30 19:23:24 2019 +0300

    net/mlx5: Expose the API to register for ANY event
    
    Expose the API to register for ANY event, mlx5_ib will be able to use
    this functionality for its needs.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Acked-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7658a4908431..24b02ab206c3 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1043,6 +1043,8 @@ int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
 int mlx5_notifier_register(struct mlx5_core_dev *dev, struct notifier_block *nb);
 int mlx5_notifier_unregister(struct mlx5_core_dev *dev, struct notifier_block *nb);
+int mlx5_eq_notifier_register(struct mlx5_core_dev *dev, struct mlx5_nb *nb);
+int mlx5_eq_notifier_unregister(struct mlx5_core_dev *dev, struct mlx5_nb *nb);
 
 int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 

commit d886aba677a0a75ad7fdb06e08418b481e09b036
Author: Parav Pandit <parav@mellanox.com>
Date:   Fri Jun 28 22:36:06 2019 +0000

    net/mlx5: Reduce dependency on enabled_vfs counter and num_vfs
    
    While enabling SR-IOV, PCI core already checks that if SR-IOV is already
    enabled, it returns failure error code.
    Hence, remove such duplicate check from mlx5_core driver.
    
    While at it, make mlx5_device_disable_sriov() to perform cleanup of VFs in
    reverse order of mlx5_device_enable_sriov().
    
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 155b8cbe1cc9..7658a4908431 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -468,7 +468,6 @@ struct mlx5_vf_context {
 struct mlx5_core_sriov {
 	struct mlx5_vf_context	*vfs_ctx;
 	int			num_vfs;
-	int			enabled_vfs;
 	u16			max_vfs;
 };
 

commit 386e75af995c3aec475a2185b919bf46af396bfc
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Fri Jun 28 22:35:58 2019 +0000

    net/mlx5: Rename mlx5_pci_dev_type to mlx5_coredev_type
    
    Rename mlx5_pci_dev_type to mlx5_coredev_type to distinguish different mlx5
    device types.
    
    mlx5_coredev_type represents mlx5_core_dev instance type. Hence keep
    mlx5_coredev_type in mlx5_core_dev structure.
    
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Signed-off-by: Vu Pham <vuhuong@mellanox.com>
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2ff624a91e3d..155b8cbe1cc9 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -182,6 +182,11 @@ enum port_state_policy {
 	MLX5_POLICY_INVALID	= 0xffffffff
 };
 
+enum mlx5_coredev_type {
+	MLX5_COREDEV_PF,
+	MLX5_COREDEV_VF
+};
+
 struct mlx5_field_desc {
 	struct dentry	       *dent;
 	int			i;
@@ -567,7 +572,6 @@ struct mlx5_priv {
 	struct mlx5_core_sriov	sriov;
 	struct mlx5_lag		*lag;
 	struct mlx5_devcom	*devcom;
-	unsigned long		pci_dev_data;
 	struct mlx5_core_roce	roce;
 	struct mlx5_fc_stats		fc_stats;
 	struct mlx5_rl_table            rl_table;
@@ -646,6 +650,7 @@ struct mlx5_vxlan;
 
 struct mlx5_core_dev {
 	struct device *device;
+	enum mlx5_coredev_type coredev_type;
 	struct pci_dev	       *pdev;
 	/* sync pci state */
 	struct mutex		pci_status_mutex;
@@ -1079,9 +1084,9 @@ enum {
 	MLX5_PCI_DEV_IS_VF		= 1 << 0,
 };
 
-static inline int mlx5_core_is_pf(struct mlx5_core_dev *dev)
+static inline bool mlx5_core_is_pf(struct mlx5_core_dev *dev)
 {
-	return !(dev->priv.pci_dev_data & MLX5_PCI_DEV_IS_VF);
+	return dev->coredev_type == MLX5_COREDEV_PF;
 }
 
 static inline bool mlx5_core_is_ecpf(struct mlx5_core_dev *dev)

commit a82e0b5bdac29d9719d3ca2df01494a7947351aa
Author: Shay Agroskin <shayag@mellanox.com>
Date:   Fri Jun 28 22:35:50 2019 +0000

    net/mlx5: Added MCQI and MCQS registers' description to ifc
    
    Given a fw component index, the MCQI register allows us to query
    this component's information (e.g. its version and capabilities).
    
    Given a fw component index, the MCQS register allows us to query the
    status of a fw component, including its type and state
    (e.g. PRESET/IN_USE).
    It can be used to find the index of a component of a specific type, by
    sequentially increasing the component index, and querying each time the
    type of the returned component.
    If max component index is reached, 'last_index_flag' is set by the HCA.
    
    These registers' description was added to query the running and pending
    fw version of the HCA.
    
    Signed-off-by: Shay Agroskin <shayag@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 87f77ded78d4..2ff624a91e3d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -138,6 +138,7 @@ enum {
 	MLX5_REG_MTPPS		 = 0x9053,
 	MLX5_REG_MTPPSE		 = 0x9054,
 	MLX5_REG_MPEGC		 = 0x9056,
+	MLX5_REG_MCQS		 = 0x9060,
 	MLX5_REG_MCQI		 = 0x9061,
 	MLX5_REG_MCC		 = 0x9062,
 	MLX5_REG_MCDA		 = 0x9063,

commit 4f5d1beadc10b62e141338570b9c32d857814bb0
Merge: 5cdda5f1d6ad 92ab1eb392c6
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Fri Jun 28 15:49:59 2019 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Misc updates from mlx5-next branch:
    
    1) E-Switch vport metadata support for source vport matching
    2) Convert mkey_table to XArray
    3) Shared IRQs and to use single IRQ for all async EQs
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 792c4e9d0bbb53b34bf1c07c2ef25609d746c57d
Author: Matthew Wilcox <willy@infradead.org>
Date:   Thu Jun 20 07:03:47 2019 +0000

    net/mlx5: Convert mkey_table to XArray
    
    The lock protecting the data structure does not need to be an rwlock.  The
    only read access to the lock is in an error path, and if that's limiting
    your scalability, you have bigger performance problems.
    
    Eliminate mlx5_mkey_table in favour of using the xarray directly.
    reg_mr_callback must use GFP_ATOMIC for allocating XArray nodes as it may
    be called in interrupt context.
    
    This also fixes a minor bug where SRCU locking was being used on the radix
    tree read side, when RCU was needed too.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d8ab633406c2..87f77ded78d4 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -41,7 +41,7 @@
 #include <linux/semaphore.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
-#include <linux/radix-tree.h>
+#include <linux/xarray.h>
 #include <linux/workqueue.h>
 #include <linux/mempool.h>
 #include <linux/interrupt.h>
@@ -452,13 +452,6 @@ struct mlx5_qp_table {
 	struct radix_tree_root	tree;
 };
 
-struct mlx5_mkey_table {
-	/* protect radix tree
-	 */
-	rwlock_t		lock;
-	struct radix_tree_root	tree;
-};
-
 struct mlx5_vf_context {
 	int	enabled;
 	u64	port_guid;
@@ -546,9 +539,7 @@ struct mlx5_priv {
 	struct dentry	       *cmdif_debugfs;
 	/* end: qp staff */
 
-	/* start: mkey staff */
-	struct mlx5_mkey_table	mkey_table;
-	/* end: mkey staff */
+	struct xarray           mkey_table;
 
 	/* start: alloc staff */
 	/* protect buffer alocation according to numa node */

commit b3bd076f7501afea2871bb4738ab53498fd32cd5
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Sun Jan 27 18:38:39 2019 +0200

    net/mlx5: Report devlink health on FW fatal issues
    
    Report devlink health on FW fatal issues via fw_fatal_reporter. The
    driver recover flow for FW fatal error is now being handled by the
    devlink health.
    
    Having the recovery controlled by devlink health, the user has the
    ability to cancel the auto-recovery for debug session and run it
    manually.
    
    Call mlx5_enter_error_state() before calling devlink_health_report() to
    ensure entering device error state even if auto-recovery is off.
    
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index caac96bf9c0d..25847beabd3f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -442,7 +442,7 @@ struct mlx5_core_health {
 	spinlock_t			wq_lock;
 	struct workqueue_struct	       *wq;
 	unsigned long			flags;
-	struct work_struct		work;
+	struct work_struct		fatal_report_work;
 	struct work_struct		report_work;
 	struct delayed_work		recover_work;
 	struct devlink_health_reporter *fw_reporter;

commit 96c82cdfe77b5e769624af71ec0554434037b82f
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Tue Dec 11 16:09:57 2018 +0200

    net/mlx5: Add fw fatal devlink_health_reporter
    
    Create mlx5_devlink_health_reporter for fw fatal reporter.
    The fw fatal reporter is added in addition to the fw reporter and
    implements the recover callback.
    The point of having two reporters for FW issues, is that we
    don't want to run FW recover on any issue, but only fatal ones.
    
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1931a4080d78..caac96bf9c0d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -446,6 +446,7 @@ struct mlx5_core_health {
 	struct work_struct		report_work;
 	struct delayed_work		recover_work;
 	struct devlink_health_reporter *fw_reporter;
+	struct devlink_health_reporter *fw_fatal_reporter;
 };
 
 struct mlx5_qp_table {

commit d1bf0e2cc4a6e66c2bff48176b8b2930098468ef
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Tue Dec 11 16:09:56 2018 +0200

    net/mlx5: Report devlink health on FW issues
    
    Use devlink_health_report() to report any symptom of FW issue as FW
    counter miss or new health syndrome.
    The FW issues detected in mlx5 during poll_health which is called in
    timer atomic context and so health work queue is used to schedule the
    reports.
    
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8d5d065d1aa6..1931a4080d78 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -435,7 +435,7 @@ struct mlx5_core_health {
 	struct timer_list		timer;
 	u32				prev;
 	int				miss_counter;
-	bool				sick;
+	u8				synd;
 	u32				fatal_error;
 	u32				crdump_size;
 	/* wq spinlock to synchronize draining */
@@ -443,6 +443,7 @@ struct mlx5_core_health {
 	struct workqueue_struct	       *wq;
 	unsigned long			flags;
 	struct work_struct		work;
+	struct work_struct		report_work;
 	struct delayed_work		recover_work;
 	struct devlink_health_reporter *fw_reporter;
 };

commit 1e34f3efd413a6318c3edd6e8e7e091f1214b2e6
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Tue Dec 11 16:09:53 2018 +0200

    net/mlx5: Create FW devlink_health_reporter
    
    Create mlx5_devlink_health_reporter for FW reporter. The FW reporter
    implements devlink_health_reporter diagnose callback.
    
    The fw reporter diagnose command can be triggered any time by the user
    to check current fw status.
    In healthy status, it will return clear syndrome. Otherwise it will
    return the syndrome and description of the error type.
    
    Command example and output on healthy status:
    $ devlink health diagnose pci/0000:82:00.0 reporter fw
    Syndrome: 0
    
    Command example and output on non healthy status:
    $ devlink health diagnose pci/0000:82:00.0 reporter fw
    Syndrome: 8 Description: unrecoverable hardware error
    
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 89205b6cc7ef..8d5d065d1aa6 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -53,6 +53,7 @@
 #include <linux/mlx5/eq.h>
 #include <linux/timecounter.h>
 #include <linux/ptp_clock_kernel.h>
+#include <net/devlink.h>
 
 enum {
 	MLX5_BOARD_ID_LEN = 64,
@@ -443,6 +444,7 @@ struct mlx5_core_health {
 	unsigned long			flags;
 	struct work_struct		work;
 	struct delayed_work		recover_work;
+	struct devlink_health_reporter *fw_reporter;
 };
 
 struct mlx5_qp_table {

commit 3e5b72ac2f298423902169db7893fef43365e0a6
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Mon Nov 12 16:40:17 2018 +0200

    net/mlx5: Issue SW reset on FW assert
    
    If a FW assert is considered fatal, indicated by a new bit in the health
    buffer, reset the FW. After the reset go through the normal recovery
    flow. Only one PF needs to issue the reset, so an attempt is made to
    prevent the 2nd function from also issuing the reset.
    It's not an error if that happens, it just slows recovery.
    
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index cc7fd8e62844..89205b6cc7ef 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -583,6 +583,7 @@ struct mlx5_priv {
 };
 
 enum mlx5_device_state {
+	MLX5_DEVICE_STATE_UNINITIALIZED,
 	MLX5_DEVICE_STATE_UP,
 	MLX5_DEVICE_STATE_INTERNAL_ERROR,
 };

commit 63cbc552eebf08818af2025aef4589a48ef849c0
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Mon Nov 12 15:23:02 2018 +0200

    net/mlx5: Handle SW reset of FW in error flow
    
    New mlx5 adapters allow the driver to reset the FW in the event of an
    error, this action called "SW Reset". When an SW reset is issued on any
    PF all PFs enter reset state which is a recoverable condition. The
    existing recovery flow was designed to allow the recovery of a VF after
    a PF driver reload. This patch adds the sw reset to the NIC states
    as a preparation for sw reset handling.
    
    When a software reset is issued the following occurs:
    1. The NIC interface mode is set to 7 while the reset is in progress.
    2. Once the reset completes the NIC interface mode is set to 1.
    
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4ae533b3da07..cc7fd8e62844 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -435,6 +435,7 @@ struct mlx5_core_health {
 	u32				prev;
 	int				miss_counter;
 	bool				sick;
+	u32				fatal_error;
 	u32				crdump_size;
 	/* wq spinlock to synchronize draining */
 	spinlock_t			wq_lock;
@@ -906,7 +907,6 @@ void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev, bool disable_health);
 void mlx5_drain_health_wq(struct mlx5_core_dev *dev);
 void mlx5_trigger_health_work(struct mlx5_core_dev *dev);
-void mlx5_drain_health_recovery(struct mlx5_core_dev *dev);
 int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
 			struct mlx5_frag_buf *buf, int node);
 int mlx5_buf_alloc(struct mlx5_core_dev *dev,

commit 8b9d8baae1de7400f19058020ee8f0f27d436687
Author: Alex Vesker <valex@mellanox.com>
Date:   Tue Jul 17 11:18:26 2018 +0300

    net/mlx5: Add Crdump support
    
    Crdump allows the driver to retrieve a dump of the FW PCI crspace.
    This is useful in case of catastrophic issues which may require FW
    reset. The crspace dump can be used for later debug.
    
    Signed-off-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Reviewed-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index f732445bcbdb..4ae533b3da07 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -435,6 +435,7 @@ struct mlx5_core_health {
 	u32				prev;
 	int				miss_counter;
 	bool				sick;
+	u32				crdump_size;
 	/* wq spinlock to synchronize draining */
 	spinlock_t			wq_lock;
 	struct workqueue_struct	       *wq;

commit b25bbc2f24dcab9cd186ef4003c39bf51ad0454c
Author: Alex Vesker <valex@mellanox.com>
Date:   Thu Jun 28 15:05:58 2018 +0300

    net/mlx5: Add Vendor Specific Capability access gateway
    
    The Vendor Specific Capability (VSC) is used to activate a gateway
    interfacing with the device. The gateway is used to read or write
    device configurations, which are organized in different domains (spaces).
    A configuration access may result in multiple actions, reads, writes.
    
    Example usages are accessing the Crspace domain to read the crspace or
    locking a device semaphore using the Semaphore domain.
    
    The configuration access use pci_cfg_access to prevent parallel access to
    the VSC space by the driver and userspace calls.
    
    Signed-off-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3a810bf043fe..f732445bcbdb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -693,6 +693,7 @@ struct mlx5_core_dev {
 	struct mlx5_clock        clock;
 	struct mlx5_ib_clock_info  *clock_info;
 	struct mlx5_fw_tracer   *tracer;
+	u32                      vsc_addr;
 };
 
 struct mlx5_db {

commit 561aa15ad69e9d1e5a8bb277adb3209bf8091ecb
Author: Yuval Avnery <yuvalav@mellanox.com>
Date:   Mon Jun 10 23:38:27 2019 +0000

    net/mlx5: Separate IRQ data from EQ table data
    
    IRQ table should only exist for mlx5_core_dev for PF and VF only.
    EQ table of mediated devices should hold a pointer to the IRQ table
    of the parent PCI device.
    
    Signed-off-by: Yuval Avnery <yuvalav@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 64155fe201ee..d8ab633406c2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -492,6 +492,7 @@ struct mlx5_eswitch;
 struct mlx5_lag;
 struct mlx5_devcom;
 struct mlx5_eq_table;
+struct mlx5_irq_table;
 
 struct mlx5_rate_limit {
 	u32			rate;
@@ -521,6 +522,8 @@ struct mlx5_core_roce {
 };
 
 struct mlx5_priv {
+	/* IRQ table valid only for real pci devices PF or VF */
+	struct mlx5_irq_table   *irq_table;
 	struct mlx5_eq_table	*eq_table;
 
 	/* pages stuff */

commit 86eec50beaf3a45f6432d491072fa5c54284dbca
Author: Bodong Wang <bodong@mellanox.com>
Date:   Mon Jun 10 23:38:19 2019 +0000

    net/mlx5: Support querying max VFs from device
    
    For ECPF with eswitch manager privilege, query the host max VF count
    by querying the device using query_functions command.
    
    With this enhancement:
    1. flow steering entries are created only for valid vports based on
       the max VF count of the PF.
    2. Driver only queries cap of valid vport.
    
    Eswitch requires the max VFs when doing initialization, so do sr-iov
    init before eswitch init.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b5431f7d97cb..64155fe201ee 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -470,6 +470,7 @@ struct mlx5_core_sriov {
 	struct mlx5_vf_context	*vfs_ctx;
 	int			num_vfs;
 	int			enabled_vfs;
+	u16			max_vfs;
 };
 
 struct mlx5_fc_stats {
@@ -1103,13 +1104,9 @@ static inline bool mlx5_ecpf_vport_exists(struct mlx5_core_dev *dev)
 	return mlx5_core_is_pf(dev) && MLX5_CAP_ESW(dev, ecpf_vport_exists);
 }
 
-#define MLX5_HOST_PF_MAX_VFS	(127u)
 static inline u16 mlx5_core_max_vfs(struct mlx5_core_dev *dev)
 {
-	if (mlx5_core_is_ecpf_esw_manager(dev))
-		return MLX5_HOST_PF_MAX_VFS;
-	else
-		return pci_sriov_get_totalvfs(dev->pdev);
+	return dev->priv.sriov.max_vfs;
 }
 
 static inline int mlx5_get_gid_table_len(u16 param)

commit 0ccc171ea6a2fa34a6b898329c0a447c84e27057
Author: Yevgeny Kliteynik <kliteyn@mellanox.com>
Date:   Wed Jan 30 17:21:55 2019 +0200

    net/mlx5: Geneve, Manage Geneve TLV options
    
    Use Geneve TLV Options object to manage the flex parser matching
    on the 32-bit options data.
    
    When the first flow with a certain class/type values is requested to
    be offloaded, create a FW object with FW command (Geneve TLV Options
    general object) and start counting the number of flows using this object.
    
    During this time, any request with a different class/type values will
    fail to be offloaded.
    Once the refcount reaches 0, destroy the TLV options general object,
    and can now offload a flow with any class/type parameters.
    
    Geneve TLV Options object is added to core device.
    It is currently used to manage Geneve TLV options general
    object allocation in FW and its reference counting only.
    In the future it will also be used for managing geneve ports
    by registering callbacks for ndo_udp_tunnel_add/del.
    
    Reviewed-by: Oz Shlomo <ozsh@mellanox.com>
    Signed-off-by: Yevgeny Kliteynik <kliteyn@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b5431f7d97cb..3a810bf043fe 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -647,6 +647,7 @@ struct mlx5_clock {
 
 struct mlx5_fw_tracer;
 struct mlx5_vxlan;
+struct mlx5_geneve;
 
 struct mlx5_core_dev {
 	struct device *device;
@@ -681,6 +682,7 @@ struct mlx5_core_dev {
 	u32			issi;
 	struct mlx5e_resources  mlx5e_res;
 	struct mlx5_vxlan       *vxlan;
+	struct mlx5_geneve      *geneve;
 	struct {
 		struct mlx5_rsvd_gids	reserved_gids;
 		u32			roce_en;

commit 0b9055a112fd86c07b9d4857b61019485ec6526f
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Wed May 29 22:50:24 2019 +0000

    net/mlx5: Add core dump register access HW bits
    
    Add Firmware core dump registers and HW definitions.
    
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5a27246db883..b5431f7d97cb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -107,6 +107,7 @@ enum {
 	MLX5_REG_FPGA_CAP	 = 0x4022,
 	MLX5_REG_FPGA_CTRL	 = 0x4023,
 	MLX5_REG_FPGA_ACCESS_REG = 0x4024,
+	MLX5_REG_CORE_DUMP	 = 0x402e,
 	MLX5_REG_PCAP		 = 0x5001,
 	MLX5_REG_PMTU		 = 0x5003,
 	MLX5_REG_PTYS		 = 0x5004,

commit dce45af5c2e9e85f22578f2f8065f225f5d11764
Merge: 055128ee008b b79656ed44c6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 9 09:02:46 2019 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull rdma updates from Jason Gunthorpe:
     "This has been a smaller cycle than normal. One new driver was
      accepted, which is unusual, and at least one more driver remains in
      review on the list.
    
      Summary:
    
       - Driver fixes for hns, hfi1, nes, rxe, i40iw, mlx5, cxgb4,
         vmw_pvrdma
    
       - Many patches from MatthewW converting radix tree and IDR users to
         use xarray
    
       - Introduction of tracepoints to the MAD layer
    
       - Build large SGLs at the start for DMA mapping and get the driver to
         split them
    
       - Generally clean SGL handling code throughout the subsystem
    
       - Support for restricting RDMA devices to net namespaces for
         containers
    
       - Progress to remove object allocation boilerplate code from drivers
    
       - Change in how the mlx5 driver shows representor ports linked to VFs
    
       - mlx5 uapi feature to access the on chip SW ICM memory
    
       - Add a new driver for 'EFA'. This is HW that supports user space
         packet processing through QPs in Amazon's cloud"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma: (186 commits)
      RDMA/ipoib: Allow user space differentiate between valid dev_port
      IB/core, ipoib: Do not overreact to SM LID change event
      RDMA/device: Don't fire uevent before device is fully initialized
      lib/scatterlist: Remove leftover from sg_page_iter comment
      RDMA/efa: Add driver to Kconfig/Makefile
      RDMA/efa: Add the efa module
      RDMA/efa: Add EFA verbs implementation
      RDMA/efa: Add common command handlers
      RDMA/efa: Implement functions that submit and complete admin commands
      RDMA/efa: Add the ABI definitions
      RDMA/efa: Add the com service API definitions
      RDMA/efa: Add the efa_com.h file
      RDMA/efa: Add the efa.h header file
      RDMA/efa: Add EFA device definitions
      RDMA: Add EFA related definitions
      RDMA/umem: Remove hugetlb flag
      RDMA/bnxt_re: Use core helpers to get aligned DMA address
      RDMA/i40iw: Use core helpers to get aligned DMA address within a supported page size
      RDMA/verbs: Add a DMA iterator to return aligned contiguous memory blocks
      RDMA/umem: Add API to find best driver supported page size in an MR
      ...

commit c515e70d675421240ff6628a1831a56e4ea0e82c
Merge: 2a369ae00388 91a40a48d52d
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Wed May 1 13:57:17 2019 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    This merge commit includes some misc shared code updates from mlx5-next branch needed
    for net-next.
    
    1) From Aya: Enable general events on all physical link types and
       restrict general event handling of subtype DELAY_DROP_TIMEOUT in mlx5 rdma
       driver to ethernet links only as it was intended.
    
    2) From Eli: Introduce low level bits for prio tag mode
    
    3) From Maor: Low level steering updates to support RDMA RX flow
       steering and enables RoCE loopback traffic when switchdev is enabled.
    
    4) From Vu and Parav: Two small mlx5 core cleanups
    
    5) From Yevgeny add HW definitions of geneve offloads
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 80f09dfc237f181e92968a72d97b7a4202baa453
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Mon Apr 29 18:14:16 2019 +0000

    net/mlx5: Eswitch, enable RoCE loopback traffic
    
    When in switchdev mode, we would like to treat loopback RoCE
    traffic (on eswitch manager) as RDMA and not as regular
    Ethernet traffic
    In order to enable it we add flow steering rule that forward RoCE
    loopback traffic to the HW RoCE filter (by adding allow rule).
    In addition we add RoCE address in GID index 0, which will be
    set in the RoCE loopback packet.
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Reviewed-by: Mark Bloch <markb@mellanox.com>
    Acked-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 582a9680b182..7fa95270dd59 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -512,6 +512,12 @@ struct mlx5_rl_table {
 	struct mlx5_rl_entry   *rl_entry;
 };
 
+struct mlx5_core_roce {
+	struct mlx5_flow_table *ft;
+	struct mlx5_flow_group *fg;
+	struct mlx5_flow_handle *allow_rule;
+};
+
 struct mlx5_priv {
 	struct mlx5_eq_table	*eq_table;
 
@@ -565,6 +571,7 @@ struct mlx5_priv {
 	struct mlx5_lag		*lag;
 	struct mlx5_devcom	*devcom;
 	unsigned long		pci_dev_data;
+	struct mlx5_core_roce	roce;
 	struct mlx5_fc_stats		fc_stats;
 	struct mlx5_rl_table            rl_table;
 

commit 27b942fbbd3107d4e969ece133925cd646239ef4
Author: Parav Pandit <parav@mellanox.com>
Date:   Mon Apr 29 18:14:02 2019 +0000

    net/mlx5: Get rid of storing copy of device name
    
    Currently mlx5 core stores copy of the PCI device name in a
    mlx5_priv structure and uses pr_warn, pr_err helpers.
    
    Get rid of the copy of this name; instead store the parent device
    pointer that contains name as well as dma specific parameters.
    This also allows to use kernel's well defined dev_warn, dev_err, dev_dbg
    device specific print routines.
    
    This is also a preparation patch to access non PCI parent device in
    future.
    
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6c43191c0186..582a9680b182 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -56,7 +56,6 @@
 
 enum {
 	MLX5_BOARD_ID_LEN = 64,
-	MLX5_MAX_NAME_LEN = 16,
 };
 
 enum {
@@ -514,7 +513,6 @@ struct mlx5_rl_table {
 };
 
 struct mlx5_priv {
-	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	*eq_table;
 
 	/* pages stuff */
@@ -641,6 +639,7 @@ struct mlx5_fw_tracer;
 struct mlx5_vxlan;
 
 struct mlx5_core_dev {
+	struct device *device;
 	struct pci_dev	       *pdev;
 	/* sync pci state */
 	struct mutex		pci_status_mutex;

commit 449a224c10a48d047c799c5c5d3b22d6aec98c60
Merge: 3c176c9d7244 4eb6ab13b991
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Wed Apr 24 16:20:34 2019 -0300

    Merge branch 'rdma_mmap' into rdma.git for-next
    
    Jason Gunthorpe says:
    
    ====================
    Upon review it turns out there are some long standing problems in BAR
    mapping area:
     * BAR pages intended for read-only can be switched to writable via mprotect.
     * Missing use of rdma_user_mmap_io for the mlx5 clock BAR page.
     * Disassociate causes SIGBUS when touching the pages.
     * CPU pages are being mapped through to the process via remap_pfn_range
       instead of the more appropriate vm_insert_page, causing weird behaviors
       during disassociation.
    
    This series adds the missing VM_* flag manipulation, adds faulting a zero
    page for disassociation and revises the CPU page mappings to use
    vm_insert_page.
    ====================
    
    For dependencies this branch is based on for-rc from
    git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma.git
    
    * branch 'rdma_mmap':
      RDMA: Remove rdma_user_mmap_page
      RDMA/mlx5: Use get_zeroed_page() for clock_info
      RDMA/ucontext: Fix regression with disassociate
      RDMA/mlx5: Use rdma_user_map_io for mapping BAR pages
      RDMA/mlx5: Do not allow the user to write to the clock page
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit ddcdc368b1033e19fd3a5f750752e10e28a87826
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Tue Apr 16 14:07:29 2019 +0300

    RDMA/mlx5: Use get_zeroed_page() for clock_info
    
    get_zeroed_page() returns a virtual address for the page which is better
    than allocating a struct page and doing a permanent kmap on it.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Reviewed-by: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0d0729648844..9ffc53acaec1 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -681,7 +681,6 @@ struct mlx5_core_dev {
 #endif
 	struct mlx5_clock        clock;
 	struct mlx5_ib_clock_info  *clock_info;
-	struct page             *clock_info_page;
 	struct mlx5_fw_tracer   *tracer;
 };
 

commit c3bdd5e65185f46150b3bac103b3854040487857
Merge: d9cb06759eca 9e98c678c2d6
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Apr 22 15:25:39 2019 -0700

    Merge tag 'v5.1-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux into mlx5-next
    
    Linux 5.1-rc1
    
    We forgot to reset the branch last merge window thus mlx5-next is outdated
    and still based on 5.0-rc2. This merge commit is needed to sync mlx5-next
    branch with 5.1-rc1.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 5331fa0db73d6b27f90a0359a7ede70264491714
Merge: ab7efbe24b28 d9cb06759eca
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Wed Apr 10 14:59:27 2019 -0300

    Merge branch 'mlx5-next' into rdma.git for-next
    
    From
    git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Required for dependencies on the next series
    
    * branch 'mlx5-next':
      net/mlx5: E-Switch, add a new prio to be used by the RDMA side
      net/mlx5: E-Switch, don't use hardcoded values for FDB prios
      net/mlx5: Fix false compilation warning
      net/mlx5: Expose MPEIN (Management PCIE INfo) register layout
      net/mlx5: Add rate limit print macros
      net/mlx5: Add explicit bar address field
      net/mlx5: Replace dev_err/warn/info by mlx5_core_err/warn/info
      net/mlx5: Use dev->priv.name instead of dev_name
      net/mlx5: Make mlx5_core messages independent from mdev->pdev
      net/mlx5: Break load_one into three stages
      net/mlx5: Function setup/teardown procedures
      net/mlx5: Move health and page alloc init to mdev_init
      net/mlx5: Split mdev init and pci init
      net/mlx5: Remove redundant init functions parameter
      net/mlx5: Remove spinlock support from mlx5_write64
      net/mlx5: Remove unused MLX5_*_DOORBELL_LOCK macros
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 8bb309e67f5722b32aa28121c9ad95c10b6801be
Merge: ed514fc5615d 6d7ee2edaa54
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Apr 8 14:31:25 2019 -0700

    Merge tag 'mlx5-updates-2019-04-02' of git://git.kernel.org/pub/scm/linux/kernel/git/saeed/linux
    
    Saeed Mamameed says:
    
    ====================
    mlx5-updates-2019-04-02
    
    This series provides misc updates to mlx5 driver
    
    1) Aya Levin (1): Handle event of power detection in the PCIE slot
    
    2) Eli Britstein (6):
      Some TC VLAN related updates and fixes to the previous VLAN modify action
      support patchset.
      Offload TC e-switch rules with egress/ingress VLAN devices
    
    3) Max Gurtovoy (1): Fix double mutex initialization in esiwtch.c
    
    4) Tariq Toukan (3): Misc small updates
      A write memory barrier is sufficient in EQ ci update
      Obsolete param field holding a constant value
      Unify logic of MTU boundaries
    
    5) Tonghao Zhang (4): Misc updates to en_tc.c
      Make the log friendly when decapsulation offload not supported
      Remove 'parse_attr' argument in parse_tc_fdb_actions()
      Deletes unnecessary setting of esw_attr->parse_attr
      Return -EOPNOTSUPP when attempting to offload an unsupported action
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b6460c72c36df973b4935492bacd90b2bbff7028
Merge: 3eed52842b9f aef6c443fe84
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Apr 2 15:43:45 2019 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    This merge commit includes some misc shared code updates from mlx5-next branch needed
    for net-next.
    
    1) From Maxim, Remove un-used macros and spinlock from mlx5 code.
    
    2) From Aya, Expose Management PCIE info register layout and add rate limit
    print macros.
    
    3) From Tariq, Compilation warning fix in fs_core.c
    
    4) From Vu, Huy and Saeed, Improve mlx5 initialization flow:
    The goal is to provide a better logical separation of mlx5 core
    device initialization flow and will help to seamlessly support
    creating different mlx5 device types such as PF, VF and SF
    mlx5 sub-function virtual devices.
    
    Mlx5_core driver needs to separate HCA resources from pci resources.
    Its initialize/load/unload will be broken into stages:
    1. Initialize common data structures
    2. Setup function which initializes pci resources (for PF/VF)
       or some other specific resources for virtual device
    3. Initialize software objects according to hardware capabilities
    4. Load all mlx5_core components
    
    It is also necessary to detach mlx5_core mdev name/message from pci
    device mdev->pdev name/message for a clearer report/debug of
    different mlx5 device types.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 4039049b5c462d3bb9ee8a68c4375582f037d5f2
Author: Aya Levin <ayal@mellanox.com>
Date:   Fri Mar 29 15:38:03 2019 -0700

    net/mlx5: Expose MPEIN (Management PCIE INfo) register layout
    
    Expose PRM layout for handling MPEIN (Management PCIE Info). It will be
    used in the downstream patch for querying MPEIN via the driver.
    
    Signed-off-by: Aya Levin <ayal@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c0ee597f5457..0bfb95e30e47 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -133,6 +133,7 @@ enum {
 	MLX5_REG_MTRC_CONF	 = 0x9041,
 	MLX5_REG_MTRC_STDB	 = 0x9042,
 	MLX5_REG_MTRC_CTRL	 = 0x9043,
+	MLX5_REG_MPEIN		 = 0x9050,
 	MLX5_REG_MPCNT		 = 0x9051,
 	MLX5_REG_MTPPS		 = 0x9053,
 	MLX5_REG_MTPPSE		 = 0x9054,

commit aa8106f137b93628d531ef5ecbbcbecef99370d7
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Fri Mar 29 15:38:01 2019 -0700

    net/mlx5: Add explicit bar address field
    
    Add bar_addr field to store bar-0 address to avoid calling
    pci_resource_start with hard-coded bar-0 as parameter.
    Also note that different mlx5 device types will have bar_addr
    on different bars.
    
    This patch does not change any functionality.
    
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Signed-off-by: Vu Pham <vuhuong@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d7f5c0e8c47a..c0ee597f5457 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -658,6 +658,7 @@ struct mlx5_core_dev {
 	u64			sys_image_guid;
 	phys_addr_t		iseg_base;
 	struct mlx5_init_seg __iomem *iseg;
+	phys_addr_t             bar_addr;
 	enum mlx5_device_state	state;
 	/* sync interface state */
 	struct mutex		intf_state_mutex;

commit 52c368dc3da7beb7b283133024af1b6d07bf93b9
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Fri Mar 29 15:37:55 2019 -0700

    net/mlx5: Move health and page alloc init to mdev_init
    
    Software structure initialization should be in mdev_init stage.
    
    This provides a better logical separation of mlx5 core device
    initialization flow and will help to seamlessly support creating different
    mlx5 device types such as PF, VF and SF mlx5 sub-function virtual device.
    
    This patch does not change any functionality.
    
    Signed-off-by: Vu Pham <vuhuong@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c5454f985e1d..d7f5c0e8c47a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -883,6 +883,7 @@ void mlx5_cmd_mbox_status(void *out, u8 *status, u32 *syndrome);
 int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);
 int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
 int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
+void mlx5_health_flush(struct mlx5_core_dev *dev);
 void mlx5_health_cleanup(struct mlx5_core_dev *dev);
 int mlx5_health_init(struct mlx5_core_dev *dev);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);

commit 80a2a9026b24c6bd34b8d58256973e22270bedec
Author: Yuval Avnery <yuvalav@mellanox.com>
Date:   Mon Mar 11 06:18:24 2019 +0200

    net/mlx5e: Add a lock on tir list
    
    Refresh tirs is looping over a global list of tirs while netdevs are
    adding and removing tirs from that list. That is why a lock is
    required.
    
    Fixes: 724b2aa15126 ("net/mlx5e: TIRs management refactoring")
    Signed-off-by: Yuval Avnery <yuvalav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 022541dc5dbf..0d0729648844 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -594,6 +594,8 @@ enum mlx5_pagefault_type_flags {
 };
 
 struct mlx5_td {
+	/* protects tirs list changes while tirs refresh */
+	struct mutex     list_lock;
 	struct list_head tirs_list;
 	u32              tdn;
 };

commit a50243b1ddcdd766d0d17fbfeeb1a22e62fdc461
Merge: 2901752c14b8 fca22e7e595f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 9 15:53:03 2019 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull rdma updates from Jason Gunthorpe:
     "This has been a slightly more active cycle than normal with ongoing
      core changes and quite a lot of collected driver updates.
    
       - Various driver fixes for bnxt_re, cxgb4, hns, mlx5, pvrdma, rxe
    
       - A new data transfer mode for HFI1 giving higher performance
    
       - Significant functional and bug fix update to the mlx5
         On-Demand-Paging MR feature
    
       - A chip hang reset recovery system for hns
    
       - Change mm->pinned_vm to an atomic64
    
       - Update bnxt_re to support a new 57500 chip
    
       - A sane netlink 'rdma link add' method for creating rxe devices and
         fixing the various unregistration race conditions in rxe's
         unregister flow
    
       - Allow lookup up objects by an ID over netlink
    
       - Various reworking of the core to driver interface:
           - drivers should not assume umem SGLs are in PAGE_SIZE chunks
           - ucontext is accessed via udata not other means
           - start to make the core code responsible for object memory
             allocation
           - drivers should convert struct device to struct ib_device via a
             helper
           - drivers have more tools to avoid use after unregister problems"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma: (280 commits)
      net/mlx5: ODP support for XRC transport is not enabled by default in FW
      IB/hfi1: Close race condition on user context disable and close
      RDMA/umem: Revert broken 'off by one' fix
      RDMA/umem: minor bug fix in error handling path
      RDMA/hns: Use GFP_ATOMIC in hns_roce_v2_modify_qp
      cxgb4: kfree mhp after the debug print
      IB/rdmavt: Fix concurrency panics in QP post_send and modify to error
      IB/rdmavt: Fix loopback send with invalidate ordering
      IB/iser: Fix dma_nents type definition
      IB/mlx5: Set correct write permissions for implicit ODP MR
      bnxt_re: Clean cq for kernel consumers only
      RDMA/uverbs: Don't do double free of allocated PD
      RDMA: Handle ucontext allocations by IB/core
      RDMA/core: Fix a WARN() message
      bnxt_re: fix the regression due to changes in alloc_pbl
      IB/mlx4: Increase the timeout for CM cache
      IB/core: Abort page fault handler silently during owning process exit
      IB/mlx5: Validate correct PD before prefetch MR
      IB/mlx5: Protect against prefetch of invalid MR
      RDMA/uverbs: Store PR pointer before it is overwritten
      ...

commit 6997b1c9cace95c0e67de620a94ab6ba88d044fe
Author: Roi Dayan <roid@mellanox.com>
Date:   Thu Feb 21 16:29:27 2019 +0200

    net/mlx5: Emit port affinity event for multipath offloads
    
    Under multipath offload scheme, as part of handling fib events, emit
    mlx5 port affinity event on the enabled ports which will be handled by
    the tc offloads code.
    
    Signed-off-by: Roi Dayan <roid@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ee109b3fbfb8..5ffb5df1a2c2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -195,6 +195,7 @@ struct mlx5_rsc_debug {
 
 enum mlx5_dev_event {
 	MLX5_DEV_EVENT_SYS_ERROR = 128, /* 0 - 127 are FW events */
+	MLX5_DEV_EVENT_PORT_AFFINITY = 129,
 };
 
 enum mlx5_port_status {

commit 724b509ca02367dbd5f5f90b0c8546280c5abc72
Author: Roi Dayan <roid@mellanox.com>
Date:   Thu Feb 21 18:24:48 2019 +0200

    net/mlx5: Add multipath mode
    
    In order to offload ecmp-on-host scheme where next-hop routes are used,
    we will make use of HW LAG. Add accessor function to let upper layers
    in the driver to realize if the lag acts in multi-path mode.
    
    Signed-off-by: Roi Dayan <roid@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c2de50f02b33..ee109b3fbfb8 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1041,6 +1041,7 @@ int mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);
 int mlx5_cmd_destroy_vport_lag(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_roce(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_sriov(struct mlx5_core_dev *dev);
+bool mlx5_lag_is_multipath(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
 struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
 int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,

commit 815f7480373e2993e0d6b0ee53b62fc7d28af6f5
Merge: ec95e0fa2162 37b6bb77c6fd
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Thu Feb 21 12:40:18 2019 -0700

    Merge branch 'mlx5-next' into rdma.git for-next
    
    From
    git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    To resolve conflicts with net-next and pick up the first patch.
    
    * branch 'mlx5-next':
      net/mlx5: Factor out HCA capabilities functions
      IB/mlx5: Add support for 50Gbps per lane link modes
      net/mlx5: Add support to ext_* fields introduced in Port Type and Speed register
      net/mlx5: Add new fields to Port Type and Speed register
      net/mlx5: Refactor queries to speed fields in Port Type and Speed register
      net/mlx5: E-Switch, Avoid magic numbers when initializing offloads mode
      net/mlx5: Relocate vport macros to the vport header file
      net/mlx5: E-Switch, Normalize the name of uplink vport number
      net/mlx5: Provide an alternative VF upper bound for ECPF
      net/mlx5: Add host params change event
      net/mlx5: Add query host params command
      net/mlx5: Update enable HCA dependency
      net/mlx5: Introduce Mellanox SmartNIC and modify page management logic
      IB/mlx5: Use unified register/load function for uplink and VF vports
      net/mlx5: Use consistent vport num argument type
      net/mlx5: Use void pointer as the type in address_of macro
      net/mlx5: Align ODP capability function with netdev coding style
      mlx5: use RCU lock in mlx5_eq_cq_get()
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 81cd229c294e2e416e9161d9286d34f3aaf19348
Author: Bodong Wang <bodong@mellanox.com>
Date:   Mon Dec 10 11:59:33 2018 -0600

    net/mlx5: E-Switch, Consider ECPF vport depends on eswitch ownership
    
    ECPF connects to the eswitch through vport 0xfffe. ECPF may or may
    not be the eswitch manager depending on firmware configuration.
    
    1. If ECPF is eswitch manager: ECPF will take over the eswitch manager
       responsibility. A rep of the host PF shall be created at the ECPF
       side for the eswitch manager to control.
    
    2. If ECPF is not eswitch manager: host PF will be the eswitch manager,
       ECPF acts similar as a VF to the host PF. Host PF will be aware
       of the ECPF vport presence and control it's rep.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c5454f985e1d..c2de50f02b33 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1088,6 +1088,11 @@ static inline bool mlx5_core_is_ecpf_esw_manager(struct mlx5_core_dev *dev)
 	return dev->caps.embedded_cpu && MLX5_CAP_GEN(dev, eswitch_manager);
 }
 
+static inline bool mlx5_ecpf_vport_exists(struct mlx5_core_dev *dev)
+{
+	return mlx5_core_is_pf(dev) && MLX5_CAP_ESW(dev, ecpf_vport_exists);
+}
+
 #define MLX5_HOST_PF_MAX_VFS	(127u)
 static inline u16 mlx5_core_max_vfs(struct mlx5_core_dev *dev)
 {

commit bf3e4d387daed36aad2cfd4f493b07714ac0cd5e
Author: Bodong Wang <bodong@mellanox.com>
Date:   Tue Feb 12 22:55:41 2019 -0800

    net/mlx5: Relocate vport macros to the vport header file
    
    These are two macros in the driver general header which deal with the
    number of total vports and if a vport is vport manager. Such macros
    are vport entities, better to place them at the vport header file.
    
    This patch doesn't change any functionality.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 46e0aa52a58a..c5454f985e1d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1097,12 +1097,6 @@ static inline u16 mlx5_core_max_vfs(struct mlx5_core_dev *dev)
 		return pci_sriov_get_totalvfs(dev->pdev);
 }
 
-#define MLX5_TOTAL_VPORTS(mdev) (1 + mlx5_core_max_vfs(mdev))
-#define MLX5_VPORT_MANAGER(mdev) \
-	(MLX5_CAP_GEN(mdev, vport_group_manager) && \
-	 (MLX5_CAP_GEN(mdev, port_type) == MLX5_CAP_PORT_TYPE_ETH) && \
-	 mlx5_core_is_pf(mdev))
-
 static inline int mlx5_get_gid_table_len(u16 param)
 {
 	if (param > 4) {

commit feb393693316bd5de2c88a020f6ded51e3a4120b
Author: Bodong Wang <bodong@mellanox.com>
Date:   Tue Feb 12 22:55:39 2019 -0800

    net/mlx5: Provide an alternative VF upper bound for ECPF
    
    ECPF doesn't support SR-IOV, but an ECPF E-Switch manager shall know
    the max VFs supported by its peer host PF in order to control those
    VF vports.
    
    The current driver implementation uses the total vfs quantity as
    provided by the pci sub-system for an upper bound of the VF vports
    the e-switch code needs to deal with. This obviously can't work as
    is on ECPF e-switch manager. For now, we use a hard coded value of
    128 on such systems.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 151563a12fc2..46e0aa52a58a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1088,7 +1088,16 @@ static inline bool mlx5_core_is_ecpf_esw_manager(struct mlx5_core_dev *dev)
 	return dev->caps.embedded_cpu && MLX5_CAP_GEN(dev, eswitch_manager);
 }
 
-#define MLX5_TOTAL_VPORTS(mdev) (1 + pci_sriov_get_totalvfs((mdev)->pdev))
+#define MLX5_HOST_PF_MAX_VFS	(127u)
+static inline u16 mlx5_core_max_vfs(struct mlx5_core_dev *dev)
+{
+	if (mlx5_core_is_ecpf_esw_manager(dev))
+		return MLX5_HOST_PF_MAX_VFS;
+	else
+		return pci_sriov_get_totalvfs(dev->pdev);
+}
+
+#define MLX5_TOTAL_VPORTS(mdev) (1 + mlx5_core_max_vfs(mdev))
 #define MLX5_VPORT_MANAGER(mdev) \
 	(MLX5_CAP_GEN(mdev, vport_group_manager) && \
 	 (MLX5_CAP_GEN(mdev, port_type) == MLX5_CAP_PORT_TYPE_ETH) && \

commit 7f0d11c7e0d08304de55b6a571a69166f3d54160
Author: Bodong Wang <bodong@mellanox.com>
Date:   Tue Feb 12 22:55:38 2019 -0800

    net/mlx5: Add host params change event
    
    In Embedded CPU (EC) configurations, the EC driver needs to know when
    the number of virtual functions change on the corresponding PF at the
    host side. This is required so the EC driver can create or destroy
    representor net devices that represent the VFs ports.
    
    Whenever a change in the number of VFs occurs, firmware will generate an
    event towards the EC which will trigger a work to complete the rest of
    the handling. The specifics of the handling will be introduced in a
    downstream patch.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index cce4e8293384..151563a12fc2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1083,6 +1083,11 @@ static inline bool mlx5_core_is_ecpf(struct mlx5_core_dev *dev)
 	return dev->caps.embedded_cpu;
 }
 
+static inline bool mlx5_core_is_ecpf_esw_manager(struct mlx5_core_dev *dev)
+{
+	return dev->caps.embedded_cpu && MLX5_CAP_GEN(dev, eswitch_manager);
+}
+
 #define MLX5_TOTAL_VPORTS(mdev) (1 + pci_sriov_get_totalvfs((mdev)->pdev))
 #define MLX5_VPORT_MANAGER(mdev) \
 	(MLX5_CAP_GEN(mdev, vport_group_manager) && \

commit 591905ba96796e3b677b14fa79f27127bfaab4ab
Author: Bodong Wang <bodong@mellanox.com>
Date:   Tue Feb 12 22:55:35 2019 -0800

    net/mlx5: Introduce Mellanox SmartNIC and modify page management logic
    
    Mellanox's SmartNIC combines embedded CPU(e.g, ARM) processing power
    with advanced network offloads to accelerate a multitude of security,
    networking and storage applications.
    
    With the introduction of the SmartNIC, there is a new PCI function
    called Embedded CPU Physical Function(ECPF). And it's possible for a
    PF to get its ICM pages from the ECPF PCI function. Driver shall
    identify if it is running on such a function by reading a bit in
    the initialization segment.
    
    When firmware asks for pages, it would issue a page request event
    specifying how many pages it requests and for which function. That
    driver responds with a manage_pages command providing the requested
    pages along with an indication for which function it is providing these
    pages.
    
    The encoding before this patch was as follows:
        function_id == 0: pages are requested for the function receiving
                          the EQE.
        function_id != 0: pages are requested for VF identified by the
                          function_id value
    
    A new one bit field in the EQE identifies that pages are requested for
    the ECPF.
    
    The notion of page_supplier can be introduced here and to support that,
    manage pages and query pages were modified so firmware can distinguish
    the following cases:
    
    1. Function provides pages for itself
    2. PF provides pages for its VF
    3. ECPF provides pages to itself
    4. ECPF provides pages for another function
    
    This distinction is possible through the introduction of the bit
    "embedded_cpu_function" in query_pages, manage_pages and page request
    EQE.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 039c9398614c..cce4e8293384 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -522,6 +522,7 @@ struct mlx5_priv {
 	atomic_t		reg_pages;
 	struct list_head	free_list;
 	int			vfs_pages;
+	int			peer_pf_pages;
 
 	struct mlx5_core_health health;
 
@@ -652,6 +653,7 @@ struct mlx5_core_dev {
 		u32 mcam[MLX5_ST_SZ_DW(mcam_reg)];
 		u32 fpga[MLX5_ST_SZ_DW(fpga_cap)];
 		u32 qcam[MLX5_ST_SZ_DW(qcam_reg)];
+		u8  embedded_cpu;
 	} caps;
 	u64			sys_image_guid;
 	phys_addr_t		iseg_base;
@@ -922,7 +924,7 @@ void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_start(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
 void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
-				 s32 npages);
+				 s32 npages, bool ec_function);
 int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);
 int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);
 void mlx5_register_debugfs(void);
@@ -1076,6 +1078,11 @@ static inline int mlx5_core_is_pf(struct mlx5_core_dev *dev)
 	return !(dev->priv.pci_dev_data & MLX5_PCI_DEV_IS_VF);
 }
 
+static inline bool mlx5_core_is_ecpf(struct mlx5_core_dev *dev)
+{
+	return dev->caps.embedded_cpu;
+}
+
 #define MLX5_TOTAL_VPORTS(mdev) (1 + pci_sriov_get_totalvfs((mdev)->pdev))
 #define MLX5_VPORT_MANAGER(mdev) \
 	(MLX5_CAP_GEN(mdev, vport_group_manager) && \

commit 55c293c38efa4408920e3ff8135a85a0dc2e3f56
Merge: b360ce3b2be9 eaebaf77e7cb
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Tue Jan 29 13:49:31 2019 -0700

    Merge branch 'devx-async' into k.o/for-next
    
    Yishai Hadas says:
    
    Enable DEVX asynchronous query commands
    
    This series enables querying a DEVX object in an asynchronous mode.
    
    The userspace application won't block when calling the firmware and it will be
    able to get the response back once that it will be ready.
    
    To enable the above functionality:
    
    - DEVX asynchronous command completion FD object was introduced.
    - The applicable file operations were implemented to enable using it by
      the user application.
    - Query asynchronous method was added to the DEVX object, it will call the
      firmware asynchronously and manages the response on the given input FD.
    - Hot unplug support was added for the FD to work properly upon
      unbind/disassociate.
    - mlx5 core fence for asynchronous commands was implemented and used to
      prevent racing upon unbind/disassociate.
    
    This branch is based on mlx5-next & v5.0-rc2 due to dependencies, from
    git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    * branch 'devx-async':
      IB/mlx5: Implement DEVX hot unplug for async command FD
      IB/mlx5: Implement the file ops of DEVX async command FD
      IB/mlx5: Introduce async DEVX obj query API
      IB/mlx5: Introduce MLX5_IB_OBJECT_DEVX_ASYNC_CMD_FD
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit e355477ed9e4f401e3931043df97325d38552d54
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Fri Jan 18 16:33:10 2019 -0800

    net/mlx5: Make mlx5_cmd_exec_cb() a safe API
    
    APIs that have deferred callbacks should have some kind of cleanup
    function that callers can use to fence the callbacks. Otherwise things
    like module unloading can lead to dangling function pointers, or worse.
    
    The IB MR code is the only place that calls this function and had a
    really poor attempt at creating this fence. Provide a good version in
    the core code as future patches will add more places that need this
    fence.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4e444863054a..039c9398614c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -850,11 +850,30 @@ void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
 
+struct mlx5_async_ctx {
+	struct mlx5_core_dev *dev;
+	atomic_t num_inflight;
+	struct wait_queue_head wait;
+};
+
+struct mlx5_async_work;
+
+typedef void (*mlx5_async_cbk_t)(int status, struct mlx5_async_work *context);
+
+struct mlx5_async_work {
+	struct mlx5_async_ctx *ctx;
+	mlx5_async_cbk_t user_callback;
+};
+
+void mlx5_cmd_init_async_ctx(struct mlx5_core_dev *dev,
+			     struct mlx5_async_ctx *ctx);
+void mlx5_cmd_cleanup_async_ctx(struct mlx5_async_ctx *ctx);
+int mlx5_cmd_exec_cb(struct mlx5_async_ctx *ctx, void *in, int in_size,
+		     void *out, int out_size, mlx5_async_cbk_t callback,
+		     struct mlx5_async_work *work);
+
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 		  int out_size);
-int mlx5_cmd_exec_cb(struct mlx5_core_dev *dev, void *in, int in_size,
-		     void *out, int out_size, mlx5_cmd_cbk_t callback,
-		     void *context);
 int mlx5_cmd_exec_polling(struct mlx5_core_dev *dev, void *in, int in_size,
 			  void *out, int out_size);
 void mlx5_cmd_mbox_status(void *out, u8 *status, u32 *syndrome);
@@ -885,9 +904,10 @@ void mlx5_init_mkey_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_mkey_table(struct mlx5_core_dev *dev);
 int mlx5_core_create_mkey_cb(struct mlx5_core_dev *dev,
 			     struct mlx5_core_mkey *mkey,
-			     u32 *in, int inlen,
-			     u32 *out, int outlen,
-			     mlx5_cmd_cbk_t callback, void *context);
+			     struct mlx5_async_ctx *async_ctx, u32 *in,
+			     int inlen, u32 *out, int outlen,
+			     mlx5_async_cbk_t callback,
+			     struct mlx5_async_work *context);
 int mlx5_core_create_mkey(struct mlx5_core_dev *dev,
 			  struct mlx5_core_mkey *mkey,
 			  u32 *in, int inlen);

commit 534fd7aac56a7994d16032f32123def9923e339f
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Sun Jan 13 16:01:17 2019 +0200

    IB/mlx5: Manage indirection mkey upon DEVX flow for ODP
    
    Manage indirection mkey upon DEVX flow to support ODP.
    
    To support a page fault event on the indirection mkey it needs to be part
    of the device mkey radix tree.
    
    Both the creation and the deletion flows for a DEVX object which is
    indirection mkey were adapted to handle that.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b6f5839f129a..619d6fee96a1 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -364,6 +364,7 @@ struct mlx5_core_sig_ctx {
 enum {
 	MLX5_MKEY_MR = 1,
 	MLX5_MKEY_MW,
+	MLX5_MKEY_INDIRECT_DEVX,
 };
 
 struct mlx5_core_mkey {

commit 73f5a82bb3c9fce550da4a74a32b8cb064b50663
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Sun Jan 13 15:57:04 2019 +0200

    RDMA/mad: Reduce MAD scope to mlx5_ib only
    
    Management Datagram Interface (MAD) is applicable
    only when physical port is Infiniband. It makes MAD
    command logic to be completely unrelated to eth/core
    parts of mlx5.
    
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Acked-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 54299251d40d..4e444863054a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -897,8 +897,6 @@ int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mkey *mkey,
 			 u32 *out, int outlen);
 int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
 int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
-int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, const void *inb, void *outb,
-		      u16 opmod, u8 port);
 int mlx5_pagealloc_init(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_start(struct mlx5_core_dev *dev);

commit 0ada768517dafa1504ef5986ba04f118b7436960
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Tue Jan 8 16:07:27 2019 +0200

    RDMA/mlx5: Delete declaration of already removed function
    
    The implementation of mlx5_core_page_fault_resume() was removed in commit
    d5d284b829a6 ("{net,IB}/mlx5: Move Page fault EQ and ODP logic to
    RDMA"). This patch removes declaration too.
    
    Fixes: d5d284b829a6 ("{net,IB}/mlx5: Move Page fault EQ and ODP logic to RDMA")
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 54299251d40d..b6f5839f129a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -939,10 +939,6 @@ int mlx5_query_odp_caps(struct mlx5_core_dev *dev,
 			struct mlx5_odp_caps *odp_caps);
 int mlx5_core_query_ib_ppcnt(struct mlx5_core_dev *dev,
 			     u8 port_num, void *out, size_t sz);
-#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
-int mlx5_core_page_fault_resume(struct mlx5_core_dev *dev, u32 token,
-				u32 wq_num, u8 type, int error);
-#endif
 
 int mlx5_init_rl_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_rl_table(struct mlx5_core_dev *dev);

commit 5d24ae67a961c51beb255a28c9c417d9710247c2
Merge: 938edb8a31b9 f617e5ffe04f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 28 14:57:10 2018 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull rdma updates from Jason Gunthorpe:
     "This has been a fairly typical cycle, with the usual sorts of driver
      updates. Several series continue to come through which improve and
      modernize various parts of the core code, and we finally are starting
      to get the uAPI command interface cleaned up.
    
       - Various driver fixes for bnxt_re, cxgb3/4, hfi1, hns, i40iw, mlx4,
         mlx5, qib, rxe, usnic
    
       - Rework the entire syscall flow for uverbs to be able to run over
         ioctl(). Finally getting past the historic bad choice to use
         write() for command execution
    
       - More functional coverage with the mlx5 'devx' user API
    
       - Start of the HFI1 series for 'TID RDMA'
    
       - SRQ support in the hns driver
    
       - Support for new IBTA defined 2x lane widths
    
       - A big series to consolidate all the driver function pointers into a
         big struct and have drivers provide a 'static const' version of the
         struct instead of open coding initialization
    
       - New 'advise_mr' uAPI to control device caching/loading of page
         tables
    
       - Support for inline data in SRPT
    
       - Modernize how umad uses the driver core and creates cdev's and
         sysfs files
    
       - First steps toward removing 'uobject' from the view of the drivers"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma: (193 commits)
      RDMA/srpt: Use kmem_cache_free() instead of kfree()
      RDMA/mlx5: Signedness bug in UVERBS_HANDLER()
      IB/uverbs: Signedness bug in UVERBS_HANDLER()
      IB/mlx5: Allocate the per-port Q counter shared when DEVX is supported
      IB/umad: Start using dev_groups of class
      IB/umad: Use class_groups and let core create class file
      IB/umad: Refactor code to use cdev_device_add()
      IB/umad: Avoid destroying device while it is accessed
      IB/umad: Simplify and avoid dynamic allocation of class
      IB/mlx5: Fix wrong error unwind
      IB/mlx4: Remove set but not used variable 'pd'
      RDMA/iwcm: Don't copy past the end of dev_name() string
      IB/mlx5: Fix long EEH recover time with NVMe offloads
      IB/mlx5: Simplify netdev unbinding
      IB/core: Move query port to ioctl
      RDMA/nldev: Expose port_cap_flags2
      IB/core: uverbs copy to struct or zero helper
      IB/rxe: Reuse code which sets port state
      IB/rxe: Make counters thread safe
      IB/mlx5: Use the correct commands for UMEM and UCTX allocation
      ...

commit ed50edfb72352c4bee489b5b27418a30177cf38f
Merge: bd1c24ccf9eb 71bef2fd583b
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Thu Dec 20 13:24:50 2018 -0700

    Merge branch 'mlx5-next' into rdma.git
    
    From git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    mlx5 updates taken for dependencies on following patches.
    
    * branche 'mlx5-next': (23 commits)
      IB/mlx5: Introduce uid as part of alloc/dealloc transport domain
      net/mlx5: Add shared Q counter bits
      net/mlx5: Continue driver initialization despite debugfs failure
      net/mlx5: Fold the modify lag code into function
      net/mlx5: Add lag affinity info to log
      net/mlx5: Split the activate lag function into two routines
      net/mlx5: E-Switch, Introduce flow counter affinity
      IB/mlx5: Unify e-switch representors load approach between uplink and VFs
      net/mlx5: Use lowercase 'X' for hex values
      net/mlx5: Remove duplicated include from eswitch.c
      net/mlx5: Remove the get protocol device interface entry
      net/mlx5: Support extended destination format in flow steering command
      net/mlx5: E-Switch, Change vhca id valid bool field to bit flag
      net/mlx5: Introduce extended destination fields
      net/mlx5: Revise gre and nvgre key formats
      net/mlx5: Add monitor commands layout and event data
      net/mlx5: Add support for plugged-disabled cable status in PME
      net/mlx5: Add support for PCIe power slot exceeded error in PME
      net/mlx5: Rework handling of port module events
      net/mlx5: Move flow counters data structures from flow steering header
      ...

commit 7c34ec19e10c0d13ca2f3435fb85d2dddccad917
Author: Aviv Heller <avivh@mellanox.com>
Date:   Thu Aug 23 13:47:53 2018 +0300

    net/mlx5: Make RoCE and SR-IOV LAG modes explicit
    
    With the introduction of SR-IOV LAG, checking whether LAG is active
    is no longer good enough, since RoCE and SR-IOV LAG each entails
    different behavior by both the core and infiniband drivers.
    
    This patch introduces facilities to discern LAG type, in addition to
    mlx5_lag_is_active(). These are implemented in such a way as to allow
    more complex mode combinations in the future.
    
    Signed-off-by: Aviv Heller <avivh@mellanox.com>
    Reviewed-by: Roi Dayan <roid@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index cd7af5d0311b..4d16ba04790e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1019,6 +1019,8 @@ int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 
 int mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);
 int mlx5_cmd_destroy_vport_lag(struct mlx5_core_dev *dev);
+bool mlx5_lag_is_roce(struct mlx5_core_dev *dev);
+bool mlx5_lag_is_sriov(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
 struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
 int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,

commit fadd59fc50d010145f251db583c7ccef37393d19
Author: Aviv Heller <avivh@mellanox.com>
Date:   Tue Dec 4 21:24:46 2018 +0200

    net/mlx5: Introduce inter-device communication mechanism
    
    This introduces devcom, a generic mechanism for performing operations
    on both physical functions of the same Connect-X card.
    
    The first user of this API is merged eswitch, which will be introduced
    in subsequent patches.
    
    Signed-off-by: Aviv Heller <avivh@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index cc29e880c733..cd7af5d0311b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -486,6 +486,7 @@ struct mlx5_events;
 struct mlx5_mpfs;
 struct mlx5_eswitch;
 struct mlx5_lag;
+struct mlx5_devcom;
 struct mlx5_eq_table;
 
 struct mlx5_rate_limit {
@@ -560,6 +561,7 @@ struct mlx5_priv {
 	struct mlx5_eswitch     *eswitch;
 	struct mlx5_core_sriov	sriov;
 	struct mlx5_lag		*lag;
+	struct mlx5_devcom	*devcom;
 	unsigned long		pci_dev_data;
 	struct mlx5_fc_stats		fc_stats;
 	struct mlx5_rl_table            rl_table;

commit 4106a758f791de11502cc6be89c971735cab360f
Author: Michael Guralnik <michaelgur@mellanox.com>
Date:   Sun Dec 9 11:49:51 2018 +0200

    IB/mlx5: Report CapabilityMask2 in ib_query_port
    
    CapabilityMask2 exists when IB_PORT_CAP_MASK2_SUP is set in the original
    capability mask. In such cases, query its value and report it in query
    port.
    
    Signed-off-by: Michael Guralnik <michaelgur@mellanox.com>
    Reviewed-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 584d8a5df7eb..b090a96f87df 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -749,8 +749,8 @@ struct mlx5_hca_vport_context {
 	u64			node_guid;
 	u32			cap_mask1;
 	u32			cap_mask1_perm;
-	u32			cap_mask2;
-	u32			cap_mask2_perm;
+	u16			cap_mask2;
+	u16			cap_mask2_perm;
 	u16			lid;
 	u8			init_type_reply; /* bitmask: see ib spec 14.2.5.6 InitTypeReply */
 	u8			lmc;

commit 6c22a11957f46ca7e9b8db20ac7c6b05441c55ed
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Mon Dec 10 13:15:17 2018 -0800

    net/mlx5: Remove the get protocol device interface entry
    
    This isn't used anywhere across the mlx5 driver stack,
    remove it.
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 584d8a5df7eb..cc29e880c733 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1004,12 +1004,10 @@ struct mlx5_interface {
 	void			(*remove)(struct mlx5_core_dev *dev, void *context);
 	int			(*attach)(struct mlx5_core_dev *dev, void *context);
 	void			(*detach)(struct mlx5_core_dev *dev, void *context);
-	void *                  (*get_dev)(void *context);
 	int			protocol;
 	struct list_head	list;
 };
 
-void *mlx5_get_protocol_dev(struct mlx5_core_dev *mdev, int protocol);
 int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
 int mlx5_notifier_register(struct mlx5_core_dev *dev, struct notifier_block *nb);

commit f3da6577da67a3cd44610ca54e308c6838c92157
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Wed Nov 28 20:53:41 2018 +0200

    RDMA/mlx5: Initialize SRQ tables on mlx5_ib
    
    Transfer initialization and cleanup from mlx5_priv struct of
    mlx5_core_dev to be part of mlx5_ib_dev. This completes removal
    of SRQ from mlx5_core.
    
    Reviewed-by: Mark Bloch <markb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1096da4fb368..584d8a5df7eb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -50,7 +50,6 @@
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
-#include <linux/mlx5/srq.h>
 #include <linux/mlx5/eq.h>
 #include <linux/timecounter.h>
 #include <linux/ptp_clock_kernel.h>
@@ -393,20 +392,6 @@ struct mlx5_core_rsc_common {
 	struct completion	free;
 };
 
-struct mlx5_core_srq {
-	struct mlx5_core_rsc_common	common; /* must be first */
-	u32		srqn;
-	int		max;
-	size_t		max_gs;
-	size_t		max_avail_gather;
-	int		wqe_shift;
-	void (*event)	(struct mlx5_core_srq *, enum mlx5_event);
-
-	atomic_t		refcount;
-	struct completion	free;
-	u16		uid;
-};
-
 struct mlx5_uars_page {
 	void __iomem	       *map;
 	bool			wc;
@@ -464,14 +449,6 @@ struct mlx5_qp_table {
 	struct radix_tree_root	tree;
 };
 
-struct mlx5_srq_table {
-	struct notifier_block   nb;
-	/* protect radix tree
-	 */
-	spinlock_t		lock;
-	struct radix_tree_root	tree;
-};
-
 struct mlx5_mkey_table {
 	/* protect radix tree
 	 */
@@ -547,8 +524,6 @@ struct mlx5_priv {
 
 	struct mlx5_core_health health;
 
-	struct mlx5_srq_table	srq_table;
-
 	/* start: qp staff */
 	struct mlx5_qp_table	qp_table;
 	struct dentry	       *qp_debugfs;

commit f02d0d6e53ac2c8a75b6cc87dc86675a9351d84d
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Wed Nov 28 20:53:37 2018 +0200

    net/mlx5: Move SRQ functions to RDMA part
    
    There is no need to keep SRQ which is RDMA object in mlx5_core.
    In this patch, we partially move the execution code, while next patches
    will move table initialization/release logic too.
    
    Reviewed-by: Mark Bloch <markb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 27a481b159ed..1096da4fb368 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -904,13 +904,6 @@ struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 						      gfp_t flags, int npages);
 void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 				 struct mlx5_cmd_mailbox *head);
-int mlx5_core_create_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
-			 struct mlx5_srq_attr *in);
-int mlx5_core_destroy_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq);
-int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
-			struct mlx5_srq_attr *out);
-int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
-		      u16 lwm, int is_srq);
 void mlx5_init_mkey_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_mkey_table(struct mlx5_core_dev *dev);
 int mlx5_core_create_mkey_cb(struct mlx5_core_dev *dev,
@@ -942,7 +935,6 @@ void mlx5_unregister_debugfs(void);
 
 void mlx5_fill_page_array(struct mlx5_frag_buf *buf, __be64 *pas);
 void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
-struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
 int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn,
 		    unsigned int *irqn);
 int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);

commit 4e2df04ad25ab8e627878817e56d6a27645ca4a8
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 26 14:39:07 2018 -0800

    net/mlx5: Forward SRQ resource events
    
    Allow forwarding of SRQ events to mlx5_core interfaces, e.g. mlx5_ib.
    Use mlx5_notifier_register/unregister in srq.c in order to allow seamless
    transition of srq.c to infiniband subsystem.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4f078b7f6620..27a481b159ed 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -465,8 +465,7 @@ struct mlx5_qp_table {
 };
 
 struct mlx5_srq_table {
-	struct mlx5_nb          catas_err_nb;
-	struct mlx5_nb          rq_limit_nb;
+	struct notifier_block   nb;
 	/* protect radix tree
 	 */
 	spinlock_t		lock;

commit 451be51c0b474f790e9833cd575fd9a6fbd679df
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 26 14:39:06 2018 -0800

    net/mlx5: Forward QP/WorkQueues resource events
    
    Allow forwarding QP and WQ events to mlx5_core interfaces, e.g. mlx5_ib
    
    Use mlx5_notifier_register/unregister in qp.c in order to allow seamless
    transition of qp.c to infiniband subsystem.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index a77bedb8a556..4f078b7f6620 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -456,7 +456,7 @@ struct mlx5_core_health {
 };
 
 struct mlx5_qp_table {
-	struct mlx5_nb          nb;
+	struct notifier_block   nb;
 
 	/* protect radix tree
 	 */

commit b8267cd765b333673e05696b517d38a1a7eb5b2e
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 26 14:39:05 2018 -0800

    net/mlx5: Remove all deprecated software versions of FW events
    
    Before the new mlx5 event notification infrastructure and API,
    mlx5_core used to process all events before forwarding them to mlx5
    interfaces (mlx5e/mlx5_ib) and used to translate the event type enum
    to a software defined enum, this is not needed anymore since it is ok
    for mlx5e and mlx5_ib to receive FW events as is, at least the few ones
    mlx5 core allows.
    
    mlx5e and mlx5_ib already moved to use the new API and they only handle FW
    events types, it is now safe to remove all equivalent software defined
    events and the logic around them.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d3ffc64f9a75..a77bedb8a556 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -196,15 +196,6 @@ struct mlx5_rsc_debug {
 
 enum mlx5_dev_event {
 	MLX5_DEV_EVENT_SYS_ERROR = 128, /* 0 - 127 are FW events */
-	MLX5_DEV_EVENT_PORT_UP,
-	MLX5_DEV_EVENT_PORT_DOWN,
-	MLX5_DEV_EVENT_PORT_INITIALIZED,
-	MLX5_DEV_EVENT_LID_CHANGE,
-	MLX5_DEV_EVENT_PKEY_CHANGE,
-	MLX5_DEV_EVENT_GUID_CHANGE,
-	MLX5_DEV_EVENT_CLIENT_REREG,
-	MLX5_DEV_EVENT_PPS,
-	MLX5_DEV_EVENT_DELAY_DROP_TIMEOUT,
 };
 
 enum mlx5_port_status {

commit 02039fb659b366011f55b15890136754f3d82e2d
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 26 14:39:01 2018 -0800

    net/mlx5: Remove unused events callback and logic
    
    The mlx5_interface->event callback is not used by mlx5e/mlx5_ib anymore.
    
    We totally remove the delayed events logic work around, since with
    the dynamic notifier registration API it is not needed anymore, mlx5_ib
    can register its notifier and start receiving events exactly at the moment
    it is ready to handle them.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 14ca74707275..d3ffc64f9a75 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -588,10 +588,7 @@ struct mlx5_priv {
 	struct list_head        dev_list;
 	struct list_head        ctx_list;
 	spinlock_t              ctx_lock;
-
-	struct list_head	waiting_events_list;
-	bool			is_accum_events;
-	struct mlx5_events     *events;
+	struct mlx5_events      *events;
 
 	struct mlx5_flow_steering *steering;
 	struct mlx5_mpfs        *mpfs;
@@ -696,9 +693,6 @@ struct mlx5_core_dev {
 	/* sync interface state */
 	struct mutex		intf_state_mutex;
 	unsigned long		intf_state;
-	void			(*event) (struct mlx5_core_dev *dev,
-					  enum mlx5_dev_event event,
-					  unsigned long param);
 	struct mlx5_priv	priv;
 	struct mlx5_profile	*profile;
 	atomic_t		num_qps;
@@ -1053,8 +1047,6 @@ struct mlx5_interface {
 	void			(*remove)(struct mlx5_core_dev *dev, void *context);
 	int			(*attach)(struct mlx5_core_dev *dev, void *context);
 	void			(*detach)(struct mlx5_core_dev *dev, void *context);
-	void			(*event)(struct mlx5_core_dev *dev, void *context,
-					 enum mlx5_dev_event event, unsigned long param);
 	void *                  (*get_dev)(void *context);
 	int			protocol;
 	struct list_head	list;

commit 58d180b34e98698fec178a469b700f1bb5a32c1f
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 26 14:38:59 2018 -0800

    net/mlx5: Forward all mlx5 events to mlx5 notifiers chain
    
    This to allow seamless migration to the new notifier chain API, and to
    eventually deprecate interfaces dev->event callback.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b96929d0cc9c..14ca74707275 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -195,7 +195,7 @@ struct mlx5_rsc_debug {
 };
 
 enum mlx5_dev_event {
-	MLX5_DEV_EVENT_SYS_ERROR,
+	MLX5_DEV_EVENT_SYS_ERROR = 128, /* 0 - 127 are FW events */
 	MLX5_DEV_EVENT_PORT_UP,
 	MLX5_DEV_EVENT_PORT_DOWN,
 	MLX5_DEV_EVENT_PORT_INITIALIZED,

commit 20902be46c4da59b1891d238801146134e0e06b5
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 26 14:38:56 2018 -0800

    net/mlx5: Driver events notifier API
    
    Use atomic notifier chain to fire events to mlx5 core driver
    consumers (mlx5e/mlx5_ib) and provide mlx5 register/unregister notifier
    API.
    
    This API will replace the current mlx5_interface->event callback and all
    the logic around it, especially the delayed events logic introduced by
    commit 97834eba7c19 ("net/mlx5: Delay events till ib registration ends")
    
    Which is not needed anymore with this new API where the mlx5 interface
    can dynamically register/unregister its notifier.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ba64ecf72478..b96929d0cc9c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -46,6 +46,7 @@
 #include <linux/mempool.h>
 #include <linux/interrupt.h>
 #include <linux/idr.h>
+#include <linux/notifier.h>
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
@@ -1062,6 +1063,9 @@ struct mlx5_interface {
 void *mlx5_get_protocol_dev(struct mlx5_core_dev *mdev, int protocol);
 int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
+int mlx5_notifier_register(struct mlx5_core_dev *dev, struct notifier_block *nb);
+int mlx5_notifier_unregister(struct mlx5_core_dev *dev, struct notifier_block *nb);
+
 int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 
 int mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);

commit 69c1280b1f3b9123bc5154b2062507abcc14c3ef
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Nov 20 14:12:27 2018 -0800

    net/mlx5: Device events, Use async events chain
    
    Move all the generic async events handling into new specific events
    handling file events.c to keep eq.c file clean from concrete event logic
    handling.
    
    Use new API to register for NOTIFY_ANY to handle generic events and
    dispatch allowed events to mlx5_core consumers (mlx5_ib and mlx5e)
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index afba0864f45c..ba64ecf72478 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -514,6 +514,7 @@ struct mlx5_fc_stats {
 	unsigned long sampling_interval; /* jiffies */
 };
 
+struct mlx5_events;
 struct mlx5_mpfs;
 struct mlx5_eswitch;
 struct mlx5_lag;
@@ -540,31 +541,6 @@ struct mlx5_rl_table {
 	struct mlx5_rl_entry   *rl_entry;
 };
 
-enum port_module_event_status_type {
-	MLX5_MODULE_STATUS_PLUGGED   = 0x1,
-	MLX5_MODULE_STATUS_UNPLUGGED = 0x2,
-	MLX5_MODULE_STATUS_ERROR     = 0x3,
-	MLX5_MODULE_STATUS_NUM       = 0x3,
-};
-
-enum  port_module_event_error_type {
-	MLX5_MODULE_EVENT_ERROR_POWER_BUDGET_EXCEEDED,
-	MLX5_MODULE_EVENT_ERROR_LONG_RANGE_FOR_NON_MLNX_CABLE_MODULE,
-	MLX5_MODULE_EVENT_ERROR_BUS_STUCK,
-	MLX5_MODULE_EVENT_ERROR_NO_EEPROM_RETRY_TIMEOUT,
-	MLX5_MODULE_EVENT_ERROR_ENFORCE_PART_NUMBER_LIST,
-	MLX5_MODULE_EVENT_ERROR_UNKNOWN_IDENTIFIER,
-	MLX5_MODULE_EVENT_ERROR_HIGH_TEMPERATURE,
-	MLX5_MODULE_EVENT_ERROR_BAD_CABLE,
-	MLX5_MODULE_EVENT_ERROR_UNKNOWN,
-	MLX5_MODULE_EVENT_ERROR_NUM,
-};
-
-struct mlx5_port_module_event_stats {
-	u64 status_counters[MLX5_MODULE_STATUS_NUM];
-	u64 error_counters[MLX5_MODULE_EVENT_ERROR_NUM];
-};
-
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	*eq_table;
@@ -614,6 +590,7 @@ struct mlx5_priv {
 
 	struct list_head	waiting_events_list;
 	bool			is_accum_events;
+	struct mlx5_events     *events;
 
 	struct mlx5_flow_steering *steering;
 	struct mlx5_mpfs        *mpfs;
@@ -624,8 +601,6 @@ struct mlx5_priv {
 	struct mlx5_fc_stats		fc_stats;
 	struct mlx5_rl_table            rl_table;
 
-	struct mlx5_port_module_event_stats  pme_stats;
-
 	struct mlx5_bfreg_data		bfregs;
 	struct mlx5_uars_page	       *uar;
 };

commit 221c14f3d12489ced0f2ca8b31b2221c5dbbf145
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Nov 20 14:12:25 2018 -0800

    net/mlx5: Resource tables, Use async events chain
    
    Remove the explicit call to QP/SRQ resources events handlers on several FW
    events and let resources logic register resources events notifiers via the
    new API.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index a8d638134fc8..afba0864f45c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -464,6 +464,8 @@ struct mlx5_core_health {
 };
 
 struct mlx5_qp_table {
+	struct mlx5_nb          nb;
+
 	/* protect radix tree
 	 */
 	spinlock_t		lock;
@@ -471,6 +473,8 @@ struct mlx5_qp_table {
 };
 
 struct mlx5_srq_table {
+	struct mlx5_nb          catas_err_nb;
+	struct mlx5_nb          rq_limit_nb;
 	/* protect radix tree
 	 */
 	spinlock_t		lock;
@@ -978,8 +982,6 @@ void mlx5_unregister_debugfs(void);
 
 void mlx5_fill_page_array(struct mlx5_frag_buf *buf, __be64 *pas);
 void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
-void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
-void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
 int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn,
 		    unsigned int *irqn);

commit 71edc69ca1a78ce18411a540c550a4ef1eb017cd
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Nov 20 14:12:24 2018 -0800

    net/mlx5: CmdIF, Use async events chain
    
    Remove the explicit call to mlx5_cmd_comp_handler on MLX5_EVENT_TYPE_CMD
    and let command interface to register its own handler when its ready.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 61088ad33500..a8d638134fc8 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -278,6 +278,8 @@ struct mlx5_cmd_stats {
 };
 
 struct mlx5_cmd {
+	struct mlx5_nb    nb;
+
 	void	       *cmd_alloc_buf;
 	dma_addr_t	alloc_dma;
 	int		alloc_size;

commit 0cf53c1247565b339a23d82a1853a0c41e9a2a34
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Nov 20 14:12:23 2018 -0800

    net/mlx5: FWPage, Use async events chain
    
    Remove the explicit call to mlx5_core_req_pages_handler on
    MLX5_EVENT_TYPE_PAGE_REQUEST and let FW page logic  to register its own
    handler when its ready.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 99a23db9a929..61088ad33500 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -564,6 +564,7 @@ struct mlx5_priv {
 	struct mlx5_eq_table	*eq_table;
 
 	/* pages stuff */
+	struct mlx5_nb          pg_nb;
 	struct workqueue_struct *pg_wq;
 	struct rb_root		page_root;
 	int			fw_pages;
@@ -962,9 +963,9 @@ int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
 int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
 int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, const void *inb, void *outb,
 		      u16 opmod, u8 port);
-void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
+int mlx5_pagealloc_init(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
-int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
+void mlx5_pagealloc_start(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
 void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
 				 s32 npages);

commit 41069256e93045a45a2c359c9715439be0b47bf4
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Nov 20 14:12:21 2018 -0800

    net/mlx5: Clock, Use async events chain
    
    Remove the explicit call to mlx5_pps_event on MLX5_EVENT_TYPE_PPS_EVENT
    and let clock logic to register its own handler when its ready.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index f41e6713df10..99a23db9a929 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -50,6 +50,7 @@
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
 #include <linux/mlx5/srq.h>
+#include <linux/mlx5/eq.h>
 #include <linux/timecounter.h>
 #include <linux/ptp_clock_kernel.h>
 
@@ -671,6 +672,8 @@ struct mlx5_pps {
 };
 
 struct mlx5_clock {
+	struct mlx5_core_dev      *mdev;
+	struct mlx5_nb             pps_nb;
 	seqlock_t                  lock;
 	struct cyclecounter        cycles;
 	struct timecounter         tc;
@@ -678,7 +681,6 @@ struct mlx5_clock {
 	u32                        nominal_c_mult;
 	unsigned long              overflow_period;
 	struct delayed_work        overflow_work;
-	struct mlx5_core_dev      *mdev;
 	struct ptp_clock          *ptp;
 	struct ptp_clock_info      ptp_info;
 	struct mlx5_pps            pps_info;

commit d5d284b829a6eb7127df24d1bd3896a698981e62
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:41 2018 -0800

    {net,IB}/mlx5: Move Page fault EQ and ODP logic to RDMA
    
    Use the new generic EQ API to move all ODP RDMA data structures and logic
    form mlx5 core driver into mlx5_ib driver.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Acked-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index fe9b552aa649..f41e6713df10 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -510,7 +510,6 @@ struct mlx5_fc_stats {
 struct mlx5_mpfs;
 struct mlx5_eswitch;
 struct mlx5_lag;
-struct mlx5_pagefault;
 struct mlx5_eq_table;
 
 struct mlx5_rate_limit {
@@ -619,13 +618,6 @@ struct mlx5_priv {
 
 	struct mlx5_port_module_event_stats  pme_stats;
 
-#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
-	void		      (*pfault)(struct mlx5_core_dev *dev,
-					void *context,
-					struct mlx5_pagefault *pfault);
-	void		       *pfault_ctx;
-	struct srcu_struct      pfault_srcu;
-#endif
 	struct mlx5_bfreg_data		bfregs;
 	struct mlx5_uars_page	       *uar;
 };
@@ -650,44 +642,6 @@ enum mlx5_pagefault_type_flags {
 	MLX5_PFAULT_RDMA      = 1 << 2,
 };
 
-/* Contains the details of a pagefault. */
-struct mlx5_pagefault {
-	u32			bytes_committed;
-	u32			token;
-	u8			event_subtype;
-	u8			type;
-	union {
-		/* Initiator or send message responder pagefault details. */
-		struct {
-			/* Received packet size, only valid for responders. */
-			u32	packet_size;
-			/*
-			 * Number of resource holding WQE, depends on type.
-			 */
-			u32	wq_num;
-			/*
-			 * WQE index. Refers to either the send queue or
-			 * receive queue, according to event_subtype.
-			 */
-			u16	wqe_index;
-		} wqe;
-		/* RDMA responder pagefault details */
-		struct {
-			u32	r_key;
-			/*
-			 * Received packet size, minimal size page fault
-			 * resolution required for forward progress.
-			 */
-			u32	packet_size;
-			u32	rdma_op_len;
-			u64	rdma_va;
-		} rdma;
-	};
-
-	struct mlx5_eq_pagefault *eq;
-	struct work_struct	work;
-};
-
 struct mlx5_td {
 	struct list_head tirs_list;
 	u32              tdn;
@@ -1118,9 +1072,6 @@ struct mlx5_interface {
 	void			(*detach)(struct mlx5_core_dev *dev, void *context);
 	void			(*event)(struct mlx5_core_dev *dev, void *context,
 					 enum mlx5_dev_event event, unsigned long param);
-	void			(*pfault)(struct mlx5_core_dev *dev,
-					  void *context,
-					  struct mlx5_pagefault *pfault);
 	void *                  (*get_dev)(void *context);
 	int			protocol;
 	struct list_head	list;

commit 16d760839ceef510cf95cbfadc069c4473c7a277
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:39 2018 -0800

    net/mlx5: EQ, Different EQ types
    
    In mlx5 we have three types of usages for EQs,
    1. Asynchronous EQs, used internally by mlx5 core for
     a. FW command completions
     b. FW page requests
     c. one EQ for all other Asynchronous events
    
    2. Completion EQs, used for CQ completion (we create one per core)
    
    3. *Special type of EQ (page fault) used for RDMA on demand paging
    (ODP).
    
    *The 3rd type shouldn't be special at least in mlx5 core, it is yet
    another async events EQ with specific use case, it will be removed in
    the next two patches, and will completely move its logic to mlx5_ib,
    as it is rdma specific.
    
    In this patch we remove use case (eq type) specific fields from
    struct mlx5_eq into a new eq type specific structures.
    
    struct mlx5_eq_async;
    truct mlx5_eq_comp;
    struct mlx5_eq_pagefault;
    
    Separate between their type specific flows.
    
    In the future we will allow users to create there own generic EQs.
    for now we will allow only one for ODP in next patches.
    
    We will introduce event listeners registration API for those who
    want to receive mlx5 async events.
    After that mlx5 eq handling will be clean from feature/user specific
    handling.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4d6246cb6c19..fe9b552aa649 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -210,14 +210,6 @@ enum mlx5_port_status {
 	MLX5_PORT_DOWN      = 2,
 };
 
-enum mlx5_eq_type {
-	MLX5_EQ_TYPE_COMP,
-	MLX5_EQ_TYPE_ASYNC,
-#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
-	MLX5_EQ_TYPE_PF,
-#endif
-};
-
 struct mlx5_bfreg_info {
 	u32		       *sys_pages;
 	int			num_low_latency_bfregs;
@@ -692,7 +684,7 @@ struct mlx5_pagefault {
 		} rdma;
 	};
 
-	struct mlx5_eq	       *eq;
+	struct mlx5_eq_pagefault *eq;
 	struct work_struct	work;
 };
 

commit f2f3df5501391bc784c8462dc97d989c2194fb74
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:38 2018 -0800

    net/mlx5: EQ, Privatize eq_table and friends
    
    Move unnecessary EQ table structures and declaration from the
    public include/linux/mlx5/driver.h into the private area of mlx5_core
    and into eq.c/eq.h.
    
    Introduce new mlx5 EQ APIs:
    
    mlx5_comp_vectors_count(dev);
    mlx5_comp_irq_get_affinity_mask(dev, vector);
    
    And use them from mlx5_ib or mlx5e netdevice instead of direct access to
    mlx5_core internal structures.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index dcc3f7aa8572..4d6246cb6c19 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -84,18 +84,6 @@ enum {
 	MLX5_MAX_PORTS	= 2,
 };
 
-enum {
-	MLX5_EQ_VEC_PAGES	 = 0,
-	MLX5_EQ_VEC_CMD		 = 1,
-	MLX5_EQ_VEC_ASYNC	 = 2,
-	MLX5_EQ_VEC_PFAULT	 = 3,
-	MLX5_EQ_VEC_COMP_BASE,
-};
-
-enum {
-	MLX5_MAX_IRQ_NAME	= 32
-};
-
 enum {
 	MLX5_ATOMIC_MODE_OFFSET = 16,
 	MLX5_ATOMIC_MODE_IB_COMP = 1,
@@ -366,49 +354,6 @@ struct mlx5_frag_buf_ctrl {
 	u8			log_frag_strides;
 };
 
-struct mlx5_eq_tasklet {
-	struct list_head list;
-	struct list_head process_list;
-	struct tasklet_struct task;
-	/* lock on completion tasklet list */
-	spinlock_t lock;
-};
-
-struct mlx5_eq_pagefault {
-	struct work_struct       work;
-	/* Pagefaults lock */
-	spinlock_t		 lock;
-	struct workqueue_struct *wq;
-	mempool_t		*pool;
-};
-
-struct mlx5_cq_table {
-	/* protect radix tree */
-	spinlock_t		lock;
-	struct radix_tree_root	tree;
-};
-
-struct mlx5_eq {
-	struct mlx5_core_dev   *dev;
-	struct mlx5_cq_table	cq_table;
-	__be32 __iomem	       *doorbell;
-	u32			cons_index;
-	struct mlx5_frag_buf	buf;
-	int			size;
-	unsigned int		irqn;
-	u8			eqn;
-	int			nent;
-	struct list_head	list;
-	struct mlx5_rsc_debug	*dbg;
-	enum mlx5_eq_type	type;
-	union {
-		struct mlx5_eq_tasklet   tasklet_ctx;
-#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
-		struct mlx5_eq_pagefault pf_ctx;
-#endif
-	};
-};
-
 struct mlx5_core_psv {
 	u32	psv_idx;
 	struct psv_layout {
@@ -475,21 +420,6 @@ struct mlx5_core_srq {
 	u16		uid;
 };
 
-struct mlx5_eq_table {
-	struct list_head	comp_eqs_list;
-	struct mlx5_eq		pages_eq;
-	struct mlx5_eq		async_eq;
-	struct mlx5_eq		cmd_eq;
-#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
-	struct mlx5_eq		pfault_eq;
-#endif
-	int			num_comp_vectors;
-	struct mlx5_irq_info	*irq_info;
-#ifdef CONFIG_RFS_ACCEL
-	struct cpu_rmap         *rmap;
-#endif
-};
-
 struct mlx5_uars_page {
 	void __iomem	       *map;
 	bool			wc;
@@ -572,11 +502,6 @@ struct mlx5_core_sriov {
 	int			enabled_vfs;
 };
 
-struct mlx5_irq_info {
-	cpumask_var_t mask;
-	char name[MLX5_MAX_IRQ_NAME];
-};
-
 struct mlx5_fc_stats {
 	spinlock_t counters_idr_lock; /* protects counters_idr */
 	struct idr counters_idr;
@@ -594,6 +519,7 @@ struct mlx5_mpfs;
 struct mlx5_eswitch;
 struct mlx5_lag;
 struct mlx5_pagefault;
+struct mlx5_eq_table;
 
 struct mlx5_rate_limit {
 	u32			rate;
@@ -643,7 +569,7 @@ struct mlx5_port_module_event_stats {
 
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
-	struct mlx5_eq_table	eq_table;
+	struct mlx5_eq_table	*eq_table;
 
 	/* pages stuff */
 	struct workqueue_struct *pg_wq;
@@ -1148,6 +1074,9 @@ int mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,
 		     bool map_wc, bool fast_path);
 void mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg);
 
+unsigned int mlx5_comp_vectors_count(struct mlx5_core_dev *dev);
+struct cpumask *
+mlx5_comp_irq_get_affinity_mask(struct mlx5_core_dev *dev, int vector);
 unsigned int mlx5_core_reserved_gids_count(struct mlx5_core_dev *dev);
 int mlx5_core_roce_gid_set(struct mlx5_core_dev *dev, unsigned int index,
 			   u8 roce_version, u8 roce_l3_type, const u8 *gid,
@@ -1299,10 +1228,4 @@ enum {
 	MLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,
 };
 
-static inline const struct cpumask *
-mlx5_get_vector_affinity_hint(struct mlx5_core_dev *dev, int vector)
-{
-	return dev->priv.eq_table.irq_info[vector + MLX5_EQ_VEC_COMP_BASE].mask;
-}
-
 #endif /* MLX5_DRIVER_H */

commit d674a9aa434409826b2408609be493739e61e6f6
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:37 2018 -0800

    net/mlx5: EQ, irq_info and rmap belong to eq_table
    
    irq_info and rmap are EQ properties of the driver, and only needed for
    EQ objects, move them to the eq_table EQs database structure.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 852e397c7624..dcc3f7aa8572 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -484,6 +484,10 @@ struct mlx5_eq_table {
 	struct mlx5_eq		pfault_eq;
 #endif
 	int			num_comp_vectors;
+	struct mlx5_irq_info	*irq_info;
+#ifdef CONFIG_RFS_ACCEL
+	struct cpu_rmap         *rmap;
+#endif
 };
 
 struct mlx5_uars_page {
@@ -640,7 +644,6 @@ struct mlx5_port_module_event_stats {
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	eq_table;
-	struct mlx5_irq_info	*irq_info;
 
 	/* pages stuff */
 	struct workqueue_struct *pg_wq;
@@ -851,9 +854,6 @@ struct mlx5_core_dev {
 	} roce;
 #ifdef CONFIG_MLX5_FPGA
 	struct mlx5_fpga_device *fpga;
-#endif
-#ifdef CONFIG_RFS_ACCEL
-	struct cpu_rmap         *rmap;
 #endif
 	struct mlx5_clock        clock;
 	struct mlx5_ib_clock_info  *clock_info;
@@ -1302,7 +1302,7 @@ enum {
 static inline const struct cpumask *
 mlx5_get_vector_affinity_hint(struct mlx5_core_dev *dev, int vector)
 {
-	return dev->priv.irq_info[vector + MLX5_EQ_VEC_COMP_BASE].mask;
+	return dev->priv.eq_table.irq_info[vector + MLX5_EQ_VEC_COMP_BASE].mask;
 }
 
 #endif /* MLX5_DRIVER_H */

commit aaa553a64438640ee4e41a2c1027c3435a75c0e7
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:34 2018 -0800

    net/mlx5: EQ, Remove redundant completion EQ list lock
    
    Completion EQs list is only modified on driver load/unload, locking is
    not required, remove it.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4b62d71825c1..852e397c7624 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -484,9 +484,6 @@ struct mlx5_eq_table {
 	struct mlx5_eq		pfault_eq;
 #endif
 	int			num_comp_vectors;
-	/* protect EQs list
-	 */
-	spinlock_t		lock;
 };
 
 struct mlx5_uars_page {

commit 2883f352571b9b830561ca21b8a666936366a120
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:33 2018 -0800

    net/mlx5: EQ, No need to store eq index as a field
    
    eq->index is used only for completion EQs and is assigned to be
    the completion eq index, it is used only when traversing the completion
    eqs list, and it can be calculated dynamically, thus remove the
    eq->index field.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 15cf6727a62d..4b62d71825c1 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -399,7 +399,6 @@ struct mlx5_eq {
 	u8			eqn;
 	int			nent;
 	struct list_head	list;
-	int			index;
 	struct mlx5_rsc_debug	*dbg;
 	enum mlx5_eq_type	type;
 	union {

commit 4de45c758636c37efd313589f91c739f613fbe7d
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:32 2018 -0800

    net/mlx5: EQ, Remove unused fields and structures
    
    Some fields and structures are not referenced nor used by the driver,
    remove them.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7d4ed995b4ce..15cf6727a62d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -398,7 +398,6 @@ struct mlx5_eq {
 	unsigned int		irqn;
 	u8			eqn;
 	int			nent;
-	u64			mask;
 	struct list_head	list;
 	int			index;
 	struct mlx5_rsc_debug	*dbg;
@@ -478,8 +477,6 @@ struct mlx5_core_srq {
 };
 
 struct mlx5_eq_table {
-	void __iomem	       *update_ci;
-	void __iomem	       *update_arm_ci;
 	struct list_head	comp_eqs_list;
 	struct mlx5_eq		pages_eq;
 	struct mlx5_eq		async_eq;

commit 1e86ace4c140fd5a693e266c9b23409358f25381
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:31 2018 -0800

    net/mlx5: EQ, Use the right place to store/read IRQ affinity hint
    
    Currently the cpu affinity hint mask for completion EQs is stored and
    read from the wrong place, since reading and storing is done from the
    same index, there is no actual issue with that, but internal irq_info
    for completion EQs stars at MLX5_EQ_VEC_COMP_BASE offset in irq_info
    array, this patch changes the code to use the correct offset to store
    and read the IRQ affinity hint.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index aa5963b5d38e..7d4ed995b4ce 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1309,7 +1309,7 @@ enum {
 static inline const struct cpumask *
 mlx5_get_vector_affinity_hint(struct mlx5_core_dev *dev, int vector)
 {
-	return dev->priv.irq_info[vector].mask;
+	return dev->priv.irq_info[vector + MLX5_EQ_VEC_COMP_BASE].mask;
 }
 
 #endif /* MLX5_DRIVER_H */

commit da19a102ce87bf3e0a7fe277a659d1fc35330d6d
Merge: e5f6d9afa341 a60109dc9a95
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 26 07:38:19 2018 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull rdma updates from Jason Gunthorpe:
     "This has been a smaller cycle with many of the commits being smallish
      code fixes and improvements across the drivers.
    
       - Driver updates for bnxt_re, cxgb4, hfi1, hns, mlx5, nes, qedr, and
         rxe
    
       - Memory window support in hns
    
       - mlx5 user API 'flow mutate/steering' allows accessing the full
         packet mangling and matching machinery from user space
    
       - Support inter-working with verbs API calls in the 'devx' mlx5 user
         API, and provide options to use devx with less privilege
    
       - Modernize the use of syfs and the device interface to use attribute
         groups and cdev properly for uverbs, and clean up some of the core
         code's device list management
    
       - More progress on net namespaces for RDMA devices
    
       - Consolidate driver BAR mmapping support into core code helpers and
         rework how RDMA holds poitners to mm_struct for get_user_pages
         cases
    
       - First pass to use 'dev_name' instead of ib_device->name
    
       - Device renaming for RDMA devices"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma: (242 commits)
      IB/mlx5: Add support for extended atomic operations
      RDMA/core: Fix comment for hw stats init for port == 0
      RDMA/core: Refactor ib_register_device() function
      RDMA/core: Fix unwinding flow in case of error to register device
      ib_srp: Remove WARN_ON in srp_terminate_io()
      IB/mlx5: Allow scatter to CQE without global signaled WRs
      IB/mlx5: Verify that driver supports user flags
      IB/mlx5: Support scatter to CQE for DC transport type
      RDMA/drivers: Use core provided API for registering device attributes
      RDMA/core: Allow existing drivers to set one sysfs group per device
      IB/rxe: Remove unnecessary enum values
      RDMA/umad: Use kernel API to allocate umad indexes
      RDMA/uverbs: Use kernel API to allocate uverbs indexes
      RDMA/core: Increase total number of RDMA ports across all devices
      IB/mlx4: Add port and TID to MAD debug print
      IB/mlx4: Enable debug print of SMPs
      RDMA/core: Rename ports_parent to ports_kobj
      RDMA/core: Do not expose unsupported counters
      IB/mlx4: Refer to the device kobject instead of ports_parent
      RDMA/nldev: Allow IB device rename through RDMA netlink
      ...

commit 2e2d6f0342be7f73a34526077fa96f42f0e8c661
Merge: 9333f2079203 48995423143a
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Oct 19 11:03:06 2018 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    net/sched/cls_api.c has overlapping changes to a call to
    nlmsg_parse(), one (from 'net') added rtm_tca_policy instead of NULL
    to the 5th argument, and another (from 'net-next') added cb->extack
    instead of NULL to the 6th argument.
    
    net/ipv4/ipmr_base.c is a case of a bug fix in 'net' being done to
    code which moved (to mr_table_dump)) in 'net-next'.  Thanks to David
    Ahern for the heads up.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 4b5b9c7d972e8a7b1e7691c7c921ec0d6dec33b9
Author: Shay Agroskin <shayag@mellanox.com>
Date:   Tue Oct 9 14:16:43 2018 +0300

    net/mlx5: Add FEC fields to Port Phy Link Mode (PPLM) reg
    
    Added FEC related fields to PPLM layout.
    These fields are needed to set and query FEC policy
    for different link speeds.
    
    Signed-off-by: Shay Agroskin <shayag@mellanox.com>
    Reviewed-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index e10f61a1f77d..696ed3f7f894 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -133,6 +133,7 @@ enum {
 	MLX5_REG_PVLC		 = 0x500f,
 	MLX5_REG_PCMR		 = 0x5041,
 	MLX5_REG_PMLP		 = 0x5002,
+	MLX5_REG_PPLM		 = 0x5023,
 	MLX5_REG_PCAM		 = 0x507f,
 	MLX5_REG_NODE_DESC	 = 0x6001,
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,

commit 4972e6fa3a04032830bc3d6bb343d08ab3546773
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Sep 12 15:36:41 2018 +0300

    net/mlx5: Refactor fragmented buffer struct fields and init flow
    
    Take struct mlx5_frag_buf out of mlx5_frag_buf_ctrl, as it is not
    needed to manage and control the datapath of the fragmented buffers API.
    
    struct mlx5_frag_buf contains control info to manage the allocation
    and de-allocation of the fragmented buffer.
    Its fields are not relevant for datapath, so here I take them out of the
    struct mlx5_frag_buf_ctrl, except for the fragments array itself.
    
    In addition, modified mlx5_fill_fbc to initialise the frags pointers
    as well. This implies that the buffer must be allocated before the
    function is called.
    
    A set of type-specific *_get_byte_size() functions are replaced by
    a generic one.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 94ffd02af7cd..e10f61a1f77d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -357,7 +357,7 @@ struct mlx5_frag_buf {
 };
 
 struct mlx5_frag_buf_ctrl {
-	struct mlx5_frag_buf	frag_buf;
+	struct mlx5_buf_list   *frags;
 	u32			sz_m1;
 	u16			frag_sz_m1;
 	u16			strides_offset;
@@ -994,10 +994,12 @@ static inline u32 mlx5_base_mkey(const u32 key)
 	return key & 0xffffff00u;
 }
 
-static inline void mlx5_fill_fbc_offset(u8 log_stride, u8 log_sz,
+static inline void mlx5_init_fbc_offset(struct mlx5_buf_list *frags,
+					u8 log_stride, u8 log_sz,
 					u16 strides_offset,
 					struct mlx5_frag_buf_ctrl *fbc)
 {
+	fbc->frags      = frags;
 	fbc->log_stride = log_stride;
 	fbc->log_sz     = log_sz;
 	fbc->sz_m1	= (1 << fbc->log_sz) - 1;
@@ -1006,18 +1008,11 @@ static inline void mlx5_fill_fbc_offset(u8 log_stride, u8 log_sz,
 	fbc->strides_offset = strides_offset;
 }
 
-static inline void mlx5_fill_fbc(u8 log_stride, u8 log_sz,
+static inline void mlx5_init_fbc(struct mlx5_buf_list *frags,
+				 u8 log_stride, u8 log_sz,
 				 struct mlx5_frag_buf_ctrl *fbc)
 {
-	mlx5_fill_fbc_offset(log_stride, log_sz, 0, fbc);
-}
-
-static inline void mlx5_core_init_cq_frag_buf(struct mlx5_frag_buf_ctrl *fbc,
-					      void *cqc)
-{
-	mlx5_fill_fbc(6 + MLX5_GET(cqc, cqc, cqe_sz),
-		      MLX5_GET(cqc, cqc, log_cq_size),
-		      fbc);
+	mlx5_init_fbc_offset(frags, log_stride, log_sz, 0, fbc);
 }
 
 static inline void *mlx5_frag_buf_get_wqe(struct mlx5_frag_buf_ctrl *fbc,
@@ -1028,8 +1023,7 @@ static inline void *mlx5_frag_buf_get_wqe(struct mlx5_frag_buf_ctrl *fbc,
 	ix  += fbc->strides_offset;
 	frag = ix >> fbc->log_frag_strides;
 
-	return fbc->frag_buf.frags[frag].buf +
-		((fbc->frag_sz_m1 & ix) << fbc->log_stride);
+	return fbc->frags[frag].buf + ((fbc->frag_sz_m1 & ix) << fbc->log_stride);
 }
 
 int mlx5_cmd_init(struct mlx5_core_dev *dev);

commit 186daf0c20507072e72a3c74db4ac50a5b6dae07
Merge: aadd4355918f 94a04d1d3d36
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Wed Oct 17 14:13:36 2018 -0700

    Merge branch 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux into net-next
    
    mlx5 updates for both net-next and rdma-next
    
    * 'mlx5-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux: (21 commits)
      net/mlx5: Expose DC scatter to CQE capability bit
      net/mlx5: Update mlx5_ifc with DEVX UID bits
      net/mlx5: Set uid as part of DCT commands
      net/mlx5: Set uid as part of SRQ commands
      net/mlx5: Set uid as part of SQ commands
      net/mlx5: Set uid as part of RQ commands
      net/mlx5: Set uid as part of QP commands
      net/mlx5: Set uid as part of CQ commands
      net/mlx5: Rename incorrect naming in IFC file
      net/mlx5: Export packet reformat alloc/dealloc functions
      net/mlx5: Pass a namespace for packet reformat ID allocation
      net/mlx5: Expose new packet reformat capabilities
      {net, RDMA}/mlx5: Rename encap to reformat packet
      net/mlx5: Move header encap type to IFC header file
      net/mlx5: Break encap/decap into two separated flow table creation flags
      net/mlx5: Add support for more namespaces when allocating modify header
      net/mlx5: Export modify header alloc/dealloc functions
      net/mlx5: Add proper NIC TX steering flow tables support
      net/mlx5: Cleanup flow namespace getter switch logic
      net/mlx5: Add memic command opcode to command checker
      ...
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit a60109dc9a954ef9eddba6577e2d2e9e7952e487
Author: Yonatan Cohen <yonatanc@mellanox.com>
Date:   Wed Oct 10 09:25:16 2018 +0300

    IB/mlx5: Add support for extended atomic operations
    
    Extended atomic operations cmp&swp and fetch&add is a Mellanox
    feature extending the standard atomic operation to use, varied
    operand sizes, as apposed to normal atomic operation that use
    an 8 byte operand only.
    Extended atomics allows masking the results and arguments.
    
    This patch configures QP to support extended atomic operation
    with the maximum size possible, as exposed by HCA capabilities.
    
    Signed-off-by: Yonatan Cohen <yonatanc@mellanox.com>
    Reviewed-by: Guy Levi <guyle@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8fb072aa8671..a73c701edd16 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -97,14 +97,15 @@ enum {
 };
 
 enum {
-	MLX5_ATOMIC_MODE_IB_COMP	= 1 << 16,
-	MLX5_ATOMIC_MODE_CX		= 2 << 16,
-	MLX5_ATOMIC_MODE_8B		= 3 << 16,
-	MLX5_ATOMIC_MODE_16B		= 4 << 16,
-	MLX5_ATOMIC_MODE_32B		= 5 << 16,
-	MLX5_ATOMIC_MODE_64B		= 6 << 16,
-	MLX5_ATOMIC_MODE_128B		= 7 << 16,
-	MLX5_ATOMIC_MODE_256B		= 8 << 16,
+	MLX5_ATOMIC_MODE_OFFSET = 16,
+	MLX5_ATOMIC_MODE_IB_COMP = 1,
+	MLX5_ATOMIC_MODE_CX = 2,
+	MLX5_ATOMIC_MODE_8B = 3,
+	MLX5_ATOMIC_MODE_16B = 4,
+	MLX5_ATOMIC_MODE_32B = 5,
+	MLX5_ATOMIC_MODE_64B = 6,
+	MLX5_ATOMIC_MODE_128B = 7,
+	MLX5_ATOMIC_MODE_256B = 8,
 };
 
 enum {
@@ -162,13 +163,11 @@ enum mlx5_dcbx_oper_mode {
 	MLX5E_DCBX_PARAM_VER_OPER_AUTO  = 0x3,
 };
 
-enum mlx5_dct_atomic_mode {
-	MLX5_ATOMIC_MODE_DCT_CX         = 2,
-};
-
 enum {
 	MLX5_ATOMIC_OPS_CMP_SWAP	= 1 << 0,
 	MLX5_ATOMIC_OPS_FETCH_ADD	= 1 << 1,
+	MLX5_ATOMIC_OPS_EXTENDED_CMP_SWAP = 1 << 2,
+	MLX5_ATOMIC_OPS_EXTENDED_FETCH_ADD = 1 << 3,
 };
 
 enum mlx5_page_fault_resume_flags {

commit 37fdffb217a45609edccbb8b407d031143f551c0
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Tue Aug 21 14:41:41 2018 +0300

    net/mlx5: WQ, fixes for fragmented WQ buffers API
    
    mlx5e netdevice used to calculate fragment edges by a call to
    mlx5_wq_cyc_get_frag_size(). This calculation did not give the correct
    indication for queues smaller than a PAGE_SIZE, (broken by default on
    PowerPC, where PAGE_SIZE == 64KB).  Here it is replaced by the correct new
    calls/API.
    
    Since (TX/RX) Work Queues buffers are fragmented, here we introduce
    changes to the API in core driver, so that it gets a stride index and
    returns the index of last stride on same fragment, and an additional
    wrapping function that returns the number of physically contiguous
    strides that can be written contiguously to the work queue.
    
    This obsoletes the following API functions, and their buggy
    usage in EN driver:
    * mlx5_wq_cyc_get_frag_size()
    * mlx5_wq_cyc_ctr2fragix()
    
    The new API improves modularity and hides the details of such
    calculation for mlx5e netdevice and mlx5_ib rdma drivers.
    
    New calculation is also more efficient, and improves performance
    as follows:
    
    Packet rate test: pktgen, UDP / IPv4, 64byte, single ring, 8K ring size.
    
    Before: 16,477,619 pps
    After:  17,085,793 pps
    
    3.7% improvement
    
    Fixes: 3a2f70331226 ("net/mlx5: Use order-0 allocations for all WQ types")
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 66d94b4557cf..88a041b73abf 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1032,6 +1032,14 @@ static inline void *mlx5_frag_buf_get_wqe(struct mlx5_frag_buf_ctrl *fbc,
 		((fbc->frag_sz_m1 & ix) << fbc->log_stride);
 }
 
+static inline u32
+mlx5_frag_buf_get_idx_last_contig_stride(struct mlx5_frag_buf_ctrl *fbc, u32 ix)
+{
+	u32 last_frag_stride_idx = (ix + fbc->strides_offset) | fbc->frag_sz_m1;
+
+	return min_t(u32, last_frag_stride_idx - fbc->strides_offset, fbc->sz_m1);
+}
+
 int mlx5_cmd_init(struct mlx5_core_dev *dev);
 void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);

commit f6a8a19bb11b46d60250ddc4e3e1ba6aa166f488
Author: Denis Drozdov <denisd@mellanox.com>
Date:   Tue Aug 14 14:08:51 2018 +0300

    RDMA/netdev: Hoist alloc_netdev_mqs out of the driver
    
    netdev has several interfaces that expect to call alloc_netdev_mqs from
    the core code, with the driver only providing the arguments.  This is
    incompatible with the rdma_netdev interface that returns the netdev
    directly.
    
    Thus re-organize the API used by ipoib so that the verbs core code calls
    alloc_netdev_mqs for the driver. This is done by allowing the drivers to
    provide the allocation parameters via a 'get_params' callback and then
    initializing an allocated netdev as a second step.
    
    Fixes: cd565b4b51e5 ("IB/IPoIB: Support acceleration options callbacks")
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Denis Drozdov <denisd@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 26a92462f4ce..4b75796cac23 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1228,21 +1228,15 @@ int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,
 struct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev);
 void mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up);
 
-#ifndef CONFIG_MLX5_CORE_IPOIB
-static inline
-struct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,
-					  struct ib_device *ibdev,
-					  const char *name,
-					  void (*setup)(struct net_device *))
-{
-	return ERR_PTR(-EOPNOTSUPP);
-}
-#else
+#ifdef CONFIG_MLX5_CORE_IPOIB
 struct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,
 					  struct ib_device *ibdev,
 					  const char *name,
 					  void (*setup)(struct net_device *));
 #endif /* CONFIG_MLX5_CORE_IPOIB */
+int mlx5_rdma_rn_get_params(struct mlx5_core_dev *mdev,
+			    struct ib_device *device,
+			    struct rdma_netdev_alloc_params *params);
 
 struct mlx5_profile {
 	u64	mask;

commit 59c9d35ea9cd73c3a55642ec9a0097770baccb93
Author: Alaa Hleihel <alaa@mellanox.com>
Date:   Wed Sep 5 17:06:37 2018 +0300

    net/mlx5: Cache the system image guid
    
    The system image guid is a read-only field which is used by the TC
    offloads code to determine if two mlx5 devices belong to the same
    ASIC while adding flows.
    
    Read this once and save it on the core device rather than querying each
    time an offloaded flow is added.
    
    Signed-off-by: Alaa Hleihel <alaa@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ed73b51f6697..26a92462f4ce 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -838,6 +838,7 @@ struct mlx5_core_dev {
 		u32 fpga[MLX5_ST_SZ_DW(fpga_cap)];
 		u32 qcam[MLX5_ST_SZ_DW(qcam_reg)];
 	} caps;
+	u64			sys_image_guid;
 	phys_addr_t		iseg_base;
 	struct mlx5_init_seg __iomem *iseg;
 	enum mlx5_device_state	state;

commit a0d8c054318976927493ffd26055d9d183c9beec
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Thu Sep 20 21:35:24 2018 +0300

    net/mlx5: Set uid as part of SRQ commands
    
    Set uid as part of SRQ commands so that the firmware can manage the
    SRQ object in a secured way.
    
    That will enable using an SRQ that was created by verbs application
    to be used by the DEVX flow in case the uid is equal.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d885e9f0e054..8fb072aa8671 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -474,6 +474,7 @@ struct mlx5_core_srq {
 
 	atomic_t		refcount;
 	struct completion	free;
+	u16		uid;
 };
 
 struct mlx5_eq_table {

commit aaf9253025e80cf8f62d7b33670e84e838eec5a3
Merge: a20625e49dde 7428b2e5d0b1
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 12 22:22:42 2018 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net

commit 64109f1dc41f25f4a9c6b114e04b6266bf4128ad
Author: Shay Agroskin <shayag@mellanox.com>
Date:   Tue Jun 5 09:22:18 2018 +0300

    net/mlx5e: Replace PTP clock lock from RW lock to seq lock
    
    Changed "priv.clock.lock" lock from 'rw_lock' to 'seq_lock'
    in order to improve packet rate performance.
    
    Tested on Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz.
    Sent 64b packets between two peers connected by ConnectX-5,
    and measured packet rate for the receiver in three modes:
            no time-stamping (base rate)
            time-stamping using rw_lock (old lock) for critical region
            time-stamping using seq_lock (new lock) for critical region
    Only the receiver time stamped its packets.
    
    The measured packet rate improvements are:
    
            Single flow (multiple TX rings to single RX ring):
                    without timestamping:     4.26 (M packets)/sec
                    with rw-lock (old lock):  4.1  (M packets)/sec
                    with seq-lock (new lock): 4.16 (M packets)/sec
                    1.46% improvement
    
            Multiple flows (multiple TX rings to six RX rings):
                    without timestamping:     22   (M packets)/sec
                    with rw-lock (old lock):  11.7 (M packets)/sec
                    with seq-lock (new lock): 21.3 (M packets)/sec
                    82.05% improvement
    
    The packet rate improvement is due to the lack of atomic operations
    for the 'readers' by the seq-lock.
    Since there are much more 'readers' than 'writers' contention
    on this lock, almost all atomic operations are saved.
    this results in a dramatic decrease in overall
    cache misses.
    
    Signed-off-by: Shay Agroskin <shayag@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2a0c845f6bdb..b7fce2c9443d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -805,7 +805,7 @@ struct mlx5_pps {
 };
 
 struct mlx5_clock {
-	rwlock_t                   lock;
+	seqlock_t                  lock;
 	struct cyclecounter        cycles;
 	struct timecounter         tc;
 	struct hwtstamp_config     hwtstamp_config;

commit 12d6066c3b29c5606c4a2466f964fbd9ede803c5
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Tue Jul 24 16:37:40 2018 +0300

    net/mlx5: Add flow counters idr
    
    Previous patch in series changed flow counter storage structure from
    rb_tree to linked list in order to improve flow counter traversal
    performance. The drawback of such solution is that flow counter lookup by
    id becomes linear in complexity.
    
    Store pointers to flow counters in idr in order to improve lookup
    performance to logarithmic again. Idr is non-intrusive data structure and
    doesn't require extending flow counter struct with new elements. This means
    that idr can be used for lookup, while linked list from previous patch is
    used for traversal, and struct mlx5_fc size is <= 2 cache lines.
    
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Acked-by: Amir Vadai <amir@vadai.me>
    Reviewed-by: Paul Blakey <paulb@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 61bed33e6675..2a0c845f6bdb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -583,6 +583,8 @@ struct mlx5_irq_info {
 };
 
 struct mlx5_fc_stats {
+	spinlock_t counters_idr_lock; /* protects counters_idr */
+	struct idr counters_idr;
 	struct list_head counters;
 	struct llist_head addlist;
 	struct llist_head dellist;

commit 9aff93d7d0d4b3f3076d7bd12a4ad06ef1cf9804
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Tue Jul 24 09:52:11 2018 +0300

    net/mlx5: Store flow counters in a list
    
    In order to improve performance of flow counter stats query loop that
    traverses all configured flow counters, replace rb_tree with double-linked
    list. This change improves performance of traversing flow counters by
    removing the tree traversal. (profiling data showed that call to rb_next
    was most top CPU consumer)
    
    However, lookup of flow flow counter in list becomes linear, instead of
    logarithmic. This problem is fixed by next patch in series, which adds idr
    for fast lookup. Idr is to be used because it is not an intrusive data
    structure and doesn't require adding any new members to struct mlx5_fc,
    which allows its control data part to stay <= 1 cache line in size.
    
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Acked-by: Amir Vadai <amir@vadai.me>
    Reviewed-by: Paul Blakey <paulb@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4b53ac64004b..61bed33e6675 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -583,7 +583,7 @@ struct mlx5_irq_info {
 };
 
 struct mlx5_fc_stats {
-	struct rb_root counters;
+	struct list_head counters;
 	struct llist_head addlist;
 	struct llist_head dellist;
 

commit 6e5e22839136fdb466af0aa46ff2404713dff974
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Mon Jul 23 11:32:05 2018 +0300

    net/mlx5: Add new list to store deleted flow counters
    
    In order to prevent flow counters stats work function from traversing whole
    flow counters tree while searching for deleted flow counters, new list to
    store deleted flow counters is added to struct mlx5_fc_stats. Lockless
    NULL-terminated single linked list data type is used due to following
    reasons:
     - This use case only needs to add single element to list and
     remove/iterate whole list. Lockless list doesn't require any additional
     synchronization for these operations.
     - First cache line of flow counter data structure only has space to store
     single additional pointer, which precludes usage of double linked list.
    
    Remove flow counter 'deleted' flag that is no longer needed.
    
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Acked-by: Amir Vadai <amir@vadai.me>
    Reviewed-by: Paul Blakey <paulb@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c00549293982..4b53ac64004b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -585,6 +585,7 @@ struct mlx5_irq_info {
 struct mlx5_fc_stats {
 	struct rb_root counters;
 	struct llist_head addlist;
+	struct llist_head dellist;
 
 	struct workqueue_struct *wq;
 	struct delayed_work work;

commit 83033688b7ade18d2dbbcefa810f02ff66ba549d
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Mon Jul 23 10:55:39 2018 +0300

    net/mlx5: Change flow counters addlist type to single linked list
    
    In order to prevent flow counters stats work function from traversing whole
    flow counters tree while searching for deleted flow counters, new list to
    store deleted flow counters will be added to struct mlx5_fc_stats. However,
    the flow counter structure itself has no space left to store any more data
    in first cache line. To free space that is needed to store additional list
    node, convert current addlist double linked list (two pointers per node) to
    atomic single linked list (one pointer per node).
    
    Lockless NULL-terminated single linked list data type doesn't require any
    additional external synchronization for operations used by flow counters
    module (add single new element, remove all elements from list and traverse
    them). Remove addlist_lock that is no longer needed.
    
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Acked-by: Amir Vadai <amir@vadai.me>
    Reviewed-by: Paul Blakey <paulb@mellanox.com>
    Reviewed-by: Roi Dayan <roid@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7a452716de4b..c00549293982 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -584,9 +584,7 @@ struct mlx5_irq_info {
 
 struct mlx5_fc_stats {
 	struct rb_root counters;
-	struct list_head addlist;
-	/* protect addlist add/splice operations */
-	spinlock_t addlist_lock;
+	struct llist_head addlist;
 
 	struct workqueue_struct *wq;
 	struct delayed_work work;

commit a09036221092989b88c55d24d1f12ceb1d7d361f
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Tue Aug 21 16:07:58 2018 +0300

    net/mlx5: Use u16 for Work Queue buffer strides offset
    
    Minimal stride size is 16.
    Hence, the number of strides in a fragment (of PAGE_SIZE)
    is <= PAGE_SIZE / 16 <= 4K.
    
    u16 is sufficient to represent this.
    
    Fixes: d7037ad73daa ("net/mlx5: Fix QP fragmented buffer allocation")
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3a1258fd8ac3..66d94b4557cf 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -363,7 +363,7 @@ struct mlx5_frag_buf_ctrl {
 	struct mlx5_frag_buf	frag_buf;
 	u32			sz_m1;
 	u16			frag_sz_m1;
-	u32			strides_offset;
+	u16			strides_offset;
 	u8			log_sz;
 	u8			log_stride;
 	u8			log_frag_strides;
@@ -995,7 +995,7 @@ static inline u32 mlx5_base_mkey(const u32 key)
 }
 
 static inline void mlx5_fill_fbc_offset(u8 log_stride, u8 log_sz,
-					u32 strides_offset,
+					u16 strides_offset,
 					struct mlx5_frag_buf_ctrl *fbc)
 {
 	fbc->log_stride = log_stride;

commit 8d71e818506718e8d7032ce824b5c74a17d4f7a5
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Tue Aug 21 16:04:41 2018 +0300

    net/mlx5: Use u16 for Work Queue buffer fragment size
    
    Minimal stride size is 16.
    Hence, the number of strides in a fragment (of PAGE_SIZE)
    is <= PAGE_SIZE / 16 <= 4K.
    
    u16 is sufficient to represent this.
    
    Fixes: 388ca8be0037 ("IB/mlx5: Implement fragmented completion queue (CQ)")
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index aa65f58c6610..3a1258fd8ac3 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -362,7 +362,7 @@ struct mlx5_frag_buf {
 struct mlx5_frag_buf_ctrl {
 	struct mlx5_frag_buf	frag_buf;
 	u32			sz_m1;
-	u32			frag_sz_m1;
+	u16			frag_sz_m1;
 	u32			strides_offset;
 	u8			log_sz;
 	u8			log_stride;

commit 76d5581c870454be5f1f1a106c57985902e7ea20
Author: Jack Morgenstein <jackm@dev.mellanox.co.il>
Date:   Sun Aug 5 09:19:33 2018 +0300

    net/mlx5: Fix use-after-free in self-healing flow
    
    When the mlx5 health mechanism detects a problem while the driver
    is in the middle of init_one or remove_one, the driver needs to prevent
    the health mechanism from scheduling future work; if future work
    is scheduled, there is a problem with use-after-free: the system WQ
    tries to run the work item (which has been freed) at the scheduled
    future time.
    
    Prevent this by disabling work item scheduling in the health mechanism
    when the driver is in the middle of init_one() or remove_one().
    
    Fixes: e126ba97dba9 ("mlx5: Add driver for Mellanox Connect-IB adapters")
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Reviewed-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7a452716de4b..aa65f58c6610 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1052,7 +1052,7 @@ int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
 void mlx5_health_cleanup(struct mlx5_core_dev *dev);
 int mlx5_health_init(struct mlx5_core_dev *dev);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);
-void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
+void mlx5_stop_health_poll(struct mlx5_core_dev *dev, bool disable_health);
 void mlx5_drain_health_wq(struct mlx5_core_dev *dev);
 void mlx5_trigger_health_work(struct mlx5_core_dev *dev);
 void mlx5_drain_health_recovery(struct mlx5_core_dev *dev);

commit aa7e80b220f3a543eefbe4b7e2c5d2b73e2e2ef7
Author: Moni Shoua <monis@mellanox.com>
Date:   Mon Sep 3 20:19:28 2018 +0300

    net/mlx5: Fix atomic_mode enum values
    
    The field atomic_mode is 4 bits wide and therefore can hold values
    from 0x0 to 0xf. Remove the unnecessary 20 bit shift that made the values
    be incorrect. While that, remove unused enum values.
    
    Fixes: 57cda166bbe0 ("net/mlx5: Add DCT command interface")
    Signed-off-by: Moni Shoua <monis@mellanox.com>
    Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7a452716de4b..d885e9f0e054 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -163,10 +163,7 @@ enum mlx5_dcbx_oper_mode {
 };
 
 enum mlx5_dct_atomic_mode {
-	MLX5_ATOMIC_MODE_DCT_OFF        = 20,
-	MLX5_ATOMIC_MODE_DCT_NONE       = 0 << MLX5_ATOMIC_MODE_DCT_OFF,
-	MLX5_ATOMIC_MODE_DCT_IB_COMP    = 1 << MLX5_ATOMIC_MODE_DCT_OFF,
-	MLX5_ATOMIC_MODE_DCT_CX         = 2 << MLX5_ATOMIC_MODE_DCT_OFF,
+	MLX5_ATOMIC_MODE_DCT_CX         = 2,
 };
 
 enum {

commit 0a3173a5f09bc58a3638ecfd0a80bdbae55e123c
Merge: 92f4e77c8591 5c60a7389d79
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Thu Aug 16 14:13:03 2018 -0600

    Merge branch 'linus/master' into rdma.git for-next
    
    rdma.git merge resolution for the 4.19 merge window
    
    Conflicts:
     drivers/infiniband/core/rdma_core.c
       - Use the rdma code and revise with the new spelling for
         atomic_fetch_add_unless
     drivers/nvme/host/rdma.c
       - Replace max_sge with max_send_sge in new blk code
     drivers/nvme/target/rdma.c
       - Use the blk code and revise to use NULL for ib_post_recv when
         appropriate
       - Replace max_sge with max_recv_sge in new blk code
     net/rds/ib_send.c
       - Use the net code and revise to use NULL for ib_post_recv when
         appropriate
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 89982f7ccee2fcd8fea7936b81eec6defbf0f131
Merge: a1ceeca679dc 94710cac0ef4
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Thu Aug 16 13:08:18 2018 -0600

    Merge tag 'v4.18' into rdma.git for-next
    
    Resolve merge conflicts from the -rc cycle against the rdma.git tree:
    
    Conflicts:
     drivers/infiniband/core/uverbs_cmd.c
      - New ifs added to ib_uverbs_ex_create_flow in -rc and for-next
      - Merge removal of file->ucontext in for-next with new code in -rc
     drivers/infiniband/core/uverbs_main.c
      - for-next removed code from ib_uverbs_write() that was modified
        in for-rc
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 9f49a5b5c21d58aa84e16cfdc5e99e49faefcb7a
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Sun Jul 29 11:34:56 2018 +0300

    RDMA/netdev: Use priv_destructor for netdev cleanup
    
    Now that the unregister_netdev flow for IPoIB no longer relies on external
    code we can now introduce the use of priv_destructor and
    needs_free_netdev.
    
    The rdma_netdev flow is switched to use the netdev common priv_destructor
    instead of the special free_rdma_netdev and the IPOIB ULP adjusted:
     - priv_destructor needs to switch to point to the ULP's destructor
       which will then call the rdma_ndev's in the right order
     - We need to be careful around the error unwind of register_netdev
       as it sometimes calls priv_destructor on failure
     - ULPs need to use ndo_init/uninit to ensure proper ordering
       of failures around register_netdev
    
    Switching to priv_destructor is a necessary pre-requisite to using
    the rtnl new_link mechanism.
    
    The VNIC user for rdma_netdev should also be revised, but that is left for
    another patch.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Denis Drozdov <denisd@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 957199c20a0f..96498ff6beb6 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1218,14 +1218,11 @@ struct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,
 {
 	return ERR_PTR(-EOPNOTSUPP);
 }
-
-static inline void mlx5_rdma_netdev_free(struct net_device *netdev) {}
 #else
 struct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,
 					  struct ib_device *ibdev,
 					  const char *name,
 					  void (*setup)(struct net_device *));
-void mlx5_rdma_netdev_free(struct net_device *netdev);
 #endif /* CONFIG_MLX5_CORE_IPOIB */
 
 struct mlx5_profile {

commit 358aa5ce288aa1085f0f3ef9f315119563fa6541
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Wed May 9 13:28:00 2018 -0700

    net/mlx5e: Vxlan, move vxlan logic to core driver
    
    Move vxlan logic and objects to mlx5 core dirver.
    Since it going to be used from different mlx5 interfaces.
    e.g. mlx5e PF NIC netdev and mlx5e E-Switch representors.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index fd0aaa5568fe..54f385cc8811 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -818,6 +818,7 @@ struct mlx5_clock {
 };
 
 struct mlx5_fw_tracer;
+struct mlx5_vxlan;
 
 struct mlx5_core_dev {
 	struct pci_dev	       *pdev;
@@ -850,6 +851,7 @@ struct mlx5_core_dev {
 	atomic_t		num_qps;
 	u32			issi;
 	struct mlx5e_resources  mlx5e_res;
+	struct mlx5_vxlan       *vxlan;
 	struct {
 		struct mlx5_rsvd_gids	reserved_gids;
 		u32			roce_en;

commit 19725496da5602b401eae389736ab00d1817e264
Merge: aea5f654e6b7 9981b4fb8684
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jul 24 19:21:58 2018 -0700

    Merge ra.kernel.org:/pub/scm/linux/kernel/git/davem/net

commit f53aaa31cce7b543e407da7e97690a700206f7b9
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Mon Jul 16 15:22:01 2018 -0700

    net/mlx5: FW tracer, implement tracer logic
    
    Implement FW tracer logic and registers access, initialization and
    cleanup flows.
    
    Initializing the tracer will be part of load one flow, as multiple
    PFs will try to acquire ownership but only one will succeed and will
    be the tracer owner.
    
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 957199c20a0f..86cb0ebf92fa 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -816,6 +816,8 @@ struct mlx5_clock {
 	struct mlx5_pps            pps_info;
 };
 
+struct mlx5_fw_tracer;
+
 struct mlx5_core_dev {
 	struct pci_dev	       *pdev;
 	/* sync pci state */
@@ -860,6 +862,7 @@ struct mlx5_core_dev {
 	struct mlx5_clock        clock;
 	struct mlx5_ib_clock_info  *clock_info;
 	struct page             *clock_info_page;
+	struct mlx5_fw_tracer   *tracer;
 };
 
 struct mlx5_db {

commit d7037ad73daa9598b8caa7d5fdf41e8ceee6ef73
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Sun Jul 8 12:14:59 2018 +0300

    net/mlx5: Fix QP fragmented buffer allocation
    
    Fix bad alignment of SQ buffer in fragmented QP allocation.
    It should start directly after RQ buffer ends.
    
    Take special care of the end case where the RQ buffer does not occupy
    a whole page. RQ size is a power of two, so would be the case only for
    small RQ sizes (RQ size < PAGE_SIZE).
    
    Fix wrong assignments for sqb->size (mistakenly assigned RQ size),
    and for npages value of RQ and SQ.
    
    Fixes: 3a2f70331226 ("net/mlx5: Use order-0 allocations for all WQ types")
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 80cbb7fdce4a..83957920653a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -358,6 +358,7 @@ struct mlx5_frag_buf_ctrl {
 	struct mlx5_frag_buf	frag_buf;
 	u32			sz_m1;
 	u32			frag_sz_m1;
+	u32			strides_offset;
 	u8			log_sz;
 	u8			log_stride;
 	u8			log_frag_strides;
@@ -983,14 +984,22 @@ static inline u32 mlx5_base_mkey(const u32 key)
 	return key & 0xffffff00u;
 }
 
-static inline void mlx5_fill_fbc(u8 log_stride, u8 log_sz,
-				 struct mlx5_frag_buf_ctrl *fbc)
+static inline void mlx5_fill_fbc_offset(u8 log_stride, u8 log_sz,
+					u32 strides_offset,
+					struct mlx5_frag_buf_ctrl *fbc)
 {
 	fbc->log_stride = log_stride;
 	fbc->log_sz     = log_sz;
 	fbc->sz_m1	= (1 << fbc->log_sz) - 1;
 	fbc->log_frag_strides = PAGE_SHIFT - fbc->log_stride;
 	fbc->frag_sz_m1	= (1 << fbc->log_frag_strides) - 1;
+	fbc->strides_offset = strides_offset;
+}
+
+static inline void mlx5_fill_fbc(u8 log_stride, u8 log_sz,
+				 struct mlx5_frag_buf_ctrl *fbc)
+{
+	mlx5_fill_fbc_offset(log_stride, log_sz, 0, fbc);
 }
 
 static inline void mlx5_core_init_cq_frag_buf(struct mlx5_frag_buf_ctrl *fbc,
@@ -1004,7 +1013,10 @@ static inline void mlx5_core_init_cq_frag_buf(struct mlx5_frag_buf_ctrl *fbc,
 static inline void *mlx5_frag_buf_get_wqe(struct mlx5_frag_buf_ctrl *fbc,
 					  u32 ix)
 {
-	unsigned int frag = (ix >> fbc->log_frag_strides);
+	unsigned int frag;
+
+	ix  += fbc->strides_offset;
+	frag = ix >> fbc->log_frag_strides;
 
 	return fbc->frag_buf.frags[frag].buf +
 		((fbc->frag_sz_m1 & ix) << fbc->log_stride);

commit 5e022dd353b74132bf216a77b169c43e39f5be9e
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Jul 16 18:35:31 2018 -0700

    net/mlx5: Expose MPEGC (Management PCIe General Configuration) structures
    
    This patch exposes PRM layout for handling MPEGC (Management PCIe
    General Configuration).
    
    This will be used in the downstream patch for configuring MPEGC via the
    driver.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Reviewed-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4a4125b4279d..957199c20a0f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -145,6 +145,7 @@ enum {
 	MLX5_REG_MPCNT		 = 0x9051,
 	MLX5_REG_MTPPS		 = 0x9053,
 	MLX5_REG_MTPPSE		 = 0x9054,
+	MLX5_REG_MPEGC		 = 0x9056,
 	MLX5_REG_MCQI		 = 0x9061,
 	MLX5_REG_MCC		 = 0x9062,
 	MLX5_REG_MCDA		 = 0x9063,

commit eff8ea8f24eac76bc21c25e4ca4ac4ee2dade846
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Mon Jul 16 18:35:30 2018 -0700

    net/mlx5: FW tracer, add hardware structures
    
    This change adds the infrastructure to mlx5 core fw tracer.
    It introduces the following 4 new registers:
    MLX5_REG_MTRC_CAP  - Used to read tracer capabilities
    MLX5_REG_MTRC_CONF - Used to set tracer configurations
    MLX5_REG_MTRC_STDB - Used to query tracer strings database
    MLX5_REG_MTRC_CTRL - Used to control the tracer
    
    The capability of the tracing can be checked using mcam access
    register, therefore, the mcam access register interface will expose
    the tracer register.
    
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1cb1c0317b77..4a4125b4279d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -138,6 +138,10 @@ enum {
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 	MLX5_REG_MCIA		 = 0x9014,
 	MLX5_REG_MLCR		 = 0x902b,
+	MLX5_REG_MTRC_CAP	 = 0x9040,
+	MLX5_REG_MTRC_CONF	 = 0x9041,
+	MLX5_REG_MTRC_STDB	 = 0x9042,
+	MLX5_REG_MTRC_CTRL	 = 0x9043,
 	MLX5_REG_MPCNT		 = 0x9051,
 	MLX5_REG_MTPPS		 = 0x9053,
 	MLX5_REG_MTPPSE		 = 0x9054,

commit 4d4fb5dc988a36307711be292bde6e39b8bdbceb
Author: Yonatan Cohen <yonatanc@mellanox.com>
Date:   Tue Jun 19 08:47:22 2018 +0300

    net/mlx5: Limit scope of dump_fill_mkey function
    
    mlx5_core_dump_fill_mkey() is going to be used in next
    patch in IB and doesn't need to be visible to whole
    mlx5_core. Move that command to mlx5_ib.
    
    Signed-off-by: Yonatan Cohen <yonatanc@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 80cbb7fdce4a..1cb1c0317b77 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1067,8 +1067,6 @@ int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev,
 			   struct mlx5_core_mkey *mkey);
 int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mkey *mkey,
 			 u32 *out, int outlen);
-int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mkey *_mkey,
-			     u32 *mkey);
 int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
 int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
 int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, const void *inb, void *outb,

commit 3a2f70331226c140e5aa27ee6bbe2a5c618acb4c
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Apr 4 12:54:23 2018 +0300

    net/mlx5: Use order-0 allocations for all WQ types
    
    Complete the transition of all WQ types to use fragmented
    order-0 coherent memory instead of high-order allocations.
    
    CQ-WQ already uses order-0.
    Here we do the same for cyclic and linked-list WQs.
    
    This allows the driver to load cleanly on systems with a highly
    fragmented coherent memory.
    
    Performance tests:
    ConnectX-5 100Gbps, CPU: Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    Packet rate of 64B packets, single transmit ring, size 8K.
    
    No degradation is sensed.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 92d292454351..80cbb7fdce4a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -983,16 +983,24 @@ static inline u32 mlx5_base_mkey(const u32 key)
 	return key & 0xffffff00u;
 }
 
-static inline void mlx5_core_init_cq_frag_buf(struct mlx5_frag_buf_ctrl *fbc,
-					      void *cqc)
+static inline void mlx5_fill_fbc(u8 log_stride, u8 log_sz,
+				 struct mlx5_frag_buf_ctrl *fbc)
 {
-	fbc->log_stride	= 6 + MLX5_GET(cqc, cqc, cqe_sz);
-	fbc->log_sz	= MLX5_GET(cqc, cqc, log_cq_size);
+	fbc->log_stride = log_stride;
+	fbc->log_sz     = log_sz;
 	fbc->sz_m1	= (1 << fbc->log_sz) - 1;
 	fbc->log_frag_strides = PAGE_SHIFT - fbc->log_stride;
 	fbc->frag_sz_m1	= (1 << fbc->log_frag_strides) - 1;
 }
 
+static inline void mlx5_core_init_cq_frag_buf(struct mlx5_frag_buf_ctrl *fbc,
+					      void *cqc)
+{
+	mlx5_fill_fbc(6 + MLX5_GET(cqc, cqc, cqe_sz),
+		      MLX5_GET(cqc, cqc, log_cq_size),
+		      fbc);
+}
+
 static inline void *mlx5_frag_buf_get_wqe(struct mlx5_frag_buf_ctrl *fbc,
 					  u32 ix)
 {

commit 50b4a3c23646254c7345f3663ff1e0a6cbcd9abb
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Fri Mar 2 15:47:01 2018 -0600

    net/mlx5: PPTB and PBMC register firmware command support
    
    Add firmware command interface to read and write PPTB and PBMC
    registers.
    
    PPTB register enables mappings priority to a specific receive buffer.
    
    PBMC registers enables changing the receive buffer's configuration such
    as buffer size, xon/xoff thresholds, buffer's lossy property and
    buffer's shared property.
    
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d703774982ca..92d292454351 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -124,6 +124,8 @@ enum {
 	MLX5_REG_PAOS		 = 0x5006,
 	MLX5_REG_PFCC            = 0x5007,
 	MLX5_REG_PPCNT		 = 0x5008,
+	MLX5_REG_PPTB            = 0x500b,
+	MLX5_REG_PBMC            = 0x500c,
 	MLX5_REG_PMAOS		 = 0x5012,
 	MLX5_REG_PUDE		 = 0x5009,
 	MLX5_REG_PMPE		 = 0x5010,

commit e3ca34880652250f524022ad89e516f8ba9a805b
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon May 14 15:38:10 2018 -0700

    net/mlx5: Fix build break when CONFIG_SMP=n
    
    Avoid using the kernel's irq_descriptor and return IRQ vector affinity
    directly from the driver.
    
    This fixes the following build break when CONFIG_SMP=n
    
    include/linux/mlx5/driver.h: In function ‘mlx5_get_vector_affinity_hint’:
    include/linux/mlx5/driver.h:1299:13: error:
            ‘struct irq_desc’ has no member named ‘affinity_hint’
    
    Fixes: 6082d9c9c94a ("net/mlx5: Fix mlx5_get_vector_affinity function")
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    CC: Randy Dunlap <rdunlap@infradead.org>
    CC: Guenter Roeck <linux@roeck-us.net>
    CC: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Israel Rukshin <israelr@mellanox.com>
    Reported-by: kbuild test robot <lkp@intel.com>
    Reported-by: Randy Dunlap <rdunlap@infradead.org>
    Tested-by: Randy Dunlap <rdunlap@infradead.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2a156c5dfadd..d703774982ca 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1286,17 +1286,7 @@ enum {
 static inline const struct cpumask *
 mlx5_get_vector_affinity_hint(struct mlx5_core_dev *dev, int vector)
 {
-	struct irq_desc *desc;
-	unsigned int irq;
-	int eqn;
-	int err;
-
-	err = mlx5_vector2eqn(dev, vector, &eqn, &irq);
-	if (err)
-		return NULL;
-
-	desc = irq_to_desc(irq);
-	return desc->affinity_hint;
+	return dev->priv.irq_info[vector].mask;
 }
 
 #endif /* MLX5_DRIVER_H */

commit 6082d9c9c94a408d7409b5f2e4e42ac9e8b16d0d
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Thu Apr 12 09:49:11 2018 +0000

    net/mlx5: Fix mlx5_get_vector_affinity function
    
    Adding the vector offset when calling to mlx5_vector2eqn() is wrong.
    This is because mlx5_vector2eqn() checks if EQ index is equal to vector number
    and the fact that the internal completion vectors that mlx5 allocates
    don't get an EQ index.
    
    The second problem here is that using effective_affinity_mask gives the same
    CPU for different vectors.
    This leads to unmapped queues when calling it from blk_mq_rdma_map_queues().
    This doesn't happen when using affinity_hint mask.
    
    Fixes: 2572cf57d75a ("mlx5: fix mlx5_get_vector_affinity to start from completion vector 0")
    Fixes: 05e0cc84e00c ("net/mlx5: Fix get vector affinity helper function")
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 767d193c269a..2a156c5dfadd 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1284,25 +1284,19 @@ enum {
 };
 
 static inline const struct cpumask *
-mlx5_get_vector_affinity(struct mlx5_core_dev *dev, int vector)
+mlx5_get_vector_affinity_hint(struct mlx5_core_dev *dev, int vector)
 {
-	const struct cpumask *mask;
 	struct irq_desc *desc;
 	unsigned int irq;
 	int eqn;
 	int err;
 
-	err = mlx5_vector2eqn(dev, MLX5_EQ_VEC_COMP_BASE + vector, &eqn, &irq);
+	err = mlx5_vector2eqn(dev, vector, &eqn, &irq);
 	if (err)
 		return NULL;
 
 	desc = irq_to_desc(irq);
-#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK
-	mask = irq_data_get_effective_affinity_mask(&desc->irq_data);
-#else
-	mask = desc->irq_common_data.affinity;
-#endif
-	return mask;
+	return desc->affinity_hint;
 }
 
 #endif /* MLX5_DRIVER_H */

commit 05d3ac978ed25b753bfe34fe76c50c31ee506a82
Author: Bodong Wang <bodong@mellanox.com>
Date:   Mon Mar 19 15:10:29 2018 +0200

    net/mlx5: Packet pacing enhancement
    
    Add two new parameters: max_burst_sz and typical_pkt_size (both
    in bytes) to rate limit configurations.
    
    max_burst_sz: The device will schedule bursts of packets for an
    SQ connected to this rate, smaller than or equal to this value.
    Value 0x0 indicates packet bursts will be limited to the device
    defaults. This field should be used if bursts of packets must be
    strictly kept under a certain value.
    
    typical_pkt_size: When the rate limit is intended for a stream of
    similar packets, stating the typical packet size can improve the
    accuracy of the rate limiter. The expected packet size will be
    the same for all SQs associated with the same rate limit index.
    
    Ethernet driver is updated according to this change, but these two
    parameters will be kept as 0 due to lacking of proper way to get the
    configurations from user space which requires to change
    ndo_set_tx_maxrate interface.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Reviewed-by: Daniel Jurgens <danielj@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index cded85ab6fe4..767d193c269a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -591,8 +591,14 @@ struct mlx5_eswitch;
 struct mlx5_lag;
 struct mlx5_pagefault;
 
+struct mlx5_rate_limit {
+	u32			rate;
+	u32			max_burst_sz;
+	u16			typical_pkt_sz;
+};
+
 struct mlx5_rl_entry {
-	u32                     rate;
+	struct mlx5_rate_limit	rl;
 	u16                     index;
 	u16                     refcount;
 };
@@ -1107,9 +1113,12 @@ int mlx5_core_page_fault_resume(struct mlx5_core_dev *dev, u32 token,
 
 int mlx5_init_rl_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_rl_table(struct mlx5_core_dev *dev);
-int mlx5_rl_add_rate(struct mlx5_core_dev *dev, u32 rate, u16 *index);
-void mlx5_rl_remove_rate(struct mlx5_core_dev *dev, u32 rate);
+int mlx5_rl_add_rate(struct mlx5_core_dev *dev, u16 *index,
+		     struct mlx5_rate_limit *rl);
+void mlx5_rl_remove_rate(struct mlx5_core_dev *dev, struct mlx5_rate_limit *rl);
 bool mlx5_rl_is_in_range(struct mlx5_core_dev *dev, u32 rate);
+bool mlx5_rl_are_equal(struct mlx5_rate_limit *rl_0,
+		       struct mlx5_rate_limit *rl_1);
 int mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,
 		     bool map_wc, bool fast_path);
 void mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg);

commit 2d873449a202d02e0c4d90009fb2beb7013ac575
Merge: 06892cc19055 bd8602ca42f6
Author: Doug Ledford <dledford@redhat.com>
Date:   Wed Mar 14 18:49:12 2018 -0400

    Merge branch 'k.o/wip/dl-for-rc' into k.o/wip/dl-for-next
    
    Due to bug fixes found by the syzkaller bot and taken into the for-rc
    branch after development for the 4.17 merge window had already started
    being taken into the for-next branch, there were fairly non-trivial
    merge issues that would need to be resolved between the for-rc branch
    and the for-next branch.  This merge resolves those conflicts and
    provides a unified base upon which ongoing development for 4.17 can
    be based.
    
    Conflicts:
            drivers/infiniband/hw/mlx5/main.c - Commit 42cea83f9524
            (IB/mlx5: Fix cleanup order on unload) added to for-rc and
            commit b5ca15ad7e61 (IB/mlx5: Add proper representors support)
            add as part of the devel cycle both needed to modify the
            init/de-init functions used by mlx5.  To support the new
            representors, the new functions added by the cleanup patch
            needed to be made non-static, and the init/de-init list
            added by the representors patch needed to be modified to
            match the init/de-init list changes made by the cleanup
            patch.
    Updates:
            drivers/infiniband/hw/mlx5/mlx5_ib.h - Update function
            prototypes added by representors patch to reflect new function
            names as changed by cleanup patch
            drivers/infiniband/hw/mlx5/ib_rep.c - Update init/de-init
            stage list to match new order from cleanup patch
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

commit c2b37f76485f073f020e60b5954b6dc4e55f693c
Author: Boris Pismenny <borisp@mellanox.com>
Date:   Thu Mar 8 15:51:41 2018 +0200

    IB/mlx5: Fix integer overflows in mlx5_ib_create_srq
    
    This patch validates user provided input to prevent integer overflow due
    to integer manipulation in the mlx5_ib_create_srq function.
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Fixes: e126ba97dba9 ("mlx5: Add driver for Mellanox Connect-IB adapters")
    Signed-off-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6ed79a8a8318..9d3a03364e6e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -453,8 +453,8 @@ struct mlx5_core_srq {
 	struct mlx5_core_rsc_common	common; /* must be first */
 	u32		srqn;
 	int		max;
-	int		max_gs;
-	int		max_avail_gather;
+	size_t		max_gs;
+	size_t		max_avail_gather;
 	int		wqe_shift;
 	void (*event)	(struct mlx5_core_srq *, enum mlx5_event);
 

commit 57cbd893c4c575a24594fa6c0835247506ce26e2
Author: Mark Bloch <markb@mellanox.com>
Date:   Tue Jan 16 14:04:14 2018 +0000

    net/mlx5: E-Switch, Move representors definition to a global scope
    
    In preparation for IB representors, move representors structs to a global
    scope, also expose functions needed for registration, unregistration,
    eswitch mode and creating a flow rule to direct traffic from SQs to the
    right VF.
    
    Signed-off-by: Mark Bloch <markb@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index bfea26af6de5..4814cad7456e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1224,6 +1224,12 @@ static inline int mlx5_core_is_pf(struct mlx5_core_dev *dev)
 	return !(dev->priv.pci_dev_data & MLX5_PCI_DEV_IS_VF);
 }
 
+#define MLX5_TOTAL_VPORTS(mdev) (1 + pci_sriov_get_totalvfs((mdev)->pdev))
+#define MLX5_VPORT_MANAGER(mdev) \
+	(MLX5_CAP_GEN(mdev, vport_group_manager) && \
+	 (MLX5_CAP_GEN(mdev, port_type) == MLX5_CAP_PORT_TYPE_ETH) && \
+	 mlx5_core_is_pf(mdev))
+
 static inline int mlx5_get_gid_table_len(u16 param)
 {
 	if (param > 4) {

commit 388ca8be00370db132464e27f745b8a0add19fcb
Author: Yonatan Cohen <yonatanc@mellanox.com>
Date:   Tue Jan 2 16:08:06 2018 +0200

    IB/mlx5: Implement fragmented completion queue (CQ)
    
    The current implementation of create CQ requires contiguous
    memory, such requirement is problematic once the memory is
    fragmented or the system is low in memory, it causes for
    failures in dma_zalloc_coherent().
    
    This patch implements new scheme of fragmented CQ to overcome
    this issue by introducing new type: 'struct mlx5_frag_buf_ctrl'
    to allocate fragmented buffers, rather than contiguous ones.
    
    Base the Completion Queues (CQs) on this new fragmented buffer.
    
    It fixes following crashes:
    kworker/29:0: page allocation failure: order:6, mode:0x80d0
    CPU: 29 PID: 8374 Comm: kworker/29:0 Tainted: G OE 3.10.0
    Workqueue: ib_cm cm_work_handler [ib_cm]
    Call Trace:
    [<>] dump_stack+0x19/0x1b
    [<>] warn_alloc_failed+0x110/0x180
    [<>] __alloc_pages_slowpath+0x6b7/0x725
    [<>] __alloc_pages_nodemask+0x405/0x420
    [<>] dma_generic_alloc_coherent+0x8f/0x140
    [<>] x86_swiotlb_alloc_coherent+0x21/0x50
    [<>] mlx5_dma_zalloc_coherent_node+0xad/0x110 [mlx5_core]
    [<>] ? mlx5_db_alloc_node+0x69/0x1b0 [mlx5_core]
    [<>] mlx5_buf_alloc_node+0x3e/0xa0 [mlx5_core]
    [<>] mlx5_buf_alloc+0x14/0x20 [mlx5_core]
    [<>] create_cq_kernel+0x90/0x1f0 [mlx5_ib]
    [<>] mlx5_ib_create_cq+0x3b0/0x4e0 [mlx5_ib]
    
    Signed-off-by: Yonatan Cohen <yonatanc@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2860a253275b..bfea26af6de5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -345,13 +345,6 @@ struct mlx5_buf_list {
 	dma_addr_t		map;
 };
 
-struct mlx5_buf {
-	struct mlx5_buf_list	direct;
-	int			npages;
-	int			size;
-	u8			page_shift;
-};
-
 struct mlx5_frag_buf {
 	struct mlx5_buf_list	*frags;
 	int			npages;
@@ -359,6 +352,15 @@ struct mlx5_frag_buf {
 	u8			page_shift;
 };
 
+struct mlx5_frag_buf_ctrl {
+	struct mlx5_frag_buf	frag_buf;
+	u32			sz_m1;
+	u32			frag_sz_m1;
+	u8			log_sz;
+	u8			log_stride;
+	u8			log_frag_strides;
+};
+
 struct mlx5_eq_tasklet {
 	struct list_head list;
 	struct list_head process_list;
@@ -386,7 +388,7 @@ struct mlx5_eq {
 	struct mlx5_cq_table	cq_table;
 	__be32 __iomem	       *doorbell;
 	u32			cons_index;
-	struct mlx5_buf		buf;
+	struct mlx5_frag_buf	buf;
 	int			size;
 	unsigned int		irqn;
 	u8			eqn;
@@ -932,9 +934,9 @@ struct mlx5_hca_vport_context {
 	bool			grh_required;
 };
 
-static inline void *mlx5_buf_offset(struct mlx5_buf *buf, int offset)
+static inline void *mlx5_buf_offset(struct mlx5_frag_buf *buf, int offset)
 {
-		return buf->direct.buf + offset;
+		return buf->frags->buf + offset;
 }
 
 #define STRUCT_FIELD(header, field) \
@@ -973,6 +975,25 @@ static inline u32 mlx5_base_mkey(const u32 key)
 	return key & 0xffffff00u;
 }
 
+static inline void mlx5_core_init_cq_frag_buf(struct mlx5_frag_buf_ctrl *fbc,
+					      void *cqc)
+{
+	fbc->log_stride	= 6 + MLX5_GET(cqc, cqc, cqe_sz);
+	fbc->log_sz	= MLX5_GET(cqc, cqc, log_cq_size);
+	fbc->sz_m1	= (1 << fbc->log_sz) - 1;
+	fbc->log_frag_strides = PAGE_SHIFT - fbc->log_stride;
+	fbc->frag_sz_m1	= (1 << fbc->log_frag_strides) - 1;
+}
+
+static inline void *mlx5_frag_buf_get_wqe(struct mlx5_frag_buf_ctrl *fbc,
+					  u32 ix)
+{
+	unsigned int frag = (ix >> fbc->log_frag_strides);
+
+	return fbc->frag_buf.frags[frag].buf +
+		((fbc->frag_sz_m1 & ix) << fbc->log_stride);
+}
+
 int mlx5_cmd_init(struct mlx5_core_dev *dev);
 void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
@@ -998,9 +1019,10 @@ void mlx5_drain_health_wq(struct mlx5_core_dev *dev);
 void mlx5_trigger_health_work(struct mlx5_core_dev *dev);
 void mlx5_drain_health_recovery(struct mlx5_core_dev *dev);
 int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
-			struct mlx5_buf *buf, int node);
-int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, struct mlx5_buf *buf);
-void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_buf *buf);
+			struct mlx5_frag_buf *buf, int node);
+int mlx5_buf_alloc(struct mlx5_core_dev *dev,
+		   int size, struct mlx5_frag_buf *buf);
+void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_frag_buf *buf);
 int mlx5_frag_buf_alloc_node(struct mlx5_core_dev *dev, int size,
 			     struct mlx5_frag_buf *buf, int node);
 void mlx5_frag_buf_free(struct mlx5_core_dev *dev, struct mlx5_frag_buf *buf);
@@ -1045,7 +1067,8 @@ int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);
 int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);
 void mlx5_register_debugfs(void);
 void mlx5_unregister_debugfs(void);
-void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
+
+void mlx5_fill_page_array(struct mlx5_frag_buf *buf, __be64 *pas);
 void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);

commit 3ec5693b17314b58977ba3c8d720d1f9cfef39f8
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Feb 1 05:42:06 2018 -0800

    net/mlx5: Remove redundant EQ API exports
    
    EQ structure and API is private to mlx5_core driver only, external
    drivers should not have access or the means to manipulate EQ objects.
    
    Remove redundant exports and move API functions out of the linux/mlx5
    include directory into the driver's mlx5_core.h private include file.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Gal Pressman <galp@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 09e2f3e8753c..2860a253275b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1045,20 +1045,11 @@ int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);
 int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);
 void mlx5_register_debugfs(void);
 void mlx5_unregister_debugfs(void);
-int mlx5_eq_init(struct mlx5_core_dev *dev);
-void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
 void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
 void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
-void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced);
-int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
-		       int nent, u64 mask, const char *name,
-		       enum mlx5_eq_type type);
-int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
-int mlx5_start_eqs(struct mlx5_core_dev *dev);
-void mlx5_stop_eqs(struct mlx5_core_dev *dev);
 int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn,
 		    unsigned int *irqn);
 int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
@@ -1070,14 +1061,6 @@ int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
 			 int size_in, void *data_out, int size_out,
 			 u16 reg_num, int arg, int write);
 
-int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
-void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
-int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
-		       u32 *out, int outlen);
-int mlx5_eq_debugfs_init(struct mlx5_core_dev *dev);
-void mlx5_eq_debugfs_cleanup(struct mlx5_core_dev *dev);
-int mlx5_cq_debugfs_init(struct mlx5_core_dev *dev);
-void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db);
 int mlx5_db_alloc_node(struct mlx5_core_dev *dev, struct mlx5_db *db,
 		       int node);

commit 3ac7afdbcf243d6c79c1569d9e29aef0096e4743
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Feb 1 04:37:07 2018 -0800

    net/mlx5: Move CQ completion and event forwarding logic to eq.c
    
    Since CQ tree is now per EQ, CQ completion and event forwarding became
    specific implementation of EQ logic, this patch moves that logic to eq.c
    and makes those functions static.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Gal Pressman <galp@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 96e003db2bcd..09e2f3e8753c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1049,12 +1049,10 @@ int mlx5_eq_init(struct mlx5_core_dev *dev);
 void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
 void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
 void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
-void mlx5_cq_completion(struct mlx5_eq *eq, u32 cqn);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
 void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced);
-void mlx5_cq_event(struct mlx5_eq *eq, u32 cqn, int event_type);
 int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 		       int nent, u64 mask, const char *name,
 		       enum mlx5_eq_type type);

commit 02d92f7903647119e125b24f5470f96cee0d4b4b
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Fri Jan 19 16:13:01 2018 -0800

    net/mlx5: CQ Database per EQ
    
    Before this patch the driver had one CQ database protected via one
    spinlock, this spinlock is meant to synchronize between CQ
    adding/removing and CQ IRQ interrupt handling.
    
    On a system with large number of CPUs and on a work load that requires
    lots of interrupts, this global spinlock becomes a very nasty hotspot
    and introduces a contention between the active cores, which will
    significantly hurt performance and becomes a bottleneck that prevents
    seamless cpu scaling.
    
    To solve this we simply move the CQ database and its spinlock to be per
    EQ (IRQ), thus per core.
    
    Tested with:
    system: 2 sockets, 14 cores per socket, hyperthreading, 2x14x2=56 cores
    netperf command: ./super_netperf 200 -P 0 -t TCP_RR  -H <server> -l 30 -- -r 300,300 -o -s 1M,1M -S 1M,1M
    
    WITHOUT THIS PATCH:
    Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft %steal  %guest  %gnice   %idle
    Average:     all    4.32    0.00   36.15    0.09    0.00   34.02   0.00    0.00    0.00   25.41
    
    Samples: 2M of event 'cycles:pp', Event count (approx.): 1554616897271
    Overhead  Command          Shared Object                 Symbol
    +   14.28%  swapper          [kernel.vmlinux]              [k] intel_idle
    +   12.25%  swapper          [kernel.vmlinux]              [k] queued_spin_lock_slowpath
    +   10.29%  netserver        [kernel.vmlinux]              [k] queued_spin_lock_slowpath
    +    1.32%  netserver        [kernel.vmlinux]              [k] mlx5e_xmit
    
    WITH THIS PATCH:
    Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
    Average:     all    4.27    0.00   34.31    0.01    0.00   18.71    0.00    0.00    0.00   42.69
    
    Samples: 2M of event 'cycles:pp', Event count (approx.): 1498132937483
    Overhead  Command          Shared Object             Symbol
    +   23.33%  swapper          [kernel.vmlinux]          [k] intel_idle
    +    1.69%  netserver        [kernel.vmlinux]          [k] mlx5e_xmit
    
    Tested-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Gal Pressman <galp@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6ed79a8a8318..96e003db2bcd 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -375,8 +375,15 @@ struct mlx5_eq_pagefault {
 	mempool_t		*pool;
 };
 
+struct mlx5_cq_table {
+	/* protect radix tree */
+	spinlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
 struct mlx5_eq {
 	struct mlx5_core_dev   *dev;
+	struct mlx5_cq_table	cq_table;
 	__be32 __iomem	       *doorbell;
 	u32			cons_index;
 	struct mlx5_buf		buf;
@@ -526,13 +533,6 @@ struct mlx5_core_health {
 	struct delayed_work		recover_work;
 };
 
-struct mlx5_cq_table {
-	/* protect radix tree
-	 */
-	spinlock_t		lock;
-	struct radix_tree_root	tree;
-};
-
 struct mlx5_qp_table {
 	/* protect radix tree
 	 */
@@ -654,10 +654,6 @@ struct mlx5_priv {
 	struct dentry	       *cmdif_debugfs;
 	/* end: qp staff */
 
-	/* start: cq staff */
-	struct mlx5_cq_table	cq_table;
-	/* end: cq staff */
-
 	/* start: mkey staff */
 	struct mlx5_mkey_table	mkey_table;
 	/* end: mkey staff */
@@ -1053,12 +1049,12 @@ int mlx5_eq_init(struct mlx5_core_dev *dev);
 void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
 void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
 void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
-void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
+void mlx5_cq_completion(struct mlx5_eq *eq, u32 cqn);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
 void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced);
-void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
+void mlx5_cq_event(struct mlx5_eq *eq, u32 cqn, int event_type);
 int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 		       int nent, u64 mask, const char *name,
 		       enum mlx5_eq_type type);

commit 2572cf57d75a7f91835d9a38771e9e76d575d122
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Mon Feb 5 16:24:52 2018 +0200

    mlx5: fix mlx5_get_vector_affinity to start from completion vector 0
    
    The consumers of this routine expects the affinity map of of vector
    index relative to the first completion vector. The upper layers are
    not aware of internal/private completion vectors that mlx5 allocates
    for its own usage.
    
    Hence, return the affinity map of vector index relative to the first
    completion vector.
    
    Fixes: 05e0cc84e00c ("net/mlx5: Fix get vector affinity helper function")
    Reported-by: Logan Gunthorpe <logang@deltatee.com>
    Tested-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Cc: <stable@vger.kernel.org> # v4.15
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index fb7e8b205eb9..6ed79a8a8318 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1277,7 +1277,7 @@ mlx5_get_vector_affinity(struct mlx5_core_dev *dev, int vector)
 	int eqn;
 	int err;
 
-	err = mlx5_vector2eqn(dev, vector, &eqn, &irq);
+	err = mlx5_vector2eqn(dev, MLX5_EQ_VEC_COMP_BASE + vector, &eqn, &irq);
 	if (err)
 		return NULL;
 

commit e7996a9a77fc669387da43ff4823b91cc4872bd0
Merge: b5fa635aab8f d8a5b80568a9
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Mon Jan 29 13:26:40 2018 -0700

    Merge tag v4.15 of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git
    
    To resolve conflicts in:
     drivers/infiniband/hw/mlx5/main.c
     drivers/infiniband/hw/mlx5/qp.c
    
    From patches merged into the -rc cycle. The conflict resolution matches
    what linux-next has been carrying.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 24d33d2c8e92abffe1f0653d42fc65b8f164a6d9
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Tue Jan 16 20:08:40 2018 +0200

    net/mlx5e: Add clock info page to mlx5 core devices
    
    Adds a new page to mlx5 core containing clock info data that allows
    user level applications to translate between cqe timestamp to
    nanoseconds. The information stored into this page is represented
    through mlx5_ib_clock_info.
    
    In order to synchronize between kernel and user space a sequence
    number is incremented at the beginning and end of each update.
    An odd number means the data is being updated while an even means
    the access was already done. To guarantee that the data structure
    was accessed atomically user will:
    
    repeat:
            seq1 = <read sequence>
            goto <repeate> while odd
            <read data structure>
            seq2 = <read sequence>
            if seq1 != seq2 goto repeat
    
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Reviewed-by: Jason Gunthorpe <jgg@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Eitan Rabin <rabin@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9136e35f2f7e..c403151133e9 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -797,6 +797,7 @@ struct mlx5_clock {
 	u32                        nominal_c_mult;
 	unsigned long              overflow_period;
 	struct delayed_work        overflow_work;
+	struct mlx5_core_dev      *mdev;
 	struct ptp_clock          *ptp;
 	struct ptp_clock_info      ptp_info;
 	struct mlx5_pps            pps_info;
@@ -844,6 +845,8 @@ struct mlx5_core_dev {
 	struct cpu_rmap         *rmap;
 #endif
 	struct mlx5_clock        clock;
+	struct mlx5_ib_clock_info  *clock_info;
+	struct page             *clock_info_page;
 };
 
 struct mlx5_db {

commit 05e0cc84e00c54fb152d1f4b86bc211823a83d0c
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Jan 4 04:35:51 2018 +0200

    net/mlx5: Fix get vector affinity helper function
    
    mlx5_get_vector_affinity used to call pci_irq_get_affinity and after
    reverting the patch that sets the device affinity via PCI_IRQ_AFFINITY
    API, calling pci_irq_get_affinity becomes useless and it breaks RDMA
    mlx5 users.  To fix this, this patch provides an alternative way to
    retrieve IRQ vector affinity using legacy IRQ API, following
    smp_affinity read procfs implementation.
    
    Fixes: 231243c82793 ("Revert mlx5: move affinity hints assignments to generic code")
    Fixes: a435393acafb ("mlx5: move affinity hints assignments to generic code")
    Cc: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1f509d072026..a0610427e168 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -36,6 +36,7 @@
 #include <linux/kernel.h>
 #include <linux/completion.h>
 #include <linux/pci.h>
+#include <linux/irq.h>
 #include <linux/spinlock_types.h>
 #include <linux/semaphore.h>
 #include <linux/slab.h>
@@ -1231,7 +1232,23 @@ enum {
 static inline const struct cpumask *
 mlx5_get_vector_affinity(struct mlx5_core_dev *dev, int vector)
 {
-	return pci_irq_get_affinity(dev->pdev, MLX5_EQ_VEC_COMP_BASE + vector);
+	const struct cpumask *mask;
+	struct irq_desc *desc;
+	unsigned int irq;
+	int eqn;
+	int err;
+
+	err = mlx5_vector2eqn(dev, vector, &eqn, &irq);
+	if (err)
+		return NULL;
+
+	desc = irq_to_desc(irq);
+#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK
+	mask = irq_data_get_effective_affinity_mask(&desc->irq_data);
+#else
+	mask = desc->irq_common_data.affinity;
+#endif
+	return mask;
 }
 
 #endif /* MLX5_DRIVER_H */

commit cfe4e37fdcacbc33176cfc2430df96355ee14489
Author: Daniel Jurgens <danielj@mellanox.com>
Date:   Thu Jan 4 17:25:41 2018 +0200

    {net, IB}/mlx5: Change set_roce_gid to take a port number
    
    When in dual port mode setting a RoCE GID for any port flows through the
    master ports mlx5_core_dev. Provide an interface to set the port when
    sending this command.
    
    Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d5c787519e06..9136e35f2f7e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1112,7 +1112,7 @@ void mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg);
 unsigned int mlx5_core_reserved_gids_count(struct mlx5_core_dev *dev);
 int mlx5_core_roce_gid_set(struct mlx5_core_dev *dev, unsigned int index,
 			   u8 roce_version, u8 roce_l3_type, const u8 *gid,
-			   const u8 *mac, bool vlan, u16 vlan_id);
+			   const u8 *mac, bool vlan, u16 vlan_id, u8 port_num);
 
 static inline int fw_initializing(struct mlx5_core_dev *dev)
 {

commit 32f69e4be269739c3850cd20f1a3322e95c1145f
Author: Daniel Jurgens <danielj@mellanox.com>
Date:   Thu Jan 4 17:25:36 2018 +0200

    {net, IB}/mlx5: Manage port association for multiport RoCE
    
    When mlx5_ib_add is called determine if the mlx5 core device being
    added is capable of dual port RoCE operation. If it is, determine
    whether it is a master device or a slave device using the
    num_vhca_ports and affiliate_nic_vport_criteria capabilities.
    
    If the device is a slave, attempt to find a master device to affiliate it
    with. Devices that can be affiliated will share a system image guid. If
    none are found place it on a list of unaffiliated ports. If a master is
    found bind the port to it by configuring the port affiliation in the NIC
    vport context.
    
    Similarly when mlx5_ib_remove is called determine the port type. If it's
    a slave port, unaffiliate it from the master device, otherwise just
    remove it from the unaffiliated port list.
    
    The IB device is registered as a multiport device, even if a 2nd port is
    not available for affiliation. When the 2nd port is affiliated later the
    GID cache must be refreshed in order to get the default GIDs for the 2nd
    port in the cache. Export roce_rescan_device to provide a mechanism to
    refresh the cache after a new port is bound.
    
    In a multiport configuration all IB object (QP, MR, PD, etc) related
    commands should flow through the master mlx5_core_dev, other commands
    must be sent to the slave port mlx5_core_mdev, an interface is provide
    to get the correct mdev for non IB object commands.
    
    Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 28733529f6ff..d5c787519e06 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1234,9 +1234,29 @@ static inline bool mlx5_rl_is_supported(struct mlx5_core_dev *dev)
 	return !!(dev->priv.rl_table.max_size);
 }
 
+static inline int mlx5_core_is_mp_slave(struct mlx5_core_dev *dev)
+{
+	return MLX5_CAP_GEN(dev, affiliate_nic_vport_criteria) &&
+	       MLX5_CAP_GEN(dev, num_vhca_ports) <= 1;
+}
+
+static inline int mlx5_core_is_mp_master(struct mlx5_core_dev *dev)
+{
+	return MLX5_CAP_GEN(dev, num_vhca_ports) > 1;
+}
+
+static inline int mlx5_core_mp_enabled(struct mlx5_core_dev *dev)
+{
+	return mlx5_core_is_mp_slave(dev) ||
+	       mlx5_core_is_mp_master(dev);
+}
+
 static inline int mlx5_core_native_port_num(struct mlx5_core_dev *dev)
 {
-	return 1;
+	if (!mlx5_core_mp_enabled(dev))
+		return 1;
+
+	return MLX5_CAP_GEN(dev, native_port_num);
 }
 
 enum {

commit 7fd8aefb7ce202dd9d97f752bf249be6215f1004
Author: Daniel Jurgens <danielj@mellanox.com>
Date:   Thu Jan 4 17:25:35 2018 +0200

    IB/mlx5: Make netdev notifications multiport capable
    
    When multiple RoCE ports are supported registration for events on
    multiple netdevs is required. Refactor the event registration and
    handling to support multiple ports.
    
    Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5b0443c9d337..28733529f6ff 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1234,6 +1234,11 @@ static inline bool mlx5_rl_is_supported(struct mlx5_core_dev *dev)
 	return !!(dev->priv.rl_table.max_size);
 }
 
+static inline int mlx5_core_native_port_num(struct mlx5_core_dev *dev)
+{
+	return 1;
+}
+
 enum {
 	MLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,
 };

commit 734dc065fc41f6143ff88225aa5d335cb1e0f6aa
Author: Daniel Jurgens <danielj@mellanox.com>
Date:   Thu Jan 4 17:25:31 2018 +0200

    net/mlx5: Fix race for multiple RoCE enable
    
    There are two potential problems with the existing implementation.
    
    1. Enable and disable can race after the atomic operations.
    2. If a command fails the refcount is left in an inconsistent state.
    
    Introduce a lock and perform error checking.
    
    Fixes: a6f7d2aff623 ("net/mlx5: Add support for multiple RoCE enable")
    Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0776554f18dc..5b0443c9d337 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -835,7 +835,7 @@ struct mlx5_core_dev {
 	struct mlx5e_resources  mlx5e_res;
 	struct {
 		struct mlx5_rsvd_gids	reserved_gids;
-		atomic_t                roce_en;
+		u32			roce_en;
 	} roce;
 #ifdef CONFIG_MLX5_FPGA
 	struct mlx5_fpga_device *fpga;

commit 57cda166bbe045151d46b2d1133fdf4afccb90ed
Author: Moni Shoua <monis@mellanox.com>
Date:   Tue Jan 2 16:19:28 2018 +0200

    net/mlx5: Add DCT command interface
    
    Add a missing command interface to work with a DCT. It includes: creating,
    destroying and get events for.
    
    Signed-off-by: Moni Shoua <monis@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2fe263f69751..0776554f18dc 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -154,6 +154,13 @@ enum mlx5_dcbx_oper_mode {
 	MLX5E_DCBX_PARAM_VER_OPER_AUTO  = 0x3,
 };
 
+enum mlx5_dct_atomic_mode {
+	MLX5_ATOMIC_MODE_DCT_OFF        = 20,
+	MLX5_ATOMIC_MODE_DCT_NONE       = 0 << MLX5_ATOMIC_MODE_DCT_OFF,
+	MLX5_ATOMIC_MODE_DCT_IB_COMP    = 1 << MLX5_ATOMIC_MODE_DCT_OFF,
+	MLX5_ATOMIC_MODE_DCT_CX         = 2 << MLX5_ATOMIC_MODE_DCT_OFF,
+};
+
 enum {
 	MLX5_ATOMIC_OPS_CMP_SWAP	= 1 << 0,
 	MLX5_ATOMIC_OPS_FETCH_ADD	= 1 << 1,
@@ -432,6 +439,7 @@ enum mlx5_res_type {
 	MLX5_RES_SRQ	= 3,
 	MLX5_RES_XSRQ	= 4,
 	MLX5_RES_XRQ	= 5,
+	MLX5_RES_DCT	= MLX5_EVENT_QUEUE_TYPE_DCT,
 };
 
 struct mlx5_core_rsc_common {

commit 19286e4a7a0ce0a7ac584be614c40513d6318ad6
Merge: 5f520fc31876 45e6ae7ef21b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 28 23:06:01 2017 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull rdma fixes from Jason Gunthorpe:
     "This is the next batch of for-rc patches from RDMA. It includes the
      fix for the ipoib regression I mentioned last time, and the result of
      a fairly major debugging effort to get iser working reliably on cxgb4
      hardware - it turns out the cxgb4 driver was not handling QP error
      flushing properly causing iser to fail.
    
       - cxgb4 fix for an iser testing failure as debugged by Steve and
         Sagi. The problem was a driver bug in the handling of shutting down
         a QP.
    
       - Various vmw_pvrdma fixes for bogus WARN_ON, missed resource free on
         error unwind and a use after free bug
    
       - Improper congestion counter values on mlx5 when link aggregation is
         enabled
    
       - ipoib lockdep regression introduced in this merge window
    
       - hfi1 regression supporting the device in a VM introduced in a
         recent patch
    
       - Typo that breaks future uAPI compatibility in the verbs core
    
       - More SELinux related oops fixing
    
       - Fix an oops during error unwind in mlx5"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma:
      IB/mlx5: Fix mlx5_ib_alloc_mr error flow
      IB/core: Verify that QP is security enabled in create and destroy
      IB/uverbs: Fix command checking as part of ib_uverbs_ex_modify_qp()
      IB/mlx5: Serialize access to the VMA list
      IB/hfi: Only read capability registers if the capability exists
      IB/ipoib: Fix lockdep issue found on ipoib_ib_dev_heavy_flush
      IB/mlx5: Fix congestion counters in LAG mode
      RDMA/vmw_pvrdma: Avoid use after free due to QP/CQ/SRQ destroy
      RDMA/vmw_pvrdma: Use refcount_dec_and_test to avoid warning
      RDMA/vmw_pvrdma: Call ib_umem_release on destroy QP path
      iw_cxgb4: when flushing, complete all wrs in a chain
      iw_cxgb4: reflect the original WR opcode in drain cqes
      iw_cxgb4: Only validate the MSN for successful completions

commit 31a78a5a7983141c17852d31eb3a1f70d8161225
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Sun Dec 24 16:31:34 2017 +0200

    IB/mlx5: Extend UAR stuff to support dynamic allocation
    
    This patch extends the alloc context flow to be prepared for working
    with dynamic UAR allocations.
    
    Currently upon alloc context there is some fix size of UARs that are
    allocated (named 'static allocation') and there is no option to user
    application to ask for more or control which UAR will be used by which
    QP.
    
    In this patch the driver prepares its data structures to manage both the
    static and the dynamic allocations and let the user driver knows about
    the max value of dynamic blue-flame registers that are allowed.
    
    Downstream patches from this series will enable the dynamic allocation
    and the association as part of QP creation.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8846919356ca..2fe263f69751 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -230,6 +230,9 @@ struct mlx5_bfreg_info {
 	u32			ver;
 	bool			lib_uar_4k;
 	u32			num_sys_pages;
+	u32			num_static_sys_pages;
+	u32			total_num_bfregs;
+	u32			num_dyn_bfregs;
 };
 
 struct mlx5_cmd_first {

commit 71a0ff65a21bf3e2c4fde208c4a635ed2bbb4e81
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Thu Dec 21 17:38:26 2017 +0200

    IB/mlx5: Fix congestion counters in LAG mode
    
    Congestion counters are counted and queried per physical function.
    When working in LAG mode, CNP packets can be sent or received on both
    of the functions, thus congestion counters should be aggregated from
    the two physical functions.
    
    Fixes: e1f24a79f424 ("IB/mlx5: Support congestion related counters")
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Reviewed-by: Aviv Heller <avivh@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index a886b51511ab..8846919356ca 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1164,6 +1164,10 @@ int mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);
 int mlx5_cmd_destroy_vport_lag(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
 struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
+int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,
+				 u64 *values,
+				 int num_counters,
+				 size_t *offsets);
 struct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev);
 void mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up);
 

commit d6b2785cd55ee72e9608762650b3ef299f801b1b
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Tue Nov 21 15:15:51 2017 +0200

    net/mlx5: Cleanup IRQs in case of unload failure
    
    When mlx5_stop_eqs fails to destroy any of the eqs it returns with an error.
    In such failure flow the function will return without
    releasing all EQs irqs and then pci_free_irq_vectors will fail.
    Fix by only warn on destroy EQ failure and continue to release other
    EQs and their irqs.
    
    It fixes the following kernel trace:
    kernel: kernel BUG at drivers/pci/msi.c:352!
    ...
    ...
    kernel: Call Trace:
    kernel: pci_disable_msix+0xd3/0x100
    kernel: pci_free_irq_vectors+0xe/0x20
    kernel: mlx5_load_one.isra.17+0x9f5/0xec0 [mlx5_core]
    
    Fixes: e126ba97dba9 ("mlx5: Add driver for Mellanox Connect-IB adapters")
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 40a6f33c4cde..57b109c6e422 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1049,7 +1049,7 @@ int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 		       enum mlx5_eq_type type);
 int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_start_eqs(struct mlx5_core_dev *dev);
-int mlx5_stop_eqs(struct mlx5_core_dev *dev);
+void mlx5_stop_eqs(struct mlx5_core_dev *dev);
 int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn,
 		    unsigned int *irqn);
 int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);

commit 231243c82793428467524227ae02ca451e6a98e7
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Fri Nov 10 15:59:52 2017 +0900

    Revert "mlx5: move affinity hints assignments to generic code"
    
    Before the offending commit, mlx5 core did the IRQ affinity itself,
    and it seems that the new generic code have some drawbacks and one
    of them is the lack for user ability to modify irq affinity after
    the initial affinity values got assigned.
    
    The issue is still being discussed and a solution in the new generic code
    is required, until then we need to revert this patch.
    
    This fixes the following issue:
    echo <new affinity> > /proc/irq/<x>/smp_affinity
    fails with  -EIO
    
    This reverts commit a435393acafbf0ecff4deb3e3cb554b34f0d0664.
    Note: kept mlx5_get_vector_affinity in include/linux/mlx5/driver.h since
    it is used in mlx5_ib driver.
    
    Fixes: a435393acafb ("mlx5: move affinity hints assignments to generic code")
    Cc: Sagi Grimberg <sagi@grimberg.me>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jes Sorensen <jsorensen@fb.com>
    Reported-by: Jes Sorensen <jsorensen@fb.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index a886b51511ab..40a6f33c4cde 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -556,6 +556,7 @@ struct mlx5_core_sriov {
 };
 
 struct mlx5_irq_info {
+	cpumask_var_t mask;
 	char name[MLX5_MAX_IRQ_NAME];
 };
 

commit 415a64aa8dc6b4fc478609c549ca652d95a12f13
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Tue Jul 18 16:08:46 2017 -0500

    net/mlx5: QPTS and QPDPM register firmware command support
    
    The QPTS register allows changing the priority trust state between pcp and
    dscp. Add support to get/set trust state from device. When the port is
    in pcp/dscp trust state, packet is routed by hardware to matching priority
    based on its pcp/dscp value respectively.
    
    The QPDPM register allow channing the dscp to priority mapping. Add support
    to get/set dscp to priority mapping from device.
    Note that to change a dscp mapping, the "e" bit of this dscp structure
    must be set in the QPDPM firmware command.
    
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ed5be52282ea..a886b51511ab 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -107,8 +107,10 @@ enum {
 };
 
 enum {
+	MLX5_REG_QPTS            = 0x4002,
 	MLX5_REG_QETCR		 = 0x4005,
 	MLX5_REG_QTCT		 = 0x400a,
+	MLX5_REG_QPDPM           = 0x4013,
 	MLX5_REG_QCAM            = 0x4019,
 	MLX5_REG_DCBX_PARAM      = 0x4020,
 	MLX5_REG_DCBX_APP        = 0x4021,
@@ -142,6 +144,11 @@ enum {
 	MLX5_REG_MCAM		 = 0x907f,
 };
 
+enum mlx5_qpts_trust_state {
+	MLX5_QPTS_TRUST_PCP  = 1,
+	MLX5_QPTS_TRUST_DSCP = 2,
+};
+
 enum mlx5_dcbx_oper_mode {
 	MLX5E_DCBX_PARAM_VER_OPER_HOST  = 0x0,
 	MLX5E_DCBX_PARAM_VER_OPER_AUTO  = 0x3,

commit c02762eb20cb57ec5b7c037b056c37d5838c803f
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Tue Jul 18 16:03:17 2017 -0500

    net/mlx5: QCAM register firmware command support
    
    The QCAM register provides capability bit for all the QoS registers
    using ACCESS_REG command.
    
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 08c77b7e59cb..ed5be52282ea 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -109,6 +109,7 @@ enum {
 enum {
 	MLX5_REG_QETCR		 = 0x4005,
 	MLX5_REG_QTCT		 = 0x400a,
+	MLX5_REG_QCAM            = 0x4019,
 	MLX5_REG_DCBX_PARAM      = 0x4020,
 	MLX5_REG_DCBX_APP        = 0x4021,
 	MLX5_REG_FPGA_CAP	 = 0x4022,
@@ -798,6 +799,7 @@ struct mlx5_core_dev {
 		u32 pcam[MLX5_ST_SZ_DW(pcam_reg)];
 		u32 mcam[MLX5_ST_SZ_DW(mcam_reg)];
 		u32 fpga[MLX5_ST_SZ_DW(fpga_cap)];
+		u32 qcam[MLX5_ST_SZ_DW(qcam_reg)];
 	} caps;
 	phys_addr_t		iseg_base;
 	struct mlx5_init_seg __iomem *iseg;

commit 7c39afb394c79e72c3795b4a42d55155b34ee073
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Tue Aug 15 13:46:04 2017 +0300

    net/mlx5: PTP code migration to driver core section
    
    PTP code is moved to core section of mlx5 driver in order to share
    it between ethernet and infiniband. This movement involves the following
    changes:
    - Change mlx5e_ prefix to be mlx5_
    - Add clock structs to Core
    - Add clock object to mlx5_core_dev
    - Call Init/Uninit clock from core init/cleanup
    - Rename mlx5e_tstamp to be mlx5_clock
    
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Eitan Rabin <rabin@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 401c8972cc3a..08c77b7e59cb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -49,6 +49,8 @@
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
 #include <linux/mlx5/srq.h>
+#include <linux/timecounter.h>
+#include <linux/ptp_clock_kernel.h>
 
 enum {
 	MLX5_BOARD_ID_LEN = 64,
@@ -760,6 +762,27 @@ struct mlx5_rsvd_gids {
 	struct ida ida;
 };
 
+#define MAX_PIN_NUM	8
+struct mlx5_pps {
+	u8                         pin_caps[MAX_PIN_NUM];
+	struct work_struct         out_work;
+	u64                        start[MAX_PIN_NUM];
+	u8                         enabled;
+};
+
+struct mlx5_clock {
+	rwlock_t                   lock;
+	struct cyclecounter        cycles;
+	struct timecounter         tc;
+	struct hwtstamp_config     hwtstamp_config;
+	u32                        nominal_c_mult;
+	unsigned long              overflow_period;
+	struct delayed_work        overflow_work;
+	struct ptp_clock          *ptp;
+	struct ptp_clock_info      ptp_info;
+	struct mlx5_pps            pps_info;
+};
+
 struct mlx5_core_dev {
 	struct pci_dev	       *pdev;
 	/* sync pci state */
@@ -800,6 +823,7 @@ struct mlx5_core_dev {
 #ifdef CONFIG_RFS_ACCEL
 	struct cpu_rmap         *rmap;
 #endif
+	struct mlx5_clock        clock;
 };
 
 struct mlx5_db {

commit 99d3cd27f755d63fd6cf85169eaa873d90769aa5
Author: Inbar Karmy <inbark@mellanox.com>
Date:   Thu Aug 24 17:21:44 2017 +0300

    net/mlx5: Fix FPGA capability location
    
    Currently, FPGA capability is located in (mdev)->caps.hca_cur,
    change the location to be (mdev)->caps.fpga,
    since hca_cur is reserved for HCA device capabilities.
    
    Fixes: e29341fb3a5b ("net/mlx5: FPGA, Add basic support for Innova")
    Signed-off-by: Inbar Karmy <inbark@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 02ff700e4f30..401c8972cc3a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -774,6 +774,7 @@ struct mlx5_core_dev {
 		u32 hca_max[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 		u32 pcam[MLX5_ST_SZ_DW(pcam_reg)];
 		u32 mcam[MLX5_ST_SZ_DW(mcam_reg)];
+		u32 fpga[MLX5_ST_SZ_DW(fpga_cap)];
 	} caps;
 	phys_addr_t		iseg_base;
 	struct mlx5_init_seg __iomem *iseg;

commit aae3dbb4776e7916b6cd442d00159bea27a695c1
Merge: ec3604c7a5aa 66bed8465a80
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 6 14:45:08 2017 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) Support ipv6 checksum offload in sunvnet driver, from Shannon
        Nelson.
    
     2) Move to RB-tree instead of custom AVL code in inetpeer, from Eric
        Dumazet.
    
     3) Allow generic XDP to work on virtual devices, from John Fastabend.
    
     4) Add bpf device maps and XDP_REDIRECT, which can be used to build
        arbitrary switching frameworks using XDP. From John Fastabend.
    
     5) Remove UFO offloads from the tree, gave us little other than bugs.
    
     6) Remove the IPSEC flow cache, from Florian Westphal.
    
     7) Support ipv6 route offload in mlxsw driver.
    
     8) Support VF representors in bnxt_en, from Sathya Perla.
    
     9) Add support for forward error correction modes to ethtool, from
        Vidya Sagar Ravipati.
    
    10) Add time filter for packet scheduler action dumping, from Jamal Hadi
        Salim.
    
    11) Extend the zerocopy sendmsg() used by virtio and tap to regular
        sockets via MSG_ZEROCOPY. From Willem de Bruijn.
    
    12) Significantly rework value tracking in the BPF verifier, from Edward
        Cree.
    
    13) Add new jump instructions to eBPF, from Daniel Borkmann.
    
    14) Rework rtnetlink plumbing so that operations can be run without
        taking the RTNL semaphore. From Florian Westphal.
    
    15) Support XDP in tap driver, from Jason Wang.
    
    16) Add 32-bit eBPF JIT for ARM, from Shubham Bansal.
    
    17) Add Huawei hinic ethernet driver.
    
    18) Allow to report MD5 keys in TCP inet_diag dumps, from Ivan
        Delalande.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1780 commits)
      i40e: point wb_desc at the nvm_wb_desc during i40e_read_nvm_aq
      i40e: avoid NVM acquire deadlock during NVM update
      drivers: net: xgene: Remove return statement from void function
      drivers: net: xgene: Configure tx/rx delay for ACPI
      drivers: net: xgene: Read tx/rx delay for ACPI
      rocker: fix kcalloc parameter order
      rds: Fix non-atomic operation on shared flag variable
      net: sched: don't use GFP_KERNEL under spin lock
      vhost_net: correctly check tx avail during rx busy polling
      net: mdio-mux: add mdio_mux parameter to mdio_mux_init()
      rxrpc: Make service connection lookup always check for retry
      net: stmmac: Delete dead code for MDIO registration
      gianfar: Fix Tx flow control deactivation
      cxgb4: Ignore MPS_TX_INT_CAUSE[Bubble] for T6
      cxgb4: Fix pause frame count in t4_get_port_stats
      cxgb4: fix memory leak
      tun: rename generic_xdp to skb_xdp
      tun: reserve extra headroom only when XDP is set
      net: dsa: bcm_sf2: Configure IMP port TC2QOS mapping
      net: dsa: bcm_sf2: Advertise number of egress queues
      ...

commit aa9d4648c2fbb455df7750ade1b73dd9ad9b3690
Merge: 906dde0f355b 8eb19e8e7c86
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Sep 3 17:49:17 2017 -0700

    Merge tag 'for-linus-ioctl' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull rdma updates from Doug Ledford:
     "This is a big pull request.
    
      Of note is that I'm sending you the new ioctl API for the rdma
      subsystem. We put it up on linux-api@, but didn't get much response.
      The API is complex, but it solves two different problems in one go:
    
       1) The bi-directional nature of the RDMA file write calls, which
          created the security hole we had to handle (and for which the fix
          is now causing problems for systems in production, we were a bit
          over zealous in the fix and the ability to open a device, then
          fork, then create new queue pairs on the device and use them is
          broken).
    
       2) The bloat caused by different vendors implementing extensions to
          the base verbs API. Each vendor's hardware is slightly different,
          and the hardware might be suitable for one extension but not
          another.
    
          By the time we add generic extensions for all the different ways
          that the different hardware can offload things, the API becomes
          bloated. Things like our completion structs have started to exceed
          a cache line in size because of all the elements needed to support
          this. That in turn shows up heavily in the performance graphs with
          a noticable drop in performance on 100Gigabit links as our
          completion structs go from occupying one cache line to 1+.
    
          This API makes things like the completion structs modular in a
          very similar way to netlink so that your structs can only include
          the items needed for the offloads/features you are actually using
          on a given queue pair. In that way we support everything, but only
          use what we need, and our structs stay smaller.
    
      The ioctl API is better explained by the posting on linux-api@ than I
      can explain it here, so I'll just leave it at that.
    
      The rest of the pull request is typical stuff.
    
      Updates for 4.14 kernel merge window
    
       - Lots of hfi1 driver updates (mixed with a few qib and core updates
         as well)
    
       - rxe updates
    
       - various mlx updates
    
       - Set default roce type to RoCEv2
    
       - Several larger fixes for bnxt_re that were too big for -rc
    
       - Several larger fixes for qedr that, likewise, were too big for -rc
    
       - Misc core changes
    
       - Make the hns_roce driver compilable on arches other than aarch64 so
         we can more easily debug build issues related to it
    
       - Add rdma-netlink infrastructure updates
    
       - Add automatic IRQ affinity infrastructure
    
       - Add 32bit lid support
    
       - Lots of misc fixes across the subsystem from random people
    
       - Autoloading of RDMA netlink modules
    
       - PCI pool cleanups from Romain Perier
    
       - mlx5 driver feature additions and fixes
    
       - Hardware tag matchine feature
    
       - Fix sleeping in atomic when resolving roce ah
    
       - Add experimental ioctl interface as posted to linux-api@"
    
    * tag 'for-linus-ioctl' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (328 commits)
      IB/core: Expose ioctl interface through experimental Kconfig
      IB/core: Assign root to all drivers
      IB/core: Add completion queue (cq) object actions
      IB/core: Add legacy driver's user-data
      IB/core: Export ioctl enum types to user-space
      IB/core: Explicitly destroy an object while keeping uobject
      IB/core: Add macros for declaring methods and attributes
      IB/core: Add uverbs merge trees functionality
      IB/core: Add DEVICE object and root tree structure
      IB/core: Declare an object instead of declaring only type attributes
      IB/core: Add new ioctl interface
      RDMA/vmw_pvrdma: Fix a signedness
      RDMA/vmw_pvrdma: Report network header type in WC
      IB/core: Add might_sleep() annotation to ib_init_ah_from_wc()
      IB/cm: Fix sleeping in atomic when RoCE is used
      IB/core: Add support to finalize objects in one transaction
      IB/core: Add a generic way to execute an operation on a uobject
      Documentation: Hardware tag matching
      IB/mlx5: Support IB_SRQT_TM
      net/mlx5: Add XRQ support
      ...

commit 6026e043d09012c6269f9a96a808d52d9c498224
Merge: 4cc5b44b29a9 138e4ad67afd
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Sep 1 17:42:05 2017 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Three cases of simple overlapping changes.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 10a8d00707082955b177164d4b4e758ffcbd4017
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Wed Aug 9 10:03:40 2017 -0500

    net/mlx5: Remove the flag MLX5_INTERFACE_STATE_SHUTDOWN
    
    MLX5_INTERFACE_STATE_SHUTDOWN is not used in the code.
    
    Fixes: 5fc7197d3a25 ("net/mlx5: Add pci shutdown callback")
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Reviewed-by: Daniel Jurgens <danielj@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 918f5e644506..205d82d4c468 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -674,7 +674,6 @@ enum mlx5_device_state {
 
 enum mlx5_interface_state {
 	MLX5_INTERFACE_STATE_UP = BIT(0),
-	MLX5_INTERFACE_STATE_SHUTDOWN = BIT(1),
 };
 
 enum mlx5_pci_status {

commit b3cb5388499c5e219324bfe7da2e46cbad82bfcf
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Tue Aug 8 13:17:00 2017 -0500

    net/mlx5: Skip mlx5_unload_one if mlx5_load_one fails
    
    There is an issue where the firmware fails during mlx5_load_one,
    the health_care timer detects the issue and schedules a health_care call.
    Then the mlx5_load_one detects the issue, cleans up and quits. Then
    the health_care starts and calls mlx5_unload_one to clean up the resources
    that no longer exist and causes kernel panic.
    
    The root cause is that the bit MLX5_INTERFACE_STATE_DOWN is not set
    after mlx5_load_one fails. The solution is removing the bit
    MLX5_INTERFACE_STATE_DOWN and quit mlx5_unload_one if the
    bit MLX5_INTERFACE_STATE_UP is not set. The bit MLX5_INTERFACE_STATE_DOWN
    is redundant and we can use MLX5_INTERFACE_STATE_UP instead.
    
    Fixes: 5fc7197d3a25 ("net/mlx5: Add pci shutdown callback")
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Reviewed-by: Daniel Jurgens <danielj@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index df6ce59a1f95..918f5e644506 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -673,9 +673,8 @@ enum mlx5_device_state {
 };
 
 enum mlx5_interface_state {
-	MLX5_INTERFACE_STATE_DOWN = BIT(0),
-	MLX5_INTERFACE_STATE_UP = BIT(1),
-	MLX5_INTERFACE_STATE_SHUTDOWN = BIT(2),
+	MLX5_INTERFACE_STATE_UP = BIT(0),
+	MLX5_INTERFACE_STATE_SHUTDOWN = BIT(1),
 };
 
 enum mlx5_pci_status {

commit 5b3ec3fcb6bbe081279c73fb574af8c72f14cea0
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Thu Aug 17 15:52:10 2017 +0300

    net/mlx5: Add XRQ support
    
    Add support to new XRQ(eXtended shared Receive Queue)
    hardware object. It supports SRQ semantics with addition
    of extended receive buffers topologies and offloads.
    
    Currently supports tag matching topology and rendezvouz offload.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Reviewed-by: Yossi Itigin <yosefe@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 99d88624ad07..c33e6f7a1afb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -418,6 +418,7 @@ enum mlx5_res_type {
 	MLX5_RES_SQ	= MLX5_EVENT_QUEUE_TYPE_SQ,
 	MLX5_RES_SRQ	= 3,
 	MLX5_RES_XSRQ	= 4,
+	MLX5_RES_XRQ	= 5,
 };
 
 struct mlx5_core_rsc_common {

commit 8b7ff7f3b301de52924cb2cf3fed47b181893116
Author: Ilya Lesokhin <ilyal@mellanox.com>
Date:   Thu Aug 17 15:52:29 2017 +0300

    IB/mlx5: Enable UMR for MRs created with reg_create
    
    This patch is the first step in decoupling UMR usage and
    allocation from the MR cache. The only functional change
    in this patch is to enables UMR for MRs created with
    reg_create.
    
    This change fixes a bug where ODP memory regions that
    were not allocated from the MR cache did not have UMR
    enabled.
    
    Signed-off-by: Ilya Lesokhin <ilyal@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index db40bc4055c7..99d88624ad07 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1093,7 +1093,7 @@ enum {
 };
 
 enum {
-	MAX_UMR_CACHE_ENTRY = 20,
+	MR_CACHE_LAST_STD_ENTRY = 20,
 	MLX5_IMR_MTT_CACHE_ENTRY,
 	MLX5_IMR_KSM_CACHE_ENTRY,
 	MAX_MR_CACHE_ENTRIES

commit 07533c6765de05199417ec73f9c2a495ddd29473
Author: Gal Pressman <galp@mellanox.com>
Date:   Mon Aug 21 17:54:21 2017 +0300

    net/mlx5: Remove a leftover unused variable
    
    mlx5_core_wq is no longer being used and should be removed
    from the code.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d26f18b39c4a..d5b6f6a9fcc5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -890,8 +890,6 @@ static inline void *mlx5_buf_offset(struct mlx5_buf *buf, int offset)
 		return buf->direct.buf + offset;
 }
 
-extern struct workqueue_struct *mlx5_core_wq;
-
 #define STRUCT_FIELD(header, field) \
 	.struct_offset_bytes = offsetof(struct ib_unpacked_ ## header, field),      \
 	.struct_size_bytes   = sizeof((struct ib_unpacked_ ## header *)0)->field

commit 18c90df9f2c00cb35ab8ba747aa0f742ee6bbf6a
Author: Romain Perier <romain.perier@collabora.com>
Date:   Tue Aug 22 13:46:59 2017 +0200

    mlx5: Replace PCI pool old API
    
    The PCI pool API is deprecated. This commit replaces the PCI pool old
    API by the appropriate function with the DMA pool API.
    
    Signed-off-by: Romain Perier <romain.perier@collabora.com>
    Reviewed-by: Peter Senna Tschudin <peter.senna@collabora.com>
    Acked-by: Doug Ledford <dledford@redhat.com>
    Tested-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 099fe311f272..db40bc4055c7 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -299,7 +299,7 @@ struct mlx5_cmd {
 	struct semaphore pages_sem;
 	int	mode;
 	struct mlx5_cmd_work_ent *ent_arr[MLX5_MAX_COMMANDS];
-	struct pci_pool *pool;
+	struct dma_pool *pool;
 	struct mlx5_cmd_debug dbg;
 	struct cmd_msg_cache cache[MLX5_NUM_COMMAND_CACHES];
 	int checksum_disabled;

commit 320438301b85038e995b5a40a24c43cbc0ed4909
Merge: 913cc67159bc ac3a949fb2ff 0b36658ca8b1
Author: Doug Ledford <dledford@redhat.com>
Date:   Thu Aug 10 14:31:29 2017 -0400

    Merge branches '32bit_lid' and 'irq_affinity' into k.o/merge-test
    
    Conflicts:
            drivers/infiniband/hw/mlx5/main.c - Both add new code
            include/rdma/ib_verbs.h - Both add new code
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

commit a435393acafbf0ecff4deb3e3cb554b34f0d0664
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Thu Jul 13 11:09:40 2017 +0300

    mlx5: move affinity hints assignments to generic code
    
    generic api takes care of spreading affinity similar to
    what mlx5 open coded (and even handles better asymmetric
    configurations). Ask the generic API to spread affinity
    for us, and feed him pre_vectors that do not participate
    in affinity settings (which is an improvement to what we
    had before).
    
    The affinity assignments should match what mlx5 tried to
    do earlier but now we do not set affinity to async, cmd
    and pages dedicated vectors.
    
    Also, remove mlx5e_get_cpu and introduce mlx5e_get_node
    (used for allocation purposes) and mlx5_get_vector_affinity
    (for indirection table construction) as they provide the needed
    information. Luckily, we have generic helpers to get cpumask
    and node given a irq vector. mlx5_get_vector_affinity will
    be used by mlx5_ib in a subsequent patch.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5bac7f53b4f9..579731842c94 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -534,7 +534,6 @@ struct mlx5_core_sriov {
 };
 
 struct mlx5_irq_info {
-	cpumask_var_t mask;
 	char name[MLX5_MAX_IRQ_NAME];
 };
 
@@ -1184,4 +1183,10 @@ enum {
 	MLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,
 };
 
+static inline const struct cpumask *
+mlx5_get_vector_affinity(struct mlx5_core_dev *dev, int vector)
+{
+	return pci_irq_get_affinity(dev->pdev, MLX5_EQ_VEC_COMP_BASE + vector);
+}
+
 #endif /* MLX5_DRIVER_H */

commit 78249c4215840edb95447ec6867b69a7ac1d7a0d
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Thu Jul 13 11:09:38 2017 +0300

    mlx5: convert to generic pci_alloc_irq_vectors
    
    Now that we have a generic code to allocate an array
    of irq vectors and even correctly spread their affinity,
    correctly handle cpu hotplug events and more, were much
    better off using it.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index df6ce59a1f95..5bac7f53b4f9 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -597,7 +597,6 @@ struct mlx5_port_module_event_stats {
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	eq_table;
-	struct msix_entry	*msix_arr;
 	struct mlx5_irq_info	*irq_info;
 
 	/* pages stuff */

commit 97834eba7c194659a72c5bb0f8c19c7055bb69ea
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Wed Jun 7 12:14:24 2017 +0300

    net/mlx5: Delay events till ib registration ends
    
    When mlx5_ib registers itself to mlx5_core as an interface, it will
    call mlx5_add_device which will call mlx5_ib interface add callback,
    in case the latter successfully returns, only then mlx5_core will add
    it to the interface list and async events will be forwarded to mlx5_ib.
    Between mlx5_ib interface add callback and mlx5_core adding the mlx5_ib
    interface to its devices list, arriving mlx5_core events can be missed
    by the new mlx5_ib registering interface.
    
    In other words:
    thread 1: mlx5_ib: mlx5_register_interface(dev)
    thread 1: mlx5_core: mlx5_add_device(dev)
    thread 1: mlx5_core: ctx = dev->add => (mlx5_ib)->mlx5_ib_add
    thread 2: mlx5_core_event: **new event arrives, forward to dev_list
    thread 1: mlx5_core: add_ctx_to_dev_list(ctx)
    /* previous event was missed by the new interface.*/
    It is ok to miss events before dev->add (mlx5_ib)->mlx5_ib_add_device
    but not after.
    
    We fix this race by accumulating the events that come between the
    ib_register_device (inside mlx5_add_device->(dev->add)) till the adding
    to the list completes and fire them to the new registering interface
    after that.
    
    Fixes: f1ee87fe55c8 ("net/mlx5: Organize device list API in one place")
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 88d6eb5b3a76..d26f18b39c4a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -647,6 +647,9 @@ struct mlx5_priv {
 	struct list_head        ctx_list;
 	spinlock_t              ctx_lock;
 
+	struct list_head	waiting_events_list;
+	bool			is_accum_events;
+
 	struct mlx5_flow_steering *steering;
 	struct mlx5_mpfs        *mpfs;
 	struct mlx5_eswitch     *eswitch;

commit eeb66cdb682678bfd1f02a4547e3649b38ffea7e
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Sun Jun 4 23:11:55 2017 +0300

    net/mlx5: Separate between E-Switch and MPFS
    
    Multi-Physical Function Switch (MPFs) is required for when multi-PF
    configuration is enabled to allow passing user configured unicast MAC
    addresses to the requesting PF.
    
    Before this patch eswitch.c used to manage the HW MPFS l2 table,
    E-Switch always (regardless of sriov) enabled vport(0) (NIC PF) vport's
    contexts update on unicast mac address list changes, to populate the PF's
    MPFS L2 table accordingly.
    
    In downstream patch we would like to allow compiling the driver without
    E-Switch functionalities, for that we move MPFS l2 table logic out
    of eswitch.c into its own file, and provide Kconfig flag (MLX5_MPFS) to
    allow compiling out MPFS for those who don't want Multi-PF support.
    
    NIC PF netdevice will now directly update MPFS l2 table via the new MPFS
    API. VF netdevice has no access to MPFS L2 table, so E-Switch will remain
    responsible of updating its MPFS l2 table on behalf of its VFs.
    
    Due to this change we also don't require enabling vport(0) (PF vport)
    unicast mac changes events anymore, for when SRIOV is not enabled.
    Which means E-Switch is now activated only on SRIOV activation, and not
    required otherwise.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Cc: Jes Sorensen <jsorensen@fb.com>
    Cc: kernel-team@fb.com

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index df6ce59a1f95..88d6eb5b3a76 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -550,6 +550,7 @@ struct mlx5_fc_stats {
 	unsigned long sampling_interval; /* jiffies */
 };
 
+struct mlx5_mpfs;
 struct mlx5_eswitch;
 struct mlx5_lag;
 struct mlx5_pagefault;
@@ -647,6 +648,7 @@ struct mlx5_priv {
 	spinlock_t              ctx_lock;
 
 	struct mlx5_flow_steering *steering;
+	struct mlx5_mpfs        *mpfs;
 	struct mlx5_eswitch     *eswitch;
 	struct mlx5_core_sriov	sriov;
 	struct mlx5_lag		*lag;

commit 246ac9814c5b2c0e9916dca5fbf8d6a40245fad1
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Tue May 30 10:29:12 2017 +0300

    net/mlx5: Introduce general notification event
    
    When delay drop timeout is expired, the firmware raises
    general notification event of DELAY_DROP_TIMEOUT subtype.
    In addition the feature is disable so the driver have to
    reactivate the timeout.
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 54221be5f69e..758ef40f9316 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -192,6 +192,7 @@ enum mlx5_dev_event {
 	MLX5_DEV_EVENT_GUID_CHANGE,
 	MLX5_DEV_EVENT_CLIENT_REREG,
 	MLX5_DEV_EVENT_PPS,
+	MLX5_DEV_EVENT_DELAY_DROP_TIMEOUT,
 };
 
 enum mlx5_port_status {

commit 7ecf6d8ff154e6f7471ee537a400d43a5f3b1c57
Author: Bodong Wang <bodong@mellanox.com>
Date:   Tue May 30 10:18:24 2017 +0300

    IB/mlx5: Restore IB guid/policy for virtual functions
    
    When a user sets port_guid, node_guid or policy of an IB virtual
    function, save this information in "struct mlx5_vf_context".
    
    This information will be restored later when pci_resume is called.
    To make sure this works, one can use aer-inject to generate PCI
    errors on mlx5 devices and verify if relevant fields are restored
    after PCI resume.
    
    Signed-off-by: Bodong Wang <bodong@mellanox.com>
    Reviewed-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index df6ce59a1f95..54221be5f69e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -162,6 +162,13 @@ enum dbg_rsc_type {
 	MLX5_DBG_RSC_CQ,
 };
 
+enum port_state_policy {
+	MLX5_POLICY_DOWN	= 0,
+	MLX5_POLICY_UP		= 1,
+	MLX5_POLICY_FOLLOW	= 2,
+	MLX5_POLICY_INVALID	= 0xffffffff
+};
+
 struct mlx5_field_desc {
 	struct dentry	       *dent;
 	int			i;
@@ -525,6 +532,9 @@ struct mlx5_mkey_table {
 
 struct mlx5_vf_context {
 	int	enabled;
+	u64	port_guid;
+	u64	node_guid;
+	enum port_state_policy	policy;
 };
 
 struct mlx5_core_sriov {
@@ -842,13 +852,6 @@ struct mlx5_pas {
 	u8	log_sz;
 };
 
-enum port_state_policy {
-	MLX5_POLICY_DOWN	= 0,
-	MLX5_POLICY_UP		= 1,
-	MLX5_POLICY_FOLLOW	= 2,
-	MLX5_POLICY_INVALID	= 0xffffffff
-};
-
 enum phy_port_state {
 	MLX5_AAA_111
 };

commit 3a3f7d130eb5c219a1a4b183b92106028747dc85
Merge: 784c372a8184 ea23b42739a2
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 3 03:42:10 2017 -0700

    Merge https://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Some overlapping changes in the mlx5 driver.
    
    A merge conflict resolution posted by Stephen Rothwell was used as a
    guide.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a9956d35d199beb406727a4496bc5d7f09c82976
Author: Ilan Tayari <ilant@mellanox.com>
Date:   Tue Apr 18 13:10:41 2017 +0300

    net/mlx5: FPGA, Add SBU infrastructure
    
    Add interface to initialize and interact with Innova FPGA SBU
    connections.
    A client driver may use these functions to set up a high-speed DMA
    connection with its SBU hardware logic, and send/receive messages
    over this connection.
    
    A later patch in this patchset will make use of these functions for
    Innova IPSec offload in mlx5 Ethernet driver.
    
    Add commands to retrieve Innova FPGA SBU capabilities, and to
    read/write Innova FPGA configuration space registers and memory,
    over internal I2C.
    
    At high level, the FPGA configuration space is divided such:
     0x00000000 - 0x007fffff is reserved for the SBU
     0x00800000 - 0xffffffff is reserved for the Shell
    0x400000000 - ...        is DDR memory
    
    A later patchset will add support for accessing FPGA CrSpace and memory
    over a high-speed connection. This is the reason for the ACCESS_TYPE
    enumeration, which currently only supports I2C.
    
    Signed-off-by: Ilan Tayari <ilant@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 32b0835d4491..2ab4ae3e3a1a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -111,6 +111,7 @@ enum {
 	MLX5_REG_DCBX_APP        = 0x4021,
 	MLX5_REG_FPGA_CAP	 = 0x4022,
 	MLX5_REG_FPGA_CTRL	 = 0x4023,
+	MLX5_REG_FPGA_ACCESS_REG = 0x4024,
 	MLX5_REG_PCAP		 = 0x5001,
 	MLX5_REG_PMTU		 = 0x5003,
 	MLX5_REG_PTYS		 = 0x5004,

commit a6f7d2aff623bb7572d4bca1caf5820e0cd5a586
Author: Ilan Tayari <ilant@mellanox.com>
Date:   Sun Mar 26 17:23:42 2017 +0300

    net/mlx5: Add support for multiple RoCE enable
    
    Previously, only mlx5_ib enabled RoCE on the port, but FPGA needs it as
    well.
    Add support for counting number of enables, so that FPGA and IB can work
    in parallel and independently.
    Program the HW to enable RoCE on the first enable call, and program to
    disable RoCE on the last disable call.
    
    Signed-off-by: Ilan Tayari <ilant@mellanox.com>
    Reviewed-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 08e99bd2cd77..32b0835d4491 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -777,6 +777,7 @@ struct mlx5_core_dev {
 	struct mlx5e_resources  mlx5e_res;
 	struct {
 		struct mlx5_rsvd_gids	reserved_gids;
+		atomic_t                roce_en;
 	} roce;
 #ifdef CONFIG_MLX5_FPGA
 	struct mlx5_fpga_device *fpga;

commit 52ec462eca9b87b8036209483efe1c6cf9c49d9a
Author: Ilan Tayari <ilant@mellanox.com>
Date:   Sun Mar 26 17:01:57 2017 +0300

    net/mlx5: Add reserved-gids support
    
    Reserved GIDs are entries in the GID table in use by the mlx5_core
    and its submodules (e.g. FPGA, SRIOV, E-Swtich, netdev).
    The entries are reserved at the high indexes of the GID table.
    
    A mlx5 submodule may reserve a certain amount of GIDs for its own use
    during the load sequence by calling mlx5_core_reserve_gids, and must
    also take care to un-reserve these GIDs when it closes.
    Reservation is only allowed during the load sequence and before any
    interfaces (e.g. mlx5_ib or mlx5_en) are up.
    
    After reservation, a submodule may call mlx5_core_reserved_gid_alloc/
    free to allocate entries from the reserved GIDs pool.
    
    Reserve a GID table entry for every supported FPGA QP.
    
    A later patch in the patchset will remove them from being reported to
    IB core.
    Another such patch will make use of these for FPGA QPs in Innova NIC.
    
    Added lib/mlx5.h to serve as a library for mlx5 submodlues, and to
    expose only public mlx5 API, more mlx5 library files will be added in
    future submissions.
    
    Signed-off-by: Ilan Tayari <ilant@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 750701b3b863..08e99bd2cd77 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -44,6 +44,7 @@
 #include <linux/workqueue.h>
 #include <linux/mempool.h>
 #include <linux/interrupt.h>
+#include <linux/idr.h>
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
@@ -737,6 +738,14 @@ struct mlx5e_resources {
 	struct mlx5_sq_bfreg       bfreg;
 };
 
+#define MLX5_MAX_RESERVED_GIDS 8
+
+struct mlx5_rsvd_gids {
+	unsigned int start;
+	unsigned int count;
+	struct ida ida;
+};
+
 struct mlx5_core_dev {
 	struct pci_dev	       *pdev;
 	/* sync pci state */
@@ -766,6 +775,9 @@ struct mlx5_core_dev {
 	atomic_t		num_qps;
 	u32			issi;
 	struct mlx5e_resources  mlx5e_res;
+	struct {
+		struct mlx5_rsvd_gids	reserved_gids;
+	} roce;
 #ifdef CONFIG_MLX5_FPGA
 	struct mlx5_fpga_device *fpga;
 #endif
@@ -1045,6 +1057,11 @@ int mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,
 		     bool map_wc, bool fast_path);
 void mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg);
 
+unsigned int mlx5_core_reserved_gids_count(struct mlx5_core_dev *dev);
+int mlx5_core_roce_gid_set(struct mlx5_core_dev *dev, unsigned int index,
+			   u8 roce_version, u8 roce_l3_type, const u8 *gid,
+			   const u8 *mac, bool vlan, u16 vlan_id);
+
 static inline int fw_initializing(struct mlx5_core_dev *dev)
 {
 	return ioread32be(&dev->iseg->initializing) >> 31;

commit 2a0165a034ac024b60cca49c61e46f4afa2e4d98
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Thu Mar 30 17:09:00 2017 +0300

    net/mlx5: Cancel delayed recovery work when unloading the driver
    
    Draining the health workqueue will ignore future health works including
    the one that report hardware failure and thus we can't enter error state
    Instead cancel the recovery flow and make sure only recovery flow won't
    be scheduled.
    
    Fixes: 5e44fca50470 ('net/mlx5: Only cancel recovery work when cleaning up device')
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 93273d9ea4d1..ba260330ce5e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -925,6 +925,7 @@ int mlx5_health_init(struct mlx5_core_dev *dev);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
 void mlx5_drain_health_wq(struct mlx5_core_dev *dev);
+void mlx5_drain_health_recovery(struct mlx5_core_dev *dev);
 int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
 			struct mlx5_buf *buf, int node);
 int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, struct mlx5_buf *buf);

commit 4717628938423fcba0aa8fa889e9fed4eb6a655f
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Tue Apr 18 13:35:39 2017 +0300

    net/mlx5: Add MCC (Management Component Control) register definitions
    
    MCC (Management Component Control) allows to control a firmware
    component update.
    
    MCDA (Management Component Data Access) allows to read and write
    a firmware component.
    
    MCQI (Management Component Query Information) allows to query
    information about firmware components.
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Yotam Gigi <yotamg@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index bf15e87da8fa..750701b3b863 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -131,6 +131,9 @@ enum {
 	MLX5_REG_MPCNT		 = 0x9051,
 	MLX5_REG_MTPPS		 = 0x9053,
 	MLX5_REG_MTPPSE		 = 0x9054,
+	MLX5_REG_MCQI		 = 0x9061,
+	MLX5_REG_MCC		 = 0x9062,
+	MLX5_REG_MCDA		 = 0x9063,
 	MLX5_REG_MCAM		 = 0x907f,
 };
 

commit 4525abeaae54560254a1bb8970b3d4c225d32ef4
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Thu Feb 9 13:20:46 2017 +0200

    net/mlx5: Expose command polling interface
    
    Add a new interface for commands execution that allows the
    caller to wait for the command's completion in a busy-wait
    loop (polling mode).
    
    This is useful if we want to execute a command in a polling mode
    while the driver is working in events mode for the rest of
    the commands.
    This interface will be used in the downstream patches.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6ea2f5734e37..bf15e87da8fa 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -817,6 +817,7 @@ struct mlx5_cmd_work_ent {
 	u64			ts1;
 	u64			ts2;
 	u16			op;
+	bool			polling;
 };
 
 struct mlx5_pas {
@@ -915,6 +916,8 @@ int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 int mlx5_cmd_exec_cb(struct mlx5_core_dev *dev, void *in, int in_size,
 		     void *out, int out_size, mlx5_cmd_cbk_t callback,
 		     void *context);
+int mlx5_cmd_exec_polling(struct mlx5_core_dev *dev, void *in, int in_size,
+			  void *out, int out_size);
 void mlx5_cmd_mbox_status(void *out, u8 *status, u32 *syndrome);
 
 int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);

commit 34aa83c2fc23e055968387c8b78ac8bafd735aff
Merge: 47936d35edba e2a9aa5ab2a4
Author: David S. Miller <davem@davemloft.net>
Date:   Fri May 26 20:46:35 2017 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Overlapping changes in drivers/net/phy/marvell.c, bug fix in 'net'
    restricting a HW workaround alongside cleanups in 'net-next'.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 73dd3a4839c1d27c36d4dcc92e1ff44225ecbeb7
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Thu Feb 23 11:19:36 2017 +0200

    net/mlx5: Avoid using pending command interface slots
    
    Currently when firmware command gets stuck or it takes long time to
    complete, the driver command will get timeout and the command slot is
    freed and can be used for new commands, and if the firmware receive new
    command on the old busy slot its behavior is unexpected and this could
    be harmful.
    To fix this when the driver command gets timeout we return failure,
    but we don't free the command slot and we wait for the firmware to
    explicitly respond to that command.
    Once all the entries are busy we will stop processing new firmware
    commands.
    
    Fixes: 9cba4ebcf374 ('net/mlx5: Fix potential deadlock in command mode change')
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Cc: kernel-team@fb.com
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index bcdf739ee41a..93273d9ea4d1 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -787,7 +787,12 @@ enum {
 
 typedef void (*mlx5_cmd_cbk_t)(int status, void *context);
 
+enum {
+	MLX5_CMD_ENT_STATE_PENDING_COMP,
+};
+
 struct mlx5_cmd_work_ent {
+	unsigned long		state;
 	struct mlx5_cmd_msg    *in;
 	struct mlx5_cmd_msg    *out;
 	void		       *uout;
@@ -976,7 +981,7 @@ void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
-void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec);
+void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced);
 void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
 int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 		       int nent, u64 mask, const char *name,

commit e29341fb3a5b885a4bb5b9a38f2814ca07d3382c
Author: Ilan Tayari <ilant@mellanox.com>
Date:   Mon Mar 13 20:05:45 2017 +0200

    net/mlx5: FPGA, Add basic support for Innova
    
    Mellanox Innova is a NIC with ConnectX and an FPGA on the same
    board. The FPGA is a bump-on-the-wire and thus affects operation of
    the mlx5_core driver on the ConnectX ASIC.
    
    Add basic support for Innova in mlx5_core.
    
    This allows using the Innova card as a regular NIC, by detecting
    the FPGA capability bit, and verifying its load state before
    initializing ConnectX interfaces.
    
    Also detect FPGA fatal runtime failures and enter error state if
    they ever happen.
    
    All new FPGA-related logic is placed in its own subdirectory 'fpga',
    which may be built by selecting CONFIG_MLX5_FPGA.
    This prepares for further support of various Innova features in later
    patchsets.
    Additional details about hardware architecture will be provided as
    more features get submitted.
    
    Signed-off-by: Ilan Tayari <ilant@mellanox.com>
    Reviewed-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index a277bb36c21f..55bb712643cb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -108,6 +108,8 @@ enum {
 	MLX5_REG_QTCT		 = 0x400a,
 	MLX5_REG_DCBX_PARAM      = 0x4020,
 	MLX5_REG_DCBX_APP        = 0x4021,
+	MLX5_REG_FPGA_CAP	 = 0x4022,
+	MLX5_REG_FPGA_CTRL	 = 0x4023,
 	MLX5_REG_PCAP		 = 0x5001,
 	MLX5_REG_PMTU		 = 0x5003,
 	MLX5_REG_PTYS		 = 0x5004,
@@ -761,6 +763,9 @@ struct mlx5_core_dev {
 	atomic_t		num_qps;
 	u32			issi;
 	struct mlx5e_resources  mlx5e_res;
+#ifdef CONFIG_MLX5_FPGA
+	struct mlx5_fpga_device *fpga;
+#endif
 #ifdef CONFIG_RFS_ACCEL
 	struct cpu_rmap         *rmap;
 #endif

commit 0179720d6be2096b8d0a4d143254ff9e77747daa
Author: Ilan Tayari <ilant@mellanox.com>
Date:   Sun May 7 13:48:31 2017 +0300

    net/mlx5: Introduce trigger_health_work function
    
    Introduce new function for entering bad-health state.
    
    This function will be called from FPGA-related logic in a later patch from
    asynchronous event (IRQ) context, for that we change the spin lock to an
    IRQ-safe one.
    
    Signed-off-by: Ilan Tayari <ilant@mellanox.com>
    Reviewed-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c2740688d679..a277bb36c21f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -915,6 +915,7 @@ int mlx5_health_init(struct mlx5_core_dev *dev);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
 void mlx5_drain_health_wq(struct mlx5_core_dev *dev);
+void mlx5_trigger_health_work(struct mlx5_core_dev *dev);
 int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
 			struct mlx5_buf *buf, int node);
 int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, struct mlx5_buf *buf);

commit 1b9a07ee25049724ab7f7c32282fbf5452530cea
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Wed May 10 21:32:18 2017 +0300

    {net, IB}/mlx5: Replace mlx5_vzalloc with kvzalloc
    
    Commit a7c3e901a46f ("mm: introduce kv[mz]alloc helpers") added
    proper implementation of mlx5_vzalloc function to the MM core.
    
    This made the mlx5_vzalloc function useless, so let's remove it.
    
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index bcdf739ee41a..c2740688d679 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -890,11 +890,6 @@ static inline u16 cmdif_rev(struct mlx5_core_dev *dev)
 	return ioread32be(&dev->iseg->cmdif_rev_fw_sub) >> 16;
 }
 
-static inline void *mlx5_vzalloc(unsigned long size)
-{
-	return kvzalloc(size, GFP_KERNEL);
-}
-
 static inline u32 mlx5_base_mkey(const u32 key)
 {
 	return key & 0xffffff00u;

commit 3341713c67d5eae5c68bab30add97e9f9ecfafa5
Merge: 857f8640147c 693dfd5a3f19 67cf3623e097
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 8 20:07:29 2017 -0700

    Merge tags 'for-linus' and 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull more rdma updates from Doug Ledford:
     "As mentioned in my first pull request, this is the subsequent pull
      requests I had. This is all I have, and in fact this cleans out the
      RDMA subsystem's entire patchworks queue of kernel changes that are
      ready to go (well, it did for the weekend anyway, a few new patches
      are in, but they'll be coming during the -rc cycle).
    
      The first tag contains a single patch that would have conflicted if
      taken from my tree or DaveM's tree as it needed our trees merged to
      come cleanly.
    
      The second tag contains the patch series from Intel plus three other
      stragllers that came in late last week. I took them because it allowed
      me to legitimately claim that the RDMA patchworks queue was, for a
      short time, 100% cleared of all waiting kernel patches, woohoo! :-).
    
      I have it under my for-next tag, so it did get 0day and linux- next
      over the end of last week, and linux-next did show one minor conflict.
    
      Summary:
    
      'for-linus' tag:
       - mlx5/IPoIB fixup patch
    
      'for-next' tag:
       - the hfi1 15 patch set that landed late
       - IPoIB get_link_ksettings which landed late because I asked for a
         respin
       - one late rxe change
       - one -rc worthy fix that's in early"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma:
      IB/mlx5: Enable IPoIB acceleration
    
    * tag 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma:
      rxe: expose num_possible_cpus() cnum_comp_vectors
      IB/rxe: Update caller's CRC for RXE_MEM_TYPE_DMA memory type
      IB/hfi1: Clean up on context initialization failure
      IB/hfi1: Fix an assign/ordering issue with shared context IDs
      IB/hfi1: Clean up context initialization
      IB/hfi1: Correctly clear the pkey
      IB/hfi1: Search shared contexts on the opened device, not all devices
      IB/hfi1: Remove atomic operations for SDMA_REQ_HAVE_AHG bit
      IB/hfi1: Use filedata rather than filepointer
      IB/hfi1: Name function prototype parameters
      IB/hfi1: Fix a subcontext memory leak
      IB/hfi1: Return an error on memory allocation failure
      IB/hfi1: Adjust default eager_buffer_size to 8MB
      IB/hfi1: Get rid of divide when setting the tx request header
      IB/hfi1: Fix yield logic in send engine
      IB/hfi1, IB/rdmavt: Move r_adefered to r_lock cache line
      IB/hfi1: Fix checks for Offline transient state
      IB/ipoib: add get_link_ksettings in ethtool

commit 752ade68cbd81d0321dfecc188f655a945551b25
Author: Michal Hocko <mhocko@suse.com>
Date:   Mon May 8 15:57:27 2017 -0700

    treewide: use kv[mz]alloc* rather than opencoded variants
    
    There are many code paths opencoding kvmalloc.  Let's use the helper
    instead.  The main difference to kvmalloc is that those users are
    usually not considering all the aspects of the memory allocator.  E.g.
    allocation requests <= 32kB (with 4kB pages) are basically never failing
    and invoke OOM killer to satisfy the allocation.  This sounds too
    disruptive for something that has a reasonable fallback - the vmalloc.
    On the other hand those requests might fallback to vmalloc even when the
    memory allocator would succeed after several more reclaim/compaction
    attempts previously.  There is no guarantee something like that happens
    though.
    
    This patch converts many of those places to kv[mz]alloc* helpers because
    they are more conservative.
    
    Link: http://lkml.kernel.org/r/20170306103327.2766-2-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com> # Xen bits
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Andreas Dilger <andreas.dilger@intel.com> # Lustre
    Acked-by: Christian Borntraeger <borntraeger@de.ibm.com> # KVM/s390
    Acked-by: Dan Williams <dan.j.williams@intel.com> # nvdim
    Acked-by: David Sterba <dsterba@suse.com> # btrfs
    Acked-by: Ilya Dryomov <idryomov@gmail.com> # Ceph
    Acked-by: Tariq Toukan <tariqt@mellanox.com> # mlx4
    Acked-by: Leon Romanovsky <leonro@mellanox.com> # mlx5
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Anton Vorontsov <anton@enomsg.org>
    Cc: Colin Cross <ccross@android.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Ben Skeggs <bskeggs@redhat.com>
    Cc: Kent Overstreet <kent.overstreet@gmail.com>
    Cc: Santosh Raspatur <santosh@chelsio.com>
    Cc: Hariprasad S <hariprasad@chelsio.com>
    Cc: Yishai Hadas <yishaih@mellanox.com>
    Cc: Oleg Drokin <oleg.drokin@intel.com>
    Cc: "Yan, Zheng" <zyan@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3fece51dcf13..18fc65b84b79 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -892,12 +892,7 @@ static inline u16 cmdif_rev(struct mlx5_core_dev *dev)
 
 static inline void *mlx5_vzalloc(unsigned long size)
 {
-	void *rtn;
-
-	rtn = kzalloc(size, GFP_KERNEL | __GFP_NOWARN);
-	if (!rtn)
-		rtn = vzalloc(size);
-	return rtn;
+	return kvzalloc(size, GFP_KERNEL);
 }
 
 static inline u32 mlx5_base_mkey(const u32 key)

commit 693dfd5a3f19efc44acf3a57217c0480e414f8ee
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Apr 27 17:01:34 2017 +0300

    IB/mlx5: Enable IPoIB acceleration
    
    Enable mlx5 IPoIB acceleration by declaring
    mlx5_ib_{alloc,free}_rdma_netdev and assigning the mlx5
    IPoIB rdma_netdev callbacks.
    
    In addition, this patch brings in sync mlx5's IPoIB parts for net and IB
    trees. As a precaution, we disabled IPoIB acceleration by default (in
    the mlx5_core Kconfig file).
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3fece51dcf13..cef2b98d479f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1102,6 +1102,25 @@ struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
 struct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev);
 void mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up);
 
+#ifndef CONFIG_MLX5_CORE_IPOIB
+static inline
+struct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,
+					  struct ib_device *ibdev,
+					  const char *name,
+					  void (*setup)(struct net_device *))
+{
+	return ERR_PTR(-EOPNOTSUPP);
+}
+
+static inline void mlx5_rdma_netdev_free(struct net_device *netdev) {}
+#else
+struct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,
+					  struct ib_device *ibdev,
+					  const char *name,
+					  void (*setup)(struct net_device *));
+void mlx5_rdma_netdev_free(struct net_device *netdev);
+#endif /* CONFIG_MLX5_CORE_IPOIB */
+
 struct mlx5_profile {
 	u64	mask;
 	u8	log_max_qp;

commit f6dfb4c3f2161c23ab2939dd1b5f133dcdf147c6
Author: Hadar Hen Zion <hadarh@mellanox.com>
Date:   Fri Feb 24 12:16:33 2017 +0200

    net/mlx5e: Update neighbour 'used' state using HW flow rules counters
    
    When IP tunnel encapsulation rules are offloaded, the kernel can't see
    the traffic of the offloaded flow. The neighbour for the IP tunnel
    destination of the offloaded flow can mistakenly become STALE and
    deleted by the kernel since its 'used' value wasn't changed.
    
    To make sure that a neighbour which is used by the HW won't become
    STALE, we proactively update the neighbour 'used' value every
    DELAY_PROBE_TIME period, when packets were matched and counted by the HW
    for one of the tunnel encap flows related to this neighbour.
    
    The periodic task that updates the used neighbours is scheduled when a
    tunnel encap rule is successfully offloaded into HW and keeps re-scheduling
    itself as long as the representor's neighbours list isn't empty.
    
    Add, remove, lookup and status change operations done over the
    representor's neighbours list or the neighbour hash entry encaps list
    are all serialized by RTNL lock.
    
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index f50864626230..3fece51dcf13 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -540,6 +540,7 @@ struct mlx5_fc_stats {
 	struct workqueue_struct *wq;
 	struct delayed_work work;
 	unsigned long next_query;
+	unsigned long sampling_interval; /* jiffies */
 };
 
 struct mlx5_eswitch;

commit aff2615763f206f897146e0ee1ddae8e22055ae3
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Sat Mar 25 00:52:05 2017 +0300

    net/mlx5e: Single bfreg (UAR) for all mlx5e SQs and netdevs
    
    One is sufficient since Blue Flame is not supported anymore.
    This will also come in handy for switchdev mode to save resources, since
    VF representors will use same single UAR as well for their own SQs.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2fcff6b4503f..f50864626230 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -728,6 +728,7 @@ struct mlx5e_resources {
 	u32                        pdn;
 	struct mlx5_td             td;
 	struct mlx5_core_mkey      mkey;
+	struct mlx5_sq_bfreg       bfreg;
 };
 
 struct mlx5_core_dev {

commit af17fe7a63db7e11d65f1296f0cbf156a89a2735
Merge: f14cc3b13d8f cdbe33d0f82d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 23 11:27:49 2017 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull Mellanox rdma updates from Doug Ledford:
     "Mellanox specific updates for 4.11 merge window
    
      Because the Mellanox code required being based on a net-next tree, I
      keept it separate from the remainder of the RDMA stack submission that
      is based on 4.10-rc3.
    
      This branch contains:
    
       - Various mlx4 and mlx5 fixes and minor changes
    
       - Support for adding a tag match rule to flow specs
    
       - Support for cvlan offload operation for raw ethernet QPs
    
       - A change to the core IB code to recognize raw eth capabilities and
         enumerate them (touches non-Mellanox code)
    
       - Implicit On-Demand Paging memory registration support"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (40 commits)
      IB/mlx5: Fix configuration of port capabilities
      IB/mlx4: Take source GID by index from HW GID table
      IB/mlx5: Fix blue flame buffer size calculation
      IB/mlx4: Remove unused variable from function declaration
      IB: Query ports via the core instead of direct into the driver
      IB: Add protocol for USNIC
      IB/mlx4: Support raw packet protocol
      IB/mlx5: Support raw packet protocol
      IB/core: Add raw packet protocol
      IB/mlx5: Add implicit MR support
      IB/mlx5: Expose MR cache for mlx5_ib
      IB/mlx5: Add null_mkey access
      IB/umem: Indicate that process is being terminated
      IB/umem: Update on demand page (ODP) support
      IB/core: Add implicit MR flag
      IB/mlx5: Support creation of a WQ with scatter FCS offload
      IB/mlx5: Enable QP creation with cvlan offload
      IB/mlx5: Enable WQ creation and modification with cvlan offload
      IB/mlx5: Expose vlan offloads capabilities
      IB/uverbs: Enable QP creation with cvlan offload
      ...

commit 81713d3788d2e6bc005f15ee1c59d0eb06050a6b
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Wed Jan 18 16:58:11 2017 +0200

    IB/mlx5: Add implicit MR support
    
    Add implicit MR, covering entire user address space.
    The MR is implemented as an indirect KSM MR consisting of
    1GB direct MRs.
    Pages and direct MRs are added/removed to MR by ODP.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2534b8a0fd7b..886ff2b00500 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1053,6 +1053,8 @@ enum {
 
 enum {
 	MAX_UMR_CACHE_ENTRY = 20,
+	MLX5_IMR_MTT_CACHE_ENTRY,
+	MLX5_IMR_KSM_CACHE_ENTRY,
 	MAX_MR_CACHE_ENTRIES
 };
 

commit 49780d42dfc9ec0f4090c32ca59688449da1a1cd
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Wed Jan 18 16:58:10 2017 +0200

    IB/mlx5: Expose MR cache for mlx5_ib
    
    Allow other parts of mlx5_ib to use MR cache mechanism.
    * Add new functions mlx5_mr_cache_alloc and mlx5_mr_cache_free
    * Traditional MTT MKey buckets are limited by MAX_UMR_CACHE_ENTRY
      Additinal buckets may be added above.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b8d69aeb1784..2534b8a0fd7b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1052,7 +1052,8 @@ enum {
 };
 
 enum {
-	MAX_MR_CACHE_ENTRIES    = 21,
+	MAX_UMR_CACHE_ENTRY = 20,
+	MAX_MR_CACHE_ENTRIES
 };
 
 enum {

commit c43f1112c068f3b4b20a0a9d461c341d9caeb376
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Wed Jan 18 14:10:33 2017 +0200

    IB/mlx5: Add additional checks before processing MADs
    
    Check the has_smi bit in vport context and class version of MADs
    before allowing MADs processing to take place.
    MAD_IFC SMI commands can be executed only if smi bit is set.
    
    Fixes: e126ba97dba9 ('mlx5: Add driver for Mellanox Connect-IB adapters')
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Signed-off-by: Parvi Kaustubhi <parvik@mellanox.com>
    Reviewed-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3a309f6a4a15..b8d69aeb1784 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -289,6 +289,7 @@ struct mlx5_port_caps {
 	int	gid_table_len;
 	int	pkey_table_len;
 	u8	ext_port_cap;
+	bool	has_smi;
 };
 
 struct mlx5_cmd_mailbox {

commit 701052c578195e6e02a22647fa6fd1c90c31dafd
Author: Gal Pressman <galp@mellanox.com>
Date:   Wed Dec 14 17:40:41 2016 +0200

    net/mlx5: Move cached hca caps to designated caps struct
    
    The caps structure consists of hca caps and port/management caps,
    all under one roof.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index f4d6d390a9cf..1bc4641734da 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -738,9 +738,9 @@ struct mlx5_core_dev {
 	char			board_id[MLX5_BOARD_ID_LEN];
 	struct mlx5_cmd		cmd;
 	struct mlx5_port_caps	port_caps[MLX5_MAX_PORTS];
-	u32 hca_caps_cur[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
-	u32 hca_caps_max[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 	struct {
+		u32 hca_cur[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
+		u32 hca_max[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 		u32 pcam[MLX5_ST_SZ_DW(pcam_reg)];
 		u32 mcam[MLX5_ST_SZ_DW(mcam_reg)];
 	} caps;

commit 8ed1a6306dc7892b63be7cdb1e3b1123265f42ff
Author: Gal Pressman <galp@mellanox.com>
Date:   Thu Nov 17 13:46:01 2016 +0200

    net/mlx5: Add MPCNT register infrastructure
    
    Add the needed infrastructure for future use of MPCNT register.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 69c4661d391e..f4d6d390a9cf 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -126,6 +126,7 @@ enum {
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 	MLX5_REG_MCIA		 = 0x9014,
 	MLX5_REG_MLCR		 = 0x902b,
+	MLX5_REG_MPCNT		 = 0x9051,
 	MLX5_REG_MTPPS		 = 0x9053,
 	MLX5_REG_MTPPSE		 = 0x9054,
 	MLX5_REG_MCAM		 = 0x907f,

commit 71862561f3a62015a11de16d1c306481e8415c08
Author: Gal Pressman <galp@mellanox.com>
Date:   Thu Dec 8 16:03:31 2016 +0200

    net/mlx5: Query and cache PCAM, MCAM registers on initialization
    
    On load_one, we now cache our capabilities registers internally, similar
    to QUERY_HCA_CAP. Capabilities can later be queried using macros
    introduced in this patch.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 60c2b156da8c..69c4661d391e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -739,6 +739,10 @@ struct mlx5_core_dev {
 	struct mlx5_port_caps	port_caps[MLX5_MAX_PORTS];
 	u32 hca_caps_cur[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 	u32 hca_caps_max[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
+	struct {
+		u32 pcam[MLX5_ST_SZ_DW(pcam_reg)];
+		u32 mcam[MLX5_ST_SZ_DW(mcam_reg)];
+	} caps;
 	phys_addr_t		iseg_base;
 	struct mlx5_init_seg __iomem *iseg;
 	enum mlx5_device_state	state;

commit cfdcbceaeffc669b70d904d80a2df9c86c232566
Author: Gal Pressman <galp@mellanox.com>
Date:   Thu Dec 8 15:52:00 2016 +0200

    net/mlx5: Expose PCAM, MCAM registers infrastructure
    
    PCAM: Ports capabilities mask register.
    MCAM: Management capabilities mask register.
    
    PCAM and MCAM registers will provide information regarding firmware
    support for different features, in order to avoid cases where new driver
    combined with old firmware results in syndromes (for ex. PCIe counters
    before this patchset).
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ebbc8834063b..60c2b156da8c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -121,12 +121,14 @@ enum {
 	MLX5_REG_PVLC		 = 0x500f,
 	MLX5_REG_PCMR		 = 0x5041,
 	MLX5_REG_PMLP		 = 0x5002,
+	MLX5_REG_PCAM		 = 0x507f,
 	MLX5_REG_NODE_DESC	 = 0x6001,
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 	MLX5_REG_MCIA		 = 0x9014,
 	MLX5_REG_MLCR		 = 0x902b,
 	MLX5_REG_MTPPS		 = 0x9053,
 	MLX5_REG_MTPPSE		 = 0x9054,
+	MLX5_REG_MCAM		 = 0x907f,
 };
 
 enum mlx5_dcbx_oper_mode {

commit f9a1ef720e9e32bc6a4a382c15ac77d62749c79e
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Mon Oct 10 16:05:53 2016 +0300

    net/mlx5: Add MTPPS and MTPPSE registers infrastructure
    
    Implement query and set functionality for MTPPS and MTPPSE registers.
    MTPPS (Management Pulse Per Second) provides the device PPS capabilities,
    configures the PPS in and out modules and holds the PPS in time stamp.
    Query MTPPS is supported only when HCA_CAP.pps is set and modify is supported
    when HCA_CAP.pps_modify is set.
    
    MTPPSE (Management Pulse Per Second Event) configures the different event
    generation modes for PPS. Supported when HCA_CAP.pps is set.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3a309f6a4a15..ebbc8834063b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -125,6 +125,8 @@ enum {
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 	MLX5_REG_MCIA		 = 0x9014,
 	MLX5_REG_MLCR		 = 0x902b,
+	MLX5_REG_MTPPS		 = 0x9053,
+	MLX5_REG_MTPPSE		 = 0x9054,
 };
 
 enum mlx5_dcbx_oper_mode {
@@ -172,6 +174,7 @@ enum mlx5_dev_event {
 	MLX5_DEV_EVENT_PKEY_CHANGE,
 	MLX5_DEV_EVENT_GUID_CHANGE,
 	MLX5_DEV_EVENT_CLIENT_REREG,
+	MLX5_DEV_EVENT_PPS,
 };
 
 enum mlx5_port_status {

commit bda65b4255ac983ce36a6c0ea6a7794f8e8fcc86
Merge: b369e7fd41f7 f502d834950a
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jan 9 17:09:31 2017 -0500

    Merge tag 'mlx5-4kuar-for-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Saeed Mahameed says:
    
    ====================
    mlx5 4K UAR
    
    The following series of patches optimizes the usage of the UAR area which is
    contained within the BAR 0-1. Previous versions of the firmware and the driver
    assumed each system page contains a single UAR. This patch set will query the
    firmware for a new capability that if published, means that the firmware can
    support UARs of fixed 4K regardless of system page size. In the case of
    powerpc, where page size equals 64KB, this means we can utilize 16 UARs per
    system page. Since user space processes by default consume eight UARs per
    context this means that with this change a process will need a single system
    page to fulfill that requirement and in fact make use of more UARs which is
    better in terms of performance.
    
    In addition to optimizing user-space processes, we introduce an allocator
    that can be used by kernel consumers to allocate blue flame registers
    (which are areas within a UAR that are used to write doorbells). This provides
    further optimization on using the UAR area since the Ethernet driver makes
    use of a single blue flame register per system page and now it will use two
    blue flame registers per 4K.
    
    The series also makes changes to naming conventions and now the terms used in
    the driver code match the terms used in the PRM (programmers reference manual).
    Thus, what used to be called UUAR (micro UAR) is now called BFREG (blue flame
    register).
    
    In order to support compatibility between different versions of
    library/driver/firmware, the library has now means to notify the kernel driver
    that it supports the new scheme and the kernel can notify the library if it
    supports this extension. So mixed versions of libraries can run concurrently
    without any issues.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 30aa60b3bd12bd79b5324b7b595bd3446ab24b52
Author: Eli Cohen <eli@mellanox.com>
Date:   Tue Jan 3 23:55:27 2017 +0200

    IB/mlx5: Support 4k UAR for libmlx5
    
    Add fields to structs to convey to kernel an indication whether the
    library supports multi UARs per page and return to the library the size
    of a UAR based on the queried value.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7e7394fef835..10e632588cd5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -467,12 +467,6 @@ struct mlx5_sq_bfreg {
 	unsigned int		offset;
 };
 
-struct mlx5_uar {
-	u32			index;
-	void __iomem	       *map;
-	void __iomem	       *bf_map;
-};
-
 struct mlx5_core_health {
 	struct health_buffer __iomem   *health;
 	__be32 __iomem		       *health_counter;
@@ -725,7 +719,6 @@ struct mlx5_td {
 };
 
 struct mlx5e_resources {
-	struct mlx5_uar            cq_uar;
 	u32                        pdn;
 	struct mlx5_td             td;
 	struct mlx5_core_mkey      mkey;
@@ -915,11 +908,6 @@ void mlx5_cmd_mbox_status(void *out, u8 *status, u32 *syndrome);
 int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);
 int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
 int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
-int mlx5_alloc_bfregs(struct mlx5_core_dev *dev, struct mlx5_bfreg_info *bfregi);
-int mlx5_free_bfregs(struct mlx5_core_dev *dev, struct mlx5_bfreg_info *bfregi);
-int mlx5_alloc_map_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar,
-		       bool map_wc);
-void mlx5_unmap_free_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);
 void mlx5_health_cleanup(struct mlx5_core_dev *dev);
 int mlx5_health_init(struct mlx5_core_dev *dev);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);

commit b037c29a8056b8e896c4e084ba7cc30d6a1f165f
Author: Eli Cohen <eli@mellanox.com>
Date:   Tue Jan 3 23:55:26 2017 +0200

    IB/mlx5: Allow future extension of libmlx5 input data
    
    Current check requests that new fields in struct
    mlx5_ib_alloc_ucontext_req_v2 that are not known to the driver be zero.
    This was introduced so new libraries passing additional information to
    the kernel through struct mlx5_ib_alloc_ucontext_req_v2 will be notified
    by old kernels that do not support their request by failing the
    operation. This schecme is problematic since it requires libmlx5 to issue
    the requests with descending input size for struct
    mlx5_ib_alloc_ucontext_req_v2.
    
    To avoid this, we require that new features that will obey the following
    rules:
    If the feature requires one or more fields in the response and the at
    least one of the fields can be encoded such that a zero value means the
    kernel ignored the request then this field will provide the indication
    to the library. If no response is required or if zero is a valid
    response, a new field should be added that indicates to the library
    whether its request was processed.
    
    Fixes: b368d7cb8ceb ('IB/mlx5: Add hca_core_clock_offset to udata in init_ucontext')
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index bb362f506a2e..7e7394fef835 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -189,18 +189,17 @@ enum mlx5_eq_type {
 };
 
 struct mlx5_bfreg_info {
-	struct mlx5_uar	       *uars;
-	int			num_uars;
+	u32		       *sys_pages;
 	int			num_low_latency_bfregs;
-	unsigned long	       *bitmap;
 	unsigned int	       *count;
-	struct mlx5_bf	       *bfs;
 
 	/*
 	 * protect bfreg allocation data structs
 	 */
 	struct mutex		lock;
 	u32			ver;
+	bool			lib_uar_4k;
+	u32			num_sys_pages;
 };
 
 struct mlx5_cmd_first {
@@ -470,13 +469,10 @@ struct mlx5_sq_bfreg {
 
 struct mlx5_uar {
 	u32			index;
-	struct list_head	bf_list;
-	unsigned		free_bf_bmap;
-	void __iomem	       *bf_map;
 	void __iomem	       *map;
+	void __iomem	       *bf_map;
 };
 
-
 struct mlx5_core_health {
 	struct health_buffer __iomem   *health;
 	__be32 __iomem		       *health_counter;

commit 5fe9dec0d045437e48f112b8fa705197bd7bc3c0
Author: Eli Cohen <eli@mellanox.com>
Date:   Tue Jan 3 23:55:25 2017 +0200

    IB/mlx5: Use blue flame register allocator in mlx5_ib
    
    Make use of the blue flame registers allocator at mlx5_ib. Since blue
    flame was not really supported we remove all the code that is related to
    blue flame and we let all consumers to use the same blue flame register.
    Once blue flame is supported we will add the code. As part of this patch
    we also move the definition of struct mlx5_bf to mlx5_ib.h as it is only
    used by mlx5_ib.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9a3a0954855b..bb362f506a2e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -203,23 +203,6 @@ struct mlx5_bfreg_info {
 	u32			ver;
 };
 
-struct mlx5_bf {
-	void __iomem	       *reg;
-	void __iomem	       *regreg;
-	int			buf_size;
-	struct mlx5_uar	       *uar;
-	unsigned long		offset;
-	int			need_lock;
-	/* protect blue flame buffer selection when needed
-	 */
-	spinlock_t		lock;
-
-	/* serialize 64 bit writes when done as two 32 bit accesses
-	 */
-	spinlock_t		lock32;
-	int			bfregn;
-};
-
 struct mlx5_cmd_first {
 	__be32		data[4];
 };
@@ -612,8 +595,6 @@ struct mlx5_priv {
 	struct mlx5_eq_table	eq_table;
 	struct msix_entry	*msix_arr;
 	struct mlx5_irq_info	*irq_info;
-	struct mlx5_bfreg_info	bfregi;
-	MLX5_DECLARE_DOORBELL_LOCK(cq_uar_lock);
 
 	/* pages stuff */
 	struct workqueue_struct *pg_wq;

commit 0118717583cda6f4f36092853ad0345e8150b286
Author: Eli Cohen <eli@mellanox.com>
Date:   Tue Jan 3 23:55:24 2017 +0200

    net/mlx5: Add interface to get reference to a UAR
    
    A reference to a UAR is required to generate CQ or EQ doorbells. Since
    CQ or EQ doorbells can all be generated using the same UAR area without
    any effect on performance, we are just getting a reference to any
    available UAR, If one is not available we allocate it but we don't waste
    the blue flame registers it can provide and we will use them for
    subsequent allocations.
    We get a reference to such UAR and put in mlx5_priv so any kernel
    consumer can make use of it.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 969aa1fe17e2..9a3a0954855b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -679,6 +679,7 @@ struct mlx5_priv {
 	struct srcu_struct      pfault_srcu;
 #endif
 	struct mlx5_bfreg_data		bfregs;
+	struct mlx5_uars_page	       *uar;
 };
 
 enum mlx5_device_state {
@@ -1007,7 +1008,7 @@ void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec);
 void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
 int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 		       int nent, u64 mask, const char *name,
-		       struct mlx5_uar *uar, enum mlx5_eq_type type);
+		       enum mlx5_eq_type type);
 int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_start_eqs(struct mlx5_core_dev *dev);
 int mlx5_stop_eqs(struct mlx5_core_dev *dev);
@@ -1118,6 +1119,8 @@ int mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);
 int mlx5_cmd_destroy_vport_lag(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
 struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
+struct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev);
+void mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up);
 
 struct mlx5_profile {
 	u64	mask;

commit a6d51b68611e98f05042ada662aed5dbe3279c1e
Author: Eli Cohen <eli@mellanox.com>
Date:   Tue Jan 3 23:55:23 2017 +0200

    net/mlx5: Introduce blue flame register allocator
    
    Here is an implementation of an allocator that allocates blue flame
    registers. A blue flame register is used for generating send doorbells.
    A blue flame register can be used to generate either a regular doorbell
    or a blue flame doorbell where the data to be sent is written to the
    device's I/O memory hence saving the need to read the data from memory.
    For blue flame kind of doorbells to succeed, the blue flame register
    need to be mapped as write combining. The user can specify what kind of
    send doorbells she wishes to use. If she requested write combining
    mapping but that failed, the allocator will fall back to non write
    combining mapping and will indicate that to the user.
    Subsequent patches in this series will make use of this allocator.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3d07e25b3bf1..969aa1fe17e2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -452,6 +452,39 @@ struct mlx5_eq_table {
 	spinlock_t		lock;
 };
 
+struct mlx5_uars_page {
+	void __iomem	       *map;
+	bool			wc;
+	u32			index;
+	struct list_head	list;
+	unsigned int		bfregs;
+	unsigned long	       *reg_bitmap; /* for non fast path bf regs */
+	unsigned long	       *fp_bitmap;
+	unsigned int		reg_avail;
+	unsigned int		fp_avail;
+	struct kref		ref_count;
+	struct mlx5_core_dev   *mdev;
+};
+
+struct mlx5_bfreg_head {
+	/* protect blue flame registers allocations */
+	struct mutex		lock;
+	struct list_head	list;
+};
+
+struct mlx5_bfreg_data {
+	struct mlx5_bfreg_head	reg_head;
+	struct mlx5_bfreg_head	wc_head;
+};
+
+struct mlx5_sq_bfreg {
+	void __iomem	       *map;
+	struct mlx5_uars_page  *up;
+	bool			wc;
+	u32			index;
+	unsigned int		offset;
+};
+
 struct mlx5_uar {
 	u32			index;
 	struct list_head	bf_list;
@@ -645,6 +678,7 @@ struct mlx5_priv {
 	void		       *pfault_ctx;
 	struct srcu_struct      pfault_srcu;
 #endif
+	struct mlx5_bfreg_data		bfregs;
 };
 
 enum mlx5_device_state {
@@ -1022,6 +1056,9 @@ void mlx5_cleanup_rl_table(struct mlx5_core_dev *dev);
 int mlx5_rl_add_rate(struct mlx5_core_dev *dev, u32 rate, u16 *index);
 void mlx5_rl_remove_rate(struct mlx5_core_dev *dev, u32 rate);
 bool mlx5_rl_is_in_range(struct mlx5_core_dev *dev, u32 rate);
+int mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,
+		     bool map_wc, bool fast_path);
+void mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg);
 
 static inline int fw_initializing(struct mlx5_core_dev *dev)
 {

commit 2f5ff26478adaff5ed9b7ad4079d6a710b5f27e7
Author: Eli Cohen <eli@mellanox.com>
Date:   Tue Jan 3 23:55:21 2017 +0200

    mlx5: Fix naming convention with respect to UARs
    
    This establishes a solid naming conventions for UARs. A UAR (User Access
    Region) can have size identical to a system page or can be fixed 4KB
    depending on a value queried by firmware. Each UAR always has 4 blue
    flame register which are used to post doorbell to send queue. In
    addition, a UAR has section used for posting doorbells to CQs or EQs. In
    this patch we change names to reflect this conventions.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index cfa49bca009c..3d07e25b3bf1 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -188,16 +188,16 @@ enum mlx5_eq_type {
 #endif
 };
 
-struct mlx5_uuar_info {
+struct mlx5_bfreg_info {
 	struct mlx5_uar	       *uars;
 	int			num_uars;
-	int			num_low_latency_uuars;
+	int			num_low_latency_bfregs;
 	unsigned long	       *bitmap;
 	unsigned int	       *count;
 	struct mlx5_bf	       *bfs;
 
 	/*
-	 * protect uuar allocation data structs
+	 * protect bfreg allocation data structs
 	 */
 	struct mutex		lock;
 	u32			ver;
@@ -217,7 +217,7 @@ struct mlx5_bf {
 	/* serialize 64 bit writes when done as two 32 bit accesses
 	 */
 	spinlock_t		lock32;
-	int			uuarn;
+	int			bfregn;
 };
 
 struct mlx5_cmd_first {
@@ -579,7 +579,7 @@ struct mlx5_priv {
 	struct mlx5_eq_table	eq_table;
 	struct msix_entry	*msix_arr;
 	struct mlx5_irq_info	*irq_info;
-	struct mlx5_uuar_info	uuari;
+	struct mlx5_bfreg_info	bfregi;
 	MLX5_DECLARE_DOORBELL_LOCK(cq_uar_lock);
 
 	/* pages stuff */
@@ -903,8 +903,8 @@ void mlx5_cmd_mbox_status(void *out, u8 *status, u32 *syndrome);
 int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);
 int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
 int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
-int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
-int mlx5_free_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
+int mlx5_alloc_bfregs(struct mlx5_core_dev *dev, struct mlx5_bfreg_info *bfregi);
+int mlx5_free_bfregs(struct mlx5_core_dev *dev, struct mlx5_bfreg_info *bfregi);
 int mlx5_alloc_map_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar,
 		       bool map_wc);
 void mlx5_unmap_free_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);

commit 76eb75be79b52a3c6ae1fd840083fa1a04458c1c
Merge: 57ea884b0dcf e02003b515e8
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Jan 5 11:03:07 2017 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net

commit aa8e08d2f523501c40b0e70f1c4ecacb97195931
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Mon Jan 2 11:37:48 2017 +0200

    IB/mlx5: Improve MR check
    
    Add "type" field to mlx5_core MKEY struct.
    Check whether page fault happens on MKEY corresponding to MR.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b52d07491fe7..cfa49bca009c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -394,11 +394,17 @@ struct mlx5_core_sig_ctx {
 	u32			sigerr_count;
 };
 
+enum {
+	MLX5_MKEY_MR = 1,
+	MLX5_MKEY_MW,
+};
+
 struct mlx5_core_mkey {
 	u64			iova;
 	u64			size;
 	u32			key;
 	u32			pd;
+	u32			type;
 };
 
 #define MLX5_24BIT_MASK		((1 << 24) - 1)

commit d9aaed838765e28234cb700c7d1ac975cadf28c9
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Mon Jan 2 11:37:46 2017 +0200

    {net,IB}/mlx5: Refactor page fault handling
    
    * Update page fault event according to last specification.
    * Separate code path for page fault EQ, completion EQ and async EQ.
    * Move page fault handling work queue from mlx5_ib static variable
      into mlx5_core page fault EQ.
    * Allocate memory to store ODP event dynamically as the
      events arrive, since in atomic context - use mempool.
    * Make mlx5_ib page fault handler run in process context.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ec52f3b50bf5..b52d07491fe7 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -42,6 +42,7 @@
 #include <linux/vmalloc.h>
 #include <linux/radix-tree.h>
 #include <linux/workqueue.h>
+#include <linux/mempool.h>
 #include <linux/interrupt.h>
 
 #include <linux/mlx5/device.h>
@@ -83,6 +84,7 @@ enum {
 	MLX5_EQ_VEC_PAGES	 = 0,
 	MLX5_EQ_VEC_CMD		 = 1,
 	MLX5_EQ_VEC_ASYNC	 = 2,
+	MLX5_EQ_VEC_PFAULT	 = 3,
 	MLX5_EQ_VEC_COMP_BASE,
 };
 
@@ -178,6 +180,14 @@ enum mlx5_port_status {
 	MLX5_PORT_DOWN      = 2,
 };
 
+enum mlx5_eq_type {
+	MLX5_EQ_TYPE_COMP,
+	MLX5_EQ_TYPE_ASYNC,
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+	MLX5_EQ_TYPE_PF,
+#endif
+};
+
 struct mlx5_uuar_info {
 	struct mlx5_uar	       *uars;
 	int			num_uars;
@@ -333,6 +343,14 @@ struct mlx5_eq_tasklet {
 	spinlock_t lock;
 };
 
+struct mlx5_eq_pagefault {
+	struct work_struct       work;
+	/* Pagefaults lock */
+	spinlock_t		 lock;
+	struct workqueue_struct *wq;
+	mempool_t		*pool;
+};
+
 struct mlx5_eq {
 	struct mlx5_core_dev   *dev;
 	__be32 __iomem	       *doorbell;
@@ -346,7 +364,13 @@ struct mlx5_eq {
 	struct list_head	list;
 	int			index;
 	struct mlx5_rsc_debug	*dbg;
-	struct mlx5_eq_tasklet	tasklet_ctx;
+	enum mlx5_eq_type	type;
+	union {
+		struct mlx5_eq_tasklet   tasklet_ctx;
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+		struct mlx5_eq_pagefault pf_ctx;
+#endif
+	};
 };
 
 struct mlx5_core_psv {
@@ -377,6 +401,8 @@ struct mlx5_core_mkey {
 	u32			pd;
 };
 
+#define MLX5_24BIT_MASK		((1 << 24) - 1)
+
 enum mlx5_res_type {
 	MLX5_RES_QP	= MLX5_EVENT_QUEUE_TYPE_QP,
 	MLX5_RES_RQ	= MLX5_EVENT_QUEUE_TYPE_RQ,
@@ -411,6 +437,9 @@ struct mlx5_eq_table {
 	struct mlx5_eq		pages_eq;
 	struct mlx5_eq		async_eq;
 	struct mlx5_eq		cmd_eq;
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+	struct mlx5_eq		pfault_eq;
+#endif
 	int			num_comp_vectors;
 	/* protect EQs list
 	 */
@@ -497,6 +526,7 @@ struct mlx5_fc_stats {
 
 struct mlx5_eswitch;
 struct mlx5_lag;
+struct mlx5_pagefault;
 
 struct mlx5_rl_entry {
 	u32                     rate;
@@ -601,6 +631,14 @@ struct mlx5_priv {
 	struct mlx5_rl_table            rl_table;
 
 	struct mlx5_port_module_event_stats  pme_stats;
+
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+	void		      (*pfault)(struct mlx5_core_dev *dev,
+					void *context,
+					struct mlx5_pagefault *pfault);
+	void		       *pfault_ctx;
+	struct srcu_struct      pfault_srcu;
+#endif
 };
 
 enum mlx5_device_state {
@@ -619,6 +657,50 @@ enum mlx5_pci_status {
 	MLX5_PCI_STATUS_ENABLED,
 };
 
+enum mlx5_pagefault_type_flags {
+	MLX5_PFAULT_REQUESTOR = 1 << 0,
+	MLX5_PFAULT_WRITE     = 1 << 1,
+	MLX5_PFAULT_RDMA      = 1 << 2,
+};
+
+/* Contains the details of a pagefault. */
+struct mlx5_pagefault {
+	u32			bytes_committed;
+	u32			token;
+	u8			event_subtype;
+	u8			type;
+	union {
+		/* Initiator or send message responder pagefault details. */
+		struct {
+			/* Received packet size, only valid for responders. */
+			u32	packet_size;
+			/*
+			 * Number of resource holding WQE, depends on type.
+			 */
+			u32	wq_num;
+			/*
+			 * WQE index. Refers to either the send queue or
+			 * receive queue, according to event_subtype.
+			 */
+			u16	wqe_index;
+		} wqe;
+		/* RDMA responder pagefault details */
+		struct {
+			u32	r_key;
+			/*
+			 * Received packet size, minimal size page fault
+			 * resolution required for forward progress.
+			 */
+			u32	packet_size;
+			u32	rdma_op_len;
+			u64	rdma_va;
+		} rdma;
+	};
+
+	struct mlx5_eq	       *eq;
+	struct work_struct	work;
+};
+
 struct mlx5_td {
 	struct list_head tirs_list;
 	u32              tdn;
@@ -879,15 +961,13 @@ void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
 void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
 void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
-#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
-void mlx5_eq_pagefault(struct mlx5_core_dev *dev, struct mlx5_eqe *eqe);
-#endif
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
 void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec);
 void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
 int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
-		       int nent, u64 mask, const char *name, struct mlx5_uar *uar);
+		       int nent, u64 mask, const char *name,
+		       struct mlx5_uar *uar, enum mlx5_eq_type type);
 int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_start_eqs(struct mlx5_core_dev *dev);
 int mlx5_stop_eqs(struct mlx5_core_dev *dev);
@@ -926,6 +1006,10 @@ int mlx5_query_odp_caps(struct mlx5_core_dev *dev,
 			struct mlx5_odp_caps *odp_caps);
 int mlx5_core_query_ib_ppcnt(struct mlx5_core_dev *dev,
 			     u8 port_num, void *out, size_t sz);
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+int mlx5_core_page_fault_resume(struct mlx5_core_dev *dev, u32 token,
+				u32 wq_num, u8 type, int error);
+#endif
 
 int mlx5_init_rl_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_rl_table(struct mlx5_core_dev *dev);
@@ -974,6 +1058,9 @@ struct mlx5_interface {
 	void			(*detach)(struct mlx5_core_dev *dev, void *context);
 	void			(*event)(struct mlx5_core_dev *dev, void *context,
 					 enum mlx5_dev_event event, unsigned long param);
+	void			(*pfault)(struct mlx5_core_dev *dev,
+					  void *context,
+					  struct mlx5_pagefault *pfault);
 	void *                  (*get_dev)(void *context);
 	int			protocol;
 	struct list_head	list;

commit 7d0cc6edcc7011133c45f62a7796a98b8cb5da0f
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Mon Jan 2 11:37:44 2017 +0200

    IB/mlx5: Add MR cache for large UMR regions
    
    In this change we turn mlx5_ib_update_mtt() into generic
    mlx5_ib_update_xlt() to perfrom HCA translation table modifiactions
    supporting both atomic and process contexts and not limited by number
    of modified entries.
    Using this function we increase preallocated MRs up to 16GB.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0ae55361e674..ec52f3b50bf5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -959,7 +959,7 @@ enum {
 };
 
 enum {
-	MAX_MR_CACHE_ENTRIES    = 16,
+	MAX_MR_CACHE_ENTRIES    = 21,
 };
 
 enum {

commit 1efbd205b3cc5882a8c386c58a57134044e9d5ba
Author: Gal Pressman <galp@mellanox.com>
Date:   Wed Dec 28 14:58:39 2016 +0200

    Revert "net/mlx5: Add MPCNT register infrastructure"
    
    This reverts commit 7f503169cabd70c1f13b9279c50eca7dfb9a7d51.
    
    Fixes: 7f503169cabd ("net/mlx5: Add MPCNT register infrastructure")
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Reported-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0ae55361e674..735b36335f29 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -123,7 +123,6 @@ enum {
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 	MLX5_REG_MCIA		 = 0x9014,
 	MLX5_REG_MLCR		 = 0x902b,
-	MLX5_REG_MPCNT		 = 0x9051,
 };
 
 enum mlx5_dcbx_oper_mode {

commit 1c1b522808a18402f043c1418b4e48c7355480cc
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Nov 30 17:59:37 2016 +0200

    net/mlx5e: Implement Fragmented Work Queue (WQ)
    
    Add new type of struct mlx5_frag_buf which is used to allocate fragmented
    buffers rather than contiguous, and make the Completion Queues (CQs) use
    it as they are big (default of 2MB per CQ in Striding RQ).
    
    This fixes the failures of type:
    "mlx5e_open_locked: mlx5e_open_channels failed, -12"
    due to dma_zalloc_coherent insufficient contiguous coherent memory to
    satisfy the driver's request when the user tries to setup more or larger
    rings.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reported-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 68b85efc3908..0ae55361e674 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -318,6 +318,13 @@ struct mlx5_buf {
 	u8			page_shift;
 };
 
+struct mlx5_frag_buf {
+	struct mlx5_buf_list	*frags;
+	int			npages;
+	int			size;
+	u8			page_shift;
+};
+
 struct mlx5_eq_tasklet {
 	struct list_head list;
 	struct list_head process_list;
@@ -822,6 +829,9 @@ int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
 			struct mlx5_buf *buf, int node);
 int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, struct mlx5_buf *buf);
 void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_buf *buf);
+int mlx5_frag_buf_alloc_node(struct mlx5_core_dev *dev, int size,
+			     struct mlx5_frag_buf *buf, int node);
+void mlx5_frag_buf_free(struct mlx5_core_dev *dev, struct mlx5_frag_buf *buf);
 struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 						      gfp_t flags, int npages);
 void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
@@ -866,6 +876,7 @@ void mlx5_unregister_debugfs(void);
 int mlx5_eq_init(struct mlx5_core_dev *dev);
 void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
 void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
+void mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);
 void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING

commit 341c5ee2fb78420ffc441df36f93226be8069b0a
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Sun Nov 27 17:02:06 2016 +0200

    net/mlx5: Add DCBX firmware commands support
    
    Add set/query commands for DCBX_PARAM register
    
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ae1f451e8f89..68b85efc3908 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -104,6 +104,8 @@ enum {
 enum {
 	MLX5_REG_QETCR		 = 0x4005,
 	MLX5_REG_QTCT		 = 0x400a,
+	MLX5_REG_DCBX_PARAM      = 0x4020,
+	MLX5_REG_DCBX_APP        = 0x4021,
 	MLX5_REG_PCAP		 = 0x5001,
 	MLX5_REG_PMTU		 = 0x5003,
 	MLX5_REG_PTYS		 = 0x5004,
@@ -124,6 +126,11 @@ enum {
 	MLX5_REG_MPCNT		 = 0x9051,
 };
 
+enum mlx5_dcbx_oper_mode {
+	MLX5E_DCBX_PARAM_VER_OPER_HOST  = 0x0,
+	MLX5E_DCBX_PARAM_VER_OPER_AUTO  = 0x3,
+};
+
 enum {
 	MLX5_ATOMIC_OPS_CMP_SWAP	= 1 << 0,
 	MLX5_ATOMIC_OPS_FETCH_ADD	= 1 << 1,

commit 7f503169cabd70c1f13b9279c50eca7dfb9a7d51
Author: Gal Pressman <galp@mellanox.com>
Date:   Thu Nov 17 13:46:01 2016 +0200

    net/mlx5: Add MPCNT register infrastructure
    
    Add the needed infrastructure for future use of MPCNT register.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7336c8e529d7..ae1f451e8f89 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -121,6 +121,7 @@ enum {
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 	MLX5_REG_MCIA		 = 0x9014,
 	MLX5_REG_MLCR		 = 0x902b,
+	MLX5_REG_MPCNT		 = 0x9051,
 };
 
 enum {

commit d4eb4cd78b0774c7061db56844ed2ea7790cc77c
Author: Huy Nguyen <huyn@mellanox.com>
Date:   Thu Nov 17 13:45:57 2016 +0200

    net/mlx5: Add handling for port module event
    
    For each asynchronous port module event:
      1. print with ratelimit to the dmesg log
      2. increment the corresponding event counter
    
    Signed-off-by: Huy Nguyen <huyn@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5e7dbbcf47f0..7336c8e529d7 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -498,6 +498,31 @@ struct mlx5_rl_table {
 	struct mlx5_rl_entry   *rl_entry;
 };
 
+enum port_module_event_status_type {
+	MLX5_MODULE_STATUS_PLUGGED   = 0x1,
+	MLX5_MODULE_STATUS_UNPLUGGED = 0x2,
+	MLX5_MODULE_STATUS_ERROR     = 0x3,
+	MLX5_MODULE_STATUS_NUM       = 0x3,
+};
+
+enum  port_module_event_error_type {
+	MLX5_MODULE_EVENT_ERROR_POWER_BUDGET_EXCEEDED,
+	MLX5_MODULE_EVENT_ERROR_LONG_RANGE_FOR_NON_MLNX_CABLE_MODULE,
+	MLX5_MODULE_EVENT_ERROR_BUS_STUCK,
+	MLX5_MODULE_EVENT_ERROR_NO_EEPROM_RETRY_TIMEOUT,
+	MLX5_MODULE_EVENT_ERROR_ENFORCE_PART_NUMBER_LIST,
+	MLX5_MODULE_EVENT_ERROR_UNKNOWN_IDENTIFIER,
+	MLX5_MODULE_EVENT_ERROR_HIGH_TEMPERATURE,
+	MLX5_MODULE_EVENT_ERROR_BAD_CABLE,
+	MLX5_MODULE_EVENT_ERROR_UNKNOWN,
+	MLX5_MODULE_EVENT_ERROR_NUM,
+};
+
+struct mlx5_port_module_event_stats {
+	u64 status_counters[MLX5_MODULE_STATUS_NUM];
+	u64 error_counters[MLX5_MODULE_EVENT_ERROR_NUM];
+};
+
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	eq_table;
@@ -559,6 +584,8 @@ struct mlx5_priv {
 	unsigned long		pci_dev_data;
 	struct mlx5_fc_stats		fc_stats;
 	struct mlx5_rl_table            rl_table;
+
+	struct mlx5_port_module_event_stats  pme_stats;
 };
 
 enum mlx5_device_state {

commit 0ac3ea70897fb9f84b620aeda074ecccf481629d
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Thu Nov 17 13:45:55 2016 +0200

    net/mlx5: Make the command interface cache more flexible
    
    Add more cache command size sets and more entries for each set based on
    the current commands set different sizes and commands frequency.
    
    Fixes: e126ba97dba9 ('mlx5: Add driver for Mellanox Connect-IB adapters')
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ecc451d89ccd..5e7dbbcf47f0 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -208,7 +208,7 @@ struct mlx5_cmd_first {
 
 struct mlx5_cmd_msg {
 	struct list_head		list;
-	struct cache_ent	       *cache;
+	struct cmd_msg_cache	       *parent;
 	u32				len;
 	struct mlx5_cmd_first		first;
 	struct mlx5_cmd_mailbox	       *next;
@@ -228,17 +228,17 @@ struct mlx5_cmd_debug {
 	u16			outlen;
 };
 
-struct cache_ent {
+struct cmd_msg_cache {
 	/* protect block chain allocations
 	 */
 	spinlock_t		lock;
 	struct list_head	head;
+	unsigned int		max_inbox_size;
+	unsigned int		num_ent;
 };
 
-struct cmd_msg_cache {
-	struct cache_ent	large;
-	struct cache_ent	med;
-
+enum {
+	MLX5_NUM_COMMAND_CACHES = 5,
 };
 
 struct mlx5_cmd_stats {
@@ -281,7 +281,7 @@ struct mlx5_cmd {
 	struct mlx5_cmd_work_ent *ent_arr[MLX5_MAX_COMMANDS];
 	struct pci_pool *pool;
 	struct mlx5_cmd_debug dbg;
-	struct cmd_msg_cache cache;
+	struct cmd_msg_cache cache[MLX5_NUM_COMMAND_CACHES];
 	int checksum_disabled;
 	struct mlx5_cmd_stats stats[MLX5_CMD_OP_MAX];
 };

commit 04c0c1ab38e95105d950db5b84e727637e149ce7
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Tue Oct 25 18:36:34 2016 +0300

    net/mlx5: PCI error recovery health care simulation
    
    In case that the kernel PCI error handlers are not called, we will
    trigger our own recovery flow.
    
    The health work will give priority to the kernel pci error handlers to
    recover the PCI by waiting for a small period, if the pci error handlers
    are not triggered the manual recovery flow will be executed.
    
    We don't save pci state in case of manual recovery because it will ruin the
    pci configuration space and we will lose dma sync.
    
    Fixes: 89d44f0a6c73 ('net/mlx5_core: Add pci error handlers to mlx5_core driver')
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7d9a5d08eb59..ecc451d89ccd 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -423,6 +423,7 @@ struct mlx5_core_health {
 	struct workqueue_struct	       *wq;
 	unsigned long			flags;
 	struct work_struct		work;
+	struct delayed_work		recover_work;
 };
 
 struct mlx5_cq_table {

commit 05ac2c0b7438ea08c5d54b48797acf9b22cb2f6f
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Tue Oct 25 18:36:33 2016 +0300

    net/mlx5: Fix race between PCI error handlers and health work
    
    Currently there is a race between the health care work and the kernel
    pci error handlers because both of them detect the error, the first one
    to be called will do the error handling.
    There is a chance that health care will disable the pci after resuming
    pci slot.
    Also create a separate WQ because now we will have two types of health
    works, one for the error detection and one for the recovery.
    
    Fixes: 89d44f0a6c73 ('net/mlx5_core: Add pci error handlers to mlx5_core driver')
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5dbda60a09f4..7d9a5d08eb59 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -418,7 +418,10 @@ struct mlx5_core_health {
 	u32				prev;
 	int				miss_counter;
 	bool				sick;
+	/* wq spinlock to synchronize draining */
+	spinlock_t			wq_lock;
 	struct workqueue_struct	       *wq;
+	unsigned long			flags;
 	struct work_struct		work;
 };
 
@@ -778,6 +781,7 @@ void mlx5_health_cleanup(struct mlx5_core_dev *dev);
 int mlx5_health_init(struct mlx5_core_dev *dev);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
+void mlx5_drain_health_wq(struct mlx5_core_dev *dev);
 int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
 			struct mlx5_buf *buf, int node);
 int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, struct mlx5_buf *buf);

commit b47bd6ea40636362a8b6605de51207cc387ba0b8
Author: Daniel Jurgens <danielj@mellanox.com>
Date:   Tue Oct 25 18:36:24 2016 +0300

    {net, ib}/mlx5: Make cache line size determination at runtime.
    
    ARM 64B cache line systems have L1_CACHE_BYTES set to 128.
    cache_line_size() will return the correct size.
    
    Fixes: cf50b5efa2fe('net/mlx5_core/ib: New device capabilities
    handling.')
    Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 85c4786427e4..5dbda60a09f4 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -625,10 +625,6 @@ struct mlx5_db {
 	int			index;
 };
 
-enum {
-	MLX5_DB_PER_PAGE = PAGE_SIZE / L1_CACHE_BYTES,
-};
-
 enum {
 	MLX5_COMP_EQ_SIZE = 1024,
 };
@@ -638,13 +634,6 @@ enum {
 	MLX5_PTYS_EN = 1 << 2,
 };
 
-struct mlx5_db_pgdir {
-	struct list_head	list;
-	DECLARE_BITMAP(bitmap, MLX5_DB_PER_PAGE);
-	__be32		       *db_page;
-	dma_addr_t		db_dma;
-};
-
 typedef void (*mlx5_cmd_cbk_t)(int status, void *context);
 
 struct mlx5_cmd_work_ent {

commit 737a234bb6384800a5b632be85c6b0ad6221d137
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Fri Sep 9 17:35:19 2016 +0300

    net/mlx5: Introduce attach/detach to interface API
    
    Add attach/detach callbacks to interface API.
    This is crucial for implementing seamless reset flow which releases the
    hardware and it's resources upon detach while keeping software
    structures and state (e.g netdev) then reset and reallocate the hardware
    needed resources upon attach.
    
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0d7aedfce1d7..85c4786427e4 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -930,6 +930,8 @@ enum {
 struct mlx5_interface {
 	void *			(*add)(struct mlx5_core_dev *dev);
 	void			(*remove)(struct mlx5_core_dev *dev, void *context);
+	int			(*attach)(struct mlx5_core_dev *dev, void *context);
+	void			(*detach)(struct mlx5_core_dev *dev, void *context);
 	void			(*event)(struct mlx5_core_dev *dev, void *context,
 					 enum mlx5_dev_event event, unsigned long param);
 	void *                  (*get_dev)(void *context);

commit 6b6adee3dad25bbe568ee24fc843372d02fb425f
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Fri Sep 9 17:35:18 2016 +0300

    net/mlx5: SRIOV core code refactoring
    
    Simplify the code and makes it look modular and symmetric.
    Split sriov enable/disable to two levels: device level and pci level.
    When user enable/disable sriov (via sriov_configure driver callback) we
    will enable/disable both device and pci sriov.
    When driver load/unload we will enable/disable (on demand) only device
    sriov while keeping the PCI sriov enabled for next driver load.
    On internal/pci error, VFs will be kept enabled on PCI and the reset
    is done only in device level.
    
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5cb9fa7aec61..0d7aedfce1d7 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -828,8 +828,6 @@ void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
 int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
-int mlx5_sriov_init(struct mlx5_core_dev *dev);
-int mlx5_sriov_cleanup(struct mlx5_core_dev *dev);
 void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
 				 s32 npages);
 int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);

commit 3bc34f3bcb087764796d9a6eaa476e270114eb8f
Author: Aviv Heller <avivh@mellanox.com>
Date:   Mon May 9 10:38:42 2016 +0000

    net/mlx5: Vport LAG creation support
    
    Add interfaces for issuing CREATE_VPORT_LAG and
    DESTROY_VPORT_LAG commands.
    
    Used for receiving PF1's eth traffic on PF0's
    root ft.
    
    Signed-off-by: Aviv Heller <avivh@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c568dd927330..5cb9fa7aec61 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -944,6 +944,8 @@ int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
 int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 
+int mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);
+int mlx5_cmd_destroy_vport_lag(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
 struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
 

commit 6a32047a441b870dd2570fe0831dada5e9ce40f6
Author: Aviv Heller <avivh@mellanox.com>
Date:   Mon May 9 11:06:44 2016 +0000

    net/mlx5: Get RoCE netdev
    
    Used by IB driver for determining the IB bond
    device's netdev, when LAG is active.
    
    Returns PF0's netdev if mode is not active-backup,
    or the PF netdev of the active slave when mode is
    active-backup.
    
    Signed-off-by: Aviv Heller <avivh@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ed983b8c3213..c568dd927330 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -945,6 +945,7 @@ void mlx5_unregister_interface(struct mlx5_interface *intf);
 int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
+struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
 
 struct mlx5_profile {
 	u64	mask;

commit 7907f23adc186700efbe56c032527e47485c86ab
Author: Aviv Heller <avivh@mellanox.com>
Date:   Sun Apr 17 16:57:32 2016 +0300

    net/mlx5: Implement RoCE LAG feature
    
    Available on dual port cards only, this feature keeps
    track, using netdev LAG events, of the bonding
    and link status of each port's PF netdev.
    
    When both of the card's PF netdevs are enslaved to the
    same bond/team master, and only them, LAG state
    is active.
    
    During LAG, only one IB device is present for both ports.
    
    In addition to the above, this commit includes FW commands
    used for managing the LAG, new facilities for adding and removing
    a single device by interface, and port remap functionality according to
    bond events.
    
    Please note that this feature is currently used only for mimicking
    Ethernet bonding for RoCE - netdevs functionality is not altered,
    and their bonding continues to be managed solely by bond/team driver.
    
    Signed-off-by: Aviv Heller <avivh@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 0ea78b5edbb2..ed983b8c3213 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -477,6 +477,7 @@ struct mlx5_fc_stats {
 };
 
 struct mlx5_eswitch;
+struct mlx5_lag;
 
 struct mlx5_rl_entry {
 	u32                     rate;
@@ -550,6 +551,7 @@ struct mlx5_priv {
 	struct mlx5_flow_steering *steering;
 	struct mlx5_eswitch     *eswitch;
 	struct mlx5_core_sriov	sriov;
+	struct mlx5_lag		*lag;
 	unsigned long		pci_dev_data;
 	struct mlx5_fc_stats		fc_stats;
 	struct mlx5_rl_table            rl_table;
@@ -942,6 +944,8 @@ int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
 int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 
+bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
+
 struct mlx5_profile {
 	u64	mask;
 	u8	log_max_qp;

commit 83b502a12e82d0ae97907d415496fbafe044f0ce
Author: Alex Vesker <valex@mellanox.com>
Date:   Thu Aug 4 17:32:02 2016 +0300

    net/mlx5: Modify RQ bitmask from mlx5 ifc
    
    Use mlx5 ifc MODIFY_BITMASK_VSD in mlx5e_modify_rq_vsd and expose counter
    set capability bit in hca caps structure.
    
    Signed-off-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ebe57abf3324..0ea78b5edbb2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -48,10 +48,6 @@
 #include <linux/mlx5/doorbell.h>
 #include <linux/mlx5/srq.h>
 
-enum {
-	MLX5_RQ_BITMASK_VSD = 1 << 1,
-};
-
 enum {
 	MLX5_BOARD_ID_LEN = 64,
 	MLX5_MAX_NAME_LEN = 16,

commit c4f287c4a6ac489c18afc4acc4353141a8c53070
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Jul 19 20:17:12 2016 +0300

    net/mlx5: Unify and improve command interface
    
    Now as all commands use mlx5 ifc interface, instead of doing two calls
    for executing a command we embed command status checking into
    mlx5_cmd_exec to simplify the interface.
    
    Also we do here some cleanup for redundant software structures
    (inbox/outbox) and functions and improved command failure output.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 173817187abb..ebe57abf3324 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -771,14 +771,15 @@ int mlx5_cmd_init(struct mlx5_core_dev *dev);
 void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
-int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
-int mlx5_cmd_status_to_err_v2(void *ptr);
-int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);
+
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 		  int out_size);
 int mlx5_cmd_exec_cb(struct mlx5_core_dev *dev, void *in, int in_size,
 		     void *out, int out_size, mlx5_cmd_cbk_t callback,
 		     void *context);
+void mlx5_cmd_mbox_status(void *out, u8 *status, u32 *syndrome);
+
+int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);
 int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
 int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
 int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);

commit ec22eb53106be1472ba6573dc900943f52f8fd1e
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Sat Jul 16 06:28:36 2016 +0300

    {net,IB}/mlx5: MKey/PSV commands via mlx5 ifc
    
    Remove old representation of manually created MKey/PSV commands layout,
    and use mlx5_ifc canonical structures and defines.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index eed4b612572d..173817187abb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -807,15 +807,18 @@ int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 		      u16 lwm, int is_srq);
 void mlx5_init_mkey_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_mkey_table(struct mlx5_core_dev *dev);
+int mlx5_core_create_mkey_cb(struct mlx5_core_dev *dev,
+			     struct mlx5_core_mkey *mkey,
+			     u32 *in, int inlen,
+			     u32 *out, int outlen,
+			     mlx5_cmd_cbk_t callback, void *context);
 int mlx5_core_create_mkey(struct mlx5_core_dev *dev,
 			  struct mlx5_core_mkey *mkey,
-			  struct mlx5_create_mkey_mbox_in *in, int inlen,
-			  mlx5_cmd_cbk_t callback, void *context,
-			  struct mlx5_create_mkey_mbox_out *out);
+			  u32 *in, int inlen);
 int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev,
 			   struct mlx5_core_mkey *mkey);
 int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mkey *mkey,
-			 struct mlx5_query_mkey_mbox_out *out, int outlen);
+			 u32 *out, int outlen);
 int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mkey *_mkey,
 			     u32 *mkey);
 int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);

commit 73b626c182dff06867ceba996a819e8372c9b2ce
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Sat Jul 16 03:26:15 2016 +0300

    net/mlx5: EQ commands via mlx5 ifc
    
    Remove old representation of manually created EQ commands layout,
    and use mlx5_ifc canonical structures and defines.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ccea6fb16482..eed4b612572d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -865,7 +865,7 @@ int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
-		       struct mlx5_query_eq_mbox_out *out, int outlen);
+		       u32 *out, int outlen);
 int mlx5_eq_debugfs_init(struct mlx5_core_dev *dev);
 void mlx5_eq_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_cq_debugfs_init(struct mlx5_core_dev *dev);

commit 0cda611386b2fcbf8bb32e9a5d82bfed4856fc36
Merge: fdf1f7ff1bd7 7f1d25b47d91
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 4 20:10:31 2016 -0400

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull base rdma updates from Doug Ledford:
     "Round one of 4.8 code: while this is mostly normal, there is a new
      driver in here (the driver was hosted outside the kernel for several
      years and is actually a fairly mature and well coded driver).  It
      amounts to 13,000 of the 16,000 lines of added code in here.
    
      Summary:
    
       - Updates/fixes for iw_cxgb4 driver
       - Updates/fixes for mlx5 driver
       - Add flow steering and RSS API
       - Add hardware stats to mlx4 and mlx5 drivers
       - Add firmware version API for RDMA driver use
       - Add the rxe driver (this is a software RoCE driver that makes any
         Ethernet device a RoCE device)
       - Fixes for i40iw driver
       - Support for send only multicast joins in the cma layer
       - Other minor fixes"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (72 commits)
      Soft RoCE driver
      IB/core: Support for CMA multicast join flags
      IB/sa: Add cached attribute containing SM information to SA port
      IB/uverbs: Fix race between uverbs_close and remove_one
      IB/mthca: Clean up error unwind flow in mthca_reset()
      IB/mthca: NULL arg to pci_dev_put is OK
      IB/hfi1: NULL arg to sc_return_credits is OK
      IB/mlx4: Add diagnostic hardware counters
      net/mlx4: Query performance and diagnostics counters
      net/mlx4: Add diagnostic counters capability bit
      Use smaller 512 byte messages for portmapper messages
      IB/ipoib: Report SG feature regardless of HW UD CSUM capability
      IB/mlx4: Don't use GFP_ATOMIC for CQ resize struct
      IB/hfi1: Disable by default
      IB/rdmavt: Disable by default
      IB/mlx5: Fix port counter ID association to QP offset
      IB/mlx5: Fix iteration overrun in GSI qps
      i40iw: Add NULL check for puda buffer
      i40iw: Change dup_ack_thresh to u8
      i40iw: Remove unnecessary check for moving CQ head
      ...

commit 29cc6679076a00a6ce193004dcf2d14ae7c428a5
Author: Amir Vadai <amir@vadai.me>
Date:   Thu Jul 14 10:32:37 2016 +0300

    net/mlx5: Store counters in rbtree instead of list
    
    In order to use bulk counters, we need to have counters sorted by id.
    
    Signed-off-by: Amir Vadai <amir@vadai.me>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 81e8396574f4..a041b99fceac 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -469,7 +469,7 @@ struct mlx5_irq_info {
 };
 
 struct mlx5_fc_stats {
-	struct list_head list;
+	struct rb_root counters;
 	struct list_head addlist;
 	/* protect addlist add/splice operations */
 	spinlock_t addlist_lock;

commit 30d0844bdcea9fb8b0b3c8abfa5547bc3bcf8baa
Merge: ae3e4562e2ce bc86765181aa
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Jul 6 10:35:22 2016 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/ethernet/mellanox/mlx5/core/en.h
            drivers/net/ethernet/mellanox/mlx5/core/en_main.c
            drivers/net/usb/r8152.c
    
    All three conflicts were overlapping changes.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit fba53f7b571925b8a0d59d460ad6de1fda928a3e
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Mon Jul 4 17:23:06 2016 +0300

    net/mlx5: Introduce mlx5_flow_steering structure
    
    Instead of having all steering private name spaces and
    steering module fields flat in mlx5_core_priv, we wrap
    them in mlx5_flow_steering for better modularity and
    API exposure.
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index e22b3456b2ee..f21c45941887 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -550,14 +550,10 @@ struct mlx5_priv {
 	struct list_head        ctx_list;
 	spinlock_t              ctx_lock;
 
+	struct mlx5_flow_steering *steering;
 	struct mlx5_eswitch     *eswitch;
 	struct mlx5_core_sriov	sriov;
 	unsigned long		pci_dev_data;
-	struct mlx5_flow_root_namespace *root_ns;
-	struct mlx5_flow_root_namespace *fdb_root_ns;
-	struct mlx5_flow_root_namespace *esw_egress_root_ns;
-	struct mlx5_flow_root_namespace *esw_ingress_root_ns;
-
 	struct mlx5_fc_stats		fc_stats;
 	struct mlx5_rl_table            rl_table;
 };

commit b50d292b4399f4eb11e82d0430aacf62dd5d5365
Author: Hadar Hen Zion <hadarh@mellanox.com>
Date:   Fri Jul 1 14:51:04 2016 +0300

    net/mlx5e: Create NIC global resources only once
    
    To allow creating more than one netdev over the same PCI function, we
    change the driver such that global NIC resources are created once and
    later be shared amongst all the mlx5e netdevs running over that port.
    
    Move the CQ UAR, PD (pdn), Transport Domain (tdn), MKey resources from
    being kept in the mlx5e priv part to a new resources structure
    (mlx5e_resources) placed under the mlx5_core device.
    
    This patch doesn't add any new functionality.
    
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 46260fdc5305..e22b3456b2ee 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -578,6 +578,18 @@ enum mlx5_pci_status {
 	MLX5_PCI_STATUS_ENABLED,
 };
 
+struct mlx5_td {
+	struct list_head tirs_list;
+	u32              tdn;
+};
+
+struct mlx5e_resources {
+	struct mlx5_uar            cq_uar;
+	u32                        pdn;
+	struct mlx5_td             td;
+	struct mlx5_core_mkey      mkey;
+};
+
 struct mlx5_core_dev {
 	struct pci_dev	       *pdev;
 	/* sync pci state */
@@ -602,6 +614,7 @@ struct mlx5_core_dev {
 	struct mlx5_profile	*profile;
 	atomic_t		num_qps;
 	u32			issi;
+	struct mlx5e_resources  mlx5e_res;
 #ifdef CONFIG_RFS_ACCEL
 	struct cpu_rmap         *rmap;
 #endif

commit 65ee67084589c1783a74b4a4a5db38d7264ec8b5
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Thu Jun 30 17:34:43 2016 +0300

    net/mlx5: Add timeout handle to commands with callback
    
    The current implementation does not handle timeout in case of command
    with callback request, and this can lead to deadlock if the command
    doesn't get fw response.
    Add delayed callback timeout work before posting the command to fw.
    In case of real fw command completion we will cancel the delayed work.
    In case of fw command timeout the callback timeout handler will be
    called and it will simulate fw completion with timeout error.
    
    Fixes: e126ba97dba9 ('mlx5: Add driver for Mellanox Connect-IB adapters')
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 80776d0c52dc..fd72ecf0ce9f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -629,6 +629,7 @@ struct mlx5_cmd_work_ent {
 	void		       *uout;
 	int			uout_size;
 	mlx5_cmd_cbk_t		callback;
+	struct delayed_work	cb_timeout_work;
 	void		       *context;
 	int			idx;
 	struct completion	done;

commit 1466cc5b23d18e7b6b8f1a45443d595393dbcae7
Author: Yevgeny Petrilin <yevgenyp@mellanox.com>
Date:   Thu Jun 23 17:02:37 2016 +0300

    net/mlx5: Rate limit tables support
    
    Configuring and managing HW rate limit tables.
    The HW holds a table of rate limits, each rate is
    associated with an index in that table.
    Later a Send Queue uses this index to set the rate limit.
    Multiple Send Queues can have the same rate limit, which is
    represented by a single entry in this table.
    Even though a rate can be shared, each queue is being rate
    limited independently of others.
    
    The SW shadow of this table holds the rate itself,
    the index in the HW table and the refcount (number of queues)
    working with this rate.
    
    The exported functions are mlx5_rl_add_rate and mlx5_rl_remove_rate.
    Number of different rates and their values are derived
    from HW capabilities.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 80776d0c52dc..46260fdc5305 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -481,6 +481,21 @@ struct mlx5_fc_stats {
 
 struct mlx5_eswitch;
 
+struct mlx5_rl_entry {
+	u32                     rate;
+	u16                     index;
+	u16                     refcount;
+};
+
+struct mlx5_rl_table {
+	/* protect rate limit table */
+	struct mutex            rl_lock;
+	u16                     max_size;
+	u32                     max_rate;
+	u32                     min_rate;
+	struct mlx5_rl_entry   *rl_entry;
+};
+
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	eq_table;
@@ -544,6 +559,7 @@ struct mlx5_priv {
 	struct mlx5_flow_root_namespace *esw_ingress_root_ns;
 
 	struct mlx5_fc_stats		fc_stats;
+	struct mlx5_rl_table            rl_table;
 };
 
 enum mlx5_device_state {
@@ -861,6 +877,12 @@ int mlx5_query_odp_caps(struct mlx5_core_dev *dev,
 int mlx5_core_query_ib_ppcnt(struct mlx5_core_dev *dev,
 			     u8 port_num, void *out, size_t sz);
 
+int mlx5_init_rl_table(struct mlx5_core_dev *dev);
+void mlx5_cleanup_rl_table(struct mlx5_core_dev *dev);
+int mlx5_rl_add_rate(struct mlx5_core_dev *dev, u32 rate, u16 *index);
+void mlx5_rl_remove_rate(struct mlx5_core_dev *dev, u32 rate);
+bool mlx5_rl_is_in_range(struct mlx5_core_dev *dev, u32 rate);
+
 static inline int fw_initializing(struct mlx5_core_dev *dev)
 {
 	return ioread32be(&dev->iseg->initializing) >> 31;
@@ -938,6 +960,11 @@ static inline int mlx5_get_gid_table_len(u16 param)
 	return 8 * (1 << param);
 }
 
+static inline bool mlx5_rl_is_supported(struct mlx5_core_dev *dev)
+{
+	return !!(dev->priv.rl_table.max_size);
+}
+
 enum {
 	MLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,
 };

commit af1ba291c5e498973cc325c501dd8da80b234571
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Fri Jun 17 15:33:32 2016 +0300

    {net, IB}/mlx5: Refactor internal SRQ API
    
    Currently, the SRQ API uses the obsolete mlx5_*_srq_mbox_{in,out}
    structs which limit the ability to pass the SRQ attributes between
    net and IB parts of the driver.
    
    This patch changes the SRQ API so as to use auto-generated structs
    and provides a better way to pass attributes which will be in use by
    coming features.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 80776d0c52dc..ba933335772c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -46,6 +46,7 @@
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
+#include <linux/mlx5/srq.h>
 
 enum {
 	MLX5_RQ_BITMASK_VSD = 1 << 1,
@@ -772,11 +773,10 @@ struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 				 struct mlx5_cmd_mailbox *head);
 int mlx5_core_create_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
-			 struct mlx5_create_srq_mbox_in *in, int inlen,
-			 int is_xrc);
+			 struct mlx5_srq_attr *in);
 int mlx5_core_destroy_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq);
 int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
-			struct mlx5_query_srq_mbox_out *out);
+			struct mlx5_srq_attr *out);
 int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 		      u16 lwm, int is_srq);
 void mlx5_init_mkey_table(struct mlx5_core_dev *dev);

commit 76b584d3125a1f7d8b64e9c522a4555bc2844bde
Merge: 7992893c5a9f c16d2750a08c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 20 14:35:07 2016 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull rdma updates from Doug Ledford:
     "Primary 4.7 merge window changes
    
       - Updates to the new Intel X722 iWARP driver
       - Updates to the hfi1 driver
       - Fixes for the iw_cxgb4 driver
       - Misc core fixes
       - Generic RDMA READ/WRITE API addition
       - SRP updates
       - Misc ipoib updates
       - Minor mlx5 updates"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (148 commits)
      IB/mlx5: Fire the CQ completion handler from tasklet
      net/mlx5_core: Use tasklet for user-space CQ completion events
      IB/core: Do not require CAP_NET_ADMIN for packet sniffing
      IB/mlx4: Fix unaligned access in send_reply_to_slave
      IB/mlx5: Report Scatter FCS device capability when supported
      IB/mlx5: Add Scatter FCS support for Raw Packet QP
      IB/core: Add Scatter FCS create flag
      IB/core: Add Raw Scatter FCS device capability
      IB/core: Add extended device capability flags
      i40iw: pass hw_stats by reference rather than by value
      i40iw: Remove unnecessary synchronize_irq() before free_irq()
      i40iw: constify i40iw_vf_cqp_ops structure
      IB/mlx5: Add UARs write-combining and non-cached mapping
      IB/mlx5: Allow mapping the free running counter on PROT_EXEC
      IB/mlx4: Use list_for_each_entry_safe
      IB/SA: Use correct free function
      IB/core: Fix a potential array overrun in CMA and SA agent
      IB/core: Remove unnecessary check in ibnl_rcv_msg
      IB/IWPM: Fix a potential skb leak
      RDMA/nes: replace custom print_hex_dump()
      ...

commit 94c6825e0ff75829207af6246782811b7c7af2c0
Author: Matan Barak <matanb@mellanox.com>
Date:   Sun Apr 17 17:08:40 2016 +0300

    net/mlx5_core: Use tasklet for user-space CQ completion events
    
    Previously, we've fired all our completion callbacks straight from
    our ISR.
    
    Some of those callbacks were lightweight (for example, mlx5 Ethernet
    napi callbacks), but some of them did more work (for example,
    the user-space RDMA stack uverbs' completion handler). Besides that,
    doing more than the minimal work in ISR is generally considered wrong,
    it could even lead to a hard lockup of the system. Since when a lot
    of completion events are generated by the hardware, the loop over
    those events could be so long, that we'll get into a hard lockup by
    the system watchdog.
    
    In order to avoid that, add a new way of invoking completion events
    callbacks. In the interrupt itself, we add the CQs which receive
    completion event to a per-EQ list and schedule a tasklet. In the
    tasklet context we loop over all the CQs in the list and invoke the
    user callback.
    
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 369c837d40f5..5a41f9003941 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -41,6 +41,7 @@
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/radix-tree.h>
+#include <linux/interrupt.h>
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
@@ -304,6 +305,14 @@ struct mlx5_buf {
 	u8			page_shift;
 };
 
+struct mlx5_eq_tasklet {
+	struct list_head list;
+	struct list_head process_list;
+	struct tasklet_struct task;
+	/* lock on completion tasklet list */
+	spinlock_t lock;
+};
+
 struct mlx5_eq {
 	struct mlx5_core_dev   *dev;
 	__be32 __iomem	       *doorbell;
@@ -317,6 +326,7 @@ struct mlx5_eq {
 	struct list_head	list;
 	int			index;
 	struct mlx5_rsc_debug	*dbg;
+	struct mlx5_eq_tasklet	tasklet_ctx;
 };
 
 struct mlx5_core_psv {

commit 43a335e055bb7ebdc8a68ce7362ef26ef5bda92b
Author: Amir Vadai <amirva@mellanox.com>
Date:   Fri May 13 12:55:41 2016 +0000

    net/mlx5_core: Flow counters infrastructure
    
    If a counter has the aging flag set when created, it is added to a list
    of counters that will be queried periodically from a workqueue.  query
    result and last use timestamp are cached.
    add/del counter must be very efficient since thousands of such
    operations might be issued in a second.
    There is only a single reference to counters without aging, therefore
    no need for locks.
    But, counters with aging enabled are stored in a list. In order to make
    code as lockless as possible, all the list manipulation and access to
    hardware is done from a single context - the periodic counters query
    thread.
    
    The hardware supports multiple counters per FTE, however currently we
    are using one counter for each FTE.
    
    Signed-off-by: Amir Vadai <amirva@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9613143f0561..07b504f7eb84 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -41,6 +41,7 @@
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/radix-tree.h>
+#include <linux/workqueue.h>
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
@@ -457,6 +458,17 @@ struct mlx5_irq_info {
 	char name[MLX5_MAX_IRQ_NAME];
 };
 
+struct mlx5_fc_stats {
+	struct list_head list;
+	struct list_head addlist;
+	/* protect addlist add/splice operations */
+	spinlock_t addlist_lock;
+
+	struct workqueue_struct *wq;
+	struct delayed_work work;
+	unsigned long next_query;
+};
+
 struct mlx5_eswitch;
 
 struct mlx5_priv {
@@ -520,6 +532,8 @@ struct mlx5_priv {
 	struct mlx5_flow_root_namespace *fdb_root_ns;
 	struct mlx5_flow_root_namespace *esw_egress_root_ns;
 	struct mlx5_flow_root_namespace *esw_ingress_root_ns;
+
+	struct mlx5_fc_stats		fc_stats;
 };
 
 enum mlx5_device_state {

commit efdc810ba39dae0ccce9cb9c1c84ff9b0157ca43
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Tue May 3 17:13:54 2016 +0300

    net/mlx5: Flow steering, Add vport ACL support
    
    Update the relevant flow steering device structs and commands to
    support vport.
    Update the flow steering core API to receive vport number.
    Add ingress and egress ACL flow table name spaces.
    Add ACL flow table support:
    * ACL (Access Control List) flow table is a table that contains
    only allow/drop steering rules.
    
    * We have two types of ACL flow tables - ingress and egress.
    
    * ACLs handle traffic sent from/to E-Switch FDB table, Ingress refers to
    traffic sent from Vport to E-Switch and Egress refers to traffic sent
    from E-Switch to vport.
    
    * Ingress ACL flow table allow/drop rules is checked against traffic
    sent from VF.
    
    * Egress ACL flow table allow/drop rules is checked against traffic sent
    to VF.
    
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d5529449ef47..9613143f0561 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -518,6 +518,8 @@ struct mlx5_priv {
 	unsigned long		pci_dev_data;
 	struct mlx5_flow_root_namespace *root_ns;
 	struct mlx5_flow_root_namespace *fdb_root_ns;
+	struct mlx5_flow_root_namespace *esw_egress_root_ns;
+	struct mlx5_flow_root_namespace *esw_ingress_root_ns;
 };
 
 enum mlx5_device_state {

commit 5a7b27eb9cf3986f487469b57a3a41286d2e7100
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Fri Apr 29 01:36:39 2016 +0300

    net/mlx5: Initializing CPU reverse mapping
    
    Allocating CPU rmap and add entry for each IRQ.
    CPU rmap is used in aRFS to get the RX queue number
    of the RX completion interrupts.
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 96a428dcac9f..d5529449ef47 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -560,6 +560,9 @@ struct mlx5_core_dev {
 	struct mlx5_profile	*profile;
 	atomic_t		num_qps;
 	u32			issi;
+#ifdef CONFIG_RFS_ACCEL
+	struct cpu_rmap         *rmap;
+#endif
 };
 
 struct mlx5_db {

commit c0cc53162a0644dd57dce5e2fbb9bbafdc57d183
Merge: 8c14586fc320 f28f20da704d
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Apr 27 15:43:10 2016 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Minor overlapping changes in the conflicts.
    
    In the macsec case, the change of the default ID macro
    name overlapped with the 64-bit netlink attribute alignment
    fixes in net-next.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 363501145e3faa650193722fe7047b767ed87172
Author: Gal Pressman <galp@mellanox.com>
Date:   Sun Apr 24 22:51:55 2016 +0300

    net/mlx5e: Add ethtool support for rxvlan-offload (vlan stripping)
    
    Use ethtool -K <interface> rxvlan <on/off> to enable/disable
    C-TAG vlan stripping by hardware.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1a170672c656..2cc5e9fd5913 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -45,6 +45,10 @@
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
 
+enum {
+	MLX5_RQ_BITMASK_VSD = 1 << 1,
+};
+
 enum {
 	MLX5_BOARD_ID_LEN = 64,
 	MLX5_MAX_NAME_LEN = 16,

commit bb64143eee8c036a89b31daa4e9bf8360a8bded1
Author: Gal Pressman <galp@mellanox.com>
Date:   Sun Apr 24 22:51:54 2016 +0300

    net/mlx5e: Add ethtool support for dump module EEPROM
    
    Add query MCIA, PMLP registers infrastructure and commands.
    Add ethtool support for get_module_info() and get_module_eeprom()
    callbacks.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2e8758d1b19e..1a170672c656 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -113,9 +113,10 @@ enum {
 	MLX5_REG_PELC		 = 0x500e,
 	MLX5_REG_PVLC		 = 0x500f,
 	MLX5_REG_PCMR		 = 0x5041,
-	MLX5_REG_PMLP		 = 0, /* TBD */
+	MLX5_REG_PMLP		 = 0x5002,
 	MLX5_REG_NODE_DESC	 = 0x6001,
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
+	MLX5_REG_MCIA		 = 0x9014,
 	MLX5_REG_MLCR		 = 0x902b,
 };
 

commit da54d24ec3ef736de04c61a01653776a9750334f
Author: Gal Pressman <galp@mellanox.com>
Date:   Sun Apr 24 22:51:53 2016 +0300

    net/mlx5e: Add ethtool support for interface identify (LED blinking)
    
    Add the needed hardware command and mlx5_ifc structs for managing LED
    control.
    Add set_phys_id ethtool callback to support ethtool -p flag.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 497a4dbd91b0..2e8758d1b19e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -116,6 +116,7 @@ enum {
 	MLX5_REG_PMLP		 = 0, /* TBD */
 	MLX5_REG_NODE_DESC	 = 0x6001,
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
+	MLX5_REG_MLCR		 = 0x902b,
 };
 
 enum {

commit 94cb1ebbafd509210887eea6ced55c40da7b4baa
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Sun Apr 24 22:51:52 2016 +0300

    net/mlx5e: Add support for RXALL netdev feature
    
    Introduce new access register named Ports Check Mask Register (PCMR) to
    control all HW checks on port. With this register, the driver can
    enable/disable Hardware FCS validation.
    
    When RXALL is enabled/disabled using ndo_set_features, enable/disable
    fcs check at HW.
    User can change HW configuration using rx-all flag at ethtool.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index dcd5ac8d3b14..497a4dbd91b0 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -112,6 +112,7 @@ enum {
 	MLX5_REG_PMPE		 = 0x5010,
 	MLX5_REG_PELC		 = 0x500e,
 	MLX5_REG_PVLC		 = 0x500f,
+	MLX5_REG_PCMR		 = 0x5041,
 	MLX5_REG_PMLP		 = 0, /* TBD */
 	MLX5_REG_NODE_DESC	 = 0x6001,
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,

commit 5fc7197d3a256d9c5de3134870304b24892a4908
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Fri Apr 22 00:33:07 2016 +0300

    net/mlx5: Add pci shutdown callback
    
    This patch introduces kexec support for mlx5.
    When switching kernels, kexec() calls shutdown, which unloads
    the driver and cleans its resources.
    
    In addition, remove unregister netdev from shutdown flow. This will
    allow a clean shutdown, even if some netdev clients did not release their
    reference from this netdev. Releasing The HW resources only is enough as
    the kernel is shutting down
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Haggai Abramovsky <hagaya@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index dcd5ac8d3b14..369c837d40f5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -519,8 +519,9 @@ enum mlx5_device_state {
 };
 
 enum mlx5_interface_state {
-	MLX5_INTERFACE_STATE_DOWN,
-	MLX5_INTERFACE_STATE_UP,
+	MLX5_INTERFACE_STATE_DOWN = BIT(0),
+	MLX5_INTERFACE_STATE_UP = BIT(1),
+	MLX5_INTERFACE_STATE_SHUTDOWN = BIT(2),
 };
 
 enum mlx5_pci_status {
@@ -544,7 +545,7 @@ struct mlx5_core_dev {
 	enum mlx5_device_state	state;
 	/* sync interface state */
 	struct mutex		intf_state_mutex;
-	enum mlx5_interface_state interface_state;
+	unsigned long		intf_state;
 	void			(*event) (struct mlx5_core_dev *dev,
 					  enum mlx5_dev_event event,
 					  unsigned long param);

commit b8ba4526832fcccba7f46e55ce9a8b79902bdcec
Merge: 01cde1538e1d 520a07bff6fb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 22 15:48:44 2016 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull more rdma updates from Doug Ledford:
     "Round two of 4.6 merge window patches.
    
      This is a monster pull request.  I held off on the hfi1 driver updates
      (the hfi1 driver is intimately tied to the qib driver and the new
      rdmavt software library that was created to help both of them) in my
      first pull request.  The hfi1/qib/rdmavt update is probably 90% of
      this pull request.  The hfi1 driver is being left in staging so that
      it can be fixed up in regards to the API that Al and yourself didn't
      like.  Intel has agreed to do the work, but in the meantime, this
      clears out 300+ patches in the backlog queue and brings my tree and
      their tree closer to sync.
    
      This also includes about 10 patches to the core and a few to mlx5 to
      create an infrastructure for configuring SRIOV ports on IB devices.
      That series includes one patch to the net core that we sent to netdev@
      and Dave Miller with each of the three revisions to the series.  We
      didn't get any response to the patch, so we took that as implicit
      approval.
    
      Finally, this series includes Intel's new iWARP driver for their x722
      cards.  It's not nearly the beast as the hfi1 driver.  It also has a
      linux-next merge issue, but that has been resolved and it now passes
      just fine.
    
      Summary:
    
       - A few minor core fixups needed for the next patch series
    
       - The IB SRIOV series.  This has bounced around for several versions.
         Of note is the fact that the first patch in this series effects the
         net core.  It was directed to netdev and DaveM for each iteration
         of the series (three versions total).  Dave did not object, but did
         not respond either.  I've taken this as permission to move forward
         with the series.
    
       - The new Intel X722 iWARP driver
    
       - A huge set of updates to the Intel hfi1 driver.  Of particular
         interest here is that we have left the driver in staging since it
         still has an API that people object to.  Intel is working on a fix,
         but getting these patches in now helps keep me sane as the upstream
         and Intel's trees were over 300 patches apart"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (362 commits)
      IB/ipoib: Allow mcast packets from other VFs
      IB/mlx5: Implement callbacks for manipulating VFs
      net/mlx5_core: Implement modify HCA vport command
      net/mlx5_core: Add VF param when querying vport counter
      IB/ipoib: Add ndo operations for configuring VFs
      IB/core: Add interfaces to control VF attributes
      IB/core: Support accessing SA in virtualized environment
      IB/core: Add subnet prefix to port info
      IB/mlx5: Fix decision on using MAD_IFC
      net/core: Add support for configuring VF GUIDs
      IB/{core, ulp} Support above 32 possible device capability flags
      IB/core: Replace setting the zero values in ib_uverbs_ex_query_device
      net/mlx5_core: Introduce offload arithmetic hardware capabilities
      net/mlx5_core: Refactor device capability function
      net/mlx5_core: Fix caching ATOMIC endian mode capability
      ib_srpt: fix a WARN_ON() message
      i40iw: Replace the obsolete crypto hash interface with shash
      IB/hfi1: Add SDMA cache eviction algorithm
      IB/hfi1: Switch to using the pin query function
      IB/hfi1: Specify mm when releasing pages
      ...

commit eff901d30e6cebd940072637f112ce4d0090ac12
Author: Eli Cohen <eli@mellanox.com>
Date:   Fri Mar 11 22:58:42 2016 +0200

    IB/mlx5: Implement callbacks for manipulating VFs
    
    Implement the IB defined callbacks used to manipulate the policy for the
    link state, set GUIDs or get statistics information. This functionality
    is added into a new file that will be used to add any SRIOV related
    functionality to the mlx5 IB layer.
    
    The following callbacks have been added:
    
    mlx5_ib_get_vf_config
    mlx5_ib_set_vf_link_state
    mlx5_ib_get_vf_stats
    mlx5_ib_set_vf_guid
    
    In addition, publish whether this device is based on a virtual function.
    
    In mlx5 supported devices, virtual functions are implemented as vHCAs.
    vHCAs have their own QP number space so it is possible that two vHCAs
    will use a QP with the same number at the same time.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 406b27ec1d42..e1d987fb49b2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -613,7 +613,10 @@ struct mlx5_pas {
 };
 
 enum port_state_policy {
-	MLX5_AAA_000
+	MLX5_POLICY_DOWN	= 0,
+	MLX5_POLICY_UP		= 1,
+	MLX5_POLICY_FOLLOW	= 2,
+	MLX5_POLICY_INVALID	= 0xffffffff
 };
 
 enum phy_port_state {

commit b06e7de8a9d8d1d540ec122bbdf2face2a211634
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Tue Feb 23 10:25:22 2016 +0200

    net/mlx5_core: Refactor device capability function
    
    Device capability function was called similar in all places.
    It was called twice for every queried parameter, while the
    difference between calls was in HCA capability mode only.
    
    The change proposed unify these calls into one function.
    
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9108904a6a56..406b27ec1d42 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -706,8 +706,7 @@ void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
 int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
 int mlx5_cmd_status_to_err_v2(void *ptr);
-int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type,
-		       enum mlx5_cap_mode cap_mode);
+int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 		  int out_size);
 int mlx5_cmd_exec_cb(struct mlx5_core_dev *dev, void *in, int in_size,

commit 1200b6809dfd9d73bc4c7db76d288c35fa4b2ebe
Merge: 6b5f04b6cf8e fe30937b6535
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 19 10:05:34 2016 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
     "Highlights:
    
       1) Support more Realtek wireless chips, from Jes Sorenson.
    
       2) New BPF types for per-cpu hash and arrap maps, from Alexei
          Starovoitov.
    
       3) Make several TCP sysctls per-namespace, from Nikolay Borisov.
    
       4) Allow the use of SO_REUSEPORT in order to do per-thread processing
       of incoming TCP/UDP connections.  The muxing can be done using a
       BPF program which hashes the incoming packet.  From Craig Gallek.
    
       5) Add a multiplexer for TCP streams, to provide a messaged based
          interface.  BPF programs can be used to determine the message
          boundaries.  From Tom Herbert.
    
       6) Add 802.1AE MACSEC support, from Sabrina Dubroca.
    
       7) Avoid factorial complexity when taking down an inetdev interface
          with lots of configured addresses.  We were doing things like
          traversing the entire address less for each address removed, and
          flushing the entire netfilter conntrack table for every address as
          well.
    
       8) Add and use SKB bulk free infrastructure, from Jesper Brouer.
    
       9) Allow offloading u32 classifiers to hardware, and implement for
          ixgbe, from John Fastabend.
    
      10) Allow configuring IRQ coalescing parameters on a per-queue basis,
          from Kan Liang.
    
      11) Extend ethtool so that larger link mode masks can be supported.
          From David Decotigny.
    
      12) Introduce devlink, which can be used to configure port link types
          (ethernet vs Infiniband, etc.), port splitting, and switch device
          level attributes as a whole.  From Jiri Pirko.
    
      13) Hardware offload support for flower classifiers, from Amir Vadai.
    
      14) Add "Local Checksum Offload".  Basically, for a tunneled packet
          the checksum of the outer header is 'constant' (because with the
          checksum field filled into the inner protocol header, the payload
          of the outer frame checksums to 'zero'), and we can take advantage
          of that in various ways.  From Edward Cree"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1548 commits)
      bonding: fix bond_get_stats()
      net: bcmgenet: fix dma api length mismatch
      net/mlx4_core: Fix backward compatibility on VFs
      phy: mdio-thunder: Fix some Kconfig typos
      lan78xx: add ndo_get_stats64
      lan78xx: handle statistics counter rollover
      RDS: TCP: Remove unused constant
      RDS: TCP: Add sysctl tunables for sndbuf/rcvbuf on rds-tcp socket
      net: smc911x: convert pxa dma to dmaengine
      team: remove duplicate set of flag IFF_MULTICAST
      bonding: remove duplicate set of flag IFF_MULTICAST
      net: fix a comment typo
      ethernet: micrel: fix some error codes
      ip_tunnels, bpf: define IP_TUNNEL_OPTS_MAX and use it
      bpf, dst: add and use dst_tclassid helper
      bpf: make skb->tc_classid also readable
      net: mvneta: bm: clarify dependencies
      cls_bpf: reset class and reuse major in da
      ldmvsw: Checkpatch sunvnet.c and sunvnet_common.c
      ldmvsw: Add ldmvsw.c driver code
      ...

commit 0ba422410bbf7081c3c7d7b2dcc10e9eb5cb46f7
Author: Moshe Lazer <moshel@mellanox.com>
Date:   Wed Mar 2 00:13:40 2016 +0200

    net/mlx5: Fix global UAR mapping
    
    Avoid double mapping of io mapped memory, Device page may be
    mapped to non-cached(NC) or to write-combining(WC).
    The code before this fix tries to map it both to WC and NC
    contrary to what stated in Intel's software developer manual.
    
    Here we remove the global WC mapping of all UARS
    "dev->priv.bf_mapping", since UAR mapping should be decided
    per UAR (e.g we want different mappings for EQs, CQs vs QPs).
    
    Caller will now have to choose whether to map via
    write-combining API or not.
    
    mlx5e SQs will choose write-combining in order to perform
    BlueFlame writes.
    
    Fixes: 88a85f99e51f ('TX latency optimization to save DMA reads')
    Signed-off-by: Moshe Lazer <moshel@mellanox.com>
    Reviewed-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3388a43b78f6..bb1a880a5bc5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -460,8 +460,6 @@ struct mlx5_priv {
 	struct mlx5_uuar_info	uuari;
 	MLX5_DECLARE_DOORBELL_LOCK(cq_uar_lock);
 
-	struct io_mapping	*bf_mapping;
-
 	/* pages stuff */
 	struct workqueue_struct *pg_wq;
 	struct rb_root		page_root;
@@ -719,7 +717,8 @@ int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
 int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
 int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
 int mlx5_free_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
-int mlx5_alloc_map_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);
+int mlx5_alloc_map_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar,
+		       bool map_wc);
 void mlx5_unmap_free_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);
 void mlx5_health_cleanup(struct mlx5_core_dev *dev);
 int mlx5_health_init(struct mlx5_core_dev *dev);

commit 6b6c07bdcdc97ccac2596063bfc32a5faddfe884
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Wed Mar 2 00:13:39 2016 +0200

    net/mlx5: Make command timeout way shorter
    
    The command timeout is terribly long, whole two hours. Make it 60s so if
    things do go wrong, the user gets feedback in relatively short time, so
    they can take corrective actions and/or investigate using tools and such.
    
    Fixes: e126ba97dba9 ('mlx5: Add driver for Mellanox Connect-IB adapters')
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index a815da92d4eb..3388a43b78f6 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -54,7 +54,7 @@ enum {
 	/* one minute for the sake of bringup. Generally, commands must always
 	 * complete and we may need to increase this timeout value
 	 */
-	MLX5_CMD_TIMEOUT_MSEC	= 7200 * 1000,
+	MLX5_CMD_TIMEOUT_MSEC	= 60 * 1000,
 	MLX5_CMD_WQ_MAX_NAME	= 32,
 };
 

commit a606b0f6691daf861482f8b77326f672238ffbfd
Author: Matan Barak <matanb@mellanox.com>
Date:   Mon Feb 29 18:05:28 2016 +0200

    net/mlx5: Refactor mlx5_core_mr to mkey
    
    Mlx5's mkey mechanism is also used for memory windows.
    The current code base uses MR (memory region) naming, which is
    inaccurate. Changing MR to mkey in order to represent its different
    usages more accurately.
    
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8edcd08853dd..9108904a6a56 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -338,7 +338,7 @@ struct mlx5_core_sig_ctx {
 	u32			sigerr_count;
 };
 
-struct mlx5_core_mr {
+struct mlx5_core_mkey {
 	u64			iova;
 	u64			size;
 	u32			key;
@@ -426,7 +426,7 @@ struct mlx5_srq_table {
 	struct radix_tree_root	tree;
 };
 
-struct mlx5_mr_table {
+struct mlx5_mkey_table {
 	/* protect radix tree
 	 */
 	rwlock_t		lock;
@@ -484,9 +484,9 @@ struct mlx5_priv {
 	struct mlx5_cq_table	cq_table;
 	/* end: cq staff */
 
-	/* start: mr staff */
-	struct mlx5_mr_table	mr_table;
-	/* end: mr staff */
+	/* start: mkey staff */
+	struct mlx5_mkey_table	mkey_table;
+	/* end: mkey staff */
 
 	/* start: alloc staff */
 	/* protect buffer alocation according to numa node */
@@ -739,16 +739,18 @@ int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 			struct mlx5_query_srq_mbox_out *out);
 int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 		      u16 lwm, int is_srq);
-void mlx5_init_mr_table(struct mlx5_core_dev *dev);
-void mlx5_cleanup_mr_table(struct mlx5_core_dev *dev);
-int mlx5_core_create_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+void mlx5_init_mkey_table(struct mlx5_core_dev *dev);
+void mlx5_cleanup_mkey_table(struct mlx5_core_dev *dev);
+int mlx5_core_create_mkey(struct mlx5_core_dev *dev,
+			  struct mlx5_core_mkey *mkey,
 			  struct mlx5_create_mkey_mbox_in *in, int inlen,
 			  mlx5_cmd_cbk_t callback, void *context,
 			  struct mlx5_create_mkey_mbox_out *out);
-int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr);
-int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev,
+			   struct mlx5_core_mkey *mkey);
+int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mkey *mkey,
 			 struct mlx5_query_mkey_mbox_out *out, int outlen);
-int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mkey *_mkey,
 			     u32 *mkey);
 int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
 int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);

commit 1c64bf6f291cae7cbe779e407db9477378bb4e7d
Author: Meny Yossefi <menyy@mellanox.com>
Date:   Thu Feb 18 18:15:00 2016 +0200

    net/mlx5_core: Add helper function to read IB error counters
    
    Added helper function to read IB standard error counters
    via the PPCNT register.
    
    The PPCNT register read command provides the 32-bit error counters
    of both IB/RoCE link layer and transport layer.
    
    Signed-off-by: Meny Yossefi <menyy@mellanox.com>
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1e3006dcf35d..8edcd08853dd 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -847,6 +847,8 @@ int mlx5_core_destroy_psv(struct mlx5_core_dev *dev, int psv_num);
 void mlx5_core_put_rsc(struct mlx5_core_rsc_common *common);
 int mlx5_query_odp_caps(struct mlx5_core_dev *dev,
 			struct mlx5_odp_caps *odp_caps);
+int mlx5_core_query_ib_ppcnt(struct mlx5_core_dev *dev,
+			     u8 port_num, void *out, size_t sz);
 
 static inline int fw_initializing(struct mlx5_core_dev *dev)
 {

commit 4f3961eeafe0aca8f6b0933899ef0d91f561352d
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Feb 22 18:17:25 2016 +0200

    net/mlx5: Introduce physical port TC/prio access functions
    
    Add access functions to set and query a physical port TC groups
    and prio parameters.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 02adc67720ce..a815da92d4eb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -99,6 +99,8 @@ enum {
 };
 
 enum {
+	MLX5_REG_QETCR		 = 0x4005,
+	MLX5_REG_QTCT		 = 0x400a,
 	MLX5_REG_PCAP		 = 0x5001,
 	MLX5_REG_PMTU		 = 0x5003,
 	MLX5_REG_PTYS		 = 0x5004,

commit ada68c31ba9c02d7aabdd87db979fe670b499d54
Author: Achiad Shochat <achiad@mellanox.com>
Date:   Mon Feb 22 18:17:23 2016 +0200

    net/mlx5: Introduce a new header file for physical port functions
    
    All the device physical port access functions are implemented in the
    port.c file.
    We just extract the exposure of these functions from driver.h into a
    dedicated header file called port.h.
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1e3006dcf35d..02adc67720ce 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -794,37 +794,6 @@ int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
 			 int size_in, void *data_out, int size_out,
 			 u16 reg_num, int arg, int write);
 
-int mlx5_set_port_caps(struct mlx5_core_dev *dev, u8 port_num, u32 caps);
-int mlx5_query_port_ptys(struct mlx5_core_dev *dev, u32 *ptys,
-			 int ptys_size, int proto_mask, u8 local_port);
-int mlx5_query_port_proto_cap(struct mlx5_core_dev *dev,
-			      u32 *proto_cap, int proto_mask);
-int mlx5_query_port_proto_admin(struct mlx5_core_dev *dev,
-				u32 *proto_admin, int proto_mask);
-int mlx5_query_port_link_width_oper(struct mlx5_core_dev *dev,
-				    u8 *link_width_oper, u8 local_port);
-int mlx5_query_port_proto_oper(struct mlx5_core_dev *dev,
-			       u8 *proto_oper, int proto_mask,
-			       u8 local_port);
-int mlx5_set_port_proto(struct mlx5_core_dev *dev, u32 proto_admin,
-			int proto_mask);
-int mlx5_set_port_admin_status(struct mlx5_core_dev *dev,
-			       enum mlx5_port_status status);
-int mlx5_query_port_admin_status(struct mlx5_core_dev *dev,
-				 enum mlx5_port_status *status);
-
-int mlx5_set_port_mtu(struct mlx5_core_dev *dev, int mtu, u8 port);
-void mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu, u8 port);
-void mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu,
-			      u8 port);
-
-int mlx5_query_port_vl_hw_cap(struct mlx5_core_dev *dev,
-			      u8 *vl_hw_cap, u8 local_port);
-
-int mlx5_set_port_pause(struct mlx5_core_dev *dev, u32 rx_pause, u32 tx_pause);
-int mlx5_query_port_pause(struct mlx5_core_dev *dev,
-			  u32 *rx_pause, u32 *tx_pause);
-
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,

commit 048ccca8c1c8f583deec3367d7df521bb1f542ae
Merge: b3e27d5d4a29 34356f64ac0d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 23 18:45:06 2016 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull rdma updates from Doug Ledford:
     "Initial roundup of 4.5 merge window patches
    
       - Remove usage of ib_query_device and instead store attributes in
         ib_device struct
    
       - Move iopoll out of block and into lib, rename to irqpoll, and use
         in several places in the rdma stack as our new completion queue
         polling library mechanism.  Update the other block drivers that
         already used iopoll to use the new mechanism too.
    
       - Replace the per-entry GID table locks with a single GID table lock
    
       - IPoIB multicast cleanup
    
       - Cleanups to the IB MR facility
    
       - Add support for 64bit extended IB counters
    
       - Fix for netlink oops while parsing RDMA nl messages
    
       - RoCEv2 support for the core IB code
    
       - mlx4 RoCEv2 support
    
       - mlx5 RoCEv2 support
    
       - Cross Channel support for mlx5
    
       - Timestamp support for mlx5
    
       - Atomic support for mlx5
    
       - Raw QP support for mlx5
    
       - MAINTAINERS update for mlx4/mlx5
    
       - Misc ocrdma, qib, nes, usNIC, cxgb3, cxgb4, mlx4, mlx5 updates
    
       - Add support for remote invalidate to the iSER driver (pushed
         through the RDMA tree due to dependencies, acknowledged by nab)
    
       - Update to NFSoRDMA (pushed through the RDMA tree due to
         dependencies, acknowledged by Bruce)"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (169 commits)
      IB/mlx5: Unify CQ create flags check
      IB/mlx5: Expose Raw Packet QP to user space consumers
      {IB, net}/mlx5: Move the modify QP operation table to mlx5_ib
      IB/mlx5: Support setting Ethernet priority for Raw Packet QPs
      IB/mlx5: Add Raw Packet QP query functionality
      IB/mlx5: Add create and destroy functionality for Raw Packet QP
      IB/mlx5: Refactor mlx5_ib_qp to accommodate other QP types
      IB/mlx5: Allocate a Transport Domain for each ucontext
      net/mlx5_core: Warn on unsupported events of QP/RQ/SQ
      net/mlx5_core: Add RQ and SQ event handling
      net/mlx5_core: Export transport objects
      IB/mlx5: Expose CQE version to user-space
      IB/mlx5: Add CQE version 1 support to user QPs and SRQs
      IB/mlx5: Fix data validation in mlx5_ib_alloc_ucontext
      IB/sa: Fix netlink local service GFP crash
      IB/srpt: Remove redundant wc array
      IB/qib: Improve ipoib UD performance
      IB/mlx4: Advertise RoCE v2 support
      IB/mlx4: Create and use another QP1 for RoCEv2
      IB/mlx4: Enable send of RoCE QP1 packets with IP/UDP headers
      ...

commit e2013b212f9f201c71fc5826ce41f39ebece0852
Author: majd@mellanox.com <majd@mellanox.com>
Date:   Thu Jan 14 19:13:00 2016 +0200

    net/mlx5_core: Add RQ and SQ event handling
    
    RQ/SQ will be used to implement IB verbs QPs, so the IB QP affiliated
    events are affiliated also with SQs and RQs.
    
    Since SQ, RQ and QP resource numbers do not share the same name
    space, a queue type field was added to the event data to specify
    the SW object that the event is affiliated with.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 53c57724c8dd..ae8f91528b6f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -346,9 +346,11 @@ struct mlx5_core_mr {
 };
 
 enum mlx5_res_type {
-	MLX5_RES_QP,
-	MLX5_RES_SRQ,
-	MLX5_RES_XSRQ,
+	MLX5_RES_QP	= MLX5_EVENT_QUEUE_TYPE_QP,
+	MLX5_RES_RQ	= MLX5_EVENT_QUEUE_TYPE_RQ,
+	MLX5_RES_SQ	= MLX5_EVENT_QUEUE_TYPE_SQ,
+	MLX5_RES_SRQ	= 3,
+	MLX5_RES_XSRQ	= 4,
 };
 
 struct mlx5_core_rsc_common {

commit 0b6e26ce89391327d955a756a7823272238eb867
Author: Doron Tsur <doront@mellanox.com>
Date:   Sun Jan 17 11:25:47 2016 +0200

    net/mlx5_core: Fix trimming down IRQ number
    
    With several ConnectX-4 cards installed on a server, one may receive
    irqn > 255 from the kernel API, which we mistakenly trim to 8bit.
    
    This causes EQ creation failure with the following stack trace:
    [<ffffffff812a11f4>] dump_stack+0x48/0x64
    [<ffffffff810ace21>] __setup_irq+0x3a1/0x4f0
    [<ffffffff810ad7e0>] request_threaded_irq+0x120/0x180
    [<ffffffffa0923660>] ? mlx5_eq_int+0x450/0x450 [mlx5_core]
    [<ffffffffa0922f64>] mlx5_create_map_eq+0x1e4/0x2b0 [mlx5_core]
    [<ffffffffa091de01>] alloc_comp_eqs+0xb1/0x180 [mlx5_core]
    [<ffffffffa091ea99>] mlx5_dev_init+0x5e9/0x6e0 [mlx5_core]
    [<ffffffffa091ec29>] init_one+0x99/0x1c0 [mlx5_core]
    [<ffffffff812e2afc>] local_pci_probe+0x4c/0xa0
    
    Fixing it by changing of the irqn type from u8 to unsigned int to
    support values > 255
    
    Fixes: 61d0e73e0a5a ('net/mlx5_core: Use the the real irqn in eq->irqn')
    Reported-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: Doron Tsur <doront@mellanox.com>
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2fd7019f69db..5162f3533042 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -303,7 +303,7 @@ struct mlx5_eq {
 	u32			cons_index;
 	struct mlx5_buf		buf;
 	int			size;
-	u8			irqn;
+	unsigned int		irqn;
 	u8			eqn;
 	int			nent;
 	u64			mask;
@@ -783,7 +783,8 @@ int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_start_eqs(struct mlx5_core_dev *dev);
 int mlx5_stop_eqs(struct mlx5_core_dev *dev);
-int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn, int *irqn);
+int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn,
+		    unsigned int *irqn);
 int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
 int mlx5_core_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
 

commit da7525d2a9ae9d9d9af754441befcf2560f6cac3
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Dec 14 16:34:10 2015 +0200

    IB/mlx5: Advertise atomic capabilities in query device
    
    In order to ensure IB spec atomic correctness in atomic operations, if
    HW is configured to host endianness, advertise IB_ATOMIC_HCA.  if not,
    advertise IB_ATOMIC_NONE.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7b9c976b42d9..53c57724c8dd 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -115,6 +115,11 @@ enum {
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 };
 
+enum {
+	MLX5_ATOMIC_OPS_CMP_SWAP	= 1 << 0,
+	MLX5_ATOMIC_OPS_FETCH_ADD	= 1 << 1,
+};
+
 enum mlx5_page_fault_resume_flags {
 	MLX5_PAGE_FAULT_RESUME_REQUESTOR = 1 << 0,
 	MLX5_PAGE_FAULT_RESUME_WRITE	 = 1 << 1,

commit 3f89a643eb29543af0838d37604bbc29a4e1eb60
Author: Achiad Shochat <achiad@mellanox.com>
Date:   Wed Dec 23 18:47:21 2015 +0200

    IB/mlx5: Extend query_device/port to support RoCE
    
    Using the vport access functions to retrieve the Ethernet
    specific information and return this information in
    ib_query_device and ib_query_port.
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5c857f2a20d7..7b9c976b42d9 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -632,13 +632,6 @@ extern struct workqueue_struct *mlx5_core_wq;
 	.struct_offset_bytes = offsetof(struct ib_unpacked_ ## header, field),      \
 	.struct_size_bytes   = sizeof((struct ib_unpacked_ ## header *)0)->field
 
-struct ib_field {
-	size_t struct_offset_bytes;
-	size_t struct_size_bytes;
-	int    offset_bits;
-	int    size_bits;
-};
-
 static inline struct mlx5_core_dev *pci2mlx5_core_dev(struct pci_dev *pdev)
 {
 	return pci_get_drvdata(pdev);

commit 2530236303d9e705db6a28eb9a10c8d79b288b37
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Thu Dec 10 17:12:43 2015 +0200

    net/mlx5_core: Flow steering tree initialization
    
    Flow steering initialization is based on static tree which
    illustrates the flow steering tree when the driver is loaded. The
    initialization considers the max supported flow table level of the device,
    a minimum of 2 kernel flow tables(vlan and mac) are required to have
    kernel flow table functionality.
    
    The tree structures when the driver is loaded:
    
                    root_namespace(receive nic)
                              |
                    priority-0 (kernel priority)
                              |
                    namespace(kernel namespace)
                              |
                    priority-0 (flow tables priority)
    
    In the following patches, When the EN driver will use the flow steering
    API, it create two flow tables and their flow groups under
    priority-0(flow tables priority).
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Signed-off-by: Moni Shoua <monis@mellanox.com>
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ac098b6b97bf..2fd7019f69db 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -502,6 +502,8 @@ struct mlx5_priv {
 	struct mlx5_eswitch     *eswitch;
 	struct mlx5_core_sriov	sriov;
 	unsigned long		pci_dev_data;
+	struct mlx5_flow_root_namespace *root_ns;
+	struct mlx5_flow_root_namespace *fdb_root_ns;
 };
 
 enum mlx5_device_state {

commit 073bb189a41d7bbad509b576a690611c46c4858f
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Dec 1 18:03:18 2015 +0200

    net/mlx5: Introducing E-Switch and l2 table
    
    E-Switch is the software entity that represents and manages ConnectX4
    inter-HCA ethernet l2 switching.
    
    E-Switch has its own Virtual Ports, each Vport/vNIC/VF can be
    connected to the device through a vport of an e-switch.
    
    Each e-switch is managed by one vNIC identified by
    HCA_CAP.vport_group_manager (usually it is the PF/vport[0]),
    and its main responsibility is to forward each packet to the
    right vport.
    
    e-Switch needs to manage its own l2-table and FDB tables.
    
    L2 table is a flow table that is managed by FW, it is needed for
    Multi-host (Multi PF) configuration for inter HCA switching between
    PFs.
    
    FDB table is a flow table that is totally managed by e-Switch driver,
    its main responsibility is to switch packets between e-Swtich internal
    vports and uplink vport that belong to the same.
    
    This patch introduces only e-Swtich l2 table management, FDB managemnt
    will come later when ethernet SRIOV/VFs will be enabled.
    
    preperation for ethernet sriov and l2 table management.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index efebb87163c8..ac098b6b97bf 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -441,6 +441,8 @@ struct mlx5_irq_info {
 	char name[MLX5_MAX_IRQ_NAME];
 };
 
+struct mlx5_eswitch;
+
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	eq_table;
@@ -496,6 +498,8 @@ struct mlx5_priv {
 	struct list_head        dev_list;
 	struct list_head        ctx_list;
 	spinlock_t              ctx_lock;
+
+	struct mlx5_eswitch     *eswitch;
 	struct mlx5_core_sriov	sriov;
 	unsigned long		pci_dev_data;
 };

commit fc50db98ff872372f266695858f87a12eb1b4f05
Author: Eli Cohen <eli@mellanox.com>
Date:   Tue Dec 1 18:03:09 2015 +0200

    net/mlx5_core: Add base sriov support
    
    This patch adds SRIOV base support for mlx5 supported devices. The same
    driver is used for both PFs and VFs; VFs are identified by the driver
    through the flag MLX5_PCI_DEV_IS_VF added to the pci table entries.
    Virtual functions are created as usual through writing a value to the
    sriov_numvs sysfs file of the PF device. Upon instantiating VFs, they will
    all be probed by the driver on the hypervisor. One can gracefully unbind
    them through /sys/bus/pci/drivers/mlx5_core/unbind.
    
    mlx5_wait_for_vf_pages() was added to ensure that when a VF dies without
    executing proper teardown, the hypervisor driver waits till all of the
    pages that were allocated at the hypervisor to maintain its operation
    are returned.
    
    In order for the VF to be operational, the PF needs to call enable_hca
    for it. This can be done before the VFs are created through a call to
    pci_enable_sriov.
    
    If the there are VFs assigned to a VMs when the driver of the PF is
    unloaded, all the VF will experience system error and PF driver unloads
    cleanly; in this case pci_disable_sriov is not called and the devices
    will show when running lspci. Once the PF driver is reloaded, it will
    sync its data structures which maintain state on its VFs.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5c857f2a20d7..efebb87163c8 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -426,6 +426,16 @@ struct mlx5_mr_table {
 	struct radix_tree_root	tree;
 };
 
+struct mlx5_vf_context {
+	int	enabled;
+};
+
+struct mlx5_core_sriov {
+	struct mlx5_vf_context	*vfs_ctx;
+	int			num_vfs;
+	int			enabled_vfs;
+};
+
 struct mlx5_irq_info {
 	cpumask_var_t mask;
 	char name[MLX5_MAX_IRQ_NAME];
@@ -447,6 +457,7 @@ struct mlx5_priv {
 	int			fw_pages;
 	atomic_t		reg_pages;
 	struct list_head	free_list;
+	int			vfs_pages;
 
 	struct mlx5_core_health health;
 
@@ -485,6 +496,8 @@ struct mlx5_priv {
 	struct list_head        dev_list;
 	struct list_head        ctx_list;
 	spinlock_t              ctx_lock;
+	struct mlx5_core_sriov	sriov;
+	unsigned long		pci_dev_data;
 };
 
 enum mlx5_device_state {
@@ -739,6 +752,8 @@ void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
 int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
+int mlx5_sriov_init(struct mlx5_core_dev *dev);
+int mlx5_sriov_cleanup(struct mlx5_core_dev *dev);
 void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
 				 s32 npages);
 int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);
@@ -884,6 +899,15 @@ struct mlx5_profile {
 	} mr_cache[MAX_MR_CACHE_ENTRIES];
 };
 
+enum {
+	MLX5_PCI_DEV_IS_VF		= 1 << 0,
+};
+
+static inline int mlx5_core_is_pf(struct mlx5_core_dev *dev)
+{
+	return !(dev->priv.pci_dev_data & MLX5_PCI_DEV_IS_VF);
+}
+
 static inline int mlx5_get_gid_table_len(u16 param)
 {
 	if (param > 4) {

commit e3297246c2c8cf8548ba722da3e3a8104cdcd035
Author: Eli Cohen <eli@mellanox.com>
Date:   Wed Oct 14 17:43:47 2015 +0300

    net/mlx5_core: Wait for FW readiness on startup
    
    On device initialization, wait till firmware indicates that that it is done
    with initialization before proceeding to initialize the device.
    
    Also update initialization segment layout to match driver/firmware
    interface definitions.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9aba8d5139fa..5c857f2a20d7 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -826,6 +826,11 @@ void mlx5_core_put_rsc(struct mlx5_core_rsc_common *common);
 int mlx5_query_odp_caps(struct mlx5_core_dev *dev,
 			struct mlx5_odp_caps *odp_caps);
 
+static inline int fw_initializing(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->initializing) >> 31;
+}
+
 static inline u32 mlx5_mkey_to_idx(u32 mkey)
 {
 	return mkey >> 8;

commit 89d44f0a6c732db23b219be708e2fe1e03ee4842
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Wed Oct 14 17:43:46 2015 +0300

    net/mlx5_core: Add pci error handlers to mlx5_core driver
    
    This patch implement the pci_error_handlers for mlx5_core which allow the
    driver to recover from PCI error.
    
    Once an error is detected in the PCI, the mlx5_pci_err_detected is called
    and it:
    1) Marks the device to be in 'Internal Error' state.
    2) Dispatches an event to the mlx5_ib to flush all the outstanding cqes
    with error.
    3) Returns all the on going commands with error.
    4) Unloads the driver.
    
    Afterwards, the FW is reset and mlx5_pci_slot_reset is called and it
    enables the device and restore it's pci state.
    
    If the later succeeds, mlx5_pci_resume is called, and it loads the SW
    stack.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 62b7d439813d..9aba8d5139fa 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -487,8 +487,26 @@ struct mlx5_priv {
 	spinlock_t              ctx_lock;
 };
 
+enum mlx5_device_state {
+	MLX5_DEVICE_STATE_UP,
+	MLX5_DEVICE_STATE_INTERNAL_ERROR,
+};
+
+enum mlx5_interface_state {
+	MLX5_INTERFACE_STATE_DOWN,
+	MLX5_INTERFACE_STATE_UP,
+};
+
+enum mlx5_pci_status {
+	MLX5_PCI_STATUS_DISABLED,
+	MLX5_PCI_STATUS_ENABLED,
+};
+
 struct mlx5_core_dev {
 	struct pci_dev	       *pdev;
+	/* sync pci state */
+	struct mutex		pci_status_mutex;
+	enum mlx5_pci_status	pci_status;
 	u8			rev_id;
 	char			board_id[MLX5_BOARD_ID_LEN];
 	struct mlx5_cmd		cmd;
@@ -497,6 +515,10 @@ struct mlx5_core_dev {
 	u32 hca_caps_max[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 	phys_addr_t		iseg_base;
 	struct mlx5_init_seg __iomem *iseg;
+	enum mlx5_device_state	state;
+	/* sync interface state */
+	struct mutex		intf_state_mutex;
+	enum mlx5_interface_state interface_state;
 	void			(*event) (struct mlx5_core_dev *dev,
 					  enum mlx5_dev_event event,
 					  unsigned long param);

commit fd76ee4da55abb21babfc69310d321b9cb9a32e0
Author: Eli Cohen <eli@mellanox.com>
Date:   Wed Oct 14 17:43:45 2015 +0300

    net/mlx5_core: Fix internal error detection conditions
    
    The detection of a fatal condition has been updated to take into account
    the state reported by the device or by detecting an all ones read of the
    firmware version which indicates that the device is not accessible.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 41a32873f608..62b7d439813d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -393,6 +393,7 @@ struct mlx5_core_health {
 	struct timer_list		timer;
 	u32				prev;
 	int				miss_counter;
+	bool				sick;
 	struct workqueue_struct	       *wq;
 	struct work_struct		work;
 };

commit ac6ea6e81a80172612e0c9ef93720f371b198918
Author: Eli Cohen <eli@mellanox.com>
Date:   Thu Oct 8 17:14:00 2015 +0300

    net/mlx5_core: Use private health thread for each device
    
    Use a single threaded work queue for each device in the system instead of
    using one thread for any device. This is required so we can concurrently
    process system error handling for all the devices that need that.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index aa899559eec0..41a32873f608 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -391,9 +391,10 @@ struct mlx5_core_health {
 	struct health_buffer __iomem   *health;
 	__be32 __iomem		       *health_counter;
 	struct timer_list		timer;
-	struct list_head		list;
 	u32				prev;
 	int				miss_counter;
+	struct workqueue_struct	       *wq;
+	struct work_struct		work;
 };
 
 struct mlx5_cq_table {
@@ -676,8 +677,8 @@ int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
 int mlx5_free_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
 int mlx5_alloc_map_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);
 void mlx5_unmap_free_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);
-void mlx5_health_cleanup(void);
-void  __init mlx5_health_init(void);
+void mlx5_health_cleanup(struct mlx5_core_dev *dev);
+int mlx5_health_init(struct mlx5_core_dev *dev);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
 int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,

commit 020446e01eebc9dbe7eda038e570ab9c7ab13586
Author: Eli Cohen <eli@mellanox.com>
Date:   Thu Oct 8 17:13:58 2015 +0300

    net/mlx5_core: Prepare cmd interface to system errors handling
    
    In preparation to handling system errors at the mlx5_core level, change the
    interface of cmd_work_handler to accept a 64 bit argument for the vector.
    
    This allows to encode a flag that signifies when the handler is called
    as a result of a driver logic that wishes to terminate commands that
    the hardware may not be able to terminate. Such command completions
    are detected at the handler and proper return status is encoded.
    
    To be able to terminate page handler commands, we make sure to set
    the corresponding bit in the bitmask.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8b6d6f2154a4..aa899559eec0 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -731,7 +731,7 @@ void mlx5_eq_pagefault(struct mlx5_core_dev *dev, struct mlx5_eqe *eqe);
 #endif
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
-void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector);
+void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec);
 void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
 int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 		       int nent, u64 mask, const char *name, struct mlx5_uar *uar);
@@ -865,4 +865,8 @@ static inline int mlx5_get_gid_table_len(u16 param)
 	return 8 * (1 << param);
 }
 
+enum {
+	MLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,
+};
+
 #endif /* MLX5_DRIVER_H */

commit c6790aa9f4fdc26b1246ba36da2fd749663beb65
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Thu Sep 24 10:34:23 2015 +0300

    IB/mlx5: Remove support for IB_DEVICE_LOCAL_DMA_LKEY
    
    Commit 96249d70dd70 ("IB/core: Guarantee that a local_dma_lkey
    is available") allows ULPs that make use of the local dma key to keep
    working as before by allocating a DMA MR with local permissions and
    converted these consumers to use the MR associated with the PD
    rather then device->local_dma_lkey.
    
    ConnectIB has some known issues with memory registration
    using the local_dma_lkey (SEND, RDMA, RECV seems to work ok).
    
    Thus don't expose support for it (remove device->local_dma_lkey
    setting), and take advantage of the above commit such that no regression
    is introduced to working systems.
    
    The local_dma_lkey support will be restored in CX4 depending on FW
    capability query.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 27b53f9a24ad..8b6d6f2154a4 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -845,7 +845,6 @@ void *mlx5_get_protocol_dev(struct mlx5_core_dev *mdev, int protocol);
 int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
 int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
-int mlx5_core_query_special_context(struct mlx5_core_dev *dev, u32 *rsvd_lkey);
 
 struct mlx5_profile {
 	u64	mask;

commit 26d2177e977c912863ac04f6c1a967e793ca3a56
Merge: a794b4f32921 d1178cbcdcf9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 9 08:33:31 2015 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull inifiniband/rdma updates from Doug Ledford:
     "This is a fairly sizeable set of changes.  I've put them through a
      decent amount of testing prior to sending the pull request due to
      that.
    
      There are still a few fixups that I know are coming, but I wanted to
      go ahead and get the big, sizable chunk into your hands sooner rather
      than waiting for those last few fixups.
    
      Of note is the fact that this creates what is intended to be a
      temporary area in the drivers/staging tree specifically for some
      cleanups and additions that are coming for the RDMA stack.  We
      deprecated two drivers (ipath and amso1100) and are waiting to hear
      back if we can deprecate another one (ehca).  We also put Intel's new
      hfi1 driver into this area because it needs to be refactored and a
      transfer library created out of the factored out code, and then it and
      the qib driver and the soft-roce driver should all be modified to use
      that library.
    
      I expect drivers/staging/rdma to be around for three or four kernel
      releases and then to go away as all of the work is completed and final
      deletions of deprecated drivers are done.
    
      Summary of changes for 4.3:
    
       - Create drivers/staging/rdma
       - Move amso1100 driver to staging/rdma and schedule for deletion
       - Move ipath driver to staging/rdma and schedule for deletion
       - Add hfi1 driver to staging/rdma and set TODO for move to regular
         tree
       - Initial support for namespaces to be used on RDMA devices
       - Add RoCE GID table handling to the RDMA core caching code
       - Infrastructure to support handling of devices with differing read
         and write scatter gather capabilities
       - Various iSER updates
       - Kill off unsafe usage of global mr registrations
       - Update SRP driver
       - Misc  mlx4 driver updates
       - Support for the mr_alloc verb
       - Support for a netlink interface between kernel and user space cache
         daemon to speed path record queries and route resolution
       - Ininitial support for safe hot removal of verbs devices"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (136 commits)
      IB/ipoib: Suppress warning for send only join failures
      IB/ipoib: Clean up send-only multicast joins
      IB/srp: Fix possible protection fault
      IB/core: Move SM class defines from ib_mad.h to ib_smi.h
      IB/core: Remove unnecessary defines from ib_mad.h
      IB/hfi1: Add PSM2 user space header to header_install
      IB/hfi1: Add CSRs for CONFIG_SDMA_VERBOSITY
      mlx5: Fix incorrect wc pkey_index assignment for GSI messages
      IB/mlx5: avoid destroying a NULL mr in reg_user_mr error flow
      IB/uverbs: reject invalid or unknown opcodes
      IB/cxgb4: Fix if statement in pick_local_ip6adddrs
      IB/sa: Fix rdma netlink message flags
      IB/ucma: HW Device hot-removal support
      IB/mlx4_ib: Disassociate support
      IB/uverbs: Enable device removal when there are active user space applications
      IB/uverbs: Explicitly pass ib_dev to uverbs commands
      IB/uverbs: Fix race between ib_uverbs_open and remove_one
      IB/uverbs: Fix reference counting usage of event files
      IB/core: Make ib_dealloc_pd return void
      IB/srp: Create an insecure all physical rkey only if needed
      ...

commit a3c874200cbcd95ed914ba84f33f571a0ef7adfa
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Mon Jul 20 19:54:36 2015 +0300

    mlx5: Fix missing device local_dma_lkey
    
    The mlx5 driver exposes device capability IB_DEVICE_LOCAL_DMA_LKEY
    but does not set the the device local_dma_lkey. This breaks
    rpcrdma drivers.
    
    Query and set this lkey when creating the device resources.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5722d88c2429..1e2e48ccb3fd 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -828,6 +828,7 @@ void *mlx5_get_protocol_dev(struct mlx5_core_dev *mdev, int protocol);
 int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
 int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
+int mlx5_core_query_special_context(struct mlx5_core_dev *dev, u32 *rsvd_lkey);
 
 struct mlx5_profile {
 	u64	mask;

commit 3c2d18ef22df1bdccfb11a5b85b29e4e61b9d9c6
Author: Achiad Shochat <achiad@mellanox.com>
Date:   Sun Aug 16 16:04:51 2015 +0300

    net/mlx5e: Support ethtool get/set_pauseparam
    
    Only rx/tx pause settings.
    Autoneg setting is currently not supported.
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 4b5d7fc88d0f..8b6d6f2154a4 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -103,6 +103,7 @@ enum {
 	MLX5_REG_PMTU		 = 0x5003,
 	MLX5_REG_PTYS		 = 0x5004,
 	MLX5_REG_PAOS		 = 0x5006,
+	MLX5_REG_PFCC            = 0x5007,
 	MLX5_REG_PPCNT		 = 0x5008,
 	MLX5_REG_PMAOS		 = 0x5012,
 	MLX5_REG_PUDE		 = 0x5009,
@@ -774,6 +775,10 @@ void mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu,
 int mlx5_query_port_vl_hw_cap(struct mlx5_core_dev *dev,
 			      u8 *vl_hw_cap, u8 local_port);
 
+int mlx5_set_port_pause(struct mlx5_core_dev *dev, u32 rx_pause, u32 tx_pause);
+int mlx5_query_port_pause(struct mlx5_core_dev *dev,
+			  u32 *rx_pause, u32 *tx_pause);
+
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,

commit 6fa1bcab6be6e9bd93f80e345c7e9a4ec7861df9
Author: Achiad Shochat <achiad@mellanox.com>
Date:   Sun Aug 16 16:04:50 2015 +0300

    net/mlx5e: Ethtool link speed setting fixes
    
    - Port speed settings are applied by the device only upon
      port admin status transition from DOWN to UP.
      So we enforce this transition regardless of the port's
      current operation state (which may be occasionally DOWN if
      for example the network cable is disconnected).
    - Fix the PORT_UP/DOWN device interface enum
    - Set the local_port bit in the device PAOS register
    - EXPORT the PAOS (Port Administrative and Operational Status)
      register set/query access functions.
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2039546b0ec6..4b5d7fc88d0f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -152,8 +152,8 @@ enum mlx5_dev_event {
 };
 
 enum mlx5_port_status {
-	MLX5_PORT_UP        = 1 << 1,
-	MLX5_PORT_DOWN      = 1 << 2,
+	MLX5_PORT_UP        = 1,
+	MLX5_PORT_DOWN      = 2,
 };
 
 struct mlx5_uuar_info {
@@ -761,9 +761,10 @@ int mlx5_query_port_proto_oper(struct mlx5_core_dev *dev,
 			       u8 local_port);
 int mlx5_set_port_proto(struct mlx5_core_dev *dev, u32 proto_admin,
 			int proto_mask);
-int mlx5_set_port_status(struct mlx5_core_dev *dev,
-			 enum mlx5_port_status status);
-int mlx5_query_port_status(struct mlx5_core_dev *dev, u8 *status);
+int mlx5_set_port_admin_status(struct mlx5_core_dev *dev,
+			       enum mlx5_port_status status);
+int mlx5_query_port_admin_status(struct mlx5_core_dev *dev,
+				 enum mlx5_port_status *status);
 
 int mlx5_set_port_mtu(struct mlx5_core_dev *dev, int mtu, u8 port);
 void mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu, u8 port);

commit efea389d3cc6427a9a94e92b2d7bf4c862f2cfcf
Author: Gal Pressman <galp@mellanox.com>
Date:   Tue Aug 4 14:05:47 2015 +0300

    net/mlx5_core: Support physical port counters
    
    Added physical port counters in the following standard formats to
    ethtool statistics:
      - IEEE 802.3
      - RFC2863
      - RFC2819
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5fe0cae1a515..2039546b0ec6 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -103,6 +103,7 @@ enum {
 	MLX5_REG_PMTU		 = 0x5003,
 	MLX5_REG_PTYS		 = 0x5004,
 	MLX5_REG_PAOS		 = 0x5006,
+	MLX5_REG_PPCNT		 = 0x5008,
 	MLX5_REG_PMAOS		 = 0x5012,
 	MLX5_REG_PUDE		 = 0x5009,
 	MLX5_REG_PMPE		 = 0x5010,

commit 88a85f99e51fb2373259ab83c8bb130a9bbf3804
Author: Achiad Shochat <achiad@mellanox.com>
Date:   Thu Jul 23 23:35:59 2015 +0300

    net/mlx5e: TX latency optimization to save DMA reads
    
    A regular TX WQE execution involves two or more DMA reads -
    one to fetch the WQE, and another one per WQE gather entry.
    
    These DMA reads obviously increase the TX latency.
    There are two mlx5 mechanisms to bypass these DMA reads:
    1) Inline WQE
    2) Blue Flame (BF)
    
    An inline WQE contains a whole packet, thus saves the DMA read/s
    of the regular WQE gather entry/s. Inline WQE support was already
    added in the previous commit.
    
    A BF WQE is written directly to the device I/O mapped memory, thus
    enables saving the DMA read that fetches the WQE.
    
    The BF WQE I/O write must be in cache line granularity, thus uses
    the CPU write combining mechanism.
    A BF WQE I/O write acts also as a TX doorbell for notifying the
    device of new TX WQEs.
    A BF WQE is written to the same I/O mapped address as the regular TX
    doorbell, thus this address is being mapped twice - once by ioremap()
    and once by io_mapping_map_wc().
    
    While both mechanisms reduce the TX latency, they both consume more CPU
    cycles than a regular WQE:
    - A BF WQE must still be written to host memory, in addition to being
      written directly to the device I/O mapped memory.
    - An inline WQE involves copying the SKB data into it.
    
    To handle this tradeoff, we introduce here a heuristic algorithm that
    strives to avoid using these two mechanisms in case the TX queue is
    being back-pressured by the device, and limit their usage rate otherwise.
    
    An inline WQE will always be "Blue Flamed" (written directly to the
    device I/O mapped memory) while a BF WQE may not be inlined (may contain
    gather entries).
    
    Preliminary testing using netperf UDP_RR shows that the latency goes down
    from 17.5us to 16.9us, while the message rate (tested with pktgen) stays
    the same.
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 1c0d5d062d7c..5fe0cae1a515 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -380,7 +380,7 @@ struct mlx5_uar {
 	u32			index;
 	struct list_head	bf_list;
 	unsigned		free_bf_bmap;
-	void __iomem	       *wc_map;
+	void __iomem	       *bf_map;
 	void __iomem	       *map;
 };
 
@@ -435,6 +435,8 @@ struct mlx5_priv {
 	struct mlx5_uuar_info	uuari;
 	MLX5_DECLARE_DOORBELL_LOCK(cq_uar_lock);
 
+	struct io_mapping	*bf_mapping;
+
 	/* pages stuff */
 	struct workqueue_struct *pg_wq;
 	struct rb_root		page_root;

commit 311c7c71c9bb8786c96fee353fe9886c08b017fe
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Jul 23 23:35:57 2015 +0300

    net/mlx5e: Allocate DMA coherent memory on reader NUMA node
    
    By affinity hints and XPS, each mlx5e channel is assigned a CPU
    core.
    
    Channel DMA coherent memory that is written by the NIC and read
    by SW (e.g CQ buffer) is allocated on the NUMA node of the CPU
    core assigned for the channel.
    
    Channel DMA coherent memory that is written by SW and read by the
    NIC (e.g SQ/RQ buffer) is allocated on the NUMA node of the NIC.
    
    Doorbell record (written by SW and read by the NIC) is an
    exception since it is accessed by SW more frequently.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 5722d88c2429..1c0d5d062d7c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -463,6 +463,10 @@ struct mlx5_priv {
 	/* end: mr staff */
 
 	/* start: alloc staff */
+	/* protect buffer alocation according to numa node */
+	struct mutex            alloc_mutex;
+	int                     numa_node;
+
 	struct mutex            pgdir_mutex;
 	struct list_head        pgdir_list;
 	/* end: alloc staff */
@@ -672,6 +676,8 @@ void mlx5_health_cleanup(void);
 void  __init mlx5_health_init(void);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
+int mlx5_buf_alloc_node(struct mlx5_core_dev *dev, int size,
+			struct mlx5_buf *buf, int node);
 int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, struct mlx5_buf *buf);
 void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_buf *buf);
 struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
@@ -773,6 +779,8 @@ void mlx5_eq_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_cq_debugfs_init(struct mlx5_core_dev *dev);
 void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db);
+int mlx5_db_alloc_node(struct mlx5_core_dev *dev, struct mlx5_db *db,
+		       int node);
 void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);
 
 const char *mlx5_command_str(int command);

commit e0456717e483bb8a9431b80a5bdc99a928b9b003
Merge: 98ec21a01896 1ea2d020ba47
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 24 16:49:49 2015 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) Add TX fast path in mac80211, from Johannes Berg.
    
     2) Add TSO/GRO support to ibmveth, from Thomas Falcon
    
     3) Move away from cached routes in ipv6, just like ipv4, from Martin
        KaFai Lau.
    
     4) Lots of new rhashtable tests, from Thomas Graf.
    
     5) Run ingress qdisc lockless, from Alexei Starovoitov.
    
     6) Allow servers to fetch TCP packet headers for SYN packets of new
        connections, for fingerprinting.  From Eric Dumazet.
    
     7) Add mode parameter to pktgen, for testing receive.  From Alexei
        Starovoitov.
    
     8) Cache access optimizations via simplifications of build_skb(), from
        Alexander Duyck.
    
     9) Move page frag allocator under mm/, also from Alexander.
    
    10) Add xmit_more support to hv_netvsc, from KY Srinivasan.
    
    11) Add a counter guard in case we try to perform endless reclassify
        loops in the packet scheduler.
    
    12) Extern flow dissector to be programmable and use it in new "Flower"
        classifier.  From Jiri Pirko.
    
    13) AF_PACKET fanout rollover fixes, performance improvements, and new
        statistics.  From Willem de Bruijn.
    
    14) Add netdev driver for GENEVE tunnels, from John W Linville.
    
    15) Add ingress netfilter hooks and filtering, from Pablo Neira Ayuso.
    
    16) Fix handling of epoll edge triggers in TCP, from Eric Dumazet.
    
    17) Add an ECN retry fallback for the initial TCP handshake, from Daniel
        Borkmann.
    
    18) Add tail call support to BPF, from Alexei Starovoitov.
    
    19) Add several pktgen helper scripts, from Jesper Dangaard Brouer.
    
    20) Add zerocopy support to AF_UNIX, from Hannes Frederic Sowa.
    
    21) Favor even port numbers for allocation to connect() requests, and
        odd port numbers for bind(0), in an effort to help avoid
        ip_local_port_range exhaustion.  From Eric Dumazet.
    
    22) Add Cavium ThunderX driver, from Sunil Goutham.
    
    23) Allow bpf programs to access skb_iif and dev->ifindex SKB metadata,
        from Alexei Starovoitov.
    
    24) Add support for T6 chips in cxgb4vf driver, from Hariprasad Shenai.
    
    25) Double TCP Small Queues default to 256K to accomodate situations
        like the XEN driver and wireless aggregation.  From Wei Liu.
    
    26) Add more entropy inputs to flow dissector, from Tom Herbert.
    
    27) Add CDG congestion control algorithm to TCP, from Kenneth Klette
        Jonassen.
    
    28) Convert ipset over to RCU locking, from Jozsef Kadlecsik.
    
    29) Track and act upon link status of ipv4 route nexthops, from Andy
        Gospodarek.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1670 commits)
      bridge: vlan: flush the dynamically learned entries on port vlan delete
      bridge: multicast: add a comment to br_port_state_selection about blocking state
      net: inet_diag: export IPV6_V6ONLY sockopt
      stmmac: troubleshoot unexpected bits in des0 & des1
      net: ipv4 sysctl option to ignore routes when nexthop link is down
      net: track link-status of ipv4 nexthops
      net: switchdev: ignore unsupported bridge flags
      net: Cavium: Fix MAC address setting in shutdown state
      drivers: net: xgene: fix for ACPI support without ACPI
      ip: report the original address of ICMP messages
      net/mlx5e: Prefetch skb data on RX
      net/mlx5e: Pop cq outside mlx5e_get_cqe
      net/mlx5e: Remove mlx5e_cq.sqrq back-pointer
      net/mlx5e: Remove extra spaces
      net/mlx5e: Avoid TX CQE generation if more xmit packets expected
      net/mlx5e: Avoid redundant dev_kfree_skb() upon NOP completion
      net/mlx5e: Remove re-assignment of wq type in mlx5e_enable_rq()
      net/mlx5e: Use skb_shinfo(skb)->gso_segs rather than counting them
      net/mlx5e: Static mapping of netdev priv resources to/from netdev TX queues
      net/mlx4_en: Use HW counters for rx/tx bytes/packets in PF device
      ...

commit facc9699f0fe7d65a92cc09e175662659306066d
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Jun 11 14:47:27 2015 +0300

    net/mlx5e: Fix HW MTU settings
    
    Previously we configured HW MTU to be netdev->mtu, actually we
    need to configure netdev->mtu + (ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN).
    
    Also, query MTU can not fail, hence make the relevant helper a
    void functionm, add mlx5e_set_dev_port_mtu, helper function to
    handle MTU setting.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6093bde16b94..c0930f8d7021 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -756,11 +756,11 @@ int mlx5_set_port_status(struct mlx5_core_dev *dev,
 			 enum mlx5_port_status status);
 int mlx5_query_port_status(struct mlx5_core_dev *dev, u8 *status);
 
-int mlx5_set_port_mtu(struct mlx5_core_dev *dev, int mtu);
-int mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu,
-			    u8 local_port);
-int mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu,
-			     u8 local_port);
+int mlx5_set_port_mtu(struct mlx5_core_dev *dev, int mtu, u8 port);
+void mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu, u8 port);
+void mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu,
+			      u8 port);
+
 int mlx5_query_port_vl_hw_cap(struct mlx5_core_dev *dev,
 			      u8 *vl_hw_cap, u8 local_port);
 

commit a124d13ef59e09941fc0924fd7c29ae6d7cd77a3
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Thu Jun 4 19:30:45 2015 +0300

    net/mlx5_core: Add more query port helpers
    
    Add the following helpers:
    
    1. mlx5_query_port_proto_oper -- queries the port speed port mask
    2. mlx5_query_port_link_width_oper - queries the port link with bitmask
    3. mlx5_query_port_vl_hw_cap - queries the Virtual Lanes supported on this port
    
    These helpers will be used from the IB driver when working in ISSI > 0 mode.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index e4b814f64014..6093bde16b94 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -107,6 +107,7 @@ enum {
 	MLX5_REG_PUDE		 = 0x5009,
 	MLX5_REG_PMPE		 = 0x5010,
 	MLX5_REG_PELC		 = 0x500e,
+	MLX5_REG_PVLC		 = 0x500f,
 	MLX5_REG_PMLP		 = 0, /* TBD */
 	MLX5_REG_NODE_DESC	 = 0x6001,
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
@@ -744,6 +745,11 @@ int mlx5_query_port_proto_cap(struct mlx5_core_dev *dev,
 			      u32 *proto_cap, int proto_mask);
 int mlx5_query_port_proto_admin(struct mlx5_core_dev *dev,
 				u32 *proto_admin, int proto_mask);
+int mlx5_query_port_link_width_oper(struct mlx5_core_dev *dev,
+				    u8 *link_width_oper, u8 local_port);
+int mlx5_query_port_proto_oper(struct mlx5_core_dev *dev,
+			       u8 *proto_oper, int proto_mask,
+			       u8 local_port);
 int mlx5_set_port_proto(struct mlx5_core_dev *dev, u32 proto_admin,
 			int proto_mask);
 int mlx5_set_port_status(struct mlx5_core_dev *dev,
@@ -755,6 +761,8 @@ int mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu,
 			    u8 local_port);
 int mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu,
 			     u8 local_port);
+int mlx5_query_port_vl_hw_cap(struct mlx5_core_dev *dev,
+			      u8 *vl_hw_cap, u8 local_port);
 
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);

commit a05bdefa4081d43f9c86c3bb693d0492a21590da
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Thu Jun 4 19:30:44 2015 +0300

    net/mlx5_core: Use port number when querying port ptys
    
    Until now, mlx5_query_port_ptys always queried port number one.
    
    Added new argument in the function's prototype so we can also query
    the second port. This will be needed  when thr helper will be invoked
    from the IB driver on non FPP (Function-Per-Port) devices.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index cd09784b6999..e4b814f64014 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -739,7 +739,7 @@ int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
 
 int mlx5_set_port_caps(struct mlx5_core_dev *dev, u8 port_num, u32 caps);
 int mlx5_query_port_ptys(struct mlx5_core_dev *dev, u32 *ptys,
-			 int ptys_size, int proto_mask);
+			 int ptys_size, int proto_mask, u8 local_port);
 int mlx5_query_port_proto_cap(struct mlx5_core_dev *dev,
 			      u32 *proto_cap, int proto_mask);
 int mlx5_query_port_proto_admin(struct mlx5_core_dev *dev,

commit e760152d08da78aa160e68ac90bf8f3f10aff462
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Thu Jun 4 19:30:43 2015 +0300

    net/mlx5_core: Use port number in the query port mtu helpers
    
    Extend the function prototypes for max and operational mtu to take the
    local port number. In the Ethernet driver is this hard coded to one,
    since ConnectX4 Ethernet devices are always function-per-port.
    The IB driver also serves older devices (ConnectIB) which isn't such,
    and hence the part can vary.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b90fb9336d21..cd09784b6999 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -751,8 +751,10 @@ int mlx5_set_port_status(struct mlx5_core_dev *dev,
 int mlx5_query_port_status(struct mlx5_core_dev *dev, u8 *status);
 
 int mlx5_set_port_mtu(struct mlx5_core_dev *dev, int mtu);
-int mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu);
-int mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu);
+int mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu,
+			    u8 local_port);
+int mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu,
+			     u8 local_port);
 
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);

commit 211e6c80e5a68ef39a81484583e8efbf9774627d
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Thu Jun 4 19:30:42 2015 +0300

    net/mlx5_core: Get vendor-id using the query adapter command
    
    Add two wrapper functions to the query adapter command:
    
    1. mlx5_query_board_id -- replaces the old mlx5_cmd_query_adapter.
    
    2. mlx5_core_query_vendor_id -- retrieves the vendor_id from the
       query_adapter command.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8ab8b8af5c32..b90fb9336d21 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -817,6 +817,7 @@ struct mlx5_interface {
 void *mlx5_get_protocol_dev(struct mlx5_core_dev *mdev, int protocol);
 int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
+int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 
 struct mlx5_profile {
 	u64	mask;

commit 707c4602cda6624940761b66a4119f1909492385
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Thu Jun 4 19:30:41 2015 +0300

    net/mlx5_core: Add new query HCA vport commands
    
    Added the implementation for the following commands:
    
    1. QUERY_HCA_VPORT_GID
    2. QUERY_HCA_VPORT_PKEY
    3. QUERY_HCA_VPORT_CONTEXT
    
    They will be needed when we move to work with ISSI > 0 in the IB driver too.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ba9f212c94bb..8ab8b8af5c32 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -553,6 +553,41 @@ struct mlx5_pas {
 	u8	log_sz;
 };
 
+enum port_state_policy {
+	MLX5_AAA_000
+};
+
+enum phy_port_state {
+	MLX5_AAA_111
+};
+
+struct mlx5_hca_vport_context {
+	u32			field_select;
+	bool			sm_virt_aware;
+	bool			has_smi;
+	bool			has_raw;
+	enum port_state_policy	policy;
+	enum phy_port_state	phys_state;
+	enum ib_port_state	vport_state;
+	u8			port_physical_state;
+	u64			sys_image_guid;
+	u64			port_guid;
+	u64			node_guid;
+	u32			cap_mask1;
+	u32			cap_mask1_perm;
+	u32			cap_mask2;
+	u32			cap_mask2_perm;
+	u16			lid;
+	u8			init_type_reply; /* bitmask: see ib spec 14.2.5.6 InitTypeReply */
+	u8			lmc;
+	u8			subnet_timeout;
+	u16			sm_lid;
+	u8			sm_sl;
+	u16			qkey_violation_counter;
+	u16			pkey_violation_counter;
+	bool			grh_required;
+};
+
 static inline void *mlx5_buf_offset(struct mlx5_buf *buf, int offset)
 {
 		return buf->direct.buf + offset;
@@ -792,4 +827,14 @@ struct mlx5_profile {
 	} mr_cache[MAX_MR_CACHE_ENTRIES];
 };
 
+static inline int mlx5_get_gid_table_len(u16 param)
+{
+	if (param > 4) {
+		pr_warn("gid table length is zero\n");
+		return 0;
+	}
+
+	return 8 * (1 << param);
+}
+
 #endif /* MLX5_DRIVER_H */

commit 01949d0109ee5fae33752f0db99a36f1619e1873
Author: Haggai Abramonvsky <hagaya@mellanox.com>
Date:   Thu Jun 4 19:30:38 2015 +0300

    net/mlx5_core: Enable XRCs and SRQs when using ISSI > 0
    
    When working in ISSI > 0 mode, the model exposed by the device for
    XRCs and SRQs is different. XRCs use XRC SRQs and plain SRQs are based
    on RPM (Receive Memory Pool).
    
    Add helper functions to create, modify, query, and arm XRC SRQs and RMPs.
    
    Signed-off-by: Haggai Abramovsky <hagaya@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7fa26f03acc1..ba9f212c94bb 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -339,6 +339,8 @@ struct mlx5_core_mr {
 
 enum mlx5_res_type {
 	MLX5_RES_QP,
+	MLX5_RES_SRQ,
+	MLX5_RES_XSRQ,
 };
 
 struct mlx5_core_rsc_common {
@@ -348,6 +350,7 @@ struct mlx5_core_rsc_common {
 };
 
 struct mlx5_core_srq {
+	struct mlx5_core_rsc_common	common; /* must be first */
 	u32		srqn;
 	int		max;
 	int		max_gs;
@@ -640,7 +643,8 @@ struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 				 struct mlx5_cmd_mailbox *head);
 int mlx5_core_create_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
-			 struct mlx5_create_srq_mbox_in *in, int inlen);
+			 struct mlx5_create_srq_mbox_in *in, int inlen,
+			 int is_xrc);
 int mlx5_core_destroy_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq);
 int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 			struct mlx5_query_srq_mbox_out *out);

commit a97e2d86a9b88ea9e9a280b594b80f0eec2c955b
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Sun May 31 17:15:30 2015 -0400

    IB/core cleanup: Add const on args - device->process_mad
    
    The process_mad device function declares some parameters as "in".  Make those
    parameters const and adjust the call tree under process_mad in the various
    drivers accordingly.
    
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Hal Rosenstock <hal@mellanox.com>
    Reviewed-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9a90e7523dc2..9ec7c93d6fa3 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -696,7 +696,7 @@ int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
 			     u32 *mkey);
 int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
 int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
-int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, void *inb, void *outb,
+int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, const void *inb, void *outb,
 		      u16 opmod, u8 port);
 void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);

commit f62b8bb8f2d30582f30f51e85a8c0e1260125d7e
Author: Amir Vadai <amirv@mellanox.com>
Date:   Thu May 28 22:28:48 2015 +0300

    net/mlx5: Extend mlx5_core to support ConnectX-4 Ethernet functionality
    
    This is the Ethernet part of the driver for the Mellanox ConnectX(R)-4
    Single/Dual-Port Adapter supporting 100Gb/s with VPI.  The driver
    extends the existing mlx5 driver with Ethernet functionality.
    
    This patch contains the driver entry points but does not include
    transmit and receive (see the previous patch in the series) routines.
    
    It also adds the option MLX5_CORE_EN to Kconfig to enable/disable the
    Ethernet functionality. Currently, Kconfig is programmed to make
    Ethernet and Infiniband functionality mutally exclusive.
    Also changed MLX5_INFINIBAND to be depandant on MLX5_CORE instead of
    selecting it, since MLX5_CORE could be selected without MLX5_INFINIBAND
    being selected.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 51738472657e..7fa26f03acc1 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -489,6 +489,7 @@ struct mlx5_core_dev {
 	struct mlx5_priv	priv;
 	struct mlx5_profile	*profile;
 	atomic_t		num_qps;
+	u32			issi;
 };
 
 struct mlx5_db {

commit e725440e75da8c4d617a31c4e38216acc55c24e3
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu May 28 22:28:45 2015 +0300

    net/mlx5_core: Set/Query port MTU commands
    
    Introduce set/Query low level functions to access MTU in hardware. To be
    used by the netdev.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6438444ab361..51738472657e 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -710,6 +710,10 @@ int mlx5_set_port_status(struct mlx5_core_dev *dev,
 			 enum mlx5_port_status status);
 int mlx5_query_port_status(struct mlx5_core_dev *dev, u8 *status);
 
+int mlx5_set_port_mtu(struct mlx5_core_dev *dev, int mtu);
+int mlx5_query_port_max_mtu(struct mlx5_core_dev *dev, int *max_mtu);
+int mlx5_query_port_oper_mtu(struct mlx5_core_dev *dev, int *oper_mtu);
+
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,

commit 4c916a798058c1acf5a980438416020932c24aca
Author: Rana Shahout <ranas@mellanox.com>
Date:   Thu May 28 22:28:43 2015 +0300

    net/mlx5_core: Implement get/set port status
    
    Implemet get/set port status low level functions to be exposed by the
    netdev.
    
    Signed-off-by: Rana Shahout <ranas@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 266d5498a270..6438444ab361 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -149,6 +149,11 @@ enum mlx5_dev_event {
 	MLX5_DEV_EVENT_CLIENT_REREG,
 };
 
+enum mlx5_port_status {
+	MLX5_PORT_UP        = 1 << 1,
+	MLX5_PORT_DOWN      = 1 << 2,
+};
+
 struct mlx5_uuar_info {
 	struct mlx5_uar	       *uars;
 	int			num_uars;
@@ -701,6 +706,9 @@ int mlx5_query_port_proto_admin(struct mlx5_core_dev *dev,
 				u32 *proto_admin, int proto_mask);
 int mlx5_set_port_proto(struct mlx5_core_dev *dev, u32 proto_admin,
 			int proto_mask);
+int mlx5_set_port_status(struct mlx5_core_dev *dev,
+			 enum mlx5_port_status status);
+int mlx5_query_port_status(struct mlx5_core_dev *dev, u8 *status);
 
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);

commit adb0c9545bce6f1b1d563e988e6ee5531861d449
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu May 28 22:28:42 2015 +0300

    net/mlx5_core: Implement access functions of ptys register fields
    
    Those registers will be used by the ethtool to set/get settings.
    
    Signed-off-by: Rana Shahout <ranas@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6b9199163633..266d5498a270 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -504,6 +504,11 @@ enum {
 	MLX5_COMP_EQ_SIZE = 1024,
 };
 
+enum {
+	MLX5_PTYS_IB = 1 << 0,
+	MLX5_PTYS_EN = 1 << 2,
+};
+
 struct mlx5_db_pgdir {
 	struct list_head	list;
 	DECLARE_BITMAP(bitmap, MLX5_DB_PER_PAGE);
@@ -686,7 +691,16 @@ void mlx5_qp_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
 			 int size_in, void *data_out, int size_out,
 			 u16 reg_num, int arg, int write);
+
 int mlx5_set_port_caps(struct mlx5_core_dev *dev, u8 port_num, u32 caps);
+int mlx5_query_port_ptys(struct mlx5_core_dev *dev, u32 *ptys,
+			 int ptys_size, int proto_mask);
+int mlx5_query_port_proto_cap(struct mlx5_core_dev *dev,
+			      u32 *proto_cap, int proto_mask);
+int mlx5_query_port_proto_admin(struct mlx5_core_dev *dev,
+				u32 *proto_admin, int proto_mask);
+int mlx5_set_port_proto(struct mlx5_core_dev *dev, u32 proto_admin,
+			int proto_mask);
 
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);

commit 938fe83c8dcbbf294d167e6163200a8540ae43c4
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu May 28 22:28:41 2015 +0300

    net/mlx5_core: New device capabilities handling
    
    - Query all supported types of dev caps on driver load.
    - Store the Cap data outbox per cap type into driver private data.
    - Introduce new Macros to access/dump stored caps (using the auto
      generated data types).
    - Obsolete SW representation of dev caps (no need for SW copy for each
      cap).
    - Modify IB driver to use new macros for checking caps.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 3fd4fdc1ba16..6b9199163633 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -268,55 +268,7 @@ struct mlx5_cmd {
 struct mlx5_port_caps {
 	int	gid_table_len;
 	int	pkey_table_len;
-};
-
-struct mlx5_general_caps {
-	u8	log_max_eq;
-	u8	log_max_cq;
-	u8	log_max_qp;
-	u8	log_max_mkey;
-	u8	log_max_pd;
-	u8	log_max_srq;
-	u8	log_max_mrw_sz;
-	u8	log_max_bsf_list_size;
-	u8	log_max_klm_list_size;
-	u32	max_cqes;
-	int	max_wqes;
-	u32	max_eqes;
-	u32	max_indirection;
-	int	max_sq_desc_sz;
-	int	max_rq_desc_sz;
-	int	max_dc_sq_desc_sz;
-	u64	flags;
-	u16	stat_rate_support;
-	int	log_max_msg;
-	int	num_ports;
-	u8	log_max_ra_res_qp;
-	u8	log_max_ra_req_qp;
-	int	max_srq_wqes;
-	int	bf_reg_size;
-	int	bf_regs_per_page;
-	struct mlx5_port_caps	port[MLX5_MAX_PORTS];
-	u8			ext_port_cap[MLX5_MAX_PORTS];
-	int	max_vf;
-	u32	reserved_lkey;
-	u8	local_ca_ack_delay;
-	u8	log_max_mcg;
-	u32	max_qp_mcg;
-	int	min_page_sz;
-	int	pd_cap;
-	u32	max_qp_counters;
-	u32	pkey_table_size;
-	u8	log_max_ra_req_dc;
-	u8	log_max_ra_res_dc;
-	u32	uar_sz;
-	u8	min_log_pg_sz;
-	u8	log_max_xrcd;
-	u16	log_uar_page_sz;
-};
-
-struct mlx5_caps {
-	struct mlx5_general_caps gen;
+	u8	ext_port_cap;
 };
 
 struct mlx5_cmd_mailbox {
@@ -521,7 +473,9 @@ struct mlx5_core_dev {
 	u8			rev_id;
 	char			board_id[MLX5_BOARD_ID_LEN];
 	struct mlx5_cmd		cmd;
-	struct mlx5_caps	caps;
+	struct mlx5_port_caps	port_caps[MLX5_MAX_PORTS];
+	u32 hca_caps_cur[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
+	u32 hca_caps_max[MLX5_CAP_NUM][MLX5_UN_SZ_DW(hca_cap_union)];
 	phys_addr_t		iseg_base;
 	struct mlx5_init_seg __iomem *iseg;
 	void			(*event) (struct mlx5_core_dev *dev,
@@ -651,8 +605,8 @@ void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
 int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
 int mlx5_cmd_status_to_err_v2(void *ptr);
-int mlx5_core_get_caps(struct mlx5_core_dev *dev, struct mlx5_caps *caps,
-		       u16 opmod);
+int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type,
+		       enum mlx5_cap_mode cap_mode);
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 		  int out_size);
 int mlx5_cmd_exec_cb(struct mlx5_core_dev *dev, void *in, int in_size,

commit e281682bf29438848daac11627216bceb1507b71
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu May 28 22:28:40 2015 +0300

    net/mlx5_core: HW data structs/types definitions cleanup
    
    mlx5_ifc.h was heavily modified here since it is now generated by a
    script from the device specification (PRM rev 0.25). This specification
    is backward compatible to existing hardware.
    
    Some structures/fields were added here in order to enable the Ethernet
    functionality of the driver.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9e8979502826..3fd4fdc1ba16 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -44,7 +44,6 @@
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
-#include <linux/mlx5/mlx5_ifc.h>
 
 enum {
 	MLX5_BOARD_ID_LEN = 64,
@@ -278,7 +277,6 @@ struct mlx5_general_caps {
 	u8	log_max_mkey;
 	u8	log_max_pd;
 	u8	log_max_srq;
-	u8	log_max_strq;
 	u8	log_max_mrw_sz;
 	u8	log_max_bsf_list_size;
 	u8	log_max_klm_list_size;
@@ -664,6 +662,8 @@ int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
 int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
 int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
 int mlx5_free_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
+int mlx5_alloc_map_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);
+void mlx5_unmap_free_uar(struct mlx5_core_dev *mdev, struct mlx5_uar *uar);
 void mlx5_health_cleanup(void);
 void  __init mlx5_health_init(void);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);

commit db058a186f98b057c19c42f7b10d9a96fd3b5d59
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu May 28 22:28:39 2015 +0300

    net/mlx5_core: Set irq affinity hints
    
    Preparation for upcoming ethernet driver.
    - Move msix array from eq_table struct to priv since its not related to
      eq_table
    - Intorduce irq_info struct to hold all irq information
    - Move name from mlx5_eq to irq_info struct since it is irq property.
    - Set IRQ affinity hints
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Rana Shahout <ranas@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c4cf25ffcc16..9e8979502826 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -85,7 +85,7 @@ enum {
 };
 
 enum {
-	MLX5_MAX_EQ_NAME	= 32
+	MLX5_MAX_IRQ_NAME	= 32
 };
 
 enum {
@@ -349,7 +349,6 @@ struct mlx5_eq {
 	u8			eqn;
 	int			nent;
 	u64			mask;
-	char			name[MLX5_MAX_EQ_NAME];
 	struct list_head	list;
 	int			index;
 	struct mlx5_rsc_debug	*dbg;
@@ -412,7 +411,6 @@ struct mlx5_eq_table {
 	struct mlx5_eq		pages_eq;
 	struct mlx5_eq		async_eq;
 	struct mlx5_eq		cmd_eq;
-	struct msix_entry	*msix_arr;
 	int			num_comp_vectors;
 	/* protect EQs list
 	 */
@@ -465,9 +463,16 @@ struct mlx5_mr_table {
 	struct radix_tree_root	tree;
 };
 
+struct mlx5_irq_info {
+	cpumask_var_t mask;
+	char name[MLX5_MAX_IRQ_NAME];
+};
+
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	eq_table;
+	struct msix_entry	*msix_arr;
+	struct mlx5_irq_info	*irq_info;
 	struct mlx5_uuar_info	uuari;
 	MLX5_DECLARE_DOORBELL_LOCK(cq_uar_lock);
 

commit 64ffaa2159b752e6c263dc57eaaaed7367d37493
Author: Amir Vadai <amirv@mellanox.com>
Date:   Thu May 28 22:28:38 2015 +0300

    net/mlx5_core,mlx5_ib: Do not use vmap() on coherent memory
    
    As David Daney pointed in mlx4_core driver [1], mlx5_core is also
    misusing the DMA-API.
    
    This patch is removing the code that vmap() memory allocated by
    dma_alloc_coherent().
    
    After this patch, users of this drivers might fail allocating resources
    on memory fragmeneted systems.  This will be fixed later on.
    
    [1] - https://patchwork.ozlabs.org/patch/458531/
    
    CC: David Daney <david.daney@cavium.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9a90e7523dc2..c4cf25ffcc16 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -334,8 +334,6 @@ struct mlx5_buf_list {
 
 struct mlx5_buf {
 	struct mlx5_buf_list	direct;
-	struct mlx5_buf_list   *page_list;
-	int			nbufs;
 	int			npages;
 	int			size;
 	u8			page_shift;
@@ -586,11 +584,7 @@ struct mlx5_pas {
 
 static inline void *mlx5_buf_offset(struct mlx5_buf *buf, int offset)
 {
-	if (likely(BITS_PER_LONG == 64 || buf->nbufs == 1))
 		return buf->direct.buf + offset;
-	else
-		return buf->page_list[offset >> PAGE_SHIFT].buf +
-			(offset & (PAGE_SIZE - 1));
 }
 
 extern struct workqueue_struct *mlx5_core_wq;
@@ -669,8 +663,7 @@ void mlx5_health_cleanup(void);
 void  __init mlx5_health_init(void);
 void mlx5_start_health_poll(struct mlx5_core_dev *dev);
 void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
-int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, int max_direct,
-		   struct mlx5_buf *buf);
+int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, struct mlx5_buf *buf);
 void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_buf *buf);
 struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
 						      gfp_t flags, int npages);

commit 64613d9499c4887485d4350387919ea507330d90
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Apr 2 17:07:34 2015 +0300

    net/mlx5_core: Extend struct mlx5_interface to support multiple protocols
    
    Preparation for ethernet driver.
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index f250f6580dad..9a90e7523dc2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -781,14 +781,22 @@ enum {
 	MAX_MR_CACHE_ENTRIES    = 16,
 };
 
+enum {
+	MLX5_INTERFACE_PROTOCOL_IB  = 0,
+	MLX5_INTERFACE_PROTOCOL_ETH = 1,
+};
+
 struct mlx5_interface {
 	void *			(*add)(struct mlx5_core_dev *dev);
 	void			(*remove)(struct mlx5_core_dev *dev, void *context);
 	void			(*event)(struct mlx5_core_dev *dev, void *context,
 					 enum mlx5_dev_event event, unsigned long param);
+	void *                  (*get_dev)(void *context);
+	int			protocol;
 	struct list_head	list;
 };
 
+void *mlx5_get_protocol_dev(struct mlx5_core_dev *mdev, int protocol);
 int mlx5_register_interface(struct mlx5_interface *intf);
 void mlx5_unregister_interface(struct mlx5_interface *intf);
 

commit 233d05d28ad942929b6b4fbc48aa8dd083c16484
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Apr 2 17:07:32 2015 +0300

    net/mlx5_core: Move completion eqs from mlx5_ib to mlx5_core
    
    Preparation for ethernet driver.
    These functions will be used in drivers other than mlx5_ib.
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8fedd39a9a60..f250f6580dad 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -410,7 +410,7 @@ struct mlx5_core_srq {
 struct mlx5_eq_table {
 	void __iomem	       *update_ci;
 	void __iomem	       *update_arm_ci;
-	struct list_head       *comp_eq_head;
+	struct list_head	comp_eqs_list;
 	struct mlx5_eq		pages_eq;
 	struct mlx5_eq		async_eq;
 	struct mlx5_eq		cmd_eq;
@@ -725,6 +725,7 @@ int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 int mlx5_start_eqs(struct mlx5_core_dev *dev);
 int mlx5_stop_eqs(struct mlx5_core_dev *dev);
+int mlx5_vector2eqn(struct mlx5_core_dev *dev, int vector, int *eqn, int *irqn);
 int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
 int mlx5_core_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
 

commit 302bdf68fc56a6330bc6b10ce435b4d466417537
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Apr 2 17:07:29 2015 +0300

    net/mlx5_core: Fix Mellanox copyright note
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8d8ca6d9b03b..8fedd39a9a60 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU

commit 64599cca51de08cef94bc13a0f98351e5bb01f41
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Thu Apr 2 17:07:25 2015 +0300

    net/mlx5_core: Use coherent memory for command interface page
    
    Use coherent memory for the commands descriptor page. Take measures to make
    sure the page is aligned to MLX5_ADAPTER_PAGE_SIZE as required by the hardware.
    
    Reported-by: Yevgeny Kliteynik <kliteyn@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 166d9315fe4b..8d8ca6d9b03b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -232,6 +232,9 @@ struct mlx5_cmd_stats {
 };
 
 struct mlx5_cmd {
+	void	       *cmd_alloc_buf;
+	dma_addr_t	alloc_dma;
+	int		alloc_size;
 	void	       *cmd_buf;
 	dma_addr_t	dma;
 	u16		cmdif_rev;

commit 6aec21f6a8322fa8d43df3ea7f051dfd8967f1b9
Author: Haggai Eran <haggaie@mellanox.com>
Date:   Thu Dec 11 17:04:23 2014 +0200

    IB/mlx5: Page faults handling infrastructure
    
    * Refactor MR registration and cleanup, and fix reg_pages accounting.
    * Create a work queue to handle page fault events in a kthread context.
    * Register a fault handler to get events from the core for each QP.
    
    The registered fault handler is empty in this patch, and only a later
    patch implements it.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Shachar Raindel <raindel@mellanox.com>
    Signed-off-by: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 7088dcd19214..166d9315fe4b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -474,7 +474,7 @@ struct mlx5_priv {
 	struct workqueue_struct *pg_wq;
 	struct rb_root		page_root;
 	int			fw_pages;
-	int			reg_pages;
+	atomic_t		reg_pages;
 	struct list_head	free_list;
 
 	struct mlx5_core_health health;

commit e420f0c0f3d1022789fcb59b2a0c4b979ce311ba
Author: Haggai Eran <haggaie@mellanox.com>
Date:   Thu Dec 11 17:04:19 2014 +0200

    mlx5_core: Add support for page faults events and low level handling
    
    * Add a handler function pointer in the mlx5_core_qp struct for page
      fault events. Handle page fault events by calling the handler
      function, if not NULL.
    * Add on-demand paging capability query command.
    * Export command for resuming QPs after page faults.
    * Add various constants related to paging support.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Shachar Raindel <raindel@mellanox.com>
    Signed-off-by: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b1bf41556b32..7088dcd19214 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -113,6 +113,13 @@ enum {
 	MLX5_REG_HOST_ENDIANNESS = 0x7004,
 };
 
+enum mlx5_page_fault_resume_flags {
+	MLX5_PAGE_FAULT_RESUME_REQUESTOR = 1 << 0,
+	MLX5_PAGE_FAULT_RESUME_WRITE	 = 1 << 1,
+	MLX5_PAGE_FAULT_RESUME_RDMA	 = 1 << 2,
+	MLX5_PAGE_FAULT_RESUME_ERROR	 = 1 << 7,
+};
+
 enum dbg_rsc_type {
 	MLX5_DBG_RSC_QP,
 	MLX5_DBG_RSC_EQ,
@@ -703,6 +710,9 @@ void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
 void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
 void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+void mlx5_eq_pagefault(struct mlx5_core_dev *dev, struct mlx5_eqe *eqe);
+#endif
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
 void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector);
@@ -740,6 +750,8 @@ int mlx5_core_create_psv(struct mlx5_core_dev *dev, u32 pdn,
 			 int npsvs, u32 *sig_index);
 int mlx5_core_destroy_psv(struct mlx5_core_dev *dev, int psv_num);
 void mlx5_core_put_rsc(struct mlx5_core_rsc_common *common);
+int mlx5_query_odp_caps(struct mlx5_core_dev *dev,
+			struct mlx5_odp_caps *odp_caps);
 
 static inline u32 mlx5_mkey_to_idx(u32 mkey)
 {

commit 479163f4608214d18bc3266ab6e4b578897a3052
Author: Al Viro <viro@ZenIV.linux.org.uk>
Date:   Thu Nov 20 08:13:57 2014 +0000

    mlx5: don't duplicate kvfree()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Acked-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 246310dc8bef..b1bf41556b32 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -633,14 +633,6 @@ static inline void *mlx5_vzalloc(unsigned long size)
 	return rtn;
 }
 
-static inline void mlx5_vfree(const void *addr)
-{
-	if (addr && is_vmalloc_addr(addr))
-		vfree(addr);
-	else
-		kfree(addr);
-}
-
 static inline u32 mlx5_base_mkey(const u32 key)
 {
 	return key & 0xffffff00u;

commit 5903325a64834211daf63a62db3b35ee580cb8bf
Author: Eli Cohen <eli@mellanox.com>
Date:   Thu Oct 2 12:19:45 2014 +0300

    net/mlx5_core: Identify resources by their type
    
    This patch puts a common part as the first field of mlx5_core_qp. This field is
    used to identify which resource generated an event. This is required since upcoming
    new resource types such as DC targets are allocated for the same numerical space
    as regular QPs and may generate the same events. By searching the resource in the
    same table we can then look at the common field to identify the resource.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index c439f9c59b93..246310dc8bef 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -375,6 +375,16 @@ struct mlx5_core_mr {
 	u32			pd;
 };
 
+enum mlx5_res_type {
+	MLX5_RES_QP,
+};
+
+struct mlx5_core_rsc_common {
+	enum mlx5_res_type	res;
+	atomic_t		refcount;
+	struct completion	free;
+};
+
 struct mlx5_core_srq {
 	u32		srqn;
 	int		max;
@@ -700,7 +710,7 @@ int mlx5_eq_init(struct mlx5_core_dev *dev);
 void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
 void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
 void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
-void mlx5_qp_event(struct mlx5_core_dev *dev, u32 qpn, int event_type);
+void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
 void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector);
@@ -737,6 +747,7 @@ void mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_core_create_psv(struct mlx5_core_dev *dev, u32 pdn,
 			 int npsvs, u32 *sig_index);
 int mlx5_core_destroy_psv(struct mlx5_core_dev *dev, int psv_num);
+void mlx5_core_put_rsc(struct mlx5_core_rsc_common *common);
 
 static inline u32 mlx5_mkey_to_idx(u32 mkey)
 {

commit b775516b042f9e35f856bd2914afefd9d23021d7
Author: Eli Cohen <eli@mellanox.com>
Date:   Thu Oct 2 12:19:44 2014 +0300

    net/mlx5_core: use set/get macros in device caps
    
    Transform device capabilities related commands to use set/get macros to
    manipulate command mailboxes.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6f48dc793b9f..c439f9c59b93 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -641,6 +641,7 @@ void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
 int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
+int mlx5_cmd_status_to_err_v2(void *ptr);
 int mlx5_core_get_caps(struct mlx5_core_dev *dev, struct mlx5_caps *caps,
 		       u16 opmod);
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,

commit d29b796adada8780db3512c4a34b339f9aeef1ae
Author: Eli Cohen <eli@mellanox.com>
Date:   Thu Oct 2 12:19:43 2014 +0300

    net/mlx5_core: Use hardware registers description header file
    
    Add an auto generated header file that describes hardware registers along with
    set of macros that set/get values. The macros do static checks to avoid
    overflow, handle endianess, and overall provide a clean way to code commands.
    Currently the header file is small and we will add structs as we make use of
    the macros.
    A few commands were removed from the commands enum since they are not supported
    currently and will be added when support is available.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 45a2add747e0..6f48dc793b9f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -44,6 +44,7 @@
 
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
+#include <linux/mlx5/mlx5_ifc.h>
 
 enum {
 	MLX5_BOARD_ID_LEN = 64,
@@ -98,81 +99,6 @@ enum {
 	MLX5_ATOMIC_MODE_256B		= 8 << 16,
 };
 
-enum {
-	MLX5_CMD_OP_QUERY_HCA_CAP		= 0x100,
-	MLX5_CMD_OP_QUERY_ADAPTER		= 0x101,
-	MLX5_CMD_OP_INIT_HCA			= 0x102,
-	MLX5_CMD_OP_TEARDOWN_HCA		= 0x103,
-	MLX5_CMD_OP_ENABLE_HCA			= 0x104,
-	MLX5_CMD_OP_DISABLE_HCA			= 0x105,
-	MLX5_CMD_OP_QUERY_PAGES			= 0x107,
-	MLX5_CMD_OP_MANAGE_PAGES		= 0x108,
-	MLX5_CMD_OP_SET_HCA_CAP			= 0x109,
-
-	MLX5_CMD_OP_CREATE_MKEY			= 0x200,
-	MLX5_CMD_OP_QUERY_MKEY			= 0x201,
-	MLX5_CMD_OP_DESTROY_MKEY		= 0x202,
-	MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS	= 0x203,
-
-	MLX5_CMD_OP_CREATE_EQ			= 0x301,
-	MLX5_CMD_OP_DESTROY_EQ			= 0x302,
-	MLX5_CMD_OP_QUERY_EQ			= 0x303,
-
-	MLX5_CMD_OP_CREATE_CQ			= 0x400,
-	MLX5_CMD_OP_DESTROY_CQ			= 0x401,
-	MLX5_CMD_OP_QUERY_CQ			= 0x402,
-	MLX5_CMD_OP_MODIFY_CQ			= 0x403,
-
-	MLX5_CMD_OP_CREATE_QP			= 0x500,
-	MLX5_CMD_OP_DESTROY_QP			= 0x501,
-	MLX5_CMD_OP_RST2INIT_QP			= 0x502,
-	MLX5_CMD_OP_INIT2RTR_QP			= 0x503,
-	MLX5_CMD_OP_RTR2RTS_QP			= 0x504,
-	MLX5_CMD_OP_RTS2RTS_QP			= 0x505,
-	MLX5_CMD_OP_SQERR2RTS_QP		= 0x506,
-	MLX5_CMD_OP_2ERR_QP			= 0x507,
-	MLX5_CMD_OP_RTS2SQD_QP			= 0x508,
-	MLX5_CMD_OP_SQD2RTS_QP			= 0x509,
-	MLX5_CMD_OP_2RST_QP			= 0x50a,
-	MLX5_CMD_OP_QUERY_QP			= 0x50b,
-	MLX5_CMD_OP_CONF_SQP			= 0x50c,
-	MLX5_CMD_OP_MAD_IFC			= 0x50d,
-	MLX5_CMD_OP_INIT2INIT_QP		= 0x50e,
-	MLX5_CMD_OP_SUSPEND_QP			= 0x50f,
-	MLX5_CMD_OP_UNSUSPEND_QP		= 0x510,
-	MLX5_CMD_OP_SQD2SQD_QP			= 0x511,
-	MLX5_CMD_OP_ALLOC_QP_COUNTER_SET	= 0x512,
-	MLX5_CMD_OP_DEALLOC_QP_COUNTER_SET	= 0x513,
-	MLX5_CMD_OP_QUERY_QP_COUNTER_SET	= 0x514,
-
-	MLX5_CMD_OP_CREATE_PSV			= 0x600,
-	MLX5_CMD_OP_DESTROY_PSV			= 0x601,
-	MLX5_CMD_OP_QUERY_PSV			= 0x602,
-	MLX5_CMD_OP_QUERY_SIG_RULE_TABLE	= 0x603,
-	MLX5_CMD_OP_QUERY_BLOCK_SIZE_TABLE	= 0x604,
-
-	MLX5_CMD_OP_CREATE_SRQ			= 0x700,
-	MLX5_CMD_OP_DESTROY_SRQ			= 0x701,
-	MLX5_CMD_OP_QUERY_SRQ			= 0x702,
-	MLX5_CMD_OP_ARM_RQ			= 0x703,
-	MLX5_CMD_OP_RESIZE_SRQ			= 0x704,
-
-	MLX5_CMD_OP_ALLOC_PD			= 0x800,
-	MLX5_CMD_OP_DEALLOC_PD			= 0x801,
-	MLX5_CMD_OP_ALLOC_UAR			= 0x802,
-	MLX5_CMD_OP_DEALLOC_UAR			= 0x803,
-
-	MLX5_CMD_OP_ATTACH_TO_MCG		= 0x806,
-	MLX5_CMD_OP_DETACH_FROM_MCG		= 0x807,
-
-
-	MLX5_CMD_OP_ALLOC_XRCD			= 0x80e,
-	MLX5_CMD_OP_DEALLOC_XRCD		= 0x80f,
-
-	MLX5_CMD_OP_ACCESS_REG			= 0x805,
-	MLX5_CMD_OP_MAX				= 0x810,
-};
-
 enum {
 	MLX5_REG_PCAP		 = 0x5001,
 	MLX5_REG_PMTU		 = 0x5003,

commit c7a08ac7ee68b9af0d5af99c7b34b574cac4d144
Author: Eli Cohen <eli@mellanox.com>
Date:   Thu Oct 2 12:19:42 2014 +0300

    net/mlx5_core: Update device capabilities handling
    
    Rearrange struct mlx5_caps so it has a "gen" field to represent the current
    capabilities configured for the device. Max capabilities can also be queried
    from the device. Also update capabilities struct to contain more fields as per
    the latest revision if firmware specification.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index b88e9b46d957..45a2add747e0 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -335,23 +335,30 @@ struct mlx5_port_caps {
 	int	pkey_table_len;
 };
 
-struct mlx5_caps {
+struct mlx5_general_caps {
 	u8	log_max_eq;
 	u8	log_max_cq;
 	u8	log_max_qp;
 	u8	log_max_mkey;
 	u8	log_max_pd;
 	u8	log_max_srq;
+	u8	log_max_strq;
+	u8	log_max_mrw_sz;
+	u8	log_max_bsf_list_size;
+	u8	log_max_klm_list_size;
 	u32	max_cqes;
 	int	max_wqes;
+	u32	max_eqes;
+	u32	max_indirection;
 	int	max_sq_desc_sz;
 	int	max_rq_desc_sz;
+	int	max_dc_sq_desc_sz;
 	u64	flags;
 	u16	stat_rate_support;
 	int	log_max_msg;
 	int	num_ports;
-	int	max_ra_res_qp;
-	int	max_ra_req_qp;
+	u8	log_max_ra_res_qp;
+	u8	log_max_ra_req_qp;
 	int	max_srq_wqes;
 	int	bf_reg_size;
 	int	bf_regs_per_page;
@@ -363,6 +370,19 @@ struct mlx5_caps {
 	u8	log_max_mcg;
 	u32	max_qp_mcg;
 	int	min_page_sz;
+	int	pd_cap;
+	u32	max_qp_counters;
+	u32	pkey_table_size;
+	u8	log_max_ra_req_dc;
+	u8	log_max_ra_res_dc;
+	u32	uar_sz;
+	u8	min_log_pg_sz;
+	u8	log_max_xrcd;
+	u16	log_uar_page_sz;
+};
+
+struct mlx5_caps {
+	struct mlx5_general_caps gen;
 };
 
 struct mlx5_cmd_mailbox {
@@ -695,6 +715,8 @@ void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
 int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
+int mlx5_core_get_caps(struct mlx5_core_dev *dev, struct mlx5_caps *caps,
+		       u16 opmod);
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 		  int out_size);
 int mlx5_cmd_exec_cb(struct mlx5_core_dev *dev, void *in, int in_size,

commit ae045e2455429c418a418a3376301a9e5753a0a8
Merge: f4f142ed4ef8 d247b6ab3ce6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 6 09:38:14 2014 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
     "Highlights:
    
       1) Steady transitioning of the BPF instructure to a generic spot so
          all kernel subsystems can make use of it, from Alexei Starovoitov.
    
       2) SFC driver supports busy polling, from Alexandre Rames.
    
       3) Take advantage of hash table in UDP multicast delivery, from David
          Held.
    
       4) Lighten locking, in particular by getting rid of the LRU lists, in
          inet frag handling.  From Florian Westphal.
    
       5) Add support for various RFC6458 control messages in SCTP, from
          Geir Ola Vaagland.
    
       6) Allow to filter bridge forwarding database dumps by device, from
          Jamal Hadi Salim.
    
       7) virtio-net also now supports busy polling, from Jason Wang.
    
       8) Some low level optimization tweaks in pktgen from Jesper Dangaard
          Brouer.
    
       9) Add support for ipv6 address generation modes, so that userland
          can have some input into the process.  From Jiri Pirko.
    
      10) Consolidate common TCP connection request code in ipv4 and ipv6,
          from Octavian Purdila.
    
      11) New ARP packet logger in netfilter, from Pablo Neira Ayuso.
    
      12) Generic resizable RCU hash table, with intial users in netlink and
          nftables.  From Thomas Graf.
    
      13) Maintain a name assignment type so that userspace can see where a
          network device name came from (enumerated by kernel, assigned
          explicitly by userspace, etc.) From Tom Gundersen.
    
      14) Automatic flow label generation on transmit in ipv6, from Tom
          Herbert.
    
      15) New packet timestamping facilities from Willem de Bruijn, meant to
          assist in measuring latencies going into/out-of the packet
          scheduler, latency from TCP data transmission to ACK, etc"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1536 commits)
      cxgb4 : Disable recursive mailbox commands when enabling vi
      net: reduce USB network driver config options.
      tg3: Modify tg3_tso_bug() to handle multiple TX rings
      amd-xgbe: Perform phy connect/disconnect at dev open/stop
      amd-xgbe: Use dma_set_mask_and_coherent to set DMA mask
      net: sun4i-emac: fix memory leak on bad packet
      sctp: fix possible seqlock seadlock in sctp_packet_transmit()
      Revert "net: phy: Set the driver when registering an MDIO bus device"
      cxgb4vf: Turn off SGE RX/TX Callback Timers and interrupts in PCI shutdown routine
      team: Simplify return path of team_newlink
      bridge: Update outdated comment on promiscuous mode
      net-timestamp: ACK timestamp for bytestreams
      net-timestamp: TCP timestamping
      net-timestamp: SCHED timestamp on entering packet scheduler
      net-timestamp: add key to disambiguate concurrent datagrams
      net-timestamp: move timestamp flags out of sk_flags
      net-timestamp: extend SCM_TIMESTAMPING ancillary data struct
      cxgb4i : Move stray CPL definitions to cxgb4 driver
      tcp: reduce spurious retransmits due to transient SACK reneging
      qlcnic: Initialize dcbnl_ops before register_netdev
      ...

commit 4d2f9bbb654b91a262638ac2c84dcb169d014aa6
Author: Jack Morgenstein <jackm@dev.mellanox.co.il>
Date:   Mon Jul 28 23:30:24 2014 +0300

    mlx5: Adjust events to use unsigned long param instead of void *
    
    In the event flow, we currently pass only a port number in the
    void *data argument.  Rather than pass a pointer to the event handlers,
    we should use an "unsigned long" parameter, and pass the port number
    value directly.
    
    In the future, if necessary for some events, we can use the unsigned long
    parameter to pass a pointer.
    
    Based on a patch by Eli Cohen <eli@mellanox.com>
    
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 76de0cc41640..9f3a5476bb71 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -559,7 +559,7 @@ struct mlx5_core_dev {
 	struct mlx5_init_seg __iomem *iseg;
 	void			(*event) (struct mlx5_core_dev *dev,
 					  enum mlx5_dev_event event,
-					  void *data);
+					  unsigned long param);
 	struct mlx5_priv	priv;
 	struct mlx5_profile	*profile;
 	atomic_t		num_qps;
@@ -817,7 +817,7 @@ struct mlx5_interface {
 	void *			(*add)(struct mlx5_core_dev *dev);
 	void			(*remove)(struct mlx5_core_dev *dev, void *context);
 	void			(*event)(struct mlx5_core_dev *dev, void *context,
-					 enum mlx5_dev_event event, void *data);
+					 enum mlx5_dev_event event, unsigned long param);
 	struct list_head	list;
 };
 

commit f241e7497ec2d22b83002b17ae91a851d4034cb7
Author: Jack Morgenstein <jackm@dev.mellanox.co.il>
Date:   Mon Jul 28 23:30:23 2014 +0300

    mlx5: minor fixes (mainly avoidance of hidden casts)
    
    There were many places where parameters which should be u8/u16 were
    integer type.
    
    Additionally, in 2 places, a check for a non-null pointer was added
    before dereferencing the pointer (this is actually a bug fix).
    
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index d0cb5984a45f..76de0cc41640 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -381,8 +381,8 @@ struct mlx5_buf {
 	struct mlx5_buf_list   *page_list;
 	int			nbufs;
 	int			npages;
-	int			page_shift;
 	int			size;
+	u8			page_shift;
 };
 
 struct mlx5_eq {
@@ -736,7 +736,7 @@ int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
 int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
 int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
 int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, void *inb, void *outb,
-		      u16 opmod, int port);
+		      u16 opmod, u8 port);
 void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
 int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
@@ -769,7 +769,7 @@ void mlx5_qp_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
 			 int size_in, void *data_out, int size_out,
 			 u16 reg_num, int arg, int write);
-int mlx5_set_port_caps(struct mlx5_core_dev *dev, int port_num, u32 caps);
+int mlx5_set_port_caps(struct mlx5_core_dev *dev, u8 port_num, u32 caps);
 
 int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
@@ -826,7 +826,7 @@ void mlx5_unregister_interface(struct mlx5_interface *intf);
 
 struct mlx5_profile {
 	u64	mask;
-	u32	log_max_qp;
+	u8	log_max_qp;
 	struct {
 		int	size;
 		int	limit;

commit 9603b61de1eee92977d74ff42541be20c0c5b1a7
Author: Jack Morgenstein <jackm@dev.mellanox.co.il>
Date:   Mon Jul 28 23:30:22 2014 +0300

    mlx5: Move pci device handling from mlx5_ib to mlx5_core
    
    In preparation for a new mlx5 device which is VPI (i.e., ports can be
    either IB or ETH), move the pci device functionality from mlx5_ib
    to mlx5_core.
    
    This involves the following changes:
    1. Move mlx5_core_dev struct out of mlx5_ib_dev. mlx5_core_dev
       is now an independent structure maintained by mlx5_core.
       mlx5_ib_dev now has a pointer to that struct.
       This requires changing a lot of places where the core_dev
       struct was accessed via mlx5_ib_dev (now, this needs to
       be a pointer dereference).
    2. All PCI initializations are now done in mlx5_core. Thus,
       it is now mlx5_core which does pci_register_device (and not
       mlx5_ib, as was previously).
    3. mlx5_ib now registers itself with mlx5_core as an "interface"
       driver. This is very similar to the mechanism employed for
       the mlx4 (ConnectX) driver. Once the HCA is initialized
       (by mlx5_core), it invokes the interface drivers to do
       their initializations.
    4. There is a new event handler which the core registers:
       mlx5_core_event(). This event handler invokes the
       event handlers registered by the interfaces.
    
    Based on a patch by Eli Cohen <eli@mellanox.com>
    
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2bce4aad2570..d0cb5984a45f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -543,6 +543,10 @@ struct mlx5_priv {
 	/* protect mkey key part */
 	spinlock_t		mkey_lock;
 	u8			mkey_key;
+
+	struct list_head        dev_list;
+	struct list_head        ctx_list;
+	spinlock_t              ctx_lock;
 };
 
 struct mlx5_core_dev {
@@ -686,8 +690,6 @@ static inline u32 mlx5_base_mkey(const u32 key)
 	return key & 0xffffff00u;
 }
 
-int mlx5_dev_init(struct mlx5_core_dev *dev, struct pci_dev *pdev);
-void mlx5_dev_cleanup(struct mlx5_core_dev *dev);
 int mlx5_cmd_init(struct mlx5_core_dev *dev);
 void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
 void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
@@ -811,6 +813,17 @@ enum {
 	MAX_MR_CACHE_ENTRIES    = 16,
 };
 
+struct mlx5_interface {
+	void *			(*add)(struct mlx5_core_dev *dev);
+	void			(*remove)(struct mlx5_core_dev *dev, void *context);
+	void			(*event)(struct mlx5_core_dev *dev, void *context,
+					 enum mlx5_dev_event event, void *data);
+	struct list_head	list;
+};
+
+int mlx5_register_interface(struct mlx5_interface *intf);
+void mlx5_unregister_interface(struct mlx5_interface *intf);
+
 struct mlx5_profile {
 	u64	mask;
 	u32	log_max_qp;

commit 14a7004671246d1b799f545335995a9897de1268
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:04:44 2014 +0000

    net: mlx5: Use ktime_get_ns()
    
    This code is beyond silly:
    
         struct timespec ts = ktime_get_ts();
         ktime_t ktime = timespec_to_ktime(ts);
    
    Further down the code builds the delta of two ktime_t values and
    converts the result to nanoseconds.
    
    Use ktime_get_ns() and replace all the nonsense.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Eli Cohen <eli@mellanox.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2bce4aad2570..52d631ca32cf 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -604,8 +604,8 @@ struct mlx5_cmd_work_ent {
 	int			page_queue;
 	u8			status;
 	u8			token;
-	struct timespec		ts1;
-	struct timespec		ts2;
+	u64			ts1;
+	u64			ts2;
 	u16			op;
 };
 

commit b475598aec63f2efbc78f0ff1895d917d2370846
Author: Haggai Eran <haggaie@mellanox.com>
Date:   Thu May 22 14:50:10 2014 +0300

    mlx5_core: Store MR attributes in mlx5_mr_core during creation and after UMR
    
    The patch stores iova, pd and size during mr creation and after UMRs
    that modify them.  It removes the unused access flags field.
    
    Signed-off-by: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 93cef6313e72..2bce4aad2570 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -427,7 +427,6 @@ struct mlx5_core_mr {
 	u64			size;
 	u32			key;
 	u32			pd;
-	u32			access;
 };
 
 struct mlx5_core_srq {

commit d5436ba01075ef4629015f7a00914d64ffd795d6
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Sun Feb 23 14:19:12 2014 +0200

    IB/mlx5: Collect signature error completion
    
    This commit takes care of the generated signature error CQE generated
    by the HW (if happened).  The underlying mlx5 driver will handle
    signature error completions and will mark the relevant memory region
    as dirty.
    
    Once the consumer gets the completion for the transaction, it must
    check for signature errors on signature memory region using a new
    lightweight verb ib_check_mr_status().
    
    In case the user doesn't check for signature error (i.e. doesn't call
    ib_check_mr_status() with status check IB_MR_CHECK_SIG_STATUS), the
    memory region cannot be used for another signature operation
    (REG_SIG_MR work request will fail).
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index e562e01e59c7..93cef6313e72 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -416,6 +416,10 @@ struct mlx5_core_psv {
 struct mlx5_core_sig_ctx {
 	struct mlx5_core_psv	psv_memory;
 	struct mlx5_core_psv	psv_wire;
+	struct ib_sig_err       err_item;
+	bool			sig_status_checked;
+	bool			sig_err_exists;
+	u32			sigerr_count;
 };
 
 struct mlx5_core_mr {

commit 3bcdb17a5e88288ead90be3c107e754a6075a5b0
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Sun Feb 23 14:19:10 2014 +0200

    IB/mlx5: Keep mlx5 MRs in a radix tree under device
    
    This will be useful when processing signature errors on a specific
    key.  The mlx5 driver will lookup the matching mlx5 memory region
    structure and mark it as dirty (contains signature errors).
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index e1cb657ccade..e562e01e59c7 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -491,6 +491,13 @@ struct mlx5_srq_table {
 	struct radix_tree_root	tree;
 };
 
+struct mlx5_mr_table {
+	/* protect radix tree
+	 */
+	rwlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
 struct mlx5_priv {
 	char			name[MLX5_MAX_NAME_LEN];
 	struct mlx5_eq_table	eq_table;
@@ -520,6 +527,10 @@ struct mlx5_priv {
 	struct mlx5_cq_table	cq_table;
 	/* end: cq staff */
 
+	/* start: mr staff */
+	struct mlx5_mr_table	mr_table;
+	/* end: mr staff */
+
 	/* start: alloc staff */
 	struct mutex            pgdir_mutex;
 	struct list_head        pgdir_list;
@@ -667,6 +678,11 @@ static inline void mlx5_vfree(const void *addr)
 		kfree(addr);
 }
 
+static inline u32 mlx5_base_mkey(const u32 key)
+{
+	return key & 0xffffff00u;
+}
+
 int mlx5_dev_init(struct mlx5_core_dev *dev, struct pci_dev *pdev);
 void mlx5_dev_cleanup(struct mlx5_core_dev *dev);
 int mlx5_cmd_init(struct mlx5_core_dev *dev);
@@ -701,6 +717,8 @@ int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 			struct mlx5_query_srq_mbox_out *out);
 int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 		      u16 lwm, int is_srq);
+void mlx5_init_mr_table(struct mlx5_core_dev *dev);
+void mlx5_cleanup_mr_table(struct mlx5_core_dev *dev);
 int mlx5_core_create_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
 			  struct mlx5_create_mkey_mbox_in *in, int inlen,
 			  mlx5_cmd_cbk_t callback, void *context,

commit 3121e3c441b5eccdd15e6c320ec32215b334b9ec
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Sun Feb 23 14:19:06 2014 +0200

    mlx5: Implement create_mr and destroy_mr
    
    Support create_mr and destroy_mr verbs.  Creating ib_mr may be done
    for either ib_mr that will register regular page lists like
    alloc_fast_reg_mr routine, or indirect ib_mrs that can register other
    (pre-registered) ib_mrs in an indirect manner.
    
    In addition user may request signature enable, that will mean that the
    created ib_mr may be attached with signature attributes (BSF, PSVs).
    
    Currently we only allow direct/indirect registration modes.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 130bc8d77fa5..e1cb657ccade 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -401,6 +401,22 @@ struct mlx5_eq {
 	struct mlx5_rsc_debug	*dbg;
 };
 
+struct mlx5_core_psv {
+	u32	psv_idx;
+	struct psv_layout {
+		u32	pd;
+		u16	syndrome;
+		u16	reserved;
+		u16	bg;
+		u16	app_tag;
+		u32	ref_tag;
+	} psv;
+};
+
+struct mlx5_core_sig_ctx {
+	struct mlx5_core_psv	psv_memory;
+	struct mlx5_core_psv	psv_wire;
+};
 
 struct mlx5_core_mr {
 	u64			iova;
@@ -746,6 +762,9 @@ void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);
 const char *mlx5_command_str(int command);
 int mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev);
 void mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev);
+int mlx5_core_create_psv(struct mlx5_core_dev *dev, u32 pdn,
+			 int npsvs, u32 *sig_index);
+int mlx5_core_destroy_psv(struct mlx5_core_dev *dev, int psv_num);
 
 static inline u32 mlx5_mkey_to_idx(u32 mkey)
 {

commit 6ecde51dd7894ffe2f959cca1fea3ea2b9ee2394
Author: Roland Dreier <roland@purestorage.com>
Date:   Thu Feb 13 20:45:17 2014 -0800

    mlx5: Add include of <linux/slab.h> because of kzalloc()/kfree() use
    
    On some architectures (for example, arm), we don't end up indirectly
    pulling in the declaration of kzalloc() and kfree(), and so building
    anything that includes <linux/mlx5/driver.h> breaks.  Fix this by adding
    an explicit include to get the declaration.
    
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 32cb18c399c2..130bc8d77fa5 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -38,8 +38,10 @@
 #include <linux/pci.h>
 #include <linux/spinlock_types.h>
 #include <linux/semaphore.h>
+#include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/radix-tree.h>
+
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
 

commit 78c0f98cc9dd46824fa66f35f14ea24ba733d145
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Thu Jan 30 13:49:48 2014 +0200

    IB/mlx5: Fix binary compatibility with libmlx5
    
    Commit c1be5232d21d ("Fix micro UAR allocator") broke binary compatibility
    between libmlx5 and mlx5_ib since it defines a different value to the number
    of micro UARs per page, leading to wrong calculation in libmlx5. This patch
    defines struct mlx5_ib_alloc_ucontext_req_v2 as an extension to struct
    mlx5_ib_alloc_ucontext_req.  The extended size is determined in mlx5_ib_alloc_ucontext()
    and in case of old library we use uuarn 0 which works fine -- this is
    acheived due to create_user_qp() falling back from high to medium then to
    low class where low class will return 0.  For new libraries we use the
    more sophisticated allocation algorithm.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Reviewed-by: Yann Droneaud <ydroneaud@opteya.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 554548cd3dd4..32cb18c399c2 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -227,6 +227,7 @@ struct mlx5_uuar_info {
 	 * protect uuar allocation data structs
 	 */
 	struct mutex		lock;
+	u32			ver;
 };
 
 struct mlx5_bf {

commit bf0bf77f6519e5dcd57a77b47e1d151c1e81b7ec
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Oct 23 09:53:19 2013 +0300

    mlx5: Support communicating arbitrary host page size to firmware
    
    Connect-IB firmware requires 4K pages to be communicated with the
    driver. This patch breaks larger pages to 4K units to enable support
    for architectures utilizing larger page size, such as PowerPC.  This
    patch also fixes several places that referred to PAGE_SHIFT instead of
    explicit 12 which is the inherent page shift on Connect-IB.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 513619a75695..554548cd3dd4 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -483,6 +483,7 @@ struct mlx5_priv {
 	struct rb_root		page_root;
 	int			fw_pages;
 	int			reg_pages;
+	struct list_head	free_list;
 
 	struct mlx5_core_health health;
 

commit 746b5583c1a48a837f4891adaff5e09d61b204a6
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Oct 23 09:53:14 2013 +0300

    IB/mlx5: Multithreaded create MR
    
    Use asynchronous commands to execute up to eight concurrent create MR
    commands. This is to fill memory caches faster so we keep consuming
    from there.  Also, increase timeout for shrinking caches to five
    minutes.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 6b8c496572c8..513619a75695 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -557,9 +557,11 @@ typedef void (*mlx5_cmd_cbk_t)(int status, void *context);
 struct mlx5_cmd_work_ent {
 	struct mlx5_cmd_msg    *in;
 	struct mlx5_cmd_msg    *out;
+	void		       *uout;
+	int			uout_size;
 	mlx5_cmd_cbk_t		callback;
 	void		       *context;
-	int idx;
+	int			idx;
 	struct completion	done;
 	struct mlx5_cmd        *cmd;
 	struct work_struct	work;
@@ -570,6 +572,7 @@ struct mlx5_cmd_work_ent {
 	u8			token;
 	struct timespec		ts1;
 	struct timespec		ts2;
+	u16			op;
 };
 
 struct mlx5_pas {
@@ -653,6 +656,9 @@ void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
 int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
 int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
 		  int out_size);
+int mlx5_cmd_exec_cb(struct mlx5_core_dev *dev, void *in, int in_size,
+		     void *out, int out_size, mlx5_cmd_cbk_t callback,
+		     void *context);
 int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
 int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
 int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
@@ -676,7 +682,9 @@ int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
 		      u16 lwm, int is_srq);
 int mlx5_core_create_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
-			  struct mlx5_create_mkey_mbox_in *in, int inlen);
+			  struct mlx5_create_mkey_mbox_in *in, int inlen,
+			  mlx5_cmd_cbk_t callback, void *context,
+			  struct mlx5_create_mkey_mbox_out *out);
 int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr);
 int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
 			 struct mlx5_query_mkey_mbox_out *out, int outlen);
@@ -745,6 +753,11 @@ static inline u32 mlx5_idx_to_mkey(u32 mkey_idx)
 	return mkey_idx << 8;
 }
 
+static inline u8 mlx5_mkey_variant(u32 mkey)
+{
+	return mkey & 0xff;
+}
+
 enum {
 	MLX5_PROF_MASK_QP_SIZE		= (u64)1 << 0,
 	MLX5_PROF_MASK_MR_CACHE		= (u64)1 << 1,

commit ada9f5d007971a71d619e2abf66ebd3a9a399413
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Wed Sep 11 16:35:34 2013 +0300

    IB/mlx5: Fix eq names to display nicely in /proc/interrupts
    
    It's helpful for a driver to put the pci slot name in its interrupt
    names, so /proc/interrupts will show the pci slot of the device.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2cfc4309d45f..6b8c496572c8 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -82,7 +82,7 @@ enum {
 };
 
 enum {
-	MLX5_MAX_EQ_NAME	= 20
+	MLX5_MAX_EQ_NAME	= 32
 };
 
 enum {

commit c1868b822515313c72445e70b7d9e47d8815bc52
Author: Eli Cohen <eli@mellanox.com>
Date:   Wed Sep 11 16:35:25 2013 +0300

    mlx5: Remove checksum on command interface commands
    
    Checksum calculations consume CPU resources and can be significant to
    the rate of resource creation/destruction.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 8888381fc150..2cfc4309d45f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -747,8 +747,7 @@ static inline u32 mlx5_idx_to_mkey(u32 mkey_idx)
 
 enum {
 	MLX5_PROF_MASK_QP_SIZE		= (u64)1 << 0,
-	MLX5_PROF_MASK_CMDIF_CSUM	= (u64)1 << 1,
-	MLX5_PROF_MASK_MR_CACHE		= (u64)1 << 2,
+	MLX5_PROF_MASK_MR_CACHE		= (u64)1 << 1,
 };
 
 enum {
@@ -758,7 +757,6 @@ enum {
 struct mlx5_profile {
 	u64	mask;
 	u32	log_max_qp;
-	int	cmdif_csum;
 	struct {
 		int	size;
 		int	limit;

commit 0a324f3189ed9c78b1aaf48d88e93cb18643c655
Author: Moshe Lazer <moshel@mellanox.com>
Date:   Wed Aug 14 17:46:48 2013 +0300

    net/mlx5_core: Support MANAGE_PAGES and QUERY_PAGES firmware command changes
    
    In the previous QUERY_PAGES command version we used one command to get the
    required amount of boot, init and post init pages.  The new version uses the
    op_mod field to specify whether the query is for the required amount of boot,
    init or post init pages. In addition the output field size for the required
    amount of pages increased from 16 to 32 bits.
    
    In MANAGE_PAGES command the input_num_entries and output_num_entries fields
    sizes changed from 16 to 32 bits and the PAS tables offset changed to 0x10.
    
    In the pages request event the num_pages field also changed to 32 bits.
    
    In the HCA-capabilities-layout the size and location of max_qp_mcg field has
    been changed to support 24 bits.
    
    This patch isn't compatible with firmware versions < 5; however, it  turns out that the
    first GA firmware we will publish will not support previous versions so this should be OK.
    
    Signed-off-by: Moshe Lazer <moshel@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 611e65e76b00..8888381fc150 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -358,7 +358,7 @@ struct mlx5_caps {
 	u32	reserved_lkey;
 	u8	local_ca_ack_delay;
 	u8	log_max_mcg;
-	u16	max_qp_mcg;
+	u32	max_qp_mcg;
 	int	min_page_sz;
 };
 
@@ -691,7 +691,7 @@ void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
 int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
 void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
-				 s16 npages);
+				 s32 npages);
 int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);
 int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);
 void mlx5_register_debugfs(void);

commit 7d46daba8dd5df1aa45724518a041ef7163d3ad5
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Mon Aug 5 16:05:32 2013 +0300

    mlx5: remove health handler plugin
    
    Remove this code, per Dave Miller's request, since it is not being used
    anywhere in the kernel.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2aa258b0ced1..611e65e76b00 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -731,9 +731,6 @@ void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db);
 void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);
 
-typedef void (*health_handler_t)(struct pci_dev *pdev, struct health_buffer __iomem *buf, int size);
-int mlx5_register_health_report_handler(health_handler_t handler);
-void mlx5_unregister_health_report_handler(void);
 const char *mlx5_command_str(int command);
 int mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev);
 void mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev);

commit cd23b14b654769db83c9684ae1ba32c0e066670f
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Thu Jul 18 15:31:08 2013 +0300

    mlx5_core: Implement new initialization sequence
    
    Introduce enbale_hca and disable_hca commands to signify when the
    driver starts or ceases to operate on the device.
    
    In addition the driver will use boot and init pages count; boot pages
    is required to allow firmware to complete boot commands and the other
    to complete init hca.  Command interface revision is bumped to 4 to
    enforce using supported firmware.
    
    This patch breaks compatibility with old versions of firmware (< 4);
    however, the first GA firmware we will publish will support version 4
    so this should not be a problem.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index f22e4419839b..2aa258b0ced1 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -101,6 +101,8 @@ enum {
 	MLX5_CMD_OP_QUERY_ADAPTER		= 0x101,
 	MLX5_CMD_OP_INIT_HCA			= 0x102,
 	MLX5_CMD_OP_TEARDOWN_HCA		= 0x103,
+	MLX5_CMD_OP_ENABLE_HCA			= 0x104,
+	MLX5_CMD_OP_DISABLE_HCA			= 0x105,
 	MLX5_CMD_OP_QUERY_PAGES			= 0x107,
 	MLX5_CMD_OP_MANAGE_PAGES		= 0x108,
 	MLX5_CMD_OP_SET_HCA_CAP			= 0x109,
@@ -690,7 +692,7 @@ int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
 void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
 				 s16 npages);
-int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev);
+int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);
 int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);
 void mlx5_register_debugfs(void);
 void mlx5_unregister_debugfs(void);

commit 63884c90ffa3f73a81b81f169c51c34d2b9cf75e
Author: Roland Dreier <roland@purestorage.com>
Date:   Mon Jul 1 14:15:17 2013 -0700

    mlx5: Fix parameter type of health_handler_t
    
    This deals with the sparse warning:
    
        drivers/net/ethernet/mellanox/mlx5/core/health.c:94:54: warning: incorrect type in argument 2 (different address spaces)
        drivers/net/ethernet/mellanox/mlx5/core/health.c:94:54:    expected void *buf
        drivers/net/ethernet/mellanox/mlx5/core/health.c:94:54:    got struct health_buffer [noderef] <asn:2>*health
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index e47f1e4c9b03..f22e4419839b 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -729,7 +729,7 @@ void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);
 int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db);
 void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);
 
-typedef void (*health_handler_t)(struct pci_dev *pdev, void *buf, int size);
+typedef void (*health_handler_t)(struct pci_dev *pdev, struct health_buffer __iomem *buf, int size);
 int mlx5_register_health_report_handler(health_handler_t handler);
 void mlx5_unregister_health_report_handler(void);
 const char *mlx5_command_str(int command);

commit e126ba97dba9edeb6fafa3665b5f8497fc9cdf8c
Author: Eli Cohen <eli@mellanox.com>
Date:   Sun Jul 7 17:25:49 2013 +0300

    mlx5: Add driver for Mellanox Connect-IB adapters
    
    The driver is comprised of two kernel modules: mlx5_ib and mlx5_core.
    This partitioning resembles what we have for mlx4, except that mlx5_ib
    is the pci device driver and not mlx5_core.
    
    mlx5_core is essentially a library that provides general functionality
    that is intended to be used by other Mellanox devices that will be
    introduced in the future.  mlx5_ib has a similar role as any hardware
    device under drivers/infiniband/hw.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    
    [ Merge in coccinelle fixes from Fengguang Wu <fengguang.wu@intel.com>.
      - Roland ]
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
new file mode 100644
index 000000000000..e47f1e4c9b03
--- /dev/null
+++ b/include/linux/mlx5/driver.h
@@ -0,0 +1,769 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_DRIVER_H
+#define MLX5_DRIVER_H
+
+#include <linux/kernel.h>
+#include <linux/completion.h>
+#include <linux/pci.h>
+#include <linux/spinlock_types.h>
+#include <linux/semaphore.h>
+#include <linux/vmalloc.h>
+#include <linux/radix-tree.h>
+#include <linux/mlx5/device.h>
+#include <linux/mlx5/doorbell.h>
+
+enum {
+	MLX5_BOARD_ID_LEN = 64,
+	MLX5_MAX_NAME_LEN = 16,
+};
+
+enum {
+	/* one minute for the sake of bringup. Generally, commands must always
+	 * complete and we may need to increase this timeout value
+	 */
+	MLX5_CMD_TIMEOUT_MSEC	= 7200 * 1000,
+	MLX5_CMD_WQ_MAX_NAME	= 32,
+};
+
+enum {
+	CMD_OWNER_SW		= 0x0,
+	CMD_OWNER_HW		= 0x1,
+	CMD_STATUS_SUCCESS	= 0,
+};
+
+enum mlx5_sqp_t {
+	MLX5_SQP_SMI		= 0,
+	MLX5_SQP_GSI		= 1,
+	MLX5_SQP_IEEE_1588	= 2,
+	MLX5_SQP_SNIFFER	= 3,
+	MLX5_SQP_SYNC_UMR	= 4,
+};
+
+enum {
+	MLX5_MAX_PORTS	= 2,
+};
+
+enum {
+	MLX5_EQ_VEC_PAGES	 = 0,
+	MLX5_EQ_VEC_CMD		 = 1,
+	MLX5_EQ_VEC_ASYNC	 = 2,
+	MLX5_EQ_VEC_COMP_BASE,
+};
+
+enum {
+	MLX5_MAX_EQ_NAME	= 20
+};
+
+enum {
+	MLX5_ATOMIC_MODE_IB_COMP	= 1 << 16,
+	MLX5_ATOMIC_MODE_CX		= 2 << 16,
+	MLX5_ATOMIC_MODE_8B		= 3 << 16,
+	MLX5_ATOMIC_MODE_16B		= 4 << 16,
+	MLX5_ATOMIC_MODE_32B		= 5 << 16,
+	MLX5_ATOMIC_MODE_64B		= 6 << 16,
+	MLX5_ATOMIC_MODE_128B		= 7 << 16,
+	MLX5_ATOMIC_MODE_256B		= 8 << 16,
+};
+
+enum {
+	MLX5_CMD_OP_QUERY_HCA_CAP		= 0x100,
+	MLX5_CMD_OP_QUERY_ADAPTER		= 0x101,
+	MLX5_CMD_OP_INIT_HCA			= 0x102,
+	MLX5_CMD_OP_TEARDOWN_HCA		= 0x103,
+	MLX5_CMD_OP_QUERY_PAGES			= 0x107,
+	MLX5_CMD_OP_MANAGE_PAGES		= 0x108,
+	MLX5_CMD_OP_SET_HCA_CAP			= 0x109,
+
+	MLX5_CMD_OP_CREATE_MKEY			= 0x200,
+	MLX5_CMD_OP_QUERY_MKEY			= 0x201,
+	MLX5_CMD_OP_DESTROY_MKEY		= 0x202,
+	MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS	= 0x203,
+
+	MLX5_CMD_OP_CREATE_EQ			= 0x301,
+	MLX5_CMD_OP_DESTROY_EQ			= 0x302,
+	MLX5_CMD_OP_QUERY_EQ			= 0x303,
+
+	MLX5_CMD_OP_CREATE_CQ			= 0x400,
+	MLX5_CMD_OP_DESTROY_CQ			= 0x401,
+	MLX5_CMD_OP_QUERY_CQ			= 0x402,
+	MLX5_CMD_OP_MODIFY_CQ			= 0x403,
+
+	MLX5_CMD_OP_CREATE_QP			= 0x500,
+	MLX5_CMD_OP_DESTROY_QP			= 0x501,
+	MLX5_CMD_OP_RST2INIT_QP			= 0x502,
+	MLX5_CMD_OP_INIT2RTR_QP			= 0x503,
+	MLX5_CMD_OP_RTR2RTS_QP			= 0x504,
+	MLX5_CMD_OP_RTS2RTS_QP			= 0x505,
+	MLX5_CMD_OP_SQERR2RTS_QP		= 0x506,
+	MLX5_CMD_OP_2ERR_QP			= 0x507,
+	MLX5_CMD_OP_RTS2SQD_QP			= 0x508,
+	MLX5_CMD_OP_SQD2RTS_QP			= 0x509,
+	MLX5_CMD_OP_2RST_QP			= 0x50a,
+	MLX5_CMD_OP_QUERY_QP			= 0x50b,
+	MLX5_CMD_OP_CONF_SQP			= 0x50c,
+	MLX5_CMD_OP_MAD_IFC			= 0x50d,
+	MLX5_CMD_OP_INIT2INIT_QP		= 0x50e,
+	MLX5_CMD_OP_SUSPEND_QP			= 0x50f,
+	MLX5_CMD_OP_UNSUSPEND_QP		= 0x510,
+	MLX5_CMD_OP_SQD2SQD_QP			= 0x511,
+	MLX5_CMD_OP_ALLOC_QP_COUNTER_SET	= 0x512,
+	MLX5_CMD_OP_DEALLOC_QP_COUNTER_SET	= 0x513,
+	MLX5_CMD_OP_QUERY_QP_COUNTER_SET	= 0x514,
+
+	MLX5_CMD_OP_CREATE_PSV			= 0x600,
+	MLX5_CMD_OP_DESTROY_PSV			= 0x601,
+	MLX5_CMD_OP_QUERY_PSV			= 0x602,
+	MLX5_CMD_OP_QUERY_SIG_RULE_TABLE	= 0x603,
+	MLX5_CMD_OP_QUERY_BLOCK_SIZE_TABLE	= 0x604,
+
+	MLX5_CMD_OP_CREATE_SRQ			= 0x700,
+	MLX5_CMD_OP_DESTROY_SRQ			= 0x701,
+	MLX5_CMD_OP_QUERY_SRQ			= 0x702,
+	MLX5_CMD_OP_ARM_RQ			= 0x703,
+	MLX5_CMD_OP_RESIZE_SRQ			= 0x704,
+
+	MLX5_CMD_OP_ALLOC_PD			= 0x800,
+	MLX5_CMD_OP_DEALLOC_PD			= 0x801,
+	MLX5_CMD_OP_ALLOC_UAR			= 0x802,
+	MLX5_CMD_OP_DEALLOC_UAR			= 0x803,
+
+	MLX5_CMD_OP_ATTACH_TO_MCG		= 0x806,
+	MLX5_CMD_OP_DETACH_FROM_MCG		= 0x807,
+
+
+	MLX5_CMD_OP_ALLOC_XRCD			= 0x80e,
+	MLX5_CMD_OP_DEALLOC_XRCD		= 0x80f,
+
+	MLX5_CMD_OP_ACCESS_REG			= 0x805,
+	MLX5_CMD_OP_MAX				= 0x810,
+};
+
+enum {
+	MLX5_REG_PCAP		 = 0x5001,
+	MLX5_REG_PMTU		 = 0x5003,
+	MLX5_REG_PTYS		 = 0x5004,
+	MLX5_REG_PAOS		 = 0x5006,
+	MLX5_REG_PMAOS		 = 0x5012,
+	MLX5_REG_PUDE		 = 0x5009,
+	MLX5_REG_PMPE		 = 0x5010,
+	MLX5_REG_PELC		 = 0x500e,
+	MLX5_REG_PMLP		 = 0, /* TBD */
+	MLX5_REG_NODE_DESC	 = 0x6001,
+	MLX5_REG_HOST_ENDIANNESS = 0x7004,
+};
+
+enum dbg_rsc_type {
+	MLX5_DBG_RSC_QP,
+	MLX5_DBG_RSC_EQ,
+	MLX5_DBG_RSC_CQ,
+};
+
+struct mlx5_field_desc {
+	struct dentry	       *dent;
+	int			i;
+};
+
+struct mlx5_rsc_debug {
+	struct mlx5_core_dev   *dev;
+	void		       *object;
+	enum dbg_rsc_type	type;
+	struct dentry	       *root;
+	struct mlx5_field_desc	fields[0];
+};
+
+enum mlx5_dev_event {
+	MLX5_DEV_EVENT_SYS_ERROR,
+	MLX5_DEV_EVENT_PORT_UP,
+	MLX5_DEV_EVENT_PORT_DOWN,
+	MLX5_DEV_EVENT_PORT_INITIALIZED,
+	MLX5_DEV_EVENT_LID_CHANGE,
+	MLX5_DEV_EVENT_PKEY_CHANGE,
+	MLX5_DEV_EVENT_GUID_CHANGE,
+	MLX5_DEV_EVENT_CLIENT_REREG,
+};
+
+struct mlx5_uuar_info {
+	struct mlx5_uar	       *uars;
+	int			num_uars;
+	int			num_low_latency_uuars;
+	unsigned long	       *bitmap;
+	unsigned int	       *count;
+	struct mlx5_bf	       *bfs;
+
+	/*
+	 * protect uuar allocation data structs
+	 */
+	struct mutex		lock;
+};
+
+struct mlx5_bf {
+	void __iomem	       *reg;
+	void __iomem	       *regreg;
+	int			buf_size;
+	struct mlx5_uar	       *uar;
+	unsigned long		offset;
+	int			need_lock;
+	/* protect blue flame buffer selection when needed
+	 */
+	spinlock_t		lock;
+
+	/* serialize 64 bit writes when done as two 32 bit accesses
+	 */
+	spinlock_t		lock32;
+	int			uuarn;
+};
+
+struct mlx5_cmd_first {
+	__be32		data[4];
+};
+
+struct mlx5_cmd_msg {
+	struct list_head		list;
+	struct cache_ent	       *cache;
+	u32				len;
+	struct mlx5_cmd_first		first;
+	struct mlx5_cmd_mailbox	       *next;
+};
+
+struct mlx5_cmd_debug {
+	struct dentry	       *dbg_root;
+	struct dentry	       *dbg_in;
+	struct dentry	       *dbg_out;
+	struct dentry	       *dbg_outlen;
+	struct dentry	       *dbg_status;
+	struct dentry	       *dbg_run;
+	void		       *in_msg;
+	void		       *out_msg;
+	u8			status;
+	u16			inlen;
+	u16			outlen;
+};
+
+struct cache_ent {
+	/* protect block chain allocations
+	 */
+	spinlock_t		lock;
+	struct list_head	head;
+};
+
+struct cmd_msg_cache {
+	struct cache_ent	large;
+	struct cache_ent	med;
+
+};
+
+struct mlx5_cmd_stats {
+	u64		sum;
+	u64		n;
+	struct dentry  *root;
+	struct dentry  *avg;
+	struct dentry  *count;
+	/* protect command average calculations */
+	spinlock_t	lock;
+};
+
+struct mlx5_cmd {
+	void	       *cmd_buf;
+	dma_addr_t	dma;
+	u16		cmdif_rev;
+	u8		log_sz;
+	u8		log_stride;
+	int		max_reg_cmds;
+	int		events;
+	u32 __iomem    *vector;
+
+	/* protect command queue allocations
+	 */
+	spinlock_t	alloc_lock;
+
+	/* protect token allocations
+	 */
+	spinlock_t	token_lock;
+	u8		token;
+	unsigned long	bitmask;
+	char		wq_name[MLX5_CMD_WQ_MAX_NAME];
+	struct workqueue_struct *wq;
+	struct semaphore sem;
+	struct semaphore pages_sem;
+	int	mode;
+	struct mlx5_cmd_work_ent *ent_arr[MLX5_MAX_COMMANDS];
+	struct pci_pool *pool;
+	struct mlx5_cmd_debug dbg;
+	struct cmd_msg_cache cache;
+	int checksum_disabled;
+	struct mlx5_cmd_stats stats[MLX5_CMD_OP_MAX];
+};
+
+struct mlx5_port_caps {
+	int	gid_table_len;
+	int	pkey_table_len;
+};
+
+struct mlx5_caps {
+	u8	log_max_eq;
+	u8	log_max_cq;
+	u8	log_max_qp;
+	u8	log_max_mkey;
+	u8	log_max_pd;
+	u8	log_max_srq;
+	u32	max_cqes;
+	int	max_wqes;
+	int	max_sq_desc_sz;
+	int	max_rq_desc_sz;
+	u64	flags;
+	u16	stat_rate_support;
+	int	log_max_msg;
+	int	num_ports;
+	int	max_ra_res_qp;
+	int	max_ra_req_qp;
+	int	max_srq_wqes;
+	int	bf_reg_size;
+	int	bf_regs_per_page;
+	struct mlx5_port_caps	port[MLX5_MAX_PORTS];
+	u8			ext_port_cap[MLX5_MAX_PORTS];
+	int	max_vf;
+	u32	reserved_lkey;
+	u8	local_ca_ack_delay;
+	u8	log_max_mcg;
+	u16	max_qp_mcg;
+	int	min_page_sz;
+};
+
+struct mlx5_cmd_mailbox {
+	void	       *buf;
+	dma_addr_t	dma;
+	struct mlx5_cmd_mailbox *next;
+};
+
+struct mlx5_buf_list {
+	void		       *buf;
+	dma_addr_t		map;
+};
+
+struct mlx5_buf {
+	struct mlx5_buf_list	direct;
+	struct mlx5_buf_list   *page_list;
+	int			nbufs;
+	int			npages;
+	int			page_shift;
+	int			size;
+};
+
+struct mlx5_eq {
+	struct mlx5_core_dev   *dev;
+	__be32 __iomem	       *doorbell;
+	u32			cons_index;
+	struct mlx5_buf		buf;
+	int			size;
+	u8			irqn;
+	u8			eqn;
+	int			nent;
+	u64			mask;
+	char			name[MLX5_MAX_EQ_NAME];
+	struct list_head	list;
+	int			index;
+	struct mlx5_rsc_debug	*dbg;
+};
+
+
+struct mlx5_core_mr {
+	u64			iova;
+	u64			size;
+	u32			key;
+	u32			pd;
+	u32			access;
+};
+
+struct mlx5_core_srq {
+	u32		srqn;
+	int		max;
+	int		max_gs;
+	int		max_avail_gather;
+	int		wqe_shift;
+	void (*event)	(struct mlx5_core_srq *, enum mlx5_event);
+
+	atomic_t		refcount;
+	struct completion	free;
+};
+
+struct mlx5_eq_table {
+	void __iomem	       *update_ci;
+	void __iomem	       *update_arm_ci;
+	struct list_head       *comp_eq_head;
+	struct mlx5_eq		pages_eq;
+	struct mlx5_eq		async_eq;
+	struct mlx5_eq		cmd_eq;
+	struct msix_entry	*msix_arr;
+	int			num_comp_vectors;
+	/* protect EQs list
+	 */
+	spinlock_t		lock;
+};
+
+struct mlx5_uar {
+	u32			index;
+	struct list_head	bf_list;
+	unsigned		free_bf_bmap;
+	void __iomem	       *wc_map;
+	void __iomem	       *map;
+};
+
+
+struct mlx5_core_health {
+	struct health_buffer __iomem   *health;
+	__be32 __iomem		       *health_counter;
+	struct timer_list		timer;
+	struct list_head		list;
+	u32				prev;
+	int				miss_counter;
+};
+
+struct mlx5_cq_table {
+	/* protect radix tree
+	 */
+	spinlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
+struct mlx5_qp_table {
+	/* protect radix tree
+	 */
+	spinlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
+struct mlx5_srq_table {
+	/* protect radix tree
+	 */
+	spinlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
+struct mlx5_priv {
+	char			name[MLX5_MAX_NAME_LEN];
+	struct mlx5_eq_table	eq_table;
+	struct mlx5_uuar_info	uuari;
+	MLX5_DECLARE_DOORBELL_LOCK(cq_uar_lock);
+
+	/* pages stuff */
+	struct workqueue_struct *pg_wq;
+	struct rb_root		page_root;
+	int			fw_pages;
+	int			reg_pages;
+
+	struct mlx5_core_health health;
+
+	struct mlx5_srq_table	srq_table;
+
+	/* start: qp staff */
+	struct mlx5_qp_table	qp_table;
+	struct dentry	       *qp_debugfs;
+	struct dentry	       *eq_debugfs;
+	struct dentry	       *cq_debugfs;
+	struct dentry	       *cmdif_debugfs;
+	/* end: qp staff */
+
+	/* start: cq staff */
+	struct mlx5_cq_table	cq_table;
+	/* end: cq staff */
+
+	/* start: alloc staff */
+	struct mutex            pgdir_mutex;
+	struct list_head        pgdir_list;
+	/* end: alloc staff */
+	struct dentry	       *dbg_root;
+
+	/* protect mkey key part */
+	spinlock_t		mkey_lock;
+	u8			mkey_key;
+};
+
+struct mlx5_core_dev {
+	struct pci_dev	       *pdev;
+	u8			rev_id;
+	char			board_id[MLX5_BOARD_ID_LEN];
+	struct mlx5_cmd		cmd;
+	struct mlx5_caps	caps;
+	phys_addr_t		iseg_base;
+	struct mlx5_init_seg __iomem *iseg;
+	void			(*event) (struct mlx5_core_dev *dev,
+					  enum mlx5_dev_event event,
+					  void *data);
+	struct mlx5_priv	priv;
+	struct mlx5_profile	*profile;
+	atomic_t		num_qps;
+};
+
+struct mlx5_db {
+	__be32			*db;
+	union {
+		struct mlx5_db_pgdir		*pgdir;
+		struct mlx5_ib_user_db_page	*user_page;
+	}			u;
+	dma_addr_t		dma;
+	int			index;
+};
+
+enum {
+	MLX5_DB_PER_PAGE = PAGE_SIZE / L1_CACHE_BYTES,
+};
+
+enum {
+	MLX5_COMP_EQ_SIZE = 1024,
+};
+
+struct mlx5_db_pgdir {
+	struct list_head	list;
+	DECLARE_BITMAP(bitmap, MLX5_DB_PER_PAGE);
+	__be32		       *db_page;
+	dma_addr_t		db_dma;
+};
+
+typedef void (*mlx5_cmd_cbk_t)(int status, void *context);
+
+struct mlx5_cmd_work_ent {
+	struct mlx5_cmd_msg    *in;
+	struct mlx5_cmd_msg    *out;
+	mlx5_cmd_cbk_t		callback;
+	void		       *context;
+	int idx;
+	struct completion	done;
+	struct mlx5_cmd        *cmd;
+	struct work_struct	work;
+	struct mlx5_cmd_layout *lay;
+	int			ret;
+	int			page_queue;
+	u8			status;
+	u8			token;
+	struct timespec		ts1;
+	struct timespec		ts2;
+};
+
+struct mlx5_pas {
+	u64	pa;
+	u8	log_sz;
+};
+
+static inline void *mlx5_buf_offset(struct mlx5_buf *buf, int offset)
+{
+	if (likely(BITS_PER_LONG == 64 || buf->nbufs == 1))
+		return buf->direct.buf + offset;
+	else
+		return buf->page_list[offset >> PAGE_SHIFT].buf +
+			(offset & (PAGE_SIZE - 1));
+}
+
+extern struct workqueue_struct *mlx5_core_wq;
+
+#define STRUCT_FIELD(header, field) \
+	.struct_offset_bytes = offsetof(struct ib_unpacked_ ## header, field),      \
+	.struct_size_bytes   = sizeof((struct ib_unpacked_ ## header *)0)->field
+
+struct ib_field {
+	size_t struct_offset_bytes;
+	size_t struct_size_bytes;
+	int    offset_bits;
+	int    size_bits;
+};
+
+static inline struct mlx5_core_dev *pci2mlx5_core_dev(struct pci_dev *pdev)
+{
+	return pci_get_drvdata(pdev);
+}
+
+extern struct dentry *mlx5_debugfs_root;
+
+static inline u16 fw_rev_maj(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->fw_rev) & 0xffff;
+}
+
+static inline u16 fw_rev_min(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->fw_rev) >> 16;
+}
+
+static inline u16 fw_rev_sub(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->cmdif_rev_fw_sub) & 0xffff;
+}
+
+static inline u16 cmdif_rev(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->cmdif_rev_fw_sub) >> 16;
+}
+
+static inline void *mlx5_vzalloc(unsigned long size)
+{
+	void *rtn;
+
+	rtn = kzalloc(size, GFP_KERNEL | __GFP_NOWARN);
+	if (!rtn)
+		rtn = vzalloc(size);
+	return rtn;
+}
+
+static inline void mlx5_vfree(const void *addr)
+{
+	if (addr && is_vmalloc_addr(addr))
+		vfree(addr);
+	else
+		kfree(addr);
+}
+
+int mlx5_dev_init(struct mlx5_core_dev *dev, struct pci_dev *pdev);
+void mlx5_dev_cleanup(struct mlx5_core_dev *dev);
+int mlx5_cmd_init(struct mlx5_core_dev *dev);
+void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
+void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
+void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
+int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
+int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
+		  int out_size);
+int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
+int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
+int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
+int mlx5_free_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
+void mlx5_health_cleanup(void);
+void  __init mlx5_health_init(void);
+void mlx5_start_health_poll(struct mlx5_core_dev *dev);
+void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
+int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, int max_direct,
+		   struct mlx5_buf *buf);
+void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_buf *buf);
+struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
+						      gfp_t flags, int npages);
+void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
+				 struct mlx5_cmd_mailbox *head);
+int mlx5_core_create_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+			 struct mlx5_create_srq_mbox_in *in, int inlen);
+int mlx5_core_destroy_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq);
+int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+			struct mlx5_query_srq_mbox_out *out);
+int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+		      u16 lwm, int is_srq);
+int mlx5_core_create_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			  struct mlx5_create_mkey_mbox_in *in, int inlen);
+int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr);
+int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			 struct mlx5_query_mkey_mbox_out *out, int outlen);
+int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			     u32 *mkey);
+int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
+int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
+int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, void *inb, void *outb,
+		      u16 opmod, int port);
+void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
+void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
+int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
+void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
+void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
+				 s16 npages);
+int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev);
+int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);
+void mlx5_register_debugfs(void);
+void mlx5_unregister_debugfs(void);
+int mlx5_eq_init(struct mlx5_core_dev *dev);
+void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
+void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
+void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
+void mlx5_qp_event(struct mlx5_core_dev *dev, u32 qpn, int event_type);
+void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
+struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
+void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector);
+void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
+int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
+		       int nent, u64 mask, const char *name, struct mlx5_uar *uar);
+int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+int mlx5_start_eqs(struct mlx5_core_dev *dev);
+int mlx5_stop_eqs(struct mlx5_core_dev *dev);
+int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
+int mlx5_core_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
+
+int mlx5_qp_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_qp_debugfs_cleanup(struct mlx5_core_dev *dev);
+int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
+			 int size_in, void *data_out, int size_out,
+			 u16 reg_num, int arg, int write);
+int mlx5_set_port_caps(struct mlx5_core_dev *dev, int port_num, u32 caps);
+
+int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
+		       struct mlx5_query_eq_mbox_out *out, int outlen);
+int mlx5_eq_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_eq_debugfs_cleanup(struct mlx5_core_dev *dev);
+int mlx5_cq_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);
+int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db);
+void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);
+
+typedef void (*health_handler_t)(struct pci_dev *pdev, void *buf, int size);
+int mlx5_register_health_report_handler(health_handler_t handler);
+void mlx5_unregister_health_report_handler(void);
+const char *mlx5_command_str(int command);
+int mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev);
+
+static inline u32 mlx5_mkey_to_idx(u32 mkey)
+{
+	return mkey >> 8;
+}
+
+static inline u32 mlx5_idx_to_mkey(u32 mkey_idx)
+{
+	return mkey_idx << 8;
+}
+
+enum {
+	MLX5_PROF_MASK_QP_SIZE		= (u64)1 << 0,
+	MLX5_PROF_MASK_CMDIF_CSUM	= (u64)1 << 1,
+	MLX5_PROF_MASK_MR_CACHE		= (u64)1 << 2,
+};
+
+enum {
+	MAX_MR_CACHE_ENTRIES    = 16,
+};
+
+struct mlx5_profile {
+	u64	mask;
+	u32	log_max_qp;
+	int	cmdif_csum;
+	struct {
+		int	size;
+		int	limit;
+	} mr_cache[MAX_MR_CACHE_ENTRIES];
+};
+
+#endif /* MLX5_DRIVER_H */
