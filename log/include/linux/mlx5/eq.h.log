commit b9a7ba5562074855e8a3f92ea7e1174b61a3e87d
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Sun Jun 30 19:23:23 2019 +0300

    net/mlx5: Use event mask based on device capabilities
    
    Use the reported device capabilities for the supported user events (i.e.
    affiliated and un-affiliated) to set the EQ mask.
    
    As the event mask can be up to 256 defined by 4 entries of u64 change
    the applicable code to work accordingly.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Acked-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
index 70e16dcfb4c4..e49d8c0d4f26 100644
--- a/include/linux/mlx5/eq.h
+++ b/include/linux/mlx5/eq.h
@@ -15,7 +15,7 @@ struct mlx5_core_dev;
 struct mlx5_eq_param {
 	u8             irq_index;
 	int            nent;
-	u64            mask;
+	u64            mask[4];
 };
 
 struct mlx5_eq *

commit 1f8a7bee27e63d7c5287719049941e285e54d370
Author: Yuval Avnery <yuvalav@mellanox.com>
Date:   Mon Jun 10 23:38:42 2019 +0000

    net/mlx5: Add EQ enable/disable API
    
    Previously, EQ joined the chain notifier on creation.
    This forced the caller to be ready to handle events before creating
    the EQ through eq_create_generic interface.
    
    To help the caller control when the created EQ will be attached to the
    IRQ, add enable/disable API.
    
    Signed-off-by: Yuval Avnery <yuvalav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
index 4a94e04eff0a..70e16dcfb4c4 100644
--- a/include/linux/mlx5/eq.h
+++ b/include/linux/mlx5/eq.h
@@ -16,13 +16,16 @@ struct mlx5_eq_param {
 	u8             irq_index;
 	int            nent;
 	u64            mask;
-	struct notifier_block *nb;
 };
 
 struct mlx5_eq *
 mlx5_eq_create_generic(struct mlx5_core_dev *dev, struct mlx5_eq_param *param);
 int
 mlx5_eq_destroy_generic(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+int mlx5_eq_enable(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
+		   struct notifier_block *nb);
+void mlx5_eq_disable(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
+		     struct notifier_block *nb);
 
 struct mlx5_eqe *mlx5_eq_get_eqe(struct mlx5_eq *eq, u32 cc);
 void mlx5_eq_update_ci(struct mlx5_eq *eq, u32 cc, bool arm);

commit 81bfa206032a67f0700459a64a5493c246629604
Author: Ariel Levkovich <lariel@mellanox.com>
Date:   Mon Jun 10 23:38:41 2019 +0000

    net/mlx5: Use a single IRQ for all async EQs
    
    The patch modifies the IRQ allocation so that all async EQs are
    assigned to the same IRQ resulting in more available IRQs for
    completion EQs.
    
    The changes are using the support for IRQ sharing and EQ polling budget
    that was introduced in previous patches so when the shared interrupt is
    triggered, the kernel will serially call the handler of each of the
    sharing EQs with a certain budget of EQEs to poll in order to prevent
    starvation.
    
    Signed-off-by: Ariel Levkovich <lariel@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
index 73ab658af764..4a94e04eff0a 100644
--- a/include/linux/mlx5/eq.h
+++ b/include/linux/mlx5/eq.h
@@ -4,17 +4,7 @@
 #ifndef MLX5_CORE_EQ_H
 #define MLX5_CORE_EQ_H
 
-enum {
-	MLX5_EQ_PAGEREQ_IDX        = 0,
-	MLX5_EQ_CMD_IDX            = 1,
-	MLX5_EQ_ASYNC_IDX          = 2,
-	/* reserved to be used by mlx5_core ulps (mlx5e/mlx5_ib) */
-	MLX5_EQ_PFAULT_IDX         = 3,
-	MLX5_EQ_MAX_ASYNC_EQS,
-	/* completion eqs vector indices start here */
-	MLX5_EQ_VEC_COMP_BASE = MLX5_EQ_MAX_ASYNC_EQS,
-};
-
+#define MLX5_IRQ_VEC_COMP_BASE 1
 #define MLX5_NUM_CMD_EQE   (32)
 #define MLX5_NUM_ASYNC_EQE (0x1000)
 #define MLX5_NUM_SPARE_EQE (0x80)
@@ -23,7 +13,7 @@ struct mlx5_eq;
 struct mlx5_core_dev;
 
 struct mlx5_eq_param {
-	u8             index;
+	u8             irq_index;
 	int            nent;
 	u64            mask;
 	struct notifier_block *nb;

commit 24163189da487b4caa751eef4e945c9333aae441
Author: Yuval Avnery <yuvalav@mellanox.com>
Date:   Mon Jun 10 23:38:25 2019 +0000

    net/mlx5: Separate IRQ request/free from EQ life cycle
    
    Instead of requesting IRQ with eq creation, IRQs will be requested
    before EQ table creation.
    Instead of freeing the IRQs after EQ destroy, free IRQs after eq
    table destroy.
    
    Signed-off-by: Yuval Avnery <yuvalav@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
index 7909f1ff197c..73ab658af764 100644
--- a/include/linux/mlx5/eq.h
+++ b/include/linux/mlx5/eq.h
@@ -30,8 +30,7 @@ struct mlx5_eq_param {
 };
 
 struct mlx5_eq *
-mlx5_eq_create_generic(struct mlx5_core_dev *dev, const char *name,
-		       struct mlx5_eq_param *param);
+mlx5_eq_create_generic(struct mlx5_core_dev *dev, struct mlx5_eq_param *param);
 int
 mlx5_eq_destroy_generic(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 

commit ca390799c2aa03632c294107fa7f647bcbdff428
Author: Yuval Avnery <yuvalav@mellanox.com>
Date:   Mon Jun 10 23:38:23 2019 +0000

    net/mlx5: Change interrupt handler to call chain notifier
    
    Multiple EQs may share the same IRQ in subsequent patches.
    
    Instead of calling the IRQ handler directly, the EQ will register
    to an atomic chain notfier.
    
    The Linux built-in shared IRQ is not used because it forces the caller
    to disable the IRQ and clear affinity before free_irq() can be called.
    
    This patch is the first step in the separation of IRQ and EQ logic.
    
    Signed-off-by: Yuval Avnery <yuvalav@mellanox.com>
    Reviewed-by: Parav Pandit <parav@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
index 00045cc4ea11..7909f1ff197c 100644
--- a/include/linux/mlx5/eq.h
+++ b/include/linux/mlx5/eq.h
@@ -26,8 +26,7 @@ struct mlx5_eq_param {
 	u8             index;
 	int            nent;
 	u64            mask;
-	void          *context;
-	irq_handler_t  handler;
+	struct notifier_block *nb;
 };
 
 struct mlx5_eq *

commit 0f597ed435b9ea1296e25474b762bedceba97a50
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Nov 20 14:12:18 2018 -0800

    net/mlx5: EQ, Introduce atomic notifier chain subscription API
    
    Use atomic_notifier_chain to fire firmware events at internal mlx5 core
    components such as eswitch/fpga/clock/FW tracer/etc.., this is to
    avoid explicit calls from low level mlx5_core to upper components and to
    simplify the mlx5_core API for future developments.
    
    Simply provide register/unregister notifiers API and call the notifier
    chain on firmware async events.
    
    Example: to subscribe to a FW event:
    struct mlx5_nb port_event;
    
    MLX5_NB_INIT(&port_event, port_event_handler, PORT_CHANGE);
    mlx5_eq_notifier_register(mdev, &port_event);
    
    where:
     - port_event_handler is the notifier block callback.
     - PORT_EVENT is the suffix of MLX5_EVENT_TYPE_PORT_CHANGE.
    
    The above will guarantee that port_event_handler will receive all FW
    events of the type MLX5_EVENT_TYPE_PORT_CHANGE.
    
    To receive all FW/HW events one can subscribe to
    MLX5_EVENT_TYPE_NOTIFY_ANY.
    
    The next few patches will start moving all mlx5 core components to use
    this new API and cleanup mlx5_eq_async_int misx handler from component
    explicit calls and specific logic.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
index 71d82c5a1a02..00045cc4ea11 100644
--- a/include/linux/mlx5/eq.h
+++ b/include/linux/mlx5/eq.h
@@ -4,8 +4,6 @@
 #ifndef MLX5_CORE_EQ_H
 #define MLX5_CORE_EQ_H
 
-#include <linux/mlx5/driver.h>
-
 enum {
 	MLX5_EQ_PAGEREQ_IDX        = 0,
 	MLX5_EQ_CMD_IDX            = 1,
@@ -22,6 +20,7 @@ enum {
 #define MLX5_NUM_SPARE_EQE (0x80)
 
 struct mlx5_eq;
+struct mlx5_core_dev;
 
 struct mlx5_eq_param {
 	u8             index;
@@ -57,4 +56,17 @@ static inline u32 mlx5_eq_update_cc(struct mlx5_eq *eq, u32 cc)
 	return cc;
 }
 
+struct mlx5_nb {
+	struct notifier_block nb;
+	u8 event_type;
+};
+
+#define mlx5_nb_cof(ptr, type, member) \
+	(container_of(container_of(ptr, struct mlx5_nb, nb), type, member))
+
+#define MLX5_NB_INIT(name, handler, event) do {              \
+	(name)->nb.notifier_call = handler;                  \
+	(name)->event_type = MLX5_EVENT_TYPE_##event;        \
+} while (0)
+
 #endif /* MLX5_CORE_EQ_H */

commit d5d284b829a6eb7127df24d1bd3896a698981e62
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:41 2018 -0800

    {net,IB}/mlx5: Move Page fault EQ and ODP logic to RDMA
    
    Use the new generic EQ API to move all ODP RDMA data structures and logic
    form mlx5 core driver into mlx5_ib driver.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Acked-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
index c733673ba5f6..71d82c5a1a02 100644
--- a/include/linux/mlx5/eq.h
+++ b/include/linux/mlx5/eq.h
@@ -17,6 +17,10 @@ enum {
 	MLX5_EQ_VEC_COMP_BASE = MLX5_EQ_MAX_ASYNC_EQS,
 };
 
+#define MLX5_NUM_CMD_EQE   (32)
+#define MLX5_NUM_ASYNC_EQE (0x1000)
+#define MLX5_NUM_SPARE_EQE (0x80)
+
 struct mlx5_eq;
 
 struct mlx5_eq_param {
@@ -36,4 +40,21 @@ mlx5_eq_destroy_generic(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 struct mlx5_eqe *mlx5_eq_get_eqe(struct mlx5_eq *eq, u32 cc);
 void mlx5_eq_update_ci(struct mlx5_eq *eq, u32 cc, bool arm);
 
+/* The HCA will think the queue has overflowed if we
+ * don't tell it we've been processing events.  We
+ * create EQs with MLX5_NUM_SPARE_EQE extra entries,
+ * so we must update our consumer index at
+ * least that often.
+ *
+ * mlx5_eq_update_cc must be called on every EQE @EQ irq handler
+ */
+static inline u32 mlx5_eq_update_cc(struct mlx5_eq *eq, u32 cc)
+{
+	if (unlikely(cc >= MLX5_NUM_SPARE_EQE)) {
+		mlx5_eq_update_ci(eq, cc, 0);
+		cc = 0;
+	}
+	return cc;
+}
+
 #endif /* MLX5_CORE_EQ_H */

commit 7701707cb94ed4d1e63ae4fa5ef62a2345ef9db7
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 19 10:52:40 2018 -0800

    net/mlx5: EQ, Generic EQ
    
    Add mlx5_eq_{create/destroy}_generic APIs and EQE access methods, for
    mlx5 core consumers generic EQs.
    
    This API will be used in downstream patch to move page fault (RDMA ODP)
    EQ logic into mlx5_ib rdma driver, hence it will use a generic EQ.
    
    Current mlx5 EQ allocation scheme:
    On load mlx5 allocates 4 (for async) + #cores (for data completions)
    MSIX vectors, mlx5 core will assign 3 MSIX vectors for internal async
    EQs and will use all of the #cores MSIX vectors for completion EQs,
    (One vector is going to be reserved for a generic EQ).
    
    After this patch an external user (e.g mlx5_ib) of mlx5_core
    can use this new API to create new generic EQs with the reserved msix
    vector index for that eq.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/eq.h b/include/linux/mlx5/eq.h
new file mode 100644
index 000000000000..c733673ba5f6
--- /dev/null
+++ b/include/linux/mlx5/eq.h
@@ -0,0 +1,39 @@
+/* SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB */
+/* Copyright (c) 2018 Mellanox Technologies. */
+
+#ifndef MLX5_CORE_EQ_H
+#define MLX5_CORE_EQ_H
+
+#include <linux/mlx5/driver.h>
+
+enum {
+	MLX5_EQ_PAGEREQ_IDX        = 0,
+	MLX5_EQ_CMD_IDX            = 1,
+	MLX5_EQ_ASYNC_IDX          = 2,
+	/* reserved to be used by mlx5_core ulps (mlx5e/mlx5_ib) */
+	MLX5_EQ_PFAULT_IDX         = 3,
+	MLX5_EQ_MAX_ASYNC_EQS,
+	/* completion eqs vector indices start here */
+	MLX5_EQ_VEC_COMP_BASE = MLX5_EQ_MAX_ASYNC_EQS,
+};
+
+struct mlx5_eq;
+
+struct mlx5_eq_param {
+	u8             index;
+	int            nent;
+	u64            mask;
+	void          *context;
+	irq_handler_t  handler;
+};
+
+struct mlx5_eq *
+mlx5_eq_create_generic(struct mlx5_core_dev *dev, const char *name,
+		       struct mlx5_eq_param *param);
+int
+mlx5_eq_destroy_generic(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+
+struct mlx5_eqe *mlx5_eq_get_eqe(struct mlx5_eq *eq, u32 cc);
+void mlx5_eq_update_ci(struct mlx5_eq *eq, u32 cc, bool arm);
+
+#endif /* MLX5_CORE_EQ_H */
