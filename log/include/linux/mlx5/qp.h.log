commit f18e26af6aba778b888044859d9c69bb9bbc7bc1
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Tue May 26 14:54:38 2020 +0300

    RDMA/mlx5: Convert modify QP to use MLX5_SET macros
    
    Instead of hand crafted mlx5_qp_context and mlx5_qp_path use common
    MLX5_SET() macros.
    
    Link: https://lore.kernel.org/r/20200526115440.205922-7-leon@kernel.org
    Reviewed-by: Maor Gottlieb <maorg@mellanox.com>
    Reviewed-by: Mark Zhang <markz@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index def601199a1a..b8992b861ae6 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -495,72 +495,6 @@ struct mlx5_core_dct {
 	struct completion	drained;
 };
 
-struct mlx5_qp_path {
-	u8			fl_free_ar;
-	u8			rsvd3;
-	__be16			pkey_index;
-	u8			rsvd0;
-	u8			grh_mlid;
-	__be16			rlid;
-	u8			ackto_lt;
-	u8			mgid_index;
-	u8			static_rate;
-	u8			hop_limit;
-	__be32			tclass_flowlabel;
-	union {
-		u8		rgid[16];
-		u8		rip[16];
-	};
-	u8			f_dscp_ecn_prio;
-	u8			ecn_dscp;
-	__be16			udp_sport;
-	u8			dci_cfi_prio_sl;
-	u8			port;
-	u8			rmac[6];
-};
-
-/* FIXME: use mlx5_ifc.h qpc */
-struct mlx5_qp_context {
-	__be32			flags;
-	__be32			flags_pd;
-	u8			mtu_msgmax;
-	u8			rq_size_stride;
-	__be16			sq_crq_size;
-	__be32			qp_counter_set_usr_page;
-	__be32			wire_qpn;
-	__be32			log_pg_sz_remote_qpn;
-	struct			mlx5_qp_path pri_path;
-	struct			mlx5_qp_path alt_path;
-	__be32			params1;
-	u8			reserved2[4];
-	__be32			next_send_psn;
-	__be32			cqn_send;
-	__be32			deth_sqpn;
-	u8			reserved3[4];
-	__be32			last_acked_psn;
-	__be32			ssn;
-	__be32			params2;
-	__be32			rnr_nextrecvpsn;
-	__be32			xrcd;
-	__be32			cqn_recv;
-	__be64			db_rec_addr;
-	__be32			qkey;
-	__be32			rq_type_srqn;
-	__be32			rmsn;
-	__be16			hw_sq_wqe_counter;
-	__be16			sw_sq_wqe_counter;
-	__be16			hw_rcyclic_byte_counter;
-	__be16			hw_rq_counter;
-	__be16			sw_rcyclic_byte_counter;
-	__be16			sw_rq_counter;
-	u8			rsvd0[5];
-	u8			cgs;
-	u8			cs_req;
-	u8			cs_res;
-	__be64			dc_access_key;
-	u8			rsvd1[24];
-};
-
 int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 

commit 10c261551359e37670a200c55c492f4aba7d23ed
Merge: 0cb9e4f9e98a 9254f8ed15b6
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Wed May 13 15:54:19 2020 -0300

    Merge branch 'mellanox/mlx5-next' into rdma.git for/next
    
    From the mlx5-next branch at
      git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Required for dependencies in following patches
    
    * branch 'mellanox/mlx5-next':
      net/mlx5: Add support in forward to namespace
      {IB/net}/mlx5: Simplify don't trap code
      net/mlx5: Replace zero-length array with flexible-array
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit b6ca09cb156d349e6fdde8a8466ec15b902d1419
Author: Gustavo A. R. Silva <gustavoars@kernel.org>
Date:   Thu May 7 13:59:35 2020 -0500

    net/mlx5: Replace zero-length array with flexible-array
    
    The current codebase makes use of the zero-length array language
    extension to the C90 standard, but the preferred mechanism to declare
    variable-length types such as these ones is a flexible array member[1][2],
    introduced in C99:
    
    struct foo {
            int stuff;
            struct boo array[];
    };
    
    By making use of the mechanism above, we will get a compiler warning
    in case the flexible array does not occur last in the structure, which
    will help us prevent some kind of undefined behavior bugs from being
    inadvertently introduced[3] to the codebase from now on.
    
    Also, notice that, dynamic memory allocations won't be affected by
    this change:
    
    "Flexible array members have incomplete type, and so the sizeof operator
    may not be applied. As a quirk of the original implementation of
    zero-length arrays, sizeof evaluates to zero."[1]
    
    sizeof(flexible-array-member) triggers a warning because flexible array
    members have incomplete type[1]. There are some instances of code in
    which the sizeof operator is being incorrectly/erroneously applied to
    zero-length arrays and the result is zero. Such instances may be hiding
    some bugs. So, this work (flexible-array member conversions) will also
    help to get completely rid of those sorts of issues.
    
    This issue was found with the help of Coccinelle.
    
    [1] https://gcc.gnu.org/onlinedocs/gcc/Zero-Length.html
    [2] https://github.com/KSPP/linux/issues/21
    [3] commit 76497732932f ("cxgb3/l2t: Fix undefined behaviour")
    
    Signed-off-by: Gustavo A. R. Silva <gustavoars@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index f23eb18526fe..1af5e460b5f6 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -408,7 +408,7 @@ struct mlx5_wqe_signature_seg {
 
 struct mlx5_wqe_inline_seg {
 	__be32	byte_count;
-	__be32	data[0];
+	__be32	data[];
 };
 
 enum mlx5_sig_type {

commit cfc1a89e449c02207952c72a4c0394691fdedf43
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Thu Apr 30 22:21:46 2020 +0300

    RDMA/mlx5: Set lag tx affinity according to slave
    
    The patch sets the lag tx affinity of the data QPs and the GSI QPs
    according to the LAG xmit slave.
    
    For GSI QPs, in case the link layer is Ethenet (RoCE) we create two GSI
    QPs, one for each physical port. When the driver selects the GSI QP, it
    will consider the port affinity result.  For connected QPs, the driver
    sets the affinity of the xmit slave.
    
    The above, ensures that RC QP and it's corresponding GSI QP will transmit
    from the same physical port.
    
    Link: https://lore.kernel.org/r/20200430192146.12863-17-maorg@mellanox.com
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index f23eb18526fe..b9facdb9b9bd 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -66,6 +66,7 @@ enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_RETRY_COUNT		= 1 << 12,
 	MLX5_QP_OPTPAR_RNR_RETRY		= 1 << 13,
 	MLX5_QP_OPTPAR_ACK_TIMEOUT		= 1 << 14,
+	MLX5_QP_OPTPAR_LAG_TX_AFF		= 1 << 15,
 	MLX5_QP_OPTPAR_PRI_PORT			= 1 << 16,
 	MLX5_QP_OPTPAR_SRQN			= 1 << 18,
 	MLX5_QP_OPTPAR_CQN_RCV			= 1 << 19,
@@ -321,6 +322,7 @@ struct mlx5_av {
 struct mlx5_ib_ah {
 	struct ib_ah		ibah;
 	struct mlx5_av		av;
+	u8			xmit_port;
 };
 
 static inline struct mlx5_ib_ah *to_mah(struct ib_ah *ibah)

commit 2dc8b5246d2c94f732c02e7a688d8a9c0c65361f
Author: Raed Salem <raeds@mellanox.com>
Date:   Fri Apr 24 12:45:10 2020 -0700

    net/mlx5: TX WQE Add trailer insertion field
    
    Add new TX WQE field for Connect-X6DX trailer insertion support,
    when set, the HW adds a trailer to the packet, the WQE trailer
    association flags are used to set to HW the header which the
    trailer belongs.
    
    Signed-off-by: Raed Salem <raeds@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index ef127a156a62..f23eb18526fe 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -229,6 +229,11 @@ enum {
 
 enum {
 	MLX5_ETH_WQE_SVLAN              = 1 << 0,
+	MLX5_ETH_WQE_TRAILER_HDR_OUTER_IP_ASSOC = 1 << 26,
+	MLX5_ETH_WQE_TRAILER_HDR_OUTER_L4_ASSOC = 1 << 27,
+	MLX5_ETH_WQE_TRAILER_HDR_INNER_IP_ASSOC = 3 << 26,
+	MLX5_ETH_WQE_TRAILER_HDR_INNER_L4_ASSOC = 1 << 28,
+	MLX5_ETH_WQE_INSERT_TRAILER     = 1 << 30,
 	MLX5_ETH_WQE_INSERT_VLAN        = 1 << 15,
 };
 
@@ -257,6 +262,7 @@ struct mlx5_wqe_eth_seg {
 			__be16 type;
 			__be16 vlan_tci;
 		} insert;
+		__be32 trailer;
 	};
 };
 

commit 333fbaa0255b8d471fc7ae767ef3a1766c732d6d
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Sat Apr 4 10:40:24 2020 +0300

    net/mlx5: Move QP logic to mlx5_ib
    
    The mlx5_core doesn't need any functionality coded in qp.c, so move
    that file to drivers/infiniband/ be under mlx5_ib responsibility.
    
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 4d25a3d24182..ef127a156a62 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -553,53 +553,8 @@ struct mlx5_qp_context {
 	u8			rsvd1[24];
 };
 
-static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u32 qpn)
-{
-	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
-}
-
-int mlx5_core_create_dct(struct mlx5_core_dev *dev,
-			 struct mlx5_core_dct *qp,
-			 u32 *in, int inlen,
-			 u32 *out, int outlen);
-int mlx5_core_create_qp(struct mlx5_core_dev *dev,
-			struct mlx5_core_qp *qp,
-			u32 *in,
-			int inlen);
-int mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 opcode,
-			u32 opt_param_mask, void *qpc,
-			struct mlx5_core_qp *qp);
-int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
-			 struct mlx5_core_qp *qp);
-int mlx5_core_destroy_dct(struct mlx5_core_dev *dev,
-			  struct mlx5_core_dct *dct);
-int mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
-		       u32 *out, int outlen);
-int mlx5_core_dct_query(struct mlx5_core_dev *dev, struct mlx5_core_dct *dct,
-			u32 *out, int outlen);
-
-int mlx5_core_set_delay_drop(struct mlx5_core_dev *dev,
-			     u32 timeout_usec);
-
-int mlx5_core_xrcd_alloc(struct mlx5_core_dev *dev, u32 *xrcdn);
-int mlx5_core_xrcd_dealloc(struct mlx5_core_dev *dev, u32 xrcdn);
-void mlx5_init_qp_table(struct mlx5_core_dev *dev);
-void mlx5_cleanup_qp_table(struct mlx5_core_dev *dev);
 int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
-int mlx5_core_create_rq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,
-				struct mlx5_core_qp *rq);
-void mlx5_core_destroy_rq_tracked(struct mlx5_core_dev *dev,
-				  struct mlx5_core_qp *rq);
-int mlx5_core_create_sq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,
-				struct mlx5_core_qp *sq);
-void mlx5_core_destroy_sq_tracked(struct mlx5_core_dev *dev,
-				  struct mlx5_core_qp *sq);
-
-struct mlx5_core_rsc_common *mlx5_core_res_hold(struct mlx5_core_dev *dev,
-						int res_num,
-						enum mlx5_res_type res_type);
-void mlx5_core_res_put(struct mlx5_core_rsc_common *res);
 
 static inline const char *mlx5_qp_type_str(int type)
 {

commit 66247fbb280c2a699a8621708c52dae6acd2e4bc
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Fri Apr 3 11:28:28 2020 +0300

    net/mlx5: Remove Q counter low level helper APIs
    
    mlx5 core users are encouraged to use low level API (mlx5_cmd_exec)
    without the need of helper functions, do this for q counters, remove
    helper functions and call mlx5_cmd_exec directly from users.
    
    This will help reduce the total amount of code and reduction of the
    mlx5_core symbol table.
    
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index ae63b1ae9004..4d25a3d24182 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -595,10 +595,6 @@ int mlx5_core_create_sq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,
 				struct mlx5_core_qp *sq);
 void mlx5_core_destroy_sq_tracked(struct mlx5_core_dev *dev,
 				  struct mlx5_core_qp *sq);
-int mlx5_core_alloc_q_counter(struct mlx5_core_dev *dev, u16 *counter_id);
-int mlx5_core_dealloc_q_counter(struct mlx5_core_dev *dev, u16 counter_id);
-int mlx5_core_query_q_counter(struct mlx5_core_dev *dev, u16 counter_id,
-			      int reset, void *out, int out_size);
 
 struct mlx5_core_rsc_common *mlx5_core_res_hold(struct mlx5_core_dev *dev,
 						int res_num,

commit d14133dd41614aaaac1fa0505c7dab01f4211d2c
Author: Mark Zhang <markz@mellanox.com>
Date:   Tue Jul 2 13:02:36 2019 +0300

    IB/mlx5: Support set qp counter
    
    Support bind a qp with counter. If counter is null then bind the qp to the
    default counter. Different QP state has different operation:
    
    - RESET: Set the counter field so that it will take effective during
      RST2INIT change;
    - RTS: Issue an RTS2RTS change to update the QP counter;
    - Other: Set the counter field and mark the counter_pending flag, when QP
      is moved to RTS state and this flag is set, then issue an RTS2RTS
      modification to update the counter.
    
    Signed-off-by: Mark Zhang <markz@mellanox.com>
    Reviewed-by: Majd Dibbiny <majd@mellanox.com>
    Acked-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 937041101504..ae63b1ae9004 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -71,6 +71,7 @@ enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_CQN_RCV			= 1 << 19,
 	MLX5_QP_OPTPAR_DC_HS			= 1 << 20,
 	MLX5_QP_OPTPAR_DC_KEY			= 1 << 21,
+	MLX5_QP_OPTPAR_COUNTER_SET_ID		= 1 << 25,
 };
 
 enum mlx5_qp_state {

commit 5600a410ea24cb8467abdd4b8530961ff4f14907
Merge: bcde9a83b13e f8efee08dd9d
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Fri Jul 5 10:16:19 2019 -0300

    Merge mlx5-next into rdma for-next
    
    From git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Required for dependencies in the next patches.
    
    * mlx5-next:
      net/mlx5: Add rts2rts_qp_counters_set_id field in hca cap
      net/mlx5: Properly name the generic WQE control field
      net/mlx5: Introduce TLS TX offload hardware bits and structures
      net/mlx5: Refactor mlx5_esw_query_functions for modularity
      net/mlx5: E-Switch prepare functions change handler to be modular
      net/mlx5: Introduce and use mlx5_eswitch_get_total_vports()

commit 0718edf528c552c66a5dc3525ffb145971efa766
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Tue Jul 2 17:12:09 2019 +0300

    net/mlx5: Properly name the generic WQE control field
    
    A generic WQE control field is used for different purposes
    in different cases.
    Use union to allow using the proper name in each case.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index d1f353c64797..127d224443e3 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -202,7 +202,12 @@ struct mlx5_wqe_ctrl_seg {
 	u8			signature;
 	u8			rsvd[2];
 	u8			fm_ce_se;
-	__be32			imm;
+	union {
+		__be32		general_id;
+		__be32		imm;
+		__be32		umr_mkey;
+		__be32		tisn;
+	};
 };
 
 #define MLX5_WQE_CTRL_DS_MASK 0x3f

commit 69ea0582f3ce7a72d312da7305e455801a8dc5a4
Merge: 2f40cf30c864 e4075c442876
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Wed Jul 3 16:43:45 2019 -0300

    Merge mlx5-next into rdma for-next
    
    From git://git.kernel.org/pub/scm/linux/kernel/git/mellanox/linux
    
    Required for dependencies in the next patches.
    
    Resolved the conflicts:
     - esw_destroy_offloads_acl_tables() use the newer mlx5_esw_for_all_vports()
       version
     - esw_offloads_steering_init() drop the cap test
     - esw_offloads_init() drop the extra function arguments
    
    * branch 'mlx5-next': (39 commits)
      net/mlx5: Expose device definitions for object events
      net/mlx5: Report EQE data upon CQ completion
      net/mlx5: Report a CQ error event only when a handler was set
      net/mlx5: mlx5_core_create_cq() enhancements
      net/mlx5: Expose the API to register for ANY event
      net/mlx5: Use event mask based on device capabilities
      net/mlx5: Fix mlx5_core_destroy_cq() error flow
      net/mlx5: E-Switch, Handle UC address change in switchdev mode
      net/mlx5: E-Switch, Consider host PF for inline mode and vlan pop
      net/mlx5: E-Switch, Use iterator for vlan and min-inline setups
      net/mlx5: E-Switch, Reg/unreg function changed event at correct stage
      net/mlx5: E-Switch, Consolidate eswitch function number of VFs
      net/mlx5: E-Switch, Refactor eswitch SR-IOV interface
      net/mlx5: Handle host PF vport mac/guid for ECPF
      net/mlx5: E-Switch, Use correct flags when configuring vlan
      net/mlx5: Reduce dependency on enabled_vfs counter and num_vfs
      net/mlx5: Don't handle VF func change if host PF is disabled
      net/mlx5: Limit scope of mlx5_get_next_phys_dev() to PCI PF devices
      net/mlx5: Move pci status reg access mutex to mlx5_pci_init
      net/mlx5: Rename mlx5_pci_dev_type to mlx5_coredev_type
      ...
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 792c4e9d0bbb53b34bf1c07c2ef25609d746c57d
Author: Matthew Wilcox <willy@infradead.org>
Date:   Thu Jun 20 07:03:47 2019 +0000

    net/mlx5: Convert mkey_table to XArray
    
    The lock protecting the data structure does not need to be an rwlock.  The
    only read access to the lock is in an error path, and if that's limiting
    your scalability, you have bigger performance problems.
    
    Eliminate mlx5_mkey_table in favour of using the xarray directly.
    reg_mr_callback must use GFP_ATOMIC for allocating XArray nodes as it may
    be called in interrupt context.
    
    This also fixes a minor bug where SRCU locking was being used on the radix
    tree read side, when RCU was needed too.
    
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 3ba4edbd17a6..d1f353c64797 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -551,11 +551,6 @@ static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u
 	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
 }
 
-static inline struct mlx5_core_mkey *__mlx5_mr_lookup(struct mlx5_core_dev *dev, u32 key)
-{
-	return radix_tree_lookup(&dev->priv.mkey_table.tree, key);
-}
-
 int mlx5_core_create_dct(struct mlx5_core_dev *dev,
 			 struct mlx5_core_dct *qp,
 			 u32 *in, int inlen,

commit 38ca87c6f1e514686d4a385246d1afe1e1f2e482
Author: Max Gurtovoy <maxg@mellanox.com>
Date:   Tue Jun 11 18:52:46 2019 +0300

    RDMA/mlx5: Introduce and implement new IB_WR_REG_MR_INTEGRITY work request
    
    This new WR will be used to perform PI (protection information) handover
    using the new API. Using the new API, the user will post a single WR that
    will internally perform all the needed actions to complete PI operation.
    This new WR will use a memory region that was allocated as
    IB_MR_TYPE_INTEGRITY and was mapped using ib_map_mr_sg_pi to perform the
    registration. In the old API, in order to perform a signature handover
    operation, each ULP should perform the following:
    1. Map and register the data buffers.
    2. Map and register the protection buffers.
    3. Post a special reg WR to configure the signature handover operation
       layout.
    4. Invalidate the signature memory key.
    5. Invalidate protection buffers memory key.
    6. Invalidate data buffers memory key.
    
    In the new API, the mapping of both data and protection buffers is
    performed using a single call to ib_map_mr_sg_pi function. Also the
    registration of the buffers and the configuration of the signature
    operation layout is done by a single new work request called
    IB_WR_REG_MR_INTEGRITY.
    This patch implements this operation for mlx5 devices that are capable to
    offload data integrity generation/validation while performing the actual
    buffer transfer.
    This patch will not remove the old signature API that is used by the iSER
    initiator and target drivers. This will be done in the future.
    
    In the internal implementation, for each IB_WR_REG_MR_INTEGRITY work
    request, we are using a single UMR operation to register both data and
    protection buffers using KLM's.
    Afterwards, another UMR operation will describe the strided block format.
    These will be followed by 2 SET_PSV operations to set the memory/wire
    domains initial signature parameters passed by the user.
    In the end of the whole transaction, only the signature memory key
    (the one that exposed for the RDMA operation) will be invalidated.
    
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 3ba4edbd17a6..08e43cd9e742 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -37,7 +37,8 @@
 #include <linux/mlx5/driver.h>
 
 #define MLX5_INVALID_LKEY	0x100
-#define MLX5_SIG_WQE_SIZE	(MLX5_SEND_WQE_BB * 5)
+/* UMR (3 WQE_BB's) + SIG (3 WQE_BB's) + PSV (mem) + PSV (wire) */
+#define MLX5_SIG_WQE_SIZE	(MLX5_SEND_WQE_BB * 8)
 #define MLX5_DIF_SIZE		8
 #define MLX5_STRIDE_BLOCK_OP	0x400
 #define MLX5_CPY_GRD_MASK	0xc0

commit c2273219baa5097a4d7c1c162b992623534f34c1
Author: Shay Agroskin <shayag@mellanox.com>
Date:   Thu Mar 14 14:54:07 2019 +0200

    net/mlx5e: XDP, Inline small packets into the TX MPWQE in XDP xmit flow
    
    Upon high packet rate with multiple CPUs TX workloads, much of the HCA's
    resources are spent on prefetching TX descriptors, thus affecting
    transmission rates.
    This patch comes to mitigate this problem by moving some workload to the
    CPU and reducing the HW data prefetch overhead for small packets (<= 256B).
    
    When forwarding packets with XDP, a packet that is smaller
    than a certain size (set to ~256 bytes) would be sent inline within
    its WQE TX descrptor (mem-copied), when the hardware tx queue is congested
    beyond a pre-defined water-mark.
    
    This is added to better utilize the HW resources (which now makes
    one less packet data prefetch) and allow better scalability, on the
    account of CPU usage (which now 'memcpy's the packet into the WQE).
    
    To load balance between HW and CPU and get max packet rate, we use
    watermarks to detect how much the HW is congested and move the work
    loads back and forth between HW and CPU.
    
    Performance:
    Tested packet rate for UDP 64Byte multi-stream
    over two dual port ConnectX-5 100Gbps NICs.
    CPU: Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    
    * Tested with hyper-threading disabled
    
    XDP_TX:
    
    |          | before | after   |       |
    | 24 rings | 51Mpps | 116Mpps | +126% |
    | 1 ring   | 12Mpps | 12Mpps  | same  |
    
    XDP_REDIRECT:
    
    ** Below is the transmit rate, not the redirection rate
    which might be larger, and is not affected by this patch.
    
    |          | before  | after   |      |
    | 32 rings | 64Mpps  | 92Mpps  | +43% |
    | 1 ring   | 6.4Mpps | 6.4Mpps | same |
    
    As we can see, feature significantly improves scaling, without
    hurting single ring performance.
    
    Signed-off-by: Shay Agroskin <shayag@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 0343c81d4c5f..3ba4edbd17a6 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -395,6 +395,7 @@ struct mlx5_wqe_signature_seg {
 
 struct mlx5_wqe_inline_seg {
 	__be32	byte_count;
+	__be32	data[0];
 };
 
 enum mlx5_sig_type {

commit c5ae1954c47d3fd8815bd5a592aba18702c93f33
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Wed Mar 6 19:21:42 2019 +0200

    IB/mlx5: Use mlx5 core to create/destroy a DEVX DCT
    
    To prevent a hardware memory leak when a DEVX DCT object is destroyed
    without calling DRAIN DCT before, (e.g. under cleanup flow), need to
    manage its creation and destruction via mlx5 core.
    
    In that case the DRAIN DCT command will be called and only once that it
    will be completed the DESTROY DCT command will be called.  Otherwise, the
    DESTROY DCT may fail and a hardware leak may occur.
    
    As of that change the DRAIN DCT command should not be exposed any more
    from DEVX, it's managed internally by the driver to work as expected by
    the device specification.
    
    Fixes: 7efce3691d33 ("IB/mlx5: Add obj create and destroy functionality")
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index b26ea9077384..0343c81d4c5f 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -557,7 +557,8 @@ static inline struct mlx5_core_mkey *__mlx5_mr_lookup(struct mlx5_core_dev *dev,
 
 int mlx5_core_create_dct(struct mlx5_core_dev *dev,
 			 struct mlx5_core_dct *qp,
-			 u32 *in, int inlen);
+			 u32 *in, int inlen,
+			 u32 *out, int outlen);
 int mlx5_core_create_qp(struct mlx5_core_dev *dev,
 			struct mlx5_core_qp *qp,
 			u32 *in,

commit 27e95603f4dfec470c6d26bea5174aa71b30e971
Author: Moni Shoua <monis@mellanox.com>
Date:   Thu Nov 8 21:10:10 2018 +0200

    net/mlx5: Add interface to hold and release core resources
    
    Sometimes upper layers may want to prevent the destruction of a core
    resource for a period of time while work on that resource is in
    progress.  Add API to support this.
    
    Signed-off-by: Moni Shoua <monis@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index fbe322c966bc..b26ea9077384 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -596,6 +596,11 @@ int mlx5_core_dealloc_q_counter(struct mlx5_core_dev *dev, u16 counter_id);
 int mlx5_core_query_q_counter(struct mlx5_core_dev *dev, u16 counter_id,
 			      int reset, void *out, int out_size);
 
+struct mlx5_core_rsc_common *mlx5_core_res_hold(struct mlx5_core_dev *dev,
+						int res_num,
+						enum mlx5_res_type res_type);
+void mlx5_core_res_put(struct mlx5_core_rsc_common *res);
+
 static inline const char *mlx5_qp_type_str(int type)
 {
 	switch (type) {

commit 4ac63ec72587f7426aae15ddfe78e8ab785724dc
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Thu Sep 20 21:35:21 2018 +0300

    net/mlx5: Set uid as part of QP commands
    
    Set uid as part of QP commands so that the firmware can manage the
    QP object in a secured way.
    
    That will enable using a QP that was created by verbs application to
    be used by the DEVX flow in case the uid is equal.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 4778d41085d4..fbe322c966bc 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -471,6 +471,7 @@ struct mlx5_core_qp {
 	int			qpn;
 	struct mlx5_rsc_debug	*dbg;
 	int			pid;
+	u16			uid;
 };
 
 struct mlx5_core_dct {

commit 57cda166bbe045151d46b2d1133fdf4afccb90ed
Author: Moni Shoua <monis@mellanox.com>
Date:   Tue Jan 2 16:19:28 2018 +0200

    net/mlx5: Add DCT command interface
    
    Add a missing command interface to work with a DCT. It includes: creating,
    destroying and get events for.
    
    Signed-off-by: Moni Shoua <monis@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 62af7512dabb..4778d41085d4 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -473,6 +473,11 @@ struct mlx5_core_qp {
 	int			pid;
 };
 
+struct mlx5_core_dct {
+	struct mlx5_core_qp	mqp;
+	struct completion	drained;
+};
+
 struct mlx5_qp_path {
 	u8			fl_free_ar;
 	u8			rsvd3;
@@ -549,6 +554,9 @@ static inline struct mlx5_core_mkey *__mlx5_mr_lookup(struct mlx5_core_dev *dev,
 	return radix_tree_lookup(&dev->priv.mkey_table.tree, key);
 }
 
+int mlx5_core_create_dct(struct mlx5_core_dev *dev,
+			 struct mlx5_core_dct *qp,
+			 u32 *in, int inlen);
 int mlx5_core_create_qp(struct mlx5_core_dev *dev,
 			struct mlx5_core_qp *qp,
 			u32 *in,
@@ -558,8 +566,12 @@ int mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 opcode,
 			struct mlx5_core_qp *qp);
 int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
 			 struct mlx5_core_qp *qp);
+int mlx5_core_destroy_dct(struct mlx5_core_dev *dev,
+			  struct mlx5_core_dct *dct);
 int mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
 		       u32 *out, int outlen);
+int mlx5_core_dct_query(struct mlx5_core_dev *dev, struct mlx5_core_dct *dct,
+			u32 *out, int outlen);
 
 int mlx5_core_set_delay_drop(struct mlx5_core_dev *dev,
 			     u32 timeout_usec);

commit 4382c7b92a1db397874ca62c73aa8b023af6dba8
Author: Gal Pressman <galp@mellanox.com>
Date:   Sun Sep 10 13:22:51 2017 +0300

    net/mlx5e: Add 802.1ad VLAN insertion support
    
    Report VLAN insertion support for S-tagged packets and add support by
    choosing the correct VLAN type in the WQE.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 66d19b611fe4..62af7512dabb 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -221,6 +221,7 @@ enum {
 };
 
 enum {
+	MLX5_ETH_WQE_SVLAN              = 1 << 0,
 	MLX5_ETH_WQE_INSERT_VLAN        = 1 << 15,
 };
 

commit 3fffc82ad6c78fcc9d5d4eca089f00db14ab0358
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Mon Jun 12 10:36:16 2017 +0300

    IB/mlx5: Fix existence check for extended address vector
    
    The extended address vector is the highest bit in be32 variable,
    but it was compared with the lowest. This patch fixes the endianness
    of that check and removes already declared define.
    
    Fixes: 17d2f88f92ce ("IB/mlx5: Add ODP atomics support")
    Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index fff4ec13f620..66d19b611fe4 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -212,7 +212,6 @@ struct mlx5_wqe_ctrl_seg {
 #define MLX5_WQE_CTRL_OPCODE_MASK 0xff
 #define MLX5_WQE_CTRL_WQE_INDEX_MASK 0x00ffff00
 #define MLX5_WQE_CTRL_WQE_INDEX_SHIFT 8
-#define MLX5_WQE_AV_EXT 0x80000000
 
 enum {
 	MLX5_ETH_WQE_L3_INNER_CSUM      = 1 << 4,

commit c1e0bfc1312d0e06bdb24e6e4e7e10b0b4313ec6
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Tue May 30 10:29:11 2017 +0300

    net/mlx5: Introduce set delay drop command
    
    Add support to SET_DELAY_DROP command.
    
    This command will be used in downstream patches for delay packet drop.
    The timeout value should be indicated by delay_drop_timeout field.
    Packet processing will be delayed till timeout value passed or until
    more WQEs are posted.
    
    Setting this value to 0 disables the feature.
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 6f41270d80c0..fff4ec13f620 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -561,6 +561,9 @@ int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
 int mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
 		       u32 *out, int outlen);
 
+int mlx5_core_set_delay_drop(struct mlx5_core_dev *dev,
+			     u32 timeout_usec);
+
 int mlx5_core_xrcd_alloc(struct mlx5_core_dev *dev, u32 *xrcdn);
 int mlx5_core_xrcd_dealloc(struct mlx5_core_dev *dev, u32 xrcdn);
 void mlx5_init_qp_table(struct mlx5_core_dev *dev);

commit 547eede070eb981f1442e494f08f4567dcf1d1c7
Author: Ilan Tayari <ilant@mellanox.com>
Date:   Tue Apr 18 16:04:28 2017 +0300

    net/mlx5e: IPSec, Innova IPSec offload infrastructure
    
    Add Innova IPSec ESP crypto offload configuration paths.
    Detect Innova IPSec device and set the NETIF_F_HW_ESP flag.
    Configure Security Associations using the API introduced in a previous
    patch.
    
    Add Software-parser hardware descriptor layout
    Software-Parser (swp) is a hardware feature in ConnectX which allows the
    host software to specify protocol header offsets in the TX path, thus
    overriding the hardware parser.
    This is useful for protocols that the ASIC may not be able to parse on
    its own.
    
    Note that due to inline metadata, XDP is not supported in Innova IPSec.
    
    Signed-off-by: Ilan Tayari <ilant@mellanox.com>
    Signed-off-by: Yossi Kuperman <yossiku@mellanox.com>
    Signed-off-by: Yevgeny Kliteynik <kliteyn@mellanox.com>
    Signed-off-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 1f637f4d1265..6f41270d80c0 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -225,10 +225,20 @@ enum {
 	MLX5_ETH_WQE_INSERT_VLAN        = 1 << 15,
 };
 
+enum {
+	MLX5_ETH_WQE_SWP_INNER_L3_IPV6  = 1 << 0,
+	MLX5_ETH_WQE_SWP_INNER_L4_UDP   = 1 << 1,
+	MLX5_ETH_WQE_SWP_OUTER_L3_IPV6  = 1 << 4,
+	MLX5_ETH_WQE_SWP_OUTER_L4_UDP   = 1 << 5,
+};
+
 struct mlx5_wqe_eth_seg {
-	u8              rsvd0[4];
+	u8              swp_outer_l4_offset;
+	u8              swp_outer_l3_offset;
+	u8              swp_inner_l4_offset;
+	u8              swp_inner_l3_offset;
 	u8              cs_flags;
-	u8              rsvd1;
+	u8              swp_flags;
 	__be16          mss;
 	__be32          rsvd2;
 	union {

commit 432609a4cdfb1c3e3a58e6e37b3501e42bfc50ab
Author: Gal Pressman <galp@mellanox.com>
Date:   Wed Jun 14 11:52:33 2017 +0300

    net/mlx5e: Move and optimize query out of buffer function
    
    Move "query queue counter out of buffer" helper function out of
    qp.c to en_main.c, since mlx5e netdev driver is the only one to use it.
    
    Also allocate the output buffer on the stack instead of the heap, to reduce
    number of heap allocs on update_stats work.
    
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Cc: kernel-team@fb.com

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index bef80d0a0e30..1f637f4d1265 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -569,8 +569,6 @@ int mlx5_core_alloc_q_counter(struct mlx5_core_dev *dev, u16 *counter_id);
 int mlx5_core_dealloc_q_counter(struct mlx5_core_dev *dev, u16 counter_id);
 int mlx5_core_query_q_counter(struct mlx5_core_dev *dev, u16 counter_id,
 			      int reset, void *out, int out_size);
-int mlx5_core_query_out_of_buffer(struct mlx5_core_dev *dev, u16 counter_id,
-				  u32 *out_of_buffer);
 
 static inline const char *mlx5_qp_type_str(int type)
 {

commit 258545449b7b410727b516b782256f8a3bde8bf2
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Apr 13 06:37:02 2017 +0300

    net/mlx5e: IPoIB, Xmit flow
    
    Implement mlx5e's IPoIB SKB transmit using the helper functions provided
    by mlx5e ethernet tx flow, the only difference in the code between
    mlx5e_xmit and mlx5i_xmit is that IPoIB has some extra fields to fill
    (UD datagram segment) in the TX descriptor (WQE) and it doesn't need to
    have any vlan handling.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 3096370fe831..bef80d0a0e30 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -295,6 +295,16 @@ struct mlx5_av {
 	u8	rgid[16];
 };
 
+struct mlx5_ib_ah {
+	struct ib_ah		ibah;
+	struct mlx5_av		av;
+};
+
+static inline struct mlx5_ib_ah *to_mah(struct ib_ah *ibah)
+{
+	return container_of(ibah, struct mlx5_ib_ah, ibah);
+}
+
 struct mlx5_wqe_datagram_seg {
 	struct mlx5_av	av;
 };

commit 2b31f7ae5f645edd852addfca445895b5806f3f9
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Nov 28 18:04:50 2016 +0200

    net/mlx5: TX WQE update
    
    Add new TX WQE fields for Connect-X5 vlan insertion support,
    type and vlan_tci, when type = MLX5_ETH_WQE_INSERT_VLAN the
    HW will insert the vlan and prio fields (vlan_tci) to the packet.
    
    Those bits and the inline header fields are mutually exclusive, and
    valid only when:
    MLX5_CAP_ETH(mdev, wqe_inline_mode) == MLX5_CAP_INLINE_MODE_NOT_REQUIRED
    and MLX5_CAP_ETH(mdev, wqe_vlan_insert),
    who will be set in ConnectX-5 and later HW generations.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 219c699c17b7..3096370fe831 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -221,14 +221,26 @@ enum {
 	MLX5_ETH_WQE_L4_CSUM            = 1 << 7,
 };
 
+enum {
+	MLX5_ETH_WQE_INSERT_VLAN        = 1 << 15,
+};
+
 struct mlx5_wqe_eth_seg {
 	u8              rsvd0[4];
 	u8              cs_flags;
 	u8              rsvd1;
 	__be16          mss;
 	__be32          rsvd2;
-	__be16          inline_hdr_sz;
-	u8              inline_hdr_start[2];
+	union {
+		struct {
+			__be16 sz;
+			u8     start[2];
+		} inline_hdr;
+		struct {
+			__be16 type;
+			__be16 vlan_tci;
+		} insert;
+	};
 };
 
 struct mlx5_wqe_xrc_seg {

commit 17d2f88f92ce39b348f125f6b2e6eeb6b0906ac7
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Mon Jan 2 11:37:47 2017 +0200

    IB/mlx5: Add ODP atomics support
    
    Handle ODP atomic operations. When initiator of RDMA atomic
    operation use ODP MR to provide source data handle pagefault properly.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 9ed775f5cb66..219c699c17b7 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -212,6 +212,7 @@ struct mlx5_wqe_ctrl_seg {
 #define MLX5_WQE_CTRL_OPCODE_MASK 0xff
 #define MLX5_WQE_CTRL_WQE_INDEX_MASK 0x00ffff00
 #define MLX5_WQE_CTRL_WQE_INDEX_SHIFT 8
+#define MLX5_WQE_AV_EXT 0x80000000
 
 enum {
 	MLX5_ETH_WQE_L3_INNER_CSUM      = 1 << 4,
@@ -242,6 +243,23 @@ struct mlx5_wqe_masked_atomic_seg {
 	__be64			compare_mask;
 };
 
+struct mlx5_base_av {
+	union {
+		struct {
+			__be32	qkey;
+			__be32	reserved;
+		} qkey;
+		__be64	dc_key;
+	} key;
+	__be32	dqp_dct;
+	u8	stat_rate_sl;
+	u8	fl_mlid;
+	union {
+		__be16	rlid;
+		__be16  udp_sport;
+	};
+};
+
 struct mlx5_av {
 	union {
 		struct {

commit d9aaed838765e28234cb700c7d1ac975cadf28c9
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Mon Jan 2 11:37:46 2017 +0200

    {net,IB}/mlx5: Refactor page fault handling
    
    * Update page fault event according to last specification.
    * Separate code path for page fault EQ, completion EQ and async EQ.
    * Move page fault handling work queue from mlx5_ib static variable
      into mlx5_core page fault EQ.
    * Allocate memory to store ODP event dynamically as the
      events arrive, since in atomic context - use mempool.
    * Make mlx5_ib page fault handler run in process context.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 693811e0cb24..9ed775f5cb66 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -50,9 +50,6 @@
 #define MLX5_BSF_APPTAG_ESCAPE	0x1
 #define MLX5_BSF_APPREF_ESCAPE	0x2
 
-#define MLX5_QPN_BITS		24
-#define MLX5_QPN_MASK		((1 << MLX5_QPN_BITS) - 1)
-
 enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,
 	MLX5_QP_OPTPAR_RRE			= 1 << 1,
@@ -418,46 +415,9 @@ struct mlx5_stride_block_ctrl_seg {
 	__be16		num_entries;
 };
 
-enum mlx5_pagefault_flags {
-	MLX5_PFAULT_REQUESTOR = 1 << 0,
-	MLX5_PFAULT_WRITE     = 1 << 1,
-	MLX5_PFAULT_RDMA      = 1 << 2,
-};
-
-/* Contains the details of a pagefault. */
-struct mlx5_pagefault {
-	u32			bytes_committed;
-	u8			event_subtype;
-	enum mlx5_pagefault_flags flags;
-	union {
-		/* Initiator or send message responder pagefault details. */
-		struct {
-			/* Received packet size, only valid for responders. */
-			u32	packet_size;
-			/*
-			 * WQE index. Refers to either the send queue or
-			 * receive queue, according to event_subtype.
-			 */
-			u16	wqe_index;
-		} wqe;
-		/* RDMA responder pagefault details */
-		struct {
-			u32	r_key;
-			/*
-			 * Received packet size, minimal size page fault
-			 * resolution required for forward progress.
-			 */
-			u32	packet_size;
-			u32	rdma_op_len;
-			u64	rdma_va;
-		} rdma;
-	};
-};
-
 struct mlx5_core_qp {
 	struct mlx5_core_rsc_common	common; /* must be first */
 	void (*event)		(struct mlx5_core_qp *, int);
-	void (*pfault_handler)(struct mlx5_core_qp *, struct mlx5_pagefault *);
 	int			qpn;
 	struct mlx5_rsc_debug	*dbg;
 	int			pid;
@@ -557,10 +517,6 @@ void mlx5_init_qp_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_qp_table(struct mlx5_core_dev *dev);
 int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
-#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
-int mlx5_core_page_fault_resume(struct mlx5_core_dev *dev, u32 qpn,
-				u8 context, int error);
-#endif
 int mlx5_core_create_rq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,
 				struct mlx5_core_qp *rq);
 void mlx5_core_destroy_rq_tracked(struct mlx5_core_dev *dev,

commit 3161625589c1d7c54e949d462f4d0c327664881a
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Mon Jan 2 11:37:42 2017 +0200

    IB/mlx5: Refactor UMR post send format
    
    * Update struct mlx5_wqe_umr_ctrl_seg.
    * Currenlty UMR send_flags aim only certain use cases: enabled/disable
      cached MR, modifying XLT for ODP. By making flags independent make UMR
      more flexible allowing arbitrary manipulations.
    * Since different UMR formats have different entry sizes UMR request
      should receive exact size of translation table update instead of
      number of entries. Rename field npages to xlt_size in struct mlx5_umr_wr
      and update relevant code accordingly.
    * Add support of length64 bit.
    
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 0aacb2a7480d..693811e0cb24 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -292,10 +292,14 @@ struct mlx5_wqe_data_seg {
 struct mlx5_wqe_umr_ctrl_seg {
 	u8		flags;
 	u8		rsvd0[3];
-	__be16		klm_octowords;
-	__be16		bsf_octowords;
+	__be16		xlt_octowords;
+	union {
+		__be16	xlt_offset;
+		__be16	bsf_octowords;
+	};
 	__be64		mkey_mask;
-	u8		rsvd1[32];
+	__be32		xlt_offset_47_16;
+	u8		rsvd1[28];
 };
 
 struct mlx5_seg_set_psv {
@@ -389,6 +393,10 @@ struct mlx5_bsf {
 	struct mlx5_bsf_inl	m_inl;
 };
 
+struct mlx5_mtt {
+	__be64		ptag;
+};
+
 struct mlx5_klm {
 	__be32		bcount;
 	__be32		key;

commit 1a412fb1caa2c1b77719ccb5ed8b0c3c2bc65da7
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Jul 19 18:03:21 2016 +0300

    {net,IB}/mlx5: Modify QP commands via mlx5 ifc
    
    Prior to this patch we assumed that modify QP commands have the
    same layout.
    
    In ConnectX-4 for each QP transition there is a specific command
    and their layout can vary.
    
    e.g: 2err/2rst commands don't have QP context in their layout and before
    this patch we posted the QP context in those commands.
    
    Fortunately the FW only checks the suffix of the commands and executes
    them, while ignoring all invalid data sent after the valid command
    layout.
    
    This patch removes mlx5_modify_qp_mbox_in and changes
    mlx5_core_qp_modify to receive the required transition and QP context
    with opt_param_mask if needed.  This way the caller is not required to
    provide the command inbox layout and it will be generated automatically.
    
    mlx5_core_qp_modify will generate the command inbox/outbox layouts
    according to the requested transition and will fill the requested
    parameters.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 16e1efecaf66..0aacb2a7480d 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -479,6 +479,7 @@ struct mlx5_qp_path {
 	u8			rmac[6];
 };
 
+/* FIXME: use mlx5_ifc.h qpc */
 struct mlx5_qp_context {
 	__be32			flags;
 	__be32			flags_pd;
@@ -520,21 +521,6 @@ struct mlx5_qp_context {
 	u8			rsvd1[24];
 };
 
-struct mlx5_modify_qp_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	__be32			qpn;
-	u8			rsvd0[4];
-	__be32			optparam;
-	u8			rsvd1[4];
-	struct mlx5_qp_context	ctx;
-	u8			rsvd2[16];
-};
-
-struct mlx5_modify_qp_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	u8			rsvd0[8];
-};
-
 static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u32 qpn)
 {
 	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
@@ -549,8 +535,8 @@ int mlx5_core_create_qp(struct mlx5_core_dev *dev,
 			struct mlx5_core_qp *qp,
 			u32 *in,
 			int inlen);
-int mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 operation,
-			struct mlx5_modify_qp_mbox_in *in, int sqd_event,
+int mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 opcode,
+			u32 opt_param_mask, void *qpc,
 			struct mlx5_core_qp *qp);
 int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
 			 struct mlx5_core_qp *qp);

commit 09a7d9eca1a6cf5eb4f9abfdf8914db9dbd96f08
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Tue Jul 19 01:17:59 2016 +0300

    {net,IB}/mlx5: QP/XRCD commands via mlx5 ifc
    
    Remove old representation of manually created QP/XRCD commands layout
    amd use mlx5_ifc canonical structures and defines.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 7879bf411891..16e1efecaf66 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -123,12 +123,13 @@ enum {
 };
 
 enum {
-	MLX5_NON_ZERO_RQ	= 0 << 24,
-	MLX5_SRQ_RQ		= 1 << 24,
-	MLX5_CRQ_RQ		= 2 << 24,
-	MLX5_ZERO_LEN_RQ	= 3 << 24
+	MLX5_NON_ZERO_RQ	= 0x0,
+	MLX5_SRQ_RQ		= 0x1,
+	MLX5_CRQ_RQ		= 0x2,
+	MLX5_ZERO_LEN_RQ	= 0x3
 };
 
+/* TODO REM */
 enum {
 	/* params1 */
 	MLX5_QP_BIT_SRE				= 1 << 15,
@@ -177,12 +178,6 @@ enum {
 	MLX5_FENCE_MODE_SMALL_AND_FENCE		= 4 << 5,
 };
 
-enum {
-	MLX5_QP_LAT_SENSITIVE	= 1 << 28,
-	MLX5_QP_BLOCK_MCAST	= 1 << 30,
-	MLX5_QP_ENABLE_SIG	= 1 << 31,
-};
-
 enum {
 	MLX5_RCV_DBR	= 0,
 	MLX5_SND_DBR	= 1,
@@ -525,34 +520,6 @@ struct mlx5_qp_context {
 	u8			rsvd1[24];
 };
 
-struct mlx5_create_qp_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	__be32			input_qpn;
-	u8			rsvd0[4];
-	__be32			opt_param_mask;
-	u8			rsvd1[4];
-	struct mlx5_qp_context	ctx;
-	u8			rsvd3[16];
-	__be64			pas[0];
-};
-
-struct mlx5_create_qp_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	__be32			qpn;
-	u8			rsvd0[4];
-};
-
-struct mlx5_destroy_qp_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	__be32			qpn;
-	u8			rsvd0[4];
-};
-
-struct mlx5_destroy_qp_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	u8			rsvd0[8];
-};
-
 struct mlx5_modify_qp_mbox_in {
 	struct mlx5_inbox_hdr	hdr;
 	__be32			qpn;
@@ -568,56 +535,6 @@ struct mlx5_modify_qp_mbox_out {
 	u8			rsvd0[8];
 };
 
-struct mlx5_query_qp_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	__be32			qpn;
-	u8			rsvd[4];
-};
-
-struct mlx5_query_qp_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	u8			rsvd1[8];
-	__be32			optparam;
-	u8			rsvd0[4];
-	struct mlx5_qp_context	ctx;
-	u8			rsvd2[16];
-	__be64			pas[0];
-};
-
-struct mlx5_conf_sqp_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	__be32			qpn;
-	u8			rsvd[3];
-	u8			type;
-};
-
-struct mlx5_conf_sqp_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	u8			rsvd[8];
-};
-
-struct mlx5_alloc_xrcd_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	u8			rsvd[8];
-};
-
-struct mlx5_alloc_xrcd_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	__be32			xrcdn;
-	u8			rsvd[4];
-};
-
-struct mlx5_dealloc_xrcd_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	__be32			xrcdn;
-	u8			rsvd[4];
-};
-
-struct mlx5_dealloc_xrcd_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	u8			rsvd[8];
-};
-
 static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u32 qpn)
 {
 	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
@@ -628,20 +545,9 @@ static inline struct mlx5_core_mkey *__mlx5_mr_lookup(struct mlx5_core_dev *dev,
 	return radix_tree_lookup(&dev->priv.mkey_table.tree, key);
 }
 
-struct mlx5_page_fault_resume_mbox_in {
-	struct mlx5_inbox_hdr	hdr;
-	__be32			flags_qpn;
-	u8			reserved[4];
-};
-
-struct mlx5_page_fault_resume_mbox_out {
-	struct mlx5_outbox_hdr	hdr;
-	u8			rsvd[8];
-};
-
 int mlx5_core_create_qp(struct mlx5_core_dev *dev,
 			struct mlx5_core_qp *qp,
-			struct mlx5_create_qp_mbox_in *in,
+			u32 *in,
 			int inlen);
 int mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 operation,
 			struct mlx5_modify_qp_mbox_in *in, int sqd_event,
@@ -649,7 +555,7 @@ int mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 operation,
 int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
 			 struct mlx5_core_qp *qp);
 int mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
-		       struct mlx5_query_qp_mbox_out *out, int outlen);
+		       u32 *out, int outlen);
 
 int mlx5_core_xrcd_alloc(struct mlx5_core_dev *dev, u32 *xrcdn);
 int mlx5_core_xrcd_dealloc(struct mlx5_core_dev *dev, u32 xrcdn);

commit 0cda611386b2fcbf8bb32e9a5d82bfed4856fc36
Merge: fdf1f7ff1bd7 7f1d25b47d91
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 4 20:10:31 2016 -0400

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull base rdma updates from Doug Ledford:
     "Round one of 4.8 code: while this is mostly normal, there is a new
      driver in here (the driver was hosted outside the kernel for several
      years and is actually a fairly mature and well coded driver).  It
      amounts to 13,000 of the 16,000 lines of added code in here.
    
      Summary:
    
       - Updates/fixes for iw_cxgb4 driver
       - Updates/fixes for mlx5 driver
       - Add flow steering and RSS API
       - Add hardware stats to mlx4 and mlx5 drivers
       - Add firmware version API for RDMA driver use
       - Add the rxe driver (this is a software RoCE driver that makes any
         Ethernet device a RoCE device)
       - Fixes for i40iw driver
       - Support for send only multicast joins in the cma layer
       - Other minor fixes"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (72 commits)
      Soft RoCE driver
      IB/core: Support for CMA multicast join flags
      IB/sa: Add cached attribute containing SM information to SA port
      IB/uverbs: Fix race between uverbs_close and remove_one
      IB/mthca: Clean up error unwind flow in mthca_reset()
      IB/mthca: NULL arg to pci_dev_put is OK
      IB/hfi1: NULL arg to sc_return_credits is OK
      IB/mlx4: Add diagnostic hardware counters
      net/mlx4: Query performance and diagnostics counters
      net/mlx4: Add diagnostic counters capability bit
      Use smaller 512 byte messages for portmapper messages
      IB/ipoib: Report SG feature regardless of HW UD CSUM capability
      IB/mlx4: Don't use GFP_ATOMIC for CQ resize struct
      IB/hfi1: Disable by default
      IB/rdmavt: Disable by default
      IB/mlx5: Fix port counter ID association to QP offset
      IB/mlx5: Fix iteration overrun in GSI qps
      i40iw: Add NULL check for puda buffer
      i40iw: Change dup_ack_thresh to u8
      i40iw: Remove unnecessary check for moving CQ head
      ...

commit aebe9bb85e6358dc85f81533b14f5c2dfe14c8b4
Merge: 3fb5e59c8887 9903fd1374e9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 24 18:52:31 2016 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull rdma fixes from Doug Ledford:
     "This is the second batch of queued up rdma patches for this rc cycle.
    
      There isn't anything really major in here.  It's passed 0day,
      linux-next, and local testing across a wide variety of hardware.
      There are still a few known issues to be tracked down, but this should
      amount to the vast majority of the rdma RC fixes.
    
      Round two of 4.7 rc fixes:
    
       - A couple minor fixes to the rdma core
       - Multiple minor fixes to hfi1
       - Multiple minor fixes to mlx4/mlx4
       - A few minor fixes to i40iw"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (31 commits)
      IB/srpt: Reduce QP buffer size
      i40iw: Enable level-1 PBL for fast memory registration
      i40iw: Return correct max_fast_reg_page_list_len
      i40iw: Correct status check on i40iw_get_pble
      i40iw: Correct CQ arming
      IB/rdmavt: Correct qp_priv_alloc() return value test
      IB/hfi1: Don't zero out qp->s_ack_queue in rvt_reset_qp
      IB/hfi1: Fix deadlock with txreq allocation slow path
      IB/mlx4: Prevent cross page boundary allocation
      IB/mlx4: Fix memory leak if QP creation failed
      IB/mlx4: Verify port number in flow steering create flow
      IB/mlx4: Fix error flow when sending mads under SRIOV
      IB/mlx4: Fix the SQ size of an RC QP
      IB/mlx5: Fix wrong naming of port_rcv_data counter
      IB/mlx5: Fix post send fence logic
      IB/uverbs: Initialize ib_qp_init_attr with zeros
      IB/core: Fix false search of the IB_SA_WELL_KNOWN_GUID
      IB/core: Fix RoCE v1 multicast join logic issue
      IB/core: Fix no default GIDs when netdevice reregisters
      IB/hfi1: Send a pkey change event on driver pkey update
      ...

commit e3353c268b06236d6c40fa1714c114f21f44451c
Author: Artemy Kovalyov <artemyko@mellanox.com>
Date:   Fri Jun 17 15:33:31 2016 +0300

    IB/mlx5: Fix MODIFY_QP command input structure
    
    Make MODIFY_QP command input structure compliant to specification
    
    Fixes: e126ba97dba9 ('mlx5: Add driver for Mellanox Connect-IB adapters')
    Signed-off-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 266320feb160..acb28c989dee 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -555,9 +555,9 @@ struct mlx5_destroy_qp_mbox_out {
 struct mlx5_modify_qp_mbox_in {
 	struct mlx5_inbox_hdr	hdr;
 	__be32			qpn;
-	u8			rsvd1[4];
-	__be32			optparam;
 	u8			rsvd0[4];
+	__be32			optparam;
+	u8			rsvd1[4];
 	struct mlx5_qp_context	ctx;
 	u8			rsvd2[16];
 };

commit c9b254955b9f8814966f5dabd34c39d0e0a2b437
Author: Eli Cohen <eli@mellanox.com>
Date:   Wed Jun 22 17:27:26 2016 +0300

    IB/mlx5: Fix post send fence logic
    
    If the caller specified IB_SEND_FENCE in the send flags of the work
    request and no previous work request stated that the successive one
    should be fenced, the work request would be executed without a fence.
    This could result in RDMA read or atomic operations failure due to a MR
    being invalidated. Fix this by adding the mlx5 enumeration for fencing
    RDMA/atomic operations and fix the logic to apply this.
    
    Fixes: e126ba97dba9 ('mlx5: Add driver for Mellanox Connect-IB adapters')
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index e4e29882fdfd..630f66a186b7 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -172,6 +172,7 @@ enum {
 enum {
 	MLX5_FENCE_MODE_NONE			= 0 << 5,
 	MLX5_FENCE_MODE_INITIATOR_SMALL		= 1 << 5,
+	MLX5_FENCE_MODE_FENCE			= 2 << 5,
 	MLX5_FENCE_MODE_STRONG_ORDERING		= 3 << 5,
 	MLX5_FENCE_MODE_SMALL_AND_FENCE		= 4 << 5,
 };

commit 698ea54dde6768d4a96080d0fb796cb3a4eadaf8
Merge: 729d378479dd 50219538ffc0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 10 08:32:24 2016 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Pull networking fixes from David Miller:
    
     1) nfnetlink timestamp taken from wrong skb, fix from Florian Westphal.
    
     2) Revert some msleep conversions in rtlwifi as these spots are in
        atomic context, from Larry Finger.
    
     3) Validate that NFTA_SET_TABLE attribute is actually specified when we
        call nf_tables_getset().  From Phil Turnbull.
    
     4) Don't do mdio_reset in stmmac driver with spinlock held as that can
        sleep, from Vincent Palatin.
    
     5) sk_filter() does things other than run a BPF filter, so we should
        not elide it's call just because sk->sk_filter is NULL.  Fix from
        Eric Dumazet.
    
     6) Fix missing backlog updates in several packet schedulers, from Cong
        Wang.
    
     7) bnx2x driver should allow VLAN add/remove while the interface is
        down, from Michal Schmidt.
    
     8) Several RDS/TCP race fixes from Sowmini Varadhan.
    
     9) fq_codel scheduler doesn't return correct queue length in dumps,
        from Eric Dumazet.
    
    10) Fix TCP stats for tail loss probe and early retransmit in ipv6, from
        Yuchung Cheng.
    
    11) Properly initialize udp_tunnel_socket_cfg in l2tp_tunnel_create(),
        from Guillaume Nault.
    
    12) qfq scheduler leaks SKBs if a kzalloc fails, fix from Florian
        Westphal.
    
    13) sock_fprog passed into PACKET_FANOUT_DATA needs compat handling,
        from Willem de Bruijn.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net: (85 commits)
      vmxnet3: segCnt can be 1 for LRO packets
      packet: compat support for sock_fprog
      stmmac: fix parameter to dwmac4_set_umac_addr()
      net/mlx5e: Fix blue flame quota logic
      net/mlx5e: Use ndo_stop explicitly at shutdown flow
      net/mlx5: E-Switch, always set mc_promisc for allmulti vports
      net/mlx5: E-Switch, Modify node guid on vf set MAC
      net/mlx5: E-Switch, Fix vport enable flow
      net/mlx5: E-Switch, Use the correct error check on returned pointers
      net/mlx5: E-Switch, Use the correct free() function
      net/mlx5: Fix E-Switch flow steering capabilities check
      net/mlx5: Fix flow steering NIC capabilities check
      net/mlx5: Fix root flow table update
      net/mlx5: Fix MLX5_CMD_OP_MAX to be defined correctly
      net/mlx5: Fix masking of reserved bits in XRCD number
      net/mlx5: Fix the size of modify QP mailbox
      mlxsw: spectrum: Don't sleep during ndo_get_phys_port_name()
      mlxsw: spectrum: Make split flow match firmware requirements
      wext: Fix 32 bit iwpriv compatibility issue with 64 bit Kernel
      cfg80211: remove get/set antenna and tx power warnings
      ...

commit 418f8399a8bedf376ec13eb01088f04a76ebdd6f
Author: Majd Dibbiny <majd@mellanox.com>
Date:   Fri Jun 10 00:07:28 2016 +0300

    net/mlx5: Fix the size of modify QP mailbox
    
    Add 16 reserved bytes at the end of mlx5_modify_qp_mbox_in to
    match the hardware spec definition.
    
    Fixes: e126ba97dba9 ('mlx5: Add driver for Mellanox Connect-IB adapters')
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 64221027bf1f..1532dcf6fc5e 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -560,6 +560,7 @@ struct mlx5_modify_qp_mbox_in {
 	__be32			optparam;
 	u8			rsvd0[4];
 	struct mlx5_qp_context	ctx;
+	u8			rsvd2[16];
 };
 
 struct mlx5_modify_qp_mbox_out {

commit d3ae2bdeba9bad8cb95301451aeaf03ce31e82f0
Author: Noa Osherovich <noaos@mellanox.com>
Date:   Sat Jun 4 15:15:36 2016 +0300

    IB/mlx5: Fix pkey_index length in the QP path record
    
    Pkey index fields in the QP context path record are extended to 16
    bits, as required by IB spec (version 1.3).
    This change affects all QP commands which include path records.
    
    To enable this change, moved the free adaptive routing flag bit
    (free_ar) to the most significant byte of the QP path record.
    
    Fixes: e126ba97dba9e ('mlx5: Add driver for Mellanox Connect-IB ...')
    Signed-off-by: Noa Osherovich <noaos@mellanox.com>
    Reviewed-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 64221027bf1f..e4e29882fdfd 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -460,10 +460,9 @@ struct mlx5_core_qp {
 };
 
 struct mlx5_qp_path {
-	u8			fl;
+	u8			fl_free_ar;
 	u8			rsvd3;
-	u8			free_ar;
-	u8			pkey_index;
+	__be16			pkey_index;
 	u8			rsvd0;
 	u8			grh_mlid;
 	__be16			rlid;

commit 237cd218099ce96edf2890a49aa191b38b84c2fc
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Apr 20 22:02:09 2016 +0300

    net/mlx5: Introduce device queue counters
    
    A queue counter can collect several statistics for one or more
    hardware queues (QPs, RQs, etc ..) that the counter is attached to.
    
    For Ethernet it will provide an "out of buffer" counter which
    collects the number of all packets that are dropped due to lack
    of software buffers.
    
    Here we add device commands to alloc/query/dealloc queue counters.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Rana Shahout <ranas@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index cf031a3f16c5..64221027bf1f 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -668,6 +668,12 @@ int mlx5_core_create_sq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,
 				struct mlx5_core_qp *sq);
 void mlx5_core_destroy_sq_tracked(struct mlx5_core_dev *dev,
 				  struct mlx5_core_qp *sq);
+int mlx5_core_alloc_q_counter(struct mlx5_core_dev *dev, u16 *counter_id);
+int mlx5_core_dealloc_q_counter(struct mlx5_core_dev *dev, u16 counter_id);
+int mlx5_core_query_q_counter(struct mlx5_core_dev *dev, u16 counter_id,
+			      int reset, void *out, int out_size);
+int mlx5_core_query_out_of_buffer(struct mlx5_core_dev *dev, u16 counter_id,
+				  u32 *out_of_buffer);
 
 static inline const char *mlx5_qp_type_str(int type)
 {

commit a606b0f6691daf861482f8b77326f672238ffbfd
Author: Matan Barak <matanb@mellanox.com>
Date:   Mon Feb 29 18:05:28 2016 +0200

    net/mlx5: Refactor mlx5_core_mr to mkey
    
    Mlx5's mkey mechanism is also used for memory windows.
    The current code base uses MR (memory region) naming, which is
    inaccurate. Changing MR to mkey in order to represent its different
    usages more accurately.
    
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index e5bbcf06de95..cf031a3f16c5 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -622,9 +622,9 @@ static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u
 	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
 }
 
-static inline struct mlx5_core_mr *__mlx5_mr_lookup(struct mlx5_core_dev *dev, u32 key)
+static inline struct mlx5_core_mkey *__mlx5_mr_lookup(struct mlx5_core_dev *dev, u32 key)
 {
-	return radix_tree_lookup(&dev->priv.mr_table.tree, key);
+	return radix_tree_lookup(&dev->priv.mkey_table.tree, key);
 }
 
 struct mlx5_page_fault_resume_mbox_in {

commit b11a4f9cde1c06e0073662882b60c1fb95a1d597
Author: Haggai Eran <haggaie@mellanox.com>
Date:   Mon Feb 29 15:45:03 2016 +0200

    IB/mlx5: Add support for setting source QP number
    
    In order to create multiple GSI QPs, we need to set the source QP number to
    one on all these QPs. Add the necessary definitions and infrastructure to
    do that.
    
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 5b8c89ffaa58..e5bbcf06de95 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -499,7 +499,8 @@ struct mlx5_qp_context {
 	u8			reserved2[4];
 	__be32			next_send_psn;
 	__be32			cqn_send;
-	u8			reserved3[8];
+	__be32			deth_sqpn;
+	u8			reserved3[4];
 	__be32			last_acked_psn;
 	__be32			ssn;
 	__be32			params2;

commit 427c1e7bcd7e5cd62160fcda0ce215ebbe0da3a1
Author: majd@mellanox.com <majd@mellanox.com>
Date:   Thu Jan 14 19:13:07 2016 +0200

    {IB, net}/mlx5: Move the modify QP operation table to mlx5_ib
    
    When modifying a QP, the desired operation was determined in
    the mlx5_core using a transition table that takes the current
    state, the final state, and returns the desired operation.
    
    Since this logic will be used for Raw Packet QP, move the
    operation table to the mlx5_ib.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index f033c7a1490c..5b8c89ffaa58 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -641,8 +641,7 @@ int mlx5_core_create_qp(struct mlx5_core_dev *dev,
 			struct mlx5_core_qp *qp,
 			struct mlx5_create_qp_mbox_in *in,
 			int inlen);
-int mlx5_core_qp_modify(struct mlx5_core_dev *dev, enum mlx5_qp_state cur_state,
-			enum mlx5_qp_state new_state,
+int mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 operation,
 			struct mlx5_modify_qp_mbox_in *in, int sqd_event,
 			struct mlx5_core_qp *qp);
 int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,

commit 6d2f89df04b796e7dcc4f9f8dc0d8f04ad7f144b
Author: majd@mellanox.com <majd@mellanox.com>
Date:   Thu Jan 14 19:13:05 2016 +0200

    IB/mlx5: Add Raw Packet QP query functionality
    
    Since Raw Packet QP is composed of RQ and SQ, the IB QP's
    state is derived from the sub-objects. Therefore we need
    to query each one of the sub-objects, and decide on the
    IB QP's state.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 431176ec70e2..f033c7a1490c 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -85,7 +85,16 @@ enum mlx5_qp_state {
 	MLX5_QP_STATE_ERR			= 6,
 	MLX5_QP_STATE_SQ_DRAINING		= 7,
 	MLX5_QP_STATE_SUSPENDED			= 9,
-	MLX5_QP_NUM_STATE
+	MLX5_QP_NUM_STATE,
+	MLX5_QP_STATE,
+	MLX5_QP_STATE_BAD,
+};
+
+enum {
+	MLX5_SQ_STATE_NA	= MLX5_SQC_STATE_ERR + 1,
+	MLX5_SQ_NUM_STATE	= MLX5_SQ_STATE_NA + 1,
+	MLX5_RQ_STATE_NA	= MLX5_RQC_STATE_ERR + 1,
+	MLX5_RQ_NUM_STATE	= MLX5_RQ_STATE_NA + 1,
 };
 
 enum {

commit e2013b212f9f201c71fc5826ce41f39ebece0852
Author: majd@mellanox.com <majd@mellanox.com>
Date:   Thu Jan 14 19:13:00 2016 +0200

    net/mlx5_core: Add RQ and SQ event handling
    
    RQ/SQ will be used to implement IB verbs QPs, so the IB QP affiliated
    events are affiliated also with SQs and RQs.
    
    Since SQ, RQ and QP resource numbers do not share the same name
    space, a queue type field was added to the event data to specify
    the SW object that the event is affiliated with.
    
    Signed-off-by: Majd Dibbiny <majd@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index fd1ff4110e80..431176ec70e2 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -651,6 +651,14 @@ void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 int mlx5_core_page_fault_resume(struct mlx5_core_dev *dev, u32 qpn,
 				u8 context, int error);
 #endif
+int mlx5_core_create_rq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,
+				struct mlx5_core_qp *rq);
+void mlx5_core_destroy_rq_tracked(struct mlx5_core_dev *dev,
+				  struct mlx5_core_qp *rq);
+int mlx5_core_create_sq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,
+				struct mlx5_core_qp *sq);
+void mlx5_core_destroy_sq_tracked(struct mlx5_core_dev *dev,
+				  struct mlx5_core_qp *sq);
 
 static inline const char *mlx5_qp_type_str(int type)
 {

commit 051f263098a90d208e2d20251bfd4834bc783214
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Sun Dec 20 12:16:11 2015 +0200

    IB/mlx5: Add driver cross-channel support
    
    Add support of cross-channel functionality to mlx5
    driver. This includes ability to ignore overrun for CQ
    which intended for cross-channel, export device capability and
    configure the QP to be sync master/slave queues.
    
    The cross-channel enabled QP supports combination of
    three possible properties:
    * WQE processing on the receive queue of this QP
    * WQE processing on the send queue of this QP
    * WQE are supported on the send queue
    
    Reviewed-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index a9ad40169191..fd1ff4110e80 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -130,6 +130,9 @@ enum {
 	MLX5_QP_BIT_RWE				= 1 << 14,
 	MLX5_QP_BIT_RAE				= 1 << 13,
 	MLX5_QP_BIT_RIC				= 1 <<	4,
+	MLX5_QP_BIT_CC_SLAVE_RECV		= 1 <<  2,
+	MLX5_QP_BIT_CC_SLAVE_SEND		= 1 <<  1,
+	MLX5_QP_BIT_CC_MASTER			= 1 <<  0
 };
 
 enum {

commit 2811ba51b04958cd001b6409c9f70e8563376346
Author: Achiad Shochat <achiad@mellanox.com>
Date:   Wed Dec 23 18:47:24 2015 +0200

    IB/mlx5: Add RoCE fields to Address Vector
    
    Set the address handle and QP address path fields according to the
    link layer type (IB/Eth).
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index f079fb1a31f7..a9ad40169191 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -248,8 +248,12 @@ struct mlx5_av {
 	__be32	dqp_dct;
 	u8	stat_rate_sl;
 	u8	fl_mlid;
-	__be16	rlid;
-	u8	reserved0[10];
+	union {
+		__be16	rlid;
+		__be16  udp_sport;
+	};
+	u8	reserved0[4];
+	u8	rmac[6];
 	u8	tclass;
 	u8	hop_limit;
 	__be32	grh_gid_fl;
@@ -456,11 +460,16 @@ struct mlx5_qp_path {
 	u8			static_rate;
 	u8			hop_limit;
 	__be32			tclass_flowlabel;
-	u8			rgid[16];
-	u8			rsvd1[4];
-	u8			sl;
+	union {
+		u8		rgid[16];
+		u8		rip[16];
+	};
+	u8			f_dscp_ecn_prio;
+	u8			ecn_dscp;
+	__be16			udp_sport;
+	u8			dci_cfi_prio_sl;
 	u8			port;
-	u8			rsvd2[6];
+	u8			rmac[6];
 };
 
 struct mlx5_qp_context {

commit e281682bf29438848daac11627216bceb1507b71
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu May 28 22:28:40 2015 +0300

    net/mlx5_core: HW data structs/types definitions cleanup
    
    mlx5_ifc.h was heavily modified here since it is now generated by a
    script from the device specification (PRM rev 0.25). This specification
    is backward compatible to existing hardware.
    
    Some structures/fields were added here in order to enable the Ethernet
    functionality of the driver.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 310b5f7fd6ae..f079fb1a31f7 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -134,13 +134,21 @@ enum {
 
 enum {
 	MLX5_WQE_CTRL_CQ_UPDATE		= 2 << 2,
+	MLX5_WQE_CTRL_CQ_UPDATE_AND_EQE	= 3 << 2,
 	MLX5_WQE_CTRL_SOLICITED		= 1 << 1,
 };
 
 enum {
+	MLX5_SEND_WQE_DS	= 16,
 	MLX5_SEND_WQE_BB	= 64,
 };
 
+#define MLX5_SEND_WQEBB_NUM_DS	(MLX5_SEND_WQE_BB / MLX5_SEND_WQE_DS)
+
+enum {
+	MLX5_SEND_WQE_MAX_WQEBBS	= 16,
+};
+
 enum {
 	MLX5_WQE_FMR_PERM_LOCAL_READ	= 1 << 27,
 	MLX5_WQE_FMR_PERM_LOCAL_WRITE	= 1 << 28,
@@ -200,6 +208,23 @@ struct mlx5_wqe_ctrl_seg {
 #define MLX5_WQE_CTRL_WQE_INDEX_MASK 0x00ffff00
 #define MLX5_WQE_CTRL_WQE_INDEX_SHIFT 8
 
+enum {
+	MLX5_ETH_WQE_L3_INNER_CSUM      = 1 << 4,
+	MLX5_ETH_WQE_L4_INNER_CSUM      = 1 << 5,
+	MLX5_ETH_WQE_L3_CSUM            = 1 << 6,
+	MLX5_ETH_WQE_L4_CSUM            = 1 << 7,
+};
+
+struct mlx5_wqe_eth_seg {
+	u8              rsvd0[4];
+	u8              cs_flags;
+	u8              rsvd1;
+	__be16          mss;
+	__be32          rsvd2;
+	__be16          inline_hdr_sz;
+	u8              inline_hdr_start[2];
+};
+
 struct mlx5_wqe_xrc_seg {
 	__be32			xrc_srqn;
 	u8			rsvd[12];

commit 302bdf68fc56a6330bc6b10ce435b4d466417537
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Apr 2 17:07:29 2015 +0300

    net/mlx5_core: Fix Mellanox copyright note
    
    Signed-off-by: Achiad Shochat <achiad@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 61f7a342d1bf..310b5f7fd6ae 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU

commit 7bdf65d411c1715d695be0d9a555d7f48d0a7220
Author: Haggai Eran <haggaie@mellanox.com>
Date:   Thu Dec 11 17:04:24 2014 +0200

    IB/mlx5: Handle page faults
    
    This patch implement a page fault handler (leaving the pages pinned as
    of time being).  The page fault handler handles initiator and responder
    page faults for UD/RC transports, for send/receive operations, as well
    as RDMA read/write initiator support.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Shachar Raindel <raindel@mellanox.com>
    Signed-off-by: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 6b1d6f60c7e6..61f7a342d1bf 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -193,7 +193,12 @@ struct mlx5_wqe_ctrl_seg {
 };
 
 #define MLX5_WQE_CTRL_DS_MASK 0x3f
+#define MLX5_WQE_CTRL_QPN_MASK 0xffffff00
+#define MLX5_WQE_CTRL_QPN_SHIFT 8
 #define MLX5_WQE_DS_UNITS 16
+#define MLX5_WQE_CTRL_OPCODE_MASK 0xff
+#define MLX5_WQE_CTRL_WQE_INDEX_MASK 0x00ffff00
+#define MLX5_WQE_CTRL_WQE_INDEX_SHIFT 8
 
 struct mlx5_wqe_xrc_seg {
 	__be32			xrc_srqn;
@@ -298,6 +303,8 @@ struct mlx5_wqe_signature_seg {
 	u8	rsvd1[11];
 };
 
+#define MLX5_WQE_INLINE_SEG_BYTE_COUNT_MASK 0x3ff
+
 struct mlx5_wqe_inline_seg {
 	__be32	byte_count;
 };

commit e420f0c0f3d1022789fcb59b2a0c4b979ce311ba
Author: Haggai Eran <haggaie@mellanox.com>
Date:   Thu Dec 11 17:04:19 2014 +0200

    mlx5_core: Add support for page faults events and low level handling
    
    * Add a handler function pointer in the mlx5_core_qp struct for page
      fault events. Handle page fault events by calling the handler
      function, if not NULL.
    * Add on-demand paging capability query command.
    * Export command for resuming QPs after page faults.
    * Add various constants related to paging support.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Shachar Raindel <raindel@mellanox.com>
    Signed-off-by: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 67f4b9660b06..6b1d6f60c7e6 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -50,6 +50,9 @@
 #define MLX5_BSF_APPTAG_ESCAPE	0x1
 #define MLX5_BSF_APPREF_ESCAPE	0x2
 
+#define MLX5_QPN_BITS		24
+#define MLX5_QPN_MASK		((1 << MLX5_QPN_BITS) - 1)
+
 enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,
 	MLX5_QP_OPTPAR_RRE			= 1 << 1,
@@ -363,9 +366,46 @@ struct mlx5_stride_block_ctrl_seg {
 	__be16		num_entries;
 };
 
+enum mlx5_pagefault_flags {
+	MLX5_PFAULT_REQUESTOR = 1 << 0,
+	MLX5_PFAULT_WRITE     = 1 << 1,
+	MLX5_PFAULT_RDMA      = 1 << 2,
+};
+
+/* Contains the details of a pagefault. */
+struct mlx5_pagefault {
+	u32			bytes_committed;
+	u8			event_subtype;
+	enum mlx5_pagefault_flags flags;
+	union {
+		/* Initiator or send message responder pagefault details. */
+		struct {
+			/* Received packet size, only valid for responders. */
+			u32	packet_size;
+			/*
+			 * WQE index. Refers to either the send queue or
+			 * receive queue, according to event_subtype.
+			 */
+			u16	wqe_index;
+		} wqe;
+		/* RDMA responder pagefault details */
+		struct {
+			u32	r_key;
+			/*
+			 * Received packet size, minimal size page fault
+			 * resolution required for forward progress.
+			 */
+			u32	packet_size;
+			u32	rdma_op_len;
+			u64	rdma_va;
+		} rdma;
+	};
+};
+
 struct mlx5_core_qp {
 	struct mlx5_core_rsc_common	common; /* must be first */
 	void (*event)		(struct mlx5_core_qp *, int);
+	void (*pfault_handler)(struct mlx5_core_qp *, struct mlx5_pagefault *);
 	int			qpn;
 	struct mlx5_rsc_debug	*dbg;
 	int			pid;
@@ -533,6 +573,17 @@ static inline struct mlx5_core_mr *__mlx5_mr_lookup(struct mlx5_core_dev *dev, u
 	return radix_tree_lookup(&dev->priv.mr_table.tree, key);
 }
 
+struct mlx5_page_fault_resume_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			flags_qpn;
+	u8			reserved[4];
+};
+
+struct mlx5_page_fault_resume_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
 int mlx5_core_create_qp(struct mlx5_core_dev *dev,
 			struct mlx5_core_qp *qp,
 			struct mlx5_create_qp_mbox_in *in,
@@ -552,6 +603,10 @@ void mlx5_init_qp_table(struct mlx5_core_dev *dev);
 void mlx5_cleanup_qp_table(struct mlx5_core_dev *dev);
 int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+int mlx5_core_page_fault_resume(struct mlx5_core_dev *dev, u32 qpn,
+				u8 context, int error);
+#endif
 
 static inline const char *mlx5_qp_type_str(int type)
 {

commit c1395a2a8c01e8a919e47d64eb3d23d00e824b8b
Author: Haggai Eran <haggaie@mellanox.com>
Date:   Thu Dec 11 17:04:14 2014 +0200

    IB/mlx5: Add function to read WQE from user-space
    
    Add a helper function mlx5_ib_read_user_wqe to read information from
    user-space owned work queues.  The function will be used in a later
    patch by the page-fault handling code in mlx5_ib.
    
    Signed-off-by: Haggai Eran <haggaie@mellanox.com>
    
    [ Add stub for ib_umem_copy_from() for CONFIG_INFINIBAND_USER_MEM=n
      - Roland ]
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 3fa075daeb1d..67f4b9660b06 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -189,6 +189,9 @@ struct mlx5_wqe_ctrl_seg {
 	__be32			imm;
 };
 
+#define MLX5_WQE_CTRL_DS_MASK 0x3f
+#define MLX5_WQE_DS_UNITS 16
+
 struct mlx5_wqe_xrc_seg {
 	__be32			xrc_srqn;
 	u8			rsvd[12];

commit 2eb7f910c158fd675ab33aff67904512779996e8
Merge: 1f6075f99073 7b909bb49ac2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Oct 19 12:29:23 2014 -0700

    Merge tag 'rdma-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband
    
    Pull infiniband/RDMA updates from Roland Dreier:
     - large set of iSER initiator improvements
     - hardware driver fixes for cxgb4, mlx5 and ocrdma
     - small fixes to core midlayer
    
    * tag 'rdma-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband: (47 commits)
      RDMA/cxgb4: Fix ntuple calculation for ipv6 and remove duplicate line
      RDMA/cxgb4: Add missing neigh_release in find_route
      RDMA/cxgb4: Take IPv6 into account for best_mtu and set_emss
      RDMA/cxgb4: Make c4iw_wr_log_size_order static
      IB/core: Fix XRC race condition in ib_uverbs_open_qp
      IB/core: Clear AH attr variable to prevent garbage data
      RDMA/ocrdma: Save the bit environment, spare unncessary parenthesis
      RDMA/ocrdma: The kernel has a perfectly good BIT() macro - use it
      RDMA/ocrdma: Don't memset() buffers we just allocated with kzalloc()
      RDMA/ocrdma: Remove a unused-label warning
      RDMA/ocrdma: Convert kernel VA to PA for mmap in user
      RDMA/ocrdma: Get vlan tag from ib_qp_attrs
      RDMA/ocrdma: Add default GID at index 0
      IB/mlx5, iser, isert: Add Signature API additions
      Target/iser: Centralize ib_sig_domain setting
      IB/iser: Centralize ib_sig_domain settings
      IB/mlx5: Use extended internal signature layout
      IB/iser: Set IP_CSUM as default guard type
      IB/iser: Remove redundant assignment
      IB/mlx5: Use enumerations for PI copy mask
      ...

commit 142537f4e5f7ffd3e34b0c46646ac9cb5d986d06
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Wed Aug 13 19:54:32 2014 +0300

    IB/mlx5: Use extended internal signature layout
    
    Rather than using the basic BSF layout which utilizes a pre-configured
    signature settings (sufficient for current DIF implementation), we use
    the extended BSF layout to expose advanced signature settings. These
    settings will also be exposed to the user later.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 4aa5634dc210..69f5378455b7 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -43,6 +43,12 @@
 #define MLX5_CPY_GRD_MASK	0xc0
 #define MLX5_CPY_APP_MASK	0x30
 #define MLX5_CPY_REF_MASK	0x0f
+#define MLX5_BSF_INC_REFTAG	(1 << 6)
+#define MLX5_BSF_INL_VALID	(1 << 15)
+#define MLX5_BSF_REFRESH_DIF	(1 << 14)
+#define MLX5_BSF_REPEAT_BLOCK	(1 << 7)
+#define MLX5_BSF_APPTAG_ESCAPE	0x1
+#define MLX5_BSF_APPREF_ESCAPE	0x2
 
 enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,
@@ -290,6 +296,22 @@ struct mlx5_wqe_inline_seg {
 	__be32	byte_count;
 };
 
+enum mlx5_sig_type {
+	MLX5_DIF_CRC = 0x1,
+	MLX5_DIF_IPCS = 0x2,
+};
+
+struct mlx5_bsf_inl {
+	__be16		vld_refresh;
+	__be16		dif_apptag;
+	__be32		dif_reftag;
+	u8		sig_type;
+	u8		rp_inv_seed;
+	u8		rsvd[3];
+	u8		dif_inc_ref_guard_check;
+	__be16		dif_app_bitmask_check;
+};
+
 struct mlx5_bsf {
 	struct mlx5_bsf_basic {
 		u8		bsf_size_sbs;
@@ -313,14 +335,8 @@ struct mlx5_bsf {
 		__be32		w_tfs_psv;
 		__be32		m_tfs_psv;
 	} ext;
-	struct mlx5_bsf_inl {
-		__be32		w_inl_vld;
-		__be32		w_rsvd;
-		__be64		w_block_format;
-		__be32		m_inl_vld;
-		__be32		m_rsvd;
-		__be64		m_block_format;
-	} inl;
+	struct mlx5_bsf_inl	w_inl;
+	struct mlx5_bsf_inl	m_inl;
 };
 
 struct mlx5_klm {

commit fd22f78cf7b95102d8e5b988afe27165e47471fc
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Wed Aug 13 19:54:29 2014 +0300

    IB/mlx5: Use enumerations for PI copy mask
    
    In case input and output space parameters match, we can use a copy
    mask from input and output space.  Use enums for those.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 9709b30e2d69..4aa5634dc210 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -40,6 +40,9 @@
 #define MLX5_SIG_WQE_SIZE	(MLX5_SEND_WQE_BB * 5)
 #define MLX5_DIF_SIZE		8
 #define MLX5_STRIDE_BLOCK_OP	0x400
+#define MLX5_CPY_GRD_MASK	0xc0
+#define MLX5_CPY_APP_MASK	0x30
+#define MLX5_CPY_REF_MASK	0x0f
 
 enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,

commit 5903325a64834211daf63a62db3b35ee580cb8bf
Author: Eli Cohen <eli@mellanox.com>
Date:   Thu Oct 2 12:19:45 2014 +0300

    net/mlx5_core: Identify resources by their type
    
    This patch puts a common part as the first field of mlx5_core_qp. This field is
    used to identify which resource generated an event. This is required since upcoming
    new resource types such as DC targets are allocated for the same numerical space
    as regular QPs and may generate the same events. By searching the resource in the
    same table we can then look at the common field to identify the resource.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 9709b30e2d69..7c4c0f1f5805 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -342,10 +342,9 @@ struct mlx5_stride_block_ctrl_seg {
 };
 
 struct mlx5_core_qp {
+	struct mlx5_core_rsc_common	common; /* must be first */
 	void (*event)		(struct mlx5_core_qp *, int);
 	int			qpn;
-	atomic_t		refcount;
-	struct completion	free;
 	struct mlx5_rsc_debug	*dbg;
 	int			pid;
 };

commit f360d88a2efddf2d2a2d01a8ac76fded34d624b4
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Apr 2 00:10:16 2014 +0300

    IB/mlx5: Add block multicast loopback support
    
    Add support for the block multicast loopback QP creation flag along
    the proper firmware API for that.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index f829ad80ff28..9709b30e2d69 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -146,6 +146,7 @@ enum {
 
 enum {
 	MLX5_QP_LAT_SENSITIVE	= 1 << 28,
+	MLX5_QP_BLOCK_MCAST	= 1 << 30,
 	MLX5_QP_ENABLE_SIG	= 1 << 31,
 };
 

commit d5436ba01075ef4629015f7a00914d64ffd795d6
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Sun Feb 23 14:19:12 2014 +0200

    IB/mlx5: Collect signature error completion
    
    This commit takes care of the generated signature error CQE generated
    by the HW (if happened).  The underlying mlx5 driver will handle
    signature error completions and will mark the relevant memory region
    as dirty.
    
    Once the consumer gets the completion for the transaction, it must
    check for signature errors on signature memory region using a new
    lightweight verb ib_check_mr_status().
    
    In case the user doesn't check for signature error (i.e. doesn't call
    ib_check_mr_status() with status check IB_MR_CHECK_SIG_STATUS), the
    memory region cannot be used for another signature operation
    (REG_SIG_MR work request will fail).
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 49af74f90ef9..f829ad80ff28 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -506,6 +506,11 @@ static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u
 	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
 }
 
+static inline struct mlx5_core_mr *__mlx5_mr_lookup(struct mlx5_core_dev *dev, u32 key)
+{
+	return radix_tree_lookup(&dev->priv.mr_table.tree, key);
+}
+
 int mlx5_core_create_qp(struct mlx5_core_dev *dev,
 			struct mlx5_core_qp *qp,
 			struct mlx5_create_qp_mbox_in *in,

commit e6631814fb3ac454fbbf47ea343c2b9508e4e1ba
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Sun Feb 23 14:19:11 2014 +0200

    IB/mlx5: Support IB_WR_REG_SIG_MR
    
    This patch implements IB_WR_REG_SIG_MR posted by the user.
    
    Baisically this WR involves 3 WQEs in order to prepare and properly
    register the signature layout:
    
    1. post UMR WR to register the sig_mr in one of two possible ways:
        * In case the user registered a single MR for data so the UMR data segment
          consists of:
          - single klm (data MR) passed by the user
          - BSF with signature attributes requested by the user.
        * In case the user registered 2 MRs, one for data and one for protection,
          the UMR consists of:
          - strided block format which includes data and protection MRs and
            their repetitive block format.
          - BSF with signature attributes requested by the user.
    
    2. post SET_PSV in order to set the memory domain initial
       signature parameters passed by the user.
       SET_PSV is not signaled and solicited CQE.
    
    3. post SET_PSV in order to set the wire domain initial
       signature parameters passed by the user.
       SET_PSV is not signaled and solicited CQE.
    
    * After this compound WR we place a small fence for next WR to come.
    
    This patch also introduces some helper functions to set the BSF correctly
    and determining the signature format selectors.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index 152756eaa8a3..49af74f90ef9 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -38,6 +38,8 @@
 
 #define MLX5_INVALID_LKEY	0x100
 #define MLX5_SIG_WQE_SIZE	(MLX5_SEND_WQE_BB * 5)
+#define MLX5_DIF_SIZE		8
+#define MLX5_STRIDE_BLOCK_OP	0x400
 
 enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,
@@ -152,6 +154,11 @@ enum {
 	MLX5_SND_DBR	= 1,
 };
 
+enum {
+	MLX5_FLAGS_INLINE	= 1<<7,
+	MLX5_FLAGS_CHECK_FREE   = 1<<5,
+};
+
 struct mlx5_wqe_fmr_seg {
 	__be32			flags;
 	__be32			mem_key;
@@ -279,6 +286,60 @@ struct mlx5_wqe_inline_seg {
 	__be32	byte_count;
 };
 
+struct mlx5_bsf {
+	struct mlx5_bsf_basic {
+		u8		bsf_size_sbs;
+		u8		check_byte_mask;
+		union {
+			u8	copy_byte_mask;
+			u8	bs_selector;
+			u8	rsvd_wflags;
+		} wire;
+		union {
+			u8	bs_selector;
+			u8	rsvd_mflags;
+		} mem;
+		__be32		raw_data_size;
+		__be32		w_bfs_psv;
+		__be32		m_bfs_psv;
+	} basic;
+	struct mlx5_bsf_ext {
+		__be32		t_init_gen_pro_size;
+		__be32		rsvd_epi_size;
+		__be32		w_tfs_psv;
+		__be32		m_tfs_psv;
+	} ext;
+	struct mlx5_bsf_inl {
+		__be32		w_inl_vld;
+		__be32		w_rsvd;
+		__be64		w_block_format;
+		__be32		m_inl_vld;
+		__be32		m_rsvd;
+		__be64		m_block_format;
+	} inl;
+};
+
+struct mlx5_klm {
+	__be32		bcount;
+	__be32		key;
+	__be64		va;
+};
+
+struct mlx5_stride_block_entry {
+	__be16		stride;
+	__be16		bcount;
+	__be32		key;
+	__be64		va;
+};
+
+struct mlx5_stride_block_ctrl_seg {
+	__be32		bcount_per_cycle;
+	__be32		op;
+	__be32		repeat_count;
+	u16		rsvd;
+	__be16		num_entries;
+};
+
 struct mlx5_core_qp {
 	void (*event)		(struct mlx5_core_qp *, int);
 	int			qpn;

commit e1e66cc26457c2e9412f67618646ec2a441fc409
Author: Sagi Grimberg <sagig@mellanox.com>
Date:   Sun Feb 23 14:19:07 2014 +0200

    IB/mlx5: Initialize mlx5_ib_qp signature-related members
    
    If user requested signature enable we initialize relevant mlx5_ib_qp
    members.  We mark the qp as sig_enable and we increase the effective
    SQ size, but still limit the user max_send_wr to original size
    computed.  We also allow the create_qp routine to accept sig_enable
    create flag.
    
    Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index d51eff713549..152756eaa8a3 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -37,6 +37,7 @@
 #include <linux/mlx5/driver.h>
 
 #define MLX5_INVALID_LKEY	0x100
+#define MLX5_SIG_WQE_SIZE	(MLX5_SEND_WQE_BB * 5)
 
 enum mlx5_qp_optpar {
 	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,

commit db81a5c374b5bd650c5e6ae85d026709751db103
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Tue Jan 14 17:45:19 2014 +0200

    mlx5_core: Improve debugfs readability
    
    Use strings to display transport service or state of QPs.  Use numeric
    value for MTU of a QP.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
index d9e3eacb3a7f..d51eff713549 100644
--- a/include/linux/mlx5/qp.h
+++ b/include/linux/mlx5/qp.h
@@ -464,4 +464,49 @@ void mlx5_cleanup_qp_table(struct mlx5_core_dev *dev);
 int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
 
+static inline const char *mlx5_qp_type_str(int type)
+{
+	switch (type) {
+	case MLX5_QP_ST_RC: return "RC";
+	case MLX5_QP_ST_UC: return "C";
+	case MLX5_QP_ST_UD: return "UD";
+	case MLX5_QP_ST_XRC: return "XRC";
+	case MLX5_QP_ST_MLX: return "MLX";
+	case MLX5_QP_ST_QP0: return "QP0";
+	case MLX5_QP_ST_QP1: return "QP1";
+	case MLX5_QP_ST_RAW_ETHERTYPE: return "RAW_ETHERTYPE";
+	case MLX5_QP_ST_RAW_IPV6: return "RAW_IPV6";
+	case MLX5_QP_ST_SNIFFER: return "SNIFFER";
+	case MLX5_QP_ST_SYNC_UMR: return "SYNC_UMR";
+	case MLX5_QP_ST_PTP_1588: return "PTP_1588";
+	case MLX5_QP_ST_REG_UMR: return "REG_UMR";
+	default: return "Invalid transport type";
+	}
+}
+
+static inline const char *mlx5_qp_state_str(int state)
+{
+	switch (state) {
+	case MLX5_QP_STATE_RST:
+	return "RST";
+	case MLX5_QP_STATE_INIT:
+	return "INIT";
+	case MLX5_QP_STATE_RTR:
+	return "RTR";
+	case MLX5_QP_STATE_RTS:
+	return "RTS";
+	case MLX5_QP_STATE_SQER:
+	return "SQER";
+	case MLX5_QP_STATE_SQD:
+	return "SQD";
+	case MLX5_QP_STATE_ERR:
+	return "ERR";
+	case MLX5_QP_STATE_SQ_DRAINING:
+	return "SQ_DRAINING";
+	case MLX5_QP_STATE_SUSPENDED:
+	return "SUSPENDED";
+	default: return "Invalid QP state";
+	}
+}
+
 #endif /* MLX5_QP_H */

commit e126ba97dba9edeb6fafa3665b5f8497fc9cdf8c
Author: Eli Cohen <eli@mellanox.com>
Date:   Sun Jul 7 17:25:49 2013 +0300

    mlx5: Add driver for Mellanox Connect-IB adapters
    
    The driver is comprised of two kernel modules: mlx5_ib and mlx5_core.
    This partitioning resembles what we have for mlx4, except that mlx5_ib
    is the pci device driver and not mlx5_core.
    
    mlx5_core is essentially a library that provides general functionality
    that is intended to be used by other Mellanox devices that will be
    introduced in the future.  mlx5_ib has a similar role as any hardware
    device under drivers/infiniband/hw.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    
    [ Merge in coccinelle fixes from Fengguang Wu <fengguang.wu@intel.com>.
      - Roland ]
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
new file mode 100644
index 000000000000..d9e3eacb3a7f
--- /dev/null
+++ b/include/linux/mlx5/qp.h
@@ -0,0 +1,467 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_QP_H
+#define MLX5_QP_H
+
+#include <linux/mlx5/device.h>
+#include <linux/mlx5/driver.h>
+
+#define MLX5_INVALID_LKEY	0x100
+
+enum mlx5_qp_optpar {
+	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,
+	MLX5_QP_OPTPAR_RRE			= 1 << 1,
+	MLX5_QP_OPTPAR_RAE			= 1 << 2,
+	MLX5_QP_OPTPAR_RWE			= 1 << 3,
+	MLX5_QP_OPTPAR_PKEY_INDEX		= 1 << 4,
+	MLX5_QP_OPTPAR_Q_KEY			= 1 << 5,
+	MLX5_QP_OPTPAR_RNR_TIMEOUT		= 1 << 6,
+	MLX5_QP_OPTPAR_PRIMARY_ADDR_PATH	= 1 << 7,
+	MLX5_QP_OPTPAR_SRA_MAX			= 1 << 8,
+	MLX5_QP_OPTPAR_RRA_MAX			= 1 << 9,
+	MLX5_QP_OPTPAR_PM_STATE			= 1 << 10,
+	MLX5_QP_OPTPAR_RETRY_COUNT		= 1 << 12,
+	MLX5_QP_OPTPAR_RNR_RETRY		= 1 << 13,
+	MLX5_QP_OPTPAR_ACK_TIMEOUT		= 1 << 14,
+	MLX5_QP_OPTPAR_PRI_PORT			= 1 << 16,
+	MLX5_QP_OPTPAR_SRQN			= 1 << 18,
+	MLX5_QP_OPTPAR_CQN_RCV			= 1 << 19,
+	MLX5_QP_OPTPAR_DC_HS			= 1 << 20,
+	MLX5_QP_OPTPAR_DC_KEY			= 1 << 21,
+};
+
+enum mlx5_qp_state {
+	MLX5_QP_STATE_RST			= 0,
+	MLX5_QP_STATE_INIT			= 1,
+	MLX5_QP_STATE_RTR			= 2,
+	MLX5_QP_STATE_RTS			= 3,
+	MLX5_QP_STATE_SQER			= 4,
+	MLX5_QP_STATE_SQD			= 5,
+	MLX5_QP_STATE_ERR			= 6,
+	MLX5_QP_STATE_SQ_DRAINING		= 7,
+	MLX5_QP_STATE_SUSPENDED			= 9,
+	MLX5_QP_NUM_STATE
+};
+
+enum {
+	MLX5_QP_ST_RC				= 0x0,
+	MLX5_QP_ST_UC				= 0x1,
+	MLX5_QP_ST_UD				= 0x2,
+	MLX5_QP_ST_XRC				= 0x3,
+	MLX5_QP_ST_MLX				= 0x4,
+	MLX5_QP_ST_DCI				= 0x5,
+	MLX5_QP_ST_DCT				= 0x6,
+	MLX5_QP_ST_QP0				= 0x7,
+	MLX5_QP_ST_QP1				= 0x8,
+	MLX5_QP_ST_RAW_ETHERTYPE		= 0x9,
+	MLX5_QP_ST_RAW_IPV6			= 0xa,
+	MLX5_QP_ST_SNIFFER			= 0xb,
+	MLX5_QP_ST_SYNC_UMR			= 0xe,
+	MLX5_QP_ST_PTP_1588			= 0xd,
+	MLX5_QP_ST_REG_UMR			= 0xc,
+	MLX5_QP_ST_MAX
+};
+
+enum {
+	MLX5_QP_PM_MIGRATED			= 0x3,
+	MLX5_QP_PM_ARMED			= 0x0,
+	MLX5_QP_PM_REARM			= 0x1
+};
+
+enum {
+	MLX5_NON_ZERO_RQ	= 0 << 24,
+	MLX5_SRQ_RQ		= 1 << 24,
+	MLX5_CRQ_RQ		= 2 << 24,
+	MLX5_ZERO_LEN_RQ	= 3 << 24
+};
+
+enum {
+	/* params1 */
+	MLX5_QP_BIT_SRE				= 1 << 15,
+	MLX5_QP_BIT_SWE				= 1 << 14,
+	MLX5_QP_BIT_SAE				= 1 << 13,
+	/* params2 */
+	MLX5_QP_BIT_RRE				= 1 << 15,
+	MLX5_QP_BIT_RWE				= 1 << 14,
+	MLX5_QP_BIT_RAE				= 1 << 13,
+	MLX5_QP_BIT_RIC				= 1 <<	4,
+};
+
+enum {
+	MLX5_WQE_CTRL_CQ_UPDATE		= 2 << 2,
+	MLX5_WQE_CTRL_SOLICITED		= 1 << 1,
+};
+
+enum {
+	MLX5_SEND_WQE_BB	= 64,
+};
+
+enum {
+	MLX5_WQE_FMR_PERM_LOCAL_READ	= 1 << 27,
+	MLX5_WQE_FMR_PERM_LOCAL_WRITE	= 1 << 28,
+	MLX5_WQE_FMR_PERM_REMOTE_READ	= 1 << 29,
+	MLX5_WQE_FMR_PERM_REMOTE_WRITE	= 1 << 30,
+	MLX5_WQE_FMR_PERM_ATOMIC	= 1 << 31
+};
+
+enum {
+	MLX5_FENCE_MODE_NONE			= 0 << 5,
+	MLX5_FENCE_MODE_INITIATOR_SMALL		= 1 << 5,
+	MLX5_FENCE_MODE_STRONG_ORDERING		= 3 << 5,
+	MLX5_FENCE_MODE_SMALL_AND_FENCE		= 4 << 5,
+};
+
+enum {
+	MLX5_QP_LAT_SENSITIVE	= 1 << 28,
+	MLX5_QP_ENABLE_SIG	= 1 << 31,
+};
+
+enum {
+	MLX5_RCV_DBR	= 0,
+	MLX5_SND_DBR	= 1,
+};
+
+struct mlx5_wqe_fmr_seg {
+	__be32			flags;
+	__be32			mem_key;
+	__be64			buf_list;
+	__be64			start_addr;
+	__be64			reg_len;
+	__be32			offset;
+	__be32			page_size;
+	u32			reserved[2];
+};
+
+struct mlx5_wqe_ctrl_seg {
+	__be32			opmod_idx_opcode;
+	__be32			qpn_ds;
+	u8			signature;
+	u8			rsvd[2];
+	u8			fm_ce_se;
+	__be32			imm;
+};
+
+struct mlx5_wqe_xrc_seg {
+	__be32			xrc_srqn;
+	u8			rsvd[12];
+};
+
+struct mlx5_wqe_masked_atomic_seg {
+	__be64			swap_add;
+	__be64			compare;
+	__be64			swap_add_mask;
+	__be64			compare_mask;
+};
+
+struct mlx5_av {
+	union {
+		struct {
+			__be32	qkey;
+			__be32	reserved;
+		} qkey;
+		__be64	dc_key;
+	} key;
+	__be32	dqp_dct;
+	u8	stat_rate_sl;
+	u8	fl_mlid;
+	__be16	rlid;
+	u8	reserved0[10];
+	u8	tclass;
+	u8	hop_limit;
+	__be32	grh_gid_fl;
+	u8	rgid[16];
+};
+
+struct mlx5_wqe_datagram_seg {
+	struct mlx5_av	av;
+};
+
+struct mlx5_wqe_raddr_seg {
+	__be64			raddr;
+	__be32			rkey;
+	u32			reserved;
+};
+
+struct mlx5_wqe_atomic_seg {
+	__be64			swap_add;
+	__be64			compare;
+};
+
+struct mlx5_wqe_data_seg {
+	__be32			byte_count;
+	__be32			lkey;
+	__be64			addr;
+};
+
+struct mlx5_wqe_umr_ctrl_seg {
+	u8		flags;
+	u8		rsvd0[3];
+	__be16		klm_octowords;
+	__be16		bsf_octowords;
+	__be64		mkey_mask;
+	u8		rsvd1[32];
+};
+
+struct mlx5_seg_set_psv {
+	__be32		psv_num;
+	__be16		syndrome;
+	__be16		status;
+	__be32		transient_sig;
+	__be32		ref_tag;
+};
+
+struct mlx5_seg_get_psv {
+	u8		rsvd[19];
+	u8		num_psv;
+	__be32		l_key;
+	__be64		va;
+	__be32		psv_index[4];
+};
+
+struct mlx5_seg_check_psv {
+	u8		rsvd0[2];
+	__be16		err_coalescing_op;
+	u8		rsvd1[2];
+	__be16		xport_err_op;
+	u8		rsvd2[2];
+	__be16		xport_err_mask;
+	u8		rsvd3[7];
+	u8		num_psv;
+	__be32		l_key;
+	__be64		va;
+	__be32		psv_index[4];
+};
+
+struct mlx5_rwqe_sig {
+	u8	rsvd0[4];
+	u8	signature;
+	u8	rsvd1[11];
+};
+
+struct mlx5_wqe_signature_seg {
+	u8	rsvd0[4];
+	u8	signature;
+	u8	rsvd1[11];
+};
+
+struct mlx5_wqe_inline_seg {
+	__be32	byte_count;
+};
+
+struct mlx5_core_qp {
+	void (*event)		(struct mlx5_core_qp *, int);
+	int			qpn;
+	atomic_t		refcount;
+	struct completion	free;
+	struct mlx5_rsc_debug	*dbg;
+	int			pid;
+};
+
+struct mlx5_qp_path {
+	u8			fl;
+	u8			rsvd3;
+	u8			free_ar;
+	u8			pkey_index;
+	u8			rsvd0;
+	u8			grh_mlid;
+	__be16			rlid;
+	u8			ackto_lt;
+	u8			mgid_index;
+	u8			static_rate;
+	u8			hop_limit;
+	__be32			tclass_flowlabel;
+	u8			rgid[16];
+	u8			rsvd1[4];
+	u8			sl;
+	u8			port;
+	u8			rsvd2[6];
+};
+
+struct mlx5_qp_context {
+	__be32			flags;
+	__be32			flags_pd;
+	u8			mtu_msgmax;
+	u8			rq_size_stride;
+	__be16			sq_crq_size;
+	__be32			qp_counter_set_usr_page;
+	__be32			wire_qpn;
+	__be32			log_pg_sz_remote_qpn;
+	struct			mlx5_qp_path pri_path;
+	struct			mlx5_qp_path alt_path;
+	__be32			params1;
+	u8			reserved2[4];
+	__be32			next_send_psn;
+	__be32			cqn_send;
+	u8			reserved3[8];
+	__be32			last_acked_psn;
+	__be32			ssn;
+	__be32			params2;
+	__be32			rnr_nextrecvpsn;
+	__be32			xrcd;
+	__be32			cqn_recv;
+	__be64			db_rec_addr;
+	__be32			qkey;
+	__be32			rq_type_srqn;
+	__be32			rmsn;
+	__be16			hw_sq_wqe_counter;
+	__be16			sw_sq_wqe_counter;
+	__be16			hw_rcyclic_byte_counter;
+	__be16			hw_rq_counter;
+	__be16			sw_rcyclic_byte_counter;
+	__be16			sw_rq_counter;
+	u8			rsvd0[5];
+	u8			cgs;
+	u8			cs_req;
+	u8			cs_res;
+	__be64			dc_access_key;
+	u8			rsvd1[24];
+};
+
+struct mlx5_create_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			input_qpn;
+	u8			rsvd0[4];
+	__be32			opt_param_mask;
+	u8			rsvd1[4];
+	struct mlx5_qp_context	ctx;
+	u8			rsvd3[16];
+	__be64			pas[0];
+};
+
+struct mlx5_create_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_destroy_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_destroy_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+};
+
+struct mlx5_modify_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd1[4];
+	__be32			optparam;
+	u8			rsvd0[4];
+	struct mlx5_qp_context	ctx;
+};
+
+struct mlx5_modify_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+};
+
+struct mlx5_query_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd[4];
+};
+
+struct mlx5_query_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd1[8];
+	__be32			optparam;
+	u8			rsvd0[4];
+	struct mlx5_qp_context	ctx;
+	u8			rsvd2[16];
+	__be64			pas[0];
+};
+
+struct mlx5_conf_sqp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd[3];
+	u8			type;
+};
+
+struct mlx5_conf_sqp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_alloc_xrcd_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_alloc_xrcd_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			xrcdn;
+	u8			rsvd[4];
+};
+
+struct mlx5_dealloc_xrcd_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			xrcdn;
+	u8			rsvd[4];
+};
+
+struct mlx5_dealloc_xrcd_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u32 qpn)
+{
+	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
+}
+
+int mlx5_core_create_qp(struct mlx5_core_dev *dev,
+			struct mlx5_core_qp *qp,
+			struct mlx5_create_qp_mbox_in *in,
+			int inlen);
+int mlx5_core_qp_modify(struct mlx5_core_dev *dev, enum mlx5_qp_state cur_state,
+			enum mlx5_qp_state new_state,
+			struct mlx5_modify_qp_mbox_in *in, int sqd_event,
+			struct mlx5_core_qp *qp);
+int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
+			 struct mlx5_core_qp *qp);
+int mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
+		       struct mlx5_query_qp_mbox_out *out, int outlen);
+
+int mlx5_core_xrcd_alloc(struct mlx5_core_dev *dev, u32 *xrcdn);
+int mlx5_core_xrcd_dealloc(struct mlx5_core_dev *dev, u32 xrcdn);
+void mlx5_init_qp_table(struct mlx5_core_dev *dev);
+void mlx5_cleanup_qp_table(struct mlx5_core_dev *dev);
+int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
+void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
+
+#endif /* MLX5_QP_H */
