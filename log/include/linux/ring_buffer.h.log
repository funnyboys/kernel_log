commit c9b7a4a72ff64e67b7e877a99fd652230dc26058
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Tue Mar 17 17:32:32 2020 -0400

    ring-buffer/tracing: Have iterator acknowledge dropped events
    
    Have the ring_buffer_iterator set a flag if events were dropped as it were
    to go and peek at the next event. Have the trace file display this fact if
    it happened with a "LOST EVENTS" message.
    
    Link: http://lkml.kernel.org/r/20200317213417.045858900@goodmis.org
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 0ae603b79b0e..c76b2f3b3ac4 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -138,6 +138,7 @@ ring_buffer_iter_peek(struct ring_buffer_iter *iter, u64 *ts);
 void ring_buffer_iter_advance(struct ring_buffer_iter *iter);
 void ring_buffer_iter_reset(struct ring_buffer_iter *iter);
 int ring_buffer_iter_empty(struct ring_buffer_iter *iter);
+bool ring_buffer_iter_dropped(struct ring_buffer_iter *iter);
 
 unsigned long ring_buffer_size(struct trace_buffer *buffer, int cpu);
 

commit bc1a72afdc4a91844928831cac85731566e03bc6
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Tue Mar 17 17:32:25 2020 -0400

    ring-buffer: Rename ring_buffer_read() to read_buffer_iter_advance()
    
    When the ring buffer was first created, the iterator followed the normal
    producer/consumer operations where it had both a peek() operation, that just
    returned the event at the current location, and a read(), that would return
    the event at the current location and also increment the iterator such that
    the next peek() or read() will return the next event.
    
    The only use of the ring_buffer_read() is currently to move the iterator to
    the next location and nothing now actually reads the event it returns.
    Rename this function to its actual use case to ring_buffer_iter_advance(),
    which also adds the "iter" part to the name, which is more meaningful. As
    the timestamp returned by ring_buffer_read() was never used, there's no
    reason that this new version should bother having returning it. It will also
    become a void function.
    
    Link: http://lkml.kernel.org/r/20200317213416.018928618@goodmis.org
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index df0124eabece..0ae603b79b0e 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -135,8 +135,7 @@ void ring_buffer_read_finish(struct ring_buffer_iter *iter);
 
 struct ring_buffer_event *
 ring_buffer_iter_peek(struct ring_buffer_iter *iter, u64 *ts);
-struct ring_buffer_event *
-ring_buffer_read(struct ring_buffer_iter *iter, u64 *ts);
+void ring_buffer_iter_advance(struct ring_buffer_iter *iter);
 void ring_buffer_iter_reset(struct ring_buffer_iter *iter);
 int ring_buffer_iter_empty(struct ring_buffer_iter *iter);
 

commit 13292494379f92f532de71b31a54018336adc589
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Fri Dec 13 13:58:57 2019 -0500

    tracing: Make struct ring_buffer less ambiguous
    
    As there's two struct ring_buffers in the kernel, it causes some confusion.
    The other one being the perf ring buffer. It was agreed upon that as neither
    of the ring buffers are generic enough to be used globally, they should be
    renamed as:
    
       perf's ring_buffer -> perf_buffer
       ftrace's ring_buffer -> trace_buffer
    
    This implements the changes to the ring buffer that ftrace uses.
    
    Link: https://lore.kernel.org/r/20191213140531.116b3200@gandalf.local.home
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 1a40277b512c..df0124eabece 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -6,7 +6,7 @@
 #include <linux/seq_file.h>
 #include <linux/poll.h>
 
-struct ring_buffer;
+struct trace_buffer;
 struct ring_buffer_iter;
 
 /*
@@ -77,13 +77,13 @@ u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event);
  *  else
  *    ring_buffer_unlock_commit(buffer, event);
  */
-void ring_buffer_discard_commit(struct ring_buffer *buffer,
+void ring_buffer_discard_commit(struct trace_buffer *buffer,
 				struct ring_buffer_event *event);
 
 /*
  * size is in bytes for each per CPU buffer.
  */
-struct ring_buffer *
+struct trace_buffer *
 __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *key);
 
 /*
@@ -97,38 +97,38 @@ __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *k
 	__ring_buffer_alloc((size), (flags), &__key);	\
 })
 
-int ring_buffer_wait(struct ring_buffer *buffer, int cpu, int full);
-__poll_t ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
+int ring_buffer_wait(struct trace_buffer *buffer, int cpu, int full);
+__poll_t ring_buffer_poll_wait(struct trace_buffer *buffer, int cpu,
 			  struct file *filp, poll_table *poll_table);
 
 
 #define RING_BUFFER_ALL_CPUS -1
 
-void ring_buffer_free(struct ring_buffer *buffer);
+void ring_buffer_free(struct trace_buffer *buffer);
 
-int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size, int cpu);
+int ring_buffer_resize(struct trace_buffer *buffer, unsigned long size, int cpu);
 
-void ring_buffer_change_overwrite(struct ring_buffer *buffer, int val);
+void ring_buffer_change_overwrite(struct trace_buffer *buffer, int val);
 
-struct ring_buffer_event *ring_buffer_lock_reserve(struct ring_buffer *buffer,
+struct ring_buffer_event *ring_buffer_lock_reserve(struct trace_buffer *buffer,
 						   unsigned long length);
-int ring_buffer_unlock_commit(struct ring_buffer *buffer,
+int ring_buffer_unlock_commit(struct trace_buffer *buffer,
 			      struct ring_buffer_event *event);
-int ring_buffer_write(struct ring_buffer *buffer,
+int ring_buffer_write(struct trace_buffer *buffer,
 		      unsigned long length, void *data);
 
-void ring_buffer_nest_start(struct ring_buffer *buffer);
-void ring_buffer_nest_end(struct ring_buffer *buffer);
+void ring_buffer_nest_start(struct trace_buffer *buffer);
+void ring_buffer_nest_end(struct trace_buffer *buffer);
 
 struct ring_buffer_event *
-ring_buffer_peek(struct ring_buffer *buffer, int cpu, u64 *ts,
+ring_buffer_peek(struct trace_buffer *buffer, int cpu, u64 *ts,
 		 unsigned long *lost_events);
 struct ring_buffer_event *
-ring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,
+ring_buffer_consume(struct trace_buffer *buffer, int cpu, u64 *ts,
 		    unsigned long *lost_events);
 
 struct ring_buffer_iter *
-ring_buffer_read_prepare(struct ring_buffer *buffer, int cpu, gfp_t flags);
+ring_buffer_read_prepare(struct trace_buffer *buffer, int cpu, gfp_t flags);
 void ring_buffer_read_prepare_sync(void);
 void ring_buffer_read_start(struct ring_buffer_iter *iter);
 void ring_buffer_read_finish(struct ring_buffer_iter *iter);
@@ -140,59 +140,59 @@ ring_buffer_read(struct ring_buffer_iter *iter, u64 *ts);
 void ring_buffer_iter_reset(struct ring_buffer_iter *iter);
 int ring_buffer_iter_empty(struct ring_buffer_iter *iter);
 
-unsigned long ring_buffer_size(struct ring_buffer *buffer, int cpu);
+unsigned long ring_buffer_size(struct trace_buffer *buffer, int cpu);
 
-void ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu);
-void ring_buffer_reset(struct ring_buffer *buffer);
+void ring_buffer_reset_cpu(struct trace_buffer *buffer, int cpu);
+void ring_buffer_reset(struct trace_buffer *buffer);
 
 #ifdef CONFIG_RING_BUFFER_ALLOW_SWAP
-int ring_buffer_swap_cpu(struct ring_buffer *buffer_a,
-			 struct ring_buffer *buffer_b, int cpu);
+int ring_buffer_swap_cpu(struct trace_buffer *buffer_a,
+			 struct trace_buffer *buffer_b, int cpu);
 #else
 static inline int
-ring_buffer_swap_cpu(struct ring_buffer *buffer_a,
-		     struct ring_buffer *buffer_b, int cpu)
+ring_buffer_swap_cpu(struct trace_buffer *buffer_a,
+		     struct trace_buffer *buffer_b, int cpu)
 {
 	return -ENODEV;
 }
 #endif
 
-bool ring_buffer_empty(struct ring_buffer *buffer);
-bool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu);
-
-void ring_buffer_record_disable(struct ring_buffer *buffer);
-void ring_buffer_record_enable(struct ring_buffer *buffer);
-void ring_buffer_record_off(struct ring_buffer *buffer);
-void ring_buffer_record_on(struct ring_buffer *buffer);
-bool ring_buffer_record_is_on(struct ring_buffer *buffer);
-bool ring_buffer_record_is_set_on(struct ring_buffer *buffer);
-void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
-void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
-
-u64 ring_buffer_oldest_event_ts(struct ring_buffer *buffer, int cpu);
-unsigned long ring_buffer_bytes_cpu(struct ring_buffer *buffer, int cpu);
-unsigned long ring_buffer_entries(struct ring_buffer *buffer);
-unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
-unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
-unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
-unsigned long ring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu);
-unsigned long ring_buffer_dropped_events_cpu(struct ring_buffer *buffer, int cpu);
-unsigned long ring_buffer_read_events_cpu(struct ring_buffer *buffer, int cpu);
-
-u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu);
-void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,
+bool ring_buffer_empty(struct trace_buffer *buffer);
+bool ring_buffer_empty_cpu(struct trace_buffer *buffer, int cpu);
+
+void ring_buffer_record_disable(struct trace_buffer *buffer);
+void ring_buffer_record_enable(struct trace_buffer *buffer);
+void ring_buffer_record_off(struct trace_buffer *buffer);
+void ring_buffer_record_on(struct trace_buffer *buffer);
+bool ring_buffer_record_is_on(struct trace_buffer *buffer);
+bool ring_buffer_record_is_set_on(struct trace_buffer *buffer);
+void ring_buffer_record_disable_cpu(struct trace_buffer *buffer, int cpu);
+void ring_buffer_record_enable_cpu(struct trace_buffer *buffer, int cpu);
+
+u64 ring_buffer_oldest_event_ts(struct trace_buffer *buffer, int cpu);
+unsigned long ring_buffer_bytes_cpu(struct trace_buffer *buffer, int cpu);
+unsigned long ring_buffer_entries(struct trace_buffer *buffer);
+unsigned long ring_buffer_overruns(struct trace_buffer *buffer);
+unsigned long ring_buffer_entries_cpu(struct trace_buffer *buffer, int cpu);
+unsigned long ring_buffer_overrun_cpu(struct trace_buffer *buffer, int cpu);
+unsigned long ring_buffer_commit_overrun_cpu(struct trace_buffer *buffer, int cpu);
+unsigned long ring_buffer_dropped_events_cpu(struct trace_buffer *buffer, int cpu);
+unsigned long ring_buffer_read_events_cpu(struct trace_buffer *buffer, int cpu);
+
+u64 ring_buffer_time_stamp(struct trace_buffer *buffer, int cpu);
+void ring_buffer_normalize_time_stamp(struct trace_buffer *buffer,
 				      int cpu, u64 *ts);
-void ring_buffer_set_clock(struct ring_buffer *buffer,
+void ring_buffer_set_clock(struct trace_buffer *buffer,
 			   u64 (*clock)(void));
-void ring_buffer_set_time_stamp_abs(struct ring_buffer *buffer, bool abs);
-bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer);
+void ring_buffer_set_time_stamp_abs(struct trace_buffer *buffer, bool abs);
+bool ring_buffer_time_stamp_abs(struct trace_buffer *buffer);
 
-size_t ring_buffer_nr_pages(struct ring_buffer *buffer, int cpu);
-size_t ring_buffer_nr_dirty_pages(struct ring_buffer *buffer, int cpu);
+size_t ring_buffer_nr_pages(struct trace_buffer *buffer, int cpu);
+size_t ring_buffer_nr_dirty_pages(struct trace_buffer *buffer, int cpu);
 
-void *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu);
-void ring_buffer_free_read_page(struct ring_buffer *buffer, int cpu, void *data);
-int ring_buffer_read_page(struct ring_buffer *buffer, void **data_page,
+void *ring_buffer_alloc_read_page(struct trace_buffer *buffer, int cpu);
+void ring_buffer_free_read_page(struct trace_buffer *buffer, int cpu, void *data);
+int ring_buffer_read_page(struct trace_buffer *buffer, void **data_page,
 			  size_t len, int cpu, int full);
 
 struct trace_seq;

commit 31b265b3baaf55f209229888b7ffea523ddab366
Author: Douglas Anderson <dianders@chromium.org>
Date:   Fri Mar 8 11:32:04 2019 -0800

    tracing: kdb: Fix ftdump to not sleep
    
    As reported back in 2016-11 [1], the "ftdump" kdb command triggers a
    BUG for "sleeping function called from invalid context".
    
    kdb's "ftdump" command wants to call ring_buffer_read_prepare() in
    atomic context.  A very simple solution for this is to add allocation
    flags to ring_buffer_read_prepare() so kdb can call it without
    triggering the allocation error.  This patch does that.
    
    Note that in the original email thread about this, it was suggested
    that perhaps the solution for kdb was to either preallocate the buffer
    ahead of time or create our own iterator.  I'm hoping that this
    alternative of adding allocation flags to ring_buffer_read_prepare()
    can be considered since it means I don't need to duplicate more of the
    core trace code into "trace_kdb.c" (for either creating my own
    iterator or re-preparing a ring allocator whose memory was already
    allocated).
    
    NOTE: another option for kdb is to actually figure out how to make it
    reuse the existing ftrace_dump() function and totally eliminate the
    duplication.  This sounds very appealing and actually works (the "sr
    z" command can be seen to properly dump the ftrace buffer).  The
    downside here is that ftrace_dump() fully consumes the trace buffer.
    Unless that is changed I'd rather not use it because it means "ftdump
    | grep xyz" won't be very useful to search the ftrace buffer since it
    will throw away the whole trace on the first grep.  A future patch to
    dump only the last few lines of the buffer will also be hard to
    implement.
    
    [1] https://lkml.kernel.org/r/20161117191605.GA21459@google.com
    
    Link: http://lkml.kernel.org/r/20190308193205.213659-1-dianders@chromium.org
    
    Reported-by: Brian Norris <briannorris@chromium.org>
    Signed-off-by: Douglas Anderson <dianders@chromium.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index f1429675f252..1a40277b512c 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -128,7 +128,7 @@ ring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,
 		    unsigned long *lost_events);
 
 struct ring_buffer_iter *
-ring_buffer_read_prepare(struct ring_buffer *buffer, int cpu);
+ring_buffer_read_prepare(struct ring_buffer *buffer, int cpu, gfp_t flags);
 void ring_buffer_read_prepare_sync(void);
 void ring_buffer_read_start(struct ring_buffer_iter *iter);
 void ring_buffer_read_finish(struct ring_buffer_iter *iter);

commit d325c402964e7c63db94e9138c530832269a1297
Author: Miroslav Benes <mbenes@suse.cz>
Date:   Fri Dec 28 14:38:47 2018 +0100

    ring-buffer: Remove unused function ring_buffer_page_len()
    
    Commit 6b7e633fe9c2 ("tracing: Remove extra zeroing out of the ring
    buffer page") removed the only caller of ring_buffer_page_len(). The
    function is now unused and may be removed.
    
    Link: http://lkml.kernel.org/r/20181228133847.106177-1-mbenes@suse.cz
    
    Signed-off-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 5b9ae62272bb..f1429675f252 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -187,8 +187,6 @@ void ring_buffer_set_clock(struct ring_buffer *buffer,
 void ring_buffer_set_time_stamp_abs(struct ring_buffer *buffer, bool abs);
 bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer);
 
-size_t ring_buffer_page_len(void *page);
-
 size_t ring_buffer_nr_pages(struct ring_buffer *buffer, int cpu);
 size_t ring_buffer_nr_dirty_pages(struct ring_buffer *buffer, int cpu);
 

commit 2c2b0a78b373908926e4683ea5571332f63c0eb5
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Thu Nov 29 20:32:26 2018 -0500

    ring-buffer: Add percentage of ring buffer full to wake up reader
    
    Instead of just waiting for a page to be full before waking up a pending
    reader, allow the reader to pass in a "percentage" of pages that have
    content before waking up a reader. This should help keep the process of
    reading the events not cause wake ups that constantly cause reading of the
    buffer.
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 0940fda59872..5b9ae62272bb 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -97,7 +97,7 @@ __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *k
 	__ring_buffer_alloc((size), (flags), &__key);	\
 })
 
-int ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full);
+int ring_buffer_wait(struct ring_buffer *buffer, int cpu, int full);
 __poll_t ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
 			  struct file *filp, poll_table *poll_table);
 
@@ -189,6 +189,8 @@ bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer);
 
 size_t ring_buffer_page_len(void *page);
 
+size_t ring_buffer_nr_pages(struct ring_buffer *buffer, int cpu);
+size_t ring_buffer_nr_dirty_pages(struct ring_buffer *buffer, int cpu);
 
 void *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu);
 void ring_buffer_free_read_page(struct ring_buffer *buffer, int cpu, void *data);

commit d7224c0e128c7337c0b0f66ac20921fbbf4efc14
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Wed Aug 1 21:09:50 2018 -0400

    ring-buffer: Make ring_buffer_record_is_set_on() return bool
    
    The value of ring_buffer_record_is_set_on() is either true or false, so have
    its return value be bool.
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 5176124fc4ba..0940fda59872 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -165,7 +165,7 @@ void ring_buffer_record_enable(struct ring_buffer *buffer);
 void ring_buffer_record_off(struct ring_buffer *buffer);
 void ring_buffer_record_on(struct ring_buffer *buffer);
 bool ring_buffer_record_is_on(struct ring_buffer *buffer);
-int ring_buffer_record_is_set_on(struct ring_buffer *buffer);
+bool ring_buffer_record_is_set_on(struct ring_buffer *buffer);
 void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
 

commit 3ebea280d7e9b610fa3d31c9cfd556b1705eeedf
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Wed Aug 1 21:08:30 2018 -0400

    ring-buffer: Make ring_buffer_record_is_on() return bool
    
    The value of ring_buffer_record_is_on() is either true or false, so have its
    return value be bool.
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 003d09ab308d..5176124fc4ba 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -164,7 +164,7 @@ void ring_buffer_record_disable(struct ring_buffer *buffer);
 void ring_buffer_record_enable(struct ring_buffer *buffer);
 void ring_buffer_record_off(struct ring_buffer *buffer);
 void ring_buffer_record_on(struct ring_buffer *buffer);
-int ring_buffer_record_is_on(struct ring_buffer *buffer);
+bool ring_buffer_record_is_on(struct ring_buffer *buffer);
 int ring_buffer_record_is_set_on(struct ring_buffer *buffer);
 void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);

commit 73c8d8945505acdcbae137c2e00a1232e0be709f
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jul 14 01:28:15 2018 +0900

    ring_buffer: tracing: Inherit the tracing setting to next ring buffer
    
    Maintain the tracing on/off setting of the ring_buffer when switching
    to the trace buffer snapshot.
    
    Taking a snapshot is done by swapping the backup ring buffer
    (max_tr_buffer). But since the tracing on/off setting is defined
    by the ring buffer, when swapping it, the tracing on/off setting
    can also be changed. This causes a strange result like below:
    
      /sys/kernel/debug/tracing # cat tracing_on
      1
      /sys/kernel/debug/tracing # echo 0 > tracing_on
      /sys/kernel/debug/tracing # cat tracing_on
      0
      /sys/kernel/debug/tracing # echo 1 > snapshot
      /sys/kernel/debug/tracing # cat tracing_on
      1
      /sys/kernel/debug/tracing # echo 1 > snapshot
      /sys/kernel/debug/tracing # cat tracing_on
      0
    
    We don't touch tracing_on, but snapshot changes tracing_on
    setting each time. This is an anomaly, because user doesn't know
    that each "ring_buffer" stores its own tracing-enable state and
    the snapshot is done by swapping ring buffers.
    
    Link: http://lkml.kernel.org/r/153149929558.11274.11730609978254724394.stgit@devbox
    
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: Tom Zanussi <tom.zanussi@linux.intel.com>
    Cc: Hiraku Toyooka <hiraku.toyooka@cybertrust.co.jp>
    Cc: stable@vger.kernel.org
    Fixes: debdd57f5145 ("tracing: Make a snapshot feature available from userspace")
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    [ Updated commit log and comment in the code ]
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index b72ebdff0b77..003d09ab308d 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -165,6 +165,7 @@ void ring_buffer_record_enable(struct ring_buffer *buffer);
 void ring_buffer_record_off(struct ring_buffer *buffer);
 void ring_buffer_record_on(struct ring_buffer *buffer);
 int ring_buffer_record_is_on(struct ring_buffer *buffer);
+int ring_buffer_record_is_set_on(struct ring_buffer *buffer);
 void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
 

commit a9235b544a0ae95fbd56443bdbd251358c7df4c5
Author: Vasyl Gomonovych <gomonovych@gmail.com>
Date:   Fri May 18 22:31:28 2018 +0200

    ring-buffer: Fix typo in comment
    
    Fix typo of the word 'been'
    
    Link: http://lkml.kernel.org/r/20180518203130.2011-1-gomonovych@gmail.com
    
    Signed-off-by: Vasyl Gomonovych <gomonovych@gmail.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index a0233edc0718..b72ebdff0b77 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -65,7 +65,7 @@ u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event);
 
 /*
  * ring_buffer_discard_commit will remove an event that has not
- *   ben committed yet. If this is used, then ring_buffer_unlock_commit
+ *   been committed yet. If this is used, then ring_buffer_unlock_commit
  *   must not be called on the discarded event. This function
  *   will try to remove the event from the ring buffer completely
  *   if another event has not been written after it.

commit 8e012066fe0de5ff5be606836f9075511bce5604
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Wed Feb 7 17:26:32 2018 -0500

    ring-buffer: Add nesting for adding events within events
    
    The ring-buffer code has recusion protection in case tracing ends up tracing
    itself, the ring-buffer will detect that it was called at the same context
    (normal, softirq, interrupt or NMI), and not continue to record the event.
    
    With the histogram synthetic events, they are called while tracing another
    event at the same context. The recusion protection triggers because it
    detects tracing at the same context and stops it.
    
    Add ring_buffer_nest_start() and ring_buffer_nest_end() that will notify the
    ring buffer that a trace is about to happen within another trace and that it
    is intended, and not to trigger the recursion blocking.
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 7cb84774c20d..a0233edc0718 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -117,6 +117,9 @@ int ring_buffer_unlock_commit(struct ring_buffer *buffer,
 int ring_buffer_write(struct ring_buffer *buffer,
 		      unsigned long length, void *data);
 
+void ring_buffer_nest_start(struct ring_buffer *buffer);
+void ring_buffer_nest_end(struct ring_buffer *buffer);
+
 struct ring_buffer_event *
 ring_buffer_peek(struct ring_buffer *buffer, int cpu, u64 *ts,
 		 unsigned long *lost_events);

commit dc4e2801d400b0346fb281ce9cf010d611e2243c
Author: Tom Zanussi <tom.zanussi@linux.intel.com>
Date:   Mon Jan 15 20:51:40 2018 -0600

    ring-buffer: Redefine the unimplemented RINGBUF_TYPE_TIME_STAMP
    
    RINGBUF_TYPE_TIME_STAMP is defined but not used, and from what I can
    gather was reserved for something like an absolute timestamp feature
    for the ring buffer, if not a complete replacement of the current
    time_delta scheme.
    
    This code redefines RINGBUF_TYPE_TIME_STAMP to implement absolute time
    stamps.  Another way to look at it is that it essentially forces
    extended time_deltas for all events.
    
    The motivation for doing this is to enable time_deltas that aren't
    dependent on previous events in the ring buffer, making it feasible to
    use the ring_buffer_event timetamps in a more random-access way, for
    purposes other than serial event printing.
    
    To set/reset this mode, use tracing_set_timestamp_abs() from the
    previous interface patch.
    
    Link: http://lkml.kernel.org/r/477b362dba1ce7fab9889a1a8e885a62c472f041.1516069914.git.tom.zanussi@linux.intel.com
    
    Signed-off-by: Tom Zanussi <tom.zanussi@linux.intel.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 025159e17e1b..7cb84774c20d 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -34,10 +34,12 @@ struct ring_buffer_event {
  *				 array[0] = time delta (28 .. 59)
  *				 size = 8 bytes
  *
- * @RINGBUF_TYPE_TIME_STAMP:	Sync time stamp with external clock
- *				 array[0]    = tv_nsec
- *				 array[1..2] = tv_sec
- *				 size = 16 bytes
+ * @RINGBUF_TYPE_TIME_STAMP:	Absolute timestamp
+ *				 Same format as TIME_EXTEND except that the
+ *				 value is an absolute timestamp, not a delta
+ *				 event.time_delta contains bottom 27 bits
+ *				 array[0] = top (28 .. 59) bits
+ *				 size = 8 bytes
  *
  * <= @RINGBUF_TYPE_DATA_TYPE_LEN_MAX:
  *				Data record
@@ -54,12 +56,12 @@ enum ring_buffer_type {
 	RINGBUF_TYPE_DATA_TYPE_LEN_MAX = 28,
 	RINGBUF_TYPE_PADDING,
 	RINGBUF_TYPE_TIME_EXTEND,
-	/* FIXME: RINGBUF_TYPE_TIME_STAMP not implemented */
 	RINGBUF_TYPE_TIME_STAMP,
 };
 
 unsigned ring_buffer_event_length(struct ring_buffer_event *event);
 void *ring_buffer_event_data(struct ring_buffer_event *event);
+u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event);
 
 /*
  * ring_buffer_discard_commit will remove an event that has not

commit 00b4145298aeb05a2d110117ed18148cb21ebd14
Author: Tom Zanussi <tom.zanussi@linux.intel.com>
Date:   Mon Jan 15 20:51:39 2018 -0600

    ring-buffer: Add interface for setting absolute time stamps
    
    Define a new function, tracing_set_time_stamp_abs(), which can be used
    to enable or disable the use of absolute timestamps rather than time
    deltas for a trace array.
    
    Only the interface is added here; a subsequent patch will add the
    underlying implementation.
    
    Link: http://lkml.kernel.org/r/ce96119de44c7fe0ee44786d15254e9b493040d3.1516069914.git.tom.zanussi@linux.intel.com
    
    Signed-off-by: Tom Zanussi <tom.zanussi@linux.intel.com>
    Signed-off-by: Baohong Liu <baohong.liu@intel.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 7d9eb39fa76a..025159e17e1b 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -178,6 +178,8 @@ void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,
 				      int cpu, u64 *ts);
 void ring_buffer_set_clock(struct ring_buffer *buffer,
 			   u64 (*clock)(void));
+void ring_buffer_set_time_stamp_abs(struct ring_buffer *buffer, bool abs);
+bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer);
 
 size_t ring_buffer_page_len(void *page);
 

commit ecf927000ce3265e9871c79d43c10ceed8bd61c9
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jul 16 22:11:54 2017 -0400

    ring_buffer_poll_wait() return value used as return value of ->poll()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 289e4d54e3e0..7d9eb39fa76a 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -96,7 +96,7 @@ __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *k
 })
 
 int ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full);
-int ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
+__poll_t ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
 			  struct file *filp, poll_table *poll_table);
 
 

commit 4950276672fce5c241857540f8561c440663673d
Author: Levin, Alexander (Sasha Levin) <alexander.levin@verizon.com>
Date:   Wed Nov 15 17:35:51 2017 -0800

    kmemcheck: remove annotations
    
    Patch series "kmemcheck: kill kmemcheck", v2.
    
    As discussed at LSF/MM, kill kmemcheck.
    
    KASan is a replacement that is able to work without the limitation of
    kmemcheck (single CPU, slow).  KASan is already upstream.
    
    We are also not aware of any users of kmemcheck (or users who don't
    consider KASan as a suitable replacement).
    
    The only objection was that since KASAN wasn't supported by all GCC
    versions provided by distros at that time we should hold off for 2
    years, and try again.
    
    Now that 2 years have passed, and all distros provide gcc that supports
    KASAN, kill kmemcheck again for the very same reasons.
    
    This patch (of 4):
    
    Remove kmemcheck annotations, and calls to kmemcheck from the kernel.
    
    [alexander.levin@verizon.com: correctly remove kmemcheck call from dma_map_sg_attrs]
      Link: http://lkml.kernel.org/r/20171012192151.26531-1-alexander.levin@verizon.com
    Link: http://lkml.kernel.org/r/20171007030159.22241-2-alexander.levin@verizon.com
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tim Hansen <devtimhansen@gmail.com>
    Cc: Vegard Nossum <vegardno@ifi.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index fa6ace66fea5..289e4d54e3e0 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -2,7 +2,6 @@
 #ifndef _LINUX_RING_BUFFER_H
 #define _LINUX_RING_BUFFER_H
 
-#include <linux/kmemcheck.h>
 #include <linux/mm.h>
 #include <linux/seq_file.h>
 #include <linux/poll.h>
@@ -14,9 +13,7 @@ struct ring_buffer_iter;
  * Don't refer to this struct directly, use functions below.
  */
 struct ring_buffer_event {
-	kmemcheck_bitfield_begin(bitfield);
 	u32		type_len:5, time_delta:27;
-	kmemcheck_bitfield_end(bitfield);
 
 	u32		array[];
 };

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index ee9b461af095..fa6ace66fea5 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LINUX_RING_BUFFER_H
 #define _LINUX_RING_BUFFER_H
 

commit 73a757e63114dfd765f1c5d1ff7e994f123d0234
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Mon May 1 09:35:09 2017 -0400

    ring-buffer: Return reader page back into existing ring buffer
    
    When reading the ring buffer for consuming, it is optimized for splice,
    where a page is taken out of the ring buffer (zero copy) and sent to the
    reading consumer. When the read is finished with the page, it calls
    ring_buffer_free_read_page(), which simply frees the page. The next time the
    reader needs to get a page from the ring buffer, it must call
    ring_buffer_alloc_read_page() which allocates and initializes a reader page
    for the ring buffer to be swapped into the ring buffer for a new filled page
    for the reader.
    
    The problem is that there's no reason to actually free the page when it is
    passed back to the ring buffer. It can hold it off and reuse it for the next
    iteration. This completely removes the interaction with the page_alloc
    mechanism.
    
    Using the trace-cmd utility to record all events (causing trace-cmd to
    require reading lots of pages from the ring buffer, and calling
    ring_buffer_alloc/free_read_page() several times), and also assigning a
    stack trace trigger to the mm_page_alloc event, we can see how many times
    the ring_buffer_alloc_read_page() needed to allocate a page for the ring
    buffer.
    
    Before this change:
    
      # trace-cmd record -e all -e mem_page_alloc -R stacktrace sleep 1
      # trace-cmd report |grep ring_buffer_alloc_read_page | wc -l
      9968
    
    After this change:
    
      # trace-cmd record -e all -e mem_page_alloc -R stacktrace sleep 1
      # trace-cmd report |grep ring_buffer_alloc_read_page | wc -l
      4
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index b6d4568795a7..ee9b461af095 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -185,7 +185,7 @@ size_t ring_buffer_page_len(void *page);
 
 
 void *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu);
-void ring_buffer_free_read_page(struct ring_buffer *buffer, void *data);
+void ring_buffer_free_read_page(struct ring_buffer *buffer, int cpu, void *data);
 int ring_buffer_read_page(struct ring_buffer *buffer, void **data_page,
 			  size_t len, int cpu, int full);
 

commit b32614c03413f8a6025d8677c2b7c0ee976e63d4
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Sun Nov 27 00:13:34 2016 +0100

    tracing/rb: Convert to hotplug state machine
    
    Install the callbacks via the state machine. The notifier in struct
    ring_buffer is replaced by the multi instance interface.  Upon
    __ring_buffer_alloc() invocation, cpuhp_state_add_instance() will invoke
    the trace_rb_cpu_prepare() on each CPU.
    
    This callback may now fail. This means __ring_buffer_alloc() will fail and
    cleanup (like previously) and during a CPU up event this failure will not
    allow the CPU to come up.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: rt@linutronix.de
    Link: http://lkml.kernel.org/r/20161126231350.10321-7-bigeasy@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 4acc552e9279..b6d4568795a7 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -198,4 +198,10 @@ enum ring_buffer_flags {
 	RB_FL_OVERWRITE		= 1 << 0,
 };
 
+#ifdef CONFIG_RING_BUFFER
+int trace_rb_cpu_prepare(unsigned int cpu, struct hlist_node *node);
+#else
+#define trace_rb_cpu_prepare	NULL
+#endif
+
 #endif /* _LINUX_RING_BUFFER_H */

commit 3d4e204d81eec30abffe55d01912e07ce81eef12
Author: Yaowei Bai <bywxiaobai@163.com>
Date:   Tue Sep 29 22:43:32 2015 +0800

    ring_buffer: ring_buffer_empty{cpu}() can return boolean
    
    Make ring_buffer_empty() and ring_buffer_empty_cpu() return bool.
    
    No functional change.
    
    Link: http://lkml.kernel.org/r/1443537816-5788-5-git-send-email-bywxiaobai@163.com
    
    Signed-off-by: Yaowei Bai <bywxiaobai@163.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index e2c13cd863bd..4acc552e9279 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -154,8 +154,8 @@ ring_buffer_swap_cpu(struct ring_buffer *buffer_a,
 }
 #endif
 
-int ring_buffer_empty(struct ring_buffer *buffer);
-int ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu);
+bool ring_buffer_empty(struct ring_buffer *buffer);
+bool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu);
 
 void ring_buffer_record_disable(struct ring_buffer *buffer);
 void ring_buffer_record_enable(struct ring_buffer *buffer);

commit e30f53aad2202b5526c40c36d8eeac8bf290bde5
Author: Rabin Vincent <rabin@rab.in>
Date:   Mon Nov 10 19:46:34 2014 +0100

    tracing: Do not busy wait in buffer splice
    
    On a !PREEMPT kernel, attempting to use trace-cmd results in a soft
    lockup:
    
     # trace-cmd record -e raw_syscalls:* -F false
     NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s! [trace-cmd:61]
     ...
     Call Trace:
      [<ffffffff8105b580>] ? __wake_up_common+0x90/0x90
      [<ffffffff81092e25>] wait_on_pipe+0x35/0x40
      [<ffffffff810936e3>] tracing_buffers_splice_read+0x2e3/0x3c0
      [<ffffffff81093300>] ? tracing_stats_read+0x2a0/0x2a0
      [<ffffffff812d10ab>] ? _raw_spin_unlock+0x2b/0x40
      [<ffffffff810dc87b>] ? do_read_fault+0x21b/0x290
      [<ffffffff810de56a>] ? handle_mm_fault+0x2ba/0xbd0
      [<ffffffff81095c80>] ? trace_event_buffer_lock_reserve+0x40/0x80
      [<ffffffff810951e2>] ? trace_buffer_lock_reserve+0x22/0x60
      [<ffffffff81095c80>] ? trace_event_buffer_lock_reserve+0x40/0x80
      [<ffffffff8112415d>] do_splice_to+0x6d/0x90
      [<ffffffff81126971>] SyS_splice+0x7c1/0x800
      [<ffffffff812d1edd>] tracesys_phase2+0xd3/0xd8
    
    The problem is this: tracing_buffers_splice_read() calls
    ring_buffer_wait() to wait for data in the ring buffers.  The buffers
    are not empty so ring_buffer_wait() returns immediately.  But
    tracing_buffers_splice_read() calls ring_buffer_read_page() with full=1,
    meaning it only wants to read a full page.  When the full page is not
    available, tracing_buffers_splice_read() tries to wait again with
    ring_buffer_wait(), which again returns immediately, and so on.
    
    Fix this by adding a "full" argument to ring_buffer_wait() which will
    make ring_buffer_wait() wait until the writer has left the reader's
    page, i.e.  until full-page reads will succeed.
    
    Link: http://lkml.kernel.org/r/1415645194-25379-1-git-send-email-rabin@rab.in
    
    Cc: stable@vger.kernel.org # 3.16+
    Fixes: b1169cc69ba9 ("tracing: Remove mock up poll wait function")
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 49a4d6f59108..e2c13cd863bd 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -97,7 +97,7 @@ __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *k
 	__ring_buffer_alloc((size), (flags), &__key);	\
 })
 
-int ring_buffer_wait(struct ring_buffer *buffer, int cpu);
+int ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full);
 int ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
 			  struct file *filp, poll_table *poll_table);
 

commit 8b8b36834d0fff67fc8668093f4312dd04dcf21d
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Tue Jun 10 09:46:00 2014 -0400

    ring-buffer: Check if buffer exists before polling
    
    The per_cpu buffers are created one per possible CPU. But these do
    not mean that those CPUs are online, nor do they even exist.
    
    With the addition of the ring buffer polling, it assumes that the
    caller polls on an existing buffer. But this is not the case if
    the user reads trace_pipe from a CPU that does not exist, and this
    causes the kernel to crash.
    
    Simple fix is to check the cpu against buffer bitmask against to see
    if the buffer was allocated or not and return -ENODEV if it is
    not.
    
    More updates were done to pass the -ENODEV back up to userspace.
    
    Link: http://lkml.kernel.org/r/5393DB61.6060707@oracle.com
    
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Cc: stable@vger.kernel.org # 3.10+
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index d69cf637a15a..49a4d6f59108 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -97,7 +97,7 @@ __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *k
 	__ring_buffer_alloc((size), (flags), &__key);	\
 })
 
-void ring_buffer_wait(struct ring_buffer *buffer, int cpu);
+int ring_buffer_wait(struct ring_buffer *buffer, int cpu);
 int ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
 			  struct file *filp, poll_table *poll_table);
 

commit 15693458c4bc0693fd63a50d60f35b628fcf4e29
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Thu Feb 28 19:59:17 2013 -0500

    tracing/ring-buffer: Move poll wake ups into ring buffer code
    
    Move the logic to wake up on ring buffer data into the ring buffer
    code itself. This simplifies the tracing code a lot and also has the
    added benefit that waiters on one of the instance buffers can be woken
    only when data is added to that instance instead of data added to
    any instance.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 1342e69542f3..d69cf637a15a 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -4,6 +4,7 @@
 #include <linux/kmemcheck.h>
 #include <linux/mm.h>
 #include <linux/seq_file.h>
+#include <linux/poll.h>
 
 struct ring_buffer;
 struct ring_buffer_iter;
@@ -96,6 +97,11 @@ __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *k
 	__ring_buffer_alloc((size), (flags), &__key);	\
 })
 
+void ring_buffer_wait(struct ring_buffer *buffer, int cpu);
+int ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
+			  struct file *filp, poll_table *poll_table);
+
+
 #define RING_BUFFER_ALL_CPUS -1
 
 void ring_buffer_free(struct ring_buffer *buffer);

commit ad964704ba9326d027fc10fd0099b7c880e50172
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Tue Jan 29 17:45:49 2013 -0500

    ring-buffer: Add stats field for amount read from trace ring buffer
    
    Add a stat about the number of events read from the ring buffer:
    
     #  cat /debug/tracing/per_cpu/cpu0/stats
    entries: 39869
    overrun: 870512
    commit overrun: 0
    bytes: 1449912
    oldest event ts:  6561.368690
    now ts:  6565.246426
    dropped events: 0
    read events: 112    <-- Added
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 519777e3fa01..1342e69542f3 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -167,6 +167,7 @@ unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_dropped_events_cpu(struct ring_buffer *buffer, int cpu);
+unsigned long ring_buffer_read_events_cpu(struct ring_buffer *buffer, int cpu);
 
 u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu);
 void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,

commit 50ecf2c3afead23a05227ab004e4212eca08c207
Author: Yoshihiro YUNOMAE <yoshihiro.yunomae.ez@hitachi.com>
Date:   Thu Oct 11 16:27:54 2012 -0700

    ring-buffer: Change unsigned long type of ring_buffer_oldest_event_ts() to u64
    
    ring_buffer_oldest_event_ts() should return a value of u64 type, because
    ring_buffer_per_cpu->buffer_page->buffer_data_page->time_stamp is u64 type.
    
    Link: http://lkml.kernel.org/r/1349998076-15495-5-git-send-email-dhsharp@google.com
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Vaibhav Nagarnaik <vnagarnaik@google.com>
    Signed-off-by: Yoshihiro YUNOMAE <yoshihiro.yunomae.ez@hitachi.com>
    Signed-off-by: David Sharp <dhsharp@google.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 2007375cfe77..519777e3fa01 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -159,7 +159,7 @@ int ring_buffer_record_is_on(struct ring_buffer *buffer);
 void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
 
-unsigned long ring_buffer_oldest_event_ts(struct ring_buffer *buffer, int cpu);
+u64 ring_buffer_oldest_event_ts(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_bytes_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_entries(struct ring_buffer *buffer);
 unsigned long ring_buffer_overruns(struct ring_buffer *buffer);

commit 884bfe89a462fcc85c8abd96171519cf2fe70929
Author: Slava Pestov <slavapestov@google.com>
Date:   Fri Jul 15 14:23:58 2011 -0700

    ring-buffer: Add a 'dropped events' counter
    
    The existing 'overrun' counter is incremented when the ring
    buffer wraps around, with overflow on (the default). We wanted
    a way to count requests lost from the buffer filling up with
    overflow off, too. I decided to add a new counter instead
    of retro-fitting the existing one because it seems like a
    different statistic to count conceptually, and also because
    of how the code was structured.
    
    Link: http://lkml.kernel.org/r/1310765038-26399-1-git-send-email-slavapestov@google.com
    
    Signed-off-by: Slava Pestov <slavapestov@google.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 6c8835f74f79..2007375cfe77 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -166,6 +166,7 @@ unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
 unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu);
+unsigned long ring_buffer_dropped_events_cpu(struct ring_buffer *buffer, int cpu);
 
 u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu);
 void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,

commit 438ced1720b584000a9e8a4349d1f6bb7ee3ad6d
Author: Vaibhav Nagarnaik <vnagarnaik@google.com>
Date:   Thu Feb 2 12:00:41 2012 -0800

    ring-buffer: Add per_cpu ring buffer control files
    
    Add a debugfs entry under per_cpu/ folder for each cpu called
    buffer_size_kb to control the ring buffer size for each CPU
    independently.
    
    If the global file buffer_size_kb is used to set size, the individual
    ring buffers will be adjusted to the given size. The buffer_size_kb will
    report the common size to maintain backward compatibility.
    
    If the buffer_size_kb file under the per_cpu/ directory is used to
    change buffer size for a specific CPU, only the size of the respective
    ring buffer is updated. When tracing/buffer_size_kb is read, it reports
    'X' to indicate that sizes of per_cpu ring buffers are not equivalent.
    
    Link: http://lkml.kernel.org/r/1328212844-11889-1-git-send-email-vnagarnaik@google.com
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Michael Rubin <mrubin@google.com>
    Cc: David Sharp <dhsharp@google.com>
    Cc: Justin Teravest <teravest@google.com>
    Signed-off-by: Vaibhav Nagarnaik <vnagarnaik@google.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 7be2e88f23fd..6c8835f74f79 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -96,9 +96,11 @@ __ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *k
 	__ring_buffer_alloc((size), (flags), &__key);	\
 })
 
+#define RING_BUFFER_ALL_CPUS -1
+
 void ring_buffer_free(struct ring_buffer *buffer);
 
-int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size);
+int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size, int cpu);
 
 void ring_buffer_change_overwrite(struct ring_buffer *buffer, int val);
 
@@ -129,7 +131,7 @@ ring_buffer_read(struct ring_buffer_iter *iter, u64 *ts);
 void ring_buffer_iter_reset(struct ring_buffer_iter *iter);
 int ring_buffer_iter_empty(struct ring_buffer_iter *iter);
 
-unsigned long ring_buffer_size(struct ring_buffer *buffer);
+unsigned long ring_buffer_size(struct ring_buffer *buffer, int cpu);
 
 void ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_reset(struct ring_buffer *buffer);

commit 499e547057f5bba5cd6f87ebe59b05d0c59da905
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Wed Feb 22 15:50:28 2012 -0500

    tracing/ring-buffer: Only have tracing_on disable tracing buffers
    
    As the ring-buffer code is being used by other facilities in the
    kernel, having tracing_on file disable *all* buffers is not a desired
    affect. It should only disable the ftrace buffers that are being used.
    
    Move the code into the trace.c file and use the buffer disabling
    for tracing_on() and tracing_off(). This way only the ftrace buffers
    will be affected by them and other kernel utilities will not be
    confused to why their output suddenly stopped.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 67be0376d8e3..7be2e88f23fd 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -151,6 +151,9 @@ int ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu);
 
 void ring_buffer_record_disable(struct ring_buffer *buffer);
 void ring_buffer_record_enable(struct ring_buffer *buffer);
+void ring_buffer_record_off(struct ring_buffer *buffer);
+void ring_buffer_record_on(struct ring_buffer *buffer);
+int ring_buffer_record_is_on(struct ring_buffer *buffer);
 void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
 

commit c64e148a3be3cb786534ad38298c25c833116c26
Author: Vaibhav Nagarnaik <vnagarnaik@google.com>
Date:   Tue Aug 16 14:46:16 2011 -0700

    trace: Add ring buffer stats to measure rate of events
    
    The stats file under per_cpu folder provides the number of entries,
    overruns and other statistics about the CPU ring buffer. However, the
    numbers do not provide any indication of how full the ring buffer is in
    bytes compared to the overall size in bytes. Also, it is helpful to know
    the rate at which the cpu buffer is filling up.
    
    This patch adds an entry "bytes: " in printed stats for per_cpu ring
    buffer which provides the actual bytes consumed in the ring buffer. This
    field includes the number of bytes used by recorded events and the
    padding bytes added when moving the tail pointer to next page.
    
    It also adds the following time stamps:
    "oldest event ts:" - the oldest timestamp in the ring buffer
    "now ts:"  - the timestamp at the time of reading
    
    The field "now ts" provides a consistent time snapshot to the userspace
    when being read. This is read from the same trace clock used by tracing
    event timestamps.
    
    Together, these values provide the rate at which the buffer is filling
    up, from the formula:
    bytes / (now_ts - oldest_event_ts)
    
    Signed-off-by: Vaibhav Nagarnaik <vnagarnaik@google.com>
    Cc: Michael Rubin <mrubin@google.com>
    Cc: David Sharp <dhsharp@google.com>
    Link: http://lkml.kernel.org/r/1313531179-9323-3-git-send-email-vnagarnaik@google.com
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index b891de96000f..67be0376d8e3 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -154,6 +154,8 @@ void ring_buffer_record_enable(struct ring_buffer *buffer);
 void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
 
+unsigned long ring_buffer_oldest_event_ts(struct ring_buffer *buffer, int cpu);
+unsigned long ring_buffer_bytes_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_entries(struct ring_buffer *buffer);
 unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
 unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);

commit 7ea5906405a1f3fc1c0033dfd7e02f2cfd1de5e5
Author: Vaibhav Nagarnaik <vnagarnaik@google.com>
Date:   Tue May 3 17:56:42 2011 -0700

    tracing: Use NUMA allocation for per-cpu ring buffer pages
    
    The tracing ring buffer is a group of per-cpu ring buffers where
    allocation and logging is done on a per-cpu basis. The events that are
    generated on a particular CPU are logged in the corresponding buffer.
    This is to provide wait-free writes between CPUs and good NUMA node
    locality while accessing the ring buffer.
    
    However, the allocation routines consider NUMA locality only for buffer
    page metadata and not for the actual buffer page. This causes the pages
    to be allocated on the NUMA node local to the CPU where the allocation
    routine is running at the time.
    
    This patch fixes the problem by using a NUMA node specific allocation
    routine so that the pages are allocated from a NUMA node local to the
    logging CPU.
    
    I tested with the getuid_microbench from autotest. It is a simple binary
    that calls getuid() in a loop and measures the average time for the
    syscall to complete. The following command was used to test:
    $ getuid_microbench 1000000
    
    Compared the numbers found on kernel with and without this patch and
    found that logging latency decreases by 30-50 ns/call.
    tracing with non-NUMA allocation - 569 ns/call
    tracing with NUMA allocation     - 512 ns/call
    
    Signed-off-by: Vaibhav Nagarnaik <vnagarnaik@google.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Michael Rubin <mrubin@google.com>
    Cc: David Sharp <dhsharp@google.com>
    Link: http://lkml.kernel.org/r/1304470602-20366-1-git-send-email-vnagarnaik@google.com
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index ab38ac80b0f9..b891de96000f 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -169,7 +169,7 @@ void ring_buffer_set_clock(struct ring_buffer *buffer,
 size_t ring_buffer_page_len(void *page);
 
 
-void *ring_buffer_alloc_read_page(struct ring_buffer *buffer);
+void *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu);
 void ring_buffer_free_read_page(struct ring_buffer *buffer, void *data);
 int ring_buffer_read_page(struct ring_buffer *buffer, void **data_page,
 			  size_t len, int cpu, int full);

commit 750912fa366312e9c5bc83eab352898a26750401
Author: David Sharp <dhsharp@google.com>
Date:   Wed Dec 8 13:46:47 2010 -0800

    tracing: Add an 'overwrite' trace_option.
    
    Add an "overwrite" trace_option for ftrace to control whether the buffer should
    be overwritten on overflow or not. The default remains to overwrite old events
    when the buffer is full. This patch adds the option to instead discard newest
    events when the buffer is full. This is useful to get a snapshot of traces just
    after enabling traces. Dropping the current event is also a simpler code path.
    
    Signed-off-by: David Sharp <dhsharp@google.com>
    LKML-Reference: <1291844807-15481-1-git-send-email-dhsharp@google.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 8d3a2486544d..ab38ac80b0f9 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -100,6 +100,8 @@ void ring_buffer_free(struct ring_buffer *buffer);
 
 int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size);
 
+void ring_buffer_change_overwrite(struct ring_buffer *buffer, int val);
+
 struct ring_buffer_event *ring_buffer_lock_reserve(struct ring_buffer *buffer,
 						   unsigned long length);
 int ring_buffer_unlock_commit(struct ring_buffer *buffer,

commit afcc5c6872f0215d515a637041bb51f8691a8ea7
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Wed Oct 20 13:37:56 2010 -0400

    ring-buffer: Remove ring_buffer_event_time_delta()
    
    The ring_buffer_event_time_delta() static inline function does not
    have any users. Remove it.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 25b4f686d918..8d3a2486544d 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -62,18 +62,6 @@ enum ring_buffer_type {
 unsigned ring_buffer_event_length(struct ring_buffer_event *event);
 void *ring_buffer_event_data(struct ring_buffer_event *event);
 
-/**
- * ring_buffer_event_time_delta - return the delta timestamp of the event
- * @event: the event to get the delta timestamp of
- *
- * The delta timestamp is the 27 bit timestamp since the last event.
- */
-static inline unsigned
-ring_buffer_event_time_delta(struct ring_buffer_event *event)
-{
-	return event->time_delta;
-}
-
 /*
  * ring_buffer_discard_commit will remove an event that has not
  *   ben committed yet. If this is used, then ring_buffer_unlock_commit

commit 72c9ddfd4c5bf54ef03cfdf57026416cb678eeba
Author: David Miller <davem@davemloft.net>
Date:   Tue Apr 20 15:47:11 2010 -0700

    ring-buffer: Make non-consuming read less expensive with lots of cpus.
    
    When performing a non-consuming read, a synchronize_sched() is
    performed once for every cpu which is actively tracing.
    
    This is very expensive, and can make it take several seconds to open
    up the 'trace' file with lots of cpus.
    
    Only one synchronize_sched() call is actually necessary.  What is
    desired is for all cpus to see the disabling state change.  So we
    transform the existing sequence:
    
            for_each_cpu() {
                    ring_buffer_read_start();
            }
    
    where each ring_buffer_start() call performs a synchronize_sched(),
    into the following:
    
            for_each_cpu() {
                    ring_buffer_read_prepare();
            }
            ring_buffer_read_prepare_sync();
            for_each_cpu() {
                    ring_buffer_read_start();
            }
    
    wherein only the single ring_buffer_read_prepare_sync() call needs to
    do the synchronize_sched().
    
    The first phase, via ring_buffer_read_prepare(), allocates the 'iter'
    memory and increments ->record_disabled.
    
    In the second phase, ring_buffer_read_prepare_sync() makes sure this
    ->record_disabled state is visible fully to all cpus.
    
    And in the final third phase, the ring_buffer_read_start() calls reset
    the 'iter' objects allocated in the first phase since we now know that
    none of the cpus are adding trace entries any more.
    
    This makes openning the 'trace' file nearly instantaneous on a
    sparc64 Niagara2 box with 128 cpus tracing.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    LKML-Reference: <20100420.154711.11246950.davem@davemloft.net>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index c8297761e414..25b4f686d918 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -127,7 +127,9 @@ ring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,
 		    unsigned long *lost_events);
 
 struct ring_buffer_iter *
-ring_buffer_read_start(struct ring_buffer *buffer, int cpu);
+ring_buffer_read_prepare(struct ring_buffer *buffer, int cpu);
+void ring_buffer_read_prepare_sync(void);
+void ring_buffer_read_start(struct ring_buffer_iter *iter);
 void ring_buffer_read_finish(struct ring_buffer_iter *iter);
 
 struct ring_buffer_event *

commit 66a8cb95ed04025664d1db4e952155ee1dccd048
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Wed Mar 31 13:21:56 2010 -0400

    ring-buffer: Add place holder recording of dropped events
    
    Currently, when the ring buffer drops events, it does not record
    the fact that it did so. It does inform the writer that the event
    was dropped by returning a NULL event, but it does not put in any
    place holder where the event was dropped.
    
    This is not a trivial thing to add because the ring buffer mostly
    runs in overwrite (flight recorder) mode. That is, when the ring
    buffer is full, new data will overwrite old data.
    
    In a produce/consumer mode, where new data is simply dropped when
    the ring buffer is full, it is trivial to add the placeholder
    for dropped events. When there's more room to write new data, then
    a special event can be added to notify the reader about the dropped
    events.
    
    But in overwrite mode, any new write can overwrite events. A place
    holder can not be inserted into the ring buffer since there never
    may be room. A reader could also come in at anytime and miss the
    placeholder.
    
    Luckily, the way the ring buffer works, the read side can find out
    if events were lost or not, and how many events. Everytime a write
    takes place, if it overwrites the header page (the next read) it
    updates a "overrun" variable that keeps track of the number of
    lost events. When a reader swaps out a page from the ring buffer,
    it can record this number, perfom the swap, and then check to
    see if the number changed, and take the diff if it has, which would be
    the number of events dropped. This can be stored by the reader
    and returned to callers of the reader.
    
    Since the reader page swap will fail if the writer moved the head
    page since the time the reader page set up the swap, this gives room
    to record the overruns without worrying about races. If the reader
    sets up the pages, records the overrun, than performs the swap,
    if the swap succeeds, then the overrun variable has not been
    updated since the setup before the swap.
    
    For binary readers of the ring buffer, a flag is set in the header
    of each sub page (sub buffer) of the ring buffer. This flag is embedded
    in the size field of the data on the sub buffer, in the 31st bit (the size
    can be 32 or 64 bits depending on the architecture), but only 27
    bits needs to be used for the actual size (less actually).
    
    We could add a new field in the sub buffer header to also record the
    number of events dropped since the last read, but this will change the
    format of the binary ring buffer a bit too much. Perhaps this change can
    be made if the information on the number of events dropped is considered
    important enough.
    
    Note, the notification of dropped events is only used by consuming reads
    or peeking at the ring buffer. Iterating over the ring buffer does not
    keep this information because the necessary data is only available when
    a page swap is made, and the iterator does not swap out pages.
    
    Cc: Robert Richter <robert.richter@amd.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: "Luis Claudio R. Goncalves" <lclaudio@uudg.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 5fcc31ed5771..c8297761e414 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -120,9 +120,11 @@ int ring_buffer_write(struct ring_buffer *buffer,
 		      unsigned long length, void *data);
 
 struct ring_buffer_event *
-ring_buffer_peek(struct ring_buffer *buffer, int cpu, u64 *ts);
+ring_buffer_peek(struct ring_buffer *buffer, int cpu, u64 *ts,
+		 unsigned long *lost_events);
 struct ring_buffer_event *
-ring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts);
+ring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,
+		    unsigned long *lost_events);
 
 struct ring_buffer_iter *
 ring_buffer_read_start(struct ring_buffer *buffer, int cpu);

commit 85bac32c4a52c592b857f2c360cc5ec93a097d70
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Sep 4 14:24:40 2009 -0400

    ring-buffer: only enable ring_buffer_swap_cpu when needed
    
    Since the ability to swap the cpu buffers adds a small overhead to
    the recording of a trace, we only want to add it when needed.
    
    Only the irqsoff and preemptoff tracers use this feature, and both are
    not recommended for production kernels. This patch disables its use
    when neither irqsoff nor preemptoff is configured.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index e061b4ecdc3a..5fcc31ed5771 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -140,8 +140,17 @@ unsigned long ring_buffer_size(struct ring_buffer *buffer);
 void ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu);
 void ring_buffer_reset(struct ring_buffer *buffer);
 
+#ifdef CONFIG_RING_BUFFER_ALLOW_SWAP
 int ring_buffer_swap_cpu(struct ring_buffer *buffer_a,
 			 struct ring_buffer *buffer_b, int cpu);
+#else
+static inline int
+ring_buffer_swap_cpu(struct ring_buffer *buffer_a,
+		     struct ring_buffer *buffer_b, int cpu)
+{
+	return -ENODEV;
+}
+#endif
 
 int ring_buffer_empty(struct ring_buffer *buffer);
 int ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu);

commit dc892f7339af2d125478b800edb9081d6149665b
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Thu Sep 3 15:33:41 2009 -0400

    ring-buffer: remove ring_buffer_event_discard
    
    The function ring_buffer_event_discard can be used on any item in the
    ring buffer, even after the item was committed. This function provides
    no safety nets and is very race prone.
    
    An item may be safely removed from the ring buffer before it is committed
    with the ring_buffer_discard_commit.
    
    Since there are currently no users of this function, and because this
    function is racey and error prone, this patch removes it altogether.
    
    Note, removing this function also allows the counters to ignore
    all discarded events (patches will follow).
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 7fca71693ae7..e061b4ecdc3a 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -74,20 +74,6 @@ ring_buffer_event_time_delta(struct ring_buffer_event *event)
 	return event->time_delta;
 }
 
-/*
- * ring_buffer_event_discard can discard any event in the ring buffer.
- *   it is up to the caller to protect against a reader from
- *   consuming it or a writer from wrapping and replacing it.
- *
- * No external protection is needed if this is called before
- * the event is commited. But in that case it would be better to
- * use ring_buffer_discard_commit.
- *
- * Note, if an event that has not been committed is discarded
- * with ring_buffer_event_discard, it must still be committed.
- */
-void ring_buffer_event_discard(struct ring_buffer_event *event);
-
 /*
  * ring_buffer_discard_commit will remove an event that has not
  *   ben committed yet. If this is used, then ring_buffer_unlock_commit

commit 77ae365eca895061c8bf2b2e3ae1d9ea62869739
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Mar 27 11:00:29 2009 -0400

    ring-buffer: make lockless
    
    This patch converts the ring buffers into a completely lockless
    buffer recording system. The read side still takes locks since
    we still serialize readers. But the writers are the ones that
    must be lockless (those can happen in NMIs).
    
    The main change is to the "head_page" pointer. We write to the
    tail, and read from the head. The "head_page" pointer in the cpu
    buffer is now just a reference to where to look. The real head
    page is now kept in the head_page->list->prev->next pointer.
    That is, in the list head of the previous page we set flags.
    
    The list pages are allocated to be aligned such that the lowest
    significant bits are always zero pointing to the list. This gives
    us play to put in flags to their pointers.
    
    bit 0: set when the page is a head page
    bit 1: set when the writer is moving the page (for overwrite mode)
    
    cmpxchg is used to update the pointer.
    
    When the writer wraps the buffer and the tail meets the head,
    in overwrite mode, the writer must move the head page forward.
    It first uses cmpxchg to change the pointer flag from 1 to 2.
    Once this is done, the reader on another CPU will not take the
    page from the buffer.
    
    The writers need to protect against interrupts (we don't bother with
    disabling interrupts because NMIs are allowed to write too).
    
    After the writer sets the pointer flag to 2, it takes care to
    manage interrupts coming in. This is discribed in detail within the
    comments of the code.
    
     Changes in version 2:
      - Let reader reset entries value of header page.
      - Fix tail page passing commit page on reader page test.
      - Always increment entries and write counter in rb_tail_page_update
      - Add safety check in rb_set_commit_to_write to break out of infinite loop
      - add mask in rb_is_reader_page
    
    [ Impact: lock free writing to the ring buffer ]
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 29f8599e6bea..7fca71693ae7 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -170,7 +170,6 @@ unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
 unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu);
-unsigned long ring_buffer_nmi_dropped_cpu(struct ring_buffer *buffer, int cpu);
 
 u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu);
 void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,

commit 1744a21d57d9c60136461adb6afa85e51b3e94d9
Author: Vegard Nossum <vegard.nossum@gmail.com>
Date:   Sat Feb 28 08:29:44 2009 +0100

    trace: annotate bitfields in struct ring_buffer_event
    
    This gets rid of a heap of false-positive warnings from the tracer
    code due to the use of bitfields.
    
    [rebased for mainline inclusion]
    Signed-off-by: Vegard Nossum <vegard.nossum@gmail.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 8670f1575fe1..29f8599e6bea 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -1,6 +1,7 @@
 #ifndef _LINUX_RING_BUFFER_H
 #define _LINUX_RING_BUFFER_H
 
+#include <linux/kmemcheck.h>
 #include <linux/mm.h>
 #include <linux/seq_file.h>
 
@@ -11,7 +12,10 @@ struct ring_buffer_iter;
  * Don't refer to this struct directly, use functions below.
  */
 struct ring_buffer_event {
+	kmemcheck_bitfield_begin(bitfield);
 	u32		type_len:5, time_delta:27;
+	kmemcheck_bitfield_end(bitfield);
+
 	u32		array[];
 };
 

commit 1f8a6a10fb9437eac3f516ea4324a19087872f30
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 8 18:18:39 2009 +0200

    ring-buffer: pass in lockdep class key for reader_lock
    
    On Sun, 7 Jun 2009, Ingo Molnar wrote:
    > Testing tracer sched_switch: <6>Starting ring buffer hammer
    > PASSED
    > Testing tracer sysprof: PASSED
    > Testing tracer function: PASSED
    > Testing tracer irqsoff:
    > =============================================
    > PASSED
    > Testing tracer preemptoff: PASSED
    > Testing tracer preemptirqsoff: [ INFO: possible recursive locking detected ]
    > PASSED
    > Testing tracer branch: 2.6.30-rc8-tip-01972-ge5b9078-dirty #5760
    > ---------------------------------------------
    > rb_consumer/431 is trying to acquire lock:
    >  (&cpu_buffer->reader_lock){......}, at: [<c109eef7>] ring_buffer_reset_cpu+0x37/0x70
    >
    > but task is already holding lock:
    >  (&cpu_buffer->reader_lock){......}, at: [<c10a019e>] ring_buffer_consume+0x7e/0xc0
    >
    > other info that might help us debug this:
    > 1 lock held by rb_consumer/431:
    >  #0:  (&cpu_buffer->reader_lock){......}, at: [<c10a019e>] ring_buffer_consume+0x7e/0xc0
    
    The ring buffer is a generic structure, and can be used outside of
    ftrace. If ftrace traces within the use of the ring buffer, it can produce
    false positives with lockdep.
    
    This patch passes in a static lock key into the allocation of the ring
    buffer, so that different ring buffers will have their own lock class.
    
    Reported-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <1244477919.13761.9042.camel@twins>
    
    [ store key in ring buffer descriptor ]
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index f1345828c7c5..8670f1575fe1 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -105,7 +105,19 @@ void ring_buffer_discard_commit(struct ring_buffer *buffer,
  * size is in bytes for each per CPU buffer.
  */
 struct ring_buffer *
-ring_buffer_alloc(unsigned long size, unsigned flags);
+__ring_buffer_alloc(unsigned long size, unsigned flags, struct lock_class_key *key);
+
+/*
+ * Because the ring buffer is generic, if other users of the ring buffer get
+ * traced by ftrace, it can produce lockdep warnings. We need to keep each
+ * ring buffer's lock class separate.
+ */
+#define ring_buffer_alloc(size, flags)			\
+({							\
+	static struct lock_class_key __key;		\
+	__ring_buffer_alloc((size), (flags), &__key);	\
+})
+
 void ring_buffer_free(struct ring_buffer *buffer);
 
 int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size);

commit f0d2c681ac0a85142fc8abe65fc33fcad35cb9b7
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Wed Apr 29 13:43:37 2009 -0400

    ring-buffer: add counters for commit overrun and nmi dropped entries
    
    The WARN_ON in the ring buffer when a commit is preempted and the
    buffer is filled by preceding writes can happen in normal operations.
    The WARN_ON makes it look like a bug, not to mention, because
    it does not stop tracing and calls printk which can also recurse, this
    is prone to deadlock (the WARN_ON is not in a position to recurse).
    
    This patch removes the WARN_ON and replaces it with a counter that
    can be retrieved by a tracer. This counter is called commit_overrun.
    
    While at it, I added a nmi_dropped counter to count any time an NMI entry
    is dropped because the NMI could not take the spinlock.
    
    [ Impact: prevent deadlock by printing normal case warning ]
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 1c2f80911fbe..f1345828c7c5 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -153,6 +153,8 @@ unsigned long ring_buffer_entries(struct ring_buffer *buffer);
 unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
 unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
+unsigned long ring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu);
+unsigned long ring_buffer_nmi_dropped_cpu(struct ring_buffer *buffer, int cpu);
 
 u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu);
 void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,

commit 334d4169a6592d3fcd863bbe822a8f6985ffa9af
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Fri Apr 24 11:27:05 2009 +0800

    ring_buffer: compressed event header
    
    RB_MAX_SMALL_DATA = 28bytes is too small for most tracers, it wastes
    an 'u32' to save the actually length for events which data size > 28.
    
    This fix uses compressed event header and enlarges RB_MAX_SMALL_DATA.
    
    [ Impact: saves about 0%-12.5%(depends on tracer) memory in ring_buffer ]
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    LKML-Reference: <49F13189.3090000@cn.fujitsu.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index fac8f1ac6f49..1c2f80911fbe 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -11,7 +11,7 @@ struct ring_buffer_iter;
  * Don't refer to this struct directly, use functions below.
  */
 struct ring_buffer_event {
-	u32		type:2, len:3, time_delta:27;
+	u32		type_len:5, time_delta:27;
 	u32		array[];
 };
 
@@ -24,7 +24,8 @@ struct ring_buffer_event {
  *				  size is variable depending on how much
  *				  padding is needed
  *				 If time_delta is non zero:
- *				  everything else same as RINGBUF_TYPE_DATA
+ *				  array[0] holds the actual length
+ *				  size = 4 + length (bytes)
  *
  * @RINGBUF_TYPE_TIME_EXTEND:	Extend the time delta
  *				 array[0] = time delta (28 .. 59)
@@ -35,22 +36,23 @@ struct ring_buffer_event {
  *				 array[1..2] = tv_sec
  *				 size = 16 bytes
  *
- * @RINGBUF_TYPE_DATA:		Data record
- *				 If len is zero:
+ * <= @RINGBUF_TYPE_DATA_TYPE_LEN_MAX:
+ *				Data record
+ *				 If type_len is zero:
  *				  array[0] holds the actual length
  *				  array[1..(length+3)/4] holds data
- *				  size = 4 + 4 + length (bytes)
+ *				  size = 4 + length (bytes)
  *				 else
- *				  length = len << 2
+ *				  length = type_len << 2
  *				  array[0..(length+3)/4-1] holds data
  *				  size = 4 + length (bytes)
  */
 enum ring_buffer_type {
+	RINGBUF_TYPE_DATA_TYPE_LEN_MAX = 28,
 	RINGBUF_TYPE_PADDING,
 	RINGBUF_TYPE_TIME_EXTEND,
 	/* FIXME: RINGBUF_TYPE_TIME_STAMP not implemented */
 	RINGBUF_TYPE_TIME_STAMP,
-	RINGBUF_TYPE_DATA,
 };
 
 unsigned ring_buffer_event_length(struct ring_buffer_event *event);

commit d1b182a8d49ed6416325b4e0a1cb0f17cd4e702a
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Wed Apr 15 16:53:47 2009 -0400

    tracing/events/ring-buffer: expose format of ring buffer headers to users
    
    Currently, every thing needed to read the binary output from the
    ring buffers is available, with the exception of the way the ring
    buffers handles itself internally.
    
    This patch creates two special files in the debugfs/tracing/events
    directory:
    
     # cat /debug/tracing/events/header_page
            field: u64 timestamp;   offset:0;       size:8;
            field: local_t commit;  offset:8;       size:8;
            field: char data;       offset:16;      size:4080;
    
     # cat /debug/tracing/events/header_event
            type        :    2 bits
            len         :    3 bits
            time_delta  :   27 bits
            array       :   32 bits
    
            padding     : type == 0
            time_extend : type == 1
            data        : type == 3
    
    This is to allow a userspace app to see if the ring buffer format changes
    or not.
    
    [ Impact: allow userspace apps to know of ringbuffer format changes ]
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index f0aa486d131c..fac8f1ac6f49 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -166,6 +166,11 @@ void ring_buffer_free_read_page(struct ring_buffer *buffer, void *data);
 int ring_buffer_read_page(struct ring_buffer *buffer, void **data_page,
 			  size_t len, int cpu, int full);
 
+struct trace_seq;
+
+int ring_buffer_print_entry_header(struct trace_seq *s);
+int ring_buffer_print_page_header(struct trace_seq *s);
+
 enum ring_buffer_flags {
 	RB_FL_OVERWRITE		= 1 << 0,
 };

commit fa1b47dd85453ec7d4bcfe4aa4a2d172ba452fc3
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Thu Apr 2 00:09:41 2009 -0400

    ring-buffer: add ring_buffer_discard_commit
    
    The ring_buffer_discard_commit is similar to ring_buffer_event_discard
    but it can only be done on an event that has yet to be commited.
    Unpredictable results can happen otherwise.
    
    The main difference between ring_buffer_discard_commit and
    ring_buffer_event_discard is that ring_buffer_discard_commit will try
    to free the data in the ring buffer if nothing has addded data
    after the reserved event. If something did, then it acts almost the
    same as ring_buffer_event_discard followed by a
    ring_buffer_unlock_commit.
    
    Note, either ring_buffer_commit_discard and ring_buffer_unlock_commit
    can be called on an event, not both.
    
    This commit also exports both discard functions to be usable by
    GPL modules.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index e1b7b2173885..f0aa486d131c 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -68,8 +68,37 @@ ring_buffer_event_time_delta(struct ring_buffer_event *event)
 	return event->time_delta;
 }
 
+/*
+ * ring_buffer_event_discard can discard any event in the ring buffer.
+ *   it is up to the caller to protect against a reader from
+ *   consuming it or a writer from wrapping and replacing it.
+ *
+ * No external protection is needed if this is called before
+ * the event is commited. But in that case it would be better to
+ * use ring_buffer_discard_commit.
+ *
+ * Note, if an event that has not been committed is discarded
+ * with ring_buffer_event_discard, it must still be committed.
+ */
 void ring_buffer_event_discard(struct ring_buffer_event *event);
 
+/*
+ * ring_buffer_discard_commit will remove an event that has not
+ *   ben committed yet. If this is used, then ring_buffer_unlock_commit
+ *   must not be called on the discarded event. This function
+ *   will try to remove the event from the ring buffer completely
+ *   if another event has not been written after it.
+ *
+ * Example use:
+ *
+ *  if (some_condition)
+ *    ring_buffer_discard_commit(buffer, event);
+ *  else
+ *    ring_buffer_unlock_commit(buffer, event);
+ */
+void ring_buffer_discard_commit(struct ring_buffer *buffer,
+				struct ring_buffer_event *event);
+
 /*
  * size is in bytes for each per CPU buffer.
  */

commit 2d622719f1572ef31e0616444a515eba3094d050
Author: Tom Zanussi <tzanussi@gmail.com>
Date:   Sun Mar 22 03:30:49 2009 -0500

    tracing: add ring_buffer_event_discard() to ring buffer
    
    This patch overloads RINGBUF_TYPE_PADDING to provide a way to discard
    events from the ring buffer, for the event-filtering mechanism
    introduced in a subsequent patch.
    
    I did the initial version but thanks to Steven Rostedt for adding
    the parts that actually made it work. ;-)
    
    Signed-off-by: Tom Zanussi <tzanussi@gmail.com>
    Acked-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 9e6052bd1a1c..e1b7b2173885 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -18,10 +18,13 @@ struct ring_buffer_event {
 /**
  * enum ring_buffer_type - internal ring buffer types
  *
- * @RINGBUF_TYPE_PADDING:	Left over page padding
- *				 array is ignored
- *				 size is variable depending on how much
+ * @RINGBUF_TYPE_PADDING:	Left over page padding or discarded event
+ *				 If time_delta is 0:
+ *				  array is ignored
+ *				  size is variable depending on how much
  *				  padding is needed
+ *				 If time_delta is non zero:
+ *				  everything else same as RINGBUF_TYPE_DATA
  *
  * @RINGBUF_TYPE_TIME_EXTEND:	Extend the time delta
  *				 array[0] = time delta (28 .. 59)
@@ -65,6 +68,8 @@ ring_buffer_event_time_delta(struct ring_buffer_event *event)
 	return event->time_delta;
 }
 
+void ring_buffer_event_discard(struct ring_buffer_event *event);
+
 /*
  * size is in bytes for each per CPU buffer.
  */

commit 37886f6a9f62d22530ffee8d3f9215c8345b6969
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Tue Mar 17 17:22:06 2009 -0400

    ring-buffer: add api to allow a tracer to change clock source
    
    This patch adds a new function called ring_buffer_set_clock that
    allows a tracer to assign its own clock source to the buffer.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index b1a0068a5557..9e6052bd1a1c 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -118,8 +118,11 @@ unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
 unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
 unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
 
-u64 ring_buffer_time_stamp(int cpu);
-void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
+u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu);
+void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,
+				      int cpu, u64 *ts);
+void ring_buffer_set_clock(struct ring_buffer *buffer,
+			   u64 (*clock)(void));
 
 size_t ring_buffer_page_len(void *page);
 

commit 2002c258faaa8f89543df284fdbaa9e4b171547f
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Thu Mar 5 10:35:56 2009 -0500

    tracing: add tracing_on/tracing_off to kernel.h
    
    Impact: cleanup
    
    The functions tracing_start/tracing_stop have been moved to kernel.h.
    These are not the functions a developer most likely wants to use
    when they want to insert a place to stop tracing and restart it from
    user space.
    
    tracing_start/tracing_stop was created to work with things like
    suspend to ram, where even calling smp_processor_id() can crash the
    system. The tracing_start/tracing_stop was used to stop the tracer from
    doing anything. These are still light weight functions, but add a bit
    more overhead to be able to stop the tracers. They also have no interface
    back to userland. That is, if the kernel calls tracing_stop, userland
    can not start tracing.
    
    What a developer most likely wants to use is tracing_on/tracing_off.
    These are very light weight functions (simply sets or clears a bit).
    These functions just stop recording into the ring buffer. The tracers
    don't even know that this happens except that they would receive NULL
    from the ring_buffer_lock_reserve function.
    
    Also, there's a way for the user land to enable or disable this bit.
    In debugfs/tracing/tracing_on, a user may echo "0" (same as tracing_off())
    or echo "1" (same as tracing_on()) into this file. This becomes handy when
    a kernel developer is debugging and wants tracing to turn off when it
    hits an anomaly. Then the developer can examine the trace, and restart
    tracing if they want to try again (echo 1 > tracing_on).
    
    This patch moves the prototypes for tracing_on/tracing_off to kernel.h
    and comments their use, so that a kernel developer will know how
    to use them.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 79fcbc4b09d6..b1a0068a5557 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -124,21 +124,6 @@ void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
 size_t ring_buffer_page_len(void *page);
 
 
-/*
- * The below functions are fine to use outside the tracing facility.
- */
-#ifdef CONFIG_RING_BUFFER
-void tracing_on(void);
-void tracing_off(void);
-void tracing_off_permanent(void);
-int tracing_is_on(void);
-#else
-static inline void tracing_on(void) { }
-static inline void tracing_off(void) { }
-static inline void tracing_off_permanent(void) { }
-static inline int tracing_is_on(void) { return 0; }
-#endif
-
 void *ring_buffer_alloc_read_page(struct ring_buffer *buffer);
 void ring_buffer_free_read_page(struct ring_buffer *buffer, void *data);
 int ring_buffer_read_page(struct ring_buffer *buffer, void **data_page,

commit ef7a4a161472b952941bf78855a9cd95703c024e
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Tue Mar 3 00:27:49 2009 -0500

    ring-buffer: fix ring_buffer_read_page
    
    The ring_buffer_read_page was broken if it were to only copy part
    of the page. This patch fixes that up as well as adds a parameter
    to allow a length field, in order to only copy part of the buffer page.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index f5e793d69bd3..79fcbc4b09d6 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -121,6 +121,9 @@ unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
 u64 ring_buffer_time_stamp(int cpu);
 void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
 
+size_t ring_buffer_page_len(void *page);
+
+
 /*
  * The below functions are fine to use outside the tracing facility.
  */
@@ -138,8 +141,8 @@ static inline int tracing_is_on(void) { return 0; }
 
 void *ring_buffer_alloc_read_page(struct ring_buffer *buffer);
 void ring_buffer_free_read_page(struct ring_buffer *buffer, void *data);
-int ring_buffer_read_page(struct ring_buffer *buffer,
-			  void **data_page, int cpu, int full);
+int ring_buffer_read_page(struct ring_buffer *buffer, void **data_page,
+			  size_t len, int cpu, int full);
 
 enum ring_buffer_flags {
 	RB_FL_OVERWRITE		= 1 << 0,

commit 988ae9d6b2bc3ebdc1a488490250a6812f85e9d4
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Sat Feb 14 19:17:02 2009 -0500

    ring-buffer: add tracing_is_on to test if ring buffer is enabled
    
    This patch adds the tracing_is_on() interface to tell if the ring
    buffer is turned on or not.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 8e6646a54acf..f5e793d69bd3 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -128,10 +128,12 @@ void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
 void tracing_on(void);
 void tracing_off(void);
 void tracing_off_permanent(void);
+int tracing_is_on(void);
 #else
 static inline void tracing_on(void) { }
 static inline void tracing_off(void) { }
 static inline void tracing_off_permanent(void) { }
+static inline int tracing_is_on(void) { return 0; }
 #endif
 
 void *ring_buffer_alloc_read_page(struct ring_buffer *buffer);

commit c3706f005c3aaf570e71f0f083fdbb59a5a9fa2e
Author: Wenji Huang <wenji.huang@oracle.com>
Date:   Tue Feb 10 01:03:18 2009 -0500

    tracing: fix typos in comments
    
    Impact: clean up.
    
    Fix typos in the comments.
    
    Signed-off-by: Wenji Huang <wenji.huang@oracle.com>
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 3c103d636da3..8e6646a54acf 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -8,7 +8,7 @@ struct ring_buffer;
 struct ring_buffer_iter;
 
 /*
- * Don't reference this struct directly, use functions below.
+ * Don't refer to this struct directly, use functions below.
  */
 struct ring_buffer_event {
 	u32		type:2, len:3, time_delta:27;

commit 44b0635481437140b0e29d6023f05e805d5e7620
Merge: 4ad476e11f94 57794a9d48b6
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Feb 9 10:35:12 2009 +0100

    Merge branch 'tip/tracing/core/devel' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-2.6-trace into tracing/ftrace
    
    Conflicts:
            kernel/trace/trace_hw_branches.c

commit d8b891a2db13c8ed296158d6f8c4e335896d0cef
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Thu Feb 5 19:54:51 2009 -0500

    ring-buffer: allow tracing_off to be used in core kernel code
    
    tracing_off() is the fastest way to stop recording to the ring buffers.
    This may be used in places like panic and die, just before the
    ftrace_dump is called.
    
    This patch adds the appropriate CPP conditionals to make it a stub
    function when the ring buffer is not configured it.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index b3b359660082..ac94c066f6e9 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -124,9 +124,18 @@ unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
 u64 ring_buffer_time_stamp(int cpu);
 void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
 
+/*
+ * The below functions are fine to use outside the tracing facility.
+ */
+#ifdef CONFIG_RING_BUFFER
 void tracing_on(void);
 void tracing_off(void);
 void tracing_off_permanent(void);
+#else
+static inline void tracing_on(void) { }
+static inline void tracing_off(void) { }
+static inline void tracing_off_permanent(void) { }
+#endif
 
 void *ring_buffer_alloc_read_page(struct ring_buffer *buffer);
 void ring_buffer_free_read_page(struct ring_buffer *buffer, void *data);

commit 0a9877514c4fed10a70720293b37213dd172ee3e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Feb 5 16:12:56 2009 -0200

    ring_buffer: remove unused flags parameter
    
    Impact: API change, cleanup
    
    >From ring_buffer_{lock_reserve,unlock_commit}.
    
    $ codiff /tmp/vmlinux.before /tmp/vmlinux.after
    linux-2.6-tip/kernel/trace/trace.c:
      trace_vprintk              |  -14
      trace_graph_return         |  -14
      trace_graph_entry          |  -10
      trace_function             |   -8
      __ftrace_trace_stack       |   -8
      ftrace_trace_userstack     |   -8
      tracing_sched_switch_trace |   -8
      ftrace_trace_special       |  -12
      tracing_sched_wakeup_trace |   -8
     9 functions changed, 90 bytes removed, diff: -90
    
    linux-2.6-tip/block/blktrace.c:
      __blk_add_trace |   -1
     1 function changed, 1 bytes removed, diff: -1
    
    /tmp/vmlinux.after:
     10 functions changed, 91 bytes removed, diff: -91
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Frédéric Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index b3b359660082..3110d92e7d81 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -74,13 +74,10 @@ void ring_buffer_free(struct ring_buffer *buffer);
 
 int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size);
 
-struct ring_buffer_event *
-ring_buffer_lock_reserve(struct ring_buffer *buffer,
-			 unsigned long length,
-			 unsigned long *flags);
+struct ring_buffer_event *ring_buffer_lock_reserve(struct ring_buffer *buffer,
+						   unsigned long length);
 int ring_buffer_unlock_commit(struct ring_buffer *buffer,
-			      struct ring_buffer_event *event,
-			      unsigned long flags);
+			      struct ring_buffer_event *event);
 int ring_buffer_write(struct ring_buffer *buffer,
 		      unsigned long length, void *data);
 

commit 526ea064f953fc5ad2fb905b537f490b9374a0f0
Merge: db5e53fbf0ab d69d59f49763
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 30 17:31:25 2008 -0800

    Merge branch 'oprofile-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'oprofile-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      oprofile: select RING_BUFFER
      ring_buffer: adding EXPORT_SYMBOLs
      oprofile: fix lost sample counter
      oprofile: remove nr_available_slots()
      oprofile: port to the new ring_buffer
      ring_buffer: add remaining cpu functions to ring_buffer.h
      oprofile: moving cpu_buffer_reset() to cpu_buffer.h
      oprofile: adding cpu_buffer_entries()
      oprofile: adding cpu_buffer_write_commit()
      oprofile: adding cpu buffer r/w access functions
      ftrace: remove unused function arg in trace_iterator_increment()
      ring_buffer: update description for ring_buffer_alloc()
      oprofile: set values to default when creating oprofilefs
      oprofile: implement switch/case in buffer_sync.c
      x86/oprofile: cleanup IBS init/exit functions in op_model_amd.c
      x86/oprofile: reordering IBS code in op_model_amd.c
      oprofile: fix typo
      oprofile: whitspace changes only
      oprofile: update comment for oprofile_add_sample()
      oprofile: comment cleanup

commit e09373f22e76cc048ca5fe10a9ff9012f5d64309
Author: Robert Richter <robert.richter@amd.com>
Date:   Wed Nov 26 14:04:19 2008 +0100

    ring_buffer: add remaining cpu functions to ring_buffer.h
    
    These functions are not yet in ring_buffer.h though they seems to be
    part of the API.
    
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Robert Richter <robert.richter@amd.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index e097c2e6b6dc..de9d8c12e5ec 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -116,6 +116,8 @@ void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
 
 unsigned long ring_buffer_entries(struct ring_buffer *buffer);
 unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
+unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
+unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
 
 u64 ring_buffer_time_stamp(int cpu);
 void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);

commit 361b73d5c34f59c3fd107bb9dbe7a1fbff2c2517
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Mon Dec 8 10:58:08 2008 +0800

    ring_buffer: fix comments
    
    Impact: comments cleanup
    
    fix incorrect comments for enum ring_buffer_type
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 1a350a847edd..d363467c8f13 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -28,17 +28,19 @@ struct ring_buffer_event {
  *				 size = 8 bytes
  *
  * @RINGBUF_TYPE_TIME_STAMP:	Sync time stamp with external clock
- *				 array[0] = tv_nsec
- *				 array[1] = tv_sec
+ *				 array[0]    = tv_nsec
+ *				 array[1..2] = tv_sec
  *				 size = 16 bytes
  *
  * @RINGBUF_TYPE_DATA:		Data record
  *				 If len is zero:
  *				  array[0] holds the actual length
- *				  array[1..(length+3)/4-1] holds data
+ *				  array[1..(length+3)/4] holds data
+ *				  size = 4 + 4 + length (bytes)
  *				 else
  *				  length = len << 2
- *				  array[0..(length+3)/4] holds data
+ *				  array[0..(length+3)/4-1] holds data
+ *				  size = 4 + length (bytes)
  */
 enum ring_buffer_type {
 	RINGBUF_TYPE_PADDING,

commit 8789a9e7df6bf9b93739c4c7d4e380725bc9e936
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Tue Dec 2 15:34:07 2008 -0500

    ring-buffer: read page interface
    
    Impact: new API to ring buffer
    
    This patch adds a new interface into the ring buffer that allows a
    page to be read from the ring buffer on a given CPU. For every page
    read, one must also be given to allow for a "swap" of the pages.
    
     rpage = ring_buffer_alloc_read_page(buffer);
     if (!rpage)
            goto err;
     ret = ring_buffer_read_page(buffer, &rpage, cpu, full);
     if (!ret)
            goto empty;
     process_page(rpage);
     ring_buffer_free_read_page(rpage);
    
    The caller of these functions must handle any waits that are
    needed to wait for new data. The ring_buffer_read_page will simply
    return 0 if there is no data, or if "full" is set and the writer
    is still on the current page.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 3bb87a753fa3..1a350a847edd 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -124,6 +124,11 @@ void tracing_on(void);
 void tracing_off(void);
 void tracing_off_permanent(void);
 
+void *ring_buffer_alloc_read_page(struct ring_buffer *buffer);
+void ring_buffer_free_read_page(struct ring_buffer *buffer, void *data);
+int ring_buffer_read_page(struct ring_buffer *buffer,
+			  void **data_page, int cpu, int full);
+
 enum ring_buffer_flags {
 	RB_FL_OVERWRITE		= 1 << 0,
 };

commit 033601a32b2012b6948e80e739cca40bff4de4a0
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Nov 21 12:41:55 2008 -0500

    ring-buffer: add tracing_off_permanent
    
    Impact: feature to permanently disable ring buffer
    
    This patch adds a API to the ring buffer code that will permanently
    disable the ring buffer from ever recording. This should only be
    called when some serious anomaly is detected, and the system
    may be in an unstable state. When that happens, shutting down the
    recording to the ring buffers may be appropriate.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index e097c2e6b6dc..3bb87a753fa3 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -122,6 +122,7 @@ void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
 
 void tracing_on(void);
 void tracing_off(void);
+void tracing_off_permanent(void);
 
 enum ring_buffer_flags {
 	RB_FL_OVERWRITE		= 1 << 0,

commit a358324466b171e145df20bdb74fe81759906de6
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Tue Nov 11 15:01:42 2008 -0500

    ring-buffer: buffer record on/off switch
    
    Impact: enable/disable ring buffer recording API added
    
    Several kernel developers have requested that there be a way to stop
    recording into the ring buffers with a simple switch that can also
    be enabled from userspace. This patch addes a new kernel API to the
    ring buffers called:
    
     tracing_on()
     tracing_off()
    
    When tracing_off() is called, all ring buffers will not be able to record
    into their buffers.
    
    tracing_on() will enable the ring buffers again.
    
    These two act like an on/off switch. That is, there is no counting of the
    number of times tracing_off or tracing_on has been called.
    
    A new file is added to the debugfs/tracing directory called
    
      tracing_on
    
    This allows for userspace applications to also flip the switch.
    
      echo 0 > debugfs/tracing/tracing_on
    
    disables the tracing.
    
      echo 1 > /debugfs/tracing/tracing_on
    
    enables it.
    
    Note, this does not disable or enable any tracers. It only sets or clears
    a flag that needs to be set in order for the ring buffers to write to
    their buffers. It is a global flag, and affects all ring buffers.
    
    The buffers start out with tracing_on enabled.
    
    There are now three flags that control recording into the buffers:
    
     tracing_on: which affects all ring buffer tracers.
    
     buffer->record_disabled: which affects an allocated buffer, which may be set
         if an anomaly is detected, and tracing is disabled.
    
     cpu_buffer->record_disabled: which is set by tracing_stop() or if an
         anomaly is detected. tracing_start can not reenable this if
         an anomaly occurred.
    
    The userspace debugfs/tracing/tracing_enabled is implemented with
    tracing_stop() but the user space code can not enable it if the kernel
    called tracing_stop().
    
    Userspace can enable the tracing_on even if the kernel disabled it.
    It is just a switch used to stop tracing if a condition was hit.
    tracing_on is not for protecting critical areas in the kernel nor is
    it for stopping tracing if an anomaly occurred. This is because userspace
    can reenable it at any time.
    
    Side effect: With this patch, I discovered a dead variable in ftrace.c
      called tracing_on. This patch removes it.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index 536b0ca46a03..e097c2e6b6dc 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -120,6 +120,9 @@ unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
 u64 ring_buffer_time_stamp(int cpu);
 void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
 
+void tracing_on(void);
+void tracing_off(void);
+
 enum ring_buffer_flags {
 	RB_FL_OVERWRITE		= 1 << 0,
 };

commit d769041f865330034131525ee6a7f72eb4af2a24
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Wed Oct 1 00:29:53 2008 -0400

    ring_buffer: implement new locking
    
    The old "lock always" scheme had issues with lockdep, and was not very
    efficient anyways.
    
    This patch does a new design to be partially lockless on writes.
    Writes will add new entries to the per cpu pages by simply disabling
    interrupts. When a write needs to go to another page than it will
    grab the lock.
    
    A new "read page" has been added so that the reader can pull out a page
    from the ring buffer to read without worrying about the writer writing over
    it. This allows us to not take the lock for all reads. The lock is
    now only taken when a read needs to go to a new page.
    
    This is far from lockless, and interrupts still need to be disabled,
    but it is a step towards a more lockless solution, and it also
    solves a lot of the issues that were noticed by the first conversion
    of ftrace to the ring buffers.
    
    Note: the ring_buffer_{un}lock API has been removed.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
index c52375b8330d..536b0ca46a03 100644
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@ -63,9 +63,6 @@ ring_buffer_event_time_delta(struct ring_buffer_event *event)
 	return event->time_delta;
 }
 
-void ring_buffer_lock(struct ring_buffer *buffer, unsigned long *flags);
-void ring_buffer_unlock(struct ring_buffer *buffer, unsigned long flags);
-
 /*
  * size is in bytes for each per CPU buffer.
  */

commit 7a8e76a3829f1067b70f715771ff88baf2fbf3c3
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Mon Sep 29 23:02:38 2008 -0400

    tracing: unified trace buffer
    
    This is a unified tracing buffer that implements a ring buffer that
    hopefully everyone will eventually be able to use.
    
    The events recorded into the buffer have the following structure:
    
      struct ring_buffer_event {
            u32 type:2, len:3, time_delta:27;
            u32 array[];
      };
    
    The minimum size of an event is 8 bytes. All events are 4 byte
    aligned inside the buffer.
    
    There are 4 types (all internal use for the ring buffer, only
    the data type is exported to the interface users).
    
     RINGBUF_TYPE_PADDING: this type is used to note extra space at the end
            of a buffer page.
    
     RINGBUF_TYPE_TIME_EXTENT: This type is used when the time between events
            is greater than the 27 bit delta can hold. We add another
            32 bits, and record that in its own event (8 byte size).
    
     RINGBUF_TYPE_TIME_STAMP: (Not implemented yet). This will hold data to
            help keep the buffer timestamps in sync.
    
    RINGBUF_TYPE_DATA: The event actually holds user data.
    
    The "len" field is only three bits. Since the data must be
    4 byte aligned, this field is shifted left by 2, giving a
    max length of 28 bytes. If the data load is greater than 28
    bytes, the first array field holds the full length of the
    data load and the len field is set to zero.
    
    Example, data size of 7 bytes:
    
            type = RINGBUF_TYPE_DATA
            len = 2
            time_delta: <time-stamp> - <prev_event-time-stamp>
            array[0..1]: <7 bytes of data> <1 byte empty>
    
    This event is saved in 12 bytes of the buffer.
    
    An event with 82 bytes of data:
    
            type = RINGBUF_TYPE_DATA
            len = 0
            time_delta: <time-stamp> - <prev_event-time-stamp>
            array[0]: 84 (Note the alignment)
            array[1..14]: <82 bytes of data> <2 bytes empty>
    
    The above event is saved in 92 bytes (if my math is correct).
    82 bytes of data, 2 bytes empty, 4 byte header, 4 byte length.
    
    Do not reference the above event struct directly. Use the following
    functions to gain access to the event table, since the
    ring_buffer_event structure may change in the future.
    
    ring_buffer_event_length(event): get the length of the event.
            This is the size of the memory used to record this
            event, and not the size of the data pay load.
    
    ring_buffer_time_delta(event): get the time delta of the event
            This returns the delta time stamp since the last event.
            Note: Even though this is in the header, there should
                    be no reason to access this directly, accept
                    for debugging.
    
    ring_buffer_event_data(event): get the data from the event
            This is the function to use to get the actual data
            from the event. Note, it is only a pointer to the
            data inside the buffer. This data must be copied to
            another location otherwise you risk it being written
            over in the buffer.
    
    ring_buffer_lock: A way to lock the entire buffer.
    ring_buffer_unlock: unlock the buffer.
    
    ring_buffer_alloc: create a new ring buffer. Can choose between
            overwrite or consumer/producer mode. Overwrite will
            overwrite old data, where as consumer producer will
            throw away new data if the consumer catches up with the
            producer.  The consumer/producer is the default.
    
    ring_buffer_free: free the ring buffer.
    
    ring_buffer_resize: resize the buffer. Changes the size of each cpu
            buffer. Note, it is up to the caller to provide that
            the buffer is not being used while this is happening.
            This requirement may go away but do not count on it.
    
    ring_buffer_lock_reserve: locks the ring buffer and allocates an
            entry on the buffer to write to.
    ring_buffer_unlock_commit: unlocks the ring buffer and commits it to
            the buffer.
    
    ring_buffer_write: writes some data into the ring buffer.
    
    ring_buffer_peek: Look at a next item in the cpu buffer.
    ring_buffer_consume: get the next item in the cpu buffer and
            consume it. That is, this function increments the head
            pointer.
    
    ring_buffer_read_start: Start an iterator of a cpu buffer.
            For now, this disables the cpu buffer, until you issue
            a finish. This is just because we do not want the iterator
            to be overwritten. This restriction may change in the future.
            But note, this is used for static reading of a buffer which
            is usually done "after" a trace. Live readings would want
            to use the ring_buffer_consume above, which will not
            disable the ring buffer.
    
    ring_buffer_read_finish: Finishes the read iterator and reenables
            the ring buffer.
    
    ring_buffer_iter_peek: Look at the next item in the cpu iterator.
    ring_buffer_read: Read the iterator and increment it.
    ring_buffer_iter_reset: Reset the iterator to point to the beginning
            of the cpu buffer.
    ring_buffer_iter_empty: Returns true if the iterator is at the end
            of the cpu buffer.
    
    ring_buffer_size: returns the size in bytes of each cpu buffer.
            Note, the real size is this times the number of CPUs.
    
    ring_buffer_reset_cpu: Sets the cpu buffer to empty
    ring_buffer_reset: sets all cpu buffers to empty
    
    ring_buffer_swap_cpu: swaps a cpu buffer from one buffer with a
            cpu buffer of another buffer. This is handy when you
            want to take a snap shot of a running trace on just one
            cpu. Having a backup buffer, to swap with facilitates this.
            Ftrace max latencies use this.
    
    ring_buffer_empty: Returns true if the ring buffer is empty.
    ring_buffer_empty_cpu: Returns true if the cpu buffer is empty.
    
    ring_buffer_record_disable: disable all cpu buffers (read only)
    ring_buffer_record_disable_cpu: disable a single cpu buffer (read only)
    ring_buffer_record_enable: enable all cpu buffers.
    ring_buffer_record_enabl_cpu: enable a single cpu buffer.
    
    ring_buffer_entries: The number of entries in a ring buffer.
    ring_buffer_overruns: The number of entries removed due to writing wrap.
    
    ring_buffer_time_stamp: Get the time stamp used by the ring buffer
    ring_buffer_normalize_time_stamp: normalize the ring buffer time stamp
            into nanosecs.
    
    I still need to implement the GTOD feature. But we need support from
    the cpu frequency infrastructure.  But this can be done at a later
    time without affecting the ring buffer interface.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h
new file mode 100644
index 000000000000..c52375b8330d
--- /dev/null
+++ b/include/linux/ring_buffer.h
@@ -0,0 +1,130 @@
+#ifndef _LINUX_RING_BUFFER_H
+#define _LINUX_RING_BUFFER_H
+
+#include <linux/mm.h>
+#include <linux/seq_file.h>
+
+struct ring_buffer;
+struct ring_buffer_iter;
+
+/*
+ * Don't reference this struct directly, use functions below.
+ */
+struct ring_buffer_event {
+	u32		type:2, len:3, time_delta:27;
+	u32		array[];
+};
+
+/**
+ * enum ring_buffer_type - internal ring buffer types
+ *
+ * @RINGBUF_TYPE_PADDING:	Left over page padding
+ *				 array is ignored
+ *				 size is variable depending on how much
+ *				  padding is needed
+ *
+ * @RINGBUF_TYPE_TIME_EXTEND:	Extend the time delta
+ *				 array[0] = time delta (28 .. 59)
+ *				 size = 8 bytes
+ *
+ * @RINGBUF_TYPE_TIME_STAMP:	Sync time stamp with external clock
+ *				 array[0] = tv_nsec
+ *				 array[1] = tv_sec
+ *				 size = 16 bytes
+ *
+ * @RINGBUF_TYPE_DATA:		Data record
+ *				 If len is zero:
+ *				  array[0] holds the actual length
+ *				  array[1..(length+3)/4-1] holds data
+ *				 else
+ *				  length = len << 2
+ *				  array[0..(length+3)/4] holds data
+ */
+enum ring_buffer_type {
+	RINGBUF_TYPE_PADDING,
+	RINGBUF_TYPE_TIME_EXTEND,
+	/* FIXME: RINGBUF_TYPE_TIME_STAMP not implemented */
+	RINGBUF_TYPE_TIME_STAMP,
+	RINGBUF_TYPE_DATA,
+};
+
+unsigned ring_buffer_event_length(struct ring_buffer_event *event);
+void *ring_buffer_event_data(struct ring_buffer_event *event);
+
+/**
+ * ring_buffer_event_time_delta - return the delta timestamp of the event
+ * @event: the event to get the delta timestamp of
+ *
+ * The delta timestamp is the 27 bit timestamp since the last event.
+ */
+static inline unsigned
+ring_buffer_event_time_delta(struct ring_buffer_event *event)
+{
+	return event->time_delta;
+}
+
+void ring_buffer_lock(struct ring_buffer *buffer, unsigned long *flags);
+void ring_buffer_unlock(struct ring_buffer *buffer, unsigned long flags);
+
+/*
+ * size is in bytes for each per CPU buffer.
+ */
+struct ring_buffer *
+ring_buffer_alloc(unsigned long size, unsigned flags);
+void ring_buffer_free(struct ring_buffer *buffer);
+
+int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size);
+
+struct ring_buffer_event *
+ring_buffer_lock_reserve(struct ring_buffer *buffer,
+			 unsigned long length,
+			 unsigned long *flags);
+int ring_buffer_unlock_commit(struct ring_buffer *buffer,
+			      struct ring_buffer_event *event,
+			      unsigned long flags);
+int ring_buffer_write(struct ring_buffer *buffer,
+		      unsigned long length, void *data);
+
+struct ring_buffer_event *
+ring_buffer_peek(struct ring_buffer *buffer, int cpu, u64 *ts);
+struct ring_buffer_event *
+ring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts);
+
+struct ring_buffer_iter *
+ring_buffer_read_start(struct ring_buffer *buffer, int cpu);
+void ring_buffer_read_finish(struct ring_buffer_iter *iter);
+
+struct ring_buffer_event *
+ring_buffer_iter_peek(struct ring_buffer_iter *iter, u64 *ts);
+struct ring_buffer_event *
+ring_buffer_read(struct ring_buffer_iter *iter, u64 *ts);
+void ring_buffer_iter_reset(struct ring_buffer_iter *iter);
+int ring_buffer_iter_empty(struct ring_buffer_iter *iter);
+
+unsigned long ring_buffer_size(struct ring_buffer *buffer);
+
+void ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu);
+void ring_buffer_reset(struct ring_buffer *buffer);
+
+int ring_buffer_swap_cpu(struct ring_buffer *buffer_a,
+			 struct ring_buffer *buffer_b, int cpu);
+
+int ring_buffer_empty(struct ring_buffer *buffer);
+int ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu);
+
+void ring_buffer_record_disable(struct ring_buffer *buffer);
+void ring_buffer_record_enable(struct ring_buffer *buffer);
+void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
+void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
+
+unsigned long ring_buffer_entries(struct ring_buffer *buffer);
+unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
+
+u64 ring_buffer_time_stamp(int cpu);
+void ring_buffer_normalize_time_stamp(int cpu, u64 *ts);
+
+enum ring_buffer_flags {
+	RB_FL_OVERWRITE		= 1 << 0,
+};
+
+#endif /* _LINUX_RING_BUFFER_H */
