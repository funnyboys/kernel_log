commit 67cd46244611ca7b0d5447dac9a0cbd76b875210
Author: Gustavo A. R. Silva <gustavoars@kernel.org>
Date:   Thu May 28 09:35:11 2020 -0500

    FS-Cache: Replace zero-length array with flexible-array
    
    There is a regular need in the kernel to provide a way to declare having a
    dynamically sized set of trailing elements in a structure. Kernel code should
    always use “flexible array members”[1] for these cases. The older style of
    one-element or zero-length arrays should no longer be used[2].
    
    [1] https://en.wikipedia.org/wiki/Flexible_array_member
    [2] https://github.com/KSPP/linux/issues/21
    
    Signed-off-by: Gustavo A. R. Silva <gustavoars@kernel.org>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index ce0b5fbf239d..3f0b19dcfae7 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -46,7 +46,7 @@ struct fscache_cache_tag {
 	unsigned long		flags;
 #define FSCACHE_TAG_RESERVED	0		/* T if tag is reserved for a cache */
 	atomic_t		usage;
-	char			name[0];	/* tag name */
+	char			name[];	/* tag name */
 };
 
 /*

commit 0e822145b564204cd5e9dd67a7fd37d4a7b8253b
Author: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>
Date:   Mon Apr 27 23:16:58 2020 +0200

    docs: filesystems: caching/backend-api.txt: convert it to ReST
    
    - Add a SPDX header;
    - Adjust document and section titles;
    - Some whitespace fixes and new line breaks;
    - Mark literal blocks as such;
    - Add table markups;
    - Add it to filesystems/caching/index.rst.
    
    Signed-off-by: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>
    Link: https://lore.kernel.org/r/5d0a61abaa87bfe913b9e2f321e74ef7af0f3dfc.1588021877.git.mchehab+huawei@kernel.org
    Signed-off-by: Jonathan Corbet <corbet@lwn.net>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index d5ba431b5d63..ce0b5fbf239d 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -6,7 +6,7 @@
  *
  * NOTE!!! See:
  *
- *	Documentation/filesystems/caching/backend-api.txt
+ *	Documentation/filesystems/caching/backend-api.rst
  *
  * for a description of the cache backend interface declared here.
  */
@@ -454,7 +454,7 @@ static inline void fscache_object_lookup_error(struct fscache_object *object)
  * Set the maximum size an object is permitted to reach, implying the highest
  * byte that may be written.  Intended to be called by the attr_changed() op.
  *
- * See Documentation/filesystems/caching/backend-api.txt for a complete
+ * See Documentation/filesystems/caching/backend-api.rst for a complete
  * description.
  */
 static inline

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 610815e3f1aa..d5ba431b5d63 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -1,13 +1,9 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /* General filesystem caching backing cache interface
  *
  * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.
  * Written by David Howells (dhowells@redhat.com)
  *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
- *
  * NOTE!!! See:
  *
  *	Documentation/filesystems/caching/backend-api.txt

commit 3f2b7b9035107d6096ea438ea3d97dcf0481b6d2
Author: kiran.modukuri <kiran.modukuri@gmail.com>
Date:   Mon Nov 26 15:41:48 2018 +0000

    fscache: Fix race in fscache_op_complete() due to split atomic_sub & read
    
    The code in fscache_retrieval_complete is using atomic_sub followed by an
    atomic_read:
    
            atomic_sub(n_pages, &op->n_pages);
            if (atomic_read(&op->n_pages) <= 0)
                    fscache_op_complete(&op->op, true);
    
    This causes two threads doing a decrement of n_pages to race with each
    other seeing the op->refcount 0 at same time - and they end up calling
    fscache_op_complete() in both the threads leading to an assertion failure.
    
    Fix this by using atomic_sub_return_relaxed() instead of two calls.  Note
    that I'm using 'relaxed' rather than, say, 'release' as there aren't
    multiple variables that appear to need ordering across the release.
    
    The oops looks something like:
    
    FS-Cache: Assertion failed
    FS-Cache: 0 > 0 is false
    ...
    kernel BUG at /usr/src/linux-4.4.0/fs/fscache/operation.c:449!
    ...
    Workqueue: fscache_operation fscache_op_work_func [fscache]
    ...
    RIP: 0010:[<ffffffffc037eacd>] fscache_op_complete+0x10d/0x180 [fscache]
    ...
    Call Trace:
     [<ffffffffc1464cf9>] cachefiles_read_copier+0x3a9/0x410 [cachefiles]
     [<ffffffffc037e272>] fscache_op_work_func+0x22/0x50 [fscache]
     [<ffffffff81096da0>] process_one_work+0x150/0x3f0
     [<ffffffff8109751a>] worker_thread+0x11a/0x470
     [<ffffffff81808e59>] ? __schedule+0x359/0x980
     [<ffffffff81097400>] ? rescuer_thread+0x310/0x310
     [<ffffffff8109cdd6>] kthread+0xd6/0xf0
     [<ffffffff8109cd00>] ? kthread_park+0x60/0x60
     [<ffffffff8180d0cf>] ret_from_fork+0x3f/0x70
     [<ffffffff8109cd00>] ? kthread_park+0x60/0x60
    
    This seen this in 4.4.x kernels and the same bug affects fscache in latest
    upstreams kernels.
    
    Fixes: 1bb4b7f98f36 ("FS-Cache: The retrieval remaining-pages counter needs to be atomic_t")
    Signed-off-by: Kiran Kumar Modukuri <kiran.modukuri@gmail.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 34cf0fdd7dc7..610815e3f1aa 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -196,8 +196,7 @@ static inline void fscache_enqueue_retrieval(struct fscache_retrieval *op)
 static inline void fscache_retrieval_complete(struct fscache_retrieval *op,
 					      int n_pages)
 {
-	atomic_sub(n_pages, &op->n_pages);
-	if (atomic_read(&op->n_pages) <= 0)
+	if (atomic_sub_return_relaxed(n_pages, &op->n_pages) <= 0)
 		fscache_op_complete(&op->op, false);
 }
 

commit ee1235a9a06813429c201bf186397a6feeea07bf
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:28 2018 +0100

    fscache: Pass object size in rather than calling back for it
    
    Pass the object size in to fscache_acquire_cookie() and
    fscache_write_page() rather than the netfs providing a callback by which it
    can be received.  This makes it easier to update the size of the object
    when a new page is written that extends the object.
    
    The current object size is also passed by fscache to the check_aux
    function, obviating the need to store it in the aux data.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Anna Schumaker <anna.schumaker@netapp.com>
    Tested-by: Steve Dickson <steved@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 3e764fd38d9f..34cf0fdd7dc7 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -553,7 +553,8 @@ extern bool fscache_object_sleep_till_congested(signed long *timeoutp);
 
 extern enum fscache_checkaux fscache_check_aux(struct fscache_object *object,
 					       const void *data,
-					       uint16_t datalen);
+					       uint16_t datalen,
+					       loff_t object_size);
 
 extern void fscache_object_retrying_stale(struct fscache_object *object);
 

commit 08c2e3d087840cd1e7141b62d92f3dc897147984
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:27 2018 +0100

    fscache: Add more tracepoints
    
    Add more tracepoints to fscache, including:
    
     (*) fscache_page - Tracks netfs pages known to fscache.
    
     (*) fscache_check_page - Tracks the netfs querying whether a page is
         pending storage.
    
     (*) fscache_wake_cookie - Tracks cookies being woken up after a page
         completes/aborts storage in the cache.
    
     (*) fscache_op - Tracks operations being initialised.
    
     (*) fscache_wrote_page - Tracks return of the backend write_page op.
    
     (*) fscache_gang_lookup - Tracks lookup of pages to be stored in the write
         operation.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index fbe102f37074..3e764fd38d9f 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -135,7 +135,8 @@ extern void fscache_op_work_func(struct work_struct *work);
 extern void fscache_enqueue_operation(struct fscache_operation *);
 extern void fscache_op_complete(struct fscache_operation *, bool);
 extern void fscache_put_operation(struct fscache_operation *);
-extern void fscache_operation_init(struct fscache_operation *,
+extern void fscache_operation_init(struct fscache_cookie *,
+				   struct fscache_operation *,
 				   fscache_operation_processor_t,
 				   fscache_operation_cancel_t,
 				   fscache_operation_release_t);

commit a18feb55769b705a44c4107786c4045eae2e87b6
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:27 2018 +0100

    fscache: Add tracepoints
    
    Add some tracepoints to fscache:
    
     (*) fscache_cookie - Tracks a cookie's usage count.
    
     (*) fscache_netfs - Logs registration of a network filesystem, including
         the pointer to the cookie allocated.
    
     (*) fscache_acquire - Logs cookie acquisition.
    
     (*) fscache_relinquish - Logs cookie relinquishment.
    
     (*) fscache_enable - Logs enablement of a cookie.
    
     (*) fscache_disable - Logs disablement of a cookie.
    
     (*) fscache_osm - Tracks execution of states in the object state machine.
    
    and cachefiles:
    
     (*) cachefiles_ref - Tracks a cachefiles object's usage count.
    
     (*) cachefiles_lookup - Logs result of lookup_one_len().
    
     (*) cachefiles_mkdir - Logs result of vfs_mkdir().
    
     (*) cachefiles_create - Logs result of vfs_create().
    
     (*) cachefiles_unlink - Logs calls to vfs_unlink().
    
     (*) cachefiles_rename - Logs calls to vfs_rename().
    
     (*) cachefiles_mark_active - Logs an object becoming active.
    
     (*) cachefiles_wait_active - Logs a wait for an old object to be
         destroyed.
    
     (*) cachefiles_mark_inactive - Logs an object becoming inactive.
    
     (*) cachefiles_mark_buried - Logs the burial of an object.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index b19fa8592fc2..fbe102f37074 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -29,6 +29,18 @@ struct fscache_cache_ops;
 struct fscache_object;
 struct fscache_operation;
 
+enum fscache_obj_ref_trace {
+	fscache_obj_get_add_to_deps,
+	fscache_obj_get_queue,
+	fscache_obj_put_alloc_fail,
+	fscache_obj_put_attach_fail,
+	fscache_obj_put_drop_obj,
+	fscache_obj_put_enq_dep,
+	fscache_obj_put_queue,
+	fscache_obj_put_work,
+	fscache_obj_ref__nr_traces
+};
+
 /*
  * cache tag definition
  */
@@ -231,7 +243,8 @@ struct fscache_cache_ops {
 	void (*lookup_complete)(struct fscache_object *object);
 
 	/* increment the usage count on this object (may fail if unmounting) */
-	struct fscache_object *(*grab_object)(struct fscache_object *object);
+	struct fscache_object *(*grab_object)(struct fscache_object *object,
+					      enum fscache_obj_ref_trace why);
 
 	/* pin an object in the cache */
 	int (*pin_object)(struct fscache_object *object);
@@ -254,7 +267,8 @@ struct fscache_cache_ops {
 	void (*drop_object)(struct fscache_object *object);
 
 	/* dispose of a reference to an object */
-	void (*put_object)(struct fscache_object *object);
+	void (*put_object)(struct fscache_object *object,
+			   enum fscache_obj_ref_trace why);
 
 	/* sync a cache */
 	void (*sync_cache)(struct fscache_cache *cache);

commit b27ddd46245311850f850024df54d0537506f3c1
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:26 2018 +0100

    fscache: Pass the correct cancelled indications to fscache_op_complete()
    
    The last parameter to fscache_op_complete() is a bool indicating whether or
    not the operation was cancelled.  A lot of the time the inverse value is
    given or no differentiation is made.  Fix this.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 3b03e29e2f1a..b19fa8592fc2 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -185,7 +185,7 @@ static inline void fscache_retrieval_complete(struct fscache_retrieval *op,
 {
 	atomic_sub(n_pages, &op->n_pages);
 	if (atomic_read(&op->n_pages) <= 0)
-		fscache_op_complete(&op->op, true);
+		fscache_op_complete(&op->op, false);
 }
 
 /**

commit dc5d4afbb0bf7b7746ff5e56e1a5688ad7f29b32
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Mar 15 11:43:43 2018 +0100

    sched/wait, fs/fscache: Convert wait_on_atomic_t() usage to the new wait_var_event() API
    
    The old wait_on_atomic_t() is going to get removed, use the more
    flexible wait_var_event() API instead.
    
    No change in functionality.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 4c467ef50159..3b03e29e2f1a 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -496,7 +496,7 @@ static inline bool __fscache_unuse_cookie(struct fscache_cookie *cookie)
 
 static inline void __fscache_wake_unused_cookie(struct fscache_cookie *cookie)
 {
-	wake_up_atomic_t(&cookie->n_active);
+	wake_up_var(&cookie->n_active);
 }
 
 /**

commit e26bfebdfc0d212d366de9990a096665d5c0209a
Author: David Howells <dhowells@redhat.com>
Date:   Tue Jan 31 09:45:28 2017 +0000

    fscache: Fix dead object requeue
    
    Under some circumstances, an fscache object can become queued such that it
    fscache_object_work_func() can be called once the object is in the
    OBJECT_DEAD state.  This results in the kernel oopsing when it tries to
    invoke the handler for the state (which is hard coded to 0x2).
    
    The way this comes about is something like the following:
    
     (1) The object dispatcher is processing a work state for an object.  This
         is done in workqueue context.
    
     (2) An out-of-band event comes in that isn't masked, causing the object to
         be queued, say EV_KILL.
    
     (3) The object dispatcher finishes processing the current work state on
         that object and then sees there's another event to process, so,
         without returning to the workqueue core, it processes that event too.
         It then follows the chain of events that initiates until we reach
         OBJECT_DEAD without going through a wait state (such as
         WAIT_FOR_CLEARANCE).
    
         At this point, object->events may be 0, object->event_mask will be 0
         and oob_event_mask will be 0.
    
     (4) The object dispatcher returns to the workqueue processor, and in due
         course, this sees that the object's work item is still queued and
         invokes it again.
    
     (5) The current state is a work state (OBJECT_DEAD), so the dispatcher
         jumps to it - resulting in an OOPS.
    
    When I'm seeing this, the work state in (1) appears to have been either
    LOOK_UP_OBJECT or CREATE_OBJECT (object->oob_table is
    fscache_osm_lookup_oob).
    
    The window for (2) is very small:
    
     (A) object->event_mask is cleared whilst the event dispatch process is
         underway - though there's no memory barrier to force this to the top
         of the function.
    
         The window, therefore is from the time the object was selected by the
         workqueue processor and made requeueable to the time the mask was
         cleared.
    
     (B) fscache_raise_event() will only queue the object if it manages to set
         the event bit and the corresponding event_mask bit was set.
    
         The enqueuement is then deferred slightly whilst we get a ref on the
         object and get the per-CPU variable for workqueue congestion.  This
         slight deferral slightly increases the probability by allowing extra
         time for the workqueue to make the item requeueable.
    
    Handle this by giving the dead state a processor function and checking the
    for the dead state address rather than seeing if the processor function is
    address 0x2.  The dead state processor function can then set a flag to
    indicate that it's occurred and give a warning if it occurs more than once
    per object.
    
    If this race occurs, an oops similar to the following is seen (note the RIP
    value):
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000002
    IP: [<0000000000000002>] 0x1
    PGD 0
    Oops: 0010 [#1] SMP
    Modules linked in: ...
    CPU: 17 PID: 16077 Comm: kworker/u48:9 Not tainted 3.10.0-327.18.2.el7.x86_64 #1
    Hardware name: HP ProLiant DL380 Gen9/ProLiant DL380 Gen9, BIOS P89 12/27/2015
    Workqueue: fscache_object fscache_object_work_func [fscache]
    task: ffff880302b63980 ti: ffff880717544000 task.ti: ffff880717544000
    RIP: 0010:[<0000000000000002>]  [<0000000000000002>] 0x1
    RSP: 0018:ffff880717547df8  EFLAGS: 00010202
    RAX: ffffffffa0368640 RBX: ffff880edf7a4480 RCX: dead000000200200
    RDX: 0000000000000002 RSI: 00000000ffffffff RDI: ffff880edf7a4480
    RBP: ffff880717547e18 R08: 0000000000000000 R09: dfc40a25cb3a4510
    R10: dfc40a25cb3a4510 R11: 0000000000000400 R12: 0000000000000000
    R13: ffff880edf7a4510 R14: ffff8817f6153400 R15: 0000000000000600
    FS:  0000000000000000(0000) GS:ffff88181f420000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 0000000000000002 CR3: 000000000194a000 CR4: 00000000001407e0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Stack:
     ffffffffa0363695 ffff880edf7a4510 ffff88093f16f900 ffff8817faa4ec00
     ffff880717547e60 ffffffff8109d5db 00000000faa4ec18 0000000000000000
     ffff8817faa4ec18 ffff88093f16f930 ffff880302b63980 ffff88093f16f900
    Call Trace:
     [<ffffffffa0363695>] ? fscache_object_work_func+0xa5/0x200 [fscache]
     [<ffffffff8109d5db>] process_one_work+0x17b/0x470
     [<ffffffff8109e4ac>] worker_thread+0x21c/0x400
     [<ffffffff8109e290>] ? rescuer_thread+0x400/0x400
     [<ffffffff810a5acf>] kthread+0xcf/0xe0
     [<ffffffff810a5a00>] ? kthread_create_on_node+0x140/0x140
     [<ffffffff816460d8>] ret_from_fork+0x58/0x90
     [<ffffffff810a5a00>] ? kthread_create_on_node+0x140/0x140
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Jeremy McNicoll <jeremymc@redhat.com>
    Tested-by: Frank Sorenson <sorenson@redhat.com>
    Tested-by: Benjamin Coddington <bcodding@redhat.com>
    Reviewed-by: Benjamin Coddington <bcodding@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 13ba552e6c09..4c467ef50159 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -360,6 +360,7 @@ struct fscache_object {
 #define FSCACHE_OBJECT_IS_AVAILABLE	5	/* T if object has become active */
 #define FSCACHE_OBJECT_RETIRED		6	/* T if object was retired on relinquishment */
 #define FSCACHE_OBJECT_KILLED_BY_CACHE	7	/* T if object was killed by the cache */
+#define FSCACHE_OBJECT_RUN_AFTER_DEAD	8	/* T if object has been dispatched after death */
 
 	struct list_head	cache_link;	/* link in cache->object_list */
 	struct hlist_node	cookie_link;	/* link in cookie->backing_objects */

commit 480ce08a70e4179f34808a3bdbfe6627f624cf54
Author: Yan, Zheng <zyan@redhat.com>
Date:   Fri May 20 18:32:31 2016 +0800

    FS-Cache: make check_consistency callback return int
    
    __fscache_check_consistency() calls check_consistency() callback
    and return the callback's return value. But the return type of
    check_consistency() is bool. So __fscache_check_consistency()
    return 1 if the cache is inconsistent. This is inconsistent with
    the document.
    
    Signed-off-by: Yan, Zheng <zyan@redhat.com>
    Acked-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 604e1526cd00..13ba552e6c09 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -241,7 +241,7 @@ struct fscache_cache_ops {
 
 	/* check the consistency between the backing cache and the FS-Cache
 	 * cookie */
-	bool (*check_consistency)(struct fscache_operation *op);
+	int (*check_consistency)(struct fscache_operation *op);
 
 	/* store the updated auxiliary data on an object */
 	void (*update_object)(struct fscache_object *object);

commit 4a47132ff472a0c2c5441baeb50cf97f2580bc43
Author: David Howells <dhowells@redhat.com>
Date:   Tue Feb 24 10:05:29 2015 +0000

    FS-Cache: Retain the netfs context in the retrieval op earlier
    
    Now that the retrieval operation may be disposed of by fscache_put_operation()
    before we actually set the context, the retrieval-specific cleanup operation
    can produce a NULL-pointer dereference when it tries to unconditionally clean
    up the netfs context.
    
    Given that it is expected that we'll get at least as far as the place where we
    currently set the context pointer and it is unlikely we'll go through the
    error handling paths prior to that point, retain the context right from the
    point that the retrieval op is allocated.
    
    Concomitant to this, we need to retain the cookie pointer in the retrieval op
    also so that we can call the netfs to release its context in the release
    method.
    
    In addition, we might now get into fscache_release_retrieval_op() with the op
    only initialised.  To this end, set the operation to DEAD only after the
    release method has been called and skip the n_pages test upon cleanup if the
    op is still in the INITIALISED state.
    
    Without these changes, the following oops might be seen:
    
            BUG: unable to handle kernel NULL pointer dereference at 00000000000000b8
            ...
            RIP: 0010:[<ffffffffa0089c98>] fscache_release_retrieval_op+0xae/0x100
            ...
            Call Trace:
             [<ffffffffa0088560>] fscache_put_operation+0x117/0x2e0
             [<ffffffffa008b8f5>] __fscache_read_or_alloc_pages+0x351/0x3ac
             [<ffffffffa00b761f>] __nfs_readpages_from_fscache+0x59/0xbf [nfs]
             [<ffffffffa00b06c5>] nfs_readpages+0x10c/0x185 [nfs]
             [<ffffffff81124925>] ? alloc_pages_current+0x119/0x13e
             [<ffffffff810ee5fd>] ? __page_cache_alloc+0xfb/0x10a
             [<ffffffff810f87f8>] __do_page_cache_readahead+0x188/0x22c
             [<ffffffff810f8b3a>] ondemand_readahead+0x29e/0x2af
             [<ffffffff810f8c92>] page_cache_sync_readahead+0x38/0x3a
             [<ffffffff810ef337>] generic_file_read_iter+0x1a2/0x55a
             [<ffffffffa00a9dff>] ? nfs_revalidate_mapping+0xd6/0x288 [nfs]
             [<ffffffffa00a6a23>] nfs_file_read+0x49/0x70 [nfs]
             [<ffffffff811363be>] new_sync_read+0x78/0x9c
             [<ffffffff81137164>] __vfs_read+0x13/0x38
             [<ffffffff8113721e>] vfs_read+0x95/0x121
             [<ffffffff811372f6>] SyS_read+0x4c/0x8a
             [<ffffffff81557a52>] system_call_fastpath+0x12/0x17
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 69c6eb10d858..604e1526cd00 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -133,6 +133,7 @@ extern void fscache_operation_init(struct fscache_operation *,
  */
 struct fscache_retrieval {
 	struct fscache_operation op;
+	struct fscache_cookie	*cookie;	/* The netfs cookie */
 	struct address_space	*mapping;	/* netfs pages */
 	fscache_rw_complete_t	end_io_func;	/* function to call on I/O completion */
 	void			*context;	/* netfs read context (pinned) */

commit d3b97ca4a99e4e6c78f5a21c968eadf5c8ba9971
Author: David Howells <dhowells@redhat.com>
Date:   Tue Feb 24 10:05:29 2015 +0000

    FS-Cache: The operation cancellation method needs calling in more places
    
    Any time an incomplete operation is cancelled, the operation cancellation
    function needs to be called to clean up.  This is currently being passed
    directly to some of the functions that might want to call it, but not all.
    
    Instead, pass the cancellation method pointer to the fscache_operation_init()
    and have that cache it in the operation struct.  Further, plug in a dummy
    cancellation handler if the caller declines to set one as this allows us to
    call the function unconditionally (the extra overhead isn't worth bothering
    about as we don't expect to be calling this typically).
    
    The cancellation method must thence be called everywhere the CANCELLED state
    is set.  Note that we call it *before* setting the CANCELLED state such that
    the method can use the old state value to guide its operation.
    
    fscache_do_cancel_retrieval() needs moving higher up in the sources so that
    the init function can use it now.
    
    Without this, the following oops may be seen:
    
            FS-Cache: Assertion failed
            FS-Cache: 3 == 0 is false
            ------------[ cut here ]------------
            kernel BUG at ../fs/fscache/page.c:261!
            ...
            RIP: 0010:[<ffffffffa0089c1b>]  fscache_release_retrieval_op+0x77/0x100
             [<ffffffffa008853d>] fscache_put_operation+0x114/0x2da
             [<ffffffffa008b8c2>] __fscache_read_or_alloc_pages+0x358/0x3b3
             [<ffffffffa00b761f>] __nfs_readpages_from_fscache+0x59/0xbf [nfs]
             [<ffffffffa00b06c5>] nfs_readpages+0x10c/0x185 [nfs]
             [<ffffffff81124925>] ? alloc_pages_current+0x119/0x13e
             [<ffffffff810ee5fd>] ? __page_cache_alloc+0xfb/0x10a
             [<ffffffff810f87f8>] __do_page_cache_readahead+0x188/0x22c
             [<ffffffff810f8b3a>] ondemand_readahead+0x29e/0x2af
             [<ffffffff810f8c92>] page_cache_sync_readahead+0x38/0x3a
             [<ffffffff810ef337>] generic_file_read_iter+0x1a2/0x55a
             [<ffffffffa00a9dff>] ? nfs_revalidate_mapping+0xd6/0x288 [nfs]
             [<ffffffffa00a6a23>] nfs_file_read+0x49/0x70 [nfs]
             [<ffffffff811363be>] new_sync_read+0x78/0x9c
             [<ffffffff81137164>] __vfs_read+0x13/0x38
             [<ffffffff8113721e>] vfs_read+0x95/0x121
             [<ffffffff811372f6>] SyS_read+0x4c/0x8a
             [<ffffffff81557a52>] system_call_fastpath+0x12/0x17
    
    The assertion is showing that the remaining number of pages (n_pages) is not 0
    when the operation is being released.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 0e26d49972e3..69c6eb10d858 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -74,6 +74,7 @@ extern wait_queue_head_t fscache_cache_cleared_wq;
  */
 typedef void (*fscache_operation_release_t)(struct fscache_operation *op);
 typedef void (*fscache_operation_processor_t)(struct fscache_operation *op);
+typedef void (*fscache_operation_cancel_t)(struct fscache_operation *op);
 
 enum fscache_operation_state {
 	FSCACHE_OP_ST_BLANK,		/* Op is not yet submitted */
@@ -109,6 +110,9 @@ struct fscache_operation {
 	 *   the op in a non-pool thread */
 	fscache_operation_processor_t processor;
 
+	/* Operation cancellation cleanup (optional) */
+	fscache_operation_cancel_t cancel;
+
 	/* operation releaser */
 	fscache_operation_release_t release;
 };
@@ -121,6 +125,7 @@ extern void fscache_op_complete(struct fscache_operation *, bool);
 extern void fscache_put_operation(struct fscache_operation *);
 extern void fscache_operation_init(struct fscache_operation *,
 				   fscache_operation_processor_t,
+				   fscache_operation_cancel_t,
 				   fscache_operation_release_t);
 
 /*

commit 1339ec98e32b4bc8efb6fbb71c006a465130aaba
Author: David Howells <dhowells@redhat.com>
Date:   Wed Feb 25 13:26:39 2015 +0000

    FS-Cache: Out of line fscache_operation_init()
    
    Out of line fscache_operation_init() so that it can access internal FS-Cache
    features, such as stats, in a later commit.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index ca3d550da11e..0e26d49972e3 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -119,27 +119,9 @@ extern void fscache_op_work_func(struct work_struct *work);
 extern void fscache_enqueue_operation(struct fscache_operation *);
 extern void fscache_op_complete(struct fscache_operation *, bool);
 extern void fscache_put_operation(struct fscache_operation *);
-
-/**
- * fscache_operation_init - Do basic initialisation of an operation
- * @op: The operation to initialise
- * @release: The release function to assign
- *
- * Do basic initialisation of an operation.  The caller must still set flags,
- * object and processor if needed.
- */
-static inline void fscache_operation_init(struct fscache_operation *op,
-					fscache_operation_processor_t processor,
-					fscache_operation_release_t release)
-{
-	INIT_WORK(&op->work, fscache_op_work_func);
-	atomic_set(&op->usage, 1);
-	op->state = FSCACHE_OP_ST_INITIALISED;
-	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
-	op->processor = processor;
-	op->release = release;
-	INIT_LIST_HEAD(&op->pend_link);
-}
+extern void fscache_operation_init(struct fscache_operation *,
+				   fscache_operation_processor_t,
+				   fscache_operation_release_t);
 
 /*
  * data read operation

commit 87021526300f1a292dd966e141e183630ac95317
Author: David Howells <dhowells@redhat.com>
Date:   Tue Feb 24 10:52:51 2015 +0000

    FS-Cache: fscache_object_is_dead() has wrong logic, kill it
    
    fscache_object_is_dead() returns true only if the object is marked dead and
    the cache got an I/O error.  This should be a logical OR instead.  Since two
    of the callers got split up into handling for separate subcases, expand the
    other callers and kill the function.  This is probably the right thing to do
    anyway since one of the subcases isn't about the object at all, but rather
    about the cache.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 2e83a141e465..ca3d550da11e 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -423,12 +423,6 @@ static inline bool fscache_object_is_active(struct fscache_object *object)
 		!fscache_cache_is_broken(object);
 }
 
-static inline bool fscache_object_is_dead(struct fscache_object *object)
-{
-	return fscache_object_is_dying(object) &&
-		fscache_cache_is_broken(object);
-}
-
 /**
  * fscache_object_destroyed - Note destruction of an object in a cache
  * @cache: The cache from which the object came

commit 30ceec6284129662efc3a1e7675b2bd857a046fe
Author: David Howells <dhowells@redhat.com>
Date:   Tue Feb 24 10:05:27 2015 +0000

    FS-Cache: When submitting an op, cancel it if the target object is dying
    
    When submitting an operation, prefer to cancel the operation immediately
    rather than queuing it for later processing if the object is marked as dying
    (ie. the object state machine has reached the KILL_OBJECT state).
    
    Whilst we're at it, change the series of related test_bit() calls into a
    READ_ONCE() and bitwise-AND operators to reduce the number of load
    instructions (test_bit() has a volatile address).
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index c9dafdaf3347..2e83a141e465 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -411,17 +411,22 @@ static inline bool fscache_object_is_available(struct fscache_object *object)
 	return test_bit(FSCACHE_OBJECT_IS_AVAILABLE, &object->flags);
 }
 
+static inline bool fscache_cache_is_broken(struct fscache_object *object)
+{
+	return test_bit(FSCACHE_IOERROR, &object->cache->flags);
+}
+
 static inline bool fscache_object_is_active(struct fscache_object *object)
 {
 	return fscache_object_is_available(object) &&
 		fscache_object_is_live(object) &&
-		!test_bit(FSCACHE_IOERROR, &object->cache->flags);
+		!fscache_cache_is_broken(object);
 }
 
 static inline bool fscache_object_is_dead(struct fscache_object *object)
 {
 	return fscache_object_is_dying(object) &&
-		test_bit(FSCACHE_IOERROR, &object->cache->flags);
+		fscache_cache_is_broken(object);
 }
 
 /**

commit 182d919b84902eece162c63ed3d476c8016b4197
Author: David Howells <dhowells@redhat.com>
Date:   Thu Feb 19 23:47:31 2015 +0000

    FS-Cache: Count culled objects and objects rejected due to lack of space
    
    Count the number of objects that get culled by the cache backend and the
    number of objects that the cache backend declines to instantiate due to lack
    of space in the cache.
    
    These numbers are made available through /proc/fs/fscache/stats
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 771484993ca7..c9dafdaf3347 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -371,6 +371,7 @@ struct fscache_object {
 #define FSCACHE_OBJECT_IS_LOOKED_UP	4	/* T if object has been looked up */
 #define FSCACHE_OBJECT_IS_AVAILABLE	5	/* T if object has become active */
 #define FSCACHE_OBJECT_RETIRED		6	/* T if object was retired on relinquishment */
+#define FSCACHE_OBJECT_KILLED_BY_CACHE	7	/* T if object was killed by the cache */
 
 	struct list_head	cache_link;	/* link in cache->object_list */
 	struct hlist_node	cookie_link;	/* link in cookie->backing_objects */
@@ -551,4 +552,15 @@ extern enum fscache_checkaux fscache_check_aux(struct fscache_object *object,
 					       const void *data,
 					       uint16_t datalen);
 
+extern void fscache_object_retrying_stale(struct fscache_object *object);
+
+enum fscache_why_object_killed {
+	FSCACHE_OBJECT_IS_STALE,
+	FSCACHE_OBJECT_NO_SPACE,
+	FSCACHE_OBJECT_WAS_RETIRED,
+	FSCACHE_OBJECT_WAS_CULLED,
+};
+extern void fscache_object_mark_killed(struct fscache_object *object,
+				       enum fscache_why_object_killed why);
+
 #endif /* _LINUX_FSCACHE_CACHE_H */

commit 94d30ae90a00cafe686c1057be57f4885f963abf
Author: David Howells <dhowells@redhat.com>
Date:   Sat Sep 21 00:09:31 2013 +0100

    FS-Cache: Provide the ability to enable/disable cookies
    
    Provide the ability to enable and disable fscache cookies.  A disabled cookie
    will reject or ignore further requests to:
    
            Acquire a child cookie
            Invalidate and update backing objects
            Check the consistency of a backing object
            Allocate storage for backing page
            Read backing pages
            Write to backing pages
    
    but still allows:
    
            Checks/waits on the completion of already in-progress objects
            Uncaching of pages
            Relinquishment of cookies
    
    Two new operations are provided:
    
     (1) Disable a cookie:
    
            void fscache_disable_cookie(struct fscache_cookie *cookie,
                                        bool invalidate);
    
         If the cookie is not already disabled, this locks the cookie against other
         dis/enablement ops, marks the cookie as being disabled, discards or
         invalidates any backing objects and waits for cessation of activity on any
         associated object.
    
         This is a wrapper around a chunk split out of fscache_relinquish_cookie(),
         but it reinitialises the cookie such that it can be reenabled.
    
         All possible failures are handled internally.  The caller should consider
         calling fscache_uncache_all_inode_pages() afterwards to make sure all page
         markings are cleared up.
    
     (2) Enable a cookie:
    
            void fscache_enable_cookie(struct fscache_cookie *cookie,
                                       bool (*can_enable)(void *data),
                                       void *data)
    
         If the cookie is not already enabled, this locks the cookie against other
         dis/enablement ops, invokes can_enable() and, if the cookie is not an
         index cookie, will begin the procedure of acquiring backing objects.
    
         The optional can_enable() function is passed the data argument and returns
         a ruling as to whether or not enablement should actually be permitted to
         begin.
    
         All possible failures are handled internally.  The cookie will only be
         marked as enabled if provisional backing objects are allocated.
    
    A later patch will introduce these to NFS.  Cookie enablement during nfs_open()
    is then contingent on i_writecount <= 0.  can_enable() checks for a race
    between open(O_RDONLY) and open(O_WRONLY/O_RDWR).  This simplifies NFS's cookie
    handling and allows us to get rid of open(O_RDONLY) accidentally introducing
    caching to an inode that's open for writing already.
    
    One operation has its API modified:
    
     (3) Acquire a cookie.
    
            struct fscache_cookie *fscache_acquire_cookie(
                    struct fscache_cookie *parent,
                    const struct fscache_cookie_def *def,
                    void *netfs_data,
                    bool enable);
    
         This now has an additional argument that indicates whether the requested
         cookie should be enabled by default.  It doesn't need the can_enable()
         function because the caller must prevent multiple calls for the same netfs
         object and it doesn't need to take the enablement lock because no one else
         can get at the cookie before this returns.
    
    Signed-off-by: David Howells <dhowells@redhat.com

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 96a2b66f5968..771484993ca7 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -308,36 +308,6 @@ struct fscache_cache_ops {
 	void (*dissociate_pages)(struct fscache_cache *cache);
 };
 
-/*
- * data file or index object cookie
- * - a file will only appear in one cache
- * - a request to cache a file may or may not be honoured, subject to
- *   constraints such as disk space
- * - indices are created on disk just-in-time
- */
-struct fscache_cookie {
-	atomic_t			usage;		/* number of users of this cookie */
-	atomic_t			n_children;	/* number of children of this cookie */
-	atomic_t			n_active;	/* number of active users of netfs ptrs */
-	spinlock_t			lock;
-	spinlock_t			stores_lock;	/* lock on page store tree */
-	struct hlist_head		backing_objects; /* object(s) backing this file/index */
-	const struct fscache_cookie_def	*def;		/* definition */
-	struct fscache_cookie		*parent;	/* parent of this entry */
-	void				*netfs_data;	/* back pointer to netfs */
-	struct radix_tree_root		stores;		/* pages to be stored on this cookie */
-#define FSCACHE_COOKIE_PENDING_TAG	0		/* pages tag: pending write to cache */
-#define FSCACHE_COOKIE_STORING_TAG	1		/* pages tag: writing to cache */
-
-	unsigned long			flags;
-#define FSCACHE_COOKIE_LOOKING_UP	0	/* T if non-index cookie being looked up still */
-#define FSCACHE_COOKIE_NO_DATA_YET	1	/* T if new object with no cached data yet */
-#define FSCACHE_COOKIE_UNAVAILABLE	2	/* T if cookie is unavailable (error, etc) */
-#define FSCACHE_COOKIE_INVALIDATING	3	/* T if cookie is being invalidated */
-#define FSCACHE_COOKIE_RELINQUISHED	4	/* T if cookie has been relinquished */
-#define FSCACHE_COOKIE_RETIRED		5	/* T if cookie was retired */
-};
-
 extern struct fscache_cookie fscache_fsdef_index;
 
 /*
@@ -400,6 +370,7 @@ struct fscache_object {
 #define FSCACHE_OBJECT_IS_LIVE		3	/* T if object is not withdrawn or relinquished */
 #define FSCACHE_OBJECT_IS_LOOKED_UP	4	/* T if object has been looked up */
 #define FSCACHE_OBJECT_IS_AVAILABLE	5	/* T if object has become active */
+#define FSCACHE_OBJECT_RETIRED		6	/* T if object was retired on relinquishment */
 
 	struct list_head	cache_link;	/* link in cache->object_list */
 	struct hlist_node	cookie_link;	/* link in cookie->backing_objects */

commit 8fb883f3e30065529e4f35d4b4f355193dcdb7a2
Author: David Howells <dhowells@redhat.com>
Date:   Sat Sep 21 00:09:31 2013 +0100

    FS-Cache: Add use/unuse/wake cookie wrappers
    
    Add wrapper functions for dealing with cookie->n_active:
    
     (*) __fscache_use_cookie() to increment it.
    
     (*) __fscache_unuse_cookie() to decrement and test against zero.
    
     (*) __fscache_wake_unused_cookie() to wake up anyone waiting for it to reach
         zero.
    
    The second and third are split so that the third can be done after cookie->lock
    has been released in case the waiter wakes up whilst we're still holding it and
    tries to get it.
    
    We will need to wake-on-zero once the cookie disablement patch is applied
    because it will then be possible to see n_active become zero without the cookie
    being relinquished.
    
    Also move the cookie usement out of fscache_attr_changed_op() and into
    fscache_attr_changed() and the operation struct so that cookie disablement
    will be able to track it.
    
    Whilst we're at it, only increment n_active if we're about to do
    fscache_submit_op() so that we don't have to deal with undoing it if anything
    earlier fails.  Possibly this should be moved into fscache_submit_op() which
    could look at FSCACHE_OP_UNUSE_COOKIE.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 7823e9ef995e..96a2b66f5968 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -511,6 +511,11 @@ static inline void fscache_end_io(struct fscache_retrieval *op,
 	op->end_io_func(page, op->context, error);
 }
 
+static inline void __fscache_use_cookie(struct fscache_cookie *cookie)
+{
+	atomic_inc(&cookie->n_active);
+}
+
 /**
  * fscache_use_cookie - Request usage of cookie attached to an object
  * @object: Object description
@@ -524,6 +529,16 @@ static inline bool fscache_use_cookie(struct fscache_object *object)
 	return atomic_inc_not_zero(&cookie->n_active) != 0;
 }
 
+static inline bool __fscache_unuse_cookie(struct fscache_cookie *cookie)
+{
+	return atomic_dec_and_test(&cookie->n_active);
+}
+
+static inline void __fscache_wake_unused_cookie(struct fscache_cookie *cookie)
+{
+	wake_up_atomic_t(&cookie->n_active);
+}
+
 /**
  * fscache_unuse_cookie - Cease usage of cookie attached to an object
  * @object: Object description
@@ -534,8 +549,8 @@ static inline bool fscache_use_cookie(struct fscache_object *object)
 static inline void fscache_unuse_cookie(struct fscache_object *object)
 {
 	struct fscache_cookie *cookie = object->cookie;
-	if (atomic_dec_and_test(&cookie->n_active))
-		wake_up_atomic_t(&cookie->n_active);
+	if (__fscache_unuse_cookie(cookie))
+		__fscache_wake_unused_cookie(cookie);
 }
 
 /*

commit da9803bc8812f5bd3b26baaa90e515b843c65ff7
Author: David Howells <dhowells@redhat.com>
Date:   Wed Aug 21 17:29:38 2013 -0400

    FS-Cache: Add interface to check consistency of a cached object
    
    Extend the fscache netfs API so that the netfs can ask as to whether a cache
    object is up to date with respect to its corresponding netfs object:
    
            int fscache_check_consistency(struct fscache_cookie *cookie)
    
    This will call back to the netfs to check whether the auxiliary data associated
    with a cookie is correct.  It returns 0 if it is and -ESTALE if it isn't; it
    may also return -ENOMEM and -ERESTARTSYS.
    
    The backends now have to implement a mandatory operation pointer:
    
            int (*check_consistency)(struct fscache_object *object)
    
    that corresponds to the above API call.  FS-Cache takes care of pinning the
    object and the cookie in memory and managing this call with respect to the
    object state.
    
    Original-author: Hongyi Jia <jiayisuse@gmail.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Hongyi Jia <jiayisuse@gmail.com>
    cc: Milosz Tanski <milosz@adfin.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index a9ff9a36b86d..7823e9ef995e 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -251,6 +251,10 @@ struct fscache_cache_ops {
 	/* unpin an object in the cache */
 	void (*unpin_object)(struct fscache_object *object);
 
+	/* check the consistency between the backing cache and the FS-Cache
+	 * cookie */
+	bool (*check_consistency)(struct fscache_operation *op);
+
 	/* store the updated auxiliary data on an object */
 	void (*update_object)(struct fscache_object *object);
 

commit 1bb4b7f98f361132ea322834515334d95b93c184
Author: David Howells <dhowells@redhat.com>
Date:   Tue May 21 13:44:15 2013 +0100

    FS-Cache: The retrieval remaining-pages counter needs to be atomic_t
    
    struct fscache_retrieval contains a count of the number of pages that still
    need some processing (n_pages).  This is decremented as the pages are
    processed.
    
    However, this needs to be atomic as fscache_retrieval_complete() (I think) just
    occasionally may be called from cachefiles_read_backing_file() and
    cachefiles_read_copier() simultaneously.
    
    This happens when an fscache_read_or_alloc_pages() request containing a lot of
    pages (say a couple of hundred) is being processed.  The read on each backing
    page is dispatched individually because we need to insert a monitor into the
    waitqueue to catch when the read completes.  However, under low-memory
    conditions, we might be forced to wait in the allocator - and this gives the
    I/O on the backing page a chance to complete first.
    
    When the I/O completes, fscache_enqueue_retrieval() chucks the retrieval onto
    the workqueue without waiting for the operation to finish the initial I/O
    dispatch (we want to release any pages we can as soon as we can), thus both can
    end up running simultaneously and potentially attempting to partially complete
    the retrieval simultaneously (ENOMEM may occur, backing pages may already be in
    the page cache).
    
    This was demonstrated by parallelling the non-atomic counter with an atomic
    counter and printing both of them when the assertion fails.  At this point, the
    atomic counter has reached zero, but the non-atomic counter has not.
    
    To fix this, make the counter an atomic_t.
    
    This results in the following bug appearing
    
            FS-Cache: Assertion failed
            3 == 5 is false
            ------------[ cut here ]------------
            kernel BUG at fs/fscache/operation.c:421!
    
    or
    
            FS-Cache: Assertion failed
            3 == 5 is false
            ------------[ cut here ]------------
            kernel BUG at fs/fscache/operation.c:414!
    
    With a backtrace like the following:
    
    RIP: 0010:[<ffffffffa0211b1d>] fscache_put_operation+0x1ad/0x240 [fscache]
    Call Trace:
     [<ffffffffa0213185>] fscache_retrieval_work+0x55/0x270 [fscache]
     [<ffffffffa0213130>] ? fscache_retrieval_work+0x0/0x270 [fscache]
     [<ffffffff81090b10>] worker_thread+0x170/0x2a0
     [<ffffffff81096d10>] ? autoremove_wake_function+0x0/0x40
     [<ffffffff810909a0>] ? worker_thread+0x0/0x2a0
     [<ffffffff81096966>] kthread+0x96/0xa0
     [<ffffffff8100c0ca>] child_rip+0xa/0x20
     [<ffffffff810968d0>] ? kthread+0x0/0xa0
     [<ffffffff8100c0c0>] ? child_rip+0x0/0x20
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-and-tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index d32f70611a00..a9ff9a36b86d 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -151,7 +151,7 @@ struct fscache_retrieval {
 	void			*context;	/* netfs read context (pinned) */
 	struct list_head	to_do;		/* list of things to be done by the backend */
 	unsigned long		start_time;	/* time at which retrieval started */
-	unsigned		n_pages;	/* number of pages to be retrieved */
+	atomic_t		n_pages;	/* number of pages to be retrieved */
 };
 
 typedef int (*fscache_page_retrieval_func_t)(struct fscache_retrieval *op,
@@ -195,15 +195,14 @@ static inline void fscache_enqueue_retrieval(struct fscache_retrieval *op)
 static inline void fscache_retrieval_complete(struct fscache_retrieval *op,
 					      int n_pages)
 {
-	op->n_pages -= n_pages;
-	if (op->n_pages <= 0)
+	atomic_sub(n_pages, &op->n_pages);
+	if (atomic_read(&op->n_pages) <= 0)
 		fscache_op_complete(&op->op, true);
 }
 
 /**
  * fscache_put_retrieval - Drop a reference to a retrieval operation
  * @op: The retrieval operation affected
- * @n_pages: The number of pages to account for
  *
  * Drop a reference to a retrieval operation.
  */

commit 1362729b169b7903c7e739dbe7904994b0d8c47f
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 10 19:50:26 2013 +0100

    FS-Cache: Simplify cookie retention for fscache_objects, fixing oops
    
    Simplify the way fscache cache objects retain their cookie.  The way I
    implemented the cookie storage handling made synchronisation a pain (ie. the
    object state machine can't rely on the cookie actually still being there).
    
    Instead of the the object being detached from the cookie and the cookie being
    freed in __fscache_relinquish_cookie(), we defer both operations:
    
     (*) The detachment of the object from the list in the cookie now takes place
         in fscache_drop_object() and is thus governed by the object state machine
         (fscache_detach_from_cookie() has been removed).
    
     (*) The release of the cookie is now in fscache_object_destroy() - which is
         called by the cache backend just before it frees the object.
    
    This means that the fscache_cookie struct is now available to the cache all the
    way through from ->alloc_object() to ->drop_object() and ->put_object() -
    meaning that it's no longer necessary to take object->lock to guarantee access.
    
    However, __fscache_relinquish_cookie() doesn't wait for the object to go all
    the way through to destruction before letting the netfs proceed.  That would
    massively slow down the netfs.  Since __fscache_relinquish_cookie() leaves the
    cookie around, in must therefore break all attachments to the netfs - which
    includes ->def, ->netfs_data and any outstanding page read/writes.
    
    To handle this, struct fscache_cookie now has an n_active counter:
    
     (1) This starts off initialised to 1.
    
     (2) Any time the cache needs to get at the netfs data, it calls
         fscache_use_cookie() to increment it - if it is not zero.  If it was zero,
         then access is not permitted.
    
     (3) When the cache has finished with the data, it calls fscache_unuse_cookie()
         to decrement it.  This does a wake-up on it if it reaches 0.
    
     (4) __fscache_relinquish_cookie() decrements n_active and then waits for it to
         reach 0.  The initialisation to 1 in step (1) ensures that we only get
         wake ups when we're trying to get rid of the cookie.
    
    This leaves __fscache_relinquish_cookie() a lot simpler.
    
    
    ***
    This fixes a problem in the current code whereby if fscache_invalidate() is
    followed sufficiently quickly by fscache_relinquish_cookie() then it is
    possible for __fscache_relinquish_cookie() to have detached the cookie from the
    object and cleared the pointer before a thread is dispatched to process the
    invalidation state in the object state machine.
    
    Since the pending write clearance was deferred to the invalidation state to
    make it asynchronous, we need to either wait in relinquishment for the stores
    tree to be cleared in the invalidation state or we need to handle the clearance
    in relinquishment.
    
    Further, if the relinquishment code does clear the tree, then the invalidation
    state need to make the clearance contingent on still having the cookie to hand
    (since that's where the tree is rooted) and we have to prevent the cookie from
    disappearing for the duration.
    
    This can lead to an oops like the following:
    
    BUG: unable to handle kernel NULL pointer dereference at 000000000000000c
    ...
    RIP: 0010:[<ffffffff8151023e>] _spin_lock+0xe/0x30
    ...
    CR2: 000000000000000c ...
    ...
    Process kslowd002 (...)
    ....
    Call Trace:
     [<ffffffffa01c3278>] fscache_invalidate_writes+0x38/0xd0 [fscache]
     [<ffffffff810096f0>] ? __switch_to+0xd0/0x320
     [<ffffffff8105e759>] ? find_busiest_queue+0x69/0x150
     [<ffffffff8110ddd4>] ? slow_work_enqueue+0x104/0x180
     [<ffffffffa01c1303>] fscache_object_slow_work_execute+0x5e3/0x9d0 [fscache]
     [<ffffffff81096b67>] ? bit_waitqueue+0x17/0xd0
     [<ffffffff8110e233>] slow_work_execute+0x233/0x310
     [<ffffffff8110e515>] slow_work_thread+0x205/0x360
     [<ffffffff81096ca0>] ? autoremove_wake_function+0x0/0x40
     [<ffffffff8110e310>] ? slow_work_thread+0x0/0x360
     [<ffffffff81096936>] kthread+0x96/0xa0
     [<ffffffff8100c0ca>] child_rip+0xa/0x20
     [<ffffffff810968a0>] ? kthread+0x0/0xa0
     [<ffffffff8100c0c0>] ? child_rip+0x0/0x20
    
    The parameter to fscache_invalidate_writes() was object->cookie which is NULL.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 9ff516b1b9a0..d32f70611a00 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -97,7 +97,8 @@ struct fscache_operation {
 #define FSCACHE_OP_WAITING	4	/* cleared when op is woken */
 #define FSCACHE_OP_EXCLUSIVE	5	/* exclusive op, other ops must wait */
 #define FSCACHE_OP_DEC_READ_CNT	6	/* decrement object->n_reads on destruction */
-#define FSCACHE_OP_KEEP_FLAGS	0x0070	/* flags to keep when repurposing an op */
+#define FSCACHE_OP_UNUSE_COOKIE	7	/* call fscache_unuse_cookie() on completion */
+#define FSCACHE_OP_KEEP_FLAGS	0x00f0	/* flags to keep when repurposing an op */
 
 	enum fscache_operation_state state;
 	atomic_t		usage;
@@ -314,6 +315,7 @@ struct fscache_cache_ops {
 struct fscache_cookie {
 	atomic_t			usage;		/* number of users of this cookie */
 	atomic_t			n_children;	/* number of children of this cookie */
+	atomic_t			n_active;	/* number of active users of netfs ptrs */
 	spinlock_t			lock;
 	spinlock_t			stores_lock;	/* lock on page store tree */
 	struct hlist_head		backing_objects; /* object(s) backing this file/index */
@@ -326,11 +328,11 @@ struct fscache_cookie {
 
 	unsigned long			flags;
 #define FSCACHE_COOKIE_LOOKING_UP	0	/* T if non-index cookie being looked up still */
-#define FSCACHE_COOKIE_CREATING		1	/* T if non-index object being created still */
-#define FSCACHE_COOKIE_NO_DATA_YET	2	/* T if new object with no cached data yet */
-#define FSCACHE_COOKIE_UNAVAILABLE	3	/* T if cookie is unavailable (error, etc) */
-#define FSCACHE_COOKIE_WAITING_ON_READS	4	/* T if cookie is waiting on reads */
-#define FSCACHE_COOKIE_INVALIDATING	5	/* T if cookie is being invalidated */
+#define FSCACHE_COOKIE_NO_DATA_YET	1	/* T if new object with no cached data yet */
+#define FSCACHE_COOKIE_UNAVAILABLE	2	/* T if cookie is unavailable (error, etc) */
+#define FSCACHE_COOKIE_INVALIDATING	3	/* T if cookie is being invalidated */
+#define FSCACHE_COOKIE_RELINQUISHED	4	/* T if cookie has been relinquished */
+#define FSCACHE_COOKIE_RETIRED		5	/* T if cookie was retired */
 };
 
 extern struct fscache_cookie fscache_fsdef_index;
@@ -392,10 +394,9 @@ struct fscache_object {
 #define FSCACHE_OBJECT_LOCK		0	/* T if object is busy being processed */
 #define FSCACHE_OBJECT_PENDING_WRITE	1	/* T if object has pending write */
 #define FSCACHE_OBJECT_WAITING		2	/* T if object is waiting on its parent */
-#define FSCACHE_OBJECT_RETIRE		3	/* T if object should be retired */
-#define FSCACHE_OBJECT_IS_LIVE		4	/* T if object is not withdrawn or relinquished */
-#define FSCACHE_OBJECT_IS_LOOKED_UP	5	/* T if object has been looked up */
-#define FSCACHE_OBJECT_IS_AVAILABLE	6	/* T if object has become active */
+#define FSCACHE_OBJECT_IS_LIVE		3	/* T if object is not withdrawn or relinquished */
+#define FSCACHE_OBJECT_IS_LOOKED_UP	4	/* T if object has been looked up */
+#define FSCACHE_OBJECT_IS_AVAILABLE	5	/* T if object has become active */
 
 	struct list_head	cache_link;	/* link in cache->object_list */
 	struct hlist_node	cookie_link;	/* link in cookie->backing_objects */
@@ -415,16 +416,11 @@ struct fscache_object {
 
 extern void fscache_object_init(struct fscache_object *, struct fscache_cookie *,
 				struct fscache_cache *);
+extern void fscache_object_destroy(struct fscache_object *);
 
 extern void fscache_object_lookup_negative(struct fscache_object *object);
 extern void fscache_obtained_object(struct fscache_object *object);
 
-#ifdef CONFIG_FSCACHE_OBJECT_LIST
-extern void fscache_object_destroy(struct fscache_object *object);
-#else
-#define fscache_object_destroy(object) do {} while(0)
-#endif
-
 static inline bool fscache_object_is_live(struct fscache_object *object)
 {
 	return test_bit(FSCACHE_OBJECT_IS_LIVE, &object->flags);
@@ -512,6 +508,33 @@ static inline void fscache_end_io(struct fscache_retrieval *op,
 	op->end_io_func(page, op->context, error);
 }
 
+/**
+ * fscache_use_cookie - Request usage of cookie attached to an object
+ * @object: Object description
+ * 
+ * Request usage of the cookie attached to an object.  NULL is returned if the
+ * relinquishment had reduced the cookie usage count to 0.
+ */
+static inline bool fscache_use_cookie(struct fscache_object *object)
+{
+	struct fscache_cookie *cookie = object->cookie;
+	return atomic_inc_not_zero(&cookie->n_active) != 0;
+}
+
+/**
+ * fscache_unuse_cookie - Cease usage of cookie attached to an object
+ * @object: Object description
+ * 
+ * Cease usage of the cookie attached to an object.  When the users count
+ * reaches zero then the cookie relinquishment will be permitted to proceed.
+ */
+static inline void fscache_unuse_cookie(struct fscache_object *object)
+{
+	struct fscache_cookie *cookie = object->cookie;
+	if (atomic_dec_and_test(&cookie->n_active))
+		wake_up_atomic_t(&cookie->n_active);
+}
+
 /*
  * out-of-line cache backend functions
  */

commit caaef6900befb45689b1d1831ce3c7e7fb5b504f
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 10 19:50:26 2013 +0100

    FS-Cache: Fix object state machine to have separate work and wait states
    
    Fix object state machine to have separate work and wait states as that makes
    it easier to envision.
    
    There are now three kinds of state:
    
     (1) Work state.  This is an execution state.  No event processing is performed
         by a work state.  The function attached to a work state returns a pointer
         indicating the next state to which the OSM should transition.  Returning
         NO_TRANSIT repeats the current state, but goes back to the scheduler
         first.
    
     (2) Wait state.  This is an event processing state.  No execution is
         performed by a wait state.  Wait states are just tables of "if event X
         occurs, clear it and transition to state Y".  The dispatcher returns to
         the scheduler if none of the events in which the wait state has an
         interest are currently pending.
    
     (3) Out-of-band state.  This is a special work state.  Transitions to normal
         states can be overridden when an unexpected event occurs (eg. I/O error).
         Instead the dispatcher disables and clears the OOB event and transits to
         the specified work state.  This then acts as an ordinary work state,
         though object->state points to the overridden destination.  Returning
         NO_TRANSIT resumes the overridden transition.
    
    In addition, the states have names in their definitions, so there's no need for
    tables of state names.  Further, the EV_REQUEUE event is no longer necessary as
    that is automatic for work states.
    
    Since the states are now separate structs rather than values in an enum, it's
    not possible to use comparisons other than (non-)equality between them, so use
    some object->flags to indicate what phase an object is in.
    
    The EV_RELEASE, EV_RETIRE and EV_WITHDRAW events have been squished into one
    (EV_KILL).  An object flag now carries the information about retirement.
    
    Similarly, the RELEASING, RECYCLING and WITHDRAWING states have been merged
    into an KILL_OBJECT state and additional states have been added for handling
    waiting dependent objects (JUMPSTART_DEPS and KILL_DEPENDENTS).
    
    A state has also been added for synchronising with parent object initialisation
    (WAIT_FOR_PARENT) and another for initiating look up (PARENT_READY).
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index c5f92347cbf8..9ff516b1b9a0 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -328,11 +328,9 @@ struct fscache_cookie {
 #define FSCACHE_COOKIE_LOOKING_UP	0	/* T if non-index cookie being looked up still */
 #define FSCACHE_COOKIE_CREATING		1	/* T if non-index object being created still */
 #define FSCACHE_COOKIE_NO_DATA_YET	2	/* T if new object with no cached data yet */
-#define FSCACHE_COOKIE_PENDING_FILL	3	/* T if pending initial fill on object */
-#define FSCACHE_COOKIE_FILLING		4	/* T if filling object incrementally */
-#define FSCACHE_COOKIE_UNAVAILABLE	5	/* T if cookie is unavailable (error, etc) */
-#define FSCACHE_COOKIE_WAITING_ON_READS	6	/* T if cookie is waiting on reads */
-#define FSCACHE_COOKIE_INVALIDATING	7	/* T if cookie is being invalidated */
+#define FSCACHE_COOKIE_UNAVAILABLE	3	/* T if cookie is unavailable (error, etc) */
+#define FSCACHE_COOKIE_WAITING_ON_READS	4	/* T if cookie is waiting on reads */
+#define FSCACHE_COOKIE_INVALIDATING	5	/* T if cookie is being invalidated */
 };
 
 extern struct fscache_cookie fscache_fsdef_index;
@@ -341,45 +339,40 @@ extern struct fscache_cookie fscache_fsdef_index;
  * Event list for fscache_object::{event_mask,events}
  */
 enum {
-	FSCACHE_OBJECT_EV_REQUEUE,	/* T if object should be requeued */
+	FSCACHE_OBJECT_EV_NEW_CHILD,	/* T if object has a new child */
+	FSCACHE_OBJECT_EV_PARENT_READY,	/* T if object's parent is ready */
 	FSCACHE_OBJECT_EV_UPDATE,	/* T if object should be updated */
 	FSCACHE_OBJECT_EV_INVALIDATE,	/* T if cache requested object invalidation */
 	FSCACHE_OBJECT_EV_CLEARED,	/* T if accessors all gone */
 	FSCACHE_OBJECT_EV_ERROR,	/* T if fatal error occurred during processing */
-	FSCACHE_OBJECT_EV_RELEASE,	/* T if netfs requested object release */
-	FSCACHE_OBJECT_EV_RETIRE,	/* T if netfs requested object retirement */
-	FSCACHE_OBJECT_EV_WITHDRAW,	/* T if cache requested object withdrawal */
+	FSCACHE_OBJECT_EV_KILL,		/* T if netfs relinquished or cache withdrew object */
 	NR_FSCACHE_OBJECT_EVENTS
 };
 
 #define FSCACHE_OBJECT_EVENTS_MASK ((1UL << NR_FSCACHE_OBJECT_EVENTS) - 1)
 
+/*
+ * States for object state machine.
+ */
+struct fscache_transition {
+	unsigned long events;
+	const struct fscache_state *transit_to;
+};
+
+struct fscache_state {
+	char name[24];
+	char short_name[8];
+	const struct fscache_state *(*work)(struct fscache_object *object,
+					    int event);
+	const struct fscache_transition transitions[];
+};
+
 /*
  * on-disk cache file or index handle
  */
 struct fscache_object {
-	enum fscache_object_state {
-		FSCACHE_OBJECT_INIT,		/* object in initial unbound state */
-		FSCACHE_OBJECT_LOOKING_UP,	/* looking up object */
-		FSCACHE_OBJECT_CREATING,	/* creating object */
-
-		/* active states */
-		FSCACHE_OBJECT_AVAILABLE,	/* cleaning up object after creation */
-		FSCACHE_OBJECT_ACTIVE,		/* object is usable */
-		FSCACHE_OBJECT_INVALIDATING,	/* object is invalidating */
-		FSCACHE_OBJECT_UPDATING,	/* object is updating */
-
-		/* terminal states */
-		FSCACHE_OBJECT_DYING,		/* object waiting for accessors to finish */
-		FSCACHE_OBJECT_LC_DYING,	/* object cleaning up after lookup/create */
-		FSCACHE_OBJECT_ABORT_INIT,	/* abort the init state */
-		FSCACHE_OBJECT_RELEASING,	/* releasing object */
-		FSCACHE_OBJECT_RECYCLING,	/* retiring object */
-		FSCACHE_OBJECT_WITHDRAWING,	/* withdrawing object */
-		FSCACHE_OBJECT_DEAD,		/* object is now dead */
-		FSCACHE_OBJECT__NSTATES
-	} state;
-
+	const struct fscache_state *state;	/* Object state machine state */
+	const struct fscache_transition *oob_table; /* OOB state transition table */
 	int			debug_id;	/* debugging ID */
 	int			n_children;	/* number of child objects */
 	int			n_ops;		/* number of extant ops on object */
@@ -390,6 +383,7 @@ struct fscache_object {
 	spinlock_t		lock;		/* state and operations lock */
 
 	unsigned long		lookup_jif;	/* time at which lookup started */
+	unsigned long		oob_event_mask;	/* OOB events this object is interested in */
 	unsigned long		event_mask;	/* events this object is interested in */
 	unsigned long		events;		/* events to be processed by this object
 						 * (order is important - using fls) */
@@ -398,6 +392,10 @@ struct fscache_object {
 #define FSCACHE_OBJECT_LOCK		0	/* T if object is busy being processed */
 #define FSCACHE_OBJECT_PENDING_WRITE	1	/* T if object has pending write */
 #define FSCACHE_OBJECT_WAITING		2	/* T if object is waiting on its parent */
+#define FSCACHE_OBJECT_RETIRE		3	/* T if object should be retired */
+#define FSCACHE_OBJECT_IS_LIVE		4	/* T if object is not withdrawn or relinquished */
+#define FSCACHE_OBJECT_IS_LOOKED_UP	5	/* T if object has been looked up */
+#define FSCACHE_OBJECT_IS_AVAILABLE	6	/* T if object has become active */
 
 	struct list_head	cache_link;	/* link in cache->object_list */
 	struct hlist_node	cookie_link;	/* link in cookie->backing_objects */
@@ -415,8 +413,6 @@ struct fscache_object {
 	loff_t			store_limit_l;	/* current storage limit */
 };
 
-extern const char *fscache_object_states[];
-
 extern void fscache_object_init(struct fscache_object *, struct fscache_cookie *,
 				struct fscache_cache *);
 
@@ -431,7 +427,7 @@ extern void fscache_object_destroy(struct fscache_object *object);
 
 static inline bool fscache_object_is_live(struct fscache_object *object)
 {
-	return object->state < FSCACHE_OBJECT_DYING;
+	return test_bit(FSCACHE_OBJECT_IS_LIVE, &object->flags);
 }
 
 static inline bool fscache_object_is_dying(struct fscache_object *object)
@@ -441,7 +437,7 @@ static inline bool fscache_object_is_dying(struct fscache_object *object)
 
 static inline bool fscache_object_is_available(struct fscache_object *object)
 {
-	return object->state >= FSCACHE_OBJECT_AVAILABLE;
+	return test_bit(FSCACHE_OBJECT_IS_AVAILABLE, &object->flags);
 }
 
 static inline bool fscache_object_is_active(struct fscache_object *object)

commit 493f7bc11457bc1f6fbf25a4b2bdf215ebaf050f
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 10 19:50:26 2013 +0100

    FS-Cache: Wrap checks on object state
    
    Wrap checks on object state (mostly outside of fs/fscache/object.c) with
    inline functions so that the mechanism can be replaced.
    
    Some of the state checks within object.c are left as-is as they will be
    replaced.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 9b9c1de4a460..c5f92347cbf8 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -417,15 +417,6 @@ struct fscache_object {
 
 extern const char *fscache_object_states[];
 
-#define fscache_object_is_active(obj)			      \
-	(!test_bit(FSCACHE_IOERROR, &(obj)->cache->flags) &&  \
-	 (obj)->state >= FSCACHE_OBJECT_AVAILABLE &&	      \
-	 (obj)->state < FSCACHE_OBJECT_DYING)
-
-#define fscache_object_is_dead(obj)				\
-	(test_bit(FSCACHE_IOERROR, &(obj)->cache->flags) &&	\
-	 (obj)->state >= FSCACHE_OBJECT_DYING)
-
 extern void fscache_object_init(struct fscache_object *, struct fscache_cookie *,
 				struct fscache_cache *);
 
@@ -438,6 +429,34 @@ extern void fscache_object_destroy(struct fscache_object *object);
 #define fscache_object_destroy(object) do {} while(0)
 #endif
 
+static inline bool fscache_object_is_live(struct fscache_object *object)
+{
+	return object->state < FSCACHE_OBJECT_DYING;
+}
+
+static inline bool fscache_object_is_dying(struct fscache_object *object)
+{
+	return !fscache_object_is_live(object);
+}
+
+static inline bool fscache_object_is_available(struct fscache_object *object)
+{
+	return object->state >= FSCACHE_OBJECT_AVAILABLE;
+}
+
+static inline bool fscache_object_is_active(struct fscache_object *object)
+{
+	return fscache_object_is_available(object) &&
+		fscache_object_is_live(object) &&
+		!test_bit(FSCACHE_IOERROR, &object->cache->flags);
+}
+
+static inline bool fscache_object_is_dead(struct fscache_object *object)
+{
+	return fscache_object_is_dying(object) &&
+		test_bit(FSCACHE_IOERROR, &object->cache->flags);
+}
+
 /**
  * fscache_object_destroyed - Note destruction of an object in a cache
  * @cache: The cache from which the object came

commit 610be24ee434aa89197f06f30fef02be83c006a5
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 10 19:50:25 2013 +0100

    FS-Cache: Uninline fscache_object_init()
    
    Uninline fscache_object_init() so as not to expose some of the FS-Cache
    internals to the cache backend.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 5dfa0aa216b6..9b9c1de4a460 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -426,42 +426,8 @@ extern const char *fscache_object_states[];
 	(test_bit(FSCACHE_IOERROR, &(obj)->cache->flags) &&	\
 	 (obj)->state >= FSCACHE_OBJECT_DYING)
 
-extern void fscache_object_work_func(struct work_struct *work);
-
-/**
- * fscache_object_init - Initialise a cache object description
- * @object: Object description
- *
- * Initialise a cache object description to its basic values.
- *
- * See Documentation/filesystems/caching/backend-api.txt for a complete
- * description.
- */
-static inline
-void fscache_object_init(struct fscache_object *object,
-			 struct fscache_cookie *cookie,
-			 struct fscache_cache *cache)
-{
-	atomic_inc(&cache->object_count);
-
-	object->state = FSCACHE_OBJECT_INIT;
-	spin_lock_init(&object->lock);
-	INIT_LIST_HEAD(&object->cache_link);
-	INIT_HLIST_NODE(&object->cookie_link);
-	INIT_WORK(&object->work, fscache_object_work_func);
-	INIT_LIST_HEAD(&object->dependents);
-	INIT_LIST_HEAD(&object->dep_link);
-	INIT_LIST_HEAD(&object->pending_ops);
-	object->n_children = 0;
-	object->n_ops = object->n_in_progress = object->n_exclusive = 0;
-	object->events = object->event_mask = 0;
-	object->flags = 0;
-	object->store_limit = 0;
-	object->store_limit_l = 0;
-	object->cache = cache;
-	object->cookie = cookie;
-	object->parent = NULL;
-}
+extern void fscache_object_init(struct fscache_object *, struct fscache_cookie *,
+				struct fscache_cache *);
 
 extern void fscache_object_lookup_negative(struct fscache_object *object);
 extern void fscache_obtained_object(struct fscache_object *object);

commit 1f372dff1da37e2b36ae9085368fa46896398598
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 13 20:03:13 2012 +0000

    FS-Cache: Mark cancellation of in-progress operation
    
    Mark as cancelled an operation that is in progress rather than pending at the
    time it is cancelled, and call fscache_complete_op() to cancel an operation so
    that blocked ops can be started.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 73e68c8d5df4..5dfa0aa216b6 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -116,7 +116,7 @@ extern atomic_t fscache_op_debug_id;
 extern void fscache_op_work_func(struct work_struct *work);
 
 extern void fscache_enqueue_operation(struct fscache_operation *);
-extern void fscache_op_complete(struct fscache_operation *);
+extern void fscache_op_complete(struct fscache_operation *, bool);
 extern void fscache_put_operation(struct fscache_operation *);
 
 /**
@@ -196,7 +196,7 @@ static inline void fscache_retrieval_complete(struct fscache_retrieval *op,
 {
 	op->n_pages -= n_pages;
 	if (op->n_pages <= 0)
-		fscache_op_complete(&op->op);
+		fscache_op_complete(&op->op, true);
 }
 
 /**

commit 36a02de5d7981435931d4608ee3e510b752e072b
Author: David Howells <dhowells@redhat.com>
Date:   Wed Dec 5 13:34:46 2012 +0000

    FS-Cache: Convert the object event ID #defines into an enum
    
    Convert the fscache_object event IDs from #defines into an enum.  Also add an
    extra label to the enum to carry the event count and redefine the event mask
    in terms of that.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 1e454ad7a832..73e68c8d5df4 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -337,6 +337,23 @@ struct fscache_cookie {
 
 extern struct fscache_cookie fscache_fsdef_index;
 
+/*
+ * Event list for fscache_object::{event_mask,events}
+ */
+enum {
+	FSCACHE_OBJECT_EV_REQUEUE,	/* T if object should be requeued */
+	FSCACHE_OBJECT_EV_UPDATE,	/* T if object should be updated */
+	FSCACHE_OBJECT_EV_INVALIDATE,	/* T if cache requested object invalidation */
+	FSCACHE_OBJECT_EV_CLEARED,	/* T if accessors all gone */
+	FSCACHE_OBJECT_EV_ERROR,	/* T if fatal error occurred during processing */
+	FSCACHE_OBJECT_EV_RELEASE,	/* T if netfs requested object release */
+	FSCACHE_OBJECT_EV_RETIRE,	/* T if netfs requested object retirement */
+	FSCACHE_OBJECT_EV_WITHDRAW,	/* T if cache requested object withdrawal */
+	NR_FSCACHE_OBJECT_EVENTS
+};
+
+#define FSCACHE_OBJECT_EVENTS_MASK ((1UL << NR_FSCACHE_OBJECT_EVENTS) - 1)
+
 /*
  * on-disk cache file or index handle
  */
@@ -376,15 +393,6 @@ struct fscache_object {
 	unsigned long		event_mask;	/* events this object is interested in */
 	unsigned long		events;		/* events to be processed by this object
 						 * (order is important - using fls) */
-#define FSCACHE_OBJECT_EV_REQUEUE	0	/* T if object should be requeued */
-#define FSCACHE_OBJECT_EV_UPDATE	1	/* T if object should be updated */
-#define FSCACHE_OBJECT_EV_CLEARED	2	/* T if accessors all gone */
-#define FSCACHE_OBJECT_EV_ERROR		3	/* T if fatal error occurred during processing */
-#define FSCACHE_OBJECT_EV_RELEASE	4	/* T if netfs requested object release */
-#define FSCACHE_OBJECT_EV_RETIRE	5	/* T if netfs requested object retirement */
-#define FSCACHE_OBJECT_EV_WITHDRAW	6	/* T if cache requested object withdrawal */
-#define FSCACHE_OBJECT_EV_INVALIDATE	7	/* T if cache requested object invalidation */
-#define FSCACHE_OBJECT_EVENTS_MASK	0xff	/* mask of all events*/
 
 	unsigned long		flags;
 #define FSCACHE_OBJECT_LOCK		0	/* T if object is busy being processed */

commit ef778e7ae67cd426c30cad43378b908f5eb0bad5
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 20 21:52:36 2012 +0000

    FS-Cache: Provide proper invalidation
    
    Provide a proper invalidation method rather than relying on the netfs retiring
    the cookie it has and getting a new one.  The problem with this is that isn't
    easy for the netfs to make sure that it has completed/cancelled all its
    outstanding storage and retrieval operations on the cookie it is retiring.
    
    Instead, have the cache provide an invalidation method that will cancel or wait
    for all currently outstanding operations before invalidating the cache, and
    will cause new operations to queue up behind that.  Whilst invalidation is in
    progress, some requests will be rejected until the cache can stack a barrier on
    the operation queue to cause new operations to be deferred behind it.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index f5facd1d333f..1e454ad7a832 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -254,6 +254,9 @@ struct fscache_cache_ops {
 	/* store the updated auxiliary data on an object */
 	void (*update_object)(struct fscache_object *object);
 
+	/* Invalidate an object */
+	void (*invalidate_object)(struct fscache_operation *op);
+
 	/* discard the resources pinned by an object and effect retirement if
 	 * necessary */
 	void (*drop_object)(struct fscache_object *object);
@@ -329,6 +332,7 @@ struct fscache_cookie {
 #define FSCACHE_COOKIE_FILLING		4	/* T if filling object incrementally */
 #define FSCACHE_COOKIE_UNAVAILABLE	5	/* T if cookie is unavailable (error, etc) */
 #define FSCACHE_COOKIE_WAITING_ON_READS	6	/* T if cookie is waiting on reads */
+#define FSCACHE_COOKIE_INVALIDATING	7	/* T if cookie is being invalidated */
 };
 
 extern struct fscache_cookie fscache_fsdef_index;
@@ -345,6 +349,7 @@ struct fscache_object {
 		/* active states */
 		FSCACHE_OBJECT_AVAILABLE,	/* cleaning up object after creation */
 		FSCACHE_OBJECT_ACTIVE,		/* object is usable */
+		FSCACHE_OBJECT_INVALIDATING,	/* object is invalidating */
 		FSCACHE_OBJECT_UPDATING,	/* object is updating */
 
 		/* terminal states */
@@ -378,7 +383,8 @@ struct fscache_object {
 #define FSCACHE_OBJECT_EV_RELEASE	4	/* T if netfs requested object release */
 #define FSCACHE_OBJECT_EV_RETIRE	5	/* T if netfs requested object retirement */
 #define FSCACHE_OBJECT_EV_WITHDRAW	6	/* T if cache requested object withdrawal */
-#define FSCACHE_OBJECT_EVENTS_MASK	0x7f	/* mask of all events*/
+#define FSCACHE_OBJECT_EV_INVALIDATE	7	/* T if cache requested object invalidation */
+#define FSCACHE_OBJECT_EVENTS_MASK	0xff	/* mask of all events*/
 
 	unsigned long		flags;
 #define FSCACHE_OBJECT_LOCK		0	/* T if object is busy being processed */

commit 9f10523f891928330b7529da54c1a3cc65180b1a
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 20 21:52:35 2012 +0000

    FS-Cache: Fix operation state management and accounting
    
    Fix the state management of internal fscache operations and the accounting of
    what operations are in what states.
    
    This is done by:
    
     (1) Give struct fscache_operation a enum variable that directly represents the
         state it's currently in, rather than spreading this knowledge over a bunch
         of flags, who's processing the operation at the moment and whether it is
         queued or not.
    
         This makes it easier to write assertions to check the state at various
         points and to prevent invalid state transitions.
    
     (2) Add an 'operation complete' state and supply a function to indicate the
         completion of an operation (fscache_op_complete()) and make things call
         it.  The final call to fscache_put_operation() can then check that an op
         in the appropriate state (complete or cancelled).
    
     (3) Adjust the use of object->n_ops, ->n_in_progress, ->n_exclusive to better
         govern the state of an object:
    
            (a) The ->n_ops is now the number of extant operations on the object
                and is now decremented by fscache_put_operation() only.
    
            (b) The ->n_in_progress is simply the number of objects that have been
                taken off of the object's pending queue for the purposes of being
                run.  This is decremented by fscache_op_complete() only.
    
            (c) The ->n_exclusive is the number of exclusive ops that have been
                submitted and queued or are in progress.  It is decremented by
                fscache_op_complete() and by fscache_cancel_op().
    
         fscache_put_operation() and fscache_operation_gc() now no longer try to
         clean up ->n_exclusive and ->n_in_progress.  That was leading to double
         decrements against fscache_cancel_op().
    
         fscache_cancel_op() now no longer decrements ->n_ops.  That was leading to
         double decrements against fscache_put_operation().
    
         fscache_submit_exclusive_op() now decides whether it has to queue an op
         based on ->n_in_progress being > 0 rather than ->n_ops > 0 as the latter
         will persist in being true even after all preceding operations have been
         cancelled or completed.  Furthermore, if an object is active and there are
         runnable ops against it, there must be at least one op running.
    
     (4) Add a remaining-pages counter (n_pages) to struct fscache_retrieval and
         provide a function to record completion of the pages as they complete.
    
         When n_pages reaches 0, the operation is deemed to be complete and
         fscache_op_complete() is called.
    
         Add calls to fscache_retrieval_complete() anywhere we've finished with a
         page we've been given to read or allocate for.  This includes places where
         we just return pages to the netfs for reading from the server and where
         accessing the cache fails and we discard the proposed netfs page.
    
    The bugs in the unfixed state management manifest themselves as oopses like the
    following where the operation completion gets out of sync with return of the
    cookie by the netfs.  This is possible because the cache unlocks and returns
    all the netfs pages before recording its completion - which means that there's
    nothing to stop the netfs discarding them and returning the cookie.
    
    
    FS-Cache: Cookie 'NFS.fh' still has outstanding reads
    ------------[ cut here ]------------
    kernel BUG at fs/fscache/cookie.c:519!
    invalid opcode: 0000 [#1] SMP
    CPU 1
    Modules linked in: cachefiles nfs fscache auth_rpcgss nfs_acl lockd sunrpc
    
    Pid: 400, comm: kswapd0 Not tainted 3.1.0-rc7-fsdevel+ #1090                  /DG965RY
    RIP: 0010:[<ffffffffa007050a>]  [<ffffffffa007050a>] __fscache_relinquish_cookie+0x170/0x343 [fscache]
    RSP: 0018:ffff8800368cfb00  EFLAGS: 00010282
    RAX: 000000000000003c RBX: ffff880023cc8790 RCX: 0000000000000000
    RDX: 0000000000002f2e RSI: 0000000000000001 RDI: ffffffff813ab86c
    RBP: ffff8800368cfb50 R08: 0000000000000002 R09: 0000000000000000
    R10: ffff88003a1b7890 R11: ffff88001df6e488 R12: ffff880023d8ed98
    R13: ffff880023cc8798 R14: 0000000000000004 R15: ffff88003b8bf370
    FS:  0000000000000000(0000) GS:ffff88003bd00000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    CR2: 00000000008ba008 CR3: 0000000023d93000 CR4: 00000000000006e0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Process kswapd0 (pid: 400, threadinfo ffff8800368ce000, task ffff88003b8bf040)
    Stack:
     ffff88003b8bf040 ffff88001df6e528 ffff88001df6e528 ffffffffa00b46b0
     ffff88003b8bf040 ffff88001df6e488 ffff88001df6e620 ffffffffa00b46b0
     ffff88001ebd04c8 0000000000000004 ffff8800368cfb70 ffffffffa00b2c91
    Call Trace:
     [<ffffffffa00b2c91>] nfs_fscache_release_inode_cookie+0x3b/0x47 [nfs]
     [<ffffffffa008f25f>] nfs_clear_inode+0x3c/0x41 [nfs]
     [<ffffffffa0090df1>] nfs4_evict_inode+0x2f/0x33 [nfs]
     [<ffffffff810d8d47>] evict+0xa1/0x15c
     [<ffffffff810d8e2e>] dispose_list+0x2c/0x38
     [<ffffffff810d9ebd>] prune_icache_sb+0x28c/0x29b
     [<ffffffff810c56b7>] prune_super+0xd5/0x140
     [<ffffffff8109b615>] shrink_slab+0x102/0x1ab
     [<ffffffff8109d690>] balance_pgdat+0x2f2/0x595
     [<ffffffff8103e009>] ? process_timeout+0xb/0xb
     [<ffffffff8109dba3>] kswapd+0x270/0x289
     [<ffffffff8104c5ea>] ? __init_waitqueue_head+0x46/0x46
     [<ffffffff8109d933>] ? balance_pgdat+0x595/0x595
     [<ffffffff8104bf7a>] kthread+0x7f/0x87
     [<ffffffff813ad6b4>] kernel_thread_helper+0x4/0x10
     [<ffffffff81026b98>] ? finish_task_switch+0x45/0xc0
     [<ffffffff813abcdd>] ? retint_restore_args+0xe/0xe
     [<ffffffff8104befb>] ? __init_kthread_worker+0x53/0x53
     [<ffffffff813ad6b0>] ? gs_change+0xb/0xb
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index e3d6d939d959..f5facd1d333f 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -75,6 +75,16 @@ extern wait_queue_head_t fscache_cache_cleared_wq;
 typedef void (*fscache_operation_release_t)(struct fscache_operation *op);
 typedef void (*fscache_operation_processor_t)(struct fscache_operation *op);
 
+enum fscache_operation_state {
+	FSCACHE_OP_ST_BLANK,		/* Op is not yet submitted */
+	FSCACHE_OP_ST_INITIALISED,	/* Op is initialised */
+	FSCACHE_OP_ST_PENDING,		/* Op is blocked from running */
+	FSCACHE_OP_ST_IN_PROGRESS,	/* Op is in progress */
+	FSCACHE_OP_ST_COMPLETE,		/* Op is complete */
+	FSCACHE_OP_ST_CANCELLED,	/* Op has been cancelled */
+	FSCACHE_OP_ST_DEAD		/* Op is now dead */
+};
+
 struct fscache_operation {
 	struct work_struct	work;		/* record for async ops */
 	struct list_head	pend_link;	/* link in object->pending_ops */
@@ -86,10 +96,10 @@ struct fscache_operation {
 #define FSCACHE_OP_MYTHREAD	0x0002	/* - processing is done be issuing thread, not pool */
 #define FSCACHE_OP_WAITING	4	/* cleared when op is woken */
 #define FSCACHE_OP_EXCLUSIVE	5	/* exclusive op, other ops must wait */
-#define FSCACHE_OP_DEAD		6	/* op is now dead */
-#define FSCACHE_OP_DEC_READ_CNT	7	/* decrement object->n_reads on destruction */
-#define FSCACHE_OP_KEEP_FLAGS	0xc0	/* flags to keep when repurposing an op */
+#define FSCACHE_OP_DEC_READ_CNT	6	/* decrement object->n_reads on destruction */
+#define FSCACHE_OP_KEEP_FLAGS	0x0070	/* flags to keep when repurposing an op */
 
+	enum fscache_operation_state state;
 	atomic_t		usage;
 	unsigned		debug_id;	/* debugging ID */
 
@@ -106,6 +116,7 @@ extern atomic_t fscache_op_debug_id;
 extern void fscache_op_work_func(struct work_struct *work);
 
 extern void fscache_enqueue_operation(struct fscache_operation *);
+extern void fscache_op_complete(struct fscache_operation *);
 extern void fscache_put_operation(struct fscache_operation *);
 
 /**
@@ -122,6 +133,7 @@ static inline void fscache_operation_init(struct fscache_operation *op,
 {
 	INIT_WORK(&op->work, fscache_op_work_func);
 	atomic_set(&op->usage, 1);
+	op->state = FSCACHE_OP_ST_INITIALISED;
 	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
 	op->processor = processor;
 	op->release = release;
@@ -138,6 +150,7 @@ struct fscache_retrieval {
 	void			*context;	/* netfs read context (pinned) */
 	struct list_head	to_do;		/* list of things to be done by the backend */
 	unsigned long		start_time;	/* time at which retrieval started */
+	unsigned		n_pages;	/* number of pages to be retrieved */
 };
 
 typedef int (*fscache_page_retrieval_func_t)(struct fscache_retrieval *op,
@@ -173,9 +186,23 @@ static inline void fscache_enqueue_retrieval(struct fscache_retrieval *op)
 	fscache_enqueue_operation(&op->op);
 }
 
+/**
+ * fscache_retrieval_complete - Record (partial) completion of a retrieval
+ * @op: The retrieval operation affected
+ * @n_pages: The number of pages to account for
+ */
+static inline void fscache_retrieval_complete(struct fscache_retrieval *op,
+					      int n_pages)
+{
+	op->n_pages -= n_pages;
+	if (op->n_pages <= 0)
+		fscache_op_complete(&op->op);
+}
+
 /**
  * fscache_put_retrieval - Drop a reference to a retrieval operation
  * @op: The retrieval operation affected
+ * @n_pages: The number of pages to account for
  *
  * Drop a reference to a retrieval operation.
  */
@@ -333,10 +360,10 @@ struct fscache_object {
 
 	int			debug_id;	/* debugging ID */
 	int			n_children;	/* number of child objects */
-	int			n_ops;		/* number of ops outstanding on object */
+	int			n_ops;		/* number of extant ops on object */
 	int			n_obj_ops;	/* number of object ops outstanding on object */
 	int			n_in_progress;	/* number of ops in progress */
-	int			n_exclusive;	/* number of exclusive ops queued */
+	int			n_exclusive;	/* number of exclusive ops queued or in progress */
 	atomic_t		n_reads;	/* number of read ops in progress */
 	spinlock_t		lock;		/* state and operations lock */
 

commit ef46ed888efb1e8da33be5d33c9b54476289a43b
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 20 21:52:35 2012 +0000

    FS-Cache: Make cookie relinquishment wait for outstanding reads
    
    Make fscache_relinquish_cookie() log a warning and wait if there are any
    outstanding reads left on the cookie it was given.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 9879183b55d8..e3d6d939d959 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -301,6 +301,7 @@ struct fscache_cookie {
 #define FSCACHE_COOKIE_PENDING_FILL	3	/* T if pending initial fill on object */
 #define FSCACHE_COOKIE_FILLING		4	/* T if filling object incrementally */
 #define FSCACHE_COOKIE_UNAVAILABLE	5	/* T if cookie is unavailable (error, etc) */
+#define FSCACHE_COOKIE_WAITING_ON_READS	6	/* T if cookie is waiting on reads */
 };
 
 extern struct fscache_cookie fscache_fsdef_index;

commit c4d6d8dbf335c7fa47341654a37c53a512b519bb
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 20 21:52:32 2012 +0000

    CacheFiles: Fix the marking of cached pages
    
    Under some circumstances CacheFiles defers the marking of pages with PG_fscache
    so that it can take advantage of pagevecs to reduce the number of calls to
    fscache_mark_pages_cached() and the netfs's hook to keep track of this.
    
    There are, however, two problems with this:
    
     (1) It can lead to the PG_fscache mark being applied _after_ the page is set
         PG_uptodate and unlocked (by the call to fscache_end_io()).
    
     (2) CacheFiles's ref on the page is dropped immediately following
         fscache_end_io() - and so may not still be held when the mark is applied.
         This can lead to the page being passed back to the allocator before the
         mark is applied.
    
    Fix this by, where appropriate, marking the page before calling
    fscache_end_io() and releasing the page.  This means that we can't take
    advantage of pagevecs and have to make a separate call for each page to the
    marking routines.
    
    The symptoms of this are Bad Page state errors cropping up under memory
    pressure, for example:
    
    BUG: Bad page state in process tar  pfn:002da
    page:ffffea0000009fb0 count:0 mapcount:0 mapping:          (null) index:0x1447
    page flags: 0x1000(private_2)
    Pid: 4574, comm: tar Tainted: G        W   3.1.0-rc4-fsdevel+ #1064
    Call Trace:
     [<ffffffff8109583c>] ? dump_page+0xb9/0xbe
     [<ffffffff81095916>] bad_page+0xd5/0xea
     [<ffffffff81095d82>] get_page_from_freelist+0x35b/0x46a
     [<ffffffff810961f3>] __alloc_pages_nodemask+0x362/0x662
     [<ffffffff810989da>] __do_page_cache_readahead+0x13a/0x267
     [<ffffffff81098942>] ? __do_page_cache_readahead+0xa2/0x267
     [<ffffffff81098d7b>] ra_submit+0x1c/0x20
     [<ffffffff8109900a>] ondemand_readahead+0x28b/0x29a
     [<ffffffff81098ee2>] ? ondemand_readahead+0x163/0x29a
     [<ffffffff810990ce>] page_cache_sync_readahead+0x38/0x3a
     [<ffffffff81091d8a>] generic_file_aio_read+0x2ab/0x67e
     [<ffffffffa008cfbe>] nfs_file_read+0xa4/0xc9 [nfs]
     [<ffffffff810c22c4>] do_sync_read+0xba/0xfa
     [<ffffffff81177a47>] ? security_file_permission+0x7b/0x84
     [<ffffffff810c25dd>] ? rw_verify_area+0xab/0xc8
     [<ffffffff810c29a4>] vfs_read+0xaa/0x13a
     [<ffffffff810c2a79>] sys_read+0x45/0x6c
     [<ffffffff813ac37b>] system_call_fastpath+0x16/0x1b
    
    As can be seen, PG_private_2 (== PG_fscache) is set in the page flags.
    
    Instrumenting fscache_mark_pages_cached() to verify whether page->mapping was
    set appropriately showed that sometimes it wasn't.  This led to the discovery
    that sometimes the page has apparently been reclaimed by the time the marker
    got to see it.
    
    Reported-by: M. Stevens <m@tippett.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Jeff Layton <jlayton@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index ce31408b1e47..9879183b55d8 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -504,6 +504,9 @@ extern void fscache_withdraw_cache(struct fscache_cache *cache);
 
 extern void fscache_io_error(struct fscache_cache *cache);
 
+extern void fscache_mark_page_cached(struct fscache_retrieval *op,
+				     struct page *page);
+
 extern void fscache_mark_pages_cached(struct fscache_retrieval *op,
 				      struct pagevec *pagevec);
 

commit b9075fa968a0a4347aef35e235e2995c0e57dddd
Author: Joe Perches <joe@perches.com>
Date:   Mon Oct 31 17:11:33 2011 -0700

    treewide: use __printf not __attribute__((format(printf,...)))
    
    Standardize the style for compiler based printf format verification.
    Standardized the location of __printf too.
    
    Done via script and a little typing.
    
    $ grep -rPl --include=*.[ch] -w "__attribute__" * | \
      grep -vP "^(tools|scripts|include/linux/compiler-gcc.h)" | \
      xargs perl -n -i -e 'local $/; while (<>) { s/\b__attribute__\s*\(\s*\(\s*format\s*\(\s*printf\s*,\s*(.+)\s*,\s*(.+)\s*\)\s*\)\s*\)/__printf($1, $2)/g ; print; }'
    
    [akpm@linux-foundation.org: revert arch bits]
    Signed-off-by: Joe Perches <joe@perches.com>
    Cc: "Kirill A. Shutemov" <kirill@shutemov.name>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index af095b54502e..ce31408b1e47 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -492,10 +492,10 @@ static inline void fscache_end_io(struct fscache_retrieval *op,
 /*
  * out-of-line cache backend functions
  */
-extern void fscache_init_cache(struct fscache_cache *cache,
-			       const struct fscache_cache_ops *ops,
-			       const char *idfmt,
-			       ...) __attribute__ ((format (printf, 3, 4)));
+extern __printf(3, 4)
+void fscache_init_cache(struct fscache_cache *cache,
+			const struct fscache_cache_ops *ops,
+			const char *idfmt, ...);
 
 extern int fscache_add_cache(struct fscache_cache *cache,
 			     struct fscache_object *fsdef,

commit e50c1f609c63223adaa38f5a79b18759a00adf72
Author: Amerigo Wang <amwang@redhat.com>
Date:   Tue May 24 17:13:11 2011 -0700

    fscache: remove dead code under CONFIG_WORKQUEUE_DEBUGFS
    
    There is no CONFIG_WORKQUEUE_DEBUGFS any more, so this code is dead.
    
    Signed-off-by: WANG Cong <amwang@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 76427e688d15..af095b54502e 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -100,17 +100,6 @@ struct fscache_operation {
 
 	/* operation releaser */
 	fscache_operation_release_t release;
-
-#ifdef CONFIG_WORKQUEUE_DEBUGFS
-	struct work_struct put_work;	/* work to delay operation put */
-	const char *name;		/* operation name */
-	const char *state;		/* operation state */
-#define fscache_set_op_name(OP, N)	do { (OP)->name  = (N); } while(0)
-#define fscache_set_op_state(OP, S)	do { (OP)->state = (S); } while(0)
-#else
-#define fscache_set_op_name(OP, N)	do { } while(0)
-#define fscache_set_op_state(OP, S)	do { } while(0)
-#endif
 };
 
 extern atomic_t fscache_op_debug_id;
@@ -137,7 +126,6 @@ static inline void fscache_operation_init(struct fscache_operation *op,
 	op->processor = processor;
 	op->release = release;
 	INIT_LIST_HEAD(&op->pend_link);
-	fscache_set_op_state(op, "Init");
 }
 
 /*

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index b8581c09d19f..76427e688d15 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -236,7 +236,7 @@ struct fscache_cache_ops {
 	/* unpin an object in the cache */
 	void (*unpin_object)(struct fscache_object *object);
 
-	/* store the updated auxilliary data on an object */
+	/* store the updated auxiliary data on an object */
 	void (*update_object)(struct fscache_object *object);
 
 	/* discard the resources pinned by an object and effect retirement if

commit d098adfb7d281258173a43151483e52e21761021
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 20 22:09:01 2010 +0200

    fscache: drop references to slow-work
    
    fscache no longer uses slow-work.  Drop references to it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 17ed9c1dbfbe..b8581c09d19f 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -20,7 +20,6 @@
 
 #include <linux/fscache.h>
 #include <linux/sched.h>
-#include <linux/slow-work.h>
 #include <linux/workqueue.h>
 
 #define NR_MAXCACHES BITS_PER_LONG

commit 8af7c12436803291c90295259db23d371a7ad9cc
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 20 22:09:01 2010 +0200

    fscache: convert operation to use workqueue instead of slow-work
    
    Make fscache operation to use only workqueue instead of combination of
    workqueue and slow-work.  FSCACHE_OP_SLOW is dropped and
    FSCACHE_OP_FAST is renamed to FSCACHE_OP_ASYNC and uses newly added
    fscache_op_wq workqueue to execute op->processor().
    fscache_operation_init_slow() is dropped and fscache_operation_init()
    now takes @processor argument directly.
    
    * Unbound workqueue is used.
    
    * fscache_retrieval_work() is no longer necessary as OP_ASYNC now does
      the equivalent thing.
    
    * sysctl fscache.operation_max_active added to control concurrency.
      The default value is nr_cpus clamped between 2 and
      WQ_UNBOUND_MAX_ACTIVE.
    
    * debugfs support is dropped for now.  Tracing API based debug
      facility is planned to be added.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 27c8df503152..17ed9c1dbfbe 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -77,18 +77,14 @@ typedef void (*fscache_operation_release_t)(struct fscache_operation *op);
 typedef void (*fscache_operation_processor_t)(struct fscache_operation *op);
 
 struct fscache_operation {
-	union {
-		struct work_struct fast_work;	/* record for fast ops */
-		struct slow_work slow_work;	/* record for (very) slow ops */
-	};
+	struct work_struct	work;		/* record for async ops */
 	struct list_head	pend_link;	/* link in object->pending_ops */
 	struct fscache_object	*object;	/* object to be operated upon */
 
 	unsigned long		flags;
 #define FSCACHE_OP_TYPE		0x000f	/* operation type */
-#define FSCACHE_OP_FAST		0x0001	/* - fast op, processor may not sleep for disk */
-#define FSCACHE_OP_SLOW		0x0002	/* - (very) slow op, processor may sleep for disk */
-#define FSCACHE_OP_MYTHREAD	0x0003	/* - processing is done be issuing thread, not pool */
+#define FSCACHE_OP_ASYNC	0x0001	/* - async op, processor may sleep for disk */
+#define FSCACHE_OP_MYTHREAD	0x0002	/* - processing is done be issuing thread, not pool */
 #define FSCACHE_OP_WAITING	4	/* cleared when op is woken */
 #define FSCACHE_OP_EXCLUSIVE	5	/* exclusive op, other ops must wait */
 #define FSCACHE_OP_DEAD		6	/* op is now dead */
@@ -106,7 +102,8 @@ struct fscache_operation {
 	/* operation releaser */
 	fscache_operation_release_t release;
 
-#ifdef CONFIG_SLOW_WORK_DEBUG
+#ifdef CONFIG_WORKQUEUE_DEBUGFS
+	struct work_struct put_work;	/* work to delay operation put */
 	const char *name;		/* operation name */
 	const char *state;		/* operation state */
 #define fscache_set_op_name(OP, N)	do { (OP)->name  = (N); } while(0)
@@ -118,7 +115,7 @@ struct fscache_operation {
 };
 
 extern atomic_t fscache_op_debug_id;
-extern const struct slow_work_ops fscache_op_slow_work_ops;
+extern void fscache_op_work_func(struct work_struct *work);
 
 extern void fscache_enqueue_operation(struct fscache_operation *);
 extern void fscache_put_operation(struct fscache_operation *);
@@ -129,33 +126,21 @@ extern void fscache_put_operation(struct fscache_operation *);
  * @release: The release function to assign
  *
  * Do basic initialisation of an operation.  The caller must still set flags,
- * object, either fast_work or slow_work if necessary, and processor if needed.
+ * object and processor if needed.
  */
 static inline void fscache_operation_init(struct fscache_operation *op,
-					  fscache_operation_release_t release)
+					fscache_operation_processor_t processor,
+					fscache_operation_release_t release)
 {
+	INIT_WORK(&op->work, fscache_op_work_func);
 	atomic_set(&op->usage, 1);
 	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
+	op->processor = processor;
 	op->release = release;
 	INIT_LIST_HEAD(&op->pend_link);
 	fscache_set_op_state(op, "Init");
 }
 
-/**
- * fscache_operation_init_slow - Do additional initialisation of a slow op
- * @op: The operation to initialise
- * @processor: The processor function to assign
- *
- * Do additional initialisation of an operation as required for slow work.
- */
-static inline
-void fscache_operation_init_slow(struct fscache_operation *op,
-				 fscache_operation_processor_t processor)
-{
-	op->processor = processor;
-	slow_work_init(&op->slow_work, &fscache_op_slow_work_ops);
-}
-
 /*
  * data read operation
  */

commit 8b8edefa2fffbff97f9eec8b70e78ae23abad1a0
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 20 22:09:01 2010 +0200

    fscache: convert object to use workqueue instead of slow-work
    
    Make fscache object state transition callbacks use workqueue instead
    of slow-work.  New dedicated unbound CPU workqueue fscache_object_wq
    is created.  get/put callbacks are renamed and modified to take
    @object and called directly from the enqueue wrapper and the work
    function.  While at it, make all open coded instances of get/put to
    use fscache_get/put_object().
    
    * Unbound workqueue is used.
    
    * work_busy() output is printed instead of slow-work flags in object
      debugging outputs.  They mean basically the same thing bit-for-bit.
    
    * sysctl fscache.object_max_active added to control concurrency.  The
      default value is nr_cpus clamped between 4 and
      WQ_UNBOUND_MAX_ACTIVE.
    
    * slow_work_sleep_till_thread_needed() is replaced with fscache
      private implementation fscache_object_sleep_till_congested() which
      waits on fscache_object_wq congestion.
    
    * debugfs support is dropped for now.  Tracing API based debug
      facility is planned to be added.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index c57db27ac861..27c8df503152 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -21,6 +21,7 @@
 #include <linux/fscache.h>
 #include <linux/sched.h>
 #include <linux/slow-work.h>
+#include <linux/workqueue.h>
 
 #define NR_MAXCACHES BITS_PER_LONG
 
@@ -389,7 +390,7 @@ struct fscache_object {
 	struct fscache_cache	*cache;		/* cache that supplied this object */
 	struct fscache_cookie	*cookie;	/* netfs's file/index object */
 	struct fscache_object	*parent;	/* parent object */
-	struct slow_work	work;		/* attention scheduling record */
+	struct work_struct	work;		/* attention scheduling record */
 	struct list_head	dependents;	/* FIFO of dependent objects */
 	struct list_head	dep_link;	/* link in parent's dependents list */
 	struct list_head	pending_ops;	/* unstarted operations on this object */
@@ -411,7 +412,7 @@ extern const char *fscache_object_states[];
 	(test_bit(FSCACHE_IOERROR, &(obj)->cache->flags) &&	\
 	 (obj)->state >= FSCACHE_OBJECT_DYING)
 
-extern const struct slow_work_ops fscache_object_slow_work_ops;
+extern void fscache_object_work_func(struct work_struct *work);
 
 /**
  * fscache_object_init - Initialise a cache object description
@@ -433,7 +434,7 @@ void fscache_object_init(struct fscache_object *object,
 	spin_lock_init(&object->lock);
 	INIT_LIST_HEAD(&object->cache_link);
 	INIT_HLIST_NODE(&object->cookie_link);
-	vslow_work_init(&object->work, &fscache_object_slow_work_ops);
+	INIT_WORK(&object->work, fscache_object_work_func);
 	INIT_LIST_HEAD(&object->dependents);
 	INIT_LIST_HEAD(&object->dep_link);
 	INIT_LIST_HEAD(&object->pending_ops);
@@ -534,6 +535,8 @@ extern void fscache_io_error(struct fscache_cache *cache);
 extern void fscache_mark_pages_cached(struct fscache_retrieval *op,
 				      struct pagevec *pagevec);
 
+extern bool fscache_object_sleep_till_congested(signed long *timeoutp);
+
 extern enum fscache_checkaux fscache_check_aux(struct fscache_object *object,
 					       const void *data,
 					       uint16_t datalen);

commit a53f4f9efaeb1d87cfae066346979d4d70e1abe9
Author: David Howells <dhowells@redhat.com>
Date:   Mon Mar 29 13:08:52 2010 +0100

    SLOW_WORK: CONFIG_SLOW_WORK_PROC should be CONFIG_SLOW_WORK_DEBUG
    
    CONFIG_SLOW_WORK_PROC was changed to CONFIG_SLOW_WORK_DEBUG, but not in all
    instances.  Change the remaining instances.  This makes the debugfs file
    display the time mark and the owner's description again.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 7be0c6fbe880..c57db27ac861 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -105,7 +105,7 @@ struct fscache_operation {
 	/* operation releaser */
 	fscache_operation_release_t release;
 
-#ifdef CONFIG_SLOW_WORK_PROC
+#ifdef CONFIG_SLOW_WORK_DEBUG
 	const char *name;		/* operation name */
 	const char *state;		/* operation state */
 #define fscache_set_op_name(OP, N)	do { (OP)->name  = (N); } while(0)

commit fee096deb4f33897937b974cb2c5168bab7935be
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:12:05 2009 +0000

    CacheFiles: Catch an overly long wait for an old active object
    
    Catch an overly long wait for an old, dying active object when we want to
    replace it with a new one.  The probability is that all the slow-work threads
    are hogged, and the delete can't get a look in.
    
    What we do instead is:
    
     (1) if there's nothing in the slow work queue, we sleep until either the dying
         object has finished dying or there is something in the slow work queue
         behind which we can queue our object.
    
     (2) if there is something in the slow work queue, we return ETIMEDOUT to
         fscache_lookup_object(), which then puts us back on the slow work queue,
         presumably behind the deletion that we're blocked by.  We are then
         deferred for a while until we work our way back through the queue -
         without blocking a slow-work thread unnecessarily.
    
    A backtrace similar to the following may appear in the log without this patch:
    
            INFO: task kslowd004:5711 blocked for more than 120 seconds.
            "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
            kslowd004     D 0000000000000000     0  5711      2 0x00000080
             ffff88000340bb80 0000000000000046 ffff88002550d000 0000000000000000
             ffff88002550d000 0000000000000007 ffff88000340bfd8 ffff88002550d2a8
             000000000000ddf0 00000000000118c0 00000000000118c0 ffff88002550d2a8
            Call Trace:
             [<ffffffff81058e21>] ? trace_hardirqs_on+0xd/0xf
             [<ffffffffa011c4d8>] ? cachefiles_wait_bit+0x0/0xd [cachefiles]
             [<ffffffffa011c4e1>] cachefiles_wait_bit+0x9/0xd [cachefiles]
             [<ffffffff81353153>] __wait_on_bit+0x43/0x76
             [<ffffffff8111ae39>] ? ext3_xattr_get+0x1ec/0x270
             [<ffffffff813531ef>] out_of_line_wait_on_bit+0x69/0x74
             [<ffffffffa011c4d8>] ? cachefiles_wait_bit+0x0/0xd [cachefiles]
             [<ffffffff8104c125>] ? wake_bit_function+0x0/0x2e
             [<ffffffffa011bc79>] cachefiles_mark_object_active+0x203/0x23b [cachefiles]
             [<ffffffffa011c209>] cachefiles_walk_to_object+0x558/0x827 [cachefiles]
             [<ffffffffa011a429>] cachefiles_lookup_object+0xac/0x12a [cachefiles]
             [<ffffffffa00aa1e9>] fscache_lookup_object+0x1c7/0x214 [fscache]
             [<ffffffffa00aafc5>] fscache_object_state_machine+0xa5/0x52d [fscache]
             [<ffffffffa00ab4ac>] fscache_object_slow_work_execute+0x5f/0xa0 [fscache]
             [<ffffffff81082093>] slow_work_execute+0x18f/0x2d1
             [<ffffffff8108239a>] slow_work_thread+0x1c5/0x308
             [<ffffffff8104c0f1>] ? autoremove_wake_function+0x0/0x34
             [<ffffffff810821d5>] ? slow_work_thread+0x0/0x308
             [<ffffffff8104be91>] kthread+0x7a/0x82
             [<ffffffff8100beda>] child_rip+0xa/0x20
             [<ffffffff8100b87c>] ? restore_args+0x0/0x30
             [<ffffffff8104be17>] ? kthread+0x0/0x82
             [<ffffffff8100bed0>] ? child_rip+0x0/0x20
            1 lock held by kslowd004/5711:
             #0:  (&sb->s_type->i_mutex_key#7/1){+.+.+.}, at: [<ffffffffa011be64>] cachefiles_walk_to_object+0x1b3/0x827 [cachefiles]
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 5db50002f3b5..7be0c6fbe880 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -234,8 +234,10 @@ struct fscache_cache_ops {
 	struct fscache_object *(*alloc_object)(struct fscache_cache *cache,
 					       struct fscache_cookie *cookie);
 
-	/* look up the object for a cookie */
-	void (*lookup_object)(struct fscache_object *object);
+	/* look up the object for a cookie
+	 * - return -ETIMEDOUT to be requeued
+	 */
+	int (*lookup_object)(struct fscache_object *object);
 
 	/* finished looking up */
 	void (*lookup_complete)(struct fscache_object *object);

commit a17754fb8c28af19cd70dcbec6d5b0773b94e0c1
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:52 2009 +0000

    CacheFiles: Don't write a full page if there's only a partial page to cache
    
    cachefiles_write_page() writes a full page to the backing file for the last
    page of the netfs file, even if the netfs file's last page is only a partial
    page.
    
    This causes the EOF on the backing file to be extended beyond the EOF of the
    netfs, and thus the backing file will be truncated by cachefiles_attr_changed()
    called from cachefiles_lookup_object().
    
    So we need to limit the write we make to the backing file on that last page
    such that it doesn't push the EOF too far.
    
    Also, if a backing file that has a partial page at the end is expanded, we
    discard the partial page and refetch it on the basis that we then have a hole
    in the file with invalid data, and should the power go out...  A better way to
    deal with this could be to record a note that the partial page contains invalid
    data until the correct data is written into it.
    
    This isn't a problem for netfs's that discard the whole backing file if the
    file size changes (such as NFS).
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 907bb56c5888..5db50002f3b5 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -395,6 +395,7 @@ struct fscache_object {
 	struct rb_node		objlist_link;	/* link in global object list */
 #endif
 	pgoff_t			store_limit;	/* current storage limit */
+	loff_t			store_limit_l;	/* current storage limit */
 };
 
 extern const char *fscache_object_states[];
@@ -439,6 +440,7 @@ void fscache_object_init(struct fscache_object *object,
 	object->events = object->event_mask = 0;
 	object->flags = 0;
 	object->store_limit = 0;
+	object->store_limit_l = 0;
 	object->cache = cache;
 	object->cookie = cookie;
 	object->parent = NULL;
@@ -491,6 +493,7 @@ static inline void fscache_object_lookup_error(struct fscache_object *object)
 static inline
 void fscache_set_store_limit(struct fscache_object *object, loff_t i_size)
 {
+	object->store_limit_l = i_size;
 	object->store_limit = i_size >> PAGE_SHIFT;
 	if (i_size & ~PAGE_MASK)
 		object->store_limit++;

commit 60d543ca724be155c2b6166e36a00c80b21bd810
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:45 2009 +0000

    FS-Cache: Start processing an object's operations on that object's death
    
    Start processing an object's operations when that object moves into the DYING
    state as the object cannot be destroyed until all its outstanding operations
    have completed.
    
    Furthermore, make sure that read and allocation operations handle being woken
    up on a dead object.  Such events are recorded in the Allocs.abt and
    Retrvls.abt statistics as viewable through /proc/fs/fscache/stats.
    
    The code for waiting for object activation for the read and allocation
    operations is also extracted into its own function as it is much the same in
    all cases, differing only in the stats incremented.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 4750d5fb419f..907bb56c5888 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -404,6 +404,10 @@ extern const char *fscache_object_states[];
 	 (obj)->state >= FSCACHE_OBJECT_AVAILABLE &&	      \
 	 (obj)->state < FSCACHE_OBJECT_DYING)
 
+#define fscache_object_is_dead(obj)				\
+	(test_bit(FSCACHE_IOERROR, &(obj)->cache->flags) &&	\
+	 (obj)->state >= FSCACHE_OBJECT_DYING)
+
 extern const struct slow_work_ops fscache_object_slow_work_ops;
 
 /**

commit 201a15428bd54f83eccec8b7c64a04b8f9431204
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:35 2009 +0000

    FS-Cache: Handle pages pending storage that get evicted under OOM conditions
    
    Handle netfs pages that the vmscan algorithm wants to evict from the pagecache
    under OOM conditions, but that are waiting for write to the cache.  Under these
    conditions, vmscan calls the releasepage() function of the netfs, asking if a
    page can be discarded.
    
    The problem is typified by the following trace of a stuck process:
    
            kslowd005     D 0000000000000000     0  4253      2 0x00000080
             ffff88001b14f370 0000000000000046 ffff880020d0d000 0000000000000007
             0000000000000006 0000000000000001 ffff88001b14ffd8 ffff880020d0d2a8
             000000000000ddf0 00000000000118c0 00000000000118c0 ffff880020d0d2a8
            Call Trace:
             [<ffffffffa00782d8>] __fscache_wait_on_page_write+0x8b/0xa7 [fscache]
             [<ffffffff8104c0f1>] ? autoremove_wake_function+0x0/0x34
             [<ffffffffa0078240>] ? __fscache_check_page_write+0x63/0x70 [fscache]
             [<ffffffffa00b671d>] nfs_fscache_release_page+0x4e/0xc4 [nfs]
             [<ffffffffa00927f0>] nfs_release_page+0x3c/0x41 [nfs]
             [<ffffffff810885d3>] try_to_release_page+0x32/0x3b
             [<ffffffff81093203>] shrink_page_list+0x316/0x4ac
             [<ffffffff8109372b>] shrink_inactive_list+0x392/0x67c
             [<ffffffff813532fa>] ? __mutex_unlock_slowpath+0x100/0x10b
             [<ffffffff81058df0>] ? trace_hardirqs_on_caller+0x10c/0x130
             [<ffffffff8135330e>] ? mutex_unlock+0x9/0xb
             [<ffffffff81093aa2>] shrink_list+0x8d/0x8f
             [<ffffffff81093d1c>] shrink_zone+0x278/0x33c
             [<ffffffff81052d6c>] ? ktime_get_ts+0xad/0xba
             [<ffffffff81094b13>] try_to_free_pages+0x22e/0x392
             [<ffffffff81091e24>] ? isolate_pages_global+0x0/0x212
             [<ffffffff8108e743>] __alloc_pages_nodemask+0x3dc/0x5cf
             [<ffffffff81089529>] grab_cache_page_write_begin+0x65/0xaa
             [<ffffffff8110f8c0>] ext3_write_begin+0x78/0x1eb
             [<ffffffff81089ec5>] generic_file_buffered_write+0x109/0x28c
             [<ffffffff8103cb69>] ? current_fs_time+0x22/0x29
             [<ffffffff8108a509>] __generic_file_aio_write+0x350/0x385
             [<ffffffff8108a588>] ? generic_file_aio_write+0x4a/0xae
             [<ffffffff8108a59e>] generic_file_aio_write+0x60/0xae
             [<ffffffff810b2e82>] do_sync_write+0xe3/0x120
             [<ffffffff8104c0f1>] ? autoremove_wake_function+0x0/0x34
             [<ffffffff810b18e1>] ? __dentry_open+0x1a5/0x2b8
             [<ffffffff810b1a76>] ? dentry_open+0x82/0x89
             [<ffffffffa00e693c>] cachefiles_write_page+0x298/0x335 [cachefiles]
             [<ffffffffa0077147>] fscache_write_op+0x178/0x2c2 [fscache]
             [<ffffffffa0075656>] fscache_op_execute+0x7a/0xd1 [fscache]
             [<ffffffff81082093>] slow_work_execute+0x18f/0x2d1
             [<ffffffff8108239a>] slow_work_thread+0x1c5/0x308
             [<ffffffff8104c0f1>] ? autoremove_wake_function+0x0/0x34
             [<ffffffff810821d5>] ? slow_work_thread+0x0/0x308
             [<ffffffff8104be91>] kthread+0x7a/0x82
             [<ffffffff8100beda>] child_rip+0xa/0x20
             [<ffffffff8100b87c>] ? restore_args+0x0/0x30
             [<ffffffff8102ef83>] ? tg_shares_up+0x171/0x227
             [<ffffffff8104be17>] ? kthread+0x0/0x82
             [<ffffffff8100bed0>] ? child_rip+0x0/0x20
    
    In the above backtrace, the following is happening:
    
     (1) A page storage operation is being executed by a slow-work thread
         (fscache_write_op()).
    
     (2) FS-Cache farms the operation out to the cache to perform
         (cachefiles_write_page()).
    
     (3) CacheFiles is then calling Ext3 to perform the actual write, using Ext3's
         standard write (do_sync_write()) under KERNEL_DS directly from the netfs
         page.
    
     (4) However, for Ext3 to perform the write, it must allocate some memory, in
         particular, it must allocate at least one page cache page into which it
         can copy the data from the netfs page.
    
     (5) Under OOM conditions, the memory allocator can't immediately come up with
         a page, so it uses vmscan to find something to discard
         (try_to_free_pages()).
    
     (6) vmscan finds a clean netfs page it might be able to discard (possibly the
         one it's trying to write out).
    
     (7) The netfs is called to throw the page away (nfs_release_page()) - but it's
         called with __GFP_WAIT, so the netfs decides to wait for the store to
         complete (__fscache_wait_on_page_write()).
    
     (8) This blocks a slow-work processing thread - possibly against itself.
    
    The system ends up stuck because it can't write out any netfs pages to the
    cache without allocating more memory.
    
    To avoid this, we make FS-Cache cancel some writes that aren't in the middle of
    actually being performed.  This means that some data won't make it into the
    cache this time.  To support this, a new FS-Cache function is added
    fscache_maybe_release_page() that replaces what the netfs releasepage()
    functions used to do with respect to the cache.
    
    The decisions fscache_maybe_release_page() makes are counted and displayed
    through /proc/fs/fscache/stats on a line labelled "VmScan".  There are four
    counters provided: "nos=N" - pages that weren't pending storage; "gon=N" -
    pages that were pending storage when we first looked, but weren't by the time
    we got the object lock; "bsy=N" - pages that we ignored as they were actively
    being written when we looked; and "can=N" - pages that we cancelled the storage
    of.
    
    What I'd really like to do is alter the behaviour of the cancellation
    heuristics, depending on how necessary it is to expel pages.  If there are
    plenty of other pages that aren't waiting to be written to the cache that
    could be ejected first, then it would be nice to hold up on immediate
    cancellation of cache writes - but I don't see a way of doing that.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index f3aa4bdafef6..4750d5fb419f 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -317,6 +317,7 @@ struct fscache_cookie {
 	void				*netfs_data;	/* back pointer to netfs */
 	struct radix_tree_root		stores;		/* pages to be stored on this cookie */
 #define FSCACHE_COOKIE_PENDING_TAG	0		/* pages tag: pending write to cache */
+#define FSCACHE_COOKIE_STORING_TAG	1		/* pages tag: writing to cache */
 
 	unsigned long			flags;
 #define FSCACHE_COOKIE_LOOKING_UP	0	/* T if non-index cookie being looked up still */

commit 1bccf513ac49d44604ba1cddcc29f5886e70f1b6
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:25 2009 +0000

    FS-Cache: Fix lock misorder in fscache_write_op()
    
    FS-Cache has two structs internally for keeping track of the internal state of
    a cached file: the fscache_cookie struct, which represents the netfs's state,
    and fscache_object struct, which represents the cache's state.  Each has a
    pointer that points to the other (when both are in existence), and each has a
    spinlock for pointer maintenance.
    
    Since netfs operations approach these structures from the cookie side, they get
    the cookie lock first, then the object lock.  Cache operations, on the other
    hand, approach from the object side, and get the object lock first.  It is not
    then permitted for a cache operation to get the cookie lock whilst it is
    holding the object lock lest deadlock occur; instead, it must do one of two
    things:
    
     (1) increment the cookie usage counter, drop the object lock and then get both
         locks in order, or
    
     (2) simply hold the object lock as certain parts of the cookie may not be
         altered whilst the object lock is held.
    
    It is also not permitted to follow either pointer without holding the lock at
    the end you start with.  To break the pointers between the cookie and the
    object, both locks must be held.
    
    fscache_write_op(), however, violates the locking rules: It attempts to get the
    cookie lock without (a) checking that the cookie pointer is a valid pointer,
    and (b) holding the object lock to protect the cookie pointer whilst it follows
    it.  This is so that it can access the pending page store tree without
    interference from __fscache_write_page().
    
    This is fixed by splitting the cookie lock, such that the page store tracking
    tree is protected by its own lock, and checking that the cookie pointer is
    non-NULL before we attempt to follow it whilst holding the object lock.
    
    The new lock is subordinate to both the cookie lock and the object lock, and so
    should be taken after those.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 184cbdfbcc99..f3aa4bdafef6 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -310,6 +310,7 @@ struct fscache_cookie {
 	atomic_t			usage;		/* number of users of this cookie */
 	atomic_t			n_children;	/* number of children of this cookie */
 	spinlock_t			lock;
+	spinlock_t			stores_lock;	/* lock on page store tree */
 	struct hlist_head		backing_objects; /* object(s) backing this file/index */
 	const struct fscache_cookie_def	*def;		/* definition */
 	struct fscache_cookie		*parent;	/* parent of this entry */

commit 4fbf4291aa15926cd4fdca0ffe9122e89d0459db
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:04 2009 +0000

    FS-Cache: Allow the current state of all objects to be dumped
    
    Allow the current state of all fscache objects to be dumped by doing:
    
            cat /proc/fs/fscache/objects
    
    By default, all objects and all fields will be shown.  This can be restricted
    by adding a suitable key to one of the caller's keyrings (such as the session
    keyring):
    
            keyctl add user fscache:objlist "<restrictions>" @s
    
    The <restrictions> are:
    
            K       Show hexdump of object key (don't show if not given)
            A       Show hexdump of object aux data (don't show if not given)
    
    And paired restrictions:
    
            C       Show objects that have a cookie
            c       Show objects that don't have a cookie
            B       Show objects that are busy
            b       Show objects that aren't busy
            W       Show objects that have pending writes
            w       Show objects that don't have pending writes
            R       Show objects that have outstanding reads
            r       Show objects that don't have outstanding reads
            S       Show objects that have slow work queued
            s       Show objects that don't have slow work queued
    
    If neither side of a restriction pair is given, then both are implied.  For
    example:
    
            keyctl add user fscache:objlist KB @s
    
    shows objects that are busy, and lists their object keys, but does not dump
    their auxiliary data.  It also implies "CcWwRrSs", but as 'B' is given, 'b' is
    not implied.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 7a9847ccd192..184cbdfbcc99 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -91,6 +91,8 @@ struct fscache_operation {
 #define FSCACHE_OP_WAITING	4	/* cleared when op is woken */
 #define FSCACHE_OP_EXCLUSIVE	5	/* exclusive op, other ops must wait */
 #define FSCACHE_OP_DEAD		6	/* op is now dead */
+#define FSCACHE_OP_DEC_READ_CNT	7	/* decrement object->n_reads on destruction */
+#define FSCACHE_OP_KEEP_FLAGS	0xc0	/* flags to keep when repurposing an op */
 
 	atomic_t		usage;
 	unsigned		debug_id;	/* debugging ID */
@@ -357,6 +359,7 @@ struct fscache_object {
 	int			n_obj_ops;	/* number of object ops outstanding on object */
 	int			n_in_progress;	/* number of ops in progress */
 	int			n_exclusive;	/* number of exclusive ops queued */
+	atomic_t		n_reads;	/* number of read ops in progress */
 	spinlock_t		lock;		/* state and operations lock */
 
 	unsigned long		lookup_jif;	/* time at which lookup started */
@@ -370,6 +373,7 @@ struct fscache_object {
 #define FSCACHE_OBJECT_EV_RELEASE	4	/* T if netfs requested object release */
 #define FSCACHE_OBJECT_EV_RETIRE	5	/* T if netfs requested object retirement */
 #define FSCACHE_OBJECT_EV_WITHDRAW	6	/* T if cache requested object withdrawal */
+#define FSCACHE_OBJECT_EVENTS_MASK	0x7f	/* mask of all events*/
 
 	unsigned long		flags;
 #define FSCACHE_OBJECT_LOCK		0	/* T if object is busy being processed */
@@ -385,6 +389,9 @@ struct fscache_object {
 	struct list_head	dependents;	/* FIFO of dependent objects */
 	struct list_head	dep_link;	/* link in parent's dependents list */
 	struct list_head	pending_ops;	/* unstarted operations on this object */
+#ifdef CONFIG_FSCACHE_OBJECT_LIST
+	struct rb_node		objlist_link;	/* link in global object list */
+#endif
 	pgoff_t			store_limit;	/* current storage limit */
 };
 
@@ -434,6 +441,12 @@ void fscache_object_init(struct fscache_object *object,
 extern void fscache_object_lookup_negative(struct fscache_object *object);
 extern void fscache_obtained_object(struct fscache_object *object);
 
+#ifdef CONFIG_FSCACHE_OBJECT_LIST
+extern void fscache_object_destroy(struct fscache_object *object);
+#else
+#define fscache_object_destroy(object) do {} while(0)
+#endif
+
 /**
  * fscache_object_destroyed - Note destruction of an object in a cache
  * @cache: The cache from which the object came

commit 440f0affe247e9990c8f8778f1861da4fd7d5e50
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:01 2009 +0000

    FS-Cache: Annotate slow-work runqueue proc lines for FS-Cache work items
    
    Annotate slow-work runqueue proc lines for FS-Cache work items.  Objects
    include the object ID and the state.  Operations include the object ID, the
    operation ID and the operation type and state.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index 84d3532dd3ea..7a9847ccd192 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -102,6 +102,16 @@ struct fscache_operation {
 
 	/* operation releaser */
 	fscache_operation_release_t release;
+
+#ifdef CONFIG_SLOW_WORK_PROC
+	const char *name;		/* operation name */
+	const char *state;		/* operation state */
+#define fscache_set_op_name(OP, N)	do { (OP)->name  = (N); } while(0)
+#define fscache_set_op_state(OP, S)	do { (OP)->state = (S); } while(0)
+#else
+#define fscache_set_op_name(OP, N)	do { } while(0)
+#define fscache_set_op_state(OP, S)	do { } while(0)
+#endif
 };
 
 extern atomic_t fscache_op_debug_id;
@@ -125,6 +135,7 @@ static inline void fscache_operation_init(struct fscache_operation *op,
 	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
 	op->release = release;
 	INIT_LIST_HEAD(&op->pend_link);
+	fscache_set_op_state(op, "Init");
 }
 
 /**
@@ -337,6 +348,7 @@ struct fscache_object {
 		FSCACHE_OBJECT_RECYCLING,	/* retiring object */
 		FSCACHE_OBJECT_WITHDRAWING,	/* withdrawing object */
 		FSCACHE_OBJECT_DEAD,		/* object is now dead */
+		FSCACHE_OBJECT__NSTATES
 	} state;
 
 	int			debug_id;	/* debugging ID */

commit 7394daa8c61dfda4baa687f133748fa0b599b017
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 3 16:42:37 2009 +0100

    FS-Cache: Add use of /proc and presentation of statistics
    
    Make FS-Cache create its /proc interface and present various statistical
    information through it.  Also provide the functions for updating this
    information.
    
    These features are enabled by:
    
            CONFIG_FSCACHE_PROC
            CONFIG_FSCACHE_STATS
            CONFIG_FSCACHE_HISTOGRAM
    
    The /proc directory for FS-Cache is also exported so that caching modules can
    add their own statistics there too.
    
    The FS-Cache module is loadable at this point, and the statistics files can be
    examined by userspace:
    
            cat /proc/fs/fscache/stats
            cat /proc/fs/fscache/histogram
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Steve Dickson <steved@redhat.com>
    Acked-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Tested-by: Daire Byrne <Daire.Byrne@framestore.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
index b2a9a484c4cf..84d3532dd3ea 100644
--- a/include/linux/fscache-cache.h
+++ b/include/linux/fscache-cache.h
@@ -29,10 +29,6 @@ struct fscache_cache_ops;
 struct fscache_object;
 struct fscache_operation;
 
-#ifdef CONFIG_FSCACHE_PROC
-extern struct proc_dir_entry *proc_fscache;
-#endif
-
 /*
  * cache tag definition
  */

commit 0dfc41d1efcc4180abfd32f68f0ade540e636ff6
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 3 16:42:36 2009 +0100

    FS-Cache: Add the FS-Cache cache backend API and documentation
    
    Add the API for a generic facility (FS-Cache) by which caches may declare them
    selves open for business, and may obtain work to be done from network
    filesystems.  The header file is included by:
    
            #include <linux/fscache-cache.h>
    
    Documentation for the API is also added to:
    
            Documentation/filesystems/caching/backend-api.txt
    
    This API is not usable without the implementation of the utility functions
    which will be added in further patches.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Steve Dickson <steved@redhat.com>
    Acked-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Tested-by: Daire Byrne <Daire.Byrne@framestore.com>

diff --git a/include/linux/fscache-cache.h b/include/linux/fscache-cache.h
new file mode 100644
index 000000000000..b2a9a484c4cf
--- /dev/null
+++ b/include/linux/fscache-cache.h
@@ -0,0 +1,509 @@
+/* General filesystem caching backing cache interface
+ *
+ * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.
+ * Written by David Howells (dhowells@redhat.com)
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ *
+ * NOTE!!! See:
+ *
+ *	Documentation/filesystems/caching/backend-api.txt
+ *
+ * for a description of the cache backend interface declared here.
+ */
+
+#ifndef _LINUX_FSCACHE_CACHE_H
+#define _LINUX_FSCACHE_CACHE_H
+
+#include <linux/fscache.h>
+#include <linux/sched.h>
+#include <linux/slow-work.h>
+
+#define NR_MAXCACHES BITS_PER_LONG
+
+struct fscache_cache;
+struct fscache_cache_ops;
+struct fscache_object;
+struct fscache_operation;
+
+#ifdef CONFIG_FSCACHE_PROC
+extern struct proc_dir_entry *proc_fscache;
+#endif
+
+/*
+ * cache tag definition
+ */
+struct fscache_cache_tag {
+	struct list_head	link;
+	struct fscache_cache	*cache;		/* cache referred to by this tag */
+	unsigned long		flags;
+#define FSCACHE_TAG_RESERVED	0		/* T if tag is reserved for a cache */
+	atomic_t		usage;
+	char			name[0];	/* tag name */
+};
+
+/*
+ * cache definition
+ */
+struct fscache_cache {
+	const struct fscache_cache_ops *ops;
+	struct fscache_cache_tag *tag;		/* tag representing this cache */
+	struct kobject		*kobj;		/* system representation of this cache */
+	struct list_head	link;		/* link in list of caches */
+	size_t			max_index_size;	/* maximum size of index data */
+	char			identifier[36];	/* cache label */
+
+	/* node management */
+	struct work_struct	op_gc;		/* operation garbage collector */
+	struct list_head	object_list;	/* list of data/index objects */
+	struct list_head	op_gc_list;	/* list of ops to be deleted */
+	spinlock_t		object_list_lock;
+	spinlock_t		op_gc_list_lock;
+	atomic_t		object_count;	/* no. of live objects in this cache */
+	struct fscache_object	*fsdef;		/* object for the fsdef index */
+	unsigned long		flags;
+#define FSCACHE_IOERROR		0	/* cache stopped on I/O error */
+#define FSCACHE_CACHE_WITHDRAWN	1	/* cache has been withdrawn */
+};
+
+extern wait_queue_head_t fscache_cache_cleared_wq;
+
+/*
+ * operation to be applied to a cache object
+ * - retrieval initiation operations are done in the context of the process
+ *   that issued them, and not in an async thread pool
+ */
+typedef void (*fscache_operation_release_t)(struct fscache_operation *op);
+typedef void (*fscache_operation_processor_t)(struct fscache_operation *op);
+
+struct fscache_operation {
+	union {
+		struct work_struct fast_work;	/* record for fast ops */
+		struct slow_work slow_work;	/* record for (very) slow ops */
+	};
+	struct list_head	pend_link;	/* link in object->pending_ops */
+	struct fscache_object	*object;	/* object to be operated upon */
+
+	unsigned long		flags;
+#define FSCACHE_OP_TYPE		0x000f	/* operation type */
+#define FSCACHE_OP_FAST		0x0001	/* - fast op, processor may not sleep for disk */
+#define FSCACHE_OP_SLOW		0x0002	/* - (very) slow op, processor may sleep for disk */
+#define FSCACHE_OP_MYTHREAD	0x0003	/* - processing is done be issuing thread, not pool */
+#define FSCACHE_OP_WAITING	4	/* cleared when op is woken */
+#define FSCACHE_OP_EXCLUSIVE	5	/* exclusive op, other ops must wait */
+#define FSCACHE_OP_DEAD		6	/* op is now dead */
+
+	atomic_t		usage;
+	unsigned		debug_id;	/* debugging ID */
+
+	/* operation processor callback
+	 * - can be NULL if FSCACHE_OP_WAITING is going to be used to perform
+	 *   the op in a non-pool thread */
+	fscache_operation_processor_t processor;
+
+	/* operation releaser */
+	fscache_operation_release_t release;
+};
+
+extern atomic_t fscache_op_debug_id;
+extern const struct slow_work_ops fscache_op_slow_work_ops;
+
+extern void fscache_enqueue_operation(struct fscache_operation *);
+extern void fscache_put_operation(struct fscache_operation *);
+
+/**
+ * fscache_operation_init - Do basic initialisation of an operation
+ * @op: The operation to initialise
+ * @release: The release function to assign
+ *
+ * Do basic initialisation of an operation.  The caller must still set flags,
+ * object, either fast_work or slow_work if necessary, and processor if needed.
+ */
+static inline void fscache_operation_init(struct fscache_operation *op,
+					  fscache_operation_release_t release)
+{
+	atomic_set(&op->usage, 1);
+	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
+	op->release = release;
+	INIT_LIST_HEAD(&op->pend_link);
+}
+
+/**
+ * fscache_operation_init_slow - Do additional initialisation of a slow op
+ * @op: The operation to initialise
+ * @processor: The processor function to assign
+ *
+ * Do additional initialisation of an operation as required for slow work.
+ */
+static inline
+void fscache_operation_init_slow(struct fscache_operation *op,
+				 fscache_operation_processor_t processor)
+{
+	op->processor = processor;
+	slow_work_init(&op->slow_work, &fscache_op_slow_work_ops);
+}
+
+/*
+ * data read operation
+ */
+struct fscache_retrieval {
+	struct fscache_operation op;
+	struct address_space	*mapping;	/* netfs pages */
+	fscache_rw_complete_t	end_io_func;	/* function to call on I/O completion */
+	void			*context;	/* netfs read context (pinned) */
+	struct list_head	to_do;		/* list of things to be done by the backend */
+	unsigned long		start_time;	/* time at which retrieval started */
+};
+
+typedef int (*fscache_page_retrieval_func_t)(struct fscache_retrieval *op,
+					     struct page *page,
+					     gfp_t gfp);
+
+typedef int (*fscache_pages_retrieval_func_t)(struct fscache_retrieval *op,
+					      struct list_head *pages,
+					      unsigned *nr_pages,
+					      gfp_t gfp);
+
+/**
+ * fscache_get_retrieval - Get an extra reference on a retrieval operation
+ * @op: The retrieval operation to get a reference on
+ *
+ * Get an extra reference on a retrieval operation.
+ */
+static inline
+struct fscache_retrieval *fscache_get_retrieval(struct fscache_retrieval *op)
+{
+	atomic_inc(&op->op.usage);
+	return op;
+}
+
+/**
+ * fscache_enqueue_retrieval - Enqueue a retrieval operation for processing
+ * @op: The retrieval operation affected
+ *
+ * Enqueue a retrieval operation for processing by the FS-Cache thread pool.
+ */
+static inline void fscache_enqueue_retrieval(struct fscache_retrieval *op)
+{
+	fscache_enqueue_operation(&op->op);
+}
+
+/**
+ * fscache_put_retrieval - Drop a reference to a retrieval operation
+ * @op: The retrieval operation affected
+ *
+ * Drop a reference to a retrieval operation.
+ */
+static inline void fscache_put_retrieval(struct fscache_retrieval *op)
+{
+	fscache_put_operation(&op->op);
+}
+
+/*
+ * cached page storage work item
+ * - used to do three things:
+ *   - batch writes to the cache
+ *   - do cache writes asynchronously
+ *   - defer writes until cache object lookup completion
+ */
+struct fscache_storage {
+	struct fscache_operation op;
+	pgoff_t			store_limit;	/* don't write more than this */
+};
+
+/*
+ * cache operations
+ */
+struct fscache_cache_ops {
+	/* name of cache provider */
+	const char *name;
+
+	/* allocate an object record for a cookie */
+	struct fscache_object *(*alloc_object)(struct fscache_cache *cache,
+					       struct fscache_cookie *cookie);
+
+	/* look up the object for a cookie */
+	void (*lookup_object)(struct fscache_object *object);
+
+	/* finished looking up */
+	void (*lookup_complete)(struct fscache_object *object);
+
+	/* increment the usage count on this object (may fail if unmounting) */
+	struct fscache_object *(*grab_object)(struct fscache_object *object);
+
+	/* pin an object in the cache */
+	int (*pin_object)(struct fscache_object *object);
+
+	/* unpin an object in the cache */
+	void (*unpin_object)(struct fscache_object *object);
+
+	/* store the updated auxilliary data on an object */
+	void (*update_object)(struct fscache_object *object);
+
+	/* discard the resources pinned by an object and effect retirement if
+	 * necessary */
+	void (*drop_object)(struct fscache_object *object);
+
+	/* dispose of a reference to an object */
+	void (*put_object)(struct fscache_object *object);
+
+	/* sync a cache */
+	void (*sync_cache)(struct fscache_cache *cache);
+
+	/* notification that the attributes of a non-index object (such as
+	 * i_size) have changed */
+	int (*attr_changed)(struct fscache_object *object);
+
+	/* reserve space for an object's data and associated metadata */
+	int (*reserve_space)(struct fscache_object *object, loff_t i_size);
+
+	/* request a backing block for a page be read or allocated in the
+	 * cache */
+	fscache_page_retrieval_func_t read_or_alloc_page;
+
+	/* request backing blocks for a list of pages be read or allocated in
+	 * the cache */
+	fscache_pages_retrieval_func_t read_or_alloc_pages;
+
+	/* request a backing block for a page be allocated in the cache so that
+	 * it can be written directly */
+	fscache_page_retrieval_func_t allocate_page;
+
+	/* request backing blocks for pages be allocated in the cache so that
+	 * they can be written directly */
+	fscache_pages_retrieval_func_t allocate_pages;
+
+	/* write a page to its backing block in the cache */
+	int (*write_page)(struct fscache_storage *op, struct page *page);
+
+	/* detach backing block from a page (optional)
+	 * - must release the cookie lock before returning
+	 * - may sleep
+	 */
+	void (*uncache_page)(struct fscache_object *object,
+			     struct page *page);
+
+	/* dissociate a cache from all the pages it was backing */
+	void (*dissociate_pages)(struct fscache_cache *cache);
+};
+
+/*
+ * data file or index object cookie
+ * - a file will only appear in one cache
+ * - a request to cache a file may or may not be honoured, subject to
+ *   constraints such as disk space
+ * - indices are created on disk just-in-time
+ */
+struct fscache_cookie {
+	atomic_t			usage;		/* number of users of this cookie */
+	atomic_t			n_children;	/* number of children of this cookie */
+	spinlock_t			lock;
+	struct hlist_head		backing_objects; /* object(s) backing this file/index */
+	const struct fscache_cookie_def	*def;		/* definition */
+	struct fscache_cookie		*parent;	/* parent of this entry */
+	void				*netfs_data;	/* back pointer to netfs */
+	struct radix_tree_root		stores;		/* pages to be stored on this cookie */
+#define FSCACHE_COOKIE_PENDING_TAG	0		/* pages tag: pending write to cache */
+
+	unsigned long			flags;
+#define FSCACHE_COOKIE_LOOKING_UP	0	/* T if non-index cookie being looked up still */
+#define FSCACHE_COOKIE_CREATING		1	/* T if non-index object being created still */
+#define FSCACHE_COOKIE_NO_DATA_YET	2	/* T if new object with no cached data yet */
+#define FSCACHE_COOKIE_PENDING_FILL	3	/* T if pending initial fill on object */
+#define FSCACHE_COOKIE_FILLING		4	/* T if filling object incrementally */
+#define FSCACHE_COOKIE_UNAVAILABLE	5	/* T if cookie is unavailable (error, etc) */
+};
+
+extern struct fscache_cookie fscache_fsdef_index;
+
+/*
+ * on-disk cache file or index handle
+ */
+struct fscache_object {
+	enum fscache_object_state {
+		FSCACHE_OBJECT_INIT,		/* object in initial unbound state */
+		FSCACHE_OBJECT_LOOKING_UP,	/* looking up object */
+		FSCACHE_OBJECT_CREATING,	/* creating object */
+
+		/* active states */
+		FSCACHE_OBJECT_AVAILABLE,	/* cleaning up object after creation */
+		FSCACHE_OBJECT_ACTIVE,		/* object is usable */
+		FSCACHE_OBJECT_UPDATING,	/* object is updating */
+
+		/* terminal states */
+		FSCACHE_OBJECT_DYING,		/* object waiting for accessors to finish */
+		FSCACHE_OBJECT_LC_DYING,	/* object cleaning up after lookup/create */
+		FSCACHE_OBJECT_ABORT_INIT,	/* abort the init state */
+		FSCACHE_OBJECT_RELEASING,	/* releasing object */
+		FSCACHE_OBJECT_RECYCLING,	/* retiring object */
+		FSCACHE_OBJECT_WITHDRAWING,	/* withdrawing object */
+		FSCACHE_OBJECT_DEAD,		/* object is now dead */
+	} state;
+
+	int			debug_id;	/* debugging ID */
+	int			n_children;	/* number of child objects */
+	int			n_ops;		/* number of ops outstanding on object */
+	int			n_obj_ops;	/* number of object ops outstanding on object */
+	int			n_in_progress;	/* number of ops in progress */
+	int			n_exclusive;	/* number of exclusive ops queued */
+	spinlock_t		lock;		/* state and operations lock */
+
+	unsigned long		lookup_jif;	/* time at which lookup started */
+	unsigned long		event_mask;	/* events this object is interested in */
+	unsigned long		events;		/* events to be processed by this object
+						 * (order is important - using fls) */
+#define FSCACHE_OBJECT_EV_REQUEUE	0	/* T if object should be requeued */
+#define FSCACHE_OBJECT_EV_UPDATE	1	/* T if object should be updated */
+#define FSCACHE_OBJECT_EV_CLEARED	2	/* T if accessors all gone */
+#define FSCACHE_OBJECT_EV_ERROR		3	/* T if fatal error occurred during processing */
+#define FSCACHE_OBJECT_EV_RELEASE	4	/* T if netfs requested object release */
+#define FSCACHE_OBJECT_EV_RETIRE	5	/* T if netfs requested object retirement */
+#define FSCACHE_OBJECT_EV_WITHDRAW	6	/* T if cache requested object withdrawal */
+
+	unsigned long		flags;
+#define FSCACHE_OBJECT_LOCK		0	/* T if object is busy being processed */
+#define FSCACHE_OBJECT_PENDING_WRITE	1	/* T if object has pending write */
+#define FSCACHE_OBJECT_WAITING		2	/* T if object is waiting on its parent */
+
+	struct list_head	cache_link;	/* link in cache->object_list */
+	struct hlist_node	cookie_link;	/* link in cookie->backing_objects */
+	struct fscache_cache	*cache;		/* cache that supplied this object */
+	struct fscache_cookie	*cookie;	/* netfs's file/index object */
+	struct fscache_object	*parent;	/* parent object */
+	struct slow_work	work;		/* attention scheduling record */
+	struct list_head	dependents;	/* FIFO of dependent objects */
+	struct list_head	dep_link;	/* link in parent's dependents list */
+	struct list_head	pending_ops;	/* unstarted operations on this object */
+	pgoff_t			store_limit;	/* current storage limit */
+};
+
+extern const char *fscache_object_states[];
+
+#define fscache_object_is_active(obj)			      \
+	(!test_bit(FSCACHE_IOERROR, &(obj)->cache->flags) &&  \
+	 (obj)->state >= FSCACHE_OBJECT_AVAILABLE &&	      \
+	 (obj)->state < FSCACHE_OBJECT_DYING)
+
+extern const struct slow_work_ops fscache_object_slow_work_ops;
+
+/**
+ * fscache_object_init - Initialise a cache object description
+ * @object: Object description
+ *
+ * Initialise a cache object description to its basic values.
+ *
+ * See Documentation/filesystems/caching/backend-api.txt for a complete
+ * description.
+ */
+static inline
+void fscache_object_init(struct fscache_object *object,
+			 struct fscache_cookie *cookie,
+			 struct fscache_cache *cache)
+{
+	atomic_inc(&cache->object_count);
+
+	object->state = FSCACHE_OBJECT_INIT;
+	spin_lock_init(&object->lock);
+	INIT_LIST_HEAD(&object->cache_link);
+	INIT_HLIST_NODE(&object->cookie_link);
+	vslow_work_init(&object->work, &fscache_object_slow_work_ops);
+	INIT_LIST_HEAD(&object->dependents);
+	INIT_LIST_HEAD(&object->dep_link);
+	INIT_LIST_HEAD(&object->pending_ops);
+	object->n_children = 0;
+	object->n_ops = object->n_in_progress = object->n_exclusive = 0;
+	object->events = object->event_mask = 0;
+	object->flags = 0;
+	object->store_limit = 0;
+	object->cache = cache;
+	object->cookie = cookie;
+	object->parent = NULL;
+}
+
+extern void fscache_object_lookup_negative(struct fscache_object *object);
+extern void fscache_obtained_object(struct fscache_object *object);
+
+/**
+ * fscache_object_destroyed - Note destruction of an object in a cache
+ * @cache: The cache from which the object came
+ *
+ * Note the destruction and deallocation of an object record in a cache.
+ */
+static inline void fscache_object_destroyed(struct fscache_cache *cache)
+{
+	if (atomic_dec_and_test(&cache->object_count))
+		wake_up_all(&fscache_cache_cleared_wq);
+}
+
+/**
+ * fscache_object_lookup_error - Note an object encountered an error
+ * @object: The object on which the error was encountered
+ *
+ * Note that an object encountered a fatal error (usually an I/O error) and
+ * that it should be withdrawn as soon as possible.
+ */
+static inline void fscache_object_lookup_error(struct fscache_object *object)
+{
+	set_bit(FSCACHE_OBJECT_EV_ERROR, &object->events);
+}
+
+/**
+ * fscache_set_store_limit - Set the maximum size to be stored in an object
+ * @object: The object to set the maximum on
+ * @i_size: The limit to set in bytes
+ *
+ * Set the maximum size an object is permitted to reach, implying the highest
+ * byte that may be written.  Intended to be called by the attr_changed() op.
+ *
+ * See Documentation/filesystems/caching/backend-api.txt for a complete
+ * description.
+ */
+static inline
+void fscache_set_store_limit(struct fscache_object *object, loff_t i_size)
+{
+	object->store_limit = i_size >> PAGE_SHIFT;
+	if (i_size & ~PAGE_MASK)
+		object->store_limit++;
+}
+
+/**
+ * fscache_end_io - End a retrieval operation on a page
+ * @op: The FS-Cache operation covering the retrieval
+ * @page: The page that was to be fetched
+ * @error: The error code (0 if successful)
+ *
+ * Note the end of an operation to retrieve a page, as covered by a particular
+ * operation record.
+ */
+static inline void fscache_end_io(struct fscache_retrieval *op,
+				  struct page *page, int error)
+{
+	op->end_io_func(page, op->context, error);
+}
+
+/*
+ * out-of-line cache backend functions
+ */
+extern void fscache_init_cache(struct fscache_cache *cache,
+			       const struct fscache_cache_ops *ops,
+			       const char *idfmt,
+			       ...) __attribute__ ((format (printf, 3, 4)));
+
+extern int fscache_add_cache(struct fscache_cache *cache,
+			     struct fscache_object *fsdef,
+			     const char *tagname);
+extern void fscache_withdraw_cache(struct fscache_cache *cache);
+
+extern void fscache_io_error(struct fscache_cache *cache);
+
+extern void fscache_mark_pages_cached(struct fscache_retrieval *op,
+				      struct pagevec *pagevec);
+
+extern enum fscache_checkaux fscache_check_aux(struct fscache_object *object,
+					       const void *data,
+					       uint16_t datalen);
+
+#endif /* _LINUX_FSCACHE_CACHE_H */
