commit 51891498f2da78ee64dfad88fa53c9e85fb50abf
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Wed Mar 4 11:05:17 2020 -0700

    seccomp: allow TSYNC and USER_NOTIF together
    
    The restriction introduced in 7a0df7fbc145 ("seccomp: Make NEW_LISTENER and
    TSYNC flags exclusive") is mostly artificial: there is enough information
    in a seccomp user notification to tell which thread triggered a
    notification. The reason it was introduced is because TSYNC makes the
    syscall return a thread-id on failure, and NEW_LISTENER returns an fd, and
    there's no way to distinguish between these two cases (well, I suppose the
    caller could check all fds it has, then do the syscall, and if the return
    value was an fd that already existed, then it must be a thread id, but
    bleh).
    
    Matthew would like to use these two flags together in the Chrome sandbox
    which wants to use TSYNC for video drivers and NEW_LISTENER to proxy
    syscalls.
    
    So, let's fix this ugliness by adding another flag, TSYNC_ESRCH, which
    tells the kernel to just return -ESRCH on a TSYNC error. This way,
    NEW_LISTENER (and any subsequent seccomp() commands that want to return
    positive values) don't conflict with each other.
    
    Suggested-by: Matthew Denton <mpdenton@google.com>
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    Link: https://lore.kernel.org/r/20200304180517.23867-1-tycho@tycho.ws
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 03583b6d1416..4192369b8418 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -7,7 +7,8 @@
 #define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC | \
 					 SECCOMP_FILTER_FLAG_LOG | \
 					 SECCOMP_FILTER_FLAG_SPEC_ALLOW | \
-					 SECCOMP_FILTER_FLAG_NEW_LISTENER)
+					 SECCOMP_FILTER_FLAG_NEW_LISTENER | \
+					 SECCOMP_FILTER_FLAG_TSYNC_ESRCH)
 
 #ifdef CONFIG_SECCOMP
 

commit fefad9ef58ffc228f7b78b667c2aea8267503350
Author: Christian Brauner <christian.brauner@ubuntu.com>
Date:   Tue Sep 24 08:44:20 2019 +0200

    seccomp: simplify secure_computing()
    
    Afaict, the struct seccomp_data argument to secure_computing() is unused
    by all current callers. So let's remove it.
    The argument was added in [1]. It was added because having the arch
    supply the syscall arguments used to be faster than having it done by
    secure_computing() (cf. Andy's comment in [2]). This is not true anymore
    though.
    
    /* References */
    [1]: 2f275de5d1ed ("seccomp: Add a seccomp_data parameter secure_computing()")
    [2]: https://lore.kernel.org/r/CALCETrU_fs_At-hTpr231kpaAd0z7xJN4ku-DvzhRU6cvcJA_w@mail.gmail.com
    
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Drewry <wad@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-parisc@vger.kernel.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-um@lists.infradead.org
    Cc: x86@kernel.org
    Acked-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20190924064420.6353-1-christian.brauner@ubuntu.com
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 84868d37b35d..03583b6d1416 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -33,10 +33,10 @@ struct seccomp {
 
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
 extern int __secure_computing(const struct seccomp_data *sd);
-static inline int secure_computing(const struct seccomp_data *sd)
+static inline int secure_computing(void)
 {
 	if (unlikely(test_thread_flag(TIF_SECCOMP)))
-		return  __secure_computing(sd);
+		return  __secure_computing(NULL);
 	return 0;
 }
 #else
@@ -59,7 +59,7 @@ struct seccomp { };
 struct seccomp_filter { };
 
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
-static inline int secure_computing(struct seccomp_data *sd) { return 0; }
+static inline int secure_computing(void) { return 0; }
 #else
 static inline void secure_computing_strict(int this_syscall) { return; }
 #endif

commit 6a21cc50f0c7f87dae5259f6cfefe024412313f6
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Sun Dec 9 11:24:13 2018 -0700

    seccomp: add a return code to trap to userspace
    
    This patch introduces a means for syscalls matched in seccomp to notify
    some other task that a particular filter has been triggered.
    
    The motivation for this is primarily for use with containers. For example,
    if a container does an init_module(), we obviously don't want to load this
    untrusted code, which may be compiled for the wrong version of the kernel
    anyway. Instead, we could parse the module image, figure out which module
    the container is trying to load and load it on the host.
    
    As another example, containers cannot mount() in general since various
    filesystems assume a trusted image. However, if an orchestrator knows that
    e.g. a particular block device has not been exposed to a container for
    writing, it want to allow the container to mount that block device (that
    is, handle the mount for it).
    
    This patch adds functionality that is already possible via at least two
    other means that I know about, both of which involve ptrace(): first, one
    could ptrace attach, and then iterate through syscalls via PTRACE_SYSCALL.
    Unfortunately this is slow, so a faster version would be to install a
    filter that does SECCOMP_RET_TRACE, which triggers a PTRACE_EVENT_SECCOMP.
    Since ptrace allows only one tracer, if the container runtime is that
    tracer, users inside the container (or outside) trying to debug it will not
    be able to use ptrace, which is annoying. It also means that older
    distributions based on Upstart cannot boot inside containers using ptrace,
    since upstart itself uses ptrace to monitor services while starting.
    
    The actual implementation of this is fairly small, although getting the
    synchronization right was/is slightly complex.
    
    Finally, it's worth noting that the classic seccomp TOCTOU of reading
    memory data from the task still applies here, but can be avoided with
    careful design of the userspace handler: if the userspace handler reads all
    of the task memory that is necessary before applying its security policy,
    the tracee's subsequent memory edits will not be read by the tracer.
    
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Eric W. Biederman <ebiederm@xmission.com>
    CC: "Serge E. Hallyn" <serge@hallyn.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    CC: Christian Brauner <christian@brauner.io>
    CC: Tyler Hicks <tyhicks@canonical.com>
    CC: Akihiro Suda <suda.akihiro@lab.ntt.co.jp>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index b5103c019cf4..84868d37b35d 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -4,9 +4,10 @@
 
 #include <uapi/linux/seccomp.h>
 
-#define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC	| \
-					 SECCOMP_FILTER_FLAG_LOG	| \
-					 SECCOMP_FILTER_FLAG_SPEC_ALLOW)
+#define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC | \
+					 SECCOMP_FILTER_FLAG_LOG | \
+					 SECCOMP_FILTER_FLAG_SPEC_ALLOW | \
+					 SECCOMP_FILTER_FLAG_NEW_LISTENER)
 
 #ifdef CONFIG_SECCOMP
 

commit a5662e4d81c4d4b08140c625d0f3c50b15786252
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Sun Dec 9 11:24:12 2018 -0700

    seccomp: switch system call argument type to void *
    
    The const qualifier causes problems for any code that wants to write to the
    third argument of the seccomp syscall, as we will do in a future patch in
    this series.
    
    The third argument to the seccomp syscall is documented as void *, so
    rather than just dropping the const, let's switch everything to use void *
    as well.
    
    I believe this is safe because of 1. the documentation above, 2. there's no
    real type information exported about syscalls anywhere besides the man
    pages.
    
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Eric W. Biederman <ebiederm@xmission.com>
    CC: "Serge E. Hallyn" <serge@hallyn.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    CC: Christian Brauner <christian@brauner.io>
    CC: Tyler Hicks <tyhicks@canonical.com>
    CC: Akihiro Suda <suda.akihiro@lab.ntt.co.jp>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index e5320f6c8654..b5103c019cf4 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -43,7 +43,7 @@ extern void secure_computing_strict(int this_syscall);
 #endif
 
 extern long prctl_get_seccomp(void);
-extern long prctl_set_seccomp(unsigned long, char __user *);
+extern long prctl_set_seccomp(unsigned long, void __user *);
 
 static inline int seccomp_mode(struct seccomp *s)
 {

commit 00a02d0c502a06d15e07b857f8ff921e3e402675
Author: Kees Cook <keescook@chromium.org>
Date:   Thu May 3 14:56:12 2018 -0700

    seccomp: Add filter flag to opt-out of SSB mitigation
    
    If a seccomp user is not interested in Speculative Store Bypass mitigation
    by default, it can set the new SECCOMP_FILTER_FLAG_SPEC_ALLOW flag when
    adding filters.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index c723a5c4e3ff..e5320f6c8654 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -4,8 +4,9 @@
 
 #include <uapi/linux/seccomp.h>
 
-#define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC | \
-					 SECCOMP_FILTER_FLAG_LOG)
+#define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC	| \
+					 SECCOMP_FILTER_FLAG_LOG	| \
+					 SECCOMP_FILTER_FLAG_SPEC_ALLOW)
 
 #ifdef CONFIG_SECCOMP
 

commit 26500475ac1b499d8636ff281311d633909f5d20
Author: Tycho Andersen <tycho@docker.com>
Date:   Wed Oct 11 09:39:21 2017 -0600

    ptrace, seccomp: add support for retrieving seccomp metadata
    
    With the new SECCOMP_FILTER_FLAG_LOG, we need to be able to extract these
    flags for checkpoint restore, since they describe the state of a filter.
    
    So, let's add PTRACE_SECCOMP_GET_METADATA, similar to ..._GET_FILTER, which
    returns the metadata of the nth filter (right now, just the flags).
    Hopefully this will be future proof, and new per-filter metadata can be
    added to this struct.
    
    Signed-off-by: Tycho Andersen <tycho@docker.com>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 10f25f7e4304..c723a5c4e3ff 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -95,11 +95,19 @@ static inline void get_seccomp_filter(struct task_struct *tsk)
 #if defined(CONFIG_SECCOMP_FILTER) && defined(CONFIG_CHECKPOINT_RESTORE)
 extern long seccomp_get_filter(struct task_struct *task,
 			       unsigned long filter_off, void __user *data);
+extern long seccomp_get_metadata(struct task_struct *task,
+				 unsigned long filter_off, void __user *data);
 #else
 static inline long seccomp_get_filter(struct task_struct *task,
 				      unsigned long n, void __user *data)
 {
 	return -EINVAL;
 }
+static inline long seccomp_get_metadata(struct task_struct *task,
+					unsigned long filter_off,
+					void __user *data)
+{
+	return -EINVAL;
+}
 #endif /* CONFIG_SECCOMP_FILTER && CONFIG_CHECKPOINT_RESTORE */
 #endif /* _LINUX_SECCOMP_H */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index c8bef436b61d..10f25f7e4304 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LINUX_SECCOMP_H
 #define _LINUX_SECCOMP_H
 

commit e66a39977985b1e69e17c4042cb290768eca9b02
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri Aug 11 04:33:56 2017 +0000

    seccomp: Filter flag to log all actions except SECCOMP_RET_ALLOW
    
    Add a new filter flag, SECCOMP_FILTER_FLAG_LOG, that enables logging for
    all actions except for SECCOMP_RET_ALLOW for the given filter.
    
    SECCOMP_RET_KILL actions are always logged, when "kill" is in the
    actions_logged sysctl, and SECCOMP_RET_ALLOW actions are never logged,
    regardless of this flag.
    
    This flag can be used to create noisy filters that result in all
    non-allowed actions to be logged. A process may have one noisy filter,
    which is loaded with this flag, as well as a quiet filter that's not
    loaded with this flag. This allows for the actions in a set of filters
    to be selectively conveyed to the admin.
    
    Since a system could have a large number of allocated seccomp_filter
    structs, struct packing was taken in consideration. On 64 bit x86, the
    new log member takes up one byte of an existing four byte hole in the
    struct. On 32 bit x86, the new log member creates a new four byte hole
    (unavoidable) and consumes one of those bytes.
    
    Unfortunately, the tests added for SECCOMP_FILTER_FLAG_LOG are not
    capable of inspecting the audit log to verify that the actions taken in
    the filter were logged.
    
    With this patch, the logic for deciding if an action will be logged is:
    
    if action == RET_ALLOW:
      do not log
    else if action == RET_KILL && RET_KILL in actions_logged:
      log
    else if filter-requests-logging && action in actions_logged:
      log
    else if audit_enabled && process-is-being-audited:
      log
    else:
      do not log
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index ecc296c137cd..c8bef436b61d 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -3,7 +3,8 @@
 
 #include <uapi/linux/seccomp.h>
 
-#define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC)
+#define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC | \
+					 SECCOMP_FILTER_FLAG_LOG)
 
 #ifdef CONFIG_SECCOMP
 

commit 8112c4f140fa03f9ee68aad2cc79afa7df5418d3
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 1 16:02:17 2016 -0700

    seccomp: remove 2-phase API
    
    Since nothing is using the 2-phase API, and it adds more complexity than
    benefit, remove it.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@kernel.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 9eaa7b34d6da..ecc296c137cd 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -35,12 +35,6 @@ static inline int secure_computing(const struct seccomp_data *sd)
 		return  __secure_computing(sd);
 	return 0;
 }
-
-#define SECCOMP_PHASE1_OK	0
-#define SECCOMP_PHASE1_SKIP	1
-
-extern u32 seccomp_phase1(struct seccomp_data *sd);
-int seccomp_phase2(u32 phase1_result);
 #else
 extern void secure_computing_strict(int this_syscall);
 #endif

commit 2f275de5d1ed7269913ef9b4c64a13952c0a38e8
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri May 27 12:57:02 2016 -0700

    seccomp: Add a seccomp_data parameter secure_computing()
    
    Currently, if arch code wants to supply seccomp_data directly to
    seccomp (which is generally much faster than having seccomp do it
    using the syscall_get_xyz() API), it has to use the two-phase
    seccomp hooks. Add it to the easy hooks, too.
    
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 2296e6b2f690..9eaa7b34d6da 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -28,11 +28,11 @@ struct seccomp {
 };
 
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
-extern int __secure_computing(void);
-static inline int secure_computing(void)
+extern int __secure_computing(const struct seccomp_data *sd);
+static inline int secure_computing(const struct seccomp_data *sd)
 {
 	if (unlikely(test_thread_flag(TIF_SECCOMP)))
-		return  __secure_computing();
+		return  __secure_computing(sd);
 	return 0;
 }
 
@@ -61,7 +61,7 @@ struct seccomp { };
 struct seccomp_filter { };
 
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
-static inline int secure_computing(void) { return 0; }
+static inline int secure_computing(struct seccomp_data *sd) { return 0; }
 #else
 static inline void secure_computing_strict(int this_syscall) { return; }
 #endif

commit f8e529ed941ba2bbcbf310b575d968159ce7e895
Author: Tycho Andersen <tycho.andersen@canonical.com>
Date:   Tue Oct 27 09:23:59 2015 +0900

    seccomp, ptrace: add support for dumping seccomp filters
    
    This patch adds support for dumping a process' (classic BPF) seccomp
    filters via ptrace.
    
    PTRACE_SECCOMP_GET_FILTER allows the tracer to dump the user's classic BPF
    seccomp filters. addr should be an integer which represents the ith seccomp
    filter (0 is the most recently installed filter). data should be a struct
    sock_filter * with enough room for the ith filter, or NULL, in which case
    the filter is not saved. The return value for this command is the number of
    BPF instructions the program represents, or negative in the case of errors.
    Command specific errors are ENOENT: which indicates that there is no ith
    filter in this seccomp tree, and EMEDIUMTYPE, which indicates that the ith
    filter was not installed as a classic BPF filter.
    
    A caveat with this approach is that there is no way to get explicitly at
    the heirarchy of seccomp filters, and users need to memcmp() filters to
    decide which are inherited. This means that a task which installs two of
    the same filter can potentially confuse users of this interface.
    
    v2: * make save_orig const
        * check that the orig_prog exists (not necessary right now, but when
           grows eBPF support it will be)
        * s/n/filter_off and make it an unsigned long to match ptrace
        * count "down" the tree instead of "up" when passing a filter offset
    
    v3: * don't take the current task's lock for inspecting its seccomp mode
        * use a 0x42** constant for the ptrace command value
    
    v4: * don't copy to userspace while holding spinlocks
    
    v5: * add another condition to WARN_ON
    
    v6: * rebase on net-next
    
    Signed-off-by: Tycho Andersen <tycho.andersen@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    CC: Will Drewry <wad@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Pavel Emelyanov <xemul@parallels.com>
    CC: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    CC: Alexei Starovoitov <ast@kernel.org>
    CC: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index f4265039a94c..2296e6b2f690 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -95,4 +95,15 @@ static inline void get_seccomp_filter(struct task_struct *tsk)
 	return;
 }
 #endif /* CONFIG_SECCOMP_FILTER */
+
+#if defined(CONFIG_SECCOMP_FILTER) && defined(CONFIG_CHECKPOINT_RESTORE)
+extern long seccomp_get_filter(struct task_struct *task,
+			       unsigned long filter_off, void __user *data);
+#else
+static inline long seccomp_get_filter(struct task_struct *task,
+				      unsigned long n, void __user *data)
+{
+	return -EINVAL;
+}
+#endif /* CONFIG_SECCOMP_FILTER && CONFIG_CHECKPOINT_RESTORE */
 #endif /* _LINUX_SECCOMP_H */

commit 221272f97ca528048a577a3ff23d7774286ca5fd
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Jun 15 15:29:16 2015 -0700

    seccomp: swap hard-coded zeros to defined name
    
    For clarity, if CONFIG_SECCOMP isn't defined, seccomp_mode() is returning
    "disabled". This makes that more clear, along with another 0-use, and
    results in no operational change.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index a19ddacdac30..f4265039a94c 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -78,7 +78,7 @@ static inline long prctl_set_seccomp(unsigned long arg2, char __user *arg3)
 
 static inline int seccomp_mode(struct seccomp *s)
 {
-	return 0;
+	return SECCOMP_MODE_DISABLED;
 }
 #endif /* CONFIG_SECCOMP */
 

commit d39bd00deabe57420f2a3669eb71b0e0c4997184
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon Jul 21 18:49:16 2014 -0700

    seccomp: Allow arch code to provide seccomp_data
    
    populate_seccomp_data is expensive: it works by inspecting
    task_pt_regs and various other bits to piece together all the
    information, and it's does so in multiple partially redundant steps.
    
    Arch-specific code in the syscall entry path can do much better.
    
    Admittedly this adds a bit of additional room for error, but the
    speedup should be worth it.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 38851085e481..a19ddacdac30 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -39,7 +39,7 @@ static inline int secure_computing(void)
 #define SECCOMP_PHASE1_OK	0
 #define SECCOMP_PHASE1_SKIP	1
 
-extern u32 seccomp_phase1(void);
+extern u32 seccomp_phase1(struct seccomp_data *sd);
 int seccomp_phase2(u32 phase1_result);
 #else
 extern void secure_computing_strict(int this_syscall);

commit 13aa72f0fd0a9f98a41cefb662487269e2f1ad65
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon Jul 21 18:49:15 2014 -0700

    seccomp: Refactor the filter callback and the API
    
    The reason I did this is to add a seccomp API that will be usable
    for an x86 fast path.  The x86 entry code needs to use a rather
    expensive slow path for a syscall that might be visible to things
    like ptrace.  By splitting seccomp into two phases, we can check
    whether we need the slow path and then use the fast path in if the
    filter allows the syscall or just returns some errno.
    
    As a side effect, I think the new code is much easier to understand
    than the old code.
    
    This has one user-visible effect: the audit record written for
    SECCOMP_RET_TRACE is now a simple indication that SECCOMP_RET_TRACE
    happened.  It used to depend in a complicated way on what the tracer
    did.  I couldn't make much sense of it.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index aa3c040230be..38851085e481 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -35,6 +35,12 @@ static inline int secure_computing(void)
 		return  __secure_computing();
 	return 0;
 }
+
+#define SECCOMP_PHASE1_OK	0
+#define SECCOMP_PHASE1_SKIP	1
+
+extern u32 seccomp_phase1(void);
+int seccomp_phase2(u32 phase1_result);
 #else
 extern void secure_computing_strict(int this_syscall);
 #endif

commit a4412fc9486ec85686c6c7929e7e829f62ae377e
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon Jul 21 18:49:14 2014 -0700

    seccomp,x86,arm,mips,s390: Remove nr parameter from secure_computing
    
    The secure_computing function took a syscall number parameter, but
    it only paid any attention to that parameter if seccomp mode 1 was
    enabled.  Rather than coming up with a kludge to get the parameter
    to work in mode 2, just remove the parameter.
    
    To avoid churn in arches that don't have seccomp filters (and may
    not even support syscall_get_nr right now), this leaves the
    parameter in secure_computing_strict, which is now a real function.
    
    For ARM, this is a bit ugly due to the fact that ARM conditionally
    supports seccomp filters.  Fixing that would probably only be a
    couple of lines of code, but it should be coordinated with the audit
    maintainers.
    
    This will be a slight slowdown on some arches.  The right fix is to
    pass in all of seccomp_data instead of trying to make just the
    syscall nr part be fast.
    
    This is a prerequisite for making two-phase seccomp work cleanly.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: linux-s390@vger.kernel.org
    Cc: x86@kernel.org
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 5d586a45a319..aa3c040230be 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -27,19 +27,17 @@ struct seccomp {
 	struct seccomp_filter *filter;
 };
 
-extern int __secure_computing(int);
-static inline int secure_computing(int this_syscall)
+#ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
+extern int __secure_computing(void);
+static inline int secure_computing(void)
 {
 	if (unlikely(test_thread_flag(TIF_SECCOMP)))
-		return  __secure_computing(this_syscall);
+		return  __secure_computing();
 	return 0;
 }
-
-/* A wrapper for architectures supporting only SECCOMP_MODE_STRICT. */
-static inline void secure_computing_strict(int this_syscall)
-{
-	BUG_ON(secure_computing(this_syscall) != 0);
-}
+#else
+extern void secure_computing_strict(int this_syscall);
+#endif
 
 extern long prctl_get_seccomp(void);
 extern long prctl_set_seccomp(unsigned long, char __user *);
@@ -56,8 +54,11 @@ static inline int seccomp_mode(struct seccomp *s)
 struct seccomp { };
 struct seccomp_filter { };
 
-static inline int secure_computing(int this_syscall) { return 0; }
+#ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
+static inline int secure_computing(void) { return 0; }
+#else
 static inline void secure_computing_strict(int this_syscall) { return; }
+#endif
 
 static inline long prctl_get_seccomp(void)
 {

commit c2e1f2e30daa551db3c670c0ccfeab20a540b9e1
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Jun 5 00:23:17 2014 -0700

    seccomp: implement SECCOMP_FILTER_FLAG_TSYNC
    
    Applying restrictive seccomp filter programs to large or diverse
    codebases often requires handling threads which may be started early in
    the process lifetime (e.g., by code that is linked in). While it is
    possible to apply permissive programs prior to process start up, it is
    difficult to further restrict the kernel ABI to those threads after that
    point.
    
    This change adds a new seccomp syscall flag to SECCOMP_SET_MODE_FILTER for
    synchronizing thread group seccomp filters at filter installation time.
    
    When calling seccomp(SECCOMP_SET_MODE_FILTER, SECCOMP_FILTER_FLAG_TSYNC,
    filter) an attempt will be made to synchronize all threads in current's
    threadgroup to its new seccomp filter program. This is possible iff all
    threads are using a filter that is an ancestor to the filter current is
    attempting to synchronize to. NULL filters (where the task is running as
    SECCOMP_MODE_NONE) are also treated as ancestors allowing threads to be
    transitioned into SECCOMP_MODE_FILTER. If prctrl(PR_SET_NO_NEW_PRIVS,
    ...) has been set on the calling thread, no_new_privs will be set for
    all synchronized threads too. On success, 0 is returned. On failure,
    the pid of one of the failing threads will be returned and no filters
    will have been applied.
    
    The race conditions against another thread are:
    - requesting TSYNC (already handled by sighand lock)
    - performing a clone (already handled by sighand lock)
    - changing its filter (already handled by sighand lock)
    - calling exec (handled by cred_guard_mutex)
    The clone case is assisted by the fact that new threads will have their
    seccomp state duplicated from their parent before appearing on the tasklist.
    
    Holding cred_guard_mutex means that seccomp filters cannot be assigned
    while in the middle of another thread's exec (potentially bypassing
    no_new_privs or similar). The call to de_thread() may kill threads waiting
    for the mutex.
    
    Changes across threads to the filter pointer includes a barrier.
    
    Based on patches by Will Drewry.
    
    Suggested-by: Julien Tinnes <jln@chromium.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 9ff98b4bfe2e..5d586a45a319 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -3,6 +3,8 @@
 
 #include <uapi/linux/seccomp.h>
 
+#define SECCOMP_FILTER_FLAG_MASK	(SECCOMP_FILTER_FLAG_TSYNC)
+
 #ifdef CONFIG_SECCOMP
 
 #include <linux/thread_info.h>

commit dbd952127d11bb44a4ea30b08cc60531b6a23d71
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Jun 27 15:18:48 2014 -0700

    seccomp: introduce writer locking
    
    Normally, task_struct.seccomp.filter is only ever read or modified by
    the task that owns it (current). This property aids in fast access
    during system call filtering as read access is lockless.
    
    Updating the pointer from another task, however, opens up race
    conditions. To allow cross-thread filter pointer updates, writes to the
    seccomp fields are now protected by the sighand spinlock (which is shared
    by all threads in the thread group). Read access remains lockless because
    pointer updates themselves are atomic.  However, writes (or cloning)
    often entail additional checking (like maximum instruction counts)
    which require locking to perform safely.
    
    In the case of cloning threads, the child is invisible to the system
    until it enters the task list. To make sure a child can't be cloned from
    a thread and left in a prior state, seccomp duplication is additionally
    moved under the sighand lock. Then parent and child are certain have
    the same seccomp state when they exit the lock.
    
    Based on patches by Will Drewry and David Drysdale.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 4054b0994071..9ff98b4bfe2e 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -14,11 +14,11 @@ struct seccomp_filter;
  *
  * @mode:  indicates one of the valid values above for controlled
  *         system calls available to a process.
- * @filter: The metadata and ruleset for determining what system calls
- *          are allowed for a task.
+ * @filter: must always point to a valid seccomp-filter or NULL as it is
+ *          accessed without locking during system call entry.
  *
  *          @filter must only be accessed from the context of current as there
- *          is no locking.
+ *          is no read locking.
  */
 struct seccomp {
 	int mode;

commit bd4cf0ed331a275e9bf5a49e6d0fd55dffc551b8
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Fri Mar 28 18:58:25 2014 +0100

    net: filter: rework/optimize internal BPF interpreter's instruction set
    
    This patch replaces/reworks the kernel-internal BPF interpreter with
    an optimized BPF instruction set format that is modelled closer to
    mimic native instruction sets and is designed to be JITed with one to
    one mapping. Thus, the new interpreter is noticeably faster than the
    current implementation of sk_run_filter(); mainly for two reasons:
    
    1. Fall-through jumps:
    
      BPF jump instructions are forced to go either 'true' or 'false'
      branch which causes branch-miss penalty. The new BPF jump
      instructions have only one branch and fall-through otherwise,
      which fits the CPU branch predictor logic better. `perf stat`
      shows drastic difference for branch-misses between the old and
      new code.
    
    2. Jump-threaded implementation of interpreter vs switch
       statement:
    
      Instead of single table-jump at the top of 'switch' statement,
      gcc will now generate multiple table-jump instructions, which
      helps CPU branch predictor logic.
    
    Note that the verification of filters is still being done through
    sk_chk_filter() in classical BPF format, so filters from user- or
    kernel space are verified in the same way as we do now, and same
    restrictions/constraints hold as well.
    
    We reuse current BPF JIT compilers in a way that this upgrade would
    even be fine as is, but nevertheless allows for a successive upgrade
    of BPF JIT compilers to the new format.
    
    The internal instruction set migration is being done after the
    probing for JIT compilation, so in case JIT compilers are able to
    create a native opcode image, we're going to use that, and in all
    other cases we're doing a follow-up migration of the BPF program's
    instruction set, so that it can be transparently run in the new
    interpreter.
    
    In short, the *internal* format extends BPF in the following way (more
    details can be taken from the appended documentation):
    
      - Number of registers increase from 2 to 10
      - Register width increases from 32-bit to 64-bit
      - Conditional jt/jf targets replaced with jt/fall-through
      - Adds signed > and >= insns
      - 16 4-byte stack slots for register spill-fill replaced
        with up to 512 bytes of multi-use stack space
      - Introduction of bpf_call insn and register passing convention
        for zero overhead calls from/to other kernel functions
      - Adds arithmetic right shift and endianness conversion insns
      - Adds atomic_add insn
      - Old tax/txa insns are replaced with 'mov dst,src' insn
    
    Performance of two BPF filters generated by libpcap resp. bpf_asm
    was measured on x86_64, i386 and arm32 (other libpcap programs
    have similar performance differences):
    
    fprog #1 is taken from Documentation/networking/filter.txt:
    tcpdump -i eth0 port 22 -dd
    
    fprog #2 is taken from 'man tcpdump':
    tcpdump -i eth0 'tcp port 22 and (((ip[2:2] - ((ip[0]&0xf)<<2)) -
       ((tcp[12]&0xf0)>>2)) != 0)' -dd
    
    Raw performance data from BPF micro-benchmark: SK_RUN_FILTER on the
    same SKB (cache-hit) or 10k SKBs (cache-miss); time in ns per call,
    smaller is better:
    
    --x86_64--
             fprog #1  fprog #1   fprog #2  fprog #2
             cache-hit cache-miss cache-hit cache-miss
    old BPF      90       101        192       202
    new BPF      31        71         47        97
    old BPF jit  12        34         17        44
    new BPF jit TBD
    
    --i386--
             fprog #1  fprog #1   fprog #2  fprog #2
             cache-hit cache-miss cache-hit cache-miss
    old BPF     107       136        227       252
    new BPF      40       119         69       172
    
    --arm32--
             fprog #1  fprog #1   fprog #2  fprog #2
             cache-hit cache-miss cache-hit cache-miss
    old BPF     202       300        475       540
    new BPF     180       270        330       470
    old BPF jit  26       182         37       202
    new BPF jit TBD
    
    Thus, without changing any userland BPF filters, applications on
    top of AF_PACKET (or other families) such as libpcap/tcpdump, cls_bpf
    classifier, netfilter's xt_bpf, team driver's load-balancing mode,
    and many more will have better interpreter filtering performance.
    
    While we are replacing the internal BPF interpreter, we also need
    to convert seccomp BPF in the same step to make use of the new
    internal structure since it makes use of lower-level API details
    without being further decoupled through higher-level calls like
    sk_unattached_filter_{create,destroy}(), for example.
    
    Just as for normal socket filtering, also seccomp BPF experiences
    a time-to-verdict speedup:
    
    05-sim-long_jumps.c of libseccomp was used as micro-benchmark:
    
      seccomp_rule_add_exact(ctx,...
      seccomp_rule_add_exact(ctx,...
    
      rc = seccomp_load(ctx);
    
      for (i = 0; i < 10000000; i++)
         syscall(199, 100);
    
    'short filter' has 2 rules
    'large filter' has 200 rules
    
    'short filter' performance is slightly better on x86_64/i386/arm32
    'large filter' is much faster on x86_64 and i386 and shows no
                   difference on arm32
    
    --x86_64-- short filter
    old BPF: 2.7 sec
     39.12%  bench  libc-2.15.so       [.] syscall
      8.10%  bench  [kernel.kallsyms]  [k] sk_run_filter
      6.31%  bench  [kernel.kallsyms]  [k] system_call
      5.59%  bench  [kernel.kallsyms]  [k] trace_hardirqs_on_caller
      4.37%  bench  [kernel.kallsyms]  [k] trace_hardirqs_off_caller
      3.70%  bench  [kernel.kallsyms]  [k] __secure_computing
      3.67%  bench  [kernel.kallsyms]  [k] lock_is_held
      3.03%  bench  [kernel.kallsyms]  [k] seccomp_bpf_load
    new BPF: 2.58 sec
     42.05%  bench  libc-2.15.so       [.] syscall
      6.91%  bench  [kernel.kallsyms]  [k] system_call
      6.25%  bench  [kernel.kallsyms]  [k] trace_hardirqs_on_caller
      6.07%  bench  [kernel.kallsyms]  [k] __secure_computing
      5.08%  bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
    
    --arm32-- short filter
    old BPF: 4.0 sec
     39.92%  bench  [kernel.kallsyms]  [k] vector_swi
     16.60%  bench  [kernel.kallsyms]  [k] sk_run_filter
     14.66%  bench  libc-2.17.so       [.] syscall
      5.42%  bench  [kernel.kallsyms]  [k] seccomp_bpf_load
      5.10%  bench  [kernel.kallsyms]  [k] __secure_computing
    new BPF: 3.7 sec
     35.93%  bench  [kernel.kallsyms]  [k] vector_swi
     21.89%  bench  libc-2.17.so       [.] syscall
     13.45%  bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
      6.25%  bench  [kernel.kallsyms]  [k] __secure_computing
      3.96%  bench  [kernel.kallsyms]  [k] syscall_trace_exit
    
    --x86_64-- large filter
    old BPF: 8.6 seconds
        73.38%    bench  [kernel.kallsyms]  [k] sk_run_filter
        10.70%    bench  libc-2.15.so       [.] syscall
         5.09%    bench  [kernel.kallsyms]  [k] seccomp_bpf_load
         1.97%    bench  [kernel.kallsyms]  [k] system_call
    new BPF: 5.7 seconds
        66.20%    bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
        16.75%    bench  libc-2.15.so       [.] syscall
         3.31%    bench  [kernel.kallsyms]  [k] system_call
         2.88%    bench  [kernel.kallsyms]  [k] __secure_computing
    
    --i386-- large filter
    old BPF: 5.4 sec
    new BPF: 3.8 sec
    
    --arm32-- large filter
    old BPF: 13.5 sec
     73.88%  bench  [kernel.kallsyms]  [k] sk_run_filter
     10.29%  bench  [kernel.kallsyms]  [k] vector_swi
      6.46%  bench  libc-2.17.so       [.] syscall
      2.94%  bench  [kernel.kallsyms]  [k] seccomp_bpf_load
      1.19%  bench  [kernel.kallsyms]  [k] __secure_computing
      0.87%  bench  [kernel.kallsyms]  [k] sys_getuid
    new BPF: 13.5 sec
     76.08%  bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
     10.98%  bench  [kernel.kallsyms]  [k] vector_swi
      5.87%  bench  libc-2.17.so       [.] syscall
      1.77%  bench  [kernel.kallsyms]  [k] __secure_computing
      0.93%  bench  [kernel.kallsyms]  [k] sys_getuid
    
    BPF filters generated by seccomp are very branchy, so the new
    internal BPF performance is better than the old one. Performance
    gains will be even higher when BPF JIT is committed for the
    new structure, which is planned in future work (as successive
    JIT migrations).
    
    BPF has also been stress-tested with trinity's BPF fuzzer.
    
    Joint work with Daniel Borkmann.
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Cc: Hagen Paul Pfeifer <hagen@jauu.net>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Paul Moore <pmoore@redhat.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: H. Peter Anvin <hpa@linux.intel.com>
    Cc: linux-kernel@vger.kernel.org
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 6f19cfd1840e..4054b0994071 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -76,7 +76,6 @@ static inline int seccomp_mode(struct seccomp *s)
 #ifdef CONFIG_SECCOMP_FILTER
 extern void put_seccomp_filter(struct task_struct *tsk);
 extern void get_seccomp_filter(struct task_struct *tsk);
-extern u32 seccomp_bpf_load(int off);
 #else  /* CONFIG_SECCOMP_FILTER */
 static inline void put_seccomp_filter(struct task_struct *tsk)
 {

commit 607ca46e97a1b6594b29647d98a32d545c24bdff
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 13 10:46:48 2012 +0100

    UAPI: (Scripted) Disintegrate include/linux
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 84f6320da50f..6f19cfd1840e 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -1,50 +1,8 @@
 #ifndef _LINUX_SECCOMP_H
 #define _LINUX_SECCOMP_H
 
-#include <linux/compiler.h>
-#include <linux/types.h>
+#include <uapi/linux/seccomp.h>
 
-
-/* Valid values for seccomp.mode and prctl(PR_SET_SECCOMP, <mode>) */
-#define SECCOMP_MODE_DISABLED	0 /* seccomp is not in use. */
-#define SECCOMP_MODE_STRICT	1 /* uses hard-coded filter. */
-#define SECCOMP_MODE_FILTER	2 /* uses user-supplied filter. */
-
-/*
- * All BPF programs must return a 32-bit value.
- * The bottom 16-bits are for optional return data.
- * The upper 16-bits are ordered from least permissive values to most.
- *
- * The ordering ensures that a min_t() over composed return values always
- * selects the least permissive choice.
- */
-#define SECCOMP_RET_KILL	0x00000000U /* kill the task immediately */
-#define SECCOMP_RET_TRAP	0x00030000U /* disallow and force a SIGSYS */
-#define SECCOMP_RET_ERRNO	0x00050000U /* returns an errno */
-#define SECCOMP_RET_TRACE	0x7ff00000U /* pass to a tracer or disallow */
-#define SECCOMP_RET_ALLOW	0x7fff0000U /* allow */
-
-/* Masks for the return value sections. */
-#define SECCOMP_RET_ACTION	0x7fff0000U
-#define SECCOMP_RET_DATA	0x0000ffffU
-
-/**
- * struct seccomp_data - the format the BPF program executes over.
- * @nr: the system call number
- * @arch: indicates system call convention as an AUDIT_ARCH_* value
- *        as defined in <linux/audit.h>.
- * @instruction_pointer: at the time of the system call.
- * @args: up to 6 system call arguments always stored as 64-bit values
- *        regardless of the architecture.
- */
-struct seccomp_data {
-	int nr;
-	__u32 arch;
-	__u64 instruction_pointer;
-	__u64 args[6];
-};
-
-#ifdef __KERNEL__
 #ifdef CONFIG_SECCOMP
 
 #include <linux/thread_info.h>
@@ -129,5 +87,4 @@ static inline void get_seccomp_filter(struct task_struct *tsk)
 	return;
 }
 #endif /* CONFIG_SECCOMP_FILTER */
-#endif /* __KERNEL__ */
 #endif /* _LINUX_SECCOMP_H */

commit e4da89d02f369450996cfd04f64b1cce4d8afaea
Author: Will Drewry <wad@chromium.org>
Date:   Tue Apr 17 14:48:57 2012 -0500

    seccomp: ignore secure_computing return values
    
    This change is inspired by
      https://lkml.org/lkml/2012/4/16/14
    which fixes the build warnings for arches that don't support
    CONFIG_HAVE_ARCH_SECCOMP_FILTER.
    
    In particular, there is no requirement for the return value of
    secure_computing() to be checked unless the architecture supports
    seccomp filter.  Instead of silencing the warnings with (void)
    a new static inline is added to encode the expected behavior
    in a compiler and human friendly way.
    
    v2: - cleans things up with a static inline
        - removes sfr's signed-off-by since it is a different approach
    v1: - matches sfr's original change
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 60f2b350ead7..84f6320da50f 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -75,6 +75,12 @@ static inline int secure_computing(int this_syscall)
 	return 0;
 }
 
+/* A wrapper for architectures supporting only SECCOMP_MODE_STRICT. */
+static inline void secure_computing_strict(int this_syscall)
+{
+	BUG_ON(secure_computing(this_syscall) != 0);
+}
+
 extern long prctl_get_seccomp(void);
 extern long prctl_set_seccomp(unsigned long, char __user *);
 
@@ -91,6 +97,7 @@ struct seccomp { };
 struct seccomp_filter { };
 
 static inline int secure_computing(int this_syscall) { return 0; }
+static inline void secure_computing_strict(int this_syscall) { return; }
 
 static inline long prctl_get_seccomp(void)
 {

commit b1fa650c7e6e81ca788fef52b1659295eb82ffdd
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Tue Apr 17 12:08:48 2012 +1000

    seccomp: use a static inline for a function stub
    
    Fixes this error message when CONFIG_SECCOMP is not set:
    
    arch/powerpc/kernel/ptrace.c: In function 'do_syscall_trace_enter':
    arch/powerpc/kernel/ptrace.c:1713:2: error: statement with no effect [-Werror=unused-value]
    
    Signed-off-by: Stephen Rothwell <sfr@ozlabs.au.ibm.com>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 5818e869651b..60f2b350ead7 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -90,7 +90,7 @@ static inline int seccomp_mode(struct seccomp *s)
 struct seccomp { };
 struct seccomp_filter { };
 
-#define secure_computing(x) 0
+static inline int secure_computing(int this_syscall) { return 0; }
 
 static inline long prctl_get_seccomp(void)
 {

commit fb0fadf9b213f55ca9368f3edafe51101d5d2deb
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:48:02 2012 -0500

    ptrace,seccomp: Add PTRACE_SECCOMP support
    
    This change adds support for a new ptrace option, PTRACE_O_TRACESECCOMP,
    and a new return value for seccomp BPF programs, SECCOMP_RET_TRACE.
    
    When a tracer specifies the PTRACE_O_TRACESECCOMP ptrace option, the
    tracer will be notified, via PTRACE_EVENT_SECCOMP, for any syscall that
    results in a BPF program returning SECCOMP_RET_TRACE.  The 16-bit
    SECCOMP_RET_DATA mask of the BPF program return value will be passed as
    the ptrace_message and may be retrieved using PTRACE_GETEVENTMSG.
    
    If the subordinate process is not using seccomp filter, then no
    system call notifications will occur even if the option is specified.
    
    If there is no tracer with PTRACE_O_TRACESECCOMP when SECCOMP_RET_TRACE
    is returned, the system call will not be executed and an -ENOSYS errno
    will be returned to userspace.
    
    This change adds a dependency on the system call slow path.  Any future
    efforts to use the system call fast path for seccomp filter will need to
    address this restriction.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: - rebase
         - comment fatal_signal check
         - acked-by
         - drop secure_computing_int comment
    v17: - ...
    v16: - update PT_TRACE_MASK to 0xbf4 so that STOP isn't clear on SETOPTIONS call (indan@nul.nu)
           [note PT_TRACE_MASK disappears in linux-next]
    v15: - add audit support for non-zero return codes
         - clean up style (indan@nul.nu)
    v14: - rebase/nochanges
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
           (Brings back a change to ptrace.c and the masks.)
    v12: - rebase to linux-next
         - use ptrace_event and update arch/Kconfig to mention slow-path dependency
         - drop all tracehook changes and inclusion (oleg@redhat.com)
    v11: - invert the logic to just make it a PTRACE_SYSCALL accelerator
           (indan@nul.nu)
    v10: - moved to PTRACE_O_SECCOMP / PT_TRACE_SECCOMP
    v9:  - n/a
    v8:  - guarded PTRACE_SECCOMP use with an ifdef
    v7:  - introduced
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 317ccb78cf40..5818e869651b 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -21,6 +21,7 @@
 #define SECCOMP_RET_KILL	0x00000000U /* kill the task immediately */
 #define SECCOMP_RET_TRAP	0x00030000U /* disallow and force a SIGSYS */
 #define SECCOMP_RET_ERRNO	0x00050000U /* returns an errno */
+#define SECCOMP_RET_TRACE	0x7ff00000U /* pass to a tracer or disallow */
 #define SECCOMP_RET_ALLOW	0x7fff0000U /* allow */
 
 /* Masks for the return value sections. */

commit bb6ea4301a1109afdacaee576fedbfcd7152fc86
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:48:01 2012 -0500

    seccomp: Add SECCOMP_RET_TRAP
    
    Adds a new return value to seccomp filters that triggers a SIGSYS to be
    delivered with the new SYS_SECCOMP si_code.
    
    This allows in-process system call emulation, including just specifying
    an errno or cleanly dumping core, rather than just dying.
    
    Suggested-by: Markus Gutschke <markus@chromium.org>
    Suggested-by: Julien Tinnes <jln@chromium.org>
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: - acked-by, rebase
         - don't mention secure_computing_int() anymore
    v15: - use audit_seccomp/skip
         - pad out error spacing; clean up switch (indan@nul.nu)
    v14: - n/a
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: - rebase on to linux-next
    v11: - clarify the comment (indan@nul.nu)
         - s/sigtrap/sigsys
    v10: - use SIGSYS, syscall_get_arch, updates arch/Kconfig
           note suggested-by (though original suggestion had other behaviors)
    v9:  - changes to SIGILL
    v8:  - clean up based on changes to dependent patches
    v7:  - introduction
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index b4ce2c816e06..317ccb78cf40 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -19,6 +19,7 @@
  * selects the least permissive choice.
  */
 #define SECCOMP_RET_KILL	0x00000000U /* kill the task immediately */
+#define SECCOMP_RET_TRAP	0x00030000U /* disallow and force a SIGSYS */
 #define SECCOMP_RET_ERRNO	0x00050000U /* returns an errno */
 #define SECCOMP_RET_ALLOW	0x7fff0000U /* allow */
 

commit acf3b2c71ed20c53dc69826683417703c2a88059
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:47:59 2012 -0500

    seccomp: add SECCOMP_RET_ERRNO
    
    This change adds the SECCOMP_RET_ERRNO as a valid return value from a
    seccomp filter.  Additionally, it makes the first use of the lower
    16-bits for storing a filter-supplied errno.  16-bits is more than
    enough for the errno-base.h calls.
    
    Returning errors instead of immediately terminating processes that
    violate seccomp policy allow for broader use of this functionality
    for kernel attack surface reduction.  For example, a linux container
    could maintain a whitelist of pre-existing system calls but drop
    all new ones with errnos.  This would keep a logically static attack
    surface while providing errnos that may allow for graceful failure
    without the downside of do_exit() on a bad call.
    
    This change also changes the signature of __secure_computing.  It
    appears the only direct caller is the arm entry code and it clobbers
    any possible return value (register) immediately.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: - fix up comments and rebase
         - fix bad var name which was fixed in later revs
         - remove _int() and just change the __secure_computing signature
    v16-v17: ...
    v15: - use audit_seccomp and add a skip label. (eparis@redhat.com)
         - clean up and pad out return codes (indan@nul.nu)
    v14: - no change/rebase
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: - move to WARN_ON if filter is NULL
           (oleg@redhat.com, luto@mit.edu, keescook@chromium.org)
         - return immediately for filter==NULL (keescook@chromium.org)
         - change evaluation to only compare the ACTION so that layered
           errnos don't result in the lowest one being returned.
           (keeschook@chromium.org)
    v11: - check for NULL filter (keescook@chromium.org)
    v10: - change loaders to fn
     v9: - n/a
     v8: - update Kconfig to note new need for syscall_set_return_value.
         - reordered such that TRAP behavior follows on later.
         - made the for loop a little less indent-y
     v7: - introduced
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 86bb68fc7683..b4ce2c816e06 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -12,13 +12,14 @@
 
 /*
  * All BPF programs must return a 32-bit value.
- * The bottom 16-bits are reserved for future use.
+ * The bottom 16-bits are for optional return data.
  * The upper 16-bits are ordered from least permissive values to most.
  *
  * The ordering ensures that a min_t() over composed return values always
  * selects the least permissive choice.
  */
 #define SECCOMP_RET_KILL	0x00000000U /* kill the task immediately */
+#define SECCOMP_RET_ERRNO	0x00050000U /* returns an errno */
 #define SECCOMP_RET_ALLOW	0x7fff0000U /* allow */
 
 /* Masks for the return value sections. */
@@ -64,11 +65,12 @@ struct seccomp {
 	struct seccomp_filter *filter;
 };
 
-extern void __secure_computing(int);
-static inline void secure_computing(int this_syscall)
+extern int __secure_computing(int);
+static inline int secure_computing(int this_syscall)
 {
 	if (unlikely(test_thread_flag(TIF_SECCOMP)))
-		__secure_computing(this_syscall);
+		return  __secure_computing(this_syscall);
+	return 0;
 }
 
 extern long prctl_get_seccomp(void);

commit e2cfabdfd075648216f99c2c03821cf3f47c1727
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:47:57 2012 -0500

    seccomp: add system call filtering using BPF
    
    [This patch depends on luto@mit.edu's no_new_privs patch:
       https://lkml.org/lkml/2012/1/30/264
     The whole series including Andrew's patches can be found here:
       https://github.com/redpig/linux/tree/seccomp
     Complete diff here:
       https://github.com/redpig/linux/compare/1dc65fed...seccomp
    ]
    
    This patch adds support for seccomp mode 2.  Mode 2 introduces the
    ability for unprivileged processes to install system call filtering
    policy expressed in terms of a Berkeley Packet Filter (BPF) program.
    This program will be evaluated in the kernel for each system call
    the task makes and computes a result based on data in the format
    of struct seccomp_data.
    
    A filter program may be installed by calling:
      struct sock_fprog fprog = { ... };
      ...
      prctl(PR_SET_SECCOMP, SECCOMP_MODE_FILTER, &fprog);
    
    The return value of the filter program determines if the system call is
    allowed to proceed or denied.  If the first filter program installed
    allows prctl(2) calls, then the above call may be made repeatedly
    by a task to further reduce its access to the kernel.  All attached
    programs must be evaluated before a system call will be allowed to
    proceed.
    
    Filter programs will be inherited across fork/clone and execve.
    However, if the task attaching the filter is unprivileged
    (!CAP_SYS_ADMIN) the no_new_privs bit will be set on the task.  This
    ensures that unprivileged tasks cannot attach filters that affect
    privileged tasks (e.g., setuid binary).
    
    There are a number of benefits to this approach. A few of which are
    as follows:
    - BPF has been exposed to userland for a long time
    - BPF optimization (and JIT'ing) are well understood
    - Userland already knows its ABI: system call numbers and desired
      arguments
    - No time-of-check-time-of-use vulnerable data accesses are possible.
    - system call arguments are loaded on access only to minimize copying
      required for system call policy decisions.
    
    Mode 2 support is restricted to architectures that enable
    HAVE_ARCH_SECCOMP_FILTER.  In this patch, the primary dependency is on
    syscall_get_arguments().  The full desired scope of this feature will
    add a few minor additional requirements expressed later in this series.
    Based on discussion, SECCOMP_RET_ERRNO and SECCOMP_RET_TRACE seem to be
    the desired additional functionality.
    
    No architectures are enabled in this patch.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Reviewed-by: Indan Zupancic <indan@nul.nu>
    Acked-by: Eric Paris <eparis@redhat.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    
    v18: - rebase to v3.4-rc2
         - s/chk/check/ (akpm@linux-foundation.org,jmorris@namei.org)
         - allocate with GFP_KERNEL|__GFP_NOWARN (indan@nul.nu)
         - add a comment for get_u32 regarding endianness (akpm@)
         - fix other typos, style mistakes (akpm@)
         - added acked-by
    v17: - properly guard seccomp filter needed headers (leann@ubuntu.com)
         - tighten return mask to 0x7fff0000
    v16: - no change
    v15: - add a 4 instr penalty when counting a path to account for seccomp_filter
           size (indan@nul.nu)
         - drop the max insns to 256KB (indan@nul.nu)
         - return ENOMEM if the max insns limit has been hit (indan@nul.nu)
         - move IP checks after args (indan@nul.nu)
         - drop !user_filter check (indan@nul.nu)
         - only allow explicit bpf codes (indan@nul.nu)
         - exit_code -> exit_sig
    v14: - put/get_seccomp_filter takes struct task_struct
           (indan@nul.nu,keescook@chromium.org)
         - adds seccomp_chk_filter and drops general bpf_run/chk_filter user
         - add seccomp_bpf_load for use by net/core/filter.c
         - lower max per-process/per-hierarchy: 1MB
         - moved nnp/capability check prior to allocation
           (all of the above: indan@nul.nu)
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: - added a maximum instruction count per path (indan@nul.nu,oleg@redhat.com)
         - removed copy_seccomp (keescook@chromium.org,indan@nul.nu)
         - reworded the prctl_set_seccomp comment (indan@nul.nu)
    v11: - reorder struct seccomp_data to allow future args expansion (hpa@zytor.com)
         - style clean up, @compat dropped, compat_sock_fprog32 (indan@nul.nu)
         - do_exit(SIGSYS) (keescook@chromium.org, luto@mit.edu)
         - pare down Kconfig doc reference.
         - extra comment clean up
    v10: - seccomp_data has changed again to be more aesthetically pleasing
           (hpa@zytor.com)
         - calling convention is noted in a new u32 field using syscall_get_arch.
           This allows for cross-calling convention tasks to use seccomp filters.
           (hpa@zytor.com)
         - lots of clean up (thanks, Indan!)
     v9: - n/a
     v8: - use bpf_chk_filter, bpf_run_filter. update load_fns
         - Lots of fixes courtesy of indan@nul.nu:
         -- fix up load behavior, compat fixups, and merge alloc code,
         -- renamed pc and dropped __packed, use bool compat.
         -- Added a hidden CONFIG_SECCOMP_FILTER to synthesize non-arch
            dependencies
     v7:  (massive overhaul thanks to Indan, others)
         - added CONFIG_HAVE_ARCH_SECCOMP_FILTER
         - merged into seccomp.c
         - minimal seccomp_filter.h
         - no config option (part of seccomp)
         - no new prctl
         - doesn't break seccomp on systems without asm/syscall.h
           (works but arg access always fails)
         - dropped seccomp_init_task, extra free functions, ...
         - dropped the no-asm/syscall.h code paths
         - merges with network sk_run_filter and sk_chk_filter
     v6: - fix memory leak on attach compat check failure
         - require no_new_privs || CAP_SYS_ADMIN prior to filter
           installation. (luto@mit.edu)
         - s/seccomp_struct_/seccomp_/ for macros/functions (amwang@redhat.com)
         - cleaned up Kconfig (amwang@redhat.com)
         - on block, note if the call was compat (so the # means something)
     v5: - uses syscall_get_arguments
           (indan@nul.nu,oleg@redhat.com, mcgrathr@chromium.org)
          - uses union-based arg storage with hi/lo struct to
            handle endianness.  Compromises between the two alternate
            proposals to minimize extra arg shuffling and account for
            endianness assuming userspace uses offsetof().
            (mcgrathr@chromium.org, indan@nul.nu)
          - update Kconfig description
          - add include/seccomp_filter.h and add its installation
          - (naive) on-demand syscall argument loading
          - drop seccomp_t (eparis@redhat.com)
     v4:  - adjusted prctl to make room for PR_[SG]ET_NO_NEW_PRIVS
          - now uses current->no_new_privs
            (luto@mit.edu,torvalds@linux-foundation.com)
          - assign names to seccomp modes (rdunlap@xenotime.net)
          - fix style issues (rdunlap@xenotime.net)
          - reworded Kconfig entry (rdunlap@xenotime.net)
     v3:  - macros to inline (oleg@redhat.com)
          - init_task behavior fixed (oleg@redhat.com)
          - drop creator entry and extra NULL check (oleg@redhat.com)
          - alloc returns -EINVAL on bad sizing (serge.hallyn@canonical.com)
          - adds tentative use of "always_unprivileged" as per
            torvalds@linux-foundation.org and luto@mit.edu
     v2:  - (patch 2 only)
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index d61f27fcaa97..86bb68fc7683 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -1,14 +1,67 @@
 #ifndef _LINUX_SECCOMP_H
 #define _LINUX_SECCOMP_H
 
+#include <linux/compiler.h>
+#include <linux/types.h>
+
+
+/* Valid values for seccomp.mode and prctl(PR_SET_SECCOMP, <mode>) */
+#define SECCOMP_MODE_DISABLED	0 /* seccomp is not in use. */
+#define SECCOMP_MODE_STRICT	1 /* uses hard-coded filter. */
+#define SECCOMP_MODE_FILTER	2 /* uses user-supplied filter. */
+
+/*
+ * All BPF programs must return a 32-bit value.
+ * The bottom 16-bits are reserved for future use.
+ * The upper 16-bits are ordered from least permissive values to most.
+ *
+ * The ordering ensures that a min_t() over composed return values always
+ * selects the least permissive choice.
+ */
+#define SECCOMP_RET_KILL	0x00000000U /* kill the task immediately */
+#define SECCOMP_RET_ALLOW	0x7fff0000U /* allow */
+
+/* Masks for the return value sections. */
+#define SECCOMP_RET_ACTION	0x7fff0000U
+#define SECCOMP_RET_DATA	0x0000ffffU
+
+/**
+ * struct seccomp_data - the format the BPF program executes over.
+ * @nr: the system call number
+ * @arch: indicates system call convention as an AUDIT_ARCH_* value
+ *        as defined in <linux/audit.h>.
+ * @instruction_pointer: at the time of the system call.
+ * @args: up to 6 system call arguments always stored as 64-bit values
+ *        regardless of the architecture.
+ */
+struct seccomp_data {
+	int nr;
+	__u32 arch;
+	__u64 instruction_pointer;
+	__u64 args[6];
+};
 
+#ifdef __KERNEL__
 #ifdef CONFIG_SECCOMP
 
 #include <linux/thread_info.h>
 #include <asm/seccomp.h>
 
+struct seccomp_filter;
+/**
+ * struct seccomp - the state of a seccomp'ed process
+ *
+ * @mode:  indicates one of the valid values above for controlled
+ *         system calls available to a process.
+ * @filter: The metadata and ruleset for determining what system calls
+ *          are allowed for a task.
+ *
+ *          @filter must only be accessed from the context of current as there
+ *          is no locking.
+ */
 struct seccomp {
 	int mode;
+	struct seccomp_filter *filter;
 };
 
 extern void __secure_computing(int);
@@ -19,7 +72,7 @@ static inline void secure_computing(int this_syscall)
 }
 
 extern long prctl_get_seccomp(void);
-extern long prctl_set_seccomp(unsigned long);
+extern long prctl_set_seccomp(unsigned long, char __user *);
 
 static inline int seccomp_mode(struct seccomp *s)
 {
@@ -31,15 +84,16 @@ static inline int seccomp_mode(struct seccomp *s)
 #include <linux/errno.h>
 
 struct seccomp { };
+struct seccomp_filter { };
 
-#define secure_computing(x) do { } while (0)
+#define secure_computing(x) 0
 
 static inline long prctl_get_seccomp(void)
 {
 	return -EINVAL;
 }
 
-static inline long prctl_set_seccomp(unsigned long arg2)
+static inline long prctl_set_seccomp(unsigned long arg2, char __user *arg3)
 {
 	return -EINVAL;
 }
@@ -48,7 +102,21 @@ static inline int seccomp_mode(struct seccomp *s)
 {
 	return 0;
 }
-
 #endif /* CONFIG_SECCOMP */
 
+#ifdef CONFIG_SECCOMP_FILTER
+extern void put_seccomp_filter(struct task_struct *tsk);
+extern void get_seccomp_filter(struct task_struct *tsk);
+extern u32 seccomp_bpf_load(int off);
+#else  /* CONFIG_SECCOMP_FILTER */
+static inline void put_seccomp_filter(struct task_struct *tsk)
+{
+	return;
+}
+static inline void get_seccomp_filter(struct task_struct *tsk)
+{
+	return;
+}
+#endif /* CONFIG_SECCOMP_FILTER */
+#endif /* __KERNEL__ */
 #endif /* _LINUX_SECCOMP_H */

commit 932ecebb0405b9a41cd18946e6cff8a17d434e23
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:47:54 2012 -0500

    seccomp: kill the seccomp_t typedef
    
    Replaces the seccomp_t typedef with struct seccomp to match modern
    kernel style.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Reviewed-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: rebase
    ...
    v14: rebase/nochanges
    v13: rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: rebase on to linux-next
    v8-v11: no changes
    v7: struct seccomp_struct -> struct seccomp
    v6: original inclusion in this series.
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index cc7a4e9cc7ad..d61f27fcaa97 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -7,7 +7,9 @@
 #include <linux/thread_info.h>
 #include <asm/seccomp.h>
 
-typedef struct { int mode; } seccomp_t;
+struct seccomp {
+	int mode;
+};
 
 extern void __secure_computing(int);
 static inline void secure_computing(int this_syscall)
@@ -19,7 +21,7 @@ static inline void secure_computing(int this_syscall)
 extern long prctl_get_seccomp(void);
 extern long prctl_set_seccomp(unsigned long);
 
-static inline int seccomp_mode(seccomp_t *s)
+static inline int seccomp_mode(struct seccomp *s)
 {
 	return s->mode;
 }
@@ -28,7 +30,7 @@ static inline int seccomp_mode(seccomp_t *s)
 
 #include <linux/errno.h>
 
-typedef struct { } seccomp_t;
+struct seccomp { };
 
 #define secure_computing(x) do { } while (0)
 
@@ -42,7 +44,7 @@ static inline long prctl_set_seccomp(unsigned long arg2)
 	return -EINVAL;
 }
 
-static inline int seccomp_mode(seccomp_t *s)
+static inline int seccomp_mode(struct seccomp *s)
 {
 	return 0;
 }

commit 5cec93c216db77c45f7ce970d46283bcb1933884
Author: Andy Lutomirski <luto@MIT.EDU>
Date:   Sun Jun 5 13:50:24 2011 -0400

    x86-64: Emulate legacy vsyscalls
    
    There's a fair amount of code in the vsyscall page.  It contains
    a syscall instruction (in the gettimeofday fallback) and who
    knows what will happen if an exploit jumps into the middle of
    some other code.
    
    Reduce the risk by replacing the vsyscalls with short magic
    incantations that cause the kernel to emulate the real
    vsyscalls. These incantations are useless if entered in the
    middle.
    
    This causes vsyscalls to be a little more expensive than real
    syscalls.  Fortunately sensible programs don't use them.
    The only exception is time() which is still called by glibc
    through the vsyscall - but calling time() millions of times
    per second is not sensible. glibc has this fixed in the
    development tree.
    
    This patch is not perfect: the vread_tsc and vread_hpet
    functions are still at a fixed address.  Fixing that might
    involve making alternative patching work in the vDSO.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Jesper Juhl <jj@chaosbits.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Jan Beulich <JBeulich@novell.com>
    Cc: richard -rw- weinberger <richard.weinberger@gmail.com>
    Cc: Mikael Pettersson <mikpe@it.uu.se>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Louis Rilling <Louis.Rilling@kerlabs.com>
    Cc: Valdis.Kletnieks@vt.edu
    Cc: pageexec@freemail.hu
    Link: http://lkml.kernel.org/r/e64e1b3c64858820d12c48fa739efbd1485e79d5.1307292171.git.luto@mit.edu
    [ Removed the CONFIG option - it's simpler to just do it unconditionally. Tidied up the code as well. ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 167c33361d9c..cc7a4e9cc7ad 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -19,6 +19,11 @@ static inline void secure_computing(int this_syscall)
 extern long prctl_get_seccomp(void);
 extern long prctl_set_seccomp(unsigned long);
 
+static inline int seccomp_mode(seccomp_t *s)
+{
+	return s->mode;
+}
+
 #else /* CONFIG_SECCOMP */
 
 #include <linux/errno.h>
@@ -37,6 +42,11 @@ static inline long prctl_set_seccomp(unsigned long arg2)
 	return -EINVAL;
 }
 
+static inline int seccomp_mode(seccomp_t *s)
+{
+	return 0;
+}
+
 #endif /* CONFIG_SECCOMP */
 
 #endif /* _LINUX_SECCOMP_H */

commit 42a17ad2762f465d291c3bc0b6ed2b3738f65481
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Sat Apr 18 11:30:56 2009 +0200

    <linux/seccomp.h> needs to include <linux/errno.h>.
    
    <linux/seccomp.h> uses EINVAL so should include <linux/errno.h>.  This
    fixes a build error on 64-bit MIPS if CONFIG_SECCOMP is disabled.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 262a8dccfa81..167c33361d9c 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -21,6 +21,8 @@ extern long prctl_set_seccomp(unsigned long);
 
 #else /* CONFIG_SECCOMP */
 
+#include <linux/errno.h>
+
 typedef struct { } seccomp_t;
 
 #define secure_computing(x) do { } while (0)

commit cf99abace7e07dd8491e7093a9a9ef11d48838ed
Author: Andrea Arcangeli <andrea@cpushare.com>
Date:   Sun Jul 15 23:41:33 2007 -0700

    make seccomp zerocost in schedule
    
    This follows a suggestion from Chuck Ebbert on how to make seccomp
    absolutely zerocost in schedule too.  The only remaining footprint of
    seccomp is in terms of the bzImage size that becomes a few bytes (perhaps
    even a few kbytes) larger, measure it if you care in the embedded.
    
    Signed-off-by: Andrea Arcangeli <andrea@cpushare.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index d708974dbfe3..262a8dccfa81 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -16,11 +16,6 @@ static inline void secure_computing(int this_syscall)
 		__secure_computing(this_syscall);
 }
 
-static inline int has_secure_computing(struct thread_info *ti)
-{
-	return unlikely(test_ti_thread_flag(ti, TIF_SECCOMP));
-}
-
 extern long prctl_get_seccomp(void);
 extern long prctl_set_seccomp(unsigned long);
 
@@ -29,11 +24,6 @@ extern long prctl_set_seccomp(unsigned long);
 typedef struct { } seccomp_t;
 
 #define secure_computing(x) do { } while (0)
-/* static inline to preserve typechecking */
-static inline int has_secure_computing(struct thread_info *ti)
-{
-	return 0;
-}
 
 static inline long prctl_get_seccomp(void)
 {

commit 1d9d02feeee89e9132034d504c9a45eeaf618a3d
Author: Andrea Arcangeli <andrea@cpushare.com>
Date:   Sun Jul 15 23:41:32 2007 -0700

    move seccomp from /proc to a prctl
    
    This reduces the memory footprint and it enforces that only the current
    task can enable seccomp on itself (this is a requirement for a
    strightforward [modulo preempt ;) ] TIF_NOTSC implementation).
    
    Signed-off-by: Andrea Arcangeli <andrea@cpushare.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 3e8b1cf54303..d708974dbfe3 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -4,8 +4,6 @@
 
 #ifdef CONFIG_SECCOMP
 
-#define NR_SECCOMP_MODES 1
-
 #include <linux/thread_info.h>
 #include <asm/seccomp.h>
 
@@ -23,6 +21,9 @@ static inline int has_secure_computing(struct thread_info *ti)
 	return unlikely(test_ti_thread_flag(ti, TIF_SECCOMP));
 }
 
+extern long prctl_get_seccomp(void);
+extern long prctl_set_seccomp(unsigned long);
+
 #else /* CONFIG_SECCOMP */
 
 typedef struct { } seccomp_t;
@@ -34,6 +35,16 @@ static inline int has_secure_computing(struct thread_info *ti)
 	return 0;
 }
 
+static inline long prctl_get_seccomp(void)
+{
+	return -EINVAL;
+}
+
+static inline long prctl_set_seccomp(unsigned long arg2)
+{
+	return -EINVAL;
+}
+
 #endif /* CONFIG_SECCOMP */
 
 #endif /* _LINUX_SECCOMP_H */

commit 62c4f0a2d5a188f73a94f2cb8ea0dba3e7cf0a7f
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Wed Apr 26 12:56:16 2006 +0100

    Don't include linux/config.h from anywhere else in include/
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index cd2773b29a64..3e8b1cf54303 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -1,7 +1,6 @@
 #ifndef _LINUX_SECCOMP_H
 #define _LINUX_SECCOMP_H
 
-#include <linux/config.h>
 
 #ifdef CONFIG_SECCOMP
 

commit a1365647022eb05a5993f270a78e9bef3bf554eb
Author: Andrew Morton <akpm@osdl.org>
Date:   Sun Jan 8 01:04:09 2006 -0800

    [PATCH] remove gcc-2 checks
    
    Remove various things which were checking for gcc-1.x and gcc-2.x compilers.
    
    From: Adrian Bunk <bunk@stusta.de>
    
        Some documentation updates and removes some code paths for gcc < 3.2.
    
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index dc89116bb1ca..cd2773b29a64 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -26,11 +26,7 @@ static inline int has_secure_computing(struct thread_info *ti)
 
 #else /* CONFIG_SECCOMP */
 
-#if (__GNUC__ > 2)
-  typedef struct { } seccomp_t;
-#else
-  typedef struct { int gcc_is_buggy; } seccomp_t;
-#endif
+typedef struct { } seccomp_t;
 
 #define secure_computing(x) do { } while (0)
 /* static inline to preserve typechecking */

commit ffaa8bd6c904d1ab79b677905067349a5ff51d84
Author: Andrea Arcangeli <andrea@suse.de>
Date:   Mon Jun 27 14:36:36 2005 -0700

    [PATCH] seccomp: tsc disable
    
    I believe at least for seccomp it's worth to turn off the tsc, not just for
    HT but for the L2 cache too.  So it's up to you, either you turn it off
    completely (which isn't very nice IMHO) or I recommend to apply this below
    patch.
    
    This has been tested successfully on x86-64 against current cogito
    repository (i686 compiles so I didn't bother testing ;).  People selling
    the cpu through cpushare may appreciate this bit for a peace of mind.
    
    There's no way to get any timing info anymore with this applied
    (gettimeofday is forbidden of course).  The seccomp environment is
    completely deterministic so it can't be allowed to get timing info, it has
    to be deterministic so in the future I can enable a computing mode that
    does a parallel computing for each task with server side transparent
    checkpointing and verification that the output is the same from all the 2/3
    seller computers for each task, without the buyer even noticing (for now
    the verification is left to the buyer client side and there's no
    checkpointing, since that would require more kernel changes to track the
    dirty bits but it'll be easy to extend once the basic mode is finished).
    
    Eliminating a cold-cache read of the cr4 global variable will save one
    cacheline during the tlb flush while making the code per-cpu-safe at the
    same time.  Thanks to Mikael Pettersson for noticing the tlb flush wasn't
    per-cpu-safe.
    
    The global tlb flush can run from irq (IPI calling do_flush_tlb_all) but
    it'll be transparent to the switch_to code since the IPI won't make any
    change to the cr4 contents from the point of view of the interrupted code
    and since it's now all per-cpu stuff, it will not race.  So no need to
    disable irqs in switch_to slow path.
    
    Signed-off-by: Andrea Arcangeli <andrea@cpushare.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index 3a2702bbb1d6..dc89116bb1ca 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -19,6 +19,11 @@ static inline void secure_computing(int this_syscall)
 		__secure_computing(this_syscall);
 }
 
+static inline int has_secure_computing(struct thread_info *ti)
+{
+	return unlikely(test_ti_thread_flag(ti, TIF_SECCOMP));
+}
+
 #else /* CONFIG_SECCOMP */
 
 #if (__GNUC__ > 2)
@@ -28,6 +33,11 @@ static inline void secure_computing(int this_syscall)
 #endif
 
 #define secure_computing(x) do { } while (0)
+/* static inline to preserve typechecking */
+static inline int has_secure_computing(struct thread_info *ti)
+{
+	return 0;
+}
 
 #endif /* CONFIG_SECCOMP */
 

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
new file mode 100644
index 000000000000..3a2702bbb1d6
--- /dev/null
+++ b/include/linux/seccomp.h
@@ -0,0 +1,34 @@
+#ifndef _LINUX_SECCOMP_H
+#define _LINUX_SECCOMP_H
+
+#include <linux/config.h>
+
+#ifdef CONFIG_SECCOMP
+
+#define NR_SECCOMP_MODES 1
+
+#include <linux/thread_info.h>
+#include <asm/seccomp.h>
+
+typedef struct { int mode; } seccomp_t;
+
+extern void __secure_computing(int);
+static inline void secure_computing(int this_syscall)
+{
+	if (unlikely(test_thread_flag(TIF_SECCOMP)))
+		__secure_computing(this_syscall);
+}
+
+#else /* CONFIG_SECCOMP */
+
+#if (__GNUC__ > 2)
+  typedef struct { } seccomp_t;
+#else
+  typedef struct { int gcc_is_buggy; } seccomp_t;
+#endif
+
+#define secure_computing(x) do { } while (0)
+
+#endif /* CONFIG_SECCOMP */
+
+#endif /* _LINUX_SECCOMP_H */
