commit 6348dd291e3653534a9e28e6917569bc9967b35b
Author: Charan Teja Kalla <charante@codeaurora.org>
Date:   Fri Jun 19 17:27:19 2020 +0530

    dmabuf: use spinlock to access dmabuf->name
    
    There exists a sleep-while-atomic bug while accessing the dmabuf->name
    under mutex in the dmabuffs_dname(). This is caused from the SELinux
    permissions checks on a process where it tries to validate the inherited
    files from fork() by traversing them through iterate_fd() (which
    traverse files under spin_lock) and call
    match_file(security/selinux/hooks.c) where the permission checks happen.
    This audit information is logged using dump_common_audit_data() where it
    calls d_path() to get the file path name. If the file check happen on
    the dmabuf's fd, then it ends up in ->dmabuffs_dname() and use mutex to
    access dmabuf->name. The flow will be like below:
    flush_unauthorized_files()
      iterate_fd()
        spin_lock() --> Start of the atomic section.
          match_file()
            file_has_perm()
              avc_has_perm()
                avc_audit()
                  slow_avc_audit()
                    common_lsm_audit()
                      dump_common_audit_data()
                        audit_log_d_path()
                          d_path()
                            dmabuffs_dname()
                              mutex_lock()--> Sleep while atomic.
    
    Call trace captured (on 4.19 kernels) is below:
    ___might_sleep+0x204/0x208
    __might_sleep+0x50/0x88
    __mutex_lock_common+0x5c/0x1068
    __mutex_lock_common+0x5c/0x1068
    mutex_lock_nested+0x40/0x50
    dmabuffs_dname+0xa0/0x170
    d_path+0x84/0x290
    audit_log_d_path+0x74/0x130
    common_lsm_audit+0x334/0x6e8
    slow_avc_audit+0xb8/0xf8
    avc_has_perm+0x154/0x218
    file_has_perm+0x70/0x180
    match_file+0x60/0x78
    iterate_fd+0x128/0x168
    selinux_bprm_committing_creds+0x178/0x248
    security_bprm_committing_creds+0x30/0x48
    install_exec_creds+0x1c/0x68
    load_elf_binary+0x3a4/0x14e0
    search_binary_handler+0xb0/0x1e0
    
    So, use spinlock to access dmabuf->name to avoid sleep-while-atomic.
    
    Cc: <stable@vger.kernel.org> [5.3+]
    Signed-off-by: Charan Teja Kalla <charante@codeaurora.org>
    Reviewed-by: Michael J. Ruhl <michael.j.ruhl@intel.com>
    Acked-by: Christian KÃ¶nig <christian.koenig@amd.com>
     [sumits: added comment to spinlock_t definition to avoid warning]
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/msgid/a83e7f0d-4e54-9848-4b58-e1acdbe06735@codeaurora.org

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index ab0c156abee6..a2ca294eaebe 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -311,6 +311,7 @@ struct dma_buf {
 	void *vmap_ptr;
 	const char *exp_name;
 	const char *name;
+	spinlock_t name_lock; /* spinlock to protect name access */
 	struct module *owner;
 	struct list_head list_node;
 	void *priv;

commit faa392181a0bd42c5478175cef601adeecdc91b6
Merge: cfa3b8068b09 9ca1f474cea0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 15:04:15 2020 -0700

    Merge tag 'drm-next-2020-06-02' of git://anongit.freedesktop.org/drm/drm
    
    Pull drm updates from Dave Airlie:
     "Highlights:
    
       - Core DRM had a lot of refactoring around managed drm resources to
         make drivers simpler.
    
       - Intel Tigerlake support is on by default
    
       - amdgpu now support p2p PCI buffer sharing and encrypted GPU memory
    
      Details:
    
      core:
       - uapi: error out EBUSY when existing master
       - uapi: rework SET/DROP MASTER permission handling
       - remove drm_pci.h
       - drm_pci* are now legacy
       - introduced managed DRM resources
       - subclassing support for drm_framebuffer
       - simple encoder helper
       - edid improvements
       - vblank + writeback documentation improved
       - drm/mm - optimise tree searches
       - port drivers to use devm_drm_dev_alloc
    
      dma-buf:
       - add flag for p2p buffer support
    
      mst:
       - ACT timeout improvements
       - remove drm_dp_mst_has_audio
       - don't use 2nd TX slot - spec recommends against it
    
      bridge:
       - dw-hdmi various improvements
       - chrontel ch7033 support
       - fix stack issues with old gcc
    
      hdmi:
       - add unpack function for drm infoframe
    
      fbdev:
       - misc fbdev driver fixes
    
      i915:
       - uapi: global sseu pinning
       - uapi: OA buffer polling
       - uapi: remove generated perf code
       - uapi: per-engine default property values in sysfs
       - Tigerlake GEN12 enabled.
       - Lots of gem refactoring
       - Tigerlake enablement patches
       - move to drm_device logging
       - Icelake gamma HW readout
       - push MST link retrain to hotplug work
       - bandwidth atomic helpers
       - ICL fixes
       - RPS/GT refactoring
       - Cherryview full-ppgtt support
       - i915 locking guidelines documented
       - require linear fb stride to be 512 multiple on gen9
       - Tigerlake SAGV support
    
      amdgpu:
       - uapi: encrypted GPU memory handling
       - uapi: add MEM_SYNC IB flag
       - p2p dma-buf support
       - export VRAM dma-bufs
       - FRU chip access support
       - RAS/SR-IOV updates
       - Powerplay locking fixes
       - VCN DPG (powergating) enablement
       - GFX10 clockgating fixes
       - DC fixes
       - GPU reset fixes
       - navi SDMA fix
       - expose FP16 for modesetting
       - DP 1.4 compliance fixes
       - gfx10 soft recovery
       - Improved Critical Thermal Faults handling
       - resizable BAR on gmc10
    
      amdkfd:
       - uapi: GWS resource management
       - track GPU memory per process
       - report PCI domain in topology
    
      radeon:
       - safe reg list generator fixes
    
      nouveau:
       - HD audio fixes on recent systems
       - vGPU detection (fail probe if we're on one, for now)
       - Interlaced mode fixes (mostly avoidance on Turing, which doesn't support it)
       - SVM improvements/fixes
       - NVIDIA format modifier support
       - Misc other fixes.
    
      adv7511:
       - HDMI SPDIF support
    
      ast:
       - allocate crtc state size
       - fix double assignment
       - fix suspend
    
      bochs:
       - drop connector register
    
      cirrus:
       - move to tiny drivers.
    
      exynos:
       - fix imported dma-buf mapping
       - enable runtime PM
       - fixes and cleanups
    
      mediatek:
       - DPI pin mode swap
       - config mipi_tx current/impedance
    
      lima:
       - devfreq + cooling device support
       - task handling improvements
       - runtime PM support
    
      pl111:
       - vexpress init improvements
       - fix module auto-load
    
      rcar-du:
       - DT bindings conversion to YAML
       - Planes zpos sanity check and fix
       - MAINTAINERS entry for LVDS panel driver
    
      mcde:
       - fix return value
    
      mgag200:
       - use managed config init
    
      stm:
       - read endpoints from DT
    
      vboxvideo:
       - use PCI managed functions
       - drop WC mtrr
    
      vkms:
       - enable cursor by default
    
      rockchip:
       - afbc support
    
      virtio:
       - various cleanups
    
      qxl:
       - fix cursor notify port
    
      hisilicon:
       - 128-byte stride alignment fix
    
      sun4i:
       - improved format handling"
    
    * tag 'drm-next-2020-06-02' of git://anongit.freedesktop.org/drm/drm: (1401 commits)
      drm/amd/display: Fix potential integer wraparound resulting in a hang
      drm/amd/display: drop cursor position check in atomic test
      drm/amdgpu: fix device attribute node create failed with multi gpu
      drm/nouveau: use correct conflicting framebuffer API
      drm/vblank: Fix -Wformat compile warnings on some arches
      drm/amdgpu: Sync with VM root BO when switching VM to CPU update mode
      drm/amd/display: Handle GPU reset for DC block
      drm/amdgpu: add apu flags (v2)
      drm/amd/powerpay: Disable gfxoff when setting manual mode on picasso and raven
      drm/amdgpu: fix pm sysfs node handling (v2)
      drm/amdgpu: move gpu_info parsing after common early init
      drm/amdgpu: move discovery gfx config fetching
      drm/nouveau/dispnv50: fix runtime pm imbalance on error
      drm/nouveau: fix runtime pm imbalance on error
      drm/nouveau: fix runtime pm imbalance on error
      drm/nouveau/debugfs: fix runtime pm imbalance on error
      drm/nouveau/nouveau/hmm: fix migrate zero page to GPU
      drm/nouveau/nouveau/hmm: fix nouveau_dmem_chunk allocations
      drm/nouveau/kms/nv50-: Share DP SST mode_valid() handling with MST
      drm/nouveau/kms/nv50-: Move 8BPC limit for MST into nv50_mstc_get_modes()
      ...

commit 6f49c2515e2258f08f2b905c9772dbf729610415
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Tue Apr 7 21:20:34 2020 -0700

    dma-buf: fix documentation build warnings
    
    Fix documentation warnings in dma-buf.[hc]:
    
    ../drivers/dma-buf/dma-buf.c:678: warning: Function parameter or member 'importer_ops' not described in 'dma_buf_dynamic_attach'
    ../drivers/dma-buf/dma-buf.c:678: warning: Function parameter or member 'importer_priv' not described in 'dma_buf_dynamic_attach'
    ../include/linux/dma-buf.h:339: warning: Incorrect use of kernel-doc format:          * @move_notify
    
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: linux-media@vger.kernel.org
    Cc: dri-devel@lists.freedesktop.org
    Cc: linaro-mm-sig@lists.linaro.org
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/msgid/7bcbe6fe-0b4b-87da-d003-b68a26eb4cf0@infradead.org

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 1ade486fc2bb..57bcef6f988a 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -329,13 +329,12 @@ struct dma_buf {
 
 /**
  * struct dma_buf_attach_ops - importer operations for an attachment
- * @move_notify: [optional] notification that the DMA-buf is moving
  *
  * Attachment operations implemented by the importer.
  */
 struct dma_buf_attach_ops {
 	/**
-	 * @move_notify
+	 * @move_notify: [optional] notification that the DMA-buf is moving
 	 *
 	 * If this callback is provided the framework can avoid pinning the
 	 * backing store while mappings exists.

commit 09606b5446c25b2c3b16c5bd2977eca730e3a570
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Thu Mar 22 17:09:42 2018 +0100

    dma-buf: add peer2peer flag
    
    Add a peer2peer flag noting that the importer can deal with device
    resources which are not backed by pages.
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/359286/

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 1ade486fc2bb..82e0a4a64601 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -334,6 +334,14 @@ struct dma_buf {
  * Attachment operations implemented by the importer.
  */
 struct dma_buf_attach_ops {
+	/**
+	 * @allow_peer2peer:
+	 *
+	 * If this is set to true the importer must be able to handle peer
+	 * resources without struct pages.
+	 */
+	bool allow_peer2peer;
+
 	/**
 	 * @move_notify
 	 *
@@ -362,6 +370,7 @@ struct dma_buf_attach_ops {
  * @node: list of dma_buf_attachment, protected by dma_resv lock of the dmabuf.
  * @sgt: cached mapping.
  * @dir: direction of cached mapping.
+ * @peer2peer: true if the importer can handle peer resources without pages.
  * @priv: exporter specific attachment data.
  * @importer_ops: importer operations for this attachment, if provided
  * dma_buf_map/unmap_attachment() must be called with the dma_resv lock held.
@@ -382,6 +391,7 @@ struct dma_buf_attachment {
 	struct list_head node;
 	struct sg_table *sgt;
 	enum dma_data_direction dir;
+	bool peer2peer;
 	const struct dma_buf_attach_ops *importer_ops;
 	void *importer_priv;
 	void *priv;

commit bd2275eeed5b2d33eb7718e3562bf39e46ee64d1
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Tue Feb 18 16:57:24 2020 +0100

    dma-buf: drop dynamic_mapping flag
    
    Instead use the pin() callback to detect dynamic DMA-buf handling.
    Since amdgpu is now migrated it doesn't make much sense to keep
    the extra flag.
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/353997/?series=73646&rev=1

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index b38cea240b67..1ade486fc2bb 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -42,18 +42,6 @@ struct dma_buf_ops {
 	  */
 	bool cache_sgt_mapping;
 
-	/**
-	 * @dynamic_mapping:
-	 *
-	 * If true the framework makes sure that the map/unmap_dma_buf
-	 * callbacks are always called with the dma_resv object locked.
-	 *
-	 * If false the framework makes sure that the map/unmap_dma_buf
-	 * callbacks are always called without the dma_resv object locked.
-	 * Mutual exclusive with @cache_sgt_mapping.
-	 */
-	bool dynamic_mapping;
-
 	/**
 	 * @attach:
 	 *
@@ -99,7 +87,8 @@ struct dma_buf_ops {
 	 * This is called by dma_buf_pin and lets the exporter know that the
 	 * DMA-buf can't be moved any more.
 	 *
-	 * This is called with the dmabuf->resv object locked.
+	 * This is called with the dmabuf->resv object locked and is mutual
+	 * exclusive with @cache_sgt_mapping.
 	 *
 	 * This callback is optional and should only be used in limited use
 	 * cases like scanout and not for temporary pin operations.
@@ -116,7 +105,8 @@ struct dma_buf_ops {
 	 * This is called by dma_buf_unpin and lets the exporter know that the
 	 * DMA-buf can be moved again.
 	 *
-	 * This is called with the dmabuf->resv object locked.
+	 * This is called with the dmabuf->resv object locked and is mutual
+	 * exclusive with @cache_sgt_mapping.
 	 *
 	 * This callback is optional.
 	 */
@@ -455,8 +445,7 @@ static inline void get_dma_buf(struct dma_buf *dmabuf)
  */
 static inline bool dma_buf_is_dynamic(struct dma_buf *dmabuf)
 {
-	/* TODO: switch to using pin/unpin functions as indicator. */
-	return dmabuf->ops->dynamic_mapping;
+	return !!dmabuf->ops->pin;
 }
 
 /**

commit bb42df4662a4476531147c3d9caa1940f7ad36bb
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Tue Jul 3 16:42:26 2018 +0200

    dma-buf: add dynamic DMA-buf handling v15
    
    On the exporter side we add optional explicit pinning callbacks. Which are
    called when the importer doesn't implement dynamic handling, move notification
    or need the DMA-buf locked in place for its use case.
    
    On the importer side we add an optional move_notify callback. This callback is
    used by the exporter to inform the importers that their mappings should be
    destroyed as soon as possible.
    
    This allows the exporter to provide the mappings without the need to pin
    the backing store.
    
    v2: don't try to invalidate mappings when the callback is NULL,
        lock the reservation obj while using the attachments,
        add helper to set the callback
    v3: move flag for invalidation support into the DMA-buf,
        use new attach_info structure to set the callback
    v4: use importer_priv field instead of mangling exporter priv.
    v5: drop invalidation_supported flag
    v6: squash together with pin/unpin changes
    v7: pin/unpin takes an attachment now
    v8: nuke dma_buf_attachment_(map|unmap)_locked,
        everything is now handled backward compatible
    v9: always cache when export/importer don't agree on dynamic handling
    v10: minimal style cleanup
    v11: drop automatically re-entry avoidance
    v12: rename callback to move_notify
    v13: add might_lock in appropriate places
    v14: rebase on separated locking change
    v15: add EXPERIMENTAL flag, some more code comments
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/353993/?series=73646&rev=1

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index abf5459a5b9d..b38cea240b67 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -93,14 +93,41 @@ struct dma_buf_ops {
 	 */
 	void (*detach)(struct dma_buf *, struct dma_buf_attachment *);
 
+	/**
+	 * @pin:
+	 *
+	 * This is called by dma_buf_pin and lets the exporter know that the
+	 * DMA-buf can't be moved any more.
+	 *
+	 * This is called with the dmabuf->resv object locked.
+	 *
+	 * This callback is optional and should only be used in limited use
+	 * cases like scanout and not for temporary pin operations.
+	 *
+	 * Returns:
+	 *
+	 * 0 on success, negative error code on failure.
+	 */
+	int (*pin)(struct dma_buf_attachment *attach);
+
+	/**
+	 * @unpin:
+	 *
+	 * This is called by dma_buf_unpin and lets the exporter know that the
+	 * DMA-buf can be moved again.
+	 *
+	 * This is called with the dmabuf->resv object locked.
+	 *
+	 * This callback is optional.
+	 */
+	void (*unpin)(struct dma_buf_attachment *attach);
+
 	/**
 	 * @map_dma_buf:
 	 *
 	 * This is called by dma_buf_map_attachment() and is used to map a
 	 * shared &dma_buf into device address space, and it is mandatory. It
-	 * can only be called if @attach has been called successfully. This
-	 * essentially pins the DMA buffer into place, and it cannot be moved
-	 * any more
+	 * can only be called if @attach has been called successfully.
 	 *
 	 * This call may sleep, e.g. when the backing storage first needs to be
 	 * allocated, or moved to a location suitable for all currently attached
@@ -141,9 +168,8 @@ struct dma_buf_ops {
 	 *
 	 * This is called by dma_buf_unmap_attachment() and should unmap and
 	 * release the &sg_table allocated in @map_dma_buf, and it is mandatory.
-	 * It should also unpin the backing storage if this is the last mapping
-	 * of the DMA buffer, it the exporter supports backing storage
-	 * migration.
+	 * For static dma_buf handling this might also unpins the backing
+	 * storage if this is the last mapping of the DMA buffer.
 	 */
 	void (*unmap_dma_buf)(struct dma_buf_attachment *,
 			      struct sg_table *,
@@ -311,6 +337,34 @@ struct dma_buf {
 	} cb_excl, cb_shared;
 };
 
+/**
+ * struct dma_buf_attach_ops - importer operations for an attachment
+ * @move_notify: [optional] notification that the DMA-buf is moving
+ *
+ * Attachment operations implemented by the importer.
+ */
+struct dma_buf_attach_ops {
+	/**
+	 * @move_notify
+	 *
+	 * If this callback is provided the framework can avoid pinning the
+	 * backing store while mappings exists.
+	 *
+	 * This callback is called with the lock of the reservation object
+	 * associated with the dma_buf held and the mapping function must be
+	 * called with this lock held as well. This makes sure that no mapping
+	 * is created concurrently with an ongoing move operation.
+	 *
+	 * Mappings stay valid and are not directly affected by this callback.
+	 * But the DMA-buf can now be in a different physical location, so all
+	 * mappings should be destroyed and re-created as soon as possible.
+	 *
+	 * New mappings can be created after this callback returns, and will
+	 * point to the new location of the DMA-buf.
+	 */
+	void (*move_notify)(struct dma_buf_attachment *attach);
+};
+
 /**
  * struct dma_buf_attachment - holds device-buffer attachment data
  * @dmabuf: buffer for this attachment.
@@ -319,8 +373,9 @@ struct dma_buf {
  * @sgt: cached mapping.
  * @dir: direction of cached mapping.
  * @priv: exporter specific attachment data.
- * @dynamic_mapping: true if dma_buf_map/unmap_attachment() is called with the
- * dma_resv lock held.
+ * @importer_ops: importer operations for this attachment, if provided
+ * dma_buf_map/unmap_attachment() must be called with the dma_resv lock held.
+ * @importer_priv: importer specific attachment data.
  *
  * This structure holds the attachment information between the dma_buf buffer
  * and its user device(s). The list contains one attachment struct per device
@@ -337,7 +392,8 @@ struct dma_buf_attachment {
 	struct list_head node;
 	struct sg_table *sgt;
 	enum dma_data_direction dir;
-	bool dynamic_mapping;
+	const struct dma_buf_attach_ops *importer_ops;
+	void *importer_priv;
 	void *priv;
 };
 
@@ -399,6 +455,7 @@ static inline void get_dma_buf(struct dma_buf *dmabuf)
  */
 static inline bool dma_buf_is_dynamic(struct dma_buf *dmabuf)
 {
+	/* TODO: switch to using pin/unpin functions as indicator. */
 	return dmabuf->ops->dynamic_mapping;
 }
 
@@ -413,16 +470,19 @@ static inline bool dma_buf_is_dynamic(struct dma_buf *dmabuf)
 static inline bool
 dma_buf_attachment_is_dynamic(struct dma_buf_attachment *attach)
 {
-	return attach->dynamic_mapping;
+	return !!attach->importer_ops;
 }
 
 struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
 					  struct device *dev);
 struct dma_buf_attachment *
 dma_buf_dynamic_attach(struct dma_buf *dmabuf, struct device *dev,
-		       bool dynamic_mapping);
+		       const struct dma_buf_attach_ops *importer_ops,
+		       void *importer_priv);
 void dma_buf_detach(struct dma_buf *dmabuf,
 		    struct dma_buf_attachment *attach);
+int dma_buf_pin(struct dma_buf_attachment *attach);
+void dma_buf_unpin(struct dma_buf_attachment *attach);
 
 struct dma_buf *dma_buf_export(const struct dma_buf_export_info *exp_info);
 

commit 4337ebbbbda3fb82e4fd928188a86e0bff0e9042
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Mon Nov 18 11:35:36 2019 +0100

    dma-buf: Remove kernel map/unmap hooks
    
    All implementations are gone now.
    
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: linux-media@vger.kernel.org
    Cc: linaro-mm-sig@lists.linaro.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20191118103536.17675-16-daniel.vetter@ffwll.ch

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 7feb9c3805ae..abf5459a5b9d 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -249,31 +249,6 @@ struct dma_buf_ops {
 	 */
 	int (*mmap)(struct dma_buf *, struct vm_area_struct *vma);
 
-	/**
-	 * @map:
-	 *
-	 * Maps a page from the buffer into kernel address space. The page is
-	 * specified by offset into the buffer in PAGE_SIZE units.
-	 *
-	 * This callback is optional.
-	 *
-	 * Returns:
-	 *
-	 * Virtual address pointer where requested page can be accessed. NULL
-	 * on error or when this function is unimplemented by the exporter.
-	 */
-	void *(*map)(struct dma_buf *, unsigned long);
-
-	/**
-	 * @unmap:
-	 *
-	 * Unmaps a page from the buffer. Page offset and address pointer should
-	 * be the same as the one passed to and returned by matching call to map.
-	 *
-	 * This callback is optional.
-	 */
-	void (*unmap)(struct dma_buf *, unsigned long, void *);
-
 	void *(*vmap)(struct dma_buf *);
 	void (*vunmap)(struct dma_buf *, void *vaddr);
 };

commit 7f0de8d80816d9620e995cf98acf4b6cd2d7c230
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Mon Nov 18 11:35:30 2019 +0100

    dma-buf: Drop dma_buf_k(un)map
    
    It's unused.
    
    10 years ago, back when 32bit was still fairly common and trying to
    not exhaust vmalloc space sounded like a worthwhile goal, adding these
    to dma_buf made sense.
    
    Reality is that they simply never caught on, and nowadays everyone who
    needs plenty of buffers will run in 64bit mode anyway.
    
    Also update the docs in this area to adjust them to reality.
    
    The actual hooks in dma_buf_ops will be removed once all the
    implementations are gone.
    
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: linux-media@vger.kernel.org
    Cc: linaro-mm-sig@lists.linaro.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20191118103536.17675-10-daniel.vetter@ffwll.ch

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index af73f835c51c..7feb9c3805ae 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -464,8 +464,6 @@ int dma_buf_begin_cpu_access(struct dma_buf *dma_buf,
 			     enum dma_data_direction dir);
 int dma_buf_end_cpu_access(struct dma_buf *dma_buf,
 			   enum dma_data_direction dir);
-void *dma_buf_kmap(struct dma_buf *, unsigned long);
-void dma_buf_kunmap(struct dma_buf *, unsigned long, void *);
 
 int dma_buf_mmap(struct dma_buf *, struct vm_area_struct *,
 		 unsigned long);

commit 15fd552d186cb0df34b9d36a07dd6677c4da56bc
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Tue Jul 3 16:42:26 2018 +0200

    dma-buf: change DMA-buf locking convention v3
    
    This patch is a stripped down version of the locking changes
    necessary to support dynamic DMA-buf handling.
    
    It adds a dynamic flag for both importers as well as exporters
    so that drivers can choose if they want the reservation object
    locked or unlocked during mapping of attachments.
    
    For compatibility between drivers we cache the DMA-buf mapping
    during attaching an importer as soon as exporter/importer
    disagree on the dynamic handling.
    
    Issues and solutions we considered:
    
    - We can't change all existing drivers, and existing improters have
      strong opinions about which locks they're holding while calling
      dma_buf_attachment_map/unmap. Exporters also have strong opinions about
      which locks they can acquire in their ->map/unmap callbacks, levaing no
      room for change. The solution to avoid this was to move the
      actual map/unmap out from this call, into the attach/detach callbacks,
      and cache the mapping. This works because drivers don't call
      attach/detach from deep within their code callchains (like deep in
      memory management code called from cs/execbuf ioctl), but directly from
      the fd2handle implementation.
    
    - The caching has some troubles on some soc drivers, which set other modes
      than DMA_BIDIRECTIONAL. We can't have 2 incompatible mappings, and we
      can't re-create the mapping at _map time due to the above locking fun.
      We very carefuly step around that by only caching at attach time if the
      dynamic mode between importer/expoert mismatches.
    
    - There's been quite some discussion on dma-buf mappings which need active
      cache management, which would all break down when caching, plus we don't
      have explicit flush operations on the attachment side. The solution to
      this was to shrug and keep the current discrepancy between what the
      dma-buf docs claim and what implementations do, with the hope that the
      begin/end_cpu_access hooks are good enough and that all necessary
      flushing to keep device mappings consistent will be done there.
    
    v2: cleanup set_name merge, improve kerneldoc
    v3: update commit message, kerneldoc and cleanup _debug_show()
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/336788/

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index ec212cb27fdc..af73f835c51c 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -42,6 +42,18 @@ struct dma_buf_ops {
 	  */
 	bool cache_sgt_mapping;
 
+	/**
+	 * @dynamic_mapping:
+	 *
+	 * If true the framework makes sure that the map/unmap_dma_buf
+	 * callbacks are always called with the dma_resv object locked.
+	 *
+	 * If false the framework makes sure that the map/unmap_dma_buf
+	 * callbacks are always called without the dma_resv object locked.
+	 * Mutual exclusive with @cache_sgt_mapping.
+	 */
+	bool dynamic_mapping;
+
 	/**
 	 * @attach:
 	 *
@@ -109,6 +121,9 @@ struct dma_buf_ops {
 	 * any other kind of sharing that the exporter might wish to make
 	 * available to buffer-users.
 	 *
+	 * This is always called with the dmabuf->resv object locked when
+	 * the dynamic_mapping flag is true.
+	 *
 	 * Returns:
 	 *
 	 * A &sg_table scatter list of or the backing storage of the DMA buffer,
@@ -267,14 +282,16 @@ struct dma_buf_ops {
  * struct dma_buf - shared buffer object
  * @size: size of the buffer
  * @file: file pointer used for sharing buffers across, and for refcounting.
- * @attachments: list of dma_buf_attachment that denotes all devices attached.
+ * @attachments: list of dma_buf_attachment that denotes all devices attached,
+ *               protected by dma_resv lock.
  * @ops: dma_buf_ops associated with this buffer object.
  * @lock: used internally to serialize list manipulation, attach/detach and
- *        vmap/unmap, and accesses to name
+ *        vmap/unmap
  * @vmapping_counter: used internally to refcnt the vmaps
  * @vmap_ptr: the current vmap ptr if vmapping_counter > 0
  * @exp_name: name of the exporter; useful for debugging.
- * @name: userspace-provided name; useful for accounting and debugging.
+ * @name: userspace-provided name; useful for accounting and debugging,
+ *        protected by @resv.
  * @owner: pointer to exporter module; used for refcounting when exporter is a
  *         kernel module.
  * @list_node: node for dma_buf accounting and debugging.
@@ -323,10 +340,12 @@ struct dma_buf {
  * struct dma_buf_attachment - holds device-buffer attachment data
  * @dmabuf: buffer for this attachment.
  * @dev: device attached to the buffer.
- * @node: list of dma_buf_attachment.
+ * @node: list of dma_buf_attachment, protected by dma_resv lock of the dmabuf.
  * @sgt: cached mapping.
  * @dir: direction of cached mapping.
  * @priv: exporter specific attachment data.
+ * @dynamic_mapping: true if dma_buf_map/unmap_attachment() is called with the
+ * dma_resv lock held.
  *
  * This structure holds the attachment information between the dma_buf buffer
  * and its user device(s). The list contains one attachment struct per device
@@ -343,6 +362,7 @@ struct dma_buf_attachment {
 	struct list_head node;
 	struct sg_table *sgt;
 	enum dma_data_direction dir;
+	bool dynamic_mapping;
 	void *priv;
 };
 
@@ -394,10 +414,40 @@ static inline void get_dma_buf(struct dma_buf *dmabuf)
 	get_file(dmabuf->file);
 }
 
+/**
+ * dma_buf_is_dynamic - check if a DMA-buf uses dynamic mappings.
+ * @dmabuf: the DMA-buf to check
+ *
+ * Returns true if a DMA-buf exporter wants to be called with the dma_resv
+ * locked for the map/unmap callbacks, false if it doesn't wants to be called
+ * with the lock held.
+ */
+static inline bool dma_buf_is_dynamic(struct dma_buf *dmabuf)
+{
+	return dmabuf->ops->dynamic_mapping;
+}
+
+/**
+ * dma_buf_attachment_is_dynamic - check if a DMA-buf attachment uses dynamic
+ * mappinsg
+ * @attach: the DMA-buf attachment to check
+ *
+ * Returns true if a DMA-buf importer wants to call the map/unmap functions with
+ * the dma_resv lock held.
+ */
+static inline bool
+dma_buf_attachment_is_dynamic(struct dma_buf_attachment *attach)
+{
+	return attach->dynamic_mapping;
+}
+
 struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
-							struct device *dev);
+					  struct device *dev);
+struct dma_buf_attachment *
+dma_buf_dynamic_attach(struct dma_buf *dmabuf, struct device *dev,
+		       bool dynamic_mapping);
 void dma_buf_detach(struct dma_buf *dmabuf,
-				struct dma_buf_attachment *dmabuf_attach);
+		    struct dma_buf_attachment *attach);
 
 struct dma_buf *dma_buf_export(const struct dma_buf_export_info *exp_info);
 
@@ -409,6 +459,7 @@ struct sg_table *dma_buf_map_attachment(struct dma_buf_attachment *,
 					enum dma_data_direction);
 void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *,
 				enum dma_data_direction);
+void dma_buf_move_notify(struct dma_buf *dma_buf);
 int dma_buf_begin_cpu_access(struct dma_buf *dma_buf,
 			     enum dma_data_direction dir);
 int dma_buf_end_cpu_access(struct dma_buf *dma_buf,

commit 52791eeec1d9f4a7e7fe08aaba0b1553149d93bc
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Sun Aug 11 10:06:32 2019 +0200

    dma-buf: rename reservation_object to dma_resv
    
    Be more consistent with the naming of the other DMA-buf objects.
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Link: https://patchwork.freedesktop.org/patch/323401/

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index bae060fae862..ec212cb27fdc 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -306,7 +306,7 @@ struct dma_buf {
 	struct module *owner;
 	struct list_head list_node;
 	void *priv;
-	struct reservation_object *resv;
+	struct dma_resv *resv;
 
 	/* poll support */
 	wait_queue_head_t poll;
@@ -365,7 +365,7 @@ struct dma_buf_export_info {
 	const struct dma_buf_ops *ops;
 	size_t size;
 	int flags;
-	struct reservation_object *resv;
+	struct dma_resv *resv;
 	void *priv;
 };
 

commit be8454afc50f43016ca8b6130d9673bdd0bd56ec
Merge: fec88ab0af97 3729fe2bc2a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 15 19:04:27 2019 -0700

    Merge tag 'drm-next-2019-07-16' of git://anongit.freedesktop.org/drm/drm
    
    Pull drm updates from Dave Airlie:
     "The biggest thing in this is the AMD Navi GPU support, this again
      contains a bunch of header files that are large. These are the new AMD
      RX5700 GPUs that just recently became available.
    
      New drivers:
       - ST-Ericsson MCDE driver
       - Ingenic JZ47xx SoC
    
      UAPI change:
       - HDR source metadata property
    
      Core:
       - HDR inforframes and EDID parsing
       - drm hdmi infoframe unpacking
       - remove prime sg_table caching into dma-buf
       - New gem vram helpers to reduce driver code
       - Lots of drmP.h removal
       - reservation fencing fix
       - documentation updates
       - drm_fb_helper_connector removed
       - mode name command handler rewrite
    
      fbcon:
       - Remove the fbcon notifiers
    
      ttm:
       - forward progress fixes
    
      dma-buf:
       - make mmap call optional
       - debugfs refcount fixes
       - dma-fence free with pending signals fix
       - each dma-buf gets an inode
    
      Panels:
       - Lots of additional panel bindings
    
      amdgpu:
       - initial navi10 support
       - avoid hw reset
       - HDR metadata support
       - new thermal sensors for vega asics
       - RAS fixes
       - use HMM rather than MMU notifier
       - xgmi topology via kfd
       - SR-IOV fixes
       - driver reload fixes
       - DC use a core bpc attribute
       - Aux fixes for DC
       - Bandwidth calc updates for DC
       - Clock handling refactor
       - kfd VEGAM support
    
      vmwgfx:
       - Coherent memory support changes
    
      i915:
       - HDR Support
       - HDMI i2c link
       - Icelake multi-segmented gamma support
       - GuC firmware update
       - Mule Creek Canyon PCH support for EHL
       - EHL platform updtes
       - move i915.alpha_support to i915.force_probe
       - runtime PM refactoring
       - VBT parsing refactoring
       - DSI fixes
       - struct mutex dependency reduction
       - GEM code reorg
    
      mali-dp:
       - Komeda driver features
    
      msm:
       - dsi vs EPROBE_DEFER fixes
       - msm8998 snapdragon 835 support
       - a540 gpu support
       - mdp5 and dpu interconnect support
    
      exynos:
       - drmP.h removal
    
      tegra:
       - misc fixes
    
      tda998x:
       - audio support improvements
       - pixel repeated mode support
       - quantisation range handling corrections
       - HDMI vendor info fix
    
      armada:
       - interlace support fix
       - overlay/video plane register handling refactor
       - add gamma support
    
      rockchip:
       - RX3328 support
    
      panfrost:
       - expose perf counters via hidden ioctls
    
      vkms:
       - enumerate CRC sources list
    
      ast:
       - rework BO handling
    
      mgag200:
       - rework BO handling
    
      dw-hdmi:
       - suspend/resume support
    
      rcar-du:
       - R8A774A1 Soc Support
       - LVDS dual-link mode support
       - Additional formats
       - Misc fixes
    
      omapdrm:
       - DSI command mode display support
    
      stm
       - fb modifier support
       - runtime PM support
    
      sun4i:
       - use vmap ops
    
      vc4:
       - binner bo binding rework
    
      v3d:
       - compute shader support
       - resync/sync fixes
       - job management refactoring
    
      lima:
       - NULL pointer in irq handler fix
       - scheduler default timeout
    
      virtio:
       - fence seqno support
       - trace events
    
      bochs:
       - misc fixes
    
      tc458767:
       - IRQ/HDP handling
    
      sii902x:
       - HDMI audio support
    
      atmel-hlcdc:
       - misc fixes
    
      meson:
       - zpos support"
    
    * tag 'drm-next-2019-07-16' of git://anongit.freedesktop.org/drm/drm: (1815 commits)
      Revert "Merge branch 'vmwgfx-next' of git://people.freedesktop.org/~thomash/linux into drm-next"
      Revert "mm: adjust apply_to_pfn_range interface for dropped token."
      mm: adjust apply_to_pfn_range interface for dropped token.
      drm/amdgpu/navi10: add uclk activity sensor
      drm/amdgpu: properly guard the generic discovery code
      drm/amdgpu: add missing documentation on new module parameters
      drm/amdgpu: don't invalidate caches in RELEASE_MEM, only do the writeback
      drm/amd/display: avoid 64-bit division
      drm/amdgpu/psp11: simplify the ucode register logic
      drm/amdgpu: properly guard DC support in navi code
      drm/amd/powerplay: vega20: fix uninitialized variable use
      drm/amd/display: dcn20: include linux/delay.h
      amdgpu: make pmu support optional
      drm/amd/powerplay: Zero initialize current_rpm in vega20_get_fan_speed_percent
      drm/amd/powerplay: Zero initialize freq in smu_v11_0_get_current_clk_freq
      drm/amd/powerplay: Use memset to initialize metrics structs
      drm/amdgpu/mes10.1: Fix header guard
      drm/amd/powerplay: add temperature sensor support for navi10
      drm/amdgpu: fix scheduler timeout calc
      drm/amdgpu: Prepare for hmm_range_register API change (v2)
      ...

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 58725f890b5b..9b84114f74ce 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Header file for dma buffer sharing framework.
  *
@@ -8,18 +9,6 @@
  * Arnd Bergmann <arnd@arndb.de>, Rob Clark <rob@ti.com> and
  * Daniel Vetter <daniel@ffwll.ch> for their support in creation and
  * refining of this idea.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 as published by
- * the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
- * more details.
- *
- * You should have received a copy of the GNU General Public License along with
- * this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #ifndef __DMA_BUF_H__
 #define __DMA_BUF_H__

commit bb2bb903042517b8fb17b2bc21e00512f2dcac01
Author: Greg Hackmann <ghackmann@google.com>
Date:   Thu Jun 13 15:34:07 2019 -0700

    dma-buf: add DMA_BUF_SET_NAME ioctls
    
    This patch adds complimentary DMA_BUF_SET_NAME  ioctls, which lets
    userspace processes attach a free-form name to each buffer.
    
    This information can be extremely helpful for tracking and accounting
    shared buffers.  For example, on Android, we know what each buffer will
    be used for at allocation time: GL, multimedia, camera, etc.  The
    userspace allocator can use DMA_BUF_SET_NAME to associate that
    information with the buffer, so we can later give developers a
    breakdown of how much memory they're allocating for graphics, camera,
    etc.
    
    Signed-off-by: Greg Hackmann <ghackmann@google.com>
    Signed-off-by: Chenbo Feng <fengc@google.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190613223408.139221-3-fengc@google.com

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 8a327566d7f4..01ad5b942a6f 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -280,10 +280,12 @@ struct dma_buf_ops {
  * @file: file pointer used for sharing buffers across, and for refcounting.
  * @attachments: list of dma_buf_attachment that denotes all devices attached.
  * @ops: dma_buf_ops associated with this buffer object.
- * @lock: used internally to serialize list manipulation, attach/detach and vmap/unmap
+ * @lock: used internally to serialize list manipulation, attach/detach and
+ *        vmap/unmap, and accesses to name
  * @vmapping_counter: used internally to refcnt the vmaps
  * @vmap_ptr: the current vmap ptr if vmapping_counter > 0
  * @exp_name: name of the exporter; useful for debugging.
+ * @name: userspace-provided name; useful for accounting and debugging.
  * @owner: pointer to exporter module; used for refcounting when exporter is a
  *         kernel module.
  * @list_node: node for dma_buf accounting and debugging.
@@ -311,6 +313,7 @@ struct dma_buf {
 	unsigned vmapping_counter;
 	void *vmap_ptr;
 	const char *exp_name;
+	const char *name;
 	struct module *owner;
 	struct list_head list_node;
 	void *priv;

commit f13e143e7444bffc53f5c2904aeed76646da69d6
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Tue Jul 3 16:42:26 2018 +0200

    dma-buf: start caching of sg_table objects v2
    
    To allow a smooth transition from pinning buffer objects to dynamic
    invalidation we first start to cache the sg_table for an attachment.
    
    v2: keep closer to the DRM implementation
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.kernel.org/patch/10943053/

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index a0bd071466fc..8a327566d7f4 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -44,6 +44,15 @@ struct dma_buf_attachment;
  * @vunmap: [optional] unmaps a vmap from the buffer
  */
 struct dma_buf_ops {
+	/**
+	  * @cache_sgt_mapping:
+	  *
+	  * If true the framework will cache the first mapping made for each
+	  * attachment. This avoids creating mappings for attachments multiple
+	  * times.
+	  */
+	bool cache_sgt_mapping;
+
 	/**
 	 * @attach:
 	 *
@@ -323,6 +332,8 @@ struct dma_buf {
  * @dmabuf: buffer for this attachment.
  * @dev: device attached to the buffer.
  * @node: list of dma_buf_attachment.
+ * @sgt: cached mapping.
+ * @dir: direction of cached mapping.
  * @priv: exporter specific attachment data.
  *
  * This structure holds the attachment information between the dma_buf buffer
@@ -338,6 +349,8 @@ struct dma_buf_attachment {
 	struct dma_buf *dmabuf;
 	struct device *dev;
 	struct list_head node;
+	struct sg_table *sgt;
+	enum dma_data_direction dir;
 	void *priv;
 };
 

commit d5ae7712b7ffbb435e8f3d98f2123eff4734c77f
Author: Andrew F. Davis <afd@ti.com>
Date:   Thu Mar 21 15:09:57 2019 -0500

    dma-buf: Update [un]map documentation to match the other functions
    
    Other function have inline documentation, a couple still have
    theirs at the top of the structure, update the docs and move
    them inline.
    
    Signed-off-by: Andrew F. Davis <afd@ti.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190321200957.16938-2-afd@ti.com

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index e4a8dab2bc54..a0bd071466fc 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -39,8 +39,6 @@ struct dma_buf_attachment;
 
 /**
  * struct dma_buf_ops - operations possible on struct dma_buf
- * @map: [optional] maps a page from the buffer into kernel address space.
- * @unmap: [optional] unmaps a page from the buffer.
  * @vmap: [optional] creates a virtual mapping for the buffer into kernel
  *	  address space. Same restrictions as for vmap and friends apply.
  * @vunmap: [optional] unmaps a vmap from the buffer
@@ -200,8 +198,6 @@ struct dma_buf_ops {
 	 * to be restarted.
 	 */
 	int (*end_cpu_access)(struct dma_buf *, enum dma_data_direction);
-	void *(*map)(struct dma_buf *, unsigned long);
-	void (*unmap)(struct dma_buf *, unsigned long, void *);
 
 	/**
 	 * @mmap:
@@ -240,6 +236,31 @@ struct dma_buf_ops {
 	 */
 	int (*mmap)(struct dma_buf *, struct vm_area_struct *vma);
 
+	/**
+	 * @map:
+	 *
+	 * Maps a page from the buffer into kernel address space. The page is
+	 * specified by offset into the buffer in PAGE_SIZE units.
+	 *
+	 * This callback is optional.
+	 *
+	 * Returns:
+	 *
+	 * Virtual address pointer where requested page can be accessed. NULL
+	 * on error or when this function is unimplemented by the exporter.
+	 */
+	void *(*map)(struct dma_buf *, unsigned long);
+
+	/**
+	 * @unmap:
+	 *
+	 * Unmaps a page from the buffer. Page offset and address pointer should
+	 * be the same as the one passed to and returned by matching call to map.
+	 *
+	 * This callback is optional.
+	 */
+	void (*unmap)(struct dma_buf *, unsigned long, void *);
+
 	void *(*vmap)(struct dma_buf *);
 	void (*vunmap)(struct dma_buf *, void *vaddr);
 };

commit 67b886d290052dbf2bcfc876a5ae41a5fe461edf
Author: Andrew F. Davis <afd@ti.com>
Date:   Thu Mar 21 15:09:56 2019 -0500

    dma-buf: Remove leftover [un]map_atomic comments
    
    The map_atomic/unmap_atomic callbacks have been removed, remove
    the related comments.
    
    Fixes: f664a5269542 ("dma-buf: remove kmap_atomic interface")
    Signed-off-by: Andrew F. Davis <afd@ti.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190321200957.16938-1-afd@ti.com

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 58725f890b5b..e4a8dab2bc54 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -39,11 +39,6 @@ struct dma_buf_attachment;
 
 /**
  * struct dma_buf_ops - operations possible on struct dma_buf
- * @map_atomic: [optional] maps a page from the buffer into kernel address
- *		space, users may not block until the subsequent unmap call.
- *		This callback must not sleep.
- * @unmap_atomic: [optional] unmaps a atomically mapped page from the buffer.
- *		  This Callback must not sleep.
  * @map: [optional] maps a page from the buffer into kernel address space.
  * @unmap: [optional] unmaps a page from the buffer.
  * @vmap: [optional] creates a virtual mapping for the buffer into kernel

commit f664a52695429b68afb4e130a0f69cd5fd1fec86
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Mon May 28 13:34:01 2018 +0200

    dma-buf: remove kmap_atomic interface
    
    Neither used nor correctly implemented anywhere. Just completely remove
    the interface.
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/226645/

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index c0ad5bf61188..58725f890b5b 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -205,8 +205,6 @@ struct dma_buf_ops {
 	 * to be restarted.
 	 */
 	int (*end_cpu_access)(struct dma_buf *, enum dma_data_direction);
-	void *(*map_atomic)(struct dma_buf *, unsigned long);
-	void (*unmap_atomic)(struct dma_buf *, unsigned long, void *);
 	void *(*map)(struct dma_buf *, unsigned long);
 	void (*unmap)(struct dma_buf *, unsigned long, void *);
 
@@ -394,8 +392,6 @@ int dma_buf_begin_cpu_access(struct dma_buf *dma_buf,
 			     enum dma_data_direction dir);
 int dma_buf_end_cpu_access(struct dma_buf *dma_buf,
 			   enum dma_data_direction dir);
-void *dma_buf_kmap_atomic(struct dma_buf *, unsigned long);
-void dma_buf_kunmap_atomic(struct dma_buf *, unsigned long, void *);
 void *dma_buf_kmap(struct dma_buf *, unsigned long);
 void dma_buf_kunmap(struct dma_buf *, unsigned long, void *);
 

commit a19741e5e5a9f1f02f8e3c037bde7d73d4bfae9c
Author: Christian KÃ¶nig <christian.koenig@amd.com>
Date:   Mon May 28 11:47:52 2018 +0200

    dma_buf: remove device parameter from attach callback v2
    
    The device parameter is completely unused because it is available in the
    attachment structure as well.
    
    v2: fix kerneldoc as well
    
    Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/226643/

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 88917fa796e4..c0ad5bf61188 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -55,11 +55,11 @@ struct dma_buf_ops {
 	 * @attach:
 	 *
 	 * This is called from dma_buf_attach() to make sure that a given
-	 * &device can access the provided &dma_buf. Exporters which support
-	 * buffer objects in special locations like VRAM or device-specific
-	 * carveout areas should check whether the buffer could be move to
-	 * system memory (or directly accessed by the provided device), and
-	 * otherwise need to fail the attach operation.
+	 * &dma_buf_attachment.dev can access the provided &dma_buf. Exporters
+	 * which support buffer objects in special locations like VRAM or
+	 * device-specific carveout areas should check whether the buffer could
+	 * be move to system memory (or directly accessed by the provided
+	 * device), and otherwise need to fail the attach operation.
 	 *
 	 * The exporter should also in general check whether the current
 	 * allocation fullfills the DMA constraints of the new device. If this
@@ -77,8 +77,7 @@ struct dma_buf_ops {
 	 * to signal that backing storage is already allocated and incompatible
 	 * with the requirements of requesting device.
 	 */
-	int (*attach)(struct dma_buf *, struct device *,
-		      struct dma_buf_attachment *);
+	int (*attach)(struct dma_buf *, struct dma_buf_attachment *);
 
 	/**
 	 * @detach:

commit 09ea0dfbf972c63dfea8cf46f2fb67f39e4d833b
Author: Gerd Hoffmann <kraxel@redhat.com>
Date:   Tue May 29 15:59:18 2018 +0200

    dma-buf: make map_atomic and map function pointers optional
    
    So drivers don't need dummy functions just returning NULL.
    
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Signed-off-by: Gerd Hoffmann <kraxel@redhat.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Reviewed-by: Oleksandr Andrushchenko <oleksandr_andrushchenko@epam.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20180529135918.19729-1-kraxel@redhat.com

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 085db2fee2d7..88917fa796e4 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -39,12 +39,12 @@ struct dma_buf_attachment;
 
 /**
  * struct dma_buf_ops - operations possible on struct dma_buf
- * @map_atomic: maps a page from the buffer into kernel address
+ * @map_atomic: [optional] maps a page from the buffer into kernel address
  *		space, users may not block until the subsequent unmap call.
  *		This callback must not sleep.
  * @unmap_atomic: [optional] unmaps a atomically mapped page from the buffer.
  *		  This Callback must not sleep.
- * @map: maps a page from the buffer into kernel address space.
+ * @map: [optional] maps a page from the buffer into kernel address space.
  * @unmap: [optional] unmaps a page from the buffer.
  * @vmap: [optional] creates a virtual mapping for the buffer into kernel
  *	  address space. Same restrictions as for vmap and friends apply.

commit 01e5d5562988efdebd6502a7e528d9bd5b8ca200
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 3 23:53:17 2017 -0400

    dmabuf: annotate dma_buf->active
    
    Contains POLL... bitmaps
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 79f27d60ec66..085db2fee2d7 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -301,7 +301,7 @@ struct dma_buf {
 		struct dma_fence_cb cb;
 		wait_queue_head_t *poll;
 
-		unsigned long active;
+		__poll_t active;
 	} cb_excl, cb_shared;
 };
 

commit f9b67f0014cba18f1aabb6fa9272335a043eb6fd
Author: Logan Gunthorpe <logang@deltatee.com>
Date:   Wed Apr 19 13:36:10 2017 -0600

    dma-buf: Rename dma-ops to prevent conflict with kunmap_atomic macro
    
    Seeing the kunmap_atomic dma_buf_ops share the same name with a macro
    in highmem.h, the former can be aliased if any dma-buf user includes
    that header.
    
    I'm personally trying to include highmem.h inside scatterlist.h and this
    breaks the dma-buf code proper.
    
    Christoph Hellwig suggested [1] renaming it and pushing this patch ASAP.
    
    To maintain consistency I've renamed all four of kmap* and kunmap* to be
    map* and unmap*. (Even though only kmap_atomic presently conflicts.)
    
    [1] https://www.spinics.net/lists/target-devel/msg15070.html
    
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Reviewed-by: Sinclair Yeh <syeh@vmware.com>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: http://patchwork.freedesktop.org/patch/msgid/1492630570-879-1-git-send-email-logang@deltatee.com

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index bfb3704fc6fc..79f27d60ec66 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -39,13 +39,13 @@ struct dma_buf_attachment;
 
 /**
  * struct dma_buf_ops - operations possible on struct dma_buf
- * @kmap_atomic: maps a page from the buffer into kernel address
- * 		 space, users may not block until the subsequent unmap call.
- * 		 This callback must not sleep.
- * @kunmap_atomic: [optional] unmaps a atomically mapped page from the buffer.
- * 		   This Callback must not sleep.
- * @kmap: maps a page from the buffer into kernel address space.
- * @kunmap: [optional] unmaps a page from the buffer.
+ * @map_atomic: maps a page from the buffer into kernel address
+ *		space, users may not block until the subsequent unmap call.
+ *		This callback must not sleep.
+ * @unmap_atomic: [optional] unmaps a atomically mapped page from the buffer.
+ *		  This Callback must not sleep.
+ * @map: maps a page from the buffer into kernel address space.
+ * @unmap: [optional] unmaps a page from the buffer.
  * @vmap: [optional] creates a virtual mapping for the buffer into kernel
  *	  address space. Same restrictions as for vmap and friends apply.
  * @vunmap: [optional] unmaps a vmap from the buffer
@@ -206,10 +206,10 @@ struct dma_buf_ops {
 	 * to be restarted.
 	 */
 	int (*end_cpu_access)(struct dma_buf *, enum dma_data_direction);
-	void *(*kmap_atomic)(struct dma_buf *, unsigned long);
-	void (*kunmap_atomic)(struct dma_buf *, unsigned long, void *);
-	void *(*kmap)(struct dma_buf *, unsigned long);
-	void (*kunmap)(struct dma_buf *, unsigned long, void *);
+	void *(*map_atomic)(struct dma_buf *, unsigned long);
+	void (*unmap_atomic)(struct dma_buf *, unsigned long, void *);
+	void *(*map)(struct dma_buf *, unsigned long);
+	void (*unmap)(struct dma_buf *, unsigned long, void *);
 
 	/**
 	 * @mmap:

commit e9b4d7b56f293ed4de9ff7d16759d33492f83180
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Thu Dec 29 21:48:25 2016 +0100

    dma-buf: Use recommended structure member reference
    
    I just learned that &struct_name.member_name works and looks pretty
    even. It doesn't (yet) link to the member directly though, which would
    be really good for big structures or vfunc tables (where the
    per-member kerneldoc tends to be long).
    
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Jani Nikula <jani.nikula@linux.intel.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Reviewed-by: David Herrmann <dh.herrmann@gmail.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/1483044517-5770-5-git-send-email-daniel.vetter@ffwll.ch

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 4d61fc55278b..bfb3704fc6fc 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -66,8 +66,8 @@ struct dma_buf_ops {
 	 * is not the case, and the allocation cannot be moved, it should also
 	 * fail the attach operation.
 	 *
-	 * Any exporter-private housekeeping data can be stored in the priv
-	 * pointer of &dma_buf_attachment structure.
+	 * Any exporter-private housekeeping data can be stored in the
+	 * &dma_buf_attachment.priv pointer.
 	 *
 	 * This callback is optional.
 	 *
@@ -106,7 +106,7 @@ struct dma_buf_ops {
 	 *
 	 * Note that any specific buffer attributes required for this function
 	 * should get added to device_dma_parameters accessible via
-	 * device->dma_params from the &dma_buf_attachment. The @attach callback
+	 * &device.dma_params from the &dma_buf_attachment. The @attach callback
 	 * should also check these constraints.
 	 *
 	 * If this is being called for the first time, the exporter can now

commit f641d3b536e559dd2bae9245ec2e7d86cdf623fd
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Thu Dec 29 21:48:24 2016 +0100

    dma-buf: use preferred struct reference in kernel-doc
    
    sed -e 's/\( \* .*\)struct &\([_a-z]*\)/\1\&struct \2/' -i
    
    Originally I wasnt a friend of this style because I thought a
    line-break between the "&struct" and "foo" part would break it. But a
    quick test shows that " * &struct \n * foo\n" works pefectly well with
    current kernel-doc. So time to mass-apply these changes!
    
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Jani Nikula <jani.nikula@linux.intel.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Reviewed-by: David Herrmann <dh.herrmann@gmail.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/1483044517-5770-4-git-send-email-daniel.vetter@ffwll.ch

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 57828154e440..4d61fc55278b 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -278,7 +278,7 @@ struct dma_buf_ops {
  * Shared dma buffers are reference counted using dma_buf_put() and
  * get_dma_buf().
  *
- * Device DMA access is handled by the separate struct &dma_buf_attachment.
+ * Device DMA access is handled by the separate &struct dma_buf_attachment.
  */
 struct dma_buf {
 	size_t size;
@@ -355,7 +355,7 @@ struct dma_buf_export_info {
  * DEFINE_DMA_BUF_EXPORT_INFO - helper macro for exporters
  * @name: export-info name
  *
- * DEFINE_DMA_BUF_EXPORT_INFO macro defines the struct &dma_buf_export_info,
+ * DEFINE_DMA_BUF_EXPORT_INFO macro defines the &struct dma_buf_export_info,
  * zeroes it out and pre-populates exp_name in it.
  */
 #define DEFINE_DMA_BUF_EXPORT_INFO(name)	\

commit 0959a1683d78270bab6381d498707fb8655ae11c
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Dec 9 19:53:08 2016 +0100

    dma-buf: Update cpu access documentation
    
    - Again move the information relevant for driver writers next to the
      callbacks.
    - Put the overview and userspace interface documentation into a DOC:
      section within the code.
    - Remove the text that mmap needs to be coherent - since the
      DMA_BUF_IOCTL_SYNC landed that's no longer the case. But keep the text
      that for pte zapping exporters need to adjust the address space.
    - Add a FIXME that kmap and the new begin/end stuff used by the SYNC
      ioctl don't really mix correctly. That's something I just realized
      while doing this doc rework.
    - Augment function and structure docs like usual.
    
    Cc: linux-doc@vger.kernel.org
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
      [sumits: fix cosmetic issues]
    Link: http://patchwork.freedesktop.org/patch/msgid/20161209185309.1682-5-daniel.vetter@ffwll.ch

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 6df170fb243f..57828154e440 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -39,10 +39,6 @@ struct dma_buf_attachment;
 
 /**
  * struct dma_buf_ops - operations possible on struct dma_buf
- * @begin_cpu_access: [optional] called before cpu access to invalidate cpu
- * 		      caches and allocate backing storage (if not yet done)
- * 		      respectively pin the object into memory.
- * @end_cpu_access: [optional] called after cpu access to flush caches.
  * @kmap_atomic: maps a page from the buffer into kernel address
  * 		 space, users may not block until the subsequent unmap call.
  * 		 This callback must not sleep.
@@ -50,10 +46,6 @@ struct dma_buf_attachment;
  * 		   This Callback must not sleep.
  * @kmap: maps a page from the buffer into kernel address space.
  * @kunmap: [optional] unmaps a page from the buffer.
- * @mmap: used to expose the backing storage to userspace. Note that the
- * 	  mapping needs to be coherent - if the exporter doesn't directly
- * 	  support this, it needs to fake coherency by shooting down any ptes
- * 	  when transitioning away from the cpu domain.
  * @vmap: [optional] creates a virtual mapping for the buffer into kernel
  *	  address space. Same restrictions as for vmap and friends apply.
  * @vunmap: [optional] unmaps a vmap from the buffer
@@ -164,13 +156,96 @@ struct dma_buf_ops {
 	 */
 	void (*release)(struct dma_buf *);
 
+	/**
+	 * @begin_cpu_access:
+	 *
+	 * This is called from dma_buf_begin_cpu_access() and allows the
+	 * exporter to ensure that the memory is actually available for cpu
+	 * access - the exporter might need to allocate or swap-in and pin the
+	 * backing storage. The exporter also needs to ensure that cpu access is
+	 * coherent for the access direction. The direction can be used by the
+	 * exporter to optimize the cache flushing, i.e. access with a different
+	 * direction (read instead of write) might return stale or even bogus
+	 * data (e.g. when the exporter needs to copy the data to temporary
+	 * storage).
+	 *
+	 * This callback is optional.
+	 *
+	 * FIXME: This is both called through the DMA_BUF_IOCTL_SYNC command
+	 * from userspace (where storage shouldn't be pinned to avoid handing
+	 * de-factor mlock rights to userspace) and for the kernel-internal
+	 * users of the various kmap interfaces, where the backing storage must
+	 * be pinned to guarantee that the atomic kmap calls can succeed. Since
+	 * there's no in-kernel users of the kmap interfaces yet this isn't a
+	 * real problem.
+	 *
+	 * Returns:
+	 *
+	 * 0 on success or a negative error code on failure. This can for
+	 * example fail when the backing storage can't be allocated. Can also
+	 * return -ERESTARTSYS or -EINTR when the call has been interrupted and
+	 * needs to be restarted.
+	 */
 	int (*begin_cpu_access)(struct dma_buf *, enum dma_data_direction);
+
+	/**
+	 * @end_cpu_access:
+	 *
+	 * This is called from dma_buf_end_cpu_access() when the importer is
+	 * done accessing the CPU. The exporter can use this to flush caches and
+	 * unpin any resources pinned in @begin_cpu_access.
+	 * The result of any dma_buf kmap calls after end_cpu_access is
+	 * undefined.
+	 *
+	 * This callback is optional.
+	 *
+	 * Returns:
+	 *
+	 * 0 on success or a negative error code on failure. Can return
+	 * -ERESTARTSYS or -EINTR when the call has been interrupted and needs
+	 * to be restarted.
+	 */
 	int (*end_cpu_access)(struct dma_buf *, enum dma_data_direction);
 	void *(*kmap_atomic)(struct dma_buf *, unsigned long);
 	void (*kunmap_atomic)(struct dma_buf *, unsigned long, void *);
 	void *(*kmap)(struct dma_buf *, unsigned long);
 	void (*kunmap)(struct dma_buf *, unsigned long, void *);
 
+	/**
+	 * @mmap:
+	 *
+	 * This callback is used by the dma_buf_mmap() function
+	 *
+	 * Note that the mapping needs to be incoherent, userspace is expected
+	 * to braket CPU access using the DMA_BUF_IOCTL_SYNC interface.
+	 *
+	 * Because dma-buf buffers have invariant size over their lifetime, the
+	 * dma-buf core checks whether a vma is too large and rejects such
+	 * mappings. The exporter hence does not need to duplicate this check.
+	 * Drivers do not need to check this themselves.
+	 *
+	 * If an exporter needs to manually flush caches and hence needs to fake
+	 * coherency for mmap support, it needs to be able to zap all the ptes
+	 * pointing at the backing storage. Now linux mm needs a struct
+	 * address_space associated with the struct file stored in vma->vm_file
+	 * to do that with the function unmap_mapping_range. But the dma_buf
+	 * framework only backs every dma_buf fd with the anon_file struct file,
+	 * i.e. all dma_bufs share the same file.
+	 *
+	 * Hence exporters need to setup their own file (and address_space)
+	 * association by setting vma->vm_file and adjusting vma->vm_pgoff in
+	 * the dma_buf mmap callback. In the specific case of a gem driver the
+	 * exporter could use the shmem file already provided by gem (and set
+	 * vm_pgoff = 0). Exporters can then zap ptes by unmapping the
+	 * corresponding range of the struct address_space associated with their
+	 * own file.
+	 *
+	 * This callback is optional.
+	 *
+	 * Returns:
+	 *
+	 * 0 on success or a negative error code on failure.
+	 */
 	int (*mmap)(struct dma_buf *, struct vm_area_struct *vma);
 
 	void *(*vmap)(struct dma_buf *);

commit 2904a8c1311f02896635fd35744262413a0b2726
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Dec 9 19:53:07 2016 +0100

    dma-buf: Reorganize device dma access docs
    
    - Put the initial overview for dma-buf into dma-buf.rst.
    - Put all the comments about detailed semantics into the right
      kernel-doc comment for functions or ops structure member.
    - To allow that detail, switch the reworked kerneldoc to inline style
      for dma_buf_ops.
    - Tie everything together into a much more streamlined overview
      comment, relying on the hyperlinks for all the details.
    - Also sprinkle some links into the kerneldoc for dma_buf and
      dma_buf_attachment to tie it all together.
    
    Cc: linux-doc@vger.kernel.org
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: http://patchwork.freedesktop.org/patch/msgid/20161209185309.1682-4-daniel.vetter@ffwll.ch

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 8daeb3ce0016..6df170fb243f 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -39,19 +39,6 @@ struct dma_buf_attachment;
 
 /**
  * struct dma_buf_ops - operations possible on struct dma_buf
- * @attach: [optional] allows different devices to 'attach' themselves to the
- *	    given buffer. It might return -EBUSY to signal that backing storage
- *	    is already allocated and incompatible with the requirements
- *	    of requesting device.
- * @detach: [optional] detach a given device from this buffer.
- * @map_dma_buf: returns list of scatter pages allocated, increases usecount
- *		 of the buffer. Requires atleast one attach to be called
- *		 before. Returned sg list should already be mapped into
- *		 _device_ address space. This call may sleep. May also return
- *		 -EINTR. Should return -EINVAL if attach hasn't been called yet.
- * @unmap_dma_buf: decreases usecount of buffer, might deallocate scatter
- *		   pages.
- * @release: release this buffer; to be called after the last dma_buf_put.
  * @begin_cpu_access: [optional] called before cpu access to invalidate cpu
  * 		      caches and allocate backing storage (if not yet done)
  * 		      respectively pin the object into memory.
@@ -72,25 +59,109 @@ struct dma_buf_attachment;
  * @vunmap: [optional] unmaps a vmap from the buffer
  */
 struct dma_buf_ops {
+	/**
+	 * @attach:
+	 *
+	 * This is called from dma_buf_attach() to make sure that a given
+	 * &device can access the provided &dma_buf. Exporters which support
+	 * buffer objects in special locations like VRAM or device-specific
+	 * carveout areas should check whether the buffer could be move to
+	 * system memory (or directly accessed by the provided device), and
+	 * otherwise need to fail the attach operation.
+	 *
+	 * The exporter should also in general check whether the current
+	 * allocation fullfills the DMA constraints of the new device. If this
+	 * is not the case, and the allocation cannot be moved, it should also
+	 * fail the attach operation.
+	 *
+	 * Any exporter-private housekeeping data can be stored in the priv
+	 * pointer of &dma_buf_attachment structure.
+	 *
+	 * This callback is optional.
+	 *
+	 * Returns:
+	 *
+	 * 0 on success, negative error code on failure. It might return -EBUSY
+	 * to signal that backing storage is already allocated and incompatible
+	 * with the requirements of requesting device.
+	 */
 	int (*attach)(struct dma_buf *, struct device *,
-			struct dma_buf_attachment *);
+		      struct dma_buf_attachment *);
 
+	/**
+	 * @detach:
+	 *
+	 * This is called by dma_buf_detach() to release a &dma_buf_attachment.
+	 * Provided so that exporters can clean up any housekeeping for an
+	 * &dma_buf_attachment.
+	 *
+	 * This callback is optional.
+	 */
 	void (*detach)(struct dma_buf *, struct dma_buf_attachment *);
 
-	/* For {map,unmap}_dma_buf below, any specific buffer attributes
-	 * required should get added to device_dma_parameters accessible
-	 * via dev->dma_params.
+	/**
+	 * @map_dma_buf:
+	 *
+	 * This is called by dma_buf_map_attachment() and is used to map a
+	 * shared &dma_buf into device address space, and it is mandatory. It
+	 * can only be called if @attach has been called successfully. This
+	 * essentially pins the DMA buffer into place, and it cannot be moved
+	 * any more
+	 *
+	 * This call may sleep, e.g. when the backing storage first needs to be
+	 * allocated, or moved to a location suitable for all currently attached
+	 * devices.
+	 *
+	 * Note that any specific buffer attributes required for this function
+	 * should get added to device_dma_parameters accessible via
+	 * device->dma_params from the &dma_buf_attachment. The @attach callback
+	 * should also check these constraints.
+	 *
+	 * If this is being called for the first time, the exporter can now
+	 * choose to scan through the list of attachments for this buffer,
+	 * collate the requirements of the attached devices, and choose an
+	 * appropriate backing storage for the buffer.
+	 *
+	 * Based on enum dma_data_direction, it might be possible to have
+	 * multiple users accessing at the same time (for reading, maybe), or
+	 * any other kind of sharing that the exporter might wish to make
+	 * available to buffer-users.
+	 *
+	 * Returns:
+	 *
+	 * A &sg_table scatter list of or the backing storage of the DMA buffer,
+	 * already mapped into the device address space of the &device attached
+	 * with the provided &dma_buf_attachment.
+	 *
+	 * On failure, returns a negative error value wrapped into a pointer.
+	 * May also return -EINTR when a signal was received while being
+	 * blocked.
 	 */
 	struct sg_table * (*map_dma_buf)(struct dma_buf_attachment *,
-						enum dma_data_direction);
+					 enum dma_data_direction);
+	/**
+	 * @unmap_dma_buf:
+	 *
+	 * This is called by dma_buf_unmap_attachment() and should unmap and
+	 * release the &sg_table allocated in @map_dma_buf, and it is mandatory.
+	 * It should also unpin the backing storage if this is the last mapping
+	 * of the DMA buffer, it the exporter supports backing storage
+	 * migration.
+	 */
 	void (*unmap_dma_buf)(struct dma_buf_attachment *,
-						struct sg_table *,
-						enum dma_data_direction);
+			      struct sg_table *,
+			      enum dma_data_direction);
+
 	/* TODO: Add try_map_dma_buf version, to return immed with -EBUSY
 	 * if the call would block.
 	 */
 
-	/* after final dma_buf_put() */
+	/**
+	 * @release:
+	 *
+	 * Called after the last dma_buf_put to release the &dma_buf, and
+	 * mandatory.
+	 */
 	void (*release)(struct dma_buf *);
 
 	int (*begin_cpu_access)(struct dma_buf *, enum dma_data_direction);
@@ -124,6 +195,15 @@ struct dma_buf_ops {
  * @poll: for userspace poll support
  * @cb_excl: for userspace poll support
  * @cb_shared: for userspace poll support
+ *
+ * This represents a shared buffer, created by calling dma_buf_export(). The
+ * userspace representation is a normal file descriptor, which can be created by
+ * calling dma_buf_fd().
+ *
+ * Shared dma buffers are reference counted using dma_buf_put() and
+ * get_dma_buf().
+ *
+ * Device DMA access is handled by the separate struct &dma_buf_attachment.
  */
 struct dma_buf {
 	size_t size;
@@ -160,6 +240,11 @@ struct dma_buf {
  * This structure holds the attachment information between the dma_buf buffer
  * and its user device(s). The list contains one attachment struct per device
  * attached to the buffer.
+ *
+ * An attachment is created by calling dma_buf_attach(), and released again by
+ * calling dma_buf_detach(). The DMA mapping itself needed to initiate a
+ * transfer is created by dma_buf_map_attachment() and freed again by calling
+ * dma_buf_unmap_attachment().
  */
 struct dma_buf_attachment {
 	struct dma_buf *dmabuf;
@@ -192,9 +277,11 @@ struct dma_buf_export_info {
 };
 
 /**
- * helper macro for exporters; zeros and fills in most common values
- *
+ * DEFINE_DMA_BUF_EXPORT_INFO - helper macro for exporters
  * @name: export-info name
+ *
+ * DEFINE_DMA_BUF_EXPORT_INFO macro defines the struct &dma_buf_export_info,
+ * zeroes it out and pre-populates exp_name in it.
  */
 #define DEFINE_DMA_BUF_EXPORT_INFO(name)	\
 	struct dma_buf_export_info name = { .exp_name = KBUILD_MODNAME, \

commit f54d1867005c3323f5d8ad83eed823e84226c429
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Tue Oct 25 13:00:45 2016 +0100

    dma-buf: Rename struct fence to dma_fence
    
    I plan to usurp the short name of struct fence for a core kernel struct,
    and so I need to rename the specialised fence/timeline for DMA
    operations to make room.
    
    A consensus was reached in
    https://lists.freedesktop.org/archives/dri-devel/2016-July/113083.html
    that making clear this fence applies to DMA operations was a good thing.
    Since then the patch has grown a bit as usage increases, so hopefully it
    remains a good thing!
    
    (v2...: rebase, rerun spatch)
    v3: Compile on msm, spotted a manual fixup that I broke.
    v4: Try again for msm, sorry Daniel
    
    coccinelle script:
    @@
    
    @@
    - struct fence
    + struct dma_fence
    @@
    
    @@
    - struct fence_ops
    + struct dma_fence_ops
    @@
    
    @@
    - struct fence_cb
    + struct dma_fence_cb
    @@
    
    @@
    - struct fence_array
    + struct dma_fence_array
    @@
    
    @@
    - enum fence_flag_bits
    + enum dma_fence_flag_bits
    @@
    
    @@
    (
    - fence_init
    + dma_fence_init
    |
    - fence_release
    + dma_fence_release
    |
    - fence_free
    + dma_fence_free
    |
    - fence_get
    + dma_fence_get
    |
    - fence_get_rcu
    + dma_fence_get_rcu
    |
    - fence_put
    + dma_fence_put
    |
    - fence_signal
    + dma_fence_signal
    |
    - fence_signal_locked
    + dma_fence_signal_locked
    |
    - fence_default_wait
    + dma_fence_default_wait
    |
    - fence_add_callback
    + dma_fence_add_callback
    |
    - fence_remove_callback
    + dma_fence_remove_callback
    |
    - fence_enable_sw_signaling
    + dma_fence_enable_sw_signaling
    |
    - fence_is_signaled_locked
    + dma_fence_is_signaled_locked
    |
    - fence_is_signaled
    + dma_fence_is_signaled
    |
    - fence_is_later
    + dma_fence_is_later
    |
    - fence_later
    + dma_fence_later
    |
    - fence_wait_timeout
    + dma_fence_wait_timeout
    |
    - fence_wait_any_timeout
    + dma_fence_wait_any_timeout
    |
    - fence_wait
    + dma_fence_wait
    |
    - fence_context_alloc
    + dma_fence_context_alloc
    |
    - fence_array_create
    + dma_fence_array_create
    |
    - to_fence_array
    + to_dma_fence_array
    |
    - fence_is_array
    + dma_fence_is_array
    |
    - trace_fence_emit
    + trace_dma_fence_emit
    |
    - FENCE_TRACE
    + DMA_FENCE_TRACE
    |
    - FENCE_WARN
    + DMA_FENCE_WARN
    |
    - FENCE_ERR
    + DMA_FENCE_ERR
    )
     (
     ...
     )
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Reviewed-by: Gustavo Padovan <gustavo.padovan@collabora.co.uk>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Acked-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: http://patchwork.freedesktop.org/patch/msgid/20161025120045.28839-1-chris@chris-wilson.co.uk

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index e0b0741ae671..8daeb3ce0016 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -30,7 +30,7 @@
 #include <linux/list.h>
 #include <linux/dma-mapping.h>
 #include <linux/fs.h>
-#include <linux/fence.h>
+#include <linux/dma-fence.h>
 #include <linux/wait.h>
 
 struct device;
@@ -143,7 +143,7 @@ struct dma_buf {
 	wait_queue_head_t poll;
 
 	struct dma_buf_poll_cb_t {
-		struct fence_cb cb;
+		struct dma_fence_cb cb;
 		wait_queue_head_t *poll;
 
 		unsigned long active;

commit bd3e22088f41a16b4c362622c91243f9f4fd7dcb
Author: Mathias Krause <minipli@googlemail.com>
Date:   Sun Jun 19 14:31:31 2016 +0200

    dma-buf: remove dma_buf_debugfs_create_file()
    
    There is only a single user of dma_buf_debugfs_create_file() and that
    one got the function pointer cast wrong. With that one fixed, there is
    no need to have a wrapper for debugfs_create_file(), just call it
    directly.
    
    With no users left, we can remove dma_buf_debugfs_create_file().
    
    While at it, simplify the error handling in dma_buf_init_debugfs()
    slightly.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: http://patchwork.freedesktop.org/patch/msgid/1466339491-12639-2-git-send-email-minipli@googlemail.com

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 4551c6f2a6c4..e0b0741ae671 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -242,6 +242,4 @@ int dma_buf_mmap(struct dma_buf *, struct vm_area_struct *,
 		 unsigned long);
 void *dma_buf_vmap(struct dma_buf *);
 void dma_buf_vunmap(struct dma_buf *, void *vaddr);
-int dma_buf_debugfs_create_file(const char *name,
-				int (*write)(struct seq_file *));
 #endif /* __DMA_BUF_H__ */

commit e2082e3ab801b989d8d5337b2ecbfc61d09781cb
Author: Rob Clark <robdclark@gmail.com>
Date:   Thu Mar 31 16:26:50 2016 -0400

    dma-buf: headerdoc fixes
    
    Apparently nobody noticed that dma-buf.h wasn't actually pulled into
    docbook build.  And as a result the headerdoc comments bitrot a bit.
    Add missing params/fields.
    
    Signed-off-by: Rob Clark <robdclark@gmail.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 3fe90d494edb..4551c6f2a6c4 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -112,19 +112,24 @@ struct dma_buf_ops {
  * @file: file pointer used for sharing buffers across, and for refcounting.
  * @attachments: list of dma_buf_attachment that denotes all devices attached.
  * @ops: dma_buf_ops associated with this buffer object.
+ * @lock: used internally to serialize list manipulation, attach/detach and vmap/unmap
+ * @vmapping_counter: used internally to refcnt the vmaps
+ * @vmap_ptr: the current vmap ptr if vmapping_counter > 0
  * @exp_name: name of the exporter; useful for debugging.
  * @owner: pointer to exporter module; used for refcounting when exporter is a
  *         kernel module.
  * @list_node: node for dma_buf accounting and debugging.
  * @priv: exporter specific private data for this buffer object.
  * @resv: reservation object linked to this dma-buf
+ * @poll: for userspace poll support
+ * @cb_excl: for userspace poll support
+ * @cb_shared: for userspace poll support
  */
 struct dma_buf {
 	size_t size;
 	struct file *file;
 	struct list_head attachments;
 	const struct dma_buf_ops *ops;
-	/* mutex to serialize list manipulation, attach/detach and vmap/unmap */
 	struct mutex lock;
 	unsigned vmapping_counter;
 	void *vmap_ptr;
@@ -188,9 +193,11 @@ struct dma_buf_export_info {
 
 /**
  * helper macro for exporters; zeros and fills in most common values
+ *
+ * @name: export-info name
  */
-#define DEFINE_DMA_BUF_EXPORT_INFO(a)	\
-	struct dma_buf_export_info a = { .exp_name = KBUILD_MODNAME, \
+#define DEFINE_DMA_BUF_EXPORT_INFO(name)	\
+	struct dma_buf_export_info name = { .exp_name = KBUILD_MODNAME, \
 					 .owner = THIS_MODULE }
 
 /**

commit 18b862dcd57a3e23e34c8cd1e939f68548c1209a
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Fri Mar 18 20:02:39 2016 +0000

    dma-buf, drm, ion: Propagate error code from dma_buf_start_cpu_access()
    
    Drivers, especially i915.ko, can fail during the initial migration of a
    dma-buf for CPU access. However, the error code from the driver was not
    being propagated back to ioctl and so userspace was blissfully ignorant
    of the failure. Rendering corruption ensues.
    
    Whilst fixing the ioctl to return the error code from
    dma_buf_start_cpu_access(), also do the same for
    dma_buf_end_cpu_access().  For most drivers, dma_buf_end_cpu_access()
    cannot fail. i915.ko however, as most drivers would, wants to avoid being
    uninterruptible (as would be required to guarrantee no failure when
    flushing the buffer to the device). As userspace already has to handle
    errors from the SYNC_IOCTL, take advantage of this to be able to restart
    the syscall across signals.
    
    This fixes a coherency issue for i915.ko as well as reducing the
    uninterruptible hold upon its BKL, the struct_mutex.
    
    Fixes commit c11e391da2a8fe973c3c2398452000bed505851e
    Author: Daniel Vetter <daniel.vetter@ffwll.ch>
    Date:   Thu Feb 11 20:04:51 2016 -0200
    
        dma-buf: Add ioctls to allow userspace to flush
    
    Testcase: igt/gem_concurrent_blit/*dmabuf*interruptible
    Testcase: igt/prime_mmap_coherency/ioctl-errors
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Tiago Vignatti <tiago.vignatti@intel.com>
    Cc: StÃ©phane Marchesin <marcheu@chromium.org>
    Cc: David Herrmann <dh.herrmann@gmail.com>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Daniel Vetter <daniel.vetter@intel.com>
    CC: linux-media@vger.kernel.org
    Cc: dri-devel@lists.freedesktop.org
    Cc: linaro-mm-sig@lists.linaro.org
    Cc: intel-gfx@lists.freedesktop.org
    Cc: devel@driverdev.osuosl.org
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: http://patchwork.freedesktop.org/patch/msgid/1458331359-2634-1-git-send-email-chris@chris-wilson.co.uk

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 532108ea0c1c..3fe90d494edb 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -94,7 +94,7 @@ struct dma_buf_ops {
 	void (*release)(struct dma_buf *);
 
 	int (*begin_cpu_access)(struct dma_buf *, enum dma_data_direction);
-	void (*end_cpu_access)(struct dma_buf *, enum dma_data_direction);
+	int (*end_cpu_access)(struct dma_buf *, enum dma_data_direction);
 	void *(*kmap_atomic)(struct dma_buf *, unsigned long);
 	void (*kunmap_atomic)(struct dma_buf *, unsigned long, void *);
 	void *(*kmap)(struct dma_buf *, unsigned long);
@@ -224,8 +224,8 @@ void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *,
 				enum dma_data_direction);
 int dma_buf_begin_cpu_access(struct dma_buf *dma_buf,
 			     enum dma_data_direction dir);
-void dma_buf_end_cpu_access(struct dma_buf *dma_buf,
-			    enum dma_data_direction dir);
+int dma_buf_end_cpu_access(struct dma_buf *dma_buf,
+			   enum dma_data_direction dir);
 void *dma_buf_kmap_atomic(struct dma_buf *, unsigned long);
 void dma_buf_kunmap_atomic(struct dma_buf *, unsigned long, void *);
 void *dma_buf_kmap(struct dma_buf *, unsigned long);

commit 831e9da7dc5c22fd2a5fb64e999f6e077a4338c3
Author: Tiago Vignatti <tiago.vignatti@intel.com>
Date:   Tue Dec 22 19:36:45 2015 -0200

    dma-buf: Remove range-based flush
    
    This patch removes range-based information used for optimizations in
    begin_cpu_access and end_cpu_access.
    
    We don't have any user nor implementation using range-based flush. It seems a
    consensus that if we ever want something like that again (or even more robust
    using 2D, 3D sub-range regions) we can use the upcoming dma-buf sync ioctl for
    such.
    
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Daniel Vetter <daniel.vetter@intel.com>
    Signed-off-by: Tiago Vignatti <tiago.vignatti@intel.com>
    Reviewed-by: StÃ©phane Marchesin <marcheu@chromium.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: http://patchwork.freedesktop.org/patch/msgid/1450820214-12509-3-git-send-email-tiago.vignatti@intel.com

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index f98bd7068d55..532108ea0c1c 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -54,7 +54,7 @@ struct dma_buf_attachment;
  * @release: release this buffer; to be called after the last dma_buf_put.
  * @begin_cpu_access: [optional] called before cpu access to invalidate cpu
  * 		      caches and allocate backing storage (if not yet done)
- * 		      respectively pin the objet into memory.
+ * 		      respectively pin the object into memory.
  * @end_cpu_access: [optional] called after cpu access to flush caches.
  * @kmap_atomic: maps a page from the buffer into kernel address
  * 		 space, users may not block until the subsequent unmap call.
@@ -93,10 +93,8 @@ struct dma_buf_ops {
 	/* after final dma_buf_put() */
 	void (*release)(struct dma_buf *);
 
-	int (*begin_cpu_access)(struct dma_buf *, size_t, size_t,
-				enum dma_data_direction);
-	void (*end_cpu_access)(struct dma_buf *, size_t, size_t,
-			       enum dma_data_direction);
+	int (*begin_cpu_access)(struct dma_buf *, enum dma_data_direction);
+	void (*end_cpu_access)(struct dma_buf *, enum dma_data_direction);
 	void *(*kmap_atomic)(struct dma_buf *, unsigned long);
 	void (*kunmap_atomic)(struct dma_buf *, unsigned long, void *);
 	void *(*kmap)(struct dma_buf *, unsigned long);
@@ -224,9 +222,9 @@ struct sg_table *dma_buf_map_attachment(struct dma_buf_attachment *,
 					enum dma_data_direction);
 void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *,
 				enum dma_data_direction);
-int dma_buf_begin_cpu_access(struct dma_buf *dma_buf, size_t start, size_t len,
+int dma_buf_begin_cpu_access(struct dma_buf *dma_buf,
 			     enum dma_data_direction dir);
-void dma_buf_end_cpu_access(struct dma_buf *dma_buf, size_t start, size_t len,
+void dma_buf_end_cpu_access(struct dma_buf *dma_buf,
 			    enum dma_data_direction dir);
 void *dma_buf_kmap_atomic(struct dma_buf *, unsigned long);
 void dma_buf_kunmap_atomic(struct dma_buf *, unsigned long, void *);

commit 9abdffe286c1532a54d5aee31571d3029be4026c
Author: Sumit Semwal <sumit.semwal@linaro.org>
Date:   Tue May 5 14:56:15 2015 +0530

    dma-buf: add ref counting for module as exporter
    
    Add reference counting on a kernel module that exports dma-buf and
    implements its operations. This prevents the module from being unloaded
    while DMABUF file is in use.
    
    The original patch [1] was submitted by Tomasz Stanislawski, but this
    is a simpler way to do it.
    
    v3: call module_put() as late as possible, per gregkh's comment.
    v2: move owner to struct dma_buf, and use DEFINE_DMA_BUF_EXPORT_INFO
        macro to simplify the change.
    
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    
    [1]: https://lkml.org/lkml/2012/8/8/163

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 2f0b431b73e0..f98bd7068d55 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -115,6 +115,8 @@ struct dma_buf_ops {
  * @attachments: list of dma_buf_attachment that denotes all devices attached.
  * @ops: dma_buf_ops associated with this buffer object.
  * @exp_name: name of the exporter; useful for debugging.
+ * @owner: pointer to exporter module; used for refcounting when exporter is a
+ *         kernel module.
  * @list_node: node for dma_buf accounting and debugging.
  * @priv: exporter specific private data for this buffer object.
  * @resv: reservation object linked to this dma-buf
@@ -129,6 +131,7 @@ struct dma_buf {
 	unsigned vmapping_counter;
 	void *vmap_ptr;
 	const char *exp_name;
+	struct module *owner;
 	struct list_head list_node;
 	void *priv;
 	struct reservation_object *resv;
@@ -164,7 +167,8 @@ struct dma_buf_attachment {
 
 /**
  * struct dma_buf_export_info - holds information needed to export a dma_buf
- * @exp_name:	name of the exporting module - useful for debugging.
+ * @exp_name:	name of the exporter - useful for debugging.
+ * @owner:	pointer to exporter module - used for refcounting kernel module
  * @ops:	Attach allocator-defined dma buf ops to the new buffer
  * @size:	Size of the buffer
  * @flags:	mode flags for the file
@@ -176,6 +180,7 @@ struct dma_buf_attachment {
  */
 struct dma_buf_export_info {
 	const char *exp_name;
+	struct module *owner;
 	const struct dma_buf_ops *ops;
 	size_t size;
 	int flags;
@@ -187,7 +192,8 @@ struct dma_buf_export_info {
  * helper macro for exporters; zeros and fills in most common values
  */
 #define DEFINE_DMA_BUF_EXPORT_INFO(a)	\
-	struct dma_buf_export_info a = { .exp_name = KBUILD_MODNAME }
+	struct dma_buf_export_info a = { .exp_name = KBUILD_MODNAME, \
+					 .owner = THIS_MODULE }
 
 /**
  * get_dma_buf - convenience wrapper for get_file.

commit d8fbe341beb617ebb22b98fb893e4aa32ae2d864
Author: Sumit Semwal <sumit.semwal@linaro.org>
Date:   Fri Jan 23 12:53:43 2015 +0530

    dma-buf: cleanup dma_buf_export() to make it easily extensible
    
    At present, dma_buf_export() takes a series of parameters, which
    makes it difficult to add any new parameters for exporters, if required.
    
    Make it simpler by moving all these parameters into a struct, and pass
    the struct * as parameter to dma_buf_export().
    
    While at it, unite dma_buf_export_named() with dma_buf_export(), and
    change all callers accordingly.
    
    Reviewed-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Daniel Thompson <daniel.thompson@linaro.org>
    Acked-by: Mauro Carvalho Chehab <mchehab@osg.samsung.com>
    Acked-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 694e1fe1c4b4..2f0b431b73e0 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -162,6 +162,33 @@ struct dma_buf_attachment {
 	void *priv;
 };
 
+/**
+ * struct dma_buf_export_info - holds information needed to export a dma_buf
+ * @exp_name:	name of the exporting module - useful for debugging.
+ * @ops:	Attach allocator-defined dma buf ops to the new buffer
+ * @size:	Size of the buffer
+ * @flags:	mode flags for the file
+ * @resv:	reservation-object, NULL to allocate default one
+ * @priv:	Attach private data of allocator to this buffer
+ *
+ * This structure holds the information required to export the buffer. Used
+ * with dma_buf_export() only.
+ */
+struct dma_buf_export_info {
+	const char *exp_name;
+	const struct dma_buf_ops *ops;
+	size_t size;
+	int flags;
+	struct reservation_object *resv;
+	void *priv;
+};
+
+/**
+ * helper macro for exporters; zeros and fills in most common values
+ */
+#define DEFINE_DMA_BUF_EXPORT_INFO(a)	\
+	struct dma_buf_export_info a = { .exp_name = KBUILD_MODNAME }
+
 /**
  * get_dma_buf - convenience wrapper for get_file.
  * @dmabuf:	[in]	pointer to dma_buf
@@ -181,12 +208,7 @@ struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
 void dma_buf_detach(struct dma_buf *dmabuf,
 				struct dma_buf_attachment *dmabuf_attach);
 
-struct dma_buf *dma_buf_export_named(void *priv, const struct dma_buf_ops *ops,
-			       size_t size, int flags, const char *,
-			       struct reservation_object *);
-
-#define dma_buf_export(priv, ops, size, flags, resv)	\
-	dma_buf_export_named(priv, ops, size, flags, KBUILD_MODNAME, resv)
+struct dma_buf *dma_buf_export(const struct dma_buf_export_info *exp_info);
 
 int dma_buf_fd(struct dma_buf *dmabuf, int flags);
 struct dma_buf *dma_buf_get(int fd);

commit 9b495a5887994a6d74d5c261d012083a92b94738
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Tue Jul 1 12:57:43 2014 +0200

    dma-buf: add poll support, v3
    
    Thanks to Fengguang Wu for spotting a missing static cast.
    
    v2:
    - Kill unused variable need_shared.
    v3:
    - Clarify the BUG() in dma_buf_release some more. (Rob Clark)
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Acked-by: Daniel Vetter <daniel@ffwll.ch>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index fd7def2e0ae2..694e1fe1c4b4 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -30,6 +30,8 @@
 #include <linux/list.h>
 #include <linux/dma-mapping.h>
 #include <linux/fs.h>
+#include <linux/fence.h>
+#include <linux/wait.h>
 
 struct device;
 struct dma_buf;
@@ -130,6 +132,16 @@ struct dma_buf {
 	struct list_head list_node;
 	void *priv;
 	struct reservation_object *resv;
+
+	/* poll support */
+	wait_queue_head_t poll;
+
+	struct dma_buf_poll_cb_t {
+		struct fence_cb cb;
+		wait_queue_head_t *poll;
+
+		unsigned long active;
+	} cb_excl, cb_shared;
 };
 
 /**

commit 3aac4502fd3f80dcf7e65dbf6edd8676893c1f46
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Tue Jul 1 12:57:26 2014 +0200

    dma-buf: use reservation objects
    
    This allows reservation objects to be used in dma-buf. it's required
    for implementing polling support on the fences that belong to a dma-buf.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Acked-by: Mauro Carvalho Chehab <m.chehab@samsung.com> #drivers/media/v4l2-core/
    Acked-by: Thomas Hellstrom <thellstrom@vmware.com> #drivers/gpu/drm/ttm
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Acked-by: Daniel Vetter <daniel@ffwll.ch>
    Signed-off-by: Vincent StehlÃ© <vincent.stehle@laposte.net> #drivers/gpu/drm/armada/
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index f886985a28b2..fd7def2e0ae2 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -115,6 +115,7 @@ struct dma_buf_ops {
  * @exp_name: name of the exporter; useful for debugging.
  * @list_node: node for dma_buf accounting and debugging.
  * @priv: exporter specific private data for this buffer object.
+ * @resv: reservation object linked to this dma-buf
  */
 struct dma_buf {
 	size_t size;
@@ -128,6 +129,7 @@ struct dma_buf {
 	const char *exp_name;
 	struct list_head list_node;
 	void *priv;
+	struct reservation_object *resv;
 };
 
 /**
@@ -168,10 +170,11 @@ void dma_buf_detach(struct dma_buf *dmabuf,
 				struct dma_buf_attachment *dmabuf_attach);
 
 struct dma_buf *dma_buf_export_named(void *priv, const struct dma_buf_ops *ops,
-			       size_t size, int flags, const char *);
+			       size_t size, int flags, const char *,
+			       struct reservation_object *);
 
-#define dma_buf_export(priv, ops, size, flags)	\
-	dma_buf_export_named(priv, ops, size, flags, KBUILD_MODNAME)
+#define dma_buf_export(priv, ops, size, flags, resv)	\
+	dma_buf_export_named(priv, ops, size, flags, KBUILD_MODNAME, resv)
 
 int dma_buf_fd(struct dma_buf *dmabuf, int flags);
 struct dma_buf *dma_buf_get(int fd);

commit c0b00a525c127d0055c1df6283300e17f601a1a1
Author: Sumit Semwal <sumit.semwal@linaro.org>
Date:   Mon Feb 3 15:09:12 2014 +0530

    dma-buf: update debugfs output
    
    Russell King observed 'wierd' looking output from debugfs, and also suggested
    better ways of getting device names (use KBUILD_MODNAME, dev_name())
    
    This patch addresses these issues to make the debugfs output correct and better
    looking.
    
    While at it, replace seq_printf with seq_puts to remove the checkpatch.pl
    warnings.
    
    Reported-by: Russell King - ARM Linux <linux@arm.linux.org.uk>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index dfac5ed31120..f886985a28b2 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -171,7 +171,7 @@ struct dma_buf *dma_buf_export_named(void *priv, const struct dma_buf_ops *ops,
 			       size_t size, int flags, const char *);
 
 #define dma_buf_export(priv, ops, size, flags)	\
-	dma_buf_export_named(priv, ops, size, flags, __FILE__)
+	dma_buf_export_named(priv, ops, size, flags, KBUILD_MODNAME)
 
 int dma_buf_fd(struct dma_buf *dmabuf, int flags);
 struct dma_buf *dma_buf_get(int fd);

commit b89e35636bc75b72d15a1af6d49798802aff77d5
Author: Sumit Semwal <sumit.semwal@linaro.org>
Date:   Thu Apr 4 11:44:37 2013 +0530

    dma-buf: Add debugfs support
    
    Add debugfs support to make it easier to print debug information
    about the dma-buf buffers.
    
    Cc: Dave Airlie <airlied@redhat.com>
     [minor fixes on init and warning fix]
    Cc: Dan Carpenter <dan.carpenter@oracle.com>
     [remove double unlock in fail case]
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 6f55c0424f12..dfac5ed31120 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -113,6 +113,7 @@ struct dma_buf_ops {
  * @attachments: list of dma_buf_attachment that denotes all devices attached.
  * @ops: dma_buf_ops associated with this buffer object.
  * @exp_name: name of the exporter; useful for debugging.
+ * @list_node: node for dma_buf accounting and debugging.
  * @priv: exporter specific private data for this buffer object.
  */
 struct dma_buf {
@@ -125,6 +126,7 @@ struct dma_buf {
 	unsigned vmapping_counter;
 	void *vmap_ptr;
 	const char *exp_name;
+	struct list_head list_node;
 	void *priv;
 };
 
@@ -192,5 +194,6 @@ int dma_buf_mmap(struct dma_buf *, struct vm_area_struct *,
 		 unsigned long);
 void *dma_buf_vmap(struct dma_buf *);
 void dma_buf_vunmap(struct dma_buf *, void *vaddr);
-
+int dma_buf_debugfs_create_file(const char *name,
+				int (*write)(struct seq_file *));
 #endif /* __DMA_BUF_H__ */

commit 78df969550e7187f4dcd70b737217dcbc8e9a06a
Author: Sumit Semwal <sumit.semwal@linaro.org>
Date:   Fri Mar 22 18:22:16 2013 +0530

    dma-buf: replace dma_buf_export() with dma_buf_export_named()
    
    For debugging purposes, it is useful to have a name-string added
    while exporting buffers. Hence, dma_buf_export() is replaced with
    dma_buf_export_named(), which additionally takes 'exp_name' as a
    parameter.
    
    For backward compatibility, and for lazy exporters who don't wish to
    name themselves, a #define dma_buf_export() is also made available,
    which adds a __FILE__ instead of 'exp_name'.
    
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
      [Thanks for the idea!]
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 9978b614a1aa..6f55c0424f12 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -112,6 +112,7 @@ struct dma_buf_ops {
  * @file: file pointer used for sharing buffers across, and for refcounting.
  * @attachments: list of dma_buf_attachment that denotes all devices attached.
  * @ops: dma_buf_ops associated with this buffer object.
+ * @exp_name: name of the exporter; useful for debugging.
  * @priv: exporter specific private data for this buffer object.
  */
 struct dma_buf {
@@ -123,6 +124,7 @@ struct dma_buf {
 	struct mutex lock;
 	unsigned vmapping_counter;
 	void *vmap_ptr;
+	const char *exp_name;
 	void *priv;
 };
 
@@ -162,8 +164,13 @@ struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
 							struct device *dev);
 void dma_buf_detach(struct dma_buf *dmabuf,
 				struct dma_buf_attachment *dmabuf_attach);
-struct dma_buf *dma_buf_export(void *priv, const struct dma_buf_ops *ops,
-			       size_t size, int flags);
+
+struct dma_buf *dma_buf_export_named(void *priv, const struct dma_buf_ops *ops,
+			       size_t size, int flags, const char *);
+
+#define dma_buf_export(priv, ops, size, flags)	\
+	dma_buf_export_named(priv, ops, size, flags, __FILE__)
+
 int dma_buf_fd(struct dma_buf *dmabuf, int flags);
 struct dma_buf *dma_buf_get(int fd);
 void dma_buf_put(struct dma_buf *dmabuf);

commit f00b4dad9d9eb001a04cf72e8351a2a1b9e99322
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Thu Dec 20 14:14:23 2012 +0100

    dma-buf: implement vmap refcounting in the interface logic
    
    All drivers which implement this need to have some sort of refcount to
    allow concurrent vmap usage. Hence implement this in the dma-buf core.
    
    To protect against concurrent calls we need a lock, which potentially
    causes new funny locking inversions. But this shouldn't be a problem
    for exporters with statically allocated backing storage, and more
    dynamic drivers have decent issues already anyway.
    
    Inspired by some refactoring patches from Aaron Plattner, who
    implemented the same idea, but only for drm/prime drivers.
    
    v2: Check in dma_buf_release that no dangling vmaps are left.
    Suggested by Aaron Plattner. We might want to do similar checks for
    attachments, but that's for another patch. Also fix up ERR_PTR return
    for vmap.
    
    v3: Check whether the passed-in vmap address matches with the cached
    one for vunmap. Eventually we might want to remove that parameter -
    compared to the kmap functions there's no need for the vaddr for
    unmapping.  Suggested by Chris Wilson.
    
    v4: Fix a brown-paper-bag bug spotted by Aaron Plattner.
    
    Cc: Aaron Plattner <aplattner@nvidia.com>
    Reviewed-by: Aaron Plattner <aplattner@nvidia.com>
    Tested-by: Aaron Plattner <aplattner@nvidia.com>
    Reviewed-by: Rob Clark <rob@ti.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 3d754a394e92..9978b614a1aa 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -119,8 +119,10 @@ struct dma_buf {
 	struct file *file;
 	struct list_head attachments;
 	const struct dma_buf_ops *ops;
-	/* mutex to serialize list manipulation and attach/detach */
+	/* mutex to serialize list manipulation, attach/detach and vmap/unmap */
 	struct mutex lock;
+	unsigned vmapping_counter;
+	void *vmap_ptr;
 	void *priv;
 };
 

commit 617677295b53a40d0e54aac4cbbc216ffbc755dd
Merge: 5c8d1b68e01a 6abb7c25775b
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Tue Jan 29 10:48:30 2013 +0100

    Merge branch 'master' into for-next
    
    Conflicts:
            drivers/devfreq/exynos4_bus.c
    
    Sync with Linus' tree to be able to apply patches that are
    against newer code (mvneta).

commit 8a168ca7074b463d0e19a9e9c15946db1afbddc4
Author: Masanari Iida <standby24x7@gmail.com>
Date:   Sat Dec 29 02:00:09 2012 +0900

    treewide: Fix typo in various drivers
    
    Correct spelling typo in printk within various drivers.
    
    Signed-off-by: Masanari Iida <standby24x7@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index eb48f3816df9..139e673a44f8 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -53,7 +53,7 @@ struct dma_buf_attachment;
  * @begin_cpu_access: [optional] called before cpu access to invalidate cpu
  * 		      caches and allocate backing storage (if not yet done)
  * 		      respectively pin the objet into memory.
- * @end_cpu_access: [optional] called after cpu access to flush cashes.
+ * @end_cpu_access: [optional] called after cpu access to flush caches.
  * @kmap_atomic: maps a page from the buffer into kernel address
  * 		 space, users may not block until the subsequent unmap call.
  * 		 This callback must not sleep.

commit ada65c74059f8c104f1b467c126205471634c435
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Wed Dec 12 10:23:03 2012 +0100

    dma-buf: remove fallback for !CONFIG_DMA_SHARED_BUFFER
    
    Documentation says that code requiring dma-buf should add it to
    select, so inline fallbacks are not going to be used. A link error
    will make it obvious what went wrong, instead of silently doing
    nothing at runtime.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Reviewed-by: Rob Clark <rob.clark@linaro.org>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index eb48f3816df9..bd2e52ccc4f2 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -156,7 +156,6 @@ static inline void get_dma_buf(struct dma_buf *dmabuf)
 	get_file(dmabuf->file);
 }
 
-#ifdef CONFIG_DMA_SHARED_BUFFER
 struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
 							struct device *dev);
 void dma_buf_detach(struct dma_buf *dmabuf,
@@ -184,103 +183,5 @@ int dma_buf_mmap(struct dma_buf *, struct vm_area_struct *,
 		 unsigned long);
 void *dma_buf_vmap(struct dma_buf *);
 void dma_buf_vunmap(struct dma_buf *, void *vaddr);
-#else
-
-static inline struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
-							struct device *dev)
-{
-	return ERR_PTR(-ENODEV);
-}
-
-static inline void dma_buf_detach(struct dma_buf *dmabuf,
-				  struct dma_buf_attachment *dmabuf_attach)
-{
-	return;
-}
-
-static inline struct dma_buf *dma_buf_export(void *priv,
-					     const struct dma_buf_ops *ops,
-					     size_t size, int flags)
-{
-	return ERR_PTR(-ENODEV);
-}
-
-static inline int dma_buf_fd(struct dma_buf *dmabuf, int flags)
-{
-	return -ENODEV;
-}
-
-static inline struct dma_buf *dma_buf_get(int fd)
-{
-	return ERR_PTR(-ENODEV);
-}
-
-static inline void dma_buf_put(struct dma_buf *dmabuf)
-{
-	return;
-}
-
-static inline struct sg_table *dma_buf_map_attachment(
-	struct dma_buf_attachment *attach, enum dma_data_direction write)
-{
-	return ERR_PTR(-ENODEV);
-}
-
-static inline void dma_buf_unmap_attachment(struct dma_buf_attachment *attach,
-			struct sg_table *sg, enum dma_data_direction dir)
-{
-	return;
-}
-
-static inline int dma_buf_begin_cpu_access(struct dma_buf *dmabuf,
-					   size_t start, size_t len,
-					   enum dma_data_direction dir)
-{
-	return -ENODEV;
-}
-
-static inline void dma_buf_end_cpu_access(struct dma_buf *dmabuf,
-					  size_t start, size_t len,
-					  enum dma_data_direction dir)
-{
-}
-
-static inline void *dma_buf_kmap_atomic(struct dma_buf *dmabuf,
-					unsigned long pnum)
-{
-	return NULL;
-}
-
-static inline void dma_buf_kunmap_atomic(struct dma_buf *dmabuf,
-					 unsigned long pnum, void *vaddr)
-{
-}
-
-static inline void *dma_buf_kmap(struct dma_buf *dmabuf, unsigned long pnum)
-{
-	return NULL;
-}
-
-static inline void dma_buf_kunmap(struct dma_buf *dmabuf,
-				  unsigned long pnum, void *vaddr)
-{
-}
-
-static inline int dma_buf_mmap(struct dma_buf *dmabuf,
-			       struct vm_area_struct *vma,
-			       unsigned long pgoff)
-{
-	return -ENODEV;
-}
-
-static inline void *dma_buf_vmap(struct dma_buf *dmabuf)
-{
-	return NULL;
-}
-
-static inline void dma_buf_vunmap(struct dma_buf *dmabuf, void *vaddr)
-{
-}
-#endif /* CONFIG_DMA_SHARED_BUFFER */
 
 #endif /* __DMA_BUF_H__ */

commit 12c4727e1d5370270a7df781d2ba0a76e05c1137
Author: Sumit Semwal <sumit.semwal@ti.com>
Date:   Wed May 23 15:27:40 2012 +0530

    dma-buf: minor documentation fixes.
    
    Some minor inline documentation fixes for gaps resulting from new patches.
    
    Signed-off-by: Sumit Semwal <sumit.semwal@ti.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index a02b1ff6488e..eb48f3816df9 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -65,6 +65,9 @@ struct dma_buf_attachment;
  * 	  mapping needs to be coherent - if the exporter doesn't directly
  * 	  support this, it needs to fake coherency by shooting down any ptes
  * 	  when transitioning away from the cpu domain.
+ * @vmap: [optional] creates a virtual mapping for the buffer into kernel
+ *	  address space. Same restrictions as for vmap and friends apply.
+ * @vunmap: [optional] unmaps a vmap from the buffer
  */
 struct dma_buf_ops {
 	int (*attach)(struct dma_buf *, struct device *,

commit 98f86c9e4ae3205e4c85c535691a5d36426360ee
Author: Dave Airlie <airlied@redhat.com>
Date:   Sun May 20 12:33:56 2012 +0530

    dma-buf: add vmap interface
    
    The main requirement I have for this interface is for scanning out
    using the USB gpu devices. Since these devices have to read the
    framebuffer on updates and linearly compress it, using kmaps
    is a major overhead for every update.
    
    v2: fix warn issues pointed out by Sylwester Nawrocki.
    
    v3: fix compile !CONFIG_DMA_SHARED_BUFFER and add _GPL for now
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Reviewed-by: Rob Clark <rob.clark@linaro.org>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 1f78d1594cc7..a02b1ff6488e 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -98,6 +98,9 @@ struct dma_buf_ops {
 	void (*kunmap)(struct dma_buf *, unsigned long, void *);
 
 	int (*mmap)(struct dma_buf *, struct vm_area_struct *vma);
+
+	void *(*vmap)(struct dma_buf *);
+	void (*vunmap)(struct dma_buf *, void *vaddr);
 };
 
 /**
@@ -176,6 +179,8 @@ void dma_buf_kunmap(struct dma_buf *, unsigned long, void *);
 
 int dma_buf_mmap(struct dma_buf *, struct vm_area_struct *,
 		 unsigned long);
+void *dma_buf_vmap(struct dma_buf *);
+void dma_buf_vunmap(struct dma_buf *, void *vaddr);
 #else
 
 static inline struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
@@ -264,6 +269,15 @@ static inline int dma_buf_mmap(struct dma_buf *dmabuf,
 {
 	return -ENODEV;
 }
+
+static inline void *dma_buf_vmap(struct dma_buf *dmabuf)
+{
+	return NULL;
+}
+
+static inline void dma_buf_vunmap(struct dma_buf *dmabuf, void *vaddr)
+{
+}
 #endif /* CONFIG_DMA_SHARED_BUFFER */
 
 #endif /* __DMA_BUF_H__ */

commit 4c78513e457f72d5554a0f6e2eabfad7b98e4f19
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Tue Apr 24 14:38:52 2012 +0530

    dma-buf: mmap support
    
    Compared to Rob Clark's RFC I've ditched the prepare/finish hooks
    and corresponding ioctls on the dma_buf file. The major reason for
    that is that many people seem to be under the impression that this is
    also for synchronization with outstanding asynchronous processsing.
    I'm pretty massively opposed to this because:
    
    - It boils down reinventing a new rather general-purpose userspace
      synchronization interface. If we look at things like futexes, this
      is hard to get right.
    - Furthermore a lot of kernel code has to interact with this
      synchronization primitive. This smells a look like the dri1 hw_lock,
      a horror show I prefer not to reinvent.
    - Even more fun is that multiple different subsystems would interact
      here, so we have plenty of opportunities to create funny deadlock
      scenarios.
    
    I think synchronization is a wholesale different problem from data
    sharing and should be tackled as an orthogonal problem.
    
    Now we could demand that prepare/finish may only ensure cache
    coherency (as Rob intended), but that runs up into the next problem:
    We not only need mmap support to facilitate sw-only processing nodes
    in a pipeline (without jumping through hoops by importing the dma_buf
    into some sw-access only importer), which allows for a nicer
    ION->dma-buf upgrade path for existing Android userspace. We also need
    mmap support for existing importing subsystems to support existing
    userspace libraries. And a loot of these subsystems are expected to
    export coherent userspace mappings.
    
    So prepare/finish can only ever be optional and the exporter /needs/
    to support coherent mappings. Given that mmap access is always
    somewhat fallback-y in nature I've decided to drop this optimization,
    instead of just making it optional. If we demonstrate a clear need for
    this, supported by benchmark results, we can always add it in again
    later as an optional extension.
    
    Other differences compared to Rob's RFC is the above mentioned support
    for mapping a dma-buf through facilities provided by the importer.
    Which results in mmap support no longer being optional.
    
    Note that this dma-buf mmap patch does _not_ support every possible
    insanity an existing subsystem could pull of with mmap: Because it
    does not allow to intercept pagefaults and shoot down ptes importing
    subsystems can't add some magic of their own at these points (e.g. to
    automatically synchronize with outstanding rendering or set up some
    special resources). I've done a cursory read through a few mmap
    implementions of various subsytems and I'm hopeful that we can avoid
    this (and the complexity it'd bring with it).
    
    Additonally I've extended the documentation a bit to explain the hows
    and whys of this mmap extension.
    
    In case we ever want to add support for explicitly cache maneged
    userspace mmap with a prepare/finish ioctl pair, we could specify that
    userspace needs to mmap a different part of the dma_buf, e.g. the
    range starting at dma_buf->size up to dma_buf->size*2. This works
    because the size of a dma_buf is invariant over it's lifetime. The
    exporter would obviously need to fall back to coherent mappings for
    both ranges if a legacy clients maps the coherent range and the
    architecture cannot suppor conflicting caching policies. Also, this
    would obviously be optional and userspace needs to be able to fall
    back to coherent mappings.
    
    v2:
    - Spelling fixes from Rob Clark.
    - Compile fix for !DMA_BUF from Rob Clark.
    - Extend commit message to explain how explicitly cache managed mmap
      support could be added later.
    - Extend the documentation with implementations notes for exporters
      that need to manually fake coherency.
    
    v3:
    - dma_buf pointer initialization goof-up noticed by Rebecca Schultz
      Zavin.
    
    Cc: Rob Clark <rob.clark@linaro.org>
    Cc: Rebecca Schultz Zavin <rebecca@android.com>
    Acked-by: Rob Clark <rob.clark@linaro.org>
    Signed-Off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 3efbfc2145c3..1f78d1594cc7 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -61,6 +61,10 @@ struct dma_buf_attachment;
  * 		   This Callback must not sleep.
  * @kmap: maps a page from the buffer into kernel address space.
  * @kunmap: [optional] unmaps a page from the buffer.
+ * @mmap: used to expose the backing storage to userspace. Note that the
+ * 	  mapping needs to be coherent - if the exporter doesn't directly
+ * 	  support this, it needs to fake coherency by shooting down any ptes
+ * 	  when transitioning away from the cpu domain.
  */
 struct dma_buf_ops {
 	int (*attach)(struct dma_buf *, struct device *,
@@ -92,6 +96,8 @@ struct dma_buf_ops {
 	void (*kunmap_atomic)(struct dma_buf *, unsigned long, void *);
 	void *(*kmap)(struct dma_buf *, unsigned long);
 	void (*kunmap)(struct dma_buf *, unsigned long, void *);
+
+	int (*mmap)(struct dma_buf *, struct vm_area_struct *vma);
 };
 
 /**
@@ -167,6 +173,9 @@ void *dma_buf_kmap_atomic(struct dma_buf *, unsigned long);
 void dma_buf_kunmap_atomic(struct dma_buf *, unsigned long, void *);
 void *dma_buf_kmap(struct dma_buf *, unsigned long);
 void dma_buf_kunmap(struct dma_buf *, unsigned long, void *);
+
+int dma_buf_mmap(struct dma_buf *, struct vm_area_struct *,
+		 unsigned long);
 #else
 
 static inline struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
@@ -248,6 +257,13 @@ static inline void dma_buf_kunmap(struct dma_buf *dmabuf,
 				  unsigned long pnum, void *vaddr)
 {
 }
+
+static inline int dma_buf_mmap(struct dma_buf *dmabuf,
+			       struct vm_area_struct *vma,
+			       unsigned long pgoff)
+{
+	return -ENODEV;
+}
 #endif /* CONFIG_DMA_SHARED_BUFFER */
 
 #endif /* __DMA_BUF_H__ */

commit ed0bb8ea059764c3fc882fb135473afd347335e9
Merge: 47b816ff7d52 3e0b2a1993c0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 28 15:02:41 2012 -0700

    Merge branch 'for-linus-3.4' of git://git.linaro.org/people/sumitsemwal/linux-dma-buf
    
    Pull dma-buf updates from Sumit Semwal:
     "This includes the following key items:
    
       - kernel cpu access support,
       - flag-passing to dma_buf_fd,
       - relevant Documentation updates, and
       - some minor cleanups and fixes.
    
      These changes are needed for the drm prime/dma-buf interface code that
      Dave Airlie plans to submit in this merge window."
    
    * 'for-linus-3.4' of git://git.linaro.org/people/sumitsemwal/linux-dma-buf:
      dma-buf: correct dummy function declarations.
      dma-buf: document fd flags and O_CLOEXEC requirement
      dma_buf: Add documentation for the new cpu access support
      dma-buf: add support for kernel cpu access
      dma-buf: don't hold the mutex around map/unmap calls
      dma-buf: add get_dma_buf()
      dma-buf: pass flags into dma_buf_fd.
      dma-buf: add dma_data_direction to unmap dma_buf_op
      dma-buf: Move code out of mutex-protected section in dma_buf_attach()
      dma-buf: Return error instead of using a goto statement when possible
      dma-buf: Remove unneeded sanity checks
      dma-buf: Constify ops argument to dma_buf_export()

commit 3e0b2a1993c06e646d90d71e163d03869a211a4c
Author: Sumit Semwal <sumit.semwal@ti.com>
Date:   Mon Mar 26 11:29:19 2012 +0530

    dma-buf: correct dummy function declarations.
    
    Dummy functions for the newly added cpu access ops need variable names for
    arguments.
    Also, the introduction of flags in dma_buf_fd  needs to be added to dummy
    functions as well.
    
    Signed-off-by: Sumit Semwal <sumit.semwal@ti.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index ee7ef9990d9a..f141745a13bf 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -188,7 +188,7 @@ static inline struct dma_buf *dma_buf_export(void *priv,
 	return ERR_PTR(-ENODEV);
 }
 
-static inline int dma_buf_fd(struct dma_buf *dmabuf)
+static inline int dma_buf_fd(struct dma_buf *dmabuf, int flags)
 {
 	return -ENODEV;
 }
@@ -215,36 +215,37 @@ static inline void dma_buf_unmap_attachment(struct dma_buf_attachment *attach,
 	return;
 }
 
-static inline int dma_buf_begin_cpu_access(struct dma_buf *,
-					   size_t, size_t,
-					   enum dma_data_direction)
+static inline int dma_buf_begin_cpu_access(struct dma_buf *dmabuf,
+					   size_t start, size_t len,
+					   enum dma_data_direction dir)
 {
 	return -ENODEV;
 }
 
-static inline void dma_buf_end_cpu_access(struct dma_buf *,
-					  size_t, size_t,
-					  enum dma_data_direction)
+static inline void dma_buf_end_cpu_access(struct dma_buf *dmabuf,
+					  size_t start, size_t len,
+					  enum dma_data_direction dir)
 {
 }
 
-static inline void *dma_buf_kmap_atomic(struct dma_buf *, unsigned long)
+static inline void *dma_buf_kmap_atomic(struct dma_buf *dmabuf,
+					unsigned long pnum)
 {
 	return NULL;
 }
 
-static inline void dma_buf_kunmap_atomic(struct dma_buf *, unsigned long,
-					 void *)
+static inline void dma_buf_kunmap_atomic(struct dma_buf *dmabuf,
+					 unsigned long pnum, void *vaddr)
 {
 }
 
-static inline void *dma_buf_kmap(struct dma_buf *, unsigned long)
+static inline void *dma_buf_kmap(struct dma_buf *dmabuf, unsigned long pnum)
 {
 	return NULL;
 }
 
-static inline void dma_buf_kunmap(struct dma_buf *, unsigned long,
-				  void *)
+static inline void dma_buf_kunmap(struct dma_buf *dmabuf,
+				  unsigned long pnum, void *vaddr)
 {
 }
 #endif /* CONFIG_DMA_SHARED_BUFFER */

commit fc13020e086bfedf2afb95c91c026d5af1f80107
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Tue Mar 20 00:02:37 2012 +0100

    dma-buf: add support for kernel cpu access
    
    Big differences to other contenders in the field (like ion) is
    that this also supports highmem, so we have to split up the cpu
    access from the kernel side into a prepare and a kmap step.
    
    Prepare is allowed to fail and should do everything required so that
    the kmap calls can succeed (like swapin/backing storage allocation,
    flushing, ...).
    
    More in-depth explanations will follow in the follow-up documentation
    patch.
    
    Changes in v2:
    
    - Clear up begin_cpu_access confusion noticed by Sumit Semwal.
    - Don't automatically fallback from the _atomic variants to the
      non-atomic variants. The _atomic callbacks are not allowed to
      sleep, so we want exporters to make this decision explicit. The
      function signatures are explicit, so simpler exporters can still
      use the same function for both.
    - Make the unmap functions optional. Simpler exporters with permanent
      mappings don't need to do anything at unmap time.
    
    Changes in v3:
    
    - Adjust the WARN_ON checks for the new ->ops functions as suggested
      by Rob Clark and Sumit Semwal.
    - Rebased on top of latest dma-buf-next git.
    
    Changes in v4:
    
    - Fixup a missing - in a return -EINVAL; statement.
    
    Signed-Off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Rob Clark <rob@ti.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 24e0f4828711..ee7ef9990d9a 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -50,6 +50,17 @@ struct dma_buf_attachment;
  * @unmap_dma_buf: decreases usecount of buffer, might deallocate scatter
  *		   pages.
  * @release: release this buffer; to be called after the last dma_buf_put.
+ * @begin_cpu_access: [optional] called before cpu access to invalidate cpu
+ * 		      caches and allocate backing storage (if not yet done)
+ * 		      respectively pin the objet into memory.
+ * @end_cpu_access: [optional] called after cpu access to flush cashes.
+ * @kmap_atomic: maps a page from the buffer into kernel address
+ * 		 space, users may not block until the subsequent unmap call.
+ * 		 This callback must not sleep.
+ * @kunmap_atomic: [optional] unmaps a atomically mapped page from the buffer.
+ * 		   This Callback must not sleep.
+ * @kmap: maps a page from the buffer into kernel address space.
+ * @kunmap: [optional] unmaps a page from the buffer.
  */
 struct dma_buf_ops {
 	int (*attach)(struct dma_buf *, struct device *,
@@ -73,6 +84,14 @@ struct dma_buf_ops {
 	/* after final dma_buf_put() */
 	void (*release)(struct dma_buf *);
 
+	int (*begin_cpu_access)(struct dma_buf *, size_t, size_t,
+				enum dma_data_direction);
+	void (*end_cpu_access)(struct dma_buf *, size_t, size_t,
+			       enum dma_data_direction);
+	void *(*kmap_atomic)(struct dma_buf *, unsigned long);
+	void (*kunmap_atomic)(struct dma_buf *, unsigned long, void *);
+	void *(*kmap)(struct dma_buf *, unsigned long);
+	void (*kunmap)(struct dma_buf *, unsigned long, void *);
 };
 
 /**
@@ -140,6 +159,14 @@ struct sg_table *dma_buf_map_attachment(struct dma_buf_attachment *,
 					enum dma_data_direction);
 void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *,
 				enum dma_data_direction);
+int dma_buf_begin_cpu_access(struct dma_buf *dma_buf, size_t start, size_t len,
+			     enum dma_data_direction dir);
+void dma_buf_end_cpu_access(struct dma_buf *dma_buf, size_t start, size_t len,
+			    enum dma_data_direction dir);
+void *dma_buf_kmap_atomic(struct dma_buf *, unsigned long);
+void dma_buf_kunmap_atomic(struct dma_buf *, unsigned long, void *);
+void *dma_buf_kmap(struct dma_buf *, unsigned long);
+void dma_buf_kunmap(struct dma_buf *, unsigned long, void *);
 #else
 
 static inline struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
@@ -188,6 +215,38 @@ static inline void dma_buf_unmap_attachment(struct dma_buf_attachment *attach,
 	return;
 }
 
+static inline int dma_buf_begin_cpu_access(struct dma_buf *,
+					   size_t, size_t,
+					   enum dma_data_direction)
+{
+	return -ENODEV;
+}
+
+static inline void dma_buf_end_cpu_access(struct dma_buf *,
+					  size_t, size_t,
+					  enum dma_data_direction)
+{
+}
+
+static inline void *dma_buf_kmap_atomic(struct dma_buf *, unsigned long)
+{
+	return NULL;
+}
+
+static inline void dma_buf_kunmap_atomic(struct dma_buf *, unsigned long,
+					 void *)
+{
+}
+
+static inline void *dma_buf_kmap(struct dma_buf *, unsigned long)
+{
+	return NULL;
+}
+
+static inline void dma_buf_kunmap(struct dma_buf *, unsigned long,
+				  void *)
+{
+}
 #endif /* CONFIG_DMA_SHARED_BUFFER */
 
 #endif /* __DMA_BUF_H__ */

commit 6b607e3a658fee490bdabfdeb739a3eb498b1bff
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Mon Mar 19 00:34:25 2012 +0100

    dma-buf: don't hold the mutex around map/unmap calls
    
    The mutex protects the attachment list and hence needs to be held
    around the callbakc to the exporters (optional) attach/detach
    functions.
    
    Holding the mutex around the map/unmap calls doesn't protect any
    dma_buf state. Exporters need to properly protect any of their own
    state anyway (to protect against calls from their own interfaces).
    So this only makes the locking messier (and lockdep easier to anger).
    
    Therefore let's just drop this.
    
    v2: Rebased on top of latest dma-buf-next git.
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Reviewed-by: Rob Clark <rob.clark@linaro.org>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index bc4203dc6e18..24e0f4828711 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -88,7 +88,7 @@ struct dma_buf {
 	struct file *file;
 	struct list_head attachments;
 	const struct dma_buf_ops *ops;
-	/* mutex to serialize list manipulation and other ops */
+	/* mutex to serialize list manipulation and attach/detach */
 	struct mutex lock;
 	void *priv;
 };

commit f9a24d1ac9cb82baf5ec5efdb6580a9ce0bd5bfc
Author: Rob Clark <rob@ti.com>
Date:   Fri Mar 16 11:04:41 2012 -0500

    dma-buf: add get_dma_buf()
    
    Works in a similar way to get_file(), and is needed in cases such as
    when the exporter needs to also keep a reference to the dmabuf (that
    is later released with a dma_buf_put()), and possibly other similar
    cases.
    
    Signed-off-by: Rob Clark <rob@ti.com>
    Reviewed-by: Dave Airlie <airlied@redhat.com>
    Reviewed-by: Kyungmin Park <kyungmin.park@samsung.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 891457a86b30..bc4203dc6e18 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -30,6 +30,7 @@
 #include <linux/scatterlist.h>
 #include <linux/list.h>
 #include <linux/dma-mapping.h>
+#include <linux/fs.h>
 
 struct dma_buf;
 struct dma_buf_attachment;
@@ -110,6 +111,20 @@ struct dma_buf_attachment {
 	void *priv;
 };
 
+/**
+ * get_dma_buf - convenience wrapper for get_file.
+ * @dmabuf:	[in]	pointer to dma_buf
+ *
+ * Increments the reference count on the dma-buf, needed in case of drivers
+ * that either need to create additional references to the dmabuf on the
+ * kernel side.  For example, an exporter that needs to keep a dmabuf ptr
+ * so that subsequent exports don't create a new dmabuf.
+ */
+static inline void get_dma_buf(struct dma_buf *dmabuf)
+{
+	get_file(dmabuf->file);
+}
+
 #ifdef CONFIG_DMA_SHARED_BUFFER
 struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
 							struct device *dev);

commit 55c1c4ca23d0f2736ef7c219d0fb005323ff8ee0
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Mar 16 10:34:02 2012 +0000

    dma-buf: pass flags into dma_buf_fd.
    
    We need to pass the flags into dma_buf_fd at this point,
    so the flags end up doing the right thing for O_CLOEXEC.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Rob Clark <rob@ti.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index a885b2689b8f..891457a86b30 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -117,7 +117,7 @@ void dma_buf_detach(struct dma_buf *dmabuf,
 				struct dma_buf_attachment *dmabuf_attach);
 struct dma_buf *dma_buf_export(void *priv, const struct dma_buf_ops *ops,
 			       size_t size, int flags);
-int dma_buf_fd(struct dma_buf *dmabuf);
+int dma_buf_fd(struct dma_buf *dmabuf, int flags);
 struct dma_buf *dma_buf_get(int fd);
 void dma_buf_put(struct dma_buf *dmabuf);
 

commit 33ea2dcb39ba50b0b69d1b1dc24702f084b46411
Author: Sumit Semwal <sumit.semwal@ti.com>
Date:   Fri Jan 27 15:09:27 2012 +0530

    dma-buf: add dma_data_direction to unmap dma_buf_op
    
    Some exporters may use DMA map/unmap APIs in dma-buf ops, which require
    enum dma_data_direction for both map and unmap operations.
    
    Thus, the unmap dma_buf_op also needs to have enum dma_data_direction as
    a parameter.
    
    Reported-by: Tomasz Stanislawski <t.stanislaws@samsung.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@ti.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index 86f624141048..a885b2689b8f 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -63,7 +63,8 @@ struct dma_buf_ops {
 	struct sg_table * (*map_dma_buf)(struct dma_buf_attachment *,
 						enum dma_data_direction);
 	void (*unmap_dma_buf)(struct dma_buf_attachment *,
-						struct sg_table *);
+						struct sg_table *,
+						enum dma_data_direction);
 	/* TODO: Add try_map_dma_buf version, to return immed with -EBUSY
 	 * if the call would block.
 	 */
@@ -122,7 +123,8 @@ void dma_buf_put(struct dma_buf *dmabuf);
 
 struct sg_table *dma_buf_map_attachment(struct dma_buf_attachment *,
 					enum dma_data_direction);
-void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *);
+void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *,
+				enum dma_data_direction);
 #else
 
 static inline struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
@@ -166,7 +168,7 @@ static inline struct sg_table *dma_buf_map_attachment(
 }
 
 static inline void dma_buf_unmap_attachment(struct dma_buf_attachment *attach,
-						struct sg_table *sg)
+			struct sg_table *sg, enum dma_data_direction dir)
 {
 	return;
 }

commit 5375764f9408b8ef1fb8d6cd1ed0efd97dce4824
Author: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
Date:   Thu Jan 26 12:27:22 2012 +0100

    dma-buf: Constify ops argument to dma_buf_export()
    
    This allows drivers to make the dma buf operations structure constant.
    
    Signed-off-by: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index f8ac076afa52..86f624141048 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -114,8 +114,8 @@ struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
 							struct device *dev);
 void dma_buf_detach(struct dma_buf *dmabuf,
 				struct dma_buf_attachment *dmabuf_attach);
-struct dma_buf *dma_buf_export(void *priv, struct dma_buf_ops *ops,
-			size_t size, int flags);
+struct dma_buf *dma_buf_export(void *priv, const struct dma_buf_ops *ops,
+			       size_t size, int flags);
 int dma_buf_fd(struct dma_buf *dmabuf);
 struct dma_buf *dma_buf_get(int fd);
 void dma_buf_put(struct dma_buf *dmabuf);
@@ -138,8 +138,8 @@ static inline void dma_buf_detach(struct dma_buf *dmabuf,
 }
 
 static inline struct dma_buf *dma_buf_export(void *priv,
-						struct dma_buf_ops *ops,
-						size_t size, int flags)
+					     const struct dma_buf_ops *ops,
+					     size_t size, int flags)
 {
 	return ERR_PTR(-ENODEV);
 }

commit 313162d0b83836e2f57e51b9b8650fb4b9c396ea
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jan 30 11:46:54 2012 -0500

    device.h: audit and cleanup users in main include dir
    
    The <linux/device.h> header includes a lot of stuff, and
    it in turn gets a lot of use just for the basic "struct device"
    which appears so often.
    
    Clean up the users as follows:
    
    1) For those headers only needing "struct device" as a pointer
    in fcn args, replace the include with exactly that.
    
    2) For headers not really using anything from device.h, simply
    delete the include altogether.
    
    3) For headers relying on getting device.h implicitly before
    being included themselves, now explicitly include device.h
    
    4) For files in which doing #1 or #2 uncovers an implicit
    dependency on some other header, fix by explicitly adding
    the required header(s).
    
    Any C files that were implicitly relying on device.h to be
    present have already been dealt with in advance.
    
    Total removals from #1 and #2: 51.  Total additions coming
    from #3: 9.  Total other implicit dependencies from #4: 7.
    
    As of 3.3-rc1, there were 110, so a net removal of 42 gives
    about a 38% reduction in device.h presence in include/*
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index f8ac076afa52..887dcd487062 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -26,11 +26,11 @@
 
 #include <linux/file.h>
 #include <linux/err.h>
-#include <linux/device.h>
 #include <linux/scatterlist.h>
 #include <linux/list.h>
 #include <linux/dma-mapping.h>
 
+struct device;
 struct dma_buf;
 struct dma_buf_attachment;
 

commit d15bd7ee445d0702ad801fdaece348fdb79e6581
Author: Sumit Semwal <sumit.semwal@ti.com>
Date:   Mon Dec 26 14:53:15 2011 +0530

    dma-buf: Introduce dma buffer sharing mechanism
    
    This is the first step in defining a dma buffer sharing mechanism.
    
    A new buffer object dma_buf is added, with operations and API to allow easy
    sharing of this buffer object across devices.
    
    The framework allows:
    - creation of a buffer object, its association with a file pointer, and
       associated allocator-defined operations on that buffer. This operation is
       called the 'export' operation.
    - different devices to 'attach' themselves to this exported buffer object, to
      facilitate backing storage negotiation, using dma_buf_attach() API.
    - the exported buffer object to be shared with the other entity by asking for
       its 'file-descriptor (fd)', and sharing the fd across.
    - a received fd to get the buffer object back, where it can be accessed using
       the associated exporter-defined operations.
    - the exporter and user to share the scatterlist associated with this buffer
       object using map_dma_buf and unmap_dma_buf operations.
    
    Atleast one 'attach()' call is required to be made prior to calling the
    map_dma_buf() operation.
    
    Couple of building blocks in map_dma_buf() are added to ease introduction
    of sync'ing across exporter and users, and late allocation by the exporter.
    
    For this first version, this framework will work with certain conditions:
    - *ONLY* exporter will be allowed to mmap to userspace (outside of this
       framework - mmap is not a buffer object operation),
    - currently, *ONLY* users that do not need CPU access to the buffer are
       allowed.
    
    More details are there in the documentation patch.
    
    This is based on design suggestions from many people at the mini-summits[1],
    most notably from Arnd Bergmann <arnd@arndb.de>, Rob Clark <rob@ti.com> and
    Daniel Vetter <daniel@ffwll.ch>.
    
    The implementation is inspired from proof-of-concept patch-set from
    Tomasz Stanislawski <t.stanislaws@samsung.com>, who demonstrated buffer sharing
    between two v4l2 devices. [2]
    
    [1]: https://wiki.linaro.org/OfficeofCTO/MemoryManagement
    [2]: http://lwn.net/Articles/454389
    
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Sumit Semwal <sumit.semwal@ti.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Reviewed-by: Dave Airlie <airlied@redhat.com>
    Reviewed-and-Tested-by: Rob Clark <rob.clark@linaro.org>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
new file mode 100644
index 000000000000..f8ac076afa52
--- /dev/null
+++ b/include/linux/dma-buf.h
@@ -0,0 +1,176 @@
+/*
+ * Header file for dma buffer sharing framework.
+ *
+ * Copyright(C) 2011 Linaro Limited. All rights reserved.
+ * Author: Sumit Semwal <sumit.semwal@ti.com>
+ *
+ * Many thanks to linaro-mm-sig list, and specially
+ * Arnd Bergmann <arnd@arndb.de>, Rob Clark <rob@ti.com> and
+ * Daniel Vetter <daniel@ffwll.ch> for their support in creation and
+ * refining of this idea.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#ifndef __DMA_BUF_H__
+#define __DMA_BUF_H__
+
+#include <linux/file.h>
+#include <linux/err.h>
+#include <linux/device.h>
+#include <linux/scatterlist.h>
+#include <linux/list.h>
+#include <linux/dma-mapping.h>
+
+struct dma_buf;
+struct dma_buf_attachment;
+
+/**
+ * struct dma_buf_ops - operations possible on struct dma_buf
+ * @attach: [optional] allows different devices to 'attach' themselves to the
+ *	    given buffer. It might return -EBUSY to signal that backing storage
+ *	    is already allocated and incompatible with the requirements
+ *	    of requesting device.
+ * @detach: [optional] detach a given device from this buffer.
+ * @map_dma_buf: returns list of scatter pages allocated, increases usecount
+ *		 of the buffer. Requires atleast one attach to be called
+ *		 before. Returned sg list should already be mapped into
+ *		 _device_ address space. This call may sleep. May also return
+ *		 -EINTR. Should return -EINVAL if attach hasn't been called yet.
+ * @unmap_dma_buf: decreases usecount of buffer, might deallocate scatter
+ *		   pages.
+ * @release: release this buffer; to be called after the last dma_buf_put.
+ */
+struct dma_buf_ops {
+	int (*attach)(struct dma_buf *, struct device *,
+			struct dma_buf_attachment *);
+
+	void (*detach)(struct dma_buf *, struct dma_buf_attachment *);
+
+	/* For {map,unmap}_dma_buf below, any specific buffer attributes
+	 * required should get added to device_dma_parameters accessible
+	 * via dev->dma_params.
+	 */
+	struct sg_table * (*map_dma_buf)(struct dma_buf_attachment *,
+						enum dma_data_direction);
+	void (*unmap_dma_buf)(struct dma_buf_attachment *,
+						struct sg_table *);
+	/* TODO: Add try_map_dma_buf version, to return immed with -EBUSY
+	 * if the call would block.
+	 */
+
+	/* after final dma_buf_put() */
+	void (*release)(struct dma_buf *);
+
+};
+
+/**
+ * struct dma_buf - shared buffer object
+ * @size: size of the buffer
+ * @file: file pointer used for sharing buffers across, and for refcounting.
+ * @attachments: list of dma_buf_attachment that denotes all devices attached.
+ * @ops: dma_buf_ops associated with this buffer object.
+ * @priv: exporter specific private data for this buffer object.
+ */
+struct dma_buf {
+	size_t size;
+	struct file *file;
+	struct list_head attachments;
+	const struct dma_buf_ops *ops;
+	/* mutex to serialize list manipulation and other ops */
+	struct mutex lock;
+	void *priv;
+};
+
+/**
+ * struct dma_buf_attachment - holds device-buffer attachment data
+ * @dmabuf: buffer for this attachment.
+ * @dev: device attached to the buffer.
+ * @node: list of dma_buf_attachment.
+ * @priv: exporter specific attachment data.
+ *
+ * This structure holds the attachment information between the dma_buf buffer
+ * and its user device(s). The list contains one attachment struct per device
+ * attached to the buffer.
+ */
+struct dma_buf_attachment {
+	struct dma_buf *dmabuf;
+	struct device *dev;
+	struct list_head node;
+	void *priv;
+};
+
+#ifdef CONFIG_DMA_SHARED_BUFFER
+struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
+							struct device *dev);
+void dma_buf_detach(struct dma_buf *dmabuf,
+				struct dma_buf_attachment *dmabuf_attach);
+struct dma_buf *dma_buf_export(void *priv, struct dma_buf_ops *ops,
+			size_t size, int flags);
+int dma_buf_fd(struct dma_buf *dmabuf);
+struct dma_buf *dma_buf_get(int fd);
+void dma_buf_put(struct dma_buf *dmabuf);
+
+struct sg_table *dma_buf_map_attachment(struct dma_buf_attachment *,
+					enum dma_data_direction);
+void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *);
+#else
+
+static inline struct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,
+							struct device *dev)
+{
+	return ERR_PTR(-ENODEV);
+}
+
+static inline void dma_buf_detach(struct dma_buf *dmabuf,
+				  struct dma_buf_attachment *dmabuf_attach)
+{
+	return;
+}
+
+static inline struct dma_buf *dma_buf_export(void *priv,
+						struct dma_buf_ops *ops,
+						size_t size, int flags)
+{
+	return ERR_PTR(-ENODEV);
+}
+
+static inline int dma_buf_fd(struct dma_buf *dmabuf)
+{
+	return -ENODEV;
+}
+
+static inline struct dma_buf *dma_buf_get(int fd)
+{
+	return ERR_PTR(-ENODEV);
+}
+
+static inline void dma_buf_put(struct dma_buf *dmabuf)
+{
+	return;
+}
+
+static inline struct sg_table *dma_buf_map_attachment(
+	struct dma_buf_attachment *attach, enum dma_data_direction write)
+{
+	return ERR_PTR(-ENODEV);
+}
+
+static inline void dma_buf_unmap_attachment(struct dma_buf_attachment *attach,
+						struct sg_table *sg)
+{
+	return;
+}
+
+#endif /* CONFIG_DMA_SHARED_BUFFER */
+
+#endif /* __DMA_BUF_H__ */
