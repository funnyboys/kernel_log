commit b99328a60a482108f5195b4d611f90992ca016ba
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 22 13:00:15 2019 +0200

    timekeeping/vsyscall: Prevent math overflow in BOOTTIME update
    
    The VDSO update for CLOCK_BOOTTIME has a overflow issue as it shifts the
    nanoseconds based boot time offset left by the clocksource shift. That
    overflows once the boot time offset becomes large enough. As a consequence
    CLOCK_BOOTTIME in the VDSO becomes a random number causing applications to
    misbehave.
    
    Fix it by storing a timespec64 representation of the offset when boot time
    is adjusted and add that to the MONOTONIC base time value in the vdso data
    page. Using the timespec64 representation avoids a 64bit division in the
    update code.
    
    Fixes: 44f57d788e7d ("timekeeping: Provide a generic update_vsyscall() implementation")
    Reported-by: Chris Clayton <chris2553@googlemail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Chris Clayton <chris2553@googlemail.com>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1908221257580.1983@nanos.tec.linutronix.de

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 7acb953298a7..84ff2844df2a 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -57,6 +57,7 @@ struct tk_read_base {
  * @cs_was_changed_seq:	The sequence number of clocksource change events
  * @next_leap_ktime:	CLOCK_MONOTONIC time value of a pending leap-second
  * @raw_sec:		CLOCK_MONOTONIC_RAW  time in seconds
+ * @monotonic_to_boot:	CLOCK_MONOTONIC to CLOCK_BOOTTIME offset
  * @cycle_interval:	Number of clock cycles in one NTP interval
  * @xtime_interval:	Number of clock shifted nano seconds in one NTP
  *			interval.
@@ -84,6 +85,9 @@ struct tk_read_base {
  *
  * wall_to_monotonic is no longer the boot time, getboottime must be
  * used instead.
+ *
+ * @monotonic_to_boottime is a timespec64 representation of @offs_boot to
+ * accelerate the VDSO update for CLOCK_BOOTTIME.
  */
 struct timekeeper {
 	struct tk_read_base	tkr_mono;
@@ -99,6 +103,7 @@ struct timekeeper {
 	u8			cs_was_changed_seq;
 	ktime_t			next_leap_ktime;
 	u64			raw_sec;
+	struct timespec64	monotonic_to_boot;
 
 	/* The following members are for timekeeping internal use */
 	u64			cycle_interval;

commit a3ed0e4393d6885b4af7ce84b437dc696490a530
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Apr 25 15:33:38 2018 +0200

    Revert: Unify CLOCK_MONOTONIC and CLOCK_BOOTTIME
    
    Revert commits
    
    92af4dcb4e1c ("tracing: Unify the "boot" and "mono" tracing clocks")
    127bfa5f4342 ("hrtimer: Unify MONOTONIC and BOOTTIME clock behavior")
    7250a4047aa6 ("posix-timers: Unify MONOTONIC and BOOTTIME clock behavior")
    d6c7270e913d ("timekeeping: Remove boot time specific code")
    f2d6fdbfd238 ("Input: Evdev - unify MONOTONIC and BOOTTIME clock behavior")
    d6ed449afdb3 ("timekeeping: Make the MONOTONIC clock behave like the BOOTTIME clock")
    72199320d49d ("timekeeping: Add the new CLOCK_MONOTONIC_ACTIVE clock")
    
    As stated in the pull request for the unification of CLOCK_MONOTONIC and
    CLOCK_BOOTTIME, it was clear that we might have to revert the change.
    
    As reported by several folks systemd and other applications rely on the
    documented behaviour of CLOCK_MONOTONIC on Linux and break with the above
    changes. After resume daemons time out and other timeout related issues are
    observed. Rafael compiled this list:
    
    * systemd kills daemons on resume, after >WatchdogSec seconds
      of suspending (Genki Sky).  [Verified that that's because systemd uses
      CLOCK_MONOTONIC and expects it to not include the suspend time.]
    
    * systemd-journald misbehaves after resume:
      systemd-journald[7266]: File /var/log/journal/016627c3c4784cd4812d4b7e96a34226/system.journal
    corrupted or uncleanly shut down, renaming and replacing.
      (Mike Galbraith).
    
    * NetworkManager reports "networking disabled" and networking is broken
      after resume 50% of the time (Pavel).  [May be because of systemd.]
    
    * MATE desktop dims the display and starts the screensaver right after
      system resume (Pavel).
    
    * Full system hang during resume (me).  [May be due to systemd or NM or both.]
    
    That happens on debian and open suse systems.
    
    It's sad, that these problems were neither catched in -next nor by those
    folks who expressed interest in this change.
    
    Reported-by: Rafael J. Wysocki <rjw@rjwysocki.net>
    Reported-by: Genki Sky <sky@genki.is>,
    Reported-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Kevin Easton <kevin@guarana.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salyzyn <salyzyn@android.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 4b3dca173e89..7acb953298a7 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -52,7 +52,6 @@ struct tk_read_base {
  * @offs_real:		Offset clock monotonic -> clock realtime
  * @offs_boot:		Offset clock monotonic -> clock boottime
  * @offs_tai:		Offset clock monotonic -> clock tai
- * @time_suspended:	Accumulated suspend time
  * @tai_offset:		The current UTC to TAI offset in seconds
  * @clock_was_set_seq:	The sequence number of clock was set events
  * @cs_was_changed_seq:	The sequence number of clocksource change events
@@ -95,7 +94,6 @@ struct timekeeper {
 	ktime_t			offs_real;
 	ktime_t			offs_boot;
 	ktime_t			offs_tai;
-	ktime_t			time_suspended;
 	s32			tai_offset;
 	unsigned int		clock_was_set_seq;
 	u8			cs_was_changed_seq;

commit 72199320d49dbafa1a99f94f1cd60dc90035c154
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 1 17:33:32 2018 +0100

    timekeeping: Add the new CLOCK_MONOTONIC_ACTIVE clock
    
    The planned change to unify the behaviour of the MONOTONIC and BOOTTIME
    clocks vs. suspend removes the ability to retrieve the active
    non-suspended time of a system.
    
    Provide a new CLOCK_MONOTONIC_ACTIVE clock which returns the active
    non-suspended time of the system via clock_gettime().
    
    This preserves the old behaviour of CLOCK_MONOTONIC before the
    BOOTTIME/MONOTONIC unification.
    
    This new clock also allows applications to detect programmatically that
    the MONOTONIC and BOOTTIME clocks are identical.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Kevin Easton <kevin@guarana.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salyzyn <salyzyn@android.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20180301165149.965235774@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 7acb953298a7..4b3dca173e89 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -52,6 +52,7 @@ struct tk_read_base {
  * @offs_real:		Offset clock monotonic -> clock realtime
  * @offs_boot:		Offset clock monotonic -> clock boottime
  * @offs_tai:		Offset clock monotonic -> clock tai
+ * @time_suspended:	Accumulated suspend time
  * @tai_offset:		The current UTC to TAI offset in seconds
  * @clock_was_set_seq:	The sequence number of clock was set events
  * @cs_was_changed_seq:	The sequence number of clocksource change events
@@ -94,6 +95,7 @@ struct timekeeper {
 	ktime_t			offs_real;
 	ktime_t			offs_boot;
 	ktime_t			offs_tai;
+	ktime_t			time_suspended;
 	s32			tai_offset;
 	unsigned int		clock_was_set_seq;
 	u8			cs_was_changed_seq;

commit 78b98e3c5a66d569a53b8f57b6a698f912794a43
Author: Miroslav Lichvar <mlichvar@redhat.com>
Date:   Fri Mar 9 10:42:48 2018 -0800

    timekeeping/ntp: Determine the multiplier directly from NTP tick length
    
    When the length of the NTP tick changes significantly, e.g. when an
    NTP/PTP application is correcting the initial offset of the clock, a
    large value may accumulate in the NTP error before the multiplier
    converges to the correct value. It may then take a very long time (hours
    or even days) before the error is corrected. This causes the clock to
    have an unstable frequency offset, which has a negative impact on the
    stability of synchronization with precise time sources (e.g. NTP/PTP
    using hardware timestamping or the PTP KVM clock).
    
    Use division to determine the correct multiplier directly from the NTP
    tick length and replace the iterative approach. This removes the last
    major source of the NTP error. The only remaining source is now limited
    resolution of the multiplier, which is corrected by adding 1 to the
    multiplier when the system clock is behind the NTP time.
    
    Signed-off-by: Miroslav Lichvar <mlichvar@redhat.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1520620971-9567-3-git-send-email-john.stultz@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index d315c3d6725c..7acb953298a7 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -117,6 +117,8 @@ struct timekeeper {
 	s64			ntp_error;
 	u32			ntp_error_shift;
 	u32			ntp_err_mult;
+	/* Flag used to avoid updating NTP twice with same second */
+	u32			skip_second_overflow;
 #ifdef CONFIG_DEBUG_TIMEKEEPING
 	long			last_warning;
 	/*

commit aea3706cfc4d952ed6d32b6d5845b5ecd99ed7f5
Author: Miroslav Lichvar <mlichvar@redhat.com>
Date:   Mon Nov 13 14:51:31 2017 -0800

    timekeeping: Remove CONFIG_GENERIC_TIME_VSYSCALL_OLD
    
    As of d4d1fc61eb38f (ia64: Update fsyscall gettime to use modern
    vsyscall_update)the last user of CONFIG_GENERIC_TIME_VSYSCALL_OLD
    have been updated, the legacy support for old-style vsyscall
    implementations can be removed from the timekeeping code.
    
    (Thanks again to Tony Luck for helping remove the last user!)
    
    [jstultz: Commit message rework]
    
    Signed-off-by: Miroslav Lichvar <mlichvar@redhat.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Link: https://lkml.kernel.org/r/1510613491-16695-1-git-send-email-john.stultz@linaro.org

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 7e9011101cb0..d315c3d6725c 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -136,13 +136,6 @@ struct timekeeper {
 extern void update_vsyscall(struct timekeeper *tk);
 extern void update_vsyscall_tz(void);
 
-#elif defined(CONFIG_GENERIC_TIME_VSYSCALL_OLD)
-
-extern void update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
-				struct clocksource *c, u32 mult,
-				u64 cycle_last);
-extern void update_vsyscall_tz(void);
-
 #else
 
 static inline void update_vsyscall(struct timekeeper *tk)

commit 2bcc673101268dc50e52b83226c5bbf38391e16d
Merge: 670310dfbae0 b24591e2fcf8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 17:56:58 2017 -0800

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer updates from Thomas Gleixner:
     "Yet another big pile of changes:
    
       - More year 2038 work from Arnd slowly reaching the point where we
         need to think about the syscalls themself.
    
       - A new timer function which allows to conditionally (re)arm a timer
         only when it's either not running or the new expiry time is sooner
         than the armed expiry time. This allows to use a single timer for
         multiple timeout requirements w/o caring about the first expiry
         time at the call site.
    
       - A new NMI safe accessor to clock real time for the printk timestamp
         work. Can be used by tracing, perf as well if required.
    
       - A large number of timer setup conversions from Kees which got
         collected here because either maintainers requested so or they
         simply got ignored. As Kees pointed out already there are a few
         trivial merge conflicts and some redundant commits which was
         unavoidable due to the size of this conversion effort.
    
       - Avoid a redundant iteration in the timer wheel softirq processing.
    
       - Provide a mechanism to treat RTC implementations depending on their
         hardware properties, i.e. don't inflict the write at the 0.5
         seconds boundary which originates from the PC CMOS RTC to all RTCs.
         No functional change as drivers need to be updated separately.
    
       - The usual small updates to core code clocksource drivers. Nothing
         really exciting"
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (111 commits)
      timers: Add a function to start/reduce a timer
      pstore: Use ktime_get_real_fast_ns() instead of __getnstimeofday()
      timer: Prepare to change all DEFINE_TIMER() callbacks
      netfilter: ipvs: Convert timers to use timer_setup()
      scsi: qla2xxx: Convert timers to use timer_setup()
      block/aoe: discover_timer: Convert timers to use timer_setup()
      ide: Convert timers to use timer_setup()
      drbd: Convert timers to use timer_setup()
      mailbox: Convert timers to use timer_setup()
      crypto: Convert timers to use timer_setup()
      drivers/pcmcia: omap1: Fix error in automated timer conversion
      ARM: footbridge: Fix typo in timer conversion
      drivers/sgi-xp: Convert timers to use timer_setup()
      drivers/pcmcia: Convert timers to use timer_setup()
      drivers/memstick: Convert timers to use timer_setup()
      drivers/macintosh: Convert timers to use timer_setup()
      hwrng/xgene-rng: Convert timers to use timer_setup()
      auxdisplay: Convert timers to use timer_setup()
      sparc/led: Convert timers to use timer_setup()
      mips: ip22/32: Convert timers to use timer_setup()
      ...

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 0a0a53daf2a2..97154c61e5d2 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * You SHOULD NOT be including this unless you're vsyscall
  * handling code or timekeeping internal code!

commit 4c3711d7fb4763c63b2654f2d07cbe21ca5aadd4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 31 17:12:48 2017 +0200

    timekeeping: Provide NMI safe access to clock realtime
    
    The configurable printk timestamping wants access to clock realtime. Right
    now there is no ktime_get_real_fast_ns() accessor because reading the
    monotonic base and the realtime offset cannot be done atomically. Contrary
    to boot time this offset can change during runtime and cause half updated
    readouts.
    
    struct tk_read_base was fully packed when the fast timekeeper access was
    implemented. commit ceea5e3771ed ("time: Fix clock->read(clock) race around
    clocksource changes") removed the 'read' function pointer from the
    structure, but of course left the comment stale.
    
    So now the structure can fit a new 64bit member w/o violating the cache
    line constraints.
    
    Add real_base to tk_read_base and update it in the fast timekeeper update
    sequence.
    
    Implement an accessor which follows the same scheme as the accessor to
    clock monotonic, but uses the new real_base to access clock real time.
    
    The runtime overhead for updating real_base is minimal as it just adds two
    cache hot values and stores them into an already dirtied cache line along
    with the other fast timekeeper updates.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead,org>
    Link: https://lkml.kernel.org/r/1505757060-2004-3-git-send-email-prarit@redhat.com

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 0a0a53daf2a2..98f645ee8409 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -13,19 +13,22 @@
 /**
  * struct tk_read_base - base structure for timekeeping readout
  * @clock:	Current clocksource used for timekeeping.
- * @read:	Read function of @clock
  * @mask:	Bitmask for two's complement subtraction of non 64bit clocks
  * @cycle_last: @clock cycle value at last update
  * @mult:	(NTP adjusted) multiplier for scaled math conversion
  * @shift:	Shift value for scaled math conversion
  * @xtime_nsec: Shifted (fractional) nano seconds offset for readout
  * @base:	ktime_t (nanoseconds) base time for readout
+ * @base_real:	Nanoseconds base value for clock REALTIME readout
  *
  * This struct has size 56 byte on 64 bit. Together with a seqcount it
  * occupies a single 64byte cache line.
  *
  * The struct is separate from struct timekeeper as it is also used
  * for a fast NMI safe accessors.
+ *
+ * @base_real is for the fast NMI safe accessor to allow reading clock
+ * realtime from any context.
  */
 struct tk_read_base {
 	struct clocksource	*clock;
@@ -35,6 +38,7 @@ struct tk_read_base {
 	u32			shift;
 	u64			xtime_nsec;
 	ktime_t			base;
+	u64			base_real;
 };
 
 /**

commit fc6eead7c1e2e5376c25d2795d4539fdacbc0648
Author: John Stultz <john.stultz@linaro.org>
Date:   Mon May 22 17:20:20 2017 -0700

    time: Clean up CLOCK_MONOTONIC_RAW time handling
    
    Now that we fixed the sub-ns handling for CLOCK_MONOTONIC_RAW,
    remove the duplicitive tk->raw_time.tv_nsec, which can be
    stored in tk->tkr_raw.xtime_nsec (similarly to how its handled
    for monotonic time).
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Daniel Mentz <danielmentz@google.com>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index f7043ccca81c..0a0a53daf2a2 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -51,7 +51,7 @@ struct tk_read_base {
  * @clock_was_set_seq:	The sequence number of clock was set events
  * @cs_was_changed_seq:	The sequence number of clocksource change events
  * @next_leap_ktime:	CLOCK_MONOTONIC time value of a pending leap-second
- * @raw_time:		Monotonic raw base time in timespec64 format
+ * @raw_sec:		CLOCK_MONOTONIC_RAW  time in seconds
  * @cycle_interval:	Number of clock cycles in one NTP interval
  * @xtime_interval:	Number of clock shifted nano seconds in one NTP
  *			interval.
@@ -93,7 +93,7 @@ struct timekeeper {
 	unsigned int		clock_was_set_seq;
 	u8			cs_was_changed_seq;
 	ktime_t			next_leap_ktime;
-	struct timespec64	raw_time;
+	u64			raw_sec;
 
 	/* The following members are for timekeeping internal use */
 	u64			cycle_interval;

commit 3d88d56c5873f6eebe23e05c3da701960146b801
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 8 16:44:21 2017 -0700

    time: Fix CLOCK_MONOTONIC_RAW sub-nanosecond accounting
    
    Due to how the MONOTONIC_RAW accumulation logic was handled,
    there is the potential for a 1ns discontinuity when we do
    accumulations. This small discontinuity has for the most part
    gone un-noticed, but since ARM64 enabled CLOCK_MONOTONIC_RAW
    in their vDSO clock_gettime implementation, we've seen failures
    with the inconsistency-check test in kselftest.
    
    This patch addresses the issue by using the same sub-ns
    accumulation handling that CLOCK_MONOTONIC uses, which avoids
    the issue for in-kernel users.
    
    Since the ARM64 vDSO implementation has its own clock_gettime
    calculation logic, this patch reduces the frequency of errors,
    but failures are still seen. The ARM64 vDSO will need to be
    updated to include the sub-nanosecond xtime_nsec values in its
    calculation for this issue to be completely fixed.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: "stable #4 . 8+" <stable@vger.kernel.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-3-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index e9834ada4d0c..f7043ccca81c 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -57,7 +57,7 @@ struct tk_read_base {
  *			interval.
  * @xtime_remainder:	Shifted nano seconds left over when rounding
  *			@cycle_interval
- * @raw_interval:	Raw nano seconds accumulated per NTP interval.
+ * @raw_interval:	Shifted raw nano seconds accumulated per NTP interval.
  * @ntp_error:		Difference between accumulated time and NTP time in ntp
  *			shifted nano seconds.
  * @ntp_error_shift:	Shift conversion between clock shifted nano seconds and
@@ -99,7 +99,7 @@ struct timekeeper {
 	u64			cycle_interval;
 	u64			xtime_interval;
 	s64			xtime_remainder;
-	u32			raw_interval;
+	u64			raw_interval;
 	/* The ntp_tick_length() value currently being used.
 	 * This cached copy ensures we consistently apply the tick
 	 * length for an entire tick, as ntp_tick_length may change

commit ceea5e3771ed2378668455fa21861bead7504df5
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 8 16:44:20 2017 -0700

    time: Fix clock->read(clock) race around clocksource changes
    
    In tests, which excercise switching of clocksources, a NULL
    pointer dereference can be observed on AMR64 platforms in the
    clocksource read() function:
    
    u64 clocksource_mmio_readl_down(struct clocksource *c)
    {
            return ~(u64)readl_relaxed(to_mmio_clksrc(c)->reg) & c->mask;
    }
    
    This is called from the core timekeeping code via:
    
            cycle_now = tkr->read(tkr->clock);
    
    tkr->read is the cached tkr->clock->read() function pointer.
    When the clocksource is changed then tkr->clock and tkr->read
    are updated sequentially. The code above results in a sequential
    load operation of tkr->read and tkr->clock as well.
    
    If the store to tkr->clock hits between the loads of tkr->read
    and tkr->clock, then the old read() function is called with the
    new clock pointer. As a consequence the read() function
    dereferences a different data structure and the resulting 'reg'
    pointer can point anywhere including NULL.
    
    This problem was introduced when the timekeeping code was
    switched over to use struct tk_read_base. Before that, it was
    theoretically possible as well when the compiler decided to
    reload clock in the code sequence:
    
         now = tk->clock->read(tk->clock);
    
    Add a helper function which avoids the issue by reading
    tk_read_base->clock once into a local variable clk and then issue
    the read function via clk->read(clk). This guarantees that the
    read() function always gets the proper clocksource pointer handed
    in.
    
    Since there is now no use for the tkr.read pointer, this patch
    also removes it, and to address stopping the fast timekeeper
    during suspend/resume, it introduces a dummy clocksource to use
    rather then just a dummy read function.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: stable <stable@vger.kernel.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Cc: Daniel Mentz <danielmentz@google.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-2-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 110f4532188c..e9834ada4d0c 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -29,7 +29,6 @@
  */
 struct tk_read_base {
 	struct clocksource	*clock;
-	u64			(*read)(struct clocksource *cs);
 	u64			mask;
 	u64			cycle_last;
 	u32			mult;

commit a5a1d1c2914b5316924c7893eb683a5420ebd3be
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Dec 21 20:32:01 2016 +0100

    clocksource: Use a plain u64 instead of cycle_t
    
    There is no point in having an extra type for extra confusion. u64 is
    unambiguous.
    
    Conversion was done with the following coccinelle script:
    
    @rem@
    @@
    -typedef u64 cycle_t;
    
    @fix@
    typedef cycle_t;
    @@
    -cycle_t
    +u64
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index e88005459035..110f4532188c 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -29,9 +29,9 @@
  */
 struct tk_read_base {
 	struct clocksource	*clock;
-	cycle_t			(*read)(struct clocksource *cs);
-	cycle_t			mask;
-	cycle_t			cycle_last;
+	u64			(*read)(struct clocksource *cs);
+	u64			mask;
+	u64			cycle_last;
 	u32			mult;
 	u32			shift;
 	u64			xtime_nsec;
@@ -97,7 +97,7 @@ struct timekeeper {
 	struct timespec64	raw_time;
 
 	/* The following members are for timekeeping internal use */
-	cycle_t			cycle_interval;
+	u64			cycle_interval;
 	u64			xtime_interval;
 	s64			xtime_remainder;
 	u32			raw_interval;
@@ -136,7 +136,7 @@ extern void update_vsyscall_tz(void);
 
 extern void update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
 				struct clocksource *c, u32 mult,
-				cycle_t cycle_last);
+				u64 cycle_last);
 extern void update_vsyscall_tz(void);
 
 #else

commit 2c756feb18d9ec258dbb3a3d11c47e28820690d7
Author: Christopher S. Hall <christopher.s.hall@intel.com>
Date:   Mon Feb 22 03:15:23 2016 -0800

    time: Add history to cross timestamp interface supporting slower devices
    
    Another representative use case of time sync and the correlated
    clocksource (in addition to PTP noted above) is PTP synchronized
    audio.
    
    In a streaming application, as an example, samples will be sent and/or
    received by multiple devices with a presentation time that is in terms
    of the PTP master clock. Synchronizing the audio output on these
    devices requires correlating the audio clock with the PTP master
    clock. The more precise this correlation is, the better the audio
    quality (i.e. out of sync audio sounds bad).
    
    From an application standpoint, to correlate the PTP master clock with
    the audio device clock, the system clock is used as a intermediate
    timebase. The transforms such an application would perform are:
    
        System Clock <-> Audio clock
        System Clock <-> Network Device Clock [<-> PTP Master Clock]
    
    Modern Intel platforms can perform a more accurate cross timestamp in
    hardware (ART,audio device clock).  The audio driver requires
    ART->system time transforms -- the same as required for the network
    driver. These platforms offload audio processing (including
    cross-timestamps) to a DSP which to ensure uninterrupted audio
    processing, communicates and response to the host only once every
    millsecond. As a result is takes up to a millisecond for the DSP to
    receive a request, the request is processed by the DSP, the audio
    output hardware is polled for completion, the result is copied into
    shared memory, and the host is notified. All of these operation occur
    on a millisecond cadence.  This transaction requires about 2 ms, but
    under heavier workloads it may take up to 4 ms.
    
    Adding a history allows these slow devices the option of providing an
    ART value outside of the current interval. In this case, the callback
    provided is an accessor function for the previously obtained counter
    value. If get_system_device_crosststamp() receives a counter value
    previous to cycle_last, it consults the history provided as an
    argument in history_ref and interpolates the realtime and monotonic
    raw system time using the provided counter value. If there are any
    clock discontinuities, e.g. from calling settimeofday(), the monotonic
    raw time is interpolated in the usual way, but the realtime clock time
    is adjusted by scaling the monotonic raw adjustment.
    
    When an accessor function is used a history argument *must* be
    provided. The history is initialized using ktime_get_snapshot() and
    must be called before the counter values are read.
    
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: kevin.b.stanton@intel.com
    Cc: kevin.j.clarke@intel.com
    Cc: hpa@zytor.com
    Cc: jeffrey.t.kirsher@intel.com
    Cc: netdev@vger.kernel.org
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Christopher S. Hall <christopher.s.hall@intel.com>
    [jstultz: Fixed up cycles_t/cycle_t type confusion]
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 25247220b4b7..e88005459035 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -50,6 +50,7 @@ struct tk_read_base {
  * @offs_tai:		Offset clock monotonic -> clock tai
  * @tai_offset:		The current UTC to TAI offset in seconds
  * @clock_was_set_seq:	The sequence number of clock was set events
+ * @cs_was_changed_seq:	The sequence number of clocksource change events
  * @next_leap_ktime:	CLOCK_MONOTONIC time value of a pending leap-second
  * @raw_time:		Monotonic raw base time in timespec64 format
  * @cycle_interval:	Number of clock cycles in one NTP interval
@@ -91,6 +92,7 @@ struct timekeeper {
 	ktime_t			offs_tai;
 	s32			tai_offset;
 	unsigned int		clock_was_set_seq;
+	u8			cs_was_changed_seq;
 	ktime_t			next_leap_ktime;
 	struct timespec64	raw_time;
 

commit 833f32d763028c1bb371c64f457788b933773b3e
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 11 15:54:55 2015 -0700

    time: Prevent early expiry of hrtimers[CLOCK_REALTIME] at the leap second edge
    
    Currently, leapsecond adjustments are done at tick time. As a result,
    the leapsecond was applied at the first timer tick *after* the
    leapsecond (~1-10ms late depending on HZ), rather then exactly on the
    second edge.
    
    This was in part historical from back when we were always tick based,
    but correcting this since has been avoided since it adds extra
    conditional checks in the gettime fastpath, which has performance
    overhead.
    
    However, it was recently pointed out that ABS_TIME CLOCK_REALTIME
    timers set for right after the leapsecond could fire a second early,
    since some timers may be expired before we trigger the timekeeping
    timer, which then applies the leapsecond.
    
    This isn't quite as bad as it sounds, since behaviorally it is similar
    to what is possible w/ ntpd made leapsecond adjustments done w/o using
    the kernel discipline. Where due to latencies, timers may fire just
    prior to the settimeofday call. (Also, one should note that all
    applications using CLOCK_REALTIME timers should always be careful,
    since they are prone to quirks from settimeofday() disturbances.)
    
    However, the purpose of having the kernel do the leap adjustment is to
    avoid such latencies, so I think this is worth fixing.
    
    So in order to properly keep those timers from firing a second early,
    this patch modifies the ntp and timekeeping logic so that we keep
    enough state so that the update_base_offsets_now accessor, which
    provides the hrtimer core the current time, can check and apply the
    leapsecond adjustment on the second edge. This prevents the hrtimer
    core from expiring timers too early.
    
    This patch does not modify any other time read path, so no additional
    overhead is incurred. However, this also means that the leap-second
    continues to be applied at tick time for all other read-paths.
    
    Apologies to Richard Cochran, who pushed for similar changes years
    ago, which I resisted due to the concerns about the performance
    overhead.
    
    While I suspect this isn't extremely critical, folks who care about
    strict leap-second correctness will likely want to watch
    this. Potentially a -stable candidate eventually.
    
    Originally-suggested-by: Richard Cochran <richardcochran@gmail.com>
    Reported-by: Daniel Bristot de Oliveira <bristot@redhat.com>
    Reported-by: Prarit Bhargava <prarit@redhat.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jiri Bohac <jbohac@suse.cz>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Link: http://lkml.kernel.org/r/1434063297-28657-4-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index e1f5a1136554..25247220b4b7 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -50,6 +50,7 @@ struct tk_read_base {
  * @offs_tai:		Offset clock monotonic -> clock tai
  * @tai_offset:		The current UTC to TAI offset in seconds
  * @clock_was_set_seq:	The sequence number of clock was set events
+ * @next_leap_ktime:	CLOCK_MONOTONIC time value of a pending leap-second
  * @raw_time:		Monotonic raw base time in timespec64 format
  * @cycle_interval:	Number of clock cycles in one NTP interval
  * @xtime_interval:	Number of clock shifted nano seconds in one NTP
@@ -90,6 +91,7 @@ struct timekeeper {
 	ktime_t			offs_tai;
 	s32			tai_offset;
 	unsigned int		clock_was_set_seq;
+	ktime_t			next_leap_ktime;
 	struct timespec64	raw_time;
 
 	/* The following members are for timekeeping internal use */

commit 57d05a93ada77c4f8a6112cbc867a2948dce7991
Author: John Stultz <john.stultz@linaro.org>
Date:   Wed May 13 16:04:47 2015 -0700

    time: Rework debugging variables so they aren't global
    
    Ingo suggested that the timekeeping debugging variables
    recently added should not be global, and should be tied
    to the timekeeper's read_base.
    
    Thus this patch implements that suggestion.
    
    This version is different from the earlier versions
    as it keeps the variables in the timekeeper structure
    rather then in the tkr.
    
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 6f8276ae579c..e1f5a1136554 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -61,6 +61,9 @@ struct tk_read_base {
  *			shifted nano seconds.
  * @ntp_error_shift:	Shift conversion between clock shifted nano seconds and
  *			ntp shifted nano seconds.
+ * @last_warning:	Warning ratelimiter (DEBUG_TIMEKEEPING)
+ * @underflow_seen:	Underflow warning flag (DEBUG_TIMEKEEPING)
+ * @overflow_seen:	Overflow warning flag (DEBUG_TIMEKEEPING)
  *
  * Note: For timespec(64) based interfaces wall_to_monotonic is what
  * we need to add to xtime (or xtime corrected for sub jiffie times)
@@ -106,6 +109,18 @@ struct timekeeper {
 	s64			ntp_error;
 	u32			ntp_error_shift;
 	u32			ntp_err_mult;
+#ifdef CONFIG_DEBUG_TIMEKEEPING
+	long			last_warning;
+	/*
+	 * These simple flag variables are managed
+	 * without locks, which is racy, but they are
+	 * ok since we don't really care about being
+	 * super precise about how many events were
+	 * seen, just that a problem was observed.
+	 */
+	int			underflow_seen;
+	int			overflow_seen;
+#endif
 };
 
 #ifdef CONFIG_GENERIC_TIME_VSYSCALL

commit 868a3e915f7f5eba8f8cb4f7da2276760807c51c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Apr 14 21:08:37 2015 +0000

    hrtimer: Make offset update smarter
    
    On every tick/hrtimer interrupt we update the offset variables of the
    clock bases. That's silly because these offsets change very seldom.
    
    Add a sequence counter to the time keeping code which keeps track of
    the offset updates (clock_was_set()). Have a sequence cache in the
    hrtimer cpu bases to evaluate whether the offsets must be updated or
    not. This allows us later to avoid pointless cacheline pollution.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Link: http://lkml.kernel.org/r/20150414203501.132820245@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index fb86963859c7..6f8276ae579c 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -49,6 +49,7 @@ struct tk_read_base {
  * @offs_boot:		Offset clock monotonic -> clock boottime
  * @offs_tai:		Offset clock monotonic -> clock tai
  * @tai_offset:		The current UTC to TAI offset in seconds
+ * @clock_was_set_seq:	The sequence number of clock was set events
  * @raw_time:		Monotonic raw base time in timespec64 format
  * @cycle_interval:	Number of clock cycles in one NTP interval
  * @xtime_interval:	Number of clock shifted nano seconds in one NTP
@@ -85,6 +86,7 @@ struct timekeeper {
 	ktime_t			offs_boot;
 	ktime_t			offs_tai;
 	s32			tai_offset;
+	unsigned int		clock_was_set_seq;
 	struct timespec64	raw_time;
 
 	/* The following members are for timekeeping internal use */

commit 4a4ad80d32cea69ee93bd4589f24dc478804cd80
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Mar 19 09:28:44 2015 +0100

    time: Add timerkeeper::tkr_raw
    
    Introduce tkr_raw and make use of it.
    
      base_raw -> tkr_raw.base
      clock->{mult,shift} -> tkr_raw.{mult.shift}
    
    Kill timekeeping_get_ns_raw() in favour of
    timekeeping_get_ns(&tkr_raw), this removes all mono_raw special
    casing.
    
    Duplicate the updates to tkr_mono.cycle_last into tkr_raw.cycle_last,
    both need the same value.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20150319093400.422589590@infradead.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 73df17f1535f..fb86963859c7 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -41,6 +41,7 @@ struct tk_read_base {
 /**
  * struct timekeeper - Structure holding internal timekeeping values.
  * @tkr_mono:		The readout base structure for CLOCK_MONOTONIC
+ * @tkr_raw:		The readout base structure for CLOCK_MONOTONIC_RAW
  * @xtime_sec:		Current CLOCK_REALTIME time in seconds
  * @ktime_sec:		Current CLOCK_MONOTONIC time in seconds
  * @wall_to_monotonic:	CLOCK_REALTIME to CLOCK_MONOTONIC offset
@@ -48,7 +49,6 @@ struct tk_read_base {
  * @offs_boot:		Offset clock monotonic -> clock boottime
  * @offs_tai:		Offset clock monotonic -> clock tai
  * @tai_offset:		The current UTC to TAI offset in seconds
- * @base_raw:		Monotonic raw base time in ktime_t format
  * @raw_time:		Monotonic raw base time in timespec64 format
  * @cycle_interval:	Number of clock cycles in one NTP interval
  * @xtime_interval:	Number of clock shifted nano seconds in one NTP
@@ -77,6 +77,7 @@ struct tk_read_base {
  */
 struct timekeeper {
 	struct tk_read_base	tkr_mono;
+	struct tk_read_base	tkr_raw;
 	u64			xtime_sec;
 	unsigned long		ktime_sec;
 	struct timespec64	wall_to_monotonic;
@@ -84,7 +85,6 @@ struct timekeeper {
 	ktime_t			offs_boot;
 	ktime_t			offs_tai;
 	s32			tai_offset;
-	ktime_t			base_raw;
 	struct timespec64	raw_time;
 
 	/* The following members are for timekeeping internal use */

commit 876e78818def2983be55878b21f7152fbaebbd36
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Mar 19 10:09:06 2015 +0100

    time: Rename timekeeper::tkr to timekeeper::tkr_mono
    
    In preparation of adding another tkr field, rename this one to
    tkr_mono. Also rename tk_read_base::base_mono to tk_read_base::base,
    since the structure is not specific to CLOCK_MONOTONIC and the mono
    name got added to the tk_read_base instance.
    
    Lots of trivial churn.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20150319093400.344679419@infradead.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 05af9a334893..73df17f1535f 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -16,16 +16,16 @@
  * @read:	Read function of @clock
  * @mask:	Bitmask for two's complement subtraction of non 64bit clocks
  * @cycle_last: @clock cycle value at last update
- * @mult:	NTP adjusted multiplier for scaled math conversion
+ * @mult:	(NTP adjusted) multiplier for scaled math conversion
  * @shift:	Shift value for scaled math conversion
  * @xtime_nsec: Shifted (fractional) nano seconds offset for readout
- * @base_mono:  ktime_t (nanoseconds) base time for readout
+ * @base:	ktime_t (nanoseconds) base time for readout
  *
  * This struct has size 56 byte on 64 bit. Together with a seqcount it
  * occupies a single 64byte cache line.
  *
  * The struct is separate from struct timekeeper as it is also used
- * for a fast NMI safe accessor to clock monotonic.
+ * for a fast NMI safe accessors.
  */
 struct tk_read_base {
 	struct clocksource	*clock;
@@ -35,12 +35,12 @@ struct tk_read_base {
 	u32			mult;
 	u32			shift;
 	u64			xtime_nsec;
-	ktime_t			base_mono;
+	ktime_t			base;
 };
 
 /**
  * struct timekeeper - Structure holding internal timekeeping values.
- * @tkr:		The readout base structure
+ * @tkr_mono:		The readout base structure for CLOCK_MONOTONIC
  * @xtime_sec:		Current CLOCK_REALTIME time in seconds
  * @ktime_sec:		Current CLOCK_MONOTONIC time in seconds
  * @wall_to_monotonic:	CLOCK_REALTIME to CLOCK_MONOTONIC offset
@@ -76,7 +76,7 @@ struct tk_read_base {
  * used instead.
  */
 struct timekeeper {
-	struct tk_read_base	tkr;
+	struct tk_read_base	tkr_mono;
 	u64			xtime_sec;
 	unsigned long		ktime_sec;
 	struct timespec64	wall_to_monotonic;

commit 9e3680b1750b9a62680b0262c9f438de98b77655
Author: Heena Sirwani <heenasirwani@gmail.com>
Date:   Wed Oct 29 16:01:16 2014 +0530

    timekeeping: Provide fast accessor to the seconds part of CLOCK_MONOTONIC
    
    This is the counterpart to get_seconds() based on CLOCK_MONOTONIC. The
    use case for this interface are kernel internal coarse grained
    timestamps which do neither require the nanoseconds fraction of
    current time nor the CLOCK_REALTIME properties. Such timestamps can
    currently only retrieved by calling ktime_get_ts64() and using the
    tv_sec field of the returned timespec64. That's inefficient as it
    involves the read of the clocksource, math operations and must be
    protected by the timekeeper sequence counter.
    
    To avoid the sequence counter protection we restrict the return value
    to unsigned 32bit on 32bit machines. This covers ~136 years of uptime
    and therefor an overflow is not expected to hit anytime soon.
    
    To avoid math in the function we calculate the current seconds portion
    of CLOCK_MONOTONIC when the timekeeper gets updated in
    tk_update_ktime_data() similar to the CLOCK_REALTIME counterpart
    xtime_sec.
    
    [ tglx: Massaged changelog, simplified and commented the update
            function, added docbook comment ]
    
    Signed-off-by: Heena Sirwani <heenasirwani@gmail.com>
    Reviewed-by: Arnd Bergman <arnd@arndb.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: opw-kernel@googlegroups.com
    Link: http://lkml.kernel.org/r/da0b63f4bdf3478909f92becb35861197da3a905.1414578445.git.heenasirwani@gmail.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 95640dcd1899..05af9a334893 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -42,6 +42,7 @@ struct tk_read_base {
  * struct timekeeper - Structure holding internal timekeeping values.
  * @tkr:		The readout base structure
  * @xtime_sec:		Current CLOCK_REALTIME time in seconds
+ * @ktime_sec:		Current CLOCK_MONOTONIC time in seconds
  * @wall_to_monotonic:	CLOCK_REALTIME to CLOCK_MONOTONIC offset
  * @offs_real:		Offset clock monotonic -> clock realtime
  * @offs_boot:		Offset clock monotonic -> clock boottime
@@ -77,6 +78,7 @@ struct tk_read_base {
 struct timekeeper {
 	struct tk_read_base	tkr;
 	u64			xtime_sec;
+	unsigned long		ktime_sec;
 	struct timespec64	wall_to_monotonic;
 	ktime_t			offs_real;
 	ktime_t			offs_boot;

commit 953dec21aed4038464fec02f96a2f1b8701a5bce
Author: John Stultz <john.stultz@linaro.org>
Date:   Fri Jul 25 21:37:19 2014 -0700

    timekeeping: Fixup typo in update_vsyscall_old definition
    
    In commit 4a0e637738f0 ("clocksource: Get rid of cycle_last"),
    currently in the -tip tree, there was a small typo where cycles_t
    was used intstead of cycle_t. This broke ppc64 builds.
    
    Fix this by using the proper cycle_t type for this usage, in
    both the definition and the ia64 implementation.
    
    Now, having both cycle_t and cycles_t types seems like a very
    bad idea just asking for these sorts of issues. But that
    will be a cleanup for another day.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1406349439-11785-1-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index e9660e52dc09..95640dcd1899 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -113,7 +113,7 @@ extern void update_vsyscall_tz(void);
 
 extern void update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
 				struct clocksource *c, u32 mult,
-				cycles_t cycle_last);
+				cycle_t cycle_last);
 extern void update_vsyscall_tz(void);
 
 #else

commit 375f45b5b53a91dfa8f0c11328e0e044f82acbed
Author: John Stultz <john.stultz@linaro.org>
Date:   Wed Apr 23 20:53:29 2014 -0700

    timekeeping: Use cached ntp_tick_length when accumulating error
    
    By caching the ntp_tick_length() when we correct the frequency error,
    and then using that cached value to accumulate error, we avoid large
    initial errors when the tick length is changed.
    
    This makes convergence happen much faster in the simulator, since the
    initial error doesn't have to be slowly whittled away.
    
    This initially seems like an accounting error, but Miroslav pointed out
    that ntp_tick_length() can change mid-tick, so when we apply it in the
    error accumulation, we are applying any recent change to the entire tick.
    
    This approach chooses to apply changes in the ntp_tick_length() only to
    the next tick, which allows us to calculate the freq correction before
    using the new tick length, which avoids accummulating error.
    
    Credit to Miroslav for pointing this out and providing the original patch
    this functionality has been pulled out from, along with the rational.
    
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Reported-by: Miroslav Lichvar <mlichvar@redhat.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index f7ac48d2edf5..e9660e52dc09 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -90,6 +90,15 @@ struct timekeeper {
 	u64			xtime_interval;
 	s64			xtime_remainder;
 	u32			raw_interval;
+	/* The ntp_tick_length() value currently being used.
+	 * This cached copy ensures we consistently apply the tick
+	 * length for an entire tick, as ntp_tick_length may change
+	 * mid-tick, and we don't want to apply that new value to
+	 * the tick in progress.
+	 */
+	u64			ntp_tick;
+	/* Difference between accumulated time and NTP time in ntp
+	 * shifted nano seconds. */
 	s64			ntp_error;
 	u32			ntp_error_shift;
 	u32			ntp_err_mult;

commit dc491596f6394382fbc74ad331156207d619fa0a
Author: John Stultz <john.stultz@linaro.org>
Date:   Fri Dec 6 17:25:21 2013 -0800

    timekeeping: Rework frequency adjustments to work better w/ nohz
    
    The existing timekeeping_adjust logic has always been complicated
    to understand. Further, since it was developed prior to NOHZ becoming
    common, its not surprising it performs poorly when NOHZ is enabled.
    
    Since Miroslav pointed out the problematic nature of the existing code
    in the NOHZ case, I've tried to refactor the code to perform better.
    
    The problem with the previous approach was that it tried to adjust
    for the total cumulative error using a scaled dampening factor. This
    resulted in large errors to be corrected slowly, while small errors
    were corrected quickly. With NOHZ the timekeeping code doesn't know
    how far out the next tick will be, so this results in bad
    over-correction to small errors, and insufficient correction to large
    errors.
    
    Inspired by Miroslav's patch, I've refactored the code to try to
    address the correction in two steps.
    
    1) Check the future freq error for the next tick, and if the frequency
    error is large, try to make sure we correct it so it doesn't cause
    much accumulated error.
    
    2) Then make a small single unit adjustment to correct any cumulative
    error that has collected over time.
    
    This method performs fairly well in the simulator Miroslav created.
    
    Major credit to Miroslav for pointing out the issue, providing the
    original patch to resolve this, a simulator for testing, as well as
    helping debug and resolve issues in my implementation so that it
    performed closer to his original implementation.
    
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Reported-by: Miroslav Lichvar <mlichvar@redhat.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 97381997625b..f7ac48d2edf5 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -92,6 +92,7 @@ struct timekeeper {
 	u32			raw_interval;
 	s64			ntp_error;
 	u32			ntp_error_shift;
+	u32			ntp_err_mult;
 };
 
 #ifdef CONFIG_GENERIC_TIME_VSYSCALL

commit d28ede83791defee9a81e558540699dc46dbbe13
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:05:16 2014 +0000

    timekeeping: Create struct tk_read_base and use it in struct timekeeper
    
    The members of the new struct are the required ones for the new NMI
    safe accessor to clcok monotonic. In order to reuse the existing
    timekeeping code and to make the update of the fast NMI safe
    timekeepers a simple memcpy use the struct for the timekeeper as well
    and convert all users.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 75bb8add78f5..97381997625b 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -10,80 +10,87 @@
 #include <linux/jiffies.h>
 #include <linux/time.h>
 
-/*
- * Structure holding internal timekeeping values.
- *
- * Note: wall_to_monotonic is what we need to add to xtime (or xtime
- * corrected for sub jiffie times) to get to monotonic time.
- * Monotonic is pegged at zero at system boot time, so
- * wall_to_monotonic will be negative, however, we will ALWAYS keep
- * the tv_nsec part positive so we can use the usual normalization.
+/**
+ * struct tk_read_base - base structure for timekeeping readout
+ * @clock:	Current clocksource used for timekeeping.
+ * @read:	Read function of @clock
+ * @mask:	Bitmask for two's complement subtraction of non 64bit clocks
+ * @cycle_last: @clock cycle value at last update
+ * @mult:	NTP adjusted multiplier for scaled math conversion
+ * @shift:	Shift value for scaled math conversion
+ * @xtime_nsec: Shifted (fractional) nano seconds offset for readout
+ * @base_mono:  ktime_t (nanoseconds) base time for readout
  *
- * wall_to_monotonic is moved after resume from suspend for the
- * monotonic time not to jump. To calculate the real boot time offset
- * we need to do offs_real - offs_boot.
+ * This struct has size 56 byte on 64 bit. Together with a seqcount it
+ * occupies a single 64byte cache line.
  *
- * - wall_to_monotonic is no longer the boot time, getboottime must be
- * used instead.
+ * The struct is separate from struct timekeeper as it is also used
+ * for a fast NMI safe accessor to clock monotonic.
  */
-struct timekeeper {
-	/* Current clocksource used for timekeeping. */
+struct tk_read_base {
 	struct clocksource	*clock;
-	/* Read function of @clock */
 	cycle_t			(*read)(struct clocksource *cs);
-	/* Bitmask for two's complement subtraction of non 64bit counters */
 	cycle_t			mask;
-	/* Last cycle value */
 	cycle_t			cycle_last;
-	/* NTP adjusted clock multiplier */
 	u32			mult;
-	/* The shift value of the current clocksource. */
 	u32			shift;
-	/* Clock shifted nano seconds */
 	u64			xtime_nsec;
-
-	/* Monotonic base time */
 	ktime_t			base_mono;
+};
 
-	/* Current CLOCK_REALTIME time in seconds */
+/**
+ * struct timekeeper - Structure holding internal timekeeping values.
+ * @tkr:		The readout base structure
+ * @xtime_sec:		Current CLOCK_REALTIME time in seconds
+ * @wall_to_monotonic:	CLOCK_REALTIME to CLOCK_MONOTONIC offset
+ * @offs_real:		Offset clock monotonic -> clock realtime
+ * @offs_boot:		Offset clock monotonic -> clock boottime
+ * @offs_tai:		Offset clock monotonic -> clock tai
+ * @tai_offset:		The current UTC to TAI offset in seconds
+ * @base_raw:		Monotonic raw base time in ktime_t format
+ * @raw_time:		Monotonic raw base time in timespec64 format
+ * @cycle_interval:	Number of clock cycles in one NTP interval
+ * @xtime_interval:	Number of clock shifted nano seconds in one NTP
+ *			interval.
+ * @xtime_remainder:	Shifted nano seconds left over when rounding
+ *			@cycle_interval
+ * @raw_interval:	Raw nano seconds accumulated per NTP interval.
+ * @ntp_error:		Difference between accumulated time and NTP time in ntp
+ *			shifted nano seconds.
+ * @ntp_error_shift:	Shift conversion between clock shifted nano seconds and
+ *			ntp shifted nano seconds.
+ *
+ * Note: For timespec(64) based interfaces wall_to_monotonic is what
+ * we need to add to xtime (or xtime corrected for sub jiffie times)
+ * to get to monotonic time.  Monotonic is pegged at zero at system
+ * boot time, so wall_to_monotonic will be negative, however, we will
+ * ALWAYS keep the tv_nsec part positive so we can use the usual
+ * normalization.
+ *
+ * wall_to_monotonic is moved after resume from suspend for the
+ * monotonic time not to jump. We need to add total_sleep_time to
+ * wall_to_monotonic to get the real boot based time offset.
+ *
+ * wall_to_monotonic is no longer the boot time, getboottime must be
+ * used instead.
+ */
+struct timekeeper {
+	struct tk_read_base	tkr;
 	u64			xtime_sec;
-	/* CLOCK_REALTIME to CLOCK_MONOTONIC offset */
 	struct timespec64	wall_to_monotonic;
-
-	/* Offset clock monotonic -> clock realtime */
 	ktime_t			offs_real;
-	/* Offset clock monotonic -> clock boottime */
 	ktime_t			offs_boot;
-	/* Offset clock monotonic -> clock tai */
 	ktime_t			offs_tai;
-
-	/* The current UTC to TAI offset in seconds */
 	s32			tai_offset;
-
-	/* Monotonic raw base time */
 	ktime_t			base_raw;
-
-	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
 	struct timespec64	raw_time;
 
-	/* Number of clock cycles in one NTP interval. */
+	/* The following members are for timekeeping internal use */
 	cycle_t			cycle_interval;
-	/* Number of clock shifted nano seconds in one NTP interval. */
 	u64			xtime_interval;
-	/* shifted nano seconds left over when rounding cycle_interval */
 	s64			xtime_remainder;
-	/* Raw nano seconds accumulated per NTP interval. */
 	u32			raw_interval;
-
-	/*
-	 * Difference between accumulated time and NTP time in ntp
-	 * shifted nano seconds.
-	 */
 	s64			ntp_error;
-	/*
-	 * Shift conversion between clock shifted nano seconds and
-	 * ntp shifted nano seconds.
-	 */
 	u32			ntp_error_shift;
 };
 

commit 6d3aadf3e180e09dbefab16478c6876b584ce16e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:05:15 2014 +0000

    timekeeping: Restructure the timekeeper some more
    
    Access to time requires to touch two cachelines at minimum
    
       1) The timekeeper data structure
    
       2) The clocksource data structure
    
    The access to the clocksource data structure can be avoided as almost
    all clocksource implementations ignore the argument to the read
    callback, which is a pointer to the clocksource.
    
    But the core needs to touch it to access the members @read and @mask.
    
    So we are better off by copying the @read function pointer and the
    @mask from the clocksource to the core data structure itself.
    
    For the most used ktime_get() access all required data including the
    @read and @mask copies fits together with the sequence counter into a
    single 64 byte cacheline.
    
    For the other time access functions we touch in the current code three
    cache lines in the worst case. But with the clocksource data copies we
    can reduce that to two adjacent cachelines, which is more efficient
    than disjunct cache lines.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index cb88096222c0..75bb8add78f5 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -29,6 +29,10 @@
 struct timekeeper {
 	/* Current clocksource used for timekeeping. */
 	struct clocksource	*clock;
+	/* Read function of @clock */
+	cycle_t			(*read)(struct clocksource *cs);
+	/* Bitmask for two's complement subtraction of non 64bit counters */
+	cycle_t			mask;
 	/* Last cycle value */
 	cycle_t			cycle_last;
 	/* NTP adjusted clock multiplier */

commit 4a0e637738f06673725792d74eed67f8779b62c7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:05:13 2014 +0000

    clocksource: Get rid of cycle_last
    
    cycle_last was added to the clocksource to support the TSC
    validation. We moved that to the core code, so we can get rid of the
    extra copy.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 2e20275a7083..cb88096222c0 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -29,6 +29,8 @@
 struct timekeeper {
 	/* Current clocksource used for timekeeping. */
 	struct clocksource	*clock;
+	/* Last cycle value */
+	cycle_t			cycle_last;
 	/* NTP adjusted clock multiplier */
 	u32			mult;
 	/* The shift value of the current clocksource. */
@@ -62,8 +64,6 @@ struct timekeeper {
 
 	/* Number of clock cycles in one NTP interval. */
 	cycle_t			cycle_interval;
-	/* Last cycle value (also stored in clock->cycle_last) */
-	cycle_t			cycle_last;
 	/* Number of clock shifted nano seconds in one NTP interval. */
 	u64			xtime_interval;
 	/* shifted nano seconds left over when rounding cycle_interval */
@@ -91,7 +91,8 @@ extern void update_vsyscall_tz(void);
 #elif defined(CONFIG_GENERIC_TIME_VSYSCALL_OLD)
 
 extern void update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
-				struct clocksource *c, u32 mult);
+				struct clocksource *c, u32 mult,
+				cycles_t cycle_last);
 extern void update_vsyscall_tz(void);
 
 #else

commit f519b1a2e08c913375324a927992bb328387f169
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:05:04 2014 +0000

    timekeeping: Provide ktime_get_raw()
    
    Provide a ktime_t based interface for raw monotonic time.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 8e5d77a01787..2e20275a7083 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -54,6 +54,9 @@ struct timekeeper {
 	/* The current UTC to TAI offset in seconds */
 	s32			tai_offset;
 
+	/* Monotonic raw base time */
+	ktime_t			base_raw;
+
 	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
 	struct timespec64	raw_time;
 

commit 47da70d32535000ec29cc206cfc1d318fbd8761f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:05:00 2014 +0000

    timekeeping: Remove timekeeper.total_sleep_time
    
    No more users. Remove it
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 87e0992564f2..8e5d77a01787 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -20,8 +20,8 @@
  * the tv_nsec part positive so we can use the usual normalization.
  *
  * wall_to_monotonic is moved after resume from suspend for the
- * monotonic time not to jump. We need to add total_sleep_time to
- * wall_to_monotonic to get the real boot based time offset.
+ * monotonic time not to jump. To calculate the real boot time offset
+ * we need to do offs_real - offs_boot.
  *
  * - wall_to_monotonic is no longer the boot time, getboottime must be
  * used instead.
@@ -51,8 +51,6 @@ struct timekeeper {
 	/* Offset clock monotonic -> clock tai */
 	ktime_t			offs_tai;
 
-	/* time spent in suspend */
-	struct timespec64	total_sleep_time;
 	/* The current UTC to TAI offset in seconds */
 	s32			tai_offset;
 

commit 7c032df5570388044b4efda3d9f4d2ffb96a3116
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:04:10 2014 +0000

    timekeeping: Provide internal ktime_t based data
    
    The ktime_t based interfaces are used a lot in performance critical
    code pathes. Add ktime_t based data so the interfaces don't have to
    convert from the xtime/timespec based data.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 2cb96235c249..87e0992564f2 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -36,6 +36,9 @@ struct timekeeper {
 	/* Clock shifted nano seconds */
 	u64			xtime_nsec;
 
+	/* Monotonic base time */
+	ktime_t			base_mono;
+
 	/* Current CLOCK_REALTIME time in seconds */
 	u64			xtime_sec;
 	/* CLOCK_REALTIME to CLOCK_MONOTONIC offset */

commit 3fdb14fd1df70325e1e91e1203a699a4803ed741
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:04:07 2014 +0000

    timekeeping: Cache optimize struct timekeeper
    
    struct timekeeper is quite badly sorted for the hot readout path. Most
    time access functions need to load two cache lines.
    
    Rearrange it so ktime_get() and getnstimeofday() are happy with a
    single cache line.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 16de6d7c240a..2cb96235c249 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -10,7 +10,22 @@
 #include <linux/jiffies.h>
 #include <linux/time.h>
 
-/* Structure holding internal timekeeping values. */
+/*
+ * Structure holding internal timekeeping values.
+ *
+ * Note: wall_to_monotonic is what we need to add to xtime (or xtime
+ * corrected for sub jiffie times) to get to monotonic time.
+ * Monotonic is pegged at zero at system boot time, so
+ * wall_to_monotonic will be negative, however, we will ALWAYS keep
+ * the tv_nsec part positive so we can use the usual normalization.
+ *
+ * wall_to_monotonic is moved after resume from suspend for the
+ * monotonic time not to jump. We need to add total_sleep_time to
+ * wall_to_monotonic to get the real boot based time offset.
+ *
+ * - wall_to_monotonic is no longer the boot time, getboottime must be
+ * used instead.
+ */
 struct timekeeper {
 	/* Current clocksource used for timekeeping. */
 	struct clocksource	*clock;
@@ -18,6 +33,29 @@ struct timekeeper {
 	u32			mult;
 	/* The shift value of the current clocksource. */
 	u32			shift;
+	/* Clock shifted nano seconds */
+	u64			xtime_nsec;
+
+	/* Current CLOCK_REALTIME time in seconds */
+	u64			xtime_sec;
+	/* CLOCK_REALTIME to CLOCK_MONOTONIC offset */
+	struct timespec64	wall_to_monotonic;
+
+	/* Offset clock monotonic -> clock realtime */
+	ktime_t			offs_real;
+	/* Offset clock monotonic -> clock boottime */
+	ktime_t			offs_boot;
+	/* Offset clock monotonic -> clock tai */
+	ktime_t			offs_tai;
+
+	/* time spent in suspend */
+	struct timespec64	total_sleep_time;
+	/* The current UTC to TAI offset in seconds */
+	s32			tai_offset;
+
+	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
+	struct timespec64	raw_time;
+
 	/* Number of clock cycles in one NTP interval. */
 	cycle_t			cycle_interval;
 	/* Last cycle value (also stored in clock->cycle_last) */
@@ -29,46 +67,16 @@ struct timekeeper {
 	/* Raw nano seconds accumulated per NTP interval. */
 	u32			raw_interval;
 
-	/* Current CLOCK_REALTIME time in seconds */
-	u64			xtime_sec;
-	/* Clock shifted nano seconds */
-	u64			xtime_nsec;
-
-	/* Difference between accumulated time and NTP time in ntp
-	 * shifted nano seconds. */
+	/*
+	 * Difference between accumulated time and NTP time in ntp
+	 * shifted nano seconds.
+	 */
 	s64			ntp_error;
-	/* Shift conversion between clock shifted nano seconds and
-	 * ntp shifted nano seconds. */
-	u32			ntp_error_shift;
-
 	/*
-	 * wall_to_monotonic is what we need to add to xtime (or xtime corrected
-	 * for sub jiffie times) to get to monotonic time.  Monotonic is pegged
-	 * at zero at system boot time, so wall_to_monotonic will be negative,
-	 * however, we will ALWAYS keep the tv_nsec part positive so we can use
-	 * the usual normalization.
-	 *
-	 * wall_to_monotonic is moved after resume from suspend for the
-	 * monotonic time not to jump. We need to add total_sleep_time to
-	 * wall_to_monotonic to get the real boot based time offset.
-	 *
-	 * - wall_to_monotonic is no longer the boot time, getboottime must be
-	 * used instead.
+	 * Shift conversion between clock shifted nano seconds and
+	 * ntp shifted nano seconds.
 	 */
-	struct timespec64	wall_to_monotonic;
-	/* Offset clock monotonic -> clock realtime */
-	ktime_t			offs_real;
-	/* time spent in suspend */
-	struct timespec64	total_sleep_time;
-	/* Offset clock monotonic -> clock boottime */
-	ktime_t			offs_boot;
-	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
-	struct timespec64	raw_time;
-	/* The current UTC to TAI offset in seconds */
-	s32			tai_offset;
-	/* Offset clock monotonic -> clock tai */
-	ktime_t			offs_tai;
-
+	u32			ntp_error_shift;
 };
 
 #ifdef CONFIG_GENERIC_TIME_VSYSCALL

commit c905fae43f61c2b4508fc01722e8db61b6b8ac0b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:04:05 2014 +0000

    timekeeper: Move tk_xtime to core code
    
    No users outside of the core.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 1b05491e10f9..16de6d7c240a 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -71,16 +71,6 @@ struct timekeeper {
 
 };
 
-static inline struct timespec64 tk_xtime(struct timekeeper *tk)
-{
-	struct timespec64 ts;
-
-	ts.tv_sec = tk->xtime_sec;
-	ts.tv_nsec = (long)(tk->xtime_nsec >> tk->shift);
-	return ts;
-}
-
-
 #ifdef CONFIG_GENERIC_TIME_VSYSCALL
 
 extern void update_vsyscall(struct timekeeper *tk);
@@ -92,14 +82,6 @@ extern void update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
 				struct clocksource *c, u32 mult);
 extern void update_vsyscall_tz(void);
 
-static inline void update_vsyscall(struct timekeeper *tk)
-{
-	struct timespec xt;
-
-	xt = tk_xtime(tk);
-	update_vsyscall_old(&xt, &tk->wall_to_monotonic, tk->clock, tk->mult);
-}
-
 #else
 
 static inline void update_vsyscall(struct timekeeper *tk)

commit 7d489d15ce4be5310ca60e5896df833f9b3b4088
Author: John Stultz <john.stultz@linaro.org>
Date:   Wed Jul 16 21:04:01 2014 +0000

    timekeeping: Convert timekeeping core to use timespec64s
    
    Convert the core timekeeping logic to use timespec64s. This moves the
    2038 issues out of the core logic and into all of the accessor
    functions.
    
    Future changes will need to push the timespec64s out to all
    timekeeping users, but that can be done interface by interface.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index c1825eb436ed..1b05491e10f9 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -55,15 +55,15 @@ struct timekeeper {
 	 * - wall_to_monotonic is no longer the boot time, getboottime must be
 	 * used instead.
 	 */
-	struct timespec		wall_to_monotonic;
+	struct timespec64	wall_to_monotonic;
 	/* Offset clock monotonic -> clock realtime */
 	ktime_t			offs_real;
 	/* time spent in suspend */
-	struct timespec		total_sleep_time;
+	struct timespec64	total_sleep_time;
 	/* Offset clock monotonic -> clock boottime */
 	ktime_t			offs_boot;
 	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
-	struct timespec		raw_time;
+	struct timespec64	raw_time;
 	/* The current UTC to TAI offset in seconds */
 	s32			tai_offset;
 	/* Offset clock monotonic -> clock tai */
@@ -71,9 +71,9 @@ struct timekeeper {
 
 };
 
-static inline struct timespec tk_xtime(struct timekeeper *tk)
+static inline struct timespec64 tk_xtime(struct timekeeper *tk)
 {
-	struct timespec ts;
+	struct timespec64 ts;
 
 	ts.tv_sec = tk->xtime_sec;
 	ts.tv_nsec = (long)(tk->xtime_nsec >> tk->shift);

commit 14a3b6abe98c8f53a13522610c257accef7321df
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 21 22:51:38 2013 +0000

    timekeeping: Store cycle_last value in timekeeper struct as well
    
    For implementing a shadow timekeeper and a split calculation/update
    region we need to store the cycle_last value in the timekeeper and
    update the value in the clocksource struct only in the update region.
    
    Add the extra storage to the timekeeper.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index a151bd70e52b..c1825eb436ed 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -20,6 +20,8 @@ struct timekeeper {
 	u32			shift;
 	/* Number of clock cycles in one NTP interval. */
 	cycle_t			cycle_interval;
+	/* Last cycle value (also stored in clock->cycle_last) */
+	cycle_t			cycle_last;
 	/* Number of clock shifted nano seconds in one NTP interval. */
 	u64			xtime_interval;
 	/* shifted nano seconds left over when rounding cycle_interval */

commit 7e40672d930b369c1984457233ec5557aa53bfb8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 21 22:51:37 2013 +0000

    timekeeping: Move lock out of timekeeper struct
    
    Make the lock a separate entity. Preparatory patch for shadow
    timekeeper structure.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    [Merged with CLOCK_TAI changes]
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 26700d870506..a151bd70e52b 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -67,8 +67,6 @@ struct timekeeper {
 	/* Offset clock monotonic -> clock tai */
 	ktime_t			offs_tai;
 
-	/* Seqlock for all timekeeper values */
-	seqlock_t		lock;
 };
 
 static inline struct timespec tk_xtime(struct timekeeper *tk)

commit 90adda98b89aaf68b06014ecf805b6c477daa19b
Author: John Stultz <john.stultz@linaro.org>
Date:   Mon Jan 21 17:00:11 2013 -0800

    hrtimer: Add hrtimer support for CLOCK_TAI
    
    Add hrtimer support for CLOCK_TAI, as well as posix timer interfaces.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index ff94f436f8b7..26700d870506 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -64,6 +64,8 @@ struct timekeeper {
 	struct timespec		raw_time;
 	/* The current UTC to TAI offset in seconds */
 	s32			tai_offset;
+	/* Offset clock monotonic -> clock tai */
+	ktime_t			offs_tai;
 
 	/* Seqlock for all timekeeper values */
 	seqlock_t		lock;

commit cc244ddae6d4c6902ac9d7d64023534f8c44a7eb
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu May 3 12:30:07 2012 -0700

    timekeeping: Move TAI managment into timekeeping core from ntp
    
    Currently NTP manages the TAI offset. Since there's plans for a
    CLOCK_TAI clockid, push the TAI management into the timekeeping
    core.
    
    CC: Thomas Gleixner <tglx@linutronix.de>
    CC: Eric Dumazet <eric.dumazet@gmail.com>
    CC: Richard Cochran <richardcochran@gmail.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index e1d558e237ec..ff94f436f8b7 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -62,6 +62,9 @@ struct timekeeper {
 	ktime_t			offs_boot;
 	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
 	struct timespec		raw_time;
+	/* The current UTC to TAI offset in seconds */
+	s32			tai_offset;
+
 	/* Seqlock for all timekeeper values */
 	seqlock_t		lock;
 };

commit 576094b7f0aaf41aadab9b7d4e5bd85faa432711
Author: John Stultz <john.stultz@linaro.org>
Date:   Tue Sep 11 19:58:13 2012 -0400

    time: Introduce new GENERIC_TIME_VSYSCALL
    
    Now that we moved everyone over to GENERIC_TIME_VSYSCALL_OLD,
    introduce the new declaration and config option for the new
    update_vsyscall method.
    
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Turner <pjt@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index a904d76a5faa..e1d558e237ec 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -66,16 +66,38 @@ struct timekeeper {
 	seqlock_t		lock;
 };
 
+static inline struct timespec tk_xtime(struct timekeeper *tk)
+{
+	struct timespec ts;
+
+	ts.tv_sec = tk->xtime_sec;
+	ts.tv_nsec = (long)(tk->xtime_nsec >> tk->shift);
+	return ts;
+}
+
+
+#ifdef CONFIG_GENERIC_TIME_VSYSCALL
+
+extern void update_vsyscall(struct timekeeper *tk);
+extern void update_vsyscall_tz(void);
 
-#ifdef CONFIG_GENERIC_TIME_VSYSCALL_OLD
-extern void
-update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
-			struct clocksource *c, u32 mult);
+#elif defined(CONFIG_GENERIC_TIME_VSYSCALL_OLD)
+
+extern void update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
+				struct clocksource *c, u32 mult);
 extern void update_vsyscall_tz(void);
+
+static inline void update_vsyscall(struct timekeeper *tk)
+{
+	struct timespec xt;
+
+	xt = tk_xtime(tk);
+	update_vsyscall_old(&xt, &tk->wall_to_monotonic, tk->clock, tk->mult);
+}
+
 #else
-static inline void
-update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
-					struct clocksource *c, u32 mult)
+
+static inline void update_vsyscall(struct timekeeper *tk)
 {
 }
 static inline void update_vsyscall_tz(void)

commit 706394211648117762edfaeffd6fc04bf3b1a75d
Author: John Stultz <john.stultz@linaro.org>
Date:   Tue Sep 4 15:34:21 2012 -0400

    time: Convert CONFIG_GENERIC_TIME_VSYSCALL to CONFIG_GENERIC_TIME_VSYSCALL_OLD
    
    To help migrate archtectures over to the new update_vsyscall method,
    redfine CONFIG_GENERIC_TIME_VSYSCALL as CONFIG_GENERIC_TIME_VSYSCALL_OLD
    
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Turner <pjt@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 9c1c2cf413a6..a904d76a5faa 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -67,13 +67,14 @@ struct timekeeper {
 };
 
 
-#ifdef CONFIG_GENERIC_TIME_VSYSCALL
+#ifdef CONFIG_GENERIC_TIME_VSYSCALL_OLD
 extern void
-update_vsyscall(struct timespec *ts, struct timespec *wtm,
+update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
 			struct clocksource *c, u32 mult);
 extern void update_vsyscall_tz(void);
 #else
-static inline void update_vsyscall(struct timespec *ts, struct timespec *wtm,
+static inline void
+update_vsyscall_old(struct timespec *ts, struct timespec *wtm,
 					struct clocksource *c, u32 mult)
 {
 }

commit 189374aed657e2228ad6b39ece438c9cdafc8dae
Author: John Stultz <john.stultz@linaro.org>
Date:   Tue Sep 4 15:27:48 2012 -0400

    time: Move update_vsyscall definitions to timekeeper_internal.h
    
    Since users will need to include timekeeper_internal.h, move
    update_vsyscall definitions to timekeeper_internal.h.
    
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Turner <pjt@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
index 8ba43fa8c7e6..9c1c2cf413a6 100644
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@ -65,4 +65,21 @@ struct timekeeper {
 	/* Seqlock for all timekeeper values */
 	seqlock_t		lock;
 };
+
+
+#ifdef CONFIG_GENERIC_TIME_VSYSCALL
+extern void
+update_vsyscall(struct timespec *ts, struct timespec *wtm,
+			struct clocksource *c, u32 mult);
+extern void update_vsyscall_tz(void);
+#else
+static inline void update_vsyscall(struct timespec *ts, struct timespec *wtm,
+					struct clocksource *c, u32 mult)
+{
+}
+static inline void update_vsyscall_tz(void)
+{
+}
+#endif
+
 #endif /* _LINUX_TIMEKEEPER_INTERNAL_H */

commit d7b4202e0581683f1a14fe598633da0067f5241e
Author: John Stultz <john.stultz@linaro.org>
Date:   Tue Sep 4 15:12:07 2012 -0400

    time: Move timekeeper structure to timekeeper_internal.h for vsyscall changes
    
    We're going to need to access the timekeeper in update_vsyscall,
    so make the structure available for those who need it.
    
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Turner <pjt@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/timekeeper_internal.h b/include/linux/timekeeper_internal.h
new file mode 100644
index 000000000000..8ba43fa8c7e6
--- /dev/null
+++ b/include/linux/timekeeper_internal.h
@@ -0,0 +1,68 @@
+/*
+ * You SHOULD NOT be including this unless you're vsyscall
+ * handling code or timekeeping internal code!
+ */
+
+#ifndef _LINUX_TIMEKEEPER_INTERNAL_H
+#define _LINUX_TIMEKEEPER_INTERNAL_H
+
+#include <linux/clocksource.h>
+#include <linux/jiffies.h>
+#include <linux/time.h>
+
+/* Structure holding internal timekeeping values. */
+struct timekeeper {
+	/* Current clocksource used for timekeeping. */
+	struct clocksource	*clock;
+	/* NTP adjusted clock multiplier */
+	u32			mult;
+	/* The shift value of the current clocksource. */
+	u32			shift;
+	/* Number of clock cycles in one NTP interval. */
+	cycle_t			cycle_interval;
+	/* Number of clock shifted nano seconds in one NTP interval. */
+	u64			xtime_interval;
+	/* shifted nano seconds left over when rounding cycle_interval */
+	s64			xtime_remainder;
+	/* Raw nano seconds accumulated per NTP interval. */
+	u32			raw_interval;
+
+	/* Current CLOCK_REALTIME time in seconds */
+	u64			xtime_sec;
+	/* Clock shifted nano seconds */
+	u64			xtime_nsec;
+
+	/* Difference between accumulated time and NTP time in ntp
+	 * shifted nano seconds. */
+	s64			ntp_error;
+	/* Shift conversion between clock shifted nano seconds and
+	 * ntp shifted nano seconds. */
+	u32			ntp_error_shift;
+
+	/*
+	 * wall_to_monotonic is what we need to add to xtime (or xtime corrected
+	 * for sub jiffie times) to get to monotonic time.  Monotonic is pegged
+	 * at zero at system boot time, so wall_to_monotonic will be negative,
+	 * however, we will ALWAYS keep the tv_nsec part positive so we can use
+	 * the usual normalization.
+	 *
+	 * wall_to_monotonic is moved after resume from suspend for the
+	 * monotonic time not to jump. We need to add total_sleep_time to
+	 * wall_to_monotonic to get the real boot based time offset.
+	 *
+	 * - wall_to_monotonic is no longer the boot time, getboottime must be
+	 * used instead.
+	 */
+	struct timespec		wall_to_monotonic;
+	/* Offset clock monotonic -> clock realtime */
+	ktime_t			offs_real;
+	/* time spent in suspend */
+	struct timespec		total_sleep_time;
+	/* Offset clock monotonic -> clock boottime */
+	ktime_t			offs_boot;
+	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
+	struct timespec		raw_time;
+	/* Seqlock for all timekeeper values */
+	seqlock_t		lock;
+};
+#endif /* _LINUX_TIMEKEEPER_INTERNAL_H */
