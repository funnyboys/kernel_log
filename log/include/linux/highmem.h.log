commit 090e77e166334b83f555de408df64b9ab394ea08
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:48:18 2020 -0700

    kmap: consolidate kmap_prot definitions
    
    Most architectures define kmap_prot to be PAGE_KERNEL.
    
    Let sparc and xtensa define there own and define PAGE_KERNEL as the
    default if not overridden.
    
    [akpm@linux-foundation.org: coding style fixes]
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-16-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 091b32dff2d1..d6e82e3de027 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -40,6 +40,10 @@ extern void kunmap_atomic_high(void *kvaddr);
 static inline void kmap_flush_tlb(unsigned long addr) { }
 #endif
 
+#ifndef kmap_prot
+#define kmap_prot PAGE_KERNEL
+#endif
+
 void *kmap_high(struct page *page);
 static inline void *kmap(struct page *page)
 {

commit 7438f36310ddd9fe536fc7403187f63427cecaba
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:48:10 2020 -0700

    parisc/kmap: remove duplicate kmap code
    
    parisc reimplements the kmap calls except to flush its dcache.  This is
    arguably an abuse of kmap but regardless it is messy and confusing.
    
    Remove the duplicate code and have parisc define ARCH_HAS_FLUSH_ON_KUNMAP
    for a kunmap_flush_on_unmap() architecture specific call to flush the
    cache.
    
    Suggested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-14-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 9c559c670299..091b32dff2d1 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -130,7 +130,6 @@ static inline struct page *kmap_to_page(void *addr)
 
 static inline unsigned long totalhigh_pages(void) { return 0UL; }
 
-#ifndef ARCH_HAS_KMAP
 static inline void *kmap(struct page *page)
 {
 	might_sleep();
@@ -143,6 +142,9 @@ static inline void kunmap_high(struct page *page)
 
 static inline void kunmap(struct page *page)
 {
+#ifdef ARCH_HAS_FLUSH_ON_KUNMAP
+	kunmap_flush_on_unmap(page_address(page));
+#endif
 }
 
 static inline void *kmap_atomic(struct page *page)
@@ -156,15 +158,17 @@ static inline void *kmap_atomic(struct page *page)
 static inline void kunmap_atomic_high(void *addr)
 {
 	/*
-	 * Nothing to do in the CONFIG_HIGHMEM=n case as kunmap_atomic()
+	 * Mostly nothing to do in the CONFIG_HIGHMEM=n case as kunmap_atomic()
 	 * handles re-enabling faults + preemption
 	 */
+#ifdef ARCH_HAS_FLUSH_ON_KUNMAP
+	kunmap_flush_on_unmap(addr);
+#endif
 }
 
 #define kmap_atomic_pfn(pfn)	kmap_atomic(pfn_to_page(pfn))
 
 #define kmap_flush_unused()	do {} while(0)
-#endif
 
 #endif /* CONFIG_HIGHMEM */
 

commit 20b271dfe9d932b02b067a1f7ba9805c5b8d79bd
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:47:58 2020 -0700

    arch/kmap: define kmap_atomic_prot() for all arch's
    
    To support kmap_atomic_prot(), all architectures need to support
    protections passed to their kmap_atomic_high() function.  Pass protections
    into kmap_atomic_high() and change the name to kmap_atomic_high_prot() to
    match.
    
    Then define kmap_atomic_prot() as a core function which calls
    kmap_atomic_high_prot() when needed.
    
    Finally, redefine kmap_atomic() as a wrapper of kmap_atomic_prot() with
    the default kmap_prot exported by the architectures.
    
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-11-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 945b58d8a57b..9c559c670299 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -32,7 +32,7 @@ static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
 #include <asm/kmap_types.h>
 
 #ifdef CONFIG_HIGHMEM
-extern void *kmap_atomic_high(struct page *page);
+extern void *kmap_atomic_high_prot(struct page *page, pgprot_t prot);
 extern void kunmap_atomic_high(void *kvaddr);
 #include <asm/highmem.h>
 
@@ -77,14 +77,15 @@ static inline void kunmap(struct page *page)
  * be used in IRQ contexts, so in some (very limited) cases we need
  * it.
  */
-static inline void *kmap_atomic(struct page *page)
+static inline void *kmap_atomic_prot(struct page *page, pgprot_t prot)
 {
 	preempt_disable();
 	pagefault_disable();
 	if (!PageHighMem(page))
 		return page_address(page);
-	return kmap_atomic_high(page);
+	return kmap_atomic_high_prot(page, prot);
 }
+#define kmap_atomic(page)	kmap_atomic_prot(page, kmap_prot)
 
 /* declarations for linux/mm/highmem.c */
 unsigned int nr_free_highpages(void);

commit abca2500c0c1b20c3e552f259da4c4a99db3b4d1
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:47:46 2020 -0700

    arch/kunmap_atomic: consolidate duplicate code
    
    Every single architecture (including !CONFIG_HIGHMEM) calls...
    
            pagefault_enable();
            preempt_enable();
    
    ... before returning from __kunmap_atomic().  Lift this code into the
    kunmap_atomic() macro.
    
    While we are at it rename __kunmap_atomic() to kunmap_atomic_high() to
    be consistent.
    
    [ira.weiny@intel.com: don't enable pagefault/preempt twice]
      Link: http://lkml.kernel.org/r/20200518184843.3029640-1-ira.weiny@intel.com
    [akpm@linux-foundation.org: coding style fixes]
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-8-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index d2209ae8be99..945b58d8a57b 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -33,6 +33,7 @@ static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
 
 #ifdef CONFIG_HIGHMEM
 extern void *kmap_atomic_high(struct page *page);
+extern void kunmap_atomic_high(void *kvaddr);
 #include <asm/highmem.h>
 
 #ifndef ARCH_HAS_KMAP_FLUSH_TLB
@@ -151,10 +152,12 @@ static inline void *kmap_atomic(struct page *page)
 }
 #define kmap_atomic_prot(page, prot)	kmap_atomic(page)
 
-static inline void __kunmap_atomic(void *addr)
+static inline void kunmap_atomic_high(void *addr)
 {
-	pagefault_enable();
-	preempt_enable();
+	/*
+	 * Nothing to do in the CONFIG_HIGHMEM=n case as kunmap_atomic()
+	 * handles re-enabling faults + preemption
+	 */
 }
 
 #define kmap_atomic_pfn(pfn)	kmap_atomic(pfn_to_page(pfn))
@@ -204,7 +207,9 @@ static inline void kmap_atomic_idx_pop(void)
 #define kunmap_atomic(addr)                                     \
 do {                                                            \
 	BUILD_BUG_ON(__same_type((addr), struct page *));       \
-	__kunmap_atomic(addr);                                  \
+	kunmap_atomic_high(addr);                                  \
+	pagefault_enable();                                     \
+	preempt_enable();                                       \
 } while (0)
 
 

commit 78b6d91ec7bbfc5bcc2dd05bb2cf13c9de1dc7cd
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:47:42 2020 -0700

    arch/kmap_atomic: consolidate duplicate code
    
    Every arch has the same code to ensure atomic operations and a check for
    !HIGHMEM page.
    
    Remove the duplicate code by defining a core kmap_atomic() which only
    calls the arch specific kmap_atomic_high() when the page is high memory.
    
    [akpm@linux-foundation.org: coding style fixes]
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-7-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 216a647ed7db..d2209ae8be99 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -32,6 +32,7 @@ static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
 #include <asm/kmap_types.h>
 
 #ifdef CONFIG_HIGHMEM
+extern void *kmap_atomic_high(struct page *page);
 #include <asm/highmem.h>
 
 #ifndef ARCH_HAS_KMAP_FLUSH_TLB
@@ -62,6 +63,28 @@ static inline void kunmap(struct page *page)
 	kunmap_high(page);
 }
 
+/*
+ * kmap_atomic/kunmap_atomic is significantly faster than kmap/kunmap because
+ * no global lock is needed and because the kmap code must perform a global TLB
+ * invalidation when the kmap pool wraps.
+ *
+ * However when holding an atomic kmap is is not legal to sleep, so atomic
+ * kmaps are appropriate for short, tight code paths only.
+ *
+ * The use of kmap_atomic/kunmap_atomic is discouraged - kmap/kunmap
+ * gives a more generic (and caching) interface. But kmap_atomic can
+ * be used in IRQ contexts, so in some (very limited) cases we need
+ * it.
+ */
+static inline void *kmap_atomic(struct page *page)
+{
+	preempt_disable();
+	pagefault_disable();
+	if (!PageHighMem(page))
+		return page_address(page);
+	return kmap_atomic_high(page);
+}
+
 /* declarations for linux/mm/highmem.c */
 unsigned int nr_free_highpages(void);
 extern atomic_long_t _totalhigh_pages;

commit e23c45976f82ac789469c37e4d5a72ea2ce30bba
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:47:34 2020 -0700

    arch/kunmap: remove duplicate kunmap implementations
    
    All architectures do exactly the same thing for kunmap(); remove all the
    duplicate definitions and lift the call to the core.
    
    This also has the benefit of changing kmap_unmap() on a number of
    architectures to be an inline call rather than an actual function.
    
    [akpm@linux-foundation.org: fix CONFIG_HIGHMEM=n build on various architectures]
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-5-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index fc3adc51254a..216a647ed7db 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -52,6 +52,16 @@ static inline void *kmap(struct page *page)
 	return addr;
 }
 
+void kunmap_high(struct page *page);
+
+static inline void kunmap(struct page *page)
+{
+	might_sleep();
+	if (!PageHighMem(page))
+		return;
+	kunmap_high(page);
+}
+
 /* declarations for linux/mm/highmem.c */
 unsigned int nr_free_highpages(void);
 extern atomic_long_t _totalhigh_pages;
@@ -102,6 +112,10 @@ static inline void *kmap(struct page *page)
 	return page_address(page);
 }
 
+static inline void kunmap_high(struct page *page)
+{
+}
+
 static inline void kunmap(struct page *page)
 {
 }

commit 525aaf9bad00e7454b9f9b3873e92795afb59f8e
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:47:30 2020 -0700

    arch/kmap: remove redundant arch specific kmaps
    
    The kmap code for all the architectures is almost 100% identical.
    
    Lift the common code to the core.  Use ARCH_HAS_KMAP_FLUSH_TLB to indicate
    if an arch defines kmap_flush_tlb() and call if if needed.
    
    This also has the benefit of changing kmap() on a number of architectures
    to be an inline call rather than an actual function.
    
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-4-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index ea5cdbd8c2c3..fc3adc51254a 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -34,6 +34,24 @@ static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
 #ifdef CONFIG_HIGHMEM
 #include <asm/highmem.h>
 
+#ifndef ARCH_HAS_KMAP_FLUSH_TLB
+static inline void kmap_flush_tlb(unsigned long addr) { }
+#endif
+
+void *kmap_high(struct page *page);
+static inline void *kmap(struct page *page)
+{
+	void *addr;
+
+	might_sleep();
+	if (!PageHighMem(page))
+		addr = page_address(page);
+	else
+		addr = kmap_high(page);
+	kmap_flush_tlb((unsigned long)addr);
+	return addr;
+}
+
 /* declarations for linux/mm/highmem.c */
 unsigned int nr_free_highpages(void);
 extern atomic_long_t _totalhigh_pages;

commit ca79b0c211af63fa3276f0e3fd7dd9ada2439839
Author: Arun KS <arunks@codeaurora.org>
Date:   Fri Dec 28 00:34:29 2018 -0800

    mm: convert totalram_pages and totalhigh_pages variables to atomic
    
    totalram_pages and totalhigh_pages are made static inline function.
    
    Main motivation was that managed_page_count_lock handling was complicating
    things.  It was discussed in length here,
    https://lore.kernel.org/patchwork/patch/995739/#1181785 So it seemes
    better to remove the lock and convert variables to atomic, with preventing
    poteintial store-to-read tearing as a bonus.
    
    [akpm@linux-foundation.org: coding style fixes]
    Link: http://lkml.kernel.org/r/1542090790-21750-4-git-send-email-arunks@codeaurora.org
    Signed-off-by: Arun KS <arunks@codeaurora.org>
    Suggested-by: Michal Hocko <mhocko@suse.com>
    Suggested-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Reviewed-by: Pavel Tatashin <pasha.tatashin@soleen.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: David Hildenbrand <david@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 0690679832d4..ea5cdbd8c2c3 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -36,7 +36,31 @@ static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
 
 /* declarations for linux/mm/highmem.c */
 unsigned int nr_free_highpages(void);
-extern unsigned long totalhigh_pages;
+extern atomic_long_t _totalhigh_pages;
+static inline unsigned long totalhigh_pages(void)
+{
+	return (unsigned long)atomic_long_read(&_totalhigh_pages);
+}
+
+static inline void totalhigh_pages_inc(void)
+{
+	atomic_long_inc(&_totalhigh_pages);
+}
+
+static inline void totalhigh_pages_dec(void)
+{
+	atomic_long_dec(&_totalhigh_pages);
+}
+
+static inline void totalhigh_pages_add(long count)
+{
+	atomic_long_add(count, &_totalhigh_pages);
+}
+
+static inline void totalhigh_pages_set(long val)
+{
+	atomic_long_set(&_totalhigh_pages, val);
+}
 
 void kmap_flush_unused(void);
 
@@ -51,7 +75,7 @@ static inline struct page *kmap_to_page(void *addr)
 	return virt_to_page(addr);
 }
 
-#define totalhigh_pages 0UL
+static inline unsigned long totalhigh_pages(void) { return 0UL; }
 
 #ifndef ARCH_HAS_KMAP
 static inline void *kmap(struct page *page)

commit a4602b62d9fdea41412ba765bbf32ecfc2b6a94c
Author: Khalid Aziz <khalid.aziz@oracle.com>
Date:   Wed Feb 21 10:15:51 2018 -0700

    mm: Allow arch code to override copy_highpage()
    
    Some architectures can support metadata for memory pages and when a
    page is copied, its metadata must also be copied. Sparc processors
    from M7 onwards support metadata for memory pages. This metadata
    provides tag based protection for access to memory pages. To maintain
    this protection, the tag data must be copied to the new page when a
    page is migrated across NUMA nodes. This patch allows arch specific
    code to override default copy_highpage() and copy metadata along
    with page data upon migration.
    
    Signed-off-by: Khalid Aziz <khalid.aziz@oracle.com>
    Cc: Khalid Aziz <khalid@gonehiking.org>
    Reviewed-by: Anthony Yznaga <anthony.yznaga@oracle.com>
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 776f90f3a1cd..0690679832d4 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -237,6 +237,8 @@ static inline void copy_user_highpage(struct page *to, struct page *from,
 
 #endif
 
+#ifndef __HAVE_ARCH_COPY_HIGHPAGE
+
 static inline void copy_highpage(struct page *to, struct page *from)
 {
 	char *vfrom, *vto;
@@ -248,4 +250,6 @@ static inline void copy_highpage(struct page *to, struct page *from)
 	kunmap_atomic(vfrom);
 }
 
+#endif
+
 #endif /* _LINUX_HIGHMEM_H */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index bb3f3297062a..776f90f3a1cd 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LINUX_HIGHMEM_H
 #define _LINUX_HIGHMEM_H
 

commit 77c5b5da02f0a30d61144a546c4ef3657e3b817d
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Mon Nov 9 14:58:23 2015 -0800

    kmap_atomic_to_page() has no users, remove it
    
    Removal started in commit 5bbeed12bdc3 ("sparc32: drop unused
    kmap_atomic_to_page").  Let's do it across the whole tree.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 6aefcd0031a6..bb3f3297062a 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -78,7 +78,6 @@ static inline void __kunmap_atomic(void *addr)
 }
 
 #define kmap_atomic_pfn(pfn)	kmap_atomic(pfn_to_page(pfn))
-#define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
 
 #define kmap_flush_unused()	do {} while(0)
 #endif

commit 2cb7c9cb426660b5ed58b643d9e7dd5d50ba901f
Author: David Hildenbrand <dahi@linux.vnet.ibm.com>
Date:   Mon May 11 17:52:09 2015 +0200

    sched/preempt, mm/kmap: Explicitly disable/enable preemption in kmap_atomic_*
    
    The existing code relies on pagefault_disable() implicitly disabling
    preemption, so that no schedule will happen between kmap_atomic() and
    kunmap_atomic().
    
    Let's make this explicit, to prepare for pagefault_disable() not
    touching preemption anymore.
    
    Reviewed-and-tested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: David.Laight@ACULAB.COM
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: airlied@linux.ie
    Cc: akpm@linux-foundation.org
    Cc: benh@kernel.crashing.org
    Cc: bigeasy@linutronix.de
    Cc: borntraeger@de.ibm.com
    Cc: daniel.vetter@intel.com
    Cc: heiko.carstens@de.ibm.com
    Cc: herbert@gondor.apana.org.au
    Cc: hocko@suse.cz
    Cc: hughd@google.com
    Cc: mst@redhat.com
    Cc: paulus@samba.org
    Cc: ralf@linux-mips.org
    Cc: schwidefsky@de.ibm.com
    Cc: yang.shi@windriver.com
    Link: http://lkml.kernel.org/r/1431359540-32227-5-git-send-email-dahi@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 9286a46b7d69..6aefcd0031a6 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -65,6 +65,7 @@ static inline void kunmap(struct page *page)
 
 static inline void *kmap_atomic(struct page *page)
 {
+	preempt_disable();
 	pagefault_disable();
 	return page_address(page);
 }
@@ -73,6 +74,7 @@ static inline void *kmap_atomic(struct page *page)
 static inline void __kunmap_atomic(void *addr)
 {
 	pagefault_enable();
+	preempt_enable();
 }
 
 #define kmap_atomic_pfn(pfn)	kmap_atomic(pfn_to_page(pfn))

commit 1d352bfd41e8219cdf9bebe79677700bdc38b540
Author: Chintan Pandya <cpandya@codeaurora.org>
Date:   Wed Aug 6 16:08:18 2014 -0700

    mm: BUG when __kmap_atomic_idx equals KM_TYPE_NR
    
    __kmap_atomic_idx is per_cpu variable.  Each CPU can use KM_TYPE_NR
    entries from FIXMAP i.e.  from 0 to KM_TYPE_NR - 1.  Allowing
    __kmap_atomic_idx to over- shoot to KM_TYPE_NR can mess up with next
    CPU's 0th entry which is a bug.  Hence BUG_ON if __kmap_atomic_idx >=
    KM_TYPE_NR.
    
    Fix the off-by-on in this test.
    
    Signed-off-by: Chintan Pandya <cpandya@codeaurora.org>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 7fb31da45d03..9286a46b7d69 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -93,7 +93,7 @@ static inline int kmap_atomic_idx_push(void)
 
 #ifdef CONFIG_DEBUG_HIGHMEM
 	WARN_ON_ONCE(in_irq() && !irqs_disabled());
-	BUG_ON(idx > KM_TYPE_NR);
+	BUG_ON(idx >= KM_TYPE_NR);
 #endif
 	return idx;
 }

commit cf82f3489cf414fe27c6c5af2b372fdcd2a58b24
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Feb 22 16:34:24 2013 -0800

    mm: remove unused memclear_highpage_flush()
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index ef788b5b4a35..7fb31da45d03 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -219,12 +219,6 @@ static inline void zero_user(struct page *page,
 	zero_user_segments(page, start, start + size, 0, 0);
 }
 
-static inline void __deprecated memclear_highpage_flush(struct page *page,
-			unsigned int offset, unsigned int size)
-{
-	zero_user(page, offset, size);
-}
-
 #ifndef __HAVE_ARCH_COPY_USER_HIGHPAGE
 
 static inline void copy_user_highpage(struct page *to, struct page *from,

commit 5a178119b0fbe37f7dfb602b37df9cc4b1dc9d71
Author: Mel Gorman <mgorman@suse.de>
Date:   Tue Jul 31 16:45:02 2012 -0700

    mm: add support for direct_IO to highmem pages
    
    The patch "mm: add support for a filesystem to activate swap files and use
    direct_IO for writing swap pages" added support for using direct_IO to
    write swap pages but it is insufficient for highmem pages.
    
    To support highmem pages, this patch kmaps() the page before calling the
    direct_IO() handler.  As direct_IO deals with virtual addresses an
    additional helper is necessary for get_kernel_pages() to lookup the struct
    page for a kmap virtual address.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Rik van Riel <riel@redhat.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Eric B Munson <emunson@mgebm.net>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: Xiaotian Feng <dfeng@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 774fa47b3b5b..ef788b5b4a35 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -39,10 +39,17 @@ extern unsigned long totalhigh_pages;
 
 void kmap_flush_unused(void);
 
+struct page *kmap_to_page(void *addr);
+
 #else /* CONFIG_HIGHMEM */
 
 static inline unsigned int nr_free_highpages(void) { return 0; }
 
+static inline struct page *kmap_to_page(void *addr)
+{
+	return virt_to_page(addr);
+}
+
 #define totalhigh_pages 0UL
 
 #ifndef ARCH_HAS_KMAP

commit 1285e4c8a751a7aedeb6bd35d2c08794e088b908
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Jun 22 23:17:53 2012 +0800

    highmem: remove the deprecated form of kmap_atomic
    
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index d3999b4e26cc..774fa47b3b5b 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -109,55 +109,16 @@ static inline void kmap_atomic_idx_pop(void)
 
 #endif
 
-/*
- * NOTE:
- * kmap_atomic() and kunmap_atomic() with two arguments are deprecated.
- * We only keep them for backward compatibility, any usage of them
- * are now warned.
- */
-
-#define PASTE(a, b) a ## b
-#define PASTE2(a, b) PASTE(a, b)
-
-#define NARG_(_2, _1, n, ...) n
-#define NARG(...) NARG_(__VA_ARGS__, 2, 1, :)
-
-static inline void __deprecated *kmap_atomic_deprecated(struct page *page,
-							enum km_type km)
-{
-	return kmap_atomic(page);
-}
-
-#define kmap_atomic1(...) kmap_atomic(__VA_ARGS__)
-#define kmap_atomic2(...) kmap_atomic_deprecated(__VA_ARGS__)
-#define kmap_atomic(...) PASTE2(kmap_atomic, NARG(__VA_ARGS__)(__VA_ARGS__))
-
-static inline void __deprecated __kunmap_atomic_deprecated(void *addr,
-							enum km_type km)
-{
-	__kunmap_atomic(addr);
-}
-
 /*
  * Prevent people trying to call kunmap_atomic() as if it were kunmap()
  * kunmap_atomic() should get the return value of kmap_atomic, not the page.
  */
-#define kunmap_atomic_deprecated(addr, km)                      \
-do {                                                            \
-	BUILD_BUG_ON(__same_type((addr), struct page *));       \
-	__kunmap_atomic_deprecated(addr, km);                   \
-} while (0)
-
-#define kunmap_atomic_withcheck(addr)                           \
+#define kunmap_atomic(addr)                                     \
 do {                                                            \
 	BUILD_BUG_ON(__same_type((addr), struct page *));       \
 	__kunmap_atomic(addr);                                  \
 } while (0)
 
-#define kunmap_atomic1(...) kunmap_atomic_withcheck(__VA_ARGS__)
-#define kunmap_atomic2(...) kunmap_atomic_deprecated(__VA_ARGS__)
-#define kunmap_atomic(...) PASTE2(kunmap_atomic, NARG(__VA_ARGS__)(__VA_ARGS__))
-/**** End of C pre-processor tricks for deprecated macros ****/
 
 /* when CONFIG_HIGHMEM is not set these will be plain clear/copy_page */
 #ifndef clear_user_highpage

commit ed2d265d1266736bd294332d7f649003943ae36e
Merge: f1d38e423a69 6c03438edeb5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 24 10:08:39 2012 -0700

    Merge tag 'bug-for-3.4' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    Pull <linux/bug.h> cleanup from Paul Gortmaker:
     "The changes shown here are to unify linux's BUG support under the one
      <linux/bug.h> file.  Due to historical reasons, we have some BUG code
      in bug.h and some in kernel.h -- i.e.  the support for BUILD_BUG in
      linux/kernel.h predates the addition of linux/bug.h, but old code in
      kernel.h wasn't moved to bug.h at that time.  As a band-aid, kernel.h
      was including <asm/bug.h> to pseudo link them.
    
      This has caused confusion[1] and general yuck/WTF[2] reactions.  Here
      is an example that violates the principle of least surprise:
    
          CC      lib/string.o
          lib/string.c: In function 'strlcat':
          lib/string.c:225:2: error: implicit declaration of function 'BUILD_BUG_ON'
          make[2]: *** [lib/string.o] Error 1
          $
          $ grep linux/bug.h lib/string.c
          #include <linux/bug.h>
          $
    
      We've included <linux/bug.h> for the BUG infrastructure and yet we
      still get a compile fail! [We've not kernel.h for BUILD_BUG_ON.] Ugh -
      very confusing for someone who is new to kernel development.
    
      With the above in mind, the goals of this changeset are:
    
      1) find and fix any include/*.h files that were relying on the
         implicit presence of BUG code.
      2) find and fix any C files that were consuming kernel.h and hence
         relying on implicitly getting some/all BUG code.
      3) Move the BUG related code living in kernel.h to <linux/bug.h>
      4) remove the asm/bug.h from kernel.h to finally break the chain.
    
      During development, the order was more like 3-4, build-test, 1-2.  But
      to ensure that git history for bisect doesn't get needless build
      failures introduced, the commits have been reorderd to fix the problem
      areas in advance.
    
            [1]  https://lkml.org/lkml/2012/1/3/90
            [2]  https://lkml.org/lkml/2012/1/17/414"
    
    Fix up conflicts (new radeon file, reiserfs header cleanups) as per Paul
    and linux-next.
    
    * tag 'bug-for-3.4' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux:
      kernel.h: doesn't explicitly use bug.h, so don't include it.
      bug: consolidate BUILD_BUG_ON with other bug code
      BUG: headers with BUG/BUG_ON etc. need linux/bug.h
      bug.h: add include of it to various implicit C users
      lib: fix implicit users of kernel.h for TAINT_WARN
      spinlock: macroize assert_spin_locked to avoid bug.h dependency
      x86: relocate get/set debugreg fcns to include/asm/debugreg.

commit a24401bcf4a67c8fe17e649e74eeb09b08b79ef5
Author: Cong Wang <amwang@redhat.com>
Date:   Sat Nov 26 10:53:39 2011 +0800

    highmem: kill all __kmap_atomic()
    [swarren@nvidia.com: highmem: Fix ARM build break due to __kmap_atomic rename]
    
    Signed-off-by: Stephen Warren <swarren@nvidia.com>
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 284ec5535f3d..6549ed75e0a7 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -55,12 +55,12 @@ static inline void kunmap(struct page *page)
 {
 }
 
-static inline void *__kmap_atomic(struct page *page)
+static inline void *kmap_atomic(struct page *page)
 {
 	pagefault_disable();
 	return page_address(page);
 }
-#define kmap_atomic_prot(page, prot)	__kmap_atomic(page)
+#define kmap_atomic_prot(page, prot)	kmap_atomic(page)
 
 static inline void __kunmap_atomic(void *addr)
 {
@@ -121,15 +121,10 @@ static inline void kmap_atomic_idx_pop(void)
 #define NARG_(_2, _1, n, ...) n
 #define NARG(...) NARG_(__VA_ARGS__, 2, 1, :)
 
-static inline void *kmap_atomic(struct page *page)
-{
-	return __kmap_atomic(page);
-}
-
 static inline void __deprecated *kmap_atomic_deprecated(struct page *page,
 							enum km_type km)
 {
-	return __kmap_atomic(page);
+	return kmap_atomic(page);
 }
 
 #define kmap_atomic1(...) kmap_atomic(__VA_ARGS__)

commit 1ec9c5ddc17aa398f05646abfcbaf315b544e62f
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 23:14:14 2011 +0800

    include/linux/highmem.h: remove the second argument of k[un]map_atomic()
    
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 11617a835cf2..284ec5535f3d 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -167,9 +167,9 @@ do {                                                            \
 #ifndef clear_user_highpage
 static inline void clear_user_highpage(struct page *page, unsigned long vaddr)
 {
-	void *addr = kmap_atomic(page, KM_USER0);
+	void *addr = kmap_atomic(page);
 	clear_user_page(addr, vaddr, page);
-	kunmap_atomic(addr, KM_USER0);
+	kunmap_atomic(addr);
 }
 #endif
 
@@ -220,16 +220,16 @@ alloc_zeroed_user_highpage_movable(struct vm_area_struct *vma,
 
 static inline void clear_highpage(struct page *page)
 {
-	void *kaddr = kmap_atomic(page, KM_USER0);
+	void *kaddr = kmap_atomic(page);
 	clear_page(kaddr);
-	kunmap_atomic(kaddr, KM_USER0);
+	kunmap_atomic(kaddr);
 }
 
 static inline void zero_user_segments(struct page *page,
 	unsigned start1, unsigned end1,
 	unsigned start2, unsigned end2)
 {
-	void *kaddr = kmap_atomic(page, KM_USER0);
+	void *kaddr = kmap_atomic(page);
 
 	BUG_ON(end1 > PAGE_SIZE || end2 > PAGE_SIZE);
 
@@ -239,7 +239,7 @@ static inline void zero_user_segments(struct page *page,
 	if (end2 > start2)
 		memset(kaddr + start2, 0, end2 - start2);
 
-	kunmap_atomic(kaddr, KM_USER0);
+	kunmap_atomic(kaddr);
 	flush_dcache_page(page);
 }
 
@@ -268,11 +268,11 @@ static inline void copy_user_highpage(struct page *to, struct page *from,
 {
 	char *vfrom, *vto;
 
-	vfrom = kmap_atomic(from, KM_USER0);
-	vto = kmap_atomic(to, KM_USER1);
+	vfrom = kmap_atomic(from);
+	vto = kmap_atomic(to);
 	copy_user_page(vto, vfrom, vaddr, to);
-	kunmap_atomic(vto, KM_USER1);
-	kunmap_atomic(vfrom, KM_USER0);
+	kunmap_atomic(vto);
+	kunmap_atomic(vfrom);
 }
 
 #endif
@@ -281,11 +281,11 @@ static inline void copy_highpage(struct page *to, struct page *from)
 {
 	char *vfrom, *vto;
 
-	vfrom = kmap_atomic(from, KM_USER0);
-	vto = kmap_atomic(to, KM_USER1);
+	vfrom = kmap_atomic(from);
+	vto = kmap_atomic(to);
 	copy_page(vto, vfrom);
-	kunmap_atomic(vto, KM_USER1);
-	kunmap_atomic(vfrom, KM_USER0);
+	kunmap_atomic(vto);
+	kunmap_atomic(vfrom);
 }
 
 #endif /* _LINUX_HIGHMEM_H */

commit 980c19e3f8ca1d5d43cce588059ea78cac27062a
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 22:08:45 2011 +0800

    highmem: mark k[un]map_atomic() with two arguments as deprecated
    
    For backward compatibility, we still keep the deprecated form,
    and will warn the users if they still use the deprecated one, like this:
    
    drivers/block/drbd/drbd_bitmap.c: In function ‘bm_page_io_async’:
    drivers/block/drbd/drbd_bitmap.c:973:3: warning: ‘kmap_atomic_deprecated’ is deprecated (declared at /home/wangcong/linux-2.6/include/linux/highmem.h:124)
    drivers/block/drbd/drbd_bitmap.c:977:3: warning: ‘kunmap_atomic_deprecated’ is deprecated (declared at /home/wangcong/linux-2.6/include/linux/highmem.h:144)
    
    Thanks to Nick Bowler for the cpp trick!
    
    Cc: Cesar Eduardo Barros <cesarb@cesarb.net>
    Cc: Nick Bowler <nbowler@elliptictech.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 3a93f73a8acc..11617a835cf2 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -109,20 +109,60 @@ static inline void kmap_atomic_idx_pop(void)
 #endif
 
 /*
- * Make both: kmap_atomic(page, idx) and kmap_atomic(page) work.
+ * NOTE:
+ * kmap_atomic() and kunmap_atomic() with two arguments are deprecated.
+ * We only keep them for backward compatibility, any usage of them
+ * are now warned.
  */
-#define kmap_atomic(page, args...) __kmap_atomic(page)
+
+#define PASTE(a, b) a ## b
+#define PASTE2(a, b) PASTE(a, b)
+
+#define NARG_(_2, _1, n, ...) n
+#define NARG(...) NARG_(__VA_ARGS__, 2, 1, :)
+
+static inline void *kmap_atomic(struct page *page)
+{
+	return __kmap_atomic(page);
+}
+
+static inline void __deprecated *kmap_atomic_deprecated(struct page *page,
+							enum km_type km)
+{
+	return __kmap_atomic(page);
+}
+
+#define kmap_atomic1(...) kmap_atomic(__VA_ARGS__)
+#define kmap_atomic2(...) kmap_atomic_deprecated(__VA_ARGS__)
+#define kmap_atomic(...) PASTE2(kmap_atomic, NARG(__VA_ARGS__)(__VA_ARGS__))
+
+static inline void __deprecated __kunmap_atomic_deprecated(void *addr,
+							enum km_type km)
+{
+	__kunmap_atomic(addr);
+}
 
 /*
  * Prevent people trying to call kunmap_atomic() as if it were kunmap()
  * kunmap_atomic() should get the return value of kmap_atomic, not the page.
  */
-#define kunmap_atomic(addr, args...)				\
-do {								\
-	BUILD_BUG_ON(__same_type((addr), struct page *));	\
-	__kunmap_atomic(addr);					\
+#define kunmap_atomic_deprecated(addr, km)                      \
+do {                                                            \
+	BUILD_BUG_ON(__same_type((addr), struct page *));       \
+	__kunmap_atomic_deprecated(addr, km);                   \
 } while (0)
 
+#define kunmap_atomic_withcheck(addr)                           \
+do {                                                            \
+	BUILD_BUG_ON(__same_type((addr), struct page *));       \
+	__kunmap_atomic(addr);                                  \
+} while (0)
+
+#define kunmap_atomic1(...) kunmap_atomic_withcheck(__VA_ARGS__)
+#define kunmap_atomic2(...) kunmap_atomic_deprecated(__VA_ARGS__)
+#define kunmap_atomic(...) PASTE2(kunmap_atomic, NARG(__VA_ARGS__)(__VA_ARGS__))
+/**** End of C pre-processor tricks for deprecated macros ****/
+
 /* when CONFIG_HIGHMEM is not set these will be plain clear/copy_page */
 #ifndef clear_user_highpage
 static inline void clear_user_highpage(struct page *page, unsigned long vaddr)

commit 187f1882b5b0748b3c4c22274663fdb372ac0452
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Nov 23 20:12:59 2011 -0500

    BUG: headers with BUG/BUG_ON etc. need linux/bug.h
    
    If a header file is making use of BUG, BUG_ON, BUILD_BUG_ON, or any
    other BUG variant in a static inline (i.e. not in a #define) then
    that header really should be including <linux/bug.h> and not just
    expecting it to be implicitly present.
    
    We can make this change risk-free, since if the files using these
    headers didn't have exposure to linux/bug.h already, they would have
    been causing compile failures/warnings.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 3a93f73a8acc..6ede661e5b8e 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -3,6 +3,7 @@
 
 #include <linux/fs.h>
 #include <linux/kernel.h>
+#include <linux/bug.h>
 #include <linux/mm.h>
 #include <linux/uaccess.h>
 #include <linux/hardirq.h>

commit cfb824349556904b319464139be5c75fce983b0d
Author: Christoph Lameter <cl@linux.com>
Date:   Mon Dec 6 11:40:03 2010 -0600

    highmem: Use this_cpu_xx_return() operations
    
    Use this_cpu operations to optimize access primitives for highmem.
    
    The main effect is the avoidance of address calculations through the
    use of a segment prefix.
    
    V3->V4
            - kmap_atomic_idx: Do not return a value.
            - Use __this_cpu_dec without HIGHMEM_DEBUG
    
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index b676c585574e..3a93f73a8acc 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -81,7 +81,8 @@ DECLARE_PER_CPU(int, __kmap_atomic_idx);
 
 static inline int kmap_atomic_idx_push(void)
 {
-	int idx = __get_cpu_var(__kmap_atomic_idx)++;
+	int idx = __this_cpu_inc_return(__kmap_atomic_idx) - 1;
+
 #ifdef CONFIG_DEBUG_HIGHMEM
 	WARN_ON_ONCE(in_irq() && !irqs_disabled());
 	BUG_ON(idx > KM_TYPE_NR);
@@ -91,16 +92,18 @@ static inline int kmap_atomic_idx_push(void)
 
 static inline int kmap_atomic_idx(void)
 {
-	return __get_cpu_var(__kmap_atomic_idx) - 1;
+	return __this_cpu_read(__kmap_atomic_idx) - 1;
 }
 
-static inline int kmap_atomic_idx_pop(void)
+static inline void kmap_atomic_idx_pop(void)
 {
-	int idx = --__get_cpu_var(__kmap_atomic_idx);
 #ifdef CONFIG_DEBUG_HIGHMEM
+	int idx = __this_cpu_dec_return(__kmap_atomic_idx);
+
 	BUG_ON(idx < 0);
+#else
+	__this_cpu_dec(__kmap_atomic_idx);
 #endif
-	return idx;
 }
 
 #endif

commit 43b3a0c732776746f53d8ed2ba659583fc1692aa
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Nov 11 14:05:10 2010 -0800

    include/linux/highmem.h needs hardirq.h
    
    Commit 3e4d3af501cc ("mm: stack based kmap_atomic()") introduced the
    kmap_atomic_idx_push() function which warns on in_irq() with
    CONFIG_DEBUG_HIGHMEM enabled.  This patch includes linux/hardirq.h for
    the in_irq definition.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index e9138198e823..b676c585574e 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -5,6 +5,7 @@
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/uaccess.h>
+#include <linux/hardirq.h>
 
 #include <asm/cacheflush.h>
 

commit 20273941f2129aa5a432796d98a276ed73d60782
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Wed Oct 27 15:32:58 2010 -0700

    mm: fix race in kunmap_atomic()
    
    Christoph reported a nice splat which illustrated a race in the new stack
    based kmap_atomic implementation.
    
    The problem is that we pop our stack slot before we're completely done
    resetting its state -- in particular clearing the PTE (sometimes that's
    CONFIG_DEBUG_HIGHMEM).  If an interrupt happens before we actually clear
    the PTE used for the last slot, that interrupt can reuse the slot in a
    dirty state, which triggers a BUG in kmap_atomic().
    
    Fix this by introducing kmap_atomic_idx() which reports the current slot
    index without actually releasing it and use that to find the PTE and delay
    the _pop() until after we're completely done.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Reported-by: Christoph Hellwig <hch@infradead.org>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 102f76be90da..e9138198e823 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -88,6 +88,11 @@ static inline int kmap_atomic_idx_push(void)
 	return idx;
 }
 
+static inline int kmap_atomic_idx(void)
+{
+	return __get_cpu_var(__kmap_atomic_idx) - 1;
+}
+
 static inline int kmap_atomic_idx_pop(void)
 {
 	int idx = --__get_cpu_var(__kmap_atomic_idx);

commit a8e23a291852cd7c4fb5ca696dbb93912185ad10
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Wed Oct 27 15:32:57 2010 -0700

    mm,x86: fix kmap_atomic_push vs ioremap_32.c
    
    It appears i386 uses kmap_atomic infrastructure regardless of
    CONFIG_HIGHMEM which results in a compile error when highmem is disabled.
    
    Cure this by providing the needed few bits for both CONFIG_HIGHMEM and
    CONFIG_X86_32.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Reported-by: Chris Wilson <chris@chris-wilson.co.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 8a85ec109a3a..102f76be90da 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -37,27 +37,6 @@ extern unsigned long totalhigh_pages;
 
 void kmap_flush_unused(void);
 
-DECLARE_PER_CPU(int, __kmap_atomic_idx);
-
-static inline int kmap_atomic_idx_push(void)
-{
-	int idx = __get_cpu_var(__kmap_atomic_idx)++;
-#ifdef CONFIG_DEBUG_HIGHMEM
-	WARN_ON_ONCE(in_irq() && !irqs_disabled());
-	BUG_ON(idx > KM_TYPE_NR);
-#endif
-	return idx;
-}
-
-static inline int kmap_atomic_idx_pop(void)
-{
-	int idx = --__get_cpu_var(__kmap_atomic_idx);
-#ifdef CONFIG_DEBUG_HIGHMEM
-	BUG_ON(idx < 0);
-#endif
-	return idx;
-}
-
 #else /* CONFIG_HIGHMEM */
 
 static inline unsigned int nr_free_highpages(void) { return 0; }
@@ -95,6 +74,31 @@ static inline void __kunmap_atomic(void *addr)
 
 #endif /* CONFIG_HIGHMEM */
 
+#if defined(CONFIG_HIGHMEM) || defined(CONFIG_X86_32)
+
+DECLARE_PER_CPU(int, __kmap_atomic_idx);
+
+static inline int kmap_atomic_idx_push(void)
+{
+	int idx = __get_cpu_var(__kmap_atomic_idx)++;
+#ifdef CONFIG_DEBUG_HIGHMEM
+	WARN_ON_ONCE(in_irq() && !irqs_disabled());
+	BUG_ON(idx > KM_TYPE_NR);
+#endif
+	return idx;
+}
+
+static inline int kmap_atomic_idx_pop(void)
+{
+	int idx = --__get_cpu_var(__kmap_atomic_idx);
+#ifdef CONFIG_DEBUG_HIGHMEM
+	BUG_ON(idx < 0);
+#endif
+	return idx;
+}
+
+#endif
+
 /*
  * Make both: kmap_atomic(page, idx) and kmap_atomic(page) work.
  */

commit 3e4d3af501cccdc8a8cca41bdbe57d54ad7e7e73
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue Oct 26 14:21:51 2010 -0700

    mm: stack based kmap_atomic()
    
    Keep the current interface but ignore the KM_type and use a stack based
    approach.
    
    The advantage is that we get rid of crappy code like:
    
            #define __KM_PTE                        \
                    (in_nmi() ? KM_NMI_PTE :        \
                     in_irq() ? KM_IRQ_PTE :        \
                     KM_PTE0)
    
    and in general can stop worrying about what context we're in and what kmap
    slots might be appropriate for that.
    
    The downside is that FRV kmap_atomic() gets more expensive.
    
    For now we use a CPP trick suggested by Andrew:
    
      #define kmap_atomic(page, args...) __kmap_atomic(page)
    
    to avoid having to touch all kmap_atomic() users in a single patch.
    
    [ not compiled on:
      - mn10300: the arch doesn't actually build with highmem to begin with ]
    
    [akpm@linux-foundation.org: coding-style fixes]
    [akpm@linux-foundation.org: fix up drivers/gpu/drm/i915/intel_overlay.c]
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Chris Metcalf <cmetcalf@tilera.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Miller <davem@davemloft.net>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Dave Airlie <airlied@linux.ie>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 283cd47bb34c..8a85ec109a3a 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -28,18 +28,6 @@ static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
 
 #include <asm/kmap_types.h>
 
-#ifdef CONFIG_DEBUG_HIGHMEM
-
-void debug_kmap_atomic(enum km_type type);
-
-#else
-
-static inline void debug_kmap_atomic(enum km_type type)
-{
-}
-
-#endif
-
 #ifdef CONFIG_HIGHMEM
 #include <asm/highmem.h>
 
@@ -49,6 +37,27 @@ extern unsigned long totalhigh_pages;
 
 void kmap_flush_unused(void);
 
+DECLARE_PER_CPU(int, __kmap_atomic_idx);
+
+static inline int kmap_atomic_idx_push(void)
+{
+	int idx = __get_cpu_var(__kmap_atomic_idx)++;
+#ifdef CONFIG_DEBUG_HIGHMEM
+	WARN_ON_ONCE(in_irq() && !irqs_disabled());
+	BUG_ON(idx > KM_TYPE_NR);
+#endif
+	return idx;
+}
+
+static inline int kmap_atomic_idx_pop(void)
+{
+	int idx = --__get_cpu_var(__kmap_atomic_idx);
+#ifdef CONFIG_DEBUG_HIGHMEM
+	BUG_ON(idx < 0);
+#endif
+	return idx;
+}
+
 #else /* CONFIG_HIGHMEM */
 
 static inline unsigned int nr_free_highpages(void) { return 0; }
@@ -66,19 +75,19 @@ static inline void kunmap(struct page *page)
 {
 }
 
-static inline void *kmap_atomic(struct page *page, enum km_type idx)
+static inline void *__kmap_atomic(struct page *page)
 {
 	pagefault_disable();
 	return page_address(page);
 }
-#define kmap_atomic_prot(page, idx, prot)	kmap_atomic(page, idx)
+#define kmap_atomic_prot(page, prot)	__kmap_atomic(page)
 
-static inline void kunmap_atomic_notypecheck(void *addr, enum km_type idx)
+static inline void __kunmap_atomic(void *addr)
 {
 	pagefault_enable();
 }
 
-#define kmap_atomic_pfn(pfn, idx)	kmap_atomic(pfn_to_page(pfn), (idx))
+#define kmap_atomic_pfn(pfn)	kmap_atomic(pfn_to_page(pfn))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
 
 #define kmap_flush_unused()	do {} while(0)
@@ -86,12 +95,20 @@ static inline void kunmap_atomic_notypecheck(void *addr, enum km_type idx)
 
 #endif /* CONFIG_HIGHMEM */
 
-/* Prevent people trying to call kunmap_atomic() as if it were kunmap() */
-/* kunmap_atomic() should get the return value of kmap_atomic, not the page. */
-#define kunmap_atomic(addr, idx) do { \
-		BUILD_BUG_ON(__same_type((addr), struct page *)); \
-		kunmap_atomic_notypecheck((addr), (idx)); \
-	} while (0)
+/*
+ * Make both: kmap_atomic(page, idx) and kmap_atomic(page) work.
+ */
+#define kmap_atomic(page, args...) __kmap_atomic(page)
+
+/*
+ * Prevent people trying to call kunmap_atomic() as if it were kunmap()
+ * kunmap_atomic() should get the return value of kmap_atomic, not the page.
+ */
+#define kunmap_atomic(addr, args...)				\
+do {								\
+	BUILD_BUG_ON(__same_type((addr), struct page *));	\
+	__kunmap_atomic(addr);					\
+} while (0)
 
 /* when CONFIG_HIGHMEM is not set these will be plain clear/copy_page */
 #ifndef clear_user_highpage

commit 61ecdb801ef2cd28e32442383106d7837d76deac
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue Oct 26 14:21:47 2010 -0700

    mm: strictly nested kmap_atomic()
    
    Ensure kmap_atomic() usage is strictly nested
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Acked-by: Chris Metcalf <cmetcalf@tilera.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Miller <davem@davemloft.net>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index e3060ef85b6d..283cd47bb34c 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -201,8 +201,8 @@ static inline void copy_user_highpage(struct page *to, struct page *from,
 	vfrom = kmap_atomic(from, KM_USER0);
 	vto = kmap_atomic(to, KM_USER1);
 	copy_user_page(vto, vfrom, vaddr, to);
-	kunmap_atomic(vfrom, KM_USER0);
 	kunmap_atomic(vto, KM_USER1);
+	kunmap_atomic(vfrom, KM_USER0);
 }
 
 #endif
@@ -214,8 +214,8 @@ static inline void copy_highpage(struct page *to, struct page *from)
 	vfrom = kmap_atomic(from, KM_USER0);
 	vto = kmap_atomic(to, KM_USER1);
 	copy_page(vto, vfrom);
-	kunmap_atomic(vfrom, KM_USER0);
 	kunmap_atomic(vto, KM_USER1);
+	kunmap_atomic(vfrom, KM_USER0);
 }
 
 #endif /* _LINUX_HIGHMEM_H */

commit 4e60c86bd9e5a7110ed28874d0b6592186550ae8
Author: Andi Kleen <andi@firstfloor.org>
Date:   Mon Aug 9 17:19:03 2010 -0700

    gcc-4.6: mm: fix unused but set warnings
    
    No real bugs, just some dead code and some fixups.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 67460f010224..e3060ef85b6d 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -73,7 +73,11 @@ static inline void *kmap_atomic(struct page *page, enum km_type idx)
 }
 #define kmap_atomic_prot(page, idx, prot)	kmap_atomic(page, idx)
 
-#define kunmap_atomic_notypecheck(addr, idx)	do { pagefault_enable(); } while (0)
+static inline void kunmap_atomic_notypecheck(void *addr, enum km_type idx)
+{
+	pagefault_enable();
+}
+
 #define kmap_atomic_pfn(pfn, idx)	kmap_atomic(pfn_to_page(pfn), (idx))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
 

commit 597781f3e51f48ef8e67be772196d9e9673752c4
Author: Cesar Eduardo Barros <cesarb@cesarb.net>
Date:   Mon Aug 9 17:18:32 2010 -0700

    kmap_atomic: make kunmap_atomic() harder to misuse
    
    kunmap_atomic() is currently at level -4 on Rusty's "Hard To Misuse"
    list[1] ("Follow common convention and you'll get it wrong"), except in
    some architectures when CONFIG_DEBUG_HIGHMEM is set[2][3].
    
    kunmap() takes a pointer to a struct page; kunmap_atomic(), however, takes
    takes a pointer to within the page itself.  This seems to once in a while
    trip people up (the convention they are following is the one from
    kunmap()).
    
    Make it much harder to misuse, by moving it to level 9 on Rusty's list[4]
    ("The compiler/linker won't let you get it wrong").  This is done by
    refusing to build if the type of its first argument is a pointer to a
    struct page.
    
    The real kunmap_atomic() is renamed to kunmap_atomic_notypecheck()
    (which is what you would call in case for some strange reason calling it
    with a pointer to a struct page is not incorrect in your code).
    
    The previous version of this patch was compile tested on x86-64.
    
    [1] http://ozlabs.org/~rusty/index.cgi/tech/2008-04-01.html
    [2] In these cases, it is at level 5, "Do it right or it will always
        break at runtime."
    [3] At least mips and powerpc look very similar, and sparc also seems to
        share a common ancestor with both; there seems to be quite some
        degree of copy-and-paste coding here. The include/asm/highmem.h file
        for these three archs mention x86 CPUs at its top.
    [4] http://ozlabs.org/~rusty/index.cgi/tech/2008-03-30.html
    [5] As an aside, could someone tell me why mn10300 uses unsigned long as
        the first parameter of kunmap_atomic() instead of void *?
    
    Signed-off-by: Cesar Eduardo Barros <cesarb@cesarb.net>
    Cc: Russell King <linux@arm.linux.org.uk> (arch/arm)
    Cc: Ralf Baechle <ralf@linux-mips.org> (arch/mips)
    Cc: David Howells <dhowells@redhat.com> (arch/frv, arch/mn10300)
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com> (arch/mn10300)
    Cc: Kyle McMartin <kyle@mcmartin.ca> (arch/parisc)
    Cc: Helge Deller <deller@gmx.de> (arch/parisc)
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org> (arch/parisc)
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org> (arch/powerpc)
    Cc: Paul Mackerras <paulus@samba.org> (arch/powerpc)
    Cc: "David S. Miller" <davem@davemloft.net> (arch/sparc)
    Cc: Thomas Gleixner <tglx@linutronix.de> (arch/x86)
    Cc: Ingo Molnar <mingo@redhat.com> (arch/x86)
    Cc: "H. Peter Anvin" <hpa@zytor.com> (arch/x86)
    Cc: Arnd Bergmann <arnd@arndb.de> (include/asm-generic)
    Cc: Rusty Russell <rusty@rustcorp.com.au> ("Hard To Misuse" list)
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index caafd0561aa1..67460f010224 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -2,6 +2,7 @@
 #define _LINUX_HIGHMEM_H
 
 #include <linux/fs.h>
+#include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/uaccess.h>
 
@@ -72,7 +73,7 @@ static inline void *kmap_atomic(struct page *page, enum km_type idx)
 }
 #define kmap_atomic_prot(page, idx, prot)	kmap_atomic(page, idx)
 
-#define kunmap_atomic(addr, idx)	do { pagefault_enable(); } while (0)
+#define kunmap_atomic_notypecheck(addr, idx)	do { pagefault_enable(); } while (0)
 #define kmap_atomic_pfn(pfn, idx)	kmap_atomic(pfn_to_page(pfn), (idx))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
 
@@ -81,6 +82,13 @@ static inline void *kmap_atomic(struct page *page, enum km_type idx)
 
 #endif /* CONFIG_HIGHMEM */
 
+/* Prevent people trying to call kunmap_atomic() as if it were kunmap() */
+/* kunmap_atomic() should get the return value of kmap_atomic, not the page. */
+#define kunmap_atomic(addr, idx) do { \
+		BUILD_BUG_ON(__same_type((addr), struct page *)); \
+		kunmap_atomic_notypecheck((addr), (idx)); \
+	} while (0)
+
 /* when CONFIG_HIGHMEM is not set these will be plain clear/copy_page */
 #ifndef clear_user_highpage
 static inline void clear_user_highpage(struct page *page, unsigned long vaddr)

commit ff3d58c22b6827039983911d3460cf0c1657f8cc
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Mon May 24 14:32:46 2010 -0700

    highmem: remove unneeded #ifdef CONFIG_TRACE_IRQFLAGS_SUPPORT for debug_kmap_atomic()
    
    In f4112de6b679d84bd9b9681c7504be7bdfb7c7d5 ("mm: introduce
    debug_kmap_atomic") I said that debug_kmap_atomic() needs
    CONFIG_TRACE_IRQFLAGS_SUPPORT.
    
    It was wrong.  (I thought irqs_disabled() is only available when the
    architecture has CONFIG_TRACE_IRQFLAGS_SUPPORT)
    
    Remove the #ifdef CONFIG_TRACE_IRQFLAGS_SUPPORT check to enable
    kmap_atomic() debugging for the architectures which do not have
    CONFIG_TRACE_IRQFLAGS_SUPPORT.
    
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 74152c08ad07..caafd0561aa1 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -27,7 +27,7 @@ static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
 
 #include <asm/kmap_types.h>
 
-#if defined(CONFIG_DEBUG_HIGHMEM) && defined(CONFIG_TRACE_IRQFLAGS_SUPPORT)
+#ifdef CONFIG_DEBUG_HIGHMEM
 
 void debug_kmap_atomic(enum km_type type);
 

commit f24407d2bde27a4eb75ce5e52069bf4f1ba0e8a5
Merge: 654451748b77 73c77e2ccc14
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 26 17:05:10 2010 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/xfs-vipt
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/xfs-vipt:
      xfs: fix xfs to work with Virtually Indexed architectures
      sh: add mm API for DMA to vmalloc/vmap areas
      arm: add mm API for DMA to vmalloc/vmap areas
      parisc: add mm API for DMA to vmalloc/vmap areas
      mm: add coherence API for DMA to vmalloc/vmap areas

commit 9df5f74194871ebd0e51ef5ad2eca5084acaaaba
Author: James Bottomley <James.Bottomley@suse.de>
Date:   Mon Jan 25 11:42:20 2010 -0600

    mm: add coherence API for DMA to vmalloc/vmap areas
    
    On Virtually Indexed architectures (which don't do automatic alias
    resolution in their caches), we have to flush via the correct
    virtual address to prepare pages for DMA.  On some architectures
    (like arm) we cannot prevent the CPU from doing data movein along
    the alias (and thus giving stale read data), so we not only have to
    introduce a flush API to push dirty cache lines out, but also an invalidate
    API to kill inconsistent cache lines that may have moved in before
    DMA changed the data
    
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 211ff4497269..adfe1013b2bd 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -17,6 +17,12 @@ static inline void flush_anon_page(struct vm_area_struct *vma, struct page *page
 static inline void flush_kernel_dcache_page(struct page *page)
 {
 }
+static inline void flush_kernel_vmap_range(void *vaddr, int size)
+{
+}
+static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
+{
+}
 #endif
 
 #include <asm/kmap_types.h>

commit 4b529401c5089cf33f7165607cbc2fde43357bfb
Author: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
Date:   Fri Jan 8 14:42:31 2010 -0800

    mm: make totalhigh_pages unsigned long
    
    Makes it consistent with the extern declaration, used when CONFIG_HIGHMEM
    is set Removes redundant casts in printout messages
    
    Signed-off-by: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Chen Liqin <liqin.chen@sunplusct.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 211ff4497269..ab2cc20e21a5 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -46,7 +46,7 @@ void kmap_flush_unused(void);
 
 static inline unsigned int nr_free_highpages(void) { return 0; }
 
-#define totalhigh_pages 0
+#define totalhigh_pages 0UL
 
 #ifndef ARCH_HAS_KMAP
 static inline void *kmap(struct page *page)

commit 31c911329e048b715a1dfeaaf617be9430fd7f4e
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Tue Jun 16 15:32:45 2009 -0700

    mm: check the argument of kunmap on architectures without highmem
    
    If you're using a non-highmem architecture, passing an argument with the
    wrong type to kunmap() doesn't give you a warning because the ifdef
    doesn't check the type.
    
    Using a static inline function solves the problem nicely.
    
    Reported-by: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 1fcb7126a01f..211ff4497269 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -55,7 +55,9 @@ static inline void *kmap(struct page *page)
 	return page_address(page);
 }
 
-#define kunmap(page) do { (void) (page); } while (0)
+static inline void kunmap(struct page *page)
+{
+}
 
 static inline void *kmap_atomic(struct page *page, enum km_type idx)
 {

commit 3688e07f83d81941c4a8b20e29602c6d0c883539
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Wed Apr 1 23:38:49 2009 -0500

    Fix highmem PPC build failure
    
    Commit f4112de6b679d84bd9b9681c7504be7bdfb7c7d5 ("mm: introduce
    debug_kmap_atomic") broke PPC builds with CONFIG_HIGHMEM=y:
    
       CC      init/main.o
      In file included from include/linux/highmem.h:25,
                       from include/linux/pagemap.h:11,
                       from include/linux/mempolicy.h:63,
                       from init/main.c:53:
      arch/powerpc/include/asm/highmem.h: In function 'kmap_atomic_prot':
      arch/powerpc/include/asm/highmem.h:98: error: implicit declaration of function 'debug_kmap_atomic'
      In file included from include/linux/pagemap.h:11,
                       from include/linux/mempolicy.h:63,
                       from init/main.c:53:
      include/linux/highmem.h: At top level:
      include/linux/highmem.h:196: warning: conflicting types for 'debug_kmap_atomic'
      include/linux/highmem.h:196: error: static declaration of 'debug_kmap_atomic' follows non-static declaration
      include/asm/highmem.h:98: error: previous implicit declaration of 'debug_kmap_atomic' was here
      make[1]: *** [init/main.o] Error 1
      make: *** [init] Error 2
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Acked-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 7ff5c55f9b55..1fcb7126a01f 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -19,8 +19,21 @@ static inline void flush_kernel_dcache_page(struct page *page)
 }
 #endif
 
-#ifdef CONFIG_HIGHMEM
+#include <asm/kmap_types.h>
+
+#if defined(CONFIG_DEBUG_HIGHMEM) && defined(CONFIG_TRACE_IRQFLAGS_SUPPORT)
+
+void debug_kmap_atomic(enum km_type type);
+
+#else
 
+static inline void debug_kmap_atomic(enum km_type type)
+{
+}
+
+#endif
+
+#ifdef CONFIG_HIGHMEM
 #include <asm/highmem.h>
 
 /* declarations for linux/mm/highmem.c */
@@ -44,8 +57,6 @@ static inline void *kmap(struct page *page)
 
 #define kunmap(page) do { (void) (page); } while (0)
 
-#include <asm/kmap_types.h>
-
 static inline void *kmap_atomic(struct page *page, enum km_type idx)
 {
 	pagefault_disable();
@@ -187,16 +198,4 @@ static inline void copy_highpage(struct page *to, struct page *from)
 	kunmap_atomic(vto, KM_USER1);
 }
 
-#if defined(CONFIG_DEBUG_HIGHMEM) && defined(CONFIG_TRACE_IRQFLAGS_SUPPORT)
-
-void debug_kmap_atomic(enum km_type type);
-
-#else
-
-static inline void debug_kmap_atomic(enum km_type type)
-{
-}
-
-#endif
-
 #endif /* _LINUX_HIGHMEM_H */

commit f4112de6b679d84bd9b9681c7504be7bdfb7c7d5
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Tue Mar 31 15:23:25 2009 -0700

    mm: introduce debug_kmap_atomic
    
    x86 has debug_kmap_atomic_prot() which is error checking function for
    kmap_atomic.  It is usefull for the other architectures, although it needs
    CONFIG_TRACE_IRQFLAGS_SUPPORT.
    
    This patch exposes it to the other architectures.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: <linux-arch@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 13875ce9112a..7ff5c55f9b55 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -187,4 +187,16 @@ static inline void copy_highpage(struct page *to, struct page *from)
 	kunmap_atomic(vto, KM_USER1);
 }
 
+#if defined(CONFIG_DEBUG_HIGHMEM) && defined(CONFIG_TRACE_IRQFLAGS_SUPPORT)
+
+void debug_kmap_atomic(enum km_type type);
+
+#else
+
+static inline void debug_kmap_atomic(enum km_type type)
+{
+}
+
+#endif
+
 #endif /* _LINUX_HIGHMEM_H */

commit 487ff32082a9bd7489d8185cf7d7a2fdf18a22fa
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Nov 27 11:13:58 2008 +0000

    Allow architectures to override copy_user_highpage()
    
    With aliasing VIPT cache support, the ARM implementation of
    clear_user_page() and copy_user_page() sets up a temporary kernel space
    mapping such that we have the same cache colour as the userspace page.
    This avoids having to consider any userspace aliases from this operation.
    
    However, when highmem is enabled, kmap_atomic() have to setup mappings.
    The copy_user_highpage() and clear_user_highpage() call these functions
    before delegating the copies to copy_user_page() and clear_user_page().
    
    The effect of this is that each of the *_user_highpage() functions setup
    their own kmap mapping, followed by the *_user_page() functions setting
    up another mapping.  This is rather wasteful.
    
    Thankfully, copy_user_highpage() can be overriden by architectures by
    defining __HAVE_ARCH_COPY_USER_HIGHPAGE.  However, replacement of
    clear_user_highpage() is more difficult because its inline definition
    is not conditional.  It seems that you're expected to define
    __HAVE_ARCH_ALLOC_ZEROED_USER_HIGHPAGE and provide a replacement
    __alloc_zeroed_user_highpage() implementation instead.
    
    The allocation itself is fine, so we don't want to override that.  What
    we really want to do is to override clear_user_highpage() with our own
    version which doesn't kmap_atomic() unnecessarily.
    
    Other VIPT architectures (PARISC and SH) would also like to override
    this function as well.
    
    Acked-by: Hugh Dickins <hugh@veritas.com>
    Acked-by: James Bottomley <James.Bottomley@HansenPartnership.com>
    Acked-by: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 7dcbc82f3b7b..13875ce9112a 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -63,12 +63,14 @@ static inline void *kmap_atomic(struct page *page, enum km_type idx)
 #endif /* CONFIG_HIGHMEM */
 
 /* when CONFIG_HIGHMEM is not set these will be plain clear/copy_page */
+#ifndef clear_user_highpage
 static inline void clear_user_highpage(struct page *page, unsigned long vaddr)
 {
 	void *addr = kmap_atomic(page, KM_USER0);
 	clear_user_page(addr, vaddr, page);
 	kunmap_atomic(addr, KM_USER0);
 }
+#endif
 
 #ifndef __HAVE_ARCH_ALLOC_ZEROED_USER_HIGHPAGE
 /**

commit 0ed361dec36945f3116ee1338638ada9a8920905
Author: Nick Piggin <npiggin@suse.de>
Date:   Mon Feb 4 22:29:34 2008 -0800

    mm: fix PageUptodate data race
    
    After running SetPageUptodate, preceeding stores to the page contents to
    actually bring it uptodate may not be ordered with the store to set the
    page uptodate.
    
    Therefore, another CPU which checks PageUptodate is true, then reads the
    page contents can get stale data.
    
    Fix this by having an smp_wmb before SetPageUptodate, and smp_rmb after
    PageUptodate.
    
    Many places that test PageUptodate, do so with the page locked, and this
    would be enough to ensure memory ordering in those places if
    SetPageUptodate were only called while the page is locked.  Unfortunately
    that is not always the case for some filesystems, but it could be an idea
    for the future.
    
    Also bring the handling of anonymous page uptodateness in line with that of
    file backed page management, by marking anon pages as uptodate when they
    _are_ uptodate, rather than when our implementation requires that they be
    marked as such.  Doing allows us to get rid of the smp_wmb's in the page
    copying functions, which were especially added for anonymous pages for an
    analogous memory ordering problem.  Both file and anonymous pages are
    handled with the same barriers.
    
    FAQ:
    Q. Why not do this in flush_dcache_page?
    A. Firstly, flush_dcache_page handles only one side (the smb side) of the
    ordering protocol; we'd still need smp_rmb somewhere. Secondly, hiding away
    memory barriers in a completely unrelated function is nasty; at least in the
    PageUptodate macros, they are located together with (half) the operations
    involved in the ordering. Thirdly, the smp_wmb is only required when first
    bringing the page uptodate, wheras flush_dcache_page should be called each time
    it is written to through the kernel mapping. It is logically the wrong place to
    put it.
    
    Q. Why does this increase my text size / reduce my performance / etc.
    A. Because it is adding the necessary instructions to eliminate the data-race.
    
    Q. Can it be improved?
    A. Yes, eg. if you were to create a rule that all SetPageUptodate operations
    run under the page lock, we could avoid the smp_rmb places where PageUptodate
    is queried under the page lock. Requires audit of all filesystems and at least
    some would need reworking. That's great you're interested, I'm eagerly awaiting
    your patches.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 61a5e5eb27f0..7dcbc82f3b7b 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -68,8 +68,6 @@ static inline void clear_user_highpage(struct page *page, unsigned long vaddr)
 	void *addr = kmap_atomic(page, KM_USER0);
 	clear_user_page(addr, vaddr, page);
 	kunmap_atomic(addr, KM_USER0);
-	/* Make sure this page is cleared on other CPU's too before using it */
-	smp_wmb();
 }
 
 #ifndef __HAVE_ARCH_ALLOC_ZEROED_USER_HIGHPAGE
@@ -172,8 +170,6 @@ static inline void copy_user_highpage(struct page *to, struct page *from,
 	copy_user_page(vto, vfrom, vaddr, to);
 	kunmap_atomic(vfrom, KM_USER0);
 	kunmap_atomic(vto, KM_USER1);
-	/* Make sure this page is cleared on other CPU's too before using it */
-	smp_wmb();
 }
 
 #endif

commit eebd2aa355692afaf9906f62118620f1a1c19dbb
Author: Christoph Lameter <clameter@sgi.com>
Date:   Mon Feb 4 22:28:29 2008 -0800

    Pagecache zeroing: zero_user_segment, zero_user_segments and zero_user
    
    Simplify page cache zeroing of segments of pages through 3 functions
    
    zero_user_segments(page, start1, end1, start2, end2)
    
            Zeros two segments of the page. It takes the position where to
            start and end the zeroing which avoids length calculations and
            makes code clearer.
    
    zero_user_segment(page, start, end)
    
            Same for a single segment.
    
    zero_user(page, start, length)
    
            Length variant for the case where we know the length.
    
    We remove the zero_user_page macro. Issues:
    
    1. Its a macro. Inline functions are preferable.
    
    2. The KM_USER0 macro is only defined for HIGHMEM.
    
       Having to treat this special case everywhere makes the
       code needlessly complex. The parameter for zeroing is always
       KM_USER0 except in one single case that we open code.
    
    Avoiding KM_USER0 makes a lot of code not having to be dealing
    with the special casing for HIGHMEM anymore. Dealing with
    kmap is only necessary for HIGHMEM configurations. In those
    configurations we use KM_USER0 like we do for a series of other
    functions defined in highmem.h.
    
    Since KM_USER0 is depends on HIGHMEM the existing zero_user_page
    function could not be a macro. zero_user_* functions introduced
    here can be be inline because that constant is not used when these
    functions are called.
    
    Also extract the flushing of the caches to be outside of the kmap.
    
    [akpm@linux-foundation.org: fix nfs and ntfs build]
    [akpm@linux-foundation.org: fix ntfs build some more]
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Cc: Steven French <sfrench@us.ibm.com>
    Cc: Michael Halcrow <mhalcrow@us.ibm.com>
    Cc: <linux-ext4@vger.kernel.org>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: "J. Bruce Fields" <bfields@fieldses.org>
    Cc: Anton Altaparmakov <aia21@cantab.net>
    Cc: Mark Fasheh <mark.fasheh@oracle.com>
    Cc: David Chinner <dgc@sgi.com>
    Cc: Michael Halcrow <mhalcrow@us.ibm.com>
    Cc: Steven French <sfrench@us.ibm.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 1fcb0033179e..61a5e5eb27f0 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -124,28 +124,40 @@ static inline void clear_highpage(struct page *page)
 	kunmap_atomic(kaddr, KM_USER0);
 }
 
-/*
- * Same but also flushes aliased cache contents to RAM.
- *
- * This must be a macro because KM_USER0 and friends aren't defined if
- * !CONFIG_HIGHMEM
- */
-#define zero_user_page(page, offset, size, km_type)		\
-	do {							\
-		void *kaddr;					\
-								\
-		BUG_ON((offset) + (size) > PAGE_SIZE);		\
-								\
-		kaddr = kmap_atomic(page, km_type);		\
-		memset((char *)kaddr + (offset), 0, (size));	\
-		flush_dcache_page(page);			\
-		kunmap_atomic(kaddr, (km_type));		\
-	} while (0)
+static inline void zero_user_segments(struct page *page,
+	unsigned start1, unsigned end1,
+	unsigned start2, unsigned end2)
+{
+	void *kaddr = kmap_atomic(page, KM_USER0);
+
+	BUG_ON(end1 > PAGE_SIZE || end2 > PAGE_SIZE);
+
+	if (end1 > start1)
+		memset(kaddr + start1, 0, end1 - start1);
+
+	if (end2 > start2)
+		memset(kaddr + start2, 0, end2 - start2);
+
+	kunmap_atomic(kaddr, KM_USER0);
+	flush_dcache_page(page);
+}
+
+static inline void zero_user_segment(struct page *page,
+	unsigned start, unsigned end)
+{
+	zero_user_segments(page, start, end, 0, 0);
+}
+
+static inline void zero_user(struct page *page,
+	unsigned start, unsigned size)
+{
+	zero_user_segments(page, start, start + size, 0, 0);
+}
 
 static inline void __deprecated memclear_highpage_flush(struct page *page,
 			unsigned int offset, unsigned int size)
 {
-	zero_user_page(page, offset, size, KM_USER0);
+	zero_user(page, offset, size);
 }
 
 #ifndef __HAVE_ARCH_COPY_USER_HIGHPAGE

commit bb2d5ce16409efcdf94017a6b6fecd468226e29c
Author: Mel Gorman <mel@csn.ul.ie>
Date:   Thu Jul 19 01:47:23 2007 -0700

    Remove alloc_zeroed_user_highpage()
    
    alloc_zeroed_user_highpage() has no in-tree users and it is not exported.
    As it is not exported, it can simply be removed.
    
    Signed-off-by: Mel Gorman <mel@csn.ul.ie>
    Acked-by: Andy Whitcroft <apw@shadowen.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 12c5e4e3135a..1fcb0033179e 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -102,21 +102,6 @@ __alloc_zeroed_user_highpage(gfp_t movableflags,
 }
 #endif
 
-/**
- * alloc_zeroed_user_highpage - Allocate a zeroed HIGHMEM page for a VMA
- * @vma: The VMA the page is to be allocated for
- * @vaddr: The virtual address the page will be inserted into
- *
- * This function will allocate a page for a VMA that the caller knows will
- * not be able to move in the future using move_pages() or reclaim. If it
- * is known that the page can move, use alloc_zeroed_user_highpage_movable
- */
-static inline struct page *
-alloc_zeroed_user_highpage(struct vm_area_struct *vma, unsigned long vaddr)
-{
-	return __alloc_zeroed_user_highpage(0, vma, vaddr);
-}
-
 /**
  * alloc_zeroed_user_highpage_movable - Allocate a zeroed HIGHMEM page for a VMA that the caller knows can move
  * @vma: The VMA the page is to be allocated for

commit 769848c03895b63e5662eb7e4ec8c4866f7d0183
Author: Mel Gorman <mel@csn.ul.ie>
Date:   Tue Jul 17 04:03:05 2007 -0700

    Add __GFP_MOVABLE for callers to flag allocations from high memory that may be migrated
    
    It is often known at allocation time whether a page may be migrated or not.
    This patch adds a flag called __GFP_MOVABLE and a new mask called
    GFP_HIGH_MOVABLE.  Allocations using the __GFP_MOVABLE can be either migrated
    using the page migration mechanism or reclaimed by syncing with backing
    storage and discarding.
    
    An API function very similar to alloc_zeroed_user_highpage() is added for
    __GFP_MOVABLE allocations called alloc_zeroed_user_highpage_movable().  The
    flags used by alloc_zeroed_user_highpage() are not changed because it would
    change the semantics of an existing API.  After this patch is applied there
    are no in-kernel users of alloc_zeroed_user_highpage() so it probably should
    be marked deprecated if this patch is merged.
    
    Note that this patch includes a minor cleanup to the use of __GFP_ZERO in
    shmem.c to keep all flag modifications to inode->mapping in the
    shmem_dir_alloc() helper function.  This clean-up suggestion is courtesy of
    Hugh Dickens.
    
    Additional credit goes to Christoph Lameter and Linus Torvalds for shaping the
    concept.  Credit to Hugh Dickens for catching issues with shmem swap vector
    and ramfs allocations.
    
    [akpm@linux-foundation.org: build fix]
    [hugh@veritas.com: __GFP_ZERO cleanup]
    Signed-off-by: Mel Gorman <mel@csn.ul.ie>
    Cc: Andy Whitcroft <apw@shadowen.org>
    Cc: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 98e2cce996a4..12c5e4e3135a 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -73,10 +73,27 @@ static inline void clear_user_highpage(struct page *page, unsigned long vaddr)
 }
 
 #ifndef __HAVE_ARCH_ALLOC_ZEROED_USER_HIGHPAGE
+/**
+ * __alloc_zeroed_user_highpage - Allocate a zeroed HIGHMEM page for a VMA with caller-specified movable GFP flags
+ * @movableflags: The GFP flags related to the pages future ability to move like __GFP_MOVABLE
+ * @vma: The VMA the page is to be allocated for
+ * @vaddr: The virtual address the page will be inserted into
+ *
+ * This function will allocate a page for a VMA but the caller is expected
+ * to specify via movableflags whether the page will be movable in the
+ * future or not
+ *
+ * An architecture may override this function by defining
+ * __HAVE_ARCH_ALLOC_ZEROED_USER_HIGHPAGE and providing their own
+ * implementation.
+ */
 static inline struct page *
-alloc_zeroed_user_highpage(struct vm_area_struct *vma, unsigned long vaddr)
+__alloc_zeroed_user_highpage(gfp_t movableflags,
+			struct vm_area_struct *vma,
+			unsigned long vaddr)
 {
-	struct page *page = alloc_page_vma(GFP_HIGHUSER, vma, vaddr);
+	struct page *page = alloc_page_vma(GFP_HIGHUSER | movableflags,
+			vma, vaddr);
 
 	if (page)
 		clear_user_highpage(page, vaddr);
@@ -85,6 +102,36 @@ alloc_zeroed_user_highpage(struct vm_area_struct *vma, unsigned long vaddr)
 }
 #endif
 
+/**
+ * alloc_zeroed_user_highpage - Allocate a zeroed HIGHMEM page for a VMA
+ * @vma: The VMA the page is to be allocated for
+ * @vaddr: The virtual address the page will be inserted into
+ *
+ * This function will allocate a page for a VMA that the caller knows will
+ * not be able to move in the future using move_pages() or reclaim. If it
+ * is known that the page can move, use alloc_zeroed_user_highpage_movable
+ */
+static inline struct page *
+alloc_zeroed_user_highpage(struct vm_area_struct *vma, unsigned long vaddr)
+{
+	return __alloc_zeroed_user_highpage(0, vma, vaddr);
+}
+
+/**
+ * alloc_zeroed_user_highpage_movable - Allocate a zeroed HIGHMEM page for a VMA that the caller knows can move
+ * @vma: The VMA the page is to be allocated for
+ * @vaddr: The virtual address the page will be inserted into
+ *
+ * This function will allocate a page for a VMA that the caller knows will
+ * be able to migrate in the future using move_pages() or reclaimed
+ */
+static inline struct page *
+alloc_zeroed_user_highpage_movable(struct vm_area_struct *vma,
+					unsigned long vaddr)
+{
+	return __alloc_zeroed_user_highpage(__GFP_MOVABLE, vma, vaddr);
+}
+
 static inline void clear_highpage(struct page *page)
 {
 	void *kaddr = kmap_atomic(page, KM_USER0);

commit f37bc2712b54ec641e0c0c8634f1a4b61d9956c0
Author: Nate Diller <nate.diller@gmail.com>
Date:   Wed May 9 02:35:09 2007 -0700

    fs: deprecate memclear_highpage_flush
    
    Now that all the in-tree users are converted over to zero_user_page(),
    deprecate the old memclear_highpage_flush() call.
    
    Signed-off-by: Nate Diller <nate.diller@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index b5f2ab42d984..98e2cce996a4 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -110,8 +110,7 @@ static inline void clear_highpage(struct page *page)
 		kunmap_atomic(kaddr, (km_type));		\
 	} while (0)
 
-
-static inline void memclear_highpage_flush(struct page *page,
+static inline void __deprecated memclear_highpage_flush(struct page *page,
 			unsigned int offset, unsigned int size)
 {
 	zero_user_page(page, offset, size, KM_USER0);

commit 01f2705daf5a36208e69d7cf95db9c330f843af6
Author: Nate Diller <nate.diller@gmail.com>
Date:   Wed May 9 02:35:07 2007 -0700

    fs: convert core functions to zero_user_page
    
    It's very common for file systems to need to zero part or all of a page,
    the simplist way is just to use kmap_atomic() and memset().  There's
    actually a library function in include/linux/highmem.h that does exactly
    that, but it's confusingly named memclear_highpage_flush(), which is
    descriptive of *how* it does the work rather than what the *purpose* is.
    So this patchset renames the function to zero_user_page(), and calls it
    from the various places that currently open code it.
    
    This first patch introduces the new function call, and converts all the
    core kernel callsites, both the open-coded ones and the old
    memclear_highpage_flush() ones.  Following this patch is a series of
    conversions for each file system individually, per AKPM, and finally a
    patch deprecating the old call.  The diffstat below shows the entire
    patchset.
    
    [akpm@linux-foundation.org: fix a few things]
    Signed-off-by: Nate Diller <nate.diller@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index a515eb0afdfb..b5f2ab42d984 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -94,17 +94,27 @@ static inline void clear_highpage(struct page *page)
 
 /*
  * Same but also flushes aliased cache contents to RAM.
+ *
+ * This must be a macro because KM_USER0 and friends aren't defined if
+ * !CONFIG_HIGHMEM
  */
-static inline void memclear_highpage_flush(struct page *page, unsigned int offset, unsigned int size)
+#define zero_user_page(page, offset, size, km_type)		\
+	do {							\
+		void *kaddr;					\
+								\
+		BUG_ON((offset) + (size) > PAGE_SIZE);		\
+								\
+		kaddr = kmap_atomic(page, km_type);		\
+		memset((char *)kaddr + (offset), 0, (size));	\
+		flush_dcache_page(page);			\
+		kunmap_atomic(kaddr, (km_type));		\
+	} while (0)
+
+
+static inline void memclear_highpage_flush(struct page *page,
+			unsigned int offset, unsigned int size)
 {
-	void *kaddr;
-
-	BUG_ON(offset + size > PAGE_SIZE);
-
-	kaddr = kmap_atomic(page, KM_USER0);
-	memset((char *)kaddr + offset, 0, size);
-	flush_dcache_page(page);
-	kunmap_atomic(kaddr, KM_USER0);
+	zero_user_page(page, offset, size, KM_USER0);
 }
 
 #ifndef __HAVE_ARCH_COPY_USER_HIGHPAGE

commit ea62ccd00fd0b6720b033adfc9984f31130ce195
Merge: 886a0768affe 35060b6a9a4e
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Sat May 5 14:55:20 2007 -0700

    Merge branch 'for-linus' of git://one.firstfloor.org/home/andi/git/linux-2.6
    
    * 'for-linus' of git://one.firstfloor.org/home/andi/git/linux-2.6: (231 commits)
      [PATCH] i386: Don't delete cpu_devs data to identify different x86 types in late_initcall
      [PATCH] i386: type may be unused
      [PATCH] i386: Some additional chipset register values validation.
      [PATCH] i386: Add missing !X86_PAE dependincy to the 2G/2G split.
      [PATCH] x86-64: Don't exclude asm-offsets.c in Documentation/dontdiff
      [PATCH] i386: avoid redundant preempt_disable in __unlazy_fpu
      [PATCH] i386: white space fixes in i387.h
      [PATCH] i386: Drop noisy e820 debugging printks
      [PATCH] x86-64: Fix allnoconfig error in genapic_flat.c
      [PATCH] x86-64: Shut up warnings for vfat compat ioctls on other file systems
      [PATCH] x86-64: Share identical video.S between i386 and x86-64
      [PATCH] x86-64: Remove CONFIG_REORDER
      [PATCH] x86-64: Print type and size correctly for unknown compat ioctls
      [PATCH] i386: Remove copy_*_user BUG_ONs for (size < 0)
      [PATCH] i386: Little cleanups in smpboot.c
      [PATCH] x86-64: Don't enable NUMA for a single node in K8 NUMA scanning
      [PATCH] x86: Use RDTSCP for synchronous get_cycles if possible
      [PATCH] i386: Add X86_FEATURE_RDTSCP
      [PATCH] i386: Implement X86_FEATURE_SYNC_RDTSC on i386
      [PATCH] i386: Implement alternative_io for i386
      ...
    
    Fix up trivial conflict in include/linux/highmem.h manually.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 254f9c5cd2d3b41e64f59df816630f7ca5548a8a
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue May 1 22:33:07 2007 +0200

    Convert non-highmem kmap_atomic() to static inline function
    
    Convert kmap_atomic() in the non-highmem case from a macro to a static
    inline function, for better type-checking and the ability to pass void
    pointers instead of struct page pointers.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 645d440807c2..7bab8eae2341 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -42,8 +42,14 @@ static inline void *kmap(struct page *page)
 
 #define kunmap(page) do { (void) (page); } while (0)
 
-#define kmap_atomic(page, idx) \
-	({ pagefault_disable(); page_address(page); })
+#include <asm/kmap_types.h>
+
+static inline void *kmap_atomic(struct page *page, enum km_type idx)
+{
+	pagefault_disable();
+	return page_address(page);
+}
+
 #define kunmap_atomic(addr, idx)	do { pagefault_enable(); } while (0)
 #define kmap_atomic_pfn(pfn, idx)	kmap_atomic(pfn_to_page(pfn), (idx))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)

commit ce6234b5298902aaec831a67d5f8d9bd2ef5a488
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed May 2 19:27:15 2007 +0200

    [PATCH] i386: PARAVIRT: add kmap_atomic_pte for mapping highpte pages
    
    Xen and VMI both have special requirements when mapping a highmem pte
    page into the kernel address space.  These can be dealt with by adding
    a new kmap_atomic_pte() function for mapping highptes, and hooking it
    into the paravirt_ops infrastructure.
    
    Xen specifically wants to map the pte page RO, so this patch exposes a
    helper function, kmap_atomic_prot, which maps the page with the
    specified page protections.
    
    This also adds a kmap_flush_unused() function to clear out the cached
    kmap mappings.  Xen needs this to clear out any potential stray RW
    mappings of pages which will become part of a pagetable.
    
    [ Zach - vmi.c will need some attention after this patch.  It wasn't
      immediately obvious to me what needs to be done. ]
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy@xensource.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Cc: Zachary Amsden <zach@vmware.com>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 645d440807c2..bca8e2dfa355 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -27,6 +27,8 @@ static inline void flush_kernel_dcache_page(struct page *page)
 unsigned int nr_free_highpages(void);
 extern unsigned long totalhigh_pages;
 
+void kmap_flush_unused(void);
+
 #else /* CONFIG_HIGHMEM */
 
 static inline unsigned int nr_free_highpages(void) { return 0; }
@@ -44,9 +46,13 @@ static inline void *kmap(struct page *page)
 
 #define kmap_atomic(page, idx) \
 	({ pagefault_disable(); page_address(page); })
+#define kmap_atomic_prot(page, idx, prot)	kmap_atomic(page, idx)
+
 #define kunmap_atomic(addr, idx)	do { pagefault_enable(); } while (0)
 #define kmap_atomic_pfn(pfn, idx)	kmap_atomic(pfn_to_page(pfn), (idx))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
+
+#define kmap_flush_unused()	do {} while(0)
 #endif
 
 #endif /* CONFIG_HIGHMEM */

commit a6f36be32622730710b2fadacb6e2649defa4371
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Dec 30 22:24:19 2006 +0000

    [ARM] pass vma for flush_anon_page()
    
    Since get_user_pages() may be used with processes other than the
    current process and calls flush_anon_page(), flush_anon_page() has to
    cope in some way with non-current processes.
    
    It may not be appropriate, or even desirable to flush a region of
    virtual memory cache in the current process when that is different to
    the process that we want the flush to occur for.
    
    Therefore, pass the vma into flush_anon_page() so that the architecture
    can work out whether the 'vmaddr' is for the current process or not.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index ca9a602cffd7..645d440807c2 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -8,7 +8,7 @@
 #include <asm/cacheflush.h>
 
 #ifndef ARCH_HAS_FLUSH_ANON_PAGE
-static inline void flush_anon_page(struct page *page, unsigned long vmaddr)
+static inline void flush_anon_page(struct vm_area_struct *vma, struct page *page, unsigned long vmaddr)
 {
 }
 #endif

commit 9de455b20705f36384a711d4a20bcf7ba1ab180b
Author: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
Date:   Tue Dec 12 17:14:55 2006 +0000

    [PATCH] Pass vma argument to copy_user_highpage().
    
    To allow a more effective copy_user_highpage() on certain architectures,
    a vma argument is added to the function and cow_user_page() allowing
    the implementation of these functions to check for the VM_EXEC bit.
    
    The main part of this patch was originally written by Ralf Baechle;
    Atushi Nemoto did the the debugging.
    
    Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index ea5780b518ef..ca9a602cffd7 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -98,7 +98,8 @@ static inline void memclear_highpage_flush(struct page *page, unsigned int offse
 
 #ifndef __HAVE_ARCH_COPY_USER_HIGHPAGE
 
-static inline void copy_user_highpage(struct page *to, struct page *from, unsigned long vaddr)
+static inline void copy_user_highpage(struct page *to, struct page *from,
+	unsigned long vaddr, struct vm_area_struct *vma)
 {
 	char *vfrom, *vto;
 

commit 77fff4ae2b7bba6d66a8287d9ab948e2b6c16145
Author: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
Date:   Tue Dec 12 17:14:54 2006 +0000

    [PATCH] Fix COW D-cache aliasing on fork
    
    Problem:
    
    1. There is a process containing two thread (T1 and T2).  The
       thread T1 calls fork().  Then dup_mmap() function called on T1 context.
    
    static inline int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)
            ...
            flush_cache_mm(current->mm);
            ...     /* A */
            (write-protect all Copy-On-Write pages)
            ...     /* B */
            flush_tlb_mm(current->mm);
            ...
    
    2. When preemption happens between A and B (or on SMP kernel), the
       thread T2 can run and modify data on COW pages without page fault
       (modified data will stay in cache).
    
    3. Some time after fork() completed, the thread T2 may cause a page
       fault by write-protect on a COW page.
    
    4. Then data of the COW page will be copied to newly allocated
       physical page (copy_cow_page()).  It reads data via kernel mapping.
       The kernel mapping can have different 'color' with user space
       mapping of the thread T2 (dcache aliasing).  Therefore
       copy_cow_page() will copy stale data.  Then the modified data in
       cache will be lost.
    
    In order to allow architecture code to deal with this problem allow
    architecture code to override copy_user_highpage() by defining
    __HAVE_ARCH_COPY_USER_HIGHPAGE in <asm/page.h>.
    
    The main part of this patch was originally written by Ralf Baechle;
    Atushi Nemoto did the the debugging.
    
    Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 3d8768b619e9..ea5780b518ef 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -96,6 +96,8 @@ static inline void memclear_highpage_flush(struct page *page, unsigned int offse
 	kunmap_atomic(kaddr, KM_USER0);
 }
 
+#ifndef __HAVE_ARCH_COPY_USER_HIGHPAGE
+
 static inline void copy_user_highpage(struct page *to, struct page *from, unsigned long vaddr)
 {
 	char *vfrom, *vto;
@@ -109,6 +111,8 @@ static inline void copy_user_highpage(struct page *to, struct page *from, unsign
 	smp_wmb();
 }
 
+#endif
+
 static inline void copy_highpage(struct page *to, struct page *from)
 {
 	char *vfrom, *vto;

commit ad76fb6b5a5183255279e0ab5260715481770678
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Wed Dec 6 20:32:21 2006 -0800

    [PATCH] mm: k{,um}map_atomic() vs in_atomic()
    
    Make kmap_atomic/kunmap_atomic denote a pagefault disabled scope.  All non
    trivial implementations already do this anyway.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index fd7d12daa94f..3d8768b619e9 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -3,6 +3,7 @@
 
 #include <linux/fs.h>
 #include <linux/mm.h>
+#include <linux/uaccess.h>
 
 #include <asm/cacheflush.h>
 
@@ -41,9 +42,10 @@ static inline void *kmap(struct page *page)
 
 #define kunmap(page) do { (void) (page); } while (0)
 
-#define kmap_atomic(page, idx)		page_address(page)
-#define kunmap_atomic(addr, idx)	do { } while (0)
-#define kmap_atomic_pfn(pfn, idx)	page_address(pfn_to_page(pfn))
+#define kmap_atomic(page, idx) \
+	({ pagefault_disable(); page_address(page); })
+#define kunmap_atomic(addr, idx)	do { pagefault_enable(); } while (0)
+#define kmap_atomic_pfn(pfn, idx)	kmap_atomic(pfn_to_page(pfn), (idx))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
 #endif
 

commit c1f60a5a419cc60aff27daffb150f5a3a3a79ef4
Author: Christoph Lameter <clameter@sgi.com>
Date:   Mon Sep 25 23:31:11 2006 -0700

    [PATCH] reduce MAX_NR_ZONES: move HIGHMEM counters into highmem.c/.h
    
    Move totalhigh_pages and nr_free_highpages() into highmem.c/.h
    
    Move the totalhigh_pages definition into highmem.c/.h.  Move the
    nr_free_highpages function into highmem.c
    
    [yoichi_yuasa@tripeaks.co.jp: build fix]
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Yoichi Yuasa <yoichi_yuasa@tripeaks.co.jp>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 42620e723abb..fd7d12daa94f 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -24,11 +24,14 @@ static inline void flush_kernel_dcache_page(struct page *page)
 
 /* declarations for linux/mm/highmem.c */
 unsigned int nr_free_highpages(void);
+extern unsigned long totalhigh_pages;
 
 #else /* CONFIG_HIGHMEM */
 
 static inline unsigned int nr_free_highpages(void) { return 0; }
 
+#define totalhigh_pages 0
+
 #ifndef ARCH_HAS_KMAP
 static inline void *kmap(struct page *page)
 {

commit a6ca1b99ed434f3fb41bbed647ed36c0420501e5
Author: James Bottomley <James.Bottomley@SteelEye.com>
Date:   Mon Sep 25 23:30:55 2006 -0700

    [PATCH] update to the kernel kmap/kunmap API
    
    Give non-highmem architectures access to the kmap API for the purposes of
    overriding (this is what the attached patch does).
    
    The proposal is that we should now require all architectures with coherence
    issues to manage data coherence via the kmap/kunmap API.  Thus driver
    writers never have to write code like
    
        kmap(page)
        modify data in page
        flush_kernel_dcache_page(page)
        kunmap(page)
    
    instead, kmap/kunmap will manage the coherence and driver (and filesystem)
    writers don't need to worry about how to flush between kmap and kunmap.
    
    For most architectures, the page only needs to be flushed if it was
    actually written to *and* there are user mappings of it, so the best
    implementation looks to be: clear the page dirty pte bit in the kernel page
    tables on kmap and on kunmap, check page->mappings for user maps, and then
    the dirty bit, and only flush if it both has user mappings and is dirty.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 85ce7ef9a512..42620e723abb 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -29,6 +29,7 @@ unsigned int nr_free_highpages(void);
 
 static inline unsigned int nr_free_highpages(void) { return 0; }
 
+#ifndef ARCH_HAS_KMAP
 static inline void *kmap(struct page *page)
 {
 	might_sleep();
@@ -41,6 +42,7 @@ static inline void *kmap(struct page *page)
 #define kunmap_atomic(addr, idx)	do { } while (0)
 #define kmap_atomic_pfn(pfn, idx)	page_address(pfn_to_page(pfn))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
+#endif
 
 #endif /* CONFIG_HIGHMEM */
 

commit 62c4f0a2d5a188f73a94f2cb8ea0dba3e7cf0a7f
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Wed Apr 26 12:56:16 2006 +0100

    Don't include linux/config.h from anywhere else in include/
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 892c4ea1b425..85ce7ef9a512 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -1,7 +1,6 @@
 #ifndef _LINUX_HIGHMEM_H
 #define _LINUX_HIGHMEM_H
 
-#include <linux/config.h>
 #include <linux/fs.h>
 #include <linux/mm.h>
 

commit 5a3a5a98b6422d05c39eaa32c8b3f83840c7b768
Author: James Bottomley <James.Bottomley@SteelEye.com>
Date:   Sun Mar 26 01:36:59 2006 -0800

    [PATCH] Add flush_kernel_dcache_page() API
    
    We have a problem in a lot of emulated storage in that it takes a page from
    get_user_pages() and does something like
    
    kmap_atomic(page)
    modify page
    kunmap_atomic(page)
    
    However, nothing has flushed the kernel cache view of the page before the
    kunmap.  We need a lightweight API to do this, so this new API would
    specifically be for flushing the kernel cache view of a user page which the
    kernel has modified.  The driver would need to add
    flush_kernel_dcache_page(page) before the final kunmap.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 7bd2593dbef9..892c4ea1b425 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -13,6 +13,12 @@ static inline void flush_anon_page(struct page *page, unsigned long vmaddr)
 }
 #endif
 
+#ifndef ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE
+static inline void flush_kernel_dcache_page(struct page *page)
+{
+}
+#endif
+
 #ifdef CONFIG_HIGHMEM
 
 #include <asm/highmem.h>

commit 03beb07664d768db97bf454ae5c9581cd4737bb4
Author: James Bottomley <James.Bottomley@SteelEye.com>
Date:   Sun Mar 26 01:36:57 2006 -0800

    [PATCH] Add API for flushing Anon pages
    
    Currently, get_user_pages() returns fully coherent pages to the kernel for
    anything other than anonymous pages.  This is a problem for things like
    fuse and the SCSI generic ioctl SG_IO which can potentially wish to do DMA
    to anonymous pages passed in by users.
    
    The fix is to add a new memory management API: flush_anon_page() which
    is used in get_user_pages() to make anonymous pages coherent.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 6bece9280eb7..7bd2593dbef9 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -7,6 +7,12 @@
 
 #include <asm/cacheflush.h>
 
+#ifndef ARCH_HAS_FLUSH_ANON_PAGE
+static inline void flush_anon_page(struct page *page, unsigned long vmaddr)
+{
+}
+#endif
+
 #ifdef CONFIG_HIGHMEM
 
 #include <asm/highmem.h>

commit 60e64d46a58236e3c718074372cab6a5b56a3b15
Author: Vivek Goyal <vgoyal@in.ibm.com>
Date:   Sat Jun 25 14:58:19 2005 -0700

    [PATCH] kdump: Routines for copying dump pages
    
    This patch provides the interfaces necessary to read the dump contents,
    treating it as a high memory device.
    
    Signed off by Hariprasad Nellitheertha <hari@in.ibm.com>
    Signed-off-by: Eric Biederman <ebiederm@xmission.com>
    Signed-off-by: Vivek Goyal <vgoyal@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 2a7e6c65c882..6bece9280eb7 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -28,6 +28,7 @@ static inline void *kmap(struct page *page)
 
 #define kmap_atomic(page, idx)		page_address(page)
 #define kunmap_atomic(addr, idx)	do { } while (0)
+#define kmap_atomic_pfn(pfn, idx)	page_address(pfn_to_page(pfn))
 #define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
 
 #endif /* CONFIG_HIGHMEM */

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
new file mode 100644
index 000000000000..2a7e6c65c882
--- /dev/null
+++ b/include/linux/highmem.h
@@ -0,0 +1,104 @@
+#ifndef _LINUX_HIGHMEM_H
+#define _LINUX_HIGHMEM_H
+
+#include <linux/config.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+
+#include <asm/cacheflush.h>
+
+#ifdef CONFIG_HIGHMEM
+
+#include <asm/highmem.h>
+
+/* declarations for linux/mm/highmem.c */
+unsigned int nr_free_highpages(void);
+
+#else /* CONFIG_HIGHMEM */
+
+static inline unsigned int nr_free_highpages(void) { return 0; }
+
+static inline void *kmap(struct page *page)
+{
+	might_sleep();
+	return page_address(page);
+}
+
+#define kunmap(page) do { (void) (page); } while (0)
+
+#define kmap_atomic(page, idx)		page_address(page)
+#define kunmap_atomic(addr, idx)	do { } while (0)
+#define kmap_atomic_to_page(ptr)	virt_to_page(ptr)
+
+#endif /* CONFIG_HIGHMEM */
+
+/* when CONFIG_HIGHMEM is not set these will be plain clear/copy_page */
+static inline void clear_user_highpage(struct page *page, unsigned long vaddr)
+{
+	void *addr = kmap_atomic(page, KM_USER0);
+	clear_user_page(addr, vaddr, page);
+	kunmap_atomic(addr, KM_USER0);
+	/* Make sure this page is cleared on other CPU's too before using it */
+	smp_wmb();
+}
+
+#ifndef __HAVE_ARCH_ALLOC_ZEROED_USER_HIGHPAGE
+static inline struct page *
+alloc_zeroed_user_highpage(struct vm_area_struct *vma, unsigned long vaddr)
+{
+	struct page *page = alloc_page_vma(GFP_HIGHUSER, vma, vaddr);
+
+	if (page)
+		clear_user_highpage(page, vaddr);
+
+	return page;
+}
+#endif
+
+static inline void clear_highpage(struct page *page)
+{
+	void *kaddr = kmap_atomic(page, KM_USER0);
+	clear_page(kaddr);
+	kunmap_atomic(kaddr, KM_USER0);
+}
+
+/*
+ * Same but also flushes aliased cache contents to RAM.
+ */
+static inline void memclear_highpage_flush(struct page *page, unsigned int offset, unsigned int size)
+{
+	void *kaddr;
+
+	BUG_ON(offset + size > PAGE_SIZE);
+
+	kaddr = kmap_atomic(page, KM_USER0);
+	memset((char *)kaddr + offset, 0, size);
+	flush_dcache_page(page);
+	kunmap_atomic(kaddr, KM_USER0);
+}
+
+static inline void copy_user_highpage(struct page *to, struct page *from, unsigned long vaddr)
+{
+	char *vfrom, *vto;
+
+	vfrom = kmap_atomic(from, KM_USER0);
+	vto = kmap_atomic(to, KM_USER1);
+	copy_user_page(vto, vfrom, vaddr, to);
+	kunmap_atomic(vfrom, KM_USER0);
+	kunmap_atomic(vto, KM_USER1);
+	/* Make sure this page is cleared on other CPU's too before using it */
+	smp_wmb();
+}
+
+static inline void copy_highpage(struct page *to, struct page *from)
+{
+	char *vfrom, *vto;
+
+	vfrom = kmap_atomic(from, KM_USER0);
+	vto = kmap_atomic(to, KM_USER1);
+	copy_page(vto, vfrom);
+	kunmap_atomic(vfrom, KM_USER0);
+	kunmap_atomic(vto, KM_USER1);
+}
+
+#endif /* _LINUX_HIGHMEM_H */
