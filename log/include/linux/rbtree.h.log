commit 14bbe3e33710be52f21d61253a94c5f44a696d02
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Wed Apr 1 10:33:43 2020 -0700

    docs: Add rbtree documentation to the core-api
    
    This file is close enough to being in rst format that I didn't feel
    the need to alter it in any way.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Acked-by: Michel Lespinasse <walken@google.com>
    Link: https://lore.kernel.org/r/20200401173343.17472-1-willy@infradead.org
    Signed-off-by: Jonathan Corbet <corbet@lwn.net>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 1fd61a9af45c..d7db17996322 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -11,7 +11,7 @@
   I know it's not the cleaner way,  but in C (not in C++) to get
   performances and genericity...
 
-  See Documentation/rbtree.txt for documentation and samples.
+  See Documentation/core-api/rbtree.rst for documentation and samples.
 */
 
 #ifndef	_LINUX_RBTREE_H

commit 9f973cb38088e0cf42e0bae97ff140813e623f13
Author: Michel Lespinasse <walken@google.com>
Date:   Tue Jul 16 16:27:45 2019 -0700

    lib/rbtree: avoid generating code twice for the cached versions
    
    As was already noted in rbtree.h, the logic to cache rb_first (or
    rb_last) can easily be implemented externally to the core rbtree api.
    
    Change the implementation to do just that.  Previously the update of
    rb_leftmost was wired deeper into the implmentation, but there were some
    disadvantages to that - mostly, lib/rbtree.c had separate instantiations
    for rb_insert_color() vs rb_insert_color_cached(), as well as rb_erase()
    vs rb_erase_cached(), which were doing exactly the same thing save for
    the rb_leftmost update at the start of either function.
    
       text    data     bss     dec     hex filename
       5405     120       0    5525    1595 lib/rbtree.o-vanilla
       3827      96       0    3923     f53 lib/rbtree.o-patch
    
    [dave@stgolabs.net: changelog addition]
      Link: http://lkml.kernel.org/r/20190628171416.by5gdizl3rcxk5h5@linux-r8p5
    [akpm@linux-foundation.org: coding-style fixes]
    Link: http://lkml.kernel.org/r/20190628045008.39926-1-walken@google.com
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Acked-by: Davidlohr Bueso <dbueso@suse.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index e6337fce08f2..1fd61a9af45c 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -32,25 +32,9 @@ struct rb_root {
 	struct rb_node *rb_node;
 };
 
-/*
- * Leftmost-cached rbtrees.
- *
- * We do not cache the rightmost node based on footprint
- * size vs number of potential users that could benefit
- * from O(1) rb_last(). Just not worth it, users that want
- * this feature can always implement the logic explicitly.
- * Furthermore, users that want to cache both pointers may
- * find it a bit asymmetric, but that's ok.
- */
-struct rb_root_cached {
-	struct rb_root rb_root;
-	struct rb_node *rb_leftmost;
-};
-
 #define rb_parent(r)   ((struct rb_node *)((r)->__rb_parent_color & ~3))
 
 #define RB_ROOT	(struct rb_root) { NULL, }
-#define RB_ROOT_CACHED (struct rb_root_cached) { {NULL, }, NULL }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
 #define RB_EMPTY_ROOT(root)  (READ_ONCE((root)->rb_node) == NULL)
@@ -72,12 +56,6 @@ extern struct rb_node *rb_prev(const struct rb_node *);
 extern struct rb_node *rb_first(const struct rb_root *);
 extern struct rb_node *rb_last(const struct rb_root *);
 
-extern void rb_insert_color_cached(struct rb_node *,
-				   struct rb_root_cached *, bool);
-extern void rb_erase_cached(struct rb_node *node, struct rb_root_cached *);
-/* Same as rb_first(), but O(1) */
-#define rb_first_cached(root) (root)->rb_leftmost
-
 /* Postorder iteration - always visit the parent after its children */
 extern struct rb_node *rb_first_postorder(const struct rb_root *);
 extern struct rb_node *rb_next_postorder(const struct rb_node *);
@@ -87,8 +65,6 @@ extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
 			    struct rb_root *root);
 extern void rb_replace_node_rcu(struct rb_node *victim, struct rb_node *new,
 				struct rb_root *root);
-extern void rb_replace_node_cached(struct rb_node *victim, struct rb_node *new,
-				   struct rb_root_cached *root);
 
 static inline void rb_link_node(struct rb_node *node, struct rb_node *parent,
 				struct rb_node **rb_link)
@@ -136,4 +112,50 @@ static inline void rb_link_node_rcu(struct rb_node *node, struct rb_node *parent
 			typeof(*pos), field); 1; }); \
 	     pos = n)
 
+/*
+ * Leftmost-cached rbtrees.
+ *
+ * We do not cache the rightmost node based on footprint
+ * size vs number of potential users that could benefit
+ * from O(1) rb_last(). Just not worth it, users that want
+ * this feature can always implement the logic explicitly.
+ * Furthermore, users that want to cache both pointers may
+ * find it a bit asymmetric, but that's ok.
+ */
+struct rb_root_cached {
+	struct rb_root rb_root;
+	struct rb_node *rb_leftmost;
+};
+
+#define RB_ROOT_CACHED (struct rb_root_cached) { {NULL, }, NULL }
+
+/* Same as rb_first(), but O(1) */
+#define rb_first_cached(root) (root)->rb_leftmost
+
+static inline void rb_insert_color_cached(struct rb_node *node,
+					  struct rb_root_cached *root,
+					  bool leftmost)
+{
+	if (leftmost)
+		root->rb_leftmost = node;
+	rb_insert_color(node, &root->rb_root);
+}
+
+static inline void rb_erase_cached(struct rb_node *node,
+				   struct rb_root_cached *root)
+{
+	if (root->rb_leftmost == node)
+		root->rb_leftmost = rb_next(node);
+	rb_erase(node, &root->rb_root);
+}
+
+static inline void rb_replace_node_cached(struct rb_node *victim,
+					  struct rb_node *new,
+					  struct rb_root_cached *root)
+{
+	if (root->rb_leftmost == victim)
+		root->rb_leftmost = new;
+	rb_replace_node(victim, new, &root->rb_root);
+}
+
 #endif	/* _LINUX_RBTREE_H */

commit 1a59d1b8e05ea6ab45f7e18897de1ef0e6bc3da6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:05 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 156
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details you
      should have received a copy of the gnu general public license along
      with this program if not write to the free software foundation inc
      59 temple place suite 330 boston ma 02111 1307 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 1334 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070033.113240726@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index fcbeed4053ef..e6337fce08f2 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -1,20 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
   Red Black Trees
   (C) 1999  Andrea Arcangeli <andrea@suse.de>
   
-  This program is free software; you can redistribute it and/or modify
-  it under the terms of the GNU General Public License as published by
-  the Free Software Foundation; either version 2 of the License, or
-  (at your option) any later version.
-
-  This program is distributed in the hope that it will be useful,
-  but WITHOUT ANY WARRANTY; without even the implied warranty of
-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-  GNU General Public License for more details.
-
-  You should have received a copy of the GNU General Public License
-  along with this program; if not, write to the Free Software
-  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 
   linux/include/linux/rbtree.h
 

commit 338f1d9d1b829fec494d053f62820a2ee625b1ec
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Thu Dec 14 15:32:28 2017 -0800

    lib/rbtree,drm/mm: add rbtree_replace_node_cached()
    
    Add a variant of rbtree_replace_node() that maintains the leftmost cache
    of struct rbtree_root_cached when replacing nodes within the rbtree.
    
    As drm_mm is the only rb_replace_node() being used on an interval tree,
    the mistake looks fairly self-contained.  Furthermore the only user of
    drm_mm_replace_node() is its testsuite...
    
    Testcase: igt/drm_mm/replace
    
    Link: http://lkml.kernel.org/r/20171122100729.3742-1-chris@chris-wilson.co.uk
    Link: https://patchwork.freedesktop.org/patch/msgid/20171109212435.9265-1-chris@chris-wilson.co.uk
    Fixes: f808c13fd373 ("lib/interval_tree: fast overlap detection")
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Reviewed-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Acked-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Jérôme Glisse <jglisse@redhat.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index d574361943ea..fcbeed4053ef 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -99,6 +99,8 @@ extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
 			    struct rb_root *root);
 extern void rb_replace_node_rcu(struct rb_node *victim, struct rb_node *new,
 				struct rb_root *root);
+extern void rb_replace_node_cached(struct rb_node *victim, struct rb_node *new,
+				   struct rb_root_cached *root);
 
 static inline void rb_link_node(struct rb_node *node, struct rb_node *parent,
 				struct rb_node **rb_link)

commit cd9e61ed1eebbcd5dfad59475d41ec58d9b64b6a
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Fri Sep 8 16:14:36 2017 -0700

    rbtree: cache leftmost node internally
    
    Patch series "rbtree: Cache leftmost node internally", v4.
    
    A series to extending rbtrees to internally cache the leftmost node such
    that we can have fast overlap check optimization for all interval tree
    users[1].  The benefits of this series are that:
    
    (i)   Unify users that do internal leftmost node caching.
    (ii)  Optimize all interval tree users.
    (iii) Convert at least two new users (epoll and procfs) to the new interface.
    
    This patch (of 16):
    
    Red-black tree semantics imply that nodes with smaller or greater (or
    equal for duplicates) keys always be to the left and right,
    respectively.  For the kernel this is extremely evident when considering
    our rb_first() semantics.  Enabling lookups for the smallest node in the
    tree in O(1) can save a good chunk of cycles in not having to walk down
    the tree each time.  To this end there are a few core users that
    explicitly do this, such as the scheduler and rtmutexes.  There is also
    the desire for interval trees to have this optimization allowing faster
    overlap checking.
    
    This patch introduces a new 'struct rb_root_cached' which is just the
    root with a cached pointer to the leftmost node.  The reason why the
    regular rb_root was not extended instead of adding a new structure was
    that this allows the user to have the choice between memory footprint
    and actual tree performance.  The new wrappers on top of the regular
    rb_root calls are:
    
     - rb_first_cached(cached_root) -- which is a fast replacement
         for rb_first.
    
     - rb_insert_color_cached(node, cached_root, new)
    
     - rb_erase_cached(node, cached_root)
    
    In addition, augmented cached interfaces are also added for basic
    insertion and deletion operations; which becomes important for the
    interval tree changes.
    
    With the exception of the inserts, which adds a bool for updating the
    new leftmost, the interfaces are kept the same.  To this end, porting rb
    users to the cached version becomes really trivial, and keeping current
    rbtree semantics for users that don't care about the optimization
    requires zero overhead.
    
    Link: http://lkml.kernel.org/r/20170719014603.19029-2-dave@stgolabs.net
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index e585018498d5..d574361943ea 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -44,10 +44,25 @@ struct rb_root {
 	struct rb_node *rb_node;
 };
 
+/*
+ * Leftmost-cached rbtrees.
+ *
+ * We do not cache the rightmost node based on footprint
+ * size vs number of potential users that could benefit
+ * from O(1) rb_last(). Just not worth it, users that want
+ * this feature can always implement the logic explicitly.
+ * Furthermore, users that want to cache both pointers may
+ * find it a bit asymmetric, but that's ok.
+ */
+struct rb_root_cached {
+	struct rb_root rb_root;
+	struct rb_node *rb_leftmost;
+};
 
 #define rb_parent(r)   ((struct rb_node *)((r)->__rb_parent_color & ~3))
 
 #define RB_ROOT	(struct rb_root) { NULL, }
+#define RB_ROOT_CACHED (struct rb_root_cached) { {NULL, }, NULL }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
 #define RB_EMPTY_ROOT(root)  (READ_ONCE((root)->rb_node) == NULL)
@@ -69,6 +84,12 @@ extern struct rb_node *rb_prev(const struct rb_node *);
 extern struct rb_node *rb_first(const struct rb_root *);
 extern struct rb_node *rb_last(const struct rb_root *);
 
+extern void rb_insert_color_cached(struct rb_node *,
+				   struct rb_root_cached *, bool);
+extern void rb_erase_cached(struct rb_node *node, struct rb_root_cached *);
+/* Same as rb_first(), but O(1) */
+#define rb_first_cached(root) (root)->rb_leftmost
+
 /* Postorder iteration - always visit the parent after its children */
 extern struct rb_node *rb_first_postorder(const struct rb_root *);
 extern struct rb_node *rb_next_postorder(const struct rb_node *);

commit c1adf20052d80f776849fa2c1acb472cdeb7786c
Author: David Howells <dhowells@redhat.com>
Date:   Fri Jul 1 07:53:51 2016 +0100

    Introduce rb_replace_node_rcu()
    
    Implement an RCU-safe variant of rb_replace_node() and rearrange
    rb_replace_node() to do things in the same order.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index b6900099ea81..e585018498d5 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -76,6 +76,8 @@ extern struct rb_node *rb_next_postorder(const struct rb_node *);
 /* Fast replacement of a single node without remove/rebalance/add/rebalance */
 extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
 			    struct rb_root *root);
+extern void rb_replace_node_rcu(struct rb_node *victim, struct rb_node *new,
+				struct rb_root *root);
 
 static inline void rb_link_node(struct rb_node *node, struct rb_node *parent,
 				struct rb_node **rb_link)

commit a460bece027301e079b9e53c5e0f67c8e3eaebc1
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Wed Jan 20 15:00:42 2016 -0800

    rbtree: use READ_ONCE in RB_EMPTY_ROOT
    
    With commit d72da4a4d97 ("rbtree: Make lockless searches non-fatal") our
    rbtrees provide weak guarantees that allows us to do lockless (and very
    speculative) reads of the tree.  Such readers cannot see partial stores
    on nodes, ie left/right as well as root.  As such, similar to the
    WRITE_ONCE semantics when doing rotations, use READ_ONCE when checking
    the root node in RB_EMPTY_ROOT.
    
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index a5aa7ae671f4..b6900099ea81 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -50,7 +50,7 @@ struct rb_root {
 #define RB_ROOT	(struct rb_root) { NULL, }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
-#define RB_EMPTY_ROOT(root)  ((root)->rb_node == NULL)
+#define RB_EMPTY_ROOT(root)  (READ_ONCE((root)->rb_node) == NULL)
 
 /* 'empty' nodes are nodes that are known not to be inserted in an rbtree */
 #define RB_EMPTY_NODE(node)  \

commit 8de1ee7ebfb4979c6444e81273e12e7a972c367d
Author: Cody P Schafer <dev@codyps.com>
Date:   Fri Nov 6 16:31:28 2015 -0800

    rbtree: clarify documentation of rbtree_postorder_for_each_entry_safe()
    
    I noticed that commit a20135ffbc44 ("writeback: don't drain
    bdi_writeback_congested on bdi destruction") added a usage of
    rbtree_postorder_for_each_entry_safe() in mm/backing-dev.c which appears
    to try to rb_erase() elements from an rbtree while iterating over it using
    rbtree_postorder_for_each_entry_safe().
    
    Doing this will cause random nodes to be missed by the iteration because
    rb_erase() may rebalance the tree, changing the ordering that we're trying
    to iterate over.
    
    The previous documentation for rbtree_postorder_for_each_entry_safe()
    wasn't clear that this wasn't allowed, it was taken from the docs for
    list_for_each_entry_safe(), where erasing isn't a problem due to
    list_del() not reordering.
    
    Explicitly warn developers about this potential pit-fall.
    
    Note that I haven't fixed the actual issue that (it appears) the commit
    referenced above introduced (not familiar enough with that code).
    
    In general (and in this case), the patterns to follow are:
     - switch to rb_first() + rb_erase(), don't use
       rbtree_postorder_for_each_entry_safe().
     - keep the postorder iteration and don't rb_erase() at all. Instead
       just clear the fields of rb_node & cgwb_congested_tree as required by
       other users of those structures.
    
    [akpm@linux-foundation.org: tweak comments]
    Signed-off-by: Cody P Schafer <dev@codyps.com>
    Cc: John de la Garza <john@jjdev.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 830c4992088d..a5aa7ae671f4 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -101,13 +101,21 @@ static inline void rb_link_node_rcu(struct rb_node *node, struct rb_node *parent
 	})
 
 /**
- * rbtree_postorder_for_each_entry_safe - iterate over rb_root in post order of
- * given type safe against removal of rb_node entry
+ * rbtree_postorder_for_each_entry_safe - iterate in post-order over rb_root of
+ * given type allowing the backing memory of @pos to be invalidated
  *
  * @pos:	the 'type *' to use as a loop cursor.
  * @n:		another 'type *' to use as temporary storage
  * @root:	'rb_root *' of the rbtree.
  * @field:	the name of the rb_node field within 'type'.
+ *
+ * rbtree_postorder_for_each_entry_safe() provides a similar guarantee as
+ * list_for_each_entry_safe() and allows the iteration to continue independent
+ * of changes to @pos by the body of the loop.
+ *
+ * Note, however, that it cannot handle other modifications that re-order the
+ * rbtree it is iterating over. This includes calling rb_erase() on @pos, as
+ * rb_erase() may rebalance the tree, causing us to miss some nodes.
  */
 #define rbtree_postorder_for_each_entry_safe(pos, n, root, field) \
 	for (pos = rb_entry_safe(rb_first_postorder(root), typeof(*pos), field); \

commit d72da4a4d973d8a0a0d3c97e7cdebf287fbe3a99
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed May 27 11:09:36 2015 +0930

    rbtree: Make lockless searches non-fatal
    
    Change the insert and erase code such that lockless searches are
    non-fatal.
    
    In and of itself an rbtree cannot be correctly searched while
    in-modification, we can however provide weaker guarantees that will
    allow the rbtree to be used in conjunction with other techniques, such
    as latches; see 9b0fd802e8c0 ("seqcount: Add raw_write_seqcount_latch()").
    
    For this to work we need the following guarantees from the rbtree
    code:
    
     1) a lockless reader must not see partial stores, this would allow it
        to observe nodes that are invalid memory.
    
     2) there must not be (temporary) loops in the tree structure in the
        modifier's program order, this would cause a lookup which
        interrupts the modifier to get stuck indefinitely.
    
    For 1) we must use WRITE_ONCE() for all updates to the tree structure;
    in particular this patch only does rb_{left,right} as those are the
    only element required for simple searches.
    
    It generates slightly worse code, probably because volatile. But in
    pointer chasing heavy code a few instructions more should not matter.
    
    For 2) I have carefully audited the code and drawn every intermediate
    link state and not found a loop.
    
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <David.Woodhouse@intel.com>
    Cc: Rik van Riel <riel@redhat.com>
    Reviewed-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index fb31765e935a..830c4992088d 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -31,6 +31,7 @@
 
 #include <linux/kernel.h>
 #include <linux/stddef.h>
+#include <linux/rcupdate.h>
 
 struct rb_node {
 	unsigned long  __rb_parent_color;
@@ -73,11 +74,11 @@ extern struct rb_node *rb_first_postorder(const struct rb_root *);
 extern struct rb_node *rb_next_postorder(const struct rb_node *);
 
 /* Fast replacement of a single node without remove/rebalance/add/rebalance */
-extern void rb_replace_node(struct rb_node *victim, struct rb_node *new, 
+extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
 			    struct rb_root *root);
 
-static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
-				struct rb_node ** rb_link)
+static inline void rb_link_node(struct rb_node *node, struct rb_node *parent,
+				struct rb_node **rb_link)
 {
 	node->__rb_parent_color = (unsigned long)parent;
 	node->rb_left = node->rb_right = NULL;
@@ -85,6 +86,15 @@ static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
 	*rb_link = node;
 }
 
+static inline void rb_link_node_rcu(struct rb_node *node, struct rb_node *parent,
+				    struct rb_node **rb_link)
+{
+	node->__rb_parent_color = (unsigned long)parent;
+	node->rb_left = node->rb_right = NULL;
+
+	rcu_assign_pointer(*rb_link, node);
+}
+
 #define rb_entry_safe(ptr, type, member) \
 	({ typeof(ptr) ____ptr = (ptr); \
 	   ____ptr ? rb_entry(____ptr, type, member) : NULL; \

commit 7647f14fe4cd98151f8e90656c01fe61044de714
Author: John de la Garza <john@jjdev.com>
Date:   Tue Feb 17 13:46:04 2015 -0800

    lib/rbtree.c: fix typo in comment
    
    Signed-off-by: John de la Garza <john@jjdev.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 57e75ae9910f..fb31765e935a 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -51,7 +51,7 @@ struct rb_root {
 
 #define RB_EMPTY_ROOT(root)  ((root)->rb_node == NULL)
 
-/* 'empty' nodes are nodes that are known not to be inserted in an rbree */
+/* 'empty' nodes are nodes that are known not to be inserted in an rbtree */
 #define RB_EMPTY_NODE(node)  \
 	((node)->__rb_parent_color == (unsigned long)(node))
 #define RB_CLEAR_NODE(node)  \

commit 1310a5a99d900ee30b9f171146406bde0c6c2bd4
Author: Jan Kara <jack@suse.cz>
Date:   Tue Nov 12 15:11:19 2013 -0800

    rbtree: fix rbtree_postorder_for_each_entry_safe() iterator
    
    The iterator rbtree_postorder_for_each_entry_safe() relies on pointer
    underflow behavior when testing for loop termination.  In particular it
    expects that
    
      &rb_entry(NULL, type, field)->field
    
    is NULL.  But the result of this expression is not defined by a C standard
    and some gcc versions (e.g.  4.3.4) assume the above expression can never
    be equal to NULL.  The net result is an oops because the iteration is not
    properly terminated.
    
    Fix the problem by modifying the iterator to avoid pointer underflows.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Cody P Schafer <cody@linux.vnet.ibm.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Artem Bityutskiy <dedekind1@gmail.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Jozsef Kadlecsik <kadlec@blackhole.kfki.hu>
    Cc: Pablo Neira Ayuso <pablo@netfilter.org>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: <stable@vger.kernel.org>            [3.12.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index aa870a4ddf54..57e75ae9910f 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -85,6 +85,11 @@ static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
 	*rb_link = node;
 }
 
+#define rb_entry_safe(ptr, type, member) \
+	({ typeof(ptr) ____ptr = (ptr); \
+	   ____ptr ? rb_entry(____ptr, type, member) : NULL; \
+	})
+
 /**
  * rbtree_postorder_for_each_entry_safe - iterate over rb_root in post order of
  * given type safe against removal of rb_node entry
@@ -95,12 +100,9 @@ static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
  * @field:	the name of the rb_node field within 'type'.
  */
 #define rbtree_postorder_for_each_entry_safe(pos, n, root, field) \
-	for (pos = rb_entry(rb_first_postorder(root), typeof(*pos), field),\
-		n = rb_entry(rb_next_postorder(&pos->field), \
-			typeof(*pos), field); \
-	     &pos->field; \
-	     pos = n, \
-		n = rb_entry(rb_next_postorder(&pos->field), \
-			typeof(*pos), field))
+	for (pos = rb_entry_safe(rb_first_postorder(root), typeof(*pos), field); \
+	     pos && ({ n = rb_entry_safe(rb_next_postorder(&pos->field), \
+			typeof(*pos), field); 1; }); \
+	     pos = n)
 
 #endif	/* _LINUX_RBTREE_H */

commit 2b529089257705499207ce7da9d0e3ae26a844ba
Author: Cody P Schafer <cody@linux.vnet.ibm.com>
Date:   Wed Sep 11 14:25:11 2013 -0700

    rbtree: add rbtree_postorder_for_each_entry_safe() helper
    
    Because deletion (of the entire tree) is a relatively common use of the
    rbtree_postorder iteration, and because doing it safely means fiddling
    with temporary storage, provide a helper to simplify postorder rbtree
    iteration.
    
    Signed-off-by: Cody P Schafer <cody@linux.vnet.ibm.com>
    Reviewed-by: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Cc: David Woodhouse <David.Woodhouse@intel.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index c467151e9950..aa870a4ddf54 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -85,4 +85,22 @@ static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
 	*rb_link = node;
 }
 
+/**
+ * rbtree_postorder_for_each_entry_safe - iterate over rb_root in post order of
+ * given type safe against removal of rb_node entry
+ *
+ * @pos:	the 'type *' to use as a loop cursor.
+ * @n:		another 'type *' to use as temporary storage
+ * @root:	'rb_root *' of the rbtree.
+ * @field:	the name of the rb_node field within 'type'.
+ */
+#define rbtree_postorder_for_each_entry_safe(pos, n, root, field) \
+	for (pos = rb_entry(rb_first_postorder(root), typeof(*pos), field),\
+		n = rb_entry(rb_next_postorder(&pos->field), \
+			typeof(*pos), field); \
+	     &pos->field; \
+	     pos = n, \
+		n = rb_entry(rb_next_postorder(&pos->field), \
+			typeof(*pos), field))
+
 #endif	/* _LINUX_RBTREE_H */

commit 9dee5c51516d2c3fff22633c1272c5652e68075a
Author: Cody P Schafer <cody@linux.vnet.ibm.com>
Date:   Wed Sep 11 14:25:10 2013 -0700

    rbtree: add postorder iteration functions
    
    Postorder iteration yields all of a node's children prior to yielding the
    node itself, and this particular implementation also avoids examining the
    leaf links in a node after that node has been yielded.
    
    In what I expect will be its most common usage, postorder iteration allows
    the deletion of every node in an rbtree without modifying the rbtree nodes
    (no _requirement_ that they be nulled) while avoiding referencing child
    nodes after they have been "deleted" (most commonly, freed).
    
    I have only updated zswap to use this functionality at this point, but
    numerous bits of code (most notably in the filesystem drivers) use a hand
    rolled postorder iteration that NULLs child links as it traverses the
    tree.  Each of those instances could be replaced with this common
    implementation.
    
    1 & 2 add rbtree postorder iteration functions.
    3 adds testing of the iteration to the rbtree runtime tests
    4 allows building the rbtree runtime tests as builtins
    5 updates zswap.
    
    This patch:
    
    Add postorder iteration functions for rbtree.  These are useful for safely
    freeing an entire rbtree without modifying the tree at all.
    
    Signed-off-by: Cody P Schafer <cody@linux.vnet.ibm.com>
    Reviewed-by: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Cc: David Woodhouse <David.Woodhouse@intel.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 0022c1bb1e26..c467151e9950 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -68,6 +68,10 @@ extern struct rb_node *rb_prev(const struct rb_node *);
 extern struct rb_node *rb_first(const struct rb_root *);
 extern struct rb_node *rb_last(const struct rb_root *);
 
+/* Postorder iteration - always visit the parent after its children */
+extern struct rb_node *rb_first_postorder(const struct rb_root *);
+extern struct rb_node *rb_next_postorder(const struct rb_node *);
+
 /* Fast replacement of a single node without remove/rebalance/add/rebalance */
 extern void rb_replace_node(struct rb_node *victim, struct rb_node *new, 
 			    struct rb_root *root);

commit 9c079add0d0f45220f4bb37febf0621137ec2d38
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:31:33 2012 -0700

    rbtree: move augmented rbtree functionality to rbtree_augmented.h
    
    Provide rb_insert_augmented() and rb_erase_augmented() through a new
    rbtree_augmented.h include file.  rb_erase_augmented() is defined there as
    an __always_inline function, in order to allow inlining of augmented
    rbtree callbacks into it.  Since this generates a relatively large
    function, each augmented rbtree user should make sure to have a single
    call site.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Hillf Danton <dhillf@gmail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 8d1e83b1c87b..0022c1bb1e26 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -62,54 +62,6 @@ extern void rb_insert_color(struct rb_node *, struct rb_root *);
 extern void rb_erase(struct rb_node *, struct rb_root *);
 
 
-struct rb_augment_callbacks {
-	void (*propagate)(struct rb_node *node, struct rb_node *stop);
-	void (*copy)(struct rb_node *old, struct rb_node *new);
-	void (*rotate)(struct rb_node *old, struct rb_node *new);
-};
-
-extern void __rb_insert_augmented(struct rb_node *node, struct rb_root *root,
-	void (*augment_rotate)(struct rb_node *old, struct rb_node *new));
-extern void rb_erase_augmented(struct rb_node *node, struct rb_root *root,
-			       const struct rb_augment_callbacks *augment);
-static inline void
-rb_insert_augmented(struct rb_node *node, struct rb_root *root,
-		    const struct rb_augment_callbacks *augment)
-{
-	__rb_insert_augmented(node, root, augment->rotate);
-}
-
-#define RB_DECLARE_CALLBACKS(rbstatic, rbname, rbstruct, rbfield,	      \
-			     rbtype, rbaugmented, rbcompute)		      \
-static void rbname ## _propagate(struct rb_node *rb, struct rb_node *stop)    \
-{									      \
-	while (rb != stop) {						      \
-		rbstruct *node = rb_entry(rb, rbstruct, rbfield);	      \
-		rbtype augmented = rbcompute(node);			      \
-		if (node->rbaugmented == augmented)			      \
-			break;						      \
-		node->rbaugmented = augmented;				      \
-		rb = rb_parent(&node->rbfield);				      \
-	}								      \
-}									      \
-static void rbname ## _copy(struct rb_node *rb_old, struct rb_node *rb_new)   \
-{									      \
-	rbstruct *old = rb_entry(rb_old, rbstruct, rbfield);		      \
-	rbstruct *new = rb_entry(rb_new, rbstruct, rbfield);		      \
-	new->rbaugmented = old->rbaugmented;				      \
-}									      \
-static void rbname ## _rotate(struct rb_node *rb_old, struct rb_node *rb_new) \
-{									      \
-	rbstruct *old = rb_entry(rb_old, rbstruct, rbfield);		      \
-	rbstruct *new = rb_entry(rb_new, rbstruct, rbfield);		      \
-	new->rbaugmented = old->rbaugmented;				      \
-	old->rbaugmented = rbcompute(old);				      \
-}									      \
-rbstatic const struct rb_augment_callbacks rbname = {			      \
-	rbname ## _propagate, rbname ## _copy, rbname ## _rotate	      \
-};
-
-
 /* Find logical next and previous nodes in a tree */
 extern struct rb_node *rb_next(const struct rb_node *);
 extern struct rb_node *rb_prev(const struct rb_node *);

commit 3908836aa77e3621aaf2101f2920e01d7c8460d6
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:31:21 2012 -0700

    rbtree: add RB_DECLARE_CALLBACKS() macro
    
    As proposed by Peter Zijlstra, this makes it easier to define the augmented
    rbtree callbacks.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 4ace31b33380..8d1e83b1c87b 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -79,6 +79,36 @@ rb_insert_augmented(struct rb_node *node, struct rb_root *root,
 	__rb_insert_augmented(node, root, augment->rotate);
 }
 
+#define RB_DECLARE_CALLBACKS(rbstatic, rbname, rbstruct, rbfield,	      \
+			     rbtype, rbaugmented, rbcompute)		      \
+static void rbname ## _propagate(struct rb_node *rb, struct rb_node *stop)    \
+{									      \
+	while (rb != stop) {						      \
+		rbstruct *node = rb_entry(rb, rbstruct, rbfield);	      \
+		rbtype augmented = rbcompute(node);			      \
+		if (node->rbaugmented == augmented)			      \
+			break;						      \
+		node->rbaugmented = augmented;				      \
+		rb = rb_parent(&node->rbfield);				      \
+	}								      \
+}									      \
+static void rbname ## _copy(struct rb_node *rb_old, struct rb_node *rb_new)   \
+{									      \
+	rbstruct *old = rb_entry(rb_old, rbstruct, rbfield);		      \
+	rbstruct *new = rb_entry(rb_new, rbstruct, rbfield);		      \
+	new->rbaugmented = old->rbaugmented;				      \
+}									      \
+static void rbname ## _rotate(struct rb_node *rb_old, struct rb_node *rb_new) \
+{									      \
+	rbstruct *old = rb_entry(rb_old, rbstruct, rbfield);		      \
+	rbstruct *new = rb_entry(rb_new, rbstruct, rbfield);		      \
+	new->rbaugmented = old->rbaugmented;				      \
+	old->rbaugmented = rbcompute(old);				      \
+}									      \
+rbstatic const struct rb_augment_callbacks rbname = {			      \
+	rbname ## _propagate, rbname ## _copy, rbname ## _rotate	      \
+};
+
 
 /* Find logical next and previous nodes in a tree */
 extern struct rb_node *rb_next(const struct rb_node *);

commit 9d9e6f9703bbd642f3f2f807e6aaa642a4cbcec9
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:31:20 2012 -0700

    rbtree: remove prior augmented rbtree implementation
    
    convert arch/x86/mm/pat_rbtree.c to the proposed augmented rbtree api
    and remove the old augmented rbtree implementation.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index c902eb9d6506..4ace31b33380 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -80,14 +80,6 @@ rb_insert_augmented(struct rb_node *node, struct rb_root *root,
 }
 
 
-typedef void (*rb_augment_f)(struct rb_node *node, void *data);
-
-extern void rb_augment_insert(struct rb_node *node,
-			      rb_augment_f func, void *data);
-extern struct rb_node *rb_augment_erase_begin(struct rb_node *node);
-extern void rb_augment_erase_end(struct rb_node *node,
-				 rb_augment_f func, void *data);
-
 /* Find logical next and previous nodes in a tree */
 extern struct rb_node *rb_next(const struct rb_node *);
 extern struct rb_node *rb_prev(const struct rb_node *);

commit 14b94af0b251a2c80885b60538166fb7d04a642e
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:31:17 2012 -0700

    rbtree: faster augmented rbtree manipulation
    
    Introduce new augmented rbtree APIs that allow minimal recalculation of
    augmented node information.
    
    A new callback is added to the rbtree insertion and erase rebalancing
    functions, to be called on each tree rotations. Such rotations preserve
    the subtree's root augmented value, but require recalculation of the one
    child that was previously located at the subtree root.
    
    In the insertion case, the handcoded search phase must be updated to
    maintain the augmented information on insertion, and then the rbtree
    coloring/rebalancing algorithms keep it up to date.
    
    In the erase case, things are more complicated since it is library
    code that manipulates the rbtree in order to remove internal nodes.
    This requires a couple additional callbacks to copy a subtree's
    augmented value when a new root is stitched in, and to recompute
    augmented values down the ancestry path when a node is removed from
    the tree.
    
    In order to preserve maximum speed for the non-augmented case,
    we provide two versions of each tree manipulation function.
    rb_insert_augmented() is the augmented equivalent of rb_insert_color(),
    and rb_erase_augmented() is the augmented equivalent of rb_erase().
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index bf836a2c6a32..c902eb9d6506 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -61,6 +61,25 @@ struct rb_root {
 extern void rb_insert_color(struct rb_node *, struct rb_root *);
 extern void rb_erase(struct rb_node *, struct rb_root *);
 
+
+struct rb_augment_callbacks {
+	void (*propagate)(struct rb_node *node, struct rb_node *stop);
+	void (*copy)(struct rb_node *old, struct rb_node *new);
+	void (*rotate)(struct rb_node *old, struct rb_node *new);
+};
+
+extern void __rb_insert_augmented(struct rb_node *node, struct rb_root *root,
+	void (*augment_rotate)(struct rb_node *old, struct rb_node *new));
+extern void rb_erase_augmented(struct rb_node *node, struct rb_root *root,
+			       const struct rb_augment_callbacks *augment);
+static inline void
+rb_insert_augmented(struct rb_node *node, struct rb_root *root,
+		    const struct rb_augment_callbacks *augment)
+{
+	__rb_insert_augmented(node, root, augment->rotate);
+}
+
+
 typedef void (*rb_augment_f)(struct rb_node *node, void *data);
 
 extern void rb_augment_insert(struct rb_node *node,

commit bf7ad8eeab995710c766df49c9c69a8592ca0216
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:30:37 2012 -0700

    rbtree: move some implementation details from rbtree.h to rbtree.c
    
    rbtree users must use the documented APIs to manipulate the tree
    structure.  Low-level helpers to manipulate node colors and parenthood are
    not part of that API, so move them to lib/rbtree.c
    
    [dwmw2@infradead.org: fix jffs2 build issue due to renamed __rb_parent_color field]
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Acked-by: David Woodhouse <David.Woodhouse@intel.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Santos <daniel.santos@pobox.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 2049087c43b7..bf836a2c6a32 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -32,37 +32,19 @@
 #include <linux/kernel.h>
 #include <linux/stddef.h>
 
-struct rb_node
-{
-	unsigned long  rb_parent_color;
-#define	RB_RED		0
-#define	RB_BLACK	1
+struct rb_node {
+	unsigned long  __rb_parent_color;
 	struct rb_node *rb_right;
 	struct rb_node *rb_left;
 } __attribute__((aligned(sizeof(long))));
     /* The alignment might seem pointless, but allegedly CRIS needs it */
 
-struct rb_root
-{
+struct rb_root {
 	struct rb_node *rb_node;
 };
 
 
-#define rb_parent(r)   ((struct rb_node *)((r)->rb_parent_color & ~3))
-#define rb_color(r)   ((r)->rb_parent_color & 1)
-#define rb_is_red(r)   (!rb_color(r))
-#define rb_is_black(r) rb_color(r)
-#define rb_set_red(r)  do { (r)->rb_parent_color &= ~1; } while (0)
-#define rb_set_black(r)  do { (r)->rb_parent_color |= 1; } while (0)
-
-static inline void rb_set_parent(struct rb_node *rb, struct rb_node *p)
-{
-	rb->rb_parent_color = (rb->rb_parent_color & 3) | (unsigned long)p;
-}
-static inline void rb_set_color(struct rb_node *rb, int color)
-{
-	rb->rb_parent_color = (rb->rb_parent_color & ~1) | color;
-}
+#define rb_parent(r)   ((struct rb_node *)((r)->__rb_parent_color & ~3))
 
 #define RB_ROOT	(struct rb_root) { NULL, }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
@@ -70,8 +52,10 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 #define RB_EMPTY_ROOT(root)  ((root)->rb_node == NULL)
 
 /* 'empty' nodes are nodes that are known not to be inserted in an rbree */
-#define RB_EMPTY_NODE(node)  ((node)->rb_parent_color == (unsigned long)(node))
-#define RB_CLEAR_NODE(node)  ((node)->rb_parent_color = (unsigned long)(node))
+#define RB_EMPTY_NODE(node)  \
+	((node)->__rb_parent_color == (unsigned long)(node))
+#define RB_CLEAR_NODE(node)  \
+	((node)->__rb_parent_color = (unsigned long)(node))
 
 
 extern void rb_insert_color(struct rb_node *, struct rb_root *);
@@ -98,7 +82,7 @@ extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
 static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
 				struct rb_node ** rb_link)
 {
-	node->rb_parent_color = (unsigned long )parent;
+	node->__rb_parent_color = (unsigned long)parent;
 	node->rb_left = node->rb_right = NULL;
 
 	*rb_link = node;

commit 4c199a93a2d36b277a9fd209a0f2793f8460a215
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:30:32 2012 -0700

    rbtree: empty nodes have no color
    
    Empty nodes have no color.  We can make use of this property to simplify
    the code emitted by the RB_EMPTY_NODE and RB_CLEAR_NODE macros.  Also,
    we can get rid of the rb_init_node function which had been introduced by
    commit 88d19cf37952 ("timers: Add rb_init_node() to allow for stack
    allocated rb nodes") to avoid some issue with the empty node's color not
    being initialized.
    
    I'm not sure what the RB_EMPTY_NODE checks in rb_prev() / rb_next() are
    doing there, though.  axboe introduced them in commit 10fd48f2376d
    ("rbtree: fixed reversed RB_EMPTY_NODE and rb_next/prev").  The way I
    see it, the 'empty node' abstraction is only used by rbtree users to
    flag nodes that they haven't inserted in any rbtree, so asking the
    predecessor or successor of such nodes doesn't make any sense.
    
    One final rb_init_node() caller was recently added in sysctl code to
    implement faster sysctl name lookups.  This code doesn't make use of
    RB_EMPTY_NODE at all, and from what I could see it only called
    rb_init_node() under the mistaken assumption that such initialization was
    required before node insertion.
    
    [sfr@canb.auug.org.au: fix net/ceph/osd_client.c build]
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Acked-by: David Woodhouse <David.Woodhouse@intel.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Santos <daniel.santos@pobox.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index e6a807720ded..2049087c43b7 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -67,17 +67,12 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 #define RB_ROOT	(struct rb_root) { NULL, }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
-#define RB_EMPTY_ROOT(root)	((root)->rb_node == NULL)
-#define RB_EMPTY_NODE(node)	(rb_parent(node) == node)
-#define RB_CLEAR_NODE(node)	(rb_set_parent(node, node))
+#define RB_EMPTY_ROOT(root)  ((root)->rb_node == NULL)
+
+/* 'empty' nodes are nodes that are known not to be inserted in an rbree */
+#define RB_EMPTY_NODE(node)  ((node)->rb_parent_color == (unsigned long)(node))
+#define RB_CLEAR_NODE(node)  ((node)->rb_parent_color = (unsigned long)(node))
 
-static inline void rb_init_node(struct rb_node *rb)
-{
-	rb->rb_parent_color = 0;
-	rb->rb_right = NULL;
-	rb->rb_left = NULL;
-	RB_CLEAR_NODE(rb);
-}
 
 extern void rb_insert_color(struct rb_node *, struct rb_root *);
 extern void rb_erase(struct rb_node *, struct rb_root *);

commit 1457d2877864d918c546735bd89c29d5e2a542f1
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:30:28 2012 -0700

    rbtree: reference Documentation/rbtree.txt for usage instructions
    
    I recently started looking at the rbtree code (with an eye towards
    improving the augmented rbtree support, but I haven't gotten there yet).
    I noticed a lot of possible speed improvements, which I am now proposing
    in this patch set.
    
    Patches 1-4 are preparatory: remove internal functions from rbtree.h so
    that users won't be tempted to use them instead of the documented APIs,
    clean up some incorrect usages I've noticed (in particular, with the
    recently added fs/proc/proc_sysctl.c rbtree usage), reference the
    documentation so that people have one less excuse to miss it, etc.
    
    Patch 5 is a small module I wrote to check the rbtree performance.  It
    creates 100 nodes with random keys and repeatedly inserts and erases them
    from an rbtree.  Additionally, it has code to check for rbtree invariants
    after each insert or erase operation.
    
    Patches 6-12 is where the rbtree optimizations are done, and they touch
    only that one file, lib/rbtree.c .  I am getting good results out of these
    - in my small benchmark doing rbtree insertion (including search) and
    erase, I'm seeing a 30% runtime reduction on Sandybridge E5, which is more
    than I initially thought would be possible.  (the results aren't as
    impressive on my two other test hosts though, AMD barcelona and Intel
    Westmere, where I am seeing 14% runtime reduction only).  The code size -
    both source (ommiting comments) and compiled - is also shorter after these
    changes.  However, I do admit that the updated code is more arduous to
    read - one big reason for that is the removal of the tree rotation
    helpers, which added some overhead but also made it easier to reason about
    things locally.  Overall, I believe this is an acceptable compromise,
    given that this code doesn't get modified very often, and that I have good
    tests for it.
    
    Upon Peter's suggestion, I added comments showing the rtree configuration
    before every rotation.  I think they help; however it's still best to have
    a copy of the cormen/leiserson/rivest book when digging into this code.
    
    This patch: reference Documentation/rbtree.txt for usage instructions
    
    include/linux/rbtree.h included some basic usage instructions, while
    Documentation/rbtree.txt had some more complete and easier to follow
    instructions.  Replacing the former with a reference to the latter.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Acked-by: David Woodhouse <David.Woodhouse@intel.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Santos <daniel.santos@pobox.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 033b507b33b1..e6a807720ded 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -23,72 +23,7 @@
   I know it's not the cleaner way,  but in C (not in C++) to get
   performances and genericity...
 
-  Some example of insert and search follows here. The search is a plain
-  normal search over an ordered tree. The insert instead must be implemented
-  in two steps: First, the code must insert the element in order as a red leaf
-  in the tree, and then the support library function rb_insert_color() must
-  be called. Such function will do the not trivial work to rebalance the
-  rbtree, if necessary.
-
------------------------------------------------------------------------
-static inline struct page * rb_search_page_cache(struct inode * inode,
-						 unsigned long offset)
-{
-	struct rb_node * n = inode->i_rb_page_cache.rb_node;
-	struct page * page;
-
-	while (n)
-	{
-		page = rb_entry(n, struct page, rb_page_cache);
-
-		if (offset < page->offset)
-			n = n->rb_left;
-		else if (offset > page->offset)
-			n = n->rb_right;
-		else
-			return page;
-	}
-	return NULL;
-}
-
-static inline struct page * __rb_insert_page_cache(struct inode * inode,
-						   unsigned long offset,
-						   struct rb_node * node)
-{
-	struct rb_node ** p = &inode->i_rb_page_cache.rb_node;
-	struct rb_node * parent = NULL;
-	struct page * page;
-
-	while (*p)
-	{
-		parent = *p;
-		page = rb_entry(parent, struct page, rb_page_cache);
-
-		if (offset < page->offset)
-			p = &(*p)->rb_left;
-		else if (offset > page->offset)
-			p = &(*p)->rb_right;
-		else
-			return page;
-	}
-
-	rb_link_node(node, parent, p);
-
-	return NULL;
-}
-
-static inline struct page * rb_insert_page_cache(struct inode * inode,
-						 unsigned long offset,
-						 struct rb_node * node)
-{
-	struct page * ret;
-	if ((ret = __rb_insert_page_cache(inode, offset, node)))
-		goto out;
-	rb_insert_color(node, &inode->i_rb_page_cache);
- out:
-	return ret;
-}
------------------------------------------------------------------------
+  See Documentation/rbtree.txt for documentation and samples.
 */
 
 #ifndef	_LINUX_RBTREE_H

commit 88d19cf37952a7e1e38b2bf87a00f0e857e63180
Author: John Stultz <john.stultz@linaro.org>
Date:   Mon Jan 3 18:59:43 2011 -0800

    timers: Add rb_init_node() to allow for stack allocated rb nodes
    
    In cases where a timerqueue_node or some structure that utilizes
    a timerqueue_node is allocated on the stack, gcc would give warnings
    caused by the timerqueue_init()'s calling RB_CLEAR_NODE, which
    self-references the nodes uninitialized data.
    
    The solution is to create an rb_init_node() function that zeros
    the rb_node structure out and then calls RB_CLEAR_NODE(), and
    then call the new init function from timerqueue_init().
    
    CC: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 7066acb2c530..033b507b33b1 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -136,6 +136,14 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 #define RB_EMPTY_NODE(node)	(rb_parent(node) == node)
 #define RB_CLEAR_NODE(node)	(rb_set_parent(node, node))
 
+static inline void rb_init_node(struct rb_node *rb)
+{
+	rb->rb_parent_color = 0;
+	rb->rb_right = NULL;
+	rb->rb_left = NULL;
+	RB_CLEAR_NODE(rb);
+}
+
 extern void rb_insert_color(struct rb_node *, struct rb_root *);
 extern void rb_erase(struct rb_node *, struct rb_root *);
 

commit b945d6b2554d550fe95caadc61e521c0ad71fb9c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat May 29 15:31:43 2010 +0200

    rbtree: Undo augmented trees performance damage and regression
    
    Reimplement augmented RB-trees without sprinkling extra branches
    all over the RB-tree code (which lives in the scheduler hot path).
    
    This approach is 'borrowed' from Fabio's BFQ implementation and
    relies on traversing the rebalance path after the RB-tree-op to
    correct the heap property for insertion/removal and make up for
    the damage done by the tree rotations.
    
    For insertion the rebalance path is trivially that from the new
    node upwards to the root, for removal it is that from the deepest
    node in the path from the to be removed node that will still
    be around after the removal.
    
    [ This patch also fixes a video driver regression reported by
      Ali Gholami Rudi - the memtype->subtree_max_end was updated
      incorrectly. ]
    
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Venkatesh Pallipadi <venki@google.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Tested-by: Ali Gholami Rudi <ali@rudi.ir>
    Cc: Fabio Checconi <fabio@gandalf.sssup.it>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    LKML-Reference: <1275414172.27810.27961.camel@twins>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index fe1872e5b37e..7066acb2c530 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -110,7 +110,6 @@ struct rb_node
 struct rb_root
 {
 	struct rb_node *rb_node;
-	void (*augment_cb)(struct rb_node *node);
 };
 
 
@@ -130,9 +129,7 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 	rb->rb_parent_color = (rb->rb_parent_color & ~1) | color;
 }
 
-#define RB_ROOT	(struct rb_root) { NULL, NULL, }
-#define RB_AUGMENT_ROOT(x)	(struct rb_root) { NULL, x}
-
+#define RB_ROOT	(struct rb_root) { NULL, }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
 #define RB_EMPTY_ROOT(root)	((root)->rb_node == NULL)
@@ -142,6 +139,14 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 extern void rb_insert_color(struct rb_node *, struct rb_root *);
 extern void rb_erase(struct rb_node *, struct rb_root *);
 
+typedef void (*rb_augment_f)(struct rb_node *node, void *data);
+
+extern void rb_augment_insert(struct rb_node *node,
+			      rb_augment_f func, void *data);
+extern struct rb_node *rb_augment_erase_begin(struct rb_node *node);
+extern void rb_augment_erase_end(struct rb_node *node,
+				 rb_augment_f func, void *data);
+
 /* Find logical next and previous nodes in a tree */
 extern struct rb_node *rb_next(const struct rb_node *);
 extern struct rb_node *rb_prev(const struct rb_node *);

commit c4fd308ed62f292518363ea9c6c2adb3c2d95f9d
Merge: 96fbeb973a7e 1f9cc3cb6a27
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 18 09:28:04 2010 -0700

    Merge branch 'x86-pat-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-pat-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, pat: Update the page flags for memtype atomically instead of using memtype_lock
      x86, pat: In rbt_memtype_check_insert(), update new->type only if valid
      x86, pat: Migrate to rbtree only backend for pat memtype management
      x86, pat: Preparatory changes in pat.c for bigger rbtree change
      rbtree: Add support for augmented rbtrees

commit 3e58974027b04e84f68b964ef368a6cd758e2f84
Author: Nikanth Karthikesan <knikanth@suse.de>
Date:   Thu Feb 25 14:44:56 2010 +0530

    doc: fix typo in comment explaining rb_tree usage
    
    Fix typo in comment explaining rb_tree usage.
    s/int/in
    
    Signed-off-by: Nikanth Karthikesan <knikanth@suse.de>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 9c295411d01f..5210a5c60877 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -25,10 +25,10 @@
 
   Some example of insert and search follows here. The search is a plain
   normal search over an ordered tree. The insert instead must be implemented
-  int two steps: as first thing the code must insert the element in
-  order as a red leaf in the tree, then the support library function
-  rb_insert_color() must be called. Such function will do the
-  not trivial work to rebalance the rbtree if necessary.
+  in two steps: First, the code must insert the element in order as a red leaf
+  in the tree, and then the support library function rb_insert_color() must
+  be called. Such function will do the not trivial work to rebalance the
+  rbtree, if necessary.
 
 -----------------------------------------------------------------------
 static inline struct page * rb_search_page_cache(struct inode * inode,

commit 17d9ddc72fb8bba0d4f67868c9c612e472a594a9
Author: Pallipadi, Venkatesh <venkatesh.pallipadi@intel.com>
Date:   Wed Feb 10 15:23:44 2010 -0800

    rbtree: Add support for augmented rbtrees
    
    Add support for augmented rbtrees in core rbtree code.
    
    This will be used in subsequent patches, in x86 PAT code, which needs
    interval trees to efficiently keep track of PAT ranges.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    LKML-Reference: <20100210232343.GA11465@linux-os.sc.intel.com>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 9c295411d01f..8e33a256ea0e 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -110,6 +110,7 @@ struct rb_node
 struct rb_root
 {
 	struct rb_node *rb_node;
+	void (*augment_cb)(struct rb_node *node);
 };
 
 
@@ -129,7 +130,9 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 	rb->rb_parent_color = (rb->rb_parent_color & ~1) | color;
 }
 
-#define RB_ROOT	(struct rb_root) { NULL, }
+#define RB_ROOT	(struct rb_root) { NULL, NULL, }
+#define RB_AUGMENT_ROOT(x)	(struct rb_root) { NULL, x}
+
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
 #define RB_EMPTY_ROOT(root)	((root)->rb_node == NULL)

commit f4b477c47332367d35686bd2b808c2156b96d7c7
Author: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>
Date:   Sat Jan 10 11:12:09 2009 +0000

    rbtree: add const qualifier to some functions
    
    The 'rb_first()', 'rb_last()', 'rb_next()' and 'rb_prev()' calls
    take a pointer to an RB node or RB root. They do not change the
    pointed objects, so add a 'const' qualifier in order to make life
    of the users of these functions easier.
    
    Indeed, if I have my own constant pointer &const struct my_type *p,
    and I call 'rb_next(&p->rb)', I get a GCC warning:
    
    warning: passing argument 1 of ‘rb_next’ discards qualifiers from pointer target type
    
    Signed-off-by: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 344bc3495ddb..9c295411d01f 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -140,10 +140,10 @@ extern void rb_insert_color(struct rb_node *, struct rb_root *);
 extern void rb_erase(struct rb_node *, struct rb_root *);
 
 /* Find logical next and previous nodes in a tree */
-extern struct rb_node *rb_next(struct rb_node *);
-extern struct rb_node *rb_prev(struct rb_node *);
-extern struct rb_node *rb_first(struct rb_root *);
-extern struct rb_node *rb_last(struct rb_root *);
+extern struct rb_node *rb_next(const struct rb_node *);
+extern struct rb_node *rb_prev(const struct rb_node *);
+extern struct rb_node *rb_first(const struct rb_root *);
+extern struct rb_node *rb_last(const struct rb_root *);
 
 /* Fast replacement of a single node without remove/rebalance/add/rebalance */
 extern void rb_replace_node(struct rb_node *victim, struct rb_node *new, 

commit 10fd48f2376db52f08bf0420d2c4f580e39269e1
Author: Jens Axboe <axboe@suse.de>
Date:   Tue Jul 11 21:15:52 2006 +0200

    [PATCH] rbtree: fixed reversed RB_EMPTY_NODE and rb_next/prev
    
    The conditions got reserved. Also make rb_next() and rb_prev() check
    for the empty condition.
    
    Signed-off-by: Jens Axboe <axboe@suse.de>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 8d5382e62c08..344bc3495ddb 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -133,7 +133,7 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
 #define RB_EMPTY_ROOT(root)	((root)->rb_node == NULL)
-#define RB_EMPTY_NODE(node)	(rb_parent(node) != node)
+#define RB_EMPTY_NODE(node)	(rb_parent(node) == node)
 #define RB_CLEAR_NODE(node)	(rb_set_parent(node, node))
 
 extern void rb_insert_color(struct rb_node *, struct rb_root *);

commit dd67d051529387f6e44d22d1d5540ef281965fdd
Author: Jens Axboe <axboe@suse.de>
Date:   Wed Jun 21 09:36:18 2006 +0200

    [PATCH] rbtree: support functions used by the io schedulers
    
    They all duplicate macros to check for empty root and/or node, and
    clearing a node. So put those in rbtree.h.
    
    Signed-off-by: Jens Axboe <axboe@suse.de>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index f37006f21664..8d5382e62c08 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -132,6 +132,10 @@ static inline void rb_set_color(struct rb_node *rb, int color)
 #define RB_ROOT	(struct rb_root) { NULL, }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
+#define RB_EMPTY_ROOT(root)	((root)->rb_node == NULL)
+#define RB_EMPTY_NODE(node)	(rb_parent(node) != node)
+#define RB_CLEAR_NODE(node)	(rb_set_parent(node, node))
+
 extern void rb_insert_color(struct rb_node *, struct rb_root *);
 extern void rb_erase(struct rb_node *, struct rb_root *);
 

commit 2f3243aebd8df4d9eecaeca04bbff6c7dbfb2142
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Mon Jun 5 20:19:05 2006 +0100

    [RBTREE] Switch rb_colour() et al to en_US spelling of 'color' for consistency
    
    Since rb_insert_color() is part of the _public_ API, while the others are
    purely internal, switch to be consistent with that.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 3cc30b0ab828..f37006f21664 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -99,7 +99,7 @@ static inline struct page * rb_insert_page_cache(struct inode * inode,
 
 struct rb_node
 {
-	unsigned long  rb_parent_colour;
+	unsigned long  rb_parent_color;
 #define	RB_RED		0
 #define	RB_BLACK	1
 	struct rb_node *rb_right;
@@ -113,20 +113,20 @@ struct rb_root
 };
 
 
-#define rb_parent(r)   ((struct rb_node *)((r)->rb_parent_colour & ~3))
-#define rb_colour(r)   ((r)->rb_parent_colour & 1)
-#define rb_is_red(r)   (!rb_colour(r))
-#define rb_is_black(r) rb_colour(r)
-#define rb_set_red(r)  do { (r)->rb_parent_colour &= ~1; } while (0)
-#define rb_set_black(r)  do { (r)->rb_parent_colour |= 1; } while (0)
+#define rb_parent(r)   ((struct rb_node *)((r)->rb_parent_color & ~3))
+#define rb_color(r)   ((r)->rb_parent_color & 1)
+#define rb_is_red(r)   (!rb_color(r))
+#define rb_is_black(r) rb_color(r)
+#define rb_set_red(r)  do { (r)->rb_parent_color &= ~1; } while (0)
+#define rb_set_black(r)  do { (r)->rb_parent_color |= 1; } while (0)
 
 static inline void rb_set_parent(struct rb_node *rb, struct rb_node *p)
 {
-	rb->rb_parent_colour = (rb->rb_parent_colour & 3) | (unsigned long)p;
+	rb->rb_parent_color = (rb->rb_parent_color & 3) | (unsigned long)p;
 }
-static inline void rb_set_colour(struct rb_node *rb, int colour)
+static inline void rb_set_color(struct rb_node *rb, int color)
 {
-	rb->rb_parent_colour = (rb->rb_parent_colour & ~1) | colour;
+	rb->rb_parent_color = (rb->rb_parent_color & ~1) | color;
 }
 
 #define RB_ROOT	(struct rb_root) { NULL, }
@@ -148,7 +148,7 @@ extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
 static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
 				struct rb_node ** rb_link)
 {
-	node->rb_parent_colour = (unsigned long )parent;
+	node->rb_parent_color = (unsigned long )parent;
 	node->rb_left = node->rb_right = NULL;
 
 	*rb_link = node;

commit e977145aeaad23d443686f2a2d5b32800d1607c5
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Fri Apr 21 23:15:39 2006 +0100

    [RBTREE] Add explicit alignment to sizeof(long) for struct rb_node.
    
    Seems like a strange requirement, but allegedly it was necessary for
    struct address_space on CRIS, because it otherwise ended up being only
    byte-aligned. It's harmless enough, and easier to just do it than to
    prove it isn't necessary... although I really ought to dig out my etrax
    board and test it some time.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 748be50329d8..3cc30b0ab828 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -104,7 +104,8 @@ struct rb_node
 #define	RB_BLACK	1
 	struct rb_node *rb_right;
 	struct rb_node *rb_left;
-};
+} __attribute__((aligned(sizeof(long))));
+    /* The alignment might seem pointless, but allegedly CRIS needs it */
 
 struct rb_root
 {

commit 55a981027fc393c86de2c4e7836c9515088a9a58
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Fri Apr 21 13:35:51 2006 +0100

    [RBTREE] Merge colour and parent fields of struct rb_node.
    
    We only used a single bit for colour information, so having a whole
    machine word of space allocated for it was a bit wasteful. Instead,
    store it in the lowest bit of the 'parent' pointer, since that was
    always going to be aligned anyway.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index ffee81ce7b6f..748be50329d8 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -99,28 +99,35 @@ static inline struct page * rb_insert_page_cache(struct inode * inode,
 
 struct rb_node
 {
-	struct rb_node *rb_parent;
-	int rb_color;
+	unsigned long  rb_parent_colour;
 #define	RB_RED		0
 #define	RB_BLACK	1
 	struct rb_node *rb_right;
 	struct rb_node *rb_left;
 };
 
-#define rb_parent(r)		((r)->rb_parent)
-#define rb_set_parent(r,p)	do { (r)->rb_parent = p; } while (0)
-#define rb_colour(r)		((r)->rb_colour)
-#define rb_is_red(r)		((r)->colour == RB_RED)
-#define rb_is_black(r)		((r)->colour == RB_BLACK)
-#define rb_set_red(r)		do { (r)->colour = RB_RED; } while (0)
-#define rb_set_black(r)		do { (r)->colour = RB_BLACK; } while (0)
-#define rb_set_colour(r,c)	do { (r)->colour = (c); } while (0)
-
 struct rb_root
 {
 	struct rb_node *rb_node;
 };
 
+
+#define rb_parent(r)   ((struct rb_node *)((r)->rb_parent_colour & ~3))
+#define rb_colour(r)   ((r)->rb_parent_colour & 1)
+#define rb_is_red(r)   (!rb_colour(r))
+#define rb_is_black(r) rb_colour(r)
+#define rb_set_red(r)  do { (r)->rb_parent_colour &= ~1; } while (0)
+#define rb_set_black(r)  do { (r)->rb_parent_colour |= 1; } while (0)
+
+static inline void rb_set_parent(struct rb_node *rb, struct rb_node *p)
+{
+	rb->rb_parent_colour = (rb->rb_parent_colour & 3) | (unsigned long)p;
+}
+static inline void rb_set_colour(struct rb_node *rb, int colour)
+{
+	rb->rb_parent_colour = (rb->rb_parent_colour & ~1) | colour;
+}
+
 #define RB_ROOT	(struct rb_root) { NULL, }
 #define	rb_entry(ptr, type, member) container_of(ptr, type, member)
 
@@ -140,8 +147,7 @@ extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
 static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
 				struct rb_node ** rb_link)
 {
-	node->rb_parent = parent;
-	node->rb_color = RB_RED;
+	node->rb_parent_colour = (unsigned long )parent;
 	node->rb_left = node->rb_right = NULL;
 
 	*rb_link = node;

commit 7fe1e133bf45b0fe70491ed3d4c5b491feff7aa8
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Fri Apr 21 13:12:44 2006 +0100

    [RBTREE] Add accessor macros for colour and parent fields of rb_node
    
    This is in preparation for merging those fields into a single
    'unsigned long', because using a whole machine-word for a single bit
    of colour information is wasteful.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
index 4b7cc4fe366d..ffee81ce7b6f 100644
--- a/include/linux/rbtree.h
+++ b/include/linux/rbtree.h
@@ -107,6 +107,15 @@ struct rb_node
 	struct rb_node *rb_left;
 };
 
+#define rb_parent(r)		((r)->rb_parent)
+#define rb_set_parent(r,p)	do { (r)->rb_parent = p; } while (0)
+#define rb_colour(r)		((r)->rb_colour)
+#define rb_is_red(r)		((r)->colour == RB_RED)
+#define rb_is_black(r)		((r)->colour == RB_BLACK)
+#define rb_set_red(r)		do { (r)->colour = RB_RED; } while (0)
+#define rb_set_black(r)		do { (r)->colour = RB_BLACK; } while (0)
+#define rb_set_colour(r,c)	do { (r)->colour = (c); } while (0)
+
 struct rb_root
 {
 	struct rb_node *rb_node;

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/rbtree.h b/include/linux/rbtree.h
new file mode 100644
index 000000000000..4b7cc4fe366d
--- /dev/null
+++ b/include/linux/rbtree.h
@@ -0,0 +1,141 @@
+/*
+  Red Black Trees
+  (C) 1999  Andrea Arcangeli <andrea@suse.de>
+  
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of the GNU General Public License as published by
+  the Free Software Foundation; either version 2 of the License, or
+  (at your option) any later version.
+
+  This program is distributed in the hope that it will be useful,
+  but WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+  GNU General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+
+  linux/include/linux/rbtree.h
+
+  To use rbtrees you'll have to implement your own insert and search cores.
+  This will avoid us to use callbacks and to drop drammatically performances.
+  I know it's not the cleaner way,  but in C (not in C++) to get
+  performances and genericity...
+
+  Some example of insert and search follows here. The search is a plain
+  normal search over an ordered tree. The insert instead must be implemented
+  int two steps: as first thing the code must insert the element in
+  order as a red leaf in the tree, then the support library function
+  rb_insert_color() must be called. Such function will do the
+  not trivial work to rebalance the rbtree if necessary.
+
+-----------------------------------------------------------------------
+static inline struct page * rb_search_page_cache(struct inode * inode,
+						 unsigned long offset)
+{
+	struct rb_node * n = inode->i_rb_page_cache.rb_node;
+	struct page * page;
+
+	while (n)
+	{
+		page = rb_entry(n, struct page, rb_page_cache);
+
+		if (offset < page->offset)
+			n = n->rb_left;
+		else if (offset > page->offset)
+			n = n->rb_right;
+		else
+			return page;
+	}
+	return NULL;
+}
+
+static inline struct page * __rb_insert_page_cache(struct inode * inode,
+						   unsigned long offset,
+						   struct rb_node * node)
+{
+	struct rb_node ** p = &inode->i_rb_page_cache.rb_node;
+	struct rb_node * parent = NULL;
+	struct page * page;
+
+	while (*p)
+	{
+		parent = *p;
+		page = rb_entry(parent, struct page, rb_page_cache);
+
+		if (offset < page->offset)
+			p = &(*p)->rb_left;
+		else if (offset > page->offset)
+			p = &(*p)->rb_right;
+		else
+			return page;
+	}
+
+	rb_link_node(node, parent, p);
+
+	return NULL;
+}
+
+static inline struct page * rb_insert_page_cache(struct inode * inode,
+						 unsigned long offset,
+						 struct rb_node * node)
+{
+	struct page * ret;
+	if ((ret = __rb_insert_page_cache(inode, offset, node)))
+		goto out;
+	rb_insert_color(node, &inode->i_rb_page_cache);
+ out:
+	return ret;
+}
+-----------------------------------------------------------------------
+*/
+
+#ifndef	_LINUX_RBTREE_H
+#define	_LINUX_RBTREE_H
+
+#include <linux/kernel.h>
+#include <linux/stddef.h>
+
+struct rb_node
+{
+	struct rb_node *rb_parent;
+	int rb_color;
+#define	RB_RED		0
+#define	RB_BLACK	1
+	struct rb_node *rb_right;
+	struct rb_node *rb_left;
+};
+
+struct rb_root
+{
+	struct rb_node *rb_node;
+};
+
+#define RB_ROOT	(struct rb_root) { NULL, }
+#define	rb_entry(ptr, type, member) container_of(ptr, type, member)
+
+extern void rb_insert_color(struct rb_node *, struct rb_root *);
+extern void rb_erase(struct rb_node *, struct rb_root *);
+
+/* Find logical next and previous nodes in a tree */
+extern struct rb_node *rb_next(struct rb_node *);
+extern struct rb_node *rb_prev(struct rb_node *);
+extern struct rb_node *rb_first(struct rb_root *);
+extern struct rb_node *rb_last(struct rb_root *);
+
+/* Fast replacement of a single node without remove/rebalance/add/rebalance */
+extern void rb_replace_node(struct rb_node *victim, struct rb_node *new, 
+			    struct rb_root *root);
+
+static inline void rb_link_node(struct rb_node * node, struct rb_node * parent,
+				struct rb_node ** rb_link)
+{
+	node->rb_parent = parent;
+	node->rb_color = RB_RED;
+	node->rb_left = node->rb_right = NULL;
+
+	*rb_link = node;
+}
+
+#endif	/* _LINUX_RBTREE_H */
