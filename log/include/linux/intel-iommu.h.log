commit 16ecf10e815d70d11d2300243f4a3b4c7c5acac7
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Tue Jun 23 07:13:41 2020 +0800

    iommu/vt-d: Set U/S bit in first level page table by default
    
    When using first-level translation for IOVA, currently the U/S bit in the
    page table is cleared which implies DMA requests with user privilege are
    blocked. As the result, following error messages might be observed when
    passing through a device to user level:
    
    DMAR: DRHD: handling fault status reg 3
    DMAR: [DMA Read] Request device [41:00.0] PASID 1 fault addr 7ecdcd000
            [fault reason 129] SM: U/S set 0 for first-level translation
            with user privilege
    
    This fixes it by setting U/S bit in the first level page table and makes
    IOVA over first level compatible with previous second-level translation.
    
    Fixes: b802d070a52a1 ("iommu/vt-d: Use iova over first level")
    Reported-by: Xin Zeng <xin.zeng@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200622231345.29722-3-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 4100bd224f5c..3e8fa1c7a1e6 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -41,6 +41,7 @@
 #define DMA_PTE_SNP		BIT_ULL(11)
 
 #define DMA_FL_PTE_PRESENT	BIT_ULL(0)
+#define DMA_FL_PTE_US		BIT_ULL(2)
 #define DMA_FL_PTE_XD		BIT_ULL(63)
 
 #define ADDR_WIDTH_5LEVEL	(57)

commit 4fda230ecddc2573ed88632e98b69b0b9b68c0ad
Author: Jon Derrick <jonathan.derrick@intel.com>
Date:   Wed May 27 10:56:16 2020 -0600

    iommu/vt-d: Allocate domain info for real DMA sub-devices
    
    Sub-devices of a real DMA device might exist on a separate segment than
    the real DMA device and its IOMMU. These devices should still have a
    valid device_domain_info, but the current dma alias model won't
    allocate info for the subdevice.
    
    This patch adds a segment member to struct device_domain_info and uses
    the sub-device's BDF so that these sub-devices won't alias to other
    devices.
    
    Fixes: 2b0140c69637e ("iommu/vt-d: Use pci_real_dma_dev() for mapping")
    Cc: stable@vger.kernel.org # v5.6+
    Signed-off-by: Jon Derrick <jonathan.derrick@intel.com>
    Acked-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200527165617.297470-3-jonathan.derrick@intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 21633cee6331..4100bd224f5c 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -609,6 +609,7 @@ struct device_domain_info {
 	struct list_head auxiliary_domains; /* auxiliary domains
 					     * attached to this device
 					     */
+	u32 segment;		/* PCI segment number */
 	u8 bus;			/* PCI bus number */
 	u8 devfn;		/* PCI devfn number */
 	u16 pfsid;		/* SRIOV physical function source ID */

commit 66ac4db36f4c12a3b02db864ccb0801cd938b6de
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat May 16 14:20:58 2020 +0800

    iommu/vt-d: Add page request draining support
    
    When a PASID is stopped or terminated, there can be pending PRQs
    (requests that haven't received responses) in remapping hardware.
    This adds the interface to drain page requests and call it when a
    PASID is terminated.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-16-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 677dee59e3c0..21633cee6331 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -292,6 +292,8 @@
 
 /* PRS_REG */
 #define DMA_PRS_PPR	((u32)1)
+#define DMA_PRS_PRO	((u32)2)
+
 #define DMA_VCS_PAS	((u64)1)
 
 #define IOMMU_WAIT_OP(iommu, offset, op, cond, sts)			\
@@ -333,6 +335,7 @@ enum {
 
 #define QI_IWD_STATUS_DATA(d)	(((u64)d) << 32)
 #define QI_IWD_STATUS_WRITE	(((u64)1) << 5)
+#define QI_IWD_FENCE		(((u64)1) << 6)
 #define QI_IWD_PRQ_DRAIN	(((u64)1) << 7)
 
 #define QI_IOTLB_DID(did) 	(((u64)did) << 16)
@@ -582,6 +585,7 @@ struct intel_iommu {
 #ifdef CONFIG_INTEL_IOMMU_SVM
 	struct page_req_dsc *prq;
 	unsigned char prq_name[16];    /* Name for PRQ interrupt */
+	struct completion prq_complete;
 	struct ioasid_allocator_ops pasid_allocator; /* Custom allocator for PASIDs */
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */

commit 8a1d824625402b3ef3c3e5965663354ff0394d86
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat May 16 14:20:55 2020 +0800

    iommu/vt-d: Multiple descriptors per qi_submit_sync()
    
    Current qi_submit_sync() only supports single invalidation descriptor
    per submission and appends wait descriptor after each submission to
    poll the hardware completion. This extends the qi_submit_sync() helper
    to support multiple descriptors, and add an option so that the caller
    could specify the Page-request Drain (PD) bit in the wait descriptor.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-13-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 42245e1e1b48..677dee59e3c0 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -333,6 +333,7 @@ enum {
 
 #define QI_IWD_STATUS_DATA(d)	(((u64)d) << 32)
 #define QI_IWD_STATUS_WRITE	(((u64)1) << 5)
+#define QI_IWD_PRQ_DRAIN	(((u64)1) << 7)
 
 #define QI_IOTLB_DID(did) 	(((u64)did) << 16)
 #define QI_IOTLB_DR(dr) 	(((u64)dr) << 7)
@@ -702,7 +703,13 @@ void qi_flush_dev_iotlb_pasid(struct intel_iommu *iommu, u16 sid, u16 pfsid,
 void qi_flush_pasid_cache(struct intel_iommu *iommu, u16 did, u64 granu,
 			  int pasid);
 
-extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
+int qi_submit_sync(struct intel_iommu *iommu, struct qi_desc *desc,
+		   unsigned int count, unsigned long options);
+/*
+ * Options used in qi_submit_sync:
+ * QI_OPT_WAIT_DRAIN - Wait for PRQ drain completion, spec 6.5.2.8.
+ */
+#define QI_OPT_WAIT_DRAIN		BIT(0)
 
 extern int dmar_ir_support(void);
 

commit 064a57d7ddfc46ada02b477b91c478001b03bfa3
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Sat May 16 14:20:54 2020 +0800

    iommu/vt-d: Replace intel SVM APIs with generic SVA APIs
    
    This patch is an initial step to replace Intel SVM code with the
    following IOMMU SVA ops:
    intel_svm_bind_mm() => iommu_sva_bind_device()
    intel_svm_unbind_mm() => iommu_sva_unbind_device()
    intel_svm_is_pasid_valid() => iommu_sva_get_pasid()
    
    The features below will continue to work but are not included in this patch
    in that they are handled mostly within the IOMMU subsystem.
    - IO page fault
    - mmu notifier
    
    Consolidation of the above will come after merging generic IOMMU sva
    code[1]. There should not be any changes needed for SVA users such as
    accelerator device drivers during this time.
    
    [1] http://jpbrucker.net/sva/
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-12-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index caa179e806fc..42245e1e1b48 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -723,6 +723,10 @@ extern int intel_svm_finish_prq(struct intel_iommu *iommu);
 int intel_svm_bind_gpasid(struct iommu_domain *domain, struct device *dev,
 			  struct iommu_gpasid_bind_data *data);
 int intel_svm_unbind_gpasid(struct device *dev, int pasid);
+struct iommu_sva *intel_svm_bind(struct device *dev, struct mm_struct *mm,
+				 void *drvdata);
+void intel_svm_unbind(struct iommu_sva *handle);
+int intel_svm_get_pasid(struct iommu_sva *handle);
 struct svm_dev_ops;
 
 struct intel_svm_dev {
@@ -730,6 +734,8 @@ struct intel_svm_dev {
 	struct rcu_head rcu;
 	struct device *dev;
 	struct svm_dev_ops *ops;
+	struct iommu_sva sva;
+	int pasid;
 	int users;
 	u16 did;
 	u16 dev_iotlb:1;

commit e85bb99b79ca5ad2681612a7bb22f94cc2c71866
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat May 16 14:20:52 2020 +0800

    iommu/vt-d: Add get_domain_info() helper
    
    Add a get_domain_info() helper to retrieve the valid per-device
    iommu private data.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-10-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index e14124f74b3a..caa179e806fc 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -714,6 +714,7 @@ int for_each_device_domain(int (*fn)(struct device_domain_info *info,
 void iommu_flush_write_buffer(struct intel_iommu *iommu);
 int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct device *dev);
 struct dmar_domain *find_domain(struct device *dev);
+struct device_domain_info *get_domain_info(struct device *dev);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
 extern void intel_svm_check(struct intel_iommu *iommu);

commit 3375303e82877552f3b2b42309e8233fe715fd9f
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Sat May 16 14:20:51 2020 +0800

    iommu/vt-d: Add custom allocator for IOASID
    
    When VT-d driver runs in the guest, PASID allocation must be
    performed via virtual command interface. This patch registers a
    custom IOASID allocator which takes precedence over the default
    XArray based allocator. The resulting IOASID allocation will always
    come from the host. This ensures that PASID namespace is system-
    wide.
    
    Virtual command registers are used in the guest only, to prevent
    vmexit cost, we cache the capability and store it during initialization.
    
    Signed-off-by: Liu, Yi L <yi.l.liu@intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-9-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index addb310b4ded..e14124f74b3a 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -19,6 +19,7 @@
 #include <linux/iommu.h>
 #include <linux/io-64-nonatomic-lo-hi.h>
 #include <linux/dmar.h>
+#include <linux/ioasid.h>
 
 #include <asm/cacheflush.h>
 #include <asm/iommu.h>
@@ -195,6 +196,9 @@
 #define ecap_max_handle_mask(e) ((e >> 20) & 0xf)
 #define ecap_sc_support(e)	((e >> 7) & 0x1) /* Snooping Control */
 
+/* Virtual command interface capability */
+#define vccap_pasid(v)		(((v) & DMA_VCS_PAS)) /* PASID allocation */
+
 /* IOTLB_REG */
 #define DMA_TLB_FLUSH_GRANU_OFFSET  60
 #define DMA_TLB_GLOBAL_FLUSH (((u64)1) << 60)
@@ -288,6 +292,7 @@
 
 /* PRS_REG */
 #define DMA_PRS_PPR	((u32)1)
+#define DMA_VCS_PAS	((u64)1)
 
 #define IOMMU_WAIT_OP(iommu, offset, op, cond, sts)			\
 do {									\
@@ -555,6 +560,7 @@ struct intel_iommu {
 	u64		reg_size; /* size of hw register set */
 	u64		cap;
 	u64		ecap;
+	u64		vccap;
 	u32		gcmd; /* Holds TE, EAFL. Don't need SRTP, SFL, WBF */
 	raw_spinlock_t	register_lock; /* protect register handling */
 	int		seq_id;	/* sequence id of the iommu */
@@ -575,6 +581,7 @@ struct intel_iommu {
 #ifdef CONFIG_INTEL_IOMMU_SVM
 	struct page_req_dsc *prq;
 	unsigned char prq_name[16];    /* Name for PRQ interrupt */
+	struct ioasid_allocator_ops pasid_allocator; /* Custom allocator for PASIDs */
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
 	u32 *iommu_state; /* Store iommu states between suspend and resume.*/

commit 24f27d32ab6b71dedcbbeeab8f9bdc143b539ac0
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat May 16 14:20:50 2020 +0800

    iommu/vt-d: Enlightened PASID allocation
    
    Enabling IOMMU in a guest requires communication with the host
    driver for certain aspects. Use of PASID ID to enable Shared Virtual
    Addressing (SVA) requires managing PASID's in the host. VT-d 3.0 spec
    provides a Virtual Command Register (VCMD) to facilitate this.
    Writes to this register in the guest are trapped by vIOMMU which
    proxies the call to the host driver.
    
    This virtual command interface consists of a capability register,
    a virtual command register, and a virtual response register. Refer
    to section 10.4.42, 10.4.43, 10.4.44 for more information.
    
    This patch adds the enlightened PASID allocation/free interfaces
    via the virtual command interface.
    
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-8-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a9c984b29a72..addb310b4ded 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -169,6 +169,7 @@
 #define ecap_smpwc(e)		(((e) >> 48) & 0x1)
 #define ecap_flts(e)		(((e) >> 47) & 0x1)
 #define ecap_slts(e)		(((e) >> 46) & 0x1)
+#define ecap_vcs(e)		(((e) >> 44) & 0x1)
 #define ecap_smts(e)		(((e) >> 43) & 0x1)
 #define ecap_dit(e)		((e >> 41) & 0x1)
 #define ecap_pasid(e)		((e >> 40) & 0x1)

commit 61a06a16e36d830f7811fbf931668d87197d95b7
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Sat May 16 14:20:48 2020 +0800

    iommu/vt-d: Support flushing more translation cache types
    
    When Shared Virtual Memory is exposed to a guest via vIOMMU, scalable
    IOTLB invalidation may be passed down from outside IOMMU subsystems.
    This patch adds invalidation functions that can be used for additional
    translation cache types.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-6-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 3dfd426dfb03..a9c984b29a72 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -334,7 +334,7 @@ enum {
 #define QI_IOTLB_GRAN(gran) 	(((u64)gran) >> (DMA_TLB_FLUSH_GRANU_OFFSET-4))
 #define QI_IOTLB_ADDR(addr)	(((u64)addr) & VTD_PAGE_MASK)
 #define QI_IOTLB_IH(ih)		(((u64)ih) << 6)
-#define QI_IOTLB_AM(am)		(((u8)am))
+#define QI_IOTLB_AM(am)		(((u8)am) & 0x3f)
 
 #define QI_CC_FM(fm)		(((u64)fm) << 48)
 #define QI_CC_SID(sid)		(((u64)sid) << 32)
@@ -353,16 +353,21 @@ enum {
 #define QI_PC_DID(did)		(((u64)did) << 16)
 #define QI_PC_GRAN(gran)	(((u64)gran) << 4)
 
-#define QI_PC_ALL_PASIDS	(QI_PC_TYPE | QI_PC_GRAN(0))
-#define QI_PC_PASID_SEL		(QI_PC_TYPE | QI_PC_GRAN(1))
+/* PASID cache invalidation granu */
+#define QI_PC_ALL_PASIDS	0
+#define QI_PC_PASID_SEL		1
 
 #define QI_EIOTLB_ADDR(addr)	((u64)(addr) & VTD_PAGE_MASK)
 #define QI_EIOTLB_IH(ih)	(((u64)ih) << 6)
-#define QI_EIOTLB_AM(am)	(((u64)am))
+#define QI_EIOTLB_AM(am)	(((u64)am) & 0x3f)
 #define QI_EIOTLB_PASID(pasid) 	(((u64)pasid) << 32)
 #define QI_EIOTLB_DID(did)	(((u64)did) << 16)
 #define QI_EIOTLB_GRAN(gran) 	(((u64)gran) << 4)
 
+/* QI Dev-IOTLB inv granu */
+#define QI_DEV_IOTLB_GRAN_ALL		1
+#define QI_DEV_IOTLB_GRAN_PASID_SEL	0
+
 #define QI_DEV_EIOTLB_ADDR(a)	((u64)(a) & VTD_PAGE_MASK)
 #define QI_DEV_EIOTLB_SIZE	(((u64)1) << 11)
 #define QI_DEV_EIOTLB_GLOB(g)	((u64)g)
@@ -679,8 +684,16 @@ extern void qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 			  unsigned int size_order, u64 type);
 extern void qi_flush_dev_iotlb(struct intel_iommu *iommu, u16 sid, u16 pfsid,
 			u16 qdep, u64 addr, unsigned mask);
+
 void qi_flush_piotlb(struct intel_iommu *iommu, u16 did, u32 pasid, u64 addr,
 		     unsigned long npages, bool ih);
+
+void qi_flush_dev_iotlb_pasid(struct intel_iommu *iommu, u16 sid, u16 pfsid,
+			      u32 pasid, u16 qdep, u64 addr,
+			      unsigned int size_order, u64 granu);
+void qi_flush_pasid_cache(struct intel_iommu *iommu, u16 did, u64 granu,
+			  int pasid);
+
 extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);

commit 56722a4398a306585ca3ed39ff54fc907af98618
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Sat May 16 14:20:47 2020 +0800

    iommu/vt-d: Add bind guest PASID support
    
    When supporting guest SVA with emulated IOMMU, the guest PASID
    table is shadowed in VMM. Updates to guest vIOMMU PASID table
    will result in PASID cache flush which will be passed down to
    the host as bind guest PASID calls.
    
    For the SL page tables, it will be harvested from device's
    default domain (request w/o PASID), or aux domain in case of
    mediated device.
    
        .-------------.  .---------------------------.
        |   vIOMMU    |  | Guest process CR3, FL only|
        |             |  '---------------------------'
        .----------------/
        | PASID Entry |--- PASID cache flush -
        '-------------'                       |
        |             |                       V
        |             |                CR3 in GPA
        '-------------'
    Guest
    ------| Shadow |--------------------------|--------
          v        v                          v
    Host
        .-------------.  .----------------------.
        |   pIOMMU    |  | Bind FL for GVA-GPA  |
        |             |  '----------------------'
        .----------------/  |
        | PASID Entry |     V (Nested xlate)
        '----------------\.------------------------------.
        |             |   |SL for GPA-HPA, default domain|
        |             |   '------------------------------'
        '-------------'
    Where:
     - FL = First level/stage one page tables
     - SL = Second level/stage two page tables
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-5-baolu.lu@linux.intel.com
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index e0d1fed7cbe4..3dfd426dfb03 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -698,7 +698,9 @@ struct dmar_domain *find_domain(struct device *dev);
 extern void intel_svm_check(struct intel_iommu *iommu);
 extern int intel_svm_enable_prq(struct intel_iommu *iommu);
 extern int intel_svm_finish_prq(struct intel_iommu *iommu);
-
+int intel_svm_bind_gpasid(struct iommu_domain *domain, struct device *dev,
+			  struct iommu_gpasid_bind_data *data);
+int intel_svm_unbind_gpasid(struct device *dev, int pasid);
 struct svm_dev_ops;
 
 struct intel_svm_dev {
@@ -715,9 +717,11 @@ struct intel_svm_dev {
 struct intel_svm {
 	struct mmu_notifier notifier;
 	struct mm_struct *mm;
+
 	struct intel_iommu *iommu;
 	int flags;
 	int pasid;
+	int gpasid; /* In case that guest PASID is different from host PASID */
 	struct list_head devs;
 	struct list_head list;
 };

commit b0d1f8741b812352fe0e5f3b2381427085f23e19
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Sat May 16 14:20:46 2020 +0800

    iommu/vt-d: Add nested translation helper function
    
    Nested translation mode is supported in VT-d 3.0 Spec.CH 3.8.
    With PASID granular translation type set to 0x11b, translation
    result from the first level(FL) also subject to a second level(SL)
    page table translation. This mode is used for SVA virtualization,
    where FL performs guest virtual to guest physical translation and
    SL performs guest physical to host physical translation.
    
    This patch adds a helper function for setting up nested translation
    where second level comes from a domain and first level comes from
    a guest PGD.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-4-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index ed7171d2ae1f..e0d1fed7cbe4 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -42,6 +42,9 @@
 #define DMA_FL_PTE_PRESENT	BIT_ULL(0)
 #define DMA_FL_PTE_XD		BIT_ULL(63)
 
+#define ADDR_WIDTH_5LEVEL	(57)
+#define ADDR_WIDTH_4LEVEL	(48)
+
 #define CONTEXT_TT_MULTI_LEVEL	0
 #define CONTEXT_TT_DEV_IOTLB	1
 #define CONTEXT_TT_PASS_THROUGH 2
@@ -480,6 +483,23 @@ struct context_entry {
 	u64 hi;
 };
 
+/* si_domain contains mulitple devices */
+#define DOMAIN_FLAG_STATIC_IDENTITY		BIT(0)
+
+/*
+ * When VT-d works in the scalable mode, it allows DMA translation to
+ * happen through either first level or second level page table. This
+ * bit marks that the DMA translation for the domain goes through the
+ * first level page table, otherwise, it goes through the second level.
+ */
+#define DOMAIN_FLAG_USE_FIRST_LEVEL		BIT(1)
+
+/*
+ * Domain represents a virtual machine which demands iommu nested
+ * translation mode support.
+ */
+#define DOMAIN_FLAG_NESTING_MODE		BIT(2)
+
 struct dmar_domain {
 	int	nid;			/* node id */
 

commit 3db9983e4327f773c490de2a8c66d6000561d88a
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Sat May 16 14:20:44 2020 +0800

    iommu/vt-d: Move domain helper to header
    
    Move domain helper to header to be used by SVA code.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Link: https://lore.kernel.org/r/20200516062101.29541-2-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 980234ae0312..ed7171d2ae1f 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -595,6 +595,12 @@ static inline void __iommu_flush_cache(
 		clflush_cache_range(addr, size);
 }
 
+/* Convert generic struct iommu_domain to private struct dmar_domain */
+static inline struct dmar_domain *to_dmar_domain(struct iommu_domain *dom)
+{
+	return container_of(dom, struct dmar_domain, domain);
+}
+
 /*
  * 0: readable
  * 1: writable

commit ba3b01d7a6f4ab9f8a0557044c9a7678f64ae070
Author: Megha Dey <megha.dey@linux.intel.com>
Date:   Mon Mar 9 13:09:46 2020 -0700

    iommu/vt-d: Fix debugfs register reads
    
    Commit 6825d3ea6cde ("iommu/vt-d: Add debugfs support to show register
    contents") dumps the register contents for all IOMMU devices.
    
    Currently, a 64 bit read(dmar_readq) is done for all the IOMMU registers,
    even though some of the registers are 32 bits, which is incorrect.
    
    Use the correct read function variant (dmar_readl/dmar_readq) while
    reading the contents of 32/64 bit registers respectively.
    
    Signed-off-by: Megha Dey <megha.dey@linux.intel.com>
    Link: https://lore.kernel.org/r/1583784587-26126-2-git-send-email-megha.dey@linux.intel.com
    Acked-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 4a16b39ae353..980234ae0312 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -123,6 +123,8 @@
 
 #define dmar_readq(a) readq(a)
 #define dmar_writeq(a,v) writeq(v,a)
+#define dmar_readl(a) readl(a)
+#define dmar_writel(a, v) writel(v, a)
 
 #define DMAR_VER_MAJOR(v)		(((v) & 0xf0) >> 4)
 #define DMAR_VER_MINOR(v)		((v) & 0x0f)

commit e2726daea583d81e447b71e09b79e67f618d6152
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Thu Jan 2 08:18:22 2020 +0800

    iommu/vt-d: debugfs: Add support to show page table internals
    
    Export page table internals of the domain attached to each device.
    Example of such dump on a Skylake machine:
    
    $ sudo cat /sys/kernel/debug/iommu/intel/domain_translation_struct
    [ ... ]
    Device 0000:00:14.0 with pasid 0 @0x15f3d9000
    IOVA_PFN                PML5E                   PML4E
    0x000000008ced0 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced1 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced2 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced3 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced4 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced5 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced6 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced7 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced8 |       0x0000000000000000      0x000000015f3da003
    0x000000008ced9 |       0x0000000000000000      0x000000015f3da003
    
    PDPE                    PDE                     PTE
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced0003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced1003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced2003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced3003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced4003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced5003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced6003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced7003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced8003
    0x000000015f3db003      0x000000015f3dc003      0x000000008ced9003
    [ ... ]
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 3a4708a8a414..4a16b39ae353 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -441,6 +441,7 @@ enum {
 #define VTD_FLAG_SVM_CAPABLE		(1 << 2)
 
 extern int intel_iommu_sm;
+extern spinlock_t device_domain_lock;
 
 #define sm_supported(iommu)	(intel_iommu_sm && ecap_smts((iommu)->ecap))
 #define pasid_supported(iommu)	(sm_supported(iommu) &&			\
@@ -663,6 +664,7 @@ int for_each_device_domain(int (*fn)(struct device_domain_info *info,
 				     void *data), void *data);
 void iommu_flush_write_buffer(struct intel_iommu *iommu);
 int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct device *dev);
+struct dmar_domain *find_domain(struct device *dev);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
 extern void intel_svm_check(struct intel_iommu *iommu);

commit 33cd6e642d6a76c1d338ce25cba5fd79a5029011
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Thu Jan 2 08:18:18 2020 +0800

    iommu/vt-d: Flush PASID-based iotlb for iova over first level
    
    When software has changed first-level tables, it should invalidate
    the affected IOTLB and the paging-structure-caches using the PASID-
    based-IOTLB Invalidate Descriptor defined in spec 6.5.2.4.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 454c69712131..3a4708a8a414 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -650,6 +650,8 @@ extern void qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 			  unsigned int size_order, u64 type);
 extern void qi_flush_dev_iotlb(struct intel_iommu *iommu, u16 sid, u16 pfsid,
 			u16 qdep, u64 addr, unsigned mask);
+void qi_flush_piotlb(struct intel_iommu *iommu, u16 did, u32 pasid, u64 addr,
+		     unsigned long npages, bool ih);
 extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);

commit ddf09b6d43ece8e4d5591e4957e89c4fe7714792
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Thu Jan 2 08:18:17 2020 +0800

    iommu/vt-d: Setup pasid entries for iova over first level
    
    Intel VT-d in scalable mode supports two types of page tables for
    IOVA translation: first level and second level. The IOMMU driver
    can choose one from both for IOVA translation according to the use
    case. This sets up the pasid entry if a domain is selected to use
    the first-level page table for iova translation.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index aaece25c055f..454c69712131 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -34,10 +34,13 @@
 #define VTD_STRIDE_SHIFT        (9)
 #define VTD_STRIDE_MASK         (((u64)-1) << VTD_STRIDE_SHIFT)
 
-#define DMA_PTE_READ (1)
-#define DMA_PTE_WRITE (2)
-#define DMA_PTE_LARGE_PAGE (1 << 7)
-#define DMA_PTE_SNP (1 << 11)
+#define DMA_PTE_READ		BIT_ULL(0)
+#define DMA_PTE_WRITE		BIT_ULL(1)
+#define DMA_PTE_LARGE_PAGE	BIT_ULL(7)
+#define DMA_PTE_SNP		BIT_ULL(11)
+
+#define DMA_FL_PTE_PRESENT	BIT_ULL(0)
+#define DMA_FL_PTE_XD		BIT_ULL(63)
 
 #define CONTEXT_TT_MULTI_LEVEL	0
 #define CONTEXT_TT_DEV_IOTLB	1
@@ -610,10 +613,11 @@ static inline void dma_clear_pte(struct dma_pte *pte)
 static inline u64 dma_pte_addr(struct dma_pte *pte)
 {
 #ifdef CONFIG_64BIT
-	return pte->val & VTD_PAGE_MASK;
+	return pte->val & VTD_PAGE_MASK & (~DMA_FL_PTE_XD);
 #else
 	/* Must have a full atomic 64-bit read */
-	return  __cmpxchg64(&pte->val, 0ULL, 0ULL) & VTD_PAGE_MASK;
+	return  __cmpxchg64(&pte->val, 0ULL, 0ULL) &
+			VTD_PAGE_MASK & (~DMA_FL_PTE_XD);
 #endif
 }
 

commit ff3dc6521f78132eaaf62a842c3ece9060dcde26
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Thu Jan 2 08:18:03 2020 +0800

    iommu/vt-d: Fix CPU and IOMMU SVM feature matching checks
    
    Shared Virtual Memory(SVM) is based on a collective set of hardware
    features detected at runtime. There are requirements for matching CPU
    and IOMMU capabilities.
    
    The current code checks CPU and IOMMU feature set for SVM support but
    the result is never stored nor used. Therefore, SVM can still be used
    even when these checks failed. The consequences can be:
    1. CPU uses 5-level paging mode for virtual address of 57 bits, but
    IOMMU can only support 4-level paging mode with 48 bits address for DMA.
    2. 1GB page size is used by CPU but IOMMU does not support it. VT-d
    unrecoverable faults may be generated.
    
    The best solution to fix these problems is to prevent them in the first
    place.
    
    This patch consolidates code for checking PASID, CPU vs. IOMMU paging
    mode compatibility, as well as provides specific error messages for
    each failed checks. On sane hardware configurations, these error message
    shall never appear in kernel log.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 6d8bf4bdf240..aaece25c055f 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -435,6 +435,7 @@ enum {
 
 #define VTD_FLAG_TRANS_PRE_ENABLED	(1 << 0)
 #define VTD_FLAG_IRQ_REMAP_PRE_ENABLED	(1 << 1)
+#define VTD_FLAG_SVM_CAPABLE		(1 << 2)
 
 extern int intel_iommu_sm;
 
@@ -658,7 +659,7 @@ void iommu_flush_write_buffer(struct intel_iommu *iommu);
 int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct device *dev);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
-int intel_svm_init(struct intel_iommu *iommu);
+extern void intel_svm_check(struct intel_iommu *iommu);
 extern int intel_svm_enable_prq(struct intel_iommu *iommu);
 extern int intel_svm_finish_prq(struct intel_iommu *iommu);
 
@@ -686,6 +687,8 @@ struct intel_svm {
 };
 
 extern struct intel_iommu *intel_svm_device_to_iommu(struct device *dev);
+#else
+static inline void intel_svm_check(struct intel_iommu *iommu) {}
 #endif
 
 #ifdef CONFIG_INTEL_IOMMU_DEBUGFS

commit 4e7120d79edb31e4ee68e6f8421448e4603be1e9
Author: Eric Auger <eric.auger@redhat.com>
Date:   Fri Nov 8 16:58:03 2019 +0100

    iommu/vt-d: Fix QI_DEV_IOTLB_PFSID and QI_DEV_EIOTLB_PFSID macros
    
    For both PASID-based-Device-TLB Invalidate Descriptor and
    Device-TLB Invalidate Descriptor, the Physical Function Source-ID
    value is split according to this layout:
    
    PFSID[3:0] is set at offset 12 and PFSID[15:4] is put at offset 52.
    Fix the part laid out at offset 52.
    
    Fixes: 0f725561e1684 ("iommu/vt-d: Add definitions for PFSID")
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Acked-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: stable@vger.kernel.org # v4.19+
    Acked-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index ed11ef594378..6d8bf4bdf240 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -336,7 +336,8 @@ enum {
 #define QI_DEV_IOTLB_SID(sid)	((u64)((sid) & 0xffff) << 32)
 #define QI_DEV_IOTLB_QDEP(qdep)	(((qdep) & 0x1f) << 16)
 #define QI_DEV_IOTLB_ADDR(addr)	((u64)(addr) & VTD_PAGE_MASK)
-#define QI_DEV_IOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | ((u64)(pfsid & 0xfff) << 52))
+#define QI_DEV_IOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | \
+				   ((u64)((pfsid >> 4) & 0xfff) << 52))
 #define QI_DEV_IOTLB_SIZE	1
 #define QI_DEV_IOTLB_MAX_INVS	32
 
@@ -360,7 +361,8 @@ enum {
 #define QI_DEV_EIOTLB_PASID(p)	(((u64)p) << 32)
 #define QI_DEV_EIOTLB_SID(sid)	((u64)((sid) & 0xffff) << 16)
 #define QI_DEV_EIOTLB_QDEP(qd)	((u64)((qd) & 0x1f) << 4)
-#define QI_DEV_EIOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | ((u64)(pfsid & 0xfff) << 52))
+#define QI_DEV_EIOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | \
+				    ((u64)((pfsid >> 4) & 0xfff) << 52))
 #define QI_DEV_EIOTLB_MAX_INVS	32
 
 /* Page group response descriptor QW0 */

commit e95adb9add75affb98570a518c902f50e5fcce1b
Merge: f74c2bb98776 96088a203a0b 7991eb39eedc 097a7df2e3af 4c0088934153 8758553791df 3623002f0f76 3d708895325b 1f76249cc3be 2896ba40d0be
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Sep 11 12:39:19 2019 +0200

    Merge branches 'arm/omap', 'arm/exynos', 'arm/smmu', 'arm/mediatek', 'arm/qcom', 'arm/renesas', 'x86/amd', 'x86/vt-d' and 'core' into next

commit fd730007a06e9b11664e3816fcebd3faa91761ea
Author: Kyung Min Park <kyung.min.park@intel.com>
Date:   Fri Sep 6 11:14:02 2019 -0700

    iommu/vt-d: Add Scalable Mode fault information
    
    Intel VT-d specification revision 3 added support for Scalable Mode
    Translation for DMA remapping. Add the Scalable Mode fault reasons to
    show detailed fault reasons when the translation fault happens.
    
    Link: https://software.intel.com/sites/default/files/managed/c5/15/vt-directed-io-spec.pdf
    
    Reviewed-by: Sohil Mehta <sohil.mehta@intel.com>
    Signed-off-by: Kyung Min Park <kyung.min.park@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index f2ae8a006ff8..10e79a49af9d 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -272,6 +272,8 @@
 #define dma_frcd_type(d) ((d >> 30) & 1)
 #define dma_frcd_fault_reason(c) (c & 0xff)
 #define dma_frcd_source_id(c) (c & 0xffff)
+#define dma_frcd_pasid_value(c) (((c) >> 8) & 0xfffff)
+#define dma_frcd_pasid_present(c) (((c) >> 31) & 1)
 /* low 64 bit */
 #define dma_frcd_page_addr(d) (d & (((u64)-1) << PAGE_SHIFT))
 

commit 8744daf4b0699b724ee0a56b313a6c0c4ea289e3
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Mon Aug 26 08:53:29 2019 -0700

    iommu/vt-d: Remove global page flush support
    
    Global pages support is removed from VT-d spec 3.0. Since global pages G
    flag only affects first-level paging structures and because DMA request
    with PASID are only supported by VT-d spec. 3.0 and onward, we can
    safely remove global pages support.
    
    For kernel shared virtual address IOTLB invalidation, PASID
    granularity and page selective within PASID will be used. There is
    no global granularity supported. Without this fix, IOTLB invalidation
    will cause invalid descriptor error in the queued invalidation (QI)
    interface.
    
    Fixes: 1c4f88b7f1f9 ("iommu/vt-d: Shared virtual address in scalable mode")
    Reported-by: Sanjay K Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index f2ae8a006ff8..4fc6454f7ebb 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -346,7 +346,6 @@ enum {
 #define QI_PC_PASID_SEL		(QI_PC_TYPE | QI_PC_GRAN(1))
 
 #define QI_EIOTLB_ADDR(addr)	((u64)(addr) & VTD_PAGE_MASK)
-#define QI_EIOTLB_GL(gl)	(((u64)gl) << 7)
 #define QI_EIOTLB_IH(ih)	(((u64)ih) << 6)
 #define QI_EIOTLB_AM(am)	(((u64)am))
 #define QI_EIOTLB_PASID(pasid) 	(((u64)pasid) << 32)
@@ -378,8 +377,6 @@ enum {
 #define QI_RESP_INVALID		0x1
 #define QI_RESP_FAILURE		0xf
 
-#define QI_GRAN_ALL_ALL			0
-#define QI_GRAN_NONG_ALL		1
 #define QI_GRAN_NONG_PASID		2
 #define QI_GRAN_PSI_PASID		3
 

commit d95c3885865b71e56d8d60c8617f2ce1f0fa079d
Merge: 0bcfa628f8a3 5cd3f2e98cca 8dd8f005bdd4 9378bfeaafcb ceedd5f74d8c 29fcea8ce7f3
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Jul 4 17:26:48 2019 +0200

    Merge branches 'x86/vt-d', 'x86/amd', 'arm/smmu', 'arm/omap', 'generic-dma-ops' and 'core' into next

commit 3b20eb23724d493eca79f02b1e062bd5432e29d0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 29 16:57:35 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 320
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms and conditions of the gnu general public license
      version 2 as published by the free software foundation this program
      is distributed in the hope it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not write to the free
      software foundation inc 59 temple place suite 330 boston ma 02111
      1307 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 33 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190530000435.254582722@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 6925a18a5ca3..6a8dd4af0147 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -1,22 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Copyright © 2006-2015, Intel Corporation.
  *
  * Authors: Ashok Raj <ashok.raj@intel.com>
  *          Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
  *          David Woodhouse <David.Woodhouse@intel.com>
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms and conditions of the GNU General Public License,
- * version 2, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
- * more details.
- *
- * You should have received a copy of the GNU General Public License along with
- * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
- * Place - Suite 330, Boston, MA 02111-1307 USA.
  */
 
 #ifndef _INTEL_IOMMU_H_

commit 4ec066c7b1476e0ca66a7acdb575627a5d1a1ee6
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat May 25 13:41:33 2019 +0800

    iommu/vt-d: Cleanup get_valid_domain_for_dev()
    
    Previously, get_valid_domain_for_dev() is used to retrieve the
    DMA domain which has been attached to the device or allocate one
    if no domain has been attached yet. As we have delegated the DMA
    domain management to upper layer, this function is used purely to
    allocate a private DMA domain if the default domain doesn't work
    for ths device. Cleanup the code for readability.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 4140726867a9..5b961c8ca64c 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -660,7 +660,6 @@ extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);
 
-struct dmar_domain *get_valid_domain_for_dev(struct device *dev);
 void *alloc_pgtable_page(int node);
 void free_pgtable_page(void *vaddr);
 struct intel_iommu *domain_get_iommu(struct dmar_domain *domain);

commit cdd3a2499d30695730b22dc025c00b9b28884c6b
Author: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
Date:   Fri May 24 16:40:16 2019 -0700

    iommu/vt-d: Introduce macros useful for dumping DMAR table
    
    A scalable mode DMAR table walk would involve looking at bits in each stage
    of walk, like,
    1. Is PASID enabled in the context entry?
    2. What's the size of PASID directory?
    3. Is the PASID directory entry present?
    4. Is the PASID table entry present?
    5. Number of PASID table entries?
    
    Hence, add these macros that will later be used during this walk.
    Apart from adding new macros, move existing macros (like
    pasid_pde_is_present(), get_pasid_table_from_pde() and pasid_supported())
    to appropriate header files so that they could be reused.
    
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Lu Baolu <baolu.lu@linux.intel.com>
    Cc: Sohil Mehta <sohil.mehta@intel.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Reviewed-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 6925a18a5ca3..4140726867a9 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -447,6 +447,12 @@ enum {
 #define VTD_FLAG_TRANS_PRE_ENABLED	(1 << 0)
 #define VTD_FLAG_IRQ_REMAP_PRE_ENABLED	(1 << 1)
 
+extern int intel_iommu_sm;
+
+#define sm_supported(iommu)	(intel_iommu_sm && ecap_smts((iommu)->ecap))
+#define pasid_supported(iommu)	(sm_supported(iommu) &&			\
+				 ecap_pasid((iommu)->ecap))
+
 struct pasid_entry;
 struct pasid_state_entry;
 struct page_req_dsc;

commit 67b8e02b5e76159a4f94f85bee370af1d9f442f9
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Mar 25 09:30:32 2019 +0800

    iommu/vt-d: Aux-domain specific domain attach/detach
    
    When multiple domains per device has been enabled by the
    device driver, the device will tag the default PASID for
    the domain to all DMA traffics out of the subset of this
    device; and the IOMMU should translate the DMA requests
    in PASID granularity.
    
    This adds the intel_iommu_aux_attach/detach_device() ops
    to support managing PASID granular translation structures
    when the device driver has enabled multiple domains per
    device.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 4f0745479b6d..6925a18a5ca3 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -489,9 +489,11 @@ struct dmar_domain {
 					/* Domain ids per IOMMU. Use u16 since
 					 * domain ids are 16 bit wide according
 					 * to VT-d spec, section 9.3 */
+	unsigned int	auxd_refcnt;	/* Refcount of auxiliary attaching */
 
 	bool has_iotlb_device;
 	struct list_head devices;	/* all devices' list */
+	struct list_head auxd;		/* link to device's auxiliary list */
 	struct iova_domain iovad;	/* iova's that belong to this domain */
 
 	struct dma_pte	*pgd;		/* virtual address */
@@ -510,6 +512,11 @@ struct dmar_domain {
 					   2 == 1GiB, 3 == 512GiB, 4 == 1TiB */
 	u64		max_addr;	/* maximum mapped address */
 
+	int		default_pasid;	/*
+					 * The default pasid used for non-SVM
+					 * traffic on mediated devices.
+					 */
+
 	struct iommu_domain domain;	/* generic domain data structure for
 					   iommu core */
 };
@@ -559,6 +566,9 @@ struct device_domain_info {
 	struct list_head link;	/* link to domain siblings */
 	struct list_head global; /* link to global list */
 	struct list_head table;	/* link to pasid table */
+	struct list_head auxiliary_domains; /* auxiliary domains
+					     * attached to this device
+					     */
 	u8 bus;			/* PCI bus number */
 	u8 devfn;		/* PCI devfn number */
 	u16 pfsid;		/* SRIOV physical function source ID */

commit 95587a75de179da35aea03735843be8278cf1857
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Mar 25 09:30:30 2019 +0800

    iommu/vt-d: Add per-device IOMMU feature ops entries
    
    This adds the iommu ops entries for aux-domain per-device
    feature query and enable/disable.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index b7d1e2fbb9ca..4f0745479b6d 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -568,6 +568,7 @@ struct device_domain_info {
 	u8 pri_enabled:1;
 	u8 ats_supported:1;
 	u8 ats_enabled:1;
+	u8 auxd_enabled:1;	/* Multiple domains per device */
 	u8 ats_qdep;
 	struct device *dev; /* it's NULL for PCIe-to-PCI bridge */
 	struct intel_iommu *iommu; /* IOMMU used by this device */

commit d7cbc0f3220fabbdfa9b3aa79275baa5b16fef5d
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Mar 25 09:30:29 2019 +0800

    iommu/vt-d: Make intel_iommu_enable_pasid() more generic
    
    This moves intel_iommu_enable_pasid() out of the scope of
    CONFIG_INTEL_IOMMU_SVM with more and more features requiring
    pasid function.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index fa364de9db18..b7d1e2fbb9ca 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -650,6 +650,7 @@ struct intel_iommu *domain_get_iommu(struct dmar_domain *domain);
 int for_each_device_domain(int (*fn)(struct device_domain_info *info,
 				     void *data), void *data);
 void iommu_flush_write_buffer(struct intel_iommu *iommu);
+int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct device *dev);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
 int intel_svm_init(struct intel_iommu *iommu);
@@ -679,7 +680,6 @@ struct intel_svm {
 	struct list_head list;
 };
 
-extern int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct intel_svm_dev *sdev);
 extern struct intel_iommu *intel_svm_device_to_iommu(struct device *dev);
 #endif
 

commit 5b438f4ba315db4f8c1489d175656798d58c014f
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Fri Jan 11 13:04:57 2019 +0800

    iommu/vt-d: Support page request in scalable mode
    
    VT-d Rev3.0 has made a few changes to the page request interface,
    
    1. widened PRQ descriptor from 128 bits to 256 bits;
    2. removed streaming response type;
    3. introduced private data that requires page response even the
       request is not last request in group (LPIG).
    
    This is a supplement to commit 1c4f88b7f1f92 ("iommu/vt-d: Shared
    virtual address in scalable mode") and makes the svm code compliant
    with VT-d Rev3.0.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Fixes: 1c4f88b7f1f92 ("iommu/vt-d: Shared virtual address in scalable mode")
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 0605f3bf6e79..fa364de9db18 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -374,20 +374,17 @@ enum {
 #define QI_DEV_EIOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | ((u64)(pfsid & 0xfff) << 52))
 #define QI_DEV_EIOTLB_MAX_INVS	32
 
-#define QI_PGRP_IDX(idx)	(((u64)(idx)) << 55)
-#define QI_PGRP_PRIV(priv)	(((u64)(priv)) << 32)
-#define QI_PGRP_RESP_CODE(res)	((u64)(res))
-#define QI_PGRP_PASID(pasid)	(((u64)(pasid)) << 32)
-#define QI_PGRP_DID(did)	(((u64)(did)) << 16)
+/* Page group response descriptor QW0 */
 #define QI_PGRP_PASID_P(p)	(((u64)(p)) << 4)
+#define QI_PGRP_PDP(p)		(((u64)(p)) << 5)
+#define QI_PGRP_RESP_CODE(res)	(((u64)(res)) << 12)
+#define QI_PGRP_DID(rid)	(((u64)(rid)) << 16)
+#define QI_PGRP_PASID(pasid)	(((u64)(pasid)) << 32)
+
+/* Page group response descriptor QW1 */
+#define QI_PGRP_LPIG(x)		(((u64)(x)) << 2)
+#define QI_PGRP_IDX(idx)	(((u64)(idx)) << 3)
 
-#define QI_PSTRM_ADDR(addr)	(((u64)(addr)) & VTD_PAGE_MASK)
-#define QI_PSTRM_DEVFN(devfn)	(((u64)(devfn)) << 4)
-#define QI_PSTRM_RESP_CODE(res)	((u64)(res))
-#define QI_PSTRM_IDX(idx)	(((u64)(idx)) << 55)
-#define QI_PSTRM_PRIV(priv)	(((u64)(priv)) << 32)
-#define QI_PSTRM_BUS(bus)	(((u64)(bus)) << 24)
-#define QI_PSTRM_PASID(pasid)	(((u64)(pasid)) << 4)
 
 #define QI_RESP_SUCCESS		0x0
 #define QI_RESP_INVALID		0x1

commit 6d68b88e0993d67e9ebb1240f84240b712fbc8a4
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:59:06 2018 +0800

    iommu/vt-d: Remove deferred invalidation
    
    Deferred invalidation is an ECS specific feature. It will not be
    supported when IOMMU works in scalable mode. As we deprecated the
    ECS support, remove deferred invalidation and cleanup the code.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Cc: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index cfcf9c1e1872..0605f3bf6e79 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -541,15 +541,8 @@ struct intel_iommu {
 	struct iommu_flush flush;
 #endif
 #ifdef CONFIG_INTEL_IOMMU_SVM
-	/* These are large and need to be contiguous, so we allocate just
-	 * one for now. We'll maybe want to rethink that if we truly give
-	 * devices away to userspace processes (e.g. for DPDK) and don't
-	 * want to trust that userspace will use *only* the PASID it was
-	 * told to. But while it's all driver-arbitrated, we're fine. */
-	struct pasid_state_entry *pasid_state_table;
 	struct page_req_dsc *prq;
 	unsigned char prq_name[16];    /* Name for PRQ interrupt */
-	u32 pasid_max;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
 	u32 *iommu_state; /* Store iommu states between suspend and resume.*/
@@ -663,7 +656,6 @@ void iommu_flush_write_buffer(struct intel_iommu *iommu);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
 int intel_svm_init(struct intel_iommu *iommu);
-int intel_svm_exit(struct intel_iommu *iommu);
 extern int intel_svm_enable_prq(struct intel_iommu *iommu);
 extern int intel_svm_finish_prq(struct intel_iommu *iommu);
 

commit 1c4f88b7f1f9298b56c7dac18c0bcd8d2f75059a
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:59:05 2018 +0800

    iommu/vt-d: Shared virtual address in scalable mode
    
    This patch enables the current SVA (Shared Virtual Address)
    implementation to work in the scalable mode.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 4ad62396e81e..cfcf9c1e1872 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -54,14 +54,7 @@
 #define CONTEXT_TT_MULTI_LEVEL	0
 #define CONTEXT_TT_DEV_IOTLB	1
 #define CONTEXT_TT_PASS_THROUGH 2
-/* Extended context entry types */
-#define CONTEXT_TT_PT_PASID	4
-#define CONTEXT_TT_PT_PASID_DEV_IOTLB 5
-#define CONTEXT_TT_MASK (7ULL << 2)
-
-#define CONTEXT_DINVE		(1ULL << 8)
-#define CONTEXT_PRS		(1ULL << 9)
-#define CONTEXT_PASIDE		(1ULL << 11)
+#define CONTEXT_PASIDE		BIT_ULL(3)
 
 /*
  * Intel IOMMU register specification per version 1.0 public spec.

commit 437f35e1cd4c8d043633bb72f4260369af68fbf7
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:59:04 2018 +0800

    iommu/vt-d: Add first level page table interface
    
    This adds an interface to setup the PASID entries for first
    level page table translation.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 5fdd33ed2cce..4ad62396e81e 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -178,6 +178,7 @@
  */
 
 #define ecap_smpwc(e)		(((e) >> 48) & 0x1)
+#define ecap_flts(e)		(((e) >> 47) & 0x1)
 #define ecap_slts(e)		(((e) >> 46) & 0x1)
 #define ecap_smts(e)		(((e) >> 43) & 0x1)
 #define ecap_dit(e)		((e >> 41) & 0x1)

commit 7373a8cc381978cfafa4b0285cdd935682f1b2d2
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:59:03 2018 +0800

    iommu/vt-d: Setup context and enable RID2PASID support
    
    This patch enables the translation for requests without PASID in
    the scalable mode by setting up the root and context entries.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index cb3ebda47fa7..5fdd33ed2cce 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -258,6 +258,7 @@
 
 /* DMA_RTADDR_REG */
 #define DMA_RTADDR_RTT (((u64)1) << 11)
+#define DMA_RTADDR_SMT (((u64)1) << 10)
 
 /* CCMD_REG */
 #define DMA_CCMD_ICC (((u64)1) << 63)

commit 6f7db75e1c469057fe7588ed959328ead771ccc7
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:59:00 2018 +0800

    iommu/vt-d: Add second level page table interface
    
    This adds the interfaces to setup or tear down the structures
    for second level page table translations. This includes types
    of second level only translation and pass through.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 08ff588a4df7..cb3ebda47fa7 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -177,6 +177,8 @@
  * Extended Capability Register
  */
 
+#define ecap_smpwc(e)		(((e) >> 48) & 0x1)
+#define ecap_slts(e)		(((e) >> 46) & 0x1)
 #define ecap_smts(e)		(((e) >> 43) & 0x1)
 #define ecap_dit(e)		((e >> 41) & 0x1)
 #define ecap_pasid(e)		((e >> 40) & 0x1)
@@ -662,6 +664,7 @@ void free_pgtable_page(void *vaddr);
 struct intel_iommu *domain_get_iommu(struct dmar_domain *domain);
 int for_each_device_domain(int (*fn)(struct device_domain_info *info,
 				     void *data), void *data);
+void iommu_flush_write_buffer(struct intel_iommu *iommu);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
 int intel_svm_init(struct intel_iommu *iommu);

commit 5d308fc1ecf5351418a4f003ccb74dc91b424bd1
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:58:58 2018 +0800

    iommu/vt-d: Add 256-bit invalidation descriptor support
    
    Intel vt-d spec rev3.0 requires software to use 256-bit
    descriptors in invalidation queue. As the spec reads in
    section 6.5.2:
    
    Remapping hardware supporting Scalable Mode Translations
    (ECAP_REG.SMTS=1) allow software to additionally program
    the width of the descriptors (128-bits or 256-bits) that
    will be written into the Queue. Software should setup the
    Invalidation Queue for 256-bit descriptors before progra-
    mming remapping hardware for scalable-mode translation as
    128-bit descriptors are treated as invalid descriptors
    (see Table 21 in Section 6.5.2.10) in scalable-mode.
    
    This patch adds 256-bit invalidation descriptor support
    if the hardware presents scalable mode capability.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index b4da61385ebf..08ff588a4df7 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -401,13 +401,18 @@ enum {
 #define QI_GRAN_NONG_PASID		2
 #define QI_GRAN_PSI_PASID		3
 
+#define qi_shift(iommu)		(DMAR_IQ_SHIFT + !!ecap_smts((iommu)->ecap))
+
 struct qi_desc {
-	u64 low, high;
+	u64 qw0;
+	u64 qw1;
+	u64 qw2;
+	u64 qw3;
 };
 
 struct q_inval {
 	raw_spinlock_t  q_lock;
-	struct qi_desc  *desc;          /* invalidation queue */
+	void		*desc;          /* invalidation queue */
 	int             *desc_status;   /* desc status */
 	int             free_head;      /* first free entry */
 	int             free_tail;      /* last free entry */

commit 4f2ed183cfebf42b29ed8fe442169de97bc0fe61
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:58:57 2018 +0800

    iommu/vt-d: Move page table helpers into header
    
    So that they could also be used in other source files.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Cc: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 8c9b6063d275..b4da61385ebf 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -590,6 +590,49 @@ static inline void __iommu_flush_cache(
 		clflush_cache_range(addr, size);
 }
 
+/*
+ * 0: readable
+ * 1: writable
+ * 2-6: reserved
+ * 7: super page
+ * 8-10: available
+ * 11: snoop behavior
+ * 12-63: Host physcial address
+ */
+struct dma_pte {
+	u64 val;
+};
+
+static inline void dma_clear_pte(struct dma_pte *pte)
+{
+	pte->val = 0;
+}
+
+static inline u64 dma_pte_addr(struct dma_pte *pte)
+{
+#ifdef CONFIG_64BIT
+	return pte->val & VTD_PAGE_MASK;
+#else
+	/* Must have a full atomic 64-bit read */
+	return  __cmpxchg64(&pte->val, 0ULL, 0ULL) & VTD_PAGE_MASK;
+#endif
+}
+
+static inline bool dma_pte_present(struct dma_pte *pte)
+{
+	return (pte->val & 3) != 0;
+}
+
+static inline bool dma_pte_superpage(struct dma_pte *pte)
+{
+	return (pte->val & DMA_PTE_LARGE_PAGE);
+}
+
+static inline int first_pte_in_page(struct dma_pte *pte)
+{
+	return !((unsigned long)pte & ~VTD_PAGE_MASK);
+}
+
 extern struct dmar_drhd_unit * dmar_find_matched_drhd_unit(struct pci_dev *dev);
 extern int dmar_find_matched_atsr_unit(struct pci_dev *dev);
 

commit 765b6a98c1de3d84dfdae344cc4ee4c24d9447f7
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Dec 10 09:58:55 2018 +0800

    iommu/vt-d: Enumerate the scalable mode capability
    
    The Intel vt-d spec rev3.0 introduces a new translation
    mode called scalable mode, which enables PASID-granular
    translations for first level, second level, nested and
    pass-through modes. At the same time, the previous
    Extended Context (ECS) mode is deprecated (no production
    ever implements ECS).
    
    This patch adds enumeration for Scalable Mode and removes
    the deprecated ECS enumeration. It provides a boot time
    option to disable scalable mode even hardware claims to
    support it.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a58bc05d6798..8c9b6063d275 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -177,6 +177,7 @@
  * Extended Capability Register
  */
 
+#define ecap_smts(e)		(((e) >> 43) & 0x1)
 #define ecap_dit(e)		((e >> 41) & 0x1)
 #define ecap_pasid(e)		((e >> 40) & 0x1)
 #define ecap_pss(e)		((e >> 35) & 0x1f)

commit daedaa33d9c578220b311fbad3748d3ecd5a8f66
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Nov 12 14:40:08 2018 +0800

    iommu/vtd: Cleanup dma_remapping.h header
    
    Commit e61d98d8dad00 ("x64, x2apic/intr-remap: Intel vt-d, IOMMU
    code reorganization") moved dma_remapping.h from drivers/pci/ to
    current place. It is entirely VT-d specific, but uses a generic
    name. This merges dma_remapping.h with include/linux/intel-iommu.h
    and removes dma_remapping.h as the result.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Sohil Mehta <sohil.mehta@intel.com>
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Liu, Yi L <yi.l.liu@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index b0ae25837361..a58bc05d6798 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -26,7 +26,6 @@
 #include <linux/iova.h>
 #include <linux/io.h>
 #include <linux/idr.h>
-#include <linux/dma_remapping.h>
 #include <linux/mmu_notifier.h>
 #include <linux/list.h>
 #include <linux/iommu.h>
@@ -37,9 +36,36 @@
 #include <asm/iommu.h>
 
 /*
- * Intel IOMMU register specification per version 1.0 public spec.
+ * VT-d hardware uses 4KiB page size regardless of host page size.
  */
+#define VTD_PAGE_SHIFT		(12)
+#define VTD_PAGE_SIZE		(1UL << VTD_PAGE_SHIFT)
+#define VTD_PAGE_MASK		(((u64)-1) << VTD_PAGE_SHIFT)
+#define VTD_PAGE_ALIGN(addr)	(((addr) + VTD_PAGE_SIZE - 1) & VTD_PAGE_MASK)
+
+#define VTD_STRIDE_SHIFT        (9)
+#define VTD_STRIDE_MASK         (((u64)-1) << VTD_STRIDE_SHIFT)
+
+#define DMA_PTE_READ (1)
+#define DMA_PTE_WRITE (2)
+#define DMA_PTE_LARGE_PAGE (1 << 7)
+#define DMA_PTE_SNP (1 << 11)
+
+#define CONTEXT_TT_MULTI_LEVEL	0
+#define CONTEXT_TT_DEV_IOTLB	1
+#define CONTEXT_TT_PASS_THROUGH 2
+/* Extended context entry types */
+#define CONTEXT_TT_PT_PASID	4
+#define CONTEXT_TT_PT_PASID_DEV_IOTLB 5
+#define CONTEXT_TT_MASK (7ULL << 2)
+
+#define CONTEXT_DINVE		(1ULL << 8)
+#define CONTEXT_PRS		(1ULL << 9)
+#define CONTEXT_PASIDE		(1ULL << 11)
 
+/*
+ * Intel IOMMU register specification per version 1.0 public spec.
+ */
 #define	DMAR_VER_REG	0x0	/* Arch version supported by this IOMMU */
 #define	DMAR_CAP_REG	0x8	/* Hardware supported capabilities */
 #define	DMAR_ECAP_REG	0x10	/* Extended capabilities supported */
@@ -632,4 +658,23 @@ bool context_present(struct context_entry *context);
 struct context_entry *iommu_context_addr(struct intel_iommu *iommu, u8 bus,
 					 u8 devfn, int alloc);
 
+#ifdef CONFIG_INTEL_IOMMU
+extern int iommu_calculate_agaw(struct intel_iommu *iommu);
+extern int iommu_calculate_max_sagaw(struct intel_iommu *iommu);
+extern int dmar_disabled;
+extern int intel_iommu_enabled;
+extern int intel_iommu_tboot_noforce;
+#else
+static inline int iommu_calculate_agaw(struct intel_iommu *iommu)
+{
+	return 0;
+}
+static inline int iommu_calculate_max_sagaw(struct intel_iommu *iommu)
+{
+	return 0;
+}
+#define dmar_disabled	(1)
+#define intel_iommu_enabled (0)
+#endif
+
 #endif

commit ee2636b8670b1ab2a02a65923a9bef59e9199c37
Author: Sohil Mehta <sohil.mehta@intel.com>
Date:   Tue Sep 11 17:11:38 2018 -0700

    iommu/vt-d: Enable base Intel IOMMU debugfs support
    
    Add a new config option CONFIG_INTEL_IOMMU_DEBUGFS and do the base
    enabling for Intel IOMMU debugfs.
    
    Cc: Lu Baolu <baolu.lu@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Co-Developed-by: Gayatri Kammela <gayatri.kammela@intel.com>
    Signed-off-by: Gayatri Kammela <gayatri.kammela@intel.com>
    Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Reviewed-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Sohil Mehta <sohil.mehta@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 3bdb9aa198af..b0ae25837361 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -621,6 +621,12 @@ extern int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct intel_svm_
 extern struct intel_iommu *intel_svm_device_to_iommu(struct device *dev);
 #endif
 
+#ifdef CONFIG_INTEL_IOMMU_DEBUGFS
+void intel_iommu_debugfs_init(void);
+#else
+static inline void intel_iommu_debugfs_init(void) {}
+#endif /* CONFIG_INTEL_IOMMU_DEBUGFS */
+
 extern const struct attribute_group *intel_iommu_groups[];
 bool context_present(struct context_entry *context);
 struct context_entry *iommu_context_addr(struct intel_iommu *iommu, u8 bus,

commit 4a2d80dbadb72b998641af32d8dd4b7b39e72aa0
Author: Sohil Mehta <sohil.mehta@intel.com>
Date:   Tue Sep 11 17:11:37 2018 -0700

    iommu/vt-d: Update register definitions to VT-d 3.0 specification
    
    Add new register definitions added in the VT-d 3.0 specification. Also
    include registers that were missing previously.
    
    Cc: Lu Baolu <baolu.lu@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Gayatri Kammela <gayatri.kammela@intel.com>
    Signed-off-by: Sohil Mehta <sohil.mehta@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index b7cf32e8ae1f..3bdb9aa198af 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -72,6 +72,42 @@
 #define	DMAR_PEDATA_REG	0xe4	/* Page request event interrupt data register */
 #define	DMAR_PEADDR_REG	0xe8	/* Page request event interrupt addr register */
 #define	DMAR_PEUADDR_REG 0xec	/* Page request event Upper address register */
+#define DMAR_MTRRCAP_REG 0x100	/* MTRR capability register */
+#define DMAR_MTRRDEF_REG 0x108	/* MTRR default type register */
+#define DMAR_MTRR_FIX64K_00000_REG 0x120 /* MTRR Fixed range registers */
+#define DMAR_MTRR_FIX16K_80000_REG 0x128
+#define DMAR_MTRR_FIX16K_A0000_REG 0x130
+#define DMAR_MTRR_FIX4K_C0000_REG 0x138
+#define DMAR_MTRR_FIX4K_C8000_REG 0x140
+#define DMAR_MTRR_FIX4K_D0000_REG 0x148
+#define DMAR_MTRR_FIX4K_D8000_REG 0x150
+#define DMAR_MTRR_FIX4K_E0000_REG 0x158
+#define DMAR_MTRR_FIX4K_E8000_REG 0x160
+#define DMAR_MTRR_FIX4K_F0000_REG 0x168
+#define DMAR_MTRR_FIX4K_F8000_REG 0x170
+#define DMAR_MTRR_PHYSBASE0_REG 0x180 /* MTRR Variable range registers */
+#define DMAR_MTRR_PHYSMASK0_REG 0x188
+#define DMAR_MTRR_PHYSBASE1_REG 0x190
+#define DMAR_MTRR_PHYSMASK1_REG 0x198
+#define DMAR_MTRR_PHYSBASE2_REG 0x1a0
+#define DMAR_MTRR_PHYSMASK2_REG 0x1a8
+#define DMAR_MTRR_PHYSBASE3_REG 0x1b0
+#define DMAR_MTRR_PHYSMASK3_REG 0x1b8
+#define DMAR_MTRR_PHYSBASE4_REG 0x1c0
+#define DMAR_MTRR_PHYSMASK4_REG 0x1c8
+#define DMAR_MTRR_PHYSBASE5_REG 0x1d0
+#define DMAR_MTRR_PHYSMASK5_REG 0x1d8
+#define DMAR_MTRR_PHYSBASE6_REG 0x1e0
+#define DMAR_MTRR_PHYSMASK6_REG 0x1e8
+#define DMAR_MTRR_PHYSBASE7_REG 0x1f0
+#define DMAR_MTRR_PHYSMASK7_REG 0x1f8
+#define DMAR_MTRR_PHYSBASE8_REG 0x200
+#define DMAR_MTRR_PHYSMASK8_REG 0x208
+#define DMAR_MTRR_PHYSBASE9_REG 0x210
+#define DMAR_MTRR_PHYSMASK9_REG 0x218
+#define DMAR_VCCAP_REG		0xe00 /* Virtual command capability register */
+#define DMAR_VCMD_REG		0xe10 /* Virtual command register */
+#define DMAR_VCRSP_REG		0xe20 /* Virtual command response register */
 
 #define OFFSET_STRIDE		(9)
 

commit 26b86092c4650311256fa2372ced7e1e17d97d7b
Author: Sohil Mehta <sohil.mehta@intel.com>
Date:   Tue Sep 11 17:11:36 2018 -0700

    iommu/vt-d: Relocate struct/function declarations to its header files
    
    To reuse the static functions and the struct declarations, move them to
    corresponding header files and export the needed functions.
    
    Cc: Lu Baolu <baolu.lu@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Ashok Raj <ashok.raj@intel.com>
    Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Gayatri Kammela <gayatri.kammela@intel.com>
    Signed-off-by: Sohil Mehta <sohil.mehta@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 28004d74ae04..b7cf32e8ae1f 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -389,6 +389,33 @@ struct pasid_entry;
 struct pasid_state_entry;
 struct page_req_dsc;
 
+/*
+ * 0: Present
+ * 1-11: Reserved
+ * 12-63: Context Ptr (12 - (haw-1))
+ * 64-127: Reserved
+ */
+struct root_entry {
+	u64     lo;
+	u64     hi;
+};
+
+/*
+ * low 64 bits:
+ * 0: present
+ * 1: fault processing disable
+ * 2-3: translation type
+ * 12-63: address space root
+ * high 64 bits:
+ * 0-2: address width
+ * 3-6: aval
+ * 8-23: domain id
+ */
+struct context_entry {
+	u64 lo;
+	u64 hi;
+};
+
 struct dmar_domain {
 	int	nid;			/* node id */
 
@@ -559,5 +586,8 @@ extern struct intel_iommu *intel_svm_device_to_iommu(struct device *dev);
 #endif
 
 extern const struct attribute_group *intel_iommu_groups[];
+bool context_present(struct context_entry *context);
+struct context_entry *iommu_context_addr(struct intel_iommu *iommu, u8 bus,
+					 u8 devfn, int alloc);
 
 #endif

commit 6488a7f35eeab463f6c9c2ea34d30ca856f0bc8e
Merge: 7efe25a70c37 5c5c87411488 379521462e4a d81dc82e0f19 04c532a1cdc7 f1a066fcc972 d9737953d851 d88e61faad52
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Aug 8 12:02:27 2018 +0200

    Merge branches 'arm/shmobile', 'arm/renesas', 'arm/msm', 'arm/smmu', 'arm/omap', 'x86/amd', 'x86/vt-d' and 'core' into next

commit d9737953d85131436b09668b5e8d3389c37c1f28
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat Jul 14 15:47:02 2018 +0800

    iommu/vt-d: Remove the obsolete per iommu pasid tables
    
    The obsolete per iommu pasid tables are no longer used. Hence,
    clean up them.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index e7901d402337..3c43882d3b77 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -453,7 +453,6 @@ struct intel_iommu {
 	 * devices away to userspace processes (e.g. for DPDK) and don't
 	 * want to trust that userspace will use *only* the PASID it was
 	 * told to. But while it's all driver-arbitrated, we're fine. */
-	struct pasid_entry *pasid_table;
 	struct pasid_state_entry *pasid_state_table;
 	struct page_req_dsc *prq;
 	unsigned char prq_name[16];    /* Name for PRQ interrupt */
@@ -526,8 +525,8 @@ int for_each_device_domain(int (*fn)(struct device_domain_info *info,
 				     void *data), void *data);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
-extern int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu);
-extern int intel_svm_free_pasid_tables(struct intel_iommu *iommu);
+int intel_svm_init(struct intel_iommu *iommu);
+int intel_svm_exit(struct intel_iommu *iommu);
 extern int intel_svm_enable_prq(struct intel_iommu *iommu);
 extern int intel_svm_finish_prq(struct intel_iommu *iommu);
 

commit cc580e41260dbf1a46269235f1f2b572137d9d03
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat Jul 14 15:46:59 2018 +0800

    iommu/vt-d: Per PCI device pasid table interfaces
    
    This patch adds the interfaces for per PCI device pasid
    table management. Currently we allocate one pasid table
    for all PCI devices under the scope of an IOMMU. It's
    insecure in some cases where multiple devices under one
    single IOMMU unit support PASID features. With per PCI
    device pasid table, we can achieve finer protection and
    isolation granularity.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Suggested-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 4fd4c6fee93e..e7901d402337 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -476,6 +476,7 @@ struct intel_iommu {
 struct device_domain_info {
 	struct list_head link;	/* link to domain siblings */
 	struct list_head global; /* link to global list */
+	struct list_head table;	/* link to pasid table */
 	u8 bus;			/* PCI bus number */
 	u8 devfn;		/* PCI devfn number */
 	u16 pfsid;		/* SRIOV physical function source ID */
@@ -489,6 +490,7 @@ struct device_domain_info {
 	struct device *dev; /* it's NULL for PCIe-to-PCI bridge */
 	struct intel_iommu *iommu; /* IOMMU used by this device */
 	struct dmar_domain *domain; /* pointer to domain */
+	struct pasid_table *pasid_table; /* pasid table */
 };
 
 static inline void __iommu_flush_cache(

commit 85319dcc8955f8f31828dc8bafff29f6aa011d93
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat Jul 14 15:46:58 2018 +0800

    iommu/vt-d: Add for_each_device_domain() helper
    
    This adds a helper named for_each_device_domain() to iterate
    over the elements in device_domain_list and invoke a callback
    against each element. This allows to search the device_domain
    list in other source files.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 2e1fbde020ca..4fd4c6fee93e 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -520,6 +520,8 @@ struct dmar_domain *get_valid_domain_for_dev(struct device *dev);
 void *alloc_pgtable_page(int node);
 void free_pgtable_page(void *vaddr);
 struct intel_iommu *domain_get_iommu(struct dmar_domain *domain);
+int for_each_device_domain(int (*fn)(struct device_domain_info *info,
+				     void *data), void *data);
 
 #ifdef CONFIG_INTEL_IOMMU_SVM
 extern int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu);

commit 9ddbfb42138d84bb326023616c40a3dc30ea2837
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat Jul 14 15:46:57 2018 +0800

    iommu/vt-d: Move device_domain_info to header
    
    This allows the per device iommu data and some helpers to be
    used in other files.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 2ff15195f73d..2e1fbde020ca 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -31,6 +31,7 @@
 #include <linux/list.h>
 #include <linux/iommu.h>
 #include <linux/io-64-nonatomic-lo-hi.h>
+#include <linux/dmar.h>
 
 #include <asm/cacheflush.h>
 #include <asm/iommu.h>
@@ -387,6 +388,42 @@ struct pasid_entry;
 struct pasid_state_entry;
 struct page_req_dsc;
 
+struct dmar_domain {
+	int	nid;			/* node id */
+
+	unsigned	iommu_refcnt[DMAR_UNITS_SUPPORTED];
+					/* Refcount of devices per iommu */
+
+
+	u16		iommu_did[DMAR_UNITS_SUPPORTED];
+					/* Domain ids per IOMMU. Use u16 since
+					 * domain ids are 16 bit wide according
+					 * to VT-d spec, section 9.3 */
+
+	bool has_iotlb_device;
+	struct list_head devices;	/* all devices' list */
+	struct iova_domain iovad;	/* iova's that belong to this domain */
+
+	struct dma_pte	*pgd;		/* virtual address */
+	int		gaw;		/* max guest address width */
+
+	/* adjusted guest address width, 0 is level 2 30-bit */
+	int		agaw;
+
+	int		flags;		/* flags to find out type of domain */
+
+	int		iommu_coherency;/* indicate coherency of iommu access */
+	int		iommu_snooping; /* indicate snooping control feature*/
+	int		iommu_count;	/* reference count of iommu */
+	int		iommu_superpage;/* Level of superpages supported:
+					   0 == 4KiB (no superpages), 1 == 2MiB,
+					   2 == 1GiB, 3 == 512GiB, 4 == 1TiB */
+	u64		max_addr;	/* maximum mapped address */
+
+	struct iommu_domain domain;	/* generic domain data structure for
+					   iommu core */
+};
+
 struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
 	u64 		reg_phys; /* physical address of hw register set */
@@ -435,6 +472,25 @@ struct intel_iommu {
 	u32		flags;      /* Software defined flags */
 };
 
+/* PCI domain-device relationship */
+struct device_domain_info {
+	struct list_head link;	/* link to domain siblings */
+	struct list_head global; /* link to global list */
+	u8 bus;			/* PCI bus number */
+	u8 devfn;		/* PCI devfn number */
+	u16 pfsid;		/* SRIOV physical function source ID */
+	u8 pasid_supported:3;
+	u8 pasid_enabled:1;
+	u8 pri_supported:1;
+	u8 pri_enabled:1;
+	u8 ats_supported:1;
+	u8 ats_enabled:1;
+	u8 ats_qdep;
+	struct device *dev; /* it's NULL for PCIe-to-PCI bridge */
+	struct intel_iommu *iommu; /* IOMMU used by this device */
+	struct dmar_domain *domain; /* pointer to domain */
+};
+
 static inline void __iommu_flush_cache(
 	struct intel_iommu *iommu, void *addr, int size)
 {
@@ -460,6 +516,11 @@ extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);
 
+struct dmar_domain *get_valid_domain_for_dev(struct device *dev);
+void *alloc_pgtable_page(int node);
+void free_pgtable_page(void *vaddr);
+struct intel_iommu *domain_get_iommu(struct dmar_domain *domain);
+
 #ifdef CONFIG_INTEL_IOMMU_SVM
 extern int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu);
 extern int intel_svm_free_pasid_tables(struct intel_iommu *iommu);

commit af39507305fb83a5d3c475c2851f4d59545d8a18
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat Jul 14 15:46:56 2018 +0800

    iommu/vt-d: Apply global PASID in SVA
    
    This patch applies the global pasid name space in the shared
    virtual address (SVA) implementation.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Reviewed-by: Liu Yi L <yi.l.liu@intel.com>
    Reviewed-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index e1e193855581..2ff15195f73d 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -420,7 +420,6 @@ struct intel_iommu {
 	struct pasid_state_entry *pasid_state_table;
 	struct page_req_dsc *prq;
 	unsigned char prq_name[16];    /* Name for PRQ interrupt */
-	struct idr pasid_idr;
 	u32 pasid_max;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */

commit 51261aac51a05c791ef880a100ac2ceed201ef72
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat Jul 14 15:46:55 2018 +0800

    iommu/vt-d: Avoid using idr_for_each_entry()
    
    idr_for_each_entry() is used to iteratte over idr elements
    of a given type. It isn't suitable for the globle pasid idr
    since the pasid idr consumer could specify different types
    of pointers to bind with a pasid.
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Reviewed-by: Liu Yi L <yi.l.liu@intel.com>
    Reviewed-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 6692b40ca814..e1e193855581 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -487,6 +487,7 @@ struct intel_svm {
 	int flags;
 	int pasid;
 	struct list_head devs;
+	struct list_head list;
 };
 
 extern int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct intel_svm_dev *sdev);

commit 2db1581e1f432ac6b4efe152c57fdfb4de85c154
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sun Jul 8 14:23:21 2018 +0800

    Revert "iommu/vt-d: Clean up pasid quirk for pre-production devices"
    
    This reverts commit ab96746aaa344fb720a198245a837e266fad3b62.
    
    The commit ab96746aaa34 ("iommu/vt-d: Clean up pasid quirk for
    pre-production devices") triggers ECS mode on some platforms
    which have broken ECS support. As the result, graphic device
    will be inoperable on boot.
    
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=107017
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 1df940196ab2..ef169d67df92 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -121,6 +121,7 @@
 #define ecap_srs(e)		((e >> 31) & 0x1)
 #define ecap_ers(e)		((e >> 30) & 0x1)
 #define ecap_prs(e)		((e >> 29) & 0x1)
+#define ecap_broken_pasid(e)	((e >> 28) & 0x1)
 #define ecap_dis(e)		((e >> 27) & 0x1)
 #define ecap_nest(e)		((e >> 26) & 0x1)
 #define ecap_mts(e)		((e >> 25) & 0x1)

commit 1c48db44924298ad0cb5a6386b88017539be8822
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Thu Jun 7 09:57:00 2018 -0700

    iommu/vt-d: Fix dev iotlb pfsid use
    
    PFSID should be used in the invalidation descriptor for flushing
    device IOTLBs on SRIOV VFs.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: stable@vger.kernel.org
    Cc: "Ashok Raj" <ashok.raj@intel.com>
    Cc: "Lu Baolu" <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 3b1c37155572..6692b40ca814 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -455,9 +455,8 @@ extern void qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,
 			     u8 fm, u64 type);
 extern void qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 			  unsigned int size_order, u64 type);
-extern void qi_flush_dev_iotlb(struct intel_iommu *iommu, u16 sid, u16 qdep,
-			       u64 addr, unsigned mask);
-
+extern void qi_flush_dev_iotlb(struct intel_iommu *iommu, u16 sid, u16 pfsid,
+			u16 qdep, u64 addr, unsigned mask);
 extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);

commit 0f725561e168485eff7277d683405c05b192f537
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Thu Jun 7 09:56:59 2018 -0700

    iommu/vt-d: Add definitions for PFSID
    
    When SRIOV VF device IOTLB is invalidated, we need to provide
    the PF source ID such that IOMMU hardware can gauge the depth
    of invalidation queue which is shared among VFs. This is needed
    when device invalidation throttle (DIT) capability is supported.
    
    This patch adds bit definitions for checking and tracking PFSID.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: stable@vger.kernel.org
    Cc: "Ashok Raj" <ashok.raj@intel.com>
    Cc: "Lu Baolu" <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 1df940196ab2..3b1c37155572 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -114,6 +114,7 @@
  * Extended Capability Register
  */
 
+#define ecap_dit(e)		((e >> 41) & 0x1)
 #define ecap_pasid(e)		((e >> 40) & 0x1)
 #define ecap_pss(e)		((e >> 35) & 0x1f)
 #define ecap_eafs(e)		((e >> 34) & 0x1)
@@ -283,6 +284,7 @@ enum {
 #define QI_DEV_IOTLB_SID(sid)	((u64)((sid) & 0xffff) << 32)
 #define QI_DEV_IOTLB_QDEP(qdep)	(((qdep) & 0x1f) << 16)
 #define QI_DEV_IOTLB_ADDR(addr)	((u64)(addr) & VTD_PAGE_MASK)
+#define QI_DEV_IOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | ((u64)(pfsid & 0xfff) << 52))
 #define QI_DEV_IOTLB_SIZE	1
 #define QI_DEV_IOTLB_MAX_INVS	32
 
@@ -307,6 +309,7 @@ enum {
 #define QI_DEV_EIOTLB_PASID(p)	(((u64)p) << 32)
 #define QI_DEV_EIOTLB_SID(sid)	((u64)((sid) & 0xffff) << 16)
 #define QI_DEV_EIOTLB_QDEP(qd)	((u64)((qd) & 0x1f) << 4)
+#define QI_DEV_EIOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | ((u64)(pfsid & 0xfff) << 52))
 #define QI_DEV_EIOTLB_MAX_INVS	32
 
 #define QI_PGRP_IDX(idx)	(((u64)(idx)) << 55)

commit ab96746aaa344fb720a198245a837e266fad3b62
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Fri May 4 13:08:18 2018 +0800

    iommu/vt-d: Clean up pasid quirk for pre-production devices
    
    The pasid28 quirk is needed only for some pre-production devices.
    Remove it to make the code concise.
    
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index ef169d67df92..1df940196ab2 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -121,7 +121,6 @@
 #define ecap_srs(e)		((e >> 31) & 0x1)
 #define ecap_ers(e)		((e >> 30) & 0x1)
 #define ecap_prs(e)		((e >> 29) & 0x1)
-#define ecap_broken_pasid(e)	((e >> 28) & 0x1)
 #define ecap_dis(e)		((e >> 27) & 0x1)
 #define ecap_nest(e)		((e >> 26) & 0x1)
 #define ecap_mts(e)		((e >> 25) & 0x1)

commit b1d03c1d12abbfa7de127772f281b309cf1650c3
Author: Dmitry Safonov <dima@arista.com>
Date:   Mon Feb 12 16:48:21 2018 +0000

    iommu/vt-d: Clean/document fault status flags
    
    So one could decode them without opening the specification.
    
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 8dad3dd26eae..ef169d67df92 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -209,12 +209,12 @@
 #define DMA_FECTL_IM (((u32)1) << 31)
 
 /* FSTS_REG */
-#define DMA_FSTS_PPF ((u32)2)
-#define DMA_FSTS_PFO ((u32)1)
-#define DMA_FSTS_IQE (1 << 4)
-#define DMA_FSTS_ICE (1 << 5)
-#define DMA_FSTS_ITE (1 << 6)
-#define DMA_FSTS_PRO (1 << 7)
+#define DMA_FSTS_PFO (1 << 0) /* Primary Fault Overflow */
+#define DMA_FSTS_PPF (1 << 1) /* Primary Pending Fault */
+#define DMA_FSTS_IQE (1 << 4) /* Invalidation Queue Error */
+#define DMA_FSTS_ICE (1 << 5) /* Invalidation Completion Error */
+#define DMA_FSTS_ITE (1 << 6) /* Invalidation Time-out Error */
+#define DMA_FSTS_PRO (1 << 7) /* Page Request Overflow */
 #define dma_fsts_fault_record_index(s) (((s) >> 8) & 0xff)
 
 /* FRCD_REG, 32 bits access */

commit f1ac10c24efbbcba0f8dae37ee90d45847f5c5af
Author: Sohil Mehta <sohil.mehta@intel.com>
Date:   Wed Dec 20 11:59:26 2017 -0800

    iommu/vt-d: Add a check for 5-level paging support
    
    Add a check to verify IOMMU 5-level paging support. If the CPU supports
    supports 5-level paging but the IOMMU does not support it then disable
    SVM by not allocating PASID tables.
    
    Signed-off-by: Sohil Mehta <sohil.mehta@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a56bab114f39..8dad3dd26eae 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -83,6 +83,7 @@
 /*
  * Decoding Capability Register
  */
+#define cap_5lp_support(c)	(((c) >> 60) & 1)
 #define cap_pi_support(c)	(((c) >> 59) & 1)
 #define cap_fl1gp_support(c)	(((c) >> 56) & 1)
 #define cap_read_drain(c)	(((c) >> 55) & 1)

commit 59103caa6839592788e7ad58b35863aac034631a
Author: Sohil Mehta <sohil.mehta@intel.com>
Date:   Wed Dec 20 11:59:25 2017 -0800

    iommu/vt-d: Add a check for 1GB page support
    
    Add a check to verify IOMMU 1GB page support. If the CPU supports 1GB
    pages but the IOMMU does not support it then disable SVM by not
    allocating PASID tables.
    
    Signed-off-by: Sohil Mehta <sohil.mehta@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index f3274d9f46a2..a56bab114f39 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -84,6 +84,7 @@
  * Decoding Capability Register
  */
 #define cap_pi_support(c)	(((c) >> 59) & 1)
+#define cap_fl1gp_support(c)	(((c) >> 56) & 1)
 #define cap_read_drain(c)	(((c) >> 55) & 1)
 #define cap_write_drain(c)	(((c) >> 54) & 1)
 #define cap_max_amask_val(c)	(((c) >> 48) & 0x3f)

commit 973b546451fdf11e518cc96d1b137af893a38db5
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Fri Nov 3 10:51:33 2017 -0600

    iommu/vt-d: Clear Page Request Overflow fault bit
    
    Currently Page Request Overflow bit in IOMMU Fault Status register
    is not cleared. Not clearing this bit would mean that any  future
    page-request is going to be automatically dropped by IOMMU.
    
    Suggested-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 485a5b48f038..f3274d9f46a2 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -212,6 +212,7 @@
 #define DMA_FSTS_IQE (1 << 4)
 #define DMA_FSTS_ICE (1 << 5)
 #define DMA_FSTS_ITE (1 << 6)
+#define DMA_FSTS_PRO (1 << 7)
 #define dma_fsts_fault_record_index(s) (((s) >> 8) & 0xff)
 
 /* FRCD_REG, 32 bits access */

commit 61012985eb132a2fa5e4a3eddbc33528334fa377
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Thu Mar 16 16:23:55 2017 +0200

    iommu/vt-d: Use lo_hi_readq() / lo_hi_writeq()
    
    There is already helper functions to do 64-bit I/O on 32-bit machines or
    buses, thus we don't need to reinvent the wheel.
    
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index c573a52ae440..485a5b48f038 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -30,6 +30,8 @@
 #include <linux/mmu_notifier.h>
 #include <linux/list.h>
 #include <linux/iommu.h>
+#include <linux/io-64-nonatomic-lo-hi.h>
+
 #include <asm/cacheflush.h>
 #include <asm/iommu.h>
 
@@ -72,24 +74,8 @@
 
 #define OFFSET_STRIDE		(9)
 
-#ifdef CONFIG_64BIT
 #define dmar_readq(a) readq(a)
 #define dmar_writeq(a,v) writeq(v,a)
-#else
-static inline u64 dmar_readq(void __iomem *addr)
-{
-	u32 lo, hi;
-	lo = readl(addr);
-	hi = readl(addr + 4);
-	return (((u64) hi) << 32) + lo;
-}
-
-static inline void dmar_writeq(void __iomem *addr, u64 val)
-{
-	writel((u32)val, addr);
-	writel((u32)(val >> 32), addr + 4);
-}
-#endif
 
 #define DMAR_VER_MAJOR(v)		(((v) & 0xf0) >> 4)
 #define DMAR_VER_MINOR(v)		((v) & 0x0f)

commit 8d2932dd0634ebeb0a42df896976772bdb569bfe
Merge: 99e8ccd3837a fff2fd1a9e4b 3b6bb5b705a4 aac7d39f200d 087a908f533f 2c9f1af528a4 f7116e115acd d0f6f5832603
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Feb 10 15:13:10 2017 +0100

    Merge branches 'iommu/fixes', 'arm/exynos', 'arm/renesas', 'arm/smmu', 'arm/mediatek', 'arm/core', 'x86/vt-d' and 'core' into next

commit 39ab9555c24110671f8dc671311a26e5c985b592
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Feb 1 16:56:46 2017 +0100

    iommu: Add sysfs bindings for struct iommu_device
    
    There is currently support for iommu sysfs bindings, but
    those need to be implemented in the IOMMU drivers. Add a
    more generic version of this by adding a struct device to
    struct iommu_device and use that for the sysfs bindings.
    
    Also convert the AMD and Intel IOMMU driver to make use of
    it.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 99a65a397861..3ba9b536387b 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -440,7 +440,6 @@ struct intel_iommu {
 	struct irq_domain *ir_domain;
 	struct irq_domain *ir_msi_domain;
 #endif
-	struct device	*iommu_dev; /* IOMMU-sysfs device */
 	struct iommu_device iommu;  /* IOMMU core code handle */
 	int		node;
 	u32		flags;      /* Software defined flags */

commit b0119e870837dcd15a207b4701542ebac5d19b45
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Feb 1 13:23:08 2017 +0100

    iommu: Introduce new 'struct iommu_device'
    
    This struct represents one hardware iommu in the iommu core
    code. For now it only has the iommu-ops associated with it,
    but that will be extended soon.
    
    The register/unregister interface is also added, as well as
    making use of it in the Intel and AMD IOMMU drivers.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index d49e26c6cdc7..99a65a397861 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -29,6 +29,7 @@
 #include <linux/dma_remapping.h>
 #include <linux/mmu_notifier.h>
 #include <linux/list.h>
+#include <linux/iommu.h>
 #include <asm/cacheflush.h>
 #include <asm/iommu.h>
 
@@ -440,6 +441,7 @@ struct intel_iommu {
 	struct irq_domain *ir_msi_domain;
 #endif
 	struct device	*iommu_dev; /* IOMMU-sysfs device */
+	struct iommu_device iommu;  /* IOMMU core code handle */
 	int		node;
 	u32		flags;      /* Software defined flags */
 };

commit aaa59306b0b7e0ca4ba92cc04c5db101cbb1c096
Author: CQ Tang <cq.tang@intel.com>
Date:   Mon Jan 30 09:39:52 2017 -0800

    iommu/vt-d: Fix some macros that are incorrectly specified in intel-iommu
    
    Some of the macros are incorrect with wrong bit-shifts resulting in picking
    the incorrect invalidation granularity. Incorrect Source-ID in extended
    devtlb invalidation caused device side errors.
    
    To: Joerg Roedel <joro@8bytes.org>
    To: David Woodhouse <dwmw2@infradead.org>
    Cc: iommu@lists.linux-foundation.org
    Cc: linux-kernel@vger.kernel.org
    Cc: stable@vger.kernel.org
    Cc: CQ Tang <cq.tang@intel.com>
    Cc: Ashok Raj <ashok.raj@intel.com>
    
    Fixes: 2f26e0a9 ("iommu/vt-d: Add basic SVM PASID support")
    Signed-off-by: CQ Tang <cq.tang@intel.com>
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Tested-by: CQ Tang <cq.tang@intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index d49e26c6cdc7..23e129ef6726 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -153,8 +153,8 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define DMA_TLB_GLOBAL_FLUSH (((u64)1) << 60)
 #define DMA_TLB_DSI_FLUSH (((u64)2) << 60)
 #define DMA_TLB_PSI_FLUSH (((u64)3) << 60)
-#define DMA_TLB_IIRG(type) ((type >> 60) & 7)
-#define DMA_TLB_IAIG(val) (((val) >> 57) & 7)
+#define DMA_TLB_IIRG(type) ((type >> 60) & 3)
+#define DMA_TLB_IAIG(val) (((val) >> 57) & 3)
 #define DMA_TLB_READ_DRAIN (((u64)1) << 49)
 #define DMA_TLB_WRITE_DRAIN (((u64)1) << 48)
 #define DMA_TLB_DID(id)	(((u64)((id) & 0xffff)) << 32)
@@ -164,9 +164,9 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 
 /* INVALID_DESC */
 #define DMA_CCMD_INVL_GRANU_OFFSET  61
-#define DMA_ID_TLB_GLOBAL_FLUSH	(((u64)1) << 3)
-#define DMA_ID_TLB_DSI_FLUSH	(((u64)2) << 3)
-#define DMA_ID_TLB_PSI_FLUSH	(((u64)3) << 3)
+#define DMA_ID_TLB_GLOBAL_FLUSH	(((u64)1) << 4)
+#define DMA_ID_TLB_DSI_FLUSH	(((u64)2) << 4)
+#define DMA_ID_TLB_PSI_FLUSH	(((u64)3) << 4)
 #define DMA_ID_TLB_READ_DRAIN	(((u64)1) << 7)
 #define DMA_ID_TLB_WRITE_DRAIN	(((u64)1) << 6)
 #define DMA_ID_TLB_DID(id)	(((u64)((id & 0xffff) << 16)))
@@ -316,8 +316,8 @@ enum {
 #define QI_DEV_EIOTLB_SIZE	(((u64)1) << 11)
 #define QI_DEV_EIOTLB_GLOB(g)	((u64)g)
 #define QI_DEV_EIOTLB_PASID(p)	(((u64)p) << 32)
-#define QI_DEV_EIOTLB_SID(sid)	((u64)((sid) & 0xffff) << 32)
-#define QI_DEV_EIOTLB_QDEP(qd)	(((qd) & 0x1f) << 16)
+#define QI_DEV_EIOTLB_SID(sid)	((u64)((sid) & 0xffff) << 16)
+#define QI_DEV_EIOTLB_QDEP(qd)	((u64)((qd) & 0x1f) << 4)
 #define QI_DEV_EIOTLB_MAX_INVS	32
 
 #define QI_PGRP_IDX(idx)	(((u64)(idx)) << 55)

commit 910170442944e1f8674fd5ddbeeb8ccd1877ea98
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Mon Sep 12 10:49:11 2016 +0800

    iommu/vt-d: Fix PASID table allocation
    
    Somehow I ended up with an off-by-three error in calculating the size of
    the PASID and PASID State tables, which triggers allocations failures as
    those tables unfortunately have to be physically contiguous.
    
    In fact, even the *correct* maximum size of 8MiB is problematic and is
    wont to lead to allocation failures. Since I have extracted a promise
    that this *will* be fixed in hardware, I'm happy to limit it on the
    current hardware to a maximum of 0x20000 PASIDs, which gives us 1MiB
    tables — still not ideal, but better than before.
    
    Reported by Mika Kuoppala <mika.kuoppala@linux.intel.com> and also by
    Xunlei Pang <xlpang@redhat.com> who submitted a simpler patch to fix
    only the allocation (and not the free) to the "correct" limit... which
    was still problematic.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>
    Cc: stable@vger.kernel.org

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 2d9b650047a5..d49e26c6cdc7 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -429,6 +429,7 @@ struct intel_iommu {
 	struct page_req_dsc *prq;
 	unsigned char prq_name[16];    /* Name for PRQ interrupt */
 	struct idr pasid_idr;
+	u32 pasid_max;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
 	u32 *iommu_state; /* Store iommu states between suspend and resume.*/

commit 46924008273ed03bd11dbb32136e3da4cfe056e1
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Mon Feb 15 12:42:38 2016 +0000

    iommu/vt-d: Clear PPR bit to ensure we get more page request interrupts
    
    According to the VT-d specification we need to clear the PPR bit in
    the Page Request Status register when handling page requests, or the
    hardware won't generate any more interrupts.
    
    This wasn't actually necessary on SKL/KBL (which may well be the
    subject of a hardware erratum, although it's harmless enough). But
    other implementations do appear to get it right, and we only ever get
    one interrupt unless we clear the PPR bit.
    
    Reported-by: CQ Tang <cq.tang@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Cc: stable@vger.kernel.org

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 821273ca4873..2d9b650047a5 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -235,6 +235,9 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 /* low 64 bit */
 #define dma_frcd_page_addr(d) (d & (((u64)-1) << PAGE_SHIFT))
 
+/* PRS_REG */
+#define DMA_PRS_PPR	((u32)1)
+
 #define IOMMU_WAIT_OP(iommu, offset, op, cond, sts)			\
 do {									\
 	cycles_t start_time = get_cycles();				\

commit 569e4f7782fb92d0e1b395b5fb01de642dd74dcf
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Thu Oct 15 13:59:14 2015 +0100

    iommu/vt-d: Implement SVM_FLAG_PRIVATE_PASID to allocate unique PASIDs
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 57be14fce640..821273ca4873 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -489,6 +489,7 @@ struct intel_svm {
 	struct mmu_notifier notifier;
 	struct mm_struct *mm;
 	struct intel_iommu *iommu;
+	int flags;
 	int pasid;
 	struct list_head devs;
 };

commit 0204a49609824163092c32a8aeb073f7e9acc76d
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Tue Oct 13 17:18:10 2015 +0100

    iommu/vt-d: Add callback to device driver on page faults
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index e5b80d31eb1b..57be14fce640 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -472,10 +472,13 @@ extern int intel_svm_free_pasid_tables(struct intel_iommu *iommu);
 extern int intel_svm_enable_prq(struct intel_iommu *iommu);
 extern int intel_svm_finish_prq(struct intel_iommu *iommu);
 
+struct svm_dev_ops;
+
 struct intel_svm_dev {
 	struct list_head list;
 	struct rcu_head rcu;
 	struct device *dev;
+	struct svm_dev_ops *ops;
 	int users;
 	u16 did;
 	u16 dev_iotlb:1;

commit a222a7f0bb6c94c31cc9c755110593656f19de89
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Oct 7 23:35:18 2015 +0100

    iommu/vt-d: Implement page request handling
    
    Largely based on the driver-mode implementation by Jesse Barnes.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index f16a2b9124d1..e5b80d31eb1b 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -265,6 +265,8 @@ enum {
 #define QI_EIOTLB_TYPE		0x6
 #define QI_PC_TYPE		0x7
 #define QI_DEIOTLB_TYPE		0x8
+#define QI_PGRP_RESP_TYPE	0x9
+#define QI_PSTRM_RESP_TYPE	0xa
 
 #define QI_IEC_SELECTIVE	(((u64)1) << 4)
 #define QI_IEC_IIDEX(idx)	(((u64)(idx & 0xffff) << 32))
@@ -315,6 +317,25 @@ enum {
 #define QI_DEV_EIOTLB_QDEP(qd)	(((qd) & 0x1f) << 16)
 #define QI_DEV_EIOTLB_MAX_INVS	32
 
+#define QI_PGRP_IDX(idx)	(((u64)(idx)) << 55)
+#define QI_PGRP_PRIV(priv)	(((u64)(priv)) << 32)
+#define QI_PGRP_RESP_CODE(res)	((u64)(res))
+#define QI_PGRP_PASID(pasid)	(((u64)(pasid)) << 32)
+#define QI_PGRP_DID(did)	(((u64)(did)) << 16)
+#define QI_PGRP_PASID_P(p)	(((u64)(p)) << 4)
+
+#define QI_PSTRM_ADDR(addr)	(((u64)(addr)) & VTD_PAGE_MASK)
+#define QI_PSTRM_DEVFN(devfn)	(((u64)(devfn)) << 4)
+#define QI_PSTRM_RESP_CODE(res)	((u64)(res))
+#define QI_PSTRM_IDX(idx)	(((u64)(idx)) << 55)
+#define QI_PSTRM_PRIV(priv)	(((u64)(priv)) << 32)
+#define QI_PSTRM_BUS(bus)	(((u64)(bus)) << 24)
+#define QI_PSTRM_PASID(pasid)	(((u64)(pasid)) << 4)
+
+#define QI_RESP_SUCCESS		0x0
+#define QI_RESP_INVALID		0x1
+#define QI_RESP_FAILURE		0xf
+
 #define QI_GRAN_ALL_ALL			0
 #define QI_GRAN_NONG_ALL		1
 #define QI_GRAN_NONG_PASID		2
@@ -369,6 +390,7 @@ enum {
 
 struct pasid_entry;
 struct pasid_state_entry;
+struct page_req_dsc;
 
 struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
@@ -401,6 +423,8 @@ struct intel_iommu {
 	 * told to. But while it's all driver-arbitrated, we're fine. */
 	struct pasid_entry *pasid_table;
 	struct pasid_state_entry *pasid_state_table;
+	struct page_req_dsc *prq;
+	unsigned char prq_name[16];    /* Name for PRQ interrupt */
 	struct idr pasid_idr;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
@@ -445,6 +469,8 @@ extern int dmar_ir_support(void);
 #ifdef CONFIG_INTEL_IOMMU_SVM
 extern int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu);
 extern int intel_svm_free_pasid_tables(struct intel_iommu *iommu);
+extern int intel_svm_enable_prq(struct intel_iommu *iommu);
+extern int intel_svm_finish_prq(struct intel_iommu *iommu);
 
 struct intel_svm_dev {
 	struct list_head list;

commit 1208225cf48fa3b170b6dfe7369f15c295260755
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Oct 7 15:37:03 2015 +0100

    iommu/vt-d: Generalise DMAR MSI setup to allow for page request events
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 46add607567b..f16a2b9124d1 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -60,6 +60,14 @@
 #define DMAR_IQA_REG	0x90	/* Invalidation queue addr register */
 #define DMAR_ICS_REG	0x9c	/* Invalidation complete status register */
 #define DMAR_IRTA_REG	0xb8    /* Interrupt remapping table addr register */
+#define DMAR_PQH_REG	0xc0	/* Page request queue head register */
+#define DMAR_PQT_REG	0xc8	/* Page request queue tail register */
+#define DMAR_PQA_REG	0xd0	/* Page request queue address register */
+#define DMAR_PRS_REG	0xdc	/* Page request status register */
+#define DMAR_PECTL_REG	0xe0	/* Page request event control register */
+#define	DMAR_PEDATA_REG	0xe4	/* Page request event interrupt data register */
+#define	DMAR_PEADDR_REG	0xe8	/* Page request event interrupt addr register */
+#define	DMAR_PEUADDR_REG 0xec	/* Page request event Upper address register */
 
 #define OFFSET_STRIDE		(9)
 
@@ -373,7 +381,7 @@ struct intel_iommu {
 	int		seq_id;	/* sequence id of the iommu */
 	int		agaw; /* agaw of this iommu */
 	int		msagaw; /* max sagaw of this iommu */
-	unsigned int 	irq;
+	unsigned int 	irq, pr_irq;
 	u16		segment;     /* PCI segment# */
 	unsigned char 	name[13];    /* Device Name */
 

commit 2f26e0a9c9860db290d63e9d85c2c8c09813677f
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Sep 9 11:40:47 2015 +0100

    iommu/vt-d: Add basic SVM PASID support
    
    This provides basic PASID support for endpoint devices, tested with a
    version of the i915 driver.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 0f38e60d40ad..46add607567b 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -1,5 +1,9 @@
 /*
- * Copyright (c) 2006, Intel Corporation.
+ * Copyright © 2006-2015, Intel Corporation.
+ *
+ * Authors: Ashok Raj <ashok.raj@intel.com>
+ *          Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
+ *          David Woodhouse <David.Woodhouse@intel.com>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
@@ -13,10 +17,6 @@
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
- *
- * Copyright (C) 2006-2008 Intel Corporation
- * Author: Ashok Raj <ashok.raj@intel.com>
- * Author: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
  */
 
 #ifndef _INTEL_IOMMU_H_
@@ -25,7 +25,10 @@
 #include <linux/types.h>
 #include <linux/iova.h>
 #include <linux/io.h>
+#include <linux/idr.h>
 #include <linux/dma_remapping.h>
+#include <linux/mmu_notifier.h>
+#include <linux/list.h>
 #include <asm/cacheflush.h>
 #include <asm/iommu.h>
 
@@ -251,6 +254,9 @@ enum {
 #define QI_DIOTLB_TYPE		0x3
 #define QI_IEC_TYPE		0x4
 #define QI_IWD_TYPE		0x5
+#define QI_EIOTLB_TYPE		0x6
+#define QI_PC_TYPE		0x7
+#define QI_DEIOTLB_TYPE		0x8
 
 #define QI_IEC_SELECTIVE	(((u64)1) << 4)
 #define QI_IEC_IIDEX(idx)	(((u64)(idx & 0xffff) << 32))
@@ -278,6 +284,34 @@ enum {
 #define QI_DEV_IOTLB_SIZE	1
 #define QI_DEV_IOTLB_MAX_INVS	32
 
+#define QI_PC_PASID(pasid)	(((u64)pasid) << 32)
+#define QI_PC_DID(did)		(((u64)did) << 16)
+#define QI_PC_GRAN(gran)	(((u64)gran) << 4)
+
+#define QI_PC_ALL_PASIDS	(QI_PC_TYPE | QI_PC_GRAN(0))
+#define QI_PC_PASID_SEL		(QI_PC_TYPE | QI_PC_GRAN(1))
+
+#define QI_EIOTLB_ADDR(addr)	((u64)(addr) & VTD_PAGE_MASK)
+#define QI_EIOTLB_GL(gl)	(((u64)gl) << 7)
+#define QI_EIOTLB_IH(ih)	(((u64)ih) << 6)
+#define QI_EIOTLB_AM(am)	(((u64)am))
+#define QI_EIOTLB_PASID(pasid) 	(((u64)pasid) << 32)
+#define QI_EIOTLB_DID(did)	(((u64)did) << 16)
+#define QI_EIOTLB_GRAN(gran) 	(((u64)gran) << 4)
+
+#define QI_DEV_EIOTLB_ADDR(a)	((u64)(a) & VTD_PAGE_MASK)
+#define QI_DEV_EIOTLB_SIZE	(((u64)1) << 11)
+#define QI_DEV_EIOTLB_GLOB(g)	((u64)g)
+#define QI_DEV_EIOTLB_PASID(p)	(((u64)p) << 32)
+#define QI_DEV_EIOTLB_SID(sid)	((u64)((sid) & 0xffff) << 32)
+#define QI_DEV_EIOTLB_QDEP(qd)	(((qd) & 0x1f) << 16)
+#define QI_DEV_EIOTLB_MAX_INVS	32
+
+#define QI_GRAN_ALL_ALL			0
+#define QI_GRAN_NONG_ALL		1
+#define QI_GRAN_NONG_PASID		2
+#define QI_GRAN_PSI_PASID		3
+
 struct qi_desc {
 	u64 low, high;
 };
@@ -359,6 +393,7 @@ struct intel_iommu {
 	 * told to. But while it's all driver-arbitrated, we're fine. */
 	struct pasid_entry *pasid_table;
 	struct pasid_state_entry *pasid_state_table;
+	struct idr pasid_idr;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
 	u32 *iommu_state; /* Store iommu states between suspend and resume.*/
@@ -399,9 +434,32 @@ extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);
 
+#ifdef CONFIG_INTEL_IOMMU_SVM
 extern int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu);
 extern int intel_svm_free_pasid_tables(struct intel_iommu *iommu);
 
+struct intel_svm_dev {
+	struct list_head list;
+	struct rcu_head rcu;
+	struct device *dev;
+	int users;
+	u16 did;
+	u16 dev_iotlb:1;
+	u16 sid, qdep;
+};
+
+struct intel_svm {
+	struct mmu_notifier notifier;
+	struct mm_struct *mm;
+	struct intel_iommu *iommu;
+	int pasid;
+	struct list_head devs;
+};
+
+extern int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct intel_svm_dev *sdev);
+extern struct intel_iommu *intel_svm_device_to_iommu(struct device *dev);
+#endif
+
 extern const struct attribute_group *intel_iommu_groups[];
 
 #endif

commit 8a94ade4ce6df22006b96c5c9a8d6d12fce67585
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Tue Mar 24 14:54:56 2015 +0000

    iommu/vt-d: Add initial support for PASID tables
    
    Add CONFIG_INTEL_IOMMU_SVM, and allocate PASID tables on supported hardware.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 1d69c1d3aa9a..0f38e60d40ad 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -325,6 +325,9 @@ enum {
 #define VTD_FLAG_TRANS_PRE_ENABLED	(1 << 0)
 #define VTD_FLAG_IRQ_REMAP_PRE_ENABLED	(1 << 1)
 
+struct pasid_entry;
+struct pasid_state_entry;
+
 struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
 	u64 		reg_phys; /* physical address of hw register set */
@@ -347,6 +350,15 @@ struct intel_iommu {
 	struct root_entry *root_entry; /* virtual address */
 
 	struct iommu_flush flush;
+#endif
+#ifdef CONFIG_INTEL_IOMMU_SVM
+	/* These are large and need to be contiguous, so we allocate just
+	 * one for now. We'll maybe want to rethink that if we truly give
+	 * devices away to userspace processes (e.g. for DPDK) and don't
+	 * want to trust that userspace will use *only* the PASID it was
+	 * told to. But while it's all driver-arbitrated, we're fine. */
+	struct pasid_entry *pasid_table;
+	struct pasid_state_entry *pasid_state_table;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
 	u32 *iommu_state; /* Store iommu states between suspend and resume.*/
@@ -387,6 +399,9 @@ extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);
 
+extern int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu);
+extern int intel_svm_free_pasid_tables(struct intel_iommu *iommu);
+
 extern const struct attribute_group *intel_iommu_groups[];
 
 #endif

commit ae853ddb9ad5e7c01cad3fbf016040acd961f407
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Sep 9 11:58:59 2015 +0100

    iommu/vt-d: Introduce intel_iommu=pasid28, and pasid_enabled() macro
    
    As long as we use an identity mapping to work around the worst of the
    hardware bugs which caused us to defeature it and change the definition
    of the capability bit, we *can* use PASID support on the devices which
    advertised it in bit 28 of the Extended Capability Register.
    
    Allow people to do so with 'intel_iommu=pasid28' on the command line.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 08802b99f057..1d69c1d3aa9a 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -121,7 +121,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define ecap_srs(e)		((e >> 31) & 0x1)
 #define ecap_ers(e)		((e >> 30) & 0x1)
 #define ecap_prs(e)		((e >> 29) & 0x1)
-/* PASID support used to be on bit 28 */
+#define ecap_broken_pasid(e)	((e >> 28) & 0x1)
 #define ecap_dis(e)		((e >> 27) & 0x1)
 #define ecap_nest(e)		((e >> 26) & 0x1)
 #define ecap_mts(e)		((e >> 25) & 0x1)

commit 50d3fb562561fcf5b745e71945834735d7386a1f
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Tue Oct 13 20:48:21 2015 +0100

    iommu/vt-d: Use plain writeq() for dmar_writeq() where available
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 6240063bdcac..08802b99f057 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -59,14 +59,11 @@
 #define DMAR_IRTA_REG	0xb8    /* Interrupt remapping table addr register */
 
 #define OFFSET_STRIDE		(9)
-/*
-#define dmar_readl(dmar, reg) readl(dmar + reg)
-#define dmar_readq(dmar, reg) ({ \
-		u32 lo, hi; \
-		lo = readl(dmar + reg); \
-		hi = readl(dmar + reg + 4); \
-		(((u64) hi) << 32) + lo; })
-*/
+
+#ifdef CONFIG_64BIT
+#define dmar_readq(a) readq(a)
+#define dmar_writeq(a,v) writeq(v,a)
+#else
 static inline u64 dmar_readq(void __iomem *addr)
 {
 	u32 lo, hi;
@@ -80,6 +77,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 	writel((u32)val, addr);
 	writel((u32)(val >> 32), addr + 4);
 }
+#endif
 
 #define DMAR_VER_MAJOR(v)		(((v) & 0xf0) >> 4)
 #define DMAR_VER_MINOR(v)		((v) & 0x0f)

commit 8bf478163e69e42973c7070179a11815139e5bf0
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Jul 21 10:41:21 2015 +0200

    iommu/vt-d: Split up iommu->domains array
    
    This array is indexed by the domain-id and contains the
    pointers to the domains attached to this iommu. Modern
    systems support 65536 domain ids, so that this array has a
    size of 512kb, per iommu.
    
    This is a huge waste of space, as the array is usually
    sparsely populated. This patch makes the array
    two-dimensional and allocates the memory for the domain
    pointers on-demand.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index d9a366d24e3b..6240063bdcac 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -344,7 +344,7 @@ struct intel_iommu {
 
 #ifdef CONFIG_INTEL_IOMMU
 	unsigned long 	*domain_ids; /* bitmap of domains */
-	struct dmar_domain **domains; /* ptr to domains */
+	struct dmar_domain ***domains; /* ptr to domains */
 	spinlock_t	lock; /* protect context, domain ids */
 	struct root_entry *root_entry; /* virtual address */
 

commit 6eae81a5e2d6646a61146501fd3032a340863c1d
Merge: 54245ed870c8 5ffde2f67181
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 23 18:27:19 2015 -0700

    Merge tag 'iommu-updates-v4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu
    
    Pull IOMMU updates from Joerg Roedel:
     "This time with bigger changes than usual:
    
       - A new IOMMU driver for the ARM SMMUv3.
    
         This IOMMU is pretty different from SMMUv1 and v2 in that it is
         configured through in-memory structures and not through the MMIO
         register region.  The ARM SMMUv3 also supports IO demand paging for
         PCI devices with PRI/PASID capabilities, but this is not
         implemented in the driver yet.
    
       - Lots of cleanups and device-tree support for the Exynos IOMMU
         driver.  This is part of the effort to bring Exynos DRM support
         upstream.
    
       - Introduction of default domains into the IOMMU core code.
    
         The rationale behind this is to move functionalily out of the IOMMU
         drivers to common code to get to a unified behavior between
         different drivers.  The patches here introduce a default domain for
         iommu-groups (isolation groups).
    
         A device will now always be attached to a domain, either the
         default domain or another domain handled by the device driver.  The
         IOMMU drivers have to be modified to make use of that feature.  So
         long the AMD IOMMU driver is converted, with others to follow.
    
       - Patches for the Intel VT-d drvier to fix DMAR faults that happen
         when a kdump kernel boots.
    
         When the kdump kernel boots it re-initializes the IOMMU hardware,
         which destroys all mappings from the crashed kernel.  As this
         happens before the endpoint devices are re-initialized, any
         in-flight DMA causes a DMAR fault.  These faults cause PCI master
         aborts, which some devices can't handle properly and go into an
         undefined state, so that the device driver in the kdump kernel
         fails to initialize them and the dump fails.
    
         This is now fixed by copying over the mapping structures (only
         context tables and interrupt remapping tables) from the old kernel
         and keep the old mappings in place until the device driver of the
         new kernel takes over.  This emulates the the behavior without an
         IOMMU to the best degree possible.
    
       - A couple of other small fixes and cleanups"
    
    * tag 'iommu-updates-v4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu: (69 commits)
      iommu/amd: Handle large pages correctly in free_pagetable
      iommu/vt-d: Don't disable IR when it was previously enabled
      iommu/vt-d: Make sure copied over IR entries are not reused
      iommu/vt-d: Copy IR table from old kernel when in kdump mode
      iommu/vt-d: Set IRTA in intel_setup_irq_remapping
      iommu/vt-d: Disable IRQ remapping in intel_prepare_irq_remapping
      iommu/vt-d: Move QI initializationt to intel_setup_irq_remapping
      iommu/vt-d: Move EIM detection to intel_prepare_irq_remapping
      iommu/vt-d: Enable Translation only if it was previously disabled
      iommu/vt-d: Don't disable translation prior to OS handover
      iommu/vt-d: Don't copy translation tables if RTT bit needs to be changed
      iommu/vt-d: Don't do early domain assignment if kdump kernel
      iommu/vt-d: Allocate si_domain in init_dmars()
      iommu/vt-d: Mark copied context entries
      iommu/vt-d: Do not re-use domain-ids from the old kernel
      iommu/vt-d: Copy translation tables from old kernel
      iommu/vt-d: Detect pre enabled translation
      iommu/vt-d: Make root entry visible for hardware right after allocation
      iommu/vt-d: Init QI before root entry is allocated
      iommu/vt-d: Cleanup log messages
      ...

commit d70b3ef54ceaf1c7c92209f5a662a670d04cbed9
Merge: 650ec5a6bd5d 7ef3d7d58d9d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 22 17:59:09 2015 -0700

    Merge branch 'x86-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 core updates from Ingo Molnar:
     "There were so many changes in the x86/asm, x86/apic and x86/mm topics
      in this cycle that the topical separation of -tip broke down somewhat -
      so the result is a more traditional architecture pull request,
      collected into the 'x86/core' topic.
    
      The topics were still maintained separately as far as possible, so
      bisectability and conceptual separation should still be pretty good -
      but there were a handful of merge points to avoid excessive
      dependencies (and conflicts) that would have been poorly tested in the
      end.
    
      The next cycle will hopefully be much more quiet (or at least will
      have fewer dependencies).
    
      The main changes in this cycle were:
    
       * x86/apic changes, with related IRQ core changes: (Jiang Liu, Thomas
         Gleixner)
    
         - This is the second and most intrusive part of changes to the x86
           interrupt handling - full conversion to hierarchical interrupt
           domains:
    
              [IOAPIC domain]   -----
                                     |
              [MSI domain]      --------[Remapping domain] ----- [ Vector domain ]
                                     |   (optional)          |
              [HPET MSI domain] -----                        |
                                                             |
              [DMAR domain]     -----------------------------
                                                             |
              [Legacy domain]   -----------------------------
    
           This now reflects the actual hardware and allowed us to distangle
           the domain specific code from the underlying parent domain, which
           can be optional in the case of interrupt remapping.  It's a clear
           separation of functionality and removes quite some duct tape
           constructs which plugged the remap code between ioapic/msi/hpet
           and the vector management.
    
         - Intel IOMMU IRQ remapping enhancements, to allow direct interrupt
           injection into guests (Feng Wu)
    
       * x86/asm changes:
    
         - Tons of cleanups and small speedups, micro-optimizations.  This
           is in preparation to move a good chunk of the low level entry
           code from assembly to C code (Denys Vlasenko, Andy Lutomirski,
           Brian Gerst)
    
         - Moved all system entry related code to a new home under
           arch/x86/entry/ (Ingo Molnar)
    
         - Removal of the fragile and ugly CFI dwarf debuginfo annotations.
           Conversion to C will reintroduce many of them - but meanwhile
           they are only getting in the way, and the upstream kernel does
           not rely on them (Ingo Molnar)
    
         - NOP handling refinements. (Borislav Petkov)
    
       * x86/mm changes:
    
         - Big PAT and MTRR rework: making the code more robust and
           preparing to phase out exposing direct MTRR interfaces to drivers -
           in favor of using PAT driven interfaces (Toshi Kani, Luis R
           Rodriguez, Borislav Petkov)
    
         - New ioremap_wt()/set_memory_wt() interfaces to support
           Write-Through cached memory mappings.  This is especially
           important for good performance on NVDIMM hardware (Toshi Kani)
    
       * x86/ras changes:
    
         - Add support for deferred errors on AMD (Aravind Gopalakrishnan)
    
           This is an important RAS feature which adds hardware support for
           poisoned data.  That means roughly that the hardware marks data
           which it has detected as corrupted but wasn't able to correct, as
           poisoned data and raises an APIC interrupt to signal that in the
           form of a deferred error.  It is the OS's responsibility then to
           take proper recovery action and thus prolonge system lifetime as
           far as possible.
    
         - Add support for Intel "Local MCE"s: upcoming CPUs will support
           CPU-local MCE interrupts, as opposed to the traditional system-
           wide broadcasted MCE interrupts (Ashok Raj)
    
         - Misc cleanups (Borislav Petkov)
    
       * x86/platform changes:
    
         - Intel Atom SoC updates
    
      ... and lots of other cleanups, fixlets and other changes - see the
      shortlog and the Git log for details"
    
    * 'x86-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (222 commits)
      x86/hpet: Use proper hpet device number for MSI allocation
      x86/hpet: Check for irq==0 when allocating hpet MSI interrupts
      x86/mm/pat, drivers/infiniband/ipath: Use arch_phys_wc_add() and require PAT disabled
      x86/mm/pat, drivers/media/ivtv: Use arch_phys_wc_add() and require PAT disabled
      x86/platform/intel/baytrail: Add comments about why we disabled HPET on Baytrail
      genirq: Prevent crash in irq_move_irq()
      genirq: Enhance irq_data_to_desc() to support hierarchy irqdomain
      iommu, x86: Properly handle posted interrupts for IOMMU hotplug
      iommu, x86: Provide irq_remapping_cap() interface
      iommu, x86: Setup Posted-Interrupts capability for Intel iommu
      iommu, x86: Add cap_pi_support() to detect VT-d PI capability
      iommu, x86: Avoid migrating VT-d posted interrupts
      iommu, x86: Save the mode (posted or remapped) of an IRTE
      iommu, x86: Implement irq_set_vcpu_affinity for intel_ir_chip
      iommu: dmar: Provide helper to copy shared irte fields
      iommu: dmar: Extend struct irte for VT-d Posted-Interrupts
      iommu: Add new member capability to struct irq_remap_ops
      x86/asm/entry/64: Disentangle error_entry/exit gsbase/ebx/usermode code
      x86/asm/entry/32: Shorten __audit_syscall_entry() args preparation
      x86/asm/entry/32: Explain reloading of registers after __audit_syscall_entry()
      ...

commit af3b358e48115588d905cc07a47b3f356e0d01d1
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Jun 12 15:00:21 2015 +0200

    iommu/vt-d: Copy IR table from old kernel when in kdump mode
    
    When we are booting into a kdump kernel and find IR enabled,
    copy over the contents of the previous IR table so that
    spurious interrupts will not be target aborted.
    
    Tested-by: ZhenHua Li <zhen-hual@hp.com>
    Tested-by: Baoquan He <bhe@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index b85b81ad5eba..9e14edcf7f6e 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -296,6 +296,7 @@ struct q_inval {
 /* 1MB - maximum possible interrupt remapping table size */
 #define INTR_REMAP_PAGE_ORDER	8
 #define INTR_REMAP_TABLE_REG_SIZE	0xf
+#define INTR_REMAP_TABLE_REG_SIZE_MASK  0xf
 
 #define INTR_REMAP_TABLE_ENTRIES	65536
 

commit 4158c2eca3c77ed3cccdcaeab153aad4e433369c
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Jun 12 10:14:02 2015 +0200

    iommu/vt-d: Detect pre enabled translation
    
    Add code to detect whether translation is already enabled in
    the IOMMU. Save this state in a flags field added to
    struct intel_iommu.
    
    Tested-by: ZhenHua Li <zhen-hual@hp.com>
    Tested-by: Baoquan He <bhe@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a240e61a7700..b85b81ad5eba 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -320,6 +320,9 @@ enum {
 	MAX_SR_DMAR_REGS
 };
 
+#define VTD_FLAG_TRANS_PRE_ENABLED	(1 << 0)
+#define VTD_FLAG_IRQ_REMAP_PRE_ENABLED	(1 << 1)
+
 struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
 	u64 		reg_phys; /* physical address of hw register set */
@@ -351,6 +354,7 @@ struct intel_iommu {
 #endif
 	struct device	*iommu_dev; /* IOMMU-sysfs device */
 	int		node;
+	u32		flags;      /* Software defined flags */
 };
 
 static inline void __iommu_flush_cache(

commit 07c09787b26db724c94a912a572a9a4fa66008f3
Author: Feng Wu <feng.wu@intel.com>
Date:   Tue Jun 9 13:20:34 2015 +0800

    iommu, x86: Add cap_pi_support() to detect VT-d PI capability
    
    Add helper function to detect VT-d Posted-Interrupts capability.
    
    Signed-off-by: Feng Wu <feng.wu@intel.com>
    Reviewed-by: Jiang Liu <jiang.liu@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: David Woodhouse <David.Woodhouse@intel.com>
    Acked-by: Joerg Roedel <joro@8bytes.org>
    Cc: iommu@lists.linux-foundation.org
    Cc: dwmw2@infradead.org
    Link: http://lkml.kernel.org/r/1433827237-3382-8-git-send-email-feng.wu@intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 0af9b03e2b1c..0c251be39836 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -87,6 +87,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 /*
  * Decoding Capability Register
  */
+#define cap_pi_support(c)	(((c) >> 59) & 1)
 #define cap_read_drain(c)	(((c) >> 55) & 1)
 #define cap_write_drain(c)	(((c) >> 54) & 1)
 #define cap_max_amask_val(c)	(((c) >> 48) & 0x3f)

commit bd00c606a6f60ca015a62bdbf671eadd48a4ca82
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Tue Jun 9 15:06:55 2015 +0100

    iommu/vt-d: Change PASID support to bit 40 of Extended Capability Register
    
    The existing hardware implementations with PASID support advertised in
    bit 28? Forget them. They do not exist. Bit 28 means nothing. When we
    have something that works, it'll use bit 40. Do not attempt to infer
    anything meaningful from bit 28.
    
    This will be reflected in an updated VT-d spec in the extremely near
    future.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 796ef9645827..a240e61a7700 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -115,13 +115,14 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
  * Extended Capability Register
  */
 
+#define ecap_pasid(e)		((e >> 40) & 0x1)
 #define ecap_pss(e)		((e >> 35) & 0x1f)
 #define ecap_eafs(e)		((e >> 34) & 0x1)
 #define ecap_nwfs(e)		((e >> 33) & 0x1)
 #define ecap_srs(e)		((e >> 31) & 0x1)
 #define ecap_ers(e)		((e >> 30) & 0x1)
 #define ecap_prs(e)		((e >> 29) & 0x1)
-#define ecap_pasid(e)		((e >> 28) & 0x1)
+/* PASID support used to be on bit 28 */
 #define ecap_dis(e)		((e >> 27) & 0x1)
 #define ecap_nest(e)		((e >> 26) & 0x1)
 #define ecap_mts(e)		((e >> 25) & 0x1)

commit 191a66353b22fad8ac89404ab4c929cbe7b0afb2
Merge: f5d6a52f5111 f21262b8e092
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon May 11 16:05:09 2015 +0200

    Merge branch 'x86/asm' into x86/apic, to resolve a conflict
    
    Conflicts:
            arch/x86/kernel/apic/io_apic.c
            arch/x86/kernel/apic/vector.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b106ee63abccbba5f5a52d6e43168a6a30c6d98a
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Apr 13 14:11:32 2015 +0800

    irq_remapping/vt-d: Enhance Intel IR driver to support hierarchical irqdomains
    
    Enhance Intel interrupt remapping driver to support hierarchical
    irqdomains. Implement intel_ir_chip to support stacked irq_chip.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Acked-by: Joerg Roedel <jroedel@suse.de>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Cohen <david.a.cohen@linux.intel.com>
    Cc: Sander Eikelenboom <linux@eikelenboom.it>
    Cc: David Vrabel <david.vrabel@citrix.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: iommu@lists.linux-foundation.org
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rafael J. Wysocki <rjw@rjwysocki.net>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dimitri Sivanich <sivanich@sgi.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Link: http://lkml.kernel.org/r/1428905519-23704-11-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a65208a8fe18..ecaf3a937845 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -286,6 +286,8 @@ struct q_inval {
 
 #define INTR_REMAP_TABLE_ENTRIES	65536
 
+struct irq_domain;
+
 struct ir_table {
 	struct irte *base;
 	unsigned long *bitmap;
@@ -335,6 +337,8 @@ struct intel_iommu {
 
 #ifdef CONFIG_IRQ_REMAP
 	struct ir_table *ir_table;	/* Interrupt remapping info */
+	struct irq_domain *ir_domain;
+	struct irq_domain *ir_msi_domain;
 #endif
 	struct device	*iommu_dev; /* IOMMU-sysfs device */
 	int		node;

commit 4423f5e7d28c26af31df711c5c21eeacfac737b4
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Mar 25 15:43:39 2015 +0000

    iommu/vt-d: Add new extended capabilities from v2.3 VT-d specification
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index ee24ada20428..796ef9645827 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -115,6 +115,17 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
  * Extended Capability Register
  */
 
+#define ecap_pss(e)		((e >> 35) & 0x1f)
+#define ecap_eafs(e)		((e >> 34) & 0x1)
+#define ecap_nwfs(e)		((e >> 33) & 0x1)
+#define ecap_srs(e)		((e >> 31) & 0x1)
+#define ecap_ers(e)		((e >> 30) & 0x1)
+#define ecap_prs(e)		((e >> 29) & 0x1)
+#define ecap_pasid(e)		((e >> 28) & 0x1)
+#define ecap_dis(e)		((e >> 27) & 0x1)
+#define ecap_nest(e)		((e >> 26) & 0x1)
+#define ecap_mts(e)		((e >> 25) & 0x1)
+#define ecap_ecs(e)		((e >> 24) & 0x1)
 #define ecap_iotlb_offset(e) 	((((e) >> 8) & 0x3ff) * 16)
 #define ecap_max_iotlb_offset(e) (ecap_iotlb_offset(e) + 16)
 #define ecap_coherent(e)	((e) & 0x1)
@@ -178,6 +189,9 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define DMA_GSTS_IRES (((u32)1) << 25)
 #define DMA_GSTS_CFIS (((u32)1) << 23)
 
+/* DMA_RTADDR_REG */
+#define DMA_RTADDR_RTT (((u64)1) << 11)
+
 /* CCMD_REG */
 #define DMA_CCMD_ICC (((u64)1) << 63)
 #define DMA_CCMD_GLOBAL_INVL (((u64)1) << 61)

commit 44caf2f37f009b2affa743073fa935826b6ab2fd
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Fri Feb 13 14:25:24 2015 +0000

    iommu/vt-d: kill bogus ecap_niotlb_iunits()
    
    As far back as I can see (which right now is a draft of the v1.2 spec
    dating from September 2008), bits 24-31 of the Extended Capability Register
    have already been reserved. I have no idea why anyone ever thought there
    would be multiple sets of IOTLB registers, but we've never supported them
    and all we do is make sure we map enough MMIO space for them.
    
    Kill it dead. Those bits do actually have a different meaning now.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a65208a8fe18..ee24ada20428 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -115,10 +115,8 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
  * Extended Capability Register
  */
 
-#define ecap_niotlb_iunits(e)	((((e) >> 24) & 0xff) + 1)
 #define ecap_iotlb_offset(e) 	((((e) >> 8) & 0x3ff) * 16)
-#define ecap_max_iotlb_offset(e) \
-	(ecap_iotlb_offset(e) + ecap_niotlb_iunits(e) * 16)
+#define ecap_max_iotlb_offset(e) (ecap_iotlb_offset(e) + 16)
 #define ecap_coherent(e)	((e) & 0x1)
 #define ecap_qis(e)		((e) & 0x2)
 #define ecap_pass_through(e)	((e >> 6) & 0x1)

commit a5459cfece880e82778a60e6290ad6c0dd688a06
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Thu Jun 12 16:12:31 2014 -0600

    iommu/vt-d: Make use of IOMMU sysfs support
    
    Register our DRHD IOMMUs, cross link devices, and provide a base set
    of attributes for the IOMMU.  Note that IRQ remapping support parses
    the DMAR table very early in boot, well before the iommu_class can
    reasonably be setup, so our registration is split between
    intel_iommu_init(), which occurs later, and alloc_iommu(), which
    typically occurs much earlier, but may happen at any time later
    with IOMMU hot-add support.
    
    On a typical desktop system, this provides the following (pruned):
    
    $ find /sys | grep dmar
    /sys/devices/virtual/iommu/dmar0
    /sys/devices/virtual/iommu/dmar0/devices
    /sys/devices/virtual/iommu/dmar0/devices/0000:00:02.0
    /sys/devices/virtual/iommu/dmar0/intel-iommu
    /sys/devices/virtual/iommu/dmar0/intel-iommu/cap
    /sys/devices/virtual/iommu/dmar0/intel-iommu/ecap
    /sys/devices/virtual/iommu/dmar0/intel-iommu/address
    /sys/devices/virtual/iommu/dmar0/intel-iommu/version
    /sys/devices/virtual/iommu/dmar1
    /sys/devices/virtual/iommu/dmar1/devices
    /sys/devices/virtual/iommu/dmar1/devices/0000:00:00.0
    /sys/devices/virtual/iommu/dmar1/devices/0000:00:01.0
    /sys/devices/virtual/iommu/dmar1/devices/0000:00:16.0
    /sys/devices/virtual/iommu/dmar1/devices/0000:00:1a.0
    /sys/devices/virtual/iommu/dmar1/devices/0000:00:1b.0
    /sys/devices/virtual/iommu/dmar1/devices/0000:00:1c.0
    ...
    /sys/devices/virtual/iommu/dmar1/intel-iommu
    /sys/devices/virtual/iommu/dmar1/intel-iommu/cap
    /sys/devices/virtual/iommu/dmar1/intel-iommu/ecap
    /sys/devices/virtual/iommu/dmar1/intel-iommu/address
    /sys/devices/virtual/iommu/dmar1/intel-iommu/version
    /sys/class/iommu/dmar0
    /sys/class/iommu/dmar1
    
    (devices also link back to the dmar units)
    
    This makes address, version, capabilities, and extended capabilities
    available, just like printed on boot.  I've tried not to duplicate
    data that can be found in the DMAR table, with the exception of the
    address, which provides an easy way to associate the sysfs device with
    a DRHD entry in the DMAR.  It's tempting to add scopes and RMRR data
    here, but the full DMAR table is already exposed under /sys/firmware/
    and therefore already provides a way for userspace to learn such
    details.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 0a2da5188217..a65208a8fe18 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -336,6 +336,7 @@ struct intel_iommu {
 #ifdef CONFIG_IRQ_REMAP
 	struct ir_table *ir_table;	/* Interrupt remapping info */
 #endif
+	struct device	*iommu_dev; /* IOMMU-sysfs device */
 	int		node;
 };
 
@@ -365,4 +366,6 @@ extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);
 
+extern const struct attribute_group *intel_iommu_groups[];
+
 #endif

commit 67ccac41fafda88492620f4c0a30d4ccb2eb7767
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Sun Mar 9 13:49:45 2014 -0700

    iommu/vt-d: Store PCI segment number in struct intel_iommu
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 2c4bed593b32..0a2da5188217 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -319,6 +319,7 @@ struct intel_iommu {
 	int		agaw; /* agaw of this iommu */
 	int		msagaw; /* max sagaw of this iommu */
 	unsigned int 	irq;
+	u16		segment;     /* PCI segment# */
 	unsigned char 	name[13];    /* Device Name */
 
 #ifdef CONFIG_INTEL_IOMMU

commit a868e6b7b661c3d3e7e681a16d0b205971987c99
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jan 6 14:18:20 2014 +0800

    iommu/vt-d: keep shared resources when failed to initialize iommu devices
    
    Data structure drhd->iommu is shared between DMA remapping driver and
    interrupt remapping driver, so DMA remapping driver shouldn't release
    drhd->iommu when it failed to initialize IOMMU devices. Otherwise it
    may cause invalid memory access to the interrupt remapping driver.
    
    Sample stack dump:
    [   13.315090] BUG: unable to handle kernel paging request at ffffc9000605a088
    [   13.323221] IP: [<ffffffff81461bac>] qi_submit_sync+0x15c/0x400
    [   13.330107] PGD 82f81e067 PUD c2f81e067 PMD 82e846067 PTE 0
    [   13.336818] Oops: 0002 [#1] SMP
    [   13.340757] Modules linked in:
    [   13.344422] CPU: 0 PID: 4 Comm: kworker/0:0 Not tainted 3.13.0-rc1-gerry+ #7
    [   13.352474] Hardware name: Intel Corporation LH Pass ........../SVRBD-ROW_T,                                               BIOS SE5C600.86B.99.99.x059.091020121352 09/10/2012
    [   13.365659] Workqueue: events work_for_cpu_fn
    [   13.370774] task: ffff88042ddf00d0 ti: ffff88042ddee000 task.ti: ffff88042dde                                              e000
    [   13.379389] RIP: 0010:[<ffffffff81461bac>]  [<ffffffff81461bac>] qi_submit_sy                                              nc+0x15c/0x400
    [   13.389055] RSP: 0000:ffff88042ddef940  EFLAGS: 00010002
    [   13.395151] RAX: 00000000000005e0 RBX: 0000000000000082 RCX: 0000000200000025
    [   13.403308] RDX: ffffc9000605a000 RSI: 0000000000000010 RDI: ffff88042ddb8610
    [   13.411446] RBP: ffff88042ddef9a0 R08: 00000000000005d0 R09: 0000000000000001
    [   13.419599] R10: 0000000000000000 R11: 000000000000005d R12: 000000000000005c
    [   13.427742] R13: ffff88102d84d300 R14: 0000000000000174 R15: ffff88042ddb4800
    [   13.435877] FS:  0000000000000000(0000) GS:ffff88043de00000(0000) knlGS:00000                                              00000000000
    [   13.445168] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   13.451749] CR2: ffffc9000605a088 CR3: 0000000001a0b000 CR4: 00000000000407f0
    [   13.459895] Stack:
    [   13.462297]  ffff88042ddb85d0 000000000000005d ffff88042ddef9b0 0000000000000                                              5d0
    [   13.471147]  00000000000005c0 ffff88042ddb8000 000000000000005c 0000000000000                                              015
    [   13.480001]  ffff88042ddb4800 0000000000000282 ffff88042ddefa40 ffff88042ddef                                              ac0
    [   13.488855] Call Trace:
    [   13.491771]  [<ffffffff8146848d>] modify_irte+0x9d/0xd0
    [   13.497778]  [<ffffffff8146886d>] intel_setup_ioapic_entry+0x10d/0x290
    [   13.505250]  [<ffffffff810a92a6>] ? trace_hardirqs_on_caller+0x16/0x1e0
    [   13.512824]  [<ffffffff810346b0>] ? default_init_apic_ldr+0x60/0x60
    [   13.519998]  [<ffffffff81468be0>] setup_ioapic_remapped_entry+0x20/0x30
    [   13.527566]  [<ffffffff8103683a>] io_apic_setup_irq_pin+0x12a/0x2c0
    [   13.534742]  [<ffffffff8136673b>] ? acpi_pci_irq_find_prt_entry+0x2b9/0x2d8
    [   13.544102]  [<ffffffff81037fd5>] io_apic_setup_irq_pin_once+0x85/0xa0
    [   13.551568]  [<ffffffff8103816f>] ? mp_find_ioapic_pin+0x8f/0xf0
    [   13.558434]  [<ffffffff81038044>] io_apic_set_pci_routing+0x34/0x70
    [   13.565621]  [<ffffffff8102f4cf>] mp_register_gsi+0xaf/0x1c0
    [   13.572111]  [<ffffffff8102f5ee>] acpi_register_gsi_ioapic+0xe/0x10
    [   13.579286]  [<ffffffff8102f33f>] acpi_register_gsi+0xf/0x20
    [   13.585779]  [<ffffffff81366b86>] acpi_pci_irq_enable+0x171/0x1e3
    [   13.592764]  [<ffffffff8146d771>] pcibios_enable_device+0x31/0x40
    [   13.599744]  [<ffffffff81320e9b>] do_pci_enable_device+0x3b/0x60
    [   13.606633]  [<ffffffff81322248>] pci_enable_device_flags+0xc8/0x120
    [   13.613887]  [<ffffffff813222f3>] pci_enable_device+0x13/0x20
    [   13.620484]  [<ffffffff8132fa7e>] pcie_port_device_register+0x1e/0x510
    [   13.627947]  [<ffffffff810a92a6>] ? trace_hardirqs_on_caller+0x16/0x1e0
    [   13.635510]  [<ffffffff810a947d>] ? trace_hardirqs_on+0xd/0x10
    [   13.642189]  [<ffffffff813302b8>] pcie_portdrv_probe+0x58/0xc0
    [   13.648877]  [<ffffffff81323ba5>] local_pci_probe+0x45/0xa0
    [   13.655266]  [<ffffffff8106bc44>] work_for_cpu_fn+0x14/0x20
    [   13.661656]  [<ffffffff8106fa79>] process_one_work+0x369/0x710
    [   13.668334]  [<ffffffff8106fa02>] ? process_one_work+0x2f2/0x710
    [   13.675215]  [<ffffffff81071d56>] ? worker_thread+0x46/0x690
    [   13.681714]  [<ffffffff81072194>] worker_thread+0x484/0x690
    [   13.688109]  [<ffffffff81071d10>] ? cancel_delayed_work_sync+0x20/0x20
    [   13.695576]  [<ffffffff81079c60>] kthread+0xf0/0x110
    [   13.701300]  [<ffffffff8108e7bf>] ? local_clock+0x3f/0x50
    [   13.707492]  [<ffffffff81079b70>] ? kthread_create_on_node+0x250/0x250
    [   13.714959]  [<ffffffff81574d2c>] ret_from_fork+0x7c/0xb0
    [   13.721152]  [<ffffffff81079b70>] ? kthread_create_on_node+0x250/0x250
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index f2c4114b8665..2c4bed593b32 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -348,7 +348,6 @@ static inline void __iommu_flush_cache(
 extern struct dmar_drhd_unit * dmar_find_matched_drhd_unit(struct pci_dev *dev);
 extern int dmar_find_matched_atsr_unit(struct pci_dev *dev);
 
-extern void free_iommu(struct intel_iommu *iommu);
 extern int dmar_enable_qi(struct intel_iommu *iommu);
 extern void dmar_disable_qi(struct intel_iommu *iommu);
 extern int dmar_reenable_qi(struct intel_iommu *iommu);

commit 694835dc227ad203886457aa447025d09b2f7523
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jan 6 14:18:16 2014 +0800

    iommu/vt-d: mark internal functions as static
    
    Functions alloc_iommu() and parse_ioapics_under_ir()
    are only used internally, so mark them as static.
    
    [Joerg: Made detect_intel_iommu() non-static again for IA64]
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index de1e5e936420..f2c4114b8665 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -348,7 +348,6 @@ static inline void __iommu_flush_cache(
 extern struct dmar_drhd_unit * dmar_find_matched_drhd_unit(struct pci_dev *dev);
 extern int dmar_find_matched_atsr_unit(struct pci_dev *dev);
 
-extern int alloc_iommu(struct dmar_drhd_unit *drhd);
 extern void free_iommu(struct intel_iommu *iommu);
 extern int dmar_enable_qi(struct intel_iommu *iommu);
 extern void dmar_disable_qi(struct intel_iommu *iommu);

commit 360eb3c5687e2df23e29e97878238765bfe6a756
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jan 6 14:18:08 2014 +0800

    iommu/vt-d: use dedicated bitmap to track remapping entry allocation status
    
    Currently Intel interrupt remapping drivers uses the "present" flag bit
    in remapping entry to track whether an entry is allocated or not.
    It works as follow:
    1) allocate a remapping entry and set its "present" flag bit to 1
    2) compose other fields for the entry
    3) update the remapping entry with the composed value
    
    The remapping hardware may access the entry between step 1 and step 3,
    which then observers an entry with the "present" flag set but random
    values in all other fields.
    
    This patch introduces a dedicated bitmap to track remapping entry
    allocation status instead of sharing the "present" flag with hardware,
    thus eliminate the race window. It also simplifies the implementation.
    
    Tested-and-reviewed-by: Yijing Wang <wangyijing@huawei.com>
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index d380c5e68008..de1e5e936420 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -288,6 +288,7 @@ struct q_inval {
 
 struct ir_table {
 	struct irte *base;
+	unsigned long *bitmap;
 };
 #endif
 

commit 82aeef0bf03684b377678c00c05e613f30dca39c
Author: Li, Zhen-Hua <zhen-hual@hp.com>
Date:   Fri Sep 13 14:27:32 2013 +0800

    x86/iommu: correct ICS register offset
    
    According to Intel Vt-D specs, the offset of Invalidation complete
    status register should be 0x9C, not 0x98.
    
    See Intel's VT-d spec, Revision 1.3, Chapter 10.4, Page 98;
    
    Signed-off-by: Li, Zhen-Hua <zhen-hual@hp.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 78e2ada50cd5..d380c5e68008 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -55,7 +55,7 @@
 #define DMAR_IQT_REG	0x88	/* Invalidation queue tail register */
 #define DMAR_IQ_SHIFT	4	/* Invalidation queue head/tail shift */
 #define DMAR_IQA_REG	0x90	/* Invalidation queue addr register */
-#define DMAR_ICS_REG	0x98	/* Invalidation complete status register */
+#define DMAR_ICS_REG	0x9c	/* Invalidation complete status register */
 #define DMAR_IRTA_REG	0xb8    /* Interrupt remapping table addr register */
 
 #define OFFSET_STRIDE		(9)

commit 6f5cf52114dd87f9ed091678f7dfc8ff21bbe2b3
Author: Donald Dutile <ddutile@redhat.com>
Date:   Mon Jun 4 17:29:02 2012 -0400

    iommu/dmar: Reserve mmio space used by the IOMMU, if the BIOS forgets to
    
    Intel-iommu initialization doesn't currently reserve the memory
    used for the IOMMU registers. This can allow the pci resource
    allocator to assign a device BAR to the same address as the
    IOMMU registers. This can cause some not so nice side affects
    when the driver ioremap's that region.
    
    Introduced two helper functions to map & unmap the IOMMU
    registers as well as simplify the init and exit paths.
    
    Signed-off-by: Donald Dutile <ddutile@redhat.com>
    Acked-by: Chris Wright <chrisw@redhat.com>
    Cc: iommu@lists.linux-foundation.org
    Cc: suresh.b.siddha@intel.com
    Cc: dwmw2@infradead.org
    Link: http://lkml.kernel.org/r/1338845342-12464-3-git-send-email-ddutile@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index e6ca56de9936..78e2ada50cd5 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -308,6 +308,8 @@ enum {
 
 struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
+	u64 		reg_phys; /* physical address of hw register set */
+	u64		reg_size; /* size of hw register set */
 	u64		cap;
 	u64		ecap;
 	u32		gcmd; /* Holds TE, EAFL. Don't need SRTP, SFL, WBF */

commit 3cfef9524677a4ecb392d6fbffe6ebce6302f1d4
Merge: 982653009b88 68cc3990a545
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 26 16:17:32 2011 +0200

    Merge branch 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (27 commits)
      rtmutex: Add missing rcu_read_unlock() in debug_rt_mutex_print_deadlock()
      lockdep: Comment all warnings
      lib: atomic64: Change the type of local lock to raw_spinlock_t
      locking, lib/atomic64: Annotate atomic64_lock::lock as raw
      locking, x86, iommu: Annotate qi->q_lock as raw
      locking, x86, iommu: Annotate irq_2_ir_lock as raw
      locking, x86, iommu: Annotate iommu->register_lock as raw
      locking, dma, ipu: Annotate bank_lock as raw
      locking, ARM: Annotate low level hw locks as raw
      locking, drivers/dca: Annotate dca_lock as raw
      locking, powerpc: Annotate uic->lock as raw
      locking, x86: mce: Annotate cmci_discover_lock as raw
      locking, ACPI: Annotate c3_lock as raw
      locking, oprofile: Annotate oprofilefs lock as raw
      locking, video: Annotate vga console lock as raw
      locking, latencytop: Annotate latency_lock as raw
      locking, timer_stats: Annotate table_lock as raw
      locking, rwsem: Annotate inner lock as raw
      locking, semaphores: Annotate inner lock as raw
      locking, sched: Annotate thread_group_cputimer as raw
      ...
    
    Fix up conflicts in kernel/posix-cpu-timers.c manually: making
    cputimer->cputime a raw lock conflicted with the ABBA fix in commit
    bcd5cff7216f ("cputimer: Cure lock inversion").

commit d3f138106b4b40640dc667f0222fd9f137387b32
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Tue Aug 23 17:05:25 2011 -0700

    iommu: Rename the DMAR and INTR_REMAP config options
    
    Change the CONFIG_DMAR to CONFIG_INTEL_IOMMU to be consistent
    with the other IOMMU options.
    
    Rename the CONFIG_INTR_REMAP to CONFIG_IRQ_REMAP to match the
    irq subsystem name.
    
    And define the CONFIG_DMAR_TABLE for the common ACPI DMAR
    routines shared by both CONFIG_INTEL_IOMMU and CONFIG_IRQ_REMAP.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: yinghai@kernel.org
    Cc: youquan.song@intel.com
    Cc: joerg.roedel@amd.com
    Cc: tony.luck@intel.com
    Cc: dwmw2@infradead.org
    Link: http://lkml.kernel.org/r/20110824001456.558630224@sbsiddha-desk.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 9310c699a37d..235b8879af45 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -279,7 +279,7 @@ struct q_inval {
 	int             free_cnt;
 };
 
-#ifdef CONFIG_INTR_REMAP
+#ifdef CONFIG_IRQ_REMAP
 /* 1MB - maximum possible interrupt remapping table size */
 #define INTR_REMAP_PAGE_ORDER	8
 #define INTR_REMAP_TABLE_REG_SIZE	0xf
@@ -318,7 +318,7 @@ struct intel_iommu {
 	unsigned int 	irq;
 	unsigned char 	name[13];    /* Device Name */
 
-#ifdef CONFIG_DMAR
+#ifdef CONFIG_INTEL_IOMMU
 	unsigned long 	*domain_ids; /* bitmap of domains */
 	struct dmar_domain **domains; /* ptr to domains */
 	spinlock_t	lock; /* protect context, domain ids */
@@ -329,7 +329,7 @@ struct intel_iommu {
 	struct q_inval  *qi;            /* Queued invalidation info */
 	u32 *iommu_state; /* Store iommu states between suspend and resume.*/
 
-#ifdef CONFIG_INTR_REMAP
+#ifdef CONFIG_IRQ_REMAP
 	struct ir_table *ir_table;	/* Interrupt remapping info */
 #endif
 	int		node;

commit 3b8f40481513a7b6123def5a02db4cff96ae2198
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 19 17:02:07 2011 +0200

    locking, x86, iommu: Annotate qi->q_lock as raw
    
    The qi->q_lock lock can be taken in atomic context and therefore
    cannot be preempted on -rt - annotate it.
    
    In mainline this change documents the low level nature of
    the lock - otherwise there's no functional difference. Lockdep
    and Sparse checking will work as usual.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 19728c462399..8b9b5d365f4e 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -271,7 +271,7 @@ struct qi_desc {
 };
 
 struct q_inval {
-	spinlock_t      q_lock;
+	raw_spinlock_t  q_lock;
 	struct qi_desc  *desc;          /* invalidation queue */
 	int             *desc_status;   /* desc status */
 	int             free_head;      /* first free entry */

commit 1f5b3c3fd2d73d6b30e9ef6dcbf131a791d5cbbd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 19 16:19:51 2011 +0200

    locking, x86, iommu: Annotate iommu->register_lock as raw
    
    The iommu->register_lock can be taken in atomic context and therefore
    must not be preempted on -rt - annotate it.
    
    In mainline this change documents the low level nature of
    the lock - otherwise there's no functional difference. Lockdep
    and Sparse checking will work as usual.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 9310c699a37d..19728c462399 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -311,7 +311,7 @@ struct intel_iommu {
 	u64		cap;
 	u64		ecap;
 	u32		gcmd; /* Holds TE, EAFL. Don't need SRTP, SFL, WBF */
-	spinlock_t	register_lock; /* protect register handling */
+	raw_spinlock_t	register_lock; /* protect register handling */
 	int		seq_id;	/* sequence id of the iommu */
 	int		agaw; /* agaw of this iommu */
 	int		msagaw; /* max sagaw of this iommu */

commit ee34b32d8c2950f66038c8975747ef9aec855289
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Fri Oct 2 11:01:21 2009 -0700

    dmar: support for parsing Remapping Hardware Static Affinity structure
    
    Add support for parsing Remapping Hardware Static Affinity (RHSA) structure.
    This enables identifying the association between remapping hardware units and
    the corresponding proximity domain. This enables to allocate transalation
    structures closer to the remapping hardware unit.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 4f0a72a9740c..9310c699a37d 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -332,6 +332,7 @@ struct intel_iommu {
 #ifdef CONFIG_INTR_REMAP
 	struct ir_table *ir_table;	/* Interrupt remapping info */
 #endif
+	int		node;
 };
 
 static inline void __iommu_flush_cache(

commit 074835f0143b83845af5044af2739c52c9f53808
Author: Youquan Song <youquan.song@intel.com>
Date:   Wed Sep 9 12:05:39 2009 -0400

    intel-iommu: Fix kernel hang if interrupt remapping disabled in BIOS
    
    BIOS clear DMAR table INTR_REMAP flag to disable interrupt remapping. Current
    kernel only check interrupt remapping(IR) flag in DRHD's extended capability
    register to decide interrupt remapping support or not. But IR flag will not
    change when BIOS disable/enable interrupt remapping.
    
    When user disable interrupt remapping in BIOS or BIOS often defaultly disable
    interrupt remapping feature when BIOS is not mature.Though BIOS disable
    interrupt remapping but intr_remapping_supported function will always report
    to OS support interrupt remapping if VT-d2 chipset populated. On this
    cases, kernel will continue enable interrupt remapping and result kernel panic.
    This bug exist on almost all platforms with interrupt remapping support.
    
    This patch add DMAR table INTR_REMAP flag check before enable interrupt
    remapping.
    
    Signed-off-by: Youquan Song <youquan.song@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 482dc91fd53a..4f0a72a9740c 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -360,4 +360,6 @@ extern void qi_flush_dev_iotlb(struct intel_iommu *iommu, u16 sid, u16 qdep,
 
 extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
+extern int dmar_ir_support(void);
+
 #endif

commit 93a23a7271dfb811b3adb72779054c3a24433112
Author: Yu Zhao <yu.zhao@intel.com>
Date:   Mon May 18 13:51:37 2009 +0800

    VT-d: support the device IOTLB
    
    Enable the device IOTLB (i.e. ATS) for both the bare metal and KVM
    environments.
    
    Signed-off-by: Yu Zhao <yu.zhao@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 40561b224a17..482dc91fd53a 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -124,6 +124,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define ecap_pass_through(e)	((e >> 6) & 0x1)
 #define ecap_eim_support(e)	((e >> 4) & 0x1)
 #define ecap_ir_support(e)	((e >> 3) & 0x1)
+#define ecap_dev_iotlb_support(e)	(((e) >> 2) & 0x1)
 #define ecap_max_handle_mask(e) ((e >> 20) & 0xf)
 #define ecap_sc_support(e)	((e >> 7) & 0x1) /* Snooping Control */
 

commit 6ba6c3a4cacfd68bf970e3e04e2ff0d66fa0f695
Author: Yu Zhao <yu.zhao@intel.com>
Date:   Mon May 18 13:51:35 2009 +0800

    VT-d: add device IOTLB invalidation support
    
    Support device IOTLB invalidation to flush the translation cached
    in the Endpoint.
    
    Signed-off-by: Yu Zhao <yu.zhao@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 0a1939f200fc..40561b224a17 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -53,6 +53,7 @@
 #define	DMAR_PHMLIMIT_REG 0x78	/* pmrr high limit */
 #define DMAR_IQH_REG	0x80	/* Invalidation queue head register */
 #define DMAR_IQT_REG	0x88	/* Invalidation queue tail register */
+#define DMAR_IQ_SHIFT	4	/* Invalidation queue head/tail shift */
 #define DMAR_IQA_REG	0x90	/* Invalidation queue addr register */
 #define DMAR_ICS_REG	0x98	/* Invalidation complete status register */
 #define DMAR_IRTA_REG	0xb8    /* Interrupt remapping table addr register */
@@ -198,6 +199,8 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define DMA_FSTS_PPF ((u32)2)
 #define DMA_FSTS_PFO ((u32)1)
 #define DMA_FSTS_IQE (1 << 4)
+#define DMA_FSTS_ICE (1 << 5)
+#define DMA_FSTS_ITE (1 << 6)
 #define dma_fsts_fault_record_index(s) (((s) >> 8) & 0xff)
 
 /* FRCD_REG, 32 bits access */
@@ -226,7 +229,8 @@ do {									\
 enum {
 	QI_FREE,
 	QI_IN_USE,
-	QI_DONE
+	QI_DONE,
+	QI_ABORT
 };
 
 #define QI_CC_TYPE		0x1
@@ -255,6 +259,12 @@ enum {
 #define QI_CC_DID(did)		(((u64)did) << 16)
 #define QI_CC_GRAN(gran)	(((u64)gran) >> (DMA_CCMD_INVL_GRANU_OFFSET-4))
 
+#define QI_DEV_IOTLB_SID(sid)	((u64)((sid) & 0xffff) << 32)
+#define QI_DEV_IOTLB_QDEP(qdep)	(((qdep) & 0x1f) << 16)
+#define QI_DEV_IOTLB_ADDR(addr)	((u64)(addr) & VTD_PAGE_MASK)
+#define QI_DEV_IOTLB_SIZE	1
+#define QI_DEV_IOTLB_MAX_INVS	32
+
 struct qi_desc {
 	u64 low, high;
 };
@@ -344,6 +354,8 @@ extern void qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,
 			     u8 fm, u64 type);
 extern void qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 			  unsigned int size_order, u64 type);
+extern void qi_flush_dev_iotlb(struct intel_iommu *iommu, u16 sid, u16 qdep,
+			       u64 addr, unsigned mask);
 
 extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 

commit aa5d2b515b6fca5f8a56eac84f7fa0a68c1ce9b7
Author: Yu Zhao <yu.zhao@intel.com>
Date:   Mon May 18 13:51:34 2009 +0800

    VT-d: parse ATSR in DMA Remapping Reporting Structure
    
    Parse the Root Port ATS Capability Reporting Structure in the DMA
    Remapping Reporting Structure ACPI table.
    
    Signed-off-by: Yu Zhao <yu.zhao@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 29e05a034c09..0a1939f200fc 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -331,6 +331,7 @@ static inline void __iommu_flush_cache(
 }
 
 extern struct dmar_drhd_unit * dmar_find_matched_drhd_unit(struct pci_dev *dev);
+extern int dmar_find_matched_atsr_unit(struct pci_dev *dev);
 
 extern int alloc_iommu(struct dmar_drhd_unit *drhd);
 extern void free_iommu(struct intel_iommu *iommu);

commit 1f0ef2aa18802a8ce7eb5a5164aaaf4d59073801
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Sun May 10 19:58:49 2009 +0100

    intel-iommu: Clean up handling of "caching mode" vs. IOTLB flushing.
    
    As we just did for context cache flushing, clean up the logic around
    whether we need to flush the iotlb or just the write-buffer, depending
    on caching mode.
    
    Fix the same bug in qi_flush_iotlb() that qi_flush_context() had -- it
    isn't supposed to be returning an error; it's supposed to be returning a
    flag which triggers a write-buffer flush.
    
    Remove some superfluous conditional write-buffer flushes which could
    never have happened because they weren't for non-present-to-present
    mapping changes anyway.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index f2b94dafbf38..29e05a034c09 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -283,8 +283,8 @@ struct ir_table {
 struct iommu_flush {
 	void (*flush_context)(struct intel_iommu *iommu, u16 did, u16 sid,
 			      u8 fm, u64 type);
-	int (*flush_iotlb)(struct intel_iommu *iommu, u16 did, u64 addr,
-		unsigned int size_order, u64 type, int non_present_entry_flush);
+	void (*flush_iotlb)(struct intel_iommu *iommu, u16 did, u64 addr,
+			    unsigned int size_order, u64 type);
 };
 
 enum {
@@ -341,9 +341,8 @@ extern void qi_global_iec(struct intel_iommu *iommu);
 
 extern void qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,
 			     u8 fm, u64 type);
-extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
-			  unsigned int size_order, u64 type,
-			  int non_present_entry_flush);
+extern void qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
+			  unsigned int size_order, u64 type);
 
 extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 

commit 4c25a2c1b90bf785fc2e2f0f0c74a80b3e070d39
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Sun May 10 17:16:06 2009 +0100

    intel-iommu: Clean up handling of "caching mode" vs. context flushing.
    
    It really doesn't make a lot of sense to have some of the logic to
    handle caching vs. non-caching mode duplicated in qi_flush_context() and
    __iommu_flush_context(), while the return value indicates whether the
    caller should take other action which depends on the same thing.
    
    Especially since qi_flush_context() thought it was returning something
    entirely different anyway.
    
    This patch makes qi_flush_context() and __iommu_flush_context() both
    return void, removes the 'non_present_entry_flush' argument and makes
    the only call site which _set_ that argument to 1 do the right thing.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 7246971a7feb..f2b94dafbf38 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -281,8 +281,8 @@ struct ir_table {
 #endif
 
 struct iommu_flush {
-	int (*flush_context)(struct intel_iommu *iommu, u16 did, u16 sid, u8 fm,
-		u64 type, int non_present_entry_flush);
+	void (*flush_context)(struct intel_iommu *iommu, u16 did, u16 sid,
+			      u8 fm, u64 type);
 	int (*flush_iotlb)(struct intel_iommu *iommu, u16 did, u64 addr,
 		unsigned int size_order, u64 type, int non_present_entry_flush);
 };
@@ -339,8 +339,8 @@ extern void dmar_disable_qi(struct intel_iommu *iommu);
 extern int dmar_reenable_qi(struct intel_iommu *iommu);
 extern void qi_global_iec(struct intel_iommu *iommu);
 
-extern int qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,
-			        u8 fm, u64 type, int non_present_entry_flush);
+extern void qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,
+			     u8 fm, u64 type);
 extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 			  unsigned int size_order, u64 type,
 			  int non_present_entry_flush);

commit 4ed0d3e6c64cfd9ba4ceb2099b10d1cf8ece4320
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Fri Apr 24 17:30:20 2009 -0700

    Intel IOMMU Pass Through Support
    
    The patch adds kernel parameter intel_iommu=pt to set up pass through
    mode in context mapping entry. This disables DMAR in linux kernel; but
    KVM still runs on VT-d and interrupt remapping still works.
    
    In this mode, kernel uses swiotlb for DMA API functions but other VT-d
    functionalities are enabled for KVM. KVM always uses multi level
    translation page table in VT-d. By default, pass though mode is disabled
    in kernel.
    
    This is useful when people don't want to enable VT-d DMAR in kernel but
    still want to use KVM and interrupt remapping for reasons like DMAR
    performance concern or debug purpose.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Acked-by: Weidong Han <weidong@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index aa8c53171233..7246971a7feb 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -120,6 +120,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 	(ecap_iotlb_offset(e) + ecap_niotlb_iunits(e) * 16)
 #define ecap_coherent(e)	((e) & 0x1)
 #define ecap_qis(e)		((e) & 0x2)
+#define ecap_pass_through(e)	((e >> 6) & 0x1)
 #define ecap_eim_support(e)	((e >> 4) & 0x1)
 #define ecap_ir_support(e)	((e >> 3) & 0x1)
 #define ecap_max_handle_mask(e) ((e >> 20) & 0xf)
@@ -302,6 +303,7 @@ struct intel_iommu {
 	spinlock_t	register_lock; /* protect register handling */
 	int		seq_id;	/* sequence id of the iommu */
 	int		agaw; /* agaw of this iommu */
+	int		msagaw; /* max sagaw of this iommu */
 	unsigned int 	irq;
 	unsigned char 	name[13];    /* Device Name */
 

commit 161fde083f3403e7aa178dc944bf43c339e18491
Author: Han, Weidong <weidong.han@intel.com>
Date:   Fri Apr 3 17:15:47 2009 +0800

    intel-iommu: set compatibility format interrupt
    
    When extended interrupt mode (x2apic mode) is not supported in a
    system, it must set compatibility format interrupt to bypass
    interrupt remapping, otherwise compatibility format interrupts
    will be blocked.
    
    This will be used when interrupt remapping is enabled while x2apic
    is not supported.
    
    Signed-off-by: Weidong Han <weidong.han@intel.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 3771cd1f876e..aa8c53171233 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -164,6 +164,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define DMA_GCMD_QIE (((u32)1) << 26)
 #define DMA_GCMD_SIRTP (((u32)1) << 24)
 #define DMA_GCMD_IRE (((u32) 1) << 25)
+#define DMA_GCMD_CFI (((u32) 1) << 23)
 
 /* GSTS_REG */
 #define DMA_GSTS_TES (((u32)1) << 31)
@@ -174,6 +175,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define DMA_GSTS_QIES (((u32)1) << 26)
 #define DMA_GSTS_IRTPS (((u32)1) << 24)
 #define DMA_GSTS_IRES (((u32)1) << 25)
+#define DMA_GSTS_CFIS (((u32)1) << 23)
 
 /* CCMD_REG */
 #define DMA_CCMD_ICC (((u64)1) << 63)

commit f59c7b69bcba31cd355ababe067202b9895d6102
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Fri Mar 27 14:22:42 2009 -0700

    Intel IOMMU Suspend/Resume Support - DMAR
    
    This patch implements the suspend and resume feature for Intel IOMMU
    DMAR. It hooks to kernel suspend and resume interface. When suspend happens, it
    saves necessary hardware registers. When resume happens, it restores the
    registers and restarts IOMMU by enabling translation, setting up root entry, and
    re-enabling queued invalidation.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 77214ead1a36..3771cd1f876e 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -284,6 +284,14 @@ struct iommu_flush {
 		unsigned int size_order, u64 type, int non_present_entry_flush);
 };
 
+enum {
+	SR_DMAR_FECTL_REG,
+	SR_DMAR_FEDATA_REG,
+	SR_DMAR_FEADDR_REG,
+	SR_DMAR_FEUADDR_REG,
+	MAX_SR_DMAR_REGS
+};
+
 struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
 	u64		cap;
@@ -304,6 +312,8 @@ struct intel_iommu {
 	struct iommu_flush flush;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
+	u32 *iommu_state; /* Store iommu states between suspend and resume.*/
+
 #ifdef CONFIG_INTR_REMAP
 	struct ir_table *ir_table;	/* Interrupt remapping info */
 #endif
@@ -322,6 +332,7 @@ extern int alloc_iommu(struct dmar_drhd_unit *drhd);
 extern void free_iommu(struct intel_iommu *iommu);
 extern int dmar_enable_qi(struct intel_iommu *iommu);
 extern void dmar_disable_qi(struct intel_iommu *iommu);
+extern int dmar_reenable_qi(struct intel_iommu *iommu);
 extern void qi_global_iec(struct intel_iommu *iommu);
 
 extern int qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,

commit ca1ee219c070eab755712d50638bbcd1f8630fc1
Merge: 3cc50ac0dbda afeeb7cebbd2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 3 10:36:57 2009 -0700

    Merge git://git.infradead.org/iommu-2.6
    
    * git://git.infradead.org/iommu-2.6:
      intel-iommu: Fix address wrap on 32-bit kernel.
      intel-iommu: Enable DMAR on 32-bit kernel.
      intel-iommu: fix PCI device detach from virtual machine
      intel-iommu: VT-d page table to support snooping control bit
      iommu: Add domain_has_cap iommu_ops
      intel-iommu: Snooping control support
    
    Fixed trivial conflicts in arch/x86/Kconfig and drivers/pci/intel-iommu.c

commit 712b0006bf3a9ed0b14a56c3291975e582127766
Merge: e1c502482853 b0d44c0dbbd5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 30 13:41:00 2009 -0700

    Merge branch 'iommu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'iommu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (60 commits)
      dma-debug: make memory range checks more consistent
      dma-debug: warn of unmapping an invalid dma address
      dma-debug: fix dma_debug_add_bus() definition for !CONFIG_DMA_API_DEBUG
      dma-debug/x86: register pci bus for dma-debug leak detection
      dma-debug: add a check dma memory leaks
      dma-debug: add checks for kernel text and rodata
      dma-debug: print stacktrace of mapping path on unmap error
      dma-debug: Documentation update
      dma-debug: x86 architecture bindings
      dma-debug: add function to dump dma mappings
      dma-debug: add checks for sync_single_sg_*
      dma-debug: add checks for sync_single_range_*
      dma-debug: add checks for sync_single_*
      dma-debug: add checking for [alloc|free]_coherent
      dma-debug: add add checking for map/unmap_sg
      dma-debug: add checking for map/unmap_page/single
      dma-debug: add core checking functions
      dma-debug: add debugfs interface
      dma-debug: add kernel command line parameters
      dma-debug: add initialization code
      ...
    
    Fix trivial conflicts due to whitespace changes in arch/x86/kernel/pci-nommu.c

commit 58c610bd1a3f50820e45a7c09ec0e44d2cda15dd
Author: Sheng Yang <sheng@linux.intel.com>
Date:   Wed Mar 18 15:33:05 2009 +0800

    intel-iommu: Snooping control support
    
    Snooping control enabled IOMMU to guarantee DMA cache coherency and thus reduce
    software effort (VMM) in maintaining effective memory type.
    
    Signed-off-by: Sheng Yang <sheng@linux.intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index d2e3cbfba14f..3ad894004938 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -123,7 +123,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define ecap_eim_support(e)	((e >> 4) & 0x1)
 #define ecap_ir_support(e)	((e >> 3) & 0x1)
 #define ecap_max_handle_mask(e) ((e >> 20) & 0xf)
-
+#define ecap_sc_support(e)	((e >> 7) & 0x1) /* Snooping Control */
 
 /* IOTLB_REG */
 #define DMA_TLB_FLUSH_GRANU_OFFSET  60

commit eba67e5da6e971993b2899d2cdf459ce77d3dbc5
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Mar 16 17:04:56 2009 -0700

    x86, dmar: routines for disabling queued invalidation and intr remapping
    
    Impact: new interfaces (not yet used)
    
    Routines for disabling queued invalidation and interrupt remapping.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a9563840644b..78c1262e8704 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -321,6 +321,7 @@ extern struct dmar_drhd_unit * dmar_find_matched_drhd_unit(struct pci_dev *dev);
 extern int alloc_iommu(struct dmar_drhd_unit *drhd);
 extern void free_iommu(struct intel_iommu *iommu);
 extern int dmar_enable_qi(struct intel_iommu *iommu);
+extern void dmar_disable_qi(struct intel_iommu *iommu);
 extern void qi_global_iec(struct intel_iommu *iommu);
 
 extern int qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,

commit 9d783ba042771284fb4ee5013c3d94220755ae7f
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Mar 16 17:04:55 2009 -0700

    x86, x2apic: enable fault handling for intr-remapping
    
    Impact: interface augmentation (not yet used)
    
    Enable fault handling flow for intr-remapping aswell. Fault handling
    code now shared by both dma-remapping and intr-remapping.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index d2e3cbfba14f..a9563840644b 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -292,6 +292,8 @@ struct intel_iommu {
 	spinlock_t	register_lock; /* protect register handling */
 	int		seq_id;	/* sequence id of the iommu */
 	int		agaw; /* agaw of this iommu */
+	unsigned int 	irq;
+	unsigned char 	name[13];    /* Device Name */
 
 #ifdef CONFIG_DMAR
 	unsigned long 	*domain_ids; /* bitmap of domains */
@@ -299,8 +301,6 @@ struct intel_iommu {
 	spinlock_t	lock; /* protect context, domain ids */
 	struct root_entry *root_entry; /* virtual address */
 
-	unsigned int irq;
-	unsigned char name[7];    /* Device Name */
 	struct iommu_flush flush;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */

commit 7df4edb07cf54a4868b9a750424c0d2aa68f8d66
Merge: 0d688da5505d 559595a985e1
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 5 12:47:28 2009 +0100

    Merge branch 'linus' into core/iommu

commit 704126ad81b8cb7d3d70adb9ecb143f4d3fb38af
Author: Yu Zhao <yu.zhao@intel.com>
Date:   Sun Jan 4 16:28:52 2009 +0800

    VT-d: handle Invalidation Queue Error to avoid system hang
    
    When hardware detects any error with a descriptor from the invalidation
    queue, it stops fetching new descriptors from the queue until software
    clears the Invalidation Queue Error bit in the Fault Status register.
    Following fix handles the IQE so the kernel won't be trapped in an
    infinite loop.
    
    Signed-off-by: Yu Zhao <yu.zhao@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index c4f6c101dbcd..d2e3cbfba14f 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -194,6 +194,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 /* FSTS_REG */
 #define DMA_FSTS_PPF ((u32)2)
 #define DMA_FSTS_PFO ((u32)1)
+#define DMA_FSTS_IQE (1 << 4)
 #define dma_fsts_fault_record_index(s) (((s) >> 8) & 0xff)
 
 /* FRCD_REG, 32 bits access */
@@ -328,7 +329,7 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 			  unsigned int size_order, u64 type,
 			  int non_present_entry_flush);
 
-extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
+extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern void *intel_alloc_coherent(struct device *, size_t, dma_addr_t *, gfp_t);
 extern void intel_free_coherent(struct device *, size_t, void *, dma_addr_t);

commit d7ab5c46ae2743079a40bb4060e510418c0842b4
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Wed Jan 28 21:53:18 2009 +0900

    intel-iommu: make dma mapping functions static
    
    The dma ops unification enables X86 and IA64 to share intel_dma_ops so
    we can make dma mapping functions static. This also remove unused
    intel_map_single().
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index a254db1decd0..43412aeddb53 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -330,13 +330,4 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
-extern void *intel_alloc_coherent(struct device *, size_t, dma_addr_t *, gfp_t);
-extern void intel_free_coherent(struct device *, size_t, void *, dma_addr_t);
-extern dma_addr_t intel_map_single(struct device *, phys_addr_t, size_t, int);
-extern void intel_unmap_single(struct device *, dma_addr_t, size_t, int);
-extern int intel_map_sg(struct device *, struct scatterlist *, int,
-			enum dma_data_direction, struct dma_attrs *);
-extern void intel_unmap_sg(struct device *, struct scatterlist *, int,
-			   enum dma_data_direction, struct dma_attrs *);
-
 #endif

commit 160c1d8e40866edfeae7d68816b7005d70acf391
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Mon Jan 5 23:59:02 2009 +0900

    x86, ia64: convert to use generic dma_map_ops struct
    
    This converts X86 and IA64 to use include/linux/dma-mapping.h.
    
    It's a bit large but pretty boring. The major change for X86 is
    converting 'int dir' to 'enum dma_data_direction dir' in DMA mapping
    operations. The major changes for IA64 is using map_page and
    unmap_page instead of map_single and unmap_single.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index c4f6c101dbcd..a254db1decd0 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -334,7 +334,9 @@ extern void *intel_alloc_coherent(struct device *, size_t, dma_addr_t *, gfp_t);
 extern void intel_free_coherent(struct device *, size_t, void *, dma_addr_t);
 extern dma_addr_t intel_map_single(struct device *, phys_addr_t, size_t, int);
 extern void intel_unmap_single(struct device *, dma_addr_t, size_t, int);
-extern int intel_map_sg(struct device *, struct scatterlist *, int, int);
-extern void intel_unmap_sg(struct device *, struct scatterlist *, int, int);
+extern int intel_map_sg(struct device *, struct scatterlist *, int,
+			enum dma_data_direction, struct dma_attrs *);
+extern void intel_unmap_sg(struct device *, struct scatterlist *, int,
+			   enum dma_data_direction, struct dma_attrs *);
 
 #endif

commit e4754c96cf8b82a754dc5ba791d6c0bf1fbe8e8e
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Wed Dec 3 15:26:42 2008 +0100

    VT-d: remove now unused intel_iommu_found function
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 26ccc0294567..c4f6c101dbcd 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -330,15 +330,6 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
-#ifdef CONFIG_DMAR
-int intel_iommu_found(void);
-#else /* CONFIG_DMAR */
-static inline int intel_iommu_found(void)
-{
-	return 0;
-}
-#endif /* CONFIG_DMAR */
-
 extern void *intel_alloc_coherent(struct device *, size_t, dma_addr_t *, gfp_t);
 extern void intel_free_coherent(struct device *, size_t, void *, dma_addr_t);
 extern dma_addr_t intel_map_single(struct device *, phys_addr_t, size_t, int);

commit d14d65777c2491dd5baf1e17f444b8f653f3cbb1
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Wed Dec 3 15:06:57 2008 +0100

    VT-d: adapt domain iova_to_phys function for IOMMU API
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 6bc26e03858c..26ccc0294567 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -330,8 +330,6 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
-u64 intel_iommu_iova_to_phys(struct dmar_domain *domain, u64 iova);
-
 #ifdef CONFIG_DMAR
 int intel_iommu_found(void);
 #else /* CONFIG_DMAR */

commit dde57a210dcdce85e2813bab8f88687761d9f6a6
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Wed Dec 3 15:04:09 2008 +0100

    VT-d: adapt domain map and unmap functions for IOMMU API
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 9909c5a1b20f..6bc26e03858c 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -330,10 +330,6 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
-int intel_iommu_map_address(struct dmar_domain *domain, dma_addr_t iova,
-			    u64 hpa, size_t size, int prot);
-void intel_iommu_unmap_address(struct dmar_domain *domain,
-			       dma_addr_t iova, size_t size);
 u64 intel_iommu_iova_to_phys(struct dmar_domain *domain, u64 iova);
 
 #ifdef CONFIG_DMAR

commit 4c5478c94eb29e6101f1f13175f7455bc8b5d953
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Wed Dec 3 14:58:24 2008 +0100

    VT-d: adapt device attach and detach functions for IOMMU API
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 0a7ba0cefc74..9909c5a1b20f 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -330,10 +330,6 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
-int intel_iommu_attach_device(struct dmar_domain *domain,
-			      struct pci_dev *pdev);
-void intel_iommu_detach_device(struct dmar_domain *domain,
-			       struct pci_dev *pdev);
 int intel_iommu_map_address(struct dmar_domain *domain, dma_addr_t iova,
 			    u64 hpa, size_t size, int prot);
 void intel_iommu_unmap_address(struct dmar_domain *domain,

commit 5d450806eb0e569c5846a5825e7f535980b0da32
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Wed Dec 3 14:52:32 2008 +0100

    VT-d: adapt domain init and destroy functions for IOMMU API
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 07973c4e4acc..0a7ba0cefc74 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -330,8 +330,6 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
-struct dmar_domain *intel_iommu_alloc_domain(void);
-void intel_iommu_free_domain(struct dmar_domain *domain);
 int intel_iommu_attach_device(struct dmar_domain *domain,
 			      struct pci_dev *pdev);
 void intel_iommu_detach_device(struct dmar_domain *domain,

commit faa3d6f5ffe7bf60ebfd0d36513fbcda0eb0ea1a
Author: Weidong Han <weidong.han@intel.com>
Date:   Mon Dec 8 23:09:29 2008 +0800

    Change intel iommu APIs of virtual machine domain
    
    These APIs are used by KVM to use VT-d
    
    Signed-off-by: Weidong Han <weidong.han@intel.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 06349fd5871b..07973c4e4acc 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -330,15 +330,17 @@ extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
 
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
-void intel_iommu_domain_exit(struct dmar_domain *domain);
-struct dmar_domain *intel_iommu_domain_alloc(struct pci_dev *pdev);
-int intel_iommu_context_mapping(struct dmar_domain *domain,
-				struct pci_dev *pdev);
-int intel_iommu_page_mapping(struct dmar_domain *domain, dma_addr_t iova,
-			     u64 hpa, size_t size, int prot);
-void intel_iommu_detach_dev(struct dmar_domain *domain, u8 bus, u8 devfn);
-struct dmar_domain *intel_iommu_find_domain(struct pci_dev *pdev);
-u64 intel_iommu_iova_to_pfn(struct dmar_domain *domain, u64 iova);
+struct dmar_domain *intel_iommu_alloc_domain(void);
+void intel_iommu_free_domain(struct dmar_domain *domain);
+int intel_iommu_attach_device(struct dmar_domain *domain,
+			      struct pci_dev *pdev);
+void intel_iommu_detach_device(struct dmar_domain *domain,
+			       struct pci_dev *pdev);
+int intel_iommu_map_address(struct dmar_domain *domain, dma_addr_t iova,
+			    u64 hpa, size_t size, int prot);
+void intel_iommu_unmap_address(struct dmar_domain *domain,
+			       dma_addr_t iova, size_t size);
+u64 intel_iommu_iova_to_phys(struct dmar_domain *domain, u64 iova);
 
 #ifdef CONFIG_DMAR
 int intel_iommu_found(void);

commit 1b5736839ae13dadc5947940144f95dd0f4a4a8c
Author: Weidong Han <weidong.han@intel.com>
Date:   Mon Dec 8 15:34:06 2008 +0800

    calculate agaw for each iommu
    
    "SAGAW" capability may be different across iommus. Use a default agaw, but if default agaw is not supported in some iommus, choose a less supported agaw.
    
    Signed-off-by: Weidong Han <weidong.han@intel.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 1bff7bf1bc2c..06349fd5871b 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -290,6 +290,7 @@ struct intel_iommu {
 	u32		gcmd; /* Holds TE, EAFL. Don't need SRTP, SFL, WBF */
 	spinlock_t	register_lock; /* protect register handling */
 	int		seq_id;	/* sequence id of the iommu */
+	int		agaw; /* agaw of this iommu */
 
 #ifdef CONFIG_DMAR
 	unsigned long 	*domain_ids; /* bitmap of domains */

commit 015ab17dc2e9de805c26e74f498b12ee5e8de07e
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Thu Nov 20 14:04:20 2008 +0000

    intel-iommu: remove some unused struct intel_iommu fields
    
    The seg, saved_msg and sysdev fields appear to be unused since
    before the code was first merged.
    
    linux/msi.h is not needed in linux/intel-iommu.h anymore since
    there is no longer a reference to struct msi_msg. The MSI code
    in drivers/pci/intel-iommu.c still has linux/msi.h included
    via linux/dmar.h.
    
    linux/sysdev.h isn't needed because there is no reference to
    struct sys_device.
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 3d017cfd245b..1bff7bf1bc2c 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -23,8 +23,6 @@
 #define _INTEL_IOMMU_H_
 
 #include <linux/types.h>
-#include <linux/msi.h>
-#include <linux/sysdev.h>
 #include <linux/iova.h>
 #include <linux/io.h>
 #include <linux/dma_remapping.h>
@@ -289,7 +287,6 @@ struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
 	u64		cap;
 	u64		ecap;
-	int		seg;
 	u32		gcmd; /* Holds TE, EAFL. Don't need SRTP, SFL, WBF */
 	spinlock_t	register_lock; /* protect register handling */
 	int		seq_id;	/* sequence id of the iommu */
@@ -302,8 +299,6 @@ struct intel_iommu {
 
 	unsigned int irq;
 	unsigned char name[7];    /* Device Name */
-	struct msi_msg saved_msg;
-	struct sys_device sysdev;
 	struct iommu_flush flush;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */

commit 5b6985ce8ec7127b4d60ad450b64ca8b82748a3b
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Thu Oct 16 18:02:32 2008 -0700

    intel-iommu: IA64 support
    
    The current Intel IOMMU code assumes that both host page size and Intel
    IOMMU page size are 4KiB. The first patch supports variable page size.
    This provides support for IA64 which has multiple page sizes.
    
    This patch also adds some other code hooks for IA64 platform including
    DMAR_OPERATION_TIMEOUT definition.
    
    [dwmw2: some cleanup]
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index afb0d2a5b7cd..3d017cfd245b 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -29,6 +29,7 @@
 #include <linux/io.h>
 #include <linux/dma_remapping.h>
 #include <asm/cacheflush.h>
+#include <asm/iommu.h>
 
 /*
  * Intel IOMMU register specification per version 1.0 public spec.
@@ -202,22 +203,21 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define dma_frcd_type(d) ((d >> 30) & 1)
 #define dma_frcd_fault_reason(c) (c & 0xff)
 #define dma_frcd_source_id(c) (c & 0xffff)
-#define dma_frcd_page_addr(d) (d & (((u64)-1) << 12)) /* low 64 bit */
-
-#define DMAR_OPERATION_TIMEOUT ((cycles_t) tsc_khz*10*1000) /* 10sec */
-
-#define IOMMU_WAIT_OP(iommu, offset, op, cond, sts) \
-{\
-	cycles_t start_time = get_cycles();\
-	while (1) {\
-		sts = op (iommu->reg + offset);\
-		if (cond)\
-			break;\
+/* low 64 bit */
+#define dma_frcd_page_addr(d) (d & (((u64)-1) << PAGE_SHIFT))
+
+#define IOMMU_WAIT_OP(iommu, offset, op, cond, sts)			\
+do {									\
+	cycles_t start_time = get_cycles();				\
+	while (1) {							\
+		sts = op(iommu->reg + offset);				\
+		if (cond)						\
+			break;						\
 		if (DMAR_OPERATION_TIMEOUT < (get_cycles() - start_time))\
-			panic("DMAR hardware is malfunctioning\n");\
-		cpu_relax();\
-	}\
-}
+			panic("DMAR hardware is malfunctioning\n");	\
+		cpu_relax();						\
+	}								\
+} while (0)
 
 #define QI_LENGTH	256	/* queue length */
 
@@ -244,7 +244,7 @@ enum {
 #define QI_IOTLB_DR(dr) 	(((u64)dr) << 7)
 #define QI_IOTLB_DW(dw) 	(((u64)dw) << 6)
 #define QI_IOTLB_GRAN(gran) 	(((u64)gran) >> (DMA_TLB_FLUSH_GRANU_OFFSET-4))
-#define QI_IOTLB_ADDR(addr)	(((u64)addr) & PAGE_MASK_4K)
+#define QI_IOTLB_ADDR(addr)	(((u64)addr) & VTD_PAGE_MASK)
 #define QI_IOTLB_IH(ih)		(((u64)ih) << 6)
 #define QI_IOTLB_AM(am)		(((u8)am))
 
@@ -353,4 +353,11 @@ static inline int intel_iommu_found(void)
 }
 #endif /* CONFIG_DMAR */
 
+extern void *intel_alloc_coherent(struct device *, size_t, dma_addr_t *, gfp_t);
+extern void intel_free_coherent(struct device *, size_t, void *, dma_addr_t);
+extern dma_addr_t intel_map_single(struct device *, phys_addr_t, size_t, int);
+extern void intel_unmap_single(struct device *, dma_addr_t, size_t, int);
+extern int intel_map_sg(struct device *, struct scatterlist *, int, int);
+extern void intel_unmap_sg(struct device *, struct scatterlist *, int, int);
+
 #endif

commit a77b67d4023770805141014b8fa9eb5467457817
Author: Youquan Song <youquan.song@intel.com>
Date:   Thu Oct 16 16:31:56 2008 -0700

    dmar: Use queued invalidation interface for IOTLB and context invalidation
    
    If queued invalidation interface is available and enabled, queued invalidation
    interface will be used instead of the register based interface.
    
    According to Vt-d2 specification, when queued invalidation is enabled,
    invalidation command submit works only through invalidation queue and not
    through the command registers interface.
    
    Signed-off-by: Youquan Song <youquan.song@intel.com>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 0c5f5e49107b..afb0d2a5b7cd 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -278,6 +278,13 @@ struct ir_table {
 };
 #endif
 
+struct iommu_flush {
+	int (*flush_context)(struct intel_iommu *iommu, u16 did, u16 sid, u8 fm,
+		u64 type, int non_present_entry_flush);
+	int (*flush_iotlb)(struct intel_iommu *iommu, u16 did, u64 addr,
+		unsigned int size_order, u64 type, int non_present_entry_flush);
+};
+
 struct intel_iommu {
 	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
 	u64		cap;
@@ -297,6 +304,7 @@ struct intel_iommu {
 	unsigned char name[7];    /* Device Name */
 	struct msi_msg saved_msg;
 	struct sys_device sysdev;
+	struct iommu_flush flush;
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
 #ifdef CONFIG_INTR_REMAP

commit 3481f21097cb560392c411377893b5109fbde557
Author: Youquan Song <youquan.song@intel.com>
Date:   Thu Oct 16 16:31:55 2008 -0700

    dmar: context cache and IOTLB invalidation using queued invalidation
    
    Implement context cache invalidate and IOTLB invalidation using
    queued invalidation interface. This interface will be used by
    DMA remapping, when queued invalidation is supported.
    
    Signed-off-by: Youquan Song <youquan.song@intel.com>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 2e117f30a76c..0c5f5e49107b 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -127,6 +127,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 
 
 /* IOTLB_REG */
+#define DMA_TLB_FLUSH_GRANU_OFFSET  60
 #define DMA_TLB_GLOBAL_FLUSH (((u64)1) << 60)
 #define DMA_TLB_DSI_FLUSH (((u64)2) << 60)
 #define DMA_TLB_PSI_FLUSH (((u64)3) << 60)
@@ -140,6 +141,7 @@ static inline void dmar_writeq(void __iomem *addr, u64 val)
 #define DMA_TLB_MAX_SIZE (0x3f)
 
 /* INVALID_DESC */
+#define DMA_CCMD_INVL_GRANU_OFFSET  61
 #define DMA_ID_TLB_GLOBAL_FLUSH	(((u64)1) << 3)
 #define DMA_ID_TLB_DSI_FLUSH	(((u64)2) << 3)
 #define DMA_ID_TLB_PSI_FLUSH	(((u64)3) << 3)
@@ -238,6 +240,19 @@ enum {
 #define QI_IWD_STATUS_DATA(d)	(((u64)d) << 32)
 #define QI_IWD_STATUS_WRITE	(((u64)1) << 5)
 
+#define QI_IOTLB_DID(did) 	(((u64)did) << 16)
+#define QI_IOTLB_DR(dr) 	(((u64)dr) << 7)
+#define QI_IOTLB_DW(dw) 	(((u64)dw) << 6)
+#define QI_IOTLB_GRAN(gran) 	(((u64)gran) >> (DMA_TLB_FLUSH_GRANU_OFFSET-4))
+#define QI_IOTLB_ADDR(addr)	(((u64)addr) & PAGE_MASK_4K)
+#define QI_IOTLB_IH(ih)		(((u64)ih) << 6)
+#define QI_IOTLB_AM(am)		(((u8)am))
+
+#define QI_CC_FM(fm)		(((u64)fm) << 48)
+#define QI_CC_SID(sid)		(((u64)sid) << 32)
+#define QI_CC_DID(did)		(((u64)did) << 16)
+#define QI_CC_GRAN(gran)	(((u64)gran) >> (DMA_CCMD_INVL_GRANU_OFFSET-4))
+
 struct qi_desc {
 	u64 low, high;
 };
@@ -303,6 +318,12 @@ extern void free_iommu(struct intel_iommu *iommu);
 extern int dmar_enable_qi(struct intel_iommu *iommu);
 extern void qi_global_iec(struct intel_iommu *iommu);
 
+extern int qi_flush_context(struct intel_iommu *iommu, u16 did, u16 sid,
+			        u8 fm, u64 type, int non_present_entry_flush);
+extern int qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,
+			  unsigned int size_order, u64 type,
+			  int non_present_entry_flush);
+
 extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 void intel_iommu_domain_exit(struct dmar_domain *domain);

commit 387179464257921eb9aa3d15cc3ff194f6945a7c
Author: Kay, Allen M <allen.m.kay@intel.com>
Date:   Tue Sep 9 18:37:29 2008 +0300

    VT-d: Changes to support KVM
    
    This patch extends the VT-d driver to support KVM
    
    [Ben: fixed memory pinning]
    [avi: move dma_remapping.h as well]
    
    Signed-off-by: Kay, Allen M <allen.m.kay@intel.com>
    Signed-off-by: Weidong Han <weidong.han@intel.com>
    Signed-off-by: Ben-Ami Yassour <benami@il.ibm.com>
    Signed-off-by: Amit Shah <amit.shah@qumranet.com>
    Acked-by: Mark Gross <mgross@linux.intel.com>
    Signed-off-by: Avi Kivity <avi@qumranet.com>

diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
new file mode 100644
index 000000000000..2e117f30a76c
--- /dev/null
+++ b/include/linux/intel-iommu.h
@@ -0,0 +1,327 @@
+/*
+ * Copyright (c) 2006, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
+ * Place - Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * Copyright (C) 2006-2008 Intel Corporation
+ * Author: Ashok Raj <ashok.raj@intel.com>
+ * Author: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
+ */
+
+#ifndef _INTEL_IOMMU_H_
+#define _INTEL_IOMMU_H_
+
+#include <linux/types.h>
+#include <linux/msi.h>
+#include <linux/sysdev.h>
+#include <linux/iova.h>
+#include <linux/io.h>
+#include <linux/dma_remapping.h>
+#include <asm/cacheflush.h>
+
+/*
+ * Intel IOMMU register specification per version 1.0 public spec.
+ */
+
+#define	DMAR_VER_REG	0x0	/* Arch version supported by this IOMMU */
+#define	DMAR_CAP_REG	0x8	/* Hardware supported capabilities */
+#define	DMAR_ECAP_REG	0x10	/* Extended capabilities supported */
+#define	DMAR_GCMD_REG	0x18	/* Global command register */
+#define	DMAR_GSTS_REG	0x1c	/* Global status register */
+#define	DMAR_RTADDR_REG	0x20	/* Root entry table */
+#define	DMAR_CCMD_REG	0x28	/* Context command reg */
+#define	DMAR_FSTS_REG	0x34	/* Fault Status register */
+#define	DMAR_FECTL_REG	0x38	/* Fault control register */
+#define	DMAR_FEDATA_REG	0x3c	/* Fault event interrupt data register */
+#define	DMAR_FEADDR_REG	0x40	/* Fault event interrupt addr register */
+#define	DMAR_FEUADDR_REG 0x44	/* Upper address register */
+#define	DMAR_AFLOG_REG	0x58	/* Advanced Fault control */
+#define	DMAR_PMEN_REG	0x64	/* Enable Protected Memory Region */
+#define	DMAR_PLMBASE_REG 0x68	/* PMRR Low addr */
+#define	DMAR_PLMLIMIT_REG 0x6c	/* PMRR low limit */
+#define	DMAR_PHMBASE_REG 0x70	/* pmrr high base addr */
+#define	DMAR_PHMLIMIT_REG 0x78	/* pmrr high limit */
+#define DMAR_IQH_REG	0x80	/* Invalidation queue head register */
+#define DMAR_IQT_REG	0x88	/* Invalidation queue tail register */
+#define DMAR_IQA_REG	0x90	/* Invalidation queue addr register */
+#define DMAR_ICS_REG	0x98	/* Invalidation complete status register */
+#define DMAR_IRTA_REG	0xb8    /* Interrupt remapping table addr register */
+
+#define OFFSET_STRIDE		(9)
+/*
+#define dmar_readl(dmar, reg) readl(dmar + reg)
+#define dmar_readq(dmar, reg) ({ \
+		u32 lo, hi; \
+		lo = readl(dmar + reg); \
+		hi = readl(dmar + reg + 4); \
+		(((u64) hi) << 32) + lo; })
+*/
+static inline u64 dmar_readq(void __iomem *addr)
+{
+	u32 lo, hi;
+	lo = readl(addr);
+	hi = readl(addr + 4);
+	return (((u64) hi) << 32) + lo;
+}
+
+static inline void dmar_writeq(void __iomem *addr, u64 val)
+{
+	writel((u32)val, addr);
+	writel((u32)(val >> 32), addr + 4);
+}
+
+#define DMAR_VER_MAJOR(v)		(((v) & 0xf0) >> 4)
+#define DMAR_VER_MINOR(v)		((v) & 0x0f)
+
+/*
+ * Decoding Capability Register
+ */
+#define cap_read_drain(c)	(((c) >> 55) & 1)
+#define cap_write_drain(c)	(((c) >> 54) & 1)
+#define cap_max_amask_val(c)	(((c) >> 48) & 0x3f)
+#define cap_num_fault_regs(c)	((((c) >> 40) & 0xff) + 1)
+#define cap_pgsel_inv(c)	(((c) >> 39) & 1)
+
+#define cap_super_page_val(c)	(((c) >> 34) & 0xf)
+#define cap_super_offset(c)	(((find_first_bit(&cap_super_page_val(c), 4)) \
+					* OFFSET_STRIDE) + 21)
+
+#define cap_fault_reg_offset(c)	((((c) >> 24) & 0x3ff) * 16)
+#define cap_max_fault_reg_offset(c) \
+	(cap_fault_reg_offset(c) + cap_num_fault_regs(c) * 16)
+
+#define cap_zlr(c)		(((c) >> 22) & 1)
+#define cap_isoch(c)		(((c) >> 23) & 1)
+#define cap_mgaw(c)		((((c) >> 16) & 0x3f) + 1)
+#define cap_sagaw(c)		(((c) >> 8) & 0x1f)
+#define cap_caching_mode(c)	(((c) >> 7) & 1)
+#define cap_phmr(c)		(((c) >> 6) & 1)
+#define cap_plmr(c)		(((c) >> 5) & 1)
+#define cap_rwbf(c)		(((c) >> 4) & 1)
+#define cap_afl(c)		(((c) >> 3) & 1)
+#define cap_ndoms(c)		(((unsigned long)1) << (4 + 2 * ((c) & 0x7)))
+/*
+ * Extended Capability Register
+ */
+
+#define ecap_niotlb_iunits(e)	((((e) >> 24) & 0xff) + 1)
+#define ecap_iotlb_offset(e) 	((((e) >> 8) & 0x3ff) * 16)
+#define ecap_max_iotlb_offset(e) \
+	(ecap_iotlb_offset(e) + ecap_niotlb_iunits(e) * 16)
+#define ecap_coherent(e)	((e) & 0x1)
+#define ecap_qis(e)		((e) & 0x2)
+#define ecap_eim_support(e)	((e >> 4) & 0x1)
+#define ecap_ir_support(e)	((e >> 3) & 0x1)
+#define ecap_max_handle_mask(e) ((e >> 20) & 0xf)
+
+
+/* IOTLB_REG */
+#define DMA_TLB_GLOBAL_FLUSH (((u64)1) << 60)
+#define DMA_TLB_DSI_FLUSH (((u64)2) << 60)
+#define DMA_TLB_PSI_FLUSH (((u64)3) << 60)
+#define DMA_TLB_IIRG(type) ((type >> 60) & 7)
+#define DMA_TLB_IAIG(val) (((val) >> 57) & 7)
+#define DMA_TLB_READ_DRAIN (((u64)1) << 49)
+#define DMA_TLB_WRITE_DRAIN (((u64)1) << 48)
+#define DMA_TLB_DID(id)	(((u64)((id) & 0xffff)) << 32)
+#define DMA_TLB_IVT (((u64)1) << 63)
+#define DMA_TLB_IH_NONLEAF (((u64)1) << 6)
+#define DMA_TLB_MAX_SIZE (0x3f)
+
+/* INVALID_DESC */
+#define DMA_ID_TLB_GLOBAL_FLUSH	(((u64)1) << 3)
+#define DMA_ID_TLB_DSI_FLUSH	(((u64)2) << 3)
+#define DMA_ID_TLB_PSI_FLUSH	(((u64)3) << 3)
+#define DMA_ID_TLB_READ_DRAIN	(((u64)1) << 7)
+#define DMA_ID_TLB_WRITE_DRAIN	(((u64)1) << 6)
+#define DMA_ID_TLB_DID(id)	(((u64)((id & 0xffff) << 16)))
+#define DMA_ID_TLB_IH_NONLEAF	(((u64)1) << 6)
+#define DMA_ID_TLB_ADDR(addr)	(addr)
+#define DMA_ID_TLB_ADDR_MASK(mask)	(mask)
+
+/* PMEN_REG */
+#define DMA_PMEN_EPM (((u32)1)<<31)
+#define DMA_PMEN_PRS (((u32)1)<<0)
+
+/* GCMD_REG */
+#define DMA_GCMD_TE (((u32)1) << 31)
+#define DMA_GCMD_SRTP (((u32)1) << 30)
+#define DMA_GCMD_SFL (((u32)1) << 29)
+#define DMA_GCMD_EAFL (((u32)1) << 28)
+#define DMA_GCMD_WBF (((u32)1) << 27)
+#define DMA_GCMD_QIE (((u32)1) << 26)
+#define DMA_GCMD_SIRTP (((u32)1) << 24)
+#define DMA_GCMD_IRE (((u32) 1) << 25)
+
+/* GSTS_REG */
+#define DMA_GSTS_TES (((u32)1) << 31)
+#define DMA_GSTS_RTPS (((u32)1) << 30)
+#define DMA_GSTS_FLS (((u32)1) << 29)
+#define DMA_GSTS_AFLS (((u32)1) << 28)
+#define DMA_GSTS_WBFS (((u32)1) << 27)
+#define DMA_GSTS_QIES (((u32)1) << 26)
+#define DMA_GSTS_IRTPS (((u32)1) << 24)
+#define DMA_GSTS_IRES (((u32)1) << 25)
+
+/* CCMD_REG */
+#define DMA_CCMD_ICC (((u64)1) << 63)
+#define DMA_CCMD_GLOBAL_INVL (((u64)1) << 61)
+#define DMA_CCMD_DOMAIN_INVL (((u64)2) << 61)
+#define DMA_CCMD_DEVICE_INVL (((u64)3) << 61)
+#define DMA_CCMD_FM(m) (((u64)((m) & 0x3)) << 32)
+#define DMA_CCMD_MASK_NOBIT 0
+#define DMA_CCMD_MASK_1BIT 1
+#define DMA_CCMD_MASK_2BIT 2
+#define DMA_CCMD_MASK_3BIT 3
+#define DMA_CCMD_SID(s) (((u64)((s) & 0xffff)) << 16)
+#define DMA_CCMD_DID(d) ((u64)((d) & 0xffff))
+
+/* FECTL_REG */
+#define DMA_FECTL_IM (((u32)1) << 31)
+
+/* FSTS_REG */
+#define DMA_FSTS_PPF ((u32)2)
+#define DMA_FSTS_PFO ((u32)1)
+#define dma_fsts_fault_record_index(s) (((s) >> 8) & 0xff)
+
+/* FRCD_REG, 32 bits access */
+#define DMA_FRCD_F (((u32)1) << 31)
+#define dma_frcd_type(d) ((d >> 30) & 1)
+#define dma_frcd_fault_reason(c) (c & 0xff)
+#define dma_frcd_source_id(c) (c & 0xffff)
+#define dma_frcd_page_addr(d) (d & (((u64)-1) << 12)) /* low 64 bit */
+
+#define DMAR_OPERATION_TIMEOUT ((cycles_t) tsc_khz*10*1000) /* 10sec */
+
+#define IOMMU_WAIT_OP(iommu, offset, op, cond, sts) \
+{\
+	cycles_t start_time = get_cycles();\
+	while (1) {\
+		sts = op (iommu->reg + offset);\
+		if (cond)\
+			break;\
+		if (DMAR_OPERATION_TIMEOUT < (get_cycles() - start_time))\
+			panic("DMAR hardware is malfunctioning\n");\
+		cpu_relax();\
+	}\
+}
+
+#define QI_LENGTH	256	/* queue length */
+
+enum {
+	QI_FREE,
+	QI_IN_USE,
+	QI_DONE
+};
+
+#define QI_CC_TYPE		0x1
+#define QI_IOTLB_TYPE		0x2
+#define QI_DIOTLB_TYPE		0x3
+#define QI_IEC_TYPE		0x4
+#define QI_IWD_TYPE		0x5
+
+#define QI_IEC_SELECTIVE	(((u64)1) << 4)
+#define QI_IEC_IIDEX(idx)	(((u64)(idx & 0xffff) << 32))
+#define QI_IEC_IM(m)		(((u64)(m & 0x1f) << 27))
+
+#define QI_IWD_STATUS_DATA(d)	(((u64)d) << 32)
+#define QI_IWD_STATUS_WRITE	(((u64)1) << 5)
+
+struct qi_desc {
+	u64 low, high;
+};
+
+struct q_inval {
+	spinlock_t      q_lock;
+	struct qi_desc  *desc;          /* invalidation queue */
+	int             *desc_status;   /* desc status */
+	int             free_head;      /* first free entry */
+	int             free_tail;      /* last free entry */
+	int             free_cnt;
+};
+
+#ifdef CONFIG_INTR_REMAP
+/* 1MB - maximum possible interrupt remapping table size */
+#define INTR_REMAP_PAGE_ORDER	8
+#define INTR_REMAP_TABLE_REG_SIZE	0xf
+
+#define INTR_REMAP_TABLE_ENTRIES	65536
+
+struct ir_table {
+	struct irte *base;
+};
+#endif
+
+struct intel_iommu {
+	void __iomem	*reg; /* Pointer to hardware regs, virtual addr */
+	u64		cap;
+	u64		ecap;
+	int		seg;
+	u32		gcmd; /* Holds TE, EAFL. Don't need SRTP, SFL, WBF */
+	spinlock_t	register_lock; /* protect register handling */
+	int		seq_id;	/* sequence id of the iommu */
+
+#ifdef CONFIG_DMAR
+	unsigned long 	*domain_ids; /* bitmap of domains */
+	struct dmar_domain **domains; /* ptr to domains */
+	spinlock_t	lock; /* protect context, domain ids */
+	struct root_entry *root_entry; /* virtual address */
+
+	unsigned int irq;
+	unsigned char name[7];    /* Device Name */
+	struct msi_msg saved_msg;
+	struct sys_device sysdev;
+#endif
+	struct q_inval  *qi;            /* Queued invalidation info */
+#ifdef CONFIG_INTR_REMAP
+	struct ir_table *ir_table;	/* Interrupt remapping info */
+#endif
+};
+
+static inline void __iommu_flush_cache(
+	struct intel_iommu *iommu, void *addr, int size)
+{
+	if (!ecap_coherent(iommu->ecap))
+		clflush_cache_range(addr, size);
+}
+
+extern struct dmar_drhd_unit * dmar_find_matched_drhd_unit(struct pci_dev *dev);
+
+extern int alloc_iommu(struct dmar_drhd_unit *drhd);
+extern void free_iommu(struct intel_iommu *iommu);
+extern int dmar_enable_qi(struct intel_iommu *iommu);
+extern void qi_global_iec(struct intel_iommu *iommu);
+
+extern void qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
+
+void intel_iommu_domain_exit(struct dmar_domain *domain);
+struct dmar_domain *intel_iommu_domain_alloc(struct pci_dev *pdev);
+int intel_iommu_context_mapping(struct dmar_domain *domain,
+				struct pci_dev *pdev);
+int intel_iommu_page_mapping(struct dmar_domain *domain, dma_addr_t iova,
+			     u64 hpa, size_t size, int prot);
+void intel_iommu_detach_dev(struct dmar_domain *domain, u8 bus, u8 devfn);
+struct dmar_domain *intel_iommu_find_domain(struct pci_dev *pdev);
+u64 intel_iommu_iova_to_pfn(struct dmar_domain *domain, u64 iova);
+
+#ifdef CONFIG_DMAR
+int intel_iommu_found(void);
+#else /* CONFIG_DMAR */
+static inline int intel_iommu_found(void)
+{
+	return 0;
+}
+#endif /* CONFIG_DMAR */
+
+#endif
