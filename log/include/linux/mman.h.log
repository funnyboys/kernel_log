commit 9035cf9a97e429e6b5291841da81c433879f5658
Author: Khalid Aziz <khalid.aziz@oracle.com>
Date:   Wed Feb 21 10:15:49 2018 -0700

    mm: Add address parameter to arch_validate_prot()
    
    A protection flag may not be valid across entire address space and
    hence arch_validate_prot() might need the address a protection bit is
    being set on to ensure it is a valid protection flag. For example, sparc
    processors support memory corruption detection (as part of ADI feature)
    flag on memory addresses mapped on to physical RAM but not on PFN mapped
    pages or addresses mapped on to devices. This patch adds address to the
    parameters being passed to arch_validate_prot() so protection bits can
    be validated in the relevant context.
    
    Signed-off-by: Khalid Aziz <khalid.aziz@oracle.com>
    Cc: Khalid Aziz <khalid@gonehiking.org>
    Reviewed-by: Anthony Yznaga <anthony.yznaga@oracle.com>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 6a4d1caaff5c..4b08e9c9c538 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -92,7 +92,7 @@ static inline void vm_unacct_memory(long pages)
  *
  * Returns true if the prot flags are valid
  */
-static inline bool arch_validate_prot(unsigned long prot)
+static inline bool arch_validate_prot(unsigned long prot, unsigned long addr)
 {
 	return (prot & ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM)) == 0;
 }

commit a3841f94c7ecb3ede0f888d3fcfe8fb6368ddd7a
Merge: adeba81ac2a6 4247f24c2358
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 17 09:51:57 2017 -0800

    Merge tag 'libnvdimm-for-4.15' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm and dax updates from Dan Williams:
     "Save for a few late fixes, all of these commits have shipped in -next
      releases since before the merge window opened, and 0day has given a
      build success notification.
    
      The ext4 touches came from Jan, and the xfs touches have Darrick's
      reviewed-by. An xfstest for the MAP_SYNC feature has been through
      a few round of reviews and is on track to be merged.
    
       - Introduce MAP_SYNC and MAP_SHARED_VALIDATE, a mechanism to enable
         'userspace flush' of persistent memory updates via filesystem-dax
         mappings. It arranges for any filesystem metadata updates that may
         be required to satisfy a write fault to also be flushed ("on disk")
         before the kernel returns to userspace from the fault handler.
         Effectively every write-fault that dirties metadata completes an
         fsync() before returning from the fault handler. The new
         MAP_SHARED_VALIDATE mapping type guarantees that the MAP_SYNC flag
         is validated as supported by the filesystem's ->mmap() file
         operation.
    
       - Add support for the standard ACPI 6.2 label access methods that
         replace the NVDIMM_FAMILY_INTEL (vendor specific) label methods.
         This enables interoperability with environments that only implement
         the standardized methods.
    
       - Add support for the ACPI 6.2 NVDIMM media error injection methods.
    
       - Add support for the NVDIMM_FAMILY_INTEL v1.6 DIMM commands for
         latch last shutdown status, firmware update, SMART error injection,
         and SMART alarm threshold control.
    
       - Cleanup physical address information disclosures to be root-only.
    
       - Fix revalidation of the DIMM "locked label area" status to support
         dynamic unlock of the label area.
    
       - Expand unit test infrastructure to mock the ACPI 6.2 Translate SPA
         (system-physical-address) command and error injection commands.
    
      Acknowledgements that came after the commits were pushed to -next:
    
       - 957ac8c421ad ("dax: fix PMD faults on zero-length files"):
           Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    
       - a39e596baa07 ("xfs: support for synchronous DAX faults") and
         7b565c9f965b ("xfs: Implement xfs_filemap_pfn_mkwrite() using __xfs_filemap_fault()")
            Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>"
    
    * tag 'libnvdimm-for-4.15' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (49 commits)
      acpi, nfit: add 'Enable Latch System Shutdown Status' command support
      dax: fix general protection fault in dax_alloc_inode
      dax: fix PMD faults on zero-length files
      dax: stop requiring a live device for dax_flush()
      brd: remove dax support
      dax: quiet bdev_dax_supported()
      fs, dax: unify IOMAP_F_DIRTY read vs write handling policy in the dax core
      tools/testing/nvdimm: unit test clear-error commands
      acpi, nfit: validate commands against the device type
      tools/testing/nvdimm: stricter bounds checking for error injection commands
      xfs: support for synchronous DAX faults
      xfs: Implement xfs_filemap_pfn_mkwrite() using __xfs_filemap_fault()
      ext4: Support for synchronous DAX faults
      ext4: Simplify error handling in ext4_dax_huge_fault()
      dax: Implement dax_finish_sync_fault()
      dax, iomap: Add support for synchronous faults
      mm: Define MAP_SYNC and VM_SYNC flags
      dax: Allow tuning whether dax_insert_mapping_entry() dirties entry
      dax: Allow dax_iomap_fault() to return pfn
      dax: Fix comment describing dax_iomap_fault()
      ...

commit b6fb293f2497a9841d94f6b57bd2bb2cd222da43
Author: Jan Kara <jack@suse.cz>
Date:   Wed Nov 1 16:36:41 2017 +0100

    mm: Define MAP_SYNC and VM_SYNC flags
    
    Define new MAP_SYNC flag and corresponding VMA VM_SYNC flag. As the
    MAP_SYNC flag is not part of LEGACY_MAP_MASK, currently it will be
    refused by all MAP_SHARED_VALIDATE map attempts and silently ignored for
    everything else.
    
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 74452e3f2536..3427bf3daef5 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -9,7 +9,7 @@
 
 /*
  * Arrange for legacy / undefined architecture specific flags to be
- * ignored by default in LEGACY_MAP_MASK.
+ * ignored by mmap handling code.
  */
 #ifndef MAP_32BIT
 #define MAP_32BIT 0
@@ -23,6 +23,9 @@
 #ifndef MAP_UNINITIALIZED
 #define MAP_UNINITIALIZED 0
 #endif
+#ifndef MAP_SYNC
+#define MAP_SYNC 0
+#endif
 
 /*
  * The historical set of flags that all mmap implementations implicitly
@@ -126,7 +129,8 @@ calc_vm_flag_bits(unsigned long flags)
 {
 	return _calc_vm_trans(flags, MAP_GROWSDOWN,  VM_GROWSDOWN ) |
 	       _calc_vm_trans(flags, MAP_DENYWRITE,  VM_DENYWRITE ) |
-	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
+	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    ) |
+	       _calc_vm_trans(flags, MAP_SYNC,	     VM_SYNC      );
 }
 
 unsigned long vm_commit_limit(void);

commit 1c9725974074a047f6080eecc62c50a8e840d050
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Nov 1 16:36:30 2017 +0100

    mm: introduce MAP_SHARED_VALIDATE, a mechanism to safely define new mmap flags
    
    The mmap(2) syscall suffers from the ABI anti-pattern of not validating
    unknown flags. However, proposals like MAP_SYNC need a mechanism to
    define new behavior that is known to fail on older kernels without the
    support. Define a new MAP_SHARED_VALIDATE flag pattern that is
    guaranteed to fail on all legacy mmap implementations.
    
    It is worth noting that the original proposal was for a standalone
    MAP_VALIDATE flag. However, when that  could not be supported by all
    archs Linus observed:
    
        I see why you *think* you want a bitmap. You think you want
        a bitmap because you want to make MAP_VALIDATE be part of MAP_SYNC
        etc, so that people can do
    
        ret = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED
                        | MAP_SYNC, fd, 0);
    
        and "know" that MAP_SYNC actually takes.
    
        And I'm saying that whole wish is bogus. You're fundamentally
        depending on special semantics, just make it explicit. It's already
        not portable, so don't try to make it so.
    
        Rename that MAP_VALIDATE as MAP_SHARED_VALIDATE, make it have a value
        of 0x3, and make people do
    
        ret = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED_VALIDATE
                        | MAP_SYNC, fd, 0);
    
        and then the kernel side is easier too (none of that random garbage
        playing games with looking at the "MAP_VALIDATE bit", but just another
        case statement in that map type thing.
    
        Boom. Done.
    
    Similar to ->fallocate() we also want the ability to validate the
    support for new flags on a per ->mmap() 'struct file_operations'
    instance basis.  Towards that end arrange for flags to be generically
    validated against a mmap_supported_flags exported by 'struct
    file_operations'. By default all existing flags are implicitly
    supported, but new flags require MAP_SHARED_VALIDATE and
    per-instance-opt-in.
    
    Cc: Jan Kara <jack@suse.cz>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Suggested-by: Christoph Hellwig <hch@lst.de>
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index edb6cf6a81ed..74452e3f2536 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -7,6 +7,45 @@
 #include <linux/atomic.h>
 #include <uapi/linux/mman.h>
 
+/*
+ * Arrange for legacy / undefined architecture specific flags to be
+ * ignored by default in LEGACY_MAP_MASK.
+ */
+#ifndef MAP_32BIT
+#define MAP_32BIT 0
+#endif
+#ifndef MAP_HUGE_2MB
+#define MAP_HUGE_2MB 0
+#endif
+#ifndef MAP_HUGE_1GB
+#define MAP_HUGE_1GB 0
+#endif
+#ifndef MAP_UNINITIALIZED
+#define MAP_UNINITIALIZED 0
+#endif
+
+/*
+ * The historical set of flags that all mmap implementations implicitly
+ * support when a ->mmap_validate() op is not provided in file_operations.
+ */
+#define LEGACY_MAP_MASK (MAP_SHARED \
+		| MAP_PRIVATE \
+		| MAP_FIXED \
+		| MAP_ANONYMOUS \
+		| MAP_DENYWRITE \
+		| MAP_EXECUTABLE \
+		| MAP_UNINITIALIZED \
+		| MAP_GROWSDOWN \
+		| MAP_LOCKED \
+		| MAP_NORESERVE \
+		| MAP_POPULATE \
+		| MAP_NONBLOCK \
+		| MAP_STACK \
+		| MAP_HUGETLB \
+		| MAP_32BIT \
+		| MAP_HUGE_2MB \
+		| MAP_HUGE_1GB)
+
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
 extern unsigned long sysctl_overcommit_kbytes;

commit 592e254502041f953e84d091eae2c68cba04c10b
Author: Jan Kara <jack@suse.cz>
Date:   Fri Nov 3 12:21:21 2017 +0100

    mm: Handle 0 flags in _calc_vm_trans() macro
    
    _calc_vm_trans() does not handle the situation when some of the passed
    flags are 0 (which can happen if these VM flags do not make sense for
    the architecture). Improve the _calc_vm_trans() macro to return 0 in
    such situation. Since all passed flags are constant, this does not add
    any runtime overhead.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index c8367041fafd..edb6cf6a81ed 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -63,8 +63,9 @@ static inline bool arch_validate_prot(unsigned long prot)
  * ("bit1" and "bit2" must be single bits)
  */
 #define _calc_vm_trans(x, bit1, bit2) \
+  ((!(bit1) || !(bit2)) ? 0 : \
   ((bit1) <= (bit2) ? ((x) & (bit1)) * ((bit2) / (bit1)) \
-   : ((x) & (bit1)) / ((bit1) / (bit2)))
+   : ((x) & (bit1)) / ((bit1) / (bit2))))
 
 /*
  * Combine the mmap "prot" argument into "vm_flags" used internally.

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index c8367041fafd..7c87b6652244 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LINUX_MMAN_H
 #define _LINUX_MMAN_H
 

commit 104b4e5139fe384431ac11c3b8a6cf4a529edf4a
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Jun 20 21:01:20 2017 +0300

    percpu_counter: Rename __percpu_counter_add to percpu_counter_add_batch
    
    Currently, percpu_counter_add is a wrapper around __percpu_counter_add
    which is preempt safe due to explicit calls to preempt_disable.  Given
    how __ prefix is used in percpu related interfaces, the naming
    unfortunately creates the false sense that __percpu_counter_add is
    less safe than percpu_counter_add.  In terms of context-safety,
    they're equivalent.  The only difference is that the __ version takes
    a batch parameter.
    
    Make this a bit more explicit by just renaming __percpu_counter_add to
    percpu_counter_add_batch.
    
    This patch doesn't cause any functional changes.
    
    tj: Minor updates to patch description for clarity.  Cosmetic
        indentation updates.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <jbacik@fb.com>
    Cc: David Sterba <dsterba@suse.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: linux-mm@kvack.org
    Cc: "David S. Miller" <davem@davemloft.net>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 634c4c51fe3a..c8367041fafd 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -22,7 +22,7 @@ unsigned long vm_memory_committed(void);
 
 static inline void vm_acct_memory(long pages)
 {
-	__percpu_counter_add(&vm_committed_as, pages, vm_committed_as_batch);
+	percpu_counter_add_batch(&vm_committed_as, pages, vm_committed_as_batch);
 }
 
 static inline void vm_unacct_memory(long pages)

commit 949bed2f5764435715e3d6dd3ab6dd4dbd890a71
Author: Chen Gang <chengang@emindsoft.com.cn>
Date:   Tue Aug 2 14:03:42 2016 -0700

    include: mman: use bool instead of int for the return value of arch_validate_prot
    
    For pure bool function's return value, bool is a little better more or
    less than int.
    
    Link: http://lkml.kernel.org/r/1469331815-2026-1-git-send-email-chengang@emindsoft.com.cn
    Signed-off-by: Chen Gang <gang.chen.5i5j@gmail.com>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 33e17f6a327a..634c4c51fe3a 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -49,7 +49,7 @@ static inline void vm_unacct_memory(long pages)
  *
  * Returns true if the prot flags are valid
  */
-static inline int arch_validate_prot(unsigned long prot)
+static inline bool arch_validate_prot(unsigned long prot)
 {
 	return (prot & ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM)) == 0;
 }

commit e6bfb70959a0ca6ddedb29e779a293c6f71ed0e7
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Feb 12 13:02:31 2016 -0800

    mm/core, arch, powerpc: Pass a protection key in to calc_vm_flag_bits()
    
    This plumbs a protection key through calc_vm_flag_bits().  We
    could have done this in calc_vm_prot_bits(), but I did not feel
    super strongly which way to go.  It was pretty arbitrary which
    one to use.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Arve Hjønnevåg <arve@android.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Chen Gang <gang.chen.5i5j@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Geliang Tang <geliangtang@163.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Leon Romanovsky <leon@leon.nu>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Maxime Coquelin <mcoquelin.stm32@gmail.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Riley Andrews <riandrews@android.com>
    Cc: Vladimir Davydov <vdavydov@virtuozzo.com>
    Cc: devel@driverdev.osuosl.org
    Cc: linux-api@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Link: http://lkml.kernel.org/r/20160212210231.E6F1F0D6@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 16373c8f5f57..33e17f6a327a 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -35,7 +35,7 @@ static inline void vm_unacct_memory(long pages)
  */
 
 #ifndef arch_calc_vm_prot_bits
-#define arch_calc_vm_prot_bits(prot) 0
+#define arch_calc_vm_prot_bits(prot, pkey) 0
 #endif
 
 #ifndef arch_vm_get_page_prot
@@ -70,12 +70,12 @@ static inline int arch_validate_prot(unsigned long prot)
  * Combine the mmap "prot" argument into "vm_flags" used internally.
  */
 static inline unsigned long
-calc_vm_prot_bits(unsigned long prot)
+calc_vm_prot_bits(unsigned long prot, unsigned long pkey)
 {
 	return _calc_vm_trans(prot, PROT_READ,  VM_READ ) |
 	       _calc_vm_trans(prot, PROT_WRITE, VM_WRITE) |
 	       _calc_vm_trans(prot, PROT_EXEC,  VM_EXEC) |
-	       arch_calc_vm_prot_bits(prot);
+	       arch_calc_vm_prot_bits(prot, pkey);
 }
 
 /*

commit 49f0ce5f92321cdcf741e35f385669a421013cb7
Author: Jerome Marchand <jmarchan@redhat.com>
Date:   Tue Jan 21 15:49:14 2014 -0800

    mm: add overcommit_kbytes sysctl variable
    
    Some applications that run on HPC clusters are designed around the
    availability of RAM and the overcommit ratio is fine tuned to get the
    maximum usage of memory without swapping.  With growing memory, the
    1%-of-all-RAM grain provided by overcommit_ratio has become too coarse
    for these workload (on a 2TB machine it represents no less than 20GB).
    
    This patch adds the new overcommit_kbytes sysctl variable that allow a
    much finer grain.
    
    [akpm@linux-foundation.org: coding-style fixes]
    [akpm@linux-foundation.org: fix nommu build]
    Signed-off-by: Jerome Marchand <jmarchan@redhat.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 7f7f8dae4b1d..16373c8f5f57 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -9,6 +9,7 @@
 
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
+extern unsigned long sysctl_overcommit_kbytes;
 extern struct percpu_counter vm_committed_as;
 
 #ifdef CONFIG_SMP

commit 00619bcc44d6b779aa366130b354153c222e4380
Author: Jerome Marchand <jmarchan@redhat.com>
Date:   Tue Nov 12 15:08:31 2013 -0800

    mm: factor commit limit calculation
    
    The same calculation is currently done in three differents places.
    Factor that code so future changes has to be made at only one place.
    
    [akpm@linux-foundation.org: uninline vm_commit_limit()]
    Signed-off-by: Jerome Marchand <jmarchan@redhat.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 92dc257251e4..7f7f8dae4b1d 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -87,4 +87,6 @@ calc_vm_flag_bits(unsigned long flags)
 	       _calc_vm_trans(flags, MAP_DENYWRITE,  VM_DENYWRITE ) |
 	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
 }
+
+unsigned long vm_commit_limit(void);
 #endif /* _LINUX_MMAN_H */

commit 917d9290af749fac9c4d90bacf18699c9d8ba28d
Author: Tim Chen <tim.c.chen@linux.intel.com>
Date:   Wed Jul 3 15:02:44 2013 -0700

    mm: tune vm_committed_as percpu_counter batching size
    
    Currently the per cpu counter's batch size for memory accounting is
    configured as twice the number of cpus in the system.  However, for
    system with very large memory, it is more appropriate to make it
    proportional to the memory size per cpu in the system.
    
    For example, for a x86_64 system with 64 cpus and 128 GB of memory, the
    batch size is only 2*64 pages (0.5 MB).  So any memory accounting
    changes of more than 0.5MB will overflow the per cpu counter into the
    global counter.  Instead, for the new scheme, the batch size is
    configured to be 0.4% of the memory/cpu = 8MB (128 GB/64 /256), which is
    more inline with the memory size.
    
    I've done a repeated brk test of 800KB (from will-it-scale test suite)
    with 80 concurrent processes on a 4 socket Westmere machine with a total
    of 40 cores.  Without the patch, about 80% of cpu is spent on spin-lock
    contention within the vm_committed_as counter.  With the patch, there's
    a 73x speedup on the benchmark and the lock contention drops off almost
    entirely.
    
    [akpm@linux-foundation.org: fix section mismatch]
    Signed-off-by: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 9aa863da287f..92dc257251e4 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -11,11 +11,17 @@ extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
 extern struct percpu_counter vm_committed_as;
 
+#ifdef CONFIG_SMP
+extern s32 vm_committed_as_batch;
+#else
+#define vm_committed_as_batch 0
+#endif
+
 unsigned long vm_memory_committed(void);
 
 static inline void vm_acct_memory(long pages)
 {
-	percpu_counter_add(&vm_committed_as, pages);
+	__percpu_counter_add(&vm_committed_as, pages, vm_committed_as_batch);
 }
 
 static inline void vm_unacct_memory(long pages)

commit 09a9f1d27892255cfb9c91203f19476765e2d8d1
Author: Michel Lespinasse <walken@google.com>
Date:   Thu Mar 28 16:26:23 2013 -0700

    Revert "mm: introduce VM_POPULATE flag to better deal with racy userspace programs"
    
    This reverts commit 186930500985 ("mm: introduce VM_POPULATE flag to
    better deal with racy userspace programs").
    
    VM_POPULATE only has any effect when userspace plays racy games with
    vmas by trying to unmap and remap memory regions that mmap or mlock are
    operating on.
    
    Also, the only effect of VM_POPULATE when userspace plays such games is
    that it avoids populating new memory regions that get remapped into the
    address range that was being operated on by the original mmap or mlock
    calls.
    
    Let's remove VM_POPULATE as there isn't any strong argument to mandate a
    new vm_flag.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 61c7a87e5d2b..9aa863da287f 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -79,8 +79,6 @@ calc_vm_flag_bits(unsigned long flags)
 {
 	return _calc_vm_trans(flags, MAP_GROWSDOWN,  VM_GROWSDOWN ) |
 	       _calc_vm_trans(flags, MAP_DENYWRITE,  VM_DENYWRITE ) |
-	       ((flags & MAP_LOCKED) ? (VM_LOCKED | VM_POPULATE) : 0) |
-	       (((flags & (MAP_POPULATE | MAP_NONBLOCK)) == MAP_POPULATE) ?
-							VM_POPULATE : 0);
+	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
 }
 #endif /* _LINUX_MMAN_H */

commit 1869305009857cdeaabe6283bcdc2359c5784543
Author: Michel Lespinasse <walken@google.com>
Date:   Fri Feb 22 16:32:46 2013 -0800

    mm: introduce VM_POPULATE flag to better deal with racy userspace programs
    
    The vm_populate() code populates user mappings without constantly
    holding the mmap_sem.  This makes it susceptible to racy userspace
    programs: the user mappings may change while vm_populate() is running,
    and in this case vm_populate() may end up populating the new mapping
    instead of the old one.
    
    In order to reduce the possibility of userspace getting surprised by
    this behavior, this change introduces the VM_POPULATE vma flag which
    gets set on vmas we want vm_populate() to work on.  This way
    vm_populate() may still end up populating the new mapping after such a
    race, but only if the new mapping is also one that the user has
    requested (using MAP_SHARED, MAP_LOCKED or mlock) to be populated.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Tested-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Greg Ungerer <gregungerer@westnet.com.au>
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 9aa863da287f..61c7a87e5d2b 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -79,6 +79,8 @@ calc_vm_flag_bits(unsigned long flags)
 {
 	return _calc_vm_trans(flags, MAP_GROWSDOWN,  VM_GROWSDOWN ) |
 	       _calc_vm_trans(flags, MAP_DENYWRITE,  VM_DENYWRITE ) |
-	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
+	       ((flags & MAP_LOCKED) ? (VM_LOCKED | VM_POPULATE) : 0) |
+	       (((flags & (MAP_POPULATE | MAP_NONBLOCK)) == MAP_POPULATE) ?
+							VM_POPULATE : 0);
 }
 #endif /* _LINUX_MMAN_H */

commit 997071bcb34005f42e0fe5bc7930e895b070f251
Author: K. Y. Srinivasan <kys@microsoft.com>
Date:   Thu Nov 15 14:34:42 2012 -0800

    mm: export a function to get vm committed memory
    
    It will be useful to be able to access global memory commitment from
    device drivers.  On the Hyper-V platform, the host has a policy engine to
    balance the available physical memory amongst all competing virtual
    machines hosted on a given node.  This policy engine is driven by a number
    of metrics including the memory commitment reported by the guests.  The
    balloon driver for Linux on Hyper-V will use this function to retrieve
    guest memory commitment.  This function is also used in Xen self
    ballooning code.
    
    [akpm@linux-foundation.org: coding-style tweak]
    Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Acked-by: Dan Magenheimer <dan.magenheimer@oracle.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index d09dde1e57fb..9aa863da287f 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -11,6 +11,8 @@ extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
 extern struct percpu_counter vm_committed_as;
 
+unsigned long vm_memory_committed(void);
+
 static inline void vm_acct_memory(long pages)
 {
 	percpu_counter_add(&vm_committed_as, pages);

commit 607ca46e97a1b6594b29647d98a32d545c24bdff
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 13 10:46:48 2012 +0100

    UAPI: (Scripted) Disintegrate include/linux
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 77cec2f45cb7..d09dde1e57fb 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -1,20 +1,11 @@
 #ifndef _LINUX_MMAN_H
 #define _LINUX_MMAN_H
 
-#include <asm/mman.h>
-
-#define MREMAP_MAYMOVE	1
-#define MREMAP_FIXED	2
-
-#define OVERCOMMIT_GUESS		0
-#define OVERCOMMIT_ALWAYS		1
-#define OVERCOMMIT_NEVER		2
-
-#ifdef __KERNEL__
 #include <linux/mm.h>
 #include <linux/percpu_counter.h>
 
 #include <linux/atomic.h>
+#include <uapi/linux/mman.h>
 
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
@@ -88,5 +79,4 @@ calc_vm_flag_bits(unsigned long flags)
 	       _calc_vm_trans(flags, MAP_DENYWRITE,  VM_DENYWRITE ) |
 	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
 }
-#endif /* __KERNEL__ */
 #endif /* _LINUX_MMAN_H */

commit e9714acf8c439688884234dcac2bfc38bb607d38
Author: Konstantin Khlebnikov <khlebnikov@openvz.org>
Date:   Mon Oct 8 16:28:54 2012 -0700

    mm: kill vma flag VM_EXECUTABLE and mm->num_exe_file_vmas
    
    Currently the kernel sets mm->exe_file during sys_execve() and then tracks
    number of vmas with VM_EXECUTABLE flag in mm->num_exe_file_vmas, as soon
    as this counter drops to zero kernel resets mm->exe_file to NULL.  Plus it
    resets mm->exe_file at last mmput() when mm->mm_users drops to zero.
    
    VMA with VM_EXECUTABLE flag appears after mapping file with flag
    MAP_EXECUTABLE, such vmas can appears only at sys_execve() or after vma
    splitting, because sys_mmap ignores this flag.  Usually binfmt module sets
    mm->exe_file and mmaps executable vmas with this file, they hold
    mm->exe_file while task is running.
    
    comment from v2.6.25-6245-g925d1c4 ("procfs task exe symlink"),
    where all this stuff was introduced:
    
    > The kernel implements readlink of /proc/pid/exe by getting the file from
    > the first executable VMA.  Then the path to the file is reconstructed and
    > reported as the result.
    >
    > Because of the VMA walk the code is slightly different on nommu systems.
    > This patch avoids separate /proc/pid/exe code on nommu systems.  Instead of
    > walking the VMAs to find the first executable file-backed VMA we store a
    > reference to the exec'd file in the mm_struct.
    >
    > That reference would prevent the filesystem holding the executable file
    > from being unmounted even after unmapping the VMAs.  So we track the number
    > of VM_EXECUTABLE VMAs and drop the new reference when the last one is
    > unmapped.  This avoids pinning the mounted filesystem.
    
    exe_file's vma accounting is hooked into every file mmap/unmmap and vma
    split/merge just to fix some hypothetical pinning fs from umounting by mm,
    which already unmapped all its executable files, but still alive.
    
    Seems like currently nobody depends on this behaviour.  We can try to
    remove this logic and keep mm->exe_file until final mmput().
    
    mm->exe_file is still protected with mm->mmap_sem, because we want to
    change it via new sys_prctl(PR_SET_MM_EXE_FILE).  Also via this syscall
    task can change its mm->exe_file and unpin mountpoint explicitly.
    
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Carsten Otte <cotte@de.ibm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: James Morris <james.l.morris@oracle.com>
    Cc: Jason Baron <jbaron@redhat.com>
    Cc: Kentaro Takeda <takedakn@nttdata.co.jp>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Robert Richter <robert.richter@amd.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Cc: Venkatesh Pallipadi <venki@google.com>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 8b74e9b1d0ad..77cec2f45cb7 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -86,7 +86,6 @@ calc_vm_flag_bits(unsigned long flags)
 {
 	return _calc_vm_trans(flags, MAP_GROWSDOWN,  VM_GROWSDOWN ) |
 	       _calc_vm_trans(flags, MAP_DENYWRITE,  VM_DENYWRITE ) |
-	       _calc_vm_trans(flags, MAP_EXECUTABLE, VM_EXECUTABLE) |
 	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
 }
 #endif /* __KERNEL__ */

commit 60063497a95e716c9a689af3be2687d261f115b4
Author: Arun Sharma <asharma@fb.com>
Date:   Tue Jul 26 16:09:06 2011 -0700

    atomic: use <linux/atomic.h>
    
    This allows us to move duplicated code in <asm/atomic.h>
    (atomic_inc_not_zero() for now) to <linux/atomic.h>
    
    Signed-off-by: Arun Sharma <asharma@fb.com>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 9872d6ca58ae..8b74e9b1d0ad 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -14,7 +14,7 @@
 #include <linux/mm.h>
 #include <linux/percpu_counter.h>
 
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;

commit 00a62ce91e554198ef28234c91c36f850f5a3bc9
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Thu Apr 30 15:08:51 2009 -0700

    mm: fix Committed_AS underflow on large NR_CPUS environment
    
    The Committed_AS field can underflow in certain situations:
    
    >         # while true; do cat /proc/meminfo  | grep _AS; sleep 1; done | uniq -c
    >               1 Committed_AS: 18446744073709323392 kB
    >              11 Committed_AS: 18446744073709455488 kB
    >               6 Committed_AS:    35136 kB
    >               5 Committed_AS: 18446744073709454400 kB
    >               7 Committed_AS:    35904 kB
    >               3 Committed_AS: 18446744073709453248 kB
    >               2 Committed_AS:    34752 kB
    >               9 Committed_AS: 18446744073709453248 kB
    >               8 Committed_AS:    34752 kB
    >               3 Committed_AS: 18446744073709320960 kB
    >               7 Committed_AS: 18446744073709454080 kB
    >               3 Committed_AS: 18446744073709320960 kB
    >               5 Committed_AS: 18446744073709454080 kB
    >               6 Committed_AS: 18446744073709320960 kB
    
    Because NR_CPUS can be greater than 1000 and meminfo_proc_show() does
    not check for underflow.
    
    But NR_CPUS proportional isn't good calculation.  In general,
    possibility of lock contention is proportional to the number of online
    cpus, not theorical maximum cpus (NR_CPUS).
    
    The current kernel has generic percpu-counter stuff.  using it is right
    way.  it makes code simplify and percpu_counter_read_positive() don't
    make underflow issue.
    
    Reported-by: Dave Hansen <dave@linux.vnet.ibm.com>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Eric B Munson <ebmunson@us.ibm.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Christoph Lameter <cl@linux-foundation.org>
    Cc: <stable@kernel.org>         [All kernel versions]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 30d1073bac3b..9872d6ca58ae 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -12,21 +12,18 @@
 
 #ifdef __KERNEL__
 #include <linux/mm.h>
+#include <linux/percpu_counter.h>
 
 #include <asm/atomic.h>
 
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
-extern atomic_long_t vm_committed_space;
+extern struct percpu_counter vm_committed_as;
 
-#ifdef CONFIG_SMP
-extern void vm_acct_memory(long pages);
-#else
 static inline void vm_acct_memory(long pages)
 {
-	atomic_long_add(pages, &vm_committed_space);
+	percpu_counter_add(&vm_committed_as, pages);
 }
-#endif
 
 static inline void vm_unacct_memory(long pages)
 {

commit b845f313d78e4e259ec449909e3bbadf77b53a6d
Author: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
Date:   Tue Jul 8 00:28:51 2008 +1000

    mm: Allow architectures to define additional protection bits
    
    This patch allows architectures to define functions to deal with
    additional protections bits for mmap() and mprotect().
    
    arch_calc_vm_prot_bits() maps additonal protection bits to vm_flags
    arch_vm_get_page_prot() maps additional vm_flags to the vma's vm_page_prot
    arch_validate_prot() checks for valid values of the protection bits
    
    Note: vm_get_page_prot() is now pretty ugly, but the generated code
    should be identical for architectures that don't define additional
    protection bits.
    
    Signed-off-by: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index dab8892e6ff1..30d1073bac3b 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -33,6 +33,32 @@ static inline void vm_unacct_memory(long pages)
 	vm_acct_memory(-pages);
 }
 
+/*
+ * Allow architectures to handle additional protection bits
+ */
+
+#ifndef arch_calc_vm_prot_bits
+#define arch_calc_vm_prot_bits(prot) 0
+#endif
+
+#ifndef arch_vm_get_page_prot
+#define arch_vm_get_page_prot(vm_flags) __pgprot(0)
+#endif
+
+#ifndef arch_validate_prot
+/*
+ * This is called from mprotect().  PROT_GROWSDOWN and PROT_GROWSUP have
+ * already been masked out.
+ *
+ * Returns true if the prot flags are valid
+ */
+static inline int arch_validate_prot(unsigned long prot)
+{
+	return (prot & ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM)) == 0;
+}
+#define arch_validate_prot arch_validate_prot
+#endif
+
 /*
  * Optimisation macro.  It is equivalent to:
  *      (x & bit1) ? bit2 : 0
@@ -51,7 +77,8 @@ calc_vm_prot_bits(unsigned long prot)
 {
 	return _calc_vm_trans(prot, PROT_READ,  VM_READ ) |
 	       _calc_vm_trans(prot, PROT_WRITE, VM_WRITE) |
-	       _calc_vm_trans(prot, PROT_EXEC,  VM_EXEC );
+	       _calc_vm_trans(prot, PROT_EXEC,  VM_EXEC) |
+	       arch_calc_vm_prot_bits(prot);
 }
 
 /*

commit 80119ef5c8153e0a6cc5edf00c083dc98a9bd348
Author: Alan Cox <alan@redhat.com>
Date:   Fri May 23 13:04:31 2008 -0700

    mm: fix atomic_t overflow in vm
    
    The atomic_t type is 32bit but a 64bit system can have more than 2^32
    pages of virtual address space available.  Without this we overflow on
    ludicrously large mappings
    
    Signed-off-by: Alan Cox <alan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 87920a0852a3..dab8892e6ff1 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -17,14 +17,14 @@
 
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
-extern atomic_t vm_committed_space;
+extern atomic_long_t vm_committed_space;
 
 #ifdef CONFIG_SMP
 extern void vm_acct_memory(long pages);
 #else
 static inline void vm_acct_memory(long pages)
 {
-	atomic_add(pages, &vm_committed_space);
+	atomic_long_add(pages, &vm_committed_space);
 }
 #endif
 

commit 62c4f0a2d5a188f73a94f2cb8ea0dba3e7cf0a7f
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Wed Apr 26 12:56:16 2006 +0100

    Don't include linux/config.h from anywhere else in include/
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 4ad21c5863fd..87920a0852a3 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -11,7 +11,6 @@
 #define OVERCOMMIT_NEVER		2
 
 #ifdef __KERNEL__
-#include <linux/config.h>
 #include <linux/mm.h>
 
 #include <asm/atomic.h>

commit 9cdcb56636717ccb935dc66c5d56681eaa5941c1
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Tue Apr 25 14:18:07 2006 +0100

    Sanitise linux/mman.h for userspace consumption
    
    It only really needs to define a few constants and include <asm/mman.h>
    when it's used by userspace. Move the rest within #ifdef __KERNEL__
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/include/linux/mman.h b/include/linux/mman.h
index 18a5689ef748..4ad21c5863fd 100644
--- a/include/linux/mman.h
+++ b/include/linux/mman.h
@@ -1,10 +1,6 @@
 #ifndef _LINUX_MMAN_H
 #define _LINUX_MMAN_H
 
-#include <linux/config.h>
-#include <linux/mm.h>
-
-#include <asm/atomic.h>
 #include <asm/mman.h>
 
 #define MREMAP_MAYMOVE	1
@@ -13,6 +9,13 @@
 #define OVERCOMMIT_GUESS		0
 #define OVERCOMMIT_ALWAYS		1
 #define OVERCOMMIT_NEVER		2
+
+#ifdef __KERNEL__
+#include <linux/config.h>
+#include <linux/mm.h>
+
+#include <asm/atomic.h>
+
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
 extern atomic_t vm_committed_space;
@@ -63,5 +66,5 @@ calc_vm_flag_bits(unsigned long flags)
 	       _calc_vm_trans(flags, MAP_EXECUTABLE, VM_EXECUTABLE) |
 	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
 }
-
+#endif /* __KERNEL__ */
 #endif /* _LINUX_MMAN_H */

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/include/linux/mman.h b/include/linux/mman.h
new file mode 100644
index 000000000000..18a5689ef748
--- /dev/null
+++ b/include/linux/mman.h
@@ -0,0 +1,67 @@
+#ifndef _LINUX_MMAN_H
+#define _LINUX_MMAN_H
+
+#include <linux/config.h>
+#include <linux/mm.h>
+
+#include <asm/atomic.h>
+#include <asm/mman.h>
+
+#define MREMAP_MAYMOVE	1
+#define MREMAP_FIXED	2
+
+#define OVERCOMMIT_GUESS		0
+#define OVERCOMMIT_ALWAYS		1
+#define OVERCOMMIT_NEVER		2
+extern int sysctl_overcommit_memory;
+extern int sysctl_overcommit_ratio;
+extern atomic_t vm_committed_space;
+
+#ifdef CONFIG_SMP
+extern void vm_acct_memory(long pages);
+#else
+static inline void vm_acct_memory(long pages)
+{
+	atomic_add(pages, &vm_committed_space);
+}
+#endif
+
+static inline void vm_unacct_memory(long pages)
+{
+	vm_acct_memory(-pages);
+}
+
+/*
+ * Optimisation macro.  It is equivalent to:
+ *      (x & bit1) ? bit2 : 0
+ * but this version is faster.
+ * ("bit1" and "bit2" must be single bits)
+ */
+#define _calc_vm_trans(x, bit1, bit2) \
+  ((bit1) <= (bit2) ? ((x) & (bit1)) * ((bit2) / (bit1)) \
+   : ((x) & (bit1)) / ((bit1) / (bit2)))
+
+/*
+ * Combine the mmap "prot" argument into "vm_flags" used internally.
+ */
+static inline unsigned long
+calc_vm_prot_bits(unsigned long prot)
+{
+	return _calc_vm_trans(prot, PROT_READ,  VM_READ ) |
+	       _calc_vm_trans(prot, PROT_WRITE, VM_WRITE) |
+	       _calc_vm_trans(prot, PROT_EXEC,  VM_EXEC );
+}
+
+/*
+ * Combine the mmap "flags" argument into "vm_flags" used internally.
+ */
+static inline unsigned long
+calc_vm_flag_bits(unsigned long flags)
+{
+	return _calc_vm_trans(flags, MAP_GROWSDOWN,  VM_GROWSDOWN ) |
+	       _calc_vm_trans(flags, MAP_DENYWRITE,  VM_DENYWRITE ) |
+	       _calc_vm_trans(flags, MAP_EXECUTABLE, VM_EXECUTABLE) |
+	       _calc_vm_trans(flags, MAP_LOCKED,     VM_LOCKED    );
+}
+
+#endif /* _LINUX_MMAN_H */
