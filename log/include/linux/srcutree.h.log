commit 056b89e7e699742cc060ce722d3f26effe51b4aa
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Thu Apr 11 16:24:21 2019 -0400

    module: Make srcu_struct ptr array as read-only
    
    Since commit title ("srcu: Allocate per-CPU data for DEFINE_SRCU() in
    modules"), modules that call DEFINE_{STATIC,}SRCU will have a new array
    of srcu_struct pointers, which is used by srcu code to initialize and
    clean up these structures and save valuable per-cpu reserved space.
    
    There is no reason for this array of pointers to be writable, and can
    cause security or other hidden bugs. Mark these are read-only after the
    module init has completed.
    
    Tested with the following diff to ensure array not writable:
    
    (diff is a bit reduced to avoid patch command getting confused)
     a/kernel/module.c
     b/kernel/module.c
      -3506,6 +3506,14  static noinline int do_init_module [snip]
            rcu_assign_pointer(mod->kallsyms, &mod->core_kallsyms);
     #endif
            module_enable_ro(mod, true);
    +
    +       if (mod->srcu_struct_ptrs) {
    +               // Check if srcu_struct_ptrs access is possible
    +               char x = *(char *)mod->srcu_struct_ptrs;
    +               *(char *)mod->srcu_struct_ptrs = 0;
    +               *(char *)mod->srcu_struct_ptrs = x;
    +       }
    +
            mod_tree_remove_init(mod);
            disable_ro_nx(&mod->init_layout);
            module_arch_freeing_init(mod);
    
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: paulmck@linux.vnet.ibm.com
    Cc: rostedt@goodmis.org
    Cc: mathieu.desnoyers@efficios.com
    Cc: rcu@vger.kernel.org
    Cc: kernel-hardening@lists.openwall.com
    Cc: kernel-team@android.com
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 8af1824c46a8..9cfcc8a756ae 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -123,7 +123,7 @@ struct srcu_struct {
 #ifdef MODULE
 # define __DEFINE_SRCU(name, is_static)					\
 	is_static struct srcu_struct name;				\
-	struct srcu_struct *__srcu_struct_##name			\
+	struct srcu_struct * const __srcu_struct_##name			\
 		__section("___srcu_struct_ptrs") = &name
 #else
 # define __DEFINE_SRCU(name, is_static)					\

commit fe15b50cdeeebd9248bf27e3c31278668f08bc04
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Fri Apr 5 16:15:00 2019 -0700

    srcu: Allocate per-CPU data for DEFINE_SRCU() in modules
    
    Adding DEFINE_SRCU() or DEFINE_STATIC_SRCU() to a loadable module requires
    that the size of the reserved region be increased, which is not something
    we want to be doing all that often.  One approach would be to require
    that loadable modules define an srcu_struct and invoke init_srcu_struct()
    from their module_init function and cleanup_srcu_struct() from their
    module_exit function.  However, this is more than a bit user unfriendly.
    
    This commit therefore creates an ___srcu_struct_ptrs linker section,
    and pointers to srcu_struct structures created by DEFINE_SRCU() and
    DEFINE_STATIC_SRCU() within a module are placed into that module's
    ___srcu_struct_ptrs section.  The required init_srcu_struct() and
    cleanup_srcu_struct() functions are then automatically invoked as needed
    when that module is loaded and unloaded, thus allowing modules to continue
    to use DEFINE_SRCU() and DEFINE_STATIC_SRCU() while avoiding the need
    to increase the size of the reserved region.
    
    Many of the algorithms and some of the code was cheerfully cherry-picked
    from other code making use of linker sections, perhaps most notably from
    tracepoints.  All bugs are nevertheless the sole property of the author.
    
    Suggested-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    [ paulmck: Use __section() and use "default" in srcu_module_notify()'s
      "switch" statement as suggested by Joel Fernandes. ]
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Tested-by: Joel Fernandes (Google) <joel@joelfernandes.org>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 7f7c8c050f63..8af1824c46a8 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -120,9 +120,17 @@ struct srcu_struct {
  *
  * See include/linux/percpu-defs.h for the rules on per-CPU variables.
  */
-#define __DEFINE_SRCU(name, is_static)					\
-	static DEFINE_PER_CPU(struct srcu_data, name##_srcu_data);\
-	is_static struct srcu_struct name = __SRCU_STRUCT_INIT(name, name##_srcu_data)
+#ifdef MODULE
+# define __DEFINE_SRCU(name, is_static)					\
+	is_static struct srcu_struct name;				\
+	struct srcu_struct *__srcu_struct_##name			\
+		__section("___srcu_struct_ptrs") = &name
+#else
+# define __DEFINE_SRCU(name, is_static)					\
+	static DEFINE_PER_CPU(struct srcu_data, name##_srcu_data);	\
+	is_static struct srcu_struct name =				\
+		__SRCU_STRUCT_INIT(name, name##_srcu_data)
+#endif
 #define DEFINE_SRCU(name)		__DEFINE_SRCU(name, /* not static */)
 #define DEFINE_STATIC_SRCU(name)	__DEFINE_SRCU(name, static)
 

commit e7ffb4eb9a6d89678e7f62461737899f88dab64e
Merge: 87d1779dc48f 423a86a610ca 6706dae90d85 5a4eb3cb2012 e81baf4cb19a 6684880a8b16
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Sat Feb 9 08:47:52 2019 -0800

    Merge branches 'doc.2019.01.26a', 'fixes.2019.01.26a', 'sil.2019.01.26a', 'spdx.2019.02.09a', 'srcu.2019.01.26a' and 'torture.2019.01.26a' into HEAD
    
    doc.2019.01.26a:  Documentation updates.
    fixes.2019.01.26a:  Miscellaneous fixes.
    sil.2019.01.26a:  Removal of a few more spin_is_locked() instances.
    spdx.2019.02.09a:  Add SPDX identifiers to RCU files
    srcu.2019.01.26a:  SRCU updates.
    torture.2019.01.26a: Torture-test updates.

commit 8c366db05b1f27fac01a7dbf9e4904d499bd5d55
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Thu Jan 17 10:39:22 2019 -0800

    linux/srcu: Convert to SPDX license identifier
    
    Replace the license boiler plate with a SPDX license identifier.
    While in the area, update an email address.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    [ paulmck: Update ,h SPDX format per Joe Perches. ]
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 6f292bd3e7db..de7a42116b2e 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -1,24 +1,11 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
 /*
  * Sleepable Read-Copy Update mechanism for mutual exclusion,
  *	tree variant.
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, you can access it online at
- * http://www.gnu.org/licenses/gpl-2.0.html.
- *
  * Copyright (C) IBM Corporation, 2017
  *
- * Author: Paul McKenney <paulmck@us.ibm.com>
+ * Author: Paul McKenney <paulmck@linux.ibm.com>
  */
 
 #ifndef _LINUX_SRCU_TREE_H

commit e81baf4cb19a9b428ba477fd0423f81672a58817
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Dec 11 12:12:38 2018 +0100

    srcu: Remove srcu_queue_delayed_work_on()
    
    srcu_queue_delayed_work_on() disables preemption (and therefore CPU
    hotplug in RCU's case) and then checks based on its own accounting if a
    CPU is online. If the CPU is online it uses queue_delayed_work_on()
    otherwise it fallbacks to queue_delayed_work().
    The problem here is that queue_work() on -RT does not work with disabled
    preemption.
    
    queue_work_on() works also on an offlined CPU. queue_delayed_work_on()
    has the problem that it is possible to program a timer on an offlined
    CPU. This timer will fire once the CPU is online again. But until then,
    the timer remains programmed and nothing will happen.
    
    Add a local timer which will fire (as requested per delay) on the local
    CPU and then enqueue the work on the specific CPU.
    
    RCUtorture testing with SRCU-P for 24h showed no problems.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 6f292bd3e7db..0faa978c9880 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -45,7 +45,8 @@ struct srcu_data {
 	unsigned long srcu_gp_seq_needed;	/* Furthest future GP needed. */
 	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
 	bool srcu_cblist_invoking;		/* Invoking these CBs? */
-	struct delayed_work work;		/* Context for CB invoking. */
+	struct timer_list delay_work;		/* Delay for CB invoking */
+	struct work_struct work;		/* Context for CB invoking. */
 	struct rcu_head srcu_barrier_head;	/* For srcu_barrier() use. */
 	struct srcu_node *mynode;		/* Leaf srcu_node. */
 	unsigned long grpmask;			/* Mask for leaf srcu_node */

commit aacb5d91ab1bfbb0e8123da59a2e333d52ba7f60
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Sun Oct 28 10:32:51 2018 -0700

    srcu: Use "ssp" instead of "sp" for srcu_struct pointer
    
    In RCU, the distinction between "rsp", "rnp", and "rdp" has served well
    for a great many years, but in SRCU, "sp" vs. "sdp" has proven confusing.
    This commit therefore renames SRCU's "sp" pointers to "ssp", so that there
    is "ssp" for srcu_struct pointer, "snp" for srcu_node pointer, and "sdp"
    for srcu_data pointer.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 0ae91b3a7406..6f292bd3e7db 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -51,7 +51,7 @@ struct srcu_data {
 	unsigned long grpmask;			/* Mask for leaf srcu_node */
 						/*  ->srcu_data_have_cbs[]. */
 	int cpu;
-	struct srcu_struct *sp;
+	struct srcu_struct *ssp;
 };
 
 /*
@@ -138,8 +138,8 @@ struct srcu_struct {
 #define DEFINE_SRCU(name)		__DEFINE_SRCU(name, /* not static */)
 #define DEFINE_STATIC_SRCU(name)	__DEFINE_SRCU(name, static)
 
-void synchronize_srcu_expedited(struct srcu_struct *sp);
-void srcu_barrier(struct srcu_struct *sp);
-void srcu_torture_stats_print(struct srcu_struct *sp, char *tt, char *tf);
+void synchronize_srcu_expedited(struct srcu_struct *ssp);
+void srcu_barrier(struct srcu_struct *ssp);
+void srcu_torture_stats_print(struct srcu_struct *ssp, char *tt, char *tf);
 
 #endif

commit 4e6ea4ef56f9425cd239ffdb6be45b3aeeb347fd
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 14 14:41:49 2018 -0700

    srcu: Make early-boot call_srcu() reuse workqueue lists
    
    Allocating a list_head structure that is almost never used, and, when
    used, is used only during early boot (rcu_init() and earlier), is a bit
    wasteful.  This commit therefore eliminates that list_head in favor of
    the one in the work_struct structure.  This is safe because the work_struct
    structure cannot be used until after rcu_init() returns.
    
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Lai Jiangshan <jiangshanlai@gmail.com>
    Tested-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 9cfa4610113a..0ae91b3a7406 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -94,7 +94,6 @@ struct srcu_struct {
 						/*  callback for the barrier */
 						/*  operation. */
 	struct delayed_work work;
-	struct list_head srcu_boot_entry;	/* Early-boot callbacks. */
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 	struct lockdep_map dep_map;
 #endif /* #ifdef CONFIG_DEBUG_LOCK_ALLOC */
@@ -110,7 +109,7 @@ struct srcu_struct {
 	.sda = &pcpu_name,						\
 	.lock = __SPIN_LOCK_UNLOCKED(name.lock),			\
 	.srcu_gp_seq_needed = -1UL,					\
-	.srcu_boot_entry = LIST_HEAD_INIT(name.srcu_boot_entry),	\
+	.work = __DELAYED_WORK_INITIALIZER(name.work, NULL, 0),		\
 	__SRCU_DEP_MAP_INIT(name)					\
 }
 

commit e0fcba9ac02af5aeb1e1c3e842eab987f817c309
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 14 08:45:54 2018 -0700

    srcu: Make call_srcu() available during very early boot
    
    Event tracing is moving to SRCU in order to take advantage of the fact
    that SRCU may be safely used from idle and even offline CPUs.  However,
    event tracing can invoke call_srcu() very early in the boot process,
    even before workqueue_init_early() is invoked (let alone rcu_init()).
    Therefore, call_srcu()'s attempts to queue work fail miserably.
    
    This commit therefore detects this situation, and refrains from attempting
    to queue work before rcu_init() time, but does everything else that it
    would have done, and in addition, adds the srcu_struct to a global list.
    The rcu_init() function now invokes a new srcu_init() function, which
    is empty if CONFIG_SRCU=n.  Otherwise, srcu_init() queues work for
    each srcu_struct on the list.  This all happens early enough in boot
    that there is but a single CPU with interrupts disabled, which allows
    synchronization to be dispensed with.
    
    Of course, the queued work won't actually be invoked until after
    workqueue_init() is invoked, which happens shortly after the scheduler
    is up and running.  This means that although call_srcu() may be invoked
    any time after per-CPU variables have been set up, there is still a very
    narrow window when synchronize_srcu() won't work, and this window
    extends from the time that the scheduler starts until the time that
    workqueue_init() returns.  This can be fixed in a manner similar to
    the fix for synchronize_rcu_expedited() and friends, but until someone
    actually needs to use synchronize_srcu() during this window, this fix
    is added churn for no benefit.
    
    Finally, note that Tree SRCU's new srcu_init() function invokes
    queue_work() rather than the queue_delayed_work() function that is
    invoked post-boot.  The reason is that queue_delayed_work() will (as you
    would expect) post a timer, and timers have not yet been initialized.
    So use of queue_work() avoids the complaints about use of uninitialized
    spinlocks that would otherwise result.  Besides, some delay is already
    provide by the aforementioned fact that the queued work won't actually
    be invoked until after the scheduler is up and running.
    
    Requested-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 745d4ca4dd50..9cfa4610113a 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -94,6 +94,7 @@ struct srcu_struct {
 						/*  callback for the barrier */
 						/*  operation. */
 	struct delayed_work work;
+	struct list_head srcu_boot_entry;	/* Early-boot callbacks. */
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 	struct lockdep_map dep_map;
 #endif /* #ifdef CONFIG_DEBUG_LOCK_ALLOC */
@@ -105,12 +106,13 @@ struct srcu_struct {
 #define SRCU_STATE_SCAN2	2
 
 #define __SRCU_STRUCT_INIT(name, pcpu_name)				\
-	{								\
-		.sda = &pcpu_name,					\
-		.lock = __SPIN_LOCK_UNLOCKED(name.lock),		\
-		.srcu_gp_seq_needed = 0 - 1,				\
-		__SRCU_DEP_MAP_INIT(name)				\
-	}
+{									\
+	.sda = &pcpu_name,						\
+	.lock = __SPIN_LOCK_UNLOCKED(name.lock),			\
+	.srcu_gp_seq_needed = -1UL,					\
+	.srcu_boot_entry = LIST_HEAD_INIT(name.srcu_boot_entry),	\
+	__SRCU_DEP_MAP_INIT(name)					\
+}
 
 /*
  * Define and initialize a srcu struct at build time.

commit 9c80172b902db58233346adbb139cfdcb9229f0f
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Fri May 25 12:19:57 2018 +0200

    kernel/SRCU: provide a static initializer
    
    There are macros for static initializer for the three out of four
    possible notifier types, that are:
            ATOMIC_NOTIFIER_HEAD()
            BLOCKING_NOTIFIER_HEAD()
            RAW_NOTIFIER_HEAD()
    
    This patch provides a static initilizer for the forth type to make it
    complete.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Tested-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 4eda108abee0..745d4ca4dd50 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -104,9 +104,9 @@ struct srcu_struct {
 #define SRCU_STATE_SCAN1	1
 #define SRCU_STATE_SCAN2	2
 
-#define __SRCU_STRUCT_INIT(name)					\
+#define __SRCU_STRUCT_INIT(name, pcpu_name)				\
 	{								\
-		.sda = &name##_srcu_data,				\
+		.sda = &pcpu_name,					\
 		.lock = __SPIN_LOCK_UNLOCKED(name.lock),		\
 		.srcu_gp_seq_needed = 0 - 1,				\
 		__SRCU_DEP_MAP_INIT(name)				\
@@ -133,7 +133,7 @@ struct srcu_struct {
  */
 #define __DEFINE_SRCU(name, is_static)					\
 	static DEFINE_PER_CPU(struct srcu_data, name##_srcu_data);\
-	is_static struct srcu_struct name = __SRCU_STRUCT_INIT(name)
+	is_static struct srcu_struct name = __SRCU_STRUCT_INIT(name, name##_srcu_data)
 #define DEFINE_SRCU(name)		__DEFINE_SRCU(name, /* not static */)
 #define DEFINE_STATIC_SRCU(name)	__DEFINE_SRCU(name, static)
 

commit d633198088bd9e358566c470ed182994403acc7a
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Oct 10 13:52:30 2017 -0700

    srcu: Prohibit call_srcu() use under raw spinlocks
    
    Invoking queue_delayed_work() while holding a raw spinlock is forbidden
    in -rt kernels, which is exactly what __call_srcu() does, indirectly via
    srcu_funnel_gp_start().  This commit therefore downgrades Tree SRCU's
    locking from raw to non-raw spinlocks, which works because call_srcu()
    is not ever called while holding a raw spinlock.
    
    Reported-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index a949f4f9e4d7..4eda108abee0 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -40,7 +40,7 @@ struct srcu_data {
 	unsigned long srcu_unlock_count[2];	/* Unlocks per CPU. */
 
 	/* Update-side state. */
-	raw_spinlock_t __private lock ____cacheline_internodealigned_in_smp;
+	spinlock_t __private lock ____cacheline_internodealigned_in_smp;
 	struct rcu_segcblist srcu_cblist;	/* List of callbacks.*/
 	unsigned long srcu_gp_seq_needed;	/* Furthest future GP needed. */
 	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
@@ -58,7 +58,7 @@ struct srcu_data {
  * Node in SRCU combining tree, similar in function to rcu_data.
  */
 struct srcu_node {
-	raw_spinlock_t __private lock;
+	spinlock_t __private lock;
 	unsigned long srcu_have_cbs[4];		/* GP seq for children */
 						/*  having CBs, but only */
 						/*  is > ->srcu_gq_seq. */
@@ -78,7 +78,7 @@ struct srcu_struct {
 	struct srcu_node *level[RCU_NUM_LVLS + 1];
 						/* First node at each level. */
 	struct mutex srcu_cb_mutex;		/* Serialize CB preparation. */
-	raw_spinlock_t __private lock;		/* Protect counters */
+	spinlock_t __private lock;		/* Protect counters */
 	struct mutex srcu_gp_mutex;		/* Serialize GP work. */
 	unsigned int srcu_idx;			/* Current rdr array element. */
 	unsigned long srcu_gp_seq;		/* Grace-period seq #. */
@@ -107,7 +107,7 @@ struct srcu_struct {
 #define __SRCU_STRUCT_INIT(name)					\
 	{								\
 		.sda = &name##_srcu_data,				\
-		.lock = __RAW_SPIN_LOCK_UNLOCKED(name.lock),		\
+		.lock = __SPIN_LOCK_UNLOCKED(name.lock),		\
 		.srcu_gp_seq_needed = 0 - 1,				\
 		__SRCU_DEP_MAP_INIT(name)				\
 	}

commit 656e7c0c0a2e8d899f87fd7f081ea7a711146604
Merge: 850bf6d59265 16c0b106070f 09efeeee173e 22e4ebb97582 952111d7db02 35732cf9dd38 f34c8585ed70
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Aug 17 08:10:04 2017 -0700

    Merge branches 'doc.2017.08.17a', 'fixes.2017.08.17a', 'hotplug.2017.07.25b', 'misc.2017.08.17a', 'spin_unlock_wait_no.2017.08.17a', 'srcu.2017.07.27c' and 'torture.2017.07.24c' into HEAD
    
    doc.2017.08.17a: Documentation updates.
    fixes.2017.08.17a: RCU fixes.
    hotplug.2017.07.25b: CPU-hotplug updates.
    misc.2017.08.17a: Miscellaneous fixes outside of RCU (give or take conflicts).
    spin_unlock_wait_no.2017.08.17a: Remove spin_unlock_wait().
    srcu.2017.07.27c: SRCU updates.
    torture.2017.07.24c: Torture-test updates.

commit 115a1a5285664f1931c30457081b4ae1e648f1f9
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon May 22 13:31:03 2017 -0700

    rcutorture: Move SRCU status printing to SRCU implementations
    
    This commit gets rid of some ugly #ifdefs in rcutorture.c by moving
    the SRCU status printing to the SRCU implementations.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 42973f787e7e..7886356bdc84 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -141,5 +141,6 @@ void process_srcu(struct work_struct *work);
 
 void synchronize_srcu_expedited(struct srcu_struct *sp);
 void srcu_barrier(struct srcu_struct *sp);
+void srcu_torture_stats_print(struct srcu_struct *sp, char *tt, char *tf);
 
 #endif

commit 0d8a1e831e21d955af68f4ae5658b58b7ec25557
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jun 15 17:06:38 2017 -0700

    srcu: Make process_srcu() be static
    
    The function process_srcu() is not invoked outside of srcutree.c, so
    this commit makes it static and drops the EXPORT_SYMBOL_GPL().
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 42973f787e7e..a026a9493bde 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -104,8 +104,6 @@ struct srcu_struct {
 #define SRCU_STATE_SCAN1	1
 #define SRCU_STATE_SCAN2	2
 
-void process_srcu(struct work_struct *work);
-
 #define __SRCU_STRUCT_INIT(name)					\
 	{								\
 		.sda = &name##_srcu_data,				\

commit a3883df3935e10caa8297719d85fa8eaff7cabbd
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 9 15:00:14 2017 -0700

    srcu: Use rnp->lock wrappers to replace explicit memory barriers
    
    This commit uses TREE RCU's rnp->lock wrappers to replace a few explicit
    memory barriers.  This change also has the advantage of making SRCU's
    memory-ordering properties be implemented in roughly the same way as they
    are in Tree RCU.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 24e949bda12a..42973f787e7e 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -40,7 +40,7 @@ struct srcu_data {
 	unsigned long srcu_unlock_count[2];	/* Unlocks per CPU. */
 
 	/* Update-side state. */
-	spinlock_t lock ____cacheline_internodealigned_in_smp;
+	raw_spinlock_t __private lock ____cacheline_internodealigned_in_smp;
 	struct rcu_segcblist srcu_cblist;	/* List of callbacks.*/
 	unsigned long srcu_gp_seq_needed;	/* Furthest future GP needed. */
 	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
@@ -58,7 +58,7 @@ struct srcu_data {
  * Node in SRCU combining tree, similar in function to rcu_data.
  */
 struct srcu_node {
-	spinlock_t lock;
+	raw_spinlock_t __private lock;
 	unsigned long srcu_have_cbs[4];		/* GP seq for children */
 						/*  having CBs, but only */
 						/*  is > ->srcu_gq_seq. */
@@ -78,7 +78,7 @@ struct srcu_struct {
 	struct srcu_node *level[RCU_NUM_LVLS + 1];
 						/* First node at each level. */
 	struct mutex srcu_cb_mutex;		/* Serialize CB preparation. */
-	spinlock_t gp_lock;			/* protect ->srcu_cblist */
+	raw_spinlock_t __private lock;		/* Protect counters */
 	struct mutex srcu_gp_mutex;		/* Serialize GP work. */
 	unsigned int srcu_idx;			/* Current rdr array element. */
 	unsigned long srcu_gp_seq;		/* Grace-period seq #. */
@@ -109,7 +109,7 @@ void process_srcu(struct work_struct *work);
 #define __SRCU_STRUCT_INIT(name)					\
 	{								\
 		.sda = &name##_srcu_data,				\
-		.gp_lock = __SPIN_LOCK_UNLOCKED(name.gp_lock),		\
+		.lock = __RAW_SPIN_LOCK_UNLOCKED(name.lock),		\
 		.srcu_gp_seq_needed = 0 - 1,				\
 		__SRCU_DEP_MAP_INIT(name)				\
 	}

commit 5a0465e17a18c467b712a816985b7b8dd8d10c16
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu May 4 11:31:04 2017 -0700

    srcu: Shrink srcu.h by moving docbook and private function
    
    The call_srcu() docbook entry is currently in include/linux/srcu.h,
    which causes needless processing for each include point.  This commit
    therefore moves this entry to kernel/rcu/srcutree.c, which the compiler
    reads only once.  In addition, the srcu_batches_completed() function is
    used only within RCU and its torture-test suites.  This commit therefore
    also moves this function's declaration from include/linux/srcutiny.h,
    include/linux/srcutree.h, and include/linux/srcuclassic.h to
    kernel/rcu/rcu.h.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index f4adfed17b51..24e949bda12a 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -141,6 +141,5 @@ void process_srcu(struct work_struct *work);
 
 void synchronize_srcu_expedited(struct srcu_struct *sp);
 void srcu_barrier(struct srcu_struct *sp);
-unsigned long srcu_batches_completed(struct srcu_struct *sp);
 
 #endif

commit cad7b3897279c869de61dc88133037b941f84233
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 10:22:57 2017 -0700

    rcu: Move torture-related definitions from rcupdate.h to rcu.h
    
    The include/linux/rcupdate.h file contains a number of definitions that
    are used only to communicate between rcutorture, rcuperf, and the RCU code
    itself.  There is no point in having these definitions exposed globally
    throughout the kernel, so this commit moves them to kernel/rcu/rcu.h.
    This change has the added benefit of shrinking rcupdate.h.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 32e86d85fd11..f4adfed17b51 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -143,8 +143,4 @@ void synchronize_srcu_expedited(struct srcu_struct *sp);
 void srcu_barrier(struct srcu_struct *sp);
 unsigned long srcu_batches_completed(struct srcu_struct *sp);
 
-void srcutorture_get_gp_data(enum rcutorture_type test_type,
-			     struct srcu_struct *sp, int *flags,
-			     unsigned long *gpnum, unsigned long *completed);
-
 #endif

commit 22607d66bbc3e81140d3bcf08894f4378eb36428
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 25 14:03:11 2017 -0700

    srcu: Specify auto-expedite holdoff time
    
    On small systems, in the absence of readers, expedited SRCU grace
    periods can complete in less than a microsecond.  This means that an
    eight-CPU system can have all CPUs doing synchronize_srcu() in a tight
    loop and almost always expedite.  This might actually be desirable in
    some situations, but in general it is a good way to needlessly burn
    CPU cycles.  And in those situations where it is desirable, your friend
    is the function synchronize_srcu_expedited().
    
    For other situations, this commit adds a kernel parameter that specifies
    a holdoff between completing the last SRCU grace period and auto-expediting
    the next.  If the next grace period starts before the holdoff expires,
    auto-expediting is disabled.  The holdoff is 50 microseconds by default,
    and can be tuned to the desired number of nanoseconds.  A value of zero
    disables auto-expediting.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Mike Galbraith <efault@gmx.de>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 86df48d3e97b..32e86d85fd11 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -84,6 +84,7 @@ struct srcu_struct {
 	unsigned long srcu_gp_seq;		/* Grace-period seq #. */
 	unsigned long srcu_gp_seq_needed;	/* Latest gp_seq needed. */
 	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
+	unsigned long srcu_last_gp_end;		/* Last GP end timestamp (ns) */
 	struct srcu_data __percpu *sda;		/* Per-CPU srcu_data array. */
 	unsigned long srcu_barrier_seq;		/* srcu_barrier seq #. */
 	struct mutex srcu_barrier_mutex;	/* Serialize barrier ops. */

commit 1e9a038b7fe9a8c10ef1238f4e695d5fbe0dd594
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Apr 24 16:02:09 2017 -0700

    srcu: Expedited grace periods with reduced memory contention
    
    Commit f60d231a87c5 ("srcu: Crude control of expedited grace periods")
    introduced a per-srcu_struct atomic counter to track outstanding
    requests for grace periods.  This works, but represents a memory-contention
    bottleneck.  This commit therefore uses the srcu_node combining tree
    to remove this bottleneck.
    
    This commit adds new ->srcu_gp_seq_needed_exp fields to the
    srcu_data, srcu_node, and srcu_struct structures, which track the
    farthest-in-the-future grace period that must be expedited, which in
    turn requires that all nearer-term grace periods also be expedited.
    Requests for expediting start with the srcu_data structure, run up
    through the srcu_node tree, and end at the srcu_struct structure.
    Note that it may be necessary to expedite a grace period that just
    now started, and this is handled by a new srcu_funnel_exp_start()
    function, which is invoked when the grace period itself is already
    in its way, but when that grace period was not marked as expedited.
    
    A new srcu_get_delay() function returns zero if there is at least one
    expedited SRCU grace period in flight, or SRCU_INTERVAL otherwise.
    This function is used to calculate delays:  Normal grace periods
    are allowed to extend in order to cover more requests with a given
    grace-period computation, which decreases per-request overhead.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Mike Galbraith <efault@gmx.de>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 3865717df124..86df48d3e97b 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -43,6 +43,7 @@ struct srcu_data {
 	spinlock_t lock ____cacheline_internodealigned_in_smp;
 	struct rcu_segcblist srcu_cblist;	/* List of callbacks.*/
 	unsigned long srcu_gp_seq_needed;	/* Furthest future GP needed. */
+	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
 	bool srcu_cblist_invoking;		/* Invoking these CBs? */
 	struct delayed_work work;		/* Context for CB invoking. */
 	struct rcu_head srcu_barrier_head;	/* For srcu_barrier() use. */
@@ -63,6 +64,7 @@ struct srcu_node {
 						/*  is > ->srcu_gq_seq. */
 	unsigned long srcu_data_have_cbs[4];	/* Which srcu_data structs */
 						/*  have CBs for given GP? */
+	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
 	struct srcu_node *srcu_parent;		/* Next up in tree. */
 	int grplo;				/* Least CPU for node. */
 	int grphi;				/* Biggest CPU for node. */
@@ -81,7 +83,7 @@ struct srcu_struct {
 	unsigned int srcu_idx;			/* Current rdr array element. */
 	unsigned long srcu_gp_seq;		/* Grace-period seq #. */
 	unsigned long srcu_gp_seq_needed;	/* Latest gp_seq needed. */
-	atomic_t srcu_exp_cnt;			/* # ongoing expedited GPs. */
+	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
 	struct srcu_data __percpu *sda;		/* Per-CPU srcu_data array. */
 	unsigned long srcu_barrier_seq;		/* srcu_barrier seq #. */
 	struct mutex srcu_barrier_mutex;	/* Serialize barrier ops. */

commit 7f6733c3c648ddd6cf459c1b80ad388a95452955
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 18 17:17:35 2017 -0700

    srcu: Make rcutorture writer stalls print SRCU GP state
    
    In the past, SRCU was simple enough that there was little point in
    making the rcutorture writer stall messages print the SRCU grace-period
    number state.  With the advent of Tree SRCU, this has changed.  This
    commit therefore makes Classic, Tiny, and Tree SRCU report this state
    to rcutorture as needed.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Mike Galbraith <efault@gmx.de>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 94515ff226fb..3865717df124 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -140,4 +140,8 @@ void synchronize_srcu_expedited(struct srcu_struct *sp);
 void srcu_barrier(struct srcu_struct *sp);
 unsigned long srcu_batches_completed(struct srcu_struct *sp);
 
+void srcutorture_get_gp_data(enum rcutorture_type test_type,
+			     struct srcu_struct *sp, int *flags,
+			     unsigned long *gpnum, unsigned long *completed);
+
 #endif

commit c7e88067c1ae89e7bcbed070fb2c4e30bc39b51f
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 18 16:01:46 2017 -0700

    srcu: Exact tracking of srcu_data structures containing callbacks
    
    The current Tree SRCU implementation schedules a workqueue for every
    srcu_data covered by a given leaf srcu_node structure having callbacks,
    even if only one of those srcu_data structures actually contains
    callbacks.  This is clearly inefficient for workloads that don't feature
    callbacks everywhere all the time.  This commit therefore adds an array
    of masks that are used by the leaf srcu_node structures to track exactly
    which srcu_data structures contain callbacks.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Mike Galbraith <efault@gmx.de>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index 0400e211aa44..94515ff226fb 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -47,6 +47,8 @@ struct srcu_data {
 	struct delayed_work work;		/* Context for CB invoking. */
 	struct rcu_head srcu_barrier_head;	/* For srcu_barrier() use. */
 	struct srcu_node *mynode;		/* Leaf srcu_node. */
+	unsigned long grpmask;			/* Mask for leaf srcu_node */
+						/*  ->srcu_data_have_cbs[]. */
 	int cpu;
 	struct srcu_struct *sp;
 };
@@ -59,6 +61,8 @@ struct srcu_node {
 	unsigned long srcu_have_cbs[4];		/* GP seq for children */
 						/*  having CBs, but only */
 						/*  is > ->srcu_gq_seq. */
+	unsigned long srcu_data_have_cbs[4];	/* Which srcu_data structs */
+						/*  have CBs for given GP? */
 	struct srcu_node *srcu_parent;		/* Next up in tree. */
 	int grplo;				/* Least CPU for node. */
 	int grphi;				/* Biggest CPU for node. */

commit da915ad5cf25b5f5d358dd3670c3378d8ae8c03e
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Apr 5 09:01:53 2017 -0700

    srcu: Parallelize callback handling
    
    Peter Zijlstra proposed using SRCU to reduce mmap_sem contention [1,2],
    however, there are workloads that could result in a high volume of
    concurrent invocations of call_srcu(), which with current SRCU would
    result in excessive lock contention on the srcu_struct structure's
    ->queue_lock, which protects SRCU's callback lists.  This commit therefore
    moves SRCU to per-CPU callback lists, thus greatly reducing contention.
    
    Because a given SRCU instance no longer has a single centralized callback
    list, starting grace periods and invoking callbacks are both more complex
    than in the single-list Classic SRCU implementation.  Starting grace
    periods and handling callbacks are now handled using an srcu_node tree
    that is in some ways similar to the rcu_node trees used by RCU-bh,
    RCU-preempt, and RCU-sched (for example, the srcu_node tree shape is
    controlled by exactly the same Kconfig options and boot parameters that
    control the shape of the rcu_node tree).
    
    In addition, the old per-CPU srcu_array structure is now named srcu_data
    and contains an rcu_segcblist structure named ->srcu_cblist for its
    callbacks (and a spinlock to protect this).  The srcu_struct gets
    an srcu_gp_seq that is used to associate callback segments with the
    corresponding completion-time grace-period number.  These completion-time
    grace-period numbers are propagated up the srcu_node tree so that the
    grace-period workqueue handler can determine whether additional grace
    periods are needed on the one hand and where to look for callbacks that
    are ready to be invoked.
    
    The srcu_barrier() function must now wait on all instances of the per-CPU
    ->srcu_cblist.  Because each ->srcu_cblist is protected by ->lock,
    srcu_barrier() can remotely add the needed callbacks.  In theory,
    it could also remotely start grace periods, but in practice doing so
    is complex and racy.  And interestingly enough, it is never necessary
    for srcu_barrier() to start a grace period because srcu_barrier() only
    enqueues a callback when a callback is already present--and it turns out
    that a grace period has to have already been started for this pre-existing
    callback.  Furthermore, it is only the callback that srcu_barrier()
    needs to wait on, not any particular grace period.  Therefore, a new
    rcu_segcblist_entrain() function enqueues the srcu_barrier() function's
    callback into the same segment occupied by the last pre-existing callback
    in the list.  The special case where all the pre-existing callbacks are
    on a different list (because they are in the process of being invoked)
    is handled by enqueuing srcu_barrier()'s callback into the RCU_DONE_TAIL
    segment, relying on the done-callbacks check that takes place after all
    callbacks are inovked.
    
    Note that the readers use the same algorithm as before.  Note that there
    is a separate srcu_idx that tells the readers what counter to increment.
    This unfortunately cannot be combined with srcu_gp_seq because they
    need to be incremented at different times.
    
    This commit introduces some ugly #ifdefs in rcutorture.  These will go
    away when I feel good enough about Tree SRCU to ditch Classic SRCU.
    
    Some crude performance comparisons, courtesy of a quickly hacked rcuperf
    asynchronous-grace-period capability:
    
                            Callback Queuing Overhead
                            -------------------------
            # CPUS          Classic SRCU    Tree SRCU
            ------          ------------    ---------
                 2              0.349 us     0.342 us
                16             31.66  us     0.4   us
                41             ---------     0.417 us
    
    The times are the 90th percentiles, a statistic that was chosen to reject
    the overheads of the occasional srcu_barrier() call needed to avoid OOMing
    the test machine.  The rcuperf test hangs when running Classic SRCU at 41
    CPUs, hence the line of dashes.  Despite the hacks to both the rcuperf code
    and that statistics, this is a convincing demonstration of Tree SRCU's
    performance and scalability advantages.
    
    [1] https://lwn.net/Articles/309030/
    [2] https://patchwork.kernel.org/patch/5108281/
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [ paulmck: Fix initialization if synchronize_srcu_expedited() called first. ]

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index f2b3bd6c6bc2..0400e211aa44 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -24,25 +24,75 @@
 #ifndef _LINUX_SRCU_TREE_H
 #define _LINUX_SRCU_TREE_H
 
-struct srcu_array {
-	unsigned long lock_count[2];
-	unsigned long unlock_count[2];
+#include <linux/rcu_node_tree.h>
+#include <linux/completion.h>
+
+struct srcu_node;
+struct srcu_struct;
+
+/*
+ * Per-CPU structure feeding into leaf srcu_node, similar in function
+ * to rcu_node.
+ */
+struct srcu_data {
+	/* Read-side state. */
+	unsigned long srcu_lock_count[2];	/* Locks per CPU. */
+	unsigned long srcu_unlock_count[2];	/* Unlocks per CPU. */
+
+	/* Update-side state. */
+	spinlock_t lock ____cacheline_internodealigned_in_smp;
+	struct rcu_segcblist srcu_cblist;	/* List of callbacks.*/
+	unsigned long srcu_gp_seq_needed;	/* Furthest future GP needed. */
+	bool srcu_cblist_invoking;		/* Invoking these CBs? */
+	struct delayed_work work;		/* Context for CB invoking. */
+	struct rcu_head srcu_barrier_head;	/* For srcu_barrier() use. */
+	struct srcu_node *mynode;		/* Leaf srcu_node. */
+	int cpu;
+	struct srcu_struct *sp;
 };
 
+/*
+ * Node in SRCU combining tree, similar in function to rcu_data.
+ */
+struct srcu_node {
+	spinlock_t lock;
+	unsigned long srcu_have_cbs[4];		/* GP seq for children */
+						/*  having CBs, but only */
+						/*  is > ->srcu_gq_seq. */
+	struct srcu_node *srcu_parent;		/* Next up in tree. */
+	int grplo;				/* Least CPU for node. */
+	int grphi;				/* Biggest CPU for node. */
+};
+
+/*
+ * Per-SRCU-domain structure, similar in function to rcu_state.
+ */
 struct srcu_struct {
-	unsigned long completed;
-	unsigned long srcu_gp_seq;
-	atomic_t srcu_exp_cnt;
-	struct srcu_array __percpu *per_cpu_ref;
-	spinlock_t queue_lock; /* protect ->srcu_cblist */
-	struct rcu_segcblist srcu_cblist;
+	struct srcu_node node[NUM_RCU_NODES];	/* Combining tree. */
+	struct srcu_node *level[RCU_NUM_LVLS + 1];
+						/* First node at each level. */
+	struct mutex srcu_cb_mutex;		/* Serialize CB preparation. */
+	spinlock_t gp_lock;			/* protect ->srcu_cblist */
+	struct mutex srcu_gp_mutex;		/* Serialize GP work. */
+	unsigned int srcu_idx;			/* Current rdr array element. */
+	unsigned long srcu_gp_seq;		/* Grace-period seq #. */
+	unsigned long srcu_gp_seq_needed;	/* Latest gp_seq needed. */
+	atomic_t srcu_exp_cnt;			/* # ongoing expedited GPs. */
+	struct srcu_data __percpu *sda;		/* Per-CPU srcu_data array. */
+	unsigned long srcu_barrier_seq;		/* srcu_barrier seq #. */
+	struct mutex srcu_barrier_mutex;	/* Serialize barrier ops. */
+	struct completion srcu_barrier_completion;
+						/* Awaken barrier rq at end. */
+	atomic_t srcu_barrier_cpu_cnt;		/* # CPUs not yet posting a */
+						/*  callback for the barrier */
+						/*  operation. */
 	struct delayed_work work;
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 	struct lockdep_map dep_map;
 #endif /* #ifdef CONFIG_DEBUG_LOCK_ALLOC */
 };
 
-/* Values for -> state variable. */
+/* Values for state variable (bottom bits of ->srcu_gp_seq). */
 #define SRCU_STATE_IDLE		0
 #define SRCU_STATE_SCAN1	1
 #define SRCU_STATE_SCAN2	2
@@ -51,11 +101,9 @@ void process_srcu(struct work_struct *work);
 
 #define __SRCU_STRUCT_INIT(name)					\
 	{								\
-		.completed = -300,					\
-		.per_cpu_ref = &name##_srcu_array,			\
-		.queue_lock = __SPIN_LOCK_UNLOCKED(name.queue_lock),	\
-		.srcu_cblist = RCU_SEGCBLIST_INITIALIZER(name.srcu_cblist),\
-		.work = __DELAYED_WORK_INITIALIZER(name.work, process_srcu, 0),\
+		.sda = &name##_srcu_data,				\
+		.gp_lock = __SPIN_LOCK_UNLOCKED(name.gp_lock),		\
+		.srcu_gp_seq_needed = 0 - 1,				\
 		__SRCU_DEP_MAP_INIT(name)				\
 	}
 
@@ -79,7 +127,7 @@ void process_srcu(struct work_struct *work);
  * See include/linux/percpu-defs.h for the rules on per-CPU variables.
  */
 #define __DEFINE_SRCU(name, is_static)					\
-	static DEFINE_PER_CPU(struct srcu_array, name##_srcu_array);\
+	static DEFINE_PER_CPU(struct srcu_data, name##_srcu_data);\
 	is_static struct srcu_struct name = __SRCU_STRUCT_INIT(name)
 #define DEFINE_SRCU(name)		__DEFINE_SRCU(name, /* not static */)
 #define DEFINE_STATIC_SRCU(name)	__DEFINE_SRCU(name, static)

commit d8be81735aa89413b333de488251f0e64e2be591
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sat Mar 25 09:59:38 2017 -0700

    srcu: Create a tiny SRCU
    
    In response to automated complaints about modifications to SRCU
    increasing its size, this commit creates a tiny SRCU that is
    used in SMP=n && PREEMPT=n builds.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
new file mode 100644
index 000000000000..f2b3bd6c6bc2
--- /dev/null
+++ b/include/linux/srcutree.h
@@ -0,0 +1,91 @@
+/*
+ * Sleepable Read-Copy Update mechanism for mutual exclusion,
+ *	tree variant.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, you can access it online at
+ * http://www.gnu.org/licenses/gpl-2.0.html.
+ *
+ * Copyright (C) IBM Corporation, 2017
+ *
+ * Author: Paul McKenney <paulmck@us.ibm.com>
+ */
+
+#ifndef _LINUX_SRCU_TREE_H
+#define _LINUX_SRCU_TREE_H
+
+struct srcu_array {
+	unsigned long lock_count[2];
+	unsigned long unlock_count[2];
+};
+
+struct srcu_struct {
+	unsigned long completed;
+	unsigned long srcu_gp_seq;
+	atomic_t srcu_exp_cnt;
+	struct srcu_array __percpu *per_cpu_ref;
+	spinlock_t queue_lock; /* protect ->srcu_cblist */
+	struct rcu_segcblist srcu_cblist;
+	struct delayed_work work;
+#ifdef CONFIG_DEBUG_LOCK_ALLOC
+	struct lockdep_map dep_map;
+#endif /* #ifdef CONFIG_DEBUG_LOCK_ALLOC */
+};
+
+/* Values for -> state variable. */
+#define SRCU_STATE_IDLE		0
+#define SRCU_STATE_SCAN1	1
+#define SRCU_STATE_SCAN2	2
+
+void process_srcu(struct work_struct *work);
+
+#define __SRCU_STRUCT_INIT(name)					\
+	{								\
+		.completed = -300,					\
+		.per_cpu_ref = &name##_srcu_array,			\
+		.queue_lock = __SPIN_LOCK_UNLOCKED(name.queue_lock),	\
+		.srcu_cblist = RCU_SEGCBLIST_INITIALIZER(name.srcu_cblist),\
+		.work = __DELAYED_WORK_INITIALIZER(name.work, process_srcu, 0),\
+		__SRCU_DEP_MAP_INIT(name)				\
+	}
+
+/*
+ * Define and initialize a srcu struct at build time.
+ * Do -not- call init_srcu_struct() nor cleanup_srcu_struct() on it.
+ *
+ * Note that although DEFINE_STATIC_SRCU() hides the name from other
+ * files, the per-CPU variable rules nevertheless require that the
+ * chosen name be globally unique.  These rules also prohibit use of
+ * DEFINE_STATIC_SRCU() within a function.  If these rules are too
+ * restrictive, declare the srcu_struct manually.  For example, in
+ * each file:
+ *
+ *	static struct srcu_struct my_srcu;
+ *
+ * Then, before the first use of each my_srcu, manually initialize it:
+ *
+ *	init_srcu_struct(&my_srcu);
+ *
+ * See include/linux/percpu-defs.h for the rules on per-CPU variables.
+ */
+#define __DEFINE_SRCU(name, is_static)					\
+	static DEFINE_PER_CPU(struct srcu_array, name##_srcu_array);\
+	is_static struct srcu_struct name = __SRCU_STRUCT_INIT(name)
+#define DEFINE_SRCU(name)		__DEFINE_SRCU(name, /* not static */)
+#define DEFINE_STATIC_SRCU(name)	__DEFINE_SRCU(name, static)
+
+void synchronize_srcu_expedited(struct srcu_struct *sp);
+void srcu_barrier(struct srcu_struct *sp);
+unsigned long srcu_batches_completed(struct srcu_struct *sp);
+
+#endif
