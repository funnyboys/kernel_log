commit ad0f75e5f57ccbceec13274e1e242f2b5a6397ed
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Thu Jul 2 11:52:56 2020 -0700

    cgroup: fix cgroup_sk_alloc() for sk_clone_lock()
    
    When we clone a socket in sk_clone_lock(), its sk_cgrp_data is
    copied, so the cgroup refcnt must be taken too. And, unlike the
    sk_alloc() path, sock_update_netprioidx() is not called here.
    Therefore, it is safe and necessary to grab the cgroup refcnt
    even when cgroup_sk_alloc is disabled.
    
    sk_clone_lock() is in BH context anyway, the in_interrupt()
    would terminate this function if called there. And for sk_alloc()
    skcd->val is always zero. So it's safe to factor out the code
    to make it more readable.
    
    The global variable 'cgroup_sk_alloc_disabled' is used to determine
    whether to take these reference counts. It is impossible to make
    the reference counting correct unless we save this bit of information
    in skcd->val. So, add a new bit there to record whether the socket
    has already taken the reference counts. This obviously relies on
    kmalloc() to align cgroup pointers to at least 4 bytes,
    ARCH_KMALLOC_MINALIGN is certainly larger than that.
    
    This bug seems to be introduced since the beginning, commit
    d979a39d7242 ("cgroup: duplicate cgroup reference when cloning sockets")
    tried to fix it but not compeletely. It seems not easy to trigger until
    the recent commit 090e28b229af
    ("netprio_cgroup: Fix unlimited memory leak of v2 cgroups") was merged.
    
    Fixes: bd1060a1d671 ("sock, cgroup: add sock->sk_cgroup")
    Reported-by: Cameron Berkenpas <cam@neo-zeon.de>
    Reported-by: Peter Geis <pgwipeout@gmail.com>
    Reported-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reported-by: Daniël Sonck <dsonck92@gmail.com>
    Reported-by: Zhang Qiang <qiang.zhang@windriver.com>
    Tested-by: Cameron Berkenpas <cam@neo-zeon.de>
    Tested-by: Peter Geis <pgwipeout@gmail.com>
    Tested-by: Thomas Lamprecht <t.lamprecht@proxmox.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Zefan Li <lizefan@huawei.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Roman Gushchin <guro@fb.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4598e4da6b1b..618838c48313 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -822,6 +822,7 @@ extern spinlock_t cgroup_sk_update_lock;
 
 void cgroup_sk_alloc_disable(void);
 void cgroup_sk_alloc(struct sock_cgroup_data *skcd);
+void cgroup_sk_clone(struct sock_cgroup_data *skcd);
 void cgroup_sk_free(struct sock_cgroup_data *skcd);
 
 static inline struct cgroup *sock_cgroup_ptr(struct sock_cgroup_data *skcd)
@@ -835,7 +836,7 @@ static inline struct cgroup *sock_cgroup_ptr(struct sock_cgroup_data *skcd)
 	 */
 	v = READ_ONCE(skcd->val);
 
-	if (v & 1)
+	if (v & 3)
 		return &cgrp_dfl_root.cgrp;
 
 	return (struct cgroup *)(unsigned long)v ?: &cgrp_dfl_root.cgrp;
@@ -847,6 +848,7 @@ static inline struct cgroup *sock_cgroup_ptr(struct sock_cgroup_data *skcd)
 #else	/* CONFIG_CGROUP_DATA */
 
 static inline void cgroup_sk_alloc(struct sock_cgroup_data *skcd) {}
+static inline void cgroup_sk_clone(struct sock_cgroup_data *skcd) {}
 static inline void cgroup_sk_free(struct sock_cgroup_data *skcd) {}
 
 #endif	/* CONFIG_CGROUP_DATA */

commit ef2c41cf38a7559bbf91af42d5b6a4429db8fc68
Author: Christian Brauner <christian.brauner@ubuntu.com>
Date:   Wed Feb 5 14:26:22 2020 +0100

    clone3: allow spawning processes into cgroups
    
    This adds support for creating a process in a different cgroup than its
    parent. Callers can limit and account processes and threads right from
    the moment they are spawned:
    - A service manager can directly spawn new services into dedicated
      cgroups.
    - A process can be directly created in a frozen cgroup and will be
      frozen as well.
    - The initial accounting jitter experienced by process supervisors and
      daemons is eliminated with this.
    - Threaded applications or even thread implementations can choose to
      create a specific cgroup layout where each thread is spawned
      directly into a dedicated cgroup.
    
    This feature is limited to the unified hierarchy. Callers need to pass
    a directory file descriptor for the target cgroup. The caller can
    choose to pass an O_PATH file descriptor. All usual migration
    restrictions apply, i.e. there can be no processes in inner nodes. In
    general, creating a process directly in a target cgroup adheres to all
    migration restrictions.
    
    One of the biggest advantages of this feature is that CLONE_INTO_GROUP does
    not need to grab the write side of the cgroup cgroup_threadgroup_rwsem.
    This global lock makes moving tasks/threads around super expensive. With
    clone3() this lock is avoided.
    
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: cgroups@vger.kernel.org
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f1219b927817..4598e4da6b1b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -27,6 +27,8 @@
 
 #include <linux/cgroup-defs.h>
 
+struct kernel_clone_args;
+
 #ifdef CONFIG_CGROUPS
 
 /*
@@ -119,9 +121,12 @@ int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
 		     struct pid *pid, struct task_struct *tsk);
 
 void cgroup_fork(struct task_struct *p);
-extern int cgroup_can_fork(struct task_struct *p);
-extern void cgroup_cancel_fork(struct task_struct *p);
-extern void cgroup_post_fork(struct task_struct *p);
+extern int cgroup_can_fork(struct task_struct *p,
+			   struct kernel_clone_args *kargs);
+extern void cgroup_cancel_fork(struct task_struct *p,
+			       struct kernel_clone_args *kargs);
+extern void cgroup_post_fork(struct task_struct *p,
+			     struct kernel_clone_args *kargs);
 void cgroup_exit(struct task_struct *p);
 void cgroup_release(struct task_struct *p);
 void cgroup_free(struct task_struct *p);
@@ -705,9 +710,12 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 				    struct dentry *dentry) { return -EINVAL; }
 
 static inline void cgroup_fork(struct task_struct *p) {}
-static inline int cgroup_can_fork(struct task_struct *p) { return 0; }
-static inline void cgroup_cancel_fork(struct task_struct *p) {}
-static inline void cgroup_post_fork(struct task_struct *p) {}
+static inline int cgroup_can_fork(struct task_struct *p,
+				  struct kernel_clone_args *kargs) { return 0; }
+static inline void cgroup_cancel_fork(struct task_struct *p,
+				      struct kernel_clone_args *kargs) {}
+static inline void cgroup_post_fork(struct task_struct *p,
+				    struct kernel_clone_args *kargs) {}
 static inline void cgroup_exit(struct task_struct *p) {}
 static inline void cgroup_release(struct task_struct *p) {}
 static inline void cgroup_free(struct task_struct *p) {}

commit f43caa2adc96fc9c95fd77eef63cdff86ebf33cb
Author: Michal Koutný <mkoutny@suse.com>
Date:   Fri Jan 24 12:40:16 2020 +0100

    cgroup: Clean up css_set task traversal
    
    css_task_iter stores pointer to head of each iterable list, this dates
    back to commit 0f0a2b4fa621 ("cgroup: reorganize css_task_iter") when we
    did not store cur_cset. Let us utilize list heads directly in cur_cset
    and streamline css_task_iter_advance_css_set a bit. This is no
    intentional function change.
    
    Signed-off-by: Michal Koutný <mkoutny@suse.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e75d2191226b..f1219b927817 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -58,9 +58,6 @@ struct css_task_iter {
 	struct list_head		*tcset_head;
 
 	struct list_head		*task_pos;
-	struct list_head		*tasks_head;
-	struct list_head		*mg_tasks_head;
-	struct list_head		*dying_tasks_head;
 
 	struct list_head		*cur_tasks_head;
 	struct css_set			*cur_cset;

commit 9c974c77246460fa6a92c18554c3311c8c83c160
Author: Michal Koutný <mkoutny@suse.com>
Date:   Fri Jan 24 12:40:15 2020 +0100

    cgroup: Iterate tasks that did not finish do_exit()
    
    PF_EXITING is set earlier than actual removal from css_set when a task
    is exitting. This can confuse cgroup.procs readers who see no PF_EXITING
    tasks, however, rmdir is checking against css_set membership so it can
    transitionally fail with EBUSY.
    
    Fix this by listing tasks that weren't unlinked from css_set active
    lists.
    It may happen that other users of the task iterator (without
    CSS_TASK_ITER_PROCS) spot a PF_EXITING task before cgroup_exit(). This
    is equal to the state before commit c03cd7738a83 ("cgroup: Include dying
    leaders with live threads in PROCS iterations") but it may be reviewed
    later.
    
    Reported-by: Suren Baghdasaryan <surenb@google.com>
    Fixes: c03cd7738a83 ("cgroup: Include dying leaders with live threads in PROCS iterations")
    Signed-off-by: Michal Koutný <mkoutny@suse.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d7ddebd0cdec..e75d2191226b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -62,6 +62,7 @@ struct css_task_iter {
 	struct list_head		*mg_tasks_head;
 	struct list_head		*dying_tasks_head;
 
+	struct list_head		*cur_tasks_head;
 	struct css_set			*cur_cset;
 	struct css_set			*cur_dcset;
 	struct task_struct		*cur_task;

commit 743210386c0354a2f8ef3d697353c7d8477fa81d
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 4 15:54:30 2019 -0800

    cgroup: use cgrp->kn->id as the cgroup ID
    
    cgroup ID is currently allocated using a dedicated per-hierarchy idr
    and used internally and exposed through tracepoints and bpf.  This is
    confusing because there are tracepoints and other interfaces which use
    the cgroupfs ino as IDs.
    
    The preceding changes made kn->id exposed as ino as 64bit ino on
    supported archs or ino+gen (low 32bits as ino, high gen).  There's no
    reason for cgroup to use different IDs.  The kernfs IDs are unique and
    userland can easily discover them and map them back to paths using
    standard file operations.
    
    This patch replaces cgroup IDs with kernfs IDs.
    
    * cgroup_id() is added and all cgroup ID users are converted to use it.
    
    * kernfs_node creation is moved to earlier during cgroup init so that
      cgroup_id() is available during init.
    
    * While at it, s/cgroup/cgrp/ in psi helpers for consistency.
    
    * Fallback ID value is changed to 1 to be consistent with root cgroup
      ID.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 815fff49d555..d7ddebd0cdec 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -304,6 +304,11 @@ void css_task_iter_end(struct css_task_iter *it);
  * Inline functions.
  */
 
+static inline u64 cgroup_id(struct cgroup *cgrp)
+{
+	return cgrp->kn->id;
+}
+
 /**
  * css_get - obtain a reference on the specified css
  * @css: target css
@@ -565,7 +570,7 @@ static inline bool cgroup_is_descendant(struct cgroup *cgrp,
 {
 	if (cgrp->root != ancestor->root || cgrp->level < ancestor->level)
 		return false;
-	return cgrp->ancestor_ids[ancestor->level] == ancestor->id;
+	return cgrp->ancestor_ids[ancestor->level] == cgroup_id(ancestor);
 }
 
 /**
@@ -687,17 +692,13 @@ static inline void cgroup_kthread_ready(void)
 	current->no_cgroup_migration = 0;
 }
 
-static inline u64 cgroup_get_kernfs_id(struct cgroup *cgrp)
-{
-	return cgrp->kn->id;
-}
-
 void cgroup_path_from_kernfs_id(u64 id, char *buf, size_t buflen);
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;
 struct cgroup;
 
+static inline u64 cgroup_id(struct cgroup *cgrp) { return 1; }
 static inline void css_get(struct cgroup_subsys_state *css) {}
 static inline void css_put(struct cgroup_subsys_state *css) {}
 static inline int cgroup_attach_task_all(struct task_struct *from,
@@ -717,10 +718,6 @@ static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_init_kthreadd(void) {}
 static inline void cgroup_kthread_ready(void) {}
-static inline union u64 cgroup_get_kernfs_id(struct cgroup *cgrp)
-{
-	return 0;
-}
 
 static inline struct cgroup *cgroup_parent(struct cgroup *cgrp)
 {

commit 67c0496e87d193b8356d2af49ab95e8a1b954b3c
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 4 15:54:30 2019 -0800

    kernfs: convert kernfs_node->id from union kernfs_node_id to u64
    
    kernfs_node->id is currently a union kernfs_node_id which represents
    either a 32bit (ino, gen) pair or u64 value.  I can't see much value
    in the usage of the union - all that's needed is a 64bit ID which the
    current code is already limited to.  Using a union makes the code
    unnecessarily complicated and prevents using 64bit ino without adding
    practical benefits.
    
    This patch drops union kernfs_node_id and makes kernfs_node->id a u64.
    ino is stored in the lower 32bits and gen upper.  Accessors -
    kernfs[_id]_ino() and kernfs[_id]_gen() - are added to retrieve the
    ino and gen.  This simplifies ID handling less cumbersome and will
    allow using 64bit inos on supported archs.
    
    This patch doesn't make any functional changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Alexei Starovoitov <ast@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f6b048902d6c..815fff49d555 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -616,7 +616,7 @@ static inline bool cgroup_is_populated(struct cgroup *cgrp)
 /* returns ino associated with a cgroup */
 static inline ino_t cgroup_ino(struct cgroup *cgrp)
 {
-	return cgrp->kn->id.ino;
+	return kernfs_ino(cgrp->kn);
 }
 
 /* cft/css accessors for cftype->write() operation */
@@ -687,13 +687,12 @@ static inline void cgroup_kthread_ready(void)
 	current->no_cgroup_migration = 0;
 }
 
-static inline union kernfs_node_id *cgroup_get_kernfs_id(struct cgroup *cgrp)
+static inline u64 cgroup_get_kernfs_id(struct cgroup *cgrp)
 {
-	return &cgrp->kn->id;
+	return cgrp->kn->id;
 }
 
-void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
-					char *buf, size_t buflen);
+void cgroup_path_from_kernfs_id(u64 id, char *buf, size_t buflen);
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;
@@ -718,9 +717,9 @@ static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_init_kthreadd(void) {}
 static inline void cgroup_kthread_ready(void) {}
-static inline union kernfs_node_id *cgroup_get_kernfs_id(struct cgroup *cgrp)
+static inline union u64 cgroup_get_kernfs_id(struct cgroup *cgrp)
 {
-	return NULL;
+	return 0;
 }
 
 static inline struct cgroup *cgroup_parent(struct cgroup *cgrp)
@@ -739,8 +738,8 @@ static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
 	return true;
 }
 
-static inline void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
-	char *buf, size_t buflen) {}
+static inline void cgroup_path_from_kernfs_id(u64 id, char *buf, size_t buflen)
+{}
 #endif /* !CONFIG_CGROUPS */
 
 #ifdef CONFIG_CGROUPS

commit 5153faac18d293fc7abb19ff7034683fbcd82dc7
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Oct 24 12:03:51 2019 -0700

    cgroup: remove cgroup_enable_task_cg_lists() optimization
    
    cgroup_enable_task_cg_lists() is used to lazyily initialize task
    cgroup associations on the first use to reduce fork / exit overheads
    on systems which don't use cgroup.  Unfortunately, locking around it
    has never been actually correct and its value is dubious given how the
    vast majority of systems use cgroup right away from boot.
    
    This patch removes the optimization.  For now, replace the cg_list
    based branches with WARN_ON_ONCE()'s to be on the safe side.  We can
    simplify the logic further in the future.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3ba3e6da13a6..f6b048902d6c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -150,7 +150,6 @@ struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset,
 struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset,
 					struct cgroup_subsys_state **dst_cssp);
 
-void cgroup_enable_task_cg_lists(void);
 void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,
 			 struct css_task_iter *it);
 struct task_struct *css_task_iter_next(struct css_task_iter *it);

commit f9a25f776d780bfa3279f0b6e5f5cf3224997976
Author: Mathieu Poirier <mathieu.poirier@linaro.org>
Date:   Fri Jul 19 15:59:55 2019 +0200

    cpusets: Rebuild root domain deadline accounting information
    
    When the topology of root domains is modified by CPUset or CPUhotplug
    operations information about the current deadline bandwidth held in the
    root domain is lost.
    
    This patch addresses the issue by recalculating the lost deadline
    bandwidth information by circling through the deadline tasks held in
    CPUsets and adding their current load to the root domain they are
    associated with.
    
    Tested-by: Dietmar Eggemann <dietmar.eggemann@arm.com>
    Signed-off-by: Mathieu Poirier <mathieu.poirier@linaro.org>
    Signed-off-by: Juri Lelli <juri.lelli@redhat.com>
    [ Various additional modifications. ]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: bristot@redhat.com
    Cc: claudio@evidence.eu.com
    Cc: lizefan@huawei.com
    Cc: longman@redhat.com
    Cc: luca.abeni@santannapisa.it
    Cc: rostedt@goodmis.org
    Cc: tj@kernel.org
    Cc: tommaso.cucinotta@santannapisa.it
    Link: https://lkml.kernel.org/r/20190719140000.31694-4-juri.lelli@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f6b048902d6c..3ba3e6da13a6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -150,6 +150,7 @@ struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset,
 struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset,
 					struct cgroup_subsys_state **dst_cssp);
 
+void cgroup_enable_task_cg_lists(void);
 void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,
 			 struct css_task_iter *it);
 struct task_struct *css_task_iter_next(struct css_task_iter *it);

commit 9637d517347e80ee2fe1c5d8ce45ba1b88d8b5cd
Merge: 273cbf61c3dd 787c79d6393f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 15 21:20:52 2019 -0700

    Merge tag 'for-linus-20190715' of git://git.kernel.dk/linux-block
    
    Pull more block updates from Jens Axboe:
     "A later pull request with some followup items. I had some vacation
      coming up to the merge window, so certain things items were delayed a
      bit. This pull request also contains fixes that came in within the
      last few days of the merge window, which I didn't want to push right
      before sending you a pull request.
    
      This contains:
    
       - NVMe pull request, mostly fixes, but also a few minor items on the
         feature side that were timing constrained (Christoph et al)
    
       - Report zones fixes (Damien)
    
       - Removal of dead code (Damien)
    
       - Turn on cgroup psi memstall (Josef)
    
       - block cgroup MAINTAINERS entry (Konstantin)
    
       - Flush init fix (Josef)
    
       - blk-throttle low iops timing fix (Konstantin)
    
       - nbd resize fixes (Mike)
    
       - nbd 0 blocksize crash fix (Xiubo)
    
       - block integrity error leak fix (Wenwen)
    
       - blk-cgroup writeback and priority inheritance fixes (Tejun)"
    
    * tag 'for-linus-20190715' of git://git.kernel.dk/linux-block: (42 commits)
      MAINTAINERS: add entry for block io cgroup
      null_blk: fixup ->report_zones() for !CONFIG_BLK_DEV_ZONED
      block: Limit zone array allocation size
      sd_zbc: Fix report zones buffer allocation
      block: Kill gfp_t argument of blkdev_report_zones()
      block: Allow mapping of vmalloc-ed buffers
      block/bio-integrity: fix a memory leak bug
      nvme: fix NULL deref for fabrics options
      nbd: add netlink reconfigure resize support
      nbd: fix crash when the blksize is zero
      block: Disable write plugging for zoned block devices
      block: Fix elevator name declaration
      block: Remove unused definitions
      nvme: fix regression upon hot device removal and insertion
      blk-throttle: fix zero wait time for iops throttled group
      block: Fix potential overflow in blk_report_zones()
      blkcg: implement REQ_CGROUP_PUNT
      blkcg, writeback: Implement wbc_blkcg_css()
      blkcg, writeback: Add wbc->no_cgroup_owner
      blkcg, writeback: Rename wbc_account_io() to wbc_account_cgroup_owner()
      ...

commit 237f83dfbe668443b5e31c3c7576125871cca674
Merge: 8f6ccf6159ae 1ff2f0fa450e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 11 10:55:49 2019 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
     "Some highlights from this development cycle:
    
       1) Big refactoring of ipv6 route and neigh handling to support
          nexthop objects configurable as units from userspace. From David
          Ahern.
    
       2) Convert explored_states in BPF verifier into a hash table,
          significantly decreased state held for programs with bpf2bpf
          calls, from Alexei Starovoitov.
    
       3) Implement bpf_send_signal() helper, from Yonghong Song.
    
       4) Various classifier enhancements to mvpp2 driver, from Maxime
          Chevallier.
    
       5) Add aRFS support to hns3 driver, from Jian Shen.
    
       6) Fix use after free in inet frags by allocating fqdirs dynamically
          and reworking how rhashtable dismantle occurs, from Eric Dumazet.
    
       7) Add act_ctinfo packet classifier action, from Kevin
          Darbyshire-Bryant.
    
       8) Add TFO key backup infrastructure, from Jason Baron.
    
       9) Remove several old and unused ISDN drivers, from Arnd Bergmann.
    
      10) Add devlink notifications for flash update status to mlxsw driver,
          from Jiri Pirko.
    
      11) Lots of kTLS offload infrastructure fixes, from Jakub Kicinski.
    
      12) Add support for mv88e6250 DSA chips, from Rasmus Villemoes.
    
      13) Various enhancements to ipv6 flow label handling, from Eric
          Dumazet and Willem de Bruijn.
    
      14) Support TLS offload in nfp driver, from Jakub Kicinski, Dirk van
          der Merwe, and others.
    
      15) Various improvements to axienet driver including converting it to
          phylink, from Robert Hancock.
    
      16) Add PTP support to sja1105 DSA driver, from Vladimir Oltean.
    
      17) Add mqprio qdisc offload support to dpaa2-eth, from Ioana
          Radulescu.
    
      18) Add devlink health reporting to mlx5, from Moshe Shemesh.
    
      19) Convert stmmac over to phylink, from Jose Abreu.
    
      20) Add PTP PHC (Physical Hardware Clock) support to mlxsw, from
          Shalom Toledo.
    
      21) Add nftables SYNPROXY support, from Fernando Fernandez Mancera.
    
      22) Convert tcp_fastopen over to use SipHash, from Ard Biesheuvel.
    
      23) Track spill/fill of constants in BPF verifier, from Alexei
          Starovoitov.
    
      24) Support bounded loops in BPF, from Alexei Starovoitov.
    
      25) Various page_pool API fixes and improvements, from Jesper Dangaard
          Brouer.
    
      26) Just like ipv4, support ref-countless ipv6 route handling. From
          Wei Wang.
    
      27) Support VLAN offloading in aquantia driver, from Igor Russkikh.
    
      28) Add AF_XDP zero-copy support to mlx5, from Maxim Mikityanskiy.
    
      29) Add flower GRE encap/decap support to nfp driver, from Pieter
          Jansen van Vuuren.
    
      30) Protect against stack overflow when using act_mirred, from John
          Hurley.
    
      31) Allow devmap map lookups from eBPF, from Toke Høiland-Jørgensen.
    
      32) Use page_pool API in netsec driver, Ilias Apalodimas.
    
      33) Add Google gve network driver, from Catherine Sullivan.
    
      34) More indirect call avoidance, from Paolo Abeni.
    
      35) Add kTLS TX HW offload support to mlx5, from Tariq Toukan.
    
      36) Add XDP_REDIRECT support to bnxt_en, from Andy Gospodarek.
    
      37) Add MPLS manipulation actions to TC, from John Hurley.
    
      38) Add sending a packet to connection tracking from TC actions, and
          then allow flower classifier matching on conntrack state. From
          Paul Blakey.
    
      39) Netfilter hw offload support, from Pablo Neira Ayuso"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (2080 commits)
      net/mlx5e: Return in default case statement in tx_post_resync_params
      mlx5: Return -EINVAL when WARN_ON_ONCE triggers in mlx5e_tls_resync().
      net: dsa: add support for BRIDGE_MROUTER attribute
      pkt_sched: Include const.h
      net: netsec: remove static declaration for netsec_set_tx_de()
      net: netsec: remove superfluous if statement
      netfilter: nf_tables: add hardware offload support
      net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload
      net: flow_offload: add flow_block_cb_is_busy() and use it
      net: sched: remove tcf block API
      drivers: net: use flow block API
      net: sched: use flow block API
      net: flow_offload: add flow_block_cb_{priv, incref, decref}()
      net: flow_offload: add list handling functions
      net: flow_offload: add flow_block_cb_alloc() and flow_block_cb_free()
      net: flow_offload: rename TCF_BLOCK_BINDER_TYPE_* to FLOW_BLOCK_BINDER_TYPE_*
      net: flow_offload: rename TC_BLOCK_{UN}BIND to FLOW_BLOCK_{UN}BIND
      net: flow_offload: add flow_block_cb_setup_simple()
      net: hisilicon: Add an tx_desc to adapt HI13X1_GMAC
      net: hisilicon: Add an rx_desc to adapt HI13X1_GMAC
      ...

commit 9b0eb69b75bccada2d341d7e7ca342f0cb1c9a6a
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 27 13:39:48 2019 -0700

    cgroup, blkcg: Prepare some symbols for module and !CONFIG_CGROUP usages
    
    btrfs is going to use css_put() and wbc helpers to improve cgroup
    writeback support.  Add dummy css_get() definition and export wbc
    helpers to prepare for module and !CONFIG_CGROUP builds.
    
    Reported-by: kbuild test robot <lkp@intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3745ecdad925..852d885df10a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -699,6 +699,7 @@ void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
 struct cgroup_subsys_state;
 struct cgroup;
 
+static inline void css_get(struct cgroup_subsys_state *css) {}
 static inline void css_put(struct cgroup_subsys_state *css) {}
 static inline int cgroup_attach_task_all(struct task_struct *from,
 					 struct task_struct *t) { return 0; }

commit 13091aa30535b719e269f20a7bc34002bf5afae5
Merge: f97252a8c33f 29f785ff76b6
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jun 17 19:48:13 2019 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Honestly all the conflicts were simple overlapping changes,
    nothing really interesting to report.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a5e112e6424adb77d953eac20e6936b952fd6b32
Author: Tejun Heo <tj@kernel.org>
Date:   Mon May 13 12:37:17 2019 -0700

    cgroup: add cgroup_parse_float()
    
    cgroup already uses floating point for percent[ile] numbers and there
    are several controllers which want to take them as input.  Add a
    generic parse helper to handle inputs.
    
    Update the interface convention documentation about the use of
    percentage numbers.  While at it, also clarify the default time unit.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0297f930a56e..3745ecdad925 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -131,6 +131,8 @@ void cgroup_free(struct task_struct *p);
 int cgroup_init_early(void);
 int cgroup_init(void);
 
+int cgroup_parse_float(const char *input, unsigned dec_shift, s64 *v);
+
 /*
  * Iteration helpers and macros.
  */

commit c03cd7738a83b13739f00546166969342c8ff014
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 31 10:38:58 2019 -0700

    cgroup: Include dying leaders with live threads in PROCS iterations
    
    CSS_TASK_ITER_PROCS currently iterates live group leaders; however,
    this means that a process with dying leader and live threads will be
    skipped.  IOW, cgroup.procs might be empty while cgroup.threads isn't,
    which is confusing to say the least.
    
    Fix it by making cset track dying tasks and include dying leaders with
    live threads in PROCS iteration.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-and-tested-by: Topi Miettinen <toiwoton@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 05ed2a209e74..0297f930a56e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -60,6 +60,7 @@ struct css_task_iter {
 	struct list_head		*task_pos;
 	struct list_head		*tasks_head;
 	struct list_head		*mg_tasks_head;
+	struct list_head		*dying_tasks_head;
 
 	struct css_set			*cur_cset;
 	struct css_set			*cur_dcset;

commit b636fd38dc40113f853337a7d2a6885ad23b8811
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 31 10:38:58 2019 -0700

    cgroup: Implement css_task_iter_skip()
    
    When a task is moved out of a cset, task iterators pointing to the
    task are advanced using the normal css_task_iter_advance() call.  This
    is fine but we'll be tracking dying tasks on csets and thus moving
    tasks from cset->tasks to (to be added) cset->dying_tasks.  When we
    remove a task from cset->tasks, if we advance the iterators, they may
    move over to the next cset before we had the chance to add the task
    back on the dying list, which can allow the task to escape iteration.
    
    This patch separates out skipping from advancing.  Skipping only moves
    the affected iterators to the next pointer rather than fully advancing
    it and the following advancing will recognize that the cursor has
    already been moved forward and do the rest of advancing.  This ensures
    that when a task moves from one list to another in its cset, as long
    as it moves in the right direction, it's always visible to iteration.
    
    This doesn't cause any visible behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a7e4611e20c8..05ed2a209e74 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -43,6 +43,9 @@
 /* walk all threaded css_sets in the domain */
 #define CSS_TASK_ITER_THREADED		(1U << 1)
 
+/* internal flags */
+#define CSS_TASK_ITER_SKIPPED		(1U << 16)
+
 /* a css_task_iter should be treated as an opaque object */
 struct css_task_iter {
 	struct cgroup_subsys		*ss;

commit 18fa84a2db0e15b02baa5d94bdb5bd509175d2f6
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 29 13:46:25 2019 -0700

    cgroup: Use css_tryget() instead of css_tryget_online() in task_get_css()
    
    A PF_EXITING task can stay associated with an offline css.  If such
    task calls task_get_css(), it can get stuck indefinitely.  This can be
    triggered by BSD process accounting which writes to a file with
    PF_EXITING set when racing against memcg disable as in the backtrace
    at the end.
    
    After this change, task_get_css() may return a css which was already
    offline when the function was called.  None of the existing users are
    affected by this change.
    
      INFO: rcu_sched self-detected stall on CPU
      INFO: rcu_sched detected stalls on CPUs/tasks:
      ...
      NMI backtrace for cpu 0
      ...
      Call Trace:
       <IRQ>
       dump_stack+0x46/0x68
       nmi_cpu_backtrace.cold.2+0x13/0x57
       nmi_trigger_cpumask_backtrace+0xba/0xca
       rcu_dump_cpu_stacks+0x9e/0xce
       rcu_check_callbacks.cold.74+0x2af/0x433
       update_process_times+0x28/0x60
       tick_sched_timer+0x34/0x70
       __hrtimer_run_queues+0xee/0x250
       hrtimer_interrupt+0xf4/0x210
       smp_apic_timer_interrupt+0x56/0x110
       apic_timer_interrupt+0xf/0x20
       </IRQ>
      RIP: 0010:balance_dirty_pages_ratelimited+0x28f/0x3d0
      ...
       btrfs_file_write_iter+0x31b/0x563
       __vfs_write+0xfa/0x140
       __kernel_write+0x4f/0x100
       do_acct_process+0x495/0x580
       acct_process+0xb9/0xdb
       do_exit+0x748/0xa00
       do_group_exit+0x3a/0xa0
       get_signal+0x254/0x560
       do_signal+0x23/0x5c0
       exit_to_usermode_loop+0x5d/0xa0
       prepare_exit_to_usermode+0x53/0x80
       retint_user+0x8/0x8
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: stable@vger.kernel.org # v4.2+
    Fixes: ec438699a9ae ("cgroup, block: implement task_get_css() and use it in bio_associate_current()")

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c0077adeea83..a7e4611e20c8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -487,7 +487,7 @@ static inline struct cgroup_subsys_state *task_css(struct task_struct *task,
  *
  * Find the css for the (@task, @subsys_id) combination, increment a
  * reference on and return it.  This function is guaranteed to return a
- * valid css.
+ * valid css.  The returned css may already have been offlined.
  */
 static inline struct cgroup_subsys_state *
 task_get_css(struct task_struct *task, int subsys_id)
@@ -497,7 +497,13 @@ task_get_css(struct task_struct *task, int subsys_id)
 	rcu_read_lock();
 	while (true) {
 		css = task_css(task, subsys_id);
-		if (likely(css_tryget_online(css)))
+		/*
+		 * Can't use css_tryget_online() here.  A task which has
+		 * PF_EXITING set may stay associated with an offline css.
+		 * If such task calls this function, css_tryget_online()
+		 * will keep failing.
+		 */
+		if (likely(css_tryget(css)))
 			break;
 		cpu_relax();
 	}

commit 4bfc0bb2c60e2f4cc8eb60f03cf8dfa72336272a
Author: Roman Gushchin <guro@fb.com>
Date:   Sat May 25 09:37:39 2019 -0700

    bpf: decouple the lifetime of cgroup_bpf from cgroup itself
    
    Currently the lifetime of bpf programs attached to a cgroup is bound
    to the lifetime of the cgroup itself. It means that if a user
    forgets (or intentionally avoids) to detach a bpf program before
    removing the cgroup, it will stay attached up to the release of the
    cgroup. Since the cgroup can stay in the dying state (the state
    between being rmdir()'ed and being released) for a very long time, it
    leads to a waste of memory. Also, it blocks a possibility to implement
    the memcg-based memory accounting for bpf objects, because a circular
    reference dependency will occur. Charged memory pages are pinning the
    corresponding memory cgroup, and if the memory cgroup is pinning
    the attached bpf program, nothing will be ever released.
    
    A dying cgroup can not contain any processes, so the only chance for
    an attached bpf program to be executed is a live socket associated
    with the cgroup. So in order to release all bpf data early, let's
    count associated sockets using a new percpu refcounter. On cgroup
    removal the counter is transitioned to the atomic mode, and as soon
    as it reaches 0, all bpf programs are detached.
    
    Because cgroup_bpf_release() can block, it can't be called from
    the percpu ref counter callback directly, so instead an asynchronous
    work is scheduled.
    
    The reference counter is not socket specific, and can be used for any
    other types of programs, which can be executed from a cgroup-bpf hook
    outside of the process context, had such a need arise in the future.
    
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Cc: jolsa@redhat.com
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c0077adeea83..49e8facf7c4a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -924,4 +924,22 @@ static inline bool cgroup_task_frozen(struct task_struct *task)
 
 #endif /* !CONFIG_CGROUPS */
 
+#ifdef CONFIG_CGROUP_BPF
+static inline void cgroup_bpf_get(struct cgroup *cgrp)
+{
+	percpu_ref_get(&cgrp->bpf.refcnt);
+}
+
+static inline void cgroup_bpf_put(struct cgroup *cgrp)
+{
+	percpu_ref_put(&cgrp->bpf.refcnt);
+}
+
+#else /* CONFIG_CGROUP_BPF */
+
+static inline void cgroup_bpf_get(struct cgroup *cgrp) {}
+static inline void cgroup_bpf_put(struct cgroup *cgrp) {}
+
+#endif /* CONFIG_CGROUP_BPF */
+
 #endif /* _LINUX_CGROUP_H */

commit 96b9c592def5d7203bdad1337d9c92a2183de5cb
Author: Roman Gushchin <guro@fb.com>
Date:   Fri Apr 26 10:59:45 2019 -0700

    cgroup: get rid of cgroup_freezer_frozen_exit()
    
    A task should never enter the exit path with the task->frozen bit set.
    Any frozen task must enter the signal handling loop and the only
    way to escape is through cgroup_leave_frozen(true), which
    unconditionally drops the task->frozen bit. So it means that
    cgroyp_freezer_frozen_exit() has zero chances to be called and
    has to be removed.
    
    Let's put a WARN_ON_ONCE() instead of the cgroup_freezer_frozen_exit()
    call to catch any potential leak of the task's frozen bit.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3e2efd412dfa..c0077adeea83 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -889,7 +889,7 @@ void cgroup_update_frozen(struct cgroup *cgrp);
 void cgroup_freeze(struct cgroup *cgrp, bool freeze);
 void cgroup_freezer_migrate_task(struct task_struct *task, struct cgroup *src,
 				 struct cgroup *dst);
-void cgroup_freezer_frozen_exit(struct task_struct *task);
+
 static inline bool cgroup_task_freeze(struct task_struct *task)
 {
 	bool ret;

commit 76f969e8948d82e78e1bc4beb6b9465908e74873
Author: Roman Gushchin <guro@fb.com>
Date:   Fri Apr 19 10:03:04 2019 -0700

    cgroup: cgroup v2 freezer
    
    Cgroup v1 implements the freezer controller, which provides an ability
    to stop the workload in a cgroup and temporarily free up some
    resources (cpu, io, network bandwidth and, potentially, memory)
    for some other tasks. Cgroup v2 lacks this functionality.
    
    This patch implements freezer for cgroup v2.
    
    Cgroup v2 freezer tries to put tasks into a state similar to jobctl
    stop. This means that tasks can be killed, ptraced (using
    PTRACE_SEIZE*), and interrupted. It is possible to attach to
    a frozen task, get some information (e.g. read registers) and detach.
    It's also possible to migrate a frozen tasks to another cgroup.
    
    This differs cgroup v2 freezer from cgroup v1 freezer, which mostly
    tried to imitate the system-wide freezer. However uninterruptible
    sleep is fine when all tasks are going to be frozen (hibernation case),
    it's not the acceptable state for some subset of the system.
    
    Cgroup v2 freezer is not supporting freezing kthreads.
    If a non-root cgroup contains kthread, the cgroup still can be frozen,
    but the kthread will remain running, the cgroup will be shown
    as non-frozen, and the notification will not be delivered.
    
    * PTRACE_ATTACH is not working because non-fatal signal delivery
    is blocked in frozen state.
    
    There are some interface differences between cgroup v1 and cgroup v2
    freezer too, which are required to conform the cgroup v2 interface
    design principles:
    1) There is no separate controller, which has to be turned on:
    the functionality is always available and is represented by
    cgroup.freeze and cgroup.events cgroup control files.
    2) The desired state is defined by the cgroup.freeze control file.
    Any hierarchical configuration is allowed.
    3) The interface is asynchronous. The actual state is available
    using cgroup.events control file ("frozen" field). There are no
    dedicated transitional states.
    4) It's allowed to make any changes with the cgroup hierarchy
    (create new cgroups, remove old cgroups, move tasks between cgroups)
    no matter if some cgroups are frozen.
    
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    No-objection-from-me-by: Oleg Nesterov <oleg@redhat.com>
    Cc: kernel-team@fb.com

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 81f58b4a5418..3e2efd412dfa 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -881,4 +881,47 @@ static inline void put_cgroup_ns(struct cgroup_namespace *ns)
 		free_cgroup_ns(ns);
 }
 
+#ifdef CONFIG_CGROUPS
+
+void cgroup_enter_frozen(void);
+void cgroup_leave_frozen(bool always_leave);
+void cgroup_update_frozen(struct cgroup *cgrp);
+void cgroup_freeze(struct cgroup *cgrp, bool freeze);
+void cgroup_freezer_migrate_task(struct task_struct *task, struct cgroup *src,
+				 struct cgroup *dst);
+void cgroup_freezer_frozen_exit(struct task_struct *task);
+static inline bool cgroup_task_freeze(struct task_struct *task)
+{
+	bool ret;
+
+	if (task->flags & PF_KTHREAD)
+		return false;
+
+	rcu_read_lock();
+	ret = test_bit(CGRP_FREEZE, &task_dfl_cgroup(task)->flags);
+	rcu_read_unlock();
+
+	return ret;
+}
+
+static inline bool cgroup_task_frozen(struct task_struct *task)
+{
+	return task->frozen;
+}
+
+#else /* !CONFIG_CGROUPS */
+
+static inline void cgroup_enter_frozen(void) { }
+static inline void cgroup_leave_frozen(bool always_leave) { }
+static inline bool cgroup_task_freeze(struct task_struct *task)
+{
+	return false;
+}
+static inline bool cgroup_task_frozen(struct task_struct *task)
+{
+	return false;
+}
+
+#endif /* !CONFIG_CGROUPS */
+
 #endif /* _LINUX_CGROUP_H */

commit 51bee5abeab2058ea5813c5615d6197a23dbf041
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Jan 28 17:00:13 2019 +0100

    cgroup/pids: turn cgroup_subsys->free() into cgroup_subsys->release() to fix the accounting
    
    The only user of cgroup_subsys->free() callback is pids_cgrp_subsys which
    needs pids_free() to uncharge the pid.
    
    However, ->free() is called from __put_task_struct()->cgroup_free() and this
    is too late. Even the trivial program which does
    
            for (;;) {
                    int pid = fork();
                    assert(pid >= 0);
                    if (pid)
                            wait(NULL);
                    else
                            exit(0);
            }
    
    can run out of limits because release_task()->call_rcu(delayed_put_task_struct)
    implies an RCU gp after the task/pid goes away and before the final put().
    
    Test-case:
    
            mkdir -p /tmp/CG
            mount -t cgroup2 none /tmp/CG
            echo '+pids' > /tmp/CG/cgroup.subtree_control
    
            mkdir /tmp/CG/PID
            echo 2 > /tmp/CG/PID/pids.max
    
            perl -e 'while ($p = fork) { wait; } $p // die "fork failed: $!\n"' &
            echo $! > /tmp/CG/PID/cgroup.procs
    
    Without this patch the forking process fails soon after migration.
    
    Rename cgroup_subsys->free() to cgroup_subsys->release() and move the callsite
    into the new helper, cgroup_release(), called by release_task() which actually
    frees the pid(s).
    
    Reported-by: Herton R. Krzesinski <hkrzesin@redhat.com>
    Reported-by: Jan Stancek <jstancek@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9968332cceed..81f58b4a5418 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -121,6 +121,7 @@ extern int cgroup_can_fork(struct task_struct *p);
 extern void cgroup_cancel_fork(struct task_struct *p);
 extern void cgroup_post_fork(struct task_struct *p);
 void cgroup_exit(struct task_struct *p);
+void cgroup_release(struct task_struct *p);
 void cgroup_free(struct task_struct *p);
 
 int cgroup_init_early(void);
@@ -697,6 +698,7 @@ static inline int cgroup_can_fork(struct task_struct *p) { return 0; }
 static inline void cgroup_cancel_fork(struct task_struct *p) {}
 static inline void cgroup_post_fork(struct task_struct *p) {}
 static inline void cgroup_exit(struct task_struct *p) {}
+static inline void cgroup_release(struct task_struct *p) {}
 static inline void cgroup_free(struct task_struct *p) {}
 
 static inline int cgroup_init_early(void) { return 0; }

commit fc5a828bfad628c1092194f2814604943561c52d
Author: Dennis Zhou <dennis@kernel.org>
Date:   Wed Dec 5 12:10:36 2018 -0500

    blkcg: remove additional reference to the css
    
    The previous patch in this series removed carrying around a pointer to
    the css in blkg. However, the blkg association logic still relied on
    taking a reference on the css to ensure we wouldn't fail in getting a
    reference for the blkg.
    
    Here the implicit dependency on the css is removed. The association
    continues to rely on the tryget logic walking up the blkg tree. This
    streamlines the three ways that association can happen: normal, swap,
    and writeback.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9d12757a65b0..9968332cceed 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -93,6 +93,8 @@ extern struct css_set init_css_set;
 
 bool css_has_online_children(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
+struct cgroup_subsys_state *cgroup_e_css(struct cgroup *cgroup,
+					 struct cgroup_subsys *ss);
 struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
 					     struct cgroup_subsys *ss);
 struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,

commit 5f21585384a4a69b8bfdd2cae7e3648ae805f57d
Merge: fcc37f76a995 9fe5c59ff6a1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 2 11:25:48 2018 -0700

    Merge tag 'for-linus-20181102' of git://git.kernel.dk/linux-block
    
    Pull block layer fixes from Jens Axboe:
     "The biggest part of this pull request is the revert of the blkcg
      cleanup series. It had one fix earlier for a stacked device issue, but
      another one was reported. Rather than play whack-a-mole with this,
      revert the entire series and try again for the next kernel release.
    
      Apart from that, only small fixes/changes.
    
      Summary:
    
       - Indentation fixup for mtip32xx (Colin Ian King)
    
       - The blkcg cleanup series revert (Dennis Zhou)
    
       - Two NVMe fixes. One fixing a regression in the nvme request
         initialization in this merge window, causing nvme-fc to not work.
         The other is a suspend/resume p2p resource issue (James, Keith)
    
       - Fix sg discard merge, allowing us to merge in cases where we didn't
         before (Jianchao Wang)
    
       - Call rq_qos_exit() after the queue is frozen, preventing a hang
         (Ming)
    
       - Fix brd queue setup, fixing an oops if we fail setting up all
         devices (Ming)"
    
    * tag 'for-linus-20181102' of git://git.kernel.dk/linux-block:
      nvme-pci: fix conflicting p2p resource adds
      nvme-fc: fix request private initialization
      blkcg: revert blkcg cleanups series
      block: brd: associate with queue until adding disk
      block: call rq_qos_exit() after queue is frozen
      mtip32xx: clean an indentation issue, remove extraneous tabs
      block: fix the DISCARD request merge

commit b5f2954d30c77649bce9c27e7a0a94299d9cfdf8
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Nov 1 17:24:10 2018 -0400

    blkcg: revert blkcg cleanups series
    
    This reverts a series committed earlier due to null pointer exception
    bug report in [1]. It seems there are edge case interactions that I did
    not consider and will need some time to understand what causes the
    adverse interactions.
    
    The original series can be found in [2] with a follow up series in [3].
    
    [1] https://www.spinics.net/lists/cgroups/msg20719.html
    [2] https://lore.kernel.org/lkml/20180911184137.35897-1-dennisszhou@gmail.com/
    [3] https://lore.kernel.org/lkml/20181020185612.51587-1-dennis@kernel.org/
    
    This reverts the following commits:
    d459d853c2ed, b2c3fa546705, 101246ec02b5, b3b9f24f5fcc, e2b0989954ae,
    f0fcb3ec89f3, c839e7a03f92, bdc2491708c4, 74b7c02a9bc1, 5bf9a1f3b4ef,
    a7b39b4e961c, 07b05bcc3213, 49f4c2dc2b50, 27e6fa996c53
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b8bcbdeb2eac..32c553556bbd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -93,8 +93,6 @@ extern struct css_set init_css_set;
 
 bool css_has_online_children(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
-struct cgroup_subsys_state *cgroup_e_css(struct cgroup *cgroup,
-					 struct cgroup_subsys *ss);
 struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
 					     struct cgroup_subsys *ss);
 struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,

commit 2ce7135adc9ad081aa3c49744144376ac74fea60
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Fri Oct 26 15:06:31 2018 -0700

    psi: cgroup support
    
    On a system that executes multiple cgrouped jobs and independent
    workloads, we don't just care about the health of the overall system, but
    also that of individual jobs, so that we can ensure individual job health,
    fairness between jobs, or prioritize some jobs over others.
    
    This patch implements pressure stall tracking for cgroups.  In kernels
    with CONFIG_PSI=y, cgroup2 groups will have cpu.pressure, memory.pressure,
    and io.pressure files that track aggregate pressure stall times for only
    the tasks inside the cgroup.
    
    Link: http://lkml.kernel.org/r/20180828172258.3185-10-hannes@cmpxchg.org
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Daniel Drake <drake@endlessm.com>
    Tested-by: Suren Baghdasaryan <surenb@google.com>
    Cc: Christopher Lameter <cl@linux.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Johannes Weiner <jweiner@fb.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Enderborg <peter.enderborg@sony.com>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Vinayak Menon <vinmenon@codeaurora.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b622d6608605..9968332cceed 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -650,6 +650,11 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 	pr_cont_kernfs_path(cgrp->kn);
 }
 
+static inline struct psi_group *cgroup_psi(struct cgroup *cgrp)
+{
+	return &cgrp->psi;
+}
+
 static inline void cgroup_init_kthreadd(void)
 {
 	/*
@@ -703,6 +708,16 @@ static inline union kernfs_node_id *cgroup_get_kernfs_id(struct cgroup *cgrp)
 	return NULL;
 }
 
+static inline struct cgroup *cgroup_parent(struct cgroup *cgrp)
+{
+	return NULL;
+}
+
+static inline struct psi_group *cgroup_psi(struct cgroup *cgrp)
+{
+	return NULL;
+}
+
 static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
 					       struct cgroup *ancestor)
 {

commit 83c4087ce468601501ecde4d0ec5b2abd5f57c31
Merge: a67eefad996f a90e90b7d55e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 25 17:15:46 2018 -0700

    Merge branch 'for-4.20' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
     "All trivial changes - simplification, typo fix and adding
      cond_resched() in a netclassid update loop"
    
    * 'for-4.20' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup, netclassid: add a preemption point to write_classid
      rdmacg: fix a typo in rdmacg documentation
      cgroup: Simplify cgroup_ancestor

commit 808c43b7c7f70360ed7b9e43e2cf980f388e71fa
Author: Andrey Ignatov <rdna@fb.com>
Date:   Fri Sep 21 17:03:27 2018 -0700

    cgroup: Simplify cgroup_ancestor
    
    Simplify cgroup_ancestor function. This is follow-up for
    commit 7723628101aa ("bpf: Introduce bpf_skb_ancestor_cgroup_id helper")
    
    Suggested-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrey Ignatov <rdna@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 32c553556bbd..e03a92430383 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -567,20 +567,11 @@ static inline bool cgroup_is_descendant(struct cgroup *cgrp,
 static inline struct cgroup *cgroup_ancestor(struct cgroup *cgrp,
 					     int ancestor_level)
 {
-	struct cgroup *ptr;
-
 	if (cgrp->level < ancestor_level)
 		return NULL;
-
-	for (ptr = cgrp;
-	     ptr && ptr->level > ancestor_level;
-	     ptr = cgroup_parent(ptr))
-		;
-
-	if (ptr && ptr->level == ancestor_level)
-		return ptr;
-
-	return NULL;
+	while (cgrp && cgrp->level > ancestor_level)
+		cgrp = cgroup_parent(cgrp);
+	return cgrp;
 }
 
 /**

commit f0fcb3ec89f37167810e660b0595d9a6155d9807
Author: Dennis Zhou (Facebook) <dennisszhou@gmail.com>
Date:   Tue Sep 11 14:41:34 2018 -0400

    blkcg: remove additional reference to the css
    
    The previous patch in this series removed carrying around a pointer to
    the css in blkg. However, the blkg association logic still relied on
    taking a reference on the css to ensure we wouldn't fail in getting a
    reference for the blkg.
    
    Here the implicit dependency on the css is removed. The association
    continues to rely on the tryget logic walking up the blkg tree. This
    streamlines the three ways that association can happen: normal, swap,
    and writeback.
    
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Dennis Zhou <dennisszhou@gmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 32c553556bbd..b8bcbdeb2eac 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -93,6 +93,8 @@ extern struct css_set init_css_set;
 
 bool css_has_online_children(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
+struct cgroup_subsys_state *cgroup_e_css(struct cgroup *cgroup,
+					 struct cgroup_subsys *ss);
 struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
 					     struct cgroup_subsys *ss);
 struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,

commit 7723628101aaeb1d723786747529b4ea65c5b5c5
Author: Andrey Ignatov <rdna@fb.com>
Date:   Sun Aug 12 10:49:27 2018 -0700

    bpf: Introduce bpf_skb_ancestor_cgroup_id helper
    
    == Problem description ==
    
    It's useful to be able to identify cgroup associated with skb in TC so
    that a policy can be applied to this skb, and existing bpf_skb_cgroup_id
    helper can help with this.
    
    Though in real life cgroup hierarchy and hierarchy to apply a policy to
    don't map 1:1.
    
    It's often the case that there is a container and corresponding cgroup,
    but there are many more sub-cgroups inside container, e.g. because it's
    delegated to containerized application to control resources for its
    subsystems, or to separate application inside container from infra that
    belongs to containerization system (e.g. sshd).
    
    At the same time it may be useful to apply a policy to container as a
    whole.
    
    If multiple containers like this are run on a host (what is often the
    case) and many of them have sub-cgroups, it may not be possible to apply
    per-container policy in TC with existing helpers such as
    bpf_skb_under_cgroup or bpf_skb_cgroup_id:
    
    * bpf_skb_cgroup_id will return id of immediate cgroup associated with
      skb, i.e. if it's a sub-cgroup inside container, it can't be used to
      identify container's cgroup;
    
    * bpf_skb_under_cgroup can work only with one cgroup and doesn't scale,
      i.e. if there are N containers on a host and a policy has to be
      applied to M of them (0 <= M <= N), it'd require M calls to
      bpf_skb_under_cgroup, and, if M changes, it'd require to rebuild &
      load new BPF program.
    
    == Solution ==
    
    The patch introduces new helper bpf_skb_ancestor_cgroup_id that can be
    used to get id of cgroup v2 that is an ancestor of cgroup associated
    with skb at specified level of cgroup hierarchy.
    
    That way admin can place all containers on one level of cgroup hierarchy
    (what is a good practice in general and already used in many
    configurations) and identify specific cgroup on this level no matter
    what sub-cgroup skb is associated with.
    
    E.g. if there is a cgroup hierarchy:
      root/
      root/container1/
      root/container1/app11/
      root/container1/app11/sub-app-a/
      root/container1/app12/
      root/container2/
      root/container2/app21/
      root/container2/app22/
      root/container2/app22/sub-app-b/
    
    , then having skb associated with root/container1/app11/sub-app-a/ it's
    possible to get ancestor at level 1, what is container1 and apply policy
    for this container, or apply another policy if it's container2.
    
    Policies can be kept e.g. in a hash map where key is a container cgroup
    id and value is an action.
    
    Levels where container cgroups are created are usually known in advance
    whether cgroup hierarchy inside container may be hard to predict
    especially in case when its creation is delegated to containerized
    application.
    
    == Implementation details ==
    
    The helper gets ancestor by walking parents up to specified level.
    
    Another option would be to get different kind of "id" from
    cgroup->ancestor_ids[level] and use it with idr_find() to get struct
    cgroup for ancestor. But that would require radix lookup what doesn't
    seem to be better (at least it's not obviously better).
    
    Format of return value of the new helper is same as that of
    bpf_skb_cgroup_id.
    
    Signed-off-by: Andrey Ignatov <rdna@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c9fdf6f57913..32c553556bbd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -553,6 +553,36 @@ static inline bool cgroup_is_descendant(struct cgroup *cgrp,
 	return cgrp->ancestor_ids[ancestor->level] == ancestor->id;
 }
 
+/**
+ * cgroup_ancestor - find ancestor of cgroup
+ * @cgrp: cgroup to find ancestor of
+ * @ancestor_level: level of ancestor to find starting from root
+ *
+ * Find ancestor of cgroup at specified level starting from root if it exists
+ * and return pointer to it. Return NULL if @cgrp doesn't have ancestor at
+ * @ancestor_level.
+ *
+ * This function is safe to call as long as @cgrp is accessible.
+ */
+static inline struct cgroup *cgroup_ancestor(struct cgroup *cgrp,
+					     int ancestor_level)
+{
+	struct cgroup *ptr;
+
+	if (cgrp->level < ancestor_level)
+		return NULL;
+
+	for (ptr = cgrp;
+	     ptr && ptr->level > ancestor_level;
+	     ptr = cgroup_parent(ptr))
+		;
+
+	if (ptr && ptr->level == ancestor_level)
+		return ptr;
+
+	return NULL;
+}
+
 /**
  * task_under_cgroup_hierarchy - test task's membership of cgroup ancestry
  * @task: the task to be tested

commit 0fa294fb1985c06c4e3325e30e759d4ca580f59a
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Apr 26 14:29:05 2018 -0700

    cgroup: Replace cgroup_rstat_mutex with a spinlock
    
    Currently, rstat flush path is protected with a mutex which is fine as
    all the existing users are from interface file show path.  However,
    rstat is being generalized for use by controllers and flushing from
    atomic contexts will be necessary.
    
    This patch replaces cgroup_rstat_mutex with a spinlock and adds a
    irq-safe flush function - cgroup_rstat_flush_irqsafe().  Explicit
    yield handling is added to the flush path so that other flush
    functions can yield to other threads and flushers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5c6018fef5aa..c9fdf6f57913 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -696,6 +696,7 @@ static inline void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
  */
 void cgroup_rstat_updated(struct cgroup *cgrp, int cpu);
 void cgroup_rstat_flush(struct cgroup *cgrp);
+void cgroup_rstat_flush_irqsafe(struct cgroup *cgrp);
 void cgroup_rstat_flush_hold(struct cgroup *cgrp);
 void cgroup_rstat_flush_release(void);
 

commit 6162cef0f741c70eb0c7ac7e6142f85808d8abc4
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Apr 26 14:29:05 2018 -0700

    cgroup: Factor out and expose cgroup_rstat_*() interface functions
    
    cgroup_rstat is being generalized so that controllers can use it too.
    This patch factors out and exposes the following interface functions.
    
    * cgroup_rstat_updated(): Renamed from cgroup_rstat_cpu_updated() for
      consistency.
    
    * cgroup_rstat_flush_hold/release(): Factored out from base stat
      implementation.
    
    * cgroup_rstat_flush(): Verbatim expose.
    
    While at it, drop assert on cgroup_rstat_mutex in
    cgroup_base_stat_flush() as it crosses layers and make a minor comment
    update.
    
    v2: Added EXPORT_SYMBOL_GPL(cgroup_rstat_updated) to fix a build bug.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 473e0c0abb86..5c6018fef5aa 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -690,11 +690,18 @@ static inline void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
 	char *buf, size_t buflen) {}
 #endif /* !CONFIG_CGROUPS */
 
+#ifdef CONFIG_CGROUPS
 /*
- * Basic resource stats.
+ * cgroup scalable recursive statistics.
  */
-#ifdef CONFIG_CGROUPS
+void cgroup_rstat_updated(struct cgroup *cgrp, int cpu);
+void cgroup_rstat_flush(struct cgroup *cgrp);
+void cgroup_rstat_flush_hold(struct cgroup *cgrp);
+void cgroup_rstat_flush_release(void);
 
+/*
+ * Basic resource stats.
+ */
 #ifdef CONFIG_CGROUP_CPUACCT
 void cpuacct_charge(struct task_struct *tsk, u64 cputime);
 void cpuacct_account_field(struct task_struct *tsk, int index, u64 val);

commit 22714a2ba4b55737cd7d5299db7aaf1fa8287354
Merge: 766ec76a27aa 5f2e673405b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 15 14:29:44 2017 -0800

    Merge branch 'for-4.15' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
     "Cgroup2 cpu controller support is finally merged.
    
       - Basic cpu statistics support to allow monitoring by default without
         the CPU controller enabled.
    
       - cgroup2 cpu controller support.
    
       - /sys/kernel/cgroup files to help dealing with new / optional
         features"
    
    * 'for-4.15' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: export list of cgroups v2 features using sysfs
      cgroup: export list of delegatable control files using sysfs
      cgroup: mark @cgrp __maybe_unused in cpu_stat_show()
      MAINTAINERS: relocate cpuset.c
      cgroup, sched: Move basic cpu stats from cgroup.stat to cpu.stat
      sched: Implement interface for cgroup unified hierarchy
      sched: Misc preps for cgroup unified hierarchy interface
      sched/cputime: Add dummy cputime_adjust() implementation for CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
      cgroup: statically initialize init_css_set->dfl_cgrp
      cgroup: Implement cgroup2 basic CPU usage accounting
      cpuacct: Introduce cgroup_account_cputime[_field]()
      sched/cputime: Expose cputime_adjust()

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d023ac5e377f..dddbc29e2009 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LINUX_CGROUP_H
 #define _LINUX_CGROUP_H
 /*

commit d41bf8c9deaed1a90b18d3ffc5639d4c19f0259a
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Oct 23 16:18:27 2017 -0700

    cgroup, sched: Move basic cpu stats from cgroup.stat to cpu.stat
    
    The basic cpu stat is currently shown with "cpu." prefix in
    cgroup.stat, and the same information is duplicated in cpu.stat when
    cpu controller is enabled.  This is ugly and not very scalable as we
    want to expand the coverage of stat information which is always
    available.
    
    This patch makes cgroup core always create "cpu.stat" file and show
    the basic cpu stat there and calls the cpu controller to show the
    extra stats when enabled.  This ensures that the same information
    isn't presented in multiple places and makes future expansion of basic
    stats easier.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 328a70ce0e23..03cad08b09d1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -703,8 +703,6 @@ static inline void cpuacct_account_field(struct task_struct *tsk, int index,
 					 u64 val) {}
 #endif
 
-void cgroup_stat_show_cputime(struct seq_file *seq, const char *prefix);
-
 void __cgroup_account_cputime(struct cgroup *cgrp, u64 delta_exec);
 void __cgroup_account_cputime_field(struct cgroup *cgrp,
 				    enum cpu_usage_stat index, u64 delta_exec);

commit 041cd640b2f3c5607171c59d8712b503659d21f7
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 25 08:12:05 2017 -0700

    cgroup: Implement cgroup2 basic CPU usage accounting
    
    In cgroup1, while cpuacct isn't actually controlling any resources, it
    is a separate controller due to combination of two factors -
    1. enabling cpu controller has significant side effects, and 2. we
    have to pick one of the hierarchies to account CPU usages on.  cpuacct
    controller is effectively used to designate a hierarchy to track CPU
    usages on.
    
    cgroup2's unified hierarchy removes the second reason and we can
    account basic CPU usages by default.  While we can use cpuacct for
    this purpose, both its interface and implementation leave a lot to be
    desired - it collects and exposes two sources of truth which don't
    agree with each other and some of the exposed statistics don't make
    much sense.  Also, it propagates all the way up the hierarchy on each
    accounting event which is unnecessary.
    
    This patch adds basic resource accounting mechanism to cgroup2's
    unified hierarchy and accounts CPU usages using it.
    
    * All accountings are done per-cpu and don't propagate immediately.
      It just bumps the per-cgroup per-cpu counters and links to the
      parent's updated list if not already on it.
    
    * On a read, the per-cpu counters are collected into the global ones
      and then propagated upwards.  Only the per-cpu counters which have
      changed since the last read are propagated.
    
    * CPU usage stats are collected and shown in "cgroup.stat" with "cpu."
      prefix.  Total usage is collected from scheduling events.  User/sys
      breakdown is sourced from tick sampling and adjusted to the usage
      using cputime_adjust().
    
    This keeps the accounting side hot path O(1) and per-cpu and the read
    side O(nr_updated_since_last_read).
    
    v2: Minor changes and documentation updates as suggested by Waiman and
        Roman.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Waiman Long <longman@redhat.com>
    Cc: Roman Gushchin <guro@fb.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 6cd579329310..328a70ce0e23 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -703,17 +703,39 @@ static inline void cpuacct_account_field(struct task_struct *tsk, int index,
 					 u64 val) {}
 #endif
 
+void cgroup_stat_show_cputime(struct seq_file *seq, const char *prefix);
+
+void __cgroup_account_cputime(struct cgroup *cgrp, u64 delta_exec);
+void __cgroup_account_cputime_field(struct cgroup *cgrp,
+				    enum cpu_usage_stat index, u64 delta_exec);
+
 static inline void cgroup_account_cputime(struct task_struct *task,
 					  u64 delta_exec)
 {
+	struct cgroup *cgrp;
+
 	cpuacct_charge(task, delta_exec);
+
+	rcu_read_lock();
+	cgrp = task_dfl_cgroup(task);
+	if (cgroup_parent(cgrp))
+		__cgroup_account_cputime(cgrp, delta_exec);
+	rcu_read_unlock();
 }
 
 static inline void cgroup_account_cputime_field(struct task_struct *task,
 						enum cpu_usage_stat index,
 						u64 delta_exec)
 {
+	struct cgroup *cgrp;
+
 	cpuacct_account_field(task, index, delta_exec);
+
+	rcu_read_lock();
+	cgrp = task_dfl_cgroup(task);
+	if (cgroup_parent(cgrp))
+		__cgroup_account_cputime_field(cgrp, index, delta_exec);
+	rcu_read_unlock();
 }
 
 #else	/* CONFIG_CGROUPS */

commit d2cc5ed6949085cfba30ec5228816cf6eb1d02b9
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 25 08:12:04 2017 -0700

    cpuacct: Introduce cgroup_account_cputime[_field]()
    
    Introduce cgroup_account_cputime[_field]() which wrap cpuacct_charge()
    and cgroup_account_field().  This doesn't introduce any functional
    changes and will be used to add cgroup basic resource accounting.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d023ac5e377f..6cd579329310 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -22,6 +22,7 @@
 #include <linux/nsproxy.h>
 #include <linux/user_namespace.h>
 #include <linux/refcount.h>
+#include <linux/kernel_stat.h>
 
 #include <linux/cgroup-defs.h>
 
@@ -688,6 +689,43 @@ static inline void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
 	char *buf, size_t buflen) {}
 #endif /* !CONFIG_CGROUPS */
 
+/*
+ * Basic resource stats.
+ */
+#ifdef CONFIG_CGROUPS
+
+#ifdef CONFIG_CGROUP_CPUACCT
+void cpuacct_charge(struct task_struct *tsk, u64 cputime);
+void cpuacct_account_field(struct task_struct *tsk, int index, u64 val);
+#else
+static inline void cpuacct_charge(struct task_struct *tsk, u64 cputime) {}
+static inline void cpuacct_account_field(struct task_struct *tsk, int index,
+					 u64 val) {}
+#endif
+
+static inline void cgroup_account_cputime(struct task_struct *task,
+					  u64 delta_exec)
+{
+	cpuacct_charge(task, delta_exec);
+}
+
+static inline void cgroup_account_cputime_field(struct task_struct *task,
+						enum cpu_usage_stat index,
+						u64 delta_exec)
+{
+	cpuacct_account_field(task, index, delta_exec);
+}
+
+#else	/* CONFIG_CGROUPS */
+
+static inline void cgroup_account_cputime(struct task_struct *task,
+					  u64 delta_exec) {}
+static inline void cgroup_account_cputime_field(struct task_struct *task,
+						enum cpu_usage_stat index,
+						u64 delta_exec) {}
+
+#endif	/* CONFIG_CGROUPS */
+
 /*
  * sock->sk_cgrp_data handling.  For more info, see sock_cgroup_data
  * definition in cgroup-defs.h.

commit a0725ab0c7536076d5477264420ef420ebb64501
Merge: 3ee31b89d9b1 ef13ecbc134d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 7 11:59:42 2017 -0700

    Merge branch 'for-4.14/block' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
     "This is the first pull request for 4.14, containing most of the code
      changes. It's a quiet series this round, which I think we needed after
      the churn of the last few series. This contains:
    
       - Fix for a registration race in loop, from Anton Volkov.
    
       - Overflow complaint fix from Arnd for DAC960.
    
       - Series of drbd changes from the usual suspects.
    
       - Conversion of the stec/skd driver to blk-mq. From Bart.
    
       - A few BFQ improvements/fixes from Paolo.
    
       - CFQ improvement from Ritesh, allowing idling for group idle.
    
       - A few fixes found by Dan's smatch, courtesy of Dan.
    
       - A warning fixup for a race between changing the IO scheduler and
         device remova. From David Jeffery.
    
       - A few nbd fixes from Josef.
    
       - Support for cgroup info in blktrace, from Shaohua.
    
       - Also from Shaohua, new features in the null_blk driver to allow it
         to actually hold data, among other things.
    
       - Various corner cases and error handling fixes from Weiping Zhang.
    
       - Improvements to the IO stats tracking for blk-mq from me. Can
         drastically improve performance for fast devices and/or big
         machines.
    
       - Series from Christoph removing bi_bdev as being needed for IO
         submission, in preparation for nvme multipathing code.
    
       - Series from Bart, including various cleanups and fixes for switch
         fall through case complaints"
    
    * 'for-4.14/block' of git://git.kernel.dk/linux-block: (162 commits)
      kernfs: checking for IS_ERR() instead of NULL
      drbd: remove BIOSET_NEED_RESCUER flag from drbd_{md_,}io_bio_set
      drbd: Fix allyesconfig build, fix recent commit
      drbd: switch from kmalloc() to kmalloc_array()
      drbd: abort drbd_start_resync if there is no connection
      drbd: move global variables to drbd namespace and make some static
      drbd: rename "usermode_helper" to "drbd_usermode_helper"
      drbd: fix race between handshake and admin disconnect/down
      drbd: fix potential deadlock when trying to detach during handshake
      drbd: A single dot should be put into a sequence.
      drbd: fix rmmod cleanup, remove _all_ debugfs entries
      drbd: Use setup_timer() instead of init_timer() to simplify the code.
      drbd: fix potential get_ldev/put_ldev refcount imbalance during attach
      drbd: new disk-option disable-write-same
      drbd: Fix resource role for newly created resources in events2
      drbd: mark symbols static where possible
      drbd: Send P_NEG_ACK upon write error in protocol != C
      drbd: add explicit plugging when submitting batches
      drbd: change list_for_each_safe to while(list_first_entry_or_null)
      drbd: introduce drbd_recv_header_maybe_unplug
      ...

commit 3e48930cc74f0c212ee1838f89ad0ca7fcf2fea1
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Aug 11 05:49:01 2017 -0700

    cgroup: misc changes
    
    Misc trivial changes to prepare for future changes.  No functional
    difference.
    
    * Expose cgroup_get(), cgroup_tryget() and cgroup_parent().
    
    * Implement task_dfl_cgroup() which dereferences css_set->dfl_cgrp.
    
    * Rename cgroup_stats_show() to cgroup_stat_show() for consistency
      with the file name.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 79faa6467f76..085056e562b1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -398,6 +398,16 @@ static inline void css_put_many(struct cgroup_subsys_state *css, unsigned int n)
 		percpu_ref_put_many(&css->refcnt, n);
 }
 
+static inline void cgroup_get(struct cgroup *cgrp)
+{
+	css_get(&cgrp->self);
+}
+
+static inline bool cgroup_tryget(struct cgroup *cgrp)
+{
+	return css_tryget(&cgrp->self);
+}
+
 static inline void cgroup_put(struct cgroup *cgrp)
 {
 	css_put(&cgrp->self);
@@ -510,6 +520,20 @@ static inline struct cgroup *task_cgroup(struct task_struct *task,
 	return task_css(task, subsys_id)->cgroup;
 }
 
+static inline struct cgroup *task_dfl_cgroup(struct task_struct *task)
+{
+	return task_css_set(task)->dfl_cgrp;
+}
+
+static inline struct cgroup *cgroup_parent(struct cgroup *cgrp)
+{
+	struct cgroup_subsys_state *parent_css = cgrp->self.parent;
+
+	if (parent_css)
+		return container_of(parent_css, struct cgroup, self);
+	return NULL;
+}
+
 /**
  * cgroup_is_descendant - test ancestry
  * @cgrp: the cgroup to be tested

commit 69fd5c391763bd94a40dd152bc72a7f230137150
Author: Shaohua Li <shli@fb.com>
Date:   Wed Jul 12 11:49:55 2017 -0700

    blktrace: add an option to allow displaying cgroup path
    
    By default we output cgroup id in blktrace. This adds an option to
    display cgroup path. Since get cgroup path is a relativly heavy
    operation, we don't enable it by default.
    
    with the option enabled, blktrace will output something like this:
    dd-1353  [007] d..2   293.015252:   8,0   /test/level  D   R 24 + 8 [dd]
    
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 52ef9a68ff14..6144fe923b73 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -613,6 +613,9 @@ static inline union kernfs_node_id *cgroup_get_kernfs_id(struct cgroup *cgrp)
 {
 	return &cgrp->kn->id;
 }
+
+void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
+					char *buf, size_t buflen);
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;
@@ -645,6 +648,9 @@ static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
 {
 	return true;
 }
+
+static inline void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
+	char *buf, size_t buflen) {}
 #endif /* !CONFIG_CGROUPS */
 
 /*

commit 121508df44d074245a72eda6b067478218480a40
Author: Shaohua Li <shli@fb.com>
Date:   Wed Jul 12 11:49:52 2017 -0700

    cgroup: export fhandle info for a cgroup
    
    Add an API to export cgroup fhandle info. We don't export a full 'struct
    file_handle', there are unrequired info. Sepcifically, cgroup is always
    a directory, so we don't need a 'FILEID_INO32_GEN_PARENT' type fhandle,
    we only need export the inode number and generation number just like
    what generic_fh_to_dentry does. And we can avoid the overhead of getting
    an inode too, since kernfs_node_id (ino and generation) has all the info
    required.
    
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 30c68773fd1e..52ef9a68ff14 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -609,6 +609,10 @@ static inline void cgroup_kthread_ready(void)
 	current->no_cgroup_migration = 0;
 }
 
+static inline union kernfs_node_id *cgroup_get_kernfs_id(struct cgroup *cgrp)
+{
+	return &cgrp->kn->id;
+}
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;
@@ -631,6 +635,10 @@ static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_init_kthreadd(void) {}
 static inline void cgroup_kthread_ready(void) {}
+static inline union kernfs_node_id *cgroup_get_kernfs_id(struct cgroup *cgrp)
+{
+	return NULL;
+}
 
 static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
 					       struct cgroup *ancestor)

commit c53cd490b1a491ebf1d8e30da97e7231459a4208
Author: Shaohua Li <shli@fb.com>
Date:   Wed Jul 12 11:49:50 2017 -0700

    kernfs: introduce kernfs_node_id
    
    inode number and generation can identify a kernfs node. We are going to
    export the identification by exportfs operations, so put ino and
    generation into a separate structure. It's convenient when later patches
    use the identification.
    
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 710a005c6b7a..30c68773fd1e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -543,7 +543,7 @@ static inline bool cgroup_is_populated(struct cgroup *cgrp)
 /* returns ino associated with a cgroup */
 static inline ino_t cgroup_ino(struct cgroup *cgrp)
 {
-	return cgrp->kn->ino;
+	return cgrp->kn->id.ino;
 }
 
 /* cft/css accessors for cftype->write() operation */

commit 450ee0c1feed657894e0b4bdd48f3974af9d394c
Author: Tejun Heo <tj@kernel.org>
Date:   Mon May 15 09:34:03 2017 -0400

    cgroup: implement CSS_TASK_ITER_THREADED
    
    cgroup v2 is in the process of growing thread granularity support.
    Once thread mode is enabled, the root cgroup of the subtree serves as
    the dom_cgrp to which the processes of the subtree conceptually belong
    and domain-level resource consumptions not tied to any specific task
    are charged.  In the subtree, threads won't be subject to process
    granularity or no-internal-task constraint and can be distributed
    arbitrarily across the subtree.
    
    This patch implements a new task iterator flag CSS_TASK_ITER_THREADED,
    which, when used on a dom_cgrp, makes the iteration include the tasks
    on all the associated threaded css_sets.  "cgroup.procs" read path is
    updated to use it so that reading the file on a proc_cgrp lists all
    processes.  This will also be used by controller implementations which
    need to walk processes or tasks at the resource domain level.
    
    Task iteration is implemented nested in css_set iteration.  If
    CSS_TASK_ITER_THREADED is specified, after walking tasks of each
    !threaded css_set, all the associated threaded css_sets are visited
    before moving onto the next !threaded css_set.
    
    v2: ->cur_pcset renamed to ->cur_dcset.  Updated for the new
        enable-threaded-per-cgroup behavior.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b7dd23040cd5..79faa6467f76 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -38,6 +38,8 @@
 
 /* walk only threadgroup leaders */
 #define CSS_TASK_ITER_PROCS		(1U << 0)
+/* walk all threaded css_sets in the domain */
+#define CSS_TASK_ITER_THREADED		(1U << 1)
 
 /* a css_task_iter should be treated as an opaque object */
 struct css_task_iter {
@@ -47,11 +49,15 @@ struct css_task_iter {
 	struct list_head		*cset_pos;
 	struct list_head		*cset_head;
 
+	struct list_head		*tcset_pos;
+	struct list_head		*tcset_head;
+
 	struct list_head		*task_pos;
 	struct list_head		*tasks_head;
 	struct list_head		*mg_tasks_head;
 
 	struct css_set			*cur_cset;
+	struct css_set			*cur_dcset;
 	struct task_struct		*cur_task;
 	struct list_head		iters_node;	/* css_set->task_iters */
 };

commit 454000adaa2a7420df6e56a42f22726d05872a3f
Author: Tejun Heo <tj@kernel.org>
Date:   Mon May 15 09:34:02 2017 -0400

    cgroup: introduce cgroup->dom_cgrp and threaded css_set handling
    
    cgroup v2 is in the process of growing thread granularity support.  A
    threaded subtree is composed of a thread root and threaded cgroups
    which are proper members of the subtree.
    
    The root cgroup of the subtree serves as the domain cgroup to which
    the processes (as opposed to threads / tasks) of the subtree
    conceptually belong and domain-level resource consumptions not tied to
    any specific task are charged.  Inside the subtree, threads won't be
    subject to process granularity or no-internal-task constraint and can
    be distributed arbitrarily across the subtree.
    
    This patch introduces cgroup->dom_cgrp along with threaded css_set
    handling.
    
    * cgroup->dom_cgrp points to self for normal and thread roots.  For
      proper thread subtree members, points to the dom_cgrp (the thread
      root).
    
    * css_set->dom_cset points to self if for normal and thread roots.  If
      threaded, points to the css_set which belongs to the cgrp->dom_cgrp.
      The dom_cgrp serves as the resource domain and keeps the matching
      csses available.  The dom_cset holds those csses and makes them
      easily accessible.
    
    * All threaded csets are linked on their dom_csets to enable iteration
      of all threaded tasks.
    
    * cgroup->nr_threaded_children keeps track of the number of threaded
      children.
    
    This patch adds the above but doesn't actually use them yet.  The
    following patches will build on top.
    
    v4: ->nr_threaded_children added.
    
    v3: ->proc_cgrp/cset renamed to ->dom_cgrp/cset.  Updated for the new
        enable-threaded-per-cgroup behavior.
    
    v2: Added cgroup_is_threaded() helper.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cae5831ae650..b7dd23040cd5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -541,7 +541,8 @@ static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
 /* no synchronization, the result can only be used as a hint */
 static inline bool cgroup_is_populated(struct cgroup *cgrp)
 {
-	return cgrp->nr_populated_csets + cgrp->nr_populated_children;
+	return cgrp->nr_populated_csets + cgrp->nr_populated_domain_children +
+		cgrp->nr_populated_threaded_children;
 }
 
 /* returns ino associated with a cgroup */

commit bc2fb7ed089ffd16d26e1d95b898a37d2b37d201
Author: Tejun Heo <tj@kernel.org>
Date:   Mon May 15 09:34:01 2017 -0400

    cgroup: add @flags to css_task_iter_start() and implement CSS_TASK_ITER_PROCS
    
    css_task_iter currently always walks all tasks.  With the scheduled
    cgroup v2 thread support, the iterator would need to handle multiple
    types of iteration.  As a preparation, add @flags to
    css_task_iter_start() and implement CSS_TASK_ITER_PROCS.  If the flag
    is not specified, it walks all tasks as before.  When asserted, the
    iterator only walks the group leaders.
    
    For now, the only user of the flag is cgroup v2 "cgroup.procs" file
    which no longer needs to skip non-leader tasks in cgroup_procs_next().
    Note that cgroup v1 "cgroup.procs" can't use the group leader walk as
    v1 "cgroup.procs" doesn't mean "list all thread group leaders in the
    cgroup" but "list all thread group id's with any threads in the
    cgroup".
    
    While at it, update cgroup_procs_show() to use task_pid_vnr() instead
    of task_tgid_vnr().  As the iteration guarantees that the function
    only sees group leaders, this doesn't change the output and will allow
    sharing the function for thread iteration.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 308b10797a54..cae5831ae650 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -36,9 +36,13 @@
 #define CGROUP_WEIGHT_DFL		100
 #define CGROUP_WEIGHT_MAX		10000
 
+/* walk only threadgroup leaders */
+#define CSS_TASK_ITER_PROCS		(1U << 0)
+
 /* a css_task_iter should be treated as an opaque object */
 struct css_task_iter {
 	struct cgroup_subsys		*ss;
+	unsigned int			flags;
 
 	struct list_head		*cset_pos;
 	struct list_head		*cset_head;
@@ -129,7 +133,7 @@ struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset,
 struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset,
 					struct cgroup_subsys_state **dst_cssp);
 
-void css_task_iter_start(struct cgroup_subsys_state *css,
+void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,
 			 struct css_task_iter *it);
 struct task_struct *css_task_iter_next(struct css_task_iter *it);
 void css_task_iter_end(struct css_task_iter *it);

commit 788b950c62e06b02278a0fd380e1a0667996ce3c
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Jul 16 21:43:33 2017 -0400

    cgroup: distinguish local and children populated states
    
    cgrp->populated_cnt counts both local (the cgroup's populated
    css_sets) and subtree proper (populated children) so that it's only
    zero when the whole subtree, including self, is empty.
    
    This patch splits the counter into two so that local and children
    populated states are tracked separately.  It allows finer-grained
    tests on the state of the hierarchy which will be used to replace
    css_set walking local populated test.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 710a005c6b7a..308b10797a54 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -537,7 +537,7 @@ static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
 /* no synchronization, the result can only be used as a hint */
 static inline bool cgroup_is_populated(struct cgroup *cgrp)
 {
-	return cgrp->populated_cnt;
+	return cgrp->nr_populated_csets + cgrp->nr_populated_children;
 }
 
 /* returns ino associated with a cgroup */

commit 41c25707d21716826e3c1f60967f5550610ec1c9
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 24 12:03:48 2017 -0400

    cpuset: consider dying css as offline
    
    In most cases, a cgroup controller don't care about the liftimes of
    cgroups.  For the controller, a css becomes online when ->css_online()
    is called on it and offline when ->css_offline() is called.
    
    However, cpuset is special in that the user interface it exposes cares
    whether certain cgroups exist or not.  Combined with the RCU delay
    between cgroup removal and css offlining, this can lead to user
    visible behavior oddities where operations which should succeed after
    cgroup removals fail for some time period.  The effects of cgroup
    removals are delayed when seen from userland.
    
    This patch adds css_is_dying() which tests whether offline is pending
    and updates is_cpuset_online() so that the function returns false also
    while offline is pending.  This gets rid of the userland visible
    delays.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Link: http://lkml.kernel.org/r/327ca1f5-7957-fbb9-9e5f-9ba149d40ba2@oracle.com
    Cc: stable@vger.kernel.org
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ed2573e149fa..710a005c6b7a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -343,6 +343,26 @@ static inline bool css_tryget_online(struct cgroup_subsys_state *css)
 	return true;
 }
 
+/**
+ * css_is_dying - test whether the specified css is dying
+ * @css: target css
+ *
+ * Test whether @css is in the process of offlining or already offline.  In
+ * most cases, ->css_online() and ->css_offline() callbacks should be
+ * enough; however, the actual offline operations are RCU delayed and this
+ * test returns %true also when @css is scheduled to be offlined.
+ *
+ * This is useful, for example, when the use case requires synchronous
+ * behavior with respect to cgroup removal.  cgroup removal schedules css
+ * offlining but the css can seem alive while the operation is being
+ * delayed.  If the delay affects user visible semantics, this test can be
+ * used to resolve the situation.
+ */
+static inline bool css_is_dying(struct cgroup_subsys_state *css)
+{
+	return !(css->flags & CSS_NO_REF) && percpu_ref_is_dying(&css->refcnt);
+}
+
 /**
  * css_put - put a css reference
  * @css: target css

commit 9410091dd5b4097819fcbb6d63987c51f62c85fd
Merge: ad1490bcd248 310b4816a5d8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 13:52:24 2017 -0700

    Merge branch 'for-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
     "Nothing major. Two notable fixes are Li's second stab at fixing the
      long-standing race condition in the mount path and suppression of
      spurious warning from cgroup_get(). All other changes are trivial"
    
    * 'for-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: mark cgroup_get() with __maybe_unused
      cgroup: avoid attaching a cgroup root to two different superblocks, take 2
      cgroup: fix spurious warnings on cgroup_is_dead() from cgroup_sk_alloc()
      cgroup: move cgroup_subsys_state parent field for cache locality
      cpuset: Remove cpuset_update_active_cpus()'s parameter.
      cgroup: switch to BUG_ON()
      cgroup: drop duplicate header nsproxy.h
      kernel: convert css_set.refcount from atomic_t to refcount_t
      kernel: convert cgroup_namespace.count from atomic_t to refcount_t

commit 8f48cfabac57977338f5c828ed3e12fc34373c7d
Author: Geliang Tang <geliangtang@gmail.com>
Date:   Fri Mar 24 22:13:35 2017 +0800

    cgroup: drop duplicate header nsproxy.h
    
    Drop duplicate header nsproxy.h from linux/cgroup.h.
    
    Signed-off-by: Geliang Tang <geliangtang@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 44129793c7b8..34b4a298e52e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -17,7 +17,6 @@
 #include <linux/seq_file.h>
 #include <linux/kernfs.h>
 #include <linux/jump_label.h>
-#include <linux/nsproxy.h>
 #include <linux/types.h>
 #include <linux/ns_common.h>
 #include <linux/nsproxy.h>

commit 77f88796cee819b9c4562b0b6b44691b3b7755b1
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Mar 16 16:54:24 2017 -0400

    cgroup, kthread: close race window where new kthreads can be migrated to non-root cgroups
    
    Creation of a kthread goes through a couple interlocked stages between
    the kthread itself and its creator.  Once the new kthread starts
    running, it initializes itself and wakes up the creator.  The creator
    then can further configure the kthread and then let it start doing its
    job by waking it up.
    
    In this configuration-by-creator stage, the creator is the only one
    that can wake it up but the kthread is visible to userland.  When
    altering the kthread's attributes from userland is allowed, this is
    fine; however, for cases where CPU affinity is critical,
    kthread_bind() is used to first disable affinity changes from userland
    and then set the affinity.  This also prevents the kthread from being
    migrated into non-root cgroups as that can affect the CPU affinity and
    many other things.
    
    Unfortunately, the cgroup side of protection is racy.  While the
    PF_NO_SETAFFINITY flag prevents further migrations, userland can win
    the race before the creator sets the flag with kthread_bind() and put
    the kthread in a non-root cgroup, which can lead to all sorts of
    problems including incorrect CPU affinity and starvation.
    
    This bug got triggered by userland which periodically tries to migrate
    all processes in the root cpuset cgroup to a non-root one.  Per-cpu
    workqueue workers got caught while being created and ended up with
    incorrected CPU affinity breaking concurrency management and sometimes
    stalling workqueue execution.
    
    This patch adds task->no_cgroup_migration which disallows the task to
    be migrated by userland.  kthreadd starts with the flag set making
    every child kthread start in the root cgroup with migration
    disallowed.  The flag is cleared after the kthread finishes
    initialization by which time PF_NO_SETAFFINITY is set if the kthread
    should stay in the root cgroup.
    
    It'd be better to wait for the initialization instead of failing but I
    couldn't think of a way of implementing that without adding either a
    new PF flag, or sleeping and retrying from waiting side.  Even if
    userland depends on changing cgroup membership of a kthread, it either
    has to be synchronized with kthread_create() or periodically repeat,
    so it's unlikely that this would break anything.
    
    v2: Switch to a simpler implementation using a new task_struct bit
        field suggested by Oleg.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Reported-and-debugged-by: Chris Mason <clm@fb.com>
    Cc: stable@vger.kernel.org # v4.3+ (we can't close the race on < v4.3)
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f6b43fbb141c..af9c86e958bd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -570,6 +570,25 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 	pr_cont_kernfs_path(cgrp->kn);
 }
 
+static inline void cgroup_init_kthreadd(void)
+{
+	/*
+	 * kthreadd is inherited by all kthreads, keep it in the root so
+	 * that the new kthreads are guaranteed to stay in the root until
+	 * initialization is finished.
+	 */
+	current->no_cgroup_migration = 1;
+}
+
+static inline void cgroup_kthread_ready(void)
+{
+	/*
+	 * This kthread finished initialization.  The creator should have
+	 * set PF_NO_SETAFFINITY if this kthread should stay in the root.
+	 */
+	current->no_cgroup_migration = 0;
+}
+
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;
@@ -590,6 +609,8 @@ static inline void cgroup_free(struct task_struct *p) {}
 
 static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
+static inline void cgroup_init_kthreadd(void) {}
+static inline void cgroup_kthread_ready(void) {}
 
 static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
 					       struct cgroup *ancestor)

commit 387ad9674b0013c8756ad20d854ff005b0c313ad
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Mon Feb 20 12:19:00 2017 +0200

    kernel: convert cgroup_namespace.count from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f6b43fbb141c..44129793c7b8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -22,6 +22,7 @@
 #include <linux/ns_common.h>
 #include <linux/nsproxy.h>
 #include <linux/user_namespace.h>
+#include <linux/refcount.h>
 
 #include <linux/cgroup-defs.h>
 
@@ -640,7 +641,7 @@ static inline void cgroup_sk_free(struct sock_cgroup_data *skcd) {}
 #endif	/* CONFIG_CGROUP_DATA */
 
 struct cgroup_namespace {
-	atomic_t		count;
+	refcount_t		count;
 	struct ns_common	ns;
 	struct user_namespace	*user_ns;
 	struct ucounts		*ucounts;
@@ -675,12 +676,12 @@ copy_cgroup_ns(unsigned long flags, struct user_namespace *user_ns,
 static inline void get_cgroup_ns(struct cgroup_namespace *ns)
 {
 	if (ns)
-		atomic_inc(&ns->count);
+		refcount_inc(&ns->count);
 }
 
 static inline void put_cgroup_ns(struct cgroup_namespace *ns)
 {
-	if (ns && atomic_dec_and_test(&ns->count))
+	if (ns && refcount_dec_and_test(&ns->count))
 		free_cgroup_ns(ns);
 }
 

commit 7b4632f048415263669676dda20fd5d811c3d3e4
Author: Geliang Tang <geliangtang@gmail.com>
Date:   Sat Dec 24 23:28:35 2016 +0800

    cgroup: fix a comment typo
    
    Fix a comment typo in cgroup.h.
    
    Signed-off-by: Geliang Tang <geliangtang@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c83c23f0577b..f6b43fbb141c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -266,7 +266,7 @@ void css_task_iter_end(struct css_task_iter *it);
  * cgroup_taskset_for_each_leader - iterate group leaders in a cgroup_taskset
  * @leader: the loop cursor
  * @dst_css: the destination css
- * @tset: takset to iterate
+ * @tset: taskset to iterate
  *
  * Iterate threadgroup leaders of @tset.  For single-task migrations, @tset
  * may not contain any.

commit f34d3606f76a8121b9d4940d2dd436bebeb2f9d7
Merge: b6daa51b9a6a bbb427e34249
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 14 12:18:50 2016 -0700

    Merge branch 'for-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
    
     - tracepoints for basic cgroup management operations added
    
     - kernfs and cgroup path formatting functions updated to behave in the
       style of strlcpy()
    
     - non-critical bug fixes
    
    * 'for-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      blkcg: Unlock blkcg_pol_mutex only once when cpd == NULL
      cgroup: fix error handling regressions in proc_cgroup_show() and cgroup_release_agent()
      cpuset: fix error handling regression in proc_cpuset_show()
      cgroup: add tracepoints for basic operations
      cgroup: make cgroup_path() and friends behave in the style of strlcpy()
      kernfs: remove kernfs_path_len()
      kernfs: make kernfs_path*() behave in the style of strlcpy()
      kernfs: add dummy implementation of kernfs_path_from_node()

commit 14986a34e1289424811443a524cdd9e1688c7913
Merge: 8d370595811e 069d5ac9ae0d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 6 09:52:23 2016 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull namespace updates from Eric Biederman:
     "This set of changes is a number of smaller things that have been
      overlooked in other development cycles focused on more fundamental
      change. The devpts changes are small things that were a distraction
      until we managed to kill off DEVPTS_MULTPLE_INSTANCES. There is an
      trivial regression fix to autofs for the unprivileged mount changes
      that went in last cycle. A pair of ioctls has been added by Andrey
      Vagin making it is possible to discover the relationships between
      namespaces when referring to them through file descriptors.
    
      The big user visible change is starting to add simple resource limits
      to catch programs that misbehave. With namespaces in general and user
      namespaces in particular allowing users to use more kinds of
      resources, it has become important to have something to limit errant
      programs. Because the purpose of these limits is to catch errant
      programs the code needs to be inexpensive to use as it always on, and
      the default limits need to be high enough that well behaved programs
      on well behaved systems don't encounter them.
    
      To this end, after some review I have implemented per user per user
      namespace limits, and use them to limit the number of namespaces. The
      limits being per user mean that one user can not exhause the limits of
      another user. The limits being per user namespace allow contexts where
      the limit is 0 and security conscious folks can remove from their
      threat anlysis the code used to manage namespaces (as they have
      historically done as it root only). At the same time the limits being
      per user namespace allow other parts of the system to use namespaces.
    
      Namespaces are increasingly being used in application sand boxing
      scenarios so an all or nothing disable for the entire system for the
      security conscious folks makes increasing use of these sandboxes
      impossible.
    
      There is also added a limit on the maximum number of mounts present in
      a single mount namespace. It is nontrivial to guess what a reasonable
      system wide limit on the number of mount structure in the kernel would
      be, especially as it various based on how a system is using
      containers. A limit on the number of mounts in a mount namespace
      however is much easier to understand and set. In most cases in
      practice only about 1000 mounts are used. Given that some autofs
      scenarious have the potential to be 30,000 to 50,000 mounts I have set
      the default limit for the number of mounts at 100,000 which is well
      above every known set of users but low enough that the mount hash
      tables don't degrade unreaonsably.
    
      These limits are a start. I expect this estabilishes a pattern that
      other limits for resources that namespaces use will follow. There has
      been interest in making inotify event limits per user per user
      namespace as well as interest expressed in making details about what
      is going on in the kernel more visible"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (28 commits)
      autofs:  Fix automounts by using current_real_cred()->uid
      mnt: Add a per mount namespace limit on the number of mounts
      netns: move {inc,dec}_net_namespaces into #ifdef
      nsfs: Simplify __ns_get_path
      tools/testing: add a test to check nsfs ioctl-s
      nsfs: add ioctl to get a parent namespace
      nsfs: add ioctl to get an owning user namespace for ns file descriptor
      kernel: add a helper to get an owning user namespace for a namespace
      devpts: Change the owner of /dev/pts/ptmx to the mounter of /dev/pts
      devpts: Remove sync_filesystems
      devpts: Make devpts_kill_sb safe if fsi is NULL
      devpts: Simplify devpts_mount by using mount_nodev
      devpts: Move the creation of /dev/pts/ptmx into fill_super
      devpts: Move parse_mount_options into fill_super
      userns: When the per user per user namespace limit is reached return ENOSPC
      userns; Document per user per user namespace limits.
      mntns: Add a limit on the number of mount namespaces.
      netns: Add a limit on the number of net namespaces
      cgroupns: Add a limit on the number of cgroup namespaces
      ipcns: Add a  limit on the number of ipc namespaces
      ...

commit aed704b7a634954dc28fe5c4b49db478cf2d96b7
Author: Sargun Dhillon <sargun@sargun.me>
Date:   Fri Aug 12 08:56:40 2016 -0700

    cgroup: Add task_under_cgroup_hierarchy cgroup inline function to headers
    
    This commit adds an inline function to cgroup.h to check whether a given
    task is under a given cgroup hierarchy. This is to avoid having to put
    ifdefs in .c files to gate access to cgroups. When cgroups are disabled
    this always returns true.
    
    Signed-off-by: Sargun Dhillon <sargun@sargun.me>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Tejun Heo <tj@kernel.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 984f73b719a9..a4414a11eea7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -497,6 +497,23 @@ static inline bool cgroup_is_descendant(struct cgroup *cgrp,
 	return cgrp->ancestor_ids[ancestor->level] == ancestor->id;
 }
 
+/**
+ * task_under_cgroup_hierarchy - test task's membership of cgroup ancestry
+ * @task: the task to be tested
+ * @ancestor: possible ancestor of @task's cgroup
+ *
+ * Tests whether @task's default cgroup hierarchy is a descendant of @ancestor.
+ * It follows all the same rules as cgroup_is_descendant, and only applies
+ * to the default hierarchy.
+ */
+static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
+					       struct cgroup *ancestor)
+{
+	struct css_set *cset = task_css_set(task);
+
+	return cgroup_is_descendant(cset->dfl_cgrp, ancestor);
+}
+
 /* no synchronization, the result can only be used as a hint */
 static inline bool cgroup_is_populated(struct cgroup *cgrp)
 {
@@ -557,6 +574,7 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;
+struct cgroup;
 
 static inline void css_put(struct cgroup_subsys_state *css) {}
 static inline int cgroup_attach_task_all(struct task_struct *from,
@@ -574,6 +592,11 @@ static inline void cgroup_free(struct task_struct *p) {}
 static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 
+static inline bool task_under_cgroup_hierarchy(struct task_struct *task,
+					       struct cgroup *ancestor)
+{
+	return true;
+}
 #endif /* !CONFIG_CGROUPS */
 
 /*

commit 4c737b41de7f4eef2a593803bad1b918dd718b10
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Aug 10 11:23:44 2016 -0400

    cgroup: make cgroup_path() and friends behave in the style of strlcpy()
    
    cgroup_path() and friends used to format the path from the end and
    thus the resulting path usually didn't start at the start of the
    passed in buffer.  Also, when the buffer was too small, the partial
    result was truncated from the head rather than tail and there was no
    way to tell how long the full path would be.  These make the functions
    less robust and more awkward to use.
    
    With recent updates to kernfs_path(), cgroup_path() and friends can be
    made to behave in strlcpy() style.
    
    * cgroup_path(), cgroup_path_ns[_locked]() and task_cgroup_path() now
      always return the length of the full path.  If buffer is too small,
      it contains nul terminated truncated output.
    
    * All users updated accordingly.
    
    v2: cgroup_path() usage in kernel/sched/debug.c converted.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Serge Hallyn <serge.hallyn@ubuntu.com>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5a9abdee43fe..6df36361a492 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -97,7 +97,7 @@ int cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cftype *cfts);
 void cgroup_file_notify(struct cgroup_file *cfile);
 
-char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
+int task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
 int cgroupstats_build(struct cgroupstats *stats, struct dentry *dentry);
 int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
 		     struct pid *pid, struct task_struct *tsk);
@@ -538,15 +538,9 @@ static inline int cgroup_name(struct cgroup *cgrp, char *buf, size_t buflen)
 	return kernfs_name(cgrp->kn, buf, buflen);
 }
 
-static inline char * __must_check cgroup_path(struct cgroup *cgrp, char *buf,
-					      size_t buflen)
+static inline int cgroup_path(struct cgroup *cgrp, char *buf, size_t buflen)
 {
-	int ret;
-
-	ret = kernfs_path(cgrp->kn, buf, buflen);
-	if (ret < 0 || ret >= buflen)
-		return NULL;
-	return buf;
+	return kernfs_path(cgrp->kn, buf, buflen);
 }
 
 static inline void pr_cont_cgroup_name(struct cgroup *cgrp)
@@ -639,8 +633,8 @@ struct cgroup_namespace *copy_cgroup_ns(unsigned long flags,
 					struct user_namespace *user_ns,
 					struct cgroup_namespace *old_ns);
 
-char *cgroup_path_ns(struct cgroup *cgrp, char *buf, size_t buflen,
-		     struct cgroup_namespace *ns);
+int cgroup_path_ns(struct cgroup *cgrp, char *buf, size_t buflen,
+		   struct cgroup_namespace *ns);
 
 #else /* !CONFIG_CGROUPS */
 

commit 3abb1d90f5d930c6183534a624aa0158a71bc5eb
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Aug 10 11:23:44 2016 -0400

    kernfs: make kernfs_path*() behave in the style of strlcpy()
    
    kernfs_path*() functions always return the length of the full path but
    the path content is undefined if the length is larger than the
    provided buffer.  This makes its behavior different from strlcpy() and
    requires error handling in all its users even when they don't care
    about truncation.  In addition, the implementation can actully be
    simplified by making it behave properly in strlcpy() style.
    
    * Update kernfs_path_from_node_locked() to always fill up the buffer
      with path.  If the buffer is not large enough, the output is
      truncated and terminated.
    
    * kernfs_path() no longer needs error handling.  Make it a simple
      inline wrapper around kernfs_path_from_node().
    
    * sysfs_warn_dup()'s use of kernfs_path() doesn't need error handling.
      Updated accordingly.
    
    * cgroup_path()'s use of kernfs_path() updated to retain the old
      behavior.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Acked-by: Serge Hallyn <serge.hallyn@ubuntu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 984f73b719a9..5a9abdee43fe 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -541,7 +541,12 @@ static inline int cgroup_name(struct cgroup *cgrp, char *buf, size_t buflen)
 static inline char * __must_check cgroup_path(struct cgroup *cgrp, char *buf,
 					      size_t buflen)
 {
-	return kernfs_path(cgrp->kn, buf, buflen);
+	int ret;
+
+	ret = kernfs_path(cgrp->kn, buf, buflen);
+	if (ret < 0 || ret >= buflen)
+		return NULL;
+	return buf;
 }
 
 static inline void pr_cont_cgroup_name(struct cgroup *cgrp)

commit d08311dd6fd8444e39710dd2fb97562895aed8fa
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Aug 8 14:25:30 2016 -0500

    cgroupns: Add a limit on the number of cgroup namespaces
    
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 984f73b719a9..1ed92812785a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -621,6 +621,7 @@ struct cgroup_namespace {
 	atomic_t		count;
 	struct ns_common	ns;
 	struct user_namespace	*user_ns;
+	struct ucounts		*ucounts;
 	struct css_set          *root_cset;
 };
 

commit 1f3fe7ebf6136c341012db9f554d4caa566fcbaa
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Thu Jun 30 10:28:42 2016 -0700

    cgroup: Add cgroup_get_from_fd
    
    Add a helper function to get a cgroup2 from a fd.  It will be
    stored in a bpf array (BPF_MAP_TYPE_CGROUP_ARRAY) which will
    be introduced in the later patch.
    
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Cc: Alexei Starovoitov <ast@fb.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Tejun Heo <tj@kernel.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a20320c666fd..984f73b719a9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -87,6 +87,7 @@ struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
 						       struct cgroup_subsys *ss);
 
 struct cgroup *cgroup_get_from_path(const char *path);
+struct cgroup *cgroup_get_from_fd(int fd);
 
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);

commit a79a908fd2b080977b45bf103184b81c9d11ad07
Author: Aditya Kali <adityakali@google.com>
Date:   Fri Jan 29 02:54:06 2016 -0600

    cgroup: introduce cgroup namespaces
    
    Introduce the ability to create new cgroup namespace. The newly created
    cgroup namespace remembers the cgroup of the process at the point
    of creation of the cgroup namespace (referred as cgroupns-root).
    The main purpose of cgroup namespace is to virtualize the contents
    of /proc/self/cgroup file. Processes inside a cgroup namespace
    are only able to see paths relative to their namespace root
    (unless they are moved outside of their cgroupns-root, at which point
     they will see a relative path from their cgroupns-root).
    For a correctly setup container this enables container-tools
    (like libcontainer, lxc, lmctfy, etc.) to create completely virtualized
    containers without leaking system level cgroup hierarchy to the task.
    This patch only implements the 'unshare' part of the cgroupns.
    
    Signed-off-by: Aditya Kali <adityakali@google.com>
    Signed-off-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 2162dca88dc0..a20320c666fd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -17,6 +17,11 @@
 #include <linux/seq_file.h>
 #include <linux/kernfs.h>
 #include <linux/jump_label.h>
+#include <linux/nsproxy.h>
+#include <linux/types.h>
+#include <linux/ns_common.h>
+#include <linux/nsproxy.h>
+#include <linux/user_namespace.h>
 
 #include <linux/cgroup-defs.h>
 
@@ -611,4 +616,48 @@ static inline void cgroup_sk_free(struct sock_cgroup_data *skcd) {}
 
 #endif	/* CONFIG_CGROUP_DATA */
 
+struct cgroup_namespace {
+	atomic_t		count;
+	struct ns_common	ns;
+	struct user_namespace	*user_ns;
+	struct css_set          *root_cset;
+};
+
+extern struct cgroup_namespace init_cgroup_ns;
+
+#ifdef CONFIG_CGROUPS
+
+void free_cgroup_ns(struct cgroup_namespace *ns);
+
+struct cgroup_namespace *copy_cgroup_ns(unsigned long flags,
+					struct user_namespace *user_ns,
+					struct cgroup_namespace *old_ns);
+
+char *cgroup_path_ns(struct cgroup *cgrp, char *buf, size_t buflen,
+		     struct cgroup_namespace *ns);
+
+#else /* !CONFIG_CGROUPS */
+
+static inline void free_cgroup_ns(struct cgroup_namespace *ns) { }
+static inline struct cgroup_namespace *
+copy_cgroup_ns(unsigned long flags, struct user_namespace *user_ns,
+	       struct cgroup_namespace *old_ns)
+{
+	return old_ns;
+}
+
+#endif /* !CONFIG_CGROUPS */
+
+static inline void get_cgroup_ns(struct cgroup_namespace *ns)
+{
+	if (ns)
+		atomic_inc(&ns->count);
+}
+
+static inline void put_cgroup_ns(struct cgroup_namespace *ns)
+{
+	if (ns && atomic_dec_and_test(&ns->count))
+		free_cgroup_ns(ns);
+}
+
 #endif /* _LINUX_CGROUP_H */

commit 34a9304a96d6351c2d35dcdc9293258378fc0bd8
Merge: aee3bfa3307c 6255c46fa037
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 12 19:20:32 2016 -0800

    Merge branch 'for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
    
     - cgroup v2 interface is now official.  It's no longer hidden behind a
       devel flag and can be mounted using the new cgroup2 fs type.
    
       Unfortunately, cpu v2 interface hasn't made it yet due to the
       discussion around in-process hierarchical resource distribution and
       only memory and io controllers can be used on the v2 interface at the
       moment.
    
     - The existing documentation which has always been a bit of mess is
       relocated under Documentation/cgroup-v1/. Documentation/cgroup-v2.txt
       is added as the authoritative documentation for the v2 interface.
    
     - Some features are added through for-4.5-ancestor-test branch to
       enable netfilter xt_cgroup match to use cgroup v2 paths.  The actual
       netfilter changes will be merged through the net tree which pulled in
       the said branch.
    
     - Various cleanups
    
    * 'for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: rename cgroup documentations
      cgroup: fix a typo.
      cgroup: Remove resource_counter.txt in Documentation/cgroup-legacy/00-INDEX.
      cgroup: demote subsystem init messages to KERN_DEBUG
      cgroup: Fix uninitialized variable warning
      cgroup: put controller Kconfig options in meaningful order
      cgroup: clean up the kernel configuration menu nomenclature
      cgroup_pids: fix a typo.
      Subject: cgroup: Fix incomplete dd command in blkio documentation
      cgroup: kill cgrp_ss_priv[CGROUP_CANFORK_COUNT] and friends
      cpuset: Replace all instances of time_t with time64_t
      cgroup: replace unified-hierarchy.txt with a proper cgroup v2 documentation
      cgroup: rename Documentation/cgroups/ to Documentation/cgroup-legacy/
      cgroup: replace __DEVEL__sane_behavior with cgroup2 fs type

commit b3e0d3d7bab14f2544a3314bec53a23dc7dd2206
Merge: 3268e5cb494d 73796d8bf273
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Dec 17 22:08:28 2015 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/geneve.c
    
    Here we had an overlapping change, where in 'net' the extraneous stats
    bump was being removed whilst in 'net-next' the final argument to
    udp_tunnel6_xmit_skb() was being changed.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit bd1060a1d67128bb8fbe2e1384c518912cbe54e7
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Dec 7 17:38:53 2015 -0500

    sock, cgroup: add sock->sk_cgroup
    
    In cgroup v1, dealing with cgroup membership was difficult because the
    number of membership associations was unbound.  As a result, cgroup v1
    grew several controllers whose primary purpose is either tagging
    membership or pull in configuration knobs from other subsystems so
    that cgroup membership test can be avoided.
    
    net_cls and net_prio controllers are examples of the latter.  They
    allow configuring network-specific attributes from cgroup side so that
    network subsystem can avoid testing cgroup membership; unfortunately,
    these are not only cumbersome but also problematic.
    
    Both net_cls and net_prio aren't properly hierarchical.  Both inherit
    configuration from the parent on creation but there's no interaction
    afterwards.  An ancestor doesn't restrict the behavior in its subtree
    in anyway and configuration changes aren't propagated downwards.
    Especially when combined with cgroup delegation, this is problematic
    because delegatees can mess up whatever network configuration
    implemented at the system level.  net_prio would allow the delegatees
    to set whatever priority value regardless of CAP_NET_ADMIN and net_cls
    the same for classid.
    
    While it is possible to solve these issues from controller side by
    implementing hierarchical allowable ranges in both controllers, it
    would involve quite a bit of complexity in the controllers and further
    obfuscate network configuration as it becomes even more difficult to
    tell what's actually being configured looking from the network side.
    While not much can be done for v1 at this point, as membership
    handling is sane on cgroup v2, it'd be better to make cgroup matching
    behave like other network matches and classifiers than introducing
    further complications.
    
    In preparation, this patch updates sock->sk_cgrp_data handling so that
    it points to the v2 cgroup that sock was created in until either
    net_prio or net_cls is used.  Once either of the two is used,
    sock->sk_cgrp_data reverts to its previous role of carrying prioidx
    and classid.  This is to avoid adding yet another cgroup related field
    to struct sock.
    
    As the mode switching can happen at most once per boot, the switching
    mechanism is aimed at lowering hot path overhead.  It may leak a
    finite, likely small, number of cgroup refs and report spurious
    prioidx or classid on switching; however, dynamic updates of prioidx
    and classid have always been racy and lossy - socks between creation
    and fd installation are never updated, config changes don't update
    existing sockets at all, and prioidx may index with dead and recycled
    cgroup IDs.  Non-critical inaccuracies from small race windows won't
    make any noticeable difference.
    
    This patch doesn't make use of the pointer yet.  The following patch
    will implement netfilter match for cgroup2 membership.
    
    v2: Use sock_cgroup_data to avoid inflating struct sock w/ another
        cgroup specific field.
    
    v3: Add comments explaining why sock_data_prioidx() and
        sock_data_classid() use different fallback values.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Daniel Wagner <daniel.wagner@bmw-carit.de>
    CC: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4c3ffab81ba7..a8ba1ea0ea5a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -578,4 +578,45 @@ static inline int cgroup_init(void) { return 0; }
 
 #endif /* !CONFIG_CGROUPS */
 
+/*
+ * sock->sk_cgrp_data handling.  For more info, see sock_cgroup_data
+ * definition in cgroup-defs.h.
+ */
+#ifdef CONFIG_SOCK_CGROUP_DATA
+
+#if defined(CONFIG_CGROUP_NET_PRIO) || defined(CONFIG_CGROUP_NET_CLASSID)
+extern spinlock_t cgroup_sk_update_lock;
+#endif
+
+void cgroup_sk_alloc_disable(void);
+void cgroup_sk_alloc(struct sock_cgroup_data *skcd);
+void cgroup_sk_free(struct sock_cgroup_data *skcd);
+
+static inline struct cgroup *sock_cgroup_ptr(struct sock_cgroup_data *skcd)
+{
+#if defined(CONFIG_CGROUP_NET_PRIO) || defined(CONFIG_CGROUP_NET_CLASSID)
+	unsigned long v;
+
+	/*
+	 * @skcd->val is 64bit but the following is safe on 32bit too as we
+	 * just need the lower ulong to be written and read atomically.
+	 */
+	v = READ_ONCE(skcd->val);
+
+	if (v & 1)
+		return &cgrp_dfl_root.cgrp;
+
+	return (struct cgroup *)(unsigned long)v ?: &cgrp_dfl_root.cgrp;
+#else
+	return (struct cgroup *)(unsigned long)skcd->val;
+#endif
+}
+
+#else	/* CONFIG_CGROUP_DATA */
+
+static inline void cgroup_sk_alloc(struct sock_cgroup_data *skcd) {}
+static inline void cgroup_sk_free(struct sock_cgroup_data *skcd) {}
+
+#endif	/* CONFIG_CGROUP_DATA */
+
 #endif /* _LINUX_CGROUP_H */

commit 177493987c1a15145922a65240f2f8ab6c63770a
Merge: e11362bb25d9 16af43964545
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Dec 7 17:24:10 2015 -0500

    Merge branch 'for-4.5-ancestor-test' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup into for-4.5
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit b53202e6308939d33ba0c78712e850f891b4e76f
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Dec 3 10:24:08 2015 -0500

    cgroup: kill cgrp_ss_priv[CGROUP_CANFORK_COUNT] and friends
    
    Now that nobody use the "priv" arg passed to can_fork/cancel_fork/fork we can
    kill CGROUP_CANFORK_COUNT/SUBSYS_TAG/etc and cgrp_ss_priv[] in copy_process().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cb91b44f5f78..2b3e231448ca 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -96,12 +96,9 @@ int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
 		     struct pid *pid, struct task_struct *tsk);
 
 void cgroup_fork(struct task_struct *p);
-extern int cgroup_can_fork(struct task_struct *p,
-			   void *ss_priv[CGROUP_CANFORK_COUNT]);
-extern void cgroup_cancel_fork(struct task_struct *p,
-			       void *ss_priv[CGROUP_CANFORK_COUNT]);
-extern void cgroup_post_fork(struct task_struct *p,
-			     void *old_ss_priv[CGROUP_CANFORK_COUNT]);
+extern int cgroup_can_fork(struct task_struct *p);
+extern void cgroup_cancel_fork(struct task_struct *p);
+extern void cgroup_post_fork(struct task_struct *p);
 void cgroup_exit(struct task_struct *p);
 void cgroup_free(struct task_struct *p);
 
@@ -539,13 +536,9 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 				    struct dentry *dentry) { return -EINVAL; }
 
 static inline void cgroup_fork(struct task_struct *p) {}
-static inline int cgroup_can_fork(struct task_struct *p,
-				  void *ss_priv[CGROUP_CANFORK_COUNT])
-{ return 0; }
-static inline void cgroup_cancel_fork(struct task_struct *p,
-				      void *ss_priv[CGROUP_CANFORK_COUNT]) {}
-static inline void cgroup_post_fork(struct task_struct *p,
-				    void *ss_priv[CGROUP_CANFORK_COUNT]) {}
+static inline int cgroup_can_fork(struct task_struct *p) { return 0; }
+static inline void cgroup_cancel_fork(struct task_struct *p) {}
+static inline void cgroup_post_fork(struct task_struct *p) {}
 static inline void cgroup_exit(struct task_struct *p) {}
 static inline void cgroup_free(struct task_struct *p) {}
 

commit 1f7dd3e5a6e4f093017fff12232572ee1aa4639b
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 3 10:18:21 2015 -0500

    cgroup: fix handling of multi-destination migration from subtree_control enabling
    
    Consider the following v2 hierarchy.
    
      P0 (+memory) --- P1 (-memory) --- A
                                     \- B
    
    P0 has memory enabled in its subtree_control while P1 doesn't.  If
    both A and B contain processes, they would belong to the memory css of
    P1.  Now if memory is enabled on P1's subtree_control, memory csses
    should be created on both A and B and A's processes should be moved to
    the former and B's processes the latter.  IOW, enabling controllers
    can cause atomic migrations into different csses.
    
    The core cgroup migration logic has been updated accordingly but the
    controller migration methods haven't and still assume that all tasks
    migrate to a single target css; furthermore, the methods were fed the
    css in which subtree_control was updated which is the parent of the
    target csses.  pids controller depends on the migration methods to
    move charges and this made the controller attribute charges to the
    wrong csses often triggering the following warning by driving a
    counter negative.
    
     WARNING: CPU: 1 PID: 1 at kernel/cgroup_pids.c:97 pids_cancel.constprop.6+0x31/0x40()
     Modules linked in:
     CPU: 1 PID: 1 Comm: systemd Not tainted 4.4.0-rc1+ #29
     ...
      ffffffff81f65382 ffff88007c043b90 ffffffff81551ffc 0000000000000000
      ffff88007c043bc8 ffffffff810de202 ffff88007a752000 ffff88007a29ab00
      ffff88007c043c80 ffff88007a1d8400 0000000000000001 ffff88007c043bd8
     Call Trace:
      [<ffffffff81551ffc>] dump_stack+0x4e/0x82
      [<ffffffff810de202>] warn_slowpath_common+0x82/0xc0
      [<ffffffff810de2fa>] warn_slowpath_null+0x1a/0x20
      [<ffffffff8118e031>] pids_cancel.constprop.6+0x31/0x40
      [<ffffffff8118e0fd>] pids_can_attach+0x6d/0xf0
      [<ffffffff81188a4c>] cgroup_taskset_migrate+0x6c/0x330
      [<ffffffff81188e05>] cgroup_migrate+0xf5/0x190
      [<ffffffff81189016>] cgroup_attach_task+0x176/0x200
      [<ffffffff8118949d>] __cgroup_procs_write+0x2ad/0x460
      [<ffffffff81189684>] cgroup_procs_write+0x14/0x20
      [<ffffffff811854e5>] cgroup_file_write+0x35/0x1c0
      [<ffffffff812e26f1>] kernfs_fop_write+0x141/0x190
      [<ffffffff81265f88>] __vfs_write+0x28/0xe0
      [<ffffffff812666fc>] vfs_write+0xac/0x1a0
      [<ffffffff81267019>] SyS_write+0x49/0xb0
      [<ffffffff81bcef32>] entry_SYSCALL_64_fastpath+0x12/0x76
    
    This patch fixes the bug by removing @css parameter from the three
    migration methods, ->can_attach, ->cancel_attach() and ->attach() and
    updating cgroup_taskset iteration helpers also return the destination
    css in addition to the task being migrated.  All controllers are
    updated accordingly.
    
    * Controllers which don't care whether there are one or multiple
      target csses can be converted trivially.  cpu, io, freezer, perf,
      netclassid and netprio fall in this category.
    
    * cpuset's current implementation assumes that there's single source
      and destination and thus doesn't support v2 hierarchy already.  The
      only change made by this patchset is how that single destination css
      is obtained.
    
    * memory migration path already doesn't do anything on v2.  How the
      single destination css is obtained is updated and the prep stage of
      mem_cgroup_can_attach() is reordered to accomodate the change.
    
    * pids is the only controller which was affected by this bug.  It now
      correctly handles multi-destination migrations and no longer causes
      counter underflow from incorrect accounting.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-and-tested-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc: Aleksa Sarai <cyphar@cyphar.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f64083030ad5..cb91b44f5f78 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -120,8 +120,10 @@ struct cgroup_subsys_state *css_rightmost_descendant(struct cgroup_subsys_state
 struct cgroup_subsys_state *css_next_descendant_post(struct cgroup_subsys_state *pos,
 						     struct cgroup_subsys_state *css);
 
-struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset);
-struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
+struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset,
+					 struct cgroup_subsys_state **dst_cssp);
+struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset,
+					struct cgroup_subsys_state **dst_cssp);
 
 void css_task_iter_start(struct cgroup_subsys_state *css,
 			 struct css_task_iter *it);
@@ -236,30 +238,39 @@ void css_task_iter_end(struct css_task_iter *it);
 /**
  * cgroup_taskset_for_each - iterate cgroup_taskset
  * @task: the loop cursor
+ * @dst_css: the destination css
  * @tset: taskset to iterate
  *
  * @tset may contain multiple tasks and they may belong to multiple
- * processes.  When there are multiple tasks in @tset, if a task of a
- * process is in @tset, all tasks of the process are in @tset.  Also, all
- * are guaranteed to share the same source and destination csses.
+ * processes.
+ *
+ * On the v2 hierarchy, there may be tasks from multiple processes and they
+ * may not share the source or destination csses.
+ *
+ * On traditional hierarchies, when there are multiple tasks in @tset, if a
+ * task of a process is in @tset, all tasks of the process are in @tset.
+ * Also, all are guaranteed to share the same source and destination csses.
  *
  * Iteration is not in any specific order.
  */
-#define cgroup_taskset_for_each(task, tset)				\
-	for ((task) = cgroup_taskset_first((tset)); (task);		\
-	     (task) = cgroup_taskset_next((tset)))
+#define cgroup_taskset_for_each(task, dst_css, tset)			\
+	for ((task) = cgroup_taskset_first((tset), &(dst_css));		\
+	     (task);							\
+	     (task) = cgroup_taskset_next((tset), &(dst_css)))
 
 /**
  * cgroup_taskset_for_each_leader - iterate group leaders in a cgroup_taskset
  * @leader: the loop cursor
+ * @dst_css: the destination css
  * @tset: takset to iterate
  *
  * Iterate threadgroup leaders of @tset.  For single-task migrations, @tset
  * may not contain any.
  */
-#define cgroup_taskset_for_each_leader(leader, tset)			\
-	for ((leader) = cgroup_taskset_first((tset)); (leader);		\
-	     (leader) = cgroup_taskset_next((tset)))			\
+#define cgroup_taskset_for_each_leader(leader, dst_css, tset)		\
+	for ((leader) = cgroup_taskset_first((tset), &(dst_css));	\
+	     (leader);							\
+	     (leader) = cgroup_taskset_next((tset), &(dst_css)))	\
 		if ((leader) != (leader)->group_leader)			\
 			;						\
 		else

commit 16af439645455fbf36984ca5e72f31073ee19ab7
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 20 15:55:52 2015 -0500

    cgroup: implement cgroup_get_from_path() and expose cgroup_put()
    
    Implement cgroup_get_from_path() using kernfs_walk_and_get() which
    obtains a default hierarchy cgroup from its path.  This will be used
    to allow cgroup path based matching from outside cgroup proper -
    e.g. networking and perf.
    
    v2: Add EXPORT_SYMBOL_GPL(cgroup_get_from_path).
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b5ee2c4210f9..4c3ffab81ba7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -81,6 +81,8 @@ struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
 struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
 						       struct cgroup_subsys *ss);
 
+struct cgroup *cgroup_get_from_path(const char *path);
+
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 
@@ -351,6 +353,11 @@ static inline void css_put_many(struct cgroup_subsys_state *css, unsigned int n)
 		percpu_ref_put_many(&css->refcnt, n);
 }
 
+static inline void cgroup_put(struct cgroup *cgrp)
+{
+	css_put(&cgrp->self);
+}
+
 /**
  * task_css_set_check - obtain a task's css_set with extra access conditions
  * @task: the task to obtain css_set for

commit b11cfb5807e30333b36c02701382b820b7dcf0d5
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 20 15:55:52 2015 -0500

    cgroup: record ancestor IDs and reimplement cgroup_is_descendant() using it
    
    cgroup_is_descendant() currently walks up the hierarchy and compares
    each ancestor to the cgroup in question.  While enough for cgroup core
    usages, this can't be used in hot paths to test cgroup membership.
    This patch adds cgroup->ancestor_ids[] which records the IDs of all
    ancestors including self and cgroup->level for the nesting level.
    
    This allows testing whether a given cgroup is a descendant of another
    in three finite steps - testing whether the two belong to the same
    hierarchy, whether the descendant candidate is at the same or a higher
    level than the ancestor and comparing the recorded ancestor_id at the
    matching level.  cgroup_is_descendant() is accordingly reimplmented
    and made inline.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 22e3754f89c5..b5ee2c4210f9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -81,7 +81,6 @@ struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
 struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
 						       struct cgroup_subsys *ss);
 
-bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 
@@ -459,6 +458,23 @@ static inline struct cgroup *task_cgroup(struct task_struct *task,
 	return task_css(task, subsys_id)->cgroup;
 }
 
+/**
+ * cgroup_is_descendant - test ancestry
+ * @cgrp: the cgroup to be tested
+ * @ancestor: possible ancestor of @cgrp
+ *
+ * Test whether @cgrp is a descendant of @ancestor.  It also returns %true
+ * if @cgrp == @ancestor.  This function is safe to call as long as @cgrp
+ * and @ancestor are accessible.
+ */
+static inline bool cgroup_is_descendant(struct cgroup *cgrp,
+					struct cgroup *ancestor)
+{
+	if (cgrp->root != ancestor->root || cgrp->level < ancestor->level)
+		return false;
+	return cgrp->ancestor_ids[ancestor->level] == ancestor->id;
+}
+
 /* no synchronization, the result can only be used as a hint */
 static inline bool cgroup_is_populated(struct cgroup *cgrp)
 {

commit 34c06254ff82a815fdccdfae7517a06c9b768cee
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Nov 5 00:12:24 2015 -0500

    cgroup: fix cftype->file_offset handling
    
    6f60eade2433 ("cgroup: generalize obtaining the handles of and
    notifying cgroup files") introduced cftype->file_offset so that the
    handles for per-css file instances can be recorded.  These handles
    then can be used, for example, to generate file modified
    notifications.
    
    Unfortunately, it made the wrong assumption that files are created
    once for a given css and removed on its destruction.  Due to the
    dependencies among subsystems, a css may be hidden from userland and
    then later shown again.  This is implemented by removing and
    re-creating the affected files, so the associated kernfs_node for a
    given cgroup file may change over time.  This incorrect assumption led
    to the corruption of css->files lists.
    
    Reimplement cftype->file_offset handling so that cgroup_file->kn is
    protected by a lock and updated as files are created and destroyed.
    This also makes keeping them on per-cgroup list unnecessary.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: James Sedgwick <jsedgwick@fb.com>
    Fixes: 6f60eade2433 ("cgroup: generalize obtaining the handles of and notifying cgroup files")
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Zefan Li <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 22e3754f89c5..f64083030ad5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -88,6 +88,7 @@ int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 int cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cftype *cfts);
+void cgroup_file_notify(struct cgroup_file *cfile);
 
 char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
 int cgroupstats_build(struct cgroupstats *stats, struct dentry *dentry);
@@ -516,19 +517,6 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 	pr_cont_kernfs_path(cgrp->kn);
 }
 
-/**
- * cgroup_file_notify - generate a file modified event for a cgroup_file
- * @cfile: target cgroup_file
- *
- * @cfile must have been obtained by setting cftype->file_offset.
- */
-static inline void cgroup_file_notify(struct cgroup_file *cfile)
-{
-	/* might not have been created due to one of the CFTYPE selector flags */
-	if (cfile->kn)
-		kernfs_notify(cfile->kn);
-}
-
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;

commit 2e91fa7f6d451e3ea9fec999065d2fd199691f9d
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Oct 15 16:41:53 2015 -0400

    cgroup: keep zombies associated with their original cgroups
    
    cgroup_exit() is called when a task exits and disassociates the
    exiting task from its cgroups and half-attach it to the root cgroup.
    This is unnecessary and undesirable.
    
    No controller actually needs an exiting task to be disassociated with
    non-root cgroups.  Both cpu and perf_event controllers update the
    association to the root cgroup from their exit callbacks just to keep
    consistent with the cgroup core behavior.
    
    Also, this disassociation makes it difficult to track resources held
    by zombies or determine where the zombies came from.  Currently, pids
    controller is completely broken as it uncharges on exit and zombies
    always escape the resource restriction.  With cgroup association being
    reset on exit, fixing it is pretty painful.
    
    There's no reason to reset cgroup membership on exit.  The zombie can
    be removed from its css_set so that it doesn't show up on
    "cgroup.procs" and thus can't be migrated or interfere with cgroup
    removal.  It can still pin and point to the css_set so that its cgroup
    membership is maintained.  This patch makes cgroup core keep zombies
    associated with their cgroups at the time of exit.
    
    * Previous patches decoupled populated_cnt tracking from css_set
      lifetime, so a dying task can be simply unlinked from its css_set
      while pinning and pointing to the css_set.  This keeps css_set
      association from task side alive while hiding it from "cgroup.procs"
      and populated_cnt tracking.  The css_set reference is dropped when
      the task_struct is freed.
    
    * ->exit() callback no longer needs the css arguments as the
      associated css never changes once PF_EXITING is set.  Removed.
    
    * cpu and perf_events controllers no longer need ->exit() callbacks.
      There's no reason to explicitly switch away on exit.  The final
      schedule out is enough.  The callbacks are removed.
    
    * On traditional hierarchies, nothing changes.  "/proc/PID/cgroup"
      still reports "/" for all zombies.  On the default hierarchy,
      "/proc/PID/cgroup" keeps reporting the cgroup that the task belonged
      to at the time of exit.  If the cgroup gets removed before the task
      is reaped, " (deleted)" is appended.
    
    v2: Build brekage due to missing dummy cgroup_free() when
        !CONFIG_CGROUP fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 46020735bcbb..22e3754f89c5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -102,6 +102,7 @@ extern void cgroup_cancel_fork(struct task_struct *p,
 extern void cgroup_post_fork(struct task_struct *p,
 			     void *old_ss_priv[CGROUP_CANFORK_COUNT]);
 void cgroup_exit(struct task_struct *p);
+void cgroup_free(struct task_struct *p);
 
 int cgroup_init_early(void);
 int cgroup_init(void);
@@ -547,6 +548,7 @@ static inline void cgroup_cancel_fork(struct task_struct *p,
 static inline void cgroup_post_fork(struct task_struct *p,
 				    void *ss_priv[CGROUP_CANFORK_COUNT]) {}
 static inline void cgroup_exit(struct task_struct *p) {}
+static inline void cgroup_free(struct task_struct *p) {}
 
 static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }

commit f0d9a5f175753a371bc7fdff0d584a8d9cd72bb0
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Oct 15 16:41:53 2015 -0400

    cgroup: make css_set_rwsem a spinlock and rename it to css_set_lock
    
    css_set_rwsem is the inner lock protecting css_sets and is accessed
    from hot paths such as fork and exit.  Internally, it has no reason to
    be a rwsem or even mutex.  There are no internal blocking operations
    while holding it.  This was rwsem because css task iteration used to
    expose it to external iterator users.  As the previous patch updated
    css task iteration such that the locking is not leaked to its users,
    there's no reason to keep it a rwsem.
    
    This patch converts css_set_rwsem to a spinlock and rename it to
    css_set_lock.  It uses bh-safe operations as a planned usage needs to
    access it from RCU callback context.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a9dcf0e76865..46020735bcbb 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -13,7 +13,6 @@
 #include <linux/nodemask.h>
 #include <linux/rculist.h>
 #include <linux/cgroupstats.h>
-#include <linux/rwsem.h>
 #include <linux/fs.h>
 #include <linux/seq_file.h>
 #include <linux/kernfs.h>
@@ -367,11 +366,11 @@ static inline void css_put_many(struct cgroup_subsys_state *css, unsigned int n)
  */
 #ifdef CONFIG_PROVE_RCU
 extern struct mutex cgroup_mutex;
-extern struct rw_semaphore css_set_rwsem;
+extern spinlock_t css_set_lock;
 #define task_css_set_check(task, __c)					\
 	rcu_dereference_check((task)->cgroups,				\
 		lockdep_is_held(&cgroup_mutex) ||			\
-		lockdep_is_held(&css_set_rwsem) ||			\
+		lockdep_is_held(&css_set_lock) ||			\
 		((task)->flags & PF_EXITING) || (__c))
 #else
 #define task_css_set_check(task, __c)					\

commit ed27b9f7a17ddfbc007e16d4d11f33dff4fc2de7
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Oct 15 16:41:52 2015 -0400

    cgroup: don't hold css_set_rwsem across css task iteration
    
    css_sets are synchronized through css_set_rwsem but the locking scheme
    is kinda bizarre.  The hot paths - fork and exit - have to write lock
    the rwsem making the rw part pointless; furthermore, many readers
    already hold cgroup_mutex.
    
    One of the readers is css task iteration.  It read locks the rwsem
    over the entire duration of iteration.  This leads to silly locking
    behavior.  When cpuset tries to migrate processes of a cgroup to a
    different NUMA node, css_set_rwsem is held across the entire migration
    attempt which can take a long time locking out forking, exiting and
    other cgroup operations.
    
    This patch updates css task iteration so that it locks css_set_rwsem
    only while the iterator is being advanced.  css task iteration
    involves two levels - css_set and task iteration.  As css_sets in use
    are practically immutable, simply pinning the current one is enough
    for resuming iteration afterwards.  Task iteration is tricky as tasks
    may leave their css_set while iteration is in progress.  This is
    solved by keeping track of active iterators and advancing them if
    their next task leaves its css_set.
    
    v2: put_task_struct() in css_task_iter_next() moved outside
        css_set_rwsem.  A later patch will add cgroup operations to
        task_struct free path which may grab the same lock and this avoids
        deadlock possibilities.
    
        css_set_move_task() updated to use list_for_each_entry_safe() when
        walking task_iters and advancing them.  This is necessary as
        advancing an iter may remove it from the list.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index bdfdb3a1a83c..a9dcf0e76865 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -42,6 +42,10 @@ struct css_task_iter {
 	struct list_head		*task_pos;
 	struct list_head		*tasks_head;
 	struct list_head		*mg_tasks_head;
+
+	struct css_set			*cur_cset;
+	struct task_struct		*cur_task;
+	struct list_head		iters_node;	/* css_set->task_iters */
 };
 
 extern struct cgroup_root cgrp_dfl_root;

commit 27bd4dbb8d51c476298e62bd088225317b7853de
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Oct 15 16:41:50 2015 -0400

    cgroup: replace cgroup_has_tasks() with cgroup_is_populated()
    
    Currently, cgroup_has_tasks() tests whether the target cgroup has any
    css_set linked to it.  This works because a css_set's refcnt converges
    with the number of tasks linked to it and thus there's no css_set
    linked to a cgroup if it doesn't have any live tasks.
    
    To help tracking resource usage of zombie tasks, putting the ref of
    css_set will be separated from disassociating the task from the
    css_set which means that a cgroup may have css_sets linked to it even
    when it doesn't have any live tasks.
    
    This patch replaces cgroup_has_tasks() with cgroup_is_populated()
    which tests cgroup->nr_populated instead which locally counts the
    number of populated css_sets.  Unlike cgroup_has_tasks(),
    cgroup_is_populated() is recursive - if any of the descendants is
    populated, the cgroup is populated too.  While this changes the
    meaning of the test, all the existing users are okay with the change.
    
    While at it, replace the open-coded ->populated_cnt test in
    cgroup_events_show() with cgroup_is_populated().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e9c3eac074e2..bdfdb3a1a83c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -456,9 +456,9 @@ static inline struct cgroup *task_cgroup(struct task_struct *task,
 }
 
 /* no synchronization, the result can only be used as a hint */
-static inline bool cgroup_has_tasks(struct cgroup *cgrp)
+static inline bool cgroup_is_populated(struct cgroup *cgrp)
 {
-	return !list_empty(&cgrp->cset_links);
+	return cgrp->populated_cnt;
 }
 
 /* returns ino associated with a cgroup */

commit 4530eddb59494b89650d6bcd980fc7f7717ad80c
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Sep 11 15:00:19 2015 -0400

    cgroup, memcg, cpuset: implement cgroup_taskset_for_each_leader()
    
    It wasn't explicitly documented but, when a process is being migrated,
    cpuset and memcg depend on cgroup_taskset_first() returning the
    threadgroup leader; however, this approach is somewhat ghetto and
    would no longer work for the planned multi-process migration.
    
    This patch introduces explicit cgroup_taskset_for_each_leader() which
    iterates over only the threadgroup leaders and replaces
    cgroup_taskset_first() usages for accessing the leader with it.
    
    This prepares both memcg and cpuset for multi-process migration.  This
    patch also updates the documentation for cgroup_taskset_for_each() to
    clarify the iteration rules and removes comments mentioning task
    ordering in tasksets.
    
    v2: A previous patch which added threadgroup leader test was dropped.
        Patch updated accordingly.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Zefan Li <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index fb717f2cba5b..e9c3eac074e2 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -232,11 +232,33 @@ void css_task_iter_end(struct css_task_iter *it);
  * cgroup_taskset_for_each - iterate cgroup_taskset
  * @task: the loop cursor
  * @tset: taskset to iterate
+ *
+ * @tset may contain multiple tasks and they may belong to multiple
+ * processes.  When there are multiple tasks in @tset, if a task of a
+ * process is in @tset, all tasks of the process are in @tset.  Also, all
+ * are guaranteed to share the same source and destination csses.
+ *
+ * Iteration is not in any specific order.
  */
 #define cgroup_taskset_for_each(task, tset)				\
 	for ((task) = cgroup_taskset_first((tset)); (task);		\
 	     (task) = cgroup_taskset_next((tset)))
 
+/**
+ * cgroup_taskset_for_each_leader - iterate group leaders in a cgroup_taskset
+ * @leader: the loop cursor
+ * @tset: takset to iterate
+ *
+ * Iterate threadgroup leaders of @tset.  For single-task migrations, @tset
+ * may not contain any.
+ */
+#define cgroup_taskset_for_each_leader(leader, tset)			\
+	for ((leader) = cgroup_taskset_first((tset)); (leader);		\
+	     (leader) = cgroup_taskset_next((tset)))			\
+		if ((leader) != (leader)->group_leader)			\
+			;						\
+		else
+
 /*
  * Inline functions.
  */

commit 6f60eade2433cb3a38687d5f8a4f44b92c6c51bf
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Sep 18 17:54:23 2015 -0400

    cgroup: generalize obtaining the handles of and notifying cgroup files
    
    cgroup core handles creations and removals of cgroup interface files
    as described by cftypes.  There are cases where the handle for a given
    file instance is necessary, for example, to generate a file modified
    event.  Currently, this is handled by explicitly matching the callback
    method pointer and storing the file handle manually in
    cgroup_add_file().  While this simple approach works for cgroup core
    files, it can't for controller interface files.
    
    This patch generalizes cgroup interface file handle handling.  struct
    cgroup_file is defined and each cftype can optionally tell cgroup core
    to store the file handle by setting ->file_offset.  A file handle
    remains accessible as long as the containing css is accessible.
    
    Both "cgroup.procs" and "cgroup.events" are converted to use the new
    generic mechanism instead of hooking directly into cgroup_add_file().
    Also, cgroup_file_notify() which takes a struct cgroup_file and
    generates a file modified event on it is added and replaces explicit
    kernfs_notify() invocations.
    
    This generalizes cgroup file handle handling and allows controllers to
    generate file modified notifications.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 355bf2ed8867..fb717f2cba5b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -490,6 +490,19 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 	pr_cont_kernfs_path(cgrp->kn);
 }
 
+/**
+ * cgroup_file_notify - generate a file modified event for a cgroup_file
+ * @cfile: target cgroup_file
+ *
+ * @cfile must have been obtained by setting cftype->file_offset.
+ */
+static inline void cgroup_file_notify(struct cgroup_file *cfile)
+{
+	/* might not have been created due to one of the CFTYPE selector flags */
+	if (cfile->kn)
+		kernfs_notify(cfile->kn);
+}
+
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;

commit 9e10a130d9b62af976d17d120c95f3650769312c
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Sep 18 11:56:28 2015 -0400

    cgroup: replace cgroup_on_dfl() tests in controllers with cgroup_subsys_on_dfl()
    
    cgroup_on_dfl() tests whether the cgroup's root is the default
    hierarchy; however, an individual controller is only interested in
    whether the controller is attached to the default hierarchy and never
    tests a cgroup which doesn't belong to the hierarchy that the
    controller is attached to.
    
    This patch replaces cgroup_on_dfl() tests in controllers with faster
    static_key based cgroup_subsys_on_dfl().  This leaves cgroup core as
    the only user of cgroup_on_dfl() and the function is moved from the
    header file to cgroup.c.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Zefan Li <lizefan@huawei.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c3a9f1eb4097..355bf2ed8867 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -433,64 +433,6 @@ static inline struct cgroup *task_cgroup(struct task_struct *task,
 	return task_css(task, subsys_id)->cgroup;
 }
 
-/**
- * cgroup_on_dfl - test whether a cgroup is on the default hierarchy
- * @cgrp: the cgroup of interest
- *
- * The default hierarchy is the v2 interface of cgroup and this function
- * can be used to test whether a cgroup is on the default hierarchy for
- * cases where a subsystem should behave differnetly depending on the
- * interface version.
- *
- * The set of behaviors which change on the default hierarchy are still
- * being determined and the mount option is prefixed with __DEVEL__.
- *
- * List of changed behaviors:
- *
- * - Mount options "noprefix", "xattr", "clone_children", "release_agent"
- *   and "name" are disallowed.
- *
- * - When mounting an existing superblock, mount options should match.
- *
- * - Remount is disallowed.
- *
- * - rename(2) is disallowed.
- *
- * - "tasks" is removed.  Everything should be at process granularity.  Use
- *   "cgroup.procs" instead.
- *
- * - "cgroup.procs" is not sorted.  pids will be unique unless they got
- *   recycled inbetween reads.
- *
- * - "release_agent" and "notify_on_release" are removed.  Replacement
- *   notification mechanism will be implemented.
- *
- * - "cgroup.clone_children" is removed.
- *
- * - "cgroup.subtree_populated" is available.  Its value is 0 if the cgroup
- *   and its descendants contain no task; otherwise, 1.  The file also
- *   generates kernfs notification which can be monitored through poll and
- *   [di]notify when the value of the file changes.
- *
- * - cpuset: tasks will be kept in empty cpusets when hotplug happens and
- *   take masks of ancestors with non-empty cpus/mems, instead of being
- *   moved to an ancestor.
- *
- * - cpuset: a task can be moved into an empty cpuset, and again it takes
- *   masks of ancestors.
- *
- * - memcg: use_hierarchy is on by default and the cgroup file for the flag
- *   is not created.
- *
- * - blkcg: blk-throttle becomes properly hierarchical.
- *
- * - debug: disallowed on the default hierarchy.
- */
-static inline bool cgroup_on_dfl(const struct cgroup *cgrp)
-{
-	return cgrp->root == &cgrp_dfl_root;
-}
-
 /* no synchronization, the result can only be used as a hint */
 static inline bool cgroup_has_tasks(struct cgroup *cgrp)
 {

commit 49d1dc4b81797f88270832b11e9f73809e7e7209
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Sep 18 11:56:28 2015 -0400

    cgroup: implement static_key based cgroup_subsys_enabled() and cgroup_subsys_on_dfl()
    
    Whether a subsys is enabled and attached to the default hierarchy
    seldom changes and may be tested in the hot paths.  This patch
    implements static_key based cgroup_subsys_enabled() and
    cgroup_subsys_on_dfl() tests.
    
    The following patches will update the users and remove duplicate
    mechanisms.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Zefan Li <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index eb7ca55f72ef..c3a9f1eb4097 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -17,6 +17,7 @@
 #include <linux/fs.h>
 #include <linux/seq_file.h>
 #include <linux/kernfs.h>
+#include <linux/jump_label.h>
 
 #include <linux/cgroup-defs.h>
 
@@ -50,6 +51,26 @@ extern struct css_set init_css_set;
 #include <linux/cgroup_subsys.h>
 #undef SUBSYS
 
+#define SUBSYS(_x)								\
+	extern struct static_key_true _x ## _cgrp_subsys_enabled_key;		\
+	extern struct static_key_true _x ## _cgrp_subsys_on_dfl_key;
+#include <linux/cgroup_subsys.h>
+#undef SUBSYS
+
+/**
+ * cgroup_subsys_enabled - fast test on whether a subsys is enabled
+ * @ss: subsystem in question
+ */
+#define cgroup_subsys_enabled(ss)						\
+	static_branch_likely(&ss ## _enabled_key)
+
+/**
+ * cgroup_subsys_on_dfl - fast test on whether a subsys is on default hierarchy
+ * @ss: subsystem in question
+ */
+#define cgroup_subsys_on_dfl(ss)						\
+	static_branch_likely(&ss ## _on_dfl_key)
+
 bool css_has_online_children(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
 struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,

commit 20f1f4b5ffb870631bf4a4e7c7ba10e3528ae6a6
Merge: ce52399520e4 3e1d2eed39d8
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 25 14:19:29 2015 -0400

    Merge branch 'for-4.3-unified-base' into for-4.3

commit 6abc8ca19df0078de17dc38340db3002ed489ce7
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 4 15:20:55 2015 -0400

    cgroup: define controller file conventions
    
    Traditionally, each cgroup controller implemented whatever interface
    it wanted leading to interfaces which are widely inconsistent.
    Examining the requirements of the controllers readily yield that there
    are only a few control schemes shared among all.
    
    Two major controllers already had to implement new interface for the
    unified hierarchy due to significant structural changes.  Let's take
    the chance to establish common conventions throughout all controllers.
    
    This patch defines CGROUP_WEIGHT_MIN/DFL/MAX to be used on all weight
    based control knobs and documents the conventions that controllers
    should follow on the unified hierarchy.  Except for io.weight knob,
    all existing unified hierarchy knobs are already compliant.  A
    follow-up patch will update io.weight.
    
    v2: Added descriptions of min, low and high knobs.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a593e299162e..c6bf9d30c270 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -22,6 +22,15 @@
 
 #ifdef CONFIG_CGROUPS
 
+/*
+ * All weight knobs on the default hierarhcy should use the following min,
+ * default and max values.  The default value is the logarithmic center of
+ * MIN and MAX and allows 100x to be expressed in both directions.
+ */
+#define CGROUP_WEIGHT_MIN		1
+#define CGROUP_WEIGHT_DFL		100
+#define CGROUP_WEIGHT_MAX		10000
+
 /* a css_task_iter should be treated as an opaque object */
 struct css_task_iter {
 	struct cgroup_subsys		*ss;

commit 7e47682ea555e7c1edef1d8fd96e2aa4c12abe59
Author: Aleksa Sarai <cyphar@cyphar.com>
Date:   Tue Jun 9 21:32:09 2015 +1000

    cgroup: allow a cgroup subsystem to reject a fork
    
    Add a new cgroup subsystem callback can_fork that conditionally
    states whether or not the fork is accepted or rejected by a cgroup
    policy. In addition, add a cancel_fork callback so that if an error
    occurs later in the forking process, any state modified by can_fork can
    be reverted.
    
    Allow for a private opaque pointer to be passed from cgroup_can_fork to
    cgroup_post_fork, allowing for the fork state to be stored by each
    subsystem separately.
    
    Also add a tagging system for cgroup_subsys.h to allow for CGROUP_<TAG>
    enumerations to be be defined and used. In addition, explicitly add a
    CGROUP_CANFORK_COUNT macro to make arrays easier to define.
    
    This is in preparation for implementing the pids cgroup subsystem.
    
    Signed-off-by: Aleksa Sarai <cyphar@cyphar.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a593e299162e..a71fe2a3984e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -62,7 +62,12 @@ int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
 		     struct pid *pid, struct task_struct *tsk);
 
 void cgroup_fork(struct task_struct *p);
-void cgroup_post_fork(struct task_struct *p);
+extern int cgroup_can_fork(struct task_struct *p,
+			   void *ss_priv[CGROUP_CANFORK_COUNT]);
+extern void cgroup_cancel_fork(struct task_struct *p,
+			       void *ss_priv[CGROUP_CANFORK_COUNT]);
+extern void cgroup_post_fork(struct task_struct *p,
+			     void *old_ss_priv[CGROUP_CANFORK_COUNT]);
 void cgroup_exit(struct task_struct *p);
 
 int cgroup_init_early(void);
@@ -524,7 +529,13 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 				    struct dentry *dentry) { return -EINVAL; }
 
 static inline void cgroup_fork(struct task_struct *p) {}
-static inline void cgroup_post_fork(struct task_struct *p) {}
+static inline int cgroup_can_fork(struct task_struct *p,
+				  void *ss_priv[CGROUP_CANFORK_COUNT])
+{ return 0; }
+static inline void cgroup_cancel_fork(struct task_struct *p,
+				      void *ss_priv[CGROUP_CANFORK_COUNT]) {}
+static inline void cgroup_post_fork(struct task_struct *p,
+				    void *ss_priv[CGROUP_CANFORK_COUNT]) {}
 static inline void cgroup_exit(struct task_struct *p) {}
 
 static inline int cgroup_init_early(void) { return 0; }

commit bbe179f88d39274630823a0dc07d2714fd19a103
Merge: 4b703b1d4c46 8a0792ef8e01
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 26 19:50:04 2015 -0700

    Merge branch 'for-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
    
     - threadgroup_lock got reorganized so that its users can pick the
       actual locking mechanism to use.  Its only user - cgroups - is
       updated to use a percpu_rwsem instead of per-process rwsem.
    
       This makes things a bit lighter on hot paths and allows cgroups to
       perform and fail multi-task (a process) migrations atomically.
       Multi-task migrations are used in several places including the
       unified hierarchy.
    
     - Delegation rule and documentation added to unified hierarchy.  This
       will likely be the last interface update from the cgroup core side
       for unified hierarchy before lifting the devel mask.
    
     - Some groundwork for the pids controller which is scheduled to be
       merged in the coming devel cycle.
    
    * 'for-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: add delegation section to unified hierarchy documentation
      cgroup: require write perm on common ancestor when moving processes on the default hierarchy
      cgroup: separate out cgroup_procs_write_permission() from __cgroup_procs_write()
      kernfs: make kernfs_get_inode() public
      MAINTAINERS: add a cgroup core co-maintainer
      cgroup: fix uninitialised iterator in for_each_subsys_which
      cgroup: replace explicit ss_mask checking with for_each_subsys_which
      cgroup: use bitmask to filter for_each_subsys
      cgroup: add seq_file forward declaration for struct cftype
      cgroup: simplify threadgroup locking
      sched, cgroup: replace signal_struct->group_rwsem with a global percpu_rwsem
      sched, cgroup: reorganize threadgroup locking
      cgroup: switch to unsigned long for bitmasks
      cgroup: reorganize include/linux/cgroup.h
      cgroup: separate out include/linux/cgroup-defs.h
      cgroup: fix some comment typos

commit ec438699a9ae0856c2ce20a50dd39cdc7e92a732
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 22 17:13:22 2015 -0400

    cgroup, block: implement task_get_css() and use it in bio_associate_current()
    
    bio_associate_current() currently open codes task_css() and
    css_tryget_online() to find and pin $current's blkcg css.  Abstract it
    into task_get_css() which is implemented from cgroup side.  As a task
    is always associated with an online css for every subsystem except
    while the css_set update is propagating, task_get_css() retries till
    css_tryget_online() succeeds.
    
    This is a cleanup and shouldn't lead to noticeable behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b9cb94c3102a..e7da0aa65b2d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -773,6 +773,31 @@ static inline struct cgroup_subsys_state *task_css(struct task_struct *task,
 	return task_css_check(task, subsys_id, false);
 }
 
+/**
+ * task_get_css - find and get the css for (task, subsys)
+ * @task: the target task
+ * @subsys_id: the target subsystem ID
+ *
+ * Find the css for the (@task, @subsys_id) combination, increment a
+ * reference on and return it.  This function is guaranteed to return a
+ * valid css.
+ */
+static inline struct cgroup_subsys_state *
+task_get_css(struct task_struct *task, int subsys_id)
+{
+	struct cgroup_subsys_state *css;
+
+	rcu_read_lock();
+	while (true) {
+		css = task_css(task, subsys_id);
+		if (likely(css_tryget_online(css)))
+			break;
+		cpu_relax();
+	}
+	rcu_read_unlock();
+	return css;
+}
+
 /**
  * task_css_is_root - test whether a task belongs to the root css
  * @task: the target task

commit c326aa2bb2209e10df4a381801bb34ca0f923038
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 13 16:24:16 2015 -0400

    cgroup: reorganize include/linux/cgroup.h
    
    From c4d440938b5e2015c70594fe6666a099c844f929 Mon Sep 17 00:00:00 2001
    From: Tejun Heo <tj@kernel.org>
    Date: Wed, 13 May 2015 16:21:40 -0400
    
    Over time, cgroup.h grew organically and doesn't have much logical
    structure at this point.  Separation of cgroup-defs.h in the previous
    patch gives us a good chance for reorganizing cgroup.h as changes to
    the header are likely to cause conflicts anyway.
    
    This patch reorganizes cgroup.h so that it has consistent logical
    grouping.
    
    This is pure reorganization.
    
    v2: Relocating #ifdef CONFIG_CGROUPS caused build failure when cgroup
        is disabled.  Dropped.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 96a2ecd5aa69..82319fb31cfe 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -22,16 +22,189 @@
 
 #ifdef CONFIG_CGROUPS
 
-extern int cgroup_init_early(void);
-extern int cgroup_init(void);
-extern void cgroup_fork(struct task_struct *p);
-extern void cgroup_post_fork(struct task_struct *p);
-extern void cgroup_exit(struct task_struct *p);
-extern int cgroupstats_build(struct cgroupstats *stats,
-				struct dentry *dentry);
+/* a css_task_iter should be treated as an opaque object */
+struct css_task_iter {
+	struct cgroup_subsys		*ss;
+
+	struct list_head		*cset_pos;
+	struct list_head		*cset_head;
+
+	struct list_head		*task_pos;
+	struct list_head		*tasks_head;
+	struct list_head		*mg_tasks_head;
+};
+
+extern struct cgroup_root cgrp_dfl_root;
+extern struct css_set init_css_set;
+
+#define SUBSYS(_x) extern struct cgroup_subsys _x ## _cgrp_subsys;
+#include <linux/cgroup_subsys.h>
+#undef SUBSYS
+
+bool css_has_online_children(struct cgroup_subsys_state *css);
+struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
+struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
+					     struct cgroup_subsys *ss);
+struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
+						       struct cgroup_subsys *ss);
+
+bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
+int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
+int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
+
+int cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
+int cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
+int cgroup_rm_cftypes(struct cftype *cfts);
+
+char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
+int cgroupstats_build(struct cgroupstats *stats, struct dentry *dentry);
+int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
+		     struct pid *pid, struct task_struct *tsk);
+
+void cgroup_fork(struct task_struct *p);
+void cgroup_post_fork(struct task_struct *p);
+void cgroup_exit(struct task_struct *p);
+
+int cgroup_init_early(void);
+int cgroup_init(void);
+
+/*
+ * Iteration helpers and macros.
+ */
+
+struct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,
+					   struct cgroup_subsys_state *parent);
+struct cgroup_subsys_state *css_next_descendant_pre(struct cgroup_subsys_state *pos,
+						    struct cgroup_subsys_state *css);
+struct cgroup_subsys_state *css_rightmost_descendant(struct cgroup_subsys_state *pos);
+struct cgroup_subsys_state *css_next_descendant_post(struct cgroup_subsys_state *pos,
+						     struct cgroup_subsys_state *css);
+
+struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset);
+struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
+
+void css_task_iter_start(struct cgroup_subsys_state *css,
+			 struct css_task_iter *it);
+struct task_struct *css_task_iter_next(struct css_task_iter *it);
+void css_task_iter_end(struct css_task_iter *it);
+
+/**
+ * css_for_each_child - iterate through children of a css
+ * @pos: the css * to use as the loop cursor
+ * @parent: css whose children to walk
+ *
+ * Walk @parent's children.  Must be called under rcu_read_lock().
+ *
+ * If a subsystem synchronizes ->css_online() and the start of iteration, a
+ * css which finished ->css_online() is guaranteed to be visible in the
+ * future iterations and will stay visible until the last reference is put.
+ * A css which hasn't finished ->css_online() or already finished
+ * ->css_offline() may show up during traversal.  It's each subsystem's
+ * responsibility to synchronize against on/offlining.
+ *
+ * It is allowed to temporarily drop RCU read lock during iteration.  The
+ * caller is responsible for ensuring that @pos remains accessible until
+ * the start of the next iteration by, for example, bumping the css refcnt.
+ */
+#define css_for_each_child(pos, parent)					\
+	for ((pos) = css_next_child(NULL, (parent)); (pos);		\
+	     (pos) = css_next_child((pos), (parent)))
+
+/**
+ * css_for_each_descendant_pre - pre-order walk of a css's descendants
+ * @pos: the css * to use as the loop cursor
+ * @root: css whose descendants to walk
+ *
+ * Walk @root's descendants.  @root is included in the iteration and the
+ * first node to be visited.  Must be called under rcu_read_lock().
+ *
+ * If a subsystem synchronizes ->css_online() and the start of iteration, a
+ * css which finished ->css_online() is guaranteed to be visible in the
+ * future iterations and will stay visible until the last reference is put.
+ * A css which hasn't finished ->css_online() or already finished
+ * ->css_offline() may show up during traversal.  It's each subsystem's
+ * responsibility to synchronize against on/offlining.
+ *
+ * For example, the following guarantees that a descendant can't escape
+ * state updates of its ancestors.
+ *
+ * my_online(@css)
+ * {
+ *	Lock @css's parent and @css;
+ *	Inherit state from the parent;
+ *	Unlock both.
+ * }
+ *
+ * my_update_state(@css)
+ * {
+ *	css_for_each_descendant_pre(@pos, @css) {
+ *		Lock @pos;
+ *		if (@pos == @css)
+ *			Update @css's state;
+ *		else
+ *			Verify @pos is alive and inherit state from its parent;
+ *		Unlock @pos;
+ *	}
+ * }
+ *
+ * As long as the inheriting step, including checking the parent state, is
+ * enclosed inside @pos locking, double-locking the parent isn't necessary
+ * while inheriting.  The state update to the parent is guaranteed to be
+ * visible by walking order and, as long as inheriting operations to the
+ * same @pos are atomic to each other, multiple updates racing each other
+ * still result in the correct state.  It's guaranateed that at least one
+ * inheritance happens for any css after the latest update to its parent.
+ *
+ * If checking parent's state requires locking the parent, each inheriting
+ * iteration should lock and unlock both @pos->parent and @pos.
+ *
+ * Alternatively, a subsystem may choose to use a single global lock to
+ * synchronize ->css_online() and ->css_offline() against tree-walking
+ * operations.
+ *
+ * It is allowed to temporarily drop RCU read lock during iteration.  The
+ * caller is responsible for ensuring that @pos remains accessible until
+ * the start of the next iteration by, for example, bumping the css refcnt.
+ */
+#define css_for_each_descendant_pre(pos, css)				\
+	for ((pos) = css_next_descendant_pre(NULL, (css)); (pos);	\
+	     (pos) = css_next_descendant_pre((pos), (css)))
+
+/**
+ * css_for_each_descendant_post - post-order walk of a css's descendants
+ * @pos: the css * to use as the loop cursor
+ * @css: css whose descendants to walk
+ *
+ * Similar to css_for_each_descendant_pre() but performs post-order
+ * traversal instead.  @root is included in the iteration and the last
+ * node to be visited.
+ *
+ * If a subsystem synchronizes ->css_online() and the start of iteration, a
+ * css which finished ->css_online() is guaranteed to be visible in the
+ * future iterations and will stay visible until the last reference is put.
+ * A css which hasn't finished ->css_online() or already finished
+ * ->css_offline() may show up during traversal.  It's each subsystem's
+ * responsibility to synchronize against on/offlining.
+ *
+ * Note that the walk visibility guarantee example described in pre-order
+ * walk doesn't apply the same to post-order walks.
+ */
+#define css_for_each_descendant_post(pos, css)				\
+	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\
+	     (pos) = css_next_descendant_post((pos), (css)))
+
+/**
+ * cgroup_taskset_for_each - iterate cgroup_taskset
+ * @task: the loop cursor
+ * @tset: taskset to iterate
+ */
+#define cgroup_taskset_for_each(task, tset)				\
+	for ((task) = cgroup_taskset_first((tset)); (task);		\
+	     (task) = cgroup_taskset_next((tset)))
 
-extern int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
-			    struct pid *pid, struct task_struct *tsk);
+/*
+ * Inline functions.
+ */
 
 /**
  * css_get - obtain a reference on the specified css
@@ -118,8 +291,87 @@ static inline void css_put_many(struct cgroup_subsys_state *css, unsigned int n)
 		percpu_ref_put_many(&css->refcnt, n);
 }
 
-extern struct cgroup_root cgrp_dfl_root;
-extern struct css_set init_css_set;
+/**
+ * task_css_set_check - obtain a task's css_set with extra access conditions
+ * @task: the task to obtain css_set for
+ * @__c: extra condition expression to be passed to rcu_dereference_check()
+ *
+ * A task's css_set is RCU protected, initialized and exited while holding
+ * task_lock(), and can only be modified while holding both cgroup_mutex
+ * and task_lock() while the task is alive.  This macro verifies that the
+ * caller is inside proper critical section and returns @task's css_set.
+ *
+ * The caller can also specify additional allowed conditions via @__c, such
+ * as locks used during the cgroup_subsys::attach() methods.
+ */
+#ifdef CONFIG_PROVE_RCU
+extern struct mutex cgroup_mutex;
+extern struct rw_semaphore css_set_rwsem;
+#define task_css_set_check(task, __c)					\
+	rcu_dereference_check((task)->cgroups,				\
+		lockdep_is_held(&cgroup_mutex) ||			\
+		lockdep_is_held(&css_set_rwsem) ||			\
+		((task)->flags & PF_EXITING) || (__c))
+#else
+#define task_css_set_check(task, __c)					\
+	rcu_dereference((task)->cgroups)
+#endif
+
+/**
+ * task_css_check - obtain css for (task, subsys) w/ extra access conds
+ * @task: the target task
+ * @subsys_id: the target subsystem ID
+ * @__c: extra condition expression to be passed to rcu_dereference_check()
+ *
+ * Return the cgroup_subsys_state for the (@task, @subsys_id) pair.  The
+ * synchronization rules are the same as task_css_set_check().
+ */
+#define task_css_check(task, subsys_id, __c)				\
+	task_css_set_check((task), (__c))->subsys[(subsys_id)]
+
+/**
+ * task_css_set - obtain a task's css_set
+ * @task: the task to obtain css_set for
+ *
+ * See task_css_set_check().
+ */
+static inline struct css_set *task_css_set(struct task_struct *task)
+{
+	return task_css_set_check(task, false);
+}
+
+/**
+ * task_css - obtain css for (task, subsys)
+ * @task: the target task
+ * @subsys_id: the target subsystem ID
+ *
+ * See task_css_check().
+ */
+static inline struct cgroup_subsys_state *task_css(struct task_struct *task,
+						   int subsys_id)
+{
+	return task_css_check(task, subsys_id, false);
+}
+
+/**
+ * task_css_is_root - test whether a task belongs to the root css
+ * @task: the target task
+ * @subsys_id: the target subsystem ID
+ *
+ * Test whether @task belongs to the root css on the specified subsystem.
+ * May be invoked in any context.
+ */
+static inline bool task_css_is_root(struct task_struct *task, int subsys_id)
+{
+	return task_css_check(task, subsys_id, true) ==
+		init_css_set.subsys[subsys_id];
+}
+
+static inline struct cgroup *task_cgroup(struct task_struct *task,
+					 int subsys_id)
+{
+	return task_css(task, subsys_id)->cgroup;
+}
 
 /**
  * cgroup_on_dfl - test whether a cgroup is on the default hierarchy
@@ -236,284 +488,22 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 	pr_cont_kernfs_path(cgrp->kn);
 }
 
-char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
-
-int cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
-int cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
-int cgroup_rm_cftypes(struct cftype *cfts);
-
-bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
-
-struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset);
-struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
-
-/**
- * cgroup_taskset_for_each - iterate cgroup_taskset
- * @task: the loop cursor
- * @tset: taskset to iterate
- */
-#define cgroup_taskset_for_each(task, tset)				\
-	for ((task) = cgroup_taskset_first((tset)); (task);		\
-	     (task) = cgroup_taskset_next((tset)))
-
-#define SUBSYS(_x) extern struct cgroup_subsys _x ## _cgrp_subsys;
-#include <linux/cgroup_subsys.h>
-#undef SUBSYS
-
-/**
- * task_css_set_check - obtain a task's css_set with extra access conditions
- * @task: the task to obtain css_set for
- * @__c: extra condition expression to be passed to rcu_dereference_check()
- *
- * A task's css_set is RCU protected, initialized and exited while holding
- * task_lock(), and can only be modified while holding both cgroup_mutex
- * and task_lock() while the task is alive.  This macro verifies that the
- * caller is inside proper critical section and returns @task's css_set.
- *
- * The caller can also specify additional allowed conditions via @__c, such
- * as locks used during the cgroup_subsys::attach() methods.
- */
-#ifdef CONFIG_PROVE_RCU
-extern struct mutex cgroup_mutex;
-extern struct rw_semaphore css_set_rwsem;
-#define task_css_set_check(task, __c)					\
-	rcu_dereference_check((task)->cgroups,				\
-		lockdep_is_held(&cgroup_mutex) ||			\
-		lockdep_is_held(&css_set_rwsem) ||			\
-		((task)->flags & PF_EXITING) || (__c))
-#else
-#define task_css_set_check(task, __c)					\
-	rcu_dereference((task)->cgroups)
-#endif
-
-/**
- * task_css_check - obtain css for (task, subsys) w/ extra access conds
- * @task: the target task
- * @subsys_id: the target subsystem ID
- * @__c: extra condition expression to be passed to rcu_dereference_check()
- *
- * Return the cgroup_subsys_state for the (@task, @subsys_id) pair.  The
- * synchronization rules are the same as task_css_set_check().
- */
-#define task_css_check(task, subsys_id, __c)				\
-	task_css_set_check((task), (__c))->subsys[(subsys_id)]
-
-/**
- * task_css_set - obtain a task's css_set
- * @task: the task to obtain css_set for
- *
- * See task_css_set_check().
- */
-static inline struct css_set *task_css_set(struct task_struct *task)
-{
-	return task_css_set_check(task, false);
-}
-
-/**
- * task_css - obtain css for (task, subsys)
- * @task: the target task
- * @subsys_id: the target subsystem ID
- *
- * See task_css_check().
- */
-static inline struct cgroup_subsys_state *task_css(struct task_struct *task,
-						   int subsys_id)
-{
-	return task_css_check(task, subsys_id, false);
-}
-
-/**
- * task_css_is_root - test whether a task belongs to the root css
- * @task: the target task
- * @subsys_id: the target subsystem ID
- *
- * Test whether @task belongs to the root css on the specified subsystem.
- * May be invoked in any context.
- */
-static inline bool task_css_is_root(struct task_struct *task, int subsys_id)
-{
-	return task_css_check(task, subsys_id, true) ==
-		init_css_set.subsys[subsys_id];
-}
-
-static inline struct cgroup *task_cgroup(struct task_struct *task,
-					 int subsys_id)
-{
-	return task_css(task, subsys_id)->cgroup;
-}
-
-struct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,
-					   struct cgroup_subsys_state *parent);
-
-struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
-
-/**
- * css_for_each_child - iterate through children of a css
- * @pos: the css * to use as the loop cursor
- * @parent: css whose children to walk
- *
- * Walk @parent's children.  Must be called under rcu_read_lock().
- *
- * If a subsystem synchronizes ->css_online() and the start of iteration, a
- * css which finished ->css_online() is guaranteed to be visible in the
- * future iterations and will stay visible until the last reference is put.
- * A css which hasn't finished ->css_online() or already finished
- * ->css_offline() may show up during traversal.  It's each subsystem's
- * responsibility to synchronize against on/offlining.
- *
- * It is allowed to temporarily drop RCU read lock during iteration.  The
- * caller is responsible for ensuring that @pos remains accessible until
- * the start of the next iteration by, for example, bumping the css refcnt.
- */
-#define css_for_each_child(pos, parent)					\
-	for ((pos) = css_next_child(NULL, (parent)); (pos);		\
-	     (pos) = css_next_child((pos), (parent)))
-
-struct cgroup_subsys_state *
-css_next_descendant_pre(struct cgroup_subsys_state *pos,
-			struct cgroup_subsys_state *css);
-
-struct cgroup_subsys_state *
-css_rightmost_descendant(struct cgroup_subsys_state *pos);
-
-/**
- * css_for_each_descendant_pre - pre-order walk of a css's descendants
- * @pos: the css * to use as the loop cursor
- * @root: css whose descendants to walk
- *
- * Walk @root's descendants.  @root is included in the iteration and the
- * first node to be visited.  Must be called under rcu_read_lock().
- *
- * If a subsystem synchronizes ->css_online() and the start of iteration, a
- * css which finished ->css_online() is guaranteed to be visible in the
- * future iterations and will stay visible until the last reference is put.
- * A css which hasn't finished ->css_online() or already finished
- * ->css_offline() may show up during traversal.  It's each subsystem's
- * responsibility to synchronize against on/offlining.
- *
- * For example, the following guarantees that a descendant can't escape
- * state updates of its ancestors.
- *
- * my_online(@css)
- * {
- *	Lock @css's parent and @css;
- *	Inherit state from the parent;
- *	Unlock both.
- * }
- *
- * my_update_state(@css)
- * {
- *	css_for_each_descendant_pre(@pos, @css) {
- *		Lock @pos;
- *		if (@pos == @css)
- *			Update @css's state;
- *		else
- *			Verify @pos is alive and inherit state from its parent;
- *		Unlock @pos;
- *	}
- * }
- *
- * As long as the inheriting step, including checking the parent state, is
- * enclosed inside @pos locking, double-locking the parent isn't necessary
- * while inheriting.  The state update to the parent is guaranteed to be
- * visible by walking order and, as long as inheriting operations to the
- * same @pos are atomic to each other, multiple updates racing each other
- * still result in the correct state.  It's guaranateed that at least one
- * inheritance happens for any css after the latest update to its parent.
- *
- * If checking parent's state requires locking the parent, each inheriting
- * iteration should lock and unlock both @pos->parent and @pos.
- *
- * Alternatively, a subsystem may choose to use a single global lock to
- * synchronize ->css_online() and ->css_offline() against tree-walking
- * operations.
- *
- * It is allowed to temporarily drop RCU read lock during iteration.  The
- * caller is responsible for ensuring that @pos remains accessible until
- * the start of the next iteration by, for example, bumping the css refcnt.
- */
-#define css_for_each_descendant_pre(pos, css)				\
-	for ((pos) = css_next_descendant_pre(NULL, (css)); (pos);	\
-	     (pos) = css_next_descendant_pre((pos), (css)))
-
-struct cgroup_subsys_state *
-css_next_descendant_post(struct cgroup_subsys_state *pos,
-			 struct cgroup_subsys_state *css);
-
-/**
- * css_for_each_descendant_post - post-order walk of a css's descendants
- * @pos: the css * to use as the loop cursor
- * @css: css whose descendants to walk
- *
- * Similar to css_for_each_descendant_pre() but performs post-order
- * traversal instead.  @root is included in the iteration and the last
- * node to be visited.
- *
- * If a subsystem synchronizes ->css_online() and the start of iteration, a
- * css which finished ->css_online() is guaranteed to be visible in the
- * future iterations and will stay visible until the last reference is put.
- * A css which hasn't finished ->css_online() or already finished
- * ->css_offline() may show up during traversal.  It's each subsystem's
- * responsibility to synchronize against on/offlining.
- *
- * Note that the walk visibility guarantee example described in pre-order
- * walk doesn't apply the same to post-order walks.
- */
-#define css_for_each_descendant_post(pos, css)				\
-	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\
-	     (pos) = css_next_descendant_post((pos), (css)))
-
-bool css_has_online_children(struct cgroup_subsys_state *css);
-
-/* A css_task_iter should be treated as an opaque object */
-struct css_task_iter {
-	struct cgroup_subsys		*ss;
-
-	struct list_head		*cset_pos;
-	struct list_head		*cset_head;
-
-	struct list_head		*task_pos;
-	struct list_head		*tasks_head;
-	struct list_head		*mg_tasks_head;
-};
-
-void css_task_iter_start(struct cgroup_subsys_state *css,
-			 struct css_task_iter *it);
-struct task_struct *css_task_iter_next(struct css_task_iter *it);
-void css_task_iter_end(struct css_task_iter *it);
-
-int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
-int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
-
-struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
-					     struct cgroup_subsys *ss);
-struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
-						       struct cgroup_subsys *ss);
-
 #else /* !CONFIG_CGROUPS */
 
 struct cgroup_subsys_state;
 
-static inline int cgroup_init_early(void) { return 0; }
-static inline int cgroup_init(void) { return 0; }
+static inline void css_put(struct cgroup_subsys_state *css) {}
+static inline int cgroup_attach_task_all(struct task_struct *from,
+					 struct task_struct *t) { return 0; }
+static inline int cgroupstats_build(struct cgroupstats *stats,
+				    struct dentry *dentry) { return -EINVAL; }
+
 static inline void cgroup_fork(struct task_struct *p) {}
 static inline void cgroup_post_fork(struct task_struct *p) {}
 static inline void cgroup_exit(struct task_struct *p) {}
 
-static inline int cgroupstats_build(struct cgroupstats *stats,
-					struct dentry *dentry)
-{
-	return -EINVAL;
-}
-
-static inline void css_put(struct cgroup_subsys_state *css) {}
-
-/* No cgroups - nothing to do */
-static inline int cgroup_attach_task_all(struct task_struct *from,
-					 struct task_struct *t)
-{
-	return 0;
-}
+static inline int cgroup_init_early(void) { return 0; }
+static inline int cgroup_init(void) { return 0; }
 
 #endif /* !CONFIG_CGROUPS */
 

commit b4a04ab7a37b490cad48e69abfe14288cacb669c
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 13 15:38:40 2015 -0400

    cgroup: separate out include/linux/cgroup-defs.h
    
    From 2d728f74bfc071df06773e2fd7577dd5dab6425d Mon Sep 17 00:00:00 2001
    From: Tejun Heo <tj@kernel.org>
    Date: Wed, 13 May 2015 15:37:01 -0400
    
    This patch separates out cgroup-defs.h from cgroup.h which has grown a
    lot of dependencies.  cgroup-defs.h currently only contains constant
    and type definitions and can be used to break circular include
    dependency.  While moving, definitions are reordered so that
    cgroup-defs.h has consistent logical structure.
    
    This patch is pure reorganization.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b9cb94c3102a..96a2ecd5aa69 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -11,23 +11,16 @@
 #include <linux/sched.h>
 #include <linux/cpumask.h>
 #include <linux/nodemask.h>
-#include <linux/rcupdate.h>
 #include <linux/rculist.h>
 #include <linux/cgroupstats.h>
 #include <linux/rwsem.h>
-#include <linux/idr.h>
-#include <linux/workqueue.h>
 #include <linux/fs.h>
-#include <linux/percpu-refcount.h>
 #include <linux/seq_file.h>
 #include <linux/kernfs.h>
-#include <linux/wait.h>
 
-#ifdef CONFIG_CGROUPS
+#include <linux/cgroup-defs.h>
 
-struct cgroup_root;
-struct cgroup_subsys;
-struct cgroup;
+#ifdef CONFIG_CGROUPS
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
@@ -40,66 +33,6 @@ extern int cgroupstats_build(struct cgroupstats *stats,
 extern int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
 			    struct pid *pid, struct task_struct *tsk);
 
-/* define the enumeration of all cgroup subsystems */
-#define SUBSYS(_x) _x ## _cgrp_id,
-enum cgroup_subsys_id {
-#include <linux/cgroup_subsys.h>
-	CGROUP_SUBSYS_COUNT,
-};
-#undef SUBSYS
-
-/*
- * Per-subsystem/per-cgroup state maintained by the system.  This is the
- * fundamental structural building block that controllers deal with.
- *
- * Fields marked with "PI:" are public and immutable and may be accessed
- * directly without synchronization.
- */
-struct cgroup_subsys_state {
-	/* PI: the cgroup that this css is attached to */
-	struct cgroup *cgroup;
-
-	/* PI: the cgroup subsystem that this css is attached to */
-	struct cgroup_subsys *ss;
-
-	/* reference count - access via css_[try]get() and css_put() */
-	struct percpu_ref refcnt;
-
-	/* PI: the parent css */
-	struct cgroup_subsys_state *parent;
-
-	/* siblings list anchored at the parent's ->children */
-	struct list_head sibling;
-	struct list_head children;
-
-	/*
-	 * PI: Subsys-unique ID.  0 is unused and root is always 1.  The
-	 * matching css can be looked up using css_from_id().
-	 */
-	int id;
-
-	unsigned int flags;
-
-	/*
-	 * Monotonically increasing unique serial number which defines a
-	 * uniform order among all csses.  It's guaranteed that all
-	 * ->children lists are in the ascending order of ->serial_nr and
-	 * used to allow interrupting and resuming iterations.
-	 */
-	u64 serial_nr;
-
-	/* percpu_ref killing and RCU release */
-	struct rcu_head rcu_head;
-	struct work_struct destroy_work;
-};
-
-/* bits in struct cgroup_subsys_state flags field */
-enum {
-	CSS_NO_REF	= (1 << 0), /* no reference counting for this css */
-	CSS_ONLINE	= (1 << 1), /* between ->css_online() and ->css_offline() */
-	CSS_RELEASED	= (1 << 2), /* refcnt reached zero, released */
-};
-
 /**
  * css_get - obtain a reference on the specified css
  * @css: target css
@@ -185,307 +118,6 @@ static inline void css_put_many(struct cgroup_subsys_state *css, unsigned int n)
 		percpu_ref_put_many(&css->refcnt, n);
 }
 
-/* bits in struct cgroup flags field */
-enum {
-	/* Control Group requires release notifications to userspace */
-	CGRP_NOTIFY_ON_RELEASE,
-	/*
-	 * Clone the parent's configuration when creating a new child
-	 * cpuset cgroup.  For historical reasons, this option can be
-	 * specified at mount time and thus is implemented here.
-	 */
-	CGRP_CPUSET_CLONE_CHILDREN,
-};
-
-struct cgroup {
-	/* self css with NULL ->ss, points back to this cgroup */
-	struct cgroup_subsys_state self;
-
-	unsigned long flags;		/* "unsigned long" so bitops work */
-
-	/*
-	 * idr allocated in-hierarchy ID.
-	 *
-	 * ID 0 is not used, the ID of the root cgroup is always 1, and a
-	 * new cgroup will be assigned with a smallest available ID.
-	 *
-	 * Allocating/Removing ID must be protected by cgroup_mutex.
-	 */
-	int id;
-
-	/*
-	 * If this cgroup contains any tasks, it contributes one to
-	 * populated_cnt.  All children with non-zero popuplated_cnt of
-	 * their own contribute one.  The count is zero iff there's no task
-	 * in this cgroup or its subtree.
-	 */
-	int populated_cnt;
-
-	struct kernfs_node *kn;		/* cgroup kernfs entry */
-	struct kernfs_node *populated_kn; /* kn for "cgroup.subtree_populated" */
-
-	/*
-	 * The bitmask of subsystems enabled on the child cgroups.
-	 * ->subtree_control is the one configured through
-	 * "cgroup.subtree_control" while ->child_subsys_mask is the
-	 * effective one which may have more subsystems enabled.
-	 * Controller knobs are made available iff it's enabled in
-	 * ->subtree_control.
-	 */
-	unsigned int subtree_control;
-	unsigned int child_subsys_mask;
-
-	/* Private pointers for each registered subsystem */
-	struct cgroup_subsys_state __rcu *subsys[CGROUP_SUBSYS_COUNT];
-
-	struct cgroup_root *root;
-
-	/*
-	 * List of cgrp_cset_links pointing at css_sets with tasks in this
-	 * cgroup.  Protected by css_set_lock.
-	 */
-	struct list_head cset_links;
-
-	/*
-	 * On the default hierarchy, a css_set for a cgroup with some
-	 * susbsys disabled will point to css's which are associated with
-	 * the closest ancestor which has the subsys enabled.  The
-	 * following lists all css_sets which point to this cgroup's css
-	 * for the given subsystem.
-	 */
-	struct list_head e_csets[CGROUP_SUBSYS_COUNT];
-
-	/*
-	 * list of pidlists, up to two for each namespace (one for procs, one
-	 * for tasks); created on demand.
-	 */
-	struct list_head pidlists;
-	struct mutex pidlist_mutex;
-
-	/* used to wait for offlining of csses */
-	wait_queue_head_t offline_waitq;
-
-	/* used to schedule release agent */
-	struct work_struct release_agent_work;
-};
-
-#define MAX_CGROUP_ROOT_NAMELEN 64
-
-/* cgroup_root->flags */
-enum {
-	CGRP_ROOT_SANE_BEHAVIOR	= (1 << 0), /* __DEVEL__sane_behavior specified */
-	CGRP_ROOT_NOPREFIX	= (1 << 1), /* mounted subsystems have no named prefix */
-	CGRP_ROOT_XATTR		= (1 << 2), /* supports extended attributes */
-};
-
-/*
- * A cgroup_root represents the root of a cgroup hierarchy, and may be
- * associated with a kernfs_root to form an active hierarchy.  This is
- * internal to cgroup core.  Don't access directly from controllers.
- */
-struct cgroup_root {
-	struct kernfs_root *kf_root;
-
-	/* The bitmask of subsystems attached to this hierarchy */
-	unsigned int subsys_mask;
-
-	/* Unique id for this hierarchy. */
-	int hierarchy_id;
-
-	/* The root cgroup.  Root is destroyed on its release. */
-	struct cgroup cgrp;
-
-	/* Number of cgroups in the hierarchy, used only for /proc/cgroups */
-	atomic_t nr_cgrps;
-
-	/* A list running through the active hierarchies */
-	struct list_head root_list;
-
-	/* Hierarchy-specific flags */
-	unsigned int flags;
-
-	/* IDs for cgroups in this hierarchy */
-	struct idr cgroup_idr;
-
-	/* The path to use for release notifications. */
-	char release_agent_path[PATH_MAX];
-
-	/* The name for this hierarchy - may be empty */
-	char name[MAX_CGROUP_ROOT_NAMELEN];
-};
-
-/*
- * A css_set is a structure holding pointers to a set of
- * cgroup_subsys_state objects. This saves space in the task struct
- * object and speeds up fork()/exit(), since a single inc/dec and a
- * list_add()/del() can bump the reference count on the entire cgroup
- * set for a task.
- */
-
-struct css_set {
-
-	/* Reference count */
-	atomic_t refcount;
-
-	/*
-	 * List running through all cgroup groups in the same hash
-	 * slot. Protected by css_set_lock
-	 */
-	struct hlist_node hlist;
-
-	/*
-	 * Lists running through all tasks using this cgroup group.
-	 * mg_tasks lists tasks which belong to this cset but are in the
-	 * process of being migrated out or in.  Protected by
-	 * css_set_rwsem, but, during migration, once tasks are moved to
-	 * mg_tasks, it can be read safely while holding cgroup_mutex.
-	 */
-	struct list_head tasks;
-	struct list_head mg_tasks;
-
-	/*
-	 * List of cgrp_cset_links pointing at cgroups referenced from this
-	 * css_set.  Protected by css_set_lock.
-	 */
-	struct list_head cgrp_links;
-
-	/* the default cgroup associated with this css_set */
-	struct cgroup *dfl_cgrp;
-
-	/*
-	 * Set of subsystem states, one for each subsystem. This array is
-	 * immutable after creation apart from the init_css_set during
-	 * subsystem registration (at boot time).
-	 */
-	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
-
-	/*
-	 * List of csets participating in the on-going migration either as
-	 * source or destination.  Protected by cgroup_mutex.
-	 */
-	struct list_head mg_preload_node;
-	struct list_head mg_node;
-
-	/*
-	 * If this cset is acting as the source of migration the following
-	 * two fields are set.  mg_src_cgrp is the source cgroup of the
-	 * on-going migration and mg_dst_cset is the destination cset the
-	 * target tasks on this cset should be migrated to.  Protected by
-	 * cgroup_mutex.
-	 */
-	struct cgroup *mg_src_cgrp;
-	struct css_set *mg_dst_cset;
-
-	/*
-	 * On the default hierarhcy, ->subsys[ssid] may point to a css
-	 * attached to an ancestor instead of the cgroup this css_set is
-	 * associated with.  The following node is anchored at
-	 * ->subsys[ssid]->cgroup->e_csets[ssid] and provides a way to
-	 * iterate through all css's attached to a given cgroup.
-	 */
-	struct list_head e_cset_node[CGROUP_SUBSYS_COUNT];
-
-	/* For RCU-protected deletion */
-	struct rcu_head rcu_head;
-};
-
-/*
- * struct cftype: handler definitions for cgroup control files
- *
- * When reading/writing to a file:
- *	- the cgroup to use is file->f_path.dentry->d_parent->d_fsdata
- *	- the 'cftype' of the file is file->f_path.dentry->d_fsdata
- */
-
-/* cftype->flags */
-enum {
-	CFTYPE_ONLY_ON_ROOT	= (1 << 0),	/* only create on root cgrp */
-	CFTYPE_NOT_ON_ROOT	= (1 << 1),	/* don't create on root cgrp */
-	CFTYPE_NO_PREFIX	= (1 << 3),	/* (DON'T USE FOR NEW FILES) no subsys prefix */
-
-	/* internal flags, do not use outside cgroup core proper */
-	__CFTYPE_ONLY_ON_DFL	= (1 << 16),	/* only on default hierarchy */
-	__CFTYPE_NOT_ON_DFL	= (1 << 17),	/* not on default hierarchy */
-};
-
-#define MAX_CFTYPE_NAME		64
-
-struct cftype {
-	/*
-	 * By convention, the name should begin with the name of the
-	 * subsystem, followed by a period.  Zero length string indicates
-	 * end of cftype array.
-	 */
-	char name[MAX_CFTYPE_NAME];
-	int private;
-	/*
-	 * If not 0, file mode is set to this value, otherwise it will
-	 * be figured out automatically
-	 */
-	umode_t mode;
-
-	/*
-	 * The maximum length of string, excluding trailing nul, that can
-	 * be passed to write.  If < PAGE_SIZE-1, PAGE_SIZE-1 is assumed.
-	 */
-	size_t max_write_len;
-
-	/* CFTYPE_* flags */
-	unsigned int flags;
-
-	/*
-	 * Fields used for internal bookkeeping.  Initialized automatically
-	 * during registration.
-	 */
-	struct cgroup_subsys *ss;	/* NULL for cgroup core files */
-	struct list_head node;		/* anchored at ss->cfts */
-	struct kernfs_ops *kf_ops;
-
-	/*
-	 * read_u64() is a shortcut for the common case of returning a
-	 * single integer. Use it in place of read()
-	 */
-	u64 (*read_u64)(struct cgroup_subsys_state *css, struct cftype *cft);
-	/*
-	 * read_s64() is a signed version of read_u64()
-	 */
-	s64 (*read_s64)(struct cgroup_subsys_state *css, struct cftype *cft);
-
-	/* generic seq_file read interface */
-	int (*seq_show)(struct seq_file *sf, void *v);
-
-	/* optional ops, implement all or none */
-	void *(*seq_start)(struct seq_file *sf, loff_t *ppos);
-	void *(*seq_next)(struct seq_file *sf, void *v, loff_t *ppos);
-	void (*seq_stop)(struct seq_file *sf, void *v);
-
-	/*
-	 * write_u64() is a shortcut for the common case of accepting
-	 * a single integer (as parsed by simple_strtoull) from
-	 * userspace. Use in place of write(); return 0 or error.
-	 */
-	int (*write_u64)(struct cgroup_subsys_state *css, struct cftype *cft,
-			 u64 val);
-	/*
-	 * write_s64() is a signed version of write_u64()
-	 */
-	int (*write_s64)(struct cgroup_subsys_state *css, struct cftype *cft,
-			 s64 val);
-
-	/*
-	 * write() is the generic write callback which maps directly to
-	 * kernfs write operation and overrides all other operations.
-	 * Maximum write size is determined by ->max_write_len.  Use
-	 * of_css/cft() to access the associated css and cft.
-	 */
-	ssize_t (*write)(struct kernfs_open_file *of,
-			 char *buf, size_t nbytes, loff_t off);
-
-#ifdef CONFIG_DEBUG_LOCK_ALLOC
-	struct lock_class_key	lockdep_key;
-#endif
-};
-
 extern struct cgroup_root cgrp_dfl_root;
 extern struct css_set init_css_set;
 
@@ -612,11 +244,6 @@ int cgroup_rm_cftypes(struct cftype *cfts);
 
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 
-/*
- * Control Group taskset, used to pass around set of tasks to cgroup_subsys
- * methods.
- */
-struct cgroup_taskset;
 struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset);
 struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
 
@@ -629,84 +256,6 @@ struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
 	for ((task) = cgroup_taskset_first((tset)); (task);		\
 	     (task) = cgroup_taskset_next((tset)))
 
-/*
- * Control Group subsystem type.
- * See Documentation/cgroups/cgroups.txt for details
- */
-
-struct cgroup_subsys {
-	struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state *parent_css);
-	int (*css_online)(struct cgroup_subsys_state *css);
-	void (*css_offline)(struct cgroup_subsys_state *css);
-	void (*css_released)(struct cgroup_subsys_state *css);
-	void (*css_free)(struct cgroup_subsys_state *css);
-	void (*css_reset)(struct cgroup_subsys_state *css);
-	void (*css_e_css_changed)(struct cgroup_subsys_state *css);
-
-	int (*can_attach)(struct cgroup_subsys_state *css,
-			  struct cgroup_taskset *tset);
-	void (*cancel_attach)(struct cgroup_subsys_state *css,
-			      struct cgroup_taskset *tset);
-	void (*attach)(struct cgroup_subsys_state *css,
-		       struct cgroup_taskset *tset);
-	void (*fork)(struct task_struct *task);
-	void (*exit)(struct cgroup_subsys_state *css,
-		     struct cgroup_subsys_state *old_css,
-		     struct task_struct *task);
-	void (*bind)(struct cgroup_subsys_state *root_css);
-
-	int disabled;
-	int early_init;
-
-	/*
-	 * If %false, this subsystem is properly hierarchical -
-	 * configuration, resource accounting and restriction on a parent
-	 * cgroup cover those of its children.  If %true, hierarchy support
-	 * is broken in some ways - some subsystems ignore hierarchy
-	 * completely while others are only implemented half-way.
-	 *
-	 * It's now disallowed to create nested cgroups if the subsystem is
-	 * broken and cgroup core will emit a warning message on such
-	 * cases.  Eventually, all subsystems will be made properly
-	 * hierarchical and this will go away.
-	 */
-	bool broken_hierarchy;
-	bool warned_broken_hierarchy;
-
-	/* the following two fields are initialized automtically during boot */
-	int id;
-#define MAX_CGROUP_TYPE_NAMELEN 32
-	const char *name;
-
-	/* link to parent, protected by cgroup_lock() */
-	struct cgroup_root *root;
-
-	/* idr for css->id */
-	struct idr css_idr;
-
-	/*
-	 * List of cftypes.  Each entry is the first entry of an array
-	 * terminated by zero length name.
-	 */
-	struct list_head cfts;
-
-	/*
-	 * Base cftypes which are automatically registered.  The two can
-	 * point to the same array.
-	 */
-	struct cftype *dfl_cftypes;	/* for the default hierarchy */
-	struct cftype *legacy_cftypes;	/* for the legacy hierarchies */
-
-	/*
-	 * A subsystem may depend on other subsystems.  When such subsystem
-	 * is enabled on a cgroup, the depended-upon subsystems are enabled
-	 * together if available.  Subsystems enabled due to dependency are
-	 * not visible to userland until explicitly enabled.  The following
-	 * specifies the mask of subsystems that this one depends on.
-	 */
-	unsigned int depends_on;
-};
-
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _cgrp_subsys;
 #include <linux/cgroup_subsys.h>
 #undef SUBSYS

commit f3ba53802eff25e3eedb60d7afe5262710e20bd5
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jan 6 12:02:46 2015 -0500

    cgroup: add dummy css_put() for !CONFIG_CGROUPS
    
    This will later be depended upon by the scheduled cgroup writeback
    support.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index da0dae0600e6..b9cb94c3102a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -943,6 +943,8 @@ struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
 
 #else /* !CONFIG_CGROUPS */
 
+struct cgroup_subsys_state;
+
 static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_fork(struct task_struct *p) {}
@@ -955,6 +957,8 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 	return -EINVAL;
 }
 
+static inline void css_put(struct cgroup_subsys_state *css) {}
+
 /* No cgroups - nothing to do */
 static inline int cgroup_attach_task_all(struct task_struct *from,
 					 struct task_struct *t)

commit 2756d373a3f45a3a9ebf4ac389f9e0e02bd35a93
Merge: 4e8790f77f05 eeecbd197151
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 11 18:57:19 2014 -0800

    Merge branch 'for-3.19' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup update from Tejun Heo:
     "cpuset got simplified a bit.  cgroup core got a fix on unified
      hierarchy and grew some effective css related interfaces which will be
      used for blkio support for writeback IO traffic which is currently
      being worked on"
    
    * 'for-3.19' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: implement cgroup_get_e_css()
      cgroup: add cgroup_subsys->css_e_css_changed()
      cgroup: add cgroup_subsys->css_released()
      cgroup: fix the async css offline wait logic in cgroup_subtree_control_write()
      cgroup: restructure child_subsys_mask handling in cgroup_subtree_control_write()
      cgroup: separate out cgroup_calc_child_subsys_mask() from cgroup_refresh_child_subsys_mask()
      cpuset: lock vs unlock typo
      cpuset: simplify cpuset_node_allowed API
      cpuset: convert callback_mutex to a spinlock

commit b6da0076bab5a12afb19312ffee41c95490af2a0
Merge: cbfe0de303a5 a53b83154914
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 10 18:34:42 2014 -0800

    Merge branch 'akpm' (patchbomb from Andrew)
    
    Merge first patchbomb from Andrew Morton:
     - a few minor cifs fixes
     - dma-debug upadtes
     - ocfs2
     - slab
     - about half of MM
     - procfs
     - kernel/exit.c
     - panic.c tweaks
     - printk upates
     - lib/ updates
     - checkpatch updates
     - fs/binfmt updates
     - the drivers/rtc tree
     - nilfs
     - kmod fixes
     - more kernel/exit.c
     - various other misc tweaks and fixes
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (190 commits)
      exit: pidns: fix/update the comments in zap_pid_ns_processes()
      exit: pidns: alloc_pid() leaks pid_namespace if child_reaper is exiting
      exit: exit_notify: re-use "dead" list to autoreap current
      exit: reparent: call forget_original_parent() under tasklist_lock
      exit: reparent: avoid find_new_reaper() if no children
      exit: reparent: introduce find_alive_thread()
      exit: reparent: introduce find_child_reaper()
      exit: reparent: document the ->has_child_subreaper checks
      exit: reparent: s/while_each_thread/for_each_thread/ in find_new_reaper()
      exit: reparent: fix the cross-namespace PR_SET_CHILD_SUBREAPER reparenting
      exit: reparent: fix the dead-parent PR_SET_CHILD_SUBREAPER reparenting
      exit: proc: don't try to flush /proc/tgid/task/tgid
      exit: release_task: fix the comment about group leader accounting
      exit: wait: drop tasklist_lock before psig->c* accounting
      exit: wait: don't use zombie->real_parent
      exit: wait: cleanup the ptrace_reparented() checks
      usermodehelper: kill the kmod_thread_locker logic
      usermodehelper: don't use CLONE_VFORK for ____call_usermodehelper()
      fs/hfs/catalog.c: fix comparison bug in hfs_cat_keycmp
      nilfs2: fix the nilfs_iget() vs. nilfs_new_inode() races
      ...

commit e8ea14cc6eadfe2ea63e9989e16e62625a2619f8
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Wed Dec 10 15:42:42 2014 -0800

    mm: memcontrol: take a css reference for each charged page
    
    Charges currently pin the css indirectly by playing tricks during
    css_offline(): user pages stall the offlining process until all of them
    have been reparented, whereas kmemcg acquires a keep-alive reference if
    outstanding kernel pages are detected at that point.
    
    In preparation for removing all this complexity, make the pinning explicit
    and acquire a css references for every charged page.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Vladimir Davydov <vdavydov@parallels.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1d5196889048..9f96b25965c2 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -112,6 +112,19 @@ static inline void css_get(struct cgroup_subsys_state *css)
 		percpu_ref_get(&css->refcnt);
 }
 
+/**
+ * css_get_many - obtain references on the specified css
+ * @css: target css
+ * @n: number of references to get
+ *
+ * The caller must already have a reference.
+ */
+static inline void css_get_many(struct cgroup_subsys_state *css, unsigned int n)
+{
+	if (!(css->flags & CSS_NO_REF))
+		percpu_ref_get_many(&css->refcnt, n);
+}
+
 /**
  * css_tryget - try to obtain a reference on the specified css
  * @css: target css
@@ -159,6 +172,19 @@ static inline void css_put(struct cgroup_subsys_state *css)
 		percpu_ref_put(&css->refcnt);
 }
 
+/**
+ * css_put_many - put css references
+ * @css: target css
+ * @n: number of references to put
+ *
+ * Put references obtained via css_get() and css_tryget_online().
+ */
+static inline void css_put_many(struct cgroup_subsys_state *css, unsigned int n)
+{
+	if (!(css->flags & CSS_NO_REF))
+		percpu_ref_put_many(&css->refcnt, n);
+}
+
 /* bits in struct cgroup flags field */
 enum {
 	/* Control Group requires release notifications to userspace */

commit b583043e99bc6d91e98fae32bd9eff6a5958240a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Oct 31 01:22:04 2014 -0400

    kill f_dentry uses
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1d5196889048..27b0c9105da5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -367,8 +367,8 @@ struct css_set {
  * struct cftype: handler definitions for cgroup control files
  *
  * When reading/writing to a file:
- *	- the cgroup to use is file->f_dentry->d_parent->d_fsdata
- *	- the 'cftype' of the file is file->f_dentry->d_fsdata
+ *	- the cgroup to use is file->f_path.dentry->d_parent->d_fsdata
+ *	- the 'cftype' of the file is file->f_path.dentry->d_fsdata
  */
 
 /* cftype->flags */

commit eeecbd1971517103e06f11750dd1a9a1dc37e4e6
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Nov 18 02:49:52 2014 -0500

    cgroup: implement cgroup_get_e_css()
    
    Implement cgroup_get_e_css() which finds and gets the effective css
    for the specified cgroup and subsystem combination.  This function
    always returns a valid pinned css.  This will be used by cgroup
    writeback support.
    
    While at it, add comment to cgroup_e_css() to explain why that
    function is different from cgroup_get_e_css() and has to test
    cgrp->child_subsys_mask instead of cgroup_css(cgrp, ss).
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Zefan Li <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3a04aeb8b5a1..9fd99f5e699f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -910,6 +910,8 @@ void css_task_iter_end(struct css_task_iter *it);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 
+struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgroup,
+					     struct cgroup_subsys *ss);
 struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
 						       struct cgroup_subsys *ss);
 

commit 56c807ba4e91f0980567b6a69de239677879b17f
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Nov 18 02:49:51 2014 -0500

    cgroup: add cgroup_subsys->css_e_css_changed()
    
    Add a new cgroup_subsys operatoin ->css_e_css_changed().  This is
    invoked if any of the effective csses seen from the css's cgroup may
    have changed.  This will be used to implement cgroup writeback
    support.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Zefan Li <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e717a39f22ea..3a04aeb8b5a1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -615,6 +615,7 @@ struct cgroup_subsys {
 	void (*css_released)(struct cgroup_subsys_state *css);
 	void (*css_free)(struct cgroup_subsys_state *css);
 	void (*css_reset)(struct cgroup_subsys_state *css);
+	void (*css_e_css_changed)(struct cgroup_subsys_state *css);
 
 	int (*can_attach)(struct cgroup_subsys_state *css,
 			  struct cgroup_taskset *tset);

commit 7d172cc89b8589e4173d0c73a1ddaae408f29c9d
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Nov 18 02:49:51 2014 -0500

    cgroup: add cgroup_subsys->css_released()
    
    Add a new cgroup subsys callback css_released().  This is called when
    the reference count of the css (cgroup_subsys_state) reaches zero
    before RCU scheduling free.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Zefan Li <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1d5196889048..e717a39f22ea 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -612,6 +612,7 @@ struct cgroup_subsys {
 	struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state *parent_css);
 	int (*css_online)(struct cgroup_subsys_state *css);
 	void (*css_offline)(struct cgroup_subsys_state *css);
+	void (*css_released)(struct cgroup_subsys_state *css);
 	void (*css_free)(struct cgroup_subsys_state *css);
 	void (*css_reset)(struct cgroup_subsys_state *css);
 

commit a25eb52e81a40e986179a790fbb5a1f02f482b7a
Author: Zefan Li <lizefan@huawei.com>
Date:   Fri Sep 19 16:51:00 2014 +0800

    cgroup: remove CGRP_RELEASABLE flag
    
    We call put_css_set() after setting CGRP_RELEASABLE flag in
    cgroup_task_migrate(), but in other places we call it without setting
    the flag. I don't see the necessity of this flag.
    
    Moreover once the flag is set, it will never be cleared, unless writing
    to the notify_on_release control file, so it can be quite confusing
    if we look at the output of debug.releasable.
    
      # mount -t cgroup -o debug xxx /cgroup
      # mkdir /cgroup/child
      # cat /cgroup/child/debug.releasable
      0   <-- shows 0 though the cgroup is empty
      # echo $$ > /cgroup/child/tasks
      # cat /cgroup/child/debug.releasable
      0
      # echo $$ > /cgroup/tasks && echo $$ > /cgroup/child/tasks
      # cat /proc/child/debug.releasable
      1   <-- shows 1 though the cgroup is not empty
    
    This patch removes the flag, and now debug.releasable shows if the
    cgroup is empty or not.
    
    Signed-off-by: Zefan Li <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 818a81fe7ccc..1d5196889048 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -161,11 +161,6 @@ static inline void css_put(struct cgroup_subsys_state *css)
 
 /* bits in struct cgroup flags field */
 enum {
-	/*
-	 * Control Group has previously had a child cgroup or a task,
-	 * but no longer (only if CGRP_NOTIFY_ON_RELEASE is set)
-	 */
-	CGRP_RELEASABLE,
 	/* Control Group requires release notifications to userspace */
 	CGRP_NOTIFY_ON_RELEASE,
 	/*

commit f29374b146dd02f5f99742aedaddd6ef3512fc9c
Author: Zefan Li <lizefan@huawei.com>
Date:   Fri Sep 19 16:29:31 2014 +0800

    cgroup: remove redundant check in cgroup_ino()
    
    After we implemented default unified hierarchy, cgrp->kn can never
    be NULL.
    
    Signed-off-by: Zefan Li <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 77a1d37b742b..818a81fe7ccc 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -532,13 +532,10 @@ static inline bool cgroup_has_tasks(struct cgroup *cgrp)
 	return !list_empty(&cgrp->cset_links);
 }
 
-/* returns ino associated with a cgroup, 0 indicates unmounted root */
+/* returns ino associated with a cgroup */
 static inline ino_t cgroup_ino(struct cgroup *cgrp)
 {
-	if (cgrp->kn)
-		return cgrp->kn->ino;
-	else
-		return 0;
+	return cgrp->kn->ino;
 }
 
 /* cft/css accessors for cftype->write() operation */

commit 006f4ac49742b5f70ef7e39176fd42a500144ccc
Author: Zefan Li <lizefan@huawei.com>
Date:   Thu Sep 18 16:03:15 2014 +0800

    cgroup: simplify proc_cgroup_show()
    
    Use the ONE macro instead of REG, and we can simplify proc_cgroup_show().
    
    Signed-off-by: Zefan Li <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 51958d0fb88f..77a1d37b742b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -37,7 +37,8 @@ extern void cgroup_exit(struct task_struct *p);
 extern int cgroupstats_build(struct cgroupstats *stats,
 				struct dentry *dentry);
 
-extern int proc_cgroup_show(struct seq_file *, void *);
+extern int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
+			    struct pid *pid, struct task_struct *tsk);
 
 /* define the enumeration of all cgroup subsystems */
 #define SUBSYS(_x) _x ## _cgrp_id,

commit 971ff49355387fef41d1327434d8939721a4eb35
Author: Zefan Li <lizefan@huawei.com>
Date:   Thu Sep 18 16:06:19 2014 +0800

    cgroup: use a per-cgroup work for release agent
    
    Instead of using a global work to schedule release agent on removable
    cgroups, we change to use a per-cgroup work to do this, which makes
    the code much simpler.
    
    v2: use a dedicated work instead of reusing css->destroy_work. (Tejun)
    
    Signed-off-by: Zefan Li <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f7898e0bce1e..51958d0fb88f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -233,13 +233,6 @@ struct cgroup {
 	 */
 	struct list_head e_csets[CGROUP_SUBSYS_COUNT];
 
-	/*
-	 * Linked list running through all cgroups that can
-	 * potentially be reaped by the release agent. Protected by
-	 * release_list_lock
-	 */
-	struct list_head release_list;
-
 	/*
 	 * list of pidlists, up to two for each namespace (one for procs, one
 	 * for tasks); created on demand.
@@ -249,6 +242,9 @@ struct cgroup {
 
 	/* used to wait for offlining of csses */
 	wait_queue_head_t offline_waitq;
+
+	/* used to schedule release agent */
+	struct work_struct release_agent_work;
 };
 
 #define MAX_CGROUP_ROOT_NAMELEN 64

commit 6213daab2547fdc0d02a86abf3ac209ac6881ae3
Author: Li Zefan <lizefan@huawei.com>
Date:   Wed Sep 17 18:18:09 2014 +0800

    cgroup: remove some useless forward declarations
    
    Signed-off-by: Zefan Li <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b5223c570eba..f7898e0bce1e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -27,7 +27,6 @@
 
 struct cgroup_root;
 struct cgroup_subsys;
-struct inode;
 struct cgroup;
 
 extern int cgroup_init_early(void);

commit 05ebb6e60f044a9cef2549b6204559276500f363
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 15 11:05:10 2014 -0400

    cgroup: make CFTYPE_ONLY_ON_DFL and CFTYPE_NO_ internal to cgroup core
    
    cgroup now distinguishes cftypes for the default and legacy
    hierarchies more explicitly by using separate arrays and
    CFTYPE_ONLY_ON_DFL and CFTYPE_INSANE should be and are used only
    inside cgroup core proper.  Let's make it clear that the flags are
    internal by prefixing them with double underscores.
    
    CFTYPE_INSANE is renamed to __CFTYPE_NOT_ON_DFL for consistency.  The
    two flags are also collected and assigned bits >= 16 so that they
    aren't mixed with the published flags.
    
    v2: Convert the extra ones in cgroup_exit_cftypes() which are added by
        revision to the previous patch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9f76236ac158..b5223c570eba 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -384,9 +384,11 @@ struct css_set {
 enum {
 	CFTYPE_ONLY_ON_ROOT	= (1 << 0),	/* only create on root cgrp */
 	CFTYPE_NOT_ON_ROOT	= (1 << 1),	/* don't create on root cgrp */
-	CFTYPE_INSANE		= (1 << 2),	/* don't create if sane_behavior */
 	CFTYPE_NO_PREFIX	= (1 << 3),	/* (DON'T USE FOR NEW FILES) no subsys prefix */
-	CFTYPE_ONLY_ON_DFL	= (1 << 4),	/* only on default hierarchy */
+
+	/* internal flags, do not use outside cgroup core proper */
+	__CFTYPE_ONLY_ON_DFL	= (1 << 16),	/* only on default hierarchy */
+	__CFTYPE_NOT_ON_DFL	= (1 << 17),	/* not on default hierarchy */
 };
 
 #define MAX_CFTYPE_NAME		64

commit a8ddc8215e1a4cd9dc5d6210811cfc381a489ec2
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 15 11:05:10 2014 -0400

    cgroup: distinguish the default and legacy hierarchies when handling cftypes
    
    Until now, cftype arrays carried files for both the default and legacy
    hierarchies and the files which needed to be used on only one of them
    were flagged with either CFTYPE_ONLY_ON_DFL or CFTYPE_INSANE.  This
    gets confusing very quickly and we may end up exposing interface files
    to the default hierarchy without thinking it through.
    
    This patch makes cgroup core provide separate sets of interfaces for
    cftype handling so that the cftypes for the default and legacy
    hierarchies are clearly distinguished.  The previous two patches
    renamed the existing ones so that they clearly indicate that they're
    for the legacy hierarchies.  This patch adds the interface for the
    default hierarchy and apply them selectively depending on the
    hierarchy type.
    
    * cftypes added through cgroup_subsys->dfl_cftypes and
      cgroup_add_dfl_cftypes() only show up on the default hierarchy.
    
    * cftypes added through cgroup_subsys->legacy_cftypes and
      cgroup_add_legacy_cftypes() only show up on the legacy hierarchies.
    
    * cgroup_subsys->dfl_cftypes and ->legacy_cftypes can point to the
      same array for the cases where the interface files are identical on
      both types of hierarchies.
    
    * This makes all the existing subsystem interface files legacy-only by
      default and all subsystems will have no interface file created when
      enabled on the default hierarchy.  Each subsystem should explicitly
      review and compose the interface for the default hierarchy.
    
    * A boot param "cgroup__DEVEL__legacy_files_on_dfl" is added which
      makes subsystems which haven't decided the interface files for the
      default hierarchy to present the legacy files on the default
      hierarchy so that its behavior on the default hierarchy can be
      tested.  As the awkward name suggests, this is for development only.
    
    * memcg's CFTYPE_INSANE on "use_hierarchy" is noop now as the whole
      array isn't used on the default hierarchy.  The flag is removed.
    
    v2: Updated documentation for cgroup__DEVEL__legacy_files_on_dfl.
    
    v3: Clear CFTYPE_ONLY_ON_DFL and CFTYPE_INSANE when cfts are removed
        as suggested by Li.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Aristeu Rozanski <aris@redhat.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f5f0feef2701..9f76236ac158 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -590,6 +590,7 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 
 char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
 
+int cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cftype *cfts);
 
@@ -671,8 +672,12 @@ struct cgroup_subsys {
 	 */
 	struct list_head cfts;
 
-	/* base cftypes, automatically registered with subsys itself */
-	struct cftype *legacy_cftypes;	/* used on the legacy hierarchies */
+	/*
+	 * Base cftypes which are automatically registered.  The two can
+	 * point to the same array.
+	 */
+	struct cftype *dfl_cftypes;	/* for the default hierarchy */
+	struct cftype *legacy_cftypes;	/* for the legacy hierarchies */
 
 	/*
 	 * A subsystem may depend on other subsystems.  When such subsystem

commit 2cf669a58dc08fa065a8bd0dca866c0e6cb358cc
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 15 11:05:09 2014 -0400

    cgroup: replace cgroup_add_cftypes() with cgroup_add_legacy_cftypes()
    
    Currently, cftypes added by cgroup_add_cftypes() are used for both the
    unified default hierarchy and legacy ones and subsystems can mark each
    file with either CFTYPE_ONLY_ON_DFL or CFTYPE_INSANE if it has to
    appear only on one of them.  This is quite hairy and error-prone.
    Also, we may end up exposing interface files to the default hierarchy
    without thinking it through.
    
    cgroup_subsys will grow two separate cftype addition functions and
    apply each only on the hierarchies of the matching type.  This will
    allow organizing cftypes in a lot clearer way and encourage subsystems
    to scrutinize the interface which is being exposed in the new default
    hierarchy.
    
    In preparation, this patch adds cgroup_add_legacy_cftypes() which
    currently is a simple wrapper around cgroup_add_cftypes() and replaces
    all cgroup_add_cftypes() usages with it.
    
    While at it, this patch drops a completely spurious return from
    __hugetlb_cgroup_file_init().
    
    This patch doesn't introduce any functional differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a6e9c2eeab89..f5f0feef2701 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -590,7 +590,7 @@ static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 
 char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
 
-int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
+int cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cftype *cfts);
 
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);

commit 5577964e64692e17cc498854b7e0833e6532cd64
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 15 11:05:09 2014 -0400

    cgroup: rename cgroup_subsys->base_cftypes to ->legacy_cftypes
    
    Currently, cgroup_subsys->base_cftypes is used for both the unified
    default hierarchy and legacy ones and subsystems can mark each file
    with either CFTYPE_ONLY_ON_DFL or CFTYPE_INSANE if it has to appear
    only on one of them.  This is quite hairy and error-prone.  Also, we
    may end up exposing interface files to the default hierarchy without
    thinking it through.
    
    cgroup_subsys will grow two separate cftype arrays and apply each only
    on the hierarchies of the matching type.  This will allow organizing
    cftypes in a lot clearer way and encourage subsystems to scrutinize
    the interface which is being exposed in the new default hierarchy.
    
    In preparation, this patch renames cgroup_subsys->base_cftypes to
    cgroup_subsys->legacy_cftypes.  This patch is pure rename.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Aristeu Rozanski <aris@redhat.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7bb274487c89..a6e9c2eeab89 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -672,7 +672,7 @@ struct cgroup_subsys {
 	struct list_head cfts;
 
 	/* base cftypes, automatically registered with subsys itself */
-	struct cftype *base_cftypes;
+	struct cftype *legacy_cftypes;	/* used on the legacy hierarchies */
 
 	/*
 	 * A subsystem may depend on other subsystems.  When such subsystem

commit aa6ec29bee8692ce232132f1a1ea2a1f9196610e
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jul 9 10:08:08 2014 -0400

    cgroup: remove sane_behavior support on non-default hierarchies
    
    sane_behavior has been used as a development vehicle for the default
    unified hierarchy.  Now that the default hierarchy is in place, the
    flag became redundant and confusing as its usage is allowed on all
    hierarchies.  There are gonna be either the default hierarchy or
    legacy ones.  Let's make that clear by removing sane_behavior support
    on non-default hierarchies.
    
    This patch replaces cgroup_sane_behavior() with cgroup_on_dfl().  The
    comment on top of CGRP_ROOT_SANE_BEHAVIOR is moved to on top of
    cgroup_on_dfl() with sane_behavior specific part dropped.
    
    On the default and legacy hierarchies w/o sane_behavior, this
    shouldn't cause any behavior differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c4901c19668b..7bb274487c89 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -256,68 +256,7 @@ struct cgroup {
 
 /* cgroup_root->flags */
 enum {
-	/*
-	 * Unfortunately, cgroup core and various controllers are riddled
-	 * with idiosyncrasies and pointless options.  The following flag,
-	 * when set, will force sane behavior - some options are forced on,
-	 * others are disallowed, and some controllers will change their
-	 * hierarchical or other behaviors.
-	 *
-	 * The set of behaviors affected by this flag are still being
-	 * determined and developed and the mount option for this flag is
-	 * prefixed with __DEVEL__.  The prefix will be dropped once we
-	 * reach the point where all behaviors are compatible with the
-	 * planned unified hierarchy, which will automatically turn on this
-	 * flag.
-	 *
-	 * The followings are the behaviors currently affected this flag.
-	 *
-	 * - Mount options "noprefix", "xattr", "clone_children",
-	 *   "release_agent" and "name" are disallowed.
-	 *
-	 * - When mounting an existing superblock, mount options should
-	 *   match.
-	 *
-	 * - Remount is disallowed.
-	 *
-	 * - rename(2) is disallowed.
-	 *
-	 * - "tasks" is removed.  Everything should be at process
-	 *   granularity.  Use "cgroup.procs" instead.
-	 *
-	 * - "cgroup.procs" is not sorted.  pids will be unique unless they
-	 *   got recycled inbetween reads.
-	 *
-	 * - "release_agent" and "notify_on_release" are removed.
-	 *   Replacement notification mechanism will be implemented.
-	 *
-	 * - "cgroup.clone_children" is removed.
-	 *
-	 * - "cgroup.subtree_populated" is available.  Its value is 0 if
-	 *   the cgroup and its descendants contain no task; otherwise, 1.
-	 *   The file also generates kernfs notification which can be
-	 *   monitored through poll and [di]notify when the value of the
-	 *   file changes.
-	 *
-	 * - If mount is requested with sane_behavior but without any
-	 *   subsystem, the default unified hierarchy is mounted.
-	 *
-	 * - cpuset: tasks will be kept in empty cpusets when hotplug happens
-	 *   and take masks of ancestors with non-empty cpus/mems, instead of
-	 *   being moved to an ancestor.
-	 *
-	 * - cpuset: a task can be moved into an empty cpuset, and again it
-	 *   takes masks of ancestors.
-	 *
-	 * - memcg: use_hierarchy is on by default and the cgroup file for
-	 *   the flag is not created.
-	 *
-	 * - blkcg: blk-throttle becomes properly hierarchical.
-	 *
-	 * - debug: disallowed on the default hierarchy.
-	 */
-	CGRP_ROOT_SANE_BEHAVIOR	= (1 << 0),
-
+	CGRP_ROOT_SANE_BEHAVIOR	= (1 << 0), /* __DEVEL__sane_behavior specified */
 	CGRP_ROOT_NOPREFIX	= (1 << 1), /* mounted subsystems have no named prefix */
 	CGRP_ROOT_XATTR		= (1 << 2), /* supports extended attributes */
 };
@@ -531,20 +470,64 @@ struct cftype {
 extern struct cgroup_root cgrp_dfl_root;
 extern struct css_set init_css_set;
 
+/**
+ * cgroup_on_dfl - test whether a cgroup is on the default hierarchy
+ * @cgrp: the cgroup of interest
+ *
+ * The default hierarchy is the v2 interface of cgroup and this function
+ * can be used to test whether a cgroup is on the default hierarchy for
+ * cases where a subsystem should behave differnetly depending on the
+ * interface version.
+ *
+ * The set of behaviors which change on the default hierarchy are still
+ * being determined and the mount option is prefixed with __DEVEL__.
+ *
+ * List of changed behaviors:
+ *
+ * - Mount options "noprefix", "xattr", "clone_children", "release_agent"
+ *   and "name" are disallowed.
+ *
+ * - When mounting an existing superblock, mount options should match.
+ *
+ * - Remount is disallowed.
+ *
+ * - rename(2) is disallowed.
+ *
+ * - "tasks" is removed.  Everything should be at process granularity.  Use
+ *   "cgroup.procs" instead.
+ *
+ * - "cgroup.procs" is not sorted.  pids will be unique unless they got
+ *   recycled inbetween reads.
+ *
+ * - "release_agent" and "notify_on_release" are removed.  Replacement
+ *   notification mechanism will be implemented.
+ *
+ * - "cgroup.clone_children" is removed.
+ *
+ * - "cgroup.subtree_populated" is available.  Its value is 0 if the cgroup
+ *   and its descendants contain no task; otherwise, 1.  The file also
+ *   generates kernfs notification which can be monitored through poll and
+ *   [di]notify when the value of the file changes.
+ *
+ * - cpuset: tasks will be kept in empty cpusets when hotplug happens and
+ *   take masks of ancestors with non-empty cpus/mems, instead of being
+ *   moved to an ancestor.
+ *
+ * - cpuset: a task can be moved into an empty cpuset, and again it takes
+ *   masks of ancestors.
+ *
+ * - memcg: use_hierarchy is on by default and the cgroup file for the flag
+ *   is not created.
+ *
+ * - blkcg: blk-throttle becomes properly hierarchical.
+ *
+ * - debug: disallowed on the default hierarchy.
+ */
 static inline bool cgroup_on_dfl(const struct cgroup *cgrp)
 {
 	return cgrp->root == &cgrp_dfl_root;
 }
 
-/*
- * See the comment above CGRP_ROOT_SANE_BEHAVIOR for details.  This
- * function can be called as long as @cgrp is accessible.
- */
-static inline bool cgroup_sane_behavior(const struct cgroup *cgrp)
-{
-	return cgrp->root->flags & CGRP_ROOT_SANE_BEHAVIOR;
-}
-
 /* no synchronization, the result can only be used as a hint */
 static inline bool cgroup_has_tasks(struct cgroup *cgrp)
 {

commit 7450e90bbb8d834c190cc8100d1cc41888358c7c
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jul 9 10:08:07 2014 -0400

    cgroup: remove CGRP_ROOT_OPTION_MASK
    
    cgroup_root->flags only contains CGRP_ROOT_* flags and there's no
    reason to mask the flags.  Remove CGRP_ROOT_OPTION_MASK.
    
    This doesn't cause any behavior differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 28853e771f3b..c4901c19668b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -320,9 +320,6 @@ enum {
 
 	CGRP_ROOT_NOPREFIX	= (1 << 1), /* mounted subsystems have no named prefix */
 	CGRP_ROOT_XATTR		= (1 << 2), /* supports extended attributes */
-
-	/* mount options live below bit 16 */
-	CGRP_ROOT_OPTION_MASK	= (1 << 16) - 1,
 };
 
 /*

commit af0ba6789c8e43518635606d0af1ff475ba7471a
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 8 18:02:57 2014 -0400

    cgroup: implement cgroup_subsys->depends_on
    
    Currently, the blkio subsystem attributes all of writeback IOs to the
    root.  One of the issues is that there's no way to tell who originated
    a writeback IO from block layer.  Those IOs are usually issued
    asynchronously from a task which didn't have anything to do with
    actually generating the dirty pages.  The memory subsystem, when
    enabled, already keeps track of the ownership of each dirty page and
    it's desirable for blkio to piggyback instead of adding its own
    per-page tag.
    
    blkio piggybacking on memory is an implementation detail which
    preferably should be handled automatically without requiring explicit
    userland action.  To achieve that, this patch implements
    cgroup_subsys->depends_on which contains the mask of subsystems which
    should be enabled together when the subsystem is enabled.
    
    The previous patches already implemented the support for enabled but
    invisible subsystems and cgroup_subsys->depends_on can be easily
    implemented by updating cgroup_refresh_child_subsys_mask() so that it
    calculates cgroup->child_subsys_mask considering
    cgroup_subsys->depends_on of the explicitly enabled subsystems.
    
    Documentation/cgroups/unified-hierarchy.txt is updated to explain that
    subsystems may not become immediately available after being unused
    from userland and that dependency could be a factor in it.  As
    subsystems may already keep residual references, this doesn't
    significantly change how subsystem rebinding can be used.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index db99e3b923b1..28853e771f3b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -693,6 +693,15 @@ struct cgroup_subsys {
 
 	/* base cftypes, automatically registered with subsys itself */
 	struct cftype *base_cftypes;
+
+	/*
+	 * A subsystem may depend on other subsystems.  When such subsystem
+	 * is enabled on a cgroup, the depended-upon subsystems are enabled
+	 * together if available.  Subsystems enabled due to dependency are
+	 * not visible to userland until explicitly enabled.  The following
+	 * specifies the mask of subsystems that this one depends on.
+	 */
+	unsigned int depends_on;
 };
 
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _cgrp_subsys;

commit b4536f0cab2b18414e26101a2b9d484c5cbea0c0
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 8 18:02:57 2014 -0400

    cgroup: implement cgroup_subsys->css_reset()
    
    cgroup is implementing support for subsystem dependency which would
    require a way to enable a subsystem even when it's not directly
    configured through "cgroup.subtree_control".
    
    The previous patches added support for explicitly and implicitly
    enabled subsystems and showing/hiding their interface files.  An
    explicitly enabled subsystem may become implicitly enabled if it's
    turned off through "cgroup.subtree_control" but there are subsystems
    depending on it.  In such cases, the subsystem, as it's turned off
    when seen from userland, shouldn't enforce any resource control.
    Also, the subsystem may be explicitly turned on later again and its
    interface files should be as close to the intial state as possible.
    
    This patch adds cgroup_subsys->css_reset() which is invoked when a css
    is hidden.  The callback should disable resource control and reset the
    state to the vanilla state.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5287f931680a..db99e3b923b1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -642,6 +642,7 @@ struct cgroup_subsys {
 	int (*css_online)(struct cgroup_subsys_state *css);
 	void (*css_offline)(struct cgroup_subsys_state *css);
 	void (*css_free)(struct cgroup_subsys_state *css);
+	void (*css_reset)(struct cgroup_subsys_state *css);
 
 	int (*can_attach)(struct cgroup_subsys_state *css,
 			  struct cgroup_taskset *tset);

commit f63070d350e3562baa6196f1043e01cd8da2509a
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 8 18:02:57 2014 -0400

    cgroup: make interface files visible iff enabled on cgroup->subtree_control
    
    cgroup is implementing support for subsystem dependency which would
    require a way to enable a subsystem even when it's not directly
    configured through "cgroup.subtree_control".
    
    The preceding patch distinguished cgroup->subtree_control and
    ->child_subsys_mask where the former is the subsystems explicitly
    configured by the userland and the latter is all enabled subsystems
    currently is equal to the former but will include subsystems
    implicitly enabled through dependency.
    
    Subsystems which are enabled due to dependency shouldn't be visible to
    userland.  This patch updates cgroup_subtree_control_write() and
    create_css() such that interface files are not created for implicitly
    enabled subsytems.
    
    * @visible paramter is added to create_css().  Interface files are
      created only when true.
    
    * If an already implicitly enabled subsystem is turned on through
      "cgroup.subtree_control", the existing css should be used.  css
      draining is skipped.
    
    * cgroup_subtree_control_write() computes the new target
      cgroup->child_subsys_mask and create/kill or show/hide csses
      accordingly.
    
    As the two subsystem masks are still kept identical, this patch
    doesn't introduce any behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8d52c8e5b510..5287f931680a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -208,6 +208,8 @@ struct cgroup {
 	 * ->subtree_control is the one configured through
 	 * "cgroup.subtree_control" while ->child_subsys_mask is the
 	 * effective one which may have more subsystems enabled.
+	 * Controller knobs are made available iff it's enabled in
+	 * ->subtree_control.
 	 */
 	unsigned int subtree_control;
 	unsigned int child_subsys_mask;

commit 667c24917144e34880f821486bf0a6e4d05a3a14
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 8 18:02:56 2014 -0400

    cgroup: introduce cgroup->subtree_control
    
    cgroup is implementing support for subsystem dependency which would
    require a way to enable a subsystem even when it's not directly
    configured through "cgroup.subtree_control".
    
    Previously, cgroup->child_subsys_mask directly reflected
    "cgroup.subtree_control" and the enabled subsystems in the child
    cgroups.  This patch adds cgroup->subtree_control which
    "cgroup.subtree_control" operates on.  cgroup->child_subsys_mask is
    now calculated from cgroup->subtree_control by
    cgroup_refresh_child_subsys_mask(), which sets it identical to
    cgroup->subtree_control for now.
    
    This will allow using cgroup->child_subsys_mask for all the enabled
    subsystems including the implicit ones and ->subtree_control for
    tracking the explicitly requested ones.  This patch keeps the two
    masks identical and doesn't introduce any behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8a111dd42d7a..8d52c8e5b510 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -203,7 +203,13 @@ struct cgroup {
 	struct kernfs_node *kn;		/* cgroup kernfs entry */
 	struct kernfs_node *populated_kn; /* kn for "cgroup.subtree_populated" */
 
-	/* the bitmask of subsystems enabled on the child cgroups */
+	/*
+	 * The bitmask of subsystems enabled on the child cgroups.
+	 * ->subtree_control is the one configured through
+	 * "cgroup.subtree_control" while ->child_subsys_mask is the
+	 * effective one which may have more subsystems enabled.
+	 */
+	unsigned int subtree_control;
 	unsigned int child_subsys_mask;
 
 	/* Private pointers for each registered subsystem */

commit 5533e0114425dcdb878f11b291f2727af8667a7c
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 14 19:33:07 2014 -0400

    cgroup: disallow debug controller on the default hierarchy
    
    The debug controller, as its name suggests, exposes cgroup core
    internals to userland to aid debugging.  Unfortunately, except for the
    name, there's no provision to prevent its usage in production
    configurations and the controller is widely enabled and mounted
    leaking internal details to userland.  Like most other debug
    information, the information exposed by debug isn't interesting even
    for debugging itself once the related parts are working reliably.
    
    This controller has no reason for existing.  This patch implements
    cgrp_dfl_root_inhibit_ss_mask which can suppress specific subsystems
    on the default hierarchy and adds the debug subsystem to it so that it
    can be gradually deprecated as usages move towards the unified
    hierarchy.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4afe544d3547..8a111dd42d7a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -305,6 +305,8 @@ enum {
 	 *   the flag is not created.
 	 *
 	 * - blkcg: blk-throttle becomes properly hierarchical.
+	 *
+	 * - debug: disallowed on the default hierarchy.
 	 */
 	CGRP_ROOT_SANE_BEHAVIOR	= (1 << 0),
 

commit 6f4524d355a86769b65d5420a6ef47fb0bba9b72
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:52 2014 -0400

    cgroup: implement css_tryget()
    
    Implement css_tryget() which tries to grab a cgroup_subsys_state's
    reference as long as it already hasn't reached zero.  Combined with
    the recent css iterator changes to include offline && !released csses
    during traversal, this can be used to access csses regardless of its
    online state.
    
    v2: Take the new flag CSS_NO_REF into account.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b76999954beb..4afe544d3547 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -112,6 +112,24 @@ static inline void css_get(struct cgroup_subsys_state *css)
 		percpu_ref_get(&css->refcnt);
 }
 
+/**
+ * css_tryget - try to obtain a reference on the specified css
+ * @css: target css
+ *
+ * Obtain a reference on @css unless it already has reached zero and is
+ * being released.  This function doesn't care whether @css is on or
+ * offline.  The caller naturally needs to ensure that @css is accessible
+ * but doesn't have to be holding a reference on it - IOW, RCU protected
+ * access is good enough for this function.  Returns %true if a reference
+ * count was successfully obtained; %false otherwise.
+ */
+static inline bool css_tryget(struct cgroup_subsys_state *css)
+{
+	if (!(css->flags & CSS_NO_REF))
+		return percpu_ref_tryget(&css->refcnt);
+	return true;
+}
+
 /**
  * css_tryget_online - try to obtain a reference on the specified css if online
  * @css: target css

commit f3d4650015301d1c880df4523f7e7ef320a38aab
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:52 2014 -0400

    cgroup: convert cgroup_has_live_children() into css_has_online_children()
    
    Now that cgroup liveliness and css onliness are the same state,
    convert cgroup_has_live_children() into css_has_online_children() so
    that it can be used for actual csses too.  The function now uses
    css_for_each_child() for iteration and is published.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 51a339c99eb6..b76999954beb 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -873,6 +873,8 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\
 	     (pos) = css_next_descendant_post((pos), (css)))
 
+bool css_has_online_children(struct cgroup_subsys_state *css);
+
 /* A css_task_iter should be treated as an opaque object */
 struct css_task_iter {
 	struct cgroup_subsys		*ss;

commit 184faf32328c65c9d86b19577b8d8b90bdd2cd2e
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:51 2014 -0400

    cgroup: use CSS_ONLINE instead of CGRP_DEAD
    
    Use CSS_ONLINE on the self css to indicate whether a cgroup has been
    killed instead of CGRP_DEAD.  This will allow re-using css online test
    for cgroup liveliness test.  This doesn't introduce any functional
    change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f2ff578fc03a..51a339c99eb6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -143,8 +143,6 @@ static inline void css_put(struct cgroup_subsys_state *css)
 
 /* bits in struct cgroup flags field */
 enum {
-	/* Control Group is dead */
-	CGRP_DEAD,
 	/*
 	 * Control Group has previously had a child cgroup or a task,
 	 * but no longer (only if CGRP_NOTIFY_ON_RELEASE is set)

commit c2931b70a32c705b9bd5762f5044f9eac8a52bb3
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:51 2014 -0400

    cgroup: iterate cgroup_subsys_states directly
    
    Currently, css_next_child() is implemented as finding the next child
    cgroup which has the css enabled, which used to be the only way to do
    it as only cgroups participated in sibling lists and thus could be
    iteratd.  This works as long as what's required during iteration is
    not missing online csses; however, it turns out that there are use
    cases where offlined but not yet released csses need to be iterated.
    This is difficult to implement through cgroup iteration the unified
    hierarchy as there may be multiple dying csses for the same subsystem
    associated with single cgroup.
    
    After the recent changes, the cgroup self and regular csses behave
    identically in how they're linked and unlinked from the sibling lists
    including assertion of CSS_RELEASED and css_next_child() can simply
    switch to iterating csses directly.  This both simplifies the logic
    and ensures that all visible non-released csses are included in the
    iteration whether there are multiple dying csses for a subsystem or
    not.
    
    As all other iterators depend on css_next_child() for sibling
    iteration, this changes behaviors of all css iterators.  Add and
    update explanations on the css states which are included in traversal
    to all iterators.
    
    As css iteration could always contain offlined csses, this shouldn't
    break any of the current users and new usages which need iteration of
    all on and offline csses can make use of the new semantics.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5375582ea5f6..f2ff578fc03a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -764,14 +764,14 @@ struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
  * @pos: the css * to use as the loop cursor
  * @parent: css whose children to walk
  *
- * Walk @parent's children.  Must be called under rcu_read_lock().  A child
- * css which hasn't finished ->css_online() or already has finished
- * ->css_offline() may show up during traversal and it's each subsystem's
- * responsibility to verify that each @pos is alive.
+ * Walk @parent's children.  Must be called under rcu_read_lock().
  *
- * If a subsystem synchronizes against the parent in its ->css_online() and
- * before starting iterating, a css which finished ->css_online() is
- * guaranteed to be visible in the future iterations.
+ * If a subsystem synchronizes ->css_online() and the start of iteration, a
+ * css which finished ->css_online() is guaranteed to be visible in the
+ * future iterations and will stay visible until the last reference is put.
+ * A css which hasn't finished ->css_online() or already finished
+ * ->css_offline() may show up during traversal.  It's each subsystem's
+ * responsibility to synchronize against on/offlining.
  *
  * It is allowed to temporarily drop RCU read lock during iteration.  The
  * caller is responsible for ensuring that @pos remains accessible until
@@ -794,17 +794,16 @@ css_rightmost_descendant(struct cgroup_subsys_state *pos);
  * @root: css whose descendants to walk
  *
  * Walk @root's descendants.  @root is included in the iteration and the
- * first node to be visited.  Must be called under rcu_read_lock().  A
- * descendant css which hasn't finished ->css_online() or already has
- * finished ->css_offline() may show up during traversal and it's each
- * subsystem's responsibility to verify that each @pos is alive.
+ * first node to be visited.  Must be called under rcu_read_lock().
  *
- * If a subsystem synchronizes against the parent in its ->css_online() and
- * before starting iterating, and synchronizes against @pos on each
- * iteration, any descendant css which finished ->css_online() is
- * guaranteed to be visible in the future iterations.
+ * If a subsystem synchronizes ->css_online() and the start of iteration, a
+ * css which finished ->css_online() is guaranteed to be visible in the
+ * future iterations and will stay visible until the last reference is put.
+ * A css which hasn't finished ->css_online() or already finished
+ * ->css_offline() may show up during traversal.  It's each subsystem's
+ * responsibility to synchronize against on/offlining.
  *
- * In other words, the following guarantees that a descendant can't escape
+ * For example, the following guarantees that a descendant can't escape
  * state updates of its ancestors.
  *
  * my_online(@css)
@@ -860,8 +859,17 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
  *
  * Similar to css_for_each_descendant_pre() but performs post-order
  * traversal instead.  @root is included in the iteration and the last
- * node to be visited.  Note that the walk visibility guarantee described
- * in pre-order walk doesn't apply the same to post-order walks.
+ * node to be visited.
+ *
+ * If a subsystem synchronizes ->css_online() and the start of iteration, a
+ * css which finished ->css_online() is guaranteed to be visible in the
+ * future iterations and will stay visible until the last reference is put.
+ * A css which hasn't finished ->css_online() or already finished
+ * ->css_offline() may show up during traversal.  It's each subsystem's
+ * responsibility to synchronize against on/offlining.
+ *
+ * Note that the walk visibility guarantee example described in pre-order
+ * walk doesn't apply the same to post-order walks.
  */
 #define css_for_each_descendant_post(pos, css)				\
 	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\

commit de3f034182ecbf0efbcef7ab8b253c6c3049a592
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:49 2014 -0400

    cgroup: introduce CSS_RELEASED and reduce css iteration fallback window
    
    css iterations allow the caller to drop RCU read lock.  As long as the
    caller keeps the current position accessible, it can simply re-grab
    RCU read lock later and continue iteration.  This is achieved by using
    CGRP_DEAD to detect whether the current positions next pointer is safe
    to dereference and if not re-iterate from the beginning to the next
    position using ->serial_nr.
    
    CGRP_DEAD is used as the marker to invalidate the next pointer and the
    only requirement is that the marker is set before the next sibling
    starts its RCU grace period.  Because CGRP_DEAD is set at the end of
    cgroup_destroy_locked() but the cgroup is unlinked when the reference
    count reaches zero, we currently have a rather large window where this
    fallback re-iteration logic can be triggered.
    
    This patch introduces CSS_RELEASED which is set when a css is unlinked
    from its sibling list.  This still keeps the re-iteration logic
    working while drastically reducing the window of its activation.
    While at it, rewrite the comment in css_next_child() to reflect the
    new flag and better explain the synchronization.
    
    This will also enable iterating csses directly instead of through
    cgroups.
    
    v2: CSS_RELEASED now assigned to 1 << 2 as 1 << 0 is used by
        CSS_NO_REF.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ebe7ce49f4b7..5375582ea5f6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -97,6 +97,7 @@ struct cgroup_subsys_state {
 enum {
 	CSS_NO_REF	= (1 << 0), /* no reference counting for this css */
 	CSS_ONLINE	= (1 << 1), /* between ->css_online() and ->css_offline() */
+	CSS_RELEASED	= (1 << 2), /* refcnt reached zero, released */
 };
 
 /**

commit 0cb51d71c1fa9234afe4213089844be76ec1765a
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:49 2014 -0400

    cgroup: move cgroup->serial_nr into cgroup_subsys_state
    
    We're moving towards using cgroup_subsys_states as the fundamental
    structural blocks.  All csses including the cgroup->self and actual
    ones now form trees through css->children and ->sibling which follow
    the same rules as what cgroup->children and ->sibling followed.  This
    patch moves cgroup->serial_nr which is used to implement css iteration
    into css.
    
    Note that all csses, regardless of their types, allocate their serial
    numbers from the same monotonically increasing counter.  This doesn't
    affect the ordering needed by css iteration or cause any other
    material behavior changes.  This will be used to update css iteration.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cf8ba26b7c6e..ebe7ce49f4b7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -80,6 +80,14 @@ struct cgroup_subsys_state {
 
 	unsigned int flags;
 
+	/*
+	 * Monotonically increasing unique serial number which defines a
+	 * uniform order among all csses.  It's guaranteed that all
+	 * ->children lists are in the ascending order of ->serial_nr and
+	 * used to allow interrupting and resuming iterations.
+	 */
+	u64 serial_nr;
+
 	/* percpu_ref killing and RCU release */
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
@@ -178,14 +186,6 @@ struct cgroup {
 	struct kernfs_node *kn;		/* cgroup kernfs entry */
 	struct kernfs_node *populated_kn; /* kn for "cgroup.subtree_populated" */
 
-	/*
-	 * Monotonically increasing unique serial number which defines a
-	 * uniform order among all cgroups.  It's guaranteed that all
-	 * ->children lists are in the ascending order of ->serial_nr.
-	 * It's used to allow interrupting and resuming iterations.
-	 */
-	u64 serial_nr;
-
 	/* the bitmask of subsystems enabled on the child cgroups */
 	unsigned int child_subsys_mask;
 

commit d5c419b68e368fdd9f1857bf8d4bb4480edb9b80
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:48 2014 -0400

    cgroup: move cgroup->sibling and ->children into cgroup_subsys_state
    
    We're moving towards using cgroup_subsys_states as the fundamental
    structural blocks.  Let's move cgroup->sibling and ->children into
    cgroup_subsys_state.  This is pure move without functional change and
    only cgroup->self's fields are actually used.  Other csses will make
    use of the fields later.
    
    While at it, update init_and_link_css() so that it zeroes the whole
    css before initializing it and remove explicit zeroing of ->flags.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index fd538f4c2bb6..cf8ba26b7c6e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -68,6 +68,10 @@ struct cgroup_subsys_state {
 	/* PI: the parent css */
 	struct cgroup_subsys_state *parent;
 
+	/* siblings list anchored at the parent's ->children */
+	struct list_head sibling;
+	struct list_head children;
+
 	/*
 	 * PI: Subsys-unique ID.  0 is unused and root is always 1.  The
 	 * matching css can be looked up using css_from_id().
@@ -171,13 +175,6 @@ struct cgroup {
 	 */
 	int populated_cnt;
 
-	/*
-	 * We link our 'sibling' struct into our parent's 'children'.
-	 * Our children link their 'sibling' into our 'children'.
-	 */
-	struct list_head sibling;	/* my parent's children */
-	struct list_head children;	/* my children */
-
 	struct kernfs_node *kn;		/* cgroup kernfs entry */
 	struct kernfs_node *populated_kn; /* kn for "cgroup.subtree_populated" */
 

commit d51f39b05ce0008118c45945e681b20484990571
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:48 2014 -0400

    cgroup: remove cgroup->parent
    
    cgroup->parent is redundant as cgroup->self.parent can also be used to
    determine the parent cgroup and we're moving towards using
    cgroup_subsys_states as the fundamental structural blocks.  This patch
    introduces cgroup_parent() which follows cgroup->self.parent and
    removes cgroup->parent.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 2549493d518d..fd538f4c2bb6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -178,7 +178,6 @@ struct cgroup {
 	struct list_head sibling;	/* my parent's children */
 	struct list_head children;	/* my children */
 
-	struct cgroup *parent;		/* my parent */
 	struct kernfs_node *kn;		/* cgroup kernfs entry */
 	struct kernfs_node *populated_kn; /* kn for "cgroup.subtree_populated" */
 

commit 5c9d535b893f30266ea29fe377cb9b002fcd76aa
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:48 2014 -0400

    cgroup: remove css_parent()
    
    cgroup in general is moving towards using cgroup_subsys_state as the
    fundamental structural component and css_parent() was introduced to
    convert from using cgroup->parent to css->parent.  It was quite some
    time ago and we're moving forward with making css more prominent.
    
    This patch drops the trivial wrapper css_parent() and let the users
    dereference css->parent.  While at it, explicitly mark fields of css
    which are public and immutable.
    
    v2: New usage from device_cgroup.c converted.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: "David S. Miller" <davem@davemloft.net>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1737db0c63fe..2549493d518d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -48,22 +48,28 @@ enum cgroup_subsys_id {
 };
 #undef SUBSYS
 
-/* Per-subsystem/per-cgroup state maintained by the system. */
+/*
+ * Per-subsystem/per-cgroup state maintained by the system.  This is the
+ * fundamental structural building block that controllers deal with.
+ *
+ * Fields marked with "PI:" are public and immutable and may be accessed
+ * directly without synchronization.
+ */
 struct cgroup_subsys_state {
-	/* the cgroup that this css is attached to */
+	/* PI: the cgroup that this css is attached to */
 	struct cgroup *cgroup;
 
-	/* the cgroup subsystem that this css is attached to */
+	/* PI: the cgroup subsystem that this css is attached to */
 	struct cgroup_subsys *ss;
 
 	/* reference count - access via css_[try]get() and css_put() */
 	struct percpu_ref refcnt;
 
-	/* the parent css */
+	/* PI: the parent css */
 	struct cgroup_subsys_state *parent;
 
 	/*
-	 * Subsys-unique ID.  0 is unused and root is always 1.  The
+	 * PI: Subsys-unique ID.  0 is unused and root is always 1.  The
 	 * matching css can be looked up using css_from_id().
 	 */
 	int id;
@@ -669,19 +675,6 @@ struct cgroup_subsys {
 #include <linux/cgroup_subsys.h>
 #undef SUBSYS
 
-/**
- * css_parent - find the parent css
- * @css: the target cgroup_subsys_state
- *
- * Return the parent css of @css.  This function is guaranteed to return
- * non-NULL parent as long as @css isn't the root.
- */
-static inline
-struct cgroup_subsys_state *css_parent(struct cgroup_subsys_state *css)
-{
-	return css->parent;
-}
-
 /**
  * task_css_set_check - obtain a task's css_set with extra access conditions
  * @task: the task to obtain css_set for

commit 3b514d24e200fcdcde0a57c354a51d3677a86743
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 16 13:22:47 2014 -0400

    cgroup: skip refcnting on normal root csses and cgrp_dfl_root self css
    
    9395a4500404 ("cgroup: enable refcnting for root csses") enabled
    reference counting for root csses (cgroup_subsys_states) so that
    cgroup's self csses can be used to manage the lifetime of the
    containing cgroups.
    
    Unfortunately, this change was incorrect.  During early init,
    cgrp_dfl_root self css refcnt is used.  percpu_ref can't initialized
    during early init and its initialization is deferred till
    cgroup_init() time.  This means that cpu was using percpu_ref which
    wasn't properly initialized.  Due to the way percpu variables are laid
    out on x86, this didn't blow up immediately on x86 but ended up
    incrementing and decrementing the percpu variable at offset zero,
    whatever it may be; however, on other archs, this caused fault and
    early boot failure.
    
    As cgroup self csses for root cgroups of non-dfl hierarchies need
    working refcounting, we can't revert 9395a4500404.  This patch adds
    CSS_NO_REF which explicitly inhibits reference counting on the css and
    sets it on all normal (non-self) csses and cgroup_dfl_root self css.
    
    v2: cgrp_dfl_root.self is the offending one.  Set the flag on it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Stephen Warren <swarren@nvidia.com>
    Tested-by: Stephen Warren <swarren@nvidia.com>
    Fixes: 9395a4500404 ("cgroup: enable refcnting for root csses")

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 76dadd77a120..1737db0c63fe 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -77,6 +77,7 @@ struct cgroup_subsys_state {
 
 /* bits in struct cgroup_subsys_state flags field */
 enum {
+	CSS_NO_REF	= (1 << 0), /* no reference counting for this css */
 	CSS_ONLINE	= (1 << 1), /* between ->css_online() and ->css_offline() */
 };
 
@@ -88,7 +89,8 @@ enum {
  */
 static inline void css_get(struct cgroup_subsys_state *css)
 {
-	percpu_ref_get(&css->refcnt);
+	if (!(css->flags & CSS_NO_REF))
+		percpu_ref_get(&css->refcnt);
 }
 
 /**
@@ -103,7 +105,9 @@ static inline void css_get(struct cgroup_subsys_state *css)
  */
 static inline bool css_tryget_online(struct cgroup_subsys_state *css)
 {
-	return percpu_ref_tryget_live(&css->refcnt);
+	if (!(css->flags & CSS_NO_REF))
+		return percpu_ref_tryget_live(&css->refcnt);
+	return true;
 }
 
 /**
@@ -114,7 +118,8 @@ static inline bool css_tryget_online(struct cgroup_subsys_state *css)
  */
 static inline void css_put(struct cgroup_subsys_state *css)
 {
-	percpu_ref_put(&css->refcnt);
+	if (!(css->flags & CSS_NO_REF))
+		percpu_ref_put(&css->refcnt);
 }
 
 /* bits in struct cgroup flags field */

commit 9d755d33f0db8c9b49438f71b38a56e375b34360
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 14 09:15:02 2014 -0400

    cgroup: use cgroup->self.refcnt for cgroup refcnting
    
    Currently cgroup implements refcnting separately using atomic_t
    cgroup->refcnt.  The destruction paths of cgroup and css are rather
    complex and bear a lot of similiarities including the use of RCU and
    bouncing to a work item.
    
    This patch makes cgroup use the refcnt of self css for refcnting
    instead of using its own.  This makes cgroup refcnting use css's
    percpu refcnt and share the destruction mechanism.
    
    * css_release_work_fn() and css_free_work_fn() are updated to handle
      both csses and cgroups.  This is a bit messy but should do until we
      can make cgroup->self a full css, which currently can't be done
      thanks to multiple hierarchies.
    
    * cgroup_destroy_locked() now performs
      percpu_ref_kill(&cgrp->self.refcnt) instead of cgroup_put(cgrp).
    
    * Negative refcnt sanity check in cgroup_get() is no longer necessary
      as percpu_ref already handles it.
    
    * Similarly, as a cgroup which hasn't been killed will never be
      released regardless of its refcnt value and percpu_ref has sanity
      check on kill, cgroup_is_dead() sanity check in cgroup_put() is no
      longer necessary.
    
    * As whether a refcnt reached zero or not can only be decided after
      the reference count is killed, cgroup_root->cgrp's refcnting can no
      longer be used to decide whether to kill the root or not.  Let's
      make cgroup_kill_sb() explicitly initiate destruction if the root
      doesn't have any children.  This makes sense anyway as unmounted
      cgroup hierarchy without any children should be destroyed.
    
    While this is a bit messy, this will allow pushing more bookkeeping
    towards cgroup->self and thus handling cgroups and csses in more
    uniform way.  In the very long term, it should be possible to
    introduce a base subsystem and convert the self css to a proper one
    making things whole lot simpler and unified.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 286e39e4e9bf..76dadd77a120 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -160,8 +160,6 @@ struct cgroup {
 	 */
 	int populated_cnt;
 
-	atomic_t refcnt;
-
 	/*
 	 * We link our 'sibling' struct into our parent's 'children'.
 	 * Our children link their 'sibling' into our 'children'.
@@ -218,10 +216,6 @@ struct cgroup {
 	struct list_head pidlists;
 	struct mutex pidlist_mutex;
 
-	/* For css percpu_ref killing and RCU-protected deletion */
-	struct rcu_head rcu_head;
-	struct work_struct destroy_work;
-
 	/* used to wait for offlining of csses */
 	wait_queue_head_t offline_waitq;
 };

commit 9395a4500404e05173eda9a2d198b6fa500e90c5
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 14 09:15:02 2014 -0400

    cgroup: enable refcnting for root csses
    
    Currently, css_get(), css_tryget() and css_tryget_online() are noops
    for root csses as an optimization; however, we're planning to use css
    refcnts to track of cgroup lifetime too and root cgroups also need to
    be reference counted.  Since css has been converted to percpu_refcnt,
    the overhead of refcnting is miniscule and this optimization isn't too
    meaningful anymore.  Furthermore, controllers which optimize the root
    cgroup often never even invoke these functions in their hot paths.
    
    This patch enables refcnting for root csses too.  This makes CSS_ROOT
    flag unused and removes it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 160fcc69149e..286e39e4e9bf 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -77,7 +77,6 @@ struct cgroup_subsys_state {
 
 /* bits in struct cgroup_subsys_state flags field */
 enum {
-	CSS_ROOT	= (1 << 0), /* this CSS is the root of the subsystem */
 	CSS_ONLINE	= (1 << 1), /* between ->css_online() and ->css_offline() */
 };
 
@@ -89,9 +88,7 @@ enum {
  */
 static inline void css_get(struct cgroup_subsys_state *css)
 {
-	/* We don't need to reference count the root state */
-	if (!(css->flags & CSS_ROOT))
-		percpu_ref_get(&css->refcnt);
+	percpu_ref_get(&css->refcnt);
 }
 
 /**
@@ -106,8 +103,6 @@ static inline void css_get(struct cgroup_subsys_state *css)
  */
 static inline bool css_tryget_online(struct cgroup_subsys_state *css)
 {
-	if (css->flags & CSS_ROOT)
-		return true;
 	return percpu_ref_tryget_live(&css->refcnt);
 }
 
@@ -119,8 +114,7 @@ static inline bool css_tryget_online(struct cgroup_subsys_state *css)
  */
 static inline void css_put(struct cgroup_subsys_state *css)
 {
-	if (!(css->flags & CSS_ROOT))
-		percpu_ref_put(&css->refcnt);
+	percpu_ref_put(&css->refcnt);
 }
 
 /* bits in struct cgroup flags field */

commit 249f3468a282dcbad53484c821bebb447f14ee03
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 14 09:15:01 2014 -0400

    cgroup: remove cgroup_destory_css_killed()
    
    cgroup_destroy_css_killed() is cgroup destruction stage which happens
    after all csses are offlined.  After the recent updates, it no longer
    does anything other than putting the base reference.  This patch
    removes the function and makes cgroup_destroy_locked() put the base
    ref at the end isntead.
    
    This also makes cgroup->nr_css unnecessary.  Removed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 164851e388e7..160fcc69149e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -158,9 +158,6 @@ struct cgroup {
 	 */
 	int id;
 
-	/* the number of attached css's */
-	int nr_css;
-
 	/*
 	 * If this cgroup contains any tasks, it contributes one to
 	 * populated_cnt.  All children with non-zero popuplated_cnt of

commit 9d800df12d31734a6853915e9d2deb5d6747985f
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 14 09:15:00 2014 -0400

    cgroup: rename cgroup->dummy_css to ->self and move it to the top
    
    cgroup->dummy_css is used as the placeholder css when performing css
    oriended operations on the cgroup.  We're gonna shift more cgroup
    management to this css.  Let's rename it to ->self and move it to the
    top.
    
    This is pure rename and field relocation.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index aa7353deaaf3..164851e388e7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -143,6 +143,9 @@ enum {
 };
 
 struct cgroup {
+	/* self css with NULL ->ss, points back to this cgroup */
+	struct cgroup_subsys_state self;
+
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
 	/*
@@ -224,9 +227,6 @@ struct cgroup {
 	struct list_head pidlists;
 	struct mutex pidlist_mutex;
 
-	/* dummy css with NULL ->ss, points back to this cgroup */
-	struct cgroup_subsys_state dummy_css;
-
 	/* For css percpu_ref killing and RCU-protected deletion */
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;

commit b7fc5ad235936379fae67a9f7b50bb53487a1a3a
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 12:16:22 2014 -0400

    cgroup: remove cgroup->control_kn
    
    Now that cgroup_subtree_control_write() has access to the associated
    kernfs_open_file and thus the kernfs_node, there's no need to cache it
    in cgroup->control_kn on creation.  Remove cgroup->control_kn and use
    @of->kn directly.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 08eb71ee600b..aa7353deaaf3 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -177,7 +177,6 @@ struct cgroup {
 
 	struct cgroup *parent;		/* my parent */
 	struct kernfs_node *kn;		/* cgroup kernfs entry */
-	struct kernfs_node *control_kn;	/* kn for "cgroup.subtree_control" */
 	struct kernfs_node *populated_kn; /* kn for "cgroup.subtree_populated" */
 
 	/*

commit 6770c64e5c8da4705d1f0973bdeb5c2bf4f3a404
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 12:16:21 2014 -0400

    cgroup: replace cftype->trigger() with cftype->write()
    
    cftype->trigger() is pointless.  It's trivial to ignore the input
    buffer from a regular ->write() operation.  Convert all ->trigger()
    users to ->write() and remove ->trigger().
    
    This patch doesn't introduce any visible behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index aecdc84fe128..08eb71ee600b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -499,14 +499,6 @@ struct cftype {
 	int (*write_s64)(struct cgroup_subsys_state *css, struct cftype *cft,
 			 s64 val);
 
-	/*
-	 * trigger() callback can be used to get some kick from the
-	 * userspace, when the actual string written is not important
-	 * at all. The private field can be used to determine the
-	 * kick type for multiplexing.
-	 */
-	int (*trigger)(struct cgroup_subsys_state *css, unsigned int event);
-
 	/*
 	 * write() is the generic write callback which maps directly to
 	 * kernfs write operation and overrides all other operations.

commit 451af504df0c62f695a69b83c250486e77c66378
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 12:16:21 2014 -0400

    cgroup: replace cftype->write_string() with cftype->write()
    
    Convert all cftype->write_string() users to the new cftype->write()
    which maps directly to kernfs write operation and has full access to
    kernfs and cgroup contexts.  The conversions are mostly mechanical.
    
    * @css and @cft are accessed using of_css() and of_cft() accessors
      respectively instead of being specified as arguments.
    
    * Should return @nbytes on success instead of 0.
    
    * @buf is not trimmed automatically.  Trim if necessary.  Note that
      blkcg and netprio don't need this as the parsers already handle
      whitespaces.
    
    cftype->write_string() has no user left after the conversions and
    removed.
    
    While at it, remove unnecessary local variable @p in
    cgroup_subtree_control_write() and stale comment about
    CGROUP_LOCAL_BUFFER_SIZE in cgroup_freezer.c.
    
    This patch doesn't introduce any visible behavior changes.
    
    v2: netprio was missing from conversion.  Converted.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Aristeu Rozanski <arozansk@redhat.com>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: "David S. Miller" <davem@davemloft.net>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c5a170ca4a48..aecdc84fe128 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -453,8 +453,7 @@ struct cftype {
 
 	/*
 	 * The maximum length of string, excluding trailing nul, that can
-	 * be passed to write_string.  If < PAGE_SIZE-1, PAGE_SIZE-1 is
-	 * assumed.
+	 * be passed to write.  If < PAGE_SIZE-1, PAGE_SIZE-1 is assumed.
 	 */
 	size_t max_write_len;
 
@@ -500,13 +499,6 @@ struct cftype {
 	int (*write_s64)(struct cgroup_subsys_state *css, struct cftype *cft,
 			 s64 val);
 
-	/*
-	 * write_string() is passed a nul-terminated kernelspace
-	 * buffer of maximum length determined by max_write_len.
-	 * Returns 0 or -ve error code.
-	 */
-	int (*write_string)(struct cgroup_subsys_state *css, struct cftype *cft,
-			    char *buffer);
 	/*
 	 * trigger() callback can be used to get some kick from the
 	 * userspace, when the actual string written is not important

commit b41686401e501430ffe93b575ef7959d2ecc6f2e
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 12:16:21 2014 -0400

    cgroup: implement cftype->write()
    
    During the recent conversion to kernfs, cftype's seq_file operations
    are updated so that they are directly mapped to kernfs operations and
    thus can fully access the associated kernfs and cgroup contexts;
    however, write path hasn't seen similar updates and none of the
    existing write operations has access to, for example, the associated
    kernfs_open_file.
    
    Let's introduce a new operation cftype->write() which maps directly to
    the kernfs write operation and has access to all the arguments and
    contexts.  This will replace ->write_string() and ->trigger() and ease
    manipulation of kernfs active protection from cgroup file operations.
    
    Two accessors - of_cft() and of_css() - are introduced to enable
    accessing the associated cgroup context from cftype->write() which
    only takes kernfs_open_file for the context information.  The
    accessors for seq_file operations - seq_cft() and seq_css() - are
    rewritten to wrap the of_ accessors.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c5f3684ef557..c5a170ca4a48 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -515,6 +515,15 @@ struct cftype {
 	 */
 	int (*trigger)(struct cgroup_subsys_state *css, unsigned int event);
 
+	/*
+	 * write() is the generic write callback which maps directly to
+	 * kernfs write operation and overrides all other operations.
+	 * Maximum write size is determined by ->max_write_len.  Use
+	 * of_css/cft() to access the associated css and cft.
+	 */
+	ssize_t (*write)(struct kernfs_open_file *of,
+			 char *buf, size_t nbytes, loff_t off);
+
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 	struct lock_class_key	lockdep_key;
 #endif
@@ -552,14 +561,24 @@ static inline ino_t cgroup_ino(struct cgroup *cgrp)
 		return 0;
 }
 
-static inline struct cftype *seq_cft(struct seq_file *seq)
+/* cft/css accessors for cftype->write() operation */
+static inline struct cftype *of_cft(struct kernfs_open_file *of)
 {
-	struct kernfs_open_file *of = seq->private;
-
 	return of->kn->priv;
 }
 
-struct cgroup_subsys_state *seq_css(struct seq_file *seq);
+struct cgroup_subsys_state *of_css(struct kernfs_open_file *of);
+
+/* cft/css accessors for cftype->seq_*() operations */
+static inline struct cftype *seq_cft(struct seq_file *seq)
+{
+	return of_cft(seq->private);
+}
+
+static inline struct cgroup_subsys_state *seq_css(struct seq_file *seq)
+{
+	return of_css(seq->private);
+}
 
 /*
  * Name / path handling functions.  All are thin wrappers around the kernfs

commit ec903c0c858e4963a9e0724bdcadfa837253341c
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 12:11:01 2014 -0400

    cgroup: rename css_tryget*() to css_tryget_online*()
    
    Unlike the more usual refcnting, what css_tryget() provides is the
    distinction between online and offline csses instead of protection
    against upping a refcnt which already reached zero.  cgroup is
    planning to provide actual tryget which fails if the refcnt already
    reached zero.  Let's rename the existing trygets so that they clearly
    indicate that they're onliness.
    
    I thought about keeping the existing names as-are and introducing new
    names for the planned actual tryget; however, given that each
    controller participates in the synchronization of the online state, it
    seems worthwhile to make it explicit that these functions are about
    on/offline state.
    
    Rename css_tryget() to css_tryget_online() and css_tryget_from_dir()
    to css_tryget_online_from_dir().  This is pure rename.
    
    v2: cgroup_freezer grew new usages of css_tryget().  Update
        accordingly.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index bde44618d8c2..c5f3684ef557 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -95,16 +95,16 @@ static inline void css_get(struct cgroup_subsys_state *css)
 }
 
 /**
- * css_tryget - try to obtain a reference on the specified css
+ * css_tryget_online - try to obtain a reference on the specified css if online
  * @css: target css
  *
- * Obtain a reference on @css if it's alive.  The caller naturally needs to
- * ensure that @css is accessible but doesn't have to be holding a
+ * Obtain a reference on @css if it's online.  The caller naturally needs
+ * to ensure that @css is accessible but doesn't have to be holding a
  * reference on it - IOW, RCU protected access is good enough for this
  * function.  Returns %true if a reference count was successfully obtained;
  * %false otherwise.
  */
-static inline bool css_tryget(struct cgroup_subsys_state *css)
+static inline bool css_tryget_online(struct cgroup_subsys_state *css)
 {
 	if (css->flags & CSS_ROOT)
 		return true;
@@ -115,7 +115,7 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
  * css_put - put a css reference
  * @css: target css
  *
- * Put a reference obtained via css_get() and css_tryget().
+ * Put a reference obtained via css_get() and css_tryget_online().
  */
 static inline void css_put(struct cgroup_subsys_state *css)
 {
@@ -905,8 +905,8 @@ void css_task_iter_end(struct css_task_iter *it);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 
-struct cgroup_subsys_state *css_tryget_from_dir(struct dentry *dentry,
-						struct cgroup_subsys *ss);
+struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
+						       struct cgroup_subsys *ss);
 
 #else /* !CONFIG_CGROUPS */
 

commit f21a4f7594a122dcaabc08ce03bfb63fdc34de1b
Merge: d39ea871c3c1 36e9d2ebcc15
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 11:30:04 2014 -0400

    Merge branch 'for-3.15-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup into for-3.16
    
    Pull to receive e37a06f10994 ("cgroup: fix the retry path of
    cgroup_mount()") to avoid unnecessary conflicts with planned
    cgroup_tree_mutex removal and also to be able to remove the temp fix
    added by 36c38fb7144a ("blkcg: use trylock on blkcg_pol_mutex in
    blkcg_reset_stats()") afterwards.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit d39ea871c3c1269e2852ea096fff492ea034df8a
Merge: 2b53f41fa860 4fb6e25049cb
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 11:27:24 2014 -0400

    Merge branch 'for-3.16' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu into for-3.16
    
    Pull to receive percpu_ref_tryget[_live]() changes.  Planned cgroup
    changes will make use of them.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit 5024ae29cd285ce9e736776414da645d3a91828c
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 7 21:31:17 2014 -0400

    cgroup: introduce task_css_is_root()
    
    Determining the css of a task usually requires RCU read lock as that's
    the only thing which keeps the returned css accessible till its
    reference is acquired; however, testing whether a task belongs to the
    root can be performed without dereferencing the returned css by
    comparing the returned pointer against the root one in init_css_set[]
    which never changes.
    
    Implement task_css_is_root() which can be invoked in any context.
    This will be used by the scheduled cgroup_freezer change.
    
    v2: cgroup no longer supports modular controllers.  No need to export
        init_css_set.  Pointed out by Li.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c2515851c1aa..d60904b9e505 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -473,6 +473,7 @@ struct cftype {
 };
 
 extern struct cgroup_root cgrp_dfl_root;
+extern struct css_set init_css_set;
 
 static inline bool cgroup_on_dfl(const struct cgroup *cgrp)
 {
@@ -700,6 +701,20 @@ static inline struct cgroup_subsys_state *task_css(struct task_struct *task,
 	return task_css_check(task, subsys_id, false);
 }
 
+/**
+ * task_css_is_root - test whether a task belongs to the root css
+ * @task: the target task
+ * @subsys_id: the target subsystem ID
+ *
+ * Test whether @task belongs to the root css on the specified subsystem.
+ * May be invoked in any context.
+ */
+static inline bool task_css_is_root(struct task_struct *task, int subsys_id)
+{
+	return task_css_check(task, subsys_id, true) ==
+		init_css_set.subsys[subsys_id];
+}
+
 static inline struct cgroup *task_cgroup(struct task_struct *task,
 					 int subsys_id)
 {

commit 2070d50e1cbe3d7f157cbf8e63279c893f375d7f
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 9 15:11:53 2014 -0400

    percpu-refcount: rename percpu_ref_tryget() to percpu_ref_tryget_live()
    
    percpu_ref_tryget() is different from the usual tryget semantics in
    that it fails if the refcnt is in its dying stage even if the refcnt
    hasn't reached zero yet.  We're about to introduce the more
    conventional tryget and the current one has only one user.  Let's
    rename it to percpu_ref_tryget_live() so that it explicitly signifies
    the peculiarities of its semantics.
    
    This is pure rename.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Kent Overstreet <kmo@daterainc.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c2515851c1aa..549aed8de32b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -101,7 +101,7 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
 {
 	if (css->flags & CSS_ROOT)
 		return true;
-	return percpu_ref_tryget(&css->refcnt);
+	return percpu_ref_tryget_live(&css->refcnt);
 }
 
 /**

commit 2b53f41fa8604845f4f7c538723694a453088b15
Author: Tejun Heo <tj@kernel.org>
Date:   Wed May 7 09:21:56 2014 -0400

    cgroup: remove unused CGRP_SANE_BEHAVIOR
    
    This cgroup flag has never been used.  Only CGRP_ROOT_SANE_BEHAVIOR is
    used.  Remove it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 2dfabb3b749a..f482f95c2c72 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -140,8 +140,6 @@ enum {
 	 * specified at mount time and thus is implemented here.
 	 */
 	CGRP_CPUSET_CLONE_CHILDREN,
-	/* see the comment above CGRP_ROOT_SANE_BEHAVIOR for details */
-	CGRP_SANE_BEHAVIOR,
 };
 
 struct cgroup {

commit 15a4c835e4ed3e60dd68727cd1907e3dd89563f4
Author: Tejun Heo <tj@kernel.org>
Date:   Sun May 4 15:09:14 2014 -0400

    cgroup, memcg: implement css->id and convert css_from_id() to use it
    
    Until now, cgroup->id has been used to identify all the associated
    csses and css_from_id() takes cgroup ID and returns the matching css
    by looking up the cgroup and then dereferencing the css associated
    with it; however, now that the lifetimes of cgroup and css are
    separate, this is incorrect and breaks on the unified hierarchy when a
    controller is disabled and enabled back again before the previous
    instance is released.
    
    This patch adds css->id which is a subsystem-unique ID and converts
    css_from_id() to look up by the new css->id instead.  memcg is the
    only user of css_from_id() and also converted to use css->id instead.
    
    For traditional hierarchies, this shouldn't make any functional
    difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Jianyu Zhan <nasa4836@gmail.com>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 793f70a48820..2dfabb3b749a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -62,6 +62,12 @@ struct cgroup_subsys_state {
 	/* the parent css */
 	struct cgroup_subsys_state *parent;
 
+	/*
+	 * Subsys-unique ID.  0 is unused and root is always 1.  The
+	 * matching css can be looked up using css_from_id().
+	 */
+	int id;
+
 	unsigned int flags;
 
 	/* percpu_ref killing and RCU release */
@@ -655,6 +661,9 @@ struct cgroup_subsys {
 	/* link to parent, protected by cgroup_lock() */
 	struct cgroup_root *root;
 
+	/* idr for css->id */
+	struct idr css_idr;
+
 	/*
 	 * List of cftypes.  Each entry is the first entry of an array
 	 * terminated by zero length name.

commit 7d699ddb2b181a2c76e5ea18b1bdf102c4bebe4b
Author: Tejun Heo <tj@kernel.org>
Date:   Sun May 4 15:09:13 2014 -0400

    cgroup, memcg: allocate cgroup ID from 1
    
    Currently, cgroup->id is allocated from 0, which is always assigned to
    the root cgroup; unfortunately, memcg wants to use ID 0 to indicate
    invalid IDs and ends up incrementing all IDs by one.
    
    It's reasonable to reserve 0 for special purposes.  This patch updates
    cgroup core so that ID 0 is not used and the root cgroups get ID 1.
    The ID incrementing is removed form memcg.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c6c703f2486b..793f70a48820 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -144,8 +144,8 @@ struct cgroup {
 	/*
 	 * idr allocated in-hierarchy ID.
 	 *
-	 * The ID of the root cgroup is always 0, and a new cgroup
-	 * will be assigned with a smallest available ID.
+	 * ID 0 is not used, the ID of the root cgroup is always 1, and a
+	 * new cgroup will be assigned with a smallest available ID.
 	 *
 	 * Allocating/Removing ID must be protected by cgroup_mutex.
 	 */

commit 69dfa00ccb72a37f3810687ca110e5a8154c6eed
Author: Tejun Heo <tj@kernel.org>
Date:   Sun May 4 15:09:13 2014 -0400

    cgroup: make flags and subsys_masks unsigned int
    
    There's no reason to use atomic bitops for cgroup_subsys_state->flags,
    cgroup_root->flags and various subsys_masks.  This patch updates those
    to use bitwise and/or operations instead and converts them form
    unsigned long to unsigned int.
    
    This makes the fields occupy (marginally) smaller space and makes it
    clear that they don't require atomicity.
    
    This patch doesn't cause any behavior difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4b38e2d6110d..c6c703f2486b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -62,7 +62,7 @@ struct cgroup_subsys_state {
 	/* the parent css */
 	struct cgroup_subsys_state *parent;
 
-	unsigned long flags;
+	unsigned int flags;
 
 	/* percpu_ref killing and RCU release */
 	struct rcu_head rcu_head;
@@ -185,7 +185,7 @@ struct cgroup {
 	u64 serial_nr;
 
 	/* the bitmask of subsystems enabled on the child cgroups */
-	unsigned long child_subsys_mask;
+	unsigned int child_subsys_mask;
 
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state __rcu *subsys[CGROUP_SUBSYS_COUNT];
@@ -312,7 +312,7 @@ struct cgroup_root {
 	struct kernfs_root *kf_root;
 
 	/* The bitmask of subsystems attached to this hierarchy */
-	unsigned long subsys_mask;
+	unsigned int subsys_mask;
 
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
@@ -327,7 +327,7 @@ struct cgroup_root {
 	struct list_head root_list;
 
 	/* Hierarchy-specific flags */
-	unsigned long flags;
+	unsigned int flags;
 
 	/* IDs for cgroups in this hierarchy */
 	struct idr cgroup_idr;

commit 842b597ee0a7e1aa5a3148164ffdba00ec17f614
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Apr 25 18:28:02 2014 -0400

    cgroup: implement cgroup.populated for the default hierarchy
    
    cgroup users often need a way to determine when a cgroup's
    subhierarchy becomes empty so that it can be cleaned up.  cgroup
    currently provides release_agent for it; unfortunately, this mechanism
    is riddled with issues.
    
    * It delivers events by forking and execing a userland binary
      specified as the release_agent.  This is a long deprecated method of
      notification delivery.  It's extremely heavy, slow and cumbersome to
      integrate with larger infrastructure.
    
    * There is single monitoring point at the root.  There's no way to
      delegate management of a subtree.
    
    * The event isn't recursive.  It triggers when a cgroup doesn't have
      any tasks or child cgroups.  Events for internal nodes trigger only
      after all children are removed.  This again makes it impossible to
      delegate management of a subtree.
    
    * Events are filtered from the kernel side.  "notify_on_release" file
      is used to subscribe to or suppress release event.  This is
      unnecessarily complicated and probably done this way because event
      delivery itself was expensive.
    
    This patch implements interface file "cgroup.populated" which can be
    used to monitor whether the cgroup's subhierarchy has tasks in it or
    not.  Its value is 0 if there is no task in the cgroup and its
    descendants; otherwise, 1, and kernfs_notify() notificaiton is
    triggers when the value changes, which can be monitored through poll
    and [di]notify.
    
    This is a lot ligther and simpler and trivially allows delegating
    management of subhierarchy - subhierarchy monitoring can block further
    propgation simply by putting itself or another process in the root of
    the subhierarchy and monitor events that it's interested in from there
    without interfering with monitoring higher in the tree.
    
    v2: Patch description updated as per Serge.
    
    v3: "cgroup.subtree_populated" renamed to "cgroup.populated".  The
        subtree_ prefix was a bit confusing because
        "cgroup.subtree_control" uses it to denote the tree rooted at the
        cgroup sans the cgroup itself while the populated state includes
        the cgroup itself.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Serge Hallyn <serge.hallyn@ubuntu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Lennart Poettering <lennart@poettering.net>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ada239253ec7..4b38e2d6110d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -154,6 +154,14 @@ struct cgroup {
 	/* the number of attached css's */
 	int nr_css;
 
+	/*
+	 * If this cgroup contains any tasks, it contributes one to
+	 * populated_cnt.  All children with non-zero popuplated_cnt of
+	 * their own contribute one.  The count is zero iff there's no task
+	 * in this cgroup or its subtree.
+	 */
+	int populated_cnt;
+
 	atomic_t refcnt;
 
 	/*
@@ -166,6 +174,7 @@ struct cgroup {
 	struct cgroup *parent;		/* my parent */
 	struct kernfs_node *kn;		/* cgroup kernfs entry */
 	struct kernfs_node *control_kn;	/* kn for "cgroup.subtree_control" */
+	struct kernfs_node *populated_kn; /* kn for "cgroup.subtree_populated" */
 
 	/*
 	 * Monotonically increasing unique serial number which defines a
@@ -264,6 +273,12 @@ enum {
 	 *
 	 * - "cgroup.clone_children" is removed.
 	 *
+	 * - "cgroup.subtree_populated" is available.  Its value is 0 if
+	 *   the cgroup and its descendants contain no task; otherwise, 1.
+	 *   The file also generates kernfs notification which can be
+	 *   monitored through poll and [di]notify when the value of the
+	 *   file changes.
+	 *
 	 * - If mount is requested with sane_behavior but without any
 	 *   subsystem, the default unified hierarchy is mounted.
 	 *

commit f8f22e53a262ebee37fc98004f16b066cf5bc125
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 23 11:13:16 2014 -0400

    cgroup: implement dynamic subtree controller enable/disable on the default hierarchy
    
    cgroup is switching away from multiple hierarchies and will use one
    unified default hierarchy where controllers can be dynamically enabled
    and disabled per subtree.  The default hierarchy will serve as the
    unified hierarchy to which all controllers are attached and a css on
    the default hierarchy would need to also serve the tasks of descendant
    cgroups which don't have the controller enabled - ie. the tree may be
    collapsed from leaf towards root when viewed from specific
    controllers.  This has been implemented through effective css in the
    previous patches.
    
    This patch finally implements dynamic subtree controller
    enable/disable on the default hierarchy via a new knob -
    "cgroup.subtree_control" which controls which controllers are enabled
    on the child cgroups.  Let's assume a hierarchy like the following.
    
      root - A - B - C
                   \ D
    
    root's "cgroup.subtree_control" determines which controllers are
    enabled on A.  A's on B.  B's on C and D.  This coincides with the
    fact that controllers on the immediate sub-level are used to
    distribute the resources of the parent.  In fact, it's natural to
    assume that resource control knobs of a child belong to its parent.
    Enabling a controller in "cgroup.subtree_control" declares that
    distribution of the respective resources of the cgroup will be
    controlled.  Note that this means that controller enable states are
    shared among siblings.
    
    The default hierarchy has an extra restriction - only cgroups which
    don't contain any task may have controllers enabled in
    "cgroup.subtree_control".  Combined with the other properties of the
    default hierarchy, this guarantees that, from the view point of
    controllers, tasks are only on the leaf cgroups.  In other words, only
    leaf csses may contain tasks.  This rules out situations where child
    cgroups compete against internal tasks of the parent, which is a
    competition between two different types of entities without any clear
    way to determine resource distribution between the two.  Different
    controllers handle it differently and all the implemented behaviors
    are ambiguous, ad-hoc, cumbersome and/or just wrong.  Having this
    structural constraints imposed from cgroup core removes the burden
    from controller implementations and enables showing one consistent
    behavior across all controllers.
    
    When a controller is enabled or disabled, css associations for the
    controller in the subtrees of each child should be updated.  After
    enabling, the whole subtree of a child should point to the new css of
    the child.  After disabling, the whole subtree of a child should point
    to the cgroup's css.  This is implemented by first updating cgroup
    states such that cgroup_e_css() result points to the appropriate css
    and then invoking cgroup_update_dfl_csses() which migrates all tasks
    in the affected subtrees to the self cgroup on the default hierarchy.
    
    * When read, "cgroup.subtree_control" lists all the currently enabled
      controllers on the children of the cgroup.
    
    * White-space separated list of controller names prefixed with either
      '+' or '-' can be written to "cgroup.subtree_control".  The ones
      prefixed with '+' are enabled on the controller and '-' disabled.
    
    * A controller can be enabled iff the parent's
      "cgroup.subtree_control" enables it and disabled iff no child's
      "cgroup.subtree_control" has it enabled.
    
    * If a cgroup has tasks, no controller can be enabled via
      "cgroup.subtree_control".  Likewise, if "cgroup.subtree_control" has
      some controllers enabled, tasks can't be migrated into the cgroup.
    
    * All controllers which aren't bound on other hierarchies are
      automatically associated with the root cgroup of the default
      hierarchy.  All the controllers which are bound to the default
      hierarchy are listed in the read-only file "cgroup.controllers" in
      the root directory.
    
    * "cgroup.controllers" in all non-root cgroups is read-only file whose
      content is equal to that of "cgroup.subtree_control" of the parent.
      This indicates which controllers can be used in the cgroup's
      "cgroup.subtree_control".
    
    This is still experimental and there are some holes, one of which is
    that ->can_attach() failure during cgroup_update_dfl_csses() may leave
    the cgroups in an undefined state.  The issues will be addressed by
    future patches.
    
    v2: Non-root cgroups now also have "cgroup.controllers".
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c49d161a71cd..ada239253ec7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -21,6 +21,7 @@
 #include <linux/percpu-refcount.h>
 #include <linux/seq_file.h>
 #include <linux/kernfs.h>
+#include <linux/wait.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -164,6 +165,7 @@ struct cgroup {
 
 	struct cgroup *parent;		/* my parent */
 	struct kernfs_node *kn;		/* cgroup kernfs entry */
+	struct kernfs_node *control_kn;	/* kn for "cgroup.subtree_control" */
 
 	/*
 	 * Monotonically increasing unique serial number which defines a
@@ -216,6 +218,9 @@ struct cgroup {
 	/* For css percpu_ref killing and RCU-protected deletion */
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
+
+	/* used to wait for offlining of csses */
+	wait_queue_head_t offline_waitq;
 };
 
 #define MAX_CGROUP_ROOT_NAMELEN 64

commit 6803c006282768ec850760766a6e4eb1a6ff87df
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 23 11:13:16 2014 -0400

    cgroup: add css_set->dfl_cgrp
    
    To implement the unified hierarchy behavior, we'll need to be able to
    determine the associated cgroup on the default hierarchy from css_set.
    Let's add css_set->dfl_cgrp so that it can be accessed conveniently
    and efficiently.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 18fcae39e63e..c49d161a71cd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -354,6 +354,9 @@ struct css_set {
 	 */
 	struct list_head cgrp_links;
 
+	/* the default cgroup associated with this css_set */
+	struct cgroup *dfl_cgrp;
+
 	/*
 	 * Set of subsystem states, one for each subsystem. This array is
 	 * immutable after creation apart from the init_css_set during

commit 3ebb2b6ef38875b866ec0118bfae7bc52afd0166
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 23 11:13:15 2014 -0400

    cgroup: teach css_task_iter about effective csses
    
    Currently, css_task_iter iterates tasks associated with a css by
    visiting each css_set associated with the owning cgroup and walking
    tasks of each of them.  This works fine for !unified hierarchies as
    each cgroup has its own css for each associated subsystem on the
    hierarchy; however, on the planned unified hierarchy, a cgroup may not
    have csses associated and its tasks would be considered associated
    with the matching css of the nearest ancestor which has the subsystem
    enabled.
    
    This means that on the default unified hierarchy, just walking all
    tasks associated with a cgroup isn't enough to walk all tasks which
    are associated with the specified css.  If any of its children doesn't
    have the matching css enabled, task iteration should also include all
    tasks from the subtree.  We already added cgroup->e_csets[] to list
    all css_sets effectively associated with a given css and walk css_sets
    on that list instead to achieve such iteration.
    
    This patch updates css_task_iter iteration such that it walks css_sets
    on cgroup->e_csets[] instead of cgroup->cset_links if iteration is
    requested on an non-dummy css.  Thanks to the previous iteration
    update, this change can be achieved with the addition of
    css_task_iter->ss and minimal updates to css_advance_task_iter() and
    css_task_iter_start().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index bee390586120..18fcae39e63e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -842,6 +842,8 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 
 /* A css_task_iter should be treated as an opaque object */
 struct css_task_iter {
+	struct cgroup_subsys		*ss;
+
 	struct list_head		*cset_pos;
 	struct list_head		*cset_head;
 

commit 0f0a2b4fa6210147131082999f1f16d7fb79abf8
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 23 11:13:15 2014 -0400

    cgroup: reorganize css_task_iter
    
    This patch reorganizes css_task_iter so that adding effective css
    support is easier.
    
    * s/->cset_link/->cset_pos/ and s/->task/->task_pos/ for consistency
    
    * ->origin_css is used to determine whether the iteration reached the
      last css_set.  Replace it with explicit ->cset_head so that
      css_advance_task_iter() doesn't have to know the termination
      condition directly.
    
    * css_task_iter_next() currently assumes that it's walking list of
      cgrp_cset_link and reaches into the current cset through the current
      link to determine the termination conditions for task walking.  As
      this won't always be true for effective css walking, add
      ->tasks_head and ->mg_tasks_head and use them to control task
      walking so that css_task_iter_next() doesn't have to know how
      css_sets are being walked.
    
    This patch doesn't make any behavior changes.  The iteration logic
    stays unchanged after the patch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 33a0043ef454..bee390586120 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -842,9 +842,12 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 
 /* A css_task_iter should be treated as an opaque object */
 struct css_task_iter {
-	struct cgroup_subsys_state	*origin_css;
-	struct list_head		*cset_link;
-	struct list_head		*task;
+	struct list_head		*cset_pos;
+	struct list_head		*cset_head;
+
+	struct list_head		*task_pos;
+	struct list_head		*tasks_head;
+	struct list_head		*mg_tasks_head;
 };
 
 void css_task_iter_start(struct cgroup_subsys_state *css,

commit 2d8f243a5e6efa57fb7c46fe83fafa45b33d0ec2
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 23 11:13:15 2014 -0400

    cgroup: implement cgroup->e_csets[]
    
    On the default unified hierarchy, a cgroup may be associated with
    csses of its ancestors, which means that a css of a given cgroup may
    be associated with css_sets of descendant cgroups.  This means that we
    can't walk all tasks associated with a css by iterating the css_sets
    associated with the cgroup as there are css_sets which are pointing to
    the css but linked on the descendants.
    
    This patch adds per-subsystem list heads cgroup->e_csets[].  Any
    css_set which is pointing to a css is linked to
    css->cgroup->e_csets[$SUBSYS_ID] through
    css_set->e_cset_node[$SUBSYS_ID].  The lists are protected by
    css_set_rwsem and will allow us to walk all css_sets associated with a
    given css so that we can find out all associated tasks.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1b5b2fe1b228..33a0043ef454 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -187,6 +187,15 @@ struct cgroup {
 	 */
 	struct list_head cset_links;
 
+	/*
+	 * On the default hierarchy, a css_set for a cgroup with some
+	 * susbsys disabled will point to css's which are associated with
+	 * the closest ancestor which has the subsys enabled.  The
+	 * following lists all css_sets which point to this cgroup's css
+	 * for the given subsystem.
+	 */
+	struct list_head e_csets[CGROUP_SUBSYS_COUNT];
+
 	/*
 	 * Linked list running through all cgroups that can
 	 * potentially be reaped by the release agent. Protected by
@@ -369,6 +378,15 @@ struct css_set {
 	struct cgroup *mg_src_cgrp;
 	struct css_set *mg_dst_cset;
 
+	/*
+	 * On the default hierarhcy, ->subsys[ssid] may point to a css
+	 * attached to an ancestor instead of the cgroup this css_set is
+	 * associated with.  The following node is anchored at
+	 * ->subsys[ssid]->cgroup->e_csets[ssid] and provides a way to
+	 * iterate through all css's attached to a given cgroup.
+	 */
+	struct list_head e_cset_node[CGROUP_SUBSYS_COUNT];
+
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;
 };

commit f392e51cd6ae6f6ee5b9b6d611cdc282b4c1711e
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Apr 23 11:13:14 2014 -0400

    cgroup: update cgroup->subsys_mask to ->child_subsys_mask and restore cgroup_root->subsys_mask
    
    944196278d3d ("cgroup: move ->subsys_mask from cgroupfs_root to
    cgroup") moved ->subsys_mask from cgroup_root to cgroup to prepare for
    the unified hierarhcy; however, it turns out that carrying the
    subsys_mask of the children in the parent, instead of itself, is a lot
    more natural.  This patch restores cgroup_root->subsys_mask and morphs
    cgroup->subsys_mask into cgroup->child_subsys_mask.
    
    * Uses of root->cgrp.subsys_mask are restored to root->subsys_mask.
    
    * Remove automatic setting and clearing of cgrp->subsys_mask and
      instead just inherit ->child_subsys_mask from the parent during
      cgroup creation.  Note that this doesn't affect any current
      behaviors.
    
    * Undo __kill_css() separation.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c2515851c1aa..1b5b2fe1b228 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -173,8 +173,8 @@ struct cgroup {
 	 */
 	u64 serial_nr;
 
-	/* The bitmask of subsystems attached to this cgroup */
-	unsigned long subsys_mask;
+	/* the bitmask of subsystems enabled on the child cgroups */
+	unsigned long child_subsys_mask;
 
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state __rcu *subsys[CGROUP_SUBSYS_COUNT];
@@ -282,6 +282,9 @@ enum {
 struct cgroup_root {
 	struct kernfs_root *kf_root;
 
+	/* The bitmask of subsystems attached to this hierarchy */
+	unsigned long subsys_mask;
+
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
 

commit 1ec41830e087cda1f62dda4182c2b62811eb0ffc
Author: Li Zefan <lizefan@huawei.com>
Date:   Fri Mar 28 15:22:19 2014 +0800

    cgroup: remove useless argument from cgroup_exit()
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 43d1ed30bae3..c2515851c1aa 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -33,7 +33,7 @@ extern int cgroup_init_early(void);
 extern int cgroup_init(void);
 extern void cgroup_fork(struct task_struct *p);
 extern void cgroup_post_fork(struct task_struct *p);
-extern void cgroup_exit(struct task_struct *p, int run_callbacks);
+extern void cgroup_exit(struct task_struct *p);
 extern int cgroupstats_build(struct cgroupstats *stats,
 				struct dentry *dentry);
 
@@ -843,7 +843,7 @@ static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_fork(struct task_struct *p) {}
 static inline void cgroup_post_fork(struct task_struct *p) {}
-static inline void cgroup_exit(struct task_struct *p, int callbacks) {}
+static inline void cgroup_exit(struct task_struct *p) {}
 
 static inline int cgroupstats_build(struct cgroupstats *stats,
 					struct dentry *dentry)

commit 8cbbf2c972c4444cad36f61cd571714c39b8cf04
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 19 10:23:55 2014 -0400

    cgroup: implement CFTYPE_ONLY_ON_DFL
    
    This cftype flag makes the file only appear on the default hierarchy.
    This will later be used for cgroup.controllers file.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7e9fa505b7bb..43d1ed30bae3 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -384,6 +384,7 @@ enum {
 	CFTYPE_NOT_ON_ROOT	= (1 << 1),	/* don't create on root cgrp */
 	CFTYPE_INSANE		= (1 << 2),	/* don't create if sane_behavior */
 	CFTYPE_NO_PREFIX	= (1 << 3),	/* (DON'T USE FOR NEW FILES) no subsys prefix */
+	CFTYPE_ONLY_ON_DFL	= (1 << 4),	/* only on default hierarchy */
 };
 
 #define MAX_CFTYPE_NAME		64

commit a2dd424750807f83632a2a70293961086fd8f870
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 19 10:23:55 2014 -0400

    cgroup: make cgrp_dfl_root mountable
    
    cgrp_dfl_root will be used as the default unified hierarchy.  This
    patch makes cgrp_dfl_root mountable by making the following changes.
    
    * cgroup_init_early() now initializes cgrp_dfl_root w/
      CGRP_ROOT_SANE_BEHAVIOR.  The default hierarchy is always sane.
    
    * parse_cgroupfs_options() and cgroup_mount() are updated such that
      cgrp_dfl_root is mounted if sane_behavior is specified w/o any
      subsystems.
    
    * rebind_subsystems() now populates the root directory of
      cgrp_dfl_root.  Note that the function still guarantees success of
      rebinding subsystems to cgrp_dfl_root.  If populating fails while
      rebinding to cgrp_dfl_root, it whines but ignores the error.
    
    * For backward compatibility, the default hierarchy shows up in
      /proc/$PID/cgroup only after it's explicitly mounted so that
      userland which doesn't make use of it doesn't see any change.
    
    * "current_css_set_cg_links" file of debug cgroup now treats the
      default hierarchy the same as other hierarchies.  This is visible to
      userland.  Given that it's for debug controller, this should be
      fine.
    
    * While at it, implement cgroup_on_dfl() which tests whether a give
      cgroup is on the default hierarchy or not.
    
    The above changes make cgrp_dfl_root mostly equivalent to other
    controllers but the actual unified hierarchy behaviors are not
    implemented yet.  Let's plug child cgroup creation in cgrp_dfl_root
    from create_cgroup() for now.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 79993ac066c5..7e9fa505b7bb 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -250,6 +250,9 @@ enum {
 	 *
 	 * - "cgroup.clone_children" is removed.
 	 *
+	 * - If mount is requested with sane_behavior but without any
+	 *   subsystem, the default unified hierarchy is mounted.
+	 *
 	 * - cpuset: tasks will be kept in empty cpusets when hotplug happens
 	 *   and take masks of ancestors with non-empty cpus/mems, instead of
 	 *   being moved to an ancestor.
@@ -468,6 +471,13 @@ struct cftype {
 #endif
 };
 
+extern struct cgroup_root cgrp_dfl_root;
+
+static inline bool cgroup_on_dfl(const struct cgroup *cgrp)
+{
+	return cgrp->root == &cgrp_dfl_root;
+}
+
 /*
  * See the comment above CGRP_ROOT_SANE_BEHAVIOR for details.  This
  * function can be called as long as @cgrp is accessible.

commit 4d3bb511b5f9980fc3e9ae5939ebc475b231d3fc
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 19 10:23:54 2014 -0400

    cgroup: drop const from @buffer of cftype->write_string()
    
    cftype->write_string() just passes on the writeable buffer from kernfs
    and there's no reason to add const restriction on the buffer.  The
    only thing const achieves is unnecessarily complicating parsing of the
    buffer.  Drop const from @buffer.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Cc: Daniel Borkmann <dborkman@redhat.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 77294fc66603..79993ac066c5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -454,7 +454,7 @@ struct cftype {
 	 * Returns 0 or -ve error code.
 	 */
 	int (*write_string)(struct cgroup_subsys_state *css, struct cftype *cft,
-			    const char *buffer);
+			    char *buffer);
 	/*
 	 * trigger() callback can be used to get some kick from the
 	 * userspace, when the actual string written is not important

commit 3dd06ffa9df99aa88f4e01eaa0c9d3cb362430b0
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 19 10:23:54 2014 -0400

    cgroup: rename cgroup_dummy_root and related names
    
    The dummy root will be repurposed to serve as the default unified
    hierarchy.  Let's rename things in preparation.
    
    * s/cgroup_dummy_root/cgrp_dfl_root/
    * s/cgroupfs_root/cgroup_root/ as we don't do fs part directly anymore
    * s/cgroup_root->top_cgroup/cgroup_root->cgrp/ for brevity
    
    This is pure rename.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3752a0182c94..77294fc66603 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -24,7 +24,7 @@
 
 #ifdef CONFIG_CGROUPS
 
-struct cgroupfs_root;
+struct cgroup_root;
 struct cgroup_subsys;
 struct inode;
 struct cgroup;
@@ -179,7 +179,7 @@ struct cgroup {
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state __rcu *subsys[CGROUP_SUBSYS_COUNT];
 
-	struct cgroupfs_root *root;
+	struct cgroup_root *root;
 
 	/*
 	 * List of cgrp_cset_links pointing at css_sets with tasks in this
@@ -211,7 +211,7 @@ struct cgroup {
 
 #define MAX_CGROUP_ROOT_NAMELEN 64
 
-/* cgroupfs_root->flags */
+/* cgroup_root->flags */
 enum {
 	/*
 	 * Unfortunately, cgroup core and various controllers are riddled
@@ -272,18 +272,18 @@ enum {
 };
 
 /*
- * A cgroupfs_root represents the root of a cgroup hierarchy, and may be
+ * A cgroup_root represents the root of a cgroup hierarchy, and may be
  * associated with a kernfs_root to form an active hierarchy.  This is
  * internal to cgroup core.  Don't access directly from controllers.
  */
-struct cgroupfs_root {
+struct cgroup_root {
 	struct kernfs_root *kf_root;
 
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
 
 	/* The root cgroup.  Root is destroyed on its release. */
-	struct cgroup top_cgroup;
+	struct cgroup cgrp;
 
 	/* Number of cgroups in the hierarchy, used only for /proc/cgroups */
 	atomic_t nr_cgrps;
@@ -598,7 +598,7 @@ struct cgroup_subsys {
 	const char *name;
 
 	/* link to parent, protected by cgroup_lock() */
-	struct cgroupfs_root *root;
+	struct cgroup_root *root;
 
 	/*
 	 * List of cftypes.  Each entry is the first entry of an array

commit 944196278d3dea0cece1636de417b56897d9a108
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 19 10:23:54 2014 -0400

    cgroup: move ->subsys_mask from cgroupfs_root to cgroup
    
    cgroupfs_root->subsys_mask represents the controllers attached to the
    hierarchy.  This patch moves the field to cgroup.  Subsystem
    initialization and rebinding updates the top cgroup's subsys_mask.
    For !root cgroups, the subsys_mask bits are set from create_css() and
    cleared from kill_css(), which effectively means that all cgroups will
    have the same subsys_mask as the top cgroup.
    
    While this doesn't make any difference now, this will help
    implementation of the default unified hierarchy where !root cgroups
    may have subsets of the top_cgroup's subsys_mask.
    
    While at it, __kill_css() is split out of kill_css().  The former
    doesn't care about the subsys_mask while the latter becomes noop if
    the controller is already killed and clears the matching bit if not
    before proceeding to killing the css.  This will be used later by the
    default unified hierarchy implementation.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9f4f253f0e47..3752a0182c94 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -173,6 +173,9 @@ struct cgroup {
 	 */
 	u64 serial_nr;
 
+	/* The bitmask of subsystems attached to this cgroup */
+	unsigned long subsys_mask;
+
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state __rcu *subsys[CGROUP_SUBSYS_COUNT];
 
@@ -276,9 +279,6 @@ enum {
 struct cgroupfs_root {
 	struct kernfs_root *kf_root;
 
-	/* The bitmask of subsystems attached to this hierarchy */
-	unsigned long subsys_mask;
-
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
 

commit fdce6bf8c5b6968eb9b96ecc5fe400514a604902
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 19 10:23:54 2014 -0400

    cgroup: remove NULL checks from [pr_cont_]cgroup_{name|path}()
    
    The dummy hierarchy is now a fully functional one and dummy_top has a
    kernfs_node associated with it.  Drop the NULL checks in
    [pr_cont_]cont_{name|path}() which are no longer necessary.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index acbb9a4cb6e9..9f4f253f0e47 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -508,39 +508,23 @@ struct cgroup_subsys_state *seq_css(struct seq_file *seq);
 
 static inline int cgroup_name(struct cgroup *cgrp, char *buf, size_t buflen)
 {
-	/* dummy_top doesn't have a kn associated */
-	if (cgrp->kn)
-		return kernfs_name(cgrp->kn, buf, buflen);
-	else
-		return strlcpy(buf, "/", buflen);
+	return kernfs_name(cgrp->kn, buf, buflen);
 }
 
 static inline char * __must_check cgroup_path(struct cgroup *cgrp, char *buf,
 					      size_t buflen)
 {
-	/* dummy_top doesn't have a kn associated */
-	if (cgrp->kn)
-		return kernfs_path(cgrp->kn, buf, buflen);
-	strlcpy(buf, "/", buflen);
-	return (buflen <= 2) ? NULL : buf;
+	return kernfs_path(cgrp->kn, buf, buflen);
 }
 
 static inline void pr_cont_cgroup_name(struct cgroup *cgrp)
 {
-	/* dummy_top doesn't have a kn associated */
-	if (cgrp->kn)
-		pr_cont_kernfs_name(cgrp->kn);
-	else
-		pr_cont("/");
+	pr_cont_kernfs_name(cgrp->kn);
 }
 
 static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
 {
-	/* dummy_top doesn't have a kn associated */
-	if (cgrp->kn)
-		pr_cont_kernfs_path(cgrp->kn);
-	else
-		pr_cont("/");
+	pr_cont_kernfs_path(cgrp->kn);
 }
 
 char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);

commit 0e1d768f1b1873272ec4e8dc1482bb5281855017
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 25 10:04:03 2014 -0500

    cgroup: drop task_lock() protection around task->cgroups
    
    For optimization, task_lock() is additionally used to protect
    task->cgroups.  The optimization is pretty dubious as either
    css_set_rwsem is grabbed anyway or PF_EXITING already protects
    task->cgroups.  It adds only overhead and confusion at this point.
    Let's drop task_[un]lock() and update comments accordingly.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4829a577c1b9..acbb9a4cb6e9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -658,10 +658,12 @@ struct cgroup_subsys_state *css_parent(struct cgroup_subsys_state *css)
  */
 #ifdef CONFIG_PROVE_RCU
 extern struct mutex cgroup_mutex;
+extern struct rw_semaphore css_set_rwsem;
 #define task_css_set_check(task, __c)					\
 	rcu_dereference_check((task)->cgroups,				\
-		lockdep_is_held(&(task)->alloc_lock) ||			\
-		lockdep_is_held(&cgroup_mutex) || (__c))
+		lockdep_is_held(&cgroup_mutex) ||			\
+		lockdep_is_held(&css_set_rwsem) ||			\
+		((task)->flags & PF_EXITING) || (__c))
 #else
 #define task_css_set_check(task, __c)					\
 	rcu_dereference((task)->cgroups)

commit 1958d2d53dadbb1c9aaf0b37741f13a60098b243
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 25 10:04:03 2014 -0500

    cgroup: split process / task migration into four steps
    
    Currently, process / task migration is a single operation which may
    fail depending on memory pressure or the involved controllers'
    ->can_attach() callbacks.  One problem with this approach is migration
    of multiple targets.  It's impossible to tell whether a given target
    will be successfully migrated beforehand and cgroup core can't keep
    track of enough states to roll back after intermediate failure.
    
    This is already an issue with cgroup_transfer_tasks().  Also, we're
    gonna need multiple target migration for unified hierarchy.
    
    This patch splits migration into four stages -
    cgroup_migrate_add_src(), cgroup_migrate_prepare_dst(),
    cgroup_migrate() and cgroup_migrate_finish(), where
    cgroup_migrate_prepare_dst() performs all the operations which may
    fail due to allocation failure without actually migrating the target.
    
    The four separate stages mean that, disregarding ->can_attach()
    failures, the success or failure of multi target migration can be
    determined before performing any actual migration.  If preparations of
    all targets succeed, the whole thing will succeed.  If not, the whole
    operation can fail without any side-effect.
    
    Since the previous patch to use css_set->mg_tasks to keep track of
    migration targets, the only thing which may need memory allocation
    during migration is the target css_sets.  cgroup_migrate_prepare()
    pins all source and target css_sets and link them up.  Note that this
    can be performed without holding threadgroup_lock even if the target
    is a process.  As long as cgroup_mutex is held, no new css_set can be
    put into play.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3a1cb265afd6..4829a577c1b9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -350,6 +350,7 @@ struct css_set {
 	 * List of csets participating in the on-going migration either as
 	 * source or destination.  Protected by cgroup_mutex.
 	 */
+	struct list_head mg_preload_node;
 	struct list_head mg_node;
 
 	/*

commit b3dc094e93905ae9c1bc0815402ad8e5b203d068
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 25 10:04:01 2014 -0500

    cgroup: use css_set->mg_tasks to track target tasks during migration
    
    Currently, while migrating tasks from one cgroup to another,
    cgroup_attach_task() builds a flex array of all target tasks;
    unfortunately, this has a couple issues.
    
    * Flex array has size limit.  On 64bit, struct task_and_cgroup is
      24bytes making the flex element limit around 87k.  It is a high
      number but not impossible to hit.  This means that the current
      cgroup implementation can't migrate a process with more than 87k
      threads.
    
    * Process migration involves memory allocation whose size is dependent
      on the number of threads the process has.  This means that cgroup
      core can't guarantee success or failure of multi-process migrations
      as memory allocation failure can happen in the middle.  This is in
      part because cgroup can't grab threadgroup locks of multiple
      processes at the same time, so when there are multiple processes to
      migrate, it is imposible to tell how many tasks are to be migrated
      beforehand.
    
      Note that this already affects cgroup_transfer_tasks().  cgroup
      currently cannot guarantee atomic success or failure of the
      operation.  It may fail in the middle and after such failure cgroup
      doesn't have enough information to roll back properly.  It just
      aborts with some tasks migrated and others not.
    
    To resolve the situation, this patch updates the migration path to use
    task->cg_list to track target tasks.  The previous patch already added
    css_set->mg_tasks and updated iterations in non-migration paths to
    include them during task migration.  This patch updates migration path
    to actually make use of it.
    
    Instead of putting onto a flex_array, each target task is moved from
    its css_set->tasks list to css_set->mg_tasks and the migration path
    keeps trace of all the source css_sets and the associated cgroups.
    Once all source css_sets are determined, the destination css_set for
    each is determined, linked to the matching source css_set and put on a
    separate list.
    
    To iterate the target tasks, migration path just needs to iterat
    through either the source or target css_sets, depending on whether
    migration has been committed or not, and the tasks on their ->mg_tasks
    lists.  cgroup_taskset is updated to contain the list_heads for source
    and target css_sets and the iteration cursor.  cgroup_taskset_*() are
    accordingly updated to walk through css_sets and their ->mg_tasks.
    
    This resolves the above listed issues with moderate additional
    complexity.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 528e2aed36c3..3a1cb265afd6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -346,6 +346,22 @@ struct css_set {
 	 */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
 
+	/*
+	 * List of csets participating in the on-going migration either as
+	 * source or destination.  Protected by cgroup_mutex.
+	 */
+	struct list_head mg_node;
+
+	/*
+	 * If this cset is acting as the source of migration the following
+	 * two fields are set.  mg_src_cgrp is the source cgroup of the
+	 * on-going migration and mg_dst_cset is the destination cset the
+	 * target tasks on this cset should be migrated to.  Protected by
+	 * cgroup_mutex.
+	 */
+	struct cgroup *mg_src_cgrp;
+	struct css_set *mg_dst_cset;
+
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;
 };

commit c75611282cf1bf717c1866e7a7eb4d0743815187
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 25 10:04:01 2014 -0500

    cgroup: add css_set->mg_tasks
    
    Currently, while migrating tasks from one cgroup to another,
    cgroup_attach_task() builds a flex array of all target tasks;
    unfortunately, this has a couple issues.
    
    * Flex array has size limit.  On 64bit, struct task_and_cgroup is
      24bytes making the flex element limit around 87k.  It is a high
      number but not impossible to hit.  This means that the current
      cgroup implementation can't migrate a process with more than 87k
      threads.
    
    * Process migration involves memory allocation whose size is dependent
      on the number of threads the process has.  This means that cgroup
      core can't guarantee success or failure of multi-process migrations
      as memory allocation failure can happen in the middle.  This is in
      part because cgroup can't grab threadgroup locks of multiple
      processes at the same time, so when there are multiple processes to
      migrate, it is imposible to tell how many tasks are to be migrated
      beforehand.
    
      Note that this already affects cgroup_transfer_tasks().  cgroup
      currently cannot guarantee atomic success or failure of the
      operation.  It may fail in the middle and after such failure cgroup
      doesn't have enough information to roll back properly.  It just
      aborts with some tasks migrated and others not.
    
    To resolve the situation, we're going to use task->cg_list during
    migration too.  Instead of building a separate array, target tasks
    will be linked into a dedicated migration list_head on the owning
    css_set.  Tasks on the migration list are treated the same as tasks on
    the usual tasks list; however, being on a separate list allows cgroup
    migration code path to keep track of the target tasks by simply
    keeping the list of css_sets with tasks being migrated, making
    unpredictable dynamic allocation unnecessary.
    
    In prepartion of such migration path update, this patch introduces
    css_set->mg_tasks list and updates css_set task iterations so that
    they walk both css_set->tasks and ->mg_tasks.  Note that ->mg_tasks
    isn't used yet.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8c283a910b91..528e2aed36c3 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -324,10 +324,14 @@ struct css_set {
 	struct hlist_node hlist;
 
 	/*
-	 * List running through all tasks using this cgroup
-	 * group. Protected by css_set_lock
+	 * Lists running through all tasks using this cgroup group.
+	 * mg_tasks lists tasks which belong to this cset but are in the
+	 * process of being migrated out or in.  Protected by
+	 * css_set_rwsem, but, during migration, once tasks are moved to
+	 * mg_tasks, it can be read safely while holding cgroup_mutex.
 	 */
 	struct list_head tasks;
+	struct list_head mg_tasks;
 
 	/*
 	 * List of cgrp_cset_links pointing at cgroups referenced from this

commit cc045e3952175e84c38dad22dea14465b9fc8fb5
Author: Li Zefan <lizefan@huawei.com>
Date:   Fri Feb 14 16:56:04 2014 +0800

    cgroup: deal with dummp_top in cgroup_name() and cgroup_path()
    
    My kernel fails to boot, because blkcg calls cgroup_path() while
    cgroupfs is not mounted.
    
    Fix both cgroup_name() and cgroup_path().
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ef0b3af0e61c..8c283a910b91 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -487,13 +487,21 @@ struct cgroup_subsys_state *seq_css(struct seq_file *seq);
 
 static inline int cgroup_name(struct cgroup *cgrp, char *buf, size_t buflen)
 {
-	return kernfs_name(cgrp->kn, buf, buflen);
+	/* dummy_top doesn't have a kn associated */
+	if (cgrp->kn)
+		return kernfs_name(cgrp->kn, buf, buflen);
+	else
+		return strlcpy(buf, "/", buflen);
 }
 
 static inline char * __must_check cgroup_path(struct cgroup *cgrp, char *buf,
 					      size_t buflen)
 {
-	return kernfs_path(cgrp->kn, buf, buflen);
+	/* dummy_top doesn't have a kn associated */
+	if (cgrp->kn)
+		return kernfs_path(cgrp->kn, buf, buflen);
+	strlcpy(buf, "/", buflen);
+	return (buflen <= 2) ? NULL : buf;
 }
 
 static inline void pr_cont_cgroup_name(struct cgroup *cgrp)

commit bc668c7519ff8b4681af80e92f463bec7bf7cf9e
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Feb 13 06:58:43 2014 -0500

    cgroup: remove cgroup_taskset_cur_css() and cgroup_taskset_size()
    
    The two functions don't have any users left.  Remove them along with
    cgroup_taskset->cur_cgrp.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 581a124c7bc8..ef0b3af0e61c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -528,9 +528,6 @@ bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 struct cgroup_taskset;
 struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset);
 struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
-struct cgroup_subsys_state *cgroup_taskset_cur_css(struct cgroup_taskset *tset,
-						   int subsys_id);
-int cgroup_taskset_size(struct cgroup_taskset *tset);
 
 /**
  * cgroup_taskset_for_each - iterate cgroup_taskset

commit 924f0d9a2078f49ff331bb43196ec5afadc16b8f
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Feb 13 06:58:41 2014 -0500

    cgroup: drop @skip_css from cgroup_taskset_for_each()
    
    If !NULL, @skip_css makes cgroup_taskset_for_each() skip the matching
    css.  The intention of the interface is to make it easy to skip css's
    (cgroup_subsys_states) which already match the migration target;
    however, this is entirely unnecessary as migration taskset doesn't
    include tasks which are already in the target cgroup.  Drop @skip_css
    from cgroup_taskset_for_each().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Cc: Daniel Borkmann <dborkman@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3bd0a7138371..581a124c7bc8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -535,15 +535,11 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
 /**
  * cgroup_taskset_for_each - iterate cgroup_taskset
  * @task: the loop cursor
- * @skip_css: skip if task's css matches this, %NULL to iterate through all
  * @tset: taskset to iterate
  */
-#define cgroup_taskset_for_each(task, skip_css, tset)			\
+#define cgroup_taskset_for_each(task, tset)				\
 	for ((task) = cgroup_taskset_first((tset)); (task);		\
-	     (task) = cgroup_taskset_next((tset)))			\
-		if (!(skip_css) ||					\
-		    cgroup_taskset_cur_css((tset),			\
-			(skip_css)->ss->id) != (skip_css))
+	     (task) = cgroup_taskset_next((tset)))
 
 /*
  * Control Group subsystem type.

commit 889ed9ceaa97bb02bf5d7349e24639f7fc5f4fa0
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Feb 13 06:58:40 2014 -0500

    cgroup: remove css_scan_tasks()
    
    css_scan_tasks() doesn't have any user left.  Remove it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 72154fb44fb5..3bd0a7138371 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -14,7 +14,6 @@
 #include <linux/rcupdate.h>
 #include <linux/rculist.h>
 #include <linux/cgroupstats.h>
-#include <linux/prio_heap.h>
 #include <linux/rwsem.h>
 #include <linux/idr.h>
 #include <linux/workqueue.h>
@@ -813,11 +812,6 @@ void css_task_iter_start(struct cgroup_subsys_state *css,
 struct task_struct *css_task_iter_next(struct css_task_iter *it);
 void css_task_iter_end(struct css_task_iter *it);
 
-int css_scan_tasks(struct cgroup_subsys_state *css,
-		   bool (*test)(struct task_struct *, void *),
-		   void (*process)(struct task_struct *, void *),
-		   void *data, struct ptr_heap *heap);
-
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 

commit 07bc356ed2950048d33d667e933e1b913c6e6b6d
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Feb 13 06:58:39 2014 -0500

    cgroup: implement cgroup_has_tasks() and unexport cgroup_task_count()
    
    cgroup_task_count() read-locks css_set_lock and walks all tasks to
    count them and then returns the result.  The only thing all the users
    want is determining whether the cgroup is empty or not.  This patch
    implements cgroup_has_tasks() which tests whether cgroup->cset_links
    is empty, replaces all cgroup_task_count() usages and unexports it.
    
    Note that the test isn't synchronized.  This is the same as before.
    The test has always been racy.
    
    This will help planned css_set locking update.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e2ffcdc26cb7..72154fb44fb5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -457,6 +457,12 @@ static inline bool cgroup_sane_behavior(const struct cgroup *cgrp)
 	return cgrp->root->flags & CGRP_ROOT_SANE_BEHAVIOR;
 }
 
+/* no synchronization, the result can only be used as a hint */
+static inline bool cgroup_has_tasks(struct cgroup *cgrp)
+{
+	return !list_empty(&cgrp->cset_links);
+}
+
 /* returns ino associated with a cgroup, 0 indicates unmounted root */
 static inline ino_t cgroup_ino(struct cgroup *cgrp)
 {
@@ -516,8 +522,6 @@ int cgroup_rm_cftypes(struct cftype *cfts);
 
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 
-int cgroup_task_count(const struct cgroup *cgrp);
-
 /*
  * Control Group taskset, used to pass around set of tasks to cgroup_subsys
  * methods.

commit 35585573055f37837eb752ee22eb5523682ca742
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Feb 13 06:58:38 2014 -0500

    cgroup: drop CGRP_ROOT_SUBSYS_BOUND
    
    Before kernfs conversion, due to the way super_block lookup works,
    cgroup roots were created and made visible before being fully
    initialized.  This in turn required a special flag to mark that the
    root hasn't been fully initialized so that the destruction path can
    tell fully bound ones from half initialized.
    
    That flag is CGRP_ROOT_SUBSYS_BOUND and no longer necessary after the
    kernfs conversion as the lookup and creation of new root are atomic
    w.r.t. cgroup_mutex.  This patch removes the flag and passes the
    requests subsystem mask to cgroup_setup_root() so that it can set the
    respective mask bits as subsystems are bound.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5f669ca0ee36..e2ffcdc26cb7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -267,8 +267,6 @@ enum {
 
 	/* mount options live below bit 16 */
 	CGRP_ROOT_OPTION_MASK	= (1 << 16) - 1,
-
-	CGRP_ROOT_SUBSYS_BOUND	= (1 << 16), /* subsystems finished binding */
 };
 
 /*

commit d3ba07c3aa9ae3e03329b0a7f1a067c0647aa2af
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Feb 13 06:58:38 2014 -0500

    cgroup: disallow xattr, release_agent and name if sane_behavior
    
    Disallow more mount options if sane_behavior.  Note that xattr used to
    generate warning.
    
    While at it, simplify option check in cgroup_mount() and update
    sane_behavior comment in cgroup.h.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 298d616e8f40..5f669ca0ee36 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -227,8 +227,8 @@ enum {
 	 *
 	 * The followings are the behaviors currently affected this flag.
 	 *
-	 * - Mount options "noprefix" and "clone_children" are disallowed.
-	 *   Also, cgroupfs file cgroup.clone_children is not created.
+	 * - Mount options "noprefix", "xattr", "clone_children",
+	 *   "release_agent" and "name" are disallowed.
 	 *
 	 * - When mounting an existing superblock, mount options should
 	 *   match.
@@ -246,7 +246,7 @@ enum {
 	 * - "release_agent" and "notify_on_release" are removed.
 	 *   Replacement notification mechanism will be implemented.
 	 *
-	 * - "xattr" mount option is deprecated.  kernfs always enables it.
+	 * - "cgroup.clone_children" is removed.
 	 *
 	 * - cpuset: tasks will be kept in empty cpusets when hotplug happens
 	 *   and take masks of ancestors with non-empty cpus/mems, instead of

commit 776f02fa4e1ad70557c0318c70ce928e0642bee0
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 12 09:29:50 2014 -0500

    cgroup: remove cgroupfs_root->refcnt
    
    Currently, cgroupfs_root and its ->top_cgroup are separated reference
    counted and the latter's is ignored.  There's no reason to do this
    separately.  This patch removes cgroupfs_root->refcnt and destroys
    cgroupfs_root when the top_cgroup is released.
    
    * cgroup_put() updated to ignore cgroup_is_dead() test for top
      cgroups.  cgroup_free_fn() updated to handle root destruction when
      releasing a top cgroup.
    
    * As root destruction is now bounced through cgroup destruction, it is
      asynchronous.  Update cgroup_mount() so that it waits for pending
      release which is currently implemented using msleep().  Converting
      this to proper wait_queue isn't hard but likely unnecessary.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f0e6105bbbc1..298d616e8f40 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -282,12 +282,10 @@ struct cgroupfs_root {
 	/* The bitmask of subsystems attached to this hierarchy */
 	unsigned long subsys_mask;
 
-	atomic_t refcnt;
-
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
 
-	/* The root cgroup for this hierarchy */
+	/* The root cgroup.  Root is destroyed on its release. */
 	struct cgroup top_cgroup;
 
 	/* Number of cgroups in the hierarchy, used only for /proc/cgroups */

commit 3c9c825b8b50de7dbb015e6bfc04bb2da79364d9
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 12 09:29:50 2014 -0500

    cgroup: rename cgroupfs_root->number_of_cgroups to ->nr_cgrps and make it atomic_t
    
    root->number_of_cgroups is currently an integer protected with
    cgroup_mutex.  Except for sanity checks and proc reporting, the only
    place it's used is to check whether the root has any child during
    remount; however, this is a bit flawed as the counter is not
    decremented when the cgroup is unlinked but when it's released,
    meaning that there could be an extended period where all cgroups are
    removed but remount is still not allowed because some internal objects
    are lingering.  While not perfect either, it'd be better to use
    emptiness test on root->top_cgroup.children.
    
    This patch updates cgroup_remount() to test top_cgroup's children
    instead, which makes number_of_cgroups only actual usage statistics
    printing in proc implemented in proc_cgroupstats_show().  Let's
    shorten its name and make it an atomic_t so that we don't have to
    worry about its synchronization.  It's purely auxiliary at this point.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4d6ff7d40cf6..f0e6105bbbc1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -290,8 +290,8 @@ struct cgroupfs_root {
 	/* The root cgroup for this hierarchy */
 	struct cgroup top_cgroup;
 
-	/* Tracks how many cgroups are currently defined in hierarchy.*/
-	int number_of_cgroups;
+	/* Number of cgroups in the hierarchy, used only for /proc/cgroups */
+	atomic_t nr_cgrps;
 
 	/* A list running through the active hierarchies */
 	struct list_head root_list;

commit e61734c55c24cdf11b07e52a74aec4dc4a7f4bd0
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 12 09:29:50 2014 -0500

    cgroup: remove cgroup->name
    
    cgroup->name handling became quite complicated over time involving
    dedicated struct cgroup_name for RCU protection.  Now that cgroup is
    on kernfs, we can drop all of it and simply use kernfs_name/path() and
    friends.  Replace cgroup->name and all related code with kernfs
    name/path constructs.
    
    * Reimplement cgroup_name() and cgroup_path() as thin wrappers on top
      of kernfs counterparts, which involves semantic changes.
      pr_cont_cgroup_name() and pr_cont_cgroup_path() added.
    
    * cgroup->name handling dropped from cgroup_rename().
    
    * All users of cgroup_name/path() updated to the new semantics.  Users
      which were formatting the string just to printk them are converted
      to use pr_cont_cgroup_name/path() instead, which simplifies things
      quite a bit.  As cgroup_name() no longer requires RCU read lock
      around it, RCU lockings which were protecting only cgroup_name() are
      removed.
    
    v2: Comment above oom_info_lock updated as suggested by Michal.
    
    v3: dummy_top doesn't have a kn associated and
        pr_cont_cgroup_name/path() ended up calling the matching kernfs
        functions with NULL kn leading to oops.  Test for NULL kn and
        print "/" if so.  This issue was reported by Fengguang Wu.
    
    v4: Rebased on top of 0ab02ca8f887 ("cgroup: protect modifications to
        cgroup_idr with cgroup_mutex").
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b42251a23129..4d6ff7d40cf6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -138,11 +138,6 @@ enum {
 	CGRP_SANE_BEHAVIOR,
 };
 
-struct cgroup_name {
-	struct rcu_head rcu_head;
-	char name[];
-};
-
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
@@ -179,19 +174,6 @@ struct cgroup {
 	 */
 	u64 serial_nr;
 
-	/*
-	 * This is a copy of dentry->d_name, and it's needed because
-	 * we can't use dentry->d_name in cgroup_path().
-	 *
-	 * You must acquire rcu_read_lock() to access cgrp->name, and
-	 * the only place that can change it is rename(), which is
-	 * protected by parent dir's i_mutex.
-	 *
-	 * Normally you should use cgroup_name() wrapper rather than
-	 * access it directly.
-	 */
-	struct cgroup_name __rcu *name;
-
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state __rcu *subsys[CGROUP_SUBSYS_COUNT];
 
@@ -479,12 +461,6 @@ static inline bool cgroup_sane_behavior(const struct cgroup *cgrp)
 	return cgrp->root->flags & CGRP_ROOT_SANE_BEHAVIOR;
 }
 
-/* Caller should hold rcu_read_lock() */
-static inline const char *cgroup_name(const struct cgroup *cgrp)
-{
-	return rcu_dereference(cgrp->name)->name;
-}
-
 /* returns ino associated with a cgroup, 0 indicates unmounted root */
 static inline ino_t cgroup_ino(struct cgroup *cgrp)
 {
@@ -503,14 +479,47 @@ static inline struct cftype *seq_cft(struct seq_file *seq)
 
 struct cgroup_subsys_state *seq_css(struct seq_file *seq);
 
+/*
+ * Name / path handling functions.  All are thin wrappers around the kernfs
+ * counterparts and can be called under any context.
+ */
+
+static inline int cgroup_name(struct cgroup *cgrp, char *buf, size_t buflen)
+{
+	return kernfs_name(cgrp->kn, buf, buflen);
+}
+
+static inline char * __must_check cgroup_path(struct cgroup *cgrp, char *buf,
+					      size_t buflen)
+{
+	return kernfs_path(cgrp->kn, buf, buflen);
+}
+
+static inline void pr_cont_cgroup_name(struct cgroup *cgrp)
+{
+	/* dummy_top doesn't have a kn associated */
+	if (cgrp->kn)
+		pr_cont_kernfs_name(cgrp->kn);
+	else
+		pr_cont("/");
+}
+
+static inline void pr_cont_cgroup_path(struct cgroup *cgrp)
+{
+	/* dummy_top doesn't have a kn associated */
+	if (cgrp->kn)
+		pr_cont_kernfs_path(cgrp->kn);
+	else
+		pr_cont("/");
+}
+
+char *task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
+
 int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cftype *cfts);
 
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 
-int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
-int task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
-
 int cgroup_task_count(const struct cgroup *cgrp);
 
 /*

commit 0adb070426dde2fd0b84e7f4f5cefcd8f0b24410
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 12 09:29:48 2014 -0500

    cgroup: remove cftype_set
    
    cftype_set was added primarily to allow registering the same cftype
    array more than once for different subsystems.  Nobody uses or needs
    such thing and it's already broken because each cftype has ->ss
    pointer which is initialized during registration.
    
    Let's add list_head ->node to cftype and use the first cftype entry in
    the array to link them instead of allocating separate cftype_set.
    While at it, trigger WARN if cft seems previously initialized during
    registration.
    
    This simplifies cftype handling a bit.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 305e94ee17f5..b42251a23129 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -412,12 +412,11 @@ struct cftype {
 	unsigned int flags;
 
 	/*
-	 * The subsys this file belongs to.  Initialized automatically
-	 * during registration.  NULL for cgroup core files.
+	 * Fields used for internal bookkeeping.  Initialized automatically
+	 * during registration.
 	 */
-	struct cgroup_subsys *ss;
-
-	/* kernfs_ops to use, initialized automatically during registration */
+	struct cgroup_subsys *ss;	/* NULL for cgroup core files */
+	struct list_head node;		/* anchored at ss->cfts */
 	struct kernfs_ops *kf_ops;
 
 	/*
@@ -471,16 +470,6 @@ struct cftype {
 #endif
 };
 
-/*
- * cftype_sets describe cftypes belonging to a subsystem and are chained at
- * cgroup_subsys->cftsets.  Each cftset points to an array of cftypes
- * terminated by zero length name.
- */
-struct cftype_set {
-	struct list_head		node;	/* chained at subsys->cftsets */
-	struct cftype			*cfts;
-};
-
 /*
  * See the comment above CGRP_ROOT_SANE_BEHAVIOR for details.  This
  * function can be called as long as @cgrp is accessible.
@@ -597,8 +586,11 @@ struct cgroup_subsys {
 	/* link to parent, protected by cgroup_lock() */
 	struct cgroupfs_root *root;
 
-	/* list of cftype_sets */
-	struct list_head cftsets;
+	/*
+	 * List of cftypes.  Each entry is the first entry of an array
+	 * terminated by zero length name.
+	 */
+	struct list_head cfts;
 
 	/* base cftypes, automatically registered with subsys itself */
 	struct cftype *base_cftypes;

commit 86bf4b68759141459864ebd36ac3038a9cda895b
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 12 09:29:48 2014 -0500

    cgroup: warn if "xattr" is specified with "sane_behavior"
    
    Mount option "xattr" is no longer necessary as it's enabled by default
    on kernfs.  Warn if "xattr" is specified with "sane_behavior" so that
    the option can be removed in the future.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0e45a932b823..305e94ee17f5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -264,6 +264,8 @@ enum {
 	 * - "release_agent" and "notify_on_release" are removed.
 	 *   Replacement notification mechanism will be implemented.
 	 *
+	 * - "xattr" mount option is deprecated.  kernfs always enables it.
+	 *
 	 * - cpuset: tasks will be kept in empty cpusets when hotplug happens
 	 *   and take masks of ancestors with non-empty cpus/mems, instead of
 	 *   being moved to an ancestor.

commit 2bd59d48ebfb3df41ee56938946ca0dd30887312
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 11 11:52:49 2014 -0500

    cgroup: convert to kernfs
    
    cgroup filesystem code was derived from the original sysfs
    implementation which was heavily intertwined with vfs objects and
    locking with the goal of re-using the existing vfs infrastructure.
    That experiment turned out rather disastrous and sysfs switched, a
    long time ago, to distributed filesystem model where a separate
    representation is maintained which is queried by vfs.  Unfortunately,
    cgroup stuck with the failed experiment all these years and
    accumulated even more problems over time.
    
    Locking and object lifetime management being entangled with vfs is
    probably the most egregious.  vfs is never designed to be misused like
    this and cgroup ends up jumping through various convoluted dancing to
    make things work.  Even then, operations across multiple cgroups can't
    be done safely as it'll deadlock with rename locking.
    
    Recently, kernfs is separated out from sysfs so that it can be used by
    users other than sysfs.  This patch converts cgroup to use kernfs,
    which will bring the following benefits.
    
    * Separation from vfs internals.  Locking and object lifetime
      management is contained in cgroup proper making things a lot
      simpler.  This removes significant amount of locking convolutions,
      hairy object lifetime rules and the restriction on multi-cgroup
      operations.
    
    * Can drop a lot of code to implement filesystem interface as most are
      provided by kernfs.
    
    * Proper "severing" semantics, which allows controllers to not worry
      about lingering file accesses after offline.
    
    While the preceding patches did as much as possible to make the
    transition less painful, large part of the conversion has to be one
    discrete step making this patch rather large.  The rest of the commit
    message lists notable changes in different areas.
    
    Overall
    -------
    
    * vfs constructs replaced with kernfs ones.  cgroup->dentry w/ ->kn,
      cgroupfs_root->sb w/ ->kf_root.
    
    * All dentry accessors are removed.  Helpers to map from kernfs
      constructs are added.
    
    * All vfs plumbing around dentry, inode and bdi removed.
    
    * cgroup_mount() now directly looks for matching root and then
      proceeds to create a new one if not found.
    
    Synchronization and object lifetime
    -----------------------------------
    
    * vfs inode locking removed.  Among other things, this removes the
      need for the convolution in cgroup_cfts_commit().  Future patches
      will further simplify it.
    
    * vfs refcnting replaced with cgroup internal ones.  cgroup->refcnt,
      cgroupfs_root->refcnt added.  cgroup_put_root() now directly puts
      root->refcnt and when it reaches zero proceeds to destroy it thus
      merging cgroup_put_root() and the former cgroup_kill_sb().
      Simliarly, cgroup_put() now directly schedules cgroup_free_rcu()
      when refcnt reaches zero.
    
    * Unlike before, kernfs objects don't hold onto cgroup objects.  When
      cgroup destroys a kernfs node, all existing operations are drained
      and the association is broken immediately.  The same for
      cgroupfs_roots and mounts.
    
    * All operations which come through kernfs guarantee that the
      associated cgroup is and stays valid for the duration of operation;
      however, there are two paths which need to find out the associated
      cgroup from dentry without going through kernfs -
      css_tryget_from_dir() and cgroupstats_build().  For these two,
      kernfs_node->priv is RCU managed so that they can dereference it
      under RCU read lock.
    
    File and directory handling
    ---------------------------
    
    * File and directory operations converted to kernfs_ops and
      kernfs_syscall_ops.
    
    * xattrs is implicitly supported by kernfs.  No need to worry about it
      from cgroup.  This means that "xattr" mount option is no longer
      necessary.  A future patch will add a deprecated warning message
      when sane_behavior.
    
    * When cftype->max_write_len > PAGE_SIZE, it's necessary to make a
      private copy of one of the kernfs_ops to set its atomic_write_len.
      cftype->kf_ops is added and cgroup_init/exit_cftypes() are updated
      to handle it.
    
    * cftype->lockdep_key added so that kernfs lockdep annotation can be
      per cftype.
    
    * Inidividual file entries and open states are now managed by kernfs.
      No need to worry about them from cgroup.  cfent, cgroup_open_file
      and their friends are removed.
    
    * kernfs_nodes are created deactivated and kernfs_activate()
      invocations added to places where creation of new nodes are
      committed.
    
    * cgroup_rmdir() uses kernfs_[un]break_active_protection() for
      self-removal.
    
    v2: - Li pointed out in an earlier patch that specifying "name="
          during mount without subsystem specification should succeed if
          there's an existing hierarchy with a matching name although it
          should fail with -EINVAL if a new hierarchy should be created.
          Prior to the conversion, this used by handled by deferring
          failure from NULL return from cgroup_root_from_opts(), which was
          necessary because root was being created before checking for
          existing ones.  Note that cgroup_root_from_opts() returned an
          ERR_PTR() value for error conditions which require immediate
          mount failure.
    
          As we now have separate search and creation steps, deferring
          failure from cgroup_root_from_opts() is no longer necessary.
          cgroup_root_from_opts() is updated to always return ERR_PTR()
          value on failure.
    
        - The logic to match existing roots is updated so that a mount
          attempt with a matching name but different subsys_mask are
          rejected.  This was handled by a separate matching loop under
          the comment "Check for name clashes with existing mounts" but
          got lost during conversion.  Merge the check into the main
          search loop.
    
        - Add __rcu __force casting in RCU_INIT_POINTER() in
          cgroup_destroy_locked() to avoid the sparse address space
          warning reported by kbuild test bot.  Maybe we want an explicit
          interface to use kn->priv as RCU protected pointer?
    
    v3: Make CONFIG_CGROUPS select CONFIG_KERNFS.
    
    v4: Rebased on top of 0ab02ca8f887 ("cgroup: protect modifications to
        cgroup_idr with cgroup_mutex").
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: kbuild test robot fengguang.wu@intel.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 523277871913..0e45a932b823 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -18,10 +18,10 @@
 #include <linux/rwsem.h>
 #include <linux/idr.h>
 #include <linux/workqueue.h>
-#include <linux/xattr.h>
 #include <linux/fs.h>
 #include <linux/percpu-refcount.h>
 #include <linux/seq_file.h>
+#include <linux/kernfs.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -159,16 +159,17 @@ struct cgroup {
 	/* the number of attached css's */
 	int nr_css;
 
+	atomic_t refcnt;
+
 	/*
 	 * We link our 'sibling' struct into our parent's 'children'.
 	 * Our children link their 'sibling' into our 'children'.
 	 */
 	struct list_head sibling;	/* my parent's children */
 	struct list_head children;	/* my children */
-	struct list_head files;		/* my files */
 
 	struct cgroup *parent;		/* my parent */
-	struct dentry *dentry;		/* cgroup fs entry, RCU protected */
+	struct kernfs_node *kn;		/* cgroup kernfs entry */
 
 	/*
 	 * Monotonically increasing unique serial number which defines a
@@ -222,9 +223,6 @@ struct cgroup {
 	/* For css percpu_ref killing and RCU-protected deletion */
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
-
-	/* directory xattrs */
-	struct simple_xattrs xattrs;
 };
 
 #define MAX_CGROUP_ROOT_NAMELEN 64
@@ -291,15 +289,17 @@ enum {
 
 /*
  * A cgroupfs_root represents the root of a cgroup hierarchy, and may be
- * associated with a superblock to form an active hierarchy.  This is
+ * associated with a kernfs_root to form an active hierarchy.  This is
  * internal to cgroup core.  Don't access directly from controllers.
  */
 struct cgroupfs_root {
-	struct super_block *sb;
+	struct kernfs_root *kf_root;
 
 	/* The bitmask of subsystems attached to this hierarchy */
 	unsigned long subsys_mask;
 
+	atomic_t refcnt;
+
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
 
@@ -415,6 +415,9 @@ struct cftype {
 	 */
 	struct cgroup_subsys *ss;
 
+	/* kernfs_ops to use, initialized automatically during registration */
+	struct kernfs_ops *kf_ops;
+
 	/*
 	 * read_u64() is a shortcut for the common case of returning a
 	 * single integer. Use it in place of read()
@@ -460,6 +463,10 @@ struct cftype {
 	 * kick type for multiplexing.
 	 */
 	int (*trigger)(struct cgroup_subsys_state *css, unsigned int event);
+
+#ifdef CONFIG_DEBUG_LOCK_ALLOC
+	struct lock_class_key	lockdep_key;
+#endif
 };
 
 /*
@@ -472,26 +479,6 @@ struct cftype_set {
 	struct cftype			*cfts;
 };
 
-/*
- * cgroupfs file entry, pointed to from leaf dentry->d_fsdata.  Don't
- * access directly.
- */
-struct cfent {
-	struct list_head		node;
-	struct dentry			*dentry;
-	struct cftype			*type;
-	struct cgroup_subsys_state	*css;
-
-	/* file xattrs */
-	struct simple_xattrs		xattrs;
-};
-
-/* seq_file->private points to the following, only ->priv is public */
-struct cgroup_open_file {
-	struct cfent			*cfe;
-	void				*priv;
-};
-
 /*
  * See the comment above CGRP_ROOT_SANE_BEHAVIOR for details.  This
  * function can be called as long as @cgrp is accessible.
@@ -510,16 +497,17 @@ static inline const char *cgroup_name(const struct cgroup *cgrp)
 /* returns ino associated with a cgroup, 0 indicates unmounted root */
 static inline ino_t cgroup_ino(struct cgroup *cgrp)
 {
-	if (cgrp->dentry)
-		return cgrp->dentry->d_inode->i_ino;
+	if (cgrp->kn)
+		return cgrp->kn->ino;
 	else
 		return 0;
 }
 
 static inline struct cftype *seq_cft(struct seq_file *seq)
 {
-	struct cgroup_open_file *of = seq->private;
-	return of->cfe->type;
+	struct kernfs_open_file *of = seq->private;
+
+	return of->kn->priv;
 }
 
 struct cgroup_subsys_state *seq_css(struct seq_file *seq);

commit 59f5296b51b86718dd6eecf0a268b2f1a1ec0a2d
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 11 11:52:49 2014 -0500

    cgroup: misc preps for kernfs conversion
    
    * Un-inline seq_css().  After kernfs conversion, the function will
      need to dereference internal data structures.
    
    * Add cgroup_get/put_root() and replace direct super_block->s_active
      manipulatinos with them.  These will be converted to kernfs_root
      refcnting.
    
    * Add cgroup_get/put() and replace dget/put() on cgrp->dentry with
      them.  These will be converted to kernfs refcnting.
    
    * Update current_css_set_cg_links_read() to use cgroup_name() instead
      of reaching into the dentry name.  The end result is the same.
    
    These changes don't make functional differences but will make
    transition to kernfs easier.
    
    v2: Rebased on top of 0ab02ca8f887 ("cgroup: protect modifications to
        cgroup_idr with cgroup_mutex").
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 06f577764414..523277871913 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -516,18 +516,14 @@ static inline ino_t cgroup_ino(struct cgroup *cgrp)
 		return 0;
 }
 
-static inline struct cgroup_subsys_state *seq_css(struct seq_file *seq)
-{
-	struct cgroup_open_file *of = seq->private;
-	return of->cfe->css;
-}
-
 static inline struct cftype *seq_cft(struct seq_file *seq)
 {
 	struct cgroup_open_file *of = seq->private;
 	return of->cfe->type;
 }
 
+struct cgroup_subsys_state *seq_css(struct seq_file *seq);
+
 int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cftype *cfts);
 

commit b1664924062393bb048203bd4622e0b1c9e1d328
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 11 11:52:49 2014 -0500

    cgroup: introduce cgroup_ino()
    
    mm/memory-failure.c::hwpoison_filter_task() has been reaching into
    cgroup to extract the associated ino to be used as a filtering
    criterion.  This is an implementation detail which shouldn't be
    depended upon from outside cgroup proper and is about to change with
    the scheduled kernfs conversion.
    
    This patch introduces a proper interface to determine the associated
    ino, cgroup_ino(), and updates hwpoison_filter_task() to use it
    instead of reaching directly into cgroup.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Wu Fengguang <fengguang.wu@intel.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 63feaed83bc6..06f577764414 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -507,6 +507,15 @@ static inline const char *cgroup_name(const struct cgroup *cgrp)
 	return rcu_dereference(cgrp->name)->name;
 }
 
+/* returns ino associated with a cgroup, 0 indicates unmounted root */
+static inline ino_t cgroup_ino(struct cgroup *cgrp)
+{
+	if (cgrp->dentry)
+		return cgrp->dentry->d_inode->i_ino;
+	else
+		return 0;
+}
+
 static inline struct cgroup_subsys_state *seq_css(struct seq_file *seq)
 {
 	struct cgroup_open_file *of = seq->private;

commit 5f46990787e2721b4db190ddc8af6fdbe8f010d7
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 11 11:52:48 2014 -0500

    cgroup: update the meaning of cftype->max_write_len
    
    cftype->max_write_len is used to extend the maximum size of writes.
    It's interpreted in such a way that the actual maximum size is one
    less than the specified value.  The default size is defined by
    CGROUP_LOCAL_BUFFER_SIZE.  Its interpretation is quite confusing - its
    value is decremented by 1 and then compared for equality with max
    size, which means that the actual default size is
    CGROUP_LOCAL_BUFFER_SIZE - 2, which is 62 chars.
    
    There's no point in having a limit that low.  Update its definition so
    that it means the actual string length sans termination and anything
    below PAGE_SIZE-1 is treated as PAGE_SIZE-1.
    
    .max_write_len for "release_agent" is updated to PATH_MAX-1 and
    cgroup_release_agent_write() is updated so that the redundant strlen()
    check is removed and it uses strlcpy() instead of strcpy().
    .max_write_len initializations in blk-throttle.c and cfq-iosched.c are
    no longer necessary and removed.  The one in cpuset is kept unchanged
    as it's an approximated value to begin with.
    
    This will also make transition to kernfs smoother.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c4350a82320b..63feaed83bc6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -400,8 +400,9 @@ struct cftype {
 	umode_t mode;
 
 	/*
-	 * If non-zero, defines the maximum length of string that can
-	 * be passed to write_string; defaults to 64
+	 * The maximum length of string, excluding trailing nul, that can
+	 * be passed to write_string.  If < PAGE_SIZE-1, PAGE_SIZE-1 is
+	 * assumed.
 	 */
 	size_t max_write_len;
 

commit de00ffa56ea3132c6013fc8f07133b8a1014cf53
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 11 11:52:48 2014 -0500

    cgroup: make cgroup_subsys->base_cftypes use cgroup_add_cftypes()
    
    Currently, cgroup_subsys->base_cftypes registration is different from
    dynamic cftypes registartion.  Instead of going through
    cgroup_add_cftypes(), cgroup_init_subsys() invokes
    cgroup_init_cftsets() which makes use of cgroup_subsys->base_cftset
    which doesn't involve dynamic allocation.
    
    While avoiding dynamic allocation is somewhat nice, having two
    separate paths for cftypes registration is nasty, especially as we're
    planning to add more operations during cftypes registration.
    
    This patch drops cgroup_init_cftsets() and cgroup_subsys->base_cftset
    and registers base_cftypes using cgroup_add_cftypes().  This is done
    as a separate step in cgroup_init() instead of a part of
    cgroup_init_subsys().  This is because cgroup_init_subsys() can be
    called very early during boot when kmalloc() isn't available yet.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1ba4fc08f776..c4350a82320b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -604,9 +604,8 @@ struct cgroup_subsys {
 	/* list of cftype_sets */
 	struct list_head cftsets;
 
-	/* base cftypes, automatically [de]registered with subsys itself */
+	/* base cftypes, automatically registered with subsys itself */
 	struct cftype *base_cftypes;
-	struct cftype_set base_cftset;
 };
 
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _cgrp_subsys;

commit 5a17f543ed6808e9085063277fe46795dea484bd
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 11 11:52:47 2014 -0500

    cgroup: improve css_from_dir() into css_tryget_from_dir()
    
    css_from_dir() returns the matching css (cgroup_subsys_state) given a
    dentry and subsystem.  The function doesn't pin the css before
    returning and requires the caller to be holding RCU read lock or
    cgroup_mutex and handling pinning on the caller side.
    
    Given that users of the function are likely to want to pin the
    returned css (both existing users do) and that getting and putting
    css's are very cheap, there's no reason for the interface to be tricky
    like this.
    
    Rename css_from_dir() to css_tryget_from_dir() and make it try to pin
    the found css and return it only if pinning succeeded.  The callers
    are updated so that they no longer do RCU locking and pinning around
    the function and just use the returned css.
    
    This will also ease converting cgroup to kernfs.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c86ba7ff7a7e..1ba4fc08f776 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -825,8 +825,8 @@ int css_scan_tasks(struct cgroup_subsys_state *css,
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 
-struct cgroup_subsys_state *css_from_dir(struct dentry *dentry,
-					 struct cgroup_subsys *ss);
+struct cgroup_subsys_state *css_tryget_from_dir(struct dentry *dentry,
+						struct cgroup_subsys *ss);
 
 #else /* !CONFIG_CGROUPS */
 

commit 398f878789fceb51bf5e424b753a3756643513c4
Merge: f7cef064aa01 0ab02ca8f887
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 11 11:02:59 2014 -0500

    Merge branch 'cgroup/for-3.14-fixes' into cgroup/for-3.15
    
    Pull for-3.14-fixes to receive 0ab02ca8f887 ("cgroup: protect
    modifications to cgroup_idr with cgroup_mutex") prior to kernfs
    conversion series to avoid non-trivial conflicts.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit 0ab02ca8f887908152d1a96db5130fc661d36a1e
Author: Li Zefan <lizefan@huawei.com>
Date:   Tue Feb 11 16:05:46 2014 +0800

    cgroup: protect modifications to cgroup_idr with cgroup_mutex
    
    Setup cgroupfs like this:
      # mount -t cgroup -o cpuacct xxx /cgroup
      # mkdir /cgroup/sub1
      # mkdir /cgroup/sub2
    
    Then run these two commands:
      # for ((; ;)) { mkdir /cgroup/sub1/tmp && rmdir /mnt/sub1/tmp; } &
      # for ((; ;)) { mkdir /cgroup/sub2/tmp && rmdir /mnt/sub2/tmp; } &
    
    After seconds you may see this warning:
    
    ------------[ cut here ]------------
    WARNING: CPU: 1 PID: 25243 at lib/idr.c:527 sub_remove+0x87/0x1b0()
    idr_remove called for id=6 which is not allocated.
    ...
    Call Trace:
     [<ffffffff8156063c>] dump_stack+0x7a/0x96
     [<ffffffff810591ac>] warn_slowpath_common+0x8c/0xc0
     [<ffffffff81059296>] warn_slowpath_fmt+0x46/0x50
     [<ffffffff81300aa7>] sub_remove+0x87/0x1b0
     [<ffffffff810f3f02>] ? css_killed_work_fn+0x32/0x1b0
     [<ffffffff81300bf5>] idr_remove+0x25/0xd0
     [<ffffffff810f2bab>] cgroup_destroy_css_killed+0x5b/0xc0
     [<ffffffff810f4000>] css_killed_work_fn+0x130/0x1b0
     [<ffffffff8107cdbc>] process_one_work+0x26c/0x550
     [<ffffffff8107eefe>] worker_thread+0x12e/0x3b0
     [<ffffffff81085f96>] kthread+0xe6/0xf0
     [<ffffffff81570bac>] ret_from_fork+0x7c/0xb0
    ---[ end trace 2d1577ec10cf80d0 ]---
    
    It's because allocating/removing cgroup ID is not properly synchronized.
    
    The bug was introduced when we converted cgroup_ida to cgroup_idr.
    While synchronization is already done inside ida_simple_{get,remove}(),
    users are responsible for concurrent calls to idr_{alloc,remove}().
    
    tj: Refreshed on top of b58c89986a77 ("cgroup: fix error return from
    cgroup_create()").
    
    Fixes: 4e96ee8e981b ("cgroup: convert cgroup_ida to cgroup_idr")
    Cc: <stable@vger.kernel.org> #3.12+
    Reported-by: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5c097596104b..9450f025fe0c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -166,6 +166,8 @@ struct cgroup {
 	 *
 	 * The ID of the root cgroup is always 0, and a new cgroup
 	 * will be assigned with a smallest available ID.
+	 *
+	 * Allocating/Removing ID must be protected by cgroup_mutex.
 	 */
 	int id;
 

commit aec25020f5d4b69aea5317551d1cb7043f6b04fb
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Feb 8 10:36:58 2014 -0500

    cgroup: rename cgroup_subsys->subsys_id to ->id
    
    It's no longer referenced outside cgroup core, so renaming is easy.
    Let's rename it for consistency & brevity.
    
    This patch is pure rename.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cd6611e622fd..198c7fcd727e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -548,7 +548,7 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
 	     (task) = cgroup_taskset_next((tset)))			\
 		if (!(skip_css) ||					\
 		    cgroup_taskset_cur_css((tset),			\
-			(skip_css)->ss->subsys_id) != (skip_css))
+			(skip_css)->ss->id) != (skip_css))
 
 /*
  * Control Group subsystem type.
@@ -592,7 +592,7 @@ struct cgroup_subsys {
 	bool warned_broken_hierarchy;
 
 	/* the following two fields are initialized automtically during boot */
-	int subsys_id;
+	int id;
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 

commit 073219e995b4a3f8cf1ce8228b7ef440b6994ac0
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Feb 8 10:36:58 2014 -0500

    cgroup: clean up cgroup_subsys names and initialization
    
    cgroup_subsys is a bit messier than it needs to be.
    
    * The name of a subsys can be different from its internal identifier
      defined in cgroup_subsys.h.  Most subsystems use the matching name
      but three - cpu, memory and perf_event - use different ones.
    
    * cgroup_subsys_id enums are postfixed with _subsys_id and each
      cgroup_subsys is postfixed with _subsys.  cgroup.h is widely
      included throughout various subsystems, it doesn't and shouldn't
      have claim on such generic names which don't have any qualifier
      indicating that they belong to cgroup.
    
    * cgroup_subsys->subsys_id should always equal the matching
      cgroup_subsys_id enum; however, we require each controller to
      initialize it and then BUG if they don't match, which is a bit
      silly.
    
    This patch cleans up cgroup_subsys names and initialization by doing
    the followings.
    
    * cgroup_subsys_id enums are now postfixed with _cgrp_id, and each
      cgroup_subsys with _cgrp_subsys.
    
    * With the above, renaming subsys identifiers to match the userland
      visible names doesn't cause any naming conflicts.  All non-matching
      identifiers are renamed to match the official names.
    
      cpu_cgroup -> cpu
      mem_cgroup -> memory
      perf -> perf_event
    
    * controllers no longer need to initialize ->subsys_id and ->name.
      They're generated in cgroup core and set automatically during boot.
    
    * Redundant cgroup_subsys declarations removed.
    
    * While updating BUG_ON()s in cgroup_init_early(), convert them to
      WARN()s.  BUGging that early during boot is stupid - the kernel
      can't print anything, even through serial console and the trap
      handler doesn't even link stack frame properly for back-tracing.
    
    This patch doesn't introduce any behavior changes.
    
    v2: Rebased on top of fe1217c4f3f7 ("net: net_cls: move cgroupfs
        classid handling into core").
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: "David S. Miller" <davem@davemloft.net>
    Acked-by: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Aristeu Rozanski <aris@redhat.com>
    Acked-by: Ingo Molnar <mingo@redhat.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Thomas Graf <tgraf@suug.ch>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d842a737d448..cd6611e622fd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -41,7 +41,7 @@ extern int cgroupstats_build(struct cgroupstats *stats,
 extern int proc_cgroup_show(struct seq_file *, void *);
 
 /* define the enumeration of all cgroup subsystems */
-#define SUBSYS(_x) _x ## _subsys_id,
+#define SUBSYS(_x) _x ## _cgrp_id,
 enum cgroup_subsys_id {
 #include <linux/cgroup_subsys.h>
 	CGROUP_SUBSYS_COUNT,
@@ -573,7 +573,6 @@ struct cgroup_subsys {
 		     struct task_struct *task);
 	void (*bind)(struct cgroup_subsys_state *root_css);
 
-	int subsys_id;
 	int disabled;
 	int early_init;
 
@@ -592,6 +591,8 @@ struct cgroup_subsys {
 	bool broken_hierarchy;
 	bool warned_broken_hierarchy;
 
+	/* the following two fields are initialized automtically during boot */
+	int subsys_id;
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 
@@ -606,7 +607,7 @@ struct cgroup_subsys {
 	struct cftype_set base_cftset;
 };
 
-#define SUBSYS(_x) extern struct cgroup_subsys _x ## _subsys;
+#define SUBSYS(_x) extern struct cgroup_subsys _x ## _cgrp_subsys;
 #include <linux/cgroup_subsys.h>
 #undef SUBSYS
 

commit 3ed80a62bf959d34ebd4d553b026fbe7e6fbcc54
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Feb 8 10:36:58 2014 -0500

    cgroup: drop module support
    
    With module supported dropped from net_prio, no controller is using
    cgroup module support.  None of actual resource controllers can be
    built as a module and we aren't gonna add new controllers which don't
    control resources.  This patch drops module support from cgroup.
    
    * cgroup_[un]load_subsys() and cgroup_subsys->module removed.
    
    * As there's no point in distinguishing IS_BUILTIN() and IS_MODULE(),
      cgroup_subsys.h now uses IS_ENABLED() directly.
    
    * enum cgroup_subsys_id now exactly matches the list of enabled
      controllers as ordered in cgroup_subsys.h.
    
    * cgroup_subsys[] is now a contiguously occupied array.  Size
      specification is no longer necessary and dropped.
    
    * for_each_builtin_subsys() is removed and for_each_subsys() is
      updated to not require any locking.
    
    * module ref handling is removed from rebind_subsystems().
    
    * Module related comments dropped.
    
    v2: Rebased on top of fe1217c4f3f7 ("net: net_cls: move cgroupfs
        classid handling into core").
    
    v3: Added {} around the if (need_forkexit_callback) block in
        cgroup_post_fork() for readability as suggested by Li.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5c097596104b..d842a737d448 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -37,28 +37,13 @@ extern void cgroup_post_fork(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 extern int cgroupstats_build(struct cgroupstats *stats,
 				struct dentry *dentry);
-extern int cgroup_load_subsys(struct cgroup_subsys *ss);
-extern void cgroup_unload_subsys(struct cgroup_subsys *ss);
 
 extern int proc_cgroup_show(struct seq_file *, void *);
 
-/*
- * Define the enumeration of all cgroup subsystems.
- *
- * We define ids for builtin subsystems and then modular ones.
- */
+/* define the enumeration of all cgroup subsystems */
 #define SUBSYS(_x) _x ## _subsys_id,
 enum cgroup_subsys_id {
-#define IS_SUBSYS_ENABLED(option) IS_BUILTIN(option)
 #include <linux/cgroup_subsys.h>
-#undef IS_SUBSYS_ENABLED
-	CGROUP_BUILTIN_SUBSYS_COUNT,
-
-	__CGROUP_SUBSYS_TEMP_PLACEHOLDER = CGROUP_BUILTIN_SUBSYS_COUNT - 1,
-
-#define IS_SUBSYS_ENABLED(option) IS_MODULE(option)
-#include <linux/cgroup_subsys.h>
-#undef IS_SUBSYS_ENABLED
 	CGROUP_SUBSYS_COUNT,
 };
 #undef SUBSYS
@@ -370,10 +355,9 @@ struct css_set {
 	struct list_head cgrp_links;
 
 	/*
-	 * Set of subsystem states, one for each subsystem. This array
-	 * is immutable after creation apart from the init_css_set
-	 * during subsystem registration (at boot time) and modular subsystem
-	 * loading/unloading.
+	 * Set of subsystem states, one for each subsystem. This array is
+	 * immutable after creation apart from the init_css_set during
+	 * subsystem registration (at boot time).
 	 */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
 
@@ -620,15 +604,10 @@ struct cgroup_subsys {
 	/* base cftypes, automatically [de]registered with subsys itself */
 	struct cftype *base_cftypes;
 	struct cftype_set base_cftset;
-
-	/* should be defined only by modular subsystems */
-	struct module *module;
 };
 
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _subsys;
-#define IS_SUBSYS_ENABLED(option) IS_BUILTIN(option)
 #include <linux/cgroup_subsys.h>
-#undef IS_SUBSYS_ENABLED
 #undef SUBSYS
 
 /**

commit b3ff8a2f9569fb41b9cf8902897d787a33bac84f
Author: Hugh Dickins <hughd@google.com>
Date:   Sun Jan 12 20:23:27 2014 -0800

    cgroup: remove stray references to css_id
    
    Trivial: remove the few stray references to css_id, which itself
    was removed in v3.13's 2ff2a7d03bbe "cgroup: kill css_id".
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cfaf416492dd..5c097596104b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -29,7 +29,6 @@ struct cgroupfs_root;
 struct cgroup_subsys;
 struct inode;
 struct cgroup;
-struct css_id;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
@@ -79,8 +78,6 @@ struct cgroup_subsys_state {
 	struct cgroup_subsys_state *parent;
 
 	unsigned long flags;
-	/* ID for this css, if possible */
-	struct css_id __rcu *id;
 
 	/* percpu_ref killing and RCU release */
 	struct rcu_head rcu_head;

commit b85d20404cef6493f9d2edbafe83f9c72aece9a8
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Dec 6 15:11:57 2013 -0500

    cgroup: remove for_each_root_subsys()
    
    After the previous patch which introduced for_each_css(),
    for_each_root_subsys() only has two users left.  This patch replaces
    it with for_each_subsys() + explicit subsys_mask testing and remove
    for_each_root_subsys() along with cgroupfs_root->subsys_list handling.
    
    This patch doesn't introduce any behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8b9a594f0c92..cfaf416492dd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -319,9 +319,6 @@ struct cgroupfs_root {
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
 
-	/* A list running through the attached subsystems */
-	struct list_head subsys_list;
-
 	/* The root cgroup for this hierarchy */
 	struct cgroup top_cgroup;
 
@@ -617,12 +614,8 @@ struct cgroup_subsys {
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 
-	/*
-	 * Link to parent, and list entry in parent's children.
-	 * Protected by cgroup_lock()
-	 */
+	/* link to parent, protected by cgroup_lock() */
 	struct cgroupfs_root *root;
-	struct list_head sibling;
 
 	/* list of cftype_sets */
 	struct list_head cftsets;

commit 6612f05b88fa309c91a345690411217959bb2486
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 5 12:28:04 2013 -0500

    cgroup: unify pidlist and other file handling
    
    In preparation of conversion to kernfs, cgroup file handling is
    updated so that it can be easily mapped to kernfs.  With the previous
    changes, the difference between pidlist and other files are very
    small.  Both are served by seq_file in a pretty standard way with the
    only difference being !pidlist files use single_open().
    
    This patch adds cftype->seq_start(), ->seq_next and ->seq_stop() and
    implements the matching cgroup_seqfile_start/next/stop() which either
    emulates single_open() behavior or invokes cftype->seq_*() operations
    if specified.  This allows using single seq_operations for both
    pidlist and other files and makes cgroup_pidlist_operations and
    cgorup_pidlist_open() no longer necessary.  As cgroup_pidlist_open()
    was the only user of cftype->open(), the method is dropped together.
    
    This brings cftype file interface very close to kernfs interface and
    mapping shouldn't be too difficult.  Once converted to kernfs, most of
    the plumbing code including cgroup_seqfile_*() will be removed as
    kernfs provides those facilities.
    
    This patch does not introduce any behavior changes.
    
    v2: Refreshed on top of the updated "cgroup: introduce struct
        cgroup_pidlist_open_file".
    
    v3: Refreshed on top of the updated "cgroup: attach cgroup_open_file
        to all cgroup files".
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b32a0f8ae9ad..8b9a594f0c92 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -434,7 +434,6 @@ struct cftype {
 	 */
 	struct cgroup_subsys *ss;
 
-	int (*open)(struct inode *inode, struct file *file);
 	/*
 	 * read_u64() is a shortcut for the common case of returning a
 	 * single integer. Use it in place of read()
@@ -448,6 +447,11 @@ struct cftype {
 	/* generic seq_file read interface */
 	int (*seq_show)(struct seq_file *sf, void *v);
 
+	/* optional ops, implement all or none */
+	void *(*seq_start)(struct seq_file *sf, loff_t *ppos);
+	void *(*seq_next)(struct seq_file *sf, void *v, loff_t *ppos);
+	void (*seq_stop)(struct seq_file *sf, void *v);
+
 	/*
 	 * write_u64() is a shortcut for the common case of accepting
 	 * a single integer (as parsed by simple_strtoull) from

commit 2da8ca822d49c8b8781800ad155aaa00e7bb5f1a
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 5 12:28:04 2013 -0500

    cgroup: replace cftype->read_seq_string() with cftype->seq_show()
    
    In preparation of conversion to kernfs, cgroup file handling is
    updated so that it can be easily mapped to kernfs.  This patch
    replaces cftype->read_seq_string() with cftype->seq_show() which is
    not limited to single_open() operation and will map directcly to
    kernfs seq_file interface.
    
    The conversions are mechanical.  As ->seq_show() doesn't have @css and
    @cft, the functions which make use of them are converted to use
    seq_css() and seq_cft() respectively.  In several occassions, e.f. if
    it has seq_string in its name, the function name is updated to fit the
    new method better.
    
    This patch does not introduce any behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Aristeu Rozanski <arozansk@redhat.com>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c3d698a72e02..b32a0f8ae9ad 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -444,12 +444,9 @@ struct cftype {
 	 * read_s64() is a signed version of read_u64()
 	 */
 	s64 (*read_s64)(struct cgroup_subsys_state *css, struct cftype *cft);
-	/*
-	 * read_seq_string() is used for outputting a simple sequence
-	 * using seqfile.
-	 */
-	int (*read_seq_string)(struct cgroup_subsys_state *css,
-			       struct cftype *cft, struct seq_file *m);
+
+	/* generic seq_file read interface */
+	int (*seq_show)(struct seq_file *sf, void *v);
 
 	/*
 	 * write_u64() is a shortcut for the common case of accepting

commit 7da112792753d71aed44b918395892a1fc53048a
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 5 12:28:04 2013 -0500

    cgroup: attach cgroup_open_file to all cgroup files
    
    In preparation of conversion to kernfs, cgroup file handling is
    updated so that it can be easily mapped to kernfs.  This patch
    attaches cgroup_open_file, which used to be attached to pidlist files,
    to all cgroup files, introduces seq_css/cft() accessors to determine
    the cgroup_subsys_state and cftype associated with a given cgroup
    seq_file, exports them as public interface.
    
    This doesn't cause any behavior changes but unifies cgroup file
    handling across different file types and will help converting them to
    kernfs seq_show() interface.
    
    v2: Li pointed out that the original patch was using
        single_open_size() incorrectly assuming that the size param is
        private data size.  Fix it by allocating @of separately and
        passing it to single_open() and explicitly freeing it in the
        release path.  This isn't the prettiest but this path is gonna be
        restructured by the following patches pretty soon.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 53e11da6e357..c3d698a72e02 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -21,6 +21,7 @@
 #include <linux/xattr.h>
 #include <linux/fs.h>
 #include <linux/percpu-refcount.h>
+#include <linux/seq_file.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -489,6 +490,26 @@ struct cftype_set {
 	struct cftype			*cfts;
 };
 
+/*
+ * cgroupfs file entry, pointed to from leaf dentry->d_fsdata.  Don't
+ * access directly.
+ */
+struct cfent {
+	struct list_head		node;
+	struct dentry			*dentry;
+	struct cftype			*type;
+	struct cgroup_subsys_state	*css;
+
+	/* file xattrs */
+	struct simple_xattrs		xattrs;
+};
+
+/* seq_file->private points to the following, only ->priv is public */
+struct cgroup_open_file {
+	struct cfent			*cfe;
+	void				*priv;
+};
+
 /*
  * See the comment above CGRP_ROOT_SANE_BEHAVIOR for details.  This
  * function can be called as long as @cgrp is accessible.
@@ -504,6 +525,18 @@ static inline const char *cgroup_name(const struct cgroup *cgrp)
 	return rcu_dereference(cgrp->name)->name;
 }
 
+static inline struct cgroup_subsys_state *seq_css(struct seq_file *seq)
+{
+	struct cgroup_open_file *of = seq->private;
+	return of->cfe->css;
+}
+
+static inline struct cftype *seq_cft(struct seq_file *seq)
+{
+	struct cgroup_open_file *of = seq->private;
+	return of->cfe->type;
+}
+
 int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cftype *cfts);
 

commit 6e0755b08dd6a3b5260fafc6969268c2ba261300
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 5 12:28:03 2013 -0500

    cgroup: remove cftype->read(), ->read_map() and ->write()
    
    In preparation of conversion to kernfs, cgroup file handling is being
    consolidated so that it can be easily mapped to the seq_file based
    interface of kernfs.
    
    After recent updates, ->read() and ->read_map() don't have any user
    left and ->write() never had any user.  Remove them.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 50d8cc37498b..53e11da6e357 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -386,16 +386,6 @@ struct css_set {
 	struct rcu_head rcu_head;
 };
 
-/*
- * cgroup_map_cb is an abstract callback API for reporting map-valued
- * control files
- */
-
-struct cgroup_map_cb {
-	int (*fill)(struct cgroup_map_cb *cb, const char *key, u64 value);
-	void *state;
-};
-
 /*
  * struct cftype: handler definitions for cgroup control files
  *
@@ -444,9 +434,6 @@ struct cftype {
 	struct cgroup_subsys *ss;
 
 	int (*open)(struct inode *inode, struct file *file);
-	ssize_t (*read)(struct cgroup_subsys_state *css, struct cftype *cft,
-			struct file *file,
-			char __user *buf, size_t nbytes, loff_t *ppos);
 	/*
 	 * read_u64() is a shortcut for the common case of returning a
 	 * single integer. Use it in place of read()
@@ -456,14 +443,6 @@ struct cftype {
 	 * read_s64() is a signed version of read_u64()
 	 */
 	s64 (*read_s64)(struct cgroup_subsys_state *css, struct cftype *cft);
-	/*
-	 * read_map() is used for defining a map of key/value
-	 * pairs. It should call cb->fill(cb, key, value) for each
-	 * entry. The key/value pairs (and their ordering) should not
-	 * change between reboots.
-	 */
-	int (*read_map)(struct cgroup_subsys_state *css, struct cftype *cft,
-			struct cgroup_map_cb *cb);
 	/*
 	 * read_seq_string() is used for outputting a simple sequence
 	 * using seqfile.
@@ -471,10 +450,6 @@ struct cftype {
 	int (*read_seq_string)(struct cgroup_subsys_state *css,
 			       struct cftype *cft, struct seq_file *m);
 
-	ssize_t (*write)(struct cgroup_subsys_state *css, struct cftype *cft,
-			 struct file *file,
-			 const char __user *buf, size_t nbytes, loff_t *ppos);
-
 	/*
 	 * write_u64() is a shortcut for the common case of accepting
 	 * a single integer (as parsed by simple_strtoull) from

commit afb2bc14e1c989cf0635bd04edb5ff55b8c1c7bd
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 29 10:42:59 2013 -0500

    cgroup: don't guarantee cgroup.procs is sorted if sane_behavior
    
    For some reason, tasks and cgroup.procs guarantee that the result is
    sorted.  This is the only reason this whole pidlist logic is necessary
    instead of just iterating through sorted member tasks.  We can't do
    anything about the existing interface but at least ensure that such
    expectation doesn't exist for the new interface so that pidlist logic
    may be removed in the distant future.
    
    This patch scrambles the sort order if sane_behavior so that the
    output is usually not sorted in the new interface.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5207c28c2402..50d8cc37498b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -275,6 +275,9 @@ enum {
 	 * - "tasks" is removed.  Everything should be at process
 	 *   granularity.  Use "cgroup.procs" instead.
 	 *
+	 * - "cgroup.procs" is not sorted.  pids will be unique unless they
+	 *   got recycled inbetween reads.
+	 *
 	 * - "release_agent" and "notify_on_release" are removed.
 	 *   Replacement notification mechanism will be implemented.
 	 *

commit b9f3cecaba592d4e98cd155c91b1414323ed51e8
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 29 10:42:58 2013 -0500

    cgroup: remove cftype->release()
    
    Now that pidlist files don't use cftype->release(), it doesn't have
    any user left.  Remove it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 492fa01ec2d3..5207c28c2402 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -499,8 +499,6 @@ struct cftype {
 	 * kick type for multiplexing.
 	 */
 	int (*trigger)(struct cgroup_subsys_state *css, unsigned int event);
-
-	int (*release)(struct inode *inode, struct file *file);
 };
 
 /*

commit edab95103d3a1eb5e3faf977eae4ad0b5bf5669c
Merge: e5fca243abae b36824c75c78
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 22 18:32:25 2013 -0500

    cgroup: Merge branch 'memcg_event' into for-3.14
    
    Merge v3.12 based patch series to move cgroup_event implementation to
    memcg into for-3.14.  The following two commits cause a conflict in
    kernel/cgroup.c
    
      2ff2a7d03bbe4 ("cgroup: kill css_id")
      79bd9814e5ec9 ("cgroup, memcg: move cgroup_event implementation to memcg")
    
    Each patch removes a struct definition from kernel/cgroup.c.  As the
    two are adjacent, they cause a context conflict.  Easily resolved by
    removing both structs.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit b36824c75c7855585d6476eef2b234f6e0e68872
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 22 18:20:44 2013 -0500

    cgroup: unexport cgroup_css() and remove __file_cft()
    
    Now that cgroup_event is made memcg specific, the temporarily exported
    functions are no longer necessary.  Unexport cgroup_css() and remove
    __file_cft() which doesn't have any user left.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 612adc5b87c5..8d9fa8967c9e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -883,11 +883,6 @@ unsigned short css_id(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *css_from_dir(struct dentry *dentry,
 					 struct cgroup_subsys *ss);
 
-/* XXX: temporary */
-struct cgroup_subsys_state *cgroup_css(struct cgroup *cgrp,
-				       struct cgroup_subsys *ss);
-struct cftype *__file_cft(struct file *file);
-
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }

commit fba94807837850e211f8975e1970e23e7804ff4d
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 22 18:20:43 2013 -0500

    cgroup, memcg: move cgroup->event_list[_lock] and event callbacks into memcg
    
    cgroup_event is being moved from cgroup core to memcg and the
    implementation is already moved by the previous patch.  This patch
    moves the data fields and callbacks.
    
    * cgroup->event_list[_lock] are moved to mem_cgroup.
    
    * cftype->[un]register_event() are moved to cgroup_event.  This makes
      it impossible for individual cftype definitions to specify their
      event callbacks.  This is worked around by simply hard-coding
      filename to event callback mapping in cgroup_write_event_control().
      This is awkward and inflexible, which is actually desirable given
      that we don't want to grow more usages of this feature.
    
    * eventfd_ctx declaration is removed from cgroup.h, which makes
      vmpressure.h miss eventfd_ctx declaration.  Include eventfd.h from
      vmpressure.h.
    
    v2: Use file name from dentry instead of cftype.  This will allow
        removing all cftype handling in the function.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 40c2427806c9..612adc5b87c5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -29,7 +29,6 @@ struct cgroup_subsys;
 struct inode;
 struct cgroup;
 struct css_id;
-struct eventfd_ctx;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
@@ -239,10 +238,6 @@ struct cgroup {
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
 
-	/* List of events which userspace want to receive */
-	struct list_head event_list;
-	spinlock_t event_list_lock;
-
 	/* directory xattrs */
 	struct simple_xattrs xattrs;
 };
@@ -506,25 +501,6 @@ struct cftype {
 	int (*trigger)(struct cgroup_subsys_state *css, unsigned int event);
 
 	int (*release)(struct inode *inode, struct file *file);
-
-	/*
-	 * register_event() callback will be used to add new userspace
-	 * waiter for changes related to the cftype. Implement it if
-	 * you want to provide this functionality. Use eventfd_signal()
-	 * on eventfd to send notification to userspace.
-	 */
-	int (*register_event)(struct cgroup_subsys_state *css,
-			      struct cftype *cft, struct eventfd_ctx *eventfd,
-			      const char *args);
-	/*
-	 * unregister_event() callback will be called when userspace
-	 * closes the eventfd or on cgroup removing.
-	 * This callback must be implemented, if you want provide
-	 * notification functionality.
-	 */
-	void (*unregister_event)(struct cgroup_subsys_state *css,
-				 struct cftype *cft,
-				 struct eventfd_ctx *eventfd);
 };
 
 /*

commit 79bd9814e5ec9a288d6599f53aeac0b548fdfe52
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 22 18:20:42 2013 -0500

    cgroup, memcg: move cgroup_event implementation to memcg
    
    cgroup_event is way over-designed and tries to build a generic
    flexible event mechanism into cgroup - fully customizable event
    specification for each user of the interface.  This is utterly
    unnecessary and overboard especially in the light of the planned
    unified hierarchy as there's gonna be single agent.  Simply generating
    events at fixed points, or if that's too restrictive, configureable
    cadence or single set of configureable points should be enough.
    
    Thankfully, memcg is the only user and gets to keep it.  Replacing it
    with something simpler on sane_behavior is strongly recommended.
    
    This patch moves cgroup_event and "cgroup.event_control"
    implementation to mm/memcontrol.c.  Clearing of events on cgroup
    destruction is moved from cgroup_destroy_locked() to
    mem_cgroup_css_offline(), which shouldn't make any noticeable
    difference.
    
    cgroup_css() and __file_cft() are exported to enable the move;
    however, this will soon be reverted once the event code is updated to
    be memcg specific.
    
    Note that "cgroup.event_control" will now exist only on the hierarchy
    with memcg attached to it.  While this change is visible to userland,
    it is unlikely to be noticeable as the file has never been meaningful
    outside memcg.
    
    Aside from the above change, this is pure code relocation.
    
    v2: Per Li Zefan's comments, init/Kconfig updated accordingly and
        poll.h inclusion moved from cgroup.c to memcontrol.c.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3561d305b1e0..40c2427806c9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -907,6 +907,11 @@ unsigned short css_id(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *css_from_dir(struct dentry *dentry,
 					 struct cgroup_subsys *ss);
 
+/* XXX: temporary */
+struct cgroup_subsys_state *cgroup_css(struct cgroup *cgrp,
+				       struct cgroup_subsys *ss);
+struct cftype *__file_cft(struct file *file);
+
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }

commit 2ff2a7d03bbe472ed44a8380dbdbea490d81c59d
Author: Li Zefan <lizefan@huawei.com>
Date:   Mon Sep 23 16:57:03 2013 +0800

    cgroup: kill css_id
    
    The only user of css_id was memcg, and it has been convered to use
    cgroup->id, so kill css_id.
    
    Signed-off-by: Li Zefan <lizefan@huwei.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3561d305b1e0..39c1d9469677 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -612,11 +612,6 @@ struct cgroup_subsys {
 	int subsys_id;
 	int disabled;
 	int early_init;
-	/*
-	 * True if this subsys uses ID. ID is not available before cgroup_init()
-	 * (not available in early_init time.)
-	 */
-	bool use_id;
 
 	/*
 	 * If %false, this subsystem is properly hierarchical -
@@ -642,9 +637,6 @@ struct cgroup_subsys {
 	 */
 	struct cgroupfs_root *root;
 	struct list_head sibling;
-	/* used when use_id == true */
-	struct idr idr;
-	spinlock_t id_lock;
 
 	/* list of cftype_sets */
 	struct list_head cftsets;
@@ -875,35 +867,6 @@ int css_scan_tasks(struct cgroup_subsys_state *css,
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 
-/*
- * CSS ID is ID for cgroup_subsys_state structs under subsys. This only works
- * if cgroup_subsys.use_id == true. It can be used for looking up and scanning.
- * CSS ID is assigned at cgroup allocation (create) automatically
- * and removed when subsys calls free_css_id() function. This is because
- * the lifetime of cgroup_subsys_state is subsys's matter.
- *
- * Looking up and scanning function should be called under rcu_read_lock().
- * Taking cgroup_mutex is not necessary for following calls.
- * But the css returned by this routine can be "not populated yet" or "being
- * destroyed". The caller should check css and cgroup's status.
- */
-
-/*
- * Typically Called at ->destroy(), or somewhere the subsys frees
- * cgroup_subsys_state.
- */
-void free_css_id(struct cgroup_subsys *ss, struct cgroup_subsys_state *css);
-
-/* Find a cgroup_subsys_state which has given ID */
-
-struct cgroup_subsys_state *css_lookup(struct cgroup_subsys *ss, int id);
-
-/* Returns true if root is ancestor of cg */
-bool css_is_ancestor(struct cgroup_subsys_state *cg,
-		     const struct cgroup_subsys_state *root);
-
-/* Get id and depth of css */
-unsigned short css_id(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *css_from_dir(struct dentry *dentry,
 					 struct cgroup_subsys *ss);
 

commit 9fa4db334c7d9570aec7a5121e84fae99aae1d04
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Aug 26 18:40:56 2013 -0400

    cgroup: implement CFTYPE_NO_PREFIX
    
    When cgroup files are created, cgroup core automatically prepends the
    name of the subsystem as prefix.  This patch adds CFTYPE_NO_ which
    disables the automatic prefix.  This is to work around historical
    baggages and shouldn't be used for new files.
    
    This will be used to move "cgroup.event_control" from cgroup core to
    memcg.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Glauber Costa <glommer@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 21ba29869eb8..3561d305b1e0 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -411,6 +411,7 @@ enum {
 	CFTYPE_ONLY_ON_ROOT	= (1 << 0),	/* only create on root cgrp */
 	CFTYPE_NOT_ON_ROOT	= (1 << 1),	/* don't create on root cgrp */
 	CFTYPE_INSANE		= (1 << 2),	/* don't create if sane_behavior */
+	CFTYPE_NO_PREFIX	= (1 << 3),	/* (DON'T USE FOR NEW FILES) no subsys prefix */
 };
 
 #define MAX_CFTYPE_NAME		64

commit 35cf083619da5677f83e9a8eae813f0b413d7082
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Aug 26 18:40:56 2013 -0400

    cgroup: rename cgroup_css_from_dir() to css_from_dir() and update its syntax
    
    cgroup_css_from_dir() will grow another user.  In preparation, make
    the following changes.
    
    * All css functions are prefixed with just "css_", rename it to
      css_from_dir().
    
    * Take dentry * instead of file * as dentry is what ultimately
      identifies a cgroup and file may not always be available.  Note that
      the function now checkes whether @dentry->d_inode is NULL as the
      caller now may specify a negative dentry.
    
    * Make it take cgroup_subsys * instead of integer subsys_id.  This
      simplifies the function and allows specifying no subsystem for
      cgroup->dummy_css.
    
    * Make return section a bit less verbose.
    
    This patch doesn't introduce any behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b685955d4b29..21ba29869eb8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -903,7 +903,8 @@ bool css_is_ancestor(struct cgroup_subsys_state *cg,
 
 /* Get id and depth of css */
 unsigned short css_id(struct cgroup_subsys_state *css);
-struct cgroup_subsys_state *cgroup_css_from_dir(struct file *f, int id);
+struct cgroup_subsys_state *css_from_dir(struct dentry *dentry,
+					 struct cgroup_subsys *ss);
 
 #else /* !CONFIG_CGROUPS */
 

commit 1cb650b91ba582f6737457b7d22e368585596d2c
Author: Li Zefan <lizefan@huawei.com>
Date:   Mon Aug 19 10:05:24 2013 +0800

    cgroup: change cgroup_from_id() to css_from_id()
    
    Now we want cgroup core to always provide the css to use to the
    subsystems, so change this API to css_from_id().
    
    Uninline css_from_id(), because it's getting bigger and cgroup_css()
    has been unexported.
    
    While at it, remove the #ifdef, and shuffle the order of the args.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c24bd0b9f93a..b685955d4b29 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -741,27 +741,11 @@ static inline struct cgroup *task_cgroup(struct task_struct *task,
 	return task_css(task, subsys_id)->cgroup;
 }
 
-/**
- * cgroup_from_id - lookup cgroup by id
- * @ss: cgroup subsys to be looked into
- * @id: the cgroup id
- *
- * Returns the cgroup if there's valid one with @id, otherwise returns NULL.
- * Should be called under rcu_read_lock().
- */
-static inline struct cgroup *cgroup_from_id(struct cgroup_subsys *ss, int id)
-{
-#ifdef CONFIG_PROVE_RCU
-	rcu_lockdep_assert(rcu_read_lock_held() ||
-			   lockdep_is_held(&cgroup_mutex),
-			   "cgroup_from_id() needs proper protection");
-#endif
-	return idr_find(&ss->root->cgroup_idr, id);
-}
-
 struct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,
 					   struct cgroup_subsys_state *parent);
 
+struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss);
+
 /**
  * css_for_each_child - iterate through children of a css
  * @pos: the css * to use as the loop cursor

commit 0c21ead136a900c36f1ab74fd7d09a306dc31324
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 13 20:22:51 2013 -0400

    cgroup: RCU protect each cgroup_subsys_state release
    
    With the planned unified hierarchy, individual css's will be created
    and destroyed dynamically across the lifetime of a cgroup.  To enable
    such usages, css destruction is being decoupled from cgroup
    destruction.  Most of the destruction path has been decoupled but the
    actual free of css still depends on cgroup free path.
    
    When all css refs are drained, css_release() kicks off
    css_free_work_fn() which puts the cgroup.  When the cgroup refcnt
    reaches zero, cgroup_diput() is invoked which in turn schedules RCU
    free of the cgroup.  After a grace period, all css's are freed along
    with the cgroup itself.
    
    This patch moves the RCU grace period and css freeing from cgroup
    release path to css release path.  css_release(), instead of kicking
    off css_free_work_fn() directly, schedules RCU callback
    css_free_rcu_fn() which in turn kicks off css_free_work_fn() after a
    RCU grace period.  css_free_work_fn() is updated to free the css
    directly.
    
    The five-way punting - percpu ref kill confirmation, a work item,
    percpu ref release, RCU grace period, and again a work item - is quite
    hairy but the work items are there only to provide process context and
    the actual sequence is kill confirm -> release -> RCU free, which
    isn't simple but not too crazy.
    
    This removes cgroup_css() usage after offline_css() allowing clearing
    cgroup->subsys[] from offline_css(), which makes it consistent with
    online_css() and brings it closer to proper lifetime management for
    individual css's.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 71e77e7cdb6f..c24bd0b9f93a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -82,7 +82,8 @@ struct cgroup_subsys_state {
 	/* ID for this css, if possible */
 	struct css_id __rcu *id;
 
-	/* percpu_ref killing and putting dentry on the last css_put() */
+	/* percpu_ref killing and RCU release */
+	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
 };
 

commit 09a503ea3a816b285b0b402b7f785eaec0c7a7e1
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 13 20:22:50 2013 -0400

    cgroup: decouple cgroup_subsys_state destruction from cgroup destruction
    
    Currently, css (cgroup_subsys_state) lifetime is tied to that of the
    associated cgroup.  css's are created when the associated cgroup is
    created and destroyed when it gets destroyed.  Also, individual css's
    aren't RCU protected but the whole cgroup is.  With the planned
    unified hierarchy, css's will need to be dynamically created and
    destroyed within the lifetime of a cgroup.
    
    To enable such usages, this patch decouples css destruction from
    cgroup destruction - offline_css() invocation and the final css_put()
    are moved from cgroup_destroy_css_killed() to css_killed_work_fn().
    Now each css is individually offlined and put as its reference count
    is killed instead of waiting for all css's attached to the cgroup to
    finish refcnt killing and then proceeding to offlining and putting
    them together.
    
    While this changes the order of destruction operations, the changes
    shouldn't be noticeable to cgroup subsystems or userland.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 80dca872f4d4..71e77e7cdb6f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -82,7 +82,7 @@ struct cgroup_subsys_state {
 	/* ID for this css, if possible */
 	struct css_id __rcu *id;
 
-	/* Used to put @cgroup->dentry on the last css_put() */
+	/* percpu_ref killing and putting dentry on the last css_put() */
 	struct work_struct destroy_work;
 };
 

commit f20104de55a212a9742d8df1807f1f29dc95b748
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 13 20:22:50 2013 -0400

    cgroup: replace cgroup->css_kill_cnt with ->nr_css
    
    Currently, css (cgroup_subsys_state) lifetime is tied to that of the
    associated cgroup.  With the planned unified hierarchy, css's will be
    dynamically created and destroyed within the lifetime of a cgroup.  To
    enable such usages, css's will be individually RCU protected instead
    of being tied to the cgroup.
    
    cgroup->css_kill_cnt is used during cgroup destruction to wait for css
    reference count disable; however, this model doesn't work once css's
    lifetimes are managed separately from cgroup's.  This patch replaces
    it with cgroup->nr_css which is an cgroup_mutex protected integer
    counting the number of attached css's.  The count is incremented from
    online_css() and decremented after refcnt kill is confirmed.  If the
    count reaches zero and the cgroup is marked dead, the second stage of
    cgroup destruction is kicked off.  If a cgroup doesn't have any css
    attached at the time of rmdir, cgroup_destroy_locked() now invokes the
    second stage directly as no css kill confirmation would happen.
    
    cgroup_offline_fn() - the second step of cgroup destruction - is
    renamed to cgroup_destroy_css_killed() and now expects to be called
    with cgroup_mutex held.
    
    While this patch changes how css destruction is punted to work items,
    it shouldn't change any visible behavior.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index eb200b5794e7..80dca872f4d4 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -171,6 +171,9 @@ struct cgroup {
 	 */
 	int id;
 
+	/* the number of attached css's */
+	int nr_css;
+
 	/*
 	 * We link our 'sibling' struct into our parent's 'children'.
 	 * Our children link their 'sibling' into our 'children'.
@@ -234,7 +237,6 @@ struct cgroup {
 	/* For css percpu_ref killing and RCU-protected deletion */
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
-	atomic_t css_kill_cnt;
 
 	/* List of events which userspace want to receive */
 	struct list_head event_list;

commit 73e80ed8007fc48a6deeb295ba37159fad274bd2
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 13 11:01:55 2013 -0400

    cgroup: add __rcu modifier to cgroup->subsys[]
    
    For the planned unified hierarchy, each css (cgroup_subsys_state) will
    be RCU protected so that it can be created and destroyed individually
    while allowing RCU accesses.  Previous changes ensured that all
    cgroup->subsys[] accesses use the cgroup_css() accessor.  This patch
    adds __rcu modifier to cgroup->subsys[], add matching RCU dereference
    in cgroup_css() and convert all assignments to either
    rcu_assign_pointer() or RCU_INIT_POINTER().
    
    This change prepares for the actual RCUfication of css's and doesn't
    introduce any visible behavior change.  The conversion is verified
    with sparse and all accesses are properly RCU annotated.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8a5dc91fbaad..eb200b5794e7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -204,7 +204,7 @@ struct cgroup {
 	struct cgroup_name __rcu *name;
 
 	/* Private pointers for each registered subsystem */
-	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
+	struct cgroup_subsys_state __rcu *subsys[CGROUP_SUBSYS_COUNT];
 
 	struct cgroupfs_root *root;
 

commit 0ae78e0bf10ac38ab53548e18383afc9997eca22
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 13 11:01:54 2013 -0400

    cgroup: add cgroup_subsys_state->parent
    
    With the planned unified hierarchy, css's (cgroup_subsys_state) will
    be RCU protected and allowed to be attached and detached dynamically
    over the course of a cgroup's lifetime.  This means that css's will
    stay accessible after being detached from its cgroup - the matching
    pointer in cgroup->subsys[] cleared - for ref draining and RCU grace
    period.
    
    cgroup core still wants to guarantee that the parent css is never
    destroyed before its children and css_parent() always returns the
    parent regardless of the state of the child css as long as it's
    accessible.
    
    This patch makes css's hold onto their parents and adds css->parent so
    that the parent css is never detroyed before its children and can be
    determined without consulting the cgroups.
    
    cgroup->dummy_css is also updated to point to the parent dummy_css;
    however, it doesn't need to worry about object lifetime as the parent
    cgroup is already pinned by the child.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 12d66fee26f8..8a5dc91fbaad 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -75,6 +75,9 @@ struct cgroup_subsys_state {
 	/* reference count - access via css_[try]get() and css_put() */
 	struct percpu_ref refcnt;
 
+	/* the parent css */
+	struct cgroup_subsys_state *parent;
+
 	unsigned long flags;
 	/* ID for this css, if possible */
 	struct css_id __rcu *id;
@@ -666,15 +669,7 @@ struct cgroup_subsys {
 static inline
 struct cgroup_subsys_state *css_parent(struct cgroup_subsys_state *css)
 {
-	struct cgroup *parent_cgrp = css->cgroup->parent;
-
-	if (!parent_cgrp)
-		return NULL;
-
-	if (css->ss)
-		return parent_cgrp->subsys[css->ss->subsys_id];
-	else
-		return &parent_cgrp->dummy_css;
+	return css->parent;
 }
 
 /**

commit 35ef10da65d43211f4cd7e7822cbb3becdfc0ae1
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Aug 13 11:01:54 2013 -0400

    cgroup: rename cgroup_subsys_state->dput_work and its callback function
    
    css (cgroup_subsys_state) will become RCU protected and there will be
    two stages which require punting to work item during release.  To
    prepare for using the work item for multiple times, rename
    css->dput_work to css->destroy_work and css_dput_fn() to
    css_free_work_fn() and move work item initialization from css init to
    right before the actual usage.
    
    This reorganization doesn't introduce any behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8ec5b0f38292..12d66fee26f8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -80,7 +80,7 @@ struct cgroup_subsys_state {
 	struct css_id __rcu *id;
 
 	/* Used to put @cgroup->dentry on the last css_put() */
-	struct work_struct dput_work;
+	struct work_struct destroy_work;
 };
 
 /* bits in struct cgroup_subsys_state flags field */

commit bd8815a6d802fc16a7a106e170593aa05dc17e72
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:27 2013 -0400

    cgroup: make css_for_each_descendant() and friends include the origin css in the iteration
    
    Previously, all css descendant iterators didn't include the origin
    (root of subtree) css in the iteration.  The reasons were maintaining
    consistency with css_for_each_child() and that at the time of
    introduction more use cases needed skipping the origin anyway;
    however, given that css_is_descendant() considers self to be a
    descendant, omitting the origin css has become more confusing and
    looking at the accumulated use cases rather clearly indicates that
    including origin would result in simpler code overall.
    
    While this is a change which can easily lead to subtle bugs, cgroup
    API including the iterators has recently gone through major
    restructuring and no out-of-tree changes will be applicable without
    adjustments making this a relatively acceptable opportunity for this
    type of change.
    
    The conversions are mostly straight-forward.  If the iteration block
    had explicit origin handling before or after, it's moved inside the
    iteration.  If not, if (pos == origin) continue; is added.  Some
    conversions add extra reference get/put around origin handling by
    consolidating origin handling and the rest.  While the extra ref
    operations aren't strictly necessary, this shouldn't cause any
    noticeable difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Aristeu Rozanski <aris@redhat.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c40e508d54e9..8ec5b0f38292 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -798,7 +798,8 @@ css_rightmost_descendant(struct cgroup_subsys_state *pos);
  * @pos: the css * to use as the loop cursor
  * @root: css whose descendants to walk
  *
- * Walk @root's descendants.  Must be called under rcu_read_lock().  A
+ * Walk @root's descendants.  @root is included in the iteration and the
+ * first node to be visited.  Must be called under rcu_read_lock().  A
  * descendant css which hasn't finished ->css_online() or already has
  * finished ->css_offline() may show up during traversal and it's each
  * subsystem's responsibility to verify that each @pos is alive.
@@ -820,13 +821,12 @@ css_rightmost_descendant(struct cgroup_subsys_state *pos);
  *
  * my_update_state(@css)
  * {
- *	Lock @css;
- *	Update @css's state;
- *	Unlock @css;
- *
  *	css_for_each_descendant_pre(@pos, @css) {
  *		Lock @pos;
- *		Verify @pos is alive and inherit state from @pos's parent;
+ *		if (@pos == @css)
+ *			Update @css's state;
+ *		else
+ *			Verify @pos is alive and inherit state from its parent;
  *		Unlock @pos;
  *	}
  * }
@@ -864,8 +864,9 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
  * @css: css whose descendants to walk
  *
  * Similar to css_for_each_descendant_pre() but performs post-order
- * traversal instead.  Note that the walk visibility guarantee described in
- * pre-order walk doesn't apply the same to post-order walks.
+ * traversal instead.  @root is included in the iteration and the last
+ * node to be visited.  Note that the walk visibility guarantee described
+ * in pre-order walk doesn't apply the same to post-order walks.
  */
 #define css_for_each_descendant_post(pos, css)				\
 	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\

commit 95109b627ba6a043c181fa5fa45d1c754dd44fbc
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:27 2013 -0400

    cgroup: unexport cgroup_css()
    
    cgroup_css() no longer has any user left outside cgroup.c proper and
    we don't want subsystems to grow new usages of the function.  cgroup
    core should always provide the css to use to the subsystems, which
    will make dynamic creation and destruction of css's across the
    lifetime of a cgroup much more manageable than exposing the cgroup
    directly to subsystems and let them dereference css's from it.
    
    Make cgroup_css() a static function in cgroup.c.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d9a970568be9..c40e508d54e9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -677,19 +677,6 @@ struct cgroup_subsys_state *css_parent(struct cgroup_subsys_state *css)
 		return &parent_cgrp->dummy_css;
 }
 
-/**
- * cgroup_css - obtain a cgroup's css for the specified subsystem
- * @cgrp: the cgroup of interest
- * @subsys_id: the subsystem of interest
- *
- * Return @cgrp's css (cgroup_subsys_state) associated with @subsys_id.
- */
-static inline struct cgroup_subsys_state *cgroup_css(struct cgroup *cgrp,
-						     int subsys_id)
-{
-	return cgrp->subsys[subsys_id];
-}
-
 /**
  * task_css_set_check - obtain a task's css_set with extra access conditions
  * @task: the task to obtain css_set for

commit d99c8727e7bbc01b70e2c57e6127bfab26b868fd
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:27 2013 -0400

    cgroup: make cgroup_taskset deal with cgroup_subsys_state instead of cgroup
    
    cgroup is in the process of converting to css (cgroup_subsys_state)
    from cgroup as the principal subsystem interface handle.  This is
    mostly to prepare for the unified hierarchy support where css's will
    be created and destroyed dynamically but also helps cleaning up
    subsystem implementations as css is usually what they are interested
    in anyway.
    
    cgroup_taskset which is used by the subsystem attach methods is the
    last cgroup subsystem API which isn't using css as the handle.  Update
    cgroup_taskset_cur_cgroup() to cgroup_taskset_cur_css() and
    cgroup_taskset_for_each() to take @skip_css instead of @skip_cgrp.
    
    The conversions are pretty mechanical.  One exception is
    cpuset::cgroup_cs(), which lost its last user and got removed.
    
    This patch shouldn't introduce any functional changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b065d24486e6..d9a970568be9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -562,20 +562,22 @@ int cgroup_task_count(const struct cgroup *cgrp);
 struct cgroup_taskset;
 struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset);
 struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
-struct cgroup *cgroup_taskset_cur_cgroup(struct cgroup_taskset *tset);
+struct cgroup_subsys_state *cgroup_taskset_cur_css(struct cgroup_taskset *tset,
+						   int subsys_id);
 int cgroup_taskset_size(struct cgroup_taskset *tset);
 
 /**
  * cgroup_taskset_for_each - iterate cgroup_taskset
  * @task: the loop cursor
- * @skip_cgrp: skip if task's cgroup matches this, %NULL to iterate through all
+ * @skip_css: skip if task's css matches this, %NULL to iterate through all
  * @tset: taskset to iterate
  */
-#define cgroup_taskset_for_each(task, skip_cgrp, tset)			\
+#define cgroup_taskset_for_each(task, skip_css, tset)			\
 	for ((task) = cgroup_taskset_first((tset)); (task);		\
 	     (task) = cgroup_taskset_next((tset)))			\
-		if (!(skip_cgrp) ||					\
-		    cgroup_taskset_cur_cgroup((tset)) != (skip_cgrp))
+		if (!(skip_css) ||					\
+		    cgroup_taskset_cur_css((tset),			\
+			(skip_css)->ss->subsys_id) != (skip_css))
 
 /*
  * Control Group subsystem type.

commit 81eeaf0411204f52af8ef78ff107cfca2fcfec1d
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:26 2013 -0400

    cgroup: make cftype->[un]register_event() deal with cgroup_subsys_state instead of cgroup
    
    cgroup is in the process of converting to css (cgroup_subsys_state)
    from cgroup as the principal subsystem interface handle.  This is
    mostly to prepare for the unified hierarchy support where css's will
    be created and destroyed dynamically but also helps cleaning up
    subsystem implementations as css is usually what they are interested
    in anyway.
    
    cftype->[un]register_event() is among the remaining couple interfaces
    which still use struct cgroup.  Convert it to cgroup_subsys_state.
    The conversion is mostly mechanical and removes the last users of
    mem_cgroup_from_cont() and cg_to_vmpressure(), which are removed.
    
    v2: indentation update as suggested by Li Zefan.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cd105fce089c..b065d24486e6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -506,16 +506,18 @@ struct cftype {
 	 * you want to provide this functionality. Use eventfd_signal()
 	 * on eventfd to send notification to userspace.
 	 */
-	int (*register_event)(struct cgroup *cgrp, struct cftype *cft,
-			struct eventfd_ctx *eventfd, const char *args);
+	int (*register_event)(struct cgroup_subsys_state *css,
+			      struct cftype *cft, struct eventfd_ctx *eventfd,
+			      const char *args);
 	/*
 	 * unregister_event() callback will be called when userspace
 	 * closes the eventfd or on cgroup removing.
 	 * This callback must be implemented, if you want provide
 	 * notification functionality.
 	 */
-	void (*unregister_event)(struct cgroup *cgrp, struct cftype *cft,
-			struct eventfd_ctx *eventfd);
+	void (*unregister_event)(struct cgroup_subsys_state *css,
+				 struct cftype *cft,
+				 struct eventfd_ctx *eventfd);
 };
 
 /*

commit 72ec7029937f0518eff21b8762743c31591684f5
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:26 2013 -0400

    cgroup: make task iterators deal with cgroup_subsys_state instead of cgroup
    
    cgroup is in the process of converting to css (cgroup_subsys_state)
    from cgroup as the principal subsystem interface handle.  This is
    mostly to prepare for the unified hierarchy support where css's will
    be created and destroyed dynamically but also helps cleaning up
    subsystem implementations as css is usually what they are interested
    in anyway.
    
    This patch converts task iterators to deal with css instead of cgroup.
    Note that under unified hierarchy, different sets of tasks will be
    considered belonging to a given cgroup depending on the subsystem in
    question and making the iterators deal with css instead cgroup
    provides them with enough information about the iteration.
    
    While at it, fix several function comment formats in cpuset.c.
    
    This patch doesn't introduce any behavior differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8472ed576b64..cd105fce089c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -880,21 +880,22 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\
 	     (pos) = css_next_descendant_post((pos), (css)))
 
-/* A cgroup_task_iter should be treated as an opaque object */
-struct cgroup_task_iter {
-	struct cgroup			*origin_cgrp;
+/* A css_task_iter should be treated as an opaque object */
+struct css_task_iter {
+	struct cgroup_subsys_state	*origin_css;
 	struct list_head		*cset_link;
 	struct list_head		*task;
 };
 
-void cgroup_task_iter_start(struct cgroup *cgrp, struct cgroup_task_iter *it);
-struct task_struct *cgroup_task_iter_next(struct cgroup_task_iter *it);
-void cgroup_task_iter_end(struct cgroup_task_iter *it);
+void css_task_iter_start(struct cgroup_subsys_state *css,
+			 struct css_task_iter *it);
+struct task_struct *css_task_iter_next(struct css_task_iter *it);
+void css_task_iter_end(struct css_task_iter *it);
 
-int cgroup_scan_tasks(struct cgroup *cgrp,
-		      bool (*test)(struct task_struct *, void *),
-		      void (*process)(struct task_struct *, void *),
-		      void *data, struct ptr_heap *heap);
+int css_scan_tasks(struct cgroup_subsys_state *css,
+		   bool (*test)(struct task_struct *, void *),
+		   void (*process)(struct task_struct *, void *),
+		   void *data, struct ptr_heap *heap);
 
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);

commit e535837b1dae17b5a2d76ea1bc22ac1a79354624
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:26 2013 -0400

    cgroup: remove struct cgroup_scanner
    
    cgroup_scan_tasks() takes a pointer to struct cgroup_scanner as its
    sole argument and the only function of that struct is packing the
    arguments of the function call which are consisted of five fields.
    It's not too unusual to pack parameters into a struct when the number
    of arguments gets excessive or the whole set needs to be passed around
    a lot, but neither holds here making it just weird.
    
    Drop struct cgroup_scanner and pass the params directly to
    cgroup_scan_tasks().  Note that struct cpuset_change_nodemask_arg was
    added to cpuset.c to pass both ->cs and ->newmems pointer to
    cpuset_change_nodemask() using single data pointer.
    
    This doesn't make any functional differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0287fccd0f54..8472ed576b64 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -528,15 +528,6 @@ struct cftype_set {
 	struct cftype			*cfts;
 };
 
-struct cgroup_scanner {
-	struct cgroup *cgrp;
-	int (*test_task)(struct task_struct *p, struct cgroup_scanner *scan);
-	void (*process_task)(struct task_struct *p,
-			struct cgroup_scanner *scan);
-	struct ptr_heap *heap;
-	void *data;
-};
-
 /*
  * See the comment above CGRP_ROOT_SANE_BEHAVIOR for details.  This
  * function can be called as long as @cgrp is accessible.
@@ -899,7 +890,12 @@ struct cgroup_task_iter {
 void cgroup_task_iter_start(struct cgroup *cgrp, struct cgroup_task_iter *it);
 struct task_struct *cgroup_task_iter_next(struct cgroup_task_iter *it);
 void cgroup_task_iter_end(struct cgroup_task_iter *it);
-int cgroup_scan_tasks(struct cgroup_scanner *scan);
+
+int cgroup_scan_tasks(struct cgroup *cgrp,
+		      bool (*test)(struct task_struct *, void *),
+		      void (*process)(struct task_struct *, void *),
+		      void *data, struct ptr_heap *heap);
+
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 

commit c59cd3d840b1b0a8f996cbbd9132128dcaabbeb9
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:26 2013 -0400

    cgroup: make cgroup_task_iter remember the cgroup being iterated
    
    Currently all cgroup_task_iter functions require @cgrp to be passed
    in, which is superflous and increases chance of usage error.  Make
    cgroup_task_iter remember the cgroup being iterated and drop @cgrp
    argument from next and end functions.
    
    This patch doesn't introduce any behavior differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ea439794bd9b..0287fccd0f54 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -891,14 +891,14 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 
 /* A cgroup_task_iter should be treated as an opaque object */
 struct cgroup_task_iter {
+	struct cgroup			*origin_cgrp;
 	struct list_head		*cset_link;
 	struct list_head		*task;
 };
 
 void cgroup_task_iter_start(struct cgroup *cgrp, struct cgroup_task_iter *it);
-struct task_struct *cgroup_task_iter_next(struct cgroup *cgrp,
-					  struct cgroup_task_iter *it);
-void cgroup_task_iter_end(struct cgroup *cgrp, struct cgroup_task_iter *it);
+struct task_struct *cgroup_task_iter_next(struct cgroup_task_iter *it);
+void cgroup_task_iter_end(struct cgroup_task_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);

commit 0942eeeef68f9493c1bcb1a52baf612b73fcf9fb
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:26 2013 -0400

    cgroup: rename cgroup_iter to cgroup_task_iter
    
    cgroup now has multiple iterators and it's quite confusing to have
    something which walks over tasks of a single cgroup named cgroup_iter.
    Let's rename it to cgroup_task_iter.
    
    While at it, reformat / update comments and replace the overview
    comment above the interface function decls with proper function
    comments.  Such overview can be useful but function comments should be
    more than enough here.
    
    This is pure rename and doesn't introduce any functional changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4bc22f4a1abb..ea439794bd9b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -889,31 +889,16 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\
 	     (pos) = css_next_descendant_post((pos), (css)))
 
-/* A cgroup_iter should be treated as an opaque object */
-struct cgroup_iter {
-	struct list_head *cset_link;
-	struct list_head *task;
+/* A cgroup_task_iter should be treated as an opaque object */
+struct cgroup_task_iter {
+	struct list_head		*cset_link;
+	struct list_head		*task;
 };
 
-/*
- * To iterate across the tasks in a cgroup:
- *
- * 1) call cgroup_iter_start to initialize an iterator
- *
- * 2) call cgroup_iter_next() to retrieve member tasks until it
- *    returns NULL or until you want to end the iteration
- *
- * 3) call cgroup_iter_end() to destroy the iterator.
- *
- * Or, call cgroup_scan_tasks() to iterate through every task in a
- * cgroup - cgroup_scan_tasks() holds the css_set_lock when calling
- * the test_task() callback, but not while calling the process_task()
- * callback.
- */
-void cgroup_iter_start(struct cgroup *cgrp, struct cgroup_iter *it);
-struct task_struct *cgroup_iter_next(struct cgroup *cgrp,
-					struct cgroup_iter *it);
-void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
+void cgroup_task_iter_start(struct cgroup *cgrp, struct cgroup_task_iter *it);
+struct task_struct *cgroup_task_iter_next(struct cgroup *cgrp,
+					  struct cgroup_task_iter *it);
+void cgroup_task_iter_end(struct cgroup *cgrp, struct cgroup_task_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);

commit 492eb21b98f88e411a8bb43d6edcd7d7022add10
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:25 2013 -0400

    cgroup: make hierarchy iterators deal with cgroup_subsys_state instead of cgroup
    
    cgroup is currently in the process of transitioning to using css
    (cgroup_subsys_state) as the primary handle instead of cgroup in
    subsystem API.  For hierarchy iterators, this is beneficial because
    
    * In most cases, css is the only thing subsystems care about anyway.
    
    * On the planned unified hierarchy, iterations for different
      subsystems will need to skip over different subtrees of the
      hierarchy depending on which subsystems are enabled on each cgroup.
      Passing around css makes it unnecessary to explicitly specify the
      subsystem in question as css is intersection between cgroup and
      subsystem
    
    * For the planned unified hierarchy, css's would need to be created
      and destroyed dynamically independent from cgroup hierarchy.  Having
      cgroup core manage css iteration makes enforcing deref rules a lot
      easier.
    
    Most subsystem conversions are straight-forward.  Noteworthy changes
    are
    
    * blkio: cgroup_to_blkcg() is no longer used.  Removed.
    
    * freezer: cgroup_freezer() is no longer used.  Removed.
    
    * devices: cgroup_to_devcgroup() is no longer used.  Removed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Aristeu Rozanski <aris@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c288bce428f8..4bc22f4a1abb 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -779,68 +779,72 @@ static inline struct cgroup *cgroup_from_id(struct cgroup_subsys *ss, int id)
 	return idr_find(&ss->root->cgroup_idr, id);
 }
 
-struct cgroup *cgroup_next_child(struct cgroup *pos, struct cgroup *cgrp);
+struct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,
+					   struct cgroup_subsys_state *parent);
 
 /**
- * cgroup_for_each_child - iterate through children of a cgroup
- * @pos: the cgroup * to use as the loop cursor
- * @cgrp: cgroup whose children to walk
+ * css_for_each_child - iterate through children of a css
+ * @pos: the css * to use as the loop cursor
+ * @parent: css whose children to walk
  *
- * Walk @cgrp's children.  Must be called under rcu_read_lock().  A child
- * cgroup which hasn't finished ->css_online() or already has finished
+ * Walk @parent's children.  Must be called under rcu_read_lock().  A child
+ * css which hasn't finished ->css_online() or already has finished
  * ->css_offline() may show up during traversal and it's each subsystem's
  * responsibility to verify that each @pos is alive.
  *
  * If a subsystem synchronizes against the parent in its ->css_online() and
- * before starting iterating, a cgroup which finished ->css_online() is
+ * before starting iterating, a css which finished ->css_online() is
  * guaranteed to be visible in the future iterations.
  *
  * It is allowed to temporarily drop RCU read lock during iteration.  The
  * caller is responsible for ensuring that @pos remains accessible until
  * the start of the next iteration by, for example, bumping the css refcnt.
  */
-#define cgroup_for_each_child(pos, cgrp)				\
-	for ((pos) = cgroup_next_child(NULL, (cgrp)); (pos);		\
-	     (pos) = cgroup_next_child((pos), (cgrp)))
+#define css_for_each_child(pos, parent)					\
+	for ((pos) = css_next_child(NULL, (parent)); (pos);		\
+	     (pos) = css_next_child((pos), (parent)))
 
-struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
-					  struct cgroup *cgroup);
-struct cgroup *cgroup_rightmost_descendant(struct cgroup *pos);
+struct cgroup_subsys_state *
+css_next_descendant_pre(struct cgroup_subsys_state *pos,
+			struct cgroup_subsys_state *css);
+
+struct cgroup_subsys_state *
+css_rightmost_descendant(struct cgroup_subsys_state *pos);
 
 /**
- * cgroup_for_each_descendant_pre - pre-order walk of a cgroup's descendants
- * @pos: the cgroup * to use as the loop cursor
- * @cgroup: cgroup whose descendants to walk
+ * css_for_each_descendant_pre - pre-order walk of a css's descendants
+ * @pos: the css * to use as the loop cursor
+ * @root: css whose descendants to walk
  *
- * Walk @cgroup's descendants.  Must be called under rcu_read_lock().  A
- * descendant cgroup which hasn't finished ->css_online() or already has
+ * Walk @root's descendants.  Must be called under rcu_read_lock().  A
+ * descendant css which hasn't finished ->css_online() or already has
  * finished ->css_offline() may show up during traversal and it's each
  * subsystem's responsibility to verify that each @pos is alive.
  *
  * If a subsystem synchronizes against the parent in its ->css_online() and
  * before starting iterating, and synchronizes against @pos on each
- * iteration, any descendant cgroup which finished ->css_online() is
+ * iteration, any descendant css which finished ->css_online() is
  * guaranteed to be visible in the future iterations.
  *
  * In other words, the following guarantees that a descendant can't escape
  * state updates of its ancestors.
  *
- * my_online(@cgrp)
+ * my_online(@css)
  * {
- *	Lock @cgrp->parent and @cgrp;
- *	Inherit state from @cgrp->parent;
+ *	Lock @css's parent and @css;
+ *	Inherit state from the parent;
  *	Unlock both.
  * }
  *
- * my_update_state(@cgrp)
+ * my_update_state(@css)
  * {
- *	Lock @cgrp;
- *	Update @cgrp's state;
- *	Unlock @cgrp;
+ *	Lock @css;
+ *	Update @css's state;
+ *	Unlock @css;
  *
- *	cgroup_for_each_descendant_pre(@pos, @cgrp) {
+ *	css_for_each_descendant_pre(@pos, @css) {
  *		Lock @pos;
- *		Verify @pos is alive and inherit state from @pos->parent;
+ *		Verify @pos is alive and inherit state from @pos's parent;
  *		Unlock @pos;
  *	}
  * }
@@ -851,8 +855,7 @@ struct cgroup *cgroup_rightmost_descendant(struct cgroup *pos);
  * visible by walking order and, as long as inheriting operations to the
  * same @pos are atomic to each other, multiple updates racing each other
  * still result in the correct state.  It's guaranateed that at least one
- * inheritance happens for any cgroup after the latest update to its
- * parent.
+ * inheritance happens for any css after the latest update to its parent.
  *
  * If checking parent's state requires locking the parent, each inheriting
  * iteration should lock and unlock both @pos->parent and @pos.
@@ -865,25 +868,26 @@ struct cgroup *cgroup_rightmost_descendant(struct cgroup *pos);
  * caller is responsible for ensuring that @pos remains accessible until
  * the start of the next iteration by, for example, bumping the css refcnt.
  */
-#define cgroup_for_each_descendant_pre(pos, cgroup)			\
-	for (pos = cgroup_next_descendant_pre(NULL, (cgroup)); (pos);	\
-	     pos = cgroup_next_descendant_pre((pos), (cgroup)))
+#define css_for_each_descendant_pre(pos, css)				\
+	for ((pos) = css_next_descendant_pre(NULL, (css)); (pos);	\
+	     (pos) = css_next_descendant_pre((pos), (css)))
 
-struct cgroup *cgroup_next_descendant_post(struct cgroup *pos,
-					   struct cgroup *cgroup);
+struct cgroup_subsys_state *
+css_next_descendant_post(struct cgroup_subsys_state *pos,
+			 struct cgroup_subsys_state *css);
 
 /**
- * cgroup_for_each_descendant_post - post-order walk of a cgroup's descendants
- * @pos: the cgroup * to use as the loop cursor
- * @cgroup: cgroup whose descendants to walk
+ * css_for_each_descendant_post - post-order walk of a css's descendants
+ * @pos: the css * to use as the loop cursor
+ * @css: css whose descendants to walk
  *
- * Similar to cgroup_for_each_descendant_pre() but performs post-order
+ * Similar to css_for_each_descendant_pre() but performs post-order
  * traversal instead.  Note that the walk visibility guarantee described in
  * pre-order walk doesn't apply the same to post-order walks.
  */
-#define cgroup_for_each_descendant_post(pos, cgroup)			\
-	for (pos = cgroup_next_descendant_post(NULL, (cgroup)); (pos);	\
-	     pos = cgroup_next_descendant_post((pos), (cgroup)))
+#define css_for_each_descendant_post(pos, css)				\
+	for ((pos) = css_next_descendant_post(NULL, (css)); (pos);	\
+	     (pos) = css_next_descendant_post((pos), (css)))
 
 /* A cgroup_iter should be treated as an opaque object */
 struct cgroup_iter {

commit f48e3924dca268c677c4e338e5d91ad9e6fe6b9e
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:24 2013 -0400

    cgroup: always use cgroup_next_child() to walk the children list
    
    There are several places where the children list is accessed directly.
    This patch converts those places to use cgroup_next_child().  This
    will help updating the hierarchy iterators to use @css instead of
    @cgrp.
    
    While cgroup_next_child() can be heavy in pathological cases - e.g. a
    lot of dead children, this shouldn't cause any noticeable behavior
    differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5f9ba5881717..c288bce428f8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -800,9 +800,8 @@ struct cgroup *cgroup_next_child(struct cgroup *pos, struct cgroup *cgrp);
  * the start of the next iteration by, for example, bumping the css refcnt.
  */
 #define cgroup_for_each_child(pos, cgrp)				\
-	for ((pos) = list_first_or_null_rcu(&(cgrp)->children,		\
-					    struct cgroup, sibling);	\
-	     (pos); (pos) = cgroup_next_child((pos), (cgrp)))
+	for ((pos) = cgroup_next_child(NULL, (cgrp)); (pos);		\
+	     (pos) = cgroup_next_child((pos), (cgrp)))
 
 struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
 					  struct cgroup *cgroup);

commit 3b287a505ef4024634beb12a93773254909d5dae
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:24 2013 -0400

    cgroup: convert cgroup_next_sibling() to cgroup_next_child()
    
    cgroup is transitioning to using css (cgroup_subsys_state) as the main
    subsys interface handle instead of cgroup and the iterators will be
    updated to use css too.  The iterators need to walk the cgroup
    hierarchy and return the css's matching the origin css, which is a bit
    cumbersome to open code.
    
    This patch converts cgroup_next_sibling() to cgroup_next_child() so
    that it can handle all steps of direct child iteration.  This will be
    used to update iterators to take @css instead of @cgrp.  In addition
    to the new iteration init handling, cgroup_next_child() is
    restructured so that the different branches share the end of iteration
    condition check.
    
    This patch doesn't change any behavior.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0b91436c68ef..5f9ba5881717 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -779,7 +779,7 @@ static inline struct cgroup *cgroup_from_id(struct cgroup_subsys *ss, int id)
 	return idr_find(&ss->root->cgroup_idr, id);
 }
 
-struct cgroup *cgroup_next_sibling(struct cgroup *pos);
+struct cgroup *cgroup_next_child(struct cgroup *pos, struct cgroup *cgrp);
 
 /**
  * cgroup_for_each_child - iterate through children of a cgroup
@@ -802,7 +802,7 @@ struct cgroup *cgroup_next_sibling(struct cgroup *pos);
 #define cgroup_for_each_child(pos, cgrp)				\
 	for ((pos) = list_first_or_null_rcu(&(cgrp)->children,		\
 					    struct cgroup, sibling);	\
-	     (pos); (pos) = cgroup_next_sibling((pos)))
+	     (pos); (pos) = cgroup_next_child((pos), (cgrp)))
 
 struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
 					  struct cgroup *cgroup);

commit 182446d087906de40e514573a92a97b203695f71
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:24 2013 -0400

    cgroup: pass around cgroup_subsys_state instead of cgroup in file methods
    
    cgroup is currently in the process of transitioning to using struct
    cgroup_subsys_state * as the primary handle instead of struct cgroup.
    Please see the previous commit which converts the subsystem methods
    for rationale.
    
    This patch converts all cftype file operations to take @css instead of
    @cgroup.  cftypes for the cgroup core files don't have their subsytem
    pointer set.  These will automatically use the dummy_css added by the
    previous patch and can be converted the same way.
    
    Most subsystem conversions are straight forwards but there are some
    interesting ones.
    
    * freezer: update_if_frozen() is also converted to take @css instead
      of @cgroup for consistency.  This will make the code look simpler
      too once iterators are converted to use css.
    
    * memory/vmpressure: mem_cgroup_from_css() needs to be exported to
      vmpressure while mem_cgroup_from_cont() can be made static.
      Updated accordingly.
    
    * cpu: cgroup_tg() doesn't have any user left.  Removed.
    
    * cpuacct: cgroup_ca() doesn't have any user left.  Removed.
    
    * hugetlb: hugetlb_cgroup_form_cgroup() doesn't have any user left.
      Removed.
    
    * net_cls: cgrp_cls_state() doesn't have any user left.  Removed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Aristeu Rozanski <aris@redhat.com>
    Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b0d5f53ae5e1..0b91436c68ef 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -439,34 +439,34 @@ struct cftype {
 	struct cgroup_subsys *ss;
 
 	int (*open)(struct inode *inode, struct file *file);
-	ssize_t (*read)(struct cgroup *cgrp, struct cftype *cft,
+	ssize_t (*read)(struct cgroup_subsys_state *css, struct cftype *cft,
 			struct file *file,
 			char __user *buf, size_t nbytes, loff_t *ppos);
 	/*
 	 * read_u64() is a shortcut for the common case of returning a
 	 * single integer. Use it in place of read()
 	 */
-	u64 (*read_u64)(struct cgroup *cgrp, struct cftype *cft);
+	u64 (*read_u64)(struct cgroup_subsys_state *css, struct cftype *cft);
 	/*
 	 * read_s64() is a signed version of read_u64()
 	 */
-	s64 (*read_s64)(struct cgroup *cgrp, struct cftype *cft);
+	s64 (*read_s64)(struct cgroup_subsys_state *css, struct cftype *cft);
 	/*
 	 * read_map() is used for defining a map of key/value
 	 * pairs. It should call cb->fill(cb, key, value) for each
 	 * entry. The key/value pairs (and their ordering) should not
 	 * change between reboots.
 	 */
-	int (*read_map)(struct cgroup *cgrp, struct cftype *cft,
+	int (*read_map)(struct cgroup_subsys_state *css, struct cftype *cft,
 			struct cgroup_map_cb *cb);
 	/*
 	 * read_seq_string() is used for outputting a simple sequence
 	 * using seqfile.
 	 */
-	int (*read_seq_string)(struct cgroup *cgrp, struct cftype *cft,
-			       struct seq_file *m);
+	int (*read_seq_string)(struct cgroup_subsys_state *css,
+			       struct cftype *cft, struct seq_file *m);
 
-	ssize_t (*write)(struct cgroup *cgrp, struct cftype *cft,
+	ssize_t (*write)(struct cgroup_subsys_state *css, struct cftype *cft,
 			 struct file *file,
 			 const char __user *buf, size_t nbytes, loff_t *ppos);
 
@@ -475,18 +475,20 @@ struct cftype {
 	 * a single integer (as parsed by simple_strtoull) from
 	 * userspace. Use in place of write(); return 0 or error.
 	 */
-	int (*write_u64)(struct cgroup *cgrp, struct cftype *cft, u64 val);
+	int (*write_u64)(struct cgroup_subsys_state *css, struct cftype *cft,
+			 u64 val);
 	/*
 	 * write_s64() is a signed version of write_u64()
 	 */
-	int (*write_s64)(struct cgroup *cgrp, struct cftype *cft, s64 val);
+	int (*write_s64)(struct cgroup_subsys_state *css, struct cftype *cft,
+			 s64 val);
 
 	/*
 	 * write_string() is passed a nul-terminated kernelspace
 	 * buffer of maximum length determined by max_write_len.
 	 * Returns 0 or -ve error code.
 	 */
-	int (*write_string)(struct cgroup *cgrp, struct cftype *cft,
+	int (*write_string)(struct cgroup_subsys_state *css, struct cftype *cft,
 			    const char *buffer);
 	/*
 	 * trigger() callback can be used to get some kick from the
@@ -494,7 +496,7 @@ struct cftype {
 	 * at all. The private field can be used to determine the
 	 * kick type for multiplexing.
 	 */
-	int (*trigger)(struct cgroup *cgrp, unsigned int event);
+	int (*trigger)(struct cgroup_subsys_state *css, unsigned int event);
 
 	int (*release)(struct inode *inode, struct file *file);
 

commit 67f4c36f83455b253445b2cb28ac9a2c4f85d99a
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:24 2013 -0400

    cgroup: add cgroup->dummy_css
    
    cgroup subsystem API is being converted to use css
    (cgroup_subsys_state) as the main handle, which makes things a bit
    awkward for subsystem agnostic core features - the "cgroup.*"
    interface files and various iterations - a bit awkward as they don't
    have a css to use.
    
    This patch adds cgroup->dummy_css which has NULL ->ss and whose only
    role is pointing back to the cgroup.  This will be used to support
    subsystem agnostic features on the coming css based API.
    
    css_parent() is updated to handle dummy_css's.  Note that css will
    soon grow its own ->parent field and css_parent() will be made
    trivial.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5db8138a0482..b0d5f53ae5e1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -225,6 +225,9 @@ struct cgroup {
 	struct list_head pidlists;
 	struct mutex pidlist_mutex;
 
+	/* dummy css with NULL ->ss, points back to this cgroup */
+	struct cgroup_subsys_state dummy_css;
+
 	/* For css percpu_ref killing and RCU-protected deletion */
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
@@ -668,7 +671,13 @@ struct cgroup_subsys_state *css_parent(struct cgroup_subsys_state *css)
 {
 	struct cgroup *parent_cgrp = css->cgroup->parent;
 
-	return parent_cgrp ? parent_cgrp->subsys[css->ss->subsys_id] : NULL;
+	if (!parent_cgrp)
+		return NULL;
+
+	if (css->ss)
+		return parent_cgrp->subsys[css->ss->subsys_id];
+	else
+		return &parent_cgrp->dummy_css;
 }
 
 /**

commit 2bb566cb68dfafad328af666ebadf0e49accd6ca
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:23 2013 -0400

    cgroup: add subsys backlink pointer to cftype
    
    cgroup is transitioning to using css (cgroup_subsys_state) instead of
    cgroup as the primary subsystem handle.  The cgroupfs file interface
    will be converted to use css's which requires finding out the
    subsystem from cftype so that the matching css can be determined from
    the cgroup.
    
    This patch adds cftype->ss which points to the subsystem the file
    belongs to.  The field is initialized while a cftype is being
    registered.  This makes it unnecessary to explicitly specify the
    subsystem for other cftype handling functions.  @ss argument dropped
    from various cftype handling functions.
    
    This patch shouldn't introduce any behavior differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9c2b9dd9121d..5db8138a0482 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -429,6 +429,12 @@ struct cftype {
 	/* CFTYPE_* flags */
 	unsigned int flags;
 
+	/*
+	 * The subsys this file belongs to.  Initialized automatically
+	 * during registration.  NULL for cgroup core files.
+	 */
+	struct cgroup_subsys *ss;
+
 	int (*open)(struct inode *inode, struct file *file);
 	ssize_t (*read)(struct cgroup *cgrp, struct cftype *cft,
 			struct file *file,
@@ -542,7 +548,7 @@ static inline const char *cgroup_name(const struct cgroup *cgrp)
 }
 
 int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
-int cgroup_rm_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
+int cgroup_rm_cftypes(struct cftype *cfts);
 
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 

commit eb95419b023abacb415e2a18fea899023ce7624d
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:23 2013 -0400

    cgroup: pass around cgroup_subsys_state instead of cgroup in subsystem methods
    
    cgroup is currently in the process of transitioning to using struct
    cgroup_subsys_state * as the primary handle instead of struct cgroup *
    in subsystem implementations for the following reasons.
    
    * With unified hierarchy, subsystems will be dynamically bound and
      unbound from cgroups and thus css's (cgroup_subsys_state) may be
      created and destroyed dynamically over the lifetime of a cgroup,
      which is different from the current state where all css's are
      allocated and destroyed together with the associated cgroup.  This
      in turn means that cgroup_css() should be synchronized and may
      return NULL, making it more cumbersome to use.
    
    * Differing levels of per-subsystem granularity in the unified
      hierarchy means that the task and descendant iterators should behave
      differently depending on the specific subsystem the iteration is
      being performed for.
    
    * In majority of the cases, subsystems only care about its part in the
      cgroup hierarchy - ie. the hierarchy of css's.  Subsystem methods
      often obtain the matching css pointer from the cgroup and don't
      bother with the cgroup pointer itself.  Passing around css fits
      much better.
    
    This patch converts all cgroup_subsys methods to take @css instead of
    @cgroup.  The conversions are mostly straight-forward.  A few
    noteworthy changes are
    
    * ->css_alloc() now takes css of the parent cgroup rather than the
      pointer to the new cgroup as the css for the new cgroup doesn't
      exist yet.  Knowing the parent css is enough for all the existing
      subsystems.
    
    * In kernel/cgroup.c::offline_css(), unnecessary open coded css
      dereference is replaced with local variable access.
    
    This patch shouldn't cause any behavior differences.
    
    v2: Unnecessary explicit cgrp->subsys[] deref in css_online() replaced
        with local variable @css as suggested by Li Zefan.
    
        Rebased on top of new for-3.12 which includes for-3.11-fixes so
        that ->css_free() invocation added by da0a12caff ("cgroup: fix a
        leak when percpu_ref_init() fails") is converted too.  Suggested
        by Li Zefan.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Aristeu Rozanski <aris@redhat.com>
    Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 18112a3bb12b..9c2b9dd9121d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -579,18 +579,22 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
  */
 
 struct cgroup_subsys {
-	struct cgroup_subsys_state *(*css_alloc)(struct cgroup *cgrp);
-	int (*css_online)(struct cgroup *cgrp);
-	void (*css_offline)(struct cgroup *cgrp);
-	void (*css_free)(struct cgroup *cgrp);
-
-	int (*can_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
-	void (*cancel_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
-	void (*attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
+	struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state *parent_css);
+	int (*css_online)(struct cgroup_subsys_state *css);
+	void (*css_offline)(struct cgroup_subsys_state *css);
+	void (*css_free)(struct cgroup_subsys_state *css);
+
+	int (*can_attach)(struct cgroup_subsys_state *css,
+			  struct cgroup_taskset *tset);
+	void (*cancel_attach)(struct cgroup_subsys_state *css,
+			      struct cgroup_taskset *tset);
+	void (*attach)(struct cgroup_subsys_state *css,
+		       struct cgroup_taskset *tset);
 	void (*fork)(struct task_struct *task);
-	void (*exit)(struct cgroup *cgrp, struct cgroup *old_cgrp,
+	void (*exit)(struct cgroup_subsys_state *css,
+		     struct cgroup_subsys_state *old_css,
 		     struct task_struct *task);
-	void (*bind)(struct cgroup *root);
+	void (*bind)(struct cgroup_subsys_state *root_css);
 
 	int subsys_id;
 	int disabled;

commit 6387698699afd72d6304566fb6ccf84bffe07c56
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:23 2013 -0400

    cgroup: add css_parent()
    
    Currently, controllers have to explicitly follow the cgroup hierarchy
    to find the parent of a given css.  cgroup is moving towards using
    cgroup_subsys_state as the main controller interface construct, so
    let's provide a way to climb the hierarchy using just csses.
    
    This patch implements css_parent() which, given a css, returns its
    parent.  The function is guarnateed to valid non-NULL parent css as
    long as the target css is not at the top of the hierarchy.
    
    freezer, cpuset, cpu, cpuacct, hugetlb, memory, net_cls and devices
    are converted to use css_parent() instead of accessing cgroup->parent
    directly.
    
    * __parent_ca() is dropped from cpuacct and its usage is replaced with
      parent_ca().  The only difference between the two was NULL test on
      cgroup->parent which is now embedded in css_parent() making the
      distinction moot.  Note that eventually a css->parent field will be
      added to css and the NULL check in css_parent() will go away.
    
    This patch shouldn't cause any behavior differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 821678aae4db..18112a3bb12b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -646,6 +646,21 @@ struct cgroup_subsys {
 #undef IS_SUBSYS_ENABLED
 #undef SUBSYS
 
+/**
+ * css_parent - find the parent css
+ * @css: the target cgroup_subsys_state
+ *
+ * Return the parent css of @css.  This function is guaranteed to return
+ * non-NULL parent as long as @css isn't the root.
+ */
+static inline
+struct cgroup_subsys_state *css_parent(struct cgroup_subsys_state *css)
+{
+	struct cgroup *parent_cgrp = css->cgroup->parent;
+
+	return parent_cgrp ? parent_cgrp->subsys[css->ss->subsys_id] : NULL;
+}
+
 /**
  * cgroup_css - obtain a cgroup's css for the specified subsystem
  * @cgrp: the cgroup of interest

commit 72c97e54e0f043d33b246d7460ae0a36c4b8c643
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:22 2013 -0400

    cgroup: add subsystem pointer to cgroup_subsys_state
    
    Currently, given a cgroup_subsys_state, there's no way to find out
    which subsystem the css is for, which we'll need to convert the cgroup
    controller API to primarily use @css instead of @cgroup.  This patch
    adds cgroup_subsys_state->ss which points to the subsystem the @css
    belongs to.
    
    While at it, remove the comment about accessing @css->cgroup to
    determine the hierarchy.  cgroup core will provide API to traverse
    hierarchy of css'es and we don't want subsystems to directly walk
    cgroup hierarchies anymore.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 552c5feef733..821678aae4db 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -66,13 +66,12 @@ enum cgroup_subsys_id {
 
 /* Per-subsystem/per-cgroup state maintained by the system. */
 struct cgroup_subsys_state {
-	/*
-	 * The cgroup that this subsystem is attached to. Useful
-	 * for subsystems that want to know about the cgroup
-	 * hierarchy structure
-	 */
+	/* the cgroup that this css is attached to */
 	struct cgroup *cgroup;
 
+	/* the cgroup subsystem that this css is attached to */
+	struct cgroup_subsys *ss;
+
 	/* reference count - access via css_[try]get() and css_put() */
 	struct percpu_ref refcnt;
 

commit 8af01f56a03e9cbd91a55d688fce1315021efba8
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:22 2013 -0400

    cgroup: s/cgroup_subsys_state/cgroup_css/ s/task_subsys_state/task_css/
    
    The names of the two struct cgroup_subsys_state accessors -
    cgroup_subsys_state() and task_subsys_state() - are somewhat awkward.
    The former clashes with the type name and the latter doesn't even
    indicate it's somehow related to cgroup.
    
    We're about to revamp large portion of cgroup API, so, let's rename
    them so that they're less awkward.  Most per-controller usages of the
    accessors are localized in accessor wrappers and given the amount of
    scheduled changes, this isn't gonna add any noticeable headache.
    
    Rename cgroup_subsys_state() to cgroup_css() and task_subsys_state()
    to task_css().  This patch is pure rename.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 44dd422d7e9b..552c5feef733 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -647,8 +647,15 @@ struct cgroup_subsys {
 #undef IS_SUBSYS_ENABLED
 #undef SUBSYS
 
-static inline struct cgroup_subsys_state *cgroup_subsys_state(
-	struct cgroup *cgrp, int subsys_id)
+/**
+ * cgroup_css - obtain a cgroup's css for the specified subsystem
+ * @cgrp: the cgroup of interest
+ * @subsys_id: the subsystem of interest
+ *
+ * Return @cgrp's css (cgroup_subsys_state) associated with @subsys_id.
+ */
+static inline struct cgroup_subsys_state *cgroup_css(struct cgroup *cgrp,
+						     int subsys_id)
 {
 	return cgrp->subsys[subsys_id];
 }
@@ -678,7 +685,7 @@ extern struct mutex cgroup_mutex;
 #endif
 
 /**
- * task_subsys_state_check - obtain css for (task, subsys) w/ extra access conds
+ * task_css_check - obtain css for (task, subsys) w/ extra access conds
  * @task: the target task
  * @subsys_id: the target subsystem ID
  * @__c: extra condition expression to be passed to rcu_dereference_check()
@@ -686,7 +693,7 @@ extern struct mutex cgroup_mutex;
  * Return the cgroup_subsys_state for the (@task, @subsys_id) pair.  The
  * synchronization rules are the same as task_css_set_check().
  */
-#define task_subsys_state_check(task, subsys_id, __c)			\
+#define task_css_check(task, subsys_id, __c)				\
 	task_css_set_check((task), (__c))->subsys[(subsys_id)]
 
 /**
@@ -701,22 +708,22 @@ static inline struct css_set *task_css_set(struct task_struct *task)
 }
 
 /**
- * task_subsys_state - obtain css for (task, subsys)
+ * task_css - obtain css for (task, subsys)
  * @task: the target task
  * @subsys_id: the target subsystem ID
  *
- * See task_subsys_state_check().
+ * See task_css_check().
  */
-static inline struct cgroup_subsys_state *
-task_subsys_state(struct task_struct *task, int subsys_id)
+static inline struct cgroup_subsys_state *task_css(struct task_struct *task,
+						   int subsys_id)
 {
-	return task_subsys_state_check(task, subsys_id, false);
+	return task_css_check(task, subsys_id, false);
 }
 
-static inline struct cgroup* task_cgroup(struct task_struct *task,
-					       int subsys_id)
+static inline struct cgroup *task_cgroup(struct task_struct *task,
+					 int subsys_id)
 {
-	return task_subsys_state(task, subsys_id)->cgroup;
+	return task_css(task, subsys_id)->cgroup;
 }
 
 /**

commit 61584e3f4964995e575618f76ff7197123796e75
Merge: b395890a092d da0a12caffad
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Aug 2 16:12:13 2013 -0400

    cgroup: Merge branch 'for-3.11-fixes' into for-3.12
    
    for-3.12 branch is about to receive invasive updates which are
    dependent on da0a12caff ("cgroup: fix a leak when percpu_ref_init()
    fails").  Given the amount of scheduled changes, I think it'd less
    painful to pull in for-3.11-fixes as preparation.  Pull in
    for-3.11-fixes into for-3.12.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit e14880f7bb7e0dc0933af304998371dd543ceb40
Author: Li Zefan <lizefan@huawei.com>
Date:   Wed Jul 31 09:51:31 2013 +0800

    cgroup: implement cgroup_from_id()
    
    This will be used as a replacement for css_lookup().
    
    There's a difference with cgroup id and css id. cgroup id starts with 0,
    while css id starts with 1.
    
    v4:
    - also check if cggroup_mutex is held.
    - make it an inline function.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4dfcd0e1b73e..bbf4d89b56a8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -720,6 +720,24 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 	return task_subsys_state(task, subsys_id)->cgroup;
 }
 
+/**
+ * cgroup_from_id - lookup cgroup by id
+ * @ss: cgroup subsys to be looked into
+ * @id: the cgroup id
+ *
+ * Returns the cgroup if there's valid one with @id, otherwise returns NULL.
+ * Should be called under rcu_read_lock().
+ */
+static inline struct cgroup *cgroup_from_id(struct cgroup_subsys *ss, int id)
+{
+#ifdef CONFIG_PROVE_RCU
+	rcu_lockdep_assert(rcu_read_lock_held() ||
+			   lockdep_is_held(&cgroup_mutex),
+			   "cgroup_from_id() needs proper protection");
+#endif
+	return idr_find(&ss->root->cgroup_idr, id);
+}
+
 struct cgroup *cgroup_next_sibling(struct cgroup *pos);
 
 /**

commit b414dc09a31d41d696093a4cce9fb2853a5ecd4e
Author: Li Zefan <lizefan@huawei.com>
Date:   Wed Jul 31 09:51:06 2013 +0800

    cgroup: document how cgroup IDs are assigned
    
    As cgroup id has been used in netprio cgroup and will be used in memcg,
    it's important to make it clear how a cgroup id is allocated.
    
    For example, in netprio cgroup, the id is used as index of anarray.
    
    Signed-off-by: Li Zefan <lizefan@huwei.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cca570e188fb..4dfcd0e1b73e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -161,7 +161,13 @@ struct cgroup_name {
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
-	int id;				/* idr allocated in-hierarchy ID */
+	/*
+	 * idr allocated in-hierarchy ID.
+	 *
+	 * The ID of the root cgroup is always 0, and a new cgroup
+	 * will be assigned with a smallest available ID.
+	 */
+	int id;
 
 	/*
 	 * We link our 'sibling' struct into our parent's 'children'.

commit 4e96ee8e981b5140a2bcc5fff0d5c0eef39a62ee
Author: Li Zefan <lizefan@huawei.com>
Date:   Wed Jul 31 09:50:50 2013 +0800

    cgroup: convert cgroup_ida to cgroup_idr
    
    This enables us to lookup a cgroup by its id.
    
    v4:
    - add a comment for idr_remove() in cgroup_offline_fn().
    
    v3:
    - on success, idr_alloc() returns the id but not 0, so fix the BUG_ON()
      in cgroup_init().
    - pass the right value to idr_alloc() so that the id for dummy cgroup is 0.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 00a7e07a1567..cca570e188fb 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -161,7 +161,7 @@ struct cgroup_name {
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
-	int id;				/* ida allocated in-hierarchy ID */
+	int id;				/* idr allocated in-hierarchy ID */
 
 	/*
 	 * We link our 'sibling' struct into our parent's 'children'.
@@ -322,7 +322,7 @@ struct cgroupfs_root {
 	unsigned long flags;
 
 	/* IDs for cgroups in this hierarchy */
-	struct ida cgroup_ida;
+	struct idr cgroup_idr;
 
 	/* The path to use for release notifications. */
 	char release_agent_path[PATH_MAX];

commit 6f4b7e632d78c2d91502211c430722cc66428492
Author: Li Zefan <lizefan@huawei.com>
Date:   Wed Jul 31 16:18:36 2013 +0800

    cgroup: more naming cleanups
    
    Constantly use @cset for css_set variables and use @cgrp as cgroup
    variables.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 297462b9f41a..00a7e07a1567 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -394,8 +394,8 @@ struct cgroup_map_cb {
 
 /* cftype->flags */
 enum {
-	CFTYPE_ONLY_ON_ROOT	= (1 << 0),	/* only create on root cg */
-	CFTYPE_NOT_ON_ROOT	= (1 << 1),	/* don't create on root cg */
+	CFTYPE_ONLY_ON_ROOT	= (1 << 0),	/* only create on root cgrp */
+	CFTYPE_NOT_ON_ROOT	= (1 << 1),	/* don't create on root cgrp */
 	CFTYPE_INSANE		= (1 << 2),	/* don't create if sane_behavior */
 };
 
@@ -513,7 +513,7 @@ struct cftype_set {
 };
 
 struct cgroup_scanner {
-	struct cgroup *cg;
+	struct cgroup *cgrp;
 	int (*test_task)(struct task_struct *p, struct cgroup_scanner *scan);
 	void (*process_task)(struct task_struct *p,
 			struct cgroup_scanner *scan);

commit 913ffdb54366f94eec65c656cae8c6e00e1ab1b0
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jul 11 16:34:48 2013 -0700

    cgroup: replace task_cgroup_path_from_hierarchy() with task_cgroup_path()
    
    task_cgroup_path_from_hierarchy() was added for the planned new users
    and none of the currently planned users wants to know about multiple
    hierarchies.  This patch drops the multiple hierarchy part and makes
    it always return the path in the first non-dummy hierarchy.
    
    As unified hierarchy will always have id 1, this is guaranteed to
    return the path for the unified hierarchy if mounted; otherwise, it
    will return the path from the hierarchy which happens to occupy the
    lowest hierarchy id, which will usually be the first hierarchy mounted
    after boot.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Lennart Poettering <lennart@poettering.net>
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Cc: Jan Kaluža <jkaluza@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index fd097ecfcd97..21cfaff7e002 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -540,8 +540,7 @@ int cgroup_rm_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 
 int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
-int task_cgroup_path_from_hierarchy(struct task_struct *task, int hierarchy_id,
-				    char *buf, size_t buflen);
+int task_cgroup_path(struct task_struct *task, char *buf, size_t buflen);
 
 int cgroup_task_count(const struct cgroup *cgrp);
 

commit 36805aaea5ae3cf1bb32f1643e0a800bb69f0d5b
Merge: 6d2fa9e141ea d50235b7bc3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 11 13:03:24 2013 -0700

    Merge branch 'for-3.11/core' of git://git.kernel.dk/linux-block
    
    Pull core block IO updates from Jens Axboe:
     "Here are the core IO block bits for 3.11. It contains:
    
       - A tweak to the reserved tag logic from Jan, for weirdo devices with
         just 3 free tags.  But for those it improves things substantially
         for random writes.
    
       - Periodic writeback fix from Jan.  Marked for stable as well.
    
       - Fix for a race condition in IO scheduler switching from Jianpeng.
    
       - The hierarchical blk-cgroup support from Tejun.  This is the grunt
         of the series.
    
       - blk-throttle fix from Vivek.
    
      Just a note that I'm in the middle of a relocation, whole family is
      flying out tomorrow.  Hence I will be awal the remainder of this week,
      but back at work again on Monday the 15th.  CC'ing Tejun, since any
      potential "surprises" will most likely be from the blk-cgroup work.
      But it's been brewing for a while and sitting in my tree and
      linux-next for a long time, so should be solid."
    
    * 'for-3.11/core' of git://git.kernel.dk/linux-block: (36 commits)
      elevator: Fix a race in elevator switching
      block: Reserve only one queue tag for sync IO if only 3 tags are available
      writeback: Fix periodic writeback after fs mount
      blk-throttle: implement proper hierarchy support
      blk-throttle: implement throtl_grp->has_rules[]
      blk-throttle: Account for child group's start time in parent while bio climbs up
      blk-throttle: add throtl_qnode for dispatch fairness
      blk-throttle: make throtl_pending_timer_fn() ready for hierarchy
      blk-throttle: make tg_dispatch_one_bio() ready for hierarchy
      blk-throttle: make blk_throtl_bio() ready for hierarchy
      blk-throttle: make blk_throtl_drain() ready for hierarchy
      blk-throttle: dispatch from throtl_pending_timer_fn()
      blk-throttle: implement dispatch looping
      blk-throttle: separate out throtl_service_queue->pending_timer from throtl_data->dispatch_work
      blk-throttle: set REQ_THROTTLED from throtl_charge_bio() and gate stats update with it
      blk-throttle: implement sq_to_tg(), sq_to_td() and throtl_log()
      blk-throttle: add throtl_service_queue->parent_sq
      blk-throttle: generalize update_disptime optimization in blk_throtl_bio()
      blk-throttle: dispatch to throtl_data->service_queue.bio_lists[]
      blk-throttle: move bio_lists[] and friends to throtl_service_queue
      ...

commit 0b0585c3e192967cb2ef0ac0816eb8a8c8d99840
Merge: b028161fbba1 c9e5fe66f594
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 2 20:04:25 2013 -0700

    Merge branch 'for-3.11-cpuset' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cpuset changes from Tejun Heo:
     "cpuset has always been rather odd about its configurations - a cgroup
      right after creation didn't allow any task executions before
      configuration, changing configuration in the parent modifies the
      descendants irreversibly and so on.  These behaviors are inherently
      nasty and almost hostile against sharing the hierarchy with other
      controllers making it very difficult to use in unified hierarchy.
    
      Li is currently in the process of updating the behaviors for
      __DEVEL__sane_behavior which is the bulk of changes in this pull
      request.  It isn't complete yet and the behaviors will change further
      but all changes are gated behind sane_behavior.  In the process, the
      rather hairy work-item punting which was used to work around the
      limitations of cgroup descendant iterator was simplified."
    
    * 'for-3.11-cpuset' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cpuset: rename @cont to @cgrp
      cpuset: fix to migrate mm correctly in a corner case
      cpuset: allow to move tasks to empty cpusets
      cpuset: allow to keep tasks in empty cpusets
      cpuset: introduce effective_{cpumask|nodemask}_cpuset()
      cpuset: record old_mems_allowed in struct cpuset
      cpuset: remove async hotplug propagation work
      cpuset: let hotplug propagation work wait for task attaching
      cpuset: re-structure update_cpumask() a bit
      cpuset: remove cpuset_test_cpumask()
      cpuset: remove unnecessary variable in cpuset_attach()
      cpuset: cleanup guarantee_online_{cpus|mems}()
      cpuset: remove redundant check in cpuset_cpus_allowed_fallback()

commit 0ce6cba35777cf96a54ce0d5856dc962566b8717
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 27 19:37:26 2013 -0700

    cgroup: CGRP_ROOT_SUBSYS_BOUND should be ignored when comparing mount options
    
    1672d04070 ("cgroup: fix cgroupfs_root early destruction path")
    introduced CGRP_ROOT_SUBSYS_BOUND which is used to mark completion of
    subsys binding on a new root; however, this broke remounts.
    cgroup_remount() doesn't allow changing root options via remount and
    CGRP_ROOT_SUBSYS_BOUND, which is set on all fully initialized roots,
    makes the function reject all remounts.
    
    Fix it by putting the options part in the lower 16 bits of root->flags
    and masking the comparions.  While at it, make cgroup_remount() emit
    an error message explaining why it's rejecting a remount request, so
    that it's less of a mystery.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ad3555bc21f4..8db53974f7b5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -276,7 +276,11 @@ enum {
 
 	CGRP_ROOT_NOPREFIX	= (1 << 1), /* mounted subsystems have no named prefix */
 	CGRP_ROOT_XATTR		= (1 << 2), /* supports extended attributes */
-	CGRP_ROOT_SUBSYS_BOUND	= (1 << 3), /* subsystems finished binding */
+
+	/* mount options live below bit 16 */
+	CGRP_ROOT_OPTION_MASK	= (1 << 16) - 1,
+
+	CGRP_ROOT_SUBSYS_BOUND	= (1 << 16), /* subsystems finished binding */
 };
 
 /*

commit 14611e51a57df10240817d8ada510842faf0ec51
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jun 25 11:48:32 2013 -0700

    cgroup: fix RCU accesses to task->cgroups
    
    task->cgroups is a RCU pointer pointing to struct css_set.  A task
    switches to a different css_set on cgroup migration but a css_set
    doesn't change once created and its pointers to cgroup_subsys_states
    aren't RCU protected.
    
    task_subsys_state[_check]() is the macro to acquire css given a task
    and subsys_id pair.  It RCU-dereferences task->cgroups->subsys[] not
    task->cgroups, so the RCU pointer task->cgroups ends up being
    dereferenced without read_barrier_depends() after it.  It's broken.
    
    Fix it by introducing task_css_set[_check]() which does
    RCU-dereference on task->cgroups.  task_subsys_state[_check]() is
    reimplemented to directly dereference ->subsys[] of the css_set
    returned from task_css_set[_check]().
    
    This removes some of sparse RCU warnings in cgroup.
    
    v2: Fixed unbalanced parenthsis and there's no need to use
        rcu_dereference_raw() when !CONFIG_PROVE_RCU.  Both spotted by Li.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: stable@vger.kernel.org

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8e4fd5e67384..ad3555bc21f4 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -635,22 +635,60 @@ static inline struct cgroup_subsys_state *cgroup_subsys_state(
 	return cgrp->subsys[subsys_id];
 }
 
-/*
- * function to get the cgroup_subsys_state which allows for extra
- * rcu_dereference_check() conditions, such as locks used during the
- * cgroup_subsys::attach() methods.
+/**
+ * task_css_set_check - obtain a task's css_set with extra access conditions
+ * @task: the task to obtain css_set for
+ * @__c: extra condition expression to be passed to rcu_dereference_check()
+ *
+ * A task's css_set is RCU protected, initialized and exited while holding
+ * task_lock(), and can only be modified while holding both cgroup_mutex
+ * and task_lock() while the task is alive.  This macro verifies that the
+ * caller is inside proper critical section and returns @task's css_set.
+ *
+ * The caller can also specify additional allowed conditions via @__c, such
+ * as locks used during the cgroup_subsys::attach() methods.
  */
 #ifdef CONFIG_PROVE_RCU
 extern struct mutex cgroup_mutex;
-#define task_subsys_state_check(task, subsys_id, __c)			\
-	rcu_dereference_check((task)->cgroups->subsys[(subsys_id)],	\
-			      lockdep_is_held(&(task)->alloc_lock) ||	\
-			      lockdep_is_held(&cgroup_mutex) || (__c))
+#define task_css_set_check(task, __c)					\
+	rcu_dereference_check((task)->cgroups,				\
+		lockdep_is_held(&(task)->alloc_lock) ||			\
+		lockdep_is_held(&cgroup_mutex) || (__c))
 #else
-#define task_subsys_state_check(task, subsys_id, __c)			\
-	rcu_dereference((task)->cgroups->subsys[(subsys_id)])
+#define task_css_set_check(task, __c)					\
+	rcu_dereference((task)->cgroups)
 #endif
 
+/**
+ * task_subsys_state_check - obtain css for (task, subsys) w/ extra access conds
+ * @task: the target task
+ * @subsys_id: the target subsystem ID
+ * @__c: extra condition expression to be passed to rcu_dereference_check()
+ *
+ * Return the cgroup_subsys_state for the (@task, @subsys_id) pair.  The
+ * synchronization rules are the same as task_css_set_check().
+ */
+#define task_subsys_state_check(task, subsys_id, __c)			\
+	task_css_set_check((task), (__c))->subsys[(subsys_id)]
+
+/**
+ * task_css_set - obtain a task's css_set
+ * @task: the task to obtain css_set for
+ *
+ * See task_css_set_check().
+ */
+static inline struct css_set *task_css_set(struct task_struct *task)
+{
+	return task_css_set_check(task, false);
+}
+
+/**
+ * task_subsys_state - obtain css for (task, subsys)
+ * @task: the target task
+ * @subsys_id: the target subsystem ID
+ *
+ * See task_subsys_state_check().
+ */
 static inline struct cgroup_subsys_state *
 task_subsys_state(struct task_struct *task, int subsys_id)
 {

commit 1672d040709b789671c0502e7aac9d632c2f9175
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jun 25 18:04:54 2013 -0700

    cgroup: fix cgroupfs_root early destruction path
    
    cgroupfs_root used to have ->actual_subsys_mask in addition to
    ->subsys_mask.  a8a648c4ac ("cgroup: remove
    cgroup->actual_subsys_mask") removed it noting that the subsys_mask is
    essentially temporary and doesn't belong in cgroupfs_root; however,
    the patch made it impossible to tell whether a cgroupfs_root actually
    has the subsystems bound or just have the bits set leading to the
    following BUG when trying to mount with subsystems which are already
    mounted elsewhere.
    
     kernel BUG at kernel/cgroup.c:1038!
     invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
     ...
     CPU: 1 PID: 7973 Comm: mount Tainted: G        W    3.10.0-rc7-next-20130625-sasha-00011-g1c1dc0e #1105
     task: ffff880fc0ae8000 ti: ffff880fc0b9a000 task.ti: ffff880fc0b9a000
     RIP: 0010:[<ffffffff81249b29>]  [<ffffffff81249b29>] rebind_subsystems+0x409/0x5f0
     ...
     Call Trace:
      [<ffffffff8124bd4f>] cgroup_kill_sb+0xff/0x210
      [<ffffffff813d21af>] deactivate_locked_super+0x4f/0x90
      [<ffffffff8124f3b3>] cgroup_mount+0x673/0x6e0
      [<ffffffff81257169>] cpuset_mount+0xd9/0x110
      [<ffffffff813d2580>] mount_fs+0xb0/0x2d0
      [<ffffffff81404afd>] vfs_kern_mount+0xbd/0x180
      [<ffffffff814070b5>] do_new_mount+0x145/0x2c0
      [<ffffffff814085d6>] do_mount+0x356/0x3c0
      [<ffffffff8140873d>] SyS_mount+0xfd/0x140
      [<ffffffff854eb600>] tracesys+0xdd/0xe2
    
    We still want rebind_subsystems() to take added/removed masks, so
    let's fix it by marking whether a cgroupfs_root has finished binding
    or not.  Also, document what's going on around ->subsys_mask
    initialization so that similar mistakes aren't repeated.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 4c1eceb8c439..8e4fd5e67384 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -276,6 +276,7 @@ enum {
 
 	CGRP_ROOT_NOPREFIX	= (1 << 1), /* mounted subsystems have no named prefix */
 	CGRP_ROOT_XATTR		= (1 << 2), /* supports extended attributes */
+	CGRP_ROOT_SUBSYS_BOUND	= (1 << 3), /* subsystems finished binding */
 };
 
 /*

commit a8a648c4acee2095262f7fa65b0d8a68a03c32e4
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Jun 24 15:21:47 2013 -0700

    cgroup: remove cgroup->actual_subsys_mask
    
    cgroup curiously has two subsystem masks, ->subsys_mask and
    ->actual_subsys_mask.  The latter only exists because the new target
    subsys_mask is passed into rebind_subsystems() via @root>subsys_mask.
    rebind_subsystems() needs to know what the current mask is to decide
    how to reach the target mask so ->actual_subsys_mask is used as the
    temp location to remember the current state.
    
    Adding a temporary field to a permanent data structure is rather silly
    and can be misleading.  Update rebind_subsystems() to take @added_mask
    and @removed_mask instead and remove @root->actual_subsys_mask.
    
    This patch shouldn't introduce any behavior changes.
    
    v2: Comment and description updated as suggested by Li.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ab27001a2c4a..4c1eceb8c439 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -286,18 +286,12 @@ enum {
 struct cgroupfs_root {
 	struct super_block *sb;
 
-	/*
-	 * The bitmask of subsystems intended to be attached to this
-	 * hierarchy
-	 */
+	/* The bitmask of subsystems attached to this hierarchy */
 	unsigned long subsys_mask;
 
 	/* Unique id for this hierarchy. */
 	int hierarchy_id;
 
-	/* The bitmask of subsystems currently attached to this hierarchy */
-	unsigned long actual_subsys_mask;
-
 	/* A list running through the attached subsystems */
 	struct list_head subsys_list;
 

commit 02c402d98588bdfd3bebd267db574e13afdef722
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Jun 24 15:21:47 2013 -0700

    cgroup: convert CFTYPE_* flags to enums
    
    Purely cosmetic.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 6c2ba52fc5d4..ab27001a2c4a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -385,9 +385,11 @@ struct cgroup_map_cb {
  */
 
 /* cftype->flags */
-#define CFTYPE_ONLY_ON_ROOT	(1U << 0)	/* only create on root cg */
-#define CFTYPE_NOT_ON_ROOT	(1U << 1)	/* don't create on root cg */
-#define CFTYPE_INSANE		(1U << 2)	/* don't create if sane_behavior */
+enum {
+	CFTYPE_ONLY_ON_ROOT	= (1 << 0),	/* only create on root cg */
+	CFTYPE_NOT_ON_ROOT	= (1 << 1),	/* don't create on root cg */
+	CFTYPE_INSANE		= (1 << 2),	/* don't create if sane_behavior */
+};
 
 #define MAX_CFTYPE_NAME		64
 

commit 03c78cbebb323fc97295ff97dc5e009d56371d57
Author: Li Zefan <lizefan@huawei.com>
Date:   Fri Jun 14 11:17:19 2013 +0800

    cgroup: rename cont to cgrp
    
    Cont is short for container. control group was named process container
    at first, but then people found container already has a meaning in
    linux kernel.
    
    Clean up the leftover variable name @cont.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b28365890646..6c2ba52fc5d4 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -433,13 +433,13 @@ struct cftype {
 	 * entry. The key/value pairs (and their ordering) should not
 	 * change between reboots.
 	 */
-	int (*read_map)(struct cgroup *cont, struct cftype *cft,
+	int (*read_map)(struct cgroup *cgrp, struct cftype *cft,
 			struct cgroup_map_cb *cb);
 	/*
 	 * read_seq_string() is used for outputting a simple sequence
 	 * using seqfile.
 	 */
-	int (*read_seq_string)(struct cgroup *cont, struct cftype *cft,
+	int (*read_seq_string)(struct cgroup *cgrp, struct cftype *cft,
 			       struct seq_file *m);
 
 	ssize_t (*write)(struct cgroup *cgrp, struct cftype *cft,

commit e8c82d20a9f729cf4b9f73043f7fd4e0872bebfd
Author: Li Zefan <lizefan@huawei.com>
Date:   Tue Jun 18 18:48:37 2013 +0800

    cgroup: convert cgroup_cft_commit() to use cgroup_for_each_descendant_pre()
    
    We used root->allcg_list to iterate cgroup hierarchy because at that time
    cgroup_for_each_descendant_pre() hasn't been invented.
    
    tj: In cgroup_cfts_commit(), s/@serial_nr/@update_upto/, move the
        assignment right above releasing cgroup_mutex and explain what's
        going on there.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f97522790682..b28365890646 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -206,9 +206,6 @@ struct cgroup {
 	 */
 	struct list_head cset_links;
 
-	struct list_head allcg_node;	/* cgroupfs_root->allcg_list */
-	struct list_head cft_q_node;	/* used during cftype add/rm */
-
 	/*
 	 * Linked list running through all cgroups that can
 	 * potentially be reaped by the release agent. Protected by
@@ -313,9 +310,6 @@ struct cgroupfs_root {
 	/* A list running through the active hierarchies */
 	struct list_head root_list;
 
-	/* All cgroups on this root, cgroup_mutex protected */
-	struct list_head allcg_list;
-
 	/* Hierarchy-specific flags */
 	unsigned long flags;
 

commit 6db8e85c5c1f89cd0183b76dab027c81009f129f
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jun 14 11:18:22 2013 -0700

    cgroup: disallow rename(2) if sane_behavior
    
    cgroup's rename(2) isn't a proper migration implementation - it can't
    move the cgroup to a different parent in the hierarchy.  All it can do
    is swapping the name string for that cgroup.  This isn't useful and
    can mislead users to think that cgroup supports proper cgroup-level
    migration.  Disallow rename(2) if sane_behavior.
    
    v2: Fail with -EPERM instead of -EINVAL so that it matches the vfs
        return value when ->rename is not implemented as suggested by Li.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 17604767adfd..f97522790682 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -270,6 +270,8 @@ enum {
 	 * - "release_agent" and "notify_on_release" are removed.
 	 *   Replacement notification mechanism will be implemented.
 	 *
+	 * - rename(2) is disallowed.
+	 *
 	 * - memcg: use_hierarchy is on by default and the cgroup file for
 	 *   the flag is not created.
 	 */

commit f63674fd0d6afa1ba24309aee1f8c60195d39041
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 13 19:58:38 2013 -0700

    cgroup: update sane_behavior documentation
    
    f12dc02014 ("cgroup: mark "tasks" cgroup file as insane") and
    cc5943a781 ("cgroup: mark "notify_on_release" and "release_agent"
    cgroup files insane") forgot to update the changed behavior
    documentation in cgroup.h.  Update it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b7bd4beae294..17604767adfd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -264,13 +264,14 @@ enum {
 	 *
 	 * - Remount is disallowed.
 	 *
-	 * - memcg: use_hierarchy is on by default and the cgroup file for
-	 *   the flag is not created.
+	 * - "tasks" is removed.  Everything should be at process
+	 *   granularity.  Use "cgroup.procs" instead.
 	 *
-	 * The followings are planned changes.
+	 * - "release_agent" and "notify_on_release" are removed.
+	 *   Replacement notification mechanism will be implemented.
 	 *
-	 * - release_agent will be disallowed once replacement notification
-	 *   mechanism is implemented.
+	 * - memcg: use_hierarchy is on by default and the cgroup file for
+	 *   the flag is not created.
 	 */
 	CGRP_ROOT_SANE_BEHAVIOR	= (1 << 0),
 

commit d3daf28da16a30af95bfb303189a634a87606725
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 13 19:39:16 2013 -0700

    cgroup: use percpu refcnt for cgroup_subsys_states
    
    A css (cgroup_subsys_state) is how each cgroup is represented to a
    controller.  As such, it can be used in hot paths across the various
    subsystems different controllers are associated with.
    
    One of the common operations is reference counting, which up until now
    has been implemented using a global atomic counter and can have
    significant adverse impact on scalability.  For example, css refcnt
    can be gotten and put multiple times by blkcg for each IO request.
    For highops configurations which try to do as much per-cpu as
    possible, the global frequent refcnting can be very expensive.
    
    In general, given the various and hugely diverse paths css's end up
    being used from, we need to make it cheap and highly scalable.  In its
    usage, css refcnting isn't very different from module refcnting.
    
    This patch converts css refcnting to use the recently added
    percpu_ref.  css_get/tryget/put() directly maps to the matching
    percpu_ref operations and the deactivation logic is no longer
    necessary as percpu_ref already has refcnt killing.
    
    The only complication is that as the refcnt is per-cpu,
    percpu_ref_kill() in itself doesn't ensure that further tryget
    operations will fail, which we need to guarantee before invoking
    ->css_offline()'s.  This is resolved collecting kill confirmation
    using percpu_ref_kill_and_confirm() and initiating the offline phase
    of destruction after all css refcnt's are confirmed to be seen as
    killed on all CPUs.  The previous patches already splitted destruction
    into two phases, so percpu_ref_kill_and_confirm() can be hooked up
    easily.
    
    This patch removes css_refcnt() which is used for rcu dereference
    sanity check in css_id().  While we can add a percpu refcnt API to ask
    the same question, css_id() itself is scheduled to be removed fairly
    soon, so let's not bother with it.  Just drop the sanity check and use
    rcu_dereference_raw() instead.
    
    v2: - init_cgroup_css() was calling percpu_ref_init() without checking
          the return value.  This causes two problems - the obvious lack
          of error handling and percpu_ref_init() being called from
          cgroup_init_subsys() before the allocators are up, which
          triggers warnings but doesn't cause actual problems as the
          refcnt isn't used for roots anyway.  Fix both by moving
          percpu_ref_init() to cgroup_create().
    
        - The base references were put too early by
          percpu_ref_kill_and_confirm() and cgroup_offline_fn() put the
          refs one extra time.  This wasn't noticeable because css's go
          through another RCU grace period before being freed.  Update
          cgroup_destroy_locked() to grab an extra reference before
          killing the refcnts.  This problem was noticed by Kent.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Kent Overstreet <koverstreet@google.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: "Alasdair G. Kergon" <agk@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Mikulas Patocka <mpatocka@redhat.com>
    Cc: Glauber Costa <glommer@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e345d8b90046..b7bd4beae294 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -20,6 +20,7 @@
 #include <linux/workqueue.h>
 #include <linux/xattr.h>
 #include <linux/fs.h>
+#include <linux/percpu-refcount.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -72,13 +73,8 @@ struct cgroup_subsys_state {
 	 */
 	struct cgroup *cgroup;
 
-	/*
-	 * State maintained by the cgroup system to allow subsystems
-	 * to be "busy". Should be accessed via css_get(),
-	 * css_tryget() and css_put().
-	 */
-
-	atomic_t refcnt;
+	/* reference count - access via css_[try]get() and css_put() */
+	struct percpu_ref refcnt;
 
 	unsigned long flags;
 	/* ID for this css, if possible */
@@ -104,11 +100,9 @@ static inline void css_get(struct cgroup_subsys_state *css)
 {
 	/* We don't need to reference count the root state */
 	if (!(css->flags & CSS_ROOT))
-		atomic_inc(&css->refcnt);
+		percpu_ref_get(&css->refcnt);
 }
 
-extern bool __css_tryget(struct cgroup_subsys_state *css);
-
 /**
  * css_tryget - try to obtain a reference on the specified css
  * @css: target css
@@ -123,11 +117,9 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
 {
 	if (css->flags & CSS_ROOT)
 		return true;
-	return __css_tryget(css);
+	return percpu_ref_tryget(&css->refcnt);
 }
 
-extern void __css_put(struct cgroup_subsys_state *css);
-
 /**
  * css_put - put a css reference
  * @css: target css
@@ -137,7 +129,7 @@ extern void __css_put(struct cgroup_subsys_state *css);
 static inline void css_put(struct cgroup_subsys_state *css)
 {
 	if (!(css->flags & CSS_ROOT))
-		__css_put(css);
+		percpu_ref_put(&css->refcnt);
 }
 
 /* bits in struct cgroup flags field */
@@ -231,9 +223,10 @@ struct cgroup {
 	struct list_head pidlists;
 	struct mutex pidlist_mutex;
 
-	/* For RCU-protected deletion */
+	/* For css percpu_ref killing and RCU-protected deletion */
 	struct rcu_head rcu_head;
 	struct work_struct destroy_work;
+	atomic_t css_kill_cnt;
 
 	/* List of events which userspace want to receive */
 	struct list_head event_list;

commit ea15f8ccdb430af1e8bc9b4e19a230eb4c356777
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 13 19:27:42 2013 -0700

    cgroup: split cgroup destruction into two steps
    
    Split cgroup_destroy_locked() into two steps and put the latter half
    into cgroup_offline_fn() which is executed from a work item.  The
    latter half is responsible for offlining the css's, removing the
    cgroup from internal lists, and propagating release notification to
    the parent.  The separation is to allow using percpu refcnt for css.
    
    Note that this allows for other cgroup operations to happen between
    the first and second halves of destruction, including creating a new
    cgroup with the same name.  As the target cgroup is marked DEAD in the
    first half and cgroup internals don't care about the names of cgroups,
    this should be fine.  A comment explaining this will be added by the
    next patch which implements the actual percpu refcnting.
    
    As RCU freeing is guaranteed to happen after the second step of
    destruction, we can use the same work item for both.  This patch
    renames cgroup->free_work to ->destroy_work and uses it for both
    purposes.  INIT_WORK() is now performed right before queueing the work
    item.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 81bfd0268e93..e345d8b90046 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -233,7 +233,7 @@ struct cgroup {
 
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;
-	struct work_struct free_work;
+	struct work_struct destroy_work;
 
 	/* List of events which userspace want to receive */
 	struct list_head event_list;

commit 6f3d828f0fb7fdaffc6f32cb8a1cb7fcf8824598
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jun 12 21:04:55 2013 -0700

    cgroup: remove cgroup->count and use
    
    cgroup->count tracks the number of css_sets associated with the cgroup
    and used only to verify that no css_set is associated when the cgroup
    is being destroyed.  It's superflous as the destruction path can
    simply check whether cgroup->cset_links is empty instead.
    
    Drop cgroup->count and check ->cset_links directly from
    cgroup_destroy_locked().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c86a93abe83d..81bfd0268e93 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -169,12 +169,6 @@ struct cgroup_name {
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
-	/*
-	 * count users of this cgroup. >0 means busy, but doesn't
-	 * necessarily indicate the number of tasks in the cgroup
-	 */
-	atomic_t count;
-
 	int id;				/* ida allocated in-hierarchy ID */
 
 	/*

commit 54766d4a1d3d6f84ff8fa475cd8f165c0a0000eb
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jun 12 21:04:53 2013 -0700

    cgroup: rename CGRP_REMOVED to CGRP_DEAD
    
    We will add another flag indicating that the cgroup is in the process
    of being killed.  REMOVING / REMOVED is more difficult to distinguish
    and cgroup_is_removing()/cgroup_is_removed() are a bit awkward.  Also,
    later percpu_ref usage will involve "kill"ing the refcnt.
    
     s/CGRP_REMOVED/CGRP_DEAD/
     s/cgroup_is_removed()/cgroup_is_dead()
    
    This patch is purely cosmetic.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a494636a34da..c86a93abe83d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -143,7 +143,7 @@ static inline void css_put(struct cgroup_subsys_state *css)
 /* bits in struct cgroup flags field */
 enum {
 	/* Control Group is dead */
-	CGRP_REMOVED,
+	CGRP_DEAD,
 	/*
 	 * Control Group has previously had a child cgroup or a task,
 	 * but no longer (only if CGRP_NOTIFY_ON_RELEASE is set)

commit 5de0107e634ce862f16360139709d9d3a656463e
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jun 12 21:04:52 2013 -0700

    cgroup: clean up css_[try]get() and css_put()
    
    * __css_get() isn't used by anyone.  Fold it into css_get().
    
    * Add proper function comments to all css reference functions.
    
    This patch is purely cosmetic.
    
    v2: Typo fix as per Li.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0e32855edc92..a494636a34da 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -94,33 +94,31 @@ enum {
 	CSS_ONLINE	= (1 << 1), /* between ->css_online() and ->css_offline() */
 };
 
-/* Caller must verify that the css is not for root cgroup */
-static inline void __css_get(struct cgroup_subsys_state *css, int count)
-{
-	atomic_add(count, &css->refcnt);
-}
-
-/*
- * Call css_get() to hold a reference on the css; it can be used
- * for a reference obtained via:
- * - an existing ref-counted reference to the css
- * - task->cgroups for a locked task
+/**
+ * css_get - obtain a reference on the specified css
+ * @css: target css
+ *
+ * The caller must already have a reference.
  */
-
 static inline void css_get(struct cgroup_subsys_state *css)
 {
 	/* We don't need to reference count the root state */
 	if (!(css->flags & CSS_ROOT))
-		__css_get(css, 1);
+		atomic_inc(&css->refcnt);
 }
 
-/*
- * Call css_tryget() to take a reference on a css if your existing
- * (known-valid) reference isn't already ref-counted. Returns false if
- * the css has been destroyed.
- */
-
 extern bool __css_tryget(struct cgroup_subsys_state *css);
+
+/**
+ * css_tryget - try to obtain a reference on the specified css
+ * @css: target css
+ *
+ * Obtain a reference on @css if it's alive.  The caller naturally needs to
+ * ensure that @css is accessible but doesn't have to be holding a
+ * reference on it - IOW, RCU protected access is good enough for this
+ * function.  Returns %true if a reference count was successfully obtained;
+ * %false otherwise.
+ */
 static inline bool css_tryget(struct cgroup_subsys_state *css)
 {
 	if (css->flags & CSS_ROOT)
@@ -128,12 +126,14 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
 	return __css_tryget(css);
 }
 
-/*
- * css_put() should be called to release a reference taken by
- * css_get() or css_tryget()
- */
-
 extern void __css_put(struct cgroup_subsys_state *css);
+
+/**
+ * css_put - put a css reference
+ * @css: target css
+ *
+ * Put a reference obtained via css_get() and css_tryget().
+ */
 static inline void css_put(struct cgroup_subsys_state *css)
 {
 	if (!(css->flags & CSS_ROOT))

commit 69d0206c793a17431eacee2694ee7a4b25df76b7
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jun 12 21:04:50 2013 -0700

    cgroup: bring some sanity to naming around cg_cgroup_link
    
    cgroups and css_sets are mapped M:N and this M:N mapping is
    represented by struct cg_cgroup_link which forms linked lists on both
    sides.  The naming around this mapping is already confusing and struct
    cg_cgroup_link exacerbates the situation quite a bit.
    
    >From cgroup side, it starts off ->css_sets and runs through
    ->cgrp_link_list.  From css_set side, it starts off ->cg_links and
    runs through ->cg_link_list.  This is rather reversed as
    cgrp_link_list is used to iterate css_sets and cg_link_list cgroups.
    Also, this is the only place which is still using the confusing "cg"
    for css_sets.  This patch cleans it up a bit.
    
    * s/cgroup->css_sets/cgroup->cset_links/
      s/css_set->cg_links/css_set->cgrp_links/
      s/cgroup_iter->cg_link/cgroup_iter->cset_link/
    
    * s/cg_cgroup_link/cgrp_cset_link/
    
    * s/cgrp_cset_link->cg/cgrp_cset_link->cset/
      s/cgrp_cset_link->cgrp_link_list/cgrp_cset_link->cset_link/
      s/cgrp_cset_link->cg_link_list/cgrp_cset_link->cgrp_link/
    
    * s/init_css_set_link/init_cgrp_cset_link/
      s/free_cg_links/free_cgrp_cset_links/
      s/allocate_cg_links/allocate_cgrp_cset_links/
    
    * s/cgl[12]/link[12]/ in compare_css_sets()
    
    * s/saved_link/tmp_link/ s/tmp/tmp_links/ and a couple similar
      adustments.
    
    * Comment and whiteline adjustments.
    
    After the changes, we have
    
            list_for_each_entry(link, &cont->cset_links, cset_link) {
                    struct css_set *cset = link->cset;
    
    instead of
    
            list_for_each_entry(link, &cont->css_sets, cgrp_link_list) {
                    struct css_set *cset = link->cg;
    
    This patch is purely cosmetic.
    
    v2: Fix broken sentences in the patch description.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5830592258dc..0e32855edc92 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -215,10 +215,10 @@ struct cgroup {
 	struct cgroupfs_root *root;
 
 	/*
-	 * List of cg_cgroup_links pointing at css_sets with
-	 * tasks in this cgroup. Protected by css_set_lock
+	 * List of cgrp_cset_links pointing at css_sets with tasks in this
+	 * cgroup.  Protected by css_set_lock.
 	 */
-	struct list_head css_sets;
+	struct list_head cset_links;
 
 	struct list_head allcg_node;	/* cgroupfs_root->allcg_list */
 	struct list_head cft_q_node;	/* used during cftype add/rm */
@@ -365,11 +365,10 @@ struct css_set {
 	struct list_head tasks;
 
 	/*
-	 * List of cg_cgroup_link objects on link chains from
-	 * cgroups referenced from this css_set. Protected by
-	 * css_set_lock
+	 * List of cgrp_cset_links pointing at cgroups referenced from this
+	 * css_set.  Protected by css_set_lock.
 	 */
-	struct list_head cg_links;
+	struct list_head cgrp_links;
 
 	/*
 	 * Set of subsystem states, one for each subsystem. This array
@@ -792,7 +791,7 @@ struct cgroup *cgroup_next_descendant_post(struct cgroup *pos,
 
 /* A cgroup_iter should be treated as an opaque object */
 struct cgroup_iter {
-	struct list_head *cg_link;
+	struct list_head *cset_link;
 	struct list_head *task;
 };
 

commit 3fc3db9a3ae0ce108badf31a4a00e41b4236f5fc
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jun 12 21:04:48 2013 -0700

    cgroup: remove now unused css_depth()
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d0ad3794b947..5830592258dc 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -848,7 +848,6 @@ bool css_is_ancestor(struct cgroup_subsys_state *cg,
 
 /* Get id and depth of css */
 unsigned short css_id(struct cgroup_subsys_state *css);
-unsigned short css_depth(struct cgroup_subsys_state *css);
 struct cgroup_subsys_state *cgroup_css_from_dir(struct file *f, int id);
 
 #else /* !CONFIG_CGROUPS */

commit 88fa523bff295f1d60244a54833480b02f775152
Author: Li Zefan <lizefan@huawei.com>
Date:   Sun Jun 9 17:16:46 2013 +0800

    cpuset: allow to move tasks to empty cpusets
    
    Currently some cpuset behaviors are not friendly when cpuset is co-mounted
    with other cgroup controllers.
    
    Now with this patchset if cpuset is mounted with sane_behavior option,
    it behaves differently:
    
    - Tasks will be kept in empty cpusets when hotplug happens and take
      masks of ancestors with non-empty cpus/mems, instead of being moved to
      an ancestor.
    
    - A task can be moved into an empty cpuset, and again it takes masks of
      ancestors, so the user can drop a task into a newly created cgroup without
      having to do anything for it.
    
    As tasks can reside in empy cpusets, here're some rules:
    
    - They can be moved to another cpuset, regardless it's empty or not.
    
    - Though it takes masks from ancestors, it takes other configs from the
      empty cpuset.
    
    - If the ancestors' masks are changed, those tasks will also be updated
      to take new masks.
    
    v2: add documentation in include/linux/cgroup.h
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 53e81a61be57..74e8b8e4cd7f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -281,6 +281,9 @@ enum {
 	 *   and take masks of ancestors with non-empty cpus/mems, instead of
 	 *   being moved to an ancestor.
 	 *
+	 * - cpuset: a task can be moved into an empty cpuset, and again it
+	 *   takes masks of ancestors.
+	 *
 	 * - memcg: use_hierarchy is on by default and the cgroup file for
 	 *   the flag is not created.
 	 *

commit 5c5cc62321d9df7a9a608346fc649c4528380c8f
Author: Li Zefan <lizefan@huawei.com>
Date:   Sun Jun 9 17:16:29 2013 +0800

    cpuset: allow to keep tasks in empty cpusets
    
    To achieve this:
    
    - We call update_tasks_cpumask/nodemask() for empty cpusets when
    hotplug happens, instead of moving tasks out of them.
    
    - When a cpuset's masks are changed by writing cpuset.cpus/mems,
    we also update tasks in child cpusets which are empty.
    
    v3:
    - do propagation work in one place for both hotplug and unplug
    
    v2:
    - drop rcu_read_lock before calling update_task_nodemask() and
      update_task_cpumask(), instead of using workqueue.
    - add documentation in include/linux/cgroup.h
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d0ad3794b947..53e81a61be57 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -277,6 +277,10 @@ enum {
 	 *
 	 * - Remount is disallowed.
 	 *
+	 * - cpuset: tasks will be kept in empty cpusets when hotplug happens
+	 *   and take masks of ancestors with non-empty cpus/mems, instead of
+	 *   being moved to an ancestor.
+	 *
 	 * - memcg: use_hierarchy is on by default and the cgroup file for
 	 *   the flag is not created.
 	 *

commit 75501a6d59e989e5c286716e5b3b66ace4660e83
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 24 10:55:38 2013 +0900

    cgroup: update iterators to use cgroup_next_sibling()
    
    This patch converts cgroup_for_each_child(),
    cgroup_next_descendant_pre/post() and thus
    cgroup_for_each_descendant_pre/post() to use cgroup_next_sibling()
    instead of manually dereferencing ->sibling.next.
    
    The only reason the iterators couldn't allow dropping RCU read lock
    while iteration is in progress was because they couldn't determine the
    next sibling safely once RCU read lock is dropped.  Using
    cgroup_next_sibling() removes that problem and enables all iterators
    to allow dropping RCU read lock in the middle.  Comments are updated
    accordingly.
    
    This makes the iterators easier to use and will simplify controllers.
    
    Note that @cgroup argument is renamed to @cgrp in
    cgroup_for_each_child() because it conflicts with "struct cgroup" used
    in the new macro body.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ee041a01a67e..d0ad3794b947 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -688,9 +688,9 @@ struct cgroup *cgroup_next_sibling(struct cgroup *pos);
 /**
  * cgroup_for_each_child - iterate through children of a cgroup
  * @pos: the cgroup * to use as the loop cursor
- * @cgroup: cgroup whose children to walk
+ * @cgrp: cgroup whose children to walk
  *
- * Walk @cgroup's children.  Must be called under rcu_read_lock().  A child
+ * Walk @cgrp's children.  Must be called under rcu_read_lock().  A child
  * cgroup which hasn't finished ->css_online() or already has finished
  * ->css_offline() may show up during traversal and it's each subsystem's
  * responsibility to verify that each @pos is alive.
@@ -698,9 +698,15 @@ struct cgroup *cgroup_next_sibling(struct cgroup *pos);
  * If a subsystem synchronizes against the parent in its ->css_online() and
  * before starting iterating, a cgroup which finished ->css_online() is
  * guaranteed to be visible in the future iterations.
+ *
+ * It is allowed to temporarily drop RCU read lock during iteration.  The
+ * caller is responsible for ensuring that @pos remains accessible until
+ * the start of the next iteration by, for example, bumping the css refcnt.
  */
-#define cgroup_for_each_child(pos, cgroup)				\
-	list_for_each_entry_rcu(pos, &(cgroup)->children, sibling)
+#define cgroup_for_each_child(pos, cgrp)				\
+	for ((pos) = list_first_or_null_rcu(&(cgrp)->children,		\
+					    struct cgroup, sibling);	\
+	     (pos); (pos) = cgroup_next_sibling((pos)))
 
 struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
 					  struct cgroup *cgroup);
@@ -759,6 +765,10 @@ struct cgroup *cgroup_rightmost_descendant(struct cgroup *pos);
  * Alternatively, a subsystem may choose to use a single global lock to
  * synchronize ->css_online() and ->css_offline() against tree-walking
  * operations.
+ *
+ * It is allowed to temporarily drop RCU read lock during iteration.  The
+ * caller is responsible for ensuring that @pos remains accessible until
+ * the start of the next iteration by, for example, bumping the css refcnt.
  */
 #define cgroup_for_each_descendant_pre(pos, cgroup)			\
 	for (pos = cgroup_next_descendant_pre(NULL, (cgroup)); (pos);	\

commit 53fa5261747a90746531e8a1c81eeb78fedc2f71
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 24 10:55:38 2013 +0900

    cgroup: add cgroup->serial_nr and implement cgroup_next_sibling()
    
    Currently, there's no easy way to find out the next sibling cgroup
    unless it's known that the current cgroup is accessed from the
    parent's children list in a single RCU critical section.  This in turn
    forces all iterators to require whole iteration to be enclosed in a
    single RCU critical section, which sometimes is too restrictive.  This
    patch implements cgroup_next_sibling() which can reliably determine
    the next sibling regardless of the state of the current cgroup as long
    as it's accessible.
    
    It currently is impossible to determine the next sibling after
    dropping RCU read lock because the cgroup being iterated could be
    removed anytime and if RCU read lock is dropped, nothing guarantess
    its ->sibling.next pointer is accessible.  A removed cgroup would
    continue to point to its next sibling for RCU accesses but stop
    receiving updates from the sibling.  IOW, the next sibling could be
    removed and then complete its grace period while RCU read lock is
    dropped, making it unsafe to dereference ->sibling.next after dropping
    and re-acquiring RCU read lock.
    
    This can be solved by adding a way to traverse to the next sibling
    without dereferencing ->sibling.next.  This patch adds a monotonically
    increasing cgroup serial number, cgroup->serial_nr, which guarantees
    that all cgroup->children lists are kept in increasing serial_nr
    order.  A new function, cgroup_next_sibling(), is implemented, which,
    if CGRP_REMOVED is not set on the current cgroup, follows
    ->sibling.next; otherwise, traverses the parent's ->children list
    until it sees a sibling with higher ->serial_nr.
    
    This allows the function to always return the next sibling regardless
    of the state of the current cgroup without adding overhead in the fast
    path.
    
    Further patches will update the iterators to use cgroup_next_sibling()
    so that they allow dropping RCU read lock and blocking while iteration
    is in progress which in turn will be used to simplify controllers.
    
    v2: Typo fix as per Serge.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8d9f3c911fca..ee041a01a67e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -188,6 +188,14 @@ struct cgroup {
 	struct cgroup *parent;		/* my parent */
 	struct dentry *dentry;		/* cgroup fs entry, RCU protected */
 
+	/*
+	 * Monotonically increasing unique serial number which defines a
+	 * uniform order among all cgroups.  It's guaranteed that all
+	 * ->children lists are in the ascending order of ->serial_nr.
+	 * It's used to allow interrupting and resuming iterations.
+	 */
+	u64 serial_nr;
+
 	/*
 	 * This is a copy of dentry->d_name, and it's needed because
 	 * we can't use dentry->d_name in cgroup_path().
@@ -675,6 +683,8 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 	return task_subsys_state(task, subsys_id)->cgroup;
 }
 
+struct cgroup *cgroup_next_sibling(struct cgroup *pos);
+
 /**
  * cgroup_for_each_child - iterate through children of a cgroup
  * @pos: the cgroup * to use as the loop cursor

commit bdc7119f1bdd0632d42f435941dc290216a436e7
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 24 10:55:38 2013 +0900

    cgroup: make cgroup_is_removed() static
    
    cgroup_is_removed() no longer has external users and it shouldn't grow
    any - controllers should deal with cgroup_subsys_state on/offline
    state instead of cgroup removal state.  Make it static.
    
    While at it, make it return bool.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1df5f699be61..8d9f3c911fca 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -538,7 +538,6 @@ static inline const char *cgroup_name(const struct cgroup *cgrp)
 int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 
-int cgroup_is_removed(const struct cgroup *cgrp);
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 
 int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);

commit 3f33e64f4a212771a0b5c63eddaa7f81e65223e3
Merge: 23958e729e70 7805d000db30
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 24 10:53:09 2013 +0900

    Merge branch 'for-3.10-fixes' into for-3.11
    
    Merging to receive 7805d000db ("cgroup: fix a subtle bug in descendant
    pre-order walk") so that further iterator updates can build upon it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit 7805d000db30a3787a4c969bab6ae4d8a5fd8ce6
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 24 10:50:24 2013 +0900

    cgroup: fix a subtle bug in descendant pre-order walk
    
    When cgroup_next_descendant_pre() initiates a walk, it checks whether
    the subtree root doesn't have any children and if not returns NULL.
    Later code assumes that the subtree isn't empty.  This is broken
    because the subtree may become empty inbetween, which can lead to the
    traversal escaping the subtree by walking to the sibling of the
    subtree root.
    
    There's no reason to have the early exit path.  Remove it along with
    the later assumption that the subtree isn't empty.  This simplifies
    the code a bit and fixes the subtle bug.
    
    While at it, fix the comment of cgroup_for_each_descendant_pre() which
    was incorrectly referring to ->css_offline() instead of
    ->css_online().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Cc: stable@vger.kernel.org

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5047355b9a0f..8bda1294c035 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -707,7 +707,7 @@ struct cgroup *cgroup_rightmost_descendant(struct cgroup *pos);
  *
  * If a subsystem synchronizes against the parent in its ->css_online() and
  * before starting iterating, and synchronizes against @pos on each
- * iteration, any descendant cgroup which finished ->css_offline() is
+ * iteration, any descendant cgroup which finished ->css_online() is
  * guaranteed to be visible in the future iterations.
  *
  * In other words, the following guarantees that a descendant can't escape

commit 9138125beabbb76b4a373d4a619870f6f5d86fc5
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 14 13:52:38 2013 -0700

    blk-throttle: implement proper hierarchy support
    
    With the recent updates, blk-throttle is finally ready for proper
    hierarchy support.  Dispatching now honors service_queue->parent_sq
    and propagates correctly.  The only thing missing is setting
    ->parent_sq correctly so that throtl_grp hierarchy matches the cgroup
    hierarchy.
    
    This patch updates throtl_pd_init() such that service_queues form the
    same hierarchy as the cgroup hierarchy if sane_behavior is enabled.
    As this concludes proper hierarchy support for blkcg, the shameful
    .broken_hierarchy tag is removed from blkio_subsys.
    
    v2: Updated blkio-controller.txt as suggested by Vivek.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Cc: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5047355b9a0f..09f1a1408ae0 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -272,6 +272,8 @@ enum {
 	 * - memcg: use_hierarchy is on by default and the cgroup file for
 	 *   the flag is not created.
 	 *
+	 * - blkcg: blk-throttle becomes properly hierarchical.
+	 *
 	 * The followings are planned changes.
 	 *
 	 * - release_agent will be disallowed once replacement notification

commit 23958e729e7029678e746bf8f4094c8863a79c3d
Author: Greg KH <gregkh@linuxfoundation.org>
Date:   Fri May 3 16:26:59 2013 -0700

    cgroup.h: remove some functions that are now gone
    
    cgroup_lock() and cgroup_unlock() are now no longer exported, so fix
    cgroup.h to not declare them if CONFIG_CGROUPS is not enabled.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 383c630f36f9..4f6f5138c340 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -840,8 +840,6 @@ static inline void cgroup_fork(struct task_struct *p) {}
 static inline void cgroup_post_fork(struct task_struct *p) {}
 static inline void cgroup_exit(struct task_struct *p, int callbacks) {}
 
-static inline void cgroup_lock(void) {}
-static inline void cgroup_unlock(void) {}
 static inline int cgroupstats_build(struct cgroupstats *stats,
 					struct dentry *dentry)
 {

commit 857a2beb09ab83e9a8185821ae16db7dfbe8b837
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 14 20:50:08 2013 -0700

    cgroup: implement task_cgroup_path_from_hierarchy()
    
    kdbus folks want a sane way to determine the cgroup path that a given
    task belongs to on a given hierarchy, which is a reasonble thing to
    expect from cgroup core.
    
    Implement task_cgroup_path_from_hierarchy().
    
    v2: Dropped unnecessary NULL check on the return value of
        task_cgroup_from_root() as suggested by Li Zefan.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Greg Kroah-Hartman <greg@kroah.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Kay Sievers <kay@vrfy.org>
    Cc: Lennart Poettering <lennart@poettering.net>
    Cc: Daniel Mack <daniel@zonque.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5047355b9a0f..383c630f36f9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -542,6 +542,8 @@ int cgroup_is_removed(const struct cgroup *cgrp);
 bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 
 int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
+int task_cgroup_path_from_hierarchy(struct task_struct *task, int hierarchy_id,
+				    char *buf, size_t buflen);
 
 int cgroup_task_count(const struct cgroup *cgrp);
 

commit a27bb332c04cec8c4afd7912df0dc7890db27560
Author: Kent Overstreet <koverstreet@google.com>
Date:   Tue May 7 16:19:08 2013 -0700

    aio: don't include aio.h in sched.h
    
    Faster kernel compiles by way of fewer unnecessary includes.
    
    [akpm@linux-foundation.org: fix fallout]
    [akpm@linux-foundation.org: fix build]
    Signed-off-by: Kent Overstreet <koverstreet@google.com>
    Cc: Zach Brown <zab@redhat.com>
    Cc: Felipe Balbi <balbi@ti.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Benjamin LaHaise <bcrl@kvack.org>
    Reviewed-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3bff9ce09cf7..5047355b9a0f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -28,6 +28,7 @@ struct cgroup_subsys;
 struct inode;
 struct cgroup;
 struct css_id;
+struct eventfd_ctx;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);

commit 20b4fb485227404329e41ad15588afad3df23050
Merge: b9394d8a657c ac3e3c5b1164
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 1 17:51:54 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull VFS updates from Al Viro,
    
    Misc cleanups all over the place, mainly wrt /proc interfaces (switch
    create_proc_entry to proc_create(), get rid of the deprecated
    create_proc_read_entry() in favor of using proc_create_data() and
    seq_file etc).
    
    7kloc removed.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (204 commits)
      don't bother with deferred freeing of fdtables
      proc: Move non-public stuff from linux/proc_fs.h to fs/proc/internal.h
      proc: Make the PROC_I() and PDE() macros internal to procfs
      proc: Supply a function to remove a proc entry by PDE
      take cgroup_open() and cpuset_open() to fs/proc/base.c
      ppc: Clean up scanlog
      ppc: Clean up rtas_flash driver somewhat
      hostap: proc: Use remove_proc_subtree()
      drm: proc: Use remove_proc_subtree()
      drm: proc: Use minor->index to label things, not PDE->name
      drm: Constify drm_proc_list[]
      zoran: Don't print proc_dir_entry data in debug
      reiserfs: Don't access the proc_dir_entry in r_open(), r_start() r_show()
      proc: Supply an accessor for getting the data from a PDE's parent
      airo: Use remove_proc_subtree()
      rtl8192u: Don't need to save device proc dir PDE
      rtl8187se: Use a dir under /proc/net/r8180/
      proc: Add proc_mkdir_data()
      proc: Move some bits from linux/proc_fs.h to linux/{of.h,signal.h,tty.h}
      proc: Move PDE_NET() to fs/proc/proc_net.c
      ...

commit 8d8b97ba499cb69fccb5fd9f2b439e3265fc3f27
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Apr 19 23:11:24 2013 -0400

    take cgroup_open() and cpuset_open() to fs/proc/base.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 900af5964f55..68f2157b71d4 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -42,7 +42,7 @@ extern int cgroupstats_build(struct cgroupstats *stats,
 extern int cgroup_load_subsys(struct cgroup_subsys *ss);
 extern void cgroup_unload_subsys(struct cgroup_subsys *ss);
 
-extern const struct file_operations proc_cgroup_operations;
+extern int proc_cgroup_show(struct seq_file *, void *);
 
 /* Define the enumeration of all builtin cgroup subsystems */
 #define SUBSYS(_x) _x ## _subsys_id,

commit 16fa94b532b1958f508e07eca1a9256351241fbc
Merge: e0972916e8fe 25f55d9d01ad
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 30 07:43:28 2013 -0700

    Merge branch 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull scheduler changes from Ingo Molnar:
     "The main changes in this development cycle were:
    
       - full dynticks preparatory work by Frederic Weisbecker
    
       - factor out the cpu time accounting code better, by Li Zefan
    
       - multi-CPU load balancer cleanups and improvements by Joonsoo Kim
    
       - various smaller fixes and cleanups"
    
    * 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (45 commits)
      sched: Fix init NOHZ_IDLE flag
      sched: Prevent to re-select dst-cpu in load_balance()
      sched: Rename load_balance_tmpmask to load_balance_mask
      sched: Move up affinity check to mitigate useless redoing overhead
      sched: Don't consider other cpus in our group in case of NEWLY_IDLE
      sched: Explicitly cpu_idle_type checking in rebalance_domains()
      sched: Change position of resched_cpu() in load_balance()
      sched: Fix wrong rq's runnable_avg update with rt tasks
      sched: Document task_struct::personality field
      sched/cpuacct/UML: Fix header file dependency bug on the UML build
      cgroup: Kill subsys.active flag
      sched/cpuacct: No need to check subsys active state
      sched/cpuacct: Initialize cpuacct subsystem earlier
      sched/cpuacct: Initialize root cpuacct earlier
      sched/cpuacct: Allocate per_cpu cpuusage for root cpuacct statically
      sched/cpuacct: Clean up cpuacct.h
      sched/cpuacct: Remove redundant NULL checks in cpuacct_acount_field()
      sched/cpuacct: Remove redundant NULL checks in cpuacct_charge()
      sched/cpuacct: Add cpuacct_acount_field()
      sched/cpuacct: Add cpuacct_init()
      ...

commit 191a712090bb8a10e6f129360eeed2d68f3d4c9a
Merge: 46d9be3e5eb0 2a0010af17b1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 29 19:14:20 2013 -0700

    Merge branch 'for-3.10' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
    
     - Fixes and a lot of cleanups.  Locking cleanup is finally complete.
       cgroup_mutex is no longer exposed to individual controlelrs which
       used to cause nasty deadlock issues.  Li fixed and cleaned up quite a
       bit including long standing ones like racy cgroup_path().
    
     - device cgroup now supports proper hierarchy thanks to Aristeu.
    
     - perf_event cgroup now supports proper hierarchy.
    
     - A new mount option "__DEVEL__sane_behavior" is added.  As indicated
       by the name, this option is to be used for development only at this
       point and generates a warning message when used.  Unfortunately,
       cgroup interface currently has too many brekages and inconsistencies
       to implement a consistent and unified hierarchy on top.  The new flag
       is used to collect the behavior changes which are necessary to
       implement consistent unified hierarchy.  It's likely that this flag
       won't be used verbatim when it becomes ready but will be enabled
       implicitly along with unified hierarchy.
    
       The option currently disables some of broken behaviors in cgroup core
       and also .use_hierarchy switch in memcg (will be routed through -mm),
       which can be used to make very unusual hierarchy where nesting is
       partially honored.  It will also be used to implement hierarchy
       support for blk-throttle which would be impossible otherwise without
       introducing a full separate set of control knobs.
    
       This is essentially versioning of interface which isn't very nice but
       at this point I can't see any other options which would allow keeping
       the interface the same while moving towards hierarchy behavior which
       is at least somewhat sane.  The planned unified hierarchy is likely
       to require some level of adaptation from userland anyway, so I think
       it'd be best to take the chance and update the interface such that
       it's supportable in the long term.
    
       Maintaining the existing interface does complicate cgroup core but
       shouldn't put too much strain on individual controllers and I think
       it'd be manageable for the foreseeable future.  Maybe we'll be able
       to drop it in a decade.
    
    Fix up conflicts (including a semantic one adding a new #include to ppc
    that was uncovered by header the file changes) as per Tejun.
    
    * 'for-3.10' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup: (45 commits)
      cpuset: fix compile warning when CONFIG_SMP=n
      cpuset: fix cpu hotplug vs rebuild_sched_domains() race
      cpuset: use rebuild_sched_domains() in cpuset_hotplug_workfn()
      cgroup: restore the call to eventfd->poll()
      cgroup: fix use-after-free when umounting cgroupfs
      cgroup: fix broken file xattrs
      devcg: remove parent_cgroup.
      memcg: force use_hierarchy if sane_behavior
      cgroup: remove cgrp->top_cgroup
      cgroup: introduce sane_behavior mount option
      move cgroupfs_root to include/linux/cgroup.h
      cgroup: convert cgroupfs_root flag bits to masks and add CGRP_ prefix
      cgroup: make cgroup_path() not print double slashes
      Revert "cgroup: remove bind() method from cgroup_subsys."
      perf: make perf_event cgroup hierarchical
      cgroup: implement cgroup_is_descendant()
      cgroup: make sure parent won't be destroyed before its children
      cgroup: remove bind() method from cgroup_subsys.
      devcg: remove broken_hierarchy tag
      cgroup: remove cgroup_lock_is_held()
      ...

commit 6d2488f64a240191f0733c1f32d73607916b01b7
Author: Michal Hocko <mhocko@suse.cz>
Date:   Mon Apr 29 15:07:21 2013 -0700

    cgroup: remove css_get_next
    
    Now that we have generic and well ordered cgroup tree walkers there is
    no need to keep css_get_next in the place.
    
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Ying Han <yinghan@google.com>
    Cc: Tejun Heo <htejun@gmail.com>
    Cc: Glauber Costa <glommer@parallels.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 900af5964f55..470073bf93d0 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -687,13 +687,6 @@ void free_css_id(struct cgroup_subsys *ss, struct cgroup_subsys_state *css);
 
 struct cgroup_subsys_state *css_lookup(struct cgroup_subsys *ss, int id);
 
-/*
- * Get a cgroup whose id is greater than or equal to id under tree of root.
- * Returning a cgroup_subsys_state or NULL.
- */
-struct cgroup_subsys_state *css_get_next(struct cgroup_subsys *ss, int id,
-		struct cgroup_subsys_state *root, int *foundid);
-
 /* Returns true if root is ancestor of cg */
 bool css_is_ancestor(struct cgroup_subsys_state *cg,
 		     const struct cgroup_subsys_state *root);

commit 712317ad97f41e738e1a19aa0a6392a78a84094e
Author: Li Zefan <lizefan@huawei.com>
Date:   Thu Apr 18 23:09:52 2013 -0700

    cgroup: fix broken file xattrs
    
    We should store file xattrs in struct cfent instead of struct cftype,
    because cftype is a type while cfent is object instance of cftype.
    
    For example each cgroup has a tasks file, and each tasks file is
    associated with a uniq cfent, but all those files share the same
    struct cftype.
    
    Alexey Kodanev reported a crash, which can be reproduced:
    
      # mount -t cgroup -o xattr /sys/fs/cgroup
      # mkdir /sys/fs/cgroup/test
      # setfattr -n trusted.value -v test_value /sys/fs/cgroup/tasks
      # rmdir /sys/fs/cgroup/test
      # umount /sys/fs/cgroup
      oops!
    
    In this case, simple_xattrs_free() will free the same struct simple_xattrs
    twice.
    
    tj: Dropped unused local variable @cft from cgroup_diput().
    
    Cc: <stable@vger.kernel.org> # 3.8.x
    Reported-by: Alexey Kodanev <alexey.kodanev@oracle.com>
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cda7eb2239e1..c371888298d5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -422,9 +422,6 @@ struct cftype {
 	/* CFTYPE_* flags */
 	unsigned int flags;
 
-	/* file xattrs */
-	struct simple_xattrs xattrs;
-
 	int (*open)(struct inode *inode, struct file *file);
 	ssize_t (*read)(struct cgroup *cgrp, struct cftype *cft,
 			struct file *file,

commit f00baae7ad6c5f1503528efa852f0be8e9513f0e
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Apr 15 13:41:15 2013 -0700

    memcg: force use_hierarchy if sane_behavior
    
    Turn on use_hierarchy by default if sane_behavior is specified and
    don't create .use_hierarchy file.
    
    It is debatable whether to remove .use_hierarchy file or make it ro as
    the former could make transition easier in certain cases; however, the
    behavior changes which will be gated by sane_behavior are intensive
    including changing basic meaning of certain control knobs in a few
    controllers and I don't really think keeping this piece would make
    things easier in any noticeable way, so let's remove it.
    
    v2: Explain that mem_cgroup_bind() doesn't have to worry about
        children as suggested by Michal Hocko.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 64047ae7fde1..cda7eb2239e1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -268,6 +268,9 @@ enum {
 	 *
 	 * - Remount is disallowed.
 	 *
+	 * - memcg: use_hierarchy is on by default and the cgroup file for
+	 *   the flag is not created.
+	 *
 	 * The followings are planned changes.
 	 *
 	 * - release_agent will be disallowed once replacement notification

commit 05fb22ec5456a472a5eadcaacb3e51eca1f8c79c
Author: Li Zefan <lizefan@huawei.com>
Date:   Mon Apr 15 14:25:05 2013 +0800

    cgroup: remove cgrp->top_cgroup
    
    It's not used, and it can be retrieved via cgrp->root->top_cgroup.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9c300ad9a911..64047ae7fde1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -204,7 +204,6 @@ struct cgroup {
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
 
 	struct cgroupfs_root *root;
-	struct cgroup *top_cgroup;
 
 	/*
 	 * List of cg_cgroup_links pointing at css_sets with

commit 873fe09ea5df6ccf6bb34811d8c9992aacb67598
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 14 20:15:26 2013 -0700

    cgroup: introduce sane_behavior mount option
    
    It's a sad fact that at this point various cgroup controllers are
    carrying so many idiosyncrasies and pure insanities that it simply
    isn't possible to reach any sort of sane consistent behavior while
    maintaining staying fully compatible with what already has been
    exposed to userland.
    
    As we can't break exposed userland interface, transitioning to sane
    behaviors can only be done in steps while maintaining backwards
    compatibility.  This patch introduces a new mount option -
    __DEVEL__sane_behavior - which disables crazy features and enforces
    consistent behaviors in cgroup core proper and various controllers.
    As exactly which behaviors it changes are still being determined, the
    mount option, at this point, is useful only for development of the new
    behaviors.  As such, the mount option is prefixed with __DEVEL__ and
    generates a warning message when used.
    
    Eventually, once we get to the point where all controller's behaviors
    are consistent enough to implement unified hierarchy, the __DEVEL__
    prefix will be dropped, and more importantly, unified-hierarchy will
    enforce sane_behavior by default.  Maybe we'll able to completely drop
    the crazy stuff after a while, maybe not, but we at least have a
    strategy to move on to saner behaviors.
    
    This patch introduces the mount option and changes the following
    behaviors in cgroup core.
    
    * Mount options "noprefix" and "clone_children" are disallowed.  Also,
      cgroupfs file cgroup.clone_children is not created.
    
    * When mounting an existing superblock, mount options should match.
      This is currently pretty crazy.  If one mounts a cgroup, creates a
      subdirectory, unmounts it and then mount it again with different
      option, it looks like the new options are applied but they aren't.
    
    * Remount is disallowed.
    
    The behaviors changes are documented in the comment above
    CGRP_ROOT_SANE_BEHAVIOR enum and will be expanded as different
    controllers are converted and planned improvements progress.
    
    v2: Dropped unnecessary explicit file permission setting sane_behavior
        cftype entry as suggested by Li Zefan.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Vivek Goyal <vgoyal@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b21881e1ea08..9c300ad9a911 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -156,6 +156,8 @@ enum {
 	 * specified at mount time and thus is implemented here.
 	 */
 	CGRP_CPUSET_CLONE_CHILDREN,
+	/* see the comment above CGRP_ROOT_SANE_BEHAVIOR for details */
+	CGRP_SANE_BEHAVIOR,
 };
 
 struct cgroup_name {
@@ -243,6 +245,37 @@ struct cgroup {
 
 /* cgroupfs_root->flags */
 enum {
+	/*
+	 * Unfortunately, cgroup core and various controllers are riddled
+	 * with idiosyncrasies and pointless options.  The following flag,
+	 * when set, will force sane behavior - some options are forced on,
+	 * others are disallowed, and some controllers will change their
+	 * hierarchical or other behaviors.
+	 *
+	 * The set of behaviors affected by this flag are still being
+	 * determined and developed and the mount option for this flag is
+	 * prefixed with __DEVEL__.  The prefix will be dropped once we
+	 * reach the point where all behaviors are compatible with the
+	 * planned unified hierarchy, which will automatically turn on this
+	 * flag.
+	 *
+	 * The followings are the behaviors currently affected this flag.
+	 *
+	 * - Mount options "noprefix" and "clone_children" are disallowed.
+	 *   Also, cgroupfs file cgroup.clone_children is not created.
+	 *
+	 * - When mounting an existing superblock, mount options should
+	 *   match.
+	 *
+	 * - Remount is disallowed.
+	 *
+	 * The followings are planned changes.
+	 *
+	 * - release_agent will be disallowed once replacement notification
+	 *   mechanism is implemented.
+	 */
+	CGRP_ROOT_SANE_BEHAVIOR	= (1 << 0),
+
 	CGRP_ROOT_NOPREFIX	= (1 << 1), /* mounted subsystems have no named prefix */
 	CGRP_ROOT_XATTR		= (1 << 2), /* supports extended attributes */
 };
@@ -360,6 +393,7 @@ struct cgroup_map_cb {
 /* cftype->flags */
 #define CFTYPE_ONLY_ON_ROOT	(1U << 0)	/* only create on root cg */
 #define CFTYPE_NOT_ON_ROOT	(1U << 1)	/* don't create on root cg */
+#define CFTYPE_INSANE		(1U << 2)	/* don't create if sane_behavior */
 
 #define MAX_CFTYPE_NAME		64
 
@@ -486,6 +520,15 @@ struct cgroup_scanner {
 	void *data;
 };
 
+/*
+ * See the comment above CGRP_ROOT_SANE_BEHAVIOR for details.  This
+ * function can be called as long as @cgrp is accessible.
+ */
+static inline bool cgroup_sane_behavior(const struct cgroup *cgrp)
+{
+	return cgrp->root->flags & CGRP_ROOT_SANE_BEHAVIOR;
+}
+
 /* Caller should hold rcu_read_lock() */
 static inline const char *cgroup_name(const struct cgroup *cgrp)
 {

commit 25a7e6848db76e22677aff202d9c4ef3503be15b
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 14 20:15:25 2013 -0700

    move cgroupfs_root to include/linux/cgroup.h
    
    While controllers shouldn't be accessing cgroupfs_root directly, it
    being hidden inside kern/cgroup.c makes somethings pretty silly.  This
    makes routing hierarchy-wide settings which need to be visible to
    controllers cumbersome.
    
    We're gonna add another hierarchy-wide setting which needs to be
    accessed from controllers.  Move cgroupfs_root and its flags to the
    header file so that we can access root settings with inline helpers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 45aee0fc6b98..b21881e1ea08 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -19,6 +19,7 @@
 #include <linux/idr.h>
 #include <linux/workqueue.h>
 #include <linux/xattr.h>
+#include <linux/fs.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -238,6 +239,62 @@ struct cgroup {
 	struct simple_xattrs xattrs;
 };
 
+#define MAX_CGROUP_ROOT_NAMELEN 64
+
+/* cgroupfs_root->flags */
+enum {
+	CGRP_ROOT_NOPREFIX	= (1 << 1), /* mounted subsystems have no named prefix */
+	CGRP_ROOT_XATTR		= (1 << 2), /* supports extended attributes */
+};
+
+/*
+ * A cgroupfs_root represents the root of a cgroup hierarchy, and may be
+ * associated with a superblock to form an active hierarchy.  This is
+ * internal to cgroup core.  Don't access directly from controllers.
+ */
+struct cgroupfs_root {
+	struct super_block *sb;
+
+	/*
+	 * The bitmask of subsystems intended to be attached to this
+	 * hierarchy
+	 */
+	unsigned long subsys_mask;
+
+	/* Unique id for this hierarchy. */
+	int hierarchy_id;
+
+	/* The bitmask of subsystems currently attached to this hierarchy */
+	unsigned long actual_subsys_mask;
+
+	/* A list running through the attached subsystems */
+	struct list_head subsys_list;
+
+	/* The root cgroup for this hierarchy */
+	struct cgroup top_cgroup;
+
+	/* Tracks how many cgroups are currently defined in hierarchy.*/
+	int number_of_cgroups;
+
+	/* A list running through the active hierarchies */
+	struct list_head root_list;
+
+	/* All cgroups on this root, cgroup_mutex protected */
+	struct list_head allcg_list;
+
+	/* Hierarchy-specific flags */
+	unsigned long flags;
+
+	/* IDs for cgroups in this hierarchy */
+	struct ida cgroup_ida;
+
+	/* The path to use for release notifications. */
+	char release_agent_path[PATH_MAX];
+
+	/* The name for this hierarchy - may be empty */
+	char name[MAX_CGROUP_ROOT_NAMELEN];
+};
+
 /*
  * A css_set is a structure holding pointers to a set of
  * cgroup_subsys_state objects. This saves space in the task struct

commit 26d5bbe5ba2073fc7ef9e69a55543b2376f5bad0
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Apr 12 10:29:04 2013 -0700

    Revert "cgroup: remove bind() method from cgroup_subsys."
    
    This reverts commit 84cfb6ab484b442d5115eb3baf9db7d74a3ea626.  There
    are scheduled changes which make use of the removed callback.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Rami Rosen <ramirose@gmail.com>
    Cc: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a2b9d4b13369..45aee0fc6b98 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -484,6 +484,8 @@ struct cgroup_subsys {
 	void (*fork)(struct task_struct *task);
 	void (*exit)(struct cgroup *cgrp, struct cgroup *old_cgrp,
 		     struct task_struct *task);
+	void (*bind)(struct cgroup *root);
+
 	int subsys_id;
 	int active;
 	int disabled;

commit 78574cf981cd3d9ae9f6adbd466a772310ec24ff
Author: Li Zefan <lizefan@huawei.com>
Date:   Mon Apr 8 19:00:38 2013 -0700

    cgroup: implement cgroup_is_descendant()
    
    A couple controllers want to determine whether two cgroups are in
    ancestor/descendant relationship.  As it's more likely that the
    descendant is the primary subject of interest and there are other
    operations focusing on the descendants, let's ask is_descendent rather
    than is_ancestor.
    
    Implementation is trivial as the previous patch guarantees that all
    ancestors of a cgroup stay accessible as long as the cgroup is
    accessible.
    
    tj: Removed depth optimization, renamed from cgroup_is_ancestor(),
        rewrote descriptions.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 92acf8601ae0..a2b9d4b13369 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -439,6 +439,7 @@ int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 
 int cgroup_is_removed(const struct cgroup *cgrp);
+bool cgroup_is_descendant(struct cgroup *cgrp, struct cgroup *ancestor);
 
 int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
 

commit 84cfb6ab484b442d5115eb3baf9db7d74a3ea626
Author: Rami Rosen <ramirose@gmail.com>
Date:   Wed Apr 10 14:41:17 2013 +0300

    cgroup: remove bind() method from cgroup_subsys.
    
    The bind() method of cgroup_subsys is not used in any of the
    controllers (cpuset, freezer, blkio, net_cls, memcg, net_prio,
    devices, perf, hugetlb, cpu and cpuacct)
    
    tj: Removed the entry on ->bind() from
        Documentation/cgroups/cgroups.txt.  Also updated a couple
        paragraphs which were suggesting that dynamic re-binding may be
        implemented.  It's not gonna.
    
    Signed-off-by: Rami Rosen <ramirose@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 515927eebb37..92acf8601ae0 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -483,8 +483,6 @@ struct cgroup_subsys {
 	void (*fork)(struct task_struct *task);
 	void (*exit)(struct cgroup *cgrp, struct cgroup *old_cgrp,
 		     struct task_struct *task);
-	void (*bind)(struct cgroup *root);
-
 	int subsys_id;
 	int active;
 	int disabled;

commit 479f614110b889d5783acdaec865ede3cdb96b97
Author: Li Zefan <lizefan@huawei.com>
Date:   Fri Mar 29 14:44:42 2013 +0800

    cgroup: Kill subsys.active flag
    
    The only user was cpuacct.
    
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/5155385A.4040207@huawei.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 900af5964f55..95c02c0e35b3 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -458,7 +458,6 @@ struct cgroup_subsys {
 	void (*bind)(struct cgroup *root);
 
 	int subsys_id;
-	int active;
 	int disabled;
 	int early_init;
 	/*

commit 2219449a65ace0290cd9c2260ff337e326b8be8a
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 7 09:29:51 2013 -0700

    cgroup: remove cgroup_lock_is_held()
    
    We don't want controllers to assume that the information is officially
    available and do funky things with it.
    
    The only user is task_subsys_state_check() which uses it to verify RCU
    access context.  We can move cgroup_lock_is_held() inside
    CONFIG_PROVE_RCU but that doesn't add meaningful protection compared
    to conditionally exposing cgroup_mutex.
    
    Remove cgroup_lock_is_held(), export cgroup_mutex iff CONFIG_PROVE_RCU
    and use lockdep_is_held() directly on the mutex in
    task_subsys_state_check().
    
    While at it, add parentheses around macro arguments in
    task_subsys_state_check().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 63deb70f3149..515927eebb37 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -30,7 +30,6 @@ struct css_id;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
-extern int cgroup_lock_is_held(void);
 extern void cgroup_fork(struct task_struct *p);
 extern void cgroup_post_fork(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
@@ -552,10 +551,16 @@ static inline struct cgroup_subsys_state *cgroup_subsys_state(
  * rcu_dereference_check() conditions, such as locks used during the
  * cgroup_subsys::attach() methods.
  */
+#ifdef CONFIG_PROVE_RCU
+extern struct mutex cgroup_mutex;
 #define task_subsys_state_check(task, subsys_id, __c)			\
-	rcu_dereference_check(task->cgroups->subsys[subsys_id],		\
-			      lockdep_is_held(&task->alloc_lock) ||	\
-			      cgroup_lock_is_held() || (__c))
+	rcu_dereference_check((task)->cgroups->subsys[(subsys_id)],	\
+			      lockdep_is_held(&(task)->alloc_lock) ||	\
+			      lockdep_is_held(&cgroup_mutex) || (__c))
+#else
+#define task_subsys_state_check(task, subsys_id, __c)			\
+	rcu_dereference((task)->cgroups->subsys[(subsys_id)])
+#endif
 
 static inline struct cgroup_subsys_state *
 task_subsys_state(struct task_struct *task, int subsys_id)

commit b9777cf8d7c7854c3c38bd6621d993b85c2afcdf
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 7 09:29:51 2013 -0700

    cgroup: unexport locking interface and cgroup_attach_task()
    
    Now that all external cgroup_lock() users are gone, we can finally
    unexport the locking interface and prevent future abuse of
    cgroup_mutex.
    
    Make cgroup_[un]lock() and cgroup_lock_live_group() static.  Also,
    cgroup_attach_task() doesn't have any user left and can't be used
    without locking interface anyway.  Make it static too.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f8eb01d75ddc..63deb70f3149 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -30,10 +30,7 @@ struct css_id;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
-extern void cgroup_lock(void);
 extern int cgroup_lock_is_held(void);
-extern bool cgroup_lock_live_group(struct cgroup *cgrp);
-extern void cgroup_unlock(void);
 extern void cgroup_fork(struct task_struct *p);
 extern void cgroup_post_fork(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
@@ -693,8 +690,6 @@ struct task_struct *cgroup_iter_next(struct cgroup *cgrp,
 					struct cgroup_iter *it);
 void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
-int cgroup_attach_task(struct cgroup *cgrp, struct task_struct *tsk,
-		       bool threadgroup);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 

commit 8cc9934520e7f752fe45d5199664d741ba24a932
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 7 09:29:50 2013 -0700

    cgroup, cpuset: replace move_member_tasks_to_cpuset() with cgroup_transfer_tasks()
    
    When a cpuset becomes empty (no CPU or memory), its tasks are
    transferred with the nearest ancestor with execution resources.  This
    is implemented using cgroup_scan_tasks() with a callback which grabs
    cgroup_mutex and invokes cgroup_attach_task() on each task.
    
    Both cgroup_mutex and cgroup_attach_task() are scheduled to be
    unexported.  Implement cgroup_transfer_tasks() in cgroup proper which
    is essentially the same as move_member_tasks_to_cpuset() except that
    it takes cgroups instead of cpusets and @to comes before @from like
    normal functions with those arguments, and replace
    move_member_tasks_to_cpuset() with it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 01c48c6806d6..f8eb01d75ddc 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -696,6 +696,7 @@ int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *cgrp, struct task_struct *tsk,
 		       bool threadgroup);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
+int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from);
 
 /*
  * CSS ID is ID for cgroup_subsys_state structs under subsys. This only works

commit 081aa458c38ba576bdd4265fc807fa95b48b9e79
Author: Li Zefan <lizefan@huawei.com>
Date:   Wed Mar 13 09:17:09 2013 +0800

    cgroup: consolidate cgroup_attach_task() and cgroup_attach_proc()
    
    These two functions share most of the code.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7e818a3ef60a..01c48c6806d6 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -693,7 +693,8 @@ struct task_struct *cgroup_iter_next(struct cgroup *cgrp,
 					struct cgroup_iter *it);
 void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
-int cgroup_attach_task(struct cgroup *, struct task_struct *);
+int cgroup_attach_task(struct cgroup *cgrp, struct task_struct *tsk,
+		       bool threadgroup);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 
 /*

commit e7b2dcc52b0e2d598a469f01cc460ccdde6869f2
Author: Li Zefan <lizefan@huawei.com>
Date:   Tue Mar 12 15:35:58 2013 -0700

    cgroup: remove cgroup_is_descendant()
    
    It was used by ns cgroup, and ns cgroup was removed long ago.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5f76829dd75e..7e818a3ef60a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -448,9 +448,6 @@ int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
 
 int cgroup_task_count(const struct cgroup *cgrp);
 
-/* Return true if cgrp is a descendant of the task's cgroup */
-int cgroup_is_descendant(const struct cgroup *cgrp, struct task_struct *task);
-
 /*
  * Control Group taskset, used to pass around set of tasks to cgroup_subsys
  * methods.

commit 7d8e0bf56a66bab08d2f316dd87e56c08cecb899
Author: Li Zefan <lizefan@huawei.com>
Date:   Tue Mar 5 10:57:03 2013 +0800

    cgroup: avoid accessing modular cgroup subsys structure without locking
    
    subsys[i] is set to NULL in cgroup_unload_subsys() at modular unload,
    and that's protected by cgroup_mutex, and then the memory *subsys[i]
    resides will be freed.
    
    So this is unsafe without any locking:
    
      if (!ss || ss->module)
      ...
    
    v2:
    - add a comment for enum cgroup_subsys_id
    - simplify the comment in cgroup_exit()
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 75c6ec1ba1ba..5f76829dd75e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -44,14 +44,25 @@ extern void cgroup_unload_subsys(struct cgroup_subsys *ss);
 
 extern const struct file_operations proc_cgroup_operations;
 
-/* Define the enumeration of all builtin cgroup subsystems */
+/*
+ * Define the enumeration of all cgroup subsystems.
+ *
+ * We define ids for builtin subsystems and then modular ones.
+ */
 #define SUBSYS(_x) _x ## _subsys_id,
-#define IS_SUBSYS_ENABLED(option) IS_ENABLED(option)
 enum cgroup_subsys_id {
+#define IS_SUBSYS_ENABLED(option) IS_BUILTIN(option)
+#include <linux/cgroup_subsys.h>
+#undef IS_SUBSYS_ENABLED
+	CGROUP_BUILTIN_SUBSYS_COUNT,
+
+	__CGROUP_SUBSYS_TEMP_PLACEHOLDER = CGROUP_BUILTIN_SUBSYS_COUNT - 1,
+
+#define IS_SUBSYS_ENABLED(option) IS_MODULE(option)
 #include <linux/cgroup_subsys.h>
+#undef IS_SUBSYS_ENABLED
 	CGROUP_SUBSYS_COUNT,
 };
-#undef IS_SUBSYS_ENABLED
 #undef SUBSYS
 
 /* Per-subsystem/per-cgroup state maintained by the system. */

commit 65dff759d2948cf18e2029fc5c0c595b8b7da3a5
Author: Li Zefan <lizefan@huawei.com>
Date:   Fri Mar 1 15:01:56 2013 +0800

    cgroup: fix cgroup_path() vs rename() race
    
    rename() will change dentry->d_name. The result of this race can
    be worse than seeing partially rewritten name, but we might access
    a stale pointer because rename() will re-allocate memory to hold
    a longer name.
    
    As accessing dentry->name must be protected by dentry->d_lock or
    parent inode's i_mutex, while on the other hand cgroup-path() can
    be called with some irq-safe spinlocks held, we can't generate
    cgroup path using dentry->d_name.
    
    Alternatively we make a copy of dentry->d_name and save it in
    cgrp->name when a cgroup is created, and update cgrp->name at
    rename().
    
    v5: use flexible array instead of zero-size array.
    v4: - allocate root_cgroup_name and all root_cgroup->name points to it.
        - add cgroup_name() wrapper.
    v3: use kfree_rcu() instead of synchronize_rcu() in user-visible path.
    v2: make cgrp->name RCU safe.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 900af5964f55..75c6ec1ba1ba 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -150,6 +150,11 @@ enum {
 	CGRP_CPUSET_CLONE_CHILDREN,
 };
 
+struct cgroup_name {
+	struct rcu_head rcu_head;
+	char name[];
+};
+
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
@@ -172,6 +177,19 @@ struct cgroup {
 	struct cgroup *parent;		/* my parent */
 	struct dentry *dentry;		/* cgroup fs entry, RCU protected */
 
+	/*
+	 * This is a copy of dentry->d_name, and it's needed because
+	 * we can't use dentry->d_name in cgroup_path().
+	 *
+	 * You must acquire rcu_read_lock() to access cgrp->name, and
+	 * the only place that can change it is rename(), which is
+	 * protected by parent dir's i_mutex.
+	 *
+	 * Normally you should use cgroup_name() wrapper rather than
+	 * access it directly.
+	 */
+	struct cgroup_name __rcu *name;
+
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
 
@@ -404,6 +422,12 @@ struct cgroup_scanner {
 	void *data;
 };
 
+/* Caller should hold rcu_read_lock() */
+static inline const char *cgroup_name(const struct cgroup *cgrp)
+{
+	return rcu_dereference(cgrp->name)->name;
+}
+
 int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 int cgroup_rm_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 

commit be44562613851235d801d41d5b3976dc4333f622
Author: Li Zefan <lizefan@huawei.com>
Date:   Thu Jan 24 14:31:42 2013 +0800

    cgroup: remove synchronize_rcu() from cgroup_diput()
    
    Free cgroup via call_rcu(). The actual work is done through
    workqueue.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8118a3120378..900af5964f55 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -203,6 +203,7 @@ struct cgroup {
 
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;
+	struct work_struct free_work;
 
 	/* List of events which userspace want to receive */
 	struct list_head event_list;

commit 12a9d2fef1d35770d3cdc2cd1faabb83c45bc0fa
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Jan 7 08:49:33 2013 -0800

    cgroup: implement cgroup_rightmost_descendant()
    
    Implement cgroup_rightmost_descendant() which returns the right most
    descendant of the specified cgroup.  This can be used to skip the
    cgroup's subtree while iterating with
    cgroup_for_each_descendant_pre().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 942e68705577..8118a3120378 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -558,6 +558,7 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 
 struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
 					  struct cgroup *cgroup);
+struct cgroup *cgroup_rightmost_descendant(struct cgroup *pos);
 
 /**
  * cgroup_for_each_descendant_pre - pre-order walk of a cgroup's descendants

commit d5b1fe68baa7213f198e5be8cd1a1037258ab2c8
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Dec 28 13:18:28 2012 -0800

    cgroup: remove unused dummy cgroup_fork_callbacks()
    
    5edee61ede ("cgroup: cgroup_subsys->fork() should be called after the
    task is added to css_set") removed cgroup_fork_callbacks() but forgot
    to remove its dummy version for !CONFIG_CGROUPS.  Remove it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Herton Ronaldo Krzesinski <herton.krzesinski@canonical.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7d73905dcba2..942e68705577 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -706,7 +706,6 @@ struct cgroup_subsys_state *cgroup_css_from_dir(struct file *f, int id);
 static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_fork(struct task_struct *p) {}
-static inline void cgroup_fork_callbacks(struct task_struct *p) {}
 static inline void cgroup_post_fork(struct task_struct *p) {}
 static inline void cgroup_exit(struct task_struct *p, int callbacks) {}
 

commit d0b2fdd2a51203f04ea0a5d716e033c15e0231af
Author: Tao Ma <boyu.mt@taobao.com>
Date:   Tue Nov 20 22:06:18 2012 +0800

    cgroup: remove obsolete guarantee from cgroup_task_migrate.
    
    'guarantee' is already removed from cgroup_task_migrate, so remove
    the corresponding comments. Some other typos in cgroup are also
    changed.
    
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tao Ma <boyu.mt@taobao.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 82cf9e6fc77b..7d73905dcba2 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -66,7 +66,7 @@ struct cgroup_subsys_state {
 	/*
 	 * State maintained by the cgroup system to allow subsystems
 	 * to be "busy". Should be accessed via css_get(),
-	 * css_tryget() and and css_put().
+	 * css_tryget() and css_put().
 	 */
 
 	atomic_t refcnt;
@@ -276,7 +276,7 @@ struct cgroup_map_cb {
 
 /* cftype->flags */
 #define CFTYPE_ONLY_ON_ROOT	(1U << 0)	/* only create on root cg */
-#define CFTYPE_NOT_ON_ROOT	(1U << 1)	/* don't create onp root cg */
+#define CFTYPE_NOT_ON_ROOT	(1U << 1)	/* don't create on root cg */
 
 #define MAX_CFTYPE_NAME		64
 

commit 0a950f65e1e64f4e82b4b5507773848ea88bcb8e
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 09:02:12 2012 -0800

    cgroup: add cgroup->id
    
    With the introduction of generic cgroup hierarchy iterators, css_id is
    being phased out.  It was unnecessarily complex, id'ing the wrong
    thing (cgroups need IDs, not CSSes) and has other oddities like not
    being available at ->css_alloc().
    
    This patch adds cgroup->id, which is a simple per-hierarchy
    ida-allocated ID which is assigned before ->css_alloc() and released
    after ->css_free().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c798997e5011..82cf9e6fc77b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -159,6 +159,8 @@ struct cgroup {
 	 */
 	atomic_t count;
 
+	int id;				/* ida allocated in-hierarchy ID */
+
 	/*
 	 * We link our 'sibling' struct into our parent's 'children'.
 	 * Our children link their 'sibling' into our 'children'.

commit 033fa1c5f5f73833598a0beb022c0048fb769dad
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:39 2012 -0800

    cgroup, cpuset: remove cgroup_subsys->post_clone()
    
    Currently CGRP_CPUSET_CLONE_CHILDREN triggers ->post_clone().  Now
    that clone_children is cpuset specific, there's no reason to have this
    rather odd option activation mechanism in cgroup core.  cpuset can
    check the flag from its ->css_allocate() and take the necessary
    action.
    
    Move cpuset_post_clone() logic to the end of cpuset_css_alloc() and
    remove cgroup_subsys->post_clone().
    
    Loosely based on Glauber's "generalize post_clone into post_create"
    patch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Original-patch-by: Glauber Costa <glommer@parallels.com>
    Original-patch: <1351686554-22592-2-git-send-email-glommer@parallels.com>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Glauber Costa <glommer@parallels.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d2f82979f6c1..c798997e5011 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -452,7 +452,6 @@ struct cgroup_subsys {
 	void (*fork)(struct task_struct *task);
 	void (*exit)(struct cgroup *cgrp, struct cgroup *old_cgrp,
 		     struct task_struct *task);
-	void (*post_clone)(struct cgroup *cgrp);
 	void (*bind)(struct cgroup *root);
 
 	int subsys_id;

commit 2260e7fc1f18ad815324605c1ce7d5c6fd9b19a2
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:38 2012 -0800

    cgroup: s/CGRP_CLONE_CHILDREN/CGRP_CPUSET_CLONE_CHILDREN/
    
    clone_children is only meaningful for cpuset and will stay that way.
    Rename the flag to reflect that and update documentation.  Also, drop
    clone_children() wrapper in cgroup.c.  The thin wrapper is used only a
    few times and one of them will go away soon.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Glauber Costa <glommer@parallels.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7a2189ca8327..d2f82979f6c1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -143,9 +143,11 @@ enum {
 	/* Control Group requires release notifications to userspace */
 	CGRP_NOTIFY_ON_RELEASE,
 	/*
-	 * Clone cgroup values when creating a new child cgroup
+	 * Clone the parent's configuration when creating a new child
+	 * cpuset cgroup.  For historical reasons, this option can be
+	 * specified at mount time and thus is implemented here.
 	 */
-	CGRP_CLONE_CHILDREN,
+	CGRP_CPUSET_CLONE_CHILDREN,
 };
 
 struct cgroup {

commit 92fb97487a7e41b222c1417cabd1d1ab7cc3a48c
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:38 2012 -0800

    cgroup: rename ->create/post_create/pre_destroy/destroy() to ->css_alloc/online/offline/free()
    
    Rename cgroup_subsys css lifetime related callbacks to better describe
    what their roles are.  Also, update documentation.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 03d8a92786da..7a2189ca8327 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -82,7 +82,7 @@ struct cgroup_subsys_state {
 /* bits in struct cgroup_subsys_state flags field */
 enum {
 	CSS_ROOT	= (1 << 0), /* this CSS is the root of the subsystem */
-	CSS_ONLINE	= (1 << 1), /* between ->post_create() and ->pre_destroy() */
+	CSS_ONLINE	= (1 << 1), /* between ->css_online() and ->css_offline() */
 };
 
 /* Caller must verify that the css is not for root cgroup */
@@ -439,10 +439,11 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
  */
 
 struct cgroup_subsys {
-	struct cgroup_subsys_state *(*create)(struct cgroup *cgrp);
-	int (*post_create)(struct cgroup *cgrp);
-	void (*pre_destroy)(struct cgroup *cgrp);
-	void (*destroy)(struct cgroup *cgrp);
+	struct cgroup_subsys_state *(*css_alloc)(struct cgroup *cgrp);
+	int (*css_online)(struct cgroup *cgrp);
+	void (*css_offline)(struct cgroup *cgrp);
+	void (*css_free)(struct cgroup *cgrp);
+
 	int (*can_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
 	void (*cancel_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
 	void (*attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
@@ -541,13 +542,13 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
  * @cgroup: cgroup whose children to walk
  *
  * Walk @cgroup's children.  Must be called under rcu_read_lock().  A child
- * cgroup which hasn't finished ->post_create() or already has finished
- * ->pre_destroy() may show up during traversal and it's each subsystem's
+ * cgroup which hasn't finished ->css_online() or already has finished
+ * ->css_offline() may show up during traversal and it's each subsystem's
  * responsibility to verify that each @pos is alive.
  *
- * If a subsystem synchronizes against the parent in its ->post_create()
- * and before starting iterating, a cgroup which finished ->post_create()
- * is guaranteed to be visible in the future iterations.
+ * If a subsystem synchronizes against the parent in its ->css_online() and
+ * before starting iterating, a cgroup which finished ->css_online() is
+ * guaranteed to be visible in the future iterations.
  */
 #define cgroup_for_each_child(pos, cgroup)				\
 	list_for_each_entry_rcu(pos, &(cgroup)->children, sibling)
@@ -561,19 +562,19 @@ struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
  * @cgroup: cgroup whose descendants to walk
  *
  * Walk @cgroup's descendants.  Must be called under rcu_read_lock().  A
- * descendant cgroup which hasn't finished ->post_create() or already has
- * finished ->pre_destroy() may show up during traversal and it's each
+ * descendant cgroup which hasn't finished ->css_online() or already has
+ * finished ->css_offline() may show up during traversal and it's each
  * subsystem's responsibility to verify that each @pos is alive.
  *
- * If a subsystem synchronizes against the parent in its ->post_create()
- * and before starting iterating, and synchronizes against @pos on each
- * iteration, any descendant cgroup which finished ->post_create() is
+ * If a subsystem synchronizes against the parent in its ->css_online() and
+ * before starting iterating, and synchronizes against @pos on each
+ * iteration, any descendant cgroup which finished ->css_offline() is
  * guaranteed to be visible in the future iterations.
  *
  * In other words, the following guarantees that a descendant can't escape
  * state updates of its ancestors.
  *
- * my_post_create(@cgrp)
+ * my_online(@cgrp)
  * {
  *	Lock @cgrp->parent and @cgrp;
  *	Inherit state from @cgrp->parent;
@@ -606,7 +607,7 @@ struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
  * iteration should lock and unlock both @pos->parent and @pos.
  *
  * Alternatively, a subsystem may choose to use a single global lock to
- * synchronize ->post_create() and ->pre_destroy() against tree-walking
+ * synchronize ->css_online() and ->css_offline() against tree-walking
  * operations.
  */
 #define cgroup_for_each_descendant_pre(pos, cgroup)			\

commit b1929db42f8a649d9a9e397119f628c27fd4021f
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:38 2012 -0800

    cgroup: allow ->post_create() to fail
    
    There could be cases where controllers want to do initialization
    operations which may fail from ->post_create().  This patch makes
    ->post_create() return -errno to indicate failure and online_css()
    relay such failures.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Glauber Costa <glommer@parallels.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f4a9c9836906..03d8a92786da 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -440,7 +440,7 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
 
 struct cgroup_subsys {
 	struct cgroup_subsys_state *(*create)(struct cgroup *cgrp);
-	void (*post_create)(struct cgroup *cgrp);
+	int (*post_create)(struct cgroup *cgrp);
 	void (*pre_destroy)(struct cgroup *cgrp);
 	void (*destroy)(struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);

commit a31f2d3ff7fe20cbe2a143515a7d7c408b29dd0d
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:37 2012 -0800

    cgroup: introduce CSS_ONLINE flag and on/offline_css() helpers
    
    New helpers on/offline_css() respectively wrap ->post_create() and
    ->pre_destroy() invocations.  online_css() sets CSS_ONLINE after
    ->post_create() is complete and offline_css() invokes ->pre_destroy()
    iff CSS_ONLINE is set and clears it while also handling the temporary
    dropping of cgroup_mutex.
    
    This patch doesn't introduce any behavior change at the moment but
    will be used to improve cgroup_create() failure path and allow
    ->post_create() to fail.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a0fc64167129..f4a9c9836906 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -82,6 +82,7 @@ struct cgroup_subsys_state {
 /* bits in struct cgroup_subsys_state flags field */
 enum {
 	CSS_ROOT	= (1 << 0), /* this CSS is the root of the subsystem */
+	CSS_ONLINE	= (1 << 1), /* between ->post_create() and ->pre_destroy() */
 };
 
 /* Caller must verify that the css is not for root cgroup */

commit 38b53abaa3e0c7e750ef73eee919cf42eee6b134
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:36 2012 -0800

    cgroup: make CSS_* flags bit masks instead of bit positions
    
    Currently, CSS_* flags are defined as bit positions and manipulated
    using atomic bitops.  There's no reason to use atomic bitops for them
    and bit positions are clunkier to deal with than bit masks.  Make
    CSS_* bit masks instead and use the usual C bitwise operators to
    access them.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d605857c4bf3..a0fc64167129 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -81,7 +81,7 @@ struct cgroup_subsys_state {
 
 /* bits in struct cgroup_subsys_state flags field */
 enum {
-	CSS_ROOT, /* This CSS is the root of the subsystem */
+	CSS_ROOT	= (1 << 0), /* this CSS is the root of the subsystem */
 };
 
 /* Caller must verify that the css is not for root cgroup */
@@ -100,7 +100,7 @@ static inline void __css_get(struct cgroup_subsys_state *css, int count)
 static inline void css_get(struct cgroup_subsys_state *css)
 {
 	/* We don't need to reference count the root state */
-	if (!test_bit(CSS_ROOT, &css->flags))
+	if (!(css->flags & CSS_ROOT))
 		__css_get(css, 1);
 }
 
@@ -113,7 +113,7 @@ static inline void css_get(struct cgroup_subsys_state *css)
 extern bool __css_tryget(struct cgroup_subsys_state *css);
 static inline bool css_tryget(struct cgroup_subsys_state *css)
 {
-	if (test_bit(CSS_ROOT, &css->flags))
+	if (css->flags & CSS_ROOT)
 		return true;
 	return __css_tryget(css);
 }
@@ -126,7 +126,7 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
 extern void __css_put(struct cgroup_subsys_state *css);
 static inline void css_put(struct cgroup_subsys_state *css)
 {
-	if (!test_bit(CSS_ROOT, &css->flags))
+	if (!(css->flags & CSS_ROOT))
 		__css_put(css);
 }
 

commit febfcef60d4f9457785b45aab548bc7ee5ea158f
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:36 2012 -0800

    cgroup: cgroup->dentry isn't a RCU pointer
    
    cgroup->dentry is marked and used as a RCU pointer; however, it isn't
    one - the final dentry put doesn't go through call_rcu().  cgroup and
    dentry share the same RCU freeing rule via synchronize_rcu() in
    cgroup_diput() (kfree_rcu() used on cgrp is unnecessary).  If cgrp is
    accessible under RCU read lock, so is its dentry and dereferencing
    cgrp->dentry doesn't need any further RCU protection or annotation.
    
    While not being accurate, before the previous patch, the RCU accessors
    served a purpose as memory barriers - cgroup->dentry used to be
    assigned after the cgroup was made visible to cgroup_path(), so the
    assignment and dereferencing in cgroup_path() needed the memory
    barrier pair.  Now that list_add_tail_rcu() happens after
    cgroup->dentry is assigned, this no longer is necessary.
    
    Remove the now unnecessary and misleading RCU annotations from
    cgroup->dentry.  To make up for the removal of rcu_dereference_check()
    in cgroup_path(), add an explicit rcu_lockdep_assert(), which asserts
    the dereference rule of @cgrp, not cgrp->dentry.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8f64b459fbd4..d605857c4bf3 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -165,7 +165,7 @@ struct cgroup {
 	struct list_head files;		/* my files */
 
 	struct cgroup *parent;		/* my parent */
-	struct dentry __rcu *dentry;	/* cgroup fs entry, RCU protected */
+	struct dentry *dentry;		/* cgroup fs entry, RCU protected */
 
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];

commit 574bd9f7c7c1d32f52dea5488018a6ff79031e22
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 9 09:12:29 2012 -0800

    cgroup: implement generic child / descendant walk macros
    
    Currently, cgroup doesn't provide any generic helper for walking a
    given cgroup's children or descendants.  This patch adds the following
    three macros.
    
    * cgroup_for_each_child() - walk immediate children of a cgroup.
    
    * cgroup_for_each_descendant_pre() - visit all descendants of a cgroup
      in pre-order tree traversal.
    
    * cgroup_for_each_descendant_post() - visit all descendants of a
      cgroup in post-order tree traversal.
    
    All three only require the user to hold RCU read lock during
    traversal.  Verifying that each iterated cgroup is online is the
    responsibility of the user.  When used with proper synchronization,
    cgroup_for_each_descendant_pre() can be used to propagate state
    updates to descendants in reliable way.  See comments for details.
    
    v2: s/config/state/ in commit message and comments per Michal.  More
        documentation on synchronization rules.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujisu.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 90c33ebdd6bc..8f64b459fbd4 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -534,6 +534,100 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 	return task_subsys_state(task, subsys_id)->cgroup;
 }
 
+/**
+ * cgroup_for_each_child - iterate through children of a cgroup
+ * @pos: the cgroup * to use as the loop cursor
+ * @cgroup: cgroup whose children to walk
+ *
+ * Walk @cgroup's children.  Must be called under rcu_read_lock().  A child
+ * cgroup which hasn't finished ->post_create() or already has finished
+ * ->pre_destroy() may show up during traversal and it's each subsystem's
+ * responsibility to verify that each @pos is alive.
+ *
+ * If a subsystem synchronizes against the parent in its ->post_create()
+ * and before starting iterating, a cgroup which finished ->post_create()
+ * is guaranteed to be visible in the future iterations.
+ */
+#define cgroup_for_each_child(pos, cgroup)				\
+	list_for_each_entry_rcu(pos, &(cgroup)->children, sibling)
+
+struct cgroup *cgroup_next_descendant_pre(struct cgroup *pos,
+					  struct cgroup *cgroup);
+
+/**
+ * cgroup_for_each_descendant_pre - pre-order walk of a cgroup's descendants
+ * @pos: the cgroup * to use as the loop cursor
+ * @cgroup: cgroup whose descendants to walk
+ *
+ * Walk @cgroup's descendants.  Must be called under rcu_read_lock().  A
+ * descendant cgroup which hasn't finished ->post_create() or already has
+ * finished ->pre_destroy() may show up during traversal and it's each
+ * subsystem's responsibility to verify that each @pos is alive.
+ *
+ * If a subsystem synchronizes against the parent in its ->post_create()
+ * and before starting iterating, and synchronizes against @pos on each
+ * iteration, any descendant cgroup which finished ->post_create() is
+ * guaranteed to be visible in the future iterations.
+ *
+ * In other words, the following guarantees that a descendant can't escape
+ * state updates of its ancestors.
+ *
+ * my_post_create(@cgrp)
+ * {
+ *	Lock @cgrp->parent and @cgrp;
+ *	Inherit state from @cgrp->parent;
+ *	Unlock both.
+ * }
+ *
+ * my_update_state(@cgrp)
+ * {
+ *	Lock @cgrp;
+ *	Update @cgrp's state;
+ *	Unlock @cgrp;
+ *
+ *	cgroup_for_each_descendant_pre(@pos, @cgrp) {
+ *		Lock @pos;
+ *		Verify @pos is alive and inherit state from @pos->parent;
+ *		Unlock @pos;
+ *	}
+ * }
+ *
+ * As long as the inheriting step, including checking the parent state, is
+ * enclosed inside @pos locking, double-locking the parent isn't necessary
+ * while inheriting.  The state update to the parent is guaranteed to be
+ * visible by walking order and, as long as inheriting operations to the
+ * same @pos are atomic to each other, multiple updates racing each other
+ * still result in the correct state.  It's guaranateed that at least one
+ * inheritance happens for any cgroup after the latest update to its
+ * parent.
+ *
+ * If checking parent's state requires locking the parent, each inheriting
+ * iteration should lock and unlock both @pos->parent and @pos.
+ *
+ * Alternatively, a subsystem may choose to use a single global lock to
+ * synchronize ->post_create() and ->pre_destroy() against tree-walking
+ * operations.
+ */
+#define cgroup_for_each_descendant_pre(pos, cgroup)			\
+	for (pos = cgroup_next_descendant_pre(NULL, (cgroup)); (pos);	\
+	     pos = cgroup_next_descendant_pre((pos), (cgroup)))
+
+struct cgroup *cgroup_next_descendant_post(struct cgroup *pos,
+					   struct cgroup *cgroup);
+
+/**
+ * cgroup_for_each_descendant_post - post-order walk of a cgroup's descendants
+ * @pos: the cgroup * to use as the loop cursor
+ * @cgroup: cgroup whose descendants to walk
+ *
+ * Similar to cgroup_for_each_descendant_pre() but performs post-order
+ * traversal instead.  Note that the walk visibility guarantee described in
+ * pre-order walk doesn't apply the same to post-order walks.
+ */
+#define cgroup_for_each_descendant_post(pos, cgroup)			\
+	for (pos = cgroup_next_descendant_post(NULL, (cgroup)); (pos);	\
+	     pos = cgroup_next_descendant_post((pos), (cgroup)))
+
 /* A cgroup_iter should be treated as an opaque object */
 struct cgroup_iter {
 	struct list_head *cg_link;

commit eb6fd5040ee799009173daa49c3e7aa0362167c9
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 9 09:12:29 2012 -0800

    cgroup: use rculist ops for cgroup->children
    
    Use RCU safe list operations for cgroup->children.  This will be used
    to implement cgroup children / descendant walking which can be used by
    controllers.
    
    Note that cgroup_create() now puts a new cgroup at the end of the
    ->children list instead of head.  This isn't strictly necessary but is
    done so that the iteration order is more conventional.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b4421221111d..90c33ebdd6bc 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -12,6 +12,7 @@
 #include <linux/cpumask.h>
 #include <linux/nodemask.h>
 #include <linux/rcupdate.h>
+#include <linux/rculist.h>
 #include <linux/cgroupstats.h>
 #include <linux/prio_heap.h>
 #include <linux/rwsem.h>

commit a8638030f668884720b8f4456448d0ce33952b05
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Nov 9 09:12:29 2012 -0800

    cgroup: add cgroup_subsys->post_create()
    
    Currently, there's no way for a controller to find out whether a new
    cgroup finished all ->create() allocatinos successfully and is
    considered "live" by cgroup.
    
    This becomes a problem later when we add generic descendants walking
    to cgroup which can be used by controllers as controllers don't have a
    synchronization point where it can synchronize against new cgroups
    appearing in such walks.
    
    This patch adds ->post_create().  It's called after all ->create()
    succeeded and the cgroup is linked into the generic cgroup hierarchy.
    This plays the counterpart of ->pre_destroy().
    
    When used in combination with the to-be-added generic descendant
    iterators, ->post_create() can be used to implement reliable state
    inheritance.  It will be explained with the descendant iterators.
    
    v2: Added a paragraph about its future use w/ descendant iterators per
        Michal.
    
    v3: Forgot to add ->post_create() invocation to cgroup_load_subsys().
        Fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Glauber Costa <glommer@parallels.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index fe876a77031a..b4421221111d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -438,6 +438,7 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
 
 struct cgroup_subsys {
 	struct cgroup_subsys_state *(*create)(struct cgroup *cgrp);
+	void (*post_create)(struct cgroup *cgrp);
 	void (*pre_destroy)(struct cgroup *cgrp);
 	void (*destroy)(struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);

commit 1db1e31b1ee3ae126ef98f39083b5f213c7b41bf
Merge: 5d8f72b55c27 bcf6de1b9129
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 5 09:21:51 2012 -0800

    Merge branch 'cgroup-rmdir-updates' into cgroup/for-3.8
    
    Pull rmdir updates into for-3.8 so that further callback updates can
    be put on top.  This pull created a trivial conflict between the
    following two commits.
    
      8c7f6edbda ("cgroup: mark subsystems with broken hierarchy support and whine if cgroups are nested for them")
      ed95779340 ("cgroup: kill cgroup_subsys->__DEPRECATED_clear_css_refs")
    
    The former added a field to cgroup_subsys and the latter removed one
    from it.  They happen to be colocated causing the conflict.  Keeping
    what's added and removing what's removed resolves the conflict.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit bcf6de1b9129531215d26dd9af8331e84973bc52
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 5 09:16:59 2012 -0800

    cgroup: make ->pre_destroy() return void
    
    All ->pre_destory() implementations return 0 now, which is the only
    allowed return value.  Make it return void.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 47868a86ba2b..adb2adc8ec1a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -436,7 +436,7 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
 
 struct cgroup_subsys {
 	struct cgroup_subsys_state *(*create)(struct cgroup *cgrp);
-	int (*pre_destroy)(struct cgroup *cgrp);
+	void (*pre_destroy)(struct cgroup *cgrp);
 	void (*destroy)(struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
 	void (*cancel_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);

commit b25ed609d0eecf077db607e88ea70bae83b6adb2
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 5 09:16:59 2012 -0800

    cgroup: remove CGRP_WAIT_ON_RMDIR, cgroup_exclude_rmdir() and cgroup_release_and_wakeup_rmdir()
    
    CGRP_WAIT_ON_RMDIR is another kludge which was added to make cgroup
    destruction rollback somewhat working.  cgroup_rmdir() used to drain
    CSS references and CGRP_WAIT_ON_RMDIR and the associated waitqueue and
    helpers were used to allow the task performing rmdir to wait for the
    next relevant event.
    
    Unfortunately, the wait is visible to controllers too and the
    mechanism got exposed to memcg by 887032670d ("cgroup avoid permanent
    sleep at rmdir").
    
    Now that the draining and retries are gone, CGRP_WAIT_ON_RMDIR is
    unnecessary.  Remove it and all the mechanisms supporting it.  Note
    that memcontrol.c changes are essentially revert of 887032670d
    ("cgroup avoid permanent sleep at rmdir").
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a3098046250b..47868a86ba2b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -144,10 +144,6 @@ enum {
 	CGRP_RELEASABLE,
 	/* Control Group requires release notifications to userspace */
 	CGRP_NOTIFY_ON_RELEASE,
-	/*
-	 * A thread in rmdir() is wating for this cgroup.
-	 */
-	CGRP_WAIT_ON_RMDIR,
 	/*
 	 * Clone cgroup values when creating a new child cgroup
 	 */
@@ -411,23 +407,6 @@ int cgroup_task_count(const struct cgroup *cgrp);
 /* Return true if cgrp is a descendant of the task's cgroup */
 int cgroup_is_descendant(const struct cgroup *cgrp, struct task_struct *task);
 
-/*
- * When the subsys has to access css and may add permanent refcnt to css,
- * it should take care of racy conditions with rmdir(). Following set of
- * functions, is for stop/restart rmdir if necessary.
- * Because these will call css_get/put, "css" should be alive css.
- *
- *  cgroup_exclude_rmdir();
- *  ...do some jobs which may access arbitrary empty cgroup
- *  cgroup_release_and_wakeup_rmdir();
- *
- *  When someone removes a cgroup while cgroup_exclude_rmdir() holds it,
- *  it sleeps and cgroup_release_and_wakeup_rmdir() will wake him up.
- */
-
-void cgroup_exclude_rmdir(struct cgroup_subsys_state *css);
-void cgroup_release_and_wakeup_rmdir(struct cgroup_subsys_state *css);
-
 /*
  * Control Group taskset, used to pass around set of tasks to cgroup_subsys
  * methods.

commit e93160803ffda2e67d9ff9cacb63bb6868c8398f
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 5 09:16:58 2012 -0800

    cgroup: kill CSS_REMOVED
    
    CSS_REMOVED is one of the several contortions which were necessary to
    support css reference draining on cgroup removal.  All css->refcnts
    which need draining should be deactivated and verified to equal zero
    atomically w.r.t. css_tryget().  If any one isn't zero, all refcnts
    needed to be re-activated and css_tryget() shouldn't fail in the
    process.
    
    This was achieved by letting css_tryget() busy-loop until either the
    refcnt is reactivated (failed removal attempt) or CSS_REMOVED is set
    (committing to removal).
    
    Now that css refcnt draining is no longer used, there's no need for
    atomic rollback mechanism.  css_tryget() simply can look at the
    reference count and fail if it's deactivated - it's never getting
    re-activated.
    
    This patch removes CSS_REMOVED and updates __css_tryget() to fail if
    the refcnt is deactivated.  As deactivation and removal are a single
    step now, they no longer need to be protected against css_tryget()
    happening from irq context.  Remove local_irq_disable/enable() from
    cgroup_rmdir().
    
    Note that this removes css_is_removed() whose only user is VM_BUG_ON()
    in memcontrol.c.  We can replace it with a check on the refcnt but
    given that the only use case is a debug assert, I think it's better to
    simply unexport it.
    
    v2: Comment updated and explanation on local_irq_disable/enable()
        added per Michal Hocko.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 02e09c0e98ab..a3098046250b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -85,7 +85,6 @@ struct cgroup_subsys_state {
 /* bits in struct cgroup_subsys_state flags field */
 enum {
 	CSS_ROOT, /* This CSS is the root of the subsystem */
-	CSS_REMOVED, /* This CSS is dead */
 };
 
 /* Caller must verify that the css is not for root cgroup */
@@ -108,11 +107,6 @@ static inline void css_get(struct cgroup_subsys_state *css)
 		__css_get(css, 1);
 }
 
-static inline bool css_is_removed(struct cgroup_subsys_state *css)
-{
-	return test_bit(CSS_REMOVED, &css->flags);
-}
-
 /*
  * Call css_tryget() to take a reference on a css if your existing
  * (known-valid) reference isn't already ref-counted. Returns false if

commit ed95779340b50e362245c81b5dec0d11a1debfa8
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 5 09:16:58 2012 -0800

    cgroup: kill cgroup_subsys->__DEPRECATED_clear_css_refs
    
    2ef37d3fe4 ("memcg: Simplify mem_cgroup_force_empty_list error
    handling") removed the last user of __DEPRECATED_clear_css_refs.  This
    patch removes __DEPRECATED_clear_css_refs and mechanisms to support
    it.
    
    * Conditionals dependent on __DEPRECATED_clear_css_refs removed.
    
    * cgroup_clear_css_refs() can no longer fail.  All that needs to be
      done are deactivating refcnts, setting CSS_REMOVED and putting the
      base reference on each css.  Remove cgroup_clear_css_refs() and the
      failure path, and open-code the loops into cgroup_rmdir().
    
    This patch keeps the two for_each_subsys() loops separate while open
    coding them.  They can be merged now but there are scheduled changes
    which need them to be separate, so keep them separate to reduce the
    amount of churn.
    
    local_irq_save/restore() from cgroup_clear_css_refs() are replaced
    with local_irq_disable/enable() for simplicity.  This is safe as
    cgroup_rmdir() is always called with IRQ enabled.  Note that this IRQ
    switching is necessary to ensure that css_tryget() isn't called from
    IRQ context on the same CPU while lower context is between CSS
    deactivation and setting CSS_REMOVED as css_tryget() would hang
    forever in such cases waiting for CSS to be re-activated or
    CSS_REMOVED set.  This will go away soon.
    
    v2: cgroup_call_pre_destroy() removal dropped per Michal.  Commit
        message updated to explain local_irq_disable/enable() conversion.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c90eaa803440..02e09c0e98ab 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -86,7 +86,6 @@ struct cgroup_subsys_state {
 enum {
 	CSS_ROOT, /* This CSS is the root of the subsystem */
 	CSS_REMOVED, /* This CSS is dead */
-	CSS_CLEAR_CSS_REFS,		/* @ss->__DEPRECATED_clear_css_refs */
 };
 
 /* Caller must verify that the css is not for root cgroup */
@@ -485,17 +484,6 @@ struct cgroup_subsys {
 	 */
 	bool use_id;
 
-	/*
-	 * If %true, cgroup removal will try to clear css refs by retrying
-	 * ss->pre_destroy() until there's no css ref left.  This behavior
-	 * is strictly for backward compatibility and will be removed as
-	 * soon as the current user (memcg) is updated.
-	 *
-	 * If %false, ss->pre_destroy() can't fail and cgroup removal won't
-	 * wait for css refs to drop to zero before proceeding.
-	 */
-	bool __DEPRECATED_clear_css_refs;
-
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 

commit 5edee61edeaaebafe584f8fb7074c1ef4658596b
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Oct 16 15:03:14 2012 -0700

    cgroup: cgroup_subsys->fork() should be called after the task is added to css_set
    
    cgroup core has a bug which violates a basic rule about event
    notifications - when a new entity needs to be added, you add that to
    the notification list first and then make the new entity conform to
    the current state.  If done in the reverse order, an event happening
    inbetween will be lost.
    
    cgroup_subsys->fork() is invoked way before the new task is added to
    the css_set.  Currently, cgroup_freezer is the only user of ->fork()
    and uses it to make new tasks conform to the current state of the
    freezer.  If FROZEN state is requested while fork is in progress
    between cgroup_fork_callbacks() and cgroup_post_fork(), the child
    could escape freezing - the cgroup isn't frozen when ->fork() is
    called and the freezer couldn't see the new task on the css_set.
    
    This patch moves cgroup_subsys->fork() invocation to
    cgroup_post_fork() after the new task is added to the css_set.
    cgroup_fork_callbacks() is removed.
    
    Because now a task may be migrated during cgroup_subsys->fork(),
    freezer_fork() is updated so that it adheres to the usual RCU locking
    and the rather pointless comment on why locking can be different there
    is removed (if it doesn't make anything simpler, why even bother?).
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: stable@vger.kernel.org

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f8a030ced0c7..4cd1d0fd2542 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -34,7 +34,6 @@ extern int cgroup_lock_is_held(void);
 extern bool cgroup_lock_live_group(struct cgroup *cgrp);
 extern void cgroup_unlock(void);
 extern void cgroup_fork(struct task_struct *p);
-extern void cgroup_fork_callbacks(struct task_struct *p);
 extern void cgroup_post_fork(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 extern int cgroupstats_build(struct cgroupstats *stats,

commit 68d47a137c3bef754923bccf73fb639c9b0bbd5e
Merge: c0e8a139a5bb 8c7f6edbda01
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 2 10:52:28 2012 -0700

    Merge branch 'for-3.7-hierarchy' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup hierarchy update from Tejun Heo:
     "Currently, different cgroup subsystems handle nested cgroups
      completely differently.  There's no consistency among subsystems and
      the behaviors often are outright broken.
    
      People at least seem to agree that the broken hierarhcy behaviors need
      to be weeded out if any progress is gonna be made on this front and
      that the fallouts from deprecating the broken behaviors should be
      acceptable especially given that the current behaviors don't make much
      sense when nested.
    
      This patch makes cgroup emit warning messages if cgroups for
      subsystems with broken hierarchy behavior are nested to prepare for
      fixing them in the future.  This was put in a separate branch because
      more related changes were expected (didn't make it this round) and the
      memory cgroup wanted to pull in this and make changes on top."
    
    * 'for-3.7-hierarchy' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: mark subsystems with broken hierarchy support and whine if cgroups are nested for them

commit 8c7f6edbda01f1b1a2e60ad61f14fe38023e433b
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Sep 13 12:20:58 2012 -0700

    cgroup: mark subsystems with broken hierarchy support and whine if cgroups are nested for them
    
    Currently, cgroup hierarchy support is a mess.  cpu related subsystems
    behave correctly - configuration, accounting and control on a parent
    properly cover its children.  blkio and freezer completely ignore
    hierarchy and treat all cgroups as if they're directly under the root
    cgroup.  Others show yet different behaviors.
    
    These differing interpretations of cgroup hierarchy make using cgroup
    confusing and it impossible to co-mount controllers into the same
    hierarchy and obtain sane behavior.
    
    Eventually, we want full hierarchy support from all subsystems and
    probably a unified hierarchy.  Users using separate hierarchies
    expecting completely different behaviors depending on the mounted
    subsystem is deterimental to making any progress on this front.
    
    This patch adds cgroup_subsys.broken_hierarchy and sets it to %true
    for controllers which are lacking in hierarchy support.  The goal of
    this patch is two-fold.
    
    * Move users away from using hierarchy on currently non-hierarchical
      subsystems, so that implementing proper hierarchy support on those
      doesn't surprise them.
    
    * Keep track of which controllers are broken how and nudge the
      subsystems to implement proper hierarchy support.
    
    For now, start with a single warning message.  We can whine louder
    later on.
    
    v2: Fixed a typo spotted by Michal. Warning message updated.
    
    v3: Updated memcg part so that it doesn't generate warning in the
        cases where .use_hierarchy=false doesn't make the behavior
        different from root.use_hierarchy=true.  Fixed a typo spotted by
        Glauber.
    
    v4: Check ->broken_hierarchy after cgroup creation is complete so that
        ->create() can affect the result per Michal.  Dropped unnecessary
        memcg root handling per Michal.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Serge E. Hallyn <serue@us.ibm.com>
    Cc: Glauber Costa <glommer@parallels.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Paul Turner <pjt@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Thomas Graf <tgraf@suug.ch>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c90eaa803440..68e8df70487e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -496,6 +496,21 @@ struct cgroup_subsys {
 	 */
 	bool __DEPRECATED_clear_css_refs;
 
+	/*
+	 * If %false, this subsystem is properly hierarchical -
+	 * configuration, resource accounting and restriction on a parent
+	 * cgroup cover those of its children.  If %true, hierarchy support
+	 * is broken in some ways - some subsystems ignore hierarchy
+	 * completely while others are only implemented half-way.
+	 *
+	 * It's now disallowed to create nested cgroups if the subsystem is
+	 * broken and cgroup core will emit a warning message on such
+	 * cases.  Eventually, all subsystems will be made properly
+	 * hierarchical and this will go away.
+	 */
+	bool broken_hierarchy;
+	bool warned_broken_hierarchy;
+
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 

commit a6f00298b2ceaf50b4ab00e6ee3eb0206ac72fac
Author: Daniel Wagner <daniel.wagner@bmw-carit.de>
Date:   Wed Sep 12 16:12:08 2012 +0200

    cgroup: Define CGROUP_SUBSYS_COUNT according the configuration
    
    Since we know exactly how many subsystems exists at compile time we are
    able to define CGROUP_SUBSYS_COUNT correctly. CGROUP_SUBSYS_COUNT will
    be at max 12 (all controllers enabled). Depending on the architecture
    we safe either 32 - 12 pointers (80 bytes) or 64 - 12 pointers (416
    bytes) per cgroup.
    
    With this change we can also remove the temporary placeholder to avoid
    compilation errors.
    
    Signed-off-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: netdev@vger.kernel.org
    Cc: cgroups@vger.kernel.org

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 018f819405c8..df354ae079c1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -49,16 +49,10 @@ extern const struct file_operations proc_cgroup_operations;
 #define IS_SUBSYS_ENABLED(option) IS_ENABLED(option)
 enum cgroup_subsys_id {
 #include <linux/cgroup_subsys.h>
-	__CGROUP_TEMPORARY_PLACEHOLDER
+	CGROUP_SUBSYS_COUNT,
 };
 #undef IS_SUBSYS_ENABLED
 #undef SUBSYS
-/*
- * This define indicates the maximum number of subsystems that can be loaded
- * at once. We limit to this many since cgroupfs_root has subsys_bits to keep
- * track of all of them.
- */
-#define CGROUP_SUBSYS_COUNT (BITS_PER_BYTE*sizeof(unsigned long))
 
 /* Per-subsystem/per-cgroup state maintained by the system. */
 struct cgroup_subsys_state {

commit 8a8e04df4747661daaee77e98e102d99c9e09b98
Author: Daniel Wagner <daniel.wagner@bmw-carit.de>
Date:   Wed Sep 12 16:12:07 2012 +0200

    cgroup: Assign subsystem IDs during compile time
    
    WARNING: With this change it is impossible to load external built
    controllers anymore.
    
    In case where CONFIG_NETPRIO_CGROUP=m and CONFIG_NET_CLS_CGROUP=m is
    set, corresponding subsys_id should also be a constant. Up to now,
    net_prio_subsys_id and net_cls_subsys_id would be of the type int and
    the value would be assigned during runtime.
    
    By switching the macro definition IS_SUBSYS_ENABLED from IS_BUILTIN
    to IS_ENABLED, all *_subsys_id will have constant value. That means we
    need to remove all the code which assumes a value can be assigned to
    net_prio_subsys_id and net_cls_subsys_id.
    
    A close look is necessary on the RCU part which was introduces by
    following patch:
    
      commit f845172531fb7410c7fb7780b1a6e51ee6df7d52
      Author:       Herbert Xu <herbert@gondor.apana.org.au>  Mon May 24 09:12:34 2010
      Committer:    David S. Miller <davem@davemloft.net>  Mon May 24 09:12:34 2010
    
      cls_cgroup: Store classid in struct sock
    
      Tis code was added to init_cgroup_cls()
    
              /* We can't use rcu_assign_pointer because this is an int. */
              smp_wmb();
              net_cls_subsys_id = net_cls_subsys.subsys_id;
    
      respectively to exit_cgroup_cls()
    
              net_cls_subsys_id = -1;
              synchronize_rcu();
    
      and in module version of task_cls_classid()
    
              rcu_read_lock();
              id = rcu_dereference(net_cls_subsys_id);
              if (id >= 0)
                      classid = container_of(task_subsys_state(p, id),
                                             struct cgroup_cls_state, css)->classid;
              rcu_read_unlock();
    
    Without an explicit explaination why the RCU part is needed. (The
    rcu_deference was fixed by exchanging it to rcu_derefence_index_check()
    in a later commit, but that is a minor detail.)
    
    So here is my pondering why it was introduced and why it safe to
    remove it now. Note that this code was copied over to net_prio the
    reasoning holds for that subsystem too.
    
    The idea behind the RCU use for net_cls_subsys_id is to make sure we
    get a valid pointer back from task_subsys_state(). task_subsys_state()
    is just blindly accessing the subsys array and returning the
    pointer. Obviously, passing in -1 as id into task_subsys_state()
    returns an invalid value (out of lower bound).
    
    So this code makes sure that only after module is loaded and the
    subsystem registered, the id is assigned.
    
    Before unregistering the module all old readers must have left the
    critical section. This is done by assigning -1 to the id and issuing a
    synchronized_rcu(). Any new readers wont call task_subsys_state()
    anymore and therefore it is safe to unregister the subsystem.
    
    The new code relies on the same trick, but it looks at the subsys
    pointer return by task_subsys_state() (remember the id is constant
    and therefore we allways have a valid index into the subsys
    array).
    
    No precautions need to be taken during module loading
    module. Eventually, all CPUs will get a valid pointer back from
    task_subsys_state() because rebind_subsystem() which is called after
    the module init() function will assigned subsys[net_cls_subsys_id] the
    newly loaded module subsystem pointer.
    
    When the subsystem is about to be removed, rebind_subsystem() will
    called before the module exit() function. In this case,
    rebind_subsys() will assign subsys[net_cls_subsys_id] a NULL pointer
    and then it calls synchronize_rcu(). All old readers have left by then
    the critical section. Any new reader wont access the subsystem
    anymore.  At this point we are safe to unregister the subsystem. No
    synchronize_rcu() call is needed.
    
    Signed-off-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: Glauber Costa <glommer@parallels.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: netdev@vger.kernel.org
    Cc: cgroups@vger.kernel.org

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a5ab5651441b..018f819405c8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -46,7 +46,7 @@ extern const struct file_operations proc_cgroup_operations;
 
 /* Define the enumeration of all builtin cgroup subsystems */
 #define SUBSYS(_x) _x ## _subsys_id,
-#define IS_SUBSYS_ENABLED(option) IS_BUILTIN(option)
+#define IS_SUBSYS_ENABLED(option) IS_ENABLED(option)
 enum cgroup_subsys_id {
 #include <linux/cgroup_subsys.h>
 	__CGROUP_TEMPORARY_PLACEHOLDER

commit 5fc0b02544b3b9bd3db5a8156b5f3e7350f8e797
Author: Daniel Wagner <daniel.wagner@bmw-carit.de>
Date:   Wed Sep 12 16:12:05 2012 +0200

    cgroup: Wrap subsystem selection macro
    
    Before we are able to define all subsystem ids at compile time we need
    a more fine grained control what gets defined when we include
    cgroup_subsys.h. For example we define the enums for the subsystems or
    to declare for struct cgroup_subsys (builtin subsystem) by including
    cgroup_subsys.h and defining SUBSYS accordingly.
    
    Currently, the decision if a subsys is used is defined inside the
    header by testing if CONFIG_*=y is true. By moving this test outside
    of cgroup_subsys.h we are able to control it on the include level.
    
    This is done by introducing IS_SUBSYS_ENABLED which then is defined
    according the task, e.g. is CONFIG_*=y or CONFIG_*=m.
    
    Signed-off-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: netdev@vger.kernel.org
    Cc: cgroups@vger.kernel.org

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1916cdb071dc..a5ab5651441b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -46,10 +46,12 @@ extern const struct file_operations proc_cgroup_operations;
 
 /* Define the enumeration of all builtin cgroup subsystems */
 #define SUBSYS(_x) _x ## _subsys_id,
+#define IS_SUBSYS_ENABLED(option) IS_BUILTIN(option)
 enum cgroup_subsys_id {
 #include <linux/cgroup_subsys.h>
 	__CGROUP_TEMPORARY_PLACEHOLDER
 };
+#undef IS_SUBSYS_ENABLED
 #undef SUBSYS
 /*
  * This define indicates the maximum number of subsystems that can be loaded
@@ -528,7 +530,9 @@ struct cgroup_subsys {
 };
 
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _subsys;
+#define IS_SUBSYS_ENABLED(option) IS_BUILTIN(option)
 #include <linux/cgroup_subsys.h>
+#undef IS_SUBSYS_ENABLED
 #undef SUBSYS
 
 static inline struct cgroup_subsys_state *cgroup_subsys_state(

commit be45c900fdc2c66baad5a7703fb8136991d88aeb
Author: Daniel Wagner <daniel.wagner@bmw-carit.de>
Date:   Thu Sep 13 09:50:55 2012 +0200

    cgroup: Remove CGROUP_BUILTIN_SUBSYS_COUNT
    
    CGROUP_BUILTIN_SUBSYS_COUNT is used as start index or stop index when
    looping over the subsys array looking either at the builtin or the
    module subsystems. Since all the builtin subsystems have an id which
    is lower then CGROUP_BUILTIN_SUBSYS_COUNT we know that any module will
    have an id larger than CGROUP_BUILTIN_SUBSYS_COUNT. In short the ids
    are sorted.
    
    We are about to change id assignment to happen only at compile time
    later in this series. That means we can't rely on the above trick
    since all ids will always be defined at compile time. Furthermore,
    ordering the builtin subsystems and the module subsystems is not
    really necessary.
    
    So we need a different way to know which subsystem is a builtin or a
    module one. We can use the subsys[]->module pointer for this. Any
    place where we need to know if a subsys is module we just check for
    the pointer. If it is NULL then the subsystem is a builtin one.
    
    With this we are able to drop the CGROUP_BUILTIN_SUBSYS_COUNT
    enum. Though we need to introduce a temporary placeholder so that we
    don't get a compilation error when only CONFIG_CGROUP is selected and
    no single controller. An empty enum definition is not valid. Later in
    this series we are able to remove the placeholder again.
    
    And with this change we get a fix for this:
    
    kernel/cgroup.c: In function ‘cgroup_load_subsys’:
    kernel/cgroup.c:4326:38: warning: array subscript is below array bounds [-Warray-bounds]
    
    when CONFIG_CGROUP=y and no built in controller was enabled.
    
    Signed-off-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: netdev@vger.kernel.org
    Cc: cgroups@vger.kernel.org

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 145901f5ef99..1916cdb071dc 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -48,7 +48,7 @@ extern const struct file_operations proc_cgroup_operations;
 #define SUBSYS(_x) _x ## _subsys_id,
 enum cgroup_subsys_id {
 #include <linux/cgroup_subsys.h>
-	CGROUP_BUILTIN_SUBSYS_COUNT
+	__CGROUP_TEMPORARY_PLACEHOLDER
 };
 #undef SUBSYS
 /*

commit 03b1cde6b22f625ae832b939bc7379ec1466aec5
Author: Aristeu Rozanski <aris@redhat.com>
Date:   Thu Aug 23 16:53:30 2012 -0400

    cgroup: add xattr support
    
    This is one of the items in the plumber's wish list.
    
    For use cases:
    
    >> What would the use case be for this?
    >
    > Attaching meta information to services, in an easily discoverable
    > way. For example, in systemd we create one cgroup for each service, and
    > could then store data like the main pid of the specific service as an
    > xattr on the cgroup itself. That way we'd have almost all service state
    > in the cgroupfs, which would make it possible to terminate systemd and
    > later restart it without losing any state information. But there's more:
    > for example, some very peculiar services cannot be terminated on
    > shutdown (i.e. fakeraid DM stuff) and it would be really nice if the
    > services in question could just mark that on their cgroup, by setting an
    > xattr. On the more desktopy side of things there are other
    > possibilities: for example there are plans defining what an application
    > is along the lines of a cgroup (i.e. an app being a collection of
    > processes). With xattrs one could then attach an icon or human readable
    > program name on the cgroup.
    >
    > The key idea is that this would allow attaching runtime meta information
    > to cgroups and everything they model (services, apps, vms), that doesn't
    > need any complex userspace infrastructure, has good access control
    > (i.e. because the file system enforces that anyway, and there's the
    > "trusted." xattr namespace), notifications (inotify), and can easily be
    > shared among applications.
    >
    > Lennart
    
    v7:
    - no changes
    v6:
    - remove user xattr namespace, only allow trusted and security
    v5:
    - check for capabilities before setting/removing xattrs
    v4:
    - no changes
    v3:
    - instead of config option, use mount option to enable xattr support
    
    Original-patch-by: Li Zefan <lizefan@huawei.com>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Hillf Danton <dhillf@gmail.com>
    Cc: Lennart Poettering <lpoetter@redhat.com>
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Aristeu Rozanski <aris@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c90eaa803440..145901f5ef99 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -17,6 +17,7 @@
 #include <linux/rwsem.h>
 #include <linux/idr.h>
 #include <linux/workqueue.h>
+#include <linux/xattr.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -216,6 +217,9 @@ struct cgroup {
 	/* List of events which userspace want to receive */
 	struct list_head event_list;
 	spinlock_t event_list_lock;
+
+	/* directory xattrs */
+	struct simple_xattrs xattrs;
 };
 
 /*
@@ -309,6 +313,9 @@ struct cftype {
 	/* CFTYPE_* flags */
 	unsigned int flags;
 
+	/* file xattrs */
+	struct simple_xattrs xattrs;
+
 	int (*open)(struct inode *inode, struct file *file);
 	ssize_t (*read)(struct cgroup *cgrp, struct cftype *cft,
 			struct file *file,
@@ -394,7 +401,7 @@ struct cftype {
  */
 struct cftype_set {
 	struct list_head		node;	/* chained at subsys->cftsets */
-	const struct cftype		*cfts;
+	struct cftype			*cfts;
 };
 
 struct cgroup_scanner {
@@ -406,8 +413,8 @@ struct cgroup_scanner {
 	void *data;
 };
 
-int cgroup_add_cftypes(struct cgroup_subsys *ss, const struct cftype *cfts);
-int cgroup_rm_cftypes(struct cgroup_subsys *ss, const struct cftype *cfts);
+int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
+int cgroup_rm_cftypes(struct cgroup_subsys *ss, struct cftype *cfts);
 
 int cgroup_is_removed(const struct cgroup *cgrp);
 

commit 6be96a5c905178637ec06a5d456a76b2b304fca3
Author: Li Zefan <lizefan@huawei.com>
Date:   Wed Jun 6 19:12:30 2012 -0700

    cgroup: remove hierarchy_mutex
    
    It was introduced for memcg to iterate cgroup hierarchy without
    holding cgroup_mutex, but soon after that it was replaced with
    a lockless way in memcg.
    
    No one used hierarchy_mutex since that, so remove it.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d3f5fba2c159..c90eaa803440 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -499,22 +499,9 @@ struct cgroup_subsys {
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 
-	/*
-	 * Protects sibling/children links of cgroups in this
-	 * hierarchy, plus protects which hierarchy (or none) the
-	 * subsystem is a part of (i.e. root/sibling).  To avoid
-	 * potential deadlocks, the following operations should not be
-	 * undertaken while holding any hierarchy_mutex:
-	 *
-	 * - allocating memory
-	 * - initiating hotplug events
-	 */
-	struct mutex hierarchy_mutex;
-	struct lock_class_key subsys_key;
-
 	/*
 	 * Link to parent, and list entry in parent's children.
-	 * Protected by this->hierarchy_mutex and cgroup_lock()
+	 * Protected by cgroup_lock()
 	 */
 	struct cgroupfs_root *root;
 	struct list_head sibling;
@@ -602,7 +589,7 @@ int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
  * the lifetime of cgroup_subsys_state is subsys's matter.
  *
  * Looking up and scanning function should be called under rcu_read_lock().
- * Taking cgroup_mutex()/hierarchy_mutex() is not necessary for following calls.
+ * Taking cgroup_mutex is not necessary for following calls.
  * But the css returned by this routine can be "not populated yet" or "being
  * destroyed". The caller should check css and cgroup's status.
  */

commit 86f82d561864e902c70282b6f17cf590c0f34691
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Apr 10 10:16:36 2012 -0700

    cgroup: remove cgroup_subsys->populate()
    
    With memcg converted, cgroup_subsys->populate() doesn't have any user
    left.  Remove it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 565c8034e6c8..d3f5fba2c159 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -472,7 +472,6 @@ struct cgroup_subsys {
 	void (*fork)(struct task_struct *task);
 	void (*exit)(struct cgroup *cgrp, struct cgroup *old_cgrp,
 		     struct task_struct *task);
-	int (*populate)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*post_clone)(struct cgroup *cgrp);
 	void (*bind)(struct cgroup *root);
 

commit 48ddbe194623ae089cc0576e60363f2d2e85662a
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:56 2012 -0700

    cgroup: make css->refcnt clearing on cgroup removal optional
    
    Currently, cgroup removal tries to drain all css references.  If there
    are active css references, the removal logic waits and retries
    ->pre_detroy() until either all refs drop to zero or removal is
    cancelled.
    
    This semantics is unusual and adds non-trivial complexity to cgroup
    core and IMHO is fundamentally misguided in that it couples internal
    implementation details (references to internal data structure) with
    externally visible operation (rmdir).  To userland, this is a behavior
    peculiarity which is unnecessary and difficult to expect (css refs is
    otherwise invisible from userland), and, to policy implementations,
    this is an unnecessary restriction (e.g. blkcg wants to hold css refs
    for caching purposes but can't as that becomes visible as rmdir hang).
    
    Unfortunately, memcg currently depends on ->pre_destroy() retrials and
    cgroup removal vetoing and can't be immmediately switched to the new
    behavior.  This patch introduces the new behavior of not waiting for
    css refs to drain and maintains the old behavior for subsystems which
    have __DEPRECATED_clear_css_refs set.
    
    Once, memcg is updated, we can drop the code paths for the old
    behavior as proposed in the following patch.  Note that the following
    patch is incorrect in that dput work item is in cgroup and may lose
    some of dputs when multiples css's are released back-to-back, and
    __css_put() triggers check_for_release() when refcnt reaches 0 instead
    of 1; however, it shows what part can be removed.
    
      http://thread.gmane.org/gmane.linux.kernel.containers/22559/focus=75251
    
    Note that, in not-too-distant future, cgroup core will start emitting
    warning messages for subsys which require the old behavior, so please
    get moving.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index be81fafae11f..565c8034e6c8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -16,6 +16,7 @@
 #include <linux/prio_heap.h>
 #include <linux/rwsem.h>
 #include <linux/idr.h>
+#include <linux/workqueue.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -76,12 +77,16 @@ struct cgroup_subsys_state {
 	unsigned long flags;
 	/* ID for this css, if possible */
 	struct css_id __rcu *id;
+
+	/* Used to put @cgroup->dentry on the last css_put() */
+	struct work_struct dput_work;
 };
 
 /* bits in struct cgroup_subsys_state flags field */
 enum {
 	CSS_ROOT, /* This CSS is the root of the subsystem */
 	CSS_REMOVED, /* This CSS is dead */
+	CSS_CLEAR_CSS_REFS,		/* @ss->__DEPRECATED_clear_css_refs */
 };
 
 /* Caller must verify that the css is not for root cgroup */
@@ -480,6 +485,18 @@ struct cgroup_subsys {
 	 * (not available in early_init time.)
 	 */
 	bool use_id;
+
+	/*
+	 * If %true, cgroup removal will try to clear css refs by retrying
+	 * ss->pre_destroy() until there's no css ref left.  This behavior
+	 * is strictly for backward compatibility and will be removed as
+	 * soon as the current user (memcg) is updated.
+	 *
+	 * If %false, ss->pre_destroy() can't fail and cgroup removal won't
+	 * wait for css refs to drop to zero before proceeding.
+	 */
+	bool __DEPRECATED_clear_css_refs;
+
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 

commit 28b4c27b8e6bb6d7ff2875281a8484f8898a87ef
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:56 2012 -0700

    cgroup: use negative bias on css->refcnt to block css_tryget()
    
    When a cgroup is about to be removed, cgroup_clear_css_refs() is
    called to check and ensure that there are no active css references.
    
    This is currently achieved by dropping the refcnt to zero iff it has
    only the base ref.  If all css refs could be dropped to zero, ref
    clearing is successful and CSS_REMOVED is set on all css.  If not, the
    base ref is restored.  While css ref is zero w/o CSS_REMOVED set, any
    css_tryget() attempt on it busy loops so that they are atomic
    w.r.t. the whole css ref clearing.
    
    This does work but dropping and re-instating the base ref is somewhat
    hairy and makes it difficult to add more logic to the put path as
    there are two of them - the regular css_put() and the reversible base
    ref clearing.
    
    This patch updates css ref clearing such that blocking new
    css_tryget() and putting the base ref are separate operations.
    CSS_DEACT_BIAS, defined as INT_MIN, is added to css->refcnt and
    css_tryget() busy loops while refcnt is negative.  After all css refs
    are deactivated, if they were all one, ref clearing succeeded and
    CSS_REMOVED is set and the base ref is put using the regular
    css_put(); otherwise, CSS_DEACT_BIAS is subtracted from the refcnts
    and the original postive values are restored.
    
    css_refcnt() accessor which always returns the unbiased positive
    reference counts is added and used to simplify refcnt usages.  While
    at it, relocate and reformat comments in cgroup_has_css_refs().
    
    This separates css->refcnt deactivation and putting the base ref,
    which enables the next patch to make ref clearing optional.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 028478c6e0c5..be81fafae11f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -115,16 +115,12 @@ static inline bool css_is_removed(struct cgroup_subsys_state *css)
  * the css has been destroyed.
  */
 
+extern bool __css_tryget(struct cgroup_subsys_state *css);
 static inline bool css_tryget(struct cgroup_subsys_state *css)
 {
 	if (test_bit(CSS_ROOT, &css->flags))
 		return true;
-	while (!atomic_inc_not_zero(&css->refcnt)) {
-		if (test_bit(CSS_REMOVED, &css->flags))
-			return false;
-		cpu_relax();
-	}
-	return true;
+	return __css_tryget(css);
 }
 
 /*
@@ -132,11 +128,11 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
  * css_get() or css_tryget()
  */
 
-extern void __css_put(struct cgroup_subsys_state *css, int count);
+extern void __css_put(struct cgroup_subsys_state *css);
 static inline void css_put(struct cgroup_subsys_state *css)
 {
 	if (!test_bit(CSS_ROOT, &css->flags))
-		__css_put(css, 1);
+		__css_put(css);
 }
 
 /* bits in struct cgroup flags field */

commit 79578621b4847afdef48d19a28d00e3b188c37e1
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:56 2012 -0700

    cgroup: implement cgroup_rm_cftypes()
    
    Implement cgroup_rm_cftypes() which removes an array of cftypes from a
    subsystem.  It can be called whether the target subsys is attached or
    not.  cgroup core will remove the specified file from all existing
    cgroups.
    
    This will be used to improve sub-subsys modularity and will be helpful
    for unified hierarchy.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 87b034ed0c31..028478c6e0c5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -406,6 +406,7 @@ struct cgroup_scanner {
 };
 
 int cgroup_add_cftypes(struct cgroup_subsys *ss, const struct cftype *cfts);
+int cgroup_rm_cftypes(struct cgroup_subsys *ss, const struct cftype *cfts);
 
 int cgroup_is_removed(const struct cgroup *cgrp);
 

commit 05ef1d7c4a5b6d09cadd2b8e9b3c395363d1a89c
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:56 2012 -0700

    cgroup: introduce struct cfent
    
    This patch adds cfent (cgroup file entry) which is the association
    between a cgroup and a file.  This is in-cgroup representation of
    files under a cgroup directory.  This simplifies walking walking
    cgroup files and thus cgroup_clear_directory(), which is now
    implemented in two parts - cgroup_rm_file() and a loop around it.
    
    cgroup_rm_file() will be used to implement cftype removal and cfent is
    scheduled to serve cgroup specific per-file data (e.g. for sysfs-like
    "sever" semantics).
    
    v2: - cfe was freed from cgroup_rm_file() which led to use-after-free
          if the file had openers at the time of removal.  Moved to
          cgroup_diput().
    
        - cgroup_clear_directory() triggered WARN_ON_ONCE() if d_subdirs
          wasn't empty after removing all files.  This triggered
          spuriously if some files were open during directory clearing.
          Removed.
    
    v3: - In cgroup_diput(), WARN_ONCE(!list_empty(&cfe->node)) could be
          spuriously triggered for root cgroups because they don't go
          through cgroup_clear_directory() on unmount.  Don't trigger WARN
          for root cgroups.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Glauber Costa <glommer@parallels.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7a3d96755114..87b034ed0c31 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -175,6 +175,7 @@ struct cgroup {
 	 */
 	struct list_head sibling;	/* my parent's children */
 	struct list_head children;	/* my children */
+	struct list_head files;		/* my files */
 
 	struct cgroup *parent;		/* my parent */
 	struct dentry __rcu *dentry;	/* cgroup fs entry, RCU protected */

commit db0416b64977cb0f382175608286cc80c7573e38
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:55 2012 -0700

    cgroup: remove cgroup_add_file[s]()
    
    No controller is using cgroup_add_files[s]().  Unexport them, and
    convert cgroup_add_files() to handle NULL entry terminated array
    instead of taking count explicitly and continue creation on failure
    for internal use.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index af6211c7a42b..7a3d96755114 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -404,22 +404,6 @@ struct cgroup_scanner {
 	void *data;
 };
 
-/*
- * Add a new file to the given cgroup directory. Should only be
- * called by subsystems from within a populate() method
- */
-int cgroup_add_file(struct cgroup *cgrp, struct cgroup_subsys *subsys,
-		       const struct cftype *cft);
-
-/*
- * Add a set of new files to the given cgroup directory. Should
- * only be called by subsystems from within a populate() method
- */
-int cgroup_add_files(struct cgroup *cgrp,
-			struct cgroup_subsys *subsys,
-			const struct cftype cft[],
-			int count);
-
 int cgroup_add_cftypes(struct cgroup_subsys *ss, const struct cftype *cfts);
 
 int cgroup_is_removed(const struct cgroup *cgrp);

commit 8e3f6541d45e1a002801e56a19530a90f775deba
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:55 2012 -0700

    cgroup: implement cgroup_add_cftypes() and friends
    
    Currently, cgroup directories are populated by subsys->populate()
    callback explicitly creating files on each cgroup creation.  This
    level of flexibility isn't needed or desirable.  It provides largely
    unused flexibility which call for abuses while severely limiting what
    the core layer can do through the lack of structure and conventions.
    
    Per each cgroup file type, the only distinction that cgroup users is
    making is whether a cgroup is root or not, which can easily be
    expressed with flags.
    
    This patch introduces cgroup_add_cftypes().  These deal with cftypes
    instead of individual files - controllers indicate that certain types
    of files exist for certain subsystem.  Newly added CFTYPE_*_ON_ROOT
    flags indicate whether a cftype should be excluded or created only on
    the root cgroup.
    
    cgroup_add_cftypes() can be called any time whether the target
    subsystem is currently attached or not.  cgroup core will create files
    on the existing cgroups as necessary.
    
    Also, cgroup_subsys->base_cftypes is added to ease registration of the
    base files for the subsystem.  If non-NULL on subsys init, the cftypes
    pointed to by ->base_cftypes are automatically registered on subsys
    init / load.
    
    Further patches will convert the existing users and remove the file
    based interface.  Note that this interface allows dynamic addition of
    files to an active controller.  This will be used for sub-controller
    modularity and unified hierarchy in the longer term.
    
    This patch implements the new mechanism but doesn't apply it to any
    user.
    
    v2: replaced DECLARE_CGROUP_CFTYPES[_COND]() with
        cgroup_subsys->base_cftypes, which works better for cgroup_subsys
        which is loaded as module.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ad2a14680b7f..af6211c7a42b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -192,6 +192,7 @@ struct cgroup {
 	struct list_head css_sets;
 
 	struct list_head allcg_node;	/* cgroupfs_root->allcg_list */
+	struct list_head cft_q_node;	/* used during cftype add/rm */
 
 	/*
 	 * Linked list running through all cgroups that can
@@ -277,11 +278,17 @@ struct cgroup_map_cb {
  *	- the 'cftype' of the file is file->f_dentry->d_fsdata
  */
 
-#define MAX_CFTYPE_NAME 64
+/* cftype->flags */
+#define CFTYPE_ONLY_ON_ROOT	(1U << 0)	/* only create on root cg */
+#define CFTYPE_NOT_ON_ROOT	(1U << 1)	/* don't create onp root cg */
+
+#define MAX_CFTYPE_NAME		64
+
 struct cftype {
 	/*
 	 * By convention, the name should begin with the name of the
-	 * subsystem, followed by a period
+	 * subsystem, followed by a period.  Zero length string indicates
+	 * end of cftype array.
 	 */
 	char name[MAX_CFTYPE_NAME];
 	int private;
@@ -297,6 +304,9 @@ struct cftype {
 	 */
 	size_t max_write_len;
 
+	/* CFTYPE_* flags */
+	unsigned int flags;
+
 	int (*open)(struct inode *inode, struct file *file);
 	ssize_t (*read)(struct cgroup *cgrp, struct cftype *cft,
 			struct file *file,
@@ -375,6 +385,16 @@ struct cftype {
 			struct eventfd_ctx *eventfd);
 };
 
+/*
+ * cftype_sets describe cftypes belonging to a subsystem and are chained at
+ * cgroup_subsys->cftsets.  Each cftset points to an array of cftypes
+ * terminated by zero length name.
+ */
+struct cftype_set {
+	struct list_head		node;	/* chained at subsys->cftsets */
+	const struct cftype		*cfts;
+};
+
 struct cgroup_scanner {
 	struct cgroup *cg;
 	int (*test_task)(struct task_struct *p, struct cgroup_scanner *scan);
@@ -400,6 +420,8 @@ int cgroup_add_files(struct cgroup *cgrp,
 			const struct cftype cft[],
 			int count);
 
+int cgroup_add_cftypes(struct cgroup_subsys *ss, const struct cftype *cfts);
+
 int cgroup_is_removed(const struct cgroup *cgrp);
 
 int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
@@ -502,6 +524,13 @@ struct cgroup_subsys {
 	struct idr idr;
 	spinlock_t id_lock;
 
+	/* list of cftype_sets */
+	struct list_head cftsets;
+
+	/* base cftypes, automatically [de]registered with subsys itself */
+	struct cftype *base_cftypes;
+	struct cftype_set base_cftset;
+
 	/* should be defined only by modular subsystems */
 	struct module *module;
 };

commit b0ca5a84fc3ad8f75bb2b7ac3dc6a77151cd3906
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:54 2012 -0700

    cgroup: build list of all cgroups under a given cgroupfs_root
    
    Build a list of all cgroups anchored at cgroupfs_root->allcg_list and
    going through cgroup->allcg_node.  The list is protected by
    cgroup_mutex and will be used to improve cgroup file handling.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5a85b3415c1b..ad2a14680b7f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -191,6 +191,8 @@ struct cgroup {
 	 */
 	struct list_head css_sets;
 
+	struct list_head allcg_node;	/* cgroupfs_root->allcg_list */
+
 	/*
 	 * Linked list running through all cgroups that can
 	 * potentially be reaped by the release agent. Protected by

commit 42aee6c495e07dba7410b863a360db6bb9ec6d66
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Mar 21 16:34:21 2012 -0700

    cgroup: revert ss_id_lock to spinlock
    
    Commit c1e2ee2dc436 ("memcg: replace ss->id_lock with a rwlock") has now
    been seen to cause the unfair behavior we should have expected from
    converting a spinlock to an rwlock: softlockup in cgroup_mkdir(), whose
    get_new_cssid() is waiting for the wlock, while there are 19 tasks using
    the rlock in css_get_next() to get on with their memcg workload (in an
    artificial test, admittedly).  Yet lib/idr.c was made suitable for RCU
    way back: revert that commit, restoring ss->id_lock to a spinlock.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 501adb1b2f43..5a85b3415c1b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -498,7 +498,7 @@ struct cgroup_subsys {
 	struct list_head sibling;
 	/* used when use_id == true */
 	struct idr idr;
-	rwlock_t id_lock;
+	spinlock_t id_lock;
 
 	/* should be defined only by modular subsystems */
 	struct module *module;

commit 761b3ef50e1c2649cffbfa67a4dcb2dcdb7982ed
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Jan 31 13:47:36 2012 +0800

    cgroup: remove cgroup_subsys argument from callbacks
    
    The argument is not used at all, and it's not necessary, because
    a specific callback handler of course knows which subsys it
    belongs to.
    
    Now only ->pupulate() takes this argument, because the handlers of
    this callback always call cgroup_add_file()/cgroup_add_files().
    
    So we reduce a few lines of code, though the shrinking of object size
    is minimal.
    
     16 files changed, 113 insertions(+), 162 deletions(-)
    
       text    data     bss     dec     hex filename
    5486240  656987 7039960 13183187         c928d3 vmlinux.o.orig
    5486170  656987 7039960 13183117         c9288d vmlinux.o
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7da3e745b74c..501adb1b2f43 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -452,23 +452,18 @@ int cgroup_taskset_size(struct cgroup_taskset *tset);
  */
 
 struct cgroup_subsys {
-	struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss,
-						  struct cgroup *cgrp);
-	int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
-	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
-	int (*can_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			  struct cgroup_taskset *tset);
-	void (*cancel_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			      struct cgroup_taskset *tset);
-	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-		       struct cgroup_taskset *tset);
-	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);
-	void (*exit)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			struct cgroup *old_cgrp, struct task_struct *task);
-	int (*populate)(struct cgroup_subsys *ss,
-			struct cgroup *cgrp);
-	void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp);
-	void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);
+	struct cgroup_subsys_state *(*create)(struct cgroup *cgrp);
+	int (*pre_destroy)(struct cgroup *cgrp);
+	void (*destroy)(struct cgroup *cgrp);
+	int (*can_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
+	void (*cancel_attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
+	void (*attach)(struct cgroup *cgrp, struct cgroup_taskset *tset);
+	void (*fork)(struct task_struct *task);
+	void (*exit)(struct cgroup *cgrp, struct cgroup *old_cgrp,
+		     struct task_struct *task);
+	int (*populate)(struct cgroup_subsys *ss, struct cgroup *cgrp);
+	void (*post_clone)(struct cgroup *cgrp);
+	void (*bind)(struct cgroup *root);
 
 	int subsys_id;
 	int active;

commit 245282557c49754af3dbcc732316e814340d6bce
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Jan 20 11:58:43 2012 +0800

    cgroup: move struct cgroup_pidlist out from the header file
    
    It's internally used only.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index dee53bdb046d..7da3e745b74c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -160,38 +160,6 @@ enum {
 	CGRP_CLONE_CHILDREN,
 };
 
-/* which pidlist file are we talking about? */
-enum cgroup_filetype {
-	CGROUP_FILE_PROCS,
-	CGROUP_FILE_TASKS,
-};
-
-/*
- * A pidlist is a list of pids that virtually represents the contents of one
- * of the cgroup files ("procs" or "tasks"). We keep a list of such pidlists,
- * a pair (one each for procs, tasks) for each pid namespace that's relevant
- * to the cgroup.
- */
-struct cgroup_pidlist {
-	/*
-	 * used to find which pidlist is wanted. doesn't change as long as
-	 * this particular list stays in the list.
-	 */
-	struct { enum cgroup_filetype type; struct pid_namespace *ns; } key;
-	/* array of xids */
-	pid_t *list;
-	/* how many elements the above list has */
-	int length;
-	/* how many files are using the current array */
-	int use_count;
-	/* each of these stored in a list by its cgroup */
-	struct list_head links;
-	/* pointer to the cgroup we belong to, for list removal purposes */
-	struct cgroup *owner;
-	/* protects the other fields */
-	struct rw_semaphore mutex;
-};
-
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 

commit a63b9072ea4e32c1fde8b783ccf6e4288414660b
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Jan 20 11:58:09 2012 +0800

    cgroup: remove cgroup_attach_task_current_cg()
    
    It's just a wrapper of cgroup_attach_task_all(), and it's no longer
    used after commit 87d6a412bd1ed82c14cabd4b408003b23bbd2880
    (vhost: fix attach to cgroups regression)
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e9b602151caf..dee53bdb046d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -602,11 +602,6 @@ int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *, struct task_struct *);
 int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
 
-static inline int cgroup_attach_task_current_cg(struct task_struct *tsk)
-{
-	return cgroup_attach_task_all(current, tsk);
-}
-
 /*
  * CSS ID is ID for cgroup_subsys_state structs under subsys. This only works
  * if cgroup_subsys.use_id == true. It can be used for looking up and scanning.
@@ -669,10 +664,6 @@ static inline int cgroup_attach_task_all(struct task_struct *from,
 {
 	return 0;
 }
-static inline int cgroup_attach_task_current_cg(struct task_struct *t)
-{
-	return 0;
-}
 
 #endif /* !CONFIG_CGROUPS */
 

commit db0c2bf69aa095d4a6de7b1145f29fe9a7c0f6a3
Merge: ac69e0928054 0d19ea866562
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 9 12:59:24 2012 -0800

    Merge branch 'for-3.3' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    * 'for-3.3' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup: (21 commits)
      cgroup: fix to allow mounting a hierarchy by name
      cgroup: move assignement out of condition in cgroup_attach_proc()
      cgroup: Remove task_lock() from cgroup_post_fork()
      cgroup: add sparse annotation to cgroup_iter_start() and cgroup_iter_end()
      cgroup: mark cgroup_rmdir_waitq and cgroup_attach_proc() as static
      cgroup: only need to check oldcgrp==newgrp once
      cgroup: remove redundant get/put of task struct
      cgroup: remove redundant get/put of old css_set from migrate
      cgroup: Remove unnecessary task_lock before fetching css_set on migration
      cgroup: Drop task_lock(parent) on cgroup_fork()
      cgroups: remove redundant get/put of css_set from css_set_check_fetched()
      resource cgroups: remove bogus cast
      cgroup: kill subsys->can_attach_task(), pre_attach() and attach_task()
      cgroup, cpuset: don't use ss->pre_attach()
      cgroup: don't use subsys->can_attach_task() or ->attach_task()
      cgroup: introduce cgroup_taskset and use it in subsys->can_attach(), cancel_attach() and attach()
      cgroup: improve old cgroup handling in cgroup_attach_proc()
      cgroup: always lock threadgroup during migration
      threadgroup: extend threadgroup_lock() to cover exit and exec
      threadgroup: rename signal->threadgroup_fork_lock to ->group_rwsem
      ...
    
    Fix up conflict in kernel/cgroup.c due to commit e0197aae59e5: "cgroups:
    fix a css_set not found bug in cgroup_attach_proc" that already
    mentioned that the bug is fixed (differently) in Tejun's cgroup
    patchset. This one, in other words.

commit a5e7ed3287e45f2eafbcf9e7e6fdc5a0191acf40
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jul 26 01:55:55 2011 -0400

    cgroup: propagate mode_t
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1b7f9d525013..a17becc36ca1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -319,7 +319,7 @@ struct cftype {
 	 * If not 0, file mode is set to this value, otherwise it will
 	 * be figured out automatically
 	 */
-	mode_t mode;
+	umode_t mode;
 
 	/*
 	 * If non-zero, defines the maximum length of string that can

commit 494c167cf76d02000adf740c215adc69a824ecc9
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Dec 12 18:12:22 2011 -0800

    cgroup: kill subsys->can_attach_task(), pre_attach() and attach_task()
    
    These three methods are no longer used.  Kill them.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Reviewed-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Paul Menage <paul@paulmenage.org>
    Cc: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 34256ad9e553..7ad5e406c421 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -490,11 +490,8 @@ struct cgroup_subsys {
 	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
 			  struct cgroup_taskset *tset);
-	int (*can_attach_task)(struct cgroup *cgrp, struct task_struct *tsk);
 	void (*cancel_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
 			      struct cgroup_taskset *tset);
-	void (*pre_attach)(struct cgroup *cgrp);
-	void (*attach_task)(struct cgroup *cgrp, struct task_struct *tsk);
 	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
 		       struct cgroup_taskset *tset);
 	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);

commit 2f7ee5691eecb67c8108b92001a85563ea336ac5
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Dec 12 18:12:21 2011 -0800

    cgroup: introduce cgroup_taskset and use it in subsys->can_attach(), cancel_attach() and attach()
    
    Currently, there's no way to pass multiple tasks to cgroup_subsys
    methods necessitating the need for separate per-process and per-task
    methods.  This patch introduces cgroup_taskset which can be used to
    pass multiple tasks and their associated cgroups to cgroup_subsys
    methods.
    
    Three methods - can_attach(), cancel_attach() and attach() - are
    converted to use cgroup_taskset.  This unifies passed parameters so
    that all methods have access to all information.  Conversions in this
    patchset are identical and don't introduce any behavior change.
    
    -v2: documentation updated as per Paul Menage's suggestion.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Reviewed-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Paul Menage <paul@paulmenage.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: James Morris <jmorris@namei.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1b7f9d525013..34256ad9e553 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -456,6 +456,28 @@ int cgroup_is_descendant(const struct cgroup *cgrp, struct task_struct *task);
 void cgroup_exclude_rmdir(struct cgroup_subsys_state *css);
 void cgroup_release_and_wakeup_rmdir(struct cgroup_subsys_state *css);
 
+/*
+ * Control Group taskset, used to pass around set of tasks to cgroup_subsys
+ * methods.
+ */
+struct cgroup_taskset;
+struct task_struct *cgroup_taskset_first(struct cgroup_taskset *tset);
+struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset);
+struct cgroup *cgroup_taskset_cur_cgroup(struct cgroup_taskset *tset);
+int cgroup_taskset_size(struct cgroup_taskset *tset);
+
+/**
+ * cgroup_taskset_for_each - iterate cgroup_taskset
+ * @task: the loop cursor
+ * @skip_cgrp: skip if task's cgroup matches this, %NULL to iterate through all
+ * @tset: taskset to iterate
+ */
+#define cgroup_taskset_for_each(task, skip_cgrp, tset)			\
+	for ((task) = cgroup_taskset_first((tset)); (task);		\
+	     (task) = cgroup_taskset_next((tset)))			\
+		if (!(skip_cgrp) ||					\
+		    cgroup_taskset_cur_cgroup((tset)) != (skip_cgrp))
+
 /*
  * Control Group subsystem type.
  * See Documentation/cgroups/cgroups.txt for details
@@ -467,14 +489,14 @@ struct cgroup_subsys {
 	int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			  struct task_struct *tsk);
+			  struct cgroup_taskset *tset);
 	int (*can_attach_task)(struct cgroup *cgrp, struct task_struct *tsk);
 	void (*cancel_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			      struct task_struct *tsk);
+			      struct cgroup_taskset *tset);
 	void (*pre_attach)(struct cgroup *cgrp);
 	void (*attach_task)(struct cgroup *cgrp, struct task_struct *tsk);
 	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-		       struct cgroup *old_cgrp, struct task_struct *tsk);
+		       struct cgroup_taskset *tset);
 	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);
 	void (*exit)(struct cgroup_subsys *ss, struct cgroup *cgrp,
 			struct cgroup *old_cgrp, struct task_struct *task);

commit c1e2ee2dc436574880758b3836fc96935b774c32
Author: Andrew Bresticker <abrestic@google.com>
Date:   Wed Nov 2 13:40:29 2011 -0700

    memcg: replace ss->id_lock with a rwlock
    
    While back-porting Johannes Weiner's patch "mm: memcg-aware global
    reclaim" for an internal effort, we noticed a significant performance
    regression during page-reclaim heavy workloads due to high contention of
    the ss->id_lock.  This lock protects idr map, and serializes calls to
    idr_get_next() in css_get_next() (which is used during the memcg hierarchy
    walk).
    
    Since idr_get_next() is just doing a look up, we need only serialize it
    with respect to idr_remove()/idr_get_new().  By making the ss->id_lock a
    rwlock, contention is greatly reduced and performance improves.
    
    Tested: cat a 256m file from a ramdisk in a 128m container 50 times on
    each core (one file + container per core) in parallel on a NUMA machine.
    Result is the time for the test to complete in 1 of the containers.
    Both kernels included Johannes' memcg-aware global reclaim patches.
    
    Before rwlock patch: 1710.778s
    After rwlock patch: 152.227s
    
    Signed-off-by: Andrew Bresticker <abrestic@google.com>
    Cc: Paul Menage <menage@gmail.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Ying Han <yinghan@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index da7e4bc34e8c..1b7f9d525013 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -516,7 +516,7 @@ struct cgroup_subsys {
 	struct list_head sibling;
 	/* used when use_id == true */
 	struct idr idr;
-	spinlock_t id_lock;
+	rwlock_t id_lock;
 
 	/* should be defined only by modular subsystems */
 	struct module *module;

commit d8bf4ca9ca9576548628344c9725edd3786e90b1
Author: Michal Hocko <mhocko@suse.cz>
Date:   Fri Jul 8 14:39:41 2011 +0200

    rcu: treewide: Do not use rcu_read_lock_held when calling rcu_dereference_check
    
    Since ca5ecddf (rcu: define __rcu address space modifier for sparse)
    rcu_dereference_check use rcu_read_lock_held as a part of condition
    automatically so callers do not have to do that as well.
    
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ab4ac0ccb857..da7e4bc34e8c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -539,7 +539,6 @@ static inline struct cgroup_subsys_state *cgroup_subsys_state(
  */
 #define task_subsys_state_check(task, subsys_id, __c)			\
 	rcu_dereference_check(task->cgroups->subsys[subsys_id],		\
-			      rcu_read_lock_held() ||			\
 			      lockdep_is_held(&task->alloc_lock) ||	\
 			      cgroup_lock_is_held() || (__c))
 

commit a77aea92010acf54ad785047234418d5d68772e2
Author: Daniel Lezcano <daniel.lezcano@free.fr>
Date:   Thu May 26 16:25:23 2011 -0700

    cgroup: remove the ns_cgroup
    
    The ns_cgroup is an annoying cgroup at the namespace / cgroup frontier and
    leads to some problems:
    
      * cgroup creation is out-of-control
      * cgroup name can conflict when pids are looping
      * it is not possible to have a single process handling a lot of
        namespaces without falling in a exponential creation time
      * we may want to create a namespace without creating a cgroup
    
      The ns_cgroup was replaced by a compatibility flag 'clone_children',
      where a newly created cgroup will copy the parent cgroup values.
      The userspace has to manually create a cgroup and add a task to
      the 'tasks' file.
    
    This patch removes the ns_cgroup as suggested in the following thread:
    
    https://lists.linux-foundation.org/pipermail/containers/2009-June/018616.html
    
    The 'cgroup_clone' function is removed because it is no longer used.
    
    This is a userspace-visible change.  Commit 45531757b45c ("cgroup: notify
    ns_cgroup deprecated") (merged into 2.6.27) caused the kernel to emit a
    printk warning users that the feature is planned for removal.  Since that
    time we have heard from XXX users who were affected by this.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@free.fr>
    Signed-off-by: Serge E. Hallyn <serge.hallyn@canonical.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Jamal Hadi Salim <hadi@cyberus.ca>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Acked-by: Matt Helsley <matthltc@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1e6cde21fa3f..ab4ac0ccb857 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -555,9 +555,6 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 	return task_subsys_state(task, subsys_id)->cgroup;
 }
 
-int cgroup_clone(struct task_struct *tsk, struct cgroup_subsys *ss,
-							char *nodename);
-
 /* A cgroup_iter should be treated as an opaque object */
 struct cgroup_iter {
 	struct list_head *cg_link;

commit f780bdb7c1c73009cb57adcf99ef50027d80bf3c
Author: Ben Blum <bblum@andrew.cmu.edu>
Date:   Thu May 26 16:25:19 2011 -0700

    cgroups: add per-thread subsystem callbacks
    
    Add cgroup subsystem callbacks for per-thread attachment in atomic contexts
    
    Add can_attach_task(), pre_attach(), and attach_task() as new callbacks
    for cgroups's subsystem interface.  Unlike can_attach and attach, these
    are for per-thread operations, to be called potentially many times when
    attaching an entire threadgroup.
    
    Also, the old "bool threadgroup" interface is removed, as replaced by
    this.  All subsystems are modified for the new interface - of note is
    cpuset, which requires from/to nodemasks for attach to be globally scoped
    (though per-cpuset would work too) to persist from its pre_attach to
    attach_task and attach.
    
    This is a pre-patch for cgroup-procs-writable.patch.
    
    Signed-off-by: Ben Blum <bblum@andrew.cmu.edu>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Reviewed-by: Paul Menage <menage@google.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 5ac7ebc36dbb..1e6cde21fa3f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -467,12 +467,14 @@ struct cgroup_subsys {
 	int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			  struct task_struct *tsk, bool threadgroup);
+			  struct task_struct *tsk);
+	int (*can_attach_task)(struct cgroup *cgrp, struct task_struct *tsk);
 	void (*cancel_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			  struct task_struct *tsk, bool threadgroup);
+			      struct task_struct *tsk);
+	void (*pre_attach)(struct cgroup *cgrp);
+	void (*attach_task)(struct cgroup *cgrp, struct task_struct *tsk);
 	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			struct cgroup *old_cgrp, struct task_struct *tsk,
-			bool threadgroup);
+		       struct cgroup *old_cgrp, struct task_struct *tsk);
 	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);
 	void (*exit)(struct cgroup_subsys *ss, struct cgroup *cgrp,
 			struct cgroup *old_cgrp, struct task_struct *task);

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e654fa239916..5ac7ebc36dbb 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -240,7 +240,7 @@ struct cgroup {
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;
 
-	/* List of events which userspace want to recieve */
+	/* List of events which userspace want to receive */
 	struct list_head event_list;
 	spinlock_t event_list_lock;
 };

commit e5d1367f17ba6a6fed5fd8b74e4d5720923e0c25
Author: Stephane Eranian <eranian@google.com>
Date:   Mon Feb 14 11:20:01 2011 +0200

    perf: Add cgroup support
    
    This kernel patch adds the ability to filter monitoring based on
    container groups (cgroups). This is for use in per-cpu mode only.
    
    The cgroup to monitor is passed as a file descriptor in the pid
    argument to the syscall. The file descriptor must be opened to
    the cgroup name in the cgroup filesystem. For instance, if the
    cgroup name is foo and cgroupfs is mounted in /cgroup, then the
    file descriptor is opened to /cgroup/foo. Cgroup mode is
    activated by passing PERF_FLAG_PID_CGROUP in the flags argument
    to the syscall.
    
    For instance to measure in cgroup foo on CPU1 assuming
    cgroupfs is mounted under /cgroup:
    
    struct perf_event_attr attr;
    int cgroup_fd, fd;
    
    cgroup_fd = open("/cgroup/foo", O_RDONLY);
    fd = perf_event_open(&attr, cgroup_fd, 1, -1, PERF_FLAG_PID_CGROUP);
    close(cgroup_fd);
    
    Signed-off-by: Stephane Eranian <eranian@google.com>
    [ added perf_cgroup_{exit,attach} ]
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <4d590250.114ddf0a.689e.4482@mx.google.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 38117d937332..e654fa239916 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -627,6 +627,7 @@ bool css_is_ancestor(struct cgroup_subsys_state *cg,
 /* Get id and depth of css */
 unsigned short css_id(struct cgroup_subsys_state *css);
 unsigned short css_depth(struct cgroup_subsys_state *css);
+struct cgroup_subsys_state *cgroup_css_from_dir(struct file *f, int id);
 
 #else /* !CONFIG_CGROUPS */
 

commit d41d5a01631af821d3a3447e6613a316f5ee6c25
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Feb 7 17:02:20 2011 +0100

    cgroup: Fix cgroup_subsys::exit callback
    
    Make the ::exit method act like ::attach, it is after all very nearly
    the same thing.
    
    The bug had no effect on correctness - fixing it is an optimization for
    the scheduler. Also, later perf-cgroups patches rely on it.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Paul Menage <menage@google.com>
    LKML-Reference: <1297160655.13327.92.camel@laptop>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ce104e33cd22..38117d937332 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -474,7 +474,8 @@ struct cgroup_subsys {
 			struct cgroup *old_cgrp, struct task_struct *tsk,
 			bool threadgroup);
 	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);
-	void (*exit)(struct cgroup_subsys *ss, struct task_struct *task);
+	void (*exit)(struct cgroup_subsys *ss, struct cgroup *cgrp,
+			struct cgroup *old_cgrp, struct task_struct *task);
 	int (*populate)(struct cgroup_subsys *ss,
 			struct cgroup *cgrp);
 	void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp);

commit b595076a180a56d1bb170e6eceda6eb9d76f4cd3
Author: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
Date:   Mon Nov 1 15:38:34 2010 -0400

    tree-wide: fix comment/printk typos
    
    "gadget", "through", "command", "maintain", "maintain", "controller", "address",
    "between", "initiali[zs]e", "instead", "function", "select", "already",
    "equal", "access", "management", "hierarchy", "registration", "interest",
    "relative", "memory", "offset", "already",
    
    Signed-off-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ed4ba111bc8d..ce104e33cd22 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -564,7 +564,7 @@ struct cgroup_iter {
 /*
  * To iterate across the tasks in a cgroup:
  *
- * 1) call cgroup_iter_start to intialize an iterator
+ * 1) call cgroup_iter_start to initialize an iterator
  *
  * 2) call cgroup_iter_next() to retrieve member tasks until it
  *    returns NULL or until you want to end the iteration

commit 97978e6d1f2da0073416870410459694fbdbfd9b
Author: Daniel Lezcano <daniel.lezcano@free.fr>
Date:   Wed Oct 27 15:33:35 2010 -0700

    cgroup: add clone_children control file
    
    The ns_cgroup is a control group interacting with the namespaces.  When a
    new namespace is created, a corresponding cgroup is automatically created
    too.  The cgroup name is the pid of the process who did 'unshare' or the
    child of 'clone'.
    
    This cgroup is tied with the namespace because it prevents a process to
    escape the control group and use the post_clone callback, so the child
    cgroup inherits the values of the parent cgroup.
    
    Unfortunately, the more we use this cgroup and the more we are facing
    problems with it:
    
    (1) when a process unshares, the cgroup name may conflict with a
        previous cgroup with the same pid, so unshare or clone return -EEXIST
    
    (2) the cgroup creation is out of control because there may have an
        application creating several namespaces where the system will
        automatically create several cgroups in his back and let them on the
        cgroupfs (eg.  a vrf based on the network namespace).
    
    (3) the mix of (1) and (2) force an administrator to regularly check
        and clean these cgroups.
    
    This patchset removes the ns_cgroup by adding a new flag to the cgroup and
    the cgroupfs mount option.  It enables the copy of the parent cgroup when
    a child cgroup is created.  We can then safely remove the ns_cgroup as
    this flag brings a compatibility.  We have now to manually create and add
    the task to a cgroup, which is consistent with the cgroup framework.
    
    This patch:
    
    Sent as an answer to a previous thread around the ns_cgroup.
    
    https://lists.linux-foundation.org/pipermail/containers/2009-June/018627.html
    
    It adds a control file 'clone_children' for a cgroup.  This control file
    is a boolean specifying if the child cgroup should be a clone of the
    parent cgroup or not.  The default value is 'false'.
    
    This flag makes the child cgroup to call the post_clone callback of all
    the subsystem, if it is available.
    
    At present, the cpuset is the only one which had implemented the
    post_clone callback.
    
    The option can be set at mount time by specifying the 'clone_children'
    mount option.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@free.fr>
    Signed-off-by: Serge E. Hallyn <serge.hallyn@canonical.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: Paul Menage <menage@google.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Jamal Hadi Salim <hadi@cyberus.ca>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Acked-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 709dfb901d11..ed4ba111bc8d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -154,6 +154,10 @@ enum {
 	 * A thread in rmdir() is wating for this cgroup.
 	 */
 	CGRP_WAIT_ON_RMDIR,
+	/*
+	 * Clone cgroup values when creating a new child cgroup
+	 */
+	CGRP_CLONE_CHILDREN,
 };
 
 /* which pidlist file are we talking about? */

commit d4f8f217b8a5d5bd02af979650418dca4caec472
Merge: 2dfbf4dfbe47 773e3f93577f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Oct 7 09:43:11 2010 +0200

    Merge branch 'rcu/urgent' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-2.6-rcu into core/rcu

commit 31583bb0cf6cc40f2a468a4d2f3b9cbefd24f891
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Thu Sep 9 16:37:37 2010 -0700

    cgroups: fix API thinko
    
    Add cgroup_attach_task_all()
    
    The existing cgroup_attach_task_current_cg() API is called by a thread to
    attach another thread to all of its cgroups; this is unsuitable for cases
    where a privileged task wants to attach itself to the cgroups of a less
    privileged one, since the call must be made from the context of the target
    task.
    
    This patch adds a more generic cgroup_attach_task_all() API that allows
    both the source task and to-be-moved task to be specified.
    cgroup_attach_task_current_cg() becomes a specialization of the more
    generic new function.
    
    [menage@google.com: rewrote changelog]
    [akpm@linux-foundation.org: address reviewer comments]
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Tested-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Ben Blum <bblum@google.com>
    Cc: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ed3e92e41c6e..0c991023ee47 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -578,7 +578,12 @@ struct task_struct *cgroup_iter_next(struct cgroup *cgrp,
 void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *, struct task_struct *);
-int cgroup_attach_task_current_cg(struct task_struct *);
+int cgroup_attach_task_all(struct task_struct *from, struct task_struct *);
+
+static inline int cgroup_attach_task_current_cg(struct task_struct *tsk)
+{
+	return cgroup_attach_task_all(current, tsk);
+}
 
 /*
  * CSS ID is ID for cgroup_subsys_state structs under subsys. This only works
@@ -636,6 +641,11 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 }
 
 /* No cgroups - nothing to do */
+static inline int cgroup_attach_task_all(struct task_struct *from,
+					 struct task_struct *t)
+{
+	return 0;
+}
 static inline int cgroup_attach_task_current_cg(struct task_struct *t)
 {
 	return 0;

commit 2c392b8c3450ceb69ba1b93cb0cddb3998fb8cdc
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Feb 24 19:41:39 2010 +0100

    cgroups: __rcu annotations
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ed3e92e41c6e..3cb7d04308cd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -75,7 +75,7 @@ struct cgroup_subsys_state {
 
 	unsigned long flags;
 	/* ID for this css, if possible */
-	struct css_id *id;
+	struct css_id __rcu *id;
 };
 
 /* bits in struct cgroup_subsys_state flags field */
@@ -205,7 +205,7 @@ struct cgroup {
 	struct list_head children;	/* my children */
 
 	struct cgroup *parent;		/* my parent */
-	struct dentry *dentry;	  	/* cgroup fs entry, RCU protected */
+	struct dentry __rcu *dentry;	/* cgroup fs entry, RCU protected */
 
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];

commit 6ba74014c1ab0e37af7de6f64b4eccbbae3cb9e7
Merge: 5abd9ccced7a 3ff1c25927e3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 4 11:47:58 2010 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next-2.6: (1443 commits)
      phy/marvell: add 88ec048 support
      igb: Program MDICNFG register prior to PHY init
      e1000e: correct MAC-PHY interconnect register offset for 82579
      hso: Add new product ID
      can: Add driver for esd CAN-USB/2 device
      l2tp: fix export of header file for userspace
      can-raw: Fix skb_orphan_try handling
      Revert "net: remove zap_completion_queue"
      net: cleanup inclusion
      phy/marvell: add 88e1121 interface mode support
      u32: negative offset fix
      net: Fix a typo from "dev" to "ndev"
      igb: Use irq_synchronize per vector when using MSI-X
      ixgbevf: fix null pointer dereference due to filter being set for VLAN 0
      e1000e: Fix irq_synchronize in MSI-X case
      e1000e: register pm_qos request on hardware activation
      ip_fragment: fix subtracting PPPOE_SES_HLEN from mtu twice
      net: Add getsockopt support for TCP thin-streams
      cxgb4: update driver version
      cxgb4: add new PCI IDs
      ...
    
    Manually fix up conflicts in:
     - drivers/net/e1000e/netdev.c: due to pm_qos registration
       infrastructure changes
     - drivers/net/phy/marvell.c: conflict between adding 88ec048 support
       and cleaning up the IDs
     - drivers/net/wireless/ipw2x00/ipw2100.c: trivial ipw2100_pm_qos_req
       conflict (registration change vs marking it static)

commit d7926ee38f5c6e0bbebe712304f99a4c67e40f84
Author: Sridhar Samudrala <samudrala.sridhar@gmail.com>
Date:   Sun May 30 22:24:39 2010 +0200

    cgroups: Add an API to attach a task to current task's cgroup
    
    Add a new kernel API to attach a task to current task's cgroup
    in all the active hierarchies.
    
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Reviewed-by: Paul Menage <menage@google.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0c621604baa1..e0aa067d1b11 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -570,6 +570,7 @@ struct task_struct *cgroup_iter_next(struct cgroup *cgrp,
 void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *, struct task_struct *);
+int cgroup_attach_task_current_cg(struct task_struct *);
 
 /*
  * CSS ID is ID for cgroup_subsys_state structs under subsys. This only works
@@ -626,6 +627,12 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 	return -EINVAL;
 }
 
+/* No cgroups - nothing to do */
+static inline int cgroup_attach_task_current_cg(struct task_struct *t)
+{
+	return 0;
+}
+
 #endif /* !CONFIG_CGROUPS */
 
 #endif /* _LINUX_CGROUP_H */

commit dc61b1d65e353d638b2445f71fb8e5b5630f2415
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue Jun 8 11:40:42 2010 +0200

    sched: Fix PROVE_RCU vs cpu_cgroup
    
    PROVE_RCU has a few issues with the cpu_cgroup because the scheduler
    typically holds rq->lock around the css rcu derefs but the generic
    cgroup code doesn't (and can't) know about that lock.
    
    Provide means to add extra checks to the css dereference and use that
    in the scheduler to annotate its users.
    
    The addition of rq->lock to these checks is correct because the
    cgroup_subsys::attach() method takes the rq->lock for each task it
    moves, therefore by holding that lock, we ensure the task is pinned to
    the current cgroup and the RCU derefence is valid.
    
    That leaves one genuine race in __sched_setscheduler() where we used
    task_group() without holding any of the required locks and thus raced
    with the cgroup code. Solve this by moving the check under the
    appropriate lock.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    LKML-Reference: <new-submission>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0c621604baa1..e3d00fdb858d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -525,13 +525,21 @@ static inline struct cgroup_subsys_state *cgroup_subsys_state(
 	return cgrp->subsys[subsys_id];
 }
 
-static inline struct cgroup_subsys_state *task_subsys_state(
-	struct task_struct *task, int subsys_id)
+/*
+ * function to get the cgroup_subsys_state which allows for extra
+ * rcu_dereference_check() conditions, such as locks used during the
+ * cgroup_subsys::attach() methods.
+ */
+#define task_subsys_state_check(task, subsys_id, __c)			\
+	rcu_dereference_check(task->cgroups->subsys[subsys_id],		\
+			      rcu_read_lock_held() ||			\
+			      lockdep_is_held(&task->alloc_lock) ||	\
+			      cgroup_lock_is_held() || (__c))
+
+static inline struct cgroup_subsys_state *
+task_subsys_state(struct task_struct *task, int subsys_id)
 {
-	return rcu_dereference_check(task->cgroups->subsys[subsys_id],
-				     rcu_read_lock_held() ||
-				     lockdep_is_held(&task->alloc_lock) ||
-				     cgroup_lock_is_held());
+	return task_subsys_state_check(task, subsys_id, false);
 }
 
 static inline struct cgroup* task_cgroup(struct task_struct *task,

commit 907860ed381a31b0102f362df67c1c5cae6ef050
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Wed May 26 14:42:46 2010 -0700

    cgroups: make cftype.unregister_event() void-returning
    
    Since we are unable to handle an error returned by
    cftype.unregister_event() properly, let's make the callback
    void-returning.
    
    mem_cgroup_unregister_event() has been rewritten to be a "never fail"
    function.  On mem_cgroup_usage_register_event() we save old buffer for
    thresholds array and reuse it in mem_cgroup_usage_unregister_event() to
    avoid allocation.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Phil Carmody <ext-phil.2.carmody@nokia.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Cc: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8f78073d7caa..0c621604baa1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -397,7 +397,7 @@ struct cftype {
 	 * This callback must be implemented, if you want provide
 	 * notification functionality.
 	 */
-	int (*unregister_event)(struct cgroup *cgrp, struct cftype *cft,
+	void (*unregister_event)(struct cgroup *cgrp, struct cftype *cft,
 			struct eventfd_ctx *eventfd);
 };
 

commit 1ce7e4ff24fe338438bc7837e02780f202bf202b
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Apr 23 10:35:52 2010 +0800

    cgroup: Check task_lock in task_subsys_state()
    
    Expand task_subsys_state()'s rcu_dereference_check() to include the full
    locking rule as documented in Documentation/cgroups/cgroups.txt by adding
    a check for task->alloc_lock being held.
    
    This fixes an RCU false positive when resuming from suspend. The warning
    comes from freezer cgroup in cgroup_freezing_or_frozen().
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Matt Helsley <matthltc@us.ibm.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b8ad1ea99586..8f78073d7caa 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -530,6 +530,7 @@ static inline struct cgroup_subsys_state *task_subsys_state(
 {
 	return rcu_dereference_check(task->cgroups->subsys[subsys_id],
 				     rcu_read_lock_held() ||
+				     lockdep_is_held(&task->alloc_lock) ||
 				     cgroup_lock_is_held());
 }
 

commit a0a4db548edcce067c1201ef25cf2bc29f32dca4
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Wed Mar 10 15:22:34 2010 -0800

    cgroups: remove events before destroying subsystem state objects
    
    Events should be removed after rmdir of cgroup directory, but before
    destroying subsystem state objects.  Let's take reference to cgroup
    directory dentry to do that.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hioryu@jp.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Dan Malek <dan@embeddedalley.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b4f2201321cd..b8ad1ea99586 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -396,9 +396,6 @@ struct cftype {
 	 * closes the eventfd or on cgroup removing.
 	 * This callback must be implemented, if you want provide
 	 * notification functionality.
-	 *
-	 * Be careful. It can be called after destroy(), so you have
-	 * to keep all nesessary data, until all events are removed.
 	 */
 	int (*unregister_event)(struct cgroup *cgrp, struct cftype *cft,
 			struct eventfd_ctx *eventfd);

commit 0dea116876eefc9c7ca9c5d74fe665481e499fa3
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Wed Mar 10 15:22:20 2010 -0800

    cgroup: implement eventfd-based generic API for notifications
    
    This patchset introduces eventfd-based API for notifications in cgroups
    and implements memory notifications on top of it.
    
    It uses statistics in memory controler to track memory usage.
    
    Output of time(1) on building kernel on tmpfs:
    
    Root cgroup before changes:
            make -j2  506.37 user 60.93s system 193% cpu 4:52.77 total
    Non-root cgroup before changes:
            make -j2  507.14 user 62.66s system 193% cpu 4:54.74 total
    Root cgroup after changes (0 thresholds):
            make -j2  507.13 user 62.20s system 193% cpu 4:53.55 total
    Non-root cgroup after changes (0 thresholds):
            make -j2  507.70 user 64.20s system 193% cpu 4:55.70 total
    Root cgroup after changes (1 thresholds, never crossed):
            make -j2  506.97 user 62.20s system 193% cpu 4:53.90 total
    Non-root cgroup after changes (1 thresholds, never crossed):
            make -j2  507.55 user 64.08s system 193% cpu 4:55.63 total
    
    This patch:
    
    Introduce the write-only file "cgroup.event_control" in every cgroup.
    
    To register new notification handler you need:
    - create an eventfd;
    - open a control file to be monitored. Callbacks register_event() and
      unregister_event() must be defined for the control file;
    - write "<event_fd> <control_fd> <args>" to cgroup.event_control.
      Interpretation of args is defined by control file implementation;
    
    eventfd will be woken up by control file implementation or when the
    cgroup is removed.
    
    To unregister notification handler just close eventfd.
    
    If you need notification functionality for a control file you have to
    implement callbacks register_event() and unregister_event() in the
    struct cftype.
    
    [kamezawa.hiroyu@jp.fujitsu.com: Kconfig fix]
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Dan Malek <dan@embeddedalley.com>
    Cc: Vladislav Buzov <vbuzov@embeddedalley.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Cc: Alexander Shishkin <virtuoso@slind.org>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 2a59d3101e5d..b4f2201321cd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -235,6 +235,10 @@ struct cgroup {
 
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;
+
+	/* List of events which userspace want to recieve */
+	struct list_head event_list;
+	spinlock_t event_list_lock;
 };
 
 /*
@@ -378,6 +382,26 @@ struct cftype {
 	int (*trigger)(struct cgroup *cgrp, unsigned int event);
 
 	int (*release)(struct inode *inode, struct file *file);
+
+	/*
+	 * register_event() callback will be used to add new userspace
+	 * waiter for changes related to the cftype. Implement it if
+	 * you want to provide this functionality. Use eventfd_signal()
+	 * on eventfd to send notification to userspace.
+	 */
+	int (*register_event)(struct cgroup *cgrp, struct cftype *cft,
+			struct eventfd_ctx *eventfd, const char *args);
+	/*
+	 * unregister_event() callback will be called when userspace
+	 * closes the eventfd or on cgroup removing.
+	 * This callback must be implemented, if you want provide
+	 * notification functionality.
+	 *
+	 * Be careful. It can be called after destroy(), so you have
+	 * to keep all nesessary data, until all events are removed.
+	 */
+	int (*unregister_event)(struct cgroup *cgrp, struct cftype *cft,
+			struct eventfd_ctx *eventfd);
 };
 
 struct cgroup_scanner {

commit cf5d5941fda647fe3d2f2d00cf9e0245236a5f08
Author: Ben Blum <bblum@andrew.cmu.edu>
Date:   Wed Mar 10 15:22:09 2010 -0800

    cgroups: subsystem module unloading
    
    Provides support for unloading modular subsystems.
    
    This patch adds a new function cgroup_unload_subsys which is to be used
    for removing a loaded subsystem during module deletion.  Reference
    counting of the subsystems' modules is moved from once (at load time) to
    once per attached hierarchy (in parse_cgroupfs_options and
    rebind_subsystems) (i.e., 0 or 1).
    
    Signed-off-by: Ben Blum <bblum@andrew.cmu.edu>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 402ce477c47e..2a59d3101e5d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -38,6 +38,7 @@ extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 extern int cgroupstats_build(struct cgroupstats *stats,
 				struct dentry *dentry);
 extern int cgroup_load_subsys(struct cgroup_subsys *ss);
+extern void cgroup_unload_subsys(struct cgroup_subsys *ss);
 
 extern const struct file_operations proc_cgroup_operations;
 
@@ -271,7 +272,8 @@ struct css_set {
 	/*
 	 * Set of subsystem states, one for each subsystem. This array
 	 * is immutable after creation apart from the init_css_set
-	 * during subsystem registration (at boot time).
+	 * during subsystem registration (at boot time) and modular subsystem
+	 * loading/unloading.
 	 */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
 

commit e6a1105ba08b265023dd71a4174fb4a29ebc7083
Author: Ben Blum <bblum@andrew.cmu.edu>
Date:   Wed Mar 10 15:22:09 2010 -0800

    cgroups: subsystem module loading interface
    
    Add interface between cgroups subsystem management and module loading
    
    This patch implements rudimentary module-loading support for cgroups -
    namely, a cgroup_load_subsys (similar to cgroup_init_subsys) for use as a
    module initcall, and a struct module pointer in struct cgroup_subsys.
    
    Several functions that might be wanted by modules have had EXPORT_SYMBOL
    added to them, but it's unclear exactly which functions want it and which
    won't.
    
    Signed-off-by: Ben Blum <bblum@andrew.cmu.edu>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 28319a9fe569..402ce477c47e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -37,6 +37,7 @@ extern void cgroup_post_fork(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 extern int cgroupstats_build(struct cgroupstats *stats,
 				struct dentry *dentry);
+extern int cgroup_load_subsys(struct cgroup_subsys *ss);
 
 extern const struct file_operations proc_cgroup_operations;
 
@@ -486,6 +487,9 @@ struct cgroup_subsys {
 	/* used when use_id == true */
 	struct idr idr;
 	spinlock_t id_lock;
+
+	/* should be defined only by modular subsystems */
+	struct module *module;
 };
 
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _subsys;

commit aae8aab40367036931608fdaf9e2dc568b516f19
Author: Ben Blum <bblum@andrew.cmu.edu>
Date:   Wed Mar 10 15:22:07 2010 -0800

    cgroups: revamp subsys array
    
    This patch series provides the ability for cgroup subsystems to be
    compiled as modules both within and outside the kernel tree.  This is
    mainly useful for classifiers and subsystems that hook into components
    that are already modules.  cls_cgroup and blkio-cgroup serve as the
    example use cases for this feature.
    
    It provides an interface cgroup_load_subsys() and cgroup_unload_subsys()
    which modular subsystems can use to register and depart during runtime.
    The net_cls classifier subsystem serves as the example for a subsystem
    which can be converted into a module using these changes.
    
    Patch #1 sets up the subsys[] array so its contents can be dynamic as
    modules appear and (eventually) disappear.  Iterations over the array are
    modified to handle when subsystems are absent, and the dynamic section of
    the array is protected by cgroup_mutex.
    
    Patch #2 implements an interface for modules to load subsystems, called
    cgroup_load_subsys, similar to cgroup_init_subsys, and adds a module
    pointer in struct cgroup_subsys.
    
    Patch #3 adds a mechanism for unloading modular subsystems, which includes
    a more advanced rework of the rudimentary reference counting introduced in
    patch 2.
    
    Patch #4 modifies the net_cls subsystem, which already had some module
    declarations, to be configurable as a module, which also serves as a
    simple proof-of-concept.
    
    Part of implementing patches 2 and 4 involved updating css pointers in
    each css_set when the module appears or leaves.  In doing this, it was
    discovered that css_sets always remain linked to the dummy cgroup,
    regardless of whether or not any subsystems are actually bound to it
    (i.e., not mounted on an actual hierarchy).  The subsystem loading and
    unloading code therefore should keep in mind the special cases where the
    added subsystem is the only one in the dummy cgroup (and therefore all
    css_sets need to be linked back into it) and where the removed subsys was
    the only one in the dummy cgroup (and therefore all css_sets should be
    unlinked from it) - however, as all css_sets always stay attached to the
    dummy cgroup anyway, these cases are ignored.  Any fix that addresses this
    issue should also make sure these cases are addressed in the subsystem
    loading and unloading code.
    
    This patch:
    
    Make subsys[] able to be dynamically populated to support modular
    subsystems
    
    This patch reworks the way the subsys[] array is used so that subsystems
    can register themselves after boot time, and enables the internals of
    cgroups to be able to handle when subsystems are not present or may
    appear/disappear.
    
    Signed-off-by: Ben Blum <bblum@andrew.cmu.edu>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 14160b5b693f..28319a9fe569 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -40,13 +40,19 @@ extern int cgroupstats_build(struct cgroupstats *stats,
 
 extern const struct file_operations proc_cgroup_operations;
 
-/* Define the enumeration of all cgroup subsystems */
+/* Define the enumeration of all builtin cgroup subsystems */
 #define SUBSYS(_x) _x ## _subsys_id,
 enum cgroup_subsys_id {
 #include <linux/cgroup_subsys.h>
-	CGROUP_SUBSYS_COUNT
+	CGROUP_BUILTIN_SUBSYS_COUNT
 };
 #undef SUBSYS
+/*
+ * This define indicates the maximum number of subsystems that can be loaded
+ * at once. We limit to this many since cgroupfs_root has subsys_bits to keep
+ * track of all of them.
+ */
+#define CGROUP_SUBSYS_COUNT (BITS_PER_BYTE*sizeof(unsigned long))
 
 /* Per-subsystem/per-cgroup state maintained by the system. */
 struct cgroup_subsys_state {

commit d7b9fff711d5e8db8c844161c684017e556c38a0
Author: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
Date:   Wed Mar 10 15:22:05 2010 -0800

    cgroup: introduce coalesce css_get() and css_put()
    
    Current css_get() and css_put() increment/decrement css->refcnt one by
    one.
    
    This patch add a new function __css_get(), which takes "count" as a arg
    and increment the css->refcnt by "count".  And this patch also add a new
    arg("count") to __css_put() and change the function to decrement the
    css->refcnt by "count".
    
    These coalesce version of __css_get()/__css_put() will be used to improve
    performance of memcg's moving charge feature later, where instead of
    calling css_get()/css_put() repeatedly, these new functions will be used.
    
    No change is needed for current users of css_get()/css_put().
    
    Signed-off-by: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Acked-by: Paul Menage <menage@google.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d08cfe7e12e5..14160b5b693f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -76,6 +76,12 @@ enum {
 	CSS_REMOVED, /* This CSS is dead */
 };
 
+/* Caller must verify that the css is not for root cgroup */
+static inline void __css_get(struct cgroup_subsys_state *css, int count)
+{
+	atomic_add(count, &css->refcnt);
+}
+
 /*
  * Call css_get() to hold a reference on the css; it can be used
  * for a reference obtained via:
@@ -87,7 +93,7 @@ static inline void css_get(struct cgroup_subsys_state *css)
 {
 	/* We don't need to reference count the root state */
 	if (!test_bit(CSS_ROOT, &css->flags))
-		atomic_inc(&css->refcnt);
+		__css_get(css, 1);
 }
 
 static inline bool css_is_removed(struct cgroup_subsys_state *css)
@@ -118,11 +124,11 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
  * css_get() or css_tryget()
  */
 
-extern void __css_put(struct cgroup_subsys_state *css);
+extern void __css_put(struct cgroup_subsys_state *css, int count);
 static inline void css_put(struct cgroup_subsys_state *css)
 {
 	if (!test_bit(CSS_ROOT, &css->flags))
-		__css_put(css);
+		__css_put(css, 1);
 }
 
 /* bits in struct cgroup flags field */

commit 2468c7234b366eeb799ee0648cb58f9cba394a54
Author: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
Date:   Wed Mar 10 15:22:03 2010 -0800

    cgroup: introduce cancel_attach()
    
    Add cancel_attach() operation to struct cgroup_subsys.  cancel_attach()
    can be used when can_attach() operation prepares something for the subsys,
    but we should rollback what can_attach() operation has prepared if attach
    task fails after we've succeeded in can_attach().
    
    Signed-off-by: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Reviewed-by: Paul Menage <menage@google.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c9bbcb2a75ae..d08cfe7e12e5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -428,6 +428,8 @@ struct cgroup_subsys {
 	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
 			  struct task_struct *tsk, bool threadgroup);
+	void (*cancel_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
+			  struct task_struct *tsk, bool threadgroup);
 	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
 			struct cgroup *old_cgrp, struct task_struct *tsk,
 			bool threadgroup);

commit d11c563dd20ff35da5652c3e1c989d9e10e1d6d0
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Feb 22 17:04:50 2010 -0800

    sched: Use lockdep-based checking on rcu_dereference()
    
    Update the rcu_dereference() usages to take advantage of the new
    lockdep-based checking.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    LKML-Reference: <1266887105-1528-6-git-send-email-paulmck@linux.vnet.ibm.com>
    [ -v2: fix allmodconfig missing symbol export build failure on x86 ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0008dee66514..c9bbcb2a75ae 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -28,6 +28,7 @@ struct css_id;
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
 extern void cgroup_lock(void);
+extern int cgroup_lock_is_held(void);
 extern bool cgroup_lock_live_group(struct cgroup *cgrp);
 extern void cgroup_unlock(void);
 extern void cgroup_fork(struct task_struct *p);
@@ -486,7 +487,9 @@ static inline struct cgroup_subsys_state *cgroup_subsys_state(
 static inline struct cgroup_subsys_state *task_subsys_state(
 	struct task_struct *task, int subsys_id)
 {
-	return rcu_dereference(task->cgroups->subsys[subsys_id]);
+	return rcu_dereference_check(task->cgroups->subsys[subsys_id],
+				     rcu_read_lock_held() ||
+				     cgroup_lock_is_held());
 }
 
 static inline struct cgroup* task_cgroup(struct task_struct *task,

commit 828c09509b9695271bcbdc53e9fc9a6a737148d2
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Thu Oct 1 15:43:56 2009 -0700

    const: constify remaining file_operations
    
    [akpm@linux-foundation.org: fix KVM]
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b62bb9294d0c..0008dee66514 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -37,7 +37,7 @@ extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 extern int cgroupstats_build(struct cgroupstats *stats,
 				struct dentry *dentry);
 
-extern struct file_operations proc_cgroup_operations;
+extern const struct file_operations proc_cgroup_operations;
 
 /* Define the enumeration of all cgroup subsystems */
 #define SUBSYS(_x) _x ## _subsys_id,

commit be367d09927023d081f9199665c8500f69f14d22
Author: Ben Blum <bblum@google.com>
Date:   Wed Sep 23 15:56:31 2009 -0700

    cgroups: let ss->can_attach and ss->attach do whole threadgroups at a time
    
    Alter the ss->can_attach and ss->attach functions to be able to deal with
    a whole threadgroup at a time, for use in cgroup_attach_proc.  (This is a
    pre-patch to cgroup-procs-writable.patch.)
    
    Currently, new mode of the attach function can only tell the subsystem
    about the old cgroup of the threadgroup leader.  No subsystem currently
    needs that information for each thread that's being moved, but if one were
    to be added (for example, one that counts tasks within a group) this bit
    would need to be reworked a bit to tell the subsystem the right
    information.
    
    [hidave.darkstar@gmail.com: fix build]
    Signed-off-by: Ben Blum <bblum@google.com>
    Signed-off-by: Paul Menage <menage@google.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Reviewed-by: Matt Helsley <matthltc@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Dave Young <hidave.darkstar@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 3ac78a2f4b5a..b62bb9294d0c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -425,10 +425,11 @@ struct cgroup_subsys {
 						  struct cgroup *cgrp);
 	int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
-	int (*can_attach)(struct cgroup_subsys *ss,
-			  struct cgroup *cgrp, struct task_struct *tsk);
+	int (*can_attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
+			  struct task_struct *tsk, bool threadgroup);
 	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			struct cgroup *old_cgrp, struct task_struct *tsk);
+			struct cgroup *old_cgrp, struct task_struct *tsk,
+			bool threadgroup);
 	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);
 	void (*exit)(struct cgroup_subsys *ss, struct task_struct *task);
 	int (*populate)(struct cgroup_subsys *ss,

commit c378369d8b4fa516ff2b1e79c3eded4e0e955ebb
Author: Ben Blum <bblum@google.com>
Date:   Wed Sep 23 15:56:29 2009 -0700

    cgroups: change css_set freeing mechanism to be under RCU
    
    Changes css_set freeing mechanism to be under RCU
    
    This is a prepatch for making the procs file writable. In order to free the
    old css_sets for each task to be moved as they're being moved, the freeing
    mechanism must be RCU-protected, or else we would have to have a call to
    synchronize_rcu() for each task before freeing its old css_set.
    
    Signed-off-by: Ben Blum <bblum@google.com>
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 88e863460726..3ac78a2f4b5a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -260,6 +260,9 @@ struct css_set {
 	 * during subsystem registration (at boot time).
 	 */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
+
+	/* For RCU-protected deletion */
+	struct rcu_head rcu_head;
 };
 
 /*

commit 72a8cb30d10d4041c455a7054607a7d519167c87
Author: Ben Blum <bblum@google.com>
Date:   Wed Sep 23 15:56:27 2009 -0700

    cgroups: ensure correct concurrent opening/reading of pidlists across pid namespaces
    
    Previously there was the problem in which two processes from different pid
    namespaces reading the tasks or procs file could result in one process
    seeing results from the other's namespace.  Rather than one pidlist for
    each file in a cgroup, we now keep a list of pidlists keyed by namespace
    and file type (tasks versus procs) in which entries are placed on demand.
    Each pidlist has its own lock, and that the pidlists themselves are passed
    around in the seq_file's private pointer means we don't have to touch the
    cgroup or its master list except when creating and destroying entries.
    
    Signed-off-by: Ben Blum <bblum@google.com>
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 2357733a0a80..88e863460726 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -141,15 +141,36 @@ enum {
 	CGRP_WAIT_ON_RMDIR,
 };
 
+/* which pidlist file are we talking about? */
+enum cgroup_filetype {
+	CGROUP_FILE_PROCS,
+	CGROUP_FILE_TASKS,
+};
+
+/*
+ * A pidlist is a list of pids that virtually represents the contents of one
+ * of the cgroup files ("procs" or "tasks"). We keep a list of such pidlists,
+ * a pair (one each for procs, tasks) for each pid namespace that's relevant
+ * to the cgroup.
+ */
 struct cgroup_pidlist {
-	/* protects the other fields */
-	struct rw_semaphore mutex;
+	/*
+	 * used to find which pidlist is wanted. doesn't change as long as
+	 * this particular list stays in the list.
+	 */
+	struct { enum cgroup_filetype type; struct pid_namespace *ns; } key;
 	/* array of xids */
 	pid_t *list;
 	/* how many elements the above list has */
 	int length;
 	/* how many files are using the current array */
 	int use_count;
+	/* each of these stored in a list by its cgroup */
+	struct list_head links;
+	/* pointer to the cgroup we belong to, for list removal purposes */
+	struct cgroup *owner;
+	/* protects the other fields */
+	struct rw_semaphore mutex;
 };
 
 struct cgroup {
@@ -190,9 +211,12 @@ struct cgroup {
 	 */
 	struct list_head release_list;
 
-	/* we will have two separate pidlists, one for pids (the tasks file)
-	 * and one for tgids (the procs file). */
-	struct cgroup_pidlist tasks, procs;
+	/*
+	 * list of pidlists, up to two for each namespace (one for procs, one
+	 * for tasks); created on demand.
+	 */
+	struct list_head pidlists;
+	struct mutex pidlist_mutex;
 
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;

commit 102a775e3647628727ae83a9a6abf0564c3ca7cb
Author: Ben Blum <bblum@google.com>
Date:   Wed Sep 23 15:56:26 2009 -0700

    cgroups: add a read-only "procs" file similar to "tasks" that shows only unique tgids
    
    struct cgroup used to have a bunch of fields for keeping track of the
    pidlist for the tasks file.  Those are now separated into a new struct
    cgroup_pidlist, of which two are had, one for procs and one for tasks.
    The way the seq_file operations are set up is changed so that just the
    pidlist struct gets passed around as the private data.
    
    Interface example: Suppose a multithreaded process has pid 1000 and other
    threads with ids 1001, 1002, 1003:
    $ cat tasks
    1000
    1001
    1002
    1003
    $ cat cgroup.procs
    1000
    $
    
    Signed-off-by: Ben Blum <bblum@google.com>
    Signed-off-by: Paul Menage <menage@google.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c833d6f23672..2357733a0a80 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -141,6 +141,17 @@ enum {
 	CGRP_WAIT_ON_RMDIR,
 };
 
+struct cgroup_pidlist {
+	/* protects the other fields */
+	struct rw_semaphore mutex;
+	/* array of xids */
+	pid_t *list;
+	/* how many elements the above list has */
+	int length;
+	/* how many files are using the current array */
+	int use_count;
+};
+
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
@@ -179,14 +190,9 @@ struct cgroup {
 	 */
 	struct list_head release_list;
 
-	/* pids_mutex protects the fields below */
-	struct rw_semaphore pids_mutex;
-	/* Array of process ids in the cgroup */
-	pid_t *tasks_pids;
-	/* How many files are using the current tasks_pids array */
-	int pids_use_count;
-	/* Length of the current tasks_pids array */
-	int pids_length;
+	/* we will have two separate pidlists, one for pids (the tasks file)
+	 * and one for tgids (the procs file). */
+	struct cgroup_pidlist tasks, procs;
 
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;

commit 8f3ff20862cfcb85500a2bb55ee64622bd59fd0c
Author: Paul Menage <menage@google.com>
Date:   Wed Sep 23 15:56:25 2009 -0700

    cgroups: revert "cgroups: fix pid namespace bug"
    
    The following series adds a "cgroup.procs" file to each cgroup that
    reports unique tgids rather than pids, and allows all threads in a
    threadgroup to be atomically moved to a new cgroup.
    
    The subsystem "attach" interface is modified to support attaching whole
    threadgroups at a time, which could introduce potential problems if any
    subsystem were to need to access the old cgroup of every thread being
    moved.  The attach interface may need to be revised if this becomes the
    case.
    
    Also added is functionality for read/write locking all CLONE_THREAD
    fork()ing within a threadgroup, by means of an rwsem that lives in the
    sighand_struct, for per-threadgroup-ness and also for sharing a cacheline
    with the sighand's atomic count.  This scheme should introduce no extra
    overhead in the fork path when there's no contention.
    
    The final patch reveals potential for a race when forking before a
    subsystem's attach function is called - one potential solution in case any
    subsystem has this problem is to hang on to the group's fork mutex through
    the attach() calls, though no subsystem yet demonstrates need for an
    extended critical section.
    
    This patch:
    
    Revert
    
    commit 096b7fe012d66ed55e98bc8022405ede0cc80e96
    Author:     Li Zefan <lizf@cn.fujitsu.com>
    AuthorDate: Wed Jul 29 15:04:04 2009 -0700
    Commit:     Linus Torvalds <torvalds@linux-foundation.org>
    CommitDate: Wed Jul 29 19:10:35 2009 -0700
    
        cgroups: fix pid namespace bug
    
    This is in preparation for some clashing cgroups changes that subsume the
    original commit's functionaliy.
    
    The original commit fixed a pid namespace bug which Ben Blum fixed
    independently (in the same way, but with different code) as part of a
    series of patches.  I played around with trying to reconcile Ben's patch
    series with Li's patch, but concluded that it was simpler to just revert
    Li's, given that Ben's patch series contained essentially the same fix.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 90bba9e62286..c833d6f23672 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -179,11 +179,14 @@ struct cgroup {
 	 */
 	struct list_head release_list;
 
-	/* pids_mutex protects pids_list and cached pid arrays. */
+	/* pids_mutex protects the fields below */
 	struct rw_semaphore pids_mutex;
-
-	/* Linked list of struct cgroup_pids */
-	struct list_head pids_list;
+	/* Array of process ids in the cgroup */
+	pid_t *tasks_pids;
+	/* How many files are using the current tasks_pids array */
+	int pids_use_count;
+	/* Length of the current tasks_pids array */
+	int pids_length;
 
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;

commit 887032670d47366a8c8f25396ea7c14b7b2cc620
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Wed Jul 29 15:04:06 2009 -0700

    cgroup avoid permanent sleep at rmdir
    
    After commit ec64f51545fffbc4cb968f0cea56341a4b07e85a ("cgroup: fix
    frequent -EBUSY at rmdir"), cgroup's rmdir (especially against memcg)
    doesn't return -EBUSY by temporary ref counts.  That commit expects all
    refs after pre_destroy() is temporary but...it wasn't.  Then, rmdir can
    wait permanently.  This patch tries to fix that and change followings.
    
     - set CGRP_WAIT_ON_RMDIR flag before pre_destroy().
     - clear CGRP_WAIT_ON_RMDIR flag when the subsys finds racy case.
       if there are sleeping ones, wakes them up.
     - rmdir() sleeps only when CGRP_WAIT_ON_RMDIR flag is set.
    
    Tested-by: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Reported-by: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Reviewed-by: Paul Menage <menage@google.com>
    Acked-by: Balbir Sigh <balbir@linux.vnet.ibm.com>
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 20411d2876f8..90bba9e62286 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -362,6 +362,23 @@ int cgroup_task_count(const struct cgroup *cgrp);
 /* Return true if cgrp is a descendant of the task's cgroup */
 int cgroup_is_descendant(const struct cgroup *cgrp, struct task_struct *task);
 
+/*
+ * When the subsys has to access css and may add permanent refcnt to css,
+ * it should take care of racy conditions with rmdir(). Following set of
+ * functions, is for stop/restart rmdir if necessary.
+ * Because these will call css_get/put, "css" should be alive css.
+ *
+ *  cgroup_exclude_rmdir();
+ *  ...do some jobs which may access arbitrary empty cgroup
+ *  cgroup_release_and_wakeup_rmdir();
+ *
+ *  When someone removes a cgroup while cgroup_exclude_rmdir() holds it,
+ *  it sleeps and cgroup_release_and_wakeup_rmdir() will wake him up.
+ */
+
+void cgroup_exclude_rmdir(struct cgroup_subsys_state *css);
+void cgroup_release_and_wakeup_rmdir(struct cgroup_subsys_state *css);
+
 /*
  * Control Group subsystem type.
  * See Documentation/cgroups/cgroups.txt for details

commit 096b7fe012d66ed55e98bc8022405ede0cc80e96
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Jul 29 15:04:04 2009 -0700

    cgroups: fix pid namespace bug
    
    The bug was introduced by commit cc31edceee04a7b87f2be48f9489ebb72d264844
    ("cgroups: convert tasks file to use a seq_file with shared pid array").
    
    We cache a pid array for all threads that are opening the same "tasks"
    file, but the pids in the array are always from the namespace of the
    last process that opened the file, so all other threads will read pids
    from that namespace instead of their own namespaces.
    
    To fix it, we maintain a list of pid arrays, which is keyed by pid_ns.
    The list will be of length 1 at most time.
    
    Reported-by: Paul Menage <menage@google.com>
    Idea-by: Paul Menage <menage@google.com>
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Reviewed-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 665fa70e4094..20411d2876f8 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -179,14 +179,11 @@ struct cgroup {
 	 */
 	struct list_head release_list;
 
-	/* pids_mutex protects the fields below */
+	/* pids_mutex protects pids_list and cached pid arrays. */
 	struct rw_semaphore pids_mutex;
-	/* Array of process ids in the cgroup */
-	pid_t *tasks_pids;
-	/* How many files are using the current tasks_pids array */
-	int pids_use_count;
-	/* Length of the current tasks_pids array */
-	int pids_length;
+
+	/* Linked list of struct cgroup_pids */
+	struct list_head pids_list;
 
 	/* For RCU-protected deletion */
 	struct rcu_head rcu_head;

commit 811158b147a503fbdf9773224004ffd32002d1fe
Merge: 4e76c5ccd5ac b26e0ed4936b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 3 15:24:35 2009 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (28 commits)
      trivial: Update my email address
      trivial: NULL noise: drivers/mtd/tests/mtd_*test.c
      trivial: NULL noise: drivers/media/dvb/frontends/drx397xD_fw.h
      trivial: Fix misspelling of "Celsius".
      trivial: remove unused variable 'path' in alloc_file()
      trivial: fix a pdlfush -> pdflush typo in comment
      trivial: jbd header comment typo fix for JBD_PARANOID_IOFAIL
      trivial: wusb: Storage class should be before const qualifier
      trivial: drivers/char/bsr.c: Storage class should be before const qualifier
      trivial: h8300: Storage class should be before const qualifier
      trivial: fix where cgroup documentation is not correctly referred to
      trivial: Give the right path in Documentation example
      trivial: MTD: remove EOL from MODULE_DESCRIPTION
      trivial: Fix typo in bio_split()'s documentation
      trivial: PWM: fix of #endif comment
      trivial: fix typos/grammar errors in Kconfig texts
      trivial: Fix misspelling of firmware
      trivial: cgroups: documentation typo and spelling corrections
      trivial: Update contact info for Jochen Hein
      trivial: fix typo "resgister" -> "register"
      ...

commit bd1a8ab73edd449fecda633449cc277b856ad4f5
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Thu Apr 2 16:57:50 2009 -0700

    cgroups: add 'data' field to struct cgroup_scanner
    
    We need to pass some data to test_task() or process_task() in some cases.
    Will be used later.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 43763bd772b9..4316a546beb5 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -337,6 +337,7 @@ struct cgroup_scanner {
 	void (*process_task)(struct task_struct *p,
 			struct cgroup_scanner *scan);
 	struct ptr_heap *heap;
+	void *data;
 };
 
 /*

commit 0b7f569e45bb6be142d87017030669a6a7d327a1
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Thu Apr 2 16:57:38 2009 -0700

    memcg: fix OOM killer under memcg
    
    This patch tries to fix OOM Killer problems caused by hierarchy.
    Now, memcg itself has OOM KILL function (in oom_kill.c) and tries to
    kill a task in memcg.
    
    But, when hierarchy is used, it's broken and correct task cannot
    be killed. For example, in following cgroup
    
            /groupA/        hierarchy=1, limit=1G,
                    01      nolimit
                    02      nolimit
    All tasks' memory usage under /groupA, /groupA/01, groupA/02 is limited to
    groupA's 1Gbytes but OOM Killer just kills tasks in groupA.
    
    This patch provides makes the bad process be selected from all tasks
    under hierarchy. BTW, currently, oom_jiffies is updated against groupA
    in above case. oom_jiffies of tree should be updated.
    
    To see how oom_jiffies is used, please check mem_cgroup_oom_called()
    callers.
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: const fix]
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b2816fba5306..43763bd772b9 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -503,7 +503,7 @@ struct cgroup_subsys_state *css_get_next(struct cgroup_subsys *ss, int id,
 
 /* Returns true if root is ancestor of cg */
 bool css_is_ancestor(struct cgroup_subsys_state *cg,
-		     struct cgroup_subsys_state *root);
+		     const struct cgroup_subsys_state *root);
 
 /* Get id and depth of css */
 unsigned short css_id(struct cgroup_subsys_state *css);

commit 099fca3225b39f7a3ed853036038054172b55581
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Thu Apr 2 16:57:29 2009 -0700

    cgroups: show correct file mode
    
    We have some read-only files and write-only files, but currently they are
    all set to 0644, which is counter-intuitive and cause trouble for some
    cgroup tools like libcgroup.
    
    This patch adds 'mode' to struct cftype to allow cgroup subsys to set it's
    own files' file mode, and for the most cases cft->mode can be default to 0
    and cgroup will figure out proper mode.
    
    Acked-by: Paul Menage <menage@google.com>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7d824b80b3d7..b2816fba5306 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -258,6 +258,11 @@ struct cftype {
 	 */
 	char name[MAX_CFTYPE_NAME];
 	int private;
+	/*
+	 * If not 0, file mode is set to this value, otherwise it will
+	 * be figured out automatically
+	 */
+	mode_t mode;
 
 	/*
 	 * If non-zero, defines the maximum length of string that can

commit ec64f51545fffbc4cb968f0cea56341a4b07e85a
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Thu Apr 2 16:57:26 2009 -0700

    cgroup: fix frequent -EBUSY at rmdir
    
    In following situation, with memory subsystem,
    
            /groupA use_hierarchy==1
                    /01 some tasks
                    /02 some tasks
                    /03 some tasks
                    /04 empty
    
    When tasks under 01/02/03 hit limit on /groupA, hierarchical reclaim
    is triggered and the kernel walks tree under groupA. In this case,
    rmdir /groupA/04 fails with -EBUSY frequently because of temporal
    refcnt from the kernel.
    
    In general. cgroup can be rmdir'd if there are no children groups and
    no tasks. Frequent fails of rmdir() is not useful to users.
    (And the reason for -EBUSY is unknown to users.....in most cases)
    
    This patch tries to modify above behavior, by
            - retries if css_refcnt is got by someone.
            - add "return value" to pre_destroy() and allows subsystem to
              say "we're really busy!"
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9a23bb098205..7d824b80b3d7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -135,6 +135,10 @@ enum {
 	CGRP_RELEASABLE,
 	/* Control Group requires release notifications to userspace */
 	CGRP_NOTIFY_ON_RELEASE,
+	/*
+	 * A thread in rmdir() is wating for this cgroup.
+	 */
+	CGRP_WAIT_ON_RMDIR,
 };
 
 struct cgroup {
@@ -360,7 +364,7 @@ int cgroup_is_descendant(const struct cgroup *cgrp, struct task_struct *task);
 struct cgroup_subsys {
 	struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss,
 						  struct cgroup *cgrp);
-	void (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
+	int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup_subsys *ss,
 			  struct cgroup *cgrp, struct task_struct *tsk);

commit 38460b48d06440de46b34cb778bd6c4855030754
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Thu Apr 2 16:57:25 2009 -0700

    cgroup: CSS ID support
    
    Patch for Per-CSS(Cgroup Subsys State) ID and private hierarchy code.
    
    This patch attaches unique ID to each css and provides following.
    
     - css_lookup(subsys, id)
       returns pointer to struct cgroup_subysys_state of id.
     - css_get_next(subsys, id, rootid, depth, foundid)
       returns the next css under "root" by scanning
    
    When cgroup_subsys->use_id is set, an id for css is maintained.
    
    The cgroup framework only parepares
            - css_id of root css for subsys
            - id is automatically attached at creation of css.
            - id is *not* freed automatically. Because the cgroup framework
              don't know lifetime of cgroup_subsys_state.
              free_css_id() function is provided. This must be called by subsys.
    
    There are several reasons to develop this.
            - Saving space .... For example, memcg's swap_cgroup is array of
              pointers to cgroup. But it is not necessary to be very fast.
              By replacing pointers(8bytes per ent) to ID (2byes per ent), we can
              reduce much amount of memory usage.
    
            - Scanning without lock.
              CSS_ID provides "scan id under this ROOT" function. By this, scanning
              css under root can be written without locks.
              ex)
              do {
                    rcu_read_lock();
                    next = cgroup_get_next(subsys, id, root, &found);
                    /* check sanity of next here */
                    css_tryget();
                    rcu_read_unlock();
                    id = found + 1
             } while(...)
    
    Characteristics:
            - Each css has unique ID under subsys.
            - Lifetime of ID is controlled by subsys.
            - css ID contains "ID" and "Depth in hierarchy" and stack of hierarchy
            - Allowed ID is 1-65535, ID 0 is UNUSED ID.
    
    Design Choices:
            - scan-by-ID v.s. scan-by-tree-walk.
              As /proc's pid scan does, scan-by-ID is robust when scanning is done
              by following kind of routine.
              scan -> rest a while(release a lock) -> conitunue from interrupted
              memcg's hierarchical reclaim does this.
    
            - When subsys->use_id is set, # of css in the system is limited to
              65535.
    
    [bharata@linux.vnet.ibm.com: remove rcu_read_lock() from css_get_next()]
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Signed-off-by: Bharata B Rao <bharata@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 788c4964c142..9a23bb098205 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -15,6 +15,7 @@
 #include <linux/cgroupstats.h>
 #include <linux/prio_heap.h>
 #include <linux/rwsem.h>
+#include <linux/idr.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -22,6 +23,7 @@ struct cgroupfs_root;
 struct cgroup_subsys;
 struct inode;
 struct cgroup;
+struct css_id;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
@@ -63,6 +65,8 @@ struct cgroup_subsys_state {
 	atomic_t refcnt;
 
 	unsigned long flags;
+	/* ID for this css, if possible */
+	struct css_id *id;
 };
 
 /* bits in struct cgroup_subsys_state flags field */
@@ -373,6 +377,11 @@ struct cgroup_subsys {
 	int active;
 	int disabled;
 	int early_init;
+	/*
+	 * True if this subsys uses ID. ID is not available before cgroup_init()
+	 * (not available in early_init time.)
+	 */
+	bool use_id;
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 
@@ -395,6 +404,9 @@ struct cgroup_subsys {
 	 */
 	struct cgroupfs_root *root;
 	struct list_head sibling;
+	/* used when use_id == true */
+	struct idr idr;
+	spinlock_t id_lock;
 };
 
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _subsys;
@@ -450,6 +462,44 @@ void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *, struct task_struct *);
 
+/*
+ * CSS ID is ID for cgroup_subsys_state structs under subsys. This only works
+ * if cgroup_subsys.use_id == true. It can be used for looking up and scanning.
+ * CSS ID is assigned at cgroup allocation (create) automatically
+ * and removed when subsys calls free_css_id() function. This is because
+ * the lifetime of cgroup_subsys_state is subsys's matter.
+ *
+ * Looking up and scanning function should be called under rcu_read_lock().
+ * Taking cgroup_mutex()/hierarchy_mutex() is not necessary for following calls.
+ * But the css returned by this routine can be "not populated yet" or "being
+ * destroyed". The caller should check css and cgroup's status.
+ */
+
+/*
+ * Typically Called at ->destroy(), or somewhere the subsys frees
+ * cgroup_subsys_state.
+ */
+void free_css_id(struct cgroup_subsys *ss, struct cgroup_subsys_state *css);
+
+/* Find a cgroup_subsys_state which has given ID */
+
+struct cgroup_subsys_state *css_lookup(struct cgroup_subsys *ss, int id);
+
+/*
+ * Get a cgroup whose id is greater than or equal to id under tree of root.
+ * Returning a cgroup_subsys_state or NULL.
+ */
+struct cgroup_subsys_state *css_get_next(struct cgroup_subsys *ss, int id,
+		struct cgroup_subsys_state *root, int *foundid);
+
+/* Returns true if root is ancestor of cg */
+bool css_is_ancestor(struct cgroup_subsys_state *cg,
+		     struct cgroup_subsys_state *root);
+
+/* Get id and depth of css */
+unsigned short css_id(struct cgroup_subsys_state *css);
+unsigned short css_depth(struct cgroup_subsys_state *css);
+
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }

commit 313e924c0852943e67335fad9d2608701f0dfe8e
Author: Grzegorz Nosek <root@localdomain.pl>
Date:   Thu Apr 2 16:57:23 2009 -0700

    cgroups: relax ns_can_attach checks to allow attaching to grandchild cgroups
    
    The ns_proxy cgroup allows moving processes to child cgroups only one
    level deep at a time.  This commit relaxes this restriction and makes it
    possible to attach tasks directly to grandchild cgroups, e.g.:
    
    ($pid is in the root cgroup)
    echo $pid > /cgroup/CG1/CG2/tasks
    
    Previously this operation would fail with -EPERM and would have to be
    performed as two steps:
    echo $pid > /cgroup/CG1/tasks
    echo $pid > /cgroup/CG1/CG2/tasks
    
    Also, the target cgroup no longer needs to be empty to move a task there.
    
    Signed-off-by: Grzegorz Nosek <root@localdomain.pl>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index bb8feb9feccd..788c4964c142 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -348,8 +348,8 @@ int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
 
 int cgroup_task_count(const struct cgroup *cgrp);
 
-/* Return true if the cgroup is a descendant of the current cgroup */
-int cgroup_is_descendant(const struct cgroup *cgrp);
+/* Return true if cgrp is a descendant of the task's cgroup */
+int cgroup_is_descendant(const struct cgroup *cgrp, struct task_struct *task);
 
 /* Control Group subsystem type. See Documentation/cgroups.txt for details */
 

commit d20a390a0ee2bf2f692c539c6ce1c829e1080bb5
Author: Paul Menage <menage@google.com>
Date:   Thu Apr 2 16:57:22 2009 -0700

    cgroups: fix cgroup.h comments
    
    Fix the style of some multi-line comments in cgroup.h to match
    Documentation/CodingStyle
    
    Signed-off-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 499900d0cee7..bb8feb9feccd 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -47,14 +47,18 @@ enum cgroup_subsys_id {
 
 /* Per-subsystem/per-cgroup state maintained by the system. */
 struct cgroup_subsys_state {
-	/* The cgroup that this subsystem is attached to. Useful
+	/*
+	 * The cgroup that this subsystem is attached to. Useful
 	 * for subsystems that want to know about the cgroup
-	 * hierarchy structure */
+	 * hierarchy structure
+	 */
 	struct cgroup *cgroup;
 
-	/* State maintained by the cgroup system to allow subsystems
+	/*
+	 * State maintained by the cgroup system to allow subsystems
 	 * to be "busy". Should be accessed via css_get(),
-	 * css_tryget() and and css_put(). */
+	 * css_tryget() and and css_put().
+	 */
 
 	atomic_t refcnt;
 
@@ -120,8 +124,10 @@ static inline void css_put(struct cgroup_subsys_state *css)
 enum {
 	/* Control Group is dead */
 	CGRP_REMOVED,
-	/* Control Group has previously had a child cgroup or a task,
-	 * but no longer (only if CGRP_NOTIFY_ON_RELEASE is set) */
+	/*
+	 * Control Group has previously had a child cgroup or a task,
+	 * but no longer (only if CGRP_NOTIFY_ON_RELEASE is set)
+	 */
 	CGRP_RELEASABLE,
 	/* Control Group requires release notifications to userspace */
 	CGRP_NOTIFY_ON_RELEASE,
@@ -130,9 +136,10 @@ enum {
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 
-	/* count users of this cgroup. >0 means busy, but doesn't
-	 * necessarily indicate the number of tasks in the
-	 * cgroup */
+	/*
+	 * count users of this cgroup. >0 means busy, but doesn't
+	 * necessarily indicate the number of tasks in the cgroup
+	 */
 	atomic_t count;
 
 	/*
@@ -142,7 +149,7 @@ struct cgroup {
 	struct list_head sibling;	/* my parent's children */
 	struct list_head children;	/* my children */
 
-	struct cgroup *parent;	/* my parent */
+	struct cgroup *parent;		/* my parent */
 	struct dentry *dentry;	  	/* cgroup fs entry, RCU protected */
 
 	/* Private pointers for each registered subsystem */
@@ -177,11 +184,12 @@ struct cgroup {
 	struct rcu_head rcu_head;
 };
 
-/* A css_set is a structure holding pointers to a set of
+/*
+ * A css_set is a structure holding pointers to a set of
  * cgroup_subsys_state objects. This saves space in the task struct
  * object and speeds up fork()/exit(), since a single inc/dec and a
- * list_add()/del() can bump the reference count on the entire
- * cgroup set for a task.
+ * list_add()/del() can bump the reference count on the entire cgroup
+ * set for a task.
  */
 
 struct css_set {
@@ -226,13 +234,8 @@ struct cgroup_map_cb {
 	void *state;
 };
 
-/* struct cftype:
- *
- * The files in the cgroup filesystem mostly have a very simple read/write
- * handling, some common function will take care of it. Nevertheless some cases
- * (read tasks) are special and therefore I define this structure for every
- * kind of file.
- *
+/*
+ * struct cftype: handler definitions for cgroup control files
  *
  * When reading/writing to a file:
  *	- the cgroup to use is file->f_dentry->d_parent->d_fsdata
@@ -241,8 +244,10 @@ struct cgroup_map_cb {
 
 #define MAX_CFTYPE_NAME 64
 struct cftype {
-	/* By convention, the name should begin with the name of the
-	 * subsystem, followed by a period */
+	/*
+	 * By convention, the name should begin with the name of the
+	 * subsystem, followed by a period
+	 */
 	char name[MAX_CFTYPE_NAME];
 	int private;
 
@@ -321,13 +326,17 @@ struct cgroup_scanner {
 	struct ptr_heap *heap;
 };
 
-/* Add a new file to the given cgroup directory. Should only be
- * called by subsystems from within a populate() method */
+/*
+ * Add a new file to the given cgroup directory. Should only be
+ * called by subsystems from within a populate() method
+ */
 int cgroup_add_file(struct cgroup *cgrp, struct cgroup_subsys *subsys,
 		       const struct cftype *cft);
 
-/* Add a set of new files to the given cgroup directory. Should
- * only be called by subsystems from within a populate() method */
+/*
+ * Add a set of new files to the given cgroup directory. Should
+ * only be called by subsystems from within a populate() method
+ */
 int cgroup_add_files(struct cgroup *cgrp,
 			struct cgroup_subsys *subsys,
 			const struct cftype cft[],
@@ -419,7 +428,8 @@ struct cgroup_iter {
 	struct list_head *task;
 };
 
-/* To iterate across the tasks in a cgroup:
+/*
+ * To iterate across the tasks in a cgroup:
  *
  * 1) call cgroup_iter_start to intialize an iterator
  *
@@ -428,9 +438,10 @@ struct cgroup_iter {
  *
  * 3) call cgroup_iter_end() to destroy the iterator.
  *
- * Or, call cgroup_scan_tasks() to iterate through every task in a cpuset.
- *    - cgroup_scan_tasks() holds the css_set_lock when calling the test_task()
- *      callback, but not while calling the process_task() callback.
+ * Or, call cgroup_scan_tasks() to iterate through every task in a
+ * cgroup - cgroup_scan_tasks() holds the css_set_lock when calling
+ * the test_task() callback, but not while calling the process_task()
+ * callback.
  */
 void cgroup_iter_start(struct cgroup *cgrp, struct cgroup_iter *it);
 struct task_struct *cgroup_iter_next(struct cgroup *cgrp,

commit 21acb9caa2e30b100e9a1943d995bb99d40f4035
Author: Thadeu Lima de Souza Cascardo <cascardo@holoscopio.com>
Date:   Wed Feb 4 10:12:08 2009 +0100

    trivial: fix where cgroup documentation is not correctly referred to
    
    cgroup documentation was moved to Documentation/cgroups/. There are some
    places that still refer to Documentation/controllers/,
    Documentation/cgroups.txt and Documentation/cpusets.txt. Fix those.
    
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@holoscopio.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 499900d0cee7..b837631fe499 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -342,7 +342,10 @@ int cgroup_task_count(const struct cgroup *cgrp);
 /* Return true if the cgroup is a descendant of the current cgroup */
 int cgroup_is_descendant(const struct cgroup *cgrp);
 
-/* Control Group subsystem type. See Documentation/cgroups.txt for details */
+/*
+ * Control Group subsystem type.
+ * See Documentation/cgroups/cgroups.txt for details
+ */
 
 struct cgroup_subsys {
 	struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss,

commit cfebe563bd0a3ff97e1bc167123120d59c7a84db
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Feb 11 13:04:36 2009 -0800

    cgroups: fix lockdep subclasses overflow
    
    I enabled all cgroup subsystems when compiling kernel, and then:
     # mount -t cgroup -o net_cls xxx /mnt
     # mkdir /mnt/0
    
    This showed up immediately:
     BUG: MAX_LOCKDEP_SUBCLASSES too low!
     turning off the locking correctness validator.
    
    It's caused by the cgroup hierarchy lock:
            for (i = 0; i < CGROUP_SUBSYS_COUNT; i++) {
                    struct cgroup_subsys *ss = subsys[i];
                    if (ss->root == root)
                            mutex_lock_nested(&ss->hierarchy_mutex, i);
            }
    
    Now we have 9 cgroup subsystems, and the above 'i' for net_cls is 8, but
    MAX_LOCKDEP_SUBCLASSES is 8.
    
    This patch uses different lockdep keys for different subsystems.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e4e8e117d27d..499900d0cee7 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -378,6 +378,7 @@ struct cgroup_subsys {
 	 * - initiating hotplug events
 	 */
 	struct mutex hierarchy_mutex;
+	struct lock_class_key subsys_key;
 
 	/*
 	 * Link to parent, and list entry in parent's children.

commit 804b3c28a4e4fa1c224571bf76edb534b9c4b1ed
Author: Paul Menage <menage@google.com>
Date:   Thu Jan 29 14:25:21 2009 -0800

    cgroups: add cpu_relax() calls in css_tryget() and cgroup_clear_css_refs()
    
    css_tryget() and cgroup_clear_css_refs() contain polling loops; these
    loops should have cpu_relax calls in them to reduce cross-cache traffic.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e267e62827bb..e4e8e117d27d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -99,6 +99,7 @@ static inline bool css_tryget(struct cgroup_subsys_state *css)
 	while (!atomic_inc_not_zero(&css->refcnt)) {
 		if (test_bit(CSS_REMOVED, &css->flags))
 			return false;
+		cpu_relax();
 	}
 	return true;
 }

commit e7c5ec9193d32b9559a3bb8893ceedbda85201ff
Author: Paul Menage <menage@google.com>
Date:   Wed Jan 7 18:08:38 2009 -0800

    cgroups: add css_tryget()
    
    Add css_tryget(), that obtains a counted reference on a CSS.  It is used
    in situations where the caller has a "weak" reference to the CSS, i.e.
    one that does not protect the cgroup from removal via a reference count,
    but would instead be cleaned up by a destroy() callback.
    
    css_tryget() will return true on success, or false if the cgroup is being
    removed.
    
    This is similar to Kamezawa Hiroyuki's patch from a week or two ago, but
    with the difference that in the event of css_tryget() racing with a
    cgroup_rmdir(), css_tryget() will only return false if the cgroup really
    does get removed.
    
    This implementation is done by biasing css->refcnt, so that a refcnt of 1
    means "releasable" and 0 means "released or releasing".  In the event of a
    race, css_tryget() distinguishes between "released" and "releasing" by
    checking for the CSS_REMOVED flag in css->flags.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Tested-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ce1c1f34c30c..e267e62827bb 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -52,9 +52,9 @@ struct cgroup_subsys_state {
 	 * hierarchy structure */
 	struct cgroup *cgroup;
 
-	/* State maintained by the cgroup system to allow
-	 * subsystems to be "busy". Should be accessed via css_get()
-	 * and css_put() */
+	/* State maintained by the cgroup system to allow subsystems
+	 * to be "busy". Should be accessed via css_get(),
+	 * css_tryget() and and css_put(). */
 
 	atomic_t refcnt;
 
@@ -64,11 +64,14 @@ struct cgroup_subsys_state {
 /* bits in struct cgroup_subsys_state flags field */
 enum {
 	CSS_ROOT, /* This CSS is the root of the subsystem */
+	CSS_REMOVED, /* This CSS is dead */
 };
 
 /*
- * Call css_get() to hold a reference on the cgroup;
- *
+ * Call css_get() to hold a reference on the css; it can be used
+ * for a reference obtained via:
+ * - an existing ref-counted reference to the css
+ * - task->cgroups for a locked task
  */
 
 static inline void css_get(struct cgroup_subsys_state *css)
@@ -77,9 +80,32 @@ static inline void css_get(struct cgroup_subsys_state *css)
 	if (!test_bit(CSS_ROOT, &css->flags))
 		atomic_inc(&css->refcnt);
 }
+
+static inline bool css_is_removed(struct cgroup_subsys_state *css)
+{
+	return test_bit(CSS_REMOVED, &css->flags);
+}
+
+/*
+ * Call css_tryget() to take a reference on a css if your existing
+ * (known-valid) reference isn't already ref-counted. Returns false if
+ * the css has been destroyed.
+ */
+
+static inline bool css_tryget(struct cgroup_subsys_state *css)
+{
+	if (test_bit(CSS_ROOT, &css->flags))
+		return true;
+	while (!atomic_inc_not_zero(&css->refcnt)) {
+		if (test_bit(CSS_REMOVED, &css->flags))
+			return false;
+	}
+	return true;
+}
+
 /*
  * css_put() should be called to release a reference taken by
- * css_get()
+ * css_get() or css_tryget()
  */
 
 extern void __css_put(struct cgroup_subsys_state *css);

commit 999cd8a450f8f93701669a61cac4d3b19eca07e8
Author: Paul Menage <menage@google.com>
Date:   Wed Jan 7 18:08:36 2009 -0800

    cgroups: add a per-subsystem hierarchy_mutex
    
    These patches introduce new locking/refcount support for cgroups to
    reduce the need for subsystems to call cgroup_lock(). This will
    ultimately allow the atomicity of cgroup_rmdir() (which was removed
    recently) to be restored.
    
    These three patches give:
    
    1/3 - introduce a per-subsystem hierarchy_mutex which a subsystem can
         use to prevent changes to its own cgroup tree
    
    2/3 - use hierarchy_mutex in place of calling cgroup_lock() in the
         memory controller
    
    3/3 - introduce a css_tryget() function similar to the one recently
          proposed by Kamezawa, but avoiding spurious refcount failures in
          the event of a race between a css_tryget() and an unsuccessful
          cgroup_rmdir()
    
    Future patches will likely involve:
    
    - using hierarchy mutex in place of cgroup_lock() in more subsystems
     where appropriate
    
    - restoring the atomicity of cgroup_rmdir() with respect to cgroup_create()
    
    This patch:
    
    Add a hierarchy_mutex to the cgroup_subsys object that protects changes to
    the hierarchy observed by that subsystem.  It is taken by the cgroup
    subsystem (in addition to cgroup_mutex) for the following operations:
    
    - linking a cgroup into that subsystem's cgroup tree
    - unlinking a cgroup from that subsystem's cgroup tree
    - moving the subsystem to/from a hierarchy (including across the
      bind() callback)
    
    Thus if the subsystem holds its own hierarchy_mutex, it can safely
    traverse its own hierarchy.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Tested-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 73d1c730c3c4..ce1c1f34c30c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -340,8 +340,23 @@ struct cgroup_subsys {
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 
-	struct cgroupfs_root *root;
+	/*
+	 * Protects sibling/children links of cgroups in this
+	 * hierarchy, plus protects which hierarchy (or none) the
+	 * subsystem is a part of (i.e. root/sibling).  To avoid
+	 * potential deadlocks, the following operations should not be
+	 * undertaken while holding any hierarchy_mutex:
+	 *
+	 * - allocating memory
+	 * - initiating hotplug events
+	 */
+	struct mutex hierarchy_mutex;
 
+	/*
+	 * Link to parent, and list entry in parent's children.
+	 * Protected by this->hierarchy_mutex and cgroup_lock()
+	 */
+	struct cgroupfs_root *root;
 	struct list_head sibling;
 };
 

commit a47295e6bc42ad35f9c15ac66f598aa24debd4e2
Author: Paul Menage <menage@google.com>
Date:   Wed Jan 7 18:07:44 2009 -0800

    cgroups: make cgroup_path() RCU-safe
    
    Fix races between /proc/sched_debug by freeing cgroup objects via an RCU
    callback.  Thus any cgroup reference obtained from an RCU-safe source will
    remain valid during the RCU section.  Since dentries are also RCU-safe,
    this allows us to traverse up the tree safely.
    
    Additionally, make cgroup_path() check for a NULL cgrp->dentry to avoid
    trying to report a path for a partially-created cgroup.
    
    [lizf@cn.fujitsu.com: call deactive_super() in cgroup_diput()]
    Signed-off-by: Paul Menage <menage@google.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Tested-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f68dfd8dd53a..73d1c730c3c4 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -116,7 +116,7 @@ struct cgroup {
 	struct list_head children;	/* my children */
 
 	struct cgroup *parent;	/* my parent */
-	struct dentry *dentry;	  	/* cgroup fs entry */
+	struct dentry *dentry;	  	/* cgroup fs entry, RCU protected */
 
 	/* Private pointers for each registered subsystem */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
@@ -145,6 +145,9 @@ struct cgroup {
 	int pids_use_count;
 	/* Length of the current tasks_pids array */
 	int pids_length;
+
+	/* For RCU-protected deletion */
+	struct rcu_head rcu_head;
 };
 
 /* A css_set is a structure holding pointers to a set of

commit b2aa30f7bb381e04c93eed106089ba55553955f1
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Wed Jan 7 18:07:37 2009 -0800

    cgroups: don't put struct cgroupfs_root protected by RCU
    
    We don't access struct cgroupfs_root in fast path, so we should not put
    struct cgroupfs_root protected by RCU
    
    But the comment in struct cgroup_subsys.root confuse us.
    
    struct cgroup_subsys.root is used in these places:
    
    1 find_css_set(): if (ss->root->subsys_list.next == &ss->sibling)
    2 rebind_subsystems(): if (ss->root != &rootnode)
                           rcu_assign_pointer(ss->root, root);
                           rcu_assign_pointer(subsys[i]->root, &rootnode);
    3 cgroup_has_css_refs(): if (ss->root != cgrp->root)
    4 cgroup_init_subsys(): ss->root = &rootnode;
    5 proc_cgroupstats_show(): ss->name, ss->root->subsys_bits,
                               ss->root->number_of_cgroups, !ss->disabled);
    6 cgroup_clone(): root = subsys->root;
                      if ((root != subsys->root) ||
    
    All these place we have held cgroup_lock() or we don't dereference to
    struct cgroupfs_root.  It's means wo don't need RCU when use struct
    cgroup_subsys.root, and we should not put struct cgroupfs_root protected
    by RCU.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Reviewed-by: Paul Menage <menage@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 08b78c09b09a..f68dfd8dd53a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -337,7 +337,6 @@ struct cgroup_subsys {
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;
 
-	/* Protected by RCU */
 	struct cgroupfs_root *root;
 
 	struct list_head sibling;

commit e5991371ee0d1c0ce19e133c6f9075b49c5b4ae8
Author: Hugh Dickins <hugh@veritas.com>
Date:   Tue Jan 6 14:39:22 2009 -0800

    mm: remove cgroup_mm_owner_callbacks
    
    cgroup_mm_owner_callbacks() was brought in to support the memrlimit
    controller, but sneaked into mainline ahead of it.  That controller has
    now been shelved, and the mm_owner_changed() args were inadequate for it
    anyway (they needed an mm pointer instead of a task pointer).
    
    Remove the dead code, and restore mm_update_next_owner() locking to how it
    was before: taking mmap_sem there does nothing for memcontrol.c, now the
    only user of mm->owner.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Cc: Paul Menage <menage@google.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 1164963c3a85..08b78c09b09a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -329,13 +329,7 @@ struct cgroup_subsys {
 			struct cgroup *cgrp);
 	void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);
-	/*
-	 * This routine is called with the task_lock of mm->owner held
-	 */
-	void (*mm_owner_changed)(struct cgroup_subsys *ss,
-					struct cgroup *old,
-					struct cgroup *new,
-					struct task_struct *p);
+
 	int subsys_id;
 	int active;
 	int disabled;
@@ -400,9 +394,6 @@ void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *, struct task_struct *);
 
-void cgroup_mm_owner_callbacks(struct task_struct *old,
-			       struct task_struct *new);
-
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }
@@ -420,9 +411,6 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 	return -EINVAL;
 }
 
-static inline void cgroup_mm_owner_callbacks(struct task_struct *old,
-					     struct task_struct *new) {}
-
 #endif /* !CONFIG_CGROUPS */
 
 #endif /* _LINUX_CGROUP_H */

commit 9b913735e53ab0da4a792bac0de8e178cc13dcfb
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Oct 29 14:00:54 2008 -0700

    cgroups: tiny cleanups
    
    - remove 'private' field from struct subsys
    - remove cgroup_init_smp()
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8b00f6643e93..1164963c3a85 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -25,7 +25,6 @@ struct cgroup;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
-extern void cgroup_init_smp(void);
 extern void cgroup_lock(void);
 extern bool cgroup_lock_live_group(struct cgroup *cgrp);
 extern void cgroup_unlock(void);
@@ -348,8 +347,6 @@ struct cgroup_subsys {
 	struct cgroupfs_root *root;
 
 	struct list_head sibling;
-
-	void *private;
 };
 
 #define SUBSYS(_x) extern struct cgroup_subsys _x ## _subsys;
@@ -410,7 +407,6 @@ void cgroup_mm_owner_callbacks(struct task_struct *old,
 
 static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
-static inline void cgroup_init_smp(void) {}
 static inline void cgroup_fork(struct task_struct *p) {}
 static inline void cgroup_fork_callbacks(struct task_struct *p) {}
 static inline void cgroup_post_fork(struct task_struct *p) {}

commit 886465f407e57d6c3c81013c919ea670ce1ae0d0
Author: Paul Menage <menage@google.com>
Date:   Sat Oct 18 20:28:05 2008 -0700

    cgroups: fix declaration of cgroup_mm_owner_callbacks
    
    The choice of real/dummy declaration for cgroup_mm_owner_callbacks()
    shouldn't be based on CONFIG_MM_OWNER, but on CONFIG_CGROUPS.  Otherwise
    kernel/exit.c fails to compile when something other than a cgroups
    controller selects CONFIG_MM_OWNER
    
    Signed-off-by: Paul Menage <menage@google.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8ab91880a0ad..8b00f6643e93 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -403,6 +403,9 @@ void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *, struct task_struct *);
 
+void cgroup_mm_owner_callbacks(struct task_struct *old,
+			       struct task_struct *new);
+
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }
@@ -421,15 +424,9 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 	return -EINVAL;
 }
 
+static inline void cgroup_mm_owner_callbacks(struct task_struct *old,
+					     struct task_struct *new) {}
+
 #endif /* !CONFIG_CGROUPS */
 
-#ifdef CONFIG_MM_OWNER
-extern void
-cgroup_mm_owner_callbacks(struct task_struct *old, struct task_struct *new);
-#else /* !CONFIG_MM_OWNER */
-static inline void
-cgroup_mm_owner_callbacks(struct task_struct *old, struct task_struct *new)
-{
-}
-#endif /* CONFIG_MM_OWNER */
 #endif /* _LINUX_CGROUP_H */

commit cc31edceee04a7b87f2be48f9489ebb72d264844
Author: Paul Menage <menage@google.com>
Date:   Sat Oct 18 20:28:04 2008 -0700

    cgroups: convert tasks file to use a seq_file with shared pid array
    
    Rather than pre-generating the entire text for the "tasks" file each
    time the file is opened, we instead just generate/update the array of
    process ids and use a seq_file to report these to userspace.  All open
    file handles on the same "tasks" file can share a pid array, which may
    be updated any time that no thread is actively reading the array.  By
    sharing the array, the potential for userspace to DoS the system by
    opening many handles on the same "tasks" file is removed.
    
    [Based on a patch by Lai Jiangshan, extended to use seq_file]
    
    Signed-off-by: Paul Menage <menage@google.com>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 7166023e07d2..8ab91880a0ad 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -14,6 +14,7 @@
 #include <linux/rcupdate.h>
 #include <linux/cgroupstats.h>
 #include <linux/prio_heap.h>
+#include <linux/rwsem.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -136,6 +137,15 @@ struct cgroup {
 	 * release_list_lock
 	 */
 	struct list_head release_list;
+
+	/* pids_mutex protects the fields below */
+	struct rw_semaphore pids_mutex;
+	/* Array of process ids in the cgroup */
+	pid_t *tasks_pids;
+	/* How many files are using the current tasks_pids array */
+	int pids_use_count;
+	/* Length of the current tasks_pids array */
+	int pids_length;
 };
 
 /* A css_set is a structure holding pointers to a set of

commit 146aa1bd0511f88ddb4e92fafa2b8aad4f2f65f3
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Sat Oct 18 20:28:03 2008 -0700

    cgroups: fix probable race with put_css_set[_taskexit] and find_css_set
    
    put_css_set_taskexit may be called when find_css_set is called on other
    cpu.  And the race will occur:
    
    put_css_set_taskexit side                    find_css_set side
    
                                            |
    atomic_dec_and_test(&kref->refcount)    |
        /* kref->refcount = 0 */            |
    ....................................................................
                                            |  read_lock(&css_set_lock)
                                            |  find_existing_css_set
                                            |  get_css_set
                                            |  read_unlock(&css_set_lock);
    ....................................................................
    __release_css_set                       |
    ....................................................................
                                            | /* use a released css_set */
                                            |
    
    [put_css_set is the same. But in the current code, all put_css_set are
    put into cgroup mutex critical region as the same as find_css_set.]
    
    [akpm@linux-foundation.org: repair comments]
    [menage@google.com: eliminate race in css_set refcounting]
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 30934e4bfaab..7166023e07d2 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -9,7 +9,6 @@
  */
 
 #include <linux/sched.h>
-#include <linux/kref.h>
 #include <linux/cpumask.h>
 #include <linux/nodemask.h>
 #include <linux/rcupdate.h>
@@ -149,7 +148,7 @@ struct cgroup {
 struct css_set {
 
 	/* Reference count */
-	struct kref ref;
+	atomic_t refcount;
 
 	/*
 	 * List running through all cgroup groups in the same hash

commit 9363b9f23c9cc36cc8ef6c05fdf879ee4a96ae92
Author: Balbir Singh <balbir@linux.vnet.ibm.com>
Date:   Wed Oct 15 22:01:05 2008 -0700

    memrlimit: cgroup mm owner callback changes to add task info
    
    This patch adds an additional field to the mm_owner callbacks. This field
    is required to get to the mm that changed. Hold mmap_sem in write mode
    before calling the mm_owner_changed callback
    
    [hugh@veritas.com: fix mmap_sem deadlock]
    Signed-off-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Sudhir Kumar <skumar@linux.vnet.ibm.com>
    Cc: YAMAMOTO Takashi <yamamoto@valinux.co.jp>
    Cc: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Pavel Emelianov <xemul@openvz.org>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index c98dd7cb7076..30934e4bfaab 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -326,7 +326,8 @@ struct cgroup_subsys {
 	 */
 	void (*mm_owner_changed)(struct cgroup_subsys *ss,
 					struct cgroup *old,
-					struct cgroup *new);
+					struct cgroup *new,
+					struct task_struct *p);
 	int subsys_id;
 	int active;
 	int disabled;

commit e885dcde75685e09f23cffae1f6d5169c105b8a0
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Fri Jul 25 01:47:06 2008 -0700

    cgroup_clone: use pid of newly created task for new cgroup
    
    cgroup_clone creates a new cgroup with the pid of the task.  This works
    correctly for unshare, but for clone cgroup_clone is called from
    copy_namespaces inside copy_process, which happens before the new pid is
    created.  As a result, the new cgroup was created with current's pid.
    This patch:
    
            1. Moves the call inside copy_process to after the new pid
               is created
            2. Passes the struct pid into ns_cgroup_clone (as it is not
               yet attached to the task)
            3. Passes a name from ns_cgroup_clone() into cgroup_clone()
               so as to keep cgroup_clone() itself simpler
            4. Uses pid_vnr() to get the process id value, so that the
               pid used to name the new cgroup is always the pid as it
               would be known to the task which did the cloning or
               unsharing.  I think that is the most intuitive thing to
               do.  This way, task t1 does clone(CLONE_NEWPID) to get
               t2, which does clone(CLONE_NEWPID) to get t3, then the
               cgroup for t3 will be named for the pid by which t2 knows
               t3.
    
    (Thanks to Dan Smith for finding the main bug)
    
    Changelog:
            June 11: Incorporate Paul Menage's feedback:  don't pass
                     NULL to ns_cgroup_clone from unshare, and reduce
                     patch size by using 'nodename' in cgroup_clone.
            June 10: Original version
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Serge Hallyn <serge@us.ibm.com>
    Acked-by: Paul Menage <menage@google.com>
    Tested-by: Dan Smith <danms@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index cc59d3a21d87..c98dd7cb7076 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -364,7 +364,8 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 	return task_subsys_state(task, subsys_id)->cgroup;
 }
 
-int cgroup_clone(struct task_struct *tsk, struct cgroup_subsys *ss);
+int cgroup_clone(struct task_struct *tsk, struct cgroup_subsys *ss,
+							char *nodename);
 
 /* A cgroup_iter should be treated as an opaque object */
 struct cgroup_iter {

commit 84eea842886ac35020be6043e04748ed22014359
Author: Paul Menage <menage@google.com>
Date:   Fri Jul 25 01:47:00 2008 -0700

    cgroups: misc cleanups to write_string patchset
    
    This patch contains cleanups suggested by reviewers for the recent
    write_string() patchset:
    
    - pair cgroup_lock_live_group() with cgroup_unlock() in cgroup.c for
      clarity, rather than directly unlocking cgroup_mutex.
    
    - make the return type of cgroup_lock_live_group() a bool
    
    - use a #define'd constant for the local buffer size in read/write functions
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e78377a91a74..cc59d3a21d87 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -21,11 +21,13 @@
 struct cgroupfs_root;
 struct cgroup_subsys;
 struct inode;
+struct cgroup;
 
 extern int cgroup_init_early(void);
 extern int cgroup_init(void);
 extern void cgroup_init_smp(void);
 extern void cgroup_lock(void);
+extern bool cgroup_lock_live_group(struct cgroup *cgrp);
 extern void cgroup_unlock(void);
 extern void cgroup_fork(struct task_struct *p);
 extern void cgroup_fork_callbacks(struct task_struct *p);
@@ -295,8 +297,6 @@ int cgroup_add_files(struct cgroup *cgrp,
 
 int cgroup_is_removed(const struct cgroup *cgrp);
 
-int cgroup_lock_live_group(struct cgroup *cgrp);
-
 int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
 
 int cgroup_task_count(const struct cgroup *cgrp);

commit e788e066c651b1bbf4a927dc95395c1aa13be436
Author: Paul Menage <menage@google.com>
Date:   Fri Jul 25 01:46:59 2008 -0700

    cgroup files: move the release_agent file to use typed handlers
    
    Adds cgroup_release_agent_write() and cgroup_release_agent_show()
    methods to handle writing/reading the path to a cgroup hierarchy's
    release agent. As a result, cgroup_common_file_read() is now unnecessary.
    
    As part of the change, a previously-tolerated race in
    cgroup_release_agent() is avoided by copying the current
    release_agent_path prior to calling call_usermode_helper().
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f5379455bb59..e78377a91a74 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -295,6 +295,8 @@ int cgroup_add_files(struct cgroup *cgrp,
 
 int cgroup_is_removed(const struct cgroup *cgrp);
 
+int cgroup_lock_live_group(struct cgroup *cgrp);
+
 int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
 
 int cgroup_task_count(const struct cgroup *cgrp);

commit db3b14978abc02041046ed8353f0899cb58ffffc
Author: Paul Menage <menage@google.com>
Date:   Fri Jul 25 01:46:58 2008 -0700

    cgroup files: add write_string cgroup control file method
    
    This patch adds a write_string() method for cgroups control files. The
    semantics are that a buffer is copied from userspace to kernelspace
    and the handler function invoked on that buffer.  The buffer is
    guaranteed to be nul-terminated, and no longer than max_write_len
    (defaulting to 64 bytes if unspecified). Later patches will convert
    existing raw file write handlers in control group subsystems to use
    this method.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Balbir Singh <balbir@in.ibm.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 88a734edccbc..f5379455bb59 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -205,6 +205,13 @@ struct cftype {
 	 * subsystem, followed by a period */
 	char name[MAX_CFTYPE_NAME];
 	int private;
+
+	/*
+	 * If non-zero, defines the maximum length of string that can
+	 * be passed to write_string; defaults to 64
+	 */
+	size_t max_write_len;
+
 	int (*open)(struct inode *inode, struct file *file);
 	ssize_t (*read)(struct cgroup *cgrp, struct cftype *cft,
 			struct file *file,
@@ -248,6 +255,13 @@ struct cftype {
 	 */
 	int (*write_s64)(struct cgroup *cgrp, struct cftype *cft, s64 val);
 
+	/*
+	 * write_string() is passed a nul-terminated kernelspace
+	 * buffer of maximum length determined by max_write_len.
+	 * Returns 0 or -ve error code.
+	 */
+	int (*write_string)(struct cgroup *cgrp, struct cftype *cft,
+			    const char *buffer);
 	/*
 	 * trigger() callback can be used to get some kick from the
 	 * userspace, when the actual string written is not important

commit ce16b49d37e748574f7fabc2726268d542d0aa1a
Author: Paul Menage <menage@google.com>
Date:   Fri Jul 25 01:46:57 2008 -0700

    cgroup files: clean up whitespace in struct cftype
    
    This patch removes some extraneous spaces from method declarations in
    struct cftype, to fit in with conventional kernel style.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e155aa78d859..88a734edccbc 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -205,48 +205,48 @@ struct cftype {
 	 * subsystem, followed by a period */
 	char name[MAX_CFTYPE_NAME];
 	int private;
-	int (*open) (struct inode *inode, struct file *file);
-	ssize_t (*read) (struct cgroup *cgrp, struct cftype *cft,
-			 struct file *file,
-			 char __user *buf, size_t nbytes, loff_t *ppos);
+	int (*open)(struct inode *inode, struct file *file);
+	ssize_t (*read)(struct cgroup *cgrp, struct cftype *cft,
+			struct file *file,
+			char __user *buf, size_t nbytes, loff_t *ppos);
 	/*
 	 * read_u64() is a shortcut for the common case of returning a
 	 * single integer. Use it in place of read()
 	 */
-	u64 (*read_u64) (struct cgroup *cgrp, struct cftype *cft);
+	u64 (*read_u64)(struct cgroup *cgrp, struct cftype *cft);
 	/*
 	 * read_s64() is a signed version of read_u64()
 	 */
-	s64 (*read_s64) (struct cgroup *cgrp, struct cftype *cft);
+	s64 (*read_s64)(struct cgroup *cgrp, struct cftype *cft);
 	/*
 	 * read_map() is used for defining a map of key/value
 	 * pairs. It should call cb->fill(cb, key, value) for each
 	 * entry. The key/value pairs (and their ordering) should not
 	 * change between reboots.
 	 */
-	int (*read_map) (struct cgroup *cont, struct cftype *cft,
-			 struct cgroup_map_cb *cb);
+	int (*read_map)(struct cgroup *cont, struct cftype *cft,
+			struct cgroup_map_cb *cb);
 	/*
 	 * read_seq_string() is used for outputting a simple sequence
 	 * using seqfile.
 	 */
-	int (*read_seq_string) (struct cgroup *cont, struct cftype *cft,
-			 struct seq_file *m);
+	int (*read_seq_string)(struct cgroup *cont, struct cftype *cft,
+			       struct seq_file *m);
 
-	ssize_t (*write) (struct cgroup *cgrp, struct cftype *cft,
-			  struct file *file,
-			  const char __user *buf, size_t nbytes, loff_t *ppos);
+	ssize_t (*write)(struct cgroup *cgrp, struct cftype *cft,
+			 struct file *file,
+			 const char __user *buf, size_t nbytes, loff_t *ppos);
 
 	/*
 	 * write_u64() is a shortcut for the common case of accepting
 	 * a single integer (as parsed by simple_strtoull) from
 	 * userspace. Use in place of write(); return 0 or error.
 	 */
-	int (*write_u64) (struct cgroup *cgrp, struct cftype *cft, u64 val);
+	int (*write_u64)(struct cgroup *cgrp, struct cftype *cft, u64 val);
 	/*
 	 * write_s64() is a signed version of write_u64()
 	 */
-	int (*write_s64) (struct cgroup *cgrp, struct cftype *cft, s64 val);
+	int (*write_s64)(struct cgroup *cgrp, struct cftype *cft, s64 val);
 
 	/*
 	 * trigger() callback can be used to get some kick from the
@@ -256,7 +256,7 @@ struct cftype {
 	 */
 	int (*trigger)(struct cgroup *cgrp, unsigned int event);
 
-	int (*release) (struct inode *inode, struct file *file);
+	int (*release)(struct inode *inode, struct file *file);
 };
 
 struct cgroup_scanner {

commit cf475ad28ac35cc9ba612d67158f29b73b38b05d
Author: Balbir Singh <balbir@linux.vnet.ibm.com>
Date:   Tue Apr 29 01:00:16 2008 -0700

    cgroups: add an owner to the mm_struct
    
    Remove the mem_cgroup member from mm_struct and instead adds an owner.
    
    This approach was suggested by Paul Menage.  The advantage of this approach
    is that, once the mm->owner is known, using the subsystem id, the cgroup
    can be determined.  It also allows several control groups that are
    virtually grouped by mm_struct, to exist independent of the memory
    controller i.e., without adding mem_cgroup's for each controller, to
    mm_struct.
    
    A new config option CONFIG_MM_OWNER is added and the memory resource
    controller selects this config option.
    
    This patch also adds cgroup callbacks to notify subsystems when mm->owner
    changes.  The mm_cgroup_changed callback is called with the task_lock() of
    the new task held and is called just prior to changing the mm->owner.
    
    I am indebted to Paul Menage for the several reviews of this patchset and
    helping me make it lighter and simpler.
    
    This patch was tested on a powerpc box, it was compiled with both the
    MM_OWNER config turned on and off.
    
    After the thread group leader exits, it's moved to init_css_state by
    cgroup_exit(), thus all future charges from runnings threads would be
    redirected to the init_css_set's subsystem.
    
    Signed-off-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Pavel Emelianov <xemul@openvz.org>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Sudhir Kumar <skumar@linux.vnet.ibm.com>
    Cc: YAMAMOTO Takashi <yamamoto@valinux.co.jp>
    Cc: Hirokazu Takahashi <taka@valinux.co.jp>
    Cc: David Rientjes <rientjes@google.com>,
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Reviewed-by: Paul Menage <menage@google.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 095248082b7e..e155aa78d859 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -305,6 +305,12 @@ struct cgroup_subsys {
 			struct cgroup *cgrp);
 	void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);
+	/*
+	 * This routine is called with the task_lock of mm->owner held
+	 */
+	void (*mm_owner_changed)(struct cgroup_subsys *ss,
+					struct cgroup *old,
+					struct cgroup *new);
 	int subsys_id;
 	int active;
 	int disabled;
@@ -390,4 +396,13 @@ static inline int cgroupstats_build(struct cgroupstats *stats,
 
 #endif /* !CONFIG_CGROUPS */
 
+#ifdef CONFIG_MM_OWNER
+extern void
+cgroup_mm_owner_callbacks(struct task_struct *old, struct task_struct *new);
+#else /* !CONFIG_MM_OWNER */
+static inline void
+cgroup_mm_owner_callbacks(struct task_struct *old, struct task_struct *new)
+{
+}
+#endif /* CONFIG_MM_OWNER */
 #endif /* _LINUX_CGROUP_H */

commit 29486df325e1fe6e1764afcb19e3370804c2b002
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Tue Apr 29 01:00:14 2008 -0700

    cgroups: introduce cft->read_seq()
    
    Introduce a read_seq() helper in cftype, which uses seq_file to print out
    lists.  Use it in the devices cgroup.  Also split devices.allow into two
    files, so now devices.deny and devices.allow are the ones to use to manipulate
    the whitelist, while devices.list outputs the cgroup's current whitelist.
    
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Acked-by: Paul Menage <menage@google.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d58a958444ab..095248082b7e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -226,6 +226,12 @@ struct cftype {
 	 */
 	int (*read_map) (struct cgroup *cont, struct cftype *cft,
 			 struct cgroup_map_cb *cb);
+	/*
+	 * read_seq_string() is used for outputting a simple sequence
+	 * using seqfile.
+	 */
+	int (*read_seq_string) (struct cgroup *cont, struct cftype *cft,
+			 struct seq_file *m);
 
 	ssize_t (*write) (struct cgroup *cgrp, struct cftype *cft,
 			  struct file *file,

commit 28fd5dfc12bde391981dfdcf20755952b6e916af
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Apr 29 01:00:13 2008 -0700

    cgroups: remove the css_set linked-list
    
    Now we can run through the hash table instead of running through the
    linked-list.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Reviewed-by: Paul Menage <menage@google.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index f585b7cde87b..d58a958444ab 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -149,12 +149,6 @@ struct css_set {
 	/* Reference count */
 	struct kref ref;
 
-	/*
-	 * List running through all cgroup groups. Protected by
-	 * css_set_lock
-	 */
-	struct list_head list;
-
 	/*
 	 * List running through all cgroup groups in the same hash
 	 * slot. Protected by css_set_lock

commit 472b1053f3c319cc60bfb2a0bb062fed77a93eb6
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Apr 29 01:00:11 2008 -0700

    cgroups: use a hash table for css_set finding
    
    When we attach a process to a different cgroup, the css_set linked-list will
    be run through to find a suitable existing css_set to use.  This patch
    implements a hash table for better performance.
    
    The following benchmarks have been tested:
    
    For N in 1, 5, 10, 50, 100, 500, 1000, create N cgroups with one sleeping
    task in each, and then move an additional task through each cgroup in
    turn.
    
    Here is a test result:
    
    N       Loop    orig - Time(s)  hash - Time(s)
    ----------------------------------------------
    1       10000   1.201231728     1.196311177
    5       2000    1.065743872     1.040566424
    10      1000    0.991054735     0.986876440
    50      200     0.976554203     0.969608733
    100     100     0.998504680     0.969218270
    500     20      1.157347764     0.962602963
    1000    10      1.619521852     1.085140172
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Reviewed-by: Paul Menage <menage@google.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 2d1d151258cf..f585b7cde87b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -155,6 +155,12 @@ struct css_set {
 	 */
 	struct list_head list;
 
+	/*
+	 * List running through all cgroup groups in the same hash
+	 * slot. Protected by css_set_lock
+	 */
+	struct hlist_node hlist;
+
 	/*
 	 * List running through all tasks using this cgroup
 	 * group. Protected by css_set_lock
@@ -174,7 +180,6 @@ struct css_set {
 	 * during subsystem registration (at boot time).
 	 */
 	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
-
 };
 
 /*

commit d447ea2f30ec60370ddb99a668e5ac12995f043d
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Apr 29 01:00:08 2008 -0700

    cgroups: add the trigger callback to struct cftype
    
    Trigger callback can be used to receive a kick-up from the user space.  The
    string written is ignored.
    
    The cftype->private is used for multiplexing events.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Paul Menage <menage@google.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 785a01cfb49d..2d1d151258cf 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -243,6 +243,14 @@ struct cftype {
 	 */
 	int (*write_s64) (struct cgroup *cgrp, struct cftype *cft, s64 val);
 
+	/*
+	 * trigger() callback can be used to get some kick from the
+	 * userspace, when the actual string written is not important
+	 * at all. The private field can be used to determine the
+	 * kick type for multiplexing.
+	 */
+	int (*trigger)(struct cgroup *cgrp, unsigned int event);
+
 	int (*release) (struct inode *inode, struct file *file);
 };
 

commit e73d2c61d1fcbd3621688ae457b49509c8d4c601
Author: Paul Menage <menage@google.com>
Date:   Tue Apr 29 01:00:06 2008 -0700

    CGroups _s64 files: add cgroups read_s64/write_s64 file methods
    
    These patches add cgroups read_s64 and write_s64 control file methods (the
    signed equivalent of read_u64/write_u64) and use them to implement the
    cpu.rt_runtime_us control file in the CFS cgroup subsystem.
    
    This patch:
    
    These are the signed equivalents of the read_u64/write_u64 methods
    
    Signed-off-by: Paul Menage <menage@google.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b40fd5ee9a76..785a01cfb49d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -215,6 +215,10 @@ struct cftype {
 	 * single integer. Use it in place of read()
 	 */
 	u64 (*read_u64) (struct cgroup *cgrp, struct cftype *cft);
+	/*
+	 * read_s64() is a signed version of read_u64()
+	 */
+	s64 (*read_s64) (struct cgroup *cgrp, struct cftype *cft);
 	/*
 	 * read_map() is used for defining a map of key/value
 	 * pairs. It should call cb->fill(cb, key, value) for each
@@ -234,6 +238,10 @@ struct cftype {
 	 * userspace. Use in place of write(); return 0 or error.
 	 */
 	int (*write_u64) (struct cgroup *cgrp, struct cftype *cft, u64 val);
+	/*
+	 * write_s64() is a signed version of write_u64()
+	 */
+	int (*write_s64) (struct cgroup *cgrp, struct cftype *cft, s64 val);
 
 	int (*release) (struct inode *inode, struct file *file);
 };

commit 3116f0e3df0a67ad56f15dd4c5f6cefb04bb4a98
Author: Paul Menage <menage@google.com>
Date:   Tue Apr 29 01:00:04 2008 -0700

    CGroup API files: move "releasable" to cgroup_debug subsystem
    
    The "releasable" control file provided by the cgroup framework exports the
    state of a per-cgroup flag that's related to the notify-on-release feature.
    This isn't really generally useful, unless you're trying to debug this
    particular feature of cgroups.
    
    This patch moves the "releasable" file to the cgroup_debug subsystem.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: "Li Zefan" <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: "YAMAMOTO Takashi" <yamamoto@valinux.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 0a3ab670dd2f..b40fd5ee9a76 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -88,6 +88,17 @@ static inline void css_put(struct cgroup_subsys_state *css)
 		__css_put(css);
 }
 
+/* bits in struct cgroup flags field */
+enum {
+	/* Control Group is dead */
+	CGRP_REMOVED,
+	/* Control Group has previously had a child cgroup or a task,
+	 * but no longer (only if CGRP_NOTIFY_ON_RELEASE is set) */
+	CGRP_RELEASABLE,
+	/* Control Group requires release notifications to userspace */
+	CGRP_NOTIFY_ON_RELEASE,
+};
+
 struct cgroup {
 	unsigned long flags;		/* "unsigned long" so bitops work */
 

commit 9179656961adcea3c25403365597e486d851ac5e
Author: Paul Menage <menage@google.com>
Date:   Tue Apr 29 01:00:01 2008 -0700

    CGroup API files: add cgroup map data type
    
    Adds a new type of supported control file representation, a map from strings
    to u64 values.
    
    Each map entry is printed as a line in a similar format to /proc/vmstat, i.e.
    "$key $value\n"
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: "Li Zefan" <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: "YAMAMOTO Takashi" <yamamoto@valinux.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 058371c5d360..0a3ab670dd2f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -166,6 +166,16 @@ struct css_set {
 
 };
 
+/*
+ * cgroup_map_cb is an abstract callback API for reporting map-valued
+ * control files
+ */
+
+struct cgroup_map_cb {
+	int (*fill)(struct cgroup_map_cb *cb, const char *key, u64 value);
+	void *state;
+};
+
 /* struct cftype:
  *
  * The files in the cgroup filesystem mostly have a very simple read/write
@@ -194,6 +204,15 @@ struct cftype {
 	 * single integer. Use it in place of read()
 	 */
 	u64 (*read_u64) (struct cgroup *cgrp, struct cftype *cft);
+	/*
+	 * read_map() is used for defining a map of key/value
+	 * pairs. It should call cb->fill(cb, key, value) for each
+	 * entry. The key/value pairs (and their ordering) should not
+	 * change between reboots.
+	 */
+	int (*read_map) (struct cgroup *cont, struct cftype *cft,
+			 struct cgroup_map_cb *cb);
+
 	ssize_t (*write) (struct cgroup *cgrp, struct cftype *cft,
 			  struct file *file,
 			  const char __user *buf, size_t nbytes, loff_t *ppos);

commit f4c753b7eacc277e506066abdda351cbc1cf8e6a
Author: Paul Menage <menage@google.com>
Date:   Tue Apr 29 00:59:56 2008 -0700

    CGroup API files: rename read/write_uint methods to read_write_u64
    
    Several people have justifiably complained that the "_uint" suffix is
    inappropriate for functions that handle u64 values, so this patch just renames
    all these functions and their users to have the suffic _u64.
    
    [peterz@infradead.org: build fix]
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: "Li Zefan" <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: "YAMAMOTO Takashi" <yamamoto@valinux.co.jp>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a6a6035a4e1e..058371c5d360 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -190,20 +190,20 @@ struct cftype {
 			 struct file *file,
 			 char __user *buf, size_t nbytes, loff_t *ppos);
 	/*
-	 * read_uint() is a shortcut for the common case of returning a
+	 * read_u64() is a shortcut for the common case of returning a
 	 * single integer. Use it in place of read()
 	 */
-	u64 (*read_uint) (struct cgroup *cgrp, struct cftype *cft);
+	u64 (*read_u64) (struct cgroup *cgrp, struct cftype *cft);
 	ssize_t (*write) (struct cgroup *cgrp, struct cftype *cft,
 			  struct file *file,
 			  const char __user *buf, size_t nbytes, loff_t *ppos);
 
 	/*
-	 * write_uint() is a shortcut for the common case of accepting
+	 * write_u64() is a shortcut for the common case of accepting
 	 * a single integer (as parsed by simple_strtoull) from
 	 * userspace. Use in place of write(); return 0 or error.
 	 */
-	int (*write_uint) (struct cgroup *cgrp, struct cftype *cft, u64 val);
+	int (*write_u64) (struct cgroup *cgrp, struct cftype *cft, u64 val);
 
 	int (*release) (struct inode *inode, struct file *file);
 };

commit 8bab8dded67d026c39367bbd5e27d2f6c556c38e
Author: Paul Menage <menage@google.com>
Date:   Fri Apr 4 14:29:57 2008 -0700

    cgroups: add cgroup support for enabling controllers at boot time
    
    The effects of cgroup_disable=foo are:
    
    - foo isn't auto-mounted if you mount all cgroups in a single hierarchy
    - foo isn't visible as an individually mountable subsystem
    
    As a result there will only ever be one call to foo->create(), at init time;
    all processes will stay in this group, and the group will never be mounted on
    a visible hierarchy.  Any additional effects (e.g.  not allocating metadata)
    are up to the foo subsystem.
    
    This doesn't handle early_init subsystems (their "disabled" bit isn't set be,
    but it could easily be extended to do so if any of the early_init systems
    wanted it - I think it would just involve some nastier parameter processing
    since it would occur before the command-line argument parser had been run.
    
    Hugh said:
    
      Ballpark figures, I'm trying to get this question out rather than
      processing the exact numbers: CONFIG_CGROUP_MEM_RES_CTLR adds 15% overhead
      to the affected paths, booting with cgroup_disable=memory cuts that back to
      1% overhead (due to slightly bigger struct page).
    
      I'm no expert on distros, they may have no interest whatever in
      CONFIG_CGROUP_MEM_RES_CTLR=y; and the rest of us can easily build with or
      without it, or apply the cgroup_disable=memory patches.
    
    Unix bench's execl test result on x86_64 was
    
    == just after boot without mounting any cgroup fs.==
    mem_cgorup=off : Execl Throughput       43.0     3150.1      732.6
    mem_cgroup=on  : Execl Throughput       43.0     2932.6      682.0
    ==
    
    [lizf@cn.fujitsu.com: fix boot option parsing]
    Signed-off-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Sudhir Kumar <skumar@linux.vnet.ibm.com>
    Cc: YAMAMOTO Takashi <yamamoto@valinux.co.jp>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 028ba3b523b1..a6a6035a4e1e 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -256,6 +256,7 @@ struct cgroup_subsys {
 	void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);
 	int subsys_id;
 	int active;
+	int disabled;
 	int early_init;
 #define MAX_CGROUP_TYPE_NAMELEN 32
 	const char *name;

commit ffd2d883399cbbb641e55730676ce1ec4845d99d
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Sat Feb 23 15:24:09 2008 -0800

    cgroup: clean up cgroup.h
    
    - replace old name 'cont' with 'cgrp' (Paul Menage did this cleanup for
      cgroup.c in commit bd89aabc6761de1c35b154fe6f914a445d301510)
    - remove a duplicate declaration of cgroup_path()
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 2ebf7afedd9f..028ba3b523b1 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -186,15 +186,15 @@ struct cftype {
 	char name[MAX_CFTYPE_NAME];
 	int private;
 	int (*open) (struct inode *inode, struct file *file);
-	ssize_t (*read) (struct cgroup *cont, struct cftype *cft,
+	ssize_t (*read) (struct cgroup *cgrp, struct cftype *cft,
 			 struct file *file,
 			 char __user *buf, size_t nbytes, loff_t *ppos);
 	/*
 	 * read_uint() is a shortcut for the common case of returning a
 	 * single integer. Use it in place of read()
 	 */
-	u64 (*read_uint) (struct cgroup *cont, struct cftype *cft);
-	ssize_t (*write) (struct cgroup *cont, struct cftype *cft,
+	u64 (*read_uint) (struct cgroup *cgrp, struct cftype *cft);
+	ssize_t (*write) (struct cgroup *cgrp, struct cftype *cft,
 			  struct file *file,
 			  const char __user *buf, size_t nbytes, loff_t *ppos);
 
@@ -203,7 +203,7 @@ struct cftype {
 	 * a single integer (as parsed by simple_strtoull) from
 	 * userspace. Use in place of write(); return 0 or error.
 	 */
-	int (*write_uint) (struct cgroup *cont, struct cftype *cft, u64 val);
+	int (*write_uint) (struct cgroup *cgrp, struct cftype *cft, u64 val);
 
 	int (*release) (struct inode *inode, struct file *file);
 };
@@ -218,41 +218,41 @@ struct cgroup_scanner {
 
 /* Add a new file to the given cgroup directory. Should only be
  * called by subsystems from within a populate() method */
-int cgroup_add_file(struct cgroup *cont, struct cgroup_subsys *subsys,
+int cgroup_add_file(struct cgroup *cgrp, struct cgroup_subsys *subsys,
 		       const struct cftype *cft);
 
 /* Add a set of new files to the given cgroup directory. Should
  * only be called by subsystems from within a populate() method */
-int cgroup_add_files(struct cgroup *cont,
+int cgroup_add_files(struct cgroup *cgrp,
 			struct cgroup_subsys *subsys,
 			const struct cftype cft[],
 			int count);
 
-int cgroup_is_removed(const struct cgroup *cont);
+int cgroup_is_removed(const struct cgroup *cgrp);
 
-int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
+int cgroup_path(const struct cgroup *cgrp, char *buf, int buflen);
 
-int cgroup_task_count(const struct cgroup *cont);
+int cgroup_task_count(const struct cgroup *cgrp);
 
 /* Return true if the cgroup is a descendant of the current cgroup */
-int cgroup_is_descendant(const struct cgroup *cont);
+int cgroup_is_descendant(const struct cgroup *cgrp);
 
 /* Control Group subsystem type. See Documentation/cgroups.txt for details */
 
 struct cgroup_subsys {
 	struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss,
-						  struct cgroup *cont);
-	void (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cont);
-	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cont);
+						  struct cgroup *cgrp);
+	void (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
+	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	int (*can_attach)(struct cgroup_subsys *ss,
-			  struct cgroup *cont, struct task_struct *tsk);
-	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cont,
-			struct cgroup *old_cont, struct task_struct *tsk);
+			  struct cgroup *cgrp, struct task_struct *tsk);
+	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp,
+			struct cgroup *old_cgrp, struct task_struct *tsk);
 	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);
 	void (*exit)(struct cgroup_subsys *ss, struct task_struct *task);
 	int (*populate)(struct cgroup_subsys *ss,
-			struct cgroup *cont);
-	void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cont);
+			struct cgroup *cgrp);
+	void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp);
 	void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);
 	int subsys_id;
 	int active;
@@ -273,9 +273,9 @@ struct cgroup_subsys {
 #undef SUBSYS
 
 static inline struct cgroup_subsys_state *cgroup_subsys_state(
-	struct cgroup *cont, int subsys_id)
+	struct cgroup *cgrp, int subsys_id)
 {
-	return cont->subsys[subsys_id];
+	return cgrp->subsys[subsys_id];
 }
 
 static inline struct cgroup_subsys_state *task_subsys_state(
@@ -290,8 +290,6 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 	return task_subsys_state(task, subsys_id)->cgroup;
 }
 
-int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
-
 int cgroup_clone(struct task_struct *tsk, struct cgroup_subsys *ss);
 
 /* A cgroup_iter should be treated as an opaque object */
@@ -313,10 +311,10 @@ struct cgroup_iter {
  *    - cgroup_scan_tasks() holds the css_set_lock when calling the test_task()
  *      callback, but not while calling the process_task() callback.
  */
-void cgroup_iter_start(struct cgroup *cont, struct cgroup_iter *it);
-struct task_struct *cgroup_iter_next(struct cgroup *cont,
+void cgroup_iter_start(struct cgroup *cgrp, struct cgroup_iter *it);
+struct task_struct *cgroup_iter_next(struct cgroup *cgrp,
 					struct cgroup_iter *it);
-void cgroup_iter_end(struct cgroup *cont, struct cgroup_iter *it);
+void cgroup_iter_end(struct cgroup *cgrp, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
 int cgroup_attach_task(struct cgroup *, struct task_struct *);
 

commit a043e3b2c63445512c5592cbe3c8694f3c655e81
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Sat Feb 23 15:24:09 2008 -0800

    cgroup: fix comments
    
    fix:
    - comments about need_forkexit_callback
    - comments about release agent
    - typo and comment style, etc.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index ff9055fc3d2a..2ebf7afedd9f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -175,7 +175,7 @@ struct css_set {
  *
  *
  * When reading/writing to a file:
- *	- the cgroup to use in file->f_dentry->d_parent->d_fsdata
+ *	- the cgroup to use is file->f_dentry->d_parent->d_fsdata
  *	- the 'cftype' of the file is file->f_dentry->d_fsdata
  */
 

commit 956db3ca0606e78456786ef19fd4dc7a5151a6e1
Author: Cliff Wickman <cpw@sgi.com>
Date:   Thu Feb 7 00:14:43 2008 -0800

    hotplug cpu: move tasks in empty cpusets to parent
    
    This patch corrects a situation that occurs when one disables all the cpus in
    a cpuset.
    
    Currently, the disabled (cpu-less) cpuset inherits the cpus of its parent,
    which is incorrect because it may then overlap its cpu-exclusive sibling.
    
    Tasks of an empty cpuset should be moved to the cpuset which is the parent of
    their current cpuset.  Or if the parent cpuset has no cpus, to its parent,
    etc.
    
    And the empty cpuset should be released (if it is flagged notify_on_release).
    
    Depends on the cgroup_scan_tasks() function (proposed by David Rientjes) to
    iterate through all tasks in the cpu-less cpuset.  We are deliberately
    avoiding a walk of the tasklist.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Cliff Wickman <cpw@sgi.com>
    Cc: Paul Menage <menage@google.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 8675c691d3e2..ff9055fc3d2a 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -318,6 +318,7 @@ struct task_struct *cgroup_iter_next(struct cgroup *cont,
 					struct cgroup_iter *it);
 void cgroup_iter_end(struct cgroup *cont, struct cgroup_iter *it);
 int cgroup_scan_tasks(struct cgroup_scanner *scan);
+int cgroup_attach_task(struct cgroup *, struct task_struct *);
 
 #else /* !CONFIG_CGROUPS */
 

commit 31a7df01fd0cd786f60873a921aecafac148c290
Author: Cliff Wickman <cpw@sgi.com>
Date:   Thu Feb 7 00:14:42 2008 -0800

    cgroups: mechanism to process each task in a cgroup
    
    Provide cgroup_scan_tasks(), which iterates through every task in a cgroup,
    calling a test function and a process function for each.  And call the process
    function without holding the css_set_lock lock.
    
    The idea is David Rientjes', predicting that such a function will make it much
    easier in the future to extend things that require access to each task in a
    cgroup without holding the lock,
    
    [akpm@linux-foundation.org: cleanup]
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Cliff Wickman <cpw@sgi.com>
    Cc: Paul Menage <menage@google.com>
    Cc: Paul Jackson <pj@sgi.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index d8e92223a79c..8675c691d3e2 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -14,6 +14,7 @@
 #include <linux/nodemask.h>
 #include <linux/rcupdate.h>
 #include <linux/cgroupstats.h>
+#include <linux/prio_heap.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -207,6 +208,14 @@ struct cftype {
 	int (*release) (struct inode *inode, struct file *file);
 };
 
+struct cgroup_scanner {
+	struct cgroup *cg;
+	int (*test_task)(struct task_struct *p, struct cgroup_scanner *scan);
+	void (*process_task)(struct task_struct *p,
+			struct cgroup_scanner *scan);
+	struct ptr_heap *heap;
+};
+
 /* Add a new file to the given cgroup directory. Should only be
  * called by subsystems from within a populate() method */
 int cgroup_add_file(struct cgroup *cont, struct cgroup_subsys *subsys,
@@ -299,11 +308,16 @@ struct cgroup_iter {
  *    returns NULL or until you want to end the iteration
  *
  * 3) call cgroup_iter_end() to destroy the iterator.
+ *
+ * Or, call cgroup_scan_tasks() to iterate through every task in a cpuset.
+ *    - cgroup_scan_tasks() holds the css_set_lock when calling the test_task()
+ *      callback, but not while calling the process_task() callback.
  */
 void cgroup_iter_start(struct cgroup *cont, struct cgroup_iter *it);
 struct task_struct *cgroup_iter_next(struct cgroup *cont,
 					struct cgroup_iter *it);
 void cgroup_iter_end(struct cgroup *cont, struct cgroup_iter *it);
+int cgroup_scan_tasks(struct cgroup_scanner *scan);
 
 #else /* !CONFIG_CGROUPS */
 

commit 4fca88c87b7969c698912e2de9b1b31088c777cb
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Thu Feb 7 00:14:27 2008 -0800

    memory cgroup enhancements: add- pre_destroy() handler
    
    Add a handler "pre_destroy" to cgroup_subsys.  It is called before
    cgroup_rmdir() checks all subsys's refcnt.
    
    I think this is useful for subsys which have some extra refs even if there
    are no tasks in cgroup.  By adding pre_destroy(), the kernel keeps the rule
    "destroy() against subsystem is called only when refcnt=0." and allows css
    ref to be used by other objects than tasks.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Paul Menage <menage@google.com>
    Cc: Pavel Emelianov <xemul@openvz.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Vaidyanathan Srinivasan <svaidy@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 87479328d46d..d8e92223a79c 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -233,6 +233,7 @@ int cgroup_is_descendant(const struct cgroup *cont);
 struct cgroup_subsys {
 	struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss,
 						  struct cgroup *cont);
+	void (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cont);
 	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cont);
 	int (*can_attach)(struct cgroup_subsys *ss,
 			  struct cgroup *cont, struct task_struct *tsk);

commit 846c7bb055747989891f5cd2bb6e8d56243ba1e7
Author: Balbir Singh <balbir@linux.vnet.ibm.com>
Date:   Thu Oct 18 23:39:44 2007 -0700

    Add cgroupstats
    
    This patch is inspired by the discussion at
    http://lkml.org/lkml/2007/4/11/187 and implements per cgroup statistics
    as suggested by Andrew Morton in http://lkml.org/lkml/2007/4/11/263.  The
    patch is on top of 2.6.21-mm1 with Paul's cgroups v9 patches (forward
    ported)
    
    This patch implements per cgroup statistics infrastructure and re-uses
    code from the taskstats interface.  A new set of cgroup operations are
    registered with commands and attributes.  It should be very easy to
    *extend* per cgroup statistics, by adding members to the cgroupstats
    structure.
    
    The current model for cgroupstats is a pull, a push model (to post
    statistics on interesting events), should be very easy to add.  Currently
    user space requests for statistics by passing the cgroup file
    descriptor.  Statistics about the state of all the tasks in the cgroup
    is returned to user space.
    
    TODO's/NOTE:
    
    This patch provides an infrastructure for implementing cgroup statistics.
    Based on the needs of each controller, we can incrementally add more statistics,
    event based support for notification of statistics, accumulation of taskstats
    into cgroup statistics in the future.
    
    Sample output
    
    # ./cgroupstats -C /cgroup/a
    sleeping 2, blocked 0, running 1, stopped 0, uninterruptible 0
    
    # ./cgroupstats -C /cgroup/
    sleeping 154, blocked 0, running 0, stopped 0, uninterruptible 0
    
    If the approach looks good, I'll enhance and post the user space utility for
    the same
    
    Feedback, comments, test results are always welcome!
    
    [akpm@linux-foundation.org: build fix]
    Signed-off-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: Jay Lan <jlan@engr.sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 9e9b7efa180b..87479328d46d 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -13,6 +13,7 @@
 #include <linux/cpumask.h>
 #include <linux/nodemask.h>
 #include <linux/rcupdate.h>
+#include <linux/cgroupstats.h>
 
 #ifdef CONFIG_CGROUPS
 
@@ -29,6 +30,8 @@ extern void cgroup_fork(struct task_struct *p);
 extern void cgroup_fork_callbacks(struct task_struct *p);
 extern void cgroup_post_fork(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
+extern int cgroupstats_build(struct cgroupstats *stats,
+				struct dentry *dentry);
 
 extern struct file_operations proc_cgroup_operations;
 
@@ -313,6 +316,11 @@ static inline void cgroup_exit(struct task_struct *p, int callbacks) {}
 
 static inline void cgroup_lock(void) {}
 static inline void cgroup_unlock(void) {}
+static inline int cgroupstats_build(struct cgroupstats *stats,
+					struct dentry *dentry)
+{
+	return -EINVAL;
+}
 
 #endif /* !CONFIG_CGROUPS */
 

commit 81a6a5cdd2c5cd70874b88afe524ab09e9e869af
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:38 2007 -0700

    Task Control Groups: automatic userspace notification of idle cgroups
    
    Add the following files to the cgroup filesystem:
    
    notify_on_release - configures/reports whether the cgroup subsystem should
    attempt to run a release script when this cgroup becomes unused
    
    release_agent - configures/reports the release agent to be used for this
    hierarchy (top level in each hierarchy only)
    
    releasable - reports whether this cgroup would have been auto-released if
    notify_on_release was true and a release agent was configured (mainly useful
    for debugging)
    
    To avoid locking issues, invoking the userspace release agent is done via a
    workqueue task; cgroups that need to have their release agents invoked by
    the workqueue task are linked on to a list.
    
    [pj@sgi.com: Need to include kmod.h]
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Paul Jackson <pj@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 836b3557bb76..9e9b7efa180b 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -77,10 +77,11 @@ static inline void css_get(struct cgroup_subsys_state *css)
  * css_get()
  */
 
+extern void __css_put(struct cgroup_subsys_state *css);
 static inline void css_put(struct cgroup_subsys_state *css)
 {
 	if (!test_bit(CSS_ROOT, &css->flags))
-		atomic_dec(&css->refcnt);
+		__css_put(css);
 }
 
 struct cgroup {
@@ -112,6 +113,13 @@ struct cgroup {
 	 * tasks in this cgroup. Protected by css_set_lock
 	 */
 	struct list_head css_sets;
+
+	/*
+	 * Linked list running through all cgroups that can
+	 * potentially be reaped by the release agent. Protected by
+	 * release_list_lock
+	 */
+	struct list_head release_list;
 };
 
 /* A css_set is a structure holding pointers to a set of
@@ -293,7 +301,6 @@ struct task_struct *cgroup_iter_next(struct cgroup *cont,
 					struct cgroup_iter *it);
 void cgroup_iter_end(struct cgroup *cont, struct cgroup_iter *it);
 
-
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }

commit 817929ec274bcfe771586d338bb31d1659615686
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:36 2007 -0700

    Task Control Groups: shared cgroup subsystem group arrays
    
    Replace the struct css_set embedded in task_struct with a pointer; all tasks
    that have the same set of memberships across all hierarchies will share a
    css_set object, and will be linked via their css_sets field to the "tasks"
    list_head in the css_set.
    
    Assuming that many tasks share the same cgroup assignments, this reduces
    overall space usage and keeps the size of the task_struct down (three pointers
    added to task_struct compared to a non-cgroups kernel, no matter how many
    subsystems are registered).
    
    [akpm@linux-foundation.org: fix a printk]
    [akpm@linux-foundation.org: build fix]
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index a9553568118f..836b3557bb76 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -27,10 +27,19 @@ extern void cgroup_lock(void);
 extern void cgroup_unlock(void);
 extern void cgroup_fork(struct task_struct *p);
 extern void cgroup_fork_callbacks(struct task_struct *p);
+extern void cgroup_post_fork(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 
 extern struct file_operations proc_cgroup_operations;
 
+/* Define the enumeration of all cgroup subsystems */
+#define SUBSYS(_x) _x ## _subsys_id,
+enum cgroup_subsys_id {
+#include <linux/cgroup_subsys.h>
+	CGROUP_SUBSYS_COUNT
+};
+#undef SUBSYS
+
 /* Per-subsystem/per-cgroup state maintained by the system. */
 struct cgroup_subsys_state {
 	/* The cgroup that this subsystem is attached to. Useful
@@ -97,6 +106,52 @@ struct cgroup {
 
 	struct cgroupfs_root *root;
 	struct cgroup *top_cgroup;
+
+	/*
+	 * List of cg_cgroup_links pointing at css_sets with
+	 * tasks in this cgroup. Protected by css_set_lock
+	 */
+	struct list_head css_sets;
+};
+
+/* A css_set is a structure holding pointers to a set of
+ * cgroup_subsys_state objects. This saves space in the task struct
+ * object and speeds up fork()/exit(), since a single inc/dec and a
+ * list_add()/del() can bump the reference count on the entire
+ * cgroup set for a task.
+ */
+
+struct css_set {
+
+	/* Reference count */
+	struct kref ref;
+
+	/*
+	 * List running through all cgroup groups. Protected by
+	 * css_set_lock
+	 */
+	struct list_head list;
+
+	/*
+	 * List running through all tasks using this cgroup
+	 * group. Protected by css_set_lock
+	 */
+	struct list_head tasks;
+
+	/*
+	 * List of cg_cgroup_link objects on link chains from
+	 * cgroups referenced from this css_set. Protected by
+	 * css_set_lock
+	 */
+	struct list_head cg_links;
+
+	/*
+	 * Set of subsystem states, one for each subsystem. This array
+	 * is immutable after creation apart from the init_css_set
+	 * during subsystem registration (at boot time).
+	 */
+	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
+
 };
 
 /* struct cftype:
@@ -157,15 +212,7 @@ int cgroup_is_removed(const struct cgroup *cont);
 
 int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
 
-int __cgroup_task_count(const struct cgroup *cont);
-static inline int cgroup_task_count(const struct cgroup *cont)
-{
-	int task_count;
-	rcu_read_lock();
-	task_count = __cgroup_task_count(cont);
-	rcu_read_unlock();
-	return task_count;
-}
+int cgroup_task_count(const struct cgroup *cont);
 
 /* Return true if the cgroup is a descendant of the current cgroup */
 int cgroup_is_descendant(const struct cgroup *cont);
@@ -213,7 +260,7 @@ static inline struct cgroup_subsys_state *cgroup_subsys_state(
 static inline struct cgroup_subsys_state *task_subsys_state(
 	struct task_struct *task, int subsys_id)
 {
-	return rcu_dereference(task->cgroups.subsys[subsys_id]);
+	return rcu_dereference(task->cgroups->subsys[subsys_id]);
 }
 
 static inline struct cgroup* task_cgroup(struct task_struct *task,
@@ -226,6 +273,27 @@ int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
 
 int cgroup_clone(struct task_struct *tsk, struct cgroup_subsys *ss);
 
+/* A cgroup_iter should be treated as an opaque object */
+struct cgroup_iter {
+	struct list_head *cg_link;
+	struct list_head *task;
+};
+
+/* To iterate across the tasks in a cgroup:
+ *
+ * 1) call cgroup_iter_start to intialize an iterator
+ *
+ * 2) call cgroup_iter_next() to retrieve member tasks until it
+ *    returns NULL or until you want to end the iteration
+ *
+ * 3) call cgroup_iter_end() to destroy the iterator.
+ */
+void cgroup_iter_start(struct cgroup *cont, struct cgroup_iter *it);
+struct task_struct *cgroup_iter_next(struct cgroup *cont,
+					struct cgroup_iter *it);
+void cgroup_iter_end(struct cgroup *cont, struct cgroup_iter *it);
+
+
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }
@@ -233,6 +301,7 @@ static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_init_smp(void) {}
 static inline void cgroup_fork(struct task_struct *p) {}
 static inline void cgroup_fork_callbacks(struct task_struct *p) {}
+static inline void cgroup_post_fork(struct task_struct *p) {}
 static inline void cgroup_exit(struct task_struct *p, int callbacks) {}
 
 static inline void cgroup_lock(void) {}

commit a424316ca154317367c7ddf89997d1c80e4a8051
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:35 2007 -0700

    Task Control Groups: add procfs interface
    
    Add:
    
    /proc/cgroups - general system info
    
    /proc/*/cgroup - per-task cgroup membership info
    
    [a.p.zijlstra@chello.nl: cgroups: bdi init hooks]
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index b21cf093ac62..a9553568118f 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -29,6 +29,8 @@ extern void cgroup_fork(struct task_struct *p);
 extern void cgroup_fork_callbacks(struct task_struct *p);
 extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 
+extern struct file_operations proc_cgroup_operations;
+
 /* Per-subsystem/per-cgroup state maintained by the system. */
 struct cgroup_subsys_state {
 	/* The cgroup that this subsystem is attached to. Useful

commit 697f41610863c9264a7ae26dac9a387c9dda8c84
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:34 2007 -0700

    Task Control Groups: add cgroup_clone() interface
    
    Add support for cgroup_clone(), a way to create new cgroups intended to
    be used for systems such as namespace unsharing.  A new subsystem callback,
    post_clone(), is added to allow subsystems to automatically configure cloned
    cgroups.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 792ad74be170..b21cf093ac62 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -182,6 +182,7 @@ struct cgroup_subsys {
 	void (*exit)(struct cgroup_subsys *ss, struct task_struct *task);
 	int (*populate)(struct cgroup_subsys *ss,
 			struct cgroup *cont);
+	void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cont);
 	void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);
 	int subsys_id;
 	int active;
@@ -221,6 +222,8 @@ static inline struct cgroup* task_cgroup(struct task_struct *task,
 
 int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
 
+int cgroup_clone(struct task_struct *tsk, struct cgroup_subsys *ss);
+
 #else /* !CONFIG_CGROUPS */
 
 static inline int cgroup_init_early(void) { return 0; }

commit b4f48b6363c81ca743ef46943ef23fd72e60f679
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:33 2007 -0700

    Task Control Groups: add fork()/exit() hooks
    
    This adds the necessary hooks to the fork() and exit() paths to ensure
    that new children inherit their parent's cgroup assignments, and that
    exiting processes release reference counts on their cgroups.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e95143c884b2..792ad74be170 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -25,6 +25,9 @@ extern int cgroup_init(void);
 extern void cgroup_init_smp(void);
 extern void cgroup_lock(void);
 extern void cgroup_unlock(void);
+extern void cgroup_fork(struct task_struct *p);
+extern void cgroup_fork_callbacks(struct task_struct *p);
+extern void cgroup_exit(struct task_struct *p, int run_callbacks);
 
 /* Per-subsystem/per-cgroup state maintained by the system. */
 struct cgroup_subsys_state {
@@ -223,6 +226,9 @@ int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
 static inline int cgroup_init_early(void) { return 0; }
 static inline int cgroup_init(void) { return 0; }
 static inline void cgroup_init_smp(void) {}
+static inline void cgroup_fork(struct task_struct *p) {}
+static inline void cgroup_fork_callbacks(struct task_struct *p) {}
+static inline void cgroup_exit(struct task_struct *p, int callbacks) {}
 
 static inline void cgroup_lock(void) {}
 static inline void cgroup_unlock(void) {}

commit 355e0c48b757b7fcc79ccb98fda8105ed37a1598
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:33 2007 -0700

    Add cgroup write_uint() helper method
    
    Add write_uint() helper method for cgroup subsystems
    
    This helper is analagous to the read_uint() helper method for
    reporting u64 values to userspace. It's designed to reduce the amount
    of boilerplate requierd for creating new cgroup subsystems.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index e2dd44f68f97..e95143c884b2 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -125,6 +125,14 @@ struct cftype {
 	ssize_t (*write) (struct cgroup *cont, struct cftype *cft,
 			  struct file *file,
 			  const char __user *buf, size_t nbytes, loff_t *ppos);
+
+	/*
+	 * write_uint() is a shortcut for the common case of accepting
+	 * a single integer (as parsed by simple_strtoull) from
+	 * userspace. Use in place of write(); return 0 or error.
+	 */
+	int (*write_uint) (struct cgroup *cont, struct cftype *cft, u64 val);
+
 	int (*release) (struct inode *inode, struct file *file);
 };
 

commit bbcb81d09104f0d440974b994c1fc508ccbe9503
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:32 2007 -0700

    Task Control Groups: add tasks file interface
    
    Add the per-directory "tasks" file for cgroupfs mounts; this allows the
    user to determine which tasks are members of a cgroup by reading a
    cgroup's "tasks", and to move a task into a cgroup by writing its pid to
    its "tasks".
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
index 60735dcf427a..e2dd44f68f97 100644
--- a/include/linux/cgroup.h
+++ b/include/linux/cgroup.h
@@ -144,6 +144,16 @@ int cgroup_is_removed(const struct cgroup *cont);
 
 int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
 
+int __cgroup_task_count(const struct cgroup *cont);
+static inline int cgroup_task_count(const struct cgroup *cont)
+{
+	int task_count;
+	rcu_read_lock();
+	task_count = __cgroup_task_count(cont);
+	rcu_read_unlock();
+	return task_count;
+}
+
 /* Return true if the cgroup is a descendant of the current cgroup */
 int cgroup_is_descendant(const struct cgroup *cont);
 

commit ddbcc7e8e50aefe467c01cac3dec71f118cd8ac2
Author: Paul Menage <menage@google.com>
Date:   Thu Oct 18 23:39:30 2007 -0700

    Task Control Groups: basic task cgroup framework
    
    Generic Process Control Groups
    --------------------------
    
    There have recently been various proposals floating around for
    resource management/accounting and other task grouping subsystems in
    the kernel, including ResGroups, User BeanCounters, NSProxy
    cgroups, and others.  These all need the basic abstraction of being
    able to group together multiple processes in an aggregate, in order to
    track/limit the resources permitted to those processes, or control
    other behaviour of the processes, and all implement this grouping in
    different ways.
    
    This patchset provides a framework for tracking and grouping processes
    into arbitrary "cgroups" and assigning arbitrary state to those
    groupings, in order to control the behaviour of the cgroup as an
    aggregate.
    
    The intention is that the various resource management and
    virtualization/cgroup efforts can also become task cgroup
    clients, with the result that:
    
    - the userspace APIs are (somewhat) normalised
    
    - it's easier to test e.g. the ResGroups CPU controller in
     conjunction with the BeanCounters memory controller, or use either of
    them as the resource-control portion of a virtual server system.
    
    - the additional kernel footprint of any of the competing resource
     management systems is substantially reduced, since it doesn't need
     to provide process grouping/containment, hence improving their
     chances of getting into the kernel
    
    This patch:
    
    Add the main task cgroups framework - the cgroup filesystem, and the
    basic structures for tracking membership and associating subsystem state
    objects to tasks.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Serge E. Hallyn <serue@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Srivatsa Vaddagiri <vatsa@in.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h
new file mode 100644
index 000000000000..60735dcf427a
--- /dev/null
+++ b/include/linux/cgroup.h
@@ -0,0 +1,214 @@
+#ifndef _LINUX_CGROUP_H
+#define _LINUX_CGROUP_H
+/*
+ *  cgroup interface
+ *
+ *  Copyright (C) 2003 BULL SA
+ *  Copyright (C) 2004-2006 Silicon Graphics, Inc.
+ *
+ */
+
+#include <linux/sched.h>
+#include <linux/kref.h>
+#include <linux/cpumask.h>
+#include <linux/nodemask.h>
+#include <linux/rcupdate.h>
+
+#ifdef CONFIG_CGROUPS
+
+struct cgroupfs_root;
+struct cgroup_subsys;
+struct inode;
+
+extern int cgroup_init_early(void);
+extern int cgroup_init(void);
+extern void cgroup_init_smp(void);
+extern void cgroup_lock(void);
+extern void cgroup_unlock(void);
+
+/* Per-subsystem/per-cgroup state maintained by the system. */
+struct cgroup_subsys_state {
+	/* The cgroup that this subsystem is attached to. Useful
+	 * for subsystems that want to know about the cgroup
+	 * hierarchy structure */
+	struct cgroup *cgroup;
+
+	/* State maintained by the cgroup system to allow
+	 * subsystems to be "busy". Should be accessed via css_get()
+	 * and css_put() */
+
+	atomic_t refcnt;
+
+	unsigned long flags;
+};
+
+/* bits in struct cgroup_subsys_state flags field */
+enum {
+	CSS_ROOT, /* This CSS is the root of the subsystem */
+};
+
+/*
+ * Call css_get() to hold a reference on the cgroup;
+ *
+ */
+
+static inline void css_get(struct cgroup_subsys_state *css)
+{
+	/* We don't need to reference count the root state */
+	if (!test_bit(CSS_ROOT, &css->flags))
+		atomic_inc(&css->refcnt);
+}
+/*
+ * css_put() should be called to release a reference taken by
+ * css_get()
+ */
+
+static inline void css_put(struct cgroup_subsys_state *css)
+{
+	if (!test_bit(CSS_ROOT, &css->flags))
+		atomic_dec(&css->refcnt);
+}
+
+struct cgroup {
+	unsigned long flags;		/* "unsigned long" so bitops work */
+
+	/* count users of this cgroup. >0 means busy, but doesn't
+	 * necessarily indicate the number of tasks in the
+	 * cgroup */
+	atomic_t count;
+
+	/*
+	 * We link our 'sibling' struct into our parent's 'children'.
+	 * Our children link their 'sibling' into our 'children'.
+	 */
+	struct list_head sibling;	/* my parent's children */
+	struct list_head children;	/* my children */
+
+	struct cgroup *parent;	/* my parent */
+	struct dentry *dentry;	  	/* cgroup fs entry */
+
+	/* Private pointers for each registered subsystem */
+	struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT];
+
+	struct cgroupfs_root *root;
+	struct cgroup *top_cgroup;
+};
+
+/* struct cftype:
+ *
+ * The files in the cgroup filesystem mostly have a very simple read/write
+ * handling, some common function will take care of it. Nevertheless some cases
+ * (read tasks) are special and therefore I define this structure for every
+ * kind of file.
+ *
+ *
+ * When reading/writing to a file:
+ *	- the cgroup to use in file->f_dentry->d_parent->d_fsdata
+ *	- the 'cftype' of the file is file->f_dentry->d_fsdata
+ */
+
+#define MAX_CFTYPE_NAME 64
+struct cftype {
+	/* By convention, the name should begin with the name of the
+	 * subsystem, followed by a period */
+	char name[MAX_CFTYPE_NAME];
+	int private;
+	int (*open) (struct inode *inode, struct file *file);
+	ssize_t (*read) (struct cgroup *cont, struct cftype *cft,
+			 struct file *file,
+			 char __user *buf, size_t nbytes, loff_t *ppos);
+	/*
+	 * read_uint() is a shortcut for the common case of returning a
+	 * single integer. Use it in place of read()
+	 */
+	u64 (*read_uint) (struct cgroup *cont, struct cftype *cft);
+	ssize_t (*write) (struct cgroup *cont, struct cftype *cft,
+			  struct file *file,
+			  const char __user *buf, size_t nbytes, loff_t *ppos);
+	int (*release) (struct inode *inode, struct file *file);
+};
+
+/* Add a new file to the given cgroup directory. Should only be
+ * called by subsystems from within a populate() method */
+int cgroup_add_file(struct cgroup *cont, struct cgroup_subsys *subsys,
+		       const struct cftype *cft);
+
+/* Add a set of new files to the given cgroup directory. Should
+ * only be called by subsystems from within a populate() method */
+int cgroup_add_files(struct cgroup *cont,
+			struct cgroup_subsys *subsys,
+			const struct cftype cft[],
+			int count);
+
+int cgroup_is_removed(const struct cgroup *cont);
+
+int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
+
+/* Return true if the cgroup is a descendant of the current cgroup */
+int cgroup_is_descendant(const struct cgroup *cont);
+
+/* Control Group subsystem type. See Documentation/cgroups.txt for details */
+
+struct cgroup_subsys {
+	struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss,
+						  struct cgroup *cont);
+	void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cont);
+	int (*can_attach)(struct cgroup_subsys *ss,
+			  struct cgroup *cont, struct task_struct *tsk);
+	void (*attach)(struct cgroup_subsys *ss, struct cgroup *cont,
+			struct cgroup *old_cont, struct task_struct *tsk);
+	void (*fork)(struct cgroup_subsys *ss, struct task_struct *task);
+	void (*exit)(struct cgroup_subsys *ss, struct task_struct *task);
+	int (*populate)(struct cgroup_subsys *ss,
+			struct cgroup *cont);
+	void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);
+	int subsys_id;
+	int active;
+	int early_init;
+#define MAX_CGROUP_TYPE_NAMELEN 32
+	const char *name;
+
+	/* Protected by RCU */
+	struct cgroupfs_root *root;
+
+	struct list_head sibling;
+
+	void *private;
+};
+
+#define SUBSYS(_x) extern struct cgroup_subsys _x ## _subsys;
+#include <linux/cgroup_subsys.h>
+#undef SUBSYS
+
+static inline struct cgroup_subsys_state *cgroup_subsys_state(
+	struct cgroup *cont, int subsys_id)
+{
+	return cont->subsys[subsys_id];
+}
+
+static inline struct cgroup_subsys_state *task_subsys_state(
+	struct task_struct *task, int subsys_id)
+{
+	return rcu_dereference(task->cgroups.subsys[subsys_id]);
+}
+
+static inline struct cgroup* task_cgroup(struct task_struct *task,
+					       int subsys_id)
+{
+	return task_subsys_state(task, subsys_id)->cgroup;
+}
+
+int cgroup_path(const struct cgroup *cont, char *buf, int buflen);
+
+#else /* !CONFIG_CGROUPS */
+
+static inline int cgroup_init_early(void) { return 0; }
+static inline int cgroup_init(void) { return 0; }
+static inline void cgroup_init_smp(void) {}
+
+static inline void cgroup_lock(void) {}
+static inline void cgroup_unlock(void) {}
+
+#endif /* !CONFIG_CGROUPS */
+
+#endif /* _LINUX_CGROUP_H */
