commit 891584f48a9084ba462f10da4c6bb28b6181b543
Author: Guillaume Nault <gnault@redhat.com>
Date:   Fri Aug 2 17:15:03 2019 +0200

    inet: frags: re-introduce skb coalescing for local delivery
    
    Before commit d4289fcc9b16 ("net: IP6 defrag: use rbtrees for IPv6
    defrag"), a netperf UDP_STREAM test[0] using big IPv6 datagrams (thus
    generating many fragments) and running over an IPsec tunnel, reported
    more than 6Gbps throughput. After that patch, the same test gets only
    9Mbps when receiving on a be2net nic (driver can make a big difference
    here, for example, ixgbe doesn't seem to be affected).
    
    By reusing the IPv4 defragmentation code, IPv6 lost fragment coalescing
    (IPv4 fragment coalescing was dropped by commit 14fe22e33462 ("Revert
    "ipv4: use skb coalescing in defragmentation"")).
    
    Without fragment coalescing, be2net runs out of Rx ring entries and
    starts to drop frames (ethtool reports rx_drops_no_frags errors). Since
    the netperf traffic is only composed of UDP fragments, any lost packet
    prevents reassembly of the full datagram. Therefore, fragments which
    have no possibility to ever get reassembled pile up in the reassembly
    queue, until the memory accounting exeeds the threshold. At that point
    no fragment is accepted anymore, which effectively discards all
    netperf traffic.
    
    When reassembly timeout expires, some stale fragments are removed from
    the reassembly queue, so a few packets can be received, reassembled
    and delivered to the netperf receiver. But the nic still drops frames
    and soon the reassembly queue gets filled again with stale fragments.
    These long time frames where no datagram can be received explain why
    the performance drop is so significant.
    
    Re-introducing fragment coalescing is enough to get the initial
    performances again (6.6Gbps with be2net): driver doesn't drop frames
    anymore (no more rx_drops_no_frags errors) and the reassembly engine
    works at full speed.
    
    This patch is quite conservative and only coalesces skbs for local
    IPv4 and IPv6 delivery (in order to avoid changing skb geometry when
    forwarding). Coalescing could be extended in the future if need be, as
    more scenarios would probably benefit from it.
    
    [0]: Test configuration
    Sender:
    ip xfrm policy flush
    ip xfrm state flush
    ip xfrm state add src fc00:1::1 dst fc00:2::1 proto esp spi 0x1000 aead 'rfc4106(gcm(aes))' 0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b 96 mode transport sel src fc00:1::1 dst fc00:2::1
    ip xfrm policy add src fc00:1::1 dst fc00:2::1 dir in tmpl src fc00:1::1 dst fc00:2::1 proto esp mode transport action allow
    ip xfrm state add src fc00:2::1 dst fc00:1::1 proto esp spi 0x1001 aead 'rfc4106(gcm(aes))' 0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b 96 mode transport sel src fc00:2::1 dst fc00:1::1
    ip xfrm policy add src fc00:2::1 dst fc00:1::1 dir out tmpl src fc00:2::1 dst fc00:1::1 proto esp mode transport action allow
    netserver -D -L fc00:2::1
    
    Receiver:
    ip xfrm policy flush
    ip xfrm state flush
    ip xfrm state add src fc00:2::1 dst fc00:1::1 proto esp spi 0x1001 aead 'rfc4106(gcm(aes))' 0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b 96 mode transport sel src fc00:2::1 dst fc00:1::1
    ip xfrm policy add src fc00:2::1 dst fc00:1::1 dir in tmpl src fc00:2::1 dst fc00:1::1 proto esp mode transport action allow
    ip xfrm state add src fc00:1::1 dst fc00:2::1 proto esp spi 0x1000 aead 'rfc4106(gcm(aes))' 0x0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b 96 mode transport sel src fc00:1::1 dst fc00:2::1
    ip xfrm policy add src fc00:1::1 dst fc00:2::1 dir out tmpl src fc00:1::1 dst fc00:2::1 proto esp mode transport action allow
    netperf -H fc00:2::1 -f k -P 0 -L fc00:1::1 -l 60 -t UDP_STREAM -I 99,5 -i 5,5 -T5,5 -6
    
    Signed-off-by: Guillaume Nault <gnault@redhat.com>
    Acked-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 010f26b31c89..bac79e817776 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -171,7 +171,7 @@ int inet_frag_queue_insert(struct inet_frag_queue *q, struct sk_buff *skb,
 void *inet_frag_reasm_prepare(struct inet_frag_queue *q, struct sk_buff *skb,
 			      struct sk_buff *parent);
 void inet_frag_reasm_finish(struct inet_frag_queue *q, struct sk_buff *head,
-			    void *reasm_data);
+			    void *reasm_data, bool try_coalesce);
 struct sk_buff *inet_frag_pull_head(struct inet_frag_queue *q);
 
 #endif

commit 08003d0b63a63bebaccca90e2f1d628dfd66cd4d
Author: Qian Cai <cai@lca.pw>
Date:   Thu Jun 20 10:52:40 2019 -0400

    inet: fix compilation warnings in fqdir_pre_exit()
    
    The linux-next commit "inet: fix various use-after-free in defrags
    units" [1] introduced compilation warnings,
    
    ./include/net/inet_frag.h:117:1: warning: 'inline' is not at beginning
    of declaration [-Wold-style-declaration]
     static void inline fqdir_pre_exit(struct fqdir *fqdir)
     ^~~~~~
    In file included from ./include/net/netns/ipv4.h:10,
                     from ./include/net/net_namespace.h:20,
                     from ./include/linux/netdevice.h:38,
                     from ./include/linux/icmpv6.h:13,
                     from ./include/linux/ipv6.h:86,
                     from ./include/net/ipv6.h:12,
                     from ./include/rdma/ib_verbs.h:51,
                     from ./include/linux/mlx5/device.h:37,
                     from ./include/linux/mlx5/driver.h:51,
                     from
    drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:37:
    
    [1] https://lore.kernel.org/netdev/20190618180900.88939-3-edumazet@google.com/
    
    Signed-off-by: Qian Cai <cai@lca.pw>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 46574d996f1d..010f26b31c89 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -114,7 +114,7 @@ void inet_frags_fini(struct inet_frags *);
 
 int fqdir_init(struct fqdir **fqdirp, struct inet_frags *f, struct net *net);
 
-static void inline fqdir_pre_exit(struct fqdir *fqdir)
+static inline void fqdir_pre_exit(struct fqdir *fqdir)
 {
 	fqdir->high_thresh = 0; /* prevent creation of new frags */
 	fqdir->dead = true;

commit d5dd88794a13c2f24cce31abad7a0a6c5e0ed2db
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Jun 18 11:09:00 2019 -0700

    inet: fix various use-after-free in defrags units
    
    syzbot reported another issue caused by my recent patches. [1]
    
    The issue here is that fqdir_exit() is initiating a work queue
    and immediately returns. A bit later cleanup_net() was able
    to free the MIB (percpu data) and the whole struct net was freed,
    but we had active frag timers that fired and triggered use-after-free.
    
    We need to make sure that timers can catch fqdir->dead being set,
    to bailout.
    
    Since RCU is used for the reader side, this means
    we want to respect an RCU grace period between these operations :
    
    1) qfdir->dead = 1;
    
    2) netns dismantle (freeing of various data structure)
    
    This patch uses new new (struct pernet_operations)->pre_exit
    infrastructure to ensures a full RCU grace period
    happens between fqdir_pre_exit() and fqdir_exit()
    
    This also means we can use a regular work queue, we no
    longer need rcu_work.
    
    Tested:
    
    $ time for i in {1..1000}; do unshare -n /bin/false;done
    
    real    0m2.585s
    user    0m0.160s
    sys     0m2.214s
    
    [1]
    
    BUG: KASAN: use-after-free in ip_expire+0x73e/0x800 net/ipv4/ip_fragment.c:152
    Read of size 8 at addr ffff88808b9fe330 by task syz-executor.4/11860
    
    CPU: 1 PID: 11860 Comm: syz-executor.4 Not tainted 5.2.0-rc2+ #22
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x172/0x1f0 lib/dump_stack.c:113
     print_address_description.cold+0x7c/0x20d mm/kasan/report.c:188
     __kasan_report.cold+0x1b/0x40 mm/kasan/report.c:317
     kasan_report+0x12/0x20 mm/kasan/common.c:614
     __asan_report_load8_noabort+0x14/0x20 mm/kasan/generic_report.c:132
     ip_expire+0x73e/0x800 net/ipv4/ip_fragment.c:152
     call_timer_fn+0x193/0x720 kernel/time/timer.c:1322
     expire_timers kernel/time/timer.c:1366 [inline]
     __run_timers kernel/time/timer.c:1685 [inline]
     __run_timers kernel/time/timer.c:1653 [inline]
     run_timer_softirq+0x66f/0x1740 kernel/time/timer.c:1698
     __do_softirq+0x25c/0x94c kernel/softirq.c:293
     invoke_softirq kernel/softirq.c:374 [inline]
     irq_exit+0x180/0x1d0 kernel/softirq.c:414
     exiting_irq arch/x86/include/asm/apic.h:536 [inline]
     smp_apic_timer_interrupt+0x13b/0x550 arch/x86/kernel/apic/apic.c:1068
     apic_timer_interrupt+0xf/0x20 arch/x86/entry/entry_64.S:806
     </IRQ>
    RIP: 0010:tomoyo_domain_quota_is_ok+0x131/0x540 security/tomoyo/util.c:1035
    Code: 24 4c 3b 65 d0 0f 84 9c 00 00 00 e8 19 1d 73 fe 49 8d 7c 24 18 48 ba 00 00 00 00 00 fc ff df 48 89 f8 48 c1 e8 03 0f b6 04 10 <48> 89 fa 83 e2 07 38 d0 7f 08 84 c0 0f 85 69 03 00 00 41 0f b6 5c
    RSP: 0018:ffff88806ae079c0 EFLAGS: 00000a02 ORIG_RAX: ffffffffffffff13
    RAX: 0000000000000000 RBX: 0000000000000010 RCX: ffffc9000e655000
    RDX: dffffc0000000000 RSI: ffffffff82fd88a7 RDI: ffff888086202398
    RBP: ffff88806ae07a00 R08: ffff88808b6c8700 R09: ffffed100d5c0f4d
    R10: ffffed100d5c0f4c R11: 0000000000000000 R12: ffff888086202380
    R13: 0000000000000030 R14: 00000000000000d3 R15: 0000000000000000
     tomoyo_supervisor+0x2e8/0xef0 security/tomoyo/common.c:2087
     tomoyo_audit_path_number_log security/tomoyo/file.c:235 [inline]
     tomoyo_path_number_perm+0x42f/0x520 security/tomoyo/file.c:734
     tomoyo_file_ioctl+0x23/0x30 security/tomoyo/tomoyo.c:335
     security_file_ioctl+0x77/0xc0 security/security.c:1370
     ksys_ioctl+0x57/0xd0 fs/ioctl.c:711
     __do_sys_ioctl fs/ioctl.c:720 [inline]
     __se_sys_ioctl fs/ioctl.c:718 [inline]
     __x64_sys_ioctl+0x73/0xb0 fs/ioctl.c:718
     do_syscall_64+0xfd/0x680 arch/x86/entry/common.c:301
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    RIP: 0033:0x4592c9
    Code: fd b7 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 cb b7 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f8db5e44c78 EFLAGS: 00000246 ORIG_RAX: 0000000000000010
    RAX: ffffffffffffffda RBX: 0000000000000003 RCX: 00000000004592c9
    RDX: 0000000020000080 RSI: 00000000000089f1 RDI: 0000000000000006
    RBP: 000000000075bf20 R08: 0000000000000000 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f8db5e456d4
    R13: 00000000004cc770 R14: 00000000004d5cd8 R15: 00000000ffffffff
    
    Allocated by task 9047:
     save_stack+0x23/0x90 mm/kasan/common.c:71
     set_track mm/kasan/common.c:79 [inline]
     __kasan_kmalloc mm/kasan/common.c:489 [inline]
     __kasan_kmalloc.constprop.0+0xcf/0xe0 mm/kasan/common.c:462
     kasan_slab_alloc+0xf/0x20 mm/kasan/common.c:497
     slab_post_alloc_hook mm/slab.h:437 [inline]
     slab_alloc mm/slab.c:3326 [inline]
     kmem_cache_alloc+0x11a/0x6f0 mm/slab.c:3488
     kmem_cache_zalloc include/linux/slab.h:732 [inline]
     net_alloc net/core/net_namespace.c:386 [inline]
     copy_net_ns+0xed/0x340 net/core/net_namespace.c:426
     create_new_namespaces+0x400/0x7b0 kernel/nsproxy.c:107
     unshare_nsproxy_namespaces+0xc2/0x200 kernel/nsproxy.c:206
     ksys_unshare+0x440/0x980 kernel/fork.c:2692
     __do_sys_unshare kernel/fork.c:2760 [inline]
     __se_sys_unshare kernel/fork.c:2758 [inline]
     __x64_sys_unshare+0x31/0x40 kernel/fork.c:2758
     do_syscall_64+0xfd/0x680 arch/x86/entry/common.c:301
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Freed by task 2541:
     save_stack+0x23/0x90 mm/kasan/common.c:71
     set_track mm/kasan/common.c:79 [inline]
     __kasan_slab_free+0x102/0x150 mm/kasan/common.c:451
     kasan_slab_free+0xe/0x10 mm/kasan/common.c:459
     __cache_free mm/slab.c:3432 [inline]
     kmem_cache_free+0x86/0x260 mm/slab.c:3698
     net_free net/core/net_namespace.c:402 [inline]
     net_drop_ns.part.0+0x70/0x90 net/core/net_namespace.c:409
     net_drop_ns net/core/net_namespace.c:408 [inline]
     cleanup_net+0x538/0x960 net/core/net_namespace.c:571
     process_one_work+0x989/0x1790 kernel/workqueue.c:2269
     worker_thread+0x98/0xe40 kernel/workqueue.c:2415
     kthread+0x354/0x420 kernel/kthread.c:255
     ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
    
    The buggy address belongs to the object at ffff88808b9fe100
     which belongs to the cache net_namespace of size 6784
    The buggy address is located 560 bytes inside of
     6784-byte region [ffff88808b9fe100, ffff88808b9ffb80)
    The buggy address belongs to the page:
    page:ffffea00022e7f80 refcount:1 mapcount:0 mapping:ffff88821b6f60c0 index:0x0 compound_mapcount: 0
    flags: 0x1fffc0000010200(slab|head)
    raw: 01fffc0000010200 ffffea000256f288 ffffea0001bbef08 ffff88821b6f60c0
    raw: 0000000000000000 ffff88808b9fe100 0000000100000001 0000000000000000
    page dumped because: kasan: bad access detected
    
    Memory state around the buggy address:
     ffff88808b9fe200: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88808b9fe280: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    >ffff88808b9fe300: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                         ^
     ffff88808b9fe380: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88808b9fe400: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    
    Fixes: 3c8fc8782044 ("inet: frags: rework rhashtable dismantle")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e91b79ad4e4a..46574d996f1d 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -20,7 +20,7 @@ struct fqdir {
 
 	/* Keep atomic mem on separate cachelines in structs that include it */
 	atomic_long_t		mem ____cacheline_aligned_in_smp;
-	struct rcu_work		destroy_rwork;
+	struct work_struct	destroy_work;
 };
 
 /**
@@ -113,6 +113,12 @@ int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
 int fqdir_init(struct fqdir **fqdirp, struct inet_frags *f, struct net *net);
+
+static void inline fqdir_pre_exit(struct fqdir *fqdir)
+{
+	fqdir->high_thresh = 0; /* prevent creation of new frags */
+	fqdir->dead = true;
+}
 void fqdir_exit(struct fqdir *fqdir);
 
 void inet_frag_kill(struct inet_frag_queue *q);

commit dc93f46bc4e00899eaf4579962cfac8cf2f9966d
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon May 27 16:56:49 2019 -0700

    inet: frags: fix use-after-free read in inet_frag_destroy_rcu
    
    As caught by syzbot [1], the rcu grace period that is respected
    before fqdir_rwork_fn() proceeds and frees fqdir is not enough
    to prevent inet_frag_destroy_rcu() being run after the freeing.
    
    We need a proper rcu_barrier() synchronization to replace
    the one we had in inet_frags_fini()
    
    We also have to fix a potential problem at module removal :
    inet_frags_fini() needs to make sure that all queued work queues
    (fqdir_rwork_fn) have completed, otherwise we might
    call kmem_cache_destroy() too soon and get another use-after-free.
    
    [1]
    BUG: KASAN: use-after-free in inet_frag_destroy_rcu+0xd9/0xe0 net/ipv4/inet_fragment.c:201
    Read of size 8 at addr ffff88806ed47a18 by task swapper/1/0
    
    CPU: 1 PID: 0 Comm: swapper/1 Not tainted 5.2.0-rc1+ #2
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x172/0x1f0 lib/dump_stack.c:113
     print_address_description.cold+0x7c/0x20d mm/kasan/report.c:188
     __kasan_report.cold+0x1b/0x40 mm/kasan/report.c:317
     kasan_report+0x12/0x20 mm/kasan/common.c:614
     __asan_report_load8_noabort+0x14/0x20 mm/kasan/generic_report.c:132
     inet_frag_destroy_rcu+0xd9/0xe0 net/ipv4/inet_fragment.c:201
     __rcu_reclaim kernel/rcu/rcu.h:222 [inline]
     rcu_do_batch kernel/rcu/tree.c:2092 [inline]
     invoke_rcu_callbacks kernel/rcu/tree.c:2310 [inline]
     rcu_core+0xba5/0x1500 kernel/rcu/tree.c:2291
     __do_softirq+0x25c/0x94c kernel/softirq.c:293
     invoke_softirq kernel/softirq.c:374 [inline]
     irq_exit+0x180/0x1d0 kernel/softirq.c:414
     exiting_irq arch/x86/include/asm/apic.h:536 [inline]
     smp_apic_timer_interrupt+0x13b/0x550 arch/x86/kernel/apic/apic.c:1068
     apic_timer_interrupt+0xf/0x20 arch/x86/entry/entry_64.S:806
     </IRQ>
    RIP: 0010:native_safe_halt+0xe/0x10 arch/x86/include/asm/irqflags.h:61
    Code: ff ff 48 89 df e8 f2 95 8c fa eb 82 e9 07 00 00 00 0f 00 2d e4 45 4b 00 f4 c3 66 90 e9 07 00 00 00 0f 00 2d d4 45 4b 00 fb f4 <c3> 90 55 48 89 e5 41 57 41 56 41 55 41 54 53 e8 8e 18 42 fa e8 99
    RSP: 0018:ffff8880a98e7d78 EFLAGS: 00000282 ORIG_RAX: ffffffffffffff13
    RAX: 1ffffffff1164e11 RBX: ffff8880a98d4340 RCX: 0000000000000000
    RDX: dffffc0000000000 RSI: 0000000000000006 RDI: ffff8880a98d4bbc
    RBP: ffff8880a98e7da8 R08: ffff8880a98d4340 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000001
    R13: ffffffff88b27078 R14: 0000000000000001 R15: 0000000000000000
     arch_cpu_idle+0xa/0x10 arch/x86/kernel/process.c:571
     default_idle_call+0x36/0x90 kernel/sched/idle.c:94
     cpuidle_idle_call kernel/sched/idle.c:154 [inline]
     do_idle+0x377/0x560 kernel/sched/idle.c:263
     cpu_startup_entry+0x1b/0x20 kernel/sched/idle.c:354
     start_secondary+0x34e/0x4c0 arch/x86/kernel/smpboot.c:267
     secondary_startup_64+0xa4/0xb0 arch/x86/kernel/head_64.S:243
    
    Allocated by task 8877:
     save_stack+0x23/0x90 mm/kasan/common.c:71
     set_track mm/kasan/common.c:79 [inline]
     __kasan_kmalloc mm/kasan/common.c:489 [inline]
     __kasan_kmalloc.constprop.0+0xcf/0xe0 mm/kasan/common.c:462
     kasan_kmalloc+0x9/0x10 mm/kasan/common.c:503
     kmem_cache_alloc_trace+0x151/0x750 mm/slab.c:3555
     kmalloc include/linux/slab.h:547 [inline]
     kzalloc include/linux/slab.h:742 [inline]
     fqdir_init include/net/inet_frag.h:115 [inline]
     ipv6_frags_init_net+0x48/0x460 net/ipv6/reassembly.c:513
     ops_init+0xb3/0x410 net/core/net_namespace.c:130
     setup_net+0x2d3/0x740 net/core/net_namespace.c:316
     copy_net_ns+0x1df/0x340 net/core/net_namespace.c:439
     create_new_namespaces+0x400/0x7b0 kernel/nsproxy.c:107
     unshare_nsproxy_namespaces+0xc2/0x200 kernel/nsproxy.c:206
     ksys_unshare+0x440/0x980 kernel/fork.c:2692
     __do_sys_unshare kernel/fork.c:2760 [inline]
     __se_sys_unshare kernel/fork.c:2758 [inline]
     __x64_sys_unshare+0x31/0x40 kernel/fork.c:2758
     do_syscall_64+0xfd/0x680 arch/x86/entry/common.c:301
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Freed by task 17:
     save_stack+0x23/0x90 mm/kasan/common.c:71
     set_track mm/kasan/common.c:79 [inline]
     __kasan_slab_free+0x102/0x150 mm/kasan/common.c:451
     kasan_slab_free+0xe/0x10 mm/kasan/common.c:459
     __cache_free mm/slab.c:3432 [inline]
     kfree+0xcf/0x220 mm/slab.c:3755
     fqdir_rwork_fn+0x33/0x40 net/ipv4/inet_fragment.c:154
     process_one_work+0x989/0x1790 kernel/workqueue.c:2269
     worker_thread+0x98/0xe40 kernel/workqueue.c:2415
     kthread+0x354/0x420 kernel/kthread.c:255
     ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
    
    The buggy address belongs to the object at ffff88806ed47a00
     which belongs to the cache kmalloc-512 of size 512
    The buggy address is located 24 bytes inside of
     512-byte region [ffff88806ed47a00, ffff88806ed47c00)
    The buggy address belongs to the page:
    page:ffffea0001bb51c0 refcount:1 mapcount:0 mapping:ffff8880aa400940 index:0x0
    flags: 0x1fffc0000000200(slab)
    raw: 01fffc0000000200 ffffea000282a788 ffffea0001bb53c8 ffff8880aa400940
    raw: 0000000000000000 ffff88806ed47000 0000000100000006 0000000000000000
    page dumped because: kasan: bad access detected
    
    Memory state around the buggy address:
     ffff88806ed47900: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88806ed47980: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    >ffff88806ed47a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                ^
     ffff88806ed47a80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88806ed47b00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    
    Fixes: 3c8fc8782044 ("inet: frags: rework rhashtable dismantle")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 94092b1ef22e..e91b79ad4e4a 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -3,6 +3,7 @@
 #define __NET_FRAG_H__
 
 #include <linux/rhashtable-types.h>
+#include <linux/completion.h>
 
 /* Per netns frag queues directory */
 struct fqdir {
@@ -104,6 +105,8 @@ struct inet_frags {
 	struct kmem_cache	*frags_cachep;
 	const char		*frags_cache_name;
 	struct rhashtable_params rhash_params;
+	refcount_t		refcnt;
+	struct completion	completion;
 };
 
 int inet_frags_init(struct inet_frags *);

commit 6b73d19711d0989cbdcd19c61faa0f79a1a5e466
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon May 27 16:56:47 2019 -0700

    inet: frags: uninline fqdir_init()
    
    fqdir_init() is not fast path and is getting bigger.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 002f23c1a1a7..94092b1ef22e 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -109,25 +109,7 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-static inline int fqdir_init(struct fqdir **fqdirp, struct inet_frags *f,
-			     struct net *net)
-{
-	struct fqdir *fqdir = kzalloc(sizeof(*fqdir), GFP_KERNEL);
-	int res;
-
-	if (!fqdir)
-		return -ENOMEM;
-	fqdir->f = f;
-	fqdir->net = net;
-	res = rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);
-	if (res < 0) {
-		kfree(fqdir);
-		return res;
-	}
-	*fqdirp = fqdir;
-	return 0;
-}
-
+int fqdir_init(struct fqdir **fqdirp, struct inet_frags *f, struct net *net);
 void fqdir_exit(struct fqdir *fqdir);
 
 void inet_frag_kill(struct inet_frag_queue *q);

commit 3c8fc87820446ce5b948dc17648509340102b818
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 24 09:03:40 2019 -0700

    inet: frags: rework rhashtable dismantle
    
    syszbot found an interesting use-after-free [1] happening
    while IPv4 fragment rhashtable was destroyed at netns dismantle.
    
    While no insertions can possibly happen at the time a dismantling
    netns is destroying this rhashtable, timers can still fire and
    attempt to remove elements from this rhashtable.
    
    This is forbidden, since rhashtable_free_and_destroy() has
    no synchronization against concurrent inserts and deletes.
    
    Add a new fqdir->dead flag so that timers do not attempt
    a rhashtable_remove_fast() operation.
    
    We also have to respect an RCU grace period before starting
    the rhashtable_free_and_destroy() from process context,
    thus we use rcu_work infrastructure.
    
    This is a refinement of a prior rough attempt to fix this bug :
    https://marc.info/?l=linux-netdev&m=153845936820900&w=2
    
    Since the rhashtable cleanup is now deferred to a work queue,
    netns dismantles should be slightly faster.
    
    [1]
    BUG: KASAN: use-after-free in __read_once_size include/linux/compiler.h:194 [inline]
    BUG: KASAN: use-after-free in rhashtable_last_table+0x162/0x180 lib/rhashtable.c:212
    Read of size 8 at addr ffff8880a6497b70 by task kworker/0:0/5
    
    CPU: 0 PID: 5 Comm: kworker/0:0 Not tainted 5.2.0-rc1+ #2
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Workqueue: events rht_deferred_worker
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x172/0x1f0 lib/dump_stack.c:113
     print_address_description.cold+0x7c/0x20d mm/kasan/report.c:188
     __kasan_report.cold+0x1b/0x40 mm/kasan/report.c:317
     kasan_report+0x12/0x20 mm/kasan/common.c:614
     __asan_report_load8_noabort+0x14/0x20 mm/kasan/generic_report.c:132
     __read_once_size include/linux/compiler.h:194 [inline]
     rhashtable_last_table+0x162/0x180 lib/rhashtable.c:212
     rht_deferred_worker+0x111/0x2030 lib/rhashtable.c:411
     process_one_work+0x989/0x1790 kernel/workqueue.c:2269
     worker_thread+0x98/0xe40 kernel/workqueue.c:2415
     kthread+0x354/0x420 kernel/kthread.c:255
     ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
    
    Allocated by task 32687:
     save_stack+0x23/0x90 mm/kasan/common.c:71
     set_track mm/kasan/common.c:79 [inline]
     __kasan_kmalloc mm/kasan/common.c:489 [inline]
     __kasan_kmalloc.constprop.0+0xcf/0xe0 mm/kasan/common.c:462
     kasan_kmalloc+0x9/0x10 mm/kasan/common.c:503
     __do_kmalloc_node mm/slab.c:3620 [inline]
     __kmalloc_node+0x4e/0x70 mm/slab.c:3627
     kmalloc_node include/linux/slab.h:590 [inline]
     kvmalloc_node+0x68/0x100 mm/util.c:431
     kvmalloc include/linux/mm.h:637 [inline]
     kvzalloc include/linux/mm.h:645 [inline]
     bucket_table_alloc+0x90/0x480 lib/rhashtable.c:178
     rhashtable_init+0x3f4/0x7b0 lib/rhashtable.c:1057
     inet_frags_init_net include/net/inet_frag.h:109 [inline]
     ipv4_frags_init_net+0x182/0x410 net/ipv4/ip_fragment.c:683
     ops_init+0xb3/0x410 net/core/net_namespace.c:130
     setup_net+0x2d3/0x740 net/core/net_namespace.c:316
     copy_net_ns+0x1df/0x340 net/core/net_namespace.c:439
     create_new_namespaces+0x400/0x7b0 kernel/nsproxy.c:107
     unshare_nsproxy_namespaces+0xc2/0x200 kernel/nsproxy.c:206
     ksys_unshare+0x440/0x980 kernel/fork.c:2692
     __do_sys_unshare kernel/fork.c:2760 [inline]
     __se_sys_unshare kernel/fork.c:2758 [inline]
     __x64_sys_unshare+0x31/0x40 kernel/fork.c:2758
     do_syscall_64+0xfd/0x680 arch/x86/entry/common.c:301
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Freed by task 7:
     save_stack+0x23/0x90 mm/kasan/common.c:71
     set_track mm/kasan/common.c:79 [inline]
     __kasan_slab_free+0x102/0x150 mm/kasan/common.c:451
     kasan_slab_free+0xe/0x10 mm/kasan/common.c:459
     __cache_free mm/slab.c:3432 [inline]
     kfree+0xcf/0x220 mm/slab.c:3755
     kvfree+0x61/0x70 mm/util.c:460
     bucket_table_free+0x69/0x150 lib/rhashtable.c:108
     rhashtable_free_and_destroy+0x165/0x8b0 lib/rhashtable.c:1155
     inet_frags_exit_net+0x3d/0x50 net/ipv4/inet_fragment.c:152
     ipv4_frags_exit_net+0x73/0x90 net/ipv4/ip_fragment.c:695
     ops_exit_list.isra.0+0xaa/0x150 net/core/net_namespace.c:154
     cleanup_net+0x3fb/0x960 net/core/net_namespace.c:553
     process_one_work+0x989/0x1790 kernel/workqueue.c:2269
     worker_thread+0x98/0xe40 kernel/workqueue.c:2415
     kthread+0x354/0x420 kernel/kthread.c:255
     ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
    
    The buggy address belongs to the object at ffff8880a6497b40
     which belongs to the cache kmalloc-1k of size 1024
    The buggy address is located 48 bytes inside of
     1024-byte region [ffff8880a6497b40, ffff8880a6497f40)
    The buggy address belongs to the page:
    page:ffffea0002992580 refcount:1 mapcount:0 mapping:ffff8880aa400ac0 index:0xffff8880a64964c0 compound_mapcount: 0
    flags: 0x1fffc0000010200(slab|head)
    raw: 01fffc0000010200 ffffea0002916e88 ffffea000218fe08 ffff8880aa400ac0
    raw: ffff8880a64964c0 ffff8880a6496040 0000000100000005 0000000000000000
    page dumped because: kasan: bad access detected
    
    Memory state around the buggy address:
     ffff8880a6497a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff8880a6497a80: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    >ffff8880a6497b00: fc fc fc fc fc fc fc fc fb fb fb fb fb fb fb fb
                                                                 ^
     ffff8880a6497b80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff8880a6497c00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    
    Fixes: 648700f76b03 ("inet: frags: use rhashtables for reassembly units")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 5f754c660cfa..002f23c1a1a7 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -13,11 +13,13 @@ struct fqdir {
 	int			max_dist;
 	struct inet_frags	*f;
 	struct net		*net;
+	bool			dead;
 
 	struct rhashtable       rhashtable ____cacheline_aligned_in_smp;
 
 	/* Keep atomic mem on separate cachelines in structs that include it */
 	atomic_long_t		mem ____cacheline_aligned_in_smp;
+	struct rcu_work		destroy_rwork;
 };
 
 /**
@@ -26,11 +28,13 @@ struct fqdir {
  * @INET_FRAG_FIRST_IN: first fragment has arrived
  * @INET_FRAG_LAST_IN: final fragment has arrived
  * @INET_FRAG_COMPLETE: frag queue has been processed and is due for destruction
+ * @INET_FRAG_HASH_DEAD: inet_frag_kill() has not removed fq from rhashtable
  */
 enum {
 	INET_FRAG_FIRST_IN	= BIT(0),
 	INET_FRAG_LAST_IN	= BIT(1),
 	INET_FRAG_COMPLETE	= BIT(2),
+	INET_FRAG_HASH_DEAD	= BIT(3),
 };
 
 struct frag_v4_compare_key {

commit 4907abc605e328d61bee56e4e89db4f56ade2090
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 24 09:03:39 2019 -0700

    net: dynamically allocate fqdir structures
    
    Following patch will add rcu grace period before fqdir
    rhashtable destruction, so we need to dynamically allocate
    fqdir structures to not force expensive synchronize_rcu() calls
    in netns dismantle path.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 37cde5c1498c..5f754c660cfa 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -105,14 +105,25 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-static inline int fqdir_init(struct fqdir *fqdir, struct inet_frags *f,
+static inline int fqdir_init(struct fqdir **fqdirp, struct inet_frags *f,
 			     struct net *net)
 {
+	struct fqdir *fqdir = kzalloc(sizeof(*fqdir), GFP_KERNEL);
+	int res;
+
+	if (!fqdir)
+		return -ENOMEM;
 	fqdir->f = f;
 	fqdir->net = net;
-	atomic_long_set(&fqdir->mem, 0);
-	return rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);
+	res = rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);
+	if (res < 0) {
+		kfree(fqdir);
+		return res;
+	}
+	*fqdirp = fqdir;
+	return 0;
 }
+
 void fqdir_exit(struct fqdir *fqdir);
 
 void inet_frag_kill(struct inet_frag_queue *q);

commit a39aca678a0626941aa99c18c1c452ca758e7865
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 24 09:03:38 2019 -0700

    net: add a net pointer to struct fqdir
    
    fqdir will soon be dynamically allocated.
    
    We need to reach the struct net pointer from fqdir,
    so add it, and replace the various container_of() constructs
    by direct access to the new field.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index fca246b0abd8..37cde5c1498c 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -12,6 +12,7 @@ struct fqdir {
 	int			timeout;
 	int			max_dist;
 	struct inet_frags	*f;
+	struct net		*net;
 
 	struct rhashtable       rhashtable ____cacheline_aligned_in_smp;
 
@@ -104,9 +105,11 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-static inline int fqdir_init(struct fqdir *fqdir, struct inet_frags *f)
+static inline int fqdir_init(struct fqdir *fqdir, struct inet_frags *f,
+			     struct net *net)
 {
 	fqdir->f = f;
+	fqdir->net = net;
 	atomic_long_set(&fqdir->mem, 0);
 	return rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);
 }

commit 9cce45f22ceedf639cbb5fb5dfe612a278d36b58
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 24 09:03:37 2019 -0700

    net: rename inet_frags_init_net() to fdir_init()
    
    And pass an extra parameter, since we will soon
    dynamically allocate fqdir structures.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index d1bfd5dbe2d4..fca246b0abd8 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -104,8 +104,9 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-static inline int inet_frags_init_net(struct fqdir *fqdir)
+static inline int fqdir_init(struct fqdir *fqdir, struct inet_frags *f)
 {
+	fqdir->f = f;
 	atomic_long_set(&fqdir->mem, 0);
 	return rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);
 }

commit 89fb900514d1623cf6019848f39d0557a3d31890
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 24 09:03:31 2019 -0700

    net: rename inet_frags_exit_net() to fqdir_exit()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index b19b1ba44ac5..d1bfd5dbe2d4 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -109,7 +109,7 @@ static inline int inet_frags_init_net(struct fqdir *fqdir)
 	atomic_long_set(&fqdir->mem, 0);
 	return rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);
 }
-void inet_frags_exit_net(struct fqdir *fqdir);
+void fqdir_exit(struct fqdir *fqdir);
 
 void inet_frag_kill(struct inet_frag_queue *q);
 void inet_frag_destroy(struct inet_frag_queue *q);

commit 6ce3b4dcee4f96a5000d3f790403eb6997e3d553
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 24 09:03:30 2019 -0700

    inet: rename netns_frags to fqdir
    
    1) struct netns_frags is renamed to struct fqdir
      This structure is really holding many frag queues in a hash table.
    
    2) (struct inet_frag_queue)->net field is renamed to fqdir
      since net is generally associated to a 'struct net' pointer
      in networking stack.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 378904ee9129..b19b1ba44ac5 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -4,7 +4,8 @@
 
 #include <linux/rhashtable-types.h>
 
-struct netns_frags {
+/* Per netns frag queues directory */
+struct fqdir {
 	/* sysctls */
 	long			high_thresh;
 	long			low_thresh;
@@ -64,7 +65,7 @@ struct frag_v6_compare_key {
  * @meat: length of received fragments so far
  * @flags: fragment queue flags
  * @max_size: maximum received fragment size
- * @net: namespace that this frag belongs to
+ * @fqdir: pointer to struct fqdir
  * @rcu: rcu head for freeing deferall
  */
 struct inet_frag_queue {
@@ -84,7 +85,7 @@ struct inet_frag_queue {
 	int			meat;
 	__u8			flags;
 	u16			max_size;
-	struct netns_frags      *net;
+	struct fqdir		*fqdir;
 	struct rcu_head		rcu;
 };
 
@@ -103,16 +104,16 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-static inline int inet_frags_init_net(struct netns_frags *nf)
+static inline int inet_frags_init_net(struct fqdir *fqdir)
 {
-	atomic_long_set(&nf->mem, 0);
-	return rhashtable_init(&nf->rhashtable, &nf->f->rhash_params);
+	atomic_long_set(&fqdir->mem, 0);
+	return rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);
 }
-void inet_frags_exit_net(struct netns_frags *nf);
+void inet_frags_exit_net(struct fqdir *fqdir);
 
 void inet_frag_kill(struct inet_frag_queue *q);
 void inet_frag_destroy(struct inet_frag_queue *q);
-struct inet_frag_queue *inet_frag_find(struct netns_frags *nf, void *key);
+struct inet_frag_queue *inet_frag_find(struct fqdir *fqdir, void *key);
 
 /* Free all skbs in the queue; return the sum of their truesizes. */
 unsigned int inet_frag_rbtree_purge(struct rb_root *root);
@@ -125,19 +126,19 @@ static inline void inet_frag_put(struct inet_frag_queue *q)
 
 /* Memory Tracking Functions. */
 
-static inline long frag_mem_limit(const struct netns_frags *nf)
+static inline long frag_mem_limit(const struct fqdir *fqdir)
 {
-	return atomic_long_read(&nf->mem);
+	return atomic_long_read(&fqdir->mem);
 }
 
-static inline void sub_frag_mem_limit(struct netns_frags *nf, long val)
+static inline void sub_frag_mem_limit(struct fqdir *fqdir, long val)
 {
-	atomic_long_sub(val, &nf->mem);
+	atomic_long_sub(val, &fqdir->mem);
 }
 
-static inline void add_frag_mem_limit(struct netns_frags *nf, long val)
+static inline void add_frag_mem_limit(struct fqdir *fqdir, long val)
 {
-	atomic_long_add(val, &nf->mem);
+	atomic_long_add(val, &fqdir->mem);
 }
 
 /* RFC 3168 support :

commit d8cf757fbd3ee96a449f656707e773c91ca805b8
Author: Peter Oskolkov <posk@google.com>
Date:   Mon Feb 25 17:43:46 2019 -0800

    net: remove unused struct inet_frag_queue.fragments field
    
    Now that all users of struct inet_frag_queue have been converted
    to use 'rb_fragments', remove the unused 'fragments' field.
    
    Build with `make allyesconfig` succeeded. ip_defrag selftest passed.
    
    Signed-off-by: Peter Oskolkov <posk@google.com>
    Acked-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index b02bf737d019..378904ee9129 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -56,7 +56,6 @@ struct frag_v6_compare_key {
  * @timer: queue expiration timer
  * @lock: spinlock protecting this frag
  * @refcnt: reference count of the queue
- * @fragments: received fragments head
  * @rb_fragments: received fragments rb-tree root
  * @fragments_tail: received fragments tail
  * @last_run_head: the head of the last "run". see ip_fragment.c
@@ -77,8 +76,7 @@ struct inet_frag_queue {
 	struct timer_list	timer;
 	spinlock_t		lock;
 	refcount_t		refcnt;
-	struct sk_buff		*fragments;  /* used in 6lopwpan IPv6. */
-	struct rb_root		rb_fragments; /* Used in IPv4/IPv6. */
+	struct rb_root		rb_fragments;
 	struct sk_buff		*fragments_tail;
 	struct sk_buff		*last_run_head;
 	ktime_t			stamp;

commit c23f35d19db3b36ffb9e04b08f1d91565d15f84f
Author: Peter Oskolkov <posk@google.com>
Date:   Tue Jan 22 10:02:50 2019 -0800

    net: IP defrag: encapsulate rbtree defrag code into callable functions
    
    This is a refactoring patch: without changing runtime behavior,
    it moves rbtree-related code from IPv4-specific files/functions
    into .h/.c defrag files shared with IPv6 defragmentation code.
    
    Signed-off-by: Peter Oskolkov <posk@google.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Florian Westphal <fw@strlen.de>
    Cc: Tom Herbert <tom@herbertland.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 1662cbc0b46b..b02bf737d019 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -77,8 +77,8 @@ struct inet_frag_queue {
 	struct timer_list	timer;
 	spinlock_t		lock;
 	refcount_t		refcnt;
-	struct sk_buff		*fragments;  /* Used in IPv6. */
-	struct rb_root		rb_fragments; /* Used in IPv4. */
+	struct sk_buff		*fragments;  /* used in 6lopwpan IPv6. */
+	struct rb_root		rb_fragments; /* Used in IPv4/IPv6. */
 	struct sk_buff		*fragments_tail;
 	struct sk_buff		*last_run_head;
 	ktime_t			stamp;
@@ -153,4 +153,16 @@ static inline void add_frag_mem_limit(struct netns_frags *nf, long val)
 
 extern const u8 ip_frag_ecn_table[16];
 
+/* Return values of inet_frag_queue_insert() */
+#define IPFRAG_OK	0
+#define IPFRAG_DUP	1
+#define IPFRAG_OVERLAP	2
+int inet_frag_queue_insert(struct inet_frag_queue *q, struct sk_buff *skb,
+			   int offset, int end);
+void *inet_frag_reasm_prepare(struct inet_frag_queue *q, struct sk_buff *skb,
+			      struct sk_buff *parent);
+void inet_frag_reasm_finish(struct inet_frag_queue *q, struct sk_buff *head,
+			    void *reasm_data);
+struct sk_buff *inet_frag_pull_head(struct inet_frag_queue *q);
+
 #endif

commit 353c9cb360874e737fb000545f783df756c06f9a
Author: Peter Oskolkov <posk@google.com>
Date:   Sat Aug 11 20:27:24 2018 +0000

    ip: add helpers to process in-order fragments faster.
    
    This patch introduces several helper functions/macros that will be
    used in the follow-up patch. No runtime changes yet.
    
    The new logic (fully implemented in the second patch) is as follows:
    
    * Nodes in the rb-tree will now contain not single fragments, but lists
      of consecutive fragments ("runs").
    
    * At each point in time, the current "active" run at the tail is
      maintained/tracked. Fragments that arrive in-order, adjacent
      to the previous tail fragment, are added to this tail run without
      triggering the re-balancing of the rb-tree.
    
    * If a fragment arrives out of order with the offset _before_ the tail run,
      it is inserted into the rb-tree as a single fragment.
    
    * If a fragment arrives after the current tail fragment (with a gap),
      it starts a new "tail" run, as is inserted into the rb-tree
      at the end as the head of the new run.
    
    skb->cb is used to store additional information
    needed here (suggested by Eric Dumazet).
    
    Reported-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: Peter Oskolkov <posk@google.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index b86d14528188..1662cbc0b46b 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -57,7 +57,9 @@ struct frag_v6_compare_key {
  * @lock: spinlock protecting this frag
  * @refcnt: reference count of the queue
  * @fragments: received fragments head
+ * @rb_fragments: received fragments rb-tree root
  * @fragments_tail: received fragments tail
+ * @last_run_head: the head of the last "run". see ip_fragment.c
  * @stamp: timestamp of the last received fragment
  * @len: total length of the original datagram
  * @meat: length of received fragments so far
@@ -78,6 +80,7 @@ struct inet_frag_queue {
 	struct sk_buff		*fragments;  /* Used in IPv6. */
 	struct rb_root		rb_fragments; /* Used in IPv4. */
 	struct sk_buff		*fragments_tail;
+	struct sk_buff		*last_run_head;
 	ktime_t			stamp;
 	int			len;
 	int			meat;
@@ -113,6 +116,9 @@ void inet_frag_kill(struct inet_frag_queue *q);
 void inet_frag_destroy(struct inet_frag_queue *q);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf, void *key);
 
+/* Free all skbs in the queue; return the sum of their truesizes. */
+unsigned int inet_frag_rbtree_purge(struct rb_root *root);
+
 static inline void inet_frag_put(struct inet_frag_queue *q)
 {
 	if (refcount_dec_and_test(&q->refcnt))

commit fa0f527358bd900ef92f925878ed6bfbd51305cc
Author: Peter Oskolkov <posk@google.com>
Date:   Thu Aug 2 23:34:39 2018 +0000

    ip: use rb trees for IP frag queue.
    
    Similar to TCP OOO RX queue, it makes sense to use rb trees to store
    IP fragments, so that OOO fragments are inserted faster.
    
    Tested:
    
    - a follow-up patch contains a rather comprehensive ip defrag
      self-test (functional)
    - ran neper `udp_stream -c -H <host> -F 100 -l 300 -T 20`:
        netstat --statistics
        Ip:
            282078937 total packets received
            0 forwarded
            0 incoming packets discarded
            946760 incoming packets delivered
            18743456 requests sent out
            101 fragments dropped after timeout
            282077129 reassemblies required
            944952 packets reassembled ok
            262734239 packet reassembles failed
       (The numbers/stats above are somewhat better re:
        reassemblies vs a kernel without this patchset. More
        comprehensive performance testing TBD).
    
    Reported-by: Jann Horn <jannh@google.com>
    Reported-by: Juha-Matti Tilli <juha-matti.tilli@iki.fi>
    Suggested-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Peter Oskolkov <posk@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index f4272a29dc44..b86d14528188 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -75,7 +75,8 @@ struct inet_frag_queue {
 	struct timer_list	timer;
 	spinlock_t		lock;
 	refcount_t		refcnt;
-	struct sk_buff		*fragments;
+	struct sk_buff		*fragments;  /* Used in IPv6. */
+	struct rb_root		rb_fragments; /* Used in IPv4. */
 	struct sk_buff		*fragments_tail;
 	ktime_t			stamp;
 	int			len;

commit 0eb71a9da5796851fa87ddc1a534066c0fe54055
Author: NeilBrown <neilb@suse.com>
Date:   Mon Jun 18 12:52:50 2018 +1000

    rhashtable: split rhashtable.h
    
    Due to the use of rhashtables in net namespaces,
    rhashtable.h is included in lots of the kernel,
    so a small changes can required a large recompilation.
    This makes development painful.
    
    This patch splits out rhashtable-types.h which just includes
    the major type declarations, and does not include (non-trivial)
    inline code.  rhashtable.h is no longer included by anything
    in the include/ directory.
    Common include files only include rhashtable-types.h so a large
    recompilation is only triggered when that changes.
    
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index ed07e3786d98..f4272a29dc44 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -2,7 +2,7 @@
 #ifndef __NET_FRAG_H__
 #define __NET_FRAG_H__
 
-#include <linux/rhashtable.h>
+#include <linux/rhashtable-types.h>
 
 struct netns_frags {
 	/* sysctls */

commit c2615cf5a761b32bf74e85bddc223dfff3d9b9f0
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:57 2018 -0700

    inet: frags: reorganize struct netns_frags
    
    Put the read-mostly fields in a separate cache line
    at the beginning of struct netns_frags, to reduce
    false sharing noticed in inet_frag_kill()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index a52e7273e7a5..ed07e3786d98 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -5,16 +5,17 @@
 #include <linux/rhashtable.h>
 
 struct netns_frags {
-	struct rhashtable       rhashtable ____cacheline_aligned_in_smp;
-
-	/* Keep atomic mem on separate cachelines in structs that include it */
-	atomic_long_t		mem ____cacheline_aligned_in_smp;
 	/* sysctls */
 	long			high_thresh;
 	long			low_thresh;
 	int			timeout;
 	int			max_dist;
 	struct inet_frags	*f;
+
+	struct rhashtable       rhashtable ____cacheline_aligned_in_smp;
+
+	/* Keep atomic mem on separate cachelines in structs that include it */
+	atomic_long_t		mem ____cacheline_aligned_in_smp;
 };
 
 /**

commit 3e67f106f619dcfaf6f4e2039599bdb69848c714
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:53 2018 -0700

    inet: frags: break the 2GB limit for frags storage
    
    Some users are willing to provision huge amounts of memory to be able
    to perform reassembly reasonnably well under pressure.
    
    Current memory tracking is using one atomic_t and integers.
    
    Switch to atomic_long_t so that 64bit arches can use more than 2GB,
    without any cost for 32bit arches.
    
    Note that this patch avoids an overflow error, if high_thresh was set
    to ~2GB, since this test in inet_frag_alloc() was never true :
    
    if (... || frag_mem_limit(nf) > nf->high_thresh)
    
    Tested:
    
    $ echo 16000000000 >/proc/sys/net/ipv4/ipfrag_high_thresh
    
    <frag DDOS>
    
    $ grep FRAG /proc/net/sockstat
    FRAG: inuse 14705885 memory 16000002880
    
    $ nstat -n ; sleep 1 ; nstat | grep Reas
    IpReasmReqds                    3317150            0.0
    IpReasmFails                    3317112            0.0
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 95e353e3305b..a52e7273e7a5 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -8,11 +8,11 @@ struct netns_frags {
 	struct rhashtable       rhashtable ____cacheline_aligned_in_smp;
 
 	/* Keep atomic mem on separate cachelines in structs that include it */
-	atomic_t		mem ____cacheline_aligned_in_smp;
+	atomic_long_t		mem ____cacheline_aligned_in_smp;
 	/* sysctls */
+	long			high_thresh;
+	long			low_thresh;
 	int			timeout;
-	int			high_thresh;
-	int			low_thresh;
 	int			max_dist;
 	struct inet_frags	*f;
 };
@@ -102,7 +102,7 @@ void inet_frags_fini(struct inet_frags *);
 
 static inline int inet_frags_init_net(struct netns_frags *nf)
 {
-	atomic_set(&nf->mem, 0);
+	atomic_long_set(&nf->mem, 0);
 	return rhashtable_init(&nf->rhashtable, &nf->f->rhash_params);
 }
 void inet_frags_exit_net(struct netns_frags *nf);
@@ -119,19 +119,19 @@ static inline void inet_frag_put(struct inet_frag_queue *q)
 
 /* Memory Tracking Functions. */
 
-static inline int frag_mem_limit(struct netns_frags *nf)
+static inline long frag_mem_limit(const struct netns_frags *nf)
 {
-	return atomic_read(&nf->mem);
+	return atomic_long_read(&nf->mem);
 }
 
-static inline void sub_frag_mem_limit(struct netns_frags *nf, int i)
+static inline void sub_frag_mem_limit(struct netns_frags *nf, long val)
 {
-	atomic_sub(i, &nf->mem);
+	atomic_long_sub(val, &nf->mem);
 }
 
-static inline void add_frag_mem_limit(struct netns_frags *nf, int i)
+static inline void add_frag_mem_limit(struct netns_frags *nf, long val)
 {
-	atomic_add(i, &nf->mem);
+	atomic_long_add(val, &nf->mem);
 }
 
 /* RFC 3168 support :

commit 2d44ed22e607f9a285b049de2263e3840673a260
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:52 2018 -0700

    inet: frags: remove inet_frag_maybe_warn_overflow()
    
    This function is obsolete, after rhashtable addition to inet defrag.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 0e8e159d88f7..95e353e3305b 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -110,8 +110,6 @@ void inet_frags_exit_net(struct netns_frags *nf);
 void inet_frag_kill(struct inet_frag_queue *q);
 void inet_frag_destroy(struct inet_frag_queue *q);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf, void *key);
-void inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,
-				   const char *prefix);
 
 static inline void inet_frag_put(struct inet_frag_queue *q)
 {

commit 399d1404be660d355192ff4df5ccc3f4159ec1e4
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:51 2018 -0700

    inet: frags: get rif of inet_frag_evicting()
    
    This refactors ip_expire() since one indentation level is removed.
    
    Note: in the future, we should try hard to avoid the skb_clone()
    since this is a serious performance cost.
    Under DDOS, the ICMP message wont be sent because of rate limits.
    
    Fact that ip6_expire_frag_queue() does not use skb_clone() is
    disturbing too. Presumably IPv6 should have the same
    issue than the one we fixed in commit ec4fbd64751d
    ("inet: frag: release spinlock before calling icmp_send()")
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 4b5449df0aad..0e8e159d88f7 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -119,11 +119,6 @@ static inline void inet_frag_put(struct inet_frag_queue *q)
 		inet_frag_destroy(q);
 }
 
-static inline bool inet_frag_evicting(struct inet_frag_queue *q)
-{
-	return false;
-}
-
 /* Memory Tracking Functions. */
 
 static inline int frag_mem_limit(struct netns_frags *nf)

commit 6befe4a78b1553edb6eed3a78b4bcd9748526672
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:50 2018 -0700

    inet: frags: remove some helpers
    
    Remove sum_frag_mem_limit(), ip_frag_mem() & ip6_frag_mem()
    
    Also since we use rhashtable we can bring back the number of fragments
    in "grep FRAG /proc/net/sockstat /proc/net/sockstat6" that was
    removed in commit 434d305405ab ("inet: frag: don't account number
    of fragment queues")
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 3fec0d3a0d01..4b5449df0aad 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -141,11 +141,6 @@ static inline void add_frag_mem_limit(struct netns_frags *nf, int i)
 	atomic_add(i, &nf->mem);
 }
 
-static inline int sum_frag_mem_limit(struct netns_frags *nf)
-{
-	return atomic_read(&nf->mem);
-}
-
 /* RFC 3168 support :
  * We want to check ECN values of all fragments, do detect invalid combinations.
  * In ipq->ecn, we store the OR value of each ip4_frag_ecn() fragment value.

commit 648700f76b03b7e8149d13cc2bdb3355035258a9
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:49 2018 -0700

    inet: frags: use rhashtables for reassembly units
    
    Some applications still rely on IP fragmentation, and to be fair linux
    reassembly unit is not working under any serious load.
    
    It uses static hash tables of 1024 buckets, and up to 128 items per bucket (!!!)
    
    A work queue is supposed to garbage collect items when host is under memory
    pressure, and doing a hash rebuild, changing seed used in hash computations.
    
    This work queue blocks softirqs for up to 25 ms when doing a hash rebuild,
    occurring every 5 seconds if host is under fire.
    
    Then there is the problem of sharing this hash table for all netns.
    
    It is time to switch to rhashtables, and allocate one of them per netns
    to speedup netns dismantle, since this is a critical metric these days.
    
    Lookup is now using RCU. A followup patch will even remove
    the refcount hold/release left from prior implementation and save
    a couple of atomic operations.
    
    Before this patch, 16 cpus (16 RX queue NIC) could not handle more
    than 1 Mpps frags DDOS.
    
    After the patch, I reach 9 Mpps without any tuning, and can use up to 2GB
    of storage for the fragments (exact number depends on frags being evicted
    after timeout)
    
    $ grep FRAG /proc/net/sockstat
    FRAG: inuse 1966916 memory 2140004608
    
    A followup patch will change the limits for 64bit arches.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Kirill Tkhai <ktkhai@virtuozzo.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Florian Westphal <fw@strlen.de>
    Cc: Jesper Dangaard Brouer <brouer@redhat.com>
    Cc: Alexander Aring <alex.aring@gmail.com>
    Cc: Stefan Schmidt <stefan@osg.samsung.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 69e531ed8189..3fec0d3a0d01 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -2,7 +2,11 @@
 #ifndef __NET_FRAG_H__
 #define __NET_FRAG_H__
 
+#include <linux/rhashtable.h>
+
 struct netns_frags {
+	struct rhashtable       rhashtable ____cacheline_aligned_in_smp;
+
 	/* Keep atomic mem on separate cachelines in structs that include it */
 	atomic_t		mem ____cacheline_aligned_in_smp;
 	/* sysctls */
@@ -26,12 +30,30 @@ enum {
 	INET_FRAG_COMPLETE	= BIT(2),
 };
 
+struct frag_v4_compare_key {
+	__be32		saddr;
+	__be32		daddr;
+	u32		user;
+	u32		vif;
+	__be16		id;
+	u16		protocol;
+};
+
+struct frag_v6_compare_key {
+	struct in6_addr	saddr;
+	struct in6_addr	daddr;
+	u32		user;
+	__be32		id;
+	u32		iif;
+};
+
 /**
  * struct inet_frag_queue - fragment queue
  *
- * @lock: spinlock protecting the queue
+ * @node: rhash node
+ * @key: keys identifying this frag.
  * @timer: queue expiration timer
- * @list: hash bucket list
+ * @lock: spinlock protecting this frag
  * @refcnt: reference count of the queue
  * @fragments: received fragments head
  * @fragments_tail: received fragments tail
@@ -41,12 +63,16 @@ enum {
  * @flags: fragment queue flags
  * @max_size: maximum received fragment size
  * @net: namespace that this frag belongs to
- * @list_evictor: list of queues to forcefully evict (e.g. due to low memory)
+ * @rcu: rcu head for freeing deferall
  */
 struct inet_frag_queue {
-	spinlock_t		lock;
+	struct rhash_head	node;
+	union {
+		struct frag_v4_compare_key v4;
+		struct frag_v6_compare_key v6;
+	} key;
 	struct timer_list	timer;
-	struct hlist_node	list;
+	spinlock_t		lock;
 	refcount_t		refcnt;
 	struct sk_buff		*fragments;
 	struct sk_buff		*fragments_tail;
@@ -55,51 +81,20 @@ struct inet_frag_queue {
 	int			meat;
 	__u8			flags;
 	u16			max_size;
-	struct netns_frags	*net;
-	struct hlist_node	list_evictor;
-};
-
-#define INETFRAGS_HASHSZ	1024
-
-/* averaged:
- * max_depth = default ipfrag_high_thresh / INETFRAGS_HASHSZ /
- *	       rounded up (SKB_TRUELEN(0) + sizeof(struct ipq or
- *	       struct frag_queue))
- */
-#define INETFRAGS_MAXDEPTH	128
-
-struct inet_frag_bucket {
-	struct hlist_head	chain;
-	spinlock_t		chain_lock;
+	struct netns_frags      *net;
+	struct rcu_head		rcu;
 };
 
 struct inet_frags {
-	struct inet_frag_bucket	hash[INETFRAGS_HASHSZ];
-
-	struct work_struct	frags_work;
-	unsigned int next_bucket;
-	unsigned long last_rebuild_jiffies;
-	bool rebuild;
-
-	/* The first call to hashfn is responsible to initialize
-	 * rnd. This is best done with net_get_random_once.
-	 *
-	 * rnd_seqlock is used to let hash insertion detect
-	 * when it needs to re-lookup the hash chain to use.
-	 */
-	u32			rnd;
-	seqlock_t		rnd_seqlock;
 	unsigned int		qsize;
 
-	unsigned int		(*hashfn)(const struct inet_frag_queue *);
-	bool			(*match)(const struct inet_frag_queue *q,
-					 const void *arg);
 	void			(*constructor)(struct inet_frag_queue *q,
 					       const void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*frag_expire)(struct timer_list *t);
 	struct kmem_cache	*frags_cachep;
 	const char		*frags_cache_name;
+	struct rhashtable_params rhash_params;
 };
 
 int inet_frags_init(struct inet_frags *);
@@ -108,15 +103,13 @@ void inet_frags_fini(struct inet_frags *);
 static inline int inet_frags_init_net(struct netns_frags *nf)
 {
 	atomic_set(&nf->mem, 0);
-	return 0;
+	return rhashtable_init(&nf->rhashtable, &nf->f->rhash_params);
 }
 void inet_frags_exit_net(struct netns_frags *nf);
 
 void inet_frag_kill(struct inet_frag_queue *q);
 void inet_frag_destroy(struct inet_frag_queue *q);
-struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
-		struct inet_frags *f, void *key, unsigned int hash);
-
+struct inet_frag_queue *inet_frag_find(struct netns_frags *nf, void *key);
 void inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,
 				   const char *prefix);
 
@@ -128,7 +121,7 @@ static inline void inet_frag_put(struct inet_frag_queue *q)
 
 static inline bool inet_frag_evicting(struct inet_frag_queue *q)
 {
-	return !hlist_unhashed(&q->list_evictor);
+	return false;
 }
 
 /* Memory Tracking Functions. */

commit 093ba72914b696521e4885756a68a3332782c8de
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:44 2018 -0700

    inet: frags: add a pointer to struct netns_frags
    
    In order to simplify the API, add a pointer to struct inet_frags.
    This will allow us to make things less complex.
    
    These functions no longer have a struct inet_frags parameter :
    
    inet_frag_destroy(struct inet_frag_queue *q  /*, struct inet_frags *f */)
    inet_frag_put(struct inet_frag_queue *q /*, struct inet_frags *f */)
    inet_frag_kill(struct inet_frag_queue *q /*, struct inet_frags *f */)
    inet_frags_exit_net(struct netns_frags *nf /*, struct inet_frags *f */)
    ip6_expire_frag_queue(struct net *net, struct frag_queue *fq)
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index b1d62176f3b4..69e531ed8189 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -10,6 +10,7 @@ struct netns_frags {
 	int			high_thresh;
 	int			low_thresh;
 	int			max_dist;
+	struct inet_frags	*f;
 };
 
 /**
@@ -109,20 +110,20 @@ static inline int inet_frags_init_net(struct netns_frags *nf)
 	atomic_set(&nf->mem, 0);
 	return 0;
 }
-void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
+void inet_frags_exit_net(struct netns_frags *nf);
 
-void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
-void inet_frag_destroy(struct inet_frag_queue *q, struct inet_frags *f);
+void inet_frag_kill(struct inet_frag_queue *q);
+void inet_frag_destroy(struct inet_frag_queue *q);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
 		struct inet_frags *f, void *key, unsigned int hash);
 
 void inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,
 				   const char *prefix);
 
-static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
+static inline void inet_frag_put(struct inet_frag_queue *q)
 {
 	if (refcount_dec_and_test(&q->refcnt))
-		inet_frag_destroy(q, f);
+		inet_frag_destroy(q);
 }
 
 static inline bool inet_frag_evicting(struct inet_frag_queue *q)

commit 787bea7748a76130566f881c2342a0be4127d182
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 31 12:58:43 2018 -0700

    inet: frags: change inet_frags_init_net() return value
    
    We will soon initialize one rhashtable per struct netns_frags
    in inet_frags_init_net().
    
    This patch changes the return value to eventually propagate an
    error.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 351f0c3cdcd9..b1d62176f3b4 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -104,9 +104,10 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-static inline void inet_frags_init_net(struct netns_frags *nf)
+static inline int inet_frags_init_net(struct netns_frags *nf)
 {
 	atomic_set(&nf->mem, 0);
+	return 0;
 }
 void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 

commit 2a171788ba7bb61995e98e8163204fc7880f63b2
Merge: bf5345882bd1 d4c2e9fca5b7
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Nov 4 09:26:51 2017 +0900

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Files removed in 'net-next' had their license header updated
    in 'net'.  We take the remove from 'net-next'.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index fc59e0775e00..a6e4edd8d4a2 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __NET_FRAG_H__
 #define __NET_FRAG_H__
 

commit 78802011fbe34331bdef6f2dfb1634011f0e4c32
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Oct 16 17:29:20 2017 -0700

    inet: frags: Convert timers to use timer_setup()
    
    In preparation for unconditionally passing the struct timer_list pointer to
    all timer callbacks, switch to using the new timer_setup() and from_timer()
    to pass the timer pointer explicitly.
    
    Cc: Alexander Aring <alex.aring@gmail.com>
    Cc: Stefan Schmidt <stefan@osg.samsung.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: Pablo Neira Ayuso <pablo@netfilter.org>
    Cc: Jozsef Kadlecsik <kadlec@blackhole.kfki.hu>
    Cc: Florian Westphal <fw@strlen.de>
    Cc: linux-wpan@vger.kernel.org
    Cc: netdev@vger.kernel.org
    Cc: netfilter-devel@vger.kernel.org
    Cc: coreteam@netfilter.org
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Stefan Schmidt <stefan@osg.samsung.com> # for ieee802154
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index fc59e0775e00..c695807ca707 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -95,7 +95,7 @@ struct inet_frags {
 	void			(*constructor)(struct inet_frag_queue *q,
 					       const void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
-	void			(*frag_expire)(unsigned long data);
+	void			(*frag_expire)(struct timer_list *t);
 	struct kmem_cache	*frags_cachep;
 	const char		*frags_cache_name;
 };

commit 5a63643e583b6a9789d7a225ae076fb4e603991c
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Fri Sep 1 11:26:13 2017 +0200

    Revert "net: fix percpu memory leaks"
    
    This reverts commit 1d6119baf0610f813eb9d9580eb4fd16de5b4ceb.
    
    After reverting commit 6d7b857d541e ("net: use lib/percpu_counter API
    for fragmentation mem accounting") then here is no need for this
    fix-up patch.  As percpu_counter is no longer used, it cannot
    memory leak it any-longer.
    
    Fixes: 6d7b857d541e ("net: use lib/percpu_counter API for fragmentation mem accounting")
    Fixes: 1d6119baf061 ("net: fix percpu memory leaks")
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index fa635aa6d0b9..fc59e0775e00 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -103,15 +103,10 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-static inline int inet_frags_init_net(struct netns_frags *nf)
+static inline void inet_frags_init_net(struct netns_frags *nf)
 {
 	atomic_set(&nf->mem, 0);
-	return 0;
 }
-static inline void inet_frags_uninit_net(struct netns_frags *nf)
-{
-}
-
 void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);

commit fb452a1aa3fd4034d7999e309c5466ff2d7005aa
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Fri Sep 1 11:26:08 2017 +0200

    Revert "net: use lib/percpu_counter API for fragmentation mem accounting"
    
    This reverts commit 6d7b857d541ecd1d9bd997c97242d4ef94b19de2.
    
    There is a bug in fragmentation codes use of the percpu_counter API,
    that can cause issues on systems with many CPUs.
    
    The frag_mem_limit() just reads the global counter (fbc->count),
    without considering other CPUs can have upto batch size (130K) that
    haven't been subtracted yet.  Due to the 3MBytes lower thresh limit,
    this become dangerous at >=24 CPUs (3*1024*1024/130000=24).
    
    The correct API usage would be to use __percpu_counter_compare() which
    does the right thing, and takes into account the number of (online)
    CPUs and batch size, to account for this and call __percpu_counter_sum()
    when needed.
    
    We choose to revert the use of the lib/percpu_counter API for frag
    memory accounting for several reasons:
    
    1) On systems with CPUs > 24, the heavier fully locked
       __percpu_counter_sum() is always invoked, which will be more
       expensive than the atomic_t that is reverted to.
    
    Given systems with more than 24 CPUs are becoming common this doesn't
    seem like a good option.  To mitigate this, the batch size could be
    decreased and thresh be increased.
    
    2) The add_frag_mem_limit+sub_frag_mem_limit pairs happen on the RX
       CPU, before SKBs are pushed into sockets on remote CPUs.  Given
       NICs can only hash on L2 part of the IP-header, the NIC-RXq's will
       likely be limited.  Thus, a fair chance that atomic add+dec happen
       on the same CPU.
    
    Revert note that commit 1d6119baf061 ("net: fix percpu memory leaks")
    removed init_frag_mem_limit() and instead use inet_frags_init_net().
    After this revert, inet_frags_uninit_net() becomes empty.
    
    Fixes: 6d7b857d541e ("net: use lib/percpu_counter API for fragmentation mem accounting")
    Fixes: 1d6119baf061 ("net: fix percpu memory leaks")
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Acked-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 6fdcd2427776..fa635aa6d0b9 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -1,14 +1,9 @@
 #ifndef __NET_FRAG_H__
 #define __NET_FRAG_H__
 
-#include <linux/percpu_counter.h>
-
 struct netns_frags {
-	/* The percpu_counter "mem" need to be cacheline aligned.
-	 *  mem.count must not share cacheline with other writers
-	 */
-	struct percpu_counter   mem ____cacheline_aligned_in_smp;
-
+	/* Keep atomic mem on separate cachelines in structs that include it */
+	atomic_t		mem ____cacheline_aligned_in_smp;
 	/* sysctls */
 	int			timeout;
 	int			high_thresh;
@@ -110,11 +105,11 @@ void inet_frags_fini(struct inet_frags *);
 
 static inline int inet_frags_init_net(struct netns_frags *nf)
 {
-	return percpu_counter_init(&nf->mem, 0, GFP_KERNEL);
+	atomic_set(&nf->mem, 0);
+	return 0;
 }
 static inline void inet_frags_uninit_net(struct netns_frags *nf)
 {
-	percpu_counter_destroy(&nf->mem);
 }
 
 void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
@@ -140,31 +135,24 @@ static inline bool inet_frag_evicting(struct inet_frag_queue *q)
 
 /* Memory Tracking Functions. */
 
-/* The default percpu_counter batch size is not big enough to scale to
- * fragmentation mem acct sizes.
- * The mem size of a 64K fragment is approx:
- *  (44 fragments * 2944 truesize) + frag_queue struct(200) = 129736 bytes
- */
-static unsigned int frag_percpu_counter_batch = 130000;
-
 static inline int frag_mem_limit(struct netns_frags *nf)
 {
-	return percpu_counter_read(&nf->mem);
+	return atomic_read(&nf->mem);
 }
 
 static inline void sub_frag_mem_limit(struct netns_frags *nf, int i)
 {
-	percpu_counter_add_batch(&nf->mem, -i, frag_percpu_counter_batch);
+	atomic_sub(i, &nf->mem);
 }
 
 static inline void add_frag_mem_limit(struct netns_frags *nf, int i)
 {
-	percpu_counter_add_batch(&nf->mem, i, frag_percpu_counter_batch);
+	atomic_add(i, &nf->mem);
 }
 
-static inline unsigned int sum_frag_mem_limit(struct netns_frags *nf)
+static inline int sum_frag_mem_limit(struct netns_frags *nf)
 {
-	return percpu_counter_sum_positive(&nf->mem);
+	return atomic_read(&nf->mem);
 }
 
 /* RFC 3168 support :

commit a4c20b9a574b9720acf6c647eaff5e7e1e688086
Merge: 9b51f04424e1 e3efe3db932b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 6 08:59:41 2017 -0700

    Merge branch 'for-4.13' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu
    
    Pull percpu updates from Tejun Heo:
     "These are the percpu changes for the v4.13-rc1 merge window. There are
      a couple visibility related changes - tracepoints and allocator stats
      through debugfs, along with __ro_after_init markings and a cosmetic
      rename in percpu_counter.
    
      Please note that the simple O(#elements_in_the_chunk) area allocator
      used by percpu allocator is again showing scalability issues,
      primarily with bpf allocating and freeing large number of counters.
      Dennis is working on the replacement allocator and the percpu
      allocator will be seeing increased churns in the coming cycles"
    
    * 'for-4.13' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu:
      percpu: fix static checker warnings in pcpu_destroy_chunk
      percpu: fix early calls for spinlock in pcpu_stats
      percpu: resolve err may not be initialized in pcpu_alloc
      percpu_counter: Rename __percpu_counter_add to percpu_counter_add_batch
      percpu: add tracepoint support for percpu memory
      percpu: expose statistics about percpu memory via debugfs
      percpu: migrate percpu data structures to internal header
      percpu: add missing lockdep_assert_held to func pcpu_free_area
      mark most percpu globals as __ro_after_init

commit edcb691871b27c3cc463b7291afe75f1c3423406
Author: Reshetova, Elena <elena.reshetova@intel.com>
Date:   Fri Jun 30 13:08:07 2017 +0300

    net: convert inet_frag_queue.refcnt from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 975779d0e7b0..440c1e9d0623 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -50,7 +50,7 @@ struct inet_frag_queue {
 	spinlock_t		lock;
 	struct timer_list	timer;
 	struct hlist_node	list;
-	atomic_t		refcnt;
+	refcount_t		refcnt;
 	struct sk_buff		*fragments;
 	struct sk_buff		*fragments_tail;
 	ktime_t			stamp;
@@ -129,7 +129,7 @@ void inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {
-	if (atomic_dec_and_test(&q->refcnt))
+	if (refcount_dec_and_test(&q->refcnt))
 		inet_frag_destroy(q, f);
 }
 

commit 104b4e5139fe384431ac11c3b8a6cf4a529edf4a
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Jun 20 21:01:20 2017 +0300

    percpu_counter: Rename __percpu_counter_add to percpu_counter_add_batch
    
    Currently, percpu_counter_add is a wrapper around __percpu_counter_add
    which is preempt safe due to explicit calls to preempt_disable.  Given
    how __ prefix is used in percpu related interfaces, the naming
    unfortunately creates the false sense that __percpu_counter_add is
    less safe than percpu_counter_add.  In terms of context-safety,
    they're equivalent.  The only difference is that the __ version takes
    a batch parameter.
    
    Make this a bit more explicit by just renaming __percpu_counter_add to
    percpu_counter_add_batch.
    
    This patch doesn't cause any functional changes.
    
    tj: Minor updates to patch description for clarity.  Cosmetic
        indentation updates.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <jbacik@fb.com>
    Cc: David Sterba <dsterba@suse.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: linux-mm@kvack.org
    Cc: "David S. Miller" <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 5894730ec82a..5932e6de8fc0 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -154,12 +154,12 @@ static inline int frag_mem_limit(struct netns_frags *nf)
 
 static inline void sub_frag_mem_limit(struct netns_frags *nf, int i)
 {
-	__percpu_counter_add(&nf->mem, -i, frag_percpu_counter_batch);
+	percpu_counter_add_batch(&nf->mem, -i, frag_percpu_counter_batch);
 }
 
 static inline void add_frag_mem_limit(struct netns_frags *nf, int i)
 {
-	__percpu_counter_add(&nf->mem, i, frag_percpu_counter_batch);
+	percpu_counter_add_batch(&nf->mem, i, frag_percpu_counter_batch);
 }
 
 static inline unsigned int sum_frag_mem_limit(struct netns_frags *nf)

commit 4c0ebd6fed66388584abb27d7b0f188cc1ec01fe
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Tue May 23 00:20:26 2017 +0300

    net: make struct inet_frags::qsize unsigned
    
    This field is sizeof of corresponding kmem_cache so it can't be negative.
    
    Prepare for 32-bit kmem_cache_create().
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 5894730ec82a..975779d0e7b0 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -92,7 +92,7 @@ struct inet_frags {
 	 */
 	u32			rnd;
 	seqlock_t		rnd_seqlock;
-	int			qsize;
+	unsigned int		qsize;
 
 	unsigned int		(*hashfn)(const struct inet_frag_queue *);
 	bool			(*match)(const struct inet_frag_queue *q,

commit c2a2efbbfcb31bedcf81170fc1aa920255c33b8f
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Jan 20 05:06:08 2017 -0800

    net: remove bh disabling around percpu_counter accesses
    
    Shaohua Li made percpu_counter irq safe in commit 098faf5805c8
    ("percpu_counter: make APIs irq safe")
    
    We can safely remove BH disable/enable sections around various
    percpu_counter manipulations.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 909972aa3acd..5894730ec82a 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -164,13 +164,7 @@ static inline void add_frag_mem_limit(struct netns_frags *nf, int i)
 
 static inline unsigned int sum_frag_mem_limit(struct netns_frags *nf)
 {
-	unsigned int res;
-
-	local_bh_disable();
-	res = percpu_counter_sum_positive(&nf->mem);
-	local_bh_enable();
-
-	return res;
+	return percpu_counter_sum_positive(&nf->mem);
 }
 
 /* RFC 3168 support :

commit 0fbf4cb27e061204c8cee8e7eb2870416bdf30fd
Author: Nikolay Borisov <kernel@kyup.com>
Date:   Mon Feb 15 12:11:31 2016 +0200

    ipv4: namespacify ip fragment max dist sysctl knob
    
    Signed-off-by: Nikolay Borisov <kernel@kyup.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 12aac0fd6ee7..909972aa3acd 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -13,6 +13,7 @@ struct netns_frags {
 	int			timeout;
 	int			high_thresh;
 	int			low_thresh;
+	int			max_dist;
 };
 
 /**

commit a72a5e2d34ec2921c0d9a7545093087e4cb90d0a
Author: Florian Westphal <fw@strlen.de>
Date:   Tue Jan 5 22:17:55 2016 +0100

    inet: kill unused skb_free op
    
    The only user was removed in commit
    029f7f3b8701cc7a ("netfilter: ipv6: nf_defrag: avoid/free clone operations").
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index ac42bbb37b2d..12aac0fd6ee7 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -99,7 +99,6 @@ struct inet_frags {
 	void			(*constructor)(struct inet_frag_queue *q,
 					       const void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
-	void			(*skb_free)(struct sk_buff *);
 	void			(*frag_expire)(unsigned long data);
 	struct kmem_cache	*frags_cachep;
 	const char		*frags_cache_name;

commit 1d6119baf0610f813eb9d9580eb4fd16de5b4ceb
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Nov 2 09:03:11 2015 -0800

    net: fix percpu memory leaks
    
    This patch fixes following problems :
    
    1) percpu_counter_init() can return an error, therefore
      init_frag_mem_limit() must propagate this error so that
      inet_frags_init_net() can do the same up to its callers.
    
    2) If ip[46]_frags_ns_ctl_register() fail, we must unwind
       properly and free the percpu_counter.
    
    Without this fix, we leave freed object in percpu_counters
    global list (if CONFIG_HOTPLUG_CPU) leading to crashes.
    
    This bug was detected by KASAN and syzkaller tool
    (http://github.com/google/syzkaller)
    
    Fixes: 6d7b857d541e ("net: use lib/percpu_counter API for fragmentation mem accounting")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Cc: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Cc: Jesper Dangaard Brouer <brouer@redhat.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 53eead2da743..ac42bbb37b2d 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -108,7 +108,15 @@ struct inet_frags {
 int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
-void inet_frags_init_net(struct netns_frags *nf);
+static inline int inet_frags_init_net(struct netns_frags *nf)
+{
+	return percpu_counter_init(&nf->mem, 0, GFP_KERNEL);
+}
+static inline void inet_frags_uninit_net(struct netns_frags *nf)
+{
+	percpu_counter_destroy(&nf->mem);
+}
+
 void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
@@ -154,11 +162,6 @@ static inline void add_frag_mem_limit(struct netns_frags *nf, int i)
 	__percpu_counter_add(&nf->mem, i, frag_percpu_counter_batch);
 }
 
-static inline void init_frag_mem_limit(struct netns_frags *nf)
-{
-	percpu_counter_init(&nf->mem, 0, GFP_KERNEL);
-}
-
 static inline unsigned int sum_frag_mem_limit(struct netns_frags *nf)
 {
 	unsigned int res;

commit caaecdd3d3f8ec0ea9906c54b1dd8ec8316d26b9
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Thu Jul 23 12:05:40 2015 +0200

    inet: frags: remove INET_FRAG_EVICTED and use list_evictor for the test
    
    We can simply remove the INET_FRAG_EVICTED flag to avoid all the flags
    race conditions with the evictor and use a participation test for the
    evictor list, when we're at that point (after inet_frag_kill) in the
    timer there're 2 possible cases:
    
    1. The evictor added the entry to its evictor list while the timer was
    waiting for the chainlock
    or
    2. The timer unchained the entry and the evictor won't see it
    
    In both cases we should be able to see list_evictor correctly due
    to the sync on the chainlock.
    
    Joint work with Florian Westphal.
    
    Tested-by: Frank Schreuder <fschreuder@transip.nl>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e71ca17024f2..53eead2da743 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -21,13 +21,11 @@ struct netns_frags {
  * @INET_FRAG_FIRST_IN: first fragment has arrived
  * @INET_FRAG_LAST_IN: final fragment has arrived
  * @INET_FRAG_COMPLETE: frag queue has been processed and is due for destruction
- * @INET_FRAG_EVICTED: frag queue is being evicted
  */
 enum {
 	INET_FRAG_FIRST_IN	= BIT(0),
 	INET_FRAG_LAST_IN	= BIT(1),
 	INET_FRAG_COMPLETE	= BIT(2),
-	INET_FRAG_EVICTED	= BIT(3)
 };
 
 /**
@@ -127,6 +125,11 @@ static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f
 		inet_frag_destroy(q, f);
 }
 
+static inline bool inet_frag_evicting(struct inet_frag_queue *q)
+{
+	return !hlist_unhashed(&q->list_evictor);
+}
+
 /* Memory Tracking Functions. */
 
 /* The default percpu_counter batch size is not big enough to scale to

commit 0e60d245a0be7fdbb723607f1d6621007916b252
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 23 12:05:38 2015 +0200

    inet: frag: change *_frag_mem_limit functions to take netns_frags as argument
    
    Followup patch will call it after inet_frag_queue was freed, so q->net
    doesn't work anymore (but netf = q->net; free(q); mem_limit(netf) would).
    
    Tested-by: Frank Schreuder <fschreuder@transip.nl>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 56a3a5685f76..e71ca17024f2 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -141,14 +141,14 @@ static inline int frag_mem_limit(struct netns_frags *nf)
 	return percpu_counter_read(&nf->mem);
 }
 
-static inline void sub_frag_mem_limit(struct inet_frag_queue *q, int i)
+static inline void sub_frag_mem_limit(struct netns_frags *nf, int i)
 {
-	__percpu_counter_add(&q->net->mem, -i, frag_percpu_counter_batch);
+	__percpu_counter_add(&nf->mem, -i, frag_percpu_counter_batch);
 }
 
-static inline void add_frag_mem_limit(struct inet_frag_queue *q, int i)
+static inline void add_frag_mem_limit(struct netns_frags *nf, int i)
 {
-	__percpu_counter_add(&q->net->mem, i, frag_percpu_counter_batch);
+	__percpu_counter_add(&nf->mem, i, frag_percpu_counter_batch);
 }
 
 static inline void init_frag_mem_limit(struct netns_frags *nf)

commit d1fe19444d82e399e38c1594c71b850eca8e9de0
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 23 12:05:37 2015 +0200

    inet: frag: don't re-use chainlist for evictor
    
    commit 65ba1f1ec0eff ("inet: frags: fix a race between inet_evict_bucket
    and inet_frag_kill") describes the bug, but the fix doesn't work reliably.
    
    Problem is that ->flags member can be set on other cpu without chainlock
    being held by that task, i.e. the RMW-Cycle can clear INET_FRAG_EVICTED
    bit after we put the element on the evictor private list.
    
    We can crash when walking the 'private' evictor list since an element can
    be deleted from list underneath the evictor.
    
    Join work with Nikolay Alexandrov.
    
    Fixes: b13d3cbfb8e8 ("inet: frag: move eviction of queues to work queue")
    Reported-by: Johan Schuijt <johan@transip.nl>
    Tested-by: Frank Schreuder <fschreuder@transip.nl>
    Signed-off-by: Nikolay Alexandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e1300b3dd597..56a3a5685f76 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -45,6 +45,7 @@ enum {
  * @flags: fragment queue flags
  * @max_size: maximum received fragment size
  * @net: namespace that this frag belongs to
+ * @list_evictor: list of queues to forcefully evict (e.g. due to low memory)
  */
 struct inet_frag_queue {
 	spinlock_t		lock;
@@ -59,6 +60,7 @@ struct inet_frag_queue {
 	__u8			flags;
 	u16			max_size;
 	struct netns_frags	*net;
+	struct hlist_node	list_evictor;
 };
 
 #define INETFRAGS_HASHSZ	1024

commit d6b915e29f4adea94bc02ba7675bb4f84e6a1abd
Author: Florian Westphal <fw@strlen.de>
Date:   Fri May 22 16:32:51 2015 +0200

    ip_fragment: don't forward defragmented DF packet
    
    We currently always send fragments without DF bit set.
    
    Thus, given following setup:
    
    mtu1500 - mtu1500:1400 - mtu1400:1280 - mtu1280
       A           R1              R2         B
    
    Where R1 and R2 run linux with netfilter defragmentation/conntrack
    enabled, then if Host A sent a fragmented packet _with_ DF set to B, R1
    will respond with icmp too big error if one of these fragments exceeded
    1400 bytes.
    
    However, if R1 receives fragment sizes 1200 and 100, it would
    forward the reassembled packet without refragmenting, i.e.
    R2 will send an icmp error in response to a packet that was never sent,
    citing mtu that the original sender never exceeded.
    
    The other minor issue is that a refragmentation on R1 will conceal the
    MTU of R2-B since refragmentation does not set DF bit on the fragments.
    
    This modifies ip_fragment so that we track largest fragment size seen
    both for DF and non-DF packets, and set frag_max_size to the largest
    value.
    
    If the DF fragment size is larger or equal to the non-df one, we will
    consider the packet a path mtu probe:
    We set DF bit on the reassembled skb and also tag it with a new IPCB flag
    to force refragmentation even if skb fits outdev mtu.
    
    We will also set DF bit on each fragment in this case.
    
    Joint work with Hannes Frederic Sowa.
    
    Reported-by: Jesse Gross <jesse@nicira.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 8d1765577acc..e1300b3dd597 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -43,7 +43,7 @@ enum {
  * @len: total length of the original datagram
  * @meat: length of received fragments so far
  * @flags: fragment queue flags
- * @max_size: (ipv4 only) maximum received fragment size with IP_DF set
+ * @max_size: maximum received fragment size
  * @net: namespace that this frag belongs to
  */
 struct inet_frag_queue {

commit 908c7f1949cb7cc6e92ba8f18f2998e87e265b8e
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 8 09:51:29 2014 +0900

    percpu_counter: add @gfp to percpu_counter_init()
    
    Percpu allocator now supports allocation mask.  Add @gfp to
    percpu_counter_init() so that !GFP_KERNEL allocation masks can be used
    with percpu_counters too.
    
    We could have left percpu_counter_init() alone and added
    percpu_counter_init_gfp(); however, the number of users isn't that
    high and introducing _gfp variants to all percpu data structures would
    be quite ugly, so let's just do the conversion.  This is the one with
    the most users.  Other percpu data structures are a lot easier to
    convert.
    
    This patch doesn't make any functional difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Jan Kara <jack@suse.cz>
    Acked-by: "David S. Miller" <davem@davemloft.net>
    Cc: x86@kernel.org
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 65a8855e99fe..8d1765577acc 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -151,7 +151,7 @@ static inline void add_frag_mem_limit(struct inet_frag_queue *q, int i)
 
 static inline void init_frag_mem_limit(struct netns_frags *nf)
 {
-	percpu_counter_init(&nf->mem, 0);
+	percpu_counter_init(&nf->mem, 0, GFP_KERNEL);
 }
 
 static inline unsigned int sum_frag_mem_limit(struct netns_frags *nf)

commit d4ad4d22e7ac6b8711b35d7e86eb29f03f8ac153
Author: Nikolay Aleksandrov <nikolay@redhat.com>
Date:   Fri Aug 1 12:29:48 2014 +0200

    inet: frags: use kmem_cache for inet_frag_queue
    
    Use kmem_cache to allocate/free inet_frag_queue objects since they're
    all the same size per inet_frags user and are alloced/freed in high volumes
    thus making it a perfect case for kmem_cache.
    
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Acked-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 90015c47b447..65a8855e99fe 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -101,9 +101,11 @@ struct inet_frags {
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*skb_free)(struct sk_buff *);
 	void			(*frag_expire)(unsigned long data);
+	struct kmem_cache	*frags_cachep;
+	const char		*frags_cache_name;
 };
 
-void inet_frags_init(struct inet_frags *);
+int inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
 void inet_frags_init_net(struct netns_frags *nf);

commit 1ab1934ed80aa90b268a62a561f8fdc60812793c
Author: Nikolay Aleksandrov <nikolay@redhat.com>
Date:   Fri Aug 1 12:29:45 2014 +0200

    inet: frags: enum the flag definitions and add descriptions
    
    Move the flags to an enum definion, swap FIRST_IN/LAST_IN to be in increasing
    order and add comments explaining each flag and the inet_frag_queue struct
    members.
    
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 5024d6c20407..90015c47b447 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -15,25 +15,49 @@ struct netns_frags {
 	int			low_thresh;
 };
 
+/**
+ * fragment queue flags
+ *
+ * @INET_FRAG_FIRST_IN: first fragment has arrived
+ * @INET_FRAG_LAST_IN: final fragment has arrived
+ * @INET_FRAG_COMPLETE: frag queue has been processed and is due for destruction
+ * @INET_FRAG_EVICTED: frag queue is being evicted
+ */
+enum {
+	INET_FRAG_FIRST_IN	= BIT(0),
+	INET_FRAG_LAST_IN	= BIT(1),
+	INET_FRAG_COMPLETE	= BIT(2),
+	INET_FRAG_EVICTED	= BIT(3)
+};
+
+/**
+ * struct inet_frag_queue - fragment queue
+ *
+ * @lock: spinlock protecting the queue
+ * @timer: queue expiration timer
+ * @list: hash bucket list
+ * @refcnt: reference count of the queue
+ * @fragments: received fragments head
+ * @fragments_tail: received fragments tail
+ * @stamp: timestamp of the last received fragment
+ * @len: total length of the original datagram
+ * @meat: length of received fragments so far
+ * @flags: fragment queue flags
+ * @max_size: (ipv4 only) maximum received fragment size with IP_DF set
+ * @net: namespace that this frag belongs to
+ */
 struct inet_frag_queue {
 	spinlock_t		lock;
-	struct timer_list	timer;      /* when will this queue expire? */
+	struct timer_list	timer;
 	struct hlist_node	list;
 	atomic_t		refcnt;
-	struct sk_buff		*fragments; /* list of received fragments */
+	struct sk_buff		*fragments;
 	struct sk_buff		*fragments_tail;
 	ktime_t			stamp;
-	int			len;        /* total length of orig datagram */
+	int			len;
 	int			meat;
-	__u8			flags;    /* first/last segment arrived? */
-
-#define INET_FRAG_EVICTED	8
-#define INET_FRAG_COMPLETE	4
-#define INET_FRAG_FIRST_IN	2
-#define INET_FRAG_LAST_IN	1
-
+	__u8			flags;
 	u16			max_size;
-
 	struct netns_frags	*net;
 };
 

commit 06aa8b8a0345c78f4d9a1fb3f852952b12a0e40c
Author: Nikolay Aleksandrov <nikolay@redhat.com>
Date:   Fri Aug 1 12:29:44 2014 +0200

    inet: frags: rename last_in to flags
    
    The last_in field has been used to store various flags different from
    first/last frag in so give it a more descriptive name: flags.
    
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 6f4930a0b660..5024d6c20407 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -25,7 +25,7 @@ struct inet_frag_queue {
 	ktime_t			stamp;
 	int			len;        /* total length of orig datagram */
 	int			meat;
-	__u8			last_in;    /* first/last segment arrived? */
+	__u8			flags;    /* first/last segment arrived? */
 
 #define INET_FRAG_EVICTED	8
 #define INET_FRAG_COMPLETE	4

commit ab1c724f633080ed2e8a0cfe61654599b55cf8f9
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 24 16:50:36 2014 +0200

    inet: frag: use seqlock for hash rebuild
    
    rehash is rare operation, don't force readers to take
    the read-side rwlock.
    
    Instead, we only have to detect the (rare) case where
    the secret was altered while we are trying to insert
    a new inetfrag queue into the table.
    
    If it was changed, drop the bucket lock and recompute
    the hash to get the 'new' chain bucket that we have to
    insert into.
    
    Joint work with Nikolay Aleksandrov.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index d9cc5bb64854..6f4930a0b660 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -53,11 +53,6 @@ struct inet_frag_bucket {
 
 struct inet_frags {
 	struct inet_frag_bucket	hash[INETFRAGS_HASHSZ];
-	/* This rwlock is a global lock (seperate per IPv4, IPv6 and
-	 * netfilter). Important to keep this on a seperate cacheline.
-	 * Its primarily a rebuild protection rwlock.
-	 */
-	rwlock_t		lock ____cacheline_aligned_in_smp;
 
 	struct work_struct	frags_work;
 	unsigned int next_bucket;
@@ -66,8 +61,12 @@ struct inet_frags {
 
 	/* The first call to hashfn is responsible to initialize
 	 * rnd. This is best done with net_get_random_once.
+	 *
+	 * rnd_seqlock is used to let hash insertion detect
+	 * when it needs to re-lookup the hash chain to use.
 	 */
 	u32			rnd;
+	seqlock_t		rnd_seqlock;
 	int			qsize;
 
 	unsigned int		(*hashfn)(const struct inet_frag_queue *);
@@ -89,8 +88,8 @@ void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q, struct inet_frags *f);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
-		struct inet_frags *f, void *key, unsigned int hash)
-	__releases(&f->lock);
+		struct inet_frags *f, void *key, unsigned int hash);
+
 void inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,
 				   const char *prefix);
 

commit e3a57d18b06179d68fcf7a0a06ad844493c65e06
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 24 16:50:35 2014 +0200

    inet: frag: remove periodic secret rebuild timer
    
    merge functionality into the eviction workqueue.
    
    Instead of rebuilding every n seconds, take advantage of the upper
    hash chain length limit.
    
    If we hit it, mark table for rebuild and schedule workqueue.
    To prevent frequent rebuilds when we're completely overloaded,
    don't rebuild more than once every 5 seconds.
    
    ipfrag_secret_interval sysctl is now obsolete and has been marked as
    deprecated, it still can be changed so scripts won't be broken but it
    won't have any effect. A comment is left above each unused secret_timer
    variable to avoid confusion.
    
    Joint work with Nikolay Aleksandrov.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 90d21ea62c59..d9cc5bb64854 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -58,11 +58,11 @@ struct inet_frags {
 	 * Its primarily a rebuild protection rwlock.
 	 */
 	rwlock_t		lock ____cacheline_aligned_in_smp;
-	int			secret_interval;
-	struct timer_list	secret_timer;
 
 	struct work_struct	frags_work;
 	unsigned int next_bucket;
+	unsigned long last_rebuild_jiffies;
+	bool rebuild;
 
 	/* The first call to hashfn is responsible to initialize
 	 * rnd. This is best done with net_get_random_once.

commit 3fd588eb90bfbba17091381006ecafe29c45db4a
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 24 16:50:34 2014 +0200

    inet: frag: remove lru list
    
    no longer used.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 68de33765705..90d21ea62c59 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -4,9 +4,6 @@
 #include <linux/percpu_counter.h>
 
 struct netns_frags {
-	struct list_head	lru_list;
-	spinlock_t		lru_lock;
-
 	/* The percpu_counter "mem" need to be cacheline aligned.
 	 *  mem.count must not share cacheline with other writers
 	 */
@@ -21,7 +18,6 @@ struct netns_frags {
 struct inet_frag_queue {
 	spinlock_t		lock;
 	struct timer_list	timer;      /* when will this queue expire? */
-	struct list_head	lru_list;   /* lru list member */
 	struct hlist_node	list;
 	atomic_t		refcnt;
 	struct sk_buff		*fragments; /* list of received fragments */
@@ -91,8 +87,7 @@ void inet_frags_init_net(struct netns_frags *nf);
 void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
-void inet_frag_destroy(struct inet_frag_queue *q,
-				struct inet_frags *f, int *work);
+void inet_frag_destroy(struct inet_frag_queue *q, struct inet_frags *f);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
 		struct inet_frags *f, void *key, unsigned int hash)
 	__releases(&f->lock);
@@ -102,7 +97,7 @@ void inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {
 	if (atomic_dec_and_test(&q->refcnt))
-		inet_frag_destroy(q, f, NULL);
+		inet_frag_destroy(q, f);
 }
 
 /* Memory Tracking Functions. */
@@ -145,29 +140,6 @@ static inline unsigned int sum_frag_mem_limit(struct netns_frags *nf)
 	return res;
 }
 
-static inline void inet_frag_lru_move(struct inet_frag_queue *q)
-{
-	spin_lock(&q->net->lru_lock);
-	if (!list_empty(&q->lru_list))
-		list_move_tail(&q->lru_list, &q->net->lru_list);
-	spin_unlock(&q->net->lru_lock);
-}
-
-static inline void inet_frag_lru_del(struct inet_frag_queue *q)
-{
-	spin_lock(&q->net->lru_lock);
-	list_del_init(&q->lru_list);
-	spin_unlock(&q->net->lru_lock);
-}
-
-static inline void inet_frag_lru_add(struct netns_frags *nf,
-				     struct inet_frag_queue *q)
-{
-	spin_lock(&nf->lru_lock);
-	list_add_tail(&q->lru_list, &nf->lru_list);
-	spin_unlock(&nf->lru_lock);
-}
-
 /* RFC 3168 support :
  * We want to check ECN values of all fragments, do detect invalid combinations.
  * In ipq->ecn, we store the OR value of each ip4_frag_ecn() fragment value.

commit 434d305405ab86414f6ea3f261307d443a2c3506
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 24 16:50:33 2014 +0200

    inet: frag: don't account number of fragment queues
    
    The 'nqueues' counter is protected by the lru list lock,
    once thats removed this needs to be converted to atomic
    counter.  Given this isn't used for anything except for
    reporting it to userspace via /proc, just remove it.
    
    We still report the memory currently used by fragment
    reassembly queues.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e975032ea11b..68de33765705 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -4,7 +4,6 @@
 #include <linux/percpu_counter.h>
 
 struct netns_frags {
-	int			nqueues;
 	struct list_head	lru_list;
 	spinlock_t		lru_lock;
 
@@ -158,7 +157,6 @@ static inline void inet_frag_lru_del(struct inet_frag_queue *q)
 {
 	spin_lock(&q->net->lru_lock);
 	list_del_init(&q->lru_list);
-	q->net->nqueues--;
 	spin_unlock(&q->net->lru_lock);
 }
 
@@ -167,7 +165,6 @@ static inline void inet_frag_lru_add(struct netns_frags *nf,
 {
 	spin_lock(&nf->lru_lock);
 	list_add_tail(&q->lru_list, &nf->lru_list);
-	q->net->nqueues++;
 	spin_unlock(&nf->lru_lock);
 }
 

commit b13d3cbfb8e8a8f53930af67d1ebf05149f32c24
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 24 16:50:32 2014 +0200

    inet: frag: move eviction of queues to work queue
    
    When the high_thresh limit is reached we try to toss the 'oldest'
    incomplete fragment queues until memory limits are below the low_thresh
    value.  This happens in softirq/packet processing context.
    
    This has two drawbacks:
    
    1) processors might evict a queue that was about to be completed
    by another cpu, because they will compete wrt. resource usage and
    resource reclaim.
    
    2) LRU list maintenance is expensive.
    
    But when constantly overloaded, even the 'least recently used' element is
    recent, so removing 'lru' queue first is not 'fairer' than removing any
    other fragment queue.
    
    This moves eviction out of the fast path:
    
    When the low threshold is reached, a work queue is scheduled
    which then iterates over the table and removes the queues that exceed
    the memory limits of the namespace. It sets a new flag called
    INET_FRAG_EVICTED on the evicted queues so the proper counters will get
    incremented when the queue is forcefully expired.
    
    When the high threshold is reached, no more fragment queues are
    created until we're below the limit again.
    
    The LRU list is now unused and will be removed in a followup patch.
    
    Joint work with Nikolay Aleksandrov.
    
    Suggested-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 9fe644d1a26e..e975032ea11b 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -32,6 +32,7 @@ struct inet_frag_queue {
 	int			meat;
 	__u8			last_in;    /* first/last segment arrived? */
 
+#define INET_FRAG_EVICTED	8
 #define INET_FRAG_COMPLETE	4
 #define INET_FRAG_FIRST_IN	2
 #define INET_FRAG_LAST_IN	1
@@ -48,7 +49,7 @@ struct inet_frag_queue {
  *	       rounded up (SKB_TRUELEN(0) + sizeof(struct ipq or
  *	       struct frag_queue))
  */
-#define INETFRAGS_MAXDEPTH		128
+#define INETFRAGS_MAXDEPTH	128
 
 struct inet_frag_bucket {
 	struct hlist_head	chain;
@@ -65,6 +66,9 @@ struct inet_frags {
 	int			secret_interval;
 	struct timer_list	secret_timer;
 
+	struct work_struct	frags_work;
+	unsigned int next_bucket;
+
 	/* The first call to hashfn is responsible to initialize
 	 * rnd. This is best done with net_get_random_once.
 	 */

commit 86e93e470cadedda9181a2bd9aee1d9d2e5e9c0f
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 24 16:50:31 2014 +0200

    inet: frag: move evictor calls into frag_find function
    
    First step to move eviction handling into a work queue.
    
    We lose two spots that accounted evicted fragments in MIB counters.
    
    Accounting will be restored since the upcoming work-queue evictor
    invokes the frag queue timer callbacks instead.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 15033057d44e..9fe644d1a26e 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -90,7 +90,6 @@ void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
-int inet_frag_evictor(struct netns_frags *nf, struct inet_frags *f, bool force);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
 		struct inet_frags *f, void *key, unsigned int hash)
 	__releases(&f->lock);

commit 36c7778218b93d96d88d68f116a711f6a598b72f
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Jul 24 16:50:29 2014 +0200

    inet: frag: constify match, hashfn and constructor arguments
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 6f59de98dabd..15033057d44e 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -71,10 +71,11 @@ struct inet_frags {
 	u32			rnd;
 	int			qsize;
 
-	unsigned int		(*hashfn)(struct inet_frag_queue *);
-	bool			(*match)(struct inet_frag_queue *q, void *arg);
+	unsigned int		(*hashfn)(const struct inet_frag_queue *);
+	bool			(*match)(const struct inet_frag_queue *q,
+					 const void *arg);
 	void			(*constructor)(struct inet_frag_queue *q,
-						void *arg);
+					       const void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*skb_free)(struct sk_buff *);
 	void			(*frag_expire)(unsigned long data);
@@ -131,9 +132,9 @@ static inline void init_frag_mem_limit(struct netns_frags *nf)
 	percpu_counter_init(&nf->mem, 0);
 }
 
-static inline int sum_frag_mem_limit(struct netns_frags *nf)
+static inline unsigned int sum_frag_mem_limit(struct netns_frags *nf)
 {
-	int res;
+	unsigned int res;
 
 	local_bh_disable();
 	res = percpu_counter_sum_positive(&nf->mem);

commit 7088ad74e6e710d0c80ea2cead9500f47a2a5d58
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Wed Oct 23 11:06:57 2013 +0200

    inet: remove old fragmentation hash initializing
    
    All fragmentation hash secrets now get initialized by their
    corresponding hash function with net_get_random_once. Thus we can
    eliminate the initial seeding.
    
    Also provide a comment that hash secret seeding happens at the first
    call to the corresponding hashing function.
    
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index bfcbc0017950..6f59de98dabd 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -64,6 +64,10 @@ struct inet_frags {
 	rwlock_t		lock ____cacheline_aligned_in_smp;
 	int			secret_interval;
 	struct timer_list	secret_timer;
+
+	/* The first call to hashfn is responsible to initialize
+	 * rnd. This is best done with net_get_random_once.
+	 */
 	u32			rnd;
 	int			qsize;
 

commit b56141ab34e2c3e2d7960cea12c20c99530c0c76
Author: Konstantin Khlebnikov <khlebnikov@openvz.org>
Date:   Sun May 5 04:56:22 2013 +0000

    net: frag, fix race conditions in LRU list maintenance
    
    This patch fixes race between inet_frag_lru_move() and inet_frag_lru_add()
    which was introduced in commit 3ef0eb0db4bf92c6d2510fe5c4dc51852746f206
    ("net: frag, move LRU list maintenance outside of rwlock")
    
    One cpu already added new fragment queue into hash but not into LRU.
    Other cpu found it in hash and tries to move it to the end of LRU.
    This leads to NULL pointer dereference inside of list_move_tail().
    
    Another possible race condition is between inet_frag_lru_move() and
    inet_frag_lru_del(): move can happens after deletion.
    
    This patch initializes LRU list head before adding fragment into hash and
    inet_frag_lru_move() doesn't touches it if it's empty.
    
    I saw this kernel oops two times in a couple of days.
    
    [119482.128853] BUG: unable to handle kernel NULL pointer dereference at           (null)
    [119482.132693] IP: [<ffffffff812ede89>] __list_del_entry+0x29/0xd0
    [119482.136456] PGD 2148f6067 PUD 215ab9067 PMD 0
    [119482.140221] Oops: 0000 [#1] SMP
    [119482.144008] Modules linked in: vfat msdos fat 8021q fuse nfsd auth_rpcgss nfs_acl nfs lockd sunrpc ppp_async ppp_generic bridge slhc stp llc w83627ehf hwmon_vid snd_hda_codec_hdmi snd_hda_codec_realtek kvm_amd k10temp kvm snd_hda_intel snd_hda_codec edac_core radeon snd_hwdep ath9k snd_pcm ath9k_common snd_page_alloc ath9k_hw snd_timer snd soundcore drm_kms_helper ath ttm r8169 mii
    [119482.152692] CPU 3
    [119482.152721] Pid: 20, comm: ksoftirqd/3 Not tainted 3.9.0-zurg-00001-g9f95269 #132 To Be Filled By O.E.M. To Be Filled By O.E.M./RS880D
    [119482.161478] RIP: 0010:[<ffffffff812ede89>]  [<ffffffff812ede89>] __list_del_entry+0x29/0xd0
    [119482.166004] RSP: 0018:ffff880216d5db58  EFLAGS: 00010207
    [119482.170568] RAX: 0000000000000000 RBX: ffff88020882b9c0 RCX: dead000000200200
    [119482.175189] RDX: 0000000000000000 RSI: 0000000000000880 RDI: ffff88020882ba00
    [119482.179860] RBP: ffff880216d5db58 R08: ffffffff8155c7f0 R09: 0000000000000014
    [119482.184570] R10: 0000000000000000 R11: 0000000000000000 R12: ffff88020882ba00
    [119482.189337] R13: ffffffff81c8d780 R14: ffff880204357f00 R15: 00000000000005a0
    [119482.194140] FS:  00007f58124dc700(0000) GS:ffff88021fcc0000(0000) knlGS:0000000000000000
    [119482.198928] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [119482.203711] CR2: 0000000000000000 CR3: 00000002155f0000 CR4: 00000000000007e0
    [119482.208533] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [119482.213371] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    [119482.218221] Process ksoftirqd/3 (pid: 20, threadinfo ffff880216d5c000, task ffff880216d3a9a0)
    [119482.223113] Stack:
    [119482.228004]  ffff880216d5dbd8 ffffffff8155dcda 0000000000000000 ffff000200000001
    [119482.233038]  ffff8802153c1f00 ffff880000289440 ffff880200000014 ffff88007bc72000
    [119482.238083]  00000000000079d5 ffff88007bc72f44 ffffffff00000002 ffff880204357f00
    [119482.243090] Call Trace:
    [119482.248009]  [<ffffffff8155dcda>] ip_defrag+0x8fa/0xd10
    [119482.252921]  [<ffffffff815a8013>] ipv4_conntrack_defrag+0x83/0xe0
    [119482.257803]  [<ffffffff8154485b>] nf_iterate+0x8b/0xa0
    [119482.262658]  [<ffffffff8155c7f0>] ? inet_del_offload+0x40/0x40
    [119482.267527]  [<ffffffff815448e4>] nf_hook_slow+0x74/0x130
    [119482.272412]  [<ffffffff8155c7f0>] ? inet_del_offload+0x40/0x40
    [119482.277302]  [<ffffffff8155d068>] ip_rcv+0x268/0x320
    [119482.282147]  [<ffffffff81519992>] __netif_receive_skb_core+0x612/0x7e0
    [119482.286998]  [<ffffffff81519b78>] __netif_receive_skb+0x18/0x60
    [119482.291826]  [<ffffffff8151a650>] process_backlog+0xa0/0x160
    [119482.296648]  [<ffffffff81519f29>] net_rx_action+0x139/0x220
    [119482.301403]  [<ffffffff81053707>] __do_softirq+0xe7/0x220
    [119482.306103]  [<ffffffff81053868>] run_ksoftirqd+0x28/0x40
    [119482.310809]  [<ffffffff81074f5f>] smpboot_thread_fn+0xff/0x1a0
    [119482.315515]  [<ffffffff81074e60>] ? lg_local_lock_cpu+0x40/0x40
    [119482.320219]  [<ffffffff8106d870>] kthread+0xc0/0xd0
    [119482.324858]  [<ffffffff8106d7b0>] ? insert_kthread_work+0x40/0x40
    [119482.329460]  [<ffffffff816c32dc>] ret_from_fork+0x7c/0xb0
    [119482.334057]  [<ffffffff8106d7b0>] ? insert_kthread_work+0x40/0x40
    [119482.338661] Code: 00 00 55 48 8b 17 48 b9 00 01 10 00 00 00 ad de 48 8b 47 08 48 89 e5 48 39 ca 74 29 48 b9 00 02 20 00 00 00 ad de 48 39 c8 74 7a <4c> 8b 00 4c 39 c7 75 53 4c 8b 42 08 4c 39 c7 75 2b 48 89 42 08
    [119482.343787] RIP  [<ffffffff812ede89>] __list_del_entry+0x29/0xd0
    [119482.348675]  RSP <ffff880216d5db58>
    [119482.353493] CR2: 0000000000000000
    
    Oops happened on this path:
    ip_defrag() -> ip_frag_queue() -> inet_frag_lru_move() -> list_move_tail() -> __list_del_entry()
    
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Cc: Jesper Dangaard Brouer <brouer@redhat.com>
    Cc: Florian Westphal <fw@strlen.de>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: David S. Miller <davem@davemloft.net>
    Acked-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 4182c9be8bb5..bfcbc0017950 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -141,14 +141,15 @@ static inline int sum_frag_mem_limit(struct netns_frags *nf)
 static inline void inet_frag_lru_move(struct inet_frag_queue *q)
 {
 	spin_lock(&q->net->lru_lock);
-	list_move_tail(&q->lru_list, &q->net->lru_list);
+	if (!list_empty(&q->lru_list))
+		list_move_tail(&q->lru_list, &q->net->lru_list);
 	spin_unlock(&q->net->lru_lock);
 }
 
 static inline void inet_frag_lru_del(struct inet_frag_queue *q)
 {
 	spin_lock(&q->net->lru_lock);
-	list_del(&q->lru_list);
+	list_del_init(&q->lru_list);
 	q->net->nqueues--;
 	spin_unlock(&q->net->lru_lock);
 }

commit a4c4009f4f54dabaaea1bb2b2c3c8930e93cd409
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Thu Apr 25 09:52:25 2013 +0000

    net: increase frag hash size
    
    Increase fragmentation hash bucket size to 1024 from old 64 elems.
    
    After we increased the frag mem limits commit c2a93660 (net: increase
    fragment memory usage limits) the hash size of 64 elements is simply
    too small.  Also considering the mem limit is per netns and the hash
    table is shared for all netns.
    
    For the embedded people, note that this increase will change the hash
    table/array from using approx 1 Kbytes to 16 Kbytes.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 6f41b45e819e..4182c9be8bb5 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -41,7 +41,7 @@ struct inet_frag_queue {
 	struct netns_frags	*net;
 };
 
-#define INETFRAGS_HASHSZ		64
+#define INETFRAGS_HASHSZ	1024
 
 /* averaged:
  * max_depth = default ipfrag_high_thresh / INETFRAGS_HASHSZ /

commit 19952cc4f8f572493293a8caed27c4be89c5fc9d
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Wed Apr 3 23:38:16 2013 +0000

    net: frag queue per hash bucket locking
    
    This patch implements per hash bucket locking for the frag queue
    hash.  This removes two write locks, and the only remaining write
    lock is for protecting hash rebuild.  This essentially reduce the
    readers-writer lock to a rebuild lock.
    
    This patch is part of "net: frag performance followup"
     http://thread.gmane.org/gmane.linux.network/263644
    of which two patches have already been accepted:
    
    Same test setup as previous:
     (http://thread.gmane.org/gmane.linux.network/257155)
     Two 10G interfaces, on seperate NUMA nodes, are under-test, and uses
     Ethernet flow-control.  A third interface is used for generating the
     DoS attack (with trafgen).
    
    Notice, I have changed the frag DoS generator script to be more
    efficient/deadly.  Before it would only hit one RX queue, now its
    sending packets causing multi-queue RX, due to "better" RX hashing.
    
    Test types summary (netperf UDP_STREAM):
     Test-20G64K     == 2x10G with 65K fragments
     Test-20G3F      == 2x10G with 3x fragments (3*1472 bytes)
     Test-20G64K+DoS == Same as 20G64K with frag DoS
     Test-20G3F+DoS  == Same as 20G3F  with frag DoS
     Test-20G64K+MQ  == Same as 20G64K with Multi-Queue frag DoS
     Test-20G3F+MQ   == Same as 20G3F  with Multi-Queue frag DoS
    
    When I rebased this-patch(03) (on top of net-next commit a210576c) and
    removed the _bh spinlock, I saw a performance regression.  BUT this
    was caused by some unrelated change in-between.  See tests below.
    
    Test (A) is what I reported before for patch-02, accepted in commit 1b5ab0de.
    Test (B) verifying-retest of commit 1b5ab0de corrospond to patch-02.
    Test (C) is what I reported before for this-patch
    
    Test (D) is net-next master HEAD (commit a210576c), which reveals some
    (unknown) performance regression (compared against test (B)).
    Test (D) function as a new base-test.
    
    Performance table summary (in Mbit/s):
    
    (#) Test-type:  20G64K    20G3F    20G64K+DoS  20G3F+DoS  20G64K+MQ 20G3F+MQ
        ----------  -------   -------  ----------  ---------  --------  -------
    (A) Patch-02  : 18848.7   13230.1   4103.04     5310.36     130.0    440.2
    (B) 1b5ab0de  : 18841.5   13156.8   4101.08     5314.57     129.0    424.2
    (C) Patch-03v1: 18838.0   13490.5   4405.11     6814.72     196.6    461.6
    
    (D) a210576c  : 18321.5   11250.4   3635.34     5160.13     119.1    405.2
    (E) with _bh  : 17247.3   11492.6   3994.74     6405.29     166.7    413.6
    (F) without bh: 17471.3   11298.7   3818.05     6102.11     165.7    406.3
    
    Test (E) and (F) is this-patch(03), with(V1) and without(V2) the _bh spinlocks.
    
    I cannot explain the slow down for 20G64K (but its an artificial
    "lab-test" so I'm not worried).  But the other results does show
    improvements.  And test (E) "with _bh" version is slightly better.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Acked-by: Eric Dumazet <edumazet@google.com>
    
    ----
    V2:
    - By analysis from Hannes Frederic Sowa and Eric Dumazet, we don't
      need the spinlock _bh versions, as Netfilter currently does a
      local_bh_disable() before entering inet_fragment.
    - Fold-in desc from cover-mail
    V3:
    - Drop the chain_len counter per hash bucket.
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 7cac9c5789b5..6f41b45e819e 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -50,10 +50,16 @@ struct inet_frag_queue {
  */
 #define INETFRAGS_MAXDEPTH		128
 
+struct inet_frag_bucket {
+	struct hlist_head	chain;
+	spinlock_t		chain_lock;
+};
+
 struct inet_frags {
-	struct hlist_head	hash[INETFRAGS_HASHSZ];
+	struct inet_frag_bucket	hash[INETFRAGS_HASHSZ];
 	/* This rwlock is a global lock (seperate per IPv4, IPv6 and
 	 * netfilter). Important to keep this on a seperate cacheline.
+	 * Its primarily a rebuild protection rwlock.
 	 */
 	rwlock_t		lock ____cacheline_aligned_in_smp;
 	int			secret_interval;

commit 1b5ab0def4f6e42e8b8097c3b11d2e8d96baafec
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Wed Mar 27 05:55:56 2013 +0000

    net: use the frag lru_lock to protect netns_frags.nqueues update
    
    Move the protection of netns_frags.nqueues updates under the LRU_lock,
    instead of the write lock.  As they are located on the same cacheline,
    and this is also needed when transitioning to use per hash bucket locking.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 64b4e7d23b8a..7cac9c5789b5 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -143,6 +143,7 @@ static inline void inet_frag_lru_del(struct inet_frag_queue *q)
 {
 	spin_lock(&q->net->lru_lock);
 	list_del(&q->lru_list);
+	q->net->nqueues--;
 	spin_unlock(&q->net->lru_lock);
 }
 
@@ -151,6 +152,7 @@ static inline void inet_frag_lru_add(struct netns_frags *nf,
 {
 	spin_lock(&nf->lru_lock);
 	list_add_tail(&q->lru_list, &nf->lru_list);
+	q->net->nqueues++;
 	spin_unlock(&nf->lru_lock);
 }
 

commit be991971d53e0f5b6d13e3940192054216590072
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Fri Mar 22 08:24:37 2013 +0000

    inet: generalize ipv4-only RFC3168 5.3 ecn fragmentation handling for future use by ipv6
    
    This patch just moves some code arround to make the ip4_frag_ecn_table
    and IPFRAG_ECN_* constants accessible from the other reassembly engines. I
    also renamed ip4_frag_ecn_table to ip_frag_ecn_table.
    
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Jesper Dangaard Brouer <jbrouer@redhat.com>
    Cc: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Acked-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 0a1dcc2fa2f5..64b4e7d23b8a 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -153,4 +153,16 @@ static inline void inet_frag_lru_add(struct netns_frags *nf,
 	list_add_tail(&q->lru_list, &nf->lru_list);
 	spin_unlock(&nf->lru_lock);
 }
+
+/* RFC 3168 support :
+ * We want to check ECN values of all fragments, do detect invalid combinations.
+ * In ipq->ecn, we store the OR value of each ip4_frag_ecn() fragment value.
+ */
+#define	IPFRAG_ECN_NOT_ECT	0x01 /* one frag had ECN_NOT_ECT */
+#define	IPFRAG_ECN_ECT_1	0x02 /* one frag had ECN_ECT_1 */
+#define	IPFRAG_ECN_ECT_0	0x04 /* one frag had ECN_ECT_0 */
+#define	IPFRAG_ECN_CE		0x08 /* one frag had ECN_CE */
+
+extern const u8 ip_frag_ecn_table[16];
+
 #endif

commit 5a3da1fe9561828d0ca7eca664b16ec2b9bf0055
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Fri Mar 15 11:32:30 2013 +0000

    inet: limit length of fragment queue hash table bucket lists
    
    This patch introduces a constant limit of the fragment queue hash
    table bucket list lengths. Currently the limit 128 is choosen somewhat
    arbitrary and just ensures that we can fill up the fragment cache with
    empty packets up to the default ip_frag_high_thresh limits. It should
    just protect from list iteration eating considerable amounts of cpu.
    
    If we reach the maximum length in one hash bucket a warning is printed.
    This is implemented on the caller side of inet_frag_find to distinguish
    between the different users of inet_fragment.c.
    
    I dropped the out of memory warning in the ipv4 fragment lookup path,
    because we already get a warning by the slab allocator.
    
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Jesper Dangaard Brouer <jbrouer@redhat.com>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 76c3fe5ecc2e..0a1dcc2fa2f5 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -43,6 +43,13 @@ struct inet_frag_queue {
 
 #define INETFRAGS_HASHSZ		64
 
+/* averaged:
+ * max_depth = default ipfrag_high_thresh / INETFRAGS_HASHSZ /
+ *	       rounded up (SKB_TRUELEN(0) + sizeof(struct ipq or
+ *	       struct frag_queue))
+ */
+#define INETFRAGS_MAXDEPTH		128
+
 struct inet_frags {
 	struct hlist_head	hash[INETFRAGS_HASHSZ];
 	/* This rwlock is a global lock (seperate per IPv4, IPv6 and
@@ -76,6 +83,8 @@ int inet_frag_evictor(struct netns_frags *nf, struct inet_frags *f, bool force);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
 		struct inet_frags *f, void *key, unsigned int hash)
 	__releases(&f->lock);
+void inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,
+				   const char *prefix);
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {

commit 4cfb04854d053e4d6391d7f84495f48082342362
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Feb 22 07:43:35 2013 +0000

    net: fix possible deadlock in sum_frag_mem_limit
    
    Dave Jones reported a lockdep splat occurring in IP defrag code.
    
    commit 6d7b857d541ecd1d (net: use lib/percpu_counter API for
    fragmentation mem accounting) added a possible deadlock.
    
    Because percpu_counter_sum_positive() needs to acquire
    a lock that can be used from softirq, we need to disable BH
    in sum_frag_mem_limit()
    
    Reported-by: Dave Jones <davej@redhat.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 3f237db0a426..76c3fe5ecc2e 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -114,7 +114,13 @@ static inline void init_frag_mem_limit(struct netns_frags *nf)
 
 static inline int sum_frag_mem_limit(struct netns_frags *nf)
 {
-	return percpu_counter_sum_positive(&nf->mem);
+	int res;
+
+	local_bh_disable();
+	res = percpu_counter_sum_positive(&nf->mem);
+	local_bh_enable();
+
+	return res;
 }
 
 static inline void inet_frag_lru_move(struct inet_frag_queue *q)

commit 3ef0eb0db4bf92c6d2510fe5c4dc51852746f206
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jan 28 23:45:51 2013 +0000

    net: frag, move LRU list maintenance outside of rwlock
    
    Updating the fragmentation queues LRU (Least-Recently-Used) list,
    required taking the hash writer lock.  However, the LRU list isn't
    tied to the hash at all, so we can use a separate lock for it.
    
    Original-idea-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e0eec7450f15..3f237db0a426 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -6,6 +6,7 @@
 struct netns_frags {
 	int			nqueues;
 	struct list_head	lru_list;
+	spinlock_t		lru_lock;
 
 	/* The percpu_counter "mem" need to be cacheline aligned.
 	 *  mem.count must not share cacheline with other writers
@@ -116,4 +117,25 @@ static inline int sum_frag_mem_limit(struct netns_frags *nf)
 	return percpu_counter_sum_positive(&nf->mem);
 }
 
+static inline void inet_frag_lru_move(struct inet_frag_queue *q)
+{
+	spin_lock(&q->net->lru_lock);
+	list_move_tail(&q->lru_list, &q->net->lru_list);
+	spin_unlock(&q->net->lru_lock);
+}
+
+static inline void inet_frag_lru_del(struct inet_frag_queue *q)
+{
+	spin_lock(&q->net->lru_lock);
+	list_del(&q->lru_list);
+	spin_unlock(&q->net->lru_lock);
+}
+
+static inline void inet_frag_lru_add(struct netns_frags *nf,
+				     struct inet_frag_queue *q)
+{
+	spin_lock(&nf->lru_lock);
+	list_add_tail(&q->lru_list, &nf->lru_list);
+	spin_unlock(&nf->lru_lock);
+}
 #endif

commit 6d7b857d541ecd1d9bd997c97242d4ef94b19de2
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jan 28 23:45:33 2013 +0000

    net: use lib/percpu_counter API for fragmentation mem accounting
    
    Replace the per network namespace shared atomic "mem" accounting
    variable, in the fragmentation code, with a lib/percpu_counter.
    
    Getting percpu_counter to scale to the fragmentation code usage
    requires some tweaks.
    
    At first view, percpu_counter looks superfast, but it does not
    scale on multi-CPU/NUMA machines, because the default batch size
    is too small, for frag code usage.  Thus, I have adjusted the
    batch size by using __percpu_counter_add() directly, instead of
    percpu_counter_sub() and percpu_counter_add().
    
    The batch size is increased to 130.000, based on the largest 64K
    fragment memory usage.  This does introduce some imprecise
    memory accounting, but its does not need to be strict for this
    use-case.
    
    It is also essential, that the percpu_counter, does not
    share cacheline with other writers, to make this scale.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index f2fabc2a79de..e0eec7450f15 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -1,14 +1,17 @@
 #ifndef __NET_FRAG_H__
 #define __NET_FRAG_H__
 
+#include <linux/percpu_counter.h>
+
 struct netns_frags {
 	int			nqueues;
 	struct list_head	lru_list;
 
-	/* Its important for performance to keep lru_list and mem on
-	 * separate cachelines
+	/* The percpu_counter "mem" need to be cacheline aligned.
+	 *  mem.count must not share cacheline with other writers
 	 */
-	atomic_t		mem ____cacheline_aligned_in_smp;
+	struct percpu_counter   mem ____cacheline_aligned_in_smp;
+
 	/* sysctls */
 	int			timeout;
 	int			high_thresh;
@@ -81,29 +84,36 @@ static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f
 
 /* Memory Tracking Functions. */
 
+/* The default percpu_counter batch size is not big enough to scale to
+ * fragmentation mem acct sizes.
+ * The mem size of a 64K fragment is approx:
+ *  (44 fragments * 2944 truesize) + frag_queue struct(200) = 129736 bytes
+ */
+static unsigned int frag_percpu_counter_batch = 130000;
+
 static inline int frag_mem_limit(struct netns_frags *nf)
 {
-	return atomic_read(&nf->mem);
+	return percpu_counter_read(&nf->mem);
 }
 
 static inline void sub_frag_mem_limit(struct inet_frag_queue *q, int i)
 {
-	atomic_sub(i, &q->net->mem);
+	__percpu_counter_add(&q->net->mem, -i, frag_percpu_counter_batch);
 }
 
 static inline void add_frag_mem_limit(struct inet_frag_queue *q, int i)
 {
-	atomic_add(i, &q->net->mem);
+	__percpu_counter_add(&q->net->mem, i, frag_percpu_counter_batch);
 }
 
 static inline void init_frag_mem_limit(struct netns_frags *nf)
 {
-	atomic_set(&nf->mem, 0);
+	percpu_counter_init(&nf->mem, 0);
 }
 
 static inline int sum_frag_mem_limit(struct netns_frags *nf)
 {
-	return atomic_read(&nf->mem);
+	return percpu_counter_sum_positive(&nf->mem);
 }
 
 #endif

commit d433673e5f9180e05a770c4b2ab18c08ad51cc21
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jan 28 23:45:12 2013 +0000

    net: frag helper functions for mem limit tracking
    
    This change is primarily a preparation to ease the extension of memory
    limit tracking.
    
    The change does reduce the number atomic operation, during freeing of
    a frag queue.  This does introduce a some performance improvement, as
    these atomic operations are at the core of the performance problems
    seen on NUMA systems.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 8e4c42523f59..f2fabc2a79de 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -79,4 +79,31 @@ static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f
 		inet_frag_destroy(q, f, NULL);
 }
 
+/* Memory Tracking Functions. */
+
+static inline int frag_mem_limit(struct netns_frags *nf)
+{
+	return atomic_read(&nf->mem);
+}
+
+static inline void sub_frag_mem_limit(struct inet_frag_queue *q, int i)
+{
+	atomic_sub(i, &q->net->mem);
+}
+
+static inline void add_frag_mem_limit(struct inet_frag_queue *q, int i)
+{
+	atomic_add(i, &q->net->mem);
+}
+
+static inline void init_frag_mem_limit(struct netns_frags *nf)
+{
+	atomic_set(&nf->mem, 0);
+}
+
+static inline int sum_frag_mem_limit(struct netns_frags *nf)
+{
+	return atomic_read(&nf->mem);
+}
+
 #endif

commit 6e34a8b37aca63f109bf990d46131ee07206f5f1
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jan 28 23:44:49 2013 +0000

    net: cacheline adjust struct inet_frag_queue
    
    Fragmentation code cacheline adjusting of struct inet_frag_queue.
    
    Take advantage of the size of struct timer_list, and move all but
    spinlock_t lock, below the timer struct.  On 64-bit 'lru_list',
    'list' and 'refcnt', fits exactly into the next cacheline, and a
    new cacheline starts at 'fragments'.
    
    The netns_frags *net pointer is moved to the end of the struct,
    because its used in a compare, with "next/close-by" elements of
    which this struct is embedded into.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 54c1de781c68..8e4c42523f59 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -16,12 +16,11 @@ struct netns_frags {
 };
 
 struct inet_frag_queue {
-	struct hlist_node	list;
-	struct netns_frags	*net;
-	struct list_head	lru_list;   /* lru list member */
 	spinlock_t		lock;
-	atomic_t		refcnt;
 	struct timer_list	timer;      /* when will this queue expire? */
+	struct list_head	lru_list;   /* lru list member */
+	struct hlist_node	list;
+	atomic_t		refcnt;
 	struct sk_buff		*fragments; /* list of received fragments */
 	struct sk_buff		*fragments_tail;
 	ktime_t			stamp;
@@ -34,6 +33,8 @@ struct inet_frag_queue {
 #define INET_FRAG_LAST_IN	1
 
 	u16			max_size;
+
+	struct netns_frags	*net;
 };
 
 #define INETFRAGS_HASHSZ		64

commit 5f8e1e8b767bdb8e471d4f49612b88c606f8811e
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jan 28 23:44:37 2013 +0000

    net: cacheline adjust struct inet_frags for better frag performance
    
    The globally shared rwlock, of struct inet_frags, shares
    cacheline with the 'rnd' number, which is used by the hash
    calculations.  Fix this, as this obviously is a bad idea, as
    unnecessary cache-misses will occur when accessing the 'rnd'
    number.
    
    Also small note that, moving function ptr (*match) up in struct,
    is to avoid it lands on the next cacheline (on 64-bit).
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 91e77975eaa6..54c1de781c68 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -40,18 +40,21 @@ struct inet_frag_queue {
 
 struct inet_frags {
 	struct hlist_head	hash[INETFRAGS_HASHSZ];
-	rwlock_t		lock;
-	u32			rnd;
-	int			qsize;
+	/* This rwlock is a global lock (seperate per IPv4, IPv6 and
+	 * netfilter). Important to keep this on a seperate cacheline.
+	 */
+	rwlock_t		lock ____cacheline_aligned_in_smp;
 	int			secret_interval;
 	struct timer_list	secret_timer;
+	u32			rnd;
+	int			qsize;
 
 	unsigned int		(*hashfn)(struct inet_frag_queue *);
+	bool			(*match)(struct inet_frag_queue *q, void *arg);
 	void			(*constructor)(struct inet_frag_queue *q,
 						void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*skb_free)(struct sk_buff *);
-	bool			(*match)(struct inet_frag_queue *q, void *arg);
 	void			(*frag_expire)(unsigned long data);
 };
 

commit cd39a7890aed7433beb3188c7ad8591e260ebf10
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jan 28 23:44:14 2013 +0000

    net: cacheline adjust struct netns_frags for better frag performance
    
    This small cacheline adjustment of struct netns_frags improves
    performance significantly for the fragmentation code.
    
    Struct members 'lru_list' and 'mem' are both hot elements, and it
    hurts performance, due to cacheline bouncing at every call point,
    when they share a cacheline.  Also notice, how mem is placed
    together with 'high_thresh' and 'low_thresh', as they are used in
    the compare operations together.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 32786a044718..91e77975eaa6 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -3,9 +3,12 @@
 
 struct netns_frags {
 	int			nqueues;
-	atomic_t		mem;
 	struct list_head	lru_list;
 
+	/* Its important for performance to keep lru_list and mem on
+	 * separate cachelines
+	 */
+	atomic_t		mem ____cacheline_aligned_in_smp;
 	/* sysctls */
 	int			timeout;
 	int			high_thresh;

commit 6b102865e7ba9ff1e3c49c32c7187bb427d91798
Author: Amerigo Wang <amwang@redhat.com>
Date:   Tue Sep 18 16:50:11 2012 +0000

    ipv6: unify fragment thresh handling code
    
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Michal Kubeek <mkubecek@suse.cz>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <amwang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 5098ee7b7e0e..32786a044718 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -61,7 +61,7 @@ void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
-int inet_frag_evictor(struct netns_frags *nf, struct inet_frags *f);
+int inet_frag_evictor(struct netns_frags *nf, struct inet_frags *f, bool force);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
 		struct inet_frags *f, void *key, unsigned int hash)
 	__releases(&f->lock);

commit 5f2d04f1f9b52604fca6ee08a77972c0df67e082
Author: Patrick McHardy <kaber@trash.net>
Date:   Sun Aug 26 19:13:55 2012 +0200

    ipv4: fix path MTU discovery with connection tracking
    
    IPv4 conntrack defragments incoming packet at the PRE_ROUTING hook and
    (in case of forwarded packets) refragments them at POST_ROUTING
    independent of the IP_DF flag. Refragmentation uses the dst_mtu() of
    the local route without caring about the original fragment sizes,
    thereby breaking PMTUD.
    
    This patch fixes this by keeping track of the largest received fragment
    with IP_DF set and generates an ICMP fragmentation required error during
    refragmentation if that size exceeds the MTU.
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Acked-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 2431cf83aeca..5098ee7b7e0e 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -29,6 +29,8 @@ struct inet_frag_queue {
 #define INET_FRAG_COMPLETE	4
 #define INET_FRAG_FIRST_IN	2
 #define INET_FRAG_LAST_IN	1
+
+	u16			max_size;
 };
 
 #define INETFRAGS_HASHSZ		64

commit cbc264cacd08e51fd4a64b5d5b1ba48f523990d1
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 18 05:57:13 2012 +0200

    ip_frag: struct inet_frags match() method returns a bool
    
    - match() method returns a boolean
    - return (A && B && C && D) -> return A && B && C && D
    - fix indentation
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 16ff29a7bb30..2431cf83aeca 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -46,8 +46,7 @@ struct inet_frags {
 						void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*skb_free)(struct sk_buff *);
-	int			(*match)(struct inet_frag_queue *q,
-						void *arg);
+	bool			(*match)(struct inet_frag_queue *q, void *arg);
 	void			(*frag_expire)(unsigned long data);
 };
 

commit d6bebca92c663fb216c072193945946f3807ca7f
Author: Changli Gao <xiaosuo@gmail.com>
Date:   Tue Jun 29 04:39:37 2010 +0000

    fragment: add fast path for in-order fragments
    
    add fast path for in-order fragments
    
    As the fragments are sent in order in most of OSes, such as Windows, Darwin and
    FreeBSD, it is likely the new fragments are at the end of the inet_frag_queue.
    In the fast path, we check if the skb at the end of the inet_frag_queue is the
    prev we expect.
    
    Signed-off-by: Changli Gao <xiaosuo@gmail.com>
    ----
     include/net/inet_frag.h |    1 +
     net/ipv4/ip_fragment.c  |   12 ++++++++++++
     net/ipv6/reassembly.c   |   11 +++++++++++
     3 files changed, 24 insertions(+)
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 39f2dc943908..16ff29a7bb30 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -20,6 +20,7 @@ struct inet_frag_queue {
 	atomic_t		refcnt;
 	struct timer_list	timer;      /* when will this queue expire? */
 	struct sk_buff		*fragments; /* list of received fragments */
+	struct sk_buff		*fragments_tail;
 	ktime_t			stamp;
 	int			len;        /* total length of orig datagram */
 	int			meat;

commit 56bca31ff1989aa8b60f717e984b0e624f06324e
Author: Hannes Eder <hannes@hanneseder.net>
Date:   Wed Feb 25 10:32:52 2009 +0000

    inet fragments: fix sparse warning: context imbalance
    
    Impact: Attribute function with __releases(...)
    
    Fix this sparse warning:
      net/ipv4/inet_fragment.c:276:35: warning: context imbalance in 'inet_frag_find' - unexpected unlock
    
    Signed-off-by: Hannes Eder <hannes@hanneseder.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e081eefd6f47..39f2dc943908 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -61,7 +61,8 @@ void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
 int inet_frag_evictor(struct netns_frags *nf, struct inet_frags *f);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
-		struct inet_frags *f, void *key, unsigned int hash);
+		struct inet_frags *f, void *key, unsigned int hash)
+	__releases(&f->lock);
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {

commit bc578a54f0fd489d0722303f9a52508495ccaf9a
Author: Joe Perches <joe@perches.com>
Date:   Fri Mar 28 16:35:27 2008 -0700

    [NET]: Rename inet_frag.h identifiers COMPLETE, FIRST_IN, LAST_IN to INET_FRAG_*
    
    On Fri, 2008-03-28 at 03:24 -0700, Andrew Morton wrote:
    > they should all be renamed.
    
    Done for include/net and net
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 7374251b9787..e081eefd6f47 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -25,9 +25,9 @@ struct inet_frag_queue {
 	int			meat;
 	__u8			last_in;    /* first/last segment arrived? */
 
-#define COMPLETE		4
-#define FIRST_IN		2
-#define LAST_IN			1
+#define INET_FRAG_COMPLETE	4
+#define INET_FRAG_FIRST_IN	2
+#define INET_FRAG_LAST_IN	1
 };
 
 #define INETFRAGS_HASHSZ		64

commit 81566e8322c3f6c6f9a2277fe0e440fee8d917bd
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:12:39 2008 -0800

    [NETNS][FRAGS]: Make the pernet subsystem for fragments.
    
    On namespace start we mainly prepare the ctl variables.
    
    When the namespace is stopped we have to kill all the fragments that
    point to this namespace.  The inet_frags_exit_net() handles it.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 3695ff4cfe63..7374251b9787 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -54,6 +54,7 @@ void inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
 void inet_frags_init_net(struct netns_frags *nf);
+void inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f);
 
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,

commit 3140c25c82106645a6b1fc469dab7006a1d09fd0
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:11:48 2008 -0800

    [NETNS][FRAGS]: Make the LRU list per namespace.
    
    The inet_frags.lru_list is used for evicting only, so we have
    to make it per-namespace, to evict only those fragments, who's
    namespace exceeded its high threshold, but not the whole hash.
    Besides, this helps to avoid long loops  in evictor.
    
    The spinlock is not per-namespace because it protects the
    hash table as well, which is global.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 1917fbeb362b..3695ff4cfe63 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -4,6 +4,7 @@
 struct netns_frags {
 	int			nqueues;
 	atomic_t		mem;
+	struct list_head	lru_list;
 
 	/* sysctls */
 	int			timeout;
@@ -32,7 +33,6 @@ struct inet_frag_queue {
 #define INETFRAGS_HASHSZ		64
 
 struct inet_frags {
-	struct list_head	lru_list;
 	struct hlist_head	hash[INETFRAGS_HASHSZ];
 	rwlock_t		lock;
 	u32			rnd;

commit 3b4bc4a2bfe80d01ebd4f2b6dcc58986c970ed16
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:11:04 2008 -0800

    [NETNS][FRAGS]: Isolate the secret interval from namespaces.
    
    Since we have one hashtable to lookup the fragment, having
    different secret_interval-s for hash rebuild doesn't make
    sense, so move this one to inet_frags.
    
    The inet_frags_ctl becomes empty after this, so remove it.
    The appropriate ctl table is kept read-only in namespaces.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index de4135925490..1917fbeb362b 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -31,18 +31,14 @@ struct inet_frag_queue {
 
 #define INETFRAGS_HASHSZ		64
 
-struct inet_frags_ctl {
-	int secret_interval;
-};
-
 struct inet_frags {
 	struct list_head	lru_list;
 	struct hlist_head	hash[INETFRAGS_HASHSZ];
 	rwlock_t		lock;
 	u32			rnd;
 	int			qsize;
+	int			secret_interval;
 	struct timer_list	secret_timer;
-	struct inet_frags_ctl	*ctl;
 
 	unsigned int		(*hashfn)(struct inet_frag_queue *);
 	void			(*constructor)(struct inet_frag_queue *q,

commit e31e0bdc7e7fb9a4b09d2f3266c035a18fdcee9d
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:10:13 2008 -0800

    [NETNS][FRAGS]: Make thresholds work in namespaces.
    
    This is the same as with the timeout variable.
    
    Currently, after exceeding the high threshold _all_
    the fragments are evicted, but it will be fixed in
    later patch.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index f56e296e6227..de4135925490 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -7,6 +7,8 @@ struct netns_frags {
 
 	/* sysctls */
 	int			timeout;
+	int			high_thresh;
+	int			low_thresh;
 };
 
 struct inet_frag_queue {
@@ -30,8 +32,6 @@ struct inet_frag_queue {
 #define INETFRAGS_HASHSZ		64
 
 struct inet_frags_ctl {
-	int high_thresh;
-	int low_thresh;
 	int secret_interval;
 };
 

commit b2fd5321dd160ef309dfb6cfc78ed8de4a830659
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:09:37 2008 -0800

    [NETNS][FRAGS]: Make the net.ipv4.ipfrag_timeout work in namespaces.
    
    Move it to the netns_frags, adjust the usage and
    make the appropriate ctl table writable.
    
    Now fragment, that live in different namespaces can
    live for different times.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 6edce7b2ff13..f56e296e6227 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -4,6 +4,9 @@
 struct netns_frags {
 	int			nqueues;
 	atomic_t		mem;
+
+	/* sysctls */
+	int			timeout;
 };
 
 struct inet_frag_queue {
@@ -29,7 +32,6 @@ struct inet_frag_queue {
 struct inet_frags_ctl {
 	int high_thresh;
 	int low_thresh;
-	int timeout;
 	int secret_interval;
 };
 

commit 6ddc082223ef0f73717b4133fa7e648842bbfd02
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:07:25 2008 -0800

    [NETNS][FRAGS]: Make the mem counter per-namespace.
    
    This is also simple, but introduces more changes, since
    then mem counter is altered in more places.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index d36f3a6e6d4e..6edce7b2ff13 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -3,6 +3,7 @@
 
 struct netns_frags {
 	int			nqueues;
+	atomic_t		mem;
 };
 
 struct inet_frag_queue {
@@ -38,7 +39,6 @@ struct inet_frags {
 	rwlock_t		lock;
 	u32			rnd;
 	int			qsize;
-	atomic_t		mem;
 	struct timer_list	secret_timer;
 	struct inet_frags_ctl	*ctl;
 
@@ -60,7 +60,7 @@ void inet_frags_init_net(struct netns_frags *nf);
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
-int inet_frag_evictor(struct inet_frags *f);
+int inet_frag_evictor(struct netns_frags *nf, struct inet_frags *f);
 struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
 		struct inet_frags *f, void *key, unsigned int hash);
 

commit e5a2bb842cd9681d00d4ca963e63e4d3647e66f8
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:06:23 2008 -0800

    [NETNS][FRAGS]: Make the nqueues counter per-namespace.
    
    This is simple - just move the variable from struct inet_frags
    to struct netns_frags and adjust the usage appropriately.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 8ab6df64a12a..d36f3a6e6d4e 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -2,6 +2,7 @@
 #define __NET_FRAG_H__
 
 struct netns_frags {
+	int			nqueues;
 };
 
 struct inet_frag_queue {
@@ -36,7 +37,6 @@ struct inet_frags {
 	struct hlist_head	hash[INETFRAGS_HASHSZ];
 	rwlock_t		lock;
 	u32			rnd;
-	int			nqueues;
 	int			qsize;
 	atomic_t		mem;
 	struct timer_list	secret_timer;
@@ -55,6 +55,8 @@ struct inet_frags {
 void inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
+void inet_frags_init_net(struct netns_frags *nf);
+
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);

commit ac18e7509e7df327e30d6e073a787d922eaf211d
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Tue Jan 22 06:02:14 2008 -0800

    [NETNS][FRAGS]: Make the inet_frag_queue lookup work in namespaces.
    
    Since fragment management code is consolidated, we cannot have the
    pointer from inet_frag_queue to struct net, since we must know what
    king of fragment this is.
    
    So, I introduce the netns_frags structure. This one is currently
    empty, but will be eventually filled with per-namespace
    attributes. Each inet_frag_queue is tagged with this one.
    
    The conntrack_reasm is not "netns-izated", so it has one static
    netns_frags instance to keep working in init namespace.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 954def408975..8ab6df64a12a 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -1,8 +1,12 @@
 #ifndef __NET_FRAG_H__
 #define __NET_FRAG_H__
 
+struct netns_frags {
+};
+
 struct inet_frag_queue {
 	struct hlist_node	list;
+	struct netns_frags	*net;
 	struct list_head	lru_list;   /* lru list member */
 	spinlock_t		lock;
 	atomic_t		refcnt;
@@ -55,8 +59,8 @@ void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
 int inet_frag_evictor(struct inet_frags *f);
-struct inet_frag_queue *inet_frag_find(struct inet_frags *f, void *key,
-		unsigned int hash);
+struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
+		struct inet_frags *f, void *key, unsigned int hash);
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {

commit 48d60056387c37a17a46feda48613587a90535e5
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Oct 17 19:47:56 2007 -0700

    [INET]: Remove no longer needed ->equal callback
    
    Since this callback is used to check for conflicts in
    hashtable when inserting a newly created frag queue, we can
    do the same by checking for matching the queue with the
    argument, used to create one.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 64299266a868..954def408975 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -43,8 +43,6 @@ struct inet_frags {
 						void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*skb_free)(struct sk_buff *);
-	int			(*equal)(struct inet_frag_queue *q1,
-					 struct inet_frag_queue *q2);
 	int			(*match)(struct inet_frag_queue *q,
 						void *arg);
 	void			(*frag_expire)(unsigned long data);

commit abd6523d15f40bfee14652619a31a7f65f77f581
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Oct 17 19:47:21 2007 -0700

    [INET]: Consolidate xxx_find() in fragment management
    
    Here we need another callback ->match to check whether the
    entry found in hash matches the key passed. The key used
    is the same as the creation argument for inet_frag_create.
    
    Yet again, this ->match is the same for netfilter and ipv6.
    Running a frew steps forward - this callback will later
    replace the ->equal one.
    
    Since the inet_frag_find() uses the already consolidated
    inet_frag_create() remove the xxx_frag_create from protocol
    codes.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e33072b9fd91..64299266a868 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -45,6 +45,8 @@ struct inet_frags {
 	void			(*skb_free)(struct sk_buff *);
 	int			(*equal)(struct inet_frag_queue *q1,
 					 struct inet_frag_queue *q2);
+	int			(*match)(struct inet_frag_queue *q,
+						void *arg);
 	void			(*frag_expire)(unsigned long data);
 };
 
@@ -55,8 +57,8 @@ void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
 int inet_frag_evictor(struct inet_frags *f);
-struct inet_frag_queue *inet_frag_create(struct inet_frags *f,
-		void *create_arg, unsigned int hash);
+struct inet_frag_queue *inet_frag_find(struct inet_frags *f, void *key,
+		unsigned int hash);
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {

commit c6fda282294da882f8d8cc4c513940277dd380f5
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Oct 17 19:46:47 2007 -0700

    [INET]: Consolidate xxx_frag_create()
    
    This one uses the xxx_frag_intern() and xxx_frag_alloc()
    routines, which are already consolidated, so remove them
    from protocol code (as promised).
    
    The ->constructor callback is used to init the rest of
    the frag queue and it is the same for netfilter and ipv6.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 412b8582a616..e33072b9fd91 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -39,6 +39,8 @@ struct inet_frags {
 	struct inet_frags_ctl	*ctl;
 
 	unsigned int		(*hashfn)(struct inet_frag_queue *);
+	void			(*constructor)(struct inet_frag_queue *q,
+						void *arg);
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*skb_free)(struct sk_buff *);
 	int			(*equal)(struct inet_frag_queue *q1,
@@ -53,9 +55,8 @@ void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
 int inet_frag_evictor(struct inet_frags *f);
-struct inet_frag_queue *inet_frag_intern(struct inet_frag_queue *q,
-		struct inet_frags *f, unsigned int hash);
-struct inet_frag_queue *inet_frag_alloc(struct inet_frags *f);
+struct inet_frag_queue *inet_frag_create(struct inet_frags *f,
+		void *create_arg, unsigned int hash);
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {

commit e521db9d790aaa60ae8920e21cb7faedc280fc36
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Oct 17 19:45:23 2007 -0700

    [INET]: Consolidate xxx_frag_alloc()
    
    Just perform the kzalloc() allocation and setup common
    fields in the inet_frag_queue(). Then return the result
    to the caller to initialize the rest.
    
    The inet_frag_alloc() may return NULL, so check the
    return value before doing the container_of(). This looks
    ugly, but the xxx_frag_alloc() will be removed soon.
    
    The xxx_expire() timer callbacks are patches,
    because the argument is now the inet_frag_queue, not
    the protocol specific queue.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 133e187fbc98..412b8582a616 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -43,6 +43,7 @@ struct inet_frags {
 	void			(*skb_free)(struct sk_buff *);
 	int			(*equal)(struct inet_frag_queue *q1,
 					 struct inet_frag_queue *q2);
+	void			(*frag_expire)(unsigned long data);
 };
 
 void inet_frags_init(struct inet_frags *);
@@ -54,6 +55,7 @@ void inet_frag_destroy(struct inet_frag_queue *q,
 int inet_frag_evictor(struct inet_frags *f);
 struct inet_frag_queue *inet_frag_intern(struct inet_frag_queue *q,
 		struct inet_frags *f, unsigned int hash);
+struct inet_frag_queue *inet_frag_alloc(struct inet_frags *f);
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {

commit 2588fe1d782f1686847493ad643157d5d10bf602
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Oct 17 19:44:34 2007 -0700

    [INET]: Consolidate xxx_frag_intern
    
    This routine checks for the existence of a given entry
    in the hash table and inserts the new one if needed.
    
    The ->equal callback is used to compare two frag_queue-s
    together, but this one is temporary and will be removed
    later. The netfilter code and the ipv6 one use the same
    routine to compare frags.
    
    The inet_frag_intern() always returns non-NULL pointer,
    so convert the inet_frag_queue into protocol specific
    one (with the container_of) without any checks.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 911c2cd02941..133e187fbc98 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -41,6 +41,8 @@ struct inet_frags {
 	unsigned int		(*hashfn)(struct inet_frag_queue *);
 	void			(*destructor)(struct inet_frag_queue *);
 	void			(*skb_free)(struct sk_buff *);
+	int			(*equal)(struct inet_frag_queue *q1,
+					 struct inet_frag_queue *q2);
 };
 
 void inet_frags_init(struct inet_frags *);
@@ -50,6 +52,8 @@ void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
 int inet_frag_evictor(struct inet_frags *f);
+struct inet_frag_queue *inet_frag_intern(struct inet_frag_queue *q,
+		struct inet_frags *f, unsigned int hash);
 
 static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
 {

commit 762cc40801ad757a34527d5e548816cf3b6fc606
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:41:56 2007 -0700

    [INET]: Consolidate the xxx_put
    
    These ones use the generic data types too, so move
    them in one place.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index cf583cf7e9ef..911c2cd02941 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -51,4 +51,10 @@ void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
 int inet_frag_evictor(struct inet_frags *f);
 
+static inline void inet_frag_put(struct inet_frag_queue *q, struct inet_frags *f)
+{
+	if (atomic_dec_and_test(&q->refcnt))
+		inet_frag_destroy(q, f, NULL);
+}
+
 #endif

commit 8e7999c44ee95e1e90ac91c83557a04e2948f160
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:40:06 2007 -0700

    [INET]: Consolidate the xxx_evictor
    
    The evictors collect some statistics for ipv4 and ipv6,
    so make it return the number of evicted queues and account
    them all at once in the caller.
    
    The XXX_ADD_STATS_BH() macros are just for this case,
    but maybe there are places in code, that can make use of
    them as well.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 2dd1cd4e7f44..cf583cf7e9ef 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -49,5 +49,6 @@ void inet_frags_fini(struct inet_frags *);
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
 void inet_frag_destroy(struct inet_frag_queue *q,
 				struct inet_frags *f, int *work);
+int inet_frag_evictor(struct inet_frags *f);
 
 #endif

commit 1e4b82873af0f21002e37a81ef063d2e5410deb3
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:39:14 2007 -0700

    [INET]: Consolidate the xxx_frag_destroy
    
    To make in possible we need to know the exact frag queue
    size for inet_frags->mem management and two callbacks:
    
     * to destoy the skb (optional, used in conntracks only)
     * to free the queue itself (mandatory, but later I plan to
       move the allocation and the destruction of frag_queues
       into the common place, so this callback will most likely
       be optional too).
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index e374412ff42b..2dd1cd4e7f44 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -33,16 +33,21 @@ struct inet_frags {
 	rwlock_t		lock;
 	u32			rnd;
 	int			nqueues;
+	int			qsize;
 	atomic_t		mem;
 	struct timer_list	secret_timer;
 	struct inet_frags_ctl	*ctl;
 
 	unsigned int		(*hashfn)(struct inet_frag_queue *);
+	void			(*destructor)(struct inet_frag_queue *);
+	void			(*skb_free)(struct sk_buff *);
 };
 
 void inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
 void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
+void inet_frag_destroy(struct inet_frag_queue *q,
+				struct inet_frags *f, int *work);
 
 #endif

commit 321a3a99e4717b960e21c62fc6a140d21453df7f
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:38:08 2007 -0700

    [INET]: Consolidate xxx_the secret_rebuild
    
    This code works with the generic data types as well, so
    move this into inet_fragment.c
    
    This move makes it possible to hide the secret_timer
    management and the secret_rebuild routine completely in
    the inet_fragment.c
    
    Introduce the ->hashfn() callback in inet_frags() to get
    the hashfun for a given inet_frag_queue() object.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 9902363f5bcc..e374412ff42b 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -36,6 +36,8 @@ struct inet_frags {
 	atomic_t		mem;
 	struct timer_list	secret_timer;
 	struct inet_frags_ctl	*ctl;
+
+	unsigned int		(*hashfn)(struct inet_frag_queue *);
 };
 
 void inet_frags_init(struct inet_frags *);

commit 277e650ddfc6944ef5f5466fd898b8da7f06cd82
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:37:18 2007 -0700

    [INET]: Consolidate the xxx_frag_kill
    
    Since now all the xxx_frag_kill functions now work
    with the generic inet_frag_queue data type, this can
    be moved into a common place.
    
    The xxx_unlink() code is moved as well.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index ada03ba3b341..9902363f5bcc 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -41,4 +41,6 @@ struct inet_frags {
 void inet_frags_init(struct inet_frags *);
 void inet_frags_fini(struct inet_frags *);
 
+void inet_frag_kill(struct inet_frag_queue *q, struct inet_frags *f);
+
 #endif

commit 04128f233f2b344f3438cde09723e9946463a573
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:33:45 2007 -0700

    [INET]: Collect common frag sysctl variables together
    
    Some sysctl variables are used to tune the frag queues
    management and it will be useful to work with them in
    a common way in the future, so move them into one
    structure, moreover they are the same for all the frag
    management codes.
    
    I don't place them in the existing inet_frags object,
    introduced in the previous patch for two reasons:
    
     1. to keep them in the __read_mostly section;
     2. not to export the whole inet_frags objects outside.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index d51f23873da9..ada03ba3b341 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -20,6 +20,13 @@ struct inet_frag_queue {
 
 #define INETFRAGS_HASHSZ		64
 
+struct inet_frags_ctl {
+	int high_thresh;
+	int low_thresh;
+	int timeout;
+	int secret_interval;
+};
+
 struct inet_frags {
 	struct list_head	lru_list;
 	struct hlist_head	hash[INETFRAGS_HASHSZ];
@@ -28,6 +35,7 @@ struct inet_frags {
 	int			nqueues;
 	atomic_t		mem;
 	struct timer_list	secret_timer;
+	struct inet_frags_ctl	*ctl;
 };
 
 void inet_frags_init(struct inet_frags *);

commit 7eb95156d9dce2f59794264db336ce007d71638b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:31:52 2007 -0700

    [INET]: Collect frag queues management objects together
    
    There are some objects that are common in all the places
    which are used to keep track of frag queues, they are:
    
     * hash table
     * LRU list
     * rw lock
     * rnd number for hash function
     * the number of queues
     * the amount of memory occupied by queues
     * secret timer
    
    Move all this stuff into one structure (struct inet_frags)
    to make it possible use them uniformly in the future. Like
    with the previous patch this mostly consists of hunks like
    
    -    write_lock(&ipfrag_lock);
    +    write_lock(&ip4_frags.lock);
    
    To address the issue with exporting the number of queues and
    the amount of memory occupied by queues outside the .c file
    they are declared in, I introduce a couple of helpers.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
index 74e9cb9b6943..d51f23873da9 100644
--- a/include/net/inet_frag.h
+++ b/include/net/inet_frag.h
@@ -18,4 +18,19 @@ struct inet_frag_queue {
 #define LAST_IN			1
 };
 
+#define INETFRAGS_HASHSZ		64
+
+struct inet_frags {
+	struct list_head	lru_list;
+	struct hlist_head	hash[INETFRAGS_HASHSZ];
+	rwlock_t		lock;
+	u32			rnd;
+	int			nqueues;
+	atomic_t		mem;
+	struct timer_list	secret_timer;
+};
+
+void inet_frags_init(struct inet_frags *);
+void inet_frags_fini(struct inet_frags *);
+
 #endif

commit 5ab11c98d3a950faf6922b6166e5f8fc874590e7
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Oct 15 02:24:19 2007 -0700

    [INET]: Move common fields from frag_queues in one place.
    
    Introduce the struct inet_frag_queue in include/net/inet_frag.h
    file and place there all the common fields from three structs:
    
     * struct ipq in ipv4/ip_fragment.c
     * struct nf_ct_frag6_queue in nf_conntrack_reasm.c
     * struct frag_queue in ipv6/reassembly.c
    
    After this, replace these fields on appropriate structures with
    this structure instance and fix the users to use correct names
    i.e. hunks like
    
    -    atomic_dec(&fq->refcnt);
    +    atomic_dec(&fq->q.refcnt);
    
    (these occupy most of the patch)
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_frag.h b/include/net/inet_frag.h
new file mode 100644
index 000000000000..74e9cb9b6943
--- /dev/null
+++ b/include/net/inet_frag.h
@@ -0,0 +1,21 @@
+#ifndef __NET_FRAG_H__
+#define __NET_FRAG_H__
+
+struct inet_frag_queue {
+	struct hlist_node	list;
+	struct list_head	lru_list;   /* lru list member */
+	spinlock_t		lock;
+	atomic_t		refcnt;
+	struct timer_list	timer;      /* when will this queue expire? */
+	struct sk_buff		*fragments; /* list of received fragments */
+	ktime_t			stamp;
+	int			len;        /* total length of orig datagram */
+	int			meat;
+	__u8			last_in;    /* first/last segment arrived? */
+
+#define COMPLETE		4
+#define FIRST_IN		2
+#define LAST_IN			1
+};
+
+#endif
