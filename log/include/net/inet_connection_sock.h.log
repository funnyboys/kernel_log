commit 6761893eeaa378321198f06194ef2e1e4e8a4ad4
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Thu Jun 4 18:55:45 2020 +0200

    inet_connection_sock: clear inet_num out of destroy helper
    
    Clearing the 'inet_num' field is necessary and safe if and
    only if the socket is not bound. The MPTCP protocol calls
    the destroy helper on bound sockets, as tcp_v{4,6}_syn_recv_sock
    completed successfully.
    
    Move the clearing of such field out of the common code, otherwise
    the MPTCP MP_JOIN error path will find the wrong 'inet_num' value
    on socket disposal, __inet_put_port() will acquire the wrong lock
    and bind_node removal could race with other modifiers possibly
    corrupting the bind hash table.
    
    Reported-and-tested-by: Christoph Paasch <cpaasch@apple.com>
    Fixes: 729cd6436f35 ("mptcp: cope better with MP_JOIN failure")
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 2f1f8c3efb26..e5b388f5fa20 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -292,7 +292,6 @@ static inline void inet_csk_prepare_for_destroy_sock(struct sock *sk)
 	/* The below has to be done to allow calling inet_csk_destroy_sock */
 	sock_set_flag(sk, SOCK_DEAD);
 	percpu_counter_inc(sk->sk_prot->orphan_count);
-	inet_sk(sk)->inet_num = 0;
 }
 
 void inet_csk_destroy_sock(struct sock *sk);

commit 2f8a397d0a54b59c05e481523ab2a88a63d82d18
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Fri May 15 19:22:16 2020 +0200

    inet_connection_sock: factor out destroy helper.
    
    Move the steps to prepare an inet_connection_sock for
    forced disposal inside a separate helper. No functional
    changes inteded, this will just simplify the next patch.
    
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Reviewed-by: Christoph Paasch <cpaasch@apple.com>
    Reviewed-by: Mat Martineau <mathew.j.martineau@linux.intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index a3f076befa4f..2f1f8c3efb26 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -287,6 +287,14 @@ static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
 void inet_csk_reqsk_queue_drop(struct sock *sk, struct request_sock *req);
 void inet_csk_reqsk_queue_drop_and_put(struct sock *sk, struct request_sock *req);
 
+static inline void inet_csk_prepare_for_destroy_sock(struct sock *sk)
+{
+	/* The below has to be done to allow calling inet_csk_destroy_sock */
+	sock_set_flag(sk, SOCK_DEAD);
+	percpu_counter_inc(sk->sk_prot->orphan_count);
+	inet_sk(sk)->inet_num = 0;
+}
+
 void inet_csk_destroy_sock(struct sock *sk);
 void inet_csk_prepare_forced_close(struct sock *sk);
 

commit 7b70973d7edb2f005511102d5a2e0116464a46a1
Author: Lorenz Bauer <lmb@cloudflare.com>
Date:   Mon Mar 9 11:12:32 2020 +0000

    bpf: sockmap: Only check ULP for TCP sockets
    
    The sock map code checks that a socket does not have an active upper
    layer protocol before inserting it into the map. This requires casting
    via inet_csk, which isn't valid for UDP sockets.
    
    Guard checks for ULP by checking inet_sk(sk)->is_icsk first.
    
    Signed-off-by: Lorenz Bauer <lmb@cloudflare.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Acked-by: John Fastabend <john.fastabend@gmail.com>
    Link: https://lore.kernel.org/bpf/20200309111243.6982-2-lmb@cloudflare.com

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 895546058a20..a3f076befa4f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -335,4 +335,10 @@ static inline void inet_csk_inc_pingpong_cnt(struct sock *sk)
 	if (icsk->icsk_ack.pingpong < U8_MAX)
 		icsk->icsk_ack.pingpong++;
 }
+
+static inline bool inet_csk_has_ulp(struct sock *sk)
+{
+	return inet_sk(sk)->is_icsk && !!inet_csk(sk)->icsk_ulp_ops;
+}
+
 #endif /* _INET_CONNECTION_SOCK_H */

commit 15a7dea750e0162f273c6e61a94f96944b75b31e
Author: Jakub Kicinski <jakub.kicinski@netronome.com>
Date:   Fri Aug 30 12:25:47 2019 +0200

    net/tls: use RCU protection on icsk->icsk_ulp_data
    
    We need to make sure context does not get freed while diag
    code is interrogating it. Free struct tls_context with
    kfree_rcu().
    
    We add the __rcu annotation directly in icsk, and cast it
    away in the datapath accessor. Presumably all ULPs will
    do a similar thing.
    
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index c57d53e7e02c..895546058a20 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -97,7 +97,7 @@ struct inet_connection_sock {
 	const struct tcp_congestion_ops *icsk_ca_ops;
 	const struct inet_connection_sock_af_ops *icsk_af_ops;
 	const struct tcp_ulp_ops  *icsk_ulp_ops;
-	void			  *icsk_ulp_data;
+	void __rcu		  *icsk_ulp_data;
 	void (*icsk_clean_acked)(struct sock *sk, u32 acked_seq);
 	struct hlist_node         icsk_listen_portaddr_node;
 	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index ff40e1d08157..c57d53e7e02c 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * NET		Generic infrastructure for INET connection oriented protocols.
  *
@@ -6,11 +7,6 @@
  * Authors:	Many people, see the TCP sources
  *
  * 		From code originally in TCP
- *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
  */
 #ifndef _INET_CONNECTION_SOCK_H
 #define _INET_CONNECTION_SOCK_H

commit 4a41f453bedfd5e9cd040bad509d9da49feb3e2c
Author: Wei Wang <weiwan@google.com>
Date:   Fri Jan 25 10:53:20 2019 -0800

    tcp: change pingpong threshold to 3
    
    In order to be more confident about an on-going interactive session, we
    increment pingpong count by 1 for every interactive transaction and we
    adjust TCP_PINGPONG_THRESH to 3.
    This means, we only consider a session in pingpong mode after we see 3
    interactive transactions, and start to activate delayed acks in quick
    ack mode.
    And in order to not over-count the credits, we only increase pingpong
    count for the first packet sent in response for the previous received
    packet.
    This is mainly to prevent delaying the ack immediately after some
    handshake protocol but no real interactive traffic pattern afterwards.
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 179609d1d1ea..ff40e1d08157 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -315,7 +315,7 @@ int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
 
 struct dst_entry *inet_csk_update_pmtu(struct sock *sk, u32 mtu);
 
-#define TCP_PINGPONG_THRESH	1
+#define TCP_PINGPONG_THRESH	3
 
 static inline void inet_csk_enter_pingpong_mode(struct sock *sk)
 {
@@ -331,4 +331,12 @@ static inline bool inet_csk_in_pingpong_mode(struct sock *sk)
 {
 	return inet_csk(sk)->icsk_ack.pingpong >= TCP_PINGPONG_THRESH;
 }
+
+static inline void inet_csk_inc_pingpong_cnt(struct sock *sk)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	if (icsk->icsk_ack.pingpong < U8_MAX)
+		icsk->icsk_ack.pingpong++;
+}
 #endif /* _INET_CONNECTION_SOCK_H */

commit 31954cd8bb667030b1c0d3d77f28fe71f06999f9
Author: Wei Wang <weiwan@google.com>
Date:   Fri Jan 25 10:53:19 2019 -0800

    tcp: Refactor pingpong code
    
    Instead of using pingpong as a single bit information, we refactor the
    code to treat it as a counter. When interactive session is detected,
    we set pingpong count to TCP_PINGPONG_THRESH. And when pingpong count
    is >= TCP_PINGPONG_THRESH, we consider the session in pingpong mode.
    
    This patch is a pure refactor and sets foundation for the next patch.
    This patch itself does not change any pingpong logic.
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index fe0d9b44d6fc..179609d1d1ea 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -314,4 +314,21 @@ int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
 			       char __user *optval, unsigned int optlen);
 
 struct dst_entry *inet_csk_update_pmtu(struct sock *sk, u32 mtu);
+
+#define TCP_PINGPONG_THRESH	1
+
+static inline void inet_csk_enter_pingpong_mode(struct sock *sk)
+{
+	inet_csk(sk)->icsk_ack.pingpong = TCP_PINGPONG_THRESH;
+}
+
+static inline void inet_csk_exit_pingpong_mode(struct sock *sk)
+{
+	inet_csk(sk)->icsk_ack.pingpong = 0;
+}
+
+static inline bool inet_csk_in_pingpong_mode(struct sock *sk)
+{
+	return inet_csk(sk)->icsk_ack.pingpong >= TCP_PINGPONG_THRESH;
+}
 #endif /* _INET_CONNECTION_SOCK_H */

commit 78dc70ebaa38aa303274e333be6c98eef87619e2
Author: Priyaranjan Jha <priyarjha@google.com>
Date:   Wed Jan 23 12:04:54 2019 -0800

    tcp_bbr: adapt cwnd based on ack aggregation estimation
    
    Aggregation effects are extremely common with wifi, cellular, and cable
    modem link technologies, ACK decimation in middleboxes, and LRO and GRO
    in receiving hosts. The aggregation can happen in either direction,
    data or ACKs, but in either case the aggregation effect is visible
    to the sender in the ACK stream.
    
    Previously BBR's sending was often limited by cwnd under severe ACK
    aggregation/decimation because BBR sized the cwnd at 2*BDP. If packets
    were acked in bursts after long delays (e.g. one ACK acking 5*BDP after
    5*RTT), BBR's sending was halted after sending 2*BDP over 2*RTT, leaving
    the bottleneck idle for potentially long periods. Note that loss-based
    congestion control does not have this issue because when facing
    aggregation it continues increasing cwnd after bursts of ACKs, growing
    cwnd until the buffer is full.
    
    To achieve good throughput in the presence of aggregation effects, this
    algorithm allows the BBR sender to put extra data in flight to keep the
    bottleneck utilized during silences in the ACK stream that it has evidence
    to suggest were caused by aggregation.
    
    A summary of the algorithm: when a burst of packets are acked by a
    stretched ACK or a burst of ACKs or both, BBR first estimates the expected
    amount of data that should have been acked, based on its estimated
    bandwidth. Then the surplus ("extra_acked") is recorded in a windowed-max
    filter to estimate the recent level of observed ACK aggregation. Then cwnd
    is increased by the ACK aggregation estimate. The larger cwnd avoids BBR
    being cwnd-limited in the face of ACK silences that recent history suggests
    were caused by aggregation. As a sanity check, the ACK aggregation degree
    is upper-bounded by the cwnd (at the time of measurement) and a global max
    of BW * 100ms. The algorithm is further described by the following
    presentation:
    https://datatracker.ietf.org/meeting/101/materials/slides-101-iccrg-an-update-on-bbr-work-at-google-00
    
    In our internal testing, we observed a significant increase in BBR
    throughput (measured using netperf), in a basic wifi setup.
    - Host1 (sender on ethernet) -> AP -> Host2 (receiver on wifi)
    - 2.4 GHz -> BBR before: ~73 Mbps; BBR after: ~102 Mbps; CUBIC: ~100 Mbps
    - 5.0 GHz -> BBR before: ~362 Mbps; BBR after: ~593 Mbps; CUBIC: ~601 Mbps
    
    Also, this code is running globally on YouTube TCP connections and produced
    significant bandwidth increases for YouTube traffic.
    
    This is based on Ian Swett's max_ack_height_ algorithm from the
    QUIC BBR implementation.
    
    Signed-off-by: Priyaranjan Jha <priyarjha@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 371b3b45fd5c..fe0d9b44d6fc 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -139,8 +139,8 @@ struct inet_connection_sock {
 	} icsk_mtup;
 	u32			  icsk_user_timeout;
 
-	u64			  icsk_ca_priv[88 / sizeof(u64)];
-#define ICSK_CA_PRIV_SIZE      (11 * sizeof(u64))
+	u64			  icsk_ca_priv[104 / sizeof(u64)];
+#define ICSK_CA_PRIV_SIZE      (13 * sizeof(u64))
 };
 
 #define ICSK_TIME_RETRANS	1	/* Retransmit timer */

commit 96d18d8254dc5a3f0067a629866af4165b3afe32
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Wed Aug 1 14:57:59 2018 -0700

    inet/connection_sock: prefer _THIS_IP_ to current_text_addr
    
    As part of the effort to reduce the code duplication between _THIS_IP_
    and current_text_addr(), let's consolidate callers of
    current_text_addr() to use _THIS_IP_.
    
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index fa43b82607d9..371b3b45fd5c 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -19,6 +19,7 @@
 #include <linux/string.h>
 #include <linux/timer.h>
 #include <linux/poll.h>
+#include <linux/kernel.h>
 
 #include <net/inet_sock.h>
 #include <net/request_sock.h>
@@ -225,7 +226,7 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 
 	if (when > max_when) {
 		pr_debug("reset_xmit_timer: sk=%p %d when=0x%lx, caller=%p\n",
-			 sk, what, when, current_text_addr());
+			 sk, what, when, (void *)_THIS_IP_);
 		when = max_when;
 	}
 

commit 466466dc6c28ca9dc401f10e235b9cde9a7c9162
Author: Yuchung Cheng <ycheng@google.com>
Date:   Thu Aug 9 09:38:09 2018 -0700

    tcp: mandate a one-time immediate ACK
    
    Add a new flag to indicate a one-time immediate ACK. This flag is
    occasionaly set under specific TCP protocol states in addition to
    the more common quickack mechanism for interactive application.
    
    In several cases in the TCP code we want to force an immediate ACK
    but do not want to call tcp_enter_quickack_mode() because we do
    not want to forget the icsk_ack.pingpong or icsk_ack.ato state.
    
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Wei Wang <weiwan@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 0a6c9e0f2b5a..fa43b82607d9 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -167,7 +167,8 @@ enum inet_csk_ack_state_t {
 	ICSK_ACK_SCHED	= 1,
 	ICSK_ACK_TIMER  = 2,
 	ICSK_ACK_PUSHED = 4,
-	ICSK_ACK_PUSHED2 = 8
+	ICSK_ACK_PUSHED2 = 8,
+	ICSK_ACK_NOW = 16	/* Send the next ACK immediately (once) */
 };
 
 void inet_csk_init_xmit_timers(struct sock *sk,

commit 03bdfc001c951cb04ad3d28aecee4ec0e18e9664
Author: Joe Perches <joe@perches.com>
Date:   Wed May 9 23:24:07 2018 -0700

    net: ipv4: remove define INET_CSK_DEBUG and unnecessary EXPORT_SYMBOL
    
    INET_CSK_DEBUG is always set and only is used for 2 pr_debug calls.
    
    EXPORT_SYMBOL(inet_csk_timer_bug_msg) is only used by these 2
    pr_debug calls and is also unnecessary as the exported string can
    be used directly by these calls.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 2ab6667275df..0a6c9e0f2b5a 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -23,8 +23,6 @@
 #include <net/inet_sock.h>
 #include <net/request_sock.h>
 
-#define INET_CSK_DEBUG 1
-
 /* Cancel timers, when they are not required. */
 #undef INET_CSK_CLEAR_TIMERS
 
@@ -196,10 +194,6 @@ static inline void inet_csk_delack_init(struct sock *sk)
 void inet_csk_delete_keepalive_timer(struct sock *sk);
 void inet_csk_reset_keepalive_timer(struct sock *sk, unsigned long timeout);
 
-#ifdef INET_CSK_DEBUG
-extern const char inet_csk_timer_bug_msg[];
-#endif
-
 static inline void inet_csk_clear_xmit_timer(struct sock *sk, const int what)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
@@ -214,12 +208,9 @@ static inline void inet_csk_clear_xmit_timer(struct sock *sk, const int what)
 #ifdef INET_CSK_CLEAR_TIMERS
 		sk_stop_timer(sk, &icsk->icsk_delack_timer);
 #endif
+	} else {
+		pr_debug("inet_csk BUG: unknown timer value\n");
 	}
-#ifdef INET_CSK_DEBUG
-	else {
-		pr_debug("%s", inet_csk_timer_bug_msg);
-	}
-#endif
 }
 
 /*
@@ -232,10 +223,8 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
 	if (when > max_when) {
-#ifdef INET_CSK_DEBUG
 		pr_debug("reset_xmit_timer: sk=%p %d when=0x%lx, caller=%p\n",
 			 sk, what, when, current_text_addr());
-#endif
 		when = max_when;
 	}
 
@@ -249,12 +238,9 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 		icsk->icsk_ack.pending |= ICSK_ACK_TIMER;
 		icsk->icsk_ack.timeout = jiffies + when;
 		sk_reset_timer(sk, &icsk->icsk_delack_timer, icsk->icsk_ack.timeout);
+	} else {
+		pr_debug("inet_csk BUG: unknown timer value\n");
 	}
-#ifdef INET_CSK_DEBUG
-	else {
-		pr_debug("%s", inet_csk_timer_bug_msg);
-	}
-#endif
 }
 
 static inline unsigned long

commit 6dac152355d9308c9e187bf1d38d98afefcaa315
Author: Ilya Lesokhin <ilyal@mellanox.com>
Date:   Mon Apr 30 10:16:10 2018 +0300

    tcp: Add clean acked data hook
    
    Called when a TCP segment is acknowledged.
    Could be used by application protocols who hold additional
    metadata associated with the stream data.
    
    This is required by TLS device offload to release
    metadata associated with acknowledged TLS records.
    
    Signed-off-by: Ilya Lesokhin <ilyal@mellanox.com>
    Signed-off-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Aviad Yehezkel <aviadye@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index b68fea022a82..2ab6667275df 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -77,6 +77,7 @@ struct inet_connection_sock_af_ops {
  * @icsk_af_ops		   Operations which are AF_INET{4,6} specific
  * @icsk_ulp_ops	   Pluggable ULP control hook
  * @icsk_ulp_data	   ULP private data
+ * @icsk_clean_acked	   Clean acked data hook
  * @icsk_listen_portaddr_node	hash to the portaddr listener hashtable
  * @icsk_ca_state:	   Congestion control state
  * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
@@ -102,6 +103,7 @@ struct inet_connection_sock {
 	const struct inet_connection_sock_af_ops *icsk_af_ops;
 	const struct tcp_ulp_ops  *icsk_ulp_ops;
 	void			  *icsk_ulp_data;
+	void (*icsk_clean_acked)(struct sock *sk, u32 acked_seq);
 	struct hlist_node         icsk_listen_portaddr_node;
 	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
 	__u8			  icsk_ca_state:6,

commit 82695b30ffeeab665f41416c6f5015dea3147bd5
Author: Stephen Hemminger <stephen@networkplumber.org>
Date:   Tue Feb 27 15:48:21 2018 -0800

    inet: whitespace cleanup
    
    Ran simple script to find/remove trailing whitespace and blank lines
    at EOF because that kind of stuff git whines about and editors leave
    behind.
    
    Signed-off-by: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index c1a93ce35e62..b68fea022a82 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -49,9 +49,9 @@ struct inet_connection_sock_af_ops {
 	u16	    net_header_len;
 	u16	    net_frag_header_len;
 	u16	    sockaddr_len;
-	int	    (*setsockopt)(struct sock *sk, int level, int optname, 
+	int	    (*setsockopt)(struct sock *sk, int level, int optname,
 				  char __user *optval, unsigned int optlen);
-	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
+	int	    (*getsockopt)(struct sock *sk, int level, int optname,
 				  char __user *optval, int __user *optlen);
 #ifdef CONFIG_COMPAT
 	int	    (*compat_setsockopt)(struct sock *sk,
@@ -67,7 +67,7 @@ struct inet_connection_sock_af_ops {
 
 /** inet_connection_sock - INET connection oriented sock
  *
- * @icsk_accept_queue:	   FIFO of established children 
+ * @icsk_accept_queue:	   FIFO of established children
  * @icsk_bind_hash:	   Bind node
  * @icsk_timeout:	   Timeout
  * @icsk_retransmit_timer: Resend (no ack)
@@ -122,7 +122,7 @@ struct inet_connection_sock {
 		unsigned long	  timeout;	 /* Currently scheduled timeout		   */
 		__u32		  lrcvtime;	 /* timestamp of last received data packet */
 		__u16		  last_seg_size; /* Size of last incoming segment	   */
-		__u16		  rcv_mss;	 /* MSS used for delayed ACK decisions	   */ 
+		__u16		  rcv_mss;	 /* MSS used for delayed ACK decisions	   */
 	} icsk_ack;
 	struct {
 		int		  enabled;
@@ -201,7 +201,7 @@ extern const char inet_csk_timer_bug_msg[];
 static inline void inet_csk_clear_xmit_timer(struct sock *sk, const int what)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
-	
+
 	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0) {
 		icsk->icsk_pending = 0;
 #ifdef INET_CSK_CLEAR_TIMERS

commit a9a08845e9acbd224e4ee466f5c1275ed50054e8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Feb 11 14:34:03 2018 -0800

    vfs: do bulk POLL* -> EPOLL* replacement
    
    This is the mindless scripted replacement of kernel use of POLL*
    variables as described by Al, done by this script:
    
        for V in IN OUT PRI ERR RDNORM RDBAND WRNORM WRBAND HUP RDHUP NVAL MSG; do
            L=`git grep -l -w POLL$V | grep -v '^t' | grep -v /um/ | grep -v '^sa' | grep -v '/poll.h$'|grep -v '^D'`
            for f in $L; do sed -i "-es/^\([^\"]*\)\(\<POLL$V\>\)/\\1E\\2/" $f; done
        done
    
    with de-mangling cleanups yet to come.
    
    NOTE! On almost all architectures, the EPOLL* constants have the same
    values as the POLL* constants do.  But they keyword here is "almost".
    For various bad reasons they aren't the same, and epoll() doesn't
    actually work quite correctly in some cases due to this on Sparc et al.
    
    The next patch from Al will sort out the final differences, and we
    should be all done.
    
    Scripted-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 6692d67e9245..c1a93ce35e62 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -310,7 +310,7 @@ void inet_csk_prepare_forced_close(struct sock *sk);
 static inline __poll_t inet_csk_listen_poll(const struct sock *sk)
 {
 	return !reqsk_queue_empty(&inet_csk(sk)->icsk_accept_queue) ?
-			(POLLIN | POLLRDNORM) : 0;
+			(EPOLLIN | EPOLLRDNORM) : 0;
 }
 
 int inet_csk_listen_start(struct sock *sk, int backlog);

commit b2fe5fa68642860e7de76167c3111623aa0d5de1
Merge: a103950e0dd2 a54667f6728c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 31 14:31:10 2018 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) Significantly shrink the core networking routing structures. Result
        of http://vger.kernel.org/~davem/seoul2017_netdev_keynote.pdf
    
     2) Add netdevsim driver for testing various offloads, from Jakub
        Kicinski.
    
     3) Support cross-chip FDB operations in DSA, from Vivien Didelot.
    
     4) Add a 2nd listener hash table for TCP, similar to what was done for
        UDP. From Martin KaFai Lau.
    
     5) Add eBPF based queue selection to tun, from Jason Wang.
    
     6) Lockless qdisc support, from John Fastabend.
    
     7) SCTP stream interleave support, from Xin Long.
    
     8) Smoother TCP receive autotuning, from Eric Dumazet.
    
     9) Lots of erspan tunneling enhancements, from William Tu.
    
    10) Add true function call support to BPF, from Alexei Starovoitov.
    
    11) Add explicit support for GRO HW offloading, from Michael Chan.
    
    12) Support extack generation in more netlink subsystems. From Alexander
        Aring, Quentin Monnet, and Jakub Kicinski.
    
    13) Add 1000BaseX, flow control, and EEE support to mvneta driver. From
        Russell King.
    
    14) Add flow table abstraction to netfilter, from Pablo Neira Ayuso.
    
    15) Many improvements and simplifications to the NFP driver bpf JIT,
        from Jakub Kicinski.
    
    16) Support for ipv6 non-equal cost multipath routing, from Ido
        Schimmel.
    
    17) Add resource abstration to devlink, from Arkadi Sharshevsky.
    
    18) Packet scheduler classifier shared filter block support, from Jiri
        Pirko.
    
    19) Avoid locking in act_csum, from Davide Caratti.
    
    20) devinet_ioctl() simplifications from Al viro.
    
    21) More TCP bpf improvements from Lawrence Brakmo.
    
    22) Add support for onlink ipv6 route flag, similar to ipv4, from David
        Ahern.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1925 commits)
      tls: Add support for encryption using async offload accelerator
      ip6mr: fix stale iterator
      net/sched: kconfig: Remove blank help texts
      openvswitch: meter: Use 64-bit arithmetic instead of 32-bit
      tcp_nv: fix potential integer overflow in tcpnv_acked
      r8169: fix RTL8168EP take too long to complete driver initialization.
      qmi_wwan: Add support for Quectel EP06
      rtnetlink: enable IFLA_IF_NETNSID for RTM_NEWLINK
      ipmr: Fix ptrdiff_t print formatting
      ibmvnic: Wait for device response when changing MAC
      qlcnic: fix deadlock bug
      tcp: release sk_frag.page in tcp_disconnect
      ipv4: Get the address of interface correctly.
      net_sched: gen_estimator: fix lockdep splat
      net: macb: Handle HRESP error
      net/mlx5e: IPoIB, Fix copy-paste bug in flow steering refactoring
      ipv6: addrconf: break critical section in addrconf_verify_rtnl()
      ipv6: change route cache aging logic
      i40e/i40evf: Update DESC_NEEDED value to reflect larger value
      bnxt_en: cleanup DIM work on device shutdown
      ...

commit 61b7c691c7317529375f90f0a81a331990b1ec1b
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Fri Dec 1 12:52:31 2017 -0800

    inet: Add a 2nd listener hashtable (port+addr)
    
    The current listener hashtable is hashed by port only.
    When a process is listening at many IP addresses with the same port (e.g.
    [IP1]:443, [IP2]:443... [IPN]:443), the inet[6]_lookup_listener()
    performance is degraded to a link list.  It is prone to syn attack.
    
    UDP had a similar issue and a second hashtable was added to resolve it.
    
    This patch adds a second hashtable for the listener's sockets.
    The second hashtable is hashed by port and address.
    
    It cannot reuse the existing skc_portaddr_node which is shared
    with skc_bind_node.  TCP listener needs to use skc_bind_node.
    Instead, this patch adds a hlist_node 'icsk_listen_portaddr_node' to
    the inet_connection_sock which the listener (like TCP) also belongs to.
    
    The new portaddr hashtable may need two lookup (First by IP:PORT.
    Second by INADDR_ANY:PORT if the IP:PORT is a not found).   Hence,
    it implements a similar cut off as UDP such that it will only consult the
    new portaddr hashtable if the current port-only hashtable has >10
    sk in the link-list.
    
    lhash2 and lhash2_mask are added to 'struct inet_hashinfo'.  I take
    this chance to plug a 4 bytes hole.  It is done by first moving
    the existing bind_bucket_cachep up and then add the new
    (int lhash2_mask, *lhash2) after the existing bhash_size.
    
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 0358745ea059..8e1bf9ae4a5e 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -77,6 +77,7 @@ struct inet_connection_sock_af_ops {
  * @icsk_af_ops		   Operations which are AF_INET{4,6} specific
  * @icsk_ulp_ops	   Pluggable ULP control hook
  * @icsk_ulp_data	   ULP private data
+ * @icsk_listen_portaddr_node	hash to the portaddr listener hashtable
  * @icsk_ca_state:	   Congestion control state
  * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
  * @icsk_pending:	   Scheduled timer event
@@ -101,6 +102,7 @@ struct inet_connection_sock {
 	const struct inet_connection_sock_af_ops *icsk_af_ops;
 	const struct tcp_ulp_ops  *icsk_ulp_ops;
 	void			  *icsk_ulp_data;
+	struct hlist_node         icsk_listen_portaddr_node;
 	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
 	__u8			  icsk_ca_state:6,
 				  icsk_ca_setsockopt:1,

commit ade994f4f6c8c3ef4c3bfc2d02166262fb9d089c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 3 00:01:49 2017 -0400

    net: annotate ->poll() instances
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 0358745ea059..ec72cdb5bc39 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -305,7 +305,7 @@ void inet_csk_prepare_forced_close(struct sock *sk);
 /*
  * LISTEN is a special case for poll..
  */
-static inline unsigned int inet_csk_listen_poll(const struct sock *sk)
+static inline __poll_t inet_csk_listen_poll(const struct sock *sk)
 {
 	return !reqsk_queue_empty(&inet_csk(sk)->icsk_accept_queue) ?
 			(POLLIN | POLLRDNORM) : 0;

commit 59f379f9046a9e0532ffd19b44e3c32fe79ec51b
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Oct 16 17:29:19 2017 -0700

    inet/connection_sock: Convert timers to use timer_setup()
    
    In preparation for unconditionally passing the struct timer_list pointer to
    all timer callbacks, switch to using the new timer_setup() and from_timer()
    to pass the timer pointer explicitly.
    
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: netdev@vger.kernel.org
    Cc: dccp@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 13e4c89a8231..0358745ea059 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -169,9 +169,9 @@ enum inet_csk_ack_state_t {
 };
 
 void inet_csk_init_xmit_timers(struct sock *sk,
-			       void (*retransmit_handler)(unsigned long),
-			       void (*delack_handler)(unsigned long),
-			       void (*keepalive_handler)(unsigned long));
+			       void (*retransmit_handler)(struct timer_list *),
+			       void (*delack_handler)(struct timer_list *),
+			       void (*keepalive_handler)(struct timer_list *));
 void inet_csk_clear_xmit_timers(struct sock *sk);
 
 static inline void inet_csk_schedule_ack(struct sock *sk)

commit 734942cc4ea6478eed125af258da1bdbb4afe578
Author: Dave Watson <davejwatson@fb.com>
Date:   Wed Jun 14 11:37:14 2017 -0700

    tcp: ULP infrastructure
    
    Add the infrustructure for attaching Upper Layer Protocols (ULPs) over TCP
    sockets. Based on a similar infrastructure in tcp_cong.  The idea is that any
    ULP can add its own logic by changing the TCP proto_ops structure to its own
    methods.
    
    Example usage:
    
    setsockopt(sock, SOL_TCP, TCP_ULP, "tls", sizeof("tls"));
    
    modules will call:
    tcp_register_ulp(&tcp_tls_ulp_ops);
    
    to register/unregister their ulp, with an init function and name.
    
    A list of registered ulps will be returned by tcp_get_available_ulp, which is
    hooked up to /proc.  Example:
    
    $ cat /proc/sys/net/ipv4/tcp_available_ulp
    tls
    
    There is currently no functionality to remove or chain ULPs, but
    it should be possible to add these in the future if needed.
    
    Signed-off-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Dave Watson <davejwatson@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index c7a577976bec..13e4c89a8231 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -75,6 +75,8 @@ struct inet_connection_sock_af_ops {
  * @icsk_pmtu_cookie	   Last pmtu seen by socket
  * @icsk_ca_ops		   Pluggable congestion control hook
  * @icsk_af_ops		   Operations which are AF_INET{4,6} specific
+ * @icsk_ulp_ops	   Pluggable ULP control hook
+ * @icsk_ulp_data	   ULP private data
  * @icsk_ca_state:	   Congestion control state
  * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
  * @icsk_pending:	   Scheduled timer event
@@ -97,6 +99,8 @@ struct inet_connection_sock {
 	__u32			  icsk_pmtu_cookie;
 	const struct tcp_congestion_ops *icsk_ca_ops;
 	const struct inet_connection_sock_af_ops *icsk_af_ops;
+	const struct tcp_ulp_ops  *icsk_ulp_ops;
+	void			  *icsk_ulp_data;
 	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
 	__u8			  icsk_ca_state:6,
 				  icsk_ca_setsockopt:1,

commit cdfbabfb2f0ce983fdaa42f20e5f7842178fc01e
Author: David Howells <dhowells@redhat.com>
Date:   Thu Mar 9 08:09:05 2017 +0000

    net: Work around lockdep limitation in sockets that use sockets
    
    Lockdep issues a circular dependency warning when AFS issues an operation
    through AF_RXRPC from a context in which the VFS/VM holds the mmap_sem.
    
    The theory lockdep comes up with is as follows:
    
     (1) If the pagefault handler decides it needs to read pages from AFS, it
         calls AFS with mmap_sem held and AFS begins an AF_RXRPC call, but
         creating a call requires the socket lock:
    
            mmap_sem must be taken before sk_lock-AF_RXRPC
    
     (2) afs_open_socket() opens an AF_RXRPC socket and binds it.  rxrpc_bind()
         binds the underlying UDP socket whilst holding its socket lock.
         inet_bind() takes its own socket lock:
    
            sk_lock-AF_RXRPC must be taken before sk_lock-AF_INET
    
     (3) Reading from a TCP socket into a userspace buffer might cause a fault
         and thus cause the kernel to take the mmap_sem, but the TCP socket is
         locked whilst doing this:
    
            sk_lock-AF_INET must be taken before mmap_sem
    
    However, lockdep's theory is wrong in this instance because it deals only
    with lock classes and not individual locks.  The AF_INET lock in (2) isn't
    really equivalent to the AF_INET lock in (3) as the former deals with a
    socket entirely internal to the kernel that never sees userspace.  This is
    a limitation in the design of lockdep.
    
    Fix the general case by:
    
     (1) Double up all the locking keys used in sockets so that one set are
         used if the socket is created by userspace and the other set is used
         if the socket is created by the kernel.
    
     (2) Store the kern parameter passed to sk_alloc() in a variable in the
         sock struct (sk_kern_sock).  This informs sock_lock_init(),
         sock_init_data() and sk_clone_lock() as to the lock keys to be used.
    
         Note that the child created by sk_clone_lock() inherits the parent's
         kern setting.
    
     (3) Add a 'kern' parameter to ->accept() that is analogous to the one
         passed in to ->create() that distinguishes whether kernel_accept() or
         sys_accept4() was the caller and can be passed to sk_alloc().
    
         Note that a lot of accept functions merely dequeue an already
         allocated socket.  I haven't touched these as the new socket already
         exists before we get the parameter.
    
         Note also that there are a couple of places where I've made the accepted
         socket unconditionally kernel-based:
    
            irda_accept()
            rds_rcp_accept_one()
            tcp_accept_from_sock()
    
         because they follow a sock_create_kern() and accept off of that.
    
    Whilst creating this, I noticed that lustre and ocfs don't create sockets
    through sock_create_kern() and thus they aren't marked as for-kernel,
    though they appear to be internal.  I wonder if these should do that so
    that they use the new set of lock keys.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 826f198374f8..c7a577976bec 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -258,7 +258,7 @@ inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
         return (unsigned long)min_t(u64, when, max_when);
 }
 
-struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
+struct sock *inet_csk_accept(struct sock *sk, int flags, int *err, bool kern);
 
 int inet_csk_get_port(struct sock *sk, unsigned short snum);
 

commit aa078842b702b4a45111f028a604a6c8f69cb27d
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue Jan 17 07:51:02 2017 -0800

    inet: drop ->bind_conflict
    
    The only difference between inet6_csk_bind_conflict and inet_csk_bind_conflict
    is how they check the rcv_saddr, so delete this call back and simply
    change inet_csk_bind_conflict to call inet_rcv_saddr_equal.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 84b2edde09b1..826f198374f8 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -62,9 +62,6 @@ struct inet_connection_sock_af_ops {
 				char __user *optval, int __user *optlen);
 #endif
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
-	int	    (*bind_conflict)(const struct sock *sk,
-				     const struct inet_bind_bucket *tb,
-				     bool relax, bool soreuseport_ok);
 	void	    (*mtu_reduced)(struct sock *sk);
 };
 
@@ -263,9 +260,6 @@ inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
 
 struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
-int inet_csk_bind_conflict(const struct sock *sk,
-			   const struct inet_bind_bucket *tb, bool relax,
-			   bool soreuseport_ok);
 int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 struct dst_entry *inet_csk_route_req(const struct sock *sk, struct flowi4 *fl4,

commit 57dde7f70de34d4251f291c9eac7ad920aaf56b2
Author: Yuchung Cheng <ycheng@google.com>
Date:   Thu Jan 12 22:11:33 2017 -0800

    tcp: add reordering timer in RACK loss detection
    
    This patch makes RACK install a reordering timer when it suspects
    some packets might be lost, but wants to delay the decision
    a little bit to accomodate reordering.
    
    It does not create a new timer but instead repurposes the existing
    RTO timer, because both are meant to retransmit packets.
    Specifically it arms a timer ICSK_TIME_REO_TIMEOUT when
    the RACK timing check fails. The wait time is set to
    
      RACK.RTT + RACK.reo_wnd - (NOW - Packet.xmit_time) + fudge
    
    This translates to expecting a packet (Packet) should take
    (RACK.RTT + RACK.reo_wnd + fudge) to deliver after it was sent.
    
    When there are multiple packets that need a timer, we use one timer
    with the maximum timeout. Therefore the timer conservatively uses
    the maximum window to expire N packets by one timeout, instead of
    N timeouts to expire N packets sent at different times.
    
    The fudge factor is 2 jiffies to ensure when the timer fires, all
    the suspected packets would exceed the deadline and be marked lost
    by tcp_rack_detect_loss(). It has to be at least 1 jiffy because the
    clock may tick between calling icsk_reset_xmit_timer(timeout) and
    actually hang the timer. The next jiffy is to lower-bound the timeout
    to 2 jiffies when reo_wnd is < 1ms.
    
    When the reordering timer fires (tcp_rack_reo_timeout): If we aren't
    in Recovery we'll enter fast recovery and force fast retransmit.
    This is very similar to the early retransmit (RFC5827) except RACK
    is not constrained to only enter recovery for small outstanding
    flights.
    
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 85ee3879499e..84b2edde09b1 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -144,6 +144,7 @@ struct inet_connection_sock {
 #define ICSK_TIME_PROBE0	3	/* Zero window probe timer */
 #define ICSK_TIME_EARLY_RETRANS 4	/* Early retransmit timer */
 #define ICSK_TIME_LOSS_PROBE	5	/* Tail loss probe timer */
+#define ICSK_TIME_REO_TIMEOUT	6	/* Reordering timer */
 
 static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
 {
@@ -234,7 +235,8 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 	}
 
 	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0 ||
-	    what == ICSK_TIME_EARLY_RETRANS || what ==  ICSK_TIME_LOSS_PROBE) {
+	    what == ICSK_TIME_EARLY_RETRANS || what == ICSK_TIME_LOSS_PROBE ||
+	    what == ICSK_TIME_REO_TIMEOUT) {
 		icsk->icsk_pending = what;
 		icsk->icsk_timeout = jiffies + when;
 		sk_reset_timer(sk, &icsk->icsk_retransmit_timer, icsk->icsk_timeout);

commit 0643ee4fd1b79c1af3bd7bc8968dbf5fd047f490
Author: Tom Herbert <tom@herbertland.com>
Date:   Wed Dec 14 16:54:16 2016 -0800

    inet: Fix get port to handle zero port number with soreuseport set
    
    A user may call listen with binding an explicit port with the intent
    that the kernel will assign an available port to the socket. In this
    case inet_csk_get_port does a port scan. For such sockets, the user may
    also set soreuseport with the intent a creating more sockets for the
    port that is selected. The problem is that the initial socket being
    opened could inadvertently choose an existing and unreleated port
    number that was already created with soreuseport.
    
    This patch adds a boolean parameter to inet_bind_conflict that indicates
    rather soreuseport is allowed for the check (in addition to
    sk->sk_reuseport). In calls to inet_bind_conflict from inet_csk_get_port
    the argument is set to true if an explicit port is being looked up (snum
    argument is nonzero), and is false if port scan is done.
    
    Signed-off-by: Tom Herbert <tom@herbertland.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 146054ceea8e..85ee3879499e 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -63,7 +63,8 @@ struct inet_connection_sock_af_ops {
 #endif
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
 	int	    (*bind_conflict)(const struct sock *sk,
-				     const struct inet_bind_bucket *tb, bool relax);
+				     const struct inet_bind_bucket *tb,
+				     bool relax, bool soreuseport_ok);
 	void	    (*mtu_reduced)(struct sock *sk);
 };
 
@@ -261,7 +262,8 @@ inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
 struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
 int inet_csk_bind_conflict(const struct sock *sk,
-			   const struct inet_bind_bucket *tb, bool relax);
+			   const struct inet_bind_bucket *tb, bool relax,
+			   bool soreuseport_ok);
 int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 struct dst_entry *inet_csk_route_req(const struct sock *sk, struct flowi4 *fl4,

commit 5ea8ea2cb7f1d0db15762c9b0bb9e7330425a071
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 26 09:27:57 2016 -0700

    tcp/dccp: drop SYN packets if accept queue is full
    
    Per listen(fd, backlog) rules, there is really no point accepting a SYN,
    sending a SYNACK, and dropping the following ACK packet if accept queue
    is full, because application is not draining accept queue fast enough.
    
    This behavior is fooling TCP clients that believe they established a
    flow, while there is nothing at server side. They might then send about
    10 MSS (if using IW10) that will be dropped anyway while server is under
    stress.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 197a30d221e9..146054ceea8e 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -289,11 +289,6 @@ static inline int inet_csk_reqsk_queue_len(const struct sock *sk)
 	return reqsk_queue_len(&inet_csk(sk)->icsk_accept_queue);
 }
 
-static inline int inet_csk_reqsk_queue_young(const struct sock *sk)
-{
-	return reqsk_queue_len_young(&inet_csk(sk)->icsk_accept_queue);
-}
-
 static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
 {
 	return inet_csk_reqsk_queue_len(sk) >= sk->sk_max_ack_backlog;

commit 7e744171386ae6da1248d3d27d10b6dbdc54f0ff
Author: Neal Cardwell <ncardwell@google.com>
Date:   Mon Sep 19 23:39:22 2016 -0400

    tcp: increase ICSK_CA_PRIV_SIZE from 64 bytes to 88
    
    The TCP CUBIC module already uses 64 bytes.
    The upcoming TCP BBR module uses 88 bytes.
    
    Signed-off-by: Van Jacobson <vanj@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Nandita Dukkipati <nanditad@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 49dcad4fe99e..197a30d221e9 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -134,8 +134,8 @@ struct inet_connection_sock {
 	} icsk_mtup;
 	u32			  icsk_user_timeout;
 
-	u64			  icsk_ca_priv[64 / sizeof(u64)];
-#define ICSK_CA_PRIV_SIZE      (8 * sizeof(u64))
+	u64			  icsk_ca_priv[88 / sizeof(u64)];
+#define ICSK_CA_PRIV_SIZE      (11 * sizeof(u64))
 };
 
 #define ICSK_TIME_RETRANS	1	/* Retransmit timer */

commit 7716682cc58e305e22207d5bb315f26af6b1e243
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Feb 18 05:39:18 2016 -0800

    tcp/dccp: fix another race at listener dismantle
    
    Ilya reported following lockdep splat:
    
    kernel: =========================
    kernel: [ BUG: held lock freed! ]
    kernel: 4.5.0-rc1-ceph-00026-g5e0a311 #1 Not tainted
    kernel: -------------------------
    kernel: swapper/5/0 is freeing memory
    ffff880035c9d200-ffff880035c9dbff, with a lock still held there!
    kernel: (&(&queue->rskq_lock)->rlock){+.-...}, at:
    [<ffffffff816f6a88>] inet_csk_reqsk_queue_add+0x28/0xa0
    kernel: 4 locks held by swapper/5/0:
    kernel: #0:  (rcu_read_lock){......}, at: [<ffffffff8169ef6b>]
    netif_receive_skb_internal+0x4b/0x1f0
    kernel: #1:  (rcu_read_lock){......}, at: [<ffffffff816e977f>]
    ip_local_deliver_finish+0x3f/0x380
    kernel: #2:  (slock-AF_INET){+.-...}, at: [<ffffffff81685ffb>]
    sk_clone_lock+0x19b/0x440
    kernel: #3:  (&(&queue->rskq_lock)->rlock){+.-...}, at:
    [<ffffffff816f6a88>] inet_csk_reqsk_queue_add+0x28/0xa0
    
    To properly fix this issue, inet_csk_reqsk_queue_add() needs
    to return to its callers if the child as been queued
    into accept queue.
    
    We also need to make sure listener is still there before
    calling sk->sk_data_ready(), by holding a reference on it,
    since the reference carried by the child can disappear as
    soon as the child is put on accept queue.
    
    Reported-by: Ilya Dryomov <idryomov@gmail.com>
    Fixes: ebb516af60e1 ("tcp/dccp: fix race at listener dismantle phase")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 481fe1c9044c..49dcad4fe99e 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -270,8 +270,9 @@ struct dst_entry *inet_csk_route_child_sock(const struct sock *sk,
 					    struct sock *newsk,
 					    const struct request_sock *req);
 
-void inet_csk_reqsk_queue_add(struct sock *sk, struct request_sock *req,
-			      struct sock *child);
+struct sock *inet_csk_reqsk_queue_add(struct sock *sk,
+				      struct request_sock *req,
+				      struct sock *child);
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
 				   unsigned long timeout);
 struct sock *inet_csk_complete_hashdance(struct sock *sk, struct sock *child,

commit 5e0724d027f0548511a2165a209572d48fe7a4c8
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Oct 22 08:20:46 2015 -0700

    tcp/dccp: fix hashdance race for passive sessions
    
    Multiple cpus can process duplicates of incoming ACK messages
    matching a SYN_RECV request socket. This is a rare event under
    normal operations, but definitely can happen.
    
    Only one must win the race, otherwise corruption would occur.
    
    To fix this without adding new atomic ops, we use logic in
    inet_ehash_nolisten() to detect the request was present in the same
    ehash bucket where we try to insert the new child.
    
    If request socket was not found, we have to undo the child creation.
    
    This actually removes a spin_lock()/spin_unlock() pair in
    reqsk_queue_unlink() for the fast path.
    
    Fixes: e994b2f0fb92 ("tcp: do not lock listener to process SYN packets")
    Fixes: 079096f103fa ("tcp/dccp: install syn_recv requests into ehash table")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 63615709839d..481fe1c9044c 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -43,7 +43,9 @@ struct inet_connection_sock_af_ops {
 	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);
 	struct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,
 				      struct request_sock *req,
-				      struct dst_entry *dst);
+				      struct dst_entry *dst,
+				      struct request_sock *req_unhash,
+				      bool *own_req);
 	u16	    net_header_len;
 	u16	    net_frag_header_len;
 	u16	    sockaddr_len;
@@ -272,6 +274,9 @@ void inet_csk_reqsk_queue_add(struct sock *sk, struct request_sock *req,
 			      struct sock *child);
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
 				   unsigned long timeout);
+struct sock *inet_csk_complete_hashdance(struct sock *sk, struct sock *child,
+					 struct request_sock *req,
+					 bool own_req);
 
 static inline void inet_csk_reqsk_queue_added(struct sock *sk)
 {

commit ebb516af60e18258aac8e80bbe068740ef1579ed
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 14 11:16:28 2015 -0700

    tcp/dccp: fix race at listener dismantle phase
    
    Under stress, a close() on a listener can trigger the
    WARN_ON(sk->sk_ack_backlog) in inet_csk_listen_stop()
    
    We need to test if listener is still active before queueing
    a child in inet_csk_reqsk_queue_add()
    
    Create a common inet_child_forget() helper, and use it
    from inet_csk_reqsk_queue_add() and inet_csk_listen_stop()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index e84ea9f2498f..63615709839d 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -268,13 +268,8 @@ struct dst_entry *inet_csk_route_child_sock(const struct sock *sk,
 					    struct sock *newsk,
 					    const struct request_sock *req);
 
-static inline void inet_csk_reqsk_queue_add(struct sock *sk,
-					    struct request_sock *req,
-					    struct sock *child)
-{
-	reqsk_queue_add(&inet_csk(sk)->icsk_accept_queue, req, sk, child);
-}
-
+void inet_csk_reqsk_queue_add(struct sock *sk, struct request_sock *req,
+			      struct sock *child);
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
 				   unsigned long timeout);
 

commit f03f2e154f52fdaa982de7e2c386737679963dc9
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 14 11:16:27 2015 -0700

    tcp/dccp: add inet_csk_reqsk_queue_drop_and_put() helper
    
    Let's reduce the confusion about inet_csk_reqsk_queue_drop() :
    In many cases we also need to release reference on request socket,
    so add a helper to do this, reducing code size and complexity.
    
    Fixes: 4bdc3d66147b ("tcp/dccp: fix behavior of stale SYN_RECV request sockets")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index fd645c49e71e..e84ea9f2498f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -299,6 +299,7 @@ static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
 }
 
 void inet_csk_reqsk_queue_drop(struct sock *sk, struct request_sock *req);
+void inet_csk_reqsk_queue_drop_and_put(struct sock *sk, struct request_sock *req);
 
 void inet_csk_destroy_sock(struct sock *sk);
 void inet_csk_prepare_forced_close(struct sock *sk);

commit f985c65c908f6b26c30019a83dc5ea295f5fcf62
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 14 06:16:49 2015 -0700

    tcp: avoid spurious SYN flood detection at listen() time
    
    At listen() time, there is a small window where listener is visible with
    a zero backlog, triggering a spurious "Possible SYN flooding on port"
    message.
    
    Nothing prevents us from setting the correct backlog.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 3208a65d1c28..fd645c49e71e 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -312,7 +312,7 @@ static inline unsigned int inet_csk_listen_poll(const struct sock *sk)
 			(POLLIN | POLLRDNORM) : 0;
 }
 
-int inet_csk_listen_start(struct sock *sk, const int nr_table_entries);
+int inet_csk_listen_start(struct sock *sk, int backlog);
 void inet_csk_listen_stop(struct sock *sk);
 
 void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);

commit ef547f2ac16bd9d77a780a0e7c70857e69e8f23f
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Oct 2 11:43:37 2015 -0700

    tcp: remove max_qlen_log
    
    This control variable was set at first listen(fd, backlog)
    call, but not updated if application tried to increase or decrease
    backlog. It made sense at the time listener had a non resizeable
    hash table.
    
    Also rounding to powers of two was not very friendly.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 730aa034cd3d..3208a65d1c28 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -295,7 +295,7 @@ static inline int inet_csk_reqsk_queue_young(const struct sock *sk)
 
 static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
 {
-	return reqsk_queue_is_full(&inet_csk(sk)->icsk_accept_queue);
+	return inet_csk_reqsk_queue_len(sk) >= sk->sk_max_ack_backlog;
 }
 
 void inet_csk_reqsk_queue_drop(struct sock *sk, struct request_sock *req);

commit 079096f103faca2dd87342cca6f23d4b34da8871
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Oct 2 11:43:32 2015 -0700

    tcp/dccp: install syn_recv requests into ehash table
    
    In this patch, we insert request sockets into TCP/DCCP
    regular ehash table (where ESTABLISHED and TIMEWAIT sockets
    are) instead of using the per listener hash table.
    
    ACK packets find SYN_RECV pseudo sockets without having
    to find and lock the listener.
    
    In nominal conditions, this halves pressure on listener lock.
    
    Note that this will allow for SO_REUSEPORT refinements,
    so that we can select a listener using cpu/numa affinities instead
    of the prior 'consistent hash', since only SYN packets will
    apply this selection logic.
    
    We will shrink listen_sock in the following patch to ease
    code review.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Ying Cai <ycai@google.com>
    Cc: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index b2e2e30befa9..730aa034cd3d 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -258,10 +258,6 @@ inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
 
 struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
-struct request_sock *inet_csk_search_req(struct sock *sk,
-					 const __be16 rport,
-					 const __be32 raddr,
-					 const __be32 laddr);
 int inet_csk_bind_conflict(const struct sock *sk,
 			   const struct inet_bind_bucket *tb, bool relax);
 int inet_csk_get_port(struct sock *sk, unsigned short snum);

commit 2feda34192a379f8b35a7c6c5826b2f23e884f32
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Oct 2 11:43:31 2015 -0700

    tcp/dccp: remove inet_csk_reqsk_queue_added() timeout argument
    
    This is no longer used.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index ee54f21a8113..b2e2e30befa9 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -282,8 +282,7 @@ static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
 				   unsigned long timeout);
 
-static inline void inet_csk_reqsk_queue_added(struct sock *sk,
-					      const unsigned long timeout)
+static inline void inet_csk_reqsk_queue_added(struct sock *sk)
 {
 	reqsk_queue_added(&inet_csk(sk)->icsk_accept_queue);
 }

commit 0c27171e66d94f9121fc00e87407ca7103bb6649
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 29 07:42:48 2015 -0700

    tcp/dccp: constify syn_recv_sock() method sock argument
    
    We'll soon no longer hold listener socket lock, these
    functions do not modify the socket in any way.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 187cef7e56d5..ee54f21a8113 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -41,7 +41,7 @@ struct inet_connection_sock_af_ops {
 	int	    (*rebuild_header)(struct sock *sk);
 	void	    (*sk_rx_dst_set)(struct sock *sk, const struct sk_buff *skb);
 	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);
-	struct sock *(*syn_recv_sock)(struct sock *sk, struct sk_buff *skb,
+	struct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,
 				      struct request_sock *req,
 				      struct dst_entry *dst);
 	u16	    net_header_len;

commit a2432c4fa5e3c4c06df6efe0c406b6f575829a7b
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 29 07:42:43 2015 -0700

    inet: constify inet_csk_route_child_sock() socket argument
    
    The socket points to the (shared) listener.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 00c3ced6ee55..187cef7e56d5 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -268,7 +268,8 @@ int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 struct dst_entry *inet_csk_route_req(const struct sock *sk, struct flowi4 *fl4,
 				     const struct request_sock *req);
-struct dst_entry *inet_csk_route_child_sock(struct sock *sk, struct sock *newsk,
+struct dst_entry *inet_csk_route_child_sock(const struct sock *sk,
+					    struct sock *newsk,
 					    const struct request_sock *req);
 
 static inline void inet_csk_reqsk_queue_add(struct sock *sk,

commit e5895bc600ccba1fde4ea0741813f9c33b5b4021
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Sep 25 07:39:11 2015 -0700

    inet: constify inet_csk_route_req() socket argument
    
    This is used by TCP listener core, and listener socket shall
    not be modified by inet_csk_route_req().
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 0320bbb7d7b5..00c3ced6ee55 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -266,7 +266,7 @@ int inet_csk_bind_conflict(const struct sock *sk,
 			   const struct inet_bind_bucket *tb, bool relax);
 int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
-struct dst_entry *inet_csk_route_req(struct sock *sk, struct flowi4 *fl4,
+struct dst_entry *inet_csk_route_req(const struct sock *sk, struct flowi4 *fl4,
 				     const struct request_sock *req);
 struct dst_entry *inet_csk_route_child_sock(struct sock *sk, struct sock *newsk,
 					    const struct request_sock *req);

commit 9f950415e4e28e7cfae2e416b43e862e8101d996
Author: Neal Cardwell <ncardwell@google.com>
Date:   Fri May 29 13:47:07 2015 -0400

    tcp: fix child sockets to use system default congestion control if not set
    
    Linux 3.17 and earlier are explicitly engineered so that if the app
    doesn't specifically request a CC module on a listener before the SYN
    arrives, then the child gets the system default CC when the connection
    is established. See tcp_init_congestion_control() in 3.17 or earlier,
    which says "if no choice made yet assign the current value set as
    default". The change ("net: tcp: assign tcp cong_ops when tcp sk is
    created") altered these semantics, so that children got their parent
    listener's congestion control even if the system default had changed
    after the listener was created.
    
    This commit returns to those original semantics from 3.17 and earlier,
    since they are the original semantics from 2007 in 4d4d3d1e8 ("[TCP]:
    Congestion control initialization."), and some Linux congestion
    control workflows depend on that.
    
    In summary, if a listener socket specifically sets TCP_CONGESTION to
    "x", or the route locks the CC module to "x", then the child gets
    "x". Otherwise the child gets current system default from
    net.ipv4.tcp_congestion_control. That's the behavior in 3.17 and
    earlier, and this commit restores that.
    
    Fixes: 55d8694fa82c ("net: tcp: assign tcp cong_ops when tcp sk is created")
    Cc: Florian Westphal <fw@strlen.de>
    Cc: Daniel Borkmann <dborkman@redhat.com>
    Cc: Glenn Judd <glenn.judd@morganstanley.com>
    Cc: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 497bc14cdb85..0320bbb7d7b5 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -98,7 +98,8 @@ struct inet_connection_sock {
 	const struct tcp_congestion_ops *icsk_ca_ops;
 	const struct inet_connection_sock_af_ops *icsk_af_ops;
 	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
-	__u8			  icsk_ca_state:7,
+	__u8			  icsk_ca_state:6,
+				  icsk_ca_setsockopt:1,
 				  icsk_ca_dst_locked:1;
 	__u8			  icsk_retransmits;
 	__u8			  icsk_pending;

commit b5d721d761fccf491f92eefc611e318561683d0a
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon May 18 17:06:14 2015 -0700

    inet: properly align icsk_ca_priv
    
    tcp_illinois and upcoming tcp_cdg require 64bit alignment of
    icsk_ca_priv
    
    x86 does not care, but other architectures might.
    
    Fixes: 05cbc0db03e82 ("ipv4: Create probe timer for tcp PMTU as per RFC4821")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Fan Du <fan.du@intel.com>
    Acked-by: Fan Du <fan.du@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 48a815823587..497bc14cdb85 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -129,9 +129,10 @@ struct inet_connection_sock {
 
 		u32		  probe_timestamp;
 	} icsk_mtup;
-	u32			  icsk_ca_priv[16];
 	u32			  icsk_user_timeout;
-#define ICSK_CA_PRIV_SIZE	(16 * sizeof(u32))
+
+	u64			  icsk_ca_priv[64 / sizeof(u64)];
+#define ICSK_CA_PRIV_SIZE      (8 * sizeof(u64))
 };
 
 #define ICSK_TIME_RETRANS	1	/* Retransmit timer */

commit b357a364c57c940ddb932224542494363df37378
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Apr 23 18:03:44 2015 -0700

    inet: fix possible panic in reqsk_queue_unlink()
    
    [ 3897.923145] BUG: unable to handle kernel NULL pointer dereference at
     0000000000000080
    [ 3897.931025] IP: [<ffffffffa9f27686>] reqsk_timer_handler+0x1a6/0x243
    
    There is a race when reqsk_timer_handler() and tcp_check_req() call
    inet_csk_reqsk_queue_unlink() on the same req at the same time.
    
    Before commit fa76ce7328b2 ("inet: get rid of central tcp/dccp listener
    timer"), listener spinlock was held and race could not happen.
    
    To solve this bug, we change reqsk_queue_unlink() to not assume req
    must be found, and we return a status, to conditionally release a
    refcount on the request sock.
    
    This also means tcp_check_req() in non fastopen case might or not
    consume req refcount, so tcp_v6_hnd_req() & tcp_v4_hnd_req() have
    to properly handle this.
    
    (Same remark for dccp_check_req() and its callers)
    
    inet_csk_reqsk_queue_drop() is now too big to be inlined, as it is
    called 4 times in tcp and 3 times in dccp.
    
    Fixes: fa76ce7328b2 ("inet: get rid of central tcp/dccp listener timer")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 7b5887cd1172..48a815823587 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -279,12 +279,6 @@ static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
 				   unsigned long timeout);
 
-static inline void inet_csk_reqsk_queue_removed(struct sock *sk,
-						struct request_sock *req)
-{
-	reqsk_queue_removed(&inet_csk(sk)->icsk_accept_queue, req);
-}
-
 static inline void inet_csk_reqsk_queue_added(struct sock *sk,
 					      const unsigned long timeout)
 {
@@ -306,19 +300,7 @@ static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
 	return reqsk_queue_is_full(&inet_csk(sk)->icsk_accept_queue);
 }
 
-static inline void inet_csk_reqsk_queue_unlink(struct sock *sk,
-					       struct request_sock *req)
-{
-	reqsk_queue_unlink(&inet_csk(sk)->icsk_accept_queue, req);
-}
-
-static inline void inet_csk_reqsk_queue_drop(struct sock *sk,
-					     struct request_sock *req)
-{
-	inet_csk_reqsk_queue_unlink(sk, req);
-	inet_csk_reqsk_queue_removed(sk, req);
-	reqsk_put(req);
-}
+void inet_csk_reqsk_queue_drop(struct sock *sk, struct request_sock *req);
 
 void inet_csk_destroy_sock(struct sock *sk);
 void inet_csk_prepare_forced_close(struct sock *sk);

commit fa76ce7328b289b6edd476e24eb52fd634261720
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Mar 19 19:04:20 2015 -0700

    inet: get rid of central tcp/dccp listener timer
    
    One of the major issue for TCP is the SYNACK rtx handling,
    done by inet_csk_reqsk_queue_prune(), fired by the keepalive
    timer of a TCP_LISTEN socket.
    
    This function runs for awful long times, with socket lock held,
    meaning that other cpus needing this lock have to spin for hundred of ms.
    
    SYNACK are sent in huge bursts, likely to cause severe drops anyway.
    
    This model was OK 15 years ago when memory was very tight.
    
    We now can afford to have a timer per request sock.
    
    Timer invocations no longer need to lock the listener,
    and can be run from all cpus in parallel.
    
    With following patch increasing somaxconn width to 32 bits,
    I tested a listener with more than 4 million active request sockets,
    and a steady SYNFLOOD of ~200,000 SYN per second.
    Host was sending ~830,000 SYNACK per second.
    
    This is ~100 times more what we could achieve before this patch.
    
    Later, we will get rid of the listener hash and use ehash instead.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 423a46106e57..7b5887cd1172 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -256,7 +256,7 @@ inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
 
 struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
-struct request_sock *inet_csk_search_req(const struct sock *sk,
+struct request_sock *inet_csk_search_req(struct sock *sk,
 					 const __be16 rport,
 					 const __be32 raddr,
 					 const __be32 laddr);
@@ -282,15 +282,13 @@ void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
 static inline void inet_csk_reqsk_queue_removed(struct sock *sk,
 						struct request_sock *req)
 {
-	if (reqsk_queue_removed(&inet_csk(sk)->icsk_accept_queue, req) == 0)
-		inet_csk_delete_keepalive_timer(sk);
+	reqsk_queue_removed(&inet_csk(sk)->icsk_accept_queue, req);
 }
 
 static inline void inet_csk_reqsk_queue_added(struct sock *sk,
 					      const unsigned long timeout)
 {
-	if (reqsk_queue_added(&inet_csk(sk)->icsk_accept_queue) == 0)
-		inet_csk_reset_keepalive_timer(sk, timeout);
+	reqsk_queue_added(&inet_csk(sk)->icsk_accept_queue);
 }
 
 static inline int inet_csk_reqsk_queue_len(const struct sock *sk)
@@ -319,14 +317,9 @@ static inline void inet_csk_reqsk_queue_drop(struct sock *sk,
 {
 	inet_csk_reqsk_queue_unlink(sk, req);
 	inet_csk_reqsk_queue_removed(sk, req);
-	reqsk_free(req);
+	reqsk_put(req);
 }
 
-void inet_csk_reqsk_queue_prune(struct sock *parent,
-				const unsigned long interval,
-				const unsigned long timeout,
-				const unsigned long max_rto);
-
 void inet_csk_destroy_sock(struct sock *sk);
 void inet_csk_prepare_forced_close(struct sock *sk);
 

commit 52452c542559ac980b48dbf22a30ee7fa0af507c
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Mar 19 19:04:19 2015 -0700

    inet: drop prev pointer handling in request sock
    
    When request sock are put in ehash table, the whole notion
    of having a previous request to update dl_next is pointless.
    
    Also, following patch will get rid of big purge timer,
    so we want to delete a request sock without holding listener lock.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index b9a6b0a94cc6..423a46106e57 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -257,7 +257,6 @@ inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
 struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
 struct request_sock *inet_csk_search_req(const struct sock *sk,
-					 struct request_sock ***prevp,
 					 const __be16 rport,
 					 const __be32 raddr,
 					 const __be32 laddr);
@@ -310,17 +309,15 @@ static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
 }
 
 static inline void inet_csk_reqsk_queue_unlink(struct sock *sk,
-					       struct request_sock *req,
-					       struct request_sock **prev)
+					       struct request_sock *req)
 {
-	reqsk_queue_unlink(&inet_csk(sk)->icsk_accept_queue, req, prev);
+	reqsk_queue_unlink(&inet_csk(sk)->icsk_accept_queue, req);
 }
 
 static inline void inet_csk_reqsk_queue_drop(struct sock *sk,
-					     struct request_sock *req,
-					     struct request_sock **prev)
+					     struct request_sock *req)
 {
-	inet_csk_reqsk_queue_unlink(sk, req, prev);
+	inet_csk_reqsk_queue_unlink(sk, req);
 	inet_csk_reqsk_queue_removed(sk, req);
 	reqsk_free(req);
 }

commit 0470c8ca1d57927f2cc3e1d5add1fb2834609447
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Mar 17 18:32:31 2015 -0700

    inet: fix request sock refcounting
    
    While testing last patch series, I found req sock refcounting was wrong.
    
    We must set skc_refcnt to 1 for all request socks added in hashes,
    but also on request sockets created by FastOpen or syncookies.
    
    It is tricky because we need to defer this initialization so that
    future RCU lookups do not try to take a refcount on a not yet
    fully initialized request socket.
    
    Also get rid of ireq_refcnt alias.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Fixes: 13854e5a6046 ("inet: add proper refcounting to request sock")
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 191feec60205..b9a6b0a94cc6 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -275,11 +275,6 @@ static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 					    struct sock *child)
 {
 	reqsk_queue_add(&inet_csk(sk)->icsk_accept_queue, req, sk, child);
-	/* before letting lookups find us, make sure all req fields
-	 * are committed to memory.
-	 */
-	smp_wmb();
-	atomic_set(&req->rsk_refcnt, 1);
 }
 
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,

commit 13854e5a60461daee08ce99842b7f4d37553d911
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Mar 15 21:12:16 2015 -0700

    inet: add proper refcounting to request sock
    
    reqsk_put() is the generic function that should be used
    to release a refcount (and automatically call reqsk_free())
    
    reqsk_free() might be called if refcount is known to be 0
    or undefined.
    
    refcnt is set to one in inet_csk_reqsk_queue_add()
    
    As request socks are not yet in global ehash table,
    I added temporary debugging checks in reqsk_put() and reqsk_free()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index b9a6b0a94cc6..191feec60205 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -275,6 +275,11 @@ static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 					    struct sock *child)
 {
 	reqsk_queue_add(&inet_csk(sk)->icsk_accept_queue, req, sk, child);
+	/* before letting lookups find us, make sure all req fields
+	 * are committed to memory.
+	 */
+	smp_wmb();
+	atomic_set(&req->rsk_refcnt, 1);
 }
 
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,

commit 05cbc0db03e82128f2e7e353d4194dd24a1627fe
Author: Fan Du <fan.du@intel.com>
Date:   Fri Mar 6 11:18:24 2015 +0800

    ipv4: Create probe timer for tcp PMTU as per RFC4821
    
    As per RFC4821 7.3.  Selecting Probe Size, a probe timer should
    be armed once probing has converged. Once this timer expired,
    probing again to take advantage of any path PMTU change. The
    recommended probing interval is 10 minutes per RFC1981. Probing
    interval could be sysctled by sysctl_tcp_probe_interval.
    
    Eric Dumazet suggested to implement pseudo timer based on 32bits
    jiffies tcp_time_stamp instead of using classic timer for such
    rare event.
    
    Signed-off-by: Fan Du <fan.du@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 5976bdecf58b..b9a6b0a94cc6 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -126,6 +126,8 @@ struct inet_connection_sock {
 
 		/* Information on the current probe. */
 		int		  probe_size;
+
+		u32		  probe_timestamp;
 	} icsk_mtup;
 	u32			  icsk_ca_priv[16];
 	u32			  icsk_user_timeout;

commit c5c6a8ab45ec0f18733afb4aaade0d4a139d80b3
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Mon Jan 5 23:57:46 2015 +0100

    net: tcp: add key management to congestion control
    
    This patch adds necessary infrastructure to the congestion control
    framework for later per route congestion control support.
    
    For a per route congestion control possibility, our aim is to store
    a unique u32 key identifier into dst metrics, which can then be
    mapped into a tcp_congestion_ops struct. We argue that having a
    RTAX key entry is the most simple, generic and easy way to manage,
    and also keeps the memory footprint of dst entries lower on 64 bit
    than with storing a pointer directly, for example. Having a unique
    key id also allows for decoupling actual TCP congestion control
    module management from the FIB layer, i.e. we don't have to care
    about expensive module refcounting inside the FIB at this point.
    
    We first thought of using an IDR store for the realization, which
    takes over dynamic assignment of unused key space and also performs
    the key to pointer mapping in RCU. While doing so, we stumbled upon
    the issue that due to the nature of dynamic key distribution, it
    just so happens, arguably in very rare occasions, that excessive
    module loads and unloads can lead to a possible reuse of previously
    used key space. Thus, previously stale keys in the dst metric are
    now being reassigned to a different congestion control algorithm,
    which might lead to unexpected behaviour. One way to resolve this
    would have been to walk FIBs on the actually rare occasion of a
    module unload and reset the metric keys for each FIB in each netns,
    but that's just very costly.
    
    Therefore, we argue a better solution is to reuse the unique
    congestion control algorithm name member and map that into u32 key
    space through jhash. For that, we split the flags attribute (as it
    currently uses 2 bits only anyway) into two u32 attributes, flags
    and key, so that we can keep the cacheline boundary of 2 cachelines
    on x86_64 and cache the precalculated key at registration time for
    the fast path. On average we might expect 2 - 4 modules being loaded
    worst case perhaps 15, so a key collision possibility is extremely
    low, and guaranteed collision-free on LE/BE for all in-tree modules.
    Overall this results in much simpler code, and all without the
    overhead of an IDR. Due to the deterministic nature, modules can
    now be unloaded, the congestion control algorithm for a specific
    but unloaded key will fall back to the default one, and on module
    reload time it will switch back to the expected algorithm
    transparently.
    
    Joint work with Florian Westphal.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 848e85cb5c61..5976bdecf58b 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -98,7 +98,8 @@ struct inet_connection_sock {
 	const struct tcp_congestion_ops *icsk_ca_ops;
 	const struct inet_connection_sock_af_ops *icsk_af_ops;
 	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
-	__u8			  icsk_ca_state;
+	__u8			  icsk_ca_state:7,
+				  icsk_ca_dst_locked:1;
 	__u8			  icsk_retransmits;
 	__u8			  icsk_pending;
 	__u8			  icsk_backoff;

commit fcdd1cf4dd63aecf86c987d7f4ec7187be5c2fbc
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Sep 22 13:19:44 2014 -0700

    tcp: avoid possible arithmetic overflows
    
    icsk_rto is a 32bit field, and icsk_backoff can reach 15 by default,
    or more if some sysctl (eg tcp_retries2) are changed.
    
    Better use 64bit to perform icsk_rto << icsk_backoff operations
    
    As Joe Perches suggested, add a helper for this.
    
    Yuchung spotted the tcp_v4_err() case.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 5fbe6568c3cf..848e85cb5c61 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -242,6 +242,15 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 #endif
 }
 
+static inline unsigned long
+inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
+		     unsigned long max_when)
+{
+        u64 when = (u64)icsk->icsk_rto << icsk->icsk_backoff;
+
+        return (unsigned long)min_t(u64, when, max_when);
+}
+
 struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
 struct request_sock *inet_csk_search_req(const struct sock *sk,

commit 4fab9071950c2021d846e18351e0f46a1cffd67b
Author: Neal Cardwell <ncardwell@google.com>
Date:   Thu Aug 14 12:40:05 2014 -0400

    tcp: fix tcp_release_cb() to dispatch via address family for mtu_reduced()
    
    Make sure we use the correct address-family-specific function for
    handling MTU reductions from within tcp_release_cb().
    
    Previously AF_INET6 sockets were incorrectly always using the IPv6
    code path when sometimes they were handling IPv4 traffic and thus had
    an IPv4 dst.
    
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Diagnosed-by: Willem de Bruijn <willemb@google.com>
    Fixes: 563d34d057862 ("tcp: dont drop MTU reduction indications")
    Reviewed-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 7a4313887568..5fbe6568c3cf 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -62,6 +62,7 @@ struct inet_connection_sock_af_ops {
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
 	int	    (*bind_conflict)(const struct sock *sk,
 				     const struct inet_bind_bucket *tb, bool relax);
+	void	    (*mtu_reduced)(struct sock *sk);
 };
 
 /** inet_connection_sock - INET connection oriented sock

commit b0270e91014dabfceaf37f5b40ad51bbf21a1302
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Apr 15 12:58:34 2014 -0400

    ipv4: add a sock pointer to ip_queue_xmit()
    
    ip_queue_xmit() assumes the skb it has to transmit is attached to an
    inet socket. Commit 31c70d5956fc ("l2tp: keep original skb ownership")
    changed l2tp to not change skb ownership and thus broke this assumption.
    
    One fix is to add a new 'struct sock *sk' parameter to ip_queue_xmit(),
    so that we do not assume skb->sk points to the socket used by l2tp
    tunnel.
    
    Fixes: 31c70d5956fc ("l2tp: keep original skb ownership")
    Reported-by: Zhan Jianyu <nasa4836@gmail.com>
    Tested-by: Zhan Jianyu <nasa4836@gmail.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index c55aeed41ace..7a4313887568 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -36,7 +36,7 @@ struct tcp_congestion_ops;
  * (i.e. things that depend on the address family)
  */
 struct inet_connection_sock_af_ops {
-	int	    (*queue_xmit)(struct sk_buff *skb, struct flowi *fl);
+	int	    (*queue_xmit)(struct sock *sk, struct sk_buff *skb, struct flowi *fl);
 	void	    (*send_check)(struct sock *sk, struct sk_buff *skb);
 	int	    (*rebuild_header)(struct sock *sk);
 	void	    (*sk_rx_dst_set)(struct sock *sk, const struct sk_buff *skb);

commit 1fd51155387264e3ca72094abadcaadb3f5969f6
Author: Joe Perches <joe@perches.com>
Date:   Sat Sep 21 10:22:41 2013 -0700

    inet*.h: Remove extern from function prototypes
    
    There are a mix of function prototypes with and without extern
    in the kernel sources.  Standardize on not using extern for
    function prototypes.
    
    Function prototypes don't need to be written with extern.
    extern is assumed by the compiler.  Its use is as unnecessary as
    using auto to declare automatic/local variables in a block.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index de2c78529afa..c55aeed41ace 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -146,9 +146,9 @@ static inline void *inet_csk_ca(const struct sock *sk)
 	return (void *)inet_csk(sk)->icsk_ca_priv;
 }
 
-extern struct sock *inet_csk_clone_lock(const struct sock *sk,
-					const struct request_sock *req,
-					const gfp_t priority);
+struct sock *inet_csk_clone_lock(const struct sock *sk,
+				 const struct request_sock *req,
+				 const gfp_t priority);
 
 enum inet_csk_ack_state_t {
 	ICSK_ACK_SCHED	= 1,
@@ -157,11 +157,11 @@ enum inet_csk_ack_state_t {
 	ICSK_ACK_PUSHED2 = 8
 };
 
-extern void inet_csk_init_xmit_timers(struct sock *sk,
-				      void (*retransmit_handler)(unsigned long),
-				      void (*delack_handler)(unsigned long),
-				      void (*keepalive_handler)(unsigned long));
-extern void inet_csk_clear_xmit_timers(struct sock *sk);
+void inet_csk_init_xmit_timers(struct sock *sk,
+			       void (*retransmit_handler)(unsigned long),
+			       void (*delack_handler)(unsigned long),
+			       void (*keepalive_handler)(unsigned long));
+void inet_csk_clear_xmit_timers(struct sock *sk);
 
 static inline void inet_csk_schedule_ack(struct sock *sk)
 {
@@ -178,8 +178,8 @@ static inline void inet_csk_delack_init(struct sock *sk)
 	memset(&inet_csk(sk)->icsk_ack, 0, sizeof(inet_csk(sk)->icsk_ack));
 }
 
-extern void inet_csk_delete_keepalive_timer(struct sock *sk);
-extern void inet_csk_reset_keepalive_timer(struct sock *sk, unsigned long timeout);
+void inet_csk_delete_keepalive_timer(struct sock *sk);
+void inet_csk_reset_keepalive_timer(struct sock *sk, unsigned long timeout);
 
 #ifdef INET_CSK_DEBUG
 extern const char inet_csk_timer_bug_msg[];
@@ -241,23 +241,21 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 #endif
 }
 
-extern struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
+struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
-extern struct request_sock *inet_csk_search_req(const struct sock *sk,
-						struct request_sock ***prevp,
-						const __be16 rport,
-						const __be32 raddr,
-						const __be32 laddr);
-extern int inet_csk_bind_conflict(const struct sock *sk,
-				  const struct inet_bind_bucket *tb, bool relax);
-extern int inet_csk_get_port(struct sock *sk, unsigned short snum);
+struct request_sock *inet_csk_search_req(const struct sock *sk,
+					 struct request_sock ***prevp,
+					 const __be16 rport,
+					 const __be32 raddr,
+					 const __be32 laddr);
+int inet_csk_bind_conflict(const struct sock *sk,
+			   const struct inet_bind_bucket *tb, bool relax);
+int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
-extern struct dst_entry* inet_csk_route_req(struct sock *sk,
-					    struct flowi4 *fl4,
+struct dst_entry *inet_csk_route_req(struct sock *sk, struct flowi4 *fl4,
+				     const struct request_sock *req);
+struct dst_entry *inet_csk_route_child_sock(struct sock *sk, struct sock *newsk,
 					    const struct request_sock *req);
-extern struct dst_entry* inet_csk_route_child_sock(struct sock *sk,
-						   struct sock *newsk,
-						   const struct request_sock *req);
 
 static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 					    struct request_sock *req,
@@ -266,9 +264,8 @@ static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 	reqsk_queue_add(&inet_csk(sk)->icsk_accept_queue, req, sk, child);
 }
 
-extern void inet_csk_reqsk_queue_hash_add(struct sock *sk,
-					  struct request_sock *req,
-					  unsigned long timeout);
+void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
+				   unsigned long timeout);
 
 static inline void inet_csk_reqsk_queue_removed(struct sock *sk,
 						struct request_sock *req)
@@ -315,13 +312,13 @@ static inline void inet_csk_reqsk_queue_drop(struct sock *sk,
 	reqsk_free(req);
 }
 
-extern void inet_csk_reqsk_queue_prune(struct sock *parent,
-				       const unsigned long interval,
-				       const unsigned long timeout,
-				       const unsigned long max_rto);
+void inet_csk_reqsk_queue_prune(struct sock *parent,
+				const unsigned long interval,
+				const unsigned long timeout,
+				const unsigned long max_rto);
 
-extern void inet_csk_destroy_sock(struct sock *sk);
-extern void inet_csk_prepare_forced_close(struct sock *sk);
+void inet_csk_destroy_sock(struct sock *sk);
+void inet_csk_prepare_forced_close(struct sock *sk);
 
 /*
  * LISTEN is a special case for poll..
@@ -332,15 +329,15 @@ static inline unsigned int inet_csk_listen_poll(const struct sock *sk)
 			(POLLIN | POLLRDNORM) : 0;
 }
 
-extern int  inet_csk_listen_start(struct sock *sk, const int nr_table_entries);
-extern void inet_csk_listen_stop(struct sock *sk);
+int inet_csk_listen_start(struct sock *sk, const int nr_table_entries);
+void inet_csk_listen_stop(struct sock *sk);
 
-extern void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);
+void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);
 
-extern int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,
-				      char __user *optval, int __user *optlen);
-extern int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
-				      char __user *optval, unsigned int optlen);
+int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,
+			       char __user *optval, int __user *optlen);
+int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
+			       char __user *optval, unsigned int optlen);
 
-extern struct dst_entry *inet_csk_update_pmtu(struct sock *sk, u32 mtu);
+struct dst_entry *inet_csk_update_pmtu(struct sock *sk, u32 mtu);
 #endif /* _INET_CONNECTION_SOCK_H */

commit 6ba8a3b19e764b6a65e4030ab0999be50c291e6c
Author: Nandita Dukkipati <nanditad@google.com>
Date:   Mon Mar 11 10:00:43 2013 +0000

    tcp: Tail loss probe (TLP)
    
    This patch series implement the Tail loss probe (TLP) algorithm described
    in http://tools.ietf.org/html/draft-dukkipati-tcpm-tcp-loss-probe-01. The
    first patch implements the basic algorithm.
    
    TLP's goal is to reduce tail latency of short transactions. It achieves
    this by converting retransmission timeouts (RTOs) occuring due
    to tail losses (losses at end of transactions) into fast recovery.
    TLP transmits one packet in two round-trips when a connection is in
    Open state and isn't receiving any ACKs. The transmitted packet, aka
    loss probe, can be either new or a retransmission. When there is tail
    loss, the ACK from a loss probe triggers FACK/early-retransmit based
    fast recovery, thus avoiding a costly RTO. In the absence of loss,
    there is no change in the connection state.
    
    PTO stands for probe timeout. It is a timer event indicating
    that an ACK is overdue and triggers a loss probe packet. The PTO value
    is set to max(2*SRTT, 10ms) and is adjusted to account for delayed
    ACK timer when there is only one oustanding packet.
    
    TLP Algorithm
    
    On transmission of new data in Open state:
      -> packets_out > 1: schedule PTO in max(2*SRTT, 10ms).
      -> packets_out == 1: schedule PTO in max(2*RTT, 1.5*RTT + 200ms)
      -> PTO = min(PTO, RTO)
    
    Conditions for scheduling PTO:
      -> Connection is in Open state.
      -> Connection is either cwnd limited or no new data to send.
      -> Number of probes per tail loss episode is limited to one.
      -> Connection is SACK enabled.
    
    When PTO fires:
      new_segment_exists:
        -> transmit new segment.
        -> packets_out++. cwnd remains same.
    
      no_new_packet:
        -> retransmit the last segment.
           Its ACK triggers FACK or early retransmit based recovery.
    
    ACK path:
      -> rearm RTO at start of ACK processing.
      -> reschedule PTO if need be.
    
    In addition, the patch includes a small variation to the Early Retransmit
    (ER) algorithm, such that ER and TLP together can in principle recover any
    N-degree of tail loss through fast recovery. TLP is controlled by the same
    sysctl as ER, tcp_early_retrans sysctl.
    tcp_early_retrans==0; disables TLP and ER.
                     ==1; enables RFC5827 ER.
                     ==2; delayed ER.
                     ==3; TLP and delayed ER. [DEFAULT]
                     ==4; TLP only.
    
    The TLP patch series have been extensively tested on Google Web servers.
    It is most effective for short Web trasactions, where it reduced RTOs by 15%
    and improved HTTP response time (average by 6%, 99th percentile by 10%).
    The transmitted probes account for <0.5% of the overall transmissions.
    
    Signed-off-by: Nandita Dukkipati <nanditad@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 183292722f6e..de2c78529afa 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -133,6 +133,8 @@ struct inet_connection_sock {
 #define ICSK_TIME_RETRANS	1	/* Retransmit timer */
 #define ICSK_TIME_DACK		2	/* Delayed ack timer */
 #define ICSK_TIME_PROBE0	3	/* Zero window probe timer */
+#define ICSK_TIME_EARLY_RETRANS 4	/* Early retransmit timer */
+#define ICSK_TIME_LOSS_PROBE	5	/* Tail loss probe timer */
 
 static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
 {
@@ -222,7 +224,8 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 		when = max_when;
 	}
 
-	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0) {
+	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0 ||
+	    what == ICSK_TIME_EARLY_RETRANS || what ==  ICSK_TIME_LOSS_PROBE) {
 		icsk->icsk_pending = what;
 		icsk->icsk_timeout = jiffies + when;
 		sk_reset_timer(sk, &icsk->icsk_retransmit_timer, icsk->icsk_timeout);

commit e337e24d6624e74a558aa69071e112a65f7b5758
Author: Christoph Paasch <christoph.paasch@uclouvain.be>
Date:   Fri Dec 14 04:07:58 2012 +0000

    inet: Fix kmemleak in tcp_v4/6_syn_recv_sock and dccp_v4/6_request_recv_sock
    
    If in either of the above functions inet_csk_route_child_sock() or
    __inet_inherit_port() fails, the newsk will not be freed:
    
    unreferenced object 0xffff88022e8a92c0 (size 1592):
      comm "softirq", pid 0, jiffies 4294946244 (age 726.160s)
      hex dump (first 32 bytes):
        0a 01 01 01 0a 01 01 02 00 00 00 00 a7 cc 16 00  ................
        02 00 03 01 00 00 00 00 00 00 00 00 00 00 00 00  ................
      backtrace:
        [<ffffffff8153d190>] kmemleak_alloc+0x21/0x3e
        [<ffffffff810ab3e7>] kmem_cache_alloc+0xb5/0xc5
        [<ffffffff8149b65b>] sk_prot_alloc.isra.53+0x2b/0xcd
        [<ffffffff8149b784>] sk_clone_lock+0x16/0x21e
        [<ffffffff814d711a>] inet_csk_clone_lock+0x10/0x7b
        [<ffffffff814ebbc3>] tcp_create_openreq_child+0x21/0x481
        [<ffffffff814e8fa5>] tcp_v4_syn_recv_sock+0x3a/0x23b
        [<ffffffff814ec5ba>] tcp_check_req+0x29f/0x416
        [<ffffffff814e8e10>] tcp_v4_do_rcv+0x161/0x2bc
        [<ffffffff814eb917>] tcp_v4_rcv+0x6c9/0x701
        [<ffffffff814cea9f>] ip_local_deliver_finish+0x70/0xc4
        [<ffffffff814cec20>] ip_local_deliver+0x4e/0x7f
        [<ffffffff814ce9f8>] ip_rcv_finish+0x1fc/0x233
        [<ffffffff814cee68>] ip_rcv+0x217/0x267
        [<ffffffff814a7bbe>] __netif_receive_skb+0x49e/0x553
        [<ffffffff814a7cc3>] netif_receive_skb+0x50/0x82
    
    This happens, because sk_clone_lock initializes sk_refcnt to 2, and thus
    a single sock_put() is not enough to free the memory. Additionally, things
    like xfrm, memcg, cookie_values,... may have been initialized.
    We have to free them properly.
    
    This is fixed by forcing a call to tcp_done(), ending up in
    inet_csk_destroy_sock, doing the final sock_put(). tcp_done() is necessary,
    because it ends up doing all the cleanup on xfrm, memcg, cookie_values,
    xfrm,...
    
    Before calling tcp_done, we have to set the socket to SOCK_DEAD, to
    force it entering inet_csk_destroy_sock. To avoid the warning in
    inet_csk_destroy_sock, inet_num has to be set to 0.
    As inet_csk_destroy_sock does a dec on orphan_count, we first have to
    increase it.
    
    Calling tcp_done() allows us to remove the calls to
    tcp_clear_xmit_timer() and tcp_cleanup_congestion_control().
    
    A similar approach is taken for dccp by calling dccp_done().
    
    This is in the kernel since 093d282321 (tproxy: fix hash locking issue
    when using port redirection in __inet_inherit_port()), thus since
    version >= 2.6.37.
    
    Signed-off-by: Christoph Paasch <christoph.paasch@uclouvain.be>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index ba1d3615acbb..183292722f6e 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -318,6 +318,7 @@ extern void inet_csk_reqsk_queue_prune(struct sock *parent,
 				       const unsigned long max_rto);
 
 extern void inet_csk_destroy_sock(struct sock *sk);
+extern void inet_csk_prepare_forced_close(struct sock *sk);
 
 /*
  * LISTEN is a special case for poll..

commit 5d299f3d3c8a2fbc732b1bf03af36333ccec3130
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Aug 6 05:09:33 2012 +0000

    net: ipv6: fix TCP early demux
    
    IPv6 needs a cookie in dst_check() call.
    
    We need to add rx_dst_cookie and provide a family independent
    sk_rx_dst_set(sk, skb) method to properly support IPv6 TCP early demux.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 5ee66f517b4f..ba1d3615acbb 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -39,6 +39,7 @@ struct inet_connection_sock_af_ops {
 	int	    (*queue_xmit)(struct sk_buff *skb, struct flowi *fl);
 	void	    (*send_check)(struct sock *sk, struct sk_buff *skb);
 	int	    (*rebuild_header)(struct sock *sk);
+	void	    (*sk_rx_dst_set)(struct sock *sk, const struct sk_buff *skb);
 	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);
 	struct sock *(*syn_recv_sock)(struct sock *sk, struct sk_buff *skb,
 				      struct request_sock *req,

commit ba3f7f04ef2b19aace38f855aedd17fe43035d50
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jul 17 14:02:46 2012 -0700

    ipv4: Kill FLOWI_FLAG_RT_NOCACHE and associated code.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 2cf44b4ed2e6..5ee66f517b4f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -250,8 +250,7 @@ extern int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,
 					    struct flowi4 *fl4,
-					    const struct request_sock *req,
-					    bool nocache);
+					    const struct request_sock *req);
 extern struct dst_entry* inet_csk_route_child_sock(struct sock *sk,
 						   struct sock *newsk,
 						   const struct request_sock *req);

commit 80d0a69fc57715dc9080c0567df1ed911b78abea
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 16 03:28:06 2012 -0700

    ipv4: Add helper inet_csk_update_pmtu().
    
    This abstracts away the call to dst_ops->update_pmtu() so that we can
    transparently handle the fact that, in the future, the dst itself can
    be invalidated by the PMTU update (when we have non-host routes cached
    in sockets).
    
    So we try to rebuild the socket cached route after the method
    invocation if necessary.
    
    This isn't used by SCTP because it needs to cache dsts per-transport,
    and thus will need it's own local version of this helper.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 291e7cee14e7..2cf44b4ed2e6 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -337,4 +337,6 @@ extern int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,
 				      char __user *optval, int __user *optlen);
 extern int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
 				      char __user *optval, unsigned int optlen);
+
+extern struct dst_entry *inet_csk_update_pmtu(struct sock *sk, u32 mtu);
 #endif /* _INET_CONNECTION_SOCK_H */

commit 16d1839907e695387654901995f9286b65fbbc6a
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jul 10 03:32:59 2012 -0700

    inet: Remove ->get_peer() method.
    
    No longer used.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index af3c743a40e4..291e7cee14e7 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -43,7 +43,6 @@ struct inet_connection_sock_af_ops {
 	struct sock *(*syn_recv_sock)(struct sock *sk, struct sk_buff *skb,
 				      struct request_sock *req,
 				      struct dst_entry *dst);
-	struct inet_peer *(*get_peer)(struct sock *sk);
 	u16	    net_header_len;
 	u16	    net_frag_header_len;
 	u16	    sockaddr_len;

commit 7586eceb0abc0ea1c2b023e3e5d4dfd4ff40930a
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 20 05:02:19 2012 +0000

    ipv4: tcp: dont cache output dst for syncookies
    
    Don't cache output dst for syncookies, as this adds pressure on IP route
    cache and rcu subsystem for no gain.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Hans Schillstrom <hans.schillstrom@ericsson.com>
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index e1b7734c456f..af3c743a40e4 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -251,7 +251,8 @@ extern int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,
 					    struct flowi4 *fl4,
-					    const struct request_sock *req);
+					    const struct request_sock *req,
+					    bool nocache);
 extern struct dst_entry* inet_csk_route_child_sock(struct sock *sk,
 						   struct sock *newsk,
 						   const struct request_sock *req);

commit 4670fd819e7f47392c7c6fc6168ea2857c66d163
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Jun 9 01:25:47 2012 -0700

    tcp: Get rid of inetpeer special cases.
    
    The get_peer method TCP uses is full of special cases that make no
    sense accommodating, and it also gets in the way of doing more
    reasonable things here.
    
    First of all, if the socket doesn't have a usable cached route, there
    is no sense in trying to optimize timewait recycling.
    
    Likewise for the case where we have IP options, such as SRR enabled,
    that make the IP header destination address (and thus the destination
    address of the route key) differ from that of the connection's
    destination address.
    
    Just return a NULL peer in these cases, and thus we're also able to
    get rid of the clumsy inetpeer release logic.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 7d83f90f203f..e1b7734c456f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -43,7 +43,7 @@ struct inet_connection_sock_af_ops {
 	struct sock *(*syn_recv_sock)(struct sock *sk, struct sk_buff *skb,
 				      struct request_sock *req,
 				      struct dst_entry *dst);
-	struct inet_peer *(*get_peer)(struct sock *sk, bool *release_it);
+	struct inet_peer *(*get_peer)(struct sock *sk);
 	u16	    net_header_len;
 	u16	    net_frag_header_len;
 	u16	    sockaddr_len;

commit 67469601406c12ced3db9956aeb0ef0854e2952f
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Apr 24 07:37:38 2012 +0000

    ipv6: RTAX_FEATURE_ALLFRAG causes inefficient TCP segment sizing
    
    Quoting Tore Anderson from :
    https://bugzilla.kernel.org/show_bug.cgi?id=42572
    
    When RTAX_FEATURE_ALLFRAG is set on a route, the effective TCP segment
    size does not take into account the size of the IPv6 Fragmentation
    header that needs to be included in outbound packets, causing every
    transmitted TCP segment to be fragmented across two IPv6 packets, the
    latter of which will only contain 8 bytes of actual payload.
    
    RTAX_FEATURE_ALLFRAG is typically set on a route in response to
    receving a ICMPv6 Packet Too Big message indicating a Path MTU of less
    than 1280 bytes. 1280 bytes is the minimum IPv6 MTU, however ICMPv6
    PTBs with MTU < 1280 are still valid, in particular when an IPv6
    packet is sent to an IPv4 destination through a stateless translator.
    Any ICMPv4 Need To Fragment packets originated from the IPv4 part of
    the path will be translated to ICMPv6 PTB which may then indicate an
    MTU of less than 1280.
    
    The Linux kernel refuses to reduce the effective MTU to anything below
    1280 bytes, instead it sets it to exactly 1280 bytes, and
    RTAX_FEATURE_ALLFRAG is also set. However, the TCP segment size appears
    to be set to 1240 bytes (1280 Path MTU - 40 bytes of IPv6 header),
    instead of 1232 (additionally taking into account the 8 bytes required
    by the IPv6 Fragmentation extension header).
    
    This in turn results in rather inefficient transmission, as every
    transmitted TCP segment now is split in two fragments containing
    1232+8 bytes of payload.
    
    After this patch, all the outgoing packets that includes a
    Fragmentation header all are "atomic" or "non-fragmented" fragments,
    i.e., they both have Offset=0 and More Fragments=0.
    
    With help from David S. Miller
    
    Reported-by: Tore Anderson <tore@fud.no>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Maciej Żenczykowski <maze@google.com>
    Cc: Tom Herbert <therbert@google.com>
    Tested-by: Tore Anderson <tore@fud.no>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 46c9e2ccdf02..7d83f90f203f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -45,6 +45,7 @@ struct inet_connection_sock_af_ops {
 				      struct dst_entry *dst);
 	struct inet_peer *(*get_peer)(struct sock *sk, bool *release_it);
 	u16	    net_header_len;
+	u16	    net_frag_header_len;
 	u16	    sockaddr_len;
 	int	    (*setsockopt)(struct sock *sk, int level, int optname, 
 				  char __user *optval, unsigned int optlen);

commit aacd9289af8b82f5fb01bcdd53d0e3406d1333c7
Author: Alex Copot <alex.mihai.c@gmail.com>
Date:   Thu Apr 12 22:21:45 2012 +0000

    tcp: bind() use stronger condition for bind_conflict
    
    We must try harder to get unique (addr, port) pairs when
    doing port autoselection for sockets with SO_REUSEADDR
    option set.
    
    We achieve this by adding a relaxation parameter to
    inet_csk_bind_conflict. When 'relax' parameter is off
    we return a conflict whenever the current searched
    pair (addr, port) is not unique.
    
    This tries to address the problems reported in patch:
            8d238b25b1ec22a73b1c2206f111df2faaff8285
            Revert "tcp: bind() fix when many ports are bound"
    
    Tests where ran for creating and binding(0) many sockets
    on 100 IPs. The results are, on average:
    
            * 60000 sockets, 600 ports / IP:
                    * 0.210 s, 620 (IP, port) duplicates without patch
                    * 0.219 s, no duplicates with patch
            * 100000 sockets, 1000 ports / IP:
                    * 0.371 s, 1720 duplicates without patch
                    * 0.373 s, no duplicates with patch
            * 200000 sockets, 2000 ports / IP:
                    * 0.766 s, 6900 duplicates without patch
                    * 0.768 s, no duplicates with patch
            * 500000 sockets, 5000 ports / IP:
                    * 2.227 s, 41500 duplicates without patch
                    * 2.284 s, no duplicates with patch
    
    Signed-off-by: Alex Copot <alex.mihai.c@gmail.com>
    Signed-off-by: Daniel Baluta <dbaluta@ixiacom.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index dbf9aab34c82..46c9e2ccdf02 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -60,7 +60,7 @@ struct inet_connection_sock_af_ops {
 #endif
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
 	int	    (*bind_conflict)(const struct sock *sk,
-				     const struct inet_bind_bucket *tb);
+				     const struct inet_bind_bucket *tb, bool relax);
 };
 
 /** inet_connection_sock - INET connection oriented sock
@@ -245,7 +245,7 @@ extern struct request_sock *inet_csk_search_req(const struct sock *sk,
 						const __be32 raddr,
 						const __be32 laddr);
 extern int inet_csk_bind_conflict(const struct sock *sk,
-				  const struct inet_bind_bucket *tb);
+				  const struct inet_bind_bucket *tb, bool relax);
 extern int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,

commit e56c57d0d3fdbbdf583d3af96bfb803b8dfa713e
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Nov 8 17:07:07 2011 -0500

    net: rename sk_clone to sk_clone_lock
    
    Make clear that sk_clone() and inet_csk_clone() return a locked socket.
    
    Add _lock() prefix and kerneldoc.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index e6db62e756dc..dbf9aab34c82 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -143,9 +143,9 @@ static inline void *inet_csk_ca(const struct sock *sk)
 	return (void *)inet_csk(sk)->icsk_ca_priv;
 }
 
-extern struct sock *inet_csk_clone(struct sock *sk,
-				   const struct request_sock *req,
-				   const gfp_t priority);
+extern struct sock *inet_csk_clone_lock(const struct sock *sk,
+					const struct request_sock *req,
+					const gfp_t priority);
 
 enum inet_csk_ack_state_t {
 	ICSK_ACK_SCHED	= 1,

commit 6bd023f3dddfc7c5f660089598c10e1f4167083b
Author: David S. Miller <davem@davemloft.net>
Date:   Wed May 18 18:32:03 2011 -0400

    ipv4: Make caller provide flowi4 key to inet_csk_route_req().
    
    This way the caller can get at the fully resolved fl4->{daddr,saddr}
    etc.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 96546cae1cba..e6db62e756dc 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -249,6 +249,7 @@ extern int inet_csk_bind_conflict(const struct sock *sk,
 extern int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,
+					    struct flowi4 *fl4,
 					    const struct request_sock *req);
 extern struct dst_entry* inet_csk_route_child_sock(struct sock *sk,
 						   struct sock *newsk,

commit d9d8da805dcb503ef8ee49918a94d49085060f23
Author: David S. Miller <davem@davemloft.net>
Date:   Fri May 6 22:23:20 2011 -0700

    inet: Pass flowi to ->queue_xmit().
    
    This allows us to acquire the exact route keying information from the
    protocol, however that might be managed.
    
    It handles all of the possibilities, from the simplest case of storing
    the key in inet->cork.fl to the more complex setup SCTP has where
    individual transports determine the flow.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 4367d913c0e2..96546cae1cba 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -36,7 +36,7 @@ struct tcp_congestion_ops;
  * (i.e. things that depend on the address family)
  */
 struct inet_connection_sock_af_ops {
-	int	    (*queue_xmit)(struct sk_buff *skb);
+	int	    (*queue_xmit)(struct sk_buff *skb, struct flowi *fl);
 	void	    (*send_check)(struct sock *sk, struct sk_buff *skb);
 	int	    (*rebuild_header)(struct sock *sk);
 	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);

commit 77357a95522ba645bbfd65253b34317c824103f9
Author: David S. Miller <davem@davemloft.net>
Date:   Sun May 8 14:34:22 2011 -0700

    ipv4: Create inet_csk_route_child_sock().
    
    This is just like inet_csk_route_req() except that it operates after
    we've created the new child socket.
    
    In this way we can use the new socket's cork flow for proper route
    key storage.
    
    This will be used by DCCP and TCP child socket creation handling.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 6ac4e3b5007f..4367d913c0e2 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -250,6 +250,9 @@ extern int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,
 					    const struct request_sock *req);
+extern struct dst_entry* inet_csk_route_child_sock(struct sock *sk,
+						   struct sock *newsk,
+						   const struct request_sock *req);
 
 static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 					    struct request_sock *req,

commit 4c306a9291a077879fc3e933326caac3bc319caa
Author: Shan Wei <shanwei@cn.fujitsu.com>
Date:   Sun Dec 19 21:59:35 2010 -0800

    net: kill unused macros
    
    These macros never be used, so remove them.
    
    Signed-off-by: Shan Wei <shanwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 6c93a56cc958..6ac4e3b5007f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -132,7 +132,6 @@ struct inet_connection_sock {
 #define ICSK_TIME_RETRANS	1	/* Retransmit timer */
 #define ICSK_TIME_DACK		2	/* Delayed ack timer */
 #define ICSK_TIME_PROBE0	3	/* Zero window probe timer */
-#define ICSK_TIME_KEEPOPEN	4	/* Keepalive timer */
 
 static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
 {

commit 3f419d2d487821093ee46e898b5f8747f9edc9cd
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Nov 29 13:37:14 2010 -0800

    inet: Turn ->remember_stamp into ->get_peer in connection AF ops.
    
    Then we can make a completely generic tcp_remember_stamp()
    that uses ->get_peer() as a helper, minimizing the AF specific
    code and minimizing the eventual code duplication when we implement
    the ipv6 side of TW recycling.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index e4f494b42e06..6c93a56cc958 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -43,7 +43,7 @@ struct inet_connection_sock_af_ops {
 	struct sock *(*syn_recv_sock)(struct sock *sk, struct sk_buff *skb,
 				      struct request_sock *req,
 				      struct dst_entry *dst);
-	int	    (*remember_stamp)(struct sock *sk);
+	struct inet_peer *(*get_peer)(struct sock *sk, bool *release_it);
 	u16	    net_header_len;
 	u16	    sockaddr_len;
 	int	    (*setsockopt)(struct sock *sk, int level, int optname, 

commit dca43c75e7e545694a9dd6288553f55c53e2a3a3
Author: Jerry Chu <hkchu@google.com>
Date:   Fri Aug 27 19:13:28 2010 +0000

    tcp: Add TCP_USER_TIMEOUT socket option.
    
    This patch provides a "user timeout" support as described in RFC793. The
    socket option is also needed for the the local half of RFC5482 "TCP User
    Timeout Option".
    
    TCP_USER_TIMEOUT is a TCP level socket option that takes an unsigned int,
    when > 0, to specify the maximum amount of time in ms that transmitted
    data may remain unacknowledged before TCP will forcefully close the
    corresponding connection and return ETIMEDOUT to the application. If
    0 is given, TCP will continue to use the system default.
    
    Increasing the user timeouts allows a TCP connection to survive extended
    periods without end-to-end connectivity. Decreasing the user timeouts
    allows applications to "fail fast" if so desired. Otherwise it may take
    upto 20 minutes with the current system defaults in a normal WAN
    environment.
    
    The socket option can be made during any state of a TCP connection, but
    is only effective during the synchronized states of a connection
    (ESTABLISHED, FIN-WAIT-1, FIN-WAIT-2, CLOSE-WAIT, CLOSING, or LAST-ACK).
    Moreover, when used with the TCP keepalive (SO_KEEPALIVE) option,
    TCP_USER_TIMEOUT will overtake keepalive to determine when to close a
    connection due to keepalive failure.
    
    The option does not change in anyway when TCP retransmits a packet, nor
    when a keepalive probe will be sent.
    
    This option, like many others, will be inherited by an acceptor from its
    listener.
    
    Signed-off-by: H.K. Jerry Chu <hkchu@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index b6d3b55da19b..e4f494b42e06 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -125,6 +125,7 @@ struct inet_connection_sock {
 		int		  probe_size;
 	} icsk_mtup;
 	u32			  icsk_ca_priv[16];
+	u32			  icsk_user_timeout;
 #define ICSK_CA_PRIV_SIZE	(16 * sizeof(u32))
 };
 

commit 4e15ed4d930297c127d280ca1d0c785be870def4
Author: Shan Wei <shanwei@cn.fujitsu.com>
Date:   Thu Apr 15 16:43:08 2010 +0000

    net: replace ipfragok with skb->local_df
    
    As Herbert Xu said: we should be able to simply replace ipfragok
    with skb->local_df. commit f88037(sctp: Drop ipfargok in sctp_xmit function)
    has droped ipfragok and set local_df value properly.
    
    The patch kills the ipfragok parameter of .queue_xmit().
    
    Signed-off-by: Shan Wei <shanwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 52c8b8b8a0b9..b6d3b55da19b 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -36,7 +36,7 @@ struct tcp_congestion_ops;
  * (i.e. things that depend on the address family)
  */
 struct inet_connection_sock_af_ops {
-	int	    (*queue_xmit)(struct sk_buff *skb, int ipfragok);
+	int	    (*queue_xmit)(struct sk_buff *skb);
 	void	    (*send_check)(struct sock *sk, struct sk_buff *skb);
 	int	    (*rebuild_header)(struct sock *sk);
 	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);

commit bb29624614c2afe2873ee8ee97cf09df42701694
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Apr 11 02:15:55 2010 +0000

    inet: Remove unused send_check length argument
    
    inet: Remove unused send_check length argument
    
    This patch removes the unused length argument from the send_check
    function in struct inet_connection_sock_af_ops.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Tested-by: Yinghai <yinghai.lu@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 696d6e4ce68a..52c8b8b8a0b9 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -37,8 +37,7 @@ struct tcp_congestion_ops;
  */
 struct inet_connection_sock_af_ops {
 	int	    (*queue_xmit)(struct sk_buff *skb, int ipfragok);
-	void	    (*send_check)(struct sock *sk, int len,
-				  struct sk_buff *skb);
+	void	    (*send_check)(struct sock *sk, struct sk_buff *skb);
 	int	    (*rebuild_header)(struct sock *sk);
 	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);
 	struct sock *(*syn_recv_sock)(struct sock *sk, struct sk_buff *skb,

commit b7058842c940ad2c08dd829b21e5c92ebe3b8758
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 30 16:12:20 2009 -0700

    net: Make setsockopt() optlen be unsigned.
    
    This provides safety against negative optlen at the type
    level instead of depending upon (sometimes non-trivial)
    checks against this sprinkled all over the the place, in
    each and every implementation.
    
    Based upon work done by Arjan van de Ven and feedback
    from Linus Torvalds.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 03cffd9f64e3..696d6e4ce68a 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -48,13 +48,13 @@ struct inet_connection_sock_af_ops {
 	u16	    net_header_len;
 	u16	    sockaddr_len;
 	int	    (*setsockopt)(struct sock *sk, int level, int optname, 
-				  char __user *optval, int optlen);
+				  char __user *optval, unsigned int optlen);
 	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
 				  char __user *optval, int __user *optlen);
 #ifdef CONFIG_COMPAT
 	int	    (*compat_setsockopt)(struct sock *sk,
 				int level, int optname,
-				char __user *optval, int optlen);
+				char __user *optval, unsigned int optlen);
 	int	    (*compat_getsockopt)(struct sock *sk,
 				int level, int optname,
 				char __user *optval, int __user *optlen);
@@ -332,5 +332,5 @@ extern void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);
 extern int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,
 				      char __user *optval, int __user *optlen);
 extern int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
-				      char __user *optval, int optlen);
+				      char __user *optval, unsigned int optlen);
 #endif /* _INET_CONNECTION_SOCK_H */

commit af01d537463714e36e2c96d2da35902b76cd6827
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Thu Aug 28 02:53:51 2008 -0700

    net: more #ifdef CONFIG_COMPAT
    
    All users of struct proto::compat_[gs]etsockopt and
    struct inet_connection_sock_af_ops::compat_[gs]etsockopt are under
    #ifdef already, so use it in structure definition too.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 2ff545a56fb5..03cffd9f64e3 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -51,12 +51,14 @@ struct inet_connection_sock_af_ops {
 				  char __user *optval, int optlen);
 	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
 				  char __user *optval, int __user *optlen);
+#ifdef CONFIG_COMPAT
 	int	    (*compat_setsockopt)(struct sock *sk,
 				int level, int optname,
 				char __user *optval, int optlen);
 	int	    (*compat_getsockopt)(struct sock *sk,
 				int level, int optname,
 				char __user *optval, int __user *optlen);
+#endif
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
 	int	    (*bind_conflict)(const struct sock *sk,
 				     const struct inet_bind_bucket *tb);

commit 3d58b5fa8e4c461ab09afdacd3d1754fccca06ad
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Apr 3 14:22:32 2008 -0700

    [INET]: Rename inet_csk_ctl_sock_create to inet_ctl_sock_create.
    
    This call is nothing common with INET connection sockets code. It
    simply creates an unhashes kernel sockets for protocol messages.
    
    Move the new call into af_inet.c after the rename.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index f00f0573627b..2ff545a56fb5 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -327,11 +327,6 @@ extern void inet_csk_listen_stop(struct sock *sk);
 
 extern void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);
 
-extern int inet_csk_ctl_sock_create(struct socket **sock,
-				    unsigned short family,
-				    unsigned short type,
-				    unsigned char protocol);
-
 extern int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,
 				      char __user *optval, int __user *optlen);
 extern int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,

commit ab1e0a13d70299e792fd0527cefd070c1405fa5b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Feb 3 04:06:04 2008 -0800

    [SOCK] proto: Add hashinfo member to struct proto
    
    This way we can remove TCP and DCCP specific versions of
    
    sk->sk_prot->get_port: both v4 and v6 use inet_csk_get_port
    sk->sk_prot->hash:     inet_hash is directly used, only v6 need
                           a specific version to deal with mapped sockets
    sk->sk_prot->unhash:   both v4 and v6 use inet_hash directly
    
    struct inet_connection_sock_af_ops also gets a new member, bind_conflict, so
    that inet_csk_get_port can find the per family routine.
    
    Now only the lookup routines receive as a parameter a struct inet_hashtable.
    
    With this we further reuse code, reducing the difference among INET transport
    protocols.
    
    Eventually work has to be done on UDP and SCTP to make them share this
    infrastructure and get as a bonus inet_diag interfaces so that iproute can be
    used with these protocols.
    
    net-2.6/net/ipv4/inet_hashtables.c:
      struct proto                       |   +8
      struct inet_connection_sock_af_ops |   +8
     2 structs changed
      __inet_hash_nolisten               |  +18
      __inet_hash                        | -210
      inet_put_port                      |   +8
      inet_bind_bucket_create            |   +1
      __inet_hash_connect                |   -8
     5 functions changed, 27 bytes added, 218 bytes removed, diff: -191
    
    net-2.6/net/core/sock.c:
      proto_seq_show                     |   +3
     1 function changed, 3 bytes added, diff: +3
    
    net-2.6/net/ipv4/inet_connection_sock.c:
      inet_csk_get_port                  |  +15
     1 function changed, 15 bytes added, diff: +15
    
    net-2.6/net/ipv4/tcp.c:
      tcp_set_state                      |   -7
     1 function changed, 7 bytes removed, diff: -7
    
    net-2.6/net/ipv4/tcp_ipv4.c:
      tcp_v4_get_port                    |  -31
      tcp_v4_hash                        |  -48
      tcp_v4_destroy_sock                |   -7
      tcp_v4_syn_recv_sock               |   -2
      tcp_unhash                         | -179
     5 functions changed, 267 bytes removed, diff: -267
    
    net-2.6/net/ipv6/inet6_hashtables.c:
      __inet6_hash |   +8
     1 function changed, 8 bytes added, diff: +8
    
    net-2.6/net/ipv4/inet_hashtables.c:
      inet_unhash                        | +190
      inet_hash                          | +242
     2 functions changed, 432 bytes added, diff: +432
    
    vmlinux:
     16 functions changed, 485 bytes added, 492 bytes removed, diff: -7
    
    /home/acme/git/net-2.6/net/ipv6/tcp_ipv6.c:
      tcp_v6_get_port                    |  -31
      tcp_v6_hash                        |   -7
      tcp_v6_syn_recv_sock               |   -9
     3 functions changed, 47 bytes removed, diff: -47
    
    /home/acme/git/net-2.6/net/dccp/proto.c:
      dccp_destroy_sock                  |   -7
      dccp_unhash                        | -179
      dccp_hash                          |  -49
      dccp_set_state                     |   -7
      dccp_done                          |   +1
     5 functions changed, 1 bytes added, 242 bytes removed, diff: -241
    
    /home/acme/git/net-2.6/net/dccp/ipv4.c:
      dccp_v4_get_port                   |  -31
      dccp_v4_request_recv_sock          |   -2
     2 functions changed, 33 bytes removed, diff: -33
    
    /home/acme/git/net-2.6/net/dccp/ipv6.c:
      dccp_v6_get_port                   |  -31
      dccp_v6_hash                       |   -7
      dccp_v6_request_recv_sock          |   +5
     3 functions changed, 5 bytes added, 38 bytes removed, diff: -33
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 133cf30d2d79..f00f0573627b 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -29,7 +29,6 @@
 #undef INET_CSK_CLEAR_TIMERS
 
 struct inet_bind_bucket;
-struct inet_hashinfo;
 struct tcp_congestion_ops;
 
 /*
@@ -59,6 +58,8 @@ struct inet_connection_sock_af_ops {
 				int level, int optname,
 				char __user *optval, int __user *optlen);
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
+	int	    (*bind_conflict)(const struct sock *sk,
+				     const struct inet_bind_bucket *tb);
 };
 
 /** inet_connection_sock - INET connection oriented sock
@@ -244,10 +245,7 @@ extern struct request_sock *inet_csk_search_req(const struct sock *sk,
 						const __be32 laddr);
 extern int inet_csk_bind_conflict(const struct sock *sk,
 				  const struct inet_bind_bucket *tb);
-extern int inet_csk_get_port(struct inet_hashinfo *hashinfo,
-			     struct sock *sk, unsigned short snum,
-			     int (*bind_conflict)(const struct sock *sk,
-						  const struct inet_bind_bucket *tb));
+extern int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,
 					    const struct request_sock *req);

commit e89862f4c5b3c4ac9afcd8cb1365d2f1e16ddc3b
Author: David S. Miller <davem@sunset.davemloft.net>
Date:   Fri Jan 26 01:04:55 2007 -0800

    [TCP]: Restore SKB socket owner setting in tcp_transmit_skb().
    
    Revert 931731123a103cfb3f70ac4b7abfc71d94ba1f03
    
    We can't elide the skb_set_owner_w() here because things like certain
    netfilter targets (such as owner MATCH) need a socket to be set on the
    SKB for correct operation.
    
    Thanks to Jan Engelhardt and other netfilter list members for
    pointing this out.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index bf16d98d372c..133cf30d2d79 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -37,8 +37,7 @@ struct tcp_congestion_ops;
  * (i.e. things that depend on the address family)
  */
 struct inet_connection_sock_af_ops {
-	int	    (*queue_xmit)(struct sk_buff *skb, struct sock *sk,
-				  int ipfragok);
+	int	    (*queue_xmit)(struct sk_buff *skb, int ipfragok);
 	void	    (*send_check)(struct sock *sk, int len,
 				  struct sk_buff *skb);
 	int	    (*rebuild_header)(struct sock *sk);

commit bd01f843c3368dcee735c19603251669f23f4477
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Oct 19 17:23:57 2006 -0400

    [PATCH] severing skbuff.h -> poll.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index cccea051e922..bf16d98d372c 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -18,6 +18,7 @@
 #include <linux/compiler.h>
 #include <linux/string.h>
 #include <linux/timer.h>
+#include <linux/poll.h>
 
 #include <net/inet_sock.h>
 #include <net/request_sock.h>

commit 850db6b8c53ff12eadee9ef2aa69360c06bce057
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Nov 27 17:56:43 2006 -0200

    [INET_CONNECTION_SOCK]: Pack struct inet_connection_sock_af_ops
    
    We have a hole in:
    
    [acme@newtoy net-2.6.20]$ pahole net/ipv6/tcp_ipv6.o inet_connection_sock_af_ops
    /* /pub/scm/linux/kernel/git/acme/net-2.6.20/include/net/inet_connection_sock.h:38 */
    struct inet_connection_sock_af_ops {
            int                        (*queue_xmit)();      /*     0     4 */
            void                       (*send_check)();      /*     4     4 */
            int                        (*rebuild_header)();  /*     8     4 */
            int                        (*conn_request)();    /*    12     4 */
            struct sock *              (*syn_recv_sock)();   /*    16     4 */
            int                        (*remember_stamp)();  /*    20     4 */
            __u16                      net_header_len;       /*    24     2 */
    
            /* XXX 2 bytes hole, try to pack */
    
            int                        (*setsockopt)();      /*    28     4 */
            int                        (*getsockopt)();      /*    32     4 */
            int                        (*compat_setsockopt)(); /*    36     4 */
            int                        (*compat_getsockopt)(); /*    40     4 */
            void                       (*addr2sockaddr)();   /*    44     4 */
            int                        sockaddr_len;         /*    48     4 */
    }; /* size: 52, sum members: 50, holes: 1, sum holes: 2 */
    
    But we don't need sockaddr_len to be an int:
    
    [acme@newtoy net-2.6.20]$ find net -name "*.[ch]" | xargs grep '\.sockaddr_len.\+=' | sort -u
    net/dccp/ipv4.c:        .sockaddr_len      = sizeof(struct sockaddr_in),
    net/dccp/ipv6.c:        .sockaddr_len      = sizeof(struct sockaddr_in6),
    net/ipv4/tcp_ipv4.c:    .sockaddr_len      = sizeof(struct sockaddr_in),
    net/ipv6/tcp_ipv6.c:    .sockaddr_len      = sizeof(struct sockaddr_in6),
    net/sctp/ipv6.c:        .sockaddr_len      = sizeof(struct sockaddr_in6),
    net/sctp/protocol.c:    .sockaddr_len      = sizeof(struct sockaddr_in),
    
    [acme@newtoy net-2.6.20]$ pahole --sizes net/ipv6/tcp_ipv6.o | grep sockaddr_in
    struct sockaddr_in: 16 0
    struct sockaddr_in6: 28 0
    [acme@newtoy net-2.6.20]$
    
    So I turned sockaddr_len a 'u16', and now:
    
    [acme@newtoy net-2.6.20]$ pahole net/ipv6/tcp_ipv6.o inet_connection_sock_af_ops
    /* /pub/scm/linux/kernel/git/acme/net-2.6.20/include/net/inet_connection_sock.h:38 */
    struct inet_connection_sock_af_ops {
            int            (*queue_xmit)();        /*     0   4 */
            void           (*send_check)();        /*     4   4 */
            int            (*rebuild_header)();    /*     8   4 */
            int            (*conn_request)();      /*    12   4 */
            struct sock *  (*syn_recv_sock)();     /*    16   4 */
            int            (*remember_stamp)();    /*    20   4 */
            u16            net_header_len;         /*    24   2 */
            u16            sockaddr_len;           /*    26   2 */
            int            (*setsockopt)();        /*    28   4 */
            int            (*getsockopt)();        /*    32   4 */
            int            (*compat_setsockopt)(); /*    36   4 */
            int            (*compat_getsockopt)(); /*    40   4 */
            void           (*addr2sockaddr)();     /*    44   4 */
    }; /* size: 48 */
    
    So we've saved 4 bytes:
    
    [acme@newtoy net-2.6.20]$ codiff -sV /tmp/tcp_ipv6.o.before net/ipv6/tcp_ipv6.o
    /pub/scm/linux/kernel/git/acme/net-2.6.20/net/ipv6/tcp_ipv6.c:
      struct inet_connection_sock_af_ops |   -4
        net_header_len;
         from: __u16                 /*    24(0)     2(0) */
         to:   u16                   /*    24(0)     2(0) */
        sockaddr_len;
         from: int                   /*    48(0)     4(0) */
         to:   u16                   /*    26(0)     2(0) */
     1 struct changed
    [acme@newtoy net-2.6.20]$
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index fd3f1d8cdc4a..cccea051e922 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -46,7 +46,8 @@ struct inet_connection_sock_af_ops {
 				      struct request_sock *req,
 				      struct dst_entry *dst);
 	int	    (*remember_stamp)(struct sock *sk);
-	__u16	    net_header_len;
+	u16	    net_header_len;
+	u16	    sockaddr_len;
 	int	    (*setsockopt)(struct sock *sk, int level, int optname, 
 				  char __user *optval, int optlen);
 	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
@@ -58,7 +59,6 @@ struct inet_connection_sock_af_ops {
 				int level, int optname,
 				char __user *optval, int __user *optlen);
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
-	int sockaddr_len;
 };
 
 /** inet_connection_sock - INET connection oriented sock

commit 931731123a103cfb3f70ac4b7abfc71d94ba1f03
Author: David S. Miller <davem@sunset.davemloft.net>
Date:   Thu Nov 9 19:58:25 2006 -0800

    [TCP]: Don't set SKB owner in tcp_transmit_skb().
    
    The data itself is already charged to the SKB, doing
    the skb_set_owner_w() just generates a lot of noise and
    extra atomics we don't really need.
    
    Lmbench improvements on lat_tcp are minimal:
    
    before:
    TCP latency using localhost: 23.2701 microseconds
    TCP latency using localhost: 23.1994 microseconds
    TCP latency using localhost: 23.2257 microseconds
    
    after:
    TCP latency using localhost: 22.8380 microseconds
    TCP latency using localhost: 22.9465 microseconds
    TCP latency using localhost: 22.8462 microseconds
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 0bcf9f237e1f..fd3f1d8cdc4a 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -36,7 +36,8 @@ struct tcp_congestion_ops;
  * (i.e. things that depend on the address family)
  */
 struct inet_connection_sock_af_ops {
-	int	    (*queue_xmit)(struct sk_buff *skb, int ipfragok);
+	int	    (*queue_xmit)(struct sk_buff *skb, struct sock *sk,
+				  int ipfragok);
 	void	    (*send_check)(struct sock *sk, int len,
 				  struct sk_buff *skb);
 	int	    (*rebuild_header)(struct sock *sk);

commit 6b72977bd6c6fefc6497d4f0275079f539eaf0ac
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Sep 27 18:36:59 2006 -0700

    [IPV4]: inet_csk_search_req() annotations
    
    rport argument is net-endian
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 8122bcc83c1d..0bcf9f237e1f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -238,7 +238,7 @@ extern struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
 extern struct request_sock *inet_csk_search_req(const struct sock *sk,
 						struct request_sock ***prevp,
-						const __u16 rport,
+						const __be16 rport,
 						const __be32 raddr,
 						const __be32 laddr);
 extern int inet_csk_bind_conflict(const struct sock *sk,

commit 7f25afbbefb266520a237df0e9b59112704a7a42
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Sep 27 18:27:47 2006 -0700

    [IPV4]: inet_csk_search_req() (partial) annotations
    
    raddr is net-endian
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index de4e83b6da4b..8122bcc83c1d 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -239,8 +239,8 @@ extern struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 extern struct request_sock *inet_csk_search_req(const struct sock *sk,
 						struct request_sock ***prevp,
 						const __u16 rport,
-						const __u32 raddr,
-						const __u32 laddr);
+						const __be32 raddr,
+						const __be32 laddr);
 extern int inet_csk_bind_conflict(const struct sock *sk,
 				  const struct inet_bind_bucket *tb);
 extern int inet_csk_get_port(struct inet_hashinfo *hashinfo,

commit 1ef9696c909060ccdae3ade245ca88692b49285b
Author: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
Date:   Tue Sep 19 12:52:50 2006 -0700

    [TCP]: Send ACKs each 2nd received segment.
    
    It does not affect either mss-sized connections (obviously) or
    connections controlled by Nagle (because there is only one small
    segment in flight).
    
    The idea is to record the fact that a small segment arrives on a
    connection, where one small segment has already been received and
    still not-ACKed. In this case ACK is forced after tcp_recvmsg() drains
    receive buffer.
    
    In other words, it is a "soft" each-2nd-segment ACK, which is enough
    to preserve ACK clock even when ABC is enabled.
    
    Signed-off-by: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 9bf73fe50948..de4e83b6da4b 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -147,7 +147,8 @@ extern struct sock *inet_csk_clone(struct sock *sk,
 enum inet_csk_ack_state_t {
 	ICSK_ACK_SCHED	= 1,
 	ICSK_ACK_TIMER  = 2,
-	ICSK_ACK_PUSHED = 4
+	ICSK_ACK_PUSHED = 4,
+	ICSK_ACK_PUSHED2 = 8
 };
 
 extern void inet_csk_init_xmit_timers(struct sock *sk,

commit dec73ff0293d59076d1fd8f4a264898ecfc457ec
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 22:46:16 2006 -0800

    [ICSK] compat: Introduce inet_csk_compat_[gs]etsockopt
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index ae61331366f0..9bf73fe50948 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -331,4 +331,9 @@ extern int inet_csk_ctl_sock_create(struct socket **sock,
 				    unsigned short family,
 				    unsigned short type,
 				    unsigned char protocol);
+
+extern int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,
+				      char __user *optval, int __user *optlen);
+extern int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
+				      char __user *optval, int optlen);
 #endif /* _INET_CONNECTION_SOCK_H */

commit 3fdadf7d27e3fbcf72930941884387d1f4936f04
Author: Dmitry Mishin <dim@openvz.org>
Date:   Mon Mar 20 22:45:21 2006 -0800

    [NET]: {get|set}sockopt compatibility layer
    
    This patch extends {get|set}sockopt compatibility layer in order to
    move protocol specific parts to their place and avoid huge universal
    net/compat.c file in the future.
    
    Signed-off-by: Dmitry Mishin <dim@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 363a067403ee..ae61331366f0 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -50,6 +50,12 @@ struct inet_connection_sock_af_ops {
 				  char __user *optval, int optlen);
 	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
 				  char __user *optval, int __user *optlen);
+	int	    (*compat_setsockopt)(struct sock *sk,
+				int level, int optname,
+				char __user *optval, int optlen);
+	int	    (*compat_getsockopt)(struct sock *sk,
+				int level, int optname,
+				char __user *optval, int __user *optlen);
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
 	int sockaddr_len;
 };

commit c4d9390941aee136fd35bb38eb1d6de4e3b1487d
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 22:01:03 2006 -0800

    [ICSK]: Introduce inet_csk_ctl_sock_create
    
    Consolidating open coded sequences in tcp and dccp, v4 and v6.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 4e5a9ff99fc3..363a067403ee 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -321,4 +321,8 @@ extern void inet_csk_listen_stop(struct sock *sk);
 
 extern void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);
 
+extern int inet_csk_ctl_sock_create(struct socket **sock,
+				    unsigned short family,
+				    unsigned short type,
+				    unsigned char protocol);
 #endif /* _INET_CONNECTION_SOCK_H */

commit 0e7b13685f9a06949ea3070c97c0f0085a08cd37
Author: John Heffner <jheffner@psc.edu>
Date:   Mon Mar 20 21:32:58 2006 -0800

    [TCP] mtu probing: move tcp-specific data out of inet_connection_sock
    
    This moves some TCP-specific MTU probing state out of
    inet_connection_sock back to tcp_sock.
    
    Signed-off-by: John Heffner <jheffner@psc.edu>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index b3abe33f4e5f..4e5a9ff99fc3 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -114,8 +114,6 @@ struct inet_connection_sock {
 
 		/* Information on the current probe. */
 		int		  probe_size;
-		__u32		  probe_seq_start;
-		__u32		  probe_seq_end;
 	} icsk_mtup;
 	u32			  icsk_ca_priv[16];
 #define ICSK_CA_PRIV_SIZE	(16 * sizeof(u32))

commit 5d424d5a674f782d0659a3b66d951f412901faee
Author: John Heffner <jheffner@psc.edu>
Date:   Mon Mar 20 17:53:41 2006 -0800

    [TCP]: MTU probing
    
    Implementation of packetization layer path mtu discovery for TCP, based on
    the internet-draft currently found at
    <http://www.ietf.org/internet-drafts/draft-ietf-pmtud-method-05.txt>.
    
    Signed-off-by: John Heffner <jheffner@psc.edu>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index fa587c94e9d0..b3abe33f4e5f 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -72,6 +72,7 @@ struct inet_connection_sock_af_ops {
  * @icsk_probes_out:	   unanswered 0 window probes
  * @icsk_ext_hdr_len:	   Network protocol overhead (IP/IPv6 options)
  * @icsk_ack:		   Delayed ACK control data
+ * @icsk_mtup;		   MTU probing control data
  */
 struct inet_connection_sock {
 	/* inet_sock has to be the first member! */
@@ -104,6 +105,18 @@ struct inet_connection_sock {
 		__u16		  last_seg_size; /* Size of last incoming segment	   */
 		__u16		  rcv_mss;	 /* MSS used for delayed ACK decisions	   */ 
 	} icsk_ack;
+	struct {
+		int		  enabled;
+
+		/* Range of MTUs to search */
+		int		  search_high;
+		int		  search_low;
+
+		/* Information on the current probe. */
+		int		  probe_size;
+		__u32		  probe_seq_start;
+		__u32		  probe_seq_end;
+	} icsk_mtup;
 	u32			  icsk_ca_priv[16];
 #define ICSK_CA_PRIV_SIZE	(16 * sizeof(u32))
 };

commit 770cfbcffdf0011ecf3a12435ecb5604c4c97a19
Author: Stephen Hemminger <shemminger@osdl.org>
Date:   Mon Jan 9 15:56:09 2006 -0800

    [INET]: congestion and af_ops can be const
    
    The congestion ops and af_ops in the inet_connection_sock
    can be const.
    
    Signed-off-by: Stephen Hemminger <shemminger@osdl.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 50234fa56a68..fa587c94e9d0 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -83,8 +83,8 @@ struct inet_connection_sock {
  	struct timer_list	  icsk_delack_timer;
 	__u32			  icsk_rto;
 	__u32			  icsk_pmtu_cookie;
-	struct tcp_congestion_ops *icsk_ca_ops;
-	struct inet_connection_sock_af_ops *icsk_af_ops;
+	const struct tcp_congestion_ops *icsk_ca_ops;
+	const struct inet_connection_sock_af_ops *icsk_af_ops;
 	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
 	__u8			  icsk_ca_state;
 	__u8			  icsk_retransmits;

commit 14c850212ed8f8cbb5972ad6b8812e08a0bc901c
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 27 02:43:12 2005 -0200

    [INET_SOCK]: Move struct inet_sock & helper functions to net/inet_sock.h
    
    To help in reducing the number of include dependencies, several files were
    touched as they were getting needed headers indirectly for stuff they use.
    
    Thanks also to Alan Menegotto for pointing out that net/dccp/proto.c had
    linux/dccp.h include twice.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 91888967d3e3..50234fa56a68 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -16,9 +16,10 @@
 #define _INET_CONNECTION_SOCK_H
 
 #include <linux/compiler.h>
-#include <linux/ip.h>
 #include <linux/string.h>
 #include <linux/timer.h>
+
+#include <net/inet_sock.h>
 #include <net/request_sock.h>
 
 #define INET_CSK_DEBUG 1

commit d83d8461f902c672bc1bd8fbc6a94e19f092da97
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:26:10 2005 -0800

    [IP_SOCKGLUE]: Remove most of the tcp specific calls
    
    As DCCP needs to be called in the same spots.
    
    Now we have a member in inet_sock (is_icsk), set at sock creation time from
    struct inet_protosw->flags (if INET_PROTOSW_ICSK is set, like for TCP and
    DCCP) to see if a struct sock instance is a inet_connection_sock for places
    like the ones in ip_sockglue.c (v4 and v6) where we previously were looking if
    sk_type was SOCK_STREAM, that is insufficient because we now use the same code
    for DCCP, that has sk_type SOCK_DCCP.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index e50e2b890c6d..91888967d3e3 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -60,6 +60,7 @@ struct inet_connection_sock_af_ops {
  * @icsk_timeout:	   Timeout
  * @icsk_retransmit_timer: Resend (no ack)
  * @icsk_rto:		   Retransmit timeout
+ * @icsk_pmtu_cookie	   Last pmtu seen by socket
  * @icsk_ca_ops		   Pluggable congestion control hook
  * @icsk_af_ops		   Operations which are AF_INET{4,6} specific
  * @icsk_ca_state:	   Congestion control state
@@ -68,6 +69,7 @@ struct inet_connection_sock_af_ops {
  * @icsk_backoff:	   Backoff
  * @icsk_syn_retries:      Number of allowed SYN (or equivalent) retries
  * @icsk_probes_out:	   unanswered 0 window probes
+ * @icsk_ext_hdr_len:	   Network protocol overhead (IP/IPv6 options)
  * @icsk_ack:		   Delayed ACK control data
  */
 struct inet_connection_sock {
@@ -79,15 +81,17 @@ struct inet_connection_sock {
  	struct timer_list	  icsk_retransmit_timer;
  	struct timer_list	  icsk_delack_timer;
 	__u32			  icsk_rto;
+	__u32			  icsk_pmtu_cookie;
 	struct tcp_congestion_ops *icsk_ca_ops;
 	struct inet_connection_sock_af_ops *icsk_af_ops;
+	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
 	__u8			  icsk_ca_state;
 	__u8			  icsk_retransmits;
 	__u8			  icsk_pending;
 	__u8			  icsk_backoff;
 	__u8			  icsk_syn_retries;
 	__u8			  icsk_probes_out;
-	/* 2 BYTES HOLE, TRY TO PACK! */
+	__u16			  icsk_ext_hdr_len;
 	struct {
 		__u8		  pending;	 /* ACK is pending			   */
 		__u8		  quick;	 /* Scheduled number of quick acks	   */

commit af05dc9394feb193d221bc9d4c6db768facb4b40
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:16:04 2005 -0800

    [ICSK]: Move v4_addr2sockaddr from TCP to icsk
    
    Renaming it to inet_csk_addr2sockaddr.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 9e20d201e951..e50e2b890c6d 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -303,4 +303,6 @@ static inline unsigned int inet_csk_listen_poll(const struct sock *sk)
 extern int  inet_csk_listen_start(struct sock *sk, const int nr_table_entries);
 extern void inet_csk_listen_stop(struct sock *sk);
 
+extern void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);
+
 #endif /* _INET_CONNECTION_SOCK_H */

commit 8292a17a399ffb7c5c8b083db4ad994e090055f7
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:15:52 2005 -0800

    [ICSK]: Rename struct tcp_func to struct inet_connection_sock_af_ops
    
    And move it to struct inet_connection_sock. DCCP will use it in the
    upcoming changesets.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index ccc81a1c550c..9e20d201e951 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -15,6 +15,7 @@
 #ifndef _INET_CONNECTION_SOCK_H
 #define _INET_CONNECTION_SOCK_H
 
+#include <linux/compiler.h>
 #include <linux/ip.h>
 #include <linux/string.h>
 #include <linux/timer.h>
@@ -29,6 +30,29 @@ struct inet_bind_bucket;
 struct inet_hashinfo;
 struct tcp_congestion_ops;
 
+/*
+ * Pointers to address related TCP functions
+ * (i.e. things that depend on the address family)
+ */
+struct inet_connection_sock_af_ops {
+	int	    (*queue_xmit)(struct sk_buff *skb, int ipfragok);
+	void	    (*send_check)(struct sock *sk, int len,
+				  struct sk_buff *skb);
+	int	    (*rebuild_header)(struct sock *sk);
+	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);
+	struct sock *(*syn_recv_sock)(struct sock *sk, struct sk_buff *skb,
+				      struct request_sock *req,
+				      struct dst_entry *dst);
+	int	    (*remember_stamp)(struct sock *sk);
+	__u16	    net_header_len;
+	int	    (*setsockopt)(struct sock *sk, int level, int optname, 
+				  char __user *optval, int optlen);
+	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
+				  char __user *optval, int __user *optlen);
+	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
+	int sockaddr_len;
+};
+
 /** inet_connection_sock - INET connection oriented sock
  *
  * @icsk_accept_queue:	   FIFO of established children 
@@ -37,6 +61,7 @@ struct tcp_congestion_ops;
  * @icsk_retransmit_timer: Resend (no ack)
  * @icsk_rto:		   Retransmit timeout
  * @icsk_ca_ops		   Pluggable congestion control hook
+ * @icsk_af_ops		   Operations which are AF_INET{4,6} specific
  * @icsk_ca_state:	   Congestion control state
  * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
  * @icsk_pending:	   Scheduled timer event
@@ -55,6 +80,7 @@ struct inet_connection_sock {
  	struct timer_list	  icsk_delack_timer;
 	__u32			  icsk_rto;
 	struct tcp_congestion_ops *icsk_ca_ops;
+	struct inet_connection_sock_af_ops *icsk_af_ops;
 	__u8			  icsk_ca_state;
 	__u8			  icsk_retransmits;
 	__u8			  icsk_pending;

commit c2977c2213993bff51911f4117281b31c4612591
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:15:12 2005 -0800

    [ICSK]: make inet_csk_reqsk_queue_hash_add timeout arg unsigned long
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index edc68e858d51..ccc81a1c550c 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -211,7 +211,7 @@ static inline void inet_csk_reqsk_queue_add(struct sock *sk,
 
 extern void inet_csk_reqsk_queue_hash_add(struct sock *sk,
 					  struct request_sock *req,
-					  const unsigned timeout);
+					  unsigned long timeout);
 
 static inline void inet_csk_reqsk_queue_removed(struct sock *sk,
 						struct request_sock *req)

commit 971af18bbfabb7b7c9c548da34a51e30869c08fc
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:14:47 2005 -0800

    [IPV6]: Reuse inet_csk_get_port in tcp_v6_get_port
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index b0c99060b78d..edc68e858d51 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -192,8 +192,12 @@ extern struct request_sock *inet_csk_search_req(const struct sock *sk,
 						const __u16 rport,
 						const __u32 raddr,
 						const __u32 laddr);
+extern int inet_csk_bind_conflict(const struct sock *sk,
+				  const struct inet_bind_bucket *tb);
 extern int inet_csk_get_port(struct inet_hashinfo *hashinfo,
-			     struct sock *sk, unsigned short snum);
+			     struct sock *sk, unsigned short snum,
+			     int (*bind_conflict)(const struct sock *sk,
+						  const struct inet_bind_bucket *tb));
 
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,
 					    const struct request_sock *req);

commit dd0fc66fb33cd610bc1a5db8a5e232d34879b4d7
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Fri Oct 7 07:46:04 2005 +0100

    [PATCH] gfp flags annotations - part 1
    
     - added typedef unsigned int __nocast gfp_t;
    
     - replaced __nocast uses for gfp flags with gfp_t - it gives exactly
       the same warnings as far as sparse is concerned, doesn't change
       generated code (from gcc point of view we replaced unsigned int with
       typedef) and documents what's going on far better.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 651f824c1008..b0c99060b78d 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -94,7 +94,7 @@ static inline void *inet_csk_ca(const struct sock *sk)
 
 extern struct sock *inet_csk_clone(struct sock *sk,
 				   const struct request_sock *req,
-				   const unsigned int __nocast priority);
+				   const gfp_t priority);
 
 enum inet_csk_ack_state_t {
 	ICSK_ACK_SCHED	= 1,

commit d8971fcb702e24d1e22c77fd1772f182ffee87e3
Author: Stephen Hemminger <shemminger@osdl.org>
Date:   Mon Aug 29 22:51:28 2005 -0700

    [INET]: compile errors when DEBUG is defined
    
    Fix build problem found by compiling driver with DEBUG defined that used tcp.h.
    Since pr_debug(arg) expands to printk("<7>" arg) the argument
    needs to be string that can be concatenated.
    
    Signed-off-by: Stephen Hemminger <shemminger@osdl.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 8a87a3a4f107..651f824c1008 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -147,7 +147,7 @@ static inline void inet_csk_clear_xmit_timer(struct sock *sk, const int what)
 	}
 #ifdef INET_CSK_DEBUG
 	else {
-		pr_debug(inet_csk_timer_bug_msg);
+		pr_debug("%s", inet_csk_timer_bug_msg);
 	}
 #endif
 }
@@ -180,7 +180,7 @@ static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
 	}
 #ifdef INET_CSK_DEBUG
 	else {
-		pr_debug(inet_csk_timer_bug_msg);
+		pr_debug("%s", inet_csk_timer_bug_msg);
 	}
 #endif
 }

commit dc40c7bc76054f5e4382835ca2bafb895b993a8a
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Aug 23 21:52:58 2005 -0700

    [ICSK]: Generalise tcp_listen_poll
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 4d7e708c07d1..8a87a3a4f107 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -260,6 +260,16 @@ extern void inet_csk_reqsk_queue_prune(struct sock *parent,
 				       const unsigned long max_rto);
 
 extern void inet_csk_destroy_sock(struct sock *sk);
+
+/*
+ * LISTEN is a special case for poll..
+ */
+static inline unsigned int inet_csk_listen_poll(const struct sock *sk)
+{
+	return !reqsk_queue_empty(&inet_csk(sk)->icsk_accept_queue) ?
+			(POLLIN | POLLRDNORM) : 0;
+}
+
 extern int  inet_csk_listen_start(struct sock *sk, const int nr_table_entries);
 extern void inet_csk_listen_stop(struct sock *sk);
 

commit 6687e988d9aeaccad6774e6a8304f681f3ec0a03
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Wed Aug 10 04:03:31 2005 -0300

    [ICSK]: Move TCP congestion avoidance members to icsk
    
    This changeset basically moves tcp_sk()->{ca_ops,ca_state,etc} to inet_csk(),
    minimal renaming/moving done in this changeset to ease review.
    
    Most of it is just changes of struct tcp_sock * to struct sock * parameters.
    
    With this we move to a state closer to two interesting goals:
    
    1. Generalisation of net/ipv4/tcp_diag.c, becoming inet_diag.c, being used
       for any INET transport protocol that has struct inet_hashinfo and are
       derived from struct inet_connection_sock. Keeps the userspace API, that will
       just not display DCCP sockets, while newer versions of tools can support
       DCCP.
    
    2. INET generic transport pluggable Congestion Avoidance infrastructure, using
       the current TCP CA infrastructure with DCCP.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index bec19d5cff26..4d7e708c07d1 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -27,6 +27,7 @@
 
 struct inet_bind_bucket;
 struct inet_hashinfo;
+struct tcp_congestion_ops;
 
 /** inet_connection_sock - INET connection oriented sock
  *
@@ -35,10 +36,13 @@ struct inet_hashinfo;
  * @icsk_timeout:	   Timeout
  * @icsk_retransmit_timer: Resend (no ack)
  * @icsk_rto:		   Retransmit timeout
+ * @icsk_ca_ops		   Pluggable congestion control hook
+ * @icsk_ca_state:	   Congestion control state
  * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
  * @icsk_pending:	   Scheduled timer event
  * @icsk_backoff:	   Backoff
  * @icsk_syn_retries:      Number of allowed SYN (or equivalent) retries
+ * @icsk_probes_out:	   unanswered 0 window probes
  * @icsk_ack:		   Delayed ACK control data
  */
 struct inet_connection_sock {
@@ -50,10 +54,14 @@ struct inet_connection_sock {
  	struct timer_list	  icsk_retransmit_timer;
  	struct timer_list	  icsk_delack_timer;
 	__u32			  icsk_rto;
+	struct tcp_congestion_ops *icsk_ca_ops;
+	__u8			  icsk_ca_state;
 	__u8			  icsk_retransmits;
 	__u8			  icsk_pending;
 	__u8			  icsk_backoff;
 	__u8			  icsk_syn_retries;
+	__u8			  icsk_probes_out;
+	/* 2 BYTES HOLE, TRY TO PACK! */
 	struct {
 		__u8		  pending;	 /* ACK is pending			   */
 		__u8		  quick;	 /* Scheduled number of quick acks	   */
@@ -65,6 +73,8 @@ struct inet_connection_sock {
 		__u16		  last_seg_size; /* Size of last incoming segment	   */
 		__u16		  rcv_mss;	 /* MSS used for delayed ACK decisions	   */ 
 	} icsk_ack;
+	u32			  icsk_ca_priv[16];
+#define ICSK_CA_PRIV_SIZE	(16 * sizeof(u32))
 };
 
 #define ICSK_TIME_RETRANS	1	/* Retransmit timer */
@@ -77,6 +87,11 @@ static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
 	return (struct inet_connection_sock *)sk;
 }
 
+static inline void *inet_csk_ca(const struct sock *sk)
+{
+	return (void *)inet_csk(sk)->icsk_ca_priv;
+}
+
 extern struct sock *inet_csk_clone(struct sock *sk,
 				   const struct request_sock *req,
 				   const unsigned int __nocast priority);

commit a019d6fe2b9da68ea4ba6cf3c4e86fc1dbf554c3
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:15:09 2005 -0700

    [ICSK]: Move generalised functions from tcp to inet_connection_sock
    
    This also improves reqsk_queue_prune and renames it to
    inet_csk_reqsk_queue_prune, as it deals with both inet_connection_sock
    and inet_request_sock objects, not just with request_sock ones thus
    belonging to inet_request_sock.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 692825fc8135..bec19d5cff26 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -239,6 +239,13 @@ static inline void inet_csk_reqsk_queue_drop(struct sock *sk,
 	reqsk_free(req);
 }
 
+extern void inet_csk_reqsk_queue_prune(struct sock *parent,
+				       const unsigned long interval,
+				       const unsigned long timeout,
+				       const unsigned long max_rto);
+
+extern void inet_csk_destroy_sock(struct sock *sk);
+extern int  inet_csk_listen_start(struct sock *sk, const int nr_table_entries);
 extern void inet_csk_listen_stop(struct sock *sk);
 
 #endif /* _INET_CONNECTION_SOCK_H */

commit 295f7324ff8d9ea58b4d3ec93b1aaa1d80e048a9
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:11:56 2005 -0700

    [ICSK]: Introduce reqsk_queue_prune from code in tcp_synack_timer
    
    With this we're very close to getting all of the current TCP
    refactorings in my dccp-2.6 tree merged, next changeset will export
    some functions needed by the current DCCP code and then dccp-2.6.git
    will be born!
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index a50f4a4b7b4b..692825fc8135 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -239,4 +239,6 @@ static inline void inet_csk_reqsk_queue_drop(struct sock *sk,
 	reqsk_free(req);
 }
 
+extern void inet_csk_listen_stop(struct sock *sk);
+
 #endif /* _INET_CONNECTION_SOCK_H */

commit 9f1d2604c71498579609b1532fedc5a89276bb00
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:11:24 2005 -0700

    [ICSK]: Introduce inet_csk_clone
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index 97e002001c1a..a50f4a4b7b4b 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -77,6 +77,10 @@ static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
 	return (struct inet_connection_sock *)sk;
 }
 
+extern struct sock *inet_csk_clone(struct sock *sk,
+				   const struct request_sock *req,
+				   const unsigned int __nocast priority);
+
 enum inet_csk_ack_state_t {
 	ICSK_ACK_SCHED	= 1,
 	ICSK_ACK_TIMER  = 2,

commit 3f421baa4720b708022f8bcc52a61e5cd6f10bf8
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:11:08 2005 -0700

    [NET]: Just move the inet_connection_sock function from tcp sources
    
    Completing the previous changeset, this also generalises tcp_v4_synq_add,
    renaming it to inet_csk_reqsk_queue_hash_add, already geing used in the
    DCCP tree, which I plan to merge RSN.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
index ef609396e41b..97e002001c1a 100644
--- a/include/net/inet_connection_sock.h
+++ b/include/net/inet_connection_sock.h
@@ -16,9 +16,15 @@
 #define _INET_CONNECTION_SOCK_H
 
 #include <linux/ip.h>
+#include <linux/string.h>
 #include <linux/timer.h>
 #include <net/request_sock.h>
 
+#define INET_CSK_DEBUG 1
+
+/* Cancel timers, when they are not required. */
+#undef INET_CSK_CLEAR_TIMERS
+
 struct inet_bind_bucket;
 struct inet_hashinfo;
 
@@ -61,17 +67,107 @@ struct inet_connection_sock {
 	} icsk_ack;
 };
 
+#define ICSK_TIME_RETRANS	1	/* Retransmit timer */
+#define ICSK_TIME_DACK		2	/* Delayed ack timer */
+#define ICSK_TIME_PROBE0	3	/* Zero window probe timer */
+#define ICSK_TIME_KEEPOPEN	4	/* Keepalive timer */
+
 static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
 {
 	return (struct inet_connection_sock *)sk;
 }
 
+enum inet_csk_ack_state_t {
+	ICSK_ACK_SCHED	= 1,
+	ICSK_ACK_TIMER  = 2,
+	ICSK_ACK_PUSHED = 4
+};
+
 extern void inet_csk_init_xmit_timers(struct sock *sk,
 				      void (*retransmit_handler)(unsigned long),
 				      void (*delack_handler)(unsigned long),
 				      void (*keepalive_handler)(unsigned long));
 extern void inet_csk_clear_xmit_timers(struct sock *sk);
 
+static inline void inet_csk_schedule_ack(struct sock *sk)
+{
+	inet_csk(sk)->icsk_ack.pending |= ICSK_ACK_SCHED;
+}
+
+static inline int inet_csk_ack_scheduled(const struct sock *sk)
+{
+	return inet_csk(sk)->icsk_ack.pending & ICSK_ACK_SCHED;
+}
+
+static inline void inet_csk_delack_init(struct sock *sk)
+{
+	memset(&inet_csk(sk)->icsk_ack, 0, sizeof(inet_csk(sk)->icsk_ack));
+}
+
+extern void inet_csk_delete_keepalive_timer(struct sock *sk);
+extern void inet_csk_reset_keepalive_timer(struct sock *sk, unsigned long timeout);
+
+#ifdef INET_CSK_DEBUG
+extern const char inet_csk_timer_bug_msg[];
+#endif
+
+static inline void inet_csk_clear_xmit_timer(struct sock *sk, const int what)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	
+	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0) {
+		icsk->icsk_pending = 0;
+#ifdef INET_CSK_CLEAR_TIMERS
+		sk_stop_timer(sk, &icsk->icsk_retransmit_timer);
+#endif
+	} else if (what == ICSK_TIME_DACK) {
+		icsk->icsk_ack.blocked = icsk->icsk_ack.pending = 0;
+#ifdef INET_CSK_CLEAR_TIMERS
+		sk_stop_timer(sk, &icsk->icsk_delack_timer);
+#endif
+	}
+#ifdef INET_CSK_DEBUG
+	else {
+		pr_debug(inet_csk_timer_bug_msg);
+	}
+#endif
+}
+
+/*
+ *	Reset the retransmission timer
+ */
+static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
+					     unsigned long when,
+					     const unsigned long max_when)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	if (when > max_when) {
+#ifdef INET_CSK_DEBUG
+		pr_debug("reset_xmit_timer: sk=%p %d when=0x%lx, caller=%p\n",
+			 sk, what, when, current_text_addr());
+#endif
+		when = max_when;
+	}
+
+	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0) {
+		icsk->icsk_pending = what;
+		icsk->icsk_timeout = jiffies + when;
+		sk_reset_timer(sk, &icsk->icsk_retransmit_timer, icsk->icsk_timeout);
+	} else if (what == ICSK_TIME_DACK) {
+		icsk->icsk_ack.pending |= ICSK_ACK_TIMER;
+		icsk->icsk_ack.timeout = jiffies + when;
+		sk_reset_timer(sk, &icsk->icsk_delack_timer, icsk->icsk_ack.timeout);
+	}
+#ifdef INET_CSK_DEBUG
+	else {
+		pr_debug(inet_csk_timer_bug_msg);
+	}
+#endif
+}
+
+extern struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
+
 extern struct request_sock *inet_csk_search_req(const struct sock *sk,
 						struct request_sock ***prevp,
 						const __u16 rport,
@@ -83,4 +179,60 @@ extern int inet_csk_get_port(struct inet_hashinfo *hashinfo,
 extern struct dst_entry* inet_csk_route_req(struct sock *sk,
 					    const struct request_sock *req);
 
+static inline void inet_csk_reqsk_queue_add(struct sock *sk,
+					    struct request_sock *req,
+					    struct sock *child)
+{
+	reqsk_queue_add(&inet_csk(sk)->icsk_accept_queue, req, sk, child);
+}
+
+extern void inet_csk_reqsk_queue_hash_add(struct sock *sk,
+					  struct request_sock *req,
+					  const unsigned timeout);
+
+static inline void inet_csk_reqsk_queue_removed(struct sock *sk,
+						struct request_sock *req)
+{
+	if (reqsk_queue_removed(&inet_csk(sk)->icsk_accept_queue, req) == 0)
+		inet_csk_delete_keepalive_timer(sk);
+}
+
+static inline void inet_csk_reqsk_queue_added(struct sock *sk,
+					      const unsigned long timeout)
+{
+	if (reqsk_queue_added(&inet_csk(sk)->icsk_accept_queue) == 0)
+		inet_csk_reset_keepalive_timer(sk, timeout);
+}
+
+static inline int inet_csk_reqsk_queue_len(const struct sock *sk)
+{
+	return reqsk_queue_len(&inet_csk(sk)->icsk_accept_queue);
+}
+
+static inline int inet_csk_reqsk_queue_young(const struct sock *sk)
+{
+	return reqsk_queue_len_young(&inet_csk(sk)->icsk_accept_queue);
+}
+
+static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
+{
+	return reqsk_queue_is_full(&inet_csk(sk)->icsk_accept_queue);
+}
+
+static inline void inet_csk_reqsk_queue_unlink(struct sock *sk,
+					       struct request_sock *req,
+					       struct request_sock **prev)
+{
+	reqsk_queue_unlink(&inet_csk(sk)->icsk_accept_queue, req, prev);
+}
+
+static inline void inet_csk_reqsk_queue_drop(struct sock *sk,
+					     struct request_sock *req,
+					     struct request_sock **prev)
+{
+	inet_csk_reqsk_queue_unlink(sk, req, prev);
+	inet_csk_reqsk_queue_removed(sk, req);
+	reqsk_free(req);
+}
+
 #endif /* _INET_CONNECTION_SOCK_H */

commit 463c84b97f24010a67cd871746d6a7e4c925a5f9
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:10:42 2005 -0700

    [NET]: Introduce inet_connection_sock
    
    This creates struct inet_connection_sock, moving members out of struct
    tcp_sock that are shareable with other INET connection oriented
    protocols, such as DCCP, that in my private tree already uses most of
    these members.
    
    The functions that operate on these members were renamed, using a
    inet_csk_ prefix while not being moved yet to a new file, so as to
    ease the review of these changes.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/net/inet_connection_sock.h b/include/net/inet_connection_sock.h
new file mode 100644
index 000000000000..ef609396e41b
--- /dev/null
+++ b/include/net/inet_connection_sock.h
@@ -0,0 +1,86 @@
+/*
+ * NET		Generic infrastructure for INET connection oriented protocols.
+ *
+ *		Definitions for inet_connection_sock 
+ *
+ * Authors:	Many people, see the TCP sources
+ *
+ * 		From code originally in TCP
+ *
+ *		This program is free software; you can redistribute it and/or
+ *		modify it under the terms of the GNU General Public License
+ *		as published by the Free Software Foundation; either version
+ *		2 of the License, or (at your option) any later version.
+ */
+#ifndef _INET_CONNECTION_SOCK_H
+#define _INET_CONNECTION_SOCK_H
+
+#include <linux/ip.h>
+#include <linux/timer.h>
+#include <net/request_sock.h>
+
+struct inet_bind_bucket;
+struct inet_hashinfo;
+
+/** inet_connection_sock - INET connection oriented sock
+ *
+ * @icsk_accept_queue:	   FIFO of established children 
+ * @icsk_bind_hash:	   Bind node
+ * @icsk_timeout:	   Timeout
+ * @icsk_retransmit_timer: Resend (no ack)
+ * @icsk_rto:		   Retransmit timeout
+ * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
+ * @icsk_pending:	   Scheduled timer event
+ * @icsk_backoff:	   Backoff
+ * @icsk_syn_retries:      Number of allowed SYN (or equivalent) retries
+ * @icsk_ack:		   Delayed ACK control data
+ */
+struct inet_connection_sock {
+	/* inet_sock has to be the first member! */
+	struct inet_sock	  icsk_inet;
+	struct request_sock_queue icsk_accept_queue;
+	struct inet_bind_bucket	  *icsk_bind_hash;
+	unsigned long		  icsk_timeout;
+ 	struct timer_list	  icsk_retransmit_timer;
+ 	struct timer_list	  icsk_delack_timer;
+	__u32			  icsk_rto;
+	__u8			  icsk_retransmits;
+	__u8			  icsk_pending;
+	__u8			  icsk_backoff;
+	__u8			  icsk_syn_retries;
+	struct {
+		__u8		  pending;	 /* ACK is pending			   */
+		__u8		  quick;	 /* Scheduled number of quick acks	   */
+		__u8		  pingpong;	 /* The session is interactive		   */
+		__u8		  blocked;	 /* Delayed ACK was blocked by socket lock */
+		__u32		  ato;		 /* Predicted tick of soft clock	   */
+		unsigned long	  timeout;	 /* Currently scheduled timeout		   */
+		__u32		  lrcvtime;	 /* timestamp of last received data packet */
+		__u16		  last_seg_size; /* Size of last incoming segment	   */
+		__u16		  rcv_mss;	 /* MSS used for delayed ACK decisions	   */ 
+	} icsk_ack;
+};
+
+static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
+{
+	return (struct inet_connection_sock *)sk;
+}
+
+extern void inet_csk_init_xmit_timers(struct sock *sk,
+				      void (*retransmit_handler)(unsigned long),
+				      void (*delack_handler)(unsigned long),
+				      void (*keepalive_handler)(unsigned long));
+extern void inet_csk_clear_xmit_timers(struct sock *sk);
+
+extern struct request_sock *inet_csk_search_req(const struct sock *sk,
+						struct request_sock ***prevp,
+						const __u16 rport,
+						const __u32 raddr,
+						const __u32 laddr);
+extern int inet_csk_get_port(struct inet_hashinfo *hashinfo,
+			     struct sock *sk, unsigned short snum);
+
+extern struct dst_entry* inet_csk_route_req(struct sock *sk,
+					    const struct request_sock *req);
+
+#endif /* _INET_CONNECTION_SOCK_H */
