commit bca031e2c8aa22a978a2452bf959e27e9fa73dc7
Author: Zenghui Yu <yuzenghui@huawei.com>
Date:   Thu Jul 18 08:15:10 2019 +0000

    KVM: arm/arm64: Introduce kvm_pmu_vcpu_init() to setup PMU counter index
    
    We use "pmc->idx" and the "chained" bitmap to determine if the pmc is
    chained, in kvm_pmu_pmc_is_chained().  But idx might be uninitialized
    (and random) when we doing this decision, through a KVM_ARM_VCPU_INIT
    ioctl -> kvm_pmu_vcpu_reset(). And the test_bit() against this random
    idx will potentially hit a KASAN BUG [1].
    
    In general, idx is the static property of a PMU counter that is not
    expected to be modified across resets, as suggested by Julien.  It
    looks more reasonable if we can setup the PMU counter idx for a vcpu
    in its creation time. Introduce a new function - kvm_pmu_vcpu_init()
    for this basic setup. Oh, and the KASAN BUG will get fixed this way.
    
    [1] https://www.spinics.net/lists/kvm-arm/msg36700.html
    
    Fixes: 80f393a23be6 ("KVM: arm/arm64: Support chained PMU counters")
    Suggested-by: Andrew Murray <andrew.murray@arm.com>
    Suggested-by: Julien Thierry <julien.thierry@arm.com>
    Acked-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Zenghui Yu <yuzenghui@huawei.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 16c769a7f979..6db030439e29 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -34,6 +34,7 @@ struct kvm_pmu {
 u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu, u64 select_idx);
 void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
+void kvm_pmu_vcpu_init(struct kvm_vcpu *vcpu);
 void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu);
 void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter_mask(struct kvm_vcpu *vcpu, u64 val);
@@ -71,6 +72,7 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 {
 	return 0;
 }
+static inline void kvm_pmu_vcpu_init(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_disable_counter_mask(struct kvm_vcpu *vcpu, u64 val) {}

commit 80f393a23be68e2f8a0f74258d6155438c200bbd
Author: Andrew Murray <andrew.murray@arm.com>
Date:   Mon Jun 17 20:01:05 2019 +0100

    KVM: arm/arm64: Support chained PMU counters
    
    ARMv8 provides support for chained PMU counters, where an event type
    of 0x001E is set for odd-numbered counters, the event counter will
    increment by one for each overflow of the preceding even-numbered
    counter. Let's emulate this in KVM by creating a 64 bit perf counter
    when a user chains two emulated counters together.
    
    For chained events we only support generating an overflow interrupt
    on the high counter. We use the attributes of the low counter to
    determine the attributes of the perf event.
    
    Suggested-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Andrew Murray <andrew.murray@arm.com>
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 48a15d4b820e..16c769a7f979 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -11,6 +11,7 @@
 #include <asm/perf_event.h>
 
 #define ARMV8_PMU_CYCLE_IDX		(ARMV8_PMU_MAX_COUNTERS - 1)
+#define ARMV8_PMU_MAX_COUNTER_PAIRS	((ARMV8_PMU_MAX_COUNTERS + 1) >> 1)
 
 #ifdef CONFIG_KVM_ARM_PMU
 
@@ -22,6 +23,7 @@ struct kvm_pmc {
 struct kvm_pmu {
 	int irq_num;
 	struct kvm_pmc pmc[ARMV8_PMU_MAX_COUNTERS];
+	DECLARE_BITMAP(chained, ARMV8_PMU_MAX_COUNTER_PAIRS);
 	bool ready;
 	bool created;
 	bool irq_level;

commit 218907cbc2b82419c70180610163c987d4764b27
Author: Andrew Murray <andrew.murray@arm.com>
Date:   Mon Jun 17 20:01:04 2019 +0100

    KVM: arm/arm64: Remove pmc->bitmask
    
    We currently use pmc->bitmask to determine the width of the pmc - however
    it's superfluous as the pmc index already describes if the pmc is a cycle
    counter or event counter. The architecture clearly describes the widths of
    these counters.
    
    Let's remove the bitmask to simplify the code.
    
    Signed-off-by: Andrew Murray <andrew.murray@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 45e5205750b4..48a15d4b820e 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -17,7 +17,6 @@
 struct kvm_pmc {
 	u8 idx;	/* index into the pmu->pmc array */
 	struct perf_event *perf_event;
-	u64 bitmask;
 };
 
 struct kvm_pmu {

commit 418e5ca88cc18b7e9eaafa40eac26397ccd66a71
Author: Andrew Murray <andrew.murray@arm.com>
Date:   Mon Jun 17 20:01:01 2019 +0100

    KVM: arm/arm64: Rename kvm_pmu_{enable/disable}_counter functions
    
    The kvm_pmu_{enable/disable}_counter functions can enable/disable
    multiple counters at once as they operate on a bitmask. Let's
    make this clearer by renaming the function.
    
    Suggested-by: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Andrew Murray <andrew.murray@arm.com>
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 84a9db156be7..45e5205750b4 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -35,8 +35,8 @@ void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
 void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu);
 void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu);
-void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
-void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_disable_counter_mask(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_enable_counter_mask(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu);
 void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu);
 bool kvm_pmu_should_notify_user(struct kvm_vcpu *vcpu);
@@ -72,8 +72,8 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 }
 static inline void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu) {}
-static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
-static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_disable_counter_mask(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_enable_counter_mask(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu) {}
 static inline bool kvm_pmu_should_notify_user(struct kvm_vcpu *vcpu)

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index f87fe20fcb05..84a9db156be7 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -1,18 +1,7 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Copyright (C) 2015 Linaro Ltd.
  * Author: Shannon Zhao <shannon.zhao@linaro.org>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #ifndef __ASM_ARM_KVM_PMU_H

commit d9f89b4e9290e46cd9b273e9ad0bff0f93e86fae
Author: Andrew Jones <drjones@redhat.com>
Date:   Sat Jul 1 18:26:54 2017 +0200

    KVM: arm/arm64: PMU: Fix overflow interrupt injection
    
    kvm_pmu_overflow_set() is called from perf's interrupt handler,
    making the call of kvm_vgic_inject_irq() from it introduced with
    "KVM: arm/arm64: PMU: remove request-less vcpu kick" a really bad
    idea, as it's quite easy to try and retake a lock that the
    interrupted context is already holding. The fix is to use a vcpu
    kick, leaving the interrupt injection to kvm_pmu_sync_hwstate(),
    like it was doing before the refactoring. We don't just revert,
    though, because before the kick was request-less, leaving the vcpu
    exposed to the request-less vcpu kick race, and also because the
    kick was used unnecessarily from register access handlers.
    
    Reviewed-by: Christoffer Dall <cdall@linaro.org>
    Signed-off-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index f6e030617467..f87fe20fcb05 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -48,7 +48,6 @@ void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu);
 void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
-void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu);
 void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu);
 bool kvm_pmu_should_notify_user(struct kvm_vcpu *vcpu);
@@ -86,7 +85,6 @@ static inline void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
-static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu) {}
 static inline bool kvm_pmu_should_notify_user(struct kvm_vcpu *vcpu)

commit a2befacf50940017e0de8461c4b924a929c4edc5
Author: Christoffer Dall <cdall@linaro.org>
Date:   Tue May 2 13:41:02 2017 +0200

    KVM: arm64: Allow creating the PMU without the in-kernel GIC
    
    Since we got support for devices in userspace which allows reporting the
    PMU overflow output status to userspace, we should actually allow
    creating the PMU on systems without an in-kernel irqchip, which in turn
    requires us to slightly clarify error codes for the ABI and move things
    around for the initialization phase.
    
    Signed-off-by: Christoffer Dall <cdall@linaro.org>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 1ab4633adf4f..f6e030617467 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -35,6 +35,7 @@ struct kvm_pmu {
 	int irq_num;
 	struct kvm_pmc pmc[ARMV8_PMU_MAX_COUNTERS];
 	bool ready;
+	bool created;
 	bool irq_level;
 };
 
@@ -63,6 +64,7 @@ int kvm_arm_pmu_v3_get_attr(struct kvm_vcpu *vcpu,
 			    struct kvm_device_attr *attr);
 int kvm_arm_pmu_v3_has_attr(struct kvm_vcpu *vcpu,
 			    struct kvm_device_attr *attr);
+int kvm_arm_pmu_v3_enable(struct kvm_vcpu *vcpu);
 #else
 struct kvm_pmu {
 };
@@ -112,6 +114,10 @@ static inline int kvm_arm_pmu_v3_has_attr(struct kvm_vcpu *vcpu,
 {
 	return -ENXIO;
 }
+static inline int kvm_arm_pmu_v3_enable(struct kvm_vcpu *vcpu)
+{
+	return 0;
+}
 #endif
 
 #endif

commit 3dbbdf78636e66094d82c4df496c54ff6ae46e31
Author: Christoffer Dall <christoffer.dall@linaro.org>
Date:   Wed Feb 1 12:51:52 2017 +0100

    KVM: arm/arm64: Report PMU overflow interrupts to userspace irqchip
    
    When not using an in-kernel VGIC, but instead emulating an interrupt
    controller in userspace, we should report the PMU overflow status to
    that userspace interrupt controller using the KVM_CAP_ARM_USER_IRQ
    feature.
    
    Reviewed-by: Alexander Graf <agraf@suse.de>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@linaro.org>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 92e7e97ca8ff..1ab4633adf4f 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -50,6 +50,8 @@ void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu);
 void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu);
+bool kvm_pmu_should_notify_user(struct kvm_vcpu *vcpu);
+void kvm_pmu_update_run(struct kvm_vcpu *vcpu);
 void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
@@ -85,6 +87,11 @@ static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu) {}
+static inline bool kvm_pmu_should_notify_user(struct kvm_vcpu *vcpu)
+{
+	return false;
+}
+static inline void kvm_pmu_update_run(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,

commit 0efce9da1255f13d910842b62cb14371044a3c50
Author: Sudeep Holla <sudeep.holla@arm.com>
Date:   Wed Jun 8 11:38:55 2016 +0100

    arm64: KVM: fix build with CONFIG_ARM_PMU disabled
    
    When CONFIG_ARM_PMU is disabled, we get the following build error:
    
    arch/arm64/kvm/sys_regs.c: In function 'pmu_counter_idx_valid':
    arch/arm64/kvm/sys_regs.c:564:27: error: 'ARMV8_PMU_CYCLE_IDX' undeclared (first use in this function)
      if (idx >= val && idx != ARMV8_PMU_CYCLE_IDX)
                               ^
    arch/arm64/kvm/sys_regs.c:564:27: note: each undeclared identifier is reported only once for each function it appears in
    arch/arm64/kvm/sys_regs.c: In function 'access_pmu_evcntr':
    arch/arm64/kvm/sys_regs.c:592:10: error: 'ARMV8_PMU_CYCLE_IDX' undeclared (first use in this function)
        idx = ARMV8_PMU_CYCLE_IDX;
              ^
    arch/arm64/kvm/sys_regs.c: In function 'access_pmu_evtyper':
    arch/arm64/kvm/sys_regs.c:638:14: error: 'ARMV8_PMU_CYCLE_IDX' undeclared (first use in this function)
       if (idx == ARMV8_PMU_CYCLE_IDX)
                  ^
    arch/arm64/kvm/hyp/switch.c:86:15: error: 'ARMV8_PMU_USERENR_MASK' undeclared (first use in this function)
      write_sysreg(ARMV8_PMU_USERENR_MASK, pmuserenr_el0);
    
    This patch fixes the build with CONFIG_ARM_PMU disabled.
    
    Cc: Christoffer Dall <christoffer.dall@linaro.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@linaro.org>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index fe389ac31489..92e7e97ca8ff 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -18,13 +18,13 @@
 #ifndef __ASM_ARM_KVM_PMU_H
 #define __ASM_ARM_KVM_PMU_H
 
-#ifdef CONFIG_KVM_ARM_PMU
-
 #include <linux/perf_event.h>
 #include <asm/perf_event.h>
 
 #define ARMV8_PMU_CYCLE_IDX		(ARMV8_PMU_MAX_COUNTERS - 1)
 
+#ifdef CONFIG_KVM_ARM_PMU
+
 struct kvm_pmc {
 	u8 idx;	/* index into the pmu->pmc array */
 	struct perf_event *perf_event;

commit bb0c70bcca6ba3c84afc2da7426f3b923bbe6825
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Mon Jan 11 21:35:32 2016 +0800

    arm64: KVM: Add a new vcpu device control group for PMUv3
    
    To configure the virtual PMUv3 overflow interrupt number, we use the
    vcpu kvm_device ioctl, encapsulating the KVM_ARM_VCPU_PMU_V3_IRQ
    attribute within the KVM_ARM_VCPU_PMU_V3_CTRL group.
    
    After configuring the PMUv3, call the vcpu ioctl with attribute
    KVM_ARM_VCPU_PMU_V3_INIT to initialize the PMUv3.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Acked-by: Peter Maydell <peter.maydell@linaro.org>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index ee62497d46f7..fe389ac31489 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -39,6 +39,7 @@ struct kvm_pmu {
 };
 
 #define kvm_arm_pmu_v3_ready(v)		((v)->arch.pmu.ready)
+#define kvm_arm_pmu_irq_initialized(v)	((v)->arch.pmu.irq_num >= VGIC_NR_SGIS)
 u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu, u64 select_idx);
 void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
@@ -54,11 +55,18 @@ void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
 				    u64 select_idx);
 bool kvm_arm_support_pmu_v3(void);
+int kvm_arm_pmu_v3_set_attr(struct kvm_vcpu *vcpu,
+			    struct kvm_device_attr *attr);
+int kvm_arm_pmu_v3_get_attr(struct kvm_vcpu *vcpu,
+			    struct kvm_device_attr *attr);
+int kvm_arm_pmu_v3_has_attr(struct kvm_vcpu *vcpu,
+			    struct kvm_device_attr *attr);
 #else
 struct kvm_pmu {
 };
 
 #define kvm_arm_pmu_v3_ready(v)		(false)
+#define kvm_arm_pmu_irq_initialized(v)	(false)
 static inline u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu,
 					    u64 select_idx)
 {
@@ -82,6 +90,21 @@ static inline void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,
 						  u64 data, u64 select_idx) {}
 static inline bool kvm_arm_support_pmu_v3(void) { return false; }
+static inline int kvm_arm_pmu_v3_set_attr(struct kvm_vcpu *vcpu,
+					  struct kvm_device_attr *attr)
+{
+	return -ENXIO;
+}
+static inline int kvm_arm_pmu_v3_get_attr(struct kvm_vcpu *vcpu,
+					  struct kvm_device_attr *attr)
+{
+	return -ENXIO;
+}
+static inline int kvm_arm_pmu_v3_has_attr(struct kvm_vcpu *vcpu,
+					  struct kvm_device_attr *attr)
+{
+	return -ENXIO;
+}
 #endif
 
 #endif

commit 808e738142e7086ef793ebf9797099c392894e65
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Mon Jan 11 22:46:15 2016 +0800

    arm64: KVM: Add a new feature bit for PMUv3
    
    To support guest PMUv3, use one bit of the VCPU INIT feature array.
    Initialize the PMU when initialzing the vcpu with that bit and PMU
    overflow interrupt set.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Acked-by: Peter Maydell <peter.maydell@linaro.org>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 9f87d717ef84..ee62497d46f7 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -53,6 +53,7 @@ void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
 				    u64 select_idx);
+bool kvm_arm_support_pmu_v3(void);
 #else
 struct kvm_pmu {
 };
@@ -80,6 +81,7 @@ static inline void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,
 						  u64 data, u64 select_idx) {}
+static inline bool kvm_arm_support_pmu_v3(void) { return false; }
 #endif
 
 #endif

commit 5f0a714a2b63c25ffba5d832773f3ca4f0d02e21
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Fri Sep 11 15:18:05 2015 +0800

    arm64: KVM: Free perf event of PMU when destroying vcpu
    
    When KVM frees VCPU, it needs to free the perf_event of PMU.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index b4993eb76aa1..9f87d717ef84 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -43,6 +43,7 @@ u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu, u64 select_idx);
 void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
 void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu);
+void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
@@ -69,6 +70,7 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 	return 0;
 }
 static inline void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu) {}
+static inline void kvm_pmu_vcpu_destroy(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}

commit 2aa36e9840d71710f06b3c29634f044fde8bcbe5
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Fri Sep 11 11:30:22 2015 +0800

    arm64: KVM: Reset PMU state when resetting vcpu
    
    When resetting vcpu, it needs to reset the PMU state to initial status.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 9c184edb8e07..b4993eb76aa1 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -42,6 +42,7 @@ struct kvm_pmu {
 u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu, u64 select_idx);
 void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
+void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
@@ -67,6 +68,7 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 {
 	return 0;
 }
+static inline void kvm_pmu_vcpu_reset(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}

commit b02386eb7dac7555a208d81aef2a0e5c6f0f8085
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Fri Feb 26 19:29:19 2016 +0800

    arm64: KVM: Add PMU overflow interrupt routing
    
    When calling perf_event_create_kernel_counter to create perf_event,
    assign a overflow handler. Then when the perf event overflows, set the
    corresponding bit of guest PMOVSSET register. If this counter is enabled
    and its interrupt is enabled as well, kick the vcpu to sync the
    interrupt.
    
    On VM entry, if there is counter overflowed and interrupt level is
    changed, inject the interrupt with corresponding level. On VM exit, sync
    the interrupt level as well if it has been changed.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 8bc92d119713..9c184edb8e07 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -35,6 +35,7 @@ struct kvm_pmu {
 	int irq_num;
 	struct kvm_pmc pmc[ARMV8_PMU_MAX_COUNTERS];
 	bool ready;
+	bool irq_level;
 };
 
 #define kvm_arm_pmu_v3_ready(v)		((v)->arch.pmu.ready)
@@ -44,6 +45,8 @@ u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu);
+void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu);
 void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
@@ -67,6 +70,8 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_flush_hwstate(struct kvm_vcpu *vcpu) {}
+static inline void kvm_pmu_sync_hwstate(struct kvm_vcpu *vcpu) {}
 static inline void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,

commit 76993739cd6f5b42e881fe3332b9f8eb98cd6907
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Wed Oct 28 12:10:30 2015 +0800

    arm64: KVM: Add helper to handle PMCR register bits
    
    According to ARMv8 spec, when writing 1 to PMCR.E, all counters are
    enabled by PMCNTENSET, while writing 0 to PMCR.E, all counters are
    disabled. When writing 1 to PMCR.P, reset all event counters, not
    including PMCCNTR, to zero. When writing 1 to PMCR.C, reset PMCCNTR to
    zero.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 348c4c9d763a..8bc92d119713 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -45,6 +45,7 @@ void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
 				    u64 select_idx);
 #else
@@ -67,6 +68,7 @@ static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_handle_pmcr(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,
 						  u64 data, u64 select_idx) {}
 #endif

commit 7a0adc7064b88609e2917446af8789fac1d4fdd1
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Tue Sep 8 15:49:39 2015 +0800

    arm64: KVM: Add access handler for PMSWINC register
    
    Add access handler which emulates writing and reading PMSWINC
    register and add support for creating software increment event.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 60061dabe881..348c4c9d763a 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -44,6 +44,7 @@ u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
 				    u64 select_idx);
 #else
@@ -65,6 +66,7 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_software_increment(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,
 						  u64 data, u64 select_idx) {}
 #endif

commit 76d883c4e6401b98ea26d40c437ff62719a517ad
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Tue Sep 8 15:03:26 2015 +0800

    arm64: KVM: Add access handler for PMOVSSET and PMOVSCLR register
    
    Since the reset value of PMOVSSET and PMOVSCLR is UNKNOWN, use
    reset_unknown for its reset handler. Add a handler to emulate writing
    PMOVSSET or PMOVSCLR register.
    
    When writing non-zero value to PMOVSSET, the counter and its interrupt
    is enabled, kick this vcpu to sync PMU interrupt.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index c57377970d4e..60061dabe881 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -43,6 +43,7 @@ void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
 				    u64 select_idx);
 #else
@@ -63,6 +64,7 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 }
 static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_overflow_set(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,
 						  u64 data, u64 select_idx) {}
 #endif

commit 7f7663587165fe1a81c3390358cb70eb7234706f
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Fri Jul 3 14:27:25 2015 +0800

    arm64: KVM: PMU: Add perf event map and introduce perf event creating function
    
    When we use tools like perf on host, perf passes the event type and the
    id of this event type category to kernel, then kernel will map them to
    hardware event number and write this number to PMU PMEVTYPER<n>_EL0
    register. When getting the event number in KVM, directly use raw event
    type to create a perf_event for it.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index b70058ef1dd6..c57377970d4e 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -43,6 +43,8 @@ void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
 void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
 void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu, u64 data,
+				    u64 select_idx);
 #else
 struct kvm_pmu {
 };
@@ -61,6 +63,8 @@ static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
 }
 static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_set_counter_event_type(struct kvm_vcpu *vcpu,
+						  u64 data, u64 select_idx) {}
 #endif
 
 #endif

commit 96b0eebcc6a14e3bdb9ff0e7176fbfc225bdde94
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Tue Sep 8 12:26:13 2015 +0800

    arm64: KVM: Add access handler for PMCNTENSET and PMCNTENCLR register
    
    Since the reset value of PMCNTENSET and PMCNTENCLR is UNKNOWN, use
    reset_unknown for its reset handler. Add a handler to emulate writing
    PMCNTENSET or PMCNTENCLR register.
    
    When writing to PMCNTENSET, call perf_event_enable to enable the perf
    event. When writing to PMCNTENCLR, call perf_event_disable to disable
    the perf event.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index bcb769805839..b70058ef1dd6 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -40,6 +40,9 @@ struct kvm_pmu {
 #define kvm_arm_pmu_v3_ready(v)		((v)->arch.pmu.ready)
 u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu, u64 select_idx);
 void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
+u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu);
+void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val);
+void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val);
 #else
 struct kvm_pmu {
 };
@@ -52,6 +55,12 @@ static inline u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu,
 }
 static inline void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu,
 					     u64 select_idx, u64 val) {}
+static inline u64 kvm_pmu_valid_counter_mask(struct kvm_vcpu *vcpu)
+{
+	return 0;
+}
+static inline void kvm_pmu_disable_counter(struct kvm_vcpu *vcpu, u64 val) {}
+static inline void kvm_pmu_enable_counter(struct kvm_vcpu *vcpu, u64 val) {}
 #endif
 
 #endif

commit 051ff581ce70e822729e9474941f3c206cbf7436
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Tue Dec 8 15:29:06 2015 +0800

    arm64: KVM: Add access handler for event counter register
    
    These kind of registers include PMEVCNTRn, PMCCNTR and PMXEVCNTR which
    is mapped to PMEVCNTRn.
    
    The access handler translates all aarch32 register offsets to aarch64
    ones and uses vcpu_sys_reg() to access their values to avoid taking care
    of big endian.
    
    When reading these registers, return the sum of register value and the
    value perf event counts.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 8157fe5bcbb0..bcb769805839 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -23,6 +23,8 @@
 #include <linux/perf_event.h>
 #include <asm/perf_event.h>
 
+#define ARMV8_PMU_CYCLE_IDX		(ARMV8_PMU_MAX_COUNTERS - 1)
+
 struct kvm_pmc {
 	u8 idx;	/* index into the pmu->pmc array */
 	struct perf_event *perf_event;
@@ -36,11 +38,20 @@ struct kvm_pmu {
 };
 
 #define kvm_arm_pmu_v3_ready(v)		((v)->arch.pmu.ready)
+u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu, u64 select_idx);
+void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu, u64 select_idx, u64 val);
 #else
 struct kvm_pmu {
 };
 
 #define kvm_arm_pmu_v3_ready(v)		(false)
+static inline u64 kvm_pmu_get_counter_value(struct kvm_vcpu *vcpu,
+					    u64 select_idx)
+{
+	return 0;
+}
+static inline void kvm_pmu_set_counter_value(struct kvm_vcpu *vcpu,
+					     u64 select_idx, u64 val) {}
 #endif
 
 #endif

commit ab9468340d2bcc2a837b8b536fa819a0fc05a32e
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Thu Jun 18 16:01:53 2015 +0800

    arm64: KVM: Add access handler for PMCR register
    
    Add reset handler which gets host value of PMCR_EL0 and make writable
    bits architecturally UNKNOWN except PMCR.E which is zero. Add an access
    handler for PMCR.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
index 3c2fd568e0a8..8157fe5bcbb0 100644
--- a/include/kvm/arm_pmu.h
+++ b/include/kvm/arm_pmu.h
@@ -34,9 +34,13 @@ struct kvm_pmu {
 	struct kvm_pmc pmc[ARMV8_PMU_MAX_COUNTERS];
 	bool ready;
 };
+
+#define kvm_arm_pmu_v3_ready(v)		((v)->arch.pmu.ready)
 #else
 struct kvm_pmu {
 };
+
+#define kvm_arm_pmu_v3_ready(v)		(false)
 #endif
 
 #endif

commit 04fe472615d0216ec0bdd66d9f3f1812b642ada6
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Fri Sep 11 09:38:32 2015 +0800

    arm64: KVM: Define PMU data structure for each vcpu
    
    Here we plan to support virtual PMU for guest by full software
    emulation, so define some basic structs and functions preparing for
    futher steps. Define struct kvm_pmc for performance monitor counter and
    struct kvm_pmu for performance monitor unit for each vcpu. According to
    ARMv8 spec, the PMU contains at most 32(ARMV8_PMU_MAX_COUNTERS)
    counters.
    
    Since this only supports ARM64 (or PMUv3), add a separate config symbol
    for it.
    
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Andrew Jones <drjones@redhat.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/include/kvm/arm_pmu.h b/include/kvm/arm_pmu.h
new file mode 100644
index 000000000000..3c2fd568e0a8
--- /dev/null
+++ b/include/kvm/arm_pmu.h
@@ -0,0 +1,42 @@
+/*
+ * Copyright (C) 2015 Linaro Ltd.
+ * Author: Shannon Zhao <shannon.zhao@linaro.org>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#ifndef __ASM_ARM_KVM_PMU_H
+#define __ASM_ARM_KVM_PMU_H
+
+#ifdef CONFIG_KVM_ARM_PMU
+
+#include <linux/perf_event.h>
+#include <asm/perf_event.h>
+
+struct kvm_pmc {
+	u8 idx;	/* index into the pmu->pmc array */
+	struct perf_event *perf_event;
+	u64 bitmask;
+};
+
+struct kvm_pmu {
+	int irq_num;
+	struct kvm_pmc pmc[ARMV8_PMU_MAX_COUNTERS];
+	bool ready;
+};
+#else
+struct kvm_pmu {
+};
+#endif
+
+#endif
