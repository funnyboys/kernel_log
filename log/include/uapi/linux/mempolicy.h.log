commit 6f52b16c5b29b89d92c0e7236f4655dc8491ad70
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:08:43 2017 +0100

    License cleanup: add SPDX license identifier to uapi header files with no license
    
    Many user space API headers are missing licensing information, which
    makes it hard for compliance tools to determine the correct license.
    
    By default are files without license information under the default
    license of the kernel, which is GPLV2.  Marking them GPLV2 would exclude
    them from being included in non GPLV2 code, which is obviously not
    intended. The user space API headers fall under the syscall exception
    which is in the kernels COPYING file:
    
       NOTE! This copyright does *not* cover user programs that use kernel
       services by normal system calls - this is merely considered normal use
       of the kernel, and does *not* fall under the heading of "derived work".
    
    otherwise syscall usage would not be possible.
    
    Update the files which contain no license information with an SPDX
    license identifier.  The chosen identifier is 'GPL-2.0 WITH
    Linux-syscall-note' which is the officially assigned identifier for the
    Linux syscall exception.  SPDX license identifiers are a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.  See the previous patch in this series for the
    methodology of how this patch was researched.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 2a4d89508fec..3354774af61e 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
 /*
  * NUMA memory policies for Linux.
  * Copyright 2003,2004 Andi Kleen SuSE Labs

commit 213980c0f23b6c4932fd5516da7e8443b2a615ea
Author: Vlastimil Babka <vbabka@suse.cz>
Date:   Thu Jul 6 15:40:06 2017 -0700

    mm, mempolicy: simplify rebinding mempolicies when updating cpusets
    
    Commit c0ff7453bb5c ("cpuset,mm: fix no node to alloc memory when
    changing cpuset's mems") has introduced a two-step protocol when
    rebinding task's mempolicy due to cpuset update, in order to avoid a
    parallel allocation seeing an empty effective nodemask and failing.
    
    Later, commit cc9a6c877661 ("cpuset: mm: reduce large amounts of memory
    barrier related damage v3") introduced a seqlock protection and removed
    the synchronization point between the two update steps.  At that point
    (or perhaps later), the two-step rebinding became unnecessary.
    
    Currently it only makes sure that the update first adds new nodes in
    step 1 and then removes nodes in step 2.  Without memory barriers the
    effects are questionable, and even then this cannot prevent a parallel
    zonelist iteration checking the nodemask at each step to observe all
    nodes as unusable for allocation.  We now fully rely on the seqlock to
    prevent premature OOMs and allocation failures.
    
    We can thus remove the two-step update parts and simplify the code.
    
    Link: http://lkml.kernel.org/r/20170517081140.30654-5-vbabka@suse.cz
    Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Dimitri Sivanich <sivanich@sgi.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 9cd8b21dddbe..2a4d89508fec 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -24,13 +24,6 @@ enum {
 	MPOL_MAX,	/* always last member of enum */
 };
 
-enum mpol_rebind_step {
-	MPOL_REBIND_ONCE,	/* do rebind work at once(not by two step) */
-	MPOL_REBIND_STEP1,	/* first step(set all the newly nodes) */
-	MPOL_REBIND_STEP2,	/* second step(clean all the disallowed nodes)*/
-	MPOL_REBIND_NSTEP,
-};
-
 /* Flags for set_mempolicy */
 #define MPOL_F_STATIC_NODES	(1 << 15)
 #define MPOL_F_RELATIVE_NODES	(1 << 14)
@@ -65,7 +58,6 @@ enum mpol_rebind_step {
  */
 #define MPOL_F_SHARED  (1 << 0)	/* identify shared policies */
 #define MPOL_F_LOCAL   (1 << 1)	/* preferred local allocation */
-#define MPOL_F_REBINDING (1 << 2)	/* identify policies in rebinding */
 #define MPOL_F_MOF	(1 << 3) /* this policy wants migrate on fault */
 #define MPOL_F_MORON	(1 << 4) /* Migrate On protnone Reference On Node */
 

commit 8a0516ed8b90c95ffa1363b420caa37418149f21
Author: Mel Gorman <mgorman@suse.de>
Date:   Thu Feb 12 14:58:22 2015 -0800

    mm: convert p[te|md]_numa users to p[te|md]_protnone_numa
    
    Convert existing users of pte_numa and friends to the new helper.  Note
    that the kernel is broken after this patch is applied until the other page
    table modifiers are also altered.  This patch layout is to make review
    easier.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Acked-by: Aneesh Kumar <aneesh.kumar@linux.vnet.ibm.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Tested-by: Sasha Levin <sasha.levin@oracle.com>
    Cc: Dave Jones <davej@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Kirill Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 0d11c3dcd3a1..9cd8b21dddbe 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -67,7 +67,7 @@ enum mpol_rebind_step {
 #define MPOL_F_LOCAL   (1 << 1)	/* preferred local allocation */
 #define MPOL_F_REBINDING (1 << 2)	/* identify policies in rebinding */
 #define MPOL_F_MOF	(1 << 3) /* this policy wants migrate on fault */
-#define MPOL_F_MORON	(1 << 4) /* Migrate On pte_numa Reference On Node */
+#define MPOL_F_MORON	(1 << 4) /* Migrate On protnone Reference On Node */
 
 
 #endif /* _UAPI_LINUX_MEMPOLICY_H */

commit 5606e3877ad8baea42f3a71ebde0a03622bbb551
Author: Mel Gorman <mgorman@suse.de>
Date:   Fri Nov 2 18:19:13 2012 +0000

    mm: numa: Migrate on reference policy
    
    This is the simplest possible policy that still does something of note.
    When a pte_numa is faulted, it is moved immediately. Any replacement
    policy must at least do better than this and in all likelihood this
    policy regresses normal workloads.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Rik van Riel <riel@redhat.com>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 16fb4e6efbc4..0d11c3dcd3a1 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -67,6 +67,7 @@ enum mpol_rebind_step {
 #define MPOL_F_LOCAL   (1 << 1)	/* preferred local allocation */
 #define MPOL_F_REBINDING (1 << 2)	/* identify policies in rebinding */
 #define MPOL_F_MOF	(1 << 3) /* this policy wants migrate on fault */
+#define MPOL_F_MORON	(1 << 4) /* Migrate On pte_numa Reference On Node */
 
 
 #endif /* _UAPI_LINUX_MEMPOLICY_H */

commit a720094ded8cbb303111035be91858011d2eac71
Author: Mel Gorman <mgorman@suse.de>
Date:   Fri Nov 16 09:37:58 2012 +0000

    mm: mempolicy: Hide MPOL_NOOP and MPOL_MF_LAZY from userspace for now
    
    The use of MPOL_NOOP and MPOL_MF_LAZY to allow an application to
    explicitly request lazy migration is a good idea but the actual
    API has not been well reviewed and once released we have to support it.
    For now this patch prevents an application using the services. This
    will need to be revisited.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 6a1baae3775d..16fb4e6efbc4 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -21,7 +21,6 @@ enum {
 	MPOL_BIND,
 	MPOL_INTERLEAVE,
 	MPOL_LOCAL,
-	MPOL_NOOP,		/* retain existing policy for range */
 	MPOL_MAX,	/* always last member of enum */
 };
 
@@ -57,8 +56,7 @@ enum mpol_rebind_step {
 
 #define MPOL_MF_VALID	(MPOL_MF_STRICT   | 	\
 			 MPOL_MF_MOVE     | 	\
-			 MPOL_MF_MOVE_ALL |	\
-			 MPOL_MF_LAZY)
+			 MPOL_MF_MOVE_ALL)
 
 /*
  * Internal flags that share the struct mempolicy flags word with

commit b24f53a0bea38b266d219ee651b22dba727c44ae
Author: Lee Schermerhorn <lee.schermerhorn@hp.com>
Date:   Thu Oct 25 14:16:32 2012 +0200

    mm: mempolicy: Add MPOL_MF_LAZY
    
    NOTE: Once again there is a lot of patch stealing and the end result
            is sufficiently different that I had to drop the signed-offs.
            Will re-add if the original authors are ok with that.
    
    This patch adds another mbind() flag to request "lazy migration".  The
    flag, MPOL_MF_LAZY, modifies MPOL_MF_MOVE* such that the selected
    pages are marked PROT_NONE. The pages will be migrated in the fault
    path on "first touch", if the policy dictates at that time.
    
    "Lazy Migration" will allow testing of migrate-on-fault via mbind().
    Also allows applications to specify that only subsequently touched
    pages be migrated to obey new policy, instead of all pages in range.
    This can be useful for multi-threaded applications working on a
    large shared data area that is initialized by an initial thread
    resulting in all pages on one [or a few, if overflowed] nodes.
    After PROT_NONE, the pages in regions assigned to the worker threads
    will be automatically migrated local to the threads on 1st touch.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Reviewed-by: Rik van Riel <riel@redhat.com>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 472de8a5d37e..6a1baae3775d 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -49,9 +49,16 @@ enum mpol_rebind_step {
 
 /* Flags for mbind */
 #define MPOL_MF_STRICT	(1<<0)	/* Verify existing pages in the mapping */
-#define MPOL_MF_MOVE	(1<<1)	/* Move pages owned by this process to conform to mapping */
-#define MPOL_MF_MOVE_ALL (1<<2)	/* Move every page to conform to mapping */
-#define MPOL_MF_INTERNAL (1<<3)	/* Internal flags start here */
+#define MPOL_MF_MOVE	 (1<<1)	/* Move pages owned by this process to conform
+				   to policy */
+#define MPOL_MF_MOVE_ALL (1<<2)	/* Move every page to conform to policy */
+#define MPOL_MF_LAZY	 (1<<3)	/* Modifies '_MOVE:  lazy migrate on fault */
+#define MPOL_MF_INTERNAL (1<<4)	/* Internal flags start here */
+
+#define MPOL_MF_VALID	(MPOL_MF_STRICT   | 	\
+			 MPOL_MF_MOVE     | 	\
+			 MPOL_MF_MOVE_ALL |	\
+			 MPOL_MF_LAZY)
 
 /*
  * Internal flags that share the struct mempolicy flags word with

commit 771fb4d806a92bf6c988fcfbd286ae40a9374332
Author: Lee Schermerhorn <lee.schermerhorn@hp.com>
Date:   Thu Oct 25 14:16:30 2012 +0200

    mm: mempolicy: Check for misplaced page
    
    This patch provides a new function to test whether a page resides
    on a node that is appropriate for the mempolicy for the vma and
    address where the page is supposed to be mapped.  This involves
    looking up the node where the page belongs.  So, the function
    returns that node so that it may be used to allocated the page
    without consulting the policy again.
    
    A subsequent patch will call this function from the fault path.
    Because of this, I don't want to go ahead and allocate the page, e.g.,
    via alloc_page_vma() only to have to free it if it has the correct
    policy.  So, I just mimic the alloc_page_vma() node computation
    logic--sort of.
    
    Note:  we could use this function to implement a MPOL_MF_STRICT
    behavior when migrating pages to match mbind() mempolicy--e.g.,
    to ensure that pages in an interleaved range are reinterleaved
    rather than left where they are when they reside on any page in
    the interleave nodemask.
    
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    [ Added MPOL_F_LAZY to trigger migrate-on-fault;
      simplified code now that we don't have to bother
      with special crap for interleaved ]
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Mel Gorman <mgorman@suse.de>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index d23dca8367cc..472de8a5d37e 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -61,6 +61,7 @@ enum mpol_rebind_step {
 #define MPOL_F_SHARED  (1 << 0)	/* identify shared policies */
 #define MPOL_F_LOCAL   (1 << 1)	/* preferred local allocation */
 #define MPOL_F_REBINDING (1 << 2)	/* identify policies in rebinding */
+#define MPOL_F_MOF	(1 << 3) /* this policy wants migrate on fault */
 
 
 #endif /* _UAPI_LINUX_MEMPOLICY_H */

commit d3a710337b0590f43fd236d5e6518439afc7410a
Author: Lee Schermerhorn <lee.schermerhorn@hp.com>
Date:   Thu Oct 25 14:16:29 2012 +0200

    mm: mempolicy: Add MPOL_NOOP
    
    This patch augments the MPOL_MF_LAZY feature by adding a "NOOP" policy
    to mbind().  When the NOOP policy is used with the 'MOVE and 'LAZY
    flags, mbind() will map the pages PROT_NONE so that they will be
    migrated on the next touch.
    
    This allows an application to prepare for a new phase of operation
    where different regions of shared storage will be assigned to
    worker threads, w/o changing policy.  Note that we could just use
    "default" policy in this case.  However, this also allows an
    application to request that pages be migrated, only if necessary,
    to follow any arbitrary policy that might currently apply to a
    range of pages, without knowing the policy, or without specifying
    multiple mbind()s for ranges with different policies.
    
    [ Bug in early version of mpol_parse_str() reported by Fengguang Wu. ]
    
    Bug-Reported-by: Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Mel Gorman <mgorman@suse.de>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 3e835c9d847b..d23dca8367cc 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -21,6 +21,7 @@ enum {
 	MPOL_BIND,
 	MPOL_INTERLEAVE,
 	MPOL_LOCAL,
+	MPOL_NOOP,		/* retain existing policy for range */
 	MPOL_MAX,	/* always last member of enum */
 };
 

commit 479e2802d09f1e18a97262c4c6f8f17ae5884bd8
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Oct 25 14:16:28 2012 +0200

    mm: mempolicy: Make MPOL_LOCAL a real policy
    
    Make MPOL_LOCAL a real and exposed policy such that applications that
    relied on the previous default behaviour can explicitly request it.
    
    Requested-by: Christoph Lameter <cl@linux.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Mel Gorman <mgorman@suse.de>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
index 23e62e0537e2..3e835c9d847b 100644
--- a/include/uapi/linux/mempolicy.h
+++ b/include/uapi/linux/mempolicy.h
@@ -20,6 +20,7 @@ enum {
 	MPOL_PREFERRED,
 	MPOL_BIND,
 	MPOL_INTERLEAVE,
+	MPOL_LOCAL,
 	MPOL_MAX,	/* always last member of enum */
 };
 

commit 607ca46e97a1b6594b29647d98a32d545c24bdff
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 13 10:46:48 2012 +0100

    UAPI: (Scripted) Disintegrate include/linux
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/include/uapi/linux/mempolicy.h b/include/uapi/linux/mempolicy.h
new file mode 100644
index 000000000000..23e62e0537e2
--- /dev/null
+++ b/include/uapi/linux/mempolicy.h
@@ -0,0 +1,64 @@
+/*
+ * NUMA memory policies for Linux.
+ * Copyright 2003,2004 Andi Kleen SuSE Labs
+ */
+#ifndef _UAPI_LINUX_MEMPOLICY_H
+#define _UAPI_LINUX_MEMPOLICY_H
+
+#include <linux/errno.h>
+
+
+/*
+ * Both the MPOL_* mempolicy mode and the MPOL_F_* optional mode flags are
+ * passed by the user to either set_mempolicy() or mbind() in an 'int' actual.
+ * The MPOL_MODE_FLAGS macro determines the legal set of optional mode flags.
+ */
+
+/* Policies */
+enum {
+	MPOL_DEFAULT,
+	MPOL_PREFERRED,
+	MPOL_BIND,
+	MPOL_INTERLEAVE,
+	MPOL_MAX,	/* always last member of enum */
+};
+
+enum mpol_rebind_step {
+	MPOL_REBIND_ONCE,	/* do rebind work at once(not by two step) */
+	MPOL_REBIND_STEP1,	/* first step(set all the newly nodes) */
+	MPOL_REBIND_STEP2,	/* second step(clean all the disallowed nodes)*/
+	MPOL_REBIND_NSTEP,
+};
+
+/* Flags for set_mempolicy */
+#define MPOL_F_STATIC_NODES	(1 << 15)
+#define MPOL_F_RELATIVE_NODES	(1 << 14)
+
+/*
+ * MPOL_MODE_FLAGS is the union of all possible optional mode flags passed to
+ * either set_mempolicy() or mbind().
+ */
+#define MPOL_MODE_FLAGS	(MPOL_F_STATIC_NODES | MPOL_F_RELATIVE_NODES)
+
+/* Flags for get_mempolicy */
+#define MPOL_F_NODE	(1<<0)	/* return next IL mode instead of node mask */
+#define MPOL_F_ADDR	(1<<1)	/* look up vma using address */
+#define MPOL_F_MEMS_ALLOWED (1<<2) /* return allowed memories */
+
+/* Flags for mbind */
+#define MPOL_MF_STRICT	(1<<0)	/* Verify existing pages in the mapping */
+#define MPOL_MF_MOVE	(1<<1)	/* Move pages owned by this process to conform to mapping */
+#define MPOL_MF_MOVE_ALL (1<<2)	/* Move every page to conform to mapping */
+#define MPOL_MF_INTERNAL (1<<3)	/* Internal flags start here */
+
+/*
+ * Internal flags that share the struct mempolicy flags word with
+ * "mode flags".  These flags are allocated from bit 0 up, as they
+ * are never OR'ed into the mode in mempolicy API arguments.
+ */
+#define MPOL_F_SHARED  (1 << 0)	/* identify shared policies */
+#define MPOL_F_LOCAL   (1 << 1)	/* preferred local allocation */
+#define MPOL_F_REBINDING (1 << 2)	/* identify policies in rebinding */
+
+
+#endif /* _UAPI_LINUX_MEMPOLICY_H */
