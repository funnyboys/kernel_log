commit b1f3e43dbfacfcd95296b0f80f84b186add9ef54
Author: Dmitry Yakunin <zeil@yandex-team.ru>
Date:   Thu Apr 30 18:51:15 2020 +0300

    inet_diag: add support for cgroup filter
    
    This patch adds ability to filter sockets based on cgroup v2 ID.
    Such filter is helpful in ss utility for filtering sockets by
    cgroup pathname.
    
    Signed-off-by: Dmitry Yakunin <zeil@yandex-team.ru>
    Reviewed-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index c9b1e551792c..e6f183ee8417 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -96,6 +96,7 @@ enum {
 	INET_DIAG_BC_MARK_COND,
 	INET_DIAG_BC_S_EQ,
 	INET_DIAG_BC_D_EQ,
+	INET_DIAG_BC_CGROUP_COND,   /* u64 cgroup v2 ID */
 };
 
 struct inet_diag_hostcond {

commit 6e3a401fc8af01828bcdc92d713195d318b36e7e
Author: Dmitry Yakunin <zeil@yandex-team.ru>
Date:   Thu Apr 30 18:51:14 2020 +0300

    inet_diag: add cgroup id attribute
    
    This patch adds cgroup v2 ID to common inet diag message attributes.
    Cgroup v2 ID is kernfs ID (ino or ino+gen). This attribute allows filter
    inet diag output by cgroup ID obtained by name_to_handle_at() syscall.
    When net_cls or net_prio cgroup is activated this ID is equal to 1 (root
    cgroup ID) for newly created sockets.
    
    Some notes about this ID:
    
    1) gets initialized in socket() syscall
    2) incoming socket gets ID from listening socket
       (not during accept() syscall)
    3) not changed when process get moved to another cgroup
    4) can point to deleted cgroup (refcounting)
    
    v2:
      - use CONFIG_SOCK_CGROUP_DATA instead if CONFIG_CGROUPS
    
    v3:
      - fix attr size by using nla_total_size_64bit() (Eric Dumazet)
      - more detailed commit message (Konstantin Khlebnikov)
    
    Signed-off-by: Dmitry Yakunin <zeil@yandex-team.ru>
    Reviewed-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Acked-By: Tejun Heo <tj@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 57cc429a9177..c9b1e551792c 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -157,6 +157,7 @@ enum {
 	INET_DIAG_MD5SIG,
 	INET_DIAG_ULP_INFO,
 	INET_DIAG_SK_BPF_STORAGES,
+	INET_DIAG_CGROUP_ID,
 	__INET_DIAG_MAX,
 };
 

commit 5147dfb5083204d6f5468d6d6d2d04b2cdc0cf2b
Author: Davide Caratti <dcaratti@redhat.com>
Date:   Fri Mar 27 14:48:49 2020 -0700

    mptcp: allow dumping subflow context to userspace
    
    add ulp-specific diagnostic functions, so that subflow information can be
    dumped to userspace programs like 'ss'.
    
    v2 -> v3:
    - uapi: use bit macros appropriate for userspace
    
    Co-developed-by: Matthieu Baerts <matthieu.baerts@tessares.net>
    Signed-off-by: Matthieu Baerts <matthieu.baerts@tessares.net>
    Co-developed-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Davide Caratti <dcaratti@redhat.com>
    Signed-off-by: Mat Martineau <mathew.j.martineau@linux.intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 75dffd78363a..57cc429a9177 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -166,6 +166,7 @@ enum {
 	INET_ULP_INFO_UNSPEC,
 	INET_ULP_INFO_NAME,
 	INET_ULP_INFO_TLS,
+	INET_ULP_INFO_MPTCP,
 	__INET_ULP_INFO_MAX,
 };
 #define INET_ULP_INFO_MAX (__INET_ULP_INFO_MAX - 1)

commit 085c20cacf2b72991ce1c9d99a5e2f1d9e73bb68
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Tue Feb 25 15:04:27 2020 -0800

    bpf: inet_diag: Dump bpf_sk_storages in inet_diag_dump()
    
    This patch will dump out the bpf_sk_storages of a sk
    if the request has the INET_DIAG_REQ_SK_BPF_STORAGES nlattr.
    
    An array of SK_DIAG_BPF_STORAGE_REQ_MAP_FD can be specified in
    INET_DIAG_REQ_SK_BPF_STORAGES to select which bpf_sk_storage to dump.
    If no map_fd is specified, all bpf_sk_storages of a sk will be dumped.
    
    bpf_sk_storages can be added to the system at runtime.  It is difficult
    to find a proper static value for cb->min_dump_alloc.
    
    This patch learns the nlattr size required to dump the bpf_sk_storages
    of a sk.  If it happens to be the very first nlmsg of a dump and it
    cannot fit the needed bpf_sk_storages,  it will try to expand the
    skb by "pskb_expand_head()".
    
    Instead of expanding it in inet_sk_diag_fill(), it is expanded at a
    sleepable context in __inet_diag_dump() so __GFP_DIRECT_RECLAIM can
    be used.  In __inet_diag_dump(), it will retry as long as the
    skb is empty and the cb->min_dump_alloc becomes larger than before.
    cb->min_dump_alloc is bounded by KMALLOC_MAX_SIZE.  The min_dump_alloc
    is also changed from 'u16' to 'u32' to accommodate a sk that may have
    a few large bpf_sk_storages.
    
    The updated cb->min_dump_alloc will also be used to allocate the skb in
    the next dump.  This logic already exists in netlink_dump().
    
    Here is the sample output of a locally modified 'ss' and it could be made
    more readable by using BTF later:
    [root@arch-fb-vm1 ~]# ss --bpf-map-id 14 --bpf-map-id 13 -t6an 'dst [::1]:8989'
    State Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess
    ESTAB 0      0              [::1]:51072        [::1]:8989
             bpf_map_id:14 value:[ 3feb ]
             bpf_map_id:13 value:[ 3f ]
    ESTAB 0      0              [::1]:51070        [::1]:8989
             bpf_map_id:14 value:[ 3feb ]
             bpf_map_id:13 value:[ 3f ]
    
    [root@arch-fb-vm1 ~]# ~/devshare/github/iproute2/misc/ss --bpf-maps -t6an 'dst [::1]:8989'
    State         Recv-Q         Send-Q                   Local Address:Port                    Peer Address:Port         Process
    ESTAB         0              0                                [::1]:51072                          [::1]:8989
             bpf_map_id:14 value:[ 3feb ]
             bpf_map_id:13 value:[ 3f ]
             bpf_map_id:12 value:[ 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000... total:65407 ]
    ESTAB         0              0                                [::1]:51070                          [::1]:8989
             bpf_map_id:14 value:[ 3feb ]
             bpf_map_id:13 value:[ 3f ]
             bpf_map_id:12 value:[ 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000... total:65407 ]
    
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Song Liu <songliubraving@fb.com>
    Link: https://lore.kernel.org/bpf/20200225230427.1976129-1-kafai@fb.com

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index bab9a9f8da12..75dffd78363a 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -64,6 +64,7 @@ struct inet_diag_req_raw {
 enum {
 	INET_DIAG_REQ_NONE,
 	INET_DIAG_REQ_BYTECODE,
+	INET_DIAG_REQ_SK_BPF_STORAGES,
 	__INET_DIAG_REQ_MAX,
 };
 
@@ -155,6 +156,7 @@ enum {
 	INET_DIAG_CLASS_ID,	/* request as INET_DIAG_TCLASS */
 	INET_DIAG_MD5SIG,
 	INET_DIAG_ULP_INFO,
+	INET_DIAG_SK_BPF_STORAGES,
 	__INET_DIAG_MAX,
 };
 

commit 0df6d32842b9a5f97a29ea90c8adc5cfac38341d
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Tue Feb 25 15:04:15 2020 -0800

    inet_diag: Move the INET_DIAG_REQ_BYTECODE nlattr to cb->data
    
    The INET_DIAG_REQ_BYTECODE nlattr is currently re-found every time when
    the "dump()" is re-started.
    
    In a latter patch, it will also need to parse the new
    INET_DIAG_REQ_SK_BPF_STORAGES nlattr to learn the map_fds. Thus, this
    patch takes this chance to store the parsed nlattr in cb->data
    during the "start" time of a dump.
    
    By doing this, the "bc" argument also becomes unnecessary
    and is removed.  Also, the two copies of the INET_DIAG_REQ_BYTECODE
    parsing-audit logic between compat/current version can be
    consolidated to one.
    
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Song Liu <songliubraving@fb.com>
    Link: https://lore.kernel.org/bpf/20200225230415.1975555-1-kafai@fb.com

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index a1ff345b3f33..bab9a9f8da12 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -64,9 +64,10 @@ struct inet_diag_req_raw {
 enum {
 	INET_DIAG_REQ_NONE,
 	INET_DIAG_REQ_BYTECODE,
+	__INET_DIAG_REQ_MAX,
 };
 
-#define INET_DIAG_REQ_MAX INET_DIAG_REQ_BYTECODE
+#define INET_DIAG_REQ_MAX (__INET_DIAG_REQ_MAX - 1)
 
 /* Bytecode is sequence of 4 byte commands followed by variable arguments.
  * All the commands identified by "code" are conditional jumps forward:

commit 26811cc9f55acf835f7fdadc5ff2bbd6f06bc3ac
Author: Davide Caratti <dcaratti@redhat.com>
Date:   Fri Aug 30 12:25:49 2019 +0200

    net: tls: export protocol version, cipher, tx_conf/rx_conf to socket diag
    
    When an application configures kernel TLS on top of a TCP socket, it's
    now possible for inet_diag_handler() to collect information regarding the
    protocol version, the cipher type and TX / RX configuration, in case
    INET_DIAG_INFO is requested.
    
    Signed-off-by: Davide Caratti <dcaratti@redhat.com>
    Reviewed-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index e2c6273274f3..a1ff345b3f33 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -162,6 +162,7 @@ enum {
 enum {
 	INET_ULP_INFO_UNSPEC,
 	INET_ULP_INFO_NAME,
+	INET_ULP_INFO_TLS,
 	__INET_ULP_INFO_MAX,
 };
 #define INET_ULP_INFO_MAX (__INET_ULP_INFO_MAX - 1)

commit 61723b393292f1e4ea27f8d123384d50b176c29d
Author: Davide Caratti <dcaratti@redhat.com>
Date:   Fri Aug 30 12:25:48 2019 +0200

    tcp: ulp: add functions to dump ulp-specific information
    
    currently, only getsockopt(TCP_ULP) can be invoked to know if a ULP is on
    top of a TCP socket. Extend idiag_get_aux() and idiag_get_aux_size(),
    introduced by commit b37e88407c1d ("inet_diag: allow protocols to provide
    additional data"), to report the ULP name and other information that can
    be made available by the ULP through optional functions.
    
    Users having CAP_NET_ADMIN privileges will then be able to retrieve this
    information through inet_diag_handler, if they specify INET_DIAG_INFO in
    the request.
    
    Signed-off-by: Davide Caratti <dcaratti@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index e8baca85bac6..e2c6273274f3 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -153,11 +153,19 @@ enum {
 	INET_DIAG_BBRINFO,	/* request as INET_DIAG_VEGASINFO */
 	INET_DIAG_CLASS_ID,	/* request as INET_DIAG_TCLASS */
 	INET_DIAG_MD5SIG,
+	INET_DIAG_ULP_INFO,
 	__INET_DIAG_MAX,
 };
 
 #define INET_DIAG_MAX (__INET_DIAG_MAX - 1)
 
+enum {
+	INET_ULP_INFO_UNSPEC,
+	INET_ULP_INFO_NAME,
+	__INET_ULP_INFO_MAX,
+};
+#define INET_ULP_INFO_MAX (__INET_ULP_INFO_MAX - 1)
+
 /* INET_DIAG_MEM */
 
 struct inet_diag_meminfo {

commit 1ec17dbd90f8b638f41ee650558609c1af63dfa0
Author: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
Date:   Sat Feb 9 13:35:52 2019 +0300

    inet_diag: fix reporting cgroup classid and fallback to priority
    
    Field idiag_ext in struct inet_diag_req_v2 used as bitmap of requested
    extensions has only 8 bits. Thus extensions starting from DCTCPINFO
    cannot be requested directly. Some of them included into response
    unconditionally or hook into some of lower 8 bits.
    
    Extension INET_DIAG_CLASS_ID has not way to request from the beginning.
    
    This patch bundle it with INET_DIAG_TCLASS (ipv6 tos), fixes space
    reservation, and documents behavior for other extensions.
    
    Also this patch adds fallback to reporting socket priority. This filed
    is more widely used for traffic classification because ipv4 sockets
    automatically maps TOS to priority and default qdisc pfifo_fast knows
    about that. But priority could be changed via setsockopt SO_PRIORITY so
    INET_DIAG_TOS isn't enough for predicting class.
    
    Also cgroup2 obsoletes net_cls classid (it always zero), but we cannot
    reuse this field for reporting cgroup2 id because it is 64-bit (ino+gen).
    
    So, after this patch INET_DIAG_CLASS_ID will report socket priority
    for most common setup when net_cls isn't set and/or cgroup2 in use.
    
    Fixes: 0888e372c37f ("net: inet: diag: expose sockets cgroup classid")
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 14565d703291..e8baca85bac6 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -137,15 +137,21 @@ enum {
 	INET_DIAG_TCLASS,
 	INET_DIAG_SKMEMINFO,
 	INET_DIAG_SHUTDOWN,
-	INET_DIAG_DCTCPINFO,
-	INET_DIAG_PROTOCOL,  /* response attribute only */
+
+	/*
+	 * Next extenstions cannot be requested in struct inet_diag_req_v2:
+	 * its field idiag_ext has only 8 bits.
+	 */
+
+	INET_DIAG_DCTCPINFO,	/* request as INET_DIAG_VEGASINFO */
+	INET_DIAG_PROTOCOL,	/* response attribute only */
 	INET_DIAG_SKV6ONLY,
 	INET_DIAG_LOCALS,
 	INET_DIAG_PEERS,
 	INET_DIAG_PAD,
-	INET_DIAG_MARK,
-	INET_DIAG_BBRINFO,
-	INET_DIAG_CLASS_ID,
+	INET_DIAG_MARK,		/* only with CAP_NET_ADMIN */
+	INET_DIAG_BBRINFO,	/* request as INET_DIAG_VEGASINFO */
+	INET_DIAG_CLASS_ID,	/* request as INET_DIAG_TCLASS */
 	INET_DIAG_MD5SIG,
 	__INET_DIAG_MAX,
 };

commit bbb6189df4077cde8592cd2f804bb1122067dd32
Author: Kristian Evensen <kristian.evensen@gmail.com>
Date:   Wed Dec 27 18:27:58 2017 +0100

    inet_diag: Add equal-operator for ports
    
    inet_diag currently provides less/greater than or equal operators for
    comparing ports when filtering sockets. An equal comparison can be
    performed by combining the two existing operators, or a user can for
    example request a port range and then do the final filtering in
    userspace. However, these approaches both have drawbacks. Implementing
    equal using LE/GE causes the size and complexity of a filter to grow
    quickly as the number of ports increase, while it on busy machines would
    be great if the kernel only returns information about relevant sockets.
    
    This patch introduces source and destination port equal operators.
    INET_DIAG_BC_S_EQ is used to match a source port, INET_DIAG_BC_D_EQ a
    destination port, and usage is the same as for the existing port
    operators.  I.e., the port to match is stored in the no-member of the
    next inet_diag_bc_op-struct in the filter.
    
    Signed-off-by: Kristian Evensen <kristian.evensen@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 817d807e9481..14565d703291 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -92,6 +92,8 @@ enum {
 	INET_DIAG_BC_D_COND,
 	INET_DIAG_BC_DEV_COND,   /* u32 ifindex */
 	INET_DIAG_BC_MARK_COND,
+	INET_DIAG_BC_S_EQ,
+	INET_DIAG_BC_D_EQ,
 };
 
 struct inet_diag_hostcond {

commit 6f52b16c5b29b89d92c0e7236f4655dc8491ad70
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:08:43 2017 +0100

    License cleanup: add SPDX license identifier to uapi header files with no license
    
    Many user space API headers are missing licensing information, which
    makes it hard for compliance tools to determine the correct license.
    
    By default are files without license information under the default
    license of the kernel, which is GPLV2.  Marking them GPLV2 would exclude
    them from being included in non GPLV2 code, which is obviously not
    intended. The user space API headers fall under the syscall exception
    which is in the kernels COPYING file:
    
       NOTE! This copyright does *not* cover user programs that use kernel
       services by normal system calls - this is merely considered normal use
       of the kernel, and does *not* fall under the heading of "derived work".
    
    otherwise syscall usage would not be possible.
    
    Update the files which contain no license information with an SPDX
    license identifier.  The chosen identifier is 'GPL-2.0 WITH
    Linux-syscall-note' which is the officially assigned identifier for the
    Linux syscall exception.  SPDX license identifiers are a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.  See the previous patch in this series for the
    methodology of how this patch was researched.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index f52ff62bfabe..817d807e9481 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
 #ifndef _UAPI_INET_DIAG_H_
 #define _UAPI_INET_DIAG_H_
 

commit c03fa9bcacd9ac04595cc13f34f3445f0a5ecf13
Author: Ivan Delalande <colona@arista.com>
Date:   Thu Aug 31 09:59:39 2017 -0700

    tcp_diag: report TCP MD5 signing keys and addresses
    
    Report TCP MD5 (RFC2385) signing keys, addresses and address prefixes to
    processes with CAP_NET_ADMIN requesting INET_DIAG_INFO. Currently it is
    not possible to retrieve these from the kernel once they have been
    configured on sockets.
    
    Signed-off-by: Ivan Delalande <colona@arista.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 678496897a68..f52ff62bfabe 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -143,6 +143,7 @@ enum {
 	INET_DIAG_MARK,
 	INET_DIAG_BBRINFO,
 	INET_DIAG_CLASS_ID,
+	INET_DIAG_MD5SIG,
 	__INET_DIAG_MAX,
 };
 

commit 0888e372c37fa31882c8ed89fb2f8188b08b6718
Author: Levin, Alexander (Sasha Levin) <alexander.levin@one.verizon.com>
Date:   Thu Aug 17 00:35:11 2017 +0000

    net: inet: diag: expose sockets cgroup classid
    
    This is useful for directly looking up a task based on class id rather than
    having to scan through all open file descriptors.
    
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index bbe201047df6..678496897a68 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -142,6 +142,7 @@ enum {
 	INET_DIAG_PAD,
 	INET_DIAG_MARK,
 	INET_DIAG_BBRINFO,
+	INET_DIAG_CLASS_ID,
 	__INET_DIAG_MAX,
 };
 

commit 432490f9d455fb842d70219f22d9d2c812371676
Author: Cyrill Gorcunov <gorcunov@gmail.com>
Date:   Fri Oct 21 13:03:44 2016 +0300

    net: ip, diag -- Add diag interface for raw sockets
    
    In criu we are actively using diag interface to collect sockets
    present in the system when dumping applications. And while for
    unix, tcp, udp[lite], packet, netlink it works as expected,
    the raw sockets do not have. Thus add it.
    
    v2:
     - add missing sock_put calls in raw_diag_dump_one (by eric.dumazet@)
     - implement @destroy for diag requests (by dsa@)
    
    v3:
     - add export of raw_abort for IPv6 (by dsa@)
     - pass net-admin flag into inet_sk_diag_fill due to
       changes in net-next branch (by dsa@)
    
    v4:
     - use @pad in struct inet_diag_req_v2 for raw socket
       protocol specification: raw module carries sockets
       which may have custom protocol passed from socket()
       syscall and sole @sdiag_protocol is not enough to
       match underlied ones
     - start reporting protocol specifed in socket() call
       when sockets are raw ones for the same reason: user
       space tools like ss may parse this attribute and use
       it for socket matching
    
    v5 (by eric.dumazet@):
     - use sock_hold in raw_sock_get instead of atomic_inc,
       we're holding (raw_v4_hashinfo|raw_v6_hashinfo)->lock
       when looking up so counter won't be zero here.
    
    v6:
     - use sdiag_raw_protocol() helper which will access @pad
       structure used for raw sockets protocol specification:
       we can't simply rename this member without breaking uapi
    
    v7:
     - sine sdiag_raw_protocol() helper is not suitable for
       uapi lets rather make an alias structure with proper
       names. __check_inet_diag_req_raw helper will catch
       if any of structure unintentionally changed.
    
    CC: David S. Miller <davem@davemloft.net>
    CC: Eric Dumazet <eric.dumazet@gmail.com>
    CC: David Ahern <dsa@cumulusnetworks.com>
    CC: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    CC: James Morris <jmorris@namei.org>
    CC: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    CC: Patrick McHardy <kaber@trash.net>
    CC: Andrey Vagin <avagin@openvz.org>
    CC: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 509cd961068d..bbe201047df6 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -43,6 +43,23 @@ struct inet_diag_req_v2 {
 	struct inet_diag_sockid id;
 };
 
+/*
+ * SOCK_RAW sockets require the underlied protocol to be
+ * additionally specified so we can use @pad member for
+ * this, but we can't rename it because userspace programs
+ * still may depend on this name. Instead lets use another
+ * structure definition as an alias for struct
+ * @inet_diag_req_v2.
+ */
+struct inet_diag_req_raw {
+	__u8	sdiag_family;
+	__u8	sdiag_protocol;
+	__u8	idiag_ext;
+	__u8	sdiag_raw_protocol;
+	__u32	idiag_states;
+	struct inet_diag_sockid id;
+};
+
 enum {
 	INET_DIAG_REQ_NONE,
 	INET_DIAG_REQ_BYTECODE,

commit 0f8782ea14974ce992618b55f0c041ef43ed0b78
Author: Neal Cardwell <ncardwell@google.com>
Date:   Mon Sep 19 23:39:23 2016 -0400

    tcp_bbr: add BBR congestion control
    
    This commit implements a new TCP congestion control algorithm: BBR
    (Bottleneck Bandwidth and RTT). A detailed description of BBR will be
    published in ACM Queue, Vol. 14 No. 5, September-October 2016, as
    "BBR: Congestion-Based Congestion Control".
    
    BBR has significantly increased throughput and reduced latency for
    connections on Google's internal backbone networks and google.com and
    YouTube Web servers.
    
    BBR requires only changes on the sender side, not in the network or
    the receiver side. Thus it can be incrementally deployed on today's
    Internet, or in datacenters.
    
    The Internet has predominantly used loss-based congestion control
    (largely Reno or CUBIC) since the 1980s, relying on packet loss as the
    signal to slow down. While this worked well for many years, loss-based
    congestion control is unfortunately out-dated in today's networks. On
    today's Internet, loss-based congestion control causes the infamous
    bufferbloat problem, often causing seconds of needless queuing delay,
    since it fills the bloated buffers in many last-mile links. On today's
    high-speed long-haul links using commodity switches with shallow
    buffers, loss-based congestion control has abysmal throughput because
    it over-reacts to losses caused by transient traffic bursts.
    
    In 1981 Kleinrock and Gale showed that the optimal operating point for
    a network maximizes delivered bandwidth while minimizing delay and
    loss, not only for single connections but for the network as a
    whole. Finding that optimal operating point has been elusive, since
    any single network measurement is ambiguous: network measurements are
    the result of both bandwidth and propagation delay, and those two
    cannot be measured simultaneously.
    
    While it is impossible to disambiguate any single bandwidth or RTT
    measurement, a connection's behavior over time tells a clearer
    story. BBR uses a measurement strategy designed to resolve this
    ambiguity. It combines these measurements with a robust servo loop
    using recent control systems advances to implement a distributed
    congestion control algorithm that reacts to actual congestion, not
    packet loss or transient queue delay, and is designed to converge with
    high probability to a point near the optimal operating point.
    
    In a nutshell, BBR creates an explicit model of the network pipe by
    sequentially probing the bottleneck bandwidth and RTT. On the arrival
    of each ACK, BBR derives the current delivery rate of the last round
    trip, and feeds it through a windowed max-filter to estimate the
    bottleneck bandwidth. Conversely it uses a windowed min-filter to
    estimate the round trip propagation delay. The max-filtered bandwidth
    and min-filtered RTT estimates form BBR's model of the network pipe.
    
    Using its model, BBR sets control parameters to govern sending
    behavior. The primary control is the pacing rate: BBR applies a gain
    multiplier to transmit faster or slower than the observed bottleneck
    bandwidth. The conventional congestion window (cwnd) is now the
    secondary control; the cwnd is set to a small multiple of the
    estimated BDP (bandwidth-delay product) in order to allow full
    utilization and bandwidth probing while bounding the potential amount
    of queue at the bottleneck.
    
    When a BBR connection starts, it enters STARTUP mode and applies a
    high gain to perform an exponential search to quickly probe the
    bottleneck bandwidth (doubling its sending rate each round trip, like
    slow start). However, instead of continuing until it fills up the
    buffer (i.e. a loss), or until delay or ACK spacing reaches some
    threshold (like Hystart), it uses its model of the pipe to estimate
    when that pipe is full: it estimates the pipe is full when it notices
    the estimated bandwidth has stopped growing. At that point it exits
    STARTUP and enters DRAIN mode, where it reduces its pacing rate to
    drain the queue it estimates it has created.
    
    Then BBR enters steady state. In steady state, PROBE_BW mode cycles
    between first pacing faster to probe for more bandwidth, then pacing
    slower to drain any queue that created if no more bandwidth was
    available, and then cruising at the estimated bandwidth to utilize the
    pipe without creating excess queue. Occasionally, on an as-needed
    basis, it sends significantly slower to probe for RTT (PROBE_RTT
    mode).
    
    BBR has been fully deployed on Google's wide-area backbone networks
    and we're experimenting with BBR on Google.com and YouTube on a global
    scale.  Replacing CUBIC with BBR has resulted in significant
    improvements in network latency and application (RPC, browser, and
    video) metrics. For more details please refer to our upcoming ACM
    Queue publication.
    
    Example performance results, to illustrate the difference between BBR
    and CUBIC:
    
    Resilience to random loss (e.g. from shallow buffers):
      Consider a netperf TCP_STREAM test lasting 30 secs on an emulated
      path with a 10Gbps bottleneck, 100ms RTT, and 1% packet loss
      rate. CUBIC gets 3.27 Mbps, and BBR gets 9150 Mbps (2798x higher).
    
    Low latency with the bloated buffers common in today's last-mile links:
      Consider a netperf TCP_STREAM test lasting 120 secs on an emulated
      path with a 10Mbps bottleneck, 40ms RTT, and 1000-packet bottleneck
      buffer. Both fully utilize the bottleneck bandwidth, but BBR
      achieves this with a median RTT 25x lower (43 ms instead of 1.09
      secs).
    
    Our long-term goal is to improve the congestion control algorithms
    used on the Internet. We are hopeful that BBR can help advance the
    efforts toward this goal, and motivate the community to do further
    research.
    
    Test results, performance evaluations, feedback, and BBR-related
    discussions are very welcome in the public e-mail list for BBR:
    
      https://groups.google.com/forum/#!forum/bbr-dev
    
    NOTE: BBR *must* be used with the fq qdisc ("man tc-fq") with pacing
    enabled, since pacing is integral to the BBR design and
    implementation. BBR without pacing would not function properly, and
    may incur unnecessary high packet loss rates.
    
    Signed-off-by: Van Jacobson <vanj@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Nandita Dukkipati <nanditad@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index b5c366f87b3e..509cd961068d 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -124,6 +124,7 @@ enum {
 	INET_DIAG_PEERS,
 	INET_DIAG_PAD,
 	INET_DIAG_MARK,
+	INET_DIAG_BBRINFO,
 	__INET_DIAG_MAX,
 };
 
@@ -157,8 +158,20 @@ struct tcp_dctcp_info {
 	__u32	dctcp_ab_tot;
 };
 
+/* INET_DIAG_BBRINFO */
+
+struct tcp_bbr_info {
+	/* u64 bw: max-filtered BW (app throughput) estimate in Byte per sec: */
+	__u32	bbr_bw_lo;		/* lower 32 bits of bw */
+	__u32	bbr_bw_hi;		/* upper 32 bits of bw */
+	__u32	bbr_min_rtt;		/* min-filtered RTT in uSec */
+	__u32	bbr_pacing_gain;	/* pacing gain shifted left 8 bits */
+	__u32	bbr_cwnd_gain;		/* cwnd gain shifted left 8 bits */
+};
+
 union tcp_cc_info {
 	struct tcpvegas_info	vegas;
 	struct tcp_dctcp_info	dctcp;
+	struct tcp_bbr_info	bbr;
 };
 #endif /* _UAPI_INET_DIAG_H_ */

commit d545caca827b65aab557a9e9dcdcf1e5a3823c2d
Author: Lorenzo Colitti <lorenzo@google.com>
Date:   Thu Sep 8 00:42:25 2016 +0900

    net: inet: diag: expose the socket mark to privileged processes.
    
    This adds the capability for a process that has CAP_NET_ADMIN on
    a socket to see the socket mark in socket dumps.
    
    Commit a52e95abf772 ("net: diag: allow socket bytecode filters to
    match socket marks") recently gave privileged processes the
    ability to filter socket dumps based on mark. This patch is
    complementary: it ensures that the mark is also passed to
    userspace in the socket's netlink attributes.  It is useful for
    tools like ss which display information about sockets.
    
    Tested: https://android-review.googlesource.com/270210
    Signed-off-by: Lorenzo Colitti <lorenzo@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 5581206a08ae..b5c366f87b3e 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -123,6 +123,7 @@ enum {
 	INET_DIAG_LOCALS,
 	INET_DIAG_PEERS,
 	INET_DIAG_PAD,
+	INET_DIAG_MARK,
 	__INET_DIAG_MAX,
 };
 

commit a52e95abf772b43c9226e9a72d3c1353903ba96f
Author: Lorenzo Colitti <lorenzo@google.com>
Date:   Wed Aug 24 15:46:26 2016 +0900

    net: diag: allow socket bytecode filters to match socket marks
    
    This allows a privileged process to filter by socket mark when
    dumping sockets via INET_DIAG_BY_FAMILY. This is useful on
    systems that use mark-based routing such as Android.
    
    The ability to filter socket marks requires CAP_NET_ADMIN, which
    is consistent with other privileged operations allowed by the
    SOCK_DIAG interface such as the ability to destroy sockets and
    the ability to inspect BPF filters attached to packet sockets.
    
    Tested: https://android-review.googlesource.com/261350
    Signed-off-by: Lorenzo Colitti <lorenzo@google.com>
    Acked-by: David Ahern <dsa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index abbd1dc5d683..5581206a08ae 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -73,6 +73,7 @@ enum {
 	INET_DIAG_BC_S_COND,
 	INET_DIAG_BC_D_COND,
 	INET_DIAG_BC_DEV_COND,   /* u32 ifindex */
+	INET_DIAG_BC_MARK_COND,
 };
 
 struct inet_diag_hostcond {
@@ -82,6 +83,11 @@ struct inet_diag_hostcond {
 	__be32	addr[0];
 };
 
+struct inet_diag_markcond {
+	__u32 mark;
+	__u32 mask;
+};
+
 /* Base info structure. It contains socket identity (addrs/ports/cookie)
  * and, alas, the information shown by netstat. */
 struct inet_diag_msg {

commit 637c841dd7a5f9bd97b75cbe90b526fa1a52e530
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Thu Jun 23 18:42:51 2016 -0700

    net: diag: Add support to filter on device index
    
    Add support to inet_diag facility to filter sockets based on device
    index. If an interface index is in the filter only sockets bound
    to that index (sk_bound_dev_if) are returned.
    
    Signed-off-by: David Ahern <dsa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index a16643705669..abbd1dc5d683 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -72,6 +72,7 @@ enum {
 	INET_DIAG_BC_AUTO,
 	INET_DIAG_BC_S_COND,
 	INET_DIAG_BC_D_COND,
+	INET_DIAG_BC_DEV_COND,   /* u32 ifindex */
 };
 
 struct inet_diag_hostcond {

commit 6ed46d1247a595c58b6c04481fa77cf532f45de0
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Tue Apr 26 10:06:14 2016 +0200

    sock_diag: align nlattr properly when needed
    
    I also fix the value of INET_DIAG_MAX. It's wrong since commit 8f840e47f190
    which is only in net-next right now, thus I didn't make a separate patch.
    
    Fixes: 8f840e47f190 ("sctp: add the sctp_diag.c file")
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index f5f3629dd553..a16643705669 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -115,9 +115,11 @@ enum {
 	INET_DIAG_SKV6ONLY,
 	INET_DIAG_LOCALS,
 	INET_DIAG_PEERS,
+	INET_DIAG_PAD,
+	__INET_DIAG_MAX,
 };
 
-#define INET_DIAG_MAX INET_DIAG_SKV6ONLY
+#define INET_DIAG_MAX (__INET_DIAG_MAX - 1)
 
 /* INET_DIAG_MEM */
 

commit 8f840e47f190cbe61a96945c13e9551048d42cef
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Apr 14 15:35:33 2016 +0800

    sctp: add the sctp_diag.c file
    
    This one will implement all the interface of inet_diag, inet_diag_handler.
    which includes sctp_diag_dump, sctp_diag_dump_one and sctp_diag_get_info.
    
    It will work as a module, and register inet_diag_handler when loading.
    
    v2->v3:
    - fix the mistake in inet_assoc_attr_size().
    
    - change inet_diag_msg_laddrs_fill() name to inet_diag_msg_sctpladdrs_fill.
    
    - change inet_diag_msg_paddrs_fill() name to inet_diag_msg_sctpaddrs_fill.
    
    - add inet_diag_msg_sctpinfo_fill() to make asoc/ep fill code clearer.
    
    - add inet_diag_msg_sctpasoc_fill() to make asoc fill code clearer.
    
    - merge inet_asoc_diag_fill() and inet_ep_diag_fill() to
      inet_sctp_diag_fill().
    
    - call sctp_diag_get_info() directly, instead by handler, cause the caller
      is in the same file with it.
    
    - call lock_sock in sctp_tsp_dump_one() to make sure we call get sctp info
      safely.
    
    - after lock_sock(sk), we should check sk != assoc->base.sk.
    
    - change mem[SK_MEMINFO_WMEM_ALLOC] to asoc->sndbuf_used for asoc dump when
      asoc->ep->sndbuf_policy is set. don't use INET_DIAG_MEMINFO attr any more.
    
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 68a1f71fde9f..f5f3629dd553 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -113,6 +113,8 @@ enum {
 	INET_DIAG_DCTCPINFO,
 	INET_DIAG_PROTOCOL,  /* response attribute only */
 	INET_DIAG_SKV6ONLY,
+	INET_DIAG_LOCALS,
+	INET_DIAG_PEERS,
 };
 
 #define INET_DIAG_MAX INET_DIAG_SKV6ONLY

commit 204621551b2a0060a013b92f7add4d5c452fa7cb
Author: Phil Sutter <phil@nwl.cc>
Date:   Wed Jun 24 11:02:51 2015 +0200

    net: inet_diag: export IPV6_V6ONLY sockopt
    
    For AF_INET6 sockets, the value of struct ipv6_pinfo.ipv6only is
    exported to userspace. It indicates whether a socket bound to in6addr_any
    listens on IPv4 as well as IPv6. Since the socket is natively IPv6, it is not
    listed by e.g. 'ss -l -4'.
    
    This patch is accompanied by an appropriate one for iproute2 to enable
    the additional information in 'ss -e'.
    
    Signed-off-by: Phil Sutter <phil@nwl.cc>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index b629fc53b109..68a1f71fde9f 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -112,9 +112,10 @@ enum {
 	INET_DIAG_SHUTDOWN,
 	INET_DIAG_DCTCPINFO,
 	INET_DIAG_PROTOCOL,  /* response attribute only */
+	INET_DIAG_SKV6ONLY,
 };
 
-#define INET_DIAG_MAX INET_DIAG_PROTOCOL
+#define INET_DIAG_MAX INET_DIAG_SKV6ONLY
 
 /* INET_DIAG_MEM */
 

commit 35ac838a9b96470f999db04320f53a2033642bfb
Author: Craig Gallek <kraig@google.com>
Date:   Mon Jun 15 11:26:20 2015 -0400

    sock_diag: implement a get_info handler for inet
    
    This get_info handler will simply dispatch to the appropriate
    existing inet protocol handler.
    
    This patch also includes a new netlink attribute
    (INET_DIAG_PROTOCOL).  This attribute is currently only used
    for multicast messages.  Without this attribute, there is no
    way of knowing the IP protocol used by the socket information
    being broadcast.  This attribute is not necessary in the 'dump'
    variant of this protocol (though it could easily be added)
    because dump requests are issued for specific family/protocol
    pairs.
    
    Tested: ss -E (note, the -E option has not yet been merged into
    the upstream version of ss).
    
    Signed-off-by: Craig Gallek <kraig@google.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index c7093c75bdd6..b629fc53b109 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -111,9 +111,10 @@ enum {
 	INET_DIAG_SKMEMINFO,
 	INET_DIAG_SHUTDOWN,
 	INET_DIAG_DCTCPINFO,
+	INET_DIAG_PROTOCOL,  /* response attribute only */
 };
 
-#define INET_DIAG_MAX INET_DIAG_DCTCPINFO
+#define INET_DIAG_MAX INET_DIAG_PROTOCOL
 
 /* INET_DIAG_MEM */
 

commit 64f40ff5bbdb1b679fb3c4dbc8230d6517d2b8dc
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Apr 28 16:23:48 2015 -0700

    tcp: prepare CC get_info() access from getsockopt()
    
    We would like that optional info provided by Congestion Control
    modules using netlink can also be read using getsockopt()
    
    This patch changes get_info() to put this information in a buffer,
    instead of skb, like tcp_get_info(), so that following patch
    can reuse this common infrastructure.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Yuchung Cheng <ycheng@google.com>
    Cc: Neal Cardwell <ncardwell@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index d65c0a09efd3..c7093c75bdd6 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -143,4 +143,8 @@ struct tcp_dctcp_info {
 	__u32	dctcp_ab_tot;
 };
 
+union tcp_cc_info {
+	struct tcpvegas_info	vegas;
+	struct tcp_dctcp_info	dctcp;
+};
 #endif /* _UAPI_INET_DIAG_H_ */

commit e3118e8359bb7c59555aca60c725106e6d78c5ce
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Fri Sep 26 22:37:36 2014 +0200

    net: tcp: add DCTCP congestion control algorithm
    
    This work adds the DataCenter TCP (DCTCP) congestion control
    algorithm [1], which has been first published at SIGCOMM 2010 [2],
    resp. follow-up analysis at SIGMETRICS 2011 [3] (and also, more
    recently as an informational IETF draft available at [4]).
    
    DCTCP is an enhancement to the TCP congestion control algorithm for
    data center networks. Typical data center workloads are i.e.
    i) partition/aggregate (queries; bursty, delay sensitive), ii) short
    messages e.g. 50KB-1MB (for coordination and control state; delay
    sensitive), and iii) large flows e.g. 1MB-100MB (data update;
    throughput sensitive). DCTCP has therefore been designed for such
    environments to provide/achieve the following three requirements:
    
      * High burst tolerance (incast due to partition/aggregate)
      * Low latency (short flows, queries)
      * High throughput (continuous data updates, large file
        transfers) with commodity, shallow buffered switches
    
    The basic idea of its design consists of two fundamentals: i) on the
    switch side, packets are being marked when its internal queue
    length > threshold K (K is chosen so that a large enough headroom
    for marked traffic is still available in the switch queue); ii) the
    sender/host side maintains a moving average of the fraction of marked
    packets, so each RTT, F is being updated as follows:
    
     F := X / Y, where X is # of marked ACKs, Y is total # of ACKs
     alpha := (1 - g) * alpha + g * F, where g is a smoothing constant
    
    The resulting alpha (iow: probability that switch queue is congested)
    is then being used in order to adaptively decrease the congestion
    window W:
    
     W := (1 - (alpha / 2)) * W
    
    The means for receiving marked packets resp. marking them on switch
    side in DCTCP is the use of ECN.
    
    RFC3168 describes a mechanism for using Explicit Congestion Notification
    from the switch for early detection of congestion, rather than waiting
    for segment loss to occur.
    
    However, this method only detects the presence of congestion, not
    the *extent*. In the presence of mild congestion, it reduces the TCP
    congestion window too aggressively and unnecessarily affects the
    throughput of long flows [4].
    
    DCTCP, as mentioned, enhances Explicit Congestion Notification (ECN)
    processing to estimate the fraction of bytes that encounter congestion,
    rather than simply detecting that some congestion has occurred. DCTCP
    then scales the TCP congestion window based on this estimate [4],
    thus it can derive multibit feedback from the information present in
    the single-bit sequence of marks in its control law. And thus act in
    *proportion* to the extent of congestion, not its *presence*.
    
    Switches therefore set the Congestion Experienced (CE) codepoint in
    packets when internal queue lengths exceed threshold K. Resulting,
    DCTCP delivers the same or better throughput than normal TCP, while
    using 90% less buffer space.
    
    It was found in [2] that DCTCP enables the applications to handle 10x
    the current background traffic, without impacting foreground traffic.
    Moreover, a 10x increase in foreground traffic did not cause any
    timeouts, and thus largely eliminates TCP incast collapse problems.
    
    The algorithm itself has already seen deployments in large production
    data centers since then.
    
    We did a long-term stress-test and analysis in a data center, short
    summary of our TCP incast tests with iperf compared to cubic:
    
    This test measured DCTCP throughput and latency and compared it with
    CUBIC throughput and latency for an incast scenario. In this test, 19
    senders sent at maximum rate to a single receiver. The receiver simply
    ran iperf -s.
    
    The senders ran iperf -c <receiver> -t 30. All senders started
    simultaneously (using local clocks synchronized by ntp).
    
    This test was repeated multiple times. Below shows the results from a
    single test. Other tests are similar. (DCTCP results were extremely
    consistent, CUBIC results show some variance induced by the TCP timeouts
    that CUBIC encountered.)
    
    For this test, we report statistics on the number of TCP timeouts,
    flow throughput, and traffic latency.
    
    1) Timeouts (total over all flows, and per flow summaries):
    
                CUBIC            DCTCP
      Total     3227             25
      Mean       169.842          1.316
      Median     183              1
      Max        207              5
      Min        123              0
      Stddev      28.991          1.600
    
    Timeout data is taken by measuring the net change in netstat -s
    "other TCP timeouts" reported. As a result, the timeout measurements
    above are not restricted to the test traffic, and we believe that it
    is likely that all of the "DCTCP timeouts" are actually timeouts for
    non-test traffic. We report them nevertheless. CUBIC will also include
    some non-test timeouts, but they are drawfed by bona fide test traffic
    timeouts for CUBIC. Clearly DCTCP does an excellent job of preventing
    TCP timeouts. DCTCP reduces timeouts by at least two orders of
    magnitude and may well have eliminated them in this scenario.
    
    2) Throughput (per flow in Mbps):
    
                CUBIC            DCTCP
      Mean      521.684          521.895
      Median    464              523
      Max       776              527
      Min       403              519
      Stddev    105.891            2.601
      Fairness    0.962            0.999
    
    Throughput data was simply the average throughput for each flow
    reported by iperf. By avoiding TCP timeouts, DCTCP is able to
    achieve much better per-flow results. In CUBIC, many flows
    experience TCP timeouts which makes flow throughput unpredictable and
    unfair. DCTCP, on the other hand, provides very clean predictable
    throughput without incurring TCP timeouts. Thus, the standard deviation
    of CUBIC throughput is dramatically higher than the standard deviation
    of DCTCP throughput.
    
    Mean throughput is nearly identical because even though cubic flows
    suffer TCP timeouts, other flows will step in and fill the unused
    bandwidth. Note that this test is something of a best case scenario
    for incast under CUBIC: it allows other flows to fill in for flows
    experiencing a timeout. Under situations where the receiver is issuing
    requests and then waiting for all flows to complete, flows cannot fill
    in for timed out flows and throughput will drop dramatically.
    
    3) Latency (in ms):
    
                CUBIC            DCTCP
      Mean      4.0088           0.04219
      Median    4.055            0.0395
      Max       4.2              0.085
      Min       3.32             0.028
      Stddev    0.1666           0.01064
    
    Latency for each protocol was computed by running "ping -i 0.2
    <receiver>" from a single sender to the receiver during the incast
    test. For DCTCP, "ping -Q 0x6 -i 0.2 <receiver>" was used to ensure
    that traffic traversed the DCTCP queue and was not dropped when the
    queue size was greater than the marking threshold. The summary
    statistics above are over all ping metrics measured between the single
    sender, receiver pair.
    
    The latency results for this test show a dramatic difference between
    CUBIC and DCTCP. CUBIC intentionally overflows the switch buffer
    which incurs the maximum queue latency (more buffer memory will lead
    to high latency.) DCTCP, on the other hand, deliberately attempts to
    keep queue occupancy low. The result is a two orders of magnitude
    reduction of latency with DCTCP - even with a switch with relatively
    little RAM. Switches with larger amounts of RAM will incur increasing
    amounts of latency for CUBIC, but not for DCTCP.
    
    4) Convergence and stability test:
    
    This test measured the time that DCTCP took to fairly redistribute
    bandwidth when a new flow commences. It also measured DCTCP's ability
    to remain stable at a fair bandwidth distribution. DCTCP is compared
    with CUBIC for this test.
    
    At the commencement of this test, a single flow is sending at maximum
    rate (near 10 Gbps) to a single receiver. One second after that first
    flow commences, a new flow from a distinct server begins sending to
    the same receiver as the first flow. After the second flow has sent
    data for 10 seconds, the second flow is terminated. The first flow
    sends for an additional second. Ideally, the bandwidth would be evenly
    shared as soon as the second flow starts, and recover as soon as it
    stops.
    
    The results of this test are shown below. Note that the flow bandwidth
    for the two flows was measured near the same time, but not
    simultaneously.
    
    DCTCP performs nearly perfectly within the measurement limitations
    of this test: bandwidth is quickly distributed fairly between the two
    flows, remains stable throughout the duration of the test, and
    recovers quickly. CUBIC, in contrast, is slow to divide the bandwidth
    fairly, and has trouble remaining stable.
    
      CUBIC                      DCTCP
    
      Seconds  Flow 1  Flow 2    Seconds  Flow 1  Flow 2
       0       9.93    0          0       9.92    0
       0.5     9.87    0          0.5     9.86    0
       1       8.73    2.25       1       6.46    4.88
       1.5     7.29    2.8        1.5     4.9     4.99
       2       6.96    3.1        2       4.92    4.94
       2.5     6.67    3.34       2.5     4.93    5
       3       6.39    3.57       3       4.92    4.99
       3.5     6.24    3.75       3.5     4.94    4.74
       4       6       3.94       4       5.34    4.71
       4.5     5.88    4.09       4.5     4.99    4.97
       5       5.27    4.98       5       4.83    5.01
       5.5     4.93    5.04       5.5     4.89    4.99
       6       4.9     4.99       6       4.92    5.04
       6.5     4.93    5.1        6.5     4.91    4.97
       7       4.28    5.8        7       4.97    4.97
       7.5     4.62    4.91       7.5     4.99    4.82
       8       5.05    4.45       8       5.16    4.76
       8.5     5.93    4.09       8.5     4.94    4.98
       9       5.73    4.2        9       4.92    5.02
       9.5     5.62    4.32       9.5     4.87    5.03
      10       6.12    3.2       10       4.91    5.01
      10.5     6.91    3.11      10.5     4.87    5.04
      11       8.48    0         11       8.49    4.94
      11.5     9.87    0         11.5     9.9     0
    
    SYN/ACK ECT test:
    
    This test demonstrates the importance of ECT on SYN and SYN-ACK packets
    by measuring the connection probability in the presence of competing
    flows for a DCTCP connection attempt *without* ECT in the SYN packet.
    The test was repeated five times for each number of competing flows.
    
                  Competing Flows  1 |    2 |    4 |    8 |   16
                                   ------------------------------
    Mean Connection Probability    1 | 0.67 | 0.45 | 0.28 |    0
    Median Connection Probability  1 | 0.65 | 0.45 | 0.25 |    0
    
    As the number of competing flows moves beyond 1, the connection
    probability drops rapidly.
    
    Enabling DCTCP with this patch requires the following steps:
    
    DCTCP must be running both on the sender and receiver side in your
    data center, i.e.:
    
      sysctl -w net.ipv4.tcp_congestion_control=dctcp
    
    Also, ECN functionality must be enabled on all switches in your
    data center for DCTCP to work. The default ECN marking threshold (K)
    heuristic on the switch for DCTCP is e.g., 20 packets (30KB) at
    1Gbps, and 65 packets (~100KB) at 10Gbps (K > 1/7 * C * RTT, [4]).
    
    In above tests, for each switch port, traffic was segregated into two
    queues. For any packet with a DSCP of 0x01 - or equivalently a TOS of
    0x04 - the packet was placed into the DCTCP queue. All other packets
    were placed into the default drop-tail queue. For the DCTCP queue,
    RED/ECN marking was enabled, here, with a marking threshold of 75 KB.
    More details however, we refer you to the paper [2] under section 3).
    
    There are no code changes required to applications running in user
    space. DCTCP has been implemented in full *isolation* of the rest of
    the TCP code as its own congestion control module, so that it can run
    without a need to expose code to the core of the TCP stack, and thus
    nothing changes for non-DCTCP users.
    
    Changes in the CA framework code are minimal, and DCTCP algorithm
    operates on mechanisms that are already available in most Silicon.
    The gain (dctcp_shift_g) is currently a fixed constant (1/16) from
    the paper, but we leave the option that it can be chosen carefully
    to a different value by the user.
    
    In case DCTCP is being used and ECN support on peer site is off,
    DCTCP falls back after 3WHS to operate in normal TCP Reno mode.
    
    ss {-4,-6} -t -i diag interface:
    
      ... dctcp wscale:7,7 rto:203 rtt:2.349/0.026 mss:1448 cwnd:2054
      ssthresh:1102 ce_state 0 alpha 15 ab_ecn 0 ab_tot 735584
      send 10129.2Mbps pacing_rate 20254.1Mbps unacked:1822 retrans:0/15
      reordering:101 rcv_space:29200
    
      ... dctcp-reno wscale:7,7 rto:201 rtt:0.711/1.327 ato:40 mss:1448
      cwnd:10 ssthresh:1102 fallback_mode send 162.9Mbps pacing_rate
      325.5Mbps rcv_rtt:1.5 rcv_space:29200
    
    More information about DCTCP can be found in [1-4].
    
      [1] http://simula.stanford.edu/~alizade/Site/DCTCP.html
      [2] http://simula.stanford.edu/~alizade/Site/DCTCP_files/dctcp-final.pdf
      [3] http://simula.stanford.edu/~alizade/Site/DCTCP_files/dctcp_analysis-full.pdf
      [4] http://tools.ietf.org/html/draft-bensley-tcpm-dctcp-00
    
    Joint work with Florian Westphal and Glenn Judd.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Glenn Judd <glenn.judd@morganstanley.com>
    Acked-by: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index bbde90fa5838..d65c0a09efd3 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -110,10 +110,10 @@ enum {
 	INET_DIAG_TCLASS,
 	INET_DIAG_SKMEMINFO,
 	INET_DIAG_SHUTDOWN,
+	INET_DIAG_DCTCPINFO,
 };
 
-#define INET_DIAG_MAX INET_DIAG_SHUTDOWN
-
+#define INET_DIAG_MAX INET_DIAG_DCTCPINFO
 
 /* INET_DIAG_MEM */
 
@@ -133,5 +133,14 @@ struct tcpvegas_info {
 	__u32	tcpv_minrtt;
 };
 
+/* INET_DIAG_DCTCPINFO */
+
+struct tcp_dctcp_info {
+	__u16	dctcp_enabled;
+	__u16	dctcp_ce_state;
+	__u32	dctcp_alpha;
+	__u32	dctcp_ab_ecn;
+	__u32	dctcp_ab_tot;
+};
 
 #endif /* _UAPI_INET_DIAG_H_ */

commit e4e541a84863b6a41f2427f59cc9156c644491a8
Author: Pavel Emelyanov <xemul@parallels.com>
Date:   Tue Oct 23 22:29:56 2012 +0400

    sock-diag: Report shutdown for inet and unix sockets (v2)
    
    Make it simple -- just put new nlattr with just sk->sk_shutdown bits.
    
    Signed-off-by: Pavel Emelyanov <xemul@parallels.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 8c469af939aa..bbde90fa5838 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -109,9 +109,10 @@ enum {
 	INET_DIAG_TOS,
 	INET_DIAG_TCLASS,
 	INET_DIAG_SKMEMINFO,
+	INET_DIAG_SHUTDOWN,
 };
 
-#define INET_DIAG_MAX INET_DIAG_SKMEMINFO
+#define INET_DIAG_MAX INET_DIAG_SHUTDOWN
 
 
 /* INET_DIAG_MEM */

commit 607ca46e97a1b6594b29647d98a32d545c24bdff
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 13 10:46:48 2012 +0100

    UAPI: (Scripted) Disintegrate include/linux
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
new file mode 100644
index 000000000000..8c469af939aa
--- /dev/null
+++ b/include/uapi/linux/inet_diag.h
@@ -0,0 +1,136 @@
+#ifndef _UAPI_INET_DIAG_H_
+#define _UAPI_INET_DIAG_H_
+
+#include <linux/types.h>
+
+/* Just some random number */
+#define TCPDIAG_GETSOCK 18
+#define DCCPDIAG_GETSOCK 19
+
+#define INET_DIAG_GETSOCK_MAX 24
+
+/* Socket identity */
+struct inet_diag_sockid {
+	__be16	idiag_sport;
+	__be16	idiag_dport;
+	__be32	idiag_src[4];
+	__be32	idiag_dst[4];
+	__u32	idiag_if;
+	__u32	idiag_cookie[2];
+#define INET_DIAG_NOCOOKIE (~0U)
+};
+
+/* Request structure */
+
+struct inet_diag_req {
+	__u8	idiag_family;		/* Family of addresses. */
+	__u8	idiag_src_len;
+	__u8	idiag_dst_len;
+	__u8	idiag_ext;		/* Query extended information */
+
+	struct inet_diag_sockid id;
+
+	__u32	idiag_states;		/* States to dump */
+	__u32	idiag_dbs;		/* Tables to dump (NI) */
+};
+
+struct inet_diag_req_v2 {
+	__u8	sdiag_family;
+	__u8	sdiag_protocol;
+	__u8	idiag_ext;
+	__u8	pad;
+	__u32	idiag_states;
+	struct inet_diag_sockid id;
+};
+
+enum {
+	INET_DIAG_REQ_NONE,
+	INET_DIAG_REQ_BYTECODE,
+};
+
+#define INET_DIAG_REQ_MAX INET_DIAG_REQ_BYTECODE
+
+/* Bytecode is sequence of 4 byte commands followed by variable arguments.
+ * All the commands identified by "code" are conditional jumps forward:
+ * to offset cc+"yes" or to offset cc+"no". "yes" is supposed to be
+ * length of the command and its arguments.
+ */
+ 
+struct inet_diag_bc_op {
+	unsigned char	code;
+	unsigned char	yes;
+	unsigned short	no;
+};
+
+enum {
+	INET_DIAG_BC_NOP,
+	INET_DIAG_BC_JMP,
+	INET_DIAG_BC_S_GE,
+	INET_DIAG_BC_S_LE,
+	INET_DIAG_BC_D_GE,
+	INET_DIAG_BC_D_LE,
+	INET_DIAG_BC_AUTO,
+	INET_DIAG_BC_S_COND,
+	INET_DIAG_BC_D_COND,
+};
+
+struct inet_diag_hostcond {
+	__u8	family;
+	__u8	prefix_len;
+	int	port;
+	__be32	addr[0];
+};
+
+/* Base info structure. It contains socket identity (addrs/ports/cookie)
+ * and, alas, the information shown by netstat. */
+struct inet_diag_msg {
+	__u8	idiag_family;
+	__u8	idiag_state;
+	__u8	idiag_timer;
+	__u8	idiag_retrans;
+
+	struct inet_diag_sockid id;
+
+	__u32	idiag_expires;
+	__u32	idiag_rqueue;
+	__u32	idiag_wqueue;
+	__u32	idiag_uid;
+	__u32	idiag_inode;
+};
+
+/* Extensions */
+
+enum {
+	INET_DIAG_NONE,
+	INET_DIAG_MEMINFO,
+	INET_DIAG_INFO,
+	INET_DIAG_VEGASINFO,
+	INET_DIAG_CONG,
+	INET_DIAG_TOS,
+	INET_DIAG_TCLASS,
+	INET_DIAG_SKMEMINFO,
+};
+
+#define INET_DIAG_MAX INET_DIAG_SKMEMINFO
+
+
+/* INET_DIAG_MEM */
+
+struct inet_diag_meminfo {
+	__u32	idiag_rmem;
+	__u32	idiag_wmem;
+	__u32	idiag_fmem;
+	__u32	idiag_tmem;
+};
+
+/* INET_DIAG_VEGASINFO */
+
+struct tcpvegas_info {
+	__u32	tcpv_enabled;
+	__u32	tcpv_rttcnt;
+	__u32	tcpv_rtt;
+	__u32	tcpv_minrtt;
+};
+
+
+#endif /* _UAPI_INET_DIAG_H_ */
