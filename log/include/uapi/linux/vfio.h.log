commit f751820bc319a30d31a80fe511d88642aaefcdee
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Thu Jun 18 13:07:13 2020 -0600

    vfio/type1: Fix migration info capability ID
    
    ID 1 is already used by the IOVA range capability, use ID 2.
    
    Reported-by: Liu Yi L <yi.l.liu@intel.com>
    Fixes: ad721705d09c ("vfio iommu: Add migration capability to report supported features")
    Reviewed-by: Kirti Wankhede <kwankhede@nvidia.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index eca6692667a3..920470502329 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -1030,7 +1030,7 @@ struct vfio_iommu_type1_info_cap_iova_range {
  * size in bytes that can be used by user applications when getting the dirty
  * bitmap.
  */
-#define VFIO_IOMMU_TYPE1_INFO_CAP_MIGRATION  1
+#define VFIO_IOMMU_TYPE1_INFO_CAP_MIGRATION  2
 
 struct vfio_iommu_type1_info_cap_migration {
 	struct	vfio_info_cap_header header;

commit 23fc02e36e4f657af242e59175c891b27c704935
Merge: 4e3a16ee9148 bfa50e1427e4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 8 12:05:31 2020 -0700

    Merge tag 's390-5.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Vasily Gorbik:
    
     - Add support for multi-function devices in pci code.
    
     - Enable PF-VF linking for architectures using the pdev->no_vf_scan
       flag (currently just s390).
    
     - Add reipl from NVMe support.
    
     - Get rid of critical section cleanup in entry.S.
    
     - Refactor PNSO CHSC (perform network subchannel operation) in cio and
       qeth.
    
     - QDIO interrupts and error handling fixes and improvements, more
       refactoring changes.
    
     - Align ioremap() with generic code.
    
     - Accept requests without the prefetch bit set in vfio-ccw.
    
     - Enable path handling via two new regions in vfio-ccw.
    
     - Other small fixes and improvements all over the code.
    
    * tag 's390-5.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (52 commits)
      vfio-ccw: make vfio_ccw_regops variables declarations static
      vfio-ccw: Add trace for CRW event
      vfio-ccw: Wire up the CRW irq and CRW region
      vfio-ccw: Introduce a new CRW region
      vfio-ccw: Refactor IRQ handlers
      vfio-ccw: Introduce a new schib region
      vfio-ccw: Refactor the unregister of the async regions
      vfio-ccw: Register a chp_event callback for vfio-ccw
      vfio-ccw: Introduce new helper functions to free/destroy regions
      vfio-ccw: document possible errors
      vfio-ccw: Enable transparent CCW IPL from DASD
      s390/pci: Log new handle in clp_disable_fh()
      s390/cio, s390/qeth: cleanup PNSO CHSC
      s390/qdio: remove q->first_to_kick
      s390/qdio: fix up qdio_start_irq() kerneldoc
      s390: remove critical section cleanup from entry.S
      s390: add machine check SIGP
      s390/pci: ioremap() align with generic code
      s390/ap: introduce new ap function ap_get_qdev()
      Documentation/s390: Update / remove developerWorks web links
      ...

commit d8cac29b1d52204e6632d2887eff766acd02b9aa
Author: Farhan Ali <alifm@linux.ibm.com>
Date:   Tue May 5 14:27:43 2020 +0200

    vfio-ccw: Introduce a new CRW region
    
    This region provides a mechanism to pass a Channel Report Word
    that affect vfio-ccw devices, and needs to be passed to the guest
    for its awareness and/or processing.
    
    The base driver (see crw_collect_info()) provides space for two
    CRWs, as a subchannel event may have two CRWs chained together
    (one for the ssid, one for the subchannel).  As vfio-ccw will
    deal with everything at the subchannel level, provide space
    for a single CRW to be transferred in one shot.
    
    Signed-off-by: Farhan Ali <alifm@linux.ibm.com>
    Signed-off-by: Eric Farman <farman@linux.ibm.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Message-Id: <20200505122745.53208-7-farman@linux.ibm.com>
    [CH: added padding to ccw_crw_region]
    Signed-off-by: Cornelia Huck <cohuck@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 7a1abbd889bd..907758cf6d60 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -379,6 +379,7 @@ struct vfio_region_gfx_edid {
 /* sub-types for VFIO_REGION_TYPE_CCW */
 #define VFIO_REGION_SUBTYPE_CCW_ASYNC_CMD	(1)
 #define VFIO_REGION_SUBTYPE_CCW_SCHIB		(2)
+#define VFIO_REGION_SUBTYPE_CCW_CRW		(3)
 
 /*
  * The MSIX mappable capability informs that MSIX data of a BAR can be mmapped
@@ -578,6 +579,7 @@ enum {
 
 enum {
 	VFIO_CCW_IO_IRQ_INDEX,
+	VFIO_CCW_CRW_IRQ_INDEX,
 	VFIO_CCW_NUM_IRQS
 };
 

commit 24c986748ba670c903a9d6a11ee96de2b3f5f1b8
Author: Farhan Ali <alifm@linux.ibm.com>
Date:   Tue May 5 14:27:41 2020 +0200

    vfio-ccw: Introduce a new schib region
    
    The schib region can be used by userspace to get the subchannel-
    information block (SCHIB) for the passthrough subchannel.
    This can be useful to get information such as channel path
    information via the SCHIB.PMCW fields.
    
    Signed-off-by: Farhan Ali <alifm@linux.ibm.com>
    Signed-off-by: Eric Farman <farman@linux.ibm.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Message-Id: <20200505122745.53208-5-farman@linux.ibm.com>
    Signed-off-by: Cornelia Huck <cohuck@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 015516bcfaa3..7a1abbd889bd 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -378,6 +378,7 @@ struct vfio_region_gfx_edid {
 
 /* sub-types for VFIO_REGION_TYPE_CCW */
 #define VFIO_REGION_SUBTYPE_CCW_ASYNC_CMD	(1)
+#define VFIO_REGION_SUBTYPE_CCW_SCHIB		(2)
 
 /*
  * The MSIX mappable capability informs that MSIX data of a BAR can be mmapped

commit ad721705d09c62f0d108a6b4f59867ebfd592c90
Author: Kirti Wankhede <kwankhede@nvidia.com>
Date:   Fri May 29 02:00:53 2020 +0530

    vfio iommu: Add migration capability to report supported features
    
    Added migration capability in IOMMU info chain.
    User application should check IOMMU info chain for migration capability
    to use dirty page tracking feature provided by kernel module.
    User application must check page sizes supported and maximum dirty
    bitmap size returned by this capability structure for ioctls used to get
    dirty bitmap.
    
    Signed-off-by: Kirti Wankhede <kwankhede@nvidia.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Reviewed-by: Yan Zhao <yan.y.zhao@intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index ff4b6706f7df..fde4692a6989 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -1013,6 +1013,29 @@ struct vfio_iommu_type1_info_cap_iova_range {
 	struct	vfio_iova_range iova_ranges[];
 };
 
+/*
+ * The migration capability allows to report supported features for migration.
+ *
+ * The structures below define version 1 of this capability.
+ *
+ * The existence of this capability indicates that IOMMU kernel driver supports
+ * dirty page logging.
+ *
+ * pgsize_bitmap: Kernel driver returns bitmap of supported page sizes for dirty
+ * page logging.
+ * max_dirty_bitmap_size: Kernel driver returns maximum supported dirty bitmap
+ * size in bytes that can be used by user applications when getting the dirty
+ * bitmap.
+ */
+#define VFIO_IOMMU_TYPE1_INFO_CAP_MIGRATION  1
+
+struct vfio_iommu_type1_info_cap_migration {
+	struct	vfio_info_cap_header header;
+	__u32	flags;
+	__u64	pgsize_bitmap;
+	__u64	max_dirty_bitmap_size;		/* in bytes */
+};
+
 #define VFIO_IOMMU_GET_INFO _IO(VFIO_TYPE, VFIO_BASE + 12)
 
 /**

commit 331e33d2960c8292bad8b02578fcfac18f721517
Author: Kirti Wankhede <kwankhede@nvidia.com>
Date:   Fri May 29 02:00:52 2020 +0530

    vfio iommu: Update UNMAP_DMA ioctl to get dirty bitmap before unmap
    
    DMA mapped pages, including those pinned by mdev vendor drivers, might
    get unpinned and unmapped while migration is active and device is still
    running. For example, in pre-copy phase while guest driver could access
    those pages, host device or vendor driver can dirty these mapped pages.
    Such pages should be marked dirty so as to maintain memory consistency
    for a user making use of dirty page tracking.
    
    To get bitmap during unmap, user should allocate memory for bitmap, set
    it all zeros, set size of allocated memory, set page size to be
    considered for bitmap and set flag VFIO_DMA_UNMAP_FLAG_GET_DIRTY_BITMAP.
    
    Signed-off-by: Kirti Wankhede <kwankhede@nvidia.com>
    Reviewed-by: Neo Jia <cjia@nvidia.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Reviewed-by: Yan Zhao <yan.y.zhao@intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 009a8c80079d..ff4b6706f7df 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -1048,12 +1048,23 @@ struct vfio_bitmap {
  * field.  No guarantee is made to the user that arbitrary unmaps of iova
  * or size different from those used in the original mapping call will
  * succeed.
+ * VFIO_DMA_UNMAP_FLAG_GET_DIRTY_BITMAP should be set to get the dirty bitmap
+ * before unmapping IO virtual addresses. When this flag is set, the user must
+ * provide a struct vfio_bitmap in data[]. User must provide zero-allocated
+ * memory via vfio_bitmap.data and its size in the vfio_bitmap.size field.
+ * A bit in the bitmap represents one page, of user provided page size in
+ * vfio_bitmap.pgsize field, consecutively starting from iova offset. Bit set
+ * indicates that the page at that offset from iova is dirty. A Bitmap of the
+ * pages in the range of unmapped size is returned in the user-provided
+ * vfio_bitmap.data.
  */
 struct vfio_iommu_type1_dma_unmap {
 	__u32	argsz;
 	__u32	flags;
+#define VFIO_DMA_UNMAP_FLAG_GET_DIRTY_BITMAP (1 << 0)
 	__u64	iova;				/* IO virtual address */
 	__u64	size;				/* Size of mapping (bytes) */
+	__u8    data[];
 };
 
 #define VFIO_IOMMU_UNMAP_DMA _IO(VFIO_TYPE, VFIO_BASE + 14)

commit b704fd14a06f678f080e44db28061f1bcb1f595c
Author: Kirti Wankhede <kwankhede@nvidia.com>
Date:   Fri May 29 02:00:50 2020 +0530

    vfio iommu: Add ioctl definition for dirty pages tracking
    
    IOMMU container maintains a list of all pages pinned by vfio_pin_pages API.
    All pages pinned by vendor driver through this API should be considered as
    dirty during migration. When container consists of IOMMU capable device and
    all pages are pinned and mapped, then all pages are marked dirty.
    Added support to start/stop dirtied pages tracking and to get bitmap of all
    dirtied pages for requested IO virtual address range.
    
    Signed-off-by: Kirti Wankhede <kwankhede@nvidia.com>
    Reviewed-by: Neo Jia <cjia@nvidia.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Reviewed-by: Yan Zhao <yan.y.zhao@intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index ad9bb5af3463..009a8c80079d 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -1033,6 +1033,12 @@ struct vfio_iommu_type1_dma_map {
 
 #define VFIO_IOMMU_MAP_DMA _IO(VFIO_TYPE, VFIO_BASE + 13)
 
+struct vfio_bitmap {
+	__u64        pgsize;	/* page size for bitmap in bytes */
+	__u64        size;	/* in bytes */
+	__u64 __user *data;	/* one bit per page */
+};
+
 /**
  * VFIO_IOMMU_UNMAP_DMA - _IOWR(VFIO_TYPE, VFIO_BASE + 14,
  *							struct vfio_dma_unmap)
@@ -1059,6 +1065,57 @@ struct vfio_iommu_type1_dma_unmap {
 #define VFIO_IOMMU_ENABLE	_IO(VFIO_TYPE, VFIO_BASE + 15)
 #define VFIO_IOMMU_DISABLE	_IO(VFIO_TYPE, VFIO_BASE + 16)
 
+/**
+ * VFIO_IOMMU_DIRTY_PAGES - _IOWR(VFIO_TYPE, VFIO_BASE + 17,
+ *                                     struct vfio_iommu_type1_dirty_bitmap)
+ * IOCTL is used for dirty pages logging.
+ * Caller should set flag depending on which operation to perform, details as
+ * below:
+ *
+ * Calling the IOCTL with VFIO_IOMMU_DIRTY_PAGES_FLAG_START flag set, instructs
+ * the IOMMU driver to log pages that are dirtied or potentially dirtied by
+ * the device; designed to be used when a migration is in progress. Dirty pages
+ * are logged until logging is disabled by user application by calling the IOCTL
+ * with VFIO_IOMMU_DIRTY_PAGES_FLAG_STOP flag.
+ *
+ * Calling the IOCTL with VFIO_IOMMU_DIRTY_PAGES_FLAG_STOP flag set, instructs
+ * the IOMMU driver to stop logging dirtied pages.
+ *
+ * Calling the IOCTL with VFIO_IOMMU_DIRTY_PAGES_FLAG_GET_BITMAP flag set
+ * returns the dirty pages bitmap for IOMMU container for a given IOVA range.
+ * The user must specify the IOVA range and the pgsize through the structure
+ * vfio_iommu_type1_dirty_bitmap_get in the data[] portion. This interface
+ * supports getting a bitmap of the smallest supported pgsize only and can be
+ * modified in future to get a bitmap of any specified supported pgsize. The
+ * user must provide a zeroed memory area for the bitmap memory and specify its
+ * size in bitmap.size. One bit is used to represent one page consecutively
+ * starting from iova offset. The user should provide page size in bitmap.pgsize
+ * field. A bit set in the bitmap indicates that the page at that offset from
+ * iova is dirty. The caller must set argsz to a value including the size of
+ * structure vfio_iommu_type1_dirty_bitmap_get, but excluding the size of the
+ * actual bitmap. If dirty pages logging is not enabled, an error will be
+ * returned.
+ *
+ * Only one of the flags _START, _STOP and _GET may be specified at a time.
+ *
+ */
+struct vfio_iommu_type1_dirty_bitmap {
+	__u32        argsz;
+	__u32        flags;
+#define VFIO_IOMMU_DIRTY_PAGES_FLAG_START	(1 << 0)
+#define VFIO_IOMMU_DIRTY_PAGES_FLAG_STOP	(1 << 1)
+#define VFIO_IOMMU_DIRTY_PAGES_FLAG_GET_BITMAP	(1 << 2)
+	__u8         data[];
+};
+
+struct vfio_iommu_type1_dirty_bitmap_get {
+	__u64              iova;	/* IO virtual address */
+	__u64              size;	/* Size of iova range */
+	struct vfio_bitmap bitmap;
+};
+
+#define VFIO_IOMMU_DIRTY_PAGES             _IO(VFIO_TYPE, VFIO_BASE + 17)
+
 /* -------- Additional API for SPAPR TCE (Server POWERPC) IOMMU -------- */
 
 /*

commit a8a24f3f6e38103b77cf399c38eb54e1219d00d6
Author: Kirti Wankhede <kwankhede@nvidia.com>
Date:   Fri May 29 02:00:47 2020 +0530

    vfio: UAPI for migration interface for device state
    
    - Defined MIGRATION region type and sub-type.
    
    - Defined vfio_device_migration_info structure which will be placed at the
      0th offset of migration region to get/set VFIO device related
      information. Defined members of structure and usage on read/write access.
    
    - Defined device states and state transition details.
    
    - Defined sequence to be followed while saving and resuming VFIO device.
    
    Signed-off-by: Kirti Wankhede <kwankhede@nvidia.com>
    Reviewed-by: Neo Jia <cjia@nvidia.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Reviewed-by: Yan Zhao <yan.y.zhao@intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 015516bcfaa3..ad9bb5af3463 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -305,6 +305,7 @@ struct vfio_region_info_cap_type {
 #define VFIO_REGION_TYPE_PCI_VENDOR_MASK	(0xffff)
 #define VFIO_REGION_TYPE_GFX                    (1)
 #define VFIO_REGION_TYPE_CCW			(2)
+#define VFIO_REGION_TYPE_MIGRATION              (3)
 
 /* sub-types for VFIO_REGION_TYPE_PCI_* */
 
@@ -379,6 +380,233 @@ struct vfio_region_gfx_edid {
 /* sub-types for VFIO_REGION_TYPE_CCW */
 #define VFIO_REGION_SUBTYPE_CCW_ASYNC_CMD	(1)
 
+/* sub-types for VFIO_REGION_TYPE_MIGRATION */
+#define VFIO_REGION_SUBTYPE_MIGRATION           (1)
+
+/*
+ * The structure vfio_device_migration_info is placed at the 0th offset of
+ * the VFIO_REGION_SUBTYPE_MIGRATION region to get and set VFIO device related
+ * migration information. Field accesses from this structure are only supported
+ * at their native width and alignment. Otherwise, the result is undefined and
+ * vendor drivers should return an error.
+ *
+ * device_state: (read/write)
+ *      - The user application writes to this field to inform the vendor driver
+ *        about the device state to be transitioned to.
+ *      - The vendor driver should take the necessary actions to change the
+ *        device state. After successful transition to a given state, the
+ *        vendor driver should return success on write(device_state, state)
+ *        system call. If the device state transition fails, the vendor driver
+ *        should return an appropriate -errno for the fault condition.
+ *      - On the user application side, if the device state transition fails,
+ *	  that is, if write(device_state, state) returns an error, read
+ *	  device_state again to determine the current state of the device from
+ *	  the vendor driver.
+ *      - The vendor driver should return previous state of the device unless
+ *        the vendor driver has encountered an internal error, in which case
+ *        the vendor driver may report the device_state VFIO_DEVICE_STATE_ERROR.
+ *      - The user application must use the device reset ioctl to recover the
+ *        device from VFIO_DEVICE_STATE_ERROR state. If the device is
+ *        indicated to be in a valid device state by reading device_state, the
+ *        user application may attempt to transition the device to any valid
+ *        state reachable from the current state or terminate itself.
+ *
+ *      device_state consists of 3 bits:
+ *      - If bit 0 is set, it indicates the _RUNNING state. If bit 0 is clear,
+ *        it indicates the _STOP state. When the device state is changed to
+ *        _STOP, driver should stop the device before write() returns.
+ *      - If bit 1 is set, it indicates the _SAVING state, which means that the
+ *        driver should start gathering device state information that will be
+ *        provided to the VFIO user application to save the device's state.
+ *      - If bit 2 is set, it indicates the _RESUMING state, which means that
+ *        the driver should prepare to resume the device. Data provided through
+ *        the migration region should be used to resume the device.
+ *      Bits 3 - 31 are reserved for future use. To preserve them, the user
+ *      application should perform a read-modify-write operation on this
+ *      field when modifying the specified bits.
+ *
+ *  +------- _RESUMING
+ *  |+------ _SAVING
+ *  ||+----- _RUNNING
+ *  |||
+ *  000b => Device Stopped, not saving or resuming
+ *  001b => Device running, which is the default state
+ *  010b => Stop the device & save the device state, stop-and-copy state
+ *  011b => Device running and save the device state, pre-copy state
+ *  100b => Device stopped and the device state is resuming
+ *  101b => Invalid state
+ *  110b => Error state
+ *  111b => Invalid state
+ *
+ * State transitions:
+ *
+ *              _RESUMING  _RUNNING    Pre-copy    Stop-and-copy   _STOP
+ *                (100b)     (001b)     (011b)        (010b)       (000b)
+ * 0. Running or default state
+ *                             |
+ *
+ * 1. Normal Shutdown (optional)
+ *                             |------------------------------------->|
+ *
+ * 2. Save the state or suspend
+ *                             |------------------------->|---------->|
+ *
+ * 3. Save the state during live migration
+ *                             |----------->|------------>|---------->|
+ *
+ * 4. Resuming
+ *                  |<---------|
+ *
+ * 5. Resumed
+ *                  |--------->|
+ *
+ * 0. Default state of VFIO device is _RUNNNG when the user application starts.
+ * 1. During normal shutdown of the user application, the user application may
+ *    optionally change the VFIO device state from _RUNNING to _STOP. This
+ *    transition is optional. The vendor driver must support this transition but
+ *    must not require it.
+ * 2. When the user application saves state or suspends the application, the
+ *    device state transitions from _RUNNING to stop-and-copy and then to _STOP.
+ *    On state transition from _RUNNING to stop-and-copy, driver must stop the
+ *    device, save the device state and send it to the application through the
+ *    migration region. The sequence to be followed for such transition is given
+ *    below.
+ * 3. In live migration of user application, the state transitions from _RUNNING
+ *    to pre-copy, to stop-and-copy, and to _STOP.
+ *    On state transition from _RUNNING to pre-copy, the driver should start
+ *    gathering the device state while the application is still running and send
+ *    the device state data to application through the migration region.
+ *    On state transition from pre-copy to stop-and-copy, the driver must stop
+ *    the device, save the device state and send it to the user application
+ *    through the migration region.
+ *    Vendor drivers must support the pre-copy state even for implementations
+ *    where no data is provided to the user before the stop-and-copy state. The
+ *    user must not be required to consume all migration data before the device
+ *    transitions to a new state, including the stop-and-copy state.
+ *    The sequence to be followed for above two transitions is given below.
+ * 4. To start the resuming phase, the device state should be transitioned from
+ *    the _RUNNING to the _RESUMING state.
+ *    In the _RESUMING state, the driver should use the device state data
+ *    received through the migration region to resume the device.
+ * 5. After providing saved device data to the driver, the application should
+ *    change the state from _RESUMING to _RUNNING.
+ *
+ * reserved:
+ *      Reads on this field return zero and writes are ignored.
+ *
+ * pending_bytes: (read only)
+ *      The number of pending bytes still to be migrated from the vendor driver.
+ *
+ * data_offset: (read only)
+ *      The user application should read data_offset field from the migration
+ *      region. The user application should read the device data from this
+ *      offset within the migration region during the _SAVING state or write
+ *      the device data during the _RESUMING state. See below for details of
+ *      sequence to be followed.
+ *
+ * data_size: (read/write)
+ *      The user application should read data_size to get the size in bytes of
+ *      the data copied in the migration region during the _SAVING state and
+ *      write the size in bytes of the data copied in the migration region
+ *      during the _RESUMING state.
+ *
+ * The format of the migration region is as follows:
+ *  ------------------------------------------------------------------
+ * |vfio_device_migration_info|    data section                      |
+ * |                          |     ///////////////////////////////  |
+ * ------------------------------------------------------------------
+ *   ^                              ^
+ *  offset 0-trapped part        data_offset
+ *
+ * The structure vfio_device_migration_info is always followed by the data
+ * section in the region, so data_offset will always be nonzero. The offset
+ * from where the data is copied is decided by the kernel driver. The data
+ * section can be trapped, mmapped, or partitioned, depending on how the kernel
+ * driver defines the data section. The data section partition can be defined
+ * as mapped by the sparse mmap capability. If mmapped, data_offset must be
+ * page aligned, whereas initial section which contains the
+ * vfio_device_migration_info structure, might not end at the offset, which is
+ * page aligned. The user is not required to access through mmap regardless
+ * of the capabilities of the region mmap.
+ * The vendor driver should determine whether and how to partition the data
+ * section. The vendor driver should return data_offset accordingly.
+ *
+ * The sequence to be followed while in pre-copy state and stop-and-copy state
+ * is as follows:
+ * a. Read pending_bytes, indicating the start of a new iteration to get device
+ *    data. Repeated read on pending_bytes at this stage should have no side
+ *    effects.
+ *    If pending_bytes == 0, the user application should not iterate to get data
+ *    for that device.
+ *    If pending_bytes > 0, perform the following steps.
+ * b. Read data_offset, indicating that the vendor driver should make data
+ *    available through the data section. The vendor driver should return this
+ *    read operation only after data is available from (region + data_offset)
+ *    to (region + data_offset + data_size).
+ * c. Read data_size, which is the amount of data in bytes available through
+ *    the migration region.
+ *    Read on data_offset and data_size should return the offset and size of
+ *    the current buffer if the user application reads data_offset and
+ *    data_size more than once here.
+ * d. Read data_size bytes of data from (region + data_offset) from the
+ *    migration region.
+ * e. Process the data.
+ * f. Read pending_bytes, which indicates that the data from the previous
+ *    iteration has been read. If pending_bytes > 0, go to step b.
+ *
+ * The user application can transition from the _SAVING|_RUNNING
+ * (pre-copy state) to the _SAVING (stop-and-copy) state regardless of the
+ * number of pending bytes. The user application should iterate in _SAVING
+ * (stop-and-copy) until pending_bytes is 0.
+ *
+ * The sequence to be followed while _RESUMING device state is as follows:
+ * While data for this device is available, repeat the following steps:
+ * a. Read data_offset from where the user application should write data.
+ * b. Write migration data starting at the migration region + data_offset for
+ *    the length determined by data_size from the migration source.
+ * c. Write data_size, which indicates to the vendor driver that data is
+ *    written in the migration region. Vendor driver must return this write
+ *    operations on consuming data. Vendor driver should apply the
+ *    user-provided migration region data to the device resume state.
+ *
+ * If an error occurs during the above sequences, the vendor driver can return
+ * an error code for next read() or write() operation, which will terminate the
+ * loop. The user application should then take the next necessary action, for
+ * example, failing migration or terminating the user application.
+ *
+ * For the user application, data is opaque. The user application should write
+ * data in the same order as the data is received and the data should be of
+ * same transaction size at the source.
+ */
+
+struct vfio_device_migration_info {
+	__u32 device_state;         /* VFIO device state */
+#define VFIO_DEVICE_STATE_STOP      (0)
+#define VFIO_DEVICE_STATE_RUNNING   (1 << 0)
+#define VFIO_DEVICE_STATE_SAVING    (1 << 1)
+#define VFIO_DEVICE_STATE_RESUMING  (1 << 2)
+#define VFIO_DEVICE_STATE_MASK      (VFIO_DEVICE_STATE_RUNNING | \
+				     VFIO_DEVICE_STATE_SAVING |  \
+				     VFIO_DEVICE_STATE_RESUMING)
+
+#define VFIO_DEVICE_STATE_VALID(state) \
+	(state & VFIO_DEVICE_STATE_RESUMING ? \
+	(state & VFIO_DEVICE_STATE_MASK) == VFIO_DEVICE_STATE_RESUMING : 1)
+
+#define VFIO_DEVICE_STATE_IS_ERROR(state) \
+	((state & VFIO_DEVICE_STATE_MASK) == (VFIO_DEVICE_STATE_SAVING | \
+					      VFIO_DEVICE_STATE_RESUMING))
+
+#define VFIO_DEVICE_STATE_SET_ERROR(state) \
+	((state & ~VFIO_DEVICE_STATE_MASK) | VFIO_DEVICE_SATE_SAVING | \
+					     VFIO_DEVICE_STATE_RESUMING)
+
+	__u32 reserved;
+	__u64 pending_bytes;
+	__u64 data_offset;
+	__u64 data_size;
+};
+
 /*
  * The MSIX mappable capability informs that MSIX data of a BAR can be mmapped
  * which allows direct access to non-MSIX registers which happened to be within

commit 43eeeecc8ed5fa05652d68032a8bfb1308ee9baa
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Tue Mar 24 09:28:27 2020 -0600

    vfio: Introduce VFIO_DEVICE_FEATURE ioctl and first user
    
    The VFIO_DEVICE_FEATURE ioctl is meant to be a general purpose, device
    agnostic ioctl for setting, retrieving, and probing device features.
    This implementation provides a 16-bit field for specifying a feature
    index, where the data porition of the ioctl is determined by the
    semantics for the given feature.  Additional flag bits indicate the
    direction and nature of the operation; SET indicates user data is
    provided into the device feature, GET indicates the device feature is
    written out into user data.  The PROBE flag augments determining
    whether the given feature is supported, and if provided, whether the
    given operation on the feature is supported.
    
    The first user of this ioctl is for setting the vfio-pci VF token,
    where the user provides a shared secret key (UUID) on a SR-IOV PF
    device, which users must provide when opening associated VF devices.
    
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 9e843a147ead..015516bcfaa3 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -707,6 +707,43 @@ struct vfio_device_ioeventfd {
 
 #define VFIO_DEVICE_IOEVENTFD		_IO(VFIO_TYPE, VFIO_BASE + 16)
 
+/**
+ * VFIO_DEVICE_FEATURE - _IORW(VFIO_TYPE, VFIO_BASE + 17,
+ *			       struct vfio_device_feature)
+ *
+ * Get, set, or probe feature data of the device.  The feature is selected
+ * using the FEATURE_MASK portion of the flags field.  Support for a feature
+ * can be probed by setting both the FEATURE_MASK and PROBE bits.  A probe
+ * may optionally include the GET and/or SET bits to determine read vs write
+ * access of the feature respectively.  Probing a feature will return success
+ * if the feature is supported and all of the optionally indicated GET/SET
+ * methods are supported.  The format of the data portion of the structure is
+ * specific to the given feature.  The data portion is not required for
+ * probing.  GET and SET are mutually exclusive, except for use with PROBE.
+ *
+ * Return 0 on success, -errno on failure.
+ */
+struct vfio_device_feature {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_DEVICE_FEATURE_MASK	(0xffff) /* 16-bit feature index */
+#define VFIO_DEVICE_FEATURE_GET		(1 << 16) /* Get feature into data[] */
+#define VFIO_DEVICE_FEATURE_SET		(1 << 17) /* Set feature from data[] */
+#define VFIO_DEVICE_FEATURE_PROBE	(1 << 18) /* Probe feature support */
+	__u8	data[];
+};
+
+#define VFIO_DEVICE_FEATURE		_IO(VFIO_TYPE, VFIO_BASE + 17)
+
+/*
+ * Provide support for setting a PCI VF Token, which is used as a shared
+ * secret between PF and VF drivers.  This feature may only be set on a
+ * PCI SR-IOV PF when SR-IOV is enabled on the PF and there are no existing
+ * open VFs.  Data provided when setting this feature is a 16-byte array
+ * (__u8 b[16]), representing a UUID.
+ */
+#define VFIO_DEVICE_FEATURE_PCI_VF_TOKEN	(0)
+
 /* -------- API for Type1 VFIO IOMMU -------- */
 
 /**

commit e6c5d727db0a86a3ff21aca6824aae87f3bc055f
Merge: e3fb13b7e47c 78becab98b8f db2cb969e8ae 92c8026854c2 eee413e620f4 b09d6e473974
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Aug 23 11:26:24 2019 -0600

    Merge branches 'v5.4/vfio/alexey-tce-memory-free-v1', 'v5.4/vfio/connie-re-arrange-v2', 'v5.4/vfio/hexin-pci-reset-v3', 'v5.4/vfio/parav-mtty-uuid-v2' and 'v5.4/vfio/shameer-iova-list-v8' into v5.4/vfio/next

commit a717072007e8aedd3f951726d8cf55454860b30d
Author: Shameer Kolothum <shameerali.kolothum.thodi@huawei.com>
Date:   Tue Jul 23 17:06:36 2019 +0100

    vfio/type1: Add IOVA range capability support
    
    This allows the user-space to retrieve the supported IOVA
    range(s), excluding any non-relaxable reserved regions. The
    implementation is based on capability chains, added to
    VFIO_IOMMU_GET_INFO ioctl.
    
    Signed-off-by: Shameer Kolothum <shameerali.kolothum.thodi@huawei.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 8f10748dac79..1259dccd09d2 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -714,7 +714,31 @@ struct vfio_iommu_type1_info {
 	__u32	argsz;
 	__u32	flags;
 #define VFIO_IOMMU_INFO_PGSIZES (1 << 0)	/* supported page sizes info */
-	__u64	iova_pgsizes;		/* Bitmap of supported page sizes */
+#define VFIO_IOMMU_INFO_CAPS	(1 << 1)	/* Info supports caps */
+	__u64	iova_pgsizes;	/* Bitmap of supported page sizes */
+	__u32   cap_offset;	/* Offset within info struct of first cap */
+};
+
+/*
+ * The IOVA capability allows to report the valid IOVA range(s)
+ * excluding any non-relaxable reserved regions exposed by
+ * devices attached to the container. Any DMA map attempt
+ * outside the valid iova range will return error.
+ *
+ * The structures below define version 1 of this capability.
+ */
+#define VFIO_IOMMU_TYPE1_INFO_CAP_IOVA_RANGE  1
+
+struct vfio_iova_range {
+	__u64	start;
+	__u64	end;
+};
+
+struct vfio_iommu_type1_info_cap_iova_range {
+	struct	vfio_info_cap_header header;
+	__u32	nr_iovas;
+	__u32	reserved;
+	struct	vfio_iova_range iova_ranges[];
 };
 
 #define VFIO_IOMMU_GET_INFO _IO(VFIO_TYPE, VFIO_BASE + 12)

commit db2cb969e8aed2395620fe2cb0bffd194c02b4b1
Author: Cornelia Huck <cohuck@redhat.com>
Date:   Tue Aug 6 11:30:00 2019 +0200

    vfio: re-arrange vfio region definitions
    
    It is easy to miss already defined region types. Let's re-arrange
    the definitions a bit and add more comments to make it hopefully
    a bit clearer.
    
    No functional change.
    
    Signed-off-by: Cornelia Huck <cohuck@redhat.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 8f10748dac79..e809b22f6a60 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -295,15 +295,38 @@ struct vfio_region_info_cap_type {
 	__u32 subtype;	/* type specific */
 };
 
+/*
+ * List of region types, global per bus driver.
+ * If you introduce a new type, please add it here.
+ */
+
+/* PCI region type containing a PCI vendor part */
 #define VFIO_REGION_TYPE_PCI_VENDOR_TYPE	(1 << 31)
 #define VFIO_REGION_TYPE_PCI_VENDOR_MASK	(0xffff)
+#define VFIO_REGION_TYPE_GFX                    (1)
+#define VFIO_REGION_TYPE_CCW			(2)
+
+/* sub-types for VFIO_REGION_TYPE_PCI_* */
 
-/* 8086 Vendor sub-types */
+/* 8086 vendor PCI sub-types */
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_OPREGION	(1)
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_HOST_CFG	(2)
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_LPC_CFG	(3)
 
-#define VFIO_REGION_TYPE_GFX                    (1)
+/* 10de vendor PCI sub-types */
+/*
+ * NVIDIA GPU NVlink2 RAM is coherent RAM mapped onto the host address space.
+ */
+#define VFIO_REGION_SUBTYPE_NVIDIA_NVLINK2_RAM	(1)
+
+/* 1014 vendor PCI sub-types */
+/*
+ * IBM NPU NVlink2 ATSD (Address Translation Shootdown) register of NPU
+ * to do TLB invalidation on a GPU.
+ */
+#define VFIO_REGION_SUBTYPE_IBM_NVLINK2_ATSD	(1)
+
+/* sub-types for VFIO_REGION_TYPE_GFX */
 #define VFIO_REGION_SUBTYPE_GFX_EDID            (1)
 
 /**
@@ -353,25 +376,9 @@ struct vfio_region_gfx_edid {
 #define VFIO_DEVICE_GFX_LINK_STATE_DOWN  2
 };
 
-#define VFIO_REGION_TYPE_CCW			(2)
-/* ccw sub-types */
+/* sub-types for VFIO_REGION_TYPE_CCW */
 #define VFIO_REGION_SUBTYPE_CCW_ASYNC_CMD	(1)
 
-/*
- * 10de vendor sub-type
- *
- * NVIDIA GPU NVlink2 RAM is coherent RAM mapped onto the host address space.
- */
-#define VFIO_REGION_SUBTYPE_NVIDIA_NVLINK2_RAM	(1)
-
-/*
- * 1014 vendor sub-type
- *
- * IBM NPU NVlink2 ATSD (Address Translation Shootdown) register of NPU
- * to do TLB invalidation on a GPU.
- */
-#define VFIO_REGION_SUBTYPE_IBM_NVLINK2_ATSD	(1)
-
 /*
  * The MSIX mappable capability informs that MSIX data of a BAR can be mmapped
  * which allows direct access to non-MSIX registers which happened to be within

commit d5afd5d135c8cc43bd2568361b4c91f0bd488c3f
Author: Cornelia Huck <cohuck@redhat.com>
Date:   Mon Jul 23 16:03:27 2018 +0200

    vfio-ccw: add handling for async channel instructions
    
    Add a region to the vfio-ccw device that can be used to submit
    asynchronous I/O instructions. ssch continues to be handled by the
    existing I/O region; the new region handles hsch and csch.
    
    Interrupt status continues to be reported through the same channels
    as for ssch.
    
    Acked-by: Eric Farman <farman@linux.ibm.com>
    Reviewed-by: Farhan Ali <alifm@linux.ibm.com>
    Signed-off-by: Cornelia Huck <cohuck@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 56e2413d3e00..8f10748dac79 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -354,6 +354,8 @@ struct vfio_region_gfx_edid {
 };
 
 #define VFIO_REGION_TYPE_CCW			(2)
+/* ccw sub-types */
+#define VFIO_REGION_SUBTYPE_CCW_ASYNC_CMD	(1)
 
 /*
  * 10de vendor sub-type

commit db8e5d17ac03a65e2e0ee0ba50bf61a99741d871
Author: Cornelia Huck <cohuck@redhat.com>
Date:   Thu Jul 19 17:53:08 2018 +0200

    vfio-ccw: add capabilities chain
    
    Allow to extend the regions used by vfio-ccw. The first user will be
    handling of halt and clear subchannel.
    
    Reviewed-by: Eric Farman <farman@linux.ibm.com>
    Reviewed-by: Farhan Ali <alifm@linux.ibm.com>
    Signed-off-by: Cornelia Huck <cohuck@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 02bb7ad6e986..56e2413d3e00 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -353,6 +353,8 @@ struct vfio_region_gfx_edid {
 #define VFIO_DEVICE_GFX_LINK_STATE_DOWN  2
 };
 
+#define VFIO_REGION_TYPE_CCW			(2)
+
 /*
  * 10de vendor sub-type
  *

commit 7f92891778dff62303c070ac81de7b7d80de331a
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Thu Dec 20 12:10:36 2018 +1100

    vfio_pci: Add NVIDIA GV100GL [Tesla V100 SXM2] subdriver
    
    POWER9 Witherspoon machines come with 4 or 6 V100 GPUs which are not
    pluggable PCIe devices but still have PCIe links which are used
    for config space and MMIO. In addition to that the GPUs have 6 NVLinks
    which are connected to other GPUs and the POWER9 CPU. POWER9 chips
    have a special unit on a die called an NPU which is an NVLink2 host bus
    adapter with p2p connections to 2 to 3 GPUs, 3 or 2 NVLinks to each.
    These systems also support ATS (address translation services) which is
    a part of the NVLink2 protocol. Such GPUs also share on-board RAM
    (16GB or 32GB) to the system via the same NVLink2 so a CPU has
    cache-coherent access to a GPU RAM.
    
    This exports GPU RAM to the userspace as a new VFIO device region. This
    preregisters the new memory as device memory as it might be used for DMA.
    This inserts pfns from the fault handler as the GPU memory is not onlined
    until the vendor driver is loaded and trained the NVLinks so doing this
    earlier causes low level errors which we fence in the firmware so
    it does not hurt the host system but still better be avoided; for the same
    reason this does not map GPU RAM into the host kernel (usual thing for
    emulated access otherwise).
    
    This exports an ATSD (Address Translation Shootdown) register of NPU which
    allows TLB invalidations inside GPU for an operating system. The register
    conveniently occupies a single 64k page. It is also presented to
    the userspace as a new VFIO device region. One NPU has 8 ATSD registers,
    each of them can be used for TLB invalidation in a GPU linked to this NPU.
    This allocates one ATSD register per an NVLink bridge allowing passing
    up to 6 registers. Due to the host firmware bug (just recently fixed),
    only 1 ATSD register per NPU was actually advertised to the host system
    so this passes that alone register via the first NVLink bridge device in
    the group which is still enough as QEMU collects them all back and
    presents to the guest via vPHB to mimic the emulated NPU PHB on the host.
    
    In order to provide the userspace with the information about GPU-to-NVLink
    connections, this exports an additional capability called "tgt"
    (which is an abbreviated host system bus address). The "tgt" property
    tells the GPU its own system address and allows the guest driver to
    conglomerate the routing information so each GPU knows how to get directly
    to the other GPUs.
    
    For ATS to work, the nest MMU (an NVIDIA block in a P9 CPU) needs to
    know LPID (a logical partition ID or a KVM guest hardware ID in other
    words) and PID (a memory context ID of a userspace process, not to be
    confused with a linux pid). This assigns a GPU to LPID in the NPU and
    this is why this adds a listener for KVM on an IOMMU group. A PID comes
    via NVLink from a GPU and NPU uses a PID wildcard to pass it through.
    
    This requires coherent memory and ATSD to be available on the host as
    the GPU vendor only supports configurations with both features enabled
    and other configurations are known not to work. Because of this and
    because of the ways the features are advertised to the host system
    (which is a device tree with very platform specific properties),
    this requires enabled POWERNV platform.
    
    The V100 GPUs do not advertise any of these capabilities via the config
    space and there are more than just one device ID so this relies on
    the platform to tell whether these GPUs have special abilities such as
    NVLinks.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 813102810f53..02bb7ad6e986 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -353,6 +353,21 @@ struct vfio_region_gfx_edid {
 #define VFIO_DEVICE_GFX_LINK_STATE_DOWN  2
 };
 
+/*
+ * 10de vendor sub-type
+ *
+ * NVIDIA GPU NVlink2 RAM is coherent RAM mapped onto the host address space.
+ */
+#define VFIO_REGION_SUBTYPE_NVIDIA_NVLINK2_RAM	(1)
+
+/*
+ * 1014 vendor sub-type
+ *
+ * IBM NPU NVlink2 ATSD (Address Translation Shootdown) register of NPU
+ * to do TLB invalidation on a GPU.
+ */
+#define VFIO_REGION_SUBTYPE_IBM_NVLINK2_ATSD	(1)
+
 /*
  * The MSIX mappable capability informs that MSIX data of a BAR can be mmapped
  * which allows direct access to non-MSIX registers which happened to be within
@@ -363,6 +378,33 @@ struct vfio_region_gfx_edid {
  */
 #define VFIO_REGION_INFO_CAP_MSIX_MAPPABLE	3
 
+/*
+ * Capability with compressed real address (aka SSA - small system address)
+ * where GPU RAM is mapped on a system bus. Used by a GPU for DMA routing
+ * and by the userspace to associate a NVLink bridge with a GPU.
+ */
+#define VFIO_REGION_INFO_CAP_NVLINK2_SSATGT	4
+
+struct vfio_region_info_cap_nvlink2_ssatgt {
+	struct vfio_info_cap_header header;
+	__u64 tgt;
+};
+
+/*
+ * Capability with an NVLink link speed. The value is read by
+ * the NVlink2 bridge driver from the bridge's "ibm,nvlink-speed"
+ * property in the device tree. The value is fixed in the hardware
+ * and failing to provide the correct value results in the link
+ * not working with no indication from the driver why.
+ */
+#define VFIO_REGION_INFO_CAP_NVLINK2_LNKSPD	5
+
+struct vfio_region_info_cap_nvlink2_lnkspd {
+	struct vfio_info_cap_header header;
+	__u32 link_speed;
+	__u32 __pad;
+};
+
 /**
  * VFIO_DEVICE_GET_IRQ_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 9,
  *				    struct vfio_irq_info)

commit 0c86e761b95131943c2b8af2ffb3c0554f9a71f5
Merge: b3491d8430dd 104c7405a64d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 31 11:01:38 2018 -0700

    Merge tag 'vfio-v4.20-rc1.v2' of git://github.com/awilliam/linux-vfio
    
    Pull VFIO updates from Alex Williamson:
    
     - EDID interfaces for vfio devices supporting display extensions (Gerd
       Hoffmann)
    
     - Generically select Type-1 IOMMU model support on ARM/ARM64 (Geert
       Uytterhoeven)
    
     - Quirk for VFs reporting INTx pin (Alex Williamson)
    
     - Fix error path memory leak in MSI support (Li Qiang)
    
    * tag 'vfio-v4.20-rc1.v2' of git://github.com/awilliam/linux-vfio:
      vfio: add edid support to mbochs sample driver
      vfio: add edid api for display (vgpu) devices.
      drivers/vfio: Allow type-1 IOMMU instantiation with all ARM/ARM64 IOMMUs
      vfio/pci: Mask buggy SR-IOV VF INTx support
      vfio/pci: Fix potential memory leak in vfio_msi_cap_len

commit 3cdf752506b29ace75b6e1318abac06073d600e4
Author: Gerd Hoffmann <kraxel@redhat.com>
Date:   Fri Sep 21 10:30:12 2018 +0200

    vfio: add edid api for display (vgpu) devices.
    
    This allows to set EDID monitor information for the vgpu display, for a
    more flexible display configuration, using a special vfio region.  Check
    the comment describing struct vfio_region_gfx_edid for more details.
    
    Signed-off-by: Gerd Hoffmann <kraxel@redhat.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 1aa7b82e8169..44b66b09c5fe 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -301,6 +301,56 @@ struct vfio_region_info_cap_type {
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_HOST_CFG	(2)
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_LPC_CFG	(3)
 
+#define VFIO_REGION_TYPE_GFX                    (1)
+#define VFIO_REGION_SUBTYPE_GFX_EDID            (1)
+
+/**
+ * struct vfio_region_gfx_edid - EDID region layout.
+ *
+ * Set display link state and EDID blob.
+ *
+ * The EDID blob has monitor information such as brand, name, serial
+ * number, physical size, supported video modes and more.
+ *
+ * This special region allows userspace (typically qemu) set a virtual
+ * EDID for the virtual monitor, which allows a flexible display
+ * configuration.
+ *
+ * For the edid blob spec look here:
+ *    https://en.wikipedia.org/wiki/Extended_Display_Identification_Data
+ *
+ * On linux systems you can find the EDID blob in sysfs:
+ *    /sys/class/drm/${card}/${connector}/edid
+ *
+ * You can use the edid-decode ulility (comes with xorg-x11-utils) to
+ * decode the EDID blob.
+ *
+ * @edid_offset: location of the edid blob, relative to the
+ *               start of the region (readonly).
+ * @edid_max_size: max size of the edid blob (readonly).
+ * @edid_size: actual edid size (read/write).
+ * @link_state: display link state (read/write).
+ * VFIO_DEVICE_GFX_LINK_STATE_UP: Monitor is turned on.
+ * VFIO_DEVICE_GFX_LINK_STATE_DOWN: Monitor is turned off.
+ * @max_xres: max display width (0 == no limitation, readonly).
+ * @max_yres: max display height (0 == no limitation, readonly).
+ *
+ * EDID update protocol:
+ *   (1) set link-state to down.
+ *   (2) update edid blob and size.
+ *   (3) set link-state to up.
+ */
+struct vfio_region_gfx_edid {
+	__u32 edid_offset;
+	__u32 edid_max_size;
+	__u32 edid_size;
+	__u32 max_xres;
+	__u32 max_yres;
+	__u32 link_state;
+#define VFIO_DEVICE_GFX_LINK_STATE_UP    1
+#define VFIO_DEVICE_GFX_LINK_STATE_DOWN  2
+};
+
 /*
  * The MSIX mappable capability informs that MSIX data of a BAR can be mmapped
  * which allows direct access to non-MSIX registers which happened to be within

commit e06670c5fe3b3a55547e2caeaec34acfdb4885e3
Author: Tony Krowiak <akrowiak@linux.ibm.com>
Date:   Tue Sep 25 19:16:27 2018 -0400

    s390: vfio-ap: implement VFIO_DEVICE_GET_INFO ioctl
    
    Adds support for the VFIO_DEVICE_GET_INFO ioctl to the VFIO
    AP Matrix device driver. This is a minimal implementation,
    as vfio-ap does not use I/O regions.
    
    Signed-off-by: Tony Krowiak <akrowiak@linux.ibm.com>
    Reviewed-by: Pierre Morel <pmorel@linux.ibm.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Acked-by: Halil Pasic <pasic@linux.ibm.com>
    Tested-by: Michael Mueller <mimu@linux.ibm.com>
    Tested-by: Farhan Ali <alifm@linux.ibm.com>
    Tested-by: Pierre Morel <pmorel@linux.ibm.com>
    Message-Id: <20180925231641.4954-13-akrowiak@linux.vnet.ibm.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index bfbe2be8f369..f378b9802d8b 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -200,6 +200,7 @@ struct vfio_device_info {
 #define VFIO_DEVICE_FLAGS_PLATFORM (1 << 2)	/* vfio-platform device */
 #define VFIO_DEVICE_FLAGS_AMBA  (1 << 3)	/* vfio-amba device */
 #define VFIO_DEVICE_FLAGS_CCW	(1 << 4)	/* vfio-ccw device */
+#define VFIO_DEVICE_FLAGS_AP	(1 << 5)	/* vfio-ap device */
 	__u32	num_regions;	/* Max region index + 1 */
 	__u32	num_irqs;	/* Max IRQ index + 1 */
 };

commit 65f06713d3fa0e4125f59ad5b9d6239109b1d7fc
Author: Tony Krowiak <akrowiak@linux.ibm.com>
Date:   Tue Sep 25 19:16:20 2018 -0400

    s390: vfio-ap: register matrix device with VFIO mdev framework
    
    Registers the matrix device created by the VFIO AP device
    driver with the VFIO mediated device framework.
    Registering the matrix device will create the sysfs
    structures needed to create mediated matrix devices
    each of which will be used to configure the AP matrix
    for a guest and connect it to the VFIO AP device driver.
    
    Registering the matrix device with the VFIO mediated device
    framework will create the following sysfs structures:
    
    /sys/devices/vfio_ap/matrix/
    ...... [mdev_supported_types]
    ......... [vfio_ap-passthrough]
    ............ create
    
    To create a mediated device for the AP matrix device, write a UUID
    to the create file:
    
            uuidgen > create
    
    A symbolic link to the mediated device's directory will be created in the
    devices subdirectory named after the generated $uuid:
    
    /sys/devices/vfio_ap/matrix/
    ...... [mdev_supported_types]
    ......... [vfio_ap-passthrough]
    ............ [devices]
    ............... [$uuid]
    
    A symbolic link to the mediated device will also be created
    in the vfio_ap matrix's directory:
    
    /sys/devices/vfio_ap/matrix/[$uuid]
    
    Signed-off-by: Tony Krowiak <akrowiak@linux.ibm.com>
    Reviewed-by: Halil Pasic <pasic@linux.ibm.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Tested-by: Michael Mueller <mimu@linux.ibm.com>
    Tested-by: Farhan Ali <alifm@linux.ibm.com>
    Message-Id: <20180925231641.4954-6-akrowiak@linux.vnet.ibm.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 1aa7b82e8169..bfbe2be8f369 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -215,6 +215,7 @@ struct vfio_device_info {
 #define VFIO_DEVICE_API_PLATFORM_STRING		"vfio-platform"
 #define VFIO_DEVICE_API_AMBA_STRING		"vfio-amba"
 #define VFIO_DEVICE_API_CCW_STRING		"vfio-ccw"
+#define VFIO_DEVICE_API_AP_STRING		"vfio-ap"
 
 /**
  * VFIO_DEVICE_GET_REGION_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 8,

commit 30656177c4080460b936709ff6648f201d7d2c1a
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Mar 21 12:46:21 2018 -0600

    vfio/pci: Add ioeventfd support
    
    The ioeventfd here is actually irqfd handling of an ioeventfd such as
    supported in KVM.  A user is able to pre-program a device write to
    occur when the eventfd triggers.  This is yet another instance of
    eventfd-irqfd triggering between KVM and vfio.  The impetus for this
    is high frequency writes to pages which are virtualized in QEMU.
    Enabling this near-direct write path for selected registers within
    the virtualized page can improve performance and reduce overhead.
    Specifically this is initially targeted at NVIDIA graphics cards where
    the driver issues a write to an MMIO register within a virtualized
    region in order to allow the MSI interrupt to re-trigger.
    
    Reviewed-by: Peter Xu <peterx@redhat.com>
    Reviewed-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index c74372163ed2..1aa7b82e8169 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -575,6 +575,33 @@ struct vfio_device_gfx_plane_info {
 
 #define VFIO_DEVICE_GET_GFX_DMABUF _IO(VFIO_TYPE, VFIO_BASE + 15)
 
+/**
+ * VFIO_DEVICE_IOEVENTFD - _IOW(VFIO_TYPE, VFIO_BASE + 16,
+ *                              struct vfio_device_ioeventfd)
+ *
+ * Perform a write to the device at the specified device fd offset, with
+ * the specified data and width when the provided eventfd is triggered.
+ * vfio bus drivers may not support this for all regions, for all widths,
+ * or at all.  vfio-pci currently only enables support for BAR regions,
+ * excluding the MSI-X vector table.
+ *
+ * Return: 0 on success, -errno on failure.
+ */
+struct vfio_device_ioeventfd {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_DEVICE_IOEVENTFD_8		(1 << 0) /* 1-byte write */
+#define VFIO_DEVICE_IOEVENTFD_16	(1 << 1) /* 2-byte write */
+#define VFIO_DEVICE_IOEVENTFD_32	(1 << 2) /* 4-byte write */
+#define VFIO_DEVICE_IOEVENTFD_64	(1 << 3) /* 8-byte write */
+#define VFIO_DEVICE_IOEVENTFD_SIZE_MASK	(0xf)
+	__u64	offset;			/* device fd offset of write */
+	__u64	data;			/* data to be written */
+	__s32	fd;			/* -1 for de-assignment */
+};
+
+#define VFIO_DEVICE_IOEVENTFD		_IO(VFIO_TYPE, VFIO_BASE + 16)
+
 /* -------- API for Type1 VFIO IOMMU -------- */
 
 /**

commit 4bf772b14675411a69b3c807f73006de0fe4b649
Merge: 3879ae653a3e 24b8ef699e82
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 1 17:48:47 2018 -0800

    Merge tag 'drm-for-v4.16' of git://people.freedesktop.org/~airlied/linux
    
    Pull drm updates from Dave Airlie:
     "This seems to have been a comparatively quieter merge window, I assume
      due to holidays etc. The "biggest" change is AMD header cleanups, which
      merge/remove a bunch of them. The AMD gpu scheduler is now being made generic
      with the etnaviv driver wanting to reuse the code, hopefully other drivers
      can go in the same direction.
    
      Otherwise it's the usual lots of stuff in i915/amdgpu, not so much stuff
      elsewhere.
    
      Core:
       - Add .last_close and .output_poll_changed helpers to reduce driver footprints
       - Fix plane clipping
       - Improved debug printing support
       - Add panel orientation property
       - Update edid derived properties at edid setting
       - Reduction in fbdev driver footprint
       - Move amdgpu scheduler into core for other drivers to use.
    
      i915:
       - Selftest and IGT improvements
       - Fast boot prep work on IPS, pipe config
       - HW workarounds for Cannonlake, Geminilake
       - Cannonlake clock and HDMI2.0 fixes
       - GPU cache invalidation and context switch improvements
       - Display planes cleanup
       - New PMU interface for perf queries
       - New firmware support for KBL/SKL
       - Geminilake HW workaround for perforamce
       - Coffeelake stolen memory improvements
       - GPU reset robustness work
       - Cannonlake horizontal plane flipping
       - GVT work
    
      amdgpu/radeon:
       - RV and Vega header file cleanups (lots of lines gone!)
       - TTM operation context support
       - 48-bit GPUVM support for Vega/RV
       - ECC support for Vega
       - Resizeable BAR support
       - Multi-display sync support
       - Enable swapout for reserved BOs during allocation
       - S3 fixes on Raven
       - GPU reset cleanup and fixes
       - 2+1 level GPU page table
    
      amdkfd:
       - GFX7/8 SDMA user queues support
       - Hardware scheduling for multiple processes
       - dGPU prep work
    
      rcar:
       - Added R8A7743/5 support
       - System suspend/resume support
    
      sun4i:
       - Multi-plane support for YUV formats
       - A83T and LVDS support
    
      msm:
       - Devfreq support for GPU
    
      tegra:
       - Prep work for adding Tegra186 support
       - Tegra186 HDMI support
       - HDMI2.0 and zpos support by using generic helpers
    
      tilcdc:
       - Misc fixes
    
      omapdrm:
       - Support memory bandwidth limits
       - DSI command mode panel cleanups
       - DMM error handling
    
      exynos:
       - drop the old IPP subdriver.
    
      etnaviv:
       - Occlusion query fixes
       - Job handling fixes
       - Prep work for hooking in gpu scheduler
    
      armada:
       - Move closer to atomic modesetting
       - Allow disabling primary plane if overlay is full screen
    
      imx:
       - Format modifier support
       - Add tile prefetch to PRE
       - Runtime PM support for PRG
    
      ast:
       - fix LUT loading"
    
    * tag 'drm-for-v4.16' of git://people.freedesktop.org/~airlied/linux: (1471 commits)
      drm/ast: Load lut in crtc_commit
      drm: Check for lessee in DROP_MASTER ioctl
      drm: fix gpu scheduler link order
      drm/amd/display: Demote error print to debug print when ATOM impl missing
      dma-buf: fix reservation_object_wait_timeout_rcu once more v2
      drm/amdgpu: Avoid leaking PM domain on driver unbind (v2)
      drm/amd/amdgpu: Add Polaris version check
      drm/amdgpu: Reenable manual GPU reset from sysfs
      drm/amdgpu: disable MMHUB power gating on raven
      drm/ttm: Don't unreserve swapped BOs that were previously reserved
      drm/ttm: Don't add swapped BOs to swap-LRU list
      drm/amdgpu: only check for ECC on Vega10
      drm/amd/powerplay: Fix smu_table_entry.handle type
      drm/ttm: add VADDR_FLAG_UPDATED_COUNT to correctly update dma_page global count
      drm: Fix PANEL_ORIENTATION_QUIRKS breaking the Kconfig DRM menuconfig
      drm/radeon: fill in rb backend map on evergreen/ni.
      drm/amdgpu/gfx9: fix ngg enablement to clear gds reserved memory (v2)
      drm/ttm: only free pages rather than update global memory count together
      drm/amdgpu: fix CPU based VM updates
      drm/amdgpu: fix typo in amdgpu_vce_validate_bo
      ...

commit a32295c612c57990d17fb0f41e7134394b2f35f6
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Dec 13 13:31:31 2017 +1100

    vfio-pci: Allow mapping MSIX BAR
    
    By default VFIO disables mapping of MSIX BAR to the userspace as
    the userspace may program it in a way allowing spurious interrupts;
    instead the userspace uses the VFIO_DEVICE_SET_IRQS ioctl.
    In order to eliminate guessing from the userspace about what is
    mmapable, VFIO also advertises a sparse list of regions allowed to mmap.
    
    This works fine as long as the system page size equals to the MSIX
    alignment requirement which is 4KB. However with a bigger page size
    the existing code prohibits mapping non-MSIX parts of a page with MSIX
    structures so these parts have to be emulated via slow reads/writes on
    a VFIO device fd. If these emulated bits are accessed often, this has
    serious impact on performance.
    
    This allows mmap of the entire BAR containing MSIX vector table.
    
    This removes the sparse capability for PCI devices as it becomes useless.
    
    As the userspace needs to know for sure whether mmapping of the MSIX
    vector containing data can succeed, this adds a new capability -
    VFIO_REGION_INFO_CAP_MSIX_MAPPABLE - which explicitly tells the userspace
    that the entire BAR can be mmapped.
    
    This does not touch the MSIX mangling in the BAR read/write handlers as
    we are doing this just to enable direct access to non MSIX registers.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw - fixup whitespace, trim function name]
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index e3301dbd27d4..0d914350f7bf 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -301,6 +301,16 @@ struct vfio_region_info_cap_type {
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_HOST_CFG	(2)
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_LPC_CFG	(3)
 
+/*
+ * The MSIX mappable capability informs that MSIX data of a BAR can be mmapped
+ * which allows direct access to non-MSIX registers which happened to be within
+ * the same system page.
+ *
+ * Even though the userspace gets direct access to the MSIX data, the existing
+ * VFIO_DEVICE_SET_IRQS interface must still be used for MSIX configuration.
+ */
+#define VFIO_REGION_INFO_CAP_MSIX_MAPPABLE	3
+
 /**
  * VFIO_DEVICE_GET_IRQ_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 9,
  *				    struct vfio_irq_info)

commit 6647852abc1fd74e9c5e0dcf404ea4cb9c929630
Merge: 3e72be177cf1 3f1f0b1c57dd
Author: Rodrigo Vivi <rodrigo.vivi@intel.com>
Date:   Fri Dec 8 10:15:30 2017 -0800

    Merge airlied/drm-next into drm-intel-next-queued
    
    Chris requested this backmerge for a reconciliation on
    drm_print.h between drm-misc-next and drm-intel-next-queued
    
    Signed-off-by: Rodrigo Vivi <rodrigo.vivi@intel.com>

commit e20eaa2382e7888a4e06ccb015c476a6fb1fda0c
Author: Tina Zhang <tina.zhang@intel.com>
Date:   Thu Nov 23 16:26:35 2017 +0800

    vfio: ABI for mdev display dma-buf operation
    
    Add VFIO_DEVICE_QUERY_GFX_PLANE ioctl command to let user query and get
    a plane and its information. So far, two types of buffers are supported:
    buffers based on dma-buf and buffers based on region.
    
    This ioctl can be invoked with:
    1) Either DMABUF or REGION flag. Vendor driver returns a plane_info
    successfully only when the specific kind of buffer is supported.
    2) Flag PROBE. And at the same time either DMABUF or REGION must be set,
    so that vendor driver returns success only when the specific kind of
    buffer is supported.
    
    Add VFIO_DEVICE_GET_GFX_DMABUF ioctl command to let user get a specific
    dma-buf fd of an exposed MDEV buffer provided by dmabuf_id which was
    returned in VFIO_DEVICE_QUERY_GFX_PLANE ioctl command.
    
    The life cycle of an exposed MDEV buffer is handled by userspace and
    tracked by kernel space. The returned dmabuf_id in struct vfio_device_
    query_gfx_plane can be a new id of a new exposed buffer or an old id of
    a re-exported buffer. Host user can check the value of dmabuf_id to see
    if it needs to create new resources according to the new exposed buffer
    or just re-use the existing resource related to the old buffer.
    
    v18:
    - update comments for VFIO_DEVICE_GET_GFX_DMABUF. (Alex)
    
    v17:
    - modify VFIO_DEVICE_GET_GFX_DMABUF interface. (Alex)
    
    v16:
    - add x_hot and y_hot fields. (Gerd)
    - add comments for VFIO_DEVICE_GET_GFX_DMABUF. (Alex)
    - rebase to 4.14.0-rc6.
    
    v15:
    - add a ioctl to get a dmabuf for a given dmabuf id. (Gerd)
    
    v14:
    - add PROBE, DMABUF and REGION flags. (Alex)
    
    v12:
    - add drm_format_mod back. (Gerd and Zhenyu)
    - add region_index. (Gerd)
    
    v11:
    - rename plane_type to drm_plane_type. (Gerd)
    - move fields of vfio_device_query_gfx_plane to vfio_device_gfx_plane_info.
      (Gerd)
    - remove drm_format_mod, start fields. (Daniel)
    - remove plane_id.
    
    v10:
    - refine the ABI API VFIO_DEVICE_QUERY_GFX_PLANE. (Alex) (Gerd)
    
    v3:
    - add a field gvt_plane_info in the drm_i915_gem_obj structure to save
      the decoded plane information to avoid look up while need the plane
      info. (Gerd)
    
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Reviewed-by: Gerd Hoffmann <kraxel@redhat.com>
    Reviewed-by: Kirti Wankhede <kwankhede@nvidia.com>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index ae461050661a..5c1cca2ba04d 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -502,6 +502,68 @@ struct vfio_pci_hot_reset {
 
 #define VFIO_DEVICE_PCI_HOT_RESET	_IO(VFIO_TYPE, VFIO_BASE + 13)
 
+/**
+ * VFIO_DEVICE_QUERY_GFX_PLANE - _IOW(VFIO_TYPE, VFIO_BASE + 14,
+ *                                    struct vfio_device_query_gfx_plane)
+ *
+ * Set the drm_plane_type and flags, then retrieve the gfx plane info.
+ *
+ * flags supported:
+ * - VFIO_GFX_PLANE_TYPE_PROBE and VFIO_GFX_PLANE_TYPE_DMABUF are set
+ *   to ask if the mdev supports dma-buf. 0 on support, -EINVAL on no
+ *   support for dma-buf.
+ * - VFIO_GFX_PLANE_TYPE_PROBE and VFIO_GFX_PLANE_TYPE_REGION are set
+ *   to ask if the mdev supports region. 0 on support, -EINVAL on no
+ *   support for region.
+ * - VFIO_GFX_PLANE_TYPE_DMABUF or VFIO_GFX_PLANE_TYPE_REGION is set
+ *   with each call to query the plane info.
+ * - Others are invalid and return -EINVAL.
+ *
+ * Note:
+ * 1. Plane could be disabled by guest. In that case, success will be
+ *    returned with zero-initialized drm_format, size, width and height
+ *    fields.
+ * 2. x_hot/y_hot is set to 0xFFFFFFFF if no hotspot information available
+ *
+ * Return: 0 on success, -errno on other failure.
+ */
+struct vfio_device_gfx_plane_info {
+	__u32 argsz;
+	__u32 flags;
+#define VFIO_GFX_PLANE_TYPE_PROBE (1 << 0)
+#define VFIO_GFX_PLANE_TYPE_DMABUF (1 << 1)
+#define VFIO_GFX_PLANE_TYPE_REGION (1 << 2)
+	/* in */
+	__u32 drm_plane_type;	/* type of plane: DRM_PLANE_TYPE_* */
+	/* out */
+	__u32 drm_format;	/* drm format of plane */
+	__u64 drm_format_mod;   /* tiled mode */
+	__u32 width;	/* width of plane */
+	__u32 height;	/* height of plane */
+	__u32 stride;	/* stride of plane */
+	__u32 size;	/* size of plane in bytes, align on page*/
+	__u32 x_pos;	/* horizontal position of cursor plane */
+	__u32 y_pos;	/* vertical position of cursor plane*/
+	__u32 x_hot;    /* horizontal position of cursor hotspot */
+	__u32 y_hot;    /* vertical position of cursor hotspot */
+	union {
+		__u32 region_index;	/* region index */
+		__u32 dmabuf_id;	/* dma-buf id */
+	};
+};
+
+#define VFIO_DEVICE_QUERY_GFX_PLANE _IO(VFIO_TYPE, VFIO_BASE + 14)
+
+/**
+ * VFIO_DEVICE_GET_GFX_DMABUF - _IOW(VFIO_TYPE, VFIO_BASE + 15, __u32)
+ *
+ * Return a new dma-buf file descriptor for an exposed guest framebuffer
+ * described by the provided dmabuf_id. The dmabuf_id is returned from VFIO_
+ * DEVICE_QUERY_GFX_PLANE as a token of the exposed guest framebuffer.
+ */
+
+#define VFIO_DEVICE_GET_GFX_DMABUF _IO(VFIO_TYPE, VFIO_BASE + 15)
+
 /* -------- API for Type1 VFIO IOMMU -------- */
 
 /**

commit e2be04c7f9958dde770eeb8b30e829ca969b37bb
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:09:13 2017 +0100

    License cleanup: add SPDX license identifier to uapi header files with a license
    
    Many user space API headers have licensing information, which is either
    incomplete, badly formatted or just a shorthand for referring to the
    license under which the file is supposed to be.  This makes it hard for
    compliance tools to determine the correct license.
    
    Update these files with an SPDX license identifier.  The identifier was
    chosen based on the license information in the file.
    
    GPL/LGPL licensed headers get the matching GPL/LGPL SPDX license
    identifier with the added 'WITH Linux-syscall-note' exception, which is
    the officially assigned exception identifier for the kernel syscall
    exception:
    
       NOTE! This copyright does *not* cover user programs that use kernel
       services by normal system calls - this is merely considered normal use
       of the kernel, and does *not* fall under the heading of "derived work".
    
    This exception makes it possible to include GPL headers into non GPL
    code, without confusing license compliance tools.
    
    Headers which have either explicit dual licensing or are just licensed
    under a non GPL license are updated with the corresponding SPDX
    identifier and the GPLv2 with syscall exception identifier.  The format
    is:
            ((GPL-2.0 WITH Linux-syscall-note) OR SPDX-ID-OF-OTHER-LICENSE)
    
    SPDX license identifiers are a legally binding shorthand, which can be
    used instead of the full boiler plate text.  The update does not remove
    existing license information as this has to be done on a case by case
    basis and the copyright holders might have to be consulted. This will
    happen in a separate step.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.  See the previous patch in this series for the
    methodology of how this patch was researched.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index ae461050661a..e3301dbd27d4 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
 /*
  * VFIO API definition
  *

commit 120e214e504fd6d3e33ec4b661193600b2faab95
Author: Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>
Date:   Fri Mar 17 04:17:38 2017 +0100

    vfio: ccw: realize VFIO_DEVICE_G(S)ET_IRQ_INFO ioctls
    
    Realize VFIO_DEVICE_GET_IRQ_INFO ioctl to retrieve
    VFIO_CCW_IO_IRQ information.
    
    Realize VFIO_DEVICE_SET_IRQS ioctl to set an eventfd fd for
    VFIO_CCW_IO_IRQ. Once a write operation to the ccw_io_region
    was performed, trigger a signal on this fd.
    
    Reviewed-by: Pierre Morel <pmorel@linux.vnet.ibm.com>
    Signed-off-by: Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Message-Id: <20170317031743.40128-12-bjsdjshi@linux.vnet.ibm.com>
    Signed-off-by: Cornelia Huck <cornelia.huck@de.ibm.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 3fd70ffe9d78..ae461050661a 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -449,8 +449,9 @@ enum {
 };
 
 /*
- * The vfio-ccw bus driver makes use of the following fixed region.
- * Unimplemented regions return a size of zero.
+ * The vfio-ccw bus driver makes use of the following fixed region and
+ * IRQ index mapping. Unimplemented regions return a size of zero.
+ * Unimplemented IRQ types return a count of zero.
  */
 
 enum {
@@ -458,6 +459,11 @@ enum {
 	VFIO_CCW_NUM_REGIONS
 };
 
+enum {
+	VFIO_CCW_IO_IRQ_INDEX,
+	VFIO_CCW_NUM_IRQS
+};
+
 /**
  * VFIO_DEVICE_GET_PCI_HOT_RESET_INFO - _IORW(VFIO_TYPE, VFIO_BASE + 12,
  *					      struct vfio_pci_hot_reset_info)

commit e01bcdd61320c91c826376e0a7dd96ef8e85dd18
Author: Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>
Date:   Fri Mar 17 04:17:36 2017 +0100

    vfio: ccw: realize VFIO_DEVICE_GET_REGION_INFO ioctl
    
    Introduce device information about vfio-ccw: VFIO_DEVICE_FLAGS_CCW.
    Realize VFIO_DEVICE_GET_REGION_INFO ioctl for vfio-ccw.
    
    Reviewed-by: Pierre Morel <pmorel@linux.vnet.ibm.com>
    Signed-off-by: Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Message-Id: <20170317031743.40128-10-bjsdjshi@linux.vnet.ibm.com>
    Signed-off-by: Cornelia Huck <cornelia.huck@de.ibm.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 61837890c132..3fd70ffe9d78 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -198,6 +198,7 @@ struct vfio_device_info {
 #define VFIO_DEVICE_FLAGS_PCI	(1 << 1)	/* vfio-pci device */
 #define VFIO_DEVICE_FLAGS_PLATFORM (1 << 2)	/* vfio-platform device */
 #define VFIO_DEVICE_FLAGS_AMBA  (1 << 3)	/* vfio-amba device */
+#define VFIO_DEVICE_FLAGS_CCW	(1 << 4)	/* vfio-ccw device */
 	__u32	num_regions;	/* Max region index + 1 */
 	__u32	num_irqs;	/* Max IRQ index + 1 */
 };
@@ -447,6 +448,16 @@ enum {
 	VFIO_PCI_NUM_IRQS
 };
 
+/*
+ * The vfio-ccw bus driver makes use of the following fixed region.
+ * Unimplemented regions return a size of zero.
+ */
+
+enum {
+	VFIO_CCW_CONFIG_REGION_INDEX,
+	VFIO_CCW_NUM_REGIONS
+};
+
 /**
  * VFIO_DEVICE_GET_PCI_HOT_RESET_INFO - _IORW(VFIO_TYPE, VFIO_BASE + 12,
  *					      struct vfio_pci_hot_reset_info)

commit aec390b937dcaf11c01483b8c348a2b004119aa7
Author: Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>
Date:   Fri Mar 17 04:17:30 2017 +0100

    vfio: ccw: define device_api strings
    
    Define vfio-ccw device API strings. CCW vendor driver using mediated
    device framework should use this string for device_api attribute.
    
    Reviewed-by: Pierre Morel <pmorel@linux.vnet.ibm.com>
    Signed-off-by: Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Message-Id: <20170317031743.40128-4-bjsdjshi@linux.vnet.ibm.com>
    Signed-off-by: Cornelia Huck <cornelia.huck@de.ibm.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 519eff362c1c..61837890c132 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -212,6 +212,7 @@ struct vfio_device_info {
 #define VFIO_DEVICE_API_PCI_STRING		"vfio-pci"
 #define VFIO_DEVICE_API_PLATFORM_STRING		"vfio-platform"
 #define VFIO_DEVICE_API_AMBA_STRING		"vfio-amba"
+#define VFIO_DEVICE_API_CCW_STRING		"vfio-ccw"
 
 /**
  * VFIO_DEVICE_GET_REGION_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 8,

commit 2818c6e91980d966d015a9f763ab24b41e6a7c3d
Author: Kirti Wankhede <kwankhede@nvidia.com>
Date:   Thu Nov 17 02:16:30 2016 +0530

    vfio: Define device_api strings
    
    Defined device API strings. Vendor driver using mediated device
    framework should use corresponding string for device_api attribute.
    
    Signed-off-by: Kirti Wankhede <kwankhede@nvidia.com>
    Signed-off-by: Neo Jia <cjia@nvidia.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 255a2113f53c..519eff362c1c 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -203,6 +203,16 @@ struct vfio_device_info {
 };
 #define VFIO_DEVICE_GET_INFO		_IO(VFIO_TYPE, VFIO_BASE + 7)
 
+/*
+ * Vendor driver using Mediated device framework should provide device_api
+ * attribute in supported type attribute groups. Device API string should be one
+ * of the following corresponding to device flags in vfio_device_info structure.
+ */
+
+#define VFIO_DEVICE_API_PCI_STRING		"vfio-pci"
+#define VFIO_DEVICE_API_PLATFORM_STRING		"vfio-platform"
+#define VFIO_DEVICE_API_AMBA_STRING		"vfio-amba"
+
 /**
  * VFIO_DEVICE_GET_REGION_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 8,
  *				       struct vfio_region_info)

commit f572a960a15e8bb56599f6d2358a9c18f0808e91
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Feb 22 16:02:45 2016 -0700

    vfio/pci: Intel IGD host and LCP bridge config space access
    
    Provide read-only access to PCI config space of the PCI host bridge
    and LPC bridge through device specific regions.  This may be used to
    configure a VM with matching register contents to satisfy driver
    requirements.  Providing this through the vfio file descriptor removes
    an additional userspace requirement for access through pci-sysfs and
    removes the CAP_SYS_ADMIN requirement that doesn't appear to apply to
    the specific devices we're accessing.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index e622982dbc53..255a2113f53c 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -283,7 +283,10 @@ struct vfio_region_info_cap_type {
 #define VFIO_REGION_TYPE_PCI_VENDOR_TYPE	(1 << 31)
 #define VFIO_REGION_TYPE_PCI_VENDOR_MASK	(0xffff)
 
+/* 8086 Vendor sub-types */
 #define VFIO_REGION_SUBTYPE_INTEL_IGD_OPREGION	(1)
+#define VFIO_REGION_SUBTYPE_INTEL_IGD_HOST_CFG	(2)
+#define VFIO_REGION_SUBTYPE_INTEL_IGD_LPC_CFG	(3)
 
 /**
  * VFIO_DEVICE_GET_IRQ_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 9,

commit 5846ff54e87d8bab4f1e330af0b5407747a0a57e
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Feb 22 16:02:43 2016 -0700

    vfio/pci: Intel IGD OpRegion support
    
    This is the first consumer of vfio device specific resource support,
    providing read-only access to the OpRegion for Intel graphics devices.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 1c37a0e500c6..e622982dbc53 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -280,6 +280,11 @@ struct vfio_region_info_cap_type {
 	__u32 subtype;	/* type specific */
 };
 
+#define VFIO_REGION_TYPE_PCI_VENDOR_TYPE	(1 << 31)
+#define VFIO_REGION_TYPE_PCI_VENDOR_MASK	(0xffff)
+
+#define VFIO_REGION_SUBTYPE_INTEL_IGD_OPREGION	(1)
+
 /**
  * VFIO_DEVICE_GET_IRQ_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 9,
  *				    struct vfio_irq_info)

commit c7bb4cb40f89224dc55755178343728e30dd583a
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Feb 22 16:02:38 2016 -0700

    vfio: Define device specific region type capability
    
    To this point vfio has only provided an interface to the user that
    allows them to determine the number of regions and specifics about
    each region.  What the region represents is left to the vfio bus
    driver.  vfio-pci chooses to use fixed indexes for fixed resources,
    index 0 is BAR0, 1 is BAR1,... 7 is config space, etc.  This works
    pretty well since all PCI devices have these regions, even if they
    don't necessarily populate all of them.  Then we start to add things
    like VGA, which only certain device even support.  We added this the
    same way, but now we've wasted a region index, and due to our offset
    implementation the corresponding address space, for all devices.
    
    Rather than continuing that process, let's try to make regions self
    describing by including a capability that defines their type.  For
    vfio-pci we'll make the current VFIO_PCI_NUM_REGIONS fixed, defining
    the end of the static indexes and the beginning of self describing
    regions.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index fde7b1e60948..1c37a0e500c6 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -252,6 +252,34 @@ struct vfio_region_info_cap_sparse_mmap {
 	struct vfio_region_sparse_mmap_area areas[];
 };
 
+/*
+ * The device specific type capability allows regions unique to a specific
+ * device or class of devices to be exposed.  This helps solve the problem for
+ * vfio bus drivers of defining which region indexes correspond to which region
+ * on the device, without needing to resort to static indexes, as done by
+ * vfio-pci.  For instance, if we were to go back in time, we might remove
+ * VFIO_PCI_VGA_REGION_INDEX and let vfio-pci simply define that all indexes
+ * greater than or equal to VFIO_PCI_NUM_REGIONS are device specific and we'd
+ * make a "VGA" device specific type to describe the VGA access space.  This
+ * means that non-VGA devices wouldn't need to waste this index, and thus the
+ * address space associated with it due to implementation of device file
+ * descriptor offsets in vfio-pci.
+ *
+ * The current implementation is now part of the user ABI, so we can't use this
+ * for VGA, but there are other upcoming use cases, such as opregions for Intel
+ * IGD devices and framebuffers for vGPU devices.  We missed VGA, but we'll
+ * use this for future additions.
+ *
+ * The structure below defines version 1 of this capability.
+ */
+#define VFIO_REGION_INFO_CAP_TYPE	2
+
+struct vfio_region_info_cap_type {
+	struct vfio_info_cap_header header;
+	__u32 type;	/* global per bus driver */
+	__u32 subtype;	/* type specific */
+};
+
 /**
  * VFIO_DEVICE_GET_IRQ_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 9,
  *				    struct vfio_irq_info)
@@ -387,7 +415,8 @@ enum {
 	 * between described ranges are unimplemented.
 	 */
 	VFIO_PCI_VGA_REGION_INDEX,
-	VFIO_PCI_NUM_REGIONS
+	VFIO_PCI_NUM_REGIONS = 9 /* Fixed user ABI, region indexes >=9 use */
+				 /* device specific cap to define content. */
 };
 
 enum {

commit ff63eb638d63b95e489f976428f1df01391e15e4
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Feb 22 16:02:35 2016 -0700

    vfio: Define sparse mmap capability for regions
    
    We can't always support mmap across an entire device region, for
    example we deny mmaps covering the MSI-X table of PCI devices, but
    we don't really have a way to report it.  We expect the user to
    implicitly know this restriction.  We also can't split the region
    because vfio-pci defines an API with fixed region index to BAR
    number mapping.  We therefore define a new capability which lists
    areas within the region that may be mmap'd.  In addition to the
    MSI-X case, this potentially enables in-kernel emulation and
    extensions to devices.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index d508adf17610..fde7b1e60948 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -221,13 +221,37 @@ struct vfio_region_info {
 #define VFIO_REGION_INFO_FLAG_READ	(1 << 0) /* Region supports read */
 #define VFIO_REGION_INFO_FLAG_WRITE	(1 << 1) /* Region supports write */
 #define VFIO_REGION_INFO_FLAG_MMAP	(1 << 2) /* Region supports mmap */
+#define VFIO_REGION_INFO_FLAG_CAPS	(1 << 3) /* Info supports caps */
 	__u32	index;		/* Region index */
-	__u32	resv;		/* Reserved for alignment */
+	__u32	cap_offset;	/* Offset within info struct of first cap */
 	__u64	size;		/* Region size (bytes) */
 	__u64	offset;		/* Region offset from start of device fd */
 };
 #define VFIO_DEVICE_GET_REGION_INFO	_IO(VFIO_TYPE, VFIO_BASE + 8)
 
+/*
+ * The sparse mmap capability allows finer granularity of specifying areas
+ * within a region with mmap support.  When specified, the user should only
+ * mmap the offset ranges specified by the areas array.  mmaps outside of the
+ * areas specified may fail (such as the range covering a PCI MSI-X table) or
+ * may result in improper device behavior.
+ *
+ * The structures below define version 1 of this capability.
+ */
+#define VFIO_REGION_INFO_CAP_SPARSE_MMAP	1
+
+struct vfio_region_sparse_mmap_area {
+	__u64	offset;	/* Offset of mmap'able area within region */
+	__u64	size;	/* Size of mmap'able area */
+};
+
+struct vfio_region_info_cap_sparse_mmap {
+	struct vfio_info_cap_header header;
+	__u32	nr_areas;
+	__u32	reserved;
+	struct vfio_region_sparse_mmap_area areas[];
+};
+
 /**
  * VFIO_DEVICE_GET_IRQ_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 9,
  *				    struct vfio_irq_info)

commit c84982adb23bcf3b99b79ca33527cd2625fbe279
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Feb 22 16:02:32 2016 -0700

    vfio: Define capability chains
    
    We have a few cases where we need to extend the data returned from the
    INFO ioctls in VFIO.  For instance we already have devices exposed
    through vfio-pci where VFIO_DEVICE_GET_REGION_INFO reports the region
    as mmap-capable, but really only supports sparse mmaps, avoiding the
    MSI-X table.  If we wanted to provide in-kernel emulation or extended
    functionality for devices, we'd also want the ability to tell the
    user not to mmap various regions, rather than forcing them to figure
    it out on their own.
    
    Another example is VFIO_IOMMU_GET_INFO.  We'd really like to expose
    the actual IOVA capabilities of the IOMMU rather than letting the
    user assume the address space they have available to them.  We could
    add IOVA base and size fields to struct vfio_iommu_type1_info, but
    what if we have multiple IOVA ranges.  For instance x86 uses a range
    of addresses at 0xfee00000 for MSI vectors.  These typically are not
    available for standard DMA IOVA mappings and splits our available IOVA
    space into two ranges.  POWER systems have both an IOVA window below
    4G as well as dynamic data window which they can use to remap all of
    guest memory.
    
    Representing variable sized arrays within a fixed structure makes it
    very difficult to parse, we'd therefore like to put this data beyond
    fixed fields within the data structures.  One way to do this is to
    emulate capabilities in PCI configuration space.  A new flag indciates
    whether capabilties are supported and a new fixed field reports the
    offset of the first entry.  Users can then walk the chain to find
    capabilities, adding capabilities does not require additional fields
    in the fixed structure, and parsing variable sized data becomes
    trivial.
    
    This patch outlines the theory and base header structure, which
    should be shared by all future users.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 7d7a4c6f2090..d508adf17610 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -59,6 +59,33 @@
 #define VFIO_TYPE	(';')
 #define VFIO_BASE	100
 
+/*
+ * For extension of INFO ioctls, VFIO makes use of a capability chain
+ * designed after PCI/e capabilities.  A flag bit indicates whether
+ * this capability chain is supported and a field defined in the fixed
+ * structure defines the offset of the first capability in the chain.
+ * This field is only valid when the corresponding bit in the flags
+ * bitmap is set.  This offset field is relative to the start of the
+ * INFO buffer, as is the next field within each capability header.
+ * The id within the header is a shared address space per INFO ioctl,
+ * while the version field is specific to the capability id.  The
+ * contents following the header are specific to the capability id.
+ */
+struct vfio_info_cap_header {
+	__u16	id;		/* Identifies capability */
+	__u16	version;	/* Version specific to the capability ID */
+	__u32	next;		/* Offset of next capability */
+};
+
+/*
+ * Callers of INFO ioctls passing insufficiently sized buffers will see
+ * the capability chain flag bit set, a zero value for the first capability
+ * offset (if available within the provided argsz), and argsz will be
+ * updated to report the necessary buffer size.  For compatibility, the
+ * INFO ioctl will not report error in this case, but the capability chain
+ * will not be available.
+ */
+
 /* -------- IOCTLs for VFIO file descriptor (/dev/vfio/vfio) -------- */
 
 /**

commit 03a76b60f8ba27974e2d252bc555d2c103420e15
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Dec 21 15:13:33 2015 -0700

    vfio: Include No-IOMMU mode
    
    There is really no way to safely give a user full access to a DMA
    capable device without an IOMMU to protect the host system.  There is
    also no way to provide DMA translation, for use cases such as device
    assignment to virtual machines.  However, there are still those users
    that want userspace drivers even under those conditions.  The UIO
    driver exists for this use case, but does not provide the degree of
    device access and programming that VFIO has.  In an effort to avoid
    code duplication, this introduces a No-IOMMU mode for VFIO.
    
    This mode requires building VFIO with CONFIG_VFIO_NOIOMMU and enabling
    the "enable_unsafe_noiommu_mode" option on the vfio driver.  This
    should make it very clear that this mode is not safe.  Additionally,
    CAP_SYS_RAWIO privileges are necessary to work with groups and
    containers using this mode.  Groups making use of this support are
    named /dev/vfio/noiommu-$GROUP and can only make use of the special
    VFIO_NOIOMMU_IOMMU for the container.  Use of this mode, specifically
    binding a device without a native IOMMU group to a VFIO bus driver
    will taint the kernel and should therefore not be considered
    supported.  This patch includes no-iommu support for the vfio-pci bus
    driver only.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Michael S. Tsirkin <mst@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index d1172331ca62..7d7a4c6f2090 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -38,6 +38,13 @@
 
 #define VFIO_SPAPR_TCE_v2_IOMMU		7
 
+/*
+ * The No-IOMMU IOMMU offers no translation or isolation for devices and
+ * supports no ioctls outside of VFIO_CHECK_EXTENSION.  Use of VFIO's No-IOMMU
+ * code will taint the host kernel and should be used with extreme caution.
+ */
+#define VFIO_NOIOMMU_IOMMU		8
+
 /*
  * The IOCTL interface is designed for extensibility by embedding the
  * structure length (argsz) and flags into structures passed between

commit 77d6bd47cc2824af016086c2bd4650685b159e22
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Dec 18 12:35:47 2015 +1100

    vfio: Add explicit alignments in vfio_iommu_spapr_tce_create
    
    The vfio_iommu_spapr_tce_create struct has 4x32bit and 2x64bit fields
    which should have resulted in sizeof(fio_iommu_spapr_tce_create) equal
    to 32 bytes. However due to the gcc's default alignment, the actual
    size of this struct is 40 bytes.
    
    This fills gaps with __resv1/2 fields.
    
    This should not cause any change in behavior.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Acked-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 9fd7b5d8df2f..d1172331ca62 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -568,8 +568,10 @@ struct vfio_iommu_spapr_tce_create {
 	__u32 flags;
 	/* in */
 	__u32 page_shift;
+	__u32 __resv1;
 	__u64 window_size;
 	__u32 levels;
+	__u32 __resv2;
 	/* out */
 	__u64 start_addr;
 };

commit ae5515d66362b9d96cdcfce504567f0b8b7bd83e
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Dec 4 08:38:42 2015 -0700

    Revert: "vfio: Include No-IOMMU mode"
    
    Revert commit 033291eccbdb ("vfio: Include No-IOMMU mode") due to lack
    of a user.  This was originally intended to fill a need for the DPDK
    driver, but uptake has been slow so rather than support an unproven
    kernel interface revert it and revisit when userspace catches up.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 751b69f858c8..9fd7b5d8df2f 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -38,13 +38,6 @@
 
 #define VFIO_SPAPR_TCE_v2_IOMMU		7
 
-/*
- * The No-IOMMU IOMMU offers no translation or isolation for devices and
- * supports no ioctls outside of VFIO_CHECK_EXTENSION.  Use of VFIO's No-IOMMU
- * code will taint the host kernel and should be used with extreme caution.
- */
-#define VFIO_NOIOMMU_IOMMU		8
-
 /*
  * The IOCTL interface is designed for extensibility by embedding the
  * structure length (argsz) and flags into structures passed between

commit 033291eccbdb1b70ffc02641edae19ac825dc75d
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Thu Oct 15 15:08:48 2015 -0600

    vfio: Include No-IOMMU mode
    
    There is really no way to safely give a user full access to a DMA
    capable device without an IOMMU to protect the host system.  There is
    also no way to provide DMA translation, for use cases such as device
    assignment to virtual machines.  However, there are still those users
    that want userspace drivers even under those conditions.  The UIO
    driver exists for this use case, but does not provide the degree of
    device access and programming that VFIO has.  In an effort to avoid
    code duplication, this introduces a No-IOMMU mode for VFIO.
    
    This mode requires building VFIO with CONFIG_VFIO_NOIOMMU and enabling
    the "enable_unsafe_noiommu_mode" option on the vfio driver.  This
    should make it very clear that this mode is not safe.  Additionally,
    CAP_SYS_RAWIO privileges are necessary to work with groups and
    containers using this mode.  Groups making use of this support are
    named /dev/vfio/noiommu-$GROUP and can only make use of the special
    VFIO_NOIOMMU_IOMMU for the container.  Use of this mode, specifically
    binding a device without a native IOMMU group to a VFIO bus driver
    will taint the kernel and should therefore not be considered
    supported.  This patch includes no-iommu support for the vfio-pci bus
    driver only.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Michael S. Tsirkin <mst@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 9fd7b5d8df2f..751b69f858c8 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -38,6 +38,13 @@
 
 #define VFIO_SPAPR_TCE_v2_IOMMU		7
 
+/*
+ * The No-IOMMU IOMMU offers no translation or isolation for devices and
+ * supports no ioctls outside of VFIO_CHECK_EXTENSION.  Use of VFIO's No-IOMMU
+ * code will taint the host kernel and should be used with extreme caution.
+ */
+#define VFIO_NOIOMMU_IOMMU		8
+
 /*
  * The IOCTL interface is designed for extensibility by embedding the
  * structure length (argsz) and flags into structures passed between

commit e633bc86a922468a82300eef5b9802e17be5e23d
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:26 2015 +1000

    vfio: powerpc/spapr: Support Dynamic DMA windows
    
    This adds create/remove window ioctls to create and remove DMA windows.
    sPAPR defines a Dynamic DMA windows capability which allows
    para-virtualized guests to create additional DMA windows on a PCI bus.
    The existing linux kernels use this new window to map the entire guest
    memory and switch to the direct DMA operations saving time on map/unmap
    requests which would normally happen in a big amounts.
    
    This adds 2 ioctl handlers - VFIO_IOMMU_SPAPR_TCE_CREATE and
    VFIO_IOMMU_SPAPR_TCE_REMOVE - to create and remove windows.
    Up to 2 windows are supported now by the hardware and by this driver.
    
    This changes VFIO_IOMMU_SPAPR_TCE_GET_INFO handler to return additional
    information such as a number of supported windows and maximum number
    levels of TCE tables.
    
    DDW is added as a capability, not as a SPAPR TCE IOMMU v2 unique feature
    as we still want to support v2 on platforms which cannot do DDW for
    the sake of TCE acceleration in KVM (coming soon).
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index fa84391a0d00..9fd7b5d8df2f 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -444,6 +444,23 @@ struct vfio_iommu_type1_dma_unmap {
 
 /* -------- Additional API for SPAPR TCE (Server POWERPC) IOMMU -------- */
 
+/*
+ * The SPAPR TCE DDW info struct provides the information about
+ * the details of Dynamic DMA window capability.
+ *
+ * @pgsizes contains a page size bitmask, 4K/64K/16M are supported.
+ * @max_dynamic_windows_supported tells the maximum number of windows
+ * which the platform can create.
+ * @levels tells the maximum number of levels in multi-level IOMMU tables;
+ * this allows splitting a table into smaller chunks which reduces
+ * the amount of physically contiguous memory required for the table.
+ */
+struct vfio_iommu_spapr_tce_ddw_info {
+	__u64 pgsizes;			/* Bitmap of supported page sizes */
+	__u32 max_dynamic_windows_supported;
+	__u32 levels;
+};
+
 /*
  * The SPAPR TCE info struct provides the information about the PCI bus
  * address ranges available for DMA, these values are programmed into
@@ -454,14 +471,17 @@ struct vfio_iommu_type1_dma_unmap {
  * addresses too so the window works as a filter rather than an offset
  * for IOVA addresses.
  *
- * A flag will need to be added if other page sizes are supported,
- * so as defined here, it is always 4k.
+ * Flags supported:
+ * - VFIO_IOMMU_SPAPR_INFO_DDW: informs the userspace that dynamic DMA windows
+ *   (DDW) support is present. @ddw is only supported when DDW is present.
  */
 struct vfio_iommu_spapr_tce_info {
 	__u32 argsz;
-	__u32 flags;			/* reserved for future use */
+	__u32 flags;
+#define VFIO_IOMMU_SPAPR_INFO_DDW	(1 << 0)	/* DDW supported */
 	__u32 dma32_window_start;	/* 32 bit window start (bytes) */
 	__u32 dma32_window_size;	/* 32 bit window size (bytes) */
+	struct vfio_iommu_spapr_tce_ddw_info ddw;
 };
 
 #define VFIO_IOMMU_SPAPR_TCE_GET_INFO	_IO(VFIO_TYPE, VFIO_BASE + 12)
@@ -534,6 +554,41 @@ struct vfio_iommu_spapr_register_memory {
  */
 #define VFIO_IOMMU_SPAPR_UNREGISTER_MEMORY	_IO(VFIO_TYPE, VFIO_BASE + 18)
 
+/**
+ * VFIO_IOMMU_SPAPR_TCE_CREATE - _IOWR(VFIO_TYPE, VFIO_BASE + 19, struct vfio_iommu_spapr_tce_create)
+ *
+ * Creates an additional TCE table and programs it (sets a new DMA window)
+ * to every IOMMU group in the container. It receives page shift, window
+ * size and number of levels in the TCE table being created.
+ *
+ * It allocates and returns an offset on a PCI bus of the new DMA window.
+ */
+struct vfio_iommu_spapr_tce_create {
+	__u32 argsz;
+	__u32 flags;
+	/* in */
+	__u32 page_shift;
+	__u64 window_size;
+	__u32 levels;
+	/* out */
+	__u64 start_addr;
+};
+#define VFIO_IOMMU_SPAPR_TCE_CREATE	_IO(VFIO_TYPE, VFIO_BASE + 19)
+
+/**
+ * VFIO_IOMMU_SPAPR_TCE_REMOVE - _IOW(VFIO_TYPE, VFIO_BASE + 20, struct vfio_iommu_spapr_tce_remove)
+ *
+ * Unprograms a TCE table from all groups in the container and destroys it.
+ * It receives a PCI bus offset as a window id.
+ */
+struct vfio_iommu_spapr_tce_remove {
+	__u32 argsz;
+	__u32 flags;
+	/* in */
+	__u64 start_addr;
+};
+#define VFIO_IOMMU_SPAPR_TCE_REMOVE	_IO(VFIO_TYPE, VFIO_BASE + 20)
+
 /* ***************************************************************** */
 
 #endif /* _UAPIVFIO_H */

commit 2157e7b82f3b81f57bd80cd67cef09ef26e5f74c
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:25 2015 +1000

    vfio: powerpc/spapr: Register memory and define IOMMU v2
    
    The existing implementation accounts the whole DMA window in
    the locked_vm counter. This is going to be worse with multiple
    containers and huge DMA windows. Also, real-time accounting would requite
    additional tracking of accounted pages due to the page size difference -
    IOMMU uses 4K pages and system uses 4K or 64K pages.
    
    Another issue is that actual pages pinning/unpinning happens on every
    DMA map/unmap request. This does not affect the performance much now as
    we spend way too much time now on switching context between
    guest/userspace/host but this will start to matter when we add in-kernel
    DMA map/unmap acceleration.
    
    This introduces a new IOMMU type for SPAPR - VFIO_SPAPR_TCE_v2_IOMMU.
    New IOMMU deprecates VFIO_IOMMU_ENABLE/VFIO_IOMMU_DISABLE and introduces
    2 new ioctls to register/unregister DMA memory -
    VFIO_IOMMU_SPAPR_REGISTER_MEMORY and VFIO_IOMMU_SPAPR_UNREGISTER_MEMORY -
    which receive user space address and size of a memory region which
    needs to be pinned/unpinned and counted in locked_vm.
    New IOMMU splits physical pages pinning and TCE table update
    into 2 different operations. It requires:
    1) guest pages to be registered first
    2) consequent map/unmap requests to work only with pre-registered memory.
    For the default single window case this means that the entire guest
    (instead of 2GB) needs to be pinned before using VFIO.
    When a huge DMA window is added, no additional pinning will be
    required, otherwise it would be guest RAM + 2GB.
    
    The new memory registration ioctls are not supported by
    VFIO_SPAPR_TCE_IOMMU. Dynamic DMA window and in-kernel acceleration
    will require memory to be preregistered in order to work.
    
    The accounting is done per the user process.
    
    This advertises v2 SPAPR TCE IOMMU and restricts what the userspace
    can do with v1 or v2 IOMMUs.
    
    In order to support memory pre-registration, we need a way to track
    the use of every registered memory region and only allow unregistration
    if a region is not in use anymore. So we need a way to tell from what
    region the just cleared TCE was from.
    
    This adds a userspace view of the TCE table into iommu_table struct.
    It contains userspace address, one per TCE entry. The table is only
    allocated when the ownership over an IOMMU group is taken which means
    it is only used from outside of the powernv code (such as VFIO).
    
    As v2 IOMMU supports IODA2 and pre-IODA2 IOMMUs (which do not support
    DDW API), this creates a default DMA window for IODA2 for consistency.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index e4fa1995f613..fa84391a0d00 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -36,6 +36,8 @@
 /* Two-stage IOMMU */
 #define VFIO_TYPE1_NESTING_IOMMU	6	/* Implies v2 */
 
+#define VFIO_SPAPR_TCE_v2_IOMMU		7
+
 /*
  * The IOCTL interface is designed for extensibility by embedding the
  * structure length (argsz) and flags into structures passed between
@@ -507,6 +509,31 @@ struct vfio_eeh_pe_op {
 
 #define VFIO_EEH_PE_OP			_IO(VFIO_TYPE, VFIO_BASE + 21)
 
+/**
+ * VFIO_IOMMU_SPAPR_REGISTER_MEMORY - _IOW(VFIO_TYPE, VFIO_BASE + 17, struct vfio_iommu_spapr_register_memory)
+ *
+ * Registers user space memory where DMA is allowed. It pins
+ * user pages and does the locked memory accounting so
+ * subsequent VFIO_IOMMU_MAP_DMA/VFIO_IOMMU_UNMAP_DMA calls
+ * get faster.
+ */
+struct vfio_iommu_spapr_register_memory {
+	__u32	argsz;
+	__u32	flags;
+	__u64	vaddr;				/* Process virtual address */
+	__u64	size;				/* Size of mapping (bytes) */
+};
+#define VFIO_IOMMU_SPAPR_REGISTER_MEMORY	_IO(VFIO_TYPE, VFIO_BASE + 17)
+
+/**
+ * VFIO_IOMMU_SPAPR_UNREGISTER_MEMORY - _IOW(VFIO_TYPE, VFIO_BASE + 18, struct vfio_iommu_spapr_register_memory)
+ *
+ * Unregisters user space memory registered with
+ * VFIO_IOMMU_SPAPR_REGISTER_MEMORY.
+ * Uses vfio_iommu_spapr_register_memory for parameters.
+ */
+#define VFIO_IOMMU_SPAPR_UNREGISTER_MEMORY	_IO(VFIO_TYPE, VFIO_BASE + 18)
+
 /* ***************************************************************** */
 
 #endif /* _UAPIVFIO_H */

commit 68cbbc3a9d1fc231810b2490bca73b3b444ef542
Author: Gavin Shan <gwshan@linux.vnet.ibm.com>
Date:   Thu Mar 26 16:42:09 2015 +1100

    drivers/vfio: Support EEH error injection
    
    The patch adds one more EEH sub-command (VFIO_EEH_PE_INJECT_ERR)
    to inject the specified EEH error, which is represented by
    (struct vfio_eeh_pe_err), to the indicated PE for testing purpose.
    
    Signed-off-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index b57b750c222f..e4fa1995f613 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -470,12 +470,23 @@ struct vfio_iommu_spapr_tce_info {
  * - unfreeze IO/DMA for frozen PE;
  * - read PE state;
  * - reset PE;
- * - configure PE.
+ * - configure PE;
+ * - inject EEH error.
  */
+struct vfio_eeh_pe_err {
+	__u32 type;
+	__u32 func;
+	__u64 addr;
+	__u64 mask;
+};
+
 struct vfio_eeh_pe_op {
 	__u32 argsz;
 	__u32 flags;
 	__u32 op;
+	union {
+		struct vfio_eeh_pe_err err;
+	};
 };
 
 #define VFIO_EEH_PE_DISABLE		0	/* Disable EEH functionality */
@@ -492,6 +503,7 @@ struct vfio_eeh_pe_op {
 #define VFIO_EEH_PE_RESET_HOT		6	/* Assert hot reset          */
 #define VFIO_EEH_PE_RESET_FUNDAMENTAL	7	/* Assert fundamental reset  */
 #define VFIO_EEH_PE_CONFIGURE		8	/* PE configuration          */
+#define VFIO_EEH_PE_INJECT_ERR		9	/* Inject EEH error          */
 
 #define VFIO_EEH_PE_OP			_IO(VFIO_TYPE, VFIO_BASE + 21)
 

commit 36fe431f2811fa3b5fed15d272c585d5a47977aa
Author: Antonios Motakis <a.motakis@virtualopensystems.com>
Date:   Mon Mar 16 14:08:44 2015 -0600

    vfio: amba: VFIO support for AMBA devices
    
    Add support for discovering AMBA devices with VFIO and handle them
    similarly to Linux platform devices.
    
    Signed-off-by: Antonios Motakis <a.motakis@virtualopensystems.com>
    Signed-off-by: Baptiste Reynal <b.reynal@virtualopensystems.com>
    Reviewed-by: Eric Auger <eric.auger@linaro.org>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index ea9514b6bb5c..b57b750c222f 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -161,6 +161,7 @@ struct vfio_device_info {
 #define VFIO_DEVICE_FLAGS_RESET	(1 << 0)	/* Device supports reset */
 #define VFIO_DEVICE_FLAGS_PCI	(1 << 1)	/* vfio-pci device */
 #define VFIO_DEVICE_FLAGS_PLATFORM (1 << 2)	/* vfio-platform device */
+#define VFIO_DEVICE_FLAGS_AMBA  (1 << 3)	/* vfio-amba device */
 	__u32	num_regions;	/* Max region index + 1 */
 	__u32	num_irqs;	/* Max IRQ index + 1 */
 };

commit 9df85aaa43297cb12dc85155695dd1bfdf94f91d
Author: Antonios Motakis <a.motakis@virtualopensystems.com>
Date:   Mon Mar 16 14:08:43 2015 -0600

    vfio: platform: probe to devices on the platform bus
    
    Driver to bind to Linux platform devices, and callbacks to discover their
    resources to be used by the main VFIO PLATFORM code.
    
    Signed-off-by: Antonios Motakis <a.motakis@virtualopensystems.com>
    Signed-off-by: Baptiste Reynal <b.reynal@virtualopensystems.com>
    Reviewed-by: Eric Auger <eric.auger@linaro.org>
    Tested-by: Eric Auger <eric.auger@linaro.org>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 82889c30f4f5..ea9514b6bb5c 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -160,6 +160,7 @@ struct vfio_device_info {
 	__u32	flags;
 #define VFIO_DEVICE_FLAGS_RESET	(1 << 0)	/* Device supports reset */
 #define VFIO_DEVICE_FLAGS_PCI	(1 << 1)	/* vfio-pci device */
+#define VFIO_DEVICE_FLAGS_PLATFORM (1 << 2)	/* vfio-platform device */
 	__u32	num_regions;	/* Max region index + 1 */
 	__u32	num_irqs;	/* Max IRQ index + 1 */
 };

commit 6140a8f5623820cec7f56c63444b9551d8d35775
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Feb 6 15:05:08 2015 -0700

    vfio-pci: Add device request interface
    
    Userspace can opt to receive a device request notification,
    indicating that the device should be released.  This is setup
    the same way as the error IRQ and also supports eventfd signaling.
    Future support may forcefully remove the device from the user if
    the request is ignored.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 29715d27548f..82889c30f4f5 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -333,6 +333,7 @@ enum {
 	VFIO_PCI_MSI_IRQ_INDEX,
 	VFIO_PCI_MSIX_IRQ_INDEX,
 	VFIO_PCI_ERR_IRQ_INDEX,
+	VFIO_PCI_REQ_IRQ_INDEX,
 	VFIO_PCI_NUM_IRQS
 };
 

commit f5c9ecebaf2a2c9381973798e389cc019dd983e0
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Sep 29 10:06:19 2014 -0600

    vfio/iommu_type1: add new VFIO_TYPE1_NESTING_IOMMU IOMMU type
    
    VFIO allows devices to be safely handed off to userspace by putting
    them behind an IOMMU configured to ensure DMA and interrupt isolation.
    This enables userspace KVM clients, such as kvmtool and qemu, to further
    map the device into a virtual machine.
    
    With IOMMUs such as the ARM SMMU, it is then possible to provide SMMU
    translation services to the guest operating system, which are nested
    with the existing translation installed by VFIO. However, enabling this
    feature means that the IOMMU driver must be informed that the VFIO domain
    is being created for the purposes of nested translation.
    
    This patch adds a new IOMMU type (VFIO_TYPE1_NESTING_IOMMU) to the VFIO
    type-1 driver. The new IOMMU type acts identically to the
    VFIO_TYPE1v2_IOMMU type, but additionally sets the DOMAIN_ATTR_NESTING
    attribute on its IOMMU domains.
    
    Cc: Joerg Roedel <joro@8bytes.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 6612974c64bf..29715d27548f 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -33,6 +33,9 @@
 /* Check if EEH is supported */
 #define VFIO_EEH			5
 
+/* Two-stage IOMMU */
+#define VFIO_TYPE1_NESTING_IOMMU	6	/* Implies v2 */
+
 /*
  * The IOCTL interface is designed for extensibility by embedding the
  * structure length (argsz) and flags into structures passed between

commit 1b69be5e8afc634f39ad695a6ab6aad0cf0975c7
Author: Gavin Shan <gwshan@linux.vnet.ibm.com>
Date:   Tue Jun 10 11:41:57 2014 +1000

    drivers/vfio: EEH support for VFIO PCI device
    
    The patch adds new IOCTL commands for sPAPR VFIO container device
    to support EEH functionality for PCI devices, which have been passed
    through from host to somebody else via VFIO.
    
    Signed-off-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Acked-by: Alexander Graf <agraf@suse.de>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index cb9023d4f063..6612974c64bf 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -30,6 +30,9 @@
  */
 #define VFIO_DMA_CC_IOMMU		4
 
+/* Check if EEH is supported */
+#define VFIO_EEH			5
+
 /*
  * The IOCTL interface is designed for extensibility by embedding the
  * structure length (argsz) and flags into structures passed between
@@ -455,6 +458,37 @@ struct vfio_iommu_spapr_tce_info {
 
 #define VFIO_IOMMU_SPAPR_TCE_GET_INFO	_IO(VFIO_TYPE, VFIO_BASE + 12)
 
+/*
+ * EEH PE operation struct provides ways to:
+ * - enable/disable EEH functionality;
+ * - unfreeze IO/DMA for frozen PE;
+ * - read PE state;
+ * - reset PE;
+ * - configure PE.
+ */
+struct vfio_eeh_pe_op {
+	__u32 argsz;
+	__u32 flags;
+	__u32 op;
+};
+
+#define VFIO_EEH_PE_DISABLE		0	/* Disable EEH functionality */
+#define VFIO_EEH_PE_ENABLE		1	/* Enable EEH functionality  */
+#define VFIO_EEH_PE_UNFREEZE_IO		2	/* Enable IO for frozen PE   */
+#define VFIO_EEH_PE_UNFREEZE_DMA	3	/* Enable DMA for frozen PE  */
+#define VFIO_EEH_PE_GET_STATE		4	/* PE state retrieval        */
+#define  VFIO_EEH_PE_STATE_NORMAL	0	/* PE in functional state    */
+#define  VFIO_EEH_PE_STATE_RESET	1	/* PE reset in progress      */
+#define  VFIO_EEH_PE_STATE_STOPPED	2	/* Stopped DMA and IO        */
+#define  VFIO_EEH_PE_STATE_STOPPED_DMA	4	/* Stopped DMA only          */
+#define  VFIO_EEH_PE_STATE_UNAVAIL	5	/* State unavailable         */
+#define VFIO_EEH_PE_RESET_DEACTIVATE	5	/* Deassert PE reset         */
+#define VFIO_EEH_PE_RESET_HOT		6	/* Assert hot reset          */
+#define VFIO_EEH_PE_RESET_FUNDAMENTAL	7	/* Assert fundamental reset  */
+#define VFIO_EEH_PE_CONFIGURE		8	/* PE configuration          */
+
+#define VFIO_EEH_PE_OP			_IO(VFIO_TYPE, VFIO_BASE + 21)
+
 /* ***************************************************************** */
 
 #endif /* _UAPIVFIO_H */

commit aa429318279b90192f35a97e9ccdc1e83b3a9624
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Feb 26 11:38:37 2014 -0700

    vfio/type1: Add extension to test DMA cache coherence of IOMMU
    
    Now that the type1 IOMMU backend can support IOMMU_CACHE, we need to
    be able to test whether coherency is currently enforced.  Add an
    extension for this.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 460fdf2e26f1..cb9023d4f063 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -24,6 +24,11 @@
 #define VFIO_TYPE1_IOMMU		1
 #define VFIO_SPAPR_TCE_IOMMU		2
 #define VFIO_TYPE1v2_IOMMU		3
+/*
+ * IOMMU enforces DMA cache coherence (ex. PCIe NoSnoop stripping).  This
+ * capability is subject to change as groups are added or removed.
+ */
+#define VFIO_DMA_CC_IOMMU		4
 
 /*
  * The IOCTL interface is designed for extensibility by embedding the

commit 1ef3e2bc04223ff956dc62abaf2dff1f3322a431
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Feb 26 11:38:36 2014 -0700

    vfio/iommu_type1: Multi-IOMMU domain support
    
    We currently have a problem that we cannot support advanced features
    of an IOMMU domain (ex. IOMMU_CACHE), because we have no guarantee
    that those features will be supported by all of the hardware units
    involved with the domain over its lifetime.  For instance, the Intel
    VT-d architecture does not require that all DRHDs support snoop
    control.  If we create a domain based on a device behind a DRHD that
    does support snoop control and enable SNP support via the IOMMU_CACHE
    mapping option, we cannot then add a device behind a DRHD which does
    not support snoop control or we'll get reserved bit faults from the
    SNP bit in the pagetables.  To add to the complexity, we can't know
    the properties of a domain until a device is attached.
    
    We could pass this problem off to userspace and require that a
    separate vfio container be used, but we don't know how to handle page
    accounting in that case.  How do we know that a page pinned in one
    container is the same page as a different container and avoid double
    billing the user for the page.
    
    The solution is therefore to support multiple IOMMU domains per
    container.  In the majority of cases, only one domain will be required
    since hardware is typically consistent within a system.  However, this
    provides us the ability to validate compatibility of domains and
    support mixed environments where page table flags can be different
    between domains.
    
    To do this, our DMA tracking needs to change.  We currently try to
    coalesce user mappings into as few tracking entries as possible.  The
    problem then becomes that we lose granularity of user mappings.  We've
    never guaranteed that a user is able to unmap at a finer granularity
    than the original mapping, but we must honor the granularity of the
    original mapping.  This coalescing code is therefore removed, allowing
    only unmaps covering complete maps.  The change in accounting is
    fairly small here, a typical QEMU VM will start out with roughly a
    dozen entries, so it's arguable if this coalescing was ever needed.
    
    We also move IOMMU domain creation to the point where a group is
    attached to the container.  An interesting side-effect of this is that
    we now have access to the device at the time of domain creation and
    can probe the devices within the group to determine the bus_type.
    This finally makes vfio_iommu_type1 completely device/bus agnostic.
    In fact, each IOMMU domain can host devices on different buses managed
    by different physical IOMMUs, and present a single DMA mapping
    interface to the user.  When a new domain is created, mappings are
    replayed to bring the IOMMU pagetables up to the state of the current
    container.  And of course, DMA mapping and unmapping automatically
    traverse all of the configured IOMMU domains.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Cc: Varun Sethi <Varun.Sethi@freescale.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 0fd47f5bc146..460fdf2e26f1 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -23,6 +23,7 @@
 
 #define VFIO_TYPE1_IOMMU		1
 #define VFIO_SPAPR_TCE_IOMMU		2
+#define VFIO_TYPE1v2_IOMMU		3
 
 /*
  * The IOCTL interface is designed for extensibility by embedding the

commit 8b27ee60bfd6bbb84d2df28fa706c5c5081066ca
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Sep 4 11:28:04 2013 -0600

    vfio-pci: PCI hot reset interface
    
    The current VFIO_DEVICE_RESET interface only maps to PCI use cases
    where we can isolate the reset to the individual PCI function.  This
    means the device must support FLR (PCIe or AF), PM reset on D3hot->D0
    transition, device specific reset, or be a singleton device on a bus
    for a secondary bus reset.  FLR does not have widespread support,
    PM reset is not very reliable, and bus topology is dictated by the
    system and device design.  We need to provide a means for a user to
    induce a bus reset in cases where the existing mechanisms are not
    available or not reliable.
    
    This device specific extension to VFIO provides the user with this
    ability.  Two new ioctls are introduced:
     - VFIO_DEVICE_PCI_GET_HOT_RESET_INFO
     - VFIO_DEVICE_PCI_HOT_RESET
    
    The first provides the user with information about the extent of
    devices affected by a hot reset.  This is essentially a list of
    devices and the IOMMU groups they belong to.  The user may then
    initiate a hot reset by calling the second ioctl.  We must be
    careful that the user has ownership of all the affected devices
    found via the first ioctl, so the second ioctl takes a list of file
    descriptors for the VFIO groups affected by the reset.  Each group
    must have IOMMU protection established for the ioctl to succeed.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 916e444e6f74..0fd47f5bc146 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -324,6 +324,44 @@ enum {
 	VFIO_PCI_NUM_IRQS
 };
 
+/**
+ * VFIO_DEVICE_GET_PCI_HOT_RESET_INFO - _IORW(VFIO_TYPE, VFIO_BASE + 12,
+ *					      struct vfio_pci_hot_reset_info)
+ *
+ * Return: 0 on success, -errno on failure:
+ *	-enospc = insufficient buffer, -enodev = unsupported for device.
+ */
+struct vfio_pci_dependent_device {
+	__u32	group_id;
+	__u16	segment;
+	__u8	bus;
+	__u8	devfn; /* Use PCI_SLOT/PCI_FUNC */
+};
+
+struct vfio_pci_hot_reset_info {
+	__u32	argsz;
+	__u32	flags;
+	__u32	count;
+	struct vfio_pci_dependent_device	devices[];
+};
+
+#define VFIO_DEVICE_GET_PCI_HOT_RESET_INFO	_IO(VFIO_TYPE, VFIO_BASE + 12)
+
+/**
+ * VFIO_DEVICE_PCI_HOT_RESET - _IOW(VFIO_TYPE, VFIO_BASE + 13,
+ *				    struct vfio_pci_hot_reset)
+ *
+ * Return: 0 on success, -errno on failure.
+ */
+struct vfio_pci_hot_reset {
+	__u32	argsz;
+	__u32	flags;
+	__u32	count;
+	__s32	group_fds[];
+};
+
+#define VFIO_DEVICE_PCI_HOT_RESET	_IO(VFIO_TYPE, VFIO_BASE + 13)
+
 /* -------- API for Type1 VFIO IOMMU -------- */
 
 /**

commit 15a49b9a90c86c6cb7f270a699d2ae7468862c28
Merge: 8d10aae2741e 8d38ef1948bd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 10 14:50:08 2013 -0700

    Merge tag 'vfio-v3.11' of git://github.com/awilliam/linux-vfio
    
    Pull vfio updates from Alex Williamson:
     "Largely hugepage support for vfio/type1 iommu and surrounding cleanups
      and fixes"
    
    * tag 'vfio-v3.11' of git://github.com/awilliam/linux-vfio:
      vfio/type1: Fix leak on error path
      vfio: Limit group opens
      vfio/type1: Fix missed frees and zero sized removes
      vfio: fix documentation
      vfio: Provide module option to disable vfio_iommu_type1 hugepage support
      vfio: hugepage support for vfio_iommu_type1
      vfio: Convert type1 iommu to use rbtree

commit 166fd7d94afdac040b28c473e45241820ca522a2
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Jun 21 09:38:02 2013 -0600

    vfio: hugepage support for vfio_iommu_type1
    
    We currently send all mappings to the iommu in PAGE_SIZE chunks,
    which prevents the iommu from enabling support for larger page sizes.
    We still need to pin pages, which means we step through them in
    PAGE_SIZE chunks, but we can batch up contiguous physical memory
    chunks to allow the iommu the opportunity to use larger pages.  The
    approach here is a bit different that the one currently used for
    legacy KVM device assignment.  Rather than looking at the vma page
    size and using that as the maximum size to pass to the iommu, we
    instead simply look at whether the next page is physically
    contiguous.  This means we might ask the iommu to map a 4MB region,
    while legacy KVM might limit itself to a maximum of 2MB.
    
    Splitting our mapping path also allows us to be smarter about locked
    memory because we can more easily unwind if the user attempts to
    exceed the limit.  Therefore, rather than assuming that a mapping
    will result in locked memory, we test each page as it is pinned to
    determine whether it locks RAM vs an mmap'd MMIO region.  This should
    result in better locking granularity and less locked page fudge
    factors in userspace.
    
    The unmap path uses the same algorithm as legacy KVM.  We don't want
    to track the pfn for each mapping ourselves, but we need the pfn in
    order to unpin pages.  We therefore ask the iommu for the iova to
    physical address translation, ask it to unpin a page, and see how many
    pages were actually unpinned.  iommus supporting large pages will
    often return something bigger than a page here, which we know will be
    physically contiguous and we can unpin a batch of pfns.  iommus not
    supporting large mappings won't see an improvement in batching here as
    they only unmap a page at a time.
    
    With this change, we also make a clarification to the API for mapping
    and unmapping DMA.  We can only guarantee unmaps at the same
    granularity as used for the original mapping.  In other words,
    unmapping a subregion of a previous mapping is not guaranteed and may
    result in a larger or smaller unmapping than requested.  The size
    field in the unmapping structure is updated to reflect this.
    Previously this was unmodified on mapping, always returning the the
    requested unmap size.  This is now updated to return the actual unmap
    size on success, allowing userspace to appropriately track mappings.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 284ff2436829..513600612995 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -361,10 +361,14 @@ struct vfio_iommu_type1_dma_map {
 #define VFIO_IOMMU_MAP_DMA _IO(VFIO_TYPE, VFIO_BASE + 13)
 
 /**
- * VFIO_IOMMU_UNMAP_DMA - _IOW(VFIO_TYPE, VFIO_BASE + 14, struct vfio_dma_unmap)
+ * VFIO_IOMMU_UNMAP_DMA - _IOWR(VFIO_TYPE, VFIO_BASE + 14,
+ *							struct vfio_dma_unmap)
  *
  * Unmap IO virtual addresses using the provided struct vfio_dma_unmap.
- * Caller sets argsz.
+ * Caller sets argsz.  The actual unmapped size is returned in the size
+ * field.  No guarantee is made to the user that arbitrary unmaps of iova
+ * or size different from those used in the original mapping call will
+ * succeed.
  */
 struct vfio_iommu_type1_dma_unmap {
 	__u32	argsz;

commit 5ffd229c02731a91d08ca21e76b503c5bbb5c095
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Tue May 21 13:33:10 2013 +1000

    powerpc/vfio: Implement IOMMU driver for VFIO
    
    VFIO implements platform independent stuff such as
    a PCI driver, BAR access (via read/write on a file descriptor
    or direct mapping when possible) and IRQ signaling.
    
    The platform dependent part includes IOMMU initialization
    and handling.  This implements an IOMMU driver for VFIO
    which does mapping/unmapping pages for the guest IO and
    provides information about DMA window (required by a POWER
    guest).
    
    Cc: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 284ff2436829..87ee4f4cff25 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -22,6 +22,7 @@
 /* Extensions */
 
 #define VFIO_TYPE1_IOMMU		1
+#define VFIO_SPAPR_TCE_IOMMU		2
 
 /*
  * The IOCTL interface is designed for extensibility by embedding the
@@ -375,4 +376,37 @@ struct vfio_iommu_type1_dma_unmap {
 
 #define VFIO_IOMMU_UNMAP_DMA _IO(VFIO_TYPE, VFIO_BASE + 14)
 
+/*
+ * IOCTLs to enable/disable IOMMU container usage.
+ * No parameters are supported.
+ */
+#define VFIO_IOMMU_ENABLE	_IO(VFIO_TYPE, VFIO_BASE + 15)
+#define VFIO_IOMMU_DISABLE	_IO(VFIO_TYPE, VFIO_BASE + 16)
+
+/* -------- Additional API for SPAPR TCE (Server POWERPC) IOMMU -------- */
+
+/*
+ * The SPAPR TCE info struct provides the information about the PCI bus
+ * address ranges available for DMA, these values are programmed into
+ * the hardware so the guest has to know that information.
+ *
+ * The DMA 32 bit window start is an absolute PCI bus address.
+ * The IOVA address passed via map/unmap ioctls are absolute PCI bus
+ * addresses too so the window works as a filter rather than an offset
+ * for IOVA addresses.
+ *
+ * A flag will need to be added if other page sizes are supported,
+ * so as defined here, it is always 4k.
+ */
+struct vfio_iommu_spapr_tce_info {
+	__u32 argsz;
+	__u32 flags;			/* reserved for future use */
+	__u32 dma32_window_start;	/* 32 bit window start (bytes) */
+	__u32 dma32_window_size;	/* 32 bit window size (bytes) */
+};
+
+#define VFIO_IOMMU_SPAPR_TCE_GET_INFO	_IO(VFIO_TYPE, VFIO_BASE + 12)
+
+/* ***************************************************************** */
+
 #endif /* _UAPIVFIO_H */

commit dad9f8972e04cd081a028d8fb1249d746d97fc03
Author: Vijay Mohan Pandarathil <vijaymohan.pandarathil@hp.com>
Date:   Mon Mar 11 09:31:22 2013 -0600

    VFIO-AER: Vfio-pci driver changes for supporting AER
    
    - New VFIO_SET_IRQ ioctl option to pass the eventfd that is signaled when
      an error occurs in the vfio_pci_device
    
    - Register pci_error_handler for the vfio_pci driver
    
    - When the device encounters an error, the error handler registered by
      the vfio_pci driver gets invoked by the AER infrastructure
    
    - In the error handler, signal the eventfd registered for the device.
    
    - This results in the qemu eventfd handler getting invoked and
      appropriate action taken for the guest.
    
    Signed-off-by: Vijay Mohan Pandarathil <vijaymohan.pandarathil@hp.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 4f41f309911e..284ff2436829 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -319,6 +319,7 @@ enum {
 	VFIO_PCI_INTX_IRQ_INDEX,
 	VFIO_PCI_MSI_IRQ_INDEX,
 	VFIO_PCI_MSIX_IRQ_INDEX,
+	VFIO_PCI_ERR_IRQ_INDEX,
 	VFIO_PCI_NUM_IRQS
 };
 

commit 84237a826b261de7ddd3d09ee53ee68cb4138937
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Feb 18 10:11:13 2013 -0700

    vfio-pci: Add support for VGA region access
    
    PCI defines display class VGA regions at I/O port address 0x3b0, 0x3c0
    and MMIO address 0xa0000.  As these are non-overlapping, we can ignore
    the I/O port vs MMIO difference and expose them both in a single
    region.  We make use of the VGA arbiter around each access to
    configure chipset access as necessary.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
index 4758d1bfcf41..4f41f309911e 100644
--- a/include/uapi/linux/vfio.h
+++ b/include/uapi/linux/vfio.h
@@ -303,6 +303,15 @@ enum {
 	VFIO_PCI_BAR5_REGION_INDEX,
 	VFIO_PCI_ROM_REGION_INDEX,
 	VFIO_PCI_CONFIG_REGION_INDEX,
+	/*
+	 * Expose VGA regions defined for PCI base class 03, subclass 00.
+	 * This includes I/O port ranges 0x3b0 to 0x3bb and 0x3c0 to 0x3df
+	 * as well as the MMIO range 0xa0000 to 0xbffff.  Each implemented
+	 * range is found at it's identity mapped offset from the region
+	 * offset, for example 0x3b0 is region_info.offset + 0x3b0.  Areas
+	 * between described ranges are unimplemented.
+	 */
+	VFIO_PCI_VGA_REGION_INDEX,
 	VFIO_PCI_NUM_REGIONS
 };
 

commit 607ca46e97a1b6594b29647d98a32d545c24bdff
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 13 10:46:48 2012 +0100

    UAPI: (Scripted) Disintegrate include/linux
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/include/uapi/linux/vfio.h b/include/uapi/linux/vfio.h
new file mode 100644
index 000000000000..4758d1bfcf41
--- /dev/null
+++ b/include/uapi/linux/vfio.h
@@ -0,0 +1,368 @@
+/*
+ * VFIO API definition
+ *
+ * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.
+ *     Author: Alex Williamson <alex.williamson@redhat.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#ifndef _UAPIVFIO_H
+#define _UAPIVFIO_H
+
+#include <linux/types.h>
+#include <linux/ioctl.h>
+
+#define VFIO_API_VERSION	0
+
+
+/* Kernel & User level defines for VFIO IOCTLs. */
+
+/* Extensions */
+
+#define VFIO_TYPE1_IOMMU		1
+
+/*
+ * The IOCTL interface is designed for extensibility by embedding the
+ * structure length (argsz) and flags into structures passed between
+ * kernel and userspace.  We therefore use the _IO() macro for these
+ * defines to avoid implicitly embedding a size into the ioctl request.
+ * As structure fields are added, argsz will increase to match and flag
+ * bits will be defined to indicate additional fields with valid data.
+ * It's *always* the caller's responsibility to indicate the size of
+ * the structure passed by setting argsz appropriately.
+ */
+
+#define VFIO_TYPE	(';')
+#define VFIO_BASE	100
+
+/* -------- IOCTLs for VFIO file descriptor (/dev/vfio/vfio) -------- */
+
+/**
+ * VFIO_GET_API_VERSION - _IO(VFIO_TYPE, VFIO_BASE + 0)
+ *
+ * Report the version of the VFIO API.  This allows us to bump the entire
+ * API version should we later need to add or change features in incompatible
+ * ways.
+ * Return: VFIO_API_VERSION
+ * Availability: Always
+ */
+#define VFIO_GET_API_VERSION		_IO(VFIO_TYPE, VFIO_BASE + 0)
+
+/**
+ * VFIO_CHECK_EXTENSION - _IOW(VFIO_TYPE, VFIO_BASE + 1, __u32)
+ *
+ * Check whether an extension is supported.
+ * Return: 0 if not supported, 1 (or some other positive integer) if supported.
+ * Availability: Always
+ */
+#define VFIO_CHECK_EXTENSION		_IO(VFIO_TYPE, VFIO_BASE + 1)
+
+/**
+ * VFIO_SET_IOMMU - _IOW(VFIO_TYPE, VFIO_BASE + 2, __s32)
+ *
+ * Set the iommu to the given type.  The type must be supported by an
+ * iommu driver as verified by calling CHECK_EXTENSION using the same
+ * type.  A group must be set to this file descriptor before this
+ * ioctl is available.  The IOMMU interfaces enabled by this call are
+ * specific to the value set.
+ * Return: 0 on success, -errno on failure
+ * Availability: When VFIO group attached
+ */
+#define VFIO_SET_IOMMU			_IO(VFIO_TYPE, VFIO_BASE + 2)
+
+/* -------- IOCTLs for GROUP file descriptors (/dev/vfio/$GROUP) -------- */
+
+/**
+ * VFIO_GROUP_GET_STATUS - _IOR(VFIO_TYPE, VFIO_BASE + 3,
+ *						struct vfio_group_status)
+ *
+ * Retrieve information about the group.  Fills in provided
+ * struct vfio_group_info.  Caller sets argsz.
+ * Return: 0 on succes, -errno on failure.
+ * Availability: Always
+ */
+struct vfio_group_status {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_GROUP_FLAGS_VIABLE		(1 << 0)
+#define VFIO_GROUP_FLAGS_CONTAINER_SET	(1 << 1)
+};
+#define VFIO_GROUP_GET_STATUS		_IO(VFIO_TYPE, VFIO_BASE + 3)
+
+/**
+ * VFIO_GROUP_SET_CONTAINER - _IOW(VFIO_TYPE, VFIO_BASE + 4, __s32)
+ *
+ * Set the container for the VFIO group to the open VFIO file
+ * descriptor provided.  Groups may only belong to a single
+ * container.  Containers may, at their discretion, support multiple
+ * groups.  Only when a container is set are all of the interfaces
+ * of the VFIO file descriptor and the VFIO group file descriptor
+ * available to the user.
+ * Return: 0 on success, -errno on failure.
+ * Availability: Always
+ */
+#define VFIO_GROUP_SET_CONTAINER	_IO(VFIO_TYPE, VFIO_BASE + 4)
+
+/**
+ * VFIO_GROUP_UNSET_CONTAINER - _IO(VFIO_TYPE, VFIO_BASE + 5)
+ *
+ * Remove the group from the attached container.  This is the
+ * opposite of the SET_CONTAINER call and returns the group to
+ * an initial state.  All device file descriptors must be released
+ * prior to calling this interface.  When removing the last group
+ * from a container, the IOMMU will be disabled and all state lost,
+ * effectively also returning the VFIO file descriptor to an initial
+ * state.
+ * Return: 0 on success, -errno on failure.
+ * Availability: When attached to container
+ */
+#define VFIO_GROUP_UNSET_CONTAINER	_IO(VFIO_TYPE, VFIO_BASE + 5)
+
+/**
+ * VFIO_GROUP_GET_DEVICE_FD - _IOW(VFIO_TYPE, VFIO_BASE + 6, char)
+ *
+ * Return a new file descriptor for the device object described by
+ * the provided string.  The string should match a device listed in
+ * the devices subdirectory of the IOMMU group sysfs entry.  The
+ * group containing the device must already be added to this context.
+ * Return: new file descriptor on success, -errno on failure.
+ * Availability: When attached to container
+ */
+#define VFIO_GROUP_GET_DEVICE_FD	_IO(VFIO_TYPE, VFIO_BASE + 6)
+
+/* --------------- IOCTLs for DEVICE file descriptors --------------- */
+
+/**
+ * VFIO_DEVICE_GET_INFO - _IOR(VFIO_TYPE, VFIO_BASE + 7,
+ *						struct vfio_device_info)
+ *
+ * Retrieve information about the device.  Fills in provided
+ * struct vfio_device_info.  Caller sets argsz.
+ * Return: 0 on success, -errno on failure.
+ */
+struct vfio_device_info {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_DEVICE_FLAGS_RESET	(1 << 0)	/* Device supports reset */
+#define VFIO_DEVICE_FLAGS_PCI	(1 << 1)	/* vfio-pci device */
+	__u32	num_regions;	/* Max region index + 1 */
+	__u32	num_irqs;	/* Max IRQ index + 1 */
+};
+#define VFIO_DEVICE_GET_INFO		_IO(VFIO_TYPE, VFIO_BASE + 7)
+
+/**
+ * VFIO_DEVICE_GET_REGION_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 8,
+ *				       struct vfio_region_info)
+ *
+ * Retrieve information about a device region.  Caller provides
+ * struct vfio_region_info with index value set.  Caller sets argsz.
+ * Implementation of region mapping is bus driver specific.  This is
+ * intended to describe MMIO, I/O port, as well as bus specific
+ * regions (ex. PCI config space).  Zero sized regions may be used
+ * to describe unimplemented regions (ex. unimplemented PCI BARs).
+ * Return: 0 on success, -errno on failure.
+ */
+struct vfio_region_info {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_REGION_INFO_FLAG_READ	(1 << 0) /* Region supports read */
+#define VFIO_REGION_INFO_FLAG_WRITE	(1 << 1) /* Region supports write */
+#define VFIO_REGION_INFO_FLAG_MMAP	(1 << 2) /* Region supports mmap */
+	__u32	index;		/* Region index */
+	__u32	resv;		/* Reserved for alignment */
+	__u64	size;		/* Region size (bytes) */
+	__u64	offset;		/* Region offset from start of device fd */
+};
+#define VFIO_DEVICE_GET_REGION_INFO	_IO(VFIO_TYPE, VFIO_BASE + 8)
+
+/**
+ * VFIO_DEVICE_GET_IRQ_INFO - _IOWR(VFIO_TYPE, VFIO_BASE + 9,
+ *				    struct vfio_irq_info)
+ *
+ * Retrieve information about a device IRQ.  Caller provides
+ * struct vfio_irq_info with index value set.  Caller sets argsz.
+ * Implementation of IRQ mapping is bus driver specific.  Indexes
+ * using multiple IRQs are primarily intended to support MSI-like
+ * interrupt blocks.  Zero count irq blocks may be used to describe
+ * unimplemented interrupt types.
+ *
+ * The EVENTFD flag indicates the interrupt index supports eventfd based
+ * signaling.
+ *
+ * The MASKABLE flags indicates the index supports MASK and UNMASK
+ * actions described below.
+ *
+ * AUTOMASKED indicates that after signaling, the interrupt line is
+ * automatically masked by VFIO and the user needs to unmask the line
+ * to receive new interrupts.  This is primarily intended to distinguish
+ * level triggered interrupts.
+ *
+ * The NORESIZE flag indicates that the interrupt lines within the index
+ * are setup as a set and new subindexes cannot be enabled without first
+ * disabling the entire index.  This is used for interrupts like PCI MSI
+ * and MSI-X where the driver may only use a subset of the available
+ * indexes, but VFIO needs to enable a specific number of vectors
+ * upfront.  In the case of MSI-X, where the user can enable MSI-X and
+ * then add and unmask vectors, it's up to userspace to make the decision
+ * whether to allocate the maximum supported number of vectors or tear
+ * down setup and incrementally increase the vectors as each is enabled.
+ */
+struct vfio_irq_info {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_IRQ_INFO_EVENTFD		(1 << 0)
+#define VFIO_IRQ_INFO_MASKABLE		(1 << 1)
+#define VFIO_IRQ_INFO_AUTOMASKED	(1 << 2)
+#define VFIO_IRQ_INFO_NORESIZE		(1 << 3)
+	__u32	index;		/* IRQ index */
+	__u32	count;		/* Number of IRQs within this index */
+};
+#define VFIO_DEVICE_GET_IRQ_INFO	_IO(VFIO_TYPE, VFIO_BASE + 9)
+
+/**
+ * VFIO_DEVICE_SET_IRQS - _IOW(VFIO_TYPE, VFIO_BASE + 10, struct vfio_irq_set)
+ *
+ * Set signaling, masking, and unmasking of interrupts.  Caller provides
+ * struct vfio_irq_set with all fields set.  'start' and 'count' indicate
+ * the range of subindexes being specified.
+ *
+ * The DATA flags specify the type of data provided.  If DATA_NONE, the
+ * operation performs the specified action immediately on the specified
+ * interrupt(s).  For example, to unmask AUTOMASKED interrupt [0,0]:
+ * flags = (DATA_NONE|ACTION_UNMASK), index = 0, start = 0, count = 1.
+ *
+ * DATA_BOOL allows sparse support for the same on arrays of interrupts.
+ * For example, to mask interrupts [0,1] and [0,3] (but not [0,2]):
+ * flags = (DATA_BOOL|ACTION_MASK), index = 0, start = 1, count = 3,
+ * data = {1,0,1}
+ *
+ * DATA_EVENTFD binds the specified ACTION to the provided __s32 eventfd.
+ * A value of -1 can be used to either de-assign interrupts if already
+ * assigned or skip un-assigned interrupts.  For example, to set an eventfd
+ * to be trigger for interrupts [0,0] and [0,2]:
+ * flags = (DATA_EVENTFD|ACTION_TRIGGER), index = 0, start = 0, count = 3,
+ * data = {fd1, -1, fd2}
+ * If index [0,1] is previously set, two count = 1 ioctls calls would be
+ * required to set [0,0] and [0,2] without changing [0,1].
+ *
+ * Once a signaling mechanism is set, DATA_BOOL or DATA_NONE can be used
+ * with ACTION_TRIGGER to perform kernel level interrupt loopback testing
+ * from userspace (ie. simulate hardware triggering).
+ *
+ * Setting of an event triggering mechanism to userspace for ACTION_TRIGGER
+ * enables the interrupt index for the device.  Individual subindex interrupts
+ * can be disabled using the -1 value for DATA_EVENTFD or the index can be
+ * disabled as a whole with: flags = (DATA_NONE|ACTION_TRIGGER), count = 0.
+ *
+ * Note that ACTION_[UN]MASK specify user->kernel signaling (irqfds) while
+ * ACTION_TRIGGER specifies kernel->user signaling.
+ */
+struct vfio_irq_set {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_IRQ_SET_DATA_NONE		(1 << 0) /* Data not present */
+#define VFIO_IRQ_SET_DATA_BOOL		(1 << 1) /* Data is bool (u8) */
+#define VFIO_IRQ_SET_DATA_EVENTFD	(1 << 2) /* Data is eventfd (s32) */
+#define VFIO_IRQ_SET_ACTION_MASK	(1 << 3) /* Mask interrupt */
+#define VFIO_IRQ_SET_ACTION_UNMASK	(1 << 4) /* Unmask interrupt */
+#define VFIO_IRQ_SET_ACTION_TRIGGER	(1 << 5) /* Trigger interrupt */
+	__u32	index;
+	__u32	start;
+	__u32	count;
+	__u8	data[];
+};
+#define VFIO_DEVICE_SET_IRQS		_IO(VFIO_TYPE, VFIO_BASE + 10)
+
+#define VFIO_IRQ_SET_DATA_TYPE_MASK	(VFIO_IRQ_SET_DATA_NONE | \
+					 VFIO_IRQ_SET_DATA_BOOL | \
+					 VFIO_IRQ_SET_DATA_EVENTFD)
+#define VFIO_IRQ_SET_ACTION_TYPE_MASK	(VFIO_IRQ_SET_ACTION_MASK | \
+					 VFIO_IRQ_SET_ACTION_UNMASK | \
+					 VFIO_IRQ_SET_ACTION_TRIGGER)
+/**
+ * VFIO_DEVICE_RESET - _IO(VFIO_TYPE, VFIO_BASE + 11)
+ *
+ * Reset a device.
+ */
+#define VFIO_DEVICE_RESET		_IO(VFIO_TYPE, VFIO_BASE + 11)
+
+/*
+ * The VFIO-PCI bus driver makes use of the following fixed region and
+ * IRQ index mapping.  Unimplemented regions return a size of zero.
+ * Unimplemented IRQ types return a count of zero.
+ */
+
+enum {
+	VFIO_PCI_BAR0_REGION_INDEX,
+	VFIO_PCI_BAR1_REGION_INDEX,
+	VFIO_PCI_BAR2_REGION_INDEX,
+	VFIO_PCI_BAR3_REGION_INDEX,
+	VFIO_PCI_BAR4_REGION_INDEX,
+	VFIO_PCI_BAR5_REGION_INDEX,
+	VFIO_PCI_ROM_REGION_INDEX,
+	VFIO_PCI_CONFIG_REGION_INDEX,
+	VFIO_PCI_NUM_REGIONS
+};
+
+enum {
+	VFIO_PCI_INTX_IRQ_INDEX,
+	VFIO_PCI_MSI_IRQ_INDEX,
+	VFIO_PCI_MSIX_IRQ_INDEX,
+	VFIO_PCI_NUM_IRQS
+};
+
+/* -------- API for Type1 VFIO IOMMU -------- */
+
+/**
+ * VFIO_IOMMU_GET_INFO - _IOR(VFIO_TYPE, VFIO_BASE + 12, struct vfio_iommu_info)
+ *
+ * Retrieve information about the IOMMU object. Fills in provided
+ * struct vfio_iommu_info. Caller sets argsz.
+ *
+ * XXX Should we do these by CHECK_EXTENSION too?
+ */
+struct vfio_iommu_type1_info {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_IOMMU_INFO_PGSIZES (1 << 0)	/* supported page sizes info */
+	__u64	iova_pgsizes;		/* Bitmap of supported page sizes */
+};
+
+#define VFIO_IOMMU_GET_INFO _IO(VFIO_TYPE, VFIO_BASE + 12)
+
+/**
+ * VFIO_IOMMU_MAP_DMA - _IOW(VFIO_TYPE, VFIO_BASE + 13, struct vfio_dma_map)
+ *
+ * Map process virtual addresses to IO virtual addresses using the
+ * provided struct vfio_dma_map. Caller sets argsz. READ &/ WRITE required.
+ */
+struct vfio_iommu_type1_dma_map {
+	__u32	argsz;
+	__u32	flags;
+#define VFIO_DMA_MAP_FLAG_READ (1 << 0)		/* readable from device */
+#define VFIO_DMA_MAP_FLAG_WRITE (1 << 1)	/* writable from device */
+	__u64	vaddr;				/* Process virtual address */
+	__u64	iova;				/* IO virtual address */
+	__u64	size;				/* Size of mapping (bytes) */
+};
+
+#define VFIO_IOMMU_MAP_DMA _IO(VFIO_TYPE, VFIO_BASE + 13)
+
+/**
+ * VFIO_IOMMU_UNMAP_DMA - _IOW(VFIO_TYPE, VFIO_BASE + 14, struct vfio_dma_unmap)
+ *
+ * Unmap IO virtual addresses using the provided struct vfio_dma_unmap.
+ * Caller sets argsz.
+ */
+struct vfio_iommu_type1_dma_unmap {
+	__u32	argsz;
+	__u32	flags;
+	__u64	iova;				/* IO virtual address */
+	__u64	size;				/* Size of mapping (bytes) */
+};
+
+#define VFIO_IOMMU_UNMAP_DMA _IO(VFIO_TYPE, VFIO_BASE + 14)
+
+#endif /* _UAPIVFIO_H */
