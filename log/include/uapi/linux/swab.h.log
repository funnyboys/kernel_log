commit 467d12f5c7842896d2de3ced74e4147ee29e97c8
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Thu Feb 20 20:04:03 2020 -0800

    include/uapi/linux/swab.h: fix userspace breakage, use __BITS_PER_LONG for swap
    
    QEMU has a funny new build error message when I use the upstream kernel
    headers:
    
          CC      block/file-posix.o
        In file included from /home/cborntra/REPOS/qemu/include/qemu/timer.h:4,
                         from /home/cborntra/REPOS/qemu/include/qemu/timed-average.h:29,
                         from /home/cborntra/REPOS/qemu/include/block/accounting.h:28,
                         from /home/cborntra/REPOS/qemu/include/block/block_int.h:27,
                         from /home/cborntra/REPOS/qemu/block/file-posix.c:30:
        /usr/include/linux/swab.h: In function `__swab':
        /home/cborntra/REPOS/qemu/include/qemu/bitops.h:20:34: error: "sizeof" is not defined, evaluates to 0 [-Werror=undef]
           20 | #define BITS_PER_LONG           (sizeof (unsigned long) * BITS_PER_BYTE)
              |                                  ^~~~~~
        /home/cborntra/REPOS/qemu/include/qemu/bitops.h:20:41: error: missing binary operator before token "("
           20 | #define BITS_PER_LONG           (sizeof (unsigned long) * BITS_PER_BYTE)
              |                                         ^
        cc1: all warnings being treated as errors
        make: *** [/home/cborntra/REPOS/qemu/rules.mak:69: block/file-posix.o] Error 1
        rm tests/qemu-iotests/socket_scm_helper.o
    
    This was triggered by commit d5767057c9a ("uapi: rename ext2_swab() to
    swab() and share globally in swab.h").  That patch is doing
    
      #include <asm/bitsperlong.h>
    
    but it uses BITS_PER_LONG.
    
    The kernel file asm/bitsperlong.h provide only __BITS_PER_LONG.
    
    Let us use the __ variant in swap.h
    
    Link: http://lkml.kernel.org/r/20200213142147.17604-1-borntraeger@de.ibm.com
    Fixes: d5767057c9a ("uapi: rename ext2_swab() to swab() and share globally in swab.h")
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Yury Norov <yury.norov@gmail.com>
    Cc: Allison Randal <allison@lohutok.net>
    Cc: Joe Perches <joe@perches.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: William Breathitt Gray <vilhelm.gray@gmail.com>
    Cc: Torsten Hilbrich <torsten.hilbrich@secunet.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/uapi/linux/swab.h b/include/uapi/linux/swab.h
index fa7f97da5b76..7272f85d6d6a 100644
--- a/include/uapi/linux/swab.h
+++ b/include/uapi/linux/swab.h
@@ -135,9 +135,9 @@ static inline __attribute_const__ __u32 __fswahb32(__u32 val)
 
 static __always_inline unsigned long __swab(const unsigned long y)
 {
-#if BITS_PER_LONG == 64
+#if __BITS_PER_LONG == 64
 	return __swab64(y);
-#else /* BITS_PER_LONG == 32 */
+#else /* __BITS_PER_LONG == 32 */
 	return __swab32(y);
 #endif
 }

commit d5767057c9a76a29f073dad66b7fa12a90e8c748
Author: Yury Norov <yury.norov@gmail.com>
Date:   Thu Jan 30 22:16:40 2020 -0800

    uapi: rename ext2_swab() to swab() and share globally in swab.h
    
    ext2_swab() is defined locally in lib/find_bit.c However it is not
    specific to ext2, neither to bitmaps.
    
    There are many potential users of it, so rename it to just swab() and
    move to include/uapi/linux/swab.h
    
    ABI guarantees that size of unsigned long corresponds to BITS_PER_LONG,
    therefore drop unneeded cast.
    
    Link: http://lkml.kernel.org/r/20200103202846.21616-1-yury.norov@gmail.com
    Signed-off-by: Yury Norov <yury.norov@gmail.com>
    Cc: Allison Randal <allison@lohutok.net>
    Cc: Joe Perches <joe@perches.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: William Breathitt Gray <vilhelm.gray@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/uapi/linux/swab.h b/include/uapi/linux/swab.h
index 23cd84868cc3..fa7f97da5b76 100644
--- a/include/uapi/linux/swab.h
+++ b/include/uapi/linux/swab.h
@@ -4,6 +4,7 @@
 
 #include <linux/types.h>
 #include <linux/compiler.h>
+#include <asm/bitsperlong.h>
 #include <asm/swab.h>
 
 /*
@@ -132,6 +133,15 @@ static inline __attribute_const__ __u32 __fswahb32(__u32 val)
 	__fswab64(x))
 #endif
 
+static __always_inline unsigned long __swab(const unsigned long y)
+{
+#if BITS_PER_LONG == 64
+	return __swab64(y);
+#else /* BITS_PER_LONG == 32 */
+	return __swab32(y);
+#endif
+}
+
 /**
  * __swahw32 - return a word-swapped 32-bit value
  * @x: value to wordswap

commit 6f52b16c5b29b89d92c0e7236f4655dc8491ad70
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:08:43 2017 +0100

    License cleanup: add SPDX license identifier to uapi header files with no license
    
    Many user space API headers are missing licensing information, which
    makes it hard for compliance tools to determine the correct license.
    
    By default are files without license information under the default
    license of the kernel, which is GPLV2.  Marking them GPLV2 would exclude
    them from being included in non GPLV2 code, which is obviously not
    intended. The user space API headers fall under the syscall exception
    which is in the kernels COPYING file:
    
       NOTE! This copyright does *not* cover user programs that use kernel
       services by normal system calls - this is merely considered normal use
       of the kernel, and does *not* fall under the heading of "derived work".
    
    otherwise syscall usage would not be possible.
    
    Update the files which contain no license information with an SPDX
    license identifier.  The chosen identifier is 'GPL-2.0 WITH
    Linux-syscall-note' which is the officially assigned identifier for the
    Linux syscall exception.  SPDX license identifiers are a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.  See the previous patch in this series for the
    methodology of how this patch was researched.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/uapi/linux/swab.h b/include/uapi/linux/swab.h
index 8f3a8f606fd9..23cd84868cc3 100644
--- a/include/uapi/linux/swab.h
+++ b/include/uapi/linux/swab.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
 #ifndef _UAPI_LINUX_SWAB_H
 #define _UAPI_LINUX_SWAB_H
 

commit 7322dd755e7dd34bc5359aa27abeed1687e0f628
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu May 5 16:22:39 2016 -0700

    byteswap: try to avoid __builtin_constant_p gcc bug
    
    This is another attempt to avoid a regression in wwn_to_u64() after that
    started using get_unaligned_be64(), which in turn ran into a bug on
    gcc-4.9 through 6.1.
    
    The regression got introduced due to the combination of two separate
    workarounds (commits e3bde9568d99: "include/linux/unaligned: force
    inlining of byteswap operations" and ef3fb2422ffe: "scsi: fc: use
    get/put_unaligned64 for wwn access") that each try to sidestep distinct
    problems with gcc behavior (code growth and increased stack usage).
    
    Unfortunately after both have been applied, a more serious gcc bug has
    been uncovered, leading to incorrect object code that discards part of a
    function and causes undefined behavior.
    
    As part of this problem is how __builtin_constant_p gets evaluated on an
    argument passed by reference into an inline function, this avoids the
    use of __builtin_constant_p() for all architectures that set
    CONFIG_ARCH_USE_BUILTIN_BSWAP.  Most architectures do not set
    ARCH_SUPPORTS_OPTIMIZED_INLINING, which means they probably do not
    suffer from the problem in the qla2xxx driver, but they might still run
    into it elsewhere.
    
    Both of the original workarounds were only merged in the 4.6 kernel, and
    the bug that is fixed by this patch should only appear if both are
    there, so we probably don't need to backport the fix.  On the other
    hand, it works by simplifying the code path and should not have any
    negative effects.
    
    [arnd@arndb.de: fix older gcc warnings]
      (http://lkml.kernel.org/r/12243652.bxSxEgjgfk@wuerfel)
    Link: https://lkml.org/lkml/headers/2016/4/12/1103
    Link: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66122
    Link: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=70232
    Link: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=70646
    Fixes: e3bde9568d99 ("include/linux/unaligned: force inlining of byteswap operations")
    Fixes: ef3fb2422ffe ("scsi: fc: use get/put_unaligned64 for wwn access")
    Link: http://lkml.kernel.org/r/1780465.XdtPJpi8Tt@wuerfel
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Josh Poimboeuf <jpoimboe@redhat.com> # on gcc-5.3
    Tested-by: Quinn Tran <quinn.tran@qlogic.com>
    Cc: Martin Jambor <mjambor@suse.cz>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Cc: James Bottomley <James.Bottomley@hansenpartnership.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Thomas Graf <tgraf@suug.ch>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Himanshu Madhani <himanshu.madhani@qlogic.com>
    Cc: Jan Hubicka <hubicka@ucw.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/uapi/linux/swab.h b/include/uapi/linux/swab.h
index 3f10e5317b46..8f3a8f606fd9 100644
--- a/include/uapi/linux/swab.h
+++ b/include/uapi/linux/swab.h
@@ -45,9 +45,7 @@
 
 static inline __attribute_const__ __u16 __fswab16(__u16 val)
 {
-#ifdef __HAVE_BUILTIN_BSWAP16__
-	return __builtin_bswap16(val);
-#elif defined (__arch_swab16)
+#if defined (__arch_swab16)
 	return __arch_swab16(val);
 #else
 	return ___constant_swab16(val);
@@ -56,9 +54,7 @@ static inline __attribute_const__ __u16 __fswab16(__u16 val)
 
 static inline __attribute_const__ __u32 __fswab32(__u32 val)
 {
-#ifdef __HAVE_BUILTIN_BSWAP32__
-	return __builtin_bswap32(val);
-#elif defined(__arch_swab32)
+#if defined(__arch_swab32)
 	return __arch_swab32(val);
 #else
 	return ___constant_swab32(val);
@@ -67,9 +63,7 @@ static inline __attribute_const__ __u32 __fswab32(__u32 val)
 
 static inline __attribute_const__ __u64 __fswab64(__u64 val)
 {
-#ifdef __HAVE_BUILTIN_BSWAP64__
-	return __builtin_bswap64(val);
-#elif defined (__arch_swab64)
+#if defined (__arch_swab64)
 	return __arch_swab64(val);
 #elif defined(__SWAB_64_THRU_32__)
 	__u32 h = val >> 32;
@@ -102,28 +96,40 @@ static inline __attribute_const__ __u32 __fswahb32(__u32 val)
  * __swab16 - return a byteswapped 16-bit value
  * @x: value to byteswap
  */
+#ifdef __HAVE_BUILTIN_BSWAP16__
+#define __swab16(x) (__u16)__builtin_bswap16((__u16)(x))
+#else
 #define __swab16(x)				\
 	(__builtin_constant_p((__u16)(x)) ?	\
 	___constant_swab16(x) :			\
 	__fswab16(x))
+#endif
 
 /**
  * __swab32 - return a byteswapped 32-bit value
  * @x: value to byteswap
  */
+#ifdef __HAVE_BUILTIN_BSWAP32__
+#define __swab32(x) (__u32)__builtin_bswap32((__u32)(x))
+#else
 #define __swab32(x)				\
 	(__builtin_constant_p((__u32)(x)) ?	\
 	___constant_swab32(x) :			\
 	__fswab32(x))
+#endif
 
 /**
  * __swab64 - return a byteswapped 64-bit value
  * @x: value to byteswap
  */
+#ifdef __HAVE_BUILTIN_BSWAP64__
+#define __swab64(x) (__u64)__builtin_bswap64((__u64)(x))
+#else
 #define __swab64(x)				\
 	(__builtin_constant_p((__u64)(x)) ?	\
 	___constant_swab64(x) :			\
 	__fswab64(x))
+#endif
 
 /**
  * __swahw32 - return a word-swapped 32-bit value

commit bc27fb68aaad44dd8f5c34924f05721f0abaeec1
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Thu Mar 17 14:22:44 2016 -0700

    include/uapi/linux/byteorder, swab: force inlining of some byteswap operations
    
    Sometimes gcc mysteriously doesn't inline
    very small functions we expect to be inlined. See
    
        https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66122
    
    With this .config:
    http://busybox.net/~vda/kernel_config_OPTIMIZE_INLINING_and_Os,
    the following functions get deinlined many times.
    Examples of disassembly:
    
    <get_unaligned_be16> (12 copies, 51 calls):
           66 8b 07                mov    (%rdi),%ax
           55                      push   %rbp
           48 89 e5                mov    %rsp,%rbp
           86 e0                   xchg   %ah,%al
           5d                      pop    %rbp
           c3                      retq
    
    <get_unaligned_be32> (12 copies, 135 calls):
           8b 07                   mov    (%rdi),%eax
           55                      push   %rbp
           48 89 e5                mov    %rsp,%rbp
           0f c8                   bswap  %eax
           5d                      pop    %rbp
           c3                      retq
    
    <get_unaligned_be64> (2 copies, 20 calls):
           48 8b 07                mov    (%rdi),%rax
           55                      push   %rbp
           48 89 e5                mov    %rsp,%rbp
           48 0f c8                bswap  %rax
           5d                      pop    %rbp
           c3                      retq
    
    <__swab16p> (16 copies, 146 calls):
           55                      push   %rbp
           89 f8                   mov    %edi,%eax
           86 e0                   xchg   %ah,%al
           48 89 e5                mov    %rsp,%rbp
           5d                      pop    %rbp
           c3                      retq
    
    <__swab32p> (43 copies, ~560 calls):
           55                      push   %rbp
           89 f8                   mov    %edi,%eax
           0f c8                   bswap  %eax
           48 89 e5                mov    %rsp,%rbp
           5d                      pop    %rbp
           c3                      retq
    
    <__swab64p> (21 copies, 119 calls):
           55                      push   %rbp
           48 89 f8                mov    %rdi,%rax
           48 0f c8                bswap  %rax
           48 89 e5                mov    %rsp,%rbp
           5d                      pop    %rbp
           c3                      retq
    
    <__swab32s> (6 copies, 47 calls):
           8b 07                   mov    (%rdi),%eax
           55                      push   %rbp
           48 89 e5                mov    %rsp,%rbp
           0f c8                   bswap  %eax
           89 07                   mov    %eax,(%rdi)
           5d                      pop    %rbp
           c3                      retq
    
    This patch fixes this via s/inline/__always_inline/.
    Code size decrease after the patch is ~4.5k:
    
        text     data      bss       dec     hex filename
    92202377 20826112 36417536 149446025 8e85d89 vmlinux
    92197848 20826112 36417536 149441496 8e84bd8 vmlinux5_swap_after
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Graf <tgraf@suug.ch>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/uapi/linux/swab.h b/include/uapi/linux/swab.h
index 0e011eb91b5d..3f10e5317b46 100644
--- a/include/uapi/linux/swab.h
+++ b/include/uapi/linux/swab.h
@@ -151,7 +151,7 @@ static inline __attribute_const__ __u32 __fswahb32(__u32 val)
  * __swab16p - return a byteswapped 16-bit value from a pointer
  * @p: pointer to a naturally-aligned 16-bit value
  */
-static inline __u16 __swab16p(const __u16 *p)
+static __always_inline __u16 __swab16p(const __u16 *p)
 {
 #ifdef __arch_swab16p
 	return __arch_swab16p(p);
@@ -164,7 +164,7 @@ static inline __u16 __swab16p(const __u16 *p)
  * __swab32p - return a byteswapped 32-bit value from a pointer
  * @p: pointer to a naturally-aligned 32-bit value
  */
-static inline __u32 __swab32p(const __u32 *p)
+static __always_inline __u32 __swab32p(const __u32 *p)
 {
 #ifdef __arch_swab32p
 	return __arch_swab32p(p);
@@ -177,7 +177,7 @@ static inline __u32 __swab32p(const __u32 *p)
  * __swab64p - return a byteswapped 64-bit value from a pointer
  * @p: pointer to a naturally-aligned 64-bit value
  */
-static inline __u64 __swab64p(const __u64 *p)
+static __always_inline __u64 __swab64p(const __u64 *p)
 {
 #ifdef __arch_swab64p
 	return __arch_swab64p(p);
@@ -232,7 +232,7 @@ static inline void __swab16s(__u16 *p)
  * __swab32s - byteswap a 32-bit value in-place
  * @p: pointer to a naturally-aligned 32-bit value
  */
-static inline void __swab32s(__u32 *p)
+static __always_inline void __swab32s(__u32 *p)
 {
 #ifdef __arch_swab32s
 	__arch_swab32s(p);
@@ -245,7 +245,7 @@ static inline void __swab32s(__u32 *p)
  * __swab64s - byteswap a 64-bit value in-place
  * @p: pointer to a naturally-aligned 64-bit value
  */
-static inline void __swab64s(__u64 *p)
+static __always_inline void __swab64s(__u64 *p)
 {
 #ifdef __arch_swab64s
 	__arch_swab64s(p);

commit cf66bb93e0f75e0a4ba1ec070692618fa028e994
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Mon Dec 3 16:25:40 2012 +0000

    byteorder: allow arch to opt to use GCC intrinsics for byteswapping
    
    Since GCC 4.4, there have been __builtin_bswap32() and __builtin_bswap16()
    intrinsics. A __builtin_bswap16() came a little later (4.6 for PowerPC,
    48 for other platforms).
    
    By using these instead of the inline assembler that most architectures
    have in their __arch_swabXX() macros, we let the compiler see what's
    actually happening. The resulting code should be at least as good, and
    much *better* in the cases where it can be combined with a nearby load
    or store, using a load-and-byteswap or store-and-byteswap instruction
    (e.g. lwbrx/stwbrx on PowerPC, movbe on Atom).
    
    When GCC is sufficiently recent *and* the architecture opts in to using
    the intrinsics by setting CONFIG_ARCH_USE_BUILTIN_BSWAP, they will be
    used in preference to the __arch_swabXX() macros. An architecture which
    does not set ARCH_USE_BUILTIN_BSWAP will continue to use its own
    hand-crafted macros.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/include/uapi/linux/swab.h b/include/uapi/linux/swab.h
index e811474724c2..0e011eb91b5d 100644
--- a/include/uapi/linux/swab.h
+++ b/include/uapi/linux/swab.h
@@ -45,7 +45,9 @@
 
 static inline __attribute_const__ __u16 __fswab16(__u16 val)
 {
-#ifdef __arch_swab16
+#ifdef __HAVE_BUILTIN_BSWAP16__
+	return __builtin_bswap16(val);
+#elif defined (__arch_swab16)
 	return __arch_swab16(val);
 #else
 	return ___constant_swab16(val);
@@ -54,7 +56,9 @@ static inline __attribute_const__ __u16 __fswab16(__u16 val)
 
 static inline __attribute_const__ __u32 __fswab32(__u32 val)
 {
-#ifdef __arch_swab32
+#ifdef __HAVE_BUILTIN_BSWAP32__
+	return __builtin_bswap32(val);
+#elif defined(__arch_swab32)
 	return __arch_swab32(val);
 #else
 	return ___constant_swab32(val);
@@ -63,7 +67,9 @@ static inline __attribute_const__ __u32 __fswab32(__u32 val)
 
 static inline __attribute_const__ __u64 __fswab64(__u64 val)
 {
-#ifdef __arch_swab64
+#ifdef __HAVE_BUILTIN_BSWAP64__
+	return __builtin_bswap64(val);
+#elif defined (__arch_swab64)
 	return __arch_swab64(val);
 #elif defined(__SWAB_64_THRU_32__)
 	__u32 h = val >> 32;

commit 607ca46e97a1b6594b29647d98a32d545c24bdff
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 13 10:46:48 2012 +0100

    UAPI: (Scripted) Disintegrate include/linux
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/include/uapi/linux/swab.h b/include/uapi/linux/swab.h
new file mode 100644
index 000000000000..e811474724c2
--- /dev/null
+++ b/include/uapi/linux/swab.h
@@ -0,0 +1,282 @@
+#ifndef _UAPI_LINUX_SWAB_H
+#define _UAPI_LINUX_SWAB_H
+
+#include <linux/types.h>
+#include <linux/compiler.h>
+#include <asm/swab.h>
+
+/*
+ * casts are necessary for constants, because we never know how for sure
+ * how U/UL/ULL map to __u16, __u32, __u64. At least not in a portable way.
+ */
+#define ___constant_swab16(x) ((__u16)(				\
+	(((__u16)(x) & (__u16)0x00ffU) << 8) |			\
+	(((__u16)(x) & (__u16)0xff00U) >> 8)))
+
+#define ___constant_swab32(x) ((__u32)(				\
+	(((__u32)(x) & (__u32)0x000000ffUL) << 24) |		\
+	(((__u32)(x) & (__u32)0x0000ff00UL) <<  8) |		\
+	(((__u32)(x) & (__u32)0x00ff0000UL) >>  8) |		\
+	(((__u32)(x) & (__u32)0xff000000UL) >> 24)))
+
+#define ___constant_swab64(x) ((__u64)(				\
+	(((__u64)(x) & (__u64)0x00000000000000ffULL) << 56) |	\
+	(((__u64)(x) & (__u64)0x000000000000ff00ULL) << 40) |	\
+	(((__u64)(x) & (__u64)0x0000000000ff0000ULL) << 24) |	\
+	(((__u64)(x) & (__u64)0x00000000ff000000ULL) <<  8) |	\
+	(((__u64)(x) & (__u64)0x000000ff00000000ULL) >>  8) |	\
+	(((__u64)(x) & (__u64)0x0000ff0000000000ULL) >> 24) |	\
+	(((__u64)(x) & (__u64)0x00ff000000000000ULL) >> 40) |	\
+	(((__u64)(x) & (__u64)0xff00000000000000ULL) >> 56)))
+
+#define ___constant_swahw32(x) ((__u32)(			\
+	(((__u32)(x) & (__u32)0x0000ffffUL) << 16) |		\
+	(((__u32)(x) & (__u32)0xffff0000UL) >> 16)))
+
+#define ___constant_swahb32(x) ((__u32)(			\
+	(((__u32)(x) & (__u32)0x00ff00ffUL) << 8) |		\
+	(((__u32)(x) & (__u32)0xff00ff00UL) >> 8)))
+
+/*
+ * Implement the following as inlines, but define the interface using
+ * macros to allow constant folding when possible:
+ * ___swab16, ___swab32, ___swab64, ___swahw32, ___swahb32
+ */
+
+static inline __attribute_const__ __u16 __fswab16(__u16 val)
+{
+#ifdef __arch_swab16
+	return __arch_swab16(val);
+#else
+	return ___constant_swab16(val);
+#endif
+}
+
+static inline __attribute_const__ __u32 __fswab32(__u32 val)
+{
+#ifdef __arch_swab32
+	return __arch_swab32(val);
+#else
+	return ___constant_swab32(val);
+#endif
+}
+
+static inline __attribute_const__ __u64 __fswab64(__u64 val)
+{
+#ifdef __arch_swab64
+	return __arch_swab64(val);
+#elif defined(__SWAB_64_THRU_32__)
+	__u32 h = val >> 32;
+	__u32 l = val & ((1ULL << 32) - 1);
+	return (((__u64)__fswab32(l)) << 32) | ((__u64)(__fswab32(h)));
+#else
+	return ___constant_swab64(val);
+#endif
+}
+
+static inline __attribute_const__ __u32 __fswahw32(__u32 val)
+{
+#ifdef __arch_swahw32
+	return __arch_swahw32(val);
+#else
+	return ___constant_swahw32(val);
+#endif
+}
+
+static inline __attribute_const__ __u32 __fswahb32(__u32 val)
+{
+#ifdef __arch_swahb32
+	return __arch_swahb32(val);
+#else
+	return ___constant_swahb32(val);
+#endif
+}
+
+/**
+ * __swab16 - return a byteswapped 16-bit value
+ * @x: value to byteswap
+ */
+#define __swab16(x)				\
+	(__builtin_constant_p((__u16)(x)) ?	\
+	___constant_swab16(x) :			\
+	__fswab16(x))
+
+/**
+ * __swab32 - return a byteswapped 32-bit value
+ * @x: value to byteswap
+ */
+#define __swab32(x)				\
+	(__builtin_constant_p((__u32)(x)) ?	\
+	___constant_swab32(x) :			\
+	__fswab32(x))
+
+/**
+ * __swab64 - return a byteswapped 64-bit value
+ * @x: value to byteswap
+ */
+#define __swab64(x)				\
+	(__builtin_constant_p((__u64)(x)) ?	\
+	___constant_swab64(x) :			\
+	__fswab64(x))
+
+/**
+ * __swahw32 - return a word-swapped 32-bit value
+ * @x: value to wordswap
+ *
+ * __swahw32(0x12340000) is 0x00001234
+ */
+#define __swahw32(x)				\
+	(__builtin_constant_p((__u32)(x)) ?	\
+	___constant_swahw32(x) :		\
+	__fswahw32(x))
+
+/**
+ * __swahb32 - return a high and low byte-swapped 32-bit value
+ * @x: value to byteswap
+ *
+ * __swahb32(0x12345678) is 0x34127856
+ */
+#define __swahb32(x)				\
+	(__builtin_constant_p((__u32)(x)) ?	\
+	___constant_swahb32(x) :		\
+	__fswahb32(x))
+
+/**
+ * __swab16p - return a byteswapped 16-bit value from a pointer
+ * @p: pointer to a naturally-aligned 16-bit value
+ */
+static inline __u16 __swab16p(const __u16 *p)
+{
+#ifdef __arch_swab16p
+	return __arch_swab16p(p);
+#else
+	return __swab16(*p);
+#endif
+}
+
+/**
+ * __swab32p - return a byteswapped 32-bit value from a pointer
+ * @p: pointer to a naturally-aligned 32-bit value
+ */
+static inline __u32 __swab32p(const __u32 *p)
+{
+#ifdef __arch_swab32p
+	return __arch_swab32p(p);
+#else
+	return __swab32(*p);
+#endif
+}
+
+/**
+ * __swab64p - return a byteswapped 64-bit value from a pointer
+ * @p: pointer to a naturally-aligned 64-bit value
+ */
+static inline __u64 __swab64p(const __u64 *p)
+{
+#ifdef __arch_swab64p
+	return __arch_swab64p(p);
+#else
+	return __swab64(*p);
+#endif
+}
+
+/**
+ * __swahw32p - return a wordswapped 32-bit value from a pointer
+ * @p: pointer to a naturally-aligned 32-bit value
+ *
+ * See __swahw32() for details of wordswapping.
+ */
+static inline __u32 __swahw32p(const __u32 *p)
+{
+#ifdef __arch_swahw32p
+	return __arch_swahw32p(p);
+#else
+	return __swahw32(*p);
+#endif
+}
+
+/**
+ * __swahb32p - return a high and low byteswapped 32-bit value from a pointer
+ * @p: pointer to a naturally-aligned 32-bit value
+ *
+ * See __swahb32() for details of high/low byteswapping.
+ */
+static inline __u32 __swahb32p(const __u32 *p)
+{
+#ifdef __arch_swahb32p
+	return __arch_swahb32p(p);
+#else
+	return __swahb32(*p);
+#endif
+}
+
+/**
+ * __swab16s - byteswap a 16-bit value in-place
+ * @p: pointer to a naturally-aligned 16-bit value
+ */
+static inline void __swab16s(__u16 *p)
+{
+#ifdef __arch_swab16s
+	__arch_swab16s(p);
+#else
+	*p = __swab16p(p);
+#endif
+}
+/**
+ * __swab32s - byteswap a 32-bit value in-place
+ * @p: pointer to a naturally-aligned 32-bit value
+ */
+static inline void __swab32s(__u32 *p)
+{
+#ifdef __arch_swab32s
+	__arch_swab32s(p);
+#else
+	*p = __swab32p(p);
+#endif
+}
+
+/**
+ * __swab64s - byteswap a 64-bit value in-place
+ * @p: pointer to a naturally-aligned 64-bit value
+ */
+static inline void __swab64s(__u64 *p)
+{
+#ifdef __arch_swab64s
+	__arch_swab64s(p);
+#else
+	*p = __swab64p(p);
+#endif
+}
+
+/**
+ * __swahw32s - wordswap a 32-bit value in-place
+ * @p: pointer to a naturally-aligned 32-bit value
+ *
+ * See __swahw32() for details of wordswapping
+ */
+static inline void __swahw32s(__u32 *p)
+{
+#ifdef __arch_swahw32s
+	__arch_swahw32s(p);
+#else
+	*p = __swahw32p(p);
+#endif
+}
+
+/**
+ * __swahb32s - high and low byteswap a 32-bit value in-place
+ * @p: pointer to a naturally-aligned 32-bit value
+ *
+ * See __swahb32() for details of high and low byte swapping
+ */
+static inline void __swahb32s(__u32 *p)
+{
+#ifdef __arch_swahb32s
+	__arch_swahb32s(p);
+#else
+	*p = __swahb32p(p);
+#endif
+}
+
+
+#endif /* _UAPI_LINUX_SWAB_H */
