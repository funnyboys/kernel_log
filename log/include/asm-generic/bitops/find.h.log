commit 169c474fb22d8a5e909e172f177b957546d0519d
Author: William Breathitt Gray <vilhelm.gray@gmail.com>
Date:   Wed Dec 4 16:50:57 2019 -0800

    bitops: introduce the for_each_set_clump8 macro
    
    Pach series "Introduce the for_each_set_clump8 macro", v18.
    
    While adding GPIO get_multiple/set_multiple callback support for various
    drivers, I noticed a pattern of looping manifesting that would be useful
    standardized as a macro.
    
    This patchset introduces the for_each_set_clump8 macro and utilizes it
    in several GPIO drivers.  The for_each_set_clump macro8 facilitates a
    for-loop syntax that iterates over a memory region entire groups of set
    bits at a time.
    
    For example, suppose you would like to iterate over a 32-bit integer 8
    bits at a time, skipping over 8-bit groups with no set bit, where
    XXXXXXXX represents the current 8-bit group:
    
        Example:        10111110 00000000 11111111 00110011
        First loop:     10111110 00000000 11111111 XXXXXXXX
        Second loop:    10111110 00000000 XXXXXXXX 00110011
        Third loop:     XXXXXXXX 00000000 11111111 00110011
    
    Each iteration of the loop returns the next 8-bit group that has at
    least one set bit.
    
    The for_each_set_clump8 macro has four parameters:
    
        * start: set to the bit offset of the current clump
        * clump: set to the current clump value
        * bits: bitmap to search within
        * size: bitmap size in number of bits
    
    In this version of the patchset, the for_each_set_clump macro has been
    reimplemented and simplified based on the suggestions provided by Rasmus
    Villemoes and Andy Shevchenko in the version 4 submission.
    
    In particular, the function of the for_each_set_clump macro has been
    restricted to handle only 8-bit clumps; the drivers that use the
    for_each_set_clump macro only handle 8-bit ports so a generic
    for_each_set_clump implementation is not necessary.  Thus, a solution
    for large clumps (i.e.  those larger than the width of a bitmap word)
    can be postponed until a driver appears that actually requires such a
    generic for_each_set_clump implementation.
    
    For what it's worth, a semi-generic for_each_set_clump (i.e.  for clumps
    smaller than the width of a bitmap word) can be implemented by simply
    replacing the hardcoded '8' and '0xFF' instances with respective
    variables.  I have not yet had a need for such an implementation, and
    since it falls short of a true generic for_each_set_clump function, I
    have decided to forgo such an implementation for now.
    
    In addition, the bitmap_get_value8 and bitmap_set_value8 functions are
    introduced to get and set 8-bit values respectively.  Their use is based
    on the behavior suggested in the patchset version 4 review.
    
    This patch (of 14):
    
    This macro iterates for each 8-bit group of bits (clump) with set bits,
    within a bitmap memory region.  For each iteration, "start" is set to
    the bit offset of the found clump, while the respective clump value is
    stored to the location pointed by "clump".  Additionally, the
    bitmap_get_value8 and bitmap_set_value8 functions are introduced to
    respectively get and set an 8-bit value in a bitmap memory region.
    
    [gustavo@embeddedor.com: fix potential sign-extension overflow]
      Link: http://lkml.kernel.org/r/20191015184657.GA26541@embeddedor
    [akpm@linux-foundation.org: s/ULL/UL/, per Joe]
    [vilhelm.gray@gmail.com: add for_each_set_clump8 documentation]
      Link: http://lkml.kernel.org/r/20191016161825.301082-1-vilhelm.gray@gmail.com
    Link: http://lkml.kernel.org/r/893c3b4f03266c9496137cc98ac2b1bd27f92c73.1570641097.git.vilhelm.gray@gmail.com
    Signed-off-by: William Breathitt Gray <vilhelm.gray@gmail.com>
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Suggested-by: Andy Shevchenko <andy.shevchenko@gmail.com>
    Suggested-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Suggested-by: Lukas Wunner <lukas@wunner.de>
    Tested-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Bartosz Golaszewski <bgolaszewski@baylibre.com>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Phil Reid <preid@electromag.com.au>
    Cc: Geert Uytterhoeven <geert+renesas@glider.be>
    Cc: Mathias Duckeck <m.duckeck@kunbus.de>
    Cc: Morten Hein Tiljeset <morten.tiljeset@prevas.dk>
    Cc: Sean Nyekjaer <sean.nyekjaer@prevas.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 8a1ee10014de..9fdf21302fdf 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -80,4 +80,21 @@ extern unsigned long find_first_zero_bit(const unsigned long *addr,
 
 #endif /* CONFIG_GENERIC_FIND_FIRST_BIT */
 
+/**
+ * find_next_clump8 - find next 8-bit clump with set bits in a memory region
+ * @clump: location to store copy of found clump
+ * @addr: address to base the search on
+ * @size: bitmap size in number of bits
+ * @offset: bit offset at which to start searching
+ *
+ * Returns the bit offset for the next set clump; the found clump value is
+ * copied to the location pointed by @clump. If no bits are set, returns @size.
+ */
+extern unsigned long find_next_clump8(unsigned long *clump,
+				      const unsigned long *addr,
+				      unsigned long size, unsigned long offset);
+
+#define find_first_clump8(clump, bits, size) \
+	find_next_clump8((clump), (bits), (size), 0)
+
 #endif /*_ASM_GENERIC_BITOPS_FIND_H_ */

commit 0ade34c37012ea5c516d9aa4d19a56e9f40a55ed
Author: Clement Courbet <courbet@google.com>
Date:   Tue Feb 6 15:38:34 2018 -0800

    lib: optimize cpumask_next_and()
    
    We've measured that we spend ~0.6% of sys cpu time in cpumask_next_and().
    It's essentially a joined iteration in search for a non-zero bit, which is
    currently implemented as a lookup join (find a nonzero bit on the lhs,
    lookup the rhs to see if it's set there).
    
    Implement a direct join (find a nonzero bit on the incrementally built
    join).  Also add generic bitmap benchmarks in the new `test_find_bit`
    module for new function (see `find_next_and_bit` in [2] and [3] below).
    
    For cpumask_next_and, direct benchmarking shows that it's 1.17x to 14x
    faster with a geometric mean of 2.1 on 32 CPUs [1].  No impact on memory
    usage.  Note that on Arm, the new pure-C implementation still outperforms
    the old one that uses a mix of C and asm (`find_next_bit`) [3].
    
    [1] Approximate benchmark code:
    
    ```
      unsigned long src1p[nr_cpumask_longs] = {pattern1};
      unsigned long src2p[nr_cpumask_longs] = {pattern2};
      for (/*a bunch of repetitions*/) {
        for (int n = -1; n <= nr_cpu_ids; ++n) {
          asm volatile("" : "+rm"(src1p)); // prevent any optimization
          asm volatile("" : "+rm"(src2p));
          unsigned long result = cpumask_next_and(n, src1p, src2p);
          asm volatile("" : "+rm"(result));
        }
      }
    ```
    
    Results:
    pattern1    pattern2     time_before/time_after
    0x0000ffff  0x0000ffff   1.65
    0x0000ffff  0x00005555   2.24
    0x0000ffff  0x00001111   2.94
    0x0000ffff  0x00000000   14.0
    0x00005555  0x0000ffff   1.67
    0x00005555  0x00005555   1.71
    0x00005555  0x00001111   1.90
    0x00005555  0x00000000   6.58
    0x00001111  0x0000ffff   1.46
    0x00001111  0x00005555   1.49
    0x00001111  0x00001111   1.45
    0x00001111  0x00000000   3.10
    0x00000000  0x0000ffff   1.18
    0x00000000  0x00005555   1.18
    0x00000000  0x00001111   1.17
    0x00000000  0x00000000   1.25
    -----------------------------
                   geo.mean  2.06
    
    [2] test_find_next_bit, X86 (skylake)
    
     [ 3913.477422] Start testing find_bit() with random-filled bitmap
     [ 3913.477847] find_next_bit: 160868 cycles, 16484 iterations
     [ 3913.477933] find_next_zero_bit: 169542 cycles, 16285 iterations
     [ 3913.478036] find_last_bit: 201638 cycles, 16483 iterations
     [ 3913.480214] find_first_bit: 4353244 cycles, 16484 iterations
     [ 3913.480216] Start testing find_next_and_bit() with random-filled
     bitmap
     [ 3913.481074] find_next_and_bit: 89604 cycles, 8216 iterations
     [ 3913.481075] Start testing find_bit() with sparse bitmap
     [ 3913.481078] find_next_bit: 2536 cycles, 66 iterations
     [ 3913.481252] find_next_zero_bit: 344404 cycles, 32703 iterations
     [ 3913.481255] find_last_bit: 2006 cycles, 66 iterations
     [ 3913.481265] find_first_bit: 17488 cycles, 66 iterations
     [ 3913.481266] Start testing find_next_and_bit() with sparse bitmap
     [ 3913.481272] find_next_and_bit: 764 cycles, 1 iterations
    
    [3] test_find_next_bit, arm (v7 odroid XU3).
    
    [  267.206928] Start testing find_bit() with random-filled bitmap
    [  267.214752] find_next_bit: 4474 cycles, 16419 iterations
    [  267.221850] find_next_zero_bit: 5976 cycles, 16350 iterations
    [  267.229294] find_last_bit: 4209 cycles, 16419 iterations
    [  267.279131] find_first_bit: 1032991 cycles, 16420 iterations
    [  267.286265] Start testing find_next_and_bit() with random-filled
    bitmap
    [  267.302386] find_next_and_bit: 2290 cycles, 8140 iterations
    [  267.309422] Start testing find_bit() with sparse bitmap
    [  267.316054] find_next_bit: 191 cycles, 66 iterations
    [  267.322726] find_next_zero_bit: 8758 cycles, 32703 iterations
    [  267.329803] find_last_bit: 84 cycles, 66 iterations
    [  267.336169] find_first_bit: 4118 cycles, 66 iterations
    [  267.342627] Start testing find_next_and_bit() with sparse bitmap
    [  267.356919] find_next_and_bit: 91 cycles, 1 iterations
    
    [courbet@google.com: v6]
      Link: http://lkml.kernel.org/r/20171129095715.23430-1-courbet@google.com
    [geert@linux-m68k.org: m68k/bitops: always include <asm-generic/bitops/find.h>]
      Link: http://lkml.kernel.org/r/1512556816-28627-1-git-send-email-geert@linux-m68k.org
    Link: http://lkml.kernel.org/r/20171128131334.23491-1-courbet@google.com
    Signed-off-by: Clement Courbet <courbet@google.com>
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Yury Norov <ynorov@caviumnetworks.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 1ba611e16fa0..8a1ee10014de 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -16,6 +16,22 @@ extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
 		size, unsigned long offset);
 #endif
 
+#ifndef find_next_and_bit
+/**
+ * find_next_and_bit - find the next set bit in both memory regions
+ * @addr1: The first address to base the search on
+ * @addr2: The second address to base the search on
+ * @offset: The bitnumber to start searching at
+ * @size: The bitmap size in bits
+ *
+ * Returns the bit number for the next set bit
+ * If no bits are set, returns @size.
+ */
+extern unsigned long find_next_and_bit(const unsigned long *addr1,
+		const unsigned long *addr2, unsigned long size,
+		unsigned long offset);
+#endif
+
 #ifndef find_next_zero_bit
 /**
  * find_next_zero_bit - find the next cleared bit in a memory region
@@ -55,8 +71,12 @@ extern unsigned long find_first_zero_bit(const unsigned long *addr,
 					 unsigned long size);
 #else /* CONFIG_GENERIC_FIND_FIRST_BIT */
 
+#ifndef find_first_bit
 #define find_first_bit(addr, size) find_next_bit((addr), (size), 0)
+#endif
+#ifndef find_first_zero_bit
 #define find_first_zero_bit(addr, size) find_next_zero_bit((addr), (size), 0)
+#endif
 
 #endif /* CONFIG_GENERIC_FIND_FIRST_BIT */
 

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 998d4d544f18..1ba611e16fa0 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_GENERIC_BITOPS_FIND_H_
 #define _ASM_GENERIC_BITOPS_FIND_H_
 

commit ec778edf97dcaa517e5b0eea6f1a9ba9d476e4a8
Author: Cody P Schafer <cody@linux.vnet.ibm.com>
Date:   Tue Nov 12 15:09:48 2013 -0800

    bitops/find: clarify and extend documentation
    
    Add return value documentation and clarify the units of the @size
    parameter.
    
    Signed-off-by: Cody P Schafer <cody@linux.vnet.ibm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Cody P Schafer <cody@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 71c778033f57..998d4d544f18 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -7,6 +7,9 @@
  * @addr: The address to base the search on
  * @offset: The bitnumber to start searching at
  * @size: The bitmap size in bits
+ *
+ * Returns the bit number for the next set bit
+ * If no bits are set, returns @size.
  */
 extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
 		size, unsigned long offset);
@@ -18,6 +21,9 @@ extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
  * @addr: The address to base the search on
  * @offset: The bitnumber to start searching at
  * @size: The bitmap size in bits
+ *
+ * Returns the bit number of the next zero bit
+ * If no bits are zero, returns @size.
  */
 extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
 		long size, unsigned long offset);
@@ -28,9 +34,10 @@ extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
 /**
  * find_first_bit - find the first set bit in a memory region
  * @addr: The address to start the search at
- * @size: The maximum size to search
+ * @size: The maximum number of bits to search
  *
  * Returns the bit number of the first set bit.
+ * If no bits are set, returns @size.
  */
 extern unsigned long find_first_bit(const unsigned long *addr,
 				    unsigned long size);
@@ -38,9 +45,10 @@ extern unsigned long find_first_bit(const unsigned long *addr,
 /**
  * find_first_zero_bit - find the first cleared bit in a memory region
  * @addr: The address to start the search at
- * @size: The maximum size to search
+ * @size: The maximum number of bits to search
  *
  * Returns the bit number of the first cleared bit.
+ * If no bits are zero, returns @size.
  */
 extern unsigned long find_first_zero_bit(const unsigned long *addr,
 					 unsigned long size);

commit 19de85ef574c3a2182e3ccad9581805052f14946
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Thu May 26 16:26:09 2011 -0700

    bitops: add #ifndef for each of find bitops
    
    The style that we normally use in asm-generic is to test the macro itself
    for existence, so in asm-generic, do:
    
            #ifndef find_next_zero_bit_le
            extern unsigned long find_next_zero_bit_le(const void *addr,
                    unsigned long size, unsigned long offset);
            #endif
    
    and in the architectures, write
    
            static inline unsigned long find_next_zero_bit_le(const void *addr,
                    unsigned long size, unsigned long offset)
            #define find_next_zero_bit_le find_next_zero_bit_le
    
    This adds the #ifndef for each of the find bitops in the generic header
    and source files.
    
    Suggested-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Greg Ungerer <gerg@uclinux.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 110fa700f853..71c778033f57 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -1,6 +1,7 @@
 #ifndef _ASM_GENERIC_BITOPS_FIND_H_
 #define _ASM_GENERIC_BITOPS_FIND_H_
 
+#ifndef find_next_bit
 /**
  * find_next_bit - find the next set bit in a memory region
  * @addr: The address to base the search on
@@ -9,7 +10,9 @@
  */
 extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
 		size, unsigned long offset);
+#endif
 
+#ifndef find_next_zero_bit
 /**
  * find_next_zero_bit - find the next cleared bit in a memory region
  * @addr: The address to base the search on
@@ -18,6 +21,7 @@ extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
  */
 extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
 		long size, unsigned long offset);
+#endif
 
 #ifdef CONFIG_GENERIC_FIND_FIRST_BIT
 

commit d852a6afd91fc928128f59ebff381838c365e358
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Wed Sep 29 18:08:51 2010 +0900

    bitops: remove duplicated extern declarations
    
    If CONFIG_GENERIC_FIND_NEXT_BIT is enabled, find_next_bit() and
    find_next_zero_bit() are doubly declared in asm-generic/bitops/find.h
    and linux/bitops.h.
    
    asm/bitops.h includes asm-generic/bitops/find.h if and only if the
    architecture enables CONFIG_GENERIC_FIND_NEXT_BIT. And asm/bitops.h
    is included by linux/bitops.h
    
    So we can just remove the extern declarations of find_next_bit() and
    find_next_zero_bit() in linux/bitops.h.
    
    Also we can remove unneeded #ifndef CONFIG_GENERIC_FIND_NEXT_BIT in
    asm-generic/bitops/find.h.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 30afec0db7d7..110fa700f853 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -1,13 +1,23 @@
 #ifndef _ASM_GENERIC_BITOPS_FIND_H_
 #define _ASM_GENERIC_BITOPS_FIND_H_
 
-#ifndef CONFIG_GENERIC_FIND_NEXT_BIT
+/**
+ * find_next_bit - find the next set bit in a memory region
+ * @addr: The address to base the search on
+ * @offset: The bitnumber to start searching at
+ * @size: The bitmap size in bits
+ */
 extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
 		size, unsigned long offset);
 
+/**
+ * find_next_zero_bit - find the next cleared bit in a memory region
+ * @addr: The address to base the search on
+ * @offset: The bitnumber to start searching at
+ * @size: The bitmap size in bits
+ */
 extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
 		long size, unsigned long offset);
-#endif
 
 #ifdef CONFIG_GENERIC_FIND_FIRST_BIT
 

commit 708ff2a0097b02d32d375b66996661f36cd4d6d1
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Wed Sep 29 18:08:50 2010 +0900

    bitops: make asm-generic/bitops/find.h more generic
    
    asm-generic/bitops/find.h has the extern declarations of find_next_bit()
    and find_next_zero_bit() and the macro definitions of find_first_bit()
    and find_first_zero_bit(). It is only usable by the architectures which
    enables CONFIG_GENERIC_FIND_NEXT_BIT and disables
    CONFIG_GENERIC_FIND_FIRST_BIT.
    
    x86 and tile enable both CONFIG_GENERIC_FIND_NEXT_BIT and
    CONFIG_GENERIC_FIND_FIRST_BIT. These architectures cannot include
    asm-generic/bitops/find.h in their asm/bitops.h. So ifdefed extern
    declarations of find_first_bit and find_first_zero_bit() are put in
    linux/bitops.h.
    
    This makes asm-generic/bitops/find.h usable by these architectures
    and use it. Also this change is needed for the forthcoming duplicated
    extern declarations cleanup.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: x86@kernel.org
    Cc: Chris Metcalf <cmetcalf@tilera.com>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 1914e9742512..30afec0db7d7 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -9,7 +9,32 @@ extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
 		long size, unsigned long offset);
 #endif
 
+#ifdef CONFIG_GENERIC_FIND_FIRST_BIT
+
+/**
+ * find_first_bit - find the first set bit in a memory region
+ * @addr: The address to start the search at
+ * @size: The maximum size to search
+ *
+ * Returns the bit number of the first set bit.
+ */
+extern unsigned long find_first_bit(const unsigned long *addr,
+				    unsigned long size);
+
+/**
+ * find_first_zero_bit - find the first cleared bit in a memory region
+ * @addr: The address to start the search at
+ * @size: The maximum size to search
+ *
+ * Returns the bit number of the first cleared bit.
+ */
+extern unsigned long find_first_zero_bit(const unsigned long *addr,
+					 unsigned long size);
+#else /* CONFIG_GENERIC_FIND_FIRST_BIT */
+
 #define find_first_bit(addr, size) find_next_bit((addr), (size), 0)
 #define find_first_zero_bit(addr, size) find_next_zero_bit((addr), (size), 0)
 
+#endif /* CONFIG_GENERIC_FIND_FIRST_BIT */
+
 #endif /*_ASM_GENERIC_BITOPS_FIND_H_ */

commit 64970b68d2b3ed32b964b0b30b1b98518fde388e
Author: Alexander van Heukelum <heukelum@mailshack.com>
Date:   Tue Mar 11 16:17:19 2008 +0100

    x86, generic: optimize find_next_(zero_)bit for small constant-size bitmaps
    
    This moves an optimization for searching constant-sized small
    bitmaps form x86_64-specific to generic code.
    
    On an i386 defconfig (the x86#testing one), the size of vmlinux hardly
    changes with this applied. I have observed only four places where this
    optimization avoids a call into find_next_bit:
    
    In the functions return_unused_surplus_pages, alloc_fresh_huge_page,
    and adjust_pool_surplus, this patch avoids a call for a 1-bit bitmap.
    In __next_cpu a call is avoided for a 32-bit bitmap. That's it.
    
    On x86_64, 52 locations are optimized with a minimal increase in
    code size:
    
    Current #testing defconfig:
            146 x bsf, 27 x find_next_*bit
       text    data     bss     dec     hex filename
       5392637  846592  724424 6963653  6a41c5 vmlinux
    
    After removing the x86_64 specific optimization for find_next_*bit:
            94 x bsf, 79 x find_next_*bit
       text    data     bss     dec     hex filename
       5392358  846592  724424 6963374  6a40ae vmlinux
    
    After this patch (making the optimization generic):
            146 x bsf, 27 x find_next_*bit
       text    data     bss     dec     hex filename
       5392396  846592  724424 6963412  6a40d4 vmlinux
    
    [ tglx@linutronix.de: build fixes ]
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
index 72a51e5a12ef..1914e9742512 100644
--- a/include/asm-generic/bitops/find.h
+++ b/include/asm-generic/bitops/find.h
@@ -1,11 +1,13 @@
 #ifndef _ASM_GENERIC_BITOPS_FIND_H_
 #define _ASM_GENERIC_BITOPS_FIND_H_
 
+#ifndef CONFIG_GENERIC_FIND_NEXT_BIT
 extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
 		size, unsigned long offset);
 
 extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
 		long size, unsigned long offset);
+#endif
 
 #define find_first_bit(addr, size) find_next_bit((addr), (size), 0)
 #define find_first_zero_bit(addr, size) find_next_zero_bit((addr), (size), 0)

commit c7f612cdf091def01454e7e132c7d7a3f419fbc4
Author: Akinobu Mita <mita@miraclelinux.com>
Date:   Sun Mar 26 01:39:11 2006 -0800

    [PATCH] bitops: generic find_{next,first}{,_zero}_bit()
    
    This patch introduces the C-language equivalents of the functions below:
    
    unsigned logn find_next_bit(const unsigned long *addr, unsigned long size,
                                unsigned long offset);
    unsigned long find_next_zero_bit(const unsigned long *addr, unsigned long size,
                                     unsigned long offset);
    unsigned long find_first_zero_bit(const unsigned long *addr,
                                      unsigned long size);
    unsigned long find_first_bit(const unsigned long *addr, unsigned long size);
    
    In include/asm-generic/bitops/find.h
    
    This code largely copied from: arch/powerpc/lib/bitops.c
    
    Signed-off-by: Akinobu Mita <mita@miraclelinux.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/include/asm-generic/bitops/find.h b/include/asm-generic/bitops/find.h
new file mode 100644
index 000000000000..72a51e5a12ef
--- /dev/null
+++ b/include/asm-generic/bitops/find.h
@@ -0,0 +1,13 @@
+#ifndef _ASM_GENERIC_BITOPS_FIND_H_
+#define _ASM_GENERIC_BITOPS_FIND_H_
+
+extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
+		size, unsigned long offset);
+
+extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
+		long size, unsigned long offset);
+
+#define find_first_bit(addr, size) find_next_bit((addr), (size), 0)
+#define find_first_zero_bit(addr, size) find_next_zero_bit((addr), (size), 0)
+
+#endif /*_ASM_GENERIC_BITOPS_FIND_H_ */
