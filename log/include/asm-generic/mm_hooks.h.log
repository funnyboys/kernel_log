commit 42222eae17f7c930833dfda7896ef280879de94a
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Thu Jan 23 10:41:16 2020 -0800

    mm: remove arch_bprm_mm_init() hook
    
    From: Dave Hansen <dave.hansen@linux.intel.com>
    
    MPX is being removed from the kernel due to a lack of support
    in the toolchain going forward (gcc).
    
    arch_bprm_mm_init() is used at execve() time.  The only non-stub
    implementation is on x86 for MPX.  Remove the hook entirely from
    all architectures and generic code.
    
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: x86@kernel.org
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-arch@vger.kernel.org
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Anton Ivanov <anton.ivanov@cambridgegreys.com>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index 6736ed2f632b..4dbb177d1150 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -22,11 +22,6 @@ static inline void arch_unmap(struct mm_struct *mm,
 {
 }
 
-static inline void arch_bprm_mm_init(struct mm_struct *mm,
-				     struct vm_area_struct *vma)
-{
-}
-
 static inline bool arch_vma_access_permitted(struct vm_area_struct *vma,
 		bool write, bool execute, bool foreign)
 {

commit 5a28fc94c9143db766d1ba5480cae82d856ad080
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Apr 19 12:47:47 2019 -0700

    x86/mpx, mm/core: Fix recursive munmap() corruption
    
    This is a bit of a mess, to put it mildly.  But, it's a bug
    that only seems to have showed up in 4.20 but wasn't noticed
    until now, because nobody uses MPX.
    
    MPX has the arch_unmap() hook inside of munmap() because MPX
    uses bounds tables that protect other areas of memory.  When
    memory is unmapped, there is also a need to unmap the MPX
    bounds tables.  Barring this, unused bounds tables can eat 80%
    of the address space.
    
    But, the recursive do_munmap() that gets called vi arch_unmap()
    wreaks havoc with __do_munmap()'s state.  It can result in
    freeing populated page tables, accessing bogus VMA state,
    double-freed VMAs and more.
    
    See the "long story" further below for the gory details.
    
    To fix this, call arch_unmap() before __do_unmap() has a chance
    to do anything meaningful.  Also, remove the 'vma' argument
    and force the MPX code to do its own, independent VMA lookup.
    
    == UML / unicore32 impact ==
    
    Remove unused 'vma' argument to arch_unmap().  No functional
    change.
    
    I compile tested this on UML but not unicore32.
    
    == powerpc impact ==
    
    powerpc uses arch_unmap() well to watch for munmap() on the
    VDSO and zeroes out 'current->mm->context.vdso_base'.  Moving
    arch_unmap() makes this happen earlier in __do_munmap().  But,
    'vdso_base' seems to only be used in perf and in the signal
    delivery that happens near the return to userspace.  I can not
    find any likely impact to powerpc, other than the zeroing
    happening a little earlier.
    
    powerpc does not use the 'vma' argument and is unaffected by
    its removal.
    
    I compile-tested a 64-bit powerpc defconfig.
    
    == x86 impact ==
    
    For the common success case this is functionally identical to
    what was there before.  For the munmap() failure case, it's
    possible that some MPX tables will be zapped for memory that
    continues to be in use.  But, this is an extraordinarily
    unlikely scenario and the harm would be that MPX provides no
    protection since the bounds table got reset (zeroed).
    
    I can't imagine anyone doing this:
    
            ptr = mmap();
            // use ptr
            ret = munmap(ptr);
            if (ret)
                    // oh, there was an error, I'll
                    // keep using ptr.
    
    Because if you're doing munmap(), you are *done* with the
    memory.  There's probably no good data in there _anyway_.
    
    This passes the original reproducer from Richard Biener as
    well as the existing mpx selftests/.
    
    The long story:
    
    munmap() has a couple of pieces:
    
     1. Find the affected VMA(s)
     2. Split the start/end one(s) if neceesary
     3. Pull the VMAs out of the rbtree
     4. Actually zap the memory via unmap_region(), including
        freeing page tables (or queueing them to be freed).
     5. Fix up some of the accounting (like fput()) and actually
        free the VMA itself.
    
    This specific ordering was actually introduced by:
    
      dd2283f2605e ("mm: mmap: zap pages with read mmap_sem in munmap")
    
    during the 4.20 merge window.  The previous __do_munmap() code
    was actually safe because the only thing after arch_unmap() was
    remove_vma_list().  arch_unmap() could not see 'vma' in the
    rbtree because it was detached, so it is not even capable of
    doing operations unsafe for remove_vma_list()'s use of 'vma'.
    
    Richard Biener reported a test that shows this in dmesg:
    
      [1216548.787498] BUG: Bad rss-counter state mm:0000000017ce560b idx:1 val:551
      [1216548.787500] BUG: non-zero pgtables_bytes on freeing mm: 24576
    
    What triggered this was the recursive do_munmap() called via
    arch_unmap().  It was freeing page tables that has not been
    properly zapped.
    
    But, the problem was bigger than this.  For one, arch_unmap()
    can free VMAs.  But, the calling __do_munmap() has variables
    that *point* to VMAs and obviously can't handle them just
    getting freed while the pointer is still in use.
    
    I tried a couple of things here.  First, I tried to fix the page
    table freeing problem in isolation, but I then found the VMA
    issue.  I also tried having the MPX code return a flag if it
    modified the rbtree which would force __do_munmap() to re-walk
    to restart.  That spiralled out of control in complexity pretty
    fast.
    
    Just moving arch_unmap() and accepting that the bonkers failure
    case might eat some bounds tables seems like the simplest viable
    fix.
    
    This was also reported in the following kernel bugzilla entry:
    
      https://bugzilla.kernel.org/show_bug.cgi?id=203123
    
    There are some reports that this commit triggered this bug:
    
      dd2283f2605 ("mm: mmap: zap pages with read mmap_sem in munmap")
    
    While that commit certainly made the issues easier to hit, I believe
    the fundamental issue has been with us as long as MPX itself, thus
    the Fixes: tag below is for one of the original MPX commits.
    
    [ mingo: Minor edits to the changelog and the patch. ]
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Reported-by: H.J. Lu <hjl.tools@gmail.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Yang Shi <yang.shi@linux.alibaba.com>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Anton Ivanov <anton.ivanov@cambridgegreys.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-mm@kvack.org
    Cc: linux-um@lists.infradead.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: stable@vger.kernel.org
    Fixes: dd2283f2605e ("mm: mmap: zap pages with read mmap_sem in munmap")
    Link: http://lkml.kernel.org/r/20190419194747.5E1AD6DC@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index 8ac4e68a12f0..6736ed2f632b 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -18,7 +18,6 @@ static inline void arch_exit_mmap(struct mm_struct *mm)
 }
 
 static inline void arch_unmap(struct mm_struct *mm,
-			struct vm_area_struct *vma,
 			unsigned long start, unsigned long end)
 {
 }

commit c10e83f598d08046dd1ebc8360d4bb12d802d51b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 14 12:27:29 2017 +0100

    arch, mm: Allow arch_dup_mmap() to fail
    
    In order to sanitize the LDT initialization on x86 arch_dup_mmap() must be
    allowed to fail. Fix up all instances.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirsky <luto@kernel.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: dan.j.williams@intel.com
    Cc: hughd@google.com
    Cc: keescook@google.com
    Cc: kirill.shutemov@linux.intel.com
    Cc: linux-mm@kvack.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index ea189d88a3cc..8ac4e68a12f0 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -7,9 +7,10 @@
 #ifndef _ASM_GENERIC_MM_HOOKS_H
 #define _ASM_GENERIC_MM_HOOKS_H
 
-static inline void arch_dup_mmap(struct mm_struct *oldmm,
-				 struct mm_struct *mm)
+static inline int arch_dup_mmap(struct mm_struct *oldmm,
+				struct mm_struct *mm)
 {
+	return 0;
 }
 
 static inline void arch_exit_mmap(struct mm_struct *mm)

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index 41e5b6784b97..ea189d88a3cc 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Define generic no-op hooks for arch_dup_mmap, arch_exit_mmap
  * and arch_unmap to be included in asm-FOO/mmu_context.h for any

commit 9a804fecee232e71b47ac37d62fd3d5d66b08b91
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Thu Mar 16 18:26:49 2017 +0300

    mm/gup: Drop the arch_pte_access_permitted() MMU callback
    
    The only arch that defines it to something meaningful is x86.
    But x86 doesn't use the generic GUP_fast() implementation -- the
    only place where the callback is called.
    
    Let's drop it.
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Aneesh Kumar K . V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Dann Frazier <dann.frazier@canonical.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Steve Capper <steve.capper@linaro.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20170316152655.37789-2-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index cc5d9a1405df..41e5b6784b97 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -32,10 +32,4 @@ static inline bool arch_vma_access_permitted(struct vm_area_struct *vma,
 	/* by default, allow everything */
 	return true;
 }
-
-static inline bool arch_pte_access_permitted(pte_t pte, bool write)
-{
-	/* by default, allow everything */
-	return true;
-}
 #endif	/* _ASM_GENERIC_MM_HOOKS_H */

commit d61172b4b695b821388cdb6088a41d431bcbb93b
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Feb 12 13:02:24 2016 -0800

    mm/core, x86/mm/pkeys: Differentiate instruction fetches
    
    As discussed earlier, we attempt to enforce protection keys in
    software.
    
    However, the code checks all faults to ensure that they are not
    violating protection key permissions.  It was assumed that all
    faults are either write faults where we check PKRU[key].WD (write
    disable) or read faults where we check the AD (access disable)
    bit.
    
    But, there is a third category of faults for protection keys:
    instruction faults.  Instruction faults never run afoul of
    protection keys because they do not affect instruction fetches.
    
    So, plumb the PF_INSTR bit down in to the
    arch_vma_access_permitted() function where we do the protection
    key checks.
    
    We also add a new FAULT_FLAG_INSTRUCTION.  This is because
    handle_mm_fault() is not passed the architecture-specific
    error_code where we keep PF_INSTR, so we need to encode the
    instruction fetch information in to the arch-generic fault
    flags.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20160212210224.96928009@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index d5c9633bd955..cc5d9a1405df 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -27,7 +27,7 @@ static inline void arch_bprm_mm_init(struct mm_struct *mm,
 }
 
 static inline bool arch_vma_access_permitted(struct vm_area_struct *vma,
-		bool write, bool foreign)
+		bool write, bool execute, bool foreign)
 {
 	/* by default, allow everything */
 	return true;

commit 1b2ee1266ea647713dbaf44825967c180dfc8d76
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Feb 12 13:02:21 2016 -0800

    mm/core: Do not enforce PKEY permissions on remote mm access
    
    We try to enforce protection keys in software the same way that we
    do in hardware.  (See long example below).
    
    But, we only want to do this when accessing our *own* process's
    memory.  If GDB set PKRU[6].AD=1 (disable access to PKEY 6), then
    tried to PTRACE_POKE a target process which just happened to have
    some mprotect_pkey(pkey=6) memory, we do *not* want to deny the
    debugger access to that memory.  PKRU is fundamentally a
    thread-local structure and we do not want to enforce it on access
    to _another_ thread's data.
    
    This gets especially tricky when we have workqueues or other
    delayed-work mechanisms that might run in a random process's context.
    We can check that we only enforce pkeys when operating on our *own* mm,
    but delayed work gets performed when a random user context is active.
    We might end up with a situation where a delayed-work gup fails when
    running randomly under its "own" task but succeeds when running under
    another process.  We want to avoid that.
    
    To avoid that, we use the new GUP flag: FOLL_REMOTE and add a
    fault flag: FAULT_FLAG_REMOTE.  They indicate that we are
    walking an mm which is not guranteed to be the same as
    current->mm and should not be subject to protection key
    enforcement.
    
    Thanks to Jerome Glisse for pointing out this scenario.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Alexey Kardashevskiy <aik@ozlabs.ru>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <dchinner@redhat.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Gibson <david@gibson.dropbear.id.au>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Dominik Dingel <dingel@linux.vnet.ibm.com>
    Cc: Dominik Vogt <vogt@linux.vnet.ibm.com>
    Cc: Eric B Munson <emunson@akamai.com>
    Cc: Geliang Tang <geliangtang@163.com>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jason Low <jason.low2@hp.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Mikulas Patocka <mpatocka@redhat.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: Shachar Raindel <raindel@mellanox.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Xie XiuQi <xiexiuqi@huawei.com>
    Cc: iommu@lists.linux-foundation.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Cc: linux-s390@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index c1fc5af3c384..d5c9633bd955 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -26,7 +26,8 @@ static inline void arch_bprm_mm_init(struct mm_struct *mm,
 {
 }
 
-static inline bool arch_vma_access_permitted(struct vm_area_struct *vma, bool write)
+static inline bool arch_vma_access_permitted(struct vm_area_struct *vma,
+		bool write, bool foreign)
 {
 	/* by default, allow everything */
 	return true;

commit 33a709b25a760b91184bb335cf7d7c32b8123013
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Feb 12 13:02:19 2016 -0800

    mm/gup, x86/mm/pkeys: Check VMAs and PTEs for protection keys
    
    Today, for normal faults and page table walks, we check the VMA
    and/or PTE to ensure that it is compatible with the action.  For
    instance, if we get a write fault on a non-writeable VMA, we
    SIGSEGV.
    
    We try to do the same thing for protection keys.  Basically, we
    try to make sure that if a user does this:
    
            mprotect(ptr, size, PROT_NONE);
            *ptr = foo;
    
    they see the same effects with protection keys when they do this:
    
            mprotect(ptr, size, PROT_READ|PROT_WRITE);
            set_pkey(ptr, size, 4);
            wrpkru(0xffffff3f); // access disable pkey 4
            *ptr = foo;
    
    The state to do that checking is in the VMA, but we also
    sometimes have to do it on the page tables only, like when doing
    a get_user_pages_fast() where we have no VMA.
    
    We add two functions and expose them to generic code:
    
            arch_pte_access_permitted(pte_flags, write)
            arch_vma_access_permitted(vma, write)
    
    These are, of course, backed up in x86 arch code with checks
    against the PTE or VMA's protection key.
    
    But, there are also cases where we do not want to respect
    protection keys.  When we ptrace(), for instance, we do not want
    to apply the tracer's PKRU permissions to the PTEs from the
    process being traced.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Alexey Kardashevskiy <aik@ozlabs.ru>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: David Gibson <david@gibson.dropbear.id.au>
    Cc: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Cc: David Vrabel <david.vrabel@citrix.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Dominik Dingel <dingel@linux.vnet.ibm.com>
    Cc: Dominik Vogt <vogt@linux.vnet.ibm.com>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Low <jason.low2@hp.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Mikulas Patocka <mpatocka@redhat.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: Shachar Raindel <raindel@mellanox.com>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Toshi Kani <toshi.kani@hpe.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Cc: linux-s390@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Link: http://lkml.kernel.org/r/20160212210219.14D5D715@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index 866aa461efa5..c1fc5af3c384 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -26,4 +26,15 @@ static inline void arch_bprm_mm_init(struct mm_struct *mm,
 {
 }
 
+static inline bool arch_vma_access_permitted(struct vm_area_struct *vma, bool write)
+{
+	/* by default, allow everything */
+	return true;
+}
+
+static inline bool arch_pte_access_permitted(pte_t pte, bool write)
+{
+	/* by default, allow everything */
+	return true;
+}
 #endif	/* _ASM_GENERIC_MM_HOOKS_H */

commit 62e88b1c00de9cb30d937841ed5debed871070b8
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Tue Nov 18 10:23:50 2014 -0800

    mm: Make arch_unmap()/bprm_mm_init() available to all architectures
    
    The x86 MPX patch set calls arch_unmap() and arch_bprm_mm_init()
    from fs/exec.c, so we need at least a stub for them in all
    architectures.  They are only called under an #ifdef for
    CONFIG_MMU=y, so we can at least restict this to architectures
    with MMU support.
    
    blackfin/c6x have no MMU support, so do not call arch_unmap().
    They also do not include mm_hooks.h or mmu_context.h at all and
    do not need to be touched.
    
    s390, um and unicore32 do not use asm-generic/mm_hooks.h, so got
    their own arch_unmap() versions.  (I also moved um's
    arch_dup_mmap() to be closer to the other mm_hooks.h functions).
    
    xtensa only includes mm_hooks when MMU=y, which should be fine
    since arch_unmap() is called only from MMU=y code.
    
    For the rest, we use the stub copies of these functions in
    asm-generic/mm_hook.h.
    
    I cross compiled defconfigs for cris (to check NOMMU) and s390
    to make sure that this works.  I also checked a 64-bit build
    of UML and all my normal x86 builds including PARAVIRT on and
    off.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: linux-arch@vger.kernel.org
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/20141118182350.8B4AA2C2@viggo.jf.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
index 67dea8123683..866aa461efa5 100644
--- a/include/asm-generic/mm_hooks.h
+++ b/include/asm-generic/mm_hooks.h
@@ -1,7 +1,7 @@
 /*
- * Define generic no-op hooks for arch_dup_mmap and arch_exit_mmap, to
- * be included in asm-FOO/mmu_context.h for any arch FOO which doesn't
- * need to hook these.
+ * Define generic no-op hooks for arch_dup_mmap, arch_exit_mmap
+ * and arch_unmap to be included in asm-FOO/mmu_context.h for any
+ * arch FOO which doesn't need to hook these.
  */
 #ifndef _ASM_GENERIC_MM_HOOKS_H
 #define _ASM_GENERIC_MM_HOOKS_H
@@ -15,4 +15,15 @@ static inline void arch_exit_mmap(struct mm_struct *mm)
 {
 }
 
+static inline void arch_unmap(struct mm_struct *mm,
+			struct vm_area_struct *vma,
+			unsigned long start, unsigned long end)
+{
+}
+
+static inline void arch_bprm_mm_init(struct mm_struct *mm,
+				     struct vm_area_struct *vma)
+{
+}
+
 #endif	/* _ASM_GENERIC_MM_HOOKS_H */

commit d6dd61c831226f9cd7750885da04d360d6455101
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed May 2 19:27:14 2007 +0200

    [PATCH] x86: PARAVIRT: add hooks to intercept mm creation and destruction
    
    Add hooks to allow a paravirt implementation to track the lifetime of
    an mm.  Paravirtualization requires three hooks, but only two are
    needed in common code.  They are:
    
    arch_dup_mmap, which is called when a new mmap is created at fork
    
    arch_exit_mmap, which is called when the last process reference to an
      mm is dropped, which typically happens on exit and exec.
    
    The third hook is activate_mm, which is called from the arch-specific
    activate_mm() macro/function, and so doesn't need stub versions for
    other architectures.  It's called when an mm is first used.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy@xensource.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Cc: linux-arch@vger.kernel.org
    Cc: James Bottomley <James.Bottomley@SteelEye.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/include/asm-generic/mm_hooks.h b/include/asm-generic/mm_hooks.h
new file mode 100644
index 000000000000..67dea8123683
--- /dev/null
+++ b/include/asm-generic/mm_hooks.h
@@ -0,0 +1,18 @@
+/*
+ * Define generic no-op hooks for arch_dup_mmap and arch_exit_mmap, to
+ * be included in asm-FOO/mmu_context.h for any arch FOO which doesn't
+ * need to hook these.
+ */
+#ifndef _ASM_GENERIC_MM_HOOKS_H
+#define _ASM_GENERIC_MM_HOOKS_H
+
+static inline void arch_dup_mmap(struct mm_struct *oldmm,
+				 struct mm_struct *mm)
+{
+}
+
+static inline void arch_exit_mmap(struct mm_struct *mm)
+{
+}
+
+#endif	/* _ASM_GENERIC_MM_HOOKS_H */
