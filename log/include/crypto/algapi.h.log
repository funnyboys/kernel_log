commit ec6e2bf33b54cc3351bd702452e5d016b8f9d2f4
Author: Iuliana Prodan <iuliana.prodan@nxp.com>
Date:   Tue Apr 28 18:49:03 2020 +0300

    crypto: algapi - create function to add request in front of queue
    
    Add crypto_enqueue_request_head function that enqueues a
    request in front of queue.
    This will be used in crypto-engine, on error path. In case a request
    was not executed by hardware, enqueue it back in front of queue (to
    keep the order of requests).
    
    Signed-off-by: Iuliana Prodan <iuliana.prodan@nxp.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index e115f9215ed5..00a9cf98debe 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -125,6 +125,8 @@ int crypto_inst_setname(struct crypto_instance *inst, const char *name,
 void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen);
 int crypto_enqueue_request(struct crypto_queue *queue,
 			   struct crypto_async_request *request);
+void crypto_enqueue_request_head(struct crypto_queue *queue,
+				 struct crypto_async_request *request);
 struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue);
 static inline unsigned int crypto_queue_len(struct crypto_queue *queue)
 {

commit a24a1fd731274ebbca873000e2c7fbe8224ae4c8
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jan 2 20:04:39 2020 -0800

    crypto: algapi - remove crypto_template::{alloc,free}()
    
    Now that all templates provide a ->create() method which creates an
    instance, installs a strongly-typed ->free() method directly to it, and
    registers it, the older ->alloc() and ->free() methods in
    'struct crypto_template' are no longer used.  Remove them.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index c16c50f8dac1..e115f9215ed5 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -63,8 +63,6 @@ struct crypto_template {
 	struct hlist_head instances;
 	struct module *module;
 
-	struct crypto_instance *(*alloc)(struct rtattr **tb);
-	void (*free)(struct crypto_instance *inst);
 	int (*create)(struct crypto_template *tmpl, struct rtattr **tb);
 
 	char name[CRYPTO_MAX_ALG_NAME];

commit aed11cf57ddb24aa97ca3b55c9e26c37759c4baa
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jan 2 19:59:08 2020 -0800

    crypto: algapi - fold crypto_init_spawn() into crypto_grab_spawn()
    
    Now that crypto_init_spawn() is only called by crypto_grab_spawn(),
    simplify things by moving its functionality into crypto_grab_spawn().
    
    In the process of doing this, also be more consistent about when the
    spawn and instance are updated, and remove the crypto_spawn::dropref
    flag since now it's always set.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 224c72743cce..c16c50f8dac1 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -82,7 +82,6 @@ struct crypto_spawn {
 	const struct crypto_type *frontend;
 	u32 mask;
 	bool dead;
-	bool dropref;
 	bool registered;
 };
 
@@ -111,8 +110,6 @@ int crypto_register_instance(struct crypto_template *tmpl,
 			     struct crypto_instance *inst);
 void crypto_unregister_instance(struct crypto_instance *inst);
 
-int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
-		      struct crypto_instance *inst, u32 mask);
 int crypto_grab_spawn(struct crypto_spawn *spawn, struct crypto_instance *inst,
 		      const char *name, u32 type, u32 mask);
 void crypto_drop_spawn(struct crypto_spawn *spawn);

commit 629f1afc15ee8f34ec67bef0c33b9bccca7eeecc
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jan 2 19:59:06 2020 -0800

    crypto: algapi - remove obsoleted instance creation helpers
    
    Remove lots of helper functions that were previously used for
    instantiating crypto templates, but are now unused:
    
    - crypto_get_attr_alg() and similar functions looked up an inner
      algorithm directly from a template parameter.  These were replaced
      with getting the algorithm's name, then calling crypto_grab_*().
    
    - crypto_init_spawn2() and similar functions initialized a spawn, given
      an algorithm.  Similarly, these were replaced with crypto_grab_*().
    
    - crypto_alloc_instance() and similar functions allocated an instance
      with a single spawn, given the inner algorithm.  These aren't useful
      anymore since crypto_grab_*() need the instance allocated first.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index bbf85a854a42..224c72743cce 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -113,12 +113,8 @@ void crypto_unregister_instance(struct crypto_instance *inst);
 
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		      struct crypto_instance *inst, u32 mask);
-int crypto_init_spawn2(struct crypto_spawn *spawn, struct crypto_alg *alg,
-		       struct crypto_instance *inst,
-		       const struct crypto_type *frontend);
 int crypto_grab_spawn(struct crypto_spawn *spawn, struct crypto_instance *inst,
 		      const char *name, u32 type, u32 mask);
-
 void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 				    u32 mask);
@@ -127,21 +123,9 @@ void *crypto_spawn_tfm2(struct crypto_spawn *spawn);
 struct crypto_attr_type *crypto_get_attr_type(struct rtattr **tb);
 int crypto_check_attr_type(struct rtattr **tb, u32 type);
 const char *crypto_attr_alg_name(struct rtattr *rta);
-struct crypto_alg *crypto_attr_alg2(struct rtattr *rta,
-				    const struct crypto_type *frontend,
-				    u32 type, u32 mask);
-
-static inline struct crypto_alg *crypto_attr_alg(struct rtattr *rta,
-						 u32 type, u32 mask)
-{
-	return crypto_attr_alg2(rta, NULL, type, mask);
-}
-
 int crypto_attr_u32(struct rtattr *rta, u32 *num);
 int crypto_inst_setname(struct crypto_instance *inst, const char *name,
 			struct crypto_alg *alg);
-void *crypto_alloc_instance(const char *name, struct crypto_alg *alg,
-			    unsigned int head);
 
 void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen);
 int crypto_enqueue_request(struct crypto_queue *queue,
@@ -254,12 +238,6 @@ static inline struct crypto_async_request *crypto_get_backlog(
 	       container_of(queue->backlog, struct crypto_async_request, list);
 }
 
-static inline struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb,
-						     u32 type, u32 mask)
-{
-	return crypto_attr_alg(tb[1], type, mask);
-}
-
 static inline int crypto_requires_off(u32 type, u32 mask, u32 off)
 {
 	return (type ^ off) & mask & off;

commit d5ed3b65f7012a6592809f7f928f3e3660df8fd9
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jan 2 19:59:05 2020 -0800

    crypto: cipher - make crypto_spawn_cipher() take a crypto_cipher_spawn
    
    Now that all users of single-block cipher spawns have been converted to
    use 'struct crypto_cipher_spawn' rather than the less specifically typed
    'struct crypto_spawn', make crypto_spawn_cipher() take a pointer to a
    'struct crypto_cipher_spawn' rather than a 'struct crypto_spawn'.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 7705387f9459..bbf85a854a42 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -234,12 +234,12 @@ static inline struct crypto_alg *crypto_spawn_cipher_alg(
 }
 
 static inline struct crypto_cipher *crypto_spawn_cipher(
-	struct crypto_spawn *spawn)
+	struct crypto_cipher_spawn *spawn)
 {
 	u32 type = CRYPTO_ALG_TYPE_CIPHER;
 	u32 mask = CRYPTO_ALG_TYPE_MASK;
 
-	return __crypto_cipher_cast(crypto_spawn_tfm(spawn, type, mask));
+	return __crypto_cipher_cast(crypto_spawn_tfm(&spawn->base, type, mask));
 }
 
 static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)

commit 0764ac28763fdb533809090005956fcd3123fb60
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jan 2 19:58:51 2020 -0800

    crypto: cipher - introduce crypto_cipher_spawn and crypto_grab_cipher()
    
    Currently, "cipher" (single-block cipher) spawns are usually initialized
    by using crypto_get_attr_alg() to look up the algorithm, then calling
    crypto_init_spawn().  In one case, crypto_grab_spawn() is used directly.
    
    The former way is different from how skcipher, aead, and akcipher spawns
    are initialized (they use crypto_grab_*()), and for no good reason.
    This difference introduces unnecessary complexity.
    
    The crypto_grab_*() functions used to have some problems, like not
    holding a reference to the algorithm and requiring the caller to
    initialize spawn->base.inst.  But those problems are fixed now.
    
    Also, the cipher spawns are not strongly typed; e.g., the API requires
    that the user manually specify the flags CRYPTO_ALG_TYPE_CIPHER and
    CRYPTO_ALG_TYPE_MASK.  Though the "cipher" algorithm type itself isn't
    yet strongly typed, we can start by making the spawns strongly typed.
    
    So, let's introduce a new 'struct crypto_cipher_spawn', and functions
    crypto_grab_cipher() and crypto_drop_cipher() to grab and drop them.
    
    Later patches will convert all cipher spawns to use these, then make
    crypto_spawn_cipher() take 'struct crypto_cipher_spawn' as well, instead
    of a bare 'struct crypto_spawn' as it currently does.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 2779c8d34ba9..7705387f9459 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -208,6 +208,31 @@ static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 	return inst->__ctx;
 }
 
+struct crypto_cipher_spawn {
+	struct crypto_spawn base;
+};
+
+static inline int crypto_grab_cipher(struct crypto_cipher_spawn *spawn,
+				     struct crypto_instance *inst,
+				     const char *name, u32 type, u32 mask)
+{
+	type &= ~CRYPTO_ALG_TYPE_MASK;
+	type |= CRYPTO_ALG_TYPE_CIPHER;
+	mask |= CRYPTO_ALG_TYPE_MASK;
+	return crypto_grab_spawn(&spawn->base, inst, name, type, mask);
+}
+
+static inline void crypto_drop_cipher(struct crypto_cipher_spawn *spawn)
+{
+	crypto_drop_spawn(&spawn->base);
+}
+
+static inline struct crypto_alg *crypto_spawn_cipher_alg(
+	struct crypto_cipher_spawn *spawn)
+{
+	return spawn->base.alg;
+}
+
 static inline struct crypto_cipher *crypto_spawn_cipher(
 	struct crypto_spawn *spawn)
 {

commit de95c9574108ec304083ed574304ab3b60b4167c
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jan 2 19:58:48 2020 -0800

    crypto: algapi - pass instance to crypto_grab_spawn()
    
    Currently, crypto_spawn::inst is first used temporarily to pass the
    instance to crypto_grab_spawn().  Then crypto_init_spawn() overwrites it
    with crypto_spawn::next, which shares the same union.  Finally,
    crypto_spawn::inst is set again when the instance is registered.
    
    Make this less convoluted by just passing the instance as an argument to
    crypto_grab_spawn() instead.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 5022cada4fc6..2779c8d34ba9 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -116,20 +116,14 @@ int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 int crypto_init_spawn2(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		       struct crypto_instance *inst,
 		       const struct crypto_type *frontend);
-int crypto_grab_spawn(struct crypto_spawn *spawn, const char *name,
-		      u32 type, u32 mask);
+int crypto_grab_spawn(struct crypto_spawn *spawn, struct crypto_instance *inst,
+		      const char *name, u32 type, u32 mask);
 
 void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 				    u32 mask);
 void *crypto_spawn_tfm2(struct crypto_spawn *spawn);
 
-static inline void crypto_set_spawn(struct crypto_spawn *spawn,
-				    struct crypto_instance *inst)
-{
-	spawn->inst = inst;
-}
-
 struct crypto_attr_type *crypto_get_attr_type(struct rtattr **tb);
 int crypto_check_attr_type(struct rtattr **tb, u32 type);
 const char *crypto_attr_alg_name(struct rtattr *rta);

commit 5f567fffaae995dce3498e175e47d5a779fb0270
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Dec 18 15:53:01 2019 +0800

    crypto: api - Retain alg refcount in crypto_grab_spawn
    
    This patch changes crypto_grab_spawn to retain the reference count
    on the algorithm.  This is because the caller needs to access the
    algorithm parameters and without the reference count the algorithm
    can be freed at any time.
    
    The reference count will be subsequently dropped by the crypto API
    once the instance has been registered.  The helper crypto_drop_spawn
    will also conditionally drop the reference count depending on whether
    it has been registered.
    
    Note that the code is actually added to crypto_init_spawn.  However,
    unless the caller activates this by setting spawn->dropref beforehand
    then nothing happens.  The only caller that sets dropref is currently
    crypto_grab_spawn.
    
    Once all legacy users of crypto_init_spawn disappear, then we can
    kill the dropref flag.
    
    Internally each instance will maintain a list of its spawns prior
    to registration.  This memory used by this list is shared with
    other fields that are only used after registration.  In order for
    this to work a new flag spawn->registered is added to indicate
    whether spawn->inst can be used.
    
    Fixes: d6ef2f198d4c ("crypto: api - Add crypto_grab_spawn primitive")
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 25661b4650ec..5022cada4fc6 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -47,7 +47,13 @@ struct crypto_instance {
 	struct crypto_alg alg;
 
 	struct crypto_template *tmpl;
-	struct hlist_node list;
+
+	union {
+		/* Node in list of instances after registration. */
+		struct hlist_node list;
+		/* List of attached spawns before registration. */
+		struct crypto_spawn *spawns;
+	};
 
 	void *__ctx[] CRYPTO_MINALIGN_ATTR;
 };
@@ -67,10 +73,17 @@ struct crypto_template {
 struct crypto_spawn {
 	struct list_head list;
 	struct crypto_alg *alg;
-	struct crypto_instance *inst;
+	union {
+		/* Back pointer to instance after registration.*/
+		struct crypto_instance *inst;
+		/* Spawn list pointer prior to registration. */
+		struct crypto_spawn *next;
+	};
 	const struct crypto_type *frontend;
 	u32 mask;
 	bool dead;
+	bool dropref;
+	bool registered;
 };
 
 struct crypto_queue {

commit c6d633a927499f35a06455a960ad6b5a59c87c2c
Author: Eric Biggers <ebiggers@google.com>
Date:   Sun Dec 15 15:51:19 2019 -0800

    crypto: algapi - make unregistration functions return void
    
    Some of the algorithm unregistration functions return -ENOENT when asked
    to unregister a non-registered algorithm, while others always return 0
    or always return void.  But no users check the return value, except for
    two of the bulk unregistration functions which print a message on error
    but still always return 0 to their caller, and crypto_del_alg() which
    calls crypto_unregister_instance() which always returns 0.
    
    Since unregistering a non-registered algorithm is always a kernel bug
    but there isn't anything callers should do to handle this situation at
    runtime, let's simplify things by making all the unregistration
    functions return void, and moving the error message into
    crypto_unregister_alg() and upgrading it to a WARN().
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 771a295ac755..25661b4650ec 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -96,7 +96,7 @@ struct crypto_template *crypto_lookup_template(const char *name);
 
 int crypto_register_instance(struct crypto_template *tmpl,
 			     struct crypto_instance *inst);
-int crypto_unregister_instance(struct crypto_instance *inst);
+void crypto_unregister_instance(struct crypto_instance *inst);
 
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		      struct crypto_instance *inst, u32 mask);

commit 4f87ee118d16b4b2116a477229573ed5003b0d78
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Dec 7 22:15:17 2019 +0800

    crypto: api - Do not zap spawn->alg
    
    Currently when a spawn is removed we will zap its alg field.
    This is racy because the spawn could belong to an unregistered
    instance which may dereference the spawn->alg field.
    
    This patch fixes this by keeping spawn->alg constant and instead
    adding a new spawn->dead field to indicate that a spawn is going
    away.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 5cd846defdd6..771a295ac755 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -70,6 +70,7 @@ struct crypto_spawn {
 	struct crypto_instance *inst;
 	const struct crypto_type *frontend;
 	u32 mask;
+	bool dead;
 };
 
 struct crypto_queue {

commit d63007eb954e425f45766482813738f41db9af45
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Sat Nov 9 18:09:53 2019 +0100

    crypto: ablkcipher - remove deprecated and unused ablkcipher support
    
    Now that all users of the deprecated ablkcipher interface have been
    moved to the skcipher interface, ablkcipher is no longer used and
    can be removed.
    
    Reviewed-by: Eric Biggers <ebiggers@kernel.org>
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index cadc5257c612..5cd846defdd6 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -85,25 +85,6 @@ struct scatter_walk {
 	unsigned int offset;
 };
 
-struct ablkcipher_walk {
-	struct {
-		struct page *page;
-		unsigned int offset;
-	} src, dst;
-
-	struct scatter_walk	in;
-	unsigned int		nbytes;
-	struct scatter_walk	out;
-	unsigned int		total;
-	struct list_head	buffers;
-	u8			*iv_buffer;
-	u8			*iv;
-	int			flags;
-	unsigned int		blocksize;
-};
-
-extern const struct crypto_type crypto_ablkcipher_type;
-
 void crypto_mod_put(struct crypto_alg *alg);
 
 int crypto_register_template(struct crypto_template *tmpl);
@@ -202,12 +183,6 @@ static inline void crypto_xor_cpy(u8 *dst, const u8 *src1, const u8 *src2,
 	}
 }
 
-int ablkcipher_walk_done(struct ablkcipher_request *req,
-			 struct ablkcipher_walk *walk, int err);
-int ablkcipher_walk_phys(struct ablkcipher_request *req,
-			 struct ablkcipher_walk *walk);
-void __ablkcipher_walk_complete(struct ablkcipher_walk *walk);
-
 static inline void *crypto_tfm_ctx_aligned(struct crypto_tfm *tfm)
 {
 	return PTR_ALIGN(crypto_tfm_ctx(tfm),
@@ -225,22 +200,6 @@ static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 	return inst->__ctx;
 }
 
-static inline struct ablkcipher_alg *crypto_ablkcipher_alg(
-	struct crypto_ablkcipher *tfm)
-{
-	return &crypto_ablkcipher_tfm(tfm)->__crt_alg->cra_ablkcipher;
-}
-
-static inline void *crypto_ablkcipher_ctx(struct crypto_ablkcipher *tfm)
-{
-	return crypto_tfm_ctx(&tfm->base);
-}
-
-static inline void *crypto_ablkcipher_ctx_aligned(struct crypto_ablkcipher *tfm)
-{
-	return crypto_tfm_ctx_aligned(&tfm->base);
-}
-
 static inline struct crypto_cipher *crypto_spawn_cipher(
 	struct crypto_spawn *spawn)
 {
@@ -255,23 +214,6 @@ static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)
 	return &crypto_cipher_tfm(tfm)->__crt_alg->cra_cipher;
 }
 
-static inline void ablkcipher_walk_init(struct ablkcipher_walk *walk,
-					struct scatterlist *dst,
-					struct scatterlist *src,
-					unsigned int nbytes)
-{
-	walk->in.sg = src;
-	walk->out.sg = dst;
-	walk->total = nbytes;
-	INIT_LIST_HEAD(&walk->buffers);
-}
-
-static inline void ablkcipher_walk_complete(struct ablkcipher_walk *walk)
-{
-	if (unlikely(!list_empty(&walk->buffers)))
-		__ablkcipher_walk_complete(walk);
-}
-
 static inline struct crypto_async_request *crypto_get_backlog(
 	struct crypto_queue *queue)
 {
@@ -279,23 +221,6 @@ static inline struct crypto_async_request *crypto_get_backlog(
 	       container_of(queue->backlog, struct crypto_async_request, list);
 }
 
-static inline int ablkcipher_enqueue_request(struct crypto_queue *queue,
-					     struct ablkcipher_request *request)
-{
-	return crypto_enqueue_request(queue, &request->base);
-}
-
-static inline struct ablkcipher_request *ablkcipher_dequeue_request(
-	struct crypto_queue *queue)
-{
-	return ablkcipher_request_cast(crypto_dequeue_request(queue));
-}
-
-static inline void *ablkcipher_request_ctx(struct ablkcipher_request *req)
-{
-	return req->__ctx;
-}
-
 static inline struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb,
 						     u32 type, u32 mask)
 {

commit c65058b7587fd3d001c57a50285477be521f5350
Author: Eric Biggers <ebiggers@google.com>
Date:   Fri Oct 25 12:41:12 2019 -0700

    crypto: skcipher - remove the "blkcipher" algorithm type
    
    Now that all "blkcipher" algorithms have been converted to "skcipher",
    remove the blkcipher algorithm type.
    
    The skcipher (symmetric key cipher) algorithm type was introduced a few
    years ago to replace both blkcipher and ablkcipher (synchronous and
    asynchronous block cipher).  The advantages of skcipher include:
    
      - A much less confusing name, since none of these algorithm types have
        ever actually been for raw block ciphers, but rather for all
        length-preserving encryption modes including block cipher modes of
        operation, stream ciphers, and other length-preserving modes.
    
      - It unified blkcipher and ablkcipher into a single algorithm type
        which supports both synchronous and asynchronous implementations.
        Note, blkcipher already operated only on scatterlists, so the fact
        that skcipher does too isn't a regression in functionality.
    
      - Better type safety by using struct skcipher_alg, struct
        crypto_skcipher, etc. instead of crypto_alg, crypto_tfm, etc.
    
      - It sometimes simplifies the implementations of algorithms.
    
    Also, the blkcipher API was no longer being tested.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index e5bd302f2c49..cadc5257c612 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -85,36 +85,6 @@ struct scatter_walk {
 	unsigned int offset;
 };
 
-struct blkcipher_walk {
-	union {
-		struct {
-			struct page *page;
-			unsigned long offset;
-		} phys;
-
-		struct {
-			u8 *page;
-			u8 *addr;
-		} virt;
-	} src, dst;
-
-	struct scatter_walk in;
-	unsigned int nbytes;
-
-	struct scatter_walk out;
-	unsigned int total;
-
-	void *page;
-	u8 *buffer;
-	u8 *iv;
-	unsigned int ivsize;
-
-	int flags;
-	unsigned int walk_blocksize;
-	unsigned int cipher_blocksize;
-	unsigned int alignmask;
-};
-
 struct ablkcipher_walk {
 	struct {
 		struct page *page;
@@ -133,7 +103,6 @@ struct ablkcipher_walk {
 };
 
 extern const struct crypto_type crypto_ablkcipher_type;
-extern const struct crypto_type crypto_blkcipher_type;
 
 void crypto_mod_put(struct crypto_alg *alg);
 
@@ -233,20 +202,6 @@ static inline void crypto_xor_cpy(u8 *dst, const u8 *src1, const u8 *src2,
 	}
 }
 
-int blkcipher_walk_done(struct blkcipher_desc *desc,
-			struct blkcipher_walk *walk, int err);
-int blkcipher_walk_virt(struct blkcipher_desc *desc,
-			struct blkcipher_walk *walk);
-int blkcipher_walk_phys(struct blkcipher_desc *desc,
-			struct blkcipher_walk *walk);
-int blkcipher_walk_virt_block(struct blkcipher_desc *desc,
-			      struct blkcipher_walk *walk,
-			      unsigned int blocksize);
-int blkcipher_aead_walk_virt_block(struct blkcipher_desc *desc,
-				   struct blkcipher_walk *walk,
-				   struct crypto_aead *tfm,
-				   unsigned int blocksize);
-
 int ablkcipher_walk_done(struct ablkcipher_request *req,
 			 struct ablkcipher_walk *walk, int err);
 int ablkcipher_walk_phys(struct ablkcipher_request *req,
@@ -286,25 +241,6 @@ static inline void *crypto_ablkcipher_ctx_aligned(struct crypto_ablkcipher *tfm)
 	return crypto_tfm_ctx_aligned(&tfm->base);
 }
 
-static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
-	struct crypto_spawn *spawn)
-{
-	u32 type = CRYPTO_ALG_TYPE_BLKCIPHER;
-	u32 mask = CRYPTO_ALG_TYPE_MASK;
-
-	return __crypto_blkcipher_cast(crypto_spawn_tfm(spawn, type, mask));
-}
-
-static inline void *crypto_blkcipher_ctx(struct crypto_blkcipher *tfm)
-{
-	return crypto_tfm_ctx(&tfm->base);
-}
-
-static inline void *crypto_blkcipher_ctx_aligned(struct crypto_blkcipher *tfm)
-{
-	return crypto_tfm_ctx_aligned(&tfm->base);
-}
-
 static inline struct crypto_cipher *crypto_spawn_cipher(
 	struct crypto_spawn *spawn)
 {
@@ -319,16 +255,6 @@ static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)
 	return &crypto_cipher_tfm(tfm)->__crt_alg->cra_cipher;
 }
 
-static inline void blkcipher_walk_init(struct blkcipher_walk *walk,
-				       struct scatterlist *dst,
-				       struct scatterlist *src,
-				       unsigned int nbytes)
-{
-	walk->in.sg = src;
-	walk->out.sg = dst;
-	walk->total = nbytes;
-}
-
 static inline void ablkcipher_walk_init(struct ablkcipher_walk *walk,
 					struct scatterlist *dst,
 					struct scatterlist *src,

commit f9981bc53825de2c001659d35c870786771f1e90
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jul 26 22:19:07 2019 +0200

    crypto: api - Remove redundant #ifdef in crypto_yield()
    
    While looking at CONFIG_PREEMPT dependencies treewide the #ifdef in
    crypto_yield() matched.
    
    CONFIG_PREEMPT and CONFIG_PREEMPT_VOLUNTARY are mutually exclusive so the
    extra !CONFIG_PREEMPT conditional is redundant.
    
    cond_resched() has only an effect when CONFIG_PREEMPT_VOLUNTARY is set,
    otherwise it's a stub which the compiler optimizes out.
    
    Remove the whole conditional.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-crypto@vger.kernel.org
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index dc1106af95c3..e5bd302f2c49 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -409,10 +409,8 @@ static inline int crypto_memneq(const void *a, const void *b, size_t size)
 
 static inline void crypto_yield(u32 flags)
 {
-#if !defined(CONFIG_PREEMPT) || defined(CONFIG_PREEMPT_VOLUNTARY)
 	if (flags & CRYPTO_TFM_REQ_MAY_SLEEP)
 		cond_resched();
-#endif
 }
 
 int crypto_register_notifier(struct notifier_block *nb);

commit 4d2fa8b44b891f0da5ceda3e5a1402ccf0ab6f26
Merge: 8b68150883ca f3880a23564e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 20:57:08 2019 -0700

    Merge branch 'linus' of git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6
    
    Pull crypto updates from Herbert Xu:
     "Here is the crypto update for 5.3:
    
      API:
       - Test shash interface directly in testmgr
       - cra_driver_name is now mandatory
    
      Algorithms:
       - Replace arc4 crypto_cipher with library helper
       - Implement 5 way interleave for ECB, CBC and CTR on arm64
       - Add xxhash
       - Add continuous self-test on noise source to drbg
       - Update jitter RNG
    
      Drivers:
       - Add support for SHA204A random number generator
       - Add support for 7211 in iproc-rng200
       - Fix fuzz test failures in inside-secure
       - Fix fuzz test failures in talitos
       - Fix fuzz test failures in qat"
    
    * 'linus' of git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6: (143 commits)
      crypto: stm32/hash - remove interruptible condition for dma
      crypto: stm32/hash - Fix hmac issue more than 256 bytes
      crypto: stm32/crc32 - rename driver file
      crypto: amcc - remove memset after dma_alloc_coherent
      crypto: ccp - Switch to SPDX license identifiers
      crypto: ccp - Validate the the error value used to index error messages
      crypto: doc - Fix formatting of new crypto engine content
      crypto: doc - Add parameter documentation
      crypto: arm64/aes-ce - implement 5 way interleave for ECB, CBC and CTR
      crypto: arm64/aes-ce - add 5 way interleave routines
      crypto: talitos - drop icv_ool
      crypto: talitos - fix hash on SEC1.
      crypto: talitos - move struct talitos_edesc into talitos.h
      lib/scatterlist: Fix mapping iterator when sg->offset is greater than PAGE_SIZE
      crypto/NX: Set receive window credits to max number of CRBs in RxFIFO
      crypto: asymmetric_keys - select CRYPTO_HASH where needed
      crypto: serpent - mark __serpent_setkey_sbox noinline
      crypto: testmgr - dynamically allocate crypto_shash
      crypto: testmgr - dynamically allocate testvec_config
      crypto: talitos - eliminate unneeded 'done' functions at build time
      ...

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 4be38cd0b8d5..743d626479ef 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -1,13 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Cryptographic API for algorithms (i.e., low-level API).
  *
  * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License as published by the Free
- * Software Foundation; either version 2 of the License, or (at your option) 
- * any later version.
- *
  */
 #ifndef _CRYPTO_ALGAPI_H
 #define _CRYPTO_ALGAPI_H

commit 5e99a0a7a9468a18efec66ee97f1e34886e55550
Author: Eric Biggers <ebiggers@google.com>
Date:   Mon May 20 09:55:15 2019 -0700

    crypto: algapi - remove crypto_tfm_in_queue()
    
    Remove the crypto_tfm_in_queue() function, which is unused.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 4be38cd0b8d5..964a26fa4ff4 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -194,7 +194,6 @@ void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen);
 int crypto_enqueue_request(struct crypto_queue *queue,
 			   struct crypto_async_request *request);
 struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue);
-int crypto_tfm_in_queue(struct crypto_queue *queue, struct crypto_tfm *tfm);
 static inline unsigned int crypto_queue_len(struct crypto_queue *queue)
 {
 	return queue->qlen;
@@ -376,12 +375,6 @@ static inline void *ablkcipher_request_ctx(struct ablkcipher_request *req)
 	return req->__ctx;
 }
 
-static inline int ablkcipher_tfm_in_queue(struct crypto_queue *queue,
-					  struct crypto_ablkcipher *tfm)
-{
-	return crypto_tfm_in_queue(queue, crypto_ablkcipher_tfm(tfm));
-}
-
 static inline struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb,
 						     u32 type, u32 mask)
 {

commit 9572442dcf487e534e70b30f43e21a364cf483e9
Author: Xiongfeng Wang <xiongfeng.wang@linaro.org>
Date:   Fri Jan 18 13:58:11 2019 +0800

    crypto: api - add a helper to (un)register a array of templates
    
    This patch add a helper to (un)register a array of templates. The
    following patches will use this helper to simplify the code.
    
    Signed-off-by: Xiongfeng Wang <xiongfeng.wang@linaro.org>
    Reviewed-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 093869f175d6..4be38cd0b8d5 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -143,7 +143,9 @@ extern const struct crypto_type crypto_blkcipher_type;
 void crypto_mod_put(struct crypto_alg *alg);
 
 int crypto_register_template(struct crypto_template *tmpl);
+int crypto_register_templates(struct crypto_template *tmpls, int count);
 void crypto_unregister_template(struct crypto_template *tmpl);
+void crypto_unregister_templates(struct crypto_template *tmpls, int count);
 struct crypto_template *crypto_lookup_template(const char *name);
 
 int crypto_register_instance(struct crypto_template *tmpl,

commit 14aa1a839a33b4ade7479ffcad8a5fabe5cc4000
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jan 3 20:16:25 2019 -0800

    crypto: algapi - remove crypto_alloc_instance()
    
    Now that all "blkcipher" templates have been converted to "skcipher",
    crypto_alloc_instance() is no longer used.  And it's not useful any
    longer as it creates an old-style weakly typed instance rather than a
    new-style strongly typed instance.  So remove it, and now that the name
    is freed up rename crypto_alloc_instance2() to crypto_alloc_instance().
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 4a5ad10e75f0..093869f175d6 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -185,10 +185,8 @@ static inline struct crypto_alg *crypto_attr_alg(struct rtattr *rta,
 int crypto_attr_u32(struct rtattr *rta, u32 *num);
 int crypto_inst_setname(struct crypto_instance *inst, const char *name,
 			struct crypto_alg *alg);
-void *crypto_alloc_instance2(const char *name, struct crypto_alg *alg,
-			     unsigned int head);
-struct crypto_instance *crypto_alloc_instance(const char *name,
-					      struct crypto_alg *alg);
+void *crypto_alloc_instance(const char *name, struct crypto_alg *alg,
+			    unsigned int head);
 
 void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen);
 int crypto_enqueue_request(struct crypto_queue *queue,

commit dd8b083f9a5ed06946d559e0ca1eda0577ef24a9
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Thu Aug 30 11:00:14 2018 -0400

    crypto: api - Introduce notifier for new crypto algorithms
    
    Introduce a facility that can be used to receive a notification
    callback when a new algorithm becomes available. This can be used by
    existing crypto registrations to trigger a switch from a software-only
    algorithm to a hardware-accelerated version.
    
    A new CRYPTO_MSG_ALG_LOADED state is introduced to the existing crypto
    notification chain, and the register/unregister functions are exported
    so they can be called by subsystems outside of crypto.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Suggested-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 21371ac8f355..4a5ad10e75f0 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -427,4 +427,14 @@ static inline void crypto_yield(u32 flags)
 #endif
 }
 
+int crypto_register_notifier(struct notifier_block *nb);
+int crypto_unregister_notifier(struct notifier_block *nb);
+
+/* Crypto notification events. */
+enum {
+	CRYPTO_MSG_ALG_REQUEST,
+	CRYPTO_MSG_ALG_REGISTER,
+	CRYPTO_MSG_ALG_LOADED,
+};
+
 #endif	/* _CRYPTO_ALGAPI_H */

commit a9f7f88a12f1494deca1fd9e173c7ae886d14f91
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Aug 7 14:18:40 2018 -0700

    crypto: api - Introduce generic max blocksize and alignmask
    
    In the quest to remove all stack VLA usage from the kernel[1], this
    exposes a new general upper bound on crypto blocksize and alignmask
    (higher than for the existing cipher limits) for VLA removal,
    and introduces new checks.
    
    At present, the highest cra_alignmask in the kernel is 63. The highest
    cra_blocksize is 144 (SHA3_224_BLOCK_SIZE, 18 8-byte words). For the
    new blocksize limit, I went with 160 (20 8-byte words).
    
    [1] https://lkml.kernel.org/r/CA+55aFzCG-zNmZwX4A2FQpadafLfEzK6CC=qPXydAacU1RqZWA@mail.gmail.com
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index bd5e8ccf1687..21371ac8f355 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -20,8 +20,10 @@
 /*
  * Maximum values for blocksize and alignmask, used to allocate
  * static buffers that are big enough for any combination of
- * ciphers and architectures.
+ * algs and architectures. Ciphers have a lower maximum size.
  */
+#define MAX_ALGAPI_BLOCKSIZE		160
+#define MAX_ALGAPI_ALIGNMASK		63
 #define MAX_CIPHER_BLOCKSIZE		16
 #define MAX_CIPHER_ALIGNMASK		15
 

commit 13c935bb09948aef0202574ee12bb089459eb43b
Author: Salvatore Mesoraca <s.mesoraca16@gmail.com>
Date:   Mon Apr 9 15:54:46 2018 +0200

    crypto: api - laying defines and checks for statically allocated buffers
    
    In preparation for the removal of VLAs[1] from crypto code.
    We create 2 new compile-time constants: all ciphers implemented
    in Linux have a block size less than or equal to 16 bytes and
    the most demanding hw require 16 bytes alignment for the block
    buffer.
    We also enforce these limits in crypto_check_alg when a new
    cipher is registered.
    
    [1] http://lkml.kernel.org/r/CA+55aFzCG-zNmZwX4A2FQpadafLfEzK6CC=qPXydAacU1RqZWA@mail.gmail.com
    
    Signed-off-by: Salvatore Mesoraca <s.mesoraca16@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 1aba888241dd..bd5e8ccf1687 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -17,6 +17,14 @@
 #include <linux/kernel.h>
 #include <linux/skbuff.h>
 
+/*
+ * Maximum values for blocksize and alignmask, used to allocate
+ * static buffers that are big enough for any combination of
+ * ciphers and architectures.
+ */
+#define MAX_CIPHER_BLOCKSIZE		16
+#define MAX_CIPHER_ALIGNMASK		15
+
 struct crypto_aead;
 struct crypto_instance;
 struct module;

commit 4989d4f07a8e738b33a79099ddbdd8e125a4da1b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Mar 20 07:41:00 2018 +0800

    crypto: api - Remove unused crypto_type lookup function
    
    The lookup function in crypto_type was only used for the implicit
    IV generators which have been completely removed from the crypto
    API.
    
    This patch removes the lookup function as it is now useless.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index e3cebf640c00..1aba888241dd 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -30,7 +30,6 @@ struct crypto_type {
 	int (*init_tfm)(struct crypto_tfm *tfm);
 	void (*show)(struct seq_file *m, struct crypto_alg *alg);
 	int (*report)(struct sk_buff *skb, struct crypto_alg *alg);
-	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
 	void (*free)(struct crypto_instance *inst);
 
 	unsigned int type;

commit 45fe93dff2fb58b22de04c729f8447ba0f773d93
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Jul 24 11:28:04 2017 +0100

    crypto: algapi - make crypto_xor() take separate dst and src arguments
    
    There are quite a number of occurrences in the kernel of the pattern
    
      if (dst != src)
              memcpy(dst, src, walk.total % AES_BLOCK_SIZE);
      crypto_xor(dst, final, walk.total % AES_BLOCK_SIZE);
    
    or
    
      crypto_xor(keystream, src, nbytes);
      memcpy(dst, keystream, nbytes);
    
    where crypto_xor() is preceded or followed by a memcpy() invocation
    that is only there because crypto_xor() uses its output parameter as
    one of the inputs. To avoid having to add new instances of this pattern
    in the arm64 code, which will be refactored to implement non-SIMD
    fallbacks, add an alternative implementation called crypto_xor_cpy(),
    taking separate input and output arguments. This removes the need for
    the separate memcpy().
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index fd547f946bf8..e3cebf640c00 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -211,6 +211,25 @@ static inline void crypto_xor(u8 *dst, const u8 *src, unsigned int size)
 	}
 }
 
+static inline void crypto_xor_cpy(u8 *dst, const u8 *src1, const u8 *src2,
+				  unsigned int size)
+{
+	if (IS_ENABLED(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS) &&
+	    __builtin_constant_p(size) &&
+	    (size % sizeof(unsigned long)) == 0) {
+		unsigned long *d = (unsigned long *)dst;
+		unsigned long *s1 = (unsigned long *)src1;
+		unsigned long *s2 = (unsigned long *)src2;
+
+		while (size > 0) {
+			*d++ = *s1++ ^ *s2++;
+			size -= sizeof(unsigned long);
+		}
+	} else {
+		__crypto_xor(dst, src1, src2, size);
+	}
+}
+
 int blkcipher_walk_done(struct blkcipher_desc *desc,
 			struct blkcipher_walk *walk, int err);
 int blkcipher_walk_virt(struct blkcipher_desc *desc,

commit a7c391f04fe3259fb0417d71fec78ae28f25780e
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Jul 24 11:28:03 2017 +0100

    crypto: algapi - use separate dst and src operands for __crypto_xor()
    
    In preparation of introducing crypto_xor_cpy(), which will use separate
    operands for input and output, modify the __crypto_xor() implementation,
    which it will share with the existing crypto_xor(), which provides the
    actual functionality when not using the inline version.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 436c4c2683c7..fd547f946bf8 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -192,7 +192,7 @@ static inline unsigned int crypto_queue_len(struct crypto_queue *queue)
 }
 
 void crypto_inc(u8 *a, unsigned int size);
-void __crypto_xor(u8 *dst, const u8 *src, unsigned int size);
+void __crypto_xor(u8 *dst, const u8 *src1, const u8 *src2, unsigned int size);
 
 static inline void crypto_xor(u8 *dst, const u8 *src, unsigned int size)
 {
@@ -207,7 +207,7 @@ static inline void crypto_xor(u8 *dst, const u8 *src, unsigned int size)
 			size -= sizeof(unsigned long);
 		}
 	} else {
-		__crypto_xor(dst, src, size);
+		__crypto_xor(dst, dst, src, size);
 	}
 }
 

commit 016df0abc56ec06d0c63c5318ef53e40738dea8b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Feb 26 12:22:35 2017 +0800

    crypto: api - Add crypto_requires_off helper
    
    This patch adds crypto_requires_off which is an extension of
    crypto_requires_sync for similar bits such as NEED_FALLBACK.
    
    Cc: stable@vger.kernel.org #4.10
    Suggested-by: Marcelo Cerri <marcelo.cerri@canonical.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index ebe4ded0c55d..436c4c2683c7 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -360,13 +360,18 @@ static inline struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb,
 	return crypto_attr_alg(tb[1], type, mask);
 }
 
+static inline int crypto_requires_off(u32 type, u32 mask, u32 off)
+{
+	return (type ^ off) & mask & off;
+}
+
 /*
  * Returns CRYPTO_ALG_ASYNC if type/mask requires the use of sync algorithms.
  * Otherwise returns zero.
  */
 static inline int crypto_requires_sync(u32 type, u32 mask)
 {
-	return (type ^ CRYPTO_ALG_ASYNC) & mask & CRYPTO_ALG_ASYNC;
+	return crypto_requires_off(type, mask, CRYPTO_ALG_ASYNC);
 }
 
 noinline unsigned long __crypto_memneq(const void *a, const void *b, size_t size);

commit db91af0fbe20474cec33263e28d15f5e6b45ebc9
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Sun Feb 5 10:06:12 2017 +0000

    crypto: algapi - make crypto_xor() and crypto_inc() alignment agnostic
    
    Instead of unconditionally forcing 4 byte alignment for all generic
    chaining modes that rely on crypto_xor() or crypto_inc() (which may
    result in unnecessary copying of data when the underlying hardware
    can perform unaligned accesses efficiently), make those functions
    deal with unaligned input explicitly, but only if the Kconfig symbol
    HAVE_EFFICIENT_UNALIGNED_ACCESS is set. This will allow us to drop
    the alignmasks from the CBC, CMAC, CTR, CTS, PCBC and SEQIV drivers.
    
    For crypto_inc(), this simply involves making the 4-byte stride
    conditional on HAVE_EFFICIENT_UNALIGNED_ACCESS being set, given that
    it typically operates on 16 byte buffers.
    
    For crypto_xor(), an algorithm is implemented that simply runs through
    the input using the largest strides possible if unaligned accesses are
    allowed. If they are not, an optimal sequence of memory accesses is
    emitted that takes the relative alignment of the input buffers into
    account, e.g., if the relative misalignment of dst and src is 4 bytes,
    the entire xor operation will be completed using 4 byte loads and stores
    (modulo unaligned bits at the start and end). Note that all expressions
    involving misalign are simply eliminated by the compiler when
    HAVE_EFFICIENT_UNALIGNED_ACCESS is defined.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 404e9558e879..ebe4ded0c55d 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -191,9 +191,25 @@ static inline unsigned int crypto_queue_len(struct crypto_queue *queue)
 	return queue->qlen;
 }
 
-/* These functions require the input/output to be aligned as u32. */
 void crypto_inc(u8 *a, unsigned int size);
-void crypto_xor(u8 *dst, const u8 *src, unsigned int size);
+void __crypto_xor(u8 *dst, const u8 *src, unsigned int size);
+
+static inline void crypto_xor(u8 *dst, const u8 *src, unsigned int size)
+{
+	if (IS_ENABLED(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS) &&
+	    __builtin_constant_p(size) &&
+	    (size % sizeof(unsigned long)) == 0) {
+		unsigned long *d = (unsigned long *)dst;
+		unsigned long *s = (unsigned long *)src;
+
+		while (size > 0) {
+			*d++ ^= *s++;
+			size -= sizeof(unsigned long);
+		}
+	} else {
+		__crypto_xor(dst, src, size);
+	}
+}
 
 int blkcipher_walk_done(struct blkcipher_desc *desc,
 			struct blkcipher_walk *walk, int err);

commit 2589ad84047f1dbed741b48785680b152db2e5db
Author: Corentin LABBE <clabbe.montjoie@gmail.com>
Date:   Wed Aug 31 14:02:57 2016 +0200

    crypto: engine - move crypto engine to its own header
    
    This patch move the whole crypto engine API to its own header
    crypto/engine.h.
    
    Signed-off-by: Corentin Labbe <clabbe.montjoie@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 8637cdfe382a..404e9558e879 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -15,7 +15,6 @@
 #include <linux/crypto.h>
 #include <linux/list.h>
 #include <linux/kernel.h>
-#include <linux/kthread.h>
 #include <linux/skbuff.h>
 
 struct crypto_aead;
@@ -129,75 +128,6 @@ struct ablkcipher_walk {
 	unsigned int		blocksize;
 };
 
-#define ENGINE_NAME_LEN	30
-/*
- * struct crypto_engine - crypto hardware engine
- * @name: the engine name
- * @idling: the engine is entering idle state
- * @busy: request pump is busy
- * @running: the engine is on working
- * @cur_req_prepared: current request is prepared
- * @list: link with the global crypto engine list
- * @queue_lock: spinlock to syncronise access to request queue
- * @queue: the crypto queue of the engine
- * @rt: whether this queue is set to run as a realtime task
- * @prepare_crypt_hardware: a request will soon arrive from the queue
- * so the subsystem requests the driver to prepare the hardware
- * by issuing this call
- * @unprepare_crypt_hardware: there are currently no more requests on the
- * queue so the subsystem notifies the driver that it may relax the
- * hardware by issuing this call
- * @prepare_request: do some prepare if need before handle the current request
- * @unprepare_request: undo any work done by prepare_message()
- * @crypt_one_request: do encryption for current request
- * @kworker: thread struct for request pump
- * @kworker_task: pointer to task for request pump kworker thread
- * @pump_requests: work struct for scheduling work to the request pump
- * @priv_data: the engine private data
- * @cur_req: the current request which is on processing
- */
-struct crypto_engine {
-	char			name[ENGINE_NAME_LEN];
-	bool			idling;
-	bool			busy;
-	bool			running;
-	bool			cur_req_prepared;
-
-	struct list_head	list;
-	spinlock_t		queue_lock;
-	struct crypto_queue	queue;
-
-	bool			rt;
-
-	int (*prepare_crypt_hardware)(struct crypto_engine *engine);
-	int (*unprepare_crypt_hardware)(struct crypto_engine *engine);
-
-	int (*prepare_request)(struct crypto_engine *engine,
-			       struct ablkcipher_request *req);
-	int (*unprepare_request)(struct crypto_engine *engine,
-				 struct ablkcipher_request *req);
-	int (*crypt_one_request)(struct crypto_engine *engine,
-				 struct ablkcipher_request *req);
-
-	struct kthread_worker           kworker;
-	struct task_struct              *kworker_task;
-	struct kthread_work             pump_requests;
-
-	void				*priv_data;
-	struct ablkcipher_request	*cur_req;
-};
-
-int crypto_transfer_request(struct crypto_engine *engine,
-			    struct ablkcipher_request *req, bool need_pump);
-int crypto_transfer_request_to_engine(struct crypto_engine *engine,
-				      struct ablkcipher_request *req);
-void crypto_finalize_request(struct crypto_engine *engine,
-			     struct ablkcipher_request *req, int err);
-int crypto_engine_start(struct crypto_engine *engine);
-int crypto_engine_stop(struct crypto_engine *engine);
-struct crypto_engine *crypto_engine_alloc_init(struct device *dev, bool rt);
-int crypto_engine_exit(struct crypto_engine *engine);
-
 extern const struct crypto_type crypto_ablkcipher_type;
 extern const struct crypto_type crypto_blkcipher_type;
 

commit 4140139734459db4dffc50dad7b9e21ed79a8dd9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 12 13:17:56 2016 +0800

    crypto: api - Optimise away crypto_yield when hard preemption is on
    
    When hard preemption is enabled there is no need to explicitly
    call crypto_yield.  This patch eliminates it if that is the case.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 0483f652ac27..8637cdfe382a 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -442,8 +442,10 @@ static inline int crypto_memneq(const void *a, const void *b, size_t size)
 
 static inline void crypto_yield(u32 flags)
 {
+#if !defined(CONFIG_PREEMPT) || defined(CONFIG_PREEMPT_VOLUNTARY)
 	if (flags & CRYPTO_TFM_REQ_MAY_SLEEP)
 		cond_resched();
+#endif
 }
 
 #endif	/* _CRYPTO_ALGAPI_H */

commit 32f27c745c26ff4b6351bce265cba049a2c74de5
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jun 29 18:04:13 2016 +0800

    crypto: api - Add crypto_inst_setname
    
    This patch adds the helper crypto_inst_setname because the current
    helper crypto_alloc_instance2 is no longer useful given that we
    now look up the algorithm after we allocate the instance object.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index eeafd21afb44..0483f652ac27 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -244,6 +244,8 @@ static inline struct crypto_alg *crypto_attr_alg(struct rtattr *rta,
 }
 
 int crypto_attr_u32(struct rtattr *rta, u32 *num);
+int crypto_inst_setname(struct crypto_instance *inst, const char *name,
+			struct crypto_alg *alg);
 void *crypto_alloc_instance2(const char *name, struct crypto_alg *alg,
 			     unsigned int head);
 struct crypto_instance *crypto_alloc_instance(const char *name,

commit 896545098777564212b9e91af4c973f094649aa7
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Feb 1 21:36:54 2016 +0800

    crypto: hash - Remove crypto_hash interface
    
    This patch removes all traces of the crypto_hash interface, now
    that everyone has switched over to shash or ahash.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index b09d43f612e1..eeafd21afb44 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -349,24 +349,6 @@ static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)
 	return &crypto_cipher_tfm(tfm)->__crt_alg->cra_cipher;
 }
 
-static inline struct crypto_hash *crypto_spawn_hash(struct crypto_spawn *spawn)
-{
-	u32 type = CRYPTO_ALG_TYPE_HASH;
-	u32 mask = CRYPTO_ALG_TYPE_HASH_MASK;
-
-	return __crypto_hash_cast(crypto_spawn_tfm(spawn, type, mask));
-}
-
-static inline void *crypto_hash_ctx(struct crypto_hash *tfm)
-{
-	return crypto_tfm_ctx(&tfm->base);
-}
-
-static inline void *crypto_hash_ctx_aligned(struct crypto_hash *tfm)
-{
-	return crypto_tfm_ctx_aligned(&tfm->base);
-}
-
 static inline void blkcipher_walk_init(struct blkcipher_walk *walk,
 				       struct scatterlist *dst,
 				       struct scatterlist *src,

commit 735d37b5424b27aa685276b8b90b7e57c4705ac1
Author: Baolin Wang <baolin.wang@linaro.org>
Date:   Tue Jan 26 20:25:39 2016 +0800

    crypto: engine - Introduce the block request crypto engine framework
    
    Now block cipher engines need to implement and maintain their own queue/thread
    for processing requests, moreover currently helpers provided for only the queue
    itself (in crypto_enqueue_request() and crypto_dequeue_request()) but they
    don't help with the mechanics of driving the hardware (things like running the
    request immediately, DMA map it or providing a thread to process the queue in)
    even though a lot of that code really shouldn't vary that much from device to
    device.
    
    Thus this patch provides a mechanism for pushing requests to the hardware
    as it becomes free that drivers could use. And this framework is patterned
    on the SPI code and has worked out well there.
    (https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/
     drivers/spi/spi.c?id=ffbbdd21329f3e15eeca6df2d4bc11c04d9d91c0)
    
    Signed-off-by: Baolin Wang <baolin.wang@linaro.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 4f861c44d066..b09d43f612e1 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -15,6 +15,7 @@
 #include <linux/crypto.h>
 #include <linux/list.h>
 #include <linux/kernel.h>
+#include <linux/kthread.h>
 #include <linux/skbuff.h>
 
 struct crypto_aead;
@@ -128,6 +129,75 @@ struct ablkcipher_walk {
 	unsigned int		blocksize;
 };
 
+#define ENGINE_NAME_LEN	30
+/*
+ * struct crypto_engine - crypto hardware engine
+ * @name: the engine name
+ * @idling: the engine is entering idle state
+ * @busy: request pump is busy
+ * @running: the engine is on working
+ * @cur_req_prepared: current request is prepared
+ * @list: link with the global crypto engine list
+ * @queue_lock: spinlock to syncronise access to request queue
+ * @queue: the crypto queue of the engine
+ * @rt: whether this queue is set to run as a realtime task
+ * @prepare_crypt_hardware: a request will soon arrive from the queue
+ * so the subsystem requests the driver to prepare the hardware
+ * by issuing this call
+ * @unprepare_crypt_hardware: there are currently no more requests on the
+ * queue so the subsystem notifies the driver that it may relax the
+ * hardware by issuing this call
+ * @prepare_request: do some prepare if need before handle the current request
+ * @unprepare_request: undo any work done by prepare_message()
+ * @crypt_one_request: do encryption for current request
+ * @kworker: thread struct for request pump
+ * @kworker_task: pointer to task for request pump kworker thread
+ * @pump_requests: work struct for scheduling work to the request pump
+ * @priv_data: the engine private data
+ * @cur_req: the current request which is on processing
+ */
+struct crypto_engine {
+	char			name[ENGINE_NAME_LEN];
+	bool			idling;
+	bool			busy;
+	bool			running;
+	bool			cur_req_prepared;
+
+	struct list_head	list;
+	spinlock_t		queue_lock;
+	struct crypto_queue	queue;
+
+	bool			rt;
+
+	int (*prepare_crypt_hardware)(struct crypto_engine *engine);
+	int (*unprepare_crypt_hardware)(struct crypto_engine *engine);
+
+	int (*prepare_request)(struct crypto_engine *engine,
+			       struct ablkcipher_request *req);
+	int (*unprepare_request)(struct crypto_engine *engine,
+				 struct ablkcipher_request *req);
+	int (*crypt_one_request)(struct crypto_engine *engine,
+				 struct ablkcipher_request *req);
+
+	struct kthread_worker           kworker;
+	struct task_struct              *kworker_task;
+	struct kthread_work             pump_requests;
+
+	void				*priv_data;
+	struct ablkcipher_request	*cur_req;
+};
+
+int crypto_transfer_request(struct crypto_engine *engine,
+			    struct ablkcipher_request *req, bool need_pump);
+int crypto_transfer_request_to_engine(struct crypto_engine *engine,
+				      struct ablkcipher_request *req);
+void crypto_finalize_request(struct crypto_engine *engine,
+			     struct ablkcipher_request *req, int err);
+int crypto_engine_start(struct crypto_engine *engine);
+int crypto_engine_stop(struct crypto_engine *engine);
+struct crypto_engine *crypto_engine_alloc_init(struct device *dev, bool rt);
+int crypto_engine_exit(struct crypto_engine *engine);
+
 extern const struct crypto_type crypto_ablkcipher_type;
 extern const struct crypto_type crypto_blkcipher_type;
 

commit 9f93a8a0ba91fa3babe76a428e6c24f4c39f125e
Author: Baolin Wang <baolin.wang@linaro.org>
Date:   Tue Jan 26 20:25:38 2016 +0800

    crypto: api - Introduce crypto_queue_len() helper function
    
    This patch introduces crypto_queue_len() helper function to help to get the
    queue length in the crypto queue list now.
    
    Signed-off-by: Baolin Wang <baolin.wang@linaro.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index c9fe145f7dd3..4f861c44d066 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -184,6 +184,10 @@ int crypto_enqueue_request(struct crypto_queue *queue,
 			   struct crypto_async_request *request);
 struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue);
 int crypto_tfm_in_queue(struct crypto_queue *queue, struct crypto_tfm *tfm);
+static inline unsigned int crypto_queue_len(struct crypto_queue *queue)
+{
+	return queue->qlen;
+}
 
 /* These functions require the input/output to be aligned as u32. */
 void crypto_inc(u8 *a, unsigned int size);

commit 319382a6970899f02f18da4b0083a6e55942456d
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Jul 9 07:17:15 2015 +0800

    crypto: api - Add instance free function to crypto_type
    
    Currently the task of freeing an instance is given to the crypto
    template.  However, it has no type information on the instance so
    we have to resort to checking type information at runtime.
    
    This patch introduces a free function to crypto_type that will be
    used to free an instance.  This can then be used to free an instance
    in a type-safe manner.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 9041a8418ef0..c9fe145f7dd3 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -18,6 +18,7 @@
 #include <linux/skbuff.h>
 
 struct crypto_aead;
+struct crypto_instance;
 struct module;
 struct rtattr;
 struct seq_file;
@@ -30,6 +31,7 @@ struct crypto_type {
 	void (*show)(struct seq_file *m, struct crypto_alg *alg);
 	int (*report)(struct sk_buff *skb, struct crypto_alg *alg);
 	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
+	void (*free)(struct crypto_instance *inst);
 
 	unsigned int type;
 	unsigned int maskclear;

commit 31d228cc644034da97394bbadb2dc55ad9bcddb9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jul 8 11:55:30 2015 +0800

    crypto: api - Remove unused __crypto_dequeue_request
    
    The function __crypto_dequeue_request is completely unused.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index d4ebf6e9af6a..9041a8418ef0 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -180,7 +180,6 @@ struct crypto_instance *crypto_alloc_instance(const char *name,
 void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen);
 int crypto_enqueue_request(struct crypto_queue *queue,
 			   struct crypto_async_request *request);
-void *__crypto_dequeue_request(struct crypto_queue *queue, unsigned int offset);
 struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue);
 int crypto_tfm_in_queue(struct crypto_queue *queue, struct crypto_tfm *tfm);
 

commit 5d1d65f8bea6de3d9c2c60fdfdd2da02da5ea672
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon May 11 17:48:12 2015 +0800

    crypto: aead - Convert top level interface to new style
    
    This patch converts the top-level aead interface to the new style.
    All user-level AEAD interface code have been moved into crypto/aead.h.
    
    The allocation/free functions have switched over to the new way of
    allocating tfms.
    
    This patch also removes the double indrection on setkey so the
    indirection now exists only at the alg level.
    
    Apart from these there are no user-visible changes.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index a949bf70983b..d4ebf6e9af6a 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -17,6 +17,7 @@
 #include <linux/kernel.h>
 #include <linux/skbuff.h>
 
+struct crypto_aead;
 struct module;
 struct rtattr;
 struct seq_file;
@@ -126,7 +127,6 @@ struct ablkcipher_walk {
 };
 
 extern const struct crypto_type crypto_ablkcipher_type;
-extern const struct crypto_type crypto_aead_type;
 extern const struct crypto_type crypto_blkcipher_type;
 
 void crypto_mod_put(struct crypto_alg *alg);
@@ -241,22 +241,6 @@ static inline void *crypto_ablkcipher_ctx_aligned(struct crypto_ablkcipher *tfm)
 	return crypto_tfm_ctx_aligned(&tfm->base);
 }
 
-static inline struct aead_alg *crypto_aead_alg(struct crypto_aead *tfm)
-{
-	return &crypto_aead_tfm(tfm)->__crt_alg->cra_aead;
-}
-
-static inline void *crypto_aead_ctx(struct crypto_aead *tfm)
-{
-	return crypto_tfm_ctx(&tfm->base);
-}
-
-static inline struct crypto_instance *crypto_aead_alg_instance(
-	struct crypto_aead *aead)
-{
-	return crypto_tfm_alg_instance(&aead->base);
-}
-
 static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
 	struct crypto_spawn *spawn)
 {
@@ -365,21 +349,6 @@ static inline int ablkcipher_tfm_in_queue(struct crypto_queue *queue,
 	return crypto_tfm_in_queue(queue, crypto_ablkcipher_tfm(tfm));
 }
 
-static inline void *aead_request_ctx(struct aead_request *req)
-{
-	return req->__ctx;
-}
-
-static inline void aead_request_complete(struct aead_request *req, int err)
-{
-	req->base.complete(&req->base, err);
-}
-
-static inline u32 aead_request_flags(struct aead_request *req)
-{
-	return req->base.flags;
-}
-
 static inline struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb,
 						     u32 type, u32 mask)
 {

commit d6ef2f198d4c9d95b77ee4918b97fc8a53c8a7b7
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon May 11 17:47:39 2015 +0800

    crypto: api - Add crypto_grab_spawn primitive
    
    This patch adds a new primitive crypto_grab_spawn which is meant
    to replace crypto_init_spawn and crypto_init_spawn2.  Under the
    new scheme the user no longer has to worry about reference counting
    the alg object before it is subsumed by the spawn.
    
    It is pretty much an exact copy of crypto_grab_aead.
    
    Prior to calling this function spawn->frontend and spawn->inst
    must have been set.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 0ecb7688af71..a949bf70983b 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -144,6 +144,8 @@ int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 int crypto_init_spawn2(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		       struct crypto_instance *inst,
 		       const struct crypto_type *frontend);
+int crypto_grab_spawn(struct crypto_spawn *spawn, const char *name,
+		      u32 type, u32 mask);
 
 void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,

commit 87b1675634e1e9f1570445c55604204771ac9078
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Apr 2 22:39:40 2015 +0800

    crypto: api - Change crypto_unregister_instance argument type
    
    This patch makes crypto_unregister_instance take a crypto_instance
    instead of a crypto_alg.  This allows us to remove a duplicate
    CRYPTO_ALG_INSTANCE check in crypto_unregister_instance.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 623a59c1ff5a..0ecb7688af71 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -137,7 +137,7 @@ struct crypto_template *crypto_lookup_template(const char *name);
 
 int crypto_register_instance(struct crypto_template *tmpl,
 			     struct crypto_instance *inst);
-int crypto_unregister_instance(struct crypto_alg *alg);
+int crypto_unregister_instance(struct crypto_instance *inst);
 
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		      struct crypto_instance *inst, u32 mask);

commit bb55a4c100abbb8d2a41e732f6362c575a7094e6
Author: Marek Vasut <marex@denx.de>
Date:   Mon May 26 15:32:05 2014 +0200

    crypto: api - Move crypto_yield() to algapi.h
    
    It makes no sense for crypto_yield() to be defined in scatterwalk.h ,
    move it into algapi.h as it's an internal function to crypto API.
    
    Signed-off-by: Marek Vasut <marex@denx.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 016c2f110f63..623a59c1ff5a 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -410,4 +410,10 @@ static inline int crypto_memneq(const void *a, const void *b, size_t size)
 	return __crypto_memneq(a, b, size) != 0UL ? 1 : 0;
 }
 
+static inline void crypto_yield(u32 flags)
+{
+	if (flags & CRYPTO_TFM_REQ_MAY_SLEEP)
+		cond_resched();
+}
+
 #endif	/* _CRYPTO_ALGAPI_H */

commit 4f7f1d7cff8f2c170ce0319eb4c01a82c328d34f
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Mar 4 13:28:39 2014 +0800

    crypto: allow blkcipher walks over AEAD data
    
    This adds the function blkcipher_aead_walk_virt_block, which allows the caller
    to use the blkcipher walk API to handle the input and output scatterlists.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index d9d14a0f0653..016c2f110f63 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -195,6 +195,10 @@ int blkcipher_walk_phys(struct blkcipher_desc *desc,
 int blkcipher_walk_virt_block(struct blkcipher_desc *desc,
 			      struct blkcipher_walk *walk,
 			      unsigned int blocksize);
+int blkcipher_aead_walk_virt_block(struct blkcipher_desc *desc,
+				   struct blkcipher_walk *walk,
+				   struct crypto_aead *tfm,
+				   unsigned int blocksize);
 
 int ablkcipher_walk_done(struct ablkcipher_request *req,
 			 struct ablkcipher_walk *walk, int err);

commit 822be00fe67105a90e536df52d1e4d688f34b5b2
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Mar 4 13:28:38 2014 +0800

    crypto: remove direct blkcipher_walk dependency on transform
    
    In order to allow other uses of the blkcipher walk API than the blkcipher
    algos themselves, this patch copies some of the transform data members to the
    walk struct so the transform is only accessed at walk init time.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index e73c19e90e38..d9d14a0f0653 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -100,9 +100,12 @@ struct blkcipher_walk {
 	void *page;
 	u8 *buffer;
 	u8 *iv;
+	unsigned int ivsize;
 
 	int flags;
-	unsigned int blocksize;
+	unsigned int walk_blocksize;
+	unsigned int cipher_blocksize;
+	unsigned int alignmask;
 };
 
 struct ablkcipher_walk {

commit 6bf37e5aa90f18baf5acf4874bca505dd667c37f
Author: James Yonan <james@openvpn.net>
Date:   Thu Sep 26 02:20:39 2013 -0600

    crypto: crypto_memneq - add equality testing of memory regions w/o timing leaks
    
    When comparing MAC hashes, AEAD authentication tags, or other hash
    values in the context of authentication or integrity checking, it
    is important not to leak timing information to a potential attacker,
    i.e. when communication happens over a network.
    
    Bytewise memory comparisons (such as memcmp) are usually optimized so
    that they return a nonzero value as soon as a mismatch is found. E.g,
    on x86_64/i5 for 512 bytes this can be ~50 cyc for a full mismatch
    and up to ~850 cyc for a full match (cold). This early-return behavior
    can leak timing information as a side channel, allowing an attacker to
    iteratively guess the correct result.
    
    This patch adds a new method crypto_memneq ("memory not equal to each
    other") to the crypto API that compares memory areas of the same length
    in roughly "constant time" (cache misses could change the timing, but
    since they don't reveal information about the content of the strings
    being compared, they are effectively benign). Iow, best and worst case
    behaviour take the same amount of time to complete (in contrast to
    memcmp).
    
    Note that crypto_memneq (unlike memcmp) can only be used to test for
    equality or inequality, NOT for lexicographical order. This, however,
    is not an issue for its use-cases within the crypto API.
    
    We tried to locate all of the places in the crypto API where memcmp was
    being used for authentication or integrity checking, and convert them
    over to crypto_memneq.
    
    crypto_memneq is declared noinline, placed in its own source file,
    and compiled with optimizations that might increase code size disabled
    ("Os") because a smart compiler (or LTO) might notice that the return
    value is always compared against zero/nonzero, and might then
    reintroduce the same early-return optimization that we are trying to
    avoid.
    
    Using #pragma or __attribute__ optimization annotations of the code
    for disabling optimization was avoided as it seems to be considered
    broken or unmaintained for long time in GCC [1]. Therefore, we work
    around that by specifying the compile flag for memneq.o directly in
    the Makefile. We found that this seems to be most appropriate.
    
    As we use ("Os"), this patch also provides a loop-free "fast-path" for
    frequently used 16 byte digests. Similarly to kernel library string
    functions, leave an option for future even further optimized architecture
    specific assembler implementations.
    
    This was a joint work of James Yonan and Daniel Borkmann. Also thanks
    for feedback from Florian Weimer on this and earlier proposals [2].
    
      [1] http://gcc.gnu.org/ml/gcc/2012-07/msg00211.html
      [2] https://lkml.org/lkml/2013/2/10/131
    
    Signed-off-by: James Yonan <james@openvpn.net>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Cc: Florian Weimer <fw@deneb.enyo.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 418d270e1806..e73c19e90e38 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -386,5 +386,21 @@ static inline int crypto_requires_sync(u32 type, u32 mask)
 	return (type ^ CRYPTO_ALG_ASYNC) & mask & CRYPTO_ALG_ASYNC;
 }
 
-#endif	/* _CRYPTO_ALGAPI_H */
+noinline unsigned long __crypto_memneq(const void *a, const void *b, size_t size);
+
+/**
+ * crypto_memneq - Compare two areas of memory without leaking
+ *		   timing information.
+ *
+ * @a: One area of memory
+ * @b: Another area of memory
+ * @size: The size of the area.
+ *
+ * Returns 0 when data is equal, 1 otherwise.
+ */
+static inline int crypto_memneq(const void *a, const void *b, size_t size)
+{
+	return __crypto_memneq(a, b, size) != 0UL ? 1 : 0;
+}
 
+#endif	/* _CRYPTO_ALGAPI_H */

commit ce3fd840f588d85a8c1be651cf90fa1ba1f029e9
Author: Steffen Klassert <steffen.klassert@secunet.com>
Date:   Tue Nov 8 10:09:17 2011 +0100

    crypto: Unlink and free instances when deleted
    
    We leak the crypto instance when we unregister an instance with
    crypto_del_alg(). Therefore we introduce crypto_unregister_instance()
    to unlink the crypto instance from the template's instances list and
    to free the recources of the instance properly.
    
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index ecc721def10c..418d270e1806 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -134,6 +134,7 @@ struct crypto_template *crypto_lookup_template(const char *name);
 
 int crypto_register_instance(struct crypto_template *tmpl,
 			     struct crypto_instance *inst);
+int crypto_unregister_instance(struct crypto_alg *alg);
 
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		      struct crypto_instance *inst, u32 mask);

commit b6aa63c09ba3b150a1030f9c95c7647361e7910e
Author: Steffen Klassert <steffen.klassert@secunet.com>
Date:   Tue Sep 27 07:24:29 2011 +0200

    crypto: Add a report function pointer to crypto_type
    
    We add a report function pointer to struct crypto_type. This function
    pointer is used from the crypto userspace configuration API to report
    crypto algorithms to userspace.
    
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 59c3e5bd2c06..ecc721def10c 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -15,6 +15,7 @@
 #include <linux/crypto.h>
 #include <linux/list.h>
 #include <linux/kernel.h>
+#include <linux/skbuff.h>
 
 struct module;
 struct rtattr;
@@ -26,6 +27,7 @@ struct crypto_type {
 	int (*init)(struct crypto_tfm *tfm, u32 type, u32 mask);
 	int (*init_tfm)(struct crypto_tfm *tfm);
 	void (*show)(struct seq_file *m, struct crypto_alg *alg);
+	int (*report)(struct sk_buff *skb, struct crypto_alg *alg);
 	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
 
 	unsigned int type;

commit bf06099db18a1244957076e51847c644cfe46808
Author: David S. Miller <davem@davemloft.net>
Date:   Wed May 19 14:13:07 2010 +1000

    crypto: skcipher - Add ablkcipher_walk interfaces
    
    These are akin to the blkcipher_walk helpers.
    
    The main differences in the async variant are:
    
    1) Only physical walking is supported.  We can't hold on to
       kmap mappings across the async operation to support virtual
       ablkcipher_walk operations anyways.
    
    2) Bounce buffers used for async more need to be persistent and
       freed at a later point in time when the async op completes.
       Therefore we maintain a list of writeback buffers and require
       that the ablkcipher_walk user call the 'complete' operation
       so we can copy the bounce buffers out to the real buffers and
       free up the bounce buffer chunks.
    
    These interfaces will be used by the new Niagara2 crypto driver.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index fc0d575c71e0..59c3e5bd2c06 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -103,6 +103,23 @@ struct blkcipher_walk {
 	unsigned int blocksize;
 };
 
+struct ablkcipher_walk {
+	struct {
+		struct page *page;
+		unsigned int offset;
+	} src, dst;
+
+	struct scatter_walk	in;
+	unsigned int		nbytes;
+	struct scatter_walk	out;
+	unsigned int		total;
+	struct list_head	buffers;
+	u8			*iv_buffer;
+	u8			*iv;
+	int			flags;
+	unsigned int		blocksize;
+};
+
 extern const struct crypto_type crypto_ablkcipher_type;
 extern const struct crypto_type crypto_aead_type;
 extern const struct crypto_type crypto_blkcipher_type;
@@ -173,6 +190,12 @@ int blkcipher_walk_virt_block(struct blkcipher_desc *desc,
 			      struct blkcipher_walk *walk,
 			      unsigned int blocksize);
 
+int ablkcipher_walk_done(struct ablkcipher_request *req,
+			 struct ablkcipher_walk *walk, int err);
+int ablkcipher_walk_phys(struct ablkcipher_request *req,
+			 struct ablkcipher_walk *walk);
+void __ablkcipher_walk_complete(struct ablkcipher_walk *walk);
+
 static inline void *crypto_tfm_ctx_aligned(struct crypto_tfm *tfm)
 {
 	return PTR_ALIGN(crypto_tfm_ctx(tfm),
@@ -283,6 +306,23 @@ static inline void blkcipher_walk_init(struct blkcipher_walk *walk,
 	walk->total = nbytes;
 }
 
+static inline void ablkcipher_walk_init(struct ablkcipher_walk *walk,
+					struct scatterlist *dst,
+					struct scatterlist *src,
+					unsigned int nbytes)
+{
+	walk->in.sg = src;
+	walk->out.sg = dst;
+	walk->total = nbytes;
+	INIT_LIST_HEAD(&walk->buffers);
+}
+
+static inline void ablkcipher_walk_complete(struct ablkcipher_walk *walk)
+{
+	if (unlikely(!list_empty(&walk->buffers)))
+		__ablkcipher_walk_complete(walk);
+}
+
 static inline struct crypto_async_request *crypto_get_backlog(
 	struct crypto_queue *queue)
 {

commit 2141b6309b1fce535329c195cb5e5274a4c84ebc
Author: Benjamin Gilbert <bgilbert@cs.cmu.edu>
Date:   Mon Oct 19 12:53:37 2009 +0900

    crypto: hash - Remove legacy hash/digest code
    
    6941c3a0 disabled compilation of the legacy digest code but didn't
    actually remove it.  Rectify this.  Also, remove the crypto_hash_type
    extern declaration from algapi.h now that the struct is gone.
    
    Signed-off-by: Benjamin Gilbert <bgilbert@cs.cmu.edu>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 1ffb53f74d37..fc0d575c71e0 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -106,7 +106,6 @@ struct blkcipher_walk {
 extern const struct crypto_type crypto_ablkcipher_type;
 extern const struct crypto_type crypto_aead_type;
 extern const struct crypto_type crypto_blkcipher_type;
-extern const struct crypto_type crypto_hash_type;
 
 void crypto_mod_put(struct crypto_alg *alg);
 

commit 332a3392188e0ad966543c87b8da2b9d246f301d
Merge: a9c86d425995 81bd5f6c966c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 11 09:38:37 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6: (102 commits)
      crypto: sha-s390 - Fix warnings in import function
      crypto: vmac - New hash algorithm for intel_txt support
      crypto: api - Do not displace newly registered algorithms
      crypto: ansi_cprng - Fix module initialization
      crypto: xcbc - Fix alignment calculation of xcbc_tfm_ctx
      crypto: fips - Depend on ansi_cprng
      crypto: blkcipher - Do not use eseqiv on stream ciphers
      crypto: ctr - Use chainiv on raw counter mode
      Revert crypto: fips - Select CPRNG
      crypto: rng - Fix typo
      crypto: talitos - add support for 36 bit addressing
      crypto: talitos - align locks on cache lines
      crypto: talitos - simplify hmac data size calculation
      crypto: mv_cesa - Add support for Orion5X crypto engine
      crypto: cryptd - Add support to access underlaying shash
      crypto: gcm - Use GHASH digest algorithm
      crypto: ghash - Add GHASH digest algorithm for GCM
      crypto: authenc - Convert to ahash
      crypto: api - Fix aligned ctx helper
      crypto: hmac - Prehash ipad/opad
      ...

commit 0c7d400fafaeab6014504a6a6249f01bac7f7db4
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Aug 29 20:44:04 2009 +1000

    crypto: skcipher - Fix skcipher_dequeue_givcrypt NULL test
    
    As struct skcipher_givcrypt_request includes struct crypto_request
    at a non-zero offset, testing for NULL after converting the pointer
    returned by crypto_dequeue_request does not work.  This can result
    in IPsec crashes when the queue is depleted.
    
    This patch fixes it by doing the pointer conversion only when the
    return value is non-NULL.  In particular, we create a new function
    __crypto_dequeue_request that does the pointer conversion.
    
    Reported-by: Brad Bosch <bradbosch@comcast.net>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 010545436efa..5a2bd1cc9656 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -137,6 +137,7 @@ struct crypto_instance *crypto_alloc_instance(const char *name,
 void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen);
 int crypto_enqueue_request(struct crypto_queue *queue,
 			   struct crypto_async_request *request);
+void *__crypto_dequeue_request(struct crypto_queue *queue, unsigned int offset);
 struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue);
 int crypto_tfm_in_queue(struct crypto_queue *queue, struct crypto_tfm *tfm);
 

commit ab300465676b0c0559af62d57ec9a902f5680b03
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Jul 24 15:26:15 2009 +0800

    crypto: api - Fix aligned ctx helper
    
    The aligned ctx helper was using a bogus alignment value thas was
    one off the correct value.  Fortunately the current users do not
    require anything beyond the natural alignment of the platform so
    this hasn't caused a problem.
    
    This patch fixes that and also removes the unnecessary minimum
    check since if the alignment is less than the natural alignment
    then the subsequent ALIGN operation should be a noop.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 9de6c38f4069..3f388146a914 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -175,12 +175,8 @@ int blkcipher_walk_virt_block(struct blkcipher_desc *desc,
 
 static inline void *crypto_tfm_ctx_aligned(struct crypto_tfm *tfm)
 {
-	unsigned long addr = (unsigned long)crypto_tfm_ctx(tfm);
-	unsigned long align = crypto_tfm_alg_alignmask(tfm);
-
-	if (align <= crypto_tfm_ctx_alignment())
-		align = 1;
-	return (void *)ALIGN(addr, align);
+	return PTR_ALIGN(crypto_tfm_ctx(tfm),
+			 crypto_tfm_alg_alignmask(tfm) + 1);
 }
 
 static inline struct crypto_instance *crypto_tfm_alg_instance(

commit 9cd899a32f611eb6328014f1d9e0ba31977812d9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 14 18:45:45 2009 +0800

    crypto: cryptd - Switch to template create API
    
    This patch changes cryptd to use the template->create function
    instead of alloc in anticipation for the switch to new style
    ahash algorithms.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 7635fde7b1a2..9de6c38f4069 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -114,6 +114,9 @@ int crypto_register_template(struct crypto_template *tmpl);
 void crypto_unregister_template(struct crypto_template *tmpl);
 struct crypto_template *crypto_lookup_template(const char *name);
 
+int crypto_register_instance(struct crypto_template *tmpl,
+			     struct crypto_instance *inst);
+
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		      struct crypto_instance *inst, u32 mask);
 int crypto_init_spawn2(struct crypto_spawn *spawn, struct crypto_alg *alg,

commit 2ca33da1dea3ba53d1425226a6bac073c5e8568c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Jul 13 20:46:25 2009 +0800

    crypto: api - Remove frontend argument from extsize/init_tfm
    
    As the extsize and init_tfm functions belong to the frontend the
    frontend argument is superfluous.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 1d15a926041e..7635fde7b1a2 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -22,11 +22,9 @@ struct seq_file;
 
 struct crypto_type {
 	unsigned int (*ctxsize)(struct crypto_alg *alg, u32 type, u32 mask);
-	unsigned int (*extsize)(struct crypto_alg *alg,
-				const struct crypto_type *frontend);
+	unsigned int (*extsize)(struct crypto_alg *alg);
 	int (*init)(struct crypto_tfm *tfm, u32 type, u32 mask);
-	int (*init_tfm)(struct crypto_tfm *tfm,
-		        const struct crypto_type *frontend);
+	int (*init_tfm)(struct crypto_tfm *tfm);
 	void (*show)(struct seq_file *m, struct crypto_alg *alg);
 	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
 

commit d06854f0243d91badabaab14503f7f3bb770061d
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jul 8 17:53:16 2009 +0800

    crypto: api - Add crypto_attr_alg2 helper
    
    This patch adds the helper crypto_attr_alg2 which is similar to
    crypto_attr_alg but takes an extra frontend argument.  This is
    intended to be used by new style algorithm types such as shash.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index c9bff92a9e0e..1d15a926041e 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -136,7 +136,16 @@ static inline void crypto_set_spawn(struct crypto_spawn *spawn,
 struct crypto_attr_type *crypto_get_attr_type(struct rtattr **tb);
 int crypto_check_attr_type(struct rtattr **tb, u32 type);
 const char *crypto_attr_alg_name(struct rtattr *rta);
-struct crypto_alg *crypto_attr_alg(struct rtattr *rta, u32 type, u32 mask);
+struct crypto_alg *crypto_attr_alg2(struct rtattr *rta,
+				    const struct crypto_type *frontend,
+				    u32 type, u32 mask);
+
+static inline struct crypto_alg *crypto_attr_alg(struct rtattr *rta,
+						 u32 type, u32 mask)
+{
+	return crypto_attr_alg2(rta, NULL, type, mask);
+}
+
 int crypto_attr_u32(struct rtattr *rta, u32 *num);
 void *crypto_alloc_instance2(const char *name, struct crypto_alg *alg,
 			     unsigned int head);

commit 97eedce1a64a57648ac5e39f03825528c47ba72e
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jul 8 15:55:52 2009 +0800

    crypto: api - Add new style spawn support
    
    This patch modifies the spawn infrastructure to support new style
    algorithms like shash.  In particular, this means storing the
    frontend type in the spawn and using crypto_create_tfm to allocate
    the tfm.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 99bb29723130..c9bff92a9e0e 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -61,6 +61,7 @@ struct crypto_spawn {
 	struct list_head list;
 	struct crypto_alg *alg;
 	struct crypto_instance *inst;
+	const struct crypto_type *frontend;
 	u32 mask;
 };
 
@@ -117,9 +118,14 @@ struct crypto_template *crypto_lookup_template(const char *name);
 
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		      struct crypto_instance *inst, u32 mask);
+int crypto_init_spawn2(struct crypto_spawn *spawn, struct crypto_alg *alg,
+		       struct crypto_instance *inst,
+		       const struct crypto_type *frontend);
+
 void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 				    u32 mask);
+void *crypto_spawn_tfm2(struct crypto_spawn *spawn);
 
 static inline void crypto_set_spawn(struct crypto_spawn *spawn,
 				    struct crypto_instance *inst)

commit 70ec7bb91ad0d6cce84c8e17f8cbb608dda7b18c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 7 14:07:37 2009 +0800

    crypto: api - Add crypto_alloc_instance2
    
    This patch adds a new argument to crypto_alloc_instance which
    sets aside some space before the instance for use by algorithms
    such as shash that place type-specific data before crypto_alg.
    
    For compatibility the function has been renamed so that existing
    users aren't affected.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index ce010a346420..99bb29723130 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -132,6 +132,8 @@ int crypto_check_attr_type(struct rtattr **tb, u32 type);
 const char *crypto_attr_alg_name(struct rtattr *rta);
 struct crypto_alg *crypto_attr_alg(struct rtattr *rta, u32 type, u32 mask);
 int crypto_attr_u32(struct rtattr *rta, u32 *num);
+void *crypto_alloc_instance2(const char *name, struct crypto_alg *alg,
+			     unsigned int head);
 struct crypto_instance *crypto_alloc_instance(const char *name,
 					      struct crypto_alg *alg);
 

commit f2ac72e8268d9559c3114d5a22679f91f80a2238
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 7 12:30:33 2009 +0800

    crypto: api - Add new template create function
    
    This patch introduces the template->create function intended
    to replace the existing alloc function.  The intention is for
    create to handle the registration directly, whereas currently
    the caller of alloc has to handle the registration.
    
    This allows type-specific code to be run prior to registration.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 010545436efa..ce010a346420 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -52,6 +52,7 @@ struct crypto_template {
 
 	struct crypto_instance *(*alloc)(struct rtattr **tb);
 	void (*free)(struct crypto_instance *inst);
+	int (*create)(struct crypto_template *tmpl, struct rtattr **tb);
 
 	char name[CRYPTO_MAX_ALG_NAME];
 };

commit 5f7082ed4f482f05db01d84dbf58190492ebf0ad
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 31 22:21:09 2008 +1000

    crypto: hash - Export shash through hash
    
    This patch allows shash algorithms to be used through the old hash
    interface.  This is a transitional measure so we can convert the
    underlying algorithms to shash before converting the users across.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 986db68548f6..010545436efa 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -248,6 +248,11 @@ static inline struct crypto_hash *crypto_spawn_hash(struct crypto_spawn *spawn)
 	return __crypto_hash_cast(crypto_spawn_tfm(spawn, type, mask));
 }
 
+static inline void *crypto_hash_ctx(struct crypto_hash *tfm)
+{
+	return crypto_tfm_ctx(&tfm->base);
+}
+
 static inline void *crypto_hash_ctx_aligned(struct crypto_hash *tfm)
 {
 	return crypto_tfm_ctx_aligned(&tfm->base);

commit 7b0bac64cd5b74d6f1147524c26216de13a501fd
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Sep 21 06:52:53 2008 +0900

    crypto: api - Rebirth of crypto_alloc_tfm
    
    This patch reintroduces a completely revamped crypto_alloc_tfm.
    The biggest change is that we now take two crypto_type objects
    when allocating a tfm, a frontend and a backend.  In fact this
    simply formalises what we've been doing behind the API's back.
    
    For example, as it stands crypto_alloc_ahash may use an
    actual ahash algorithm or a crypto_hash algorithm.  Putting
    this in the API allows us to do this much more cleanly.
    
    The existing types will be converted across gradually.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 5fb6d8618d4d..986db68548f6 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -22,8 +22,18 @@ struct seq_file;
 
 struct crypto_type {
 	unsigned int (*ctxsize)(struct crypto_alg *alg, u32 type, u32 mask);
+	unsigned int (*extsize)(struct crypto_alg *alg,
+				const struct crypto_type *frontend);
 	int (*init)(struct crypto_tfm *tfm, u32 type, u32 mask);
+	int (*init_tfm)(struct crypto_tfm *tfm,
+		        const struct crypto_type *frontend);
 	void (*show)(struct seq_file *m, struct crypto_alg *alg);
+	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
+
+	unsigned int type;
+	unsigned int maskclear;
+	unsigned int maskset;
+	unsigned int tfmsize;
 };
 
 struct crypto_instance {

commit 4a7794860ba2b56693b1d89fd485fd08cdc763e3
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Sep 13 18:19:03 2008 -0700

    crypto: api - Move type exit function into crypto_tfm
    
    The type exit function needs to undo any allocations done by the type
    init function.  However, the type init function may differ depending
    on the upper-level type of the transform (e.g., a crypto_blkcipher
    instantiated as a crypto_ablkcipher).
    
    So we need to move the exit function out of the lower-level
    structure and into crypto_tfm itself.
    
    As it stands this is a no-op since nobody uses exit functions at
    all.  However, all cases where a lower-level type is instantiated
    as a different upper-level type (such as blkcipher as ablkcipher)
    will be converted such that they allocate the underlying transform
    and use that instead of casting (e.g., crypto_ablkcipher casted
    into crypto_blkcipher).  That will need to use a different exit
    function depending on the upper-level type.
    
    This patch also allows the type init/exit functions to call (or not)
    cra_init/cra_exit instead of always calling them from the top level.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 60d06e784be3..5fb6d8618d4d 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -23,7 +23,6 @@ struct seq_file;
 struct crypto_type {
 	unsigned int (*ctxsize)(struct crypto_alg *alg, u32 type, u32 mask);
 	int (*init)(struct crypto_tfm *tfm, u32 type, u32 mask);
-	void (*exit)(struct crypto_tfm *tfm);
 	void (*show)(struct seq_file *m, struct crypto_alg *alg);
 };
 

commit 45d44eb56ad197cfccb8f84b5df64abff8b7cb96
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Dec 2 21:21:02 2007 +1100

    [CRYPTO] skcipher: Remove crypto_spawn_ablkcipher
    
    Now that gcm and authenc have been converted to crypto_spawn_skcipher,
    this patch removes the obsolete crypto_spawn_ablkcipher function.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index fda1759ffe2d..60d06e784be3 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -198,14 +198,6 @@ static inline struct crypto_instance *crypto_aead_alg_instance(
 	return crypto_tfm_alg_instance(&aead->base);
 }
 
-static inline struct crypto_ablkcipher *crypto_spawn_ablkcipher(
-	struct crypto_spawn *spawn)
-{
-	return __crypto_ablkcipher_cast(
-		crypto_spawn_tfm(spawn, crypto_skcipher_type(0),
-				 crypto_skcipher_mask(0)));
-}
-
 static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
 	struct crypto_spawn *spawn)
 {

commit 378f4f51f9fdd8df80ea875320e2bf1d7c6e6e77
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Dec 17 20:07:31 2007 +0800

    [CRYPTO] skcipher: Add crypto_grab_skcipher interface
    
    Note: From now on the collective of ablkcipher/blkcipher/givcipher will
    be known as skcipher, i.e., symmetric key cipher.  The name blkcipher has
    always been much of a misnomer since it supports stream ciphers too.
    
    This patch adds the function crypto_grab_skcipher as a new way of getting
    an ablkcipher spawn.  The problem is that previously we did this in two
    steps, first getting the algorithm and then calling crypto_init_spawn.
    
    This meant that each spawn user had to be aware of what type and mask to
    use for these two steps.  This is difficult and also presents a problem
    when the type/mask changes as they're about to be for IV generators.
    
    The new interface does both steps together just like crypto_alloc_ablkcipher.
    
    As a side-effect this also allows us to be stronger on type enforcement
    for spawns.  For now this is only done for ablkcipher but it's trivial
    to extend for other types.
    
    This patch also moves the type/mask logic for skcipher into the helpers
    crypto_skcipher_type and crypto_skcipher_mask.
    
    Finally this patch introduces the function crypto_require_sync to determine
    whether the user is specifically requesting a sync algorithm.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 726a765e5ec6..fda1759ffe2d 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -111,6 +111,12 @@ void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 				    u32 mask);
 
+static inline void crypto_set_spawn(struct crypto_spawn *spawn,
+				    struct crypto_instance *inst)
+{
+	spawn->inst = inst;
+}
+
 struct crypto_attr_type *crypto_get_attr_type(struct rtattr **tb);
 int crypto_check_attr_type(struct rtattr **tb, u32 type);
 const char *crypto_attr_alg_name(struct rtattr *rta);
@@ -195,10 +201,9 @@ static inline struct crypto_instance *crypto_aead_alg_instance(
 static inline struct crypto_ablkcipher *crypto_spawn_ablkcipher(
 	struct crypto_spawn *spawn)
 {
-	u32 type = CRYPTO_ALG_TYPE_BLKCIPHER;
-	u32 mask = CRYPTO_ALG_TYPE_BLKCIPHER_MASK;
-
-	return __crypto_ablkcipher_cast(crypto_spawn_tfm(spawn, type, mask));
+	return __crypto_ablkcipher_cast(
+		crypto_spawn_tfm(spawn, crypto_skcipher_type(0),
+				 crypto_skcipher_mask(0)));
 }
 
 static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
@@ -308,5 +313,14 @@ static inline struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb,
 	return crypto_attr_alg(tb[1], type, mask);
 }
 
+/*
+ * Returns CRYPTO_ALG_ASYNC if type/mask requires the use of sync algorithms.
+ * Otherwise returns zero.
+ */
+static inline int crypto_requires_sync(u32 type, u32 mask)
+{
+	return (type ^ CRYPTO_ALG_ASYNC) & mask & CRYPTO_ALG_ASYNC;
+}
+
 #endif	/* _CRYPTO_ALGAPI_H */
 

commit 68b6c7d6919be7c732fc6229c55e35d0166e9258
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Dec 7 20:18:17 2007 +0800

    [CRYPTO] api: Add crypto_attr_alg_name
    
    This patch adds a new helper crypto_attr_alg_name which is basically the
    first half of crypto_attr_alg.  That is, it returns an algorithm name
    parameter as a string without looking it up.  The caller can then look it
    up immediately or defer it until later.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 2cdb227fc39d..726a765e5ec6 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -113,6 +113,7 @@ struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 
 struct crypto_attr_type *crypto_get_attr_type(struct rtattr **tb);
 int crypto_check_attr_type(struct rtattr **tb, u32 type);
+const char *crypto_attr_alg_name(struct rtattr *rta);
 struct crypto_alg *crypto_attr_alg(struct rtattr *rta, u32 type, u32 mask);
 int crypto_attr_u32(struct rtattr *rta, u32 *num);
 struct crypto_instance *crypto_alloc_instance(const char *name,

commit 7613636def82092a5c7b6322078a2af832410417
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Nov 20 17:26:06 2007 +0800

    [CRYPTO] api: Add crypto_inc and crypto_xor
    
    With the addition of more stream ciphers we need to curb the proliferation
    of ad-hoc xor functions.  This patch creates a generic pair of functions,
    crypto_inc and crypto_xor which does big-endian increment and exclusive or,
    respectively.
    
    For optimum performance, they both use u32 operations so alignment must be
    as that of u32 even though the arguments are of type u8 *.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 88619f902c10..2cdb227fc39d 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -124,6 +124,10 @@ int crypto_enqueue_request(struct crypto_queue *queue,
 struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue);
 int crypto_tfm_in_queue(struct crypto_queue *queue, struct crypto_tfm *tfm);
 
+/* These functions require the input/output to be aligned as u32. */
+void crypto_inc(u8 *a, unsigned int size);
+void crypto_xor(u8 *dst, const u8 *src, unsigned int size);
+
 int blkcipher_walk_done(struct blkcipher_desc *desc,
 			struct blkcipher_walk *walk, int err);
 int blkcipher_walk_virt(struct blkcipher_desc *desc,

commit 332f8840f7095d294f9bb066b175a100bcde214c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Nov 15 22:36:07 2007 +0800

    [CRYPTO] ablkcipher: Add distinct ABLKCIPHER type
    
    Up until now we have ablkcipher algorithms have been identified as
    type BLKCIPHER with the ASYNC bit set.  This is suboptimal because
    ablkcipher refers to two things.  On the one hand it refers to the
    top-level ablkcipher interface with requests.  On the other hand it
    refers to and algorithm type underneath.
    
    As it is you cannot request a synchronous block cipher algorithm
    with the ablkcipher interface on top.  This is a problem because
    we want to be able to eventually phase out the blkcipher top-level
    interface.
    
    This patch fixes this by making ABLKCIPHER its own type, just as
    we have distinct types for HASH and DIGEST.  The type it associated
    with the algorithm implementation only.
    
    Which top-level interface is used for synchronous block ciphers is
    then determined by the mask that's used.  If it's a specific mask
    then the old blkcipher interface is given, otherwise we go with the
    new ablkcipher interface.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index b9b05d399d2b..88619f902c10 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -191,7 +191,7 @@ static inline struct crypto_ablkcipher *crypto_spawn_ablkcipher(
 	struct crypto_spawn *spawn)
 {
 	u32 type = CRYPTO_ALG_TYPE_BLKCIPHER;
-	u32 mask = CRYPTO_ALG_TYPE_MASK;
+	u32 mask = CRYPTO_ALG_TYPE_BLKCIPHER_MASK;
 
 	return __crypto_ablkcipher_cast(crypto_spawn_tfm(spawn, type, mask));
 }
@@ -200,7 +200,7 @@ static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
 	struct crypto_spawn *spawn)
 {
 	u32 type = CRYPTO_ALG_TYPE_BLKCIPHER;
-	u32 mask = CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_ASYNC;
+	u32 mask = CRYPTO_ALG_TYPE_MASK;
 
 	return __crypto_blkcipher_cast(crypto_spawn_tfm(spawn, type, mask));
 }

commit 7607bd8ff03b8af5af887931318cb2bb20361856
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Oct 4 15:24:05 2007 +0800

    [CRYPTO] blkcipher: Added blkcipher_walk_virt_block
    
    This patch adds the helper blkcipher_walk_virt_block which is similar to
    blkcipher_walk_virt but uses a supplied block size instead of the block
    size of the block cipher.  This is useful for CTR where the block size is
    1 but we still want to walk by the block size of the underlying cipher.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 4af72dc21202..b9b05d399d2b 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -91,6 +91,7 @@ struct blkcipher_walk {
 	u8 *iv;
 
 	int flags;
+	unsigned int blocksize;
 };
 
 extern const struct crypto_type crypto_ablkcipher_type;
@@ -129,6 +130,9 @@ int blkcipher_walk_virt(struct blkcipher_desc *desc,
 			struct blkcipher_walk *walk);
 int blkcipher_walk_phys(struct blkcipher_desc *desc,
 			struct blkcipher_walk *walk);
+int blkcipher_walk_virt_block(struct blkcipher_desc *desc,
+			      struct blkcipher_walk *walk,
+			      unsigned int blocksize);
 
 static inline void *crypto_tfm_ctx_aligned(struct crypto_tfm *tfm)
 {

commit 3c09f17c3d11f3e98928f55b600e6de22f58017a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Aug 30 16:24:15 2007 +0800

    [CRYPTO] aead: Add authenc
    
    This patch adds the authenc algorithm which constructs an AEAD algorithm
    from an asynchronous block cipher and a hash.  The construction is done
    by concatenating the encrypted result from the cipher with the output
    from the hash, as is used by the IPsec ESP protocol.
    
    The authenc algorithm exists as a template with four parameters:
    
            authenc(auth, authsize, enc, enckeylen).
    
    The authentication algorithm, the authentication size (i.e., truncating
    the output of the authentication algorithm), the encryption algorithm,
    and the encryption key length.  Both the size field and the key length
    field are in bytes.  For example, AES-128 with SHA1-HMAC would be
    represented by
    
            authenc(hmac(sha1), 12, cbc(aes), 16)
    
    The key for the authenc algorithm is the concatenation of the keys for
    the authentication algorithm with the encryption algorithm.  For the
    above example, if a key of length 36 bytes is given, then hmac(sha1)
    would receive the first 20 bytes while the last 16 would be given to
    cbc(aes).
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index cd721a7ce78f..4af72dc21202 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -112,7 +112,8 @@ struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 
 struct crypto_attr_type *crypto_get_attr_type(struct rtattr **tb);
 int crypto_check_attr_type(struct rtattr **tb, u32 type);
-struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb, u32 type, u32 mask);
+struct crypto_alg *crypto_attr_alg(struct rtattr *rta, u32 type, u32 mask);
+int crypto_attr_u32(struct rtattr *rta, u32 *num);
 struct crypto_instance *crypto_alloc_instance(const char *name,
 					      struct crypto_alg *alg);
 
@@ -171,6 +172,26 @@ static inline struct aead_alg *crypto_aead_alg(struct crypto_aead *tfm)
 	return &crypto_aead_tfm(tfm)->__crt_alg->cra_aead;
 }
 
+static inline void *crypto_aead_ctx(struct crypto_aead *tfm)
+{
+	return crypto_tfm_ctx(&tfm->base);
+}
+
+static inline struct crypto_instance *crypto_aead_alg_instance(
+	struct crypto_aead *aead)
+{
+	return crypto_tfm_alg_instance(&aead->base);
+}
+
+static inline struct crypto_ablkcipher *crypto_spawn_ablkcipher(
+	struct crypto_spawn *spawn)
+{
+	u32 type = CRYPTO_ALG_TYPE_BLKCIPHER;
+	u32 mask = CRYPTO_ALG_TYPE_MASK;
+
+	return __crypto_ablkcipher_cast(crypto_spawn_tfm(spawn, type, mask));
+}
+
 static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
 	struct crypto_spawn *spawn)
 {
@@ -257,5 +278,26 @@ static inline int ablkcipher_tfm_in_queue(struct crypto_queue *queue,
 	return crypto_tfm_in_queue(queue, crypto_ablkcipher_tfm(tfm));
 }
 
+static inline void *aead_request_ctx(struct aead_request *req)
+{
+	return req->__ctx;
+}
+
+static inline void aead_request_complete(struct aead_request *req, int err)
+{
+	req->base.complete(&req->base, err);
+}
+
+static inline u32 aead_request_flags(struct aead_request *req)
+{
+	return req->base.flags;
+}
+
+static inline struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb,
+						     u32 type, u32 mask)
+{
+	return crypto_attr_alg(tb[1], type, mask);
+}
+
 #endif	/* _CRYPTO_ALGAPI_H */
 

commit 2de98e75449fc1c43d2fbb857668ae62d4f5eece
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 26 19:12:47 2007 +0800

    [CRYPTO] ablkcipher: Remove queue pointer from common alg object
    
    Since not everyone needs a queue pointer and those who need it can
    always get it from the context anyway the queue pointer in the
    common alg object is redundant.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 290bce0c5bd5..cd721a7ce78f 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -234,16 +234,16 @@ static inline struct crypto_async_request *crypto_get_backlog(
 	       container_of(queue->backlog, struct crypto_async_request, list);
 }
 
-static inline int ablkcipher_enqueue_request(struct ablkcipher_alg *alg,
+static inline int ablkcipher_enqueue_request(struct crypto_queue *queue,
 					     struct ablkcipher_request *request)
 {
-	return crypto_enqueue_request(alg->queue, &request->base);
+	return crypto_enqueue_request(queue, &request->base);
 }
 
 static inline struct ablkcipher_request *ablkcipher_dequeue_request(
-	struct ablkcipher_alg *alg)
+	struct crypto_queue *queue)
 {
-	return ablkcipher_request_cast(crypto_dequeue_request(alg->queue));
+	return ablkcipher_request_cast(crypto_dequeue_request(queue));
 }
 
 static inline void *ablkcipher_request_ctx(struct ablkcipher_request *req)
@@ -251,10 +251,10 @@ static inline void *ablkcipher_request_ctx(struct ablkcipher_request *req)
 	return req->__ctx;
 }
 
-static inline int ablkcipher_tfm_in_queue(struct crypto_ablkcipher *tfm)
+static inline int ablkcipher_tfm_in_queue(struct crypto_queue *queue,
+					  struct crypto_ablkcipher *tfm)
 {
-	return crypto_tfm_in_queue(crypto_ablkcipher_alg(tfm)->queue,
-				   crypto_ablkcipher_tfm(tfm));
+	return crypto_tfm_in_queue(queue, crypto_ablkcipher_tfm(tfm));
 }
 
 #endif	/* _CRYPTO_ALGAPI_H */

commit 1ae978208e2ee9ba1b01d309164bc5e590cd242d
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Aug 30 15:36:14 2007 +0800

    [CRYPTO] api: Add aead crypto type
    
    This patch adds crypto_aead which is the interface for AEAD
    (Authenticated Encryption with Associated Data) algorithms.
    
    AEAD algorithms perform authentication and encryption in one
    step.  Traditionally users (such as IPsec) would use two
    different crypto algorithms to perform these.  With AEAD
    this comes down to one algorithm and one operation.
    
    Of course if traditional algorithms were used we'd still
    be doing two operations underneath.  However, real AEAD
    algorithms may allow the underlying operations to be
    optimised as well.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 8081294e4328..290bce0c5bd5 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -94,6 +94,7 @@ struct blkcipher_walk {
 };
 
 extern const struct crypto_type crypto_ablkcipher_type;
+extern const struct crypto_type crypto_aead_type;
 extern const struct crypto_type crypto_blkcipher_type;
 extern const struct crypto_type crypto_hash_type;
 
@@ -165,6 +166,11 @@ static inline void *crypto_ablkcipher_ctx_aligned(struct crypto_ablkcipher *tfm)
 	return crypto_tfm_ctx_aligned(&tfm->base);
 }
 
+static inline struct aead_alg *crypto_aead_alg(struct crypto_aead *tfm)
+{
+	return &crypto_aead_tfm(tfm)->__crt_alg->cra_aead;
+}
+
 static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
 	struct crypto_spawn *spawn)
 {

commit aa379a6ab17ff5b06552c52360ce6d9f8c7c209a
Author: Sebastian Siewior <sebastian@breakpoint.cc>
Date:   Thu Aug 2 20:41:53 2007 +0800

    [CRYPTO] api: Add crypto_ablkcipher_ctx_aligned
    
    This is function does the same thing for ablkcipher that is done for
    blkcipher by crypto_blkcipher_ctx_aligned(): it returns an aligned
    address of the private ctx.
    
    Signed-off-by: Sebastian Siewior <sebastian@breakpoint.cc>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index b2b1e6efd812..8081294e4328 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -160,6 +160,11 @@ static inline void *crypto_ablkcipher_ctx(struct crypto_ablkcipher *tfm)
 	return crypto_tfm_ctx(&tfm->base);
 }
 
+static inline void *crypto_ablkcipher_ctx_aligned(struct crypto_ablkcipher *tfm)
+{
+	return crypto_tfm_ctx_aligned(&tfm->base);
+}
+
 static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
 	struct crypto_spawn *spawn)
 {

commit 124b53d020622ffa24e27406f2373d5a3debd0d3
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Apr 16 20:49:20 2007 +1000

    [CRYPTO] cryptd: Add software async crypto daemon
    
    This patch adds the cryptd module which is a template that takes a
    synchronous software crypto algorithm and converts it to an asynchronous
    one by executing it in a kernel thread.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 7847fc2a03f0..b2b1e6efd812 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -138,6 +138,12 @@ static inline void *crypto_tfm_ctx_aligned(struct crypto_tfm *tfm)
 	return (void *)ALIGN(addr, align);
 }
 
+static inline struct crypto_instance *crypto_tfm_alg_instance(
+	struct crypto_tfm *tfm)
+{
+	return container_of(tfm->__crt_alg, struct crypto_instance, alg);
+}
+
 static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 {
 	return inst->__ctx;
@@ -154,6 +160,15 @@ static inline void *crypto_ablkcipher_ctx(struct crypto_ablkcipher *tfm)
 	return crypto_tfm_ctx(&tfm->base);
 }
 
+static inline struct crypto_blkcipher *crypto_spawn_blkcipher(
+	struct crypto_spawn *spawn)
+{
+	u32 type = CRYPTO_ALG_TYPE_BLKCIPHER;
+	u32 mask = CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_ASYNC;
+
+	return __crypto_blkcipher_cast(crypto_spawn_tfm(spawn, type, mask));
+}
+
 static inline void *crypto_blkcipher_ctx(struct crypto_blkcipher *tfm)
 {
 	return crypto_tfm_ctx(&tfm->base);

commit a73e69965fa2647faa36caf40f4132b9c99d61fd
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Apr 8 21:31:36 2007 +1000

    [CRYPTO] api: Do not remove users unless new algorithm matches
    
    As it is whenever a new algorithm with the same name is registered
    users of the old algorithm will be removed so that they can take
    advantage of the new algorithm.  This presents a problem when the
    new algorithm is not equivalent to the old algorithm.  In particular,
    the new algorithm might only function on top of the existing one.
    
    Hence we should not remove users unless they can make use of the
    new algorithm.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 469f511315c5..7847fc2a03f0 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -51,6 +51,7 @@ struct crypto_spawn {
 	struct list_head list;
 	struct crypto_alg *alg;
 	struct crypto_instance *inst;
+	u32 mask;
 };
 
 struct crypto_queue {
@@ -103,7 +104,7 @@ void crypto_unregister_template(struct crypto_template *tmpl);
 struct crypto_template *crypto_lookup_template(const char *name);
 
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
-		      struct crypto_instance *inst);
+		      struct crypto_instance *inst, u32 mask);
 void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 				    u32 mask);

commit b5b7f08869340aa8cfa23303f7d195f161479592
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Apr 16 20:48:54 2007 +1000

    [CRYPTO] api: Add async blkcipher type
    
    This patch adds the mid-level interface for asynchronous block ciphers.
    It also includes a generic queueing mechanism that can be used by other
    asynchronous crypto operations in future.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index d0c190b4d02f..469f511315c5 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -13,6 +13,8 @@
 #define _CRYPTO_ALGAPI_H
 
 #include <linux/crypto.h>
+#include <linux/list.h>
+#include <linux/kernel.h>
 
 struct module;
 struct rtattr;
@@ -51,6 +53,14 @@ struct crypto_spawn {
 	struct crypto_instance *inst;
 };
 
+struct crypto_queue {
+	struct list_head list;
+	struct list_head *backlog;
+
+	unsigned int qlen;
+	unsigned int max_qlen;
+};
+
 struct scatter_walk {
 	struct scatterlist *sg;
 	unsigned int offset;
@@ -82,6 +92,7 @@ struct blkcipher_walk {
 	int flags;
 };
 
+extern const struct crypto_type crypto_ablkcipher_type;
 extern const struct crypto_type crypto_blkcipher_type;
 extern const struct crypto_type crypto_hash_type;
 
@@ -103,6 +114,12 @@ struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb, u32 type, u32 mask);
 struct crypto_instance *crypto_alloc_instance(const char *name,
 					      struct crypto_alg *alg);
 
+void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen);
+int crypto_enqueue_request(struct crypto_queue *queue,
+			   struct crypto_async_request *request);
+struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue);
+int crypto_tfm_in_queue(struct crypto_queue *queue, struct crypto_tfm *tfm);
+
 int blkcipher_walk_done(struct blkcipher_desc *desc,
 			struct blkcipher_walk *walk, int err);
 int blkcipher_walk_virt(struct blkcipher_desc *desc,
@@ -125,6 +142,17 @@ static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 	return inst->__ctx;
 }
 
+static inline struct ablkcipher_alg *crypto_ablkcipher_alg(
+	struct crypto_ablkcipher *tfm)
+{
+	return &crypto_ablkcipher_tfm(tfm)->__crt_alg->cra_ablkcipher;
+}
+
+static inline void *crypto_ablkcipher_ctx(struct crypto_ablkcipher *tfm)
+{
+	return crypto_tfm_ctx(&tfm->base);
+}
+
 static inline void *crypto_blkcipher_ctx(struct crypto_blkcipher *tfm)
 {
 	return crypto_tfm_ctx(&tfm->base);
@@ -172,5 +200,35 @@ static inline void blkcipher_walk_init(struct blkcipher_walk *walk,
 	walk->total = nbytes;
 }
 
+static inline struct crypto_async_request *crypto_get_backlog(
+	struct crypto_queue *queue)
+{
+	return queue->backlog == &queue->list ? NULL :
+	       container_of(queue->backlog, struct crypto_async_request, list);
+}
+
+static inline int ablkcipher_enqueue_request(struct ablkcipher_alg *alg,
+					     struct ablkcipher_request *request)
+{
+	return crypto_enqueue_request(alg->queue, &request->base);
+}
+
+static inline struct ablkcipher_request *ablkcipher_dequeue_request(
+	struct ablkcipher_alg *alg)
+{
+	return ablkcipher_request_cast(crypto_dequeue_request(alg->queue));
+}
+
+static inline void *ablkcipher_request_ctx(struct ablkcipher_request *req)
+{
+	return req->__ctx;
+}
+
+static inline int ablkcipher_tfm_in_queue(struct crypto_ablkcipher *tfm)
+{
+	return crypto_tfm_in_queue(crypto_ablkcipher_alg(tfm)->queue,
+				   crypto_ablkcipher_tfm(tfm));
+}
+
 #endif	/* _CRYPTO_ALGAPI_H */
 

commit ebc610e5bc76df073221e64e86c3f7533a09ea40
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Jan 1 18:37:02 2007 +1100

    [CRYPTO] templates: Pass type/mask when creating instances
    
    This patch passes the type/mask along when constructing instances of
    templates.  This is in preparation for templates that may support
    multiple types of instances depending on what is requested.  For example,
    the planned software async crypto driver will use this construct.
    
    For the moment this allows us to check whether the instance constructed
    is of the correct type and avoid returning success if the type does not
    match.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 4e05e93ff681..d0c190b4d02f 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -15,6 +15,7 @@
 #include <linux/crypto.h>
 
 struct module;
+struct rtattr;
 struct seq_file;
 
 struct crypto_type {
@@ -38,7 +39,7 @@ struct crypto_template {
 	struct hlist_head instances;
 	struct module *module;
 
-	struct crypto_instance *(*alloc)(void *param, unsigned int len);
+	struct crypto_instance *(*alloc)(struct rtattr **tb);
 	void (*free)(struct crypto_instance *inst);
 
 	char name[CRYPTO_MAX_ALG_NAME];
@@ -96,8 +97,9 @@ void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
 				    u32 mask);
 
-struct crypto_alg *crypto_get_attr_alg(void *param, unsigned int len,
-				       u32 type, u32 mask);
+struct crypto_attr_type *crypto_get_attr_type(struct rtattr **tb);
+int crypto_check_attr_type(struct rtattr **tb, u32 type);
+struct crypto_alg *crypto_get_attr_alg(struct rtattr **tb, u32 type, u32 mask);
 struct crypto_instance *crypto_alloc_instance(const char *name,
 					      struct crypto_alg *alg);
 

commit 27d2a3300755387d2fec231d37944907ff992ce8
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jan 24 20:50:26 2007 +1100

    [CRYPTO] api: Allow multiple frontends per backend
    
    This patch adds support for multiple frontend types for each backend
    algorithm by passing the type and mask through to the backend type
    init function.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 99c534d573d2..4e05e93ff681 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -18,8 +18,8 @@ struct module;
 struct seq_file;
 
 struct crypto_type {
-	unsigned int (*ctxsize)(struct crypto_alg *alg);
-	int (*init)(struct crypto_tfm *tfm);
+	unsigned int (*ctxsize)(struct crypto_alg *alg, u32 type, u32 mask);
+	int (*init)(struct crypto_tfm *tfm, u32 type, u32 mask);
 	void (*exit)(struct crypto_tfm *tfm);
 	void (*show)(struct seq_file *m, struct crypto_alg *alg);
 };

commit 2e306ee016fd4750289e65c3b1856db569f1f3f2
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Dec 17 10:05:58 2006 +1100

    [CRYPTO] api: Add type-safe spawns
    
    This patch allows spawns of specific types (e.g., cipher) to be allocated.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 5748aecdb414..99c534d573d2 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -93,7 +93,8 @@ struct crypto_template *crypto_lookup_template(const char *name);
 int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 		      struct crypto_instance *inst);
 void crypto_drop_spawn(struct crypto_spawn *spawn);
-struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn);
+struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn, u32 type,
+				    u32 mask);
 
 struct crypto_alg *crypto_get_attr_alg(void *param, unsigned int len,
 				       u32 type, u32 mask);
@@ -132,11 +133,28 @@ static inline void *crypto_blkcipher_ctx_aligned(struct crypto_blkcipher *tfm)
 	return crypto_tfm_ctx_aligned(&tfm->base);
 }
 
+static inline struct crypto_cipher *crypto_spawn_cipher(
+	struct crypto_spawn *spawn)
+{
+	u32 type = CRYPTO_ALG_TYPE_CIPHER;
+	u32 mask = CRYPTO_ALG_TYPE_MASK;
+
+	return __crypto_cipher_cast(crypto_spawn_tfm(spawn, type, mask));
+}
+
 static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)
 {
 	return &crypto_cipher_tfm(tfm)->__crt_alg->cra_cipher;
 }
 
+static inline struct crypto_hash *crypto_spawn_hash(struct crypto_spawn *spawn)
+{
+	u32 type = CRYPTO_ALG_TYPE_HASH;
+	u32 mask = CRYPTO_ALG_TYPE_HASH_MASK;
+
+	return __crypto_hash_cast(crypto_spawn_tfm(spawn, type, mask));
+}
+
 static inline void *crypto_hash_ctx_aligned(struct crypto_hash *tfm)
 {
 	return crypto_tfm_ctx_aligned(&tfm->base);

commit 055bcee3102dc35f019b69df9c2618e9d6dd1c09
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Aug 19 22:24:23 2006 +1000

    [CRYPTO] digest: Added user API for new hash type
    
    The existing digest user interface is inadequate for support asynchronous
    operations.  For one it doesn't return a value to indicate success or
    failure, nor does it take a per-operation descriptor which is essential
    for the issuing of requests while other requests are still outstanding.
    
    This patch is the first in a series of steps to remodel the interface
    for asynchronous operations.
    
    For the ease of transition the new interface will be known as "hash"
    while the old one will remain as "digest".
    
    This patch also changes sg_next to allow chaining.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 444f602724db..5748aecdb414 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -82,6 +82,7 @@ struct blkcipher_walk {
 };
 
 extern const struct crypto_type crypto_blkcipher_type;
+extern const struct crypto_type crypto_hash_type;
 
 void crypto_mod_put(struct crypto_alg *alg);
 
@@ -136,6 +137,11 @@ static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)
 	return &crypto_cipher_tfm(tfm)->__crt_alg->cra_cipher;
 }
 
+static inline void *crypto_hash_ctx_aligned(struct crypto_hash *tfm)
+{
+	return crypto_tfm_ctx_aligned(&tfm->base);
+}
+
 static inline void blkcipher_walk_init(struct blkcipher_walk *walk,
 				       struct scatterlist *dst,
 				       struct scatterlist *src,

commit db131ef9084110d9e82549c0a627e157e8bb99d7
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Sep 21 11:44:08 2006 +1000

    [CRYPTO] cipher: Added block ciphers for CBC/ECB
    
    This patch adds two block cipher algorithms, CBC and ECB.  These
    are implemented as templates on top of existing single-block cipher
    algorithms.  They invoke the single-block cipher through the new
    encrypt_one/decrypt_one interface.
    
    This also optimises the in-place encryption and decryption to remove
    the cost of an IV copy each round.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index f3946baf0c07..444f602724db 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -83,6 +83,8 @@ struct blkcipher_walk {
 
 extern const struct crypto_type crypto_blkcipher_type;
 
+void crypto_mod_put(struct crypto_alg *alg);
+
 int crypto_register_template(struct crypto_template *tmpl);
 void crypto_unregister_template(struct crypto_template *tmpl);
 struct crypto_template *crypto_lookup_template(const char *name);

commit 5cde0af2a9825dd1edaca233bd9590566579ef21
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Aug 22 00:07:53 2006 +1000

    [CRYPTO] cipher: Added block cipher type
    
    This patch adds the new type of block ciphers.  Unlike current cipher
    algorithms which operate on a single block at a time, block ciphers
    operate on an arbitrarily long linear area of data.  As it is block-based,
    it will skip any data remaining at the end which cannot form a block.
    
    The block cipher has one major difference when compared to the existing
    block cipher implementation.  The sg walking is now performed by the
    algorithm rather than the cipher mid-layer.  This is needed for drivers
    that directly support sg lists.  It also improves performance for all
    algorithms as it reduces the total number of indirect calls by one.
    
    In future the existing cipher algorithm will be converted to only have
    a single-block interface.  This will be done after all existing users
    have switched over to the new block cipher type.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index f21ae672e8a8..f3946baf0c07 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -55,6 +55,34 @@ struct scatter_walk {
 	unsigned int offset;
 };
 
+struct blkcipher_walk {
+	union {
+		struct {
+			struct page *page;
+			unsigned long offset;
+		} phys;
+
+		struct {
+			u8 *page;
+			u8 *addr;
+		} virt;
+	} src, dst;
+
+	struct scatter_walk in;
+	unsigned int nbytes;
+
+	struct scatter_walk out;
+	unsigned int total;
+
+	void *page;
+	u8 *buffer;
+	u8 *iv;
+
+	int flags;
+};
+
+extern const struct crypto_type crypto_blkcipher_type;
+
 int crypto_register_template(struct crypto_template *tmpl);
 void crypto_unregister_template(struct crypto_template *tmpl);
 struct crypto_template *crypto_lookup_template(const char *name);
@@ -69,15 +97,52 @@ struct crypto_alg *crypto_get_attr_alg(void *param, unsigned int len,
 struct crypto_instance *crypto_alloc_instance(const char *name,
 					      struct crypto_alg *alg);
 
+int blkcipher_walk_done(struct blkcipher_desc *desc,
+			struct blkcipher_walk *walk, int err);
+int blkcipher_walk_virt(struct blkcipher_desc *desc,
+			struct blkcipher_walk *walk);
+int blkcipher_walk_phys(struct blkcipher_desc *desc,
+			struct blkcipher_walk *walk);
+
+static inline void *crypto_tfm_ctx_aligned(struct crypto_tfm *tfm)
+{
+	unsigned long addr = (unsigned long)crypto_tfm_ctx(tfm);
+	unsigned long align = crypto_tfm_alg_alignmask(tfm);
+
+	if (align <= crypto_tfm_ctx_alignment())
+		align = 1;
+	return (void *)ALIGN(addr, align);
+}
+
 static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 {
 	return inst->__ctx;
 }
 
+static inline void *crypto_blkcipher_ctx(struct crypto_blkcipher *tfm)
+{
+	return crypto_tfm_ctx(&tfm->base);
+}
+
+static inline void *crypto_blkcipher_ctx_aligned(struct crypto_blkcipher *tfm)
+{
+	return crypto_tfm_ctx_aligned(&tfm->base);
+}
+
 static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)
 {
 	return &crypto_cipher_tfm(tfm)->__crt_alg->cra_cipher;
 }
 
+static inline void blkcipher_walk_init(struct blkcipher_walk *walk,
+				       struct scatterlist *dst,
+				       struct scatterlist *src,
+				       unsigned int nbytes)
+{
+	walk->in.sg = src;
+	walk->out.sg = dst;
+	walk->total = nbytes;
+}
+
 #endif	/* _CRYPTO_ALGAPI_H */
 

commit 5c64097aa0f6dc4f27718ef47ca9a12538d62860
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Aug 12 21:56:17 2006 +1000

    [CRYPTO] scatterwalk: Prepare for block ciphers
    
    This patch prepares the scatterwalk code for use by the new block cipher
    type.
    
    Firstly it halves the size of scatter_walk on 32-bit platforms.  This
    is important as we allocate at least two of these objects on the stack
    for each block cipher operation.
    
    It also exports the symbols since the block cipher code can be built as
    a module.
    
    Finally there is a hack in scatterwalk_unmap that relies on progress
    being made.  Unfortunately, for hardware crypto we can't guarantee
    progress to be made since the hardware can fail.
    
    So this also gets rid of the hack by not advancing the address returned
    by scatterwalk_map.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 6f9fb27b2071..f21ae672e8a8 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -50,6 +50,11 @@ struct crypto_spawn {
 	struct crypto_instance *inst;
 };
 
+struct scatter_walk {
+	struct scatterlist *sg;
+	unsigned int offset;
+};
+
 int crypto_register_template(struct crypto_template *tmpl);
 void crypto_unregister_template(struct crypto_template *tmpl);
 struct crypto_template *crypto_lookup_template(const char *name);

commit f28776a369b12f9a03a822a8e1090ed670a41f4f
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 13 20:58:18 2006 +1000

    [CRYPTO] cipher: Added encrypt_one/decrypt_one
    
    This patch adds two new operations for the simple cipher that encrypts or
    decrypts a single block at a time.  This will be the main interface after
    the existing block operations have moved over to the new block ciphers.
    
    It also adds the crypto_cipher type which is currently only used on the
    new operations but will be extended to setkey as well once existing users
    have been converted to use block ciphers where applicable.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index c533c0a291af..6f9fb27b2071 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -69,5 +69,10 @@ static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 	return inst->__ctx;
 }
 
+static inline struct cipher_alg *crypto_cipher_alg(struct crypto_cipher *tfm)
+{
+	return &crypto_cipher_tfm(tfm)->__crt_alg->cra_cipher;
+}
+
 #endif	/* _CRYPTO_ALGAPI_H */
 

commit e853c3cfa8cc24869ecd2526e589bcb176bc12e9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Aug 22 00:06:54 2006 +1000

    [CRYPTO] api: Added crypto_type support
    
    This patch adds the crypto_type structure which will be used for all new
    crypto algorithm types, beginning with block ciphers.
    
    The primary purpose of this abstraction is to allow different crypto_type
    objects for crypto algorithms of the same type, in particular, there will
    be a different crypto_type objects for asynchronous algorithms.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index 1a598f829417..c533c0a291af 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -15,6 +15,14 @@
 #include <linux/crypto.h>
 
 struct module;
+struct seq_file;
+
+struct crypto_type {
+	unsigned int (*ctxsize)(struct crypto_alg *alg);
+	int (*init)(struct crypto_tfm *tfm);
+	void (*exit)(struct crypto_tfm *tfm);
+	void (*show)(struct seq_file *m, struct crypto_alg *alg);
+};
 
 struct crypto_instance {
 	struct crypto_alg alg;

commit 7fed0bf271b374be4c98a5880faed4b1128e78e9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 6 23:10:45 2006 +1000

    [CRYPTO] api: Add common instance initialisation code
    
    This patch adds the helpers crypto_get_attr_alg and crypto_alloc_instance
    which can be used by simple one-argument templates like hmac to process
    input parameters and allocate instances.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index b20f4bdb23ba..1a598f829417 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -51,6 +51,11 @@ int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
 void crypto_drop_spawn(struct crypto_spawn *spawn);
 struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn);
 
+struct crypto_alg *crypto_get_attr_alg(void *param, unsigned int len,
+				       u32 type, u32 mask);
+struct crypto_instance *crypto_alloc_instance(const char *name,
+					      struct crypto_alg *alg);
+
 static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 {
 	return inst->__ctx;

commit 6bfd48096ff8ecabf955958b51ddfa7988eb0a14
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Sep 21 11:39:29 2006 +1000

    [CRYPTO] api: Added spawns
    
    Spawns lock a specific crypto algorithm in place.  They can then be used
    with crypto_spawn_tfm to allocate a tfm for that algorithm.  When the base
    algorithm of a spawn is deregistered, all its spawns will be automatically
    removed.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index ffec530d52fb..b20f4bdb23ba 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -36,10 +36,21 @@ struct crypto_template {
 	char name[CRYPTO_MAX_ALG_NAME];
 };
 
+struct crypto_spawn {
+	struct list_head list;
+	struct crypto_alg *alg;
+	struct crypto_instance *inst;
+};
+
 int crypto_register_template(struct crypto_template *tmpl);
 void crypto_unregister_template(struct crypto_template *tmpl);
 struct crypto_template *crypto_lookup_template(const char *name);
 
+int crypto_init_spawn(struct crypto_spawn *spawn, struct crypto_alg *alg,
+		      struct crypto_instance *inst);
+void crypto_drop_spawn(struct crypto_spawn *spawn);
+struct crypto_tfm *crypto_spawn_tfm(struct crypto_spawn *spawn);
+
 static inline void *crypto_instance_ctx(struct crypto_instance *inst)
 {
 	return inst->__ctx;

commit 4cc7720cd165273b08a72b4193146dffee58e34b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 6 21:16:34 2006 +1000

    [CRYPTO] api: Add template registration
    
    A crypto_template generates a crypto_alg object when given a set of
    parameters.  this patch adds the basic data structure fo templates
    and code to handle their registration/deregistration.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
index ed68d494b364..ffec530d52fb 100644
--- a/include/crypto/algapi.h
+++ b/include/crypto/algapi.h
@@ -14,5 +14,36 @@
 
 #include <linux/crypto.h>
 
+struct module;
+
+struct crypto_instance {
+	struct crypto_alg alg;
+
+	struct crypto_template *tmpl;
+	struct hlist_node list;
+
+	void *__ctx[] CRYPTO_MINALIGN_ATTR;
+};
+
+struct crypto_template {
+	struct list_head list;
+	struct hlist_head instances;
+	struct module *module;
+
+	struct crypto_instance *(*alloc)(void *param, unsigned int len);
+	void (*free)(struct crypto_instance *inst);
+
+	char name[CRYPTO_MAX_ALG_NAME];
+};
+
+int crypto_register_template(struct crypto_template *tmpl);
+void crypto_unregister_template(struct crypto_template *tmpl);
+struct crypto_template *crypto_lookup_template(const char *name);
+
+static inline void *crypto_instance_ctx(struct crypto_instance *inst)
+{
+	return inst->__ctx;
+}
+
 #endif	/* _CRYPTO_ALGAPI_H */
 

commit cce9e06d100df19a327b19f23adad76e7bf63edd
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Aug 21 21:08:13 2006 +1000

    [CRYPTO] api: Split out low-level API
    
    The crypto API is made up of the part facing users such as IPsec and the
    low-level part which is used by cryptographic entities such as algorithms.
    This patch splits out the latter so that the two APIs are more clearly
    delineated.  As a bonus the low-level API can now be modularised if all
    algorithms are built as modules.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/include/crypto/algapi.h b/include/crypto/algapi.h
new file mode 100644
index 000000000000..ed68d494b364
--- /dev/null
+++ b/include/crypto/algapi.h
@@ -0,0 +1,18 @@
+/*
+ * Cryptographic API for algorithms (i.e., low-level API).
+ *
+ * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option) 
+ * any later version.
+ *
+ */
+#ifndef _CRYPTO_ALGAPI_H
+#define _CRYPTO_ALGAPI_H
+
+#include <linux/crypto.h>
+
+#endif	/* _CRYPTO_ALGAPI_H */
+
