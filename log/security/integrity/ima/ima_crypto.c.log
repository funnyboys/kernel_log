commit 20c59ce010f84300f6c655d32db2610d3433f85c
Author: Maurizio Drocco <maurizio.drocco@ibm.com>
Date:   Tue Jun 23 11:57:32 2020 -0400

    ima: extend boot_aggregate with kernel measurements
    
    Registers 8-9 are used to store measurements of the kernel and its
    command line (e.g., grub2 bootloader with tpm module enabled). IMA
    should include them in the boot aggregate. Registers 8-9 should be
    only included in non-SHA1 digests to avoid ambiguity.
    
    Signed-off-by: Maurizio Drocco <maurizio.drocco@ibm.com>
    Reviewed-by: Bruno Meneguele <bmeneg@redhat.com>
    Tested-by: Bruno Meneguele <bmeneg@redhat.com>  (TPM 1.2, TPM 2.0)
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 220b14920c37..011c3c76af86 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -823,13 +823,26 @@ static int ima_calc_boot_aggregate_tfm(char *digest, u16 alg_id,
 	if (rc != 0)
 		return rc;
 
-	/* cumulative sha1 over tpm registers 0-7 */
+	/* cumulative digest over TPM registers 0-7 */
 	for (i = TPM_PCR0; i < TPM_PCR8; i++) {
 		ima_pcrread(i, &d);
 		/* now accumulate with current aggregate */
 		rc = crypto_shash_update(shash, d.digest,
 					 crypto_shash_digestsize(tfm));
 	}
+	/*
+	 * Extend cumulative digest over TPM registers 8-9, which contain
+	 * measurement for the kernel command line (reg. 8) and image (reg. 9)
+	 * in a typical PCR allocation. Registers 8-9 are only included in
+	 * non-SHA1 boot_aggregate digests to avoid ambiguity.
+	 */
+	if (alg_id != TPM_ALG_SHA1) {
+		for (i = TPM_PCR8; i < TPM_PCR10; i++) {
+			ima_pcrread(i, &d);
+			rc = crypto_shash_update(shash, d.digest,
+						crypto_shash_digestsize(tfm));
+		}
+	}
 	if (!rc)
 		crypto_shash_final(shash, digest);
 	return rc;

commit 8b8c704d913b0fe490af370631a4200e26334ec0
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Sun Jun 7 23:00:29 2020 +0200

    ima: Remove __init annotation from ima_pcrread()
    
    Commit 6cc7c266e5b4 ("ima: Call ima_calc_boot_aggregate() in
    ima_eventdigest_init()") added a call to ima_calc_boot_aggregate() so that
    the digest can be recalculated for the boot_aggregate measurement entry if
    the 'd' template field has been requested. For the 'd' field, only SHA1 and
    MD5 digests are accepted.
    
    Given that ima_eventdigest_init() does not have the __init annotation, all
    functions called should not have it. This patch removes __init from
    ima_pcrread().
    
    Cc: stable@vger.kernel.org
    Fixes:  6cc7c266e5b4 ("ima: Call ima_calc_boot_aggregate() in ima_eventdigest_init()")
    Reported-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index ba5cc3264240..220b14920c37 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -786,7 +786,7 @@ int ima_calc_buffer_hash(const void *buf, loff_t len,
 	return calc_buffer_shash(buf, len, hash);
 }
 
-static void __init ima_pcrread(u32 idx, struct tpm_digest *d)
+static void ima_pcrread(u32 idx, struct tpm_digest *d)
 {
 	if (!ima_tpm_chip)
 		return;

commit 3c0ad98c2eda5ff30d23777e30744be6f7b8f097
Merge: aaa2faab4ed8 42413b49804b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jun 6 09:39:05 2020 -0700

    Merge tag 'integrity-v5.8' of git://git.kernel.org/pub/scm/linux/kernel/git/zohar/linux-integrity
    
    Pull integrity updates from Mimi Zohar:
     "The main changes are extending the TPM 2.0 PCR banks with bank
      specific file hashes, calculating the "boot_aggregate" based on other
      TPM PCR banks, using the default IMA hash algorithm, instead of SHA1,
      as the basis for the cache hash table key, and preventing the mprotect
      syscall to circumvent an IMA mmap appraise policy rule.
    
       - In preparation for extending TPM 2.0 PCR banks with bank specific
         digests, commit 0b6cf6b97b7e ("tpm: pass an array of
         tpm_extend_digest structures to tpm_pcr_extend()") modified
         tpm_pcr_extend(). The original SHA1 file digests were
         padded/truncated, before being extended into the other TPM PCR
         banks. This pull request calculates and extends the TPM PCR banks
         with bank specific file hashes completing the above change.
    
       - The "boot_aggregate", the first IMA measurement list record, is the
         "trusted boot" link between the pre-boot environment and the
         running OS. With TPM 2.0, the "boot_aggregate" record is not
         limited to being based on the SHA1 TPM PCR bank, but can be
         calculated based on any enabled bank, assuming the hash algorithm
         is also enabled in the kernel.
    
      Other changes include the following and five other bug fixes/code
      clean up:
    
       - supporting both a SHA1 and a larger "boot_aggregate" digest in a
         custom template format containing both the the SHA1 ('d') and
         larger digests ('d-ng') fields.
    
       - Initial hash table key fix, but additional changes would be good"
    
    * tag 'integrity-v5.8' of git://git.kernel.org/pub/scm/linux/kernel/git/zohar/linux-integrity:
      ima: Directly free *entry in ima_alloc_init_template() if digests is NULL
      ima: Call ima_calc_boot_aggregate() in ima_eventdigest_init()
      ima: Directly assign the ima_default_policy pointer to ima_rules
      ima: verify mprotect change is consistent with mmap policy
      evm: Fix possible memory leak in evm_calc_hmac_or_hash()
      ima: Set again build_ima_appraise variable
      ima: Remove redundant policy rule set in add_rules()
      ima: Fix ima digest hash table key calculation
      ima: Use ima_hash_algo for collision detection in the measurement list
      ima: Calculate and extend PCR with digests in ima_template_entry
      ima: Allocate and initialize tfm for each PCR bank
      ima: Switch to dynamically allocated buffer for template digests
      ima: Store template digest directly in ima_template_entry
      ima: Evaluate error in init_ima()
      ima: Switch to ima_hash_algo for boot aggregate

commit 6cc7c266e5b47d3cd2b5bb7fd3aac4e6bb2dd1d2
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Jun 3 17:08:21 2020 +0200

    ima: Call ima_calc_boot_aggregate() in ima_eventdigest_init()
    
    If the template field 'd' is chosen and the digest to be added to the
    measurement entry was not calculated with SHA1 or MD5, it is
    recalculated with SHA1, by using the passed file descriptor. However, this
    cannot be done for boot_aggregate, because there is no file descriptor.
    
    This patch adds a call to ima_calc_boot_aggregate() in
    ima_eventdigest_init(), so that the digest can be recalculated also for the
    boot_aggregate entry.
    
    Cc: stable@vger.kernel.org # 3.13.x
    Fixes: 3ce1217d6cd5d ("ima: define template fields library and new helpers")
    Reported-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 5201f5ec2ce4..002fdf6994d5 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -806,8 +806,8 @@ static void __init ima_pcrread(u32 idx, struct tpm_digest *d)
  * hash algorithm for reading the TPM PCRs as for calculating the boot
  * aggregate digest as stored in the measurement list.
  */
-static int __init ima_calc_boot_aggregate_tfm(char *digest, u16 alg_id,
-					      struct crypto_shash *tfm)
+static int ima_calc_boot_aggregate_tfm(char *digest, u16 alg_id,
+				       struct crypto_shash *tfm)
 {
 	struct tpm_digest d = { .alg_id = alg_id, .digest = {0} };
 	int rc;
@@ -835,7 +835,7 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest, u16 alg_id,
 	return rc;
 }
 
-int __init ima_calc_boot_aggregate(struct ima_digest_data *hash)
+int ima_calc_boot_aggregate(struct ima_digest_data *hash)
 {
 	struct crypto_shash *tfm;
 	u16 crypto_id, alg_id;

commit 0014cc04e8ec077dc482f00c87dfd949cfe2b98f
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Mon Apr 27 12:28:55 2020 +0200

    ima: Set file->f_mode instead of file->f_flags in ima_calc_file_hash()
    
    Commit a408e4a86b36 ("ima: open a new file instance if no read
    permissions") tries to create a new file descriptor to calculate a file
    digest if the file has not been opened with O_RDONLY flag. However, if a
    new file descriptor cannot be obtained, it sets the FMODE_READ flag to
    file->f_flags instead of file->f_mode.
    
    This patch fixes this issue by replacing f_flags with f_mode as it was
    before that commit.
    
    Cc: stable@vger.kernel.org # 4.20.x
    Fixes: a408e4a86b36 ("ima: open a new file instance if no read permissions")
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Reviewed-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 423c84f95a14..88b5e288f241 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -411,7 +411,7 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 	loff_t i_size;
 	int rc;
 	struct file *f = file;
-	bool new_file_instance = false, modified_flags = false;
+	bool new_file_instance = false, modified_mode = false;
 
 	/*
 	 * For consistency, fail file's opened with the O_DIRECT flag on
@@ -431,13 +431,13 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 		f = dentry_open(&file->f_path, flags, file->f_cred);
 		if (IS_ERR(f)) {
 			/*
-			 * Cannot open the file again, lets modify f_flags
+			 * Cannot open the file again, lets modify f_mode
 			 * of original and continue
 			 */
 			pr_info_ratelimited("Unable to reopen file for reading.\n");
 			f = file;
-			f->f_flags |= FMODE_READ;
-			modified_flags = true;
+			f->f_mode |= FMODE_READ;
+			modified_mode = true;
 		} else {
 			new_file_instance = true;
 		}
@@ -455,8 +455,8 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 out:
 	if (new_file_instance)
 		fput(f);
-	else if (modified_flags)
-		f->f_flags &= ~FMODE_READ;
+	else if (modified_mode)
+		f->f_mode &= ~FMODE_READ;
 	return rc;
 }
 

commit 2592677c0486e64a08e0b930a7dfa6fbf77e6fc1
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Mar 25 11:54:24 2020 +0100

    ima: Use ima_hash_algo for collision detection in the measurement list
    
    Before calculating a digest for each PCR bank, collisions were detected
    with a SHA1 digest. This patch includes ima_hash_algo among the algorithms
    used to calculate the template digest and checks collisions on that digest.
    
    The position in the measurement entry array of the template digest
    calculated with the IMA default hash algorithm is stored in the
    ima_hash_algo_idx global variable and is determined at IMA initialization
    time.
    
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index a94972d3f929..5201f5ec2ce4 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -63,6 +63,7 @@ struct ima_algo_desc {
 };
 
 int ima_sha1_idx __ro_after_init;
+int ima_hash_algo_idx __ro_after_init;
 /*
  * Additional number of slots reserved, as needed, for SHA1
  * and IMA default algo.
@@ -122,15 +123,25 @@ int __init ima_init_crypto(void)
 		return rc;
 
 	ima_sha1_idx = -1;
+	ima_hash_algo_idx = -1;
 
 	for (i = 0; i < NR_BANKS(ima_tpm_chip); i++) {
 		algo = ima_tpm_chip->allocated_banks[i].crypto_id;
 		if (algo == HASH_ALGO_SHA1)
 			ima_sha1_idx = i;
+
+		if (algo == ima_hash_algo)
+			ima_hash_algo_idx = i;
 	}
 
-	if (ima_sha1_idx < 0)
+	if (ima_sha1_idx < 0) {
 		ima_sha1_idx = NR_BANKS(ima_tpm_chip) + ima_extra_slots++;
+		if (ima_hash_algo == HASH_ALGO_SHA1)
+			ima_hash_algo_idx = ima_sha1_idx;
+	}
+
+	if (ima_hash_algo_idx < 0)
+		ima_hash_algo_idx = NR_BANKS(ima_tpm_chip) + ima_extra_slots++;
 
 	ima_algo_array = kcalloc(NR_BANKS(ima_tpm_chip) + ima_extra_slots,
 				 sizeof(*ima_algo_array), GFP_KERNEL);
@@ -179,6 +190,12 @@ int __init ima_init_crypto(void)
 		ima_algo_array[ima_sha1_idx].algo = HASH_ALGO_SHA1;
 	}
 
+	if (ima_hash_algo_idx >= NR_BANKS(ima_tpm_chip) &&
+	    ima_hash_algo_idx != ima_sha1_idx) {
+		ima_algo_array[ima_hash_algo_idx].tfm = ima_shash_tfm;
+		ima_algo_array[ima_hash_algo_idx].algo = ima_hash_algo;
+	}
+
 	return 0;
 out_array:
 	for (i = 0; i < NR_BANKS(ima_tpm_chip) + ima_extra_slots; i++) {

commit 1ea973df6e2166d1a576cabe5d08925d3261ff9d
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Mar 25 11:53:50 2020 +0100

    ima: Calculate and extend PCR with digests in ima_template_entry
    
    This patch modifies ima_calc_field_array_hash() to calculate a template
    digest for each allocated PCR bank and SHA1. It also passes the tpm_digest
    array of the template entry to ima_pcr_extend() or in case of a violation,
    the pre-initialized digests array filled with 0xff.
    
    Padding with zeros is still done if the mapping between TPM algorithm ID
    and crypto ID is unknown.
    
    This patch calculates again the template digest when a measurement list is
    restored. Copying only the SHA1 digest (due to the limitation of the
    current measurement list format) is not sufficient, as hash collision
    detection will be done on the digest calculated with the IMA default hash
    algorithm.
    
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index ab1c05ad1314..a94972d3f929 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -619,9 +619,36 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 int ima_calc_field_array_hash(struct ima_field_data *field_data,
 			      struct ima_template_entry *entry)
 {
-	int rc;
+	u16 alg_id;
+	int rc, i;
 
 	rc = ima_calc_field_array_hash_tfm(field_data, entry, ima_sha1_idx);
+	if (rc)
+		return rc;
+
+	entry->digests[ima_sha1_idx].alg_id = TPM_ALG_SHA1;
+
+	for (i = 0; i < NR_BANKS(ima_tpm_chip) + ima_extra_slots; i++) {
+		if (i == ima_sha1_idx)
+			continue;
+
+		if (i < NR_BANKS(ima_tpm_chip)) {
+			alg_id = ima_tpm_chip->allocated_banks[i].alg_id;
+			entry->digests[i].alg_id = alg_id;
+		}
+
+		/* for unmapped TPM algorithms digest is still a padded SHA1 */
+		if (!ima_algo_array[i].tfm) {
+			memcpy(entry->digests[i].digest,
+			       entry->digests[ima_sha1_idx].digest,
+			       TPM_DIGEST_SIZE);
+			continue;
+		}
+
+		rc = ima_calc_field_array_hash_tfm(field_data, entry, i);
+		if (rc)
+			return rc;
+	}
 	return rc;
 }
 

commit 6d94809af6b0830c4dfcad661535a5939bcb8a7d
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Mar 25 11:52:48 2020 +0100

    ima: Allocate and initialize tfm for each PCR bank
    
    This patch creates a crypto_shash structure for each allocated PCR bank and
    for SHA1 if a bank with that algorithm is not currently allocated.
    
    Reported-by: kbuild test robot <lkp@intel.com>
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index fe02eb28b32b..ab1c05ad1314 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -57,14 +57,21 @@ MODULE_PARM_DESC(ahash_bufsize, "Maximum ahash buffer size");
 static struct crypto_shash *ima_shash_tfm;
 static struct crypto_ahash *ima_ahash_tfm;
 
+struct ima_algo_desc {
+	struct crypto_shash *tfm;
+	enum hash_algo algo;
+};
+
 int ima_sha1_idx __ro_after_init;
 /*
  * Additional number of slots reserved, as needed, for SHA1
  * and IMA default algo.
  */
-int ima_extra_slots __ro_after_init = 1;
+int ima_extra_slots __ro_after_init;
 
-int __init ima_init_crypto(void)
+static struct ima_algo_desc *ima_algo_array;
+
+static int __init ima_init_ima_crypto(void)
 {
 	long rc;
 
@@ -83,26 +90,121 @@ int __init ima_init_crypto(void)
 static struct crypto_shash *ima_alloc_tfm(enum hash_algo algo)
 {
 	struct crypto_shash *tfm = ima_shash_tfm;
-	int rc;
+	int rc, i;
 
 	if (algo < 0 || algo >= HASH_ALGO__LAST)
 		algo = ima_hash_algo;
 
-	if (algo != ima_hash_algo) {
-		tfm = crypto_alloc_shash(hash_algo_name[algo], 0, 0);
-		if (IS_ERR(tfm)) {
-			rc = PTR_ERR(tfm);
-			pr_err("Can not allocate %s (reason: %d)\n",
-			       hash_algo_name[algo], rc);
-		}
+	if (algo == ima_hash_algo)
+		return tfm;
+
+	for (i = 0; i < NR_BANKS(ima_tpm_chip) + ima_extra_slots; i++)
+		if (ima_algo_array[i].tfm && ima_algo_array[i].algo == algo)
+			return ima_algo_array[i].tfm;
+
+	tfm = crypto_alloc_shash(hash_algo_name[algo], 0, 0);
+	if (IS_ERR(tfm)) {
+		rc = PTR_ERR(tfm);
+		pr_err("Can not allocate %s (reason: %d)\n",
+		       hash_algo_name[algo], rc);
 	}
 	return tfm;
 }
 
+int __init ima_init_crypto(void)
+{
+	enum hash_algo algo;
+	long rc;
+	int i;
+
+	rc = ima_init_ima_crypto();
+	if (rc)
+		return rc;
+
+	ima_sha1_idx = -1;
+
+	for (i = 0; i < NR_BANKS(ima_tpm_chip); i++) {
+		algo = ima_tpm_chip->allocated_banks[i].crypto_id;
+		if (algo == HASH_ALGO_SHA1)
+			ima_sha1_idx = i;
+	}
+
+	if (ima_sha1_idx < 0)
+		ima_sha1_idx = NR_BANKS(ima_tpm_chip) + ima_extra_slots++;
+
+	ima_algo_array = kcalloc(NR_BANKS(ima_tpm_chip) + ima_extra_slots,
+				 sizeof(*ima_algo_array), GFP_KERNEL);
+	if (!ima_algo_array) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < NR_BANKS(ima_tpm_chip); i++) {
+		algo = ima_tpm_chip->allocated_banks[i].crypto_id;
+		ima_algo_array[i].algo = algo;
+
+		/* unknown TPM algorithm */
+		if (algo == HASH_ALGO__LAST)
+			continue;
+
+		if (algo == ima_hash_algo) {
+			ima_algo_array[i].tfm = ima_shash_tfm;
+			continue;
+		}
+
+		ima_algo_array[i].tfm = ima_alloc_tfm(algo);
+		if (IS_ERR(ima_algo_array[i].tfm)) {
+			if (algo == HASH_ALGO_SHA1) {
+				rc = PTR_ERR(ima_algo_array[i].tfm);
+				ima_algo_array[i].tfm = NULL;
+				goto out_array;
+			}
+
+			ima_algo_array[i].tfm = NULL;
+		}
+	}
+
+	if (ima_sha1_idx >= NR_BANKS(ima_tpm_chip)) {
+		if (ima_hash_algo == HASH_ALGO_SHA1) {
+			ima_algo_array[ima_sha1_idx].tfm = ima_shash_tfm;
+		} else {
+			ima_algo_array[ima_sha1_idx].tfm =
+						ima_alloc_tfm(HASH_ALGO_SHA1);
+			if (IS_ERR(ima_algo_array[ima_sha1_idx].tfm)) {
+				rc = PTR_ERR(ima_algo_array[ima_sha1_idx].tfm);
+				goto out_array;
+			}
+		}
+
+		ima_algo_array[ima_sha1_idx].algo = HASH_ALGO_SHA1;
+	}
+
+	return 0;
+out_array:
+	for (i = 0; i < NR_BANKS(ima_tpm_chip) + ima_extra_slots; i++) {
+		if (!ima_algo_array[i].tfm ||
+		    ima_algo_array[i].tfm == ima_shash_tfm)
+			continue;
+
+		crypto_free_shash(ima_algo_array[i].tfm);
+	}
+out:
+	crypto_free_shash(ima_shash_tfm);
+	return rc;
+}
+
 static void ima_free_tfm(struct crypto_shash *tfm)
 {
-	if (tfm != ima_shash_tfm)
-		crypto_free_shash(tfm);
+	int i;
+
+	if (tfm == ima_shash_tfm)
+		return;
+
+	for (i = 0; i < NR_BANKS(ima_tpm_chip) + ima_extra_slots; i++)
+		if (ima_algo_array[i].tfm == tfm)
+			return;
+
+	crypto_free_shash(tfm);
 }
 
 /**
@@ -472,14 +574,14 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
  */
 static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 					 struct ima_template_entry *entry,
-					 struct crypto_shash *tfm)
+					 int tfm_idx)
 {
-	SHASH_DESC_ON_STACK(shash, tfm);
+	SHASH_DESC_ON_STACK(shash, ima_algo_array[tfm_idx].tfm);
 	struct ima_template_desc *td = entry->template_desc;
 	int num_fields = entry->template_desc->num_fields;
 	int rc, i;
 
-	shash->tfm = tfm;
+	shash->tfm = ima_algo_array[tfm_idx].tfm;
 
 	rc = crypto_shash_init(shash);
 	if (rc != 0)
@@ -509,8 +611,7 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 	}
 
 	if (!rc)
-		rc = crypto_shash_final(shash,
-					entry->digests[ima_sha1_idx].digest);
+		rc = crypto_shash_final(shash, entry->digests[tfm_idx].digest);
 
 	return rc;
 }
@@ -518,17 +619,9 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 int ima_calc_field_array_hash(struct ima_field_data *field_data,
 			      struct ima_template_entry *entry)
 {
-	struct crypto_shash *tfm;
 	int rc;
 
-	tfm = ima_alloc_tfm(HASH_ALGO_SHA1);
-	if (IS_ERR(tfm))
-		return PTR_ERR(tfm);
-
-	rc = ima_calc_field_array_hash_tfm(field_data, entry, tfm);
-
-	ima_free_tfm(tfm);
-
+	rc = ima_calc_field_array_hash_tfm(field_data, entry, ima_sha1_idx);
 	return rc;
 }
 

commit aa724fe18a8a8285d0071c3bfc932efb090d142d
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Mar 25 11:47:09 2020 +0100

    ima: Switch to dynamically allocated buffer for template digests
    
    This patch dynamically allocates the array of tpm_digest structures in
    ima_alloc_init_template() and ima_restore_template_data(). The size of the
    array is equal to the number of PCR banks plus ima_extra_slots, to make
    room for SHA1 and the IMA default hash algorithm, when PCR banks with those
    algorithms are not allocated.
    
    Calculating the SHA1 digest is mandatory, as SHA1 still remains the default
    hash algorithm for the measurement list. When IMA will support the Crypto
    Agile format, remaining digests will be also provided.
    
    The position in the measurement entry array of the SHA1 digest is stored in
    the ima_sha1_idx global variable and is determined at IMA initialization
    time.
    
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 03d73a4009ab..fe02eb28b32b 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -57,6 +57,13 @@ MODULE_PARM_DESC(ahash_bufsize, "Maximum ahash buffer size");
 static struct crypto_shash *ima_shash_tfm;
 static struct crypto_ahash *ima_ahash_tfm;
 
+int ima_sha1_idx __ro_after_init;
+/*
+ * Additional number of slots reserved, as needed, for SHA1
+ * and IMA default algo.
+ */
+int ima_extra_slots __ro_after_init = 1;
+
 int __init ima_init_crypto(void)
 {
 	long rc;
@@ -502,7 +509,8 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 	}
 
 	if (!rc)
-		rc = crypto_shash_final(shash, entry->digest);
+		rc = crypto_shash_final(shash,
+					entry->digests[ima_sha1_idx].digest);
 
 	return rc;
 }

commit 7ca79645a1f8837c3850b881a2c0b43cfba5dc36
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Mar 25 11:47:08 2020 +0100

    ima: Store template digest directly in ima_template_entry
    
    In preparation for the patch that calculates a digest for each allocated
    PCR bank, this patch passes to ima_calc_field_array_hash() the
    ima_template_entry structure, so that digests can be directly stored in
    that structure instead of ima_digest_data.
    
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 8e445a671225..03d73a4009ab 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -464,18 +464,16 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
  * Calculate the hash of template data
  */
 static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
-					 struct ima_template_desc *td,
-					 int num_fields,
-					 struct ima_digest_data *hash,
+					 struct ima_template_entry *entry,
 					 struct crypto_shash *tfm)
 {
 	SHASH_DESC_ON_STACK(shash, tfm);
+	struct ima_template_desc *td = entry->template_desc;
+	int num_fields = entry->template_desc->num_fields;
 	int rc, i;
 
 	shash->tfm = tfm;
 
-	hash->length = crypto_shash_digestsize(tfm);
-
 	rc = crypto_shash_init(shash);
 	if (rc != 0)
 		return rc;
@@ -504,24 +502,22 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 	}
 
 	if (!rc)
-		rc = crypto_shash_final(shash, hash->digest);
+		rc = crypto_shash_final(shash, entry->digest);
 
 	return rc;
 }
 
 int ima_calc_field_array_hash(struct ima_field_data *field_data,
-			      struct ima_template_desc *desc, int num_fields,
-			      struct ima_digest_data *hash)
+			      struct ima_template_entry *entry)
 {
 	struct crypto_shash *tfm;
 	int rc;
 
-	tfm = ima_alloc_tfm(hash->algo);
+	tfm = ima_alloc_tfm(HASH_ALGO_SHA1);
 	if (IS_ERR(tfm))
 		return PTR_ERR(tfm);
 
-	rc = ima_calc_field_array_hash_tfm(field_data, desc, num_fields,
-					   hash, tfm);
+	rc = ima_calc_field_array_hash_tfm(field_data, entry, tfm);
 
 	ima_free_tfm(tfm);
 

commit 6f1a1d103b48b1533a9c804e7a069e2c8e937ce7
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Mar 25 11:47:06 2020 +0100

    ima: Switch to ima_hash_algo for boot aggregate
    
    boot_aggregate is the first entry of IMA measurement list. Its purpose is
    to link pre-boot measurements to IMA measurements. As IMA was designed to
    work with a TPM 1.2, the SHA1 PCR bank was always selected even if a
    TPM 2.0 with support for stronger hash algorithms is available.
    
    This patch first tries to find a PCR bank with the IMA default hash
    algorithm. If it does not find it, it selects the SHA256 PCR bank for
    TPM 2.0 and SHA1 for TPM 1.2. Ultimately, it selects SHA1 also for TPM 2.0
    if the SHA256 PCR bank is not found.
    
    If none of the PCR banks above can be found, boot_aggregate file digest is
    filled with zeros, as for TPM bypass, making it impossible to perform a
    remote attestation of the system.
    
    Cc: stable@vger.kernel.org # 5.1.x
    Fixes: 879b589210a9 ("tpm: retrieve digest size of unknown algorithms with PCR read")
    Reported-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Suggested-by: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 423c84f95a14..8e445a671225 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -655,18 +655,29 @@ static void __init ima_pcrread(u32 idx, struct tpm_digest *d)
 }
 
 /*
- * Calculate the boot aggregate hash
+ * The boot_aggregate is a cumulative hash over TPM registers 0 - 7.  With
+ * TPM 1.2 the boot_aggregate was based on reading the SHA1 PCRs, but with
+ * TPM 2.0 hash agility, TPM chips could support multiple TPM PCR banks,
+ * allowing firmware to configure and enable different banks.
+ *
+ * Knowing which TPM bank is read to calculate the boot_aggregate digest
+ * needs to be conveyed to a verifier.  For this reason, use the same
+ * hash algorithm for reading the TPM PCRs as for calculating the boot
+ * aggregate digest as stored in the measurement list.
  */
-static int __init ima_calc_boot_aggregate_tfm(char *digest,
+static int __init ima_calc_boot_aggregate_tfm(char *digest, u16 alg_id,
 					      struct crypto_shash *tfm)
 {
-	struct tpm_digest d = { .alg_id = TPM_ALG_SHA1, .digest = {0} };
+	struct tpm_digest d = { .alg_id = alg_id, .digest = {0} };
 	int rc;
 	u32 i;
 	SHASH_DESC_ON_STACK(shash, tfm);
 
 	shash->tfm = tfm;
 
+	pr_devel("calculating the boot-aggregate based on TPM bank: %04x\n",
+		 d.alg_id);
+
 	rc = crypto_shash_init(shash);
 	if (rc != 0)
 		return rc;
@@ -675,7 +686,8 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest,
 	for (i = TPM_PCR0; i < TPM_PCR8; i++) {
 		ima_pcrread(i, &d);
 		/* now accumulate with current aggregate */
-		rc = crypto_shash_update(shash, d.digest, TPM_DIGEST_SIZE);
+		rc = crypto_shash_update(shash, d.digest,
+					 crypto_shash_digestsize(tfm));
 	}
 	if (!rc)
 		crypto_shash_final(shash, digest);
@@ -685,14 +697,37 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest,
 int __init ima_calc_boot_aggregate(struct ima_digest_data *hash)
 {
 	struct crypto_shash *tfm;
-	int rc;
+	u16 crypto_id, alg_id;
+	int rc, i, bank_idx = -1;
+
+	for (i = 0; i < ima_tpm_chip->nr_allocated_banks; i++) {
+		crypto_id = ima_tpm_chip->allocated_banks[i].crypto_id;
+		if (crypto_id == hash->algo) {
+			bank_idx = i;
+			break;
+		}
+
+		if (crypto_id == HASH_ALGO_SHA256)
+			bank_idx = i;
+
+		if (bank_idx == -1 && crypto_id == HASH_ALGO_SHA1)
+			bank_idx = i;
+	}
+
+	if (bank_idx == -1) {
+		pr_err("No suitable TPM algorithm for boot aggregate\n");
+		return 0;
+	}
+
+	hash->algo = ima_tpm_chip->allocated_banks[bank_idx].crypto_id;
 
 	tfm = ima_alloc_tfm(hash->algo);
 	if (IS_ERR(tfm))
 		return PTR_ERR(tfm);
 
 	hash->length = crypto_shash_digestsize(tfm);
-	rc = ima_calc_boot_aggregate_tfm(hash->digest, tfm);
+	alg_id = ima_tpm_chip->allocated_banks[bank_idx].alg_id;
+	rc = ima_calc_boot_aggregate_tfm(hash->digest, alg_id, tfm);
 
 	ima_free_tfm(tfm);
 

commit 555d6d71d57c4a2e4ff750f6a41d2b7d7c861863
Author: Tushar Sugandhi <tusharsu@linux.microsoft.com>
Date:   Tue Feb 18 16:06:11 2020 -0800

    integrity: Remove duplicate pr_fmt definitions
    
    The #define for formatting log messages, pr_fmt, is duplicated in the
    files under security/integrity.
    
    This change moves the definition to security/integrity/integrity.h and
    removes the duplicate definitions in the other files under
    security/integrity.
    
    With this change, the messages in the following files will be prefixed
    with 'integrity'.
    
         security/integrity/platform_certs/platform_keyring.c
         security/integrity/platform_certs/load_powerpc.c
         security/integrity/platform_certs/load_uefi.c
         security/integrity/iint.c
    
         e.g. "integrity: Error adding keys to platform keyring %s\n"
    
    And the messages in the following file will be prefixed with 'ima'.
    
         security/integrity/ima/ima_mok.c
    
         e.g. "ima: Allocating IMA blacklist keyring.\n"
    
    For the rest of the files under security/integrity, there will be no
    change in the message format.
    
    Suggested-by: Shuah Khan <skhan@linuxfoundation.org>
    Suggested-by: Joe Perches <joe@perches.com>
    Signed-off-by: Tushar Sugandhi <tusharsu@linux.microsoft.com>
    Reviewed-by: Lakshmi Ramasubramanian <nramas@linux.microsoft.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 7967a6904851..423c84f95a14 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -10,8 +10,6 @@
  *	Calculates md5/sha1 file hash, template hash, boot-aggreate hash
  */
 
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
 #include <linux/kernel.h>
 #include <linux/moduleparam.h>
 #include <linux/ratelimit.h>

commit 96c9e1de99545ce4be1b5e7dff217a896ba96d06
Author: Patrick Callaghan <patrickc@linux.ibm.com>
Date:   Mon Nov 11 14:23:48 2019 -0500

    ima: avoid appraise error for hash calc interrupt
    
    The integrity_kernel_read() call in ima_calc_file_hash_tfm() can return
    a value of 0 before all bytes of the file are read. A value of 0 would
    normally indicate an EOF. This has been observed if a user process is
    causing a file appraisal and is terminated with a SIGTERM signal. The
    most common occurrence of seeing the problem is if a shutdown or systemd
    reload is initiated while files are being appraised.
    
    The problem is similar to commit <f5e1040196db> (ima: always return
    negative code for error) that fixed the problem in
    ima_calc_file_hash_atfm().
    
    Suggested-by: Mimi Zohar <zohar@linux.ibm.com>
    Signed-off-by: Patrick Callaghan <patrickc@linux.ibm.com>
    Reviewed-by: Sascha Hauer <s.hauer@pengutronix.de>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 73044fc6a952..7967a6904851 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -362,8 +362,10 @@ static int ima_calc_file_hash_tfm(struct file *file,
 			rc = rbuf_len;
 			break;
 		}
-		if (rbuf_len == 0)
+		if (rbuf_len == 0) {	/* unexpected EOF */
+			rc = -EINVAL;
 			break;
+		}
 		offset += rbuf_len;
 
 		rc = crypto_shash_update(shash, rbuf, rbuf_len);

commit 4ece3125f21b1d42b84896c5646dbf0e878464e1
Author: Sascha Hauer <s.hauer@pengutronix.de>
Date:   Tue Jul 2 10:00:41 2019 +0200

    ima: fix freeing ongoing ahash_request
    
    integrity_kernel_read() can fail in which case we forward to call
    ahash_request_free() on a currently running request. We have to wait
    for its completion before we can free the request.
    
    This was observed by interrupting a "find / -type f -xdev -print0 | xargs -0
    cat 1>/dev/null" with ctrl-c on an IMA enabled filesystem.
    
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 7532b062be59..73044fc6a952 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -271,6 +271,11 @@ static int ima_calc_file_hash_atfm(struct file *file,
 		if (rc != rbuf_len) {
 			if (rc >= 0)
 				rc = -EINVAL;
+			/*
+			 * Forward current rc, do not overwrite with return value
+			 * from ahash_wait()
+			 */
+			ahash_wait(ahash_rc, &wait);
 			goto out3;
 		}
 

commit f5e1040196dbfe14c77ce3dfe3b7b08d2d961e88
Author: Sascha Hauer <s.hauer@pengutronix.de>
Date:   Tue Jul 2 10:00:40 2019 +0200

    ima: always return negative code for error
    
    integrity_kernel_read() returns the number of bytes read. If this is
    a short read then this positive value is returned from
    ima_calc_file_hash_atfm(). Currently this is only indirectly called from
    ima_calc_file_hash() and this function only tests for the return value
    being zero or nonzero and also doesn't forward the return value.
    Nevertheless there's no point in returning a positive value as an error,
    so translate a short read into -EINVAL.
    
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index d4c7b8e1b083..7532b062be59 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -268,8 +268,11 @@ static int ima_calc_file_hash_atfm(struct file *file,
 		rbuf_len = min_t(loff_t, i_size - offset, rbuf_size[active]);
 		rc = integrity_kernel_read(file, offset, rbuf[active],
 					   rbuf_len);
-		if (rc != rbuf_len)
+		if (rc != rbuf_len) {
+			if (rc >= 0)
+				rc = -EINVAL;
 			goto out3;
+		}
 
 		if (rbuf[1] && offset) {
 			/* Using two buffers, and it is not the first

commit b886d83c5b621abc84ff9616f14c529be3f6b147
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jun 1 10:08:55 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 441
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation version 2 of the license
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 315 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Armijn Hemel <armijn@tjaldur.nl>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190531190115.503150771@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index a32878e10ebc..d4c7b8e1b083 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Copyright (C) 2005,2006,2007,2008 IBM Corporation
  *
@@ -5,10 +6,6 @@
  * Mimi Zohar <zohar@us.ibm.com>
  * Kylene Hall <kjhall@us.ibm.com>
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation, version 2 of the License.
- *
  * File: ima_crypto.c
  *	Calculates md5/sha1 file hash, template hash, boot-aggreate hash
  */

commit 877b5691f27a1aec0d9b53095a323e45c30069e2
Author: Eric Biggers <ebiggers@google.com>
Date:   Sun Apr 14 17:37:09 2019 -0700

    crypto: shash - remove shash_desc::flags
    
    The flags field in 'struct shash_desc' never actually does anything.
    The only ostensibly supported flag is CRYPTO_TFM_REQ_MAY_SLEEP.
    However, no shash algorithm ever sleeps, making this flag a no-op.
    
    With this being the case, inevitably some users who can't sleep wrongly
    pass MAY_SLEEP.  These would all need to be fixed if any shash algorithm
    actually started sleeping.  For example, the shash_ahash_*() functions,
    which wrap a shash algorithm with the ahash API, pass through MAY_SLEEP
    from the ahash API to the shash API.  However, the shash functions are
    called under kmap_atomic(), so actually they're assumed to never sleep.
    
    Even if it turns out that some users do need preemption points while
    hashing large buffers, we could easily provide a helper function
    crypto_shash_update_large() which divides the data into smaller chunks
    and calls crypto_shash_update() and cond_resched() for each chunk.  It's
    not necessary to have a flag in 'struct shash_desc', nor is it necessary
    to make individual shash algorithms aware of this at all.
    
    Therefore, remove shash_desc::flags, and document that the
    crypto_shash_*() functions can be called from any context.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 16a4f45863b1..a32878e10ebc 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -333,7 +333,6 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	SHASH_DESC_ON_STACK(shash, tfm);
 
 	shash->tfm = tfm;
-	shash->flags = 0;
 
 	hash->length = crypto_shash_digestsize(tfm);
 
@@ -469,7 +468,6 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 	int rc, i;
 
 	shash->tfm = tfm;
-	shash->flags = 0;
 
 	hash->length = crypto_shash_digestsize(tfm);
 
@@ -591,7 +589,6 @@ static int calc_buffer_shash_tfm(const void *buf, loff_t size,
 	int rc;
 
 	shash->tfm = tfm;
-	shash->flags = 0;
 
 	hash->length = crypto_shash_digestsize(tfm);
 
@@ -664,7 +661,6 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest,
 	SHASH_DESC_ON_STACK(shash, tfm);
 
 	shash->tfm = tfm;
-	shash->flags = 0;
 
 	rc = crypto_shash_init(shash);
 	if (rc != 0)

commit 879b589210a9a0c9f77d301aaf0ddee20f2c5052
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Wed Feb 6 17:24:49 2019 +0100

    tpm: retrieve digest size of unknown algorithms with PCR read
    
    Currently, the TPM driver retrieves the digest size from a table mapping
    TPM algorithms identifiers to identifiers defined by the crypto subsystem.
    If the algorithm is not defined by the latter, the digest size can be
    retrieved from the output of the PCR read command.
    
    The patch modifies the definition of tpm_pcr_read() and tpm2_pcr_read() to
    pass the desired hash algorithm and obtain the digest size at TPM startup.
    Algorithms and corresponding digest sizes are stored in the new structure
    tpm_bank_info, member of tpm_chip, so that the information can be used by
    other kernel subsystems.
    
    tpm_bank_info contains: the TPM algorithm identifier, necessary to generate
    the event log as defined by Trusted Computing Group (TCG); the digest size,
    to pad/truncate a digest calculated with a different algorithm; the crypto
    subsystem identifier, to calculate the digest of event data.
    
    This patch also protects against data corruption that could happen in the
    bus, by checking that the digest size returned by the TPM during a PCR read
    matches the size of the algorithm passed to tpm2_pcr_read().
    
    For the initial PCR read, when digest sizes are not yet available, this
    patch ensures that the amount of data copied from the output returned by
    the TPM does not exceed the size of the array data are copied to.
    
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Reviewed-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Tested-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Acked-by: Mimi Zohar <zohar@linux.ibm.com>
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index acf2c7df7145..16a4f45863b1 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -643,12 +643,12 @@ int ima_calc_buffer_hash(const void *buf, loff_t len,
 	return calc_buffer_shash(buf, len, hash);
 }
 
-static void __init ima_pcrread(u32 idx, u8 *pcr)
+static void __init ima_pcrread(u32 idx, struct tpm_digest *d)
 {
 	if (!ima_tpm_chip)
 		return;
 
-	if (tpm_pcr_read(ima_tpm_chip, idx, pcr) != 0)
+	if (tpm_pcr_read(ima_tpm_chip, idx, d) != 0)
 		pr_err("Error Communicating to TPM chip\n");
 }
 
@@ -658,7 +658,7 @@ static void __init ima_pcrread(u32 idx, u8 *pcr)
 static int __init ima_calc_boot_aggregate_tfm(char *digest,
 					      struct crypto_shash *tfm)
 {
-	u8 pcr_i[TPM_DIGEST_SIZE];
+	struct tpm_digest d = { .alg_id = TPM_ALG_SHA1, .digest = {0} };
 	int rc;
 	u32 i;
 	SHASH_DESC_ON_STACK(shash, tfm);
@@ -672,9 +672,9 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest,
 
 	/* cumulative sha1 over tpm registers 0-7 */
 	for (i = TPM_PCR0; i < TPM_PCR8; i++) {
-		ima_pcrread(i, pcr_i);
+		ima_pcrread(i, &d);
 		/* now accumulate with current aggregate */
-		rc = crypto_shash_update(shash, pcr_i, TPM_DIGEST_SIZE);
+		rc = crypto_shash_update(shash, d.digest, TPM_DIGEST_SIZE);
 	}
 	if (!rc)
 		crypto_shash_final(shash, digest);

commit 95adc6b410b7aa895dcf5ed9cb7dc4a20a3d5c5a
Author: Tomas Winkler <tomas.winkler@intel.com>
Date:   Fri Oct 19 21:23:07 2018 +0300

    tpm: use u32 instead of int for PCR index
    
    The TPM specs defines PCR index as a positive number, and there is
    no reason to use a signed number. It is also a possible security
    issue as currently no functions check for a negative index,
    which may become a large number when converted to u32.
    
    Adjust the API to use u32 instead of int in all PCR related
    functions.
    
    Signed-off-by: Tomas Winkler <tomas.winkler@intel.com>
    Reviewed-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Tested-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index d9e7728027c6..acf2c7df7145 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -643,7 +643,7 @@ int ima_calc_buffer_hash(const void *buf, loff_t len,
 	return calc_buffer_shash(buf, len, hash);
 }
 
-static void __init ima_pcrread(int idx, u8 *pcr)
+static void __init ima_pcrread(u32 idx, u8 *pcr)
 {
 	if (!ima_tpm_chip)
 		return;
@@ -659,7 +659,8 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest,
 					      struct crypto_shash *tfm)
 {
 	u8 pcr_i[TPM_DIGEST_SIZE];
-	int rc, i;
+	int rc;
+	u32 i;
 	SHASH_DESC_ON_STACK(shash, tfm);
 
 	shash->tfm = tfm;

commit a408e4a86b36bf98ad15b9ada531cf0e5118ac67
Author: Goldwyn Rodrigues <rgoldwyn@suse.de>
Date:   Tue Oct 9 10:12:33 2018 -0500

    ima: open a new file instance if no read permissions
    
    Open a new file instance as opposed to changing file->f_mode when
    the file is not readable.  This is done to accomodate overlayfs
    stacked file operations change.  The real struct file is hidden
    behind the overlays struct file.  So, any file->f_mode manipulations are
    not reflected on the real struct file.  Open the file again in read mode
    if original file cannot be read, read and calculate the hash.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Cc: stable@vger.kernel.org (linux-4.19)
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 7e7e7e7c250a..d9e7728027c6 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -210,7 +210,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 {
 	loff_t i_size, offset;
 	char *rbuf[2] = { NULL, };
-	int rc, read = 0, rbuf_len, active = 0, ahash_rc = 0;
+	int rc, rbuf_len, active = 0, ahash_rc = 0;
 	struct ahash_request *req;
 	struct scatterlist sg[1];
 	struct crypto_wait wait;
@@ -257,11 +257,6 @@ static int ima_calc_file_hash_atfm(struct file *file,
 					  &rbuf_size[1], 0);
 	}
 
-	if (!(file->f_mode & FMODE_READ)) {
-		file->f_mode |= FMODE_READ;
-		read = 1;
-	}
-
 	for (offset = 0; offset < i_size; offset += rbuf_len) {
 		if (!rbuf[1] && offset) {
 			/* Not using two buffers, and it is not the first
@@ -300,8 +295,6 @@ static int ima_calc_file_hash_atfm(struct file *file,
 	/* wait for the last update request to complete */
 	rc = ahash_wait(ahash_rc, &wait);
 out3:
-	if (read)
-		file->f_mode &= ~FMODE_READ;
 	ima_free_pages(rbuf[0], rbuf_size[0]);
 	ima_free_pages(rbuf[1], rbuf_size[1]);
 out2:
@@ -336,7 +329,7 @@ static int ima_calc_file_hash_tfm(struct file *file,
 {
 	loff_t i_size, offset = 0;
 	char *rbuf;
-	int rc, read = 0;
+	int rc;
 	SHASH_DESC_ON_STACK(shash, tfm);
 
 	shash->tfm = tfm;
@@ -357,11 +350,6 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	if (!rbuf)
 		return -ENOMEM;
 
-	if (!(file->f_mode & FMODE_READ)) {
-		file->f_mode |= FMODE_READ;
-		read = 1;
-	}
-
 	while (offset < i_size) {
 		int rbuf_len;
 
@@ -378,8 +366,6 @@ static int ima_calc_file_hash_tfm(struct file *file,
 		if (rc)
 			break;
 	}
-	if (read)
-		file->f_mode &= ~FMODE_READ;
 	kfree(rbuf);
 out:
 	if (!rc)
@@ -420,6 +406,8 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 {
 	loff_t i_size;
 	int rc;
+	struct file *f = file;
+	bool new_file_instance = false, modified_flags = false;
 
 	/*
 	 * For consistency, fail file's opened with the O_DIRECT flag on
@@ -431,15 +419,41 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 		return -EINVAL;
 	}
 
-	i_size = i_size_read(file_inode(file));
+	/* Open a new file instance in O_RDONLY if we cannot read */
+	if (!(file->f_mode & FMODE_READ)) {
+		int flags = file->f_flags & ~(O_WRONLY | O_APPEND |
+				O_TRUNC | O_CREAT | O_NOCTTY | O_EXCL);
+		flags |= O_RDONLY;
+		f = dentry_open(&file->f_path, flags, file->f_cred);
+		if (IS_ERR(f)) {
+			/*
+			 * Cannot open the file again, lets modify f_flags
+			 * of original and continue
+			 */
+			pr_info_ratelimited("Unable to reopen file for reading.\n");
+			f = file;
+			f->f_flags |= FMODE_READ;
+			modified_flags = true;
+		} else {
+			new_file_instance = true;
+		}
+	}
+
+	i_size = i_size_read(file_inode(f));
 
 	if (ima_ahash_minsize && i_size >= ima_ahash_minsize) {
-		rc = ima_calc_file_ahash(file, hash);
+		rc = ima_calc_file_ahash(f, hash);
 		if (!rc)
-			return 0;
+			goto out;
 	}
 
-	return ima_calc_file_shash(file, hash);
+	rc = ima_calc_file_shash(f, hash);
+out:
+	if (new_file_instance)
+		fput(f);
+	else if (modified_flags)
+		f->f_flags &= ~FMODE_READ;
+	return rc;
 }
 
 /*

commit ec403d8ed08c8272cfeeeea154fdebcd289988c8
Author: Stefan Berger <stefanb@linux.vnet.ibm.com>
Date:   Tue Jun 26 15:09:33 2018 -0400

    ima: Get rid of ima_used_chip and use ima_tpm_chip != NULL instead
    
    Get rid of ima_used_chip and use ima_tpm_chip variable instead for
    determining whether to use the TPM chip.
    
    Signed-off-by: Stefan Berger <stefanb@linux.vnet.ibm.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Reviewed-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 88082f35adb2..7e7e7e7c250a 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -631,7 +631,7 @@ int ima_calc_buffer_hash(const void *buf, loff_t len,
 
 static void __init ima_pcrread(int idx, u8 *pcr)
 {
-	if (!ima_used_chip)
+	if (!ima_tpm_chip)
 		return;
 
 	if (tpm_pcr_read(ima_tpm_chip, idx, pcr) != 0)

commit 5c2a640aff73914e11ac0db310b32d3b7a1b87ad
Author: Stefan Berger <stefanb@linux.vnet.ibm.com>
Date:   Tue Jun 26 15:09:32 2018 -0400

    ima: Use tpm_default_chip() and call TPM functions with a tpm_chip
    
    Rather than accessing the TPM functions by passing a NULL pointer for
    the tpm_chip, which causes a lookup for a suitable chip every time, get a
    hold of a tpm_chip and access the TPM functions using it.
    
    Signed-off-by: Stefan Berger <stefanb@linux.vnet.ibm.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Reviewed-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 4e085a17124f..88082f35adb2 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -634,7 +634,7 @@ static void __init ima_pcrread(int idx, u8 *pcr)
 	if (!ima_used_chip)
 		return;
 
-	if (tpm_pcr_read(NULL, idx, pcr) != 0)
+	if (tpm_pcr_read(ima_tpm_chip, idx, pcr) != 0)
 		pr_err("Error Communicating to TPM chip\n");
 }
 

commit ab60368ab6a452466885ef4edf0cefd089465132
Author: Petr Vorel <pvorel@suse.cz>
Date:   Fri Mar 23 14:41:08 2018 +0100

    ima: Fallback to the builtin hash algorithm
    
    IMA requires having it's hash algorithm be compiled-in due to it's
    early use.  The default IMA algorithm is protected by Kconfig to be
    compiled-in.
    
    The ima_hash kernel parameter allows to choose the hash algorithm. When
    the specified algorithm is not available or available as a module, IMA
    initialization fails, which leads to a kernel panic (mknodat syscall calls
    ima_post_path_mknod()).  Therefore as fallback we force IMA to use
    the default builtin Kconfig hash algorithm.
    
    Fixed crash:
    
    $ grep CONFIG_CRYPTO_MD4 .config
    CONFIG_CRYPTO_MD4=m
    
    [    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-4.12.14-2.3-default root=UUID=74ae8202-9ca7-4e39-813b-22287ec52f7a video=1024x768-16 plymouth.ignore-serial-consoles console=ttyS0 console=tty resume=/dev/disk/by-path/pci-0000:00:07.0-part3 splash=silent showopts ima_hash=md4
    ...
    [    1.545190] ima: Can not allocate md4 (reason: -2)
    ...
    [    2.610120] BUG: unable to handle kernel NULL pointer dereference at           (null)
    [    2.611903] IP: ima_match_policy+0x23/0x390
    [    2.612967] PGD 0 P4D 0
    [    2.613080] Oops: 0000 [#1] SMP
    [    2.613080] Modules linked in: autofs4
    [    2.613080] Supported: Yes
    [    2.613080] CPU: 0 PID: 1 Comm: systemd Not tainted 4.12.14-2.3-default #1
    [    2.613080] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.0.0-prebuilt.qemu-project.org 04/01/2014
    [    2.613080] task: ffff88003e2d0040 task.stack: ffffc90000190000
    [    2.613080] RIP: 0010:ima_match_policy+0x23/0x390
    [    2.613080] RSP: 0018:ffffc90000193e88 EFLAGS: 00010296
    [    2.613080] RAX: 0000000000000000 RBX: 000000000000000c RCX: 0000000000000004
    [    2.613080] RDX: 0000000000000010 RSI: 0000000000000001 RDI: ffff880037071728
    [    2.613080] RBP: 0000000000008000 R08: 0000000000000000 R09: 0000000000000000
    [    2.613080] R10: 0000000000000008 R11: 61c8864680b583eb R12: 00005580ff10086f
    [    2.613080] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000008000
    [    2.613080] FS:  00007f5c1da08940(0000) GS:ffff88003fc00000(0000) knlGS:0000000000000000
    [    2.613080] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [    2.613080] CR2: 0000000000000000 CR3: 0000000037002000 CR4: 00000000003406f0
    [    2.613080] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [    2.613080] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [    2.613080] Call Trace:
    [    2.613080]  ? shmem_mknod+0xbf/0xd0
    [    2.613080]  ima_post_path_mknod+0x1c/0x40
    [    2.613080]  SyS_mknod+0x210/0x220
    [    2.613080]  entry_SYSCALL_64_fastpath+0x1a/0xa5
    [    2.613080] RIP: 0033:0x7f5c1bfde570
    [    2.613080] RSP: 002b:00007ffde1c90dc8 EFLAGS: 00000246 ORIG_RAX: 0000000000000085
    [    2.613080] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f5c1bfde570
    [    2.613080] RDX: 0000000000000000 RSI: 0000000000008000 RDI: 00005580ff10086f
    [    2.613080] RBP: 00007ffde1c91040 R08: 00005580ff10086f R09: 0000000000000000
    [    2.613080] R10: 0000000000104000 R11: 0000000000000246 R12: 00005580ffb99660
    [    2.613080] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000002
    [    2.613080] Code: 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 41 57 41 56 44 8d 14 09 41 55 41 54 55 53 44 89 d3 09 cb 48 83 ec 38 48 8b 05 c5 03 29 01 <4c> 8b 20 4c 39 e0 0f 84 d7 01 00 00 4c 89 44 24 08 89 54 24 20
    [    2.613080] RIP: ima_match_policy+0x23/0x390 RSP: ffffc90000193e88
    [    2.613080] CR2: 0000000000000000
    [    2.613080] ---[ end trace 9a9f0a8a73079f6a ]---
    [    2.673052] Kernel panic - not syncing: Attempted to kill init! exitcode=0x00000009
    [    2.673052]
    [    2.675337] Kernel Offset: disabled
    [    2.676405] ---[ end Kernel panic - not syncing: Attempted to kill init! exitcode=0x00000009
    
    Signed-off-by: Petr Vorel <pvorel@suse.cz>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 205bc69361ea..4e085a17124f 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -73,6 +73,8 @@ int __init ima_init_crypto(void)
 		       hash_algo_name[ima_hash_algo], rc);
 		return rc;
 	}
+	pr_info("Allocated hash algorithm: %s\n",
+		hash_algo_name[ima_hash_algo]);
 	return 0;
 }
 

commit aad887f6641145fec2a801da2ce4ed36cf99c6a5
Author: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
Date:   Sun Nov 5 13:16:26 2017 +0200

    tpm: use struct tpm_chip for tpm_chip_find_get()
    
    Device number (the character device index) is not a stable identifier
    for a TPM chip. That is the reason why every call site passes
    TPM_ANY_NUM to tpm_chip_find_get().
    
    This commit changes the API in a way that instead a struct tpm_chip
    instance is given and NULL means the default chip. In addition, this
    commit refines the documentation to be up to date with the
    implementation.
    
    Suggested-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com> (@chip_num -> @chip part)
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Reviewed-by: Jason Gunthorpe <jgg@ziepe.ca>
    Tested-by: PrasannaKumar Muralidharan <prasannatsmkumar@gmail.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 9057b163c378..205bc69361ea 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -632,7 +632,7 @@ static void __init ima_pcrread(int idx, u8 *pcr)
 	if (!ima_used_chip)
 		return;
 
-	if (tpm_pcr_read(TPM_ANY_NUM, idx, pcr) != 0)
+	if (tpm_pcr_read(NULL, idx, pcr) != 0)
 		pr_err("Error Communicating to TPM chip\n");
 }
 

commit 37dc79565c4b7e735f190eaa6ed5bb6eb3d3968a
Merge: 894025f24bd0 1d9ddde12e3c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 10:52:09 2017 -0800

    Merge branch 'linus' of git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6
    
    Pull crypto updates from Herbert Xu:
     "Here is the crypto update for 4.15:
    
      API:
    
       - Disambiguate EBUSY when queueing crypto request by adding ENOSPC.
         This change touches code outside the crypto API.
       - Reset settings when empty string is written to rng_current.
    
      Algorithms:
    
       - Add OSCCA SM3 secure hash.
    
      Drivers:
    
       - Remove old mv_cesa driver (replaced by marvell/cesa).
       - Enable rfc3686/ecb/cfb/ofb AES in crypto4xx.
       - Add ccm/gcm AES in crypto4xx.
       - Add support for BCM7278 in iproc-rng200.
       - Add hash support on Exynos in s5p-sss.
       - Fix fallback-induced error in vmx.
       - Fix output IV in atmel-aes.
       - Fix empty GCM hash in mediatek.
    
      Others:
    
       - Fix DoS potential in lib/mpi.
       - Fix potential out-of-order issues with padata"
    
    * 'linus' of git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6: (162 commits)
      lib/mpi: call cond_resched() from mpi_powm() loop
      crypto: stm32/hash - Fix return issue on update
      crypto: dh - Remove pointless checks for NULL 'p' and 'g'
      crypto: qat - Clean up error handling in qat_dh_set_secret()
      crypto: dh - Don't permit 'key' or 'g' size longer than 'p'
      crypto: dh - Don't permit 'p' to be 0
      crypto: dh - Fix double free of ctx->p
      hwrng: iproc-rng200 - Add support for BCM7278
      dt-bindings: rng: Document BCM7278 RNG200 compatible
      crypto: chcr - Replace _manual_ swap with swap macro
      crypto: marvell - Add a NULL entry at the end of mv_cesa_plat_id_table[]
      hwrng: virtio - Virtio RNG devices need to be re-registered after suspend/resume
      crypto: atmel - remove empty functions
      crypto: ecdh - remove empty exit()
      MAINTAINERS: update maintainer for qat
      crypto: caam - remove unused param of ctx_map_to_sec4_sg()
      crypto: caam - remove unneeded edesc zeroization
      crypto: atmel-aes - Reset the controller before each use
      crypto: atmel-aes - properly set IV after {en,de}crypt
      hwrng: core - Reset user selected rng by writing "" to rng_current
      ...

commit f3cc6b25dcc5616f0d5c720009b2ac66f97df2ff
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Sat Jun 17 23:56:23 2017 -0400

    ima: always measure and audit files in policy
    
    All files matching a "measure" rule must be included in the IMA
    measurement list, even when the file hash cannot be calculated.
    Similarly, all files matching an "audit" rule must be audited, even when
    the file hash can not be calculated.
    
    The file data hash field contained in the IMA measurement list template
    data will contain 0's instead of the actual file hash digest.
    
    Note:
    In general, adding, deleting or in anyway changing which files are
    included in the IMA measurement list is not a good idea, as it might
    result in not being able to unseal trusted keys sealed to a specific
    TPM PCR value.  This patch not only adds file measurements that were
    not previously measured, but specifies that the file hash value for
    these files will be 0's.
    
    As the IMA measurement list ordering is not consistent from one boot
    to the next, it is unlikely that anyone is sealing keys based on the
    IMA measurement list.  Remote attestation servers should be able to
    process these new measurement records, but might complain about
    these unknown records.
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Reviewed-by: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 802d5d20f36f..a856d8c9c9f3 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -441,6 +441,16 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 	loff_t i_size;
 	int rc;
 
+	/*
+	 * For consistency, fail file's opened with the O_DIRECT flag on
+	 * filesystems mounted with/without DAX option.
+	 */
+	if (file->f_flags & O_DIRECT) {
+		hash->length = hash_digest_size[ima_hash_algo];
+		hash->algo = ima_hash_algo;
+		return -EINVAL;
+	}
+
 	i_size = i_size_read(file_inode(file));
 
 	if (ima_ahash_minsize && i_size >= ima_ahash_minsize) {

commit 46f1414c8a92d85b4391bc324dd58eace8c48837
Author: Gilad Ben-Yossef <gilad@benyossef.com>
Date:   Wed Oct 18 08:00:47 2017 +0100

    ima: move to generic async completion
    
    ima starts several async crypto ops and  waits for their completions.
    Move it over to generic code doing the same.
    
    Signed-off-by: Gilad Ben-Yossef <gilad@benyossef.com>
    Acked-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 802d5d20f36f..0e4db1fe153b 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -27,11 +27,6 @@
 
 #include "ima.h"
 
-struct ahash_completion {
-	struct completion completion;
-	int err;
-};
-
 /* minimum file size for ahash use */
 static unsigned long ima_ahash_minsize;
 module_param_named(ahash_minsize, ima_ahash_minsize, ulong, 0644);
@@ -196,30 +191,13 @@ static void ima_free_atfm(struct crypto_ahash *tfm)
 		crypto_free_ahash(tfm);
 }
 
-static void ahash_complete(struct crypto_async_request *req, int err)
+static inline int ahash_wait(int err, struct crypto_wait *wait)
 {
-	struct ahash_completion *res = req->data;
 
-	if (err == -EINPROGRESS)
-		return;
-	res->err = err;
-	complete(&res->completion);
-}
+	err = crypto_wait_req(err, wait);
 
-static int ahash_wait(int err, struct ahash_completion *res)
-{
-	switch (err) {
-	case 0:
-		break;
-	case -EINPROGRESS:
-	case -EBUSY:
-		wait_for_completion(&res->completion);
-		reinit_completion(&res->completion);
-		err = res->err;
-		/* fall through */
-	default:
+	if (err)
 		pr_crit_ratelimited("ahash calculation failed: err: %d\n", err);
-	}
 
 	return err;
 }
@@ -233,7 +211,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 	int rc, read = 0, rbuf_len, active = 0, ahash_rc = 0;
 	struct ahash_request *req;
 	struct scatterlist sg[1];
-	struct ahash_completion res;
+	struct crypto_wait wait;
 	size_t rbuf_size[2];
 
 	hash->length = crypto_ahash_digestsize(tfm);
@@ -242,12 +220,12 @@ static int ima_calc_file_hash_atfm(struct file *file,
 	if (!req)
 		return -ENOMEM;
 
-	init_completion(&res.completion);
+	crypto_init_wait(&wait);
 	ahash_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG |
 				   CRYPTO_TFM_REQ_MAY_SLEEP,
-				   ahash_complete, &res);
+				   crypto_req_done, &wait);
 
-	rc = ahash_wait(crypto_ahash_init(req), &res);
+	rc = ahash_wait(crypto_ahash_init(req), &wait);
 	if (rc)
 		goto out1;
 
@@ -288,7 +266,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 			 * read/request, wait for the completion of the
 			 * previous ahash_update() request.
 			 */
-			rc = ahash_wait(ahash_rc, &res);
+			rc = ahash_wait(ahash_rc, &wait);
 			if (rc)
 				goto out3;
 		}
@@ -304,7 +282,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 			 * read/request, wait for the completion of the
 			 * previous ahash_update() request.
 			 */
-			rc = ahash_wait(ahash_rc, &res);
+			rc = ahash_wait(ahash_rc, &wait);
 			if (rc)
 				goto out3;
 		}
@@ -318,7 +296,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 			active = !active; /* swap buffers, if we use two */
 	}
 	/* wait for the last update request to complete */
-	rc = ahash_wait(ahash_rc, &res);
+	rc = ahash_wait(ahash_rc, &wait);
 out3:
 	if (read)
 		file->f_mode &= ~FMODE_READ;
@@ -327,7 +305,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 out2:
 	if (!rc) {
 		ahash_request_set_crypt(req, NULL, hash->digest, 0);
-		rc = ahash_wait(crypto_ahash_final(req), &res);
+		rc = ahash_wait(crypto_ahash_final(req), &wait);
 	}
 out1:
 	ahash_request_free(req);
@@ -527,7 +505,7 @@ static int calc_buffer_ahash_atfm(const void *buf, loff_t len,
 {
 	struct ahash_request *req;
 	struct scatterlist sg;
-	struct ahash_completion res;
+	struct crypto_wait wait;
 	int rc, ahash_rc = 0;
 
 	hash->length = crypto_ahash_digestsize(tfm);
@@ -536,12 +514,12 @@ static int calc_buffer_ahash_atfm(const void *buf, loff_t len,
 	if (!req)
 		return -ENOMEM;
 
-	init_completion(&res.completion);
+	crypto_init_wait(&wait);
 	ahash_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG |
 				   CRYPTO_TFM_REQ_MAY_SLEEP,
-				   ahash_complete, &res);
+				   crypto_req_done, &wait);
 
-	rc = ahash_wait(crypto_ahash_init(req), &res);
+	rc = ahash_wait(crypto_ahash_init(req), &wait);
 	if (rc)
 		goto out;
 
@@ -551,10 +529,10 @@ static int calc_buffer_ahash_atfm(const void *buf, loff_t len,
 	ahash_rc = crypto_ahash_update(req);
 
 	/* wait for the update request to complete */
-	rc = ahash_wait(ahash_rc, &res);
+	rc = ahash_wait(ahash_rc, &wait);
 	if (!rc) {
 		ahash_request_set_crypt(req, NULL, hash->digest, 0);
-		rc = ahash_wait(crypto_ahash_final(req), &res);
+		rc = ahash_wait(crypto_ahash_final(req), &wait);
 	}
 out:
 	ahash_request_free(req);

commit 98e1d55d033eed2a474924c94fc2051ab20de402
Author: Andreas Steffen <andreas.steffen@strongswan.org>
Date:   Mon Dec 19 16:23:00 2016 -0800

    ima: platform-independent hash value
    
    For remote attestion it is important for the ima measurement values to
    be platform-independent.  Therefore integer fields to be hashed must be
    converted to canonical format.
    
    Link: http://lkml.kernel.org/r/1480554346-29071-11-git-send-email-zohar@linux.vnet.ibm.com
    Signed-off-by: Andreas Steffen <andreas.steffen@strongswan.org>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Cc: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Dmitry Kasatkin <dmitry.kasatkin@gmail.com>
    Cc: Josh Sklar <sklar@linux.vnet.ibm.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Stewart Smith <stewart@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 38f2ed830dd6..802d5d20f36f 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -477,11 +477,13 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 		u8 buffer[IMA_EVENT_NAME_LEN_MAX + 1] = { 0 };
 		u8 *data_to_hash = field_data[i].data;
 		u32 datalen = field_data[i].len;
+		u32 datalen_to_hash =
+		    !ima_canonical_fmt ? datalen : cpu_to_le32(datalen);
 
 		if (strcmp(td->name, IMA_TEMPLATE_IMA_NAME) != 0) {
 			rc = crypto_shash_update(shash,
-						(const u8 *) &field_data[i].len,
-						sizeof(field_data[i].len));
+						(const u8 *) &datalen_to_hash,
+						sizeof(datalen_to_hash));
 			if (rc)
 				break;
 		} else if (strcmp(td->fields[i]->field_id, "n") == 0) {

commit 98304bcf71845e97c0b5c800ae619311156b66c1
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Mon Dec 28 11:56:09 2015 -0500

    ima: calculate the hash of a buffer using aynchronous hash(ahash)
    
    Setting up ahash has some overhead.  Only use ahash to calculate the
    hash of a buffer, if the buffer is larger than ima_ahash_minsize.
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Acked-by: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index fccb6ceb388b..38f2ed830dd6 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -519,6 +519,63 @@ int ima_calc_field_array_hash(struct ima_field_data *field_data,
 	return rc;
 }
 
+static int calc_buffer_ahash_atfm(const void *buf, loff_t len,
+				  struct ima_digest_data *hash,
+				  struct crypto_ahash *tfm)
+{
+	struct ahash_request *req;
+	struct scatterlist sg;
+	struct ahash_completion res;
+	int rc, ahash_rc = 0;
+
+	hash->length = crypto_ahash_digestsize(tfm);
+
+	req = ahash_request_alloc(tfm, GFP_KERNEL);
+	if (!req)
+		return -ENOMEM;
+
+	init_completion(&res.completion);
+	ahash_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG |
+				   CRYPTO_TFM_REQ_MAY_SLEEP,
+				   ahash_complete, &res);
+
+	rc = ahash_wait(crypto_ahash_init(req), &res);
+	if (rc)
+		goto out;
+
+	sg_init_one(&sg, buf, len);
+	ahash_request_set_crypt(req, &sg, NULL, len);
+
+	ahash_rc = crypto_ahash_update(req);
+
+	/* wait for the update request to complete */
+	rc = ahash_wait(ahash_rc, &res);
+	if (!rc) {
+		ahash_request_set_crypt(req, NULL, hash->digest, 0);
+		rc = ahash_wait(crypto_ahash_final(req), &res);
+	}
+out:
+	ahash_request_free(req);
+	return rc;
+}
+
+static int calc_buffer_ahash(const void *buf, loff_t len,
+			     struct ima_digest_data *hash)
+{
+	struct crypto_ahash *tfm;
+	int rc;
+
+	tfm = ima_alloc_atfm(hash->algo);
+	if (IS_ERR(tfm))
+		return PTR_ERR(tfm);
+
+	rc = calc_buffer_ahash_atfm(buf, len, hash, tfm);
+
+	ima_free_atfm(tfm);
+
+	return rc;
+}
+
 static int calc_buffer_shash_tfm(const void *buf, loff_t size,
 				struct ima_digest_data *hash,
 				struct crypto_shash *tfm)
@@ -550,8 +607,8 @@ static int calc_buffer_shash_tfm(const void *buf, loff_t size,
 	return rc;
 }
 
-int ima_calc_buffer_hash(const void *buf, loff_t len,
-			 struct ima_digest_data *hash)
+static int calc_buffer_shash(const void *buf, loff_t len,
+			     struct ima_digest_data *hash)
 {
 	struct crypto_shash *tfm;
 	int rc;
@@ -566,6 +623,20 @@ int ima_calc_buffer_hash(const void *buf, loff_t len,
 	return rc;
 }
 
+int ima_calc_buffer_hash(const void *buf, loff_t len,
+			 struct ima_digest_data *hash)
+{
+	int rc;
+
+	if (ima_ahash_minsize && len >= ima_ahash_minsize) {
+		rc = calc_buffer_ahash(buf, len, hash);
+		if (!rc)
+			return 0;
+	}
+
+	return calc_buffer_shash(buf, len, hash);
+}
+
 static void __init ima_pcrread(int idx, u8 *pcr)
 {
 	if (!ima_used_chip)

commit 11d7646df8e800f434ff710ad6100acbea59068e
Author: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>
Date:   Thu Apr 17 12:01:40 2014 +0300

    ima: provide buffer hash calculation function
    
    This patch provides convenient buffer hash calculation function.
    
    Changelog v3:
    - fix while hash calculation - Dmitry
    v1:
    - rewrite to support loff_t sized buffers - Mimi
      (based on Fenguang Wu's testing)
    
    Signed-off-by: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index fb30ce406af4..fccb6ceb388b 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -519,6 +519,53 @@ int ima_calc_field_array_hash(struct ima_field_data *field_data,
 	return rc;
 }
 
+static int calc_buffer_shash_tfm(const void *buf, loff_t size,
+				struct ima_digest_data *hash,
+				struct crypto_shash *tfm)
+{
+	SHASH_DESC_ON_STACK(shash, tfm);
+	unsigned int len;
+	int rc;
+
+	shash->tfm = tfm;
+	shash->flags = 0;
+
+	hash->length = crypto_shash_digestsize(tfm);
+
+	rc = crypto_shash_init(shash);
+	if (rc != 0)
+		return rc;
+
+	while (size) {
+		len = size < PAGE_SIZE ? size : PAGE_SIZE;
+		rc = crypto_shash_update(shash, buf, len);
+		if (rc)
+			break;
+		buf += len;
+		size -= len;
+	}
+
+	if (!rc)
+		rc = crypto_shash_final(shash, hash->digest);
+	return rc;
+}
+
+int ima_calc_buffer_hash(const void *buf, loff_t len,
+			 struct ima_digest_data *hash)
+{
+	struct crypto_shash *tfm;
+	int rc;
+
+	tfm = ima_alloc_tfm(hash->algo);
+	if (IS_ERR(tfm))
+		return PTR_ERR(tfm);
+
+	rc = calc_buffer_shash_tfm(buf, len, hash, tfm);
+
+	ima_free_tfm(tfm);
+	return rc;
+}
+
 static void __init ima_pcrread(int idx, u8 *pcr)
 {
 	if (!ima_used_chip)

commit 1525b06d99b117198ea8d6c128ee5bf28ceb6723
Author: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>
Date:   Thu Oct 30 12:39:39 2014 +0200

    ima: separate 'security.ima' reading functionality from collect
    
    Instead of passing pointers to pointers to ima_collect_measurent() to
    read and return the 'security.ima' xattr value, this patch moves the
    functionality to the calling process_measurement() to directly read
    the xattr and pass only the hash algo to the ima_collect_measurement().
    
    Signed-off-by: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 6eb62936c672..fb30ce406af4 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -24,7 +24,7 @@
 #include <linux/err.h>
 #include <linux/slab.h>
 #include <crypto/hash.h>
-#include <crypto/hash_info.h>
+
 #include "ima.h"
 
 struct ahash_completion {

commit 71baba4b92dc1fa1bc461742c6ab1942ec6034e9
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Nov 6 16:28:28 2015 -0800

    mm, page_alloc: rename __GFP_WAIT to __GFP_RECLAIM
    
    __GFP_WAIT was used to signal that the caller was in atomic context and
    could not sleep.  Now it is possible to distinguish between true atomic
    context and callers that are not willing to sleep.  The latter should
    clear __GFP_DIRECT_RECLAIM so kswapd will still wake.  As clearing
    __GFP_WAIT behaves differently, there is a risk that people will clear the
    wrong flags.  This patch renames __GFP_WAIT to __GFP_RECLAIM to clearly
    indicate what it does -- setting it allows all reclaim activity, clearing
    them prevents it.
    
    [akpm@linux-foundation.org: fix build]
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Christoph Lameter <cl@linux.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Vitaly Wool <vitalywool@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index e24121afb2f2..6eb62936c672 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -126,7 +126,7 @@ static void *ima_alloc_pages(loff_t max_size, size_t *allocated_size,
 {
 	void *ptr;
 	int order = ima_maxorder;
-	gfp_t gfp_mask = __GFP_WAIT | __GFP_NOWARN | __GFP_NORETRY;
+	gfp_t gfp_mask = __GFP_RECLAIM | __GFP_NOWARN | __GFP_NORETRY;
 
 	if (order)
 		order = min(get_order(max_size), order);

commit 9c27847dda9cfae7c273cde62becf364f9fa9ea3
Author: Luis R. Rodriguez <mcgrof@suse.com>
Date:   Wed May 27 11:09:38 2015 +0930

    kernel/params: constify struct kernel_param_ops uses
    
    Most code already uses consts for the struct kernel_param_ops,
    sweep the kernel for the last offending stragglers. Other than
    include/linux/moduleparam.h and kernel/params.c all other changes
    were generated with the following Coccinelle SmPL patch. Merge
    conflicts between trees can be handled with Coccinelle.
    
    In the future git could get Coccinelle merge support to deal with
    patch --> fail --> grammar --> Coccinelle --> new patch conflicts
    automatically for us on patches where the grammar is available and
    the patch is of high confidence. Consider this a feature request.
    
    Test compiled on x86_64 against:
    
            * allnoconfig
            * allmodconfig
            * allyesconfig
    
    @ const_found @
    identifier ops;
    @@
    
    const struct kernel_param_ops ops = {
    };
    
    @ const_not_found depends on !const_found @
    identifier ops;
    @@
    
    -struct kernel_param_ops ops = {
    +const struct kernel_param_ops ops = {
    };
    
    Generated-by: Coccinelle SmPL
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Junio C Hamano <gitster@pobox.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: cocci@systeme.lip6.fr
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Luis R. Rodriguez <mcgrof@suse.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 686355fea7fd..e24121afb2f2 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -55,7 +55,7 @@ static int param_set_bufsize(const char *val, const struct kernel_param *kp)
 	return 0;
 }
 
-static struct kernel_param_ops param_ops_bufsize = {
+static const struct kernel_param_ops param_ops_bufsize = {
 	.set = param_set_bufsize,
 	.get = param_get_uint,
 };

commit 67e2c3883828b39548cee2091b36656787775d95
Merge: 6ae840e7cc4b b2d1965dcea1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Dec 14 20:36:37 2014 -0800

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security layer updates from James Morris:
     "In terms of changes, there's general maintenance to the Smack,
      SELinux, and integrity code.
    
      The IMA code adds a new kconfig option, IMA_APPRAISE_SIGNED_INIT,
      which allows IMA appraisal to require signatures.  Support for reading
      keys from rootfs before init is call is also added"
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security: (23 commits)
      selinux: Remove security_ops extern
      security: smack: fix out-of-bounds access in smk_parse_smack()
      VFS: refactor vfs_read()
      ima: require signature based appraisal
      integrity: provide a hook to load keys when rootfs is ready
      ima: load x509 certificate from the kernel
      integrity: provide a function to load x509 certificate from the kernel
      integrity: define a new function integrity_read_file()
      Security: smack: replace kzalloc with kmem_cache for inode_smack
      Smack: Lock mode for the floor and hat labels
      ima: added support for new kernel cmdline parameter ima_template_fmt
      ima: allocate field pointers array on demand in template_desc_init_fields()
      ima: don't allocate a copy of template_fmt in template_desc_init_fields()
      ima: display template format in meas. list if template name length is zero
      ima: added error messages to template-related functions
      ima: use atomic bit operations to protect policy update interface
      ima: ignore empty and with whitespaces policy lines
      ima: no need to allocate entry for comment
      ima: report policy load status
      ima: use path names cache
      ...

commit e3c4abbfa97ed0b7aed36f18b32911ccf76d52c2
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Wed Nov 5 17:01:12 2014 +0200

    integrity: define a new function integrity_read_file()
    
    This patch defines a new function called integrity_read_file()
    to read file from the kernel into a buffer. Subsequent patches
    will read a file containing the public keys and load them onto
    the IMA keyring.
    
    This patch moves and renames ima_kernel_read(), the non-security
    checking version of kernel_read(), to integrity_kernel_read().
    
    Changes in v3:
    * Patch descriptions improved (Mimi)
    * Add missing cast (kbuild test robot)
    
    Changes in v2:
    * configuration option removed
    * function declared as '__init'
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index d34e7dfc1118..5df4d960d4dc 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -67,36 +67,6 @@ MODULE_PARM_DESC(ahash_bufsize, "Maximum ahash buffer size");
 static struct crypto_shash *ima_shash_tfm;
 static struct crypto_ahash *ima_ahash_tfm;
 
-/**
- * ima_kernel_read - read file content
- *
- * This is a function for reading file content instead of kernel_read().
- * It does not perform locking checks to ensure it cannot be blocked.
- * It does not perform security checks because it is irrelevant for IMA.
- *
- */
-static int ima_kernel_read(struct file *file, loff_t offset,
-			   char *addr, unsigned long count)
-{
-	mm_segment_t old_fs;
-	char __user *buf = addr;
-	ssize_t ret = -EINVAL;
-
-	if (!(file->f_mode & FMODE_READ))
-		return -EBADF;
-
-	old_fs = get_fs();
-	set_fs(get_ds());
-	if (file->f_op->read)
-		ret = file->f_op->read(file, buf, count, &offset);
-	else if (file->f_op->aio_read)
-		ret = do_sync_read(file, buf, count, &offset);
-	else if (file->f_op->read_iter)
-		ret = new_sync_read(file, buf, count, &offset);
-	set_fs(old_fs);
-	return ret;
-}
-
 int __init ima_init_crypto(void)
 {
 	long rc;
@@ -324,7 +294,8 @@ static int ima_calc_file_hash_atfm(struct file *file,
 		}
 		/* read buffer */
 		rbuf_len = min_t(loff_t, i_size - offset, rbuf_size[active]);
-		rc = ima_kernel_read(file, offset, rbuf[active], rbuf_len);
+		rc = integrity_kernel_read(file, offset, rbuf[active],
+					   rbuf_len);
 		if (rc != rbuf_len)
 			goto out3;
 
@@ -417,7 +388,7 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	while (offset < i_size) {
 		int rbuf_len;
 
-		rbuf_len = ima_kernel_read(file, offset, rbuf, PAGE_SIZE);
+		rbuf_len = integrity_kernel_read(file, offset, rbuf, PAGE_SIZE);
 		if (rbuf_len < 0) {
 			rc = rbuf_len;
 			break;

commit 357aabed626fe3fc753a99ef1d652f4e2d82ba26
Author: Behan Webster <behanw@converseincode.com>
Date:   Fri Apr 4 18:18:00 2014 -0300

    security, crypto: LLVMLinux: Remove VLAIS from ima_crypto.c
    
    Replaced the use of a Variable Length Array In Struct (VLAIS) with a C99
    compliant equivalent. This patch allocates the appropriate amount of memory
    using a char array using the SHASH_DESC_ON_STACK macro.
    
    The new code can be compiled with both gcc and clang.
    
    Signed-off-by: Behan Webster <behanw@converseincode.com>
    Reviewed-by: Mark Charlebois <charlebm@gmail.com>
    Reviewed-by: Jan-Simon Mller <dl9pf@gmx.de>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Acked-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Cc: tglx@linutronix.de

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index d34e7dfc1118..78d66dae15f4 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -386,17 +386,14 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	loff_t i_size, offset = 0;
 	char *rbuf;
 	int rc, read = 0;
-	struct {
-		struct shash_desc shash;
-		char ctx[crypto_shash_descsize(tfm)];
-	} desc;
+	SHASH_DESC_ON_STACK(shash, tfm);
 
-	desc.shash.tfm = tfm;
-	desc.shash.flags = 0;
+	shash->tfm = tfm;
+	shash->flags = 0;
 
 	hash->length = crypto_shash_digestsize(tfm);
 
-	rc = crypto_shash_init(&desc.shash);
+	rc = crypto_shash_init(shash);
 	if (rc != 0)
 		return rc;
 
@@ -426,7 +423,7 @@ static int ima_calc_file_hash_tfm(struct file *file,
 			break;
 		offset += rbuf_len;
 
-		rc = crypto_shash_update(&desc.shash, rbuf, rbuf_len);
+		rc = crypto_shash_update(shash, rbuf, rbuf_len);
 		if (rc)
 			break;
 	}
@@ -435,7 +432,7 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	kfree(rbuf);
 out:
 	if (!rc)
-		rc = crypto_shash_final(&desc.shash, hash->digest);
+		rc = crypto_shash_final(shash, hash->digest);
 	return rc;
 }
 
@@ -493,18 +490,15 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 					 struct ima_digest_data *hash,
 					 struct crypto_shash *tfm)
 {
-	struct {
-		struct shash_desc shash;
-		char ctx[crypto_shash_descsize(tfm)];
-	} desc;
+	SHASH_DESC_ON_STACK(shash, tfm);
 	int rc, i;
 
-	desc.shash.tfm = tfm;
-	desc.shash.flags = 0;
+	shash->tfm = tfm;
+	shash->flags = 0;
 
 	hash->length = crypto_shash_digestsize(tfm);
 
-	rc = crypto_shash_init(&desc.shash);
+	rc = crypto_shash_init(shash);
 	if (rc != 0)
 		return rc;
 
@@ -514,7 +508,7 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 		u32 datalen = field_data[i].len;
 
 		if (strcmp(td->name, IMA_TEMPLATE_IMA_NAME) != 0) {
-			rc = crypto_shash_update(&desc.shash,
+			rc = crypto_shash_update(shash,
 						(const u8 *) &field_data[i].len,
 						sizeof(field_data[i].len));
 			if (rc)
@@ -524,13 +518,13 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 			data_to_hash = buffer;
 			datalen = IMA_EVENT_NAME_LEN_MAX + 1;
 		}
-		rc = crypto_shash_update(&desc.shash, data_to_hash, datalen);
+		rc = crypto_shash_update(shash, data_to_hash, datalen);
 		if (rc)
 			break;
 	}
 
 	if (!rc)
-		rc = crypto_shash_final(&desc.shash, hash->digest);
+		rc = crypto_shash_final(shash, hash->digest);
 
 	return rc;
 }
@@ -571,15 +565,12 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest,
 {
 	u8 pcr_i[TPM_DIGEST_SIZE];
 	int rc, i;
-	struct {
-		struct shash_desc shash;
-		char ctx[crypto_shash_descsize(tfm)];
-	} desc;
+	SHASH_DESC_ON_STACK(shash, tfm);
 
-	desc.shash.tfm = tfm;
-	desc.shash.flags = 0;
+	shash->tfm = tfm;
+	shash->flags = 0;
 
-	rc = crypto_shash_init(&desc.shash);
+	rc = crypto_shash_init(shash);
 	if (rc != 0)
 		return rc;
 
@@ -587,10 +578,10 @@ static int __init ima_calc_boot_aggregate_tfm(char *digest,
 	for (i = TPM_PCR0; i < TPM_PCR8; i++) {
 		ima_pcrread(i, pcr_i);
 		/* now accumulate with current aggregate */
-		rc = crypto_shash_update(&desc.shash, pcr_i, TPM_DIGEST_SIZE);
+		rc = crypto_shash_update(shash, pcr_i, TPM_DIGEST_SIZE);
 	}
 	if (!rc)
-		crypto_shash_final(&desc.shash, digest);
+		crypto_shash_final(shash, digest);
 	return rc;
 }
 

commit e4a9c5196566bd47ac92f6e5ef7f48412ded7176
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Wed Sep 3 10:19:58 2014 +0300

    ima: add missing '__init' keywords
    
    Add missing keywords to the function definition to cleanup
    to discard initialization code.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Reviewed-by: Roberto Sassu <roberto.sassu@polito.it>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 3b26472fbf0a..d34e7dfc1118 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -97,7 +97,7 @@ static int ima_kernel_read(struct file *file, loff_t offset,
 	return ret;
 }
 
-int ima_init_crypto(void)
+int __init ima_init_crypto(void)
 {
 	long rc;
 

commit 27cd1fc3ae5374a4a86662c67033f15ef27b2461
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Mon Jun 23 20:32:56 2014 +0300

    ima: fix fallback to use new_sync_read()
    
    3.16 commit aad4f8bb42af06371aa0e85bf0cd9d52c0494985
    'switch simple generic_file_aio_read() users to ->read_iter()'
    replaced ->aio_read with ->read_iter in most of the file systems
    and introduced new_sync_read() as a replacement for do_sync_read().
    
    Most of file systems set '->read' and ima_kernel_read is not affected.
    When ->read is not set, this patch adopts fallback call changes from the
    vfs_read.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org>  3.16+

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 1178b307d562..3b26472fbf0a 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -80,19 +80,19 @@ static int ima_kernel_read(struct file *file, loff_t offset,
 {
 	mm_segment_t old_fs;
 	char __user *buf = addr;
-	ssize_t ret;
+	ssize_t ret = -EINVAL;
 
 	if (!(file->f_mode & FMODE_READ))
 		return -EBADF;
-	if (!file->f_op->read && !file->f_op->aio_read)
-		return -EINVAL;
 
 	old_fs = get_fs();
 	set_fs(get_ds());
 	if (file->f_op->read)
 		ret = file->f_op->read(file, buf, count, &offset);
-	else
+	else if (file->f_op->aio_read)
 		ret = do_sync_read(file, buf, count, &offset);
+	else if (file->f_op->read_iter)
+		ret = new_sync_read(file, buf, count, &offset);
 	set_fs(old_fs);
 	return ret;
 }

commit 23c19e2ca736722a9523b64b07cda7efab7b6c57
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Fri Aug 15 13:28:52 2014 +0300

    ima: prevent buffer overflow in ima_alloc_tfm()
    
    This patch fixes the case where the file's signature/hash xattr contains
    an invalid hash algorithm.  Although we can not verify the xattr, we still
    need to measure the file.  Use the default IMA hash algorithm.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 2d103dc13d90..1178b307d562 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -116,7 +116,10 @@ static struct crypto_shash *ima_alloc_tfm(enum hash_algo algo)
 	struct crypto_shash *tfm = ima_shash_tfm;
 	int rc;
 
-	if (algo != ima_hash_algo && algo < HASH_ALGO__LAST) {
+	if (algo < 0 || algo >= HASH_ALGO__LAST)
+		algo = ima_hash_algo;
+
+	if (algo != ima_hash_algo) {
 		tfm = crypto_alloc_shash(hash_algo_name[algo], 0, 0);
 		if (IS_ERR(tfm)) {
 			rc = PTR_ERR(tfm);

commit 9a8d289fbcb7dfd1fc74959e9930b406e76b2002
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Mon Jul 28 07:59:49 2014 -0400

    ima: fix ima_alloc_atfm()
    
    The patch 3bcced39ea7d: "ima: use ahash API for file hash
    calculation" from Feb 26, 2014, leads to the following static checker
    warning:
    
    security/integrity/ima/ima_crypto.c:204 ima_alloc_atfm()
     error: buffer overflow 'hash_algo_name' 17 <= 17
    
    Unlike shash tfm memory, which is allocated on initialization, the
    ahash tfm memory allocation is deferred until needed.
    
    This patch fixes the case where ima_ahash_tfm has not yet been
    allocated and the file's signature/hash xattr contains an invalid hash
    algorithm.  Although we can not verify the xattr, we still need to
    measure the file.  Use the default IMA hash algorithm.
    
    Changelog:
    - set valid algo before testing tfm - based on Dmitry's comment
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 0bd732843fe7..2d103dc13d90 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -200,7 +200,10 @@ static struct crypto_ahash *ima_alloc_atfm(enum hash_algo algo)
 	struct crypto_ahash *tfm = ima_ahash_tfm;
 	int rc;
 
-	if ((algo != ima_hash_algo && algo < HASH_ALGO__LAST) || !tfm) {
+	if (algo < 0 || algo >= HASH_ALGO__LAST)
+		algo = ima_hash_algo;
+
+	if (algo != ima_hash_algo || !tfm) {
 		tfm = crypto_alloc_ahash(hash_algo_name[algo], 0, 0);
 		if (!IS_ERR(tfm)) {
 			if (algo == ima_hash_algo)

commit 32c2e6752ff0f48fe03b9e1c7c64bde580a840d2
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Tue May 6 14:54:27 2014 +0300

    ima: provide double buffering for hash calculation
    
    The asynchronous hash API allows initiating a hash calculation and
    then performing other tasks, while waiting for the hash calculation
    to complete.
    
    This patch introduces usage of double buffering for simultaneous
    hashing and reading of the next chunk of data from storage.
    
    Changes in v3:
    - better comments
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 84b938f86bea..0bd732843fe7 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -253,12 +253,12 @@ static int ima_calc_file_hash_atfm(struct file *file,
 				   struct crypto_ahash *tfm)
 {
 	loff_t i_size, offset;
-	char *rbuf;
-	int rc, read = 0, rbuf_len;
+	char *rbuf[2] = { NULL, };
+	int rc, read = 0, rbuf_len, active = 0, ahash_rc = 0;
 	struct ahash_request *req;
 	struct scatterlist sg[1];
 	struct ahash_completion res;
-	size_t rbuf_size;
+	size_t rbuf_size[2];
 
 	hash->length = crypto_ahash_digestsize(tfm);
 
@@ -284,36 +284,69 @@ static int ima_calc_file_hash_atfm(struct file *file,
 	 * Try to allocate maximum size of memory.
 	 * Fail if even a single page cannot be allocated.
 	 */
-	rbuf = ima_alloc_pages(i_size, &rbuf_size, 1);
-	if (!rbuf) {
+	rbuf[0] = ima_alloc_pages(i_size, &rbuf_size[0], 1);
+	if (!rbuf[0]) {
 		rc = -ENOMEM;
 		goto out1;
 	}
 
+	/* Only allocate one buffer if that is enough. */
+	if (i_size > rbuf_size[0]) {
+		/*
+		 * Try to allocate secondary buffer. If that fails fallback to
+		 * using single buffering. Use previous memory allocation size
+		 * as baseline for possible allocation size.
+		 */
+		rbuf[1] = ima_alloc_pages(i_size - rbuf_size[0],
+					  &rbuf_size[1], 0);
+	}
+
 	if (!(file->f_mode & FMODE_READ)) {
 		file->f_mode |= FMODE_READ;
 		read = 1;
 	}
 
 	for (offset = 0; offset < i_size; offset += rbuf_len) {
-		rbuf_len = ima_kernel_read(file, offset, rbuf, PAGE_SIZE);
-		if (rbuf_len < 0) {
-			rc = rbuf_len;
-			break;
+		if (!rbuf[1] && offset) {
+			/* Not using two buffers, and it is not the first
+			 * read/request, wait for the completion of the
+			 * previous ahash_update() request.
+			 */
+			rc = ahash_wait(ahash_rc, &res);
+			if (rc)
+				goto out3;
+		}
+		/* read buffer */
+		rbuf_len = min_t(loff_t, i_size - offset, rbuf_size[active]);
+		rc = ima_kernel_read(file, offset, rbuf[active], rbuf_len);
+		if (rc != rbuf_len)
+			goto out3;
+
+		if (rbuf[1] && offset) {
+			/* Using two buffers, and it is not the first
+			 * read/request, wait for the completion of the
+			 * previous ahash_update() request.
+			 */
+			rc = ahash_wait(ahash_rc, &res);
+			if (rc)
+				goto out3;
 		}
-		if (rbuf_len == 0)
-			break;
 
-		sg_init_one(&sg[0], rbuf, rbuf_len);
+		sg_init_one(&sg[0], rbuf[active], rbuf_len);
 		ahash_request_set_crypt(req, sg, NULL, rbuf_len);
 
-		rc = ahash_wait(crypto_ahash_update(req), &res);
-		if (rc)
-			break;
+		ahash_rc = crypto_ahash_update(req);
+
+		if (rbuf[1])
+			active = !active; /* swap buffers, if we use two */
 	}
+	/* wait for the last update request to complete */
+	rc = ahash_wait(ahash_rc, &res);
+out3:
 	if (read)
 		file->f_mode &= ~FMODE_READ;
-	ima_free_pages(rbuf, rbuf_size);
+	ima_free_pages(rbuf[0], rbuf_size[0]);
+	ima_free_pages(rbuf[1], rbuf_size[1]);
 out2:
 	if (!rc) {
 		ahash_request_set_crypt(req, NULL, hash->digest, 0);

commit 6edf7a89260859c5e72861dc4e6e169495f076c8
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Tue May 6 14:47:13 2014 +0300

    ima: introduce multi-page collect buffers
    
    Use of multiple-page collect buffers reduces:
    1) the number of block IO requests
    2) the number of asynchronous hash update requests
    
    Second is important for HW accelerated hashing, because significant
    amount of time is spent for preparation of hash update operation,
    which includes configuring acceleration HW, DMA engine, etc...
    Thus, HW accelerators are more efficient when working on large
    chunks of data.
    
    This patch introduces usage of multi-page collect buffers. Buffer size
    can be specified using 'ahash_bufsize' module parameter. Default buffer
    size is 4096 bytes.
    
    Changes in v3:
    - kernel parameter replaced with module parameter
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index b9e5120559d4..84b938f86bea 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -37,6 +37,33 @@ static unsigned long ima_ahash_minsize;
 module_param_named(ahash_minsize, ima_ahash_minsize, ulong, 0644);
 MODULE_PARM_DESC(ahash_minsize, "Minimum file size for ahash use");
 
+/* default is 0 - 1 page. */
+static int ima_maxorder;
+static unsigned int ima_bufsize = PAGE_SIZE;
+
+static int param_set_bufsize(const char *val, const struct kernel_param *kp)
+{
+	unsigned long long size;
+	int order;
+
+	size = memparse(val, NULL);
+	order = get_order(size);
+	if (order >= MAX_ORDER)
+		return -EINVAL;
+	ima_maxorder = order;
+	ima_bufsize = PAGE_SIZE << order;
+	return 0;
+}
+
+static struct kernel_param_ops param_ops_bufsize = {
+	.set = param_set_bufsize,
+	.get = param_get_uint,
+};
+#define param_check_bufsize(name, p) __param_check(name, p, unsigned int)
+
+module_param_named(ahash_bufsize, ima_bufsize, bufsize, 0644);
+MODULE_PARM_DESC(ahash_bufsize, "Maximum ahash buffer size");
+
 static struct crypto_shash *ima_shash_tfm;
 static struct crypto_ahash *ima_ahash_tfm;
 
@@ -106,6 +133,68 @@ static void ima_free_tfm(struct crypto_shash *tfm)
 		crypto_free_shash(tfm);
 }
 
+/**
+ * ima_alloc_pages() - Allocate contiguous pages.
+ * @max_size:       Maximum amount of memory to allocate.
+ * @allocated_size: Returned size of actual allocation.
+ * @last_warn:      Should the min_size allocation warn or not.
+ *
+ * Tries to do opportunistic allocation for memory first trying to allocate
+ * max_size amount of memory and then splitting that until zero order is
+ * reached. Allocation is tried without generating allocation warnings unless
+ * last_warn is set. Last_warn set affects only last allocation of zero order.
+ *
+ * By default, ima_maxorder is 0 and it is equivalent to kmalloc(GFP_KERNEL)
+ *
+ * Return pointer to allocated memory, or NULL on failure.
+ */
+static void *ima_alloc_pages(loff_t max_size, size_t *allocated_size,
+			     int last_warn)
+{
+	void *ptr;
+	int order = ima_maxorder;
+	gfp_t gfp_mask = __GFP_WAIT | __GFP_NOWARN | __GFP_NORETRY;
+
+	if (order)
+		order = min(get_order(max_size), order);
+
+	for (; order; order--) {
+		ptr = (void *)__get_free_pages(gfp_mask, order);
+		if (ptr) {
+			*allocated_size = PAGE_SIZE << order;
+			return ptr;
+		}
+	}
+
+	/* order is zero - one page */
+
+	gfp_mask = GFP_KERNEL;
+
+	if (!last_warn)
+		gfp_mask |= __GFP_NOWARN;
+
+	ptr = (void *)__get_free_pages(gfp_mask, 0);
+	if (ptr) {
+		*allocated_size = PAGE_SIZE;
+		return ptr;
+	}
+
+	*allocated_size = 0;
+	return NULL;
+}
+
+/**
+ * ima_free_pages() - Free pages allocated by ima_alloc_pages().
+ * @ptr:  Pointer to allocated pages.
+ * @size: Size of allocated buffer.
+ */
+static void ima_free_pages(void *ptr, size_t size)
+{
+	if (!ptr)
+		return;
+	free_pages((unsigned long)ptr, get_order(size));
+}
+
 static struct crypto_ahash *ima_alloc_atfm(enum hash_algo algo)
 {
 	struct crypto_ahash *tfm = ima_ahash_tfm;
@@ -169,6 +258,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 	struct ahash_request *req;
 	struct scatterlist sg[1];
 	struct ahash_completion res;
+	size_t rbuf_size;
 
 	hash->length = crypto_ahash_digestsize(tfm);
 
@@ -190,7 +280,11 @@ static int ima_calc_file_hash_atfm(struct file *file,
 	if (i_size == 0)
 		goto out2;
 
-	rbuf = kzalloc(PAGE_SIZE, GFP_KERNEL);
+	/*
+	 * Try to allocate maximum size of memory.
+	 * Fail if even a single page cannot be allocated.
+	 */
+	rbuf = ima_alloc_pages(i_size, &rbuf_size, 1);
 	if (!rbuf) {
 		rc = -ENOMEM;
 		goto out1;
@@ -219,7 +313,7 @@ static int ima_calc_file_hash_atfm(struct file *file,
 	}
 	if (read)
 		file->f_mode &= ~FMODE_READ;
-	kfree(rbuf);
+	ima_free_pages(rbuf, rbuf_size);
 out2:
 	if (!rc) {
 		ahash_request_set_crypt(req, NULL, hash->digest, 0);

commit 3bcced39ea7d1b0da0a991e221f53de480c6b60b
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Wed Feb 26 17:05:20 2014 +0200

    ima: use ahash API for file hash calculation
    
    Async hash API allows the use of HW acceleration for hash calculation.
    It may give significant performance gain and/or reduce power consumption,
    which might be very beneficial for battery powered devices.
    
    This patch introduces hash calculation using ahash API. ahash performance
    depends on the data size and the particular HW. Depending on the specific
    system, shash performance may be better.
    
    This patch defines 'ahash_minsize' module parameter, which is used to
    define the minimal file size to use with ahash.  If this minimum file size
    is not set or the file is smaller than defined by the parameter, shash will
    be used.
    
    Changes in v3:
    - kernel parameter replaced with module parameter
    - pr_crit replaced with pr_crit_ratelimited
    - more comment changes - Mimi
    
    Changes in v2:
    - ima_ahash_size became as ima_ahash
    - ahash pre-allocation moved out from __init code to be able to use
      ahash crypto modules. Ahash allocated once on the first use.
    - hash calculation falls back to shash if ahash allocation/calculation fails
    - complex initialization separated from variable declaration
    - improved comments
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index ccd0ac8fa9a0..b9e5120559d4 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -16,6 +16,8 @@
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
+#include <linux/moduleparam.h>
+#include <linux/ratelimit.h>
 #include <linux/file.h>
 #include <linux/crypto.h>
 #include <linux/scatterlist.h>
@@ -25,7 +27,18 @@
 #include <crypto/hash_info.h>
 #include "ima.h"
 
+struct ahash_completion {
+	struct completion completion;
+	int err;
+};
+
+/* minimum file size for ahash use */
+static unsigned long ima_ahash_minsize;
+module_param_named(ahash_minsize, ima_ahash_minsize, ulong, 0644);
+MODULE_PARM_DESC(ahash_minsize, "Minimum file size for ahash use");
+
 static struct crypto_shash *ima_shash_tfm;
+static struct crypto_ahash *ima_ahash_tfm;
 
 /**
  * ima_kernel_read - read file content
@@ -93,9 +106,146 @@ static void ima_free_tfm(struct crypto_shash *tfm)
 		crypto_free_shash(tfm);
 }
 
-/*
- * Calculate the MD5/SHA1 file digest
- */
+static struct crypto_ahash *ima_alloc_atfm(enum hash_algo algo)
+{
+	struct crypto_ahash *tfm = ima_ahash_tfm;
+	int rc;
+
+	if ((algo != ima_hash_algo && algo < HASH_ALGO__LAST) || !tfm) {
+		tfm = crypto_alloc_ahash(hash_algo_name[algo], 0, 0);
+		if (!IS_ERR(tfm)) {
+			if (algo == ima_hash_algo)
+				ima_ahash_tfm = tfm;
+		} else {
+			rc = PTR_ERR(tfm);
+			pr_err("Can not allocate %s (reason: %d)\n",
+			       hash_algo_name[algo], rc);
+		}
+	}
+	return tfm;
+}
+
+static void ima_free_atfm(struct crypto_ahash *tfm)
+{
+	if (tfm != ima_ahash_tfm)
+		crypto_free_ahash(tfm);
+}
+
+static void ahash_complete(struct crypto_async_request *req, int err)
+{
+	struct ahash_completion *res = req->data;
+
+	if (err == -EINPROGRESS)
+		return;
+	res->err = err;
+	complete(&res->completion);
+}
+
+static int ahash_wait(int err, struct ahash_completion *res)
+{
+	switch (err) {
+	case 0:
+		break;
+	case -EINPROGRESS:
+	case -EBUSY:
+		wait_for_completion(&res->completion);
+		reinit_completion(&res->completion);
+		err = res->err;
+		/* fall through */
+	default:
+		pr_crit_ratelimited("ahash calculation failed: err: %d\n", err);
+	}
+
+	return err;
+}
+
+static int ima_calc_file_hash_atfm(struct file *file,
+				   struct ima_digest_data *hash,
+				   struct crypto_ahash *tfm)
+{
+	loff_t i_size, offset;
+	char *rbuf;
+	int rc, read = 0, rbuf_len;
+	struct ahash_request *req;
+	struct scatterlist sg[1];
+	struct ahash_completion res;
+
+	hash->length = crypto_ahash_digestsize(tfm);
+
+	req = ahash_request_alloc(tfm, GFP_KERNEL);
+	if (!req)
+		return -ENOMEM;
+
+	init_completion(&res.completion);
+	ahash_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG |
+				   CRYPTO_TFM_REQ_MAY_SLEEP,
+				   ahash_complete, &res);
+
+	rc = ahash_wait(crypto_ahash_init(req), &res);
+	if (rc)
+		goto out1;
+
+	i_size = i_size_read(file_inode(file));
+
+	if (i_size == 0)
+		goto out2;
+
+	rbuf = kzalloc(PAGE_SIZE, GFP_KERNEL);
+	if (!rbuf) {
+		rc = -ENOMEM;
+		goto out1;
+	}
+
+	if (!(file->f_mode & FMODE_READ)) {
+		file->f_mode |= FMODE_READ;
+		read = 1;
+	}
+
+	for (offset = 0; offset < i_size; offset += rbuf_len) {
+		rbuf_len = ima_kernel_read(file, offset, rbuf, PAGE_SIZE);
+		if (rbuf_len < 0) {
+			rc = rbuf_len;
+			break;
+		}
+		if (rbuf_len == 0)
+			break;
+
+		sg_init_one(&sg[0], rbuf, rbuf_len);
+		ahash_request_set_crypt(req, sg, NULL, rbuf_len);
+
+		rc = ahash_wait(crypto_ahash_update(req), &res);
+		if (rc)
+			break;
+	}
+	if (read)
+		file->f_mode &= ~FMODE_READ;
+	kfree(rbuf);
+out2:
+	if (!rc) {
+		ahash_request_set_crypt(req, NULL, hash->digest, 0);
+		rc = ahash_wait(crypto_ahash_final(req), &res);
+	}
+out1:
+	ahash_request_free(req);
+	return rc;
+}
+
+static int ima_calc_file_ahash(struct file *file, struct ima_digest_data *hash)
+{
+	struct crypto_ahash *tfm;
+	int rc;
+
+	tfm = ima_alloc_atfm(hash->algo);
+	if (IS_ERR(tfm))
+		return PTR_ERR(tfm);
+
+	rc = ima_calc_file_hash_atfm(file, hash, tfm);
+
+	ima_free_atfm(tfm);
+
+	return rc;
+}
+
 static int ima_calc_file_hash_tfm(struct file *file,
 				  struct ima_digest_data *hash,
 				  struct crypto_shash *tfm)
@@ -156,7 +306,7 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	return rc;
 }
 
-int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
+static int ima_calc_file_shash(struct file *file, struct ima_digest_data *hash)
 {
 	struct crypto_shash *tfm;
 	int rc;
@@ -172,6 +322,35 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 	return rc;
 }
 
+/*
+ * ima_calc_file_hash - calculate file hash
+ *
+ * Asynchronous hash (ahash) allows using HW acceleration for calculating
+ * a hash. ahash performance varies for different data sizes on different
+ * crypto accelerators. shash performance might be better for smaller files.
+ * The 'ima.ahash_minsize' module parameter allows specifying the best
+ * minimum file size for using ahash on the system.
+ *
+ * If the ima.ahash_minsize parameter is not specified, this function uses
+ * shash for the hash calculation.  If ahash fails, it falls back to using
+ * shash.
+ */
+int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
+{
+	loff_t i_size;
+	int rc;
+
+	i_size = i_size_read(file_inode(file));
+
+	if (ima_ahash_minsize && i_size >= ima_ahash_minsize) {
+		rc = ima_calc_file_ahash(file, hash);
+		if (!rc)
+			return 0;
+	}
+
+	return ima_calc_file_shash(file, hash);
+}
+
 /*
  * Calculate the hash of template data
  */

commit 0430e49b6e7c6b5e076be8fefdee089958c9adad
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Thu May 8 14:03:22 2014 +0300

    ima: introduce ima_kernel_read()
    
    Commit 8aac62706 "move exit_task_namespaces() outside of exit_notify"
    introduced the kernel opps since the kernel v3.10, which happens when
    Apparmor and IMA-appraisal are enabled at the same time.
    
    ----------------------------------------------------------------------
    [  106.750167] BUG: unable to handle kernel NULL pointer dereference at
    0000000000000018
    [  106.750221] IP: [<ffffffff811ec7da>] our_mnt+0x1a/0x30
    [  106.750241] PGD 0
    [  106.750254] Oops: 0000 [#1] SMP
    [  106.750272] Modules linked in: cuse parport_pc ppdev bnep rfcomm
    bluetooth rpcsec_gss_krb5 nfsd auth_rpcgss nfs_acl nfs lockd sunrpc
    fscache dm_crypt intel_rapl x86_pkg_temp_thermal intel_powerclamp
    kvm_intel snd_hda_codec_hdmi kvm crct10dif_pclmul crc32_pclmul
    ghash_clmulni_intel aesni_intel aes_x86_64 glue_helper lrw gf128mul
    ablk_helper cryptd snd_hda_codec_realtek dcdbas snd_hda_intel
    snd_hda_codec snd_hwdep snd_pcm snd_page_alloc snd_seq_midi
    snd_seq_midi_event snd_rawmidi psmouse snd_seq microcode serio_raw
    snd_timer snd_seq_device snd soundcore video lpc_ich coretemp mac_hid lp
    parport mei_me mei nbd hid_generic e1000e usbhid ahci ptp hid libahci
    pps_core
    [  106.750658] CPU: 6 PID: 1394 Comm: mysqld Not tainted 3.13.0-rc7-kds+ #15
    [  106.750673] Hardware name: Dell Inc. OptiPlex 9010/0M9KCM, BIOS A08
    09/19/2012
    [  106.750689] task: ffff8800de804920 ti: ffff880400fca000 task.ti:
    ffff880400fca000
    [  106.750704] RIP: 0010:[<ffffffff811ec7da>]  [<ffffffff811ec7da>]
    our_mnt+0x1a/0x30
    [  106.750725] RSP: 0018:ffff880400fcba60  EFLAGS: 00010286
    [  106.750738] RAX: 0000000000000000 RBX: 0000000000000100 RCX:
    ffff8800d51523e7
    [  106.750764] RDX: ffffffffffffffea RSI: ffff880400fcba34 RDI:
    ffff880402d20020
    [  106.750791] RBP: ffff880400fcbae0 R08: 0000000000000000 R09:
    0000000000000001
    [  106.750817] R10: 0000000000000000 R11: 0000000000000001 R12:
    ffff8800d5152300
    [  106.750844] R13: ffff8803eb8df510 R14: ffff880400fcbb28 R15:
    ffff8800d51523e7
    [  106.750871] FS:  0000000000000000(0000) GS:ffff88040d200000(0000)
    knlGS:0000000000000000
    [  106.750910] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  106.750935] CR2: 0000000000000018 CR3: 0000000001c0e000 CR4:
    00000000001407e0
    [  106.750962] Stack:
    [  106.750981]  ffffffff813434eb ffff880400fcbb20 ffff880400fcbb18
    0000000000000000
    [  106.751037]  ffff8800de804920 ffffffff8101b9b9 0001800000000000
    0000000000000100
    [  106.751093]  0000010000000000 0000000000000002 000000000000000e
    ffff8803eb8df500
    [  106.751149] Call Trace:
    [  106.751172]  [<ffffffff813434eb>] ? aa_path_name+0x2ab/0x430
    [  106.751199]  [<ffffffff8101b9b9>] ? sched_clock+0x9/0x10
    [  106.751225]  [<ffffffff8134a68d>] aa_path_perm+0x7d/0x170
    [  106.751250]  [<ffffffff8101b945>] ? native_sched_clock+0x15/0x80
    [  106.751276]  [<ffffffff8134aa73>] aa_file_perm+0x33/0x40
    [  106.751301]  [<ffffffff81348c5e>] common_file_perm+0x8e/0xb0
    [  106.751327]  [<ffffffff81348d78>] apparmor_file_permission+0x18/0x20
    [  106.751355]  [<ffffffff8130c853>] security_file_permission+0x23/0xa0
    [  106.751382]  [<ffffffff811c77a2>] rw_verify_area+0x52/0xe0
    [  106.751407]  [<ffffffff811c789d>] vfs_read+0x6d/0x170
    [  106.751432]  [<ffffffff811cda31>] kernel_read+0x41/0x60
    [  106.751457]  [<ffffffff8134fd45>] ima_calc_file_hash+0x225/0x280
    [  106.751483]  [<ffffffff8134fb52>] ? ima_calc_file_hash+0x32/0x280
    [  106.751509]  [<ffffffff8135022d>] ima_collect_measurement+0x9d/0x160
    [  106.751536]  [<ffffffff810b552d>] ? trace_hardirqs_on+0xd/0x10
    [  106.751562]  [<ffffffff8134f07c>] ? ima_file_free+0x6c/0xd0
    [  106.751587]  [<ffffffff81352824>] ima_update_xattr+0x34/0x60
    [  106.751612]  [<ffffffff8134f0d0>] ima_file_free+0xc0/0xd0
    [  106.751637]  [<ffffffff811c9635>] __fput+0xd5/0x300
    [  106.751662]  [<ffffffff811c98ae>] ____fput+0xe/0x10
    [  106.751687]  [<ffffffff81086774>] task_work_run+0xc4/0xe0
    [  106.751712]  [<ffffffff81066fad>] do_exit+0x2bd/0xa90
    [  106.751738]  [<ffffffff8173c958>] ? retint_swapgs+0x13/0x1b
    [  106.751763]  [<ffffffff8106780c>] do_group_exit+0x4c/0xc0
    [  106.751788]  [<ffffffff81067894>] SyS_exit_group+0x14/0x20
    [  106.751814]  [<ffffffff8174522d>] system_call_fastpath+0x1a/0x1f
    [  106.751839] Code: c3 0f 1f 44 00 00 55 48 89 e5 e8 22 fe ff ff 5d c3
    0f 1f 44 00 00 55 65 48 8b 04 25 c0 c9 00 00 48 8b 80 28 06 00 00 48 89
    e5 5d <48> 8b 40 18 48 39 87 c0 00 00 00 0f 94 c0 c3 0f 1f 80 00 00 00
    [  106.752185] RIP  [<ffffffff811ec7da>] our_mnt+0x1a/0x30
    [  106.752214]  RSP <ffff880400fcba60>
    [  106.752236] CR2: 0000000000000018
    [  106.752258] ---[ end trace 3c520748b4732721 ]---
    ----------------------------------------------------------------------
    
    The reason for the oops is that IMA-appraisal uses "kernel_read()" when
    file is closed. kernel_read() honors LSM security hook which calls
    Apparmor handler, which uses current->nsproxy->mnt_ns. The 'guilty'
    commit changed the order of cleanup code so that nsproxy->mnt_ns was
    not already available for Apparmor.
    
    Discussion about the issue with Al Viro and Eric W. Biederman suggested
    that kernel_read() is too high-level for IMA. Another issue, except
    security checking, that was identified is mandatory locking. kernel_read
    honors it as well and it might prevent IMA from calculating necessary hash.
    It was suggested to use simplified version of the function without security
    and locking checks.
    
    This patch introduces special version ima_kernel_read(), which skips security
    and mandatory locking checking. It prevents the kernel oops to happen.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Suggested-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 1bde8e627766..ccd0ac8fa9a0 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -27,6 +27,36 @@
 
 static struct crypto_shash *ima_shash_tfm;
 
+/**
+ * ima_kernel_read - read file content
+ *
+ * This is a function for reading file content instead of kernel_read().
+ * It does not perform locking checks to ensure it cannot be blocked.
+ * It does not perform security checks because it is irrelevant for IMA.
+ *
+ */
+static int ima_kernel_read(struct file *file, loff_t offset,
+			   char *addr, unsigned long count)
+{
+	mm_segment_t old_fs;
+	char __user *buf = addr;
+	ssize_t ret;
+
+	if (!(file->f_mode & FMODE_READ))
+		return -EBADF;
+	if (!file->f_op->read && !file->f_op->aio_read)
+		return -EINVAL;
+
+	old_fs = get_fs();
+	set_fs(get_ds());
+	if (file->f_op->read)
+		ret = file->f_op->read(file, buf, count, &offset);
+	else
+		ret = do_sync_read(file, buf, count, &offset);
+	set_fs(old_fs);
+	return ret;
+}
+
 int ima_init_crypto(void)
 {
 	long rc;
@@ -104,7 +134,7 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	while (offset < i_size) {
 		int rbuf_len;
 
-		rbuf_len = kernel_read(file, offset, rbuf, PAGE_SIZE);
+		rbuf_len = ima_kernel_read(file, offset, rbuf, PAGE_SIZE);
 		if (rbuf_len < 0) {
 			rc = rbuf_len;
 			break;

commit 1d91ac6213003f525ac34da5e39cbb6612d19deb
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Thu Feb 27 20:16:47 2014 +0200

    ima: skip memory allocation for empty files
    
    Memory allocation is unnecessary for empty files.
    This patch calculates the hash without memory allocation.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index d257e3631152..1bde8e627766 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -87,16 +87,20 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	if (rc != 0)
 		return rc;
 
-	rbuf = kzalloc(PAGE_SIZE, GFP_KERNEL);
-	if (!rbuf) {
-		rc = -ENOMEM;
+	i_size = i_size_read(file_inode(file));
+
+	if (i_size == 0)
 		goto out;
-	}
+
+	rbuf = kzalloc(PAGE_SIZE, GFP_KERNEL);
+	if (!rbuf)
+		return -ENOMEM;
+
 	if (!(file->f_mode & FMODE_READ)) {
 		file->f_mode |= FMODE_READ;
 		read = 1;
 	}
-	i_size = i_size_read(file_inode(file));
+
 	while (offset < i_size) {
 		int rbuf_len;
 
@@ -113,12 +117,12 @@ static int ima_calc_file_hash_tfm(struct file *file,
 		if (rc)
 			break;
 	}
-	kfree(rbuf);
-	if (!rc)
-		rc = crypto_shash_final(&desc.shash, hash->digest);
 	if (read)
 		file->f_mode &= ~FMODE_READ;
+	kfree(rbuf);
 out:
+	if (!rc)
+		rc = crypto_shash_final(&desc.shash, hash->digest);
 	return rc;
 }
 

commit 2bb930abcf39d8be243ddb4583cf013ea2a750d6
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Tue Mar 4 18:04:20 2014 +0200

    integrity: fix checkpatch errors
    
    Between checkpatch changes (eg. sizeof) and inconsistencies between
    Lindent and checkpatch, unfixed checkpatch errors make it difficult
    to see new errors. This patch fixes them. Some lines with over 80 chars
    remained unchanged to improve code readability.
    
    The "extern" keyword is removed from internal evm.h to make it consistent
    with internal ima.h.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 99990578b7cd..d257e3631152 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -10,7 +10,7 @@
  * the Free Software Foundation, version 2 of the License.
  *
  * File: ima_crypto.c
- * 	Calculates md5/sha1 file hash, template hash, boot-aggreate hash
+ *	Calculates md5/sha1 file hash, template hash, boot-aggreate hash
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt

commit 20ee451f5a7cd43edda56ba36cbec4d881d3329f
Author: Joe Perches <joe@perches.com>
Date:   Mon Feb 24 13:59:56 2014 -0800

    security: integrity: Use a more current logging style
    
    Convert printks to pr_<level>.
    Add pr_fmt.
    Remove embedded prefixes.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index d8b55c952005..99990578b7cd 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -13,6 +13,8 @@
  * 	Calculates md5/sha1 file hash, template hash, boot-aggreate hash
  */
 
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
 #include <linux/kernel.h>
 #include <linux/file.h>
 #include <linux/crypto.h>
@@ -212,7 +214,7 @@ static void __init ima_pcrread(int idx, u8 *pcr)
 		return;
 
 	if (tpm_pcr_read(TPM_ANY_NUM, idx, pcr) != 0)
-		pr_err("IMA: Error Communicating to TPM chip\n");
+		pr_err("Error Communicating to TPM chip\n");
 }
 
 /*

commit e3b64c268b485f578a498c2f6d5704ef54ab4432
Author: Roberto Sassu <roberto.sassu@polito.it>
Date:   Mon Feb 3 13:56:05 2014 +0100

    ima: reduce memory usage when a template containing the n field is used
    
    Before this change, to correctly calculate the template digest for the
    'ima' template, the event name field (id: 'n') length was set to the fixed
    size of 256 bytes.
    
    This patch reduces the length of the event name field to the string
    length incremented of one (to make room for the termination character '\0')
    and handles the specific case of the digest calculation for the 'ima'
    template directly in ima_calc_field_array_hash_tfm().
    
    Signed-off-by: Roberto Sassu <roberto.sassu@polito.it>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index fdf60def52e9..d8b55c952005 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -161,15 +161,22 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 		return rc;
 
 	for (i = 0; i < num_fields; i++) {
+		u8 buffer[IMA_EVENT_NAME_LEN_MAX + 1] = { 0 };
+		u8 *data_to_hash = field_data[i].data;
+		u32 datalen = field_data[i].len;
+
 		if (strcmp(td->name, IMA_TEMPLATE_IMA_NAME) != 0) {
 			rc = crypto_shash_update(&desc.shash,
 						(const u8 *) &field_data[i].len,
 						sizeof(field_data[i].len));
 			if (rc)
 				break;
+		} else if (strcmp(td->fields[i]->field_id, "n") == 0) {
+			memcpy(buffer, data_to_hash, datalen);
+			data_to_hash = buffer;
+			datalen = IMA_EVENT_NAME_LEN_MAX + 1;
 		}
-		rc = crypto_shash_update(&desc.shash, field_data[i].data,
-					 field_data[i].len);
+		rc = crypto_shash_update(&desc.shash, data_to_hash, datalen);
 		if (rc)
 			break;
 	}

commit b6f8f16f41d92861621b043389ef49de1c52d613
Author: Roberto Sassu <roberto.sassu@polito.it>
Date:   Fri Nov 8 19:21:39 2013 +0100

    ima: do not include field length in template digest calc for ima template
    
    To maintain compatibility with userspace tools, the field length must not
    be included in the template digest calculation for the 'ima' template.
    
    Fixes commit: a71dc65 ima: switch to new template management mechanism
    
    Signed-off-by: Roberto Sassu <roberto.sassu@polito.it>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 676e0292dfec..fdf60def52e9 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -140,6 +140,7 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
  * Calculate the hash of template data
  */
 static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
+					 struct ima_template_desc *td,
 					 int num_fields,
 					 struct ima_digest_data *hash,
 					 struct crypto_shash *tfm)
@@ -160,9 +161,13 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 		return rc;
 
 	for (i = 0; i < num_fields; i++) {
-		rc = crypto_shash_update(&desc.shash,
-					 (const u8 *) &field_data[i].len,
-					 sizeof(field_data[i].len));
+		if (strcmp(td->name, IMA_TEMPLATE_IMA_NAME) != 0) {
+			rc = crypto_shash_update(&desc.shash,
+						(const u8 *) &field_data[i].len,
+						sizeof(field_data[i].len));
+			if (rc)
+				break;
+		}
 		rc = crypto_shash_update(&desc.shash, field_data[i].data,
 					 field_data[i].len);
 		if (rc)
@@ -175,7 +180,8 @@ static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
 	return rc;
 }
 
-int ima_calc_field_array_hash(struct ima_field_data *field_data, int num_fields,
+int ima_calc_field_array_hash(struct ima_field_data *field_data,
+			      struct ima_template_desc *desc, int num_fields,
 			      struct ima_digest_data *hash)
 {
 	struct crypto_shash *tfm;
@@ -185,7 +191,8 @@ int ima_calc_field_array_hash(struct ima_field_data *field_data, int num_fields,
 	if (IS_ERR(tfm))
 		return PTR_ERR(tfm);
 
-	rc = ima_calc_field_array_hash_tfm(field_data, num_fields, hash, tfm);
+	rc = ima_calc_field_array_hash_tfm(field_data, desc, num_fields,
+					   hash, tfm);
 
 	ima_free_tfm(tfm);
 

commit a71dc65d30a472409f05d247f4eab91b14acf2f5
Author: Roberto Sassu <roberto.sassu@polito.it>
Date:   Fri Jun 7 12:16:33 2013 +0200

    ima: switch to new template management mechanism
    
    This patch performs the switch to the new template mechanism by modifying
    the functions ima_alloc_init_template(), ima_measurements_show() and
    ima_ascii_measurements_show(). The old function ima_template_show() was
    removed as it is no longer needed. Also, if the template descriptor used
    to generate a measurement entry is not 'ima', the whole length of field
    data stored for an entry is provided before the data itself through the
    binary_runtime_measurement interface.
    
    Changelog:
    - unnecessary to use strncmp() (Mimi Zohar)
    - create new variable 'field' in ima_alloc_init_template() (Roberto Sassu)
    - use GFP_NOFS flag in ima_alloc_init_template() (Roberto Sassu)
    - new variable 'num_fields' in ima_store_template() (Roberto Sassu,
      proposed by Mimi Zohar)
    - rename ima_calc_buffer_hash/template_hash() to ima_calc_field_array_hash(),
      something more generic (Mimi, requested by Dmitry)
    - sparse error fix - Fengguang Wu
    - fix lindent warnings
    - always include the field length in the template data length
    - include the template field length variable size in the template data length
    - include both the template field data and field length in the template digest
      calculation. Simplifies verifying the template digest. (Mimi)
    
    Signed-off-by: Roberto Sassu <roberto.sassu@polito.it>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 22be23f13b3d..676e0292dfec 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -137,26 +137,46 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 }
 
 /*
- * Calculate the hash of a given buffer
+ * Calculate the hash of template data
  */
-static int ima_calc_buffer_hash_tfm(const void *buf, int len,
-				    struct ima_digest_data *hash,
-				    struct crypto_shash *tfm)
+static int ima_calc_field_array_hash_tfm(struct ima_field_data *field_data,
+					 int num_fields,
+					 struct ima_digest_data *hash,
+					 struct crypto_shash *tfm)
 {
 	struct {
 		struct shash_desc shash;
 		char ctx[crypto_shash_descsize(tfm)];
 	} desc;
+	int rc, i;
 
 	desc.shash.tfm = tfm;
 	desc.shash.flags = 0;
 
 	hash->length = crypto_shash_digestsize(tfm);
 
-	return crypto_shash_digest(&desc.shash, buf, len, hash->digest);
+	rc = crypto_shash_init(&desc.shash);
+	if (rc != 0)
+		return rc;
+
+	for (i = 0; i < num_fields; i++) {
+		rc = crypto_shash_update(&desc.shash,
+					 (const u8 *) &field_data[i].len,
+					 sizeof(field_data[i].len));
+		rc = crypto_shash_update(&desc.shash, field_data[i].data,
+					 field_data[i].len);
+		if (rc)
+			break;
+	}
+
+	if (!rc)
+		rc = crypto_shash_final(&desc.shash, hash->digest);
+
+	return rc;
 }
 
-int ima_calc_buffer_hash(const void *buf, int len, struct ima_digest_data *hash)
+int ima_calc_field_array_hash(struct ima_field_data *field_data, int num_fields,
+			      struct ima_digest_data *hash)
 {
 	struct crypto_shash *tfm;
 	int rc;
@@ -165,7 +185,7 @@ int ima_calc_buffer_hash(const void *buf, int len, struct ima_digest_data *hash)
 	if (IS_ERR(tfm))
 		return PTR_ERR(tfm);
 
-	rc = ima_calc_buffer_hash_tfm(buf, len, hash, tfm);
+	rc = ima_calc_field_array_hash_tfm(field_data, num_fields, hash, tfm);
 
 	ima_free_tfm(tfm);
 

commit 09ef54359c4ad49c01a12503b2c510b424ecf059
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Fri Jun 7 12:16:25 2013 +0200

    ima: ima_calc_boot_agregate must use SHA1
    
    With multiple hash algorithms, ima_hash_tfm is no longer guaranteed to be sha1.
    Need to force to use sha1.
    
    Changelog:
    - pass ima_digest_data to ima_calc_boot_aggregate() instead of char *
      (Roberto Sassu);
    - create an ima_digest_data structure in ima_add_boot_aggregate()
      (Roberto Sassu);
    - pass hash->algo to ima_alloc_tfm() (Roberto Sassu, reported by Dmitry).
    - "move hash definition in ima_add_boot_aggregate()" commit hunk to here.
    - sparse warning fix - Fengguang Wu
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Roberto Sassu <roberto.sassu@polito.it>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index e2be2524a372..22be23f13b3d 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -184,16 +184,17 @@ static void __init ima_pcrread(int idx, u8 *pcr)
 /*
  * Calculate the boot aggregate hash
  */
-int __init ima_calc_boot_aggregate(char *digest)
+static int __init ima_calc_boot_aggregate_tfm(char *digest,
+					      struct crypto_shash *tfm)
 {
 	u8 pcr_i[TPM_DIGEST_SIZE];
 	int rc, i;
 	struct {
 		struct shash_desc shash;
-		char ctx[crypto_shash_descsize(ima_shash_tfm)];
+		char ctx[crypto_shash_descsize(tfm)];
 	} desc;
 
-	desc.shash.tfm = ima_shash_tfm;
+	desc.shash.tfm = tfm;
 	desc.shash.flags = 0;
 
 	rc = crypto_shash_init(&desc.shash);
@@ -210,3 +211,20 @@ int __init ima_calc_boot_aggregate(char *digest)
 		crypto_shash_final(&desc.shash, digest);
 	return rc;
 }
+
+int __init ima_calc_boot_aggregate(struct ima_digest_data *hash)
+{
+	struct crypto_shash *tfm;
+	int rc;
+
+	tfm = ima_alloc_tfm(hash->algo);
+	if (IS_ERR(tfm))
+		return PTR_ERR(tfm);
+
+	hash->length = crypto_shash_digestsize(tfm);
+	rc = ima_calc_boot_aggregate_tfm(hash->digest, tfm);
+
+	ima_free_tfm(tfm);
+
+	return rc;
+}

commit ea593993d361748e795f5eb783a5fb5144fb2df9
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Fri Jun 7 12:16:24 2013 +0200

    ima: support arbitrary hash algorithms in ima_calc_buffer_hash
    
    ima_calc_buffer_hash will be used with different hash algorithms.
    This patch provides support for arbitrary hash algorithms in
    ima_calc_buffer_hash.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index e5d3ebf18436..e2be2524a372 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -139,23 +139,39 @@ int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 /*
  * Calculate the hash of a given buffer
  */
-int ima_calc_buffer_hash(const void *buf, int len, struct ima_digest_data *hash)
+static int ima_calc_buffer_hash_tfm(const void *buf, int len,
+				    struct ima_digest_data *hash,
+				    struct crypto_shash *tfm)
 {
 	struct {
 		struct shash_desc shash;
-		char ctx[crypto_shash_descsize(ima_shash_tfm)];
+		char ctx[crypto_shash_descsize(tfm)];
 	} desc;
 
-	desc.shash.tfm = ima_shash_tfm;
+	desc.shash.tfm = tfm;
 	desc.shash.flags = 0;
 
-	/* this function uses default algo */
-	hash->algo = ima_hash_algo;
-	hash->length = crypto_shash_digestsize(ima_shash_tfm);
+	hash->length = crypto_shash_digestsize(tfm);
 
 	return crypto_shash_digest(&desc.shash, buf, len, hash->digest);
 }
 
+int ima_calc_buffer_hash(const void *buf, int len, struct ima_digest_data *hash)
+{
+	struct crypto_shash *tfm;
+	int rc;
+
+	tfm = ima_alloc_tfm(hash->algo);
+	if (IS_ERR(tfm))
+		return PTR_ERR(tfm);
+
+	rc = ima_calc_buffer_hash_tfm(buf, len, hash, tfm);
+
+	ima_free_tfm(tfm);
+
+	return rc;
+}
+
 static void __init ima_pcrread(int idx, u8 *pcr)
 {
 	if (!ima_used_chip)

commit 723326b927b675daf4223fe31d7428eca68f194b
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Thu Jul 4 17:40:01 2013 +0300

    ima: provide dedicated hash algo allocation function
    
    This patch provides dedicated hash algo allocation and
    deallocation function which can be used by different clients.
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 872c6698067c..e5d3ebf18436 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -39,6 +39,28 @@ int ima_init_crypto(void)
 	return 0;
 }
 
+static struct crypto_shash *ima_alloc_tfm(enum hash_algo algo)
+{
+	struct crypto_shash *tfm = ima_shash_tfm;
+	int rc;
+
+	if (algo != ima_hash_algo && algo < HASH_ALGO__LAST) {
+		tfm = crypto_alloc_shash(hash_algo_name[algo], 0, 0);
+		if (IS_ERR(tfm)) {
+			rc = PTR_ERR(tfm);
+			pr_err("Can not allocate %s (reason: %d)\n",
+			       hash_algo_name[algo], rc);
+		}
+	}
+	return tfm;
+}
+
+static void ima_free_tfm(struct crypto_shash *tfm)
+{
+	if (tfm != ima_shash_tfm)
+		crypto_free_shash(tfm);
+}
+
 /*
  * Calculate the MD5/SHA1 file digest
  */
@@ -57,6 +79,8 @@ static int ima_calc_file_hash_tfm(struct file *file,
 	desc.shash.tfm = tfm;
 	desc.shash.flags = 0;
 
+	hash->length = crypto_shash_digestsize(tfm);
+
 	rc = crypto_shash_init(&desc.shash);
 	if (rc != 0)
 		return rc;
@@ -98,25 +122,16 @@ static int ima_calc_file_hash_tfm(struct file *file,
 
 int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
 {
-	struct crypto_shash *tfm = ima_shash_tfm;
+	struct crypto_shash *tfm;
 	int rc;
 
-	if (hash->algo != ima_hash_algo && hash->algo < HASH_ALGO__LAST) {
-		tfm = crypto_alloc_shash(hash_algo_name[hash->algo], 0, 0);
-		if (IS_ERR(tfm)) {
-			rc = PTR_ERR(tfm);
-			pr_err("Can not allocate %s (reason: %d)\n",
-			       hash_algo_name[hash->algo], rc);
-			return rc;
-		}
-	}
-
-	hash->length = crypto_shash_digestsize(tfm);
+	tfm = ima_alloc_tfm(hash->algo);
+	if (IS_ERR(tfm))
+		return PTR_ERR(tfm);
 
 	rc = ima_calc_file_hash_tfm(file, hash, tfm);
 
-	if (tfm != ima_shash_tfm)
-		crypto_free_shash(tfm);
+	ima_free_tfm(tfm);
 
 	return rc;
 }

commit 140d802240a4ba3351494b4ab199964b96f87493
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Mon Mar 11 20:29:47 2013 -0400

    ima: differentiate between template hash and file data hash sizes
    
    The TPM v1.2 limits the template hash size to 20 bytes.  This
    patch differentiates between the template hash size, as defined
    in the ima_template_entry, and the file data hash size, as
    defined in the ima_template_data.  Subsequent patches add support
    for different file data hash algorithms.
    
    Change log:
    - hash digest definition in ima_store_template() should be TPM_DIGEST_SIZE
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 2fd178651467..872c6698067c 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -155,7 +155,7 @@ static void __init ima_pcrread(int idx, u8 *pcr)
  */
 int __init ima_calc_boot_aggregate(char *digest)
 {
-	u8 pcr_i[IMA_DIGEST_SIZE];
+	u8 pcr_i[TPM_DIGEST_SIZE];
 	int rc, i;
 	struct {
 		struct shash_desc shash;
@@ -173,7 +173,7 @@ int __init ima_calc_boot_aggregate(char *digest)
 	for (i = TPM_PCR0; i < TPM_PCR8; i++) {
 		ima_pcrread(i, pcr_i);
 		/* now accumulate with current aggregate */
-		rc = crypto_shash_update(&desc.shash, pcr_i, IMA_DIGEST_SIZE);
+		rc = crypto_shash_update(&desc.shash, pcr_i, TPM_DIGEST_SIZE);
 	}
 	if (!rc)
 		crypto_shash_final(&desc.shash, digest);

commit c7c8bb237fdbff932b5e431aebee5ce862ea07d1
Author: Dmitry Kasatkin <d.kasatkin@samsung.com>
Date:   Thu Apr 25 10:43:56 2013 +0300

    ima: provide support for arbitrary hash algorithms
    
    In preparation of supporting more hash algorithms with larger hash sizes
    needed for signature verification, this patch replaces the 20 byte sized
    digest, with a more flexible structure.  The new structure includes the
    hash algorithm, digest size, and digest.
    
    Changelog:
    - recalculate filedata hash for the measurement list, if the signature
      hash digest size is greater than 20 bytes.
    - use generic HASH_ALGO_
    - make ima_calc_file_hash static
    - scripts lindent and checkpatch fixes
    
    Signed-off-by: Dmitry Kasatkin <d.kasatkin@samsung.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index a02e0791cf15..2fd178651467 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -20,6 +20,7 @@
 #include <linux/err.h>
 #include <linux/slab.h>
 #include <crypto/hash.h>
+#include <crypto/hash_info.h>
 #include "ima.h"
 
 static struct crypto_shash *ima_shash_tfm;
@@ -28,10 +29,11 @@ int ima_init_crypto(void)
 {
 	long rc;
 
-	ima_shash_tfm = crypto_alloc_shash(ima_hash, 0, 0);
+	ima_shash_tfm = crypto_alloc_shash(hash_algo_name[ima_hash_algo], 0, 0);
 	if (IS_ERR(ima_shash_tfm)) {
 		rc = PTR_ERR(ima_shash_tfm);
-		pr_err("Can not allocate %s (reason: %ld)\n", ima_hash, rc);
+		pr_err("Can not allocate %s (reason: %ld)\n",
+		       hash_algo_name[ima_hash_algo], rc);
 		return rc;
 	}
 	return 0;
@@ -40,17 +42,19 @@ int ima_init_crypto(void)
 /*
  * Calculate the MD5/SHA1 file digest
  */
-int ima_calc_file_hash(struct file *file, char *digest)
+static int ima_calc_file_hash_tfm(struct file *file,
+				  struct ima_digest_data *hash,
+				  struct crypto_shash *tfm)
 {
 	loff_t i_size, offset = 0;
 	char *rbuf;
 	int rc, read = 0;
 	struct {
 		struct shash_desc shash;
-		char ctx[crypto_shash_descsize(ima_shash_tfm)];
+		char ctx[crypto_shash_descsize(tfm)];
 	} desc;
 
-	desc.shash.tfm = ima_shash_tfm;
+	desc.shash.tfm = tfm;
 	desc.shash.flags = 0;
 
 	rc = crypto_shash_init(&desc.shash);
@@ -85,17 +89,42 @@ int ima_calc_file_hash(struct file *file, char *digest)
 	}
 	kfree(rbuf);
 	if (!rc)
-		rc = crypto_shash_final(&desc.shash, digest);
+		rc = crypto_shash_final(&desc.shash, hash->digest);
 	if (read)
 		file->f_mode &= ~FMODE_READ;
 out:
 	return rc;
 }
 
+int ima_calc_file_hash(struct file *file, struct ima_digest_data *hash)
+{
+	struct crypto_shash *tfm = ima_shash_tfm;
+	int rc;
+
+	if (hash->algo != ima_hash_algo && hash->algo < HASH_ALGO__LAST) {
+		tfm = crypto_alloc_shash(hash_algo_name[hash->algo], 0, 0);
+		if (IS_ERR(tfm)) {
+			rc = PTR_ERR(tfm);
+			pr_err("Can not allocate %s (reason: %d)\n",
+			       hash_algo_name[hash->algo], rc);
+			return rc;
+		}
+	}
+
+	hash->length = crypto_shash_digestsize(tfm);
+
+	rc = ima_calc_file_hash_tfm(file, hash, tfm);
+
+	if (tfm != ima_shash_tfm)
+		crypto_free_shash(tfm);
+
+	return rc;
+}
+
 /*
  * Calculate the hash of a given buffer
  */
-int ima_calc_buffer_hash(const void *data, int len, char *digest)
+int ima_calc_buffer_hash(const void *buf, int len, struct ima_digest_data *hash)
 {
 	struct {
 		struct shash_desc shash;
@@ -105,7 +134,11 @@ int ima_calc_buffer_hash(const void *data, int len, char *digest)
 	desc.shash.tfm = ima_shash_tfm;
 	desc.shash.flags = 0;
 
-	return crypto_shash_digest(&desc.shash, data, len, digest);
+	/* this function uses default algo */
+	hash->algo = ima_hash_algo;
+	hash->length = crypto_shash_digestsize(ima_shash_tfm);
+
+	return crypto_shash_digest(&desc.shash, buf, len, hash->digest);
 }
 
 static void __init ima_pcrread(int idx, u8 *pcr)

commit d895cb1af15c04c522a25c79cc429076987c089b
Merge: 9626357371b5 d3d009cb965e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 26 20:16:07 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile (part one) from Al Viro:
     "Assorted stuff - cleaning namei.c up a bit, fixing ->d_name/->d_parent
      locking violations, etc.
    
      The most visible changes here are death of FS_REVAL_DOT (replaced with
      "has ->d_weak_revalidate()") and a new helper getting from struct file
      to inode.  Some bits of preparation to xattr method interface changes.
    
      Misc patches by various people sent this cycle *and* ocfs2 fixes from
      several cycles ago that should've been upstream right then.
    
      PS: the next vfs pile will be xattr stuff."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (46 commits)
      saner proc_get_inode() calling conventions
      proc: avoid extra pde_put() in proc_fill_super()
      fs: change return values from -EACCES to -EPERM
      fs/exec.c: make bprm_mm_init() static
      ocfs2/dlm: use GFP_ATOMIC inside a spin_lock
      ocfs2: fix possible use-after-free with AIO
      ocfs2: Fix oops in ocfs2_fast_symlink_readpage() code path
      get_empty_filp()/alloc_file() leave both ->f_pos and ->f_version zero
      target: writev() on single-element vector is pointless
      export kernel_write(), convert open-coded instances
      fs: encode_fh: return FILEID_INVALID if invalid fid_type
      kill f_vfsmnt
      vfs: kill FS_REVAL_DOT by adding a d_weak_revalidate dentry op
      nfsd: handle vfs_getattr errors in acl protocol
      switch vfs_getattr() to struct path
      default SET_PERSONALITY() in linux/elf.h
      ceph: prepopulate inodes only when request is aborted
      d_hash_and_lookup(): export, switch open-coded instances
      9p: switch v9fs_set_create_acl() to inode+fid, do it before d_instantiate()
      9p: split dropping the acls from v9fs_set_create_acl()
      ...

commit 496ad9aa8ef448058e36ca7a787c61f2e63f0f54
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 23 17:07:38 2013 -0500

    new helper: file_inode(file)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index b21ee5b5495a..81dcaa26401e 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -63,7 +63,7 @@ int ima_calc_hash(struct file *file, char *digest)
 		file->f_mode |= FMODE_READ;
 		read = 1;
 	}
-	i_size = i_size_read(file->f_dentry->d_inode);
+	i_size = i_size_read(file_inode(file));
 	while (offset < i_size) {
 		int rbuf_len;
 

commit 50af554466804bf51a52fa3d1d0a76f96bd33929
Author: Dmitry Kasatkin <dmitry.kasatkin@intel.com>
Date:   Mon May 14 14:13:56 2012 +0300

    ima: rename hash calculation functions
    
    Rename hash calculation functions to reflect meaning
    and change argument order in conventional way.
    
    Signed-off-by: Dmitry Kasatkin <dmitry.kasatkin@intel.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 920f49cfbf13..b691e0f3830c 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -40,7 +40,7 @@ int ima_init_crypto(void)
 /*
  * Calculate the MD5/SHA1 file digest
  */
-int ima_calc_hash(struct file *file, char *digest)
+int ima_calc_file_hash(struct file *file, char *digest)
 {
 	loff_t i_size, offset = 0;
 	char *rbuf;
@@ -93,9 +93,9 @@ int ima_calc_hash(struct file *file, char *digest)
 }
 
 /*
- * Calculate the hash of a given template
+ * Calculate the hash of a given buffer
  */
-int ima_calc_template_hash(int template_len, void *template, char *digest)
+int ima_calc_buffer_hash(const void *data, int len, char *digest)
 {
 	struct {
 		struct shash_desc shash;
@@ -105,7 +105,7 @@ int ima_calc_template_hash(int template_len, void *template, char *digest)
 	desc.shash.tfm = ima_shash_tfm;
 	desc.shash.flags = 0;
 
-	return crypto_shash_digest(&desc.shash, template, template_len, digest);
+	return crypto_shash_digest(&desc.shash, data, len, digest);
 }
 
 static void __init ima_pcrread(int idx, u8 *pcr)

commit 76bb28f6126f20ee987b9d2570fa653d95d30ae9
Author: Dmitry Kasatkin <dmitry.kasatkin@intel.com>
Date:   Fri Jun 8 10:42:30 2012 +0300

    ima: use new crypto_shash API instead of old crypto_hash
    
    Old crypto hash API internally uses shash API.
    Using shash API directly is more efficient.
    
    Signed-off-by: Dmitry Kasatkin <dmitry.kasatkin@intel.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index b21ee5b5495a..920f49cfbf13 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -19,24 +19,22 @@
 #include <linux/scatterlist.h>
 #include <linux/err.h>
 #include <linux/slab.h>
+#include <crypto/hash.h>
 #include "ima.h"
 
-static int init_desc(struct hash_desc *desc)
+static struct crypto_shash *ima_shash_tfm;
+
+int ima_init_crypto(void)
 {
-	int rc;
+	long rc;
 
-	desc->tfm = crypto_alloc_hash(ima_hash, 0, CRYPTO_ALG_ASYNC);
-	if (IS_ERR(desc->tfm)) {
-		pr_info("IMA: failed to load %s transform: %ld\n",
-			ima_hash, PTR_ERR(desc->tfm));
-		rc = PTR_ERR(desc->tfm);
+	ima_shash_tfm = crypto_alloc_shash(ima_hash, 0, 0);
+	if (IS_ERR(ima_shash_tfm)) {
+		rc = PTR_ERR(ima_shash_tfm);
+		pr_err("Can not allocate %s (reason: %ld)\n", ima_hash, rc);
 		return rc;
 	}
-	desc->flags = 0;
-	rc = crypto_hash_init(desc);
-	if (rc)
-		crypto_free_hash(desc->tfm);
-	return rc;
+	return 0;
 }
 
 /*
@@ -44,13 +42,18 @@ static int init_desc(struct hash_desc *desc)
  */
 int ima_calc_hash(struct file *file, char *digest)
 {
-	struct hash_desc desc;
-	struct scatterlist sg[1];
 	loff_t i_size, offset = 0;
 	char *rbuf;
 	int rc, read = 0;
+	struct {
+		struct shash_desc shash;
+		char ctx[crypto_shash_descsize(ima_shash_tfm)];
+	} desc;
 
-	rc = init_desc(&desc);
+	desc.shash.tfm = ima_shash_tfm;
+	desc.shash.flags = 0;
+
+	rc = crypto_shash_init(&desc.shash);
 	if (rc != 0)
 		return rc;
 
@@ -75,19 +78,17 @@ int ima_calc_hash(struct file *file, char *digest)
 		if (rbuf_len == 0)
 			break;
 		offset += rbuf_len;
-		sg_init_one(sg, rbuf, rbuf_len);
 
-		rc = crypto_hash_update(&desc, sg, rbuf_len);
+		rc = crypto_shash_update(&desc.shash, rbuf, rbuf_len);
 		if (rc)
 			break;
 	}
 	kfree(rbuf);
 	if (!rc)
-		rc = crypto_hash_final(&desc, digest);
+		rc = crypto_shash_final(&desc.shash, digest);
 	if (read)
 		file->f_mode &= ~FMODE_READ;
 out:
-	crypto_free_hash(desc.tfm);
 	return rc;
 }
 
@@ -96,20 +97,15 @@ int ima_calc_hash(struct file *file, char *digest)
  */
 int ima_calc_template_hash(int template_len, void *template, char *digest)
 {
-	struct hash_desc desc;
-	struct scatterlist sg[1];
-	int rc;
+	struct {
+		struct shash_desc shash;
+		char ctx[crypto_shash_descsize(ima_shash_tfm)];
+	} desc;
 
-	rc = init_desc(&desc);
-	if (rc != 0)
-		return rc;
+	desc.shash.tfm = ima_shash_tfm;
+	desc.shash.flags = 0;
 
-	sg_init_one(sg, template, template_len);
-	rc = crypto_hash_update(&desc, sg, template_len);
-	if (!rc)
-		rc = crypto_hash_final(&desc, digest);
-	crypto_free_hash(desc.tfm);
-	return rc;
+	return crypto_shash_digest(&desc.shash, template, template_len, digest);
 }
 
 static void __init ima_pcrread(int idx, u8 *pcr)
@@ -126,12 +122,17 @@ static void __init ima_pcrread(int idx, u8 *pcr)
  */
 int __init ima_calc_boot_aggregate(char *digest)
 {
-	struct hash_desc desc;
-	struct scatterlist sg;
 	u8 pcr_i[IMA_DIGEST_SIZE];
 	int rc, i;
+	struct {
+		struct shash_desc shash;
+		char ctx[crypto_shash_descsize(ima_shash_tfm)];
+	} desc;
+
+	desc.shash.tfm = ima_shash_tfm;
+	desc.shash.flags = 0;
 
-	rc = init_desc(&desc);
+	rc = crypto_shash_init(&desc.shash);
 	if (rc != 0)
 		return rc;
 
@@ -139,11 +140,9 @@ int __init ima_calc_boot_aggregate(char *digest)
 	for (i = TPM_PCR0; i < TPM_PCR8; i++) {
 		ima_pcrread(i, pcr_i);
 		/* now accumulate with current aggregate */
-		sg_init_one(&sg, pcr_i, IMA_DIGEST_SIZE);
-		rc = crypto_hash_update(&desc, &sg, IMA_DIGEST_SIZE);
+		rc = crypto_shash_update(&desc.shash, pcr_i, IMA_DIGEST_SIZE);
 	}
 	if (!rc)
-		crypto_hash_final(&desc, digest);
-	crypto_free_hash(desc.tfm);
+		crypto_shash_final(&desc.shash, digest);
 	return rc;
 }

commit 2fe5d6def1672ae6635dd71867bf36dcfaa7434b
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Mon Feb 13 10:15:05 2012 -0500

    ima: integrity appraisal extension
    
    IMA currently maintains an integrity measurement list used to assert the
    integrity of the running system to a third party.  The IMA-appraisal
    extension adds local integrity validation and enforcement of the
    measurement against a "good" value stored as an extended attribute
    'security.ima'.  The initial methods for validating 'security.ima' are
    hashed based, which provides file data integrity, and digital signature
    based, which in addition to providing file data integrity, provides
    authenticity.
    
    This patch creates and maintains the 'security.ima' xattr, containing
    the file data hash measurement.  Protection of the xattr is provided by
    EVM, if enabled and configured.
    
    Based on policy, IMA calls evm_verifyxattr() to verify a file's metadata
    integrity and, assuming success, compares the file's current hash value
    with the one stored as an extended attribute in 'security.ima'.
    
    Changelov v4:
    - changed iint cache flags to hex values
    
    Changelog v3:
    - change appraisal default for filesystems without xattr support to fail
    
    Changelog v2:
    - fix audit msg 'res' value
    - removed unused 'ima_appraise=' values
    
    Changelog v1:
    - removed unused iint mutex (Dmitry Kasatkin)
    - setattr hook must not reset appraised (Dmitry Kasatkin)
    - evm_verifyxattr() now differentiates between no 'security.evm' xattr
      (INTEGRITY_NOLABEL) and no EVM 'protected' xattrs included in the
      'security.evm' (INTEGRITY_NOXATTRS).
    - replace hash_status with ima_status (Dmitry Kasatkin)
    - re-initialize slab element ima_status on free (Dmitry Kasatkin)
    - include 'security.ima' in EVM if CONFIG_IMA_APPRAISE, not CONFIG_IMA
    - merged half "ima: ima_must_appraise_or_measure API change" (Dmitry Kasatkin)
    - removed unnecessary error variable in process_measurement() (Dmitry Kasatkin)
    - use ima_inode_post_setattr() stub function, if IMA_APPRAISE not configured
      (moved ima_inode_post_setattr() to ima_appraise.c)
    - make sure ima_collect_measurement() can read file
    
    Changelog:
    - add 'iint' to evm_verifyxattr() call (Dimitry Kasatkin)
    - fix the race condition between chmod, which takes the i_mutex and then
      iint->mutex, and ima_file_free() and process_measurement(), which take
      the locks in the reverse order, by eliminating iint->mutex. (Dmitry Kasatkin)
    - cleanup of ima_appraise_measurement() (Dmitry Kasatkin)
    - changes as a result of the iint not allocated for all regular files, but
      only for those measured/appraised.
    - don't try to appraise new/empty files
    - expanded ima_appraisal description in ima/Kconfig
    - IMA appraise definitions required even if IMA_APPRAISE not enabled
    - add return value to ima_must_appraise() stub
    - unconditionally set status = INTEGRITY_PASS *after* testing status,
      not before.  (Found by Joe Perches)
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: Dmitry Kasatkin <dmitry.kasatkin@intel.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 9b3ade7468b2..b21ee5b5495a 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -48,7 +48,7 @@ int ima_calc_hash(struct file *file, char *digest)
 	struct scatterlist sg[1];
 	loff_t i_size, offset = 0;
 	char *rbuf;
-	int rc;
+	int rc, read = 0;
 
 	rc = init_desc(&desc);
 	if (rc != 0)
@@ -59,6 +59,10 @@ int ima_calc_hash(struct file *file, char *digest)
 		rc = -ENOMEM;
 		goto out;
 	}
+	if (!(file->f_mode & FMODE_READ)) {
+		file->f_mode |= FMODE_READ;
+		read = 1;
+	}
 	i_size = i_size_read(file->f_dentry->d_inode);
 	while (offset < i_size) {
 		int rbuf_len;
@@ -80,6 +84,8 @@ int ima_calc_hash(struct file *file, char *digest)
 	kfree(rbuf);
 	if (!rc)
 		rc = crypto_hash_final(&desc, digest);
+	if (read)
+		file->f_mode &= ~FMODE_READ;
 out:
 	crypto_free_hash(desc.tfm);
 	return rc;

commit 0ffbe2699cda6afbe08501098dff8a8c2fe6ae09
Merge: 4e5d6f7ec383 7ebd467551ed
Author: James Morris <jmorris@namei.org>
Date:   Thu May 6 10:56:07 2010 +1000

    Merge branch 'master' into next

commit eb8dae9607901fd3fc181325ff3f30dce8f574c5
Author: Eric Paris <eparis@redhat.com>
Date:   Thu Apr 22 10:49:36 2010 -0400

    IMA: include the word IMA in printk messages
    
    As an example IMA emits a warning when it can't find a TPM chip:
    
    "No TPM chip found, activating TPM-bypass!"
    
    This patch prefaces that message with IMA so we know what subsystem is
    bypassing the TPM.  Do this for all pr_info and pr_err messages.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Acked-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 46642a19bc78..acd4226f73ef 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -26,7 +26,7 @@ static int init_desc(struct hash_desc *desc)
 
 	desc->tfm = crypto_alloc_hash(ima_hash, 0, CRYPTO_ALG_ASYNC);
 	if (IS_ERR(desc->tfm)) {
-		pr_info("failed to load %s transform: %ld\n",
+		pr_info("IMA: failed to load %s transform: %ld\n",
 			ima_hash, PTR_ERR(desc->tfm));
 		rc = PTR_ERR(desc->tfm);
 		return rc;
@@ -111,7 +111,7 @@ static void __init ima_pcrread(int idx, u8 *pcr)
 		return;
 
 	if (tpm_pcr_read(TPM_ANY_NUM, idx, pcr) != 0)
-		pr_err("Error Communicating to TPM chip\n");
+		pr_err("IMA: Error Communicating to TPM chip\n");
 }
 
 /*

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 46642a19bc78..952e51373f58 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -18,6 +18,7 @@
 #include <linux/crypto.h>
 #include <linux/scatterlist.h>
 #include <linux/err.h>
+#include <linux/slab.h>
 #include "ima.h"
 
 static int init_desc(struct hash_desc *desc)

commit 16bfa38b1936212428cb38fbfbbb8f6c62b8d81f
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Fri Aug 21 14:32:49 2009 -0400

    ima: hashing large files bug fix
    
    Hashing files larger than INT_MAX causes process to loop.
    Dependent on redefining kernel_read() offset type to loff_t.
    
    (http://bugzilla.kernel.org/show_bug.cgi?id=13909)
    
    Cc: stable@kernel.org
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 63003a63aaee..46642a19bc78 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -45,9 +45,9 @@ int ima_calc_hash(struct file *file, char *digest)
 {
 	struct hash_desc desc;
 	struct scatterlist sg[1];
-	loff_t i_size;
+	loff_t i_size, offset = 0;
 	char *rbuf;
-	int rc, offset = 0;
+	int rc;
 
 	rc = init_desc(&desc);
 	if (rc != 0)
@@ -67,6 +67,8 @@ int ima_calc_hash(struct file *file, char *digest)
 			rc = rbuf_len;
 			break;
 		}
+		if (rbuf_len == 0)
+			break;
 		offset += rbuf_len;
 		sg_init_one(sg, rbuf, rbuf_len);
 

commit 932995f0ce52525b32ff5127b522c2c164de3810
Author: Eric Paris <eparis@redhat.com>
Date:   Thu May 21 15:43:32 2009 -0400

    IMA: Add __init notation to ima functions
    
    A number of IMA functions only used during init are not marked with __init.
    Add those notations so they are freed automatically.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Acked-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index 50d572b74caf..63003a63aaee 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -103,7 +103,7 @@ int ima_calc_template_hash(int template_len, void *template, char *digest)
 	return rc;
 }
 
-static void ima_pcrread(int idx, u8 *pcr)
+static void __init ima_pcrread(int idx, u8 *pcr)
 {
 	if (!ima_used_chip)
 		return;
@@ -115,7 +115,7 @@ static void ima_pcrread(int idx, u8 *pcr)
 /*
  * Calculate the boot aggregate hash
  */
-int ima_calc_boot_aggregate(char *digest)
+int __init ima_calc_boot_aggregate(char *digest)
 {
 	struct hash_desc desc;
 	struct scatterlist sg;

commit 0da0a420bb542b13ebae142109a9d2045ade0cb1
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Thu Feb 19 21:23:50 2009 -0500

    integrity: ima scatterlist bug fix
    
    Based on Alexander Beregalov's post http://lkml.org/lkml/2009/2/19/198
    
    - replaced sg_set_buf() with sg_init_one()
    
     kernel BUG at include/linux/scatterlist.h:65!
     invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
     last sysfs file:
     CPU 2
     Modules linked in:
     Pid: 1, comm: swapper Not tainted 2.6.29-rc5-next-20090219 #5 PowerEdge 1950
     RIP: 0010:[<ffffffff8045ec70>]  [<ffffffff8045ec70>] ima_calc_hash+0xc0/0x160
     RSP: 0018:ffff88007f46bc40  EFLAGS: 00010286
     RAX: ffffe200032c45e8 RBX: 00000000fffffff4 RCX: 0000000087654321
     RDX: 0000000000000002 RSI: 0000000000000001 RDI: ffff88007cf71048
     RBP: ffff88007f46bcd0 R08: 0000000000000000 R09: 0000000000000163
     R10: ffff88007f4707a8 R11: 0000000000000000 R12: ffff88007cf71048
     R13: 0000000000001000 R14: 0000000000000000 R15: 0000000000009d98
     FS:  0000000000000000(0000) GS:ffff8800051ac000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0018 ES: 0018 CR0: 000000008005003b
     CR2: 0000000000000000 CR3: 0000000000201000 CR4: 00000000000006e0
     DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Tested-by: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
index c2a46e40999d..50d572b74caf 100644
--- a/security/integrity/ima/ima_crypto.c
+++ b/security/integrity/ima/ima_crypto.c
@@ -68,7 +68,7 @@ int ima_calc_hash(struct file *file, char *digest)
 			break;
 		}
 		offset += rbuf_len;
-		sg_set_buf(sg, rbuf, rbuf_len);
+		sg_init_one(sg, rbuf, rbuf_len);
 
 		rc = crypto_hash_update(&desc, sg, rbuf_len);
 		if (rc)
@@ -95,7 +95,7 @@ int ima_calc_template_hash(int template_len, void *template, char *digest)
 	if (rc != 0)
 		return rc;
 
-	sg_set_buf(sg, template, template_len);
+	sg_init_one(sg, template, template_len);
 	rc = crypto_hash_update(&desc, sg, template_len);
 	if (!rc)
 		rc = crypto_hash_final(&desc, digest);

commit 3323eec921efd815178a23107ab63588c605c0b2
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Wed Feb 4 09:06:58 2009 -0500

    integrity: IMA as an integrity service provider
    
    IMA provides hardware (TPM) based measurement and attestation for
    file measurements. As the Trusted Computing (TPM) model requires,
    IMA measures all files before they are accessed in any way (on the
    integrity_bprm_check, integrity_path_check and integrity_file_mmap
    hooks), and commits the measurements to the TPM. Once added to the
    TPM, measurements can not be removed.
    
    In addition, IMA maintains a list of these file measurements, which
    can be used to validate the aggregate value stored in the TPM.  The
    TPM can sign these measurements, and thus the system can prove, to
    itself and to a third party, the system's integrity in a way that
    cannot be circumvented by malicious or compromised software.
    
    - alloc ima_template_entry before calling ima_store_template()
    - log ima_add_boot_aggregate() failure
    - removed unused IMA_TEMPLATE_NAME_LEN
    - replaced hard coded string length with #define name
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/security/integrity/ima/ima_crypto.c b/security/integrity/ima/ima_crypto.c
new file mode 100644
index 000000000000..c2a46e40999d
--- /dev/null
+++ b/security/integrity/ima/ima_crypto.c
@@ -0,0 +1,140 @@
+/*
+ * Copyright (C) 2005,2006,2007,2008 IBM Corporation
+ *
+ * Authors:
+ * Mimi Zohar <zohar@us.ibm.com>
+ * Kylene Hall <kjhall@us.ibm.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, version 2 of the License.
+ *
+ * File: ima_crypto.c
+ * 	Calculates md5/sha1 file hash, template hash, boot-aggreate hash
+ */
+
+#include <linux/kernel.h>
+#include <linux/file.h>
+#include <linux/crypto.h>
+#include <linux/scatterlist.h>
+#include <linux/err.h>
+#include "ima.h"
+
+static int init_desc(struct hash_desc *desc)
+{
+	int rc;
+
+	desc->tfm = crypto_alloc_hash(ima_hash, 0, CRYPTO_ALG_ASYNC);
+	if (IS_ERR(desc->tfm)) {
+		pr_info("failed to load %s transform: %ld\n",
+			ima_hash, PTR_ERR(desc->tfm));
+		rc = PTR_ERR(desc->tfm);
+		return rc;
+	}
+	desc->flags = 0;
+	rc = crypto_hash_init(desc);
+	if (rc)
+		crypto_free_hash(desc->tfm);
+	return rc;
+}
+
+/*
+ * Calculate the MD5/SHA1 file digest
+ */
+int ima_calc_hash(struct file *file, char *digest)
+{
+	struct hash_desc desc;
+	struct scatterlist sg[1];
+	loff_t i_size;
+	char *rbuf;
+	int rc, offset = 0;
+
+	rc = init_desc(&desc);
+	if (rc != 0)
+		return rc;
+
+	rbuf = kzalloc(PAGE_SIZE, GFP_KERNEL);
+	if (!rbuf) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	i_size = i_size_read(file->f_dentry->d_inode);
+	while (offset < i_size) {
+		int rbuf_len;
+
+		rbuf_len = kernel_read(file, offset, rbuf, PAGE_SIZE);
+		if (rbuf_len < 0) {
+			rc = rbuf_len;
+			break;
+		}
+		offset += rbuf_len;
+		sg_set_buf(sg, rbuf, rbuf_len);
+
+		rc = crypto_hash_update(&desc, sg, rbuf_len);
+		if (rc)
+			break;
+	}
+	kfree(rbuf);
+	if (!rc)
+		rc = crypto_hash_final(&desc, digest);
+out:
+	crypto_free_hash(desc.tfm);
+	return rc;
+}
+
+/*
+ * Calculate the hash of a given template
+ */
+int ima_calc_template_hash(int template_len, void *template, char *digest)
+{
+	struct hash_desc desc;
+	struct scatterlist sg[1];
+	int rc;
+
+	rc = init_desc(&desc);
+	if (rc != 0)
+		return rc;
+
+	sg_set_buf(sg, template, template_len);
+	rc = crypto_hash_update(&desc, sg, template_len);
+	if (!rc)
+		rc = crypto_hash_final(&desc, digest);
+	crypto_free_hash(desc.tfm);
+	return rc;
+}
+
+static void ima_pcrread(int idx, u8 *pcr)
+{
+	if (!ima_used_chip)
+		return;
+
+	if (tpm_pcr_read(TPM_ANY_NUM, idx, pcr) != 0)
+		pr_err("Error Communicating to TPM chip\n");
+}
+
+/*
+ * Calculate the boot aggregate hash
+ */
+int ima_calc_boot_aggregate(char *digest)
+{
+	struct hash_desc desc;
+	struct scatterlist sg;
+	u8 pcr_i[IMA_DIGEST_SIZE];
+	int rc, i;
+
+	rc = init_desc(&desc);
+	if (rc != 0)
+		return rc;
+
+	/* cumulative sha1 over tpm registers 0-7 */
+	for (i = TPM_PCR0; i < TPM_PCR8; i++) {
+		ima_pcrread(i, pcr_i);
+		/* now accumulate with current aggregate */
+		sg_init_one(&sg, pcr_i, IMA_DIGEST_SIZE);
+		rc = crypto_hash_update(&desc, &sg, IMA_DIGEST_SIZE);
+	}
+	if (!rc)
+		crypto_hash_final(&desc, digest);
+	crypto_free_hash(desc.tfm);
+	return rc;
+}
