commit 1ccea77e2a2687cae171b7987eb44730ec8c6d5f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 15:51:43 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 13
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details you
      should have received a copy of the gnu general public license along
      with this program if not see http www gnu org licenses
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details [based]
      [from] [clk] [highbank] [c] you should have received a copy of the
      gnu general public license along with this program if not see http
      www gnu org licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 355 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Jilayne Lovejoy <opensource@jilayne.com>
    Reviewed-by: Steve Winslow <swinslow@gmail.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190519154041.837383322@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
index 01c9cf003ca2..cd76d7ebe598 100644
--- a/samples/livepatch/livepatch-sample.c
+++ b/samples/livepatch/livepatch-sample.c
@@ -1,20 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * livepatch-sample.c - Kernel Live Patching Sample Module
  *
  * Copyright (C) 2014 Seth Jennings <sjenning@redhat.com>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2
- * of the License, or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt

commit 958ef1e39d24d6cb8bf2a7406130a98c9564230f
Author: Petr Mladek <pmladek@suse.com>
Date:   Wed Jan 9 13:43:23 2019 +0100

    livepatch: Simplify API by removing registration step
    
    The possibility to re-enable a registered patch was useful for immediate
    patches where the livepatch module had to stay until the system reboot.
    The improved consistency model allows to achieve the same result by
    unloading and loading the livepatch module again.
    
    Also we are going to add a feature called atomic replace. It will allow
    to create a patch that would replace all already registered patches.
    The aim is to handle dependent patches more securely. It will obsolete
    the stack of patches that helped to handle the dependencies so far.
    Then it might be unclear when a cumulative patch re-enabling is safe.
    
    It would be complicated to support the many modes. Instead we could
    actually make the API and code easier to understand.
    
    Therefore, remove the two step public API. All the checks and init calls
    are moved from klp_register_patch() to klp_enabled_patch(). Also the patch
    is automatically freed, including the sysfs interface when the transition
    to the disabled state is completed.
    
    As a result, there is never a disabled patch on the top of the stack.
    Therefore we do not need to check the stack in __klp_enable_patch().
    And we could simplify the check in __klp_disable_patch().
    
    Also the API and logic is much easier. It is enough to call
    klp_enable_patch() in module_init() call. The patch can be disabled
    by writing '0' into /sys/kernel/livepatch/<patch>/enabled. Then the module
    can be removed once the transition finishes and sysfs interface is freed.
    
    The only problem is how to free the structures and kobjects safely.
    The operation is triggered from the sysfs interface. We could not put
    the related kobject from there because it would cause lock inversion
    between klp_mutex and kernfs locks, see kn->count lockdep map.
    
    Therefore, offload the free task to a workqueue. It is perfectly fine:
    
      + The patch can no longer be used in the livepatch operations.
    
      + The module could not be removed until the free operation finishes
        and module_put() is called.
    
      + The operation is asynchronous already when the first
        klp_try_complete_transition() fails and another call
        is queued with a delay.
    
    Suggested-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
index 2d554dd930e2..01c9cf003ca2 100644
--- a/samples/livepatch/livepatch-sample.c
+++ b/samples/livepatch/livepatch-sample.c
@@ -69,22 +69,11 @@ static struct klp_patch patch = {
 
 static int livepatch_init(void)
 {
-	int ret;
-
-	ret = klp_register_patch(&patch);
-	if (ret)
-		return ret;
-	ret = klp_enable_patch(&patch);
-	if (ret) {
-		WARN_ON(klp_unregister_patch(&patch));
-		return ret;
-	}
-	return 0;
+	return klp_enable_patch(&patch);
 }
 
 static void livepatch_exit(void)
 {
-	WARN_ON(klp_unregister_patch(&patch));
 }
 
 module_init(livepatch_init);

commit d0807da78e11d46f18399cbf8c4028c731346766
Author: Miroslav Benes <mbenes@suse.cz>
Date:   Wed Jan 10 11:01:28 2018 +0100

    livepatch: Remove immediate feature
    
    Immediate flag has been used to disable per-task consistency and patch
    all tasks immediately. It could be useful if the patch doesn't change any
    function or data semantics.
    
    However, it causes problems on its own. The consistency problem is
    currently broken with respect to immediate patches.
    
    func            a
    patches         1i
                    2i
                    3
    
    When the patch 3 is applied, only 2i function is checked (by stack
    checking facility). There might be a task sleeping in 1i though. Such
    task is migrated to 3, because we do not check 1i in
    klp_check_stack_func() at all.
    
    Coming atomic replace feature would be easier to implement and more
    reliable without immediate.
    
    Thus, remove immediate feature completely and save us from the problems.
    
    Note that force feature has the similar problem. However it is
    considered as a last resort. If used, administrator should not apply any
    new live patches and should plan for reboot into an updated kernel.
    
    The architectures would now need to provide HAVE_RELIABLE_STACKTRACE to
    fully support livepatch.
    
    Signed-off-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
index 84795223f15f..2d554dd930e2 100644
--- a/samples/livepatch/livepatch-sample.c
+++ b/samples/livepatch/livepatch-sample.c
@@ -71,21 +71,6 @@ static int livepatch_init(void)
 {
 	int ret;
 
-	if (!klp_have_reliable_stack() && !patch.immediate) {
-		/*
-		 * WARNING: Be very careful when using 'patch.immediate' in
-		 * your patches.  It's ok to use it for simple patches like
-		 * this, but for more complex patches which change function
-		 * semantics, locking semantics, or data structures, it may not
-		 * be safe.  Use of this option will also prevent removal of
-		 * the patch.
-		 *
-		 * See Documentation/livepatch/livepatch.txt for more details.
-		 */
-		patch.immediate = true;
-		pr_notice("The consistency model isn't supported for your architecture.  Bypassing safety mechanisms and applying the patch immediately.\n");
-	}
-
 	ret = klp_register_patch(&patch);
 	if (ret)
 		return ret;

commit 3ec24776bfd09668079df7dca0c0136d80820ab4
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Mon Mar 6 11:20:29 2017 -0600

    livepatch: allow removal of a disabled patch
    
    Currently we do not allow patch module to unload since there is no
    method to determine if a task is still running in the patched code.
    
    The consistency model gives us the way because when the unpatching
    finishes we know that all tasks were marked as safe to call an original
    function. Thus every new call to the function calls the original code
    and at the same time no task can be somewhere in the patched code,
    because it had to leave that code to be marked as safe.
    
    We can safely let the patch module go after that.
    
    Completion is used for synchronization between module removal and sysfs
    infrastructure in a similar way to commit 942e443127e9 ("module: Fix
    mod->mkobj.kobj potentially freed too early").
    
    Note that we still do not allow the removal for immediate model, that is
    no consistency model. The module refcount may increase in this case if
    somebody disables and enables the patch several times. This should not
    cause any harm.
    
    With this change a call to try_module_get() is moved to
    __klp_enable_patch from klp_register_patch to make module reference
    counting symmetric (module_put() is in a patch disable path) and to
    allow to take a new reference to a disabled module when being enabled.
    
    Finally, we need to be very careful about possible races between
    klp_unregister_patch(), kobject_put() functions and operations
    on the related sysfs files.
    
    kobject_put(&patch->kobj) must be called without klp_mutex. Otherwise,
    it might be blocked by enabled_store() that needs the mutex as well.
    In addition, enabled_store() must check if the patch was not
    unregisted in the meantime.
    
    There is no need to do the same for other kobject_put() callsites
    at the moment. Their sysfs operations neither take the lock nor
    they access any data that might be freed in the meantime.
    
    There was an attempt to use kobjects the right way and prevent these
    races by design. But it made the patch definition more complicated
    and opened another can of worms. See
    https://lkml.kernel.org/r/1464018848-4303-1-git-send-email-pmladek@suse.com
    
    [Thanks to Petr Mladek for improving the commit message.]
    
    Signed-off-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
index 629e0dca0887..84795223f15f 100644
--- a/samples/livepatch/livepatch-sample.c
+++ b/samples/livepatch/livepatch-sample.c
@@ -99,7 +99,6 @@ static int livepatch_init(void)
 
 static void livepatch_exit(void)
 {
-	WARN_ON(klp_disable_patch(&patch));
 	WARN_ON(klp_unregister_patch(&patch));
 }
 

commit d83a7cb375eec21f04c83542395d08b2f6641da2
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Mon Feb 13 19:42:40 2017 -0600

    livepatch: change to a per-task consistency model
    
    Change livepatch to use a basic per-task consistency model.  This is the
    foundation which will eventually enable us to patch those ~10% of
    security patches which change function or data semantics.  This is the
    biggest remaining piece needed to make livepatch more generally useful.
    
    This code stems from the design proposal made by Vojtech [1] in November
    2014.  It's a hybrid of kGraft and kpatch: it uses kGraft's per-task
    consistency and syscall barrier switching combined with kpatch's stack
    trace switching.  There are also a number of fallback options which make
    it quite flexible.
    
    Patches are applied on a per-task basis, when the task is deemed safe to
    switch over.  When a patch is enabled, livepatch enters into a
    transition state where tasks are converging to the patched state.
    Usually this transition state can complete in a few seconds.  The same
    sequence occurs when a patch is disabled, except the tasks converge from
    the patched state to the unpatched state.
    
    An interrupt handler inherits the patched state of the task it
    interrupts.  The same is true for forked tasks: the child inherits the
    patched state of the parent.
    
    Livepatch uses several complementary approaches to determine when it's
    safe to patch tasks:
    
    1. The first and most effective approach is stack checking of sleeping
       tasks.  If no affected functions are on the stack of a given task,
       the task is patched.  In most cases this will patch most or all of
       the tasks on the first try.  Otherwise it'll keep trying
       periodically.  This option is only available if the architecture has
       reliable stacks (HAVE_RELIABLE_STACKTRACE).
    
    2. The second approach, if needed, is kernel exit switching.  A
       task is switched when it returns to user space from a system call, a
       user space IRQ, or a signal.  It's useful in the following cases:
    
       a) Patching I/O-bound user tasks which are sleeping on an affected
          function.  In this case you have to send SIGSTOP and SIGCONT to
          force it to exit the kernel and be patched.
       b) Patching CPU-bound user tasks.  If the task is highly CPU-bound
          then it will get patched the next time it gets interrupted by an
          IRQ.
       c) In the future it could be useful for applying patches for
          architectures which don't yet have HAVE_RELIABLE_STACKTRACE.  In
          this case you would have to signal most of the tasks on the
          system.  However this isn't supported yet because there's
          currently no way to patch kthreads without
          HAVE_RELIABLE_STACKTRACE.
    
    3. For idle "swapper" tasks, since they don't ever exit the kernel, they
       instead have a klp_update_patch_state() call in the idle loop which
       allows them to be patched before the CPU enters the idle state.
    
       (Note there's not yet such an approach for kthreads.)
    
    All the above approaches may be skipped by setting the 'immediate' flag
    in the 'klp_patch' struct, which will disable per-task consistency and
    patch all tasks immediately.  This can be useful if the patch doesn't
    change any function or data semantics.  Note that, even with this flag
    set, it's possible that some tasks may still be running with an old
    version of the function, until that function returns.
    
    There's also an 'immediate' flag in the 'klp_func' struct which allows
    you to specify that certain functions in the patch can be applied
    without per-task consistency.  This might be useful if you want to patch
    a common function like schedule(), and the function change doesn't need
    consistency but the rest of the patch does.
    
    For architectures which don't have HAVE_RELIABLE_STACKTRACE, the user
    must set patch->immediate which causes all tasks to be patched
    immediately.  This option should be used with care, only when the patch
    doesn't change any function or data semantics.
    
    In the future, architectures which don't have HAVE_RELIABLE_STACKTRACE
    may be allowed to use per-task consistency if we can come up with
    another way to patch kthreads.
    
    The /sys/kernel/livepatch/<patch>/transition file shows whether a patch
    is in transition.  Only a single patch (the topmost patch on the stack)
    can be in transition at a given time.  A patch can remain in transition
    indefinitely, if any of the tasks are stuck in the initial patch state.
    
    A transition can be reversed and effectively canceled by writing the
    opposite value to the /sys/kernel/livepatch/<patch>/enabled file while
    the transition is in progress.  Then all the tasks will attempt to
    converge back to the original patch state.
    
    [1] https://lkml.kernel.org/r/20141107140458.GA21774@suse.cz
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Ingo Molnar <mingo@kernel.org>        # for the scheduler changes
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
index e34f871e69b1..629e0dca0887 100644
--- a/samples/livepatch/livepatch-sample.c
+++ b/samples/livepatch/livepatch-sample.c
@@ -17,6 +17,8 @@
  * along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
 #include <linux/module.h>
 #include <linux/kernel.h>
 #include <linux/livepatch.h>
@@ -69,6 +71,21 @@ static int livepatch_init(void)
 {
 	int ret;
 
+	if (!klp_have_reliable_stack() && !patch.immediate) {
+		/*
+		 * WARNING: Be very careful when using 'patch.immediate' in
+		 * your patches.  It's ok to use it for simple patches like
+		 * this, but for more complex patches which change function
+		 * semantics, locking semantics, or data structures, it may not
+		 * be safe.  Use of this option will also prevent removal of
+		 * the patch.
+		 *
+		 * See Documentation/livepatch/livepatch.txt for more details.
+		 */
+		patch.immediate = true;
+		pr_notice("The consistency model isn't supported for your architecture.  Bypassing safety mechanisms and applying the patch immediately.\n");
+	}
+
 	ret = klp_register_patch(&patch);
 	if (ret)
 		return ret;

commit 425595a7fc2096ab46c741b5ed5372c5ab5bbeac
Author: Jessica Yu <jeyu@redhat.com>
Date:   Tue Mar 22 20:03:18 2016 -0400

    livepatch: reuse module loader code to write relocations
    
    Reuse module loader code to write relocations, thereby eliminating the need
    for architecture specific relocation code in livepatch. Specifically, reuse
    the apply_relocate_add() function in the module loader to write relocations
    instead of duplicating functionality in livepatch's arch-dependent
    klp_write_module_reloc() function.
    
    In order to accomplish this, livepatch modules manage their own relocation
    sections (marked with the SHF_RELA_LIVEPATCH section flag) and
    livepatch-specific symbols (marked with SHN_LIVEPATCH symbol section
    index). To apply livepatch relocation sections, livepatch symbols
    referenced by relocs are resolved and then apply_relocate_add() is called
    to apply those relocations.
    
    In addition, remove x86 livepatch relocation code and the s390
    klp_write_module_reloc() function stub. They are no longer needed since
    relocation work has been offloaded to module loader.
    
    Lastly, mark the module as a livepatch module so that the module loader
    canappropriately identify and initialize it.
    
    Signed-off-by: Jessica Yu <jeyu@redhat.com>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>   # for s390 changes
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
index fb8c8614e728..e34f871e69b1 100644
--- a/samples/livepatch/livepatch-sample.c
+++ b/samples/livepatch/livepatch-sample.c
@@ -89,3 +89,4 @@ static void livepatch_exit(void)
 module_init(livepatch_init);
 module_exit(livepatch_exit);
 MODULE_LICENSE("GPL");
+MODULE_INFO(livepatch, "Y");

commit 700a3048aaa394b2a6d1468430f892151ce04a01
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Tue Dec 23 17:06:43 2014 -0600

    livepatch: samples: fix usage example comments
    
    Fix a few typos in the livepatch-sample.c usage example comments and add
    some whitespace to make the comments a little more legible.
    
    Reported-by: Udo Seidel <udoseidel@gmx.de>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
index 21f159d51074..fb8c8614e728 100644
--- a/samples/livepatch/livepatch-sample.c
+++ b/samples/livepatch/livepatch-sample.c
@@ -26,12 +26,16 @@
  * kernel boot cmdline when /proc/cmdline is read.
  *
  * Example:
+ *
  * $ cat /proc/cmdline
  * <your cmdline>
+ *
  * $ insmod livepatch-sample.ko
  * $ cat /proc/cmdline
  * this has been live patched
- * $ echo 0 > /sys/kernel/livepatch/klp_sample/enabled
+ *
+ * $ echo 0 > /sys/kernel/livepatch/livepatch_sample/enabled
+ * $ cat /proc/cmdline
  * <your cmdline>
  */
 

commit 13d1cf7e702596e0cd8ec62afa6bd49c431f2d0c
Author: Seth Jennings <sjenning@redhat.com>
Date:   Tue Dec 16 11:58:20 2014 -0600

    livepatch: samples: add sample live patching module
    
    Add a sample live patching module.
    
    Signed-off-by: Seth Jennings <sjenning@redhat.com>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Reviewed-by: Petr Mladek <pmladek@suse.cz>
    Reviewed-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/samples/livepatch/livepatch-sample.c b/samples/livepatch/livepatch-sample.c
new file mode 100644
index 000000000000..21f159d51074
--- /dev/null
+++ b/samples/livepatch/livepatch-sample.c
@@ -0,0 +1,87 @@
+/*
+ * livepatch-sample.c - Kernel Live Patching Sample Module
+ *
+ * Copyright (C) 2014 Seth Jennings <sjenning@redhat.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/livepatch.h>
+
+/*
+ * This (dumb) live patch overrides the function that prints the
+ * kernel boot cmdline when /proc/cmdline is read.
+ *
+ * Example:
+ * $ cat /proc/cmdline
+ * <your cmdline>
+ * $ insmod livepatch-sample.ko
+ * $ cat /proc/cmdline
+ * this has been live patched
+ * $ echo 0 > /sys/kernel/livepatch/klp_sample/enabled
+ * <your cmdline>
+ */
+
+#include <linux/seq_file.h>
+static int livepatch_cmdline_proc_show(struct seq_file *m, void *v)
+{
+	seq_printf(m, "%s\n", "this has been live patched");
+	return 0;
+}
+
+static struct klp_func funcs[] = {
+	{
+		.old_name = "cmdline_proc_show",
+		.new_func = livepatch_cmdline_proc_show,
+	}, { }
+};
+
+static struct klp_object objs[] = {
+	{
+		/* name being NULL means vmlinux */
+		.funcs = funcs,
+	}, { }
+};
+
+static struct klp_patch patch = {
+	.mod = THIS_MODULE,
+	.objs = objs,
+};
+
+static int livepatch_init(void)
+{
+	int ret;
+
+	ret = klp_register_patch(&patch);
+	if (ret)
+		return ret;
+	ret = klp_enable_patch(&patch);
+	if (ret) {
+		WARN_ON(klp_unregister_patch(&patch));
+		return ret;
+	}
+	return 0;
+}
+
+static void livepatch_exit(void)
+{
+	WARN_ON(klp_disable_patch(&patch));
+	WARN_ON(klp_unregister_patch(&patch));
+}
+
+module_init(livepatch_init);
+module_exit(livepatch_exit);
+MODULE_LICENSE("GPL");
