commit 7cf245a37ef013b2c1c5ca7ae25061de2ba7ad01
Author: Toke Høiland-Jørgensen <toke@redhat.com>
Date:   Mon Jan 20 14:06:49 2020 +0100

    samples/bpf: Use consistent include paths for libbpf
    
    Fix all files in samples/bpf to include libbpf header files with the bpf/
    prefix, to be consistent with external users of the library. Also ensure
    that all includes of exported libbpf header files (those that are exported
    on 'make install' of the library) use bracketed includes instead of quoted.
    
    To make sure no new files are introduced that doesn't include the bpf/
    prefix in its include, remove tools/lib/bpf from the include path entirely,
    and use tools/lib instead.
    
    Fixes: 6910d7d3867a ("selftests/bpf: Ensure bpf_helper_defs.h are taken from selftests dir")
    Signed-off-by: Toke Høiland-Jørgensen <toke@redhat.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Link: https://lore.kernel.org/bpf/157952560911.1683545.8795966751309534150.stgit@toke.dk

diff --git a/samples/bpf/xdp_rxq_info_kern.c b/samples/bpf/xdp_rxq_info_kern.c
index 272d0f82a6b5..5e7459f9bf3e 100644
--- a/samples/bpf/xdp_rxq_info_kern.c
+++ b/samples/bpf/xdp_rxq_info_kern.c
@@ -6,7 +6,7 @@
 #include <uapi/linux/bpf.h>
 #include <uapi/linux/if_ether.h>
 #include <uapi/linux/in.h>
-#include "bpf_helpers.h"
+#include <bpf/bpf_helpers.h>
 
 /* Config setup from with userspace
  *

commit 451d1dc886b548d6e18c933adca326c1307023c9
Author: Daniel T. Lee <danieltimlee@gmail.com>
Date:   Thu Nov 7 09:51:53 2019 +0900

    samples: bpf: update map definition to new syntax BTF-defined map
    
    Since, the new syntax of BTF-defined map has been introduced,
    the syntax for using maps under samples directory are mixed up.
    For example, some are already using the new syntax, and some are using
    existing syntax by calling them as 'legacy'.
    
    As stated at commit abd29c931459 ("libbpf: allow specifying map
    definitions using BTF"), the BTF-defined map has more compatablility
    with extending supported map definition features.
    
    The commit doesn't replace all of the map to new BTF-defined map,
    because some of the samples still use bpf_load instead of libbpf, which
    can't properly create BTF-defined map.
    
    This will only updates the samples which uses libbpf API for loading bpf
    program. (ex. bpf_prog_load_xattr)
    
    Signed-off-by: Daniel T. Lee <danieltimlee@gmail.com>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/samples/bpf/xdp_rxq_info_kern.c b/samples/bpf/xdp_rxq_info_kern.c
index 222a83eed1cb..272d0f82a6b5 100644
--- a/samples/bpf/xdp_rxq_info_kern.c
+++ b/samples/bpf/xdp_rxq_info_kern.c
@@ -23,12 +23,13 @@ enum cfg_options_flags {
 	READ_MEM = 0x1U,
 	SWAP_MAC = 0x2U,
 };
-struct bpf_map_def SEC("maps") config_map = {
-	.type		= BPF_MAP_TYPE_ARRAY,
-	.key_size	= sizeof(int),
-	.value_size	= sizeof(struct config),
-	.max_entries	= 1,
-};
+
+struct {
+	__uint(type, BPF_MAP_TYPE_ARRAY);
+	__type(key, int);
+	__type(value, struct config);
+	__uint(max_entries, 1);
+} config_map SEC(".maps");
 
 /* Common stats data record (shared with userspace) */
 struct datarec {
@@ -36,22 +37,22 @@ struct datarec {
 	__u64 issue;
 };
 
-struct bpf_map_def SEC("maps") stats_global_map = {
-	.type		= BPF_MAP_TYPE_PERCPU_ARRAY,
-	.key_size	= sizeof(u32),
-	.value_size	= sizeof(struct datarec),
-	.max_entries	= 1,
-};
+struct {
+	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+	__type(key, u32);
+	__type(value, struct datarec);
+	__uint(max_entries, 1);
+} stats_global_map SEC(".maps");
 
 #define MAX_RXQs 64
 
 /* Stats per rx_queue_index (per CPU) */
-struct bpf_map_def SEC("maps") rx_queue_index_map = {
-	.type		= BPF_MAP_TYPE_PERCPU_ARRAY,
-	.key_size	= sizeof(u32),
-	.value_size	= sizeof(struct datarec),
-	.max_entries	= MAX_RXQs + 1,
-};
+struct {
+	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+	__type(key, u32);
+	__type(value, struct datarec);
+	__uint(max_entries, MAX_RXQs + 1);
+} rx_queue_index_map SEC(".maps");
 
 static __always_inline
 void swap_src_dst_mac(void *data)

commit 509fda105ba8f9a1a5c6f8b79e4c7fc50b35c1e3
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jun 25 16:27:48 2018 +0200

    samples/bpf: xdp_rxq_info action XDP_TX must adjust MAC-addrs
    
    XDP_TX requires also changing the MAC-addrs, else some hardware
    may drop the TX packet before reaching the wire.  This was
    observed with driver mlx5.
    
    If xdp_rxq_info select --action XDP_TX the swapmac functionality
    is activated.  It is also possible to manually enable via cmdline
    option --swapmac.  This is practical if wanting to measure the
    overhead of writing/updating payload for other action types.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Toke Høiland-Jørgensen <toke@toke.dk>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/samples/bpf/xdp_rxq_info_kern.c b/samples/bpf/xdp_rxq_info_kern.c
index 61af6210df2f..222a83eed1cb 100644
--- a/samples/bpf/xdp_rxq_info_kern.c
+++ b/samples/bpf/xdp_rxq_info_kern.c
@@ -21,6 +21,7 @@ struct config {
 enum cfg_options_flags {
 	NO_TOUCH = 0x0U,
 	READ_MEM = 0x1U,
+	SWAP_MAC = 0x2U,
 };
 struct bpf_map_def SEC("maps") config_map = {
 	.type		= BPF_MAP_TYPE_ARRAY,
@@ -52,6 +53,23 @@ struct bpf_map_def SEC("maps") rx_queue_index_map = {
 	.max_entries	= MAX_RXQs + 1,
 };
 
+static __always_inline
+void swap_src_dst_mac(void *data)
+{
+	unsigned short *p = data;
+	unsigned short dst[3];
+
+	dst[0] = p[0];
+	dst[1] = p[1];
+	dst[2] = p[2];
+	p[0] = p[3];
+	p[1] = p[4];
+	p[2] = p[5];
+	p[3] = dst[0];
+	p[4] = dst[1];
+	p[5] = dst[2];
+}
+
 SEC("xdp_prog0")
 int  xdp_prognum0(struct xdp_md *ctx)
 {
@@ -98,7 +116,7 @@ int  xdp_prognum0(struct xdp_md *ctx)
 		rxq_rec->issue++;
 
 	/* Default: Don't touch packet data, only count packets */
-	if (unlikely(config->options & READ_MEM)) {
+	if (unlikely(config->options & (READ_MEM|SWAP_MAC))) {
 		struct ethhdr *eth = data;
 
 		if (eth + 1 > data_end)
@@ -107,6 +125,12 @@ int  xdp_prognum0(struct xdp_md *ctx)
 		/* Avoid compiler removing this: Drop non 802.3 Ethertypes */
 		if (ntohs(eth->h_proto) < ETH_P_802_3_MIN)
 			return XDP_ABORTED;
+
+		/* XDP_TX requires changing MAC-addrs, else HW may drop.
+		 * Can also be enabled with --swapmac (for test purposes)
+		 */
+		if (unlikely(config->options & SWAP_MAC))
+			swap_src_dst_mac(data);
 	}
 
 	return config->action;

commit 0d25c43ab988766ad52ff2930af3bf47d92c20ac
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Mon Jun 25 16:27:43 2018 +0200

    samples/bpf: extend xdp_rxq_info to read packet payload
    
    There is a cost associated with reading the packet data payload
    that this test ignored.  Add option --read to allow enabling
    reading part of the payload.
    
    This sample/tool helps us analyse an issue observed with a NIC
    mlx5 (ConnectX-5 Ex) and an Intel(R) Xeon(R) CPU E5-1650 v4.
    
    With no_touch of data:
    
    Running XDP on dev:mlx5p1 (ifindex:8) action:XDP_DROP options:no_touch
    XDP stats       CPU     pps         issue-pps
    XDP-RX CPU      0       14,465,157  0
    XDP-RX CPU      1       14,464,728  0
    XDP-RX CPU      2       14,465,283  0
    XDP-RX CPU      3       14,465,282  0
    XDP-RX CPU      4       14,464,159  0
    XDP-RX CPU      5       14,465,379  0
    XDP-RX CPU      total   86,789,992
    
    When not touching data, we observe that the CPUs have idle cycles.
    When reading data the CPUs are 100% busy in softirq.
    
    With reading data:
    
    Running XDP on dev:mlx5p1 (ifindex:8) action:XDP_DROP options:read
    XDP stats       CPU     pps         issue-pps
    XDP-RX CPU      0       9,620,639   0
    XDP-RX CPU      1       9,489,843   0
    XDP-RX CPU      2       9,407,854   0
    XDP-RX CPU      3       9,422,289   0
    XDP-RX CPU      4       9,321,959   0
    XDP-RX CPU      5       9,395,242   0
    XDP-RX CPU      total   56,657,828
    
    The effect seen above is a result of cache-misses occuring when
    more RXQs are being used.  Based on perf-event observations, our
    conclusion is that the CPUs DDIO (Direct Data I/O) choose to
    deliver packet into main memory, instead of L3-cache.  We also
    found, that this can be mitigated by either using less RXQs or by
    reducing NICs the RX-ring size.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Toke Høiland-Jørgensen <toke@toke.dk>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/samples/bpf/xdp_rxq_info_kern.c b/samples/bpf/xdp_rxq_info_kern.c
index 3fd209291653..61af6210df2f 100644
--- a/samples/bpf/xdp_rxq_info_kern.c
+++ b/samples/bpf/xdp_rxq_info_kern.c
@@ -4,6 +4,8 @@
  *  Example howto extract XDP RX-queue info
  */
 #include <uapi/linux/bpf.h>
+#include <uapi/linux/if_ether.h>
+#include <uapi/linux/in.h>
 #include "bpf_helpers.h"
 
 /* Config setup from with userspace
@@ -14,6 +16,11 @@
 struct config {
 	__u32 action;
 	int ifindex;
+	__u32 options;
+};
+enum cfg_options_flags {
+	NO_TOUCH = 0x0U,
+	READ_MEM = 0x1U,
 };
 struct bpf_map_def SEC("maps") config_map = {
 	.type		= BPF_MAP_TYPE_ARRAY,
@@ -90,6 +97,18 @@ int  xdp_prognum0(struct xdp_md *ctx)
 	if (key == MAX_RXQs)
 		rxq_rec->issue++;
 
+	/* Default: Don't touch packet data, only count packets */
+	if (unlikely(config->options & READ_MEM)) {
+		struct ethhdr *eth = data;
+
+		if (eth + 1 > data_end)
+			return XDP_ABORTED;
+
+		/* Avoid compiler removing this: Drop non 802.3 Ethertypes */
+		if (ntohs(eth->h_proto) < ETH_P_802_3_MIN)
+			return XDP_ABORTED;
+	}
+
 	return config->action;
 }
 

commit 0fca931a6f21c11f675363b92b5a4fe86da59f30
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Wed Jan 3 11:26:19 2018 +0100

    samples/bpf: program demonstrating access to xdp_rxq_info
    
    This sample program can be used for monitoring and reporting how many
    packets per sec (pps) are received per NIC RX queue index and which
    CPU processed the packet. In itself it is a useful tool for quickly
    identifying RSS imbalance issues, see below.
    
    The default XDP action is XDP_PASS in-order to provide a monitor
    mode. For benchmarking purposes it is possible to specify other XDP
    actions on the cmdline --action.
    
    Output below shows an imbalance RSS case where most RXQ's deliver to
    CPU-0 while CPU-2 only get packets from a single RXQ.  Looking at
    things from a CPU level the two CPUs are processing approx the same
    amount, BUT looking at the rx_queue_index levels it is clear that
    RXQ-2 receive much better service, than other RXQs which all share CPU-0.
    
    Running XDP on dev:i40e1 (ifindex:3) action:XDP_PASS
    XDP stats       CPU     pps         issue-pps
    XDP-RX CPU      0       900,473     0
    XDP-RX CPU      2       906,921     0
    XDP-RX CPU      total   1,807,395
    
    RXQ stats       RXQ:CPU pps         issue-pps
    rx_queue_index    0:0   180,098     0
    rx_queue_index    0:sum 180,098
    rx_queue_index    1:0   180,098     0
    rx_queue_index    1:sum 180,098
    rx_queue_index    2:2   906,921     0
    rx_queue_index    2:sum 906,921
    rx_queue_index    3:0   180,098     0
    rx_queue_index    3:sum 180,098
    rx_queue_index    4:0   180,082     0
    rx_queue_index    4:sum 180,082
    rx_queue_index    5:0   180,093     0
    rx_queue_index    5:sum 180,093
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/samples/bpf/xdp_rxq_info_kern.c b/samples/bpf/xdp_rxq_info_kern.c
new file mode 100644
index 000000000000..3fd209291653
--- /dev/null
+++ b/samples/bpf/xdp_rxq_info_kern.c
@@ -0,0 +1,96 @@
+/* SPDX-License-Identifier: GPL-2.0
+ * Copyright (c) 2017 Jesper Dangaard Brouer, Red Hat Inc.
+ *
+ *  Example howto extract XDP RX-queue info
+ */
+#include <uapi/linux/bpf.h>
+#include "bpf_helpers.h"
+
+/* Config setup from with userspace
+ *
+ * User-side setup ifindex in config_map, to verify that
+ * ctx->ingress_ifindex is correct (against configured ifindex)
+ */
+struct config {
+	__u32 action;
+	int ifindex;
+};
+struct bpf_map_def SEC("maps") config_map = {
+	.type		= BPF_MAP_TYPE_ARRAY,
+	.key_size	= sizeof(int),
+	.value_size	= sizeof(struct config),
+	.max_entries	= 1,
+};
+
+/* Common stats data record (shared with userspace) */
+struct datarec {
+	__u64 processed;
+	__u64 issue;
+};
+
+struct bpf_map_def SEC("maps") stats_global_map = {
+	.type		= BPF_MAP_TYPE_PERCPU_ARRAY,
+	.key_size	= sizeof(u32),
+	.value_size	= sizeof(struct datarec),
+	.max_entries	= 1,
+};
+
+#define MAX_RXQs 64
+
+/* Stats per rx_queue_index (per CPU) */
+struct bpf_map_def SEC("maps") rx_queue_index_map = {
+	.type		= BPF_MAP_TYPE_PERCPU_ARRAY,
+	.key_size	= sizeof(u32),
+	.value_size	= sizeof(struct datarec),
+	.max_entries	= MAX_RXQs + 1,
+};
+
+SEC("xdp_prog0")
+int  xdp_prognum0(struct xdp_md *ctx)
+{
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data     = (void *)(long)ctx->data;
+	struct datarec *rec, *rxq_rec;
+	int ingress_ifindex;
+	struct config *config;
+	u32 key = 0;
+
+	/* Global stats record */
+	rec = bpf_map_lookup_elem(&stats_global_map, &key);
+	if (!rec)
+		return XDP_ABORTED;
+	rec->processed++;
+
+	/* Accessing ctx->ingress_ifindex, cause BPF to rewrite BPF
+	 * instructions inside kernel to access xdp_rxq->dev->ifindex
+	 */
+	ingress_ifindex = ctx->ingress_ifindex;
+
+	config = bpf_map_lookup_elem(&config_map, &key);
+	if (!config)
+		return XDP_ABORTED;
+
+	/* Simple test: check ctx provided ifindex is as expected */
+	if (ingress_ifindex != config->ifindex) {
+		/* count this error case */
+		rec->issue++;
+		return XDP_ABORTED;
+	}
+
+	/* Update stats per rx_queue_index. Handle if rx_queue_index
+	 * is larger than stats map can contain info for.
+	 */
+	key = ctx->rx_queue_index;
+	if (key >= MAX_RXQs)
+		key = MAX_RXQs;
+	rxq_rec = bpf_map_lookup_elem(&rx_queue_index_map, &key);
+	if (!rxq_rec)
+		return XDP_ABORTED;
+	rxq_rec->processed++;
+	if (key == MAX_RXQs)
+		rxq_rec->issue++;
+
+	return config->action;
+}
+
+char _license[] SEC("license") = "GPL";
