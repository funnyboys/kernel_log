commit 6603523bf5e432c7c8490fb500793bb15d4e5f61
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Apr 10 16:09:42 2020 +1000

    crypto: api - Fix use-after-free and race in crypto_spawn_alg
    
    There are two problems in crypto_spawn_alg.  First of all it may
    return spawn->alg even if spawn->dead is set.  This results in a
    double-free as detected by syzbot.
    
    Secondly the setting of the DYING flag is racy because we hold
    the read-lock instead of the write-lock.  We should instead call
    crypto_shoot_alg in a safe manner by gaining a refcount, dropping
    the lock, and then releasing the refcount.
    
    This patch fixes both problems.
    
    Reported-by: syzbot+fc0674cde00b66844470@syzkaller.appspotmail.com
    Fixes: 4f87ee118d16 ("crypto: api - Do not zap spawn->alg")
    Fixes: 73669cc55646 ("crypto: api - Fix race condition in...")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 7d71a9b10e5f..edcf690800d4 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -333,12 +333,13 @@ static unsigned int crypto_ctxsize(struct crypto_alg *alg, u32 type, u32 mask)
 	return len;
 }
 
-static void crypto_shoot_alg(struct crypto_alg *alg)
+void crypto_shoot_alg(struct crypto_alg *alg)
 {
 	down_write(&crypto_alg_sem);
 	alg->cra_flags |= CRYPTO_ALG_DYING;
 	up_write(&crypto_alg_sem);
 }
+EXPORT_SYMBOL_GPL(crypto_shoot_alg);
 
 struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 type,
 				      u32 mask)

commit 2bbb3375d967155bccc86a5887d4a6e29c56b683
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Dec 11 10:50:11 2019 +0800

    crypto: api - fix unexpectedly getting generic implementation
    
    When CONFIG_CRYPTO_MANAGER_EXTRA_TESTS=y, the first lookup of an
    algorithm that needs to be instantiated using a template will always get
    the generic implementation, even when an accelerated one is available.
    
    This happens because the extra self-tests for the accelerated
    implementation allocate the generic implementation for comparison
    purposes, and then crypto_alg_tested() for the generic implementation
    "fulfills" the original request (i.e. sets crypto_larval::adult).
    
    This patch fixes this by only fulfilling the original request if
    we are currently the best outstanding larval as judged by the
    priority.  If we're not the best then we will ask all waiters on
    that larval request to retry the lookup.
    
    Note that this patch introduces a behaviour change when the module
    providing the new algorithm is unregistered during the process.
    Previously we would have failed with ENOENT, after the patch we
    will instead redo the lookup.
    
    Fixes: 9a8a6b3f0950 ("crypto: testmgr - fuzz hashes against...")
    Fixes: d435e10e67be ("crypto: testmgr - fuzz skciphers against...")
    Fixes: 40153b10d91c ("crypto: testmgr - fuzz AEADs against...")
    Reported-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Reviewed-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 676d54ffada8..7d71a9b10e5f 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -97,7 +97,7 @@ static void crypto_larval_destroy(struct crypto_alg *alg)
 	struct crypto_larval *larval = (void *)alg;
 
 	BUG_ON(!crypto_is_larval(alg));
-	if (larval->adult)
+	if (!IS_ERR_OR_NULL(larval->adult))
 		crypto_mod_put(larval->adult);
 	kfree(larval);
 }
@@ -178,6 +178,8 @@ static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 		alg = ERR_PTR(-ETIMEDOUT);
 	else if (!alg)
 		alg = ERR_PTR(-ENOENT);
+	else if (IS_ERR(alg))
+		;
 	else if (crypto_is_test_larval(larval) &&
 		 !(alg->cra_flags & CRYPTO_ALG_TESTED))
 		alg = ERR_PTR(-EAGAIN);

commit 73669cc556462f4e50376538d77ee312142e8a8a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Dec 7 22:15:15 2019 +0800

    crypto: api - Fix race condition in crypto_spawn_alg
    
    The function crypto_spawn_alg is racy because it drops the lock
    before shooting the dying algorithm.  The algorithm could disappear
    altogether before we shoot it.
    
    This patch fixes it by moving the shooting into the locked section.
    
    Fixes: 6bfd48096ff8 ("[CRYPTO] api: Added spawns")
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index ef96142ceca7..676d54ffada8 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -331,13 +331,12 @@ static unsigned int crypto_ctxsize(struct crypto_alg *alg, u32 type, u32 mask)
 	return len;
 }
 
-void crypto_shoot_alg(struct crypto_alg *alg)
+static void crypto_shoot_alg(struct crypto_alg *alg)
 {
 	down_write(&crypto_alg_sem);
 	alg->cra_flags |= CRYPTO_ALG_DYING;
 	up_write(&crypto_alg_sem);
 }
-EXPORT_SYMBOL_GPL(crypto_shoot_alg);
 
 struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 type,
 				      u32 mask)

commit e8cfed5e4e2b5929371955f476a52a4c3398ead3
Author: Eric Biggers <ebiggers@google.com>
Date:   Mon Dec 2 13:42:30 2019 -0800

    crypto: cipher - remove crt_u.cipher (struct cipher_tfm)
    
    Of the three fields in crt_u.cipher (struct cipher_tfm), ->cit_setkey()
    is pointless because it always points to setkey() in crypto/cipher.c.
    
    ->cit_decrypt_one() and ->cit_encrypt_one() are slightly less pointless,
    since if the algorithm doesn't have an alignmask, they are set directly
    to ->cia_encrypt() and ->cia_decrypt().  However, this "optimization"
    isn't worthwhile because:
    
    - The "cipher" algorithm type is the only algorithm still using crt_u,
      so it's bloating every struct crypto_tfm for every algorithm type.
    
    - If the algorithm has an alignmask, this "optimization" actually makes
      things slower, as it causes 2 indirect calls per block rather than 1.
    
    - It adds extra code complexity.
    
    - Some templates already call ->cia_encrypt()/->cia_decrypt() directly
      instead of going through ->cit_encrypt_one()/->cit_decrypt_one().
    
    - The "cipher" algorithm type never gives optimal performance anyway.
      For that, a higher-level type such as skcipher needs to be used.
    
    Therefore, just remove the extra indirection, and make
    crypto_cipher_setkey(), crypto_cipher_encrypt_one(), and
    crypto_cipher_decrypt_one() be direct calls into crypto/cipher.c.
    
    Also remove the unused function crypto_cipher_cast().
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 268129979bc2..ef96142ceca7 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -295,20 +295,7 @@ static int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)
 
 	if (type_obj)
 		return type_obj->init(tfm, type, mask);
-
-	switch (crypto_tfm_alg_type(tfm)) {
-	case CRYPTO_ALG_TYPE_CIPHER:
-		return crypto_init_cipher_ops(tfm);
-
-	case CRYPTO_ALG_TYPE_COMPRESS:
-		return 0;
-
-	default:
-		break;
-	}
-
-	BUG();
-	return -EINVAL;
+	return 0;
 }
 
 static void crypto_exit_ops(struct crypto_tfm *tfm)

commit c441a909c68618ff64aa70394d0b270b0665a229
Author: Eric Biggers <ebiggers@google.com>
Date:   Mon Dec 2 13:42:29 2019 -0800

    crypto: compress - remove crt_u.compress (struct compress_tfm)
    
    crt_u.compress (struct compress_tfm) is pointless because its two
    fields, ->cot_compress() and ->cot_decompress(), always point to
    crypto_compress() and crypto_decompress().
    
    Remove this pointless indirection, and just make crypto_comp_compress()
    and crypto_comp_decompress() be direct calls to what used to be
    crypto_compress() and crypto_decompress().
    
    Also remove the unused function crypto_comp_cast().
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 4d3d13872fac..268129979bc2 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -301,7 +301,7 @@ static int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)
 		return crypto_init_cipher_ops(tfm);
 
 	case CRYPTO_ALG_TYPE_COMPRESS:
-		return crypto_init_compress_ops(tfm);
+		return 0;
 
 	default:
 		break;

commit 0a940d4e27658a545884351c46a70b132272a38d
Author: Eric Biggers <ebiggers@google.com>
Date:   Fri Nov 29 10:16:48 2019 -0800

    crypto: api - remove another reference to blkcipher
    
    Update a comment to refer to crypto_alloc_skcipher() rather than
    crypto_alloc_blkcipher() (the latter having been removed).
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 55bca28df92d..4d3d13872fac 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -516,7 +516,7 @@ EXPORT_SYMBOL_GPL(crypto_find_alg);
  *
  *	The returned transform is of a non-determinate type.  Most people
  *	should use one of the more specific allocation functions such as
- *	crypto_alloc_blkcipher.
+ *	crypto_alloc_skcipher().
  *
  *	In case of error the return value is an error pointer.
  */

commit 8ab23d547f652979bafd710d9e34983aaceea517
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Nov 8 18:26:30 2019 +0800

    crypto: api - Add softdep on cryptomgr
    
    The crypto API requires cryptomgr to be present for probing to work
    so we need a softdep to ensure that cryptomgr is added to the
    initramfs.
    
    This was usually not a problem because until very recently it was
    not practical to build crypto API as module but with the recent
    work to eliminate direct AES users this is now possible.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 3e1f9e95095a..55bca28df92d 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -608,3 +608,4 @@ EXPORT_SYMBOL_GPL(crypto_req_done);
 
 MODULE_DESCRIPTION("Cryptographic core API");
 MODULE_LICENSE("GPL");
+MODULE_SOFTDEP("pre: cryptomgr");

commit c65058b7587fd3d001c57a50285477be521f5350
Author: Eric Biggers <ebiggers@google.com>
Date:   Fri Oct 25 12:41:12 2019 -0700

    crypto: skcipher - remove the "blkcipher" algorithm type
    
    Now that all "blkcipher" algorithms have been converted to "skcipher",
    remove the blkcipher algorithm type.
    
    The skcipher (symmetric key cipher) algorithm type was introduced a few
    years ago to replace both blkcipher and ablkcipher (synchronous and
    asynchronous block cipher).  The advantages of skcipher include:
    
      - A much less confusing name, since none of these algorithm types have
        ever actually been for raw block ciphers, but rather for all
        length-preserving encryption modes including block cipher modes of
        operation, stream ciphers, and other length-preserving modes.
    
      - It unified blkcipher and ablkcipher into a single algorithm type
        which supports both synchronous and asynchronous implementations.
        Note, blkcipher already operated only on scatterlists, so the fact
        that skcipher does too isn't a regression in functionality.
    
      - Better type safety by using struct skcipher_alg, struct
        crypto_skcipher, etc. instead of crypto_alg, crypto_tfm, etc.
    
      - It sometimes simplifies the implementations of algorithms.
    
    Also, the blkcipher API was no longer being tested.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index d8ba54142620..3e1f9e95095a 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -406,7 +406,7 @@ EXPORT_SYMBOL_GPL(__crypto_alloc_tfm);
  *
  *	The returned transform is of a non-determinate type.  Most people
  *	should use one of the more specific allocation functions such as
- *	crypto_alloc_blkcipher.
+ *	crypto_alloc_skcipher().
  *
  *	In case of error the return value is an error pointer.
  */

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/crypto/api.c b/crypto/api.c
index 7aca9f86c5f3..d8ba54142620 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Scatterlist Cryptographic API.
  *
@@ -7,12 +8,6 @@
  *
  * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>
  * and Nettle, by Niels MÃ¶ller.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License as published by the Free
- * Software Foundation; either version 2 of the License, or (at your option)
- * any later version.
- *
  */
 
 #include <linux/err.h>

commit e2861fa71641c6414831d628a1f4f793b6562580
Author: Matthew Garrett <mjg59@google.com>
Date:   Fri Jun 8 14:57:42 2018 -0700

    evm: Don't deadlock if a crypto algorithm is unavailable
    
    When EVM attempts to appraise a file signed with a crypto algorithm the
    kernel doesn't have support for, it will cause the kernel to trigger a
    module load. If the EVM policy includes appraisal of kernel modules this
    will in turn call back into EVM - since EVM is holding a lock until the
    crypto initialisation is complete, this triggers a deadlock. Add a
    CRYPTO_NOLOAD flag and skip module loading if it's set, and add that flag
    in the EVM case in order to fail gracefully with an error message
    instead of deadlocking.
    
    Signed-off-by: Matthew Garrett <mjg59@google.com>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/crypto/api.c b/crypto/api.c
index 0ee632bba064..7aca9f86c5f3 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -229,7 +229,7 @@ static struct crypto_alg *crypto_larval_lookup(const char *name, u32 type,
 	mask &= ~(CRYPTO_ALG_LARVAL | CRYPTO_ALG_DEAD);
 
 	alg = crypto_alg_lookup(name, type, mask);
-	if (!alg) {
+	if (!alg && !(mask & CRYPTO_NOLOAD)) {
 		request_module("crypto-%s", name);
 
 		if (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask &

commit b346e492d7127e4332d5a9989b844b2095cc4fcd
Author: Eric Biggers <ebiggers@google.com>
Date:   Mon Apr 16 16:59:13 2018 -0700

    crypto: api - fix finding algorithm currently being tested
    
    Commit eb02c38f0197 ("crypto: api - Keep failed instances alive") is
    making allocating crypto transforms sometimes fail with ELIBBAD, when
    multiple processes try to access encrypted files with fscrypt for the
    first time since boot.  The problem is that the "request larval" for the
    algorithm is being mistaken for an algorithm which failed its tests.
    
    Fix it by only returning ELIBBAD for "non-larval" algorithms.  Also
    don't leak a reference to the algorithm.
    
    Fixes: eb02c38f0197 ("crypto: api - Keep failed instances alive")
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 1d5290c67108..0ee632bba064 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -204,9 +204,14 @@ static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
 
 	down_read(&crypto_alg_sem);
 	alg = __crypto_alg_lookup(name, type | test, mask | test);
-	if (!alg && test)
-		alg = __crypto_alg_lookup(name, type, mask) ?
-		      ERR_PTR(-ELIBBAD) : NULL;
+	if (!alg && test) {
+		alg = __crypto_alg_lookup(name, type, mask);
+		if (alg && !crypto_is_larval(alg)) {
+			/* Test failed */
+			crypto_mod_put(alg);
+			alg = ERR_PTR(-ELIBBAD);
+		}
+	}
 	up_read(&crypto_alg_sem);
 
 	return alg;

commit eb02c38f019726ede53eb31c3c604fd77cfedc2e
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Mar 20 15:52:45 2018 +0800

    crypto: api - Keep failed instances alive
    
    This patch reverts commit 9c521a200bc3 ("crypto: api - remove
    instance when test failed") and fixes the underlying problem
    in a different way.
    
    To recap, prior to the reverted commit, an instance that fails
    a self-test is kept around.  However, it would satisfy any new
    lookups against its name and therefore the system may accumlulate
    an unbounded number of failed instances for the same algorithm
    name.
    
    The reverted commit fixed it by unregistering the instance.  Hoever,
    this still does not prevent the creation of the same failed instance
    over and over again each time the name is looked up.
    
    This patch fixes it by keeping the failed instance around, just as
    we would if it were a normal algorithm.  However, the lookup code
    has been udpated so that we do not attempt to create another
    instance as long as this failed one is still registered.  Of course,
    you could still force a new creation by deleting the instance from
    user-space.
    
    A new error (ELIBBAD) has been commandeered for this purpose and
    will be returned when all registered algorithm of a given name
    have failed the self-test.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index bb9fe480f092..1d5290c67108 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -197,9 +197,16 @@ static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
 					    u32 mask)
 {
 	struct crypto_alg *alg;
+	u32 test = 0;
+
+	if (!((type | mask) & CRYPTO_ALG_TESTED))
+		test |= CRYPTO_ALG_TESTED;
 
 	down_read(&crypto_alg_sem);
-	alg = __crypto_alg_lookup(name, type, mask);
+	alg = __crypto_alg_lookup(name, type | test, mask | test);
+	if (!alg && test)
+		alg = __crypto_alg_lookup(name, type, mask) ?
+		      ERR_PTR(-ELIBBAD) : NULL;
 	up_read(&crypto_alg_sem);
 
 	return alg;
@@ -227,10 +234,12 @@ static struct crypto_alg *crypto_larval_lookup(const char *name, u32 type,
 		alg = crypto_alg_lookup(name, type, mask);
 	}
 
-	if (alg)
-		return crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;
+	if (!IS_ERR_OR_NULL(alg) && crypto_is_larval(alg))
+		alg = crypto_larval_wait(alg);
+	else if (!alg)
+		alg = crypto_larval_add(name, type, mask);
 
-	return crypto_larval_add(name, type, mask);
+	return alg;
 }
 
 int crypto_probing_notify(unsigned long val, void *v)
@@ -253,11 +262,6 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 	struct crypto_alg *larval;
 	int ok;
 
-	if (!((type | mask) & CRYPTO_ALG_TESTED)) {
-		type |= CRYPTO_ALG_TESTED;
-		mask |= CRYPTO_ALG_TESTED;
-	}
-
 	/*
 	 * If the internal flag is set for a cipher, require a caller to
 	 * to invoke the cipher with the internal flag to use that cipher.

commit 3ca1e9948940230bd2c4b17e320bbab3367fc37b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Mar 20 08:05:39 2018 +0800

    crypto: api - Make crypto_alg_lookup static
    
    The function crypto_alg_lookup is only usd within the crypto API
    and should be not be exported to the modules.  This patch marks
    it as a static function.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 0e9cd200a506..bb9fe480f092 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -193,7 +193,8 @@ static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 	return alg;
 }
 
-struct crypto_alg *crypto_alg_lookup(const char *name, u32 type, u32 mask)
+static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
+					    u32 mask)
 {
 	struct crypto_alg *alg;
 
@@ -203,7 +204,6 @@ struct crypto_alg *crypto_alg_lookup(const char *name, u32 type, u32 mask)
 
 	return alg;
 }
-EXPORT_SYMBOL_GPL(crypto_alg_lookup);
 
 static struct crypto_alg *crypto_larval_lookup(const char *name, u32 type,
 					       u32 mask)

commit 4989d4f07a8e738b33a79099ddbdd8e125a4da1b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Mar 20 07:41:00 2018 +0800

    crypto: api - Remove unused crypto_type lookup function
    
    The lookup function in crypto_type was only used for the implicit
    IV generators which have been completely removed from the crypto
    API.
    
    This patch removes the lookup function as it is now useless.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 70a894e52ff3..0e9cd200a506 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -485,20 +485,14 @@ struct crypto_alg *crypto_find_alg(const char *alg_name,
 				   const struct crypto_type *frontend,
 				   u32 type, u32 mask)
 {
-	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask) =
-		crypto_alg_mod_lookup;
-
 	if (frontend) {
 		type &= frontend->maskclear;
 		mask &= frontend->maskclear;
 		type |= frontend->type;
 		mask |= frontend->maskset;
-
-		if (frontend->lookup)
-			lookup = frontend->lookup;
 	}
 
-	return lookup(alg_name, type, mask);
+	return crypto_alg_mod_lookup(alg_name, type, mask);
 }
 EXPORT_SYMBOL_GPL(crypto_find_alg);
 

commit ce8614a312ef750bb60677bb13680cb27d1c284b
Author: Eric Biggers <ebiggers@google.com>
Date:   Fri Dec 29 10:00:46 2017 -0600

    crypto: algapi - convert cra_refcnt to refcount_t
    
    Reference counters should use refcount_t rather than atomic_t, since the
    refcount_t implementation can prevent overflows, reducing the
    exploitability of reference leak bugs.  crypto_alg.cra_refcount is a
    reference counter with the usual semantics, so switch it over to
    refcount_t.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 6da802d7be67..70a894e52ff3 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -137,7 +137,7 @@ static struct crypto_alg *crypto_larval_add(const char *name, u32 type,
 	if (IS_ERR(larval))
 		return ERR_CAST(larval);
 
-	atomic_set(&larval->alg.cra_refcnt, 2);
+	refcount_set(&larval->alg.cra_refcnt, 2);
 
 	down_write(&crypto_alg_sem);
 	alg = __crypto_alg_lookup(name, type, mask);

commit cadc9ab50350a24140612814109e826bb0e2ae37
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Dec 7 10:55:59 2017 -0800

    crypto: api - Unexport crypto_larval_lookup()
    
    crypto_larval_lookup() is not used outside of crypto/api.c, so unexport
    it and mark it 'static'.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 2a2479d168aa..6da802d7be67 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -205,7 +205,8 @@ struct crypto_alg *crypto_alg_lookup(const char *name, u32 type, u32 mask)
 }
 EXPORT_SYMBOL_GPL(crypto_alg_lookup);
 
-struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
+static struct crypto_alg *crypto_larval_lookup(const char *name, u32 type,
+					       u32 mask)
 {
 	struct crypto_alg *alg;
 
@@ -231,7 +232,6 @@ struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 
 	return crypto_larval_add(name, type, mask);
 }
-EXPORT_SYMBOL_GPL(crypto_larval_lookup);
 
 int crypto_probing_notify(unsigned long val, void *v)
 {

commit ada69a1639eca54ff74d839a6513c43db8d57d70
Author: Gilad Ben-Yossef <gilad@benyossef.com>
Date:   Wed Oct 18 08:00:38 2017 +0100

    crypto: introduce crypto wait for async op
    
    Invoking a possibly async. crypto op and waiting for completion
    while correctly handling backlog processing is a common task
    in the crypto API implementation and outside users of it.
    
    This patch adds a generic implementation for doing so in
    preparation for using it across the board instead of hand
    rolled versions.
    
    Signed-off-by: Gilad Ben-Yossef <gilad@benyossef.com>
    CC: Eric Biggers <ebiggers3@gmail.com>
    CC: Jonathan Cameron <Jonathan.Cameron@huawei.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 941cd4c6c7ec..2a2479d168aa 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -24,6 +24,7 @@
 #include <linux/sched/signal.h>
 #include <linux/slab.h>
 #include <linux/string.h>
+#include <linux/completion.h>
 #include "internal.h"
 
 LIST_HEAD(crypto_alg_list);
@@ -595,5 +596,17 @@ int crypto_has_alg(const char *name, u32 type, u32 mask)
 }
 EXPORT_SYMBOL_GPL(crypto_has_alg);
 
+void crypto_req_done(struct crypto_async_request *req, int err)
+{
+	struct crypto_wait *wait = req->data;
+
+	if (err == -EINPROGRESS)
+		return;
+
+	wait->err = err;
+	complete(&wait->completion);
+}
+EXPORT_SYMBOL_GPL(crypto_req_done);
+
 MODULE_DESCRIPTION("Cryptographic core API");
 MODULE_LICENSE("GPL");

commit 174cd4b1e5fbd0d74c68cf3a74f5bd4923485512
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 2 19:15:33 2017 +0100

    sched/headers: Prepare to move signal wakeup & sigpending methods from <linux/sched.h> into <linux/sched/signal.h>
    
    Fix up affected files that include this signal functionality via sched.h.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/crypto/api.c b/crypto/api.c
index b16ce1653284..941cd4c6c7ec 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -21,7 +21,7 @@
 #include <linux/kmod.h>
 #include <linux/module.h>
 #include <linux/param.h>
-#include <linux/sched.h>
+#include <linux/sched/signal.h>
 #include <linux/slab.h>
 #include <linux/string.h>
 #include "internal.h"

commit 430b441cdcdeb7c3eff4c208effb970f41867934
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Nov 22 20:08:21 2016 +0800

    crypto: api - Do not clear type bits in crypto_larval_lookup
    
    Currently all bits not set in mask are cleared in crypto_larval_lookup.
    This is unnecessary as wherever the type bits are used it is always
    masked anyway.
    
    This patch removes the clearing so that we may use bits set in the
    type but not in the mask for special purposes, e.g., picking up
    internal algorithms.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index a88729ffe4bd..b16ce1653284 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -211,8 +211,8 @@ struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 	if (!name)
 		return ERR_PTR(-ENOENT);
 
+	type &= ~(CRYPTO_ALG_LARVAL | CRYPTO_ALG_DEAD);
 	mask &= ~(CRYPTO_ALG_LARVAL | CRYPTO_ALG_DEAD);
-	type &= mask;
 
 	alg = crypto_alg_lookup(name, type, mask);
 	if (!alg) {

commit 9c8ae17bbf416d837b81be7820d6d210d8353262
Author: Eric Biggers <ebiggers@google.com>
Date:   Fri Oct 7 14:13:35 2016 -0700

    crypto: api - Remove no-op exit_ops code
    
    crypto_exit_cipher_ops() and crypto_exit_compress_ops() are no-ops and
    have been for a long time, so remove them.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index bbc147cb5dec..a88729ffe4bd 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -310,24 +310,8 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 {
 	const struct crypto_type *type = tfm->__crt_alg->cra_type;
 
-	if (type) {
-		if (tfm->exit)
-			tfm->exit(tfm);
-		return;
-	}
-
-	switch (crypto_tfm_alg_type(tfm)) {
-	case CRYPTO_ALG_TYPE_CIPHER:
-		crypto_exit_cipher_ops(tfm);
-		break;
-
-	case CRYPTO_ALG_TYPE_COMPRESS:
-		crypto_exit_compress_ops(tfm);
-		break;
-
-	default:
-		BUG();
-	}
+	if (type && tfm->exit)
+		tfm->exit(tfm);
 }
 
 static unsigned int crypto_ctxsize(struct crypto_alg *alg, u32 type, u32 mask)

commit 3fc89adb9fa4beff31374a4bf50b3d099d88ae83
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Oct 19 18:23:57 2015 +0800

    crypto: api - Only abort operations on fatal signal
    
    Currently a number of Crypto API operations may fail when a signal
    occurs.  This causes nasty problems as the caller of those operations
    are often not in a good position to restart the operation.
    
    In fact there is currently no need for those operations to be
    interrupted by user signals at all.  All we need is for them to
    be killable.
    
    This patch replaces the relevant calls of signal_pending with
    fatal_signal_pending, and wait_for_completion_interruptible with
    wait_for_completion_killable, respectively.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index afe4610afc4b..bbc147cb5dec 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -172,7 +172,7 @@ static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 	struct crypto_larval *larval = (void *)alg;
 	long timeout;
 
-	timeout = wait_for_completion_interruptible_timeout(
+	timeout = wait_for_completion_killable_timeout(
 		&larval->completion, 60 * HZ);
 
 	alg = larval->adult;
@@ -445,7 +445,7 @@ struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
 err:
 		if (err != -EAGAIN)
 			break;
-		if (signal_pending(current)) {
+		if (fatal_signal_pending(current)) {
 			err = -EINTR;
 			break;
 		}
@@ -562,7 +562,7 @@ void *crypto_alloc_tfm(const char *alg_name,
 err:
 		if (err != -EAGAIN)
 			break;
-		if (signal_pending(current)) {
+		if (fatal_signal_pending(current)) {
 			err = -EINTR;
 			break;
 		}

commit 06ca7f68d4c861d549a8deb161e1527065a80bb1
Author: Stephan Mueller <smueller@chronox.de>
Date:   Mon Mar 30 21:55:52 2015 +0200

    crypto: api - prevent helper ciphers from being used
    
    Several hardware related cipher implementations are implemented as
    follows: a "helper" cipher implementation is registered with the
    kernel crypto API.
    
    Such helper ciphers are never intended to be called by normal users. In
    some cases, calling them via the normal crypto API may even cause
    failures including kernel crashes. In a normal case, the "wrapping"
    ciphers that use the helpers ensure that these helpers are invoked
    such that they cannot cause any calamity.
    
    Considering the AF_ALG user space interface, unprivileged users can
    call all ciphers registered with the crypto API, including these
    helper ciphers that are not intended to be called directly. That
    means, with AF_ALG user space may invoke these helper ciphers
    and may cause undefined states or side effects.
    
    To avoid any potential side effects with such helpers, the patch
    prevents the helpers to be called directly. A new cipher type
    flag is added: CRYPTO_ALG_INTERNAL. This flag shall be used
    to mark helper ciphers. These ciphers can only be used if the
    caller invoke the cipher with CRYPTO_ALG_INTERNAL in the type and
    mask field.
    
    Signed-off-by: Stephan Mueller <smueller@chronox.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 2a81e98a0021..afe4610afc4b 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -257,6 +257,16 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 		mask |= CRYPTO_ALG_TESTED;
 	}
 
+	/*
+	 * If the internal flag is set for a cipher, require a caller to
+	 * to invoke the cipher with the internal flag to use that cipher.
+	 * Also, if a caller wants to allocate a cipher that may or may
+	 * not be an internal cipher, use type | CRYPTO_ALG_INTERNAL and
+	 * !(mask & CRYPTO_ALG_INTERNAL).
+	 */
+	if (!((type | mask) & CRYPTO_ALG_INTERNAL))
+		mask |= CRYPTO_ALG_INTERNAL;
+
 	larval = crypto_larval_lookup(name, type, mask);
 	if (IS_ERR(larval) || !crypto_is_larval(larval))
 		return larval;

commit 5d26a105b5a73e5635eae0629b42fa0a90e07b7b
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Nov 20 17:05:53 2014 -0800

    crypto: prefix module autoloading with "crypto-"
    
    This prefixes all crypto module loading with "crypto-" so we never run
    the risk of exposing module auto-loading to userspace via a crypto API,
    as demonstrated by Mathias Krause:
    
    https://lkml.org/lkml/2013/3/4/70
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index a2b39c5f3649..2a81e98a0021 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -216,11 +216,11 @@ struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 
 	alg = crypto_alg_lookup(name, type, mask);
 	if (!alg) {
-		request_module("%s", name);
+		request_module("crypto-%s", name);
 
 		if (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask &
 		      CRYPTO_ALG_NEED_FALLBACK))
-			request_module("%s-all", name);
+			request_module("crypto-%s-all", name);
 
 		alg = crypto_alg_lookup(name, type, mask);
 	}

commit 77dbd7a95e4a4f15264c333a9e9ab97ee27dc2aa
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Sep 8 14:33:50 2013 +1000

    crypto: api - Fix race condition in larval lookup
    
    crypto_larval_lookup should only return a larval if it created one.
    Any larval created by another entity must be processed through
    crypto_larval_wait before being returned.
    
    Otherwise this will lead to a larval being killed twice, which
    will most likely lead to a crash.
    
    Cc: stable@vger.kernel.org
    Reported-by: Kees Cook <keescook@chromium.org>
    Tested-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 320ea4d8a0f5..a2b39c5f3649 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -34,6 +34,8 @@ EXPORT_SYMBOL_GPL(crypto_alg_sem);
 BLOCKING_NOTIFIER_HEAD(crypto_chain);
 EXPORT_SYMBOL_GPL(crypto_chain);
 
+static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg);
+
 struct crypto_alg *crypto_mod_get(struct crypto_alg *alg)
 {
 	return try_module_get(alg->cra_module) ? crypto_alg_get(alg) : NULL;
@@ -144,8 +146,11 @@ static struct crypto_alg *crypto_larval_add(const char *name, u32 type,
 	}
 	up_write(&crypto_alg_sem);
 
-	if (alg != &larval->alg)
+	if (alg != &larval->alg) {
 		kfree(larval);
+		if (crypto_is_larval(alg))
+			alg = crypto_larval_wait(alg);
+	}
 
 	return alg;
 }

commit fd1a190029cc29fadf14bb9a1e82767e80c6ebdb
Author: Cristian Stoica <cristian.stoica@freescale.com>
Date:   Fri Jun 28 15:56:20 2013 +0300

    crypto: fix typo in comment
    
    Signed-off-by: Cristian Stoica <cristian.stoica@freescale.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/crypto/api.c b/crypto/api.c
index 3b6180336d3d..320ea4d8a0f5 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -391,7 +391,7 @@ EXPORT_SYMBOL_GPL(__crypto_alloc_tfm);
  *	@mask: Mask for type comparison
  *
  *	This function should not be used by new algorithm types.
- *	Plesae use crypto_alloc_tfm instead.
+ *	Please use crypto_alloc_tfm instead.
  *
  *	crypto_alloc_base() will first attempt to locate an already loaded
  *	algorithm.  If that fails and the kernel supports dynamically loadable

commit 939e17799619e31331d2433041196529515a86a6
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jun 25 19:15:17 2013 +0800

    crypto: algboss - Hold ref count on larval
    
    On Thu, Jun 20, 2013 at 10:00:21AM +0200, Daniel Borkmann wrote:
    > After having fixed a NULL pointer dereference in SCTP 1abd165e ("net:
    > sctp: fix NULL pointer dereference in socket destruction"), I ran into
    > the following NULL pointer dereference in the crypto subsystem with
    > the same reproducer, easily hit each time:
    >
    > BUG: unable to handle kernel NULL pointer dereference at (null)
    > IP: [<ffffffff81070321>] __wake_up_common+0x31/0x90
    > PGD 0
    > Oops: 0000 [#1] SMP
    > Modules linked in: padlock_sha(F-) sha256_generic(F) sctp(F) libcrc32c(F) [..]
    > CPU: 6 PID: 3326 Comm: cryptomgr_probe Tainted: GF            3.10.0-rc5+ #1
    > Hardware name: Dell Inc. PowerEdge T410/0H19HD, BIOS 1.6.3 02/01/2011
    > task: ffff88007b6cf4e0 ti: ffff88007b7cc000 task.ti: ffff88007b7cc000
    > RIP: 0010:[<ffffffff81070321>]  [<ffffffff81070321>] __wake_up_common+0x31/0x90
    > RSP: 0018:ffff88007b7cde08  EFLAGS: 00010082
    > RAX: ffffffffffffffe8 RBX: ffff88003756c130 RCX: 0000000000000000
    > RDX: 0000000000000000 RSI: 0000000000000003 RDI: ffff88003756c130
    > RBP: ffff88007b7cde48 R08: 0000000000000000 R09: ffff88012b173200
    > R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000282
    > R13: ffff88003756c138 R14: 0000000000000000 R15: 0000000000000000
    > FS:  0000000000000000(0000) GS:ffff88012fc60000(0000) knlGS:0000000000000000
    > CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    > CR2: 0000000000000000 CR3: 0000000001a0b000 CR4: 00000000000007e0
    > DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    > DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    > Stack:
    >  ffff88007b7cde28 0000000300000000 ffff88007b7cde28 ffff88003756c130
    >  0000000000000282 ffff88003756c128 ffffffff81227670 0000000000000000
    >  ffff88007b7cde78 ffffffff810722b7 ffff88007cdcf000 ffffffff81a90540
    > Call Trace:
    >  [<ffffffff81227670>] ? crypto_alloc_pcomp+0x20/0x20
    >  [<ffffffff810722b7>] complete_all+0x47/0x60
    >  [<ffffffff81227708>] cryptomgr_probe+0x98/0xc0
    >  [<ffffffff81227670>] ? crypto_alloc_pcomp+0x20/0x20
    >  [<ffffffff8106760e>] kthread+0xce/0xe0
    >  [<ffffffff81067540>] ? kthread_freezable_should_stop+0x70/0x70
    >  [<ffffffff815450dc>] ret_from_fork+0x7c/0xb0
    >  [<ffffffff81067540>] ? kthread_freezable_should_stop+0x70/0x70
    > Code: 41 56 41 55 41 54 53 48 83 ec 18 66 66 66 66 90 89 75 cc 89 55 c8
    >       4c 8d 6f 08 48 8b 57 08 41 89 cf 4d 89 c6 48 8d 42 e
    > RIP  [<ffffffff81070321>] __wake_up_common+0x31/0x90
    >  RSP <ffff88007b7cde08>
    > CR2: 0000000000000000
    > ---[ end trace b495b19270a4d37e ]---
    >
    > My assumption is that the following is happening: the minimal SCTP
    > tool runs under ``echo 1 > /proc/sys/net/sctp/auth_enable'', hence
    > it's making use of crypto_alloc_hash() via sctp_auth_init_hmacs().
    > It forks itself, heavily allocates, binds, listens and waits in
    > accept on sctp sockets, and then randomly kills some of them (no
    > need for an actual client in this case to hit this). Then, again,
    > allocating, binding, etc, and then killing child processes.
    >
    > The problem that might be happening here is that cryptomgr requests
    > the module to probe/load through cryptomgr_schedule_probe(), but
    > before the thread handler cryptomgr_probe() returns, we return from
    > the wait_for_completion_interruptible() function and probably already
    > have cleared up larval, thus we run into a NULL pointer dereference
    > when in cryptomgr_probe() complete_all() is being called.
    >
    > If we wait with wait_for_completion() instead, this panic will not
    > occur anymore. This is valid, because in case a signal is pending,
    > cryptomgr_probe() returns from probing anyway with properly calling
    > complete_all().
    
    The use of wait_for_completion_interruptible is intentional so that
    we don't lock up the thread if a bug causes us to never wake up.
    
    This bug is caused by the helper thread using the larval without
    holding a reference count on it.  If the helper thread completes
    after the original thread requesting for help has gone away and
    destroyed the larval, then we get the crash above.
    
    So the fix is to hold a reference count on the larval.
    
    Cc: <stable@vger.kernel.org> # 3.6+
    Reported-by: Daniel Borkmann <dborkman@redhat.com>
    Tested-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 033a7147e5eb..3b6180336d3d 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -34,12 +34,6 @@ EXPORT_SYMBOL_GPL(crypto_alg_sem);
 BLOCKING_NOTIFIER_HEAD(crypto_chain);
 EXPORT_SYMBOL_GPL(crypto_chain);
 
-static inline struct crypto_alg *crypto_alg_get(struct crypto_alg *alg)
-{
-	atomic_inc(&alg->cra_refcnt);
-	return alg;
-}
-
 struct crypto_alg *crypto_mod_get(struct crypto_alg *alg)
 {
 	return try_module_get(alg->cra_module) ? crypto_alg_get(alg) : NULL;

commit 3d01a33b77b120f8b11d8757c346442ed7961b11
Author: Richard Hartmann <richih.mailinglist@gmail.com>
Date:   Tue Feb 16 20:26:46 2010 +0800

    crypto: api - Fix checkpatch errors
    
    Signed-off-by: Richard Hartmann <richih.mailinglist@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 798526d90538..033a7147e5eb 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -10,7 +10,7 @@
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License as published by the Free
- * Software Foundation; either version 2 of the License, or (at your option) 
+ * Software Foundation; either version 2 of the License, or (at your option)
  * any later version.
  *
  */
@@ -288,11 +288,11 @@ static int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)
 
 	case CRYPTO_ALG_TYPE_COMPRESS:
 		return crypto_init_compress_ops(tfm);
-	
+
 	default:
 		break;
 	}
-	
+
 	BUG();
 	return -EINVAL;
 }
@@ -315,10 +315,9 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 	case CRYPTO_ALG_TYPE_COMPRESS:
 		crypto_exit_compress_ops(tfm);
 		break;
-	
+
 	default:
 		BUG();
-		
 	}
 }
 
@@ -593,12 +592,12 @@ int crypto_has_alg(const char *name, u32 type, u32 mask)
 {
 	int ret = 0;
 	struct crypto_alg *alg = crypto_alg_mod_lookup(name, type, mask);
-	
+
 	if (!IS_ERR(alg)) {
 		crypto_mod_put(alg);
 		ret = 1;
 	}
-	
+
 	return ret;
 }
 EXPORT_SYMBOL_GPL(crypto_has_alg);

commit 2ca33da1dea3ba53d1425226a6bac073c5e8568c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Jul 13 20:46:25 2009 +0800

    crypto: api - Remove frontend argument from extsize/init_tfm
    
    As the extsize and init_tfm functions belong to the frontend the
    frontend argument is superfluous.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index c8ac18f7ac1e..798526d90538 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -457,7 +457,7 @@ void *crypto_create_tfm(struct crypto_alg *alg,
 	int err = -ENOMEM;
 
 	tfmsize = frontend->tfmsize;
-	total = tfmsize + sizeof(*tfm) + frontend->extsize(alg, frontend);
+	total = tfmsize + sizeof(*tfm) + frontend->extsize(alg);
 
 	mem = kzalloc(total, GFP_KERNEL);
 	if (mem == NULL)
@@ -466,7 +466,7 @@ void *crypto_create_tfm(struct crypto_alg *alg,
 	tfm = (struct crypto_tfm *)(mem + tfmsize);
 	tfm->__crt_alg = alg;
 
-	err = frontend->init_tfm(tfm, frontend);
+	err = frontend->init_tfm(tfm);
 	if (err)
 		goto out_free_tfm;
 

commit 6941c3a0aabb6ad4167827360f384e9daed7dd7f
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Jul 12 13:58:04 2009 +0800

    crypto: hash - Remove legacy hash/digest implementaion
    
    This patch removes the implementation of hash and digest now that
    no algorithms use them anymore.  The interface though will remain
    until the users are converted across.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index ba81221b3bef..c8ac18f7ac1e 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -285,13 +285,6 @@ static int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)
 	switch (crypto_tfm_alg_type(tfm)) {
 	case CRYPTO_ALG_TYPE_CIPHER:
 		return crypto_init_cipher_ops(tfm);
-		
-	case CRYPTO_ALG_TYPE_DIGEST:
-		if ((mask & CRYPTO_ALG_TYPE_HASH_MASK) !=
-		    CRYPTO_ALG_TYPE_HASH_MASK)
-			return crypto_init_digest_ops_async(tfm);
-		else
-			return crypto_init_digest_ops(tfm);
 
 	case CRYPTO_ALG_TYPE_COMPRESS:
 		return crypto_init_compress_ops(tfm);
@@ -318,11 +311,7 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 	case CRYPTO_ALG_TYPE_CIPHER:
 		crypto_exit_cipher_ops(tfm);
 		break;
-		
-	case CRYPTO_ALG_TYPE_DIGEST:
-		crypto_exit_digest_ops(tfm);
-		break;
-		
+
 	case CRYPTO_ALG_TYPE_COMPRESS:
 		crypto_exit_compress_ops(tfm);
 		break;
@@ -349,11 +338,7 @@ static unsigned int crypto_ctxsize(struct crypto_alg *alg, u32 type, u32 mask)
 	case CRYPTO_ALG_TYPE_CIPHER:
 		len += crypto_cipher_ctxsize(alg);
 		break;
-		
-	case CRYPTO_ALG_TYPE_DIGEST:
-		len += crypto_digest_ctxsize(alg);
-		break;
-		
+
 	case CRYPTO_ALG_TYPE_COMPRESS:
 		len += crypto_compress_ctxsize(alg);
 		break;

commit d06854f0243d91badabaab14503f7f3bb770061d
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jul 8 17:53:16 2009 +0800

    crypto: api - Add crypto_attr_alg2 helper
    
    This patch adds the helper crypto_attr_alg2 which is similar to
    crypto_attr_alg but takes an extra frontend argument.  This is
    intended to be used by new style algorithm types such as shash.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index d5944f92b416..ba81221b3bef 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -503,6 +503,27 @@ void *crypto_create_tfm(struct crypto_alg *alg,
 }
 EXPORT_SYMBOL_GPL(crypto_create_tfm);
 
+struct crypto_alg *crypto_find_alg(const char *alg_name,
+				   const struct crypto_type *frontend,
+				   u32 type, u32 mask)
+{
+	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask) =
+		crypto_alg_mod_lookup;
+
+	if (frontend) {
+		type &= frontend->maskclear;
+		mask &= frontend->maskclear;
+		type |= frontend->type;
+		mask |= frontend->maskset;
+
+		if (frontend->lookup)
+			lookup = frontend->lookup;
+	}
+
+	return lookup(alg_name, type, mask);
+}
+EXPORT_SYMBOL_GPL(crypto_find_alg);
+
 /*
  *	crypto_alloc_tfm - Locate algorithm and allocate transform
  *	@alg_name: Name of algorithm
@@ -526,21 +547,13 @@ EXPORT_SYMBOL_GPL(crypto_create_tfm);
 void *crypto_alloc_tfm(const char *alg_name,
 		       const struct crypto_type *frontend, u32 type, u32 mask)
 {
-	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
 	void *tfm;
 	int err;
 
-	type &= frontend->maskclear;
-	mask &= frontend->maskclear;
-	type |= frontend->type;
-	mask |= frontend->maskset;
-
-	lookup = frontend->lookup ?: crypto_alg_mod_lookup;
-
 	for (;;) {
 		struct crypto_alg *alg;
 
-		alg = lookup(alg_name, type, mask);
+		alg = crypto_find_alg(alg_name, frontend, type, mask);
 		if (IS_ERR(alg)) {
 			err = PTR_ERR(alg);
 			goto err;

commit aa07a6990f4b6a8ef9fc538dea55bac6f92255f2
Author: Alex Riesen <raa.lkml@gmail.com>
Date:   Tue Jun 2 14:13:14 2009 +1000

    crypto: api - Use formatting of module name
    
    Besdies, for the old code, gcc-4.3.3 produced this warning:
      "format not a string literal and no format arguments"
    
    Signed-off-by: Alex Riesen <raa.lkml@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index f500fb840be9..d5944f92b416 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -217,14 +217,11 @@ struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 
 	alg = crypto_alg_lookup(name, type, mask);
 	if (!alg) {
-		char tmp[CRYPTO_MAX_ALG_NAME];
-
-		request_module(name);
+		request_module("%s", name);
 
 		if (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask &
-		      CRYPTO_ALG_NEED_FALLBACK) &&
-		    snprintf(tmp, sizeof(tmp), "%s-all", name) < sizeof(tmp))
-			request_module(tmp);
+		      CRYPTO_ALG_NEED_FALLBACK))
+			request_module("%s-all", name);
 
 		alg = crypto_alg_lookup(name, type, mask);
 	}

commit 811d8f062668077e268a7292202bb923fe2ae896
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Sun Mar 29 15:20:48 2009 +0800

    crypto: api - Use kzfree
    
    Use kzfree() instead of memset() + kfree().
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index fd2545decb28..f500fb840be9 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -580,20 +580,17 @@ EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
 void crypto_destroy_tfm(void *mem, struct crypto_tfm *tfm)
 {
 	struct crypto_alg *alg;
-	int size;
 
 	if (unlikely(!mem))
 		return;
 
 	alg = tfm->__crt_alg;
-	size = ksize(mem);
 
 	if (!tfm->exit && alg->cra_exit)
 		alg->cra_exit(tfm);
 	crypto_exit_ops(tfm);
 	crypto_mod_put(alg);
-	memset(mem, 0, size);
-	kfree(mem);
+	kzfree(mem);
 }
 EXPORT_SYMBOL_GPL(crypto_destroy_tfm);
 

commit 37fc334cc8eb84f5fe0a5a1cbe6a6a68049e142a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Apr 21 13:27:16 2009 +0800

    crypto: api - Fix algorithm module auto-loading
    
    The commit a760a6656e6f00bb0144a42a048cf0266646e22c (crypto:
    api - Fix module load deadlock with fallback algorithms) broke
    the auto-loading of algorithms that require fallbacks.  The
    problem is that the fallback mask check is missing an and which
    cauess bits that should be considered to interfere with the
    result.
    
    Reported-by: Chuck Ebbert <cebbert@redhat.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 314dab96840e..fd2545decb28 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -221,7 +221,8 @@ struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 
 		request_module(name);
 
-		if (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask) &&
+		if (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask &
+		      CRYPTO_ALG_NEED_FALLBACK) &&
 		    snprintf(tmp, sizeof(tmp), "%s-all", name) < sizeof(tmp))
 			request_module(tmp);
 

commit 562f477a54478002ddfbb5b85627c009ca41e71d
Merge: ada19a31a90b 949abe574739
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 26 11:04:34 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6: (29 commits)
      crypto: sha512-s390 - Add missing block size
      hwrng: timeriomem - Breaks an allyesconfig build on s390:
      nlattr: Fix build error with NET off
      crypto: testmgr - add zlib test
      crypto: zlib - New zlib crypto module, using pcomp
      crypto: testmgr - Add support for the pcomp interface
      crypto: compress - Add pcomp interface
      netlink: Move netlink attribute parsing support to lib
      crypto: Fix dead links
      hwrng: timeriomem - New driver
      crypto: chainiv - Use kcrypto_wq instead of keventd_wq
      crypto: cryptd - Per-CPU thread implementation based on kcrypto_wq
      crypto: api - Use dedicated workqueue for crypto subsystem
      crypto: testmgr - Test skciphers with no IVs
      crypto: aead - Avoid infinite loop when nivaead fails selftest
      crypto: skcipher - Avoid infinite loop when cipher fails selftest
      crypto: api - Fix crypto_alloc_tfm/create_create_tfm return convention
      crypto: api - crypto_alg_mod_lookup either tested or untested
      crypto: amcc - Add crypt4xx driver
      crypto: ansi_cprng - Add maintainer
      ...

commit a760a6656e6f00bb0144a42a048cf0266646e22c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Feb 26 14:06:31 2009 +0800

    crypto: api - Fix module load deadlock with fallback algorithms
    
    With the mandatory algorithm testing at registration, we have
    now created a deadlock with algorithms requiring fallbacks.
    This can happen if the module containing the algorithm requiring
    fallback is loaded first, without the fallback module being loaded
    first.  The system will then try to test the new algorithm, find
    that it needs to load a fallback, and then try to load that.
    
    As both algorithms share the same module alias, it can attempt
    to load the original algorithm again and block indefinitely.
    
    As algorithms requiring fallbacks are a special case, we can fix
    this by giving them a different module alias than the rest.  Then
    it's just a matter of using the right aliases according to what
    algorithms we're trying to find.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index efe77df6863f..38a2bc02a98c 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -215,8 +215,19 @@ struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 	mask &= ~(CRYPTO_ALG_LARVAL | CRYPTO_ALG_DEAD);
 	type &= mask;
 
-	alg = try_then_request_module(crypto_alg_lookup(name, type, mask),
-				      name);
+	alg = crypto_alg_lookup(name, type, mask);
+	if (!alg) {
+		char tmp[CRYPTO_MAX_ALG_NAME];
+
+		request_module(name);
+
+		if (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask) &&
+		    snprintf(tmp, sizeof(tmp), "%s-all", name) < sizeof(tmp))
+			request_module(tmp);
+
+		alg = crypto_alg_lookup(name, type, mask);
+	}
+
 	if (alg)
 		return crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;
 

commit 3f683d6175748ef9daf4698d9ef5a488dd037063
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Feb 18 16:56:59 2009 +0800

    crypto: api - Fix crypto_alloc_tfm/create_create_tfm return convention
    
    This is based on a report and patch by Geert Uytterhoeven.
    
    The functions crypto_alloc_tfm and create_create_tfm return a
    pointer that needs to be adjusted by the caller when successful
    and otherwise an error value.  This means that the caller has
    to check for the error and only perform the adjustment if the
    pointer returned is valid.
    
    Since all callers want to make the adjustment and we know how
    to adjust it ourselves, it's much easier to just return adjusted
    pointer directly.
    
    The only caveat is that we have to return a void * instead of
    struct crypto_tfm *.  However, this isn't that bad because both
    of these functions are for internal use only (by types code like
    shash.c, not even algorithms code).
    
    This patch also moves crypto_alloc_tfm into crypto/internal.h
    (crypto_create_tfm is already there) to reflect this.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 56b6e0e66311..22385cac90bb 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -453,8 +453,8 @@ struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
 }
 EXPORT_SYMBOL_GPL(crypto_alloc_base);
 
-struct crypto_tfm *crypto_create_tfm(struct crypto_alg *alg,
-				     const struct crypto_type *frontend)
+void *crypto_create_tfm(struct crypto_alg *alg,
+			const struct crypto_type *frontend)
 {
 	char *mem;
 	struct crypto_tfm *tfm = NULL;
@@ -488,9 +488,9 @@ struct crypto_tfm *crypto_create_tfm(struct crypto_alg *alg,
 		crypto_shoot_alg(alg);
 	kfree(mem);
 out_err:
-	tfm = ERR_PTR(err);
+	mem = ERR_PTR(err);
 out:
-	return tfm;
+	return mem;
 }
 EXPORT_SYMBOL_GPL(crypto_create_tfm);
 
@@ -514,12 +514,11 @@ EXPORT_SYMBOL_GPL(crypto_create_tfm);
  *
  *	In case of error the return value is an error pointer.
  */
-struct crypto_tfm *crypto_alloc_tfm(const char *alg_name,
-				    const struct crypto_type *frontend,
-				    u32 type, u32 mask)
+void *crypto_alloc_tfm(const char *alg_name,
+		       const struct crypto_type *frontend, u32 type, u32 mask)
 {
 	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
-	struct crypto_tfm *tfm;
+	void *tfm;
 	int err;
 
 	type &= frontend->maskclear;

commit ff753308d2f70f210ba468492cd9a01274d9d7ce
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Feb 17 20:18:34 2009 +0800

    crypto: api - crypto_alg_mod_lookup either tested or untested
    
    As it stands crypto_alg_mod_lookup will search either tested or
    untested algorithms, but never both at the same time.  However,
    we need exactly that when constructing givcipher and aead so
    this patch adds support for that by setting the tested bit in
    type but clearing it in mask.  This combination is currently
    unused.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index efe77df6863f..56b6e0e66311 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -244,7 +244,7 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 	struct crypto_alg *larval;
 	int ok;
 
-	if (!(mask & CRYPTO_ALG_TESTED)) {
+	if (!((type | mask) & CRYPTO_ALG_TESTED)) {
 		type |= CRYPTO_ALG_TESTED;
 		mask |= CRYPTO_ALG_TESTED;
 	}

commit 7b2cd92adc5430b0c1adeb120971852b4ea1ab08
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Feb 5 16:48:24 2009 +1100

    crypto: api - Fix zeroing on free
    
    Geert Uytterhoeven pointed out that we're not zeroing all the
    memory when freeing a transform.  This patch fixes it by calling
    ksize to ensure that we zero everything in sight.
    
    Reported-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 9975a7bd246c..efe77df6863f 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -557,34 +557,34 @@ struct crypto_tfm *crypto_alloc_tfm(const char *alg_name,
 	return ERR_PTR(err);
 }
 EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
- 
+
 /*
- *	crypto_free_tfm - Free crypto transform
+ *	crypto_destroy_tfm - Free crypto transform
+ *	@mem: Start of tfm slab
  *	@tfm: Transform to free
  *
- *	crypto_free_tfm() frees up the transform and any associated resources,
+ *	This function frees up the transform and any associated resources,
  *	then drops the refcount on the associated algorithm.
  */
-void crypto_free_tfm(struct crypto_tfm *tfm)
+void crypto_destroy_tfm(void *mem, struct crypto_tfm *tfm)
 {
 	struct crypto_alg *alg;
 	int size;
 
-	if (unlikely(!tfm))
+	if (unlikely(!mem))
 		return;
 
 	alg = tfm->__crt_alg;
-	size = sizeof(*tfm) + alg->cra_ctxsize;
+	size = ksize(mem);
 
 	if (!tfm->exit && alg->cra_exit)
 		alg->cra_exit(tfm);
 	crypto_exit_ops(tfm);
 	crypto_mod_put(alg);
-	memset(tfm, 0, size);
-	kfree(tfm);
+	memset(mem, 0, size);
+	kfree(mem);
 }
-
-EXPORT_SYMBOL_GPL(crypto_free_tfm);
+EXPORT_SYMBOL_GPL(crypto_destroy_tfm);
 
 int crypto_has_alg(const char *name, u32 type, u32 mask)
 {

commit 7b0bac64cd5b74d6f1147524c26216de13a501fd
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Sep 21 06:52:53 2008 +0900

    crypto: api - Rebirth of crypto_alloc_tfm
    
    This patch reintroduces a completely revamped crypto_alloc_tfm.
    The biggest change is that we now take two crypto_type objects
    when allocating a tfm, a frontend and a backend.  In fact this
    simply formalises what we've been doing behind the API's back.
    
    For example, as it stands crypto_alloc_ahash may use an
    actual ahash algorithm or a crypto_hash algorithm.  Putting
    this in the API allows us to do this much more cleanly.
    
    The existing types will be converted across gradually.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index cbaaf346ad13..9975a7bd246c 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -403,6 +403,9 @@ EXPORT_SYMBOL_GPL(__crypto_alloc_tfm);
  *	@type: Type of algorithm
  *	@mask: Mask for type comparison
  *
+ *	This function should not be used by new algorithm types.
+ *	Plesae use crypto_alloc_tfm instead.
+ *
  *	crypto_alloc_base() will first attempt to locate an already loaded
  *	algorithm.  If that fails and the kernel supports dynamically loadable
  *	modules, it will then attempt to load a module of the same name or
@@ -449,6 +452,111 @@ struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
 	return ERR_PTR(err);
 }
 EXPORT_SYMBOL_GPL(crypto_alloc_base);
+
+struct crypto_tfm *crypto_create_tfm(struct crypto_alg *alg,
+				     const struct crypto_type *frontend)
+{
+	char *mem;
+	struct crypto_tfm *tfm = NULL;
+	unsigned int tfmsize;
+	unsigned int total;
+	int err = -ENOMEM;
+
+	tfmsize = frontend->tfmsize;
+	total = tfmsize + sizeof(*tfm) + frontend->extsize(alg, frontend);
+
+	mem = kzalloc(total, GFP_KERNEL);
+	if (mem == NULL)
+		goto out_err;
+
+	tfm = (struct crypto_tfm *)(mem + tfmsize);
+	tfm->__crt_alg = alg;
+
+	err = frontend->init_tfm(tfm, frontend);
+	if (err)
+		goto out_free_tfm;
+
+	if (!tfm->exit && alg->cra_init && (err = alg->cra_init(tfm)))
+		goto cra_init_failed;
+
+	goto out;
+
+cra_init_failed:
+	crypto_exit_ops(tfm);
+out_free_tfm:
+	if (err == -EAGAIN)
+		crypto_shoot_alg(alg);
+	kfree(mem);
+out_err:
+	tfm = ERR_PTR(err);
+out:
+	return tfm;
+}
+EXPORT_SYMBOL_GPL(crypto_create_tfm);
+
+/*
+ *	crypto_alloc_tfm - Locate algorithm and allocate transform
+ *	@alg_name: Name of algorithm
+ *	@frontend: Frontend algorithm type
+ *	@type: Type of algorithm
+ *	@mask: Mask for type comparison
+ *
+ *	crypto_alloc_tfm() will first attempt to locate an already loaded
+ *	algorithm.  If that fails and the kernel supports dynamically loadable
+ *	modules, it will then attempt to load a module of the same name or
+ *	alias.  If that fails it will send a query to any loaded crypto manager
+ *	to construct an algorithm on the fly.  A refcount is grabbed on the
+ *	algorithm which is then associated with the new transform.
+ *
+ *	The returned transform is of a non-determinate type.  Most people
+ *	should use one of the more specific allocation functions such as
+ *	crypto_alloc_blkcipher.
+ *
+ *	In case of error the return value is an error pointer.
+ */
+struct crypto_tfm *crypto_alloc_tfm(const char *alg_name,
+				    const struct crypto_type *frontend,
+				    u32 type, u32 mask)
+{
+	struct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask);
+	struct crypto_tfm *tfm;
+	int err;
+
+	type &= frontend->maskclear;
+	mask &= frontend->maskclear;
+	type |= frontend->type;
+	mask |= frontend->maskset;
+
+	lookup = frontend->lookup ?: crypto_alg_mod_lookup;
+
+	for (;;) {
+		struct crypto_alg *alg;
+
+		alg = lookup(alg_name, type, mask);
+		if (IS_ERR(alg)) {
+			err = PTR_ERR(alg);
+			goto err;
+		}
+
+		tfm = crypto_create_tfm(alg, frontend);
+		if (!IS_ERR(tfm))
+			return tfm;
+
+		crypto_mod_put(alg);
+		err = PTR_ERR(tfm);
+
+err:
+		if (err != -EAGAIN)
+			break;
+		if (signal_pending(current)) {
+			err = -EINTR;
+			break;
+		}
+	}
+
+	return ERR_PTR(err);
+}
+EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
  
 /*
  *	crypto_free_tfm - Free crypto transform

commit 4a7794860ba2b56693b1d89fd485fd08cdc763e3
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Sep 13 18:19:03 2008 -0700

    crypto: api - Move type exit function into crypto_tfm
    
    The type exit function needs to undo any allocations done by the type
    init function.  However, the type init function may differ depending
    on the upper-level type of the transform (e.g., a crypto_blkcipher
    instantiated as a crypto_ablkcipher).
    
    So we need to move the exit function out of the lower-level
    structure and into crypto_tfm itself.
    
    As it stands this is a no-op since nobody uses exit functions at
    all.  However, all cases where a lower-level type is instantiated
    as a different upper-level type (such as blkcipher as ablkcipher)
    will be converted such that they allocate the underlying transform
    and use that instead of casting (e.g., crypto_ablkcipher casted
    into crypto_blkcipher).  That will need to use a different exit
    function depending on the upper-level type.
    
    This patch also allows the type init/exit functions to call (or not)
    cra_init/cra_exit instead of always calling them from the top level.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 0444d242e985..cbaaf346ad13 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -300,8 +300,8 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 	const struct crypto_type *type = tfm->__crt_alg->cra_type;
 
 	if (type) {
-		if (type->exit)
-			type->exit(tfm);
+		if (tfm->exit)
+			tfm->exit(tfm);
 		return;
 	}
 
@@ -379,17 +379,16 @@ struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 type,
 	if (err)
 		goto out_free_tfm;
 
-	if (alg->cra_init && (err = alg->cra_init(tfm))) {
-		if (err == -EAGAIN)
-			crypto_shoot_alg(alg);
+	if (!tfm->exit && alg->cra_init && (err = alg->cra_init(tfm)))
 		goto cra_init_failed;
-	}
 
 	goto out;
 
 cra_init_failed:
 	crypto_exit_ops(tfm);
 out_free_tfm:
+	if (err == -EAGAIN)
+		crypto_shoot_alg(alg);
 	kfree(tfm);
 out_err:
 	tfm = ERR_PTR(err);
@@ -469,7 +468,7 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 	alg = tfm->__crt_alg;
 	size = sizeof(*tfm) + alg->cra_ctxsize;
 
-	if (alg->cra_exit)
+	if (!tfm->exit && alg->cra_exit)
 		alg->cra_exit(tfm);
 	crypto_exit_ops(tfm);
 	crypto_mod_put(alg);

commit 73d3864a4823abda19ebc4387b6ddcbf416e3a77
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 3 21:15:23 2008 +0800

    crypto: api - Use test infrastructure
    
    This patch makes use of the new testing infrastructure by requiring
    algorithms to pass a run-time test before they're made available to
    users.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 0906cedd4521..0444d242e985 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -55,6 +55,11 @@ void crypto_mod_put(struct crypto_alg *alg)
 }
 EXPORT_SYMBOL_GPL(crypto_mod_put);
 
+static inline int crypto_is_test_larval(struct crypto_larval *larval)
+{
+	return larval->alg.cra_driver_name[0];
+}
+
 static struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type,
 					      u32 mask)
 {
@@ -71,6 +76,7 @@ static struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type,
 			continue;
 
 		if (crypto_is_larval(q) &&
+		    !crypto_is_test_larval((struct crypto_larval *)q) &&
 		    ((struct crypto_larval *)q)->mask != mask)
 			continue;
 
@@ -104,10 +110,8 @@ static void crypto_larval_destroy(struct crypto_alg *alg)
 	kfree(larval);
 }
 
-static struct crypto_alg *crypto_larval_alloc(const char *name, u32 type,
-					      u32 mask)
+struct crypto_larval *crypto_larval_alloc(const char *name, u32 type, u32 mask)
 {
-	struct crypto_alg *alg;
 	struct crypto_larval *larval;
 
 	larval = kzalloc(sizeof(*larval), GFP_KERNEL);
@@ -119,10 +123,25 @@ static struct crypto_alg *crypto_larval_alloc(const char *name, u32 type,
 	larval->alg.cra_priority = -1;
 	larval->alg.cra_destroy = crypto_larval_destroy;
 
-	atomic_set(&larval->alg.cra_refcnt, 2);
 	strlcpy(larval->alg.cra_name, name, CRYPTO_MAX_ALG_NAME);
 	init_completion(&larval->completion);
 
+	return larval;
+}
+EXPORT_SYMBOL_GPL(crypto_larval_alloc);
+
+static struct crypto_alg *crypto_larval_add(const char *name, u32 type,
+					    u32 mask)
+{
+	struct crypto_alg *alg;
+	struct crypto_larval *larval;
+
+	larval = crypto_larval_alloc(name, type, mask);
+	if (IS_ERR(larval))
+		return ERR_CAST(larval);
+
+	atomic_set(&larval->alg.cra_refcnt, 2);
+
 	down_write(&crypto_alg_sem);
 	alg = __crypto_alg_lookup(name, type, mask);
 	if (!alg) {
@@ -152,14 +171,23 @@ EXPORT_SYMBOL_GPL(crypto_larval_kill);
 static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 {
 	struct crypto_larval *larval = (void *)alg;
+	long timeout;
+
+	timeout = wait_for_completion_interruptible_timeout(
+		&larval->completion, 60 * HZ);
 
-	wait_for_completion_interruptible_timeout(&larval->completion, 60 * HZ);
 	alg = larval->adult;
-	if (alg) {
-		if (!crypto_mod_get(alg))
-			alg = ERR_PTR(-EAGAIN);
-	} else
+	if (timeout < 0)
+		alg = ERR_PTR(-EINTR);
+	else if (!timeout)
+		alg = ERR_PTR(-ETIMEDOUT);
+	else if (!alg)
 		alg = ERR_PTR(-ENOENT);
+	else if (crypto_is_test_larval(larval) &&
+		 !(alg->cra_flags & CRYPTO_ALG_TESTED))
+		alg = ERR_PTR(-EAGAIN);
+	else if (!crypto_mod_get(alg))
+		alg = ERR_PTR(-EAGAIN);
 	crypto_mod_put(&larval->alg);
 
 	return alg;
@@ -192,25 +220,40 @@ struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 	if (alg)
 		return crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;
 
-	return crypto_larval_alloc(name, type, mask);
+	return crypto_larval_add(name, type, mask);
 }
 EXPORT_SYMBOL_GPL(crypto_larval_lookup);
 
+int crypto_probing_notify(unsigned long val, void *v)
+{
+	int ok;
+
+	ok = blocking_notifier_call_chain(&crypto_chain, val, v);
+	if (ok == NOTIFY_DONE) {
+		request_module("cryptomgr");
+		ok = blocking_notifier_call_chain(&crypto_chain, val, v);
+	}
+
+	return ok;
+}
+EXPORT_SYMBOL_GPL(crypto_probing_notify);
+
 struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 {
 	struct crypto_alg *alg;
 	struct crypto_alg *larval;
 	int ok;
 
+	if (!(mask & CRYPTO_ALG_TESTED)) {
+		type |= CRYPTO_ALG_TESTED;
+		mask |= CRYPTO_ALG_TESTED;
+	}
+
 	larval = crypto_larval_lookup(name, type, mask);
 	if (IS_ERR(larval) || !crypto_is_larval(larval))
 		return larval;
 
-	ok = crypto_notify(CRYPTO_MSG_ALG_REQUEST, larval);
-	if (ok == NOTIFY_DONE) {
-		request_module("cryptomgr");
-		ok = crypto_notify(CRYPTO_MSG_ALG_REQUEST, larval);
-	}
+	ok = crypto_probing_notify(CRYPTO_MSG_ALG_REQUEST, larval);
 
 	if (ok == NOTIFY_STOP)
 		alg = crypto_larval_wait(larval);

commit c51b6c8102a82239163c8c04e404c7cc2857b4be
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Aug 4 11:44:59 2008 +0800

    crypto: api - Export crypto_alg_lookup instead of __crypto_alg_lookup
    
    Since the only user of __crypto_alg_lookup is doing exactly what
    crypto_alg_lookup does, we can now the latter in lieu of the former.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index d06e33270abe..0906cedd4521 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -55,7 +55,8 @@ void crypto_mod_put(struct crypto_alg *alg)
 }
 EXPORT_SYMBOL_GPL(crypto_mod_put);
 
-struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type, u32 mask)
+static struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type,
+					      u32 mask)
 {
 	struct crypto_alg *q, *alg = NULL;
 	int best = -2;
@@ -92,7 +93,6 @@ struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type, u32 mask)
 
 	return alg;
 }
-EXPORT_SYMBOL_GPL(__crypto_alg_lookup);
 
 static void crypto_larval_destroy(struct crypto_alg *alg)
 {
@@ -165,8 +165,7 @@ static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 	return alg;
 }
 
-static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
-					    u32 mask)
+struct crypto_alg *crypto_alg_lookup(const char *name, u32 type, u32 mask)
 {
 	struct crypto_alg *alg;
 
@@ -176,6 +175,7 @@ static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
 
 	return alg;
 }
+EXPORT_SYMBOL_GPL(crypto_alg_lookup);
 
 struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 {

commit 004a403c2e954734090a69aedc7f4f822bdcc142
Author: Loc Ho <lho@amcc.com>
Date:   Wed May 14 20:41:47 2008 +0800

    [CRYPTO] hash: Add asynchronous hash support
    
    This patch adds asynchronous hash and digest support.
    
    Signed-off-by: Loc Ho <lho@amcc.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 0a0f41ef255f..d06e33270abe 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -235,8 +235,12 @@ static int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)
 		return crypto_init_cipher_ops(tfm);
 		
 	case CRYPTO_ALG_TYPE_DIGEST:
-		return crypto_init_digest_ops(tfm);
-		
+		if ((mask & CRYPTO_ALG_TYPE_HASH_MASK) !=
+		    CRYPTO_ALG_TYPE_HASH_MASK)
+			return crypto_init_digest_ops_async(tfm);
+		else
+			return crypto_init_digest_ops(tfm);
+
 	case CRYPTO_ALG_TYPE_COMPRESS:
 		return crypto_init_compress_ops(tfm);
 	

commit c3715cb90f722b1cf5f6f073be02cc8a49659b90
Author: Sebastian Siewior <sebastian@breakpoint.cc>
Date:   Sun Mar 30 16:36:09 2008 +0800

    [CRYPTO] api: Make the crypto subsystem fully modular
    
    Signed-off-by: Sebastian Siewior <sebastian@breakpoint.cc>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index a2496d1bc6d4..0a0f41ef255f 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -445,3 +445,6 @@ int crypto_has_alg(const char *name, u32 type, u32 mask)
 	return ret;
 }
 EXPORT_SYMBOL_GPL(crypto_has_alg);
+
+MODULE_DESCRIPTION("Cryptographic core API");
+MODULE_LICENSE("GPL");

commit b9c55aa475599183d0eab6833ea23e70c52dd24b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Dec 4 12:46:48 2007 +1100

    [CRYPTO] skcipher: Create default givcipher instances
    
    This patch makes crypto_alloc_ablkcipher/crypto_grab_skcipher always
    return algorithms that are capable of generating their own IVs through
    givencrypt and givdecrypt.  Each algorithm may specify its default IV
    generator through the geniv field.
    
    For algorithms that do not set the geniv field, the blkcipher layer will
    pick a default.  Currently it's chainiv for synchronous algorithms and
    eseqiv for asynchronous algorithms.  Note that if these wrappers do not
    work on an algorithm then that algorithm must specify its own geniv or
    it can't be used at all.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 1f5c72477356..a2496d1bc6d4 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -137,7 +137,7 @@ static struct crypto_alg *crypto_larval_alloc(const char *name, u32 type,
 	return alg;
 }
 
-static void crypto_larval_kill(struct crypto_alg *alg)
+void crypto_larval_kill(struct crypto_alg *alg)
 {
 	struct crypto_larval *larval = (void *)alg;
 
@@ -147,6 +147,7 @@ static void crypto_larval_kill(struct crypto_alg *alg)
 	complete_all(&larval->completion);
 	crypto_alg_put(alg);
 }
+EXPORT_SYMBOL_GPL(crypto_larval_kill);
 
 static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 {
@@ -176,11 +177,9 @@ static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
 	return alg;
 }
 
-struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
+struct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)
 {
 	struct crypto_alg *alg;
-	struct crypto_alg *larval;
-	int ok;
 
 	if (!name)
 		return ERR_PTR(-ENOENT);
@@ -193,7 +192,17 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 	if (alg)
 		return crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;
 
-	larval = crypto_larval_alloc(name, type, mask);
+	return crypto_larval_alloc(name, type, mask);
+}
+EXPORT_SYMBOL_GPL(crypto_larval_lookup);
+
+struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
+{
+	struct crypto_alg *alg;
+	struct crypto_alg *larval;
+	int ok;
+
+	larval = crypto_larval_lookup(name, type, mask);
 	if (IS_ERR(larval) || !crypto_is_larval(larval))
 		return larval;
 

commit 991d17403c24421614ca74d2a1cae8878f3097c9
Author: John Anthony Kazos Jr <jakj@j-a-k-j.com>
Date:   Fri Oct 19 23:06:17 2007 +0200

    crypto: convert "crypto" subdirectory to UTF-8
    
    Convert the subdirectory "crypto" to UTF-8. The files changed are
    <crypto/fcrypt.c> and <crypto/api.c>.
    
    Signed-off-by: John Anthony Kazos Jr. <jakj@j-a-k-j.com>
    Signed-off-by: Adrian Bunk <bunk@kernel.org>

diff --git a/crypto/api.c b/crypto/api.c
index 4ccc5af6c265..1f5c72477356 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -6,7 +6,7 @@
  * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>
  *
  * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>
- * and Nettle, by Niels Möller.
+ * and Nettle, by Niels MÃ¶ller.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License as published by the Free

commit fe3c5206adc5d7395828185ab73e9a522655b984
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat May 19 17:51:40 2007 +1000

    [CRYPTO] api: Wake up all waiters when larval completes
    
    Right now when a larval matures or when it dies of an error we
    only wake up one waiter.  This would cause other waiters to timeout
    unnecessarily.  This patch changes it to use complete_all to wake
    up all waiters.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 33734fd9198f..4ccc5af6c265 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -144,7 +144,7 @@ static void crypto_larval_kill(struct crypto_alg *alg)
 	down_write(&crypto_alg_sem);
 	list_del(&alg->cra_list);
 	up_write(&crypto_alg_sem);
-	complete(&larval->completion);
+	complete_all(&larval->completion);
 	crypto_alg_put(alg);
 }
 

commit da7cd59ab9c8ed233df4809f6c8c90c636f676c7
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat May 19 14:51:00 2007 +1000

    [CRYPTO] api: Read module pointer before freeing algorithm
    
    The function crypto_mod_put first frees the algorithm and then drops
    the reference to its module.  Unfortunately we read the module pointer
    which after freeing the algorithm and that pointer sits inside the
    object that we just freed.
    
    So this patch reads the module pointer out before we free the object.
    
    Thanks to Luca Tettamanti for reporting this.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 55af8bb0f050..33734fd9198f 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -48,8 +48,10 @@ EXPORT_SYMBOL_GPL(crypto_mod_get);
 
 void crypto_mod_put(struct crypto_alg *alg)
 {
+	struct module *module = alg->cra_module;
+
 	crypto_alg_put(alg);
-	module_put(alg->cra_module);
+	module_put(module);
 }
 EXPORT_SYMBOL_GPL(crypto_mod_put);
 

commit 27d2a3300755387d2fec231d37944907ff992ce8
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jan 24 20:50:26 2007 +1100

    [CRYPTO] api: Allow multiple frontends per backend
    
    This patch adds support for multiple frontend types for each backend
    algorithm by passing the type and mask through to the backend type
    init function.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 8b80baec853a..55af8bb0f050 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -212,12 +212,12 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 }
 EXPORT_SYMBOL_GPL(crypto_alg_mod_lookup);
 
-static int crypto_init_ops(struct crypto_tfm *tfm)
+static int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)
 {
-	const struct crypto_type *type = tfm->__crt_alg->cra_type;
+	const struct crypto_type *type_obj = tfm->__crt_alg->cra_type;
 
-	if (type)
-		return type->init(tfm);
+	if (type_obj)
+		return type_obj->init(tfm, type, mask);
 
 	switch (crypto_tfm_alg_type(tfm)) {
 	case CRYPTO_ALG_TYPE_CIPHER:
@@ -266,14 +266,14 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 	}
 }
 
-static unsigned int crypto_ctxsize(struct crypto_alg *alg)
+static unsigned int crypto_ctxsize(struct crypto_alg *alg, u32 type, u32 mask)
 {
-	const struct crypto_type *type = alg->cra_type;
+	const struct crypto_type *type_obj = alg->cra_type;
 	unsigned int len;
 
 	len = alg->cra_alignmask & ~(crypto_tfm_ctx_alignment() - 1);
-	if (type)
-		return len + type->ctxsize(alg);
+	if (type_obj)
+		return len + type_obj->ctxsize(alg, type, mask);
 
 	switch (alg->cra_flags & CRYPTO_ALG_TYPE_MASK) {
 	default:
@@ -303,20 +303,21 @@ void crypto_shoot_alg(struct crypto_alg *alg)
 }
 EXPORT_SYMBOL_GPL(crypto_shoot_alg);
 
-struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg)
+struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 type,
+				      u32 mask)
 {
 	struct crypto_tfm *tfm = NULL;
 	unsigned int tfm_size;
 	int err = -ENOMEM;
 
-	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg);
+	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg, type, mask);
 	tfm = kzalloc(tfm_size, GFP_KERNEL);
 	if (tfm == NULL)
 		goto out_err;
 
 	tfm->__crt_alg = alg;
 
-	err = crypto_init_ops(tfm);
+	err = crypto_init_ops(tfm, type, mask);
 	if (err)
 		goto out_free_tfm;
 
@@ -372,7 +373,7 @@ struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
 			goto err;
 		}
 
-		tfm = __crypto_alloc_tfm(alg);
+		tfm = __crypto_alloc_tfm(alg, type, mask);
 		if (!IS_ERR(tfm))
 			return tfm;
 

commit f1ddcaf3393b7a3871809b97fae90fac841a1f39
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Jan 27 10:05:15 2007 +1100

    [CRYPTO] api: Remove deprecated interface
    
    This patch removes the old cipher interface and related code.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 8c446871cd5b..8b80baec853a 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -212,25 +212,6 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 }
 EXPORT_SYMBOL_GPL(crypto_alg_mod_lookup);
 
-static int crypto_init_flags(struct crypto_tfm *tfm, u32 flags)
-{
-	tfm->crt_flags = flags & CRYPTO_TFM_REQ_MASK;
-	flags &= ~CRYPTO_TFM_REQ_MASK;
-	
-	switch (crypto_tfm_alg_type(tfm)) {
-	case CRYPTO_ALG_TYPE_CIPHER:
-		return crypto_init_cipher_flags(tfm, flags);
-		
-	case CRYPTO_ALG_TYPE_DIGEST:
-		return crypto_init_digest_flags(tfm, flags);
-		
-	case CRYPTO_ALG_TYPE_COMPRESS:
-		return crypto_init_compress_flags(tfm, flags);
-	}
-	
-	return 0;
-}
-
 static int crypto_init_ops(struct crypto_tfm *tfm)
 {
 	const struct crypto_type *type = tfm->__crt_alg->cra_type;
@@ -285,7 +266,7 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 	}
 }
 
-static unsigned int crypto_ctxsize(struct crypto_alg *alg, int flags)
+static unsigned int crypto_ctxsize(struct crypto_alg *alg)
 {
 	const struct crypto_type *type = alg->cra_type;
 	unsigned int len;
@@ -299,15 +280,15 @@ static unsigned int crypto_ctxsize(struct crypto_alg *alg, int flags)
 		BUG();
 
 	case CRYPTO_ALG_TYPE_CIPHER:
-		len += crypto_cipher_ctxsize(alg, flags);
+		len += crypto_cipher_ctxsize(alg);
 		break;
 		
 	case CRYPTO_ALG_TYPE_DIGEST:
-		len += crypto_digest_ctxsize(alg, flags);
+		len += crypto_digest_ctxsize(alg);
 		break;
 		
 	case CRYPTO_ALG_TYPE_COMPRESS:
-		len += crypto_compress_ctxsize(alg, flags);
+		len += crypto_compress_ctxsize(alg);
 		break;
 	}
 
@@ -322,23 +303,19 @@ void crypto_shoot_alg(struct crypto_alg *alg)
 }
 EXPORT_SYMBOL_GPL(crypto_shoot_alg);
 
-struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 flags)
+struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg)
 {
 	struct crypto_tfm *tfm = NULL;
 	unsigned int tfm_size;
 	int err = -ENOMEM;
 
-	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg, flags);
+	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg);
 	tfm = kzalloc(tfm_size, GFP_KERNEL);
 	if (tfm == NULL)
 		goto out_err;
 
 	tfm->__crt_alg = alg;
 
-	err = crypto_init_flags(tfm, flags);
-	if (err)
-		goto out_free_tfm;
-		
 	err = crypto_init_ops(tfm);
 	if (err)
 		goto out_free_tfm;
@@ -362,31 +339,6 @@ struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 flags)
 }
 EXPORT_SYMBOL_GPL(__crypto_alloc_tfm);
 
-struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
-{
-	struct crypto_tfm *tfm = NULL;
-	int err;
-
-	do {
-		struct crypto_alg *alg;
-
-		alg = crypto_alg_mod_lookup(name, 0, CRYPTO_ALG_ASYNC);
-		err = PTR_ERR(alg);
-		if (IS_ERR(alg))
-			continue;
-
-		tfm = __crypto_alloc_tfm(alg, flags);
-		err = 0;
-		if (IS_ERR(tfm)) {
-			crypto_mod_put(alg);
-			err = PTR_ERR(tfm);
-			tfm = NULL;
-		}
-	} while (err == -EAGAIN && !signal_pending(current));
-
-	return tfm;
-}
-
 /*
  *	crypto_alloc_base - Locate algorithm and allocate transform
  *	@alg_name: Name of algorithm
@@ -420,7 +372,7 @@ struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
 			goto err;
 		}
 
-		tfm = __crypto_alloc_tfm(alg, 0);
+		tfm = __crypto_alloc_tfm(alg);
 		if (!IS_ERR(tfm))
 			return tfm;
 
@@ -466,7 +418,6 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 	kfree(tfm);
 }
 
-EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
 EXPORT_SYMBOL_GPL(crypto_free_tfm);
 
 int crypto_has_alg(const char *name, u32 type, u32 mask)

commit cc44215eaaa5e4032946b962353526ae6c370c0e
Author: Adrian Bunk <bunk@stusta.de>
Date:   Wed Nov 22 17:55:00 2006 +1100

    [CRYPTO] api: Remove unused functions
    
    This patch removes the following no longer used functions:
    - api.c: crypto_alg_available()
    - digest.c: crypto_digest_init()
    - digest.c: crypto_digest_update()
    - digest.c: crypto_digest_final()
    - digest.c: crypto_digest_digest()
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 4fb7fa45cb0d..8c446871cd5b 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -466,23 +466,8 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 	kfree(tfm);
 }
 
-int crypto_alg_available(const char *name, u32 flags)
-{
-	int ret = 0;
-	struct crypto_alg *alg = crypto_alg_mod_lookup(name, 0,
-						       CRYPTO_ALG_ASYNC);
-	
-	if (!IS_ERR(alg)) {
-		crypto_mod_put(alg);
-		ret = 1;
-	}
-	
-	return ret;
-}
-
 EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
 EXPORT_SYMBOL_GPL(crypto_free_tfm);
-EXPORT_SYMBOL_GPL(crypto_alg_available);
 
 int crypto_has_alg(const char *name, u32 type, u32 mask)
 {

commit 9765d262b8230b735c4b2815b041c09a00833cf1
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Wed Oct 11 22:29:51 2006 +1000

    [CRYPTO] api: fix crypto_alloc_base() return value
    
    This patch makes crypto_alloc_base() return proper return value.
    
    - If kzalloc() failure happens within __crypto_alloc_tfm(),
      crypto_alloc_base() returns NULL. But crypto_alloc_base()
      is supposed to return error code as pointer. So this patch
      makes it return -ENOMEM in that case.
    
    - crypto_alloc_base() is suppose to return -EINTR, if it is
      interrupted by signal. But it may not return -EINTR.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 2e84d4b54790..4fb7fa45cb0d 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -331,7 +331,7 @@ struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 flags)
 	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg, flags);
 	tfm = kzalloc(tfm_size, GFP_KERNEL);
 	if (tfm == NULL)
-		goto out;
+		goto out_err;
 
 	tfm->__crt_alg = alg;
 
@@ -355,6 +355,7 @@ struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 flags)
 	crypto_exit_ops(tfm);
 out_free_tfm:
 	kfree(tfm);
+out_err:
 	tfm = ERR_PTR(err);
 out:
 	return tfm;
@@ -414,14 +415,14 @@ struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
 		struct crypto_alg *alg;
 
 		alg = crypto_alg_mod_lookup(alg_name, type, mask);
-		err = PTR_ERR(alg);
-		tfm = ERR_PTR(err);
-		if (IS_ERR(alg))
+		if (IS_ERR(alg)) {
+			err = PTR_ERR(alg);
 			goto err;
+		}
 
 		tfm = __crypto_alloc_tfm(alg, 0);
 		if (!IS_ERR(tfm))
-			break;
+			return tfm;
 
 		crypto_mod_put(alg);
 		err = PTR_ERR(tfm);
@@ -433,9 +434,9 @@ struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
 			err = -EINTR;
 			break;
 		}
-	};
+	}
 
-	return tfm;
+	return ERR_PTR(err);
 }
 EXPORT_SYMBOL_GPL(crypto_alloc_base);
  

commit fce32d70ba834129b164c40c2d4260e5a7a7d850
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Aug 26 17:35:45 2006 +1000

    [CRYPTO] api: Add crypto_comp and crypto_has_*
    
    This patch adds the crypto_comp type to complete the compile-time checking
    conversion.  The functions crypto_has_alg and crypto_has_cipher, etc. are
    also added to replace crypto_alg_available.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index edaa843d8e83..2e84d4b54790 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -482,3 +482,17 @@ int crypto_alg_available(const char *name, u32 flags)
 EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
 EXPORT_SYMBOL_GPL(crypto_free_tfm);
 EXPORT_SYMBOL_GPL(crypto_alg_available);
+
+int crypto_has_alg(const char *name, u32 type, u32 mask)
+{
+	int ret = 0;
+	struct crypto_alg *alg = crypto_alg_mod_lookup(name, type, mask);
+	
+	if (!IS_ERR(alg)) {
+		crypto_mod_put(alg);
+		ret = 1;
+	}
+	
+	return ret;
+}
+EXPORT_SYMBOL_GPL(crypto_has_alg);

commit e853c3cfa8cc24869ecd2526e589bcb176bc12e9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Aug 22 00:06:54 2006 +1000

    [CRYPTO] api: Added crypto_type support
    
    This patch adds the crypto_type structure which will be used for all new
    crypto algorithm types, beginning with block ciphers.
    
    The primary purpose of this abstraction is to allow different crypto_type
    objects for crypto algorithms of the same type, in particular, there will
    be a different crypto_type objects for asynchronous algorithms.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index bc4b7901acdf..edaa843d8e83 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -226,17 +226,18 @@ static int crypto_init_flags(struct crypto_tfm *tfm, u32 flags)
 		
 	case CRYPTO_ALG_TYPE_COMPRESS:
 		return crypto_init_compress_flags(tfm, flags);
-	
-	default:
-		break;
 	}
 	
-	BUG();
-	return -EINVAL;
+	return 0;
 }
 
 static int crypto_init_ops(struct crypto_tfm *tfm)
 {
+	const struct crypto_type *type = tfm->__crt_alg->cra_type;
+
+	if (type)
+		return type->init(tfm);
+
 	switch (crypto_tfm_alg_type(tfm)) {
 	case CRYPTO_ALG_TYPE_CIPHER:
 		return crypto_init_cipher_ops(tfm);
@@ -257,6 +258,14 @@ static int crypto_init_ops(struct crypto_tfm *tfm)
 
 static void crypto_exit_ops(struct crypto_tfm *tfm)
 {
+	const struct crypto_type *type = tfm->__crt_alg->cra_type;
+
+	if (type) {
+		if (type->exit)
+			type->exit(tfm);
+		return;
+	}
+
 	switch (crypto_tfm_alg_type(tfm)) {
 	case CRYPTO_ALG_TYPE_CIPHER:
 		crypto_exit_cipher_ops(tfm);
@@ -278,26 +287,31 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 
 static unsigned int crypto_ctxsize(struct crypto_alg *alg, int flags)
 {
+	const struct crypto_type *type = alg->cra_type;
 	unsigned int len;
 
+	len = alg->cra_alignmask & ~(crypto_tfm_ctx_alignment() - 1);
+	if (type)
+		return len + type->ctxsize(alg);
+
 	switch (alg->cra_flags & CRYPTO_ALG_TYPE_MASK) {
 	default:
 		BUG();
 
 	case CRYPTO_ALG_TYPE_CIPHER:
-		len = crypto_cipher_ctxsize(alg, flags);
+		len += crypto_cipher_ctxsize(alg, flags);
 		break;
 		
 	case CRYPTO_ALG_TYPE_DIGEST:
-		len = crypto_digest_ctxsize(alg, flags);
+		len += crypto_digest_ctxsize(alg, flags);
 		break;
 		
 	case CRYPTO_ALG_TYPE_COMPRESS:
-		len = crypto_compress_ctxsize(alg, flags);
+		len += crypto_compress_ctxsize(alg, flags);
 		break;
 	}
 
-	return len + (alg->cra_alignmask & ~(crypto_tfm_ctx_alignment() - 1));
+	return len;
 }
 
 void crypto_shoot_alg(struct crypto_alg *alg)

commit 6d7d684d635ac5a345f075015f2c84169c111c6a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Jul 30 11:53:01 2006 +1000

    [CRYPTO] api: Added crypto_alloc_base
    
    Up until now all crypto transforms have been of the same type, struct
    crypto_tfm, regardless of whether they are ciphers, digests, or other
    types.  As a result of that, we check the types at run-time before
    each crypto operation.
    
    This is rather cumbersome.  We could instead use different C types for
    each crypto type to ensure that the correct types are used at compile
    time.  That is, we would have crypto_cipher/crypto_digest instead of
    just crypto_tfm.  The appropriate type would then be required for the
    actual operations such as crypto_digest_digest.
    
    Now that we have the type/mask fields when looking up algorithms, it
    is easy to request for an algorithm of the precise type that the user
    wants.  However, crypto_alloc_tfm currently does not expose these new
    attributes.
    
    This patch introduces the function crypto_alloc_base which will carry
    these new parameters.  It will be renamed to crypto_alloc_tfm once
    all existing users have been converted.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 1e4692a13474..bc4b7901acdf 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -372,6 +372,66 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 	return tfm;
 }
 
+/*
+ *	crypto_alloc_base - Locate algorithm and allocate transform
+ *	@alg_name: Name of algorithm
+ *	@type: Type of algorithm
+ *	@mask: Mask for type comparison
+ *
+ *	crypto_alloc_base() will first attempt to locate an already loaded
+ *	algorithm.  If that fails and the kernel supports dynamically loadable
+ *	modules, it will then attempt to load a module of the same name or
+ *	alias.  If that fails it will send a query to any loaded crypto manager
+ *	to construct an algorithm on the fly.  A refcount is grabbed on the
+ *	algorithm which is then associated with the new transform.
+ *
+ *	The returned transform is of a non-determinate type.  Most people
+ *	should use one of the more specific allocation functions such as
+ *	crypto_alloc_blkcipher.
+ *
+ *	In case of error the return value is an error pointer.
+ */
+struct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)
+{
+	struct crypto_tfm *tfm;
+	int err;
+
+	for (;;) {
+		struct crypto_alg *alg;
+
+		alg = crypto_alg_mod_lookup(alg_name, type, mask);
+		err = PTR_ERR(alg);
+		tfm = ERR_PTR(err);
+		if (IS_ERR(alg))
+			goto err;
+
+		tfm = __crypto_alloc_tfm(alg, 0);
+		if (!IS_ERR(tfm))
+			break;
+
+		crypto_mod_put(alg);
+		err = PTR_ERR(tfm);
+
+err:
+		if (err != -EAGAIN)
+			break;
+		if (signal_pending(current)) {
+			err = -EINTR;
+			break;
+		}
+	};
+
+	return tfm;
+}
+EXPORT_SYMBOL_GPL(crypto_alloc_base);
+ 
+/*
+ *	crypto_free_tfm - Free crypto transform
+ *	@tfm: Transform to free
+ *
+ *	crypto_free_tfm() frees up the transform and any associated resources,
+ *	then drops the refcount on the associated algorithm.
+ */
 void crypto_free_tfm(struct crypto_tfm *tfm)
 {
 	struct crypto_alg *alg;

commit f3f632d61ae9af85d436706ee8e33af1a7fb9c28
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 6 23:12:59 2006 +1000

    [CRYPTO] api: Added asynchronous flag
    
    This patch adds the asynchronous flag and changes all existing users to
    only look up algorithms that are synchronous.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 7e5522cf856e..1e4692a13474 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -355,7 +355,7 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 	do {
 		struct crypto_alg *alg;
 
-		alg = crypto_alg_mod_lookup(name, 0, 0);
+		alg = crypto_alg_mod_lookup(name, 0, CRYPTO_ALG_ASYNC);
 		err = PTR_ERR(alg);
 		if (IS_ERR(alg))
 			continue;
@@ -394,7 +394,8 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 int crypto_alg_available(const char *name, u32 flags)
 {
 	int ret = 0;
-	struct crypto_alg *alg = crypto_alg_mod_lookup(name, 0, 0);
+	struct crypto_alg *alg = crypto_alg_mod_lookup(name, 0,
+						       CRYPTO_ALG_ASYNC);
 	
 	if (!IS_ERR(alg)) {
 		crypto_mod_put(alg);

commit 6bfd48096ff8ecabf955958b51ddfa7988eb0a14
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Sep 21 11:39:29 2006 +1000

    [CRYPTO] api: Added spawns
    
    Spawns lock a specific crypto algorithm in place.  They can then be used
    with crypto_spawn_tfm to allocate a tfm for that algorithm.  When the base
    algorithm of a spawn is deregistered, all its spawns will be automatically
    removed.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index ddf6a767acdd..7e5522cf856e 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -15,11 +15,13 @@
  *
  */
 
+#include <linux/err.h>
 #include <linux/errno.h>
 #include <linux/kernel.h>
 #include <linux/kmod.h>
 #include <linux/module.h>
 #include <linux/param.h>
+#include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/string.h>
 #include "internal.h"
@@ -38,12 +40,6 @@ static inline struct crypto_alg *crypto_alg_get(struct crypto_alg *alg)
 	return alg;
 }
 
-static inline void crypto_alg_put(struct crypto_alg *alg)
-{
-	if (atomic_dec_and_test(&alg->cra_refcnt) && alg->cra_destroy)
-		alg->cra_destroy(alg);
-}
-
 struct crypto_alg *crypto_mod_get(struct crypto_alg *alg)
 {
 	return try_module_get(alg->cra_module) ? crypto_alg_get(alg) : NULL;
@@ -65,6 +61,9 @@ struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type, u32 mask)
 	list_for_each_entry(q, &crypto_alg_list, cra_list) {
 		int exact, fuzzy;
 
+		if (crypto_is_moribund(q))
+			continue;
+
 		if ((q->cra_flags ^ type) & mask)
 			continue;
 
@@ -111,7 +110,7 @@ static struct crypto_alg *crypto_larval_alloc(const char *name, u32 type,
 
 	larval = kzalloc(sizeof(*larval), GFP_KERNEL);
 	if (!larval)
-		return NULL;
+		return ERR_PTR(-ENOMEM);
 
 	larval->mask = mask;
 	larval->alg.cra_flags = CRYPTO_ALG_LARVAL | type;
@@ -153,8 +152,11 @@ static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 
 	wait_for_completion_interruptible_timeout(&larval->completion, 60 * HZ);
 	alg = larval->adult;
-	if (alg && !crypto_mod_get(alg))
-		alg = NULL;
+	if (alg) {
+		if (!crypto_mod_get(alg))
+			alg = ERR_PTR(-EAGAIN);
+	} else
+		alg = ERR_PTR(-ENOENT);
 	crypto_mod_put(&larval->alg);
 
 	return alg;
@@ -165,9 +167,6 @@ static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
 {
 	struct crypto_alg *alg;
 
-	if (!name)
-		return NULL;
-
 	down_read(&crypto_alg_sem);
 	alg = __crypto_alg_lookup(name, type, mask);
 	up_read(&crypto_alg_sem);
@@ -181,7 +180,10 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 	struct crypto_alg *larval;
 	int ok;
 
-	mask &= ~CRYPTO_ALG_LARVAL;
+	if (!name)
+		return ERR_PTR(-ENOENT);
+
+	mask &= ~(CRYPTO_ALG_LARVAL | CRYPTO_ALG_DEAD);
 	type &= mask;
 
 	alg = try_then_request_module(crypto_alg_lookup(name, type, mask),
@@ -190,7 +192,7 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 		return crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;
 
 	larval = crypto_larval_alloc(name, type, mask);
-	if (!larval || !crypto_is_larval(larval))
+	if (IS_ERR(larval) || !crypto_is_larval(larval))
 		return larval;
 
 	ok = crypto_notify(CRYPTO_MSG_ALG_REQUEST, larval);
@@ -203,7 +205,7 @@ struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 		alg = crypto_larval_wait(larval);
 	else {
 		crypto_mod_put(larval);
-		alg = NULL;
+		alg = ERR_PTR(-ENOENT);
 	}
 	crypto_larval_kill(larval);
 	return alg;
@@ -298,31 +300,40 @@ static unsigned int crypto_ctxsize(struct crypto_alg *alg, int flags)
 	return len + (alg->cra_alignmask & ~(crypto_tfm_ctx_alignment() - 1));
 }
 
-struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
+void crypto_shoot_alg(struct crypto_alg *alg)
+{
+	down_write(&crypto_alg_sem);
+	alg->cra_flags |= CRYPTO_ALG_DYING;
+	up_write(&crypto_alg_sem);
+}
+EXPORT_SYMBOL_GPL(crypto_shoot_alg);
+
+struct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 flags)
 {
 	struct crypto_tfm *tfm = NULL;
-	struct crypto_alg *alg;
 	unsigned int tfm_size;
-
-	alg = crypto_alg_mod_lookup(name, 0, 0);
-	if (alg == NULL)
-		goto out;
+	int err = -ENOMEM;
 
 	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg, flags);
 	tfm = kzalloc(tfm_size, GFP_KERNEL);
 	if (tfm == NULL)
-		goto out_put;
+		goto out;
 
 	tfm->__crt_alg = alg;
-	
-	if (crypto_init_flags(tfm, flags))
+
+	err = crypto_init_flags(tfm, flags);
+	if (err)
 		goto out_free_tfm;
 		
-	if (crypto_init_ops(tfm))
+	err = crypto_init_ops(tfm);
+	if (err)
 		goto out_free_tfm;
 
-	if (alg->cra_init && alg->cra_init(tfm))
+	if (alg->cra_init && (err = alg->cra_init(tfm))) {
+		if (err == -EAGAIN)
+			crypto_shoot_alg(alg);
 		goto cra_init_failed;
+	}
 
 	goto out;
 
@@ -330,12 +341,36 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 	crypto_exit_ops(tfm);
 out_free_tfm:
 	kfree(tfm);
-	tfm = NULL;
-out_put:
-	crypto_mod_put(alg);
+	tfm = ERR_PTR(err);
 out:
 	return tfm;
 }
+EXPORT_SYMBOL_GPL(__crypto_alloc_tfm);
+
+struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
+{
+	struct crypto_tfm *tfm = NULL;
+	int err;
+
+	do {
+		struct crypto_alg *alg;
+
+		alg = crypto_alg_mod_lookup(name, 0, 0);
+		err = PTR_ERR(alg);
+		if (IS_ERR(alg))
+			continue;
+
+		tfm = __crypto_alloc_tfm(alg, flags);
+		err = 0;
+		if (IS_ERR(tfm)) {
+			crypto_mod_put(alg);
+			err = PTR_ERR(tfm);
+			tfm = NULL;
+		}
+	} while (err == -EAGAIN && !signal_pending(current));
+
+	return tfm;
+}
 
 void crypto_free_tfm(struct crypto_tfm *tfm)
 {
@@ -361,7 +396,7 @@ int crypto_alg_available(const char *name, u32 flags)
 	int ret = 0;
 	struct crypto_alg *alg = crypto_alg_mod_lookup(name, 0, 0);
 	
-	if (alg) {
+	if (!IS_ERR(alg)) {
 		crypto_mod_put(alg);
 		ret = 1;
 	}

commit 492e2b63eb10c28f4f0b694264d74a8755cd1be0
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Sep 21 11:35:17 2006 +1000

    [CRYPTO] api: Allow algorithm lookup by type
    
    This patch also adds the infrastructure to pick an algorithm based on
    their type.  For example, this allows you to select the encryption
    algorithm "aes", instead of any algorithm registered under the name
    "aes".  For now this is only accessible internally.  Eventually it
    will be made available through crypto_alloc_tfm.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index 67cd6f87b74a..ddf6a767acdd 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -57,7 +57,7 @@ void crypto_mod_put(struct crypto_alg *alg)
 }
 EXPORT_SYMBOL_GPL(crypto_mod_put);
 
-struct crypto_alg *__crypto_alg_lookup(const char *name)
+struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type, u32 mask)
 {
 	struct crypto_alg *q, *alg = NULL;
 	int best = -2;
@@ -65,6 +65,13 @@ struct crypto_alg *__crypto_alg_lookup(const char *name)
 	list_for_each_entry(q, &crypto_alg_list, cra_list) {
 		int exact, fuzzy;
 
+		if ((q->cra_flags ^ type) & mask)
+			continue;
+
+		if (crypto_is_larval(q) &&
+		    ((struct crypto_larval *)q)->mask != mask)
+			continue;
+
 		exact = !strcmp(q->cra_driver_name, name);
 		fuzzy = !strcmp(q->cra_name, name);
 		if (!exact && !(fuzzy && q->cra_priority > best))
@@ -96,7 +103,8 @@ static void crypto_larval_destroy(struct crypto_alg *alg)
 	kfree(larval);
 }
 
-static struct crypto_alg *crypto_larval_alloc(const char *name)
+static struct crypto_alg *crypto_larval_alloc(const char *name, u32 type,
+					      u32 mask)
 {
 	struct crypto_alg *alg;
 	struct crypto_larval *larval;
@@ -105,7 +113,8 @@ static struct crypto_alg *crypto_larval_alloc(const char *name)
 	if (!larval)
 		return NULL;
 
-	larval->alg.cra_flags = CRYPTO_ALG_LARVAL;
+	larval->mask = mask;
+	larval->alg.cra_flags = CRYPTO_ALG_LARVAL | type;
 	larval->alg.cra_priority = -1;
 	larval->alg.cra_destroy = crypto_larval_destroy;
 
@@ -114,7 +123,7 @@ static struct crypto_alg *crypto_larval_alloc(const char *name)
 	init_completion(&larval->completion);
 
 	down_write(&crypto_alg_sem);
-	alg = __crypto_alg_lookup(name);
+	alg = __crypto_alg_lookup(name, type, mask);
 	if (!alg) {
 		alg = &larval->alg;
 		list_add(&alg->cra_list, &crypto_alg_list);
@@ -151,7 +160,8 @@ static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
 	return alg;
 }
 
-static struct crypto_alg *crypto_alg_lookup(const char *name)
+static struct crypto_alg *crypto_alg_lookup(const char *name, u32 type,
+					    u32 mask)
 {
 	struct crypto_alg *alg;
 
@@ -159,25 +169,27 @@ static struct crypto_alg *crypto_alg_lookup(const char *name)
 		return NULL;
 
 	down_read(&crypto_alg_sem);
-	alg = __crypto_alg_lookup(name);
+	alg = __crypto_alg_lookup(name, type, mask);
 	up_read(&crypto_alg_sem);
 
 	return alg;
 }
 
-/* A far more intelligent version of this is planned.  For now, just
- * try an exact match on the name of the algorithm. */
-static struct crypto_alg *crypto_alg_mod_lookup(const char *name)
+struct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)
 {
 	struct crypto_alg *alg;
 	struct crypto_alg *larval;
 	int ok;
 
-	alg = try_then_request_module(crypto_alg_lookup(name), name);
+	mask &= ~CRYPTO_ALG_LARVAL;
+	type &= mask;
+
+	alg = try_then_request_module(crypto_alg_lookup(name, type, mask),
+				      name);
 	if (alg)
 		return crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;
 
-	larval = crypto_larval_alloc(name);
+	larval = crypto_larval_alloc(name, type, mask);
 	if (!larval || !crypto_is_larval(larval))
 		return larval;
 
@@ -196,6 +208,7 @@ static struct crypto_alg *crypto_alg_mod_lookup(const char *name)
 	crypto_larval_kill(larval);
 	return alg;
 }
+EXPORT_SYMBOL_GPL(crypto_alg_mod_lookup);
 
 static int crypto_init_flags(struct crypto_tfm *tfm, u32 flags)
 {
@@ -291,7 +304,7 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 	struct crypto_alg *alg;
 	unsigned int tfm_size;
 
-	alg = crypto_alg_mod_lookup(name);
+	alg = crypto_alg_mod_lookup(name, 0, 0);
 	if (alg == NULL)
 		goto out;
 
@@ -346,7 +359,7 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 int crypto_alg_available(const char *name, u32 flags)
 {
 	int ret = 0;
-	struct crypto_alg *alg = crypto_alg_mod_lookup(name);
+	struct crypto_alg *alg = crypto_alg_mod_lookup(name, 0, 0);
 	
 	if (alg) {
 		crypto_mod_put(alg);

commit 2b8c19dbdc692e81243a328725a02efb77b144a5
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Sep 21 11:31:44 2006 +1000

    [CRYPTO] api: Add cryptomgr
    
    The cryptomgr module is a simple manager of crypto algorithm instances.
    It ensures that parameterised algorithms of the type tmpl(alg) (e.g.,
    cbc(aes)) are always created.
    
    This is meant to satisfy the needs for most users.  For more complex
    cases such as deeper combinations or multiple parameters, a netlink
    module will be created which allows arbitrary expressions to be parsed
    in user-space.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index 5a0d6a17cfd7..67cd6f87b74a 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -18,6 +18,7 @@
 #include <linux/errno.h>
 #include <linux/kernel.h>
 #include <linux/kmod.h>
+#include <linux/module.h>
 #include <linux/param.h>
 #include <linux/slab.h>
 #include <linux/string.h>
@@ -170,6 +171,7 @@ static struct crypto_alg *crypto_alg_mod_lookup(const char *name)
 {
 	struct crypto_alg *alg;
 	struct crypto_alg *larval;
+	int ok;
 
 	alg = try_then_request_module(crypto_alg_lookup(name), name);
 	if (alg)
@@ -179,7 +181,13 @@ static struct crypto_alg *crypto_alg_mod_lookup(const char *name)
 	if (!larval || !crypto_is_larval(larval))
 		return larval;
 
-	if (crypto_notify(CRYPTO_MSG_ALG_REQUEST, larval) == NOTIFY_STOP)
+	ok = crypto_notify(CRYPTO_MSG_ALG_REQUEST, larval);
+	if (ok == NOTIFY_DONE) {
+		request_module("cryptomgr");
+		ok = crypto_notify(CRYPTO_MSG_ALG_REQUEST, larval);
+	}
+
+	if (ok == NOTIFY_STOP)
 		alg = crypto_larval_wait(larval);
 	else {
 		crypto_mod_put(larval);

commit 2825982d9d66ebba4b532a07391dfbb357f71c5f
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 6 21:23:26 2006 +1000

    [CRYPTO] api: Added event notification
    
    This patch adds a notifier chain for algorithm/template registration events.
    This will be used to register compound algorithms such as cbc(aes).  In
    future this will also be passed onto user-space through netlink.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index c922090b4842..5a0d6a17cfd7 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -18,6 +18,7 @@
 #include <linux/errno.h>
 #include <linux/kernel.h>
 #include <linux/kmod.h>
+#include <linux/param.h>
 #include <linux/slab.h>
 #include <linux/string.h>
 #include "internal.h"
@@ -27,6 +28,9 @@ EXPORT_SYMBOL_GPL(crypto_alg_list);
 DECLARE_RWSEM(crypto_alg_sem);
 EXPORT_SYMBOL_GPL(crypto_alg_sem);
 
+BLOCKING_NOTIFIER_HEAD(crypto_chain);
+EXPORT_SYMBOL_GPL(crypto_chain);
+
 static inline struct crypto_alg *crypto_alg_get(struct crypto_alg *alg)
 {
 	atomic_inc(&alg->cra_refcnt);
@@ -39,27 +43,24 @@ static inline void crypto_alg_put(struct crypto_alg *alg)
 		alg->cra_destroy(alg);
 }
 
-static struct crypto_alg *crypto_mod_get(struct crypto_alg *alg)
+struct crypto_alg *crypto_mod_get(struct crypto_alg *alg)
 {
 	return try_module_get(alg->cra_module) ? crypto_alg_get(alg) : NULL;
 }
+EXPORT_SYMBOL_GPL(crypto_mod_get);
 
-static void crypto_mod_put(struct crypto_alg *alg)
+void crypto_mod_put(struct crypto_alg *alg)
 {
 	crypto_alg_put(alg);
 	module_put(alg->cra_module);
 }
+EXPORT_SYMBOL_GPL(crypto_mod_put);
 
-static struct crypto_alg *crypto_alg_lookup(const char *name)
+struct crypto_alg *__crypto_alg_lookup(const char *name)
 {
 	struct crypto_alg *q, *alg = NULL;
-	int best = -1;
+	int best = -2;
 
-	if (!name)
-		return NULL;
-	
-	down_read(&crypto_alg_sem);
-	
 	list_for_each_entry(q, &crypto_alg_list, cra_list) {
 		int exact, fuzzy;
 
@@ -79,16 +80,113 @@ static struct crypto_alg *crypto_alg_lookup(const char *name)
 		if (exact)
 			break;
 	}
-	
+
+	return alg;
+}
+EXPORT_SYMBOL_GPL(__crypto_alg_lookup);
+
+static void crypto_larval_destroy(struct crypto_alg *alg)
+{
+	struct crypto_larval *larval = (void *)alg;
+
+	BUG_ON(!crypto_is_larval(alg));
+	if (larval->adult)
+		crypto_mod_put(larval->adult);
+	kfree(larval);
+}
+
+static struct crypto_alg *crypto_larval_alloc(const char *name)
+{
+	struct crypto_alg *alg;
+	struct crypto_larval *larval;
+
+	larval = kzalloc(sizeof(*larval), GFP_KERNEL);
+	if (!larval)
+		return NULL;
+
+	larval->alg.cra_flags = CRYPTO_ALG_LARVAL;
+	larval->alg.cra_priority = -1;
+	larval->alg.cra_destroy = crypto_larval_destroy;
+
+	atomic_set(&larval->alg.cra_refcnt, 2);
+	strlcpy(larval->alg.cra_name, name, CRYPTO_MAX_ALG_NAME);
+	init_completion(&larval->completion);
+
+	down_write(&crypto_alg_sem);
+	alg = __crypto_alg_lookup(name);
+	if (!alg) {
+		alg = &larval->alg;
+		list_add(&alg->cra_list, &crypto_alg_list);
+	}
+	up_write(&crypto_alg_sem);
+
+	if (alg != &larval->alg)
+		kfree(larval);
+
+	return alg;
+}
+
+static void crypto_larval_kill(struct crypto_alg *alg)
+{
+	struct crypto_larval *larval = (void *)alg;
+
+	down_write(&crypto_alg_sem);
+	list_del(&alg->cra_list);
+	up_write(&crypto_alg_sem);
+	complete(&larval->completion);
+	crypto_alg_put(alg);
+}
+
+static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)
+{
+	struct crypto_larval *larval = (void *)alg;
+
+	wait_for_completion_interruptible_timeout(&larval->completion, 60 * HZ);
+	alg = larval->adult;
+	if (alg && !crypto_mod_get(alg))
+		alg = NULL;
+	crypto_mod_put(&larval->alg);
+
+	return alg;
+}
+
+static struct crypto_alg *crypto_alg_lookup(const char *name)
+{
+	struct crypto_alg *alg;
+
+	if (!name)
+		return NULL;
+
+	down_read(&crypto_alg_sem);
+	alg = __crypto_alg_lookup(name);
 	up_read(&crypto_alg_sem);
+
 	return alg;
 }
 
 /* A far more intelligent version of this is planned.  For now, just
  * try an exact match on the name of the algorithm. */
-static inline struct crypto_alg *crypto_alg_mod_lookup(const char *name)
+static struct crypto_alg *crypto_alg_mod_lookup(const char *name)
 {
-	return try_then_request_module(crypto_alg_lookup(name), name);
+	struct crypto_alg *alg;
+	struct crypto_alg *larval;
+
+	alg = try_then_request_module(crypto_alg_lookup(name), name);
+	if (alg)
+		return crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;
+
+	larval = crypto_larval_alloc(name);
+	if (!larval || !crypto_is_larval(larval))
+		return larval;
+
+	if (crypto_notify(CRYPTO_MSG_ALG_REQUEST, larval) == NOTIFY_STOP)
+		alg = crypto_larval_wait(larval);
+	else {
+		crypto_mod_put(larval);
+		alg = NULL;
+	}
+	crypto_larval_kill(larval);
+	return alg;
 }
 
 static int crypto_init_flags(struct crypto_tfm *tfm, u32 flags)

commit cce9e06d100df19a327b19f23adad76e7bf63edd
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Aug 21 21:08:13 2006 +1000

    [CRYPTO] api: Split out low-level API
    
    The crypto API is made up of the part facing users such as IPsec and the
    low-level part which is used by cryptographic entities such as algorithms.
    This patch splits out the latter so that the two APIs are more clearly
    delineated.  As a bonus the low-level API can now be modularised if all
    algorithms are built as modules.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 5994a58ef954..c922090b4842 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -15,19 +15,17 @@
  *
  */
 
-#include <linux/compiler.h>
-#include <linux/init.h>
-#include <linux/crypto.h>
 #include <linux/errno.h>
 #include <linux/kernel.h>
 #include <linux/kmod.h>
-#include <linux/rwsem.h>
 #include <linux/slab.h>
 #include <linux/string.h>
 #include "internal.h"
 
 LIST_HEAD(crypto_alg_list);
+EXPORT_SYMBOL_GPL(crypto_alg_list);
 DECLARE_RWSEM(crypto_alg_sem);
+EXPORT_SYMBOL_GPL(crypto_alg_sem);
 
 static inline struct crypto_alg *crypto_alg_get(struct crypto_alg *alg)
 {
@@ -239,86 +237,6 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 	kfree(tfm);
 }
 
-static inline int crypto_set_driver_name(struct crypto_alg *alg)
-{
-	static const char suffix[] = "-generic";
-	char *driver_name = alg->cra_driver_name;
-	int len;
-
-	if (*driver_name)
-		return 0;
-
-	len = strlcpy(driver_name, alg->cra_name, CRYPTO_MAX_ALG_NAME);
-	if (len + sizeof(suffix) > CRYPTO_MAX_ALG_NAME)
-		return -ENAMETOOLONG;
-
-	memcpy(driver_name + len, suffix, sizeof(suffix));
-	return 0;
-}
-
-int crypto_register_alg(struct crypto_alg *alg)
-{
-	int ret;
-	struct crypto_alg *q;
-
-	if (alg->cra_alignmask & (alg->cra_alignmask + 1))
-		return -EINVAL;
-
-	if (alg->cra_alignmask & alg->cra_blocksize)
-		return -EINVAL;
-
-	if (alg->cra_blocksize > PAGE_SIZE / 8)
-		return -EINVAL;
-
-	if (alg->cra_priority < 0)
-		return -EINVAL;
-	
-	ret = crypto_set_driver_name(alg);
-	if (unlikely(ret))
-		return ret;
-
-	down_write(&crypto_alg_sem);
-	
-	list_for_each_entry(q, &crypto_alg_list, cra_list) {
-		if (q == alg) {
-			ret = -EEXIST;
-			goto out;
-		}
-	}
-	
-	list_add(&alg->cra_list, &crypto_alg_list);
-	atomic_set(&alg->cra_refcnt, 1);
-out:	
-	up_write(&crypto_alg_sem);
-	return ret;
-}
-
-int crypto_unregister_alg(struct crypto_alg *alg)
-{
-	int ret = -ENOENT;
-	struct crypto_alg *q;
-	
-	down_write(&crypto_alg_sem);
-	list_for_each_entry(q, &crypto_alg_list, cra_list) {
-		if (alg == q) {
-			list_del(&alg->cra_list);
-			ret = 0;
-			goto out;
-		}
-	}
-out:	
-	up_write(&crypto_alg_sem);
-
-	if (ret)
-		return ret;
-
-	BUG_ON(atomic_read(&alg->cra_refcnt) != 1);
-	if (alg->cra_destroy)
-		alg->cra_destroy(alg);
-
-	return 0;
-}
-
 int crypto_alg_available(const char *name, u32 flags)
 {
 	int ret = 0;
@@ -332,17 +250,6 @@ int crypto_alg_available(const char *name, u32 flags)
 	return ret;
 }
 
-static int __init init_crypto(void)
-{
-	printk(KERN_INFO "Initializing Cryptographic API\n");
-	crypto_init_proc();
-	return 0;
-}
-
-__initcall(init_crypto);
-
-EXPORT_SYMBOL_GPL(crypto_register_alg);
-EXPORT_SYMBOL_GPL(crypto_unregister_alg);
 EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
 EXPORT_SYMBOL_GPL(crypto_free_tfm);
 EXPORT_SYMBOL_GPL(crypto_alg_available);

commit 6521f30273fbec65146a0f16de74b7b402b0f7b0
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Aug 6 20:28:44 2006 +1000

    [CRYPTO] api: Add crypto_alg reference counting
    
    Up until now we've relied on module reference counting to ensure that the
    crypto_alg structures don't disappear from under us.  This was good enough
    as long as each crypto_alg came from exactly one module.
    
    However, with parameterised crypto algorithms a crypto_alg object may need
    two or more modules to operate.  This means that we need to count the
    references to the crypto_alg object directly.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index 8c2743a05f90..5994a58ef954 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -29,13 +29,26 @@
 LIST_HEAD(crypto_alg_list);
 DECLARE_RWSEM(crypto_alg_sem);
 
-static inline int crypto_mod_get(struct crypto_alg *alg)
+static inline struct crypto_alg *crypto_alg_get(struct crypto_alg *alg)
 {
-	return try_module_get(alg->cra_module);
+	atomic_inc(&alg->cra_refcnt);
+	return alg;
+}
+
+static inline void crypto_alg_put(struct crypto_alg *alg)
+{
+	if (atomic_dec_and_test(&alg->cra_refcnt) && alg->cra_destroy)
+		alg->cra_destroy(alg);
+}
+
+static struct crypto_alg *crypto_mod_get(struct crypto_alg *alg)
+{
+	return try_module_get(alg->cra_module) ? crypto_alg_get(alg) : NULL;
 }
 
-static inline void crypto_mod_put(struct crypto_alg *alg)
+static void crypto_mod_put(struct crypto_alg *alg)
 {
+	crypto_alg_put(alg);
 	module_put(alg->cra_module);
 }
 
@@ -274,6 +287,7 @@ int crypto_register_alg(struct crypto_alg *alg)
 	}
 	
 	list_add(&alg->cra_list, &crypto_alg_list);
+	atomic_set(&alg->cra_refcnt, 1);
 out:	
 	up_write(&crypto_alg_sem);
 	return ret;
@@ -284,8 +298,6 @@ int crypto_unregister_alg(struct crypto_alg *alg)
 	int ret = -ENOENT;
 	struct crypto_alg *q;
 	
-	BUG_ON(!alg->cra_module);
-	
 	down_write(&crypto_alg_sem);
 	list_for_each_entry(q, &crypto_alg_list, cra_list) {
 		if (alg == q) {
@@ -296,7 +308,15 @@ int crypto_unregister_alg(struct crypto_alg *alg)
 	}
 out:	
 	up_write(&crypto_alg_sem);
-	return ret;
+
+	if (ret)
+		return ret;
+
+	BUG_ON(atomic_read(&alg->cra_refcnt) != 1);
+	if (alg->cra_destroy)
+		alg->cra_destroy(alg);
+
+	return 0;
 }
 
 int crypto_alg_available(const char *name, u32 flags)

commit 72fa491912689ca69dd15f4266945d2c2f2819f8
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun May 28 09:05:24 2006 +1000

    [CRYPTO] api: Rename crypto_alg_get to crypto_mod_get
    
    The functions crypto_alg_get and crypto_alg_put operates on the crypto
    modules rather than the algorithms.  Therefore it makes sense to call
    them crypto_mod_get and crypto_alg_put respectively.
    
    This is needed because we need to have real algorithm reference counters
    for parameterised algorithms as they can be unregistered from below by
    when their parameter algorithms are themselves unregistered.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index c11ec1fd4f18..8c2743a05f90 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -29,12 +29,12 @@
 LIST_HEAD(crypto_alg_list);
 DECLARE_RWSEM(crypto_alg_sem);
 
-static inline int crypto_alg_get(struct crypto_alg *alg)
+static inline int crypto_mod_get(struct crypto_alg *alg)
 {
 	return try_module_get(alg->cra_module);
 }
 
-static inline void crypto_alg_put(struct crypto_alg *alg)
+static inline void crypto_mod_put(struct crypto_alg *alg)
 {
 	module_put(alg->cra_module);
 }
@@ -57,12 +57,12 @@ static struct crypto_alg *crypto_alg_lookup(const char *name)
 		if (!exact && !(fuzzy && q->cra_priority > best))
 			continue;
 
-		if (unlikely(!crypto_alg_get(q)))
+		if (unlikely(!crypto_mod_get(q)))
 			continue;
 
 		best = q->cra_priority;
 		if (alg)
-			crypto_alg_put(alg);
+			crypto_mod_put(alg);
 		alg = q;
 
 		if (exact)
@@ -202,7 +202,7 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 	kfree(tfm);
 	tfm = NULL;
 out_put:
-	crypto_alg_put(alg);
+	crypto_mod_put(alg);
 out:
 	return tfm;
 }
@@ -221,7 +221,7 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 	if (alg->cra_exit)
 		alg->cra_exit(tfm);
 	crypto_exit_ops(tfm);
-	crypto_alg_put(alg);
+	crypto_mod_put(alg);
 	memset(tfm, 0, size);
 	kfree(tfm);
 }
@@ -305,7 +305,7 @@ int crypto_alg_available(const char *name, u32 flags)
 	struct crypto_alg *alg = crypto_alg_mod_lookup(name);
 	
 	if (alg) {
-		crypto_alg_put(alg);
+		crypto_mod_put(alg);
 		ret = 1;
 	}
 	

commit 996e2523cc347cc98237d2da3454aedc779fdcba
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun May 21 11:57:20 2006 +1000

    [CRYPTO] api: Allow replacement when registering new algorithms
    
    We already allow asynchronous removal of existing algorithm modules.  By
    allowing the replacement of existing algorithms, we can replace algorithms
    without having to wait for for all existing users to complete.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 735fdedd8217..c11ec1fd4f18 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -267,13 +267,13 @@ int crypto_register_alg(struct crypto_alg *alg)
 	down_write(&crypto_alg_sem);
 	
 	list_for_each_entry(q, &crypto_alg_list, cra_list) {
-		if (!strcmp(q->cra_driver_name, alg->cra_driver_name)) {
+		if (q == alg) {
 			ret = -EEXIST;
 			goto out;
 		}
 	}
 	
-	list_add_tail(&alg->cra_list, &crypto_alg_list);
+	list_add(&alg->cra_list, &crypto_alg_list);
 out:	
 	up_write(&crypto_alg_sem);
 	return ret;

commit d913ea0d6b6a48dd6eed8fc5e299b8b10e049186
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun May 21 08:45:26 2006 +1000

    [CRYPTO] api: Removed const from cra_name/cra_driver_name
    
    We do need to change these names now and even more so in future with
    instantiated algorithms.  So let's stop lying to the compiler and get
    rid of the const modifiers.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 8145310d7985..735fdedd8217 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -229,7 +229,7 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 static inline int crypto_set_driver_name(struct crypto_alg *alg)
 {
 	static const char suffix[] = "-generic";
-	char *driver_name = (char *)alg->cra_driver_name;
+	char *driver_name = alg->cra_driver_name;
 	int len;
 
 	if (*driver_name)

commit c7fc05992afcf1d63d6d5fb6142c8d39094dbca9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed May 24 13:02:26 2006 +1000

    [CRYPTO] api: Added cra_init/cra_exit
    
    This patch adds the hooks cra_init/cra_exit which are called during a tfm's
    construction and destruction respectively.  This will be used by the instances
    to allocate child tfm's.
    
    For now this lets us get rid of the coa_init/coa_exit functions which are
    used for exactly that purpose (unlike the dia_init function which is called
    for each transaction).
    
    In fact the coa_exit path is currently buggy as it may get called twice
    when an error is encountered during initialisation.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 80bba637fba7..8145310d7985 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -188,13 +188,16 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 	if (crypto_init_flags(tfm, flags))
 		goto out_free_tfm;
 		
-	if (crypto_init_ops(tfm)) {
-		crypto_exit_ops(tfm);
+	if (crypto_init_ops(tfm))
 		goto out_free_tfm;
-	}
+
+	if (alg->cra_init && alg->cra_init(tfm))
+		goto cra_init_failed;
 
 	goto out;
 
+cra_init_failed:
+	crypto_exit_ops(tfm);
 out_free_tfm:
 	kfree(tfm);
 	tfm = NULL;
@@ -215,6 +218,8 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 	alg = tfm->__crt_alg;
 	size = sizeof(*tfm) + alg->cra_ctxsize;
 
+	if (alg->cra_exit)
+		alg->cra_exit(tfm);
 	crypto_exit_ops(tfm);
 	crypto_alg_put(alg);
 	memset(tfm, 0, size);

commit bbeb563f7bb5e703e4d60c18bed81c987781343f
Author: Eric Sesterhenn <snakebyte@gmx.de>
Date:   Mon Mar 6 21:42:07 2006 +1100

    [CRYPTO] all: Use kzalloc where possible
    
    this patch converts crypto/ to kzalloc usage.
    Compile tested with allyesconfig.
    
    Signed-off-by: Eric Sesterhenn <snakebyte@gmx.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 34e02caffc2a..80bba637fba7 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -179,12 +179,10 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 		goto out;
 
 	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg, flags);
-	tfm = kmalloc(tfm_size, GFP_KERNEL);
+	tfm = kzalloc(tfm_size, GFP_KERNEL);
 	if (tfm == NULL)
 		goto out_put;
 
-	memset(tfm, 0, tfm_size);
-	
 	tfm->__crt_alg = alg;
 	
 	if (crypto_init_flags(tfm, flags))

commit f10b7897ee29649fa7f0ccdc8d859ccd6ce7dbfd
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jan 25 22:34:01 2006 +1100

    [CRYPTO] api: Align tfm context as wide as possible
    
    Since tfm contexts can contain arbitrary types we should provide at least
    natural alignment (__attribute__ ((__aligned__))) for them.  In particular,
    this is needed on the Xscale which is a 32-bit architecture with a u64 type
    that requires 64-bit alignment.  This problem was reported by Ronen Shitrit.
    
    The crypto_tfm structure's size was 44 bytes on 32-bit architectures and
    80 bytes on 64-bit architectures.  So adding this requirement only means
    that we have to add an extra 4 bytes on 32-bit architectures.
    
    On i386 the natural alignment is 16 bytes which also benefits the VIA
    Padlock as it no longer has to manually align its context structure to
    128 bits.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index e26156f71839..34e02caffc2a 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -165,7 +165,7 @@ static unsigned int crypto_ctxsize(struct crypto_alg *alg, int flags)
 		break;
 	}
 
-	return len + alg->cra_alignmask;
+	return len + (alg->cra_alignmask & ~(crypto_tfm_ctx_alignment() - 1));
 }
 
 struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)

commit 7302533aac2df321b76e8a113e5cfa529c825b09
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Jan 7 16:24:15 2006 +1100

    [CRYPTO] api: Require block size to be less than PAGE_SIZE/8
    
    The cipher code path may allocate up to two blocks of data on the stack.
    Therefore we need to place limits on the maximum block size.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 2715afdf678c..e26156f71839 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -251,7 +251,7 @@ int crypto_register_alg(struct crypto_alg *alg)
 	if (alg->cra_alignmask & alg->cra_blocksize)
 		return -EINVAL;
 
-	if (alg->cra_blocksize > PAGE_SIZE)
+	if (alg->cra_blocksize > PAGE_SIZE / 8)
 		return -EINVAL;
 
 	if (alg->cra_priority < 0)

commit 5cb1454b862ab3040b78364d58330262fea1ddba
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Nov 5 16:58:14 2005 +1100

    [CRYPTO] Allow multiple implementations of the same algorithm
    
    This is the first step on the road towards asynchronous support in
    the Crypto API.  It adds support for having multiple crypto_alg objects
    for the same algorithm registered in the system.
    
    For example, each device driver would register a crypto_alg object
    for each algorithm that it supports.  While at the same time the
    user may load software implementations of those same algorithms.
    
    Users of the Crypto API may then select a specific implementation
    by name, or choose any implementation for a given algorithm with
    the highest priority.
    
    The priority field is a 32-bit signed integer.  In future it will be
    possible to modify it from user-space.
    
    This also provides a solution to the problem of selecting amongst
    various AES implementations, that is, aes vs. aes-i586 vs. aes-padlock.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 40ae42e9b6a6..2715afdf678c 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -3,6 +3,7 @@
  *
  * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>
  * Copyright (c) 2002 David S. Miller (davem@redhat.com)
+ * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>
  *
  * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>
  * and Nettle, by Niels Möller.
@@ -18,9 +19,11 @@
 #include <linux/init.h>
 #include <linux/crypto.h>
 #include <linux/errno.h>
+#include <linux/kernel.h>
 #include <linux/kmod.h>
 #include <linux/rwsem.h>
 #include <linux/slab.h>
+#include <linux/string.h>
 #include "internal.h"
 
 LIST_HEAD(crypto_alg_list);
@@ -39,6 +42,7 @@ static inline void crypto_alg_put(struct crypto_alg *alg)
 static struct crypto_alg *crypto_alg_lookup(const char *name)
 {
 	struct crypto_alg *q, *alg = NULL;
+	int best = -1;
 
 	if (!name)
 		return NULL;
@@ -46,11 +50,23 @@ static struct crypto_alg *crypto_alg_lookup(const char *name)
 	down_read(&crypto_alg_sem);
 	
 	list_for_each_entry(q, &crypto_alg_list, cra_list) {
-		if (!(strcmp(q->cra_name, name))) {
-			if (crypto_alg_get(q))
-				alg = q;
+		int exact, fuzzy;
+
+		exact = !strcmp(q->cra_driver_name, name);
+		fuzzy = !strcmp(q->cra_name, name);
+		if (!exact && !(fuzzy && q->cra_priority > best))
+			continue;
+
+		if (unlikely(!crypto_alg_get(q)))
+			continue;
+
+		best = q->cra_priority;
+		if (alg)
+			crypto_alg_put(alg);
+		alg = q;
+
+		if (exact)
 			break;
-		}
 	}
 	
 	up_read(&crypto_alg_sem);
@@ -207,9 +223,26 @@ void crypto_free_tfm(struct crypto_tfm *tfm)
 	kfree(tfm);
 }
 
+static inline int crypto_set_driver_name(struct crypto_alg *alg)
+{
+	static const char suffix[] = "-generic";
+	char *driver_name = (char *)alg->cra_driver_name;
+	int len;
+
+	if (*driver_name)
+		return 0;
+
+	len = strlcpy(driver_name, alg->cra_name, CRYPTO_MAX_ALG_NAME);
+	if (len + sizeof(suffix) > CRYPTO_MAX_ALG_NAME)
+		return -ENAMETOOLONG;
+
+	memcpy(driver_name + len, suffix, sizeof(suffix));
+	return 0;
+}
+
 int crypto_register_alg(struct crypto_alg *alg)
 {
-	int ret = 0;
+	int ret;
 	struct crypto_alg *q;
 
 	if (alg->cra_alignmask & (alg->cra_alignmask + 1))
@@ -220,11 +253,18 @@ int crypto_register_alg(struct crypto_alg *alg)
 
 	if (alg->cra_blocksize > PAGE_SIZE)
 		return -EINVAL;
+
+	if (alg->cra_priority < 0)
+		return -EINVAL;
 	
+	ret = crypto_set_driver_name(alg);
+	if (unlikely(ret))
+		return ret;
+
 	down_write(&crypto_alg_sem);
 	
 	list_for_each_entry(q, &crypto_alg_list, cra_list) {
-		if (!(strcmp(q->cra_name, alg->cra_name))) {
+		if (!strcmp(q->cra_driver_name, alg->cra_driver_name)) {
 			ret = -EEXIST;
 			goto out;
 		}

commit 1b40efd772f4419fbc1a8940506424246985c333
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Oct 3 15:15:36 2005 +1000

    [CRYPTO] Check cra_alignmask against cra_blocksize
    
    The cipher code relies on the fact that the block size is a multiple
    of the required alignment.  So we should check this at the time of
    algorith registration.  We also ensure that the block size is bounded
    by the page size.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/api.c b/crypto/api.c
index 959c4e5f264f..40ae42e9b6a6 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -215,7 +215,10 @@ int crypto_register_alg(struct crypto_alg *alg)
 	if (alg->cra_alignmask & (alg->cra_alignmask + 1))
 		return -EINVAL;
 
-	if (alg->cra_alignmask > PAGE_SIZE)
+	if (alg->cra_alignmask & alg->cra_blocksize)
+		return -EINVAL;
+
+	if (alg->cra_blocksize > PAGE_SIZE)
 		return -EINVAL;
 	
 	down_write(&crypto_alg_sem);

commit 64baf3cfea974d2b9e671ccfdbc03e030ea5ebc6
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Sep 1 17:43:05 2005 -0700

    [CRYPTO]: Added CRYPTO_TFM_REQ_MAY_SLEEP flag
    
    The crypto layer currently uses in_atomic() to determine whether it is
    allowed to sleep.  This is incorrect since spin locks don't always cause
    in_atomic() to return true.
    
    Instead of that, this patch returns to an earlier idea of a per-tfm flag
    which determines whether sleeping is allowed.  Unlike the earlier version,
    the default is to not allow sleeping.  This ensures that no existing code
    can break.
    
    As usual, this flag may either be set through crypto_alloc_tfm(), or
    just before a specific crypto operation.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index b4728811ce3b..959c4e5f264f 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -66,7 +66,8 @@ static inline struct crypto_alg *crypto_alg_mod_lookup(const char *name)
 
 static int crypto_init_flags(struct crypto_tfm *tfm, u32 flags)
 {
-	tfm->crt_flags = 0;
+	tfm->crt_flags = flags & CRYPTO_TFM_REQ_MASK;
+	flags &= ~CRYPTO_TFM_REQ_MASK;
 	
 	switch (crypto_tfm_alg_type(tfm)) {
 	case CRYPTO_ALG_TYPE_CIPHER:

commit a61cc44812ff94793987bf43b70a3d9bc64a6820
Author: Jesper Juhl <juhl-lkml@dif.dk>
Date:   Wed Jul 6 13:54:31 2005 -0700

    [CRYPTO] Add null short circuit to crypto_free_tfm
    
    As far as I'm aware there's a general concensus that functions that are
    responsible for freeing resources should be able to cope with being passed
    a NULL pointer. This makes sense as it removes the need for all callers to
    check for NULL, thus elliminating the bugs that happen when some forget
    (safer to just check centrally in the freeing function) and it also makes
    for smaller code all over due to the lack of all those NULL checks.
    This patch makes it safe to pass the crypto_free_tfm() function a NULL
    pointer. Once this patch is applied we can start removing the NULL checks
    from the callers.
    
    Signed-off-by: Jesper Juhl <juhl-lkml@dif.dk>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index 2d8d828c0ca2..b4728811ce3b 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -13,6 +13,8 @@
  * any later version.
  *
  */
+
+#include <linux/compiler.h>
 #include <linux/init.h>
 #include <linux/crypto.h>
 #include <linux/errno.h>
@@ -189,8 +191,14 @@ struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 
 void crypto_free_tfm(struct crypto_tfm *tfm)
 {
-	struct crypto_alg *alg = tfm->__crt_alg;
-	int size = sizeof(*tfm) + alg->cra_ctxsize;
+	struct crypto_alg *alg;
+	int size;
+
+	if (unlikely(!tfm))
+		return;
+
+	alg = tfm->__crt_alg;
+	size = sizeof(*tfm) + alg->cra_ctxsize;
 
 	crypto_exit_ops(tfm);
 	crypto_alg_put(alg);

commit fbdae9f3e7fb57c07cb0d973f113eb25da2e8ff2
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jul 6 13:53:29 2005 -0700

    [CRYPTO] Ensure cit_iv is aligned correctly
    
    This patch ensures that cit_iv is aligned according to cra_alignmask
    by allocating it as part of the tfm structure.  As a side effect the
    crypto layer will also guarantee that the tfm ctx area has enough space
    to be aligned by cra_alignmask.  This allows us to remove the extra
    space reservation from the Padlock driver.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index 0b583d24f7fa..2d8d828c0ca2 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -125,20 +125,46 @@ static void crypto_exit_ops(struct crypto_tfm *tfm)
 	}
 }
 
+static unsigned int crypto_ctxsize(struct crypto_alg *alg, int flags)
+{
+	unsigned int len;
+
+	switch (alg->cra_flags & CRYPTO_ALG_TYPE_MASK) {
+	default:
+		BUG();
+
+	case CRYPTO_ALG_TYPE_CIPHER:
+		len = crypto_cipher_ctxsize(alg, flags);
+		break;
+		
+	case CRYPTO_ALG_TYPE_DIGEST:
+		len = crypto_digest_ctxsize(alg, flags);
+		break;
+		
+	case CRYPTO_ALG_TYPE_COMPRESS:
+		len = crypto_compress_ctxsize(alg, flags);
+		break;
+	}
+
+	return len + alg->cra_alignmask;
+}
+
 struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
 {
 	struct crypto_tfm *tfm = NULL;
 	struct crypto_alg *alg;
+	unsigned int tfm_size;
 
 	alg = crypto_alg_mod_lookup(name);
 	if (alg == NULL)
 		goto out;
-	
-	tfm = kmalloc(sizeof(*tfm) + alg->cra_ctxsize, GFP_KERNEL);
+
+	tfm_size = sizeof(*tfm) + crypto_ctxsize(alg, flags);
+	tfm = kmalloc(tfm_size, GFP_KERNEL);
 	if (tfm == NULL)
 		goto out_put;
 
-	memset(tfm, 0, sizeof(*tfm) + alg->cra_ctxsize);
+	memset(tfm, 0, tfm_size);
 	
 	tfm->__crt_alg = alg;
 	

commit 176c3652c544b6f8d4bb1984c58c10080f45dbf0
Author: Adrian Bunk <bunk@stusta.de>
Date:   Wed Jul 6 13:53:09 2005 -0700

    [CRYPTO] Make crypto_alg_lookup static
    
    This patch makes a needlessly global function static.
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index f55856b21992..0b583d24f7fa 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -16,6 +16,7 @@
 #include <linux/init.h>
 #include <linux/crypto.h>
 #include <linux/errno.h>
+#include <linux/kmod.h>
 #include <linux/rwsem.h>
 #include <linux/slab.h>
 #include "internal.h"
@@ -33,7 +34,7 @@ static inline void crypto_alg_put(struct crypto_alg *alg)
 	module_put(alg->cra_module);
 }
 
-struct crypto_alg *crypto_alg_lookup(const char *name)
+static struct crypto_alg *crypto_alg_lookup(const char *name)
 {
 	struct crypto_alg *q, *alg = NULL;
 
@@ -54,6 +55,13 @@ struct crypto_alg *crypto_alg_lookup(const char *name)
 	return alg;
 }
 
+/* A far more intelligent version of this is planned.  For now, just
+ * try an exact match on the name of the algorithm. */
+static inline struct crypto_alg *crypto_alg_mod_lookup(const char *name)
+{
+	return try_then_request_module(crypto_alg_lookup(name), name);
+}
+
 static int crypto_init_flags(struct crypto_tfm *tfm, u32 flags)
 {
 	tfm->crt_flags = 0;

commit 95477377995aefa2ec1654a9a3777bd57ea99146
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jul 6 13:52:09 2005 -0700

    [CRYPTO] Add alignmask for low-level cipher implementations
    
    The VIA Padlock device requires the input and output buffers to
    be aligned on 16-byte boundaries.  This patch adds the alignmask
    attribute for low-level cipher implementations to indicate their
    alignment requirements.
    
    The mid-level crypt() function will copy the input/output buffers
    if they are not aligned correctly before they are passed to the
    low-level implementation.
    
    Strictly speaking, some of the software implementations require
    the buffers to be aligned on 4-byte boundaries as they do 32-bit
    loads.  However, it is not clear whether it is better to copy
    the buffers or pay the penalty for unaligned loads/stores.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/api.c b/crypto/api.c
index 394169a8577d..f55856b21992 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -168,6 +168,12 @@ int crypto_register_alg(struct crypto_alg *alg)
 {
 	int ret = 0;
 	struct crypto_alg *q;
+
+	if (alg->cra_alignmask & (alg->cra_alignmask + 1))
+		return -EINVAL;
+
+	if (alg->cra_alignmask > PAGE_SIZE)
+		return -EINVAL;
 	
 	down_write(&crypto_alg_sem);
 	

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/crypto/api.c b/crypto/api.c
new file mode 100644
index 000000000000..394169a8577d
--- /dev/null
+++ b/crypto/api.c
@@ -0,0 +1,233 @@
+/*
+ * Scatterlist Cryptographic API.
+ *
+ * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>
+ * Copyright (c) 2002 David S. Miller (davem@redhat.com)
+ *
+ * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>
+ * and Nettle, by Niels Möller.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option) 
+ * any later version.
+ *
+ */
+#include <linux/init.h>
+#include <linux/crypto.h>
+#include <linux/errno.h>
+#include <linux/rwsem.h>
+#include <linux/slab.h>
+#include "internal.h"
+
+LIST_HEAD(crypto_alg_list);
+DECLARE_RWSEM(crypto_alg_sem);
+
+static inline int crypto_alg_get(struct crypto_alg *alg)
+{
+	return try_module_get(alg->cra_module);
+}
+
+static inline void crypto_alg_put(struct crypto_alg *alg)
+{
+	module_put(alg->cra_module);
+}
+
+struct crypto_alg *crypto_alg_lookup(const char *name)
+{
+	struct crypto_alg *q, *alg = NULL;
+
+	if (!name)
+		return NULL;
+	
+	down_read(&crypto_alg_sem);
+	
+	list_for_each_entry(q, &crypto_alg_list, cra_list) {
+		if (!(strcmp(q->cra_name, name))) {
+			if (crypto_alg_get(q))
+				alg = q;
+			break;
+		}
+	}
+	
+	up_read(&crypto_alg_sem);
+	return alg;
+}
+
+static int crypto_init_flags(struct crypto_tfm *tfm, u32 flags)
+{
+	tfm->crt_flags = 0;
+	
+	switch (crypto_tfm_alg_type(tfm)) {
+	case CRYPTO_ALG_TYPE_CIPHER:
+		return crypto_init_cipher_flags(tfm, flags);
+		
+	case CRYPTO_ALG_TYPE_DIGEST:
+		return crypto_init_digest_flags(tfm, flags);
+		
+	case CRYPTO_ALG_TYPE_COMPRESS:
+		return crypto_init_compress_flags(tfm, flags);
+	
+	default:
+		break;
+	}
+	
+	BUG();
+	return -EINVAL;
+}
+
+static int crypto_init_ops(struct crypto_tfm *tfm)
+{
+	switch (crypto_tfm_alg_type(tfm)) {
+	case CRYPTO_ALG_TYPE_CIPHER:
+		return crypto_init_cipher_ops(tfm);
+		
+	case CRYPTO_ALG_TYPE_DIGEST:
+		return crypto_init_digest_ops(tfm);
+		
+	case CRYPTO_ALG_TYPE_COMPRESS:
+		return crypto_init_compress_ops(tfm);
+	
+	default:
+		break;
+	}
+	
+	BUG();
+	return -EINVAL;
+}
+
+static void crypto_exit_ops(struct crypto_tfm *tfm)
+{
+	switch (crypto_tfm_alg_type(tfm)) {
+	case CRYPTO_ALG_TYPE_CIPHER:
+		crypto_exit_cipher_ops(tfm);
+		break;
+		
+	case CRYPTO_ALG_TYPE_DIGEST:
+		crypto_exit_digest_ops(tfm);
+		break;
+		
+	case CRYPTO_ALG_TYPE_COMPRESS:
+		crypto_exit_compress_ops(tfm);
+		break;
+	
+	default:
+		BUG();
+		
+	}
+}
+
+struct crypto_tfm *crypto_alloc_tfm(const char *name, u32 flags)
+{
+	struct crypto_tfm *tfm = NULL;
+	struct crypto_alg *alg;
+
+	alg = crypto_alg_mod_lookup(name);
+	if (alg == NULL)
+		goto out;
+	
+	tfm = kmalloc(sizeof(*tfm) + alg->cra_ctxsize, GFP_KERNEL);
+	if (tfm == NULL)
+		goto out_put;
+
+	memset(tfm, 0, sizeof(*tfm) + alg->cra_ctxsize);
+	
+	tfm->__crt_alg = alg;
+	
+	if (crypto_init_flags(tfm, flags))
+		goto out_free_tfm;
+		
+	if (crypto_init_ops(tfm)) {
+		crypto_exit_ops(tfm);
+		goto out_free_tfm;
+	}
+
+	goto out;
+
+out_free_tfm:
+	kfree(tfm);
+	tfm = NULL;
+out_put:
+	crypto_alg_put(alg);
+out:
+	return tfm;
+}
+
+void crypto_free_tfm(struct crypto_tfm *tfm)
+{
+	struct crypto_alg *alg = tfm->__crt_alg;
+	int size = sizeof(*tfm) + alg->cra_ctxsize;
+
+	crypto_exit_ops(tfm);
+	crypto_alg_put(alg);
+	memset(tfm, 0, size);
+	kfree(tfm);
+}
+
+int crypto_register_alg(struct crypto_alg *alg)
+{
+	int ret = 0;
+	struct crypto_alg *q;
+	
+	down_write(&crypto_alg_sem);
+	
+	list_for_each_entry(q, &crypto_alg_list, cra_list) {
+		if (!(strcmp(q->cra_name, alg->cra_name))) {
+			ret = -EEXIST;
+			goto out;
+		}
+	}
+	
+	list_add_tail(&alg->cra_list, &crypto_alg_list);
+out:	
+	up_write(&crypto_alg_sem);
+	return ret;
+}
+
+int crypto_unregister_alg(struct crypto_alg *alg)
+{
+	int ret = -ENOENT;
+	struct crypto_alg *q;
+	
+	BUG_ON(!alg->cra_module);
+	
+	down_write(&crypto_alg_sem);
+	list_for_each_entry(q, &crypto_alg_list, cra_list) {
+		if (alg == q) {
+			list_del(&alg->cra_list);
+			ret = 0;
+			goto out;
+		}
+	}
+out:	
+	up_write(&crypto_alg_sem);
+	return ret;
+}
+
+int crypto_alg_available(const char *name, u32 flags)
+{
+	int ret = 0;
+	struct crypto_alg *alg = crypto_alg_mod_lookup(name);
+	
+	if (alg) {
+		crypto_alg_put(alg);
+		ret = 1;
+	}
+	
+	return ret;
+}
+
+static int __init init_crypto(void)
+{
+	printk(KERN_INFO "Initializing Cryptographic API\n");
+	crypto_init_proc();
+	return 0;
+}
+
+__initcall(init_crypto);
+
+EXPORT_SYMBOL_GPL(crypto_register_alg);
+EXPORT_SYMBOL_GPL(crypto_unregister_alg);
+EXPORT_SYMBOL_GPL(crypto_alloc_tfm);
+EXPORT_SYMBOL_GPL(crypto_free_tfm);
+EXPORT_SYMBOL_GPL(crypto_alg_available);
