commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index d0b92c1cd6e9..16f6ba896fb6 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Cryptographic API.
  *
@@ -6,12 +7,6 @@
  * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>
  *               2002 Adam J. Richter <adam@yggdrasil.com>
  *               2004 Jean-Luc Cooke <jlcooke@certainkey.com>
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License as published by the Free
- * Software Foundation; either version 2 of the License, or (at your option)
- * any later version.
- *
  */
 
 #include <crypto/scatterwalk.h>

commit 8c30fbe63e4eff1b221f8db70ae5c48a9331eae0
Author: Eric Biggers <ebiggers@google.com>
Date:   Mon Jul 23 10:01:33 2018 -0700

    crypto: scatterwalk - remove 'chain' argument from scatterwalk_crypto_chain()
    
    All callers pass chain=0 to scatterwalk_crypto_chain().
    
    Remove this unneeded parameter.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index c16c94f88733..d0b92c1cd6e9 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -91,7 +91,7 @@ struct scatterlist *scatterwalk_ffwd(struct scatterlist dst[2],
 
 	sg_init_table(dst, 2);
 	sg_set_page(dst, sg_page(src), src->length - len, src->offset + len);
-	scatterwalk_crypto_chain(dst, sg_next(src), 0, 2);
+	scatterwalk_crypto_chain(dst, sg_next(src), 2);
 
 	return dst;
 }

commit c8467f7a3620698bf3c22f0e199b550fb611a8ae
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Nov 21 16:26:19 2016 +0800

    crypto: scatterwalk - Remove unnecessary aliasing check in map_and_copy
    
    The aliasing check in map_and_copy is no longer necessary because
    the IPsec ESP code no longer provides an IV that points into the
    actual request data.  As this check is now triggering BUG checks
    due to the vmalloced stack code, I'm removing it.
    
    Reported-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 52ce17a3dd63..c16c94f88733 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -68,10 +68,6 @@ void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
 
 	sg = scatterwalk_ffwd(tmp, sg, start);
 
-	if (sg_page(sg) == virt_to_page(buf) &&
-	    sg->offset == offset_in_page(buf))
-		return;
-
 	scatterwalk_start(&walk, sg);
 	scatterwalk_copychunks(buf, &walk, nbytes, out);
 	scatterwalk_done(&walk, out, 0);

commit ac02725812cb3a814cfe1fdc2a8a59db073e7e66
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 12 13:18:00 2016 +0800

    crypto: scatterwalk - Inline start/map/done
    
    This patch inlines the functions scatterwalk_start, scatterwalk_map
    and scatterwalk_done as they're all tiny and mostly used by the block
    cipher walker.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index ddffbb3ee712..52ce17a3dd63 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -18,8 +18,6 @@
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/module.h>
-#include <linux/pagemap.h>
-#include <linux/highmem.h>
 #include <linux/scatterlist.h>
 
 static inline void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
@@ -30,47 +28,6 @@ static inline void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
 	memcpy(dst, src, nbytes);
 }
 
-void scatterwalk_start(struct scatter_walk *walk, struct scatterlist *sg)
-{
-	walk->sg = sg;
-	walk->offset = sg->offset;
-}
-EXPORT_SYMBOL_GPL(scatterwalk_start);
-
-void *scatterwalk_map(struct scatter_walk *walk)
-{
-	return kmap_atomic(scatterwalk_page(walk)) +
-	       offset_in_page(walk->offset);
-}
-EXPORT_SYMBOL_GPL(scatterwalk_map);
-
-static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
-				 unsigned int more)
-{
-	if (out) {
-		struct page *page;
-
-		page = sg_page(walk->sg) + ((walk->offset - 1) >> PAGE_SHIFT);
-		/* Test ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE first as
-		 * PageSlab cannot be optimised away per se due to
-		 * use of volatile pointer.
-		 */
-		if (ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE && !PageSlab(page))
-			flush_dcache_page(page);
-	}
-
-	if (more && walk->offset >= walk->sg->offset + walk->sg->length)
-		scatterwalk_start(walk, sg_next(walk->sg));
-}
-
-void scatterwalk_done(struct scatter_walk *walk, int out, int more)
-{
-	if (!more || walk->offset >= walk->sg->offset + walk->sg->length ||
-	    !(walk->offset & (PAGE_SIZE - 1)))
-		scatterwalk_pagedone(walk, out, more);
-}
-EXPORT_SYMBOL_GPL(scatterwalk_done);
-
 void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 			    size_t nbytes, int out)
 {

commit 2ee732d57496b8365819dfb958bc1ff04fcd4cac
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 12 13:17:59 2016 +0800

    crypto: scatterwalk - Remove unnecessary BUG in scatterwalk_start
    
    Nothing bad will happen even if sg->length is zero, so there is
    no point in keeping this BUG_ON in scatterwalk_start.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 2ec5368ed649..ddffbb3ee712 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -33,9 +33,6 @@ static inline void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
 void scatterwalk_start(struct scatter_walk *walk, struct scatterlist *sg)
 {
 	walk->sg = sg;
-
-	BUG_ON(!sg->length);
-
 	walk->offset = sg->offset;
 }
 EXPORT_SYMBOL_GPL(scatterwalk_start);

commit 28cf86fafdd663cfcad3c5a5fe9869f1fa01b472
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 12 13:17:58 2016 +0800

    crypto: scatterwalk - Remove unnecessary advance in scatterwalk_pagedone
    
    The offset advance in scatterwalk_pagedone not only is unnecessary,
    but it was also buggy when it was needed by scatterwalk_copychunks.
    As the latter has long ago been fixed to call scatterwalk_advance
    directly, we can remove this unnecessary offset adjustment.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 52aae2974794..2ec5368ed649 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -62,12 +62,8 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 			flush_dcache_page(page);
 	}
 
-	if (more) {
-		walk->offset += PAGE_SIZE - 1;
-		walk->offset &= PAGE_MASK;
-		if (walk->offset >= walk->sg->offset + walk->sg->length)
-			scatterwalk_start(walk, sg_next(walk->sg));
-	}
+	if (more && walk->offset >= walk->sg->offset + walk->sg->length)
+		scatterwalk_start(walk, sg_next(walk->sg));
 }
 
 void scatterwalk_done(struct scatter_walk *walk, int out, int more)

commit 5f070e81bee35f1b7bd1477bb223a873ff657803
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 12 13:17:57 2016 +0800

    crypto: scatterwalk - Fix test in scatterwalk_done
    
    When there is more data to be processed, the current test in
    scatterwalk_done may prevent us from calling pagedone even when
    we should.
    
    In particular, if we're on an SG entry spanning multiple pages
    where the last page is not a full page, we will incorrectly skip
    calling pagedone on the second last page.
    
    This patch fixes this by adding a separate test for whether we've
    reached the end of a page.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index e124ce26feed..52aae2974794 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -72,7 +72,8 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 
 void scatterwalk_done(struct scatter_walk *walk, int out, int more)
 {
-	if (!(scatterwalk_pagelen(walk) & (PAGE_SIZE - 1)) || !more)
+	if (!more || walk->offset >= walk->sg->offset + walk->sg->length ||
+	    !(walk->offset & (PAGE_SIZE - 1)))
 		scatterwalk_pagedone(walk, out, more);
 }
 EXPORT_SYMBOL_GPL(scatterwalk_done);

commit 85eccddee401ae81067e763516889780b5545160
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 12 13:17:55 2016 +0800

    crypto: scatterwalk - Add no-copy support to copychunks
    
    The function ablkcipher_done_slow is pretty much identical to
    scatterwalk_copychunks except that it doesn't actually copy as
    the processing hasn't been completed yet.
    
    This patch allows scatterwalk_copychunks to be used in this case
    by specifying out == 2.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 03ca4aef1b9d..e124ce26feed 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -87,9 +87,11 @@ void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 		if (len_this_page > nbytes)
 			len_this_page = nbytes;
 
-		vaddr = scatterwalk_map(walk);
-		memcpy_dir(buf, vaddr, len_this_page, out);
-		scatterwalk_unmap(vaddr);
+		if (out != 2) {
+			vaddr = scatterwalk_map(walk);
+			memcpy_dir(buf, vaddr, len_this_page, out);
+			scatterwalk_unmap(vaddr);
+		}
 
 		scatterwalk_advance(walk, len_this_page);
 
@@ -99,7 +101,7 @@ void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 		buf += len_this_page;
 		nbytes -= len_this_page;
 
-		scatterwalk_pagedone(walk, out, 1);
+		scatterwalk_pagedone(walk, out & 1, 1);
 	}
 }
 EXPORT_SYMBOL_GPL(scatterwalk_copychunks);

commit 5506f53c7cc17c4ad5e69e5512a35faf77182986
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 12 13:17:53 2016 +0800

    crypto: scatterwalk - Remove scatterwalk_bytes_sglen
    
    This patch removes the now unused scatterwalk_bytes_sglen.  Anyone
    using this out-of-tree should switch over to sg_nents_for_len.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index ea5815c5e128..03ca4aef1b9d 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -125,28 +125,6 @@ void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
 }
 EXPORT_SYMBOL_GPL(scatterwalk_map_and_copy);
 
-int scatterwalk_bytes_sglen(struct scatterlist *sg, int num_bytes)
-{
-	int offset = 0, n = 0;
-
-	/* num_bytes is too small */
-	if (num_bytes < sg->length)
-		return -1;
-
-	do {
-		offset += sg->length;
-		n++;
-		sg = sg_next(sg);
-
-		/* num_bytes is too large */
-		if (unlikely(!sg && (num_bytes < offset)))
-			return -1;
-	} while (sg && (num_bytes > offset));
-
-	return n;
-}
-EXPORT_SYMBOL_GPL(scatterwalk_bytes_sglen);
-
 struct scatterlist *scatterwalk_ffwd(struct scatterlist dst[2],
 				     struct scatterlist *src,
 				     unsigned int len)

commit 160544075f2a4028209721723a51f16add7b08b9
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Jun 1 16:22:03 2015 +0800

    crypto: scatterwalk - Hide PageSlab call to optimise away flush_dcache_page
    
    On architectures where flush_dcache_page is not needed, we will
    end up generating all the code up to the PageSlab call.  This is
    because PageSlab operates on a volatile pointer and thus cannot
    be optimised away.
    
    This patch works around this by checking whether flush_dcache_page
    is needed before we call PageSlab which then allows PageSlab to be
    compiled awy.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 2ef9cbbc5dbf..ea5815c5e128 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -54,7 +54,11 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 		struct page *page;
 
 		page = sg_page(walk->sg) + ((walk->offset - 1) >> PAGE_SHIFT);
-		if (!PageSlab(page))
+		/* Test ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE first as
+		 * PageSlab cannot be optimised away per se due to
+		 * use of volatile pointer.
+		 */
+		if (ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE && !PageSlab(page))
 			flush_dcache_page(page);
 	}
 

commit fdaef75f66bba5999a94f3cd9156bf353ba2ef98
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed May 27 14:37:27 2015 +0800

    crypto: scatterwalk - Add missing sg_init_table to scatterwalk_ffwd
    
    We need to call sg_init_table as otherwise the first entry may
    inadvertently become the last.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 8690324d3aef..2ef9cbbc5dbf 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -158,6 +158,7 @@ struct scatterlist *scatterwalk_ffwd(struct scatterlist dst[2],
 		src = sg_next(src);
 	}
 
+	sg_init_table(dst, 2);
 	sg_set_page(dst, sg_page(src), src->length - len, src->offset + len);
 	scatterwalk_crypto_chain(dst, sg_next(src), 0, 2);
 

commit 74412fd5d71b6eda0beb302aa467da000f0d530c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu May 21 15:11:12 2015 +0800

    crypto: scatterwalk - Check for same address in map_and_copy
    
    This patch adds a check for in scatterwalk_map_and_copy to avoid
    copying from the same address to the same address.  This is going
    to be used for IV copying in AEAD IV generators.
    
    There is no provision for partial overlaps.
    
    This patch also uses the new scatterwalk_ffwd instead of doing
    it by hand in scatterwalk_map_and_copy.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index db920b59a6c3..8690324d3aef 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -104,22 +104,18 @@ void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
 			      unsigned int start, unsigned int nbytes, int out)
 {
 	struct scatter_walk walk;
-	unsigned int offset = 0;
+	struct scatterlist tmp[2];
 
 	if (!nbytes)
 		return;
 
-	for (;;) {
-		scatterwalk_start(&walk, sg);
-
-		if (start < offset + sg->length)
-			break;
+	sg = scatterwalk_ffwd(tmp, sg, start);
 
-		offset += sg->length;
-		sg = sg_next(sg);
-	}
+	if (sg_page(sg) == virt_to_page(buf) &&
+	    sg->offset == offset_in_page(buf))
+		return;
 
-	scatterwalk_advance(&walk, start - offset);
+	scatterwalk_start(&walk, sg);
 	scatterwalk_copychunks(buf, &walk, nbytes, out);
 	scatterwalk_done(&walk, out, 0);
 }

commit fc42bcba97bae738f905b83741134a63af7e6c02
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu May 21 15:10:59 2015 +0800

    crypto: scatterwalk - Add scatterwalk_ffwd helper
    
    This patch adds the scatterwalk_ffwd helper which can create an
    SG list that starts in the middle of an existing SG list.  The
    new list may either be part of the existing list or be a chain
    that latches onto part of the existing list.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 3bd749c7bb70..db920b59a6c3 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -146,3 +146,25 @@ int scatterwalk_bytes_sglen(struct scatterlist *sg, int num_bytes)
 	return n;
 }
 EXPORT_SYMBOL_GPL(scatterwalk_bytes_sglen);
+
+struct scatterlist *scatterwalk_ffwd(struct scatterlist dst[2],
+				     struct scatterlist *src,
+				     unsigned int len)
+{
+	for (;;) {
+		if (!len)
+			return src;
+
+		if (src->length > len)
+			break;
+
+		len -= src->length;
+		src = sg_next(src);
+	}
+
+	sg_set_page(dst, sg_page(src), src->length - len, src->offset + len);
+	scatterwalk_crypto_chain(dst, sg_next(src), 0, 2);
+
+	return dst;
+}
+EXPORT_SYMBOL_GPL(scatterwalk_ffwd);

commit 5be4d4c94b1f98b839344fda7a8752a4a09d0ef5
Author: Cristian Stoica <cristian.stoica@freescale.com>
Date:   Tue Jan 20 10:06:16 2015 +0200

    crypto: replace scatterwalk_sg_next with sg_next
    
    Modify crypto drivers to use the generic SG helper since
    both of them are equivalent and the one from crypto is redundant.
    
    See also:
      468577abe37ff7b453a9ac613e0ea155349203ae   reverted in
      b2ab4a57b018aafbba35bff088218f5cc3d2142e
    
    Signed-off-by: Cristian Stoica <cristian.stoica@freescale.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 79ca2278c2a3..3bd749c7bb70 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -62,7 +62,7 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 		walk->offset += PAGE_SIZE - 1;
 		walk->offset &= PAGE_MASK;
 		if (walk->offset >= walk->sg->offset + walk->sg->length)
-			scatterwalk_start(walk, scatterwalk_sg_next(walk->sg));
+			scatterwalk_start(walk, sg_next(walk->sg));
 	}
 }
 
@@ -116,7 +116,7 @@ void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
 			break;
 
 		offset += sg->length;
-		sg = scatterwalk_sg_next(sg);
+		sg = sg_next(sg);
 	}
 
 	scatterwalk_advance(&walk, start - offset);
@@ -136,7 +136,7 @@ int scatterwalk_bytes_sglen(struct scatterlist *sg, int num_bytes)
 	do {
 		offset += sg->length;
 		n++;
-		sg = scatterwalk_sg_next(sg);
+		sg = sg_next(sg);
 
 		/* num_bytes is too large */
 		if (unlikely(!sg && (num_bytes < offset)))

commit 257aff515409f9455edff3a946344e71baf9e116
Author: Joel Fernandes <joelf@ti.com>
Date:   Sat Aug 17 21:42:22 2013 -0500

    crypto: scatterwalk - Add support for calculating number of SG elements
    
    Crypto layer only passes nbytes to encrypt but in omap-aes driver we need to
    know number of SG elements to pass to dmaengine slave API.  We add function for
    the same to scatterwalk library.
    
    Signed-off-by: Joel Fernandes <joelf@ti.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 7281b8a93ad3..79ca2278c2a3 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -124,3 +124,25 @@ void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
 	scatterwalk_done(&walk, out, 0);
 }
 EXPORT_SYMBOL_GPL(scatterwalk_map_and_copy);
+
+int scatterwalk_bytes_sglen(struct scatterlist *sg, int num_bytes)
+{
+	int offset = 0, n = 0;
+
+	/* num_bytes is too small */
+	if (num_bytes < sg->length)
+		return -1;
+
+	do {
+		offset += sg->length;
+		n++;
+		sg = scatterwalk_sg_next(sg);
+
+		/* num_bytes is too large */
+		if (unlikely(!sg && (num_bytes < offset)))
+			return -1;
+	} while (sg && (num_bytes > offset));
+
+	return n;
+}
+EXPORT_SYMBOL_GPL(scatterwalk_bytes_sglen);

commit f0dfc0b0b7f3d961da8a98bcfccc8be9107a848b
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 23:14:17 2011 +0800

    crypto: remove the second argument of k[un]map_atomic()
    
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 41e529af0773..7281b8a93ad3 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -40,9 +40,9 @@ void scatterwalk_start(struct scatter_walk *walk, struct scatterlist *sg)
 }
 EXPORT_SYMBOL_GPL(scatterwalk_start);
 
-void *scatterwalk_map(struct scatter_walk *walk, int out)
+void *scatterwalk_map(struct scatter_walk *walk)
 {
-	return crypto_kmap(scatterwalk_page(walk), out) +
+	return kmap_atomic(scatterwalk_page(walk)) +
 	       offset_in_page(walk->offset);
 }
 EXPORT_SYMBOL_GPL(scatterwalk_map);
@@ -83,9 +83,9 @@ void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 		if (len_this_page > nbytes)
 			len_this_page = nbytes;
 
-		vaddr = scatterwalk_map(walk, out);
+		vaddr = scatterwalk_map(walk);
 		memcpy_dir(buf, vaddr, len_this_page, out);
-		scatterwalk_unmap(vaddr, out);
+		scatterwalk_unmap(vaddr);
 
 		scatterwalk_advance(walk, len_this_page);
 

commit 85c6201a80ce4464a52c58a5f5ea8de15a557a6f
Author: David S. Miller <davem@davemloft.net>
Date:   Wed May 19 14:06:29 2010 +1000

    crypto: scatterwalk - Fix scatterwalk_done() test
    
    We are done with the scattergather entry when the walk offset goes
    past sg->offset + sg->length, not when it crosses a page boundary.
    
    There is a similarly queer test in the second half of
    scatterwalk_pagedone() that probably needs some scrutiny.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 3de89a424401..41e529af0773 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -68,7 +68,7 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 
 void scatterwalk_done(struct scatter_walk *walk, int out, int more)
 {
-	if (!offset_in_page(walk->offset) || !more)
+	if (!(scatterwalk_pagelen(walk) & (PAGE_SIZE - 1)) || !more)
 		scatterwalk_pagedone(walk, out, more);
 }
 EXPORT_SYMBOL_GPL(scatterwalk_done);

commit 4f3e797ad07d52d34983354a77b365dfcd48c1b4
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Feb 9 14:22:14 2009 +1100

    crypto: scatterwalk - Avoid flush_dcache_page on slab pages
    
    It's illegal to call flush_dcache_page on slab pages on a number
    of architectures.  So this patch avoids doing so if PageSlab is
    true.
    
    In future we can move the flush_dcache_page call to those page
    cache users that actually need it.
    
    Reported-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 9aeeb52004a5..3de89a424401 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -54,7 +54,8 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 		struct page *page;
 
 		page = sg_page(walk->sg) + ((walk->offset - 1) >> PAGE_SHIFT);
-		flush_dcache_page(page);
+		if (!PageSlab(page))
+			flush_dcache_page(page);
 	}
 
 	if (more) {

commit 6e050778c5d08a97d5d98f7cb62bc503e872615c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Dec 14 00:44:11 2007 +0800

    [CRYPTO] scatterwalk: Handle zero nbytes in scatterwalk_map_and_copy
    
    It's better to return silently than crash and burn when someone feeds us
    a zero length.  In particular the null digest algorithm when used as part
    of authenc will do that to us.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 297e19d13c4e..9aeeb52004a5 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -105,6 +105,9 @@ void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
 	struct scatter_walk walk;
 	unsigned int offset = 0;
 
+	if (!nbytes)
+		return;
+
 	for (;;) {
 		scatterwalk_start(&walk, sg);
 

commit b2ab4a57b018aafbba35bff088218f5cc3d2142e
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Dec 5 20:59:25 2007 +1100

    [CRYPTO] scatterwalk: Restore custom sg chaining for now
    
    Unfortunately the generic chaining hasn't been ported to all architectures
    yet, and notably not s390.  So this patch restores the chainging that we've
    been using previously which does work everywhere.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 12d19019e178..297e19d13c4e 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -61,7 +61,7 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 		walk->offset += PAGE_SIZE - 1;
 		walk->offset &= PAGE_MASK;
 		if (walk->offset >= walk->sg->offset + walk->sg->length)
-			scatterwalk_start(walk, sg_next(walk->sg));
+			scatterwalk_start(walk, scatterwalk_sg_next(walk->sg));
 	}
 }
 
@@ -112,7 +112,7 @@ void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
 			break;
 
 		offset += sg->length;
-		sg = sg_next(sg);
+		sg = scatterwalk_sg_next(sg);
 	}
 
 	scatterwalk_advance(&walk, start - offset);

commit 42c271c6c538857cb13c5ead5184d264d745f675
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Dec 7 18:52:49 2007 +0800

    [CRYPTO] scatterwalk: Move scatterwalk.h to linux/crypto
    
    The scatterwalk infrastructure is used by algorithms so it needs to
    move out of crypto for future users that may live in drivers/crypto
    or asm/*/crypto.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 206c39a97e57..12d19019e178 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -13,6 +13,8 @@
  * any later version.
  *
  */
+
+#include <crypto/scatterwalk.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/module.h>
@@ -20,9 +22,6 @@
 #include <linux/highmem.h>
 #include <linux/scatterlist.h>
 
-#include "internal.h"
-#include "scatterwalk.h"
-
 static inline void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
 {
 	void *src = out ? buf : sgdata;

commit 468577abe37ff7b453a9ac613e0ea155349203ae
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Nov 15 12:08:45 2007 +0800

    [CRYPTO] scatterwalk: Use generic scatterlist chaining
    
    This patch converts the crypto scatterwalk code to use the generic
    scatterlist chaining rather the version specific to crypto.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index b9bbda0bb9f9..206c39a97e57 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -62,7 +62,7 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 		walk->offset += PAGE_SIZE - 1;
 		walk->offset &= PAGE_MASK;
 		if (walk->offset >= walk->sg->offset + walk->sg->length)
-			scatterwalk_start(walk, scatterwalk_sg_next(walk->sg));
+			scatterwalk_start(walk, sg_next(walk->sg));
 	}
 }
 

commit 78c2f0b8c285c5305b3e67b0595200541e15eb43
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Mon Oct 22 19:40:16 2007 +0200

    [SG] Update crypto/ to sg helpers
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index d6852c33cfb7..b9bbda0bb9f9 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -54,7 +54,7 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 	if (out) {
 		struct page *page;
 
-		page = walk->sg->page + ((walk->offset - 1) >> PAGE_SHIFT);
+		page = sg_page(walk->sg) + ((walk->offset - 1) >> PAGE_SHIFT);
 		flush_dcache_page(page);
 	}
 

commit ab83407e9ee35a4972457aa487be6a7a21afd715
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Wed May 9 08:58:32 2007 +0200

    crypto: don't pollute the global namespace with sg_next()
    
    It's a subsystem function, prefix it as such.
    
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 3052f6507f53..d6852c33cfb7 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -62,7 +62,7 @@ static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 		walk->offset += PAGE_SIZE - 1;
 		walk->offset &= PAGE_MASK;
 		if (walk->offset >= walk->sg->offset + walk->sg->length)
-			scatterwalk_start(walk, sg_next(walk->sg));
+			scatterwalk_start(walk, scatterwalk_sg_next(walk->sg));
 	}
 }
 

commit 70dec235d8ac8cfb56ed2a3597e7d6c5b801f018
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Sep 1 16:52:13 2007 +0800

    [CRYPTO] api: Kill crypto_km_types
    
    When scatterwalk is built as a module digest.c was broken because it
    requires the crypto_km_types structure which is in scatterwalk.  This
    patch removes the crypto_km_types structure by encoding the logic into
    crypto_kmap_type directly.
    
    In fact, this even saves a few bytes of code (not to mention the data
    structure itself) on i386 which is about the only place where it's
    needed.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index e93a8f6f35d4..3052f6507f53 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -23,14 +23,6 @@
 #include "internal.h"
 #include "scatterwalk.h"
 
-enum km_type crypto_km_types[] = {
-	KM_USER0,
-	KM_USER1,
-	KM_SOFTIRQ0,
-	KM_SOFTIRQ1,
-};
-EXPORT_SYMBOL_GPL(crypto_km_types);
-
 static inline void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
 {
 	void *src = out ? buf : sgdata;

commit 5fa0fea27461f5ff7fad07687618db08272e9502
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Aug 29 16:31:34 2007 +0800

    [CRYPTO] scatterwalk: Add scatterwalk_map_and_copy
    
    This patch adds the function scatterwalk_map_and_copy which reads or
    writes a chunk of data from a scatterlist at a given offset.  It will
    be used by authenc which would read/write the authentication data at
    the end of the cipher/plain text.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 81afd1790a1d..e93a8f6f35d4 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -107,3 +107,25 @@ void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 	}
 }
 EXPORT_SYMBOL_GPL(scatterwalk_copychunks);
+
+void scatterwalk_map_and_copy(void *buf, struct scatterlist *sg,
+			      unsigned int start, unsigned int nbytes, int out)
+{
+	struct scatter_walk walk;
+	unsigned int offset = 0;
+
+	for (;;) {
+		scatterwalk_start(&walk, sg);
+
+		if (start < offset + sg->length)
+			break;
+
+		offset += sg->length;
+		sg = sg_next(sg);
+	}
+
+	scatterwalk_advance(&walk, start - offset);
+	scatterwalk_copychunks(buf, &walk, nbytes, out);
+	scatterwalk_done(&walk, out, 0);
+}
+EXPORT_SYMBOL_GPL(scatterwalk_map_and_copy);

commit 9f1167272890c210399e6b8a32d7cf7295713f5d
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Mar 31 12:58:20 2007 +1000

    [CRYPTO] api: Flush the current page right than the next
    
    On platforms where flush_dcache_page is needed we're currently flushing
    the next page right than the one we've just processed.  This patch fixes
    the off-by-one error.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 0f76175f623f..81afd1790a1d 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -59,8 +59,12 @@ EXPORT_SYMBOL_GPL(scatterwalk_map);
 static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 				 unsigned int more)
 {
-	if (out)
-		flush_dcache_page(scatterwalk_page(walk));
+	if (out) {
+		struct page *page;
+
+		page = walk->sg->page + ((walk->offset - 1) >> PAGE_SHIFT);
+		flush_dcache_page(page);
+	}
 
 	if (more) {
 		walk->offset += PAGE_SIZE - 1;

commit 4ee531a3e661207d4b2174486b0f86017a3adb82
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Mar 31 12:16:20 2007 +1000

    [CRYPTO] api: Use the right value when advancing scatterwalk_copychunks
    
    In the scatterwalk_copychunks loop, We should be advancing by
    len_this_page and not nbytes.  The latter is the total length.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index a66423121773..0f76175f623f 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -91,7 +91,7 @@ void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 		memcpy_dir(buf, vaddr, len_this_page, out);
 		scatterwalk_unmap(vaddr, out);
 
-		scatterwalk_advance(walk, nbytes);
+		scatterwalk_advance(walk, len_this_page);
 
 		if (nbytes == len_this_page)
 			break;

commit f70ee5ec8fc59ba2d905e6daf0d395edf6fb461d
Author: J. Bruce Fields <bfields@citi.umich.edu>
Date:   Wed Mar 21 08:50:12 2007 +1100

    [CRYPTO] api: scatterwalk_copychunks() fails to advance through scatterlist
    
    In the loop in scatterwalk_copychunks(), if walk->offset is zero,
    then scatterwalk_pagedone rounds that up to the nearest page boundary:
    
                    walk->offset += PAGE_SIZE - 1;
                    walk->offset &= PAGE_MASK;
    
    which is a no-op in this case, so we don't advance to the next element
    of the scatterlist array:
    
                    if (walk->offset >= walk->sg->offset + walk->sg->length)
                            scatterwalk_start(walk, sg_next(walk->sg));
    
    and we end up copying the same data twice.
    
    It appears that other callers of scatterwalk_{page}done first advance
    walk->offset, so I believe that's the correct thing to do here.
    
    This caused a bug in NFS when run with krb5p security, which would
    cause some writes to fail with permissions errors--for example, writes
    of less than 8 bytes (the des blocksize) at the start of a file.
    
    A git-bisect shows the bug was originally introduced by
    5c64097aa0f6dc4f27718ef47ca9a12538d62860, first in 2.6.19-rc1.
    
    Signed-off-by: "J. Bruce Fields" <bfields@citi.umich.edu>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 35172d3f043b..a66423121773 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -91,6 +91,8 @@ void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 		memcpy_dir(buf, vaddr, len_this_page, out);
 		scatterwalk_unmap(vaddr, out);
 
+		scatterwalk_advance(walk, nbytes);
+
 		if (nbytes == len_this_page)
 			break;
 
@@ -99,7 +101,5 @@ void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 
 		scatterwalk_pagedone(walk, out, 1);
 	}
-
-	scatterwalk_advance(walk, nbytes);
 }
 EXPORT_SYMBOL_GPL(scatterwalk_copychunks);

commit 5c64097aa0f6dc4f27718ef47ca9a12538d62860
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Aug 12 21:56:17 2006 +1000

    [CRYPTO] scatterwalk: Prepare for block ciphers
    
    This patch prepares the scatterwalk code for use by the new block cipher
    type.
    
    Firstly it halves the size of scatter_walk on 32-bit platforms.  This
    is important as we allocate at least two of these objects on the stack
    for each block cipher operation.
    
    It also exports the symbols since the block cipher code can be built as
    a module.
    
    Finally there is a hack in scatterwalk_unmap that relies on progress
    being made.  Unfortunately, for hardware crypto we can't guarantee
    progress to be made since the hardware can fail.
    
    So this also gets rid of the hack by not advancing the address returned
    by scatterwalk_map.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 2953e2cc56f0..35172d3f043b 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -15,9 +15,11 @@
  */
 #include <linux/kernel.h>
 #include <linux/mm.h>
+#include <linux/module.h>
 #include <linux/pagemap.h>
 #include <linux/highmem.h>
-#include <asm/scatterlist.h>
+#include <linux/scatterlist.h>
+
 #include "internal.h"
 #include "scatterwalk.h"
 
@@ -27,88 +29,77 @@ enum km_type crypto_km_types[] = {
 	KM_SOFTIRQ0,
 	KM_SOFTIRQ1,
 };
+EXPORT_SYMBOL_GPL(crypto_km_types);
 
-static void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
+static inline void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
 {
-	if (out)
-		memcpy(sgdata, buf, nbytes);
-	else
-		memcpy(buf, sgdata, nbytes);
+	void *src = out ? buf : sgdata;
+	void *dst = out ? sgdata : buf;
+
+	memcpy(dst, src, nbytes);
 }
 
 void scatterwalk_start(struct scatter_walk *walk, struct scatterlist *sg)
 {
-	unsigned int rest_of_page;
-
 	walk->sg = sg;
 
-	walk->page = sg->page;
-	walk->len_this_segment = sg->length;
-
 	BUG_ON(!sg->length);
 
-	rest_of_page = PAGE_CACHE_SIZE - (sg->offset & (PAGE_CACHE_SIZE - 1));
-	walk->len_this_page = min(sg->length, rest_of_page);
 	walk->offset = sg->offset;
 }
+EXPORT_SYMBOL_GPL(scatterwalk_start);
 
-void scatterwalk_map(struct scatter_walk *walk, int out)
-{
-	walk->data = crypto_kmap(walk->page, out) + walk->offset;
-}
-
-static inline void scatterwalk_unmap(struct scatter_walk *walk, int out)
+void *scatterwalk_map(struct scatter_walk *walk, int out)
 {
-	/* walk->data may be pointing the first byte of the next page;
-	   however, we know we transfered at least one byte.  So,
-	   walk->data - 1 will be a virtual address in the mapped page. */
-	crypto_kunmap(walk->data - 1, out);
+	return crypto_kmap(scatterwalk_page(walk), out) +
+	       offset_in_page(walk->offset);
 }
+EXPORT_SYMBOL_GPL(scatterwalk_map);
 
 static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
 				 unsigned int more)
 {
 	if (out)
-		flush_dcache_page(walk->page);
+		flush_dcache_page(scatterwalk_page(walk));
 
 	if (more) {
-		walk->len_this_segment -= walk->len_this_page;
-
-		if (walk->len_this_segment) {
-			walk->page++;
-			walk->len_this_page = min(walk->len_this_segment,
-						  (unsigned)PAGE_CACHE_SIZE);
-			walk->offset = 0;
-		}
-		else
+		walk->offset += PAGE_SIZE - 1;
+		walk->offset &= PAGE_MASK;
+		if (walk->offset >= walk->sg->offset + walk->sg->length)
 			scatterwalk_start(walk, sg_next(walk->sg));
 	}
 }
 
 void scatterwalk_done(struct scatter_walk *walk, int out, int more)
 {
-	scatterwalk_unmap(walk, out);
-	if (walk->len_this_page == 0 || !more)
+	if (!offset_in_page(walk->offset) || !more)
 		scatterwalk_pagedone(walk, out, more);
 }
+EXPORT_SYMBOL_GPL(scatterwalk_done);
 
-/*
- * Do not call this unless the total length of all of the fragments
- * has been verified as multiple of the block size.
- */
-int scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
-			   size_t nbytes, int out)
+void scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
+			    size_t nbytes, int out)
 {
-	while (nbytes > walk->len_this_page) {
-		memcpy_dir(buf, walk->data, walk->len_this_page, out);
-		buf += walk->len_this_page;
-		nbytes -= walk->len_this_page;
+	for (;;) {
+		unsigned int len_this_page = scatterwalk_pagelen(walk);
+		u8 *vaddr;
+
+		if (len_this_page > nbytes)
+			len_this_page = nbytes;
+
+		vaddr = scatterwalk_map(walk, out);
+		memcpy_dir(buf, vaddr, len_this_page, out);
+		scatterwalk_unmap(vaddr, out);
+
+		if (nbytes == len_this_page)
+			break;
+
+		buf += len_this_page;
+		nbytes -= len_this_page;
 
-		scatterwalk_unmap(walk, out);
 		scatterwalk_pagedone(walk, out, 1);
-		scatterwalk_map(walk, out);
 	}
 
-	memcpy_dir(buf, walk->data, nbytes, out);
-	return nbytes;
+	scatterwalk_advance(walk, nbytes);
 }
+EXPORT_SYMBOL_GPL(scatterwalk_copychunks);

commit 1b8623545b42c03eb92e51b28c84acf4b8ba00a3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Dec 15 01:07:03 2005 -0500

    [PATCH] remove bogus asm/bug.h includes.
    
    A bunch of asm/bug.h includes are both not needed (since it will get
    pulled anyway) and bogus (since they are done too early).  Removed.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 47ac90e615f4..2953e2cc56f0 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -17,7 +17,6 @@
 #include <linux/mm.h>
 #include <linux/pagemap.h>
 #include <linux/highmem.h>
-#include <asm/bug.h>
 #include <asm/scatterlist.h>
 #include "internal.h"
 #include "scatterwalk.h"

commit c774e93e2152d0be2612739418689e6e6400f4eb
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Jul 6 13:51:31 2005 -0700

    [CRYPTO] Add plumbing for multi-block operations
    
    The VIA Padlock device is able to perform much better when multiple
    blocks are fed to it at once.  As this device offers an exceptional
    throughput rate it is worthwhile to optimise the infrastructure
    specifically for it.
    
    We shift the existing page-sized fast path down to the CBC/ECB functions.
    We can then replace the CBC/ECB functions with functions provided by the
    underlying algorithm that performs the multi-block operations.
    
    As a side-effect this improves the performance of large cipher operations
    for all existing algorithm implementations.  I've measured the gain to be
    around 5% for 3DES and 15% for AES.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
index 50c9461e8cc6..47ac90e615f4 100644
--- a/crypto/scatterwalk.c
+++ b/crypto/scatterwalk.c
@@ -100,7 +100,7 @@ void scatterwalk_done(struct scatter_walk *walk, int out, int more)
 int scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 			   size_t nbytes, int out)
 {
-	do {
+	while (nbytes > walk->len_this_page) {
 		memcpy_dir(buf, walk->data, walk->len_this_page, out);
 		buf += walk->len_this_page;
 		nbytes -= walk->len_this_page;
@@ -108,7 +108,7 @@ int scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
 		scatterwalk_unmap(walk, out);
 		scatterwalk_pagedone(walk, out, 1);
 		scatterwalk_map(walk, out);
-	} while (nbytes > walk->len_this_page);
+	}
 
 	memcpy_dir(buf, walk->data, nbytes, out);
 	return nbytes;

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/crypto/scatterwalk.c b/crypto/scatterwalk.c
new file mode 100644
index 000000000000..50c9461e8cc6
--- /dev/null
+++ b/crypto/scatterwalk.c
@@ -0,0 +1,115 @@
+/*
+ * Cryptographic API.
+ *
+ * Cipher operations.
+ *
+ * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>
+ *               2002 Adam J. Richter <adam@yggdrasil.com>
+ *               2004 Jean-Luc Cooke <jlcooke@certainkey.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option)
+ * any later version.
+ *
+ */
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/pagemap.h>
+#include <linux/highmem.h>
+#include <asm/bug.h>
+#include <asm/scatterlist.h>
+#include "internal.h"
+#include "scatterwalk.h"
+
+enum km_type crypto_km_types[] = {
+	KM_USER0,
+	KM_USER1,
+	KM_SOFTIRQ0,
+	KM_SOFTIRQ1,
+};
+
+static void memcpy_dir(void *buf, void *sgdata, size_t nbytes, int out)
+{
+	if (out)
+		memcpy(sgdata, buf, nbytes);
+	else
+		memcpy(buf, sgdata, nbytes);
+}
+
+void scatterwalk_start(struct scatter_walk *walk, struct scatterlist *sg)
+{
+	unsigned int rest_of_page;
+
+	walk->sg = sg;
+
+	walk->page = sg->page;
+	walk->len_this_segment = sg->length;
+
+	BUG_ON(!sg->length);
+
+	rest_of_page = PAGE_CACHE_SIZE - (sg->offset & (PAGE_CACHE_SIZE - 1));
+	walk->len_this_page = min(sg->length, rest_of_page);
+	walk->offset = sg->offset;
+}
+
+void scatterwalk_map(struct scatter_walk *walk, int out)
+{
+	walk->data = crypto_kmap(walk->page, out) + walk->offset;
+}
+
+static inline void scatterwalk_unmap(struct scatter_walk *walk, int out)
+{
+	/* walk->data may be pointing the first byte of the next page;
+	   however, we know we transfered at least one byte.  So,
+	   walk->data - 1 will be a virtual address in the mapped page. */
+	crypto_kunmap(walk->data - 1, out);
+}
+
+static void scatterwalk_pagedone(struct scatter_walk *walk, int out,
+				 unsigned int more)
+{
+	if (out)
+		flush_dcache_page(walk->page);
+
+	if (more) {
+		walk->len_this_segment -= walk->len_this_page;
+
+		if (walk->len_this_segment) {
+			walk->page++;
+			walk->len_this_page = min(walk->len_this_segment,
+						  (unsigned)PAGE_CACHE_SIZE);
+			walk->offset = 0;
+		}
+		else
+			scatterwalk_start(walk, sg_next(walk->sg));
+	}
+}
+
+void scatterwalk_done(struct scatter_walk *walk, int out, int more)
+{
+	scatterwalk_unmap(walk, out);
+	if (walk->len_this_page == 0 || !more)
+		scatterwalk_pagedone(walk, out, more);
+}
+
+/*
+ * Do not call this unless the total length of all of the fragments
+ * has been verified as multiple of the block size.
+ */
+int scatterwalk_copychunks(void *buf, struct scatter_walk *walk,
+			   size_t nbytes, int out)
+{
+	do {
+		memcpy_dir(buf, walk->data, walk->len_this_page, out);
+		buf += walk->len_this_page;
+		nbytes -= walk->len_this_page;
+
+		scatterwalk_unmap(walk, out);
+		scatterwalk_pagedone(walk, out, 1);
+		scatterwalk_map(walk, out);
+	} while (nbytes > walk->len_this_page);
+
+	memcpy_dir(buf, walk->data, nbytes, out);
+	return nbytes;
+}
