commit 4d2fa8b44b891f0da5ceda3e5a1402ccf0ab6f26
Merge: 8b68150883ca f3880a23564e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 20:57:08 2019 -0700

    Merge branch 'linus' of git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6
    
    Pull crypto updates from Herbert Xu:
     "Here is the crypto update for 5.3:
    
      API:
       - Test shash interface directly in testmgr
       - cra_driver_name is now mandatory
    
      Algorithms:
       - Replace arc4 crypto_cipher with library helper
       - Implement 5 way interleave for ECB, CBC and CTR on arm64
       - Add xxhash
       - Add continuous self-test on noise source to drbg
       - Update jitter RNG
    
      Drivers:
       - Add support for SHA204A random number generator
       - Add support for 7211 in iproc-rng200
       - Fix fuzz test failures in inside-secure
       - Fix fuzz test failures in talitos
       - Fix fuzz test failures in qat"
    
    * 'linus' of git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6: (143 commits)
      crypto: stm32/hash - remove interruptible condition for dma
      crypto: stm32/hash - Fix hmac issue more than 256 bytes
      crypto: stm32/crc32 - rename driver file
      crypto: amcc - remove memset after dma_alloc_coherent
      crypto: ccp - Switch to SPDX license identifiers
      crypto: ccp - Validate the the error value used to index error messages
      crypto: doc - Fix formatting of new crypto engine content
      crypto: doc - Add parameter documentation
      crypto: arm64/aes-ce - implement 5 way interleave for ECB, CBC and CTR
      crypto: arm64/aes-ce - add 5 way interleave routines
      crypto: talitos - drop icv_ool
      crypto: talitos - fix hash on SEC1.
      crypto: talitos - move struct talitos_edesc into talitos.h
      lib/scatterlist: Fix mapping iterator when sg->offset is greater than PAGE_SIZE
      crypto/NX: Set receive window credits to max number of CRBs in RxFIFO
      crypto: asymmetric_keys - select CRYPTO_HASH where needed
      crypto: serpent - mark __serpent_setkey_sbox noinline
      crypto: testmgr - dynamically allocate crypto_shash
      crypto: testmgr - dynamically allocate testvec_config
      crypto: talitos - eliminate unneeded 'done' functions at build time
      ...

commit d6ebf5286f8f94a254a8c90d4b9f2a8b076a8634
Author: Eric Biggers <ebiggers@google.com>
Date:   Sun Jun 2 22:40:57 2019 -0700

    crypto: make all generic algorithms set cra_driver_name
    
    Most generic crypto algorithms declare a driver name ending in
    "-generic".  The rest don't declare a driver name and instead rely on
    the crypto API automagically appending "-generic" upon registration.
    
    Having multiple conventions is unnecessarily confusing and makes it
    harder to grep for all generic algorithms in the kernel source tree.
    But also, allowing NULL driver names is problematic because sometimes
    people fail to set it, e.g. the case fixed by commit 417980364300
    ("crypto: cavium/zip - fix collision with generic cra_driver_name").
    
    Of course, people can also incorrectly name their drivers "-generic".
    But that's much easier to notice / grep for.
    
    Therefore, let's make cra_driver_name mandatory.  In preparation for
    this, this patch makes all generic algorithms set cra_driver_name.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index 2f062574fc8c..9327af0fe4b7 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -371,6 +371,7 @@ static struct shash_alg alg = {
 	.descsize	=	sizeof(struct rmd320_ctx),
 	.base		=	{
 		.cra_name	 =	"rmd320",
+		.cra_driver_name =	"rmd320-generic",
 		.cra_blocksize	 =	RMD320_BLOCK_SIZE,
 		.cra_module	 =	THIS_MODULE,
 	}

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index 2f062574fc8c..b2392ef7467b 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Cryptographic API.
  *
@@ -6,12 +7,6 @@
  * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC
  *
  * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License as published by the Free
- * Software Foundation; either version 2 of the License, or (at your option)
- * any later version.
- *
  */
 #include <crypto/internal/hash.h>
 #include <linux/init.h>

commit c4741b23059794bd99beef0f700103b0d983b3fd
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Apr 11 21:57:42 2019 -0700

    crypto: run initcalls for generic implementations earlier
    
    Use subsys_initcall for registration of all templates and generic
    algorithm implementations, rather than module_init.  Then change
    cryptomgr to use arch_initcall, to place it before the subsys_initcalls.
    
    This is needed so that when both a generic and optimized implementation
    of an algorithm are built into the kernel (not loadable modules), the
    generic implementation is registered before the optimized one.
    Otherwise, the self-tests for the optimized implementation are unable to
    allocate the generic implementation for the new comparison fuzz tests.
    
    Note that on arm, a side effect of this change is that self-tests for
    generic implementations may run before the unaligned access handler has
    been installed.  So, unaligned accesses will crash the kernel.  This is
    arguably a good thing as it makes it easier to detect that type of bug.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index 3ae1df5bb48c..2f062574fc8c 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -386,7 +386,7 @@ static void __exit rmd320_mod_fini(void)
 	crypto_unregister_shash(&alg);
 }
 
-module_init(rmd320_mod_init);
+subsys_initcall(rmd320_mod_init);
 module_exit(rmd320_mod_fini);
 
 MODULE_LICENSE("GPL");

commit a4789089937941959be6c18fa53e1fc0189257fd
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Wed Jul 18 12:19:08 2018 -0500

    crypto: rmd320 - use swap macro in rmd320_transform
    
    Make use of the swap macro and remove unnecessary variable *tmp*.
    This makes the code easier to read and maintain.
    
    This code was detected with the help of Coccinelle.
    
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index ab3cf93624d2..3ae1df5bb48c 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -53,7 +53,7 @@ struct rmd320_ctx {
 
 static void rmd320_transform(u32 *state, const __le32 *in)
 {
-	u32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee, tmp;
+	u32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee;
 
 	/* Initialize left lane */
 	aa = state[0];
@@ -106,7 +106,7 @@ static void rmd320_transform(u32 *state, const __le32 *in)
 	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[12],  6);
 
 	/* Swap contents of "a" registers */
-	tmp = aa; aa = aaa; aaa = tmp;
+	swap(aa, aaa);
 
 	/* round 2: left lane" */
 	ROUND(ee, aa, bb, cc, dd, F2, K2, in[7],   7);
@@ -145,7 +145,7 @@ static void rmd320_transform(u32 *state, const __le32 *in)
 	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[2],  11);
 
 	/* Swap contents of "b" registers */
-	tmp = bb; bb = bbb; bbb = tmp;
+	swap(bb, bbb);
 
 	/* round 3: left lane" */
 	ROUND(dd, ee, aa, bb, cc, F3, K3, in[3],  11);
@@ -184,7 +184,7 @@ static void rmd320_transform(u32 *state, const __le32 *in)
 	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[13],  5);
 
 	/* Swap contents of "c" registers */
-	tmp = cc; cc = ccc; ccc = tmp;
+	swap(cc, ccc);
 
 	/* round 4: left lane" */
 	ROUND(cc, dd, ee, aa, bb, F4, K4, in[1],  11);
@@ -223,7 +223,7 @@ static void rmd320_transform(u32 *state, const __le32 *in)
 	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[14],  8);
 
 	/* Swap contents of "d" registers */
-	tmp = dd; dd = ddd; ddd = tmp;
+	swap(dd, ddd);
 
 	/* round 5: left lane" */
 	ROUND(bb, cc, dd, ee, aa, F5, K5, in[4],   9);
@@ -262,7 +262,7 @@ static void rmd320_transform(u32 *state, const __le32 *in)
 	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[11], 11);
 
 	/* Swap contents of "e" registers */
-	tmp = ee; ee = eee; eee = tmp;
+	swap(ee, eee);
 
 	/* combine results */
 	state[0] += aa;

commit e50944e219f908968a6e01fbd0e8811a33bd5f04
Author: Eric Biggers <ebiggers@google.com>
Date:   Sat Jun 30 15:16:11 2018 -0700

    crypto: shash - remove useless setting of type flags
    
    Many shash algorithms set .cra_flags = CRYPTO_ALG_TYPE_SHASH.  But this
    is redundant with the C structure type ('struct shash_alg'), and
    crypto_register_shash() already sets the type flag automatically,
    clearing any type flag that was already there.  Apparently the useless
    assignment has just been copy+pasted around.
    
    So, remove the useless assignment from all the shash algorithms.
    
    This patch shouldn't change any actual behavior.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index e1315e4869e8..ab3cf93624d2 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -371,7 +371,6 @@ static struct shash_alg alg = {
 	.descsize	=	sizeof(struct rmd320_ctx),
 	.base		=	{
 		.cra_name	 =	"rmd320",
-		.cra_flags	 =	CRYPTO_ALG_TYPE_SHASH,
 		.cra_blocksize	 =	RMD320_BLOCK_SIZE,
 		.cra_module	 =	THIS_MODULE,
 	}

commit 52872f5288ea38ab9e2bb352a47b71051f7aefcc
Author: Geliang Tang <geliangtang@gmail.com>
Date:   Mon Aug 28 22:00:07 2017 +0800

    crypto: drop unnecessary return statements
    
    Fix checkpatch.pl warnings:
    
    WARNING: void function return statements are not generally useful
    FILE: crypto/rmd128.c:218:
    FILE: crypto/rmd160.c:261:
    FILE: crypto/rmd256.c:233:
    FILE: crypto/rmd320.c:280:
    FILE: crypto/tcrypt.c:385:
    FILE: drivers/crypto/ixp4xx_crypto.c:538:
    FILE: drivers/crypto/marvell/cesa.c:81:
    FILE: drivers/crypto/ux500/cryp/cryp_core.c:1755:
    
    Signed-off-by: Geliang Tang <geliangtang@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index 770f2cb369f8..e1315e4869e8 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -275,8 +275,6 @@ static void rmd320_transform(u32 *state, const __le32 *in)
 	state[7] += ccc;
 	state[8] += ddd;
 	state[9] += eee;
-
-	return;
 }
 
 static int rmd320_init(struct shash_desc *desc)

commit 5d26a105b5a73e5635eae0629b42fa0a90e07b7b
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Nov 20 17:05:53 2014 -0800

    crypto: prefix module autoloading with "crypto-"
    
    This prefixes all crypto module loading with "crypto-" so we never run
    the risk of exposing module auto-loading to userspace via a crypto API,
    as demonstrated by Mathias Krause:
    
    https://lkml.org/lkml/2013/3/4/70
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index 09f97dfdfbba..770f2cb369f8 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -395,3 +395,4 @@ module_exit(rmd320_mod_fini);
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Adrian-Ken Rueegsegger <ken@codelabs.ch>");
 MODULE_DESCRIPTION("RIPEMD-320 Message Digest");
+MODULE_ALIAS_CRYPTO("rmd320");

commit 3181c22587cfeb1fe415e55b2dd8b83c7cc33e44
Author: Adrian-Ken Rueegsegger <ken@codelabs.ch>
Date:   Tue Jan 4 15:35:51 2011 +1100

    crypto: ripemd - Set module author and update email address
    
    Signed-off-by: Adrian-Ken Rueegsegger <ken@codelabs.ch>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index 86becaba2f05..09f97dfdfbba 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -5,7 +5,7 @@
  *
  * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC
  *
- * Copyright (c) 2008 Adrian-Ken Rueegsegger <rueegsegger (at) swiss-it.ch>
+ * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License as published by the Free
@@ -393,4 +393,5 @@ module_init(rmd320_mod_init);
 module_exit(rmd320_mod_fini);
 
 MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Adrian-Ken Rueegsegger <ken@codelabs.ch>");
 MODULE_DESCRIPTION("RIPEMD-320 Message Digest");

commit 3b8efb4c4147094652570d7791a516d07b7df8c2
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Nov 8 10:11:09 2008 +0800

    crypto: rmd320 - Switch to shash
    
    This patch changes rmd320 to the new shash interface.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index b143d66e42c8..86becaba2f05 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -13,11 +13,10 @@
  * any later version.
  *
  */
+#include <crypto/internal/hash.h>
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/mm.h>
-#include <linux/crypto.h>
-#include <linux/cryptohash.h>
 #include <linux/types.h>
 #include <asm/byteorder.h>
 
@@ -280,9 +279,9 @@ static void rmd320_transform(u32 *state, const __le32 *in)
 	return;
 }
 
-static void rmd320_init(struct crypto_tfm *tfm)
+static int rmd320_init(struct shash_desc *desc)
 {
-	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
+	struct rmd320_ctx *rctx = shash_desc_ctx(desc);
 
 	rctx->byte_count = 0;
 
@@ -298,12 +297,14 @@ static void rmd320_init(struct crypto_tfm *tfm)
 	rctx->state[9] = RMD_H9;
 
 	memset(rctx->buffer, 0, sizeof(rctx->buffer));
+
+	return 0;
 }
 
-static void rmd320_update(struct crypto_tfm *tfm, const u8 *data,
-			  unsigned int len)
+static int rmd320_update(struct shash_desc *desc, const u8 *data,
+			 unsigned int len)
 {
-	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
+	struct rmd320_ctx *rctx = shash_desc_ctx(desc);
 	const u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);
 
 	rctx->byte_count += len;
@@ -312,7 +313,7 @@ static void rmd320_update(struct crypto_tfm *tfm, const u8 *data,
 	if (avail > len) {
 		memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
 		       data, len);
-		return;
+		goto out;
 	}
 
 	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
@@ -330,12 +331,15 @@ static void rmd320_update(struct crypto_tfm *tfm, const u8 *data,
 	}
 
 	memcpy(rctx->buffer, data, len);
+
+out:
+	return 0;
 }
 
 /* Add padding and return the message digest. */
-static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
+static int rmd320_final(struct shash_desc *desc, u8 *out)
 {
-	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
+	struct rmd320_ctx *rctx = shash_desc_ctx(desc);
 	u32 i, index, padlen;
 	__le64 bits;
 	__le32 *dst = (__le32 *)out;
@@ -346,10 +350,10 @@ static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
 	/* Pad out to 56 mod 64 */
 	index = rctx->byte_count & 0x3f;
 	padlen = (index < 56) ? (56 - index) : ((64+56) - index);
-	rmd320_update(tfm, padding, padlen);
+	rmd320_update(desc, padding, padlen);
 
 	/* Append length */
-	rmd320_update(tfm, (const u8 *)&bits, sizeof(bits));
+	rmd320_update(desc, (const u8 *)&bits, sizeof(bits));
 
 	/* Store state in digest */
 	for (i = 0; i < 10; i++)
@@ -357,31 +361,32 @@ static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
 
 	/* Wipe context */
 	memset(rctx, 0, sizeof(*rctx));
+
+	return 0;
 }
 
-static struct crypto_alg alg = {
-	.cra_name	 =	"rmd320",
-	.cra_driver_name =	"rmd320",
-	.cra_flags	 =	CRYPTO_ALG_TYPE_DIGEST,
-	.cra_blocksize	 =	RMD320_BLOCK_SIZE,
-	.cra_ctxsize	 =	sizeof(struct rmd320_ctx),
-	.cra_module	 =	THIS_MODULE,
-	.cra_list	 =	LIST_HEAD_INIT(alg.cra_list),
-	.cra_u		 =	{ .digest = {
-	.dia_digestsize	 =	RMD320_DIGEST_SIZE,
-	.dia_init	 =	rmd320_init,
-	.dia_update	 =	rmd320_update,
-	.dia_final	 =	rmd320_final } }
+static struct shash_alg alg = {
+	.digestsize	=	RMD320_DIGEST_SIZE,
+	.init		=	rmd320_init,
+	.update		=	rmd320_update,
+	.final		=	rmd320_final,
+	.descsize	=	sizeof(struct rmd320_ctx),
+	.base		=	{
+		.cra_name	 =	"rmd320",
+		.cra_flags	 =	CRYPTO_ALG_TYPE_SHASH,
+		.cra_blocksize	 =	RMD320_BLOCK_SIZE,
+		.cra_module	 =	THIS_MODULE,
+	}
 };
 
 static int __init rmd320_mod_init(void)
 {
-	return crypto_register_alg(&alg);
+	return crypto_register_shash(&alg);
 }
 
 static void __exit rmd320_mod_fini(void)
 {
-	crypto_unregister_alg(&alg);
+	crypto_unregister_shash(&alg);
 }
 
 module_init(rmd320_mod_init);
@@ -389,5 +394,3 @@ module_exit(rmd320_mod_fini);
 
 MODULE_LICENSE("GPL");
 MODULE_DESCRIPTION("RIPEMD-320 Message Digest");
-
-MODULE_ALIAS("rmd320");

commit caee16883a235b1b042282276859e7d5901fad21
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Fri Jul 4 19:48:58 2008 +0800

    crypto: rmd - sparse annotations
    
    Similar to the rmd128.c annotations, significantly cuts down on the
    noise.
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index dba03ecf5360..b143d66e42c8 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -26,7 +26,7 @@
 struct rmd320_ctx {
 	u64 byte_count;
 	u32 state[10];
-	u32 buffer[16];
+	__le32 buffer[16];
 };
 
 #define K1  RMD_K1
@@ -52,7 +52,7 @@ struct rmd320_ctx {
 	(c) = rol32((c), 10); \
 }
 
-static void rmd320_transform(u32 *state, u32 const *in)
+static void rmd320_transform(u32 *state, const __le32 *in)
 {
 	u32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee, tmp;
 
@@ -337,8 +337,8 @@ static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
 {
 	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
 	u32 i, index, padlen;
-	u64 bits;
-	u32 *dst = (u32 *)out;
+	__le64 bits;
+	__le32 *dst = (__le32 *)out;
 	static const u8 padding[64] = { 0x80, };
 
 	bits = cpu_to_le64(rctx->byte_count << 3);

commit 5cdcc22f25b0766fe16d5dd8e3b2efc91fa4da6e
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Jun 2 21:30:38 2008 +1000

    [CRYPTO] rmd: Use pointer form of endian swapping operations
    
    This patch converts the relevant code in the rmd implementations to
    use the pointer form of the endian swapping operations.  This allows
    certain architectures to generate more optimised code.  For example,
    on sparc64 this more than halves the CPU cycles on a typical hashing
    operation.
    
    Based on a patch by David Miller.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index 5b172f89e0c9..dba03ecf5360 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -47,7 +47,7 @@ struct rmd320_ctx {
 #define F5(x, y, z) (x ^ (y | ~z))
 
 #define ROUND(a, b, c, d, e, f, k, x, s)  { \
-	(a) += f((b), (c), (d)) + le32_to_cpu(x) + (k); \
+	(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \
 	(a) = rol32((a), (s)) + (e); \
 	(c) = rol32((c), 10); \
 }
@@ -353,7 +353,7 @@ static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
 
 	/* Store state in digest */
 	for (i = 0; i < 10; i++)
-		dst[i] = cpu_to_le32(rctx->state[i]);
+		dst[i] = cpu_to_le32p(&rctx->state[i]);
 
 	/* Wipe context */
 	memset(rctx, 0, sizeof(*rctx));

commit feedfdaa7bc02694c122d2d5246184248fb04513
Author: Adrian-Ken Rueegsegger <rueegsegger@swiss-it.ch>
Date:   Mon May 26 20:54:34 2008 +1000

    [CRYPTO] rmd320: Fix endian issues
    
    This patch fixes endian issues making rmd320 work
    properly on big-endian machines.
    
    Signed-off-by: Adrian-Ken Rueegsegger <rueegsegger@swiss-it.ch>
    Acked-by: Sebastian Siewior <sebastian@breakpoint.cc>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
index b39c0543a8fa..5b172f89e0c9 100644
--- a/crypto/rmd320.c
+++ b/crypto/rmd320.c
@@ -47,7 +47,7 @@ struct rmd320_ctx {
 #define F5(x, y, z) (x ^ (y | ~z))
 
 #define ROUND(a, b, c, d, e, f, k, x, s)  { \
-	(a) += f((b), (c), (d)) + (x) + (k); \
+	(a) += f((b), (c), (d)) + le32_to_cpu(x) + (k); \
 	(a) = rol32((a), (s)) + (e); \
 	(c) = rol32((c), 10); \
 }
@@ -280,28 +280,6 @@ static void rmd320_transform(u32 *state, u32 const *in)
 	return;
 }
 
-static inline void le32_to_cpu_array(u32 *buf, unsigned int words)
-{
-	while (words--) {
-		le32_to_cpus(buf);
-		buf++;
-	}
-}
-
-static inline void cpu_to_le32_array(u32 *buf, unsigned int words)
-{
-	while (words--) {
-		cpu_to_le32s(buf);
-		buf++;
-	}
-}
-
-static inline void rmd320_transform_helper(struct rmd320_ctx *ctx)
-{
-	le32_to_cpu_array(ctx->buffer, sizeof(ctx->buffer) / sizeof(u32));
-	rmd320_transform(ctx->state, ctx->buffer);
-}
-
 static void rmd320_init(struct crypto_tfm *tfm)
 {
 	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
@@ -340,13 +318,13 @@ static void rmd320_update(struct crypto_tfm *tfm, const u8 *data,
 	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
 	       data, avail);
 
-	rmd320_transform_helper(rctx);
+	rmd320_transform(rctx->state, rctx->buffer);
 	data += avail;
 	len -= avail;
 
 	while (len >= sizeof(rctx->buffer)) {
 		memcpy(rctx->buffer, data, sizeof(rctx->buffer));
-		rmd320_transform_helper(rctx);
+		rmd320_transform(rctx->state, rctx->buffer);
 		data += sizeof(rctx->buffer);
 		len -= sizeof(rctx->buffer);
 	}
@@ -358,10 +336,12 @@ static void rmd320_update(struct crypto_tfm *tfm, const u8 *data,
 static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
 {
 	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
-	u32 index, padlen;
+	u32 i, index, padlen;
 	u64 bits;
+	u32 *dst = (u32 *)out;
 	static const u8 padding[64] = { 0x80, };
-	bits = rctx->byte_count << 3;
+
+	bits = cpu_to_le64(rctx->byte_count << 3);
 
 	/* Pad out to 56 mod 64 */
 	index = rctx->byte_count & 0x3f;
@@ -372,7 +352,8 @@ static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
 	rmd320_update(tfm, (const u8 *)&bits, sizeof(bits));
 
 	/* Store state in digest */
-	memcpy(out, rctx->state, sizeof(rctx->state));
+	for (i = 0; i < 10; i++)
+		dst[i] = cpu_to_le32(rctx->state[i]);
 
 	/* Wipe context */
 	memset(rctx, 0, sizeof(*rctx));

commit c555c28d9da517579085a00fc80e725b0b5d9fce
Author: Adrian-Ken Rueegsegger <rueegsegger@swiss-it.ch>
Date:   Fri May 9 21:27:02 2008 +0800

    [CRYPTO] ripemd: Add support for RIPEMD-256 and RIPEMD-320
    
    This patch adds support for the extended RIPEMD hash
    algorithms RIPEMD-256 and RIPEMD-320.
    
    Signed-off-by: Adrian-Ken Rueegsegger <rueegsegger@swiss-it.ch>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/crypto/rmd320.c b/crypto/rmd320.c
new file mode 100644
index 000000000000..b39c0543a8fa
--- /dev/null
+++ b/crypto/rmd320.c
@@ -0,0 +1,412 @@
+/*
+ * Cryptographic API.
+ *
+ * RIPEMD-320 - RACE Integrity Primitives Evaluation Message Digest.
+ *
+ * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC
+ *
+ * Copyright (c) 2008 Adrian-Ken Rueegsegger <rueegsegger (at) swiss-it.ch>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option)
+ * any later version.
+ *
+ */
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/mm.h>
+#include <linux/crypto.h>
+#include <linux/cryptohash.h>
+#include <linux/types.h>
+#include <asm/byteorder.h>
+
+#include "ripemd.h"
+
+struct rmd320_ctx {
+	u64 byte_count;
+	u32 state[10];
+	u32 buffer[16];
+};
+
+#define K1  RMD_K1
+#define K2  RMD_K2
+#define K3  RMD_K3
+#define K4  RMD_K4
+#define K5  RMD_K5
+#define KK1 RMD_K6
+#define KK2 RMD_K7
+#define KK3 RMD_K8
+#define KK4 RMD_K9
+#define KK5 RMD_K1
+
+#define F1(x, y, z) (x ^ y ^ z)		/* XOR */
+#define F2(x, y, z) (z ^ (x & (y ^ z)))	/* x ? y : z */
+#define F3(x, y, z) ((x | ~y) ^ z)
+#define F4(x, y, z) (y ^ (z & (x ^ y)))	/* z ? x : y */
+#define F5(x, y, z) (x ^ (y | ~z))
+
+#define ROUND(a, b, c, d, e, f, k, x, s)  { \
+	(a) += f((b), (c), (d)) + (x) + (k); \
+	(a) = rol32((a), (s)) + (e); \
+	(c) = rol32((c), 10); \
+}
+
+static void rmd320_transform(u32 *state, u32 const *in)
+{
+	u32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee, tmp;
+
+	/* Initialize left lane */
+	aa = state[0];
+	bb = state[1];
+	cc = state[2];
+	dd = state[3];
+	ee = state[4];
+
+	/* Initialize right lane */
+	aaa = state[5];
+	bbb = state[6];
+	ccc = state[7];
+	ddd = state[8];
+	eee = state[9];
+
+	/* round 1: left lane */
+	ROUND(aa, bb, cc, dd, ee, F1, K1, in[0],  11);
+	ROUND(ee, aa, bb, cc, dd, F1, K1, in[1],  14);
+	ROUND(dd, ee, aa, bb, cc, F1, K1, in[2],  15);
+	ROUND(cc, dd, ee, aa, bb, F1, K1, in[3],  12);
+	ROUND(bb, cc, dd, ee, aa, F1, K1, in[4],   5);
+	ROUND(aa, bb, cc, dd, ee, F1, K1, in[5],   8);
+	ROUND(ee, aa, bb, cc, dd, F1, K1, in[6],   7);
+	ROUND(dd, ee, aa, bb, cc, F1, K1, in[7],   9);
+	ROUND(cc, dd, ee, aa, bb, F1, K1, in[8],  11);
+	ROUND(bb, cc, dd, ee, aa, F1, K1, in[9],  13);
+	ROUND(aa, bb, cc, dd, ee, F1, K1, in[10], 14);
+	ROUND(ee, aa, bb, cc, dd, F1, K1, in[11], 15);
+	ROUND(dd, ee, aa, bb, cc, F1, K1, in[12],  6);
+	ROUND(cc, dd, ee, aa, bb, F1, K1, in[13],  7);
+	ROUND(bb, cc, dd, ee, aa, F1, K1, in[14],  9);
+	ROUND(aa, bb, cc, dd, ee, F1, K1, in[15],  8);
+
+	/* round 1: right lane */
+	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[5],   8);
+	ROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[14],  9);
+	ROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[7],   9);
+	ROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[0],  11);
+	ROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[9],  13);
+	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[2],  15);
+	ROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[11], 15);
+	ROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[4],   5);
+	ROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[13],  7);
+	ROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[6],   7);
+	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[15],  8);
+	ROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[8],  11);
+	ROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[1],  14);
+	ROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[10], 14);
+	ROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[3],  12);
+	ROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[12],  6);
+
+	/* Swap contents of "a" registers */
+	tmp = aa; aa = aaa; aaa = tmp;
+
+	/* round 2: left lane" */
+	ROUND(ee, aa, bb, cc, dd, F2, K2, in[7],   7);
+	ROUND(dd, ee, aa, bb, cc, F2, K2, in[4],   6);
+	ROUND(cc, dd, ee, aa, bb, F2, K2, in[13],  8);
+	ROUND(bb, cc, dd, ee, aa, F2, K2, in[1],  13);
+	ROUND(aa, bb, cc, dd, ee, F2, K2, in[10], 11);
+	ROUND(ee, aa, bb, cc, dd, F2, K2, in[6],   9);
+	ROUND(dd, ee, aa, bb, cc, F2, K2, in[15],  7);
+	ROUND(cc, dd, ee, aa, bb, F2, K2, in[3],  15);
+	ROUND(bb, cc, dd, ee, aa, F2, K2, in[12],  7);
+	ROUND(aa, bb, cc, dd, ee, F2, K2, in[0],  12);
+	ROUND(ee, aa, bb, cc, dd, F2, K2, in[9],  15);
+	ROUND(dd, ee, aa, bb, cc, F2, K2, in[5],   9);
+	ROUND(cc, dd, ee, aa, bb, F2, K2, in[2],  11);
+	ROUND(bb, cc, dd, ee, aa, F2, K2, in[14],  7);
+	ROUND(aa, bb, cc, dd, ee, F2, K2, in[11], 13);
+	ROUND(ee, aa, bb, cc, dd, F2, K2, in[8],  12);
+
+	/* round 2: right lane */
+	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[6],   9);
+	ROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[11], 13);
+	ROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[3],  15);
+	ROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[7],   7);
+	ROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[0],  12);
+	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[13],  8);
+	ROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[5],   9);
+	ROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[10], 11);
+	ROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[14],  7);
+	ROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[15],  7);
+	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[8],  12);
+	ROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[12],  7);
+	ROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[4],   6);
+	ROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[9],  15);
+	ROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[1],  13);
+	ROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[2],  11);
+
+	/* Swap contents of "b" registers */
+	tmp = bb; bb = bbb; bbb = tmp;
+
+	/* round 3: left lane" */
+	ROUND(dd, ee, aa, bb, cc, F3, K3, in[3],  11);
+	ROUND(cc, dd, ee, aa, bb, F3, K3, in[10], 13);
+	ROUND(bb, cc, dd, ee, aa, F3, K3, in[14],  6);
+	ROUND(aa, bb, cc, dd, ee, F3, K3, in[4],   7);
+	ROUND(ee, aa, bb, cc, dd, F3, K3, in[9],  14);
+	ROUND(dd, ee, aa, bb, cc, F3, K3, in[15],  9);
+	ROUND(cc, dd, ee, aa, bb, F3, K3, in[8],  13);
+	ROUND(bb, cc, dd, ee, aa, F3, K3, in[1],  15);
+	ROUND(aa, bb, cc, dd, ee, F3, K3, in[2],  14);
+	ROUND(ee, aa, bb, cc, dd, F3, K3, in[7],   8);
+	ROUND(dd, ee, aa, bb, cc, F3, K3, in[0],  13);
+	ROUND(cc, dd, ee, aa, bb, F3, K3, in[6],   6);
+	ROUND(bb, cc, dd, ee, aa, F3, K3, in[13],  5);
+	ROUND(aa, bb, cc, dd, ee, F3, K3, in[11], 12);
+	ROUND(ee, aa, bb, cc, dd, F3, K3, in[5],   7);
+	ROUND(dd, ee, aa, bb, cc, F3, K3, in[12],  5);
+
+	/* round 3: right lane */
+	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[15],  9);
+	ROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[5],   7);
+	ROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[1],  15);
+	ROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[3],  11);
+	ROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[7],   8);
+	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[14],  6);
+	ROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[6],   6);
+	ROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[9],  14);
+	ROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[11], 12);
+	ROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[8],  13);
+	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[12],  5);
+	ROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[2],  14);
+	ROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[10], 13);
+	ROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[0],  13);
+	ROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[4],   7);
+	ROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[13],  5);
+
+	/* Swap contents of "c" registers */
+	tmp = cc; cc = ccc; ccc = tmp;
+
+	/* round 4: left lane" */
+	ROUND(cc, dd, ee, aa, bb, F4, K4, in[1],  11);
+	ROUND(bb, cc, dd, ee, aa, F4, K4, in[9],  12);
+	ROUND(aa, bb, cc, dd, ee, F4, K4, in[11], 14);
+	ROUND(ee, aa, bb, cc, dd, F4, K4, in[10], 15);
+	ROUND(dd, ee, aa, bb, cc, F4, K4, in[0],  14);
+	ROUND(cc, dd, ee, aa, bb, F4, K4, in[8],  15);
+	ROUND(bb, cc, dd, ee, aa, F4, K4, in[12],  9);
+	ROUND(aa, bb, cc, dd, ee, F4, K4, in[4],   8);
+	ROUND(ee, aa, bb, cc, dd, F4, K4, in[13],  9);
+	ROUND(dd, ee, aa, bb, cc, F4, K4, in[3],  14);
+	ROUND(cc, dd, ee, aa, bb, F4, K4, in[7],   5);
+	ROUND(bb, cc, dd, ee, aa, F4, K4, in[15],  6);
+	ROUND(aa, bb, cc, dd, ee, F4, K4, in[14],  8);
+	ROUND(ee, aa, bb, cc, dd, F4, K4, in[5],   6);
+	ROUND(dd, ee, aa, bb, cc, F4, K4, in[6],   5);
+	ROUND(cc, dd, ee, aa, bb, F4, K4, in[2],  12);
+
+	/* round 4: right lane */
+	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[8],  15);
+	ROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[6],   5);
+	ROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[4],   8);
+	ROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[1],  11);
+	ROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[3],  14);
+	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[11], 14);
+	ROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[15],  6);
+	ROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[0],  14);
+	ROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[5],   6);
+	ROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[12],  9);
+	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[2],  12);
+	ROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[13],  9);
+	ROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[9],  12);
+	ROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[7],   5);
+	ROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[10], 15);
+	ROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[14],  8);
+
+	/* Swap contents of "d" registers */
+	tmp = dd; dd = ddd; ddd = tmp;
+
+	/* round 5: left lane" */
+	ROUND(bb, cc, dd, ee, aa, F5, K5, in[4],   9);
+	ROUND(aa, bb, cc, dd, ee, F5, K5, in[0],  15);
+	ROUND(ee, aa, bb, cc, dd, F5, K5, in[5],   5);
+	ROUND(dd, ee, aa, bb, cc, F5, K5, in[9],  11);
+	ROUND(cc, dd, ee, aa, bb, F5, K5, in[7],   6);
+	ROUND(bb, cc, dd, ee, aa, F5, K5, in[12],  8);
+	ROUND(aa, bb, cc, dd, ee, F5, K5, in[2],  13);
+	ROUND(ee, aa, bb, cc, dd, F5, K5, in[10], 12);
+	ROUND(dd, ee, aa, bb, cc, F5, K5, in[14],  5);
+	ROUND(cc, dd, ee, aa, bb, F5, K5, in[1],  12);
+	ROUND(bb, cc, dd, ee, aa, F5, K5, in[3],  13);
+	ROUND(aa, bb, cc, dd, ee, F5, K5, in[8],  14);
+	ROUND(ee, aa, bb, cc, dd, F5, K5, in[11], 11);
+	ROUND(dd, ee, aa, bb, cc, F5, K5, in[6],   8);
+	ROUND(cc, dd, ee, aa, bb, F5, K5, in[15],  5);
+	ROUND(bb, cc, dd, ee, aa, F5, K5, in[13],  6);
+
+	/* round 5: right lane */
+	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[12],  8);
+	ROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[15],  5);
+	ROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[10], 12);
+	ROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[4],   9);
+	ROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[1],  12);
+	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[5],   5);
+	ROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[8],  14);
+	ROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[7],   6);
+	ROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[6],   8);
+	ROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[2],  13);
+	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[13],  6);
+	ROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[14],  5);
+	ROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[0],  15);
+	ROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[3],  13);
+	ROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[9],  11);
+	ROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[11], 11);
+
+	/* Swap contents of "e" registers */
+	tmp = ee; ee = eee; eee = tmp;
+
+	/* combine results */
+	state[0] += aa;
+	state[1] += bb;
+	state[2] += cc;
+	state[3] += dd;
+	state[4] += ee;
+	state[5] += aaa;
+	state[6] += bbb;
+	state[7] += ccc;
+	state[8] += ddd;
+	state[9] += eee;
+
+	return;
+}
+
+static inline void le32_to_cpu_array(u32 *buf, unsigned int words)
+{
+	while (words--) {
+		le32_to_cpus(buf);
+		buf++;
+	}
+}
+
+static inline void cpu_to_le32_array(u32 *buf, unsigned int words)
+{
+	while (words--) {
+		cpu_to_le32s(buf);
+		buf++;
+	}
+}
+
+static inline void rmd320_transform_helper(struct rmd320_ctx *ctx)
+{
+	le32_to_cpu_array(ctx->buffer, sizeof(ctx->buffer) / sizeof(u32));
+	rmd320_transform(ctx->state, ctx->buffer);
+}
+
+static void rmd320_init(struct crypto_tfm *tfm)
+{
+	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
+
+	rctx->byte_count = 0;
+
+	rctx->state[0] = RMD_H0;
+	rctx->state[1] = RMD_H1;
+	rctx->state[2] = RMD_H2;
+	rctx->state[3] = RMD_H3;
+	rctx->state[4] = RMD_H4;
+	rctx->state[5] = RMD_H5;
+	rctx->state[6] = RMD_H6;
+	rctx->state[7] = RMD_H7;
+	rctx->state[8] = RMD_H8;
+	rctx->state[9] = RMD_H9;
+
+	memset(rctx->buffer, 0, sizeof(rctx->buffer));
+}
+
+static void rmd320_update(struct crypto_tfm *tfm, const u8 *data,
+			  unsigned int len)
+{
+	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
+	const u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);
+
+	rctx->byte_count += len;
+
+	/* Enough space in buffer? If so copy and we're done */
+	if (avail > len) {
+		memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
+		       data, len);
+		return;
+	}
+
+	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
+	       data, avail);
+
+	rmd320_transform_helper(rctx);
+	data += avail;
+	len -= avail;
+
+	while (len >= sizeof(rctx->buffer)) {
+		memcpy(rctx->buffer, data, sizeof(rctx->buffer));
+		rmd320_transform_helper(rctx);
+		data += sizeof(rctx->buffer);
+		len -= sizeof(rctx->buffer);
+	}
+
+	memcpy(rctx->buffer, data, len);
+}
+
+/* Add padding and return the message digest. */
+static void rmd320_final(struct crypto_tfm *tfm, u8 *out)
+{
+	struct rmd320_ctx *rctx = crypto_tfm_ctx(tfm);
+	u32 index, padlen;
+	u64 bits;
+	static const u8 padding[64] = { 0x80, };
+	bits = rctx->byte_count << 3;
+
+	/* Pad out to 56 mod 64 */
+	index = rctx->byte_count & 0x3f;
+	padlen = (index < 56) ? (56 - index) : ((64+56) - index);
+	rmd320_update(tfm, padding, padlen);
+
+	/* Append length */
+	rmd320_update(tfm, (const u8 *)&bits, sizeof(bits));
+
+	/* Store state in digest */
+	memcpy(out, rctx->state, sizeof(rctx->state));
+
+	/* Wipe context */
+	memset(rctx, 0, sizeof(*rctx));
+}
+
+static struct crypto_alg alg = {
+	.cra_name	 =	"rmd320",
+	.cra_driver_name =	"rmd320",
+	.cra_flags	 =	CRYPTO_ALG_TYPE_DIGEST,
+	.cra_blocksize	 =	RMD320_BLOCK_SIZE,
+	.cra_ctxsize	 =	sizeof(struct rmd320_ctx),
+	.cra_module	 =	THIS_MODULE,
+	.cra_list	 =	LIST_HEAD_INIT(alg.cra_list),
+	.cra_u		 =	{ .digest = {
+	.dia_digestsize	 =	RMD320_DIGEST_SIZE,
+	.dia_init	 =	rmd320_init,
+	.dia_update	 =	rmd320_update,
+	.dia_final	 =	rmd320_final } }
+};
+
+static int __init rmd320_mod_init(void)
+{
+	return crypto_register_alg(&alg);
+}
+
+static void __exit rmd320_mod_fini(void)
+{
+	crypto_unregister_alg(&alg);
+}
+
+module_init(rmd320_mod_init);
+module_exit(rmd320_mod_fini);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("RIPEMD-320 Message Digest");
+
+MODULE_ALIAS("rmd320");
