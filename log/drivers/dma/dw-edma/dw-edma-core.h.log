commit fc6f5d0a4983e2ba9451cc1377a8da5a82cdc52d
Author: Alan Mikhak <alan.mikhak@sifive.com>
Date:   Wed Apr 15 10:27:09 2020 -0700

    dmaengine: dw-edma: Decouple dw-edma-core.c from struct pci_dev
    
    Decouple dw-edma-core.c from struct pci_dev as a step toward integration
    of dw-edma with pci-epf-test so the latter can initiate dma operations
    locally from the endpoint side. A barrier to such integration is the
    dependency of dw_edma_probe() and other functions in dw-edma-core.c on
    struct pci_dev.
    
    The Synopsys DesignWare dw-edma driver was designed to run on host side
    of PCIe link to initiate DMA operations remotely using eDMA channels of
    PCIe controller on the endpoint side. This can be inferred from seeing
    that dw-edma uses struct pci_dev and accesses hardware registers of dma
    channels across the bus using BAR0 and BAR2.
    
    The ops field of struct dw_edma in dw-edma-core.h is currenty undefined:
    
    const struct dw_edma_core_ops   *ops;
    
    However, the kernel builds without failure even when dw-edma driver is
    enabled. Instead of removing the currently undefined and usued ops field,
    define struct dw_edma_core_ops and use the ops field to decouple
    dw-edma-core.c from struct pci_dev.
    
    Signed-off-by: Alan Mikhak <alan.mikhak@sifive.com>
    Acked-by: Gustavo Pimentel <gustavo.pimentel@synopsys.com>
    Link: https://lore.kernel.org/r/1586971629-30196-1-git-send-email-alan.mikhak@sifive.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/dw-edma/dw-edma-core.h b/drivers/dma/dw-edma/dw-edma-core.h
index 4e5f9f6e901b..31fc50d31792 100644
--- a/drivers/dma/dw-edma/dw-edma-core.h
+++ b/drivers/dma/dw-edma/dw-edma-core.h
@@ -103,6 +103,10 @@ struct dw_edma_irq {
 	struct dw_edma			*dw;
 };
 
+struct dw_edma_core_ops {
+	int	(*irq_vector)(struct device *dev, unsigned int nr);
+};
+
 struct dw_edma {
 	char				name[20];
 

commit 756c3ef93492af382c541e039c1417b96a3d335e
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Jul 22 14:44:44 2019 +0200

    dmaengine: dw-edma: fix __iomem type confusion
    
    The new driver mixes up dma_addr_t and __iomem pointers, which results
    in warnings on some 32-bit architectures, like:
    
    drivers/dma/dw-edma/dw-edma-v0-core.c: In function '__dw_regs':
    drivers/dma/dw-edma/dw-edma-v0-core.c:28:9: error: cast to pointer from integer of different size [-Werror=int-to-pointer-cast]
      return (struct dw_edma_v0_regs __iomem *)dw->rg_region.vaddr;
    
    Make it use __iomem pointers consistently here, and avoid using dma_addr_t
    for __iomem tokens altogether.
    
    A small complication here is the debugfs code, which passes an __iomem
    token as the private data for debugfs files, requiring the use of
    extra __force.
    
    Fixes: 7e4b8a4fbe2c ("dmaengine: Add Synopsys eDMA IP version 0 support")
    Link: https://lore.kernel.org/lkml/20190617131918.2518727-1-arnd@arndb.de/
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Link: https://lore.kernel.org/r/20190722124457.1093886-2-arnd@arndb.de
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/dw-edma/dw-edma-core.h b/drivers/dma/dw-edma/dw-edma-core.h
index b6cc90cbc9dc..4e5f9f6e901b 100644
--- a/drivers/dma/dw-edma/dw-edma-core.h
+++ b/drivers/dma/dw-edma/dw-edma-core.h
@@ -50,7 +50,7 @@ struct dw_edma_burst {
 
 struct dw_edma_region {
 	phys_addr_t			paddr;
-	dma_addr_t			vaddr;
+	void				__iomem *vaddr;
 	size_t				sz;
 };
 

commit e63d79d1ffcd2201a2dbff1d7a1184b8f3ec74cf
Author: Gustavo Pimentel <Gustavo.Pimentel@synopsys.com>
Date:   Tue Jun 4 15:29:22 2019 +0200

    dmaengine: Add Synopsys eDMA IP core driver
    
    Add Synopsys PCIe Endpoint eDMA IP core driver to kernel.
    
    This IP is generally distributed with Synopsys PCIe Endpoint IP (depends
    of the use and licensing agreement).
    
    This core driver, initializes and configures the eDMA IP using vma-helpers
    functions and dma-engine subsystem.
    
    This driver can be compile as built-in or external module in kernel.
    
    To enable this driver just select DW_EDMA option in kernel configuration,
    however it requires and selects automatically DMA_ENGINE and
    DMA_VIRTUAL_CHANNELS option too.
    
    In order to transfer data from point A to B as fast as possible this IP
    requires a dedicated memory space containing linked list of elements.
    
    All elements of this linked list are continuous and each one describes a
    data transfer (source and destination addresses, length and a control
    variable).
    
    For the sake of simplicity, lets assume a memory space for channel write
    0 which allows about 42 elements.
    
    +---------+
    | Desc #0 |-+
    +---------+ |
                V
           +----------+
           | Chunk #0 |-+
           |  CB = 1  | |  +----------+  +-----+  +-----------+  +-----+
           +----------+ +->| Burst #0 |->| ... |->| Burst #41 |->| llp |
                |          +----------+  +-----+  +-----------+  +-----+
                V
           +----------+
           | Chunk #1 |-+
           |  CB = 0  | |  +-----------+  +-----+  +-----------+  +-----+
           +----------+ +->| Burst #42 |->| ... |->| Burst #83 |->| llp |
                |          +-----------+  +-----+  +-----------+  +-----+
                V
           +----------+
           | Chunk #2 |-+
           |  CB = 1  | |  +-----------+  +-----+  +------------+  +-----+
           +----------+ +->| Burst #84 |->| ... |->| Burst #125 |->| llp |
                |          +-----------+  +-----+  +------------+  +-----+
                V
           +----------+
           | Chunk #3 |-+
           |  CB = 0  | |  +------------+  +-----+  +------------+  +-----+
           +----------+ +->| Burst #126 |->| ... |->| Burst #129 |->| llp |
                           +------------+  +-----+  +------------+  +-----+
    
    Legend:
     - Linked list, also know as Chunk
     - Linked list element*, also know as Burst *CB*, also know as Change Bit,
    it's a control bit (and typically is toggled) that allows to easily
    identify and differentiate between the current linked list and the
    previous or the next one.
     - LLP, is a special element that indicates the end of the linked list
    element stream also informs that the next CB should be toggle
    
    On every last Burst of the Chunk (Burst #41, Burst #83, Burst #125 or
    even Burst #129) is set some flags on their control variable (RIE and
    LIE bits) that will trigger the send of "done" interruption.
    
    On the interruptions callback, is decided whether to recycle the linked
    list memory space by writing a new set of Bursts elements (if still
    exists Chunks to transfer) or is considered completed (if there is no
    Chunks available to transfer).
    
    On scatter-gather transfer mode, the client will submit a scatter-gather
    list of n (on this case 130) elements, that will be divide in multiple
    Chunks, each Chunk will have (on this case 42) a limited number of
    Bursts and after transferring all Bursts, an interrupt will be
    triggered, which will allow to recycle the all linked list dedicated
    memory again with the new information relative to the next Chunk and
    respective Burst associated and repeat the whole cycle again.
    
    On cyclic transfer mode, the client will submit a buffer pointer, length
    of it and number of repetitions, in this case each burst will correspond
    directly to each repetition.
    
    Each Burst can describes a data transfer from point A(source) to point
    B(destination) with a length that can be from 1 byte up to 4 GB. Since
    dedicated the memory space where the linked list will reside is limited,
    the whole n burst elements will be organized in several Chunks, that
    will be used later to recycle the dedicated memory space to initiate a
    new sequence of data transfers.
    
    The whole transfer is considered has completed when it was transferred
    all bursts.
    
    Currently this IP has a set well-known register map, which includes
    support for legacy and unroll modes. Legacy mode is version of this
    register map that has multiplexer register that allows to switch
    registers between all write and read channels and the unroll modes
    repeats all write and read channels registers with an offset between
    them. This register map is called v0.
    
    The IP team is creating a new register map more suitable to the latest
    PCIe features, that very likely will change the map register, which this
    version will be called v1. As soon as this new version is released by
    the IP team the support for this version in be included on this driver.
    
    According to the logic, patches 1, 2 and 3 should be squashed into 1
    unique patch, but for the sake of simplicity of review, it was divided
    in this 3 patches files.
    
    Signed-off-by: Gustavo Pimentel <gustavo.pimentel@synopsys.com>
    Cc: Vinod Koul <vkoul@kernel.org>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Cc: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Joao Pinto <jpinto@synopsys.com>
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/dw-edma/dw-edma-core.h b/drivers/dma/dw-edma/dw-edma-core.h
new file mode 100644
index 000000000000..b6cc90cbc9dc
--- /dev/null
+++ b/drivers/dma/dw-edma/dw-edma-core.h
@@ -0,0 +1,165 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018-2019 Synopsys, Inc. and/or its affiliates.
+ * Synopsys DesignWare eDMA core driver
+ *
+ * Author: Gustavo Pimentel <gustavo.pimentel@synopsys.com>
+ */
+
+#ifndef _DW_EDMA_CORE_H
+#define _DW_EDMA_CORE_H
+
+#include <linux/msi.h>
+#include <linux/dma/edma.h>
+
+#include "../virt-dma.h"
+
+#define EDMA_LL_SZ					24
+
+enum dw_edma_dir {
+	EDMA_DIR_WRITE = 0,
+	EDMA_DIR_READ
+};
+
+enum dw_edma_mode {
+	EDMA_MODE_LEGACY = 0,
+	EDMA_MODE_UNROLL
+};
+
+enum dw_edma_request {
+	EDMA_REQ_NONE = 0,
+	EDMA_REQ_STOP,
+	EDMA_REQ_PAUSE
+};
+
+enum dw_edma_status {
+	EDMA_ST_IDLE = 0,
+	EDMA_ST_PAUSE,
+	EDMA_ST_BUSY
+};
+
+struct dw_edma_chan;
+struct dw_edma_chunk;
+
+struct dw_edma_burst {
+	struct list_head		list;
+	u64				sar;
+	u64				dar;
+	u32				sz;
+};
+
+struct dw_edma_region {
+	phys_addr_t			paddr;
+	dma_addr_t			vaddr;
+	size_t				sz;
+};
+
+struct dw_edma_chunk {
+	struct list_head		list;
+	struct dw_edma_chan		*chan;
+	struct dw_edma_burst		*burst;
+
+	u32				bursts_alloc;
+
+	u8				cb;
+	struct dw_edma_region		ll_region;	/* Linked list */
+};
+
+struct dw_edma_desc {
+	struct virt_dma_desc		vd;
+	struct dw_edma_chan		*chan;
+	struct dw_edma_chunk		*chunk;
+
+	u32				chunks_alloc;
+
+	u32				alloc_sz;
+	u32				xfer_sz;
+};
+
+struct dw_edma_chan {
+	struct virt_dma_chan		vc;
+	struct dw_edma_chip		*chip;
+	int				id;
+	enum dw_edma_dir		dir;
+
+	off_t				ll_off;
+	u32				ll_max;
+
+	off_t				dt_off;
+
+	struct msi_msg			msi;
+
+	enum dw_edma_request		request;
+	enum dw_edma_status		status;
+	u8				configured;
+
+	struct dma_slave_config		config;
+};
+
+struct dw_edma_irq {
+	struct msi_msg                  msi;
+	u32				wr_mask;
+	u32				rd_mask;
+	struct dw_edma			*dw;
+};
+
+struct dw_edma {
+	char				name[20];
+
+	struct dma_device		wr_edma;
+	u16				wr_ch_cnt;
+
+	struct dma_device		rd_edma;
+	u16				rd_ch_cnt;
+
+	struct dw_edma_region		rg_region;	/* Registers */
+	struct dw_edma_region		ll_region;	/* Linked list */
+	struct dw_edma_region		dt_region;	/* Data */
+
+	struct dw_edma_irq		*irq;
+	int				nr_irqs;
+
+	u32				version;
+	enum dw_edma_mode		mode;
+
+	struct dw_edma_chan		*chan;
+	const struct dw_edma_core_ops	*ops;
+
+	raw_spinlock_t			lock;		/* Only for legacy */
+};
+
+struct dw_edma_sg {
+	struct scatterlist		*sgl;
+	unsigned int			len;
+};
+
+struct dw_edma_cyclic {
+	dma_addr_t			paddr;
+	size_t				len;
+	size_t				cnt;
+};
+
+struct dw_edma_transfer {
+	struct dma_chan			*dchan;
+	union dw_edma_xfer {
+		struct dw_edma_sg	sg;
+		struct dw_edma_cyclic	cyclic;
+	} xfer;
+	enum dma_transfer_direction	direction;
+	unsigned long			flags;
+	bool				cyclic;
+};
+
+static inline
+struct dw_edma_chan *vc2dw_edma_chan(struct virt_dma_chan *vc)
+{
+	return container_of(vc, struct dw_edma_chan, vc);
+}
+
+static inline
+struct dw_edma_chan *dchan2dw_edma_chan(struct dma_chan *dchan)
+{
+	return vc2dw_edma_chan(to_virt_chan(dchan));
+}
+
+#endif /* _DW_EDMA_CORE_H */
