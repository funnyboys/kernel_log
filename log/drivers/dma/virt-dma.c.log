commit a5b871c91d470326eed3ae0ebd2fc07f3aee9050
Merge: 715d12856953 71723a96b8b1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 27 10:55:50 2020 -0800

    Merge tag 'dmaengine-5.6-rc1' of git://git.infradead.org/users/vkoul/slave-dma
    
    Pull dmaengine updates from Vinod Koul:
     "This time we have a bunch of core changes to support dynamic channels,
      hotplug of controllers, new apis for metadata ops etc along with new
      drivers for Intel data accelerators, TI K3 UDMA, PLX DMA engine and
      hisilicon Kunpeng DMA engine. Also usual assorted updates to drivers.
    
      Core:
       - Support for dynamic channels
       - Removal of various slave wrappers
       - Make few slave request APIs as private to dmaengine
       - Symlinks between channels and slaves
       - Support for hotplug of controllers
       - Support for metadata_ops for dma_async_tx_descriptor
       - Reporting DMA cached data amount
       - Virtual dma channel locking updates
    
      New drivers/device/feature support support:
       - Driver for Intel data accelerators
       - Driver for TI K3 UDMA
       - Driver for PLX DMA engine
       - Driver for hisilicon Kunpeng DMA engine
       - Support for eDMA support for QorIQ LS1028A in fsl edma driver
       - Support for cyclic dma in sun4i driver
       - Support for X1830 in JZ4780 driver"
    
    * tag 'dmaengine-5.6-rc1' of git://git.infradead.org/users/vkoul/slave-dma: (62 commits)
      dmaengine: Create symlinks between DMA channels and slaves
      dmaengine: hisilicon: Add Kunpeng DMA engine support
      dmaengine: idxd: add char driver to expose submission portal to userland
      dmaengine: idxd: connect idxd to dmaengine subsystem
      dmaengine: idxd: add descriptor manipulation routines
      dmaengine: idxd: add sysfs ABI for idxd driver
      dmaengine: idxd: add configuration component of driver
      dmaengine: idxd: Init and probe for Intel data accelerators
      dmaengine: add support to dynamic register/unregister of channels
      dmaengine: break out channel registration
      x86/asm: add iosubmit_cmds512() based on MOVDIR64B CPU instruction
      dmaengine: ti: k3-udma: fix spelling mistake "limted" -> "limited"
      dmaengine: s3c24xx-dma: fix spelling mistake "to" -> "too"
      dmaengine: Move dma_get_{,any_}slave_channel() to private dmaengine.h
      dmaengine: Remove dma_request_slave_channel_compat() wrapper
      dmaengine: Remove dma_device_satisfies_mask() wrapper
      dt-bindings: fsl-imx-sdma: Add i.MX8MM/i.MX8MN/i.MX8MP compatible string
      dmaengine: zynqmp_dma: fix burst length configuration
      dmaengine: sun4i: Add support for cyclic requests with dedicated DMA
      dmaengine: fsl-qdma: fix duplicated argument to &&
      ...

commit b167f94d2928f3516176c8107cb698a6d9bb9911
Author: Sascha Hauer <s.hauer@pengutronix.de>
Date:   Mon Dec 16 11:53:25 2019 +0100

    dmaengine: virt-dma: use vchan_vdesc_fini() to free descriptors
    
    vchan_dma_desc_free_list() basically open codes vchan_vdesc_fini() in its
    loop body. Call it directly rather than duplicating the code.
    
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Reviewed-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Tested-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Link: https://lore.kernel.org/r/20191216105328.15198-7-s.hauer@pengutronix.de
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 26e08c7a7465..95dfe431777e 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -115,16 +115,8 @@ void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 	struct virt_dma_desc *vd, *_vd;
 
 	list_for_each_entry_safe(vd, _vd, head, node) {
-		if (dmaengine_desc_test_reuse(&vd->tx)) {
-			unsigned long flags;
-
-			spin_lock_irqsave(&vc->lock, flags);
-			list_move_tail(&vd->node, &vc->desc_allocated);
-			spin_unlock_irqrestore(&vc->lock, flags);
-		} else {
-			list_del(&vd->node);
-			vc->desc_free(vd);
-		}
+		list_del(&vd->node);
+		vchan_vdesc_fini(vd);
 	}
 }
 EXPORT_SYMBOL_GPL(vchan_dma_desc_free_list);

commit f882101122aa110ef8e64be04472e5a47030300e
Author: Sascha Hauer <s.hauer@pengutronix.de>
Date:   Mon Dec 16 11:53:23 2019 +0100

    dmaengine: virt-dma: Do not call desc_free() under a spin_lock
    
    vchan_vdesc_fini() shouldn't be called under a spin_lock. This is done
    in two places, once in vchan_terminate_vdesc() and once in
    vchan_synchronize(). Instead of freeing the vdesc right away, collect
    the aborted vdescs on a separate list and free them along with the other
    vdescs. The terminated descs are also freed in vchan_synchronize as done
    before this patch.
    
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Reviewed-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Tested-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Link: https://lore.kernel.org/r/20191216105328.15198-5-s.hauer@pengutronix.de
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 7ba712888ac7..26e08c7a7465 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -138,6 +138,7 @@ void vchan_init(struct virt_dma_chan *vc, struct dma_device *dmadev)
 	INIT_LIST_HEAD(&vc->desc_submitted);
 	INIT_LIST_HEAD(&vc->desc_issued);
 	INIT_LIST_HEAD(&vc->desc_completed);
+	INIT_LIST_HEAD(&vc->desc_terminated);
 
 	tasklet_init(&vc->task, vchan_complete, (unsigned long)vc);
 

commit df660a2b6dfcf26001af6cd2441268c29416dd64
Author: Sascha Hauer <s.hauer@pengutronix.de>
Date:   Mon Dec 16 11:53:22 2019 +0100

    dmaengine: virt-dma: remove debug message
    
    vchan_dma_desc_free_list() basically open codes vchan_vdesc_fini() in
    the loop body. One difference is an additional debug message. As this
    isn't overly useful remove it.
    
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Reviewed-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Tested-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Link: https://lore.kernel.org/r/20191216105328.15198-4-s.hauer@pengutronix.de
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 660267ca5e42..7ba712888ac7 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -122,7 +122,6 @@ void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 			list_move_tail(&vd->node, &vc->desc_allocated);
 			spin_unlock_irqrestore(&vc->lock, flags);
 		} else {
-			dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
 			list_del(&vd->node);
 			vc->desc_free(vd);
 		}

commit 51fe9cd2bd92d95fc200385187d346e293ceefc9
Author: Sascha Hauer <s.hauer@pengutronix.de>
Date:   Mon Dec 16 11:53:21 2019 +0100

    dmaengine: virt-dma: Add missing locking
    
    Originally freeing descriptors was split into a locked and an unlocked
    part. The locked part in vchan_get_all_descriptors() collected all
    descriptors on a separate list_head. This was done to allow iterating
    over that new list in vchan_dma_desc_free_list() without a lock held.
    
    This became broken in 13bb26ae8850 ("dmaengine: virt-dma: don't always
    free descriptor upon completion"). With this commit
    vchan_dma_desc_free_list() no longer exclusively operates on the
    separate list, but starts to put descriptors which can be reused back on
    &vc->desc_allocated. This list operation should have been locked, but
    wasn't.
    In the mean time drivers started to call vchan_dma_desc_free_list() with
    their lock held so that we now have the situation that
    vchan_dma_desc_free_list() is called locked from some drivers and
    unlocked from others.
    To clean this up we have to do two things:
    
    1. Add missing locking in vchan_dma_desc_free_list()
    2. Make sure drivers call vchan_dma_desc_free_list() unlocked
    
    This needs to be done atomically, so in this patch the locking is added
    and all drivers are fixed.
    
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Reviewed-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Tested-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Reviewed-by: Green Wan <green.wan@sifive.com>
    Tested-by: Green Wan <green.wan@sifive.com>
    Link: https://lore.kernel.org/r/20191216105328.15198-3-s.hauer@pengutronix.de
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index ec4adf4260a0..660267ca5e42 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -116,7 +116,11 @@ void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 
 	list_for_each_entry_safe(vd, _vd, head, node) {
 		if (dmaengine_desc_test_reuse(&vd->tx)) {
+			unsigned long flags;
+
+			spin_lock_irqsave(&vc->lock, flags);
 			list_move_tail(&vd->node, &vc->desc_allocated);
+			spin_unlock_irqrestore(&vc->lock, flags);
 		} else {
 			dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
 			list_del(&vd->node);

commit 24461d9792c2c706092805ff1b067628933441bd
Author: Peter Ujfalusi <peter.ujfalusi@ti.com>
Date:   Fri Dec 20 15:11:00 2019 +0200

    dmaengine: virt-dma: Fix access after free in vchan_complete()
    
    vchan_vdesc_fini() is freeing up 'vd' so the access to vd->tx_result is
    via already freed up memory.
    
    Move the vchan_vdesc_fini() after invoking the callback to avoid this.
    
    Fixes: 09d5b702b0f97 ("dmaengine: virt-dma: store result on dma descriptor")
    Signed-off-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Reviewed-by: Alexandru Ardelean <alexandru.ardelean@analog.com>
    Link: https://lore.kernel.org/r/20191220131100.21804-1-peter.ujfalusi@ti.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index ec4adf4260a0..256fc662c500 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -104,9 +104,8 @@ static void vchan_complete(unsigned long arg)
 		dmaengine_desc_get_callback(&vd->tx, &cb);
 
 		list_del(&vd->node);
-		vchan_vdesc_fini(vd);
-
 		dmaengine_desc_callback_invoke(&cb, &vd->tx_result);
+		vchan_vdesc_fini(vd);
 	}
 }
 

commit 47ebe00b684c2bc183a766bc33c8b5943bc0df85
Merge: fa121bb3fed6 5c274ca4cfb2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 17 09:55:43 2019 -0700

    Merge tag 'dmaengine-5.3-rc1' of git://git.infradead.org/users/vkoul/slave-dma
    
    Pull dmaengine updates from Vinod Koul:
    
     - Add support in dmaengine core to do device node checks for DT devices
       and update bunch of drivers to use that and remove open coding from
       drivers
    
     - New driver/driver support for new hardware, namely:
         - MediaTek UART APDMA
         - Freescale i.mx7ulp edma2
         - Synopsys eDMA IP core version 0
         - Allwinner H6 DMA
    
     - Updates to axi-dma and support for interleaved cyclic transfers
    
     - Greg's debugfs return value check removals on drivers
    
     - Updates to stm32-dma, hsu, dw, pl330, tegra drivers
    
    * tag 'dmaengine-5.3-rc1' of git://git.infradead.org/users/vkoul/slave-dma: (68 commits)
      dmaengine: Revert "dmaengine: fsl-edma: add i.mx7ulp edma2 version support"
      dmaengine: at_xdmac: check for non-empty xfers_list before invoking callback
      Documentation: dmaengine: clean up description of dmatest usage
      dmaengine: tegra210-adma: remove PM_CLK dependency
      dmaengine: fsl-edma: add i.mx7ulp edma2 version support
      dt-bindings: dma: fsl-edma: add new i.mx7ulp-edma
      dmaengine: fsl-edma-common: version check for v2 instead
      dmaengine: fsl-edma-common: move dmamux register to another single function
      dmaengine: fsl-edma: add drvdata for fsl-edma
      dmaengine: Revert "dmaengine: fsl-edma: support little endian for edma driver"
      dmaengine: rcar-dmac: Reject zero-length slave DMA requests
      dmaengine: dw: Enable iDMA 32-bit on Intel Elkhart Lake
      dmaengine: dw-edma: fix semicolon.cocci warnings
      dmaengine: sh: usb-dmac: Use [] to denote a flexible array member
      dmaengine: dmatest: timeout value of -1 should specify infinite wait
      dmaengine: dw: Distinguish ->remove() between DW and iDMA 32-bit
      dmaengine: fsl-edma: support little endian for edma driver
      dmaengine: hsu: Revert "set HSU_CH_MTSR to memory width"
      dmagengine: pl330: add code to get reset property
      dt-bindings: pl330: document the optional resets property
      ...

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 88ad8ed2a8d6..bb5390847257 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -1,11 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Virtual DMA channel support for DMAengine
  *
  * Copyright (C) 2012 Russell King
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/device.h>
 #include <linux/dmaengine.h>

commit 09d5b702b0f97dd0768dade7106b6bf7622b1355
Author: Alexandru Ardelean <alexandru.ardelean@analog.com>
Date:   Thu Jun 6 13:45:47 2019 +0300

    dmaengine: virt-dma: store result on dma descriptor
    
    This allows each virtual channel to store information about each transfer
    that completed, i.e. which transfer succeeded (or which failed) and if
    there was any residue data on each (completed) transfer.
    
    Signed-off-by: Alexandru Ardelean <alexandru.ardelean@analog.com>
    Signed-off-by: Vinod Koul <vkoul@kernel.org>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 88ad8ed2a8d6..bf560a20c8a8 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -101,7 +101,7 @@ static void vchan_complete(unsigned long arg)
 	}
 	spin_unlock_irq(&vc->lock);
 
-	dmaengine_desc_callback_invoke(&cb, NULL);
+	dmaengine_desc_callback_invoke(&cb, &vd->tx_result);
 
 	list_for_each_entry_safe(vd, _vd, &head, node) {
 		dmaengine_desc_get_callback(&vd->tx, &cb);
@@ -109,7 +109,7 @@ static void vchan_complete(unsigned long arg)
 		list_del(&vd->node);
 		vchan_vdesc_fini(vd);
 
-		dmaengine_desc_callback_invoke(&cb, NULL);
+		dmaengine_desc_callback_invoke(&cb, &vd->tx_result);
 	}
 }
 

commit 6af149d2b1422e0e873d8558274713e6f63142c2
Author: Peter Ujfalusi <peter.ujfalusi@ti.com>
Date:   Tue Nov 14 16:32:03 2017 +0200

    dmaengine: virt-dma: Add helper to free/reuse a descriptor
    
    The vchan_vdesc_fini() can be used to free or reuse a given descriptor
    after it has been marked as completed.
    
    Signed-off-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Vinod Koul <vinod.koul@intel.com>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 545e97279083..88ad8ed2a8d6 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -107,10 +107,7 @@ static void vchan_complete(unsigned long arg)
 		dmaengine_desc_get_callback(&vd->tx, &cb);
 
 		list_del(&vd->node);
-		if (dmaengine_desc_test_reuse(&vd->tx))
-			list_add(&vd->node, &vc->desc_allocated);
-		else
-			vc->desc_free(vd);
+		vchan_vdesc_fini(vd);
 
 		dmaengine_desc_callback_invoke(&cb, NULL);
 	}

commit fdb980fb17c6a474614dd984b500418a2811d9e7
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Tue Apr 25 22:36:38 2017 +0300

    dmaengine: virt-dma: Convert to use list_for_each_entry_safe()
    
    Use list_for_each_entry_safe() instead of open coding variants.
    
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Vinod Koul <vinod.koul@intel.com>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index e47fc9b0944f..545e97279083 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -86,7 +86,7 @@ EXPORT_SYMBOL_GPL(vchan_find_desc);
 static void vchan_complete(unsigned long arg)
 {
 	struct virt_dma_chan *vc = (struct virt_dma_chan *)arg;
-	struct virt_dma_desc *vd;
+	struct virt_dma_desc *vd, *_vd;
 	struct dmaengine_desc_callback cb;
 	LIST_HEAD(head);
 
@@ -103,8 +103,7 @@ static void vchan_complete(unsigned long arg)
 
 	dmaengine_desc_callback_invoke(&cb, NULL);
 
-	while (!list_empty(&head)) {
-		vd = list_first_entry(&head, struct virt_dma_desc, node);
+	list_for_each_entry_safe(vd, _vd, &head, node) {
 		dmaengine_desc_get_callback(&vd->tx, &cb);
 
 		list_del(&vd->node);
@@ -119,9 +118,9 @@ static void vchan_complete(unsigned long arg)
 
 void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 {
-	while (!list_empty(head)) {
-		struct virt_dma_desc *vd = list_first_entry(head,
-			struct virt_dma_desc, node);
+	struct virt_dma_desc *vd, *_vd;
+
+	list_for_each_entry_safe(vd, _vd, head, node) {
 		if (dmaengine_desc_test_reuse(&vd->tx)) {
 			list_move_tail(&vd->node, &vc->desc_allocated);
 		} else {

commit 4f03ac6a2da050591e6e78921cacdff1546418c3
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed Jul 20 13:13:33 2016 -0700

    dmaengine: virt-dma: convert callback to helper function
    
    This is in preperation of moving to a callback that provides results to the
    callback for the transaction. The conversion will maintain current behavior
    and the driver must convert to new callback mechanism at a later time in
    order to receive results.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Reviewed-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Vinod Koul <vinod.koul@intel.com>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index a35c211857dd..e47fc9b0944f 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -87,8 +87,7 @@ static void vchan_complete(unsigned long arg)
 {
 	struct virt_dma_chan *vc = (struct virt_dma_chan *)arg;
 	struct virt_dma_desc *vd;
-	dma_async_tx_callback cb = NULL;
-	void *cb_data = NULL;
+	struct dmaengine_desc_callback cb;
 	LIST_HEAD(head);
 
 	spin_lock_irq(&vc->lock);
@@ -96,18 +95,17 @@ static void vchan_complete(unsigned long arg)
 	vd = vc->cyclic;
 	if (vd) {
 		vc->cyclic = NULL;
-		cb = vd->tx.callback;
-		cb_data = vd->tx.callback_param;
+		dmaengine_desc_get_callback(&vd->tx, &cb);
+	} else {
+		memset(&cb, 0, sizeof(cb));
 	}
 	spin_unlock_irq(&vc->lock);
 
-	if (cb)
-		cb(cb_data);
+	dmaengine_desc_callback_invoke(&cb, NULL);
 
 	while (!list_empty(&head)) {
 		vd = list_first_entry(&head, struct virt_dma_desc, node);
-		cb = vd->tx.callback;
-		cb_data = vd->tx.callback_param;
+		dmaengine_desc_get_callback(&vd->tx, &cb);
 
 		list_del(&vd->node);
 		if (dmaengine_desc_test_reuse(&vd->tx))
@@ -115,8 +113,7 @@ static void vchan_complete(unsigned long arg)
 		else
 			vc->desc_free(vd);
 
-		if (cb)
-			cb(cb_data);
+		dmaengine_desc_callback_invoke(&cb, NULL);
 	}
 }
 

commit 13bb26ae8850ede9cfb5ba20e646fe08e23aca97
Author: Robert Jarzmik <robert.jarzmik@free.fr>
Date:   Tue Oct 13 21:54:28 2015 +0200

    dmaengine: virt-dma: don't always free descriptor upon completion
    
    This patch attempts to enhance the case of a transfer submitted multiple
    times, and where the cost of creating the descriptors chain is not
    negligible.
    
    This happens with big video buffers (several megabytes, ie. several
    thousands of linked descriptors in one scatter-gather list). In these
    cases, a video driver would want to do :
     - tx = dmaengine_prep_slave_sg()
     - dma_engine_submit(tx);
     - dma_async_issue_pending()
     - wait for video completion
     - read video data (or not, skipping a frame is also possible)
     - dma_engine_submit(tx)
       => here, the descriptors chain recalculation will take time
       => the dma coherent allocation over and over might create holes in
          the dma pool, which is counter-productive.
     - dma_async_issue_pending()
     - etc ...
    
    In order to cope with this case, virt-dma is modified to prevent freeing
    the descriptors upon completion if DMA_CTRL_REUSE flag is set in the
    transfer.
    
    This patch is a respin of the former DMA_CTRL_ACK approach, which was
    reverted due to a regression in audio drivers.
    
    Signed-off-by: Robert Jarzmik <robert.jarzmik@free.fr>
    Signed-off-by: Vinod Koul <vinod.koul@intel.com>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 6f80432a3f0a..a35c211857dd 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -29,7 +29,7 @@ dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *tx)
 	spin_lock_irqsave(&vc->lock, flags);
 	cookie = dma_cookie_assign(tx);
 
-	list_add_tail(&vd->node, &vc->desc_submitted);
+	list_move_tail(&vd->node, &vc->desc_submitted);
 	spin_unlock_irqrestore(&vc->lock, flags);
 
 	dev_dbg(vc->chan.device->dev, "vchan %p: txd %p[%x]: submitted\n",
@@ -39,6 +39,33 @@ dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *tx)
 }
 EXPORT_SYMBOL_GPL(vchan_tx_submit);
 
+/**
+ * vchan_tx_desc_free - free a reusable descriptor
+ * @tx: the transfer
+ *
+ * This function frees a previously allocated reusable descriptor. The only
+ * other way is to clear the DMA_CTRL_REUSE flag and submit one last time the
+ * transfer.
+ *
+ * Returns 0 upon success
+ */
+int vchan_tx_desc_free(struct dma_async_tx_descriptor *tx)
+{
+	struct virt_dma_chan *vc = to_virt_chan(tx->chan);
+	struct virt_dma_desc *vd = to_virt_desc(tx);
+	unsigned long flags;
+
+	spin_lock_irqsave(&vc->lock, flags);
+	list_del(&vd->node);
+	spin_unlock_irqrestore(&vc->lock, flags);
+
+	dev_dbg(vc->chan.device->dev, "vchan %p: txd %p[%x]: freeing\n",
+		vc, vd, vd->tx.cookie);
+	vc->desc_free(vd);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(vchan_tx_desc_free);
+
 struct virt_dma_desc *vchan_find_desc(struct virt_dma_chan *vc,
 	dma_cookie_t cookie)
 {
@@ -83,8 +110,10 @@ static void vchan_complete(unsigned long arg)
 		cb_data = vd->tx.callback_param;
 
 		list_del(&vd->node);
-
-		vc->desc_free(vd);
+		if (dmaengine_desc_test_reuse(&vd->tx))
+			list_add(&vd->node, &vc->desc_allocated);
+		else
+			vc->desc_free(vd);
 
 		if (cb)
 			cb(cb_data);
@@ -96,9 +125,13 @@ void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 	while (!list_empty(head)) {
 		struct virt_dma_desc *vd = list_first_entry(head,
 			struct virt_dma_desc, node);
-		list_del(&vd->node);
-		dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
-		vc->desc_free(vd);
+		if (dmaengine_desc_test_reuse(&vd->tx)) {
+			list_move_tail(&vd->node, &vc->desc_allocated);
+		} else {
+			dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
+			list_del(&vd->node);
+			vc->desc_free(vd);
+		}
 	}
 }
 EXPORT_SYMBOL_GPL(vchan_dma_desc_free_list);
@@ -108,6 +141,7 @@ void vchan_init(struct virt_dma_chan *vc, struct dma_device *dmadev)
 	dma_cookie_init(&vc->chan);
 
 	spin_lock_init(&vc->lock);
+	INIT_LIST_HEAD(&vc->desc_allocated);
 	INIT_LIST_HEAD(&vc->desc_submitted);
 	INIT_LIST_HEAD(&vc->desc_issued);
 	INIT_LIST_HEAD(&vc->desc_completed);

commit 8c8fe97b2b8a216523e2faf1ccca66ddab634e3e
Author: Jun Nie <jun.nie@linaro.org>
Date:   Fri Jul 10 20:02:49 2015 +0800

    Revert "dmaengine: virt-dma: don't always free descriptor upon completion"
    
    This reverts commit b9855f03d560d351e95301b9de0bc3cad3b31fe9.
    The patch break existing DMA usage case. For example, audio SOC
    dmaengine never release channel and cause virt-dma to cache too
    much memory in descriptor to exhaust system memory.
    
    Signed-off-by: Vinod Koul <vinod.koul@intel.com>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 7d2c17d8d30f..6f80432a3f0a 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -29,7 +29,7 @@ dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *tx)
 	spin_lock_irqsave(&vc->lock, flags);
 	cookie = dma_cookie_assign(tx);
 
-	list_move_tail(&vd->node, &vc->desc_submitted);
+	list_add_tail(&vd->node, &vc->desc_submitted);
 	spin_unlock_irqrestore(&vc->lock, flags);
 
 	dev_dbg(vc->chan.device->dev, "vchan %p: txd %p[%x]: submitted\n",
@@ -83,10 +83,8 @@ static void vchan_complete(unsigned long arg)
 		cb_data = vd->tx.callback_param;
 
 		list_del(&vd->node);
-		if (async_tx_test_ack(&vd->tx))
-			list_add(&vd->node, &vc->desc_allocated);
-		else
-			vc->desc_free(vd);
+
+		vc->desc_free(vd);
 
 		if (cb)
 			cb(cb_data);
@@ -98,13 +96,9 @@ void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 	while (!list_empty(head)) {
 		struct virt_dma_desc *vd = list_first_entry(head,
 			struct virt_dma_desc, node);
-		if (async_tx_test_ack(&vd->tx)) {
-			list_move_tail(&vd->node, &vc->desc_allocated);
-		} else {
-			dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
-			list_del(&vd->node);
-			vc->desc_free(vd);
-		}
+		list_del(&vd->node);
+		dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
+		vc->desc_free(vd);
 	}
 }
 EXPORT_SYMBOL_GPL(vchan_dma_desc_free_list);
@@ -114,7 +108,6 @@ void vchan_init(struct virt_dma_chan *vc, struct dma_device *dmadev)
 	dma_cookie_init(&vc->chan);
 
 	spin_lock_init(&vc->lock);
-	INIT_LIST_HEAD(&vc->desc_allocated);
 	INIT_LIST_HEAD(&vc->desc_submitted);
 	INIT_LIST_HEAD(&vc->desc_issued);
 	INIT_LIST_HEAD(&vc->desc_completed);

commit b9855f03d560d351e95301b9de0bc3cad3b31fe9
Author: Robert Jarzmik <robert.jarzmik@free.fr>
Date:   Tue May 26 23:06:33 2015 +0200

    dmaengine: virt-dma: don't always free descriptor upon completion
    
    This patch attempts to enhance the case of a transfer submitted multiple
    times, and where the cost of creating the descriptors chain is not
    negligible.
    
    This happens with big video buffers (several megabytes, ie. several
    thousands of linked descriptors in one scatter-gather list). In these
    cases, a video driver would want to do :
     - tx = dmaengine_prep_slave_sg()
     - dma_engine_submit(tx);
     - dma_async_issue_pending()
     - wait for video completion
     - read video data (or not, skipping a frame is also possible)
     - dma_engine_submit(tx)
       => here, the descriptors chain recalculation will take time
       => the dma coherent allocation over and over might create holes in
          the dma pool, which is counter-productive.
     - dma_async_issue_pending()
     - etc ...
    
    In order to cope with this case, virt-dma is modified to prevent freeing
    the descriptors upon completion if DMA_CTRL_ACK flag is set in the
    transfer.
    
    Signed-off-by: Robert Jarzmik <robert.jarzmik@free.fr>
    Signed-off-by: Vinod Koul <vinod.koul@intel.com>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 6f80432a3f0a..7d2c17d8d30f 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -29,7 +29,7 @@ dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *tx)
 	spin_lock_irqsave(&vc->lock, flags);
 	cookie = dma_cookie_assign(tx);
 
-	list_add_tail(&vd->node, &vc->desc_submitted);
+	list_move_tail(&vd->node, &vc->desc_submitted);
 	spin_unlock_irqrestore(&vc->lock, flags);
 
 	dev_dbg(vc->chan.device->dev, "vchan %p: txd %p[%x]: submitted\n",
@@ -83,8 +83,10 @@ static void vchan_complete(unsigned long arg)
 		cb_data = vd->tx.callback_param;
 
 		list_del(&vd->node);
-
-		vc->desc_free(vd);
+		if (async_tx_test_ack(&vd->tx))
+			list_add(&vd->node, &vc->desc_allocated);
+		else
+			vc->desc_free(vd);
 
 		if (cb)
 			cb(cb_data);
@@ -96,9 +98,13 @@ void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 	while (!list_empty(head)) {
 		struct virt_dma_desc *vd = list_first_entry(head,
 			struct virt_dma_desc, node);
-		list_del(&vd->node);
-		dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
-		vc->desc_free(vd);
+		if (async_tx_test_ack(&vd->tx)) {
+			list_move_tail(&vd->node, &vc->desc_allocated);
+		} else {
+			dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
+			list_del(&vd->node);
+			vc->desc_free(vd);
+		}
 	}
 }
 EXPORT_SYMBOL_GPL(vchan_dma_desc_free_list);
@@ -108,6 +114,7 @@ void vchan_init(struct virt_dma_chan *vc, struct dma_device *dmadev)
 	dma_cookie_init(&vc->chan);
 
 	spin_lock_init(&vc->lock);
+	INIT_LIST_HEAD(&vc->desc_allocated);
 	INIT_LIST_HEAD(&vc->desc_submitted);
 	INIT_LIST_HEAD(&vc->desc_issued);
 	INIT_LIST_HEAD(&vc->desc_completed);

commit 571fa74034701391b1be2ad193f684acfdeb75d1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon May 14 15:17:20 2012 +0100

    dmaengine: virt-dma: add support for cyclic DMA periodic callbacks
    
    Add support for cyclic DMA's periodic callbacks.  Drivers are expected
    to call vchan_cyclic_callback() when a period has completed, which will
    schedule the tasklet to make the callback into the driver.
    
    As callbacks are made from tasklet context, it is important to realise
    that we don't guarantee a callback for each completed period, but for
    N completed periods where N may be greater than one.
    
    Tested-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index a8054fc40cef..6f80432a3f0a 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -59,17 +59,28 @@ EXPORT_SYMBOL_GPL(vchan_find_desc);
 static void vchan_complete(unsigned long arg)
 {
 	struct virt_dma_chan *vc = (struct virt_dma_chan *)arg;
+	struct virt_dma_desc *vd;
+	dma_async_tx_callback cb = NULL;
+	void *cb_data = NULL;
 	LIST_HEAD(head);
 
 	spin_lock_irq(&vc->lock);
 	list_splice_tail_init(&vc->desc_completed, &head);
+	vd = vc->cyclic;
+	if (vd) {
+		vc->cyclic = NULL;
+		cb = vd->tx.callback;
+		cb_data = vd->tx.callback_param;
+	}
 	spin_unlock_irq(&vc->lock);
 
+	if (cb)
+		cb(cb_data);
+
 	while (!list_empty(&head)) {
-		struct virt_dma_desc *vd = list_first_entry(&head,
-				struct virt_dma_desc, node);
-		dma_async_tx_callback cb = vd->tx.callback;
-		void *cb_data = vd->tx.callback_param;
+		vd = list_first_entry(&head, struct virt_dma_desc, node);
+		cb = vd->tx.callback;
+		cb_data = vd->tx.callback_param;
 
 		list_del(&vd->node);
 

commit fe045874aaf4480386c65baf1acae82af4c5e21f
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu May 10 23:39:27 2012 +0100

    dmaengine: virt-dma: vchan_find_desc()
    
    Add a function to find a descriptor within the depths of the
    virtualized DMA channel support.  Needed for tx_status functionality.
    
    Tested-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index bd85b052b481..a8054fc40cef 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -39,6 +39,19 @@ dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *tx)
 }
 EXPORT_SYMBOL_GPL(vchan_tx_submit);
 
+struct virt_dma_desc *vchan_find_desc(struct virt_dma_chan *vc,
+	dma_cookie_t cookie)
+{
+	struct virt_dma_desc *vd;
+
+	list_for_each_entry(vd, &vc->desc_issued, node)
+		if (vd->tx.cookie == cookie)
+			return vd;
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(vchan_find_desc);
+
 /*
  * This tasklet handles the completion of a DMA descriptor by
  * calling its callback and freeing it.

commit 50437bff7f7374f86837986f66e15e73a364f894
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Apr 13 12:07:23 2012 +0100

    dmaengine: split out virtual channel DMA support from sa11x0 driver
    
    Split the virtual slave channel DMA support from the sa11x0 driver so
    this code can be shared with other slave DMA engine drivers.
    
    Acked-by: Linus Walleij <linus.walleij@linaro.org>
    Tested-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
new file mode 100644
index 000000000000..bd85b052b481
--- /dev/null
+++ b/drivers/dma/virt-dma.c
@@ -0,0 +1,99 @@
+/*
+ * Virtual DMA channel support for DMAengine
+ *
+ * Copyright (C) 2012 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/device.h>
+#include <linux/dmaengine.h>
+#include <linux/module.h>
+#include <linux/spinlock.h>
+
+#include "virt-dma.h"
+
+static struct virt_dma_desc *to_virt_desc(struct dma_async_tx_descriptor *tx)
+{
+	return container_of(tx, struct virt_dma_desc, tx);
+}
+
+dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *tx)
+{
+	struct virt_dma_chan *vc = to_virt_chan(tx->chan);
+	struct virt_dma_desc *vd = to_virt_desc(tx);
+	unsigned long flags;
+	dma_cookie_t cookie;
+
+	spin_lock_irqsave(&vc->lock, flags);
+	cookie = dma_cookie_assign(tx);
+
+	list_add_tail(&vd->node, &vc->desc_submitted);
+	spin_unlock_irqrestore(&vc->lock, flags);
+
+	dev_dbg(vc->chan.device->dev, "vchan %p: txd %p[%x]: submitted\n",
+		vc, vd, cookie);
+
+	return cookie;
+}
+EXPORT_SYMBOL_GPL(vchan_tx_submit);
+
+/*
+ * This tasklet handles the completion of a DMA descriptor by
+ * calling its callback and freeing it.
+ */
+static void vchan_complete(unsigned long arg)
+{
+	struct virt_dma_chan *vc = (struct virt_dma_chan *)arg;
+	LIST_HEAD(head);
+
+	spin_lock_irq(&vc->lock);
+	list_splice_tail_init(&vc->desc_completed, &head);
+	spin_unlock_irq(&vc->lock);
+
+	while (!list_empty(&head)) {
+		struct virt_dma_desc *vd = list_first_entry(&head,
+				struct virt_dma_desc, node);
+		dma_async_tx_callback cb = vd->tx.callback;
+		void *cb_data = vd->tx.callback_param;
+
+		list_del(&vd->node);
+
+		vc->desc_free(vd);
+
+		if (cb)
+			cb(cb_data);
+	}
+}
+
+void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
+{
+	while (!list_empty(head)) {
+		struct virt_dma_desc *vd = list_first_entry(head,
+			struct virt_dma_desc, node);
+		list_del(&vd->node);
+		dev_dbg(vc->chan.device->dev, "txd %p: freeing\n", vd);
+		vc->desc_free(vd);
+	}
+}
+EXPORT_SYMBOL_GPL(vchan_dma_desc_free_list);
+
+void vchan_init(struct virt_dma_chan *vc, struct dma_device *dmadev)
+{
+	dma_cookie_init(&vc->chan);
+
+	spin_lock_init(&vc->lock);
+	INIT_LIST_HEAD(&vc->desc_submitted);
+	INIT_LIST_HEAD(&vc->desc_issued);
+	INIT_LIST_HEAD(&vc->desc_completed);
+
+	tasklet_init(&vc->task, vchan_complete, (unsigned long)vc);
+
+	vc->chan.device = dmadev;
+	list_add_tail(&vc->chan.device_node, &dmadev->channels);
+}
+EXPORT_SYMBOL_GPL(vchan_init);
+
+MODULE_AUTHOR("Russell King");
+MODULE_LICENSE("GPL");
