commit 4c9ee1bfca820b93f107957f5322845c862ea368
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Jan 23 13:55:19 2020 +1000

    drm/nouveau: zero vma pointer even if we only unreference it rather than free
    
    I'm not sure this affects anything, but best be safe.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 77061182a1cf..b28c7dc13ad6 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -69,8 +69,8 @@ nouveau_vma_del(struct nouveau_vma **pvma)
 		}
 		list_del(&vma->head);
 		kfree(*pvma);
-		*pvma = NULL;
 	}
+	*pvma = NULL;
 }
 
 int

commit eeaf06ac1a5584e41cf289f8351e446bb131374b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Jul 5 12:57:12 2018 +1000

    drm/nouveau/svm: initial support for shared virtual memory
    
    This uses HMM to mirror a process' CPU page tables into a channel's page
    tables, and keep them synchronised so that both the CPU and GPU are able
    to access the same memory at the same virtual address.
    
    While this code also supports Volta/Turing, it's only enabled for Pascal
    GPUs currently due to channel recovery being unreliable right now on the
    later GPUs.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 724d02d7c049..77061182a1cf 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -22,6 +22,7 @@
 #include "nouveau_vmm.h"
 #include "nouveau_drv.h"
 #include "nouveau_bo.h"
+#include "nouveau_svm.h"
 #include "nouveau_mem.h"
 
 void
@@ -119,6 +120,7 @@ nouveau_vma_new(struct nouveau_bo *nvbo, struct nouveau_vmm *vmm,
 void
 nouveau_vmm_fini(struct nouveau_vmm *vmm)
 {
+	nouveau_svmm_fini(&vmm->svmm);
 	nvif_vmm_fini(&vmm->vmm);
 	vmm->cli = NULL;
 }

commit 2606f291621eb319726243e0f3893644114277f8
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jun 13 16:25:53 2018 +1000

    drm/nouveau/mmu: support initialisation of client-managed address-spaces
    
    NVKM is currently responsible for managing the allocation of a client's
    GPU address-space, but there's various use-cases (ie. HMM address-space
    mirroring) where giving a client more direct control is desirable.
    
    This commit allows for a VMM to be created where the area allocated for
    NVKM is limited to a client-specified window, the remainder of address-
    space is controlled directly by the client.
    
    Leaving a window is necessary to support various internal requirements,
    but also to support existing allocation interfaces as not all of the HW
    is capable of working with a HMM allocation.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 2032c3e4f6e5..724d02d7c049 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -126,7 +126,7 @@ nouveau_vmm_fini(struct nouveau_vmm *vmm)
 int
 nouveau_vmm_init(struct nouveau_cli *cli, s32 oclass, struct nouveau_vmm *vmm)
 {
-	int ret = nvif_vmm_init(&cli->mmu, oclass, PAGE_SIZE, 0, NULL, 0,
+	int ret = nvif_vmm_init(&cli->mmu, oclass, false, PAGE_SIZE, 0, NULL, 0,
 				&vmm->vmm);
 	if (ret)
 		return ret;

commit 0db912af8f5ad4fa4dc08a9c8e411a10953c5403
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:47 2018 +1000

    drm/nouveau/gem: attach fences to VMAs to track GPU usage
    
    An upcoming patch will use these to fix issues related to the deferred
    unmapping of GEM objects.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index f5371d96b003..2032c3e4f6e5 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -92,6 +92,7 @@ nouveau_vma_new(struct nouveau_bo *nvbo, struct nouveau_vmm *vmm,
 	vma->refs = 1;
 	vma->addr = ~0ULL;
 	vma->mem = NULL;
+	vma->fence = NULL;
 	list_add_tail(&vma->head, &nvbo->vma_list);
 
 	if (nvbo->bo.mem.mem_type != TTM_PL_SYSTEM &&

commit 4ef928929987c19fff4d3c1650f139560ba1cc13
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Dec 20 08:38:46 2017 +1000

    drm/nouveau: fix obvious memory leak
    
    fdo#104340.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 9e2628dd8e4d..f5371d96b003 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -67,8 +67,8 @@ nouveau_vma_del(struct nouveau_vma **pvma)
 			nvif_vmm_put(&vma->vmm->vmm, &tmp);
 		}
 		list_del(&vma->head);
-		*pvma = NULL;
 		kfree(*pvma);
+		*pvma = NULL;
 	}
 }
 

commit 632b740c5481988152a3a60319aaa49c99577b77
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:20 2017 +1000

    drm/nouveau/mmu: remove old vmm frontend
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 2367ddf19513..9e2628dd8e4d 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -131,6 +131,5 @@ nouveau_vmm_init(struct nouveau_cli *cli, s32 oclass, struct nouveau_vmm *vmm)
 		return ret;
 
 	vmm->cli = cli;
-	vmm->vm = nvkm_uvmm(vmm->vmm.object.priv)->vmm;
 	return 0;
 }

commit d7722134b8254bcee6086230723814cddf9ab54b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:20 2017 +1000

    drm/nouveau: switch over to new memory and vmm interfaces
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 656f43ad012d..2367ddf19513 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -28,7 +28,7 @@ void
 nouveau_vma_unmap(struct nouveau_vma *vma)
 {
 	if (vma->mem) {
-		nvkm_vm_unmap(&vma->_vma);
+		nvif_vmm_unmap(&vma->vmm->vmm, vma->addr);
 		vma->mem = NULL;
 	}
 }
@@ -36,7 +36,8 @@ nouveau_vma_unmap(struct nouveau_vma *vma)
 int
 nouveau_vma_map(struct nouveau_vma *vma, struct nouveau_mem *mem)
 {
-	int ret = nouveau_mem_map(mem, vma->vmm->vm, &vma->_vma);
+	struct nvif_vma tmp = { .addr = vma->addr };
+	int ret = nouveau_mem_map(mem, &vma->vmm->vmm, &tmp);
 	if (ret)
 		return ret;
 	vma->mem = mem;
@@ -61,8 +62,10 @@ nouveau_vma_del(struct nouveau_vma **pvma)
 {
 	struct nouveau_vma *vma = *pvma;
 	if (vma && --vma->refs <= 0) {
-		if (likely(vma->addr != ~0ULL))
-			nvkm_vm_put(&vma->_vma);
+		if (likely(vma->addr != ~0ULL)) {
+			struct nvif_vma tmp = { .addr = vma->addr, .size = 1 };
+			nvif_vmm_put(&vma->vmm->vmm, &tmp);
+		}
 		list_del(&vma->head);
 		*pvma = NULL;
 		kfree(*pvma);
@@ -75,6 +78,7 @@ nouveau_vma_new(struct nouveau_bo *nvbo, struct nouveau_vmm *vmm,
 {
 	struct nouveau_mem *mem = nouveau_mem(&nvbo->bo.mem);
 	struct nouveau_vma *vma;
+	struct nvif_vma tmp;
 	int ret;
 
 	if ((vma = *pvma = nouveau_vma_find(nvbo, vmm))) {
@@ -92,17 +96,17 @@ nouveau_vma_new(struct nouveau_bo *nvbo, struct nouveau_vmm *vmm,
 
 	if (nvbo->bo.mem.mem_type != TTM_PL_SYSTEM &&
 	    mem->mem.page == nvbo->page) {
-		ret = nvkm_vm_get(vmm->vm, mem->_mem->size << 12, mem->mem.page,
-				  NV_MEM_ACCESS_RW, &vma->_vma);
+		ret = nvif_vmm_get(&vmm->vmm, LAZY, false, mem->mem.page, 0,
+				   mem->mem.size, &tmp);
 		if (ret)
 			goto done;
 
-		vma->addr = vma->_vma.offset;
+		vma->addr = tmp.addr;
 		ret = nouveau_vma_map(vma, mem);
 	} else {
-		ret = nvkm_vm_get(vmm->vm, mem->_mem->size << 12, mem->mem.page,
-				  NV_MEM_ACCESS_RW, &vma->_vma);
-		vma->addr = vma->_vma.offset;
+		ret = nvif_vmm_get(&vmm->vmm, PTES, false, mem->mem.page, 0,
+				   mem->mem.size, &tmp);
+		vma->addr = tmp.addr;
 	}
 
 done:

commit 96da0bcd51964ca708d8de2987ff473a9da4406d
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:20 2017 +1000

    drm/nouveau: allocate vmm object for every client
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 6dc14f92b988..656f43ad012d 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -114,13 +114,19 @@ nouveau_vma_new(struct nouveau_bo *nvbo, struct nouveau_vmm *vmm,
 void
 nouveau_vmm_fini(struct nouveau_vmm *vmm)
 {
-	nvkm_vm_ref(NULL, &vmm->vm, NULL);
+	nvif_vmm_fini(&vmm->vmm);
+	vmm->cli = NULL;
 }
 
 int
 nouveau_vmm_init(struct nouveau_cli *cli, s32 oclass, struct nouveau_vmm *vmm)
 {
+	int ret = nvif_vmm_init(&cli->mmu, oclass, PAGE_SIZE, 0, NULL, 0,
+				&vmm->vmm);
+	if (ret)
+		return ret;
+
 	vmm->cli = cli;
-	return nvkm_vm_new(nvxx_device(&cli->device), 0, (1ULL << 40),
-			   0x1000, NULL, &vmm->vm);
+	vmm->vm = nvkm_uvmm(vmm->vmm.object.priv)->vmm;
+	return 0;
 }

commit 3a314f747ba5b4cca22a36603768c176d1761afd
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau: remove explicit unmaps
    
    If the VMA is being deleted, we don't need to explicity unmap first
    anymore.  The MMU code will automatically merge the operations into
    a single page tree walk.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
index 855d549e17cf..6dc14f92b988 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vmm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -61,10 +61,8 @@ nouveau_vma_del(struct nouveau_vma **pvma)
 {
 	struct nouveau_vma *vma = *pvma;
 	if (vma && --vma->refs <= 0) {
-		if (likely(vma->addr != ~0ULL)) {
-			nouveau_vma_unmap(vma);
+		if (likely(vma->addr != ~0ULL))
 			nvkm_vm_put(&vma->_vma);
-		}
 		list_del(&vma->head);
 		*pvma = NULL;
 		kfree(*pvma);

commit 24e8375b1bfdf7f6014b9e3d7903d6a8f81aa249
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau: separate constant-va tracking from nvkm vma structure
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nouveau_vmm.c b/drivers/gpu/drm/nouveau/nouveau_vmm.c
new file mode 100644
index 000000000000..855d549e17cf
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_vmm.c
@@ -0,0 +1,128 @@
+/*
+ * Copyright 2017 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+#include "nouveau_vmm.h"
+#include "nouveau_drv.h"
+#include "nouveau_bo.h"
+#include "nouveau_mem.h"
+
+void
+nouveau_vma_unmap(struct nouveau_vma *vma)
+{
+	if (vma->mem) {
+		nvkm_vm_unmap(&vma->_vma);
+		vma->mem = NULL;
+	}
+}
+
+int
+nouveau_vma_map(struct nouveau_vma *vma, struct nouveau_mem *mem)
+{
+	int ret = nouveau_mem_map(mem, vma->vmm->vm, &vma->_vma);
+	if (ret)
+		return ret;
+	vma->mem = mem;
+	return 0;
+}
+
+struct nouveau_vma *
+nouveau_vma_find(struct nouveau_bo *nvbo, struct nouveau_vmm *vmm)
+{
+	struct nouveau_vma *vma;
+
+	list_for_each_entry(vma, &nvbo->vma_list, head) {
+		if (vma->vmm == vmm)
+			return vma;
+	}
+
+	return NULL;
+}
+
+void
+nouveau_vma_del(struct nouveau_vma **pvma)
+{
+	struct nouveau_vma *vma = *pvma;
+	if (vma && --vma->refs <= 0) {
+		if (likely(vma->addr != ~0ULL)) {
+			nouveau_vma_unmap(vma);
+			nvkm_vm_put(&vma->_vma);
+		}
+		list_del(&vma->head);
+		*pvma = NULL;
+		kfree(*pvma);
+	}
+}
+
+int
+nouveau_vma_new(struct nouveau_bo *nvbo, struct nouveau_vmm *vmm,
+		struct nouveau_vma **pvma)
+{
+	struct nouveau_mem *mem = nouveau_mem(&nvbo->bo.mem);
+	struct nouveau_vma *vma;
+	int ret;
+
+	if ((vma = *pvma = nouveau_vma_find(nvbo, vmm))) {
+		vma->refs++;
+		return 0;
+	}
+
+	if (!(vma = *pvma = kmalloc(sizeof(*vma), GFP_KERNEL)))
+		return -ENOMEM;
+	vma->vmm = vmm;
+	vma->refs = 1;
+	vma->addr = ~0ULL;
+	vma->mem = NULL;
+	list_add_tail(&vma->head, &nvbo->vma_list);
+
+	if (nvbo->bo.mem.mem_type != TTM_PL_SYSTEM &&
+	    mem->mem.page == nvbo->page) {
+		ret = nvkm_vm_get(vmm->vm, mem->_mem->size << 12, mem->mem.page,
+				  NV_MEM_ACCESS_RW, &vma->_vma);
+		if (ret)
+			goto done;
+
+		vma->addr = vma->_vma.offset;
+		ret = nouveau_vma_map(vma, mem);
+	} else {
+		ret = nvkm_vm_get(vmm->vm, mem->_mem->size << 12, mem->mem.page,
+				  NV_MEM_ACCESS_RW, &vma->_vma);
+		vma->addr = vma->_vma.offset;
+	}
+
+done:
+	if (ret)
+		nouveau_vma_del(pvma);
+	return ret;
+}
+
+void
+nouveau_vmm_fini(struct nouveau_vmm *vmm)
+{
+	nvkm_vm_ref(NULL, &vmm->vm, NULL);
+}
+
+int
+nouveau_vmm_init(struct nouveau_cli *cli, s32 oclass, struct nouveau_vmm *vmm)
+{
+	vmm->cli = cli;
+	return nvkm_vm_new(nvxx_device(&cli->device), 0, (1ULL << 40),
+			   0x1000, NULL, &vmm->vm);
+}
