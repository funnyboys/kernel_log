commit 91a4e83a2d3e99af33a666508e86b96f4210fae6
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: rename msgq-related nvkm_msgqueue_queue to nvkm_falcon_msgq
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index f3f2e333a10b..cbfe09a561a1 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -23,74 +23,74 @@
 #include "qmgr.h"
 
 static void
-msg_queue_open(struct nvkm_msgqueue_queue *queue)
+nvkm_falcon_msgq_open(struct nvkm_falcon_msgq *msgq)
 {
-	mutex_lock(&queue->mutex);
-	queue->position = nvkm_falcon_rd32(queue->qmgr->falcon, queue->tail_reg);
+	mutex_lock(&msgq->mutex);
+	msgq->position = nvkm_falcon_rd32(msgq->qmgr->falcon, msgq->tail_reg);
 }
 
 static void
-msg_queue_close(struct nvkm_msgqueue_queue *queue, bool commit)
+nvkm_falcon_msgq_close(struct nvkm_falcon_msgq *msgq, bool commit)
 {
-	struct nvkm_falcon *falcon = queue->qmgr->falcon;
+	struct nvkm_falcon *falcon = msgq->qmgr->falcon;
 
 	if (commit)
-		nvkm_falcon_wr32(falcon, queue->tail_reg, queue->position);
+		nvkm_falcon_wr32(falcon, msgq->tail_reg, msgq->position);
 
-	mutex_unlock(&queue->mutex);
+	mutex_unlock(&msgq->mutex);
 }
 
 static bool
-msg_queue_empty(struct nvkm_msgqueue_queue *queue)
+nvkm_falcon_msgq_empty(struct nvkm_falcon_msgq *msgq)
 {
-	u32 head = nvkm_falcon_rd32(queue->qmgr->falcon, queue->head_reg);
-	u32 tail = nvkm_falcon_rd32(queue->qmgr->falcon, queue->tail_reg);
+	u32 head = nvkm_falcon_rd32(msgq->qmgr->falcon, msgq->head_reg);
+	u32 tail = nvkm_falcon_rd32(msgq->qmgr->falcon, msgq->tail_reg);
 	return head == tail;
 }
 
 static int
-msg_queue_pop(struct nvkm_msgqueue_queue *queue, void *data, u32 size)
+nvkm_falcon_msgq_pop(struct nvkm_falcon_msgq *msgq, void *data, u32 size)
 {
-	struct nvkm_falcon *falcon = queue->qmgr->falcon;
+	struct nvkm_falcon *falcon = msgq->qmgr->falcon;
 	u32 head, tail, available;
 
-	head = nvkm_falcon_rd32(falcon, queue->head_reg);
+	head = nvkm_falcon_rd32(falcon, msgq->head_reg);
 	/* has the buffer looped? */
-	if (head < queue->position)
-		queue->position = queue->offset;
+	if (head < msgq->position)
+		msgq->position = msgq->offset;
 
-	tail = queue->position;
+	tail = msgq->position;
 
 	available = head - tail;
 	if (size > available) {
-		FLCNQ_ERR(queue, "requested %d bytes, but only %d available",
+		FLCNQ_ERR(msgq, "requested %d bytes, but only %d available",
 			  size, available);
 		return -EINVAL;
 	}
 
 	nvkm_falcon_read_dmem(falcon, tail, size, 0, data);
-	queue->position += ALIGN(size, QUEUE_ALIGNMENT);
+	msgq->position += ALIGN(size, QUEUE_ALIGNMENT);
 	return 0;
 }
 
 static int
-msg_queue_read(struct nvkm_msgqueue_queue *queue, struct nv_falcon_msg *hdr)
+nvkm_falcon_msgq_read(struct nvkm_falcon_msgq *msgq, struct nv_falcon_msg *hdr)
 {
 	int ret = 0;
 
-	msg_queue_open(queue);
+	nvkm_falcon_msgq_open(msgq);
 
-	if (msg_queue_empty(queue))
+	if (nvkm_falcon_msgq_empty(msgq))
 		goto close;
 
-	ret = msg_queue_pop(queue, hdr, HDR_SIZE);
+	ret = nvkm_falcon_msgq_pop(msgq, hdr, HDR_SIZE);
 	if (ret) {
-		FLCNQ_ERR(queue, "failed to read message header");
+		FLCNQ_ERR(msgq, "failed to read message header");
 		goto close;
 	}
 
 	if (hdr->size > MSG_BUF_SIZE) {
-		FLCNQ_ERR(queue, "message too big, %d bytes", hdr->size);
+		FLCNQ_ERR(msgq, "message too big, %d bytes", hdr->size);
 		ret = -ENOSPC;
 		goto close;
 	}
@@ -98,21 +98,21 @@ msg_queue_read(struct nvkm_msgqueue_queue *queue, struct nv_falcon_msg *hdr)
 	if (hdr->size > HDR_SIZE) {
 		u32 read_size = hdr->size - HDR_SIZE;
 
-		ret = msg_queue_pop(queue, (hdr + 1), read_size);
+		ret = nvkm_falcon_msgq_pop(msgq, (hdr + 1), read_size);
 		if (ret) {
-			FLCNQ_ERR(queue, "failed to read message data");
+			FLCNQ_ERR(msgq, "failed to read message data");
 			goto close;
 		}
 	}
 
 	ret = 1;
 close:
-	msg_queue_close(queue, (ret >= 0));
+	nvkm_falcon_msgq_close(msgq, (ret >= 0));
 	return ret;
 }
 
 static int
-msgqueue_msg_handle(struct nvkm_falcon_msgq *msgq, struct nv_falcon_msg *hdr)
+nvkm_falcon_msgq_exec(struct nvkm_falcon_msgq *msgq, struct nv_falcon_msg *hdr)
 {
 	struct nvkm_falcon_qmgr_seq *seq;
 
@@ -136,6 +136,20 @@ msgqueue_msg_handle(struct nvkm_falcon_msgq *msgq, struct nv_falcon_msg *hdr)
 	return 0;
 }
 
+void
+nvkm_falcon_msgq_recv(struct nvkm_falcon_msgq *msgq)
+{
+	/*
+	 * We are invoked from a worker thread, so normally we have plenty of
+	 * stack space to work with.
+	 */
+	u8 msg_buffer[MSG_BUF_SIZE];
+	struct nv_falcon_msg *hdr = (void *)msg_buffer;
+
+	while (nvkm_falcon_msgq_read(msgq, hdr) > 0)
+		nvkm_falcon_msgq_exec(msgq, hdr);
+}
+
 int
 nvkm_falcon_msgq_recv_initmsg(struct nvkm_falcon_msgq *msgq,
 			      void *data, u32 size)
@@ -148,31 +162,17 @@ nvkm_falcon_msgq_recv_initmsg(struct nvkm_falcon_msgq *msgq,
 	msgq->tail_reg = falcon->func->msgq.tail;
 	msgq->offset = nvkm_falcon_rd32(falcon, falcon->func->msgq.tail);
 
-	msg_queue_open(msgq);
-	ret = msg_queue_pop(msgq, data, size);
+	nvkm_falcon_msgq_open(msgq);
+	ret = nvkm_falcon_msgq_pop(msgq, data, size);
 	if (ret == 0 && hdr->size != size) {
 		FLCN_ERR(falcon, "unexpected init message size %d vs %d",
 			 hdr->size, size);
 		ret = -EINVAL;
 	}
-	msg_queue_close(msgq, ret == 0);
+	nvkm_falcon_msgq_close(msgq, ret == 0);
 	return ret;
 }
 
-void
-nvkm_falcon_msgq_recv(struct nvkm_falcon_msgq *queue)
-{
-	/*
-	 * We are invoked from a worker thread, so normally we have plenty of
-	 * stack space to work with.
-	 */
-	u8 msg_buffer[MSG_BUF_SIZE];
-	struct nv_falcon_msg *hdr = (void *)msg_buffer;
-
-	while (msg_queue_read(queue, hdr) > 0)
-		msgqueue_msg_handle(queue, hdr);
-}
-
 void
 nvkm_falcon_msgq_init(struct nvkm_falcon_msgq *msgq,
 		      u32 index, u32 offset, u32 size)

commit e1cc579898aed48fe6a6ac1bf5a7491784c5d690
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: pass explicit message queue pointer to recv()
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index b906534fc7fa..f3f2e333a10b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -160,8 +160,7 @@ nvkm_falcon_msgq_recv_initmsg(struct nvkm_falcon_msgq *msgq,
 }
 
 void
-nvkm_msgqueue_process_msgs(struct nvkm_msgqueue *priv,
-			   struct nvkm_msgqueue_queue *queue)
+nvkm_falcon_msgq_recv(struct nvkm_falcon_msgq *queue)
 {
 	/*
 	 * We are invoked from a worker thread, so normally we have plenty of

commit d114a1393fa01c4034d895072905578319a903f9
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: move handling of init message to subdevs
    
    When the PMU/SEC2 LS FWs have booted, they'll send a message to the host
    with various information, including the configuration of message/command
    queues that are available.
    
    Move the handling for this to the relevant subdevs.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 1c7dab86af80..b906534fc7fa 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -136,40 +136,27 @@ msgqueue_msg_handle(struct nvkm_falcon_msgq *msgq, struct nv_falcon_msg *hdr)
 	return 0;
 }
 
-static int
-msgqueue_handle_init_msg(struct nvkm_msgqueue *priv)
+int
+nvkm_falcon_msgq_recv_initmsg(struct nvkm_falcon_msgq *msgq,
+			      void *data, u32 size)
 {
-	struct nvkm_falcon *falcon = priv->falcon;
-	const struct nvkm_subdev *subdev = falcon->owner;
-	const u32 tail_reg = falcon->func->msgq.tail;
-	u8 msg_buffer[MSG_BUF_SIZE];
-	struct nvkm_msgqueue_hdr *hdr = (void *)msg_buffer;
-	u32 tail;
+	struct nvkm_falcon *falcon = msgq->qmgr->falcon;
+	struct nv_falcon_msg *hdr = data;
 	int ret;
 
-	/*
-	 * Read the message - queues are not initialized yet so we cannot rely
-	 * on msg_queue_read()
-	 */
-	tail = nvkm_falcon_rd32(falcon, tail_reg);
-	nvkm_falcon_read_dmem(falcon, tail, HDR_SIZE, 0, hdr);
+	msgq->head_reg = falcon->func->msgq.head;
+	msgq->tail_reg = falcon->func->msgq.tail;
+	msgq->offset = nvkm_falcon_rd32(falcon, falcon->func->msgq.tail);
 
-	if (hdr->size > MSG_BUF_SIZE) {
-		nvkm_error(subdev, "message too big (%d bytes)\n", hdr->size);
-		return -ENOSPC;
+	msg_queue_open(msgq);
+	ret = msg_queue_pop(msgq, data, size);
+	if (ret == 0 && hdr->size != size) {
+		FLCN_ERR(falcon, "unexpected init message size %d vs %d",
+			 hdr->size, size);
+		ret = -EINVAL;
 	}
-
-	nvkm_falcon_read_dmem(falcon, tail + HDR_SIZE, hdr->size - HDR_SIZE, 0,
-			      (hdr + 1));
-
-	tail += ALIGN(hdr->size, QUEUE_ALIGNMENT);
-	nvkm_falcon_wr32(falcon, tail_reg, tail);
-
-	ret = priv->func->init_func->init_callback(priv, hdr);
-	if (ret)
-		return ret;
-
-	return 0;
+	msg_queue_close(msgq, ret == 0);
+	return ret;
 }
 
 void
@@ -182,17 +169,9 @@ nvkm_msgqueue_process_msgs(struct nvkm_msgqueue *priv,
 	 */
 	u8 msg_buffer[MSG_BUF_SIZE];
 	struct nv_falcon_msg *hdr = (void *)msg_buffer;
-	int ret;
 
-	/* the first message we receive must be the init message */
-	if ((!priv->init_msg_received)) {
-		ret = msgqueue_handle_init_msg(priv);
-		if (!ret)
-			priv->init_msg_received = true;
-	} else {
-		while (msg_queue_read(queue, hdr) > 0)
-			msgqueue_msg_handle(queue, hdr);
-	}
+	while (msg_queue_read(queue, hdr) > 0)
+		msgqueue_msg_handle(queue, hdr);
 }
 
 void

commit 2d063981d710391cdea4e8c6483d94b519b1cde2
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: drop nvkm_msgqueue argument to functions
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 7fdd81bf3858..1c7dab86af80 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -23,18 +23,16 @@
 #include "qmgr.h"
 
 static void
-msg_queue_open(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue)
+msg_queue_open(struct nvkm_msgqueue_queue *queue)
 {
-	struct nvkm_falcon *falcon = priv->falcon;
 	mutex_lock(&queue->mutex);
-	queue->position = nvkm_falcon_rd32(falcon, queue->tail_reg);
+	queue->position = nvkm_falcon_rd32(queue->qmgr->falcon, queue->tail_reg);
 }
 
 static void
-msg_queue_close(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
-		bool commit)
+msg_queue_close(struct nvkm_msgqueue_queue *queue, bool commit)
 {
-	struct nvkm_falcon *falcon = priv->falcon;
+	struct nvkm_falcon *falcon = queue->qmgr->falcon;
 
 	if (commit)
 		nvkm_falcon_wr32(falcon, queue->tail_reg, queue->position);
@@ -43,19 +41,17 @@ msg_queue_close(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 }
 
 static bool
-msg_queue_empty(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue)
+msg_queue_empty(struct nvkm_msgqueue_queue *queue)
 {
-	struct nvkm_falcon *falcon = priv->falcon;
-	u32 head = nvkm_falcon_rd32(falcon, queue->head_reg);
-	u32 tail = nvkm_falcon_rd32(falcon, queue->tail_reg);
+	u32 head = nvkm_falcon_rd32(queue->qmgr->falcon, queue->head_reg);
+	u32 tail = nvkm_falcon_rd32(queue->qmgr->falcon, queue->tail_reg);
 	return head == tail;
 }
 
 static int
-msg_queue_pop(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
-	      void *data, u32 size)
+msg_queue_pop(struct nvkm_msgqueue_queue *queue, void *data, u32 size)
 {
-	struct nvkm_falcon *falcon = priv->falcon;
+	struct nvkm_falcon *falcon = queue->qmgr->falcon;
 	u32 head, tail, available;
 
 	head = nvkm_falcon_rd32(falcon, queue->head_reg);
@@ -72,23 +68,22 @@ msg_queue_pop(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 		return -EINVAL;
 	}
 
-	nvkm_falcon_read_dmem(priv->falcon, tail, size, 0, data);
+	nvkm_falcon_read_dmem(falcon, tail, size, 0, data);
 	queue->position += ALIGN(size, QUEUE_ALIGNMENT);
 	return 0;
 }
 
 static int
-msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
-	       struct nv_falcon_msg *hdr)
+msg_queue_read(struct nvkm_msgqueue_queue *queue, struct nv_falcon_msg *hdr)
 {
 	int ret = 0;
 
-	msg_queue_open(priv, queue);
+	msg_queue_open(queue);
 
-	if (msg_queue_empty(priv, queue))
+	if (msg_queue_empty(queue))
 		goto close;
 
-	ret = msg_queue_pop(priv, queue, hdr, HDR_SIZE);
+	ret = msg_queue_pop(queue, hdr, HDR_SIZE);
 	if (ret) {
 		FLCNQ_ERR(queue, "failed to read message header");
 		goto close;
@@ -103,7 +98,7 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 	if (hdr->size > HDR_SIZE) {
 		u32 read_size = hdr->size - HDR_SIZE;
 
-		ret = msg_queue_pop(priv, queue, (hdr + 1), read_size);
+		ret = msg_queue_pop(queue, (hdr + 1), read_size);
 		if (ret) {
 			FLCNQ_ERR(queue, "failed to read message data");
 			goto close;
@@ -112,14 +107,12 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 
 	ret = 1;
 close:
-	msg_queue_close(priv, queue, (ret >= 0));
+	msg_queue_close(queue, (ret >= 0));
 	return ret;
 }
 
 static int
-msgqueue_msg_handle(struct nvkm_msgqueue *priv,
-		    struct nvkm_falcon_msgq *msgq,
-		    struct nv_falcon_msg *hdr)
+msgqueue_msg_handle(struct nvkm_falcon_msgq *msgq, struct nv_falcon_msg *hdr)
 {
 	struct nvkm_falcon_qmgr_seq *seq;
 
@@ -197,8 +190,8 @@ nvkm_msgqueue_process_msgs(struct nvkm_msgqueue *priv,
 		if (!ret)
 			priv->init_msg_received = true;
 	} else {
-		while (msg_queue_read(priv, queue, hdr) > 0)
-			msgqueue_msg_handle(priv, queue, hdr);
+		while (msg_queue_read(queue, hdr) > 0)
+			msgqueue_msg_handle(queue, hdr);
 	}
 }
 

commit 77b1ab61fd1c08c7364ee6e184887202995a71e4
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: switch to falcon queue printk macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 15299ff45685..7fdd81bf3858 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -56,7 +56,6 @@ msg_queue_pop(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 	      void *data, u32 size)
 {
 	struct nvkm_falcon *falcon = priv->falcon;
-	const struct nvkm_subdev *subdev = priv->falcon->owner;
 	u32 head, tail, available;
 
 	head = nvkm_falcon_rd32(falcon, queue->head_reg);
@@ -68,7 +67,8 @@ msg_queue_pop(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 
 	available = head - tail;
 	if (size > available) {
-		nvkm_warn(subdev, "message data smaller than read request\n");
+		FLCNQ_ERR(queue, "requested %d bytes, but only %d available",
+			  size, available);
 		return -EINVAL;
 	}
 
@@ -81,7 +81,6 @@ static int
 msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 	       struct nv_falcon_msg *hdr)
 {
-	const struct nvkm_subdev *subdev = priv->falcon->owner;
 	int ret = 0;
 
 	msg_queue_open(priv, queue);
@@ -91,12 +90,12 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 
 	ret = msg_queue_pop(priv, queue, hdr, HDR_SIZE);
 	if (ret) {
-		nvkm_error(subdev, "failed to read message header: %d\n", ret);
+		FLCNQ_ERR(queue, "failed to read message header");
 		goto close;
 	}
 
 	if (hdr->size > MSG_BUF_SIZE) {
-		nvkm_error(subdev, "message too big (%d bytes)\n", hdr->size);
+		FLCNQ_ERR(queue, "message too big, %d bytes", hdr->size);
 		ret = -ENOSPC;
 		goto close;
 	}
@@ -106,7 +105,7 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 
 		ret = msg_queue_pop(priv, queue, (hdr + 1), read_size);
 		if (ret) {
-			nvkm_error(subdev, "failed to read message: %d\n", ret);
+			FLCNQ_ERR(queue, "failed to read message data");
 			goto close;
 		}
 	}
@@ -122,12 +121,11 @@ msgqueue_msg_handle(struct nvkm_msgqueue *priv,
 		    struct nvkm_falcon_msgq *msgq,
 		    struct nv_falcon_msg *hdr)
 {
-	const struct nvkm_subdev *subdev = priv->falcon->owner;
 	struct nvkm_falcon_qmgr_seq *seq;
 
 	seq = &msgq->qmgr->seq.id[hdr->seq_id];
 	if (seq->state != SEQ_STATE_USED && seq->state != SEQ_STATE_CANCELLED) {
-		nvkm_error(subdev, "msg for unknown sequence %d", seq->id);
+		FLCNQ_ERR(msgq, "message for unknown sequence %08x", seq->id);
 		return -EINVAL;
 	}
 

commit e9602a1bd7e996aca5c231bc07cad41fff9b290b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: simplify msg_queue_pop() error handling
    
    We always want at least requested size, make anything less a more direct
    error condition.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index ea3e7c73e990..15299ff45685 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -67,20 +67,14 @@ msg_queue_pop(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 	tail = queue->position;
 
 	available = head - tail;
-
-	if (available == 0) {
-		nvkm_warn(subdev, "no message data available\n");
-		return 0;
-	}
-
 	if (size > available) {
 		nvkm_warn(subdev, "message data smaller than read request\n");
-		size = available;
+		return -EINVAL;
 	}
 
 	nvkm_falcon_read_dmem(priv->falcon, tail, size, 0, data);
 	queue->position += ALIGN(size, QUEUE_ALIGNMENT);
-	return size;
+	return 0;
 }
 
 static int
@@ -88,19 +82,15 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 	       struct nv_falcon_msg *hdr)
 {
 	const struct nvkm_subdev *subdev = priv->falcon->owner;
-	int ret;
+	int ret = 0;
 
 	msg_queue_open(priv, queue);
 
-	if (msg_queue_empty(priv, queue)) {
-		ret = 0;
+	if (msg_queue_empty(priv, queue))
 		goto close;
-	}
 
 	ret = msg_queue_pop(priv, queue, hdr, HDR_SIZE);
-	if (ret >= 0 && ret != HDR_SIZE)
-		ret = -EINVAL;
-	if (ret < 0) {
+	if (ret) {
 		nvkm_error(subdev, "failed to read message header: %d\n", ret);
 		goto close;
 	}
@@ -115,14 +105,13 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 		u32 read_size = hdr->size - HDR_SIZE;
 
 		ret = msg_queue_pop(priv, queue, (hdr + 1), read_size);
-		if (ret >= 0 && ret != read_size)
-			ret = -EINVAL;
-		if (ret < 0) {
+		if (ret) {
 			nvkm_error(subdev, "failed to read message: %d\n", ret);
 			goto close;
 		}
 	}
 
+	ret = 1;
 close:
 	msg_queue_close(priv, queue, (ret >= 0));
 	return ret;

commit f09a3ee36bdc097d197e5188b6d0fd5354ddfa1a
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: remove error handling for msg_queue_open(), it can't fail
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index eb499b796fe5..ea3e7c73e990 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -22,13 +22,12 @@
  */
 #include "qmgr.h"
 
-static int
+static void
 msg_queue_open(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue)
 {
 	struct nvkm_falcon *falcon = priv->falcon;
 	mutex_lock(&queue->mutex);
 	queue->position = nvkm_falcon_rd32(falcon, queue->tail_reg);
-	return 0;
 }
 
 static void
@@ -91,11 +90,7 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 	const struct nvkm_subdev *subdev = priv->falcon->owner;
 	int ret;
 
-	ret = msg_queue_open(priv, queue);
-	if (ret) {
-		nvkm_error(subdev, "fail to open queue %d\n", queue->index);
-		return ret;
-	}
+	msg_queue_open(priv, queue);
 
 	if (msg_queue_empty(priv, queue)) {
 		ret = 0;

commit a15d8f580ccbe387dbc8c1d11a71fa737edd7e7f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/qmgr: rename remaining nvkm_msgqueue bits to nvkm_falcon_qmgr
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 7e9e82da7ea7..eb499b796fe5 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -139,9 +139,9 @@ msgqueue_msg_handle(struct nvkm_msgqueue *priv,
 		    struct nv_falcon_msg *hdr)
 {
 	const struct nvkm_subdev *subdev = priv->falcon->owner;
-	struct nvkm_msgqueue_seq *seq;
+	struct nvkm_falcon_qmgr_seq *seq;
 
-	seq = &msgq->qmgr->seq[hdr->seq_id];
+	seq = &msgq->qmgr->seq.id[hdr->seq_id];
 	if (seq->state != SEQ_STATE_USED && seq->state != SEQ_STATE_CANCELLED) {
 		nvkm_error(subdev, "msg for unknown sequence %d", seq->id);
 		return -EINVAL;

commit 8e90a98dfb804f4a86a9bc40706e9f00e870a2ba
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/qmgr: support syncronous command submission from common code
    
    Functions implementing FW commands had to implement this themselves, let's
    move that to common code and plumb the return code from callbacks through.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 7f84a5ef7905..7e9e82da7ea7 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -152,10 +152,12 @@ msgqueue_msg_handle(struct nvkm_msgqueue *priv,
 			seq->result = seq->callback(seq->priv, hdr);
 	}
 
-	if (seq->completion)
-		complete(seq->completion);
+	if (seq->async) {
+		nvkm_falcon_qmgr_seq_release(msgq->qmgr, seq);
+		return 0;
+	}
 
-	nvkm_falcon_qmgr_seq_release(msgq->qmgr, seq);
+	complete_all(&seq->done);
 	return 0;
 }
 

commit c80157a25e712daf69cbba8cafa0463c0895f56c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/qmgr: allow arbtrary priv + return code for callbacks
    
    Code to interface with LS firmwares is being moved to the subdevs where it
    belongs, rather than living in the common falcon code.
    
    Arbitrary private data passed to callbacks is to allow for something other
    than struct nvkm_msgqueue to be passed into the callback (like the pointer
    to the subdev itself, for example), and the return code will be used where
    we'd like to detect failure from synchronous messages.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 303f9faf3423..7f84a5ef7905 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -86,7 +86,7 @@ msg_queue_pop(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 
 static int
 msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
-	       struct nvkm_msgqueue_hdr *hdr)
+	       struct nv_falcon_msg *hdr)
 {
 	const struct nvkm_subdev *subdev = priv->falcon->owner;
 	int ret;
@@ -136,7 +136,7 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 static int
 msgqueue_msg_handle(struct nvkm_msgqueue *priv,
 		    struct nvkm_falcon_msgq *msgq,
-		    struct nvkm_msgqueue_hdr *hdr)
+		    struct nv_falcon_msg *hdr)
 {
 	const struct nvkm_subdev *subdev = priv->falcon->owner;
 	struct nvkm_msgqueue_seq *seq;
@@ -149,7 +149,7 @@ msgqueue_msg_handle(struct nvkm_msgqueue *priv,
 
 	if (seq->state == SEQ_STATE_USED) {
 		if (seq->callback)
-			seq->callback(priv, hdr);
+			seq->result = seq->callback(seq->priv, hdr);
 	}
 
 	if (seq->completion)
@@ -160,12 +160,13 @@ msgqueue_msg_handle(struct nvkm_msgqueue *priv,
 }
 
 static int
-msgqueue_handle_init_msg(struct nvkm_msgqueue *priv,
-			 struct nvkm_msgqueue_hdr *hdr)
+msgqueue_handle_init_msg(struct nvkm_msgqueue *priv)
 {
 	struct nvkm_falcon *falcon = priv->falcon;
 	const struct nvkm_subdev *subdev = falcon->owner;
 	const u32 tail_reg = falcon->func->msgq.tail;
+	u8 msg_buffer[MSG_BUF_SIZE];
+	struct nvkm_msgqueue_hdr *hdr = (void *)msg_buffer;
 	u32 tail;
 	int ret;
 
@@ -203,12 +204,12 @@ nvkm_msgqueue_process_msgs(struct nvkm_msgqueue *priv,
 	 * stack space to work with.
 	 */
 	u8 msg_buffer[MSG_BUF_SIZE];
-	struct nvkm_msgqueue_hdr *hdr = (void *)msg_buffer;
+	struct nv_falcon_msg *hdr = (void *)msg_buffer;
 	int ret;
 
 	/* the first message we receive must be the init message */
 	if ((!priv->init_msg_received)) {
-		ret = msgqueue_handle_init_msg(priv, hdr);
+		ret = msgqueue_handle_init_msg(priv);
 		if (!ret)
 			priv->init_msg_received = true;
 	} else {

commit 0ae59432ba6d647297f2e1bed97139147ce140ac
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/qmgr: move sequence tracking from nvkm_msgqueue to nvkm_falcon_qmgr
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 7be610427eef..303f9faf3423 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -134,12 +134,14 @@ msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
 }
 
 static int
-msgqueue_msg_handle(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_hdr *hdr)
+msgqueue_msg_handle(struct nvkm_msgqueue *priv,
+		    struct nvkm_falcon_msgq *msgq,
+		    struct nvkm_msgqueue_hdr *hdr)
 {
 	const struct nvkm_subdev *subdev = priv->falcon->owner;
 	struct nvkm_msgqueue_seq *seq;
 
-	seq = &priv->seq[hdr->seq_id];
+	seq = &msgq->qmgr->seq[hdr->seq_id];
 	if (seq->state != SEQ_STATE_USED && seq->state != SEQ_STATE_CANCELLED) {
 		nvkm_error(subdev, "msg for unknown sequence %d", seq->id);
 		return -EINVAL;
@@ -153,7 +155,7 @@ msgqueue_msg_handle(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_hdr *hdr)
 	if (seq->completion)
 		complete(seq->completion);
 
-	msgqueue_seq_release(priv, seq);
+	nvkm_falcon_qmgr_seq_release(msgq->qmgr, seq);
 	return 0;
 }
 
@@ -211,7 +213,7 @@ nvkm_msgqueue_process_msgs(struct nvkm_msgqueue *priv,
 			priv->init_msg_received = true;
 	} else {
 		while (msg_queue_read(priv, queue, hdr) > 0)
-			msgqueue_msg_handle(priv, hdr);
+			msgqueue_msg_handle(priv, queue, hdr);
 	}
 }
 

commit 22431189d6690071db01079606feb1daa2784afe
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn/msgq: explicitly create message queue from subdevs
    
    Code to interface with LS firmwares is being moved to the subdevs where it
    belongs, rather than living in the common falcon code.
    
    This is an incremental step towards that goal.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
index 5db0b41bc2c8..7be610427eef 100644
--- a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -214,3 +214,42 @@ nvkm_msgqueue_process_msgs(struct nvkm_msgqueue *priv,
 			msgqueue_msg_handle(priv, hdr);
 	}
 }
+
+void
+nvkm_falcon_msgq_init(struct nvkm_falcon_msgq *msgq,
+		      u32 index, u32 offset, u32 size)
+{
+	const struct nvkm_falcon_func *func = msgq->qmgr->falcon->func;
+
+	msgq->head_reg = func->msgq.head + index * func->msgq.stride;
+	msgq->tail_reg = func->msgq.tail + index * func->msgq.stride;
+	msgq->offset = offset;
+
+	FLCNQ_DBG(msgq, "initialised @ index %d offset 0x%08x size 0x%08x",
+		  index, msgq->offset, size);
+}
+
+void
+nvkm_falcon_msgq_del(struct nvkm_falcon_msgq **pmsgq)
+{
+	struct nvkm_falcon_msgq *msgq = *pmsgq;
+	if (msgq) {
+		kfree(*pmsgq);
+		*pmsgq = NULL;
+	}
+}
+
+int
+nvkm_falcon_msgq_new(struct nvkm_falcon_qmgr *qmgr, const char *name,
+		     struct nvkm_falcon_msgq **pmsgq)
+{
+	struct nvkm_falcon_msgq *msgq = *pmsgq;
+
+	if (!(msgq = *pmsgq = kzalloc(sizeof(*msgq), GFP_KERNEL)))
+		return -ENOMEM;
+
+	msgq->qmgr = qmgr;
+	msgq->name = name;
+	mutex_init(&msgq->mutex);
+	return 0;
+}

commit 7e1659cc3b33e8765ea155b4b46d8e658d5277d2
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 15 06:34:22 2020 +1000

    drm/nouveau/flcn: split msgqueue into multiple pieces
    
    To make things clearer while modifying the interfaces, split msgqueue into
    Queue Manager, Command Queue, and Message Queue.
    
    There should be no code changes here, these will be done incrementally.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
new file mode 100644
index 000000000000..5db0b41bc2c8
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvkm/falcon/msgq.c
@@ -0,0 +1,216 @@
+/*
+ * Copyright (c) 2017, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+#include "qmgr.h"
+
+static int
+msg_queue_open(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue)
+{
+	struct nvkm_falcon *falcon = priv->falcon;
+	mutex_lock(&queue->mutex);
+	queue->position = nvkm_falcon_rd32(falcon, queue->tail_reg);
+	return 0;
+}
+
+static void
+msg_queue_close(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
+		bool commit)
+{
+	struct nvkm_falcon *falcon = priv->falcon;
+
+	if (commit)
+		nvkm_falcon_wr32(falcon, queue->tail_reg, queue->position);
+
+	mutex_unlock(&queue->mutex);
+}
+
+static bool
+msg_queue_empty(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue)
+{
+	struct nvkm_falcon *falcon = priv->falcon;
+	u32 head = nvkm_falcon_rd32(falcon, queue->head_reg);
+	u32 tail = nvkm_falcon_rd32(falcon, queue->tail_reg);
+	return head == tail;
+}
+
+static int
+msg_queue_pop(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
+	      void *data, u32 size)
+{
+	struct nvkm_falcon *falcon = priv->falcon;
+	const struct nvkm_subdev *subdev = priv->falcon->owner;
+	u32 head, tail, available;
+
+	head = nvkm_falcon_rd32(falcon, queue->head_reg);
+	/* has the buffer looped? */
+	if (head < queue->position)
+		queue->position = queue->offset;
+
+	tail = queue->position;
+
+	available = head - tail;
+
+	if (available == 0) {
+		nvkm_warn(subdev, "no message data available\n");
+		return 0;
+	}
+
+	if (size > available) {
+		nvkm_warn(subdev, "message data smaller than read request\n");
+		size = available;
+	}
+
+	nvkm_falcon_read_dmem(priv->falcon, tail, size, 0, data);
+	queue->position += ALIGN(size, QUEUE_ALIGNMENT);
+	return size;
+}
+
+static int
+msg_queue_read(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_queue *queue,
+	       struct nvkm_msgqueue_hdr *hdr)
+{
+	const struct nvkm_subdev *subdev = priv->falcon->owner;
+	int ret;
+
+	ret = msg_queue_open(priv, queue);
+	if (ret) {
+		nvkm_error(subdev, "fail to open queue %d\n", queue->index);
+		return ret;
+	}
+
+	if (msg_queue_empty(priv, queue)) {
+		ret = 0;
+		goto close;
+	}
+
+	ret = msg_queue_pop(priv, queue, hdr, HDR_SIZE);
+	if (ret >= 0 && ret != HDR_SIZE)
+		ret = -EINVAL;
+	if (ret < 0) {
+		nvkm_error(subdev, "failed to read message header: %d\n", ret);
+		goto close;
+	}
+
+	if (hdr->size > MSG_BUF_SIZE) {
+		nvkm_error(subdev, "message too big (%d bytes)\n", hdr->size);
+		ret = -ENOSPC;
+		goto close;
+	}
+
+	if (hdr->size > HDR_SIZE) {
+		u32 read_size = hdr->size - HDR_SIZE;
+
+		ret = msg_queue_pop(priv, queue, (hdr + 1), read_size);
+		if (ret >= 0 && ret != read_size)
+			ret = -EINVAL;
+		if (ret < 0) {
+			nvkm_error(subdev, "failed to read message: %d\n", ret);
+			goto close;
+		}
+	}
+
+close:
+	msg_queue_close(priv, queue, (ret >= 0));
+	return ret;
+}
+
+static int
+msgqueue_msg_handle(struct nvkm_msgqueue *priv, struct nvkm_msgqueue_hdr *hdr)
+{
+	const struct nvkm_subdev *subdev = priv->falcon->owner;
+	struct nvkm_msgqueue_seq *seq;
+
+	seq = &priv->seq[hdr->seq_id];
+	if (seq->state != SEQ_STATE_USED && seq->state != SEQ_STATE_CANCELLED) {
+		nvkm_error(subdev, "msg for unknown sequence %d", seq->id);
+		return -EINVAL;
+	}
+
+	if (seq->state == SEQ_STATE_USED) {
+		if (seq->callback)
+			seq->callback(priv, hdr);
+	}
+
+	if (seq->completion)
+		complete(seq->completion);
+
+	msgqueue_seq_release(priv, seq);
+	return 0;
+}
+
+static int
+msgqueue_handle_init_msg(struct nvkm_msgqueue *priv,
+			 struct nvkm_msgqueue_hdr *hdr)
+{
+	struct nvkm_falcon *falcon = priv->falcon;
+	const struct nvkm_subdev *subdev = falcon->owner;
+	const u32 tail_reg = falcon->func->msgq.tail;
+	u32 tail;
+	int ret;
+
+	/*
+	 * Read the message - queues are not initialized yet so we cannot rely
+	 * on msg_queue_read()
+	 */
+	tail = nvkm_falcon_rd32(falcon, tail_reg);
+	nvkm_falcon_read_dmem(falcon, tail, HDR_SIZE, 0, hdr);
+
+	if (hdr->size > MSG_BUF_SIZE) {
+		nvkm_error(subdev, "message too big (%d bytes)\n", hdr->size);
+		return -ENOSPC;
+	}
+
+	nvkm_falcon_read_dmem(falcon, tail + HDR_SIZE, hdr->size - HDR_SIZE, 0,
+			      (hdr + 1));
+
+	tail += ALIGN(hdr->size, QUEUE_ALIGNMENT);
+	nvkm_falcon_wr32(falcon, tail_reg, tail);
+
+	ret = priv->func->init_func->init_callback(priv, hdr);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+void
+nvkm_msgqueue_process_msgs(struct nvkm_msgqueue *priv,
+			   struct nvkm_msgqueue_queue *queue)
+{
+	/*
+	 * We are invoked from a worker thread, so normally we have plenty of
+	 * stack space to work with.
+	 */
+	u8 msg_buffer[MSG_BUF_SIZE];
+	struct nvkm_msgqueue_hdr *hdr = (void *)msg_buffer;
+	int ret;
+
+	/* the first message we receive must be the init message */
+	if ((!priv->init_msg_received)) {
+		ret = msgqueue_handle_init_msg(priv, hdr);
+		if (!ret)
+			priv->init_msg_received = true;
+	} else {
+		while (msg_queue_read(priv, queue, hdr) > 0)
+			msgqueue_msg_handle(priv, hdr);
+	}
+}
