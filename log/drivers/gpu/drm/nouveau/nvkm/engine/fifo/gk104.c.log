commit cde540211ab1346a262ad9a5ecc52c9ff8f5975f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Jun 13 14:23:04 2019 +1000

    drm/nouveau/fifo/gk104-: fix parsing of mmu fault data
    
    Pascal was particularly incorrect, as the register changed to be more in the
    same format as the MMU fault buffers are.
    
    Shouldn't have impacted much more than confusing MMU fault log messages.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index ac9abcc1470a..5d4b695cab8e 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -646,31 +646,6 @@ gk104_fifo_intr_dropped_fault(struct gk104_fifo *fifo)
 	nvkm_error(subdev, "DROPPED_MMU_FAULT %08x\n", stat);
 }
 
-static void
-gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
-{
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
-	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
-	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
-	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
-	u32 type = nvkm_rd32(device, 0x00280c + (unit * 0x10));
-	struct nvkm_fault_data info;
-
-	info.inst   =  (u64)inst << 12;
-	info.addr   = ((u64)vahi << 32) | valo;
-	info.time   = 0;
-	info.engine = unit;
-	info.valid  = 1;
-	info.gpc    = (type & 0x1f000000) >> 24;
-	info.client = (type & 0x00001f00) >> 8;
-	info.access = (type & 0x00000080) >> 7;
-	info.hub    = (type & 0x00000040) >> 6;
-	info.reason = (type & 0x0000001f);
-
-	nvkm_fifo_fault(&fifo->base, &info);
-}
-
 static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {
 	{ 0x00000001, "MEMREQ" },
 	{ 0x00000002, "MEMACK_TIMEOUT" },
@@ -849,7 +824,7 @@ gk104_fifo_intr(struct nvkm_fifo *base)
 		u32 mask = nvkm_rd32(device, 0x00259c);
 		while (mask) {
 			u32 unit = __ffs(mask);
-			gk104_fifo_intr_fault(fifo, unit);
+			fifo->func->intr.fault(&fifo->base, unit);
 			nvkm_wr32(device, 0x00259c, (1 << unit));
 			mask &= ~(1 << unit);
 		}
@@ -1204,6 +1179,7 @@ gk104_fifo_fault_gpcclient[] = {
 
 static const struct gk104_fifo_func
 gk104_fifo = {
+	.intr.fault = gf100_fifo_intr_fault,
 	.pbdma = &gk104_fifo_pbdma,
 	.fault.access = gk104_fifo_fault_access,
 	.fault.engine = gk104_fifo_fault_engine,

commit cf9518b50a9c68cafb07e05fc54731071228ced3
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Jun 13 13:58:50 2019 +1000

    drm/nouveau/fifo/gf1xx: convert to using nvkm_fault_data
    
    Would like to be able to reuse gf100_fifo_intr_fault() for (some of) the
    later chipsets too, as it's identical.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 1053fe796466..ac9abcc1470a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -666,7 +666,7 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	info.client = (type & 0x00001f00) >> 8;
 	info.access = (type & 0x00000080) >> 7;
 	info.hub    = (type & 0x00000040) >> 6;
-	info.reason = (type & 0x000000ff);
+	info.reason = (type & 0x0000001f);
 
 	nvkm_fifo_fault(&fifo->base, &info);
 }

commit f7cc47e436c1238031548e0380eecc1ab66f24ba
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue Dec 11 14:50:02 2018 +1000

    drm/nouveau/fifo/gm200-: read pbdma count more directly
    
    The trick we used (and still use for older GPUs) doesn't work on Turing.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 79e0b58c5de7..1053fe796466 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -256,8 +256,18 @@ gk104_fifo_pbdma_init(struct gk104_fifo *fifo)
 	nvkm_wr32(device, 0x000204, (1 << fifo->pbdma_nr) - 1);
 }
 
+int
+gk104_fifo_pbdma_nr(struct gk104_fifo *fifo)
+{
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	/* Determine number of PBDMAs by checking valid enable bits. */
+	nvkm_wr32(device, 0x000204, 0xffffffff);
+	return hweight32(nvkm_rd32(device, 0x000204));
+}
+
 const struct gk104_fifo_pbdma_func
 gk104_fifo_pbdma = {
+	.nr = gk104_fifo_pbdma_nr,
 	.init = gk104_fifo_pbdma_init,
 };
 
@@ -925,9 +935,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	enum nvkm_devidx engidx;
 	u32 *map;
 
-	/* Determine number of PBDMAs by checking valid enable bits. */
-	nvkm_wr32(device, 0x000204, 0xffffffff);
-	fifo->pbdma_nr = hweight32(nvkm_rd32(device, 0x000204));
+	fifo->pbdma_nr = fifo->func->pbdma->nr(fifo);
 	nvkm_debug(subdev, "%d PBDMA(s)\n", fifo->pbdma_nr);
 
 	/* Read PBDMA->runlist(s) mapping from HW. */

commit f37a302e67195af7d5a410901c5e8ddbbe895182
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue Dec 11 14:50:02 2018 +1000

    drm/nouveau/fifo/gk104-: virtualise pbdma enable function
    
    Turing will require different code.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 1a6bafbc53ca..79e0b58c5de7 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -249,8 +249,16 @@ gk104_fifo_runlist = {
 	.commit = gk104_fifo_runlist_commit,
 };
 
+void
+gk104_fifo_pbdma_init(struct gk104_fifo *fifo)
+{
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	nvkm_wr32(device, 0x000204, (1 << fifo->pbdma_nr) - 1);
+}
+
 const struct gk104_fifo_pbdma_func
 gk104_fifo_pbdma = {
+	.init = gk104_fifo_pbdma_init,
 };
 
 static void
@@ -991,7 +999,7 @@ gk104_fifo_init(struct nvkm_fifo *base)
 	int i;
 
 	/* Enable PBDMAs. */
-	nvkm_wr32(device, 0x000204, (1 << fifo->pbdma_nr) - 1);
+	fifo->func->pbdma->init(fifo);
 
 	/* PBDMA[n] */
 	for (i = 0; i < fifo->pbdma_nr; i++) {

commit fb80ad15f86f9e7eb510930b1e02dfa86adffa8f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue Dec 11 14:50:02 2018 +1000

    drm/nouveau/fifo/gk104-: group pbdma functions together
    
    We're about to be adding more of them.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 5480f12dede2..1a6bafbc53ca 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -249,6 +249,10 @@ gk104_fifo_runlist = {
 	.commit = gk104_fifo_runlist_commit,
 };
 
+const struct gk104_fifo_pbdma_func
+gk104_fifo_pbdma = {
+};
+
 static void
 gk104_fifo_recover_work(struct work_struct *w)
 {
@@ -1004,8 +1008,8 @@ gk104_fifo_init(struct nvkm_fifo *base)
 
 	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar->addr >> 12);
 
-	if (fifo->func->init_pbdma_timeout)
-		fifo->func->init_pbdma_timeout(fifo);
+	if (fifo->func->pbdma->init_timeout)
+		fifo->func->pbdma->init_timeout(fifo);
 
 	nvkm_wr32(device, 0x002100, 0xffffffff);
 	nvkm_wr32(device, 0x002140, 0x7fffffff);
@@ -1184,6 +1188,7 @@ gk104_fifo_fault_gpcclient[] = {
 
 static const struct gk104_fifo_func
 gk104_fifo = {
+	.pbdma = &gk104_fifo_pbdma,
 	.fault.access = gk104_fifo_fault_access,
 	.fault.engine = gk104_fifo_fault_engine,
 	.fault.reason = gk104_fifo_fault_reason,

commit efa44c664f6aef0a2b94cffd197c501b0965db97
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue Dec 11 14:50:02 2018 +1000

    drm/nouveau/fifo/gk104-: separate runlist building from committing to hw
    
    We will need to bash different registers on Turing.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index cd917035d96c..5480f12dede2 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -149,16 +149,41 @@ gk104_fifo_uevent_init(struct nvkm_fifo *fifo)
 }
 
 void
-gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
+gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl,
+			  struct nvkm_memory *mem, int nr)
+{
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	int target;
+
+	switch (nvkm_memory_target(mem)) {
+	case NVKM_MEM_TARGET_VRAM: target = 0; break;
+	case NVKM_MEM_TARGET_NCOH: target = 3; break;
+	default:
+		WARN_ON(1);
+		return;
+	}
+
+	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(mem) >> 12) |
+				    (target << 28));
+	nvkm_wr32(device, 0x002274, (runl << 20) | nr);
+
+	if (nvkm_msec(device, 2000,
+		if (!(nvkm_rd32(device, 0x002284 + (runl * 0x08)) & 0x00100000))
+			break;
+	) < 0)
+		nvkm_error(subdev, "runlist %d update timeout\n", runl);
+}
+
+void
+gk104_fifo_runlist_update(struct gk104_fifo *fifo, int runl)
 {
 	const struct gk104_fifo_runlist_func *func = fifo->func->runlist;
 	struct gk104_fifo_chan *chan;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
 	struct nvkm_memory *mem;
 	struct nvkm_fifo_cgrp *cgrp;
 	int nr = 0;
-	int target;
 
 	mutex_lock(&subdev->mutex);
 	mem = fifo->runlist[runl].mem[fifo->runlist[runl].next];
@@ -177,24 +202,7 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 	}
 	nvkm_done(mem);
 
-	switch (nvkm_memory_target(mem)) {
-	case NVKM_MEM_TARGET_VRAM: target = 0; break;
-	case NVKM_MEM_TARGET_NCOH: target = 3; break;
-	default:
-		WARN_ON(1);
-		goto unlock;
-	}
-
-	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(mem) >> 12) |
-				    (target << 28));
-	nvkm_wr32(device, 0x002274, (runl << 20) | nr);
-
-	if (nvkm_msec(device, 2000,
-		if (!(nvkm_rd32(device, 0x002284 + (runl * 0x08)) & 0x00100000))
-			break;
-	) < 0)
-		nvkm_error(subdev, "runlist %d update timeout\n", runl);
-unlock:
+	func->commit(fifo, runl, mem, nr);
 	mutex_unlock(&subdev->mutex);
 }
 
@@ -238,6 +246,7 @@ const struct gk104_fifo_runlist_func
 gk104_fifo_runlist = {
 	.size = 8,
 	.chan = gk104_fifo_runlist_chan,
+	.commit = gk104_fifo_runlist_commit,
 };
 
 static void
@@ -267,7 +276,7 @@ gk104_fifo_recover_work(struct work_struct *w)
 	}
 
 	for (todo = runm; runl = __ffs(todo), todo; todo &= ~BIT(runl))
-		gk104_fifo_runlist_commit(fifo, runl);
+		gk104_fifo_runlist_update(fifo, runl);
 
 	nvkm_wr32(device, 0x00262c, runm);
 	nvkm_mask(device, 0x002630, runm, 0x00000000);

commit 302daab1a7b1206d33a9191d5b42ce606ed46e21
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue Dec 11 14:50:02 2018 +1000

    drm/nouveau/fifo/gf100-: call into BAR to reset BARs after MMU fault
    
    This is needed for Turing, but we're supposed to wait for completion after
    re-writing the value on older GPUs anyway.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index afccf9721cf0..cd917035d96c 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -456,10 +456,10 @@ gk104_fifo_fault(struct nvkm_fifo *base, struct nvkm_fault_data *info)
 	if (ee && ee->data2) {
 		switch (ee->data2) {
 		case NVKM_SUBDEV_BAR:
-			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
+			nvkm_bar_bar1_reset(device);
 			break;
 		case NVKM_SUBDEV_INSTMEM:
-			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
+			nvkm_bar_bar2_reset(device);
 			break;
 		case NVKM_ENGINE_IFB:
 			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);

commit 6396bb221514d2876fd6dc0aa2a1f240d99b37bb
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jun 12 14:03:40 2018 -0700

    treewide: kzalloc() -> kcalloc()
    
    The kzalloc() function has a 2-factor argument form, kcalloc(). This
    patch replaces cases of:
    
            kzalloc(a * b, gfp)
    
    with:
            kcalloc(a * b, gfp)
    
    as well as handling cases of:
    
            kzalloc(a * b * c, gfp)
    
    with:
    
            kzalloc(array3_size(a, b, c), gfp)
    
    as it's slightly less ugly than:
    
            kzalloc_array(array_size(a, b), c, gfp)
    
    This does, however, attempt to ignore constant size factors like:
    
            kzalloc(4 * 1024, gfp)
    
    though any constants defined via macros get caught up in the conversion.
    
    Any factors with a sizeof() of "unsigned char", "char", and "u8" were
    dropped, since they're redundant.
    
    The Coccinelle script used for this was:
    
    // Fix redundant parens around sizeof().
    @@
    type TYPE;
    expression THING, E;
    @@
    
    (
      kzalloc(
    -       (sizeof(TYPE)) * E
    +       sizeof(TYPE) * E
      , ...)
    |
      kzalloc(
    -       (sizeof(THING)) * E
    +       sizeof(THING) * E
      , ...)
    )
    
    // Drop single-byte sizes and redundant parens.
    @@
    expression COUNT;
    typedef u8;
    typedef __u8;
    @@
    
    (
      kzalloc(
    -       sizeof(u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(__u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(char) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(unsigned char) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(u8) * COUNT
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(__u8) * COUNT
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(char) * COUNT
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(unsigned char) * COUNT
    +       COUNT
      , ...)
    )
    
    // 2-factor product with sizeof(type/expression) and identifier or constant.
    @@
    type TYPE;
    expression THING;
    identifier COUNT_ID;
    constant COUNT_CONST;
    @@
    
    (
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * (COUNT_ID)
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * COUNT_ID
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * COUNT_CONST
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * (COUNT_ID)
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * COUNT_ID
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * COUNT_CONST
    +       COUNT_CONST, sizeof(THING)
      , ...)
    )
    
    // 2-factor product, only identifiers.
    @@
    identifier SIZE, COUNT;
    @@
    
    - kzalloc
    + kcalloc
      (
    -       SIZE * COUNT
    +       COUNT, SIZE
      , ...)
    
    // 3-factor product with 1 sizeof(type) or sizeof(expression), with
    // redundant parens removed.
    @@
    expression THING;
    identifier STRIDE, COUNT;
    type TYPE;
    @@
    
    (
      kzalloc(
    -       sizeof(TYPE) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    )
    
    // 3-factor product with 2 sizeof(variable), with redundant parens removed.
    @@
    expression THING1, THING2;
    identifier COUNT;
    type TYPE1, TYPE2;
    @@
    
    (
      kzalloc(
    -       sizeof(TYPE1) * sizeof(TYPE2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kzalloc(
    -       sizeof(THING1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kzalloc(
    -       sizeof(THING1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    )
    
    // 3-factor product, only identifiers, with redundant parens removed.
    @@
    identifier STRIDE, SIZE, COUNT;
    @@
    
    (
      kzalloc(
    -       (COUNT) * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       (COUNT) * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       (COUNT) * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       (COUNT) * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    )
    
    // Any remaining multi-factor products, first at least 3-factor products,
    // when they're not all constants...
    @@
    expression E1, E2, E3;
    constant C1, C2, C3;
    @@
    
    (
      kzalloc(C1 * C2 * C3, ...)
    |
      kzalloc(
    -       (E1) * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kzalloc(
    -       (E1) * (E2) * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kzalloc(
    -       (E1) * (E2) * (E3)
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kzalloc(
    -       E1 * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    )
    
    // And then all remaining 2 factors products when they're not all constants,
    // keeping sizeof() as the second factor argument.
    @@
    expression THING, E1, E2;
    type TYPE;
    constant C1, C2, C3;
    @@
    
    (
      kzalloc(sizeof(THING) * C2, ...)
    |
      kzalloc(sizeof(TYPE) * C2, ...)
    |
      kzalloc(C1 * C2 * C3, ...)
    |
      kzalloc(C1 * C2, ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * (E2)
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * E2
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * (E2)
    +       E2, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * E2
    +       E2, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       (E1) * E2
    +       E1, E2
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       (E1) * (E2)
    +       E1, E2
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       E1 * E2
    +       E1, E2
      , ...)
    )
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index a99046414a18..afccf9721cf0 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -910,7 +910,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	nvkm_debug(subdev, "%d PBDMA(s)\n", fifo->pbdma_nr);
 
 	/* Read PBDMA->runlist(s) mapping from HW. */
-	if (!(map = kzalloc(sizeof(*map) * fifo->pbdma_nr, GFP_KERNEL)))
+	if (!(map = kcalloc(fifo->pbdma_nr, sizeof(*map), GFP_KERNEL)))
 		return -ENOMEM;
 
 	for (i = 0; i < fifo->pbdma_nr; i++)

commit 37e1c45a58b5c1f699d583483f612462418dd2ee
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:48 2018 +1000

    drm/nouveau/fifo/gv100: initial support
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 767e0ab44cb8..a99046414a18 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -103,6 +103,10 @@ gk104_fifo_class_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 	if (oclass->engn == &fifo->func->chan) {
 		const struct gk104_fifo_chan_user *user = oclass->engn;
 		return user->ctor(fifo, oclass, argv, argc, pobject);
+	} else
+	if (oclass->engn == &fifo->func->user) {
+		const struct gk104_fifo_user_user *user = oclass->engn;
+		return user->ctor(oclass, argv, argc, pobject);
 	}
 	WARN_ON(1);
 	return -EINVAL;
@@ -115,6 +119,12 @@ gk104_fifo_class_get(struct nvkm_fifo *base, int index,
 	struct gk104_fifo *fifo = gk104_fifo(base);
 	int c = 0;
 
+	if (fifo->func->user.ctor && c++ == index) {
+		oclass->base =  fifo->func->user.user;
+		oclass->engn = &fifo->func->user;
+		return 0;
+	}
+
 	if (fifo->func->chan.ctor && c++ == index) {
 		oclass->base =  fifo->func->chan.user;
 		oclass->engn = &fifo->func->chan;

commit 334cc26d4db10ae7d8f18de27869b95fe84c7d28
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gp100-: force individual channels into a channel group
    
    RM does this for some reason, and is enforced in HW on Volta.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 5c22ce916530..767e0ab44cb8 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -285,6 +285,32 @@ gk104_fifo_recover_runl(struct gk104_fifo *fifo, int runl)
 	schedule_work(&fifo->recover.work);
 }
 
+static struct gk104_fifo_chan *
+gk104_fifo_recover_chid(struct gk104_fifo *fifo, int runl, int chid)
+{
+	struct gk104_fifo_chan *chan;
+	struct nvkm_fifo_cgrp *cgrp;
+
+	list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
+		if (chan->base.chid == chid) {
+			list_del_init(&chan->head);
+			return chan;
+		}
+	}
+
+	list_for_each_entry(cgrp, &fifo->runlist[runl].cgrp, head) {
+		if (cgrp->id == chid) {
+			chan = list_first_entry(&cgrp->chan, typeof(*chan), head);
+			list_del_init(&chan->head);
+			if (!--cgrp->chan_nr)
+				list_del_init(&cgrp->head);
+			return chan;
+		}
+	}
+
+	return NULL;
+}
+
 static void
 gk104_fifo_recover_chan(struct nvkm_fifo *base, int chid)
 {
@@ -302,13 +328,10 @@ gk104_fifo_recover_chan(struct nvkm_fifo *base, int chid)
 		return;
 
 	/* Lookup SW state for channel, and mark it as dead. */
-	list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
-		if (chan->base.chid == chid) {
-			list_del_init(&chan->head);
-			chan->killed = true;
-			nvkm_fifo_kevent(&fifo->base, chid);
-			break;
-		}
+	chan = gk104_fifo_recover_chid(fifo, runl, chid);
+	if (chan) {
+		chan->killed = true;
+		nvkm_fifo_kevent(&fifo->base, chid);
 	}
 
 	/* Disable channel. */

commit 79bb4b617f965736d2e1c616235302c1d0e823b2
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gk208-: write pbdma timeout regs during initialisation
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index bc87f18c3092..5c22ce916530 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -962,6 +962,9 @@ gk104_fifo_init(struct nvkm_fifo *base)
 
 	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar->addr >> 12);
 
+	if (fifo->func->init_pbdma_timeout)
+		fifo->func->init_pbdma_timeout(fifo);
+
 	nvkm_wr32(device, 0x002100, 0xffffffff);
 	nvkm_wr32(device, 0x002140, 0x7fffffff);
 }

commit 8c4e9f9dffb96a891d31e108b47f081233cb3e81
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gk110-: support writing channel group runlist entries
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 2b8e0d3d2d96..bc87f18c3092 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -22,6 +22,7 @@
  * Authors: Ben Skeggs
  */
 #include "gk104.h"
+#include "cgrp.h"
 #include "changk104.h"
 
 #include <core/client.h>
@@ -145,6 +146,7 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	struct nvkm_memory *mem;
+	struct nvkm_fifo_cgrp *cgrp;
 	int nr = 0;
 	int target;
 
@@ -156,6 +158,13 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 	list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
 		func->chan(chan, mem, nr++ * func->size);
 	}
+
+	list_for_each_entry(cgrp, &fifo->runlist[runl].cgrp, head) {
+		func->cgrp(cgrp, mem, nr++ * func->size);
+		list_for_each_entry(chan, &cgrp->chan, head) {
+			func->chan(chan, mem, nr++ * func->size);
+		}
+	}
 	nvkm_done(mem);
 
 	switch (nvkm_memory_target(mem)) {
@@ -182,16 +191,28 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 void
 gk104_fifo_runlist_remove(struct gk104_fifo *fifo, struct gk104_fifo_chan *chan)
 {
+	struct nvkm_fifo_cgrp *cgrp = chan->cgrp;
 	mutex_lock(&fifo->base.engine.subdev.mutex);
-	list_del_init(&chan->head);
+	if (!list_empty(&chan->head)) {
+		list_del_init(&chan->head);
+		if (cgrp && !--cgrp->chan_nr)
+			list_del_init(&cgrp->head);
+	}
 	mutex_unlock(&fifo->base.engine.subdev.mutex);
 }
 
 void
 gk104_fifo_runlist_insert(struct gk104_fifo *fifo, struct gk104_fifo_chan *chan)
 {
+	struct nvkm_fifo_cgrp *cgrp = chan->cgrp;
 	mutex_lock(&fifo->base.engine.subdev.mutex);
-	list_add_tail(&chan->head, &fifo->runlist[chan->runl].chan);
+	if (cgrp) {
+		if (!cgrp->chan_nr++)
+			list_add_tail(&cgrp->head, &fifo->runlist[chan->runl].cgrp);
+		list_add_tail(&chan->head, &cgrp->chan);
+	} else {
+		list_add_tail(&chan->head, &fifo->runlist[chan->runl].chan);
+	}
 	mutex_unlock(&fifo->base.engine.subdev.mutex);
 }
 
@@ -898,6 +919,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 		}
 
 		init_waitqueue_head(&fifo->runlist[i].wait);
+		INIT_LIST_HEAD(&fifo->runlist[i].cgrp);
 		INIT_LIST_HEAD(&fifo->runlist[i].chan);
 	}
 

commit 4f2fc25c0f8bcc8db1b8a7b21e88c3d7f35c5acb
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gk104-: poll for runlist update completion
    
    Newer HW doesn't appear to send this event, which will cause long delays
    in runlist updates if they don't complete immediately.
    
    RM doesn't use these events anywhere, and an NVGPU commit message notes
    that polling is the preferred method even on HW that supports the event.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index afb3ed06ec89..2b8e0d3d2d96 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -170,10 +170,10 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 				    (target << 28));
 	nvkm_wr32(device, 0x002274, (runl << 20) | nr);
 
-	if (wait_event_timeout(fifo->runlist[runl].wait,
-			       !(nvkm_rd32(device, 0x002284 + (runl * 0x08))
-				       & 0x00100000),
-			       msecs_to_jiffies(2000)) == 0)
+	if (nvkm_msec(device, 2000,
+		if (!(nvkm_rd32(device, 0x002284 + (runl * 0x08)) & 0x00100000))
+			break;
+	) < 0)
 		nvkm_error(subdev, "runlist %d update timeout\n", runl);
 unlock:
 	mutex_unlock(&subdev->mutex);

commit 665870837a764fc7ba6f0e1291291e86f909c29b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gk104-: add interfaces to support different runlist layouts
    
    This will be required to support features on newer hardware.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 316b2b1d08e8..afb3ed06ec89 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -140,6 +140,7 @@ gk104_fifo_uevent_init(struct nvkm_fifo *fifo)
 void
 gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 {
+	const struct gk104_fifo_runlist_func *func = fifo->func->runlist;
 	struct gk104_fifo_chan *chan;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
@@ -153,9 +154,7 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 
 	nvkm_kmap(mem);
 	list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
-		nvkm_wo32(mem, (nr * 8) + 0, chan->base.chid);
-		nvkm_wo32(mem, (nr * 8) + 4, 0x00000000);
-		nr++;
+		func->chan(chan, mem, nr++ * func->size);
 	}
 	nvkm_done(mem);
 
@@ -196,6 +195,20 @@ gk104_fifo_runlist_insert(struct gk104_fifo *fifo, struct gk104_fifo_chan *chan)
 	mutex_unlock(&fifo->base.engine.subdev.mutex);
 }
 
+void
+gk104_fifo_runlist_chan(struct gk104_fifo_chan *chan,
+			struct nvkm_memory *memory, u32 offset)
+{
+	nvkm_wo32(memory, offset + 0, chan->base.chid);
+	nvkm_wo32(memory, offset + 4, 0x00000000);
+}
+
+const struct gk104_fifo_runlist_func
+gk104_fifo_runlist = {
+	.size = 8,
+	.chan = gk104_fifo_runlist_chan,
+};
+
 static void
 gk104_fifo_recover_work(struct work_struct *w)
 {
@@ -874,17 +887,15 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	kfree(map);
 
 	for (i = 0; i < fifo->runlist_nr; i++) {
-		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-				      0x8000, 0x1000, false,
-				      &fifo->runlist[i].mem[0]);
-		if (ret)
-			return ret;
-
-		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-				      0x8000, 0x1000, false,
-				      &fifo->runlist[i].mem[1]);
-		if (ret)
-			return ret;
+		for (j = 0; j < ARRAY_SIZE(fifo->runlist[i].mem); j++) {
+			ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+					      fifo->base.nr * 2/* TSG+chan */ *
+					      fifo->func->runlist->size,
+					      0x1000, false,
+					      &fifo->runlist[i].mem[j]);
+			if (ret)
+				return ret;
+		}
 
 		init_waitqueue_head(&fifo->runlist[i].wait);
 		INIT_LIST_HEAD(&fifo->runlist[i].chan);
@@ -1111,6 +1122,7 @@ gk104_fifo = {
 	.fault.reason = gk104_fifo_fault_reason,
 	.fault.hubclient = gk104_fifo_fault_hubclient,
 	.fault.gpcclient = gk104_fifo_fault_gpcclient,
+	.runlist = &gk104_fifo_runlist,
 	.chan = {{0,0,KEPLER_CHANNEL_GPFIFO_A}, gk104_fifo_gpfifo_new },
 };
 

commit f9360c3aa61f792de3c839c63bfadf8640255d8c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gk104-: simplify definition of channel classes
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index b6c23cf43f83..316b2b1d08e8 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -94,16 +94,30 @@ gk104_fifo_engine_status(struct gk104_fifo *fifo, int engn,
 		   status->chan == &status->next ? "*" : " ");
 }
 
+static int
+gk104_fifo_class_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
+		     void *argv, u32 argc, struct nvkm_object **pobject)
+{
+	struct gk104_fifo *fifo = gk104_fifo(base);
+	if (oclass->engn == &fifo->func->chan) {
+		const struct gk104_fifo_chan_user *user = oclass->engn;
+		return user->ctor(fifo, oclass, argv, argc, pobject);
+	}
+	WARN_ON(1);
+	return -EINVAL;
+}
+
 static int
 gk104_fifo_class_get(struct nvkm_fifo *base, int index,
-		     const struct nvkm_fifo_chan_oclass **psclass)
+		     struct nvkm_oclass *oclass)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
 	int c = 0;
 
-	while ((*psclass = fifo->func->chan[c])) {
-		if (c++ == index)
-			return 0;
+	if (fifo->func->chan.ctor && c++ == index) {
+		oclass->base =  fifo->func->chan.user;
+		oclass->engn = &fifo->func->chan;
+		return 0;
 	}
 
 	return c;
@@ -950,6 +964,7 @@ gk104_fifo_ = {
 	.uevent_fini = gk104_fifo_uevent_fini,
 	.recover_chan = gk104_fifo_recover_chan,
 	.class_get = gk104_fifo_class_get,
+	.class_new = gk104_fifo_class_new,
 };
 
 int
@@ -1096,10 +1111,7 @@ gk104_fifo = {
 	.fault.reason = gk104_fifo_fault_reason,
 	.fault.hubclient = gk104_fifo_fault_hubclient,
 	.fault.gpcclient = gk104_fifo_fault_gpcclient,
-	.chan = {
-		&gk104_fifo_gpfifo_oclass,
-		NULL
-	},
+	.chan = {{0,0,KEPLER_CHANNEL_GPFIFO_A}, gk104_fifo_gpfifo_new },
 };
 
 int

commit cc36205085bb6e3a4eed1edbe413fd2235cadb27
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gk104-: support querying engines available on each runlist
    
    Will be used to improve channel runlist selection.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index b5706b15a64d..b6c23cf43f83 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -33,6 +33,7 @@
 #include <engine/sw.h>
 
 #include <nvif/class.h>
+#include <nvif/cl0080.h>
 
 struct gk104_fifo_engine_status {
 	bool busy;
@@ -783,6 +784,34 @@ gk104_fifo_fini(struct nvkm_fifo *base)
 	nvkm_mask(device, 0x002140, 0x10000000, 0x10000000);
 }
 
+static int
+gk104_fifo_info(struct nvkm_fifo *base, u64 mthd, u64 *data)
+{
+	struct gk104_fifo *fifo = gk104_fifo(base);
+	switch (mthd) {
+	case NV_DEVICE_FIFO_RUNLISTS:
+		*data = (1ULL << fifo->runlist_nr) - 1;
+		return 0;
+	case NV_DEVICE_FIFO_RUNLIST_ENGINES(0)...
+	     NV_DEVICE_FIFO_RUNLIST_ENGINES(63): {
+		int runl = mthd - NV_DEVICE_FIFO_RUNLIST_ENGINES(0), engn;
+		if (runl < fifo->runlist_nr) {
+			unsigned long engm = fifo->runlist[runl].engm;
+			struct nvkm_engine *engine;
+			*data = 0;
+			for_each_set_bit(engn, &engm, fifo->engine_nr) {
+				if ((engine = fifo->engine[engn].engine))
+					*data |= BIT_ULL(engine->subdev.index);
+			}
+			return 0;
+		}
+	}
+		return -EINVAL;
+	default:
+		return -EINVAL;
+	}
+}
+
 static int
 gk104_fifo_oneinit(struct nvkm_fifo *base)
 {
@@ -912,6 +941,7 @@ static const struct nvkm_fifo_func
 gk104_fifo_ = {
 	.dtor = gk104_fifo_dtor,
 	.oneinit = gk104_fifo_oneinit,
+	.info = gk104_fifo_info,
 	.init = gk104_fifo_init,
 	.fini = gk104_fifo_fini,
 	.intr = gk104_fifo_intr,

commit ddc669e25645b32158cc2b6da26faf5dac92fffc
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 8 20:39:46 2018 +1000

    drm/nouveau/fifo/gk104-: allow fault recovery code to be called by other subdevs
    
    This will be required to support Volta.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 84bd703dd897..b5706b15a64d 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -27,6 +27,7 @@
 #include <core/client.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
+#include <subdev/fault.h>
 #include <subdev/timer.h>
 #include <subdev/top.h>
 #include <engine/sw.h>
@@ -347,6 +348,90 @@ gk104_fifo_recover_engn(struct gk104_fifo *fifo, int engn)
 	schedule_work(&fifo->recover.work);
 }
 
+static void
+gk104_fifo_fault(struct nvkm_fifo *base, struct nvkm_fault_data *info)
+{
+	struct gk104_fifo *fifo = gk104_fifo(base);
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	const struct nvkm_enum *er, *ee, *ec, *ea;
+	struct nvkm_engine *engine = NULL;
+	struct nvkm_fifo_chan *chan;
+	unsigned long flags;
+	char ct[8] = "HUB/", en[16] = "";
+	int engn;
+
+	er = nvkm_enum_find(fifo->func->fault.reason, info->reason);
+	ee = nvkm_enum_find(fifo->func->fault.engine, info->engine);
+	if (info->hub) {
+		ec = nvkm_enum_find(fifo->func->fault.hubclient, info->client);
+	} else {
+		ec = nvkm_enum_find(fifo->func->fault.gpcclient, info->client);
+		snprintf(ct, sizeof(ct), "GPC%d/", info->gpc);
+	}
+	ea = nvkm_enum_find(fifo->func->fault.access, info->access);
+
+	if (ee && ee->data2) {
+		switch (ee->data2) {
+		case NVKM_SUBDEV_BAR:
+			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
+			break;
+		case NVKM_SUBDEV_INSTMEM:
+			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
+			break;
+		case NVKM_ENGINE_IFB:
+			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
+			break;
+		default:
+			engine = nvkm_device_engine(device, ee->data2);
+			break;
+		}
+	}
+
+	if (ee == NULL) {
+		enum nvkm_devidx engidx = nvkm_top_fault(device, info->engine);
+		if (engidx < NVKM_SUBDEV_NR) {
+			const char *src = nvkm_subdev_name[engidx];
+			char *dst = en;
+			do {
+				*dst++ = toupper(*src++);
+			} while(*src);
+			engine = nvkm_device_engine(device, engidx);
+		}
+	} else {
+		snprintf(en, sizeof(en), "%s", ee->name);
+	}
+
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	chan = nvkm_fifo_chan_inst_locked(&fifo->base, info->inst);
+
+	nvkm_error(subdev,
+		   "fault %02x [%s] at %016llx engine %02x [%s] client %02x "
+		   "[%s%s] reason %02x [%s] on channel %d [%010llx %s]\n",
+		   info->access, ea ? ea->name : "", info->addr,
+		   info->engine, ee ? ee->name : en,
+		   info->client, ct, ec ? ec->name : "",
+		   info->reason, er ? er->name : "", chan ? chan->chid : -1,
+		   info->inst, chan ? chan->object.client->name : "unknown");
+
+	/* Kill the channel that caused the fault. */
+	if (chan)
+		gk104_fifo_recover_chan(&fifo->base, chan->chid);
+
+	/* Channel recovery will probably have already done this for the
+	 * correct engine(s), but just in case we can't find the channel
+	 * information...
+	 */
+	for (engn = 0; engn < fifo->engine_nr && engine; engn++) {
+		if (fifo->engine[engn].engine == engine) {
+			gk104_fifo_recover_engn(fifo, engn);
+			break;
+		}
+	}
+
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
+}
+
 static const struct nvkm_enum
 gk104_fifo_bind_reason[] = {
 	{ 0x01, "BIND_NOT_UNBOUND" },
@@ -456,88 +541,21 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
 	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
 	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
-	u32 stat = nvkm_rd32(device, 0x00280c + (unit * 0x10));
-	u32 gpc    = (stat & 0x1f000000) >> 24;
-	u32 client = (stat & 0x00001f00) >> 8;
-	u32 write  = (stat & 0x00000080);
-	u32 hub    = (stat & 0x00000040);
-	u32 reason = (stat & 0x0000000f);
-	const struct nvkm_enum *er, *eu, *ec;
-	struct nvkm_engine *engine = NULL;
-	struct nvkm_fifo_chan *chan;
-	unsigned long flags;
-	char gpcid[8] = "", en[16] = "";
-	int engn;
-
-	er = nvkm_enum_find(fifo->func->fault.reason, reason);
-	eu = nvkm_enum_find(fifo->func->fault.engine, unit);
-	if (hub) {
-		ec = nvkm_enum_find(fifo->func->fault.hubclient, client);
-	} else {
-		ec = nvkm_enum_find(fifo->func->fault.gpcclient, client);
-		snprintf(gpcid, sizeof(gpcid), "GPC%d/", gpc);
-	}
-
-	if (eu && eu->data2) {
-		switch (eu->data2) {
-		case NVKM_SUBDEV_BAR:
-			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
-			break;
-		case NVKM_SUBDEV_INSTMEM:
-			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
-			break;
-		case NVKM_ENGINE_IFB:
-			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
-			break;
-		default:
-			engine = nvkm_device_engine(device, eu->data2);
-			break;
-		}
-	}
-
-	if (eu == NULL) {
-		enum nvkm_devidx engidx = nvkm_top_fault(device, unit);
-		if (engidx < NVKM_SUBDEV_NR) {
-			const char *src = nvkm_subdev_name[engidx];
-			char *dst = en;
-			do {
-				*dst++ = toupper(*src++);
-			} while(*src);
-			engine = nvkm_device_engine(device, engidx);
-		}
-	} else {
-		snprintf(en, sizeof(en), "%s", eu->name);
-	}
-
-	spin_lock_irqsave(&fifo->base.lock, flags);
-	chan = nvkm_fifo_chan_inst_locked(&fifo->base, (u64)inst << 12);
-
-	nvkm_error(subdev,
-		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
-		   "reason %02x [%s] on channel %d [%010llx %s]\n",
-		   write ? "write" : "read", (u64)vahi << 32 | valo,
-		   unit, en, client, gpcid, ec ? ec->name : "",
-		   reason, er ? er->name : "", chan ? chan->chid : -1,
-		   (u64)inst << 12,
-		   chan ? chan->object.client->name : "unknown");
-
-
-	/* Kill the channel that caused the fault. */
-	if (chan)
-		gk104_fifo_recover_chan(&fifo->base, chan->chid);
-
-	/* Channel recovery will probably have already done this for the
-	 * correct engine(s), but just in case we can't find the channel
-	 * information...
-	 */
-	for (engn = 0; engn < fifo->engine_nr && engine; engn++) {
-		if (fifo->engine[engn].engine == engine) {
-			gk104_fifo_recover_engn(fifo, engn);
-			break;
-		}
-	}
-
-	spin_unlock_irqrestore(&fifo->base.lock, flags);
+	u32 type = nvkm_rd32(device, 0x00280c + (unit * 0x10));
+	struct nvkm_fault_data info;
+
+	info.inst   =  (u64)inst << 12;
+	info.addr   = ((u64)vahi << 32) | valo;
+	info.time   = 0;
+	info.engine = unit;
+	info.valid  = 1;
+	info.gpc    = (type & 0x1f000000) >> 24;
+	info.client = (type & 0x00001f00) >> 8;
+	info.access = (type & 0x00000080) >> 7;
+	info.hub    = (type & 0x00000040) >> 6;
+	info.reason = (type & 0x000000ff);
+
+	nvkm_fifo_fault(&fifo->base, &info);
 }
 
 static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {
@@ -897,6 +915,7 @@ gk104_fifo_ = {
 	.init = gk104_fifo_init,
 	.fini = gk104_fifo_fini,
 	.intr = gk104_fifo_intr,
+	.fault = gk104_fifo_fault,
 	.uevent_init = gk104_fifo_uevent_init,
 	.uevent_fini = gk104_fifo_uevent_fini,
 	.recover_chan = gk104_fifo_recover_chan,
@@ -918,6 +937,13 @@ gk104_fifo_new_(const struct gk104_fifo_func *func, struct nvkm_device *device,
 	return nvkm_fifo_ctor(&gk104_fifo_, device, index, nr, &fifo->base);
 }
 
+const struct nvkm_enum
+gk104_fifo_fault_access[] = {
+	{ 0x0, "READ" },
+	{ 0x1, "WRITE" },
+	{}
+};
+
 const struct nvkm_enum
 gk104_fifo_fault_engine[] = {
 	{ 0x00, "GR", NULL, NVKM_ENGINE_GR },
@@ -1035,6 +1061,7 @@ gk104_fifo_fault_gpcclient[] = {
 
 static const struct gk104_fifo_func
 gk104_fifo = {
+	.fault.access = gk104_fifo_fault_access,
 	.fault.engine = gk104_fifo_fault_engine,
 	.fault.reason = gk104_fifo_fault_reason,
 	.fault.hubclient = gk104_fifo_fault_hubclient,

commit 01f349fcad68d80939db53d9110135e6341b786d
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/fifo/gf100-: use new interfaces for vmm operations
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index eddf9f12e9ee..84bd703dd897 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -27,7 +27,6 @@
 #include <core/client.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
-#include <subdev/fb.h>
 #include <subdev/timer.h>
 #include <subdev/top.h>
 #include <engine/sw.h>
@@ -836,12 +835,12 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	if (ret)
 		return ret;
 
-	ret = nvkm_vm_get(bar, nvkm_memory_size(fifo->user.mem), 12,
-			  NV_MEM_ACCESS_RW, &fifo->user.bar);
+	ret = nvkm_vmm_get(bar, 12, nvkm_memory_size(fifo->user.mem),
+			   &fifo->user.bar);
 	if (ret)
 		return ret;
 
-	return nvkm_memory_map(fifo->user.mem, 0, bar, &fifo->user.bar, NULL, 0);
+	return nvkm_memory_map(fifo->user.mem, 0, bar, fifo->user.bar, NULL, 0);
 }
 
 static void
@@ -867,7 +866,7 @@ gk104_fifo_init(struct nvkm_fifo *base)
 		nvkm_wr32(device, 0x04014c + (i * 0x2000), 0xffffffff); /* INTREN */
 	}
 
-	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
+	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar->addr >> 12);
 
 	nvkm_wr32(device, 0x002100, 0xffffffff);
 	nvkm_wr32(device, 0x002140, 0x7fffffff);
@@ -877,9 +876,10 @@ static void *
 gk104_fifo_dtor(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	int i;
 
-	nvkm_vm_put(&fifo->user.bar);
+	nvkm_vmm_put(nvkm_bar_bar1_vmm(device), &fifo->user.bar);
 	nvkm_memory_unref(&fifo->user.mem);
 
 	for (i = 0; i < fifo->runlist_nr; i++) {

commit 997a89003c2d950466bc289147ffb823c0c51fb0
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/memory: add reference counting
    
    We need to be able to prevent memory from being freed while it's still
    mapped in a GPU's address-space.
    
    Will be used by upcoming MMU changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 9629416f4947..eddf9f12e9ee 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -880,11 +880,11 @@ gk104_fifo_dtor(struct nvkm_fifo *base)
 	int i;
 
 	nvkm_vm_put(&fifo->user.bar);
-	nvkm_memory_del(&fifo->user.mem);
+	nvkm_memory_unref(&fifo->user.mem);
 
 	for (i = 0; i < fifo->runlist_nr; i++) {
-		nvkm_memory_del(&fifo->runlist[i].mem[1]);
-		nvkm_memory_del(&fifo->runlist[i].mem[0]);
+		nvkm_memory_unref(&fifo->runlist[i].mem[1]);
+		nvkm_memory_unref(&fifo->runlist[i].mem[0]);
 	}
 
 	return fifo;

commit 19a82e492c3d71efe8763d50496a1701dfcf3f15
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/memory: change map interface to support upcoming mmu changes
    
    Map flags (access, kind, etc) are currently defined in either the VMA,
    or the memory object, which turns out to not be ideal for things like
    suballocated buffers, etc.
    
    These will become per-map flags instead, so we need to support passing
    these arguments in nvkm_memory_map().
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index cdadff59bb4c..9629416f4947 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -841,8 +841,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	if (ret)
 		return ret;
 
-	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
-	return 0;
+	return nvkm_memory_map(fifo->user.mem, 0, bar, &fifo->user.bar, NULL, 0);
 }
 
 static void

commit 570889dc5070e1f98b5898dce426f970c9b9329b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/bar: modify interface to bar1 vmm mapping
    
    Upcoming changes will remove the nvkm_vmm pointer from nvkm_vma, instead
    requiring it to be explicitly specified on each operation.
    
    It's not currently possible to get this information for BAR1 mappings,
    so let's fix that ahead of time.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index a7e55c422501..cdadff59bb4c 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -27,6 +27,7 @@
 #include <core/client.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
+#include <subdev/fb.h>
 #include <subdev/timer.h>
 #include <subdev/top.h>
 #include <engine/sw.h>
@@ -771,6 +772,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	struct gk104_fifo *fifo = gk104_fifo(base);
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
+	struct nvkm_vmm *bar = nvkm_bar_bar1_vmm(device);
 	int engn, runl, pbid, ret, i, j;
 	enum nvkm_devidx engidx;
 	u32 *map;
@@ -834,8 +836,8 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	if (ret)
 		return ret;
 
-	ret = nvkm_bar_umap(device->bar, fifo->base.nr * 0x200, 12,
-			    &fifo->user.bar);
+	ret = nvkm_vm_get(bar, nvkm_memory_size(fifo->user.mem), 12,
+			  NV_MEM_ACCESS_RW, &fifo->user.bar);
 	if (ret)
 		return ret;
 

commit 2579b8b0ece53248b815042f8662a4531acf120d
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu Apr 27 12:12:56 2017 +0300

    drm/nouveau/fifo/gk104-: Silence a locking warning
    
    Presumably we can never actually hit this return, but static checkers
    complain that we should unlock before we return.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 3a24788c3185..a7e55c422501 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -148,7 +148,7 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 	case NVKM_MEM_TARGET_NCOH: target = 3; break;
 	default:
 		WARN_ON(1);
-		return;
+		goto unlock;
 	}
 
 	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(mem) >> 12) |
@@ -160,6 +160,7 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 				       & 0x00100000),
 			       msecs_to_jiffies(2000)) == 0)
 		nvkm_error(subdev, "runlist %d update timeout\n", runl);
+unlock:
 	mutex_unlock(&subdev->mutex);
 }
 

commit 3ebef76a1d46cd7e45aee6ad3efff9683b3a0f07
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 18 15:37:24 2017 +1000

    drm/nouveau/fifo/gk104-: trigger mmu fault before attempting engine recovery
    
    Greatly improves the chances of recovering the GPU from a CTXSW_TIMEOUT.
    
    Tested with piglit's arb_shader_image_load_store-atomicity, which causes
    GR to hang in such a way that recovery failed (CTXSW_TIMEOUT continually
    re-triggers).
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index e4e68f6fb138..3a24788c3185 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -280,10 +280,13 @@ gk104_fifo_recover_chan(struct nvkm_fifo *base, int chid)
 static void
 gk104_fifo_recover_engn(struct gk104_fifo *fifo, int engn)
 {
+	struct nvkm_engine *engine = fifo->engine[engn].engine;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	const u32 runl = fifo->engine[engn].runl;
 	const u32 engm = BIT(engn);
 	struct gk104_fifo_engine_status status;
+	int mmui = -1;
 
 	assert_spin_locked(&fifo->base.lock);
 	if (fifo->recover.engm & engm)
@@ -300,6 +303,44 @@ gk104_fifo_recover_engn(struct gk104_fifo *fifo, int engn)
 		gk104_fifo_recover_chan(&fifo->base, status.chan->id);
 	}
 
+	/* Determine MMU fault ID for the engine, if we're not being
+	 * called from the fault handler already.
+	 */
+	if (!status.faulted && engine) {
+		mmui = nvkm_top_fault_id(device, engine->subdev.index);
+		if (mmui < 0) {
+			const struct nvkm_enum *en = fifo->func->fault.engine;
+			for (; en && en->name; en++) {
+				if (en->data2 == engine->subdev.index) {
+					mmui = en->value;
+					break;
+				}
+			}
+		}
+		WARN_ON(mmui < 0);
+	}
+
+	/* Trigger a MMU fault for the engine.
+	 *
+	 * No good idea why this is needed, but nvgpu does something similar,
+	 * and it makes recovery from CTXSW_TIMEOUT a lot more reliable.
+	 */
+	if (mmui >= 0) {
+		nvkm_wr32(device, 0x002a30 + (engn * 0x04), 0x00000100 | mmui);
+
+		/* Wait for fault to trigger. */
+		nvkm_msec(device, 2000,
+			gk104_fifo_engine_status(fifo, engn, &status);
+			if (status.faulted)
+				break;
+		);
+
+		/* Release MMU fault trigger, and ACK the fault. */
+		nvkm_wr32(device, 0x002a30 + (engn * 0x04), 0x00000000);
+		nvkm_wr32(device, 0x00259c, BIT(mmui));
+		nvkm_wr32(device, 0x002100, 0x10000000);
+	}
+
 	/* Schedule recovery. */
 	nvkm_warn(subdev, "engine %d: scheduled for recovery\n", engn);
 	schedule_work(&fifo->recover.work);

commit 03f16f5f278af9ef477aa847fda4b09ed87dc382
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 18 16:05:15 2017 +1000

    drm/nouveau/fifo/gk104-: ACK SCHED_ERROR before attempting CTXSW_TIMEOUT recovery
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 52aedd891e80..e4e68f6fb138 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -338,10 +338,17 @@ gk104_fifo_sched_reason[] = {
 static void
 gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 {
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	unsigned long flags, engm = 0;
 	u32 engn;
 
+	/* We need to ACK the SCHED_ERROR here, and prevent it reasserting,
+	 * as MMU_FAULT cannot be triggered while it's pending.
+	 */
 	spin_lock_irqsave(&fifo->base.lock, flags);
+	nvkm_mask(device, 0x002140, 0x00000100, 0x00000000);
+	nvkm_wr32(device, 0x002100, 0x00000100);
+
 	for (engn = 0; engn < fifo->engine_nr; engn++) {
 		struct gk104_fifo_engine_status status;
 
@@ -355,6 +362,7 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 	for_each_set_bit(engn, &engm, fifo->engine_nr)
 		gk104_fifo_recover_engn(fifo, engn);
 
+	nvkm_mask(device, 0x002140, 0x00000100, 0x00000100);
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
 }
 

commit 91b9d659abfd557f79a02c0bc1f92393fdba1e22
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 18 16:03:44 2017 +1000

    drm/nouveau/fifo/gk104-: directly use new recovery code for ctxsw timeout
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 4422891d3a86..52aedd891e80 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -305,20 +305,6 @@ gk104_fifo_recover_engn(struct gk104_fifo *fifo, int engn)
 	schedule_work(&fifo->recover.work);
 }
 
-static void
-gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
-		   struct gk104_fifo_chan *chan)
-{
-	int engn;
-	for (engn = 0; engn < fifo->engine_nr; engn++) {
-		if (fifo->engine[engn].engine == engine) {
-			gk104_fifo_recover_engn(fifo, engn);
-			break;
-		}
-	}
-	gk104_fifo_recover_chan(&fifo->base, chan->base.chid);
-}
-
 static const struct nvkm_enum
 gk104_fifo_bind_reason[] = {
 	{ 0x01, "BIND_NOT_UNBOUND" },
@@ -352,27 +338,23 @@ gk104_fifo_sched_reason[] = {
 static void
 gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 {
-	struct gk104_fifo_chan *chan;
-	unsigned long flags;
+	unsigned long flags, engm = 0;
 	u32 engn;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
 	for (engn = 0; engn < fifo->engine_nr; engn++) {
-		struct nvkm_engine *engine = fifo->engine[engn].engine;
-		int runl = fifo->engine[engn].runl;
 		struct gk104_fifo_engine_status status;
 
 		gk104_fifo_engine_status(fifo, engn, &status);
 		if (!status.busy || !status.chsw)
 			continue;
 
-		list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
-			if (chan->base.chid == status.chan->id && engine) {
-				gk104_fifo_recover(fifo, engine, chan);
-				break;
-			}
-		}
+		engm |= BIT(engn);
 	}
+
+	for_each_set_bit(engn, &engm, fifo->engine_nr)
+		gk104_fifo_recover_engn(fifo, engn);
+
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
 }
 

commit 3534821df5e3635e3e7914a4802a74497815817e
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 18 16:01:11 2017 +1000

    drm/nouveau/fifo/gk104-: directly use new recovery code for mmu faults
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 4f174470c02b..4422891d3a86 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -435,6 +435,7 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	struct nvkm_fifo_chan *chan;
 	unsigned long flags;
 	char gpcid[8] = "", en[16] = "";
+	int engn;
 
 	er = nvkm_enum_find(fifo->func->fault.reason, reason);
 	eu = nvkm_enum_find(fifo->func->fault.engine, unit);
@@ -476,7 +477,8 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 		snprintf(en, sizeof(en), "%s", eu->name);
 	}
 
-	chan = nvkm_fifo_chan_inst(&fifo->base, (u64)inst << 12, &flags);
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	chan = nvkm_fifo_chan_inst_locked(&fifo->base, (u64)inst << 12);
 
 	nvkm_error(subdev,
 		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
@@ -487,9 +489,23 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 		   (u64)inst << 12,
 		   chan ? chan->object.client->name : "unknown");
 
-	if (engine && chan)
-		gk104_fifo_recover(fifo, engine, (void *)chan);
-	nvkm_fifo_chan_put(&fifo->base, flags, &chan);
+
+	/* Kill the channel that caused the fault. */
+	if (chan)
+		gk104_fifo_recover_chan(&fifo->base, chan->chid);
+
+	/* Channel recovery will probably have already done this for the
+	 * correct engine(s), but just in case we can't find the channel
+	 * information...
+	 */
+	for (engn = 0; engn < fifo->engine_nr && engine; engn++) {
+		if (fifo->engine[engn].engine == engine) {
+			gk104_fifo_recover_engn(fifo, engn);
+			break;
+		}
+	}
+
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
 }
 
 static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {

commit eaa5ed65eebb3ee9679a5f7b597c34a6207843c2
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 18 15:35:16 2017 +1000

    drm/nouveau/fifo/gk104-: reset all engines a killed channel is still active on
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index c45f732366b4..4f174470c02b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -243,6 +243,7 @@ gk104_fifo_recover_chan(struct nvkm_fifo *base, int chid)
 	const u32  stat = nvkm_rd32(device, 0x800004 + (chid * 0x08));
 	const u32  runl = (stat & 0x000f0000) >> 16;
 	const bool used = (stat & 0x00000001);
+	unsigned long engn, engm = fifo->runlist[runl].engm;
 	struct gk104_fifo_chan *chan;
 
 	assert_spin_locked(&fifo->base.lock);
@@ -262,6 +263,18 @@ gk104_fifo_recover_chan(struct nvkm_fifo *base, int chid)
 	/* Disable channel. */
 	nvkm_wr32(device, 0x800004 + (chid * 0x08), stat | 0x00000800);
 	nvkm_warn(subdev, "channel %d: killed\n", chid);
+
+	/* Block channel assignments from changing during recovery. */
+	gk104_fifo_recover_runl(fifo, runl);
+
+	/* Schedule recovery for any engines the channel is on. */
+	for_each_set_bit(engn, &engm, fifo->engine_nr) {
+		struct gk104_fifo_engine_status status;
+		gk104_fifo_engine_status(fifo, engn, &status);
+		if (!status.chan || status.chan->id != chid)
+			continue;
+		gk104_fifo_recover_engn(fifo, engn);
+	}
 }
 
 static void

commit 0faaa47d440df5302132c47f8f84b3f61d9fc424
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 18 15:22:43 2017 +1000

    drm/nouveau/fifo/gk104-: refactor recovery code
    
    This will serve as a basis for implementing some improvements to how
    we recover the GPU from channel errors.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 32c35397ae64..c45f732366b4 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -27,6 +27,7 @@
 #include <core/client.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
+#include <subdev/timer.h>
 #include <subdev/top.h>
 #include <engine/sw.h>
 
@@ -211,33 +212,98 @@ gk104_fifo_recover_work(struct work_struct *w)
 	nvkm_mask(device, 0x002630, runm, 0x00000000);
 }
 
+static void gk104_fifo_recover_engn(struct gk104_fifo *fifo, int engn);
+
 static void
-gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
-		   struct gk104_fifo_chan *chan)
+gk104_fifo_recover_runl(struct gk104_fifo *fifo, int runl)
 {
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	u32 chid = chan->base.chid;
-	int engn;
+	const u32 runm = BIT(runl);
 
-	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
-		   nvkm_subdev_name[engine->subdev.index], chid);
 	assert_spin_locked(&fifo->base.lock);
+	if (fifo->recover.runm & runm)
+		return;
+	fifo->recover.runm |= runm;
 
-	nvkm_mask(device, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
-	list_del_init(&chan->head);
-	chan->killed = true;
+	/* Block runlist to prevent channel assignment(s) from changing. */
+	nvkm_mask(device, 0x002630, runm, runm);
 
-	for (engn = 0; engn < fifo->engine_nr; engn++) {
-		if (fifo->engine[engn].engine == engine) {
-			fifo->recover.engm |= BIT(engn);
+	/* Schedule recovery. */
+	nvkm_warn(subdev, "runlist %d: scheduled for recovery\n", runl);
+	schedule_work(&fifo->recover.work);
+}
+
+static void
+gk104_fifo_recover_chan(struct nvkm_fifo *base, int chid)
+{
+	struct gk104_fifo *fifo = gk104_fifo(base);
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	const u32  stat = nvkm_rd32(device, 0x800004 + (chid * 0x08));
+	const u32  runl = (stat & 0x000f0000) >> 16;
+	const bool used = (stat & 0x00000001);
+	struct gk104_fifo_chan *chan;
+
+	assert_spin_locked(&fifo->base.lock);
+	if (!used)
+		return;
+
+	/* Lookup SW state for channel, and mark it as dead. */
+	list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
+		if (chan->base.chid == chid) {
+			list_del_init(&chan->head);
+			chan->killed = true;
+			nvkm_fifo_kevent(&fifo->base, chid);
 			break;
 		}
 	}
 
-	fifo->recover.runm |= BIT(chan->runl);
+	/* Disable channel. */
+	nvkm_wr32(device, 0x800004 + (chid * 0x08), stat | 0x00000800);
+	nvkm_warn(subdev, "channel %d: killed\n", chid);
+}
+
+static void
+gk104_fifo_recover_engn(struct gk104_fifo *fifo, int engn)
+{
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	const u32 runl = fifo->engine[engn].runl;
+	const u32 engm = BIT(engn);
+	struct gk104_fifo_engine_status status;
+
+	assert_spin_locked(&fifo->base.lock);
+	if (fifo->recover.engm & engm)
+		return;
+	fifo->recover.engm |= engm;
+
+	/* Block channel assignments from changing during recovery. */
+	gk104_fifo_recover_runl(fifo, runl);
+
+	/* Determine which channel (if any) is currently on the engine. */
+	gk104_fifo_engine_status(fifo, engn, &status);
+	if (status.chan) {
+		/* The channel is not longer viable, kill it. */
+		gk104_fifo_recover_chan(&fifo->base, status.chan->id);
+	}
+
+	/* Schedule recovery. */
+	nvkm_warn(subdev, "engine %d: scheduled for recovery\n", engn);
 	schedule_work(&fifo->recover.work);
-	nvkm_fifo_kevent(&fifo->base, chid);
+}
+
+static void
+gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
+		   struct gk104_fifo_chan *chan)
+{
+	int engn;
+	for (engn = 0; engn < fifo->engine_nr; engn++) {
+		if (fifo->engine[engn].engine == engine) {
+			gk104_fifo_recover_engn(fifo, engn);
+			break;
+		}
+	}
+	gk104_fifo_recover_chan(&fifo->base, chan->base.chid);
 }
 
 static const struct nvkm_enum
@@ -771,6 +837,7 @@ gk104_fifo_ = {
 	.intr = gk104_fifo_intr,
 	.uevent_init = gk104_fifo_uevent_init,
 	.uevent_fini = gk104_fifo_uevent_fini,
+	.recover_chan = gk104_fifo_recover_chan,
 	.class_get = gk104_fifo_class_get,
 };
 

commit ec5c6bda19408b78f8bc0e0592c7805e8550470f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Mon Jan 16 10:36:00 2017 +1000

    drm/nouveau/fifo/gk104-: better detection of chid when parsing engine status
    
    The previous commit simply changes the interface, but should result in
    the same behaviour as previously.  This commit has been split out from
    it as it can result in a different channel being selected.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 6d12a2efee11..32c35397ae64 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -48,6 +48,7 @@ static void
 gk104_fifo_engine_status(struct gk104_fifo *fifo, int engn,
 			 struct gk104_fifo_engine_status *status)
 {
+	struct nvkm_engine *engine = fifo->engine[engn].engine;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
@@ -61,7 +62,24 @@ gk104_fifo_engine_status(struct gk104_fifo *fifo, int engn,
 	status->load     = !!(stat & 0x00002000);
 	status->prev.tsg = !!(stat & 0x00001000);
 	status->prev.id  =   (stat & 0x00000fff);
-	status->chan     = status->load ? &status->next : &status->prev;
+	status->chan     = NULL;
+
+	if (status->busy && status->chsw) {
+		if (status->load && status->save) {
+			if (engine && nvkm_engine_chsw_load(engine))
+				status->chan = &status->next;
+			else
+				status->chan = &status->prev;
+		} else
+		if (status->load) {
+			status->chan = &status->next;
+		} else {
+			status->chan = &status->prev;
+		}
+	} else
+	if (status->load) {
+		status->chan = &status->prev;
+	}
 
 	nvkm_debug(subdev, "engine %02d: busy %d faulted %d chsw %d "
 			   "save %d load %d %sid %d%s-> %sid %d%s\n",

commit b88917fe0fbb1a8479545ba62496ff71d63b397b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Mon Jan 16 10:14:36 2017 +1000

    drm/nouveau/fifo/gk104-: separate out engine status parsing
    
    We'll be wanting to reuse this logic in more places.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 67a6a514b5fa..6d12a2efee11 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -32,6 +32,47 @@
 
 #include <nvif/class.h>
 
+struct gk104_fifo_engine_status {
+	bool busy;
+	bool faulted;
+	bool chsw;
+	bool save;
+	bool load;
+	struct {
+		bool tsg;
+		u32 id;
+	} prev, next, *chan;
+};
+
+static void
+gk104_fifo_engine_status(struct gk104_fifo *fifo, int engn,
+			 struct gk104_fifo_engine_status *status)
+{
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
+
+	status->busy     = !!(stat & 0x80000000);
+	status->faulted  = !!(stat & 0x40000000);
+	status->next.tsg = !!(stat & 0x10000000);
+	status->next.id  =   (stat & 0x0fff0000) >> 16;
+	status->chsw     = !!(stat & 0x00008000);
+	status->save     = !!(stat & 0x00004000);
+	status->load     = !!(stat & 0x00002000);
+	status->prev.tsg = !!(stat & 0x00001000);
+	status->prev.id  =   (stat & 0x00000fff);
+	status->chan     = status->load ? &status->next : &status->prev;
+
+	nvkm_debug(subdev, "engine %02d: busy %d faulted %d chsw %d "
+			   "save %d load %d %sid %d%s-> %sid %d%s\n",
+		   engn, status->busy, status->faulted,
+		   status->chsw, status->save, status->load,
+		   status->prev.tsg ? "tsg" : "ch", status->prev.id,
+		   status->chan == &status->prev ? "*" : " ",
+		   status->next.tsg ? "tsg" : "ch", status->next.id,
+		   status->chan == &status->next ? "*" : " ");
+}
+
 static int
 gk104_fifo_class_get(struct nvkm_fifo *base, int index,
 		     const struct nvkm_fifo_chan_oclass **psclass)
@@ -214,7 +255,6 @@ gk104_fifo_sched_reason[] = {
 static void
 gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct gk104_fifo_chan *chan;
 	unsigned long flags;
 	u32 engn;
@@ -223,21 +263,14 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 	for (engn = 0; engn < fifo->engine_nr; engn++) {
 		struct nvkm_engine *engine = fifo->engine[engn].engine;
 		int runl = fifo->engine[engn].runl;
-		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
-		u32 busy = (stat & 0x80000000);
-		u32 next = (stat & 0x0fff0000) >> 16;
-		u32 chsw = (stat & 0x00008000);
-		u32 save = (stat & 0x00004000);
-		u32 load = (stat & 0x00002000);
-		u32 prev = (stat & 0x00000fff);
-		u32 chid = load ? next : prev;
-		(void)save;
-
-		if (!busy || !chsw)
+		struct gk104_fifo_engine_status status;
+
+		gk104_fifo_engine_status(fifo, engn, &status);
+		if (!status.busy || !status.chsw)
 			continue;
 
 		list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
-			if (chan->base.chid == chid && engine) {
+			if (chan->base.chid == status.chan->id && engine) {
 				gk104_fifo_recover(fifo, engine, chan);
 				break;
 			}

commit ff9f29abf0ef4c43e696bef7621884518e6bdbda
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Sat Nov 5 13:05:14 2016 +1000

    drm/nouveau/fifo/gf100-: provide notification to user if channel is killed
    
    There are instances (such as non-recoverable GPU page faults) where
    NVKM decides that a channel's context is no longer viable, and will
    be removed from the runlist.
    
    This commit notifies the owner of the channel when this happens, so
    it has the opportunity to take some kind of recovery action instead
    of hanging.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 73ae4ecc2e9a..67a6a514b5fa 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -178,6 +178,7 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 
 	fifo->recover.runm |= BIT(chan->runl);
 	schedule_work(&fifo->recover.work);
+	nvkm_fifo_kevent(&fifo->base, chid);
 }
 
 static const struct nvkm_enum

commit d2ee360564dca43cbfb2bd8ceead7671c87962d2
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 10 12:42:26 2016 +1000

    drm/nouveau/core/memory: distinguish between coherent/non-coherent targets
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 38c0910722c0..73ae4ecc2e9a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -83,10 +83,13 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 	}
 	nvkm_done(mem);
 
-	if (nvkm_memory_target(mem) == NVKM_MEM_TARGET_VRAM)
-		target = 0;
-	else
-		target = 3;
+	switch (nvkm_memory_target(mem)) {
+	case NVKM_MEM_TARGET_VRAM: target = 0; break;
+	case NVKM_MEM_TARGET_NCOH: target = 3; break;
+	default:
+		WARN_ON(1);
+		return;
+	}
 
 	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(mem) >> 12) |
 				    (target << 28));

commit ec884f74f1ec8ffa6a77a2769087117aeec80c1f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Dec 9 17:13:08 2016 +1000

    drm/nouveau/fifo/gf100-: recover from host mmu faults
    
    This has been on the TODO list for a while now, recovering from things
    such as attempting to execute a push buffer or touch a semaphore in an
    unmapped memory area.
    
    The only thing required on the HW side here is that the offending
    channel is removed from the runlist, and *not* a full reset of PFIFO.
    
    This used to be a bit messier to handle before the rework to make use
    of engine topology info, but is apparently now trivial.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 103c0afaaa6d..38c0910722c0 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -743,14 +743,14 @@ gk104_fifo_fault_engine[] = {
 	{ 0x04, "BAR1", NULL, NVKM_SUBDEV_BAR },
 	{ 0x05, "BAR2", NULL, NVKM_SUBDEV_INSTMEM },
 	{ 0x06, "SCHED" },
-	{ 0x07, "HOST0" },
-	{ 0x08, "HOST1" },
-	{ 0x09, "HOST2" },
-	{ 0x0a, "HOST3" },
-	{ 0x0b, "HOST4" },
-	{ 0x0c, "HOST5" },
-	{ 0x0d, "HOST6" },
-	{ 0x0e, "HOST7" },
+	{ 0x07, "HOST0", NULL, NVKM_ENGINE_FIFO },
+	{ 0x08, "HOST1", NULL, NVKM_ENGINE_FIFO },
+	{ 0x09, "HOST2", NULL, NVKM_ENGINE_FIFO },
+	{ 0x0a, "HOST3", NULL, NVKM_ENGINE_FIFO },
+	{ 0x0b, "HOST4", NULL, NVKM_ENGINE_FIFO },
+	{ 0x0c, "HOST5", NULL, NVKM_ENGINE_FIFO },
+	{ 0x0d, "HOST6", NULL, NVKM_ENGINE_FIFO },
+	{ 0x0e, "HOST7", NULL, NVKM_ENGINE_FIFO },
 	{ 0x0f, "HOSTSR" },
 	{ 0x10, "MSVLD", NULL, NVKM_ENGINE_MSVLD },
 	{ 0x11, "MSPPP", NULL, NVKM_ENGINE_MSPPP },

commit 1fe8c02fbcc0a3310a7790a3b694cb5105a7302f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jun 22 10:17:11 2016 +1000

    drm/nouveau/fifo/gk104-: translate engidx into human-readable name in debug output
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index f574b744cf66..103c0afaaa6d 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -616,8 +616,8 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 			}
 		}
 
-		nvkm_debug(subdev, "engine %2d: runlist %2d pbdma %2d\n",
-			   engn, runl, pbid);
+		nvkm_debug(subdev, "engine %2d: runlist %2d pbdma %2d (%s)\n",
+			   engn, runl, pbid, nvkm_subdev_name[engidx]);
 
 		fifo->engine[engn].engine = nvkm_device_engine(device, engidx);
 		fifo->engine[engn].runl = runl;

commit 952eb819e3234b9deceb3287398f0c2a272e4760
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Mon May 30 10:32:55 2016 +1000

    drm/nouveau/top: take nvkm_device as argument to public functions
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 743f3a189f28..f574b744cf66 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -329,7 +329,7 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	}
 
 	if (eu == NULL) {
-		enum nvkm_devidx engidx = nvkm_top_fault(device->top, unit);
+		enum nvkm_devidx engidx = nvkm_top_fault(device, unit);
 		if (engidx < NVKM_SUBDEV_NR) {
 			const char *src = nvkm_subdev_name[engidx];
 			char *dst = en;
@@ -589,7 +589,6 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	struct gk104_fifo *fifo = gk104_fifo(base);
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	struct nvkm_top *top = device->top;
 	int engn, runl, pbid, ret, i, j;
 	enum nvkm_devidx engidx;
 	u32 *map;
@@ -608,7 +607,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 
 	/* Determine runlist configuration from topology device info. */
 	i = 0;
-	while ((int)(engidx = nvkm_top_engine(top, i++, &runl, &engn)) >= 0) {
+	while ((int)(engidx = nvkm_top_engine(device, i++, &runl, &engn)) >= 0) {
 		/* Determine which PBDMA handles requests for this engine. */
 		for (j = 0, pbid = -1; j < fifo->pbdma_nr; j++) {
 			if (map[j] & (1 << runl)) {

commit 289e082706ca8191be16298ca8f06879a70d0f46
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Apr 8 17:24:40 2016 +1000

    drm/nouveau/fifo/gk104-: identify mmu engine ids for host faults
    
    It appears these don't map to PBDMAs (at least on Kepler, it may or may
    be valid for Fermi - this hasn't been checked), but to runlists.
    
    This drops the NVKM_ENGINE_FIFO data from the entries too, as resetting
    all of PFIFO is *not* the way to handle such faults.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 6e842768f558..743f3a189f28 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -738,12 +738,21 @@ gk104_fifo_new_(const struct gk104_fifo_func *func, struct nvkm_device *device,
 const struct nvkm_enum
 gk104_fifo_fault_engine[] = {
 	{ 0x00, "GR", NULL, NVKM_ENGINE_GR },
+	{ 0x01, "DISPLAY" },
+	{ 0x02, "CAPTURE" },
 	{ 0x03, "IFB", NULL, NVKM_ENGINE_IFB },
 	{ 0x04, "BAR1", NULL, NVKM_SUBDEV_BAR },
-	{ 0x05, "BAR3", NULL, NVKM_SUBDEV_INSTMEM },
-	{ 0x07, "PBDMA0", NULL, NVKM_ENGINE_FIFO },
-	{ 0x08, "PBDMA1", NULL, NVKM_ENGINE_FIFO },
-	{ 0x09, "PBDMA2", NULL, NVKM_ENGINE_FIFO },
+	{ 0x05, "BAR2", NULL, NVKM_SUBDEV_INSTMEM },
+	{ 0x06, "SCHED" },
+	{ 0x07, "HOST0" },
+	{ 0x08, "HOST1" },
+	{ 0x09, "HOST2" },
+	{ 0x0a, "HOST3" },
+	{ 0x0b, "HOST4" },
+	{ 0x0c, "HOST5" },
+	{ 0x0d, "HOST6" },
+	{ 0x0e, "HOST7" },
+	{ 0x0f, "HOSTSR" },
 	{ 0x10, "MSVLD", NULL, NVKM_ENGINE_MSVLD },
 	{ 0x11, "MSPPP", NULL, NVKM_ENGINE_MSPPP },
 	{ 0x13, "PERF" },
@@ -751,6 +760,7 @@ gk104_fifo_fault_engine[] = {
 	{ 0x15, "CE0", NULL, NVKM_ENGINE_CE0 },
 	{ 0x16, "CE1", NULL, NVKM_ENGINE_CE1 },
 	{ 0x17, "PMU" },
+	{ 0x18, "PTP" },
 	{ 0x19, "MSENC", NULL, NVKM_ENGINE_MSENC },
 	{ 0x1b, "CE2", NULL, NVKM_ENGINE_CE2 },
 	{}

commit e50d0237fc371be7053082f35efab03a740d055f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Apr 8 17:24:40 2016 +1000

    drm/nouveau/fifo/gk104-: implement support for PTOP fault info
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 67d440b374f0..6e842768f558 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -300,7 +300,7 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	struct nvkm_engine *engine = NULL;
 	struct nvkm_fifo_chan *chan;
 	unsigned long flags;
-	char gpcid[8] = "";
+	char gpcid[8] = "", en[16] = "";
 
 	er = nvkm_enum_find(fifo->func->fault.reason, reason);
 	eu = nvkm_enum_find(fifo->func->fault.engine, unit);
@@ -328,13 +328,27 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 		}
 	}
 
+	if (eu == NULL) {
+		enum nvkm_devidx engidx = nvkm_top_fault(device->top, unit);
+		if (engidx < NVKM_SUBDEV_NR) {
+			const char *src = nvkm_subdev_name[engidx];
+			char *dst = en;
+			do {
+				*dst++ = toupper(*src++);
+			} while(*src);
+			engine = nvkm_device_engine(device, engidx);
+		}
+	} else {
+		snprintf(en, sizeof(en), "%s", eu->name);
+	}
+
 	chan = nvkm_fifo_chan_inst(&fifo->base, (u64)inst << 12, &flags);
 
 	nvkm_error(subdev,
 		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
 		   "reason %02x [%s] on channel %d [%010llx %s]\n",
 		   write ? "write" : "read", (u64)vahi << 32 | valo,
-		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
+		   unit, en, client, gpcid, ec ? ec->name : "",
 		   reason, er ? er->name : "", chan ? chan->chid : -1,
 		   (u64)inst << 12,
 		   chan ? chan->object.client->name : "unknown");

commit 91419acf7819d8a0ca5f36b924f224c92f96eeb8
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Apr 8 17:24:40 2016 +1000

    drm/nouveau/fifo/gk104-: abstract mmu fault data structures
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index ddab2c82c6d5..67d440b374f0 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -25,7 +25,6 @@
 #include "changk104.h"
 
 #include <core/client.h>
-#include <core/enum.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
 #include <subdev/top.h>
@@ -283,111 +282,6 @@ gk104_fifo_intr_dropped_fault(struct gk104_fifo *fifo)
 	nvkm_error(subdev, "DROPPED_MMU_FAULT %08x\n", stat);
 }
 
-static const struct nvkm_enum
-gk104_fifo_fault_engine[] = {
-	{ 0x00, "GR", NULL, NVKM_ENGINE_GR },
-	{ 0x03, "IFB", NULL, NVKM_ENGINE_IFB },
-	{ 0x04, "BAR1", NULL, NVKM_SUBDEV_BAR },
-	{ 0x05, "BAR3", NULL, NVKM_SUBDEV_INSTMEM },
-	{ 0x07, "PBDMA0", NULL, NVKM_ENGINE_FIFO },
-	{ 0x08, "PBDMA1", NULL, NVKM_ENGINE_FIFO },
-	{ 0x09, "PBDMA2", NULL, NVKM_ENGINE_FIFO },
-	{ 0x10, "MSVLD", NULL, NVKM_ENGINE_MSVLD },
-	{ 0x11, "MSPPP", NULL, NVKM_ENGINE_MSPPP },
-	{ 0x13, "PERF" },
-	{ 0x14, "MSPDEC", NULL, NVKM_ENGINE_MSPDEC },
-	{ 0x15, "CE0", NULL, NVKM_ENGINE_CE0 },
-	{ 0x16, "CE1", NULL, NVKM_ENGINE_CE1 },
-	{ 0x17, "PMU" },
-	{ 0x19, "MSENC", NULL, NVKM_ENGINE_MSENC },
-	{ 0x1b, "CE2", NULL, NVKM_ENGINE_CE2 },
-	{}
-};
-
-static const struct nvkm_enum
-gk104_fifo_fault_reason[] = {
-	{ 0x00, "PDE" },
-	{ 0x01, "PDE_SIZE" },
-	{ 0x02, "PTE" },
-	{ 0x03, "VA_LIMIT_VIOLATION" },
-	{ 0x04, "UNBOUND_INST_BLOCK" },
-	{ 0x05, "PRIV_VIOLATION" },
-	{ 0x06, "RO_VIOLATION" },
-	{ 0x07, "WO_VIOLATION" },
-	{ 0x08, "PITCH_MASK_VIOLATION" },
-	{ 0x09, "WORK_CREATION" },
-	{ 0x0a, "UNSUPPORTED_APERTURE" },
-	{ 0x0b, "COMPRESSION_FAILURE" },
-	{ 0x0c, "UNSUPPORTED_KIND" },
-	{ 0x0d, "REGION_VIOLATION" },
-	{ 0x0e, "BOTH_PTES_VALID" },
-	{ 0x0f, "INFO_TYPE_POISONED" },
-	{}
-};
-
-static const struct nvkm_enum
-gk104_fifo_fault_hubclient[] = {
-	{ 0x00, "VIP" },
-	{ 0x01, "CE0" },
-	{ 0x02, "CE1" },
-	{ 0x03, "DNISO" },
-	{ 0x04, "FE" },
-	{ 0x05, "FECS" },
-	{ 0x06, "HOST" },
-	{ 0x07, "HOST_CPU" },
-	{ 0x08, "HOST_CPU_NB" },
-	{ 0x09, "ISO" },
-	{ 0x0a, "MMU" },
-	{ 0x0b, "MSPDEC" },
-	{ 0x0c, "MSPPP" },
-	{ 0x0d, "MSVLD" },
-	{ 0x0e, "NISO" },
-	{ 0x0f, "P2P" },
-	{ 0x10, "PD" },
-	{ 0x11, "PERF" },
-	{ 0x12, "PMU" },
-	{ 0x13, "RASTERTWOD" },
-	{ 0x14, "SCC" },
-	{ 0x15, "SCC_NB" },
-	{ 0x16, "SEC" },
-	{ 0x17, "SSYNC" },
-	{ 0x18, "GR_CE" },
-	{ 0x19, "CE2" },
-	{ 0x1a, "XV" },
-	{ 0x1b, "MMU_NB" },
-	{ 0x1c, "MSENC" },
-	{ 0x1d, "DFALCON" },
-	{ 0x1e, "SKED" },
-	{ 0x1f, "AFALCON" },
-	{}
-};
-
-static const struct nvkm_enum
-gk104_fifo_fault_gpcclient[] = {
-	{ 0x00, "L1_0" }, { 0x01, "T1_0" }, { 0x02, "PE_0" },
-	{ 0x03, "L1_1" }, { 0x04, "T1_1" }, { 0x05, "PE_1" },
-	{ 0x06, "L1_2" }, { 0x07, "T1_2" }, { 0x08, "PE_2" },
-	{ 0x09, "L1_3" }, { 0x0a, "T1_3" }, { 0x0b, "PE_3" },
-	{ 0x0c, "RAST" },
-	{ 0x0d, "GCC" },
-	{ 0x0e, "GPCCS" },
-	{ 0x0f, "PROP_0" },
-	{ 0x10, "PROP_1" },
-	{ 0x11, "PROP_2" },
-	{ 0x12, "PROP_3" },
-	{ 0x13, "L1_4" }, { 0x14, "T1_4" }, { 0x15, "PE_4" },
-	{ 0x16, "L1_5" }, { 0x17, "T1_5" }, { 0x18, "PE_5" },
-	{ 0x19, "L1_6" }, { 0x1a, "T1_6" }, { 0x1b, "PE_6" },
-	{ 0x1c, "L1_7" }, { 0x1d, "T1_7" }, { 0x1e, "PE_7" },
-	{ 0x1f, "GPM" },
-	{ 0x20, "LTP_UTLB_0" },
-	{ 0x21, "LTP_UTLB_1" },
-	{ 0x22, "LTP_UTLB_2" },
-	{ 0x23, "LTP_UTLB_3" },
-	{ 0x24, "GPC_RGG_UTLB" },
-	{}
-};
-
 static void
 gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 {
@@ -408,12 +302,12 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	unsigned long flags;
 	char gpcid[8] = "";
 
-	er = nvkm_enum_find(gk104_fifo_fault_reason, reason);
-	eu = nvkm_enum_find(gk104_fifo_fault_engine, unit);
+	er = nvkm_enum_find(fifo->func->fault.reason, reason);
+	eu = nvkm_enum_find(fifo->func->fault.engine, unit);
 	if (hub) {
-		ec = nvkm_enum_find(gk104_fifo_fault_hubclient, client);
+		ec = nvkm_enum_find(fifo->func->fault.hubclient, client);
 	} else {
-		ec = nvkm_enum_find(gk104_fifo_fault_gpcclient, client);
+		ec = nvkm_enum_find(fifo->func->fault.gpcclient, client);
 		snprintf(gpcid, sizeof(gpcid), "GPC%d/", gpc);
 	}
 
@@ -827,8 +721,117 @@ gk104_fifo_new_(const struct gk104_fifo_func *func, struct nvkm_device *device,
 	return nvkm_fifo_ctor(&gk104_fifo_, device, index, nr, &fifo->base);
 }
 
+const struct nvkm_enum
+gk104_fifo_fault_engine[] = {
+	{ 0x00, "GR", NULL, NVKM_ENGINE_GR },
+	{ 0x03, "IFB", NULL, NVKM_ENGINE_IFB },
+	{ 0x04, "BAR1", NULL, NVKM_SUBDEV_BAR },
+	{ 0x05, "BAR3", NULL, NVKM_SUBDEV_INSTMEM },
+	{ 0x07, "PBDMA0", NULL, NVKM_ENGINE_FIFO },
+	{ 0x08, "PBDMA1", NULL, NVKM_ENGINE_FIFO },
+	{ 0x09, "PBDMA2", NULL, NVKM_ENGINE_FIFO },
+	{ 0x10, "MSVLD", NULL, NVKM_ENGINE_MSVLD },
+	{ 0x11, "MSPPP", NULL, NVKM_ENGINE_MSPPP },
+	{ 0x13, "PERF" },
+	{ 0x14, "MSPDEC", NULL, NVKM_ENGINE_MSPDEC },
+	{ 0x15, "CE0", NULL, NVKM_ENGINE_CE0 },
+	{ 0x16, "CE1", NULL, NVKM_ENGINE_CE1 },
+	{ 0x17, "PMU" },
+	{ 0x19, "MSENC", NULL, NVKM_ENGINE_MSENC },
+	{ 0x1b, "CE2", NULL, NVKM_ENGINE_CE2 },
+	{}
+};
+
+const struct nvkm_enum
+gk104_fifo_fault_reason[] = {
+	{ 0x00, "PDE" },
+	{ 0x01, "PDE_SIZE" },
+	{ 0x02, "PTE" },
+	{ 0x03, "VA_LIMIT_VIOLATION" },
+	{ 0x04, "UNBOUND_INST_BLOCK" },
+	{ 0x05, "PRIV_VIOLATION" },
+	{ 0x06, "RO_VIOLATION" },
+	{ 0x07, "WO_VIOLATION" },
+	{ 0x08, "PITCH_MASK_VIOLATION" },
+	{ 0x09, "WORK_CREATION" },
+	{ 0x0a, "UNSUPPORTED_APERTURE" },
+	{ 0x0b, "COMPRESSION_FAILURE" },
+	{ 0x0c, "UNSUPPORTED_KIND" },
+	{ 0x0d, "REGION_VIOLATION" },
+	{ 0x0e, "BOTH_PTES_VALID" },
+	{ 0x0f, "INFO_TYPE_POISONED" },
+	{}
+};
+
+const struct nvkm_enum
+gk104_fifo_fault_hubclient[] = {
+	{ 0x00, "VIP" },
+	{ 0x01, "CE0" },
+	{ 0x02, "CE1" },
+	{ 0x03, "DNISO" },
+	{ 0x04, "FE" },
+	{ 0x05, "FECS" },
+	{ 0x06, "HOST" },
+	{ 0x07, "HOST_CPU" },
+	{ 0x08, "HOST_CPU_NB" },
+	{ 0x09, "ISO" },
+	{ 0x0a, "MMU" },
+	{ 0x0b, "MSPDEC" },
+	{ 0x0c, "MSPPP" },
+	{ 0x0d, "MSVLD" },
+	{ 0x0e, "NISO" },
+	{ 0x0f, "P2P" },
+	{ 0x10, "PD" },
+	{ 0x11, "PERF" },
+	{ 0x12, "PMU" },
+	{ 0x13, "RASTERTWOD" },
+	{ 0x14, "SCC" },
+	{ 0x15, "SCC_NB" },
+	{ 0x16, "SEC" },
+	{ 0x17, "SSYNC" },
+	{ 0x18, "GR_CE" },
+	{ 0x19, "CE2" },
+	{ 0x1a, "XV" },
+	{ 0x1b, "MMU_NB" },
+	{ 0x1c, "MSENC" },
+	{ 0x1d, "DFALCON" },
+	{ 0x1e, "SKED" },
+	{ 0x1f, "AFALCON" },
+	{}
+};
+
+const struct nvkm_enum
+gk104_fifo_fault_gpcclient[] = {
+	{ 0x00, "L1_0" }, { 0x01, "T1_0" }, { 0x02, "PE_0" },
+	{ 0x03, "L1_1" }, { 0x04, "T1_1" }, { 0x05, "PE_1" },
+	{ 0x06, "L1_2" }, { 0x07, "T1_2" }, { 0x08, "PE_2" },
+	{ 0x09, "L1_3" }, { 0x0a, "T1_3" }, { 0x0b, "PE_3" },
+	{ 0x0c, "RAST" },
+	{ 0x0d, "GCC" },
+	{ 0x0e, "GPCCS" },
+	{ 0x0f, "PROP_0" },
+	{ 0x10, "PROP_1" },
+	{ 0x11, "PROP_2" },
+	{ 0x12, "PROP_3" },
+	{ 0x13, "L1_4" }, { 0x14, "T1_4" }, { 0x15, "PE_4" },
+	{ 0x16, "L1_5" }, { 0x17, "T1_5" }, { 0x18, "PE_5" },
+	{ 0x19, "L1_6" }, { 0x1a, "T1_6" }, { 0x1b, "PE_6" },
+	{ 0x1c, "L1_7" }, { 0x1d, "T1_7" }, { 0x1e, "PE_7" },
+	{ 0x1f, "GPM" },
+	{ 0x20, "LTP_UTLB_0" },
+	{ 0x21, "LTP_UTLB_1" },
+	{ 0x22, "LTP_UTLB_2" },
+	{ 0x23, "LTP_UTLB_3" },
+	{ 0x24, "GPC_RGG_UTLB" },
+	{}
+};
+
 static const struct gk104_fifo_func
 gk104_fifo = {
+	.fault.engine = gk104_fifo_fault_engine,
+	.fault.reason = gk104_fifo_fault_reason,
+	.fault.hubclient = gk104_fifo_fault_hubclient,
+	.fault.gpcclient = gk104_fifo_fault_gpcclient,
 	.chan = {
 		&gk104_fifo_gpfifo_oclass,
 		NULL

commit 98ac3f061afa9b8347948451cb4e2d336d0a8912
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Apr 8 17:24:40 2016 +1000

    drm/nouveau/fifo/gk104-: subclass func
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index fcb9a7593dbf..ddab2c82c6d5 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -33,14 +33,29 @@
 
 #include <nvif/class.h>
 
-void
+static int
+gk104_fifo_class_get(struct nvkm_fifo *base, int index,
+		     const struct nvkm_fifo_chan_oclass **psclass)
+{
+	struct gk104_fifo *fifo = gk104_fifo(base);
+	int c = 0;
+
+	while ((*psclass = fifo->func->chan[c])) {
+		if (c++ == index)
+			return 0;
+	}
+
+	return c;
+}
+
+static void
 gk104_fifo_uevent_fini(struct nvkm_fifo *fifo)
 {
 	struct nvkm_device *device = fifo->engine.subdev.device;
 	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
 }
 
-void
+static void
 gk104_fifo_uevent_init(struct nvkm_fifo *fifo)
 {
 	struct nvkm_device *device = fifo->engine.subdev.device;
@@ -558,7 +573,7 @@ gk104_fifo_intr_engine(struct gk104_fifo *fifo)
 	nvkm_fifo_uevent(&fifo->base);
 }
 
-void
+static void
 gk104_fifo_intr(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
@@ -650,7 +665,7 @@ gk104_fifo_intr(struct nvkm_fifo *base)
 	}
 }
 
-void
+static void
 gk104_fifo_fini(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
@@ -660,7 +675,7 @@ gk104_fifo_fini(struct nvkm_fifo *base)
 	nvkm_mask(device, 0x002140, 0x10000000, 0x10000000);
 }
 
-int
+static int
 gk104_fifo_oneinit(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
@@ -739,7 +754,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	return 0;
 }
 
-void
+static void
 gk104_fifo_init(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
@@ -768,7 +783,7 @@ gk104_fifo_init(struct nvkm_fifo *base)
 	nvkm_wr32(device, 0x002140, 0x7fffffff);
 }
 
-void *
+static void *
 gk104_fifo_dtor(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
@@ -785,29 +800,35 @@ gk104_fifo_dtor(struct nvkm_fifo *base)
 	return fifo;
 }
 
+static const struct nvkm_fifo_func
+gk104_fifo_ = {
+	.dtor = gk104_fifo_dtor,
+	.oneinit = gk104_fifo_oneinit,
+	.init = gk104_fifo_init,
+	.fini = gk104_fifo_fini,
+	.intr = gk104_fifo_intr,
+	.uevent_init = gk104_fifo_uevent_init,
+	.uevent_fini = gk104_fifo_uevent_fini,
+	.class_get = gk104_fifo_class_get,
+};
+
 int
-gk104_fifo_new_(const struct nvkm_fifo_func *func, struct nvkm_device *device,
+gk104_fifo_new_(const struct gk104_fifo_func *func, struct nvkm_device *device,
 		int index, int nr, struct nvkm_fifo **pfifo)
 {
 	struct gk104_fifo *fifo;
 
 	if (!(fifo = kzalloc(sizeof(*fifo), GFP_KERNEL)))
 		return -ENOMEM;
+	fifo->func = func;
 	INIT_WORK(&fifo->recover.work, gk104_fifo_recover_work);
 	*pfifo = &fifo->base;
 
-	return nvkm_fifo_ctor(func, device, index, nr, &fifo->base);
+	return nvkm_fifo_ctor(&gk104_fifo_, device, index, nr, &fifo->base);
 }
 
-static const struct nvkm_fifo_func
+static const struct gk104_fifo_func
 gk104_fifo = {
-	.dtor = gk104_fifo_dtor,
-	.oneinit = gk104_fifo_oneinit,
-	.init = gk104_fifo_init,
-	.fini = gk104_fifo_fini,
-	.intr = gk104_fifo_intr,
-	.uevent_init = gk104_fifo_uevent_init,
-	.uevent_fini = gk104_fifo_uevent_fini,
 	.chan = {
 		&gk104_fifo_gpfifo_oclass,
 		NULL

commit e93e198d468f6ae41cf62265f389da2925fe16bb
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Apr 8 17:24:40 2016 +1000

    drm/nouveau/fifo/gk104-: use device info from top subdev
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 68acb36b3e6d..fcb9a7593dbf 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -28,6 +28,7 @@
 #include <core/enum.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
+#include <subdev/top.h>
 #include <engine/sw.h>
 
 #include <nvif/class.h>
@@ -665,7 +666,9 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	struct gk104_fifo *fifo = gk104_fifo(base);
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	int ret, i;
+	struct nvkm_top *top = device->top;
+	int engn, runl, pbid, ret, i, j;
+	enum nvkm_devidx engidx;
 	u32 *map;
 
 	/* Determine number of PBDMAs by checking valid enable bits. */
@@ -680,86 +683,26 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	for (i = 0; i < fifo->pbdma_nr; i++)
 		map[i] = nvkm_rd32(device, 0x002390 + (i * 0x04));
 
-	/* Read device topology from HW. */
-	for (i = 0; i < 64; i++) {
-		int type = -1, pbid = -1, engidx = -1;
-		int engn = -1, runl = -1, intr = -1, mcen = -1;
-		int fault = -1, j;
-		u32 data, addr = 0;
-
-		do {
-			data = nvkm_rd32(device, 0x022700 + (i * 0x04));
-			nvkm_trace(subdev, "%02x: %08x\n", i, data);
-			switch (data & 0x00000003) {
-			case 0x00000000: /* NOT_VALID */
-				continue;
-			case 0x00000001: /* DATA */
-				addr  = (data & 0x00fff000);
-				fault = (data & 0x000000f8) >> 3;
-				break;
-			case 0x00000002: /* ENUM */
-				if (data & 0x00000020)
-					engn = (data & 0x3c000000) >> 26;
-				if (data & 0x00000010)
-					runl = (data & 0x01e00000) >> 21;
-				if (data & 0x00000008)
-					intr = (data & 0x000f8000) >> 15;
-				if (data & 0x00000004)
-					mcen = (data & 0x00003e00) >> 9;
-				break;
-			case 0x00000003: /* ENGINE_TYPE */
-				type = (data & 0x7ffffffc) >> 2;
-				break;
-			}
-		} while ((data & 0x80000000) && ++i < 64);
-
-		if (!data)
-			continue;
-
+	/* Determine runlist configuration from topology device info. */
+	i = 0;
+	while ((int)(engidx = nvkm_top_engine(top, i++, &runl, &engn)) >= 0) {
 		/* Determine which PBDMA handles requests for this engine. */
-		for (j = 0; runl >= 0 && j < fifo->pbdma_nr; j++) {
+		for (j = 0, pbid = -1; j < fifo->pbdma_nr; j++) {
 			if (map[j] & (1 << runl)) {
 				pbid = j;
 				break;
 			}
 		}
 
-		/* Translate engine type to NVKM engine identifier. */
-		switch (type) {
-		case 0x00000000: engidx = NVKM_ENGINE_GR; break;
-		case 0x00000001: engidx = NVKM_ENGINE_CE0; break;
-		case 0x00000002: engidx = NVKM_ENGINE_CE1; break;
-		case 0x00000003: engidx = NVKM_ENGINE_CE2; break;
-		case 0x00000008: engidx = NVKM_ENGINE_MSPDEC; break;
-		case 0x00000009: engidx = NVKM_ENGINE_MSPPP; break;
-		case 0x0000000a: engidx = NVKM_ENGINE_MSVLD; break;
-		case 0x0000000b: engidx = NVKM_ENGINE_MSENC; break;
-		case 0x0000000c: engidx = NVKM_ENGINE_VIC; break;
-		case 0x0000000d: engidx = NVKM_ENGINE_SEC; break;
-		case 0x0000000e: engidx = NVKM_ENGINE_NVENC0; break;
-		case 0x0000000f: engidx = NVKM_ENGINE_NVENC1; break;
-		case 0x00000010: engidx = NVKM_ENGINE_NVDEC; break;
-			break;
-		default:
-			break;
-		}
+		nvkm_debug(subdev, "engine %2d: runlist %2d pbdma %2d\n",
+			   engn, runl, pbid);
 
-		nvkm_debug(subdev, "%02x (%8s): engine %2d runlist %2d "
-				   "pbdma %2d intr %2d reset %2d "
-				   "fault %2d addr %06x\n", type,
-			   engidx < 0 ? NULL : nvkm_subdev_name[engidx],
-			   engn, runl, pbid, intr, mcen, fault, addr);
-
-		/* Mark the engine as supported if everything checks out. */
-		if (engn >= 0 && runl >= 0) {
-			fifo->engine[engn].engine = engidx < 0 ? NULL :
-				nvkm_device_engine(device, engidx);
-			fifo->engine[engn].runl = runl;
-			fifo->engine[engn].pbid = pbid;
-			fifo->engine_nr = max(fifo->engine_nr, engn + 1);
-			fifo->runlist[runl].engm |= 1 << engn;
-			fifo->runlist_nr = max(fifo->runlist_nr, runl + 1);
-		}
+		fifo->engine[engn].engine = nvkm_device_engine(device, engidx);
+		fifo->engine[engn].runl = runl;
+		fifo->engine[engn].pbid = pbid;
+		fifo->engine_nr = max(fifo->engine_nr, engn + 1);
+		fifo->runlist[runl].engm |= 1 << engn;
+		fifo->runlist_nr = max(fifo->runlist_nr, runl + 1);
 	}
 
 	kfree(map);

commit b4c5fc4b853a1d508cbd3133f5d363037bfd5844
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: submit NOP after all PBDMA_INTR_0, not just DEVICE
    
    Prevents the same interrupt from re-triggering forever.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index a1b30133ae19..68acb36b3e6d 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -490,9 +490,10 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 			if (nvkm_sw_mthd(device->sw, chid, subc, mthd, data))
 				show &= ~0x00800000;
 		}
-		nvkm_wr32(device, 0x0400c0 + (unit * 0x2000), 0x80600008);
 	}
 
+	nvkm_wr32(device, 0x0400c0 + (unit * 0x2000), 0x80600008);
+
 	if (show) {
 		nvkm_snprintbf(msg, sizeof(msg), gk104_fifo_pbdma_intr_0, show);
 		chan = nvkm_fifo_chan_chid(&fifo->base, chid, &flags);

commit 608fd040b730a137ff771df43207aa702973d210
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: add nvdec plumbing
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index a8115b17e5b1..a1b30133ae19 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -737,6 +737,7 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 		case 0x0000000d: engidx = NVKM_ENGINE_SEC; break;
 		case 0x0000000e: engidx = NVKM_ENGINE_NVENC0; break;
 		case 0x0000000f: engidx = NVKM_ENGINE_NVENC1; break;
+		case 0x00000010: engidx = NVKM_ENGINE_NVDEC; break;
 			break;
 		default:
 			break;

commit 9e4fff320521be3dabc01fb09fdc4c04b5b94769
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: add nvenc plumbing
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index c7b5707488c5..a8115b17e5b1 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -735,6 +735,8 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 		case 0x0000000b: engidx = NVKM_ENGINE_MSENC; break;
 		case 0x0000000c: engidx = NVKM_ENGINE_VIC; break;
 		case 0x0000000d: engidx = NVKM_ENGINE_SEC; break;
+		case 0x0000000e: engidx = NVKM_ENGINE_NVENC0; break;
+		case 0x0000000f: engidx = NVKM_ENGINE_NVENC1; break;
 			break;
 		default:
 			break;

commit 19f89279faca691c7e5222015324b9bac60cd836
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: make use of topology info during fault recovery
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index cc9bb77e12fe..c7b5707488c5 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -108,37 +108,40 @@ gk104_fifo_recover_work(struct work_struct *w)
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_engine *engine;
 	unsigned long flags;
-	u32 engn, engm = 0;
-	u64 mask, todo;
+	u32 engm, runm, todo;
+	int engn, runl;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
-	mask = fifo->recover.mask;
-	fifo->recover.mask = 0ULL;
+	runm = fifo->recover.runm;
+	engm = fifo->recover.engm;
+	fifo->recover.engm = 0;
+	fifo->recover.runm = 0;
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
 
-	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
-		engm |= 1 << gk104_fifo_subdev_engine(engn);
-	nvkm_mask(device, 0x002630, engm, engm);
+	nvkm_mask(device, 0x002630, runm, runm);
 
-	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
-		if ((engine = nvkm_device_engine(device, engn))) {
+	for (todo = engm; engn = __ffs(todo), todo; todo &= ~BIT(engn)) {
+		if ((engine = fifo->engine[engn].engine)) {
 			nvkm_subdev_fini(&engine->subdev, false);
 			WARN_ON(nvkm_subdev_init(&engine->subdev));
 		}
-		gk104_fifo_runlist_commit(fifo, gk104_fifo_subdev_engine(engn));
 	}
 
-	nvkm_wr32(device, 0x00262c, engm);
-	nvkm_mask(device, 0x002630, engm, 0x00000000);
+	for (todo = runm; runl = __ffs(todo), todo; todo &= ~BIT(runl))
+		gk104_fifo_runlist_commit(fifo, runl);
+
+	nvkm_wr32(device, 0x00262c, runm);
+	nvkm_mask(device, 0x002630, runm, 0x00000000);
 }
 
 static void
 gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
-		  struct gk104_fifo_chan *chan)
+		   struct gk104_fifo_chan *chan)
 {
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	u32 chid = chan->base.chid;
+	int engn;
 
 	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
 		   nvkm_subdev_name[engine->subdev.index], chid);
@@ -148,7 +151,14 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 	list_del_init(&chan->head);
 	chan->killed = true;
 
-	fifo->recover.mask |= 1ULL << engine->subdev.index;
+	for (engn = 0; engn < fifo->engine_nr; engn++) {
+		if (fifo->engine[engn].engine == engine) {
+			fifo->recover.engm |= BIT(engn);
+			break;
+		}
+	}
+
+	fifo->recover.runm |= BIT(chan->runl);
 	schedule_work(&fifo->recover.work);
 }
 

commit af83a67779afce9bbf74d5b3903fc138a473ce18
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: make use of topology info when handling ctxsw timeout
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 26889fe65f73..cc9bb77e12fe 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -101,16 +101,6 @@ gk104_fifo_runlist_insert(struct gk104_fifo *fifo, struct gk104_fifo_chan *chan)
 	mutex_unlock(&fifo->base.engine.subdev.mutex);
 }
 
-static inline struct nvkm_engine *
-gk104_fifo_engine(struct gk104_fifo *fifo, u32 engn)
-{
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	u64 subdevs = gk104_fifo_engine_subdev(engn);
-	if (subdevs)
-		return nvkm_device_engine(device, __ffs(subdevs));
-	return NULL;
-}
-
 static void
 gk104_fifo_recover_work(struct work_struct *w)
 {
@@ -196,13 +186,14 @@ static void
 gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 {
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	struct nvkm_engine *engine;
 	struct gk104_fifo_chan *chan;
 	unsigned long flags;
 	u32 engn;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
 	for (engn = 0; engn < fifo->engine_nr; engn++) {
+		struct nvkm_engine *engine = fifo->engine[engn].engine;
+		int runl = fifo->engine[engn].runl;
 		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
 		u32 busy = (stat & 0x80000000);
 		u32 next = (stat & 0x0fff0000) >> 16;
@@ -213,15 +204,13 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 		u32 chid = load ? next : prev;
 		(void)save;
 
-		if (busy && chsw) {
-			list_for_each_entry(chan, &fifo->runlist[engn].chan, head) {
-				if (chan->base.chid == chid) {
-					engine = gk104_fifo_engine(fifo, engn);
-					if (!engine)
-						break;
-					gk104_fifo_recover(fifo, engine, chan);
-					break;
-				}
+		if (!busy || !chsw)
+			continue;
+
+		list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
+			if (chan->base.chid == chid && engine) {
+				gk104_fifo_recover(fifo, engine, chan);
+				break;
 			}
 		}
 	}

commit 41e5171ba84f4aa6d37825218d299dca5d10e9a8
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: read device topology information from hw
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 47bf23e9a8cc..26889fe65f73 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -202,7 +202,7 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 	u32 engn;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
-	for (engn = 0; engn < ARRAY_SIZE(fifo->runlist); engn++) {
+	for (engn = 0; engn < fifo->engine_nr; engn++) {
 		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
 		u32 busy = (stat & 0x80000000);
 		u32 next = (stat & 0x0fff0000) >> 16;
@@ -666,13 +666,102 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	int ret, i;
+	u32 *map;
 
 	/* Determine number of PBDMAs by checking valid enable bits. */
 	nvkm_wr32(device, 0x000204, 0xffffffff);
 	fifo->pbdma_nr = hweight32(nvkm_rd32(device, 0x000204));
 	nvkm_debug(subdev, "%d PBDMA(s)\n", fifo->pbdma_nr);
 
-	for (i = 0; i < ARRAY_SIZE(fifo->runlist); i++) {
+	/* Read PBDMA->runlist(s) mapping from HW. */
+	if (!(map = kzalloc(sizeof(*map) * fifo->pbdma_nr, GFP_KERNEL)))
+		return -ENOMEM;
+
+	for (i = 0; i < fifo->pbdma_nr; i++)
+		map[i] = nvkm_rd32(device, 0x002390 + (i * 0x04));
+
+	/* Read device topology from HW. */
+	for (i = 0; i < 64; i++) {
+		int type = -1, pbid = -1, engidx = -1;
+		int engn = -1, runl = -1, intr = -1, mcen = -1;
+		int fault = -1, j;
+		u32 data, addr = 0;
+
+		do {
+			data = nvkm_rd32(device, 0x022700 + (i * 0x04));
+			nvkm_trace(subdev, "%02x: %08x\n", i, data);
+			switch (data & 0x00000003) {
+			case 0x00000000: /* NOT_VALID */
+				continue;
+			case 0x00000001: /* DATA */
+				addr  = (data & 0x00fff000);
+				fault = (data & 0x000000f8) >> 3;
+				break;
+			case 0x00000002: /* ENUM */
+				if (data & 0x00000020)
+					engn = (data & 0x3c000000) >> 26;
+				if (data & 0x00000010)
+					runl = (data & 0x01e00000) >> 21;
+				if (data & 0x00000008)
+					intr = (data & 0x000f8000) >> 15;
+				if (data & 0x00000004)
+					mcen = (data & 0x00003e00) >> 9;
+				break;
+			case 0x00000003: /* ENGINE_TYPE */
+				type = (data & 0x7ffffffc) >> 2;
+				break;
+			}
+		} while ((data & 0x80000000) && ++i < 64);
+
+		if (!data)
+			continue;
+
+		/* Determine which PBDMA handles requests for this engine. */
+		for (j = 0; runl >= 0 && j < fifo->pbdma_nr; j++) {
+			if (map[j] & (1 << runl)) {
+				pbid = j;
+				break;
+			}
+		}
+
+		/* Translate engine type to NVKM engine identifier. */
+		switch (type) {
+		case 0x00000000: engidx = NVKM_ENGINE_GR; break;
+		case 0x00000001: engidx = NVKM_ENGINE_CE0; break;
+		case 0x00000002: engidx = NVKM_ENGINE_CE1; break;
+		case 0x00000003: engidx = NVKM_ENGINE_CE2; break;
+		case 0x00000008: engidx = NVKM_ENGINE_MSPDEC; break;
+		case 0x00000009: engidx = NVKM_ENGINE_MSPPP; break;
+		case 0x0000000a: engidx = NVKM_ENGINE_MSVLD; break;
+		case 0x0000000b: engidx = NVKM_ENGINE_MSENC; break;
+		case 0x0000000c: engidx = NVKM_ENGINE_VIC; break;
+		case 0x0000000d: engidx = NVKM_ENGINE_SEC; break;
+			break;
+		default:
+			break;
+		}
+
+		nvkm_debug(subdev, "%02x (%8s): engine %2d runlist %2d "
+				   "pbdma %2d intr %2d reset %2d "
+				   "fault %2d addr %06x\n", type,
+			   engidx < 0 ? NULL : nvkm_subdev_name[engidx],
+			   engn, runl, pbid, intr, mcen, fault, addr);
+
+		/* Mark the engine as supported if everything checks out. */
+		if (engn >= 0 && runl >= 0) {
+			fifo->engine[engn].engine = engidx < 0 ? NULL :
+				nvkm_device_engine(device, engidx);
+			fifo->engine[engn].runl = runl;
+			fifo->engine[engn].pbid = pbid;
+			fifo->engine_nr = max(fifo->engine_nr, engn + 1);
+			fifo->runlist[runl].engm |= 1 << engn;
+			fifo->runlist_nr = max(fifo->runlist_nr, runl + 1);
+		}
+	}
+
+	kfree(map);
+
+	for (i = 0; i < fifo->runlist_nr; i++) {
 		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 				      0x8000, 0x1000, false,
 				      &fifo->runlist[i].mem[0]);
@@ -742,7 +831,7 @@ gk104_fifo_dtor(struct nvkm_fifo *base)
 	nvkm_vm_put(&fifo->user.bar);
 	nvkm_memory_del(&fifo->user.mem);
 
-	for (i = 0; i < ARRAY_SIZE(fifo->runlist); i++) {
+	for (i = 0; i < fifo->runlist_nr; i++) {
 		nvkm_memory_del(&fifo->runlist[i].mem[1]);
 		nvkm_memory_del(&fifo->runlist[i].mem[0]);
 	}

commit 69aa40e276c79fc4d6b47b3126ce475aa3d09de1
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: cosmetic engine->runlist changes
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 4529adc7835b..47bf23e9a8cc 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -47,38 +47,41 @@ gk104_fifo_uevent_init(struct nvkm_fifo *fifo)
 }
 
 void
-gk104_fifo_runlist_commit(struct gk104_fifo *fifo, u32 engine)
+gk104_fifo_runlist_commit(struct gk104_fifo *fifo, int runl)
 {
-	struct gk104_fifo_engn *engn = &fifo->engine[engine];
 	struct gk104_fifo_chan *chan;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	struct nvkm_memory *cur;
+	struct nvkm_memory *mem;
 	int nr = 0;
 	int target;
 
 	mutex_lock(&subdev->mutex);
-	cur = engn->runlist[engn->cur_runlist];
-	engn->cur_runlist = !engn->cur_runlist;
+	mem = fifo->runlist[runl].mem[fifo->runlist[runl].next];
+	fifo->runlist[runl].next = !fifo->runlist[runl].next;
 
-	nvkm_kmap(cur);
-	list_for_each_entry(chan, &engn->chan, head) {
-		nvkm_wo32(cur, (nr * 8) + 0, chan->base.chid);
-		nvkm_wo32(cur, (nr * 8) + 4, 0x00000000);
+	nvkm_kmap(mem);
+	list_for_each_entry(chan, &fifo->runlist[runl].chan, head) {
+		nvkm_wo32(mem, (nr * 8) + 0, chan->base.chid);
+		nvkm_wo32(mem, (nr * 8) + 4, 0x00000000);
 		nr++;
 	}
-	nvkm_done(cur);
+	nvkm_done(mem);
 
-	target = (nvkm_memory_target(cur) == NVKM_MEM_TARGET_HOST) ? 0x3 : 0x0;
+	if (nvkm_memory_target(mem) == NVKM_MEM_TARGET_VRAM)
+		target = 0;
+	else
+		target = 3;
 
-	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(cur) >> 12) |
+	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(mem) >> 12) |
 				    (target << 28));
-	nvkm_wr32(device, 0x002274, (engine << 20) | nr);
+	nvkm_wr32(device, 0x002274, (runl << 20) | nr);
 
-	if (wait_event_timeout(engn->wait, !(nvkm_rd32(device, 0x002284 +
-			       (engine * 0x08)) & 0x00100000),
-				msecs_to_jiffies(2000)) == 0)
-		nvkm_error(subdev, "runlist %d update timeout\n", engine);
+	if (wait_event_timeout(fifo->runlist[runl].wait,
+			       !(nvkm_rd32(device, 0x002284 + (runl * 0x08))
+				       & 0x00100000),
+			       msecs_to_jiffies(2000)) == 0)
+		nvkm_error(subdev, "runlist %d update timeout\n", runl);
 	mutex_unlock(&subdev->mutex);
 }
 
@@ -94,7 +97,7 @@ void
 gk104_fifo_runlist_insert(struct gk104_fifo *fifo, struct gk104_fifo_chan *chan)
 {
 	mutex_lock(&fifo->base.engine.subdev.mutex);
-	list_add_tail(&chan->head, &fifo->engine[chan->engine].chan);
+	list_add_tail(&chan->head, &fifo->runlist[chan->runl].chan);
 	mutex_unlock(&fifo->base.engine.subdev.mutex);
 }
 
@@ -199,7 +202,7 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 	u32 engn;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
-	for (engn = 0; engn < ARRAY_SIZE(fifo->engine); engn++) {
+	for (engn = 0; engn < ARRAY_SIZE(fifo->runlist); engn++) {
 		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
 		u32 busy = (stat & 0x80000000);
 		u32 next = (stat & 0x0fff0000) >> 16;
@@ -211,7 +214,7 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 		(void)save;
 
 		if (busy && chsw) {
-			list_for_each_entry(chan, &fifo->engine[engn].chan, head) {
+			list_for_each_entry(chan, &fifo->runlist[engn].chan, head) {
 				if (chan->base.chid == chid) {
 					engine = gk104_fifo_engine(fifo, engn);
 					if (!engine)
@@ -541,10 +544,10 @@ gk104_fifo_intr_runlist(struct gk104_fifo *fifo)
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u32 mask = nvkm_rd32(device, 0x002a00);
 	while (mask) {
-		u32 engn = __ffs(mask);
-		wake_up(&fifo->engine[engn].wait);
-		nvkm_wr32(device, 0x002a00, 1 << engn);
-		mask &= ~(1 << engn);
+		int runl = __ffs(mask);
+		wake_up(&fifo->runlist[runl].wait);
+		nvkm_wr32(device, 0x002a00, 1 << runl);
+		mask &= ~(1 << runl);
 	}
 }
 
@@ -669,21 +672,21 @@ gk104_fifo_oneinit(struct nvkm_fifo *base)
 	fifo->pbdma_nr = hweight32(nvkm_rd32(device, 0x000204));
 	nvkm_debug(subdev, "%d PBDMA(s)\n", fifo->pbdma_nr);
 
-	for (i = 0; i < ARRAY_SIZE(fifo->engine); i++) {
+	for (i = 0; i < ARRAY_SIZE(fifo->runlist); i++) {
 		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 				      0x8000, 0x1000, false,
-				      &fifo->engine[i].runlist[0]);
+				      &fifo->runlist[i].mem[0]);
 		if (ret)
 			return ret;
 
 		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 				      0x8000, 0x1000, false,
-				      &fifo->engine[i].runlist[1]);
+				      &fifo->runlist[i].mem[1]);
 		if (ret)
 			return ret;
 
-		init_waitqueue_head(&fifo->engine[i].wait);
-		INIT_LIST_HEAD(&fifo->engine[i].chan);
+		init_waitqueue_head(&fifo->runlist[i].wait);
+		INIT_LIST_HEAD(&fifo->runlist[i].chan);
 	}
 
 	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
@@ -739,9 +742,9 @@ gk104_fifo_dtor(struct nvkm_fifo *base)
 	nvkm_vm_put(&fifo->user.bar);
 	nvkm_memory_del(&fifo->user.mem);
 
-	for (i = 0; i < ARRAY_SIZE(fifo->engine); i++) {
-		nvkm_memory_del(&fifo->engine[i].runlist[1]);
-		nvkm_memory_del(&fifo->engine[i].runlist[0]);
+	for (i = 0; i < ARRAY_SIZE(fifo->runlist); i++) {
+		nvkm_memory_del(&fifo->runlist[i].mem[1]);
+		nvkm_memory_del(&fifo->runlist[i].mem[0]);
 	}
 
 	return fifo;

commit acdf7d4f7ea95211fe0e6739e4dc36fcf73b7a46
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: don't attempt recovery of unknown mmu engines
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index a46971a54169..4529adc7835b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -399,7 +399,7 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 		snprintf(gpcid, sizeof(gpcid), "GPC%d/", gpc);
 	}
 
-	if (eu) {
+	if (eu && eu->data2) {
 		switch (eu->data2) {
 		case NVKM_SUBDEV_BAR:
 			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);

commit 55252da1612d95b7c19fab66dd0540171ef80c77
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: identify fault-recovery members more clearly
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 03defc92f5bb..a46971a54169 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -109,9 +109,9 @@ gk104_fifo_engine(struct gk104_fifo *fifo, u32 engn)
 }
 
 static void
-gk104_fifo_recover_work(struct work_struct *work)
+gk104_fifo_recover_work(struct work_struct *w)
 {
-	struct gk104_fifo *fifo = container_of(work, typeof(*fifo), fault);
+	struct gk104_fifo *fifo = container_of(w, typeof(*fifo), recover.work);
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_engine *engine;
 	unsigned long flags;
@@ -119,8 +119,8 @@ gk104_fifo_recover_work(struct work_struct *work)
 	u64 mask, todo;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
-	mask = fifo->mask;
-	fifo->mask = 0ULL;
+	mask = fifo->recover.mask;
+	fifo->recover.mask = 0ULL;
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
@@ -155,8 +155,8 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 	list_del_init(&chan->head);
 	chan->killed = true;
 
-	fifo->mask |= 1ULL << engine->subdev.index;
-	schedule_work(&fifo->fault);
+	fifo->recover.mask |= 1ULL << engine->subdev.index;
+	schedule_work(&fifo->recover.work);
 }
 
 static const struct nvkm_enum
@@ -651,7 +651,7 @@ gk104_fifo_fini(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	flush_work(&fifo->fault);
+	flush_work(&fifo->recover.work);
 	/* allow mmu fault interrupts, even when we're not using fifo */
 	nvkm_mask(device, 0x002140, 0x10000000, 0x10000000);
 }
@@ -755,7 +755,7 @@ gk104_fifo_new_(const struct nvkm_fifo_func *func, struct nvkm_device *device,
 
 	if (!(fifo = kzalloc(sizeof(*fifo), GFP_KERNEL)))
 		return -ENOMEM;
-	INIT_WORK(&fifo->fault, gk104_fifo_recover_work);
+	INIT_WORK(&fifo->recover.work, gk104_fifo_recover_work);
 	*pfifo = &fifo->base;
 
 	return nvkm_fifo_ctor(func, device, index, nr, &fifo->base);

commit 6d39b83f13d9e0b24edc9a25022d260a8eb6bfa3
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gk104: rename spoon to pbdma, and move detection to oneinit
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index cd0f08a2f811..03defc92f5bb 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -660,9 +660,15 @@ int
 gk104_fifo_oneinit(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	int ret, i;
 
+	/* Determine number of PBDMAs by checking valid enable bits. */
+	nvkm_wr32(device, 0x000204, 0xffffffff);
+	fifo->pbdma_nr = hweight32(nvkm_rd32(device, 0x000204));
+	nvkm_debug(subdev, "%d PBDMA(s)\n", fifo->pbdma_nr);
+
 	for (i = 0; i < ARRAY_SIZE(fifo->engine); i++) {
 		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 				      0x8000, 0x1000, false,
@@ -699,24 +705,21 @@ void
 gk104_fifo_init(struct nvkm_fifo *base)
 {
 	struct gk104_fifo *fifo = gk104_fifo(base);
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	int i;
 
-	/* enable all available PBDMA units */
-	nvkm_wr32(device, 0x000204, 0xffffffff);
-	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x000204));
-	nvkm_debug(subdev, "%d PBDMA unit(s)\n", fifo->spoon_nr);
+	/* Enable PBDMAs. */
+	nvkm_wr32(device, 0x000204, (1 << fifo->pbdma_nr) - 1);
 
 	/* PBDMA[n] */
-	for (i = 0; i < fifo->spoon_nr; i++) {
+	for (i = 0; i < fifo->pbdma_nr; i++) {
 		nvkm_mask(device, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
 		nvkm_wr32(device, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
 		nvkm_wr32(device, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
 	}
 
 	/* PBDMA[n].HCE */
-	for (i = 0; i < fifo->spoon_nr; i++) {
+	for (i = 0; i < fifo->pbdma_nr; i++) {
 		nvkm_wr32(device, 0x040148 + (i * 0x2000), 0xffffffff); /* INTR */
 		nvkm_wr32(device, 0x04014c + (i * 0x2000), 0xffffffff); /* INTREN */
 	}

commit a2e435a1b0a3c2bc766d40356151610cc54b8772
Author: Alexandre Courbot <acourbot@nvidia.com>
Date:   Tue Mar 1 16:51:58 2016 +0900

    drm/nouveau/fifo/gk104: take runlist target into account
    
    Bits 28:29 of RUNLIST_BASE specify the memory target of the runlist. Set
    it to 0x3 (SYS_MEM_NONCOHERENT) if the runlist object resides in system
    memory.
    
    Signed-off-by: Alexandre Courbot <acourbot@nvidia.com>
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index d6a88cf67416..cd0f08a2f811 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -55,6 +55,7 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, u32 engine)
 	struct nvkm_device *device = subdev->device;
 	struct nvkm_memory *cur;
 	int nr = 0;
+	int target;
 
 	mutex_lock(&subdev->mutex);
 	cur = engn->runlist[engn->cur_runlist];
@@ -68,7 +69,10 @@ gk104_fifo_runlist_commit(struct gk104_fifo *fifo, u32 engine)
 	}
 	nvkm_done(cur);
 
-	nvkm_wr32(device, 0x002270, nvkm_memory_addr(cur) >> 12);
+	target = (nvkm_memory_target(cur) == NVKM_MEM_TARGET_HOST) ? 0x3 : 0x0;
+
+	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(cur) >> 12) |
+				    (target << 28));
 	nvkm_wr32(device, 0x002274, (engine << 20) | nr);
 
 	if (wait_event_timeout(engn->wait, !(nvkm_rd32(device, 0x002284 +

commit 0689aad70d719842c3a07f5782b7d35bb12efe9d
Author: Xia Yang <xiay@nvidia.com>
Date:   Thu Feb 25 17:59:08 2016 +0900

    drm/nouveau/fifo/gk104: fix chid bit mask
    
    Fix the channel id bit mask in FIFO schedule timeout error handling.
    
    FIFO_ENGINE_STATUS_NEXT_ID is bit 27:16 thus 0x0fff0000.
    FIFO_ENGINE_STATUS_ID      is bit 11:0  thus 0x00000fff.
    
    Signed-off-by: Xia Yang <xiay@nvidia.com>
    Reviewed-by: Alexandre Courbot <acourbot@nvidia.com>
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 4fcd147d43c8..d6a88cf67416 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -198,11 +198,11 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 	for (engn = 0; engn < ARRAY_SIZE(fifo->engine); engn++) {
 		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
 		u32 busy = (stat & 0x80000000);
-		u32 next = (stat & 0x07ff0000) >> 16;
+		u32 next = (stat & 0x0fff0000) >> 16;
 		u32 chsw = (stat & 0x00008000);
 		u32 save = (stat & 0x00004000);
 		u32 load = (stat & 0x00002000);
-		u32 prev = (stat & 0x000007ff);
+		u32 prev = (stat & 0x00000fff);
 		u32 chid = load ? next : prev;
 		(void)save;
 

commit da4ee13cd5755a347f16e80e0a8583478c3fef5b
Author: Vince Hsu <vinceh@nvidia.com>
Date:   Mon Nov 16 15:38:30 2015 +0800

    drm/nouveau/fifo/gk104: fix engine status register offset
    
    The offset should be 8 on Kepler and later.
    
    Signed-off-by: Vince Hsu <vinceh@nvidia.com>
    Reviewed-by: Alexandre Courbot <acourbot@nvidia.com>
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 8d5db6d5a558..4fcd147d43c8 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -196,7 +196,7 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
 	for (engn = 0; engn < ARRAY_SIZE(fifo->engine); engn++) {
-		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
+		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x08));
 		u32 busy = (stat & 0x80000000);
 		u32 next = (stat & 0x07ff0000) >> 16;
 		u32 chsw = (stat & 0x00008000);

commit 386ffd5e80d54fd6ecca0a81fc50abc97aeee73f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 11 09:37:05 2015 +1000

    drm/nouveau/fifo/gk104: fix race condition when updating engine runlists
    
    The CPU-side tracking of engine runlists was not protected by a lock,
    leading to list corruption, eventually causing runlist_update() to
    overrun the GPU-side runlist, triggering an OOPS.
    
    Fixes some of the issues noticed during parallel piglit runs.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 98970a0b7a66..8d5db6d5a558 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -47,7 +47,7 @@ gk104_fifo_uevent_init(struct nvkm_fifo *fifo)
 }
 
 void
-gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
+gk104_fifo_runlist_commit(struct gk104_fifo *fifo, u32 engine)
 {
 	struct gk104_fifo_engn *engn = &fifo->engine[engine];
 	struct gk104_fifo_chan *chan;
@@ -78,6 +78,22 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	mutex_unlock(&subdev->mutex);
 }
 
+void
+gk104_fifo_runlist_remove(struct gk104_fifo *fifo, struct gk104_fifo_chan *chan)
+{
+	mutex_lock(&fifo->base.engine.subdev.mutex);
+	list_del_init(&chan->head);
+	mutex_unlock(&fifo->base.engine.subdev.mutex);
+}
+
+void
+gk104_fifo_runlist_insert(struct gk104_fifo *fifo, struct gk104_fifo_chan *chan)
+{
+	mutex_lock(&fifo->base.engine.subdev.mutex);
+	list_add_tail(&chan->head, &fifo->engine[chan->engine].chan);
+	mutex_unlock(&fifo->base.engine.subdev.mutex);
+}
+
 static inline struct nvkm_engine *
 gk104_fifo_engine(struct gk104_fifo *fifo, u32 engn)
 {
@@ -112,7 +128,7 @@ gk104_fifo_recover_work(struct work_struct *work)
 			nvkm_subdev_fini(&engine->subdev, false);
 			WARN_ON(nvkm_subdev_init(&engine->subdev));
 		}
-		gk104_fifo_runlist_update(fifo, gk104_fifo_subdev_engine(engn));
+		gk104_fifo_runlist_commit(fifo, gk104_fifo_subdev_engine(engn));
 	}
 
 	nvkm_wr32(device, 0x00262c, engm);

commit fbd58ebda9c8572ca6285b88e3348c7712f125ec
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/object: merge with handle
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index fc0ff2d37d06..98970a0b7a66 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -27,7 +27,6 @@
 #include <core/client.h>
 #include <core/enum.h>
 #include <core/gpuobj.h>
-#include <core/handle.h>
 #include <subdev/bar.h>
 #include <engine/sw.h>
 

commit 68f3f702b6a430a8d1e909455a60d26c0f2da530
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/core: remove the remainder of the previous style
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 465b52dee277..fc0ff2d37d06 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -248,22 +248,22 @@ gk104_fifo_intr_dropped_fault(struct gk104_fifo *fifo)
 
 static const struct nvkm_enum
 gk104_fifo_fault_engine[] = {
-	{ 0x00, "GR", NULL, NVDEV_ENGINE_GR },
-	{ 0x03, "IFB", NULL, NVDEV_ENGINE_IFB },
-	{ 0x04, "BAR1", NULL, NVDEV_SUBDEV_BAR },
-	{ 0x05, "BAR3", NULL, NVDEV_SUBDEV_INSTMEM },
-	{ 0x07, "PBDMA0", NULL, NVDEV_ENGINE_FIFO },
-	{ 0x08, "PBDMA1", NULL, NVDEV_ENGINE_FIFO },
-	{ 0x09, "PBDMA2", NULL, NVDEV_ENGINE_FIFO },
-	{ 0x10, "MSVLD", NULL, NVDEV_ENGINE_MSVLD },
-	{ 0x11, "MSPPP", NULL, NVDEV_ENGINE_MSPPP },
+	{ 0x00, "GR", NULL, NVKM_ENGINE_GR },
+	{ 0x03, "IFB", NULL, NVKM_ENGINE_IFB },
+	{ 0x04, "BAR1", NULL, NVKM_SUBDEV_BAR },
+	{ 0x05, "BAR3", NULL, NVKM_SUBDEV_INSTMEM },
+	{ 0x07, "PBDMA0", NULL, NVKM_ENGINE_FIFO },
+	{ 0x08, "PBDMA1", NULL, NVKM_ENGINE_FIFO },
+	{ 0x09, "PBDMA2", NULL, NVKM_ENGINE_FIFO },
+	{ 0x10, "MSVLD", NULL, NVKM_ENGINE_MSVLD },
+	{ 0x11, "MSPPP", NULL, NVKM_ENGINE_MSPPP },
 	{ 0x13, "PERF" },
-	{ 0x14, "MSPDEC", NULL, NVDEV_ENGINE_MSPDEC },
-	{ 0x15, "CE0", NULL, NVDEV_ENGINE_CE0 },
-	{ 0x16, "CE1", NULL, NVDEV_ENGINE_CE1 },
+	{ 0x14, "MSPDEC", NULL, NVKM_ENGINE_MSPDEC },
+	{ 0x15, "CE0", NULL, NVKM_ENGINE_CE0 },
+	{ 0x16, "CE1", NULL, NVKM_ENGINE_CE1 },
 	{ 0x17, "PMU" },
-	{ 0x19, "MSENC", NULL, NVDEV_ENGINE_MSENC },
-	{ 0x1b, "CE2", NULL, NVDEV_ENGINE_CE2 },
+	{ 0x19, "MSENC", NULL, NVKM_ENGINE_MSENC },
+	{ 0x1b, "CE2", NULL, NVKM_ENGINE_CE2 },
 	{}
 };
 
@@ -382,13 +382,13 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 
 	if (eu) {
 		switch (eu->data2) {
-		case NVDEV_SUBDEV_BAR:
+		case NVKM_SUBDEV_BAR:
 			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
 			break;
-		case NVDEV_SUBDEV_INSTMEM:
+		case NVKM_SUBDEV_INSTMEM:
 			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
 			break;
-		case NVDEV_ENGINE_IFB:
+		case NVKM_ENGINE_IFB:
 			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:

commit 13de7f462902d1a452d501cdb2d06ef02cabbfff
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/fifo: convert to new-style nvkm_engine
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index a69f61f3ecac..465b52dee277 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -26,35 +26,27 @@
 
 #include <core/client.h>
 #include <core/enum.h>
+#include <core/gpuobj.h>
 #include <core/handle.h>
 #include <subdev/bar.h>
 #include <engine/sw.h>
 
 #include <nvif/class.h>
 
-static void
-gk104_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
+void
+gk104_fifo_uevent_fini(struct nvkm_fifo *fifo)
 {
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
 	struct nvkm_device *device = fifo->engine.subdev.device;
 	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
 }
 
-static void
-gk104_fifo_uevent_init(struct nvkm_event *event, int type, int index)
+void
+gk104_fifo_uevent_init(struct nvkm_fifo *fifo)
 {
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
 	struct nvkm_device *device = fifo->engine.subdev.device;
 	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
 }
 
-static const struct nvkm_event_func
-gk104_fifo_uevent_func = {
-	.ctor = nvkm_fifo_uevent_ctor,
-	.init = gk104_fifo_uevent_init,
-	.fini = gk104_fifo_uevent_fini,
-};
-
 void
 gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 {
@@ -65,7 +57,7 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	struct nvkm_memory *cur;
 	int nr = 0;
 
-	mutex_lock(&nv_subdev(fifo)->mutex);
+	mutex_lock(&subdev->mutex);
 	cur = engn->runlist[engn->cur_runlist];
 	engn->cur_runlist = !engn->cur_runlist;
 
@@ -84,15 +76,16 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 			       (engine * 0x08)) & 0x00100000),
 				msecs_to_jiffies(2000)) == 0)
 		nvkm_error(subdev, "runlist %d update timeout\n", engine);
-	mutex_unlock(&nv_subdev(fifo)->mutex);
+	mutex_unlock(&subdev->mutex);
 }
 
 static inline struct nvkm_engine *
 gk104_fifo_engine(struct gk104_fifo *fifo, u32 engn)
 {
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u64 subdevs = gk104_fifo_engine_subdev(engn);
 	if (subdevs)
-		return nvkm_engine(fifo, __ffs(subdevs));
+		return nvkm_device_engine(device, __ffs(subdevs));
 	return NULL;
 }
 
@@ -136,14 +129,14 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 	u32 chid = chan->base.chid;
 
 	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
-		   nvkm_subdev_name[nv_subdev(engine)->index], chid);
+		   nvkm_subdev_name[engine->subdev.index], chid);
 	assert_spin_locked(&fifo->base.lock);
 
 	nvkm_mask(device, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
 	list_del_init(&chan->head);
 	chan->killed = true;
 
-	fifo->mask |= 1ULL << nv_engidx(engine);
+	fifo->mask |= 1ULL << engine->subdev.index;
 	schedule_work(&fifo->fault);
 }
 
@@ -399,7 +392,7 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:
-			engine = nvkm_engine(fifo, eu->data2);
+			engine = nvkm_device_engine(device, eu->data2);
 			break;
 		}
 	}
@@ -542,11 +535,12 @@ gk104_fifo_intr_engine(struct gk104_fifo *fifo)
 	nvkm_fifo_uevent(&fifo->base);
 }
 
-static void
-gk104_fifo_intr(struct nvkm_subdev *subdev)
+void
+gk104_fifo_intr(struct nvkm_fifo *base)
 {
-	struct gk104_fifo *fifo = (void *)subdev;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct gk104_fifo *fifo = gk104_fifo(base);
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 mask = nvkm_rd32(device, 0x002140);
 	u32 stat = nvkm_rd32(device, 0x002100) & mask;
 
@@ -633,33 +627,62 @@ gk104_fifo_intr(struct nvkm_subdev *subdev)
 	}
 }
 
+void
+gk104_fifo_fini(struct nvkm_fifo *base)
+{
+	struct gk104_fifo *fifo = gk104_fifo(base);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	flush_work(&fifo->fault);
+	/* allow mmu fault interrupts, even when we're not using fifo */
+	nvkm_mask(device, 0x002140, 0x10000000, 0x10000000);
+}
+
 int
-gk104_fifo_fini(struct nvkm_object *object, bool suspend)
+gk104_fifo_oneinit(struct nvkm_fifo *base)
 {
-	struct gk104_fifo *fifo = (void *)object;
+	struct gk104_fifo *fifo = gk104_fifo(base);
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	int ret;
+	int ret, i;
 
-	ret = nvkm_fifo_fini(&fifo->base, suspend);
+	for (i = 0; i < ARRAY_SIZE(fifo->engine); i++) {
+		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+				      0x8000, 0x1000, false,
+				      &fifo->engine[i].runlist[0]);
+		if (ret)
+			return ret;
+
+		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+				      0x8000, 0x1000, false,
+				      &fifo->engine[i].runlist[1]);
+		if (ret)
+			return ret;
+
+		init_waitqueue_head(&fifo->engine[i].wait);
+		INIT_LIST_HEAD(&fifo->engine[i].chan);
+	}
+
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+			      fifo->base.nr * 0x200, 0x1000, true,
+			      &fifo->user.mem);
 	if (ret)
 		return ret;
 
-	/* allow mmu fault interrupts, even when we're not using fifo */
-	nvkm_mask(device, 0x002140, 0x10000000, 0x10000000);
+	ret = nvkm_bar_umap(device->bar, fifo->base.nr * 0x200, 12,
+			    &fifo->user.bar);
+	if (ret)
+		return ret;
+
+	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
 	return 0;
 }
 
-int
-gk104_fifo_init(struct nvkm_object *object)
+void
+gk104_fifo_init(struct nvkm_fifo *base)
 {
-	struct gk104_fifo *fifo = (void *)object;
+	struct gk104_fifo *fifo = gk104_fifo(base);
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	int ret, i;
-
-	ret = nvkm_fifo_init(&fifo->base);
-	if (ret)
-		return ret;
+	int i;
 
 	/* enable all available PBDMA units */
 	nvkm_wr32(device, 0x000204, 0xffffffff);
@@ -683,13 +706,12 @@ gk104_fifo_init(struct nvkm_object *object)
 
 	nvkm_wr32(device, 0x002100, 0xffffffff);
 	nvkm_wr32(device, 0x002140, 0x7fffffff);
-	return 0;
 }
 
-void
-gk104_fifo_dtor(struct nvkm_object *object)
+void *
+gk104_fifo_dtor(struct nvkm_fifo *base)
 {
-	struct gk104_fifo *fifo = (void *)object;
+	struct gk104_fifo *fifo = gk104_fifo(base);
 	int i;
 
 	nvkm_vm_put(&fifo->user.bar);
@@ -700,11 +722,32 @@ gk104_fifo_dtor(struct nvkm_object *object)
 		nvkm_memory_del(&fifo->engine[i].runlist[0]);
 	}
 
-	nvkm_fifo_destroy(&fifo->base);
+	return fifo;
+}
+
+int
+gk104_fifo_new_(const struct nvkm_fifo_func *func, struct nvkm_device *device,
+		int index, int nr, struct nvkm_fifo **pfifo)
+{
+	struct gk104_fifo *fifo;
+
+	if (!(fifo = kzalloc(sizeof(*fifo), GFP_KERNEL)))
+		return -ENOMEM;
+	INIT_WORK(&fifo->fault, gk104_fifo_recover_work);
+	*pfifo = &fifo->base;
+
+	return nvkm_fifo_ctor(func, device, index, nr, &fifo->base);
 }
 
 static const struct nvkm_fifo_func
-gk104_fifo_func = {
+gk104_fifo = {
+	.dtor = gk104_fifo_dtor,
+	.oneinit = gk104_fifo_oneinit,
+	.init = gk104_fifo_init,
+	.fini = gk104_fifo_fini,
+	.intr = gk104_fifo_intr,
+	.uevent_init = gk104_fifo_uevent_init,
+	.uevent_fini = gk104_fifo_uevent_fini,
 	.chan = {
 		&gk104_fifo_gpfifo_oclass,
 		NULL
@@ -712,72 +755,7 @@ gk104_fifo_func = {
 };
 
 int
-gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-		struct nvkm_oclass *oclass, void *data, u32 size,
-		struct nvkm_object **pobject)
+gk104_fifo_new(struct nvkm_device *device, int index, struct nvkm_fifo **pfifo)
 {
-	struct nvkm_device *device = (void *)parent;
-	struct nvkm_bar *bar = device->bar;
-	struct gk104_fifo_impl *impl = (void *)oclass;
-	struct gk104_fifo *fifo;
-	int ret, i;
-
-	ret = nvkm_fifo_create(parent, engine, oclass, 0,
-			       impl->channels - 1, &fifo);
-	*pobject = nv_object(fifo);
-	if (ret)
-		return ret;
-
-	fifo->base.func = &gk104_fifo_func;
-
-	INIT_WORK(&fifo->fault, gk104_fifo_recover_work);
-
-	for (i = 0; i < ARRAY_SIZE(fifo->engine); i++) {
-		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-				      0x8000, 0x1000, false,
-				      &fifo->engine[i].runlist[0]);
-		if (ret)
-			return ret;
-
-		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-				      0x8000, 0x1000, false,
-				      &fifo->engine[i].runlist[1]);
-		if (ret)
-			return ret;
-
-		init_waitqueue_head(&fifo->engine[i].wait);
-		INIT_LIST_HEAD(&fifo->engine[i].chan);
-	}
-
-	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-			      impl->channels * 0x200, 0x1000,
-			      true, &fifo->user.mem);
-	if (ret)
-		return ret;
-
-	ret = nvkm_bar_umap(bar, impl->channels * 0x200, 12, &fifo->user.bar);
-	if (ret)
-		return ret;
-
-	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
-
-	ret = nvkm_event_init(&gk104_fifo_uevent_func, 1, 1, &fifo->base.uevent);
-	if (ret)
-		return ret;
-
-	nv_subdev(fifo)->unit = 0x00000100;
-	nv_subdev(fifo)->intr = gk104_fifo_intr;
-	return 0;
+	return gk104_fifo_new_(&gk104_fifo, device, index, 4096, pfifo);
 }
-
-struct nvkm_oclass *
-gk104_fifo_oclass = &(struct gk104_fifo_impl) {
-	.base.handle = NV_ENGINE(FIFO, 0xe0),
-	.base.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = gk104_fifo_ctor,
-		.dtor = gk104_fifo_dtor,
-		.init = gk104_fifo_init,
-		.fini = gk104_fifo_fini,
-	},
-	.channels = 4096,
-}.base;

commit 3293228174e4d44cca56d809cc8409c3f88f8b90
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:20 2015 +1000

    drm/nouveau/bar: convert to new-style nvkm_subdev
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index e7f467997194..a69f61f3ecac 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -755,7 +755,7 @@ gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	ret = bar->umap(bar, impl->channels * 0x200, 12, &fifo->user.bar);
+	ret = nvkm_bar_umap(bar, impl->channels * 0x200, 12, &fifo->user.bar);
 	if (ret)
 		return ret;
 

commit 8f0649b5c6e70ec18122255690e39f010c12a614
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:19 2015 +1000

    drm/nouveau/fifo: convert user classes to new-style nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 9ab3fd40b7dd..e7f467997194 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -32,23 +32,6 @@
 
 #include <nvif/class.h>
 
-#define _(a,b) { (a), ((1ULL << (a)) | (b)) }
-static const struct {
-	u64 subdev;
-	u64 mask;
-} fifo_engine[] = {
-	_(NVDEV_ENGINE_GR      , (1ULL << NVDEV_ENGINE_SW) |
-				 (1ULL << NVDEV_ENGINE_CE2)),
-	_(NVDEV_ENGINE_MSPDEC  , 0),
-	_(NVDEV_ENGINE_MSPPP   , 0),
-	_(NVDEV_ENGINE_MSVLD   , 0),
-	_(NVDEV_ENGINE_CE0     , 0),
-	_(NVDEV_ENGINE_CE1     , 0),
-	_(NVDEV_ENGINE_MSENC   , 0),
-};
-#undef _
-#define FIFO_ENGINE_NR ARRAY_SIZE(fifo_engine)
-
 static void
 gk104_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
 {
@@ -76,28 +59,26 @@ void
 gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 {
 	struct gk104_fifo_engn *engn = &fifo->engine[engine];
+	struct gk104_fifo_chan *chan;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	struct nvkm_memory *cur;
-	int i, p;
+	int nr = 0;
 
 	mutex_lock(&nv_subdev(fifo)->mutex);
 	cur = engn->runlist[engn->cur_runlist];
 	engn->cur_runlist = !engn->cur_runlist;
 
 	nvkm_kmap(cur);
-	for (i = 0, p = 0; i < fifo->base.max; i++) {
-		struct gk104_fifo_chan *chan = (void *)fifo->base.channel[i];
-		if (chan && chan->state == RUNNING && chan->engine == engine) {
-			nvkm_wo32(cur, p + 0, i);
-			nvkm_wo32(cur, p + 4, 0x00000000);
-			p += 8;
-		}
+	list_for_each_entry(chan, &engn->chan, head) {
+		nvkm_wo32(cur, (nr * 8) + 0, chan->base.chid);
+		nvkm_wo32(cur, (nr * 8) + 4, 0x00000000);
+		nr++;
 	}
 	nvkm_done(cur);
 
 	nvkm_wr32(device, 0x002270, nvkm_memory_addr(cur) >> 12);
-	nvkm_wr32(device, 0x002274, (engine << 20) | (p >> 3));
+	nvkm_wr32(device, 0x002274, (engine << 20) | nr);
 
 	if (wait_event_timeout(engn->wait, !(nvkm_rd32(device, 0x002284 +
 			       (engine * 0x08)) & 0x00100000),
@@ -106,31 +87,13 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	mutex_unlock(&nv_subdev(fifo)->mutex);
 }
 
-static inline int
-gk104_fifo_engidx(struct gk104_fifo *fifo, u32 engn)
-{
-	switch (engn) {
-	case NVDEV_ENGINE_GR    :
-	case NVDEV_ENGINE_CE2   : engn = 0; break;
-	case NVDEV_ENGINE_MSVLD : engn = 1; break;
-	case NVDEV_ENGINE_MSPPP : engn = 2; break;
-	case NVDEV_ENGINE_MSPDEC: engn = 3; break;
-	case NVDEV_ENGINE_CE0   : engn = 4; break;
-	case NVDEV_ENGINE_CE1   : engn = 5; break;
-	case NVDEV_ENGINE_MSENC : engn = 6; break;
-	default:
-		return -1;
-	}
-
-	return engn;
-}
-
 static inline struct nvkm_engine *
 gk104_fifo_engine(struct gk104_fifo *fifo, u32 engn)
 {
-	if (engn >= ARRAY_SIZE(fifo_engine))
-		return NULL;
-	return nvkm_engine(fifo, fifo_engine[engn].subdev);
+	u64 subdevs = gk104_fifo_engine_subdev(engn);
+	if (subdevs)
+		return nvkm_engine(fifo, __ffs(subdevs));
+	return NULL;
 }
 
 static void
@@ -149,7 +112,7 @@ gk104_fifo_recover_work(struct work_struct *work)
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
-		engm |= 1 << gk104_fifo_engidx(fifo, engn);
+		engm |= 1 << gk104_fifo_subdev_engine(engn);
 	nvkm_mask(device, 0x002630, engm, engm);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
@@ -157,7 +120,7 @@ gk104_fifo_recover_work(struct work_struct *work)
 			nvkm_subdev_fini(&engine->subdev, false);
 			WARN_ON(nvkm_subdev_init(&engine->subdev));
 		}
-		gk104_fifo_runlist_update(fifo, gk104_fifo_engidx(fifo, engn));
+		gk104_fifo_runlist_update(fifo, gk104_fifo_subdev_engine(engn));
 	}
 
 	nvkm_wr32(device, 0x00262c, engm);
@@ -177,7 +140,8 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 	assert_spin_locked(&fifo->base.lock);
 
 	nvkm_mask(device, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
-	chan->state = KILLED;
+	list_del_init(&chan->head);
+	chan->killed = true;
 
 	fifo->mask |= 1ULL << nv_engidx(engine);
 	schedule_work(&fifo->fault);
@@ -223,7 +187,7 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 	u32 engn;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
-	for (engn = 0; engn < ARRAY_SIZE(fifo_engine); engn++) {
+	for (engn = 0; engn < ARRAY_SIZE(fifo->engine); engn++) {
 		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
 		u32 busy = (stat & 0x80000000);
 		u32 next = (stat & 0x07ff0000) >> 16;
@@ -235,11 +199,15 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 		(void)save;
 
 		if (busy && chsw) {
-			if (!(chan = (void *)fifo->base.channel[chid]))
-				continue;
-			if (!(engine = gk104_fifo_engine(fifo, engn)))
-				continue;
-			gk104_fifo_recover(fifo, engine, chan);
+			list_for_each_entry(chan, &fifo->engine[engn].chan, head) {
+				if (chan->base.chid == chid) {
+					engine = gk104_fifo_engine(fifo, engn);
+					if (!engine)
+						break;
+					gk104_fifo_recover(fifo, engine, chan);
+					break;
+				}
+			}
 		}
 	}
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
@@ -444,7 +412,8 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 		   write ? "write" : "read", (u64)vahi << 32 | valo,
 		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
 		   reason, er ? er->name : "", chan ? chan->chid : -1,
-		   (u64)inst << 12, nvkm_client_name(chan));
+		   (u64)inst << 12,
+		   chan ? chan->object.client->name : "unknown");
 
 	if (engine && chan)
 		gk104_fifo_recover(fifo, engine, (void *)chan);
@@ -498,6 +467,8 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
 	u32 show = stat;
+	struct nvkm_fifo_chan *chan;
+	unsigned long flags;
 	char msg[128];
 
 	if (stat & 0x00800000) {
@@ -510,11 +481,13 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 
 	if (show) {
 		nvkm_snprintbf(msg, sizeof(msg), gk104_fifo_pbdma_intr_0, show);
-		nvkm_error(subdev, "PBDMA%d: %08x [%s] ch %d [%s] subc %d "
-				   "mthd %04x data %08x\n",
-			   unit, show, msg, chid,
-			   nvkm_client_name_for_fifo_chid(&fifo->base, chid),
+		chan = nvkm_fifo_chan_chid(&fifo->base, chid, &flags);
+		nvkm_error(subdev, "PBDMA%d: %08x [%s] ch %d [%010llx %s] "
+				   "subc %d mthd %04x data %08x\n",
+			   unit, show, msg, chid, chan ? chan->inst->addr : 0,
+			   chan ? chan->object.client->name : "unknown",
 			   subc, mthd, data);
+		nvkm_fifo_chan_put(&fifo->base, flags, &chan);
 	}
 
 	nvkm_wr32(device, 0x040108 + (unit * 0x2000), stat);
@@ -722,7 +695,7 @@ gk104_fifo_dtor(struct nvkm_object *object)
 	nvkm_vm_put(&fifo->user.bar);
 	nvkm_memory_del(&fifo->user.mem);
 
-	for (i = 0; i < FIFO_ENGINE_NR; i++) {
+	for (i = 0; i < ARRAY_SIZE(fifo->engine); i++) {
 		nvkm_memory_del(&fifo->engine[i].runlist[1]);
 		nvkm_memory_del(&fifo->engine[i].runlist[0]);
 	}
@@ -730,6 +703,14 @@ gk104_fifo_dtor(struct nvkm_object *object)
 	nvkm_fifo_destroy(&fifo->base);
 }
 
+static const struct nvkm_fifo_func
+gk104_fifo_func = {
+	.chan = {
+		&gk104_fifo_gpfifo_oclass,
+		NULL
+	},
+};
+
 int
 gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct nvkm_oclass *oclass, void *data, u32 size,
@@ -747,9 +728,11 @@ gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
+	fifo->base.func = &gk104_fifo_func;
+
 	INIT_WORK(&fifo->fault, gk104_fifo_recover_work);
 
-	for (i = 0; i < FIFO_ENGINE_NR; i++) {
+	for (i = 0; i < ARRAY_SIZE(fifo->engine); i++) {
 		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 				      0x8000, 0x1000, false,
 				      &fifo->engine[i].runlist[0]);
@@ -763,6 +746,7 @@ gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 			return ret;
 
 		init_waitqueue_head(&fifo->engine[i].wait);
+		INIT_LIST_HEAD(&fifo->engine[i].chan);
 	}
 
 	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
@@ -783,8 +767,6 @@ gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	nv_subdev(fifo)->unit = 0x00000100;
 	nv_subdev(fifo)->intr = gk104_fifo_intr;
-	nv_engine(fifo)->cclass = &gk104_fifo_cclass;
-	nv_engine(fifo)->sclass = gk104_fifo_sclass;
 	return 0;
 }
 

commit 9a65a38c456ebac97f0498e85fe26f6d26fe3936
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:19 2015 +1000

    drm/nouveau/fifo: split user classes out from engine implementations
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index e0badfc54dc8..9ab3fd40b7dd 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -22,20 +22,15 @@
  * Authors: Ben Skeggs
  */
 #include "gk104.h"
+#include "changk104.h"
 
 #include <core/client.h>
-#include <core/engctx.h>
 #include <core/enum.h>
 #include <core/handle.h>
 #include <subdev/bar.h>
-#include <subdev/fb.h>
-#include <subdev/mmu.h>
-#include <subdev/timer.h>
 #include <engine/sw.h>
 
 #include <nvif/class.h>
-#include <nvif/ioctl.h>
-#include <nvif/unpack.h>
 
 #define _(a,b) { (a), ((1ULL << (a)) | (b)) }
 static const struct {
@@ -54,47 +49,30 @@ static const struct {
 #undef _
 #define FIFO_ENGINE_NR ARRAY_SIZE(fifo_engine)
 
-struct gk104_fifo_engn {
-	struct nvkm_memory *runlist[2];
-	int cur_runlist;
-	wait_queue_head_t wait;
-};
-
-struct gk104_fifo {
-	struct nvkm_fifo base;
-
-	struct work_struct fault;
-	u64 mask;
-
-	struct gk104_fifo_engn engine[FIFO_ENGINE_NR];
-	struct {
-		struct nvkm_memory *mem;
-		struct nvkm_vma bar;
-	} user;
-	int spoon_nr;
-};
+static void
+gk104_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
+}
 
-struct gk104_fifo_base {
-	struct nvkm_fifo_base base;
-	struct nvkm_gpuobj *pgd;
-	struct nvkm_vm *vm;
-};
+static void
+gk104_fifo_uevent_init(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
+}
 
-struct gk104_fifo_chan {
-	struct nvkm_fifo_chan base;
-	u32 engine;
-	enum {
-		STOPPED,
-		RUNNING,
-		KILLED
-	} state;
+static const struct nvkm_event_func
+gk104_fifo_uevent_func = {
+	.ctor = nvkm_fifo_uevent_ctor,
+	.init = gk104_fifo_uevent_init,
+	.fini = gk104_fifo_uevent_fini,
 };
 
-/*******************************************************************************
- * FIFO channel objects
- ******************************************************************************/
-
-static void
+void
 gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 {
 	struct gk104_fifo_engn *engn = &fifo->engine[engine];
@@ -128,322 +106,6 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	mutex_unlock(&nv_subdev(fifo)->mutex);
 }
 
-static int
-gk104_fifo_context_attach(struct nvkm_object *parent,
-			  struct nvkm_object *object)
-{
-	struct gk104_fifo_base *base = (void *)parent->parent;
-	struct nvkm_gpuobj *engn = &base->base.gpuobj;
-	struct nvkm_engctx *ectx = (void *)object;
-	u32 addr;
-	int ret;
-
-	switch (nv_engidx(object->engine)) {
-	case NVDEV_ENGINE_SW   :
-		return 0;
-	case NVDEV_ENGINE_CE0:
-	case NVDEV_ENGINE_CE1:
-	case NVDEV_ENGINE_CE2:
-		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
-		return 0;
-	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
-	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
-	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
-	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
-	default:
-		return -EINVAL;
-	}
-
-	if (!ectx->vma.node) {
-		ret = nvkm_gpuobj_map(nv_gpuobj(ectx), base->vm,
-				      NV_MEM_ACCESS_RW, &ectx->vma);
-		if (ret)
-			return ret;
-
-		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
-	}
-
-	nvkm_kmap(engn);
-	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
-	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
-	nvkm_done(engn);
-	return 0;
-}
-
-static int
-gk104_fifo_chan_kick(struct gk104_fifo_chan *chan)
-{
-	struct nvkm_object *obj = (void *)chan;
-	struct gk104_fifo *fifo = (void *)obj->engine;
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
-
-	nvkm_wr32(device, 0x002634, chan->base.chid);
-	if (nvkm_msec(device, 2000,
-		if (!(nvkm_rd32(device, 0x002634) & 0x00100000))
-			break;
-	) < 0) {
-		nvkm_error(subdev, "channel %d [%s] kick timeout\n",
-			   chan->base.chid, nvkm_client_name(chan));
-		return -EBUSY;
-	}
-
-	return 0;
-}
-
-static int
-gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
-			  struct nvkm_object *object)
-{
-	struct gk104_fifo_base *base = (void *)parent->parent;
-	struct gk104_fifo_chan *chan = (void *)parent;
-	struct nvkm_gpuobj *engn = &base->base.gpuobj;
-	u32 addr;
-	int ret;
-
-	switch (nv_engidx(object->engine)) {
-	case NVDEV_ENGINE_SW    : return 0;
-	case NVDEV_ENGINE_CE0   :
-	case NVDEV_ENGINE_CE1   :
-	case NVDEV_ENGINE_CE2   : addr = 0x0000; break;
-	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
-	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
-	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
-	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
-	default:
-		return -EINVAL;
-	}
-
-	ret = gk104_fifo_chan_kick(chan);
-	if (ret && suspend)
-		return ret;
-
-	if (addr) {
-		nvkm_kmap(engn);
-		nvkm_wo32(engn, addr + 0x00, 0x00000000);
-		nvkm_wo32(engn, addr + 0x04, 0x00000000);
-		nvkm_done(engn);
-	}
-
-	return 0;
-}
-
-static int
-gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-		     struct nvkm_oclass *oclass, void *data, u32 size,
-		     struct nvkm_object **pobject)
-{
-	union {
-		struct kepler_channel_gpfifo_a_v0 v0;
-	} *args = data;
-	struct gk104_fifo *fifo = (void *)engine;
-	struct gk104_fifo_base *base = (void *)parent;
-	struct gk104_fifo_chan *chan;
-	struct nvkm_gpuobj *ramfc = &base->base.gpuobj;
-	u64 usermem, ioffset, ilength;
-	u32 engines;
-	int ret, i;
-
-	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
-	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d "
-				   "ioffset %016llx ilength %08x engine %08x\n",
-			   args->v0.version, args->v0.ioffset,
-			   args->v0.ilength, args->v0.engine);
-		if (args->v0.vm)
-			return -ENOENT;
-	} else
-		return ret;
-
-	for (i = 0, engines = 0; i < FIFO_ENGINE_NR; i++) {
-		if (!nvkm_engine(parent, fifo_engine[i].subdev))
-			continue;
-		engines |= (1 << i);
-	}
-
-	if (!args->v0.engine) {
-		static struct nvkm_oclass oclass = {
-			.ofuncs = &nvkm_object_ofuncs,
-		};
-		args->v0.engine = engines;
-		return nvkm_object_old(parent, engine, &oclass, NULL, 0, pobject);
-	}
-
-	engines &= args->v0.engine;
-	if (!engines) {
-		nvif_ioctl(parent, "unsupported engines %08x\n",
-			   args->v0.engine);
-		return -ENODEV;
-	}
-	i = __ffs(engines);
-
-	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
-				       fifo->user.bar.offset, 0x200, 0,
-				       fifo_engine[i].mask, &chan);
-	*pobject = nv_object(chan);
-	if (ret)
-		return ret;
-
-	chan->base.inst = base->base.gpuobj.addr;
-	args->v0.chid = chan->base.chid;
-
-	nv_parent(chan)->context_attach = gk104_fifo_context_attach;
-	nv_parent(chan)->context_detach = gk104_fifo_context_detach;
-	chan->engine = i;
-
-	usermem = chan->base.chid * 0x200;
-	ioffset = args->v0.ioffset;
-	ilength = order_base_2(args->v0.ilength / 8);
-
-	nvkm_kmap(fifo->user.mem);
-	for (i = 0; i < 0x200; i += 4)
-		nvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);
-	nvkm_done(fifo->user.mem);
-	usermem = nvkm_memory_addr(fifo->user.mem) + usermem;
-
-	nvkm_kmap(ramfc);
-	nvkm_wo32(ramfc, 0x08, lower_32_bits(usermem));
-	nvkm_wo32(ramfc, 0x0c, upper_32_bits(usermem));
-	nvkm_wo32(ramfc, 0x10, 0x0000face);
-	nvkm_wo32(ramfc, 0x30, 0xfffff902);
-	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
-	nvkm_wo32(ramfc, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
-	nvkm_wo32(ramfc, 0x84, 0x20400000);
-	nvkm_wo32(ramfc, 0x94, 0x30000001);
-	nvkm_wo32(ramfc, 0x9c, 0x00000100);
-	nvkm_wo32(ramfc, 0xac, 0x0000001f);
-	nvkm_wo32(ramfc, 0xe8, chan->base.chid);
-	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
-	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
-	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
-	nvkm_done(ramfc);
-	return 0;
-}
-
-static int
-gk104_fifo_chan_init(struct nvkm_object *object)
-{
-	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
-	struct gk104_fifo *fifo = (void *)object->engine;
-	struct gk104_fifo_chan *chan = (void *)object;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	u32 chid = chan->base.chid;
-	int ret;
-
-	ret = nvkm_fifo_channel_init(&chan->base);
-	if (ret)
-		return ret;
-
-	nvkm_mask(device, 0x800004 + (chid * 8), 0x000f0000, chan->engine << 16);
-	nvkm_wr32(device, 0x800000 + (chid * 8), 0x80000000 | base->addr >> 12);
-
-	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
-		nvkm_mask(device, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
-		gk104_fifo_runlist_update(fifo, chan->engine);
-		nvkm_mask(device, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
-	}
-
-	return 0;
-}
-
-static int
-gk104_fifo_chan_fini(struct nvkm_object *object, bool suspend)
-{
-	struct gk104_fifo *fifo = (void *)object->engine;
-	struct gk104_fifo_chan *chan = (void *)object;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	u32 chid = chan->base.chid;
-
-	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
-		nvkm_mask(device, 0x800004 + (chid * 8), 0x00000800, 0x00000800);
-		gk104_fifo_runlist_update(fifo, chan->engine);
-	}
-
-	nvkm_wr32(device, 0x800000 + (chid * 8), 0x00000000);
-	return nvkm_fifo_channel_fini(&chan->base, suspend);
-}
-
-struct nvkm_ofuncs
-gk104_fifo_chan_ofuncs = {
-	.ctor = gk104_fifo_chan_ctor,
-	.dtor = _nvkm_fifo_channel_dtor,
-	.init = gk104_fifo_chan_init,
-	.fini = gk104_fifo_chan_fini,
-	.map  = _nvkm_fifo_channel_map,
-	.rd32 = _nvkm_fifo_channel_rd32,
-	.wr32 = _nvkm_fifo_channel_wr32,
-	.ntfy = _nvkm_fifo_channel_ntfy
-};
-
-static struct nvkm_oclass
-gk104_fifo_sclass[] = {
-	{ KEPLER_CHANNEL_GPFIFO_A, &gk104_fifo_chan_ofuncs },
-	{}
-};
-
-/*******************************************************************************
- * FIFO context - instmem heap and vm setup
- ******************************************************************************/
-
-static int
-gk104_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-			struct nvkm_oclass *oclass, void *data, u32 size,
-			struct nvkm_object **pobject)
-{
-	struct nvkm_device *device = nv_engine(engine)->subdev.device;
-	struct gk104_fifo_base *base;
-	int ret;
-
-	ret = nvkm_fifo_context_create(parent, engine, oclass, NULL, 0x1000,
-				       0x1000, NVOBJ_FLAG_ZERO_ALLOC, &base);
-	*pobject = nv_object(base);
-	if (ret)
-		return ret;
-
-	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &base->pgd);
-	if (ret)
-		return ret;
-
-	nvkm_kmap(&base->base.gpuobj);
-	nvkm_wo32(&base->base.gpuobj, 0x0200, lower_32_bits(base->pgd->addr));
-	nvkm_wo32(&base->base.gpuobj, 0x0204, upper_32_bits(base->pgd->addr));
-	nvkm_wo32(&base->base.gpuobj, 0x0208, 0xffffffff);
-	nvkm_wo32(&base->base.gpuobj, 0x020c, 0x000000ff);
-	nvkm_done(&base->base.gpuobj);
-
-	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
-	if (ret)
-		return ret;
-
-	return 0;
-}
-
-static void
-gk104_fifo_context_dtor(struct nvkm_object *object)
-{
-	struct gk104_fifo_base *base = (void *)object;
-	nvkm_vm_ref(NULL, &base->vm, base->pgd);
-	nvkm_gpuobj_del(&base->pgd);
-	nvkm_fifo_context_destroy(&base->base);
-}
-
-static struct nvkm_oclass
-gk104_fifo_cclass = {
-	.handle = NV_ENGCTX(FIFO, 0xe0),
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = gk104_fifo_context_ctor,
-		.dtor = gk104_fifo_context_dtor,
-		.init = _nvkm_fifo_context_init,
-		.fini = _nvkm_fifo_context_fini,
-		.rd32 = _nvkm_fifo_context_rd32,
-		.wr32 = _nvkm_fifo_context_wr32,
-	},
-};
-
-/*******************************************************************************
- * PFIFO engine
- ******************************************************************************/
-
 static inline int
 gk104_fifo_engidx(struct gk104_fifo *fifo, u32 engn)
 {
@@ -998,29 +660,6 @@ gk104_fifo_intr(struct nvkm_subdev *subdev)
 	}
 }
 
-static void
-gk104_fifo_uevent_init(struct nvkm_event *event, int type, int index)
-{
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	struct nvkm_device *device = fifo->engine.subdev.device;
-	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
-}
-
-static void
-gk104_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
-{
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	struct nvkm_device *device = fifo->engine.subdev.device;
-	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
-}
-
-static const struct nvkm_event_func
-gk104_fifo_uevent_func = {
-	.ctor = nvkm_fifo_uevent_ctor,
-	.init = gk104_fifo_uevent_init,
-	.fini = gk104_fifo_uevent_fini,
-};
-
 int
 gk104_fifo_fini(struct nvkm_object *object, bool suspend)
 {

commit 6157091177102638c7d94ffc159c0b157a1c9b56
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:18 2015 +1000

    drm/nouveau/sw: remove dependence on namedb/engctx lookup
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 3d2b16e7a7ee..e0badfc54dc8 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -31,6 +31,7 @@
 #include <subdev/fb.h>
 #include <subdev/mmu.h>
 #include <subdev/timer.h>
+#include <engine/sw.h>
 
 #include <nvif/class.h>
 #include <nvif/ioctl.h>
@@ -520,32 +521,6 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 	schedule_work(&fifo->fault);
 }
 
-static int
-gk104_fifo_swmthd(struct gk104_fifo *fifo, u32 chid, u32 mthd, u32 data)
-{
-	struct gk104_fifo_chan *chan = NULL;
-	struct nvkm_handle *bind;
-	unsigned long flags;
-	int ret = -EINVAL;
-
-	spin_lock_irqsave(&fifo->base.lock, flags);
-	if (likely(chid >= fifo->base.min && chid <= fifo->base.max))
-		chan = (void *)fifo->base.channel[chid];
-	if (unlikely(!chan))
-		goto out;
-
-	bind = nvkm_namedb_get_class(nv_namedb(chan), NVIF_IOCTL_NEW_V0_SW_GF100);
-	if (likely(bind)) {
-		if (!mthd || !nv_call(bind->object, mthd, data))
-			ret = 0;
-		nvkm_namedb_put(bind);
-	}
-
-out:
-	spin_unlock_irqrestore(&fifo->base.lock, flags);
-	return ret;
-}
-
 static const struct nvkm_enum
 gk104_fifo_bind_reason[] = {
 	{ 0x01, "BIND_NOT_UNBOUND" },
@@ -864,8 +839,10 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 	char msg[128];
 
 	if (stat & 0x00800000) {
-		if (!gk104_fifo_swmthd(fifo, chid, mthd, data))
-			show &= ~0x00800000;
+		if (device->sw) {
+			if (nvkm_sw_mthd(device->sw, chid, subc, mthd, data))
+				show &= ~0x00800000;
+		}
 		nvkm_wr32(device, 0x0400c0 + (unit * 0x2000), 0x80600008);
 	}
 

commit 6ca307b0c9c7878eb1b2b42982c05671f0591229
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:18 2015 +1000

    drm/nouveau/fifo: remove dependence on namedb/engctx lookup
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 4407f6bbf94f..3d2b16e7a7ee 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -508,17 +508,15 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	u32 chid = chan->base.chid;
-	unsigned long flags;
 
 	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
 		   nvkm_subdev_name[nv_subdev(engine)->index], chid);
+	assert_spin_locked(&fifo->base.lock);
 
 	nvkm_mask(device, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
 	chan->state = KILLED;
 
-	spin_lock_irqsave(&fifo->base.lock, flags);
 	fifo->mask |= 1ULL << nv_engidx(engine);
-	spin_unlock_irqrestore(&fifo->base.lock, flags);
 	schedule_work(&fifo->fault);
 }
 
@@ -584,8 +582,10 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_engine *engine;
 	struct gk104_fifo_chan *chan;
+	unsigned long flags;
 	u32 engn;
 
+	spin_lock_irqsave(&fifo->base.lock, flags);
 	for (engn = 0; engn < ARRAY_SIZE(fifo_engine); engn++) {
 		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
 		u32 busy = (stat & 0x80000000);
@@ -605,6 +605,7 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 			gk104_fifo_recover(fifo, engine, chan);
 		}
 	}
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
 }
 
 static void
@@ -766,9 +767,10 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	u32 write  = (stat & 0x00000080);
 	u32 hub    = (stat & 0x00000040);
 	u32 reason = (stat & 0x0000000f);
-	struct nvkm_object *engctx = NULL, *object;
-	struct nvkm_engine *engine = NULL;
 	const struct nvkm_enum *er, *eu, *ec;
+	struct nvkm_engine *engine = NULL;
+	struct nvkm_fifo_chan *chan;
+	unsigned long flags;
 	char gpcid[8] = "";
 
 	er = nvkm_enum_find(gk104_fifo_fault_reason, reason);
@@ -793,32 +795,23 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 			break;
 		default:
 			engine = nvkm_engine(fifo, eu->data2);
-			if (engine)
-				engctx = nvkm_engctx_get(engine, inst);
 			break;
 		}
 	}
 
+	chan = nvkm_fifo_chan_inst(&fifo->base, (u64)inst << 12, &flags);
+
 	nvkm_error(subdev,
 		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
 		   "reason %02x [%s] on channel %d [%010llx %s]\n",
 		   write ? "write" : "read", (u64)vahi << 32 | valo,
 		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
-		   reason, er ? er->name : "", -1, (u64)inst << 12,
-		   nvkm_client_name(engctx));
-
-	object = engctx;
-	while (object) {
-		switch (nv_mclass(object)) {
-		case KEPLER_CHANNEL_GPFIFO_A:
-		case MAXWELL_CHANNEL_GPFIFO_A:
-			gk104_fifo_recover(fifo, engine, (void *)object);
-			break;
-		}
-		object = object->parent;
-	}
+		   reason, er ? er->name : "", chan ? chan->chid : -1,
+		   (u64)inst << 12, nvkm_client_name(chan));
 
-	nvkm_engctx_put(engctx);
+	if (engine && chan)
+		gk104_fifo_recover(fifo, engine, (void *)chan);
+	nvkm_fifo_chan_put(&fifo->base, flags, &chan);
 }
 
 static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {

commit 344c2d429dd86b1b0113177e18f15adb74e9d936
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:18 2015 +1000

    drm/nouveau/fb: remove dependence on namedb/engctx lookup
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 39dae1a28dd1..4407f6bbf94f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -283,6 +283,7 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
+	chan->base.inst = base->base.gpuobj.addr;
 	args->v0.chid = chan->base.chid;
 
 	nv_parent(chan)->context_attach = gk104_fifo_context_attach;

commit f027f49166171c98d5945af12ac3ee9bc9f9bf4c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/gpuobj: separate allocation from nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 0e8356d5fa02..39dae1a28dd1 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -154,8 +154,8 @@ gk104_fifo_context_attach(struct nvkm_object *parent,
 	}
 
 	if (!ectx->vma.node) {
-		ret = nvkm_gpuobj_map_vm(nv_gpuobj(ectx), base->vm,
-					 NV_MEM_ACCESS_RW, &ectx->vma);
+		ret = nvkm_gpuobj_map(nv_gpuobj(ectx), base->vm,
+				      NV_MEM_ACCESS_RW, &ectx->vma);
 		if (ret)
 			return ret;
 
@@ -388,6 +388,7 @@ gk104_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 			struct nvkm_oclass *oclass, void *data, u32 size,
 			struct nvkm_object **pobject)
 {
+	struct nvkm_device *device = nv_engine(engine)->subdev.device;
 	struct gk104_fifo_base *base;
 	int ret;
 
@@ -397,8 +398,7 @@ gk104_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(base), NULL, 0x10000, 0x1000, 0,
-			      &base->pgd);
+	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &base->pgd);
 	if (ret)
 		return ret;
 
@@ -421,7 +421,7 @@ gk104_fifo_context_dtor(struct nvkm_object *object)
 {
 	struct gk104_fifo_base *base = (void *)object;
 	nvkm_vm_ref(NULL, &base->vm, base->pgd);
-	nvkm_gpuobj_ref(NULL, &base->pgd);
+	nvkm_gpuobj_del(&base->pgd);
 	nvkm_fifo_context_destroy(&base->base);
 }
 

commit 358ce601ae5de59bf6f08f79455c5b3cb7d359d4
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/fifo: directly use instmem for runlists and polling areas
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index d1238aa7bec5..0e8356d5fa02 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -27,6 +27,7 @@
 #include <core/engctx.h>
 #include <core/enum.h>
 #include <core/handle.h>
+#include <subdev/bar.h>
 #include <subdev/fb.h>
 #include <subdev/mmu.h>
 #include <subdev/timer.h>
@@ -53,7 +54,7 @@ static const struct {
 #define FIFO_ENGINE_NR ARRAY_SIZE(fifo_engine)
 
 struct gk104_fifo_engn {
-	struct nvkm_gpuobj *runlist[2];
+	struct nvkm_memory *runlist[2];
 	int cur_runlist;
 	wait_queue_head_t wait;
 };
@@ -66,7 +67,7 @@ struct gk104_fifo {
 
 	struct gk104_fifo_engn engine[FIFO_ENGINE_NR];
 	struct {
-		struct nvkm_gpuobj *mem;
+		struct nvkm_memory *mem;
 		struct nvkm_vma bar;
 	} user;
 	int spoon_nr;
@@ -98,7 +99,7 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	struct gk104_fifo_engn *engn = &fifo->engine[engine];
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	struct nvkm_gpuobj *cur;
+	struct nvkm_memory *cur;
 	int i, p;
 
 	mutex_lock(&nv_subdev(fifo)->mutex);
@@ -116,7 +117,7 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	}
 	nvkm_done(cur);
 
-	nvkm_wr32(device, 0x002270, cur->addr >> 12);
+	nvkm_wr32(device, 0x002270, nvkm_memory_addr(cur) >> 12);
 	nvkm_wr32(device, 0x002274, (engine << 20) | (p >> 3));
 
 	if (wait_event_timeout(engn->wait, !(nvkm_rd32(device, 0x002284 +
@@ -296,10 +297,11 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	for (i = 0; i < 0x200; i += 4)
 		nvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);
 	nvkm_done(fifo->user.mem);
+	usermem = nvkm_memory_addr(fifo->user.mem) + usermem;
 
 	nvkm_kmap(ramfc);
-	nvkm_wo32(ramfc, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
-	nvkm_wo32(ramfc, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
+	nvkm_wo32(ramfc, 0x08, lower_32_bits(usermem));
+	nvkm_wo32(ramfc, 0x0c, upper_32_bits(usermem));
 	nvkm_wo32(ramfc, 0x10, 0x0000face);
 	nvkm_wo32(ramfc, 0x30, 0xfffff902);
 	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
@@ -1107,12 +1109,12 @@ gk104_fifo_dtor(struct nvkm_object *object)
 	struct gk104_fifo *fifo = (void *)object;
 	int i;
 
-	nvkm_gpuobj_unmap(&fifo->user.bar);
-	nvkm_gpuobj_ref(NULL, &fifo->user.mem);
+	nvkm_vm_put(&fifo->user.bar);
+	nvkm_memory_del(&fifo->user.mem);
 
 	for (i = 0; i < FIFO_ENGINE_NR; i++) {
-		nvkm_gpuobj_ref(NULL, &fifo->engine[i].runlist[1]);
-		nvkm_gpuobj_ref(NULL, &fifo->engine[i].runlist[0]);
+		nvkm_memory_del(&fifo->engine[i].runlist[1]);
+		nvkm_memory_del(&fifo->engine[i].runlist[0]);
 	}
 
 	nvkm_fifo_destroy(&fifo->base);
@@ -1123,6 +1125,8 @@ gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct nvkm_oclass *oclass, void *data, u32 size,
 		struct nvkm_object **pobject)
 {
+	struct nvkm_device *device = (void *)parent;
+	struct nvkm_bar *bar = device->bar;
 	struct gk104_fifo_impl *impl = (void *)oclass;
 	struct gk104_fifo *fifo;
 	int ret, i;
@@ -1136,29 +1140,33 @@ gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	INIT_WORK(&fifo->fault, gk104_fifo_recover_work);
 
 	for (i = 0; i < FIFO_ENGINE_NR; i++) {
-		ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x8000, 0x1000,
-				      0, &fifo->engine[i].runlist[0]);
+		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+				      0x8000, 0x1000, false,
+				      &fifo->engine[i].runlist[0]);
 		if (ret)
 			return ret;
 
-		ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x8000, 0x1000,
-				      0, &fifo->engine[i].runlist[1]);
+		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+				      0x8000, 0x1000, false,
+				      &fifo->engine[i].runlist[1]);
 		if (ret)
 			return ret;
 
 		init_waitqueue_head(&fifo->engine[i].wait);
 	}
 
-	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, impl->channels * 0x200,
-			      0x1000, NVOBJ_FLAG_ZERO_ALLOC, &fifo->user.mem);
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+			      impl->channels * 0x200, 0x1000,
+			      true, &fifo->user.mem);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_map(fifo->user.mem, NV_MEM_ACCESS_RW,
-			      &fifo->user.bar);
+	ret = bar->umap(bar, impl->channels * 0x200, 12, &fifo->user.bar);
 	if (ret)
 		return ret;
 
+	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
+
 	ret = nvkm_event_init(&gk104_fifo_uevent_func, 1, 1, &fifo->base.uevent);
 	if (ret)
 		return ret;

commit d8e83994aaf6749b7124a219f5b46bd1329e2a08
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/imem: improve management of instance memory
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 62b3de4e9353..d1238aa7bec5 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -27,7 +27,6 @@
 #include <core/engctx.h>
 #include <core/enum.h>
 #include <core/handle.h>
-#include <subdev/bar.h>
 #include <subdev/fb.h>
 #include <subdev/mmu.h>
 #include <subdev/timer.h>
@@ -99,7 +98,6 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	struct gk104_fifo_engn *engn = &fifo->engine[engine];
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	struct nvkm_bar *bar = device->bar;
 	struct nvkm_gpuobj *cur;
 	int i, p;
 
@@ -116,7 +114,6 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 			p += 8;
 		}
 	}
-	bar->flush(bar);
 	nvkm_done(cur);
 
 	nvkm_wr32(device, 0x002270, cur->addr >> 12);
@@ -133,7 +130,6 @@ static int
 gk104_fifo_context_attach(struct nvkm_object *parent,
 			  struct nvkm_object *object)
 {
-	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gk104_fifo_base *base = (void *)parent->parent;
 	struct nvkm_gpuobj *engn = &base->base.gpuobj;
 	struct nvkm_engctx *ectx = (void *)object;
@@ -168,7 +164,6 @@ gk104_fifo_context_attach(struct nvkm_object *parent,
 	nvkm_kmap(engn);
 	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
 	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
-	bar->flush(bar);
 	nvkm_done(engn);
 	return 0;
 }
@@ -198,7 +193,6 @@ static int
 gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 			  struct nvkm_object *object)
 {
-	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gk104_fifo_base *base = (void *)parent->parent;
 	struct gk104_fifo_chan *chan = (void *)parent;
 	struct nvkm_gpuobj *engn = &base->base.gpuobj;
@@ -226,7 +220,6 @@ gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 		nvkm_kmap(engn);
 		nvkm_wo32(engn, addr + 0x00, 0x00000000);
 		nvkm_wo32(engn, addr + 0x04, 0x00000000);
-		bar->flush(bar);
 		nvkm_done(engn);
 	}
 
@@ -241,7 +234,6 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	union {
 		struct kepler_channel_gpfifo_a_v0 v0;
 	} *args = data;
-	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gk104_fifo *fifo = (void *)engine;
 	struct gk104_fifo_base *base = (void *)parent;
 	struct gk104_fifo_chan *chan;
@@ -320,7 +312,6 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
 	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
 	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
-	bar->flush(bar);
 	nvkm_done(ramfc);
 	return 0;
 }

commit 6cf813fb26640ef539051fb7f965af8c9ff10d92
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/device: prepare for new-style subdevs
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 216205cdf115..62b3de4e9353 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -481,7 +481,7 @@ gk104_fifo_recover_work(struct work_struct *work)
 {
 	struct gk104_fifo *fifo = container_of(work, typeof(*fifo), fault);
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	struct nvkm_object *engine;
+	struct nvkm_engine *engine;
 	unsigned long flags;
 	u32 engn, engm = 0;
 	u64 mask, todo;
@@ -496,9 +496,9 @@ gk104_fifo_recover_work(struct work_struct *work)
 	nvkm_mask(device, 0x002630, engm, engm);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
-		if ((engine = (void *)nvkm_engine(fifo, engn))) {
-			nvkm_object_fini(engine, false);
-			WARN_ON(nvkm_object_init(engine));
+		if ((engine = nvkm_device_engine(device, engn))) {
+			nvkm_subdev_fini(&engine->subdev, false);
+			WARN_ON(nvkm_subdev_init(&engine->subdev));
 		}
 		gk104_fifo_runlist_update(fifo, gk104_fifo_engidx(fifo, engn));
 	}

commit f0290215c44370ff5d55c01a13dc5a44a1f86efa
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/subdev: implement support for new-style nvkm_subdev
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 9d75dbaa01c0..216205cdf115 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -517,7 +517,7 @@ gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 	unsigned long flags;
 
 	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
-		   nv_subdev(engine)->name, chid);
+		   nvkm_subdev_name[nv_subdev(engine)->index], chid);
 
 	nvkm_mask(device, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
 	chan->state = KILLED;

commit cbea21e2ab658ca1256bfe5f4c535b2b1b9e4060
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/object: implement support for new-style nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 3562b791162f..9d75dbaa01c0 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -497,8 +497,8 @@ gk104_fifo_recover_work(struct work_struct *work)
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
 		if ((engine = (void *)nvkm_engine(fifo, engn))) {
-			nv_ofuncs(engine)->fini(engine, false);
-			WARN_ON(nv_ofuncs(engine)->init(engine));
+			nvkm_object_fini(engine, false);
+			WARN_ON(nvkm_object_init(engine));
 		}
 		gk104_fifo_runlist_update(fifo, gk104_fifo_engidx(fifo, engn));
 	}

commit aa35888ff024b18c7b6b29eb773a221f642987f7
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/object: rename some functions to avoid upcoming conflicts
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 48b526cb8cb5..3562b791162f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -272,7 +272,7 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 			.ofuncs = &nvkm_object_ofuncs,
 		};
 		args->v0.engine = engines;
-		return nvkm_object_ctor(parent, engine, &oclass, NULL, 0, pobject);
+		return nvkm_object_old(parent, engine, &oclass, NULL, 0, pobject);
 	}
 
 	engines &= args->v0.engine;

commit 159045cdc460794df27e2cc624a9641be5c54b23
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/nvif: replace pushbuf with vm in fermi/kepler gpfifo class args
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index bdd0b00c59c9..48b526cb8cb5 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -252,10 +252,12 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %llx "
+		nvif_ioctl(parent, "create channel gpfifo vers %d "
 				   "ioffset %016llx ilength %08x engine %08x\n",
-			   args->v0.version, args->v0.pushbuf, args->v0.ioffset,
+			   args->v0.version, args->v0.ioffset,
 			   args->v0.ilength, args->v0.engine);
+		if (args->v0.vm)
+			return -ENOENT;
 	} else
 		return ret;
 
@@ -282,8 +284,7 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	i = __ffs(engines);
 
 	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
-				       fifo->user.bar.offset, 0x200,
-				       args->v0.pushbuf,
+				       fifo->user.bar.offset, 0x200, 0,
 				       fifo_engine[i].mask, &chan);
 	*pobject = nv_object(chan);
 	if (ret)

commit d56241794c293ff7341d373d853e5a4e2f5de244
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/nvif: add supported engines query to kepler gpfifo class
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 49d7ea0acbd1..bdd0b00c59c9 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -245,9 +245,9 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	struct gk104_fifo *fifo = (void *)engine;
 	struct gk104_fifo_base *base = (void *)parent;
 	struct gk104_fifo_chan *chan;
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_gpuobj *ramfc = &base->base.gpuobj;
 	u64 usermem, ioffset, ilength;
+	u32 engines;
 	int ret, i;
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
@@ -259,20 +259,27 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	} else
 		return ret;
 
-	for (i = 0; i < FIFO_ENGINE_NR; i++) {
-		if (args->v0.engine & (1 << i)) {
-			if (nvkm_engine(parent, fifo_engine[i].subdev)) {
-				args->v0.engine = (1 << i);
-				break;
-			}
-		}
+	for (i = 0, engines = 0; i < FIFO_ENGINE_NR; i++) {
+		if (!nvkm_engine(parent, fifo_engine[i].subdev))
+			continue;
+		engines |= (1 << i);
+	}
+
+	if (!args->v0.engine) {
+		static struct nvkm_oclass oclass = {
+			.ofuncs = &nvkm_object_ofuncs,
+		};
+		args->v0.engine = engines;
+		return nvkm_object_ctor(parent, engine, &oclass, NULL, 0, pobject);
 	}
 
-	if (i == FIFO_ENGINE_NR) {
-		nvkm_error(subdev, "unsupported engines %08x\n",
+	engines &= args->v0.engine;
+	if (!engines) {
+		nvif_ioctl(parent, "unsupported engines %08x\n",
 			   args->v0.engine);
 		return -ENODEV;
 	}
+	i = __ffs(engines);
 
 	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
 				       fifo->user.bar.offset, 0x200,

commit f58ddf9581655d3fea51465f06f292d365af9c87
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/nvif: assign internal class identifiers to sw classes
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 9c423514fee7..49d7ea0acbd1 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -33,6 +33,7 @@
 #include <subdev/timer.h>
 
 #include <nvif/class.h>
+#include <nvif/ioctl.h>
 #include <nvif/unpack.h>
 
 #define _(a,b) { (a), ((1ULL << (a)) | (b)) }
@@ -533,7 +534,7 @@ gk104_fifo_swmthd(struct gk104_fifo *fifo, u32 chid, u32 mthd, u32 data)
 	if (unlikely(!chan))
 		goto out;
 
-	bind = nvkm_namedb_get_class(nv_namedb(chan), 0x906e);
+	bind = nvkm_namedb_get_class(nv_namedb(chan), NVIF_IOCTL_NEW_V0_SW_GF100);
 	if (likely(bind)) {
 		if (!mthd || !nv_call(bind->object, mthd, data))
 			ret = 0;

commit bf81df9be28657eea4aca8c6ab4ed3e69f8a051c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/nvif: replace path-based object identification
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 9a1ecef24813..9c423514fee7 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -251,7 +251,7 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
+		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %llx "
 				   "ioffset %016llx ilength %08x engine %08x\n",
 			   args->v0.version, args->v0.pushbuf, args->v0.ioffset,
 			   args->v0.ilength, args->v0.engine);

commit 5444e770e3991ddb5a9583d622fc18bbf414b551
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:14 2015 +1000

    drm/nouveau/fifo: switch to gpuobj accessor macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index ce12e4e12b22..9a1ecef24813 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -106,15 +106,17 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	cur = engn->runlist[engn->cur_runlist];
 	engn->cur_runlist = !engn->cur_runlist;
 
+	nvkm_kmap(cur);
 	for (i = 0, p = 0; i < fifo->base.max; i++) {
 		struct gk104_fifo_chan *chan = (void *)fifo->base.channel[i];
 		if (chan && chan->state == RUNNING && chan->engine == engine) {
-			nv_wo32(cur, p + 0, i);
-			nv_wo32(cur, p + 4, 0x00000000);
+			nvkm_wo32(cur, p + 0, i);
+			nvkm_wo32(cur, p + 4, 0x00000000);
 			p += 8;
 		}
 	}
 	bar->flush(bar);
+	nvkm_done(cur);
 
 	nvkm_wr32(device, 0x002270, cur->addr >> 12);
 	nvkm_wr32(device, 0x002274, (engine << 20) | (p >> 3));
@@ -132,6 +134,7 @@ gk104_fifo_context_attach(struct nvkm_object *parent,
 {
 	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gk104_fifo_base *base = (void *)parent->parent;
+	struct nvkm_gpuobj *engn = &base->base.gpuobj;
 	struct nvkm_engctx *ectx = (void *)object;
 	u32 addr;
 	int ret;
@@ -161,9 +164,11 @@ gk104_fifo_context_attach(struct nvkm_object *parent,
 		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
 	}
 
-	nv_wo32(base, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
-	nv_wo32(base, addr + 0x04, upper_32_bits(ectx->vma.offset));
+	nvkm_kmap(engn);
+	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
+	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
 	bar->flush(bar);
+	nvkm_done(engn);
 	return 0;
 }
 
@@ -195,6 +200,7 @@ gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gk104_fifo_base *base = (void *)parent->parent;
 	struct gk104_fifo_chan *chan = (void *)parent;
+	struct nvkm_gpuobj *engn = &base->base.gpuobj;
 	u32 addr;
 	int ret;
 
@@ -216,9 +222,11 @@ gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 		return ret;
 
 	if (addr) {
-		nv_wo32(base, addr + 0x00, 0x00000000);
-		nv_wo32(base, addr + 0x04, 0x00000000);
+		nvkm_kmap(engn);
+		nvkm_wo32(engn, addr + 0x00, 0x00000000);
+		nvkm_wo32(engn, addr + 0x04, 0x00000000);
 		bar->flush(bar);
+		nvkm_done(engn);
 	}
 
 	return 0;
@@ -237,6 +245,7 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	struct gk104_fifo_base *base = (void *)parent;
 	struct gk104_fifo_chan *chan;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_gpuobj *ramfc = &base->base.gpuobj;
 	u64 usermem, ioffset, ilength;
 	int ret, i;
 
@@ -282,24 +291,28 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	ioffset = args->v0.ioffset;
 	ilength = order_base_2(args->v0.ilength / 8);
 
+	nvkm_kmap(fifo->user.mem);
 	for (i = 0; i < 0x200; i += 4)
-		nv_wo32(fifo->user.mem, usermem + i, 0x00000000);
-
-	nv_wo32(base, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
-	nv_wo32(base, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
-	nv_wo32(base, 0x10, 0x0000face);
-	nv_wo32(base, 0x30, 0xfffff902);
-	nv_wo32(base, 0x48, lower_32_bits(ioffset));
-	nv_wo32(base, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
-	nv_wo32(base, 0x84, 0x20400000);
-	nv_wo32(base, 0x94, 0x30000001);
-	nv_wo32(base, 0x9c, 0x00000100);
-	nv_wo32(base, 0xac, 0x0000001f);
-	nv_wo32(base, 0xe8, chan->base.chid);
-	nv_wo32(base, 0xb8, 0xf8000000);
-	nv_wo32(base, 0xf8, 0x10003080); /* 0x002310 */
-	nv_wo32(base, 0xfc, 0x10000010); /* 0x002350 */
+		nvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);
+	nvkm_done(fifo->user.mem);
+
+	nvkm_kmap(ramfc);
+	nvkm_wo32(ramfc, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
+	nvkm_wo32(ramfc, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
+	nvkm_wo32(ramfc, 0x10, 0x0000face);
+	nvkm_wo32(ramfc, 0x30, 0xfffff902);
+	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
+	nvkm_wo32(ramfc, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
+	nvkm_wo32(ramfc, 0x84, 0x20400000);
+	nvkm_wo32(ramfc, 0x94, 0x30000001);
+	nvkm_wo32(ramfc, 0x9c, 0x00000100);
+	nvkm_wo32(ramfc, 0xac, 0x0000001f);
+	nvkm_wo32(ramfc, 0xe8, chan->base.chid);
+	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
+	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
+	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
 	bar->flush(bar);
+	nvkm_done(ramfc);
 	return 0;
 }
 
@@ -387,10 +400,12 @@ gk104_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	nv_wo32(base, 0x0200, lower_32_bits(base->pgd->addr));
-	nv_wo32(base, 0x0204, upper_32_bits(base->pgd->addr));
-	nv_wo32(base, 0x0208, 0xffffffff);
-	nv_wo32(base, 0x020c, 0x000000ff);
+	nvkm_kmap(&base->base.gpuobj);
+	nvkm_wo32(&base->base.gpuobj, 0x0200, lower_32_bits(base->pgd->addr));
+	nvkm_wo32(&base->base.gpuobj, 0x0204, upper_32_bits(base->pgd->addr));
+	nvkm_wo32(&base->base.gpuobj, 0x0208, 0xffffffff);
+	nvkm_wo32(&base->base.gpuobj, 0x020c, 0x000000ff);
+	nvkm_done(&base->base.gpuobj);
 
 	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
 	if (ret)

commit 53003941067534b1071b0f7b71f4700c16d97b28
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:13 2015 +1000

    drm/nouveau/core: remove last printks
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 258a1deb1105..ce12e4e12b22 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -240,12 +240,12 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	u64 usermem, ioffset, ilength;
 	int ret, i;
 
-	nv_ioctl(parent, "create channel gpfifo size %d\n", size);
+	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nv_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
-				 "ioffset %016llx ilength %08x engine %08x\n",
-			 args->v0.version, args->v0.pushbuf, args->v0.ioffset,
-			 args->v0.ilength, args->v0.engine);
+		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
+				   "ioffset %016llx ilength %08x engine %08x\n",
+			   args->v0.version, args->v0.pushbuf, args->v0.ioffset,
+			   args->v0.ilength, args->v0.engine);
 	} else
 		return ret;
 

commit e5c5e4f5d319799fe67dc67531e41ba0b7ed15e6
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:13 2015 +1000

    drm/nouveau/fifo: switch to subdev printk macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index cc8151129888..258a1deb1105 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -96,7 +96,8 @@ static void
 gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 {
 	struct gk104_fifo_engn *engn = &fifo->engine[engine];
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	struct nvkm_bar *bar = device->bar;
 	struct nvkm_gpuobj *cur;
 	int i, p;
@@ -121,7 +122,7 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	if (wait_event_timeout(engn->wait, !(nvkm_rd32(device, 0x002284 +
 			       (engine * 0x08)) & 0x00100000),
 				msecs_to_jiffies(2000)) == 0)
-		nv_error(fifo, "runlist %d update timeout\n", engine);
+		nvkm_error(subdev, "runlist %d update timeout\n", engine);
 	mutex_unlock(&nv_subdev(fifo)->mutex);
 }
 
@@ -171,15 +172,16 @@ gk104_fifo_chan_kick(struct gk104_fifo_chan *chan)
 {
 	struct nvkm_object *obj = (void *)chan;
 	struct gk104_fifo *fifo = (void *)obj->engine;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 
 	nvkm_wr32(device, 0x002634, chan->base.chid);
 	if (nvkm_msec(device, 2000,
 		if (!(nvkm_rd32(device, 0x002634) & 0x00100000))
 			break;
 	) < 0) {
-		nv_error(fifo, "channel %d [%s] kick timeout\n",
-			 chan->base.chid, nvkm_client_name(chan));
+		nvkm_error(subdev, "channel %d [%s] kick timeout\n",
+			   chan->base.chid, nvkm_client_name(chan));
 		return -EBUSY;
 	}
 
@@ -234,6 +236,7 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	struct gk104_fifo *fifo = (void *)engine;
 	struct gk104_fifo_base *base = (void *)parent;
 	struct gk104_fifo_chan *chan;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	u64 usermem, ioffset, ilength;
 	int ret, i;
 
@@ -256,7 +259,8 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	}
 
 	if (i == FIFO_ENGINE_NR) {
-		nv_error(fifo, "unsupported engines 0x%08x\n", args->v0.engine);
+		nvkm_error(subdev, "unsupported engines %08x\n",
+			   args->v0.engine);
 		return -ENODEV;
 	}
 
@@ -483,12 +487,13 @@ static void
 gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 		  struct gk104_fifo_chan *chan)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 chid = chan->base.chid;
 	unsigned long flags;
 
-	nv_error(fifo, "%s engine fault on channel %d, recovering...\n",
-		       nv_subdev(engine)->name, chid);
+	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
+		   nv_subdev(engine)->name, chid);
 
 	nvkm_mask(device, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
 	chan->state = KILLED;
@@ -539,17 +544,14 @@ gk104_fifo_bind_reason[] = {
 static void
 gk104_fifo_intr_bind(struct gk104_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 intr = nvkm_rd32(device, 0x00252c);
 	u32 code = intr & 0x000000ff;
-	const struct nvkm_enum *en;
-	char enunk[6] = "";
+	const struct nvkm_enum *en =
+		nvkm_enum_find(gk104_fifo_bind_reason, code);
 
-	en = nvkm_enum_find(gk104_fifo_bind_reason, code);
-	if (!en)
-		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
-
-	nv_error(fifo, "BIND_ERROR [ %s ]\n", en ? en->name : enunk);
+	nvkm_error(subdev, "BIND_ERROR %02x [%s]\n", code, en ? en->name : "");
 }
 
 static const struct nvkm_enum
@@ -590,17 +592,14 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 static void
 gk104_fifo_intr_sched(struct gk104_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 intr = nvkm_rd32(device, 0x00254c);
 	u32 code = intr & 0x000000ff;
-	const struct nvkm_enum *en;
-	char enunk[6] = "";
-
-	en = nvkm_enum_find(gk104_fifo_sched_reason, code);
-	if (!en)
-		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
+	const struct nvkm_enum *en =
+		nvkm_enum_find(gk104_fifo_sched_reason, code);
 
-	nv_error(fifo, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
+	nvkm_error(subdev, "SCHED_ERROR %02x [%s]\n", code, en ? en->name : "");
 
 	switch (code) {
 	case 0x0a:
@@ -614,18 +613,20 @@ gk104_fifo_intr_sched(struct gk104_fifo *fifo)
 static void
 gk104_fifo_intr_chsw(struct gk104_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 stat = nvkm_rd32(device, 0x00256c);
-	nv_error(fifo, "CHSW_ERROR 0x%08x\n", stat);
+	nvkm_error(subdev, "CHSW_ERROR %08x\n", stat);
 	nvkm_wr32(device, 0x00256c, stat);
 }
 
 static void
 gk104_fifo_intr_dropped_fault(struct gk104_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 stat = nvkm_rd32(device, 0x00259c);
-	nv_error(fifo, "DROPPED_MMU_FAULT 0x%08x\n", stat);
+	nvkm_error(subdev, "DROPPED_MMU_FAULT %08x\n", stat);
 }
 
 static const struct nvkm_enum
@@ -736,7 +737,8 @@ gk104_fifo_fault_gpcclient[] = {
 static void
 gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
 	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
 	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
@@ -749,16 +751,17 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	struct nvkm_object *engctx = NULL, *object;
 	struct nvkm_engine *engine = NULL;
 	const struct nvkm_enum *er, *eu, *ec;
-	char erunk[6] = "";
-	char euunk[6] = "";
-	char ecunk[6] = "";
-	char gpcid[3] = "";
+	char gpcid[8] = "";
 
 	er = nvkm_enum_find(gk104_fifo_fault_reason, reason);
-	if (!er)
-		snprintf(erunk, sizeof(erunk), "UNK%02X", reason);
-
 	eu = nvkm_enum_find(gk104_fifo_fault_engine, unit);
+	if (hub) {
+		ec = nvkm_enum_find(gk104_fifo_fault_hubclient, client);
+	} else {
+		ec = nvkm_enum_find(gk104_fifo_fault_gpcclient, client);
+		snprintf(gpcid, sizeof(gpcid), "GPC%d/", gpc);
+	}
+
 	if (eu) {
 		switch (eu->data2) {
 		case NVDEV_SUBDEV_BAR:
@@ -776,26 +779,15 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 				engctx = nvkm_engctx_get(engine, inst);
 			break;
 		}
-	} else {
-		snprintf(euunk, sizeof(euunk), "UNK%02x", unit);
-	}
-
-	if (hub) {
-		ec = nvkm_enum_find(gk104_fifo_fault_hubclient, client);
-	} else {
-		ec = nvkm_enum_find(gk104_fifo_fault_gpcclient, client);
-		snprintf(gpcid, sizeof(gpcid), "%d", gpc);
 	}
 
-	if (!ec)
-		snprintf(ecunk, sizeof(ecunk), "UNK%02x", client);
-
-	nv_error(fifo, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
-		       "channel 0x%010llx [%s]\n", write ? "write" : "read",
-		 (u64)vahi << 32 | valo, er ? er->name : erunk,
-		 eu ? eu->name : euunk, hub ? "" : "GPC", gpcid, hub ? "" : "/",
-		 ec ? ec->name : ecunk, (u64)inst << 12,
-		 nvkm_client_name(engctx));
+	nvkm_error(subdev,
+		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
+		   "reason %02x [%s] on channel %d [%010llx %s]\n",
+		   write ? "write" : "read", (u64)vahi << 32 | valo,
+		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
+		   reason, er ? er->name : "", -1, (u64)inst << 12,
+		   nvkm_client_name(engctx));
 
 	object = engctx;
 	while (object) {
@@ -848,7 +840,8 @@ static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {
 static void
 gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 mask = nvkm_rd32(device, 0x04010c + (unit * 0x2000));
 	u32 stat = nvkm_rd32(device, 0x040108 + (unit * 0x2000)) & mask;
 	u32 addr = nvkm_rd32(device, 0x0400c0 + (unit * 0x2000));
@@ -857,6 +850,7 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
 	u32 show = stat;
+	char msg[128];
 
 	if (stat & 0x00800000) {
 		if (!gk104_fifo_swmthd(fifo, chid, mthd, data))
@@ -865,14 +859,12 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 	}
 
 	if (show) {
-		nv_error(fifo, "PBDMA%d:", unit);
-		nvkm_bitfield_print(gk104_fifo_pbdma_intr_0, show);
-		pr_cont("\n");
-		nv_error(fifo,
-			 "PBDMA%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
-			 unit, chid,
-			 nvkm_client_name_for_fifo_chid(&fifo->base, chid),
-			 subc, mthd, data);
+		nvkm_snprintbf(msg, sizeof(msg), gk104_fifo_pbdma_intr_0, show);
+		nvkm_error(subdev, "PBDMA%d: %08x [%s] ch %d [%s] subc %d "
+				   "mthd %04x data %08x\n",
+			   unit, show, msg, chid,
+			   nvkm_client_name_for_fifo_chid(&fifo->base, chid),
+			   subc, mthd, data);
 	}
 
 	nvkm_wr32(device, 0x040108 + (unit * 0x2000), stat);
@@ -890,18 +882,19 @@ static const struct nvkm_bitfield gk104_fifo_pbdma_intr_1[] = {
 static void
 gk104_fifo_intr_pbdma_1(struct gk104_fifo *fifo, int unit)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 mask = nvkm_rd32(device, 0x04014c + (unit * 0x2000));
 	u32 stat = nvkm_rd32(device, 0x040148 + (unit * 0x2000)) & mask;
 	u32 chid = nvkm_rd32(device, 0x040120 + (unit * 0x2000)) & 0xfff;
+	char msg[128];
 
 	if (stat) {
-		nv_error(fifo, "PBDMA%d:", unit);
-		nvkm_bitfield_print(gk104_fifo_pbdma_intr_1, stat);
-		pr_cont("\n");
-		nv_error(fifo, "PBDMA%d: ch %d %08x %08x\n", unit, chid,
-			 nvkm_rd32(device, 0x040150 + (unit * 0x2000)),
-			 nvkm_rd32(device, 0x040154 + (unit * 0x2000)));
+		nvkm_snprintbf(msg, sizeof(msg), gk104_fifo_pbdma_intr_1, stat);
+		nvkm_error(subdev, "PBDMA%d: %08x [%s] ch %d %08x %08x\n",
+			   unit, stat, msg, chid,
+			   nvkm_rd32(device, 0x040150 + (unit * 0x2000)),
+			   nvkm_rd32(device, 0x040154 + (unit * 0x2000)));
 	}
 
 	nvkm_wr32(device, 0x040148 + (unit * 0x2000), stat);
@@ -941,7 +934,7 @@ gk104_fifo_intr(struct nvkm_subdev *subdev)
 	}
 
 	if (stat & 0x00000010) {
-		nv_error(fifo, "PIO_ERROR\n");
+		nvkm_error(subdev, "PIO_ERROR\n");
 		nvkm_wr32(device, 0x002100, 0x00000010);
 		stat &= ~0x00000010;
 	}
@@ -959,13 +952,13 @@ gk104_fifo_intr(struct nvkm_subdev *subdev)
 	}
 
 	if (stat & 0x00800000) {
-		nv_error(fifo, "FB_FLUSH_TIMEOUT\n");
+		nvkm_error(subdev, "FB_FLUSH_TIMEOUT\n");
 		nvkm_wr32(device, 0x002100, 0x00800000);
 		stat &= ~0x00800000;
 	}
 
 	if (stat & 0x01000000) {
-		nv_error(fifo, "LB_ERROR\n");
+		nvkm_error(subdev, "LB_ERROR\n");
 		nvkm_wr32(device, 0x002100, 0x01000000);
 		stat &= ~0x01000000;
 	}
@@ -1011,7 +1004,7 @@ gk104_fifo_intr(struct nvkm_subdev *subdev)
 	}
 
 	if (stat) {
-		nv_error(fifo, "INTR 0x%08x\n", stat);
+		nvkm_error(subdev, "INTR %08x\n", stat);
 		nvkm_mask(device, 0x002140, stat, 0x00000000);
 		nvkm_wr32(device, 0x002100, stat);
 	}
@@ -1060,7 +1053,8 @@ int
 gk104_fifo_init(struct nvkm_object *object)
 {
 	struct gk104_fifo *fifo = (void *)object;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	int ret, i;
 
 	ret = nvkm_fifo_init(&fifo->base);
@@ -1070,7 +1064,7 @@ gk104_fifo_init(struct nvkm_object *object)
 	/* enable all available PBDMA units */
 	nvkm_wr32(device, 0x000204, 0xffffffff);
 	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x000204));
-	nv_debug(fifo, "%d PBDMA unit(s)\n", fifo->spoon_nr);
+	nvkm_debug(subdev, "%d PBDMA unit(s)\n", fifo->spoon_nr);
 
 	/* PBDMA[n] */
 	for (i = 0; i < fifo->spoon_nr; i++) {

commit af3082b3c621e75371dc6d11fac5a2dc2b19b1bc
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:11 2015 +1000

    drm/nouveau/fifo: switch to new-style timer macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index cec1281dbd12..cc8151129888 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -174,7 +174,10 @@ gk104_fifo_chan_kick(struct gk104_fifo_chan *chan)
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 
 	nvkm_wr32(device, 0x002634, chan->base.chid);
-	if (!nv_wait(fifo, 0x002634, 0x100000, 0x000000)) {
+	if (nvkm_msec(device, 2000,
+		if (!(nvkm_rd32(device, 0x002634) & 0x00100000))
+			break;
+	) < 0) {
 		nv_error(fifo, "channel %d [%s] kick timeout\n",
 			 chan->base.chid, nvkm_client_name(chan));
 		return -EBUSY;

commit 8774440390cdfe37c5d003f850847c9fd67cdf61
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:10 2015 +1000

    drm/nouveau/fifo: switch to device pri macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index ed8d3820a044..cec1281dbd12 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -95,8 +95,9 @@ struct gk104_fifo_chan {
 static void
 gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 {
-	struct nvkm_bar *bar = nvkm_bar(fifo);
 	struct gk104_fifo_engn *engn = &fifo->engine[engine];
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_bar *bar = device->bar;
 	struct nvkm_gpuobj *cur;
 	int i, p;
 
@@ -114,10 +115,10 @@ gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 	}
 	bar->flush(bar);
 
-	nv_wr32(fifo, 0x002270, cur->addr >> 12);
-	nv_wr32(fifo, 0x002274, (engine << 20) | (p >> 3));
+	nvkm_wr32(device, 0x002270, cur->addr >> 12);
+	nvkm_wr32(device, 0x002274, (engine << 20) | (p >> 3));
 
-	if (wait_event_timeout(engn->wait, !(nv_rd32(fifo, 0x002284 +
+	if (wait_event_timeout(engn->wait, !(nvkm_rd32(device, 0x002284 +
 			       (engine * 0x08)) & 0x00100000),
 				msecs_to_jiffies(2000)) == 0)
 		nv_error(fifo, "runlist %d update timeout\n", engine);
@@ -170,8 +171,9 @@ gk104_fifo_chan_kick(struct gk104_fifo_chan *chan)
 {
 	struct nvkm_object *obj = (void *)chan;
 	struct gk104_fifo *fifo = (void *)obj->engine;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 
-	nv_wr32(fifo, 0x002634, chan->base.chid);
+	nvkm_wr32(device, 0x002634, chan->base.chid);
 	if (!nv_wait(fifo, 0x002634, 0x100000, 0x000000)) {
 		nv_error(fifo, "channel %d [%s] kick timeout\n",
 			 chan->base.chid, nvkm_client_name(chan));
@@ -300,6 +302,7 @@ gk104_fifo_chan_init(struct nvkm_object *object)
 	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
 	struct gk104_fifo *fifo = (void *)object->engine;
 	struct gk104_fifo_chan *chan = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u32 chid = chan->base.chid;
 	int ret;
 
@@ -307,13 +310,13 @@ gk104_fifo_chan_init(struct nvkm_object *object)
 	if (ret)
 		return ret;
 
-	nv_mask(fifo, 0x800004 + (chid * 8), 0x000f0000, chan->engine << 16);
-	nv_wr32(fifo, 0x800000 + (chid * 8), 0x80000000 | base->addr >> 12);
+	nvkm_mask(device, 0x800004 + (chid * 8), 0x000f0000, chan->engine << 16);
+	nvkm_wr32(device, 0x800000 + (chid * 8), 0x80000000 | base->addr >> 12);
 
 	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
-		nv_mask(fifo, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
+		nvkm_mask(device, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
 		gk104_fifo_runlist_update(fifo, chan->engine);
-		nv_mask(fifo, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
+		nvkm_mask(device, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
 	}
 
 	return 0;
@@ -324,14 +327,15 @@ gk104_fifo_chan_fini(struct nvkm_object *object, bool suspend)
 {
 	struct gk104_fifo *fifo = (void *)object->engine;
 	struct gk104_fifo_chan *chan = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u32 chid = chan->base.chid;
 
 	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
-		nv_mask(fifo, 0x800004 + (chid * 8), 0x00000800, 0x00000800);
+		nvkm_mask(device, 0x800004 + (chid * 8), 0x00000800, 0x00000800);
 		gk104_fifo_runlist_update(fifo, chan->engine);
 	}
 
-	nv_wr32(fifo, 0x800000 + (chid * 8), 0x00000000);
+	nvkm_wr32(device, 0x800000 + (chid * 8), 0x00000000);
 	return nvkm_fifo_channel_fini(&chan->base, suspend);
 }
 
@@ -445,6 +449,7 @@ static void
 gk104_fifo_recover_work(struct work_struct *work)
 {
 	struct gk104_fifo *fifo = container_of(work, typeof(*fifo), fault);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_object *engine;
 	unsigned long flags;
 	u32 engn, engm = 0;
@@ -457,7 +462,7 @@ gk104_fifo_recover_work(struct work_struct *work)
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
 		engm |= 1 << gk104_fifo_engidx(fifo, engn);
-	nv_mask(fifo, 0x002630, engm, engm);
+	nvkm_mask(device, 0x002630, engm, engm);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
 		if ((engine = (void *)nvkm_engine(fifo, engn))) {
@@ -467,21 +472,22 @@ gk104_fifo_recover_work(struct work_struct *work)
 		gk104_fifo_runlist_update(fifo, gk104_fifo_engidx(fifo, engn));
 	}
 
-	nv_wr32(fifo, 0x00262c, engm);
-	nv_mask(fifo, 0x002630, engm, 0x00000000);
+	nvkm_wr32(device, 0x00262c, engm);
+	nvkm_mask(device, 0x002630, engm, 0x00000000);
 }
 
 static void
 gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 		  struct gk104_fifo_chan *chan)
 {
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u32 chid = chan->base.chid;
 	unsigned long flags;
 
 	nv_error(fifo, "%s engine fault on channel %d, recovering...\n",
 		       nv_subdev(engine)->name, chid);
 
-	nv_mask(fifo, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
+	nvkm_mask(device, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
 	chan->state = KILLED;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
@@ -530,7 +536,8 @@ gk104_fifo_bind_reason[] = {
 static void
 gk104_fifo_intr_bind(struct gk104_fifo *fifo)
 {
-	u32 intr = nv_rd32(fifo, 0x00252c);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 intr = nvkm_rd32(device, 0x00252c);
 	u32 code = intr & 0x000000ff;
 	const struct nvkm_enum *en;
 	char enunk[6] = "";
@@ -551,12 +558,13 @@ gk104_fifo_sched_reason[] = {
 static void
 gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 {
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_engine *engine;
 	struct gk104_fifo_chan *chan;
 	u32 engn;
 
 	for (engn = 0; engn < ARRAY_SIZE(fifo_engine); engn++) {
-		u32 stat = nv_rd32(fifo, 0x002640 + (engn * 0x04));
+		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
 		u32 busy = (stat & 0x80000000);
 		u32 next = (stat & 0x07ff0000) >> 16;
 		u32 chsw = (stat & 0x00008000);
@@ -579,7 +587,8 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 static void
 gk104_fifo_intr_sched(struct gk104_fifo *fifo)
 {
-	u32 intr = nv_rd32(fifo, 0x00254c);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 intr = nvkm_rd32(device, 0x00254c);
 	u32 code = intr & 0x000000ff;
 	const struct nvkm_enum *en;
 	char enunk[6] = "";
@@ -602,15 +611,17 @@ gk104_fifo_intr_sched(struct gk104_fifo *fifo)
 static void
 gk104_fifo_intr_chsw(struct gk104_fifo *fifo)
 {
-	u32 stat = nv_rd32(fifo, 0x00256c);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 stat = nvkm_rd32(device, 0x00256c);
 	nv_error(fifo, "CHSW_ERROR 0x%08x\n", stat);
-	nv_wr32(fifo, 0x00256c, stat);
+	nvkm_wr32(device, 0x00256c, stat);
 }
 
 static void
 gk104_fifo_intr_dropped_fault(struct gk104_fifo *fifo)
 {
-	u32 stat = nv_rd32(fifo, 0x00259c);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 stat = nvkm_rd32(device, 0x00259c);
 	nv_error(fifo, "DROPPED_MMU_FAULT 0x%08x\n", stat);
 }
 
@@ -722,10 +733,11 @@ gk104_fifo_fault_gpcclient[] = {
 static void
 gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 {
-	u32 inst = nv_rd32(fifo, 0x002800 + (unit * 0x10));
-	u32 valo = nv_rd32(fifo, 0x002804 + (unit * 0x10));
-	u32 vahi = nv_rd32(fifo, 0x002808 + (unit * 0x10));
-	u32 stat = nv_rd32(fifo, 0x00280c + (unit * 0x10));
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
+	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
+	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
+	u32 stat = nvkm_rd32(device, 0x00280c + (unit * 0x10));
 	u32 gpc    = (stat & 0x1f000000) >> 24;
 	u32 client = (stat & 0x00001f00) >> 8;
 	u32 write  = (stat & 0x00000080);
@@ -747,13 +759,13 @@ gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 	if (eu) {
 		switch (eu->data2) {
 		case NVDEV_SUBDEV_BAR:
-			nv_mask(fifo, 0x001704, 0x00000000, 0x00000000);
+			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_SUBDEV_INSTMEM:
-			nv_mask(fifo, 0x001714, 0x00000000, 0x00000000);
+			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_ENGINE_IFB:
-			nv_mask(fifo, 0x001718, 0x00000000, 0x00000000);
+			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:
 			engine = nvkm_engine(fifo, eu->data2);
@@ -833,11 +845,12 @@ static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {
 static void
 gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 {
-	u32 mask = nv_rd32(fifo, 0x04010c + (unit * 0x2000));
-	u32 stat = nv_rd32(fifo, 0x040108 + (unit * 0x2000)) & mask;
-	u32 addr = nv_rd32(fifo, 0x0400c0 + (unit * 0x2000));
-	u32 data = nv_rd32(fifo, 0x0400c4 + (unit * 0x2000));
-	u32 chid = nv_rd32(fifo, 0x040120 + (unit * 0x2000)) & 0xfff;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 mask = nvkm_rd32(device, 0x04010c + (unit * 0x2000));
+	u32 stat = nvkm_rd32(device, 0x040108 + (unit * 0x2000)) & mask;
+	u32 addr = nvkm_rd32(device, 0x0400c0 + (unit * 0x2000));
+	u32 data = nvkm_rd32(device, 0x0400c4 + (unit * 0x2000));
+	u32 chid = nvkm_rd32(device, 0x040120 + (unit * 0x2000)) & 0xfff;
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
 	u32 show = stat;
@@ -845,7 +858,7 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 	if (stat & 0x00800000) {
 		if (!gk104_fifo_swmthd(fifo, chid, mthd, data))
 			show &= ~0x00800000;
-		nv_wr32(fifo, 0x0400c0 + (unit * 0x2000), 0x80600008);
+		nvkm_wr32(device, 0x0400c0 + (unit * 0x2000), 0x80600008);
 	}
 
 	if (show) {
@@ -859,7 +872,7 @@ gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 			 subc, mthd, data);
 	}
 
-	nv_wr32(fifo, 0x040108 + (unit * 0x2000), stat);
+	nvkm_wr32(device, 0x040108 + (unit * 0x2000), stat);
 }
 
 static const struct nvkm_bitfield gk104_fifo_pbdma_intr_1[] = {
@@ -874,30 +887,32 @@ static const struct nvkm_bitfield gk104_fifo_pbdma_intr_1[] = {
 static void
 gk104_fifo_intr_pbdma_1(struct gk104_fifo *fifo, int unit)
 {
-	u32 mask = nv_rd32(fifo, 0x04014c + (unit * 0x2000));
-	u32 stat = nv_rd32(fifo, 0x040148 + (unit * 0x2000)) & mask;
-	u32 chid = nv_rd32(fifo, 0x040120 + (unit * 0x2000)) & 0xfff;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 mask = nvkm_rd32(device, 0x04014c + (unit * 0x2000));
+	u32 stat = nvkm_rd32(device, 0x040148 + (unit * 0x2000)) & mask;
+	u32 chid = nvkm_rd32(device, 0x040120 + (unit * 0x2000)) & 0xfff;
 
 	if (stat) {
 		nv_error(fifo, "PBDMA%d:", unit);
 		nvkm_bitfield_print(gk104_fifo_pbdma_intr_1, stat);
 		pr_cont("\n");
 		nv_error(fifo, "PBDMA%d: ch %d %08x %08x\n", unit, chid,
-			 nv_rd32(fifo, 0x040150 + (unit * 0x2000)),
-			 nv_rd32(fifo, 0x040154 + (unit * 0x2000)));
+			 nvkm_rd32(device, 0x040150 + (unit * 0x2000)),
+			 nvkm_rd32(device, 0x040154 + (unit * 0x2000)));
 	}
 
-	nv_wr32(fifo, 0x040148 + (unit * 0x2000), stat);
+	nvkm_wr32(device, 0x040148 + (unit * 0x2000), stat);
 }
 
 static void
 gk104_fifo_intr_runlist(struct gk104_fifo *fifo)
 {
-	u32 mask = nv_rd32(fifo, 0x002a00);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 mask = nvkm_rd32(device, 0x002a00);
 	while (mask) {
 		u32 engn = __ffs(mask);
 		wake_up(&fifo->engine[engn].wait);
-		nv_wr32(fifo, 0x002a00, 1 << engn);
+		nvkm_wr32(device, 0x002a00, 1 << engn);
 		mask &= ~(1 << engn);
 	}
 }
@@ -912,69 +927,70 @@ static void
 gk104_fifo_intr(struct nvkm_subdev *subdev)
 {
 	struct gk104_fifo *fifo = (void *)subdev;
-	u32 mask = nv_rd32(fifo, 0x002140);
-	u32 stat = nv_rd32(fifo, 0x002100) & mask;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 mask = nvkm_rd32(device, 0x002140);
+	u32 stat = nvkm_rd32(device, 0x002100) & mask;
 
 	if (stat & 0x00000001) {
 		gk104_fifo_intr_bind(fifo);
-		nv_wr32(fifo, 0x002100, 0x00000001);
+		nvkm_wr32(device, 0x002100, 0x00000001);
 		stat &= ~0x00000001;
 	}
 
 	if (stat & 0x00000010) {
 		nv_error(fifo, "PIO_ERROR\n");
-		nv_wr32(fifo, 0x002100, 0x00000010);
+		nvkm_wr32(device, 0x002100, 0x00000010);
 		stat &= ~0x00000010;
 	}
 
 	if (stat & 0x00000100) {
 		gk104_fifo_intr_sched(fifo);
-		nv_wr32(fifo, 0x002100, 0x00000100);
+		nvkm_wr32(device, 0x002100, 0x00000100);
 		stat &= ~0x00000100;
 	}
 
 	if (stat & 0x00010000) {
 		gk104_fifo_intr_chsw(fifo);
-		nv_wr32(fifo, 0x002100, 0x00010000);
+		nvkm_wr32(device, 0x002100, 0x00010000);
 		stat &= ~0x00010000;
 	}
 
 	if (stat & 0x00800000) {
 		nv_error(fifo, "FB_FLUSH_TIMEOUT\n");
-		nv_wr32(fifo, 0x002100, 0x00800000);
+		nvkm_wr32(device, 0x002100, 0x00800000);
 		stat &= ~0x00800000;
 	}
 
 	if (stat & 0x01000000) {
 		nv_error(fifo, "LB_ERROR\n");
-		nv_wr32(fifo, 0x002100, 0x01000000);
+		nvkm_wr32(device, 0x002100, 0x01000000);
 		stat &= ~0x01000000;
 	}
 
 	if (stat & 0x08000000) {
 		gk104_fifo_intr_dropped_fault(fifo);
-		nv_wr32(fifo, 0x002100, 0x08000000);
+		nvkm_wr32(device, 0x002100, 0x08000000);
 		stat &= ~0x08000000;
 	}
 
 	if (stat & 0x10000000) {
-		u32 mask = nv_rd32(fifo, 0x00259c);
+		u32 mask = nvkm_rd32(device, 0x00259c);
 		while (mask) {
 			u32 unit = __ffs(mask);
 			gk104_fifo_intr_fault(fifo, unit);
-			nv_wr32(fifo, 0x00259c, (1 << unit));
+			nvkm_wr32(device, 0x00259c, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x10000000;
 	}
 
 	if (stat & 0x20000000) {
-		u32 mask = nv_rd32(fifo, 0x0025a0);
+		u32 mask = nvkm_rd32(device, 0x0025a0);
 		while (mask) {
 			u32 unit = __ffs(mask);
 			gk104_fifo_intr_pbdma_0(fifo, unit);
 			gk104_fifo_intr_pbdma_1(fifo, unit);
-			nv_wr32(fifo, 0x0025a0, (1 << unit));
+			nvkm_wr32(device, 0x0025a0, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x20000000;
@@ -986,15 +1002,15 @@ gk104_fifo_intr(struct nvkm_subdev *subdev)
 	}
 
 	if (stat & 0x80000000) {
-		nv_wr32(fifo, 0x002100, 0x80000000);
+		nvkm_wr32(device, 0x002100, 0x80000000);
 		gk104_fifo_intr_engine(fifo);
 		stat &= ~0x80000000;
 	}
 
 	if (stat) {
 		nv_error(fifo, "INTR 0x%08x\n", stat);
-		nv_mask(fifo, 0x002140, stat, 0x00000000);
-		nv_wr32(fifo, 0x002100, stat);
+		nvkm_mask(device, 0x002140, stat, 0x00000000);
+		nvkm_wr32(device, 0x002100, stat);
 	}
 }
 
@@ -1002,14 +1018,16 @@ static void
 gk104_fifo_uevent_init(struct nvkm_event *event, int type, int index)
 {
 	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	nv_mask(fifo, 0x002140, 0x80000000, 0x80000000);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
 }
 
 static void
 gk104_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
 {
 	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	nv_mask(fifo, 0x002140, 0x80000000, 0x00000000);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
 }
 
 static const struct nvkm_event_func
@@ -1023,6 +1041,7 @@ int
 gk104_fifo_fini(struct nvkm_object *object, bool suspend)
 {
 	struct gk104_fifo *fifo = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	int ret;
 
 	ret = nvkm_fifo_fini(&fifo->base, suspend);
@@ -1030,7 +1049,7 @@ gk104_fifo_fini(struct nvkm_object *object, bool suspend)
 		return ret;
 
 	/* allow mmu fault interrupts, even when we're not using fifo */
-	nv_mask(fifo, 0x002140, 0x10000000, 0x10000000);
+	nvkm_mask(device, 0x002140, 0x10000000, 0x10000000);
 	return 0;
 }
 
@@ -1038,6 +1057,7 @@ int
 gk104_fifo_init(struct nvkm_object *object)
 {
 	struct gk104_fifo *fifo = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	int ret, i;
 
 	ret = nvkm_fifo_init(&fifo->base);
@@ -1045,27 +1065,27 @@ gk104_fifo_init(struct nvkm_object *object)
 		return ret;
 
 	/* enable all available PBDMA units */
-	nv_wr32(fifo, 0x000204, 0xffffffff);
-	fifo->spoon_nr = hweight32(nv_rd32(fifo, 0x000204));
+	nvkm_wr32(device, 0x000204, 0xffffffff);
+	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x000204));
 	nv_debug(fifo, "%d PBDMA unit(s)\n", fifo->spoon_nr);
 
 	/* PBDMA[n] */
 	for (i = 0; i < fifo->spoon_nr; i++) {
-		nv_mask(fifo, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
-		nv_wr32(fifo, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
-		nv_wr32(fifo, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+		nvkm_mask(device, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+		nvkm_wr32(device, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+		nvkm_wr32(device, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
 	}
 
 	/* PBDMA[n].HCE */
 	for (i = 0; i < fifo->spoon_nr; i++) {
-		nv_wr32(fifo, 0x040148 + (i * 0x2000), 0xffffffff); /* INTR */
-		nv_wr32(fifo, 0x04014c + (i * 0x2000), 0xffffffff); /* INTREN */
+		nvkm_wr32(device, 0x040148 + (i * 0x2000), 0xffffffff); /* INTR */
+		nvkm_wr32(device, 0x04014c + (i * 0x2000), 0xffffffff); /* INTREN */
 	}
 
-	nv_wr32(fifo, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
+	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
 
-	nv_wr32(fifo, 0x002100, 0xffffffff);
-	nv_wr32(fifo, 0x002140, 0x7fffffff);
+	nvkm_wr32(device, 0x002100, 0xffffffff);
+	nvkm_wr32(device, 0x002140, 0x7fffffff);
 	return 0;
 }
 

commit 6189f1b0938dc0621c27494031b83ffae566e318
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:07 2015 +1000

    drm/nouveau/fifo: cosmetic changes
    
    This is purely preparation for upcoming commits, there should be no
    code changes here.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index e10f9644140f..ed8d3820a044 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -58,7 +58,7 @@ struct gk104_fifo_engn {
 	wait_queue_head_t wait;
 };
 
-struct gk104_fifo_priv {
+struct gk104_fifo {
 	struct nvkm_fifo base;
 
 	struct work_struct fault;
@@ -93,19 +93,19 @@ struct gk104_fifo_chan {
  ******************************************************************************/
 
 static void
-gk104_fifo_runlist_update(struct gk104_fifo_priv *priv, u32 engine)
+gk104_fifo_runlist_update(struct gk104_fifo *fifo, u32 engine)
 {
-	struct nvkm_bar *bar = nvkm_bar(priv);
-	struct gk104_fifo_engn *engn = &priv->engine[engine];
+	struct nvkm_bar *bar = nvkm_bar(fifo);
+	struct gk104_fifo_engn *engn = &fifo->engine[engine];
 	struct nvkm_gpuobj *cur;
 	int i, p;
 
-	mutex_lock(&nv_subdev(priv)->mutex);
+	mutex_lock(&nv_subdev(fifo)->mutex);
 	cur = engn->runlist[engn->cur_runlist];
 	engn->cur_runlist = !engn->cur_runlist;
 
-	for (i = 0, p = 0; i < priv->base.max; i++) {
-		struct gk104_fifo_chan *chan = (void *)priv->base.channel[i];
+	for (i = 0, p = 0; i < fifo->base.max; i++) {
+		struct gk104_fifo_chan *chan = (void *)fifo->base.channel[i];
 		if (chan && chan->state == RUNNING && chan->engine == engine) {
 			nv_wo32(cur, p + 0, i);
 			nv_wo32(cur, p + 4, 0x00000000);
@@ -114,14 +114,14 @@ gk104_fifo_runlist_update(struct gk104_fifo_priv *priv, u32 engine)
 	}
 	bar->flush(bar);
 
-	nv_wr32(priv, 0x002270, cur->addr >> 12);
-	nv_wr32(priv, 0x002274, (engine << 20) | (p >> 3));
+	nv_wr32(fifo, 0x002270, cur->addr >> 12);
+	nv_wr32(fifo, 0x002274, (engine << 20) | (p >> 3));
 
-	if (wait_event_timeout(engn->wait, !(nv_rd32(priv, 0x002284 +
+	if (wait_event_timeout(engn->wait, !(nv_rd32(fifo, 0x002284 +
 			       (engine * 0x08)) & 0x00100000),
 				msecs_to_jiffies(2000)) == 0)
-		nv_error(priv, "runlist %d update timeout\n", engine);
-	mutex_unlock(&nv_subdev(priv)->mutex);
+		nv_error(fifo, "runlist %d update timeout\n", engine);
+	mutex_unlock(&nv_subdev(fifo)->mutex);
 }
 
 static int
@@ -165,15 +165,31 @@ gk104_fifo_context_attach(struct nvkm_object *parent,
 	return 0;
 }
 
+static int
+gk104_fifo_chan_kick(struct gk104_fifo_chan *chan)
+{
+	struct nvkm_object *obj = (void *)chan;
+	struct gk104_fifo *fifo = (void *)obj->engine;
+
+	nv_wr32(fifo, 0x002634, chan->base.chid);
+	if (!nv_wait(fifo, 0x002634, 0x100000, 0x000000)) {
+		nv_error(fifo, "channel %d [%s] kick timeout\n",
+			 chan->base.chid, nvkm_client_name(chan));
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
 static int
 gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 			  struct nvkm_object *object)
 {
 	struct nvkm_bar *bar = nvkm_bar(parent);
-	struct gk104_fifo_priv *priv = (void *)parent->engine;
 	struct gk104_fifo_base *base = (void *)parent->parent;
 	struct gk104_fifo_chan *chan = (void *)parent;
 	u32 addr;
+	int ret;
 
 	switch (nv_engidx(object->engine)) {
 	case NVDEV_ENGINE_SW    : return 0;
@@ -188,13 +204,9 @@ gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 		return -EINVAL;
 	}
 
-	nv_wr32(priv, 0x002634, chan->base.chid);
-	if (!nv_wait(priv, 0x002634, 0xffffffff, chan->base.chid)) {
-		nv_error(priv, "channel %d [%s] kick timeout\n",
-			 chan->base.chid, nvkm_client_name(chan));
-		if (suspend)
-			return -EBUSY;
-	}
+	ret = gk104_fifo_chan_kick(chan);
+	if (ret && suspend)
+		return ret;
 
 	if (addr) {
 		nv_wo32(base, addr + 0x00, 0x00000000);
@@ -214,7 +226,7 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct kepler_channel_gpfifo_a_v0 v0;
 	} *args = data;
 	struct nvkm_bar *bar = nvkm_bar(parent);
-	struct gk104_fifo_priv *priv = (void *)engine;
+	struct gk104_fifo *fifo = (void *)engine;
 	struct gk104_fifo_base *base = (void *)parent;
 	struct gk104_fifo_chan *chan;
 	u64 usermem, ioffset, ilength;
@@ -239,12 +251,12 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	}
 
 	if (i == FIFO_ENGINE_NR) {
-		nv_error(priv, "unsupported engines 0x%08x\n", args->v0.engine);
+		nv_error(fifo, "unsupported engines 0x%08x\n", args->v0.engine);
 		return -ENODEV;
 	}
 
 	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
-				       priv->user.bar.offset, 0x200,
+				       fifo->user.bar.offset, 0x200,
 				       args->v0.pushbuf,
 				       fifo_engine[i].mask, &chan);
 	*pobject = nv_object(chan);
@@ -262,10 +274,10 @@ gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	ilength = order_base_2(args->v0.ilength / 8);
 
 	for (i = 0; i < 0x200; i += 4)
-		nv_wo32(priv->user.mem, usermem + i, 0x00000000);
+		nv_wo32(fifo->user.mem, usermem + i, 0x00000000);
 
-	nv_wo32(base, 0x08, lower_32_bits(priv->user.mem->addr + usermem));
-	nv_wo32(base, 0x0c, upper_32_bits(priv->user.mem->addr + usermem));
+	nv_wo32(base, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
+	nv_wo32(base, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
 	nv_wo32(base, 0x10, 0x0000face);
 	nv_wo32(base, 0x30, 0xfffff902);
 	nv_wo32(base, 0x48, lower_32_bits(ioffset));
@@ -286,7 +298,7 @@ static int
 gk104_fifo_chan_init(struct nvkm_object *object)
 {
 	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
-	struct gk104_fifo_priv *priv = (void *)object->engine;
+	struct gk104_fifo *fifo = (void *)object->engine;
 	struct gk104_fifo_chan *chan = (void *)object;
 	u32 chid = chan->base.chid;
 	int ret;
@@ -295,13 +307,13 @@ gk104_fifo_chan_init(struct nvkm_object *object)
 	if (ret)
 		return ret;
 
-	nv_mask(priv, 0x800004 + (chid * 8), 0x000f0000, chan->engine << 16);
-	nv_wr32(priv, 0x800000 + (chid * 8), 0x80000000 | base->addr >> 12);
+	nv_mask(fifo, 0x800004 + (chid * 8), 0x000f0000, chan->engine << 16);
+	nv_wr32(fifo, 0x800000 + (chid * 8), 0x80000000 | base->addr >> 12);
 
 	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
-		nv_mask(priv, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
-		gk104_fifo_runlist_update(priv, chan->engine);
-		nv_mask(priv, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
+		nv_mask(fifo, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
+		gk104_fifo_runlist_update(fifo, chan->engine);
+		nv_mask(fifo, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
 	}
 
 	return 0;
@@ -310,16 +322,16 @@ gk104_fifo_chan_init(struct nvkm_object *object)
 static int
 gk104_fifo_chan_fini(struct nvkm_object *object, bool suspend)
 {
-	struct gk104_fifo_priv *priv = (void *)object->engine;
+	struct gk104_fifo *fifo = (void *)object->engine;
 	struct gk104_fifo_chan *chan = (void *)object;
 	u32 chid = chan->base.chid;
 
 	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
-		nv_mask(priv, 0x800004 + (chid * 8), 0x00000800, 0x00000800);
-		gk104_fifo_runlist_update(priv, chan->engine);
+		nv_mask(fifo, 0x800004 + (chid * 8), 0x00000800, 0x00000800);
+		gk104_fifo_runlist_update(fifo, chan->engine);
 	}
 
-	nv_wr32(priv, 0x800000 + (chid * 8), 0x00000000);
+	nv_wr32(fifo, 0x800000 + (chid * 8), 0x00000000);
 	return nvkm_fifo_channel_fini(&chan->base, suspend);
 }
 
@@ -403,7 +415,7 @@ gk104_fifo_cclass = {
  ******************************************************************************/
 
 static inline int
-gk104_fifo_engidx(struct gk104_fifo_priv *priv, u32 engn)
+gk104_fifo_engidx(struct gk104_fifo *fifo, u32 engn)
 {
 	switch (engn) {
 	case NVDEV_ENGINE_GR    :
@@ -422,73 +434,73 @@ gk104_fifo_engidx(struct gk104_fifo_priv *priv, u32 engn)
 }
 
 static inline struct nvkm_engine *
-gk104_fifo_engine(struct gk104_fifo_priv *priv, u32 engn)
+gk104_fifo_engine(struct gk104_fifo *fifo, u32 engn)
 {
 	if (engn >= ARRAY_SIZE(fifo_engine))
 		return NULL;
-	return nvkm_engine(priv, fifo_engine[engn].subdev);
+	return nvkm_engine(fifo, fifo_engine[engn].subdev);
 }
 
 static void
 gk104_fifo_recover_work(struct work_struct *work)
 {
-	struct gk104_fifo_priv *priv = container_of(work, typeof(*priv), fault);
+	struct gk104_fifo *fifo = container_of(work, typeof(*fifo), fault);
 	struct nvkm_object *engine;
 	unsigned long flags;
 	u32 engn, engm = 0;
 	u64 mask, todo;
 
-	spin_lock_irqsave(&priv->base.lock, flags);
-	mask = priv->mask;
-	priv->mask = 0ULL;
-	spin_unlock_irqrestore(&priv->base.lock, flags);
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	mask = fifo->mask;
+	fifo->mask = 0ULL;
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
-		engm |= 1 << gk104_fifo_engidx(priv, engn);
-	nv_mask(priv, 0x002630, engm, engm);
+		engm |= 1 << gk104_fifo_engidx(fifo, engn);
+	nv_mask(fifo, 0x002630, engm, engm);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
-		if ((engine = (void *)nvkm_engine(priv, engn))) {
+		if ((engine = (void *)nvkm_engine(fifo, engn))) {
 			nv_ofuncs(engine)->fini(engine, false);
 			WARN_ON(nv_ofuncs(engine)->init(engine));
 		}
-		gk104_fifo_runlist_update(priv, gk104_fifo_engidx(priv, engn));
+		gk104_fifo_runlist_update(fifo, gk104_fifo_engidx(fifo, engn));
 	}
 
-	nv_wr32(priv, 0x00262c, engm);
-	nv_mask(priv, 0x002630, engm, 0x00000000);
+	nv_wr32(fifo, 0x00262c, engm);
+	nv_mask(fifo, 0x002630, engm, 0x00000000);
 }
 
 static void
-gk104_fifo_recover(struct gk104_fifo_priv *priv, struct nvkm_engine *engine,
+gk104_fifo_recover(struct gk104_fifo *fifo, struct nvkm_engine *engine,
 		  struct gk104_fifo_chan *chan)
 {
 	u32 chid = chan->base.chid;
 	unsigned long flags;
 
-	nv_error(priv, "%s engine fault on channel %d, recovering...\n",
+	nv_error(fifo, "%s engine fault on channel %d, recovering...\n",
 		       nv_subdev(engine)->name, chid);
 
-	nv_mask(priv, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
+	nv_mask(fifo, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
 	chan->state = KILLED;
 
-	spin_lock_irqsave(&priv->base.lock, flags);
-	priv->mask |= 1ULL << nv_engidx(engine);
-	spin_unlock_irqrestore(&priv->base.lock, flags);
-	schedule_work(&priv->fault);
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	fifo->mask |= 1ULL << nv_engidx(engine);
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
+	schedule_work(&fifo->fault);
 }
 
 static int
-gk104_fifo_swmthd(struct gk104_fifo_priv *priv, u32 chid, u32 mthd, u32 data)
+gk104_fifo_swmthd(struct gk104_fifo *fifo, u32 chid, u32 mthd, u32 data)
 {
 	struct gk104_fifo_chan *chan = NULL;
 	struct nvkm_handle *bind;
 	unsigned long flags;
 	int ret = -EINVAL;
 
-	spin_lock_irqsave(&priv->base.lock, flags);
-	if (likely(chid >= priv->base.min && chid <= priv->base.max))
-		chan = (void *)priv->base.channel[chid];
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	if (likely(chid >= fifo->base.min && chid <= fifo->base.max))
+		chan = (void *)fifo->base.channel[chid];
 	if (unlikely(!chan))
 		goto out;
 
@@ -500,7 +512,7 @@ gk104_fifo_swmthd(struct gk104_fifo_priv *priv, u32 chid, u32 mthd, u32 data)
 	}
 
 out:
-	spin_unlock_irqrestore(&priv->base.lock, flags);
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
 	return ret;
 }
 
@@ -516,9 +528,9 @@ gk104_fifo_bind_reason[] = {
 };
 
 static void
-gk104_fifo_intr_bind(struct gk104_fifo_priv *priv)
+gk104_fifo_intr_bind(struct gk104_fifo *fifo)
 {
-	u32 intr = nv_rd32(priv, 0x00252c);
+	u32 intr = nv_rd32(fifo, 0x00252c);
 	u32 code = intr & 0x000000ff;
 	const struct nvkm_enum *en;
 	char enunk[6] = "";
@@ -527,7 +539,7 @@ gk104_fifo_intr_bind(struct gk104_fifo_priv *priv)
 	if (!en)
 		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
 
-	nv_error(priv, "BIND_ERROR [ %s ]\n", en ? en->name : enunk);
+	nv_error(fifo, "BIND_ERROR [ %s ]\n", en ? en->name : enunk);
 }
 
 static const struct nvkm_enum
@@ -537,14 +549,14 @@ gk104_fifo_sched_reason[] = {
 };
 
 static void
-gk104_fifo_intr_sched_ctxsw(struct gk104_fifo_priv *priv)
+gk104_fifo_intr_sched_ctxsw(struct gk104_fifo *fifo)
 {
 	struct nvkm_engine *engine;
 	struct gk104_fifo_chan *chan;
 	u32 engn;
 
 	for (engn = 0; engn < ARRAY_SIZE(fifo_engine); engn++) {
-		u32 stat = nv_rd32(priv, 0x002640 + (engn * 0x04));
+		u32 stat = nv_rd32(fifo, 0x002640 + (engn * 0x04));
 		u32 busy = (stat & 0x80000000);
 		u32 next = (stat & 0x07ff0000) >> 16;
 		u32 chsw = (stat & 0x00008000);
@@ -555,19 +567,19 @@ gk104_fifo_intr_sched_ctxsw(struct gk104_fifo_priv *priv)
 		(void)save;
 
 		if (busy && chsw) {
-			if (!(chan = (void *)priv->base.channel[chid]))
+			if (!(chan = (void *)fifo->base.channel[chid]))
 				continue;
-			if (!(engine = gk104_fifo_engine(priv, engn)))
+			if (!(engine = gk104_fifo_engine(fifo, engn)))
 				continue;
-			gk104_fifo_recover(priv, engine, chan);
+			gk104_fifo_recover(fifo, engine, chan);
 		}
 	}
 }
 
 static void
-gk104_fifo_intr_sched(struct gk104_fifo_priv *priv)
+gk104_fifo_intr_sched(struct gk104_fifo *fifo)
 {
-	u32 intr = nv_rd32(priv, 0x00254c);
+	u32 intr = nv_rd32(fifo, 0x00254c);
 	u32 code = intr & 0x000000ff;
 	const struct nvkm_enum *en;
 	char enunk[6] = "";
@@ -576,11 +588,11 @@ gk104_fifo_intr_sched(struct gk104_fifo_priv *priv)
 	if (!en)
 		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
 
-	nv_error(priv, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
+	nv_error(fifo, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
 
 	switch (code) {
 	case 0x0a:
-		gk104_fifo_intr_sched_ctxsw(priv);
+		gk104_fifo_intr_sched_ctxsw(fifo);
 		break;
 	default:
 		break;
@@ -588,18 +600,18 @@ gk104_fifo_intr_sched(struct gk104_fifo_priv *priv)
 }
 
 static void
-gk104_fifo_intr_chsw(struct gk104_fifo_priv *priv)
+gk104_fifo_intr_chsw(struct gk104_fifo *fifo)
 {
-	u32 stat = nv_rd32(priv, 0x00256c);
-	nv_error(priv, "CHSW_ERROR 0x%08x\n", stat);
-	nv_wr32(priv, 0x00256c, stat);
+	u32 stat = nv_rd32(fifo, 0x00256c);
+	nv_error(fifo, "CHSW_ERROR 0x%08x\n", stat);
+	nv_wr32(fifo, 0x00256c, stat);
 }
 
 static void
-gk104_fifo_intr_dropped_fault(struct gk104_fifo_priv *priv)
+gk104_fifo_intr_dropped_fault(struct gk104_fifo *fifo)
 {
-	u32 stat = nv_rd32(priv, 0x00259c);
-	nv_error(priv, "DROPPED_MMU_FAULT 0x%08x\n", stat);
+	u32 stat = nv_rd32(fifo, 0x00259c);
+	nv_error(fifo, "DROPPED_MMU_FAULT 0x%08x\n", stat);
 }
 
 static const struct nvkm_enum
@@ -708,12 +720,12 @@ gk104_fifo_fault_gpcclient[] = {
 };
 
 static void
-gk104_fifo_intr_fault(struct gk104_fifo_priv *priv, int unit)
+gk104_fifo_intr_fault(struct gk104_fifo *fifo, int unit)
 {
-	u32 inst = nv_rd32(priv, 0x002800 + (unit * 0x10));
-	u32 valo = nv_rd32(priv, 0x002804 + (unit * 0x10));
-	u32 vahi = nv_rd32(priv, 0x002808 + (unit * 0x10));
-	u32 stat = nv_rd32(priv, 0x00280c + (unit * 0x10));
+	u32 inst = nv_rd32(fifo, 0x002800 + (unit * 0x10));
+	u32 valo = nv_rd32(fifo, 0x002804 + (unit * 0x10));
+	u32 vahi = nv_rd32(fifo, 0x002808 + (unit * 0x10));
+	u32 stat = nv_rd32(fifo, 0x00280c + (unit * 0x10));
 	u32 gpc    = (stat & 0x1f000000) >> 24;
 	u32 client = (stat & 0x00001f00) >> 8;
 	u32 write  = (stat & 0x00000080);
@@ -735,16 +747,16 @@ gk104_fifo_intr_fault(struct gk104_fifo_priv *priv, int unit)
 	if (eu) {
 		switch (eu->data2) {
 		case NVDEV_SUBDEV_BAR:
-			nv_mask(priv, 0x001704, 0x00000000, 0x00000000);
+			nv_mask(fifo, 0x001704, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_SUBDEV_INSTMEM:
-			nv_mask(priv, 0x001714, 0x00000000, 0x00000000);
+			nv_mask(fifo, 0x001714, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_ENGINE_IFB:
-			nv_mask(priv, 0x001718, 0x00000000, 0x00000000);
+			nv_mask(fifo, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:
-			engine = nvkm_engine(priv, eu->data2);
+			engine = nvkm_engine(fifo, eu->data2);
 			if (engine)
 				engctx = nvkm_engctx_get(engine, inst);
 			break;
@@ -763,7 +775,7 @@ gk104_fifo_intr_fault(struct gk104_fifo_priv *priv, int unit)
 	if (!ec)
 		snprintf(ecunk, sizeof(ecunk), "UNK%02x", client);
 
-	nv_error(priv, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
+	nv_error(fifo, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
 		       "channel 0x%010llx [%s]\n", write ? "write" : "read",
 		 (u64)vahi << 32 | valo, er ? er->name : erunk,
 		 eu ? eu->name : euunk, hub ? "" : "GPC", gpcid, hub ? "" : "/",
@@ -775,7 +787,7 @@ gk104_fifo_intr_fault(struct gk104_fifo_priv *priv, int unit)
 		switch (nv_mclass(object)) {
 		case KEPLER_CHANNEL_GPFIFO_A:
 		case MAXWELL_CHANNEL_GPFIFO_A:
-			gk104_fifo_recover(priv, engine, (void *)object);
+			gk104_fifo_recover(fifo, engine, (void *)object);
 			break;
 		}
 		object = object->parent;
@@ -819,35 +831,35 @@ static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {
 };
 
 static void
-gk104_fifo_intr_pbdma_0(struct gk104_fifo_priv *priv, int unit)
+gk104_fifo_intr_pbdma_0(struct gk104_fifo *fifo, int unit)
 {
-	u32 mask = nv_rd32(priv, 0x04010c + (unit * 0x2000));
-	u32 stat = nv_rd32(priv, 0x040108 + (unit * 0x2000)) & mask;
-	u32 addr = nv_rd32(priv, 0x0400c0 + (unit * 0x2000));
-	u32 data = nv_rd32(priv, 0x0400c4 + (unit * 0x2000));
-	u32 chid = nv_rd32(priv, 0x040120 + (unit * 0x2000)) & 0xfff;
+	u32 mask = nv_rd32(fifo, 0x04010c + (unit * 0x2000));
+	u32 stat = nv_rd32(fifo, 0x040108 + (unit * 0x2000)) & mask;
+	u32 addr = nv_rd32(fifo, 0x0400c0 + (unit * 0x2000));
+	u32 data = nv_rd32(fifo, 0x0400c4 + (unit * 0x2000));
+	u32 chid = nv_rd32(fifo, 0x040120 + (unit * 0x2000)) & 0xfff;
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
 	u32 show = stat;
 
 	if (stat & 0x00800000) {
-		if (!gk104_fifo_swmthd(priv, chid, mthd, data))
+		if (!gk104_fifo_swmthd(fifo, chid, mthd, data))
 			show &= ~0x00800000;
-		nv_wr32(priv, 0x0400c0 + (unit * 0x2000), 0x80600008);
+		nv_wr32(fifo, 0x0400c0 + (unit * 0x2000), 0x80600008);
 	}
 
 	if (show) {
-		nv_error(priv, "PBDMA%d:", unit);
+		nv_error(fifo, "PBDMA%d:", unit);
 		nvkm_bitfield_print(gk104_fifo_pbdma_intr_0, show);
 		pr_cont("\n");
-		nv_error(priv,
+		nv_error(fifo,
 			 "PBDMA%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
 			 unit, chid,
-			 nvkm_client_name_for_fifo_chid(&priv->base, chid),
+			 nvkm_client_name_for_fifo_chid(&fifo->base, chid),
 			 subc, mthd, data);
 	}
 
-	nv_wr32(priv, 0x040108 + (unit * 0x2000), stat);
+	nv_wr32(fifo, 0x040108 + (unit * 0x2000), stat);
 }
 
 static const struct nvkm_bitfield gk104_fifo_pbdma_intr_1[] = {
@@ -860,129 +872,129 @@ static const struct nvkm_bitfield gk104_fifo_pbdma_intr_1[] = {
 };
 
 static void
-gk104_fifo_intr_pbdma_1(struct gk104_fifo_priv *priv, int unit)
+gk104_fifo_intr_pbdma_1(struct gk104_fifo *fifo, int unit)
 {
-	u32 mask = nv_rd32(priv, 0x04014c + (unit * 0x2000));
-	u32 stat = nv_rd32(priv, 0x040148 + (unit * 0x2000)) & mask;
-	u32 chid = nv_rd32(priv, 0x040120 + (unit * 0x2000)) & 0xfff;
+	u32 mask = nv_rd32(fifo, 0x04014c + (unit * 0x2000));
+	u32 stat = nv_rd32(fifo, 0x040148 + (unit * 0x2000)) & mask;
+	u32 chid = nv_rd32(fifo, 0x040120 + (unit * 0x2000)) & 0xfff;
 
 	if (stat) {
-		nv_error(priv, "PBDMA%d:", unit);
+		nv_error(fifo, "PBDMA%d:", unit);
 		nvkm_bitfield_print(gk104_fifo_pbdma_intr_1, stat);
 		pr_cont("\n");
-		nv_error(priv, "PBDMA%d: ch %d %08x %08x\n", unit, chid,
-			 nv_rd32(priv, 0x040150 + (unit * 0x2000)),
-			 nv_rd32(priv, 0x040154 + (unit * 0x2000)));
+		nv_error(fifo, "PBDMA%d: ch %d %08x %08x\n", unit, chid,
+			 nv_rd32(fifo, 0x040150 + (unit * 0x2000)),
+			 nv_rd32(fifo, 0x040154 + (unit * 0x2000)));
 	}
 
-	nv_wr32(priv, 0x040148 + (unit * 0x2000), stat);
+	nv_wr32(fifo, 0x040148 + (unit * 0x2000), stat);
 }
 
 static void
-gk104_fifo_intr_runlist(struct gk104_fifo_priv *priv)
+gk104_fifo_intr_runlist(struct gk104_fifo *fifo)
 {
-	u32 mask = nv_rd32(priv, 0x002a00);
+	u32 mask = nv_rd32(fifo, 0x002a00);
 	while (mask) {
 		u32 engn = __ffs(mask);
-		wake_up(&priv->engine[engn].wait);
-		nv_wr32(priv, 0x002a00, 1 << engn);
+		wake_up(&fifo->engine[engn].wait);
+		nv_wr32(fifo, 0x002a00, 1 << engn);
 		mask &= ~(1 << engn);
 	}
 }
 
 static void
-gk104_fifo_intr_engine(struct gk104_fifo_priv *priv)
+gk104_fifo_intr_engine(struct gk104_fifo *fifo)
 {
-	nvkm_fifo_uevent(&priv->base);
+	nvkm_fifo_uevent(&fifo->base);
 }
 
 static void
 gk104_fifo_intr(struct nvkm_subdev *subdev)
 {
-	struct gk104_fifo_priv *priv = (void *)subdev;
-	u32 mask = nv_rd32(priv, 0x002140);
-	u32 stat = nv_rd32(priv, 0x002100) & mask;
+	struct gk104_fifo *fifo = (void *)subdev;
+	u32 mask = nv_rd32(fifo, 0x002140);
+	u32 stat = nv_rd32(fifo, 0x002100) & mask;
 
 	if (stat & 0x00000001) {
-		gk104_fifo_intr_bind(priv);
-		nv_wr32(priv, 0x002100, 0x00000001);
+		gk104_fifo_intr_bind(fifo);
+		nv_wr32(fifo, 0x002100, 0x00000001);
 		stat &= ~0x00000001;
 	}
 
 	if (stat & 0x00000010) {
-		nv_error(priv, "PIO_ERROR\n");
-		nv_wr32(priv, 0x002100, 0x00000010);
+		nv_error(fifo, "PIO_ERROR\n");
+		nv_wr32(fifo, 0x002100, 0x00000010);
 		stat &= ~0x00000010;
 	}
 
 	if (stat & 0x00000100) {
-		gk104_fifo_intr_sched(priv);
-		nv_wr32(priv, 0x002100, 0x00000100);
+		gk104_fifo_intr_sched(fifo);
+		nv_wr32(fifo, 0x002100, 0x00000100);
 		stat &= ~0x00000100;
 	}
 
 	if (stat & 0x00010000) {
-		gk104_fifo_intr_chsw(priv);
-		nv_wr32(priv, 0x002100, 0x00010000);
+		gk104_fifo_intr_chsw(fifo);
+		nv_wr32(fifo, 0x002100, 0x00010000);
 		stat &= ~0x00010000;
 	}
 
 	if (stat & 0x00800000) {
-		nv_error(priv, "FB_FLUSH_TIMEOUT\n");
-		nv_wr32(priv, 0x002100, 0x00800000);
+		nv_error(fifo, "FB_FLUSH_TIMEOUT\n");
+		nv_wr32(fifo, 0x002100, 0x00800000);
 		stat &= ~0x00800000;
 	}
 
 	if (stat & 0x01000000) {
-		nv_error(priv, "LB_ERROR\n");
-		nv_wr32(priv, 0x002100, 0x01000000);
+		nv_error(fifo, "LB_ERROR\n");
+		nv_wr32(fifo, 0x002100, 0x01000000);
 		stat &= ~0x01000000;
 	}
 
 	if (stat & 0x08000000) {
-		gk104_fifo_intr_dropped_fault(priv);
-		nv_wr32(priv, 0x002100, 0x08000000);
+		gk104_fifo_intr_dropped_fault(fifo);
+		nv_wr32(fifo, 0x002100, 0x08000000);
 		stat &= ~0x08000000;
 	}
 
 	if (stat & 0x10000000) {
-		u32 mask = nv_rd32(priv, 0x00259c);
+		u32 mask = nv_rd32(fifo, 0x00259c);
 		while (mask) {
 			u32 unit = __ffs(mask);
-			gk104_fifo_intr_fault(priv, unit);
-			nv_wr32(priv, 0x00259c, (1 << unit));
+			gk104_fifo_intr_fault(fifo, unit);
+			nv_wr32(fifo, 0x00259c, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x10000000;
 	}
 
 	if (stat & 0x20000000) {
-		u32 mask = nv_rd32(priv, 0x0025a0);
+		u32 mask = nv_rd32(fifo, 0x0025a0);
 		while (mask) {
 			u32 unit = __ffs(mask);
-			gk104_fifo_intr_pbdma_0(priv, unit);
-			gk104_fifo_intr_pbdma_1(priv, unit);
-			nv_wr32(priv, 0x0025a0, (1 << unit));
+			gk104_fifo_intr_pbdma_0(fifo, unit);
+			gk104_fifo_intr_pbdma_1(fifo, unit);
+			nv_wr32(fifo, 0x0025a0, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x20000000;
 	}
 
 	if (stat & 0x40000000) {
-		gk104_fifo_intr_runlist(priv);
+		gk104_fifo_intr_runlist(fifo);
 		stat &= ~0x40000000;
 	}
 
 	if (stat & 0x80000000) {
-		nv_wr32(priv, 0x002100, 0x80000000);
-		gk104_fifo_intr_engine(priv);
+		nv_wr32(fifo, 0x002100, 0x80000000);
+		gk104_fifo_intr_engine(fifo);
 		stat &= ~0x80000000;
 	}
 
 	if (stat) {
-		nv_error(priv, "INTR 0x%08x\n", stat);
-		nv_mask(priv, 0x002140, stat, 0x00000000);
-		nv_wr32(priv, 0x002100, stat);
+		nv_error(fifo, "INTR 0x%08x\n", stat);
+		nv_mask(fifo, 0x002140, stat, 0x00000000);
+		nv_wr32(fifo, 0x002100, stat);
 	}
 }
 
@@ -1010,68 +1022,68 @@ gk104_fifo_uevent_func = {
 int
 gk104_fifo_fini(struct nvkm_object *object, bool suspend)
 {
-	struct gk104_fifo_priv *priv = (void *)object;
+	struct gk104_fifo *fifo = (void *)object;
 	int ret;
 
-	ret = nvkm_fifo_fini(&priv->base, suspend);
+	ret = nvkm_fifo_fini(&fifo->base, suspend);
 	if (ret)
 		return ret;
 
 	/* allow mmu fault interrupts, even when we're not using fifo */
-	nv_mask(priv, 0x002140, 0x10000000, 0x10000000);
+	nv_mask(fifo, 0x002140, 0x10000000, 0x10000000);
 	return 0;
 }
 
 int
 gk104_fifo_init(struct nvkm_object *object)
 {
-	struct gk104_fifo_priv *priv = (void *)object;
+	struct gk104_fifo *fifo = (void *)object;
 	int ret, i;
 
-	ret = nvkm_fifo_init(&priv->base);
+	ret = nvkm_fifo_init(&fifo->base);
 	if (ret)
 		return ret;
 
 	/* enable all available PBDMA units */
-	nv_wr32(priv, 0x000204, 0xffffffff);
-	priv->spoon_nr = hweight32(nv_rd32(priv, 0x000204));
-	nv_debug(priv, "%d PBDMA unit(s)\n", priv->spoon_nr);
+	nv_wr32(fifo, 0x000204, 0xffffffff);
+	fifo->spoon_nr = hweight32(nv_rd32(fifo, 0x000204));
+	nv_debug(fifo, "%d PBDMA unit(s)\n", fifo->spoon_nr);
 
 	/* PBDMA[n] */
-	for (i = 0; i < priv->spoon_nr; i++) {
-		nv_mask(priv, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
-		nv_wr32(priv, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
-		nv_wr32(priv, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+	for (i = 0; i < fifo->spoon_nr; i++) {
+		nv_mask(fifo, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+		nv_wr32(fifo, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+		nv_wr32(fifo, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
 	}
 
 	/* PBDMA[n].HCE */
-	for (i = 0; i < priv->spoon_nr; i++) {
-		nv_wr32(priv, 0x040148 + (i * 0x2000), 0xffffffff); /* INTR */
-		nv_wr32(priv, 0x04014c + (i * 0x2000), 0xffffffff); /* INTREN */
+	for (i = 0; i < fifo->spoon_nr; i++) {
+		nv_wr32(fifo, 0x040148 + (i * 0x2000), 0xffffffff); /* INTR */
+		nv_wr32(fifo, 0x04014c + (i * 0x2000), 0xffffffff); /* INTREN */
 	}
 
-	nv_wr32(priv, 0x002254, 0x10000000 | priv->user.bar.offset >> 12);
+	nv_wr32(fifo, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
 
-	nv_wr32(priv, 0x002100, 0xffffffff);
-	nv_wr32(priv, 0x002140, 0x7fffffff);
+	nv_wr32(fifo, 0x002100, 0xffffffff);
+	nv_wr32(fifo, 0x002140, 0x7fffffff);
 	return 0;
 }
 
 void
 gk104_fifo_dtor(struct nvkm_object *object)
 {
-	struct gk104_fifo_priv *priv = (void *)object;
+	struct gk104_fifo *fifo = (void *)object;
 	int i;
 
-	nvkm_gpuobj_unmap(&priv->user.bar);
-	nvkm_gpuobj_ref(NULL, &priv->user.mem);
+	nvkm_gpuobj_unmap(&fifo->user.bar);
+	nvkm_gpuobj_ref(NULL, &fifo->user.mem);
 
 	for (i = 0; i < FIFO_ENGINE_NR; i++) {
-		nvkm_gpuobj_ref(NULL, &priv->engine[i].runlist[1]);
-		nvkm_gpuobj_ref(NULL, &priv->engine[i].runlist[0]);
+		nvkm_gpuobj_ref(NULL, &fifo->engine[i].runlist[1]);
+		nvkm_gpuobj_ref(NULL, &fifo->engine[i].runlist[0]);
 	}
 
-	nvkm_fifo_destroy(&priv->base);
+	nvkm_fifo_destroy(&fifo->base);
 }
 
 int
@@ -1080,49 +1092,49 @@ gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct nvkm_object **pobject)
 {
 	struct gk104_fifo_impl *impl = (void *)oclass;
-	struct gk104_fifo_priv *priv;
+	struct gk104_fifo *fifo;
 	int ret, i;
 
 	ret = nvkm_fifo_create(parent, engine, oclass, 0,
-			       impl->channels - 1, &priv);
-	*pobject = nv_object(priv);
+			       impl->channels - 1, &fifo);
+	*pobject = nv_object(fifo);
 	if (ret)
 		return ret;
 
-	INIT_WORK(&priv->fault, gk104_fifo_recover_work);
+	INIT_WORK(&fifo->fault, gk104_fifo_recover_work);
 
 	for (i = 0; i < FIFO_ENGINE_NR; i++) {
-		ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
-				      0, &priv->engine[i].runlist[0]);
+		ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x8000, 0x1000,
+				      0, &fifo->engine[i].runlist[0]);
 		if (ret)
 			return ret;
 
-		ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
-				      0, &priv->engine[i].runlist[1]);
+		ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x8000, 0x1000,
+				      0, &fifo->engine[i].runlist[1]);
 		if (ret)
 			return ret;
 
-		init_waitqueue_head(&priv->engine[i].wait);
+		init_waitqueue_head(&fifo->engine[i].wait);
 	}
 
-	ret = nvkm_gpuobj_new(nv_object(priv), NULL, impl->channels * 0x200,
-			      0x1000, NVOBJ_FLAG_ZERO_ALLOC, &priv->user.mem);
+	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, impl->channels * 0x200,
+			      0x1000, NVOBJ_FLAG_ZERO_ALLOC, &fifo->user.mem);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_map(priv->user.mem, NV_MEM_ACCESS_RW,
-			      &priv->user.bar);
+	ret = nvkm_gpuobj_map(fifo->user.mem, NV_MEM_ACCESS_RW,
+			      &fifo->user.bar);
 	if (ret)
 		return ret;
 
-	ret = nvkm_event_init(&gk104_fifo_uevent_func, 1, 1, &priv->base.uevent);
+	ret = nvkm_event_init(&gk104_fifo_uevent_func, 1, 1, &fifo->base.uevent);
 	if (ret)
 		return ret;
 
-	nv_subdev(priv)->unit = 0x00000100;
-	nv_subdev(priv)->intr = gk104_fifo_intr;
-	nv_engine(priv)->cclass = &gk104_fifo_cclass;
-	nv_engine(priv)->sclass = gk104_fifo_sclass;
+	nv_subdev(fifo)->unit = 0x00000100;
+	nv_subdev(fifo)->intr = gk104_fifo_intr;
+	nv_engine(fifo)->cclass = &gk104_fifo_cclass;
+	nv_engine(fifo)->sclass = gk104_fifo_sclass;
 	return 0;
 }
 

commit 89025bd458a572f15e30f59d1ac5acb599cb53bc
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Mar 11 12:21:15 2015 +1000

    drm/nouveau/fifo/gm204: initial support
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
index 9585539e59f2..e10f9644140f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -323,8 +323,8 @@ gk104_fifo_chan_fini(struct nvkm_object *object, bool suspend)
 	return nvkm_fifo_channel_fini(&chan->base, suspend);
 }
 
-static struct nvkm_ofuncs
-gk104_fifo_ofuncs = {
+struct nvkm_ofuncs
+gk104_fifo_chan_ofuncs = {
 	.ctor = gk104_fifo_chan_ctor,
 	.dtor = _nvkm_fifo_channel_dtor,
 	.init = gk104_fifo_chan_init,
@@ -337,7 +337,7 @@ gk104_fifo_ofuncs = {
 
 static struct nvkm_oclass
 gk104_fifo_sclass[] = {
-	{ KEPLER_CHANNEL_GPFIFO_A, &gk104_fifo_ofuncs },
+	{ KEPLER_CHANNEL_GPFIFO_A, &gk104_fifo_chan_ofuncs },
 	{}
 };
 
@@ -774,6 +774,7 @@ gk104_fifo_intr_fault(struct gk104_fifo_priv *priv, int unit)
 	while (object) {
 		switch (nv_mclass(object)) {
 		case KEPLER_CHANNEL_GPFIFO_A:
+		case MAXWELL_CHANNEL_GPFIFO_A:
 			gk104_fifo_recover(priv, engine, (void *)object);
 			break;
 		}

commit 05c7145dae17a53b030238f477bf28211a21b736
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 15:28:47 2015 +1000

    drm/nouveau/fifo: namespace + nvidia gpu names (no binary change)
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
new file mode 100644
index 000000000000..9585539e59f2
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gk104.c
@@ -0,0 +1,1138 @@
+/*
+ * Copyright 2012 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+#include "gk104.h"
+
+#include <core/client.h>
+#include <core/engctx.h>
+#include <core/enum.h>
+#include <core/handle.h>
+#include <subdev/bar.h>
+#include <subdev/fb.h>
+#include <subdev/mmu.h>
+#include <subdev/timer.h>
+
+#include <nvif/class.h>
+#include <nvif/unpack.h>
+
+#define _(a,b) { (a), ((1ULL << (a)) | (b)) }
+static const struct {
+	u64 subdev;
+	u64 mask;
+} fifo_engine[] = {
+	_(NVDEV_ENGINE_GR      , (1ULL << NVDEV_ENGINE_SW) |
+				 (1ULL << NVDEV_ENGINE_CE2)),
+	_(NVDEV_ENGINE_MSPDEC  , 0),
+	_(NVDEV_ENGINE_MSPPP   , 0),
+	_(NVDEV_ENGINE_MSVLD   , 0),
+	_(NVDEV_ENGINE_CE0     , 0),
+	_(NVDEV_ENGINE_CE1     , 0),
+	_(NVDEV_ENGINE_MSENC   , 0),
+};
+#undef _
+#define FIFO_ENGINE_NR ARRAY_SIZE(fifo_engine)
+
+struct gk104_fifo_engn {
+	struct nvkm_gpuobj *runlist[2];
+	int cur_runlist;
+	wait_queue_head_t wait;
+};
+
+struct gk104_fifo_priv {
+	struct nvkm_fifo base;
+
+	struct work_struct fault;
+	u64 mask;
+
+	struct gk104_fifo_engn engine[FIFO_ENGINE_NR];
+	struct {
+		struct nvkm_gpuobj *mem;
+		struct nvkm_vma bar;
+	} user;
+	int spoon_nr;
+};
+
+struct gk104_fifo_base {
+	struct nvkm_fifo_base base;
+	struct nvkm_gpuobj *pgd;
+	struct nvkm_vm *vm;
+};
+
+struct gk104_fifo_chan {
+	struct nvkm_fifo_chan base;
+	u32 engine;
+	enum {
+		STOPPED,
+		RUNNING,
+		KILLED
+	} state;
+};
+
+/*******************************************************************************
+ * FIFO channel objects
+ ******************************************************************************/
+
+static void
+gk104_fifo_runlist_update(struct gk104_fifo_priv *priv, u32 engine)
+{
+	struct nvkm_bar *bar = nvkm_bar(priv);
+	struct gk104_fifo_engn *engn = &priv->engine[engine];
+	struct nvkm_gpuobj *cur;
+	int i, p;
+
+	mutex_lock(&nv_subdev(priv)->mutex);
+	cur = engn->runlist[engn->cur_runlist];
+	engn->cur_runlist = !engn->cur_runlist;
+
+	for (i = 0, p = 0; i < priv->base.max; i++) {
+		struct gk104_fifo_chan *chan = (void *)priv->base.channel[i];
+		if (chan && chan->state == RUNNING && chan->engine == engine) {
+			nv_wo32(cur, p + 0, i);
+			nv_wo32(cur, p + 4, 0x00000000);
+			p += 8;
+		}
+	}
+	bar->flush(bar);
+
+	nv_wr32(priv, 0x002270, cur->addr >> 12);
+	nv_wr32(priv, 0x002274, (engine << 20) | (p >> 3));
+
+	if (wait_event_timeout(engn->wait, !(nv_rd32(priv, 0x002284 +
+			       (engine * 0x08)) & 0x00100000),
+				msecs_to_jiffies(2000)) == 0)
+		nv_error(priv, "runlist %d update timeout\n", engine);
+	mutex_unlock(&nv_subdev(priv)->mutex);
+}
+
+static int
+gk104_fifo_context_attach(struct nvkm_object *parent,
+			  struct nvkm_object *object)
+{
+	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct gk104_fifo_base *base = (void *)parent->parent;
+	struct nvkm_engctx *ectx = (void *)object;
+	u32 addr;
+	int ret;
+
+	switch (nv_engidx(object->engine)) {
+	case NVDEV_ENGINE_SW   :
+		return 0;
+	case NVDEV_ENGINE_CE0:
+	case NVDEV_ENGINE_CE1:
+	case NVDEV_ENGINE_CE2:
+		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
+		return 0;
+	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
+	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
+	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
+	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
+	default:
+		return -EINVAL;
+	}
+
+	if (!ectx->vma.node) {
+		ret = nvkm_gpuobj_map_vm(nv_gpuobj(ectx), base->vm,
+					 NV_MEM_ACCESS_RW, &ectx->vma);
+		if (ret)
+			return ret;
+
+		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
+	}
+
+	nv_wo32(base, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
+	nv_wo32(base, addr + 0x04, upper_32_bits(ectx->vma.offset));
+	bar->flush(bar);
+	return 0;
+}
+
+static int
+gk104_fifo_context_detach(struct nvkm_object *parent, bool suspend,
+			  struct nvkm_object *object)
+{
+	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct gk104_fifo_priv *priv = (void *)parent->engine;
+	struct gk104_fifo_base *base = (void *)parent->parent;
+	struct gk104_fifo_chan *chan = (void *)parent;
+	u32 addr;
+
+	switch (nv_engidx(object->engine)) {
+	case NVDEV_ENGINE_SW    : return 0;
+	case NVDEV_ENGINE_CE0   :
+	case NVDEV_ENGINE_CE1   :
+	case NVDEV_ENGINE_CE2   : addr = 0x0000; break;
+	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
+	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
+	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
+	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
+	default:
+		return -EINVAL;
+	}
+
+	nv_wr32(priv, 0x002634, chan->base.chid);
+	if (!nv_wait(priv, 0x002634, 0xffffffff, chan->base.chid)) {
+		nv_error(priv, "channel %d [%s] kick timeout\n",
+			 chan->base.chid, nvkm_client_name(chan));
+		if (suspend)
+			return -EBUSY;
+	}
+
+	if (addr) {
+		nv_wo32(base, addr + 0x00, 0x00000000);
+		nv_wo32(base, addr + 0x04, 0x00000000);
+		bar->flush(bar);
+	}
+
+	return 0;
+}
+
+static int
+gk104_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+		     struct nvkm_oclass *oclass, void *data, u32 size,
+		     struct nvkm_object **pobject)
+{
+	union {
+		struct kepler_channel_gpfifo_a_v0 v0;
+	} *args = data;
+	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct gk104_fifo_priv *priv = (void *)engine;
+	struct gk104_fifo_base *base = (void *)parent;
+	struct gk104_fifo_chan *chan;
+	u64 usermem, ioffset, ilength;
+	int ret, i;
+
+	nv_ioctl(parent, "create channel gpfifo size %d\n", size);
+	if (nvif_unpack(args->v0, 0, 0, false)) {
+		nv_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
+				 "ioffset %016llx ilength %08x engine %08x\n",
+			 args->v0.version, args->v0.pushbuf, args->v0.ioffset,
+			 args->v0.ilength, args->v0.engine);
+	} else
+		return ret;
+
+	for (i = 0; i < FIFO_ENGINE_NR; i++) {
+		if (args->v0.engine & (1 << i)) {
+			if (nvkm_engine(parent, fifo_engine[i].subdev)) {
+				args->v0.engine = (1 << i);
+				break;
+			}
+		}
+	}
+
+	if (i == FIFO_ENGINE_NR) {
+		nv_error(priv, "unsupported engines 0x%08x\n", args->v0.engine);
+		return -ENODEV;
+	}
+
+	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
+				       priv->user.bar.offset, 0x200,
+				       args->v0.pushbuf,
+				       fifo_engine[i].mask, &chan);
+	*pobject = nv_object(chan);
+	if (ret)
+		return ret;
+
+	args->v0.chid = chan->base.chid;
+
+	nv_parent(chan)->context_attach = gk104_fifo_context_attach;
+	nv_parent(chan)->context_detach = gk104_fifo_context_detach;
+	chan->engine = i;
+
+	usermem = chan->base.chid * 0x200;
+	ioffset = args->v0.ioffset;
+	ilength = order_base_2(args->v0.ilength / 8);
+
+	for (i = 0; i < 0x200; i += 4)
+		nv_wo32(priv->user.mem, usermem + i, 0x00000000);
+
+	nv_wo32(base, 0x08, lower_32_bits(priv->user.mem->addr + usermem));
+	nv_wo32(base, 0x0c, upper_32_bits(priv->user.mem->addr + usermem));
+	nv_wo32(base, 0x10, 0x0000face);
+	nv_wo32(base, 0x30, 0xfffff902);
+	nv_wo32(base, 0x48, lower_32_bits(ioffset));
+	nv_wo32(base, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
+	nv_wo32(base, 0x84, 0x20400000);
+	nv_wo32(base, 0x94, 0x30000001);
+	nv_wo32(base, 0x9c, 0x00000100);
+	nv_wo32(base, 0xac, 0x0000001f);
+	nv_wo32(base, 0xe8, chan->base.chid);
+	nv_wo32(base, 0xb8, 0xf8000000);
+	nv_wo32(base, 0xf8, 0x10003080); /* 0x002310 */
+	nv_wo32(base, 0xfc, 0x10000010); /* 0x002350 */
+	bar->flush(bar);
+	return 0;
+}
+
+static int
+gk104_fifo_chan_init(struct nvkm_object *object)
+{
+	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
+	struct gk104_fifo_priv *priv = (void *)object->engine;
+	struct gk104_fifo_chan *chan = (void *)object;
+	u32 chid = chan->base.chid;
+	int ret;
+
+	ret = nvkm_fifo_channel_init(&chan->base);
+	if (ret)
+		return ret;
+
+	nv_mask(priv, 0x800004 + (chid * 8), 0x000f0000, chan->engine << 16);
+	nv_wr32(priv, 0x800000 + (chid * 8), 0x80000000 | base->addr >> 12);
+
+	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
+		nv_mask(priv, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
+		gk104_fifo_runlist_update(priv, chan->engine);
+		nv_mask(priv, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
+	}
+
+	return 0;
+}
+
+static int
+gk104_fifo_chan_fini(struct nvkm_object *object, bool suspend)
+{
+	struct gk104_fifo_priv *priv = (void *)object->engine;
+	struct gk104_fifo_chan *chan = (void *)object;
+	u32 chid = chan->base.chid;
+
+	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
+		nv_mask(priv, 0x800004 + (chid * 8), 0x00000800, 0x00000800);
+		gk104_fifo_runlist_update(priv, chan->engine);
+	}
+
+	nv_wr32(priv, 0x800000 + (chid * 8), 0x00000000);
+	return nvkm_fifo_channel_fini(&chan->base, suspend);
+}
+
+static struct nvkm_ofuncs
+gk104_fifo_ofuncs = {
+	.ctor = gk104_fifo_chan_ctor,
+	.dtor = _nvkm_fifo_channel_dtor,
+	.init = gk104_fifo_chan_init,
+	.fini = gk104_fifo_chan_fini,
+	.map  = _nvkm_fifo_channel_map,
+	.rd32 = _nvkm_fifo_channel_rd32,
+	.wr32 = _nvkm_fifo_channel_wr32,
+	.ntfy = _nvkm_fifo_channel_ntfy
+};
+
+static struct nvkm_oclass
+gk104_fifo_sclass[] = {
+	{ KEPLER_CHANNEL_GPFIFO_A, &gk104_fifo_ofuncs },
+	{}
+};
+
+/*******************************************************************************
+ * FIFO context - instmem heap and vm setup
+ ******************************************************************************/
+
+static int
+gk104_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+			struct nvkm_oclass *oclass, void *data, u32 size,
+			struct nvkm_object **pobject)
+{
+	struct gk104_fifo_base *base;
+	int ret;
+
+	ret = nvkm_fifo_context_create(parent, engine, oclass, NULL, 0x1000,
+				       0x1000, NVOBJ_FLAG_ZERO_ALLOC, &base);
+	*pobject = nv_object(base);
+	if (ret)
+		return ret;
+
+	ret = nvkm_gpuobj_new(nv_object(base), NULL, 0x10000, 0x1000, 0,
+			      &base->pgd);
+	if (ret)
+		return ret;
+
+	nv_wo32(base, 0x0200, lower_32_bits(base->pgd->addr));
+	nv_wo32(base, 0x0204, upper_32_bits(base->pgd->addr));
+	nv_wo32(base, 0x0208, 0xffffffff);
+	nv_wo32(base, 0x020c, 0x000000ff);
+
+	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static void
+gk104_fifo_context_dtor(struct nvkm_object *object)
+{
+	struct gk104_fifo_base *base = (void *)object;
+	nvkm_vm_ref(NULL, &base->vm, base->pgd);
+	nvkm_gpuobj_ref(NULL, &base->pgd);
+	nvkm_fifo_context_destroy(&base->base);
+}
+
+static struct nvkm_oclass
+gk104_fifo_cclass = {
+	.handle = NV_ENGCTX(FIFO, 0xe0),
+	.ofuncs = &(struct nvkm_ofuncs) {
+		.ctor = gk104_fifo_context_ctor,
+		.dtor = gk104_fifo_context_dtor,
+		.init = _nvkm_fifo_context_init,
+		.fini = _nvkm_fifo_context_fini,
+		.rd32 = _nvkm_fifo_context_rd32,
+		.wr32 = _nvkm_fifo_context_wr32,
+	},
+};
+
+/*******************************************************************************
+ * PFIFO engine
+ ******************************************************************************/
+
+static inline int
+gk104_fifo_engidx(struct gk104_fifo_priv *priv, u32 engn)
+{
+	switch (engn) {
+	case NVDEV_ENGINE_GR    :
+	case NVDEV_ENGINE_CE2   : engn = 0; break;
+	case NVDEV_ENGINE_MSVLD : engn = 1; break;
+	case NVDEV_ENGINE_MSPPP : engn = 2; break;
+	case NVDEV_ENGINE_MSPDEC: engn = 3; break;
+	case NVDEV_ENGINE_CE0   : engn = 4; break;
+	case NVDEV_ENGINE_CE1   : engn = 5; break;
+	case NVDEV_ENGINE_MSENC : engn = 6; break;
+	default:
+		return -1;
+	}
+
+	return engn;
+}
+
+static inline struct nvkm_engine *
+gk104_fifo_engine(struct gk104_fifo_priv *priv, u32 engn)
+{
+	if (engn >= ARRAY_SIZE(fifo_engine))
+		return NULL;
+	return nvkm_engine(priv, fifo_engine[engn].subdev);
+}
+
+static void
+gk104_fifo_recover_work(struct work_struct *work)
+{
+	struct gk104_fifo_priv *priv = container_of(work, typeof(*priv), fault);
+	struct nvkm_object *engine;
+	unsigned long flags;
+	u32 engn, engm = 0;
+	u64 mask, todo;
+
+	spin_lock_irqsave(&priv->base.lock, flags);
+	mask = priv->mask;
+	priv->mask = 0ULL;
+	spin_unlock_irqrestore(&priv->base.lock, flags);
+
+	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
+		engm |= 1 << gk104_fifo_engidx(priv, engn);
+	nv_mask(priv, 0x002630, engm, engm);
+
+	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
+		if ((engine = (void *)nvkm_engine(priv, engn))) {
+			nv_ofuncs(engine)->fini(engine, false);
+			WARN_ON(nv_ofuncs(engine)->init(engine));
+		}
+		gk104_fifo_runlist_update(priv, gk104_fifo_engidx(priv, engn));
+	}
+
+	nv_wr32(priv, 0x00262c, engm);
+	nv_mask(priv, 0x002630, engm, 0x00000000);
+}
+
+static void
+gk104_fifo_recover(struct gk104_fifo_priv *priv, struct nvkm_engine *engine,
+		  struct gk104_fifo_chan *chan)
+{
+	u32 chid = chan->base.chid;
+	unsigned long flags;
+
+	nv_error(priv, "%s engine fault on channel %d, recovering...\n",
+		       nv_subdev(engine)->name, chid);
+
+	nv_mask(priv, 0x800004 + (chid * 0x08), 0x00000800, 0x00000800);
+	chan->state = KILLED;
+
+	spin_lock_irqsave(&priv->base.lock, flags);
+	priv->mask |= 1ULL << nv_engidx(engine);
+	spin_unlock_irqrestore(&priv->base.lock, flags);
+	schedule_work(&priv->fault);
+}
+
+static int
+gk104_fifo_swmthd(struct gk104_fifo_priv *priv, u32 chid, u32 mthd, u32 data)
+{
+	struct gk104_fifo_chan *chan = NULL;
+	struct nvkm_handle *bind;
+	unsigned long flags;
+	int ret = -EINVAL;
+
+	spin_lock_irqsave(&priv->base.lock, flags);
+	if (likely(chid >= priv->base.min && chid <= priv->base.max))
+		chan = (void *)priv->base.channel[chid];
+	if (unlikely(!chan))
+		goto out;
+
+	bind = nvkm_namedb_get_class(nv_namedb(chan), 0x906e);
+	if (likely(bind)) {
+		if (!mthd || !nv_call(bind->object, mthd, data))
+			ret = 0;
+		nvkm_namedb_put(bind);
+	}
+
+out:
+	spin_unlock_irqrestore(&priv->base.lock, flags);
+	return ret;
+}
+
+static const struct nvkm_enum
+gk104_fifo_bind_reason[] = {
+	{ 0x01, "BIND_NOT_UNBOUND" },
+	{ 0x02, "SNOOP_WITHOUT_BAR1" },
+	{ 0x03, "UNBIND_WHILE_RUNNING" },
+	{ 0x05, "INVALID_RUNLIST" },
+	{ 0x06, "INVALID_CTX_TGT" },
+	{ 0x0b, "UNBIND_WHILE_PARKED" },
+	{}
+};
+
+static void
+gk104_fifo_intr_bind(struct gk104_fifo_priv *priv)
+{
+	u32 intr = nv_rd32(priv, 0x00252c);
+	u32 code = intr & 0x000000ff;
+	const struct nvkm_enum *en;
+	char enunk[6] = "";
+
+	en = nvkm_enum_find(gk104_fifo_bind_reason, code);
+	if (!en)
+		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
+
+	nv_error(priv, "BIND_ERROR [ %s ]\n", en ? en->name : enunk);
+}
+
+static const struct nvkm_enum
+gk104_fifo_sched_reason[] = {
+	{ 0x0a, "CTXSW_TIMEOUT" },
+	{}
+};
+
+static void
+gk104_fifo_intr_sched_ctxsw(struct gk104_fifo_priv *priv)
+{
+	struct nvkm_engine *engine;
+	struct gk104_fifo_chan *chan;
+	u32 engn;
+
+	for (engn = 0; engn < ARRAY_SIZE(fifo_engine); engn++) {
+		u32 stat = nv_rd32(priv, 0x002640 + (engn * 0x04));
+		u32 busy = (stat & 0x80000000);
+		u32 next = (stat & 0x07ff0000) >> 16;
+		u32 chsw = (stat & 0x00008000);
+		u32 save = (stat & 0x00004000);
+		u32 load = (stat & 0x00002000);
+		u32 prev = (stat & 0x000007ff);
+		u32 chid = load ? next : prev;
+		(void)save;
+
+		if (busy && chsw) {
+			if (!(chan = (void *)priv->base.channel[chid]))
+				continue;
+			if (!(engine = gk104_fifo_engine(priv, engn)))
+				continue;
+			gk104_fifo_recover(priv, engine, chan);
+		}
+	}
+}
+
+static void
+gk104_fifo_intr_sched(struct gk104_fifo_priv *priv)
+{
+	u32 intr = nv_rd32(priv, 0x00254c);
+	u32 code = intr & 0x000000ff;
+	const struct nvkm_enum *en;
+	char enunk[6] = "";
+
+	en = nvkm_enum_find(gk104_fifo_sched_reason, code);
+	if (!en)
+		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
+
+	nv_error(priv, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
+
+	switch (code) {
+	case 0x0a:
+		gk104_fifo_intr_sched_ctxsw(priv);
+		break;
+	default:
+		break;
+	}
+}
+
+static void
+gk104_fifo_intr_chsw(struct gk104_fifo_priv *priv)
+{
+	u32 stat = nv_rd32(priv, 0x00256c);
+	nv_error(priv, "CHSW_ERROR 0x%08x\n", stat);
+	nv_wr32(priv, 0x00256c, stat);
+}
+
+static void
+gk104_fifo_intr_dropped_fault(struct gk104_fifo_priv *priv)
+{
+	u32 stat = nv_rd32(priv, 0x00259c);
+	nv_error(priv, "DROPPED_MMU_FAULT 0x%08x\n", stat);
+}
+
+static const struct nvkm_enum
+gk104_fifo_fault_engine[] = {
+	{ 0x00, "GR", NULL, NVDEV_ENGINE_GR },
+	{ 0x03, "IFB", NULL, NVDEV_ENGINE_IFB },
+	{ 0x04, "BAR1", NULL, NVDEV_SUBDEV_BAR },
+	{ 0x05, "BAR3", NULL, NVDEV_SUBDEV_INSTMEM },
+	{ 0x07, "PBDMA0", NULL, NVDEV_ENGINE_FIFO },
+	{ 0x08, "PBDMA1", NULL, NVDEV_ENGINE_FIFO },
+	{ 0x09, "PBDMA2", NULL, NVDEV_ENGINE_FIFO },
+	{ 0x10, "MSVLD", NULL, NVDEV_ENGINE_MSVLD },
+	{ 0x11, "MSPPP", NULL, NVDEV_ENGINE_MSPPP },
+	{ 0x13, "PERF" },
+	{ 0x14, "MSPDEC", NULL, NVDEV_ENGINE_MSPDEC },
+	{ 0x15, "CE0", NULL, NVDEV_ENGINE_CE0 },
+	{ 0x16, "CE1", NULL, NVDEV_ENGINE_CE1 },
+	{ 0x17, "PMU" },
+	{ 0x19, "MSENC", NULL, NVDEV_ENGINE_MSENC },
+	{ 0x1b, "CE2", NULL, NVDEV_ENGINE_CE2 },
+	{}
+};
+
+static const struct nvkm_enum
+gk104_fifo_fault_reason[] = {
+	{ 0x00, "PDE" },
+	{ 0x01, "PDE_SIZE" },
+	{ 0x02, "PTE" },
+	{ 0x03, "VA_LIMIT_VIOLATION" },
+	{ 0x04, "UNBOUND_INST_BLOCK" },
+	{ 0x05, "PRIV_VIOLATION" },
+	{ 0x06, "RO_VIOLATION" },
+	{ 0x07, "WO_VIOLATION" },
+	{ 0x08, "PITCH_MASK_VIOLATION" },
+	{ 0x09, "WORK_CREATION" },
+	{ 0x0a, "UNSUPPORTED_APERTURE" },
+	{ 0x0b, "COMPRESSION_FAILURE" },
+	{ 0x0c, "UNSUPPORTED_KIND" },
+	{ 0x0d, "REGION_VIOLATION" },
+	{ 0x0e, "BOTH_PTES_VALID" },
+	{ 0x0f, "INFO_TYPE_POISONED" },
+	{}
+};
+
+static const struct nvkm_enum
+gk104_fifo_fault_hubclient[] = {
+	{ 0x00, "VIP" },
+	{ 0x01, "CE0" },
+	{ 0x02, "CE1" },
+	{ 0x03, "DNISO" },
+	{ 0x04, "FE" },
+	{ 0x05, "FECS" },
+	{ 0x06, "HOST" },
+	{ 0x07, "HOST_CPU" },
+	{ 0x08, "HOST_CPU_NB" },
+	{ 0x09, "ISO" },
+	{ 0x0a, "MMU" },
+	{ 0x0b, "MSPDEC" },
+	{ 0x0c, "MSPPP" },
+	{ 0x0d, "MSVLD" },
+	{ 0x0e, "NISO" },
+	{ 0x0f, "P2P" },
+	{ 0x10, "PD" },
+	{ 0x11, "PERF" },
+	{ 0x12, "PMU" },
+	{ 0x13, "RASTERTWOD" },
+	{ 0x14, "SCC" },
+	{ 0x15, "SCC_NB" },
+	{ 0x16, "SEC" },
+	{ 0x17, "SSYNC" },
+	{ 0x18, "GR_CE" },
+	{ 0x19, "CE2" },
+	{ 0x1a, "XV" },
+	{ 0x1b, "MMU_NB" },
+	{ 0x1c, "MSENC" },
+	{ 0x1d, "DFALCON" },
+	{ 0x1e, "SKED" },
+	{ 0x1f, "AFALCON" },
+	{}
+};
+
+static const struct nvkm_enum
+gk104_fifo_fault_gpcclient[] = {
+	{ 0x00, "L1_0" }, { 0x01, "T1_0" }, { 0x02, "PE_0" },
+	{ 0x03, "L1_1" }, { 0x04, "T1_1" }, { 0x05, "PE_1" },
+	{ 0x06, "L1_2" }, { 0x07, "T1_2" }, { 0x08, "PE_2" },
+	{ 0x09, "L1_3" }, { 0x0a, "T1_3" }, { 0x0b, "PE_3" },
+	{ 0x0c, "RAST" },
+	{ 0x0d, "GCC" },
+	{ 0x0e, "GPCCS" },
+	{ 0x0f, "PROP_0" },
+	{ 0x10, "PROP_1" },
+	{ 0x11, "PROP_2" },
+	{ 0x12, "PROP_3" },
+	{ 0x13, "L1_4" }, { 0x14, "T1_4" }, { 0x15, "PE_4" },
+	{ 0x16, "L1_5" }, { 0x17, "T1_5" }, { 0x18, "PE_5" },
+	{ 0x19, "L1_6" }, { 0x1a, "T1_6" }, { 0x1b, "PE_6" },
+	{ 0x1c, "L1_7" }, { 0x1d, "T1_7" }, { 0x1e, "PE_7" },
+	{ 0x1f, "GPM" },
+	{ 0x20, "LTP_UTLB_0" },
+	{ 0x21, "LTP_UTLB_1" },
+	{ 0x22, "LTP_UTLB_2" },
+	{ 0x23, "LTP_UTLB_3" },
+	{ 0x24, "GPC_RGG_UTLB" },
+	{}
+};
+
+static void
+gk104_fifo_intr_fault(struct gk104_fifo_priv *priv, int unit)
+{
+	u32 inst = nv_rd32(priv, 0x002800 + (unit * 0x10));
+	u32 valo = nv_rd32(priv, 0x002804 + (unit * 0x10));
+	u32 vahi = nv_rd32(priv, 0x002808 + (unit * 0x10));
+	u32 stat = nv_rd32(priv, 0x00280c + (unit * 0x10));
+	u32 gpc    = (stat & 0x1f000000) >> 24;
+	u32 client = (stat & 0x00001f00) >> 8;
+	u32 write  = (stat & 0x00000080);
+	u32 hub    = (stat & 0x00000040);
+	u32 reason = (stat & 0x0000000f);
+	struct nvkm_object *engctx = NULL, *object;
+	struct nvkm_engine *engine = NULL;
+	const struct nvkm_enum *er, *eu, *ec;
+	char erunk[6] = "";
+	char euunk[6] = "";
+	char ecunk[6] = "";
+	char gpcid[3] = "";
+
+	er = nvkm_enum_find(gk104_fifo_fault_reason, reason);
+	if (!er)
+		snprintf(erunk, sizeof(erunk), "UNK%02X", reason);
+
+	eu = nvkm_enum_find(gk104_fifo_fault_engine, unit);
+	if (eu) {
+		switch (eu->data2) {
+		case NVDEV_SUBDEV_BAR:
+			nv_mask(priv, 0x001704, 0x00000000, 0x00000000);
+			break;
+		case NVDEV_SUBDEV_INSTMEM:
+			nv_mask(priv, 0x001714, 0x00000000, 0x00000000);
+			break;
+		case NVDEV_ENGINE_IFB:
+			nv_mask(priv, 0x001718, 0x00000000, 0x00000000);
+			break;
+		default:
+			engine = nvkm_engine(priv, eu->data2);
+			if (engine)
+				engctx = nvkm_engctx_get(engine, inst);
+			break;
+		}
+	} else {
+		snprintf(euunk, sizeof(euunk), "UNK%02x", unit);
+	}
+
+	if (hub) {
+		ec = nvkm_enum_find(gk104_fifo_fault_hubclient, client);
+	} else {
+		ec = nvkm_enum_find(gk104_fifo_fault_gpcclient, client);
+		snprintf(gpcid, sizeof(gpcid), "%d", gpc);
+	}
+
+	if (!ec)
+		snprintf(ecunk, sizeof(ecunk), "UNK%02x", client);
+
+	nv_error(priv, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
+		       "channel 0x%010llx [%s]\n", write ? "write" : "read",
+		 (u64)vahi << 32 | valo, er ? er->name : erunk,
+		 eu ? eu->name : euunk, hub ? "" : "GPC", gpcid, hub ? "" : "/",
+		 ec ? ec->name : ecunk, (u64)inst << 12,
+		 nvkm_client_name(engctx));
+
+	object = engctx;
+	while (object) {
+		switch (nv_mclass(object)) {
+		case KEPLER_CHANNEL_GPFIFO_A:
+			gk104_fifo_recover(priv, engine, (void *)object);
+			break;
+		}
+		object = object->parent;
+	}
+
+	nvkm_engctx_put(engctx);
+}
+
+static const struct nvkm_bitfield gk104_fifo_pbdma_intr_0[] = {
+	{ 0x00000001, "MEMREQ" },
+	{ 0x00000002, "MEMACK_TIMEOUT" },
+	{ 0x00000004, "MEMACK_EXTRA" },
+	{ 0x00000008, "MEMDAT_TIMEOUT" },
+	{ 0x00000010, "MEMDAT_EXTRA" },
+	{ 0x00000020, "MEMFLUSH" },
+	{ 0x00000040, "MEMOP" },
+	{ 0x00000080, "LBCONNECT" },
+	{ 0x00000100, "LBREQ" },
+	{ 0x00000200, "LBACK_TIMEOUT" },
+	{ 0x00000400, "LBACK_EXTRA" },
+	{ 0x00000800, "LBDAT_TIMEOUT" },
+	{ 0x00001000, "LBDAT_EXTRA" },
+	{ 0x00002000, "GPFIFO" },
+	{ 0x00004000, "GPPTR" },
+	{ 0x00008000, "GPENTRY" },
+	{ 0x00010000, "GPCRC" },
+	{ 0x00020000, "PBPTR" },
+	{ 0x00040000, "PBENTRY" },
+	{ 0x00080000, "PBCRC" },
+	{ 0x00100000, "XBARCONNECT" },
+	{ 0x00200000, "METHOD" },
+	{ 0x00400000, "METHODCRC" },
+	{ 0x00800000, "DEVICE" },
+	{ 0x02000000, "SEMAPHORE" },
+	{ 0x04000000, "ACQUIRE" },
+	{ 0x08000000, "PRI" },
+	{ 0x20000000, "NO_CTXSW_SEG" },
+	{ 0x40000000, "PBSEG" },
+	{ 0x80000000, "SIGNATURE" },
+	{}
+};
+
+static void
+gk104_fifo_intr_pbdma_0(struct gk104_fifo_priv *priv, int unit)
+{
+	u32 mask = nv_rd32(priv, 0x04010c + (unit * 0x2000));
+	u32 stat = nv_rd32(priv, 0x040108 + (unit * 0x2000)) & mask;
+	u32 addr = nv_rd32(priv, 0x0400c0 + (unit * 0x2000));
+	u32 data = nv_rd32(priv, 0x0400c4 + (unit * 0x2000));
+	u32 chid = nv_rd32(priv, 0x040120 + (unit * 0x2000)) & 0xfff;
+	u32 subc = (addr & 0x00070000) >> 16;
+	u32 mthd = (addr & 0x00003ffc);
+	u32 show = stat;
+
+	if (stat & 0x00800000) {
+		if (!gk104_fifo_swmthd(priv, chid, mthd, data))
+			show &= ~0x00800000;
+		nv_wr32(priv, 0x0400c0 + (unit * 0x2000), 0x80600008);
+	}
+
+	if (show) {
+		nv_error(priv, "PBDMA%d:", unit);
+		nvkm_bitfield_print(gk104_fifo_pbdma_intr_0, show);
+		pr_cont("\n");
+		nv_error(priv,
+			 "PBDMA%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
+			 unit, chid,
+			 nvkm_client_name_for_fifo_chid(&priv->base, chid),
+			 subc, mthd, data);
+	}
+
+	nv_wr32(priv, 0x040108 + (unit * 0x2000), stat);
+}
+
+static const struct nvkm_bitfield gk104_fifo_pbdma_intr_1[] = {
+	{ 0x00000001, "HCE_RE_ILLEGAL_OP" },
+	{ 0x00000002, "HCE_RE_ALIGNB" },
+	{ 0x00000004, "HCE_PRIV" },
+	{ 0x00000008, "HCE_ILLEGAL_MTHD" },
+	{ 0x00000010, "HCE_ILLEGAL_CLASS" },
+	{}
+};
+
+static void
+gk104_fifo_intr_pbdma_1(struct gk104_fifo_priv *priv, int unit)
+{
+	u32 mask = nv_rd32(priv, 0x04014c + (unit * 0x2000));
+	u32 stat = nv_rd32(priv, 0x040148 + (unit * 0x2000)) & mask;
+	u32 chid = nv_rd32(priv, 0x040120 + (unit * 0x2000)) & 0xfff;
+
+	if (stat) {
+		nv_error(priv, "PBDMA%d:", unit);
+		nvkm_bitfield_print(gk104_fifo_pbdma_intr_1, stat);
+		pr_cont("\n");
+		nv_error(priv, "PBDMA%d: ch %d %08x %08x\n", unit, chid,
+			 nv_rd32(priv, 0x040150 + (unit * 0x2000)),
+			 nv_rd32(priv, 0x040154 + (unit * 0x2000)));
+	}
+
+	nv_wr32(priv, 0x040148 + (unit * 0x2000), stat);
+}
+
+static void
+gk104_fifo_intr_runlist(struct gk104_fifo_priv *priv)
+{
+	u32 mask = nv_rd32(priv, 0x002a00);
+	while (mask) {
+		u32 engn = __ffs(mask);
+		wake_up(&priv->engine[engn].wait);
+		nv_wr32(priv, 0x002a00, 1 << engn);
+		mask &= ~(1 << engn);
+	}
+}
+
+static void
+gk104_fifo_intr_engine(struct gk104_fifo_priv *priv)
+{
+	nvkm_fifo_uevent(&priv->base);
+}
+
+static void
+gk104_fifo_intr(struct nvkm_subdev *subdev)
+{
+	struct gk104_fifo_priv *priv = (void *)subdev;
+	u32 mask = nv_rd32(priv, 0x002140);
+	u32 stat = nv_rd32(priv, 0x002100) & mask;
+
+	if (stat & 0x00000001) {
+		gk104_fifo_intr_bind(priv);
+		nv_wr32(priv, 0x002100, 0x00000001);
+		stat &= ~0x00000001;
+	}
+
+	if (stat & 0x00000010) {
+		nv_error(priv, "PIO_ERROR\n");
+		nv_wr32(priv, 0x002100, 0x00000010);
+		stat &= ~0x00000010;
+	}
+
+	if (stat & 0x00000100) {
+		gk104_fifo_intr_sched(priv);
+		nv_wr32(priv, 0x002100, 0x00000100);
+		stat &= ~0x00000100;
+	}
+
+	if (stat & 0x00010000) {
+		gk104_fifo_intr_chsw(priv);
+		nv_wr32(priv, 0x002100, 0x00010000);
+		stat &= ~0x00010000;
+	}
+
+	if (stat & 0x00800000) {
+		nv_error(priv, "FB_FLUSH_TIMEOUT\n");
+		nv_wr32(priv, 0x002100, 0x00800000);
+		stat &= ~0x00800000;
+	}
+
+	if (stat & 0x01000000) {
+		nv_error(priv, "LB_ERROR\n");
+		nv_wr32(priv, 0x002100, 0x01000000);
+		stat &= ~0x01000000;
+	}
+
+	if (stat & 0x08000000) {
+		gk104_fifo_intr_dropped_fault(priv);
+		nv_wr32(priv, 0x002100, 0x08000000);
+		stat &= ~0x08000000;
+	}
+
+	if (stat & 0x10000000) {
+		u32 mask = nv_rd32(priv, 0x00259c);
+		while (mask) {
+			u32 unit = __ffs(mask);
+			gk104_fifo_intr_fault(priv, unit);
+			nv_wr32(priv, 0x00259c, (1 << unit));
+			mask &= ~(1 << unit);
+		}
+		stat &= ~0x10000000;
+	}
+
+	if (stat & 0x20000000) {
+		u32 mask = nv_rd32(priv, 0x0025a0);
+		while (mask) {
+			u32 unit = __ffs(mask);
+			gk104_fifo_intr_pbdma_0(priv, unit);
+			gk104_fifo_intr_pbdma_1(priv, unit);
+			nv_wr32(priv, 0x0025a0, (1 << unit));
+			mask &= ~(1 << unit);
+		}
+		stat &= ~0x20000000;
+	}
+
+	if (stat & 0x40000000) {
+		gk104_fifo_intr_runlist(priv);
+		stat &= ~0x40000000;
+	}
+
+	if (stat & 0x80000000) {
+		nv_wr32(priv, 0x002100, 0x80000000);
+		gk104_fifo_intr_engine(priv);
+		stat &= ~0x80000000;
+	}
+
+	if (stat) {
+		nv_error(priv, "INTR 0x%08x\n", stat);
+		nv_mask(priv, 0x002140, stat, 0x00000000);
+		nv_wr32(priv, 0x002100, stat);
+	}
+}
+
+static void
+gk104_fifo_uevent_init(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	nv_mask(fifo, 0x002140, 0x80000000, 0x80000000);
+}
+
+static void
+gk104_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	nv_mask(fifo, 0x002140, 0x80000000, 0x00000000);
+}
+
+static const struct nvkm_event_func
+gk104_fifo_uevent_func = {
+	.ctor = nvkm_fifo_uevent_ctor,
+	.init = gk104_fifo_uevent_init,
+	.fini = gk104_fifo_uevent_fini,
+};
+
+int
+gk104_fifo_fini(struct nvkm_object *object, bool suspend)
+{
+	struct gk104_fifo_priv *priv = (void *)object;
+	int ret;
+
+	ret = nvkm_fifo_fini(&priv->base, suspend);
+	if (ret)
+		return ret;
+
+	/* allow mmu fault interrupts, even when we're not using fifo */
+	nv_mask(priv, 0x002140, 0x10000000, 0x10000000);
+	return 0;
+}
+
+int
+gk104_fifo_init(struct nvkm_object *object)
+{
+	struct gk104_fifo_priv *priv = (void *)object;
+	int ret, i;
+
+	ret = nvkm_fifo_init(&priv->base);
+	if (ret)
+		return ret;
+
+	/* enable all available PBDMA units */
+	nv_wr32(priv, 0x000204, 0xffffffff);
+	priv->spoon_nr = hweight32(nv_rd32(priv, 0x000204));
+	nv_debug(priv, "%d PBDMA unit(s)\n", priv->spoon_nr);
+
+	/* PBDMA[n] */
+	for (i = 0; i < priv->spoon_nr; i++) {
+		nv_mask(priv, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+		nv_wr32(priv, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+		nv_wr32(priv, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+	}
+
+	/* PBDMA[n].HCE */
+	for (i = 0; i < priv->spoon_nr; i++) {
+		nv_wr32(priv, 0x040148 + (i * 0x2000), 0xffffffff); /* INTR */
+		nv_wr32(priv, 0x04014c + (i * 0x2000), 0xffffffff); /* INTREN */
+	}
+
+	nv_wr32(priv, 0x002254, 0x10000000 | priv->user.bar.offset >> 12);
+
+	nv_wr32(priv, 0x002100, 0xffffffff);
+	nv_wr32(priv, 0x002140, 0x7fffffff);
+	return 0;
+}
+
+void
+gk104_fifo_dtor(struct nvkm_object *object)
+{
+	struct gk104_fifo_priv *priv = (void *)object;
+	int i;
+
+	nvkm_gpuobj_unmap(&priv->user.bar);
+	nvkm_gpuobj_ref(NULL, &priv->user.mem);
+
+	for (i = 0; i < FIFO_ENGINE_NR; i++) {
+		nvkm_gpuobj_ref(NULL, &priv->engine[i].runlist[1]);
+		nvkm_gpuobj_ref(NULL, &priv->engine[i].runlist[0]);
+	}
+
+	nvkm_fifo_destroy(&priv->base);
+}
+
+int
+gk104_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+		struct nvkm_oclass *oclass, void *data, u32 size,
+		struct nvkm_object **pobject)
+{
+	struct gk104_fifo_impl *impl = (void *)oclass;
+	struct gk104_fifo_priv *priv;
+	int ret, i;
+
+	ret = nvkm_fifo_create(parent, engine, oclass, 0,
+			       impl->channels - 1, &priv);
+	*pobject = nv_object(priv);
+	if (ret)
+		return ret;
+
+	INIT_WORK(&priv->fault, gk104_fifo_recover_work);
+
+	for (i = 0; i < FIFO_ENGINE_NR; i++) {
+		ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
+				      0, &priv->engine[i].runlist[0]);
+		if (ret)
+			return ret;
+
+		ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
+				      0, &priv->engine[i].runlist[1]);
+		if (ret)
+			return ret;
+
+		init_waitqueue_head(&priv->engine[i].wait);
+	}
+
+	ret = nvkm_gpuobj_new(nv_object(priv), NULL, impl->channels * 0x200,
+			      0x1000, NVOBJ_FLAG_ZERO_ALLOC, &priv->user.mem);
+	if (ret)
+		return ret;
+
+	ret = nvkm_gpuobj_map(priv->user.mem, NV_MEM_ACCESS_RW,
+			      &priv->user.bar);
+	if (ret)
+		return ret;
+
+	ret = nvkm_event_init(&gk104_fifo_uevent_func, 1, 1, &priv->base.uevent);
+	if (ret)
+		return ret;
+
+	nv_subdev(priv)->unit = 0x00000100;
+	nv_subdev(priv)->intr = gk104_fifo_intr;
+	nv_engine(priv)->cclass = &gk104_fifo_cclass;
+	nv_engine(priv)->sclass = gk104_fifo_sclass;
+	return 0;
+}
+
+struct nvkm_oclass *
+gk104_fifo_oclass = &(struct gk104_fifo_impl) {
+	.base.handle = NV_ENGINE(FIFO, 0xe0),
+	.base.ofuncs = &(struct nvkm_ofuncs) {
+		.ctor = gk104_fifo_ctor,
+		.dtor = gk104_fifo_dtor,
+		.init = gk104_fifo_init,
+		.fini = gk104_fifo_fini,
+	},
+	.channels = 4096,
+}.base;
