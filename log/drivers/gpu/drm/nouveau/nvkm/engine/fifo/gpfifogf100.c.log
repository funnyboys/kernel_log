commit 832ca2ac3c95feb01e53c24fcd1a00b4cf05cbdc
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:20 2017 +1000

    drm/nouveau: pass handle of vmm object to channel allocation ioctls
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 78114068c6dd..75f9632789b3 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -225,10 +225,12 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (!(ret = nvif_unpack(ret, &data, &size, args->v0, 0, 0, false))) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d vm %llx "
+		nvif_ioctl(parent, "create channel gpfifo vers %d vmm %llx "
 				   "ioffset %016llx ilength %08x\n",
-			   args->v0.version, args->v0.vm, args->v0.ioffset,
+			   args->v0.version, args->v0.vmm, args->v0.ioffset,
 			   args->v0.ilength);
+		if (!args->v0.vmm)
+			return -EINVAL;
 	} else
 		return ret;
 
@@ -240,7 +242,7 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 	INIT_LIST_HEAD(&chan->head);
 
 	ret = nvkm_fifo_chan_ctor(&gf100_fifo_gpfifo_func, &fifo->base,
-				  0x1000, 0x1000, true, args->v0.vm, 0,
+				  0x1000, 0x1000, true, args->v0.vmm, 0,
 				  (1ULL << NVKM_ENGINE_CE0) |
 				  (1ULL << NVKM_ENGINE_CE1) |
 				  (1ULL << NVKM_ENGINE_GR) |

commit 01f349fcad68d80939db53d9110135e6341b786d
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/fifo/gf100-: use new interfaces for vmm operations
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 3e2b1a82e640..78114068c6dd 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -111,7 +111,7 @@ gf100_fifo_gpfifo_engine_init(struct nvkm_fifo_chan *base,
 	struct nvkm_gpuobj *inst = chan->base.inst;
 
 	if (offset) {
-		u64 addr = chan->engn[engine->subdev.index].vma.offset;
+		u64 addr = chan->engn[engine->subdev.index].vma->addr;
 		nvkm_kmap(inst);
 		nvkm_wo32(inst, offset + 0x00, lower_32_bits(addr) | 4);
 		nvkm_wo32(inst, offset + 0x04, upper_32_bits(addr));
@@ -126,11 +126,7 @@ gf100_fifo_gpfifo_engine_dtor(struct nvkm_fifo_chan *base,
 			      struct nvkm_engine *engine)
 {
 	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
-	struct nvkm_vma *vma = &chan->engn[engine->subdev.index].vma;
-	if (vma->vm) {
-		nvkm_vm_unmap(vma);
-		nvkm_vm_put(vma);
-	}
+	nvkm_vmm_put(chan->base.vmm, &chan->engn[engine->subdev.index].vma);
 	nvkm_gpuobj_del(&chan->engn[engine->subdev.index].inst);
 }
 
@@ -150,13 +146,13 @@ gf100_fifo_gpfifo_engine_ctor(struct nvkm_fifo_chan *base,
 	if (ret)
 		return ret;
 
-	ret = nvkm_vm_get(chan->base.vmm, chan->engn[engn].inst->size, 12,
-			  NV_MEM_ACCESS_RW, &chan->engn[engn].vma);
+	ret = nvkm_vmm_get(chan->base.vmm, 12, chan->engn[engn].inst->size,
+			   &chan->engn[engn].vma);
 	if (ret)
 		return ret;
 
 	return nvkm_memory_map(chan->engn[engn].inst, 0, chan->base.vmm,
-			       &chan->engn[engn].vma, NULL, 0);
+			       chan->engn[engn].vma, NULL, 0);
 }
 
 static void
@@ -252,7 +248,7 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 				  (1ULL << NVKM_ENGINE_MSPPP) |
 				  (1ULL << NVKM_ENGINE_MSVLD) |
 				  (1ULL << NVKM_ENGINE_SW),
-				  1, fifo->user.bar.offset, 0x1000,
+				  1, fifo->user.bar->addr, 0x1000,
 				  oclass, &chan->base);
 	if (ret)
 		return ret;

commit f66c57d9229c313de3adf340c604b1c7a40e5306
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/fifo: initialise vmm with new interfaces
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 695d0721b1ad..3e2b1a82e640 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -150,12 +150,12 @@ gf100_fifo_gpfifo_engine_ctor(struct nvkm_fifo_chan *base,
 	if (ret)
 		return ret;
 
-	ret = nvkm_vm_get(chan->vm, chan->engn[engn].inst->size, 12,
+	ret = nvkm_vm_get(chan->base.vmm, chan->engn[engn].inst->size, 12,
 			  NV_MEM_ACCESS_RW, &chan->engn[engn].vma);
 	if (ret)
 		return ret;
 
-	return nvkm_memory_map(chan->engn[engn].inst, 0, chan->vm,
+	return nvkm_memory_map(chan->engn[engn].inst, 0, chan->base.vmm,
 			       &chan->engn[engn].vma, NULL, 0);
 }
 
@@ -199,10 +199,7 @@ gf100_fifo_gpfifo_init(struct nvkm_fifo_chan *base)
 static void *
 gf100_fifo_gpfifo_dtor(struct nvkm_fifo_chan *base)
 {
-	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
-	if (chan->base.inst)
-		nvkm_vm_ref(NULL, &chan->vm, chan->base.inst->memory);
-	return chan;
+	return gf100_fifo_chan(base);
 }
 
 static const struct nvkm_fifo_chan_func
@@ -262,10 +259,6 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 
 	args->v0.chid = chan->base.chid;
 
-	ret = nvkm_vm_ref(chan->base.vm, &chan->vm, chan->base.inst->memory);
-	if (ret)
-		return ret;
-
 	/* clear channel control registers */
 
 	usermem = chan->base.chid * 0x1000;

commit d30af7ce2c96e57b503da1d70454818331f0a6d5
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu: handle instance block setup
    
    We previously required each VMM user to allocate their own page directory
    and fill in the instance block themselves.
    
    It makes more sense to handle this in a common location.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 6343e0c84d96..695d0721b1ad 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -200,8 +200,8 @@ static void *
 gf100_fifo_gpfifo_dtor(struct nvkm_fifo_chan *base)
 {
 	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
-	nvkm_vm_ref(NULL, &chan->vm, chan->pgd);
-	nvkm_gpuobj_del(&chan->pgd);
+	if (chan->base.inst)
+		nvkm_vm_ref(NULL, &chan->vm, chan->base.inst->memory);
 	return chan;
 }
 
@@ -225,7 +225,6 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 		struct fermi_channel_gpfifo_v0 v0;
 	} *args = data;
 	struct gf100_fifo *fifo = gf100_fifo(base);
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_object *parent = oclass->parent;
 	struct gf100_fifo_chan *chan;
 	u64 usermem, ioffset, ilength;
@@ -263,19 +262,7 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 
 	args->v0.chid = chan->base.chid;
 
-	/* page directory */
-	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &chan->pgd);
-	if (ret)
-		return ret;
-
-	nvkm_kmap(chan->base.inst);
-	nvkm_wo32(chan->base.inst, 0x0200, lower_32_bits(chan->pgd->addr));
-	nvkm_wo32(chan->base.inst, 0x0204, upper_32_bits(chan->pgd->addr));
-	nvkm_wo32(chan->base.inst, 0x0208, 0xffffffff);
-	nvkm_wo32(chan->base.inst, 0x020c, 0x000000ff);
-	nvkm_done(chan->base.inst);
-
-	ret = nvkm_vm_ref(chan->base.vm, &chan->vm, chan->pgd);
+	ret = nvkm_vm_ref(chan->base.vm, &chan->vm, chan->base.inst->memory);
 	if (ret)
 		return ret;
 

commit 19a82e492c3d71efe8763d50496a1701dfcf3f15
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/memory: change map interface to support upcoming mmu changes
    
    Map flags (access, kind, etc) are currently defined in either the VMA,
    or the memory object, which turns out to not be ideal for things like
    suballocated buffers, etc.
    
    These will become per-map flags instead, so we need to support passing
    these arguments in nvkm_memory_map().
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index f9e0377d3d24..6343e0c84d96 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -126,7 +126,11 @@ gf100_fifo_gpfifo_engine_dtor(struct nvkm_fifo_chan *base,
 			      struct nvkm_engine *engine)
 {
 	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
-	nvkm_gpuobj_unmap(&chan->engn[engine->subdev.index].vma);
+	struct nvkm_vma *vma = &chan->engn[engine->subdev.index].vma;
+	if (vma->vm) {
+		nvkm_vm_unmap(vma);
+		nvkm_vm_put(vma);
+	}
 	nvkm_gpuobj_del(&chan->engn[engine->subdev.index].inst);
 }
 
@@ -146,8 +150,13 @@ gf100_fifo_gpfifo_engine_ctor(struct nvkm_fifo_chan *base,
 	if (ret)
 		return ret;
 
-	return nvkm_gpuobj_map(chan->engn[engn].inst, chan->vm,
-			       NV_MEM_ACCESS_RW, &chan->engn[engn].vma);
+	ret = nvkm_vm_get(chan->vm, chan->engn[engn].inst->size, 12,
+			  NV_MEM_ACCESS_RW, &chan->engn[engn].vma);
+	if (ret)
+		return ret;
+
+	return nvkm_memory_map(chan->engn[engn].inst, 0, chan->vm,
+			       &chan->engn[engn].vma, NULL, 0);
 }
 
 static void

commit ff9f29abf0ef4c43e696bef7621884518e6bdbda
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Sat Nov 5 13:05:14 2016 +1000

    drm/nouveau/fifo/gf100-: provide notification to user if channel is killed
    
    There are instances (such as non-recoverable GPU page faults) where
    NVKM decides that a channel's context is no longer viable, and will
    be removed from the runlist.
    
    This commit notifies the owner of the channel when this happens, so
    it has the opportunity to take some kind of recovery action instead
    of hanging.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 12d964260a29..f9e0377d3d24 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -32,6 +32,23 @@
 #include <nvif/cl906f.h>
 #include <nvif/unpack.h>
 
+int
+gf100_fifo_chan_ntfy(struct nvkm_fifo_chan *chan, u32 type,
+		     struct nvkm_event **pevent)
+{
+	switch (type) {
+	case NV906F_V0_NTFY_NON_STALL_INTERRUPT:
+		*pevent = &chan->fifo->uevent;
+		return 0;
+	case NV906F_V0_NTFY_KILLED:
+		*pevent = &chan->fifo->kevent;
+		return 0;
+	default:
+		break;
+	}
+	return -EINVAL;
+}
+
 static u32
 gf100_fifo_gpfifo_engine_addr(struct nvkm_engine *engine)
 {
@@ -184,7 +201,7 @@ gf100_fifo_gpfifo_func = {
 	.dtor = gf100_fifo_gpfifo_dtor,
 	.init = gf100_fifo_gpfifo_init,
 	.fini = gf100_fifo_gpfifo_fini,
-	.ntfy = g84_fifo_chan_ntfy,
+	.ntfy = gf100_fifo_chan_ntfy,
 	.engine_ctor = gf100_fifo_gpfifo_engine_ctor,
 	.engine_dtor = gf100_fifo_gpfifo_engine_dtor,
 	.engine_init = gf100_fifo_gpfifo_engine_init,

commit b27add13f500469127afdf011dbcc9c649e16e54
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Sat Nov 5 14:33:14 2016 +1000

    drm/nouveau/fifo/gf100-: protect channel preempt with subdev mutex
    
    This avoids an issue that occurs when we're attempting to preempt multiple
    channels simultaneously.  HW seems to ignore preempt requests while it's
    still processing a previous one, which, well, makes sense.
    
    Fixes random "fifo: SCHED_ERROR 0d []" + GPCCS page faults during parallel
    piglit runs on (at least) GM107.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index cbc67f262322..12d964260a29 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -60,6 +60,7 @@ gf100_fifo_gpfifo_engine_fini(struct nvkm_fifo_chan *base,
 	struct nvkm_gpuobj *inst = chan->base.inst;
 	int ret = 0;
 
+	mutex_lock(&subdev->mutex);
 	nvkm_wr32(device, 0x002634, chan->base.chid);
 	if (nvkm_msec(device, 2000,
 		if (nvkm_rd32(device, 0x002634) == chan->base.chid)
@@ -67,10 +68,12 @@ gf100_fifo_gpfifo_engine_fini(struct nvkm_fifo_chan *base,
 	) < 0) {
 		nvkm_error(subdev, "channel %d [%s] kick timeout\n",
 			   chan->base.chid, chan->base.object.client->name);
-		ret = -EBUSY;
-		if (suspend)
-			return ret;
+		ret = -ETIMEDOUT;
 	}
+	mutex_unlock(&subdev->mutex);
+
+	if (ret && suspend)
+		return ret;
 
 	if (offset) {
 		nvkm_kmap(inst);

commit f01c4e682c941ba70e0ebec44db754844a1b9b82
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Mon Nov 9 09:21:27 2015 +1000

    drm/nouveau/nvif: modify nvif_unvers/nvif_unpack macros to be more obvious
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 8db9cf018c89..cbc67f262322 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -200,10 +200,10 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 	struct nvkm_object *parent = oclass->parent;
 	struct gf100_fifo_chan *chan;
 	u64 usermem, ioffset, ilength;
-	int ret, i;
+	int ret = -ENOSYS, i;
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
-	if (nvif_unpack(args->v0, 0, 0, false)) {
+	if (!(ret = nvif_unpack(ret, &data, &size, args->v0, 0, 0, false))) {
 		nvif_ioctl(parent, "create channel gpfifo vers %d vm %llx "
 				   "ioffset %016llx ilength %08x\n",
 			   args->v0.version, args->v0.vm, args->v0.ioffset,

commit 8ed1730ccd6cf2a84243456e371a5f4484be60f5
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Sun Nov 8 11:28:26 2015 +1000

    drm/nouveau/nvif: split out fifo interface definitions
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 3f3767518558..8db9cf018c89 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -29,6 +29,7 @@
 #include <subdev/timer.h>
 
 #include <nvif/class.h>
+#include <nvif/cl906f.h>
 #include <nvif/unpack.h>
 
 static u32

commit d40d0fd487375c66ed444ec2bbd5ffa5d64ebede
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 11 10:07:22 2015 +1000

    drm/nouveau/fifo/gf100: fix race condition when updating engine runlists
    
    Similar in spirit to the gk104 fix with a similar title.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index e7cbc139c1d4..3f3767518558 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -138,9 +138,9 @@ gf100_fifo_gpfifo_fini(struct nvkm_fifo_chan *base)
 	u32 coff = chan->base.chid * 8;
 
 	if (!list_empty(&chan->head) && !chan->killed) {
-		list_del_init(&chan->head);
+		gf100_fifo_runlist_remove(fifo, chan);
 		nvkm_mask(device, 0x003004 + coff, 0x00000001, 0x00000000);
-		gf100_fifo_runlist_update(fifo);
+		gf100_fifo_runlist_commit(fifo);
 	}
 
 	gf100_fifo_intr_engine(fifo);
@@ -160,9 +160,9 @@ gf100_fifo_gpfifo_init(struct nvkm_fifo_chan *base)
 	nvkm_wr32(device, 0x003000 + coff, 0xc0000000 | addr);
 
 	if (list_empty(&chan->head) && !chan->killed) {
-		list_add_tail(&chan->head, &fifo->chan);
+		gf100_fifo_runlist_insert(fifo, chan);
 		nvkm_wr32(device, 0x003004 + coff, 0x001f0001);
-		gf100_fifo_runlist_update(fifo);
+		gf100_fifo_runlist_commit(fifo);
 	}
 }
 

commit 68f3f702b6a430a8d1e909455a60d26c0f2da530
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/core: remove the remainder of the previous style
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 5d76c3013a80..e7cbc139c1d4 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -35,13 +35,13 @@ static u32
 gf100_fifo_gpfifo_engine_addr(struct nvkm_engine *engine)
 {
 	switch (engine->subdev.index) {
-	case NVDEV_ENGINE_SW    : return 0;
-	case NVDEV_ENGINE_GR    : return 0x0210;
-	case NVDEV_ENGINE_CE0   : return 0x0230;
-	case NVDEV_ENGINE_CE1   : return 0x0240;
-	case NVDEV_ENGINE_MSPDEC: return 0x0250;
-	case NVDEV_ENGINE_MSPPP : return 0x0260;
-	case NVDEV_ENGINE_MSVLD : return 0x0270;
+	case NVKM_ENGINE_SW    : return 0;
+	case NVKM_ENGINE_GR    : return 0x0210;
+	case NVKM_ENGINE_CE0   : return 0x0230;
+	case NVKM_ENGINE_CE1   : return 0x0240;
+	case NVKM_ENGINE_MSPDEC: return 0x0250;
+	case NVKM_ENGINE_MSPPP : return 0x0260;
+	case NVKM_ENGINE_MSVLD : return 0x0270;
 	default:
 		WARN_ON(1);
 		return 0;
@@ -121,12 +121,6 @@ gf100_fifo_gpfifo_engine_ctor(struct nvkm_fifo_chan *base,
 	if (!gf100_fifo_gpfifo_engine_addr(engine))
 		return 0;
 
-	if (object->oclass) {
-		return nvkm_gpuobj_map(nv_gpuobj(object), chan->vm,
-				       NV_MEM_ACCESS_RW,
-				       &chan->engn[engn].vma);
-	}
-
 	ret = nvkm_object_bind(object, NULL, 0, &chan->engn[engn].inst);
 	if (ret)
 		return ret;
@@ -225,13 +219,13 @@ gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
 
 	ret = nvkm_fifo_chan_ctor(&gf100_fifo_gpfifo_func, &fifo->base,
 				  0x1000, 0x1000, true, args->v0.vm, 0,
-				  (1ULL << NVDEV_ENGINE_CE0) |
-				  (1ULL << NVDEV_ENGINE_CE1) |
-				  (1ULL << NVDEV_ENGINE_GR) |
-				  (1ULL << NVDEV_ENGINE_MSPDEC) |
-				  (1ULL << NVDEV_ENGINE_MSPPP) |
-				  (1ULL << NVDEV_ENGINE_MSVLD) |
-				  (1ULL << NVDEV_ENGINE_SW),
+				  (1ULL << NVKM_ENGINE_CE0) |
+				  (1ULL << NVKM_ENGINE_CE1) |
+				  (1ULL << NVKM_ENGINE_GR) |
+				  (1ULL << NVKM_ENGINE_MSPDEC) |
+				  (1ULL << NVKM_ENGINE_MSPPP) |
+				  (1ULL << NVKM_ENGINE_MSVLD) |
+				  (1ULL << NVKM_ENGINE_SW),
 				  1, fifo->user.bar.offset, 0x1000,
 				  oclass, &chan->base);
 	if (ret)

commit 13de7f462902d1a452d501cdb2d06ef02cabbfff
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/fifo: convert to new-style nvkm_engine
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index eb9195a6f375..5d76c3013a80 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -24,6 +24,7 @@
 #include "changf100.h"
 
 #include <core/client.h>
+#include <core/gpuobj.h>
 #include <subdev/fb.h>
 #include <subdev/timer.h>
 

commit 8f0649b5c6e70ec18122255690e39f010c12a614
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:19 2015 +1000

    drm/nouveau/fifo: convert user classes to new-style nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
index 7fd6401ca905..eb9195a6f375 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -30,29 +30,33 @@
 #include <nvif/class.h>
 #include <nvif/unpack.h>
 
-static int
-gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
-			  struct nvkm_object *object)
+static u32
+gf100_fifo_gpfifo_engine_addr(struct nvkm_engine *engine)
 {
-	struct gf100_fifo *fifo = (void *)parent->engine;
-	struct gf100_fifo_base *base = (void *)parent->parent;
-	struct gf100_fifo_chan *chan = (void *)parent;
-	struct nvkm_gpuobj *engn = &base->base.gpuobj;
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
-	u32 addr;
-
-	switch (nv_engidx(object->engine)) {
+	switch (engine->subdev.index) {
 	case NVDEV_ENGINE_SW    : return 0;
-	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
-	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
-	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
-	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
-	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
-	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
+	case NVDEV_ENGINE_GR    : return 0x0210;
+	case NVDEV_ENGINE_CE0   : return 0x0230;
+	case NVDEV_ENGINE_CE1   : return 0x0240;
+	case NVDEV_ENGINE_MSPDEC: return 0x0250;
+	case NVDEV_ENGINE_MSPPP : return 0x0260;
+	case NVDEV_ENGINE_MSVLD : return 0x0270;
 	default:
-		return -EINVAL;
+		WARN_ON(1);
+		return 0;
 	}
+}
+
+static int
+gf100_fifo_gpfifo_engine_fini(struct nvkm_fifo_chan *base,
+			      struct nvkm_engine *engine, bool suspend)
+{
+	const u32 offset = gf100_fifo_gpfifo_engine_addr(engine);
+	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
+	struct nvkm_subdev *subdev = &chan->fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	struct nvkm_gpuobj *inst = chan->base.inst;
+	int ret = 0;
 
 	nvkm_wr32(device, 0x002634, chan->base.chid);
 	if (nvkm_msec(device, 2000,
@@ -60,143 +64,197 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 			break;
 	) < 0) {
 		nvkm_error(subdev, "channel %d [%s] kick timeout\n",
-			   chan->base.chid, nvkm_client_name(chan));
+			   chan->base.chid, chan->base.object.client->name);
+		ret = -EBUSY;
 		if (suspend)
-			return -EBUSY;
+			return ret;
+	}
+
+	if (offset) {
+		nvkm_kmap(inst);
+		nvkm_wo32(inst, offset + 0x00, 0x00000000);
+		nvkm_wo32(inst, offset + 0x04, 0x00000000);
+		nvkm_done(inst);
+	}
+
+	return ret;
+}
+
+static int
+gf100_fifo_gpfifo_engine_init(struct nvkm_fifo_chan *base,
+			      struct nvkm_engine *engine)
+{
+	const u32 offset = gf100_fifo_gpfifo_engine_addr(engine);
+	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
+	struct nvkm_gpuobj *inst = chan->base.inst;
+
+	if (offset) {
+		u64 addr = chan->engn[engine->subdev.index].vma.offset;
+		nvkm_kmap(inst);
+		nvkm_wo32(inst, offset + 0x00, lower_32_bits(addr) | 4);
+		nvkm_wo32(inst, offset + 0x04, upper_32_bits(addr));
+		nvkm_done(inst);
 	}
 
-	nvkm_kmap(engn);
-	nvkm_wo32(engn, addr + 0x00, 0x00000000);
-	nvkm_wo32(engn, addr + 0x04, 0x00000000);
-	nvkm_done(engn);
 	return 0;
 }
 
+static void
+gf100_fifo_gpfifo_engine_dtor(struct nvkm_fifo_chan *base,
+			      struct nvkm_engine *engine)
+{
+	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
+	nvkm_gpuobj_unmap(&chan->engn[engine->subdev.index].vma);
+	nvkm_gpuobj_del(&chan->engn[engine->subdev.index].inst);
+}
+
 static int
-gf100_fifo_context_attach(struct nvkm_object *parent,
-			  struct nvkm_object *object)
+gf100_fifo_gpfifo_engine_ctor(struct nvkm_fifo_chan *base,
+			      struct nvkm_engine *engine,
+			      struct nvkm_object *object)
 {
-	struct gf100_fifo_base *base = (void *)parent->parent;
-	struct nvkm_gpuobj *engn = &base->base.gpuobj;
-	struct nvkm_engctx *ectx = (void *)object;
-	u32 addr;
+	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
+	int engn = engine->subdev.index;
 	int ret;
 
-	switch (nv_engidx(object->engine)) {
-	case NVDEV_ENGINE_SW    : return 0;
-	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
-	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
-	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
-	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
-	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
-	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
-	default:
-		return -EINVAL;
-	}
-
-	if (!ectx->vma.node) {
-		ret = nvkm_gpuobj_map(nv_gpuobj(ectx), base->vm,
-				      NV_MEM_ACCESS_RW, &ectx->vma);
-		if (ret)
-			return ret;
+	if (!gf100_fifo_gpfifo_engine_addr(engine))
+		return 0;
 
-		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
+	if (object->oclass) {
+		return nvkm_gpuobj_map(nv_gpuobj(object), chan->vm,
+				       NV_MEM_ACCESS_RW,
+				       &chan->engn[engn].vma);
 	}
 
-	nvkm_kmap(engn);
-	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
-	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
-	nvkm_done(engn);
-	return 0;
+	ret = nvkm_object_bind(object, NULL, 0, &chan->engn[engn].inst);
+	if (ret)
+		return ret;
+
+	return nvkm_gpuobj_map(chan->engn[engn].inst, chan->vm,
+			       NV_MEM_ACCESS_RW, &chan->engn[engn].vma);
 }
 
-static int
-gf100_fifo_chan_fini(struct nvkm_object *object, bool suspend)
+static void
+gf100_fifo_gpfifo_fini(struct nvkm_fifo_chan *base)
 {
-	struct gf100_fifo *fifo = (void *)object->engine;
-	struct gf100_fifo_chan *chan = (void *)object;
+	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
+	struct gf100_fifo *fifo = chan->fifo;
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	u32 chid = chan->base.chid;
+	u32 coff = chan->base.chid * 8;
 
-	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
-		nvkm_mask(device, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
+	if (!list_empty(&chan->head) && !chan->killed) {
+		list_del_init(&chan->head);
+		nvkm_mask(device, 0x003004 + coff, 0x00000001, 0x00000000);
 		gf100_fifo_runlist_update(fifo);
 	}
 
 	gf100_fifo_intr_engine(fifo);
 
-	nvkm_wr32(device, 0x003000 + (chid * 8), 0x00000000);
-	return nvkm_fifo_channel_fini(&chan->base, suspend);
+	nvkm_wr32(device, 0x003000 + coff, 0x00000000);
 }
 
-static int
-gf100_fifo_chan_init(struct nvkm_object *object)
+static void
+gf100_fifo_gpfifo_init(struct nvkm_fifo_chan *base)
 {
-	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
-	struct gf100_fifo *fifo = (void *)object->engine;
-	struct gf100_fifo_chan *chan = (void *)object;
+	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
+	struct gf100_fifo *fifo = chan->fifo;
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	u32 chid = chan->base.chid;
-	int ret;
-
-	ret = nvkm_fifo_channel_init(&chan->base);
-	if (ret)
-		return ret;
+	u32 addr = chan->base.inst->addr >> 12;
+	u32 coff = chan->base.chid * 8;
 
-	nvkm_wr32(device, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
+	nvkm_wr32(device, 0x003000 + coff, 0xc0000000 | addr);
 
-	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
-		nvkm_wr32(device, 0x003004 + (chid * 8), 0x001f0001);
+	if (list_empty(&chan->head) && !chan->killed) {
+		list_add_tail(&chan->head, &fifo->chan);
+		nvkm_wr32(device, 0x003004 + coff, 0x001f0001);
 		gf100_fifo_runlist_update(fifo);
 	}
+}
 
-	return 0;
+static void *
+gf100_fifo_gpfifo_dtor(struct nvkm_fifo_chan *base)
+{
+	struct gf100_fifo_chan *chan = gf100_fifo_chan(base);
+	nvkm_vm_ref(NULL, &chan->vm, chan->pgd);
+	nvkm_gpuobj_del(&chan->pgd);
+	return chan;
 }
 
+static const struct nvkm_fifo_chan_func
+gf100_fifo_gpfifo_func = {
+	.dtor = gf100_fifo_gpfifo_dtor,
+	.init = gf100_fifo_gpfifo_init,
+	.fini = gf100_fifo_gpfifo_fini,
+	.ntfy = g84_fifo_chan_ntfy,
+	.engine_ctor = gf100_fifo_gpfifo_engine_ctor,
+	.engine_dtor = gf100_fifo_gpfifo_engine_dtor,
+	.engine_init = gf100_fifo_gpfifo_engine_init,
+	.engine_fini = gf100_fifo_gpfifo_engine_fini,
+};
+
 static int
-gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-		     struct nvkm_oclass *oclass, void *data, u32 size,
-		     struct nvkm_object **pobject)
+gf100_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,
+		      void *data, u32 size, struct nvkm_object **pobject)
 {
 	union {
 		struct fermi_channel_gpfifo_v0 v0;
 	} *args = data;
-	struct gf100_fifo *fifo = (void *)engine;
-	struct gf100_fifo_base *base = (void *)parent;
+	struct gf100_fifo *fifo = gf100_fifo(base);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_object *parent = oclass->parent;
 	struct gf100_fifo_chan *chan;
-	struct nvkm_gpuobj *ramfc = &base->base.gpuobj;
 	u64 usermem, ioffset, ilength;
 	int ret, i;
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d vm %llx"
+		nvif_ioctl(parent, "create channel gpfifo vers %d vm %llx "
 				   "ioffset %016llx ilength %08x\n",
 			   args->v0.version, args->v0.vm, args->v0.ioffset,
 			   args->v0.ilength);
-		if (args->v0.vm)
-			return -ENOENT;
 	} else
 		return ret;
 
-	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
-				       fifo->user.bar.offset, 0x1000, 0,
-				       (1ULL << NVDEV_ENGINE_SW) |
-				       (1ULL << NVDEV_ENGINE_GR) |
-				       (1ULL << NVDEV_ENGINE_CE0) |
-				       (1ULL << NVDEV_ENGINE_CE1) |
-				       (1ULL << NVDEV_ENGINE_MSVLD) |
-				       (1ULL << NVDEV_ENGINE_MSPDEC) |
-				       (1ULL << NVDEV_ENGINE_MSPPP), &chan);
-	*pobject = nv_object(chan);
+	/* allocate channel */
+	if (!(chan = kzalloc(sizeof(*chan), GFP_KERNEL)))
+		return -ENOMEM;
+	*pobject = &chan->base.object;
+	chan->fifo = fifo;
+	INIT_LIST_HEAD(&chan->head);
+
+	ret = nvkm_fifo_chan_ctor(&gf100_fifo_gpfifo_func, &fifo->base,
+				  0x1000, 0x1000, true, args->v0.vm, 0,
+				  (1ULL << NVDEV_ENGINE_CE0) |
+				  (1ULL << NVDEV_ENGINE_CE1) |
+				  (1ULL << NVDEV_ENGINE_GR) |
+				  (1ULL << NVDEV_ENGINE_MSPDEC) |
+				  (1ULL << NVDEV_ENGINE_MSPPP) |
+				  (1ULL << NVDEV_ENGINE_MSVLD) |
+				  (1ULL << NVDEV_ENGINE_SW),
+				  1, fifo->user.bar.offset, 0x1000,
+				  oclass, &chan->base);
 	if (ret)
 		return ret;
 
-	chan->base.inst = base->base.gpuobj.addr;
 	args->v0.chid = chan->base.chid;
 
-	nv_parent(chan)->context_attach = gf100_fifo_context_attach;
-	nv_parent(chan)->context_detach = gf100_fifo_context_detach;
+	/* page directory */
+	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &chan->pgd);
+	if (ret)
+		return ret;
+
+	nvkm_kmap(chan->base.inst);
+	nvkm_wo32(chan->base.inst, 0x0200, lower_32_bits(chan->pgd->addr));
+	nvkm_wo32(chan->base.inst, 0x0204, upper_32_bits(chan->pgd->addr));
+	nvkm_wo32(chan->base.inst, 0x0208, 0xffffffff);
+	nvkm_wo32(chan->base.inst, 0x020c, 0x000000ff);
+	nvkm_done(chan->base.inst);
+
+	ret = nvkm_vm_ref(chan->base.vm, &chan->vm, chan->pgd);
+	if (ret)
+		return ret;
+
+	/* clear channel control registers */
 
 	usermem = chan->base.chid * 0x1000;
 	ioffset = args->v0.ioffset;
@@ -208,97 +266,33 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	nvkm_done(fifo->user.mem);
 	usermem = nvkm_memory_addr(fifo->user.mem) + usermem;
 
-	nvkm_kmap(ramfc);
-	nvkm_wo32(ramfc, 0x08, lower_32_bits(usermem));
-	nvkm_wo32(ramfc, 0x0c, upper_32_bits(usermem));
-	nvkm_wo32(ramfc, 0x10, 0x0000face);
-	nvkm_wo32(ramfc, 0x30, 0xfffff902);
-	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
-	nvkm_wo32(ramfc, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
-	nvkm_wo32(ramfc, 0x54, 0x00000002);
-	nvkm_wo32(ramfc, 0x84, 0x20400000);
-	nvkm_wo32(ramfc, 0x94, 0x30000001);
-	nvkm_wo32(ramfc, 0x9c, 0x00000100);
-	nvkm_wo32(ramfc, 0xa4, 0x1f1f1f1f);
-	nvkm_wo32(ramfc, 0xa8, 0x1f1f1f1f);
-	nvkm_wo32(ramfc, 0xac, 0x0000001f);
-	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
-	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
-	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
-	nvkm_done(ramfc);
-	return 0;
-}
-
-static struct nvkm_ofuncs
-gf100_fifo_ofuncs = {
-	.ctor = gf100_fifo_chan_ctor,
-	.dtor = _nvkm_fifo_channel_dtor,
-	.init = gf100_fifo_chan_init,
-	.fini = gf100_fifo_chan_fini,
-	.map  = _nvkm_fifo_channel_map,
-	.rd32 = _nvkm_fifo_channel_rd32,
-	.wr32 = _nvkm_fifo_channel_wr32,
-	.ntfy = _nvkm_fifo_channel_ntfy
-};
-
-struct nvkm_oclass
-gf100_fifo_sclass[] = {
-	{ FERMI_CHANNEL_GPFIFO, &gf100_fifo_ofuncs },
-	{}
-};
-
-static int
-gf100_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-			struct nvkm_oclass *oclass, void *data, u32 size,
-			struct nvkm_object **pobject)
-{
-	struct nvkm_device *device = nv_engine(engine)->subdev.device;
-	struct gf100_fifo_base *base;
-	int ret;
-
-	ret = nvkm_fifo_context_create(parent, engine, oclass, NULL, 0x1000,
-				       0x1000, NVOBJ_FLAG_ZERO_ALLOC |
-				       NVOBJ_FLAG_HEAP, &base);
-	*pobject = nv_object(base);
-	if (ret)
-		return ret;
-
-	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &base->pgd);
-	if (ret)
-		return ret;
-
-	nvkm_kmap(&base->base.gpuobj);
-	nvkm_wo32(&base->base.gpuobj, 0x0200, lower_32_bits(base->pgd->addr));
-	nvkm_wo32(&base->base.gpuobj, 0x0204, upper_32_bits(base->pgd->addr));
-	nvkm_wo32(&base->base.gpuobj, 0x0208, 0xffffffff);
-	nvkm_wo32(&base->base.gpuobj, 0x020c, 0x000000ff);
-	nvkm_done(&base->base.gpuobj);
-
-	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
-	if (ret)
-		return ret;
-
+	/* RAMFC */
+	nvkm_kmap(chan->base.inst);
+	nvkm_wo32(chan->base.inst, 0x08, lower_32_bits(usermem));
+	nvkm_wo32(chan->base.inst, 0x0c, upper_32_bits(usermem));
+	nvkm_wo32(chan->base.inst, 0x10, 0x0000face);
+	nvkm_wo32(chan->base.inst, 0x30, 0xfffff902);
+	nvkm_wo32(chan->base.inst, 0x48, lower_32_bits(ioffset));
+	nvkm_wo32(chan->base.inst, 0x4c, upper_32_bits(ioffset) |
+					 (ilength << 16));
+	nvkm_wo32(chan->base.inst, 0x54, 0x00000002);
+	nvkm_wo32(chan->base.inst, 0x84, 0x20400000);
+	nvkm_wo32(chan->base.inst, 0x94, 0x30000001);
+	nvkm_wo32(chan->base.inst, 0x9c, 0x00000100);
+	nvkm_wo32(chan->base.inst, 0xa4, 0x1f1f1f1f);
+	nvkm_wo32(chan->base.inst, 0xa8, 0x1f1f1f1f);
+	nvkm_wo32(chan->base.inst, 0xac, 0x0000001f);
+	nvkm_wo32(chan->base.inst, 0xb8, 0xf8000000);
+	nvkm_wo32(chan->base.inst, 0xf8, 0x10003080); /* 0x002310 */
+	nvkm_wo32(chan->base.inst, 0xfc, 0x10000010); /* 0x002350 */
+	nvkm_done(chan->base.inst);
 	return 0;
 }
 
-static void
-gf100_fifo_context_dtor(struct nvkm_object *object)
-{
-	struct gf100_fifo_base *base = (void *)object;
-	nvkm_vm_ref(NULL, &base->vm, base->pgd);
-	nvkm_gpuobj_del(&base->pgd);
-	nvkm_fifo_context_destroy(&base->base);
-}
-
-struct nvkm_oclass
-gf100_fifo_cclass = {
-	.handle = NV_ENGCTX(FIFO, 0xc0),
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = gf100_fifo_context_ctor,
-		.dtor = gf100_fifo_context_dtor,
-		.init = _nvkm_fifo_context_init,
-		.fini = _nvkm_fifo_context_fini,
-		.rd32 = _nvkm_fifo_context_rd32,
-		.wr32 = _nvkm_fifo_context_wr32,
-	},
+const struct nvkm_fifo_chan_oclass
+gf100_fifo_gpfifo_oclass = {
+	.base.oclass = FERMI_CHANNEL_GPFIFO,
+	.base.minver = 0,
+	.base.maxver = 0,
+	.ctor = gf100_fifo_gpfifo_new,
 };

commit 9a65a38c456ebac97f0498e85fe26f6d26fe3936
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:19 2015 +1000

    drm/nouveau/fifo: split user classes out from engine implementations
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
new file mode 100644
index 000000000000..7fd6401ca905
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gpfifogf100.c
@@ -0,0 +1,304 @@
+/*
+ * Copyright 2012 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+#include "changf100.h"
+
+#include <core/client.h>
+#include <subdev/fb.h>
+#include <subdev/timer.h>
+
+#include <nvif/class.h>
+#include <nvif/unpack.h>
+
+static int
+gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
+			  struct nvkm_object *object)
+{
+	struct gf100_fifo *fifo = (void *)parent->engine;
+	struct gf100_fifo_base *base = (void *)parent->parent;
+	struct gf100_fifo_chan *chan = (void *)parent;
+	struct nvkm_gpuobj *engn = &base->base.gpuobj;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	u32 addr;
+
+	switch (nv_engidx(object->engine)) {
+	case NVDEV_ENGINE_SW    : return 0;
+	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
+	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
+	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
+	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
+	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
+	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
+	default:
+		return -EINVAL;
+	}
+
+	nvkm_wr32(device, 0x002634, chan->base.chid);
+	if (nvkm_msec(device, 2000,
+		if (nvkm_rd32(device, 0x002634) == chan->base.chid)
+			break;
+	) < 0) {
+		nvkm_error(subdev, "channel %d [%s] kick timeout\n",
+			   chan->base.chid, nvkm_client_name(chan));
+		if (suspend)
+			return -EBUSY;
+	}
+
+	nvkm_kmap(engn);
+	nvkm_wo32(engn, addr + 0x00, 0x00000000);
+	nvkm_wo32(engn, addr + 0x04, 0x00000000);
+	nvkm_done(engn);
+	return 0;
+}
+
+static int
+gf100_fifo_context_attach(struct nvkm_object *parent,
+			  struct nvkm_object *object)
+{
+	struct gf100_fifo_base *base = (void *)parent->parent;
+	struct nvkm_gpuobj *engn = &base->base.gpuobj;
+	struct nvkm_engctx *ectx = (void *)object;
+	u32 addr;
+	int ret;
+
+	switch (nv_engidx(object->engine)) {
+	case NVDEV_ENGINE_SW    : return 0;
+	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
+	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
+	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
+	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
+	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
+	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
+	default:
+		return -EINVAL;
+	}
+
+	if (!ectx->vma.node) {
+		ret = nvkm_gpuobj_map(nv_gpuobj(ectx), base->vm,
+				      NV_MEM_ACCESS_RW, &ectx->vma);
+		if (ret)
+			return ret;
+
+		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
+	}
+
+	nvkm_kmap(engn);
+	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
+	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
+	nvkm_done(engn);
+	return 0;
+}
+
+static int
+gf100_fifo_chan_fini(struct nvkm_object *object, bool suspend)
+{
+	struct gf100_fifo *fifo = (void *)object->engine;
+	struct gf100_fifo_chan *chan = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 chid = chan->base.chid;
+
+	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
+		nvkm_mask(device, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
+		gf100_fifo_runlist_update(fifo);
+	}
+
+	gf100_fifo_intr_engine(fifo);
+
+	nvkm_wr32(device, 0x003000 + (chid * 8), 0x00000000);
+	return nvkm_fifo_channel_fini(&chan->base, suspend);
+}
+
+static int
+gf100_fifo_chan_init(struct nvkm_object *object)
+{
+	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
+	struct gf100_fifo *fifo = (void *)object->engine;
+	struct gf100_fifo_chan *chan = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 chid = chan->base.chid;
+	int ret;
+
+	ret = nvkm_fifo_channel_init(&chan->base);
+	if (ret)
+		return ret;
+
+	nvkm_wr32(device, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
+
+	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
+		nvkm_wr32(device, 0x003004 + (chid * 8), 0x001f0001);
+		gf100_fifo_runlist_update(fifo);
+	}
+
+	return 0;
+}
+
+static int
+gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+		     struct nvkm_oclass *oclass, void *data, u32 size,
+		     struct nvkm_object **pobject)
+{
+	union {
+		struct fermi_channel_gpfifo_v0 v0;
+	} *args = data;
+	struct gf100_fifo *fifo = (void *)engine;
+	struct gf100_fifo_base *base = (void *)parent;
+	struct gf100_fifo_chan *chan;
+	struct nvkm_gpuobj *ramfc = &base->base.gpuobj;
+	u64 usermem, ioffset, ilength;
+	int ret, i;
+
+	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
+	if (nvif_unpack(args->v0, 0, 0, false)) {
+		nvif_ioctl(parent, "create channel gpfifo vers %d vm %llx"
+				   "ioffset %016llx ilength %08x\n",
+			   args->v0.version, args->v0.vm, args->v0.ioffset,
+			   args->v0.ilength);
+		if (args->v0.vm)
+			return -ENOENT;
+	} else
+		return ret;
+
+	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
+				       fifo->user.bar.offset, 0x1000, 0,
+				       (1ULL << NVDEV_ENGINE_SW) |
+				       (1ULL << NVDEV_ENGINE_GR) |
+				       (1ULL << NVDEV_ENGINE_CE0) |
+				       (1ULL << NVDEV_ENGINE_CE1) |
+				       (1ULL << NVDEV_ENGINE_MSVLD) |
+				       (1ULL << NVDEV_ENGINE_MSPDEC) |
+				       (1ULL << NVDEV_ENGINE_MSPPP), &chan);
+	*pobject = nv_object(chan);
+	if (ret)
+		return ret;
+
+	chan->base.inst = base->base.gpuobj.addr;
+	args->v0.chid = chan->base.chid;
+
+	nv_parent(chan)->context_attach = gf100_fifo_context_attach;
+	nv_parent(chan)->context_detach = gf100_fifo_context_detach;
+
+	usermem = chan->base.chid * 0x1000;
+	ioffset = args->v0.ioffset;
+	ilength = order_base_2(args->v0.ilength / 8);
+
+	nvkm_kmap(fifo->user.mem);
+	for (i = 0; i < 0x1000; i += 4)
+		nvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);
+	nvkm_done(fifo->user.mem);
+	usermem = nvkm_memory_addr(fifo->user.mem) + usermem;
+
+	nvkm_kmap(ramfc);
+	nvkm_wo32(ramfc, 0x08, lower_32_bits(usermem));
+	nvkm_wo32(ramfc, 0x0c, upper_32_bits(usermem));
+	nvkm_wo32(ramfc, 0x10, 0x0000face);
+	nvkm_wo32(ramfc, 0x30, 0xfffff902);
+	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
+	nvkm_wo32(ramfc, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
+	nvkm_wo32(ramfc, 0x54, 0x00000002);
+	nvkm_wo32(ramfc, 0x84, 0x20400000);
+	nvkm_wo32(ramfc, 0x94, 0x30000001);
+	nvkm_wo32(ramfc, 0x9c, 0x00000100);
+	nvkm_wo32(ramfc, 0xa4, 0x1f1f1f1f);
+	nvkm_wo32(ramfc, 0xa8, 0x1f1f1f1f);
+	nvkm_wo32(ramfc, 0xac, 0x0000001f);
+	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
+	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
+	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
+	nvkm_done(ramfc);
+	return 0;
+}
+
+static struct nvkm_ofuncs
+gf100_fifo_ofuncs = {
+	.ctor = gf100_fifo_chan_ctor,
+	.dtor = _nvkm_fifo_channel_dtor,
+	.init = gf100_fifo_chan_init,
+	.fini = gf100_fifo_chan_fini,
+	.map  = _nvkm_fifo_channel_map,
+	.rd32 = _nvkm_fifo_channel_rd32,
+	.wr32 = _nvkm_fifo_channel_wr32,
+	.ntfy = _nvkm_fifo_channel_ntfy
+};
+
+struct nvkm_oclass
+gf100_fifo_sclass[] = {
+	{ FERMI_CHANNEL_GPFIFO, &gf100_fifo_ofuncs },
+	{}
+};
+
+static int
+gf100_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+			struct nvkm_oclass *oclass, void *data, u32 size,
+			struct nvkm_object **pobject)
+{
+	struct nvkm_device *device = nv_engine(engine)->subdev.device;
+	struct gf100_fifo_base *base;
+	int ret;
+
+	ret = nvkm_fifo_context_create(parent, engine, oclass, NULL, 0x1000,
+				       0x1000, NVOBJ_FLAG_ZERO_ALLOC |
+				       NVOBJ_FLAG_HEAP, &base);
+	*pobject = nv_object(base);
+	if (ret)
+		return ret;
+
+	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &base->pgd);
+	if (ret)
+		return ret;
+
+	nvkm_kmap(&base->base.gpuobj);
+	nvkm_wo32(&base->base.gpuobj, 0x0200, lower_32_bits(base->pgd->addr));
+	nvkm_wo32(&base->base.gpuobj, 0x0204, upper_32_bits(base->pgd->addr));
+	nvkm_wo32(&base->base.gpuobj, 0x0208, 0xffffffff);
+	nvkm_wo32(&base->base.gpuobj, 0x020c, 0x000000ff);
+	nvkm_done(&base->base.gpuobj);
+
+	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static void
+gf100_fifo_context_dtor(struct nvkm_object *object)
+{
+	struct gf100_fifo_base *base = (void *)object;
+	nvkm_vm_ref(NULL, &base->vm, base->pgd);
+	nvkm_gpuobj_del(&base->pgd);
+	nvkm_fifo_context_destroy(&base->base);
+}
+
+struct nvkm_oclass
+gf100_fifo_cclass = {
+	.handle = NV_ENGCTX(FIFO, 0xc0),
+	.ofuncs = &(struct nvkm_ofuncs) {
+		.ctor = gf100_fifo_context_ctor,
+		.dtor = gf100_fifo_context_dtor,
+		.init = _nvkm_fifo_context_init,
+		.fini = _nvkm_fifo_context_fini,
+		.rd32 = _nvkm_fifo_context_rd32,
+		.wr32 = _nvkm_fifo_context_wr32,
+	},
+};
