commit cf9518b50a9c68cafb07e05fc54731071228ced3
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Jun 13 13:58:50 2019 +1000

    drm/nouveau/fifo/gf1xx: convert to using nvkm_fault_data
    
    Would like to be able to reuse gf100_fifo_intr_fault() for (some of) the
    later chipsets too, as it's identical.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 10a2e7039a75..5a39e51d42d7 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -28,6 +28,7 @@
 #include <core/enum.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
+#include <subdev/fault.h>
 #include <engine/sw.h>
 
 #include <nvif/class.h>
@@ -193,68 +194,6 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	nvkm_fifo_kevent(&fifo->base, chid);
 }
 
-static const struct nvkm_enum
-gf100_fifo_sched_reason[] = {
-	{ 0x0a, "CTXSW_TIMEOUT" },
-	{}
-};
-
-static void
-gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
-{
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	struct nvkm_engine *engine;
-	struct gf100_fifo_chan *chan;
-	unsigned long flags;
-	u32 engn;
-
-	spin_lock_irqsave(&fifo->base.lock, flags);
-	for (engn = 0; engn < 6; engn++) {
-		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
-		u32 busy = (stat & 0x80000000);
-		u32 save = (stat & 0x00100000); /* maybe? */
-		u32 unk0 = (stat & 0x00040000);
-		u32 unk1 = (stat & 0x00001000);
-		u32 chid = (stat & 0x0000007f);
-		(void)save;
-
-		if (busy && unk0 && unk1) {
-			list_for_each_entry(chan, &fifo->chan, head) {
-				if (chan->base.chid == chid) {
-					engine = gf100_fifo_engine(fifo, engn);
-					if (!engine)
-						break;
-					gf100_fifo_recover(fifo, engine, chan);
-					break;
-				}
-			}
-		}
-	}
-	spin_unlock_irqrestore(&fifo->base.lock, flags);
-}
-
-static void
-gf100_fifo_intr_sched(struct gf100_fifo *fifo)
-{
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
-	u32 intr = nvkm_rd32(device, 0x00254c);
-	u32 code = intr & 0x000000ff;
-	const struct nvkm_enum *en;
-
-	en = nvkm_enum_find(gf100_fifo_sched_reason, code);
-
-	nvkm_error(subdev, "SCHED_ERROR %02x [%s]\n", code, en ? en->name : "");
-
-	switch (code) {
-	case 0x0a:
-		gf100_fifo_intr_sched_ctxsw(fifo);
-		break;
-	default:
-		break;
-	}
-}
-
 static const struct nvkm_enum
 gf100_fifo_fault_engine[] = {
 	{ 0x00, "PGRAPH", NULL, NVKM_ENGINE_GR },
@@ -315,32 +254,24 @@ gf100_fifo_fault_gpcclient[] = {
 };
 
 static void
-gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
+gf100_fifo_fault(struct nvkm_fifo *base, struct nvkm_fault_data *info)
 {
+	struct gf100_fifo *fifo = gf100_fifo(base);
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
-	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
-	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
-	u32 stat = nvkm_rd32(device, 0x00280c + (unit * 0x10));
-	u32 gpc    = (stat & 0x1f000000) >> 24;
-	u32 client = (stat & 0x00001f00) >> 8;
-	u32 write  = (stat & 0x00000080);
-	u32 hub    = (stat & 0x00000040);
-	u32 reason = (stat & 0x0000000f);
 	const struct nvkm_enum *er, *eu, *ec;
 	struct nvkm_engine *engine = NULL;
 	struct nvkm_fifo_chan *chan;
 	unsigned long flags;
 	char gpcid[8] = "";
 
-	er = nvkm_enum_find(gf100_fifo_fault_reason, reason);
-	eu = nvkm_enum_find(gf100_fifo_fault_engine, unit);
-	if (hub) {
-		ec = nvkm_enum_find(gf100_fifo_fault_hubclient, client);
+	er = nvkm_enum_find(gf100_fifo_fault_reason, info->reason);
+	eu = nvkm_enum_find(gf100_fifo_fault_engine, info->engine);
+	if (info->hub) {
+		ec = nvkm_enum_find(gf100_fifo_fault_hubclient, info->client);
 	} else {
-		ec = nvkm_enum_find(gf100_fifo_fault_gpcclient, client);
-		snprintf(gpcid, sizeof(gpcid), "GPC%d/", gpc);
+		ec = nvkm_enum_find(gf100_fifo_fault_gpcclient, info->client);
+		snprintf(gpcid, sizeof(gpcid), "GPC%d/", info->gpc);
 	}
 
 	if (eu && eu->data2) {
@@ -360,22 +291,108 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 		}
 	}
 
-	chan = nvkm_fifo_chan_inst(&fifo->base, (u64)inst << 12, &flags);
+	chan = nvkm_fifo_chan_inst(&fifo->base, info->inst, &flags);
 
 	nvkm_error(subdev,
 		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
 		   "reason %02x [%s] on channel %d [%010llx %s]\n",
-		   write ? "write" : "read", (u64)vahi << 32 | valo,
-		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
-		   reason, er ? er->name : "", chan ? chan->chid : -1,
-		   (u64)inst << 12,
-		   chan ? chan->object.client->name : "unknown");
+		   info->access ? "write" : "read", info->addr,
+		   info->engine, eu ? eu->name : "",
+		   info->client, gpcid, ec ? ec->name : "",
+		   info->reason, er ? er->name : "", chan ? chan->chid : -1,
+		   info->inst, chan ? chan->object.client->name : "unknown");
 
 	if (engine && chan)
 		gf100_fifo_recover(fifo, engine, (void *)chan);
 	nvkm_fifo_chan_put(&fifo->base, flags, &chan);
 }
 
+static const struct nvkm_enum
+gf100_fifo_sched_reason[] = {
+	{ 0x0a, "CTXSW_TIMEOUT" },
+	{}
+};
+
+static void
+gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
+{
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_engine *engine;
+	struct gf100_fifo_chan *chan;
+	unsigned long flags;
+	u32 engn;
+
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	for (engn = 0; engn < 6; engn++) {
+		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
+		u32 busy = (stat & 0x80000000);
+		u32 save = (stat & 0x00100000); /* maybe? */
+		u32 unk0 = (stat & 0x00040000);
+		u32 unk1 = (stat & 0x00001000);
+		u32 chid = (stat & 0x0000007f);
+		(void)save;
+
+		if (busy && unk0 && unk1) {
+			list_for_each_entry(chan, &fifo->chan, head) {
+				if (chan->base.chid == chid) {
+					engine = gf100_fifo_engine(fifo, engn);
+					if (!engine)
+						break;
+					gf100_fifo_recover(fifo, engine, chan);
+					break;
+				}
+			}
+		}
+	}
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
+}
+
+static void
+gf100_fifo_intr_sched(struct gf100_fifo *fifo)
+{
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	u32 intr = nvkm_rd32(device, 0x00254c);
+	u32 code = intr & 0x000000ff;
+	const struct nvkm_enum *en;
+
+	en = nvkm_enum_find(gf100_fifo_sched_reason, code);
+
+	nvkm_error(subdev, "SCHED_ERROR %02x [%s]\n", code, en ? en->name : "");
+
+	switch (code) {
+	case 0x0a:
+		gf100_fifo_intr_sched_ctxsw(fifo);
+		break;
+	default:
+		break;
+	}
+}
+
+void
+gf100_fifo_intr_fault(struct nvkm_fifo *fifo, int unit)
+{
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
+	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
+	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
+	u32 type = nvkm_rd32(device, 0x00280c + (unit * 0x10));
+	struct nvkm_fault_data info;
+
+	info.inst   =  (u64)inst << 12;
+	info.addr   = ((u64)vahi << 32) | valo;
+	info.time   = 0;
+	info.engine = unit;
+	info.valid  = 1;
+	info.gpc    = (type & 0x1f000000) >> 24;
+	info.client = (type & 0x00001f00) >> 8;
+	info.access = (type & 0x00000080) >> 7;
+	info.hub    = (type & 0x00000040) >> 6;
+	info.reason = (type & 0x0000000f);
+
+	nvkm_fifo_fault(fifo, &info);
+}
+
 static const struct nvkm_bitfield
 gf100_fifo_pbdma_intr[] = {
 /*	{ 0x00008000, "" }	seen with null ib push */
@@ -518,7 +535,7 @@ gf100_fifo_intr(struct nvkm_fifo *base)
 		u32 mask = nvkm_rd32(device, 0x00259c);
 		while (mask) {
 			u32 unit = __ffs(mask);
-			gf100_fifo_intr_fault(fifo, unit);
+			gf100_fifo_intr_fault(&fifo->base, unit);
 			nvkm_wr32(device, 0x00259c, (1 << unit));
 			mask &= ~(1 << unit);
 		}
@@ -655,6 +672,7 @@ gf100_fifo = {
 	.init = gf100_fifo_init,
 	.fini = gf100_fifo_fini,
 	.intr = gf100_fifo_intr,
+	.fault = gf100_fifo_fault,
 	.uevent_init = gf100_fifo_uevent_init,
 	.uevent_fini = gf100_fifo_uevent_fini,
 	.chan = {

commit 302daab1a7b1206d33a9191d5b42ce606ed46e21
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue Dec 11 14:50:02 2018 +1000

    drm/nouveau/fifo/gf100-: call into BAR to reset BARs after MMU fault
    
    This is needed for Turing, but we're supposed to wait for completion after
    re-writing the value on older GPUs anyway.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index f69576868164..10a2e7039a75 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -346,10 +346,10 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 	if (eu && eu->data2) {
 		switch (eu->data2) {
 		case NVKM_SUBDEV_BAR:
-			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
+			nvkm_bar_bar1_reset(device);
 			break;
 		case NVKM_SUBDEV_INSTMEM:
-			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
+			nvkm_bar_bar2_reset(device);
 			break;
 		case NVKM_ENGINE_IFB:
 			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);

commit 01f349fcad68d80939db53d9110135e6341b786d
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/fifo/gf100-: use new interfaces for vmm operations
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 24a4c28b32c5..f69576868164 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -28,7 +28,6 @@
 #include <core/enum.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
-#include <subdev/fb.h>
 #include <engine/sw.h>
 
 #include <nvif/class.h>
@@ -586,12 +585,12 @@ gf100_fifo_oneinit(struct nvkm_fifo *base)
 	if (ret)
 		return ret;
 
-	ret = nvkm_vm_get(bar, nvkm_memory_size(fifo->user.mem), 12,
-			  NV_MEM_ACCESS_RW, &fifo->user.bar);
+	ret = nvkm_vmm_get(bar, 12, nvkm_memory_size(fifo->user.mem),
+			   &fifo->user.bar);
 	if (ret)
 		return ret;
 
-	return nvkm_memory_map(fifo->user.mem, 0, bar, &fifo->user.bar, NULL, 0);
+	return nvkm_memory_map(fifo->user.mem, 0, bar, fifo->user.bar, NULL, 0);
 }
 
 static void
@@ -630,7 +629,7 @@ gf100_fifo_init(struct nvkm_fifo *base)
 	}
 
 	nvkm_mask(device, 0x002200, 0x00000001, 0x00000001);
-	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
+	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar->addr >> 12);
 
 	nvkm_wr32(device, 0x002100, 0xffffffff);
 	nvkm_wr32(device, 0x002140, 0x7fffffff);
@@ -641,7 +640,8 @@ static void *
 gf100_fifo_dtor(struct nvkm_fifo *base)
 {
 	struct gf100_fifo *fifo = gf100_fifo(base);
-	nvkm_vm_put(&fifo->user.bar);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	nvkm_vmm_put(nvkm_bar_bar1_vmm(device), &fifo->user.bar);
 	nvkm_memory_unref(&fifo->user.mem);
 	nvkm_memory_unref(&fifo->runlist.mem[0]);
 	nvkm_memory_unref(&fifo->runlist.mem[1]);

commit 997a89003c2d950466bc289147ffb823c0c51fb0
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/memory: add reference counting
    
    We need to be able to prevent memory from being freed while it's still
    mapped in a GPU's address-space.
    
    Will be used by upcoming MMU changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 14b1a616d26a..24a4c28b32c5 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -642,9 +642,9 @@ gf100_fifo_dtor(struct nvkm_fifo *base)
 {
 	struct gf100_fifo *fifo = gf100_fifo(base);
 	nvkm_vm_put(&fifo->user.bar);
-	nvkm_memory_del(&fifo->user.mem);
-	nvkm_memory_del(&fifo->runlist.mem[0]);
-	nvkm_memory_del(&fifo->runlist.mem[1]);
+	nvkm_memory_unref(&fifo->user.mem);
+	nvkm_memory_unref(&fifo->runlist.mem[0]);
+	nvkm_memory_unref(&fifo->runlist.mem[1]);
 	return fifo;
 }
 

commit 19a82e492c3d71efe8763d50496a1701dfcf3f15
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/memory: change map interface to support upcoming mmu changes
    
    Map flags (access, kind, etc) are currently defined in either the VMA,
    or the memory object, which turns out to not be ideal for things like
    suballocated buffers, etc.
    
    These will become per-map flags instead, so we need to support passing
    these arguments in nvkm_memory_map().
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index b1ab34f1a0e9..14b1a616d26a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -591,8 +591,7 @@ gf100_fifo_oneinit(struct nvkm_fifo *base)
 	if (ret)
 		return ret;
 
-	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
-	return 0;
+	return nvkm_memory_map(fifo->user.mem, 0, bar, &fifo->user.bar, NULL, 0);
 }
 
 static void

commit 570889dc5070e1f98b5898dce426f970c9b9329b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/bar: modify interface to bar1 vmm mapping
    
    Upcoming changes will remove the nvkm_vmm pointer from nvkm_vma, instead
    requiring it to be explicitly specified on each operation.
    
    It's not currently possible to get this information for BAR1 mappings,
    so let's fix that ahead of time.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index cd468ab1db12..b1ab34f1a0e9 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -28,6 +28,7 @@
 #include <core/enum.h>
 #include <core/gpuobj.h>
 #include <subdev/bar.h>
+#include <subdev/fb.h>
 #include <engine/sw.h>
 
 #include <nvif/class.h>
@@ -559,6 +560,7 @@ gf100_fifo_oneinit(struct nvkm_fifo *base)
 	struct gf100_fifo *fifo = gf100_fifo(base);
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
+	struct nvkm_vmm *bar = nvkm_bar_bar1_vmm(device);
 	int ret;
 
 	/* Determine number of PBDMAs by checking valid enable bits. */
@@ -584,7 +586,8 @@ gf100_fifo_oneinit(struct nvkm_fifo *base)
 	if (ret)
 		return ret;
 
-	ret = nvkm_bar_umap(device->bar, 128 * 0x1000, 12, &fifo->user.bar);
+	ret = nvkm_vm_get(bar, nvkm_memory_size(fifo->user.mem), 12,
+			  NV_MEM_ACCESS_RW, &fifo->user.bar);
 	if (ret)
 		return ret;
 

commit ff9f29abf0ef4c43e696bef7621884518e6bdbda
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Sat Nov 5 13:05:14 2016 +1000

    drm/nouveau/fifo/gf100-: provide notification to user if channel is killed
    
    There are instances (such as non-recoverable GPU page faults) where
    NVKM decides that a channel's context is no longer viable, and will
    be removed from the runlist.
    
    This commit notifies the owner of the channel when this happens, so
    it has the opportunity to take some kind of recovery action instead
    of hanging.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 8772a995329a..cd468ab1db12 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -190,6 +190,7 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	if (engine != &fifo->base.engine)
 		fifo->recover.mask |= 1ULL << engine->subdev.index;
 	schedule_work(&fifo->recover.work);
+	nvkm_fifo_kevent(&fifo->base, chid);
 }
 
 static const struct nvkm_enum

commit d2ee360564dca43cbfb2bd8ceead7671c87962d2
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue May 10 12:42:26 2016 +1000

    drm/nouveau/core/memory: distinguish between coherent/non-coherent targets
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index ec68ea9747d5..8772a995329a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -68,7 +68,14 @@ gf100_fifo_runlist_commit(struct gf100_fifo *fifo)
 	}
 	nvkm_done(cur);
 
-	target = (nvkm_memory_target(cur) == NVKM_MEM_TARGET_HOST) ? 0x3 : 0x0;
+	switch (nvkm_memory_target(cur)) {
+	case NVKM_MEM_TARGET_VRAM: target = 0; break;
+	case NVKM_MEM_TARGET_NCOH: target = 3; break;
+	default:
+		mutex_unlock(&subdev->mutex);
+		WARN_ON(1);
+		return;
+	}
 
 	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(cur) >> 12) |
 				    (target << 28));

commit ec884f74f1ec8ffa6a77a2769087117aeec80c1f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Dec 9 17:13:08 2016 +1000

    drm/nouveau/fifo/gf100-: recover from host mmu faults
    
    This has been on the TODO list for a while now, recovering from things
    such as attempting to execute a push buffer or touch a semaphore in an
    unmapped memory area.
    
    The only thing required on the HW side here is that the offending
    channel is removed from the runlist, and *not* a full reset of PFIFO.
    
    This used to be a bit messier to handle before the rework to make use
    of engine topology info, but is apparently now trivial.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 352a0baec84d..ec68ea9747d5 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -180,7 +180,8 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	list_del_init(&chan->head);
 	chan->killed = true;
 
-	fifo->recover.mask |= 1ULL << engine->subdev.index;
+	if (engine != &fifo->base.engine)
+		fifo->recover.mask |= 1ULL << engine->subdev.index;
 	schedule_work(&fifo->recover.work);
 }
 

commit 1015d81122f3f527b2e042960ffc65916834fd1d
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gf100: fix certain engines not being recovered after a fault
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index c56311acc9fe..352a0baec84d 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -148,11 +148,11 @@ gf100_fifo_recover_work(struct work_struct *w)
 	fifo->recover.mask = 0ULL;
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
 
-	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
+	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~BIT_ULL(engn))
 		engm |= 1 << gf100_fifo_engidx(fifo, engn);
 	nvkm_mask(device, 0x002630, engm, engm);
 
-	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
+	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~BIT_ULL(engn)) {
 		if ((engine = nvkm_device_engine(device, engn))) {
 			nvkm_subdev_fini(&engine->subdev, false);
 			WARN_ON(nvkm_subdev_init(&engine->subdev));

commit f22d7d45fab4a1a5cba7b932b55d74e925ffd6be
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gf100: don't attempt recovery of unknown mmu engines
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index b9090bf597f3..c56311acc9fe 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -334,7 +334,7 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 		snprintf(gpcid, sizeof(gpcid), "GPC%d/", gpc);
 	}
 
-	if (eu) {
+	if (eu && eu->data2) {
 		switch (eu->data2) {
 		case NVKM_SUBDEV_BAR:
 			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);

commit 792662439cf24176db8751e1f740ab5343a5c1b9
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gf100: identify fault-recovery members more clearly
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 97d0ca6b4be6..b9090bf597f3 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -134,9 +134,9 @@ gf100_fifo_engine(struct gf100_fifo *fifo, u32 engn)
 }
 
 static void
-gf100_fifo_recover_work(struct work_struct *work)
+gf100_fifo_recover_work(struct work_struct *w)
 {
-	struct gf100_fifo *fifo = container_of(work, typeof(*fifo), fault);
+	struct gf100_fifo *fifo = container_of(w, typeof(*fifo), recover.work);
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_engine *engine;
 	unsigned long flags;
@@ -144,8 +144,8 @@ gf100_fifo_recover_work(struct work_struct *work)
 	u64 mask, todo;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
-	mask = fifo->mask;
-	fifo->mask = 0ULL;
+	mask = fifo->recover.mask;
+	fifo->recover.mask = 0ULL;
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
@@ -180,8 +180,8 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	list_del_init(&chan->head);
 	chan->killed = true;
 
-	fifo->mask |= 1ULL << engine->subdev.index;
-	schedule_work(&fifo->fault);
+	fifo->recover.mask |= 1ULL << engine->subdev.index;
+	schedule_work(&fifo->recover.work);
 }
 
 static const struct nvkm_enum
@@ -587,7 +587,7 @@ static void
 gf100_fifo_fini(struct nvkm_fifo *base)
 {
 	struct gf100_fifo *fifo = gf100_fifo(base);
-	flush_work(&fifo->fault);
+	flush_work(&fifo->recover.work);
 }
 
 static void
@@ -660,7 +660,7 @@ gf100_fifo_new(struct nvkm_device *device, int index, struct nvkm_fifo **pfifo)
 	if (!(fifo = kzalloc(sizeof(*fifo), GFP_KERNEL)))
 		return -ENOMEM;
 	INIT_LIST_HEAD(&fifo->chan);
-	INIT_WORK(&fifo->fault, gf100_fifo_recover_work);
+	INIT_WORK(&fifo->recover.work, gf100_fifo_recover_work);
 	*pfifo = &fifo->base;
 
 	return nvkm_fifo_ctor(&gf100_fifo, device, index, 128, &fifo->base);

commit adbe24a21eb7433496b5225fa37a3ded5d2fde97
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Fri Mar 11 13:09:28 2016 +1000

    drm/nouveau/fifo/gf100: rename spooon to pbdma, and move detection to oneinit
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 3cac5ebd0a4b..97d0ca6b4be6 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -548,9 +548,16 @@ static int
 gf100_fifo_oneinit(struct nvkm_fifo *base)
 {
 	struct gf100_fifo *fifo = gf100_fifo(base);
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	int ret;
 
+	/* Determine number of PBDMAs by checking valid enable bits. */
+	nvkm_wr32(device, 0x002204, 0xffffffff);
+	fifo->pbdma_nr = hweight32(nvkm_rd32(device, 0x002204));
+	nvkm_debug(subdev, "%d PBDMA(s)\n", fifo->pbdma_nr);
+
+
 	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
 			      false, &fifo->runlist.mem[0]);
 	if (ret)
@@ -587,18 +594,15 @@ static void
 gf100_fifo_init(struct nvkm_fifo *base)
 {
 	struct gf100_fifo *fifo = gf100_fifo(base);
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	int i;
 
-	nvkm_wr32(device, 0x000204, 0xffffffff);
-	nvkm_wr32(device, 0x002204, 0xffffffff);
-
-	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x002204));
-	nvkm_debug(subdev, "%d PBDMA unit(s)\n", fifo->spoon_nr);
+	/* Enable PBDMAs. */
+	nvkm_wr32(device, 0x000204, (1 << fifo->pbdma_nr) - 1);
+	nvkm_wr32(device, 0x002204, (1 << fifo->pbdma_nr) - 1);
 
-	/* assign engines to PBDMAs */
-	if (fifo->spoon_nr >= 3) {
+	/* Assign engines to PBDMAs. */
+	if (fifo->pbdma_nr >= 3) {
 		nvkm_wr32(device, 0x002208, ~(1 << 0)); /* PGRAPH */
 		nvkm_wr32(device, 0x00220c, ~(1 << 1)); /* PVP */
 		nvkm_wr32(device, 0x002210, ~(1 << 1)); /* PMSPP */
@@ -608,7 +612,7 @@ gf100_fifo_init(struct nvkm_fifo *base)
 	}
 
 	/* PBDMA[n] */
-	for (i = 0; i < fifo->spoon_nr; i++) {
+	for (i = 0; i < fifo->pbdma_nr; i++) {
 		nvkm_mask(device, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
 		nvkm_wr32(device, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
 		nvkm_wr32(device, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */

commit c694ecad9dc4b2b367e33387c4407532b706dab7
Author: Alexandre Courbot <acourbot@nvidia.com>
Date:   Tue Mar 1 16:51:57 2016 +0900

    drm/nouveau/fifo/gf100: take runlist target into account
    
    Bits 28:29 of RUNLIST_BASE specify the memory target of the runlist. Set
    it to 0x3 (SYS_MEM_NONCOHERENT) if the runlist object resides in system
    memory.
    
    Signed-off-by: Alexandre Courbot <acourbot@nvidia.com>
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 36a39c7fd8d2..3cac5ebd0a4b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -54,6 +54,7 @@ gf100_fifo_runlist_commit(struct gf100_fifo *fifo)
 	struct nvkm_device *device = subdev->device;
 	struct nvkm_memory *cur;
 	int nr = 0;
+	int target;
 
 	mutex_lock(&subdev->mutex);
 	cur = fifo->runlist.mem[fifo->runlist.active];
@@ -67,7 +68,10 @@ gf100_fifo_runlist_commit(struct gf100_fifo *fifo)
 	}
 	nvkm_done(cur);
 
-	nvkm_wr32(device, 0x002270, nvkm_memory_addr(cur) >> 12);
+	target = (nvkm_memory_target(cur) == NVKM_MEM_TARGET_HOST) ? 0x3 : 0x0;
+
+	nvkm_wr32(device, 0x002270, (nvkm_memory_addr(cur) >> 12) |
+				    (target << 28));
 	nvkm_wr32(device, 0x002274, 0x01f00000 | nr);
 
 	if (wait_event_timeout(fifo->runlist.wait,

commit 9402aec5448fe0d307beb0dcebb2153cf9c23161
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Mon Jan 4 12:24:46 2016 +1000

    drm/nouveau/fifo/gf100: remove references to "daemon"
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 6f276dab4a25..36a39c7fd8d2 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -255,7 +255,7 @@ gf100_fifo_fault_engine[] = {
 	{ 0x14, "PMSPDEC", NULL, NVKM_ENGINE_MSPDEC },
 	{ 0x15, "PCE0", NULL, NVKM_ENGINE_CE0 },
 	{ 0x16, "PCE1", NULL, NVKM_ENGINE_CE1 },
-	{ 0x17, "PDAEMON" },
+	{ 0x17, "PMU" },
 	{}
 };
 
@@ -286,7 +286,7 @@ gf100_fifo_fault_hubclient[] = {
 	{ 0x0c, "PMSPPP" },
 	{ 0x0d, "PMSVLD" },
 	{ 0x11, "PCOUNTER" },
-	{ 0x12, "PDAEMON" },
+	{ 0x12, "PMU" },
 	{ 0x14, "CCACHE" },
 	{ 0x15, "CCACHE_POST" },
 	{}

commit d40d0fd487375c66ed444ec2bbd5ffa5d64ebede
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 11 10:07:22 2015 +1000

    drm/nouveau/fifo/gf100: fix race condition when updating engine runlists
    
    Similar in spirit to the gk104 fix with a similar title.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index ff6fcbda615b..6f276dab4a25 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -47,7 +47,7 @@ gf100_fifo_uevent_fini(struct nvkm_fifo *fifo)
 }
 
 void
-gf100_fifo_runlist_update(struct gf100_fifo *fifo)
+gf100_fifo_runlist_commit(struct gf100_fifo *fifo)
 {
 	struct gf100_fifo_chan *chan;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
@@ -77,6 +77,22 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 	mutex_unlock(&subdev->mutex);
 }
 
+void
+gf100_fifo_runlist_remove(struct gf100_fifo *fifo, struct gf100_fifo_chan *chan)
+{
+	mutex_lock(&fifo->base.engine.subdev.mutex);
+	list_del_init(&chan->head);
+	mutex_unlock(&fifo->base.engine.subdev.mutex);
+}
+
+void
+gf100_fifo_runlist_insert(struct gf100_fifo *fifo, struct gf100_fifo_chan *chan)
+{
+	mutex_lock(&fifo->base.engine.subdev.mutex);
+	list_add_tail(&chan->head, &fifo->chan);
+	mutex_unlock(&fifo->base.engine.subdev.mutex);
+}
+
 static inline int
 gf100_fifo_engidx(struct gf100_fifo *fifo, u32 engn)
 {
@@ -139,7 +155,7 @@ gf100_fifo_recover_work(struct work_struct *work)
 		}
 	}
 
-	gf100_fifo_runlist_update(fifo);
+	gf100_fifo_runlist_commit(fifo);
 	nvkm_wr32(device, 0x00262c, engm);
 	nvkm_mask(device, 0x002630, engm, 0x00000000);
 }

commit fbd58ebda9c8572ca6285b88e3348c7712f125ec
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/object: merge with handle
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 172f24301113..ff6fcbda615b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -27,7 +27,6 @@
 #include <core/client.h>
 #include <core/enum.h>
 #include <core/gpuobj.h>
-#include <core/handle.h>
 #include <subdev/bar.h>
 #include <engine/sw.h>
 

commit 68f3f702b6a430a8d1e909455a60d26c0f2da530
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/core: remove the remainder of the previous style
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index bc094223f687..172f24301113 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -82,12 +82,12 @@ static inline int
 gf100_fifo_engidx(struct gf100_fifo *fifo, u32 engn)
 {
 	switch (engn) {
-	case NVDEV_ENGINE_GR    : engn = 0; break;
-	case NVDEV_ENGINE_MSVLD : engn = 1; break;
-	case NVDEV_ENGINE_MSPPP : engn = 2; break;
-	case NVDEV_ENGINE_MSPDEC: engn = 3; break;
-	case NVDEV_ENGINE_CE0   : engn = 4; break;
-	case NVDEV_ENGINE_CE1   : engn = 5; break;
+	case NVKM_ENGINE_GR    : engn = 0; break;
+	case NVKM_ENGINE_MSVLD : engn = 1; break;
+	case NVKM_ENGINE_MSPPP : engn = 2; break;
+	case NVKM_ENGINE_MSPDEC: engn = 3; break;
+	case NVKM_ENGINE_CE0   : engn = 4; break;
+	case NVKM_ENGINE_CE1   : engn = 5; break;
 	default:
 		return -1;
 	}
@@ -101,12 +101,12 @@ gf100_fifo_engine(struct gf100_fifo *fifo, u32 engn)
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 
 	switch (engn) {
-	case 0: engn = NVDEV_ENGINE_GR; break;
-	case 1: engn = NVDEV_ENGINE_MSVLD; break;
-	case 2: engn = NVDEV_ENGINE_MSPPP; break;
-	case 3: engn = NVDEV_ENGINE_MSPDEC; break;
-	case 4: engn = NVDEV_ENGINE_CE0; break;
-	case 5: engn = NVDEV_ENGINE_CE1; break;
+	case 0: engn = NVKM_ENGINE_GR; break;
+	case 1: engn = NVKM_ENGINE_MSVLD; break;
+	case 2: engn = NVKM_ENGINE_MSPPP; break;
+	case 3: engn = NVKM_ENGINE_MSPDEC; break;
+	case 4: engn = NVKM_ENGINE_CE0; break;
+	case 5: engn = NVKM_ENGINE_CE1; break;
 	default:
 		return NULL;
 	}
@@ -229,17 +229,17 @@ gf100_fifo_intr_sched(struct gf100_fifo *fifo)
 
 static const struct nvkm_enum
 gf100_fifo_fault_engine[] = {
-	{ 0x00, "PGRAPH", NULL, NVDEV_ENGINE_GR },
-	{ 0x03, "PEEPHOLE", NULL, NVDEV_ENGINE_IFB },
-	{ 0x04, "BAR1", NULL, NVDEV_SUBDEV_BAR },
-	{ 0x05, "BAR3", NULL, NVDEV_SUBDEV_INSTMEM },
-	{ 0x07, "PFIFO", NULL, NVDEV_ENGINE_FIFO },
-	{ 0x10, "PMSVLD", NULL, NVDEV_ENGINE_MSVLD },
-	{ 0x11, "PMSPPP", NULL, NVDEV_ENGINE_MSPPP },
+	{ 0x00, "PGRAPH", NULL, NVKM_ENGINE_GR },
+	{ 0x03, "PEEPHOLE", NULL, NVKM_ENGINE_IFB },
+	{ 0x04, "BAR1", NULL, NVKM_SUBDEV_BAR },
+	{ 0x05, "BAR3", NULL, NVKM_SUBDEV_INSTMEM },
+	{ 0x07, "PFIFO", NULL, NVKM_ENGINE_FIFO },
+	{ 0x10, "PMSVLD", NULL, NVKM_ENGINE_MSVLD },
+	{ 0x11, "PMSPPP", NULL, NVKM_ENGINE_MSPPP },
 	{ 0x13, "PCOUNTER" },
-	{ 0x14, "PMSPDEC", NULL, NVDEV_ENGINE_MSPDEC },
-	{ 0x15, "PCE0", NULL, NVDEV_ENGINE_CE0 },
-	{ 0x16, "PCE1", NULL, NVDEV_ENGINE_CE1 },
+	{ 0x14, "PMSPDEC", NULL, NVKM_ENGINE_MSPDEC },
+	{ 0x15, "PCE0", NULL, NVKM_ENGINE_CE0 },
+	{ 0x16, "PCE1", NULL, NVKM_ENGINE_CE1 },
 	{ 0x17, "PDAEMON" },
 	{}
 };
@@ -317,13 +317,13 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 
 	if (eu) {
 		switch (eu->data2) {
-		case NVDEV_SUBDEV_BAR:
+		case NVKM_SUBDEV_BAR:
 			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
 			break;
-		case NVDEV_SUBDEV_INSTMEM:
+		case NVKM_SUBDEV_INSTMEM:
 			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
 			break;
-		case NVDEV_ENGINE_IFB:
+		case NVKM_ENGINE_IFB:
 			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:

commit 13de7f462902d1a452d501cdb2d06ef02cabbfff
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/fifo: convert to new-style nvkm_engine
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index e8598fc44796..bc094223f687 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -26,6 +26,7 @@
 
 #include <core/client.h>
 #include <core/enum.h>
+#include <core/gpuobj.h>
 #include <core/handle.h>
 #include <subdev/bar.h>
 #include <engine/sw.h>
@@ -33,28 +34,19 @@
 #include <nvif/class.h>
 
 static void
-gf100_fifo_uevent_init(struct nvkm_event *event, int type, int index)
+gf100_fifo_uevent_init(struct nvkm_fifo *fifo)
 {
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
 	struct nvkm_device *device = fifo->engine.subdev.device;
 	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
 }
 
 static void
-gf100_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
+gf100_fifo_uevent_fini(struct nvkm_fifo *fifo)
 {
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
 	struct nvkm_device *device = fifo->engine.subdev.device;
 	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
 }
 
-static const struct nvkm_event_func
-gf100_fifo_uevent_func = {
-	.ctor = nvkm_fifo_uevent_ctor,
-	.init = gf100_fifo_uevent_init,
-	.fini = gf100_fifo_uevent_fini,
-};
-
 void
 gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
@@ -64,7 +56,7 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 	struct nvkm_memory *cur;
 	int nr = 0;
 
-	mutex_lock(&nv_subdev(fifo)->mutex);
+	mutex_lock(&subdev->mutex);
 	cur = fifo->runlist.mem[fifo->runlist.active];
 	fifo->runlist.active = !fifo->runlist.active;
 
@@ -83,7 +75,7 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 			       !(nvkm_rd32(device, 0x00227c) & 0x00100000),
 			       msecs_to_jiffies(2000)) == 0)
 		nvkm_error(subdev, "runlist update timeout\n");
-	mutex_unlock(&nv_subdev(fifo)->mutex);
+	mutex_unlock(&subdev->mutex);
 }
 
 static inline int
@@ -106,6 +98,8 @@ gf100_fifo_engidx(struct gf100_fifo *fifo, u32 engn)
 static inline struct nvkm_engine *
 gf100_fifo_engine(struct gf100_fifo *fifo, u32 engn)
 {
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+
 	switch (engn) {
 	case 0: engn = NVDEV_ENGINE_GR; break;
 	case 1: engn = NVDEV_ENGINE_MSVLD; break;
@@ -117,7 +111,7 @@ gf100_fifo_engine(struct gf100_fifo *fifo, u32 engn)
 		return NULL;
 	}
 
-	return nvkm_engine(fifo, engn);
+	return nvkm_device_engine(device, engn);
 }
 
 static void
@@ -167,7 +161,7 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	list_del_init(&chan->head);
 	chan->killed = true;
 
-	fifo->mask |= 1ULL << nv_engidx(engine);
+	fifo->mask |= 1ULL << engine->subdev.index;
 	schedule_work(&fifo->fault);
 }
 
@@ -333,7 +327,7 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:
-			engine = nvkm_engine(fifo, eu->data2);
+			engine = nvkm_device_engine(device, eu->data2);
 			break;
 		}
 	}
@@ -457,10 +451,11 @@ gf100_fifo_intr_engine(struct gf100_fifo *fifo)
 }
 
 static void
-gf100_fifo_intr(struct nvkm_subdev *subdev)
+gf100_fifo_intr(struct nvkm_fifo *base)
 {
-	struct gf100_fifo *fifo = (void *)subdev;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct gf100_fifo *fifo = gf100_fifo(base);
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 mask = nvkm_rd32(device, 0x002140);
 	u32 stat = nvkm_rd32(device, 0x002100) & mask;
 
@@ -531,17 +526,52 @@ gf100_fifo_intr(struct nvkm_subdev *subdev)
 }
 
 static int
-gf100_fifo_init(struct nvkm_object *object)
+gf100_fifo_oneinit(struct nvkm_fifo *base)
 {
-	struct gf100_fifo *fifo = (void *)object;
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
-	int ret, i;
+	struct gf100_fifo *fifo = gf100_fifo(base);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	int ret;
 
-	ret = nvkm_fifo_init(&fifo->base);
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
+			      false, &fifo->runlist.mem[0]);
+	if (ret)
+		return ret;
+
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
+			      false, &fifo->runlist.mem[1]);
 	if (ret)
 		return ret;
 
+	init_waitqueue_head(&fifo->runlist.wait);
+
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 128 * 0x1000,
+			      0x1000, false, &fifo->user.mem);
+	if (ret)
+		return ret;
+
+	ret = nvkm_bar_umap(device->bar, 128 * 0x1000, 12, &fifo->user.bar);
+	if (ret)
+		return ret;
+
+	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
+	return 0;
+}
+
+static void
+gf100_fifo_fini(struct nvkm_fifo *base)
+{
+	struct gf100_fifo *fifo = gf100_fifo(base);
+	flush_work(&fifo->fault);
+}
+
+static void
+gf100_fifo_init(struct nvkm_fifo *base)
+{
+	struct gf100_fifo *fifo = gf100_fifo(base);
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	int i;
+
 	nvkm_wr32(device, 0x000204, 0xffffffff);
 	nvkm_wr32(device, 0x002204, 0xffffffff);
 
@@ -571,90 +601,44 @@ gf100_fifo_init(struct nvkm_object *object)
 	nvkm_wr32(device, 0x002100, 0xffffffff);
 	nvkm_wr32(device, 0x002140, 0x7fffffff);
 	nvkm_wr32(device, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
-	return 0;
 }
 
-static void
-gf100_fifo_dtor(struct nvkm_object *object)
+static void *
+gf100_fifo_dtor(struct nvkm_fifo *base)
 {
-	struct gf100_fifo *fifo = (void *)object;
-
+	struct gf100_fifo *fifo = gf100_fifo(base);
 	nvkm_vm_put(&fifo->user.bar);
 	nvkm_memory_del(&fifo->user.mem);
 	nvkm_memory_del(&fifo->runlist.mem[0]);
 	nvkm_memory_del(&fifo->runlist.mem[1]);
-
-	nvkm_fifo_destroy(&fifo->base);
+	return fifo;
 }
 
 static const struct nvkm_fifo_func
-gf100_fifo_func = {
+gf100_fifo = {
+	.dtor = gf100_fifo_dtor,
+	.oneinit = gf100_fifo_oneinit,
+	.init = gf100_fifo_init,
+	.fini = gf100_fifo_fini,
+	.intr = gf100_fifo_intr,
+	.uevent_init = gf100_fifo_uevent_init,
+	.uevent_fini = gf100_fifo_uevent_fini,
 	.chan = {
 		&gf100_fifo_gpfifo_oclass,
 		NULL
 	},
 };
 
-static int
-gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-		struct nvkm_oclass *oclass, void *data, u32 size,
-		struct nvkm_object **pobject)
+int
+gf100_fifo_new(struct nvkm_device *device, int index, struct nvkm_fifo **pfifo)
 {
-	struct nvkm_device *device = (void *)parent;
-	struct nvkm_bar *bar = device->bar;
 	struct gf100_fifo *fifo;
-	int ret;
-
-	ret = nvkm_fifo_create(parent, engine, oclass, 0, 127, &fifo);
-	*pobject = nv_object(fifo);
-	if (ret)
-		return ret;
-
-	fifo->base.func = &gf100_fifo_func;
 
+	if (!(fifo = kzalloc(sizeof(*fifo), GFP_KERNEL)))
+		return -ENOMEM;
 	INIT_LIST_HEAD(&fifo->chan);
 	INIT_WORK(&fifo->fault, gf100_fifo_recover_work);
+	*pfifo = &fifo->base;
 
-	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
-			      false, &fifo->runlist.mem[0]);
-	if (ret)
-		return ret;
-
-	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
-			      false, &fifo->runlist.mem[1]);
-	if (ret)
-		return ret;
-
-	init_waitqueue_head(&fifo->runlist.wait);
-
-	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 128 * 0x1000,
-			      0x1000, false, &fifo->user.mem);
-	if (ret)
-		return ret;
-
-	ret = nvkm_bar_umap(bar, 128 * 0x1000, 12, &fifo->user.bar);
-	if (ret)
-		return ret;
-
-	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
-
-	ret = nvkm_event_init(&gf100_fifo_uevent_func, 1, 1, &fifo->base.uevent);
-	if (ret)
-		return ret;
-
-	nv_subdev(fifo)->unit = 0x00000100;
-	nv_subdev(fifo)->intr = gf100_fifo_intr;
-	return 0;
+	return nvkm_fifo_ctor(&gf100_fifo, device, index, 128, &fifo->base);
 }
-
-
-struct nvkm_oclass *
-gf100_fifo_oclass = &(struct nvkm_oclass) {
-	.handle = NV_ENGINE(FIFO, 0xc0),
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = gf100_fifo_ctor,
-		.dtor = gf100_fifo_dtor,
-		.init = gf100_fifo_init,
-		.fini = _nvkm_fifo_fini,
-	},
-};

commit 3293228174e4d44cca56d809cc8409c3f88f8b90
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:20 2015 +1000

    drm/nouveau/bar: convert to new-style nvkm_subdev
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index bdad44e84b92..e8598fc44796 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -632,7 +632,7 @@ gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	ret = bar->umap(bar, 128 * 0x1000, 12, &fifo->user.bar);
+	ret = nvkm_bar_umap(bar, 128 * 0x1000, 12, &fifo->user.bar);
 	if (ret)
 		return ret;
 

commit 8f0649b5c6e70ec18122255690e39f010c12a614
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:19 2015 +1000

    drm/nouveau/fifo: convert user classes to new-style nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index b88e7c569c0a..bdad44e84b92 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -58,28 +58,26 @@ gf100_fifo_uevent_func = {
 void
 gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
+	struct gf100_fifo_chan *chan;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	struct nvkm_memory *cur;
-	int i, p;
+	int nr = 0;
 
 	mutex_lock(&nv_subdev(fifo)->mutex);
 	cur = fifo->runlist.mem[fifo->runlist.active];
 	fifo->runlist.active = !fifo->runlist.active;
 
 	nvkm_kmap(cur);
-	for (i = 0, p = 0; i < 128; i++) {
-		struct gf100_fifo_chan *chan = (void *)fifo->base.channel[i];
-		if (chan && chan->state == RUNNING) {
-			nvkm_wo32(cur, p + 0, i);
-			nvkm_wo32(cur, p + 4, 0x00000004);
-			p += 8;
-		}
+	list_for_each_entry(chan, &fifo->chan, head) {
+		nvkm_wo32(cur, (nr * 8) + 0, chan->base.chid);
+		nvkm_wo32(cur, (nr * 8) + 4, 0x00000004);
+		nr++;
 	}
 	nvkm_done(cur);
 
 	nvkm_wr32(device, 0x002270, nvkm_memory_addr(cur) >> 12);
-	nvkm_wr32(device, 0x002274, 0x01f00000 | (p >> 3));
+	nvkm_wr32(device, 0x002274, 0x01f00000 | nr);
 
 	if (wait_event_timeout(fifo->runlist.wait,
 			       !(nvkm_rd32(device, 0x00227c) & 0x00100000),
@@ -166,7 +164,8 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	assert_spin_locked(&fifo->base.lock);
 
 	nvkm_mask(device, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
-	chan->state = KILLED;
+	list_del_init(&chan->head);
+	chan->killed = true;
 
 	fifo->mask |= 1ULL << nv_engidx(engine);
 	schedule_work(&fifo->fault);
@@ -198,11 +197,15 @@ gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
 		(void)save;
 
 		if (busy && unk0 && unk1) {
-			if (!(chan = (void *)fifo->base.channel[chid]))
-				continue;
-			if (!(engine = gf100_fifo_engine(fifo, engn)))
-				continue;
-			gf100_fifo_recover(fifo, engine, chan);
+			list_for_each_entry(chan, &fifo->chan, head) {
+				if (chan->base.chid == chid) {
+					engine = gf100_fifo_engine(fifo, engn);
+					if (!engine)
+						break;
+					gf100_fifo_recover(fifo, engine, chan);
+					break;
+				}
+			}
 		}
 	}
 	spin_unlock_irqrestore(&fifo->base.lock, flags);
@@ -343,7 +346,8 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 		   write ? "write" : "read", (u64)vahi << 32 | valo,
 		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
 		   reason, er ? er->name : "", chan ? chan->chid : -1,
-		   (u64)inst << 12,  nvkm_client_name(chan));
+		   (u64)inst << 12,
+		   chan ? chan->object.client->name : "unknown");
 
 	if (engine && chan)
 		gf100_fifo_recover(fifo, engine, (void *)chan);
@@ -369,6 +373,8 @@ gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 	u32 chid = nvkm_rd32(device, 0x040120 + (unit * 0x2000)) & 0x7f;
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
+	struct nvkm_fifo_chan *chan;
+	unsigned long flags;
 	u32 show= stat;
 	char msg[128];
 
@@ -381,11 +387,13 @@ gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 
 	if (show) {
 		nvkm_snprintbf(msg, sizeof(msg), gf100_fifo_pbdma_intr, show);
-		nvkm_error(subdev, "PBDMA%d: %08x [%s] ch %d [%s] subc %d "
-				   "mthd %04x data %08x\n",
-			   unit, show, msg, chid,
-			   nvkm_client_name_for_fifo_chid(&fifo->base, chid),
+		chan = nvkm_fifo_chan_chid(&fifo->base, chid, &flags);
+		nvkm_error(subdev, "PBDMA%d: %08x [%s] ch %d [%010llx %s] "
+				   "subc %d mthd %04x data %08x\n",
+			   unit, show, msg, chid, chan ? chan->inst->addr : 0,
+			   chan ? chan->object.client->name : "unknown",
 			   subc, mthd, data);
+		nvkm_fifo_chan_put(&fifo->base, flags, &chan);
 	}
 
 	nvkm_wr32(device, 0x0400c0 + (unit * 0x2000), 0x80600008);
@@ -579,6 +587,14 @@ gf100_fifo_dtor(struct nvkm_object *object)
 	nvkm_fifo_destroy(&fifo->base);
 }
 
+static const struct nvkm_fifo_func
+gf100_fifo_func = {
+	.chan = {
+		&gf100_fifo_gpfifo_oclass,
+		NULL
+	},
+};
+
 static int
 gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct nvkm_oclass *oclass, void *data, u32 size,
@@ -594,6 +610,9 @@ gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
+	fifo->base.func = &gf100_fifo_func;
+
+	INIT_LIST_HEAD(&fifo->chan);
 	INIT_WORK(&fifo->fault, gf100_fifo_recover_work);
 
 	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
@@ -625,8 +644,6 @@ gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	nv_subdev(fifo)->unit = 0x00000100;
 	nv_subdev(fifo)->intr = gf100_fifo_intr;
-	nv_engine(fifo)->cclass = &gf100_fifo_cclass;
-	nv_engine(fifo)->sclass = gf100_fifo_sclass;
 	return 0;
 }
 

commit 9a65a38c456ebac97f0498e85fe26f6d26fe3936
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:19 2015 +1000

    drm/nouveau/fifo: split user classes out from engine implementations
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 7f05985ebb37..b88e7c569c0a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -21,61 +21,41 @@
  *
  * Authors: Ben Skeggs
  */
-#include <engine/fifo.h>
+#include "gf100.h"
+#include "changf100.h"
 
 #include <core/client.h>
-#include <core/engctx.h>
 #include <core/enum.h>
 #include <core/handle.h>
 #include <subdev/bar.h>
-#include <subdev/fb.h>
-#include <subdev/mmu.h>
-#include <subdev/timer.h>
 #include <engine/sw.h>
 
 #include <nvif/class.h>
-#include <nvif/ioctl.h>
-#include <nvif/unpack.h>
-
-struct gf100_fifo {
-	struct nvkm_fifo base;
-
-	struct work_struct fault;
-	u64 mask;
-
-	struct {
-		struct nvkm_memory *mem[2];
-		int active;
-		wait_queue_head_t wait;
-	} runlist;
-
-	struct {
-		struct nvkm_memory *mem;
-		struct nvkm_vma bar;
-	} user;
-	int spoon_nr;
-};
 
-struct gf100_fifo_base {
-	struct nvkm_fifo_base base;
-	struct nvkm_gpuobj *pgd;
-	struct nvkm_vm *vm;
-};
+static void
+gf100_fifo_uevent_init(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
+}
 
-struct gf100_fifo_chan {
-	struct nvkm_fifo_chan base;
-	enum {
-		STOPPED,
-		RUNNING,
-		KILLED
-	} state;
-};
+static void
+gf100_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
+}
 
-/*******************************************************************************
- * FIFO channel objects
- ******************************************************************************/
+static const struct nvkm_event_func
+gf100_fifo_uevent_func = {
+	.ctor = nvkm_fifo_uevent_ctor,
+	.init = gf100_fifo_uevent_init,
+	.fini = gf100_fifo_uevent_fini,
+};
 
-static void
+void
 gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
@@ -108,289 +88,6 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 	mutex_unlock(&nv_subdev(fifo)->mutex);
 }
 
-static int
-gf100_fifo_context_attach(struct nvkm_object *parent,
-			  struct nvkm_object *object)
-{
-	struct gf100_fifo_base *base = (void *)parent->parent;
-	struct nvkm_gpuobj *engn = &base->base.gpuobj;
-	struct nvkm_engctx *ectx = (void *)object;
-	u32 addr;
-	int ret;
-
-	switch (nv_engidx(object->engine)) {
-	case NVDEV_ENGINE_SW    : return 0;
-	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
-	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
-	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
-	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
-	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
-	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
-	default:
-		return -EINVAL;
-	}
-
-	if (!ectx->vma.node) {
-		ret = nvkm_gpuobj_map(nv_gpuobj(ectx), base->vm,
-				      NV_MEM_ACCESS_RW, &ectx->vma);
-		if (ret)
-			return ret;
-
-		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
-	}
-
-	nvkm_kmap(engn);
-	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
-	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
-	nvkm_done(engn);
-	return 0;
-}
-
-static int
-gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
-			  struct nvkm_object *object)
-{
-	struct gf100_fifo *fifo = (void *)parent->engine;
-	struct gf100_fifo_base *base = (void *)parent->parent;
-	struct gf100_fifo_chan *chan = (void *)parent;
-	struct nvkm_gpuobj *engn = &base->base.gpuobj;
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
-	u32 addr;
-
-	switch (nv_engidx(object->engine)) {
-	case NVDEV_ENGINE_SW    : return 0;
-	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
-	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
-	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
-	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
-	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
-	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
-	default:
-		return -EINVAL;
-	}
-
-	nvkm_wr32(device, 0x002634, chan->base.chid);
-	if (nvkm_msec(device, 2000,
-		if (nvkm_rd32(device, 0x002634) == chan->base.chid)
-			break;
-	) < 0) {
-		nvkm_error(subdev, "channel %d [%s] kick timeout\n",
-			   chan->base.chid, nvkm_client_name(chan));
-		if (suspend)
-			return -EBUSY;
-	}
-
-	nvkm_kmap(engn);
-	nvkm_wo32(engn, addr + 0x00, 0x00000000);
-	nvkm_wo32(engn, addr + 0x04, 0x00000000);
-	nvkm_done(engn);
-	return 0;
-}
-
-static int
-gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-		     struct nvkm_oclass *oclass, void *data, u32 size,
-		     struct nvkm_object **pobject)
-{
-	union {
-		struct fermi_channel_gpfifo_v0 v0;
-	} *args = data;
-	struct gf100_fifo *fifo = (void *)engine;
-	struct gf100_fifo_base *base = (void *)parent;
-	struct gf100_fifo_chan *chan;
-	struct nvkm_gpuobj *ramfc = &base->base.gpuobj;
-	u64 usermem, ioffset, ilength;
-	int ret, i;
-
-	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
-	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d "
-				   "ioffset %016llx ilength %08x\n",
-			   args->v0.version, args->v0.ioffset,
-			   args->v0.ilength);
-		if (args->v0.vm)
-			return -ENOENT;
-	} else
-		return ret;
-
-	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
-				       fifo->user.bar.offset, 0x1000, 0,
-				       (1ULL << NVDEV_ENGINE_SW) |
-				       (1ULL << NVDEV_ENGINE_GR) |
-				       (1ULL << NVDEV_ENGINE_CE0) |
-				       (1ULL << NVDEV_ENGINE_CE1) |
-				       (1ULL << NVDEV_ENGINE_MSVLD) |
-				       (1ULL << NVDEV_ENGINE_MSPDEC) |
-				       (1ULL << NVDEV_ENGINE_MSPPP), &chan);
-	*pobject = nv_object(chan);
-	if (ret)
-		return ret;
-
-	chan->base.inst = base->base.gpuobj.addr;
-	args->v0.chid = chan->base.chid;
-
-	nv_parent(chan)->context_attach = gf100_fifo_context_attach;
-	nv_parent(chan)->context_detach = gf100_fifo_context_detach;
-
-	usermem = chan->base.chid * 0x1000;
-	ioffset = args->v0.ioffset;
-	ilength = order_base_2(args->v0.ilength / 8);
-
-	nvkm_kmap(fifo->user.mem);
-	for (i = 0; i < 0x1000; i += 4)
-		nvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);
-	nvkm_done(fifo->user.mem);
-	usermem = nvkm_memory_addr(fifo->user.mem) + usermem;
-
-	nvkm_kmap(ramfc);
-	nvkm_wo32(ramfc, 0x08, lower_32_bits(usermem));
-	nvkm_wo32(ramfc, 0x0c, upper_32_bits(usermem));
-	nvkm_wo32(ramfc, 0x10, 0x0000face);
-	nvkm_wo32(ramfc, 0x30, 0xfffff902);
-	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
-	nvkm_wo32(ramfc, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
-	nvkm_wo32(ramfc, 0x54, 0x00000002);
-	nvkm_wo32(ramfc, 0x84, 0x20400000);
-	nvkm_wo32(ramfc, 0x94, 0x30000001);
-	nvkm_wo32(ramfc, 0x9c, 0x00000100);
-	nvkm_wo32(ramfc, 0xa4, 0x1f1f1f1f);
-	nvkm_wo32(ramfc, 0xa8, 0x1f1f1f1f);
-	nvkm_wo32(ramfc, 0xac, 0x0000001f);
-	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
-	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
-	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
-	nvkm_done(ramfc);
-	return 0;
-}
-
-static int
-gf100_fifo_chan_init(struct nvkm_object *object)
-{
-	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
-	struct gf100_fifo *fifo = (void *)object->engine;
-	struct gf100_fifo_chan *chan = (void *)object;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	u32 chid = chan->base.chid;
-	int ret;
-
-	ret = nvkm_fifo_channel_init(&chan->base);
-	if (ret)
-		return ret;
-
-	nvkm_wr32(device, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
-
-	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
-		nvkm_wr32(device, 0x003004 + (chid * 8), 0x001f0001);
-		gf100_fifo_runlist_update(fifo);
-	}
-
-	return 0;
-}
-
-static void gf100_fifo_intr_engine(struct gf100_fifo *fifo);
-
-static int
-gf100_fifo_chan_fini(struct nvkm_object *object, bool suspend)
-{
-	struct gf100_fifo *fifo = (void *)object->engine;
-	struct gf100_fifo_chan *chan = (void *)object;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	u32 chid = chan->base.chid;
-
-	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
-		nvkm_mask(device, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
-		gf100_fifo_runlist_update(fifo);
-	}
-
-	gf100_fifo_intr_engine(fifo);
-
-	nvkm_wr32(device, 0x003000 + (chid * 8), 0x00000000);
-	return nvkm_fifo_channel_fini(&chan->base, suspend);
-}
-
-static struct nvkm_ofuncs
-gf100_fifo_ofuncs = {
-	.ctor = gf100_fifo_chan_ctor,
-	.dtor = _nvkm_fifo_channel_dtor,
-	.init = gf100_fifo_chan_init,
-	.fini = gf100_fifo_chan_fini,
-	.map  = _nvkm_fifo_channel_map,
-	.rd32 = _nvkm_fifo_channel_rd32,
-	.wr32 = _nvkm_fifo_channel_wr32,
-	.ntfy = _nvkm_fifo_channel_ntfy
-};
-
-static struct nvkm_oclass
-gf100_fifo_sclass[] = {
-	{ FERMI_CHANNEL_GPFIFO, &gf100_fifo_ofuncs },
-	{}
-};
-
-/*******************************************************************************
- * FIFO context - instmem heap and vm setup
- ******************************************************************************/
-
-static int
-gf100_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-			struct nvkm_oclass *oclass, void *data, u32 size,
-			struct nvkm_object **pobject)
-{
-	struct nvkm_device *device = nv_engine(engine)->subdev.device;
-	struct gf100_fifo_base *base;
-	int ret;
-
-	ret = nvkm_fifo_context_create(parent, engine, oclass, NULL, 0x1000,
-				       0x1000, NVOBJ_FLAG_ZERO_ALLOC |
-				       NVOBJ_FLAG_HEAP, &base);
-	*pobject = nv_object(base);
-	if (ret)
-		return ret;
-
-	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &base->pgd);
-	if (ret)
-		return ret;
-
-	nvkm_kmap(&base->base.gpuobj);
-	nvkm_wo32(&base->base.gpuobj, 0x0200, lower_32_bits(base->pgd->addr));
-	nvkm_wo32(&base->base.gpuobj, 0x0204, upper_32_bits(base->pgd->addr));
-	nvkm_wo32(&base->base.gpuobj, 0x0208, 0xffffffff);
-	nvkm_wo32(&base->base.gpuobj, 0x020c, 0x000000ff);
-	nvkm_done(&base->base.gpuobj);
-
-	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
-	if (ret)
-		return ret;
-
-	return 0;
-}
-
-static void
-gf100_fifo_context_dtor(struct nvkm_object *object)
-{
-	struct gf100_fifo_base *base = (void *)object;
-	nvkm_vm_ref(NULL, &base->vm, base->pgd);
-	nvkm_gpuobj_del(&base->pgd);
-	nvkm_fifo_context_destroy(&base->base);
-}
-
-static struct nvkm_oclass
-gf100_fifo_cclass = {
-	.handle = NV_ENGCTX(FIFO, 0xc0),
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = gf100_fifo_context_ctor,
-		.dtor = gf100_fifo_context_dtor,
-		.init = _nvkm_fifo_context_init,
-		.fini = _nvkm_fifo_context_fini,
-		.rd32 = _nvkm_fifo_context_rd32,
-		.wr32 = _nvkm_fifo_context_wr32,
-	},
-};
-
-/*******************************************************************************
- * PFIFO engine
- ******************************************************************************/
-
 static inline int
 gf100_fifo_engidx(struct gf100_fifo *fifo, u32 engn)
 {
@@ -739,7 +436,7 @@ gf100_fifo_intr_engine_unit(struct gf100_fifo *fifo, int engn)
 	}
 }
 
-static void
+void
 gf100_fifo_intr_engine(struct gf100_fifo *fifo)
 {
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
@@ -825,28 +522,62 @@ gf100_fifo_intr(struct nvkm_subdev *subdev)
 	}
 }
 
-static void
-gf100_fifo_uevent_init(struct nvkm_event *event, int type, int index)
+static int
+gf100_fifo_init(struct nvkm_object *object)
 {
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	struct nvkm_device *device = fifo->engine.subdev.device;
-	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
+	struct gf100_fifo *fifo = (void *)object;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
+	int ret, i;
+
+	ret = nvkm_fifo_init(&fifo->base);
+	if (ret)
+		return ret;
+
+	nvkm_wr32(device, 0x000204, 0xffffffff);
+	nvkm_wr32(device, 0x002204, 0xffffffff);
+
+	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x002204));
+	nvkm_debug(subdev, "%d PBDMA unit(s)\n", fifo->spoon_nr);
+
+	/* assign engines to PBDMAs */
+	if (fifo->spoon_nr >= 3) {
+		nvkm_wr32(device, 0x002208, ~(1 << 0)); /* PGRAPH */
+		nvkm_wr32(device, 0x00220c, ~(1 << 1)); /* PVP */
+		nvkm_wr32(device, 0x002210, ~(1 << 1)); /* PMSPP */
+		nvkm_wr32(device, 0x002214, ~(1 << 1)); /* PMSVLD */
+		nvkm_wr32(device, 0x002218, ~(1 << 2)); /* PCE0 */
+		nvkm_wr32(device, 0x00221c, ~(1 << 1)); /* PCE1 */
+	}
+
+	/* PBDMA[n] */
+	for (i = 0; i < fifo->spoon_nr; i++) {
+		nvkm_mask(device, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+		nvkm_wr32(device, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+		nvkm_wr32(device, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+	}
+
+	nvkm_mask(device, 0x002200, 0x00000001, 0x00000001);
+	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
+
+	nvkm_wr32(device, 0x002100, 0xffffffff);
+	nvkm_wr32(device, 0x002140, 0x7fffffff);
+	nvkm_wr32(device, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
+	return 0;
 }
 
 static void
-gf100_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
+gf100_fifo_dtor(struct nvkm_object *object)
 {
-	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	struct nvkm_device *device = fifo->engine.subdev.device;
-	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
-}
+	struct gf100_fifo *fifo = (void *)object;
 
-static const struct nvkm_event_func
-gf100_fifo_uevent_func = {
-	.ctor = nvkm_fifo_uevent_ctor,
-	.init = gf100_fifo_uevent_init,
-	.fini = gf100_fifo_uevent_fini,
-};
+	nvkm_vm_put(&fifo->user.bar);
+	nvkm_memory_del(&fifo->user.mem);
+	nvkm_memory_del(&fifo->runlist.mem[0]);
+	nvkm_memory_del(&fifo->runlist.mem[1]);
+
+	nvkm_fifo_destroy(&fifo->base);
+}
 
 static int
 gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
@@ -899,62 +630,6 @@ gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	return 0;
 }
 
-static void
-gf100_fifo_dtor(struct nvkm_object *object)
-{
-	struct gf100_fifo *fifo = (void *)object;
-
-	nvkm_vm_put(&fifo->user.bar);
-	nvkm_memory_del(&fifo->user.mem);
-	nvkm_memory_del(&fifo->runlist.mem[0]);
-	nvkm_memory_del(&fifo->runlist.mem[1]);
-
-	nvkm_fifo_destroy(&fifo->base);
-}
-
-static int
-gf100_fifo_init(struct nvkm_object *object)
-{
-	struct gf100_fifo *fifo = (void *)object;
-	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
-	struct nvkm_device *device = subdev->device;
-	int ret, i;
-
-	ret = nvkm_fifo_init(&fifo->base);
-	if (ret)
-		return ret;
-
-	nvkm_wr32(device, 0x000204, 0xffffffff);
-	nvkm_wr32(device, 0x002204, 0xffffffff);
-
-	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x002204));
-	nvkm_debug(subdev, "%d PBDMA unit(s)\n", fifo->spoon_nr);
-
-	/* assign engines to PBDMAs */
-	if (fifo->spoon_nr >= 3) {
-		nvkm_wr32(device, 0x002208, ~(1 << 0)); /* PGRAPH */
-		nvkm_wr32(device, 0x00220c, ~(1 << 1)); /* PVP */
-		nvkm_wr32(device, 0x002210, ~(1 << 1)); /* PMSPP */
-		nvkm_wr32(device, 0x002214, ~(1 << 1)); /* PMSVLD */
-		nvkm_wr32(device, 0x002218, ~(1 << 2)); /* PCE0 */
-		nvkm_wr32(device, 0x00221c, ~(1 << 1)); /* PCE1 */
-	}
-
-	/* PBDMA[n] */
-	for (i = 0; i < fifo->spoon_nr; i++) {
-		nvkm_mask(device, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
-		nvkm_wr32(device, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
-		nvkm_wr32(device, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
-	}
-
-	nvkm_mask(device, 0x002200, 0x00000001, 0x00000001);
-	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
-
-	nvkm_wr32(device, 0x002100, 0xffffffff);
-	nvkm_wr32(device, 0x002140, 0x7fffffff);
-	nvkm_wr32(device, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
-	return 0;
-}
 
 struct nvkm_oclass *
 gf100_fifo_oclass = &(struct nvkm_oclass) {

commit 6157091177102638c7d94ffc159c0b157a1c9b56
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:18 2015 +1000

    drm/nouveau/sw: remove dependence on namedb/engctx lookup
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 39031841d057..7f05985ebb37 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -31,6 +31,7 @@
 #include <subdev/fb.h>
 #include <subdev/mmu.h>
 #include <subdev/timer.h>
+#include <engine/sw.h>
 
 #include <nvif/class.h>
 #include <nvif/ioctl.h>
@@ -474,32 +475,6 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	schedule_work(&fifo->fault);
 }
 
-static int
-gf100_fifo_swmthd(struct gf100_fifo *fifo, u32 chid, u32 mthd, u32 data)
-{
-	struct gf100_fifo_chan *chan = NULL;
-	struct nvkm_handle *bind;
-	unsigned long flags;
-	int ret = -EINVAL;
-
-	spin_lock_irqsave(&fifo->base.lock, flags);
-	if (likely(chid >= fifo->base.min && chid <= fifo->base.max))
-		chan = (void *)fifo->base.channel[chid];
-	if (unlikely(!chan))
-		goto out;
-
-	bind = nvkm_namedb_get_class(nv_namedb(chan), NVIF_IOCTL_NEW_V0_SW_GF100);
-	if (likely(bind)) {
-		if (!mthd || !nv_call(bind->object, mthd, data))
-			ret = 0;
-		nvkm_namedb_put(bind);
-	}
-
-out:
-	spin_unlock_irqrestore(&fifo->base.lock, flags);
-	return ret;
-}
-
 static const struct nvkm_enum
 gf100_fifo_sched_reason[] = {
 	{ 0x0a, "CTXSW_TIMEOUT" },
@@ -701,8 +676,10 @@ gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 	char msg[128];
 
 	if (stat & 0x00800000) {
-		if (!gf100_fifo_swmthd(fifo, chid, mthd, data))
-			show &= ~0x00800000;
+		if (device->sw) {
+			if (nvkm_sw_mthd(device->sw, chid, subc, mthd, data))
+				show &= ~0x00800000;
+		}
 	}
 
 	if (show) {

commit 6ca307b0c9c7878eb1b2b42982c05671f0591229
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:18 2015 +1000

    drm/nouveau/fifo: remove dependence on namedb/engctx lookup
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 9053730aafca..39031841d057 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -462,17 +462,15 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	u32 chid = chan->base.chid;
-	unsigned long flags;
 
 	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
 		   nvkm_subdev_name[engine->subdev.index], chid);
+	assert_spin_locked(&fifo->base.lock);
 
 	nvkm_mask(device, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
 	chan->state = KILLED;
 
-	spin_lock_irqsave(&fifo->base.lock, flags);
 	fifo->mask |= 1ULL << nv_engidx(engine);
-	spin_unlock_irqrestore(&fifo->base.lock, flags);
 	schedule_work(&fifo->fault);
 }
 
@@ -514,8 +512,10 @@ gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_engine *engine;
 	struct gf100_fifo_chan *chan;
+	unsigned long flags;
 	u32 engn;
 
+	spin_lock_irqsave(&fifo->base.lock, flags);
 	for (engn = 0; engn < 6; engn++) {
 		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
 		u32 busy = (stat & 0x80000000);
@@ -533,6 +533,7 @@ gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
 			gf100_fifo_recover(fifo, engine, chan);
 		}
 	}
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
 }
 
 static void
@@ -630,9 +631,10 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 	u32 write  = (stat & 0x00000080);
 	u32 hub    = (stat & 0x00000040);
 	u32 reason = (stat & 0x0000000f);
-	struct nvkm_object *engctx = NULL, *object;
-	struct nvkm_engine *engine = NULL;
 	const struct nvkm_enum *er, *eu, *ec;
+	struct nvkm_engine *engine = NULL;
+	struct nvkm_fifo_chan *chan;
+	unsigned long flags;
 	char gpcid[8] = "";
 
 	er = nvkm_enum_find(gf100_fifo_fault_reason, reason);
@@ -657,31 +659,23 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 			break;
 		default:
 			engine = nvkm_engine(fifo, eu->data2);
-			if (engine)
-				engctx = nvkm_engctx_get(engine, inst);
 			break;
 		}
 	}
 
+	chan = nvkm_fifo_chan_inst(&fifo->base, (u64)inst << 12, &flags);
+
 	nvkm_error(subdev,
 		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
 		   "reason %02x [%s] on channel %d [%010llx %s]\n",
 		   write ? "write" : "read", (u64)vahi << 32 | valo,
 		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
-		   reason, er ? er->name : "", -1, (u64)inst << 12,
-		   nvkm_client_name(engctx));
-
-	object = engctx;
-	while (object) {
-		switch (nv_mclass(object)) {
-		case FERMI_CHANNEL_GPFIFO:
-			gf100_fifo_recover(fifo, engine, (void *)object);
-			break;
-		}
-		object = object->parent;
-	}
+		   reason, er ? er->name : "", chan ? chan->chid : -1,
+		   (u64)inst << 12,  nvkm_client_name(chan));
 
-	nvkm_engctx_put(engctx);
+	if (engine && chan)
+		gf100_fifo_recover(fifo, engine, (void *)chan);
+	nvkm_fifo_chan_put(&fifo->base, flags, &chan);
 }
 
 static const struct nvkm_bitfield

commit 344c2d429dd86b1b0113177e18f15adb74e9d936
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:18 2015 +1000

    drm/nouveau/fb: remove dependence on namedb/engctx lookup
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 77b8df1f57fb..9053730aafca 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -226,6 +226,7 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
+	chan->base.inst = base->base.gpuobj.addr;
 	args->v0.chid = chan->base.chid;
 
 	nv_parent(chan)->context_attach = gf100_fifo_context_attach;

commit f027f49166171c98d5945af12ac3ee9bc9f9bf4c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/gpuobj: separate allocation from nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index cbb8d249e7fb..77b8df1f57fb 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -130,8 +130,8 @@ gf100_fifo_context_attach(struct nvkm_object *parent,
 	}
 
 	if (!ectx->vma.node) {
-		ret = nvkm_gpuobj_map_vm(nv_gpuobj(ectx), base->vm,
-					 NV_MEM_ACCESS_RW, &ectx->vma);
+		ret = nvkm_gpuobj_map(nv_gpuobj(ectx), base->vm,
+				      NV_MEM_ACCESS_RW, &ectx->vma);
 		if (ret)
 			return ret;
 
@@ -334,6 +334,7 @@ gf100_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 			struct nvkm_oclass *oclass, void *data, u32 size,
 			struct nvkm_object **pobject)
 {
+	struct nvkm_device *device = nv_engine(engine)->subdev.device;
 	struct gf100_fifo_base *base;
 	int ret;
 
@@ -344,8 +345,7 @@ gf100_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(base), NULL, 0x10000, 0x1000, 0,
-			      &base->pgd);
+	ret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &base->pgd);
 	if (ret)
 		return ret;
 
@@ -368,7 +368,7 @@ gf100_fifo_context_dtor(struct nvkm_object *object)
 {
 	struct gf100_fifo_base *base = (void *)object;
 	nvkm_vm_ref(NULL, &base->vm, base->pgd);
-	nvkm_gpuobj_ref(NULL, &base->pgd);
+	nvkm_gpuobj_del(&base->pgd);
 	nvkm_fifo_context_destroy(&base->base);
 }
 

commit 358ce601ae5de59bf6f08f79455c5b3cb7d359d4
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/fifo: directly use instmem for runlists and polling areas
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 763a2db7603a..cbb8d249e7fb 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -27,6 +27,7 @@
 #include <core/engctx.h>
 #include <core/enum.h>
 #include <core/handle.h>
+#include <subdev/bar.h>
 #include <subdev/fb.h>
 #include <subdev/mmu.h>
 #include <subdev/timer.h>
@@ -42,13 +43,13 @@ struct gf100_fifo {
 	u64 mask;
 
 	struct {
-		struct nvkm_gpuobj *mem[2];
+		struct nvkm_memory *mem[2];
 		int active;
 		wait_queue_head_t wait;
 	} runlist;
 
 	struct {
-		struct nvkm_gpuobj *mem;
+		struct nvkm_memory *mem;
 		struct nvkm_vma bar;
 	} user;
 	int spoon_nr;
@@ -78,7 +79,7 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	struct nvkm_gpuobj *cur;
+	struct nvkm_memory *cur;
 	int i, p;
 
 	mutex_lock(&nv_subdev(fifo)->mutex);
@@ -96,7 +97,7 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 	}
 	nvkm_done(cur);
 
-	nvkm_wr32(device, 0x002270, cur->addr >> 12);
+	nvkm_wr32(device, 0x002270, nvkm_memory_addr(cur) >> 12);
 	nvkm_wr32(device, 0x002274, 0x01f00000 | (p >> 3));
 
 	if (wait_event_timeout(fifo->runlist.wait,
@@ -238,10 +239,11 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	for (i = 0; i < 0x1000; i += 4)
 		nvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);
 	nvkm_done(fifo->user.mem);
+	usermem = nvkm_memory_addr(fifo->user.mem) + usermem;
 
 	nvkm_kmap(ramfc);
-	nvkm_wo32(ramfc, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
-	nvkm_wo32(ramfc, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
+	nvkm_wo32(ramfc, 0x08, lower_32_bits(usermem));
+	nvkm_wo32(ramfc, 0x0c, upper_32_bits(usermem));
 	nvkm_wo32(ramfc, 0x10, 0x0000face);
 	nvkm_wo32(ramfc, 0x30, 0xfffff902);
 	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
@@ -879,6 +881,8 @@ gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct nvkm_oclass *oclass, void *data, u32 size,
 		struct nvkm_object **pobject)
 {
+	struct nvkm_device *device = (void *)parent;
+	struct nvkm_bar *bar = device->bar;
 	struct gf100_fifo *fifo;
 	int ret;
 
@@ -889,28 +893,29 @@ gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	INIT_WORK(&fifo->fault, gf100_fifo_recover_work);
 
-	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x1000, 0x1000, 0,
-			      &fifo->runlist.mem[0]);
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
+			      false, &fifo->runlist.mem[0]);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x1000, 0x1000, 0,
-			      &fifo->runlist.mem[1]);
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 0x1000, 0x1000,
+			      false, &fifo->runlist.mem[1]);
 	if (ret)
 		return ret;
 
 	init_waitqueue_head(&fifo->runlist.wait);
 
-	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 128 * 0x1000, 0x1000, 0,
-			      &fifo->user.mem);
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, 128 * 0x1000,
+			      0x1000, false, &fifo->user.mem);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_map(fifo->user.mem, NV_MEM_ACCESS_RW,
-			      &fifo->user.bar);
+	ret = bar->umap(bar, 128 * 0x1000, 12, &fifo->user.bar);
 	if (ret)
 		return ret;
 
+	nvkm_memory_map(fifo->user.mem, &fifo->user.bar, 0);
+
 	ret = nvkm_event_init(&gf100_fifo_uevent_func, 1, 1, &fifo->base.uevent);
 	if (ret)
 		return ret;
@@ -927,10 +932,10 @@ gf100_fifo_dtor(struct nvkm_object *object)
 {
 	struct gf100_fifo *fifo = (void *)object;
 
-	nvkm_gpuobj_unmap(&fifo->user.bar);
-	nvkm_gpuobj_ref(NULL, &fifo->user.mem);
-	nvkm_gpuobj_ref(NULL, &fifo->runlist.mem[0]);
-	nvkm_gpuobj_ref(NULL, &fifo->runlist.mem[1]);
+	nvkm_vm_put(&fifo->user.bar);
+	nvkm_memory_del(&fifo->user.mem);
+	nvkm_memory_del(&fifo->runlist.mem[0]);
+	nvkm_memory_del(&fifo->runlist.mem[1]);
 
 	nvkm_fifo_destroy(&fifo->base);
 }

commit d8e83994aaf6749b7124a219f5b46bd1329e2a08
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/imem: improve management of instance memory
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index ba6b390a1fef..763a2db7603a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -27,7 +27,6 @@
 #include <core/engctx.h>
 #include <core/enum.h>
 #include <core/handle.h>
-#include <subdev/bar.h>
 #include <subdev/fb.h>
 #include <subdev/mmu.h>
 #include <subdev/timer.h>
@@ -79,7 +78,6 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	struct nvkm_bar *bar = device->bar;
 	struct nvkm_gpuobj *cur;
 	int i, p;
 
@@ -96,7 +94,6 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 			p += 8;
 		}
 	}
-	bar->flush(bar);
 	nvkm_done(cur);
 
 	nvkm_wr32(device, 0x002270, cur->addr >> 12);
@@ -113,7 +110,6 @@ static int
 gf100_fifo_context_attach(struct nvkm_object *parent,
 			  struct nvkm_object *object)
 {
-	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gf100_fifo_base *base = (void *)parent->parent;
 	struct nvkm_gpuobj *engn = &base->base.gpuobj;
 	struct nvkm_engctx *ectx = (void *)object;
@@ -144,7 +140,6 @@ gf100_fifo_context_attach(struct nvkm_object *parent,
 	nvkm_kmap(engn);
 	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
 	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
-	bar->flush(bar);
 	nvkm_done(engn);
 	return 0;
 }
@@ -159,7 +154,6 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 	struct nvkm_gpuobj *engn = &base->base.gpuobj;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
-	struct nvkm_bar *bar = device->bar;
 	u32 addr;
 
 	switch (nv_engidx(object->engine)) {
@@ -188,7 +182,6 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 	nvkm_kmap(engn);
 	nvkm_wo32(engn, addr + 0x00, 0x00000000);
 	nvkm_wo32(engn, addr + 0x04, 0x00000000);
-	bar->flush(bar);
 	nvkm_done(engn);
 	return 0;
 }
@@ -201,7 +194,6 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	union {
 		struct fermi_channel_gpfifo_v0 v0;
 	} *args = data;
-	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gf100_fifo *fifo = (void *)engine;
 	struct gf100_fifo_base *base = (void *)parent;
 	struct gf100_fifo_chan *chan;
@@ -264,7 +256,6 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
 	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
 	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
-	bar->flush(bar);
 	nvkm_done(ramfc);
 	return 0;
 }

commit 6cf813fb26640ef539051fb7f965af8c9ff10d92
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/device: prepare for new-style subdevs
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 975a2547b8cd..ba6b390a1fef 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -435,7 +435,7 @@ gf100_fifo_recover_work(struct work_struct *work)
 {
 	struct gf100_fifo *fifo = container_of(work, typeof(*fifo), fault);
 	struct nvkm_device *device = fifo->base.engine.subdev.device;
-	struct nvkm_object *engine;
+	struct nvkm_engine *engine;
 	unsigned long flags;
 	u32 engn, engm = 0;
 	u64 mask, todo;
@@ -450,9 +450,9 @@ gf100_fifo_recover_work(struct work_struct *work)
 	nvkm_mask(device, 0x002630, engm, engm);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
-		if ((engine = (void *)nvkm_engine(fifo, engn))) {
-			nvkm_object_fini(engine, false);
-			WARN_ON(nvkm_object_init(engine));
+		if ((engine = nvkm_device_engine(device, engn))) {
+			nvkm_subdev_fini(&engine->subdev, false);
+			WARN_ON(nvkm_subdev_init(&engine->subdev));
 		}
 	}
 

commit f0290215c44370ff5d55c01a13dc5a44a1f86efa
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/subdev: implement support for new-style nvkm_subdev
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index dd7fe30edf46..975a2547b8cd 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -471,7 +471,7 @@ gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 	unsigned long flags;
 
 	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
-		   engine->subdev.name, chid);
+		   nvkm_subdev_name[engine->subdev.index], chid);
 
 	nvkm_mask(device, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
 	chan->state = KILLED;

commit cbea21e2ab658ca1256bfe5f4c535b2b1b9e4060
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/object: implement support for new-style nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 1fa38227059f..dd7fe30edf46 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -451,8 +451,8 @@ gf100_fifo_recover_work(struct work_struct *work)
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
 		if ((engine = (void *)nvkm_engine(fifo, engn))) {
-			nv_ofuncs(engine)->fini(engine, false);
-			WARN_ON(nv_ofuncs(engine)->init(engine));
+			nvkm_object_fini(engine, false);
+			WARN_ON(nvkm_object_init(engine));
 		}
 	}
 

commit 159045cdc460794df27e2cc624a9641be5c54b23
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/nvif: replace pushbuf with vm in fermi/kepler gpfifo class args
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index cdb25b5cf275..1fa38227059f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -199,7 +199,7 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		     struct nvkm_object **pobject)
 {
 	union {
-		struct nv50_channel_gpfifo_v0 v0;
+		struct fermi_channel_gpfifo_v0 v0;
 	} *args = data;
 	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gf100_fifo *fifo = (void *)engine;
@@ -211,16 +211,17 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %llx "
+		nvif_ioctl(parent, "create channel gpfifo vers %d "
 				   "ioffset %016llx ilength %08x\n",
-			   args->v0.version, args->v0.pushbuf, args->v0.ioffset,
+			   args->v0.version, args->v0.ioffset,
 			   args->v0.ilength);
+		if (args->v0.vm)
+			return -ENOENT;
 	} else
 		return ret;
 
 	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
-				       fifo->user.bar.offset, 0x1000,
-				       args->v0.pushbuf,
+				       fifo->user.bar.offset, 0x1000, 0,
 				       (1ULL << NVDEV_ENGINE_SW) |
 				       (1ULL << NVDEV_ENGINE_GR) |
 				       (1ULL << NVDEV_ENGINE_CE0) |

commit f58ddf9581655d3fea51465f06f292d365af9c87
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/nvif: assign internal class identifiers to sw classes
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index cfaa8aeb2223..cdb25b5cf275 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -33,6 +33,7 @@
 #include <subdev/timer.h>
 
 #include <nvif/class.h>
+#include <nvif/ioctl.h>
 #include <nvif/unpack.h>
 
 struct gf100_fifo {
@@ -494,7 +495,7 @@ gf100_fifo_swmthd(struct gf100_fifo *fifo, u32 chid, u32 mthd, u32 data)
 	if (unlikely(!chan))
 		goto out;
 
-	bind = nvkm_namedb_get_class(nv_namedb(chan), 0x906e);
+	bind = nvkm_namedb_get_class(nv_namedb(chan), NVIF_IOCTL_NEW_V0_SW_GF100);
 	if (likely(bind)) {
 		if (!mthd || !nv_call(bind->object, mthd, data))
 			ret = 0;

commit bf81df9be28657eea4aca8c6ab4ed3e69f8a051c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/nvif: replace path-based object identification
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index d940d41d1182..cfaa8aeb2223 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -210,7 +210,7 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
+		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %llx "
 				   "ioffset %016llx ilength %08x\n",
 			   args->v0.version, args->v0.pushbuf, args->v0.ioffset,
 			   args->v0.ilength);

commit 5444e770e3991ddb5a9583d622fc18bbf414b551
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:14 2015 +1000

    drm/nouveau/fifo: switch to gpuobj accessor macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index b043d08a35c9..d940d41d1182 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -86,15 +86,17 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 	cur = fifo->runlist.mem[fifo->runlist.active];
 	fifo->runlist.active = !fifo->runlist.active;
 
+	nvkm_kmap(cur);
 	for (i = 0, p = 0; i < 128; i++) {
 		struct gf100_fifo_chan *chan = (void *)fifo->base.channel[i];
 		if (chan && chan->state == RUNNING) {
-			nv_wo32(cur, p + 0, i);
-			nv_wo32(cur, p + 4, 0x00000004);
+			nvkm_wo32(cur, p + 0, i);
+			nvkm_wo32(cur, p + 4, 0x00000004);
 			p += 8;
 		}
 	}
 	bar->flush(bar);
+	nvkm_done(cur);
 
 	nvkm_wr32(device, 0x002270, cur->addr >> 12);
 	nvkm_wr32(device, 0x002274, 0x01f00000 | (p >> 3));
@@ -112,6 +114,7 @@ gf100_fifo_context_attach(struct nvkm_object *parent,
 {
 	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gf100_fifo_base *base = (void *)parent->parent;
+	struct nvkm_gpuobj *engn = &base->base.gpuobj;
 	struct nvkm_engctx *ectx = (void *)object;
 	u32 addr;
 	int ret;
@@ -137,9 +140,11 @@ gf100_fifo_context_attach(struct nvkm_object *parent,
 		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
 	}
 
-	nv_wo32(base, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
-	nv_wo32(base, addr + 0x04, upper_32_bits(ectx->vma.offset));
+	nvkm_kmap(engn);
+	nvkm_wo32(engn, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
+	nvkm_wo32(engn, addr + 0x04, upper_32_bits(ectx->vma.offset));
 	bar->flush(bar);
+	nvkm_done(engn);
 	return 0;
 }
 
@@ -150,6 +155,7 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 	struct gf100_fifo *fifo = (void *)parent->engine;
 	struct gf100_fifo_base *base = (void *)parent->parent;
 	struct gf100_fifo_chan *chan = (void *)parent;
+	struct nvkm_gpuobj *engn = &base->base.gpuobj;
 	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
 	struct nvkm_device *device = subdev->device;
 	struct nvkm_bar *bar = device->bar;
@@ -178,9 +184,11 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 			return -EBUSY;
 	}
 
-	nv_wo32(base, addr + 0x00, 0x00000000);
-	nv_wo32(base, addr + 0x04, 0x00000000);
+	nvkm_kmap(engn);
+	nvkm_wo32(engn, addr + 0x00, 0x00000000);
+	nvkm_wo32(engn, addr + 0x04, 0x00000000);
 	bar->flush(bar);
+	nvkm_done(engn);
 	return 0;
 }
 
@@ -196,6 +204,7 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	struct gf100_fifo *fifo = (void *)engine;
 	struct gf100_fifo_base *base = (void *)parent;
 	struct gf100_fifo_chan *chan;
+	struct nvkm_gpuobj *ramfc = &base->base.gpuobj;
 	u64 usermem, ioffset, ilength;
 	int ret, i;
 
@@ -231,26 +240,30 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	ioffset = args->v0.ioffset;
 	ilength = order_base_2(args->v0.ilength / 8);
 
+	nvkm_kmap(fifo->user.mem);
 	for (i = 0; i < 0x1000; i += 4)
-		nv_wo32(fifo->user.mem, usermem + i, 0x00000000);
-
-	nv_wo32(base, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
-	nv_wo32(base, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
-	nv_wo32(base, 0x10, 0x0000face);
-	nv_wo32(base, 0x30, 0xfffff902);
-	nv_wo32(base, 0x48, lower_32_bits(ioffset));
-	nv_wo32(base, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
-	nv_wo32(base, 0x54, 0x00000002);
-	nv_wo32(base, 0x84, 0x20400000);
-	nv_wo32(base, 0x94, 0x30000001);
-	nv_wo32(base, 0x9c, 0x00000100);
-	nv_wo32(base, 0xa4, 0x1f1f1f1f);
-	nv_wo32(base, 0xa8, 0x1f1f1f1f);
-	nv_wo32(base, 0xac, 0x0000001f);
-	nv_wo32(base, 0xb8, 0xf8000000);
-	nv_wo32(base, 0xf8, 0x10003080); /* 0x002310 */
-	nv_wo32(base, 0xfc, 0x10000010); /* 0x002350 */
+		nvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);
+	nvkm_done(fifo->user.mem);
+
+	nvkm_kmap(ramfc);
+	nvkm_wo32(ramfc, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
+	nvkm_wo32(ramfc, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
+	nvkm_wo32(ramfc, 0x10, 0x0000face);
+	nvkm_wo32(ramfc, 0x30, 0xfffff902);
+	nvkm_wo32(ramfc, 0x48, lower_32_bits(ioffset));
+	nvkm_wo32(ramfc, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
+	nvkm_wo32(ramfc, 0x54, 0x00000002);
+	nvkm_wo32(ramfc, 0x84, 0x20400000);
+	nvkm_wo32(ramfc, 0x94, 0x30000001);
+	nvkm_wo32(ramfc, 0x9c, 0x00000100);
+	nvkm_wo32(ramfc, 0xa4, 0x1f1f1f1f);
+	nvkm_wo32(ramfc, 0xa8, 0x1f1f1f1f);
+	nvkm_wo32(ramfc, 0xac, 0x0000001f);
+	nvkm_wo32(ramfc, 0xb8, 0xf8000000);
+	nvkm_wo32(ramfc, 0xf8, 0x10003080); /* 0x002310 */
+	nvkm_wo32(ramfc, 0xfc, 0x10000010); /* 0x002350 */
 	bar->flush(bar);
+	nvkm_done(ramfc);
 	return 0;
 }
 
@@ -341,10 +354,12 @@ gf100_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	nv_wo32(base, 0x0200, lower_32_bits(base->pgd->addr));
-	nv_wo32(base, 0x0204, upper_32_bits(base->pgd->addr));
-	nv_wo32(base, 0x0208, 0xffffffff);
-	nv_wo32(base, 0x020c, 0x000000ff);
+	nvkm_kmap(&base->base.gpuobj);
+	nvkm_wo32(&base->base.gpuobj, 0x0200, lower_32_bits(base->pgd->addr));
+	nvkm_wo32(&base->base.gpuobj, 0x0204, upper_32_bits(base->pgd->addr));
+	nvkm_wo32(&base->base.gpuobj, 0x0208, 0xffffffff);
+	nvkm_wo32(&base->base.gpuobj, 0x020c, 0x000000ff);
+	nvkm_done(&base->base.gpuobj);
 
 	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
 	if (ret)

commit 53003941067534b1071b0f7b71f4700c16d97b28
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:13 2015 +1000

    drm/nouveau/core: remove last printks
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index e438e9fee206..b043d08a35c9 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -199,12 +199,12 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	u64 usermem, ioffset, ilength;
 	int ret, i;
 
-	nv_ioctl(parent, "create channel gpfifo size %d\n", size);
+	nvif_ioctl(parent, "create channel gpfifo size %d\n", size);
 	if (nvif_unpack(args->v0, 0, 0, false)) {
-		nv_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
-				 "ioffset %016llx ilength %08x\n",
-			 args->v0.version, args->v0.pushbuf, args->v0.ioffset,
-			 args->v0.ilength);
+		nvif_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
+				   "ioffset %016llx ilength %08x\n",
+			   args->v0.version, args->v0.pushbuf, args->v0.ioffset,
+			   args->v0.ilength);
 	} else
 		return ret;
 

commit e5c5e4f5d319799fe67dc67531e41ba0b7ed15e6
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:13 2015 +1000

    drm/nouveau/fifo: switch to subdev printk macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 503ea8088345..e438e9fee206 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -76,7 +76,8 @@ struct gf100_fifo_chan {
 static void
 gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	struct nvkm_bar *bar = device->bar;
 	struct nvkm_gpuobj *cur;
 	int i, p;
@@ -101,7 +102,7 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 	if (wait_event_timeout(fifo->runlist.wait,
 			       !(nvkm_rd32(device, 0x00227c) & 0x00100000),
 			       msecs_to_jiffies(2000)) == 0)
-		nv_error(fifo, "runlist update timeout\n");
+		nvkm_error(subdev, "runlist update timeout\n");
 	mutex_unlock(&nv_subdev(fifo)->mutex);
 }
 
@@ -149,7 +150,8 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 	struct gf100_fifo *fifo = (void *)parent->engine;
 	struct gf100_fifo_base *base = (void *)parent->parent;
 	struct gf100_fifo_chan *chan = (void *)parent;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	struct nvkm_bar *bar = device->bar;
 	u32 addr;
 
@@ -170,8 +172,8 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 		if (nvkm_rd32(device, 0x002634) == chan->base.chid)
 			break;
 	) < 0) {
-		nv_error(fifo, "channel %d [%s] kick timeout\n",
-			 chan->base.chid, nvkm_client_name(chan));
+		nvkm_error(subdev, "channel %d [%s] kick timeout\n",
+			   chan->base.chid, nvkm_client_name(chan));
 		if (suspend)
 			return -EBUSY;
 	}
@@ -446,12 +448,13 @@ static void
 gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 		   struct gf100_fifo_chan *chan)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 chid = chan->base.chid;
 	unsigned long flags;
 
-	nv_error(fifo, "%s engine fault on channel %d, recovering...\n",
-		       nv_subdev(engine)->name, chid);
+	nvkm_error(subdev, "%s engine fault on channel %d, recovering...\n",
+		   engine->subdev.name, chid);
 
 	nvkm_mask(device, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
 	chan->state = KILLED;
@@ -524,17 +527,15 @@ gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
 static void
 gf100_fifo_intr_sched(struct gf100_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 intr = nvkm_rd32(device, 0x00254c);
 	u32 code = intr & 0x000000ff;
 	const struct nvkm_enum *en;
-	char enunk[6] = "";
 
 	en = nvkm_enum_find(gf100_fifo_sched_reason, code);
-	if (!en)
-		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
 
-	nv_error(fifo, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
+	nvkm_error(subdev, "SCHED_ERROR %02x [%s]\n", code, en ? en->name : "");
 
 	switch (code) {
 	case 0x0a:
@@ -607,7 +608,8 @@ gf100_fifo_fault_gpcclient[] = {
 static void
 gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
 	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
 	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
@@ -620,16 +622,17 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 	struct nvkm_object *engctx = NULL, *object;
 	struct nvkm_engine *engine = NULL;
 	const struct nvkm_enum *er, *eu, *ec;
-	char erunk[6] = "";
-	char euunk[6] = "";
-	char ecunk[6] = "";
-	char gpcid[3] = "";
+	char gpcid[8] = "";
 
 	er = nvkm_enum_find(gf100_fifo_fault_reason, reason);
-	if (!er)
-		snprintf(erunk, sizeof(erunk), "UNK%02X", reason);
-
 	eu = nvkm_enum_find(gf100_fifo_fault_engine, unit);
+	if (hub) {
+		ec = nvkm_enum_find(gf100_fifo_fault_hubclient, client);
+	} else {
+		ec = nvkm_enum_find(gf100_fifo_fault_gpcclient, client);
+		snprintf(gpcid, sizeof(gpcid), "GPC%d/", gpc);
+	}
+
 	if (eu) {
 		switch (eu->data2) {
 		case NVDEV_SUBDEV_BAR:
@@ -647,26 +650,15 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 				engctx = nvkm_engctx_get(engine, inst);
 			break;
 		}
-	} else {
-		snprintf(euunk, sizeof(euunk), "UNK%02x", unit);
-	}
-
-	if (hub) {
-		ec = nvkm_enum_find(gf100_fifo_fault_hubclient, client);
-	} else {
-		ec = nvkm_enum_find(gf100_fifo_fault_gpcclient, client);
-		snprintf(gpcid, sizeof(gpcid), "%d", gpc);
 	}
 
-	if (!ec)
-		snprintf(ecunk, sizeof(ecunk), "UNK%02x", client);
-
-	nv_error(fifo, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
-		       "channel 0x%010llx [%s]\n", write ? "write" : "read",
-		 (u64)vahi << 32 | valo, er ? er->name : erunk,
-		 eu ? eu->name : euunk, hub ? "" : "GPC", gpcid, hub ? "" : "/",
-		 ec ? ec->name : ecunk, (u64)inst << 12,
-		 nvkm_client_name(engctx));
+	nvkm_error(subdev,
+		   "%s fault at %010llx engine %02x [%s] client %02x [%s%s] "
+		   "reason %02x [%s] on channel %d [%010llx %s]\n",
+		   write ? "write" : "read", (u64)vahi << 32 | valo,
+		   unit, eu ? eu->name : "", client, gpcid, ec ? ec->name : "",
+		   reason, er ? er->name : "", -1, (u64)inst << 12,
+		   nvkm_client_name(engctx));
 
 	object = engctx;
 	while (object) {
@@ -692,14 +684,16 @@ gf100_fifo_pbdma_intr[] = {
 static void
 gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 stat = nvkm_rd32(device, 0x040108 + (unit * 0x2000));
 	u32 addr = nvkm_rd32(device, 0x0400c0 + (unit * 0x2000));
 	u32 data = nvkm_rd32(device, 0x0400c4 + (unit * 0x2000));
 	u32 chid = nvkm_rd32(device, 0x040120 + (unit * 0x2000)) & 0x7f;
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
-	u32 show = stat;
+	u32 show= stat;
+	char msg[128];
 
 	if (stat & 0x00800000) {
 		if (!gf100_fifo_swmthd(fifo, chid, mthd, data))
@@ -707,14 +701,12 @@ gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 	}
 
 	if (show) {
-		nv_error(fifo, "PBDMA%d:", unit);
-		nvkm_bitfield_print(gf100_fifo_pbdma_intr, show);
-		pr_cont("\n");
-		nv_error(fifo,
-			 "PBDMA%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
-			 unit, chid,
-			 nvkm_client_name_for_fifo_chid(&fifo->base, chid),
-			 subc, mthd, data);
+		nvkm_snprintbf(msg, sizeof(msg), gf100_fifo_pbdma_intr, show);
+		nvkm_error(subdev, "PBDMA%d: %08x [%s] ch %d [%s] subc %d "
+				   "mthd %04x data %08x\n",
+			   unit, show, msg, chid,
+			   nvkm_client_name_for_fifo_chid(&fifo->base, chid),
+			   subc, mthd, data);
 	}
 
 	nvkm_wr32(device, 0x0400c0 + (unit * 0x2000), 0x80600008);
@@ -724,7 +716,8 @@ gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 static void
 gf100_fifo_intr_runlist(struct gf100_fifo *fifo)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 intr = nvkm_rd32(device, 0x002a00);
 
 	if (intr & 0x10000000) {
@@ -734,7 +727,7 @@ gf100_fifo_intr_runlist(struct gf100_fifo *fifo)
 	}
 
 	if (intr) {
-		nv_error(fifo, "RUNLIST 0x%08x\n", intr);
+		nvkm_error(subdev, "RUNLIST %08x\n", intr);
 		nvkm_wr32(device, 0x002a00, intr);
 	}
 }
@@ -742,7 +735,8 @@ gf100_fifo_intr_runlist(struct gf100_fifo *fifo)
 static void
 gf100_fifo_intr_engine_unit(struct gf100_fifo *fifo, int engn)
 {
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	u32 intr = nvkm_rd32(device, 0x0025a8 + (engn * 0x04));
 	u32 inte = nvkm_rd32(device, 0x002628);
 	u32 unkn;
@@ -756,7 +750,8 @@ gf100_fifo_intr_engine_unit(struct gf100_fifo *fifo, int engn)
 			ints &= ~1;
 		}
 		if (ints) {
-			nv_error(fifo, "ENGINE %d %d %01x", engn, unkn, ints);
+			nvkm_error(subdev, "ENGINE %d %d %01x",
+				   engn, unkn, ints);
 			nvkm_mask(device, 0x002628, ints, 0);
 		}
 	}
@@ -784,7 +779,7 @@ gf100_fifo_intr(struct nvkm_subdev *subdev)
 
 	if (stat & 0x00000001) {
 		u32 intr = nvkm_rd32(device, 0x00252c);
-		nv_warn(fifo, "INTR 0x00000001: 0x%08x\n", intr);
+		nvkm_warn(subdev, "INTR 00000001: %08x\n", intr);
 		nvkm_wr32(device, 0x002100, 0x00000001);
 		stat &= ~0x00000001;
 	}
@@ -797,14 +792,14 @@ gf100_fifo_intr(struct nvkm_subdev *subdev)
 
 	if (stat & 0x00010000) {
 		u32 intr = nvkm_rd32(device, 0x00256c);
-		nv_warn(fifo, "INTR 0x00010000: 0x%08x\n", intr);
+		nvkm_warn(subdev, "INTR 00010000: %08x\n", intr);
 		nvkm_wr32(device, 0x002100, 0x00010000);
 		stat &= ~0x00010000;
 	}
 
 	if (stat & 0x01000000) {
 		u32 intr = nvkm_rd32(device, 0x00258c);
-		nv_warn(fifo, "INTR 0x01000000: 0x%08x\n", intr);
+		nvkm_warn(subdev, "INTR 01000000: %08x\n", intr);
 		nvkm_wr32(device, 0x002100, 0x01000000);
 		stat &= ~0x01000000;
 	}
@@ -842,7 +837,7 @@ gf100_fifo_intr(struct nvkm_subdev *subdev)
 	}
 
 	if (stat) {
-		nv_error(fifo, "INTR 0x%08x\n", stat);
+		nvkm_error(subdev, "INTR %08x\n", stat);
 		nvkm_mask(device, 0x002140, stat, 0x00000000);
 		nvkm_wr32(device, 0x002100, stat);
 	}
@@ -936,7 +931,8 @@ static int
 gf100_fifo_init(struct nvkm_object *object)
 {
 	struct gf100_fifo *fifo = (void *)object;
-	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_subdev *subdev = &fifo->base.engine.subdev;
+	struct nvkm_device *device = subdev->device;
 	int ret, i;
 
 	ret = nvkm_fifo_init(&fifo->base);
@@ -947,7 +943,7 @@ gf100_fifo_init(struct nvkm_object *object)
 	nvkm_wr32(device, 0x002204, 0xffffffff);
 
 	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x002204));
-	nv_debug(fifo, "%d PBDMA unit(s)\n", fifo->spoon_nr);
+	nvkm_debug(subdev, "%d PBDMA unit(s)\n", fifo->spoon_nr);
 
 	/* assign engines to PBDMAs */
 	if (fifo->spoon_nr >= 3) {

commit af3082b3c621e75371dc6d11fac5a2dc2b19b1bc
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:11 2015 +1000

    drm/nouveau/fifo: switch to new-style timer macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index f714bda4230f..503ea8088345 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -166,7 +166,10 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 	}
 
 	nvkm_wr32(device, 0x002634, chan->base.chid);
-	if (!nv_wait(fifo, 0x002634, 0xffffffff, chan->base.chid)) {
+	if (nvkm_msec(device, 2000,
+		if (nvkm_rd32(device, 0x002634) == chan->base.chid)
+			break;
+	) < 0) {
 		nv_error(fifo, "channel %d [%s] kick timeout\n",
 			 chan->base.chid, nvkm_client_name(chan));
 		if (suspend)

commit 8774440390cdfe37c5d003f850847c9fd67cdf61
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:10 2015 +1000

    drm/nouveau/fifo: switch to device pri macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index 0a7971a3317c..f714bda4230f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -76,7 +76,8 @@ struct gf100_fifo_chan {
 static void
 gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
-	struct nvkm_bar *bar = nvkm_bar(fifo);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_bar *bar = device->bar;
 	struct nvkm_gpuobj *cur;
 	int i, p;
 
@@ -94,11 +95,11 @@ gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 	}
 	bar->flush(bar);
 
-	nv_wr32(fifo, 0x002270, cur->addr >> 12);
-	nv_wr32(fifo, 0x002274, 0x01f00000 | (p >> 3));
+	nvkm_wr32(device, 0x002270, cur->addr >> 12);
+	nvkm_wr32(device, 0x002274, 0x01f00000 | (p >> 3));
 
 	if (wait_event_timeout(fifo->runlist.wait,
-			       !(nv_rd32(fifo, 0x00227c) & 0x00100000),
+			       !(nvkm_rd32(device, 0x00227c) & 0x00100000),
 			       msecs_to_jiffies(2000)) == 0)
 		nv_error(fifo, "runlist update timeout\n");
 	mutex_unlock(&nv_subdev(fifo)->mutex);
@@ -145,10 +146,11 @@ static int
 gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 			  struct nvkm_object *object)
 {
-	struct nvkm_bar *bar = nvkm_bar(parent);
 	struct gf100_fifo *fifo = (void *)parent->engine;
 	struct gf100_fifo_base *base = (void *)parent->parent;
 	struct gf100_fifo_chan *chan = (void *)parent;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	struct nvkm_bar *bar = device->bar;
 	u32 addr;
 
 	switch (nv_engidx(object->engine)) {
@@ -163,7 +165,7 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 		return -EINVAL;
 	}
 
-	nv_wr32(fifo, 0x002634, chan->base.chid);
+	nvkm_wr32(device, 0x002634, chan->base.chid);
 	if (!nv_wait(fifo, 0x002634, 0xffffffff, chan->base.chid)) {
 		nv_error(fifo, "channel %d [%s] kick timeout\n",
 			 chan->base.chid, nvkm_client_name(chan));
@@ -253,6 +255,7 @@ gf100_fifo_chan_init(struct nvkm_object *object)
 	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
 	struct gf100_fifo *fifo = (void *)object->engine;
 	struct gf100_fifo_chan *chan = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u32 chid = chan->base.chid;
 	int ret;
 
@@ -260,10 +263,10 @@ gf100_fifo_chan_init(struct nvkm_object *object)
 	if (ret)
 		return ret;
 
-	nv_wr32(fifo, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
+	nvkm_wr32(device, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
 
 	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
-		nv_wr32(fifo, 0x003004 + (chid * 8), 0x001f0001);
+		nvkm_wr32(device, 0x003004 + (chid * 8), 0x001f0001);
 		gf100_fifo_runlist_update(fifo);
 	}
 
@@ -277,16 +280,17 @@ gf100_fifo_chan_fini(struct nvkm_object *object, bool suspend)
 {
 	struct gf100_fifo *fifo = (void *)object->engine;
 	struct gf100_fifo_chan *chan = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u32 chid = chan->base.chid;
 
 	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
-		nv_mask(fifo, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
+		nvkm_mask(device, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
 		gf100_fifo_runlist_update(fifo);
 	}
 
 	gf100_fifo_intr_engine(fifo);
 
-	nv_wr32(fifo, 0x003000 + (chid * 8), 0x00000000);
+	nvkm_wr32(device, 0x003000 + (chid * 8), 0x00000000);
 	return nvkm_fifo_channel_fini(&chan->base, suspend);
 }
 
@@ -408,6 +412,7 @@ static void
 gf100_fifo_recover_work(struct work_struct *work)
 {
 	struct gf100_fifo *fifo = container_of(work, typeof(*fifo), fault);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_object *engine;
 	unsigned long flags;
 	u32 engn, engm = 0;
@@ -420,7 +425,7 @@ gf100_fifo_recover_work(struct work_struct *work)
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
 		engm |= 1 << gf100_fifo_engidx(fifo, engn);
-	nv_mask(fifo, 0x002630, engm, engm);
+	nvkm_mask(device, 0x002630, engm, engm);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
 		if ((engine = (void *)nvkm_engine(fifo, engn))) {
@@ -430,21 +435,22 @@ gf100_fifo_recover_work(struct work_struct *work)
 	}
 
 	gf100_fifo_runlist_update(fifo);
-	nv_wr32(fifo, 0x00262c, engm);
-	nv_mask(fifo, 0x002630, engm, 0x00000000);
+	nvkm_wr32(device, 0x00262c, engm);
+	nvkm_mask(device, 0x002630, engm, 0x00000000);
 }
 
 static void
 gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 		   struct gf100_fifo_chan *chan)
 {
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	u32 chid = chan->base.chid;
 	unsigned long flags;
 
 	nv_error(fifo, "%s engine fault on channel %d, recovering...\n",
 		       nv_subdev(engine)->name, chid);
 
-	nv_mask(fifo, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
+	nvkm_mask(device, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
 	chan->state = KILLED;
 
 	spin_lock_irqsave(&fifo->base.lock, flags);
@@ -488,12 +494,13 @@ gf100_fifo_sched_reason[] = {
 static void
 gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
 {
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	struct nvkm_engine *engine;
 	struct gf100_fifo_chan *chan;
 	u32 engn;
 
 	for (engn = 0; engn < 6; engn++) {
-		u32 stat = nv_rd32(fifo, 0x002640 + (engn * 0x04));
+		u32 stat = nvkm_rd32(device, 0x002640 + (engn * 0x04));
 		u32 busy = (stat & 0x80000000);
 		u32 save = (stat & 0x00100000); /* maybe? */
 		u32 unk0 = (stat & 0x00040000);
@@ -514,7 +521,8 @@ gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
 static void
 gf100_fifo_intr_sched(struct gf100_fifo *fifo)
 {
-	u32 intr = nv_rd32(fifo, 0x00254c);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 intr = nvkm_rd32(device, 0x00254c);
 	u32 code = intr & 0x000000ff;
 	const struct nvkm_enum *en;
 	char enunk[6] = "";
@@ -596,10 +604,11 @@ gf100_fifo_fault_gpcclient[] = {
 static void
 gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 {
-	u32 inst = nv_rd32(fifo, 0x002800 + (unit * 0x10));
-	u32 valo = nv_rd32(fifo, 0x002804 + (unit * 0x10));
-	u32 vahi = nv_rd32(fifo, 0x002808 + (unit * 0x10));
-	u32 stat = nv_rd32(fifo, 0x00280c + (unit * 0x10));
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 inst = nvkm_rd32(device, 0x002800 + (unit * 0x10));
+	u32 valo = nvkm_rd32(device, 0x002804 + (unit * 0x10));
+	u32 vahi = nvkm_rd32(device, 0x002808 + (unit * 0x10));
+	u32 stat = nvkm_rd32(device, 0x00280c + (unit * 0x10));
 	u32 gpc    = (stat & 0x1f000000) >> 24;
 	u32 client = (stat & 0x00001f00) >> 8;
 	u32 write  = (stat & 0x00000080);
@@ -621,13 +630,13 @@ gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 	if (eu) {
 		switch (eu->data2) {
 		case NVDEV_SUBDEV_BAR:
-			nv_mask(fifo, 0x001704, 0x00000000, 0x00000000);
+			nvkm_mask(device, 0x001704, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_SUBDEV_INSTMEM:
-			nv_mask(fifo, 0x001714, 0x00000000, 0x00000000);
+			nvkm_mask(device, 0x001714, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_ENGINE_IFB:
-			nv_mask(fifo, 0x001718, 0x00000000, 0x00000000);
+			nvkm_mask(device, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:
 			engine = nvkm_engine(fifo, eu->data2);
@@ -680,10 +689,11 @@ gf100_fifo_pbdma_intr[] = {
 static void
 gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 {
-	u32 stat = nv_rd32(fifo, 0x040108 + (unit * 0x2000));
-	u32 addr = nv_rd32(fifo, 0x0400c0 + (unit * 0x2000));
-	u32 data = nv_rd32(fifo, 0x0400c4 + (unit * 0x2000));
-	u32 chid = nv_rd32(fifo, 0x040120 + (unit * 0x2000)) & 0x7f;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 stat = nvkm_rd32(device, 0x040108 + (unit * 0x2000));
+	u32 addr = nvkm_rd32(device, 0x0400c0 + (unit * 0x2000));
+	u32 data = nvkm_rd32(device, 0x0400c4 + (unit * 0x2000));
+	u32 chid = nvkm_rd32(device, 0x040120 + (unit * 0x2000)) & 0x7f;
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
 	u32 show = stat;
@@ -704,35 +714,37 @@ gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 			 subc, mthd, data);
 	}
 
-	nv_wr32(fifo, 0x0400c0 + (unit * 0x2000), 0x80600008);
-	nv_wr32(fifo, 0x040108 + (unit * 0x2000), stat);
+	nvkm_wr32(device, 0x0400c0 + (unit * 0x2000), 0x80600008);
+	nvkm_wr32(device, 0x040108 + (unit * 0x2000), stat);
 }
 
 static void
 gf100_fifo_intr_runlist(struct gf100_fifo *fifo)
 {
-	u32 intr = nv_rd32(fifo, 0x002a00);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 intr = nvkm_rd32(device, 0x002a00);
 
 	if (intr & 0x10000000) {
 		wake_up(&fifo->runlist.wait);
-		nv_wr32(fifo, 0x002a00, 0x10000000);
+		nvkm_wr32(device, 0x002a00, 0x10000000);
 		intr &= ~0x10000000;
 	}
 
 	if (intr) {
 		nv_error(fifo, "RUNLIST 0x%08x\n", intr);
-		nv_wr32(fifo, 0x002a00, intr);
+		nvkm_wr32(device, 0x002a00, intr);
 	}
 }
 
 static void
 gf100_fifo_intr_engine_unit(struct gf100_fifo *fifo, int engn)
 {
-	u32 intr = nv_rd32(fifo, 0x0025a8 + (engn * 0x04));
-	u32 inte = nv_rd32(fifo, 0x002628);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 intr = nvkm_rd32(device, 0x0025a8 + (engn * 0x04));
+	u32 inte = nvkm_rd32(device, 0x002628);
 	u32 unkn;
 
-	nv_wr32(fifo, 0x0025a8 + (engn * 0x04), intr);
+	nvkm_wr32(device, 0x0025a8 + (engn * 0x04), intr);
 
 	for (unkn = 0; unkn < 8; unkn++) {
 		u32 ints = (intr >> (unkn * 0x04)) & inte;
@@ -742,7 +754,7 @@ gf100_fifo_intr_engine_unit(struct gf100_fifo *fifo, int engn)
 		}
 		if (ints) {
 			nv_error(fifo, "ENGINE %d %d %01x", engn, unkn, ints);
-			nv_mask(fifo, 0x002628, ints, 0);
+			nvkm_mask(device, 0x002628, ints, 0);
 		}
 	}
 }
@@ -750,7 +762,8 @@ gf100_fifo_intr_engine_unit(struct gf100_fifo *fifo, int engn)
 static void
 gf100_fifo_intr_engine(struct gf100_fifo *fifo)
 {
-	u32 mask = nv_rd32(fifo, 0x0025a4);
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 mask = nvkm_rd32(device, 0x0025a4);
 	while (mask) {
 		u32 unit = __ffs(mask);
 		gf100_fifo_intr_engine_unit(fifo, unit);
@@ -762,53 +775,54 @@ static void
 gf100_fifo_intr(struct nvkm_subdev *subdev)
 {
 	struct gf100_fifo *fifo = (void *)subdev;
-	u32 mask = nv_rd32(fifo, 0x002140);
-	u32 stat = nv_rd32(fifo, 0x002100) & mask;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
+	u32 mask = nvkm_rd32(device, 0x002140);
+	u32 stat = nvkm_rd32(device, 0x002100) & mask;
 
 	if (stat & 0x00000001) {
-		u32 intr = nv_rd32(fifo, 0x00252c);
+		u32 intr = nvkm_rd32(device, 0x00252c);
 		nv_warn(fifo, "INTR 0x00000001: 0x%08x\n", intr);
-		nv_wr32(fifo, 0x002100, 0x00000001);
+		nvkm_wr32(device, 0x002100, 0x00000001);
 		stat &= ~0x00000001;
 	}
 
 	if (stat & 0x00000100) {
 		gf100_fifo_intr_sched(fifo);
-		nv_wr32(fifo, 0x002100, 0x00000100);
+		nvkm_wr32(device, 0x002100, 0x00000100);
 		stat &= ~0x00000100;
 	}
 
 	if (stat & 0x00010000) {
-		u32 intr = nv_rd32(fifo, 0x00256c);
+		u32 intr = nvkm_rd32(device, 0x00256c);
 		nv_warn(fifo, "INTR 0x00010000: 0x%08x\n", intr);
-		nv_wr32(fifo, 0x002100, 0x00010000);
+		nvkm_wr32(device, 0x002100, 0x00010000);
 		stat &= ~0x00010000;
 	}
 
 	if (stat & 0x01000000) {
-		u32 intr = nv_rd32(fifo, 0x00258c);
+		u32 intr = nvkm_rd32(device, 0x00258c);
 		nv_warn(fifo, "INTR 0x01000000: 0x%08x\n", intr);
-		nv_wr32(fifo, 0x002100, 0x01000000);
+		nvkm_wr32(device, 0x002100, 0x01000000);
 		stat &= ~0x01000000;
 	}
 
 	if (stat & 0x10000000) {
-		u32 mask = nv_rd32(fifo, 0x00259c);
+		u32 mask = nvkm_rd32(device, 0x00259c);
 		while (mask) {
 			u32 unit = __ffs(mask);
 			gf100_fifo_intr_fault(fifo, unit);
-			nv_wr32(fifo, 0x00259c, (1 << unit));
+			nvkm_wr32(device, 0x00259c, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x10000000;
 	}
 
 	if (stat & 0x20000000) {
-		u32 mask = nv_rd32(fifo, 0x0025a0);
+		u32 mask = nvkm_rd32(device, 0x0025a0);
 		while (mask) {
 			u32 unit = __ffs(mask);
 			gf100_fifo_intr_pbdma(fifo, unit);
-			nv_wr32(fifo, 0x0025a0, (1 << unit));
+			nvkm_wr32(device, 0x0025a0, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x20000000;
@@ -826,8 +840,8 @@ gf100_fifo_intr(struct nvkm_subdev *subdev)
 
 	if (stat) {
 		nv_error(fifo, "INTR 0x%08x\n", stat);
-		nv_mask(fifo, 0x002140, stat, 0x00000000);
-		nv_wr32(fifo, 0x002100, stat);
+		nvkm_mask(device, 0x002140, stat, 0x00000000);
+		nvkm_wr32(device, 0x002100, stat);
 	}
 }
 
@@ -835,14 +849,16 @@ static void
 gf100_fifo_uevent_init(struct nvkm_event *event, int type, int index)
 {
 	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	nv_mask(fifo, 0x002140, 0x80000000, 0x80000000);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x80000000);
 }
 
 static void
 gf100_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
 {
 	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
-	nv_mask(fifo, 0x002140, 0x80000000, 0x00000000);
+	struct nvkm_device *device = fifo->engine.subdev.device;
+	nvkm_mask(device, 0x002140, 0x80000000, 0x00000000);
 }
 
 static const struct nvkm_event_func
@@ -917,41 +933,42 @@ static int
 gf100_fifo_init(struct nvkm_object *object)
 {
 	struct gf100_fifo *fifo = (void *)object;
+	struct nvkm_device *device = fifo->base.engine.subdev.device;
 	int ret, i;
 
 	ret = nvkm_fifo_init(&fifo->base);
 	if (ret)
 		return ret;
 
-	nv_wr32(fifo, 0x000204, 0xffffffff);
-	nv_wr32(fifo, 0x002204, 0xffffffff);
+	nvkm_wr32(device, 0x000204, 0xffffffff);
+	nvkm_wr32(device, 0x002204, 0xffffffff);
 
-	fifo->spoon_nr = hweight32(nv_rd32(fifo, 0x002204));
+	fifo->spoon_nr = hweight32(nvkm_rd32(device, 0x002204));
 	nv_debug(fifo, "%d PBDMA unit(s)\n", fifo->spoon_nr);
 
 	/* assign engines to PBDMAs */
 	if (fifo->spoon_nr >= 3) {
-		nv_wr32(fifo, 0x002208, ~(1 << 0)); /* PGRAPH */
-		nv_wr32(fifo, 0x00220c, ~(1 << 1)); /* PVP */
-		nv_wr32(fifo, 0x002210, ~(1 << 1)); /* PMSPP */
-		nv_wr32(fifo, 0x002214, ~(1 << 1)); /* PMSVLD */
-		nv_wr32(fifo, 0x002218, ~(1 << 2)); /* PCE0 */
-		nv_wr32(fifo, 0x00221c, ~(1 << 1)); /* PCE1 */
+		nvkm_wr32(device, 0x002208, ~(1 << 0)); /* PGRAPH */
+		nvkm_wr32(device, 0x00220c, ~(1 << 1)); /* PVP */
+		nvkm_wr32(device, 0x002210, ~(1 << 1)); /* PMSPP */
+		nvkm_wr32(device, 0x002214, ~(1 << 1)); /* PMSVLD */
+		nvkm_wr32(device, 0x002218, ~(1 << 2)); /* PCE0 */
+		nvkm_wr32(device, 0x00221c, ~(1 << 1)); /* PCE1 */
 	}
 
 	/* PBDMA[n] */
 	for (i = 0; i < fifo->spoon_nr; i++) {
-		nv_mask(fifo, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
-		nv_wr32(fifo, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
-		nv_wr32(fifo, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+		nvkm_mask(device, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+		nvkm_wr32(device, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+		nvkm_wr32(device, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
 	}
 
-	nv_mask(fifo, 0x002200, 0x00000001, 0x00000001);
-	nv_wr32(fifo, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
+	nvkm_mask(device, 0x002200, 0x00000001, 0x00000001);
+	nvkm_wr32(device, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
 
-	nv_wr32(fifo, 0x002100, 0xffffffff);
-	nv_wr32(fifo, 0x002140, 0x7fffffff);
-	nv_wr32(fifo, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
+	nvkm_wr32(device, 0x002100, 0xffffffff);
+	nvkm_wr32(device, 0x002140, 0x7fffffff);
+	nvkm_wr32(device, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
 	return 0;
 }
 

commit 6189f1b0938dc0621c27494031b83ffae566e318
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:07 2015 +1000

    drm/nouveau/fifo: cosmetic changes
    
    This is purely preparation for upcoming commits, there should be no
    code changes here.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
index b745252f2261..0a7971a3317c 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -35,7 +35,7 @@
 #include <nvif/class.h>
 #include <nvif/unpack.h>
 
-struct gf100_fifo_priv {
+struct gf100_fifo {
 	struct nvkm_fifo base;
 
 	struct work_struct fault;
@@ -74,18 +74,18 @@ struct gf100_fifo_chan {
  ******************************************************************************/
 
 static void
-gf100_fifo_runlist_update(struct gf100_fifo_priv *priv)
+gf100_fifo_runlist_update(struct gf100_fifo *fifo)
 {
-	struct nvkm_bar *bar = nvkm_bar(priv);
+	struct nvkm_bar *bar = nvkm_bar(fifo);
 	struct nvkm_gpuobj *cur;
 	int i, p;
 
-	mutex_lock(&nv_subdev(priv)->mutex);
-	cur = priv->runlist.mem[priv->runlist.active];
-	priv->runlist.active = !priv->runlist.active;
+	mutex_lock(&nv_subdev(fifo)->mutex);
+	cur = fifo->runlist.mem[fifo->runlist.active];
+	fifo->runlist.active = !fifo->runlist.active;
 
 	for (i = 0, p = 0; i < 128; i++) {
-		struct gf100_fifo_chan *chan = (void *)priv->base.channel[i];
+		struct gf100_fifo_chan *chan = (void *)fifo->base.channel[i];
 		if (chan && chan->state == RUNNING) {
 			nv_wo32(cur, p + 0, i);
 			nv_wo32(cur, p + 4, 0x00000004);
@@ -94,14 +94,14 @@ gf100_fifo_runlist_update(struct gf100_fifo_priv *priv)
 	}
 	bar->flush(bar);
 
-	nv_wr32(priv, 0x002270, cur->addr >> 12);
-	nv_wr32(priv, 0x002274, 0x01f00000 | (p >> 3));
+	nv_wr32(fifo, 0x002270, cur->addr >> 12);
+	nv_wr32(fifo, 0x002274, 0x01f00000 | (p >> 3));
 
-	if (wait_event_timeout(priv->runlist.wait,
-			       !(nv_rd32(priv, 0x00227c) & 0x00100000),
+	if (wait_event_timeout(fifo->runlist.wait,
+			       !(nv_rd32(fifo, 0x00227c) & 0x00100000),
 			       msecs_to_jiffies(2000)) == 0)
-		nv_error(priv, "runlist update timeout\n");
-	mutex_unlock(&nv_subdev(priv)->mutex);
+		nv_error(fifo, "runlist update timeout\n");
+	mutex_unlock(&nv_subdev(fifo)->mutex);
 }
 
 static int
@@ -146,7 +146,7 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 			  struct nvkm_object *object)
 {
 	struct nvkm_bar *bar = nvkm_bar(parent);
-	struct gf100_fifo_priv *priv = (void *)parent->engine;
+	struct gf100_fifo *fifo = (void *)parent->engine;
 	struct gf100_fifo_base *base = (void *)parent->parent;
 	struct gf100_fifo_chan *chan = (void *)parent;
 	u32 addr;
@@ -163,9 +163,9 @@ gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
 		return -EINVAL;
 	}
 
-	nv_wr32(priv, 0x002634, chan->base.chid);
-	if (!nv_wait(priv, 0x002634, 0xffffffff, chan->base.chid)) {
-		nv_error(priv, "channel %d [%s] kick timeout\n",
+	nv_wr32(fifo, 0x002634, chan->base.chid);
+	if (!nv_wait(fifo, 0x002634, 0xffffffff, chan->base.chid)) {
+		nv_error(fifo, "channel %d [%s] kick timeout\n",
 			 chan->base.chid, nvkm_client_name(chan));
 		if (suspend)
 			return -EBUSY;
@@ -186,7 +186,7 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct nv50_channel_gpfifo_v0 v0;
 	} *args = data;
 	struct nvkm_bar *bar = nvkm_bar(parent);
-	struct gf100_fifo_priv *priv = (void *)engine;
+	struct gf100_fifo *fifo = (void *)engine;
 	struct gf100_fifo_base *base = (void *)parent;
 	struct gf100_fifo_chan *chan;
 	u64 usermem, ioffset, ilength;
@@ -202,7 +202,7 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		return ret;
 
 	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
-				       priv->user.bar.offset, 0x1000,
+				       fifo->user.bar.offset, 0x1000,
 				       args->v0.pushbuf,
 				       (1ULL << NVDEV_ENGINE_SW) |
 				       (1ULL << NVDEV_ENGINE_GR) |
@@ -225,10 +225,10 @@ gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	ilength = order_base_2(args->v0.ilength / 8);
 
 	for (i = 0; i < 0x1000; i += 4)
-		nv_wo32(priv->user.mem, usermem + i, 0x00000000);
+		nv_wo32(fifo->user.mem, usermem + i, 0x00000000);
 
-	nv_wo32(base, 0x08, lower_32_bits(priv->user.mem->addr + usermem));
-	nv_wo32(base, 0x0c, upper_32_bits(priv->user.mem->addr + usermem));
+	nv_wo32(base, 0x08, lower_32_bits(fifo->user.mem->addr + usermem));
+	nv_wo32(base, 0x0c, upper_32_bits(fifo->user.mem->addr + usermem));
 	nv_wo32(base, 0x10, 0x0000face);
 	nv_wo32(base, 0x30, 0xfffff902);
 	nv_wo32(base, 0x48, lower_32_bits(ioffset));
@@ -251,7 +251,7 @@ static int
 gf100_fifo_chan_init(struct nvkm_object *object)
 {
 	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
-	struct gf100_fifo_priv *priv = (void *)object->engine;
+	struct gf100_fifo *fifo = (void *)object->engine;
 	struct gf100_fifo_chan *chan = (void *)object;
 	u32 chid = chan->base.chid;
 	int ret;
@@ -260,33 +260,33 @@ gf100_fifo_chan_init(struct nvkm_object *object)
 	if (ret)
 		return ret;
 
-	nv_wr32(priv, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
+	nv_wr32(fifo, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
 
 	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
-		nv_wr32(priv, 0x003004 + (chid * 8), 0x001f0001);
-		gf100_fifo_runlist_update(priv);
+		nv_wr32(fifo, 0x003004 + (chid * 8), 0x001f0001);
+		gf100_fifo_runlist_update(fifo);
 	}
 
 	return 0;
 }
 
-static void gf100_fifo_intr_engine(struct gf100_fifo_priv *priv);
+static void gf100_fifo_intr_engine(struct gf100_fifo *fifo);
 
 static int
 gf100_fifo_chan_fini(struct nvkm_object *object, bool suspend)
 {
-	struct gf100_fifo_priv *priv = (void *)object->engine;
+	struct gf100_fifo *fifo = (void *)object->engine;
 	struct gf100_fifo_chan *chan = (void *)object;
 	u32 chid = chan->base.chid;
 
 	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
-		nv_mask(priv, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
-		gf100_fifo_runlist_update(priv);
+		nv_mask(fifo, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
+		gf100_fifo_runlist_update(fifo);
 	}
 
-	gf100_fifo_intr_engine(priv);
+	gf100_fifo_intr_engine(fifo);
 
-	nv_wr32(priv, 0x003000 + (chid * 8), 0x00000000);
+	nv_wr32(fifo, 0x003000 + (chid * 8), 0x00000000);
 	return nvkm_fifo_channel_fini(&chan->base, suspend);
 }
 
@@ -371,7 +371,7 @@ gf100_fifo_cclass = {
  ******************************************************************************/
 
 static inline int
-gf100_fifo_engidx(struct gf100_fifo_priv *priv, u32 engn)
+gf100_fifo_engidx(struct gf100_fifo *fifo, u32 engn)
 {
 	switch (engn) {
 	case NVDEV_ENGINE_GR    : engn = 0; break;
@@ -388,7 +388,7 @@ gf100_fifo_engidx(struct gf100_fifo_priv *priv, u32 engn)
 }
 
 static inline struct nvkm_engine *
-gf100_fifo_engine(struct gf100_fifo_priv *priv, u32 engn)
+gf100_fifo_engine(struct gf100_fifo *fifo, u32 engn)
 {
 	switch (engn) {
 	case 0: engn = NVDEV_ENGINE_GR; break;
@@ -401,69 +401,69 @@ gf100_fifo_engine(struct gf100_fifo_priv *priv, u32 engn)
 		return NULL;
 	}
 
-	return nvkm_engine(priv, engn);
+	return nvkm_engine(fifo, engn);
 }
 
 static void
 gf100_fifo_recover_work(struct work_struct *work)
 {
-	struct gf100_fifo_priv *priv = container_of(work, typeof(*priv), fault);
+	struct gf100_fifo *fifo = container_of(work, typeof(*fifo), fault);
 	struct nvkm_object *engine;
 	unsigned long flags;
 	u32 engn, engm = 0;
 	u64 mask, todo;
 
-	spin_lock_irqsave(&priv->base.lock, flags);
-	mask = priv->mask;
-	priv->mask = 0ULL;
-	spin_unlock_irqrestore(&priv->base.lock, flags);
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	mask = fifo->mask;
+	fifo->mask = 0ULL;
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
-		engm |= 1 << gf100_fifo_engidx(priv, engn);
-	nv_mask(priv, 0x002630, engm, engm);
+		engm |= 1 << gf100_fifo_engidx(fifo, engn);
+	nv_mask(fifo, 0x002630, engm, engm);
 
 	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
-		if ((engine = (void *)nvkm_engine(priv, engn))) {
+		if ((engine = (void *)nvkm_engine(fifo, engn))) {
 			nv_ofuncs(engine)->fini(engine, false);
 			WARN_ON(nv_ofuncs(engine)->init(engine));
 		}
 	}
 
-	gf100_fifo_runlist_update(priv);
-	nv_wr32(priv, 0x00262c, engm);
-	nv_mask(priv, 0x002630, engm, 0x00000000);
+	gf100_fifo_runlist_update(fifo);
+	nv_wr32(fifo, 0x00262c, engm);
+	nv_mask(fifo, 0x002630, engm, 0x00000000);
 }
 
 static void
-gf100_fifo_recover(struct gf100_fifo_priv *priv, struct nvkm_engine *engine,
+gf100_fifo_recover(struct gf100_fifo *fifo, struct nvkm_engine *engine,
 		   struct gf100_fifo_chan *chan)
 {
 	u32 chid = chan->base.chid;
 	unsigned long flags;
 
-	nv_error(priv, "%s engine fault on channel %d, recovering...\n",
+	nv_error(fifo, "%s engine fault on channel %d, recovering...\n",
 		       nv_subdev(engine)->name, chid);
 
-	nv_mask(priv, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
+	nv_mask(fifo, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
 	chan->state = KILLED;
 
-	spin_lock_irqsave(&priv->base.lock, flags);
-	priv->mask |= 1ULL << nv_engidx(engine);
-	spin_unlock_irqrestore(&priv->base.lock, flags);
-	schedule_work(&priv->fault);
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	fifo->mask |= 1ULL << nv_engidx(engine);
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
+	schedule_work(&fifo->fault);
 }
 
 static int
-gf100_fifo_swmthd(struct gf100_fifo_priv *priv, u32 chid, u32 mthd, u32 data)
+gf100_fifo_swmthd(struct gf100_fifo *fifo, u32 chid, u32 mthd, u32 data)
 {
 	struct gf100_fifo_chan *chan = NULL;
 	struct nvkm_handle *bind;
 	unsigned long flags;
 	int ret = -EINVAL;
 
-	spin_lock_irqsave(&priv->base.lock, flags);
-	if (likely(chid >= priv->base.min && chid <= priv->base.max))
-		chan = (void *)priv->base.channel[chid];
+	spin_lock_irqsave(&fifo->base.lock, flags);
+	if (likely(chid >= fifo->base.min && chid <= fifo->base.max))
+		chan = (void *)fifo->base.channel[chid];
 	if (unlikely(!chan))
 		goto out;
 
@@ -475,7 +475,7 @@ gf100_fifo_swmthd(struct gf100_fifo_priv *priv, u32 chid, u32 mthd, u32 data)
 	}
 
 out:
-	spin_unlock_irqrestore(&priv->base.lock, flags);
+	spin_unlock_irqrestore(&fifo->base.lock, flags);
 	return ret;
 }
 
@@ -486,14 +486,14 @@ gf100_fifo_sched_reason[] = {
 };
 
 static void
-gf100_fifo_intr_sched_ctxsw(struct gf100_fifo_priv *priv)
+gf100_fifo_intr_sched_ctxsw(struct gf100_fifo *fifo)
 {
 	struct nvkm_engine *engine;
 	struct gf100_fifo_chan *chan;
 	u32 engn;
 
 	for (engn = 0; engn < 6; engn++) {
-		u32 stat = nv_rd32(priv, 0x002640 + (engn * 0x04));
+		u32 stat = nv_rd32(fifo, 0x002640 + (engn * 0x04));
 		u32 busy = (stat & 0x80000000);
 		u32 save = (stat & 0x00100000); /* maybe? */
 		u32 unk0 = (stat & 0x00040000);
@@ -502,19 +502,19 @@ gf100_fifo_intr_sched_ctxsw(struct gf100_fifo_priv *priv)
 		(void)save;
 
 		if (busy && unk0 && unk1) {
-			if (!(chan = (void *)priv->base.channel[chid]))
+			if (!(chan = (void *)fifo->base.channel[chid]))
 				continue;
-			if (!(engine = gf100_fifo_engine(priv, engn)))
+			if (!(engine = gf100_fifo_engine(fifo, engn)))
 				continue;
-			gf100_fifo_recover(priv, engine, chan);
+			gf100_fifo_recover(fifo, engine, chan);
 		}
 	}
 }
 
 static void
-gf100_fifo_intr_sched(struct gf100_fifo_priv *priv)
+gf100_fifo_intr_sched(struct gf100_fifo *fifo)
 {
-	u32 intr = nv_rd32(priv, 0x00254c);
+	u32 intr = nv_rd32(fifo, 0x00254c);
 	u32 code = intr & 0x000000ff;
 	const struct nvkm_enum *en;
 	char enunk[6] = "";
@@ -523,11 +523,11 @@ gf100_fifo_intr_sched(struct gf100_fifo_priv *priv)
 	if (!en)
 		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
 
-	nv_error(priv, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
+	nv_error(fifo, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
 
 	switch (code) {
 	case 0x0a:
-		gf100_fifo_intr_sched_ctxsw(priv);
+		gf100_fifo_intr_sched_ctxsw(fifo);
 		break;
 	default:
 		break;
@@ -594,12 +594,12 @@ gf100_fifo_fault_gpcclient[] = {
 };
 
 static void
-gf100_fifo_intr_fault(struct gf100_fifo_priv *priv, int unit)
+gf100_fifo_intr_fault(struct gf100_fifo *fifo, int unit)
 {
-	u32 inst = nv_rd32(priv, 0x002800 + (unit * 0x10));
-	u32 valo = nv_rd32(priv, 0x002804 + (unit * 0x10));
-	u32 vahi = nv_rd32(priv, 0x002808 + (unit * 0x10));
-	u32 stat = nv_rd32(priv, 0x00280c + (unit * 0x10));
+	u32 inst = nv_rd32(fifo, 0x002800 + (unit * 0x10));
+	u32 valo = nv_rd32(fifo, 0x002804 + (unit * 0x10));
+	u32 vahi = nv_rd32(fifo, 0x002808 + (unit * 0x10));
+	u32 stat = nv_rd32(fifo, 0x00280c + (unit * 0x10));
 	u32 gpc    = (stat & 0x1f000000) >> 24;
 	u32 client = (stat & 0x00001f00) >> 8;
 	u32 write  = (stat & 0x00000080);
@@ -621,16 +621,16 @@ gf100_fifo_intr_fault(struct gf100_fifo_priv *priv, int unit)
 	if (eu) {
 		switch (eu->data2) {
 		case NVDEV_SUBDEV_BAR:
-			nv_mask(priv, 0x001704, 0x00000000, 0x00000000);
+			nv_mask(fifo, 0x001704, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_SUBDEV_INSTMEM:
-			nv_mask(priv, 0x001714, 0x00000000, 0x00000000);
+			nv_mask(fifo, 0x001714, 0x00000000, 0x00000000);
 			break;
 		case NVDEV_ENGINE_IFB:
-			nv_mask(priv, 0x001718, 0x00000000, 0x00000000);
+			nv_mask(fifo, 0x001718, 0x00000000, 0x00000000);
 			break;
 		default:
-			engine = nvkm_engine(priv, eu->data2);
+			engine = nvkm_engine(fifo, eu->data2);
 			if (engine)
 				engctx = nvkm_engctx_get(engine, inst);
 			break;
@@ -649,7 +649,7 @@ gf100_fifo_intr_fault(struct gf100_fifo_priv *priv, int unit)
 	if (!ec)
 		snprintf(ecunk, sizeof(ecunk), "UNK%02x", client);
 
-	nv_error(priv, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
+	nv_error(fifo, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
 		       "channel 0x%010llx [%s]\n", write ? "write" : "read",
 		 (u64)vahi << 32 | valo, er ? er->name : erunk,
 		 eu ? eu->name : euunk, hub ? "" : "GPC", gpcid, hub ? "" : "/",
@@ -660,7 +660,7 @@ gf100_fifo_intr_fault(struct gf100_fifo_priv *priv, int unit)
 	while (object) {
 		switch (nv_mclass(object)) {
 		case FERMI_CHANNEL_GPFIFO:
-			gf100_fifo_recover(priv, engine, (void *)object);
+			gf100_fifo_recover(fifo, engine, (void *)object);
 			break;
 		}
 		object = object->parent;
@@ -678,82 +678,82 @@ gf100_fifo_pbdma_intr[] = {
 };
 
 static void
-gf100_fifo_intr_pbdma(struct gf100_fifo_priv *priv, int unit)
+gf100_fifo_intr_pbdma(struct gf100_fifo *fifo, int unit)
 {
-	u32 stat = nv_rd32(priv, 0x040108 + (unit * 0x2000));
-	u32 addr = nv_rd32(priv, 0x0400c0 + (unit * 0x2000));
-	u32 data = nv_rd32(priv, 0x0400c4 + (unit * 0x2000));
-	u32 chid = nv_rd32(priv, 0x040120 + (unit * 0x2000)) & 0x7f;
+	u32 stat = nv_rd32(fifo, 0x040108 + (unit * 0x2000));
+	u32 addr = nv_rd32(fifo, 0x0400c0 + (unit * 0x2000));
+	u32 data = nv_rd32(fifo, 0x0400c4 + (unit * 0x2000));
+	u32 chid = nv_rd32(fifo, 0x040120 + (unit * 0x2000)) & 0x7f;
 	u32 subc = (addr & 0x00070000) >> 16;
 	u32 mthd = (addr & 0x00003ffc);
 	u32 show = stat;
 
 	if (stat & 0x00800000) {
-		if (!gf100_fifo_swmthd(priv, chid, mthd, data))
+		if (!gf100_fifo_swmthd(fifo, chid, mthd, data))
 			show &= ~0x00800000;
 	}
 
 	if (show) {
-		nv_error(priv, "PBDMA%d:", unit);
+		nv_error(fifo, "PBDMA%d:", unit);
 		nvkm_bitfield_print(gf100_fifo_pbdma_intr, show);
 		pr_cont("\n");
-		nv_error(priv,
+		nv_error(fifo,
 			 "PBDMA%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
 			 unit, chid,
-			 nvkm_client_name_for_fifo_chid(&priv->base, chid),
+			 nvkm_client_name_for_fifo_chid(&fifo->base, chid),
 			 subc, mthd, data);
 	}
 
-	nv_wr32(priv, 0x0400c0 + (unit * 0x2000), 0x80600008);
-	nv_wr32(priv, 0x040108 + (unit * 0x2000), stat);
+	nv_wr32(fifo, 0x0400c0 + (unit * 0x2000), 0x80600008);
+	nv_wr32(fifo, 0x040108 + (unit * 0x2000), stat);
 }
 
 static void
-gf100_fifo_intr_runlist(struct gf100_fifo_priv *priv)
+gf100_fifo_intr_runlist(struct gf100_fifo *fifo)
 {
-	u32 intr = nv_rd32(priv, 0x002a00);
+	u32 intr = nv_rd32(fifo, 0x002a00);
 
 	if (intr & 0x10000000) {
-		wake_up(&priv->runlist.wait);
-		nv_wr32(priv, 0x002a00, 0x10000000);
+		wake_up(&fifo->runlist.wait);
+		nv_wr32(fifo, 0x002a00, 0x10000000);
 		intr &= ~0x10000000;
 	}
 
 	if (intr) {
-		nv_error(priv, "RUNLIST 0x%08x\n", intr);
-		nv_wr32(priv, 0x002a00, intr);
+		nv_error(fifo, "RUNLIST 0x%08x\n", intr);
+		nv_wr32(fifo, 0x002a00, intr);
 	}
 }
 
 static void
-gf100_fifo_intr_engine_unit(struct gf100_fifo_priv *priv, int engn)
+gf100_fifo_intr_engine_unit(struct gf100_fifo *fifo, int engn)
 {
-	u32 intr = nv_rd32(priv, 0x0025a8 + (engn * 0x04));
-	u32 inte = nv_rd32(priv, 0x002628);
+	u32 intr = nv_rd32(fifo, 0x0025a8 + (engn * 0x04));
+	u32 inte = nv_rd32(fifo, 0x002628);
 	u32 unkn;
 
-	nv_wr32(priv, 0x0025a8 + (engn * 0x04), intr);
+	nv_wr32(fifo, 0x0025a8 + (engn * 0x04), intr);
 
 	for (unkn = 0; unkn < 8; unkn++) {
 		u32 ints = (intr >> (unkn * 0x04)) & inte;
 		if (ints & 0x1) {
-			nvkm_fifo_uevent(&priv->base);
+			nvkm_fifo_uevent(&fifo->base);
 			ints &= ~1;
 		}
 		if (ints) {
-			nv_error(priv, "ENGINE %d %d %01x", engn, unkn, ints);
-			nv_mask(priv, 0x002628, ints, 0);
+			nv_error(fifo, "ENGINE %d %d %01x", engn, unkn, ints);
+			nv_mask(fifo, 0x002628, ints, 0);
 		}
 	}
 }
 
 static void
-gf100_fifo_intr_engine(struct gf100_fifo_priv *priv)
+gf100_fifo_intr_engine(struct gf100_fifo *fifo)
 {
-	u32 mask = nv_rd32(priv, 0x0025a4);
+	u32 mask = nv_rd32(fifo, 0x0025a4);
 	while (mask) {
 		u32 unit = __ffs(mask);
-		gf100_fifo_intr_engine_unit(priv, unit);
+		gf100_fifo_intr_engine_unit(fifo, unit);
 		mask &= ~(1 << unit);
 	}
 }
@@ -761,73 +761,73 @@ gf100_fifo_intr_engine(struct gf100_fifo_priv *priv)
 static void
 gf100_fifo_intr(struct nvkm_subdev *subdev)
 {
-	struct gf100_fifo_priv *priv = (void *)subdev;
-	u32 mask = nv_rd32(priv, 0x002140);
-	u32 stat = nv_rd32(priv, 0x002100) & mask;
+	struct gf100_fifo *fifo = (void *)subdev;
+	u32 mask = nv_rd32(fifo, 0x002140);
+	u32 stat = nv_rd32(fifo, 0x002100) & mask;
 
 	if (stat & 0x00000001) {
-		u32 intr = nv_rd32(priv, 0x00252c);
-		nv_warn(priv, "INTR 0x00000001: 0x%08x\n", intr);
-		nv_wr32(priv, 0x002100, 0x00000001);
+		u32 intr = nv_rd32(fifo, 0x00252c);
+		nv_warn(fifo, "INTR 0x00000001: 0x%08x\n", intr);
+		nv_wr32(fifo, 0x002100, 0x00000001);
 		stat &= ~0x00000001;
 	}
 
 	if (stat & 0x00000100) {
-		gf100_fifo_intr_sched(priv);
-		nv_wr32(priv, 0x002100, 0x00000100);
+		gf100_fifo_intr_sched(fifo);
+		nv_wr32(fifo, 0x002100, 0x00000100);
 		stat &= ~0x00000100;
 	}
 
 	if (stat & 0x00010000) {
-		u32 intr = nv_rd32(priv, 0x00256c);
-		nv_warn(priv, "INTR 0x00010000: 0x%08x\n", intr);
-		nv_wr32(priv, 0x002100, 0x00010000);
+		u32 intr = nv_rd32(fifo, 0x00256c);
+		nv_warn(fifo, "INTR 0x00010000: 0x%08x\n", intr);
+		nv_wr32(fifo, 0x002100, 0x00010000);
 		stat &= ~0x00010000;
 	}
 
 	if (stat & 0x01000000) {
-		u32 intr = nv_rd32(priv, 0x00258c);
-		nv_warn(priv, "INTR 0x01000000: 0x%08x\n", intr);
-		nv_wr32(priv, 0x002100, 0x01000000);
+		u32 intr = nv_rd32(fifo, 0x00258c);
+		nv_warn(fifo, "INTR 0x01000000: 0x%08x\n", intr);
+		nv_wr32(fifo, 0x002100, 0x01000000);
 		stat &= ~0x01000000;
 	}
 
 	if (stat & 0x10000000) {
-		u32 mask = nv_rd32(priv, 0x00259c);
+		u32 mask = nv_rd32(fifo, 0x00259c);
 		while (mask) {
 			u32 unit = __ffs(mask);
-			gf100_fifo_intr_fault(priv, unit);
-			nv_wr32(priv, 0x00259c, (1 << unit));
+			gf100_fifo_intr_fault(fifo, unit);
+			nv_wr32(fifo, 0x00259c, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x10000000;
 	}
 
 	if (stat & 0x20000000) {
-		u32 mask = nv_rd32(priv, 0x0025a0);
+		u32 mask = nv_rd32(fifo, 0x0025a0);
 		while (mask) {
 			u32 unit = __ffs(mask);
-			gf100_fifo_intr_pbdma(priv, unit);
-			nv_wr32(priv, 0x0025a0, (1 << unit));
+			gf100_fifo_intr_pbdma(fifo, unit);
+			nv_wr32(fifo, 0x0025a0, (1 << unit));
 			mask &= ~(1 << unit);
 		}
 		stat &= ~0x20000000;
 	}
 
 	if (stat & 0x40000000) {
-		gf100_fifo_intr_runlist(priv);
+		gf100_fifo_intr_runlist(fifo);
 		stat &= ~0x40000000;
 	}
 
 	if (stat & 0x80000000) {
-		gf100_fifo_intr_engine(priv);
+		gf100_fifo_intr_engine(fifo);
 		stat &= ~0x80000000;
 	}
 
 	if (stat) {
-		nv_error(priv, "INTR 0x%08x\n", stat);
-		nv_mask(priv, 0x002140, stat, 0x00000000);
-		nv_wr32(priv, 0x002100, stat);
+		nv_error(fifo, "INTR 0x%08x\n", stat);
+		nv_mask(fifo, 0x002140, stat, 0x00000000);
+		nv_wr32(fifo, 0x002100, stat);
 	}
 }
 
@@ -857,101 +857,101 @@ gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		struct nvkm_oclass *oclass, void *data, u32 size,
 		struct nvkm_object **pobject)
 {
-	struct gf100_fifo_priv *priv;
+	struct gf100_fifo *fifo;
 	int ret;
 
-	ret = nvkm_fifo_create(parent, engine, oclass, 0, 127, &priv);
-	*pobject = nv_object(priv);
+	ret = nvkm_fifo_create(parent, engine, oclass, 0, 127, &fifo);
+	*pobject = nv_object(fifo);
 	if (ret)
 		return ret;
 
-	INIT_WORK(&priv->fault, gf100_fifo_recover_work);
+	INIT_WORK(&fifo->fault, gf100_fifo_recover_work);
 
-	ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x1000, 0x1000, 0,
-			      &priv->runlist.mem[0]);
+	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x1000, 0x1000, 0,
+			      &fifo->runlist.mem[0]);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x1000, 0x1000, 0,
-			      &priv->runlist.mem[1]);
+	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 0x1000, 0x1000, 0,
+			      &fifo->runlist.mem[1]);
 	if (ret)
 		return ret;
 
-	init_waitqueue_head(&priv->runlist.wait);
+	init_waitqueue_head(&fifo->runlist.wait);
 
-	ret = nvkm_gpuobj_new(nv_object(priv), NULL, 128 * 0x1000, 0x1000, 0,
-			      &priv->user.mem);
+	ret = nvkm_gpuobj_new(nv_object(fifo), NULL, 128 * 0x1000, 0x1000, 0,
+			      &fifo->user.mem);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_map(priv->user.mem, NV_MEM_ACCESS_RW,
-			      &priv->user.bar);
+	ret = nvkm_gpuobj_map(fifo->user.mem, NV_MEM_ACCESS_RW,
+			      &fifo->user.bar);
 	if (ret)
 		return ret;
 
-	ret = nvkm_event_init(&gf100_fifo_uevent_func, 1, 1, &priv->base.uevent);
+	ret = nvkm_event_init(&gf100_fifo_uevent_func, 1, 1, &fifo->base.uevent);
 	if (ret)
 		return ret;
 
-	nv_subdev(priv)->unit = 0x00000100;
-	nv_subdev(priv)->intr = gf100_fifo_intr;
-	nv_engine(priv)->cclass = &gf100_fifo_cclass;
-	nv_engine(priv)->sclass = gf100_fifo_sclass;
+	nv_subdev(fifo)->unit = 0x00000100;
+	nv_subdev(fifo)->intr = gf100_fifo_intr;
+	nv_engine(fifo)->cclass = &gf100_fifo_cclass;
+	nv_engine(fifo)->sclass = gf100_fifo_sclass;
 	return 0;
 }
 
 static void
 gf100_fifo_dtor(struct nvkm_object *object)
 {
-	struct gf100_fifo_priv *priv = (void *)object;
+	struct gf100_fifo *fifo = (void *)object;
 
-	nvkm_gpuobj_unmap(&priv->user.bar);
-	nvkm_gpuobj_ref(NULL, &priv->user.mem);
-	nvkm_gpuobj_ref(NULL, &priv->runlist.mem[0]);
-	nvkm_gpuobj_ref(NULL, &priv->runlist.mem[1]);
+	nvkm_gpuobj_unmap(&fifo->user.bar);
+	nvkm_gpuobj_ref(NULL, &fifo->user.mem);
+	nvkm_gpuobj_ref(NULL, &fifo->runlist.mem[0]);
+	nvkm_gpuobj_ref(NULL, &fifo->runlist.mem[1]);
 
-	nvkm_fifo_destroy(&priv->base);
+	nvkm_fifo_destroy(&fifo->base);
 }
 
 static int
 gf100_fifo_init(struct nvkm_object *object)
 {
-	struct gf100_fifo_priv *priv = (void *)object;
+	struct gf100_fifo *fifo = (void *)object;
 	int ret, i;
 
-	ret = nvkm_fifo_init(&priv->base);
+	ret = nvkm_fifo_init(&fifo->base);
 	if (ret)
 		return ret;
 
-	nv_wr32(priv, 0x000204, 0xffffffff);
-	nv_wr32(priv, 0x002204, 0xffffffff);
+	nv_wr32(fifo, 0x000204, 0xffffffff);
+	nv_wr32(fifo, 0x002204, 0xffffffff);
 
-	priv->spoon_nr = hweight32(nv_rd32(priv, 0x002204));
-	nv_debug(priv, "%d PBDMA unit(s)\n", priv->spoon_nr);
+	fifo->spoon_nr = hweight32(nv_rd32(fifo, 0x002204));
+	nv_debug(fifo, "%d PBDMA unit(s)\n", fifo->spoon_nr);
 
 	/* assign engines to PBDMAs */
-	if (priv->spoon_nr >= 3) {
-		nv_wr32(priv, 0x002208, ~(1 << 0)); /* PGRAPH */
-		nv_wr32(priv, 0x00220c, ~(1 << 1)); /* PVP */
-		nv_wr32(priv, 0x002210, ~(1 << 1)); /* PMSPP */
-		nv_wr32(priv, 0x002214, ~(1 << 1)); /* PMSVLD */
-		nv_wr32(priv, 0x002218, ~(1 << 2)); /* PCE0 */
-		nv_wr32(priv, 0x00221c, ~(1 << 1)); /* PCE1 */
+	if (fifo->spoon_nr >= 3) {
+		nv_wr32(fifo, 0x002208, ~(1 << 0)); /* PGRAPH */
+		nv_wr32(fifo, 0x00220c, ~(1 << 1)); /* PVP */
+		nv_wr32(fifo, 0x002210, ~(1 << 1)); /* PMSPP */
+		nv_wr32(fifo, 0x002214, ~(1 << 1)); /* PMSVLD */
+		nv_wr32(fifo, 0x002218, ~(1 << 2)); /* PCE0 */
+		nv_wr32(fifo, 0x00221c, ~(1 << 1)); /* PCE1 */
 	}
 
 	/* PBDMA[n] */
-	for (i = 0; i < priv->spoon_nr; i++) {
-		nv_mask(priv, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
-		nv_wr32(priv, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
-		nv_wr32(priv, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+	for (i = 0; i < fifo->spoon_nr; i++) {
+		nv_mask(fifo, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+		nv_wr32(fifo, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+		nv_wr32(fifo, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
 	}
 
-	nv_mask(priv, 0x002200, 0x00000001, 0x00000001);
-	nv_wr32(priv, 0x002254, 0x10000000 | priv->user.bar.offset >> 12);
+	nv_mask(fifo, 0x002200, 0x00000001, 0x00000001);
+	nv_wr32(fifo, 0x002254, 0x10000000 | fifo->user.bar.offset >> 12);
 
-	nv_wr32(priv, 0x002100, 0xffffffff);
-	nv_wr32(priv, 0x002140, 0x7fffffff);
-	nv_wr32(priv, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
+	nv_wr32(fifo, 0x002100, 0xffffffff);
+	nv_wr32(fifo, 0x002140, 0x7fffffff);
+	nv_wr32(fifo, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
 	return 0;
 }
 

commit 05c7145dae17a53b030238f477bf28211a21b736
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 15:28:47 2015 +1000

    drm/nouveau/fifo: namespace + nvidia gpu names (no binary change)
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
new file mode 100644
index 000000000000..b745252f2261
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/fifo/gf100.c
@@ -0,0 +1,967 @@
+/*
+ * Copyright 2012 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+#include <engine/fifo.h>
+
+#include <core/client.h>
+#include <core/engctx.h>
+#include <core/enum.h>
+#include <core/handle.h>
+#include <subdev/bar.h>
+#include <subdev/fb.h>
+#include <subdev/mmu.h>
+#include <subdev/timer.h>
+
+#include <nvif/class.h>
+#include <nvif/unpack.h>
+
+struct gf100_fifo_priv {
+	struct nvkm_fifo base;
+
+	struct work_struct fault;
+	u64 mask;
+
+	struct {
+		struct nvkm_gpuobj *mem[2];
+		int active;
+		wait_queue_head_t wait;
+	} runlist;
+
+	struct {
+		struct nvkm_gpuobj *mem;
+		struct nvkm_vma bar;
+	} user;
+	int spoon_nr;
+};
+
+struct gf100_fifo_base {
+	struct nvkm_fifo_base base;
+	struct nvkm_gpuobj *pgd;
+	struct nvkm_vm *vm;
+};
+
+struct gf100_fifo_chan {
+	struct nvkm_fifo_chan base;
+	enum {
+		STOPPED,
+		RUNNING,
+		KILLED
+	} state;
+};
+
+/*******************************************************************************
+ * FIFO channel objects
+ ******************************************************************************/
+
+static void
+gf100_fifo_runlist_update(struct gf100_fifo_priv *priv)
+{
+	struct nvkm_bar *bar = nvkm_bar(priv);
+	struct nvkm_gpuobj *cur;
+	int i, p;
+
+	mutex_lock(&nv_subdev(priv)->mutex);
+	cur = priv->runlist.mem[priv->runlist.active];
+	priv->runlist.active = !priv->runlist.active;
+
+	for (i = 0, p = 0; i < 128; i++) {
+		struct gf100_fifo_chan *chan = (void *)priv->base.channel[i];
+		if (chan && chan->state == RUNNING) {
+			nv_wo32(cur, p + 0, i);
+			nv_wo32(cur, p + 4, 0x00000004);
+			p += 8;
+		}
+	}
+	bar->flush(bar);
+
+	nv_wr32(priv, 0x002270, cur->addr >> 12);
+	nv_wr32(priv, 0x002274, 0x01f00000 | (p >> 3));
+
+	if (wait_event_timeout(priv->runlist.wait,
+			       !(nv_rd32(priv, 0x00227c) & 0x00100000),
+			       msecs_to_jiffies(2000)) == 0)
+		nv_error(priv, "runlist update timeout\n");
+	mutex_unlock(&nv_subdev(priv)->mutex);
+}
+
+static int
+gf100_fifo_context_attach(struct nvkm_object *parent,
+			  struct nvkm_object *object)
+{
+	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct gf100_fifo_base *base = (void *)parent->parent;
+	struct nvkm_engctx *ectx = (void *)object;
+	u32 addr;
+	int ret;
+
+	switch (nv_engidx(object->engine)) {
+	case NVDEV_ENGINE_SW    : return 0;
+	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
+	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
+	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
+	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
+	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
+	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
+	default:
+		return -EINVAL;
+	}
+
+	if (!ectx->vma.node) {
+		ret = nvkm_gpuobj_map_vm(nv_gpuobj(ectx), base->vm,
+					 NV_MEM_ACCESS_RW, &ectx->vma);
+		if (ret)
+			return ret;
+
+		nv_engctx(ectx)->addr = nv_gpuobj(base)->addr >> 12;
+	}
+
+	nv_wo32(base, addr + 0x00, lower_32_bits(ectx->vma.offset) | 4);
+	nv_wo32(base, addr + 0x04, upper_32_bits(ectx->vma.offset));
+	bar->flush(bar);
+	return 0;
+}
+
+static int
+gf100_fifo_context_detach(struct nvkm_object *parent, bool suspend,
+			  struct nvkm_object *object)
+{
+	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct gf100_fifo_priv *priv = (void *)parent->engine;
+	struct gf100_fifo_base *base = (void *)parent->parent;
+	struct gf100_fifo_chan *chan = (void *)parent;
+	u32 addr;
+
+	switch (nv_engidx(object->engine)) {
+	case NVDEV_ENGINE_SW    : return 0;
+	case NVDEV_ENGINE_GR    : addr = 0x0210; break;
+	case NVDEV_ENGINE_CE0   : addr = 0x0230; break;
+	case NVDEV_ENGINE_CE1   : addr = 0x0240; break;
+	case NVDEV_ENGINE_MSVLD : addr = 0x0270; break;
+	case NVDEV_ENGINE_MSPDEC: addr = 0x0250; break;
+	case NVDEV_ENGINE_MSPPP : addr = 0x0260; break;
+	default:
+		return -EINVAL;
+	}
+
+	nv_wr32(priv, 0x002634, chan->base.chid);
+	if (!nv_wait(priv, 0x002634, 0xffffffff, chan->base.chid)) {
+		nv_error(priv, "channel %d [%s] kick timeout\n",
+			 chan->base.chid, nvkm_client_name(chan));
+		if (suspend)
+			return -EBUSY;
+	}
+
+	nv_wo32(base, addr + 0x00, 0x00000000);
+	nv_wo32(base, addr + 0x04, 0x00000000);
+	bar->flush(bar);
+	return 0;
+}
+
+static int
+gf100_fifo_chan_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+		     struct nvkm_oclass *oclass, void *data, u32 size,
+		     struct nvkm_object **pobject)
+{
+	union {
+		struct nv50_channel_gpfifo_v0 v0;
+	} *args = data;
+	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct gf100_fifo_priv *priv = (void *)engine;
+	struct gf100_fifo_base *base = (void *)parent;
+	struct gf100_fifo_chan *chan;
+	u64 usermem, ioffset, ilength;
+	int ret, i;
+
+	nv_ioctl(parent, "create channel gpfifo size %d\n", size);
+	if (nvif_unpack(args->v0, 0, 0, false)) {
+		nv_ioctl(parent, "create channel gpfifo vers %d pushbuf %08x "
+				 "ioffset %016llx ilength %08x\n",
+			 args->v0.version, args->v0.pushbuf, args->v0.ioffset,
+			 args->v0.ilength);
+	} else
+		return ret;
+
+	ret = nvkm_fifo_channel_create(parent, engine, oclass, 1,
+				       priv->user.bar.offset, 0x1000,
+				       args->v0.pushbuf,
+				       (1ULL << NVDEV_ENGINE_SW) |
+				       (1ULL << NVDEV_ENGINE_GR) |
+				       (1ULL << NVDEV_ENGINE_CE0) |
+				       (1ULL << NVDEV_ENGINE_CE1) |
+				       (1ULL << NVDEV_ENGINE_MSVLD) |
+				       (1ULL << NVDEV_ENGINE_MSPDEC) |
+				       (1ULL << NVDEV_ENGINE_MSPPP), &chan);
+	*pobject = nv_object(chan);
+	if (ret)
+		return ret;
+
+	args->v0.chid = chan->base.chid;
+
+	nv_parent(chan)->context_attach = gf100_fifo_context_attach;
+	nv_parent(chan)->context_detach = gf100_fifo_context_detach;
+
+	usermem = chan->base.chid * 0x1000;
+	ioffset = args->v0.ioffset;
+	ilength = order_base_2(args->v0.ilength / 8);
+
+	for (i = 0; i < 0x1000; i += 4)
+		nv_wo32(priv->user.mem, usermem + i, 0x00000000);
+
+	nv_wo32(base, 0x08, lower_32_bits(priv->user.mem->addr + usermem));
+	nv_wo32(base, 0x0c, upper_32_bits(priv->user.mem->addr + usermem));
+	nv_wo32(base, 0x10, 0x0000face);
+	nv_wo32(base, 0x30, 0xfffff902);
+	nv_wo32(base, 0x48, lower_32_bits(ioffset));
+	nv_wo32(base, 0x4c, upper_32_bits(ioffset) | (ilength << 16));
+	nv_wo32(base, 0x54, 0x00000002);
+	nv_wo32(base, 0x84, 0x20400000);
+	nv_wo32(base, 0x94, 0x30000001);
+	nv_wo32(base, 0x9c, 0x00000100);
+	nv_wo32(base, 0xa4, 0x1f1f1f1f);
+	nv_wo32(base, 0xa8, 0x1f1f1f1f);
+	nv_wo32(base, 0xac, 0x0000001f);
+	nv_wo32(base, 0xb8, 0xf8000000);
+	nv_wo32(base, 0xf8, 0x10003080); /* 0x002310 */
+	nv_wo32(base, 0xfc, 0x10000010); /* 0x002350 */
+	bar->flush(bar);
+	return 0;
+}
+
+static int
+gf100_fifo_chan_init(struct nvkm_object *object)
+{
+	struct nvkm_gpuobj *base = nv_gpuobj(object->parent);
+	struct gf100_fifo_priv *priv = (void *)object->engine;
+	struct gf100_fifo_chan *chan = (void *)object;
+	u32 chid = chan->base.chid;
+	int ret;
+
+	ret = nvkm_fifo_channel_init(&chan->base);
+	if (ret)
+		return ret;
+
+	nv_wr32(priv, 0x003000 + (chid * 8), 0xc0000000 | base->addr >> 12);
+
+	if (chan->state == STOPPED && (chan->state = RUNNING) == RUNNING) {
+		nv_wr32(priv, 0x003004 + (chid * 8), 0x001f0001);
+		gf100_fifo_runlist_update(priv);
+	}
+
+	return 0;
+}
+
+static void gf100_fifo_intr_engine(struct gf100_fifo_priv *priv);
+
+static int
+gf100_fifo_chan_fini(struct nvkm_object *object, bool suspend)
+{
+	struct gf100_fifo_priv *priv = (void *)object->engine;
+	struct gf100_fifo_chan *chan = (void *)object;
+	u32 chid = chan->base.chid;
+
+	if (chan->state == RUNNING && (chan->state = STOPPED) == STOPPED) {
+		nv_mask(priv, 0x003004 + (chid * 8), 0x00000001, 0x00000000);
+		gf100_fifo_runlist_update(priv);
+	}
+
+	gf100_fifo_intr_engine(priv);
+
+	nv_wr32(priv, 0x003000 + (chid * 8), 0x00000000);
+	return nvkm_fifo_channel_fini(&chan->base, suspend);
+}
+
+static struct nvkm_ofuncs
+gf100_fifo_ofuncs = {
+	.ctor = gf100_fifo_chan_ctor,
+	.dtor = _nvkm_fifo_channel_dtor,
+	.init = gf100_fifo_chan_init,
+	.fini = gf100_fifo_chan_fini,
+	.map  = _nvkm_fifo_channel_map,
+	.rd32 = _nvkm_fifo_channel_rd32,
+	.wr32 = _nvkm_fifo_channel_wr32,
+	.ntfy = _nvkm_fifo_channel_ntfy
+};
+
+static struct nvkm_oclass
+gf100_fifo_sclass[] = {
+	{ FERMI_CHANNEL_GPFIFO, &gf100_fifo_ofuncs },
+	{}
+};
+
+/*******************************************************************************
+ * FIFO context - instmem heap and vm setup
+ ******************************************************************************/
+
+static int
+gf100_fifo_context_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+			struct nvkm_oclass *oclass, void *data, u32 size,
+			struct nvkm_object **pobject)
+{
+	struct gf100_fifo_base *base;
+	int ret;
+
+	ret = nvkm_fifo_context_create(parent, engine, oclass, NULL, 0x1000,
+				       0x1000, NVOBJ_FLAG_ZERO_ALLOC |
+				       NVOBJ_FLAG_HEAP, &base);
+	*pobject = nv_object(base);
+	if (ret)
+		return ret;
+
+	ret = nvkm_gpuobj_new(nv_object(base), NULL, 0x10000, 0x1000, 0,
+			      &base->pgd);
+	if (ret)
+		return ret;
+
+	nv_wo32(base, 0x0200, lower_32_bits(base->pgd->addr));
+	nv_wo32(base, 0x0204, upper_32_bits(base->pgd->addr));
+	nv_wo32(base, 0x0208, 0xffffffff);
+	nv_wo32(base, 0x020c, 0x000000ff);
+
+	ret = nvkm_vm_ref(nvkm_client(parent)->vm, &base->vm, base->pgd);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static void
+gf100_fifo_context_dtor(struct nvkm_object *object)
+{
+	struct gf100_fifo_base *base = (void *)object;
+	nvkm_vm_ref(NULL, &base->vm, base->pgd);
+	nvkm_gpuobj_ref(NULL, &base->pgd);
+	nvkm_fifo_context_destroy(&base->base);
+}
+
+static struct nvkm_oclass
+gf100_fifo_cclass = {
+	.handle = NV_ENGCTX(FIFO, 0xc0),
+	.ofuncs = &(struct nvkm_ofuncs) {
+		.ctor = gf100_fifo_context_ctor,
+		.dtor = gf100_fifo_context_dtor,
+		.init = _nvkm_fifo_context_init,
+		.fini = _nvkm_fifo_context_fini,
+		.rd32 = _nvkm_fifo_context_rd32,
+		.wr32 = _nvkm_fifo_context_wr32,
+	},
+};
+
+/*******************************************************************************
+ * PFIFO engine
+ ******************************************************************************/
+
+static inline int
+gf100_fifo_engidx(struct gf100_fifo_priv *priv, u32 engn)
+{
+	switch (engn) {
+	case NVDEV_ENGINE_GR    : engn = 0; break;
+	case NVDEV_ENGINE_MSVLD : engn = 1; break;
+	case NVDEV_ENGINE_MSPPP : engn = 2; break;
+	case NVDEV_ENGINE_MSPDEC: engn = 3; break;
+	case NVDEV_ENGINE_CE0   : engn = 4; break;
+	case NVDEV_ENGINE_CE1   : engn = 5; break;
+	default:
+		return -1;
+	}
+
+	return engn;
+}
+
+static inline struct nvkm_engine *
+gf100_fifo_engine(struct gf100_fifo_priv *priv, u32 engn)
+{
+	switch (engn) {
+	case 0: engn = NVDEV_ENGINE_GR; break;
+	case 1: engn = NVDEV_ENGINE_MSVLD; break;
+	case 2: engn = NVDEV_ENGINE_MSPPP; break;
+	case 3: engn = NVDEV_ENGINE_MSPDEC; break;
+	case 4: engn = NVDEV_ENGINE_CE0; break;
+	case 5: engn = NVDEV_ENGINE_CE1; break;
+	default:
+		return NULL;
+	}
+
+	return nvkm_engine(priv, engn);
+}
+
+static void
+gf100_fifo_recover_work(struct work_struct *work)
+{
+	struct gf100_fifo_priv *priv = container_of(work, typeof(*priv), fault);
+	struct nvkm_object *engine;
+	unsigned long flags;
+	u32 engn, engm = 0;
+	u64 mask, todo;
+
+	spin_lock_irqsave(&priv->base.lock, flags);
+	mask = priv->mask;
+	priv->mask = 0ULL;
+	spin_unlock_irqrestore(&priv->base.lock, flags);
+
+	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn))
+		engm |= 1 << gf100_fifo_engidx(priv, engn);
+	nv_mask(priv, 0x002630, engm, engm);
+
+	for (todo = mask; engn = __ffs64(todo), todo; todo &= ~(1 << engn)) {
+		if ((engine = (void *)nvkm_engine(priv, engn))) {
+			nv_ofuncs(engine)->fini(engine, false);
+			WARN_ON(nv_ofuncs(engine)->init(engine));
+		}
+	}
+
+	gf100_fifo_runlist_update(priv);
+	nv_wr32(priv, 0x00262c, engm);
+	nv_mask(priv, 0x002630, engm, 0x00000000);
+}
+
+static void
+gf100_fifo_recover(struct gf100_fifo_priv *priv, struct nvkm_engine *engine,
+		   struct gf100_fifo_chan *chan)
+{
+	u32 chid = chan->base.chid;
+	unsigned long flags;
+
+	nv_error(priv, "%s engine fault on channel %d, recovering...\n",
+		       nv_subdev(engine)->name, chid);
+
+	nv_mask(priv, 0x003004 + (chid * 0x08), 0x00000001, 0x00000000);
+	chan->state = KILLED;
+
+	spin_lock_irqsave(&priv->base.lock, flags);
+	priv->mask |= 1ULL << nv_engidx(engine);
+	spin_unlock_irqrestore(&priv->base.lock, flags);
+	schedule_work(&priv->fault);
+}
+
+static int
+gf100_fifo_swmthd(struct gf100_fifo_priv *priv, u32 chid, u32 mthd, u32 data)
+{
+	struct gf100_fifo_chan *chan = NULL;
+	struct nvkm_handle *bind;
+	unsigned long flags;
+	int ret = -EINVAL;
+
+	spin_lock_irqsave(&priv->base.lock, flags);
+	if (likely(chid >= priv->base.min && chid <= priv->base.max))
+		chan = (void *)priv->base.channel[chid];
+	if (unlikely(!chan))
+		goto out;
+
+	bind = nvkm_namedb_get_class(nv_namedb(chan), 0x906e);
+	if (likely(bind)) {
+		if (!mthd || !nv_call(bind->object, mthd, data))
+			ret = 0;
+		nvkm_namedb_put(bind);
+	}
+
+out:
+	spin_unlock_irqrestore(&priv->base.lock, flags);
+	return ret;
+}
+
+static const struct nvkm_enum
+gf100_fifo_sched_reason[] = {
+	{ 0x0a, "CTXSW_TIMEOUT" },
+	{}
+};
+
+static void
+gf100_fifo_intr_sched_ctxsw(struct gf100_fifo_priv *priv)
+{
+	struct nvkm_engine *engine;
+	struct gf100_fifo_chan *chan;
+	u32 engn;
+
+	for (engn = 0; engn < 6; engn++) {
+		u32 stat = nv_rd32(priv, 0x002640 + (engn * 0x04));
+		u32 busy = (stat & 0x80000000);
+		u32 save = (stat & 0x00100000); /* maybe? */
+		u32 unk0 = (stat & 0x00040000);
+		u32 unk1 = (stat & 0x00001000);
+		u32 chid = (stat & 0x0000007f);
+		(void)save;
+
+		if (busy && unk0 && unk1) {
+			if (!(chan = (void *)priv->base.channel[chid]))
+				continue;
+			if (!(engine = gf100_fifo_engine(priv, engn)))
+				continue;
+			gf100_fifo_recover(priv, engine, chan);
+		}
+	}
+}
+
+static void
+gf100_fifo_intr_sched(struct gf100_fifo_priv *priv)
+{
+	u32 intr = nv_rd32(priv, 0x00254c);
+	u32 code = intr & 0x000000ff;
+	const struct nvkm_enum *en;
+	char enunk[6] = "";
+
+	en = nvkm_enum_find(gf100_fifo_sched_reason, code);
+	if (!en)
+		snprintf(enunk, sizeof(enunk), "UNK%02x", code);
+
+	nv_error(priv, "SCHED_ERROR [ %s ]\n", en ? en->name : enunk);
+
+	switch (code) {
+	case 0x0a:
+		gf100_fifo_intr_sched_ctxsw(priv);
+		break;
+	default:
+		break;
+	}
+}
+
+static const struct nvkm_enum
+gf100_fifo_fault_engine[] = {
+	{ 0x00, "PGRAPH", NULL, NVDEV_ENGINE_GR },
+	{ 0x03, "PEEPHOLE", NULL, NVDEV_ENGINE_IFB },
+	{ 0x04, "BAR1", NULL, NVDEV_SUBDEV_BAR },
+	{ 0x05, "BAR3", NULL, NVDEV_SUBDEV_INSTMEM },
+	{ 0x07, "PFIFO", NULL, NVDEV_ENGINE_FIFO },
+	{ 0x10, "PMSVLD", NULL, NVDEV_ENGINE_MSVLD },
+	{ 0x11, "PMSPPP", NULL, NVDEV_ENGINE_MSPPP },
+	{ 0x13, "PCOUNTER" },
+	{ 0x14, "PMSPDEC", NULL, NVDEV_ENGINE_MSPDEC },
+	{ 0x15, "PCE0", NULL, NVDEV_ENGINE_CE0 },
+	{ 0x16, "PCE1", NULL, NVDEV_ENGINE_CE1 },
+	{ 0x17, "PDAEMON" },
+	{}
+};
+
+static const struct nvkm_enum
+gf100_fifo_fault_reason[] = {
+	{ 0x00, "PT_NOT_PRESENT" },
+	{ 0x01, "PT_TOO_SHORT" },
+	{ 0x02, "PAGE_NOT_PRESENT" },
+	{ 0x03, "VM_LIMIT_EXCEEDED" },
+	{ 0x04, "NO_CHANNEL" },
+	{ 0x05, "PAGE_SYSTEM_ONLY" },
+	{ 0x06, "PAGE_READ_ONLY" },
+	{ 0x0a, "COMPRESSED_SYSRAM" },
+	{ 0x0c, "INVALID_STORAGE_TYPE" },
+	{}
+};
+
+static const struct nvkm_enum
+gf100_fifo_fault_hubclient[] = {
+	{ 0x01, "PCOPY0" },
+	{ 0x02, "PCOPY1" },
+	{ 0x04, "DISPATCH" },
+	{ 0x05, "CTXCTL" },
+	{ 0x06, "PFIFO" },
+	{ 0x07, "BAR_READ" },
+	{ 0x08, "BAR_WRITE" },
+	{ 0x0b, "PVP" },
+	{ 0x0c, "PMSPPP" },
+	{ 0x0d, "PMSVLD" },
+	{ 0x11, "PCOUNTER" },
+	{ 0x12, "PDAEMON" },
+	{ 0x14, "CCACHE" },
+	{ 0x15, "CCACHE_POST" },
+	{}
+};
+
+static const struct nvkm_enum
+gf100_fifo_fault_gpcclient[] = {
+	{ 0x01, "TEX" },
+	{ 0x0c, "ESETUP" },
+	{ 0x0e, "CTXCTL" },
+	{ 0x0f, "PROP" },
+	{}
+};
+
+static void
+gf100_fifo_intr_fault(struct gf100_fifo_priv *priv, int unit)
+{
+	u32 inst = nv_rd32(priv, 0x002800 + (unit * 0x10));
+	u32 valo = nv_rd32(priv, 0x002804 + (unit * 0x10));
+	u32 vahi = nv_rd32(priv, 0x002808 + (unit * 0x10));
+	u32 stat = nv_rd32(priv, 0x00280c + (unit * 0x10));
+	u32 gpc    = (stat & 0x1f000000) >> 24;
+	u32 client = (stat & 0x00001f00) >> 8;
+	u32 write  = (stat & 0x00000080);
+	u32 hub    = (stat & 0x00000040);
+	u32 reason = (stat & 0x0000000f);
+	struct nvkm_object *engctx = NULL, *object;
+	struct nvkm_engine *engine = NULL;
+	const struct nvkm_enum *er, *eu, *ec;
+	char erunk[6] = "";
+	char euunk[6] = "";
+	char ecunk[6] = "";
+	char gpcid[3] = "";
+
+	er = nvkm_enum_find(gf100_fifo_fault_reason, reason);
+	if (!er)
+		snprintf(erunk, sizeof(erunk), "UNK%02X", reason);
+
+	eu = nvkm_enum_find(gf100_fifo_fault_engine, unit);
+	if (eu) {
+		switch (eu->data2) {
+		case NVDEV_SUBDEV_BAR:
+			nv_mask(priv, 0x001704, 0x00000000, 0x00000000);
+			break;
+		case NVDEV_SUBDEV_INSTMEM:
+			nv_mask(priv, 0x001714, 0x00000000, 0x00000000);
+			break;
+		case NVDEV_ENGINE_IFB:
+			nv_mask(priv, 0x001718, 0x00000000, 0x00000000);
+			break;
+		default:
+			engine = nvkm_engine(priv, eu->data2);
+			if (engine)
+				engctx = nvkm_engctx_get(engine, inst);
+			break;
+		}
+	} else {
+		snprintf(euunk, sizeof(euunk), "UNK%02x", unit);
+	}
+
+	if (hub) {
+		ec = nvkm_enum_find(gf100_fifo_fault_hubclient, client);
+	} else {
+		ec = nvkm_enum_find(gf100_fifo_fault_gpcclient, client);
+		snprintf(gpcid, sizeof(gpcid), "%d", gpc);
+	}
+
+	if (!ec)
+		snprintf(ecunk, sizeof(ecunk), "UNK%02x", client);
+
+	nv_error(priv, "%s fault at 0x%010llx [%s] from %s/%s%s%s%s on "
+		       "channel 0x%010llx [%s]\n", write ? "write" : "read",
+		 (u64)vahi << 32 | valo, er ? er->name : erunk,
+		 eu ? eu->name : euunk, hub ? "" : "GPC", gpcid, hub ? "" : "/",
+		 ec ? ec->name : ecunk, (u64)inst << 12,
+		 nvkm_client_name(engctx));
+
+	object = engctx;
+	while (object) {
+		switch (nv_mclass(object)) {
+		case FERMI_CHANNEL_GPFIFO:
+			gf100_fifo_recover(priv, engine, (void *)object);
+			break;
+		}
+		object = object->parent;
+	}
+
+	nvkm_engctx_put(engctx);
+}
+
+static const struct nvkm_bitfield
+gf100_fifo_pbdma_intr[] = {
+/*	{ 0x00008000, "" }	seen with null ib push */
+	{ 0x00200000, "ILLEGAL_MTHD" },
+	{ 0x00800000, "EMPTY_SUBC" },
+	{}
+};
+
+static void
+gf100_fifo_intr_pbdma(struct gf100_fifo_priv *priv, int unit)
+{
+	u32 stat = nv_rd32(priv, 0x040108 + (unit * 0x2000));
+	u32 addr = nv_rd32(priv, 0x0400c0 + (unit * 0x2000));
+	u32 data = nv_rd32(priv, 0x0400c4 + (unit * 0x2000));
+	u32 chid = nv_rd32(priv, 0x040120 + (unit * 0x2000)) & 0x7f;
+	u32 subc = (addr & 0x00070000) >> 16;
+	u32 mthd = (addr & 0x00003ffc);
+	u32 show = stat;
+
+	if (stat & 0x00800000) {
+		if (!gf100_fifo_swmthd(priv, chid, mthd, data))
+			show &= ~0x00800000;
+	}
+
+	if (show) {
+		nv_error(priv, "PBDMA%d:", unit);
+		nvkm_bitfield_print(gf100_fifo_pbdma_intr, show);
+		pr_cont("\n");
+		nv_error(priv,
+			 "PBDMA%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
+			 unit, chid,
+			 nvkm_client_name_for_fifo_chid(&priv->base, chid),
+			 subc, mthd, data);
+	}
+
+	nv_wr32(priv, 0x0400c0 + (unit * 0x2000), 0x80600008);
+	nv_wr32(priv, 0x040108 + (unit * 0x2000), stat);
+}
+
+static void
+gf100_fifo_intr_runlist(struct gf100_fifo_priv *priv)
+{
+	u32 intr = nv_rd32(priv, 0x002a00);
+
+	if (intr & 0x10000000) {
+		wake_up(&priv->runlist.wait);
+		nv_wr32(priv, 0x002a00, 0x10000000);
+		intr &= ~0x10000000;
+	}
+
+	if (intr) {
+		nv_error(priv, "RUNLIST 0x%08x\n", intr);
+		nv_wr32(priv, 0x002a00, intr);
+	}
+}
+
+static void
+gf100_fifo_intr_engine_unit(struct gf100_fifo_priv *priv, int engn)
+{
+	u32 intr = nv_rd32(priv, 0x0025a8 + (engn * 0x04));
+	u32 inte = nv_rd32(priv, 0x002628);
+	u32 unkn;
+
+	nv_wr32(priv, 0x0025a8 + (engn * 0x04), intr);
+
+	for (unkn = 0; unkn < 8; unkn++) {
+		u32 ints = (intr >> (unkn * 0x04)) & inte;
+		if (ints & 0x1) {
+			nvkm_fifo_uevent(&priv->base);
+			ints &= ~1;
+		}
+		if (ints) {
+			nv_error(priv, "ENGINE %d %d %01x", engn, unkn, ints);
+			nv_mask(priv, 0x002628, ints, 0);
+		}
+	}
+}
+
+static void
+gf100_fifo_intr_engine(struct gf100_fifo_priv *priv)
+{
+	u32 mask = nv_rd32(priv, 0x0025a4);
+	while (mask) {
+		u32 unit = __ffs(mask);
+		gf100_fifo_intr_engine_unit(priv, unit);
+		mask &= ~(1 << unit);
+	}
+}
+
+static void
+gf100_fifo_intr(struct nvkm_subdev *subdev)
+{
+	struct gf100_fifo_priv *priv = (void *)subdev;
+	u32 mask = nv_rd32(priv, 0x002140);
+	u32 stat = nv_rd32(priv, 0x002100) & mask;
+
+	if (stat & 0x00000001) {
+		u32 intr = nv_rd32(priv, 0x00252c);
+		nv_warn(priv, "INTR 0x00000001: 0x%08x\n", intr);
+		nv_wr32(priv, 0x002100, 0x00000001);
+		stat &= ~0x00000001;
+	}
+
+	if (stat & 0x00000100) {
+		gf100_fifo_intr_sched(priv);
+		nv_wr32(priv, 0x002100, 0x00000100);
+		stat &= ~0x00000100;
+	}
+
+	if (stat & 0x00010000) {
+		u32 intr = nv_rd32(priv, 0x00256c);
+		nv_warn(priv, "INTR 0x00010000: 0x%08x\n", intr);
+		nv_wr32(priv, 0x002100, 0x00010000);
+		stat &= ~0x00010000;
+	}
+
+	if (stat & 0x01000000) {
+		u32 intr = nv_rd32(priv, 0x00258c);
+		nv_warn(priv, "INTR 0x01000000: 0x%08x\n", intr);
+		nv_wr32(priv, 0x002100, 0x01000000);
+		stat &= ~0x01000000;
+	}
+
+	if (stat & 0x10000000) {
+		u32 mask = nv_rd32(priv, 0x00259c);
+		while (mask) {
+			u32 unit = __ffs(mask);
+			gf100_fifo_intr_fault(priv, unit);
+			nv_wr32(priv, 0x00259c, (1 << unit));
+			mask &= ~(1 << unit);
+		}
+		stat &= ~0x10000000;
+	}
+
+	if (stat & 0x20000000) {
+		u32 mask = nv_rd32(priv, 0x0025a0);
+		while (mask) {
+			u32 unit = __ffs(mask);
+			gf100_fifo_intr_pbdma(priv, unit);
+			nv_wr32(priv, 0x0025a0, (1 << unit));
+			mask &= ~(1 << unit);
+		}
+		stat &= ~0x20000000;
+	}
+
+	if (stat & 0x40000000) {
+		gf100_fifo_intr_runlist(priv);
+		stat &= ~0x40000000;
+	}
+
+	if (stat & 0x80000000) {
+		gf100_fifo_intr_engine(priv);
+		stat &= ~0x80000000;
+	}
+
+	if (stat) {
+		nv_error(priv, "INTR 0x%08x\n", stat);
+		nv_mask(priv, 0x002140, stat, 0x00000000);
+		nv_wr32(priv, 0x002100, stat);
+	}
+}
+
+static void
+gf100_fifo_uevent_init(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	nv_mask(fifo, 0x002140, 0x80000000, 0x80000000);
+}
+
+static void
+gf100_fifo_uevent_fini(struct nvkm_event *event, int type, int index)
+{
+	struct nvkm_fifo *fifo = container_of(event, typeof(*fifo), uevent);
+	nv_mask(fifo, 0x002140, 0x80000000, 0x00000000);
+}
+
+static const struct nvkm_event_func
+gf100_fifo_uevent_func = {
+	.ctor = nvkm_fifo_uevent_ctor,
+	.init = gf100_fifo_uevent_init,
+	.fini = gf100_fifo_uevent_fini,
+};
+
+static int
+gf100_fifo_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+		struct nvkm_oclass *oclass, void *data, u32 size,
+		struct nvkm_object **pobject)
+{
+	struct gf100_fifo_priv *priv;
+	int ret;
+
+	ret = nvkm_fifo_create(parent, engine, oclass, 0, 127, &priv);
+	*pobject = nv_object(priv);
+	if (ret)
+		return ret;
+
+	INIT_WORK(&priv->fault, gf100_fifo_recover_work);
+
+	ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x1000, 0x1000, 0,
+			      &priv->runlist.mem[0]);
+	if (ret)
+		return ret;
+
+	ret = nvkm_gpuobj_new(nv_object(priv), NULL, 0x1000, 0x1000, 0,
+			      &priv->runlist.mem[1]);
+	if (ret)
+		return ret;
+
+	init_waitqueue_head(&priv->runlist.wait);
+
+	ret = nvkm_gpuobj_new(nv_object(priv), NULL, 128 * 0x1000, 0x1000, 0,
+			      &priv->user.mem);
+	if (ret)
+		return ret;
+
+	ret = nvkm_gpuobj_map(priv->user.mem, NV_MEM_ACCESS_RW,
+			      &priv->user.bar);
+	if (ret)
+		return ret;
+
+	ret = nvkm_event_init(&gf100_fifo_uevent_func, 1, 1, &priv->base.uevent);
+	if (ret)
+		return ret;
+
+	nv_subdev(priv)->unit = 0x00000100;
+	nv_subdev(priv)->intr = gf100_fifo_intr;
+	nv_engine(priv)->cclass = &gf100_fifo_cclass;
+	nv_engine(priv)->sclass = gf100_fifo_sclass;
+	return 0;
+}
+
+static void
+gf100_fifo_dtor(struct nvkm_object *object)
+{
+	struct gf100_fifo_priv *priv = (void *)object;
+
+	nvkm_gpuobj_unmap(&priv->user.bar);
+	nvkm_gpuobj_ref(NULL, &priv->user.mem);
+	nvkm_gpuobj_ref(NULL, &priv->runlist.mem[0]);
+	nvkm_gpuobj_ref(NULL, &priv->runlist.mem[1]);
+
+	nvkm_fifo_destroy(&priv->base);
+}
+
+static int
+gf100_fifo_init(struct nvkm_object *object)
+{
+	struct gf100_fifo_priv *priv = (void *)object;
+	int ret, i;
+
+	ret = nvkm_fifo_init(&priv->base);
+	if (ret)
+		return ret;
+
+	nv_wr32(priv, 0x000204, 0xffffffff);
+	nv_wr32(priv, 0x002204, 0xffffffff);
+
+	priv->spoon_nr = hweight32(nv_rd32(priv, 0x002204));
+	nv_debug(priv, "%d PBDMA unit(s)\n", priv->spoon_nr);
+
+	/* assign engines to PBDMAs */
+	if (priv->spoon_nr >= 3) {
+		nv_wr32(priv, 0x002208, ~(1 << 0)); /* PGRAPH */
+		nv_wr32(priv, 0x00220c, ~(1 << 1)); /* PVP */
+		nv_wr32(priv, 0x002210, ~(1 << 1)); /* PMSPP */
+		nv_wr32(priv, 0x002214, ~(1 << 1)); /* PMSVLD */
+		nv_wr32(priv, 0x002218, ~(1 << 2)); /* PCE0 */
+		nv_wr32(priv, 0x00221c, ~(1 << 1)); /* PCE1 */
+	}
+
+	/* PBDMA[n] */
+	for (i = 0; i < priv->spoon_nr; i++) {
+		nv_mask(priv, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+		nv_wr32(priv, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+		nv_wr32(priv, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+	}
+
+	nv_mask(priv, 0x002200, 0x00000001, 0x00000001);
+	nv_wr32(priv, 0x002254, 0x10000000 | priv->user.bar.offset >> 12);
+
+	nv_wr32(priv, 0x002100, 0xffffffff);
+	nv_wr32(priv, 0x002140, 0x7fffffff);
+	nv_wr32(priv, 0x002628, 0x00000001); /* ENGINE_INTR_EN */
+	return 0;
+}
+
+struct nvkm_oclass *
+gf100_fifo_oclass = &(struct nvkm_oclass) {
+	.handle = NV_ENGINE(FIFO, 0xc0),
+	.ofuncs = &(struct nvkm_ofuncs) {
+		.ctor = gf100_fifo_ctor,
+		.dtor = gf100_fifo_dtor,
+		.init = gf100_fifo_init,
+		.fini = _nvkm_fifo_fini,
+	},
+};
