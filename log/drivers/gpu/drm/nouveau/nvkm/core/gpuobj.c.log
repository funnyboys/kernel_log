commit 997a89003c2d950466bc289147ffb823c0c51fb0
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/memory: add reference counting
    
    We need to be able to prevent memory from being freed while it's still
    mapped in a GPU's address-space.
    
    Will be used by upcoming MMU changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 1264d5fc632b..d6de2b3ed2c3 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -219,7 +219,7 @@ nvkm_gpuobj_del(struct nvkm_gpuobj **pgpuobj)
 		if (gpuobj->parent)
 			nvkm_mm_free(&gpuobj->parent->heap, &gpuobj->node);
 		nvkm_mm_fini(&gpuobj->heap);
-		nvkm_memory_del(&gpuobj->memory);
+		nvkm_memory_unref(&gpuobj->memory);
 		kfree(*pgpuobj);
 		*pgpuobj = NULL;
 	}

commit 19a82e492c3d71efe8763d50496a1701dfcf3f15
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/memory: change map interface to support upcoming mmu changes
    
    Map flags (access, kind, etc) are currently defined in either the VMA,
    or the memory object, which turns out to not be ideal for things like
    suballocated buffers, etc.
    
    These will become per-map flags instead, so we need to support passing
    these arguments in nvkm_memory_map().
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 04e5b2136f0c..1264d5fc632b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -42,6 +42,14 @@ nvkm_gpuobj_wr32_fast(struct nvkm_gpuobj *gpuobj, u32 offset, u32 data)
 }
 
 /* accessor functions for gpuobjs allocated directly from instmem */
+static int
+nvkm_gpuobj_heap_map(struct nvkm_gpuobj *gpuobj, u64 offset,
+		     struct nvkm_vmm *vmm, struct nvkm_vma *vma,
+		     void *argv, u32 argc)
+{
+	return nvkm_memory_map(gpuobj->memory, offset, vmm, vma, argv, argc);
+}
+
 static u32
 nvkm_gpuobj_heap_rd32(struct nvkm_gpuobj *gpuobj, u32 offset)
 {
@@ -67,6 +75,7 @@ nvkm_gpuobj_heap_fast = {
 	.release = nvkm_gpuobj_heap_release,
 	.rd32 = nvkm_gpuobj_rd32_fast,
 	.wr32 = nvkm_gpuobj_wr32_fast,
+	.map = nvkm_gpuobj_heap_map,
 };
 
 static const struct nvkm_gpuobj_func
@@ -74,6 +83,7 @@ nvkm_gpuobj_heap_slow = {
 	.release = nvkm_gpuobj_heap_release,
 	.rd32 = nvkm_gpuobj_heap_rd32,
 	.wr32 = nvkm_gpuobj_heap_wr32,
+	.map = nvkm_gpuobj_heap_map,
 };
 
 static void *
@@ -90,9 +100,19 @@ nvkm_gpuobj_heap_acquire(struct nvkm_gpuobj *gpuobj)
 static const struct nvkm_gpuobj_func
 nvkm_gpuobj_heap = {
 	.acquire = nvkm_gpuobj_heap_acquire,
+	.map = nvkm_gpuobj_heap_map,
 };
 
 /* accessor functions for gpuobjs sub-allocated from a parent gpuobj */
+static int
+nvkm_gpuobj_map(struct nvkm_gpuobj *gpuobj, u64 offset,
+		struct nvkm_vmm *vmm, struct nvkm_vma *vma,
+		void *argv, u32 argc)
+{
+	return nvkm_memory_map(gpuobj->parent, gpuobj->node->offset + offset,
+			       vmm, vma, argv, argc);
+}
+
 static u32
 nvkm_gpuobj_rd32(struct nvkm_gpuobj *gpuobj, u32 offset)
 {
@@ -118,6 +138,7 @@ nvkm_gpuobj_fast = {
 	.release = nvkm_gpuobj_release,
 	.rd32 = nvkm_gpuobj_rd32_fast,
 	.wr32 = nvkm_gpuobj_wr32_fast,
+	.map = nvkm_gpuobj_map,
 };
 
 static const struct nvkm_gpuobj_func
@@ -125,6 +146,7 @@ nvkm_gpuobj_slow = {
 	.release = nvkm_gpuobj_release,
 	.rd32 = nvkm_gpuobj_rd32,
 	.wr32 = nvkm_gpuobj_wr32,
+	.map = nvkm_gpuobj_map,
 };
 
 static void *
@@ -143,6 +165,7 @@ nvkm_gpuobj_acquire(struct nvkm_gpuobj *gpuobj)
 static const struct nvkm_gpuobj_func
 nvkm_gpuobj_func = {
 	.acquire = nvkm_gpuobj_acquire,
+	.map = nvkm_gpuobj_map,
 };
 
 static int
@@ -218,26 +241,6 @@ nvkm_gpuobj_new(struct nvkm_device *device, u32 size, int align, bool zero,
 	return ret;
 }
 
-int
-nvkm_gpuobj_map(struct nvkm_gpuobj *gpuobj, struct nvkm_vm *vm,
-		u32 access, struct nvkm_vma *vma)
-{
-	struct nvkm_memory *memory = gpuobj->memory;
-	int ret = nvkm_vm_get(vm, gpuobj->size, 12, access, vma);
-	if (ret == 0)
-		nvkm_memory_map(memory, vma, 0);
-	return ret;
-}
-
-void
-nvkm_gpuobj_unmap(struct nvkm_vma *vma)
-{
-	if (vma->node) {
-		nvkm_vm_unmap(vma);
-		nvkm_vm_put(vma);
-	}
-}
-
 /* the below is basically only here to support sharing the paged dma object
  * for PCI(E)GART on <=nv4x chipsets, and should *not* be expected to work
  * anywhere else.

commit 4d058fab63f79e5cf13d21edd9db1a63748da0a1
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/core/mm: have users explicitly define heap identifiers
    
    Different sections of VRAM may have different properties (ie. can't be used
    for compression/display, can't be mapped, etc).
    
    We currently already support this, but it's a bit magic.  This change makes
    it more obvious where we're allocating from.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index a7bd22706b2a..04e5b2136f0c 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -185,7 +185,7 @@ nvkm_gpuobj_ctor(struct nvkm_device *device, u32 size, int align, bool zero,
 		gpuobj->size = nvkm_memory_size(gpuobj->memory);
 	}
 
-	return nvkm_mm_init(&gpuobj->heap, 0, gpuobj->size, 1);
+	return nvkm_mm_init(&gpuobj->heap, 0, 0, gpuobj->size, 1);
 }
 
 void

commit 5d2083d2f9f144024787da8296a14ed052849853
Author: Alexandre Courbot <acourbot@nvidia.com>
Date:   Wed Feb 24 14:42:14 2016 +0900

    drm/nouveau/core: add gpuobj memcpy helper functions
    
    Add memcpy functions to copy a buffer to a gpuobj and vice-versa. This
    will be used by the secure boot code.
    
    Signed-off-by: Alexandre Courbot <acourbot@nvidia.com>
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index c3a790eb8d6a..a7bd22706b2a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -253,3 +253,23 @@ nvkm_gpuobj_wrap(struct nvkm_memory *memory, struct nvkm_gpuobj **pgpuobj)
 	(*pgpuobj)->size = nvkm_memory_size(memory);
 	return 0;
 }
+
+void
+nvkm_gpuobj_memcpy_to(struct nvkm_gpuobj *dst, u32 dstoffset, void *src,
+		      u32 length)
+{
+	int i;
+
+	for (i = 0; i < length; i += 4)
+		nvkm_wo32(dst, dstoffset + i, *(u32 *)(src + i));
+}
+
+void
+nvkm_gpuobj_memcpy_from(void *dst, struct nvkm_gpuobj *src, u32 srcoffset,
+			u32 length)
+{
+	int i;
+
+	for (i = 0; i < length; i += 4)
+		((u32 *)src)[i / 4] = nvkm_ro32(src, srcoffset + i);
+}

commit 68f3f702b6a430a8d1e909455a60d26c0f2da530
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/core: remove the remainder of the previous style
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index b8fc539e0a99..c3a790eb8d6a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -218,99 +218,6 @@ nvkm_gpuobj_new(struct nvkm_device *device, u32 size, int align, bool zero,
 	return ret;
 }
 
-void
-nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
-{
-	if (gpuobj->node)
-		nvkm_mm_free(&gpuobj->parent->heap, &gpuobj->node);
-
-	gpuobj->heap.block_size = 1;
-	nvkm_mm_fini(&gpuobj->heap);
-
-	nvkm_memory_del(&gpuobj->memory);
-	nvkm_object_destroy(&gpuobj->object);
-}
-
-#include <engine/fifo/chan.h>
-
-int
-nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
-		    struct nvkm_oclass *oclass, u32 pclass,
-		    struct nvkm_object *objgpu, u32 size, u32 align, u32 flags,
-		    int length, void **pobject)
-{
-	struct nvkm_device *device = nv_device(parent);
-	struct nvkm_gpuobj *pargpu = NULL;
-	struct nvkm_gpuobj *gpuobj;
-	struct nvkm_object *object = objgpu;
-	const bool zero = (flags & NVOBJ_FLAG_ZERO_ALLOC);
-	int ret;
-
-	*pobject = NULL;
-
-	while (object && object->func != &nvkm_fifo_chan_func)
-		object = object->parent;
-
-	if (object) {
-		struct nvkm_fifo_chan *chan = nvkm_fifo_chan(object);
-		pargpu = chan->inst;
-	} else
-	if (objgpu) {
-		while ((objgpu = nv_pclass(objgpu, NV_GPUOBJ_CLASS))) {
-			if (nv_gpuobj(objgpu)->heap.block_size)
-				break;
-			objgpu = objgpu->parent;
-		}
-
-		if (WARN_ON(objgpu == NULL))
-			return -EINVAL;
-		pargpu = nv_gpuobj(objgpu);
-	}
-
-	ret = nvkm_object_create_(parent, engine, oclass, pclass |
-				  NV_GPUOBJ_CLASS, length, pobject);
-	gpuobj = *pobject;
-	if (ret)
-		return ret;
-
-	ret = nvkm_gpuobj_ctor(device, size, align, zero, pargpu, gpuobj);
-	if (!(flags & NVOBJ_FLAG_HEAP))
-		gpuobj->heap.block_size = 0;
-	return ret;
-}
-
-void
-_nvkm_gpuobj_dtor(struct nvkm_object *object)
-{
-	nvkm_gpuobj_destroy(nv_gpuobj(object));
-}
-
-int
-_nvkm_gpuobj_init(struct nvkm_object *object)
-{
-	return nvkm_gpuobj_init(nv_gpuobj(object));
-}
-
-int
-_nvkm_gpuobj_fini(struct nvkm_object *object, bool suspend)
-{
-	return nvkm_gpuobj_fini(nv_gpuobj(object), suspend);
-}
-
-u32
-_nvkm_gpuobj_rd32(struct nvkm_object *object, u64 addr)
-{
-	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
-	return nvkm_ro32(gpuobj, addr);
-}
-
-void
-_nvkm_gpuobj_wr32(struct nvkm_object *object, u64 addr, u32 data)
-{
-	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
-	nvkm_wo32(gpuobj, addr, data);
-}
-
 int
 nvkm_gpuobj_map(struct nvkm_gpuobj *gpuobj, struct nvkm_vm *vm,
 		u32 access, struct nvkm_vma *vma)

commit 13de7f462902d1a452d501cdb2d06ef02cabbfff
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:22 2015 +1000

    drm/nouveau/fifo: convert to new-style nvkm_engine
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index e056f7afc35c..b8fc539e0a99 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -231,7 +231,7 @@ nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
 	nvkm_object_destroy(&gpuobj->object);
 }
 
-#include <engine/fifo.h>
+#include <engine/fifo/chan.h>
 
 int
 nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,

commit 8f0649b5c6e70ec18122255690e39f010c12a614
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:19 2015 +1000

    drm/nouveau/fifo: convert user classes to new-style nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 54b46037f4ba..e056f7afc35c 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -231,6 +231,8 @@ nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
 	nvkm_object_destroy(&gpuobj->object);
 }
 
+#include <engine/fifo.h>
+
 int
 nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 		    struct nvkm_oclass *oclass, u32 pclass,
@@ -240,11 +242,19 @@ nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 	struct nvkm_device *device = nv_device(parent);
 	struct nvkm_gpuobj *pargpu = NULL;
 	struct nvkm_gpuobj *gpuobj;
+	struct nvkm_object *object = objgpu;
 	const bool zero = (flags & NVOBJ_FLAG_ZERO_ALLOC);
 	int ret;
 
 	*pobject = NULL;
 
+	while (object && object->func != &nvkm_fifo_chan_func)
+		object = object->parent;
+
+	if (object) {
+		struct nvkm_fifo_chan *chan = nvkm_fifo_chan(object);
+		pargpu = chan->inst;
+	} else
 	if (objgpu) {
 		while ((objgpu = nv_pclass(objgpu, NV_GPUOBJ_CLASS))) {
 			if (nv_gpuobj(objgpu)->heap.block_size)

commit f027f49166171c98d5945af12ac3ee9bc9f9bf4c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/gpuobj: separate allocation from nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index c14469c3a861..54b46037f4ba 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -28,74 +28,209 @@
 #include <subdev/bar.h>
 #include <subdev/mmu.h>
 
-static void
-nvkm_gpuobj_release(struct nvkm_gpuobj *gpuobj)
+/* fast-path, where backend is able to provide direct pointer to memory */
+static u32
+nvkm_gpuobj_rd32_fast(struct nvkm_gpuobj *gpuobj, u32 offset)
 {
-	if (gpuobj->node) {
-		nvkm_done(gpuobj->parent);
-		return;
-	}
-	nvkm_done(gpuobj->memory);
+	return ioread32_native(gpuobj->map + offset);
 }
 
 static void
-nvkm_gpuobj_acquire(struct nvkm_gpuobj *gpuobj)
+nvkm_gpuobj_wr32_fast(struct nvkm_gpuobj *gpuobj, u32 offset, u32 data)
 {
-	if (gpuobj->node) {
-		nvkm_kmap(gpuobj->parent);
-		return;
-	}
-	nvkm_kmap(gpuobj->memory);
+	iowrite32_native(data, gpuobj->map + offset);
 }
 
+/* accessor functions for gpuobjs allocated directly from instmem */
 static u32
-nvkm_gpuobj_rd32(struct nvkm_gpuobj *gpuobj, u32 offset)
+nvkm_gpuobj_heap_rd32(struct nvkm_gpuobj *gpuobj, u32 offset)
 {
-	if (gpuobj->node)
-		return nvkm_ro32(gpuobj->parent, gpuobj->node->offset + offset);
 	return nvkm_ro32(gpuobj->memory, offset);
 }
 
 static void
-nvkm_gpuobj_wr32(struct nvkm_gpuobj *gpuobj, u32 offset, u32 data)
+nvkm_gpuobj_heap_wr32(struct nvkm_gpuobj *gpuobj, u32 offset, u32 data)
 {
-	if (gpuobj->node) {
-		nvkm_wo32(gpuobj->parent, gpuobj->node->offset + offset, data);
-		return;
-	}
 	nvkm_wo32(gpuobj->memory, offset, data);
 }
 
-void
-nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
+static const struct nvkm_gpuobj_func nvkm_gpuobj_heap;
+static void
+nvkm_gpuobj_heap_release(struct nvkm_gpuobj *gpuobj)
 {
-	int i;
+	gpuobj->func = &nvkm_gpuobj_heap;
+	nvkm_done(gpuobj->memory);
+}
 
-	if (gpuobj->flags & NVOBJ_FLAG_ZERO_FREE) {
-		nvkm_kmap(gpuobj);
-		for (i = 0; i < gpuobj->size; i += 4)
-			nvkm_wo32(gpuobj, i, 0x00000000);
-		nvkm_done(gpuobj);
-	}
+static const struct nvkm_gpuobj_func
+nvkm_gpuobj_heap_fast = {
+	.release = nvkm_gpuobj_heap_release,
+	.rd32 = nvkm_gpuobj_rd32_fast,
+	.wr32 = nvkm_gpuobj_wr32_fast,
+};
 
-	if (gpuobj->node)
-		nvkm_mm_free(&nv_gpuobj(gpuobj->parent)->heap, &gpuobj->node);
+static const struct nvkm_gpuobj_func
+nvkm_gpuobj_heap_slow = {
+	.release = nvkm_gpuobj_heap_release,
+	.rd32 = nvkm_gpuobj_heap_rd32,
+	.wr32 = nvkm_gpuobj_heap_wr32,
+};
 
-	if (gpuobj->heap.block_size)
-		nvkm_mm_fini(&gpuobj->heap);
+static void *
+nvkm_gpuobj_heap_acquire(struct nvkm_gpuobj *gpuobj)
+{
+	gpuobj->map = nvkm_kmap(gpuobj->memory);
+	if (likely(gpuobj->map))
+		gpuobj->func = &nvkm_gpuobj_heap_fast;
+	else
+		gpuobj->func = &nvkm_gpuobj_heap_slow;
+	return gpuobj->map;
+}
 
-	nvkm_memory_del(&gpuobj->memory);
-	nvkm_object_destroy(&gpuobj->object);
+static const struct nvkm_gpuobj_func
+nvkm_gpuobj_heap = {
+	.acquire = nvkm_gpuobj_heap_acquire,
+};
+
+/* accessor functions for gpuobjs sub-allocated from a parent gpuobj */
+static u32
+nvkm_gpuobj_rd32(struct nvkm_gpuobj *gpuobj, u32 offset)
+{
+	return nvkm_ro32(gpuobj->parent, gpuobj->node->offset + offset);
+}
+
+static void
+nvkm_gpuobj_wr32(struct nvkm_gpuobj *gpuobj, u32 offset, u32 data)
+{
+	nvkm_wo32(gpuobj->parent, gpuobj->node->offset + offset, data);
+}
+
+static const struct nvkm_gpuobj_func nvkm_gpuobj_func;
+static void
+nvkm_gpuobj_release(struct nvkm_gpuobj *gpuobj)
+{
+	gpuobj->func = &nvkm_gpuobj_func;
+	nvkm_done(gpuobj->parent);
 }
 
 static const struct nvkm_gpuobj_func
-nvkm_gpuobj_func = {
-	.acquire = nvkm_gpuobj_acquire,
+nvkm_gpuobj_fast = {
+	.release = nvkm_gpuobj_release,
+	.rd32 = nvkm_gpuobj_rd32_fast,
+	.wr32 = nvkm_gpuobj_wr32_fast,
+};
+
+static const struct nvkm_gpuobj_func
+nvkm_gpuobj_slow = {
 	.release = nvkm_gpuobj_release,
 	.rd32 = nvkm_gpuobj_rd32,
 	.wr32 = nvkm_gpuobj_wr32,
 };
 
+static void *
+nvkm_gpuobj_acquire(struct nvkm_gpuobj *gpuobj)
+{
+	gpuobj->map = nvkm_kmap(gpuobj->parent);
+	if (likely(gpuobj->map)) {
+		gpuobj->map  = (u8 *)gpuobj->map + gpuobj->node->offset;
+		gpuobj->func = &nvkm_gpuobj_fast;
+	} else {
+		gpuobj->func = &nvkm_gpuobj_slow;
+	}
+	return gpuobj->map;
+}
+
+static const struct nvkm_gpuobj_func
+nvkm_gpuobj_func = {
+	.acquire = nvkm_gpuobj_acquire,
+};
+
+static int
+nvkm_gpuobj_ctor(struct nvkm_device *device, u32 size, int align, bool zero,
+		 struct nvkm_gpuobj *parent, struct nvkm_gpuobj *gpuobj)
+{
+	u32 offset;
+	int ret;
+
+	if (parent) {
+		if (align >= 0) {
+			ret = nvkm_mm_head(&parent->heap, 0, 1, size, size,
+					   max(align, 1), &gpuobj->node);
+		} else {
+			ret = nvkm_mm_tail(&parent->heap, 0, 1, size, size,
+					   -align, &gpuobj->node);
+		}
+		if (ret)
+			return ret;
+
+		gpuobj->parent = parent;
+		gpuobj->func = &nvkm_gpuobj_func;
+		gpuobj->addr = parent->addr + gpuobj->node->offset;
+		gpuobj->size = gpuobj->node->length;
+
+		if (zero) {
+			nvkm_kmap(gpuobj);
+			for (offset = 0; offset < gpuobj->size; offset += 4)
+				nvkm_wo32(gpuobj, offset, 0x00000000);
+			nvkm_done(gpuobj);
+		}
+	} else {
+		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST, size,
+				      abs(align), zero, &gpuobj->memory);
+		if (ret)
+			return ret;
+
+		gpuobj->func = &nvkm_gpuobj_heap;
+		gpuobj->addr = nvkm_memory_addr(gpuobj->memory);
+		gpuobj->size = nvkm_memory_size(gpuobj->memory);
+	}
+
+	return nvkm_mm_init(&gpuobj->heap, 0, gpuobj->size, 1);
+}
+
+void
+nvkm_gpuobj_del(struct nvkm_gpuobj **pgpuobj)
+{
+	struct nvkm_gpuobj *gpuobj = *pgpuobj;
+	if (gpuobj) {
+		if (gpuobj->parent)
+			nvkm_mm_free(&gpuobj->parent->heap, &gpuobj->node);
+		nvkm_mm_fini(&gpuobj->heap);
+		nvkm_memory_del(&gpuobj->memory);
+		kfree(*pgpuobj);
+		*pgpuobj = NULL;
+	}
+}
+
+int
+nvkm_gpuobj_new(struct nvkm_device *device, u32 size, int align, bool zero,
+		struct nvkm_gpuobj *parent, struct nvkm_gpuobj **pgpuobj)
+{
+	struct nvkm_gpuobj *gpuobj;
+	int ret;
+
+	if (!(gpuobj = *pgpuobj = kzalloc(sizeof(*gpuobj), GFP_KERNEL)))
+		return -ENOMEM;
+
+	ret = nvkm_gpuobj_ctor(device, size, align, zero, parent, gpuobj);
+	if (ret)
+		nvkm_gpuobj_del(pgpuobj);
+	return ret;
+}
+
+void
+nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
+{
+	if (gpuobj->node)
+		nvkm_mm_free(&gpuobj->parent->heap, &gpuobj->node);
+
+	gpuobj->heap.block_size = 1;
+	nvkm_mm_fini(&gpuobj->heap);
+
+	nvkm_memory_del(&gpuobj->memory);
+	nvkm_object_destroy(&gpuobj->object);
+}
+
 int
 nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 		    struct nvkm_oclass *oclass, u32 pclass,
@@ -103,12 +238,10 @@ nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 		    int length, void **pobject)
 {
 	struct nvkm_device *device = nv_device(parent);
-	struct nvkm_memory *memory = NULL;
 	struct nvkm_gpuobj *pargpu = NULL;
 	struct nvkm_gpuobj *gpuobj;
-	struct nvkm_mm *heap = NULL;
-	int ret, i;
-	u64 addr;
+	const bool zero = (flags & NVOBJ_FLAG_ZERO_ALLOC);
+	int ret;
 
 	*pobject = NULL;
 
@@ -122,83 +255,18 @@ nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 		if (WARN_ON(objgpu == NULL))
 			return -EINVAL;
 		pargpu = nv_gpuobj(objgpu);
-
-		addr =  pargpu->addr;
-		heap = &pargpu->heap;
-	} else {
-		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-				      size, align, false, &memory);
-		if (ret)
-			return ret;
-
-		addr = nvkm_memory_addr(memory);
-		size = nvkm_memory_size(memory);
 	}
 
 	ret = nvkm_object_create_(parent, engine, oclass, pclass |
 				  NV_GPUOBJ_CLASS, length, pobject);
 	gpuobj = *pobject;
-	if (ret) {
-		nvkm_memory_del(&memory);
-		return ret;
-	}
-
-	gpuobj->func = &nvkm_gpuobj_func;
-	gpuobj->memory = memory;
-	gpuobj->parent = pargpu;
-	gpuobj->flags = flags;
-	gpuobj->addr = addr;
-	gpuobj->size = size;
-
-	if (heap) {
-		ret = nvkm_mm_head(heap, 0, 1, size, size, max(align, (u32)1),
-				   &gpuobj->node);
-		if (ret)
-			return ret;
-
-		gpuobj->addr += gpuobj->node->offset;
-	}
-
-	if (gpuobj->flags & NVOBJ_FLAG_HEAP) {
-		ret = nvkm_mm_init(&gpuobj->heap, 0, gpuobj->size, 1);
-		if (ret)
-			return ret;
-	}
-
-	if (flags & NVOBJ_FLAG_ZERO_ALLOC) {
-		nvkm_kmap(gpuobj);
-		for (i = 0; i < gpuobj->size; i += 4)
-			nvkm_wo32(gpuobj, i, 0x00000000);
-		nvkm_done(gpuobj);
-	}
-
-	return ret;
-}
-
-struct nvkm_gpuobj_class {
-	struct nvkm_object *pargpu;
-	u64 size;
-	u32 align;
-	u32 flags;
-};
-
-static int
-_nvkm_gpuobj_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-		  struct nvkm_oclass *oclass, void *data, u32 size,
-		  struct nvkm_object **pobject)
-{
-	struct nvkm_gpuobj_class *args = data;
-	struct nvkm_gpuobj *object;
-	int ret;
-
-	ret = nvkm_gpuobj_create(parent, engine, oclass, 0, args->pargpu,
-				 args->size, args->align, args->flags,
-				 &object);
-	*pobject = nv_object(object);
 	if (ret)
 		return ret;
 
-	return 0;
+	ret = nvkm_gpuobj_ctor(device, size, align, zero, pargpu, gpuobj);
+	if (!(flags & NVOBJ_FLAG_HEAP))
+		gpuobj->heap.block_size = 0;
+	return ret;
 }
 
 void
@@ -233,39 +301,9 @@ _nvkm_gpuobj_wr32(struct nvkm_object *object, u64 addr, u32 data)
 	nvkm_wo32(gpuobj, addr, data);
 }
 
-static struct nvkm_oclass
-_nvkm_gpuobj_oclass = {
-	.handle = 0x00000000,
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = _nvkm_gpuobj_ctor,
-		.dtor = _nvkm_gpuobj_dtor,
-		.init = _nvkm_gpuobj_init,
-		.fini = _nvkm_gpuobj_fini,
-		.rd32 = _nvkm_gpuobj_rd32,
-		.wr32 = _nvkm_gpuobj_wr32,
-	},
-};
-
-int
-nvkm_gpuobj_new(struct nvkm_object *parent, struct nvkm_object *pargpu,
-		u32 size, u32 align, u32 flags,
-		struct nvkm_gpuobj **pgpuobj)
-{
-	struct nvkm_gpuobj_class args = {
-		.pargpu = pargpu,
-		.size = size,
-		.align = align,
-		.flags = flags,
-	};
-
-	return nvkm_object_old(parent, &parent->engine->subdev.object,
-			       &_nvkm_gpuobj_oclass, &args, sizeof(args),
-			       (struct nvkm_object **)pgpuobj);
-}
-
 int
-nvkm_gpuobj_map_vm(struct nvkm_gpuobj *gpuobj, struct nvkm_vm *vm,
-		   u32 access, struct nvkm_vma *vma)
+nvkm_gpuobj_map(struct nvkm_gpuobj *gpuobj, struct nvkm_vm *vm,
+		u32 access, struct nvkm_vma *vma)
 {
 	struct nvkm_memory *memory = gpuobj->memory;
 	int ret = nvkm_vm_get(vm, gpuobj->size, 12, access, vma);
@@ -288,37 +326,13 @@ nvkm_gpuobj_unmap(struct nvkm_vma *vma)
  * anywhere else.
  */
 
-static void
-nvkm_gpudup_dtor(struct nvkm_object *object)
-{
-	struct nvkm_gpuobj *gpuobj = (void *)object;
-	nvkm_object_destroy(&gpuobj->object);
-}
-
-static struct nvkm_oclass
-nvkm_gpudup_oclass = {
-	.handle = NV_GPUOBJ_CLASS,
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.dtor = nvkm_gpudup_dtor,
-		.init = _nvkm_object_init,
-		.fini = _nvkm_object_fini,
-	},
-};
-
 int
-nvkm_gpuobj_dup(struct nvkm_object *parent, struct nvkm_memory *base,
-		struct nvkm_gpuobj **pgpuobj)
+nvkm_gpuobj_wrap(struct nvkm_memory *memory, struct nvkm_gpuobj **pgpuobj)
 {
-	struct nvkm_gpuobj *gpuobj;
-	int ret;
-
-	ret = nvkm_object_create(parent, &parent->engine->subdev.object,
-				 &nvkm_gpudup_oclass, 0, &gpuobj);
-	*pgpuobj = gpuobj;
-	if (ret)
-		return ret;
+	if (!(*pgpuobj = kzalloc(sizeof(**pgpuobj), GFP_KERNEL)))
+		return -ENOMEM;
 
-	gpuobj->addr = nvkm_memory_addr(base);
-	gpuobj->size = nvkm_memory_size(base);
+	(*pgpuobj)->addr = nvkm_memory_addr(memory);
+	(*pgpuobj)->size = nvkm_memory_size(memory);
 	return 0;
 }

commit 358ce601ae5de59bf6f08f79455c5b3cb7d359d4
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/fifo: directly use instmem for runlists and polling areas
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index ada5b6114a40..c14469c3a861 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -263,22 +263,6 @@ nvkm_gpuobj_new(struct nvkm_object *parent, struct nvkm_object *pargpu,
 			       (struct nvkm_object **)pgpuobj);
 }
 
-int
-nvkm_gpuobj_map(struct nvkm_gpuobj *gpuobj, u32 access, struct nvkm_vma *vma)
-{
-	struct nvkm_memory *memory = gpuobj->memory;
-	struct nvkm_bar *bar = nvkm_bar(gpuobj);
-	int ret = -EINVAL;
-
-	if (bar && bar->umap) {
-		ret = bar->umap(bar, gpuobj->size, 12, vma);
-		if (ret == 0)
-			nvkm_memory_map(memory, vma, 0);
-	}
-
-	return ret;
-}
-
 int
 nvkm_gpuobj_map_vm(struct nvkm_gpuobj *gpuobj, struct nvkm_vm *vm,
 		   u32 access, struct nvkm_vma *vma)

commit d0659d3277cd7bf50e45d48f4692a7fbb11e5957
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/mmu: directly use instmem for page tables
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 037036069839..ada5b6114a40 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -308,7 +308,6 @@ static void
 nvkm_gpudup_dtor(struct nvkm_object *object)
 {
 	struct nvkm_gpuobj *gpuobj = (void *)object;
-	nvkm_object_ref(NULL, (struct nvkm_object **)&gpuobj->parent);
 	nvkm_object_destroy(&gpuobj->object);
 }
 
@@ -323,7 +322,7 @@ nvkm_gpudup_oclass = {
 };
 
 int
-nvkm_gpuobj_dup(struct nvkm_object *parent, struct nvkm_gpuobj *base,
+nvkm_gpuobj_dup(struct nvkm_object *parent, struct nvkm_memory *base,
 		struct nvkm_gpuobj **pgpuobj)
 {
 	struct nvkm_gpuobj *gpuobj;
@@ -335,8 +334,7 @@ nvkm_gpuobj_dup(struct nvkm_object *parent, struct nvkm_gpuobj *base,
 	if (ret)
 		return ret;
 
-	nvkm_object_ref(nv_object(base), (struct nvkm_object **)&gpuobj->parent);
-	gpuobj->addr = base->addr;
-	gpuobj->size = base->size;
+	gpuobj->addr = nvkm_memory_addr(base);
+	gpuobj->size = nvkm_memory_size(base);
 	return 0;
 }

commit d8e83994aaf6749b7124a219f5b46bd1329e2a08
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/imem: improve management of instance memory
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index bc4b3c2d075e..037036069839 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -28,6 +28,44 @@
 #include <subdev/bar.h>
 #include <subdev/mmu.h>
 
+static void
+nvkm_gpuobj_release(struct nvkm_gpuobj *gpuobj)
+{
+	if (gpuobj->node) {
+		nvkm_done(gpuobj->parent);
+		return;
+	}
+	nvkm_done(gpuobj->memory);
+}
+
+static void
+nvkm_gpuobj_acquire(struct nvkm_gpuobj *gpuobj)
+{
+	if (gpuobj->node) {
+		nvkm_kmap(gpuobj->parent);
+		return;
+	}
+	nvkm_kmap(gpuobj->memory);
+}
+
+static u32
+nvkm_gpuobj_rd32(struct nvkm_gpuobj *gpuobj, u32 offset)
+{
+	if (gpuobj->node)
+		return nvkm_ro32(gpuobj->parent, gpuobj->node->offset + offset);
+	return nvkm_ro32(gpuobj->memory, offset);
+}
+
+static void
+nvkm_gpuobj_wr32(struct nvkm_gpuobj *gpuobj, u32 offset, u32 data)
+{
+	if (gpuobj->node) {
+		nvkm_wo32(gpuobj->parent, gpuobj->node->offset + offset, data);
+		return;
+	}
+	nvkm_wo32(gpuobj->memory, offset, data);
+}
+
 void
 nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
 {
@@ -46,17 +84,27 @@ nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
 	if (gpuobj->heap.block_size)
 		nvkm_mm_fini(&gpuobj->heap);
 
+	nvkm_memory_del(&gpuobj->memory);
 	nvkm_object_destroy(&gpuobj->object);
 }
 
+static const struct nvkm_gpuobj_func
+nvkm_gpuobj_func = {
+	.acquire = nvkm_gpuobj_acquire,
+	.release = nvkm_gpuobj_release,
+	.rd32 = nvkm_gpuobj_rd32,
+	.wr32 = nvkm_gpuobj_wr32,
+};
+
 int
 nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 		    struct nvkm_oclass *oclass, u32 pclass,
-		    struct nvkm_object *pargpu, u32 size, u32 align, u32 flags,
+		    struct nvkm_object *objgpu, u32 size, u32 align, u32 flags,
 		    int length, void **pobject)
 {
-	struct nvkm_instmem *imem = nvkm_instmem(parent);
-	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct nvkm_device *device = nv_device(parent);
+	struct nvkm_memory *memory = NULL;
+	struct nvkm_gpuobj *pargpu = NULL;
 	struct nvkm_gpuobj *gpuobj;
 	struct nvkm_mm *heap = NULL;
 	int ret, i;
@@ -64,46 +112,39 @@ nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	*pobject = NULL;
 
-	if (pargpu) {
-		while ((pargpu = nv_pclass(pargpu, NV_GPUOBJ_CLASS))) {
-			if (nv_gpuobj(pargpu)->heap.block_size)
+	if (objgpu) {
+		while ((objgpu = nv_pclass(objgpu, NV_GPUOBJ_CLASS))) {
+			if (nv_gpuobj(objgpu)->heap.block_size)
 				break;
-			pargpu = pargpu->parent;
+			objgpu = objgpu->parent;
 		}
 
-		if (WARN_ON(pargpu == NULL))
+		if (WARN_ON(objgpu == NULL))
 			return -EINVAL;
+		pargpu = nv_gpuobj(objgpu);
 
-		addr =  nv_gpuobj(pargpu)->addr;
-		heap = &nv_gpuobj(pargpu)->heap;
-		atomic_inc(&parent->refcount);
+		addr =  pargpu->addr;
+		heap = &pargpu->heap;
 	} else {
-		ret = imem->alloc(imem, parent, size, align, &parent);
-		pargpu = parent;
+		ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+				      size, align, false, &memory);
 		if (ret)
 			return ret;
 
-		addr = nv_memobj(pargpu)->addr;
-		size = nv_memobj(pargpu)->size;
-
-		if (bar && bar->alloc) {
-			struct nvkm_instobj *iobj = (void *)parent;
-			struct nvkm_mem **mem = (void *)(iobj + 1);
-			struct nvkm_mem *node = *mem;
-			if (!bar->alloc(bar, parent, node, &pargpu)) {
-				nvkm_object_ref(NULL, &parent);
-				parent = pargpu;
-			}
-		}
+		addr = nvkm_memory_addr(memory);
+		size = nvkm_memory_size(memory);
 	}
 
 	ret = nvkm_object_create_(parent, engine, oclass, pclass |
 				  NV_GPUOBJ_CLASS, length, pobject);
-	nvkm_object_ref(NULL, &parent);
 	gpuobj = *pobject;
-	if (ret)
+	if (ret) {
+		nvkm_memory_del(&memory);
 		return ret;
+	}
 
+	gpuobj->func = &nvkm_gpuobj_func;
+	gpuobj->memory = memory;
 	gpuobj->parent = pargpu;
 	gpuobj->flags = flags;
 	gpuobj->addr = addr;
@@ -182,20 +223,14 @@ u32
 _nvkm_gpuobj_rd32(struct nvkm_object *object, u64 addr)
 {
 	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
-	u32 data;
-	if (gpuobj->node)
-		addr += gpuobj->node->offset;
-	nvkm_object_rd32(gpuobj->parent, addr, &data);
-	return data;
+	return nvkm_ro32(gpuobj, addr);
 }
 
 void
 _nvkm_gpuobj_wr32(struct nvkm_object *object, u64 addr, u32 data)
 {
 	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
-	if (gpuobj->node)
-		addr += gpuobj->node->offset;
-	nvkm_object_wr32(gpuobj->parent, addr, data);
+	nvkm_wo32(gpuobj, addr, data);
 }
 
 static struct nvkm_oclass
@@ -231,14 +266,14 @@ nvkm_gpuobj_new(struct nvkm_object *parent, struct nvkm_object *pargpu,
 int
 nvkm_gpuobj_map(struct nvkm_gpuobj *gpuobj, u32 access, struct nvkm_vma *vma)
 {
+	struct nvkm_memory *memory = gpuobj->memory;
 	struct nvkm_bar *bar = nvkm_bar(gpuobj);
 	int ret = -EINVAL;
 
 	if (bar && bar->umap) {
-		struct nvkm_instobj *iobj = (void *)
-			nv_pclass(nv_object(gpuobj), NV_MEMOBJ_CLASS);
-		struct nvkm_mem **mem = (void *)(iobj + 1);
-		ret = bar->umap(bar, *mem, access, vma);
+		ret = bar->umap(bar, gpuobj->size, 12, vma);
+		if (ret == 0)
+			nvkm_memory_map(memory, vma, 0);
 	}
 
 	return ret;
@@ -248,17 +283,11 @@ int
 nvkm_gpuobj_map_vm(struct nvkm_gpuobj *gpuobj, struct nvkm_vm *vm,
 		   u32 access, struct nvkm_vma *vma)
 {
-	struct nvkm_instobj *iobj = (void *)
-		nv_pclass(nv_object(gpuobj), NV_MEMOBJ_CLASS);
-	struct nvkm_mem **mem = (void *)(iobj + 1);
-	int ret;
-
-	ret = nvkm_vm_get(vm, gpuobj->size, 12, access, vma);
-	if (ret)
-		return ret;
-
-	nvkm_vm_map(vma, *mem);
-	return 0;
+	struct nvkm_memory *memory = gpuobj->memory;
+	int ret = nvkm_vm_get(vm, gpuobj->size, 12, access, vma);
+	if (ret == 0)
+		nvkm_memory_map(memory, vma, 0);
+	return ret;
 }
 
 void
@@ -279,7 +308,7 @@ static void
 nvkm_gpudup_dtor(struct nvkm_object *object)
 {
 	struct nvkm_gpuobj *gpuobj = (void *)object;
-	nvkm_object_ref(NULL, &gpuobj->parent);
+	nvkm_object_ref(NULL, (struct nvkm_object **)&gpuobj->parent);
 	nvkm_object_destroy(&gpuobj->object);
 }
 
@@ -306,7 +335,7 @@ nvkm_gpuobj_dup(struct nvkm_object *parent, struct nvkm_gpuobj *base,
 	if (ret)
 		return ret;
 
-	nvkm_object_ref(nv_object(base), &gpuobj->parent);
+	nvkm_object_ref(nv_object(base), (struct nvkm_object **)&gpuobj->parent);
 	gpuobj->addr = base->addr;
 	gpuobj->size = base->size;
 	return 0;

commit cbea21e2ab658ca1256bfe5f4c535b2b1b9e4060
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/object: implement support for new-style nvkm_object
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 1ca5479ee38b..bc4b3c2d075e 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -182,20 +182,20 @@ u32
 _nvkm_gpuobj_rd32(struct nvkm_object *object, u64 addr)
 {
 	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
-	struct nvkm_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
+	u32 data;
 	if (gpuobj->node)
 		addr += gpuobj->node->offset;
-	return pfuncs->rd32(gpuobj->parent, addr);
+	nvkm_object_rd32(gpuobj->parent, addr, &data);
+	return data;
 }
 
 void
 _nvkm_gpuobj_wr32(struct nvkm_object *object, u64 addr, u32 data)
 {
 	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
-	struct nvkm_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
 	if (gpuobj->node)
 		addr += gpuobj->node->offset;
-	pfuncs->wr32(gpuobj->parent, addr, data);
+	nvkm_object_wr32(gpuobj->parent, addr, data);
 }
 
 static struct nvkm_oclass

commit aa35888ff024b18c7b6b29eb773a221f642987f7
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/object: rename some functions to avoid upcoming conflicts
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 6e2683323570..1ca5479ee38b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -223,9 +223,9 @@ nvkm_gpuobj_new(struct nvkm_object *parent, struct nvkm_object *pargpu,
 		.flags = flags,
 	};
 
-	return nvkm_object_ctor(parent, &parent->engine->subdev.object,
-				&_nvkm_gpuobj_oclass, &args, sizeof(args),
-				(struct nvkm_object **)pgpuobj);
+	return nvkm_object_old(parent, &parent->engine->subdev.object,
+			       &_nvkm_gpuobj_oclass, &args, sizeof(args),
+			       (struct nvkm_object **)pgpuobj);
 }
 
 int
@@ -288,8 +288,8 @@ nvkm_gpudup_oclass = {
 	.handle = NV_GPUOBJ_CLASS,
 	.ofuncs = &(struct nvkm_ofuncs) {
 		.dtor = nvkm_gpudup_dtor,
-		.init = nvkm_object_init,
-		.fini = nvkm_object_fini,
+		.init = _nvkm_object_init,
+		.fini = _nvkm_object_fini,
 	},
 };
 

commit a1e88736221d2e971726931c449ed7d0af31755b
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:15 2015 +1000

    drm/nouveau/device: decouple from engine machinery
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index f99b446c1e10..6e2683323570 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -216,7 +216,6 @@ nvkm_gpuobj_new(struct nvkm_object *parent, struct nvkm_object *pargpu,
 		u32 size, u32 align, u32 flags,
 		struct nvkm_gpuobj **pgpuobj)
 {
-	struct nvkm_object *engine = parent;
 	struct nvkm_gpuobj_class args = {
 		.pargpu = pargpu,
 		.size = size,
@@ -224,12 +223,8 @@ nvkm_gpuobj_new(struct nvkm_object *parent, struct nvkm_object *pargpu,
 		.flags = flags,
 	};
 
-	if (!nv_iclass(engine, NV_SUBDEV_CLASS))
-		engine = &engine->engine->subdev.object;
-	BUG_ON(engine == NULL);
-
-	return nvkm_object_ctor(parent, engine, &_nvkm_gpuobj_oclass,
-				&args, sizeof(args),
+	return nvkm_object_ctor(parent, &parent->engine->subdev.object,
+				&_nvkm_gpuobj_oclass, &args, sizeof(args),
 				(struct nvkm_object **)pgpuobj);
 }
 

commit 45ea503161af6e94d593a59e8cca8981d0435d5c
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:14 2015 +1000

    drm/nouveau/core: switch to gpuobj accessor macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index c6e5f7a7f005..f99b446c1e10 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -34,8 +34,10 @@ nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
 	int i;
 
 	if (gpuobj->flags & NVOBJ_FLAG_ZERO_FREE) {
+		nvkm_kmap(gpuobj);
 		for (i = 0; i < gpuobj->size; i += 4)
-			nv_wo32(gpuobj, i, 0x00000000);
+			nvkm_wo32(gpuobj, i, 0x00000000);
+		nvkm_done(gpuobj);
 	}
 
 	if (gpuobj->node)
@@ -123,8 +125,10 @@ nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 	}
 
 	if (flags & NVOBJ_FLAG_ZERO_ALLOC) {
+		nvkm_kmap(gpuobj);
 		for (i = 0; i < gpuobj->size; i += 4)
-			nv_wo32(gpuobj, i, 0x00000000);
+			nvkm_wo32(gpuobj, i, 0x00000000);
+		nvkm_done(gpuobj);
 	}
 
 	return ret;

commit 53003941067534b1071b0f7b71f4700c16d97b28
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:13 2015 +1000

    drm/nouveau/core: remove last printks
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 2eba801aae6f..c6e5f7a7f005 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -69,10 +69,8 @@ nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
 			pargpu = pargpu->parent;
 		}
 
-		if (unlikely(pargpu == NULL)) {
-			nv_error(parent, "no gpuobj heap\n");
+		if (WARN_ON(pargpu == NULL))
 			return -EINVAL;
-		}
 
 		addr =  nv_gpuobj(pargpu)->addr;
 		heap = &nv_gpuobj(pargpu)->heap;

commit 42594600095f03244a674fecdd2b5f6da2441180
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 15:09:19 2015 +1000

    drm/nouveau/mmu: namespace + nvidia gpu names (no binary change)
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 0c5cb55fc617..2eba801aae6f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -22,6 +22,7 @@
  * Authors: Ben Skeggs
  */
 #include <core/gpuobj.h>
+#include <core/engine.h>
 
 #include <subdev/instmem.h>
 #include <subdev/bar.h>

commit 5025407b9862349d17b1dff25737aaef6520a439
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 14:11:21 2015 +1000

    drm/nouveau/core: namespace + nvidia gpu names (no binary change)
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 68a4232d35cc..0c5cb55fc617 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -21,8 +21,6 @@
  *
  * Authors: Ben Skeggs
  */
-
-#include <core/object.h>
 #include <core/gpuobj.h>
 
 #include <subdev/instmem.h>
@@ -30,7 +28,7 @@
 #include <subdev/mmu.h>
 
 void
-nouveau_gpuobj_destroy(struct nouveau_gpuobj *gpuobj)
+nvkm_gpuobj_destroy(struct nvkm_gpuobj *gpuobj)
 {
 	int i;
 
@@ -39,29 +37,25 @@ nouveau_gpuobj_destroy(struct nouveau_gpuobj *gpuobj)
 			nv_wo32(gpuobj, i, 0x00000000);
 	}
 
-	if (gpuobj->node) {
-		nouveau_mm_free(&nv_gpuobj(gpuobj->parent)->heap,
-				&gpuobj->node);
-	}
+	if (gpuobj->node)
+		nvkm_mm_free(&nv_gpuobj(gpuobj->parent)->heap, &gpuobj->node);
 
 	if (gpuobj->heap.block_size)
-		nouveau_mm_fini(&gpuobj->heap);
+		nvkm_mm_fini(&gpuobj->heap);
 
-	nouveau_object_destroy(&gpuobj->object);
+	nvkm_object_destroy(&gpuobj->object);
 }
 
 int
-nouveau_gpuobj_create_(struct nouveau_object *parent,
-		       struct nouveau_object *engine,
-		       struct nouveau_oclass *oclass, u32 pclass,
-		       struct nouveau_object *pargpu,
-		       u32 size, u32 align, u32 flags,
-		       int length, void **pobject)
+nvkm_gpuobj_create_(struct nvkm_object *parent, struct nvkm_object *engine,
+		    struct nvkm_oclass *oclass, u32 pclass,
+		    struct nvkm_object *pargpu, u32 size, u32 align, u32 flags,
+		    int length, void **pobject)
 {
-	struct nouveau_instmem *imem = nouveau_instmem(parent);
-	struct nouveau_bar *bar = nouveau_bar(parent);
-	struct nouveau_gpuobj *gpuobj;
-	struct nouveau_mm *heap = NULL;
+	struct nvkm_instmem *imem = nvkm_instmem(parent);
+	struct nvkm_bar *bar = nvkm_bar(parent);
+	struct nvkm_gpuobj *gpuobj;
+	struct nvkm_mm *heap = NULL;
 	int ret, i;
 	u64 addr;
 
@@ -92,19 +86,19 @@ nouveau_gpuobj_create_(struct nouveau_object *parent,
 		size = nv_memobj(pargpu)->size;
 
 		if (bar && bar->alloc) {
-			struct nouveau_instobj *iobj = (void *)parent;
-			struct nouveau_mem **mem = (void *)(iobj + 1);
-			struct nouveau_mem *node = *mem;
+			struct nvkm_instobj *iobj = (void *)parent;
+			struct nvkm_mem **mem = (void *)(iobj + 1);
+			struct nvkm_mem *node = *mem;
 			if (!bar->alloc(bar, parent, node, &pargpu)) {
-				nouveau_object_ref(NULL, &parent);
+				nvkm_object_ref(NULL, &parent);
 				parent = pargpu;
 			}
 		}
 	}
 
-	ret = nouveau_object_create_(parent, engine, oclass, pclass |
-				     NV_GPUOBJ_CLASS, length, pobject);
-	nouveau_object_ref(NULL, &parent);
+	ret = nvkm_object_create_(parent, engine, oclass, pclass |
+				  NV_GPUOBJ_CLASS, length, pobject);
+	nvkm_object_ref(NULL, &parent);
 	gpuobj = *pobject;
 	if (ret)
 		return ret;
@@ -115,8 +109,8 @@ nouveau_gpuobj_create_(struct nouveau_object *parent,
 	gpuobj->size = size;
 
 	if (heap) {
-		ret = nouveau_mm_head(heap, 0, 1, size, size,
-				      max(align, (u32)1), &gpuobj->node);
+		ret = nvkm_mm_head(heap, 0, 1, size, size, max(align, (u32)1),
+				   &gpuobj->node);
 		if (ret)
 			return ret;
 
@@ -124,7 +118,7 @@ nouveau_gpuobj_create_(struct nouveau_object *parent,
 	}
 
 	if (gpuobj->flags & NVOBJ_FLAG_HEAP) {
-		ret = nouveau_mm_init(&gpuobj->heap, 0, gpuobj->size, 1);
+		ret = nvkm_mm_init(&gpuobj->heap, 0, gpuobj->size, 1);
 		if (ret)
 			return ret;
 	}
@@ -137,26 +131,25 @@ nouveau_gpuobj_create_(struct nouveau_object *parent,
 	return ret;
 }
 
-struct nouveau_gpuobj_class {
-	struct nouveau_object *pargpu;
+struct nvkm_gpuobj_class {
+	struct nvkm_object *pargpu;
 	u64 size;
 	u32 align;
 	u32 flags;
 };
 
 static int
-_nouveau_gpuobj_ctor(struct nouveau_object *parent,
-		     struct nouveau_object *engine,
-		     struct nouveau_oclass *oclass, void *data, u32 size,
-		     struct nouveau_object **pobject)
+_nvkm_gpuobj_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+		  struct nvkm_oclass *oclass, void *data, u32 size,
+		  struct nvkm_object **pobject)
 {
-	struct nouveau_gpuobj_class *args = data;
-	struct nouveau_gpuobj *object;
+	struct nvkm_gpuobj_class *args = data;
+	struct nvkm_gpuobj *object;
 	int ret;
 
-	ret = nouveau_gpuobj_create(parent, engine, oclass, 0, args->pargpu,
-				    args->size, args->align, args->flags,
-				    &object);
+	ret = nvkm_gpuobj_create(parent, engine, oclass, 0, args->pargpu,
+				 args->size, args->align, args->flags,
+				 &object);
 	*pobject = nv_object(object);
 	if (ret)
 		return ret;
@@ -165,63 +158,63 @@ _nouveau_gpuobj_ctor(struct nouveau_object *parent,
 }
 
 void
-_nouveau_gpuobj_dtor(struct nouveau_object *object)
+_nvkm_gpuobj_dtor(struct nvkm_object *object)
 {
-	nouveau_gpuobj_destroy(nv_gpuobj(object));
+	nvkm_gpuobj_destroy(nv_gpuobj(object));
 }
 
 int
-_nouveau_gpuobj_init(struct nouveau_object *object)
+_nvkm_gpuobj_init(struct nvkm_object *object)
 {
-	return nouveau_gpuobj_init(nv_gpuobj(object));
+	return nvkm_gpuobj_init(nv_gpuobj(object));
 }
 
 int
-_nouveau_gpuobj_fini(struct nouveau_object *object, bool suspend)
+_nvkm_gpuobj_fini(struct nvkm_object *object, bool suspend)
 {
-	return nouveau_gpuobj_fini(nv_gpuobj(object), suspend);
+	return nvkm_gpuobj_fini(nv_gpuobj(object), suspend);
 }
 
 u32
-_nouveau_gpuobj_rd32(struct nouveau_object *object, u64 addr)
+_nvkm_gpuobj_rd32(struct nvkm_object *object, u64 addr)
 {
-	struct nouveau_gpuobj *gpuobj = nv_gpuobj(object);
-	struct nouveau_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
+	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
+	struct nvkm_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
 	if (gpuobj->node)
 		addr += gpuobj->node->offset;
 	return pfuncs->rd32(gpuobj->parent, addr);
 }
 
 void
-_nouveau_gpuobj_wr32(struct nouveau_object *object, u64 addr, u32 data)
+_nvkm_gpuobj_wr32(struct nvkm_object *object, u64 addr, u32 data)
 {
-	struct nouveau_gpuobj *gpuobj = nv_gpuobj(object);
-	struct nouveau_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
+	struct nvkm_gpuobj *gpuobj = nv_gpuobj(object);
+	struct nvkm_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
 	if (gpuobj->node)
 		addr += gpuobj->node->offset;
 	pfuncs->wr32(gpuobj->parent, addr, data);
 }
 
-static struct nouveau_oclass
-_nouveau_gpuobj_oclass = {
+static struct nvkm_oclass
+_nvkm_gpuobj_oclass = {
 	.handle = 0x00000000,
-	.ofuncs = &(struct nouveau_ofuncs) {
-		.ctor = _nouveau_gpuobj_ctor,
-		.dtor = _nouveau_gpuobj_dtor,
-		.init = _nouveau_gpuobj_init,
-		.fini = _nouveau_gpuobj_fini,
-		.rd32 = _nouveau_gpuobj_rd32,
-		.wr32 = _nouveau_gpuobj_wr32,
+	.ofuncs = &(struct nvkm_ofuncs) {
+		.ctor = _nvkm_gpuobj_ctor,
+		.dtor = _nvkm_gpuobj_dtor,
+		.init = _nvkm_gpuobj_init,
+		.fini = _nvkm_gpuobj_fini,
+		.rd32 = _nvkm_gpuobj_rd32,
+		.wr32 = _nvkm_gpuobj_wr32,
 	},
 };
 
 int
-nouveau_gpuobj_new(struct nouveau_object *parent, struct nouveau_object *pargpu,
-		   u32 size, u32 align, u32 flags,
-		   struct nouveau_gpuobj **pgpuobj)
+nvkm_gpuobj_new(struct nvkm_object *parent, struct nvkm_object *pargpu,
+		u32 size, u32 align, u32 flags,
+		struct nvkm_gpuobj **pgpuobj)
 {
-	struct nouveau_object *engine = parent;
-	struct nouveau_gpuobj_class args = {
+	struct nvkm_object *engine = parent;
+	struct nvkm_gpuobj_class args = {
 		.pargpu = pargpu,
 		.size = size,
 		.align = align,
@@ -232,22 +225,21 @@ nouveau_gpuobj_new(struct nouveau_object *parent, struct nouveau_object *pargpu,
 		engine = &engine->engine->subdev.object;
 	BUG_ON(engine == NULL);
 
-	return nouveau_object_ctor(parent, engine, &_nouveau_gpuobj_oclass,
-				   &args, sizeof(args),
-				   (struct nouveau_object **)pgpuobj);
+	return nvkm_object_ctor(parent, engine, &_nvkm_gpuobj_oclass,
+				&args, sizeof(args),
+				(struct nvkm_object **)pgpuobj);
 }
 
 int
-nouveau_gpuobj_map(struct nouveau_gpuobj *gpuobj, u32 access,
-		   struct nouveau_vma *vma)
+nvkm_gpuobj_map(struct nvkm_gpuobj *gpuobj, u32 access, struct nvkm_vma *vma)
 {
-	struct nouveau_bar *bar = nouveau_bar(gpuobj);
+	struct nvkm_bar *bar = nvkm_bar(gpuobj);
 	int ret = -EINVAL;
 
 	if (bar && bar->umap) {
-		struct nouveau_instobj *iobj = (void *)
+		struct nvkm_instobj *iobj = (void *)
 			nv_pclass(nv_object(gpuobj), NV_MEMOBJ_CLASS);
-		struct nouveau_mem **mem = (void *)(iobj + 1);
+		struct nvkm_mem **mem = (void *)(iobj + 1);
 		ret = bar->umap(bar, *mem, access, vma);
 	}
 
@@ -255,28 +247,28 @@ nouveau_gpuobj_map(struct nouveau_gpuobj *gpuobj, u32 access,
 }
 
 int
-nouveau_gpuobj_map_vm(struct nouveau_gpuobj *gpuobj, struct nouveau_vm *vm,
-		      u32 access, struct nouveau_vma *vma)
+nvkm_gpuobj_map_vm(struct nvkm_gpuobj *gpuobj, struct nvkm_vm *vm,
+		   u32 access, struct nvkm_vma *vma)
 {
-	struct nouveau_instobj *iobj = (void *)
+	struct nvkm_instobj *iobj = (void *)
 		nv_pclass(nv_object(gpuobj), NV_MEMOBJ_CLASS);
-	struct nouveau_mem **mem = (void *)(iobj + 1);
+	struct nvkm_mem **mem = (void *)(iobj + 1);
 	int ret;
 
-	ret = nouveau_vm_get(vm, gpuobj->size, 12, access, vma);
+	ret = nvkm_vm_get(vm, gpuobj->size, 12, access, vma);
 	if (ret)
 		return ret;
 
-	nouveau_vm_map(vma, *mem);
+	nvkm_vm_map(vma, *mem);
 	return 0;
 }
 
 void
-nouveau_gpuobj_unmap(struct nouveau_vma *vma)
+nvkm_gpuobj_unmap(struct nvkm_vma *vma)
 {
 	if (vma->node) {
-		nouveau_vm_unmap(vma);
-		nouveau_vm_put(vma);
+		nvkm_vm_unmap(vma);
+		nvkm_vm_put(vma);
 	}
 }
 
@@ -286,37 +278,37 @@ nouveau_gpuobj_unmap(struct nouveau_vma *vma)
  */
 
 static void
-nouveau_gpudup_dtor(struct nouveau_object *object)
+nvkm_gpudup_dtor(struct nvkm_object *object)
 {
-	struct nouveau_gpuobj *gpuobj = (void *)object;
-	nouveau_object_ref(NULL, &gpuobj->parent);
-	nouveau_object_destroy(&gpuobj->object);
+	struct nvkm_gpuobj *gpuobj = (void *)object;
+	nvkm_object_ref(NULL, &gpuobj->parent);
+	nvkm_object_destroy(&gpuobj->object);
 }
 
-static struct nouveau_oclass
-nouveau_gpudup_oclass = {
+static struct nvkm_oclass
+nvkm_gpudup_oclass = {
 	.handle = NV_GPUOBJ_CLASS,
-	.ofuncs = &(struct nouveau_ofuncs) {
-		.dtor = nouveau_gpudup_dtor,
-		.init = nouveau_object_init,
-		.fini = nouveau_object_fini,
+	.ofuncs = &(struct nvkm_ofuncs) {
+		.dtor = nvkm_gpudup_dtor,
+		.init = nvkm_object_init,
+		.fini = nvkm_object_fini,
 	},
 };
 
 int
-nouveau_gpuobj_dup(struct nouveau_object *parent, struct nouveau_gpuobj *base,
-		   struct nouveau_gpuobj **pgpuobj)
+nvkm_gpuobj_dup(struct nvkm_object *parent, struct nvkm_gpuobj *base,
+		struct nvkm_gpuobj **pgpuobj)
 {
-	struct nouveau_gpuobj *gpuobj;
+	struct nvkm_gpuobj *gpuobj;
 	int ret;
 
-	ret = nouveau_object_create(parent, &parent->engine->subdev.object,
-				   &nouveau_gpudup_oclass, 0, &gpuobj);
+	ret = nvkm_object_create(parent, &parent->engine->subdev.object,
+				 &nvkm_gpudup_oclass, 0, &gpuobj);
 	*pgpuobj = gpuobj;
 	if (ret)
 		return ret;
 
-	nouveau_object_ref(nv_object(base), &gpuobj->parent);
+	nvkm_object_ref(nv_object(base), &gpuobj->parent);
 	gpuobj->addr = base->addr;
 	gpuobj->size = base->size;
 	return 0;

commit 5ce3bf3c72436c49fbd9a5b71d7d278665f4bf55
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 09:57:36 2015 +1000

    drm/nouveau/mmu: rename from vmmgr (no binary change)
    
    Switch to NVIDIA's name for the device.
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
index 0fa64576b8d6..68a4232d35cc 100644
--- a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -27,7 +27,7 @@
 
 #include <subdev/instmem.h>
 #include <subdev/bar.h>
-#include <subdev/vm.h>
+#include <subdev/mmu.h>
 
 void
 nouveau_gpuobj_destroy(struct nouveau_gpuobj *gpuobj)

commit c39f472e9f14e49a9bc091977ced0ec45fc00c57
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Tue Jan 13 22:13:14 2015 +1000

    drm/nouveau: remove symlinks, move core/ to nvkm/ (no code changes)
    
    The symlinks were annoying some people, and they're not used anywhere
    else in the kernel tree.  The include directory structure has been
    changed so that symlinks aren't needed anymore.
    
    NVKM has been moved from core/ to nvkm/ to make it more obvious as to
    what the directory is for, and as some minor prep for when NVKM gets
    split out into its own module (virt) at a later date.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
new file mode 100644
index 000000000000..0fa64576b8d6
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvkm/core/gpuobj.c
@@ -0,0 +1,323 @@
+/*
+ * Copyright 2012 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include <core/object.h>
+#include <core/gpuobj.h>
+
+#include <subdev/instmem.h>
+#include <subdev/bar.h>
+#include <subdev/vm.h>
+
+void
+nouveau_gpuobj_destroy(struct nouveau_gpuobj *gpuobj)
+{
+	int i;
+
+	if (gpuobj->flags & NVOBJ_FLAG_ZERO_FREE) {
+		for (i = 0; i < gpuobj->size; i += 4)
+			nv_wo32(gpuobj, i, 0x00000000);
+	}
+
+	if (gpuobj->node) {
+		nouveau_mm_free(&nv_gpuobj(gpuobj->parent)->heap,
+				&gpuobj->node);
+	}
+
+	if (gpuobj->heap.block_size)
+		nouveau_mm_fini(&gpuobj->heap);
+
+	nouveau_object_destroy(&gpuobj->object);
+}
+
+int
+nouveau_gpuobj_create_(struct nouveau_object *parent,
+		       struct nouveau_object *engine,
+		       struct nouveau_oclass *oclass, u32 pclass,
+		       struct nouveau_object *pargpu,
+		       u32 size, u32 align, u32 flags,
+		       int length, void **pobject)
+{
+	struct nouveau_instmem *imem = nouveau_instmem(parent);
+	struct nouveau_bar *bar = nouveau_bar(parent);
+	struct nouveau_gpuobj *gpuobj;
+	struct nouveau_mm *heap = NULL;
+	int ret, i;
+	u64 addr;
+
+	*pobject = NULL;
+
+	if (pargpu) {
+		while ((pargpu = nv_pclass(pargpu, NV_GPUOBJ_CLASS))) {
+			if (nv_gpuobj(pargpu)->heap.block_size)
+				break;
+			pargpu = pargpu->parent;
+		}
+
+		if (unlikely(pargpu == NULL)) {
+			nv_error(parent, "no gpuobj heap\n");
+			return -EINVAL;
+		}
+
+		addr =  nv_gpuobj(pargpu)->addr;
+		heap = &nv_gpuobj(pargpu)->heap;
+		atomic_inc(&parent->refcount);
+	} else {
+		ret = imem->alloc(imem, parent, size, align, &parent);
+		pargpu = parent;
+		if (ret)
+			return ret;
+
+		addr = nv_memobj(pargpu)->addr;
+		size = nv_memobj(pargpu)->size;
+
+		if (bar && bar->alloc) {
+			struct nouveau_instobj *iobj = (void *)parent;
+			struct nouveau_mem **mem = (void *)(iobj + 1);
+			struct nouveau_mem *node = *mem;
+			if (!bar->alloc(bar, parent, node, &pargpu)) {
+				nouveau_object_ref(NULL, &parent);
+				parent = pargpu;
+			}
+		}
+	}
+
+	ret = nouveau_object_create_(parent, engine, oclass, pclass |
+				     NV_GPUOBJ_CLASS, length, pobject);
+	nouveau_object_ref(NULL, &parent);
+	gpuobj = *pobject;
+	if (ret)
+		return ret;
+
+	gpuobj->parent = pargpu;
+	gpuobj->flags = flags;
+	gpuobj->addr = addr;
+	gpuobj->size = size;
+
+	if (heap) {
+		ret = nouveau_mm_head(heap, 0, 1, size, size,
+				      max(align, (u32)1), &gpuobj->node);
+		if (ret)
+			return ret;
+
+		gpuobj->addr += gpuobj->node->offset;
+	}
+
+	if (gpuobj->flags & NVOBJ_FLAG_HEAP) {
+		ret = nouveau_mm_init(&gpuobj->heap, 0, gpuobj->size, 1);
+		if (ret)
+			return ret;
+	}
+
+	if (flags & NVOBJ_FLAG_ZERO_ALLOC) {
+		for (i = 0; i < gpuobj->size; i += 4)
+			nv_wo32(gpuobj, i, 0x00000000);
+	}
+
+	return ret;
+}
+
+struct nouveau_gpuobj_class {
+	struct nouveau_object *pargpu;
+	u64 size;
+	u32 align;
+	u32 flags;
+};
+
+static int
+_nouveau_gpuobj_ctor(struct nouveau_object *parent,
+		     struct nouveau_object *engine,
+		     struct nouveau_oclass *oclass, void *data, u32 size,
+		     struct nouveau_object **pobject)
+{
+	struct nouveau_gpuobj_class *args = data;
+	struct nouveau_gpuobj *object;
+	int ret;
+
+	ret = nouveau_gpuobj_create(parent, engine, oclass, 0, args->pargpu,
+				    args->size, args->align, args->flags,
+				    &object);
+	*pobject = nv_object(object);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+void
+_nouveau_gpuobj_dtor(struct nouveau_object *object)
+{
+	nouveau_gpuobj_destroy(nv_gpuobj(object));
+}
+
+int
+_nouveau_gpuobj_init(struct nouveau_object *object)
+{
+	return nouveau_gpuobj_init(nv_gpuobj(object));
+}
+
+int
+_nouveau_gpuobj_fini(struct nouveau_object *object, bool suspend)
+{
+	return nouveau_gpuobj_fini(nv_gpuobj(object), suspend);
+}
+
+u32
+_nouveau_gpuobj_rd32(struct nouveau_object *object, u64 addr)
+{
+	struct nouveau_gpuobj *gpuobj = nv_gpuobj(object);
+	struct nouveau_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
+	if (gpuobj->node)
+		addr += gpuobj->node->offset;
+	return pfuncs->rd32(gpuobj->parent, addr);
+}
+
+void
+_nouveau_gpuobj_wr32(struct nouveau_object *object, u64 addr, u32 data)
+{
+	struct nouveau_gpuobj *gpuobj = nv_gpuobj(object);
+	struct nouveau_ofuncs *pfuncs = nv_ofuncs(gpuobj->parent);
+	if (gpuobj->node)
+		addr += gpuobj->node->offset;
+	pfuncs->wr32(gpuobj->parent, addr, data);
+}
+
+static struct nouveau_oclass
+_nouveau_gpuobj_oclass = {
+	.handle = 0x00000000,
+	.ofuncs = &(struct nouveau_ofuncs) {
+		.ctor = _nouveau_gpuobj_ctor,
+		.dtor = _nouveau_gpuobj_dtor,
+		.init = _nouveau_gpuobj_init,
+		.fini = _nouveau_gpuobj_fini,
+		.rd32 = _nouveau_gpuobj_rd32,
+		.wr32 = _nouveau_gpuobj_wr32,
+	},
+};
+
+int
+nouveau_gpuobj_new(struct nouveau_object *parent, struct nouveau_object *pargpu,
+		   u32 size, u32 align, u32 flags,
+		   struct nouveau_gpuobj **pgpuobj)
+{
+	struct nouveau_object *engine = parent;
+	struct nouveau_gpuobj_class args = {
+		.pargpu = pargpu,
+		.size = size,
+		.align = align,
+		.flags = flags,
+	};
+
+	if (!nv_iclass(engine, NV_SUBDEV_CLASS))
+		engine = &engine->engine->subdev.object;
+	BUG_ON(engine == NULL);
+
+	return nouveau_object_ctor(parent, engine, &_nouveau_gpuobj_oclass,
+				   &args, sizeof(args),
+				   (struct nouveau_object **)pgpuobj);
+}
+
+int
+nouveau_gpuobj_map(struct nouveau_gpuobj *gpuobj, u32 access,
+		   struct nouveau_vma *vma)
+{
+	struct nouveau_bar *bar = nouveau_bar(gpuobj);
+	int ret = -EINVAL;
+
+	if (bar && bar->umap) {
+		struct nouveau_instobj *iobj = (void *)
+			nv_pclass(nv_object(gpuobj), NV_MEMOBJ_CLASS);
+		struct nouveau_mem **mem = (void *)(iobj + 1);
+		ret = bar->umap(bar, *mem, access, vma);
+	}
+
+	return ret;
+}
+
+int
+nouveau_gpuobj_map_vm(struct nouveau_gpuobj *gpuobj, struct nouveau_vm *vm,
+		      u32 access, struct nouveau_vma *vma)
+{
+	struct nouveau_instobj *iobj = (void *)
+		nv_pclass(nv_object(gpuobj), NV_MEMOBJ_CLASS);
+	struct nouveau_mem **mem = (void *)(iobj + 1);
+	int ret;
+
+	ret = nouveau_vm_get(vm, gpuobj->size, 12, access, vma);
+	if (ret)
+		return ret;
+
+	nouveau_vm_map(vma, *mem);
+	return 0;
+}
+
+void
+nouveau_gpuobj_unmap(struct nouveau_vma *vma)
+{
+	if (vma->node) {
+		nouveau_vm_unmap(vma);
+		nouveau_vm_put(vma);
+	}
+}
+
+/* the below is basically only here to support sharing the paged dma object
+ * for PCI(E)GART on <=nv4x chipsets, and should *not* be expected to work
+ * anywhere else.
+ */
+
+static void
+nouveau_gpudup_dtor(struct nouveau_object *object)
+{
+	struct nouveau_gpuobj *gpuobj = (void *)object;
+	nouveau_object_ref(NULL, &gpuobj->parent);
+	nouveau_object_destroy(&gpuobj->object);
+}
+
+static struct nouveau_oclass
+nouveau_gpudup_oclass = {
+	.handle = NV_GPUOBJ_CLASS,
+	.ofuncs = &(struct nouveau_ofuncs) {
+		.dtor = nouveau_gpudup_dtor,
+		.init = nouveau_object_init,
+		.fini = nouveau_object_fini,
+	},
+};
+
+int
+nouveau_gpuobj_dup(struct nouveau_object *parent, struct nouveau_gpuobj *base,
+		   struct nouveau_gpuobj **pgpuobj)
+{
+	struct nouveau_gpuobj *gpuobj;
+	int ret;
+
+	ret = nouveau_object_create(parent, &parent->engine->subdev.object,
+				   &nouveau_gpudup_oclass, 0, &gpuobj);
+	*pgpuobj = gpuobj;
+	if (ret)
+		return ret;
+
+	nouveau_object_ref(nv_object(base), &gpuobj->parent);
+	gpuobj->addr = base->addr;
+	gpuobj->size = base->size;
+	return 0;
+}
