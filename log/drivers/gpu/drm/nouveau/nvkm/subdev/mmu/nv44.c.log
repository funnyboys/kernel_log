commit 632b740c5481988152a3a60319aaa49c99577b77
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:20 2017 +1000

    drm/nouveau/mmu: remove old vmm frontend
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 2fdc4c787b7a..598c53a27bde 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -28,8 +28,6 @@
 
 #include <nvif/class.h>
 
-#define NV44_GART_SIZE (512 * 1024 * 1024)
-
 static void
 nv44_mmu_init(struct nvkm_mmu *mmu)
 {
@@ -57,9 +55,7 @@ nv44_mmu_init(struct nvkm_mmu *mmu)
 static const struct nvkm_mmu_func
 nv44_mmu = {
 	.init = nv44_mmu_init,
-	.limit = NV44_GART_SIZE,
 	.dma_bits = 39,
-	.lpg_shift = 12,
 	.mmu = {{ -1, -1, NVIF_CLASS_MMU_NV04}},
 	.mem = {{ -1, -1, NVIF_CLASS_MEM_NV04}, nv04_mem_new, nv04_mem_map },
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv44_vmm_new, true },

commit eea5cf0f0170fbc54fbb3c501b0ec7cce7f68369
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu: define user interfaces to mmu
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 5f15ec58bbd4..2fdc4c787b7a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -60,6 +60,7 @@ nv44_mmu = {
 	.limit = NV44_GART_SIZE,
 	.dma_bits = 39,
 	.lpg_shift = 12,
+	.mmu = {{ -1, -1, NVIF_CLASS_MMU_NV04}},
 	.mem = {{ -1, -1, NVIF_CLASS_MEM_NV04}, nv04_mem_new, nv04_mem_map },
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv44_vmm_new, true },
 };

commit 957e18a70da19373f966c20dcf3ae5e1d49f9ed0
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv04-nv4x: type-based vram allocation and bar mapping
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 998287021e3f..5f15ec58bbd4 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -21,6 +21,7 @@
  *
  * Authors: Ben Skeggs
  */
+#include "mem.h"
 #include "vmm.h"
 
 #include <core/option.h>
@@ -59,6 +60,7 @@ nv44_mmu = {
 	.limit = NV44_GART_SIZE,
 	.dma_bits = 39,
 	.lpg_shift = 12,
+	.mem = {{ -1, -1, NVIF_CLASS_MEM_NV04}, nv04_mem_new, nv04_mem_map },
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv44_vmm_new, true },
 };
 

commit 26880e76863ace2dd34c14fcadaedf97a2ace417
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu: remove support for old backends
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 2072139bff4d..998287021e3f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -58,8 +58,6 @@ nv44_mmu = {
 	.init = nv44_mmu_init,
 	.limit = NV44_GART_SIZE,
 	.dma_bits = 39,
-	.pgt_bits = 32 - 12,
-	.spg_shift = 12,
 	.lpg_shift = 12,
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv44_vmm_new, true },
 };

commit 6ce513529aa57a8c4f61e588142643a9252037ae
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv44: implement new vmm backend
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 48ca0cdf2acf..2072139bff4d 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -24,150 +24,16 @@
 #include "vmm.h"
 
 #include <core/option.h>
-#include <subdev/timer.h>
 
 #include <nvif/class.h>
 
 #define NV44_GART_SIZE (512 * 1024 * 1024)
-#define NV44_GART_PAGE (  4 * 1024)
-
-/*******************************************************************************
- * VM map/unmap callbacks
- ******************************************************************************/
-
-static void
-nv44_vm_fill(struct nvkm_memory *pgt, dma_addr_t null,
-	     dma_addr_t *list, u32 pte, u32 cnt)
-{
-	u32 base = (pte << 2) & ~0x0000000f;
-	u32 tmp[4];
-
-	tmp[0] = nvkm_ro32(pgt, base + 0x0);
-	tmp[1] = nvkm_ro32(pgt, base + 0x4);
-	tmp[2] = nvkm_ro32(pgt, base + 0x8);
-	tmp[3] = nvkm_ro32(pgt, base + 0xc);
-
-	while (cnt--) {
-		u32 addr = list ? (*list++ >> 12) : (null >> 12);
-		switch (pte++ & 0x3) {
-		case 0:
-			tmp[0] &= ~0x07ffffff;
-			tmp[0] |= addr;
-			break;
-		case 1:
-			tmp[0] &= ~0xf8000000;
-			tmp[0] |= addr << 27;
-			tmp[1] &= ~0x003fffff;
-			tmp[1] |= addr >> 5;
-			break;
-		case 2:
-			tmp[1] &= ~0xffc00000;
-			tmp[1] |= addr << 22;
-			tmp[2] &= ~0x0001ffff;
-			tmp[2] |= addr >> 10;
-			break;
-		case 3:
-			tmp[2] &= ~0xfffe0000;
-			tmp[2] |= addr << 17;
-			tmp[3] &= ~0x00000fff;
-			tmp[3] |= addr >> 15;
-			break;
-		}
-	}
-
-	nvkm_wo32(pgt, base + 0x0, tmp[0]);
-	nvkm_wo32(pgt, base + 0x4, tmp[1]);
-	nvkm_wo32(pgt, base + 0x8, tmp[2]);
-	nvkm_wo32(pgt, base + 0xc, tmp[3] | 0x40000000);
-}
-
-static void
-nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_memory *pgt,
-	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
-{
-	u32 tmp[4];
-	int i;
-
-	nvkm_kmap(pgt);
-	if (pte & 3) {
-		u32  max = 4 - (pte & 3);
-		u32 part = (cnt > max) ? max : cnt;
-		nv44_vm_fill(pgt, vma->vm->null, list, pte, part);
-		pte  += part;
-		list += part;
-		cnt  -= part;
-	}
-
-	while (cnt >= 4) {
-		for (i = 0; i < 4; i++)
-			tmp[i] = *list++ >> 12;
-		nvkm_wo32(pgt, pte++ * 4, tmp[0] >>  0 | tmp[1] << 27);
-		nvkm_wo32(pgt, pte++ * 4, tmp[1] >>  5 | tmp[2] << 22);
-		nvkm_wo32(pgt, pte++ * 4, tmp[2] >> 10 | tmp[3] << 17);
-		nvkm_wo32(pgt, pte++ * 4, tmp[3] >> 15 | 0x40000000);
-		cnt -= 4;
-	}
-
-	if (cnt)
-		nv44_vm_fill(pgt, vma->vm->null, list, pte, cnt);
-	nvkm_done(pgt);
-}
-
-static void
-nv44_vm_unmap(struct nvkm_vma *vma, struct nvkm_memory *pgt, u32 pte, u32 cnt)
-{
-	nvkm_kmap(pgt);
-	if (pte & 3) {
-		u32  max = 4 - (pte & 3);
-		u32 part = (cnt > max) ? max : cnt;
-		nv44_vm_fill(pgt, vma->vm->null, NULL, pte, part);
-		pte  += part;
-		cnt  -= part;
-	}
-
-	while (cnt >= 4) {
-		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
-		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
-		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
-		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
-		cnt -= 4;
-	}
-
-	if (cnt)
-		nv44_vm_fill(pgt, vma->vm->null, NULL, pte, cnt);
-	nvkm_done(pgt);
-}
-
-static void
-nv44_vm_flush(struct nvkm_vm *vm)
-{
-	struct nvkm_device *device = vm->mmu->subdev.device;
-	nvkm_wr32(device, 0x100814, vm->mmu->limit - NV44_GART_PAGE);
-	nvkm_wr32(device, 0x100808, 0x00000020);
-	nvkm_msec(device, 2000,
-		if (nvkm_rd32(device, 0x100808) & 0x00000001)
-			break;
-	);
-	nvkm_wr32(device, 0x100808, 0x00000000);
-}
-
-/*******************************************************************************
- * MMU subdev
- ******************************************************************************/
-
-static int
-nv44_mmu_oneinit(struct nvkm_mmu *mmu)
-{
-	mmu->vmm->pgt[0].mem[0] = mmu->vmm->pd->pt[0]->memory;
-	mmu->vmm->pgt[0].refcount[0] = 1;
-	return 0;
-}
 
 static void
 nv44_mmu_init(struct nvkm_mmu *mmu)
 {
 	struct nvkm_device *device = mmu->subdev.device;
-	struct nvkm_memory *gart = mmu->vmm->pgt[0].mem[0];
+	struct nvkm_memory *pt = mmu->vmm->pd->pt[0]->memory;
 	u32 addr;
 
 	/* calculate vram address of this PRAMIN block, object must be
@@ -175,11 +41,11 @@ nv44_mmu_init(struct nvkm_mmu *mmu)
 	 * of 512KiB for this to work correctly
 	 */
 	addr  = nvkm_rd32(device, 0x10020c);
-	addr -= ((nvkm_memory_addr(gart) >> 19) + 1) << 19;
+	addr -= ((nvkm_memory_addr(pt) >> 19) + 1) << 19;
 
 	nvkm_wr32(device, 0x100850, 0x80000000);
 	nvkm_wr32(device, 0x100818, mmu->vmm->null);
-	nvkm_wr32(device, 0x100804, NV44_GART_SIZE);
+	nvkm_wr32(device, 0x100804, (nvkm_memory_size(pt) / 4) * 4096);
 	nvkm_wr32(device, 0x100850, 0x00008000);
 	nvkm_mask(device, 0x10008c, 0x00000200, 0x00000200);
 	nvkm_wr32(device, 0x100820, 0x00000000);
@@ -189,16 +55,12 @@ nv44_mmu_init(struct nvkm_mmu *mmu)
 
 static const struct nvkm_mmu_func
 nv44_mmu = {
-	.oneinit = nv44_mmu_oneinit,
 	.init = nv44_mmu_init,
 	.limit = NV44_GART_SIZE,
 	.dma_bits = 39,
 	.pgt_bits = 32 - 12,
 	.spg_shift = 12,
 	.lpg_shift = 12,
-	.map_sg = nv44_vm_map_sg,
-	.unmap = nv44_vm_unmap,
-	.flush = nv44_vm_flush,
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv44_vmm_new, true },
 };
 

commit 03b0ba7b545ba0c5b19fedb14a771a3517a1328e
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv44: implement vmm on top of new base
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index cc97500a0901..48ca0cdf2acf 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -21,12 +21,13 @@
  *
  * Authors: Ben Skeggs
  */
-#include "nv04.h"
+#include "vmm.h"
 
-#include <core/gpuobj.h>
 #include <core/option.h>
 #include <subdev/timer.h>
 
+#include <nvif/class.h>
+
 #define NV44_GART_SIZE (512 * 1024 * 1024)
 #define NV44_GART_PAGE (  4 * 1024)
 
@@ -84,7 +85,6 @@ static void
 nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_memory *pgt,
 	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
 {
-	struct nv04_mmu *mmu = nv04_mmu(vma->vm->mmu);
 	u32 tmp[4];
 	int i;
 
@@ -92,7 +92,7 @@ nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_memory *pgt,
 	if (pte & 3) {
 		u32  max = 4 - (pte & 3);
 		u32 part = (cnt > max) ? max : cnt;
-		nv44_vm_fill(pgt, mmu->null, list, pte, part);
+		nv44_vm_fill(pgt, vma->vm->null, list, pte, part);
 		pte  += part;
 		list += part;
 		cnt  -= part;
@@ -109,20 +109,18 @@ nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_memory *pgt,
 	}
 
 	if (cnt)
-		nv44_vm_fill(pgt, mmu->null, list, pte, cnt);
+		nv44_vm_fill(pgt, vma->vm->null, list, pte, cnt);
 	nvkm_done(pgt);
 }
 
 static void
 nv44_vm_unmap(struct nvkm_vma *vma, struct nvkm_memory *pgt, u32 pte, u32 cnt)
 {
-	struct nv04_mmu *mmu = nv04_mmu(vma->vm->mmu);
-
 	nvkm_kmap(pgt);
 	if (pte & 3) {
 		u32  max = 4 - (pte & 3);
 		u32 part = (cnt > max) ? max : cnt;
-		nv44_vm_fill(pgt, mmu->null, NULL, pte, part);
+		nv44_vm_fill(pgt, vma->vm->null, NULL, pte, part);
 		pte  += part;
 		cnt  -= part;
 	}
@@ -136,16 +134,15 @@ nv44_vm_unmap(struct nvkm_vma *vma, struct nvkm_memory *pgt, u32 pte, u32 cnt)
 	}
 
 	if (cnt)
-		nv44_vm_fill(pgt, mmu->null, NULL, pte, cnt);
+		nv44_vm_fill(pgt, vma->vm->null, NULL, pte, cnt);
 	nvkm_done(pgt);
 }
 
 static void
 nv44_vm_flush(struct nvkm_vm *vm)
 {
-	struct nv04_mmu *mmu = nv04_mmu(vm->mmu);
-	struct nvkm_device *device = mmu->base.subdev.device;
-	nvkm_wr32(device, 0x100814, mmu->base.limit - NV44_GART_PAGE);
+	struct nvkm_device *device = vm->mmu->subdev.device;
+	nvkm_wr32(device, 0x100814, vm->mmu->limit - NV44_GART_PAGE);
 	nvkm_wr32(device, 0x100808, 0x00000020);
 	nvkm_msec(device, 2000,
 		if (nvkm_rd32(device, 0x100808) & 0x00000001)
@@ -159,38 +156,18 @@ nv44_vm_flush(struct nvkm_vm *vm)
  ******************************************************************************/
 
 static int
-nv44_mmu_oneinit(struct nvkm_mmu *base)
+nv44_mmu_oneinit(struct nvkm_mmu *mmu)
 {
-	struct nv04_mmu *mmu = nv04_mmu(base);
-	struct nvkm_device *device = mmu->base.subdev.device;
-	int ret;
-
-	mmu->nullp = dma_alloc_coherent(device->dev, 16 * 1024,
-					&mmu->null, GFP_KERNEL);
-	if (!mmu->nullp) {
-		nvkm_warn(&mmu->base.subdev, "unable to allocate dummy pages\n");
-		mmu->null = 0;
-	}
-
-	ret = nvkm_vm_create(&mmu->base, 0, NV44_GART_SIZE, 0, 4096, NULL,
-			     &mmu->base.vmm);
-	if (ret)
-		return ret;
-
-	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-			      (NV44_GART_SIZE / NV44_GART_PAGE) * 4,
-			      512 * 1024, true,
-			      &mmu->base.vmm->pgt[0].mem[0]);
-	mmu->base.vmm->pgt[0].refcount[0] = 1;
-	return ret;
+	mmu->vmm->pgt[0].mem[0] = mmu->vmm->pd->pt[0]->memory;
+	mmu->vmm->pgt[0].refcount[0] = 1;
+	return 0;
 }
 
 static void
-nv44_mmu_init(struct nvkm_mmu *base)
+nv44_mmu_init(struct nvkm_mmu *mmu)
 {
-	struct nv04_mmu *mmu = nv04_mmu(base);
-	struct nvkm_device *device = mmu->base.subdev.device;
-	struct nvkm_memory *gart = mmu->base.vmm->pgt[0].mem[0];
+	struct nvkm_device *device = mmu->subdev.device;
+	struct nvkm_memory *gart = mmu->vmm->pgt[0].mem[0];
 	u32 addr;
 
 	/* calculate vram address of this PRAMIN block, object must be
@@ -201,7 +178,7 @@ nv44_mmu_init(struct nvkm_mmu *base)
 	addr -= ((nvkm_memory_addr(gart) >> 19) + 1) << 19;
 
 	nvkm_wr32(device, 0x100850, 0x80000000);
-	nvkm_wr32(device, 0x100818, mmu->null);
+	nvkm_wr32(device, 0x100818, mmu->vmm->null);
 	nvkm_wr32(device, 0x100804, NV44_GART_SIZE);
 	nvkm_wr32(device, 0x100850, 0x00008000);
 	nvkm_mask(device, 0x10008c, 0x00000200, 0x00000200);
@@ -212,7 +189,6 @@ nv44_mmu_init(struct nvkm_mmu *base)
 
 static const struct nvkm_mmu_func
 nv44_mmu = {
-	.dtor = nv04_mmu_dtor,
 	.oneinit = nv44_mmu_oneinit,
 	.init = nv44_mmu_init,
 	.limit = NV44_GART_SIZE,
@@ -223,6 +199,7 @@ nv44_mmu = {
 	.map_sg = nv44_vm_map_sg,
 	.unmap = nv44_vm_unmap,
 	.flush = nv44_vm_flush,
+	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv44_vmm_new, true },
 };
 
 int
@@ -232,5 +209,5 @@ nv44_mmu_new(struct nvkm_device *device, int index, struct nvkm_mmu **pmmu)
 	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true))
 		return nv04_mmu_new(device, index, pmmu);
 
-	return nv04_mmu_new_(&nv44_mmu, device, index, pmmu);
+	return nvkm_mmu_new_(&nv44_mmu, device, index, pmmu);
 }

commit 0b11b30de9d2960d87373e50223800c8f9f6a89f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv04-nv4x: move global vmm to nvkm_mmu
    
    In a future commit, this will be constructed by common code.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index a648c2395545..cc97500a0901 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -173,15 +173,15 @@ nv44_mmu_oneinit(struct nvkm_mmu *base)
 	}
 
 	ret = nvkm_vm_create(&mmu->base, 0, NV44_GART_SIZE, 0, 4096, NULL,
-			     &mmu->vm);
+			     &mmu->base.vmm);
 	if (ret)
 		return ret;
 
 	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 			      (NV44_GART_SIZE / NV44_GART_PAGE) * 4,
 			      512 * 1024, true,
-			      &mmu->vm->pgt[0].mem[0]);
-	mmu->vm->pgt[0].refcount[0] = 1;
+			      &mmu->base.vmm->pgt[0].mem[0]);
+	mmu->base.vmm->pgt[0].refcount[0] = 1;
 	return ret;
 }
 
@@ -190,7 +190,7 @@ nv44_mmu_init(struct nvkm_mmu *base)
 {
 	struct nv04_mmu *mmu = nv04_mmu(base);
 	struct nvkm_device *device = mmu->base.subdev.device;
-	struct nvkm_memory *gart = mmu->vm->pgt[0].mem[0];
+	struct nvkm_memory *gart = mmu->base.vmm->pgt[0].mem[0];
 	u32 addr;
 
 	/* calculate vram address of this PRAMIN block, object must be

commit 26c9e8effebb9166eb1cfba2d164676e98c505c7
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:23 2015 +1000

    drm/nouveau/device: remove pci/platform_device from common struct
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 7c37bd84b862..a648c2395545 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -165,7 +165,8 @@ nv44_mmu_oneinit(struct nvkm_mmu *base)
 	struct nvkm_device *device = mmu->base.subdev.device;
 	int ret;
 
-	mmu->nullp = pci_alloc_consistent(device->pdev, 16 * 1024, &mmu->null);
+	mmu->nullp = dma_alloc_coherent(device->dev, 16 * 1024,
+					&mmu->null, GFP_KERNEL);
 	if (!mmu->nullp) {
 		nvkm_warn(&mmu->base.subdev, "unable to allocate dummy pages\n");
 		mmu->null = 0;
@@ -227,7 +228,7 @@ nv44_mmu = {
 int
 nv44_mmu_new(struct nvkm_device *device, int index, struct nvkm_mmu **pmmu)
 {
-	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
+	if (device->type == NVKM_DEVICE_AGP ||
 	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true))
 		return nv04_mmu_new(device, index, pmmu);
 

commit c9582455ab74246ec9f5986db3821b33058de585
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:21 2015 +1000

    drm/nouveau/mmu: convert to new-style nvkm_subdev
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index d2b586bc57a2..7c37bd84b862 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -159,36 +159,12 @@ nv44_vm_flush(struct nvkm_vm *vm)
  ******************************************************************************/
 
 static int
-nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-	      struct nvkm_oclass *oclass, void *data, u32 size,
-	      struct nvkm_object **pobject)
+nv44_mmu_oneinit(struct nvkm_mmu *base)
 {
-	struct nvkm_device *device = nv_device(parent);
-	struct nv04_mmu *mmu;
+	struct nv04_mmu *mmu = nv04_mmu(base);
+	struct nvkm_device *device = mmu->base.subdev.device;
 	int ret;
 
-	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
-	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true)) {
-		return nvkm_object_old(parent, engine, &nv04_mmu_oclass,
-					data, size, pobject);
-	}
-
-	ret = nvkm_mmu_create(parent, engine, oclass, "PCIEGART",
-			      "mmu", &mmu);
-	*pobject = nv_object(mmu);
-	if (ret)
-		return ret;
-
-	mmu->base.create = nv04_vm_create;
-	mmu->base.limit = NV44_GART_SIZE;
-	mmu->base.dma_bits = 39;
-	mmu->base.pgt_bits = 32 - 12;
-	mmu->base.spg_shift = 12;
-	mmu->base.lpg_shift = 12;
-	mmu->base.map_sg = nv44_vm_map_sg;
-	mmu->base.unmap = nv44_vm_unmap;
-	mmu->base.flush = nv44_vm_flush;
-
 	mmu->nullp = pci_alloc_consistent(device->pdev, 16 * 1024, &mmu->null);
 	if (!mmu->nullp) {
 		nvkm_warn(&mmu->base.subdev, "unable to allocate dummy pages\n");
@@ -205,24 +181,16 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 			      512 * 1024, true,
 			      &mmu->vm->pgt[0].mem[0]);
 	mmu->vm->pgt[0].refcount[0] = 1;
-	if (ret)
-		return ret;
-
-	return 0;
+	return ret;
 }
 
-static int
-nv44_mmu_init(struct nvkm_object *object)
+static void
+nv44_mmu_init(struct nvkm_mmu *base)
 {
-	struct nv04_mmu *mmu = (void *)object;
+	struct nv04_mmu *mmu = nv04_mmu(base);
 	struct nvkm_device *device = mmu->base.subdev.device;
 	struct nvkm_memory *gart = mmu->vm->pgt[0].mem[0];
 	u32 addr;
-	int ret;
-
-	ret = nvkm_mmu_init(&mmu->base);
-	if (ret)
-		return ret;
 
 	/* calculate vram address of this PRAMIN block, object must be
 	 * allocated on 512KiB alignment, and not exceed a total size
@@ -239,16 +207,29 @@ nv44_mmu_init(struct nvkm_object *object)
 	nvkm_wr32(device, 0x100820, 0x00000000);
 	nvkm_wr32(device, 0x10082c, 0x00000001);
 	nvkm_wr32(device, 0x100800, addr | 0x00000010);
-	return 0;
 }
 
-struct nvkm_oclass
-nv44_mmu_oclass = {
-	.handle = NV_SUBDEV(MMU, 0x44),
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = nv44_mmu_ctor,
-		.dtor = nv04_mmu_dtor,
-		.init = nv44_mmu_init,
-		.fini = _nvkm_mmu_fini,
-	},
+static const struct nvkm_mmu_func
+nv44_mmu = {
+	.dtor = nv04_mmu_dtor,
+	.oneinit = nv44_mmu_oneinit,
+	.init = nv44_mmu_init,
+	.limit = NV44_GART_SIZE,
+	.dma_bits = 39,
+	.pgt_bits = 32 - 12,
+	.spg_shift = 12,
+	.lpg_shift = 12,
+	.map_sg = nv44_vm_map_sg,
+	.unmap = nv44_vm_unmap,
+	.flush = nv44_vm_flush,
 };
+
+int
+nv44_mmu_new(struct nvkm_device *device, int index, struct nvkm_mmu **pmmu)
+{
+	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
+	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true))
+		return nv04_mmu_new(device, index, pmmu);
+
+	return nv04_mmu_new_(&nv44_mmu, device, index, pmmu);
+}

commit d0659d3277cd7bf50e45d48f4692a7fbb11e5957
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/mmu: directly use instmem for page tables
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index ef53dfa356bb..d2b586bc57a2 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -35,7 +35,7 @@
  ******************************************************************************/
 
 static void
-nv44_vm_fill(struct nvkm_gpuobj *pgt, dma_addr_t null,
+nv44_vm_fill(struct nvkm_memory *pgt, dma_addr_t null,
 	     dma_addr_t *list, u32 pte, u32 cnt)
 {
 	u32 base = (pte << 2) & ~0x0000000f;
@@ -81,10 +81,10 @@ nv44_vm_fill(struct nvkm_gpuobj *pgt, dma_addr_t null,
 }
 
 static void
-nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
+nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_memory *pgt,
 	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
 {
-	struct nv04_mmu *mmu = (void *)vma->vm->mmu;
+	struct nv04_mmu *mmu = nv04_mmu(vma->vm->mmu);
 	u32 tmp[4];
 	int i;
 
@@ -114,9 +114,9 @@ nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
 }
 
 static void
-nv44_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
+nv44_vm_unmap(struct nvkm_vma *vma, struct nvkm_memory *pgt, u32 pte, u32 cnt)
 {
-	struct nv04_mmu *mmu = (void *)nvkm_mmu(pgt);
+	struct nv04_mmu *mmu = nv04_mmu(vma->vm->mmu);
 
 	nvkm_kmap(pgt);
 	if (pte & 3) {
@@ -143,7 +143,7 @@ nv44_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 static void
 nv44_vm_flush(struct nvkm_vm *vm)
 {
-	struct nv04_mmu *mmu = (void *)vm->mmu;
+	struct nv04_mmu *mmu = nv04_mmu(vm->mmu);
 	struct nvkm_device *device = mmu->base.subdev.device;
 	nvkm_wr32(device, 0x100814, mmu->base.limit - NV44_GART_PAGE);
 	nvkm_wr32(device, 0x100808, 0x00000020);
@@ -200,10 +200,10 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(mmu), NULL,
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 			      (NV44_GART_SIZE / NV44_GART_PAGE) * 4,
-			      512 * 1024, NVOBJ_FLAG_ZERO_ALLOC,
-			      &mmu->vm->pgt[0].obj[0]);
+			      512 * 1024, true,
+			      &mmu->vm->pgt[0].mem[0]);
 	mmu->vm->pgt[0].refcount[0] = 1;
 	if (ret)
 		return ret;
@@ -216,7 +216,7 @@ nv44_mmu_init(struct nvkm_object *object)
 {
 	struct nv04_mmu *mmu = (void *)object;
 	struct nvkm_device *device = mmu->base.subdev.device;
-	struct nvkm_gpuobj *gart = mmu->vm->pgt[0].obj[0];
+	struct nvkm_memory *gart = mmu->vm->pgt[0].mem[0];
 	u32 addr;
 	int ret;
 
@@ -229,7 +229,7 @@ nv44_mmu_init(struct nvkm_object *object)
 	 * of 512KiB for this to work correctly
 	 */
 	addr  = nvkm_rd32(device, 0x10020c);
-	addr -= ((gart->addr >> 19) + 1) << 19;
+	addr -= ((nvkm_memory_addr(gart) >> 19) + 1) << 19;
 
 	nvkm_wr32(device, 0x100850, 0x80000000);
 	nvkm_wr32(device, 0x100818, mmu->null);

commit 1de68568d69ac518db076cc6118af91e930b5f90
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/mmu: protect each vm with its own mutex
    
    An upcoming commit requires being able to modify the PRAMIN BAR page
    tables while already holding the MMU subdev mutex.
    
    To solve this issue, each VM has been given its own mutex.  As a nice
    side-effect, this also allows separate VMs to be updated concurrently.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 3e51dc772536..ef53dfa356bb 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -195,7 +195,7 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 		mmu->null = 0;
 	}
 
-	ret = nvkm_vm_create(&mmu->base, 0, NV44_GART_SIZE, 0, 4096,
+	ret = nvkm_vm_create(&mmu->base, 0, NV44_GART_SIZE, 0, 4096, NULL,
 			     &mmu->vm);
 	if (ret)
 		return ret;

commit aa35888ff024b18c7b6b29eb773a221f642987f7
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/object: rename some functions to avoid upcoming conflicts
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 3be8a796d797..3e51dc772536 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -169,7 +169,7 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
 	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true)) {
-		return nvkm_object_ctor(parent, engine, &nv04_mmu_oclass,
+		return nvkm_object_old(parent, engine, &nv04_mmu_oclass,
 					data, size, pobject);
 	}
 

commit cd821077aa7f180f83f3a5d60ec47cb75d56fd37
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:14 2015 +1000

    drm/nouveau/mmu: switch to gpuobj accessor macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 76e1a657dfc9..3be8a796d797 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -41,10 +41,10 @@ nv44_vm_fill(struct nvkm_gpuobj *pgt, dma_addr_t null,
 	u32 base = (pte << 2) & ~0x0000000f;
 	u32 tmp[4];
 
-	tmp[0] = nv_ro32(pgt, base + 0x0);
-	tmp[1] = nv_ro32(pgt, base + 0x4);
-	tmp[2] = nv_ro32(pgt, base + 0x8);
-	tmp[3] = nv_ro32(pgt, base + 0xc);
+	tmp[0] = nvkm_ro32(pgt, base + 0x0);
+	tmp[1] = nvkm_ro32(pgt, base + 0x4);
+	tmp[2] = nvkm_ro32(pgt, base + 0x8);
+	tmp[3] = nvkm_ro32(pgt, base + 0xc);
 
 	while (cnt--) {
 		u32 addr = list ? (*list++ >> 12) : (null >> 12);
@@ -74,10 +74,10 @@ nv44_vm_fill(struct nvkm_gpuobj *pgt, dma_addr_t null,
 		}
 	}
 
-	nv_wo32(pgt, base + 0x0, tmp[0]);
-	nv_wo32(pgt, base + 0x4, tmp[1]);
-	nv_wo32(pgt, base + 0x8, tmp[2]);
-	nv_wo32(pgt, base + 0xc, tmp[3] | 0x40000000);
+	nvkm_wo32(pgt, base + 0x0, tmp[0]);
+	nvkm_wo32(pgt, base + 0x4, tmp[1]);
+	nvkm_wo32(pgt, base + 0x8, tmp[2]);
+	nvkm_wo32(pgt, base + 0xc, tmp[3] | 0x40000000);
 }
 
 static void
@@ -88,6 +88,7 @@ nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
 	u32 tmp[4];
 	int i;
 
+	nvkm_kmap(pgt);
 	if (pte & 3) {
 		u32  max = 4 - (pte & 3);
 		u32 part = (cnt > max) ? max : cnt;
@@ -100,15 +101,16 @@ nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
 	while (cnt >= 4) {
 		for (i = 0; i < 4; i++)
 			tmp[i] = *list++ >> 12;
-		nv_wo32(pgt, pte++ * 4, tmp[0] >>  0 | tmp[1] << 27);
-		nv_wo32(pgt, pte++ * 4, tmp[1] >>  5 | tmp[2] << 22);
-		nv_wo32(pgt, pte++ * 4, tmp[2] >> 10 | tmp[3] << 17);
-		nv_wo32(pgt, pte++ * 4, tmp[3] >> 15 | 0x40000000);
+		nvkm_wo32(pgt, pte++ * 4, tmp[0] >>  0 | tmp[1] << 27);
+		nvkm_wo32(pgt, pte++ * 4, tmp[1] >>  5 | tmp[2] << 22);
+		nvkm_wo32(pgt, pte++ * 4, tmp[2] >> 10 | tmp[3] << 17);
+		nvkm_wo32(pgt, pte++ * 4, tmp[3] >> 15 | 0x40000000);
 		cnt -= 4;
 	}
 
 	if (cnt)
 		nv44_vm_fill(pgt, mmu->null, list, pte, cnt);
+	nvkm_done(pgt);
 }
 
 static void
@@ -116,6 +118,7 @@ nv44_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 {
 	struct nv04_mmu *mmu = (void *)nvkm_mmu(pgt);
 
+	nvkm_kmap(pgt);
 	if (pte & 3) {
 		u32  max = 4 - (pte & 3);
 		u32 part = (cnt > max) ? max : cnt;
@@ -125,15 +128,16 @@ nv44_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 	}
 
 	while (cnt >= 4) {
-		nv_wo32(pgt, pte++ * 4, 0x00000000);
-		nv_wo32(pgt, pte++ * 4, 0x00000000);
-		nv_wo32(pgt, pte++ * 4, 0x00000000);
-		nv_wo32(pgt, pte++ * 4, 0x00000000);
+		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
+		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
+		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
+		nvkm_wo32(pgt, pte++ * 4, 0x00000000);
 		cnt -= 4;
 	}
 
 	if (cnt)
 		nv44_vm_fill(pgt, mmu->null, NULL, pte, cnt);
+	nvkm_done(pgt);
 }
 
 static void

commit 85ae830f5ac177244892b934953106d11cd5a679
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:12 2015 +1000

    drm/nouveau/mmu: switch to subdev printk macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 64203abaaee7..76e1a657dfc9 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -187,7 +187,7 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	mmu->nullp = pci_alloc_consistent(device->pdev, 16 * 1024, &mmu->null);
 	if (!mmu->nullp) {
-		nv_warn(mmu, "unable to allocate dummy pages\n");
+		nvkm_warn(&mmu->base.subdev, "unable to allocate dummy pages\n");
 		mmu->null = 0;
 	}
 

commit 909604d444eb26ed37860268cfc6a68d4a5f28cb
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:11 2015 +1000

    drm/nouveau/mmu: switch to new-style timer macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 371f627e17db..64203abaaee7 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -143,8 +143,10 @@ nv44_vm_flush(struct nvkm_vm *vm)
 	struct nvkm_device *device = mmu->base.subdev.device;
 	nvkm_wr32(device, 0x100814, mmu->base.limit - NV44_GART_PAGE);
 	nvkm_wr32(device, 0x100808, 0x00000020);
-	if (!nv_wait(mmu, 0x100808, 0x00000001, 0x00000001))
-		nv_error(mmu, "timeout: 0x%08x\n", nvkm_rd32(device, 0x100808));
+	nvkm_msec(device, 2000,
+		if (nvkm_rd32(device, 0x100808) & 0x00000001)
+			break;
+	);
 	nvkm_wr32(device, 0x100808, 0x00000000);
 }
 

commit 83f56106ead017a07868176279746d73bc7a7060
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:09 2015 +1000

    drm/nouveau/mmu: switch to device pri macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 860654fee387..371f627e17db 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -140,11 +140,12 @@ static void
 nv44_vm_flush(struct nvkm_vm *vm)
 {
 	struct nv04_mmu *mmu = (void *)vm->mmu;
-	nv_wr32(mmu, 0x100814, mmu->base.limit - NV44_GART_PAGE);
-	nv_wr32(mmu, 0x100808, 0x00000020);
+	struct nvkm_device *device = mmu->base.subdev.device;
+	nvkm_wr32(device, 0x100814, mmu->base.limit - NV44_GART_PAGE);
+	nvkm_wr32(device, 0x100808, 0x00000020);
 	if (!nv_wait(mmu, 0x100808, 0x00000001, 0x00000001))
-		nv_error(mmu, "timeout: 0x%08x\n", nv_rd32(mmu, 0x100808));
-	nv_wr32(mmu, 0x100808, 0x00000000);
+		nv_error(mmu, "timeout: 0x%08x\n", nvkm_rd32(device, 0x100808));
+	nvkm_wr32(device, 0x100808, 0x00000000);
 }
 
 /*******************************************************************************
@@ -208,6 +209,7 @@ static int
 nv44_mmu_init(struct nvkm_object *object)
 {
 	struct nv04_mmu *mmu = (void *)object;
+	struct nvkm_device *device = mmu->base.subdev.device;
 	struct nvkm_gpuobj *gart = mmu->vm->pgt[0].obj[0];
 	u32 addr;
 	int ret;
@@ -220,17 +222,17 @@ nv44_mmu_init(struct nvkm_object *object)
 	 * allocated on 512KiB alignment, and not exceed a total size
 	 * of 512KiB for this to work correctly
 	 */
-	addr  = nv_rd32(mmu, 0x10020c);
+	addr  = nvkm_rd32(device, 0x10020c);
 	addr -= ((gart->addr >> 19) + 1) << 19;
 
-	nv_wr32(mmu, 0x100850, 0x80000000);
-	nv_wr32(mmu, 0x100818, mmu->null);
-	nv_wr32(mmu, 0x100804, NV44_GART_SIZE);
-	nv_wr32(mmu, 0x100850, 0x00008000);
-	nv_mask(mmu, 0x10008c, 0x00000200, 0x00000200);
-	nv_wr32(mmu, 0x100820, 0x00000000);
-	nv_wr32(mmu, 0x10082c, 0x00000001);
-	nv_wr32(mmu, 0x100800, addr | 0x00000010);
+	nvkm_wr32(device, 0x100850, 0x80000000);
+	nvkm_wr32(device, 0x100818, mmu->null);
+	nvkm_wr32(device, 0x100804, NV44_GART_SIZE);
+	nvkm_wr32(device, 0x100850, 0x00008000);
+	nvkm_mask(device, 0x10008c, 0x00000200, 0x00000200);
+	nvkm_wr32(device, 0x100820, 0x00000000);
+	nvkm_wr32(device, 0x10082c, 0x00000001);
+	nvkm_wr32(device, 0x100800, addr | 0x00000010);
 	return 0;
 }
 

commit 1f5bffca226929a834c7d631464d420e78cbe5f1
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:07 2015 +1000

    drm/nouveau/mmu: cosmetic changes
    
    This is purely preparation for upcoming commits, there should be no
    code changes here.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index 87824693f9cc..860654fee387 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -84,14 +84,14 @@ static void
 nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
 	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
 {
-	struct nv04_mmu_priv *priv = (void *)vma->vm->mmu;
+	struct nv04_mmu *mmu = (void *)vma->vm->mmu;
 	u32 tmp[4];
 	int i;
 
 	if (pte & 3) {
 		u32  max = 4 - (pte & 3);
 		u32 part = (cnt > max) ? max : cnt;
-		nv44_vm_fill(pgt, priv->null, list, pte, part);
+		nv44_vm_fill(pgt, mmu->null, list, pte, part);
 		pte  += part;
 		list += part;
 		cnt  -= part;
@@ -108,18 +108,18 @@ nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
 	}
 
 	if (cnt)
-		nv44_vm_fill(pgt, priv->null, list, pte, cnt);
+		nv44_vm_fill(pgt, mmu->null, list, pte, cnt);
 }
 
 static void
 nv44_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 {
-	struct nv04_mmu_priv *priv = (void *)nvkm_mmu(pgt);
+	struct nv04_mmu *mmu = (void *)nvkm_mmu(pgt);
 
 	if (pte & 3) {
 		u32  max = 4 - (pte & 3);
 		u32 part = (cnt > max) ? max : cnt;
-		nv44_vm_fill(pgt, priv->null, NULL, pte, part);
+		nv44_vm_fill(pgt, mmu->null, NULL, pte, part);
 		pte  += part;
 		cnt  -= part;
 	}
@@ -133,18 +133,18 @@ nv44_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 	}
 
 	if (cnt)
-		nv44_vm_fill(pgt, priv->null, NULL, pte, cnt);
+		nv44_vm_fill(pgt, mmu->null, NULL, pte, cnt);
 }
 
 static void
 nv44_vm_flush(struct nvkm_vm *vm)
 {
-	struct nv04_mmu_priv *priv = (void *)vm->mmu;
-	nv_wr32(priv, 0x100814, priv->base.limit - NV44_GART_PAGE);
-	nv_wr32(priv, 0x100808, 0x00000020);
-	if (!nv_wait(priv, 0x100808, 0x00000001, 0x00000001))
-		nv_error(priv, "timeout: 0x%08x\n", nv_rd32(priv, 0x100808));
-	nv_wr32(priv, 0x100808, 0x00000000);
+	struct nv04_mmu *mmu = (void *)vm->mmu;
+	nv_wr32(mmu, 0x100814, mmu->base.limit - NV44_GART_PAGE);
+	nv_wr32(mmu, 0x100808, 0x00000020);
+	if (!nv_wait(mmu, 0x100808, 0x00000001, 0x00000001))
+		nv_error(mmu, "timeout: 0x%08x\n", nv_rd32(mmu, 0x100808));
+	nv_wr32(mmu, 0x100808, 0x00000000);
 }
 
 /*******************************************************************************
@@ -157,7 +157,7 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	      struct nvkm_object **pobject)
 {
 	struct nvkm_device *device = nv_device(parent);
-	struct nv04_mmu_priv *priv;
+	struct nv04_mmu *mmu;
 	int ret;
 
 	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
@@ -167,37 +167,37 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	}
 
 	ret = nvkm_mmu_create(parent, engine, oclass, "PCIEGART",
-			      "pciegart", &priv);
-	*pobject = nv_object(priv);
+			      "mmu", &mmu);
+	*pobject = nv_object(mmu);
 	if (ret)
 		return ret;
 
-	priv->base.create = nv04_vm_create;
-	priv->base.limit = NV44_GART_SIZE;
-	priv->base.dma_bits = 39;
-	priv->base.pgt_bits = 32 - 12;
-	priv->base.spg_shift = 12;
-	priv->base.lpg_shift = 12;
-	priv->base.map_sg = nv44_vm_map_sg;
-	priv->base.unmap = nv44_vm_unmap;
-	priv->base.flush = nv44_vm_flush;
-
-	priv->nullp = pci_alloc_consistent(device->pdev, 16 * 1024, &priv->null);
-	if (!priv->nullp) {
-		nv_error(priv, "unable to allocate dummy pages\n");
-		return -ENOMEM;
+	mmu->base.create = nv04_vm_create;
+	mmu->base.limit = NV44_GART_SIZE;
+	mmu->base.dma_bits = 39;
+	mmu->base.pgt_bits = 32 - 12;
+	mmu->base.spg_shift = 12;
+	mmu->base.lpg_shift = 12;
+	mmu->base.map_sg = nv44_vm_map_sg;
+	mmu->base.unmap = nv44_vm_unmap;
+	mmu->base.flush = nv44_vm_flush;
+
+	mmu->nullp = pci_alloc_consistent(device->pdev, 16 * 1024, &mmu->null);
+	if (!mmu->nullp) {
+		nv_warn(mmu, "unable to allocate dummy pages\n");
+		mmu->null = 0;
 	}
 
-	ret = nvkm_vm_create(&priv->base, 0, NV44_GART_SIZE, 0, 4096,
-			     &priv->vm);
+	ret = nvkm_vm_create(&mmu->base, 0, NV44_GART_SIZE, 0, 4096,
+			     &mmu->vm);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(priv), NULL,
+	ret = nvkm_gpuobj_new(nv_object(mmu), NULL,
 			      (NV44_GART_SIZE / NV44_GART_PAGE) * 4,
 			      512 * 1024, NVOBJ_FLAG_ZERO_ALLOC,
-			      &priv->vm->pgt[0].obj[0]);
-	priv->vm->pgt[0].refcount[0] = 1;
+			      &mmu->vm->pgt[0].obj[0]);
+	mmu->vm->pgt[0].refcount[0] = 1;
 	if (ret)
 		return ret;
 
@@ -207,12 +207,12 @@ nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 static int
 nv44_mmu_init(struct nvkm_object *object)
 {
-	struct nv04_mmu_priv *priv = (void *)object;
-	struct nvkm_gpuobj *gart = priv->vm->pgt[0].obj[0];
+	struct nv04_mmu *mmu = (void *)object;
+	struct nvkm_gpuobj *gart = mmu->vm->pgt[0].obj[0];
 	u32 addr;
 	int ret;
 
-	ret = nvkm_mmu_init(&priv->base);
+	ret = nvkm_mmu_init(&mmu->base);
 	if (ret)
 		return ret;
 
@@ -220,17 +220,17 @@ nv44_mmu_init(struct nvkm_object *object)
 	 * allocated on 512KiB alignment, and not exceed a total size
 	 * of 512KiB for this to work correctly
 	 */
-	addr  = nv_rd32(priv, 0x10020c);
+	addr  = nv_rd32(mmu, 0x10020c);
 	addr -= ((gart->addr >> 19) + 1) << 19;
 
-	nv_wr32(priv, 0x100850, 0x80000000);
-	nv_wr32(priv, 0x100818, priv->null);
-	nv_wr32(priv, 0x100804, NV44_GART_SIZE);
-	nv_wr32(priv, 0x100850, 0x00008000);
-	nv_mask(priv, 0x10008c, 0x00000200, 0x00000200);
-	nv_wr32(priv, 0x100820, 0x00000000);
-	nv_wr32(priv, 0x10082c, 0x00000001);
-	nv_wr32(priv, 0x100800, addr | 0x00000010);
+	nv_wr32(mmu, 0x100850, 0x80000000);
+	nv_wr32(mmu, 0x100818, mmu->null);
+	nv_wr32(mmu, 0x100804, NV44_GART_SIZE);
+	nv_wr32(mmu, 0x100850, 0x00008000);
+	nv_mask(mmu, 0x10008c, 0x00000200, 0x00000200);
+	nv_wr32(mmu, 0x100820, 0x00000000);
+	nv_wr32(mmu, 0x10082c, 0x00000001);
+	nv_wr32(mmu, 0x100800, addr | 0x00000010);
 	return 0;
 }
 

commit 9ace404b1098221021b01c2ba0eeea0c257fa4a5
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:06 2015 +1000

    drm/nouveau/device: include core/device.h automatically for subdevs/engines
    
    Pretty much every subdev/engine is going to need access to nvkm_device
    shortly to touch registers and/or output messages.
    
    The odd placement of the includes is necessary to work around some
    inter-dependencies that currently exist.  This will be fixed later.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index b90ded1887aa..87824693f9cc 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -23,7 +23,6 @@
  */
 #include "nv04.h"
 
-#include <core/device.h>
 #include <core/gpuobj.h>
 #include <core/option.h>
 #include <subdev/timer.h>

commit 42594600095f03244a674fecdd2b5f6da2441180
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 15:09:19 2015 +1000

    drm/nouveau/mmu: namespace + nvidia gpu names (no binary change)
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
index f5319e3e7fe5..b90ded1887aa 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -21,14 +21,12 @@
  *
  * Authors: Ben Skeggs
  */
+#include "nv04.h"
 
+#include <core/device.h>
 #include <core/gpuobj.h>
 #include <core/option.h>
-
 #include <subdev/timer.h>
-#include <subdev/mmu.h>
-
-#include "nv04.h"
 
 #define NV44_GART_SIZE (512 * 1024 * 1024)
 #define NV44_GART_PAGE (  4 * 1024)
@@ -38,7 +36,7 @@
  ******************************************************************************/
 
 static void
-nv44_vm_fill(struct nouveau_gpuobj *pgt, dma_addr_t null,
+nv44_vm_fill(struct nvkm_gpuobj *pgt, dma_addr_t null,
 	     dma_addr_t *list, u32 pte, u32 cnt)
 {
 	u32 base = (pte << 2) & ~0x0000000f;
@@ -84,8 +82,8 @@ nv44_vm_fill(struct nouveau_gpuobj *pgt, dma_addr_t null,
 }
 
 static void
-nv44_vm_map_sg(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,
-	       struct nouveau_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
+nv44_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
+	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
 {
 	struct nv04_mmu_priv *priv = (void *)vma->vm->mmu;
 	u32 tmp[4];
@@ -115,9 +113,9 @@ nv44_vm_map_sg(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,
 }
 
 static void
-nv44_vm_unmap(struct nouveau_gpuobj *pgt, u32 pte, u32 cnt)
+nv44_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 {
-	struct nv04_mmu_priv *priv = (void *)nouveau_mmu(pgt);
+	struct nv04_mmu_priv *priv = (void *)nvkm_mmu(pgt);
 
 	if (pte & 3) {
 		u32  max = 4 - (pte & 3);
@@ -140,7 +138,7 @@ nv44_vm_unmap(struct nouveau_gpuobj *pgt, u32 pte, u32 cnt)
 }
 
 static void
-nv44_vm_flush(struct nouveau_vm *vm)
+nv44_vm_flush(struct nvkm_vm *vm)
 {
 	struct nv04_mmu_priv *priv = (void *)vm->mmu;
 	nv_wr32(priv, 0x100814, priv->base.limit - NV44_GART_PAGE);
@@ -155,22 +153,22 @@ nv44_vm_flush(struct nouveau_vm *vm)
  ******************************************************************************/
 
 static int
-nv44_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-		struct nouveau_oclass *oclass, void *data, u32 size,
-		struct nouveau_object **pobject)
+nv44_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+	      struct nvkm_oclass *oclass, void *data, u32 size,
+	      struct nvkm_object **pobject)
 {
-	struct nouveau_device *device = nv_device(parent);
+	struct nvkm_device *device = nv_device(parent);
 	struct nv04_mmu_priv *priv;
 	int ret;
 
 	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
-	    !nouveau_boolopt(device->cfgopt, "NvPCIE", true)) {
-		return nouveau_object_ctor(parent, engine, &nv04_mmu_oclass,
-					   data, size, pobject);
+	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true)) {
+		return nvkm_object_ctor(parent, engine, &nv04_mmu_oclass,
+					data, size, pobject);
 	}
 
-	ret = nouveau_mmu_create(parent, engine, oclass, "PCIEGART",
-				   "pciegart", &priv);
+	ret = nvkm_mmu_create(parent, engine, oclass, "PCIEGART",
+			      "pciegart", &priv);
 	*pobject = nv_object(priv);
 	if (ret)
 		return ret;
@@ -191,15 +189,15 @@ nv44_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
 		return -ENOMEM;
 	}
 
-	ret = nouveau_vm_create(&priv->base, 0, NV44_GART_SIZE, 0, 4096,
-				&priv->vm);
+	ret = nvkm_vm_create(&priv->base, 0, NV44_GART_SIZE, 0, 4096,
+			     &priv->vm);
 	if (ret)
 		return ret;
 
-	ret = nouveau_gpuobj_new(nv_object(priv), NULL,
-				(NV44_GART_SIZE / NV44_GART_PAGE) * 4,
-				 512 * 1024, NVOBJ_FLAG_ZERO_ALLOC,
-				 &priv->vm->pgt[0].obj[0]);
+	ret = nvkm_gpuobj_new(nv_object(priv), NULL,
+			      (NV44_GART_SIZE / NV44_GART_PAGE) * 4,
+			      512 * 1024, NVOBJ_FLAG_ZERO_ALLOC,
+			      &priv->vm->pgt[0].obj[0]);
 	priv->vm->pgt[0].refcount[0] = 1;
 	if (ret)
 		return ret;
@@ -208,14 +206,14 @@ nv44_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
 }
 
 static int
-nv44_mmu_init(struct nouveau_object *object)
+nv44_mmu_init(struct nvkm_object *object)
 {
 	struct nv04_mmu_priv *priv = (void *)object;
-	struct nouveau_gpuobj *gart = priv->vm->pgt[0].obj[0];
+	struct nvkm_gpuobj *gart = priv->vm->pgt[0].obj[0];
 	u32 addr;
 	int ret;
 
-	ret = nouveau_mmu_init(&priv->base);
+	ret = nvkm_mmu_init(&priv->base);
 	if (ret)
 		return ret;
 
@@ -237,13 +235,13 @@ nv44_mmu_init(struct nouveau_object *object)
 	return 0;
 }
 
-struct nouveau_oclass
+struct nvkm_oclass
 nv44_mmu_oclass = {
 	.handle = NV_SUBDEV(MMU, 0x44),
-	.ofuncs = &(struct nouveau_ofuncs) {
+	.ofuncs = &(struct nvkm_ofuncs) {
 		.ctor = nv44_mmu_ctor,
 		.dtor = nv04_mmu_dtor,
 		.init = nv44_mmu_init,
-		.fini = _nouveau_mmu_fini,
+		.fini = _nvkm_mmu_fini,
 	},
 };

commit 5ce3bf3c72436c49fbd9a5b71d7d278665f4bf55
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 09:57:36 2015 +1000

    drm/nouveau/mmu: rename from vmmgr (no binary change)
    
    Switch to NVIDIA's name for the device.
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
new file mode 100644
index 000000000000..f5319e3e7fe5
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv44.c
@@ -0,0 +1,249 @@
+/*
+ * Copyright 2012 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include <core/gpuobj.h>
+#include <core/option.h>
+
+#include <subdev/timer.h>
+#include <subdev/mmu.h>
+
+#include "nv04.h"
+
+#define NV44_GART_SIZE (512 * 1024 * 1024)
+#define NV44_GART_PAGE (  4 * 1024)
+
+/*******************************************************************************
+ * VM map/unmap callbacks
+ ******************************************************************************/
+
+static void
+nv44_vm_fill(struct nouveau_gpuobj *pgt, dma_addr_t null,
+	     dma_addr_t *list, u32 pte, u32 cnt)
+{
+	u32 base = (pte << 2) & ~0x0000000f;
+	u32 tmp[4];
+
+	tmp[0] = nv_ro32(pgt, base + 0x0);
+	tmp[1] = nv_ro32(pgt, base + 0x4);
+	tmp[2] = nv_ro32(pgt, base + 0x8);
+	tmp[3] = nv_ro32(pgt, base + 0xc);
+
+	while (cnt--) {
+		u32 addr = list ? (*list++ >> 12) : (null >> 12);
+		switch (pte++ & 0x3) {
+		case 0:
+			tmp[0] &= ~0x07ffffff;
+			tmp[0] |= addr;
+			break;
+		case 1:
+			tmp[0] &= ~0xf8000000;
+			tmp[0] |= addr << 27;
+			tmp[1] &= ~0x003fffff;
+			tmp[1] |= addr >> 5;
+			break;
+		case 2:
+			tmp[1] &= ~0xffc00000;
+			tmp[1] |= addr << 22;
+			tmp[2] &= ~0x0001ffff;
+			tmp[2] |= addr >> 10;
+			break;
+		case 3:
+			tmp[2] &= ~0xfffe0000;
+			tmp[2] |= addr << 17;
+			tmp[3] &= ~0x00000fff;
+			tmp[3] |= addr >> 15;
+			break;
+		}
+	}
+
+	nv_wo32(pgt, base + 0x0, tmp[0]);
+	nv_wo32(pgt, base + 0x4, tmp[1]);
+	nv_wo32(pgt, base + 0x8, tmp[2]);
+	nv_wo32(pgt, base + 0xc, tmp[3] | 0x40000000);
+}
+
+static void
+nv44_vm_map_sg(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,
+	       struct nouveau_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
+{
+	struct nv04_mmu_priv *priv = (void *)vma->vm->mmu;
+	u32 tmp[4];
+	int i;
+
+	if (pte & 3) {
+		u32  max = 4 - (pte & 3);
+		u32 part = (cnt > max) ? max : cnt;
+		nv44_vm_fill(pgt, priv->null, list, pte, part);
+		pte  += part;
+		list += part;
+		cnt  -= part;
+	}
+
+	while (cnt >= 4) {
+		for (i = 0; i < 4; i++)
+			tmp[i] = *list++ >> 12;
+		nv_wo32(pgt, pte++ * 4, tmp[0] >>  0 | tmp[1] << 27);
+		nv_wo32(pgt, pte++ * 4, tmp[1] >>  5 | tmp[2] << 22);
+		nv_wo32(pgt, pte++ * 4, tmp[2] >> 10 | tmp[3] << 17);
+		nv_wo32(pgt, pte++ * 4, tmp[3] >> 15 | 0x40000000);
+		cnt -= 4;
+	}
+
+	if (cnt)
+		nv44_vm_fill(pgt, priv->null, list, pte, cnt);
+}
+
+static void
+nv44_vm_unmap(struct nouveau_gpuobj *pgt, u32 pte, u32 cnt)
+{
+	struct nv04_mmu_priv *priv = (void *)nouveau_mmu(pgt);
+
+	if (pte & 3) {
+		u32  max = 4 - (pte & 3);
+		u32 part = (cnt > max) ? max : cnt;
+		nv44_vm_fill(pgt, priv->null, NULL, pte, part);
+		pte  += part;
+		cnt  -= part;
+	}
+
+	while (cnt >= 4) {
+		nv_wo32(pgt, pte++ * 4, 0x00000000);
+		nv_wo32(pgt, pte++ * 4, 0x00000000);
+		nv_wo32(pgt, pte++ * 4, 0x00000000);
+		nv_wo32(pgt, pte++ * 4, 0x00000000);
+		cnt -= 4;
+	}
+
+	if (cnt)
+		nv44_vm_fill(pgt, priv->null, NULL, pte, cnt);
+}
+
+static void
+nv44_vm_flush(struct nouveau_vm *vm)
+{
+	struct nv04_mmu_priv *priv = (void *)vm->mmu;
+	nv_wr32(priv, 0x100814, priv->base.limit - NV44_GART_PAGE);
+	nv_wr32(priv, 0x100808, 0x00000020);
+	if (!nv_wait(priv, 0x100808, 0x00000001, 0x00000001))
+		nv_error(priv, "timeout: 0x%08x\n", nv_rd32(priv, 0x100808));
+	nv_wr32(priv, 0x100808, 0x00000000);
+}
+
+/*******************************************************************************
+ * MMU subdev
+ ******************************************************************************/
+
+static int
+nv44_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
+		struct nouveau_oclass *oclass, void *data, u32 size,
+		struct nouveau_object **pobject)
+{
+	struct nouveau_device *device = nv_device(parent);
+	struct nv04_mmu_priv *priv;
+	int ret;
+
+	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
+	    !nouveau_boolopt(device->cfgopt, "NvPCIE", true)) {
+		return nouveau_object_ctor(parent, engine, &nv04_mmu_oclass,
+					   data, size, pobject);
+	}
+
+	ret = nouveau_mmu_create(parent, engine, oclass, "PCIEGART",
+				   "pciegart", &priv);
+	*pobject = nv_object(priv);
+	if (ret)
+		return ret;
+
+	priv->base.create = nv04_vm_create;
+	priv->base.limit = NV44_GART_SIZE;
+	priv->base.dma_bits = 39;
+	priv->base.pgt_bits = 32 - 12;
+	priv->base.spg_shift = 12;
+	priv->base.lpg_shift = 12;
+	priv->base.map_sg = nv44_vm_map_sg;
+	priv->base.unmap = nv44_vm_unmap;
+	priv->base.flush = nv44_vm_flush;
+
+	priv->nullp = pci_alloc_consistent(device->pdev, 16 * 1024, &priv->null);
+	if (!priv->nullp) {
+		nv_error(priv, "unable to allocate dummy pages\n");
+		return -ENOMEM;
+	}
+
+	ret = nouveau_vm_create(&priv->base, 0, NV44_GART_SIZE, 0, 4096,
+				&priv->vm);
+	if (ret)
+		return ret;
+
+	ret = nouveau_gpuobj_new(nv_object(priv), NULL,
+				(NV44_GART_SIZE / NV44_GART_PAGE) * 4,
+				 512 * 1024, NVOBJ_FLAG_ZERO_ALLOC,
+				 &priv->vm->pgt[0].obj[0]);
+	priv->vm->pgt[0].refcount[0] = 1;
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int
+nv44_mmu_init(struct nouveau_object *object)
+{
+	struct nv04_mmu_priv *priv = (void *)object;
+	struct nouveau_gpuobj *gart = priv->vm->pgt[0].obj[0];
+	u32 addr;
+	int ret;
+
+	ret = nouveau_mmu_init(&priv->base);
+	if (ret)
+		return ret;
+
+	/* calculate vram address of this PRAMIN block, object must be
+	 * allocated on 512KiB alignment, and not exceed a total size
+	 * of 512KiB for this to work correctly
+	 */
+	addr  = nv_rd32(priv, 0x10020c);
+	addr -= ((gart->addr >> 19) + 1) << 19;
+
+	nv_wr32(priv, 0x100850, 0x80000000);
+	nv_wr32(priv, 0x100818, priv->null);
+	nv_wr32(priv, 0x100804, NV44_GART_SIZE);
+	nv_wr32(priv, 0x100850, 0x00008000);
+	nv_mask(priv, 0x10008c, 0x00000200, 0x00000200);
+	nv_wr32(priv, 0x100820, 0x00000000);
+	nv_wr32(priv, 0x10082c, 0x00000001);
+	nv_wr32(priv, 0x100800, addr | 0x00000010);
+	return 0;
+}
+
+struct nouveau_oclass
+nv44_mmu_oclass = {
+	.handle = NV_SUBDEV(MMU, 0x44),
+	.ofuncs = &(struct nouveau_ofuncs) {
+		.ctor = nv44_mmu_ctor,
+		.dtor = nv04_mmu_dtor,
+		.init = nv44_mmu_init,
+		.fini = _nouveau_mmu_fini,
+	},
+};
