commit 632b740c5481988152a3a60319aaa49c99577b77
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:20 2017 +1000

    drm/nouveau/mmu: remove old vmm frontend
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 8e683a0f796d..adca81895c09 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -28,8 +28,6 @@
 
 #include <nvif/class.h>
 
-#define NV41_GART_SIZE (512 * 1024 * 1024)
-
 static void
 nv41_mmu_init(struct nvkm_mmu *mmu)
 {
@@ -42,9 +40,7 @@ nv41_mmu_init(struct nvkm_mmu *mmu)
 static const struct nvkm_mmu_func
 nv41_mmu = {
 	.init = nv41_mmu_init,
-	.limit = NV41_GART_SIZE,
 	.dma_bits = 39,
-	.lpg_shift = 12,
 	.mmu = {{ -1, -1, NVIF_CLASS_MMU_NV04}},
 	.mem = {{ -1, -1, NVIF_CLASS_MEM_NV04}, nv04_mem_new, nv04_mem_map },
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv41_vmm_new, true },

commit eea5cf0f0170fbc54fbb3c501b0ec7cce7f68369
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu: define user interfaces to mmu
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index caee0858f522..8e683a0f796d 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -45,6 +45,7 @@ nv41_mmu = {
 	.limit = NV41_GART_SIZE,
 	.dma_bits = 39,
 	.lpg_shift = 12,
+	.mmu = {{ -1, -1, NVIF_CLASS_MMU_NV04}},
 	.mem = {{ -1, -1, NVIF_CLASS_MEM_NV04}, nv04_mem_new, nv04_mem_map },
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv41_vmm_new, true },
 };

commit 957e18a70da19373f966c20dcf3ae5e1d49f9ed0
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv04-nv4x: type-based vram allocation and bar mapping
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 5bcbc10d8564..caee0858f522 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -21,6 +21,7 @@
  *
  * Authors: Ben Skeggs
  */
+#include "mem.h"
 #include "vmm.h"
 
 #include <core/option.h>
@@ -44,6 +45,7 @@ nv41_mmu = {
 	.limit = NV41_GART_SIZE,
 	.dma_bits = 39,
 	.lpg_shift = 12,
+	.mem = {{ -1, -1, NVIF_CLASS_MEM_NV04}, nv04_mem_new, nv04_mem_map },
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv41_vmm_new, true },
 };
 

commit 26880e76863ace2dd34c14fcadaedf97a2ace417
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu: remove support for old backends
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 457cf509591b..5bcbc10d8564 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -43,8 +43,6 @@ nv41_mmu = {
 	.init = nv41_mmu_init,
 	.limit = NV41_GART_SIZE,
 	.dma_bits = 39,
-	.pgt_bits = 32 - 12,
-	.spg_shift = 12,
 	.lpg_shift = 12,
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv41_vmm_new, true },
 };

commit 473f9aca6c1063bf77cd61c2683fc496850d63b3
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv41: implement new vmm backend
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index cb037f4a1780..457cf509591b 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -24,75 +24,10 @@
 #include "vmm.h"
 
 #include <core/option.h>
-#include <subdev/timer.h>
 
 #include <nvif/class.h>
 
 #define NV41_GART_SIZE (512 * 1024 * 1024)
-#define NV41_GART_PAGE (  4 * 1024)
-
-/*******************************************************************************
- * VM map/unmap callbacks
- ******************************************************************************/
-
-static void
-nv41_vm_map_sg(struct nvkm_vma *vma, struct nvkm_memory *pgt,
-	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
-{
-	pte = pte * 4;
-	nvkm_kmap(pgt);
-	while (cnt) {
-		u32 page = PAGE_SIZE / NV41_GART_PAGE;
-		u64 phys = (u64)*list++;
-		while (cnt && page--) {
-			nvkm_wo32(pgt, pte, (phys >> 7) | 1);
-			phys += NV41_GART_PAGE;
-			pte += 4;
-			cnt -= 1;
-		}
-	}
-	nvkm_done(pgt);
-}
-
-static void
-nv41_vm_unmap(struct nvkm_vma *vma, struct nvkm_memory *pgt, u32 pte, u32 cnt)
-{
-	pte = pte * 4;
-	nvkm_kmap(pgt);
-	while (cnt--) {
-		nvkm_wo32(pgt, pte, 0x00000000);
-		pte += 4;
-	}
-	nvkm_done(pgt);
-}
-
-static void
-nv41_vm_flush(struct nvkm_vm *vm)
-{
-	struct nvkm_subdev *subdev = &vm->mmu->subdev;
-	struct nvkm_device *device = subdev->device;
-
-	mutex_lock(&subdev->mutex);
-	nvkm_wr32(device, 0x100810, 0x00000022);
-	nvkm_msec(device, 2000,
-		if (nvkm_rd32(device, 0x100810) & 0x00000020)
-			break;
-	);
-	nvkm_wr32(device, 0x100810, 0x00000000);
-	mutex_unlock(&subdev->mutex);
-}
-
-/*******************************************************************************
- * MMU subdev
- ******************************************************************************/
-
-static int
-nv41_mmu_oneinit(struct nvkm_mmu *mmu)
-{
-	mmu->vmm->pgt[0].mem[0] = mmu->vmm->pd->pt[0]->memory;
-	mmu->vmm->pgt[0].refcount[0] = 1;
-	return 0;
-}
 
 static void
 nv41_mmu_init(struct nvkm_mmu *mmu)
@@ -105,16 +40,12 @@ nv41_mmu_init(struct nvkm_mmu *mmu)
 
 static const struct nvkm_mmu_func
 nv41_mmu = {
-	.oneinit = nv41_mmu_oneinit,
 	.init = nv41_mmu_init,
 	.limit = NV41_GART_SIZE,
 	.dma_bits = 39,
 	.pgt_bits = 32 - 12,
 	.spg_shift = 12,
 	.lpg_shift = 12,
-	.map_sg = nv41_vm_map_sg,
-	.unmap = nv41_vm_unmap,
-	.flush = nv41_vm_flush,
 	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv41_vmm_new, true },
 };
 

commit 77783435c31182166c4679ad75358e1756d1e5da
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv41: implement vmm on top of new base
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 9b5375c587a7..cb037f4a1780 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -21,12 +21,13 @@
  *
  * Authors: Ben Skeggs
  */
-#include "nv04.h"
+#include "vmm.h"
 
-#include <core/gpuobj.h>
 #include <core/option.h>
 #include <subdev/timer.h>
 
+#include <nvif/class.h>
+
 #define NV41_GART_SIZE (512 * 1024 * 1024)
 #define NV41_GART_PAGE (  4 * 1024)
 
@@ -68,17 +69,17 @@ nv41_vm_unmap(struct nvkm_vma *vma, struct nvkm_memory *pgt, u32 pte, u32 cnt)
 static void
 nv41_vm_flush(struct nvkm_vm *vm)
 {
-	struct nv04_mmu *mmu = nv04_mmu(vm->mmu);
-	struct nvkm_device *device = mmu->base.subdev.device;
+	struct nvkm_subdev *subdev = &vm->mmu->subdev;
+	struct nvkm_device *device = subdev->device;
 
-	mutex_lock(&mmu->base.subdev.mutex);
+	mutex_lock(&subdev->mutex);
 	nvkm_wr32(device, 0x100810, 0x00000022);
 	nvkm_msec(device, 2000,
 		if (nvkm_rd32(device, 0x100810) & 0x00000020)
 			break;
 	);
 	nvkm_wr32(device, 0x100810, 0x00000000);
-	mutex_unlock(&mmu->base.subdev.mutex);
+	mutex_unlock(&subdev->mutex);
 }
 
 /*******************************************************************************
@@ -86,38 +87,24 @@ nv41_vm_flush(struct nvkm_vm *vm)
  ******************************************************************************/
 
 static int
-nv41_mmu_oneinit(struct nvkm_mmu *base)
+nv41_mmu_oneinit(struct nvkm_mmu *mmu)
 {
-	struct nv04_mmu *mmu = nv04_mmu(base);
-	struct nvkm_device *device = mmu->base.subdev.device;
-	int ret;
-
-	ret = nvkm_vm_create(&mmu->base, 0, NV41_GART_SIZE, 0, 4096, NULL,
-			     &mmu->base.vmm);
-	if (ret)
-		return ret;
-
-	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
-			      (NV41_GART_SIZE / NV41_GART_PAGE) * 4, 16, true,
-			      &mmu->base.vmm->pgt[0].mem[0]);
-	mmu->base.vmm->pgt[0].refcount[0] = 1;
-	return ret;
+	mmu->vmm->pgt[0].mem[0] = mmu->vmm->pd->pt[0]->memory;
+	mmu->vmm->pgt[0].refcount[0] = 1;
+	return 0;
 }
 
 static void
-nv41_mmu_init(struct nvkm_mmu *base)
+nv41_mmu_init(struct nvkm_mmu *mmu)
 {
-	struct nv04_mmu *mmu = nv04_mmu(base);
-	struct nvkm_device *device = mmu->base.subdev.device;
-	struct nvkm_memory *dma = mmu->base.vmm->pgt[0].mem[0];
-	nvkm_wr32(device, 0x100800, 0x00000002 | nvkm_memory_addr(dma));
+	struct nvkm_device *device = mmu->subdev.device;
+	nvkm_wr32(device, 0x100800, 0x00000002 | mmu->vmm->pd->pt[0]->addr);
 	nvkm_mask(device, 0x10008c, 0x00000100, 0x00000100);
 	nvkm_wr32(device, 0x100820, 0x00000000);
 }
 
 static const struct nvkm_mmu_func
 nv41_mmu = {
-	.dtor = nv04_mmu_dtor,
 	.oneinit = nv41_mmu_oneinit,
 	.init = nv41_mmu_init,
 	.limit = NV41_GART_SIZE,
@@ -128,6 +115,7 @@ nv41_mmu = {
 	.map_sg = nv41_vm_map_sg,
 	.unmap = nv41_vm_unmap,
 	.flush = nv41_vm_flush,
+	.vmm = {{ -1, -1, NVIF_CLASS_VMM_NV04}, nv41_vmm_new, true },
 };
 
 int
@@ -137,5 +125,5 @@ nv41_mmu_new(struct nvkm_device *device, int index, struct nvkm_mmu **pmmu)
 	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true))
 		return nv04_mmu_new(device, index, pmmu);
 
-	return nv04_mmu_new_(&nv41_mmu, device, index, pmmu);
+	return nvkm_mmu_new_(&nv41_mmu, device, index, pmmu);
 }

commit 0b11b30de9d2960d87373e50223800c8f9f6a89f
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Nov 1 03:56:19 2017 +1000

    drm/nouveau/mmu/nv04-nv4x: move global vmm to nvkm_mmu
    
    In a future commit, this will be constructed by common code.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index c6a26f907009..9b5375c587a7 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -93,14 +93,14 @@ nv41_mmu_oneinit(struct nvkm_mmu *base)
 	int ret;
 
 	ret = nvkm_vm_create(&mmu->base, 0, NV41_GART_SIZE, 0, 4096, NULL,
-			     &mmu->vm);
+			     &mmu->base.vmm);
 	if (ret)
 		return ret;
 
 	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
 			      (NV41_GART_SIZE / NV41_GART_PAGE) * 4, 16, true,
-			      &mmu->vm->pgt[0].mem[0]);
-	mmu->vm->pgt[0].refcount[0] = 1;
+			      &mmu->base.vmm->pgt[0].mem[0]);
+	mmu->base.vmm->pgt[0].refcount[0] = 1;
 	return ret;
 }
 
@@ -109,7 +109,7 @@ nv41_mmu_init(struct nvkm_mmu *base)
 {
 	struct nv04_mmu *mmu = nv04_mmu(base);
 	struct nvkm_device *device = mmu->base.subdev.device;
-	struct nvkm_memory *dma = mmu->vm->pgt[0].mem[0];
+	struct nvkm_memory *dma = mmu->base.vmm->pgt[0].mem[0];
 	nvkm_wr32(device, 0x100800, 0x00000002 | nvkm_memory_addr(dma));
 	nvkm_mask(device, 0x10008c, 0x00000100, 0x00000100);
 	nvkm_wr32(device, 0x100820, 0x00000000);

commit 26c9e8effebb9166eb1cfba2d164676e98c505c7
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:23 2015 +1000

    drm/nouveau/device: remove pci/platform_device from common struct
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index f30c3b890626..c6a26f907009 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -133,7 +133,7 @@ nv41_mmu = {
 int
 nv41_mmu_new(struct nvkm_device *device, int index, struct nvkm_mmu **pmmu)
 {
-	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
+	if (device->type == NVKM_DEVICE_AGP ||
 	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true))
 		return nv04_mmu_new(device, index, pmmu);
 

commit c9582455ab74246ec9f5986db3821b33058de585
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:21 2015 +1000

    drm/nouveau/mmu: convert to new-style nvkm_subdev
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 0f91d7aeb53f..f30c3b890626 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -71,14 +71,14 @@ nv41_vm_flush(struct nvkm_vm *vm)
 	struct nv04_mmu *mmu = nv04_mmu(vm->mmu);
 	struct nvkm_device *device = mmu->base.subdev.device;
 
-	mutex_lock(&nv_subdev(mmu)->mutex);
+	mutex_lock(&mmu->base.subdev.mutex);
 	nvkm_wr32(device, 0x100810, 0x00000022);
 	nvkm_msec(device, 2000,
 		if (nvkm_rd32(device, 0x100810) & 0x00000020)
 			break;
 	);
 	nvkm_wr32(device, 0x100810, 0x00000000);
-	mutex_unlock(&nv_subdev(mmu)->mutex);
+	mutex_unlock(&mmu->base.subdev.mutex);
 }
 
 /*******************************************************************************
@@ -86,36 +86,12 @@ nv41_vm_flush(struct nvkm_vm *vm)
  ******************************************************************************/
 
 static int
-nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
-	      struct nvkm_oclass *oclass, void *data, u32 size,
-	      struct nvkm_object **pobject)
+nv41_mmu_oneinit(struct nvkm_mmu *base)
 {
-	struct nvkm_device *device = nv_device(parent);
-	struct nv04_mmu *mmu;
+	struct nv04_mmu *mmu = nv04_mmu(base);
+	struct nvkm_device *device = mmu->base.subdev.device;
 	int ret;
 
-	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
-	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true)) {
-		return nvkm_object_old(parent, engine, &nv04_mmu_oclass,
-					data, size, pobject);
-	}
-
-	ret = nvkm_mmu_create(parent, engine, oclass, "PCIEGART",
-			      "mmu", &mmu);
-	*pobject = nv_object(mmu);
-	if (ret)
-		return ret;
-
-	mmu->base.create = nv04_vm_create;
-	mmu->base.limit = NV41_GART_SIZE;
-	mmu->base.dma_bits = 39;
-	mmu->base.pgt_bits = 32 - 12;
-	mmu->base.spg_shift = 12;
-	mmu->base.lpg_shift = 12;
-	mmu->base.map_sg = nv41_vm_map_sg;
-	mmu->base.unmap = nv41_vm_unmap;
-	mmu->base.flush = nv41_vm_flush;
-
 	ret = nvkm_vm_create(&mmu->base, 0, NV41_GART_SIZE, 0, 4096, NULL,
 			     &mmu->vm);
 	if (ret)
@@ -125,37 +101,41 @@ nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 			      (NV41_GART_SIZE / NV41_GART_PAGE) * 4, 16, true,
 			      &mmu->vm->pgt[0].mem[0]);
 	mmu->vm->pgt[0].refcount[0] = 1;
-	if (ret)
-		return ret;
-
-	return 0;
+	return ret;
 }
 
-static int
-nv41_mmu_init(struct nvkm_object *object)
+static void
+nv41_mmu_init(struct nvkm_mmu *base)
 {
-	struct nv04_mmu *mmu = (void *)object;
+	struct nv04_mmu *mmu = nv04_mmu(base);
 	struct nvkm_device *device = mmu->base.subdev.device;
 	struct nvkm_memory *dma = mmu->vm->pgt[0].mem[0];
-	int ret;
-
-	ret = nvkm_mmu_init(&mmu->base);
-	if (ret)
-		return ret;
-
 	nvkm_wr32(device, 0x100800, 0x00000002 | nvkm_memory_addr(dma));
 	nvkm_mask(device, 0x10008c, 0x00000100, 0x00000100);
 	nvkm_wr32(device, 0x100820, 0x00000000);
-	return 0;
 }
 
-struct nvkm_oclass
-nv41_mmu_oclass = {
-	.handle = NV_SUBDEV(MMU, 0x41),
-	.ofuncs = &(struct nvkm_ofuncs) {
-		.ctor = nv41_mmu_ctor,
-		.dtor = nv04_mmu_dtor,
-		.init = nv41_mmu_init,
-		.fini = _nvkm_mmu_fini,
-	},
+static const struct nvkm_mmu_func
+nv41_mmu = {
+	.dtor = nv04_mmu_dtor,
+	.oneinit = nv41_mmu_oneinit,
+	.init = nv41_mmu_init,
+	.limit = NV41_GART_SIZE,
+	.dma_bits = 39,
+	.pgt_bits = 32 - 12,
+	.spg_shift = 12,
+	.lpg_shift = 12,
+	.map_sg = nv41_vm_map_sg,
+	.unmap = nv41_vm_unmap,
+	.flush = nv41_vm_flush,
 };
+
+int
+nv41_mmu_new(struct nvkm_device *device, int index, struct nvkm_mmu **pmmu)
+{
+	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
+	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true))
+		return nv04_mmu_new(device, index, pmmu);
+
+	return nv04_mmu_new_(&nv41_mmu, device, index, pmmu);
+}

commit d0659d3277cd7bf50e45d48f4692a7fbb11e5957
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/mmu: directly use instmem for page tables
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 6fd74f1f7290..0f91d7aeb53f 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -35,7 +35,7 @@
  ******************************************************************************/
 
 static void
-nv41_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
+nv41_vm_map_sg(struct nvkm_vma *vma, struct nvkm_memory *pgt,
 	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
 {
 	pte = pte * 4;
@@ -54,7 +54,7 @@ nv41_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
 }
 
 static void
-nv41_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
+nv41_vm_unmap(struct nvkm_vma *vma, struct nvkm_memory *pgt, u32 pte, u32 cnt)
 {
 	pte = pte * 4;
 	nvkm_kmap(pgt);
@@ -68,7 +68,7 @@ nv41_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 static void
 nv41_vm_flush(struct nvkm_vm *vm)
 {
-	struct nv04_mmu *mmu = (void *)vm->mmu;
+	struct nv04_mmu *mmu = nv04_mmu(vm->mmu);
 	struct nvkm_device *device = mmu->base.subdev.device;
 
 	mutex_lock(&nv_subdev(mmu)->mutex);
@@ -121,10 +121,9 @@ nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(mmu), NULL,
-			      (NV41_GART_SIZE / NV41_GART_PAGE) * 4, 16,
-			      NVOBJ_FLAG_ZERO_ALLOC,
-			      &mmu->vm->pgt[0].obj[0]);
+	ret = nvkm_memory_new(device, NVKM_MEM_TARGET_INST,
+			      (NV41_GART_SIZE / NV41_GART_PAGE) * 4, 16, true,
+			      &mmu->vm->pgt[0].mem[0]);
 	mmu->vm->pgt[0].refcount[0] = 1;
 	if (ret)
 		return ret;
@@ -137,14 +136,14 @@ nv41_mmu_init(struct nvkm_object *object)
 {
 	struct nv04_mmu *mmu = (void *)object;
 	struct nvkm_device *device = mmu->base.subdev.device;
-	struct nvkm_gpuobj *dma = mmu->vm->pgt[0].obj[0];
+	struct nvkm_memory *dma = mmu->vm->pgt[0].mem[0];
 	int ret;
 
 	ret = nvkm_mmu_init(&mmu->base);
 	if (ret)
 		return ret;
 
-	nvkm_wr32(device, 0x100800, dma->addr | 0x00000002);
+	nvkm_wr32(device, 0x100800, 0x00000002 | nvkm_memory_addr(dma));
 	nvkm_mask(device, 0x10008c, 0x00000100, 0x00000100);
 	nvkm_wr32(device, 0x100820, 0x00000000);
 	return 0;

commit 1de68568d69ac518db076cc6118af91e930b5f90
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:17 2015 +1000

    drm/nouveau/mmu: protect each vm with its own mutex
    
    An upcoming commit requires being able to modify the PRAMIN BAR page
    tables while already holding the MMU subdev mutex.
    
    To solve this issue, each VM has been given its own mutex.  As a nice
    side-effect, this also allows separate VMs to be updated concurrently.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 26192b91e456..6fd74f1f7290 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -116,7 +116,7 @@ nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	mmu->base.unmap = nv41_vm_unmap;
 	mmu->base.flush = nv41_vm_flush;
 
-	ret = nvkm_vm_create(&mmu->base, 0, NV41_GART_SIZE, 0, 4096,
+	ret = nvkm_vm_create(&mmu->base, 0, NV41_GART_SIZE, 0, 4096, NULL,
 			     &mmu->vm);
 	if (ret)
 		return ret;

commit aa35888ff024b18c7b6b29eb773a221f642987f7
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:16 2015 +1000

    drm/nouveau/object: rename some functions to avoid upcoming conflicts
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index c44f880120ab..26192b91e456 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -96,7 +96,7 @@ nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 
 	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
 	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true)) {
-		return nvkm_object_ctor(parent, engine, &nv04_mmu_oclass,
+		return nvkm_object_old(parent, engine, &nv04_mmu_oclass,
 					data, size, pobject);
 	}
 

commit cd821077aa7f180f83f3a5d60ec47cb75d56fd37
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:14 2015 +1000

    drm/nouveau/mmu: switch to gpuobj accessor macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 378cd1d363ae..c44f880120ab 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -39,26 +39,30 @@ nv41_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
 	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
 {
 	pte = pte * 4;
+	nvkm_kmap(pgt);
 	while (cnt) {
 		u32 page = PAGE_SIZE / NV41_GART_PAGE;
 		u64 phys = (u64)*list++;
 		while (cnt && page--) {
-			nv_wo32(pgt, pte, (phys >> 7) | 1);
+			nvkm_wo32(pgt, pte, (phys >> 7) | 1);
 			phys += NV41_GART_PAGE;
 			pte += 4;
 			cnt -= 1;
 		}
 	}
+	nvkm_done(pgt);
 }
 
 static void
 nv41_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 {
 	pte = pte * 4;
+	nvkm_kmap(pgt);
 	while (cnt--) {
-		nv_wo32(pgt, pte, 0x00000000);
+		nvkm_wo32(pgt, pte, 0x00000000);
 		pte += 4;
 	}
+	nvkm_done(pgt);
 }
 
 static void

commit 909604d444eb26ed37860268cfc6a68d4a5f28cb
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:11 2015 +1000

    drm/nouveau/mmu: switch to new-style timer macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 609c6a69b60a..378cd1d363ae 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -69,10 +69,10 @@ nv41_vm_flush(struct nvkm_vm *vm)
 
 	mutex_lock(&nv_subdev(mmu)->mutex);
 	nvkm_wr32(device, 0x100810, 0x00000022);
-	if (!nv_wait(mmu, 0x100810, 0x00000020, 0x00000020)) {
-		nv_warn(mmu, "flush timeout, 0x%08x\n",
-			nvkm_rd32(device, 0x100810));
-	}
+	nvkm_msec(device, 2000,
+		if (nvkm_rd32(device, 0x100810) & 0x00000020)
+			break;
+	);
 	nvkm_wr32(device, 0x100810, 0x00000000);
 	mutex_unlock(&nv_subdev(mmu)->mutex);
 }

commit 83f56106ead017a07868176279746d73bc7a7060
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:09 2015 +1000

    drm/nouveau/mmu: switch to device pri macros
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 17b2b3979da4..609c6a69b60a 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -65,14 +65,15 @@ static void
 nv41_vm_flush(struct nvkm_vm *vm)
 {
 	struct nv04_mmu *mmu = (void *)vm->mmu;
+	struct nvkm_device *device = mmu->base.subdev.device;
 
 	mutex_lock(&nv_subdev(mmu)->mutex);
-	nv_wr32(mmu, 0x100810, 0x00000022);
+	nvkm_wr32(device, 0x100810, 0x00000022);
 	if (!nv_wait(mmu, 0x100810, 0x00000020, 0x00000020)) {
 		nv_warn(mmu, "flush timeout, 0x%08x\n",
-			nv_rd32(mmu, 0x100810));
+			nvkm_rd32(device, 0x100810));
 	}
-	nv_wr32(mmu, 0x100810, 0x00000000);
+	nvkm_wr32(device, 0x100810, 0x00000000);
 	mutex_unlock(&nv_subdev(mmu)->mutex);
 }
 
@@ -131,6 +132,7 @@ static int
 nv41_mmu_init(struct nvkm_object *object)
 {
 	struct nv04_mmu *mmu = (void *)object;
+	struct nvkm_device *device = mmu->base.subdev.device;
 	struct nvkm_gpuobj *dma = mmu->vm->pgt[0].obj[0];
 	int ret;
 
@@ -138,9 +140,9 @@ nv41_mmu_init(struct nvkm_object *object)
 	if (ret)
 		return ret;
 
-	nv_wr32(mmu, 0x100800, dma->addr | 0x00000002);
-	nv_mask(mmu, 0x10008c, 0x00000100, 0x00000100);
-	nv_wr32(mmu, 0x100820, 0x00000000);
+	nvkm_wr32(device, 0x100800, dma->addr | 0x00000002);
+	nvkm_mask(device, 0x10008c, 0x00000100, 0x00000100);
+	nvkm_wr32(device, 0x100820, 0x00000000);
 	return 0;
 }
 

commit 1f5bffca226929a834c7d631464d420e78cbe5f1
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:07 2015 +1000

    drm/nouveau/mmu: cosmetic changes
    
    This is purely preparation for upcoming commits, there should be no
    code changes here.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 37b943aba114..17b2b3979da4 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -64,16 +64,16 @@ nv41_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 static void
 nv41_vm_flush(struct nvkm_vm *vm)
 {
-	struct nv04_mmu_priv *priv = (void *)vm->mmu;
+	struct nv04_mmu *mmu = (void *)vm->mmu;
 
-	mutex_lock(&nv_subdev(priv)->mutex);
-	nv_wr32(priv, 0x100810, 0x00000022);
-	if (!nv_wait(priv, 0x100810, 0x00000020, 0x00000020)) {
-		nv_warn(priv, "flush timeout, 0x%08x\n",
-			nv_rd32(priv, 0x100810));
+	mutex_lock(&nv_subdev(mmu)->mutex);
+	nv_wr32(mmu, 0x100810, 0x00000022);
+	if (!nv_wait(mmu, 0x100810, 0x00000020, 0x00000020)) {
+		nv_warn(mmu, "flush timeout, 0x%08x\n",
+			nv_rd32(mmu, 0x100810));
 	}
-	nv_wr32(priv, 0x100810, 0x00000000);
-	mutex_unlock(&nv_subdev(priv)->mutex);
+	nv_wr32(mmu, 0x100810, 0x00000000);
+	mutex_unlock(&nv_subdev(mmu)->mutex);
 }
 
 /*******************************************************************************
@@ -86,7 +86,7 @@ nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	      struct nvkm_object **pobject)
 {
 	struct nvkm_device *device = nv_device(parent);
-	struct nv04_mmu_priv *priv;
+	struct nv04_mmu *mmu;
 	int ret;
 
 	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
@@ -96,31 +96,31 @@ nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 	}
 
 	ret = nvkm_mmu_create(parent, engine, oclass, "PCIEGART",
-			      "pciegart", &priv);
-	*pobject = nv_object(priv);
+			      "mmu", &mmu);
+	*pobject = nv_object(mmu);
 	if (ret)
 		return ret;
 
-	priv->base.create = nv04_vm_create;
-	priv->base.limit = NV41_GART_SIZE;
-	priv->base.dma_bits = 39;
-	priv->base.pgt_bits = 32 - 12;
-	priv->base.spg_shift = 12;
-	priv->base.lpg_shift = 12;
-	priv->base.map_sg = nv41_vm_map_sg;
-	priv->base.unmap = nv41_vm_unmap;
-	priv->base.flush = nv41_vm_flush;
-
-	ret = nvkm_vm_create(&priv->base, 0, NV41_GART_SIZE, 0, 4096,
-			     &priv->vm);
+	mmu->base.create = nv04_vm_create;
+	mmu->base.limit = NV41_GART_SIZE;
+	mmu->base.dma_bits = 39;
+	mmu->base.pgt_bits = 32 - 12;
+	mmu->base.spg_shift = 12;
+	mmu->base.lpg_shift = 12;
+	mmu->base.map_sg = nv41_vm_map_sg;
+	mmu->base.unmap = nv41_vm_unmap;
+	mmu->base.flush = nv41_vm_flush;
+
+	ret = nvkm_vm_create(&mmu->base, 0, NV41_GART_SIZE, 0, 4096,
+			     &mmu->vm);
 	if (ret)
 		return ret;
 
-	ret = nvkm_gpuobj_new(nv_object(priv), NULL,
+	ret = nvkm_gpuobj_new(nv_object(mmu), NULL,
 			      (NV41_GART_SIZE / NV41_GART_PAGE) * 4, 16,
 			      NVOBJ_FLAG_ZERO_ALLOC,
-			      &priv->vm->pgt[0].obj[0]);
-	priv->vm->pgt[0].refcount[0] = 1;
+			      &mmu->vm->pgt[0].obj[0]);
+	mmu->vm->pgt[0].refcount[0] = 1;
 	if (ret)
 		return ret;
 
@@ -130,17 +130,17 @@ nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
 static int
 nv41_mmu_init(struct nvkm_object *object)
 {
-	struct nv04_mmu_priv *priv = (void *)object;
-	struct nvkm_gpuobj *dma = priv->vm->pgt[0].obj[0];
+	struct nv04_mmu *mmu = (void *)object;
+	struct nvkm_gpuobj *dma = mmu->vm->pgt[0].obj[0];
 	int ret;
 
-	ret = nvkm_mmu_init(&priv->base);
+	ret = nvkm_mmu_init(&mmu->base);
 	if (ret)
 		return ret;
 
-	nv_wr32(priv, 0x100800, dma->addr | 0x00000002);
-	nv_mask(priv, 0x10008c, 0x00000100, 0x00000100);
-	nv_wr32(priv, 0x100820, 0x00000000);
+	nv_wr32(mmu, 0x100800, dma->addr | 0x00000002);
+	nv_mask(mmu, 0x10008c, 0x00000100, 0x00000100);
+	nv_wr32(mmu, 0x100820, 0x00000000);
 	return 0;
 }
 

commit 9ace404b1098221021b01c2ba0eeea0c257fa4a5
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 20 14:54:06 2015 +1000

    drm/nouveau/device: include core/device.h automatically for subdevs/engines
    
    Pretty much every subdev/engine is going to need access to nvkm_device
    shortly to touch registers and/or output messages.
    
    The odd placement of the includes is necessary to work around some
    inter-dependencies that currently exist.  This will be fixed later.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 61ee3ab11660..37b943aba114 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -23,7 +23,6 @@
  */
 #include "nv04.h"
 
-#include <core/device.h>
 #include <core/gpuobj.h>
 #include <core/option.h>
 #include <subdev/timer.h>

commit 42594600095f03244a674fecdd2b5f6da2441180
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 15:09:19 2015 +1000

    drm/nouveau/mmu: namespace + nvidia gpu names (no binary change)
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
index 61af036f1252..61ee3ab11660 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -21,14 +21,12 @@
  *
  * Authors: Ben Skeggs
  */
+#include "nv04.h"
 
+#include <core/device.h>
 #include <core/gpuobj.h>
 #include <core/option.h>
-
 #include <subdev/timer.h>
-#include <subdev/mmu.h>
-
-#include "nv04.h"
 
 #define NV41_GART_SIZE (512 * 1024 * 1024)
 #define NV41_GART_PAGE (  4 * 1024)
@@ -38,8 +36,8 @@
  ******************************************************************************/
 
 static void
-nv41_vm_map_sg(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,
-	       struct nouveau_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
+nv41_vm_map_sg(struct nvkm_vma *vma, struct nvkm_gpuobj *pgt,
+	       struct nvkm_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
 {
 	pte = pte * 4;
 	while (cnt) {
@@ -55,7 +53,7 @@ nv41_vm_map_sg(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,
 }
 
 static void
-nv41_vm_unmap(struct nouveau_gpuobj *pgt, u32 pte, u32 cnt)
+nv41_vm_unmap(struct nvkm_gpuobj *pgt, u32 pte, u32 cnt)
 {
 	pte = pte * 4;
 	while (cnt--) {
@@ -65,7 +63,7 @@ nv41_vm_unmap(struct nouveau_gpuobj *pgt, u32 pte, u32 cnt)
 }
 
 static void
-nv41_vm_flush(struct nouveau_vm *vm)
+nv41_vm_flush(struct nvkm_vm *vm)
 {
 	struct nv04_mmu_priv *priv = (void *)vm->mmu;
 
@@ -84,22 +82,22 @@ nv41_vm_flush(struct nouveau_vm *vm)
  ******************************************************************************/
 
 static int
-nv41_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-		struct nouveau_oclass *oclass, void *data, u32 size,
-		struct nouveau_object **pobject)
+nv41_mmu_ctor(struct nvkm_object *parent, struct nvkm_object *engine,
+	      struct nvkm_oclass *oclass, void *data, u32 size,
+	      struct nvkm_object **pobject)
 {
-	struct nouveau_device *device = nv_device(parent);
+	struct nvkm_device *device = nv_device(parent);
 	struct nv04_mmu_priv *priv;
 	int ret;
 
 	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
-	    !nouveau_boolopt(device->cfgopt, "NvPCIE", true)) {
-		return nouveau_object_ctor(parent, engine, &nv04_mmu_oclass,
-					   data, size, pobject);
+	    !nvkm_boolopt(device->cfgopt, "NvPCIE", true)) {
+		return nvkm_object_ctor(parent, engine, &nv04_mmu_oclass,
+					data, size, pobject);
 	}
 
-	ret = nouveau_mmu_create(parent, engine, oclass, "PCIEGART",
-				   "pciegart", &priv);
+	ret = nvkm_mmu_create(parent, engine, oclass, "PCIEGART",
+			      "pciegart", &priv);
 	*pobject = nv_object(priv);
 	if (ret)
 		return ret;
@@ -114,15 +112,15 @@ nv41_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
 	priv->base.unmap = nv41_vm_unmap;
 	priv->base.flush = nv41_vm_flush;
 
-	ret = nouveau_vm_create(&priv->base, 0, NV41_GART_SIZE, 0, 4096,
-				&priv->vm);
+	ret = nvkm_vm_create(&priv->base, 0, NV41_GART_SIZE, 0, 4096,
+			     &priv->vm);
 	if (ret)
 		return ret;
 
-	ret = nouveau_gpuobj_new(nv_object(priv), NULL,
-				(NV41_GART_SIZE / NV41_GART_PAGE) * 4,
-				 16, NVOBJ_FLAG_ZERO_ALLOC,
-				 &priv->vm->pgt[0].obj[0]);
+	ret = nvkm_gpuobj_new(nv_object(priv), NULL,
+			      (NV41_GART_SIZE / NV41_GART_PAGE) * 4, 16,
+			      NVOBJ_FLAG_ZERO_ALLOC,
+			      &priv->vm->pgt[0].obj[0]);
 	priv->vm->pgt[0].refcount[0] = 1;
 	if (ret)
 		return ret;
@@ -131,13 +129,13 @@ nv41_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
 }
 
 static int
-nv41_mmu_init(struct nouveau_object *object)
+nv41_mmu_init(struct nvkm_object *object)
 {
 	struct nv04_mmu_priv *priv = (void *)object;
-	struct nouveau_gpuobj *dma = priv->vm->pgt[0].obj[0];
+	struct nvkm_gpuobj *dma = priv->vm->pgt[0].obj[0];
 	int ret;
 
-	ret = nouveau_mmu_init(&priv->base);
+	ret = nvkm_mmu_init(&priv->base);
 	if (ret)
 		return ret;
 
@@ -147,13 +145,13 @@ nv41_mmu_init(struct nouveau_object *object)
 	return 0;
 }
 
-struct nouveau_oclass
+struct nvkm_oclass
 nv41_mmu_oclass = {
 	.handle = NV_SUBDEV(MMU, 0x41),
-	.ofuncs = &(struct nouveau_ofuncs) {
+	.ofuncs = &(struct nvkm_ofuncs) {
 		.ctor = nv41_mmu_ctor,
 		.dtor = nv04_mmu_dtor,
 		.init = nv41_mmu_init,
-		.fini = _nouveau_mmu_fini,
+		.fini = _nvkm_mmu_fini,
 	},
 };

commit 5ce3bf3c72436c49fbd9a5b71d7d278665f4bf55
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Wed Jan 14 09:57:36 2015 +1000

    drm/nouveau/mmu: rename from vmmgr (no binary change)
    
    Switch to NVIDIA's name for the device.
    
    The namespace of NVKM is being changed to nvkm_ instead of nouveau_,
    which will be used for the DRM part of the driver.  This is being
    done in order to make it very clear as to what part of the driver a
    given symbol belongs to, and as a minor step towards splitting the
    DRM driver out to be able to stand on its own (for virt).
    
    Because there's already a large amount of churn here anyway, this is
    as good a time as any to also switch to NVIDIA's device and chipset
    naming to ease collaboration with them.
    
    A comparison of objdump disassemblies proves no code changes.
    
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
new file mode 100644
index 000000000000..61af036f1252
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/nv41.c
@@ -0,0 +1,159 @@
+/*
+ * Copyright 2012 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include <core/gpuobj.h>
+#include <core/option.h>
+
+#include <subdev/timer.h>
+#include <subdev/mmu.h>
+
+#include "nv04.h"
+
+#define NV41_GART_SIZE (512 * 1024 * 1024)
+#define NV41_GART_PAGE (  4 * 1024)
+
+/*******************************************************************************
+ * VM map/unmap callbacks
+ ******************************************************************************/
+
+static void
+nv41_vm_map_sg(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,
+	       struct nouveau_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)
+{
+	pte = pte * 4;
+	while (cnt) {
+		u32 page = PAGE_SIZE / NV41_GART_PAGE;
+		u64 phys = (u64)*list++;
+		while (cnt && page--) {
+			nv_wo32(pgt, pte, (phys >> 7) | 1);
+			phys += NV41_GART_PAGE;
+			pte += 4;
+			cnt -= 1;
+		}
+	}
+}
+
+static void
+nv41_vm_unmap(struct nouveau_gpuobj *pgt, u32 pte, u32 cnt)
+{
+	pte = pte * 4;
+	while (cnt--) {
+		nv_wo32(pgt, pte, 0x00000000);
+		pte += 4;
+	}
+}
+
+static void
+nv41_vm_flush(struct nouveau_vm *vm)
+{
+	struct nv04_mmu_priv *priv = (void *)vm->mmu;
+
+	mutex_lock(&nv_subdev(priv)->mutex);
+	nv_wr32(priv, 0x100810, 0x00000022);
+	if (!nv_wait(priv, 0x100810, 0x00000020, 0x00000020)) {
+		nv_warn(priv, "flush timeout, 0x%08x\n",
+			nv_rd32(priv, 0x100810));
+	}
+	nv_wr32(priv, 0x100810, 0x00000000);
+	mutex_unlock(&nv_subdev(priv)->mutex);
+}
+
+/*******************************************************************************
+ * MMU subdev
+ ******************************************************************************/
+
+static int
+nv41_mmu_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
+		struct nouveau_oclass *oclass, void *data, u32 size,
+		struct nouveau_object **pobject)
+{
+	struct nouveau_device *device = nv_device(parent);
+	struct nv04_mmu_priv *priv;
+	int ret;
+
+	if (pci_find_capability(device->pdev, PCI_CAP_ID_AGP) ||
+	    !nouveau_boolopt(device->cfgopt, "NvPCIE", true)) {
+		return nouveau_object_ctor(parent, engine, &nv04_mmu_oclass,
+					   data, size, pobject);
+	}
+
+	ret = nouveau_mmu_create(parent, engine, oclass, "PCIEGART",
+				   "pciegart", &priv);
+	*pobject = nv_object(priv);
+	if (ret)
+		return ret;
+
+	priv->base.create = nv04_vm_create;
+	priv->base.limit = NV41_GART_SIZE;
+	priv->base.dma_bits = 39;
+	priv->base.pgt_bits = 32 - 12;
+	priv->base.spg_shift = 12;
+	priv->base.lpg_shift = 12;
+	priv->base.map_sg = nv41_vm_map_sg;
+	priv->base.unmap = nv41_vm_unmap;
+	priv->base.flush = nv41_vm_flush;
+
+	ret = nouveau_vm_create(&priv->base, 0, NV41_GART_SIZE, 0, 4096,
+				&priv->vm);
+	if (ret)
+		return ret;
+
+	ret = nouveau_gpuobj_new(nv_object(priv), NULL,
+				(NV41_GART_SIZE / NV41_GART_PAGE) * 4,
+				 16, NVOBJ_FLAG_ZERO_ALLOC,
+				 &priv->vm->pgt[0].obj[0]);
+	priv->vm->pgt[0].refcount[0] = 1;
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int
+nv41_mmu_init(struct nouveau_object *object)
+{
+	struct nv04_mmu_priv *priv = (void *)object;
+	struct nouveau_gpuobj *dma = priv->vm->pgt[0].obj[0];
+	int ret;
+
+	ret = nouveau_mmu_init(&priv->base);
+	if (ret)
+		return ret;
+
+	nv_wr32(priv, 0x100800, dma->addr | 0x00000002);
+	nv_mask(priv, 0x10008c, 0x00000100, 0x00000100);
+	nv_wr32(priv, 0x100820, 0x00000000);
+	return 0;
+}
+
+struct nouveau_oclass
+nv41_mmu_oclass = {
+	.handle = NV_SUBDEV(MMU, 0x41),
+	.ofuncs = &(struct nouveau_ofuncs) {
+		.ctor = nv41_mmu_ctor,
+		.dtor = nv04_mmu_dtor,
+		.init = nv41_mmu_init,
+		.fini = _nouveau_mmu_fini,
+	},
+};
