commit 6aebc51d7aeff5a30d86485f320f0c871b5f23a4
Author: Qiang Yu <yuq825@gmail.com>
Date:   Thu Jan 16 21:11:55 2020 +0800

    drm/lima: support heap buffer creation
    
    heap buffer is used as output of GP and input of PP for
    Mali Utgard GPU. Size of heap buffer depends on the task
    so is a runtime variable.
    
    Previously we just create a large enough buffer as heap
    buffer. Now we add a heap buffer type to be able to
    increase the backup memory dynamically when GP fail due
    to lack of heap memory.
    
    Reviewed-by: Vasily Khoruzhick <anarsoul@gmail.com>
    Tested-by: Andreas Baierl <ichgeh@imkreisrum.de>
    Signed-off-by: Qiang Yu <yuq825@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200116131157.13346-4-yuq825@gmail.com

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index d0059d8c97d8..5404e0d668db 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -4,6 +4,8 @@
 #include <linux/mm.h>
 #include <linux/sync_file.h>
 #include <linux/pagemap.h>
+#include <linux/shmem_fs.h>
+#include <linux/dma-mapping.h>
 
 #include <drm/drm_file.h>
 #include <drm/drm_syncobj.h>
@@ -15,6 +17,83 @@
 #include "lima_gem.h"
 #include "lima_vm.h"
 
+int lima_heap_alloc(struct lima_bo *bo, struct lima_vm *vm)
+{
+	struct page **pages;
+	struct address_space *mapping = bo->base.base.filp->f_mapping;
+	struct device *dev = bo->base.base.dev->dev;
+	size_t old_size = bo->heap_size;
+	size_t new_size = bo->heap_size ? bo->heap_size * 2 :
+		(lima_heap_init_nr_pages << PAGE_SHIFT);
+	struct sg_table sgt;
+	int i, ret;
+
+	if (bo->heap_size >= bo->base.base.size)
+		return -ENOSPC;
+
+	new_size = min(new_size, bo->base.base.size);
+
+	mutex_lock(&bo->base.pages_lock);
+
+	if (bo->base.pages) {
+		pages = bo->base.pages;
+	} else {
+		pages = kvmalloc_array(bo->base.base.size >> PAGE_SHIFT,
+				       sizeof(*pages), GFP_KERNEL | __GFP_ZERO);
+		if (!pages) {
+			mutex_unlock(&bo->base.pages_lock);
+			return -ENOMEM;
+		}
+
+		bo->base.pages = pages;
+		bo->base.pages_use_count = 1;
+
+		mapping_set_unevictable(mapping);
+	}
+
+	for (i = old_size >> PAGE_SHIFT; i < new_size >> PAGE_SHIFT; i++) {
+		struct page *page = shmem_read_mapping_page(mapping, i);
+
+		if (IS_ERR(page)) {
+			mutex_unlock(&bo->base.pages_lock);
+			return PTR_ERR(page);
+		}
+		pages[i] = page;
+	}
+
+	mutex_unlock(&bo->base.pages_lock);
+
+	ret = sg_alloc_table_from_pages(&sgt, pages, i, 0,
+					new_size, GFP_KERNEL);
+	if (ret)
+		return ret;
+
+	if (bo->base.sgt) {
+		dma_unmap_sg(dev, bo->base.sgt->sgl,
+			     bo->base.sgt->nents, DMA_BIDIRECTIONAL);
+		sg_free_table(bo->base.sgt);
+	} else {
+		bo->base.sgt = kmalloc(sizeof(*bo->base.sgt), GFP_KERNEL);
+		if (!bo->base.sgt) {
+			sg_free_table(&sgt);
+			return -ENOMEM;
+		}
+	}
+
+	dma_map_sg(dev, sgt.sgl, sgt.nents, DMA_BIDIRECTIONAL);
+
+	*bo->base.sgt = sgt;
+
+	if (vm) {
+		ret = lima_vm_map_bo(vm, bo, old_size >> PAGE_SHIFT);
+		if (ret)
+			return ret;
+	}
+
+	bo->heap_size = new_size;
+	return 0;
+}
+
 int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
 			   u32 size, u32 flags, u32 *handle)
 {
@@ -22,7 +101,8 @@ int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
 	gfp_t mask;
 	struct drm_gem_shmem_object *shmem;
 	struct drm_gem_object *obj;
-	struct sg_table *sgt;
+	struct lima_bo *bo;
+	bool is_heap = flags & LIMA_BO_FLAG_HEAP;
 
 	shmem = drm_gem_shmem_create(dev, size);
 	if (IS_ERR(shmem))
@@ -36,10 +116,18 @@ int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
 	mask |= __GFP_DMA32;
 	mapping_set_gfp_mask(obj->filp->f_mapping, mask);
 
-	sgt = drm_gem_shmem_get_pages_sgt(obj);
-	if (IS_ERR(sgt)) {
-		err = PTR_ERR(sgt);
-		goto out;
+	if (is_heap) {
+		bo = to_lima_bo(obj);
+		err = lima_heap_alloc(bo, NULL);
+		if (err)
+			goto out;
+	} else {
+		struct sg_table *sgt = drm_gem_shmem_get_pages_sgt(obj);
+
+		if (IS_ERR(sgt)) {
+			err = PTR_ERR(sgt);
+			goto out;
+		}
 	}
 
 	err = drm_gem_handle_create(file, obj, handle);
@@ -79,17 +167,47 @@ static void lima_gem_object_close(struct drm_gem_object *obj, struct drm_file *f
 	lima_vm_bo_del(vm, bo);
 }
 
+static int lima_gem_pin(struct drm_gem_object *obj)
+{
+	struct lima_bo *bo = to_lima_bo(obj);
+
+	if (bo->heap_size)
+		return -EINVAL;
+
+	return drm_gem_shmem_pin(obj);
+}
+
+static void *lima_gem_vmap(struct drm_gem_object *obj)
+{
+	struct lima_bo *bo = to_lima_bo(obj);
+
+	if (bo->heap_size)
+		return ERR_PTR(-EINVAL);
+
+	return drm_gem_shmem_vmap(obj);
+}
+
+static int lima_gem_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma)
+{
+	struct lima_bo *bo = to_lima_bo(obj);
+
+	if (bo->heap_size)
+		return -EINVAL;
+
+	return drm_gem_shmem_mmap(obj, vma);
+}
+
 static const struct drm_gem_object_funcs lima_gem_funcs = {
 	.free = lima_gem_free_object,
 	.open = lima_gem_object_open,
 	.close = lima_gem_object_close,
 	.print_info = drm_gem_shmem_print_info,
-	.pin = drm_gem_shmem_pin,
+	.pin = lima_gem_pin,
 	.unpin = drm_gem_shmem_unpin,
 	.get_sg_table = drm_gem_shmem_get_sg_table,
-	.vmap = drm_gem_shmem_vmap,
+	.vmap = lima_gem_vmap,
 	.vunmap = drm_gem_shmem_vunmap,
-	.mmap = drm_gem_shmem_mmap,
+	.mmap = lima_gem_mmap,
 };
 
 struct drm_gem_object *lima_gem_create_object(struct drm_device *dev, size_t size)

commit e305b8b6d1ff227779804e4695b8c5cb6864a620
Author: Qiang Yu <yuq825@gmail.com>
Date:   Thu Oct 10 22:01:51 2019 +0800

    drm/lima: use drm_gem_(un)lock_reservations
    
    Simplify the driver code with DRM GEM helper function.
    
    v2:
    improve commit comment.
    
    Reviewed-by: Vasily Khoruzhick <anarsoul@gmail.com>
    Signed-off-by: Qiang Yu <yuq825@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20191010140152.17747-3-yuq825@gmail.com

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 4a62455fa0aa..d0059d8c97d8 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -147,61 +147,6 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo,
 	return drm_gem_fence_array_add_implicit(&task->deps, &bo->base.base, write);
 }
 
-static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
-			     struct ww_acquire_ctx *ctx)
-{
-	int i, ret = 0, contended, slow_locked = -1;
-
-	ww_acquire_init(ctx, &reservation_ww_class);
-
-retry:
-	for (i = 0; i < nr_bos; i++) {
-		if (i == slow_locked) {
-			slow_locked = -1;
-			continue;
-		}
-
-		ret = ww_mutex_lock_interruptible(&lima_bo_resv(bos[i])->lock, ctx);
-		if (ret < 0) {
-			contended = i;
-			goto err;
-		}
-	}
-
-	ww_acquire_done(ctx);
-	return 0;
-
-err:
-	for (i--; i >= 0; i--)
-		ww_mutex_unlock(&lima_bo_resv(bos[i])->lock);
-
-	if (slow_locked >= 0)
-		ww_mutex_unlock(&lima_bo_resv(bos[slow_locked])->lock);
-
-	if (ret == -EDEADLK) {
-		/* we lost out in a seqno race, lock and retry.. */
-		ret = ww_mutex_lock_slow_interruptible(
-			&lima_bo_resv(bos[contended])->lock, ctx);
-		if (!ret) {
-			slow_locked = contended;
-			goto retry;
-		}
-	}
-	ww_acquire_fini(ctx);
-
-	return ret;
-}
-
-static void lima_gem_unlock_bos(struct lima_bo **bos, u32 nr_bos,
-				struct ww_acquire_ctx *ctx)
-{
-	int i;
-
-	for (i = 0; i < nr_bos; i++)
-		ww_mutex_unlock(&lima_bo_resv(bos[i])->lock);
-	ww_acquire_fini(ctx);
-}
-
 static int lima_gem_add_deps(struct drm_file *file, struct lima_submit *submit)
 {
 	int i, err;
@@ -267,7 +212,8 @@ int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
 		bos[i] = bo;
 	}
 
-	err = lima_gem_lock_bos(bos, submit->nr_bos, &ctx);
+	err = drm_gem_lock_reservations((struct drm_gem_object **)bos,
+					submit->nr_bos, &ctx);
 	if (err)
 		goto err_out0;
 
@@ -300,7 +246,8 @@ int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
 			dma_resv_add_shared_fence(lima_bo_resv(bos[i]), fence);
 	}
 
-	lima_gem_unlock_bos(bos, submit->nr_bos, &ctx);
+	drm_gem_unlock_reservations((struct drm_gem_object **)bos,
+				    submit->nr_bos, &ctx);
 
 	for (i = 0; i < submit->nr_bos; i++)
 		drm_gem_object_put_unlocked(&bos[i]->base.base);
@@ -317,7 +264,8 @@ int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
 err_out2:
 	lima_sched_task_fini(submit->task);
 err_out1:
-	lima_gem_unlock_bos(bos, submit->nr_bos, &ctx);
+	drm_gem_unlock_reservations((struct drm_gem_object **)bos,
+				    submit->nr_bos, &ctx);
 err_out0:
 	for (i = 0; i < submit->nr_bos; i++) {
 		if (!bos[i])

commit d61dd248ddadf85b3222b3f63c3d268fcc24beb4
Author: Qiang Yu <yuq825@gmail.com>
Date:   Thu Oct 10 22:01:50 2019 +0800

    drm/lima: use drm_gem_shmem_helpers
    
    Do not need to maintain our own shmem memory management
    code as drm_gem_shmem_helpers provides it. And we can
    also benifit from the work of others with shared code.
    
    This is also a preparation for implementing buffer madv.
    
    Reviewed-by: Vasily Khoruzhick <anarsoul@gmail.com>
    Signed-off-by: Qiang Yu <yuq825@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20191010140152.17747-2-yuq825@gmail.com

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 4da21353c3a2..4a62455fa0aa 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -3,7 +3,7 @@
 
 #include <linux/mm.h>
 #include <linux/sync_file.h>
-#include <linux/pfn_t.h>
+#include <linux/pagemap.h>
 
 #include <drm/drm_file.h>
 #include <drm/drm_syncobj.h>
@@ -13,40 +13,55 @@
 
 #include "lima_drv.h"
 #include "lima_gem.h"
-#include "lima_gem_prime.h"
 #include "lima_vm.h"
-#include "lima_object.h"
 
 int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
 			   u32 size, u32 flags, u32 *handle)
 {
 	int err;
-	struct lima_bo *bo;
-	struct lima_device *ldev = to_lima_dev(dev);
+	gfp_t mask;
+	struct drm_gem_shmem_object *shmem;
+	struct drm_gem_object *obj;
+	struct sg_table *sgt;
+
+	shmem = drm_gem_shmem_create(dev, size);
+	if (IS_ERR(shmem))
+		return PTR_ERR(shmem);
 
-	bo = lima_bo_create(ldev, size, flags, NULL);
-	if (IS_ERR(bo))
-		return PTR_ERR(bo);
+	obj = &shmem->base;
 
-	err = drm_gem_handle_create(file, &bo->gem, handle);
+	/* Mali Utgard GPU can only support 32bit address space */
+	mask = mapping_gfp_mask(obj->filp->f_mapping);
+	mask &= ~__GFP_HIGHMEM;
+	mask |= __GFP_DMA32;
+	mapping_set_gfp_mask(obj->filp->f_mapping, mask);
+
+	sgt = drm_gem_shmem_get_pages_sgt(obj);
+	if (IS_ERR(sgt)) {
+		err = PTR_ERR(sgt);
+		goto out;
+	}
 
+	err = drm_gem_handle_create(file, obj, handle);
+
+out:
 	/* drop reference from allocate - handle holds it now */
-	drm_gem_object_put_unlocked(&bo->gem);
+	drm_gem_object_put_unlocked(obj);
 
 	return err;
 }
 
-void lima_gem_free_object(struct drm_gem_object *obj)
+static void lima_gem_free_object(struct drm_gem_object *obj)
 {
 	struct lima_bo *bo = to_lima_bo(obj);
 
 	if (!list_empty(&bo->va))
 		dev_err(obj->dev->dev, "lima gem free bo still has va\n");
 
-	lima_bo_destroy(bo);
+	drm_gem_shmem_free_object(obj);
 }
 
-int lima_gem_object_open(struct drm_gem_object *obj, struct drm_file *file)
+static int lima_gem_object_open(struct drm_gem_object *obj, struct drm_file *file)
 {
 	struct lima_bo *bo = to_lima_bo(obj);
 	struct lima_drm_priv *priv = to_lima_drm_priv(file);
@@ -55,7 +70,7 @@ int lima_gem_object_open(struct drm_gem_object *obj, struct drm_file *file)
 	return lima_vm_bo_add(vm, bo, true);
 }
 
-void lima_gem_object_close(struct drm_gem_object *obj, struct drm_file *file)
+static void lima_gem_object_close(struct drm_gem_object *obj, struct drm_file *file)
 {
 	struct lima_bo *bo = to_lima_bo(obj);
 	struct lima_drm_priv *priv = to_lima_drm_priv(file);
@@ -64,13 +79,41 @@ void lima_gem_object_close(struct drm_gem_object *obj, struct drm_file *file)
 	lima_vm_bo_del(vm, bo);
 }
 
+static const struct drm_gem_object_funcs lima_gem_funcs = {
+	.free = lima_gem_free_object,
+	.open = lima_gem_object_open,
+	.close = lima_gem_object_close,
+	.print_info = drm_gem_shmem_print_info,
+	.pin = drm_gem_shmem_pin,
+	.unpin = drm_gem_shmem_unpin,
+	.get_sg_table = drm_gem_shmem_get_sg_table,
+	.vmap = drm_gem_shmem_vmap,
+	.vunmap = drm_gem_shmem_vunmap,
+	.mmap = drm_gem_shmem_mmap,
+};
+
+struct drm_gem_object *lima_gem_create_object(struct drm_device *dev, size_t size)
+{
+	struct lima_bo *bo;
+
+	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
+	if (!bo)
+		return NULL;
+
+	mutex_init(&bo->lock);
+	INIT_LIST_HEAD(&bo->va);
+
+	bo->base.base.funcs = &lima_gem_funcs;
+
+	return &bo->base.base;
+}
+
 int lima_gem_get_info(struct drm_file *file, u32 handle, u32 *va, u64 *offset)
 {
 	struct drm_gem_object *obj;
 	struct lima_bo *bo;
 	struct lima_drm_priv *priv = to_lima_drm_priv(file);
 	struct lima_vm *vm = priv->vm;
-	int err;
 
 	obj = drm_gem_object_lookup(file, handle);
 	if (!obj)
@@ -80,53 +123,9 @@ int lima_gem_get_info(struct drm_file *file, u32 handle, u32 *va, u64 *offset)
 
 	*va = lima_vm_get_va(vm, bo);
 
-	err = drm_gem_create_mmap_offset(obj);
-	if (!err)
-		*offset = drm_vma_node_offset_addr(&obj->vma_node);
+	*offset = drm_vma_node_offset_addr(&obj->vma_node);
 
 	drm_gem_object_put_unlocked(obj);
-	return err;
-}
-
-static vm_fault_t lima_gem_fault(struct vm_fault *vmf)
-{
-	struct vm_area_struct *vma = vmf->vma;
-	struct drm_gem_object *obj = vma->vm_private_data;
-	struct lima_bo *bo = to_lima_bo(obj);
-	pfn_t pfn;
-	pgoff_t pgoff;
-
-	/* We don't use vmf->pgoff since that has the fake offset: */
-	pgoff = (vmf->address - vma->vm_start) >> PAGE_SHIFT;
-	pfn = __pfn_to_pfn_t(page_to_pfn(bo->pages[pgoff]), PFN_DEV);
-
-	return vmf_insert_mixed(vma, vmf->address, pfn);
-}
-
-const struct vm_operations_struct lima_gem_vm_ops = {
-	.fault = lima_gem_fault,
-	.open = drm_gem_vm_open,
-	.close = drm_gem_vm_close,
-};
-
-void lima_set_vma_flags(struct vm_area_struct *vma)
-{
-	pgprot_t prot = vm_get_page_prot(vma->vm_flags);
-
-	vma->vm_flags |= VM_MIXEDMAP;
-	vma->vm_flags &= ~VM_PFNMAP;
-	vma->vm_page_prot = pgprot_writecombine(prot);
-}
-
-int lima_gem_mmap(struct file *filp, struct vm_area_struct *vma)
-{
-	int ret;
-
-	ret = drm_gem_mmap(filp, vma);
-	if (ret)
-		return ret;
-
-	lima_set_vma_flags(vma);
 	return 0;
 }
 
@@ -136,7 +135,7 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo,
 	int err = 0;
 
 	if (!write) {
-		err = dma_resv_reserve_shared(bo->gem.resv, 1);
+		err = dma_resv_reserve_shared(lima_bo_resv(bo), 1);
 		if (err)
 			return err;
 	}
@@ -145,7 +144,7 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo,
 	if (explicit)
 		return 0;
 
-	return drm_gem_fence_array_add_implicit(&task->deps, &bo->gem, write);
+	return drm_gem_fence_array_add_implicit(&task->deps, &bo->base.base, write);
 }
 
 static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
@@ -162,7 +161,7 @@ static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
 			continue;
 		}
 
-		ret = ww_mutex_lock_interruptible(&bos[i]->gem.resv->lock, ctx);
+		ret = ww_mutex_lock_interruptible(&lima_bo_resv(bos[i])->lock, ctx);
 		if (ret < 0) {
 			contended = i;
 			goto err;
@@ -174,15 +173,15 @@ static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
 
 err:
 	for (i--; i >= 0; i--)
-		ww_mutex_unlock(&bos[i]->gem.resv->lock);
+		ww_mutex_unlock(&lima_bo_resv(bos[i])->lock);
 
 	if (slow_locked >= 0)
-		ww_mutex_unlock(&bos[slow_locked]->gem.resv->lock);
+		ww_mutex_unlock(&lima_bo_resv(bos[slow_locked])->lock);
 
 	if (ret == -EDEADLK) {
 		/* we lost out in a seqno race, lock and retry.. */
 		ret = ww_mutex_lock_slow_interruptible(
-			&bos[contended]->gem.resv->lock, ctx);
+			&lima_bo_resv(bos[contended])->lock, ctx);
 		if (!ret) {
 			slow_locked = contended;
 			goto retry;
@@ -199,7 +198,7 @@ static void lima_gem_unlock_bos(struct lima_bo **bos, u32 nr_bos,
 	int i;
 
 	for (i = 0; i < nr_bos; i++)
-		ww_mutex_unlock(&bos[i]->gem.resv->lock);
+		ww_mutex_unlock(&lima_bo_resv(bos[i])->lock);
 	ww_acquire_fini(ctx);
 }
 
@@ -296,15 +295,15 @@ int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
 
 	for (i = 0; i < submit->nr_bos; i++) {
 		if (submit->bos[i].flags & LIMA_SUBMIT_BO_WRITE)
-			dma_resv_add_excl_fence(bos[i]->gem.resv, fence);
+			dma_resv_add_excl_fence(lima_bo_resv(bos[i]), fence);
 		else
-			dma_resv_add_shared_fence(bos[i]->gem.resv, fence);
+			dma_resv_add_shared_fence(lima_bo_resv(bos[i]), fence);
 	}
 
 	lima_gem_unlock_bos(bos, submit->nr_bos, &ctx);
 
 	for (i = 0; i < submit->nr_bos; i++)
-		drm_gem_object_put_unlocked(&bos[i]->gem);
+		drm_gem_object_put_unlocked(&bos[i]->base.base);
 
 	if (out_sync) {
 		drm_syncobj_replace_fence(out_sync, fence);
@@ -324,7 +323,7 @@ int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
 		if (!bos[i])
 			break;
 		lima_vm_bo_del(vm, bos[i]);
-		drm_gem_object_put_unlocked(&bos[i]->gem);
+		drm_gem_object_put_unlocked(&bos[i]->base.base);
 	}
 	if (out_sync)
 		drm_syncobj_put(out_sync);

commit 574cc4539762561d96b456dbc0544d8898bd4c6e
Merge: 3c2edc36a774 945b584c94f8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 19 16:24:24 2019 -0700

    Merge tag 'drm-next-2019-09-18' of git://anongit.freedesktop.org/drm/drm
    
    Pull drm updates from Dave Airlie:
     "This is the main pull request for 5.4-rc1 merge window. I don't think
      there is anything outstanding so next week should just be fixes, but
      we'll see if I missed anything. I landed some fixes earlier in the
      week but got delayed writing summary and sending it out, due to a mix
      of sick kid and jetlag!
    
      There are some fixes pending, but I'd rather get the main merge out of
      the way instead of delaying it longer.
    
      It's also pretty large in commit count and new amd header file size.
      The largest thing is four new amdgpu products (navi12/14, arcturus and
      renoir APU support).
    
      Otherwise it's pretty much lots of work across the board, i915 has
      started landing tigerlake support, lots of icelake fixes and lots of
      locking reworking for future gpu support, lots of header file rework
      (drmP.h is nearly gone), some old legacy hacks (DRM_WAIT_ON) have been
      put into the places they are needed.
    
      uapi:
       - content protection type property for HDCP
    
      core:
       - rework include dependencies
       - lots of drmP.h removals
       - link rate calculation robustness fix
       - make fb helper map only when required
       - add connector->DDC adapter link
       - DRM_WAIT_ON removed
       - drop DRM_AUTH usage from drivers
    
      dma-buf:
       - reservation object fence helper
    
      dma-fence:
       - shrink dma_fence struct
       - merge signal functions
       - store timestamps in dma_fence
       - selftests
    
      ttm:
       - embed drm_get_object struct into ttm_buffer_object
       - release_notify callback
    
      bridges:
       - sii902x - audio graph card support
       - tc358767 - aux data handling rework
       - ti-snd64dsi86 - debugfs support, DSI mode flags support
    
      panels:
       - Support for GiantPlus GPM940B0, Sharp LQ070Y3DG3B, Ortustech
         COM37H3M, Novatek NT39016, Sharp LS020B1DD01D, Raydium RM67191, Boe
         Himax8279d, Sharp LD-D5116Z01B
       - TI nspire, NEC NL8048HL11, LG Philips LB035Q02, Sharp LS037V7DW01,
         Sony ACX565AKM, Toppoly TD028TTEC1 Toppoly TD043MTEA1
    
      i915:
       - Initial tigerlake platform support
       - Locking simplification work, general all over refactoring.
       - Selftests
       - HDCP debug info improvements
       - DSI properties
       - Icelake display PLL fixes, colorspace fixes, bandwidth fixes, DSI
         suspend/resume
       - GuC fixes
       - Perf fixes
       - ElkhartLake enablement
       - DP MST fixes
       - GVT - command parser enhancements
    
      amdgpu:
       - add wipe memory on release flag for buffer creation
       - Navi12/14 support (may be marked experimental)
       - Arcturus support
       - Renoir APU support
       - mclk DPM for Navi
       - DC display fixes
       - Raven scatter/gather support
       - RAS support for GFX
       - Navi12 + Arcturus power features
       - GPU reset for Picasso
       - smu11 i2c controller support
    
      amdkfd:
       - navi12/14 support
       - Arcturus support
    
      radeon:
       - kexec fix
    
      nouveau:
       - improved display color management
       - detect lack of GPU power cables
    
      vmwgfx:
       - evicition priority support
       - remove unused security feature
    
      msm:
       - msm8998 display support
       - better async commit support for cursor updates
    
      etnaviv:
       - per-process address space support
       - performance counter fixes
       - softpin support
    
      mcde:
       - DCS transfers fix
    
      exynos:
       - drmP.h cleanup
    
      lima:
       - reduce logging
    
      kirin:
       - misc clenaups
    
      komeda:
       - dual-link support
       - DT memory regions
    
      hisilicon:
       - misc fixes
    
      imx:
       - IPUv3 image converter fixes
       - 32-bit RGB V4L2 pixel format support
    
      ingenic:
       - more support for panel related cases
    
      mgag200:
       - cursor support fix
    
      panfrost:
       - export GPU features register to userspace
       - gpu heap allocations
       - per-fd address space support
    
      pl111:
       - CLD pads wiring support removed from DT
    
      rockchip:
       - rework to use DRM PSR helpers
       - fix bug in VOP_WIN_GET macro
       - DSI DT binding rework
    
      sun4i:
       - improve support for color encoding and range
       - DDC enabled GPIO
    
      tinydrm:
       - rework SPI support
       - improve MIPI-DBI support
       - moved to drm/tiny
    
      vkms:
       - rework CRC tracking
    
      dw-hdmi:
       - get_eld and i2s improvements
    
      gm12u320:
       - misc fixes
    
      meson:
       - global code cleanup
       - vpu feature detect
    
      omap:
       - alpha/pixel blend mode properties
    
      rcar-du:
       - misc fixes"
    
    * tag 'drm-next-2019-09-18' of git://anongit.freedesktop.org/drm/drm: (2112 commits)
      drm/nouveau/bar/gm20b: Avoid BAR1 teardown during init
      drm/nouveau: Fix ordering between TTM and GEM release
      drm/nouveau/prime: Extend DMA reservation object lock
      drm/nouveau: Fix fallout from reservation object rework
      drm/nouveau/kms/nv50-: Don't create MSTMs for eDP connectors
      drm/i915: Use NOEVICT for first pass on attemping to pin a GGTT mmap
      drm/i915: to make vgpu ppgtt notificaiton as atomic operation
      drm/i915: Flush the existing fence before GGTT read/write
      drm/i915: Hold irq-off for the entire fake lock period
      drm/i915/gvt: update RING_START reg of vGPU when the context is submitted to i915
      drm/i915/gvt: update vgpu workload head pointer correctly
      drm/mcde: Fix DSI transfers
      drm/msm: Use the correct dma_sync calls harder
      drm/msm: remove unlikely() from WARN_ON() conditions
      drm/msm/dsi: Fix return value check for clk_get_parent
      drm/msm: add atomic traces
      drm/msm/dpu: async commit support
      drm/msm: async commit support
      drm/msm: split power control from prepare/complete_commit
      drm/msm: add kms->flush_commit()
      ...

commit 21670bd78a25001cf8ef2679b378c73fb73b904f
Author: Vasily Khoruzhick <anarsoul@gmail.com>
Date:   Sat Sep 7 19:48:00 2019 -0700

    drm/lima: fix lima_gem_wait() return value
    
    drm_gem_reservation_object_wait() returns 0 if it succeeds and -ETIME
    if it timeouts, but lima driver assumed that 0 is error.
    
    Cc: stable@vger.kernel.org
    Fixes: a1d2a6339961e ("drm/lima: driver for ARM Mali4xx GPUs")
    Signed-off-by: Vasily Khoruzhick <anarsoul@gmail.com>
    Signed-off-by: Qiang Yu <yuq825@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190908024800.23229-1-anarsoul@gmail.com

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 477c0f766663..b609dc030d6c 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -342,7 +342,7 @@ int lima_gem_wait(struct drm_file *file, u32 handle, u32 op, s64 timeout_ns)
 	timeout = drm_timeout_abs_to_jiffies(timeout_ns);
 
 	ret = drm_gem_reservation_object_wait(file, handle, write, timeout);
-	if (ret == 0)
+	if (ret == -ETIME)
 		ret = timeout ? -ETIMEDOUT : -EBUSY;
 
 	return ret;

commit 52791eeec1d9f4a7e7fe08aaba0b1553149d93bc
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Aug 11 10:06:32 2019 +0200

    dma-buf: rename reservation_object to dma_resv
    
    Be more consistent with the naming of the other DMA-buf objects.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Link: https://patchwork.freedesktop.org/patch/323401/

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index fd1a024703d2..ff3d9acc24fc 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -136,7 +136,7 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo,
 	int err = 0;
 
 	if (!write) {
-		err = reservation_object_reserve_shared(bo->gem.resv, 1);
+		err = dma_resv_reserve_shared(bo->gem.resv, 1);
 		if (err)
 			return err;
 	}
@@ -296,9 +296,9 @@ int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
 
 	for (i = 0; i < submit->nr_bos; i++) {
 		if (submit->bos[i].flags & LIMA_SUBMIT_BO_WRITE)
-			reservation_object_add_excl_fence(bos[i]->gem.resv, fence);
+			dma_resv_add_excl_fence(bos[i]->gem.resv, fence);
 		else
-			reservation_object_add_shared_fence(bos[i]->gem.resv, fence);
+			dma_resv_add_shared_fence(bos[i]->gem.resv, fence);
 	}
 
 	lima_gem_unlock_bos(bos, submit->nr_bos, &ctx);
@@ -341,7 +341,7 @@ int lima_gem_wait(struct drm_file *file, u32 handle, u32 op, s64 timeout_ns)
 
 	timeout = drm_timeout_abs_to_jiffies(timeout_ns);
 
-	ret = drm_gem_reservation_object_wait(file, handle, write, timeout);
+	ret = drm_gem_dma_resv_wait(file, handle, write, timeout);
 	if (ret == 0)
 		ret = timeout ? -ETIMEDOUT : -EBUSY;
 

commit 0fbbd27e5ab18a0d2bd91e63ec9d16349d42d5bf
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Jun 14 22:35:59 2019 +0200

    drm/lima: Drop resv argument from lima_bo_create_struct
    
    It was only used for prime import, which is now handled by
    drm_prime.c.
    
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Reviewed-by: Emil Velikov <emil.velikov@collabora.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Qiang Yu <yuq825@gmail.com>
    Cc: lima@lists.freedesktop.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20190614203615.12639-44-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 477c0f766663..fd1a024703d2 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -24,7 +24,7 @@ int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
 	struct lima_bo *bo;
 	struct lima_device *ldev = to_lima_dev(dev);
 
-	bo = lima_bo_create(ldev, size, flags, NULL, NULL);
+	bo = lima_bo_create(ldev, size, flags, NULL);
 	if (IS_ERR(bo))
 		return PTR_ERR(bo);
 

commit f3fb20074e02865e1724c586eae46a77a7f2266b
Author: Eric Anholt <eric@anholt.net>
Date:   Mon Apr 1 15:26:35 2019 -0700

    drm/lima: Use the drm_gem_fence_array_add helpers for our deps.
    
    It's a pretty direct port of what I did for v3d.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190401222635.25013-8-eric@anholt.net
    Reviewed-and-tested-by: Qiang Yu <yuq825@gmail.com>

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 1d69498bc17e..477c0f766663 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -145,40 +145,7 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo,
 	if (explicit)
 		return 0;
 
-	/* implicit sync use bo fence in resv obj */
-	if (write) {
-		unsigned nr_fences;
-		struct dma_fence **fences;
-		int i;
-
-		err = reservation_object_get_fences_rcu(
-			bo->gem.resv, NULL, &nr_fences, &fences);
-		if (err || !nr_fences)
-			return err;
-
-		for (i = 0; i < nr_fences; i++) {
-			err = lima_sched_task_add_dep(task, fences[i]);
-			if (err)
-				break;
-		}
-
-		/* for error case free remaining fences */
-		for ( ; i < nr_fences; i++)
-			dma_fence_put(fences[i]);
-
-		kfree(fences);
-	} else {
-		struct dma_fence *fence;
-
-		fence = reservation_object_get_excl_rcu(bo->gem.resv);
-		if (fence) {
-			err = lima_sched_task_add_dep(task, fence);
-			if (err)
-				dma_fence_put(fence);
-		}
-	}
-
-	return err;
+	return drm_gem_fence_array_add_implicit(&task->deps, &bo->gem, write);
 }
 
 static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
@@ -251,7 +218,7 @@ static int lima_gem_add_deps(struct drm_file *file, struct lima_submit *submit)
 		if (err)
 			return err;
 
-		err = lima_sched_task_add_dep(submit->task, fence);
+		err = drm_gem_fence_array_add(&submit->task->deps, fence);
 		if (err) {
 			dma_fence_put(fence);
 			return err;

commit 80bb8d983224337b713a93babfffedb376031034
Author: Qiang Yu <yuq825@gmail.com>
Date:   Tue Apr 9 08:36:17 2019 +0800

    drm/lima: include used header file explicitly
    
    To prevent build fail on some platform which does
    not have it in the include file chain.
    
    Reviewed-by: Neil Armstrong <narmstrong@baylibre.com>
    Suggested-by: Randy Dunlap <rdunlap@infradead.org>
    Fixes: a1d2a6339961 ("drm/lima: driver for ARM Mali4xx GPUs")
    Signed-off-by: Qiang Yu <yuq825@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190409003617.4470-2-yuq825@gmail.com

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 2d3cf96f6c58..1d69498bc17e 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -1,6 +1,7 @@
 // SPDX-License-Identifier: GPL-2.0 OR MIT
 /* Copyright 2017-2019 Qiang Yu <yuq825@gmail.com> */
 
+#include <linux/mm.h>
 #include <linux/sync_file.h>
 #include <linux/pfn_t.h>
 

commit a1d2a6339961efc078208dc3b2f006e9e9a8e119
Author: Qiang Yu <yuq825@gmail.com>
Date:   Sat Mar 9 20:20:12 2019 +0800

    drm/lima: driver for ARM Mali4xx GPUs
    
    - Mali 4xx GPUs have two kinds of processors GP and PP. GP is for
      OpenGL vertex shader processing and PP is for fragment shader
      processing. Each processor has its own MMU so prcessors work in
      virtual address space.
    - There's only one GP but multiple PP (max 4 for mali 400 and 8
      for mali 450) in the same mali 4xx GPU. All PPs are grouped
      togather to handle a single fragment shader task divided by
      FB output tiled pixels. Mali 400 user space driver is
      responsible for assign target tiled pixels to each PP, but mali
      450 has a HW module called DLBU to dynamically balance each
      PP's load.
    - User space driver allocate buffer object and map into GPU
      virtual address space, upload command stream and draw data with
      CPU mmap of the buffer object, then submit task to GP/PP with
      a register frame indicating where is the command stream and misc
      settings.
    - There's no command stream validation/relocation due to each user
      process has its own GPU virtual address space. GP/PP's MMU switch
      virtual address space before running two tasks from different
      user process. Error or evil user space code just get MMU fault
      or GP/PP error IRQ, then the HW/SW will be recovered.
    - Use GEM+shmem for MM. Currently just alloc and pin memory when
      gem object creation. GPU vm map of the buffer is also done in
      the alloc stage in kernel space. We may delay the memory
      allocation and real GPU vm map to command submission stage in the
      furture as improvement.
    - Use drm_sched for GPU task schedule. Each OpenGL context should
      have a lima context object in the kernel to distinguish tasks
      from different user. drm_sched gets task from each lima context
      in a fair way.
    
    mesa driver can be found here before upstreamed:
    https://gitlab.freedesktop.org/lima/mesa
    
    v8:
    - add comments for in_sync
    - fix ctx free miss mutex unlock
    
    v7:
    - remove lima_fence_ops with default value
    - move fence slab create to device probe
    - check pad ioctl args to be zero
    - add comments for user/kernel interface
    
    v6:
    - fix comments by checkpatch.pl
    
    v5:
    - export gp/pp version to userspace
    - rebase on drm-misc-next
    
    v4:
    - use get param interface to get info
    - separate context create/free ioctl
    - remove unused max sched task param
    - update copyright time
    - use xarray instead of idr
    - stop using drmP.h
    
    v3:
    - fix comments from kbuild robot
    - restrict supported arch to tested ones
    
    v2:
    - fix syscall argument check
    - fix job finish fence leak since kernel 5.0
    - use drm syncobj to replace native fence
    - move buffer object GPU va map into kernel
    - reserve syscall argument space for future info
    - remove kernel gem modifier
    - switch TTM back to GEM+shmem MM
    - use time based io poll
    - use whole register name
    - adopt gem reservation obj integration
    - use drm_timeout_abs_to_jiffies
    
    Cc: Eric Anholt <eric@anholt.net>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Christian König <ckoenig.leichtzumerken@gmail.com>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Alex Deucher <alexdeucher@gmail.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Cc: Rob Clark <robdclark@gmail.com>
    Cc: Dave Airlie <airlied@gmail.com>
    Signed-off-by: Andreas Baierl <ichgeh@imkreisrum.de>
    Signed-off-by: Erico Nunes <nunes.erico@gmail.com>
    Signed-off-by: Heiko Stuebner <heiko@sntech.de>
    Signed-off-by: Marek Vasut <marex@denx.de>
    Signed-off-by: Neil Armstrong <narmstrong@baylibre.com>
    Signed-off-by: Simon Shields <simon@lineageos.org>
    Signed-off-by: Vasily Khoruzhick <anarsoul@gmail.com>
    Signed-off-by: Qiang Yu <yuq825@gmail.com>
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Reviewed-by: Rob Herring <robh@kerrnel.org>
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/291200/

diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
new file mode 100644
index 000000000000..2d3cf96f6c58
--- /dev/null
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -0,0 +1,381 @@
+// SPDX-License-Identifier: GPL-2.0 OR MIT
+/* Copyright 2017-2019 Qiang Yu <yuq825@gmail.com> */
+
+#include <linux/sync_file.h>
+#include <linux/pfn_t.h>
+
+#include <drm/drm_file.h>
+#include <drm/drm_syncobj.h>
+#include <drm/drm_utils.h>
+
+#include <drm/lima_drm.h>
+
+#include "lima_drv.h"
+#include "lima_gem.h"
+#include "lima_gem_prime.h"
+#include "lima_vm.h"
+#include "lima_object.h"
+
+int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
+			   u32 size, u32 flags, u32 *handle)
+{
+	int err;
+	struct lima_bo *bo;
+	struct lima_device *ldev = to_lima_dev(dev);
+
+	bo = lima_bo_create(ldev, size, flags, NULL, NULL);
+	if (IS_ERR(bo))
+		return PTR_ERR(bo);
+
+	err = drm_gem_handle_create(file, &bo->gem, handle);
+
+	/* drop reference from allocate - handle holds it now */
+	drm_gem_object_put_unlocked(&bo->gem);
+
+	return err;
+}
+
+void lima_gem_free_object(struct drm_gem_object *obj)
+{
+	struct lima_bo *bo = to_lima_bo(obj);
+
+	if (!list_empty(&bo->va))
+		dev_err(obj->dev->dev, "lima gem free bo still has va\n");
+
+	lima_bo_destroy(bo);
+}
+
+int lima_gem_object_open(struct drm_gem_object *obj, struct drm_file *file)
+{
+	struct lima_bo *bo = to_lima_bo(obj);
+	struct lima_drm_priv *priv = to_lima_drm_priv(file);
+	struct lima_vm *vm = priv->vm;
+
+	return lima_vm_bo_add(vm, bo, true);
+}
+
+void lima_gem_object_close(struct drm_gem_object *obj, struct drm_file *file)
+{
+	struct lima_bo *bo = to_lima_bo(obj);
+	struct lima_drm_priv *priv = to_lima_drm_priv(file);
+	struct lima_vm *vm = priv->vm;
+
+	lima_vm_bo_del(vm, bo);
+}
+
+int lima_gem_get_info(struct drm_file *file, u32 handle, u32 *va, u64 *offset)
+{
+	struct drm_gem_object *obj;
+	struct lima_bo *bo;
+	struct lima_drm_priv *priv = to_lima_drm_priv(file);
+	struct lima_vm *vm = priv->vm;
+	int err;
+
+	obj = drm_gem_object_lookup(file, handle);
+	if (!obj)
+		return -ENOENT;
+
+	bo = to_lima_bo(obj);
+
+	*va = lima_vm_get_va(vm, bo);
+
+	err = drm_gem_create_mmap_offset(obj);
+	if (!err)
+		*offset = drm_vma_node_offset_addr(&obj->vma_node);
+
+	drm_gem_object_put_unlocked(obj);
+	return err;
+}
+
+static vm_fault_t lima_gem_fault(struct vm_fault *vmf)
+{
+	struct vm_area_struct *vma = vmf->vma;
+	struct drm_gem_object *obj = vma->vm_private_data;
+	struct lima_bo *bo = to_lima_bo(obj);
+	pfn_t pfn;
+	pgoff_t pgoff;
+
+	/* We don't use vmf->pgoff since that has the fake offset: */
+	pgoff = (vmf->address - vma->vm_start) >> PAGE_SHIFT;
+	pfn = __pfn_to_pfn_t(page_to_pfn(bo->pages[pgoff]), PFN_DEV);
+
+	return vmf_insert_mixed(vma, vmf->address, pfn);
+}
+
+const struct vm_operations_struct lima_gem_vm_ops = {
+	.fault = lima_gem_fault,
+	.open = drm_gem_vm_open,
+	.close = drm_gem_vm_close,
+};
+
+void lima_set_vma_flags(struct vm_area_struct *vma)
+{
+	pgprot_t prot = vm_get_page_prot(vma->vm_flags);
+
+	vma->vm_flags |= VM_MIXEDMAP;
+	vma->vm_flags &= ~VM_PFNMAP;
+	vma->vm_page_prot = pgprot_writecombine(prot);
+}
+
+int lima_gem_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	int ret;
+
+	ret = drm_gem_mmap(filp, vma);
+	if (ret)
+		return ret;
+
+	lima_set_vma_flags(vma);
+	return 0;
+}
+
+static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo,
+			    bool write, bool explicit)
+{
+	int err = 0;
+
+	if (!write) {
+		err = reservation_object_reserve_shared(bo->gem.resv, 1);
+		if (err)
+			return err;
+	}
+
+	/* explicit sync use user passed dep fence */
+	if (explicit)
+		return 0;
+
+	/* implicit sync use bo fence in resv obj */
+	if (write) {
+		unsigned nr_fences;
+		struct dma_fence **fences;
+		int i;
+
+		err = reservation_object_get_fences_rcu(
+			bo->gem.resv, NULL, &nr_fences, &fences);
+		if (err || !nr_fences)
+			return err;
+
+		for (i = 0; i < nr_fences; i++) {
+			err = lima_sched_task_add_dep(task, fences[i]);
+			if (err)
+				break;
+		}
+
+		/* for error case free remaining fences */
+		for ( ; i < nr_fences; i++)
+			dma_fence_put(fences[i]);
+
+		kfree(fences);
+	} else {
+		struct dma_fence *fence;
+
+		fence = reservation_object_get_excl_rcu(bo->gem.resv);
+		if (fence) {
+			err = lima_sched_task_add_dep(task, fence);
+			if (err)
+				dma_fence_put(fence);
+		}
+	}
+
+	return err;
+}
+
+static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
+			     struct ww_acquire_ctx *ctx)
+{
+	int i, ret = 0, contended, slow_locked = -1;
+
+	ww_acquire_init(ctx, &reservation_ww_class);
+
+retry:
+	for (i = 0; i < nr_bos; i++) {
+		if (i == slow_locked) {
+			slow_locked = -1;
+			continue;
+		}
+
+		ret = ww_mutex_lock_interruptible(&bos[i]->gem.resv->lock, ctx);
+		if (ret < 0) {
+			contended = i;
+			goto err;
+		}
+	}
+
+	ww_acquire_done(ctx);
+	return 0;
+
+err:
+	for (i--; i >= 0; i--)
+		ww_mutex_unlock(&bos[i]->gem.resv->lock);
+
+	if (slow_locked >= 0)
+		ww_mutex_unlock(&bos[slow_locked]->gem.resv->lock);
+
+	if (ret == -EDEADLK) {
+		/* we lost out in a seqno race, lock and retry.. */
+		ret = ww_mutex_lock_slow_interruptible(
+			&bos[contended]->gem.resv->lock, ctx);
+		if (!ret) {
+			slow_locked = contended;
+			goto retry;
+		}
+	}
+	ww_acquire_fini(ctx);
+
+	return ret;
+}
+
+static void lima_gem_unlock_bos(struct lima_bo **bos, u32 nr_bos,
+				struct ww_acquire_ctx *ctx)
+{
+	int i;
+
+	for (i = 0; i < nr_bos; i++)
+		ww_mutex_unlock(&bos[i]->gem.resv->lock);
+	ww_acquire_fini(ctx);
+}
+
+static int lima_gem_add_deps(struct drm_file *file, struct lima_submit *submit)
+{
+	int i, err;
+
+	for (i = 0; i < ARRAY_SIZE(submit->in_sync); i++) {
+		struct dma_fence *fence = NULL;
+
+		if (!submit->in_sync[i])
+			continue;
+
+		err = drm_syncobj_find_fence(file, submit->in_sync[i],
+					     0, 0, &fence);
+		if (err)
+			return err;
+
+		err = lima_sched_task_add_dep(submit->task, fence);
+		if (err) {
+			dma_fence_put(fence);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
+{
+	int i, err = 0;
+	struct ww_acquire_ctx ctx;
+	struct lima_drm_priv *priv = to_lima_drm_priv(file);
+	struct lima_vm *vm = priv->vm;
+	struct drm_syncobj *out_sync = NULL;
+	struct dma_fence *fence;
+	struct lima_bo **bos = submit->lbos;
+
+	if (submit->out_sync) {
+		out_sync = drm_syncobj_find(file, submit->out_sync);
+		if (!out_sync)
+			return -ENOENT;
+	}
+
+	for (i = 0; i < submit->nr_bos; i++) {
+		struct drm_gem_object *obj;
+		struct lima_bo *bo;
+
+		obj = drm_gem_object_lookup(file, submit->bos[i].handle);
+		if (!obj) {
+			err = -ENOENT;
+			goto err_out0;
+		}
+
+		bo = to_lima_bo(obj);
+
+		/* increase refcnt of gpu va map to prevent unmapped when executing,
+		 * will be decreased when task done
+		 */
+		err = lima_vm_bo_add(vm, bo, false);
+		if (err) {
+			drm_gem_object_put_unlocked(obj);
+			goto err_out0;
+		}
+
+		bos[i] = bo;
+	}
+
+	err = lima_gem_lock_bos(bos, submit->nr_bos, &ctx);
+	if (err)
+		goto err_out0;
+
+	err = lima_sched_task_init(
+		submit->task, submit->ctx->context + submit->pipe,
+		bos, submit->nr_bos, vm);
+	if (err)
+		goto err_out1;
+
+	err = lima_gem_add_deps(file, submit);
+	if (err)
+		goto err_out2;
+
+	for (i = 0; i < submit->nr_bos; i++) {
+		err = lima_gem_sync_bo(
+			submit->task, bos[i],
+			submit->bos[i].flags & LIMA_SUBMIT_BO_WRITE,
+			submit->flags & LIMA_SUBMIT_FLAG_EXPLICIT_FENCE);
+		if (err)
+			goto err_out2;
+	}
+
+	fence = lima_sched_context_queue_task(
+		submit->ctx->context + submit->pipe, submit->task);
+
+	for (i = 0; i < submit->nr_bos; i++) {
+		if (submit->bos[i].flags & LIMA_SUBMIT_BO_WRITE)
+			reservation_object_add_excl_fence(bos[i]->gem.resv, fence);
+		else
+			reservation_object_add_shared_fence(bos[i]->gem.resv, fence);
+	}
+
+	lima_gem_unlock_bos(bos, submit->nr_bos, &ctx);
+
+	for (i = 0; i < submit->nr_bos; i++)
+		drm_gem_object_put_unlocked(&bos[i]->gem);
+
+	if (out_sync) {
+		drm_syncobj_replace_fence(out_sync, fence);
+		drm_syncobj_put(out_sync);
+	}
+
+	dma_fence_put(fence);
+
+	return 0;
+
+err_out2:
+	lima_sched_task_fini(submit->task);
+err_out1:
+	lima_gem_unlock_bos(bos, submit->nr_bos, &ctx);
+err_out0:
+	for (i = 0; i < submit->nr_bos; i++) {
+		if (!bos[i])
+			break;
+		lima_vm_bo_del(vm, bos[i]);
+		drm_gem_object_put_unlocked(&bos[i]->gem);
+	}
+	if (out_sync)
+		drm_syncobj_put(out_sync);
+	return err;
+}
+
+int lima_gem_wait(struct drm_file *file, u32 handle, u32 op, s64 timeout_ns)
+{
+	bool write = op & LIMA_GEM_WAIT_WRITE;
+	long ret, timeout;
+
+	if (!op)
+		return 0;
+
+	timeout = drm_timeout_abs_to_jiffies(timeout_ns);
+
+	ret = drm_gem_reservation_object_wait(file, handle, write, timeout);
+	if (ret == 0)
+		ret = timeout ? -ETIMEDOUT : -EBUSY;
+
+	return ret;
+}
