commit 2636a5172da2eadee8190fad8d82d25d9a276525
Author: Ben Dooks <ben.dooks@codethink.co.uk>
Date:   Wed Oct 9 13:14:47 2019 +0100

    drm/scheduler: make unexported items static
    
    The drm_sched_fence_ops_{scheduled,finished} are not exported
    from the file so make them static to avoid the following
    warnings from sparse:
    
    drivers/gpu/drm/scheduler/sched_fence.c:131:28: warning: symbol 'drm_sched_fence_ops_scheduled' was not declared. Should it be static?
    drivers/gpu/drm/scheduler/sched_fence.c:137:28: warning: symbol 'drm_sched_fence_ops_finished' was not declared. Should it be static?
    
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20191009121447.31017-1-ben.dooks@codethink.co.uk

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
index 54977408f574..8b45c3a1b84e 100644
--- a/drivers/gpu/drm/scheduler/sched_fence.c
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -128,13 +128,13 @@ static void drm_sched_fence_release_finished(struct dma_fence *f)
 	dma_fence_put(&fence->scheduled);
 }
 
-const struct dma_fence_ops drm_sched_fence_ops_scheduled = {
+static const struct dma_fence_ops drm_sched_fence_ops_scheduled = {
 	.get_driver_name = drm_sched_fence_get_driver_name,
 	.get_timeline_name = drm_sched_fence_get_timeline_name,
 	.release = drm_sched_fence_release_scheduled,
 };
 
-const struct dma_fence_ops drm_sched_fence_ops_finished = {
+static const struct dma_fence_ops drm_sched_fence_ops_finished = {
 	.get_driver_name = drm_sched_fence_get_driver_name,
 	.get_timeline_name = drm_sched_fence_get_timeline_name,
 	.release = drm_sched_fence_release_finished,

commit 7c1be93c8e983077b8ec964497f09f2bfb6e7b29
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Sun Jun 30 08:19:14 2019 +0200

    drm/scheduler: drop use of drmP.h
    
    Drop use of the deprecated drmP.h header file.
    Fix fallout.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Acked-by: Emil Velikov <emil.velikov@collabora.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Alex Deucher <alexander.deucher@amd.com>
    Cc: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Cc: Huang Rui <ray.huang@amd.com>
    Cc: Eric Anholt <eric@anholt.net>
    Cc: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
    Cc: Sharat Masetty <smasetty@codeaurora.org>
    Cc: Nathan Chancellor <natechancellor@gmail.com>
    Cc: Nayan Deshmukh <nayan26deshmukh@gmail.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190630061922.7254-26-sam@ravnborg.org

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
index d8d2dff9ea2f..54977408f574 100644
--- a/drivers/gpu/drm/scheduler/sched_fence.c
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -22,9 +22,11 @@
  */
 
 #include <linux/kthread.h>
-#include <linux/wait.h>
+#include <linux/module.h>
 #include <linux/sched.h>
-#include <drm/drmP.h>
+#include <linux/slab.h>
+#include <linux/wait.h>
+
 #include <drm/gpu_scheduler.h>
 
 static struct kmem_cache *sched_fence_slab;

commit 068c330419ffb3422a43cb7d34351f1ef033950f
Author: Nayan Deshmukh <nayan26deshmukh@gmail.com>
Date:   Fri Jul 20 17:51:06 2018 +0530

    drm/scheduler: remove sched field from the entity
    
    The scheduler of the entity is decided by the run queue on which
    it is queued. This patch avoids us the effort required to maintain
    a sync between rq and sched field when we start shifting entites
    among different rqs.
    
    Signed-off-by: Nayan Deshmukh <nayan26deshmukh@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
index 45d9c3affbea..d8d2dff9ea2f 100644
--- a/drivers/gpu/drm/scheduler/sched_fence.c
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -161,7 +161,7 @@ struct drm_sched_fence *drm_sched_fence_create(struct drm_sched_entity *entity,
 		return NULL;
 
 	fence->owner = owner;
-	fence->sched = entity->sched;
+	fence->sched = entity->rq->sched;
 	spin_lock_init(&fence->lock);
 
 	seq = atomic_inc_return(&entity->fence_seq);

commit 99e227cb03970287958d05ed41589cc82383534d
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Thu May 3 16:25:54 2018 +0200

    drm: Remove unecessary dma_fence_ops
    
    dma_fence_default_wait is the default now, same for the trivial
    enable_signaling implementation.
    
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Gustavo Padovan <gustavo@padovan.org>
    Cc: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
    Cc: Sean Paul <seanpaul@chromium.org>
    Cc: David Airlie <airlied@linux.ie>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180503142603.28513-7-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
index df4461648e3f..45d9c3affbea 100644
--- a/drivers/gpu/drm/scheduler/sched_fence.c
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -81,11 +81,6 @@ static const char *drm_sched_fence_get_timeline_name(struct dma_fence *f)
 	return (const char *)fence->sched->name;
 }
 
-static bool drm_sched_fence_enable_signaling(struct dma_fence *f)
-{
-	return true;
-}
-
 /**
  * drm_sched_fence_free - free up the fence memory
  *
@@ -134,18 +129,12 @@ static void drm_sched_fence_release_finished(struct dma_fence *f)
 const struct dma_fence_ops drm_sched_fence_ops_scheduled = {
 	.get_driver_name = drm_sched_fence_get_driver_name,
 	.get_timeline_name = drm_sched_fence_get_timeline_name,
-	.enable_signaling = drm_sched_fence_enable_signaling,
-	.signaled = NULL,
-	.wait = dma_fence_default_wait,
 	.release = drm_sched_fence_release_scheduled,
 };
 
 const struct dma_fence_ops drm_sched_fence_ops_finished = {
 	.get_driver_name = drm_sched_fence_get_driver_name,
 	.get_timeline_name = drm_sched_fence_get_timeline_name,
-	.enable_signaling = drm_sched_fence_enable_signaling,
-	.signaled = NULL,
-	.wait = dma_fence_default_wait,
 	.release = drm_sched_fence_release_finished,
 };
 

commit 52bf20f414bc34899203307034227ccc95d6adb3
Author: Emily Deng <Emily.Deng@amd.com>
Date:   Wed May 23 15:53:03 2018 +0800

    drm/sched: add rcu_barrier after entity fini
    
    To free the fence from the amdgpu_fence_slab, need twice call_rcu, to avoid
    the amdgpu_fence_slab_fini call kmem_cache_destroy(amdgpu_fence_slab) before
    kmem_cache_free(amdgpu_fence_slab, fence), add rcu_barrier after drm_sched_entity_fini.
    
    The kmem_cache_free(amdgpu_fence_slab, fence)'s call trace as below:
    1.drm_sched_entity_fini ->
    drm_sched_entity_cleanup ->
    dma_fence_put(entity->last_scheduled) ->
    drm_sched_fence_release_finished ->
    drm_sched_fence_release_scheduled ->
    call_rcu(&fence->finished.rcu, drm_sched_fence_free)
    
    2.drm_sched_fence_free ->
    dma_fence_put(fence->parent) ->
    amdgpu_fence_release ->
    call_rcu(&f->rcu, amdgpu_fence_free) ->
    kmem_cache_free(amdgpu_fence_slab, fence);
    
    v2:put the barrier before the kmem_cache_destroy
    v3:put the dma_fence_put(fence->parent) before call_rcu in
    drm_sched_fence_release_scheduled
    
    Signed-off-by: Emily Deng <Emily.Deng@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
index 786b47f15783..df4461648e3f 100644
--- a/drivers/gpu/drm/scheduler/sched_fence.c
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -98,7 +98,6 @@ static void drm_sched_fence_free(struct rcu_head *rcu)
 	struct dma_fence *f = container_of(rcu, struct dma_fence, rcu);
 	struct drm_sched_fence *fence = to_drm_sched_fence(f);
 
-	dma_fence_put(fence->parent);
 	kmem_cache_free(sched_fence_slab, fence);
 }
 
@@ -114,6 +113,7 @@ static void drm_sched_fence_release_scheduled(struct dma_fence *f)
 {
 	struct drm_sched_fence *fence = to_drm_sched_fence(f);
 
+	dma_fence_put(fence->parent);
 	call_rcu(&fence->finished.rcu, drm_sched_fence_free);
 }
 

commit 652470ac55543fbbdcbce25492a7e370d23a38a0
Author: Nayan Deshmukh <nayan26deshmukh@gmail.com>
Date:   Wed May 16 18:54:18 2018 +0530

    drm/scheduler: fix function name prefix in comments
    
    That got missed while moving the files outside of amdgpu.
    
    Signed-off-by: Nayan Deshmukh <nayan26deshmukh@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
index 69aab086b913..786b47f15783 100644
--- a/drivers/gpu/drm/scheduler/sched_fence.c
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -87,7 +87,7 @@ static bool drm_sched_fence_enable_signaling(struct dma_fence *f)
 }
 
 /**
- * amd_sched_fence_free - free up the fence memory
+ * drm_sched_fence_free - free up the fence memory
  *
  * @rcu: RCU callback head
  *
@@ -103,7 +103,7 @@ static void drm_sched_fence_free(struct rcu_head *rcu)
 }
 
 /**
- * amd_sched_fence_release_scheduled - callback that fence can be freed
+ * drm_sched_fence_release_scheduled - callback that fence can be freed
  *
  * @fence: fence
  *
@@ -118,7 +118,7 @@ static void drm_sched_fence_release_scheduled(struct dma_fence *f)
 }
 
 /**
- * amd_sched_fence_release_finished - drop extra reference
+ * drm_sched_fence_release_finished - drop extra reference
  *
  * @f: fence
  *

commit 4983e48c8539282be15f660bdd2c4260467b1190
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Wed Dec 6 17:49:40 2017 +0100

    drm/sched: move fence slab handling to module init/exit
    
    This is the only part of the scheduler which must not be called from
    different drivers. Move it to module init/exit so it is done a single
    time when loading the scheduler.
    
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
index f6f2955890c4..69aab086b913 100644
--- a/drivers/gpu/drm/scheduler/sched_fence.c
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -29,7 +29,7 @@
 
 static struct kmem_cache *sched_fence_slab;
 
-int drm_sched_fence_slab_init(void)
+static int __init drm_sched_fence_slab_init(void)
 {
 	sched_fence_slab = kmem_cache_create(
 		"drm_sched_fence", sizeof(struct drm_sched_fence), 0,
@@ -39,14 +39,12 @@ int drm_sched_fence_slab_init(void)
 
 	return 0;
 }
-EXPORT_SYMBOL_GPL(drm_sched_fence_slab_init);
 
-void drm_sched_fence_slab_fini(void)
+static void __exit drm_sched_fence_slab_fini(void)
 {
 	rcu_barrier();
 	kmem_cache_destroy(sched_fence_slab);
 }
-EXPORT_SYMBOL_GPL(drm_sched_fence_slab_fini);
 
 void drm_sched_fence_scheduled(struct drm_sched_fence *fence)
 {
@@ -185,3 +183,9 @@ struct drm_sched_fence *drm_sched_fence_create(struct drm_sched_entity *entity,
 
 	return fence;
 }
+
+module_init(drm_sched_fence_slab_init);
+module_exit(drm_sched_fence_slab_fini);
+
+MODULE_DESCRIPTION("DRM GPU scheduler");
+MODULE_LICENSE("GPL and additional rights");

commit 1b1f42d8fde4fef1ed7873bf5aa91755f8c3de35
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Wed Dec 6 17:49:39 2017 +0100

    drm: move amd_gpu_scheduler into common location
    
    This moves and renames the AMDGPU scheduler to a common location in DRM
    in order to facilitate re-use by other drivers. This is mostly a straight
    forward rename with no code changes.
    
    One notable exception is the function to_drm_sched_fence(), which is no
    longer a inline header function to avoid the need to export the
    drm_sched_fence_ops_scheduled and drm_sched_fence_ops_finished structures.
    
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/scheduler/sched_fence.c b/drivers/gpu/drm/scheduler/sched_fence.c
new file mode 100644
index 000000000000..f6f2955890c4
--- /dev/null
+++ b/drivers/gpu/drm/scheduler/sched_fence.c
@@ -0,0 +1,187 @@
+/*
+ * Copyright 2015 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include <linux/kthread.h>
+#include <linux/wait.h>
+#include <linux/sched.h>
+#include <drm/drmP.h>
+#include <drm/gpu_scheduler.h>
+
+static struct kmem_cache *sched_fence_slab;
+
+int drm_sched_fence_slab_init(void)
+{
+	sched_fence_slab = kmem_cache_create(
+		"drm_sched_fence", sizeof(struct drm_sched_fence), 0,
+		SLAB_HWCACHE_ALIGN, NULL);
+	if (!sched_fence_slab)
+		return -ENOMEM;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(drm_sched_fence_slab_init);
+
+void drm_sched_fence_slab_fini(void)
+{
+	rcu_barrier();
+	kmem_cache_destroy(sched_fence_slab);
+}
+EXPORT_SYMBOL_GPL(drm_sched_fence_slab_fini);
+
+void drm_sched_fence_scheduled(struct drm_sched_fence *fence)
+{
+	int ret = dma_fence_signal(&fence->scheduled);
+
+	if (!ret)
+		DMA_FENCE_TRACE(&fence->scheduled,
+				"signaled from irq context\n");
+	else
+		DMA_FENCE_TRACE(&fence->scheduled,
+				"was already signaled\n");
+}
+
+void drm_sched_fence_finished(struct drm_sched_fence *fence)
+{
+	int ret = dma_fence_signal(&fence->finished);
+
+	if (!ret)
+		DMA_FENCE_TRACE(&fence->finished,
+				"signaled from irq context\n");
+	else
+		DMA_FENCE_TRACE(&fence->finished,
+				"was already signaled\n");
+}
+
+static const char *drm_sched_fence_get_driver_name(struct dma_fence *fence)
+{
+	return "drm_sched";
+}
+
+static const char *drm_sched_fence_get_timeline_name(struct dma_fence *f)
+{
+	struct drm_sched_fence *fence = to_drm_sched_fence(f);
+	return (const char *)fence->sched->name;
+}
+
+static bool drm_sched_fence_enable_signaling(struct dma_fence *f)
+{
+	return true;
+}
+
+/**
+ * amd_sched_fence_free - free up the fence memory
+ *
+ * @rcu: RCU callback head
+ *
+ * Free up the fence memory after the RCU grace period.
+ */
+static void drm_sched_fence_free(struct rcu_head *rcu)
+{
+	struct dma_fence *f = container_of(rcu, struct dma_fence, rcu);
+	struct drm_sched_fence *fence = to_drm_sched_fence(f);
+
+	dma_fence_put(fence->parent);
+	kmem_cache_free(sched_fence_slab, fence);
+}
+
+/**
+ * amd_sched_fence_release_scheduled - callback that fence can be freed
+ *
+ * @fence: fence
+ *
+ * This function is called when the reference count becomes zero.
+ * It just RCU schedules freeing up the fence.
+ */
+static void drm_sched_fence_release_scheduled(struct dma_fence *f)
+{
+	struct drm_sched_fence *fence = to_drm_sched_fence(f);
+
+	call_rcu(&fence->finished.rcu, drm_sched_fence_free);
+}
+
+/**
+ * amd_sched_fence_release_finished - drop extra reference
+ *
+ * @f: fence
+ *
+ * Drop the extra reference from the scheduled fence to the base fence.
+ */
+static void drm_sched_fence_release_finished(struct dma_fence *f)
+{
+	struct drm_sched_fence *fence = to_drm_sched_fence(f);
+
+	dma_fence_put(&fence->scheduled);
+}
+
+const struct dma_fence_ops drm_sched_fence_ops_scheduled = {
+	.get_driver_name = drm_sched_fence_get_driver_name,
+	.get_timeline_name = drm_sched_fence_get_timeline_name,
+	.enable_signaling = drm_sched_fence_enable_signaling,
+	.signaled = NULL,
+	.wait = dma_fence_default_wait,
+	.release = drm_sched_fence_release_scheduled,
+};
+
+const struct dma_fence_ops drm_sched_fence_ops_finished = {
+	.get_driver_name = drm_sched_fence_get_driver_name,
+	.get_timeline_name = drm_sched_fence_get_timeline_name,
+	.enable_signaling = drm_sched_fence_enable_signaling,
+	.signaled = NULL,
+	.wait = dma_fence_default_wait,
+	.release = drm_sched_fence_release_finished,
+};
+
+struct drm_sched_fence *to_drm_sched_fence(struct dma_fence *f)
+{
+	if (f->ops == &drm_sched_fence_ops_scheduled)
+		return container_of(f, struct drm_sched_fence, scheduled);
+
+	if (f->ops == &drm_sched_fence_ops_finished)
+		return container_of(f, struct drm_sched_fence, finished);
+
+	return NULL;
+}
+EXPORT_SYMBOL(to_drm_sched_fence);
+
+struct drm_sched_fence *drm_sched_fence_create(struct drm_sched_entity *entity,
+					       void *owner)
+{
+	struct drm_sched_fence *fence = NULL;
+	unsigned seq;
+
+	fence = kmem_cache_zalloc(sched_fence_slab, GFP_KERNEL);
+	if (fence == NULL)
+		return NULL;
+
+	fence->owner = owner;
+	fence->sched = entity->sched;
+	spin_lock_init(&fence->lock);
+
+	seq = atomic_inc_return(&entity->fence_seq);
+	dma_fence_init(&fence->scheduled, &drm_sched_fence_ops_scheduled,
+		       &fence->lock, entity->fence_context, seq);
+	dma_fence_init(&fence->finished, &drm_sched_fence_ops_finished,
+		       &fence->lock, entity->fence_context + 1, seq);
+
+	return fence;
+}
