commit e139e8aed0d3a536b67446cb1755a61f52e8d4c9
Merge: b45f1b3b585e 98ae41adb252
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Feb 7 12:22:23 2020 +1000

    Merge tag 'drm/tegra/for-5.6-rc1-fixes' of git://anongit.freedesktop.org/tegra/linux into drm-next
    
    drm/tegra: Fixes for v5.6-rc1
    
    These are a couple of quick fixes for regressions that were found during
    the first two weeks of the merge window.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    From: Thierry Reding <thierry.reding@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200206172753.2185390-1-thierry.reding@gmail.com

commit 273da5a046965ccf0ec79eb63f2d5173467e20fa
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Feb 4 14:59:25 2020 +0100

    drm/tegra: Reuse IOVA mapping where possible
    
    This partially reverts the DMA API support that was recently merged
    because it was causing performance regressions on older Tegra devices.
    Unfortunately, the cache maintenance performed by dma_map_sg() and
    dma_unmap_sg() causes performance to drop by a factor of 10.
    
    The right solution for this would be to cache mappings for buffers per
    consumer device, but that's a bit involved. Instead, we simply revert to
    the old behaviour of sharing IOVA mappings when we know that devices can
    do so (i.e. they share the same IOMMU domain).
    
    Cc: <stable@vger.kernel.org> # v5.5
    Reported-by: Dmitry Osipenko <digetx@gmail.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Dmitry Osipenko <digetx@gmail.com>
    Reviewed-by: Dmitry Osipenko <digetx@gmail.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index bc15b430156d..c46b4d4190ac 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -60,8 +60,16 @@ static struct sg_table *tegra_bo_pin(struct device *dev, struct host1x_bo *bo,
 	/*
 	 * If we've manually mapped the buffer object through the IOMMU, make
 	 * sure to return the IOVA address of our mapping.
+	 *
+	 * Similarly, for buffers that have been allocated by the DMA API the
+	 * physical address can be used for devices that are not attached to
+	 * an IOMMU. For these devices, callers must pass a valid pointer via
+	 * the @phys argument.
+	 *
+	 * Imported buffers were also already mapped at import time, so the
+	 * existing mapping can be reused.
 	 */
-	if (phys && obj->mm) {
+	if (phys) {
 		*phys = obj->iova;
 		return NULL;
 	}

commit 6c56e8adc0011b3bc01b6b2bab7e41d5ecb43c0f
Merge: d1eef1c61974 2156873f08c7
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Tue Dec 17 13:57:54 2019 +0100

    Merge tag 'drm-misc-next-2019-12-16' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for v5.6:
    
    UAPI Changes:
    - Add support for DMA-BUF HEAPS.
    
    Cross-subsystem Changes:
    - mipi dsi definition updates, pulled into drm-intel as well.
    - Add lockdep annotations for dma_resv vs mmap_sem and fs_reclaim.
    - Remove support for dma-buf kmap/kunmap.
    - Constify fb_ops in all fbdev drivers, including drm drivers and drm-core, and media as well.
    
    Core Changes:
    - Small cleanups to ttm.
    - Fix SCDC definition.
    - Assorted cleanups to core.
    - Add todo to remove load/unload hooks, and use generic fbdev emulation.
    - Assorted documentation updates.
    - Use blocking ww lock in ttm fault handler.
    - Remove drm_fb_helper_fbdev_setup/teardown.
    - Warning fixes with W=1 for atomic.
    - Use drm_debug_enabled() instead of drm_debug flag testing in various drivers.
    - Fallback to nontiled mode in fbdev emulation when not all tiles are present. (Later on reverted)
    - Various kconfig indentation fixes in core and drivers.
    - Fix freeing transactions in dp-mst correctly.
    - Sean Paul is steping down as core maintainer. :-(
    - Add lockdep annotations for atomic locks vs dma-resv.
    - Prevent use-after-free for a bad job in drm_scheduler.
    - Fill out all block sizes in the P01x and P210 definitions.
    - Avoid division by zero in drm/rect, and fix bounds.
    - Add drm/rect selftests.
    - Add aspect ratio and alternate clocks for HDMI 4k modes.
    - Add todo for drm_framebuffer_funcs and fb_create cleanup.
    - Drop DRM_AUTH for prime import/export ioctls.
    - Clear DP-MST payload id tables downstream when initializating.
    - Fix for DSC throughput definition.
    - Add extra FEC definitions.
    - Fix fake offset in drm_gem_object_funs.mmap.
    - Stop using encoder->bridge in core directly
    - Handle bridge chaining slightly better.
    - Add backlight support to drm/panel, and use it in many panel drivers.
    - Increase max number of y420 modes from 128 to 256, as preparation to add the new modes.
    
    Driver Changes:
    - Small fixes all over.
    - Fix documentation in vkms.
    - Fix mmap_sem vs dma_resv in nouveau.
    - Small cleanup in komeda.
    - Add page flip support in gma500 for psb/cdv.
    - Add ddc symlink in the connector sysfs directory for many drivers.
    - Add support for analogic an6345, and fix small bugs in it.
    - Add atomic modesetting support to ast.
    - Fix radeon fault handler VMA race.
    - Switch udl to use generic shmem helpers.
    - Unconditional vblank handling for mcde.
    - Miscellaneous fixes to mcde.
    - Tweak debug output from komeda using debugfs.
    - Add gamma and color transform support to komeda for DOU-IPS.
    - Add support for sony acx424AKP panel.
    - Various small cleanups to gma500.
    - Use generic fbdev emulation in udl, and replace udl_framebuffer with generic implementation.
    - Add support for Logic PD Type 28 panel.
    - Use drm_panel_* wrapper functions in exynos/tegra/msm.
    - Add devicetree bindings for generic DSI panels.
    - Don't include drm_pci.h directly in many drivers.
    - Add support for begin/end_cpu_access in udmabuf.
    - Stop using drm_get_pci_dev in gma500 and mga200.
    - Fixes to UDL damage handling, and use dma_buf_begin/end_cpu_access.
    - Add devfreq thermal support to panfrost.
    - Fix hotplug with daisy chained monitors by removing VCPI when disabling topology manager.
    - meson: Add support for OSD1 plane AFBC commit.
    - Stop displaying garbage when toggling ast primary plane on/off.
    - More cleanups and fixes to UDL.
    - Add D32 suport to komeda.
    - Remove globle copy of drm_dev in gma500.
    - Add support for Boe Himax8279d MIPI-DSI LCD panel.
    - Add support for ingenic JZ4770 panel.
    - Small null pointer deference fix in ingenic.
    - Remove support for the special tfp420 driver, as there is a generic way to do it.
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    
    From: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/ba73535a-9334-5302-2e1f-5208bd7390bd@linux.intel.com

commit 49f821919bb9d45de7f1cde6072de01d36235b5d
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Dec 3 17:19:08 2019 +0100

    drm/tegra: gem: Remove premature import restrictions
    
    All the display related blocks on Tegra require contiguous memory. Using
    the DMA API, there is no knowing at import time which device will end up
    using the buffer, so it's not known whether or not an IOMMU will be used
    to map the buffer.
    
    Move the check for non-contiguous buffers/mappings to the tegra_dc_pin()
    function which is now the earliest point where it is known if a DMA BUF
    can be used by the given device or not.
    
    v2: add check for contiguous buffer/mapping in tegra_dc_pin()
    
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 6dfad56eee2b..bc15b430156d 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -440,13 +440,6 @@ static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 		err = tegra_bo_iommu_map(tegra, bo);
 		if (err < 0)
 			goto detach;
-	} else {
-		if (bo->sgt->nents > 1) {
-			err = -EINVAL;
-			goto detach;
-		}
-
-		bo->iova = sg_dma_address(bo->sgt->sgl);
 	}
 
 	bo->gem.import_attach = attach;

commit 1f16deac766926f1f59a7c038e939b09ef8edfc8
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Dec 3 17:19:07 2019 +0100

    drm/tegra: gem: Properly pin imported buffers
    
    Buffers that are imported from a DMA-BUF don't have pages allocated with
    them. At the same time an SG table for them can't be derived using the
    DMA API helpers because the necessary information doesn't exist. However
    there's already an SG table that was created during import, so this can
    simply be duplicated.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 746dae32c484..6dfad56eee2b 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -27,6 +27,29 @@ static void tegra_bo_put(struct host1x_bo *bo)
 	drm_gem_object_put_unlocked(&obj->gem);
 }
 
+/* XXX move this into lib/scatterlist.c? */
+static int sg_alloc_table_from_sg(struct sg_table *sgt, struct scatterlist *sg,
+				  unsigned int nents, gfp_t gfp_mask)
+{
+	struct scatterlist *dst;
+	unsigned int i;
+	int err;
+
+	err = sg_alloc_table(sgt, nents, gfp_mask);
+	if (err < 0)
+		return err;
+
+	dst = sgt->sgl;
+
+	for (i = 0; i < nents; i++) {
+		sg_set_page(dst, sg_page(sg), sg->length, 0);
+		dst = sg_next(dst);
+		sg = sg_next(sg);
+	}
+
+	return 0;
+}
+
 static struct sg_table *tegra_bo_pin(struct device *dev, struct host1x_bo *bo,
 				     dma_addr_t *phys)
 {
@@ -52,11 +75,31 @@ static struct sg_table *tegra_bo_pin(struct device *dev, struct host1x_bo *bo,
 		return ERR_PTR(-ENOMEM);
 
 	if (obj->pages) {
+		/*
+		 * If the buffer object was allocated from the explicit IOMMU
+		 * API code paths, construct an SG table from the pages.
+		 */
 		err = sg_alloc_table_from_pages(sgt, obj->pages, obj->num_pages,
 						0, obj->gem.size, GFP_KERNEL);
 		if (err < 0)
 			goto free;
+	} else if (obj->sgt) {
+		/*
+		 * If the buffer object already has an SG table but no pages
+		 * were allocated for it, it means the buffer was imported and
+		 * the SG table needs to be copied to avoid overwriting any
+		 * other potential users of the original SG table.
+		 */
+		err = sg_alloc_table_from_sg(sgt, obj->sgt->sgl, obj->sgt->nents,
+					     GFP_KERNEL);
+		if (err < 0)
+			goto free;
 	} else {
+		/*
+		 * If the buffer object had no pages allocated and if it was
+		 * not imported, it had to be allocated with the DMA API, so
+		 * the DMA API helper can be used.
+		 */
 		err = dma_get_sgtable(dev, sgt, obj->vaddr, obj->iova,
 				      obj->gem.size);
 		if (err < 0)

commit 7195cf427b6822a40210f5ab1078aecaa5aaea8a
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Mon Nov 18 11:35:29 2019 +0100

    drm/tegra: Remove dma_buf->k(un)map
    
    No in-tree users left.
    
    Reviewed-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Thierry Reding <treding@nvidia.com>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Cc: Jonathan Hunter <jonathanh@nvidia.com>
    Cc: linux-tegra@vger.kernel.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20191118103536.17675-9-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 0c55df20e0ef..d266b66c1292 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -554,16 +554,6 @@ static int tegra_gem_prime_end_cpu_access(struct dma_buf *buf,
 	return 0;
 }
 
-static void *tegra_gem_prime_kmap(struct dma_buf *buf, unsigned long page)
-{
-	return NULL;
-}
-
-static void tegra_gem_prime_kunmap(struct dma_buf *buf, unsigned long page,
-				   void *addr)
-{
-}
-
 static int tegra_gem_prime_mmap(struct dma_buf *buf, struct vm_area_struct *vma)
 {
 	struct drm_gem_object *gem = buf->priv;
@@ -594,8 +584,6 @@ static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
 	.release = tegra_gem_prime_release,
 	.begin_cpu_access = tegra_gem_prime_begin_cpu_access,
 	.end_cpu_access = tegra_gem_prime_end_cpu_access,
-	.map = tegra_gem_prime_kmap,
-	.unmap = tegra_gem_prime_kunmap,
 	.mmap = tegra_gem_prime_mmap,
 	.vmap = tegra_gem_prime_vmap,
 	.vunmap = tegra_gem_prime_vunmap,

commit 35bd71dd1c161e6e89b21138e01e8c04c6347716
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Mon Nov 18 11:35:23 2019 +0100

    drm/tegra: Delete host1x_bo_ops->k(un)map
    
    It doesn't have any callers anymore.
    
    Aside: The ->mmap/munmap hooks have a bit a confusing name, they don't
    do userspace mmaps, but a kernel vmap. I think most places use vmap
    for this, except ttm, which uses kmap for vmap for added confusion.
    mmap seems entirely for userspace mappings set up through mmap(2)
    syscall.
    
    Reviewed-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Thierry Reding <treding@nvidia.com>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Cc: Jonathan Hunter <jonathanh@nvidia.com>
    Cc: linux-tegra@vger.kernel.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20191118103536.17675-3-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index fb7667c8dd4c..0c55df20e0ef 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -65,32 +65,6 @@ static void tegra_bo_munmap(struct host1x_bo *bo, void *addr)
 		vunmap(addr);
 }
 
-static void *tegra_bo_kmap(struct host1x_bo *bo, unsigned int page)
-{
-	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
-
-	if (obj->vaddr)
-		return obj->vaddr + page * PAGE_SIZE;
-	else if (obj->gem.import_attach)
-		return dma_buf_kmap(obj->gem.import_attach->dmabuf, page);
-	else
-		return vmap(obj->pages + page, 1, VM_MAP,
-			    pgprot_writecombine(PAGE_KERNEL));
-}
-
-static void tegra_bo_kunmap(struct host1x_bo *bo, unsigned int page,
-			    void *addr)
-{
-	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
-
-	if (obj->vaddr)
-		return;
-	else if (obj->gem.import_attach)
-		dma_buf_kunmap(obj->gem.import_attach->dmabuf, page, addr);
-	else
-		vunmap(addr);
-}
-
 static struct host1x_bo *tegra_bo_get(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
@@ -107,8 +81,6 @@ static const struct host1x_bo_ops tegra_bo_ops = {
 	.unpin = tegra_bo_unpin,
 	.mmap = tegra_bo_mmap,
 	.munmap = tegra_bo_munmap,
-	.kmap = tegra_bo_kmap,
-	.kunmap = tegra_bo_kunmap,
 };
 
 static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)

commit af1cbfb9bf0fe079ca328231451fd4db8b3eafec
Author: Thierry Reding <treding@nvidia.com>
Date:   Mon Oct 28 13:37:13 2019 +0100

    gpu: host1x: Support DMA mapping of buffers
    
    If host1x_bo_pin() returns an SG table, create a DMA mapping for the
    buffer. For buffers that the host1x client has already mapped itself,
    host1x_bo_pin() returns NULL and the existing DMA address is used.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 564ef60f67c2..746dae32c484 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -34,9 +34,19 @@ static struct sg_table *tegra_bo_pin(struct device *dev, struct host1x_bo *bo,
 	struct sg_table *sgt;
 	int err;
 
-	if (phys)
+	/*
+	 * If we've manually mapped the buffer object through the IOMMU, make
+	 * sure to return the IOVA address of our mapping.
+	 */
+	if (phys && obj->mm) {
 		*phys = obj->iova;
+		return NULL;
+	}
 
+	/*
+	 * If we don't have a mapping for this buffer yet, return an SG table
+	 * so that host1x can do the mapping for us via the DMA API.
+	 */
 	sgt = kzalloc(sizeof(*sgt), GFP_KERNEL);
 	if (!sgt)
 		return ERR_PTR(-ENOMEM);
@@ -62,8 +72,10 @@ static struct sg_table *tegra_bo_pin(struct device *dev, struct host1x_bo *bo,
 
 static void tegra_bo_unpin(struct device *dev, struct sg_table *sgt)
 {
-	sg_free_table(sgt);
-	kfree(sgt);
+	if (sgt) {
+		sg_free_table(sgt);
+		kfree(sgt);
+	}
 }
 
 static void *tegra_bo_mmap(struct host1x_bo *bo)

commit 80327ce3d4edaa9abde1c6e1a1785572c7de3750
Author: Thierry Reding <treding@nvidia.com>
Date:   Mon Oct 28 13:37:09 2019 +0100

    gpu: host1x: Overhaul host1x_bo_{pin,unpin}() API
    
    The host1x_bo_pin() and host1x_bo_unpin() APIs are used to pin and unpin
    buffers during host1x job submission. Pinning currently returns the SG
    table and the DMA address (an IOVA if an IOMMU is used or a physical
    address if no IOMMU is used) of the buffer. The DMA address is only used
    for buffers that are relocated, whereas the host1x driver will map
    gather buffers into its own IOVA space so that they can be processed by
    the CDMA engine.
    
    This approach has a couple of issues. On one hand it's not very useful
    to return a DMA address for the buffer if host1x doesn't need it. On the
    other hand, returning the SG table of the buffer is suboptimal because a
    single SG table cannot be shared for multiple mappings, because the DMA
    address is stored within the SG table, and the DMA address may be
    different for different devices.
    
    Subsequent patches will move the host1x driver over to the DMA API which
    doesn't work with a single shared SG table. Fix this by returning a new
    SG table each time a buffer is pinned. This allows the buffer to be
    referenced by multiple jobs for different engines.
    
    Change the prototypes of host1x_bo_pin() and host1x_bo_unpin() to take a
    struct device *, specifying the device for which the buffer should be
    pinned. This is required in order to be able to properly construct the
    SG table. While at it, make host1x_bo_pin() return the SG table because
    that allows us to return an ERR_PTR()-encoded error code if we need to,
    or return NULL to signal that we don't need the SG table to be remapped
    and can simply use the DMA address as-is. At the same time, returning
    the DMA address is made optional because in the example of command
    buffers, host1x doesn't need to know the DMA address since it will have
    to create its own mapping anyway.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index d2f88cc3134f..564ef60f67c2 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -27,17 +27,43 @@ static void tegra_bo_put(struct host1x_bo *bo)
 	drm_gem_object_put_unlocked(&obj->gem);
 }
 
-static dma_addr_t tegra_bo_pin(struct host1x_bo *bo, struct sg_table **sgt)
+static struct sg_table *tegra_bo_pin(struct device *dev, struct host1x_bo *bo,
+				     dma_addr_t *phys)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+	struct sg_table *sgt;
+	int err;
+
+	if (phys)
+		*phys = obj->iova;
 
-	*sgt = obj->sgt;
+	sgt = kzalloc(sizeof(*sgt), GFP_KERNEL);
+	if (!sgt)
+		return ERR_PTR(-ENOMEM);
 
-	return obj->iova;
+	if (obj->pages) {
+		err = sg_alloc_table_from_pages(sgt, obj->pages, obj->num_pages,
+						0, obj->gem.size, GFP_KERNEL);
+		if (err < 0)
+			goto free;
+	} else {
+		err = dma_get_sgtable(dev, sgt, obj->vaddr, obj->iova,
+				      obj->gem.size);
+		if (err < 0)
+			goto free;
+	}
+
+	return sgt;
+
+free:
+	kfree(sgt);
+	return ERR_PTR(err);
 }
 
-static void tegra_bo_unpin(struct host1x_bo *bo, struct sg_table *sgt)
+static void tegra_bo_unpin(struct device *dev, struct sg_table *sgt)
 {
+	sg_free_table(sgt);
+	kfree(sgt);
 }
 
 static void *tegra_bo_mmap(struct host1x_bo *bo)

commit acf6b77c4c3dc38de1e435d114c267cd8dedc913
Author: Thierry Reding <treding@nvidia.com>
Date:   Fri Jun 8 15:00:05 2018 +0200

    drm/tegra: gem: Use sg_alloc_table_from_pages()
    
    Instead of manually creating the SG table for a discontiguous buffer,
    use the existing sg_alloc_table_from_pages(). Note that this is not safe
    to be used with the ARM DMA/IOMMU integration code because that will not
    ensure that the whole buffer is mapped contiguously. Depending on the
    size of the individual entries the mapping may end up containing holes
    to ensure alignment.
    
    However, we only ever use these buffers with explicit IOMMU API usage
    and know how to avoid these holes.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 00701cadaceb..d2f88cc3134f 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -508,14 +508,9 @@ tegra_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,
 		return NULL;
 
 	if (bo->pages) {
-		struct scatterlist *sg;
-		unsigned int i;
-
-		if (sg_alloc_table(sgt, bo->num_pages, GFP_KERNEL))
+		if (sg_alloc_table_from_pages(sgt, bo->pages, bo->num_pages,
+					      0, gem->size, GFP_KERNEL) < 0)
 			goto free;
-
-		for_each_sg(sgt->sgl, sg, bo->num_pages, i)
-			sg_set_page(sg, bo->pages[i], PAGE_SIZE, 0);
 	} else {
 		if (dma_get_sgtable(attach->dev, sgt, bo->vaddr, bo->iova,
 				    gem->size) < 0)

commit 8b5a3c17a2778fba817c38beb545bc48228b8da5
Author: Thierry Reding <treding@nvidia.com>
Date:   Fri Jun 8 14:59:13 2018 +0200

    drm/tegra: gem: Always map SG tables for DMA-BUFs
    
    When an importer wants to map a DMA-BUF, make sure to always actually
    map it, irrespective of whether the buffer is contiguous or not.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 3345cce14662..00701cadaceb 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -516,15 +516,15 @@ tegra_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,
 
 		for_each_sg(sgt->sgl, sg, bo->num_pages, i)
 			sg_set_page(sg, bo->pages[i], PAGE_SIZE, 0);
-
-		if (dma_map_sg(attach->dev, sgt->sgl, sgt->nents, dir) == 0)
-			goto free;
 	} else {
 		if (dma_get_sgtable(attach->dev, sgt, bo->vaddr, bo->iova,
 				    gem->size) < 0)
 			goto free;
 	}
 
+	if (dma_map_sg(attach->dev, sgt->sgl, sgt->nents, dir) == 0)
+		goto free;
+
 	return sgt;
 
 free:

commit d81f3431e61771028acb69a23601ef5379e39f2a
Author: Thierry Reding <treding@nvidia.com>
Date:   Fri Jun 8 14:56:04 2018 +0200

    drm/tegra: gem: Use dma_get_sgtable()
    
    Rather than manually creating an SG table in an incorrect way, let the
    standard dma_get_sgtable() function do it.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 7412e23500d1..3345cce14662 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -520,11 +520,9 @@ tegra_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,
 		if (dma_map_sg(attach->dev, sgt->sgl, sgt->nents, dir) == 0)
 			goto free;
 	} else {
-		if (sg_alloc_table(sgt, 1, GFP_KERNEL))
+		if (dma_get_sgtable(attach->dev, sgt, bo->vaddr, bo->iova,
+				    gem->size) < 0)
 			goto free;
-
-		sg_dma_address(sgt->sgl) = bo->iova;
-		sg_dma_len(sgt->sgl) = gem->size;
 	}
 
 	return sgt;

commit 7e3c53a096a9e75b12e69f93ef1fbc7cb1b27297
Author: Thierry Reding <treding@nvidia.com>
Date:   Mon Jun 4 17:36:50 2018 +0200

    drm/tegra: gem: Rename paddr -> iova
    
    The address can refer to either physical memory or IO virtual memory.
    If referring to IO virtual memory, there will always be an associated
    physical memory address. Rename this variable to "iova" to clarify in
    all cases that this is the IO virtual memory, which in the absence of
    an IOMMU is identical to the physical address.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index fb7667c8dd4c..7412e23500d1 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -33,7 +33,7 @@ static dma_addr_t tegra_bo_pin(struct host1x_bo *bo, struct sg_table **sgt)
 
 	*sgt = obj->sgt;
 
-	return obj->paddr;
+	return obj->iova;
 }
 
 static void tegra_bo_unpin(struct host1x_bo *bo, struct sg_table *sgt)
@@ -133,9 +133,9 @@ static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 		goto unlock;
 	}
 
-	bo->paddr = bo->mm->start;
+	bo->iova = bo->mm->start;
 
-	bo->size = iommu_map_sg(tegra->domain, bo->paddr, bo->sgt->sgl,
+	bo->size = iommu_map_sg(tegra->domain, bo->iova, bo->sgt->sgl,
 				bo->sgt->nents, prot);
 	if (!bo->size) {
 		dev_err(tegra->drm->dev, "failed to map buffer\n");
@@ -161,7 +161,7 @@ static int tegra_bo_iommu_unmap(struct tegra_drm *tegra, struct tegra_bo *bo)
 		return 0;
 
 	mutex_lock(&tegra->mm_lock);
-	iommu_unmap(tegra->domain, bo->paddr, bo->size);
+	iommu_unmap(tegra->domain, bo->iova, bo->size);
 	drm_mm_remove_node(bo->mm);
 	mutex_unlock(&tegra->mm_lock);
 
@@ -209,7 +209,7 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 		sg_free_table(bo->sgt);
 		kfree(bo->sgt);
 	} else if (bo->vaddr) {
-		dma_free_wc(drm->dev, bo->gem.size, bo->vaddr, bo->paddr);
+		dma_free_wc(drm->dev, bo->gem.size, bo->vaddr, bo->iova);
 	}
 }
 
@@ -264,7 +264,7 @@ static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo)
 	} else {
 		size_t size = bo->gem.size;
 
-		bo->vaddr = dma_alloc_wc(drm->dev, size, &bo->paddr,
+		bo->vaddr = dma_alloc_wc(drm->dev, size, &bo->iova,
 					 GFP_KERNEL | __GFP_NOWARN);
 		if (!bo->vaddr) {
 			dev_err(drm->dev,
@@ -365,7 +365,7 @@ static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 			goto detach;
 		}
 
-		bo->paddr = sg_dma_address(bo->sgt->sgl);
+		bo->iova = sg_dma_address(bo->sgt->sgl);
 	}
 
 	bo->gem.import_attach = attach;
@@ -461,7 +461,7 @@ int __tegra_gem_mmap(struct drm_gem_object *gem, struct vm_area_struct *vma)
 		vma->vm_flags &= ~VM_PFNMAP;
 		vma->vm_pgoff = 0;
 
-		err = dma_mmap_wc(gem->dev->dev, vma, bo->vaddr, bo->paddr,
+		err = dma_mmap_wc(gem->dev->dev, vma, bo->vaddr, bo->iova,
 				  gem->size);
 		if (err < 0) {
 			drm_gem_vm_close(vma);
@@ -523,7 +523,7 @@ tegra_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,
 		if (sg_alloc_table(sgt, 1, GFP_KERNEL))
 			goto free;
 
-		sg_dma_address(sgt->sgl) = bo->paddr;
+		sg_dma_address(sgt->sgl) = bo->iova;
 		sg_dma_len(sgt->sgl) = gem->size;
 	}
 

commit eb1df694cd7271632763bb99f7fb3891357461d8
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Sun Aug 4 11:41:30 2019 +0200

    drm/tegra: drop use of drmP.h
    
    Drop use of the deprecated drmP.h header file.
    
    For all touched files divide include files into blocks,
    and sort them within the blocks.
    Fix fallout.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Reviewed-by: Thierry Reding <treding@nvidia.com>
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Cc: Jonathan Hunter <jonathanh@nvidia.com>
    Cc: linux-tegra@vger.kernel.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20190804094132.29463-3-sam@ravnborg.org

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 0a3d925d5284..fb7667c8dd4c 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -12,6 +12,9 @@
 
 #include <linux/dma-buf.h>
 #include <linux/iommu.h>
+
+#include <drm/drm_drv.h>
+#include <drm/drm_prime.h>
 #include <drm/tegra_drm.h>
 
 #include "drm.h"

commit 03b0f2ce735e97e9f49790d4563c82515b8fa702
Merge: e4f86e437164 5f9e832c1370
Author: Maxime Ripard <maxime.ripard@bootlin.com>
Date:   Mon Jul 22 21:24:10 2019 +0200

    Merge v5.3-rc1 into drm-misc-next
    
    Noralf needs some SPI patches in 5.3 to merge some work on tinydrm.
    
    Signed-off-by: Maxime Ripard <maxime.ripard@bootlin.com>

commit e4fa8457b2197118538a1400b75c898f9faaf164
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Jun 14 22:35:25 2019 +0200

    drm/prime: Align gem_prime_export with obj_funcs.export
    
    The idea is that gem_prime_export is deprecated in favor of
    obj_funcs.export. That's much easier to do if both have matching
    function signatures.
    
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Reviewed-by: Emil Velikov <emil.velikov@collabora.com>
    Acked-by: Christian König <christian.koenig@amd.com>
    Acked-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
    Cc: Maxime Ripard <maxime.ripard@bootlin.com>
    Cc: Sean Paul <sean@poorly.run>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Cc: Zhi Wang <zhi.a.wang@intel.com>
    Cc: Jani Nikula <jani.nikula@linux.intel.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Rodrigo Vivi <rodrigo.vivi@intel.com>
    Cc: Tomi Valkeinen <tomi.valkeinen@ti.com>
    Cc: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Cc: "David (ChunMing) Zhou" <David1.Zhou@amd.com>
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Cc: Jonathan Hunter <jonathanh@nvidia.com>
    Cc: Dave Airlie <airlied@redhat.com>
    Cc: Eric Anholt <eric@anholt.net>
    Cc: "Michel Dänzer" <michel.daenzer@amd.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Huang Rui <ray.huang@amd.com>
    Cc: Felix Kuehling <Felix.Kuehling@amd.com>
    Cc: Hawking Zhang <Hawking.Zhang@amd.com>
    Cc: Feifei Xu <Feifei.Xu@amd.com>
    Cc: Jim Qu <Jim.Qu@amd.com>
    Cc: Evan Quan <evan.quan@amd.com>
    Cc: Matthew Auld <matthew.auld@intel.com>
    Cc: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Cc: Thomas Zimmermann <tdz@users.sourceforge.net>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Jilayne Lovejoy <opensource@jilayne.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Mikulas Patocka <mpatocka@redhat.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Junwei Zhang <Jerry.Zhang@amd.com>
    Cc: intel-gvt-dev@lists.freedesktop.org
    Cc: intel-gfx@lists.freedesktop.org
    Cc: amd-gfx@lists.freedesktop.org
    Cc: linux-tegra@vger.kernel.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20190614203615.12639-10-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 4cce11fd8836..fd5e9c3a2789 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -629,20 +629,19 @@ static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
 	.vunmap = tegra_gem_prime_vunmap,
 };
 
-struct dma_buf *tegra_gem_prime_export(struct drm_device *drm,
-				       struct drm_gem_object *gem,
+struct dma_buf *tegra_gem_prime_export(struct drm_gem_object *gem,
 				       int flags)
 {
 	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);
 
 	exp_info.exp_name = KBUILD_MODNAME;
-	exp_info.owner = drm->driver->fops->owner;
+	exp_info.owner = gem->dev->driver->fops->owner;
 	exp_info.ops = &tegra_gem_prime_dmabuf_ops;
 	exp_info.size = gem->size;
 	exp_info.flags = flags;
 	exp_info.priv = gem;
 
-	return drm_gem_dmabuf_export(drm, &exp_info);
+	return drm_gem_dmabuf_export(gem->dev, &exp_info);
 }
 
 struct drm_gem_object *tegra_gem_prime_import(struct drm_device *drm,

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 4cce11fd8836..df53a46285a3 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * NVIDIA Tegra DRM GEM helper functions
  *
@@ -7,10 +8,6 @@
  * Based on the GEM/CMA helpers
  *
  * Copyright (c) 2011 Samsung Electronics Co., Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 
 #include <linux/dma-buf.h>

commit 61b51fb51c01a519a249d28ec55c6513a13be5a3
Author: Dmitry Osipenko <digetx@gmail.com>
Date:   Thu Mar 7 01:55:19 2019 +0300

    drm/tegra: gem: Fix CPU-cache maintenance for BO's allocated using get_pages()
    
    The allocated pages need to be invalidated in CPU caches. On ARM32 the
    DMA_BIDIRECTIONAL flag only ensures that data is written-back to DRAM and
    the data stays in CPU cache lines. While the DMA_FROM_DEVICE flag ensures
    that the corresponding CPU cache lines are getting invalidated and nothing
    more, that's exactly what is needed for a newly allocated pages.
    
    This fixes randomly failing rendercheck tests on Tegra30 using the
    Opentegra driver for tests that use small-sized pixmaps (10x10 and less,
    i.e. 1-2 memory pages) because apparently CPU reads out stale data from
    caches and/or that data is getting evicted to DRAM at the time of HW job
    execution.
    
    Fixes: bd43c9f0fa1f ("drm/tegra: gem: Map pages via the DMA API")
    Cc: stable <stable@vger.kernel.org>
    Signed-off-by: Dmitry Osipenko <digetx@gmail.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 4f80100ff5f3..4cce11fd8836 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -204,7 +204,7 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 {
 	if (bo->pages) {
 		dma_unmap_sg(drm->dev, bo->sgt->sgl, bo->sgt->nents,
-			     DMA_BIDIRECTIONAL);
+			     DMA_FROM_DEVICE);
 		drm_gem_put_pages(&bo->gem, bo->pages, true, true);
 		sg_free_table(bo->sgt);
 		kfree(bo->sgt);
@@ -230,7 +230,7 @@ static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 	}
 
 	err = dma_map_sg(drm->dev, bo->sgt->sgl, bo->sgt->nents,
-			 DMA_BIDIRECTIONAL);
+			 DMA_FROM_DEVICE);
 	if (err == 0) {
 		err = -EFAULT;
 		goto free_sgt;

commit d98c71dadc2d0debdb80beb5a478baf1e6f98758
Merge: d67b6a206507 daf0678c2036
Author: Gustavo Padovan <gustavo.padovan@collabora.com>
Date:   Wed Jun 20 13:22:22 2018 -0300

    Merge drm-upstream/drm-next into drm-misc-next
    
    We got a few conflicts in drm_atomic.c after merging the DRM writeback support,
    now we need a backmerge to unlock develop development on drm-misc-next.
    
    Signed-off-by: Gustavo Padovan <gustavo.padovan@collabora.com>

commit f664a52695429b68afb4e130a0f69cd5fd1fec86
Author: Christian König <christian.koenig@amd.com>
Date:   Mon May 28 13:34:01 2018 +0200

    dma-buf: remove kmap_atomic interface
    
    Neither used nor correctly implemented anywhere. Just completely remove
    the interface.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: https://patchwork.freedesktop.org/patch/226645/

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 8b0b4ff64bb4..d7661702c11c 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -596,18 +596,6 @@ static int tegra_gem_prime_end_cpu_access(struct dma_buf *buf,
 	return 0;
 }
 
-static void *tegra_gem_prime_kmap_atomic(struct dma_buf *buf,
-					 unsigned long page)
-{
-	return NULL;
-}
-
-static void tegra_gem_prime_kunmap_atomic(struct dma_buf *buf,
-					  unsigned long page,
-					  void *addr)
-{
-}
-
 static void *tegra_gem_prime_kmap(struct dma_buf *buf, unsigned long page)
 {
 	return NULL;
@@ -648,8 +636,6 @@ static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
 	.release = tegra_gem_prime_release,
 	.begin_cpu_access = tegra_gem_prime_begin_cpu_access,
 	.end_cpu_access = tegra_gem_prime_end_cpu_access,
-	.map_atomic = tegra_gem_prime_kmap_atomic,
-	.unmap_atomic = tegra_gem_prime_kunmap_atomic,
 	.map = tegra_gem_prime_kmap,
 	.unmap = tegra_gem_prime_kunmap,
 	.mmap = tegra_gem_prime_mmap,

commit 4bd91a5b5dbb8b536208396c3d032cba8e3c3913
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed May 16 18:49:04 2018 +0200

    drm/tegra: gem: Fill in missing export info
    
    Set the owner and name of the exported DMA-BUF in addition to the
    already filled-in fields.
    
    Reviewed-by: Dmitry Osipenko <digetx@gmail.com>
    Tested-by: Dmitry Osipenko <digetx@gmail.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 1c4011774c3f..00a5c9f32254 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -649,6 +649,8 @@ struct dma_buf *tegra_gem_prime_export(struct drm_device *drm,
 {
 	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);
 
+	exp_info.exp_name = KBUILD_MODNAME;
+	exp_info.owner = drm->driver->fops->owner;
 	exp_info.ops = &tegra_gem_prime_dmabuf_ops;
 	exp_info.size = gem->size;
 	exp_info.flags = flags;

commit cc7add70cad12054e096b034578827d7065f64bb
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Tue Apr 17 19:17:55 2018 +0530

    drm/tegra: Adding new typedef vm_fault_t
    
    Use new return type vm_fault_t for fault handler. For now, this is just
    documenting that the function returns a VM_FAULT value rather than an
    errno. Once all instances are converted, vm_fault_t will become a
    distinct type.
    
    Reference id -> 1c8f422059ae ("mm: change return type to vm_fault_t")
    
    Previously vm_insert_page() returns err which driver mapped into
    VM_FAULT_* type. The new function vmf_insert_page() will replace this
    inefficiency by returning VM_FAULT_* type.
    
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 8b0b4ff64bb4..1c4011774c3f 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -422,14 +422,13 @@ int tegra_bo_dumb_create(struct drm_file *file, struct drm_device *drm,
 	return 0;
 }
 
-static int tegra_bo_fault(struct vm_fault *vmf)
+static vm_fault_t tegra_bo_fault(struct vm_fault *vmf)
 {
 	struct vm_area_struct *vma = vmf->vma;
 	struct drm_gem_object *gem = vma->vm_private_data;
 	struct tegra_bo *bo = to_tegra_bo(gem);
 	struct page *page;
 	pgoff_t offset;
-	int err;
 
 	if (!bo->pages)
 		return VM_FAULT_SIGBUS;
@@ -437,20 +436,7 @@ static int tegra_bo_fault(struct vm_fault *vmf)
 	offset = (vmf->address - vma->vm_start) >> PAGE_SHIFT;
 	page = bo->pages[offset];
 
-	err = vm_insert_page(vma, vmf->address, page);
-	switch (err) {
-	case -EAGAIN:
-	case 0:
-	case -ERESTARTSYS:
-	case -EINTR:
-	case -EBUSY:
-		return VM_FAULT_NOPAGE;
-
-	case -ENOMEM:
-		return VM_FAULT_OOM;
-	}
-
-	return VM_FAULT_SIGBUS;
+	return vmf_insert_page(vma, vmf->address, page);
 }
 
 const struct vm_operations_struct tegra_bo_vm_ops = {

commit 27e92f1f1600c214bf649daddb9b88b68330a8d1
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Dec 13 12:25:14 2017 +0100

    drm/tegra: prime: Implement ->{begin,end}_cpu_access()
    
    These callbacks allow the exporter to swap in and pin the backing
    storage for buffers as well as invalidate the cache in preparation for
    accessing the buffer from the CPU, and flush the cache and unpin the
    backing storage when the CPU is done modifying the buffer.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 8fc5860ab19a..8b0b4ff64bb4 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -568,6 +568,34 @@ static void tegra_gem_prime_release(struct dma_buf *buf)
 	drm_gem_dmabuf_release(buf);
 }
 
+static int tegra_gem_prime_begin_cpu_access(struct dma_buf *buf,
+					    enum dma_data_direction direction)
+{
+	struct drm_gem_object *gem = buf->priv;
+	struct tegra_bo *bo = to_tegra_bo(gem);
+	struct drm_device *drm = gem->dev;
+
+	if (bo->pages)
+		dma_sync_sg_for_cpu(drm->dev, bo->sgt->sgl, bo->sgt->nents,
+				    DMA_FROM_DEVICE);
+
+	return 0;
+}
+
+static int tegra_gem_prime_end_cpu_access(struct dma_buf *buf,
+					  enum dma_data_direction direction)
+{
+	struct drm_gem_object *gem = buf->priv;
+	struct tegra_bo *bo = to_tegra_bo(gem);
+	struct drm_device *drm = gem->dev;
+
+	if (bo->pages)
+		dma_sync_sg_for_device(drm->dev, bo->sgt->sgl, bo->sgt->nents,
+				       DMA_TO_DEVICE);
+
+	return 0;
+}
+
 static void *tegra_gem_prime_kmap_atomic(struct dma_buf *buf,
 					 unsigned long page)
 {
@@ -618,6 +646,8 @@ static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
 	.map_dma_buf = tegra_gem_prime_map_dma_buf,
 	.unmap_dma_buf = tegra_gem_prime_unmap_dma_buf,
 	.release = tegra_gem_prime_release,
+	.begin_cpu_access = tegra_gem_prime_begin_cpu_access,
+	.end_cpu_access = tegra_gem_prime_end_cpu_access,
 	.map_atomic = tegra_gem_prime_kmap_atomic,
 	.unmap_atomic = tegra_gem_prime_kunmap_atomic,
 	.map = tegra_gem_prime_kmap,

commit bd43c9f0fa1f664b58eefdc8aab7ac3c8b2026ec
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Dec 13 12:22:48 2017 +0100

    drm/tegra: gem: Map pages via the DMA API
    
    When allocating pages, map them with the DMA API in order to invalidate
    caches. This is the correct usage of the API and works just as well as
    faking up the SG table and using the dma_sync_sg_for_device() function.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index d3b3aa148225..8fc5860ab19a 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -203,6 +203,8 @@ static struct tegra_bo *tegra_bo_alloc_object(struct drm_device *drm,
 static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 {
 	if (bo->pages) {
+		dma_unmap_sg(drm->dev, bo->sgt->sgl, bo->sgt->nents,
+			     DMA_BIDIRECTIONAL);
 		drm_gem_put_pages(&bo->gem, bo->pages, true, true);
 		sg_free_table(bo->sgt);
 		kfree(bo->sgt);
@@ -213,8 +215,7 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 
 static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 {
-	struct scatterlist *s;
-	unsigned int i;
+	int err;
 
 	bo->pages = drm_gem_get_pages(&bo->gem);
 	if (IS_ERR(bo->pages))
@@ -223,27 +224,26 @@ static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 	bo->num_pages = bo->gem.size >> PAGE_SHIFT;
 
 	bo->sgt = drm_prime_pages_to_sg(bo->pages, bo->num_pages);
-	if (IS_ERR(bo->sgt))
+	if (IS_ERR(bo->sgt)) {
+		err = PTR_ERR(bo->sgt);
 		goto put_pages;
+	}
 
-	/*
-	 * Fake up the SG table so that dma_sync_sg_for_device() can be used
-	 * to flush the pages associated with it.
-	 *
-	 * TODO: Replace this by drm_clflash_sg() once it can be implemented
-	 * without relying on symbols that are not exported.
-	 */
-	for_each_sg(bo->sgt->sgl, s, bo->sgt->nents, i)
-		sg_dma_address(s) = sg_phys(s);
-
-	dma_sync_sg_for_device(drm->dev, bo->sgt->sgl, bo->sgt->nents,
-			       DMA_TO_DEVICE);
+	err = dma_map_sg(drm->dev, bo->sgt->sgl, bo->sgt->nents,
+			 DMA_BIDIRECTIONAL);
+	if (err == 0) {
+		err = -EFAULT;
+		goto free_sgt;
+	}
 
 	return 0;
 
+free_sgt:
+	sg_free_table(bo->sgt);
+	kfree(bo->sgt);
 put_pages:
 	drm_gem_put_pages(&bo->gem, bo->pages, false, false);
-	return PTR_ERR(bo->sgt);
+	return err;
 }
 
 static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo)

commit 04c0746663bd3ae3cce5e02d5b32c8ade2a833b8
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Feb 7 18:45:55 2018 +0100

    drm/tegra: gem: Make __tegra_gem_mmap() available more widely
    
    This function allows mapping a GEM object into a virtual memory address
    space, which makes it useful outside of the GEM code.
    
    While at it, rename the function so it doesn't clash with the function
    that implements the DRM_TEGRA_GEM_MMAP IOCTL.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 49b9bf28f872..d3b3aa148225 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -459,8 +459,7 @@ const struct vm_operations_struct tegra_bo_vm_ops = {
 	.close = drm_gem_vm_close,
 };
 
-static int tegra_gem_mmap(struct drm_gem_object *gem,
-			  struct vm_area_struct *vma)
+int __tegra_gem_mmap(struct drm_gem_object *gem, struct vm_area_struct *vma)
 {
 	struct tegra_bo *bo = to_tegra_bo(gem);
 
@@ -507,7 +506,7 @@ int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 
 	gem = vma->vm_private_data;
 
-	return tegra_gem_mmap(gem, vma);
+	return __tegra_gem_mmap(gem, vma);
 }
 
 static struct sg_table *
@@ -600,7 +599,7 @@ static int tegra_gem_prime_mmap(struct dma_buf *buf, struct vm_area_struct *vma)
 	if (err < 0)
 		return err;
 
-	return tegra_gem_mmap(gem, vma);
+	return __tegra_gem_mmap(gem, vma);
 }
 
 static void *tegra_gem_prime_vmap(struct dma_buf *buf)

commit 04184b1fc990ac67777392be87e020e4f1af185c
Author: Dmitry Osipenko <digetx@gmail.com>
Date:   Wed Dec 20 18:46:13 2017 +0300

    drm/tegra: gem: Correct iommu_map_sg() error checking
    
    iommu_map_sg() doesn't return a error value, but a size of the requested
    IOMMU mapping or zero in case of error.
    
    Signed-off-by: Dmitry Osipenko <digetx@gmail.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index ab1e53d434e8..49b9bf28f872 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -114,7 +114,7 @@ static const struct host1x_bo_ops tegra_bo_ops = {
 static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 {
 	int prot = IOMMU_READ | IOMMU_WRITE;
-	ssize_t err;
+	int err;
 
 	if (bo->mm)
 		return -EBUSY;
@@ -128,22 +128,21 @@ static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 	err = drm_mm_insert_node_generic(&tegra->mm,
 					 bo->mm, bo->gem.size, PAGE_SIZE, 0, 0);
 	if (err < 0) {
-		dev_err(tegra->drm->dev, "out of I/O virtual memory: %zd\n",
+		dev_err(tegra->drm->dev, "out of I/O virtual memory: %d\n",
 			err);
 		goto unlock;
 	}
 
 	bo->paddr = bo->mm->start;
 
-	err = iommu_map_sg(tegra->domain, bo->paddr, bo->sgt->sgl,
-			   bo->sgt->nents, prot);
-	if (err < 0) {
-		dev_err(tegra->drm->dev, "failed to map buffer: %zd\n", err);
+	bo->size = iommu_map_sg(tegra->domain, bo->paddr, bo->sgt->sgl,
+				bo->sgt->nents, prot);
+	if (!bo->size) {
+		dev_err(tegra->drm->dev, "failed to map buffer\n");
+		err = -ENOMEM;
 		goto remove;
 	}
 
-	bo->size = err;
-
 	mutex_unlock(&tegra->mm_lock);
 
 	return 0;

commit 3aadb888b1b62ba04798414cae431d3c3bd5f452
Merge: e5fa05b96b02 ec73c4cfe7de
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Aug 21 17:37:33 2017 +1000

    Merge tag 'drm/tegra/for-4.14-rc1' of git://anongit.freedesktop.org/tegra/linux into drm-next
    
    drm/tegra: Changes for v4.14-rc1
    
    This contains a couple of fixes and improvements for host1x, with some
    preparatory work for Tegra186 support.
    
    The remainder is cleanup and minor bugfixes for Tegra DRM along with
    enhancements to debuggability.
    
    There have also been some enhancements to the kernel interfaces for
    host1x job submissions and support for mmap'ing PRIME buffers directly,
    all of which get the interfaces very close to ready for serious work.
    
    * tag 'drm/tegra/for-4.14-rc1' of git://anongit.freedesktop.org/tegra/linux: (21 commits)
      drm/tegra: Prevent BOs from being freed during job submission
      drm/tegra: gem: Implement mmap() for PRIME buffers
      drm/tegra: Support render node
      drm/tegra: sor: Trace register accesses
      drm/tegra: dpaux: Trace register accesses
      drm/tegra: dsi: Trace register accesses
      drm/tegra: hdmi: Trace register accesses
      drm/tegra: dc: Trace register accesses
      drm/tegra: sor: Use unsigned int for register offsets
      drm/tegra: hdmi: Use unsigned int for register offsets
      drm/tegra: dsi: Use unsigned int for register offsets
      drm/tegra: dpaux: Use unsigned int for register offsets
      drm/tegra: dc: Use unsigned int for register offsets
      drm/tegra: Fix NULL deref in debugfs/iova
      drm/tegra: switch to drm_*_get(), drm_*_put() helpers
      drm/tegra: Set MODULE_FIRMWARE for the VIC
      drm/tegra: Add CONFIG_OF dependency
      gpu: host1x: Support sub-devices recursively
      gpu: host1x: fix error return code in host1x_probe()
      gpu: host1x: Fix bitshift/mask multipliers
      ...

commit a8bc8c6510d64b759644647a03f8aec55056bded
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Aug 15 15:42:40 2017 +0200

    drm/tegra: gem: Implement mmap() for PRIME buffers
    
    The mapping of PRIME buffers can reuse much of the GEM mapping code, so
    extract the common bits into a new tegra_gem_mmap() helper.
    
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index fe77bcd23800..ef068556a9d7 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -481,30 +481,28 @@ const struct vm_operations_struct tegra_bo_vm_ops = {
 	.close = drm_gem_vm_close,
 };
 
-int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
+static int tegra_gem_mmap(struct drm_gem_object *gem,
+			  struct vm_area_struct *vma)
 {
-	struct drm_gem_object *gem;
-	struct tegra_bo *bo;
-	int ret;
-
-	ret = drm_gem_mmap(file, vma);
-	if (ret)
-		return ret;
-
-	gem = vma->vm_private_data;
-	bo = to_tegra_bo(gem);
+	struct tegra_bo *bo = to_tegra_bo(gem);
 
 	if (!bo->pages) {
 		unsigned long vm_pgoff = vma->vm_pgoff;
+		int err;
 
+		/*
+		 * Clear the VM_PFNMAP flag that was set by drm_gem_mmap(),
+		 * and set the vm_pgoff (used as a fake buffer offset by DRM)
+		 * to 0 as we want to map the whole buffer.
+		 */
 		vma->vm_flags &= ~VM_PFNMAP;
 		vma->vm_pgoff = 0;
 
-		ret = dma_mmap_wc(gem->dev->dev, vma, bo->vaddr, bo->paddr,
+		err = dma_mmap_wc(gem->dev->dev, vma, bo->vaddr, bo->paddr,
 				  gem->size);
-		if (ret) {
+		if (err < 0) {
 			drm_gem_vm_close(vma);
-			return ret;
+			return err;
 		}
 
 		vma->vm_pgoff = vm_pgoff;
@@ -520,6 +518,20 @@ int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 	return 0;
 }
 
+int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	struct drm_gem_object *gem;
+	int err;
+
+	err = drm_gem_mmap(file, vma);
+	if (err < 0)
+		return err;
+
+	gem = vma->vm_private_data;
+
+	return tegra_gem_mmap(gem, vma);
+}
+
 static struct sg_table *
 tegra_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,
 			    enum dma_data_direction dir)
@@ -603,7 +615,14 @@ static void tegra_gem_prime_kunmap(struct dma_buf *buf, unsigned long page,
 
 static int tegra_gem_prime_mmap(struct dma_buf *buf, struct vm_area_struct *vma)
 {
-	return -EINVAL;
+	struct drm_gem_object *gem = buf->priv;
+	int err;
+
+	err = drm_gem_mmap_obj(gem, gem->size, vma);
+	if (err < 0)
+		return err;
+
+	return tegra_gem_mmap(gem, vma);
 }
 
 static void *tegra_gem_prime_vmap(struct dma_buf *buf)

commit 7664b2fa42b5e962dd9ffd9e386dc20cbc966176
Author: Cihangir Akturk <cakturk@gmail.com>
Date:   Fri Aug 11 15:33:07 2017 +0300

    drm/tegra: switch to drm_*_get(), drm_*_put() helpers
    
    Use drm_*_get() and drm_*_put() helpers instead of drm_*_reference()
    and drm_*_unreference() helpers.
    
    drm_*_reference() and drm_*_unreference() functions are just
    compatibility alias for drm_*_get() and drm_*_put() and should not be
    used by new code. So convert all users of compatibility functions to
    use the new APIs.
    
    Generated by: scripts/coccinelle/api/drm-get-put.cocci
    
    Signed-off-by: Cihangir Akturk <cakturk@gmail.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 7a39a355678a..fe77bcd23800 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -24,7 +24,7 @@ static void tegra_bo_put(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
 
-	drm_gem_object_unreference_unlocked(&obj->gem);
+	drm_gem_object_put_unlocked(&obj->gem);
 }
 
 static dma_addr_t tegra_bo_pin(struct host1x_bo *bo, struct sg_table **sgt)
@@ -95,7 +95,7 @@ static struct host1x_bo *tegra_bo_get(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
 
-	drm_gem_object_reference(&obj->gem);
+	drm_gem_object_get(&obj->gem);
 
 	return bo;
 }
@@ -325,7 +325,7 @@ struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
 		return ERR_PTR(err);
 	}
 
-	drm_gem_object_unreference_unlocked(&bo->gem);
+	drm_gem_object_put_unlocked(&bo->gem);
 
 	return bo;
 }
@@ -439,7 +439,7 @@ int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
 
 	*offset = drm_vma_node_offset_addr(&bo->gem.vma_node);
 
-	drm_gem_object_unreference_unlocked(gem);
+	drm_gem_object_put_unlocked(gem);
 
 	return 0;
 }
@@ -654,7 +654,7 @@ struct drm_gem_object *tegra_gem_prime_import(struct drm_device *drm,
 		struct drm_gem_object *gem = buf->priv;
 
 		if (gem->dev == drm) {
-			drm_gem_object_reference(gem);
+			drm_gem_object_get(gem);
 			return gem;
 		}
 	}

commit bcf877181eb5439074bf6312e42087d988413adb
Author: Noralf Trønnes <noralf@tronnes.org>
Date:   Sun Aug 6 17:40:55 2017 +0200

    drm/tegra: Use .dumb_map_offset and .dumb_destroy defaults
    
    This driver can use the drm_driver.dumb_destroy and
    drm_driver.dumb_map_offset defaults, so no need to set them.
    
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Signed-off-by: Noralf Trønnes <noralf@tronnes.org>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/1502034068-51384-7-git-send-email-noralf@tronnes.org

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 7a39a355678a..c6079affe642 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -423,27 +423,6 @@ int tegra_bo_dumb_create(struct drm_file *file, struct drm_device *drm,
 	return 0;
 }
 
-int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
-			     u32 handle, u64 *offset)
-{
-	struct drm_gem_object *gem;
-	struct tegra_bo *bo;
-
-	gem = drm_gem_object_lookup(file, handle);
-	if (!gem) {
-		dev_err(drm->dev, "failed to lookup GEM object\n");
-		return -EINVAL;
-	}
-
-	bo = to_tegra_bo(gem);
-
-	*offset = drm_vma_node_offset_addr(&bo->gem.vma_node);
-
-	drm_gem_object_unreference_unlocked(gem);
-
-	return 0;
-}
-
 static int tegra_bo_fault(struct vm_fault *vmf)
 {
 	struct vm_area_struct *vma = vmf->vma;

commit 368f622c0d76a22662af33759be8c4408819295d
Author: Dmitry Osipenko <digetx@gmail.com>
Date:   Thu Jun 15 02:18:26 2017 +0300

    drm/tegra: Check for malformed offsets and sizes in the 'submit' IOCTL
    
    If commands buffer claims a number of words that is higher than its BO can
    fit, a kernel OOPS will be fired on the out-of-bounds BO access. This was
    triggered by an opentegra Xorg driver that erroneously pushed too many
    commands to the pushbuf.
    
    The CDMA commands buffer address is 4 bytes aligned, so check its
    alignment.
    
    The maximum number of the CDMA gather fetches is 16383, add a check for
    it.
    
    Add a sanity check for the relocations in a same way.
    
    [   46.829393] Unable to handle kernel paging request at virtual address f09b2000
    ...
    [<c04a3ba4>] (host1x_job_pin) from [<c04dfcd0>] (tegra_drm_submit+0x474/0x510)
    [<c04dfcd0>] (tegra_drm_submit) from [<c04deea0>] (tegra_submit+0x50/0x6c)
    [<c04deea0>] (tegra_submit) from [<c04c07c0>] (drm_ioctl+0x1e4/0x3ec)
    [<c04c07c0>] (drm_ioctl) from [<c02541a0>] (do_vfs_ioctl+0x9c/0x8e4)
    [<c02541a0>] (do_vfs_ioctl) from [<c0254a1c>] (SyS_ioctl+0x34/0x5c)
    [<c0254a1c>] (SyS_ioctl) from [<c0107640>] (ret_fast_syscall+0x0/0x3c)
    
    Signed-off-by: Dmitry Osipenko <digetx@gmail.com>
    Reviewed-by: Erik Faye-Lund <kusmabite@gmail.com>
    Reviewed-by: Mikko Perttunen <mperttunen@nvidia.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 424569b53e57..7a39a355678a 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -20,11 +20,6 @@
 #include "drm.h"
 #include "gem.h"
 
-static inline struct tegra_bo *host1x_to_tegra_bo(struct host1x_bo *bo)
-{
-	return container_of(bo, struct tegra_bo, base);
-}
-
 static void tegra_bo_put(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);

commit 644b4930bf7e2adeffbe842e1097f7933c6a9158
Merge: 8b03d1ed2c43 b0d36daa0ab5
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri May 5 11:47:01 2017 +1000

    Merge tag 'drm/tegra/for-4.12-rc1' of git://anongit.freedesktop.org/tegra/linux into drm-next
    
    drm/tegra: Changes for v4.12-rc1
    
    This contains various fixes to the host1x driver as well as a plug for a
    leak of kernel pointers to userspace.
    
    A fairly big addition this time around is the Video Image Composer (VIC)
    support that can be used to accelerate some 2D and image compositing
    operations.
    
    Furthermore the driver now supports FB modifiers, so we no longer rely
    on a custom IOCTL to set those.
    
    Finally this contains a few preparatory patches for Tegra186 support
    which unfortunately didn't quite make it this time, but will hopefully
    be ready for v4.13.
    
    * tag 'drm/tegra/for-4.12-rc1' of git://anongit.freedesktop.org/tegra/linux:
      gpu: host1x: Fix host1x driver shutdown
      gpu: host1x: Support module reset
      gpu: host1x: Sort includes alphabetically
      drm/tegra: Add VIC support
      dt-bindings: Add bindings for the Tegra VIC
      drm/tegra: Add falcon helper library
      drm/tegra: Add Tegra DRM allocation API
      drm/tegra: Add tiling FB modifiers
      drm/tegra: Don't leak kernel pointer to userspace
      drm/tegra: Protect IOMMU operations by mutex
      drm/tegra: Enable IOVA API when IOMMU support is enabled
      gpu: host1x: Add IOMMU support
      gpu: host1x: Fix potential out-of-bounds access
      iommu/iova: Fix compile error with CONFIG_IOMMU_IOVA=m
      iommu: Add dummy implementations for !IOMMU_IOVA
      MAINTAINERS: Add related headers to IOMMU section
      iommu/iova: Consolidate code for adding new node to iovad domain rbtree

commit f9b67f0014cba18f1aabb6fa9272335a043eb6fd
Author: Logan Gunthorpe <logang@deltatee.com>
Date:   Wed Apr 19 13:36:10 2017 -0600

    dma-buf: Rename dma-ops to prevent conflict with kunmap_atomic macro
    
    Seeing the kunmap_atomic dma_buf_ops share the same name with a macro
    in highmem.h, the former can be aliased if any dma-buf user includes
    that header.
    
    I'm personally trying to include highmem.h inside scatterlist.h and this
    breaks the dma-buf code proper.
    
    Christoph Hellwig suggested [1] renaming it and pushing this patch ASAP.
    
    To maintain consistency I've renamed all four of kmap* and kunmap* to be
    map* and unmap*. (Even though only kmap_atomic presently conflicts.)
    
    [1] https://www.spinics.net/lists/target-devel/msg15070.html
    
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Reviewed-by: Sinclair Yeh <syeh@vmware.com>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
    Link: http://patchwork.freedesktop.org/patch/msgid/1492630570-879-1-git-send-email-logang@deltatee.com

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 17e62ecb5d4d..8672f5d2f237 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -619,10 +619,10 @@ static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
 	.map_dma_buf = tegra_gem_prime_map_dma_buf,
 	.unmap_dma_buf = tegra_gem_prime_unmap_dma_buf,
 	.release = tegra_gem_prime_release,
-	.kmap_atomic = tegra_gem_prime_kmap_atomic,
-	.kunmap_atomic = tegra_gem_prime_kunmap_atomic,
-	.kmap = tegra_gem_prime_kmap,
-	.kunmap = tegra_gem_prime_kunmap,
+	.map_atomic = tegra_gem_prime_kmap_atomic,
+	.unmap_atomic = tegra_gem_prime_kunmap_atomic,
+	.map = tegra_gem_prime_kmap,
+	.unmap = tegra_gem_prime_kunmap,
 	.mmap = tegra_gem_prime_mmap,
 	.vmap = tegra_gem_prime_vmap,
 	.vunmap = tegra_gem_prime_vunmap,

commit 347ad49d35a1c65d509e7ef5b0760e97ede41ec2
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Mar 9 20:04:56 2017 +0100

    drm/tegra: Protect IOMMU operations by mutex
    
    IOMMU support is currently not thread-safe, which can cause crashes,
    amongst other things, under certain workloads.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 17e62ecb5d4d..050ba78d3fab 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -128,12 +128,14 @@ static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 	if (!bo->mm)
 		return -ENOMEM;
 
+	mutex_lock(&tegra->mm_lock);
+
 	err = drm_mm_insert_node_generic(&tegra->mm,
 					 bo->mm, bo->gem.size, PAGE_SIZE, 0, 0);
 	if (err < 0) {
 		dev_err(tegra->drm->dev, "out of I/O virtual memory: %zd\n",
 			err);
-		goto free;
+		goto unlock;
 	}
 
 	bo->paddr = bo->mm->start;
@@ -147,11 +149,14 @@ static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 
 	bo->size = err;
 
+	mutex_unlock(&tegra->mm_lock);
+
 	return 0;
 
 remove:
 	drm_mm_remove_node(bo->mm);
-free:
+unlock:
+	mutex_unlock(&tegra->mm_lock);
 	kfree(bo->mm);
 	return err;
 }
@@ -161,8 +166,11 @@ static int tegra_bo_iommu_unmap(struct tegra_drm *tegra, struct tegra_bo *bo)
 	if (!bo->mm)
 		return 0;
 
+	mutex_lock(&tegra->mm_lock);
 	iommu_unmap(tegra->domain, bo->paddr, bo->size);
 	drm_mm_remove_node(bo->mm);
+	mutex_unlock(&tegra->mm_lock);
+
 	kfree(bo->mm);
 
 	return 0;

commit 11bac80004499ea59f361ef2a5516c84b6eab675
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Fri Feb 24 14:56:41 2017 -0800

    mm, fs: reduce fault, page_mkwrite, and pfn_mkwrite to take only vmf
    
    ->fault(), ->page_mkwrite(), and ->pfn_mkwrite() calls do not need to
    take a vma and vmf parameter when the vma already resides in vmf.
    
    Remove the vma parameter to simplify things.
    
    [arnd@arndb.de: fix ARM build]
      Link: http://lkml.kernel.org/r/20170125223558.1451224-1-arnd@arndb.de
    Link: http://lkml.kernel.org/r/148521301778.19116.10840599906674778980.stgit@djiang5-desk3.ch.intel.com
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jan Kara <jack@suse.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index b523a5d4a38c..17e62ecb5d4d 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -441,8 +441,9 @@ int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
 	return 0;
 }
 
-static int tegra_bo_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+static int tegra_bo_fault(struct vm_fault *vmf)
 {
+	struct vm_area_struct *vma = vmf->vma;
 	struct drm_gem_object *gem = vma->vm_private_data;
 	struct tegra_bo *bo = to_tegra_bo(gem);
 	struct page *page;

commit 4e64e5539d152e202ad6eea2b6f65f3ab58d9428
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Thu Feb 2 21:04:38 2017 +0000

    drm: Improve drm_mm search (and fix topdown allocation) with rbtrees
    
    The drm_mm range manager claimed to support top-down insertion, but it
    was neither searching for the top-most hole that could fit the
    allocation request nor fitting the request to the hole correctly.
    
    In order to search the range efficiently, we create a secondary index
    for the holes using either their size or their address. This index
    allows us to find the smallest hole or the hole at the bottom or top of
    the range efficiently, whilst keeping the hole stack to rapidly service
    evictions.
    
    v2: Search for holes both high and low. Rename flags to mode.
    v3: Discover rb_entry_safe() and use it!
    v4: Kerneldoc for enum drm_mm_insert_mode.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Reviewed-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Jani Nikula <jani.nikula@linux.intel.com>
    Cc: Sean Paul <seanpaul@chromium.org>
    Cc: Lucas Stach <l.stach@pengutronix.de>
    Cc: Christian Gmeiner <christian.gmeiner@gmail.com>
    Cc: Rob Clark <robdclark@gmail.com>
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Cc: Stephen Warren <swarren@wwwdotorg.org>
    Cc: Alexandre Courbot <gnurou@gmail.com>
    Cc: Eric Anholt <eric@anholt.net>
    Cc: Sinclair Yeh <syeh@vmware.com>
    Cc: Thomas Hellstrom <thellstrom@vmware.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Sinclair Yeh <syeh@vmware.com> # vmwgfx
    Reviewed-by: Lucas Stach <l.stach@pengutronix.de> #etnaviv
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: http://patchwork.freedesktop.org/patch/msgid/20170202210438.28702-1-chris@chris-wilson.co.uk

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 7d853e6b5ff0..b523a5d4a38c 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -128,8 +128,8 @@ static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 	if (!bo->mm)
 		return -ENOMEM;
 
-	err = drm_mm_insert_node_generic(&tegra->mm, bo->mm, bo->gem.size,
-					 PAGE_SIZE, 0, 0, 0);
+	err = drm_mm_insert_node_generic(&tegra->mm,
+					 bo->mm, bo->gem.size, PAGE_SIZE, 0, 0);
 	if (err < 0) {
 		dev_err(tegra->drm->dev, "out of I/O virtual memory: %zd\n",
 			err);

commit 1a29d85eb0f19b7d8271923d8917d7b4f5540b3e
Author: Jan Kara <jack@suse.cz>
Date:   Wed Dec 14 15:07:01 2016 -0800

    mm: use vmf->address instead of of vmf->virtual_address
    
    Every single user of vmf->virtual_address typed that entry to unsigned
    long before doing anything with it so the type of virtual_address does
    not really provide us any additional safety.  Just use masked
    vmf->address which already has the appropriate type.
    
    Link: http://lkml.kernel.org/r/1479460644-25076-3-git-send-email-jack@suse.cz
    Signed-off-by: Jan Kara <jack@suse.cz>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index c08e5279eeac..7d853e6b5ff0 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -452,10 +452,10 @@ static int tegra_bo_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 	if (!bo->pages)
 		return VM_FAULT_SIGBUS;
 
-	offset = ((unsigned long)vmf->virtual_address - vma->vm_start) >> PAGE_SHIFT;
+	offset = (vmf->address - vma->vm_start) >> PAGE_SHIFT;
 	page = bo->pages[offset];
 
-	err = vm_insert_page(vma, (unsigned long)vmf->virtual_address, page);
+	err = vm_insert_page(vma, vmf->address, page);
 	switch (err) {
 	case -EAGAIN:
 	case 0:

commit 585ee0f27ef7b8db46807b960388b7e58b60766d
Author: Mikko Perttunen <mperttunen@nvidia.com>
Date:   Tue Nov 8 19:51:35 2016 +0200

    drm/tegra: Set sgt pointer in BO pin
    
    Fix tegra_bo_pin() to set the parameter sgt pointer. host1x job pinning
    requires the sgt to determine physical memory addresses of gathers.
    
    Signed-off-by: Mikko Perttunen <mperttunen@nvidia.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 25083729a89c..c08e5279eeac 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -36,6 +36,8 @@ static dma_addr_t tegra_bo_pin(struct host1x_bo *bo, struct sg_table **sgt)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
 
+	*sgt = obj->sgt;
+
 	return obj->paddr;
 }
 

commit 7ecada3cc44798c88d2c3deed38746b9a7a9b746
Author: Arto Merilainen <amerilainen@nvidia.com>
Date:   Tue Nov 8 19:51:34 2016 +0200

    drm/tegra: Support kernel mappings with IOMMU
    
    host1x command buffer patching requires that the buffer object can be
    mapped into kernel address space. However, the recent addition of IOMMU
    support did not account for this requirement. Therefore host1x engines
    cannot be used if IOMMU is enabled.
    
    This patch implements kmap, kunmap, mmap and munmap functions to host1x
    buffer objects.
    
    Signed-off-by: Arto Merilainen <amerilainen@nvidia.com>
    Signed-off-by: Mikko Perttunen <mperttunen@nvidia.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 19bf9cdf1f11..25083729a89c 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -2,7 +2,7 @@
  * NVIDIA Tegra DRM GEM helper functions
  *
  * Copyright (C) 2012 Sascha Hauer, Pengutronix
- * Copyright (C) 2013 NVIDIA CORPORATION, All rights reserved.
+ * Copyright (C) 2013-2015 NVIDIA CORPORATION, All rights reserved.
  *
  * Based on the GEM/CMA helpers
  *
@@ -47,23 +47,51 @@ static void *tegra_bo_mmap(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
 
-	return obj->vaddr;
+	if (obj->vaddr)
+		return obj->vaddr;
+	else if (obj->gem.import_attach)
+		return dma_buf_vmap(obj->gem.import_attach->dmabuf);
+	else
+		return vmap(obj->pages, obj->num_pages, VM_MAP,
+			    pgprot_writecombine(PAGE_KERNEL));
 }
 
 static void tegra_bo_munmap(struct host1x_bo *bo, void *addr)
 {
+	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+
+	if (obj->vaddr)
+		return;
+	else if (obj->gem.import_attach)
+		dma_buf_vunmap(obj->gem.import_attach->dmabuf, addr);
+	else
+		vunmap(addr);
 }
 
 static void *tegra_bo_kmap(struct host1x_bo *bo, unsigned int page)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
 
-	return obj->vaddr + page * PAGE_SIZE;
+	if (obj->vaddr)
+		return obj->vaddr + page * PAGE_SIZE;
+	else if (obj->gem.import_attach)
+		return dma_buf_kmap(obj->gem.import_attach->dmabuf, page);
+	else
+		return vmap(obj->pages + page, 1, VM_MAP,
+			    pgprot_writecombine(PAGE_KERNEL));
 }
 
 static void tegra_bo_kunmap(struct host1x_bo *bo, unsigned int page,
 			    void *addr)
 {
+	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+
+	if (obj->vaddr)
+		return;
+	else if (obj->gem.import_attach)
+		dma_buf_kunmap(obj->gem.import_attach->dmabuf, page, addr);
+	else
+		vunmap(addr);
 }
 
 static struct host1x_bo *tegra_bo_get(struct host1x_bo *bo)

commit cc09cb6da9b0eefe4b4e47a73170a349c4cf3426
Author: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
Date:   Sun Oct 30 16:50:29 2016 +0100

    drm/tegra: gem: Remove some dead code
    
    dma_buf_map_attachment() never returns NULL, so there is no need to
    check for it.
    
    Signed-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 95e622e31931..19bf9cdf1f11 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -318,11 +318,6 @@ static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 	get_dma_buf(buf);
 
 	bo->sgt = dma_buf_map_attachment(attach, DMA_TO_DEVICE);
-	if (!bo->sgt) {
-		err = -ENOMEM;
-		goto detach;
-	}
-
 	if (IS_ERR(bo->sgt)) {
 		err = PTR_ERR(bo->sgt);
 		goto detach;

commit a4fce9cb782ad340ee5576a38e934e5e75832dc6
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Wed Oct 5 13:21:44 2016 +0100

    drm/prime: Take a ref on the drm_dev when exporting a dma_buf
    
    dma_buf may live a long time, longer than the last direct user of the
    driver. We already hold a reference to the owner module (that prevents
    the object code from disappearing), but there is no reference to the
    drm_dev - so the pointers to the driver backend themselves may vanish.
    
    v2: Resist temptation to fix the bug in armada_gem.c not setting the
    correct flags on the exported dma-buf (it should pass the flags through
    and not be arbitrarily setting O_RDWR).
    
    Use a common wrapper for exporting the dmabuf and acquiring the
    reference to the drm_device.
    
    Testcase: igt/vgem_basic/unload
    Suggested-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Petri Latvala <petri.latvala@intel.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: stable@vger.kernel.org
    Tested-by: Petri Latvala <petri.latvala@intel.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: http://patchwork.freedesktop.org/patch/msgid/20161005122145.1507-2-chris@chris-wilson.co.uk

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index aa60d9909ea2..95e622e31931 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -613,7 +613,7 @@ struct dma_buf *tegra_gem_prime_export(struct drm_device *drm,
 	exp_info.flags = flags;
 	exp_info.priv = gem;
 
-	return dma_buf_export(&exp_info);
+	return drm_gem_dmabuf_export(drm, &exp_info);
 }
 
 struct drm_gem_object *tegra_gem_prime_import(struct drm_device *drm,

commit a8ad0bd84f986072314595d05444719fdf29e412
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Mon May 9 11:04:54 2016 +0100

    drm: Remove unused drm_device from drm_gem_object_lookup()
    
    drm_gem_object_lookup() has never required the drm_device for its file
    local translation of the user handle to the GEM object. Let's remove the
    unused parameter and save some space.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: dri-devel@lists.freedesktop.org
    Cc: Dave Airlie <airlied@redhat.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    [danvet: Fixup kerneldoc too.]
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 3b0d8c392b70..aa60d9909ea2 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -401,7 +401,7 @@ int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
 	struct drm_gem_object *gem;
 	struct tegra_bo *bo;
 
-	gem = drm_gem_object_lookup(drm, file, handle);
+	gem = drm_gem_object_lookup(file, handle);
 	if (!gem) {
 		dev_err(drm->dev, "failed to lookup GEM object\n");
 		return -EINVAL;

commit f6e45661f9be546811b62b2b01f32f4bf0c436c0
Author: Luis R. Rodriguez <mcgrof@suse.com>
Date:   Fri Jan 22 18:34:22 2016 -0800

    dma, mm/pat: Rename dma_*_writecombine() to dma_*_wc()
    
    Rename dma_*_writecombine() to dma_*_wc(), so that the naming
    is coherent across the various write-combining APIs. Keep the
    old names for compatibility for a while, these can be removed
    at a later time. A guard is left to enable backporting of the
    rename, and later remove of the old mapping defines seemlessly.
    
    Build tested successfully with allmodconfig.
    
    The following Coccinelle SmPL patch was used for this simple
    transformation:
    
    @ rename_dma_alloc_writecombine @
    expression dev, size, dma_addr, gfp;
    @@
    
    -dma_alloc_writecombine(dev, size, dma_addr, gfp)
    +dma_alloc_wc(dev, size, dma_addr, gfp)
    
    @ rename_dma_free_writecombine @
    expression dev, size, cpu_addr, dma_addr;
    @@
    
    -dma_free_writecombine(dev, size, cpu_addr, dma_addr)
    +dma_free_wc(dev, size, cpu_addr, dma_addr)
    
    @ rename_dma_mmap_writecombine @
    expression dev, vma, cpu_addr, dma_addr, size;
    @@
    
    -dma_mmap_writecombine(dev, vma, cpu_addr, dma_addr, size)
    +dma_mmap_wc(dev, vma, cpu_addr, dma_addr, size)
    
    We also keep the old names as compatibility helpers, and
    guard against their definition to make backporting easier.
    
    Generated-by: Coccinelle SmPL
    Suggested-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Luis R. Rodriguez <mcgrof@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: airlied@linux.ie
    Cc: akpm@linux-foundation.org
    Cc: benh@kernel.crashing.org
    Cc: bhelgaas@google.com
    Cc: bp@suse.de
    Cc: dan.j.williams@intel.com
    Cc: daniel.vetter@ffwll.ch
    Cc: dhowells@redhat.com
    Cc: julia.lawall@lip6.fr
    Cc: konrad.wilk@oracle.com
    Cc: linux-fbdev@vger.kernel.org
    Cc: linux-pci@vger.kernel.org
    Cc: luto@amacapital.net
    Cc: mst@redhat.com
    Cc: tomi.valkeinen@ti.com
    Cc: toshi.kani@hp.com
    Cc: vinod.koul@intel.com
    Cc: xen-devel@lists.xensource.com
    Link: http://lkml.kernel.org/r/1453516462-4844-1-git-send-email-mcgrof@do-not-panic.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 33add93b4ed9..3b0d8c392b70 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -175,8 +175,7 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 		sg_free_table(bo->sgt);
 		kfree(bo->sgt);
 	} else if (bo->vaddr) {
-		dma_free_writecombine(drm->dev, bo->gem.size, bo->vaddr,
-				      bo->paddr);
+		dma_free_wc(drm->dev, bo->gem.size, bo->vaddr, bo->paddr);
 	}
 }
 
@@ -233,8 +232,8 @@ static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo)
 	} else {
 		size_t size = bo->gem.size;
 
-		bo->vaddr = dma_alloc_writecombine(drm->dev, size, &bo->paddr,
-						   GFP_KERNEL | __GFP_NOWARN);
+		bo->vaddr = dma_alloc_wc(drm->dev, size, &bo->paddr,
+					 GFP_KERNEL | __GFP_NOWARN);
 		if (!bo->vaddr) {
 			dev_err(drm->dev,
 				"failed to allocate buffer of size %zu\n",
@@ -472,8 +471,8 @@ int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 		vma->vm_flags &= ~VM_PFNMAP;
 		vma->vm_pgoff = 0;
 
-		ret = dma_mmap_writecombine(gem->dev->dev, vma, bo->vaddr,
-					    bo->paddr, gem->size);
+		ret = dma_mmap_wc(gem->dev->dev, vma, bo->vaddr, bo->paddr,
+				  gem->size);
 		if (ret) {
 			drm_gem_vm_close(vma);
 			return ret;

commit a07cdfe5389e0ca43f525c7d1da0930b7447e0c8
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Mon Nov 23 10:32:48 2015 +0100

    drm/tegra: Use drm_gem_object_unreference_unlocked()
    
    This only grabs the mutex when really needed, but still has a might-
    acquire lockdep check to make sure that's always possible. With this
    patch Tegra DRM is officially struct_mutex free, yay!
    
    v2: refernce_unlocked doesn't exist as kbuild spotted.
    
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Acked-by: Thierry Reding <thierry.reding@gmail.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    [treding@nvidia.com: remove unused variables]
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index fb712316c522..33add93b4ed9 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -28,11 +28,8 @@ static inline struct tegra_bo *host1x_to_tegra_bo(struct host1x_bo *bo)
 static void tegra_bo_put(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
-	struct drm_device *drm = obj->gem.dev;
 
-	mutex_lock(&drm->struct_mutex);
-	drm_gem_object_unreference(&obj->gem);
-	mutex_unlock(&drm->struct_mutex);
+	drm_gem_object_unreference_unlocked(&obj->gem);
 }
 
 static dma_addr_t tegra_bo_pin(struct host1x_bo *bo, struct sg_table **sgt)
@@ -72,11 +69,8 @@ static void tegra_bo_kunmap(struct host1x_bo *bo, unsigned int page,
 static struct host1x_bo *tegra_bo_get(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
-	struct drm_device *drm = obj->gem.dev;
 
-	mutex_lock(&drm->struct_mutex);
 	drm_gem_object_reference(&obj->gem);
-	mutex_unlock(&drm->struct_mutex);
 
 	return bo;
 }

commit d849c82fac61921301cf2d6f0a3477a121a2ef2a
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Mon Nov 23 10:32:47 2015 +0100

    drm/tegra: Don't take dev->struct_mutex in mmap offset ioctl
    
    Since David Herrmann's mmap vma manager rework we don't need to grab
    dev->struct_mutex any more to prevent races when looking up the mmap
    offset. Drop it and instead don't forget to use the unref_unlocked
    variant (since the drm core still cares).
    
    v2: Finally get rid of the copypasta from another commit in this
    commit message. And convert to _unlocked like we need to (Patrik).
    
    Cc: Patrik Jakobsson <patrik.r.jakobsson@gmail.com>
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Acked-by: Thierry Reding <thierry.reding@gmail.com>
    Reviewed-by: Patrik Jakobsson <patrik.r.jakobsson@gmail.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 01e16e146bfe..fb712316c522 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -408,12 +408,9 @@ int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
 	struct drm_gem_object *gem;
 	struct tegra_bo *bo;
 
-	mutex_lock(&drm->struct_mutex);
-
 	gem = drm_gem_object_lookup(drm, file, handle);
 	if (!gem) {
 		dev_err(drm->dev, "failed to lookup GEM object\n");
-		mutex_unlock(&drm->struct_mutex);
 		return -EINVAL;
 	}
 
@@ -421,9 +418,7 @@ int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
 
 	*offset = drm_vma_node_offset_addr(&bo->gem.vma_node);
 
-	drm_gem_object_unreference(gem);
-
-	mutex_unlock(&drm->struct_mutex);
+	drm_gem_object_unreference_unlocked(gem);
 
 	return 0;
 }

commit fd73caa5e72f0fcf9732b18d123eead96286fd5b
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Apr 14 12:52:36 2015 +0200

    drm/tegra: gem: Flush pages after allocation
    
    Pages allocated from shmemfs don't end up being cleared and flushed on
    ARMv7, so they must be flushed explicitly. Use the DMA mapping API for
    that purpose, even though it's not used for anything else.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 1217272a51f2..01e16e146bfe 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -189,7 +189,6 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 {
 	struct scatterlist *s;
-	struct sg_table *sgt;
 	unsigned int i;
 
 	bo->pages = drm_gem_get_pages(&bo->gem);
@@ -198,36 +197,28 @@ static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 
 	bo->num_pages = bo->gem.size >> PAGE_SHIFT;
 
-	sgt = drm_prime_pages_to_sg(bo->pages, bo->num_pages);
-	if (IS_ERR(sgt))
+	bo->sgt = drm_prime_pages_to_sg(bo->pages, bo->num_pages);
+	if (IS_ERR(bo->sgt))
 		goto put_pages;
 
 	/*
-	 * Fake up the SG table so that dma_map_sg() can be used to flush the
-	 * pages associated with it. Note that this relies on the fact that
-	 * the DMA API doesn't hook into IOMMU on Tegra, therefore mapping is
-	 * only cache maintenance.
+	 * Fake up the SG table so that dma_sync_sg_for_device() can be used
+	 * to flush the pages associated with it.
 	 *
 	 * TODO: Replace this by drm_clflash_sg() once it can be implemented
 	 * without relying on symbols that are not exported.
 	 */
-	for_each_sg(sgt->sgl, s, sgt->nents, i)
+	for_each_sg(bo->sgt->sgl, s, bo->sgt->nents, i)
 		sg_dma_address(s) = sg_phys(s);
 
-	if (dma_map_sg(drm->dev, sgt->sgl, sgt->nents, DMA_TO_DEVICE) == 0)
-		goto release_sgt;
-
-	bo->sgt = sgt;
+	dma_sync_sg_for_device(drm->dev, bo->sgt->sgl, bo->sgt->nents,
+			       DMA_TO_DEVICE);
 
 	return 0;
 
-release_sgt:
-	sg_free_table(sgt);
-	kfree(sgt);
-	sgt = ERR_PTR(-ENOMEM);
 put_pages:
 	drm_gem_put_pages(&bo->gem, bo->pages, false, false);
-	return PTR_ERR(sgt);
+	return PTR_ERR(bo->sgt);
 }
 
 static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo)

commit d8fbe341beb617ebb22b98fb893e4aa32ae2d864
Author: Sumit Semwal <sumit.semwal@linaro.org>
Date:   Fri Jan 23 12:53:43 2015 +0530

    dma-buf: cleanup dma_buf_export() to make it easily extensible
    
    At present, dma_buf_export() takes a series of parameters, which
    makes it difficult to add any new parameters for exporters, if required.
    
    Make it simpler by moving all these parameters into a struct, and pass
    the struct * as parameter to dma_buf_export().
    
    While at it, unite dma_buf_export_named() with dma_buf_export(), and
    change all callers accordingly.
    
    Reviewed-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Daniel Thompson <daniel.thompson@linaro.org>
    Acked-by: Mauro Carvalho Chehab <mchehab@osg.samsung.com>
    Acked-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index cfb481943b6b..1217272a51f2 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -627,8 +627,14 @@ struct dma_buf *tegra_gem_prime_export(struct drm_device *drm,
 				       struct drm_gem_object *gem,
 				       int flags)
 {
-	return dma_buf_export(gem, &tegra_gem_prime_dmabuf_ops, gem->size,
-			      flags, NULL);
+	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);
+
+	exp_info.ops = &tegra_gem_prime_dmabuf_ops;
+	exp_info.size = gem->size;
+	exp_info.flags = flags;
+	exp_info.priv = gem;
+
+	return dma_buf_export(&exp_info);
 }
 
 struct drm_gem_object *tegra_gem_prime_import(struct drm_device *drm,

commit 2cb207e413a9ace502edbce51c604e2088b0acb2
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Fri Jan 16 13:43:42 2015 +0300

    drm/tegra: gem: oops in error handling
    
    kfree(ERR_PTR(-ENOMEM)) will not work very well.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 1ccde09d01c8..cfb481943b6b 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -214,10 +214,8 @@ static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 	for_each_sg(sgt->sgl, s, sgt->nents, i)
 		sg_dma_address(s) = sg_phys(s);
 
-	if (dma_map_sg(drm->dev, sgt->sgl, sgt->nents, DMA_TO_DEVICE) == 0) {
-		sgt = ERR_PTR(-ENOMEM);
+	if (dma_map_sg(drm->dev, sgt->sgl, sgt->nents, DMA_TO_DEVICE) == 0)
 		goto release_sgt;
-	}
 
 	bo->sgt = sgt;
 
@@ -226,6 +224,7 @@ static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 release_sgt:
 	sg_free_table(sgt);
 	kfree(sgt);
+	sgt = ERR_PTR(-ENOMEM);
 put_pages:
 	drm_gem_put_pages(&bo->gem, bo->pages, false, false);
 	return PTR_ERR(sgt);

commit 8c8cb58ed6429da3cd41c1b44770c7a4b1b33933
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Dec 17 16:46:37 2014 +0100

    drm/tegra: gem: Use iommu_map_sg()
    
    The iommu_map_sg() function is now available in the IOMMU API, so drop
    the open-coded variant.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 8777b7f75791..1ccde09d01c8 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -92,36 +92,6 @@ static const struct host1x_bo_ops tegra_bo_ops = {
 	.kunmap = tegra_bo_kunmap,
 };
 
-/*
- * A generic iommu_map_sg() function is being reviewed and will hopefully be
- * merged soon. At that point this function can be dropped in favour of the
- * one provided by the IOMMU API.
- */
-static ssize_t __iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
-			      struct scatterlist *sg, unsigned int nents,
-			      int prot)
-{
-	struct scatterlist *s;
-	size_t offset = 0;
-	unsigned int i;
-	int err;
-
-	for_each_sg(sg, s, nents, i) {
-		phys_addr_t phys = page_to_phys(sg_page(s));
-		size_t length = s->offset + s->length;
-
-		err = iommu_map(domain, iova + offset, phys, length, prot);
-		if (err < 0) {
-			iommu_unmap(domain, iova, offset);
-			return err;
-		}
-
-		offset += length;
-	}
-
-	return offset;
-}
-
 static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 {
 	int prot = IOMMU_READ | IOMMU_WRITE;
@@ -144,8 +114,8 @@ static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
 
 	bo->paddr = bo->mm->start;
 
-	err = __iommu_map_sg(tegra->domain, bo->paddr, bo->sgt->sgl,
-			     bo->sgt->nents, prot);
+	err = iommu_map_sg(tegra->domain, bo->paddr, bo->sgt->sgl,
+			   bo->sgt->nents, prot);
 	if (err < 0) {
 		dev_err(tegra->drm->dev, "failed to map buffer: %zd\n", err);
 		goto remove;

commit 73c42c79767a03ae64d11457e3ce80e80e09e514
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Dec 16 16:41:47 2014 +0100

    drm/tegra: gem: Use the proper size for GEM objects
    
    If the requested buffer size wasn't a multiple of the page size, the
    IOMMU code would round down the size to the next multiple of the page
    size, thereby causing translation errors. To fix this we no longer pass
    around the requested size but reuse the computed size of the GEM object.
    This is already rounded to the next page boundary, so mapping that size
    works out fine.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index c888bed4036f..8777b7f75791 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -216,8 +216,7 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 	}
 }
 
-static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo,
-			      size_t size)
+static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo)
 {
 	struct scatterlist *s;
 	struct sg_table *sgt;
@@ -227,7 +226,7 @@ static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo,
 	if (IS_ERR(bo->pages))
 		return PTR_ERR(bo->pages);
 
-	bo->num_pages = size >> PAGE_SHIFT;
+	bo->num_pages = bo->gem.size >> PAGE_SHIFT;
 
 	sgt = drm_prime_pages_to_sg(bo->pages, bo->num_pages);
 	if (IS_ERR(sgt))
@@ -262,14 +261,13 @@ static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo,
 	return PTR_ERR(sgt);
 }
 
-static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo,
-			  size_t size)
+static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo)
 {
 	struct tegra_drm *tegra = drm->dev_private;
 	int err;
 
 	if (tegra->domain) {
-		err = tegra_bo_get_pages(drm, bo, size);
+		err = tegra_bo_get_pages(drm, bo);
 		if (err < 0)
 			return err;
 
@@ -279,6 +277,8 @@ static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo,
 			return err;
 		}
 	} else {
+		size_t size = bo->gem.size;
+
 		bo->vaddr = dma_alloc_writecombine(drm->dev, size, &bo->paddr,
 						   GFP_KERNEL | __GFP_NOWARN);
 		if (!bo->vaddr) {
@@ -302,7 +302,7 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, size_t size,
 	if (IS_ERR(bo))
 		return bo;
 
-	err = tegra_bo_alloc(drm, bo, size);
+	err = tegra_bo_alloc(drm, bo);
 	if (err < 0)
 		goto release;
 

commit a04251fc94b58ec25476e57986dfec727b812c22
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Dec 16 16:35:26 2014 +0100

    drm/tegra: gem: Flush buffer objects upon allocation
    
    Buffers obtained via shmem may still have associated cachelines. If they
    aren't properly flushed they may cause framebuffer corruption if the
    cache gets flushed after the application has drawn to it.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index da32086cbeaf..c888bed4036f 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -219,19 +219,47 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo,
 			      size_t size)
 {
+	struct scatterlist *s;
+	struct sg_table *sgt;
+	unsigned int i;
+
 	bo->pages = drm_gem_get_pages(&bo->gem);
 	if (IS_ERR(bo->pages))
 		return PTR_ERR(bo->pages);
 
 	bo->num_pages = size >> PAGE_SHIFT;
 
-	bo->sgt = drm_prime_pages_to_sg(bo->pages, bo->num_pages);
-	if (IS_ERR(bo->sgt)) {
-		drm_gem_put_pages(&bo->gem, bo->pages, false, false);
-		return PTR_ERR(bo->sgt);
+	sgt = drm_prime_pages_to_sg(bo->pages, bo->num_pages);
+	if (IS_ERR(sgt))
+		goto put_pages;
+
+	/*
+	 * Fake up the SG table so that dma_map_sg() can be used to flush the
+	 * pages associated with it. Note that this relies on the fact that
+	 * the DMA API doesn't hook into IOMMU on Tegra, therefore mapping is
+	 * only cache maintenance.
+	 *
+	 * TODO: Replace this by drm_clflash_sg() once it can be implemented
+	 * without relying on symbols that are not exported.
+	 */
+	for_each_sg(sgt->sgl, s, sgt->nents, i)
+		sg_dma_address(s) = sg_phys(s);
+
+	if (dma_map_sg(drm->dev, sgt->sgl, sgt->nents, DMA_TO_DEVICE) == 0) {
+		sgt = ERR_PTR(-ENOMEM);
+		goto release_sgt;
 	}
 
+	bo->sgt = sgt;
+
 	return 0;
+
+release_sgt:
+	sg_free_table(sgt);
+	kfree(sgt);
+put_pages:
+	drm_gem_put_pages(&bo->gem, bo->pages, false, false);
+	return PTR_ERR(sgt);
 }
 
 static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo,

commit 7e0180e3570cc791e95e6b6cd5fbeb0aedc62776
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Nov 6 14:41:31 2014 +0100

    drm/tegra: gem: Check before freeing CMA memory
    
    dma_free_writecombine() must not be called on a buffer that couldn't be
    allocated. Check for a valid virtual address before attempting to free
    the memory to avoid a crash.
    
    Reported-by: Sean Paul <seanpaul@chromium.org>
    Reviewed-by: Sean Paul <seanpaul@chromium.org>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 4a4f967c6397..da32086cbeaf 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -210,7 +210,7 @@ static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
 		drm_gem_put_pages(&bo->gem, bo->pages, true, true);
 		sg_free_table(bo->sgt);
 		kfree(bo->sgt);
-	} else {
+	} else if (bo->vaddr) {
 		dma_free_writecombine(drm->dev, bo->gem.size, bo->vaddr,
 				      bo->paddr);
 	}

commit 71c38629d6bd4be74009fc73946255254477c77e
Author: Thierry Reding <treding@nvidia.com>
Date:   Mon Nov 3 13:23:02 2014 +0100

    drm/tegra: gem: Use more consistent data types
    
    Use size_t consistently for sizes and u32/u64 instead of uint32_t and
    uint64_t.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 8348783f7d64..4a4f967c6397 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -264,7 +264,7 @@ static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo,
 	return 0;
 }
 
-struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
+struct tegra_bo *tegra_bo_create(struct drm_device *drm, size_t size,
 				 unsigned long flags)
 {
 	struct tegra_bo *bo;
@@ -294,9 +294,9 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 
 struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
 					     struct drm_device *drm,
-					     unsigned int size,
+					     size_t size,
 					     unsigned long flags,
-					     unsigned int *handle)
+					     u32 *handle)
 {
 	struct tegra_bo *bo;
 	int err;
@@ -415,7 +415,7 @@ int tegra_bo_dumb_create(struct drm_file *file, struct drm_device *drm,
 }
 
 int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
-			     uint32_t handle, uint64_t *offset)
+			     u32 handle, u64 *offset)
 {
 	struct drm_gem_object *gem;
 	struct tegra_bo *bo;

commit dc6057ecb39edb34b0461ca55382094410bd257a
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Oct 30 15:32:56 2014 +0100

    drm/tegra: gem: dumb: pitch and size are outputs
    
    When creating a dumb buffer object using the DRM_IOCTL_MODE_CREATE_DUMB
    IOCTL, only the width, height, bpp and flags parameters are inputs. The
    caller is not guaranteed to zero out or set handle, pitch and size, so
    the driver must not treat these values as possible inputs.
    
    Fixes a bug where running the Weston compositor on Tegra DRM would cause
    an attempt to allocate a 3 GiB framebuffer to be allocated.
    
    Fixes: de2ba664c30f ("gpu: host1x: drm: Add memory manager and fb")
    Cc: stable@vger.kernel.org
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 8b1095d05c58..8348783f7d64 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -399,16 +399,12 @@ void tegra_bo_free_object(struct drm_gem_object *gem)
 int tegra_bo_dumb_create(struct drm_file *file, struct drm_device *drm,
 			 struct drm_mode_create_dumb *args)
 {
-	int min_pitch = DIV_ROUND_UP(args->width * args->bpp, 8);
+	unsigned int min_pitch = DIV_ROUND_UP(args->width * args->bpp, 8);
 	struct tegra_drm *tegra = drm->dev_private;
 	struct tegra_bo *bo;
 
-	min_pitch = round_up(min_pitch, tegra->pitch_align);
-	if (args->pitch < min_pitch)
-		args->pitch = min_pitch;
-
-	if (args->size < args->pitch * args->height)
-		args->size = args->pitch * args->height;
+	args->pitch = round_up(min_pitch, tegra->pitch_align);
+	args->size = args->pitch * args->height;
 
 	bo = tegra_bo_create_with_handle(file, drm, args->size, 0,
 					 &args->handle);

commit df06b759f2cf4690fa9991edb1504ba39932b2bb
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Jun 26 21:41:53 2014 +0200

    drm/tegra: Add IOMMU support
    
    When an IOMMU device is available on the platform bus, allocate an IOMMU
    domain and attach the display controllers to it. The display controllers
    can then scan out non-contiguous buffers by mapping them through the
    IOMMU.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 9905598ebfc4..8b1095d05c58 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -14,6 +14,7 @@
  */
 
 #include <linux/dma-buf.h>
+#include <linux/iommu.h>
 #include <drm/tegra_drm.h>
 
 #include "drm.h"
@@ -91,6 +92,88 @@ static const struct host1x_bo_ops tegra_bo_ops = {
 	.kunmap = tegra_bo_kunmap,
 };
 
+/*
+ * A generic iommu_map_sg() function is being reviewed and will hopefully be
+ * merged soon. At that point this function can be dropped in favour of the
+ * one provided by the IOMMU API.
+ */
+static ssize_t __iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
+			      struct scatterlist *sg, unsigned int nents,
+			      int prot)
+{
+	struct scatterlist *s;
+	size_t offset = 0;
+	unsigned int i;
+	int err;
+
+	for_each_sg(sg, s, nents, i) {
+		phys_addr_t phys = page_to_phys(sg_page(s));
+		size_t length = s->offset + s->length;
+
+		err = iommu_map(domain, iova + offset, phys, length, prot);
+		if (err < 0) {
+			iommu_unmap(domain, iova, offset);
+			return err;
+		}
+
+		offset += length;
+	}
+
+	return offset;
+}
+
+static int tegra_bo_iommu_map(struct tegra_drm *tegra, struct tegra_bo *bo)
+{
+	int prot = IOMMU_READ | IOMMU_WRITE;
+	ssize_t err;
+
+	if (bo->mm)
+		return -EBUSY;
+
+	bo->mm = kzalloc(sizeof(*bo->mm), GFP_KERNEL);
+	if (!bo->mm)
+		return -ENOMEM;
+
+	err = drm_mm_insert_node_generic(&tegra->mm, bo->mm, bo->gem.size,
+					 PAGE_SIZE, 0, 0, 0);
+	if (err < 0) {
+		dev_err(tegra->drm->dev, "out of I/O virtual memory: %zd\n",
+			err);
+		goto free;
+	}
+
+	bo->paddr = bo->mm->start;
+
+	err = __iommu_map_sg(tegra->domain, bo->paddr, bo->sgt->sgl,
+			     bo->sgt->nents, prot);
+	if (err < 0) {
+		dev_err(tegra->drm->dev, "failed to map buffer: %zd\n", err);
+		goto remove;
+	}
+
+	bo->size = err;
+
+	return 0;
+
+remove:
+	drm_mm_remove_node(bo->mm);
+free:
+	kfree(bo->mm);
+	return err;
+}
+
+static int tegra_bo_iommu_unmap(struct tegra_drm *tegra, struct tegra_bo *bo)
+{
+	if (!bo->mm)
+		return 0;
+
+	iommu_unmap(tegra->domain, bo->paddr, bo->size);
+	drm_mm_remove_node(bo->mm);
+	kfree(bo->mm);
+
+	return 0;
+}
+
 static struct tegra_bo *tegra_bo_alloc_object(struct drm_device *drm,
 					      size_t size)
 {
@@ -121,9 +204,64 @@ static struct tegra_bo *tegra_bo_alloc_object(struct drm_device *drm,
 	return ERR_PTR(err);
 }
 
-static void tegra_bo_destroy(struct drm_device *drm, struct tegra_bo *bo)
+static void tegra_bo_free(struct drm_device *drm, struct tegra_bo *bo)
+{
+	if (bo->pages) {
+		drm_gem_put_pages(&bo->gem, bo->pages, true, true);
+		sg_free_table(bo->sgt);
+		kfree(bo->sgt);
+	} else {
+		dma_free_writecombine(drm->dev, bo->gem.size, bo->vaddr,
+				      bo->paddr);
+	}
+}
+
+static int tegra_bo_get_pages(struct drm_device *drm, struct tegra_bo *bo,
+			      size_t size)
+{
+	bo->pages = drm_gem_get_pages(&bo->gem);
+	if (IS_ERR(bo->pages))
+		return PTR_ERR(bo->pages);
+
+	bo->num_pages = size >> PAGE_SHIFT;
+
+	bo->sgt = drm_prime_pages_to_sg(bo->pages, bo->num_pages);
+	if (IS_ERR(bo->sgt)) {
+		drm_gem_put_pages(&bo->gem, bo->pages, false, false);
+		return PTR_ERR(bo->sgt);
+	}
+
+	return 0;
+}
+
+static int tegra_bo_alloc(struct drm_device *drm, struct tegra_bo *bo,
+			  size_t size)
 {
-	dma_free_writecombine(drm->dev, bo->gem.size, bo->vaddr, bo->paddr);
+	struct tegra_drm *tegra = drm->dev_private;
+	int err;
+
+	if (tegra->domain) {
+		err = tegra_bo_get_pages(drm, bo, size);
+		if (err < 0)
+			return err;
+
+		err = tegra_bo_iommu_map(tegra, bo);
+		if (err < 0) {
+			tegra_bo_free(drm, bo);
+			return err;
+		}
+	} else {
+		bo->vaddr = dma_alloc_writecombine(drm->dev, size, &bo->paddr,
+						   GFP_KERNEL | __GFP_NOWARN);
+		if (!bo->vaddr) {
+			dev_err(drm->dev,
+				"failed to allocate buffer of size %zu\n",
+				size);
+			return -ENOMEM;
+		}
+	}
+
+	return 0;
 }
 
 struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
@@ -136,14 +274,9 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 	if (IS_ERR(bo))
 		return bo;
 
-	bo->vaddr = dma_alloc_writecombine(drm->dev, size, &bo->paddr,
-					   GFP_KERNEL | __GFP_NOWARN);
-	if (!bo->vaddr) {
-		dev_err(drm->dev, "failed to allocate buffer with size %u\n",
-			size);
-		err = -ENOMEM;
-		goto err_dma;
-	}
+	err = tegra_bo_alloc(drm, bo, size);
+	if (err < 0)
+		goto release;
 
 	if (flags & DRM_TEGRA_GEM_CREATE_TILED)
 		bo->tiling.mode = TEGRA_BO_TILING_MODE_TILED;
@@ -153,9 +286,9 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 
 	return bo;
 
-err_dma:
+release:
+	drm_gem_object_release(&bo->gem);
 	kfree(bo);
-
 	return ERR_PTR(err);
 }
 
@@ -186,6 +319,7 @@ struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
 static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 					struct dma_buf *buf)
 {
+	struct tegra_drm *tegra = drm->dev_private;
 	struct dma_buf_attachment *attach;
 	struct tegra_bo *bo;
 	int err;
@@ -213,12 +347,19 @@ static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 		goto detach;
 	}
 
-	if (bo->sgt->nents > 1) {
-		err = -EINVAL;
-		goto detach;
+	if (tegra->domain) {
+		err = tegra_bo_iommu_map(tegra, bo);
+		if (err < 0)
+			goto detach;
+	} else {
+		if (bo->sgt->nents > 1) {
+			err = -EINVAL;
+			goto detach;
+		}
+
+		bo->paddr = sg_dma_address(bo->sgt->sgl);
 	}
 
-	bo->paddr = sg_dma_address(bo->sgt->sgl);
 	bo->gem.import_attach = attach;
 
 	return bo;
@@ -237,14 +378,18 @@ static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 
 void tegra_bo_free_object(struct drm_gem_object *gem)
 {
+	struct tegra_drm *tegra = gem->dev->dev_private;
 	struct tegra_bo *bo = to_tegra_bo(gem);
 
+	if (tegra->domain)
+		tegra_bo_iommu_unmap(tegra, bo);
+
 	if (gem->import_attach) {
 		dma_buf_unmap_attachment(gem->import_attach, bo->sgt,
 					 DMA_TO_DEVICE);
 		drm_prime_gem_destroy(gem, NULL);
 	} else {
-		tegra_bo_destroy(gem->dev, bo);
+		tegra_bo_free(gem->dev, bo);
 	}
 
 	drm_gem_object_release(gem);
@@ -299,14 +444,44 @@ int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
 	return 0;
 }
 
+static int tegra_bo_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+{
+	struct drm_gem_object *gem = vma->vm_private_data;
+	struct tegra_bo *bo = to_tegra_bo(gem);
+	struct page *page;
+	pgoff_t offset;
+	int err;
+
+	if (!bo->pages)
+		return VM_FAULT_SIGBUS;
+
+	offset = ((unsigned long)vmf->virtual_address - vma->vm_start) >> PAGE_SHIFT;
+	page = bo->pages[offset];
+
+	err = vm_insert_page(vma, (unsigned long)vmf->virtual_address, page);
+	switch (err) {
+	case -EAGAIN:
+	case 0:
+	case -ERESTARTSYS:
+	case -EINTR:
+	case -EBUSY:
+		return VM_FAULT_NOPAGE;
+
+	case -ENOMEM:
+		return VM_FAULT_OOM;
+	}
+
+	return VM_FAULT_SIGBUS;
+}
+
 const struct vm_operations_struct tegra_bo_vm_ops = {
+	.fault = tegra_bo_fault,
 	.open = drm_gem_vm_open,
 	.close = drm_gem_vm_close,
 };
 
 int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 {
-	unsigned long vm_pgoff = vma->vm_pgoff;
 	struct drm_gem_object *gem;
 	struct tegra_bo *bo;
 	int ret;
@@ -318,17 +493,28 @@ int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 	gem = vma->vm_private_data;
 	bo = to_tegra_bo(gem);
 
-	vma->vm_flags &= ~VM_PFNMAP;
-	vma->vm_pgoff = 0;
+	if (!bo->pages) {
+		unsigned long vm_pgoff = vma->vm_pgoff;
 
-	ret = dma_mmap_writecombine(gem->dev->dev, vma, bo->vaddr, bo->paddr,
-				    gem->size);
-	if (ret) {
-		drm_gem_vm_close(vma);
-		return ret;
-	}
+		vma->vm_flags &= ~VM_PFNMAP;
+		vma->vm_pgoff = 0;
 
-	vma->vm_pgoff = vm_pgoff;
+		ret = dma_mmap_writecombine(gem->dev->dev, vma, bo->vaddr,
+					    bo->paddr, gem->size);
+		if (ret) {
+			drm_gem_vm_close(vma);
+			return ret;
+		}
+
+		vma->vm_pgoff = vm_pgoff;
+	} else {
+		pgprot_t prot = vm_get_page_prot(vma->vm_flags);
+
+		vma->vm_flags |= VM_MIXEDMAP;
+		vma->vm_flags &= ~VM_PFNMAP;
+
+		vma->vm_page_prot = pgprot_writecombine(prot);
+	}
 
 	return 0;
 }
@@ -345,21 +531,44 @@ tegra_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,
 	if (!sgt)
 		return NULL;
 
-	if (sg_alloc_table(sgt, 1, GFP_KERNEL)) {
-		kfree(sgt);
-		return NULL;
-	}
+	if (bo->pages) {
+		struct scatterlist *sg;
+		unsigned int i;
+
+		if (sg_alloc_table(sgt, bo->num_pages, GFP_KERNEL))
+			goto free;
 
-	sg_dma_address(sgt->sgl) = bo->paddr;
-	sg_dma_len(sgt->sgl) = gem->size;
+		for_each_sg(sgt->sgl, sg, bo->num_pages, i)
+			sg_set_page(sg, bo->pages[i], PAGE_SIZE, 0);
+
+		if (dma_map_sg(attach->dev, sgt->sgl, sgt->nents, dir) == 0)
+			goto free;
+	} else {
+		if (sg_alloc_table(sgt, 1, GFP_KERNEL))
+			goto free;
+
+		sg_dma_address(sgt->sgl) = bo->paddr;
+		sg_dma_len(sgt->sgl) = gem->size;
+	}
 
 	return sgt;
+
+free:
+	sg_free_table(sgt);
+	kfree(sgt);
+	return NULL;
 }
 
 static void tegra_gem_prime_unmap_dma_buf(struct dma_buf_attachment *attach,
 					  struct sg_table *sgt,
 					  enum dma_data_direction dir)
 {
+	struct drm_gem_object *gem = attach->dmabuf->priv;
+	struct tegra_bo *bo = to_tegra_bo(gem);
+
+	if (bo->pages)
+		dma_unmap_sg(attach->dev, sgt->sgl, sgt->nents, dir);
+
 	sg_free_table(sgt);
 	kfree(sgt);
 }

commit 53ea72132df8dd62bb77b28df7b05074dcea96fe
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Sep 24 16:14:04 2014 +0200

    drm/tegra: gem: Use dma_mmap_writecombine()
    
    Use the existing API rather than open-coding equivalent functionality
    in the driver.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index a42d4c9a4d7d..9905598ebfc4 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -306,6 +306,7 @@ const struct vm_operations_struct tegra_bo_vm_ops = {
 
 int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 {
+	unsigned long vm_pgoff = vma->vm_pgoff;
 	struct drm_gem_object *gem;
 	struct tegra_bo *bo;
 	int ret;
@@ -317,12 +318,19 @@ int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 	gem = vma->vm_private_data;
 	bo = to_tegra_bo(gem);
 
-	ret = remap_pfn_range(vma, vma->vm_start, bo->paddr >> PAGE_SHIFT,
-			      vma->vm_end - vma->vm_start, vma->vm_page_prot);
-	if (ret)
+	vma->vm_flags &= ~VM_PFNMAP;
+	vma->vm_pgoff = 0;
+
+	ret = dma_mmap_writecombine(gem->dev->dev, vma, bo->vaddr, bo->paddr,
+				    gem->size);
+	if (ret) {
 		drm_gem_vm_close(vma);
+		return ret;
+	}
+
+	vma->vm_pgoff = vm_pgoff;
 
-	return ret;
+	return 0;
 }
 
 static struct sg_table *

commit e55a8bd8ead046e5b7f78c321afc7594034257f9
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Oct 16 14:23:36 2014 +0200

    drm/tegra: gem: Remove redundant drm_gem_free_mmap_offset()
    
    The drm_gem_object_release() function already performs this cleanup, so
    there is no reason to do it explicitly.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index b1d778a7f3e7..a42d4c9a4d7d 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -247,9 +247,7 @@ void tegra_bo_free_object(struct drm_gem_object *gem)
 		tegra_bo_destroy(gem->dev, bo);
 	}
 
-	drm_gem_free_mmap_offset(gem);
 	drm_gem_object_release(gem);
-
 	kfree(bo);
 }
 

commit a8b48df5925fad5ba9ebc49c80ef60774cc97628
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Oct 16 14:22:50 2014 +0200

    drm/tegra: gem: Cleanup tegra_bo_create_with_handle()
    
    There is only a single location where the function needs to do cleanup.
    Skip the error unwinding path and call the cleanup function directly
    instead.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index d86ded791935..b1d778a7f3e7 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -166,23 +166,21 @@ struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
 					     unsigned int *handle)
 {
 	struct tegra_bo *bo;
-	int ret;
+	int err;
 
 	bo = tegra_bo_create(drm, size, flags);
 	if (IS_ERR(bo))
 		return bo;
 
-	ret = drm_gem_handle_create(file, &bo->gem, handle);
-	if (ret)
-		goto err;
+	err = drm_gem_handle_create(file, &bo->gem, handle);
+	if (err) {
+		tegra_bo_free_object(&bo->gem);
+		return ERR_PTR(err);
+	}
 
 	drm_gem_object_unreference_unlocked(&bo->gem);
 
 	return bo;
-
-err:
-	tegra_bo_free_object(&bo->gem);
-	return ERR_PTR(ret);
 }
 
 static struct tegra_bo *tegra_bo_import(struct drm_device *drm,

commit c28d4a317fef0401be180b34f48d193ff2a6787b
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Oct 16 14:18:50 2014 +0200

    drm/tegra: gem: Extract tegra_bo_alloc_object()
    
    This function implements the common buffer object allocation used for
    both allocation and import paths.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index ce023fa3e8ae..d86ded791935 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -91,6 +91,36 @@ static const struct host1x_bo_ops tegra_bo_ops = {
 	.kunmap = tegra_bo_kunmap,
 };
 
+static struct tegra_bo *tegra_bo_alloc_object(struct drm_device *drm,
+					      size_t size)
+{
+	struct tegra_bo *bo;
+	int err;
+
+	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
+	if (!bo)
+		return ERR_PTR(-ENOMEM);
+
+	host1x_bo_init(&bo->base, &tegra_bo_ops);
+	size = round_up(size, PAGE_SIZE);
+
+	err = drm_gem_object_init(drm, &bo->gem, size);
+	if (err < 0)
+		goto free;
+
+	err = drm_gem_create_mmap_offset(&bo->gem);
+	if (err < 0)
+		goto release;
+
+	return bo;
+
+release:
+	drm_gem_object_release(&bo->gem);
+free:
+	kfree(bo);
+	return ERR_PTR(err);
+}
+
 static void tegra_bo_destroy(struct drm_device *drm, struct tegra_bo *bo)
 {
 	dma_free_writecombine(drm->dev, bo->gem.size, bo->vaddr, bo->paddr);
@@ -102,12 +132,9 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 	struct tegra_bo *bo;
 	int err;
 
-	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
-	if (!bo)
-		return ERR_PTR(-ENOMEM);
-
-	host1x_bo_init(&bo->base, &tegra_bo_ops);
-	size = round_up(size, PAGE_SIZE);
+	bo = tegra_bo_alloc_object(drm, size);
+	if (IS_ERR(bo))
+		return bo;
 
 	bo->vaddr = dma_alloc_writecombine(drm->dev, size, &bo->paddr,
 					   GFP_KERNEL | __GFP_NOWARN);
@@ -118,14 +145,6 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 		goto err_dma;
 	}
 
-	err = drm_gem_object_init(drm, &bo->gem, size);
-	if (err)
-		goto err_init;
-
-	err = drm_gem_create_mmap_offset(&bo->gem);
-	if (err)
-		goto err_mmap;
-
 	if (flags & DRM_TEGRA_GEM_CREATE_TILED)
 		bo->tiling.mode = TEGRA_BO_TILING_MODE_TILED;
 
@@ -134,10 +153,6 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 
 	return bo;
 
-err_mmap:
-	drm_gem_object_release(&bo->gem);
-err_init:
-	tegra_bo_destroy(drm, bo);
 err_dma:
 	kfree(bo);
 
@@ -175,28 +190,16 @@ static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 {
 	struct dma_buf_attachment *attach;
 	struct tegra_bo *bo;
-	ssize_t size;
 	int err;
 
-	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
-	if (!bo)
-		return ERR_PTR(-ENOMEM);
-
-	host1x_bo_init(&bo->base, &tegra_bo_ops);
-	size = round_up(buf->size, PAGE_SIZE);
-
-	err = drm_gem_object_init(drm, &bo->gem, size);
-	if (err < 0)
-		goto free;
-
-	err = drm_gem_create_mmap_offset(&bo->gem);
-	if (err < 0)
-		goto release;
+	bo = tegra_bo_alloc_object(drm, buf->size);
+	if (IS_ERR(bo))
+		return bo;
 
 	attach = dma_buf_attach(buf, drm->dev);
 	if (IS_ERR(attach)) {
 		err = PTR_ERR(attach);
-		goto free_mmap;
+		goto free;
 	}
 
 	get_dma_buf(buf);
@@ -228,13 +231,9 @@ static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
 
 	dma_buf_detach(buf, attach);
 	dma_buf_put(buf);
-free_mmap:
-	drm_gem_free_mmap_offset(&bo->gem);
-release:
-	drm_gem_object_release(&bo->gem);
 free:
+	drm_gem_object_release(&bo->gem);
 	kfree(bo);
-
 	return ERR_PTR(err);
 }
 

commit a7d7a143d0b4cb1914705884ca5c25e322dba693
Merge: 43c40df2c7fe 7963e9db1b1f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 7 17:36:12 2014 -0700

    Merge branch 'drm-next' of git://people.freedesktop.org/~airlied/linux
    
    Pull DRM updates from Dave Airlie:
     "Like all good pull reqs this ends with a revert, so it must mean we
      tested it,
    
    [ Ed. That's _one_ way of looking at it ]
    
      This pull is missing nouveau, Ben has been stuck trying to track down
      a very longstanding bug that revealed itself due to some other
      changes.  I've asked him to send you a direct pull request for nouveau
      once he cleans things up.  I'm away until Monday so don't want to
      delay things, you can make a decision on that when he sends it, I have
      my phone so I can ack things just not really merge much.
    
      It has one trivial conflict with your tree in armada_drv.c, and also
      the pull request contains some component changes that are already in
      your tree, the base tree from Russell went via Greg's tree already,
      but some stuff still shows up in here that doesn't when I merge my
      tree into yours.
    
      Otherwise all pretty standard graphics fare, one new driver and
      changes all over the place.
    
      New drivers:
       - sti kms driver for STMicroelectronics chipsets stih416 and stih407.
    
      core:
       - lots of cleanups to the drm core
       - DP MST helper code merged
       - universal cursor planes.
       - render nodes enabled by default
    
      panel:
       - better panel interfaces
       - new panel support
       - non-continuous cock advertising ability
    
      ttm:
       - shrinker fixes
    
      i915:
       - hopefully ditched UMS support
       - runtime pm fixes
       - psr tracking and locking - now enabled by default
       - userptr fixes
       - backlight brightness fixes
       - MST support merged
       - runtime PM for dpms
       - primary planes locking fixes
       - gen8 hw semaphore support
       - fbc fixes
       - runtime PM on SOix sleep state hw.
       - mmio base page flipping
       - lots of vlv/chv fixes.
       - universal cursor planes
    
      radeon:
       - Hawaii fixes
       - display scalar support for non-fixed mode displays
       - new firmware format support
       - dpm on more asics by default
       - GPUVM improvements
       - uncached and wc GTT buffers
       - BOs > visible VRAM
    
      exynos:
       - i80 interface support
       - module auto-loading
       - ipp driver consolidated.
    
      armada:
       - irq handling in crtc layer only
       - crtc renumbering
       - add component support
       - DT interaction changes.
    
      tegra:
       - load as module fixes
       - eDP bpp and sync polarity fixed
       - DSI non-continuous clock mode support
       - better support for importing buffers from nouveau
    
      msm:
       - mdp5/adq8084 v1.3 hw enablement
       - devicetree clk changse
       - ifc6410 board working
    
      tda998x:
       - component support
       - DT documentation update
    
      vmwgfx:
       - fix compat shader namespace"
    
    * 'drm-next' of git://people.freedesktop.org/~airlied/linux: (551 commits)
      Revert "drm: drop redundant drm_file->is_master"
      drm/panel: simple: Use devm_gpiod_get_optional()
      drm/dsi: Replace upcasting macro by function
      drm/panel: ld9040: Replace upcasting macro by function
      drm/exynos: dp: Modify driver to support drm_panel
      drm/exynos: Move DP setup into commit()
      drm/panel: simple: Add AUO B133HTN01 panel support
      drm/panel: simple: Support delays in panel functions
      drm/panel: simple: Add proper definition for prepare and unprepare
      drm/panel: s6e8aa0: Add proper definition for prepare and unprepare
      drm/panel: ld9040: Add proper definition for prepare and unprepare
      drm/tegra: Add support for panel prepare and unprepare routines
      drm/exynos: dsi: Add support for panel prepare and unprepare routines
      drm/exynos: dpi: Add support for panel prepare and unprepare routines
      drm/panel: simple: Add dummy prepare and unprepare routines
      drm/panel: s6e8aa0: Add dummy prepare and unprepare routines
      drm/panel: ld9040: Add dummy prepare and unprepare routines
      drm/panel: Provide convenience wrapper for .get_modes()
      drm/panel: add .prepare() and .unprepare() functions
      drm/panel: simple: Remove simple-panel compatible
      ...

commit d1f3e1e0b38d49cbb996dcf0fde5b5205d12a23d
Author: Thierry Reding <treding@nvidia.com>
Date:   Fri Jul 11 08:29:14 2014 +0200

    drm/tegra: Properly align stride for framebuffers
    
    Tegra20 and Tegra30 both required the buffer line stride to be aligned
    on 8 byte boundaries. Tegra114 and Tegra124 increased the alignment to
    64 bytes. Introduce a parameter to specify the alignment requirements
    for each display controller and round up the pitch of newly allocated
    framebuffers appropriately.
    
    Originally-by: Stéphane Marchesin <marcheu@chromium.org>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index c1e4e8b6e5ca..2545c7a468a2 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -16,6 +16,7 @@
 #include <linux/dma-buf.h>
 #include <drm/tegra_drm.h>
 
+#include "drm.h"
 #include "gem.h"
 
 static inline struct tegra_bo *host1x_to_tegra_bo(struct host1x_bo *bo)
@@ -259,8 +260,10 @@ int tegra_bo_dumb_create(struct drm_file *file, struct drm_device *drm,
 			 struct drm_mode_create_dumb *args)
 {
 	int min_pitch = DIV_ROUND_UP(args->width * args->bpp, 8);
+	struct tegra_drm *tegra = drm->dev_private;
 	struct tegra_bo *bo;
 
+	min_pitch = round_up(min_pitch, tegra->pitch_align);
 	if (args->pitch < min_pitch)
 		args->pitch = min_pitch;
 

commit c134f019abcfaa1cb6e07f6154e92a4f8ce8ddd8
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Jun 3 14:48:12 2014 +0200

    drm/tegra: Implement more tiling modes
    
    Tegra124 supports a block-linear mode in addition to the regular pitch
    linear and tiled modes. Add support for these by moving the internal
    representation into a structure rather than a simple flag.
    
    Tested-by: Alexandre Courbot <acourbot@nvidia.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index aa85b7b26f10..c1e4e8b6e5ca 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -126,7 +126,7 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 		goto err_mmap;
 
 	if (flags & DRM_TEGRA_GEM_CREATE_TILED)
-		bo->flags |= TEGRA_BO_TILED;
+		bo->tiling.mode = TEGRA_BO_TILING_MODE_TILED;
 
 	if (flags & DRM_TEGRA_GEM_CREATE_BOTTOM_UP)
 		bo->flags |= TEGRA_BO_BOTTOM_UP;

commit 3aac4502fd3f80dcf7e65dbf6edd8676893c1f46
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Tue Jul 1 12:57:26 2014 +0200

    dma-buf: use reservation objects
    
    This allows reservation objects to be used in dma-buf. it's required
    for implementing polling support on the fences that belong to a dma-buf.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Acked-by: Mauro Carvalho Chehab <m.chehab@samsung.com> #drivers/media/v4l2-core/
    Acked-by: Thomas Hellstrom <thellstrom@vmware.com> #drivers/gpu/drm/ttm
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Acked-by: Daniel Vetter <daniel@ffwll.ch>
    Signed-off-by: Vincent Stehlé <vincent.stehle@laposte.net> #drivers/gpu/drm/armada/
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index aa85b7b26f10..78cc8143760a 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -420,7 +420,7 @@ struct dma_buf *tegra_gem_prime_export(struct drm_device *drm,
 				       int flags)
 {
 	return dma_buf_export(gem, &tegra_gem_prime_dmabuf_ops, gem->size,
-			      flags);
+			      flags, NULL);
 }
 
 struct drm_gem_object *tegra_gem_prime_import(struct drm_device *drm,

commit 540457cc1fc14707f60b0eddf9df2904ba75c269
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue May 13 16:46:11 2014 +0200

    drm/tegra: gem - Make tegra_bo_import() static
    
    The function is never used outside of the source file and therefore can
    be locally scoped.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index bcf9895cef9f..aa85b7b26f10 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -169,7 +169,8 @@ struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
 	return ERR_PTR(ret);
 }
 
-struct tegra_bo *tegra_bo_import(struct drm_device *drm, struct dma_buf *buf)
+static struct tegra_bo *tegra_bo_import(struct drm_device *drm,
+					struct dma_buf *buf)
 {
 	struct dma_buf_attachment *attach;
 	struct tegra_bo *bo;

commit 9a2ac2dcdc4baa63c913377f9856993498398025
Author: Thierry Reding <treding@nvidia.com>
Date:   Tue Feb 11 15:52:01 2014 +0100

    drm/tegra: Relicense under GPL v2
    
    The majority of the code in this driver is licensed under the GPL v2, so
    relicense the rest under GPL v2 as well for consistency.
    
    Acked-by: Stephen Warren <swarren@nvidia.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 29913eb9b25d..bcf9895cef9f 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -8,14 +8,9 @@
  *
  * Copyright (c) 2011 Samsung Electronics Co., Ltd.
  *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2
- * of the License, or (at your option) any later version.
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
  */
 
 #include <linux/dma-buf.h>

commit d40326f4b9f9617cdfd30f83a2db57d47e9c5bac
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Jan 29 20:32:33 2014 +0100

    drm/tegra: prime: Add vmap support
    
    This is trivial to support since all GEM objects are mapped into kernel
    space anyway.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index ef853e558036..29913eb9b25d 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -394,6 +394,18 @@ static int tegra_gem_prime_mmap(struct dma_buf *buf, struct vm_area_struct *vma)
 	return -EINVAL;
 }
 
+static void *tegra_gem_prime_vmap(struct dma_buf *buf)
+{
+	struct drm_gem_object *gem = buf->priv;
+	struct tegra_bo *bo = to_tegra_bo(gem);
+
+	return bo->vaddr;
+}
+
+static void tegra_gem_prime_vunmap(struct dma_buf *buf, void *vaddr)
+{
+}
+
 static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
 	.map_dma_buf = tegra_gem_prime_map_dma_buf,
 	.unmap_dma_buf = tegra_gem_prime_unmap_dma_buf,
@@ -403,6 +415,8 @@ static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
 	.kmap = tegra_gem_prime_kmap,
 	.kunmap = tegra_gem_prime_kunmap,
 	.mmap = tegra_gem_prime_mmap,
+	.vmap = tegra_gem_prime_vmap,
+	.vunmap = tegra_gem_prime_vunmap,
 };
 
 struct dma_buf *tegra_gem_prime_export(struct drm_device *drm,

commit 3800391db1b22a7f5d5ae92f9c54fa00327d682a
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Dec 12 10:00:43 2013 +0100

    drm/tegra: Add PRIME support
    
    Implement very basic PRIME support. This currently only works with
    buffers that are contiguous in memory and will refuse to import any
    physically non-contiguous buffers.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 7741e3355c98..ef853e558036 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -18,6 +18,7 @@
  * GNU General Public License for more details.
  */
 
+#include <linux/dma-buf.h>
 #include <drm/tegra_drm.h>
 
 #include "gem.h"
@@ -173,13 +174,87 @@ struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
 	return ERR_PTR(ret);
 }
 
+struct tegra_bo *tegra_bo_import(struct drm_device *drm, struct dma_buf *buf)
+{
+	struct dma_buf_attachment *attach;
+	struct tegra_bo *bo;
+	ssize_t size;
+	int err;
+
+	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
+	if (!bo)
+		return ERR_PTR(-ENOMEM);
+
+	host1x_bo_init(&bo->base, &tegra_bo_ops);
+	size = round_up(buf->size, PAGE_SIZE);
+
+	err = drm_gem_object_init(drm, &bo->gem, size);
+	if (err < 0)
+		goto free;
+
+	err = drm_gem_create_mmap_offset(&bo->gem);
+	if (err < 0)
+		goto release;
+
+	attach = dma_buf_attach(buf, drm->dev);
+	if (IS_ERR(attach)) {
+		err = PTR_ERR(attach);
+		goto free_mmap;
+	}
+
+	get_dma_buf(buf);
+
+	bo->sgt = dma_buf_map_attachment(attach, DMA_TO_DEVICE);
+	if (!bo->sgt) {
+		err = -ENOMEM;
+		goto detach;
+	}
+
+	if (IS_ERR(bo->sgt)) {
+		err = PTR_ERR(bo->sgt);
+		goto detach;
+	}
+
+	if (bo->sgt->nents > 1) {
+		err = -EINVAL;
+		goto detach;
+	}
+
+	bo->paddr = sg_dma_address(bo->sgt->sgl);
+	bo->gem.import_attach = attach;
+
+	return bo;
+
+detach:
+	if (!IS_ERR_OR_NULL(bo->sgt))
+		dma_buf_unmap_attachment(attach, bo->sgt, DMA_TO_DEVICE);
+
+	dma_buf_detach(buf, attach);
+	dma_buf_put(buf);
+free_mmap:
+	drm_gem_free_mmap_offset(&bo->gem);
+release:
+	drm_gem_object_release(&bo->gem);
+free:
+	kfree(bo);
+
+	return ERR_PTR(err);
+}
+
 void tegra_bo_free_object(struct drm_gem_object *gem)
 {
 	struct tegra_bo *bo = to_tegra_bo(gem);
 
+	if (gem->import_attach) {
+		dma_buf_unmap_attachment(gem->import_attach, bo->sgt,
+					 DMA_TO_DEVICE);
+		drm_prime_gem_destroy(gem, NULL);
+	} else {
+		tegra_bo_destroy(gem->dev, bo);
+	}
+
 	drm_gem_free_mmap_offset(gem);
 	drm_gem_object_release(gem);
-	tegra_bo_destroy(gem->dev, bo);
 
 	kfree(bo);
 }
@@ -255,3 +330,106 @@ int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
 
 	return ret;
 }
+
+static struct sg_table *
+tegra_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,
+			    enum dma_data_direction dir)
+{
+	struct drm_gem_object *gem = attach->dmabuf->priv;
+	struct tegra_bo *bo = to_tegra_bo(gem);
+	struct sg_table *sgt;
+
+	sgt = kmalloc(sizeof(*sgt), GFP_KERNEL);
+	if (!sgt)
+		return NULL;
+
+	if (sg_alloc_table(sgt, 1, GFP_KERNEL)) {
+		kfree(sgt);
+		return NULL;
+	}
+
+	sg_dma_address(sgt->sgl) = bo->paddr;
+	sg_dma_len(sgt->sgl) = gem->size;
+
+	return sgt;
+}
+
+static void tegra_gem_prime_unmap_dma_buf(struct dma_buf_attachment *attach,
+					  struct sg_table *sgt,
+					  enum dma_data_direction dir)
+{
+	sg_free_table(sgt);
+	kfree(sgt);
+}
+
+static void tegra_gem_prime_release(struct dma_buf *buf)
+{
+	drm_gem_dmabuf_release(buf);
+}
+
+static void *tegra_gem_prime_kmap_atomic(struct dma_buf *buf,
+					 unsigned long page)
+{
+	return NULL;
+}
+
+static void tegra_gem_prime_kunmap_atomic(struct dma_buf *buf,
+					  unsigned long page,
+					  void *addr)
+{
+}
+
+static void *tegra_gem_prime_kmap(struct dma_buf *buf, unsigned long page)
+{
+	return NULL;
+}
+
+static void tegra_gem_prime_kunmap(struct dma_buf *buf, unsigned long page,
+				   void *addr)
+{
+}
+
+static int tegra_gem_prime_mmap(struct dma_buf *buf, struct vm_area_struct *vma)
+{
+	return -EINVAL;
+}
+
+static const struct dma_buf_ops tegra_gem_prime_dmabuf_ops = {
+	.map_dma_buf = tegra_gem_prime_map_dma_buf,
+	.unmap_dma_buf = tegra_gem_prime_unmap_dma_buf,
+	.release = tegra_gem_prime_release,
+	.kmap_atomic = tegra_gem_prime_kmap_atomic,
+	.kunmap_atomic = tegra_gem_prime_kunmap_atomic,
+	.kmap = tegra_gem_prime_kmap,
+	.kunmap = tegra_gem_prime_kunmap,
+	.mmap = tegra_gem_prime_mmap,
+};
+
+struct dma_buf *tegra_gem_prime_export(struct drm_device *drm,
+				       struct drm_gem_object *gem,
+				       int flags)
+{
+	return dma_buf_export(gem, &tegra_gem_prime_dmabuf_ops, gem->size,
+			      flags);
+}
+
+struct drm_gem_object *tegra_gem_prime_import(struct drm_device *drm,
+					      struct dma_buf *buf)
+{
+	struct tegra_bo *bo;
+
+	if (buf->ops == &tegra_gem_prime_dmabuf_ops) {
+		struct drm_gem_object *gem = buf->priv;
+
+		if (gem->dev == drm) {
+			drm_gem_object_reference(gem);
+			return gem;
+		}
+	}
+
+	bo = tegra_bo_import(drm, buf);
+	if (IS_ERR(bo))
+		return ERR_CAST(bo);
+
+	return &bo->gem;
+}

commit 425c0fdc427440fdaf039a649eab713d932fa368
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Dec 12 10:10:46 2013 +0100

    drm/tegra: Do not export tegra_bo_ops
    
    These buffer object operations are never used outside of the GEM
    implementation so there is no use in exporting them.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index de0a9e6207e2..7741e3355c98 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -83,7 +83,7 @@ static struct host1x_bo *tegra_bo_get(struct host1x_bo *bo)
 	return bo;
 }
 
-const struct host1x_bo_ops tegra_bo_ops = {
+static const struct host1x_bo_ops tegra_bo_ops = {
 	.get = tegra_bo_get,
 	.put = tegra_bo_put,
 	.pin = tegra_bo_pin,

commit f1f34ad56456a10262970d56a59931d00346190c
Author: Thierry Reding <treding@nvidia.com>
Date:   Thu Dec 12 10:09:46 2013 +0100

    drm/tegra: Remove spurious blank line
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 28a9cbc07ab9..de0a9e6207e2 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -145,7 +145,6 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 	kfree(bo);
 
 	return ERR_PTR(err);
-
 }
 
 struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,

commit db7fbdfd25ee009165b6c3b80a9d1c6d8534ad94
Author: Thierry Reding <thierry.reding@avionic-design.de>
Date:   Mon Oct 7 09:47:58 2013 +0200

    drm/tegra: Support bottom-up buffer objects
    
    The gr3d engine renders images bottom-up. Allow buffers that are used
    for 3D content to be marked as such and implement support in the display
    controller to present them properly.
    
    Signed-off-by: Thierry Reding <thierry.reding@avionic-design.de>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index d851ec106cf4..28a9cbc07ab9 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -132,6 +132,9 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
 	if (flags & DRM_TEGRA_GEM_CREATE_TILED)
 		bo->flags |= TEGRA_BO_TILED;
 
+	if (flags & DRM_TEGRA_GEM_CREATE_BOTTOM_UP)
+		bo->flags |= TEGRA_BO_BOTTOM_UP;
+
 	return bo;
 
 err_mmap:

commit 773af77fc479fd454c3f6836f86bf63996545cf4
Author: Thierry Reding <thierry.reding@avionic-design.de>
Date:   Fri Oct 4 22:34:01 2013 +0200

    drm/tegra: Add support for tiled buffer objects
    
    The gr2d and gr3d engines work more efficiently on buffers with a tiled
    memory layout. Allow created buffers to be marked as tiled so that the
    display controller can scan them out properly.
    
    Signed-off-by: Thierry Reding <thierry.reding@avionic-design.de>
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index 267c0c21e5cc..d851ec106cf4 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -18,6 +18,8 @@
  * GNU General Public License for more details.
  */
 
+#include <drm/tegra_drm.h>
+
 #include "gem.h"
 
 static inline struct tegra_bo *host1x_to_tegra_bo(struct host1x_bo *bo)
@@ -97,7 +99,8 @@ static void tegra_bo_destroy(struct drm_device *drm, struct tegra_bo *bo)
 	dma_free_writecombine(drm->dev, bo->gem.size, bo->vaddr, bo->paddr);
 }
 
-struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size)
+struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size,
+				 unsigned long flags)
 {
 	struct tegra_bo *bo;
 	int err;
@@ -126,6 +129,9 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size)
 	if (err)
 		goto err_mmap;
 
+	if (flags & DRM_TEGRA_GEM_CREATE_TILED)
+		bo->flags |= TEGRA_BO_TILED;
+
 	return bo;
 
 err_mmap:
@@ -142,12 +148,13 @@ struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size)
 struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
 					     struct drm_device *drm,
 					     unsigned int size,
+					     unsigned long flags,
 					     unsigned int *handle)
 {
 	struct tegra_bo *bo;
 	int ret;
 
-	bo = tegra_bo_create(drm, size);
+	bo = tegra_bo_create(drm, size, flags);
 	if (IS_ERR(bo))
 		return bo;
 
@@ -187,7 +194,7 @@ int tegra_bo_dumb_create(struct drm_file *file, struct drm_device *drm,
 	if (args->size < args->pitch * args->height)
 		args->size = args->pitch * args->height;
 
-	bo = tegra_bo_create_with_handle(file, drm, args->size,
+	bo = tegra_bo_create_with_handle(file, drm, args->size, 0,
 					 &args->handle);
 	if (IS_ERR(bo))
 		return PTR_ERR(bo);

commit dee8268f8fb218c9e9b604a40f7dbdd395e910f9
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Oct 9 10:32:49 2013 +0200

    drm/tegra: Move driver to DRM tree
    
    In order to make subsystem-wide changes easier, move the Tegra DRM
    driver back into the DRM tree.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>

diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
new file mode 100644
index 000000000000..267c0c21e5cc
--- /dev/null
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -0,0 +1,248 @@
+/*
+ * NVIDIA Tegra DRM GEM helper functions
+ *
+ * Copyright (C) 2012 Sascha Hauer, Pengutronix
+ * Copyright (C) 2013 NVIDIA CORPORATION, All rights reserved.
+ *
+ * Based on the GEM/CMA helpers
+ *
+ * Copyright (c) 2011 Samsung Electronics Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include "gem.h"
+
+static inline struct tegra_bo *host1x_to_tegra_bo(struct host1x_bo *bo)
+{
+	return container_of(bo, struct tegra_bo, base);
+}
+
+static void tegra_bo_put(struct host1x_bo *bo)
+{
+	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+	struct drm_device *drm = obj->gem.dev;
+
+	mutex_lock(&drm->struct_mutex);
+	drm_gem_object_unreference(&obj->gem);
+	mutex_unlock(&drm->struct_mutex);
+}
+
+static dma_addr_t tegra_bo_pin(struct host1x_bo *bo, struct sg_table **sgt)
+{
+	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+
+	return obj->paddr;
+}
+
+static void tegra_bo_unpin(struct host1x_bo *bo, struct sg_table *sgt)
+{
+}
+
+static void *tegra_bo_mmap(struct host1x_bo *bo)
+{
+	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+
+	return obj->vaddr;
+}
+
+static void tegra_bo_munmap(struct host1x_bo *bo, void *addr)
+{
+}
+
+static void *tegra_bo_kmap(struct host1x_bo *bo, unsigned int page)
+{
+	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+
+	return obj->vaddr + page * PAGE_SIZE;
+}
+
+static void tegra_bo_kunmap(struct host1x_bo *bo, unsigned int page,
+			    void *addr)
+{
+}
+
+static struct host1x_bo *tegra_bo_get(struct host1x_bo *bo)
+{
+	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
+	struct drm_device *drm = obj->gem.dev;
+
+	mutex_lock(&drm->struct_mutex);
+	drm_gem_object_reference(&obj->gem);
+	mutex_unlock(&drm->struct_mutex);
+
+	return bo;
+}
+
+const struct host1x_bo_ops tegra_bo_ops = {
+	.get = tegra_bo_get,
+	.put = tegra_bo_put,
+	.pin = tegra_bo_pin,
+	.unpin = tegra_bo_unpin,
+	.mmap = tegra_bo_mmap,
+	.munmap = tegra_bo_munmap,
+	.kmap = tegra_bo_kmap,
+	.kunmap = tegra_bo_kunmap,
+};
+
+static void tegra_bo_destroy(struct drm_device *drm, struct tegra_bo *bo)
+{
+	dma_free_writecombine(drm->dev, bo->gem.size, bo->vaddr, bo->paddr);
+}
+
+struct tegra_bo *tegra_bo_create(struct drm_device *drm, unsigned int size)
+{
+	struct tegra_bo *bo;
+	int err;
+
+	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
+	if (!bo)
+		return ERR_PTR(-ENOMEM);
+
+	host1x_bo_init(&bo->base, &tegra_bo_ops);
+	size = round_up(size, PAGE_SIZE);
+
+	bo->vaddr = dma_alloc_writecombine(drm->dev, size, &bo->paddr,
+					   GFP_KERNEL | __GFP_NOWARN);
+	if (!bo->vaddr) {
+		dev_err(drm->dev, "failed to allocate buffer with size %u\n",
+			size);
+		err = -ENOMEM;
+		goto err_dma;
+	}
+
+	err = drm_gem_object_init(drm, &bo->gem, size);
+	if (err)
+		goto err_init;
+
+	err = drm_gem_create_mmap_offset(&bo->gem);
+	if (err)
+		goto err_mmap;
+
+	return bo;
+
+err_mmap:
+	drm_gem_object_release(&bo->gem);
+err_init:
+	tegra_bo_destroy(drm, bo);
+err_dma:
+	kfree(bo);
+
+	return ERR_PTR(err);
+
+}
+
+struct tegra_bo *tegra_bo_create_with_handle(struct drm_file *file,
+					     struct drm_device *drm,
+					     unsigned int size,
+					     unsigned int *handle)
+{
+	struct tegra_bo *bo;
+	int ret;
+
+	bo = tegra_bo_create(drm, size);
+	if (IS_ERR(bo))
+		return bo;
+
+	ret = drm_gem_handle_create(file, &bo->gem, handle);
+	if (ret)
+		goto err;
+
+	drm_gem_object_unreference_unlocked(&bo->gem);
+
+	return bo;
+
+err:
+	tegra_bo_free_object(&bo->gem);
+	return ERR_PTR(ret);
+}
+
+void tegra_bo_free_object(struct drm_gem_object *gem)
+{
+	struct tegra_bo *bo = to_tegra_bo(gem);
+
+	drm_gem_free_mmap_offset(gem);
+	drm_gem_object_release(gem);
+	tegra_bo_destroy(gem->dev, bo);
+
+	kfree(bo);
+}
+
+int tegra_bo_dumb_create(struct drm_file *file, struct drm_device *drm,
+			 struct drm_mode_create_dumb *args)
+{
+	int min_pitch = DIV_ROUND_UP(args->width * args->bpp, 8);
+	struct tegra_bo *bo;
+
+	if (args->pitch < min_pitch)
+		args->pitch = min_pitch;
+
+	if (args->size < args->pitch * args->height)
+		args->size = args->pitch * args->height;
+
+	bo = tegra_bo_create_with_handle(file, drm, args->size,
+					 &args->handle);
+	if (IS_ERR(bo))
+		return PTR_ERR(bo);
+
+	return 0;
+}
+
+int tegra_bo_dumb_map_offset(struct drm_file *file, struct drm_device *drm,
+			     uint32_t handle, uint64_t *offset)
+{
+	struct drm_gem_object *gem;
+	struct tegra_bo *bo;
+
+	mutex_lock(&drm->struct_mutex);
+
+	gem = drm_gem_object_lookup(drm, file, handle);
+	if (!gem) {
+		dev_err(drm->dev, "failed to lookup GEM object\n");
+		mutex_unlock(&drm->struct_mutex);
+		return -EINVAL;
+	}
+
+	bo = to_tegra_bo(gem);
+
+	*offset = drm_vma_node_offset_addr(&bo->gem.vma_node);
+
+	drm_gem_object_unreference(gem);
+
+	mutex_unlock(&drm->struct_mutex);
+
+	return 0;
+}
+
+const struct vm_operations_struct tegra_bo_vm_ops = {
+	.open = drm_gem_vm_open,
+	.close = drm_gem_vm_close,
+};
+
+int tegra_drm_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	struct drm_gem_object *gem;
+	struct tegra_bo *bo;
+	int ret;
+
+	ret = drm_gem_mmap(file, vma);
+	if (ret)
+		return ret;
+
+	gem = vma->vm_private_data;
+	bo = to_tegra_bo(gem);
+
+	ret = remap_pfn_range(vma, vma->vm_start, bo->paddr >> PAGE_SHIFT,
+			      vma->vm_end - vma->vm_start, vma->vm_page_prot);
+	if (ret)
+		drm_gem_vm_close(vma);
+
+	return ret;
+}
